{"filename": "covid-optimize.py", "chunked_list": ["import os\n\timport argparse\n\tfrom fairseq_models import AntibodyRobertaModel\n\tfrom torch.nn.utils.rnn import pad_sequence\n\timport numpy as np\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\tfrom fairseq import utils\n\tfrom fairseq.data import encoders\n", "from fairseq import checkpoint_utils\n\tfrom tqdm import tqdm\n\tfrom fairseq.data import Dictionary\n\tfrom fairseq_models.data.abgen_dataset import AntibodyComplexDataset\n\tfrom fairseq_models.data.ab_dictionary import ALPHABET\n\tfrom fairseq_models.modules.utils import compute_rmsd\n\tfrom fairseq.data import data_utils\n\timport json\n\timport csv\n\timport math, random, sys\n", "import numpy as np\n\timport argparse\n\timport os\n\tfrom copy import deepcopy\n\tfrom tqdm import tqdm, trange\n\tfrom neut_model import *\n\tfrom structgen import *\n\tfrom igfold import IgFoldRunner\n\tclass CovidNeutralizationModel():\n\t    def __init__(self):\n", "        MODEL_PATH = \"checkpoints/pretrained/ckpts/covid/neut_model1.ckpt\"\n\t        MODEL_ARGS = {\n\t            \"hidden_dim\": 256,\n\t            \"n_layers\": 2,\n\t            \"use_srupp\": False\n\t        }\n\t        MODEL_ARGS.update(MultiABOnlyCoronavirusModel.add_extra_args())\n\t        self.model = MultiABOnlyCoronavirusModel.load_from_checkpoint(\n\t            MODEL_PATH,\n\t            **MODEL_ARGS,  # type: ignore\n", "        )\n\t        self.model.cuda()\n\t        self.model.eval()\n\t    def predict(self, vh, vl):\n\t        ab_sequence = vh\n\t        ab_sequence = torch.tensor([AA_VOCAB[aa] for aa in ab_sequence]).long()\n\t        ab_sequence = ab_sequence.unsqueeze(0).cuda()\n\t        neut_logits = self.model(ab_sequence)\n\t        prob = torch.sigmoid(neut_logits)\n\t        return prob[0, 1].item()\n", "def data_curate(batch, seq_vocab, tag_vocab, mask_idx):\n\t    entry = batch\n\t    # construct data for ABGNN\n\t    surface = torch.tensor(\n\t            [i for i,v in enumerate(entry['cdr']) if v in ['3']]\n\t    )\n\t    paratope_surface = surface\n\t    seq_len = len(entry['seq'])\n\t    cdr_len = len(surface)\n\t    antibody_coords = torch.zeros((seq_len, 4, 3))\n", "    mask_cdr_coords = torch.zeros((cdr_len, 4, 3))\n\t    paratope_coords = mask_cdr_coords.clone()\n\t    paratope_seq = ''.join([entry['seq'][i] for i in surface.tolist()])\n\t    paratope_seq = torch.tensor([ALPHABET.index(a) for a in paratope_seq])\n\t    antibody_seq = torch.tensor([seq_vocab.index(a) for a in batch['seq']])\n\t    antibody_cdr = torch.tensor([tag_vocab.index(a) for a in entry['cdr']])\n\t    # data for AbBERT\n\t    cdr_mask = antibody_cdr == tag_vocab.index('3')\n\t    masked_antibody_seq = torch.full_like(antibody_seq, mask_idx)\n\t    masked_antibody_seq[~cdr_mask] = antibody_seq[~cdr_mask]\n", "    label_antibody_seq = torch.full_like(antibody_seq, seq_vocab.pad())\n\t    label_antibody_seq[cdr_mask] = antibody_seq[cdr_mask]\n\t    antibody_seq = antibody_seq - 3\n\t    cdr_string = entry['cdr']\n\t    return masked_antibody_seq.cuda(), antibody_cdr.cuda(), label_antibody_seq.cuda(), \\\n\t            paratope_seq.cuda(), paratope_coords.cuda(), \\\n\t            paratope_surface.cuda(), mask_cdr_coords.cuda(), \\\n\t            antibody_coords.cuda(), antibody_seq.cuda(), cdr_string\n\tdef collater(batch, pad_idx):\n\t    try:\n", "        masked_antibody_seq, antibody_cdr, label_antibody_seq, \\\n\t        paratope_seq, paratope_coords, \\\n\t        paratope_surface, mask_cdr_coords, \\\n\t        antibody_coords, antibody_seq, cdr_string \\\n\t        = tuple(zip(*batch))\n\t    except:\n\t        return None\n\t    # for bert\n\t    batched_seq = data_utils.collate_tokens(masked_antibody_seq, pad_idx, left_pad=False)\n\t    batched_tag = data_utils.collate_tokens(antibody_cdr, pad_idx, left_pad=False)\n", "    batched_label = data_utils.collate_tokens(label_antibody_seq, pad_idx, left_pad=False)\n\t    # for decoder \n\t    def featurize_paratope(seq_batch, coords_batch, mask_cdr_coords_batch):\n\t        X = pad_sequence(coords_batch, batch_first=True, padding_value=0)\n\t        S = pad_sequence(seq_batch, batch_first=True, padding_value=0)\n\t        X_init = torch.cat([i for i in mask_cdr_coords_batch])\n\t        cont_S = torch.cat([i for i in seq_batch])\n\t        return X, S, cont_S, X_init\n\t    def feature_framework(antibody_seq, antibody_coords, antibody_cdr):\n\t        X = pad_sequence(antibody_coords, batch_first=True, padding_value=0)\n", "        S = pad_sequence(antibody_seq, batch_first=True, padding_value=0)\n\t        antibody_cdr = list(antibody_cdr)\n\t        mask = S.bool().float()\n\t        return X, S, antibody_cdr, mask\n\t    paratope = featurize_paratope(paratope_seq, paratope_coords, mask_cdr_coords)\n\t    antibody = feature_framework(antibody_seq, antibody_coords, cdr_string)\n\t    return batched_seq, batched_tag, batched_label, paratope, antibody\n\tdef extract_fn(query):\n\t    all_viruses = [\n\t        x.replace(\"(weak)\", \"\").strip()\n", "        for x in query.replace(\" and \", \";\").replace(\",\", \";\").split(\";\")\n\t    ]\n\t    filtered = [virus for virus in all_viruses if virus in RELEVANT_VIRUSES]\n\t    return set(filtered)\n\tdef load_data():\n\t    # Load antibody data\n\t    with open(\"dataset/exp3-covabdab/CoV-AbDab_050821.csv\", \"r\") as f:\n\t        full_data = list(csv.DictReader(f))\n\t    # First filter to relevant AB's\n\t    full_data = [\n", "        item\n\t        for item in full_data\n\t        if any(\n\t            virus in item[key]\n\t            for virus in RELEVANT_VIRUSES\n\t            for key in RELEVANT_KEYS\n\t        )\n\t        and item[\"Ab or Nb\"] == \"Ab\"  # remove nanobodies\n\t        and len(item[\"VH or VHH\"].strip()) > 2  # ensure sequence available\n\t        and len(item[\"VL\"].strip()) > 2  # ensure sequence available\n", "        and \"S\" in item[\"Protein + Epitope\"]  # ensure binds to S protein\n\t        and TYPE_MAP[item[\"Protein + Epitope\"]] == \"rbd\"\n\t    ]\n\t    sarscov2_ab_data = []\n\t    for item in full_data:\n\t        bindings = set()\n\t        if item[\"Binds to\"]:\n\t            bindings = extract_fn(item[\"Binds to\"])\n\t        non_bindings = set()\n\t        if item[\"Doesn't Bind to\"]:\n", "            non_bindings = extract_fn(item[\"Doesn't Bind to\"])\n\t        neutralizing = set()\n\t        if item[\"Neutralising Vs\"]:\n\t            neutralizing = extract_fn(item[\"Neutralising Vs\"])\n\t        non_neutralizing = set()\n\t        if item[\"Not Neutralising Vs\"]:\n\t            non_neutralizing = extract_fn(item[\"Not Neutralising Vs\"])\n\t        all_viruses = bindings | non_bindings | neutralizing | non_neutralizing\n\t        full_label = [0, 0]\n\t        full_mask = [0, 0]\n", "        for virus in all_viruses:\n\t            label = [0, 0]\n\t            mask = [0, 0]\n\t            if virus in bindings and neutralizing:\n\t                label = [1, 1]\n\t                mask = [1, 1]\n\t            elif virus in bindings and non_neutralizing:\n\t                label = [0, 1]\n\t                mask = [1, 1]\n\t            elif virus in non_bindings:\n", "                label = [0, 0]\n\t                mask = [1, 1]\n\t            elif virus in neutralizing:\n\t                label = [1, 1]\n\t                mask = [1, 1]\n\t            elif virus in bindings:\n\t                label = [0, 1]\n\t                mask = [0, 1]\n\t            elif virus in non_neutralizing:\n\t                label = [0, 1]\n", "                mask = [1, 0]\n\t            idx = virus == \"SARS-CoV2\"\n\t            full_label[idx] = label[0]\n\t            full_mask[idx] = mask[0]\n\t        # Save sars-cov2 data for later\n\t        sarscov2_ab_data.append({\n\t            'name': item[\"\\ufeffName\"],\n\t            'label': full_label[1],\n\t            'mask': full_mask[1],\n\t            'epitope': TYPE_MAP[item[\"Protein + Epitope\"]],\n", "            'ab': item[\"VH or VHH\"].replace(\" \", \"\") + \"-\" + item[\"VL\"].replace(\" \", \"\"),\n\t            'hcdr3': item[\"CDRH3\"],\n\t            'lcdr3': item[\"CDRL3\"],\n\t        })\n\t    return sarscov2_ab_data\n\tdef make_entry(d, args, igfold):\n\t    entry = {k: d[k] for k in ['name', 'hcdr3', 'lcdr3']}\n\t    entry['VH'], entry['VL'] = d['ab'].split('-')\n\t    assert entry['VH'].count(entry['hcdr3']) == 1\n\t    entry['context'] = entry['VH'].replace(entry['hcdr3'], '#' * len(entry['hcdr3']))\n", "    fw1, fw2 = entry['context'].replace('#', ' ').split()\n\t    entry['cdr'] = '0' * len(fw1) + '3' * len(entry['hcdr3']) + '0' * len(fw2)\n\t    sequences = {\n\t        \"H\": entry['VH'],\n\t        \"L\": entry['VL'],\n\t    }\n\t    pred_pdb = \"checkpoints/exp3-igfold-structs/\" + entry['name'] + \".pdb\" # save dir\n\t    predicted_pdb = igfold.fold(\n\t        pred_pdb, # Output PDB file\n\t        sequences=sequences, # Antibody sequences\n", "        do_refine=False, # Refine the antibody structure with PyRosetta\n\t        do_renum=False, # Renumber predicted antibody structure (Chothia)\n\t    )\n\t    coords = np.array(predicted_pdb.coords[0, :len(entry['VH'])].cpu()) # (N, 5, 3)\n\t    entry['coords'] = {\n\t            \"N\": coords[:, 0],\n\t            \"CA\":coords[:, 1],\n\t            \"C\": coords[:, 2],\n\t            \"O\": coords[:, 4],\n\t    }\n", "    entry['label'] = d['label']\n\t    entry['seq'] = entry['VH'] if args.architecture == 'hierarchical' else entry['hcdr3']\n\t    return entry\n\t# Decode new sequences\n\tdef decode(model, ab, args, seq_vocab, tag_vocab, mask_idx):\n\t    ab = data_curate(ab, seq_vocab, tag_vocab, mask_idx)\n\t    batch = [ab] * args.batch_size\n\t    model.eval()\n\t    model.inference = True\n\t    with torch.no_grad():\n", "        batched_seq, batched_tag, batched_label, paratope, antibody = collater(batch, seq_vocab.pad())\n\t        masked_tokens = batched_label.ne(seq_vocab.pad())\n\t        sample_size = masked_tokens.int().sum()\n\t        out = model(\n\t            src_tokens=batched_seq, \n\t            tag_tokens=batched_tag,\n\t            paratope=paratope,\n\t            epitope=None,\n\t            antibody=antibody,\n\t            masked_tokens=masked_tokens,\n", "            num_decode=1\n\t            )[0]\n\t        new_seqs = out.handle\n\t    return new_seqs, out.ppl.exp()\n\tdef evaluate(model, predictor, evaluator, data, args, seq_vocab, tag_vocab, mask_idx):\n\t    succ, tot = 0, 0\n\t    sum_ppl, tot_aa = 0., 0.\n\t    model.eval()\n\t    with torch.no_grad():\n\t        for ab in tqdm(data):\n", "            # print(ab)\n\t            new_seqs, ppl = decode(model, ab, args, seq_vocab, tag_vocab, mask_idx)\n\t            tot = tot + len(new_seqs)\n\t            prior_ppl = is_natural_seq(evaluator, ab, new_seqs)\n\t            for new_cdr, ppl in zip(new_seqs, prior_ppl):\n\t                if is_valid_seq(new_cdr) and ppl <= args.max_prior_ppl:\n\t                    VH = ab['VH'].replace(ab['hcdr3'], new_cdr)\n\t                    prob = predictor.predict(VH, ab['VL'])\n\t                    succ = succ + prob\n\t                else:\n", "                    succ = succ + ab['score']  # not valid, improvement=0\n\t            sum_ppl += ppl * len(new_seqs)\n\t            tot_aa += len(new_seqs)\n\t    return succ / tot, sum_ppl / tot_aa\n\t# Glycoslation is bad\n\tdef is_valid_seq(cdr):\n\t    if '#' in cdr: return False\n\t    charge = [CHARGE[x] for x in cdr]\n\t    if sum(charge) >= 3 or sum(charge) <= -3:\n\t        return False\n", "    for a in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n\t        if ('N' + a + 'T') in cdr:\n\t            return False\n\t        if ('N' + a + 'S') in cdr:\n\t            return False\n\t        if (a * 4) in cdr:\n\t            return False\n\t    return True\n\tdef is_natural_seq(evaluator, ab, cand_cdrs):\n\t    with torch.no_grad():\n", "        batch = []\n\t        for cdr in cand_cdrs:\n\t            ab = deepcopy(ab)\n\t            ab['seq'] = ab['VH'].replace(ab['hcdr3'], cdr)\n\t            batch.append(ab)\n\t        hX, hS, hL, hmask = completize(batch)\n\t        cand_ppl1 = evaluator[0].log_prob(hS, hL, hmask).ppl.exp()\n\t        batch = []\n\t        for cdr in cand_cdrs:\n\t            ab = deepcopy(ab)\n", "            ab['seq'] = cdr\n\t            batch.append(ab)\n\t        (hX, hS, hL, hmask), context = featurize(batch, context=True)\n\t        cand_ppl2 = evaluator[1].log_prob(hS, hmask, context=context).ppl.exp()\n\t        cand_ppl3 = evaluator[2].log_prob(hS, hmask, context=context).ppl.exp()\n\t        cand_ppl = torch.maximum(cand_ppl1, torch.maximum(cand_ppl2, cand_ppl3))\n\t    return cand_ppl.tolist()\n\tdef main(args):\n\t    modelhub = AntibodyRobertaModel.from_pretrained(\n\t        model_name_or_path=args.cktpath,\n", "        inference=True,\n\t        fix_bert_param=args.fix_bert_param,\n\t    )\n\t    optimizer = modelhub.optimizer\n\t    model = modelhub.model\n\t    seq_vocab = modelhub.task.source_dictionary\n\t    tag_vocab = modelhub.task.tag_source_dictionary\n\t    mask_idx = modelhub.task.mask_idx\n\t    model.cuda()\n\t    def print_parameter_number(net):\n", "        net_name = type(net).__name__\n\t        total_num = sum(p.numel() for p in net.parameters())\n\t        trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n\t        print(f'{net_name} total parameters:{total_num}, trainable: {trainable_num}')\n\t    # print_parameter_number(model.classification_heads)\n\t    print_parameter_number(model)\n\t    os.makedirs(args.save_dir, exist_ok=True)\n\t    split_map = {}\n\t    with open(args.cluster) as f:\n\t        for line in f:\n", "            cdr3, fold = line.strip(\"\\r\\n \").split()\n\t            split_map[cdr3] = fold\n\t    torch.manual_seed(args.seed)\n\t    np.random.seed(args.seed)\n\t    random.seed(args.seed)\n\t    predictor = CovidNeutralizationModel()\n\t    optimizer.set_lr(args.lr)\n\t    # Language model ensemble (ensure CDR naturalness) \n\t    evaluator = [None, None, None]\n\t    eval_args = deepcopy(args)\n", "    eval_args.hidden_size = 256\n\t    eval_args.depth = 4\n\t    eval_args.block_size = 8\n\t    evaluator[0] = HierarchicalDecoder(eval_args).cuda()\n\t    evaluator[0].eval()\n\t    model_ckpt = torch.load(\"checkpoints/pretrained/ckpts/covid/hieratt.ckpt\")[0]\n\t    evaluator[0].load_state_dict(model_ckpt)\n\t    eval_args = deepcopy(args)\n\t    eval_args.hidden_size = 128\n\t    eval_args.depth = 1\n", "    evaluator[1] = Seq2Seq(eval_args).cuda()\n\t    evaluator[1].eval()\n\t    model_ckpt = torch.load(\"checkpoints/pretrained/ckpts/covid/lstm.ckpt\")[0]\n\t    evaluator[1].load_state_dict(model_ckpt)\n\t    eval_args = deepcopy(args)\n\t    eval_args.hidden_size = 256\n\t    eval_args.depth = 3\n\t    evaluator[2] = Decoder(eval_args, return_coords=False).cuda()\n\t    evaluator[2].eval()\n\t    model_ckpt = torch.load(\"checkpoints/pretrained/ckpts/covid/autoreg.ckpt\")[0]\n", "    evaluator[2].load_state_dict(model_ckpt)\n\t    # data preparation\n\t    igfold = IgFoldRunner()\n\t    all_ab = [make_entry(d, args, igfold) for d in load_data() if d['hcdr3'] in d['ab'] and d['mask'] == 1]\n\t    for entry in tqdm(all_ab):\n\t        entry['score'] = predictor.predict(entry['VH'], entry['VL'])\n\t    train_ab = [d for d in all_ab if split_map[d['hcdr3']] == 'train' and d['label'] == 1]\n\t    val_ab = [d for d in all_ab if split_map[d['hcdr3']] == 'val' and d['label'] == 1]\n\t    test_ab = [d for d in all_ab if split_map[d['hcdr3']] == 'test' and d['label'] == 1]\n\t    print(\"train/val/test:\", len(train_ab), len(val_ab), len(test_ab))\n", "    train_data = {entry['name'] : [entry] for entry in train_ab}\n\t    best_score, best_epoch = -10.0, 0\n\t    cross_entropy = nn.CrossEntropyLoss(reduction=\"sum\", ignore_index=seq_vocab.pad())\n\t    for e in trange(args.epochs):\n\t        # Decode new cdrs\n\t        ab = random.choice(train_ab)\n\t        name = ab['name']\n\t        new_seqs, _ = decode(model, ab, args, seq_vocab, tag_vocab, mask_idx)\n\t        prior_ppl = is_natural_seq(evaluator, ab, new_seqs)\n\t        for new_cdr, ppl in zip(new_seqs, prior_ppl):\n", "            if is_valid_seq(new_cdr) and ppl <= args.max_prior_ppl:\n\t                entry = deepcopy(ab)\n\t                entry['VH'] = entry['VH'].replace(entry['hcdr3'], new_cdr)\n\t                prob = predictor.predict(entry['VH'], entry['VL'])\n\t                #print(name, entry['hcdr3'], entry['score'], '-->', new_cdr, prob)\n\t                if prob > entry['score']: # first round: about 24 in 200\n\t                    entry['score'] = prob\n\t                    entry['hcdr3'] = new_cdr\n\t                    entry['seq'] = entry['VH'] if args.architecture == 'hierarchical' else entry['hcdr3']\n\t                    train_data[name].append(entry)\n", "        if name in train_data:\n\t            dlist = sorted(train_data[name], key=lambda d:d['score'], reverse=True)\n\t            train_data[name] = dlist[:args.topk]\n\t        else:\n\t            exit(0)\n\t        # Train model\n\t        model.train()\n\t        model.inference = False\n\t        optimizer.zero_grad()\n\t        train_keys = sorted(train_data.keys())\n", "        name = random.choice(train_keys)\n\t        batch = train_data[name]\n\t        name_samples = []\n\t        for name_sample in batch:\n\t            name_samples.append(data_curate(name_sample, seq_vocab, tag_vocab, mask_idx))\n\t        batched_seq, batched_tag, batched_label, paratope, antibody = collater(name_samples, seq_vocab.pad())\n\t        masked_tokens = batched_label.ne(seq_vocab.pad())\n\t        sample_size = masked_tokens.int().sum()\n\t        out, transformer_logits, _ = model(\n\t            src_tokens=batched_seq, \n", "            tag_tokens=batched_tag,\n\t            paratope=paratope,\n\t            epitope=None,\n\t            antibody=antibody,\n\t            masked_tokens=masked_tokens\n\t            )\n\t        # compute encoder loss\n\t        if out.nll == 0.: # bertonly ablation\n\t            targets = batched_label\n\t            if masked_tokens is not None:\n", "                targets = targets[masked_tokens]\n\t            loss = cross_entropy(\n\t                transformer_logits.view(-1, transformer_logits.size(-1)),\n\t                targets.view(-1) - 3, \n\t            ) / sample_size / math.log(2)\n\t        else:\n\t            loss = out.nll\n\t        loss.backward()\n\t        optimizer.step()\n\t        if (e + 1) % args.valid_iter == 0:\n", "            ckpt = (model.state_dict(), optimizer.state_dict())\n\t            torch.save(ckpt, os.path.join(args.save_dir, f\"model.ckpt.{e+1}\"))\n\t            val_score, val_ppl = evaluate(model, predictor, evaluator, val_ab, args, seq_vocab, tag_vocab, mask_idx)\n\t            test_score, test_ppl = evaluate(model, predictor, evaluator, test_ab, args, seq_vocab, tag_vocab, mask_idx)\n\t            print(f'Epoch {e+1}: average valid neutralization score: {val_score:.3f}')\n\t            print(f'             average valid ppl: {val_ppl:.3f}')\n\t            print(f'Epoch {e+1}: average test neutralization score: {test_score:.3f}')\n\t            print(f'             average test ppl: {test_ppl:.3f}')\n\t            if val_score > best_score:\n\t                best_epoch = e + 1\n", "                best_score = val_score\n\t    # best_epoch = 10000\n\t    if best_epoch > 0:\n\t        best_ckpt = os.path.join(args.save_dir, f\"model.ckpt.{best_epoch}\")\n\t        model.load_state_dict(torch.load(best_ckpt)[0])\n\t    test_score, test_ppl = evaluate(model, predictor, evaluator, test_ab, args, seq_vocab, tag_vocab, mask_idx)\n\t    print(f'Test average neutralization score: {test_score:.3f}')\n\t    print(f'             average test ppl: {test_ppl:.3f}')\n\tif __name__ == \"__main__\":\n\t    parser = argparse.ArgumentParser()\n", "    # data and ckpts\n\t    parser.add_argument(\"--cluster\", type=str, default=\"dataset/exp3-covabdab/cdrh3_split.txt\")\n\t    parser.add_argument(\"--cktpath\", type=str, default=\"checkpoints/0301-exp3-sabdab/checkpoint_best.pt\")\n\t    parser.add_argument(\"--save_dir\", type=str, default='checkpoints/exp3-ckpts/temp')\n\t    # training settings    \n\t    parser.add_argument(\"--seed\", type=int, default=42)\n\t    parser.add_argument(\"--batch_size\", type=int, default=100)\n\t    parser.add_argument(\"--lr\", type=float, default=1e-4)\n\t    parser.add_argument(\"--epochs\", type=int, default=10000)\n\t    parser.add_argument(\"--valid_iter\", type=int, default=1000)\n", "    parser.add_argument(\"--topk\", type=int, default=16)\n\t    parser.add_argument(\"--fix_bert_param\", action=\"store_true\", default=False)\n\t    # evaluate naturalness (and relevant refinegnn setting)  ===  fixed\n\t    parser.add_argument(\"--load_model\", type=str, default=\"checkpoints/pretrained/RefineGNN-rabd/model.best\")\n\t    parser.add_argument(\"--architecture\", type=str, default=\"hierarchical\")\n\t    parser.add_argument(\"--cdr_type\", type=str, default=\"3\")\n\t    parser.add_argument(\"--hidden_size\", type=int, default=256)\n\t    parser.add_argument(\"--k_neighbors\", type=int, default=9)\n\t    parser.add_argument(\"--update_freq\", type=int, default=1)\n\t    parser.add_argument(\"--augment_eps\", type=float, default=3.0)\n", "    parser.add_argument(\"--block_size\", type=int, default=8)\n\t    parser.add_argument(\"--depth\", type=int, default=4)\n\t    parser.add_argument(\"--vocab_size\", type=int, default=21)\n\t    parser.add_argument(\"--num_rbf\", type=int, default=16)\n\t    parser.add_argument(\"--dropout\", type=float, default=0.1)\n\t    parser.add_argument(\"--max_prior_ppl\", type=int, default=10)\n\t    parser.add_argument(\"--context\", type=bool, default=True)\n\t    args = parser.parse_args()\n\t    assert os.path.exists(args.cktpath)\n\t    main(args)\n"]}
{"filename": "inference.py", "chunked_list": ["import os\n\timport argparse\n\tfrom fairseq_models import AntibodyRobertaModel\n\timport numpy as np\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\tfrom fairseq import utils\n\tfrom fairseq.data import encoders\n\tfrom fairseq import checkpoint_utils\n", "from tqdm import tqdm\n\tfrom fairseq.data import Dictionary\n\tfrom fairseq_models.data.abgen_dataset import AntibodyComplexDataset\n\tfrom fairseq_models.data.ab_dictionary import ALPHABET\n\tfrom fairseq_models.modules.utils import compute_rmsd\n\tdef main(args):\n\t    modelhub = AntibodyRobertaModel.from_pretrained(\n\t        model_name_or_path=args.cktpath,\n\t        inference=True,\n\t    )\n", "    modelhub.cuda()\n\t    modelhub.eval()\n\t    num_decode=args.num_decode\n\t    succ, tot = 0, 0\n\t    tot_ppl = 0.\n\t    topk=args.topk\n\t    dataset = AntibodyComplexDataset(\n\t        data_path=args.data_path,\n\t        split=args.split,\n\t        seq_vocab=modelhub.task.source_dictionary,\n", "        tag_vocab=modelhub.task.tag_source_dictionary,\n\t        cdr_types=[args.cdr_type],\n\t        L_target=20,\n\t        pad_idx=modelhub.task.source_dictionary.pad(),\n\t        mask_idx=modelhub.task.mask_idx,\n\t        max_len=256\n\t    )\n\t    print('PDB', 'Native', 'Designed', 'Perplexity', 'RMSD')\n\t    sum_rmsd = 0.\n\t    with torch.no_grad():\n", "        for ab in tqdm(dataset):\n\t            new_cdrs, new_ppl, new_rmsd = [], [], []\n\t            sample = dataset.collater([ab] * 1)\n\t            batched_seq, batched_tag, batched_label, paratope, epitope, antibody = sample\n\t            batched_seq, batched_tag, batched_label = [item.to(modelhub.device) for item in [batched_seq, batched_tag, batched_label]]\n\t            paratope = [item.to(modelhub.device) for item in paratope]\n\t            epitope = [item.to(modelhub.device) for item in epitope]\n\t            antibody_X, antibody_S, antibody_cdr, padding_mask = antibody\n\t            antibody_X, antibody_S, antibody_cdr, padding_mask = antibody_X.to(modelhub.device), antibody_S.to(modelhub.device), antibody_cdr, padding_mask.to(modelhub.device)\n\t            antibody = (antibody_X, antibody_S, antibody_cdr, padding_mask)\n", "            masked_tokens = batched_label.ne(modelhub.task.source_dictionary.pad())\n\t            sample_size = masked_tokens.int().sum()\n\t            out = modelhub.model(\n\t                src_tokens=batched_seq, \n\t                tag_tokens=batched_tag,\n\t                paratope=paratope,\n\t                epitope=epitope,\n\t                antibody=antibody,\n\t                masked_tokens=masked_tokens,\n\t                num_decode=num_decode\n", "            )[0]\n\t            bind_X, bind_S, _, _ = paratope\n\t            bind_mask = bind_S > 0\n\t            out_X = out.bind_X.unsqueeze(0)\n\t            rmsd = compute_rmsd(\n\t                    out_X[:, :, 1], bind_X[:, :, 1], bind_mask\n\t                )\n\t            new_rmsd.extend([rmsd] * num_decode)\n\t            new_cdrs.extend(out.handle)\n\t            new_ppl.extend(out.ppl.tolist())\n", "            orig_cdr = ''.join([ALPHABET[i] for i in ab[3]])\n\t            new_res = sorted(zip(new_cdrs, new_ppl, new_rmsd), key=lambda x:x[1])\n\t            for cdr,ppl,rmsd in new_res[:topk]:\n\t                # print(orig_cdr, cdr, '%.3f' % ppl, '%.4f' % rmsd)\n\t                match = [int(a == b) for a,b in zip(orig_cdr, cdr)]\n\t                succ += sum(match) \n\t                tot += len(match)\n\t                tot_ppl += ppl\n\t                sum_rmsd += rmsd\n\t    print(f'PPL = {tot_ppl / len(dataset) / topk:.4f}')\n", "    print(f'RMSD = {sum_rmsd.item() / len(dataset) / topk:.4f}')\n\t    print(f'Amino acid recovery rate = {succ / tot:.4f}') \n\tif __name__ == \"__main__\":\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\"--cktpath\", type=str, default='checkpoints/baseline/checkpoint_best.pt')\n\t    parser.add_argument(\"--num_decode\", type=int, default=10000)\n\t    parser.add_argument(\"--topk\", type=int, default=100)\n\t    parser.add_argument(\"--cdr_type\", type=str, default='3')\n\t    parser.add_argument(\"--data_path\", type=str, default=\"dataset/exp2-hern\")\n\t    parser.add_argument(\"--split\", type=str, default=\"test\")\n", "    args = parser.parse_args()\n\t    assert os.path.exists(args.cktpath)\n\t    main(args)\n"]}
{"filename": "neut_model.py", "chunked_list": ["from typing import Dict, Optional, Tuple\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport pytorch_lightning as pl\n\tfrom torch import Tensor\n\tfrom pytorch_lightning.callbacks import ModelCheckpoint\n\tAA_VOCAB = {\n\t    \"#\": 0,\n\t    \"A\": 1,\n", "    \"R\": 2,\n\t    \"N\": 3,\n\t    \"D\": 4,\n\t    \"C\": 5,\n\t    \"Q\": 6,\n\t    \"E\": 7,\n\t    \"G\": 8,\n\t    \"H\": 9,\n\t    \"I\": 10,\n\t    \"L\": 11,\n", "    \"K\": 12,\n\t    \"M\": 13,\n\t    \"F\": 14,\n\t    \"P\": 15,\n\t    \"S\": 16,\n\t    \"T\": 17,\n\t    \"W\": 18,\n\t    \"Y\": 19,\n\t    \"V\": 20,\n\t    \"X\": 21,\n", "    \"-\": 22,\n\t    \"O\": 23,\n\t    \"*\": 24,\n\t}\n\tRELEVANT_VIRUSES = {\"SARS-CoV1\", \"SARS-CoV2\"}\n\tRELEVANT_KEYS = {\n\t    \"Neutralising Vs\",\n\t    \"Not Neutralising Vs\",\n\t    \"Binds to\",\n\t    \"Doesn't Bind to\",\n", "}\n\tTYPE_MAP = {\n\t    \"S1; non-RBD\": \"ntd\",\n\t    \"S2 (quaternary glycan epitope)\": \"s2\",\n\t    \"S: NTD\": \"ntd\",\n\t    \"S: RBD\": \"rbd\",\n\t    \"S; NTD\": \"ntd\",\n\t    \"S; Possibly RBD\": \"rbd\",\n\t    \"S; RBD\": \"rbd\",\n\t    \"S; RBD/non-RBD\": \"unk\",\n", "    \"S; S1\": \"unk\",\n\t    \"S; S1 non-RBD\": \"ntd\",\n\t    \"S; S1/S2\": \"unk\",\n\t    \"S; S1/S2 Cleavage Site\": \"unk\",\n\t    \"S; S2\": \"s2\",\n\t    \"S; S2 (quaternary glycan epitope)\": \"s2\",\n\t    \"S; S2 Stem Helix\": \"s2\",\n\t    \"S; Unk\": \"unk\",\n\t    \"S; non-RBD\": \"unk\",\n\t    \"S; non-S1\": \"s2\",\n", "    \"S; probably RBD (implied by clustering)\": \"rbd\",\n\t}\n\tclass RNNEncoder(nn.Module):\n\t    \"\"\"Implements a multi-layer RNN.\n\t    This module can be used to create multi-layer RNN models, and\n\t    provides a way to reduce to output of the RNN to a single hidden\n\t    state by pooling the encoder states either by taking the maximum,\n\t    average, or by taking the last hidden state before padding.\n\t    Padding is dealt with by using torch's PackedSequence.\n\t    Attributes\n", "    ----------\n\t    rnn: nn.Module\n\t        The rnn submodule\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        input_size: int,\n\t        hidden_size: int,\n\t        n_layers: int = 1,\n\t        rnn_type: str = \"lstm\",\n", "        dropout: float = 0,\n\t        attn_dropout: float = 0,\n\t        attn_heads: int = 1,\n\t        bidirectional: bool = False,\n\t        layer_norm: bool = False,\n\t        highway_bias: float = -2,\n\t        rescale: bool = True,\n\t        enforce_sorted: bool = False,\n\t        **kwargs,\n\t    ) -> None:\n", "        \"\"\"Initializes the RNNEncoder object.\n\t        Parameters\n\t        ----------\n\t        input_size : int\n\t            The dimension the input data\n\t        hidden_size : int\n\t            The hidden dimension to encode the data in\n\t        n_layers : int, optional\n\t            The number of rnn layers, defaults to 1\n\t        rnn_type : str, optional\n", "           The type of rnn cell, one of: `lstm`, `gru`, `sru`\n\t           defaults to `lstm`\n\t        dropout : float, optional\n\t            Amount of dropout to use between RNN layers, defaults to 0\n\t        bidirectional : bool, optional\n\t            Set to use a bidrectional encoder, defaults to False\n\t        layer_norm : bool, optional\n\t            [SRU only] whether to use layer norm\n\t        highway_bias : float, optional\n\t            [SRU only] value to use for the highway bias\n", "        rescale : bool, optional\n\t            [SRU only] whether to use rescaling\n\t        enforce_sorted: bool\n\t            Whether rnn should enforce that sequences are ordered by\n\t            length. Requires True for ONNX support. Defaults to False.\n\t        kwargs\n\t            Additional parameters to be passed to SRU when building\n\t            the rnn.\n\t        Raises\n\t        ------\n", "        ValueError\n\t            The rnn type should be one of: `lstm`, `gru`, `sru`\n\t        \"\"\"\n\t        super().__init__()\n\t        self.rnn_type = rnn_type\n\t        self.input_size = input_size\n\t        self.hidden_size = hidden_size\n\t        self.enforce_sorted = enforce_sorted\n\t        self.output_size = 2 * hidden_size if bidirectional else hidden_size\n\t        if rnn_type in [\"lstm\", \"gru\"]:\n", "            rnn_fn = nn.LSTM if rnn_type == \"lstm\" else nn.GRU\n\t            self.rnn = rnn_fn(\n\t                input_size=input_size,\n\t                hidden_size=hidden_size,\n\t                num_layers=n_layers,\n\t                dropout=dropout,\n\t                bidirectional=bidirectional,\n\t            )\n\t        elif rnn_type == \"sru\":\n\t            from sru import SRU\n", "            try:\n\t                self.rnn = SRU(\n\t                    input_size,\n\t                    hidden_size,\n\t                    num_layers=n_layers,\n\t                    dropout=dropout,\n\t                    bidirectional=bidirectional,\n\t                    layer_norm=layer_norm,\n\t                    rescale=rescale,\n\t                    highway_bias=highway_bias,\n", "                    **kwargs,\n\t                )\n\t            except TypeError:\n\t                raise ValueError(f\"Unkown kwargs passed to SRU: {kwargs}\")\n\t        elif rnn_type == \"srupp\":\n\t            from sru import SRUpp\n\t            try:\n\t                self.rnn = SRUpp(\n\t                    input_size,\n\t                    hidden_size,\n", "                    hidden_size // 2,\n\t                    num_layers=n_layers,\n\t                    highway_bias=highway_bias,\n\t                    dropout=dropout,\n\t                    attn_dropout=attn_dropout,\n\t                    num_heads=attn_heads,\n\t                    layer_norm=layer_norm,\n\t                    attn_layer_norm=True,\n\t                    bidirectional=bidirectional,\n\t                    **kwargs,\n", "                )\n\t            except TypeError:\n\t                raise ValueError(f\"Unkown kwargs passed to SRU: {kwargs}\")\n\t        else:\n\t            raise ValueError(f\"Unkown rnn type: {rnn_type}, use of of: gru, sru, lstm\")\n\t    def forward(\n\t        self,\n\t        data: Tensor,\n\t        state: Optional[Tensor] = None,\n\t        padding_mask: Optional[Tensor] = None,\n", "    ) -> Tuple[Tensor, Tensor]:\n\t        \"\"\"Performs a forward pass through the network.\n\t        Parameters\n\t        ----------\n\t        data : Tensor\n\t            The input data, as a float tensor of shape [B x S x E]\n\t        state: Tensor\n\t            An optional previous state of shape [L x B x H]\n\t        padding_mask: Tensor, optional\n\t            The padding mask of shape [B x S], dtype should be bool\n", "        Returns\n\t        -------\n\t        Tensor\n\t            The encoded output, as a float tensor of shape [B x S x H]\n\t        Tensor\n\t            The encoded state, as a float tensor of shape [L x B x H]\n\t        \"\"\"\n\t        data = data.transpose(0, 1)\n\t        if padding_mask is not None:\n\t            padding_mask = padding_mask.transpose(0, 1)\n", "        if padding_mask is None:\n\t            # Default RNN behavior\n\t            output, state = self.rnn(data, state)\n\t        elif self.rnn_type == \"sru\":\n\t            # SRU takes a mask instead of PackedSequence objects\n\t            # ~ operator negates bool tensor in torch 1.3\n\t            output, state = self.rnn(data, state, mask_pad=(~padding_mask))\n\t        elif self.rnn_type == \"srupp\":\n\t            # SRU takes a mask instead of PackedSequence objects\n\t            # ~ operator negates bool tensor in torch 1.3\n", "            output, state, _ = self.rnn(data, state, mask_pad=(~padding_mask))\n\t        else:\n\t            # Deal with variable length sequences\n\t            lengths = padding_mask.long().sum(dim=0)\n\t            # Pass through the RNN\n\t            packed = nn.utils.rnn.pack_padded_sequence(\n\t                data, lengths.cpu(), enforce_sorted=self.enforce_sorted\n\t            )\n\t            output, state = self.rnn(packed, state)\n\t            output, _ = nn.utils.rnn.pad_packed_sequence(output, total_length=data.size(0))\n", "        # TODO investigate why PyTorch returns type Any for output\n\t        return output.transpose(0, 1).contiguous(), state  # type: ignore\n\tclass SRUppModel(nn.Module):\n\t    def __init__(\n\t        self,\n\t        num_aa: int,\n\t        num_tokens: int,\n\t        n_layers: int = 1,\n\t        hidden_dim: int = 256,\n\t        dropout: float = 0,\n", "        ab_pad_id: int = 0,\n\t        virus_pad_id: int = 0,\n\t        use_srupp: bool = False,\n\t    ):\n\t        super().__init__()\n\t        # Virus encoder\n\t        self.hidden_dim = hidden_dim\n\t        self.seq_embedding = nn.Embedding(num_aa, hidden_dim // 4)\n\t        # Antibody encoder\n\t        rnn_type = \"srupp\" if use_srupp else \"sru\"\n", "        self.dropout = nn.Dropout(dropout)\n\t        self.rnn_ab = RNNEncoder(\n\t            hidden_dim // 4,\n\t            hidden_dim // 2,\n\t            n_layers=n_layers,\n\t            rnn_type=rnn_type,\n\t            bidirectional=True,\n\t            dropout=dropout,\n\t        )\n\t        self.ab_pad_id = ab_pad_id\n", "        self.virus_pad_id = virus_pad_id\n\t        self.num_tokens = num_tokens\n\t    @property\n\t    def output_dim(self):\n\t        return self.hidden_dim\n\t    def forward(self, ab_seq):\n\t        # Compute padding mask\n\t        padding_ab = ab_seq != self.ab_pad_id\n\t        # Compute token embeddings\n\t        ab_emb = self.dropout(self.seq_embedding(ab_seq))\n", "        # Pass through SRUpp layers\n\t        ab_encodings, _ = self.rnn_ab(ab_emb, padding_mask=padding_ab)\n\t        return ab_encodings\n\tclass MultiABOnlyCoronavirusModel(pl.LightningModule):\n\t    def __init__(\n\t        self,\n\t        num_aa: int,\n\t        num_tokens: int,\n\t        n_layers: int = 1,\n\t        hidden_dim: int = 128,\n", "        dropout: float = 0,\n\t        lr: float = 1e-3,\n\t        ab_pad_id: int = 0,\n\t        virus_pad_id: int = 0,\n\t        neut_lambda: float = 0.5,\n\t        use_srupp: bool = False,\n\t    ):\n\t        super().__init__()\n\t        self.save_hyperparameters()\n\t        self.lr = lr\n", "        self.ab_pad_id = ab_pad_id\n\t        self.virus_pad_id = virus_pad_id\n\t        self.neut_lambda = neut_lambda\n\t        self.dropout = nn.Dropout(dropout)\n\t        self.encoder = SRUppModel(  # type: ignore\n\t            num_aa=num_aa,\n\t            num_tokens=num_tokens,\n\t            n_layers=n_layers,\n\t            hidden_dim=hidden_dim,\n\t            dropout=dropout,\n", "            ab_pad_id=ab_pad_id,\n\t            virus_pad_id=virus_pad_id,\n\t            use_srupp=use_srupp,\n\t        )\n\t        encoder_dim = self.encoder.output_dim\n\t        self.fc_neut = nn.Sequential(\n\t            nn.Linear(encoder_dim, hidden_dim // 2),\n\t            nn.ReLU(),\n\t            nn.Dropout(),\n\t            nn.Linear(hidden_dim // 2, 2),\n", "        )\n\t        #self.neut_auc_sars2 = AUROCWithMask(\n\t        #    num_classes=2, average=None, compute_on_step=False\n\t        #)\n\t        #self.neut_auc_sars1 = AUROCWithMask(\n\t        #    num_classes=2, average=None, compute_on_step=False\n\t        #)\n\t    @classmethod\n\t    def add_extra_args(cls) -> Dict:\n\t        extra_args = {\n", "            \"num_aa\": len(AA_VOCAB),\n\t            \"num_tokens\": 1024,\n\t            \"ab_pad_id\": AA_VOCAB[\"#\"],\n\t            \"virus_pad_id\": AA_VOCAB[\"#\"],\n\t        }\n\t        return extra_args\n\t    def average(self, data, padding):\n\t        data = (data * padding.unsqueeze(2)).sum(dim=1)\n\t        padding_sum = padding.sum(dim=1)\n\t        padding_sum[padding_sum == 0] = 1.0\n", "        avg = data / padding_sum.unsqueeze(1)\n\t        return avg\n\t    def forward(self, ab_seq):\n\t        padding_mask_ab = (ab_seq != self.ab_pad_id).float()\n\t        ab_encodings = self.encoder(ab_seq)\n\t        output_encoding = self.average(ab_encodings, padding_mask_ab)\n\t        output_encoding = self.dropout(output_encoding)\n\t        neut_logits = self.fc_neut(output_encoding).squeeze(1)\n\t        return neut_logits\n\t    def configure_callbacks(self):\n", "        return [ModelCheckpoint(monitor=\"auc\", save_top_k=1, mode=\"max\")]\n\t    def compute_metrics(self, batch):\n\t        ab_seq = batch[\"ab\"]\n\t        neut_label = batch[\"neut_label\"]\n\t        neut_mask = batch[\"neut_mask\"]\n\t        neut_logits = self(ab_seq)\n\t        neut_loss = F.binary_cross_entropy_with_logits(\n\t            neut_logits, neut_label.float(), reduction=\"none\"\n\t        )\n\t        neut_mask_sum = neut_mask.sum()\n", "        neut_mask_sum = neut_mask_sum if neut_mask_sum > 0 else 1.0\n\t        neut_loss = (neut_loss * neut_mask).sum() / neut_mask_sum\n\t        # Final loss\n\t        loss = neut_loss\n\t        # Compute metrics (ignore neg label 0)\n\t        self.neut_auc_sars1(\n\t            torch.sigmoid(neut_logits[:, 0]),\n\t            neut_label[:, 0].long(),\n\t            neut_mask[:, 0].bool(),\n\t        )\n", "        self.neut_auc_sars2(\n\t            torch.sigmoid(neut_logits[:, 1]),\n\t            neut_label[:, 1].long(),\n\t            neut_mask[:, 1].bool(),\n\t        )\n\t        return loss\n\t    def training_step(self, batch, batch_idx):\n\t        loss = self.compute_metrics(batch)\n\t        self.log(\"loss\", loss, prog_bar=True)\n\t        return loss\n", "    def validation_step(self, batch, batch_idx):\n\t        loss = self.compute_metrics(batch)\n\t        self.log(\"val_loss\", loss, prog_bar=True)\n\t    def training_epoch_end(self, output):\n\t        try:\n\t            neut_auc_sars1 = self.neut_auc_sars1.compute()\n\t        except Exception:\n\t            neut_auc_sars1 = 0.5\n\t        try:\n\t            neut_auc_sars2 = self.neut_auc_sars2.compute()\n", "        except Exception:\n\t            neut_auc_sars2 = 0.5\n\t        self.log(\"train_auc_sars_cov_1\", neut_auc_sars1, prog_bar=False)\n\t        self.log(\"train_auc_sars_cov_2\", neut_auc_sars2, prog_bar=False)\n\t        self.neut_auc_sars1.reset()\n\t        self.neut_auc_sars2.reset()\n\t    def validation_epoch_end(self, output):\n\t        try:\n\t            neut_auc_sars1 = self.neut_auc_sars1.compute()\n\t        except Exception as e:\n", "            print(e)\n\t            neut_auc_sars1 = 0.5\n\t        try:\n\t            neut_auc_sars2 = self.neut_auc_sars2.compute()\n\t        except Exception:\n\t            neut_auc_sars2 = 0.5\n\t        self.log(\"auc\", (neut_auc_sars1 + neut_auc_sars2) / 2, prog_bar=True)\n\t        self.log(\"auc_sars_cov_1\", neut_auc_sars1, prog_bar=True)\n\t        self.log(\"auc_sars_cov_2\", neut_auc_sars2, prog_bar=True)\n\t        self.neut_auc_sars1.reset()\n", "        self.neut_auc_sars2.reset()\n\t    def test_step(self, batch, batch_idx):\n\t        return self.validation_step(batch, batch_idx)\n\t    def test_epoch_end(self, output):\n\t        return self.validation_epoch_end(output)\n\t    def configure_optimizers(self):\n\t        return RAdam((p for p in self.parameters() if p.requires_grad), lr=self.lr)"]}
{"filename": "fairseq_models/__init__.py", "chunked_list": ["from .tasks.abbert_mlm_task import AntibodyMaskedLMTask\n\tfrom .tasks.abgen_task import AntibodyGenerationTask\n\tfrom .criterions.abbert_masked_lm import AntibodyMaskedLmLoss\n\tfrom .criterions.abgen_criterions import AntibodyGenerationLoss\n\tfrom .models.ab_roberta_base import AntibodyRobertaModel\n"]}
{"filename": "fairseq_models/data/abgen_dataset_noantigen.py", "chunked_list": ["import torch\n\tfrom torch.nn.utils.rnn import pad_sequence\n\timport numpy as np\n\timport json, copy\n\timport torch.nn.functional as F\n\tfrom tqdm import tqdm\n\tfrom collections import defaultdict\n\tfrom fairseq_models.modules.utils import full_square_dist\n\tfrom functools import lru_cache\n\tfrom pathlib import Path\n", "from fairseq.data import (\n\t    data_utils,\n\t    Dictionary,\n\t    FairseqDataset\n\t)\n\tfrom .ab_dictionary import (\n\t    ALPHABET,\n\t    ALPHABET_FULL,\n\t    RESTYPE_1to3,\n\t    ATOM_TYPES,\n", "    RES_ATOM14,\n\t    UNK_LIST\n\t)\n\tclass AntibodyOnlyDataset(FairseqDataset):\n\t    def __init__(self, data_path, split, seq_vocab, tag_vocab, cdr_types, L_target, pad_idx, mask_idx, max_len):\n\t        if split not in ('train', 'valid', 'test'):\n\t            raise ValueError(f\"Unrecognized split: {split}. \"\n\t                             f\"Must be one of ['train', 'valid', 'test']\")\n\t        data_path = Path(data_path)\n\t        data_file = f'{split}_data.jsonl'\n", "        jsonl_file = data_path / data_file\n\t        self.seq_vocab = seq_vocab\n\t        self.tag_vocab = tag_vocab\n\t        self.cdr_types = cdr_types\n\t        self.pad_idx = pad_idx\n\t        self.mask_idx = mask_idx\n\t        self.cdr_types = cdr_types\n\t        self.data = []\n\t        with open(jsonl_file) as f:\n\t            all_lines = f.readlines()\n", "            for line in tqdm(all_lines):\n\t                entry = json.loads(line)\n\t                assert len(entry['antibody_coords']) == len(entry['antibody_seq'])\n\t                for cdr in cdr_types:\n\t                    if entry['antibody_cdr'].count(cdr) <= 4:\n\t                        continue\n\t                if entry['pdb'] in UNK_LIST:\n\t                    continue\n\t                if len(entry['antibody_seq']) > max_len:\n\t                    continue\n", "                if entry['antibody_cdr'][-1] != '0':\n\t                    # print('no fwr4')\n\t                    continue\n\t                # zero struct and cdr3 only\n\t                # seq_len = len(entry['antibody_seq'])\n\t                # entry['antibody_coords'] = torch.zeros((seq_len, 4, 3))\n\t                entry['antibody_cdr'] = entry['antibody_cdr'].replace(\"1\", \"0\")\n\t                entry['antibody_cdr'] = entry['antibody_cdr'].replace(\"2\", \"0\")\n\t                # paratope region\n\t                surface = torch.tensor(\n", "                        [i for i,v in enumerate(entry['antibody_cdr']) if v in cdr_types]\n\t                )\n\t                entry['paratope_surface'] = surface\n\t                entry['cdr_string'] = entry['antibody_cdr']\n\t                l_coord, r_coord = torch.tensor(entry['antibody_coords'])[surface[0] - 1], torch.tensor(entry['antibody_coords'])[surface[-1] + 1]\n\t                n_span = len(surface) + 1\n\t                coord_offsets = (r_coord - l_coord).unsqueeze(0).expand(n_span - 1, 4, 3) \n\t                coord_offsets = torch.cumsum(coord_offsets, dim=0)\n\t                mask_cdr_coords = l_coord + coord_offsets / n_span # [cdr_len, 4, 3]\n\t                entry['mask_cdr_coords'] = mask_cdr_coords\n", "                entry['paratope_seq'] = ''.join([entry['antibody_seq'][i] for i in surface.tolist()])\n\t                entry['paratope_coords'] = torch.tensor(entry['antibody_coords'])[surface]\n\t                if len(entry['paratope_coords']) > 4 and entry['antibody_cdr'].count('001') <= 1:\n\t                    # string to list\n\t                    entry['antibody_seq_str'] = entry['antibody_seq']\n\t                    entry['antibody_seq'] = torch.tensor([ALPHABET_FULL.index(a) for a in entry['antibody_seq']])\n\t                    entry['paratope_seq'] = torch.tensor([ALPHABET.index(a) for a in entry['paratope_seq']])\n\t                    entry['antibody_cdr'] = torch.tensor([self.tag_vocab.index(a) for a in entry['antibody_cdr']])\n\t                    entry['antibody_coords'] = torch.tensor(entry['antibody_coords'])\n\t                    # make masked dataset\n", "                    # only implement one cdr predicting\n\t                    for cdr in self.cdr_types:\n\t                        cdr_mask = entry['antibody_cdr'] == self.tag_vocab.index(cdr)\n\t                        entry['prefix_len'] = entry['cdr_string'].index(cdr)\n\t                    # print(cdr_mask)\n\t                    label_seq = torch.full_like(entry['antibody_seq'], self.pad_idx)\n\t                    label_seq[cdr_mask] = entry['antibody_seq'][cdr_mask]\n\t                    entry['label_antibody_seq'] = label_seq\n\t                    masked_seq = torch.full_like(entry['antibody_seq'], self.mask_idx)\n\t                    masked_seq[~cdr_mask] = entry['antibody_seq'][~cdr_mask]\n", "                    entry['masked_antibody_seq'] = masked_seq\n\t                    # from bert vocab to decoder vocab\n\t                    entry['antibody_seq'] = entry['antibody_seq'] - 3\n\t                    self.data.append(entry)\n\t        self.sizes = np.array([len(item['paratope_seq']) for item in self.data])\n\t        self.prefix_len = np.array([item['prefix_len'] for item in self.data])\n\t    def __len__(self):\n\t        return len(self.data)\n\t    @lru_cache(maxsize=8)\n\t    def __getitem__(self, idx):\n", "        item = self.data[idx]\n\t        return item['masked_antibody_seq'], item['antibody_cdr'], item['label_antibody_seq'], \\\n\t               item['paratope_seq'], item['paratope_coords'], \\\n\t               item['paratope_surface'], item['mask_cdr_coords'], \\\n\t               item['antibody_coords'], item['antibody_seq'], item['cdr_string']\n\t    def collater(self, samples):\n\t        return self.collate_fn(samples)\n\t    def num_tokens(self, index):\n\t        return self.sizes[index]\n\t    def size(self, index):\n", "        return self.sizes[index]\n\t    def collate_fn(self, batch):\n\t        try:\n\t            masked_antibody_seq, antibody_cdr, label_antibody_seq, \\\n\t            paratope_seq, paratope_coords, \\\n\t            paratope_surface, mask_cdr_coords, \\\n\t            antibody_coords, antibody_seq, cdr_string \\\n\t            = tuple(zip(*batch))\n\t        except:\n\t            return None\n", "        # for bert\n\t        batched_seq = data_utils.collate_tokens(masked_antibody_seq, self.pad_idx, left_pad=False)\n\t        batched_tag = data_utils.collate_tokens(antibody_cdr, self.pad_idx, left_pad=False)\n\t        batched_label = data_utils.collate_tokens(label_antibody_seq, self.pad_idx, left_pad=False)\n\t        # for decoder \n\t        def featurize_paratope(seq_batch, coords_batch, mask_cdr_coords_batch):\n\t            X = pad_sequence(coords_batch, batch_first=True, padding_value=0)\n\t            S = pad_sequence(seq_batch, batch_first=True, padding_value=0)\n\t            X_init = torch.cat([i for i in mask_cdr_coords_batch])\n\t            cont_S = torch.cat([i for i in seq_batch])\n", "            return X, S, cont_S, X_init\n\t        def feature_framework(antibody_seq, antibody_coords, antibody_cdr):\n\t            X = pad_sequence(antibody_coords, batch_first=True, padding_value=0)\n\t            S = pad_sequence(antibody_seq, batch_first=True, padding_value=0)\n\t            antibody_cdr = list(antibody_cdr)\n\t            mask = S.bool().float()\n\t            return X, S, antibody_cdr, mask\n\t        paratope = featurize_paratope(paratope_seq, paratope_coords, mask_cdr_coords)\n\t        antibody = feature_framework(antibody_seq, antibody_coords, cdr_string)\n\t        return batched_seq, batched_tag, batched_label, paratope, None, antibody\n"]}
{"filename": "fairseq_models/data/ab_dictionary.py", "chunked_list": ["from fairseq.data import Dictionary\n\tALPHABET_FOR_INIT = '#SGTYVALRDKQWINFEPCMH'\n\tclass AbgenDictionary(Dictionary):\n\t    def __init__(self):\n\t        self.symbols = [\n\t            '#', 'S', 'G', 'T', 'Y', 'V', 'A', 'L', 'R', 'D', 'K', 'Q', 'W', 'I', 'N', 'F', 'E', 'P', 'C', 'M', 'H'\n\t        ]\n\t        self.count = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\t        self.indices = {\n\t            '#': 0,  'S': 1, 'G': 2, 'T': 3, 'Y': 4, 'V': 5, 'A': 6, 'L': 7, 'R': 8, 'D': 9, 'K': 10, \n", "            'Q': 11, 'W': 12, 'I': 13, 'N': 14, 'F': 15, 'E': 16, 'P': 17, 'C': 18, 'M': 19, 'H': 20\n\t        }\n\t        self.nspecial = len(self.symbols) \n\tclass AbbertDictionary(Dictionary):\n\t    def __init__(self):\n\t        bos=\"<s>\"\n\t        pad=\"<pad>\"\n\t        eos=\"</s>\"\n\t        unk=\"<unk>\"\n\t        self.bos_word, self.unk_word, self.pad_word, self.eos_word = bos, unk, pad, eos\n", "        self.symbols = [\n\t            '<s>', '<pad>', '</s>', '<unk>', 'S', 'G', 'T', 'Y', 'V', 'A', 'L', 'R', 'D', 'K', 'Q', 'W', 'I', 'N', 'F', 'E', 'P', 'C', 'M', 'H', \n\t            'X', '*', 'madeupword0000', 'madeupword0001', 'madeupword0002', 'madeupword0003', 'madeupword0004', 'madeupword0005'\n\t        ]\n\t        self.count = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\t        self.indices = {\n\t            '<s>': 0, '<pad>': 1, '</s>': 2, '<unk>': 3, 'S': 4, 'G': 5, 'T': 6, 'Y': 7, 'V': 8, 'A': 9, 'L': 10, 'R': 11, 'D': 12, \n\t            'K': 13, 'Q': 14, 'W': 15, 'I': 16, 'N': 17, 'F': 18, 'E': 19, 'P': 20, 'C': 21, 'M': 22, 'H': 23, 'X': 24, '*': 25, \n\t            'madeupword0000': 26, 'madeupword0001': 27, 'madeupword0002': 28, 'madeupword0003': 29, 'madeupword0004': 30, 'madeupword0005': 31}\n\t        self.bos_index = self.indices[bos]\n", "        self.pad_index = self.indices[pad]\n\t        self.eos_index = self.indices[eos]\n\t        self.unk_index = self.indices[unk]\n\t        self.nspecial = len(self.symbols) \n\tclass TagDictionary(Dictionary):\n\t    def __init__(self):\n\t        bos=\"<s>\"\n\t        pad=\"<pad>\"\n\t        eos=\"</s>\"\n\t        unk=\"<unk>\"\n", "        self.bos_word, self.unk_word, self.pad_word, self.eos_word = bos, unk, pad, eos\n\t        self.symbols = [\n\t            '<s>', '<pad>', '</s>', '<unk>', '0', '3', '1', '2'\n\t        ]\n\t        self.count = [1, 1, 1, 1, 0, 0, 0, 0]\n\t        self.indices = {\n\t            '<s>': 0, '<pad>': 1, '</s>': 2, '<unk>': 3, '0': 4, '3': 5, '1': 6, '2': 7\n\t        }\n\t        self.bos_index = self.indices[bos]\n\t        self.pad_index = self.indices[pad]\n", "        self.eos_index = self.indices[eos]\n\t        self.unk_index = self.indices[unk]\n\t        self.nspecial = len(self.symbols) \n\tALPHABET = AbgenDictionary()\n\tALPHABET_FULL = AbbertDictionary()\n\tTAG_FULL = TagDictionary()\n\tRESTYPE_1to3 = {\n\t     \"A\": \"ALA\", \"R\": \"ARG\", \"N\": \"ASN\", \"D\": \"ASP\", \"C\": \"CYS\", \"Q\": \"GLN\",\"E\": \"GLU\", \"G\": \"GLY\", \"H\": \"HIS\", \"I\": \"ILE\", \"L\": \"LEU\", \"K\": \"LYS\", \"M\": \"MET\", \"F\": \"PHE\", \"P\": \"PRO\", \"S\": \"SER\", \"T\": \"THR\", \"W\": \"TRP\", \"Y\": \"TYR\", \"V\": \"VAL\",\n\t}\n\t# ALPHABET = ['#', 'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n", "ATOM_TYPES = [\n\t    '', 'N', 'CA', 'C', 'O', 'CB', 'CG', 'CG1', 'CG2', 'OG', 'OG1', 'SG', 'CD',\n\t    'CD1', 'CD2', 'ND1', 'ND2', 'OD1', 'OD2', 'SD', 'CE', 'CE1', 'CE2', 'CE3',\n\t    'NE', 'NE1', 'NE2', 'OE1', 'OE2', 'CH2', 'NH1', 'NH2', 'OH', 'CZ', 'CZ2',\n\t    'CZ3', 'NZ', 'OXT'\n\t]\n\tRES_ATOM14 = [\n\t    ['', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'OG', '', '', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', '', '', '', '', '', '', '', '', '', ''],\n", "    ['N', 'CA', 'C', 'O', 'CB', 'OG1', 'CG2', '', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD1', 'CD2', 'CE1', 'CE2', 'CZ', 'OH', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG1', 'CG2', '', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', '', '', '', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD1', 'CD2', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD', 'NE', 'CZ', 'NH1', 'NH2', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'OD1', 'OD2', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD', 'CE', 'NZ', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD', 'OE1', 'NE2', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD1', 'CD2', 'NE1', 'CE2', 'CE3', 'CZ2', 'CZ3', 'CH2'],\n", "    ['N', 'CA', 'C', 'O', 'CB', 'CG1', 'CG2', 'CD1', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'OD1', 'ND2', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD1', 'CD2', 'CE1', 'CE2', 'CZ', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD', 'OE1', 'OE2', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'CD', '', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'SG', '', '', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'SD', 'CE', '', '', '', '', '', ''],\n\t    ['N', 'CA', 'C', 'O', 'CB', 'CG', 'ND1', 'CD2', 'CE1', 'NE2', '', '', '', ''],\n\t]\n\tUNK_LIST = [\n", "    '6u8k',\n\t    '6db8',\n\t    '5e08',\n\t    '5gkr',\n\t    '4xwo',\n\t    '4kzd',\n\t    '6x5n',\n\t    '6db9',\n\t    '1keg',\n\t    '2ok0',\n", "    '2fr4',\n\t    '6b3k',\n\t    '6b14',\n\t    '2r8s',\n\t    '1xf2',\n\t    '1i8m',\n\t    '6mwn',\n\t    '6x5m',\n\t    '1cbv',\n\t    '4kze',\n", "    '1ehl',\n\t    '3ivk',\n\t    '6u8d'\n\t]\n"]}
{"filename": "fairseq_models/data/abgen_dataset.py", "chunked_list": ["import torch\n\tfrom torch.nn.utils.rnn import pad_sequence\n\timport numpy as np\n\timport json, copy\n\timport torch.nn.functional as F\n\tfrom tqdm import tqdm\n\tfrom collections import defaultdict\n\tfrom fairseq_models.modules.utils import full_square_dist\n\tfrom functools import lru_cache\n\tfrom pathlib import Path\n", "from fairseq.data import (\n\t    data_utils,\n\t    Dictionary,\n\t    FairseqDataset\n\t)\n\tfrom .ab_dictionary import (\n\t    ALPHABET,\n\t    ALPHABET_FULL,\n\t    RESTYPE_1to3,\n\t    ATOM_TYPES,\n", "    RES_ATOM14,\n\t    UNK_LIST\n\t)\n\tclass AntibodyComplexDataset(FairseqDataset):\n\t    def __init__(self, data_path, split, seq_vocab, tag_vocab, cdr_types, L_target, pad_idx, mask_idx, max_len):\n\t        if split not in ('train', 'valid', 'test'):\n\t            raise ValueError(f\"Unrecognized split: {split}. \"\n\t                             f\"Must be one of ['train', 'valid', 'test']\")\n\t        data_path = Path(data_path)\n\t        data_file = f'{split}_data.jsonl'\n", "        jsonl_file = data_path / data_file\n\t        self.seq_vocab = seq_vocab\n\t        self.tag_vocab = tag_vocab\n\t        self.cdr_types = cdr_types\n\t        self.pad_idx = pad_idx\n\t        self.mask_idx = mask_idx\n\t        self.cdr_types = cdr_types\n\t        self.data = []\n\t        with open(jsonl_file) as f:\n\t            all_lines = f.readlines()\n", "            for line in tqdm(all_lines):\n\t                entry = json.loads(line)\n\t                assert len(entry['antibody_coords']) == len(entry['antibody_seq'])\n\t                assert len(entry['antigen_coords']) == len(entry['antigen_seq'])\n\t                for cdr in cdr_types:\n\t                    if entry['antibody_cdr'].count(cdr) <= 4:\n\t                        continue\n\t                if entry['pdb'] in UNK_LIST:\n\t                    continue\n\t                if len(entry['antibody_seq']) > max_len:\n", "                    continue\n\t                # paratope region\n\t                surface = torch.tensor(\n\t                        [i for i,v in enumerate(entry['antibody_cdr']) if v in cdr_types]\n\t                )\n\t                entry['paratope_surface'] = surface\n\t                entry['cdr_string'] = entry['antibody_cdr']\n\t                l_coord, r_coord = torch.tensor(entry['antibody_coords'])[surface[0] - 1], torch.tensor(entry['antibody_coords'])[surface[-1] + 1]\n\t                n_span = len(surface) + 1\n\t                coord_offsets = (r_coord - l_coord).unsqueeze(0).expand(n_span - 1, 14, 3) \n", "                coord_offsets = torch.cumsum(coord_offsets, dim=0)\n\t                mask_cdr_coords = l_coord + coord_offsets / n_span # [cdr_len, 14, 3]\n\t                mask_cdr_coords[:, 4:] = mask_cdr_coords[:, 1].unsqueeze(1) # regularize side chain atoms\n\t                entry['mask_cdr_coords'] = mask_cdr_coords\n\t                entry['paratope_seq'] = ''.join([entry['antibody_seq'][i] for i in surface.tolist()])\n\t                entry['paratope_coords'] = torch.tensor(entry['antibody_coords'])[surface]\n\t                entry['paratope_atypes'] = torch.tensor(\n\t                        [[ATOM_TYPES.index(a) for a in RES_ATOM14[ALPHABET.index(s)]] for s in entry['paratope_seq']]\n\t                )\n\t                if entry['paratope_coords'][0][0].norm(dim=-1) < 1e-6:\n", "                    # print('here')\n\t                    continue\n\t                mask = (entry['paratope_coords'].norm(dim=-1) > 1e-6).long()\n\t                entry['paratope_atypes'] *= mask\n\t                # Create epitope\n\t                entry['antigen_seq'] = entry['antigen_seq']\n\t                entry['antigen_coords'] = torch.tensor(entry['antigen_coords'])\n\t                entry['antigen_atypes'] = torch.tensor(\n\t                        [[ATOM_TYPES.index(a) for a in RES_ATOM14[ALPHABET.index(s)]] for s in entry['antigen_seq']]\n\t                )\n", "                mask = (entry['antigen_coords'].norm(dim=-1) > 1e-6).long()\n\t                entry['antigen_atypes'] *= mask\n\t                # Find epitope surface\n\t                dist, _ = full_square_dist(\n\t                        entry['antigen_coords'][None,...], \n\t                        entry['paratope_coords'][None,...], \n\t                        entry['antigen_atypes'][None,...], \n\t                        entry['paratope_atypes'][None,...], \n\t                        contact=True\n\t                )\n", "                K = min(len(dist[0]), L_target)\n\t                epitope = dist[0].amin(dim=-1).topk(k=K, largest=False).indices\n\t                entry['epitope_surface'] = torch.sort(epitope).values\n\t                if len(entry['paratope_coords']) > 4 and len(entry['antigen_coords']) > 4 and entry['antibody_cdr'].count('001') <= 1:\n\t                    # string to list\n\t                    entry['antibody_seq_str'] = entry['antibody_seq']\n\t                    entry['antigen_seq_str'] = entry['antigen_seq']\n\t                    entry['antibody_seq'] = torch.tensor([ALPHABET_FULL.index(a) for a in entry['antibody_seq']])\n\t                    entry['paratope_seq'] = torch.tensor([ALPHABET.index(a) for a in entry['paratope_seq']])\n\t                    entry['antigen_seq'] = torch.tensor([ALPHABET.index(a) for a in entry['antigen_seq']])\n", "                    entry['antibody_cdr'] = torch.tensor([self.tag_vocab.index(a) for a in entry['antibody_cdr']])\n\t                    entry['antibody_coords'] = torch.tensor(entry['antibody_coords'])\n\t                    # make masked dataset\n\t                    # only implement one cdr predicting\n\t                    for cdr in self.cdr_types:\n\t                        cdr_mask = entry['antibody_cdr'] == self.tag_vocab.index(cdr)\n\t                        entry['prefix_len'] = entry['cdr_string'].index(cdr)\n\t                    # print(cdr_mask)\n\t                    label_seq = torch.full_like(entry['antibody_seq'], self.pad_idx)\n\t                    label_seq[cdr_mask] = entry['antibody_seq'][cdr_mask]\n", "                    entry['label_antibody_seq'] = label_seq\n\t                    masked_seq = torch.full_like(entry['antibody_seq'], self.mask_idx)\n\t                    masked_seq[~cdr_mask] = entry['antibody_seq'][~cdr_mask]\n\t                    entry['masked_antibody_seq'] = masked_seq\n\t                    # from bert vocab to decoder vocab\n\t                    entry['antibody_seq'] = entry['antibody_seq'] - 3\n\t                    self.data.append(entry)\n\t        self.sizes = np.array([len(item['paratope_seq']) for item in self.data])\n\t        self.prefix_len = np.array([item['prefix_len'] for item in self.data])\n\t    def __len__(self):\n", "        return len(self.data)\n\t    @lru_cache(maxsize=8)\n\t    def __getitem__(self, idx):\n\t        item = self.data[idx]\n\t        return item['masked_antibody_seq'], item['antibody_cdr'], item['label_antibody_seq'], \\\n\t               item['paratope_seq'], item['paratope_coords'], item['paratope_atypes'], \\\n\t               item['antigen_seq'], item['antigen_coords'], item['antigen_atypes'], \\\n\t               item['paratope_surface'], item['epitope_surface'], item['mask_cdr_coords'], \\\n\t               item['antibody_coords'], item['antibody_seq'], item['cdr_string']\n\t    def collater(self, samples):\n", "        return self.collate_fn(samples)\n\t    def num_tokens(self, index):\n\t        return self.sizes[index]\n\t    def size(self, index):\n\t        return self.sizes[index]\n\t    def collate_fn(self, batch):\n\t        try:\n\t            masked_antibody_seq, antibody_cdr, label_antibody_seq, \\\n\t            paratope_seq, paratope_coords, paratope_atypes, \\\n\t            antigen_seq, antigen_coords, antigen_atypes, \\\n", "            paratope_surface, epitope_surface, mask_cdr_coords, \\\n\t            antibody_coords, antibody_seq, cdr_string \\\n\t            = tuple(zip(*batch))\n\t        except:\n\t            return None\n\t        # for bert\n\t        batched_seq = data_utils.collate_tokens(masked_antibody_seq, self.pad_idx, left_pad=False)\n\t        batched_tag = data_utils.collate_tokens(antibody_cdr, self.pad_idx, left_pad=False)\n\t        batched_label = data_utils.collate_tokens(label_antibody_seq, self.pad_idx, left_pad=False)\n\t        # for decoder \n", "        def featurize_antigen(seq_batch, coords_batch, atypes_batch):\n\t            S = pad_sequence(seq_batch, batch_first=True, padding_value=0)\n\t            X = pad_sequence(coords_batch, batch_first=True, padding_value=0)\n\t            A = pad_sequence(atypes_batch, batch_first=True, padding_value=0)\n\t            return X, S, A\n\t        def featurize_paratope(seq_batch, coords_batch, mask_cdr_coords_batch):\n\t            X = pad_sequence(coords_batch, batch_first=True, padding_value=0)\n\t            S = pad_sequence(seq_batch, batch_first=True, padding_value=0)\n\t            X_init = torch.cat([i for i in mask_cdr_coords_batch])\n\t            cont_S = torch.cat([i for i in seq_batch])\n", "            return X, S, cont_S, X_init\n\t        def feature_framework(antibody_seq, antibody_coords, antibody_cdr):\n\t            X = pad_sequence(antibody_coords, batch_first=True, padding_value=0)\n\t            S = pad_sequence(antibody_seq, batch_first=True, padding_value=0)\n\t            antibody_cdr = list(antibody_cdr)\n\t            mask = S.bool().float()\n\t            return X, S, antibody_cdr, mask\n\t        def select_target(tgt_X, tgt_S, tgt_A, tgt_pos):\n\t            max_len = max([len(pos) for pos in tgt_pos])\n\t            xlist = [tgt_X[i, pos] for i,pos in enumerate(tgt_pos)]\n", "            slist = [tgt_S[i, pos] for i,pos in enumerate(tgt_pos)]\n\t            alist = [tgt_A[i, pos] for i,pos in enumerate(tgt_pos)]\n\t            tgt_X = [F.pad(x, (0,0,0,0,0,max_len-len(x))) for x in xlist]\n\t            tgt_S = [F.pad(s, (0,max_len-len(s))) for s in slist]\n\t            tgt_A = [F.pad(a, (0,0,0,max_len-len(a))) for a in alist]\n\t            return torch.stack(tgt_X, dim=0), torch.stack(tgt_S, dim=0), torch.stack(tgt_A, dim=0)\n\t        antigen = featurize_antigen(antigen_seq, antigen_coords, antigen_atypes)\n\t        epitope = select_target(antigen[0], antigen[1], antigen[2], [t_s for t_s in epitope_surface]) # select epitope from antigen\n\t        paratope = featurize_paratope(paratope_seq, paratope_coords, mask_cdr_coords)\n\t        antibody = feature_framework(antibody_seq, antibody_coords, cdr_string)\n", "        return batched_seq, batched_tag, batched_label, paratope, epitope, antibody\n"]}
{"filename": "fairseq_models/models/ab_decoder.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\timport copy\n\tfrom fairseq_models.data.abgen_dataset import ALPHABET, ATOM_TYPES, RES_ATOM14\n\tfrom fairseq_models.modules.hmpn_encoder import *\n\tfrom fairseq_models.modules.framework_encoder import HierarchicalDecoder\n\tfrom fairseq_models.modules.nnutils import * \n\tfrom fairseq_models.modules.utils import *\n", "class FullshotRefineDecoder(ABModel):\n\t    def __init__(self, args):\n\t        super(FullshotRefineDecoder, self).__init__(args)\n\t        self.args = args\n\t        self.hierarchical = args.hierarchical\n\t        self.residue_atom14 = torch.tensor([\n\t                [ATOM_TYPES.index(a) for a in atoms] for atoms in RES_ATOM14\n\t        ]).cuda()\n\t        self.W_s = nn.Linear(args.hidden_size, len(ALPHABET))\n\t        self.W_t = nn.Linear(self.embedding.dim(), args.hidden_size)\n", "        self.U_i = nn.Linear(self.embedding.dim(), args.hidden_size)\n\t        # self.W_trans = nn.Linear(args.hidden_size, self.embedding.dim())\n\t        self.coord_loss = nn.SmoothL1Loss(reduction='sum')\n\t        if args.hierarchical:\n\t            self.struct_mpn = HierEGNNEncoder(args)\n\t            self.seq_mpn = HierEGNNEncoder(args, update_X=False, backbone_CA_only=False)\n\t        else:\n\t            self.struct_mpn = EGNNEncoder(args)\n\t            self.seq_mpn = EGNNEncoder(args, update_X=False)\n\t        self.framework_encoder = HierarchicalDecoder(args)\n", "        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    def struct_loss(self, antibody_X, epitope_X, true_V, true_R, true_D, inter_D, true_C):\n\t        # dihedral loss\n\t        antibody_V = self.features._dihedrals(antibody_X)\n\t        vloss = self.mse_loss(antibody_V, true_V).sum(dim=-1)\n\t        # local loss\n\t        rdist = antibody_X.unsqueeze(2) - antibody_X.unsqueeze(3)\n\t        rdist = torch.sum(rdist ** 2, dim=-1)\n", "        rloss = self.huber_loss(rdist, true_R) + 10 * F.relu(1.5 - rdist)\n\t        # full loss\n\t        cdist, _ = full_square_dist(antibody_X, antibody_X, torch.ones_like(antibody_X)[..., 0], torch.ones_like(antibody_X)[..., 0])\n\t        closs = self.huber_loss(cdist, true_C) + 10 * F.relu(1.5 - cdist)\n\t        # alpha carbon\n\t        antibody_X, epitope_X = antibody_X[:, :, 1], epitope_X[:, :, 1]\n\t        # CDR self distance\n\t        dist = antibody_X.unsqueeze(1) - antibody_X.unsqueeze(2)\n\t        dist = torch.sum(dist ** 2, dim=-1)\n\t        dloss = self.huber_loss(dist, true_D) + 10 * F.relu(14.4 - dist)\n", "        # inter distance\n\t        idist = antibody_X.unsqueeze(2) - epitope_X.unsqueeze(1)\n\t        idist = torch.sum(idist ** 2, dim=-1)\n\t        iloss = self.huber_loss(idist, inter_D) + 10 * F.relu(14.4 - idist)\n\t        return dloss, vloss, rloss, iloss, closs\n\t    def forward(\n\t        self, init_prob, paratope, epitope, antibody,\n\t        pretrained_embedding=None, masked_tokens=None\n\t    ):\n\t        # return ReturnType(xloss=3.0, nll=2., bind_X=torch.ones(masked_tokens.sum().item(), 14, 3), handle=(None, None))\n", "        _, true_cdr_S, flatten_cdr_S, flatten_init_X = paratope\n\t        epitope_X, epitope_S, epitope_A = epitope\n\t        antibody_X, antibody_S, antibody_cdr, padding_mask = antibody\n\t        # Encode target\n\t        epitope_h = self.U_i(self.embedding(epitope_S))\n\t        epitope_V = self.features._dihedrals(epitope_X)\n\t        epitope_mask = epitope_A[:,:,1].clamp(max=1).float()\n\t        # antibody_h_0: initialized antibody embedding with shape [B, antibody_N, 256]\n\t        # paratope_mask: mask for paratope nodes with shape [B, antibody_N]\n\t        # padding_mask: mask for existing nodes with shape [B, antibody_N]\n", "        init_prob = F.softmax(init_prob, dim=-1)\n\t        antibody_h_0, true_antibody_X, paratope_mask, antibody_X, padding_mask = self.framework_encoder(\n\t            antibody_X, antibody_S, antibody_cdr, padding_mask, init_prob, masked_tokens, flatten_init_X.detach().clone()\n\t        )\n\t        B, paratope_N = true_cdr_S.size(0), true_cdr_S.size(1)\n\t        antibody_N = paratope_mask.size(1)\n\t        antibody_A = torch.zeros(B, antibody_N, 14).cuda().long()\n\t        antibody_A[padding_mask>0] = torch.tensor(\n\t            [1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n\t        ).cuda().expand(int(padding_mask.sum()), -1)  # backbone atoms\n", "        # Refine\n\t        dloss = vloss = rloss = iloss = sloss = closs = 0\n\t        for t in range(self.args.refine_iteration):\n\t            if t < self.args.refine_iteration - 1:\n\t                with torch.no_grad():\n\t                    # sequence update\n\t                    antibody_V = self.features._dihedrals(antibody_X.detach())\n\t                    complex_V = torch.cat([antibody_V, epitope_V], dim=1).detach()\n\t                    complex_X = torch.cat([antibody_X, epitope_X], dim=1).detach()\n\t                    complex_A = torch.cat([antibody_A, epitope_A], dim=1).detach()\n", "                    # sequence message passing\n\t                    complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t                    complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                    logits = self.W_s(complex_h[:, :antibody_N])\n\t                    logits = logits[paratope_mask]\n\t                    antibody_h_0 = antibody_h_0.clone()\n\t                    # calculate sequence loss\n\t                    snll = self.ce_loss(logits, flatten_cdr_S)\n\t                    sloss = sloss + torch.sum(snll)\n\t                    # update paratope embedding\n", "                    probs = F.softmax(logits, dim=-1)\n\t                    antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n\t                    # structrue message passing\n\t                    complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t                    complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                    antibody_X = antibody_X.clone()\n\t                    antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t                    ratio = (t + 1) / self.args.refine_iteration\n\t                    label_X = true_antibody_X * ratio + antibody_X * (1 - ratio)\n\t                    true_V = self.features._dihedrals(label_X)\n", "                    true_R, rmask_2D = inner_square_dist(label_X, antibody_A.clamp(max=1).float())\n\t                    true_D, mask_2D = self_square_dist(label_X, paratope_mask)\n\t                    true_C, cmask_2D = full_square_dist(label_X, label_X, antibody_A, antibody_A)\n\t                    inter_D, imask_2D = cross_square_dist(label_X, epitope_X, paratope_mask, epitope_mask)\n\t                    dloss_t, vloss_t, rloss_t, iloss_t, closs_t = self.struct_loss(\n\t                            antibody_X, epitope_X, true_V, true_R, true_D, inter_D, true_C\n\t                    )\n\t                    vloss = vloss + vloss_t * paratope_mask\n\t                    dloss = dloss + dloss_t * mask_2D\n\t                    iloss = iloss + iloss_t * imask_2D\n", "                    rloss = rloss + rloss_t * rmask_2D\n\t                    closs = closs + closs_t * cmask_2D\n\t            else:\n\t                # sequence update\n\t                antibody_V = self.features._dihedrals(antibody_X.detach())\n\t                complex_V = torch.cat([antibody_V, epitope_V], dim=1).detach()\n\t                complex_X = torch.cat([antibody_X, epitope_X], dim=1).detach()\n\t                complex_A = torch.cat([antibody_A, epitope_A], dim=1).detach()\n\t                # sequence message passing\n\t                complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n", "                complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                logits = self.W_s(complex_h[:, :antibody_N])\n\t                logits = logits[paratope_mask]\n\t                antibody_h_0 = antibody_h_0.clone()\n\t                # calculate sequence loss\n\t                snll = self.ce_loss(logits, flatten_cdr_S)\n\t                sloss = sloss + torch.sum(snll)\n\t                # update paratope embedding\n\t                probs = F.softmax(logits, dim=-1)\n\t                antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n", "                # structrue message passing\n\t                complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t                complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                antibody_X = antibody_X.clone()\n\t                antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t                ratio = (t + 1) / self.args.refine_iteration\n\t                label_X = true_antibody_X * ratio + antibody_X * (1 - ratio)\n\t                true_V = self.features._dihedrals(label_X)\n\t                true_R, rmask_2D = inner_square_dist(label_X, antibody_A.clamp(max=1).float())\n\t                true_D, mask_2D = self_square_dist(label_X, paratope_mask)\n", "                true_C, cmask_2D = full_square_dist(label_X, label_X, antibody_A, antibody_A)\n\t                inter_D, imask_2D = cross_square_dist(label_X, epitope_X, paratope_mask, epitope_mask)\n\t                dloss_t, vloss_t, rloss_t, iloss_t, closs_t = self.struct_loss(\n\t                        antibody_X, epitope_X, true_V, true_R, true_D, inter_D, true_C\n\t                )\n\t                vloss = vloss + vloss_t * paratope_mask\n\t                dloss = dloss + dloss_t * mask_2D\n\t                iloss = iloss + iloss_t * imask_2D\n\t                rloss = rloss + rloss_t * rmask_2D\n\t                closs = closs + closs_t * cmask_2D\n", "        sloss = sloss / paratope_mask.sum() # / self.args.refine_iteration\n\t        dloss = torch.sum(dloss) / mask_2D.sum() \n\t        iloss = torch.sum(iloss) / imask_2D.sum() \n\t        vloss = torch.sum(vloss) / paratope_mask.sum() \n\t        # print('mask_2D', mask_2D.sum())\n\t        if self.hierarchical:\n\t            rloss = torch.sum(rloss) / rmask_2D.sum()\n\t            closs = torch.sum(closs) / cmask_2D.sum()\n\t        else:\n\t            rloss = torch.sum(rloss[:,:,:4,:4]) / rmask_2D[:,:,:4,:4].sum()\n", "            closs = 0\n\t        struct_loss = (dloss + iloss + vloss + rloss + closs) / paratope_mask.sum() # / self.args.refine_iteration\n\t        seq_loss = sloss\n\t        return ReturnType(xloss=struct_loss, nll=seq_loss, bind_X=antibody_X[paratope_mask].detach(), handle=(epitope_X, epitope_A))\n\t    def generate(\n\t        self, init_prob, paratope, epitope, antibody,\n\t        pretrained_embedding=None, masked_tokens=None, num_decode=1\n\t    ):\n\t        _, true_cdr_S, flatten_cdr_S, flatten_init_X = paratope\n\t        epitope_X, epitope_S, epitope_A = epitope\n", "        antibody_X, antibody_S, antibody_cdr, antibody_mask = antibody\n\t        # Encode target (assumes same target)\n\t        epitope_h = self.U_i(self.embedding(epitope_S))\n\t        epitope_V = self.features._dihedrals(epitope_X)\n\t        epitope_mask = epitope_A[:,:,1].clamp(max=1).float()\n\t        # antibody_h_0: initialized antibody embedding with shape [B, antibody_N, 256]\n\t        # paratope_mask: mask for paratope nodes with shape [B, antibody_N]\n\t        # padding_mask: mask for existing nodes with shape [B, antibody_N]\n\t        init_prob = F.softmax(init_prob, dim=-1)\n\t        antibody_h_0, _, paratope_mask, antibody_X, padding_mask = self.framework_encoder(\n", "            antibody_X, antibody_S, antibody_cdr, antibody_mask, init_prob, masked_tokens, flatten_init_X.detach().clone()\n\t        )\n\t        B, paratope_N = true_cdr_S.size(0), true_cdr_S.size(1)\n\t        antibody_N = paratope_mask.size(1)\n\t        antibody_A = torch.zeros(B, antibody_N, 14).cuda().long()\n\t        antibody_A[padding_mask>0] = torch.tensor(\n\t            [1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n\t        ).cuda().expand(int(padding_mask.sum()), -1)  # backbone atoms\n\t        # Refine\n\t        for t in range(self.args.refine_iteration):\n", "            # sequence update\n\t            antibody_V = self.features._dihedrals(antibody_X.detach())\n\t            complex_V = torch.cat([antibody_V, epitope_V], dim=1).detach()\n\t            complex_X = torch.cat([antibody_X, epitope_X], dim=1).detach()\n\t            complex_A = torch.cat([antibody_A, epitope_A], dim=1).detach()\n\t            # sequence message passing\n\t            complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t            complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t            logits = self.W_s(complex_h[:, :antibody_N])\n\t            logits = logits[paratope_mask]\n", "            antibody_h_0 = antibody_h_0.clone()\n\t            # update paratope embedding\n\t            probs = F.softmax(logits, dim=-1)\n\t            antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n\t            # structrue message passing\n\t            complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t            complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t            antibody_X = antibody_X.clone()\n\t            antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t        # sample new sequences\n", "        prob = F.softmax(logits.view(-1, len(ALPHABET)), dim=-1)\n\t        bind_I = torch.multinomial(prob, num_samples=num_decode, replacement=True)\n\t        bind_I = torch.transpose(bind_I, 0, 1)\n\t        repeat_logits = logits.view(-1, len(ALPHABET)).repeat(num_decode, 1)\n\t        snll = self.ce_loss(repeat_logits, bind_I.reshape(-1))\n\t        sloss = snll.view(num_decode, paratope_N).mean(dim=1)\n\t        S = bind_I.tolist()\n\t        S = [''.join([ALPHABET[S[i][j]] for j in range(paratope_N)]) for i in range(num_decode)]\n\t        ppl = torch.exp(sloss / paratope_N)\n\t        return ReturnType(handle=S, ppl=ppl, bind_X=antibody_X[paratope_mask].detach())\n"]}
{"filename": "fairseq_models/models/ab_roberta_base.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\t\"\"\"\n\tRoBERTa: A Robustly Optimized BERT Pretraining Approach.\n\t\"\"\"\n\timport logging\n\timport torch\n\timport torch.nn as nn\n", "import torch.nn.functional as F\n\tfrom fairseq import utils\n\tfrom fairseq.models import (\n\t    FairseqEncoder,\n\t    FairseqEncoderModel,\n\t    register_model,\n\t    register_model_architecture,\n\t)\n\tfrom fairseq.modules import LayerNorm\n\tfrom fairseq.modules.quant_noise import quant_noise as apply_quant_noise_\n", "from fairseq.modules.transformer_sentence_encoder import init_bert_params\n\tfrom fairseq_models.modules.ab_transformer_sentence_encoder import AntibodyTransformerSentenceEncoder\n\tfrom fairseq_models.models.ab_decoder import FullshotRefineDecoder\n\tfrom fairseq_models.models.ab_decoder_ablation import FullshotRefineDecoderStack, BertonlyDecoder\n\tfrom fairseq_models.models.ab_decoder_noantigen import NoAntigenFullshotRefineDecoder\n\tfrom fairseq_models.data.ab_dictionary import ALPHABET, ALPHABET_FULL, TAG_FULL\n\tfrom fairseq.data import Dictionary\n\tlogger = logging.getLogger(__name__)\n\tclass PrefixEncoder(torch.nn.Module):\n\t    def __init__(self, args):\n", "        super().__init__()\n\t        self.prefix_projection = args.prefix_projection\n\t        prefix_hidden_size = args.encoder_embed_dim\n\t        if self.prefix_projection:\n\t            # Use a two-layer MLP to encode the prefix\n\t            self.embedding = torch.nn.Embedding(args.pre_seq_len, args.encoder_embed_dim)\n\t            self.trans = torch.nn.Sequential(\n\t                torch.nn.Linear(args.encoder_embed_dim, prefix_hidden_size),\n\t                torch.nn.Tanh(),\n\t                torch.nn.Linear(prefix_hidden_size, args.encoder_layers * 2 * args.encoder_embed_dim)\n", "            )\n\t        else:\n\t            self.embedding = torch.nn.Embedding(args.pre_seq_len, args.encoder_layers * 2 * args.encoder_embed_dim)\n\t    def forward(self, prefix: torch.Tensor):\n\t        if self.prefix_projection:\n\t            prefix_tokens = self.embedding(prefix)\n\t            past_key_values = self.trans(prefix_tokens)\n\t            # print(self.trans[0].weight)\n\t            # exit(0)\n\t        else:\n", "            past_key_values = self.embedding(prefix)\n\t        return past_key_values\n\t@register_model(\"antibody_roberta\")\n\tclass AntibodyRobertaModel(FairseqEncoderModel):\n\t    def __init__(self, args, encoder, dictionary, inference=False):\n\t        super().__init__(encoder)\n\t        self.args = args\n\t        self.dictionary = dictionary\n\t        self.inference=inference\n\t        if self.args.finetune:\n", "            if self.args.finetune_bert_scheme == 'prefix_tuning' and self.args.pre_seq_len > 0:\n\t                for param in self.encoder.parameters():\n\t                    param.requires_grad = False\n\t                self.pre_seq_len = args.pre_seq_len\n\t                self.n_layer = args.encoder_layers\n\t                self.n_head = args.encoder_attention_heads\n\t                self.n_embd = args.encoder_embed_dim // args.encoder_attention_heads\n\t                self.prefix_tokens = torch.arange(self.pre_seq_len).long()\n\t                self.prefix_encoder = PrefixEncoder(args)\n\t                # print(self.n_layer)\n", "            elif self.args.finetune_bert_scheme == 'fixed':\n\t                for param in self.encoder.parameters():\n\t                    param.requires_grad = False\n\t            if self.args.bertonly:\n\t                self.structure_decoder = BertonlyDecoder(self.args)\n\t            elif self.args.noantigen:\n\t                self.structure_decoder = NoAntigenFullshotRefineDecoder(self.args)\n\t            elif self.args.stack:\n\t                self.structure_decoder = FullshotRefineDecoderStack(self.args)\n\t            else:\n", "                self.structure_decoder = FullshotRefineDecoder(self.args)\n\t        # We follow BERT's random weight initialization\n\t        self.apply(init_bert_params)\n\t    def print_parameter_number(self, net):\n\t        net_name = type(net).__name__\n\t        total_num = sum(p.numel() for p in net.parameters())\n\t        trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n\t        print(f'{net_name} total parameters:{total_num}, trainable: {trainable_num}')\n\t    @staticmethod\n\t    def add_args(parser):\n", "        \"\"\"Add model-specific arguments to the parser.\"\"\"\n\t        parser.add_argument(\n\t            \"--encoder-layers\", type=int, metavar=\"L\", help=\"num encoder layers\"\n\t        )\n\t        parser.add_argument(\n\t            \"--encoder-embed-dim\",\n\t            type=int,\n\t            metavar=\"H\",\n\t            help=\"encoder embedding dimension\",\n\t        )\n", "        parser.add_argument(\n\t            \"--encoder-ffn-embed-dim\",\n\t            type=int,\n\t            metavar=\"F\",\n\t            help=\"encoder embedding dimension for FFN\",\n\t        )\n\t        parser.add_argument(\n\t            \"--encoder-attention-heads\",\n\t            type=int,\n\t            metavar=\"A\",\n", "            help=\"num encoder attention heads\",\n\t        )\n\t        parser.add_argument(\n\t            \"--activation-fn\",\n\t            choices=utils.get_available_activation_fns(),\n\t            help=\"activation function to use\",\n\t        )\n\t        parser.add_argument(\n\t            \"--pooler-activation-fn\",\n\t            choices=utils.get_available_activation_fns(),\n", "            help=\"activation function to use for pooler layer\",\n\t        )\n\t        parser.add_argument(\n\t            \"--encoder-normalize-before\",\n\t            action=\"store_true\",\n\t            help=\"apply layernorm before each encoder block\",\n\t        )\n\t        parser.add_argument(\n\t            \"--dropout\", type=float, metavar=\"D\", help=\"dropout probability\"\n\t        )\n", "        parser.add_argument(\n\t            \"--attention-dropout\",\n\t            type=float,\n\t            metavar=\"D\",\n\t            help=\"dropout probability for attention weights\",\n\t        )\n\t        parser.add_argument(\n\t            \"--activation-dropout\",\n\t            type=float,\n\t            metavar=\"D\",\n", "            help=\"dropout probability after activation in FFN\",\n\t        )\n\t        parser.add_argument(\n\t            \"--pooler-dropout\",\n\t            type=float,\n\t            metavar=\"D\",\n\t            help=\"dropout probability in the masked_lm pooler layers\",\n\t        )\n\t        parser.add_argument(\n\t            \"--max-positions\", type=int, help=\"number of positional embeddings to learn\"\n", "        )\n\t        parser.add_argument(\n\t            \"--load-checkpoint-heads\",\n\t            action=\"store_true\",\n\t            help=\"(re-)register and load heads when loading checkpoints\",\n\t        )\n\t        # args for \"Reducing Transformer Depth on Demand with Structured Dropout\" (Fan et al., 2019)\n\t        parser.add_argument(\n\t            \"--encoder-layerdrop\",\n\t            type=float,\n", "            metavar=\"D\",\n\t            default=0,\n\t            help=\"LayerDrop probability for encoder\",\n\t        )\n\t        parser.add_argument(\n\t            \"--encoder-layers-to-keep\",\n\t            default=None,\n\t            help=\"which layers to *keep* when pruning as a comma-separated list\",\n\t        )\n\t        # args for Training with Quantization Noise for Extreme Model Compression ({Fan*, Stock*} et al., 2020)\n", "        parser.add_argument(\n\t            \"--quant-noise-pq\",\n\t            type=float,\n\t            metavar=\"D\",\n\t            default=0,\n\t            help=\"iterative PQ quantization noise at training time\",\n\t        )\n\t        parser.add_argument(\n\t            \"--quant-noise-pq-block-size\",\n\t            type=int,\n", "            metavar=\"D\",\n\t            default=8,\n\t            help=\"block size of quantization noise at training time\",\n\t        )\n\t        parser.add_argument(\n\t            \"--quant-noise-scalar\",\n\t            type=float,\n\t            metavar=\"D\",\n\t            default=0,\n\t            help=\"scalar quantization noise and scalar quantization at training time\",\n", "        )\n\t        parser.add_argument(\n\t            \"--untie-weights-roberta\",\n\t            action=\"store_true\",\n\t            help=\"Untie weights between embeddings and classifiers in RoBERTa\",\n\t        )\n\t        parser.add_argument(\n\t            \"--spectral-norm-classification-head\",\n\t            action=\"store_true\",\n\t            default=False,\n", "            help=\"Apply spectral normalization on the classification head\",\n\t        )\n\t        # args for Hierarchical Equivariant Refinement Network (HERN)\n\t        parser.add_argument('--hidden_size', type=int, default=256)\n\t        parser.add_argument('--k_neighbors', type=int, default=9)\n\t        parser.add_argument('--depth', type=int, default=4)\n\t        parser.add_argument('--clash_step', type=int, default=10)\n\t        parser.add_argument('--num_rbf', type=int, default=16)\n\t        parser.add_argument('--hierarchical', type=bool, default=True)\n\t        # new addedargs\n", "        parser.add_argument('--finetune-bert-scheme', type=str, default='fixed', choices=['prefix_tuning', 'fixed', 'all_tuning'])\n\t        parser.add_argument('--pre-seq-len', type=int, default=1)\n\t        parser.add_argument('--prefix-projection', type=bool, default=True)\n\t        parser.add_argument('--refine-iteration', type=int, default=5)\n\t        parser.add_argument('--block_size', type=int, default=8)\n\t        parser.add_argument('--use-no-pretrain', type=bool, default=False)\n\t        # finetune or pretrain\n\t        parser.add_argument('--finetune', action='store_true', default=False)\n\t        parser.add_argument('--stack', action='store_true', default=False)\n\t        parser.add_argument('--bertonly', action='store_true', default=False)\n", "    @classmethod\n\t    def build_model(cls, args, task, inference=False):\n\t        \"\"\"Build a new model instance.\"\"\"\n\t        # make sure all arguments are present\n\t        base_architecture(args)\n\t        if not hasattr(args, \"max_positions\"):\n\t            args.max_positions = args.tokens_per_sample\n\t        encoder = RobertaEncoder(args, task.source_dictionary, task.tag_source_dictionary)\n\t        return cls(args, encoder, task.source_dictionary, inference)\n\t    def get_prompt(self, batch_size, data_device):\n", "        prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1).to(data_device)\n\t        past_key_values = self.prefix_encoder(prefix_tokens)\n\t        past_key_values = past_key_values.view(\n\t            batch_size,\n\t            self.pre_seq_len,\n\t            self.n_layer * 2, \n\t            self.n_head,\n\t            self.n_embd\n\t        )\n\t        # past_key_values = self.dropout(past_key_values)\n", "        past_key_values = past_key_values.permute([2, 0, 3, 1, 4]).split(2) # (key, value) n_layer x batch_size x n_head x pre_seq_len x n_embd\n\t        # n_layer * [2, bsz, head, len, dim//head]\n\t        return past_key_values\n\t    def forward(\n\t        self,\n\t        src_tokens,\n\t        tag_tokens,\n\t        paratope=None,\n\t        epitope=None,\n\t        antibody=None,\n", "        features_only=False, \n\t        return_all_hiddens=False,\n\t        masked_tokens=None,\n\t        num_decode=1,\n\t        **kwargs\n\t    ):\n\t        if self.args.finetune:\n\t            batch_size = src_tokens.shape[0]\n\t            if self.args.finetune_bert_scheme == 'prefix_tuning':\n\t                past_key_values = self.get_prompt(batch_size=batch_size, data_device=src_tokens.device)\n", "            else:\n\t                past_key_values = None\n\t            enc_out, pt_emb, extra = self.encoder(        \n\t                src_tokens=src_tokens,\n\t                tag_tokens=tag_tokens,\n\t                features_only=features_only,\n\t                return_all_hiddens=return_all_hiddens,\n\t                past_key_values=past_key_values, \n\t                masked_tokens=masked_tokens,\n\t                **kwargs\n", "            )\n\t            # for ablation\n\t            # extra = None\n\t            # enc_out = torch.zeros((masked_tokens.sum(), 21), device=masked_tokens.device)\n\t            # pt_emb = torch.zeros((masked_tokens.sum(), 768), device=masked_tokens.device)\n\t            if self.inference:\n\t                decoder_out = self.structure_decoder.generate(\n\t                    enc_out, paratope, epitope, antibody, pt_emb, masked_tokens, num_decode\n\t                )\n\t            else:\n", "                decoder_out = self.structure_decoder( # feed into the generation model\n\t                    enc_out, paratope, epitope, antibody, pt_emb, masked_tokens\n\t                )\n\t            return decoder_out, enc_out, extra\n\t        else:\n\t            x, _, extra = self.encoder(src_tokens, tag_tokens, features_only, return_all_hiddens, masked_tokens=masked_tokens, **kwargs)\n\t            return x, extra\n\t    def get_normalized_probs(self, net_output, log_probs, sample=None):\n\t        \"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"\n\t        logits = net_output[0].float()\n", "        if log_probs:\n\t            return F.log_softmax(logits, dim=-1)\n\t        else:\n\t            return F.softmax(logits, dim=-1)\n\t    def upgrade_state_dict_named(self, state_dict, name):\n\t        prefix = name + '.' if name != \"\" else \"\"\n\t        super().upgrade_state_dict_named(state_dict, name)\n\t        # Copy any newly-added classification heads into the state dict\n\t        # with their current weights.\n\t        if hasattr(self, \"structure_decoder\"):\n", "            cur_state = self.structure_decoder.state_dict()\n\t            for k, v in cur_state.items():\n\t                if prefix + \"structure_decoder.\" + k not in state_dict:\n\t                    logger.info(\"Overwriting \" + prefix + \"structure_decoder.\" + k)\n\t                    state_dict[prefix + \"structure_decoder.\" + k] = v\n\t        if self.args.finetune_bert_scheme == 'prefix_tuning' and self.args.pre_seq_len > 0:\n\t            cur_state = self.prefix_encoder.state_dict()\n\t            for k, v in cur_state.items():\n\t                if prefix + \"prefix_encoder.\" + k not in state_dict:\n\t                    logger.info(\"Overwriting \" + prefix + \"prefix_encoder.\" + k)\n", "                    state_dict[prefix + \"prefix_encoder.\" + k] = v\n\t    @property\n\t    def supported_targets(self):\n\t        return {\"self\"}\n\t    @classmethod\n\t    def from_pretrained(\n\t        cls,\n\t        model_name_or_path,\n\t        inference=False,\n\t        fix_bert_param=False,\n", "        **kwargs\n\t    ):\n\t        from fairseq.checkpoint_utils import load_checkpoint_to_cpu\n\t        import os\n\t        state = load_checkpoint_to_cpu(model_name_or_path, arg_overrides=None)\n\t        args = state[\"args\"]\n\t        from fairseq import models, quantization_utils\n\t        class TaskConfig:\n\t            def __init__(self):\n\t                self.source_dictionary = ALPHABET_FULL\n", "                self.mask_idx = self.source_dictionary.add_symbol(\"<mask>\")\n\t                self.tag_source_dictionary =  TAG_FULL\n\t        task = TaskConfig()\n\t        model = cls.build_model(args, task, inference)\n\t        # model.add_state_dict_named(state['model'], \"\")\n\t        model.load_state_dict(state[\"model\"], strict=True, args=args)\n\t        from itertools import chain\n\t        from fairseq.optim.adam import FairseqAdam\n\t        params = list(\n\t            filter(\n", "                lambda p: p.requires_grad,\n\t                chain(model.parameters()),\n\t            )\n\t        )\n\t        optimizer = FairseqAdam(args, params)\n\t        last_optim_state = state[\"last_optimizer_state\"]\n\t        optimizer.load_state_dict(last_optim_state)\n\t        if fix_bert_param:\n\t            for param in model.prefix_encoder.parameters():\n\t                param.requires_grad = False\n", "        cls.upgrade_args(args)\n\t        logger.info(args)\n\t        return HubInterface(args, model, task, optimizer)\n\tclass HubInterface(nn.Module):\n\t    \"\"\"A simple PyTorch Hub interface to RoBERTa.\n\t    Usage: https://github.com/pytorch/fairseq/tree/master/examples/roberta\n\t    \"\"\"\n\t    def __init__(self, args, model, task, optimizer):\n\t        super().__init__()\n\t        self.args = args\n", "        self.model = model\n\t        self.task = task\n\t        self.optimizer = optimizer\n\t        # this is useful for determining the device\n\t        self.register_buffer(\"_float_tensor\", torch.tensor([0], dtype=torch.float))\n\t    @property\n\t    def device(self):\n\t        return self._float_tensor.device\n\tclass RobertaLMHead(nn.Module):\n\t    \"\"\"Head for masked language modeling.\"\"\"\n", "    def __init__(self, embed_dim, output_dim, activation_fn, weight=None, finetune=False):\n\t        super().__init__()\n\t        self.dense = nn.Linear(embed_dim, embed_dim)\n\t        self.activation_fn = utils.get_activation_fn(activation_fn)\n\t        self.layer_norm = LayerNorm(embed_dim)\n\t        self.finetune = finetune\n\t        if weight is None:\n\t            weight = nn.Linear(embed_dim, output_dim, bias=False).weight\n\t        self.weight = weight\n\t        self.bias = nn.Parameter(torch.zeros(output_dim))\n", "    def forward(self, features, masked_tokens=None, **kwargs):\n\t        # Only project the masked tokens while training,\n\t        # saves both memory and computation\n\t        if masked_tokens is not None:\n\t            features = features[masked_tokens, :]\n\t        x = self.dense(features)\n\t        x = self.activation_fn(x)\n\t        x = self.layer_norm(x)\n\t        # project back to size of vocabulary with bias\n\t        x = F.linear(x, self.weight) + self.bias\n", "        if self.finetune:\n\t            x = torch.cat((torch.zeros((x.shape[0], 1), device=x.device), x[:, 4:24]), dim=1)\n\t        return x\n\tclass RobertaEncoder(FairseqEncoder):\n\t    \"\"\"RoBERTa encoder.\"\"\"\n\t    def __init__(self, args, dictionary, tag_dict):\n\t        super().__init__(dictionary)\n\t        self.args = args\n\t        tt = torch.tensor([i for i in range(len(dictionary))])\n\t        print('dictionary string: ', dictionary.string(tt))\n", "        if args.encoder_layers_to_keep:\n\t            args.encoder_layers = len(args.encoder_layers_to_keep.split(\",\"))\n\t        self.sentence_encoder = AntibodyTransformerSentenceEncoder(\n\t            padding_idx=dictionary.pad(),\n\t            vocab_size=len(dictionary),\n\t            num_encoder_layers=args.encoder_layers,\n\t            embedding_dim=args.encoder_embed_dim,\n\t            ffn_embedding_dim=args.encoder_ffn_embed_dim,\n\t            num_attention_heads=args.encoder_attention_heads,\n\t            dropout=args.dropout,\n", "            attention_dropout=args.attention_dropout,\n\t            activation_dropout=args.activation_dropout,\n\t            layerdrop=args.encoder_layerdrop,\n\t            max_seq_len=args.max_positions,\n\t            segments_vocab=tag_dict,\n\t            encoder_normalize_before=True,\n\t            apply_bert_init=True,\n\t            activation_fn=args.activation_fn,\n\t            q_noise=args.quant_noise_pq,\n\t            qn_block_size=args.quant_noise_pq_block_size,\n", "        )\n\t        args.untie_weights_roberta = getattr(args, \"untie_weights_roberta\", False)\n\t        self.lm_head = RobertaLMHead(\n\t            embed_dim=args.encoder_embed_dim,\n\t            output_dim=len(dictionary),\n\t            activation_fn=args.activation_fn,\n\t            weight=(\n\t                self.sentence_encoder.embed_tokens.weight\n\t                if not args.untie_weights_roberta\n\t                else None\n", "            ),\n\t            finetune=args.finetune\n\t        )\n\t    def forward(\n\t        self,\n\t        src_tokens,\n\t        tag_tokens,\n\t        features_only=False,\n\t        return_all_hiddens=False,\n\t        masked_tokens=None,\n", "        past_key_values=None,\n\t        **unused\n\t    ):\n\t        \"\"\"\n\t        Args:\n\t            src_tokens (LongTensor): input tokens of shape `(batch, src_len)`\n\t            features_only (bool, optional): skip LM head and just return\n\t                features. If True, the output will be of shape\n\t                `(batch, src_len, embed_dim)`.\n\t            return_all_hiddens (bool, optional): also return all of the\n", "                intermediate hidden states (default: False).\n\t        Returns:\n\t            tuple:\n\t                - the LM output of shape `(batch, src_len, vocab)`\n\t                - a dictionary of additional data, where 'inner_states'\n\t                  is a list of hidden states. Note that the hidden\n\t                  states have shape `(src_len, batch, vocab)`.\n\t        \"\"\"\n\t        x, extra = self.extract_features(\n\t            src_tokens, tag_tokens, return_all_hiddens=return_all_hiddens, past_key_values=past_key_values,\n", "        )\n\t        if self.args.finetune:\n\t            pt_emb = x.clone().detach()\n\t            if masked_tokens is not None:\n\t                pt_emb = pt_emb[masked_tokens, :]\n\t        else:\n\t            pt_emb = None\n\t        if not features_only:\n\t            x = self.output_layer(x, masked_tokens=masked_tokens)\n\t        return x, pt_emb, extra\n", "    def extract_features(self, src_tokens, tag_tokens, return_all_hiddens=False, past_key_values=None, **kwargs):\n\t        inner_states, _ = self.sentence_encoder(\n\t            src_tokens,\n\t            segment_labels=tag_tokens,\n\t            last_state_only=not return_all_hiddens,\n\t            token_embeddings=kwargs.get(\"token_embeddings\", None),\n\t            past_key_values=past_key_values,\n\t        )\n\t        features = inner_states[-1].transpose(0, 1)  # T x B x C -> B x T x C\n\t        return features, {\"inner_states\": inner_states if return_all_hiddens else None}\n", "    def output_layer(self, features, masked_tokens=None, **unused):\n\t        return self.lm_head(features, masked_tokens)\n\t    def max_positions(self):\n\t        \"\"\"Maximum output length supported by the encoder.\"\"\"\n\t        return self.args.max_positions\n\t@register_model_architecture(\"antibody_roberta\", \"antibody_roberta\")\n\tdef base_architecture(args):\n\t    args.encoder_layers = getattr(args, \"encoder_layers\", 12)\n\t    args.encoder_embed_dim = getattr(args, \"encoder_embed_dim\", 768)\n\t    args.encoder_ffn_embed_dim = getattr(args, \"encoder_ffn_embed_dim\", 3072)\n", "    args.encoder_attention_heads = getattr(args, \"encoder_attention_heads\", 12)\n\t    args.activation_fn = getattr(args, \"activation_fn\", \"gelu\")\n\t    args.pooler_activation_fn = getattr(args, \"pooler_activation_fn\", \"tanh\")\n\t    args.dropout = getattr(args, \"dropout\", 0.1)\n\t    args.attention_dropout = getattr(args, \"attention_dropout\", 0.1)\n\t    args.activation_dropout = getattr(args, \"activation_dropout\", 0.0)\n\t    args.pooler_dropout = getattr(args, \"pooler_dropout\", 0.0)\n\t    args.encoder_layers_to_keep = getattr(args, \"encoder_layers_to_keep\", None)\n\t    args.encoder_layerdrop = getattr(args, \"encoder_layerdrop\", 0.0)\n\t    args.encoder_layerdrop = getattr(args, \"encoder_layerdrop\", 0.0)\n", "    args.spectral_norm_classification_head = getattr(\n\t        args, \"spectral_nrom_classification_head\", False\n\t    )\n\t@register_model_architecture(\"antibody_roberta\", \"antibody_roberta_base\")\n\tdef roberta_base_architecture(args):\n\t    base_architecture(args)\n"]}
{"filename": "fairseq_models/models/ab_decoder_ablation.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\timport copy\n\tfrom fairseq_models.data.abgen_dataset import ALPHABET, ATOM_TYPES, RES_ATOM14\n\tfrom fairseq_models.modules.hmpn_encoder import *\n\tfrom fairseq_models.modules.framework_encoder import HierarchicalDecoder\n\tfrom fairseq_models.modules.nnutils import * \n\tfrom fairseq_models.modules.utils import *\n", "class BertonlyDecoder(nn.Module):\n\t    def __init__(self, args):\n\t        super(BertonlyDecoder, self).__init__()\n\t        self.args = args\n\t        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\t    def forward(self, enc_out, paratope, epitope, antibody, pt_emb, masked_tokens):\n\t        bind_X, _, _, _ = paratope\n\t        bind_X = torch.zeros((bind_X.size(0), bind_X.size(1), 4, 3), device=enc_out.device)\n\t        return ReturnType(xloss=0., nll=0., bind_X=bind_X)\n\t    def generate(self, enc_out, paratope, epitope, antibody, pt_emb, masked_tokens, num_decode):\n", "        B, paratope_N = paratope[1].size(0), paratope[1].size(1)\n\t        prob = F.softmax(enc_out.view(-1, len(ALPHABET)), dim=-1)\n\t        bind_I = torch.multinomial(prob, num_samples=1).squeeze(-1)\n\t        snll = self.ce_loss(enc_out.view(-1, len(ALPHABET)), bind_I)\n\t        sloss = snll.view(B, paratope_N).mean(dim=1)\n\t        S = bind_I.view(B, paratope_N).tolist()\n\t        S = [''.join([ALPHABET[S[i][j]] for j in range(paratope_N)]) for i in range(B)]\n\t        ppl = torch.exp(sloss / paratope_N)\n\t        return ReturnType(handle=S, ppl=ppl, bind_X=None)\n\t        # B, paratope_N = paratope[1].size(0), paratope[1].size(1)\n", "        # prob = F.softmax(enc_out.view(-1, len(ALPHABET)), dim=-1)\n\t        # bind_I = torch.multinomial(prob, num_samples=num_decode, replacement=True)\n\t        # bind_I = torch.transpose(bind_I, 0, 1)\n\t        # repeat_logits = enc_out.view(-1, len(ALPHABET)).repeat(num_decode, 1)\n\t        # snll = self.ce_loss(repeat_logits, bind_I.reshape(-1))\n\t        # sloss = snll.view(num_decode, paratope_N).mean(dim=1)\n\t        # S = bind_I.tolist()\n\t        # S = [''.join([ALPHABET[S[i][j]] for j in range(paratope_N)]) for i in range(num_decode)]\n\t        # ppl = torch.exp(sloss / paratope_N)\n\t        # return ReturnType(handle=S, ppl=ppl, bind_X=None)\n", "        # B, N = paratope[1].size(0), paratope[1].size(1)\n\t        # bind_I = torch.zeros(B* N).cuda().long()\n\t        # prob = F.softmax(enc_out.view(-1, len(ALPHABET)), dim=-1)\n\t        # bind_I = torch.multinomial(prob, num_samples=1).squeeze(-1)\n\t        # sloss = self.ce_loss(enc_out.view(-1, len(ALPHABET)), bind_I)\n\t        # S = bind_I.view(B, N).tolist()\n\t        # S = [''.join([ALPHABET[S[i][j]] for j in range(N)]) for i in range(B)]\n\t        # ppl = torch.exp(sloss / N)\n\t        # ReturnType(handle=S, ppl=ppl, bind_X=None)\n\tclass FullshotRefineDecoderStack(ABModel):\n", "    def __init__(self, args):\n\t        super(FullshotRefineDecoderStack, self).__init__(args)\n\t        self.args = args\n\t        self.hierarchical = args.hierarchical\n\t        self.residue_atom14 = torch.tensor([\n\t                [ATOM_TYPES.index(a) for a in atoms] for atoms in RES_ATOM14\n\t        ]).cuda()\n\t        self.W_s = nn.Linear(args.hidden_size, len(ALPHABET))\n\t        self.W_t = nn.Linear(self.embedding.dim(), args.hidden_size)\n\t        self.U_i = nn.Linear(self.embedding.dim(), args.hidden_size)\n", "        # self.W_trans = nn.Linear(args.hidden_size, self.embedding.dim())\n\t        self.coord_loss = nn.SmoothL1Loss(reduction='sum')\n\t        if args.hierarchical:\n\t            self.struct_mpn = HierEGNNEncoder(args)\n\t            self.seq_mpn = HierEGNNEncoder(args, update_X=False, backbone_CA_only=False)\n\t        else:\n\t            self.struct_mpn = EGNNEncoder(args)\n\t            self.seq_mpn = EGNNEncoder(args, update_X=False)\n\t        self.framework_encoder = HierarchicalDecoder(args)\n\t        for param in self.parameters():\n", "            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    def struct_loss(self, antibody_X, epitope_X, true_V, true_R, true_D, inter_D, true_C):\n\t        # dihedral loss\n\t        antibody_V = self.features._dihedrals(antibody_X)\n\t        vloss = self.mse_loss(antibody_V, true_V).sum(dim=-1)\n\t        # local loss\n\t        rdist = antibody_X.unsqueeze(2) - antibody_X.unsqueeze(3)\n\t        rdist = torch.sum(rdist ** 2, dim=-1)\n\t        rloss = self.huber_loss(rdist, true_R) + 10 * F.relu(1.5 - rdist)\n", "        # full loss\n\t        cdist, _ = full_square_dist(antibody_X, antibody_X, torch.ones_like(antibody_X)[..., 0], torch.ones_like(antibody_X)[..., 0])\n\t        closs = self.huber_loss(cdist, true_C) + 10 * F.relu(1.5 - cdist)\n\t        # alpha carbon\n\t        antibody_X, epitope_X = antibody_X[:, :, 1], epitope_X[:, :, 1]\n\t        # CDR self distance\n\t        dist = antibody_X.unsqueeze(1) - antibody_X.unsqueeze(2)\n\t        dist = torch.sum(dist ** 2, dim=-1)\n\t        dloss = self.huber_loss(dist, true_D) + 10 * F.relu(14.4 - dist)\n\t        # inter distance\n", "        idist = antibody_X.unsqueeze(2) - epitope_X.unsqueeze(1)\n\t        idist = torch.sum(idist ** 2, dim=-1)\n\t        iloss = self.huber_loss(idist, inter_D) + 10 * F.relu(14.4 - idist)\n\t        return dloss, vloss, rloss, iloss, closs\n\t    def forward(\n\t        self, init_prob, paratope, epitope, antibody,\n\t        pretrained_embedding=None, masked_tokens=None\n\t    ):\n\t        # return ReturnType(xloss=3.0, nll=2., bind_X=torch.ones(masked_tokens.sum().item(), 14, 3), handle=(None, None))\n\t        _, true_cdr_S, flatten_cdr_S, flatten_init_X = paratope\n", "        epitope_X, epitope_S, epitope_A = epitope\n\t        antibody_X, antibody_S, antibody_cdr, padding_mask = antibody\n\t        # Encode target\n\t        epitope_h = self.U_i(self.embedding(epitope_S))\n\t        epitope_V = self.features._dihedrals(epitope_X)\n\t        epitope_mask = epitope_A[:,:,1].clamp(max=1).float()\n\t        # antibody_h_0: initialized antibody embedding with shape [B, antibody_N, 256]\n\t        # paratope_mask: mask for paratope nodes with shape [B, antibody_N]\n\t        # padding_mask: mask for existing nodes with shape [B, antibody_N]\n\t        init_prob = F.softmax(init_prob, dim=-1)\n", "        antibody_h_0, true_antibody_X, paratope_mask, antibody_X, padding_mask = self.framework_encoder(\n\t            antibody_X, antibody_S, antibody_cdr, padding_mask, init_prob, masked_tokens, flatten_init_X.detach().clone()\n\t        )\n\t        B, paratope_N = true_cdr_S.size(0), true_cdr_S.size(1)\n\t        antibody_N = paratope_mask.size(1)\n\t        antibody_A = torch.zeros(B, antibody_N, 14).cuda().long()\n\t        antibody_A[padding_mask>0] = torch.tensor(\n\t            [1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n\t        ).cuda().expand(int(padding_mask.sum()), -1)  # backbone atoms\n\t        # Refine\n", "        dloss = vloss = rloss = iloss = sloss = closs = 0\n\t        for t in range(self.args.refine_iteration):\n\t            # sequence update\n\t            antibody_V = self.features._dihedrals(antibody_X.detach())\n\t            complex_V = torch.cat([antibody_V, epitope_V], dim=1).detach()\n\t            complex_X = torch.cat([antibody_X, epitope_X], dim=1).detach()\n\t            complex_A = torch.cat([antibody_A, epitope_A], dim=1).detach()\n\t            # sequence message passing\n\t            complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t            complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n", "            logits = self.W_s(complex_h[:, :antibody_N])\n\t            logits = logits[paratope_mask]\n\t            antibody_h_0 = antibody_h_0.clone()\n\t            # calculate sequence loss\n\t            snll = self.ce_loss(logits, flatten_cdr_S)\n\t            sloss = sloss + torch.sum(snll)\n\t            # update paratope embedding\n\t            probs = F.softmax(logits, dim=-1)\n\t            antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n\t            # structrue message passing\n", "            complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t            complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t            antibody_X = antibody_X.clone()\n\t            antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t            ratio = (t + 1) / self.args.refine_iteration\n\t            label_X = true_antibody_X * ratio + antibody_X * (1 - ratio)\n\t            true_V = self.features._dihedrals(label_X)\n\t            true_R, rmask_2D = inner_square_dist(label_X, antibody_A.clamp(max=1).float())\n\t            true_D, mask_2D = self_square_dist(label_X, paratope_mask)\n\t            true_C, cmask_2D = full_square_dist(label_X, label_X, antibody_A, antibody_A)\n", "            inter_D, imask_2D = cross_square_dist(label_X, epitope_X, paratope_mask, epitope_mask)\n\t            dloss_t, vloss_t, rloss_t, iloss_t, closs_t = self.struct_loss(\n\t                    antibody_X, epitope_X, true_V, true_R, true_D, inter_D, true_C\n\t            )\n\t            vloss = vloss + vloss_t * paratope_mask\n\t            dloss = dloss + dloss_t * mask_2D\n\t            iloss = iloss + iloss_t * imask_2D\n\t            rloss = rloss + rloss_t * rmask_2D\n\t            closs = closs + closs_t * cmask_2D\n\t        sloss = sloss / paratope_mask.sum() # / self.args.refine_iteration\n", "        dloss = torch.sum(dloss) / mask_2D.sum() \n\t        iloss = torch.sum(iloss) / imask_2D.sum() \n\t        vloss = torch.sum(vloss) / paratope_mask.sum() \n\t        # print('mask_2D', mask_2D.sum())\n\t        if self.hierarchical:\n\t            rloss = torch.sum(rloss) / rmask_2D.sum()\n\t            closs = torch.sum(closs) / cmask_2D.sum()\n\t        else:\n\t            rloss = torch.sum(rloss[:,:,:4,:4]) / rmask_2D[:,:,:4,:4].sum()\n\t            closs = 0\n", "        struct_loss = (dloss + iloss + vloss + rloss + closs) / paratope_mask.sum() # / self.args.refine_iteration\n\t        seq_loss = sloss\n\t        return ReturnType(xloss=struct_loss, nll=seq_loss, bind_X=antibody_X[paratope_mask].detach(), handle=(epitope_X, epitope_A))\n\t    def generate(\n\t        self, init_prob, paratope, epitope, antibody,\n\t        pretrained_embedding=None, masked_tokens=None, num_decode=1\n\t    ):\n\t        _, true_cdr_S, flatten_cdr_S, flatten_init_X = paratope\n\t        epitope_X, epitope_S, epitope_A = epitope\n\t        antibody_X, antibody_S, antibody_cdr, antibody_mask = antibody\n", "        # Encode target (assumes same target)\n\t        epitope_h = self.U_i(self.embedding(epitope_S))\n\t        epitope_V = self.features._dihedrals(epitope_X)\n\t        epitope_mask = epitope_A[:,:,1].clamp(max=1).float()\n\t        # antibody_h_0: initialized antibody embedding with shape [B, antibody_N, 256]\n\t        # paratope_mask: mask for paratope nodes with shape [B, antibody_N]\n\t        # padding_mask: mask for existing nodes with shape [B, antibody_N]\n\t        init_prob = F.softmax(init_prob, dim=-1)\n\t        antibody_h_0, _, paratope_mask, antibody_X, padding_mask = self.framework_encoder(\n\t            antibody_X, antibody_S, antibody_cdr, antibody_mask, init_prob, masked_tokens, flatten_init_X.detach().clone()\n", "        )\n\t        B, paratope_N = true_cdr_S.size(0), true_cdr_S.size(1)\n\t        antibody_N = paratope_mask.size(1)\n\t        antibody_A = torch.zeros(B, antibody_N, 14).cuda().long()\n\t        antibody_A[padding_mask>0] = torch.tensor(\n\t            [1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n\t        ).cuda().expand(int(padding_mask.sum()), -1)  # backbone atoms\n\t        # Refine\n\t        for t in range(self.args.refine_iteration):\n\t            # sequence update\n", "            antibody_V = self.features._dihedrals(antibody_X.detach())\n\t            complex_V = torch.cat([antibody_V, epitope_V], dim=1).detach()\n\t            complex_X = torch.cat([antibody_X, epitope_X], dim=1).detach()\n\t            complex_A = torch.cat([antibody_A, epitope_A], dim=1).detach()\n\t            # sequence message passing\n\t            complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t            complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t            logits = self.W_s(complex_h[:, :antibody_N])\n\t            logits = logits[paratope_mask]\n\t            antibody_h_0 = antibody_h_0.clone()\n", "            # update paratope embedding\n\t            probs = F.softmax(logits, dim=-1)\n\t            antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n\t            # structrue message passing\n\t            complex_h = self.W_i(torch.cat([antibody_h_0, epitope_h], dim=1))\n\t            complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t            antibody_X = antibody_X.clone()\n\t            antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t        # sample new sequences\n\t        prob = F.softmax(logits.view(-1, len(ALPHABET)), dim=-1)\n", "        bind_I = torch.multinomial(prob, num_samples=num_decode, replacement=True)\n\t        bind_I = torch.transpose(bind_I, 0, 1)\n\t        repeat_logits = logits.view(-1, len(ALPHABET)).repeat(num_decode, 1)\n\t        snll = self.ce_loss(repeat_logits, bind_I.reshape(-1))\n\t        sloss = snll.view(num_decode, paratope_N).mean(dim=1)\n\t        S = bind_I.tolist()\n\t        S = [''.join([ALPHABET[S[i][j]] for j in range(paratope_N)]) for i in range(num_decode)]\n\t        ppl = torch.exp(sloss / paratope_N)\n\t        return ReturnType(handle=S, ppl=ppl, bind_X=antibody_X[paratope_mask].detach())\n"]}
{"filename": "fairseq_models/models/ab_decoder_noantigen.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\timport copy\n\tfrom fairseq_models.data.abgen_dataset import ALPHABET, ATOM_TYPES, RES_ATOM14\n\tfrom fairseq_models.modules.hmpn_encoder import *\n\tfrom fairseq_models.modules.framework_encoder import HierarchicalDecoder\n\tfrom fairseq_models.modules.nnutils import * \n\tfrom fairseq_models.modules.utils import *\n", "class NoAntigenFullshotRefineDecoder(ABModel):\n\t    def __init__(self, args):\n\t        super(NoAntigenFullshotRefineDecoder, self).__init__(args)\n\t        self.args = args\n\t        self.hierarchical = args.hierarchical\n\t        self.residue_atom14 = torch.tensor([\n\t                [ATOM_TYPES.index(a) for a in atoms] for atoms in RES_ATOM14\n\t        ]).cuda()\n\t        self.W_s = nn.Linear(args.hidden_size, len(ALPHABET))\n\t        self.W_t = nn.Linear(self.embedding.dim(), args.hidden_size)\n", "        self.U_i = nn.Linear(self.embedding.dim(), args.hidden_size)\n\t        # self.W_trans = nn.Linear(args.hidden_size, self.embedding.dim())\n\t        self.coord_loss = nn.SmoothL1Loss(reduction='sum')\n\t        if args.hierarchical:\n\t            self.struct_mpn = HierEGNNEncoder(args)\n\t            self.seq_mpn = HierEGNNEncoder(args, update_X=False, backbone_CA_only=False)\n\t        else:\n\t            self.struct_mpn = EGNNEncoder(args)\n\t            self.seq_mpn = EGNNEncoder(args, update_X=False)\n\t        self.framework_encoder = HierarchicalDecoder(args)\n", "        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    def struct_loss(self, antibody_X, true_V, true_R, true_D, true_C):\n\t        # dihedral loss\n\t        antibody_V = self.features._dihedrals(antibody_X)\n\t        vloss = self.mse_loss(antibody_V, true_V).sum(dim=-1)\n\t        # local loss\n\t        rdist = antibody_X.unsqueeze(2) - antibody_X.unsqueeze(3)\n\t        rdist = torch.sum(rdist ** 2, dim=-1)\n", "        rloss = self.huber_loss(rdist, true_R) + 10 * F.relu(1.5 - rdist)\n\t        # full loss\n\t        cdist, _ = full_square_dist(antibody_X, antibody_X, torch.ones_like(antibody_X)[..., 0], torch.ones_like(antibody_X)[..., 0])\n\t        closs = self.huber_loss(cdist, true_C) + 10 * F.relu(1.5 - cdist)\n\t        # alpha carbon\n\t        antibody_X = antibody_X[:, :, 1]\n\t        # CDR self distance\n\t        dist = antibody_X.unsqueeze(1) - antibody_X.unsqueeze(2)\n\t        dist = torch.sum(dist ** 2, dim=-1)\n\t        dloss = self.huber_loss(dist, true_D) + 10 * F.relu(14.4 - dist)\n", "        return dloss, vloss, rloss, closs\n\t    def forward(\n\t        self, init_prob, paratope, epitope=None, antibody=None,\n\t        pretrained_embedding=None, masked_tokens=None\n\t    ):\n\t        # return ReturnType(xloss=3.0, nll=2., bind_X=torch.ones(masked_tokens.sum().item(), 14, 3), handle=(None, None))\n\t        _, true_cdr_S, flatten_cdr_S, flatten_init_X = paratope\n\t        antibody_X, antibody_S, antibody_cdr, padding_mask = antibody\n\t        # antibody_h_0: initialized antibody embedding with shape [B, antibody_N, 256]\n\t        # paratope_mask: mask for paratope nodes with shape [B, antibody_N]\n", "        # padding_mask: mask for existing nodes with shape [B, antibody_N]\n\t        init_prob = F.softmax(init_prob, dim=-1)\n\t        antibody_h_0, true_antibody_X, paratope_mask, antibody_X, padding_mask = self.framework_encoder(\n\t            antibody_X, antibody_S, antibody_cdr, padding_mask, init_prob, masked_tokens, flatten_init_X.detach().clone()\n\t        )\n\t        # antibody_X = torch.zeros_like(antibody_X)\n\t        B, paratope_N = true_cdr_S.size(0), true_cdr_S.size(1)\n\t        antibody_N = paratope_mask.size(1)\n\t        antibody_A = torch.zeros(B, antibody_N, 4).cuda().long()\n\t        antibody_A[padding_mask>0] = torch.tensor(\n", "            [1, 2, 3, 4], \n\t        ).cuda().expand(int(padding_mask.sum()), -1)  # backbone atoms\n\t        # Refine\n\t        dloss = vloss = rloss = sloss = closs = 0\n\t        for t in range(self.args.refine_iteration):\n\t            if t < self.args.refine_iteration - 1:\n\t                with torch.no_grad():\n\t                    # sequence update\n\t                    antibody_V = self.features._dihedrals(antibody_X.detach())\n\t                    complex_V = antibody_V.detach()\n", "                    complex_X = antibody_X.detach()\n\t                    complex_A = antibody_A.detach()\n\t                    # sequence message passing\n\t                    complex_h = self.W_i(antibody_h_0)\n\t                    complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                    logits = self.W_s(complex_h[:, :antibody_N])\n\t                    logits = logits[paratope_mask]\n\t                    antibody_h_0 = antibody_h_0.clone()\n\t                    # calculate sequence loss\n\t                    snll = self.ce_loss(logits, flatten_cdr_S)\n", "                    sloss = sloss + torch.sum(snll)\n\t                    # update paratope embedding\n\t                    probs = F.softmax(logits, dim=-1)\n\t                    antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n\t                    # structrue message passing\n\t                    complex_h = self.W_i(antibody_h_0)\n\t                    complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                    antibody_X = antibody_X.clone()\n\t                    antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t                    ratio = (t + 1) / self.args.refine_iteration\n", "                    label_X = true_antibody_X * ratio + antibody_X * (1 - ratio)\n\t                    true_V = self.features._dihedrals(label_X)\n\t                    true_R, rmask_2D = inner_square_dist(label_X, antibody_A.clamp(max=1).float())\n\t                    true_D, mask_2D = self_square_dist(label_X, paratope_mask)\n\t                    true_C, cmask_2D = full_square_dist(label_X, label_X, antibody_A, antibody_A)\n\t                    dloss_t, vloss_t, rloss_t, closs_t = self.struct_loss(\n\t                            antibody_X, true_V, true_R, true_D, true_C\n\t                    )\n\t                    vloss = vloss + vloss_t * paratope_mask\n\t                    dloss = dloss + dloss_t * mask_2D\n", "                    rloss = rloss + rloss_t * rmask_2D\n\t                    closs = closs + closs_t * cmask_2D\n\t            else:\n\t                # sequence update\n\t                antibody_V = self.features._dihedrals(antibody_X.detach())\n\t                complex_V = antibody_V.detach()\n\t                complex_X = antibody_X.detach()\n\t                complex_A = antibody_A.detach()\n\t                # sequence message passing\n\t                complex_h = self.W_i(antibody_h_0)\n", "                complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                logits = self.W_s(complex_h[:, :antibody_N])\n\t                logits = logits[paratope_mask]\n\t                antibody_h_0 = antibody_h_0.clone()\n\t                # calculate sequence loss\n\t                snll = self.ce_loss(logits, flatten_cdr_S)\n\t                sloss = sloss + torch.sum(snll)\n\t                # update paratope embedding\n\t                probs = F.softmax(logits, dim=-1)\n\t                antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n", "                # structrue message passing\n\t                complex_h = self.W_i(antibody_h_0)\n\t                complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t                antibody_X = antibody_X.clone()\n\t                antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t                ratio = (t + 1) / self.args.refine_iteration\n\t                label_X = true_antibody_X * ratio + antibody_X * (1 - ratio)\n\t                true_V = self.features._dihedrals(label_X)\n\t                true_R, rmask_2D = inner_square_dist(label_X, antibody_A.clamp(max=1).float())\n\t                true_D, mask_2D = self_square_dist(label_X, paratope_mask)\n", "                true_C, cmask_2D = full_square_dist(label_X, label_X, antibody_A, antibody_A)\n\t                dloss_t, vloss_t, rloss_t, closs_t = self.struct_loss(\n\t                        antibody_X, true_V, true_R, true_D, true_C\n\t                )\n\t                vloss = vloss + vloss_t * paratope_mask\n\t                dloss = dloss + dloss_t * mask_2D\n\t                rloss = rloss + rloss_t * rmask_2D\n\t                closs = closs + closs_t * cmask_2D\n\t        sloss = sloss / paratope_mask.sum() / self.args.refine_iteration\n\t        dloss = torch.sum(dloss) / mask_2D.sum() \n", "        vloss = torch.sum(vloss) / paratope_mask.sum() \n\t        # print('mask_2D', mask_2D.sum())\n\t        if self.hierarchical:\n\t            rloss = torch.sum(rloss) / rmask_2D.sum()\n\t            closs = torch.sum(closs) / cmask_2D.sum()\n\t        else:\n\t            rloss = torch.sum(rloss[:,:,:4,:4]) / rmask_2D[:,:,:4,:4].sum()\n\t            closs = 0\n\t        struct_loss = (dloss + vloss + rloss + closs) / paratope_N / self.args.refine_iteration\n\t        seq_loss = sloss\n", "        return ReturnType(xloss=struct_loss, nll=seq_loss, bind_X=antibody_X[paratope_mask].detach())\n\t    def generate(\n\t        self, init_prob, paratope, epitope=None, antibody=None,\n\t        pretrained_embedding=None, masked_tokens=None, num_decode=1\n\t    ):\n\t        _, true_cdr_S, flatten_cdr_S, flatten_init_X = paratope\n\t        antibody_X, antibody_S, antibody_cdr, antibody_mask = antibody\n\t        # antibody_h_0: initialized antibody embedding with shape [B, antibody_N, 256]\n\t        # paratope_mask: mask for paratope nodes with shape [B, antibody_N]\n\t        # padding_mask: mask for existing nodes with shape [B, antibody_N]\n", "        init_prob = F.softmax(init_prob, dim=-1)\n\t        antibody_h_0, _, paratope_mask, antibody_X, padding_mask = self.framework_encoder(\n\t            antibody_X, antibody_S, antibody_cdr, antibody_mask, init_prob, masked_tokens, flatten_init_X.detach().clone()\n\t        )\n\t        B, paratope_N = true_cdr_S.size(0), true_cdr_S.size(1)\n\t        antibody_N = paratope_mask.size(1)\n\t        antibody_A = torch.zeros(B, antibody_N, 4).cuda().long()\n\t        antibody_A[padding_mask>0] = torch.tensor(\n\t            [1, 2, 3, 4], \n\t        ).cuda().expand(int(padding_mask.sum()), -1)  # backbone atoms\n", "        # Refine\n\t        for t in range(self.args.refine_iteration):\n\t            # sequence update\n\t            antibody_V = self.features._dihedrals(antibody_X.detach())\n\t            complex_V = antibody_V.detach()\n\t            complex_X = antibody_X.detach()\n\t            complex_A = antibody_A.detach()\n\t            # sequence message passing\n\t            complex_h = self.W_i(antibody_h_0)\n\t            complex_h, _ = self.seq_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n", "            logits = self.W_s(complex_h[:, :antibody_N])\n\t            logits = logits[paratope_mask]\n\t            antibody_h_0 = antibody_h_0.clone()\n\t            # update paratope embedding\n\t            probs = F.softmax(logits, dim=-1)\n\t            antibody_h_0[paratope_mask] = self.W_t(self.embedding.soft_forward(probs))\n\t            # structrue message passing\n\t            complex_h = self.W_i(antibody_h_0)\n\t            complex_h, complex_X = self.struct_mpn(complex_X, complex_V, complex_h, complex_A, antibody_N=antibody_N, paratope_mask=paratope_mask, pretrained_embedding=pretrained_embedding)\n\t            antibody_X = antibody_X.clone()\n", "            antibody_X[paratope_mask] = complex_X[:, :antibody_N][paratope_mask]\n\t        # sample new sequences\n\t        prob = F.softmax(logits.view(-1, len(ALPHABET)), dim=-1)\n\t        bind_I = torch.multinomial(prob, num_samples=1).squeeze(-1)\n\t        snll = self.ce_loss(logits.view(-1, len(ALPHABET)), bind_I)\n\t        sloss = snll.view(B, paratope_N).mean(dim=1)\n\t        S = bind_I.view(B, paratope_N).tolist()\n\t        S = [''.join([ALPHABET[S[i][j]] for j in range(paratope_N)]) for i in range(B)]\n\t        ppl = torch.exp(sloss / paratope_N)\n\t        return ReturnType(handle=S, ppl=ppl, bind_X=antibody_X[paratope_mask].detach())\n"]}
{"filename": "fairseq_models/modules/protein_features.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\timport copy\n\t# from matplotlib import pyplot as plt\n\tfrom .utils import gather_edges, gather_nodes\n\tclass PositionalEncodings(nn.Module):\n\t    def __init__(self, num_embeddings, period_range=[2,1000]):\n\t        super(PositionalEncodings, self).__init__()\n", "        self.num_embeddings = num_embeddings\n\t        self.period_range = period_range \n\t    def forward(self, E_idx):\n\t        # i-j\n\t        N_batch = E_idx.size(0)\n\t        N_nodes = E_idx.size(1)\n\t        N_neighbors = E_idx.size(2)\n\t        ii = torch.arange(N_nodes).view((1, -1, 1)).to(E_idx.device)\n\t        d = (E_idx.float() - ii).unsqueeze(-1)\n\t        # Original Transformer frequencies\n", "        frequency = torch.exp(\n\t            torch.arange(0, self.num_embeddings, 2)\n\t            * -(np.log(10000.0) / self.num_embeddings)\n\t        ).to(E_idx.device)\n\t        # Grid-aligned\n\t        # frequency = 2. * np.pi * torch.exp(\n\t        #     -torch.linspace(\n\t        #         np.log(self.period_range[0]), \n\t        #         np.log(self.period_range[1]),\n\t        #         self.num_embeddings / 2\n", "        #     )\n\t        # )\n\t        angles = d * frequency.view((1,1,1,-1))\n\t        E = torch.cat((torch.cos(angles), torch.sin(angles)), -1)\n\t        return E\n\tclass ProteinFeatures(nn.Module):\n\t    def __init__(self, num_positional_embeddings=16, num_rbf=16, top_k=30, features_type='backbone', direction='forward'):\n\t        \"\"\" Extract protein features \"\"\"\n\t        super(ProteinFeatures, self).__init__()\n\t        self.top_k = top_k\n", "        self.num_rbf = num_rbf\n\t        self.num_positional_embeddings = num_positional_embeddings\n\t        self.direction = direction\n\t        # Feature types\n\t        self.features_type = features_type\n\t        self.feature_dimensions = {\n\t            'atom': (0, num_positional_embeddings + num_rbf),\n\t            'backbone': (6, num_positional_embeddings + num_rbf + 7),\n\t        }\n\t        # Positional encoding\n", "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n\t    def _dist(self, X, mask, eps=1E-6):\n\t        \"\"\" Pairwise euclidean distances \"\"\"\n\t        N = X.size(1)\n\t        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n\t        if self.direction == 'bidirectional':\n\t            mask_2D = mask_2D - torch.eye(N).unsqueeze(0).cuda()  # remove self\n\t            mask_2D = mask_2D.clamp(min=0)\n\t        elif self.direction == 'forward':\n\t            nmask = torch.arange(X.size(1)).cuda()\n", "            nmask = nmask.view(1,-1,1) > nmask.view(1,1,-1)\n\t            mask_2D = nmask.float() * mask_2D  # [B, N, N]\n\t        else:\n\t            raise ValueError('invalid direction', direction)\n\t        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n\t        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n\t        # Identify k nearest neighbors (not including self)\n\t        D_adjust = D + (1. - mask_2D) * 10000\n\t        top_k = min(self.top_k, N)\n\t        D_neighbors, E_idx = torch.topk(D_adjust, top_k, dim=-1, largest=False)\n", "        mask_neighbors = gather_edges(mask_2D.unsqueeze(-1), E_idx)\n\t        # Debug plot KNN\n\t        # print(E_idx[:10,:10])\n\t        # D_simple = mask_2D * torch.zeros(D.size()).scatter(-1, E_idx, torch.ones_like(knn_D))\n\t        # print(D_simple)\n\t        # fig = plt.figure(figsize=(4,4))\n\t        # ax = fig.add_subplot(111)\n\t        # D_simple = D.data.numpy()[0,:,:]\n\t        # plt.imshow(D_simple, aspect='equal')\n\t        # plt.axis('off')\n", "        # plt.tight_layout()\n\t        # plt.savefig('D_knn.pdf')\n\t        # exit(0)\n\t        return D_neighbors, E_idx, mask_neighbors\n\t    def _rbf(self, D):\n\t        # Distance radial basis function\n\t        D_min, D_max, D_count = 0., 20., self.num_rbf\n\t        D_mu = torch.linspace(D_min, D_max, D_count).cuda()\n\t        D_mu = D_mu.view([1,1,1,-1])\n\t        D_sigma = (D_max - D_min) / D_count\n", "        D_expand = torch.unsqueeze(D, -1)\n\t        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n\t        # for i in range(D_count):\n\t        #     fig = plt.figure(figsize=(4,4))\n\t        #     ax = fig.add_subplot(111)\n\t        #     rbf_i = RBF.data.numpy()[0,i,:,:]\n\t        #     # rbf_i = D.data.numpy()[0,0,:,:]\n\t        #     plt.imshow(rbf_i, aspect='equal')\n\t        #     plt.axis('off')\n\t        #     plt.tight_layout()\n", "        #     plt.savefig('rbf{}.pdf'.format(i))\n\t        #     print(np.min(rbf_i), np.max(rbf_i), np.mean(rbf_i))\n\t        # exit(0)\n\t        return RBF\n\t    def _quaternions(self, R):\n\t        \"\"\" Convert a batch of 3D rotations [R] to quaternions [Q]\n\t            R [...,3,3]\n\t            Q [...,4]\n\t        \"\"\"\n\t        # Simple Wikipedia version\n", "        # en.wikipedia.org/wiki/Rotation_matrix#Quaternion\n\t        # For other options see math.stackexchange.com/questions/2074316/calculating-rotation-axis-from-rotation-matrix\n\t        diag = torch.diagonal(R, dim1=-2, dim2=-1)\n\t        Rxx, Ryy, Rzz = diag.unbind(-1)\n\t        magnitudes = 0.5 * torch.sqrt(torch.abs(1 + torch.stack([\n\t              Rxx - Ryy - Rzz, \n\t            - Rxx + Ryy - Rzz, \n\t            - Rxx - Ryy + Rzz\n\t        ], -1)))\n\t        _R = lambda i,j: R[:,:,:,i,j]\n", "        signs = torch.sign(torch.stack([\n\t            _R(2,1) - _R(1,2),\n\t            _R(0,2) - _R(2,0),\n\t            _R(1,0) - _R(0,1)\n\t        ], -1))\n\t        xyz = signs * magnitudes\n\t        # The relu enforces a non-negative trace\n\t        w = torch.sqrt(F.relu(1 + diag.sum(-1, keepdim=True))) / 2.\n\t        Q = torch.cat((xyz, w), -1)\n\t        Q = F.normalize(Q, dim=-1)\n", "        # Axis of rotation\n\t        # Replace bad rotation matrices with identity\n\t        # I = torch.eye(3).view((1,1,1,3,3))\n\t        # I = I.expand(*(list(R.shape[:3]) + [-1,-1]))\n\t        # det = (\n\t        #     R[:,:,:,0,0] * (R[:,:,:,1,1] * R[:,:,:,2,2] - R[:,:,:,1,2] * R[:,:,:,2,1])\n\t        #     - R[:,:,:,0,1] * (R[:,:,:,1,0] * R[:,:,:,2,2] - R[:,:,:,1,2] * R[:,:,:,2,0])\n\t        #     + R[:,:,:,0,2] * (R[:,:,:,1,0] * R[:,:,:,2,1] - R[:,:,:,1,1] * R[:,:,:,2,0])\n\t        # )\n\t        # det_mask = torch.abs(det.unsqueeze(-1).unsqueeze(-1))\n", "        # R = det_mask * R + (1 - det_mask) * I\n\t        # DEBUG\n\t        # https://math.stackexchange.com/questions/2074316/calculating-rotation-axis-from-rotation-matrix\n\t        # Columns of this are in rotation plane\n\t        # A = R - I\n\t        # v1, v2 = A[:,:,:,:,0], A[:,:,:,:,1]\n\t        # axis = F.normalize(torch.cross(v1, v2), dim=-1)\n\t        return Q\n\t    def _contacts(self, D_neighbors, E_idx, mask_neighbors, cutoff=8):\n\t        \"\"\" Contacts \"\"\"\n", "        D_neighbors = D_neighbors.unsqueeze(-1)\n\t        neighbor_C = mask_neighbors * (D_neighbors < cutoff)\n\t        return neighbor_C\n\t    def _hbonds(self, X, E_idx, mask_neighbors, eps=1E-3):\n\t        \"\"\" Hydrogen bonds and contact map\n\t        \"\"\"\n\t        X_atoms = dict(zip(['N', 'CA', 'C', 'O'], torch.unbind(X, 2)))\n\t        # Virtual hydrogens\n\t        X_atoms['C_prev'] = F.pad(X_atoms['C'][:,1:,:], (0,0,0,1), 'constant', 0)\n\t        X_atoms['H'] = X_atoms['N'] + F.normalize(\n", "             F.normalize(X_atoms['N'] - X_atoms['C_prev'], -1)\n\t          +  F.normalize(X_atoms['N'] - X_atoms['CA'], -1)\n\t        , -1)\n\t        def _distance(X_a, X_b):\n\t            return torch.norm(X_a[:,None,:,:] - X_b[:,:,None,:], dim=-1)\n\t        def _inv_distance(X_a, X_b):\n\t            return 1. / (_distance(X_a, X_b) + eps)\n\t        # DSSP vacuum electrostatics model\n\t        U = (0.084 * 332) * (\n\t              _inv_distance(X_atoms['O'], X_atoms['N'])\n", "            + _inv_distance(X_atoms['C'], X_atoms['H'])\n\t            - _inv_distance(X_atoms['O'], X_atoms['H'])\n\t            - _inv_distance(X_atoms['C'], X_atoms['N'])\n\t        )\n\t        HB = (U < -0.5)\n\t        neighbor_HB = mask_neighbors * gather_edges(HB.unsqueeze(-1),  E_idx)\n\t        # print(HB)\n\t        # HB = F.sigmoid(U)\n\t        # U_np = U.cpu().data.numpy()\n\t        # # plt.matshow(np.mean(U_np < -0.5, axis=0))\n", "        # plt.matshow(HB[0,:,:])\n\t        # plt.colorbar()\n\t        # plt.show()\n\t        # D_CA = _distance(X_atoms['CA'], X_atoms['CA'])\n\t        # D_CA = D_CA.cpu().data.numpy()\n\t        # plt.matshow(D_CA[0,:,:] < contact_D)\n\t        # # plt.colorbar()\n\t        # plt.show()\n\t        # exit(0)\n\t        return neighbor_HB\n", "    def _AD_features(self, X, eps=1e-6):\n\t        # Shifted slices of unit vectors\n\t        dX = X[:,1:,:] - X[:,:-1,:]\n\t        U = F.normalize(dX, dim=-1)\n\t        u_2 = U[:,:-2,:]\n\t        u_1 = U[:,1:-1,:]\n\t        u_0 = U[:,2:,:]\n\t        # Backbone normals\n\t        n_2 = F.normalize(torch.cross(u_2, u_1), dim=-1)\n\t        n_1 = F.normalize(torch.cross(u_1, u_0), dim=-1)\n", "        # Bond angle calculation\n\t        cosA = -(u_1 * u_0).sum(-1)\n\t        cosA = torch.clamp(cosA, -1+eps, 1-eps)\n\t        A = torch.acos(cosA)\n\t        # Angle between normals\n\t        cosD = (n_2 * n_1).sum(-1)\n\t        cosD = torch.clamp(cosD, -1+eps, 1-eps)\n\t        D = torch.sign((u_2 * n_1).sum(-1)) * torch.acos(cosD)\n\t        # Backbone features\n\t        AD_features = torch.stack((torch.cos(A), torch.sin(A) * torch.cos(D), torch.sin(A) * torch.sin(D)), 2)\n", "        return F.pad(AD_features, (0,0,1,2), 'constant', 0)\n\t    def _orientations_coarse(self, X, E_idx, eps=1e-6):\n\t        # Shifted slices of unit vectors\n\t        dX = X[:,1:,:] - X[:,:-1,:]\n\t        U = F.normalize(dX, dim=-1)\n\t        u_2 = U[:,:-2,:]\n\t        u_1 = U[:,1:-1,:]\n\t        u_0 = U[:,2:,:]\n\t        # Backbone normals\n\t        n_2 = F.normalize(torch.cross(u_2, u_1), dim=-1)\n", "        n_1 = F.normalize(torch.cross(u_1, u_0), dim=-1)\n\t        # Build relative orientations\n\t        o_1 = F.normalize(u_2 - u_1, dim=-1)\n\t        O = torch.stack((o_1, n_2, torch.cross(o_1, n_2)), 2)\n\t        O = O.view(list(O.shape[:2]) + [9])\n\t        O = F.pad(O, (0,0,1,2), 'constant', 0)\n\t        O_neighbors = gather_nodes(O, E_idx)\n\t        X_neighbors = gather_nodes(X, E_idx)\n\t        # Re-view as rotation matrices\n\t        O = O.view(list(O.shape[:2]) + [3,3])\n", "        O_neighbors = O_neighbors.view(list(O_neighbors.shape[:3]) + [3,3])\n\t        # Rotate into local reference frames\n\t        dX = X_neighbors - X.unsqueeze(-2)\n\t        dU = torch.matmul(O.unsqueeze(2), dX.unsqueeze(-1)).squeeze(-1)\n\t        dU = F.normalize(dU, dim=-1)\n\t        R = torch.matmul(O.unsqueeze(2).transpose(-1,-2).contiguous(), O_neighbors)\n\t        Q = self._quaternions(R)\n\t        return torch.cat((dU,Q), dim=-1)\n\t    def _dihedrals(self, X, eps=1e-7):\n\t        # First 3 coordinates are N, CA, C\n", "        X = X[:,:,:3,:].reshape(X.shape[0], 3*X.shape[1], 3)\n\t        # Shifted slices of unit vectors\n\t        dX = X[:,1:,:] - X[:,:-1,:]\n\t        U = F.normalize(dX, dim=-1)\n\t        u_2 = U[:,:-2,:]\n\t        u_1 = U[:,1:-1,:]\n\t        u_0 = U[:,2:,:]\n\t        # Backbone normals\n\t        n_2 = F.normalize(torch.cross(u_2, u_1), dim=-1)\n\t        n_1 = F.normalize(torch.cross(u_1, u_0), dim=-1)\n", "        # Angle between normals\n\t        cosD = (n_2 * n_1).sum(-1)\n\t        cosD = torch.clamp(cosD, -1+eps, 1-eps)\n\t        D = torch.sign((u_2 * n_1).sum(-1)) * torch.acos(cosD)\n\t        D = F.pad(D, (3,0), 'constant', 0)\n\t        D = D.view((D.size(0), int(D.size(1)/3), 3))\n\t        phi, psi, omega = torch.unbind(D,-1)\n\t        # print(cosD.cpu().data.numpy().flatten())\n\t        # print(omega.sum().cpu().data.numpy().flatten())\n\t        # Bond angle calculation\n", "        # A = torch.acos(-(u_1 * u_0).sum(-1))\n\t        # DEBUG: Ramachandran plot\n\t        # x = phi.cpu().data.numpy().flatten()\n\t        # y = psi.cpu().data.numpy().flatten()\n\t        # plt.scatter(x * 180 / np.pi, y * 180 / np.pi, s=1, marker='.')\n\t        # plt.xlabel('phi')\n\t        # plt.ylabel('psi')\n\t        # plt.axis('square')\n\t        # plt.grid()\n\t        # plt.axis([-180,180,-180,180])\n", "        # plt.show()\n\t        # Lift angle representations to the circle\n\t        D_features = torch.cat((torch.cos(D), torch.sin(D)), 2)\n\t        return D_features\n\t    def forward(self, X, mask):\n\t        \"\"\" Featurize coordinates as an attributed graph \"\"\"\n\t        if self.features_type == 'backbone':\n\t            X_ca = X[:,:,1,:]\n\t            D_neighbors, E_idx, mask_neighbors = self._dist(X_ca, mask)\n\t            RBF = self._rbf(D_neighbors)\n", "            E_positional = self.embeddings(E_idx)\n\t            O_features = self._orientations_coarse(X_ca, E_idx)\n\t            E = torch.cat((E_positional, RBF, O_features), -1)\n\t            V = self._dihedrals(X)\n\t        elif self.features_type == 'atom':\n\t            D_neighbors, E_idx, mask_neighbors = self._dist(X, mask)\n\t            RBF = self._rbf(D_neighbors)\n\t            E_positional = self.embeddings(E_idx)\n\t            E = torch.cat((E_positional, RBF), -1)\n\t            V = None\n", "        return V, E, E_idx\n"]}
{"filename": "fairseq_models/modules/framework_encoder.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom .utils import *\n\tfrom .nnutils import * \n\tfrom .protein_features import ProteinFeatures\n\tclass HierarchicalDecoder(nn.Module):\n\t    def __init__(self, args):\n\t        super(HierarchicalDecoder, self).__init__()\n", "        self.cdr_type = args.cdr_type\n\t        self.k_neighbors = args.k_neighbors\n\t        self.block_size = args.block_size\n\t        self.hidden_size = args.hidden_size\n\t        self.args = args\n\t        self.features = ProteinFeatures(\n\t                top_k=args.k_neighbors, num_rbf=args.num_rbf,\n\t                features_type='full',\n\t                direction='bidirectional'\n\t        )\n", "        # self.node_in, self.edge_in = self.features.feature_dimensions['full']\n\t        self.embedding = AAEmbedding()\n\t        self.W_s = nn.Linear(self.embedding.dim(), args.hidden_size)\n\t        self.rnn = nn.GRU(\n\t                args.hidden_size, args.hidden_size, batch_first=True, \n\t                num_layers=1, bidirectional=True\n\t        )\n\t        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n", "    def mask_mean(self, X, mask, i):\n\t        # [B, N, 4, 3] -> [B, 1, 4, 3] / [B, 1, 1, 1]\n\t        X = X[:, i:i+self.block_size]\n\t        if X.dim() == 4:\n\t            mask = mask[:, i:i+self.block_size].unsqueeze(-1).unsqueeze(-1)\n\t        else:\n\t            mask = mask[:, i:i+self.block_size].unsqueeze(-1)\n\t        return torch.sum(X * mask, dim=1, keepdims=True) / (mask.sum(dim=1, keepdims=True) + 1e-8)\n\t    def make_X_blocks(self, X, l, r, mask):\n\t        N = X.size(1)\n", "        lblocks = [self.mask_mean(X, mask, i) for i in range(0, l, self.block_size)]\n\t        rblocks = [self.mask_mean(X, mask, i) for i in range(r + 1, N, self.block_size)]\n\t        bX = torch.cat(lblocks + [X[:, l:r+1]] + rblocks, dim=1)\n\t        return bX.detach()\n\t    def make_S_blocks(self, hS, l, r, mask):\n\t        N = hS.size(1) # 130\n\t        # l=T_min=96, r=T_max=109, range of cdr-3\n\t        # block_size=8\n\t        # ==> len(LS)=12, LS[i].shape=[7, 1, 256]\n\t        # ==> len(RS)=3, RS[i].shape=[7, 1, 256]\n", "        lseqs = [self.mask_mean(hS, mask, i) for i in range(0, l, self.block_size)] # mask_mean: calculate mean without mask\n\t        rseqs = [self.mask_mean(hS, mask, i) for i in range(r + 1, N, self.block_size)]\n\t        bS = torch.cat(lseqs + [hS[:, l:r+1]] + rseqs, dim=1) # 12 + 14 + 3 = 29 ==> [7, 29, 256]\n\t        return bS, len(lseqs), len(rseqs)\n\t    def make_mask_blocks(self, mask, l, r):\n\t        N = mask.size(1)\n\t        lmask = [mask[:, i:i+self.block_size].amax(dim=1, keepdims=True) for i in range(0, l, self.block_size)] # amax: max val of each row\n\t        rmask = [mask[:, i:i+self.block_size].amax(dim=1, keepdims=True) for i in range(r + 1, N, self.block_size)] # if one elem masked, the whole block masked\n\t        bmask = torch.cat(lmask + [mask[:, l:r+1]] + rmask, dim=1)\n\t        return bmask\n", "    def get_completion_mask(self, B, N, cdr_range):\n\t        cmask = torch.zeros(B, N).cuda()\n\t        for i, (l,r) in enumerate(cdr_range): \n\t            cmask[i, l:r+1] = 1\n\t        return cmask\n\t    def remove_cdr_coords(self, X, cdr_range):\n\t        X = X.clone()\n\t        for i, (l,r) in enumerate(cdr_range):\n\t            X[i, l:r+1, :, :] = 0\n\t        return X.clone()\n", "    def forward(self, antibody_X, antibody_S, antibody_cdr, padding_mask, c_init_prob, paratope_mask, init_X):\n\t        B, N = padding_mask.size(0), padding_mask.size(1)\n\t        cdr_range = [(cdr.index(self.cdr_type), cdr.rindex(self.cdr_type)) for cdr in antibody_cdr]\n\t        T_min = min([l for l,r in cdr_range])\n\t        T_max = max([r for l,r in cdr_range])\n\t        antibody_init_X = antibody_X.clone()\n\t        # print(init_X.shape) [8, 13, 14, 3]\n\t        # print(antibody_init_X.shape) [8, 221, 14, 3]\n\t        # print(padding_mask)\n\t        # print(padding_mask.shape)\n", "        # print(antibody_init_X[padding_mask>0].shape)\n\t        antibody_init_X[paratope_mask>0] = init_X\n\t        antibody_init_X = self.make_X_blocks(antibody_init_X, T_min, T_max, padding_mask)\n\t        # make blocks and encode framework\n\t        S = antibody_S.clone() * (1 - paratope_mask.long()) # type_id, 0 for cdr-3 [7, 130]\n\t        seq_emb = self.embedding(S)\n\t        seq_emb[paratope_mask>0] = self.embedding.soft_forward(c_init_prob)\n\t        hS = self.W_s(seq_emb)\n\t        hS, offset, suffix = self.make_S_blocks(hS, T_min, T_max, padding_mask)\n\t        paratope_mask = torch.cat([paratope_mask.new_zeros(B, offset), paratope_mask[:, T_min:T_max+1], paratope_mask.new_zeros(B, suffix)], dim=1) # [7, 12+14+3]\n", "        # Ground truth \n\t        antibody_X = self.make_X_blocks(antibody_X, T_min, T_max, padding_mask) # [7, 130, 4, 3] ==> [7, 29, 4, 3]\n\t        padding_mask = self.make_mask_blocks(padding_mask, T_min, T_max)\n\t        return hS, antibody_X, paratope_mask, antibody_init_X, padding_mask\n"]}
{"filename": "fairseq_models/modules/utils.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom collections import namedtuple\n\tReturnType = namedtuple('ReturnType',('xloss','nll','ppl','bind_X','handle'), defaults=(None, None, None, None, None))\n\tdef kabsch(A, B):\n\t    a_mean = A.mean(dim=1, keepdims=True)\n\t    b_mean = B.mean(dim=1, keepdims=True)\n\t    A_c = A - a_mean\n", "    B_c = B - b_mean\n\t    # Covariance matrix\n\t    H = torch.bmm(A_c.transpose(1,2), B_c)  # [B, 3, 3]\n\t    U, S, V = torch.svd(H)\n\t    # Rotation matrix\n\t    R = torch.bmm(V, U.transpose(1,2))  # [B, 3, 3]\n\t    # Translation vector\n\t    t = b_mean - torch.bmm(R, a_mean.transpose(1,2)).transpose(1,2)\n\t    A_aligned = torch.bmm(R, A.transpose(1,2)).transpose(1,2) + t\n\t    return A_aligned, R, t\n", "# X: [B, N, 4, 3], R: [B, 3, 3], t: [B, 3]\n\tdef rigid_transform(X, R, t):\n\t    B, N, L = X.size(0), X.size(1), X.size(2)\n\t    X = X.reshape(B, N * L, 3)\n\t    X = torch.bmm(R, X.transpose(1,2)).transpose(1,2) + t\n\t    return X.view(B, N, L, 3)\n\t# A: [B, N, 3], B: [B, N, 3], mask: [B, N]\n\tdef compute_rmsd(A, B, mask):\n\t    A_aligned, _, _ = kabsch(A, B)\n\t    rmsd = ((A_aligned - B) ** 2).sum(dim=-1)\n", "    rmsd = torch.sum(rmsd * mask, dim=-1) / (mask.sum(dim=-1) + 1e-6)\n\t    return rmsd.sqrt()\n\t# A: [B, N, 3], B: [B, N, 3], mask: [B, N]\n\tdef compute_rmsd_no_align(A, B, mask):\n\t    rmsd = ((A - B) ** 2).sum(dim=-1)\n\t    rmsd = torch.sum(rmsd * mask, dim=-1) / (mask.sum(dim=-1) + 1e-6)\n\t    return rmsd.sqrt()\n\tdef eig_coord(X, mask):\n\t    D, mask_2D = self_square_dist(X, torch.ones_like(mask))\n\t    return eig_coord_from_dist(D)\n", "def eig_coord_from_dist(D):\n\t    M = (D[:, :1, :] + D[:, :, :1] - D) / 2\n\t    L, V = torch.linalg.eigh(M)\n\t    L = torch.diag_embed(L)\n\t    X = torch.matmul(V, L.clamp(min=0).sqrt())\n\t    return X[:, :, -3:].detach()\n\tdef inner_square_dist(X, mask):\n\t    L = mask.size(2)\n\t    dX = X.unsqueeze(2) - X.unsqueeze(3)  # [B,N,1,L,3] - [B,N,L,1,3]\n\t    mask_2D = mask.unsqueeze(2) * mask.unsqueeze(3)\n", "    mask_2D = mask_2D * (1 - torch.eye(L)[None,None,:,:]).to(mask_2D)\n\t    D = torch.sum(dX**2, dim=-1)\n\t    return D * mask_2D, mask_2D\n\tdef self_square_dist(X, mask):\n\t    X = X[:, :, 1] \n\t    dX = X.unsqueeze(1) - X.unsqueeze(2)  # [B, 1, N, 3] - [B, N, 1, 3]\n\t    D = torch.sum(dX**2, dim=-1)\n\t    mask_2D = mask.unsqueeze(1) * mask.unsqueeze(2)  # [B, 1, N] x [B, N, 1]\n\t    mask_2D = mask_2D * (1 - torch.eye(mask.size(1))[None,:,:]).to(mask_2D)\n\t    return D, mask_2D\n", "def cross_square_dist(X, Y, xmask, ymask):\n\t    X, Y = X[:, :, 1], Y[:, :, 1]\n\t    dxy = X.unsqueeze(2) - Y.unsqueeze(1)  # [B, N, 1, 3] - [B, 1, M, 3]\n\t    D = torch.sum(dxy ** 2, dim=-1)\n\t    mask_2D = xmask.unsqueeze(2) * ymask.unsqueeze(1)  # [B, N, 1] x [B, 1, M]\n\t    return D, mask_2D\n\tdef full_square_dist(X, Y, XA, YA, contact=False, remove_diag=False):\n\t    B, N, M, L = X.size(0), X.size(1), Y.size(1), Y.size(2)\n\t    X = X.view(B, N * L, 3)\n\t    Y = Y.view(B, M * L, 3)\n", "    dxy = X.unsqueeze(2) - Y.unsqueeze(1)  # [B, NL, 1, 3] - [B, 1, ML, 3]\n\t    D = torch.sum(dxy ** 2, dim=-1)\n\t    D = D.view(B, N, L, M, L)\n\t    D = D.transpose(2, 3).reshape(B, N, M, L*L)\n\t    xmask = XA.clamp(max=1).float().view(B, N * L)\n\t    ymask = YA.clamp(max=1).float().view(B, M * L)\n\t    mask = xmask.unsqueeze(2) * ymask.unsqueeze(1)  # [B, NL, 1] x [B, 1, ML]\n\t    mask = mask.view(B, N, L, M, L)\n\t    mask = mask.transpose(2, 3).reshape(B, N, M, L*L)\n\t    if remove_diag:\n", "        mask = mask * (1 - torch.eye(N)[None,:,:,None]).to(mask)\n\t    if contact:\n\t        D = D + 1e6 * (1 - mask)\n\t        return D.amin(dim=-1), mask.amax(dim=-1)\n\t    else:\n\t        return D, mask\n\t\"\"\" Quaternion functions \"\"\"\n\tdef quaternion_to_matrix(quaternions):\n\t    r, i, j, k = torch.unbind(quaternions, -1)\n\t    two_s = 2.0 / (1e-4 + (quaternions * quaternions).sum(-1))\n", "    o = torch.stack(\n\t        (\n\t            1 - two_s * (j * j + k * k),\n\t            two_s * (i * j - k * r),\n\t            two_s * (i * k + j * r),\n\t            two_s * (i * j + k * r),\n\t            1 - two_s * (i * i + k * k),\n\t            two_s * (j * k - i * r),\n\t            two_s * (i * k - j * r),\n\t            two_s * (j * k + i * r),\n", "            1 - two_s * (i * i + j * j),\n\t        ),\n\t        -1,\n\t    )\n\t    return o.reshape(quaternions.shape[:-1] + (3, 3))\n\tdef matrix_to_quaternion(rot):\n\t    if(rot.shape[-2:] != (3, 3)):\n\t        raise ValueError(\"Input rotation is incorrectly shaped\")\n\t    rot = [[rot[..., i, j] for j in range(3)] for i in range(3)]\n\t    [[xx, xy, xz], [yx, yy, yz], [zx, zy, zz]] = rot \n", "    k = [\n\t        [ xx + yy + zz,      zy - yz,      xz - zx,      yx - xy,],\n\t        [      zy - yz, xx - yy - zz,      xy + yx,      xz + zx,],\n\t        [      xz - zx,      xy + yx, yy - xx - zz,      yz + zy,],\n\t        [      yx - xy,      xz + zx,      yz + zy, zz - xx - yy,]\n\t    ]\n\t    k = (1./3.) * torch.stack([torch.stack(t, dim=-1) for t in k], dim=-2)\n\t    _, vectors = torch.linalg.eigh(k)\n\t    return vectors[..., -1]\n\t\"\"\" Graph functions \"\"\"\n", "def autoregressive_mask(E_idx):\n\t    N_nodes = E_idx.size(1)\n\t    ii = torch.arange(N_nodes).cuda()\n\t    ii = ii.view((1, -1, 1))\n\t    mask = E_idx - ii < 0\n\t    return mask.float()\n\t# The following gather functions\n\tdef gather_edges(edges, neighbor_idx):\n\t    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n\t    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n", "    edge_features = torch.gather(edges, 2, neighbors)\n\t    return edge_features\n\tdef gather_nodes(nodes, neighbor_idx):\n\t    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n\t    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n\t    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n\t    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n\t    # Gather and re-pack\n\t    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n\t    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n", "    return neighbor_features\n\tdef cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n\t    h_nodes = gather_nodes(h_nodes, E_idx)\n\t    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n\t    return h_nn\n\tdef pairwise_distance(X, mask):\n\t    X_ca = X[:, :, 1, :]  # alpha carbon\n\t    mask_2D = mask.unsqueeze(1) * mask.unsqueeze(2)\n\t    dX = X_ca.unsqueeze(1) - X_ca.unsqueeze(2)\n\t    D = mask_2D * torch.sqrt(torch.sum(dX**2, dim=3))\n", "    return D, mask_2D\n"]}
{"filename": "fairseq_models/modules/nnutils.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom .protein_features import ProteinFeatures\n\tfrom .utils import *\n\tfrom fairseq_models.data.ab_dictionary import ALPHABET_FOR_INIT\n\tclass Normalize(nn.Module):\n\t    def __init__(self, features, epsilon=1e-6):\n\t        super(Normalize, self).__init__()\n", "        self.gain = nn.Parameter(torch.ones(features))\n\t        self.bias = nn.Parameter(torch.zeros(features))\n\t        self.epsilon = epsilon\n\t    def forward(self, x, dim=-1):\n\t        mu = x.mean(dim, keepdim=True)\n\t        sigma = torch.sqrt(x.var(dim, keepdim=True) + self.epsilon)\n\t        gain = self.gain\n\t        bias = self.bias\n\t        # Reshape\n\t        if dim != -1:\n", "            shape = [1] * len(mu.size())\n\t            shape[dim] = self.gain.size()[0]\n\t            gain = gain.view(shape)\n\t            bias = bias.view(shape)\n\t        return gain * (x - mu) / (sigma + self.epsilon) + bias\n\tclass MPNNLayer(nn.Module):\n\t    def __init__(self, num_hidden, num_in, dropout):\n\t        super(MPNNLayer, self).__init__()\n\t        self.num_hidden = num_hidden\n\t        self.num_in = num_in\n", "        self.dropout = nn.Dropout(dropout)\n\t        self.norm = nn.Identity() #Normalize(num_hidden)\n\t        self.W = nn.Sequential(\n\t                nn.Linear(num_hidden + num_in, num_hidden),\n\t                nn.ReLU(),\n\t                nn.Linear(num_hidden, num_hidden),\n\t                nn.ReLU(),\n\t                nn.Linear(num_hidden, num_hidden),\n\t        )\n\t    def forward(self, h_V, h_E, mask_attend):\n", "        # h_V: [B, N, H]; h_E: [B, N, K, H]\n\t        # mask_attend: [B, N, K]\n\t        h_V_expand = h_V.unsqueeze(-2).expand(-1, -1, h_E.size(-2), -1)\n\t        h_EV = torch.cat([h_V_expand, h_E], dim=-1)  # [B, N, K, H]\n\t        h_message = self.W(h_EV) * mask_attend.unsqueeze(-1)\n\t        dh = torch.mean(h_message, dim=-2)\n\t        h_V = self.norm(h_V + self.dropout(dh))\n\t        return h_V\n\tclass PosEmbedding(nn.Module):\n\t    def __init__(self, num_embeddings):\n", "        super(PosEmbedding, self).__init__()\n\t        self.num_embeddings = num_embeddings\n\t    # E_idx: [B, N]\n\t    def forward(self, E_idx):\n\t        frequency = torch.exp(\n\t            torch.arange(0, self.num_embeddings, 2, dtype=torch.float32)\n\t            * -(np.log(10000.0) / self.num_embeddings)\n\t        ).cuda()\n\t        angles = E_idx.unsqueeze(-1) * frequency.view((1,1,-1))\n\t        E = torch.cat((torch.cos(angles), torch.sin(angles)), -1)\n", "        return E\n\tclass AAEmbedding(nn.Module):\n\t    def __init__(self):\n\t        super(AAEmbedding, self).__init__()\n\t        self.hydropathy = {'#': 0, \"I\":4.5, \"V\":4.2, \"L\":3.8, \"F\":2.8, \"C\":2.5, \"M\":1.9, \"A\":1.8, \"W\":-0.9, \"G\":-0.4, \"T\":-0.7, \"S\":-0.8, \"Y\":-1.3, \"P\":-1.6, \"H\":-3.2, \"N\":-3.5, \"D\":-3.5, \"Q\":-3.5, \"E\":-3.5, \"K\":-3.9, \"R\":-4.5}\n\t        self.volume = {'#': 0, \"G\":60.1, \"A\":88.6, \"S\":89.0, \"C\":108.5, \"D\":111.1, \"P\":112.7, \"N\":114.1, \"T\":116.1, \"E\":138.4, \"V\":140.0, \"Q\":143.8, \"H\":153.2, \"M\":162.9, \"I\":166.7, \"L\":166.7, \"K\":168.6, \"R\":173.4, \"F\":189.9, \"Y\":193.6, \"W\":227.8}\n\t        self.charge = {**{'R':1, 'K':1, 'D':-1, 'E':-1, 'H':0.1}, **{x:0 for x in 'ABCFGIJLMNOPQSTUVWXYZ#'}}\n\t        self.polarity = {**{x:1 for x in 'RNDQEHKSTY'}, **{x:0 for x in \"ACGILMFPWV#\"}}\n\t        self.acceptor = {**{x:1 for x in 'DENQHSTY'}, **{x:0 for x in \"RKWACGILMFPV#\"}}\n\t        self.donor = {**{x:1 for x in 'RKWNQHSTY'}, **{x:0 for x in \"DEACGILMFPV#\"}}\n", "        alphabet = ALPHABET_FOR_INIT\n\t        self.embedding = torch.tensor([\n\t            [self.hydropathy[alphabet[i]], self.volume[alphabet[i]] / 100, self.charge[alphabet[i]],\n\t            self.polarity[alphabet[i]], self.acceptor[alphabet[i]], self.donor[alphabet[i]]]\n\t            for i in range(len(alphabet))\n\t        ]).cuda()\n\t    def to_rbf(self, D, D_min, D_max, stride):\n\t        D_count = int((D_max - D_min) / stride)\n\t        D_mu = torch.linspace(D_min, D_max, D_count).cuda()\n\t        D_mu = D_mu.view(1,1,-1)  # [1, 1, K]\n", "        D_expand = torch.unsqueeze(D, -1)  # [B, N, 1]\n\t        return torch.exp(-((D_expand - D_mu) / stride) ** 2)\n\t    def transform(self, aa_vecs):\n\t        return torch.cat([\n\t            self.to_rbf(aa_vecs[:, :, 0], -4.5, 4.5, 0.1),\n\t            self.to_rbf(aa_vecs[:, :, 1], 0, 2.2, 0.1),\n\t            self.to_rbf(aa_vecs[:, :, 2], -1.0, 1.0, 0.25),\n\t            torch.sigmoid(aa_vecs[:, :, 3:] * 6 - 3),\n\t        ], dim=-1)\n\t    def dim(self):\n", "        return 90 + 22 + 8 + 3\n\t    def forward(self, x, raw=False):\n\t        B, N = x.size(0), x.size(1)\n\t        aa_vecs = self.embedding[x.view(-1)].view(B, N, -1)\n\t        rbf_vecs = self.transform(aa_vecs)\n\t        return aa_vecs if raw else rbf_vecs\n\t    def to_rbf_(self, D, D_min, D_max, stride):\n\t        D_count = int((D_max - D_min) / stride)\n\t        D_mu = torch.linspace(D_min, D_max, D_count).cuda()\n\t        D_mu = D_mu.view(1,-1)  # [1, 1, K]\n", "        D_expand = torch.unsqueeze(D, -1)  # [B, N, 1]\n\t        return torch.exp(-((D_expand - D_mu) / stride) ** 2)  \n\t    def soft_forward(self, x):\n\t        aa_vecs = torch.matmul(x, self.embedding)\n\t        rbf_vecs = torch.cat([\n\t            self.to_rbf_(aa_vecs[:, 0], -4.5, 4.5, 0.1),\n\t            self.to_rbf_(aa_vecs[:, 1], 0, 2.2, 0.1),\n\t            self.to_rbf_(aa_vecs[:, 2], -1.0, 1.0, 0.25),\n\t            torch.sigmoid(aa_vecs[:, 3:] * 6 - 3),\n\t        ], dim=-1)\n", "        return rbf_vecs\n\tclass ABModel(nn.Module):\n\t    def __init__(self, args):\n\t        super(ABModel, self).__init__()\n\t        self.k_neighbors = args.k_neighbors\n\t        self.hidden_size = args.hidden_size\n\t        self.embedding = AAEmbedding()\n\t        self.features = ProteinFeatures(\n\t                top_k=args.k_neighbors, num_rbf=args.num_rbf,\n\t                features_type='full',\n", "                direction='bidirectional'\n\t        )\n\t        self.W_i = nn.Linear(args.hidden_size, args.hidden_size)\n\t        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n\t        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\t        self.mse_loss = nn.MSELoss(reduction='none')\n\t        self.huber_loss = nn.SmoothL1Loss(reduction='none')\n\t    def select_target(self, tgt_X, tgt_h, tgt_A, tgt_pos):\n\t        max_len = max([len(pos) for pos in tgt_pos])\n\t        xlist = [tgt_X[i, pos] for i,pos in enumerate(tgt_pos)]\n", "        hlist = [tgt_h[i, pos] for i,pos in enumerate(tgt_pos)]\n\t        alist = [tgt_A[i, pos] for i,pos in enumerate(tgt_pos)]\n\t        tgt_X = [F.pad(x, (0,0,0,0,0,max_len-len(x))) for x in xlist]\n\t        tgt_h = [F.pad(h, (0,0,0,max_len-len(h))) for h in hlist]\n\t        tgt_A = [F.pad(a, (0,0,0,max_len-len(a))) for a in alist]\n\t        return torch.stack(tgt_X, dim=0), torch.stack(tgt_h, dim=0), torch.stack(tgt_A, dim=0)\n"]}
{"filename": "fairseq_models/modules/ab_transformer_sentence_encoder.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\tfrom typing import Optional, Tuple\n\timport torch\n\timport torch.nn as nn\n\tfrom fairseq.modules import (\n\t    FairseqDropout,\n\t    LayerDropModuleList,\n", "    LayerNorm,\n\t    MultiheadAttention,\n\t    PositionalEmbedding,\n\t)\n\tfrom fairseq.modules.quant_noise import quant_noise as apply_quant_noise_\n\tfrom fairseq.data import Dictionary\n\tfrom .ab_transformer_sentence_encoder_layer import TransformerSentenceEncoderLayer\n\tdef init_bert_params(module):\n\t    \"\"\"\n\t    Initialize the weights specific to the BERT Model.\n", "    This overrides the default initializations depending on the specified arguments.\n\t        1. If normal_init_linear_weights is set then weights of linear\n\t           layer will be initialized using the normal distribution and\n\t           bais will be set to the specified value.\n\t        2. If normal_init_embed_weights is set then weights of embedding\n\t           layer will be initialized using the normal distribution.\n\t        3. If normal_init_proj_weights is set then weights of\n\t           in_project_weight for MultiHeadAttention initialized using\n\t           the normal distribution (to be validated).\n\t    \"\"\"\n", "    if isinstance(module, nn.Linear):\n\t        module.weight.data.normal_(mean=0.0, std=0.02)\n\t        if module.bias is not None:\n\t            module.bias.data.zero_()\n\t    if isinstance(module, nn.Embedding):\n\t        module.weight.data.normal_(mean=0.0, std=0.02)\n\t        if module.padding_idx is not None:\n\t            module.weight.data[module.padding_idx].zero_()\n\t    if isinstance(module, MultiheadAttention):\n\t        module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n", "        module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n\t        module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n\tclass AntibodyTransformerSentenceEncoder(nn.Module):\n\t    \"\"\"\n\t    Implementation for a Bi-directional Transformer based Sentence Encoder used\n\t    in BERT/XLM style pre-trained models.\n\t    This first computes the token embedding using the token embedding matrix,\n\t    position embeddings (if specified) and segment embeddings\n\t    (if specified). After applying the specified number of\n\t    TransformerEncoderLayers, it outputs all the internal states of the\n", "    encoder as well as the final representation associated with the first\n\t    token (usually CLS token).\n\t    Input:\n\t        - tokens: B x T matrix representing sentences\n\t        - segment_labels: B x T matrix representing segment label for tokens\n\t    Output:\n\t        - a tuple of the following:\n\t            - a list of internal model states used to compute the\n\t              predictions where each tensor has shape T x B x C\n\t            - sentence representation associated with first input token\n", "              in format B x C.\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        padding_idx: int,\n\t        vocab_size: int,\n\t        num_encoder_layers: int = 6,\n\t        embedding_dim: int = 768,\n\t        ffn_embedding_dim: int = 3072,\n\t        num_attention_heads: int = 8,\n", "        dropout: float = 0.1,\n\t        attention_dropout: float = 0.1,\n\t        activation_dropout: float = 0.1,\n\t        layerdrop: float = 0.0,\n\t        max_seq_len: int = 256,\n\t        segments_vocab: Dictionary = None,\n\t        use_position_embeddings: bool = True,\n\t        offset_positions_by_padding: bool = True,\n\t        encoder_normalize_before: bool = False,\n\t        apply_bert_init: bool = False,\n", "        activation_fn: str = \"relu\",\n\t        learned_pos_embedding: bool = True,\n\t        embed_scale: float = None,\n\t        freeze_embeddings: bool = False,\n\t        n_trans_layers_to_freeze: int = 0,\n\t        export: bool = False,\n\t        traceable: bool = False,\n\t        q_noise: float = 0.0,\n\t        qn_block_size: int = 8,\n\t    ) -> None:\n", "        super().__init__()\n\t        self.padding_idx = padding_idx\n\t        self.vocab_size = vocab_size\n\t        self.dropout_module = FairseqDropout(\n\t            dropout, module_name=self.__class__.__name__\n\t        )\n\t        self.layerdrop = layerdrop\n\t        self.max_seq_len = max_seq_len\n\t        self.embedding_dim = embedding_dim\n\t        self.num_segments = len(segments_vocab)\n", "        self.use_position_embeddings = use_position_embeddings\n\t        self.apply_bert_init = apply_bert_init\n\t        self.learned_pos_embedding = learned_pos_embedding\n\t        self.traceable = traceable\n\t        self.tpu = False  # whether we're on TPU\n\t        self.embed_tokens = self.build_embedding(\n\t            self.vocab_size, self.embedding_dim, self.padding_idx\n\t        )\n\t        self.embed_scale = embed_scale\n\t        if q_noise > 0:\n", "            self.quant_noise = apply_quant_noise_(\n\t                nn.Linear(self.embedding_dim, self.embedding_dim, bias=False),\n\t                q_noise,\n\t                qn_block_size,\n\t            )\n\t        else:\n\t            self.quant_noise = None\n\t        self.segment_embeddings = (\n\t            nn.Embedding(self.num_segments, self.embedding_dim, padding_idx=segments_vocab.pad())\n\t            if self.num_segments > 0\n", "            else None\n\t        )\n\t        self.embed_positions = (\n\t            PositionalEmbedding(\n\t                self.max_seq_len,\n\t                self.embedding_dim,\n\t                padding_idx=(self.padding_idx if offset_positions_by_padding else None),\n\t                learned=self.learned_pos_embedding,\n\t            )\n\t            if self.use_position_embeddings\n", "            else None\n\t        )\n\t        if self.layerdrop > 0.0:\n\t            self.layers = LayerDropModuleList(p=self.layerdrop)\n\t        else:\n\t            self.layers = nn.ModuleList([])\n\t        self.layers.extend(\n\t            [\n\t                self.build_transformer_sentence_encoder_layer(\n\t                    embedding_dim=self.embedding_dim,\n", "                    ffn_embedding_dim=ffn_embedding_dim,\n\t                    num_attention_heads=num_attention_heads,\n\t                    dropout=self.dropout_module.p,\n\t                    attention_dropout=attention_dropout,\n\t                    activation_dropout=activation_dropout,\n\t                    activation_fn=activation_fn,\n\t                    export=export,\n\t                    q_noise=q_noise,\n\t                    qn_block_size=qn_block_size,\n\t                )\n", "                for _ in range(num_encoder_layers)\n\t            ]\n\t        )\n\t        if encoder_normalize_before:\n\t            self.emb_layer_norm = LayerNorm(self.embedding_dim, export=export)\n\t        else:\n\t            self.emb_layer_norm = None\n\t        # Apply initialization of model params after building the model\n\t        if self.apply_bert_init:\n\t            self.apply(init_bert_params)\n", "        def freeze_module_params(m):\n\t            if m is not None:\n\t                for p in m.parameters():\n\t                    p.requires_grad = False\n\t        if freeze_embeddings:\n\t            freeze_module_params(self.embed_tokens)\n\t            freeze_module_params(self.segment_embeddings)\n\t            freeze_module_params(self.embed_positions)\n\t            freeze_module_params(self.emb_layer_norm)\n\t        for layer in range(n_trans_layers_to_freeze):\n", "            freeze_module_params(self.layers[layer])\n\t    def build_embedding(self, vocab_size, embedding_dim, padding_idx):\n\t        return nn.Embedding(vocab_size, embedding_dim, padding_idx)\n\t    def build_transformer_sentence_encoder_layer(\n\t        self,\n\t        embedding_dim,\n\t        ffn_embedding_dim,\n\t        num_attention_heads,\n\t        dropout,\n\t        attention_dropout,\n", "        activation_dropout,\n\t        activation_fn,\n\t        export,\n\t        q_noise,\n\t        qn_block_size,\n\t    ):\n\t        return TransformerSentenceEncoderLayer(\n\t            embedding_dim=embedding_dim,\n\t            ffn_embedding_dim=ffn_embedding_dim,\n\t            num_attention_heads=num_attention_heads,\n", "            dropout=dropout,\n\t            attention_dropout=attention_dropout,\n\t            activation_dropout=activation_dropout,\n\t            activation_fn=activation_fn,\n\t            export=export,\n\t            q_noise=q_noise,\n\t            qn_block_size=qn_block_size,\n\t        )\n\t    def prepare_for_tpu_(self, **kwargs):\n\t        self.tpu = True\n", "    def forward(\n\t        self,\n\t        tokens: torch.Tensor,\n\t        segment_labels: torch.Tensor = None,\n\t        last_state_only: bool = False,\n\t        positions: Optional[torch.Tensor] = None,\n\t        token_embeddings: Optional[torch.Tensor] = None,\n\t        past_key_values=None,\n\t    ) -> Tuple[torch.Tensor, torch.Tensor]:\n\t        # compute padding mask. This is needed for multi-head attention\n", "        padding_mask = tokens.eq(self.padding_idx)\n\t        if not self.traceable and not self.tpu and not padding_mask.any():\n\t            padding_mask = None\n\t        if token_embeddings is not None:\n\t            x = token_embeddings\n\t        else:\n\t            x = self.embed_tokens(tokens)\n\t        if self.embed_scale is not None:\n\t            x = x * self.embed_scale\n\t        if self.embed_positions is not None:\n", "            x = x + self.embed_positions(tokens, positions=positions)\n\t        if self.segment_embeddings is not None and segment_labels is not None:\n\t            x = x + self.segment_embeddings(segment_labels)\n\t        if self.quant_noise is not None:\n\t            x = self.quant_noise(x)\n\t        if self.emb_layer_norm is not None:\n\t            x = self.emb_layer_norm(x)\n\t        x = self.dropout_module(x)\n\t        # account for padding while computing the representation\n\t        if padding_mask is not None:\n", "            x = x * (1 - padding_mask.unsqueeze(-1).type_as(x))\n\t        # if past_key_values is not None:\n\t        #     prefix_attention_mask = torch.zeros(padding_mask.shape[0], 1).to(padding_mask.device)\n\t        #     padding_mask = torch.cat((prefix_attention_mask, padding_mask), dim=1)\n\t        # B x T x C -> T x B x C\n\t        x = x.transpose(0, 1)\n\t        inner_states = []\n\t        if not last_state_only:\n\t            inner_states.append(x)\n\t        for i, layer in enumerate(self.layers):\n", "            past_key_value = past_key_values[i] if past_key_values is not None else None\n\t            x, _ = layer(x, past_key_value=past_key_value)\n\t            if not last_state_only:\n\t                inner_states.append(x)\n\t        sentence_rep = x[0, :, :]\n\t        if last_state_only:\n\t            inner_states = [x]\n\t        if self.traceable:\n\t            return torch.stack(inner_states), sentence_rep\n\t        else:\n", "            return inner_states, sentence_rep\n"]}
{"filename": "fairseq_models/modules/ab_multihead_attention.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\timport math\n\tfrom typing import Dict, Optional, Tuple\n\timport torch\n\timport torch.nn.functional as F\n\tfrom fairseq import utils\n\tfrom fairseq.incremental_decoding_utils import with_incremental_state\n", "from fairseq.modules.fairseq_dropout import FairseqDropout\n\tfrom fairseq.modules.quant_noise import quant_noise\n\tfrom torch import Tensor, nn\n\tfrom torch.nn import Parameter\n\t@with_incremental_state\n\tclass MultiheadAttention(nn.Module):\n\t    \"\"\"Multi-headed attention.\n\t    See \"Attention Is All You Need\" for more details.\n\t    \"\"\"\n\t    def __init__(\n", "        self,\n\t        embed_dim,\n\t        num_heads,\n\t        kdim=None,\n\t        vdim=None,\n\t        dropout=0.0,\n\t        bias=True,\n\t        add_bias_kv=False,\n\t        add_zero_attn=False,\n\t        self_attention=False,\n", "        encoder_decoder_attention=False,\n\t        q_noise=0.0,\n\t        qn_block_size=8,\n\t    ):\n\t        super().__init__()\n\t        self.embed_dim = embed_dim\n\t        self.kdim = kdim if kdim is not None else embed_dim\n\t        self.vdim = vdim if vdim is not None else embed_dim\n\t        self.qkv_same_dim = self.kdim == embed_dim and self.vdim == embed_dim\n\t        self.num_heads = num_heads\n", "        self.dropout_module = FairseqDropout(\n\t            dropout, module_name=self.__class__.__name__\n\t        )\n\t        self.head_dim = embed_dim // num_heads\n\t        assert (\n\t            self.head_dim * num_heads == self.embed_dim\n\t        ), \"embed_dim must be divisible by num_heads\"\n\t        self.scaling = self.head_dim ** -0.5\n\t        self.self_attention = self_attention\n\t        self.encoder_decoder_attention = encoder_decoder_attention\n", "        assert not self.self_attention or self.qkv_same_dim, (\n\t            \"Self-attention requires query, key and \" \"value to be of the same size\"\n\t        )\n\t        self.k_proj = quant_noise(\n\t            nn.Linear(self.kdim, embed_dim, bias=bias), q_noise, qn_block_size\n\t        )\n\t        self.v_proj = quant_noise(\n\t            nn.Linear(self.vdim, embed_dim, bias=bias), q_noise, qn_block_size\n\t        )\n\t        self.q_proj = quant_noise(\n", "            nn.Linear(embed_dim, embed_dim, bias=bias), q_noise, qn_block_size\n\t        )\n\t        self.out_proj = quant_noise(\n\t            nn.Linear(embed_dim, embed_dim, bias=bias), q_noise, qn_block_size\n\t        )\n\t        if add_bias_kv:\n\t            self.bias_k = Parameter(torch.Tensor(1, 1, embed_dim))\n\t            self.bias_v = Parameter(torch.Tensor(1, 1, embed_dim))\n\t        else:\n\t            self.bias_k = self.bias_v = None\n", "        self.add_zero_attn = add_zero_attn\n\t        self.reset_parameters()\n\t        self.onnx_trace = False\n\t        self.tpu = False\n\t    def prepare_for_onnx_export_(self):\n\t        self.onnx_trace = True\n\t    def prepare_for_tpu_(self, **kwargs):\n\t        self.tpu = True\n\t    def reset_parameters(self):\n\t        if self.qkv_same_dim:\n", "            # Empirically observed the convergence to be much better with\n\t            # the scaled initialization\n\t            nn.init.xavier_uniform_(self.k_proj.weight, gain=1 / math.sqrt(2))\n\t            nn.init.xavier_uniform_(self.v_proj.weight, gain=1 / math.sqrt(2))\n\t            nn.init.xavier_uniform_(self.q_proj.weight, gain=1 / math.sqrt(2))\n\t        else:\n\t            nn.init.xavier_uniform_(self.k_proj.weight)\n\t            nn.init.xavier_uniform_(self.v_proj.weight)\n\t            nn.init.xavier_uniform_(self.q_proj.weight)\n\t        nn.init.xavier_uniform_(self.out_proj.weight)\n", "        if self.out_proj.bias is not None:\n\t            nn.init.constant_(self.out_proj.bias, 0.0)\n\t        if self.bias_k is not None:\n\t            nn.init.xavier_normal_(self.bias_k)\n\t        if self.bias_v is not None:\n\t            nn.init.xavier_normal_(self.bias_v)\n\t    def forward(\n\t        self,\n\t        query,\n\t        key: Optional[Tensor],\n", "        value: Optional[Tensor],\n\t        key_padding_mask: Optional[Tensor] = None,\n\t        incremental_state: Optional[Dict[str, Dict[str, Optional[Tensor]]]] = None,\n\t        need_weights: bool = True,\n\t        static_kv: bool = False,\n\t        attn_mask: Optional[Tensor] = None,\n\t        before_softmax: bool = False,\n\t        need_head_weights: bool = False,\n\t        past_key_value: Optional[tuple] = None,\n\t    ) -> Tuple[Tensor, Optional[Tensor]]:\n", "        \"\"\"Input shape: Time x Batch x Channel\n\t        Args:\n\t            key_padding_mask (ByteTensor, optional): mask to exclude\n\t                keys that are pads, of shape `(batch, src_len)`, where\n\t                padding elements are indicated by 1s.\n\t            need_weights (bool, optional): return the attention weights,\n\t                averaged over heads (default: False).\n\t            attn_mask (ByteTensor, optional): typically used to\n\t                implement causal attention, where the mask prevents the\n\t                attention from looking forward in time (default: None).\n", "            before_softmax (bool, optional): return the raw attention\n\t                weights and values before the attention softmax.\n\t            need_head_weights (bool, optional): return the attention\n\t                weights for each head. Implies *need_weights*. Default:\n\t                return the average attention weights over all heads.\n\t        \"\"\"\n\t        if need_head_weights:\n\t            need_weights = True\n\t        tgt_len, bsz, embed_dim = query.size()\n\t        # print(query.shape)\n", "        # print(attn_mask)\n\t        assert embed_dim == self.embed_dim\n\t        assert list(query.size()) == [tgt_len, bsz, embed_dim]\n\t        if (\n\t            not self.onnx_trace\n\t            and not self.tpu  # don't use PyTorch version on TPUs\n\t            and incremental_state is None\n\t            and not static_kv\n\t            # A workaround for quantization to work. Otherwise JIT compilation\n\t            # treats bias in linear module as method.\n", "            and not torch.jit.is_scripting()\n\t            and past_key_value is None\n\t        ):\n\t            assert key is not None and value is not None\n\t            return F.multi_head_attention_forward(\n\t                query,\n\t                key,\n\t                value,\n\t                self.embed_dim,\n\t                self.num_heads,\n", "                torch.empty([0]),\n\t                torch.cat((self.q_proj.bias, self.k_proj.bias, self.v_proj.bias)),\n\t                self.bias_k,\n\t                self.bias_v,\n\t                self.add_zero_attn,\n\t                self.dropout_module.p,\n\t                self.out_proj.weight,\n\t                self.out_proj.bias,\n\t                self.training or self.dropout_module.apply_during_inference,\n\t                key_padding_mask,\n", "                need_weights,\n\t                attn_mask,\n\t                use_separate_proj_weight=True,\n\t                q_proj_weight=self.q_proj.weight,\n\t                k_proj_weight=self.k_proj.weight,\n\t                v_proj_weight=self.v_proj.weight,\n\t            )\n\t        if incremental_state is not None:\n\t            saved_state = self._get_input_buffer(incremental_state)\n\t            if saved_state is not None and \"prev_key\" in saved_state:\n", "                # previous time steps are cached - no need to recompute\n\t                # key and value if they are static\n\t                if static_kv:\n\t                    assert self.encoder_decoder_attention and not self.self_attention\n\t                    key = value = None\n\t        else:\n\t            saved_state = None\n\t        if self.self_attention:\n\t            q = self.q_proj(query)\n\t            k = self.k_proj(query)\n", "            v = self.v_proj(query)\n\t        elif self.encoder_decoder_attention:\n\t            # encoder-decoder attention\n\t            q = self.q_proj(query)\n\t            if key is None:\n\t                assert value is None\n\t                k = v = None\n\t            else:\n\t                k = self.k_proj(key)\n\t                v = self.v_proj(key)\n", "        else:\n\t            assert key is not None and value is not None\n\t            q = self.q_proj(query)\n\t            k = self.k_proj(key)\n\t            v = self.v_proj(value)\n\t        q *= self.scaling\n\t        if self.bias_k is not None:\n\t            assert self.bias_v is not None\n\t            k = torch.cat([k, self.bias_k.repeat(1, bsz, 1)])\n\t            v = torch.cat([v, self.bias_v.repeat(1, bsz, 1)])\n", "            if attn_mask is not None:\n\t                attn_mask = torch.cat(\n\t                    [attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)], dim=1\n\t                )\n\t            if key_padding_mask is not None:\n\t                key_padding_mask = torch.cat(\n\t                    [\n\t                        key_padding_mask,\n\t                        key_padding_mask.new_zeros(key_padding_mask.size(0), 1),\n\t                    ],\n", "                    dim=1,\n\t                )\n\t        q = (\n\t            q.contiguous()\n\t            .view(tgt_len, bsz * self.num_heads, self.head_dim)\n\t            .transpose(0, 1)\n\t        )\n\t        if k is not None:\n\t            k = (\n\t                k.contiguous()\n", "                .view(-1, bsz * self.num_heads, self.head_dim)\n\t                .transpose(0, 1)\n\t            )\n\t        if v is not None:\n\t            v = (\n\t                v.contiguous()\n\t                .view(-1, bsz * self.num_heads, self.head_dim)\n\t                .transpose(0, 1)\n\t            )\n\t        if past_key_value is not None:\n", "            # print(q.shape)\n\t            # print(past_key_value[0].contiguous().view(bsz * self.num_heads, -1, self.head_dim).shape)\n\t            # print(past_key_value[0].shape) # torch.Size([8, 12, 1, 64])\n\t            # # print(past_key_value[1].shape)\n\t            # print(k.shape) # 96, 232, 64\n\t            # # print(v.shape)\n\t            # # (key, value) n_layer x batch_size x n_head x pre_seq_len x n_embd\n\t            k = torch.cat([past_key_value[0].contiguous().view(bsz * self.num_heads, -1, self.head_dim), k], dim=1)\n\t            v = torch.cat([past_key_value[1].contiguous().view(bsz * self.num_heads, -1, self.head_dim), v], dim=1)\n\t        if saved_state is not None:\n", "            # saved states are stored with shape (bsz, num_heads, seq_len, head_dim)\n\t            if \"prev_key\" in saved_state:\n\t                _prev_key = saved_state[\"prev_key\"]\n\t                assert _prev_key is not None\n\t                prev_key = _prev_key.view(bsz * self.num_heads, -1, self.head_dim)\n\t                if static_kv:\n\t                    k = prev_key\n\t                else:\n\t                    assert k is not None\n\t                    k = torch.cat([prev_key, k], dim=1)\n", "            if \"prev_value\" in saved_state:\n\t                _prev_value = saved_state[\"prev_value\"]\n\t                assert _prev_value is not None\n\t                prev_value = _prev_value.view(bsz * self.num_heads, -1, self.head_dim)\n\t                if static_kv:\n\t                    v = prev_value\n\t                else:\n\t                    assert v is not None\n\t                    v = torch.cat([prev_value, v], dim=1)\n\t            prev_key_padding_mask: Optional[Tensor] = None\n", "            if \"prev_key_padding_mask\" in saved_state:\n\t                prev_key_padding_mask = saved_state[\"prev_key_padding_mask\"]\n\t            assert k is not None and v is not None\n\t            key_padding_mask = MultiheadAttention._append_prev_key_padding_mask(\n\t                key_padding_mask=key_padding_mask,\n\t                prev_key_padding_mask=prev_key_padding_mask,\n\t                batch_size=bsz,\n\t                src_len=k.size(1),\n\t                static_kv=static_kv,\n\t            )\n", "            saved_state[\"prev_key\"] = k.view(bsz, self.num_heads, -1, self.head_dim)\n\t            saved_state[\"prev_value\"] = v.view(bsz, self.num_heads, -1, self.head_dim)\n\t            saved_state[\"prev_key_padding_mask\"] = key_padding_mask\n\t            # In this branch incremental_state is never None\n\t            assert incremental_state is not None\n\t            incremental_state = self._set_input_buffer(incremental_state, saved_state)\n\t        assert k is not None\n\t        src_len = k.size(1)\n\t        # This is part of a workaround to get around fork/join parallelism\n\t        # not supporting Optional types.\n", "        if key_padding_mask is not None and key_padding_mask.dim() == 0:\n\t            key_padding_mask = None\n\t        if key_padding_mask is not None:\n\t            assert key_padding_mask.size(0) == bsz\n\t            assert key_padding_mask.size(1) == src_len\n\t        if self.add_zero_attn:\n\t            assert v is not None\n\t            src_len += 1\n\t            k = torch.cat([k, k.new_zeros((k.size(0), 1) + k.size()[2:])], dim=1)\n\t            v = torch.cat([v, v.new_zeros((v.size(0), 1) + v.size()[2:])], dim=1)\n", "            if attn_mask is not None:\n\t                attn_mask = torch.cat(\n\t                    [attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)], dim=1\n\t                )\n\t            if key_padding_mask is not None:\n\t                key_padding_mask = torch.cat(\n\t                    [\n\t                        key_padding_mask,\n\t                        torch.zeros(key_padding_mask.size(0), 1).type_as(\n\t                            key_padding_mask\n", "                        ),\n\t                    ],\n\t                    dim=1,\n\t                )\n\t        attn_weights = torch.bmm(q, k.transpose(1, 2))\n\t        attn_weights = self.apply_sparse_mask(attn_weights, tgt_len, src_len, bsz)\n\t        assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n\t        if attn_mask is not None:\n\t            attn_mask = attn_mask.unsqueeze(0)\n\t            if self.onnx_trace:\n", "                attn_mask = attn_mask.repeat(attn_weights.size(0), 1, 1)\n\t            attn_weights += attn_mask\n\t        if key_padding_mask is not None:\n\t            # don't attend to padding symbols\n\t            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n\t            if not self.tpu:\n\t                attn_weights = attn_weights.masked_fill(\n\t                    key_padding_mask.unsqueeze(1).unsqueeze(2).to(torch.bool),\n\t                    float(\"-inf\"),\n\t                )\n", "            else:\n\t                attn_weights = attn_weights.transpose(0, 2)\n\t                attn_weights = attn_weights.masked_fill(key_padding_mask, float(\"-inf\"))\n\t                attn_weights = attn_weights.transpose(0, 2)\n\t            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n\t        if before_softmax:\n\t            return attn_weights, v\n\t        attn_weights_float = utils.softmax(\n\t            attn_weights, dim=-1, onnx_trace=self.onnx_trace\n\t        )\n", "        attn_weights = attn_weights_float.type_as(attn_weights)\n\t        attn_probs = self.dropout_module(attn_weights)\n\t        assert v is not None\n\t        attn = torch.bmm(attn_probs, v)\n\t        assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n\t        if self.onnx_trace and attn.size(1) == 1:\n\t            # when ONNX tracing a single decoder step (sequence length == 1)\n\t            # the transpose is a no-op copy before view, thus unnecessary\n\t            attn = attn.contiguous().view(tgt_len, bsz, embed_dim)\n\t        else:\n", "            attn = attn.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n\t        attn = self.out_proj(attn)\n\t        attn_weights: Optional[Tensor] = None\n\t        if need_weights:\n\t            attn_weights = attn_weights_float.view(\n\t                bsz, self.num_heads, tgt_len, src_len\n\t            ).transpose(1, 0)\n\t            if not need_head_weights:\n\t                # average attention weights over heads\n\t                attn_weights = attn_weights.mean(dim=0)\n", "        return attn, attn_weights\n\t    @staticmethod\n\t    def _append_prev_key_padding_mask(\n\t        key_padding_mask: Optional[Tensor],\n\t        prev_key_padding_mask: Optional[Tensor],\n\t        batch_size: int,\n\t        src_len: int,\n\t        static_kv: bool,\n\t    ) -> Optional[Tensor]:\n\t        # saved key padding masks have shape (bsz, seq_len)\n", "        if prev_key_padding_mask is not None and static_kv:\n\t            new_key_padding_mask = prev_key_padding_mask\n\t        elif prev_key_padding_mask is not None and key_padding_mask is not None:\n\t            new_key_padding_mask = torch.cat(\n\t                [prev_key_padding_mask.float(), key_padding_mask.float()], dim=1\n\t            )\n\t        # During incremental decoding, as the padding token enters and\n\t        # leaves the frame, there will be a time when prev or current\n\t        # is None\n\t        elif prev_key_padding_mask is not None:\n", "            filler = torch.zeros(\n\t                (batch_size, src_len - prev_key_padding_mask.size(1)),\n\t                device=prev_key_padding_mask.device,\n\t            )\n\t            new_key_padding_mask = torch.cat(\n\t                [prev_key_padding_mask.float(), filler.float()], dim=1\n\t            )\n\t        elif key_padding_mask is not None:\n\t            filler = torch.zeros(\n\t                (batch_size, src_len - key_padding_mask.size(1)),\n", "                device=key_padding_mask.device,\n\t            )\n\t            new_key_padding_mask = torch.cat(\n\t                [filler.float(), key_padding_mask.float()], dim=1\n\t            )\n\t        else:\n\t            new_key_padding_mask = prev_key_padding_mask\n\t        return new_key_padding_mask\n\t    @torch.jit.export\n\t    def reorder_incremental_state(\n", "        self,\n\t        incremental_state: Dict[str, Dict[str, Optional[Tensor]]],\n\t        new_order: Tensor,\n\t    ):\n\t        \"\"\"Reorder buffered internal state (for incremental generation).\"\"\"\n\t        input_buffer = self._get_input_buffer(incremental_state)\n\t        if input_buffer is not None:\n\t            for k in input_buffer.keys():\n\t                input_buffer_k = input_buffer[k]\n\t                if input_buffer_k is not None:\n", "                    if self.encoder_decoder_attention and input_buffer_k.size(\n\t                        0\n\t                    ) == new_order.size(0):\n\t                        break\n\t                    input_buffer[k] = input_buffer_k.index_select(0, new_order)\n\t            incremental_state = self._set_input_buffer(incremental_state, input_buffer)\n\t        return incremental_state\n\t    def _get_input_buffer(\n\t        self, incremental_state: Optional[Dict[str, Dict[str, Optional[Tensor]]]]\n\t    ) -> Dict[str, Optional[Tensor]]:\n", "        result = self.get_incremental_state(incremental_state, \"attn_state\")\n\t        if result is not None:\n\t            return result\n\t        else:\n\t            empty_result: Dict[str, Optional[Tensor]] = {}\n\t            return empty_result\n\t    def _set_input_buffer(\n\t        self,\n\t        incremental_state: Dict[str, Dict[str, Optional[Tensor]]],\n\t        buffer: Dict[str, Optional[Tensor]],\n", "    ):\n\t        return self.set_incremental_state(incremental_state, \"attn_state\", buffer)\n\t    def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):\n\t        return attn_weights\n\t    def upgrade_state_dict_named(self, state_dict, name):\n\t        prefix = name + \".\" if name != \"\" else \"\"\n\t        items_to_add = {}\n\t        keys_to_remove = []\n\t        for k in state_dict.keys():\n\t            if k.endswith(prefix + \"in_proj_weight\"):\n", "                # in_proj_weight used to be q + k + v with same dimensions\n\t                dim = int(state_dict[k].shape[0] / 3)\n\t                items_to_add[prefix + \"q_proj.weight\"] = state_dict[k][:dim]\n\t                items_to_add[prefix + \"k_proj.weight\"] = state_dict[k][dim : 2 * dim]\n\t                items_to_add[prefix + \"v_proj.weight\"] = state_dict[k][2 * dim :]\n\t                keys_to_remove.append(k)\n\t                k_bias = prefix + \"in_proj_bias\"\n\t                if k_bias in state_dict.keys():\n\t                    dim = int(state_dict[k].shape[0] / 3)\n\t                    items_to_add[prefix + \"q_proj.bias\"] = state_dict[k_bias][:dim]\n", "                    items_to_add[prefix + \"k_proj.bias\"] = state_dict[k_bias][\n\t                        dim : 2 * dim\n\t                    ]\n\t                    items_to_add[prefix + \"v_proj.bias\"] = state_dict[k_bias][2 * dim :]\n\t                    keys_to_remove.append(prefix + \"in_proj_bias\")\n\t        for k in keys_to_remove:\n\t            del state_dict[k]\n\t        for key, value in items_to_add.items():\n\t            state_dict[key] = value\n"]}
{"filename": "fairseq_models/modules/ab_transformer_sentence_encoder_layer.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\tfrom typing import Callable, Optional\n\timport torch\n\timport torch.nn as nn\n\tfrom fairseq import utils\n\tfrom fairseq.modules import LayerNorm\n\tfrom fairseq.modules.fairseq_dropout import FairseqDropout\n", "from fairseq.modules.quant_noise import quant_noise\n\tfrom .ab_multihead_attention import MultiheadAttention\n\tclass TransformerSentenceEncoderLayer(nn.Module):\n\t    \"\"\"\n\t    Implements a Transformer Encoder Layer used in BERT/XLM style pre-trained\n\t    models.\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        embedding_dim: int = 768,\n", "        ffn_embedding_dim: int = 3072,\n\t        num_attention_heads: int = 8,\n\t        dropout: float = 0.1,\n\t        attention_dropout: float = 0.1,\n\t        activation_dropout: float = 0.1,\n\t        activation_fn: str = \"relu\",\n\t        export: bool = False,\n\t        q_noise: float = 0.0,\n\t        qn_block_size: int = 8,\n\t        init_fn: Callable = None,\n", "    ) -> None:\n\t        super().__init__()\n\t        if init_fn is not None:\n\t            init_fn()\n\t        # Initialize parameters\n\t        self.embedding_dim = embedding_dim\n\t        self.num_attention_heads = num_attention_heads\n\t        self.attention_dropout = attention_dropout\n\t        self.q_noise = q_noise\n\t        self.qn_block_size = qn_block_size\n", "        self.dropout_module = FairseqDropout(\n\t            dropout, module_name=self.__class__.__name__\n\t        )\n\t        self.activation_dropout_module = FairseqDropout(\n\t            activation_dropout, module_name=self.__class__.__name__\n\t        )\n\t        # Initialize blocks\n\t        self.activation_fn = utils.get_activation_fn(activation_fn)\n\t        self.self_attn = self.build_self_attention(\n\t            self.embedding_dim,\n", "            num_attention_heads,\n\t            dropout=attention_dropout,\n\t            self_attention=True,\n\t            q_noise=q_noise,\n\t            qn_block_size=qn_block_size,\n\t        )\n\t        # layer norm associated with the self attention layer\n\t        self.self_attn_layer_norm = LayerNorm(self.embedding_dim, export=export)\n\t        self.fc1 = self.build_fc1(\n\t            self.embedding_dim,\n", "            ffn_embedding_dim,\n\t            q_noise=q_noise,\n\t            qn_block_size=qn_block_size,\n\t        )\n\t        self.fc2 = self.build_fc2(\n\t            ffn_embedding_dim,\n\t            self.embedding_dim,\n\t            q_noise=q_noise,\n\t            qn_block_size=qn_block_size,\n\t        )\n", "        # layer norm associated with the position wise feed-forward NN\n\t        self.final_layer_norm = LayerNorm(self.embedding_dim, export=export)\n\t    def build_fc1(self, input_dim, output_dim, q_noise, qn_block_size):\n\t        return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)\n\t    def build_fc2(self, input_dim, output_dim, q_noise, qn_block_size):\n\t        return quant_noise(nn.Linear(input_dim, output_dim), q_noise, qn_block_size)\n\t    def build_self_attention(\n\t        self,\n\t        embed_dim,\n\t        num_attention_heads,\n", "        dropout,\n\t        self_attention,\n\t        q_noise,\n\t        qn_block_size,\n\t    ):\n\t        return MultiheadAttention(\n\t            embed_dim,\n\t            num_attention_heads,\n\t            dropout=dropout,\n\t            self_attention=True,\n", "            q_noise=q_noise,\n\t            qn_block_size=qn_block_size,\n\t        )\n\t    def forward(\n\t        self,\n\t        x: torch.Tensor,\n\t        self_attn_mask: Optional[torch.Tensor] = None,\n\t        self_attn_padding_mask: Optional[torch.Tensor] = None,\n\t        past_key_value=None,\n\t    ):\n", "        \"\"\"\n\t        LayerNorm is applied either before or after the self-attention/ffn\n\t        modules similar to the original Transformer implementation.\n\t        \"\"\"\n\t        residual = x\n\t        x, attn = self.self_attn(\n\t            query=x,\n\t            key=x,\n\t            value=x,\n\t            key_padding_mask=self_attn_padding_mask,\n", "            need_weights=False,\n\t            attn_mask=self_attn_mask,\n\t            past_key_value=past_key_value\n\t        )\n\t        x = self.dropout_module(x)\n\t        x = residual + x\n\t        x = self.self_attn_layer_norm(x)\n\t        residual = x\n\t        x = self.activation_fn(self.fc1(x))\n\t        # print(self.fc1.weight)\n", "        # exit(0)\n\t        x = self.activation_dropout_module(x)\n\t        x = self.fc2(x)\n\t        x = self.dropout_module(x)\n\t        x = residual + x\n\t        x = self.final_layer_norm(x)\n\t        return x, attn\n"]}
{"filename": "fairseq_models/modules/hmpn_encoder.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\timport copy\n\tfrom .utils import *\n\tfrom .nnutils import *\n\tfrom .protein_features import ProteinFeatures\n\tclass EGNNEncoder(nn.Module):\n\t    def __init__(self, args, node_hdim=0, features_type='backbone', update_X=True):\n", "        super(EGNNEncoder, self).__init__()\n\t        self.update_X = update_X\n\t        self.features_type = features_type\n\t        self.features = ProteinFeatures(\n\t                top_k=args.k_neighbors, num_rbf=args.num_rbf,\n\t                features_type=features_type,\n\t                direction='bidirectional'\n\t        )\n\t        self.node_in, self.edge_in = self.features.feature_dimensions[features_type]\n\t        self.node_in += node_hdim\n", "        self.W_v = nn.Linear(self.node_in, args.hidden_size)\n\t        self.W_e = nn.Linear(self.edge_in, args.hidden_size)\n\t        self.layers = nn.ModuleList([\n\t                MPNNLayer(args.hidden_size, args.hidden_size * 3, dropout=args.dropout)\n\t                for _ in range(args.depth)\n\t        ])\n\t        if self.update_X:\n\t            self.W_x = nn.Linear(args.hidden_size, args.hidden_size)\n\t            self.U_x = nn.Linear(args.hidden_size, args.hidden_size)\n\t            self.T_x = nn.Sequential(nn.ReLU(), nn.Linear(args.hidden_size, 14))\n", "        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    # [backbone] X: [B,N,L,3], V/S: [B,N,H], A: [B,N,L]\n\t    # [atom] X: [B,N*L,3], V/S: [B,N*L,H], A: [B,N*L]\n\t    def forward(self, X, V, S, A):\n\t        mask = A.clamp(max=1).float() # if position in A has value => Set to 1 = True\n\t        vmask = mask[:,:,1] if self.features_type == 'backbone' else mask\n\t        _, E, E_idx = self.features(X, vmask)\n\t        # E = torch.ones(X.shape[0], X.shape[1], 9, self.features.feature_dimensions[self.features_type][1]).to(X.device)\n", "        # E_idx = torch.ones(X.shape[0], X.shape[1], 9).to(X.device).type(torch.int64)\n\t        h = self.W_v(V)    # [B, N, H] \n\t        h_e = self.W_e(E)  # [B, N, K, H] \n\t        nei_s = gather_nodes(S, E_idx)  # [B, N, K, H]\n\t        emask = gather_nodes(vmask[...,None], E_idx).squeeze(-1)\n\t        # message passing\n\t        for layer in self.layers:\n\t            nei_v = gather_nodes(h, E_idx)  # [B, N, K, H]\n\t            nei_h = torch.cat([nei_v, nei_s, h_e], dim=-1) # [B, N, K, H*3]\n\t            h = layer(h, nei_h, mask_attend=emask)  # [B, N, H]\n", "            h = h * vmask.unsqueeze(-1)  # [B, N, H]\n\t        if self.update_X and self.features_type == 'backbone':\n\t            ca_mask = mask[:,:,1]  # [B, N]\n\t            mij = self.W_x(h).unsqueeze(2) + self.U_x(h).unsqueeze(1)  # [B,N,N,H]\n\t            xij = X.unsqueeze(2) - X.unsqueeze(1)  # [B,N,N,L,3]\n\t            xij = xij * self.T_x(mij).unsqueeze(-1)  # [B,N,N,L,3]\n\t            f = torch.sum(xij * ca_mask[:,None,:,None,None], dim=2)  # [B,N,N,L,3] * [B,1,N,1,1]\n\t            f = f / (1e-6 + ca_mask.sum(dim=1)[:,None,None,None])    # [B,N,L,3] / [B,1,1,1]\n\t            X = X + f.clamp(min=-20.0, max=20.0)\n\t        return h, X * mask[...,None]\n", "class HierEGNNEncoder(nn.Module):\n\t    def __init__(self, args, update_X=True, backbone_CA_only=True):\n\t        super(HierEGNNEncoder, self).__init__()\n\t        self.args = args\n\t        self.update_X = update_X\n\t        self.backbone_CA_only = backbone_CA_only\n\t        self.clash_step = args.clash_step\n\t        self.residue_mpn = EGNNEncoder(\n\t                args, features_type='backbone',\n\t                node_hdim=args.hidden_size,\n", "                update_X=False,\n\t        )\n\t        self.atom_mpn = EGNNEncoder(\n\t                args, features_type='atom',\n\t                node_hdim=args.hidden_size,\n\t                update_X=False,\n\t        )\n\t        if self.update_X:\n\t            # backbone coord update\n\t            self.W_x = nn.Linear(args.hidden_size, args.hidden_size)\n", "            self.U_x = nn.Linear(args.hidden_size, args.hidden_size)\n\t            self.T_x = nn.Sequential(nn.ReLU(), nn.Linear(args.hidden_size, 4))\n\t            # side chain coord update\n\t            self.W_a = nn.Linear(args.hidden_size, args.hidden_size)\n\t            self.U_a = nn.Linear(args.hidden_size, args.hidden_size)\n\t            self.T_a = nn.Sequential(nn.ReLU(), nn.Linear(args.hidden_size, 1))\n\t        self.embedding = nn.Embedding(38, args.hidden_size) # 38: len(ATOM_TYPES)\n\t        self.W_fusion = nn.Sequential(\n\t            nn.Linear(args.hidden_size + args.encoder_embed_dim, args.hidden_size),\n\t            nn.ReLU(),\n", "            nn.Linear(args.hidden_size, args.hidden_size)\n\t        )\n\t        # self.node_in = 6\n\t        # self.node_in += args.hidden_size\n\t        # self.LLiner = nn.Linear(self.node_in, args.hidden_size)\n\t        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    # X: [B,N,L,3], V: [B,N,6], S: [B,N,H], A: [B,N,L]\n\t    def forward(self, X, V, S, A, antibody_N=0, paratope_mask=None, pretrained_embedding=None):\n", "        B, N, L = X.size()[:3]\n\t        X_atom = X.view(B, N*L, 3)\n\t        mask = A.clamp(max=1).float()\n\t        # atom message passing\n\t        h_atom = self.embedding(A).view(B, N*L, -1)\n\t        h_atom, _ = self.atom_mpn(X_atom, h_atom, h_atom, A.view(B,-1))\n\t        h_atom = h_atom.view(B,N,L,-1)\n\t        h_atom = h_atom * mask[...,None]\n\t        h_A = h_atom.sum(dim=-2) / (1e-6 + mask.sum(dim=-1)[...,None])\n\t        # residue message passing\n", "        h_V = torch.cat([V, h_A], dim=-1)\n\t        # h_res = self.LLiner(h_V)\n\t        h_res, _ = self.residue_mpn(X, h_V, S, A)\n\t        # pretrained embedding fusion\n\t        if antibody_N > 0:\n\t            new_item = h_res[:, :antibody_N].clone()\n\t            new_item[paratope_mask] = self.W_fusion(\n\t                torch.cat((h_res[:, :antibody_N][paratope_mask], pretrained_embedding), dim=1)\n\t            )\n\t            h_res[:, :antibody_N] = new_item\n", "        if self.update_X:\n\t            # backbone update\n\t            bb_mask = mask[:,:,:4]  # [B, N, 4]\n\t            X_bb = X[:,:,:4]  # backbone atoms\n\t            mij = self.W_x(h_res).unsqueeze(2) + self.U_x(h_res).unsqueeze(1)  # [B,N,N,H]\n\t            xij = X_bb.unsqueeze(2) - X_bb.unsqueeze(1)  # [B,N,N,4,3]\n\t            dij = xij.norm(dim=-1)  # [B,N,N,4]\n\t            fij = torch.maximum(self.T_x(mij), 3.8 - dij)  # break term [B,N,N,4]\n\t            xij = xij * fij.unsqueeze(-1)\n\t            f_res = torch.sum(xij * bb_mask[:,None,:,:,None], dim=2)  # [B,N,N,4,3] * [B,1,N,4,1] -> [B,N,4,3]\n", "            f_res = f_res / (1e-6 + bb_mask.sum(dim=1, keepdims=True)[...,None])  # [B,N,4,3]\n\t            X_bb = X_bb + f_res.clamp(min=-20.0, max=20.0)\n\t            # Clash correction\n\t            for _ in range(self.clash_step):\n\t                xij = X_bb.unsqueeze(2) - X_bb.unsqueeze(1)  # [B,N,N,4,3]\n\t                dij = xij.norm(dim=-1)  # [B,N,N,4]\n\t                fij = F.relu(3.8 - dij)  # repulsion term [B,N,N,4]\n\t                xij = xij * fij.unsqueeze(-1)\n\t                f_res = torch.sum(xij * bb_mask[:,None,:,:,None], dim=2)  # [B,N,N,4,3] * [B,1,N,4,1] -> [B,N,4,3]\n\t                f_res = f_res / (1e-6 + bb_mask.sum(dim=1, keepdims=True)[...,None])  # [B,N,4,3]\n", "                X_bb = X_bb + f_res.clamp(min=-20.0, max=20.0)\n\t            # side chain update\n\t            mij = self.W_a(h_atom).unsqueeze(3) + self.U_a(h_atom).unsqueeze(2)  # [B,N,L,1,H] + [B,N,1,L,H]\n\t            xij = X.unsqueeze(3) - X.unsqueeze(2)  # [B,N,L,1,3] - [B,N,1,L,3]\n\t            dij = xij.norm(dim=-1)  # [B,N,L,L]\n\t            fij = torch.maximum(self.T_a(mij).squeeze(-1), 1.5 - dij)  # break term [B,N,L,L]\n\t            xij = xij * fij.unsqueeze(-1)  # [B,N,L,L,3]\n\t            f_atom = torch.sum(xij * mask[:,:,None,:,None], dim=3)  # [B,N,L,L,3] * [B,N,1,L,1] -> [B,N,L,3]\n\t            X_sc = X + 0.1 * f_atom\n\t            if self.backbone_CA_only:\n", "                X = torch.cat((X_sc[:,:,:1], X_bb[:,:,1:2], X_sc[:,:,2:]), dim=2)\n\t            else:\n\t                X = torch.cat((X_bb[:,:,:4], X_sc[:,:,4:]), dim=2)\n\t        return h_res, X * mask[...,None]\n"]}
{"filename": "fairseq_models/tasks/abbert_mlm_task.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\timport logging\n\timport os\n\timport numpy as np\n\tfrom fairseq import utils\n\tfrom fairseq.data import (\n\t    Dictionary,\n", "    IdDataset,\n\t    NestedDictionaryDataset,\n\t    NumelDataset,\n\t    NumSamplesDataset,\n\t    PrependTokenDataset,\n\t    RightPadDataset,\n\t    SortDataset,\n\t    TokenBlockDataset,\n\t    data_utils,\n\t)\n", "from fairseq.data.shorten_dataset import maybe_shorten_dataset\n\tfrom fairseq.tasks import LegacyFairseqTask, register_task\n\tfrom fairseq_models.tasks.abbert_mask_tokens_dataset import AntibodyMaskTokensDataset\n\tlogger = logging.getLogger(__name__)\n\t@register_task(\"antibody_masked_lm\")\n\tclass AntibodyMaskedLMTask(LegacyFairseqTask):\n\t    \"\"\"Task for training masked language models (e.g., BERT, RoBERTa).\"\"\"\n\t    @staticmethod\n\t    def add_args(parser):\n\t        \"\"\"Add task-specific arguments to the parser.\"\"\"\n", "        # data: seq data-bin\n\t        parser.add_argument(\n\t            \"data\",\n\t            help=\"colon separated path to data directories list, \\\n\t                            will be iterated upon during epochs in round-robin manner\",\n\t        )\n\t        parser.add_argument(\n\t            \"--tag-data\", \n\t            help='name of the tag data'\n\t        )\n", "        parser.add_argument(\n\t            \"--sample-break-mode\",\n\t            default=\"complete\",\n\t            choices=[\"none\", \"complete\", \"complete_doc\", \"eos\"],\n\t            help='If omitted or \"none\", fills each sample with tokens-per-sample '\n\t            'tokens. If set to \"complete\", splits samples only at the end '\n\t            \"of sentence, but may include multiple sentences per sample. \"\n\t            '\"complete_doc\" is similar but respects doc boundaries. '\n\t            'If set to \"eos\", includes only one sentence per sample.',\n\t        )\n", "        parser.add_argument(\n\t            \"--tokens-per-sample\",\n\t            default=512,\n\t            type=int,\n\t            help=\"max number of total tokens over all segments \"\n\t            \"per sample for BERT dataset\",\n\t        )\n\t        parser.add_argument(\n\t            \"--mask-prob\",\n\t            default=0.15,\n", "            type=float,\n\t            help=\"probability of replacing a token with mask\",\n\t        )\n\t        parser.add_argument(\n\t            \"--leave-unmasked-prob\",\n\t            default=0.1,\n\t            type=float,\n\t            help=\"probability that a masked token is unmasked\",\n\t        )\n\t        parser.add_argument(\n", "            \"--random-token-prob\",\n\t            default=0.1,\n\t            type=float,\n\t            help=\"probability of replacing a token with a random token\",\n\t        )\n\t        parser.add_argument(\n\t            \"--freq-weighted-replacement\",\n\t            default=False,\n\t            action=\"store_true\",\n\t            help=\"sample random replacement words based on word frequencies\",\n", "        )\n\t        # parser.add_argument(\n\t        #     \"--mask-aa-pieces\",\n\t        #     default=False,\n\t        #     action=\"store_true\",\n\t        #     help=\"mask whole A.A. pieces\",\n\t        # )\n\t        parser.add_argument(\n\t            \"--mask-multiple-length\",\n\t            default=1,\n", "            type=int,\n\t            help=\"repeat the mask indices multiple times\",\n\t        )\n\t        parser.add_argument(\n\t            \"--mask-stdev\", default=0.0, type=float, help=\"stdev of the mask length\"\n\t        )\n\t        parser.add_argument(\n\t            \"--shorten-method\",\n\t            default=\"none\",\n\t            choices=[\"none\", \"truncate\", \"random_crop\"],\n", "            help=\"if not none, shorten sequences that exceed --tokens-per-sample\",\n\t        )\n\t        parser.add_argument(\n\t            \"--shorten-data-split-list\",\n\t            default=\"\",\n\t            help=\"comma-separated list of dataset splits to apply shortening to, \"\n\t            'e.g., \"train,valid\" (default: all dataset splits)',\n\t        )\n\t        # parser.add_argument(\n\t        #     \"--sentencepiece-model-path\",\n", "        #     type=str,\n\t        #     default=None,\n\t        #     help=\"path to the used sentencepiece tokenizer\",\n\t        # )\n\t    def __init__(self, args, seq_dict, tag_dict):\n\t        super().__init__(args)\n\t        self.seq_dict = seq_dict\n\t        self.tag_dict = tag_dict\n\t        self.seed = args.seed\n\t        # add mask token\n", "        self.mask_idx = seq_dict.add_symbol(\"<mask>\")\n\t        # self.mask_idx = tag_dict.add_symbol('<mask>')\n\t    @classmethod\n\t    def setup_task(cls, args, **kwargs):\n\t        seq_dict = Dictionary.load(os.path.join(args.data, 'dict.txt'))\n\t        tag_dict = Dictionary.load(os.path.join(args.tag_data, 'dict.txt'))\n\t        logger.info(\"[input] dictionary: {} types\".format(len(seq_dict)))\n\t        logger.info(\"[input] dictionary: {} types\".format(len(tag_dict)))\n\t        # AAPieceFromUniprot21.set_model_path(args.sentencepiece_model_path)\n\t        return cls(args, seq_dict, tag_dict)\n", "    def load_dataset(self, split, epoch=1, combine=False, **kwargs):\n\t        \"\"\"Load a given dataset split.\n\t        Args:\n\t            split (str): name of the split (e.g., train, valid, test)\n\t        \"\"\"\n\t        def curate_dataset(dataset_path, dictionary):\n\t            paths = utils.split_paths(dataset_path)\n\t            assert len(paths) > 0\n\t            data_path = paths[(epoch - 1) % len(paths)]\n\t            split_path = os.path.join(data_path, split)\n", "            dataset = data_utils.load_indexed_dataset(\n\t                split_path,\n\t                dictionary,\n\t                self.args.dataset_impl,\n\t                combine=combine,\n\t            )\n\t            if dataset is None:\n\t                raise FileNotFoundError(\n\t                    \"Dataset not found: {} ({})\".format(split, split_path)\n\t                )\n", "            dataset = maybe_shorten_dataset(\n\t                dataset,\n\t                split,\n\t                self.args.shorten_data_split_list,\n\t                self.args.shorten_method,\n\t                self.args.tokens_per_sample,\n\t                self.args.seed,\n\t            )\n\t            # create continuous blocks of tokens\n\t            dataset = TokenBlockDataset(\n", "                dataset,\n\t                dataset.sizes,\n\t                self.args.tokens_per_sample - 1,  # one less for <s>\n\t                pad=dictionary.pad(),\n\t                eos=dictionary.eos(),\n\t                break_mode=self.args.sample_break_mode,\n\t            )\n\t            logger.info(\"loaded {} blocks from: {}\".format(len(dataset), split_path))\n\t            # prepend beginning-of-sentence token (<s>, equiv. to [CLS] in BERT)\n\t            dataset = PrependTokenDataset(dataset, dictionary.bos())\n", "            return dataset\n\t        seq_dataset = curate_dataset(self.args.data, self.source_dictionary)\n\t        tag_dataset = curate_dataset(self.args.tag_data, self.tag_source_dictionary)\n\t        # print(max([len(seq_dataset[i]) for i in range(900)]))\n\t        # print(tag_dataset[5])\n\t        # exit(0)\n\t        # aa_piece_dataset=AAPieceDataset(dataset,enabled=self.args.mask_aa_pieces)\n\t        # homology_dataset=HomologyDataset(dataset,enabled=self.args.contrastive_learning,negative_sample=(self.args.criterion=='masked_lm_with_msa'))\n\t        # create masked input and targets\n\t        src_dataset, tgt_dataset = AntibodyMaskTokensDataset.apply_mask(\n", "            seq_dataset,\n\t            tag_dataset,\n\t            self.source_dictionary,\n\t            self.tag_source_dictionary,\n\t            pad_idx=self.source_dictionary.pad(),\n\t            mask_idx=self.mask_idx,\n\t            seed=self.args.seed,\n\t            mask_prob=self.args.mask_prob,\n\t            leave_unmasked_prob=self.args.leave_unmasked_prob,\n\t            random_token_prob=self.args.random_token_prob,\n", "            # random_token_prob=0,     ###   self.args.random_token_prob,   不随机替换token, for BPE training\n\t            freq_weighted_replacement=self.args.freq_weighted_replacement,\n\t            # mask_aa_pieces=self.args.mask_aa_pieces,\n\t            # aa_piece_dataset=aa_piece_dataset,\n\t            mask_multiple_length=self.args.mask_multiple_length,\n\t            mask_stdev=self.args.mask_stdev,\n\t        )\n\t        with data_utils.numpy_seed(self.args.seed):\n\t            shuffle = np.random.permutation(len(src_dataset))\n\t        self.datasets[split] = SortDataset(\n", "            NestedDictionaryDataset(\n\t                {\n\t                    \"id\": IdDataset(),\n\t                    \"net_input0\": {\n\t                        \"src_tokens\": RightPadDataset(\n\t                            src_dataset,\n\t                            pad_idx=self.source_dictionary.pad(),\n\t                        ),\n\t                        \"src_lengths\": NumelDataset(src_dataset, reduce=False),\n\t                    },\n", "                    \"net_input1\": {\n\t                        \"src_tokens\": RightPadDataset(\n\t                            tag_dataset,\n\t                            pad_idx=self.tag_source_dictionary.pad(),\n\t                        ),\n\t                        \"src_lengths\": NumelDataset(src_dataset, reduce=False),\n\t                    },\n\t                    \"target\": RightPadDataset(\n\t                        tgt_dataset,\n\t                        pad_idx=self.source_dictionary.pad(),\n", "                    ),\n\t                    \"nsentences\": NumSamplesDataset(),\n\t                    \"ntokens\": NumelDataset(src_dataset, reduce=True),\n\t                },\n\t                sizes=[src_dataset.sizes],\n\t            ),\n\t            sort_order=[\n\t                shuffle,\n\t                src_dataset.sizes,\n\t            ],\n", "        )\n\t    def build_dataset_for_inference(self, src_tokens, src_lengths, sort=True):\n\t        src_dataset=TokenBlockDataset(\n\t                src_tokens,\n\t                src_lengths,\n\t                self.args.tokens_per_sample - 1,  # one less for <s>\n\t                pad=self.source_dictionary.pad(),\n\t                eos=self.source_dictionary.eos(),\n\t                break_mode=\"eos\",\n\t            )\n", "        src_dataset = PrependTokenDataset(src_dataset, self.source_dictionary.bos())\n\t        # aa_piece_dataset = AAPieceDataset(src_dataset,enabled=self.args.mask_aa_pieces)\n\t        src_dataset = RightPadDataset(\n\t            src_dataset,\n\t            pad_idx=self.source_dictionary.pad(),\n\t        )\n\t        src_dataset = NestedDictionaryDataset(\n\t            {\n\t                \"id\": IdDataset(),\n\t                \"net_input\": {\n", "                    \"src_tokens\": src_dataset,\n\t                    \"src_lengths\": NumelDataset(src_dataset, reduce=False),\n\t                    # \"aa_piece_handlers\": aa_piece_dataset,\n\t                },\n\t            },\n\t            sizes=src_lengths,\n\t        )\n\t        if sort:\n\t            src_dataset = SortDataset(src_dataset, sort_order=[src_lengths])\n\t        return src_dataset\n", "    @property\n\t    def source_dictionary(self):\n\t        return self.seq_dict\n\t    @property\n\t    def tag_source_dictionary(self):\n\t        return self.tag_dict\n\t    @property\n\t    def target_dictionary(self):\n\t        return self.seq_dict\n"]}
{"filename": "fairseq_models/tasks/abgen_task.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\timport argparse\n\timport logging\n\timport os\n\timport fairseq\n\timport numpy as np\n\timport torch\n", "import warnings\n\tfrom fairseq import utils\n\tfrom fairseq.data import (\n\t    data_utils,\n\t    Dictionary,\n\t    SortDataset,\n\t)\n\tfrom fairseq.tasks import LegacyFairseqTask, register_task\n\tfrom fairseq_models.data.abgen_dataset import AntibodyComplexDataset\n\tfrom fairseq_models.data.abgen_dataset_noantigen import AntibodyOnlyDataset\n", "logger = logging.getLogger(__name__)\n\t@register_task('antibody_generation_task')\n\tclass AntibodyGenerationTask(LegacyFairseqTask):\n\t    \"\"\"\n\t    Notice: till now, one of the MLM/PSSM Pred. is must needed for build & load the dataset\n\t    Sentence (or sentence pair) prediction (classification or regression) task.\n\t    Args:\n\t        dictionary (Dictionary): the dictionary for the input of the task\n\t    \"\"\"\n\t    @staticmethod\n", "    def add_args(parser):\n\t        \"\"\"Add task-specific arguments to the parser.\"\"\"\n\t        parser.add_argument('--sabdab-data', help=\"sabdab data path\")\n\t        parser.add_argument(\n\t            '--cdr-type', \n\t            default='3', \n\t            choices=['1', '2', '3'],\n\t            help=\"which part to predict\"\n\t        )\n\t        parser.add_argument(\n", "            '--L-target', \n\t            default=20,\n\t            type=int,\n\t            help=\"number of antigen residues to be considered as epitope\"\n\t        )\n\t        parser.add_argument('--noantigen', action='store_true', default=False)\n\t    def __init__(self, args, seq_dict, tag_dict):\n\t        super().__init__(args)\n\t        self.args = args\n\t        self.seq_dict = seq_dict\n", "        self.tag_dict = tag_dict\n\t        self.seed = args.seed\n\t        self.mask_idx = seq_dict.add_symbol(\"<mask>\")\n\t    @classmethod\n\t    def setup_task(cls, args, **kwargs):\n\t        seq_dict = Dictionary.load(os.path.join('data', 'seq_dict.txt'))\n\t        tag_dict = Dictionary.load(os.path.join('data', 'tag_dict.txt'))\n\t        logger.info(\"[input] dictionary: {} types\".format(len(seq_dict)))\n\t        logger.info(\"[input] dictionary: {} types\".format(len(tag_dict)))\n\t        return cls(args, seq_dict, tag_dict)  # Done: needs refine to TAPE's tokenizer\n", "    def load_dataset(self, split, epoch=1, combine=False, **kwargs):\n\t        \"\"\"Load a given dataset split.\n\t        Args:\n\t            split (str): name of the split (e.g., train, valid, test)\n\t        \"\"\"\n\t        ### downstream tasks\n\t        if self.args.noantigen:\n\t            dataset = AntibodyOnlyDataset(\n\t                data_path=self.args.sabdab_data,\n\t                split=split,\n", "                seq_vocab=self.source_dictionary,\n\t                tag_vocab=self.tag_source_dictionary,\n\t                cdr_types=[*self.args.cdr_type],\n\t                L_target=self.args.L_target,\n\t                pad_idx=self.source_dictionary.pad(),\n\t                mask_idx=self.mask_idx,\n\t                max_len=self.args.max_positions\n\t            )\n\t        else:\n\t            dataset = AntibodyComplexDataset(\n", "                data_path=self.args.sabdab_data,\n\t                split=split,\n\t                seq_vocab=self.source_dictionary,\n\t                tag_vocab=self.tag_source_dictionary,\n\t                cdr_types=[*self.args.cdr_type],\n\t                L_target=self.args.L_target,\n\t                pad_idx=self.source_dictionary.pad(),\n\t                mask_idx=self.mask_idx,\n\t                max_len=self.args.max_positions\n\t            )\n", "        with data_utils.numpy_seed(self.args.seed + epoch):\n\t            shuffle = np.random.permutation(len(dataset))\n\t        self.datasets[split] = SortDataset(dataset, sort_order=[shuffle, dataset.prefix_len, dataset.sizes])\n\t        return None  # return in advance\n\t    def build_model(self, args):\n\t        model = super().build_model(args)\n\t        def inplace_relu(m):\n\t            classname = m.__class__.__name__\n\t            if classname.find('ReLU') != -1:\n\t                m.inplace=True\n", "        model.apply(inplace_relu)\n\t        return model\n\t    @property\n\t    def source_dictionary(self):\n\t        return self.seq_dict\n\t    @property\n\t    def tag_source_dictionary(self):\n\t        return self.tag_dict\n\t    @property\n\t    def target_dictionary(self):\n", "        return self.seq_dict"]}
{"filename": "fairseq_models/tasks/abbert_mask_tokens_dataset.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\tfrom functools import lru_cache\n\timport numpy as np\n\timport torch\n\tfrom fairseq.data import Dictionary, data_utils\n\tfrom fairseq.data import BaseWrapperDataset, LRUCacheDataset\n\t# from fairseq_models.aa_piece_dataset import AAPieceDataset\n", "class AntibodyMaskTokensDataset(BaseWrapperDataset):\n\t    \"\"\"\n\t    A wrapper Dataset for masked language modeling.\n\t    Input items are masked according to the specified masking probability.\n\t    Args:\n\t        dataset: Dataset to wrap.\n\t        sizes: Sentence lengths\n\t        vocab: Dictionary with the vocabulary and special tokens.\n\t        pad_idx: Id of pad token in vocab\n\t        mask_idx: Id of mask token in vocab\n", "        return_masked_tokens: controls whether to return the non-masked tokens\n\t            (the default) or to return a tensor with the original masked token\n\t            IDs (and *pad_idx* elsewhere). The latter is useful as targets for\n\t            masked LM training.\n\t        seed: Seed for random number generator for reproducibility.\n\t        mask_prob: probability of replacing a token with *mask_idx*.\n\t        leave_unmasked_prob: probability that a masked token is unmasked.\n\t        random_token_prob: probability of replacing a masked token with a\n\t            random token from the vocabulary.\n\t        freq_weighted_replacement: sample random replacement words based on\n", "            word frequencies in the vocab.\n\t        mask_whole_words: only mask whole words. This should be a byte mask\n\t            over vocab indices, indicating whether it is the beginning of a\n\t            word. We will extend any mask to encompass the whole word.\n\t        bpe: BPE to use for whole-word masking.\n\t        mask_multiple_length : repeat each mask index multiple times. Default\n\t            value is 1.\n\t        mask_stdev : standard deviation of masks distribution in case of\n\t            multiple masking. Default value is 0.\n\t    \"\"\"\n", "    @classmethod\n\t    def apply_mask(cls, dataset1: torch.utils.data.Dataset, dataset2: torch.utils.data.Dataset, *args, **kwargs):\n\t        \"\"\"Return the source and target datasets for masked LM training.\"\"\"\n\t        dataset1 = LRUCacheDataset(dataset1)\n\t        dataset2 = LRUCacheDataset(dataset2)\n\t        return (\n\t            LRUCacheDataset(cls(dataset1, dataset2, *args, **kwargs, return_masked_tokens=False)),\n\t            LRUCacheDataset(cls(dataset1, dataset2, *args, **kwargs, return_masked_tokens=True)),\n\t        )\n\t    def __init__(\n", "        self,\n\t        dataset: torch.utils.data.Dataset,\n\t        tag_dataset: torch.utils.data.Dataset,\n\t        seq_vocab: Dictionary,\n\t        tag_vocab: Dictionary,\n\t        pad_idx: int,\n\t        mask_idx: int,\n\t        return_masked_tokens: bool = False,\n\t        seed: int = 1,\n\t        mask_prob: float = 0.15,\n", "        leave_unmasked_prob: float = 0.1,\n\t        random_token_prob: float = 0.1,\n\t        freq_weighted_replacement: bool = False,\n\t        # mask_aa_pieces:bool=False,\n\t        # aa_piece_dataset:AAPieceDataset=None,\n\t        mask_multiple_length: int = 1,\n\t        mask_stdev: float = 0.0,\n\t    ):\n\t        assert 0.0 < mask_prob <= 1.0\n\t        assert 0.0 <= random_token_prob <= 1.0\n", "        assert 0.0 <= leave_unmasked_prob <= 1.0\n\t        assert random_token_prob + leave_unmasked_prob <= 1.0\n\t        assert mask_multiple_length >= 1\n\t        assert mask_stdev >= 0.0\n\t        self.dataset = dataset\n\t        self.tag_dataset = tag_dataset\n\t        self.seq_vocab = seq_vocab\n\t        self.tag_vocab = tag_vocab\n\t        self.pad_idx = pad_idx\n\t        self.mask_idx = mask_idx\n", "        self.return_masked_tokens = return_masked_tokens\n\t        self.seed = seed\n\t        self.mask_prob = mask_prob\n\t        self.leave_unmasked_prob = leave_unmasked_prob\n\t        self.random_token_prob = random_token_prob\n\t        # self.mask_aa_pieces=mask_aa_pieces\n\t        # self.aa_piece_dataset=aa_piece_dataset\n\t        self.mask_multiple_length = mask_multiple_length\n\t        self.mask_stdev = mask_stdev\n\t        if random_token_prob > 0.0:\n", "            if freq_weighted_replacement:\n\t                weights = np.array(self.seq_vocab.count)\n\t            else:\n\t                weights = np.ones(len(self.seq_vocab))\n\t            weights[: self.seq_vocab.nspecial] = 0\n\t            self.weights = weights / weights.sum()\n\t        # if mask_aa_pieces:\n\t        #     # self.aa_pieces=AAPieceFromUniprot21()\n\t        #     self.aa_piece_dataset=aa_piece_dataset\n\t        self.epoch = 0\n", "    @property\n\t    def can_reuse_epoch_itr_across_epochs(self):\n\t        return True  # only the noise changes, not item sizes\n\t    def set_epoch(self, epoch, **unused):\n\t        super().set_epoch(epoch)\n\t        self.epoch = epoch\n\t    def __getitem__(self, index: int):\n\t        return self.__getitem_cached__(self.seed, self.epoch, index)\n\t    @lru_cache(maxsize=8)\n\t    def __getitem_cached__(self, seed: int, epoch: int, index: int):\n", "        with data_utils.numpy_seed(self.seed, self.epoch, index):\n\t            item = self.dataset[index]\n\t            tag = self.tag_dataset[index]\n\t            cdr1_idx = self.tag_vocab.index('1')\n\t            cdr2_idx = self.tag_vocab.index('2')\n\t            cdr3_idx = self.tag_vocab.index('3')\n\t            cdr_mask = torch.logical_or(\n\t                torch.logical_or(tag==cdr1_idx, tag==cdr2_idx),\n\t                tag==cdr3_idx\n\t            )\n", "            sz = cdr_mask.sum()\n\t            assert (\n\t                self.mask_idx not in item\n\t            ), \"Dataset contains mask_idx (={}), this is not expected!\".format(\n\t                self.mask_idx,\n\t            )\n\t            # if self.mask_aa_pieces:\n\t            #     # word_begins_mask = self.mask_whole_words.gather(0, item)\n\t            #     # word_begins_idx = word_begins_mask.nonzero().view(-1)\n\t            #     # sz = len(word_begins_idx)\n", "            #     # words = np.split(word_begins_mask, word_begins_idx)[1:]\n\t            #     # assert len(words) == sz\n\t            #     # word_lens = list(map(len, words))\n\t            #     # 对item做BPE粒度的mask，注意1个item只含1条序列，即sample-break-mode选项必须为eos\n\t            #     # pieces = self.aa_pieces.encode_pieces(item)\n\t            #     pieces = self.aa_piece_dataset[index].get_pieces()\n\t            #     word_lens = list(map(len, pieces))\n\t            #     word_lens=[1]+word_lens+[1]\n\t            #     sz = len(word_lens)\n\t            if self.mask_prob == 1.0:\n", "                mask = np.full(sz, True)\n\t                if self.return_masked_tokens:\n\t                    # exit early if we're just returning the masked tokens\n\t                    # (i.e., the targets for masked LM training)\n\t                    # if self.mask_aa_pieces:\n\t                    #     mask = np.repeat(mask, word_lens)\n\t                    new_item = np.full(len(item), self.pad_idx)\n\t                    pre_mask = np.full(sz, self.pad_idx)\n\t                    pre_mask[mask] = item[cdr_mask][torch.from_numpy(mask.astype(np.uint8)) == 1]\n\t                    new_item[cdr_mask] = pre_mask\n", "                    return torch.from_numpy(new_item)\n\t                # decide unmasking and random replacement\n\t                rand_or_unmask_prob = self.random_token_prob + self.leave_unmasked_prob\n\t                if rand_or_unmask_prob > 0.0:\n\t                    rand_or_unmask = mask & (np.random.rand(sz) < rand_or_unmask_prob)\n\t                    if self.random_token_prob == 0.0:\n\t                        unmask = rand_or_unmask\n\t                        rand_mask = None\n\t                    elif self.leave_unmasked_prob == 0.0:\n\t                        unmask = None\n", "                        rand_mask = rand_or_unmask\n\t                    else:\n\t                        unmask_prob = self.leave_unmasked_prob / rand_or_unmask_prob\n\t                        decision = np.random.rand(sz) < unmask_prob\n\t                        unmask = rand_or_unmask & decision\n\t                        rand_mask = rand_or_unmask & (~decision)\n\t                else:\n\t                    unmask = rand_mask = None\n\t                if unmask is not None:\n\t                    mask = mask ^ unmask\n", "                # if self.mask_aa_pieces:\n\t                #     mask = np.repeat(mask, word_lens)\n\t                new_item = np.copy(item)\n\t                pre_mask = np.full(sz, self.pad_idx)\n\t                pre_mask[mask] = self.mask_idx\n\t                if rand_mask is not None:\n\t                    num_rand = rand_mask.sum()\n\t                    if num_rand > 0:\n\t                        # if self.mask_aa_pieces:\n\t                        #     rand_mask = np.repeat(rand_mask, word_lens)\n", "                        #     num_rand = rand_mask.sum()\n\t                        pre_mask[rand_mask] = np.random.choice(\n\t                            len(self.seq_vocab),\n\t                            num_rand,\n\t                            p=self.weights,\n\t                        )\n\t                new_item[cdr_mask] = pre_mask\n\t                # print(\"sentence: \", item)\n\t                # print(\"tag: \", tag)\n\t                # print(\"tag seq\", self.tag_vocab.string(tag))\n", "                # print(\"new sent: \", torch.from_numpy(new_item))\n\t                # print('tag_vocab: ', self.tag_vocab)\n\t                # exit(0)\n\t                return torch.from_numpy(new_item)\n\t            # decide elements to mask\n\t            mask = np.full(sz, False)\n\t            num_mask = int(\n\t                # add a random number for probabilistic rounding\n\t                self.mask_prob * sz\n\t                + np.random.rand()\n", "            )\n\t            # multiple masking as described in the vq-wav2vec paper (https://arxiv.org/abs/1910.05453)\n\t            mask_idc = np.random.choice(sz, num_mask, replace=False)\n\t            mask_idc = mask_idc[mask_idc < len(mask)]\n\t            try:\n\t                mask[mask_idc] = True\n\t            except:  # something wrong\n\t                print(\n\t                    \"Assigning mask indexes {} to mask {} failed!\".format(\n\t                        mask_idc, mask\n", "                    )\n\t                )\n\t                raise\n\t            if self.return_masked_tokens:\n\t                # exit early if we're just returning the masked tokens\n\t                # (i.e., the targets for masked LM training)\n\t                # if self.mask_aa_pieces:\n\t                #     mask = np.repeat(mask, word_lens)\n\t                new_item = np.full(len(item), self.pad_idx)\n\t                pre_mask = np.full(sz, self.pad_idx)\n", "                pre_mask[mask] = item[cdr_mask][torch.from_numpy(mask.astype(np.uint8)) == 1]\n\t                new_item[cdr_mask] = pre_mask\n\t                return torch.from_numpy(new_item)\n\t            # decide unmasking and random replacement\n\t            rand_or_unmask_prob = self.random_token_prob + self.leave_unmasked_prob\n\t            if rand_or_unmask_prob > 0.0:\n\t                rand_or_unmask = mask & (np.random.rand(sz) < rand_or_unmask_prob)\n\t                if self.random_token_prob == 0.0:\n\t                    unmask = rand_or_unmask\n\t                    rand_mask = None\n", "                elif self.leave_unmasked_prob == 0.0:\n\t                    unmask = None\n\t                    rand_mask = rand_or_unmask\n\t                else:\n\t                    unmask_prob = self.leave_unmasked_prob / rand_or_unmask_prob\n\t                    decision = np.random.rand(sz) < unmask_prob\n\t                    unmask = rand_or_unmask & decision\n\t                    rand_mask = rand_or_unmask & (~decision)\n\t            else:\n\t                unmask = rand_mask = None\n", "            if unmask is not None:\n\t                mask = mask ^ unmask\n\t            # if self.mask_aa_pieces:\n\t            #     mask = np.repeat(mask, word_lens)\n\t            new_item = np.copy(item)\n\t            pre_mask = np.full(sz, self.pad_idx)\n\t            pre_mask[mask] = self.mask_idx\n\t            if rand_mask is not None:\n\t                num_rand = rand_mask.sum()\n\t                if num_rand > 0:\n", "                    # if self.mask_aa_pieces:\n\t                    #     rand_mask = np.repeat(rand_mask, word_lens)\n\t                    #     num_rand = rand_mask.sum()\n\t                    pre_mask[rand_mask] = np.random.choice(\n\t                        len(self.seq_vocab),\n\t                        num_rand,\n\t                        p=self.weights,\n\t                    )\n\t            new_item[cdr_mask] = pre_mask\n\t            # print(\"sentence: \", item)\n", "            # print(\"tag: \", tag)\n\t            # print(\"tag seq\", self.tag_vocab.string(tag))\n\t            # print(\"new sent: \", torch.from_numpy(new_item))\n\t            # print('tag_vocab: ', self.tag_vocab)\n\t            # exit(0)\n\t            return torch.from_numpy(new_item)\n"]}
{"filename": "fairseq_models/criterions/abbert_masked_lm.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\timport math\n\timport torch\n\timport torch.nn.functional as F\n\tfrom fairseq import metrics, modules, utils\n\tfrom fairseq.criterions import FairseqCriterion, register_criterion\n\t@register_criterion(\"antibody_masked_lm\")\n", "class AntibodyMaskedLmLoss(FairseqCriterion):\n\t    \"\"\"\n\t    Implementation for the loss used in masked language model (MLM) training.\n\t    \"\"\"\n\t    def __init__(self, task, tpu=False):\n\t        super().__init__(task)\n\t        self.tpu = tpu\n\t    def forward(self, model, sample, reduce=True):\n\t        \"\"\"Compute the loss for the given sample.\n\t        Returns a tuple with three elements:\n", "        1) the loss\n\t        2) the sample size, which is used as the denominator for the gradient\n\t        3) logging outputs to display while training\n\t        \"\"\"\n\t        masked_tokens = sample[\"target\"].ne(self.padding_idx)\n\t        sample_size = masked_tokens.int().sum()\n\t        logits = model(src_tokens=sample[\"net_input0\"][\"src_tokens\"], tag_tokens=sample[\"net_input1\"][\"src_tokens\"], masked_tokens=masked_tokens)[0]\n\t        targets = model.get_targets(sample, [logits])\n\t        if masked_tokens is not None:\n\t            targets = targets[masked_tokens]\n", "        loss = modules.cross_entropy(\n\t            logits.view(-1, logits.size(-1)),\n\t            targets.view(-1),\n\t            reduction=\"sum\",\n\t            ignore_index=self.padding_idx,\n\t        )\n\t        logging_output = {\n\t            \"loss\": loss if self.tpu else loss.data,\n\t            \"ntokens\": sample[\"ntokens\"],\n\t            \"nsentences\": sample[\"nsentences\"],\n", "            \"sample_size\": sample_size,\n\t        }\n\t        return loss, sample_size, logging_output\n\t    @staticmethod\n\t    def reduce_metrics(logging_outputs) -> None:\n\t        \"\"\"Aggregate logging outputs from data parallel training.\"\"\"\n\t        loss_sum = sum(log.get(\"loss\", 0) for log in logging_outputs)\n\t        sample_size = sum(log.get(\"sample_size\", 0) for log in logging_outputs)\n\t        metrics.log_scalar(\n\t            \"loss\", loss_sum / sample_size / math.log(2), sample_size, round=3\n", "        )\n\t        metrics.log_derived(\n\t            \"ppl\", lambda meters: utils.get_perplexity(meters[\"loss\"].avg)\n\t        )\n\t    @staticmethod\n\t    def logging_outputs_can_be_summed() -> bool:\n\t        \"\"\"\n\t        Whether the logging outputs returned by `forward` can be summed\n\t        across workers prior to calling `reduce_metrics`. Setting this\n\t        to True will improves distributed training speed.\n", "        \"\"\"\n\t        return True\n"]}
{"filename": "fairseq_models/criterions/abgen_criterions.py", "chunked_list": ["# Copyright (c) Facebook, Inc. and its affiliates.\n\t#\n\t# This source code is licensed under the MIT license found in the\n\t# LICENSE file in the root directory of this source tree.\n\timport math\n\timport torch\n\timport torch.nn as nn\n\tfrom fairseq import utils\n\tfrom fairseq import metrics\n\tfrom fairseq.criterions import LegacyFairseqCriterion, register_criterion\n", "from fairseq_models.modules.utils import compute_rmsd\n\t@register_criterion(\"antibody_generation_loss\")\n\tclass AntibodyGenerationLoss(LegacyFairseqCriterion):\n\t    \"\"\" \n\t    Implementation for the loss used in masked language model (MLM) training.\n\t    \"\"\"\n\t    def __init__(self, args, task, tpu=False):\n\t        super().__init__(args, task)\n\t        self.tpu = tpu\n\t        self.cross_entropy = nn.CrossEntropyLoss(reduction=\"sum\", ignore_index=self.padding_idx)\n", "        self.update_num = 0\n\t        self.args = args\n\t    @staticmethod\n\t    def add_args(parser):\n\t        parser.add_argument('--loss-scale-enc', type=float, default=1.,\n\t                            help='loss scale of encoder loss')\n\t        parser.add_argument('--loss-scale-dec-sloss', type=float, default=1.,\n\t                            help='loss scale of decoder sloss')\n\t        parser.add_argument('--loss-scale-dec-xloss', type=float, default=1.,\n\t                            help='loss scale of decoder xloss')\n", "    def forward(self, model, sample):\n\t        \"\"\"Compute the loss for the given sample.\n\t        Returns a tuple with three elements:\n\t        1) the loss\n\t        2) the sample size, which is used as the denominator for the gradient\n\t        3) logging outputs to display while training\n\t        \"\"\"\n\t        batched_seq, batched_tag, batched_label, paratope, epitope, antibody = sample\n\t        masked_tokens = batched_label.ne(self.padding_idx)\n\t        sample_size = masked_tokens.int().sum()\n", "        out, transformer_logits, _ = model(\n\t            src_tokens=batched_seq, \n\t            tag_tokens=batched_tag,\n\t            paratope=paratope,\n\t            epitope=epitope,\n\t            antibody=antibody,\n\t            masked_tokens=masked_tokens,\n\t        )\n\t        # compute encoder loss\n\t        targets = batched_label\n", "        if masked_tokens is not None:\n\t            targets = targets[masked_tokens]\n\t        if transformer_logits is not None:\n\t            sloss = self.cross_entropy(\n\t                transformer_logits.view(-1, transformer_logits.size(-1)),\n\t                targets.view(-1) - 3, \n\t            ) / sample_size / math.log(2)\n\t        else:\n\t            sloss = 0\n\t        # compute RMSD score\n", "        bind_X, bind_S, _, _ = paratope\n\t        bind_mask = bind_S > 0\n\t        if self.args.noantigen: # noantigen version has no side chains\n\t            ret = torch.zeros((bind_X.size(0), bind_X.size(1), 4, 3), device=batched_seq.device)\n\t        else:\n\t            ret = torch.zeros((bind_X.size(0), bind_X.size(1), 14, 3), device=batched_seq.device)\n\t        cnt = 0\n\t        for i, v in enumerate([sum(mask) for mask in masked_tokens]):\n\t            ret[i, :v] = out.bind_X[cnt:cnt+v]\n\t            cnt += v\n", "        rmsd = compute_rmsd(\n\t                ret[:, :, 1], bind_X[:, :, 1], bind_mask\n\t            )\n\t        rmsd = sum(rmsd) / len(rmsd)\n\t        # loss sum\n\t        loss =  self.args.loss_scale_enc * sloss + \\\n\t                self.args.loss_scale_dec_xloss * out.xloss + \\\n\t                self.args.loss_scale_dec_sloss * out.nll\n\t        logging_output = {\n\t            \"encoder_sloss\": sloss.item(),\n", "            \"decoder_sloss\": out.nll,\n\t            \"decoder_xloss\": out.xloss,\n\t            \"sample_size\": sample_size.item(),\n\t            \"loss\": loss.item(),\n\t            \"rmsd\": rmsd.item()\n\t        }\n\t        return loss, sample_size.item(), logging_output\n\t    @staticmethod\n\t    def reduce_metrics(logging_outputs) -> None:\n\t        \"\"\"Aggregate logging outputs from data parallel training.\"\"\"\n", "        encoder_sloss = sum(log.get(\"encoder_sloss\", 0) for log in logging_outputs)\n\t        decoder_sloss = sum(log.get(\"decoder_sloss\", 0) for log in logging_outputs)\n\t        decoder_xloss = sum(log.get(\"decoder_xloss\", 0) for log in logging_outputs)\n\t        sample_size = sum(log.get(\"sample_size\", 0) for log in logging_outputs)\n\t        loss = sum(log.get(\"loss\", 0) for log in logging_outputs)\n\t        rmsd = sum(log.get(\"rmsd\", 0) for log in logging_outputs)\n\t        metrics.log_scalar(\n\t            \"encoder_sloss\", encoder_sloss, sample_size, round=3\n\t        )\n\t        metrics.log_derived(\n", "            \"encoder_ppl\", lambda meters: utils.get_perplexity(meters[\"encoder_sloss\"].avg)\n\t        )\n\t        metrics.log_scalar(\n\t            \"decoder_sloss\", decoder_sloss, sample_size, round=3\n\t        )\n\t        metrics.log_derived(\n\t            \"decoder_ppl\", lambda meters: utils.get_perplexity(meters[\"decoder_sloss\"].avg)\n\t        )\n\t        metrics.log_scalar(\n\t            \"decoder_xloss\", decoder_xloss, sample_size, round=3\n", "        )\n\t        metrics.log_scalar(\n\t            \"loss\", loss, sample_size, round=3\n\t        )\n\t        metrics.log_scalar(\n\t            \"rmsd\", rmsd, sample_size, round=3\n\t        )\n\t    @staticmethod\n\t    def logging_outputs_can_be_summed() -> bool:\n\t        \"\"\"\n", "        Whether the logging outputs returned by `forward` can be summed\n\t        across workers prior to calling `reduce_metrics`. Setting this\n\t        to True will improves distributed training speed.\n\t        \"\"\"\n\t        return True\n"]}
{"filename": "structgen/decoder.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom structgen.encoder import MPNEncoder\n\tfrom structgen.data import alphabet\n\tfrom structgen.utils import *\n\tfrom structgen.protein_features import ProteinFeatures\n\tclass Decoder(nn.Module):\n\t    def __init__(self, args, return_coords=True):\n", "        super(Decoder, self).__init__()\n\t        self.k_neighbors = args.k_neighbors\n\t        self.depth = args.depth\n\t        self.hidden_size = args.hidden_size\n\t        self.augment_eps = args.augment_eps\n\t        self.context = args.context\n\t        self.return_coords = return_coords\n\t        self.pos_embedding = PosEmbedding(16)\n\t        self.features = ProteinFeatures(\n\t                top_k=args.k_neighbors, num_rbf=args.num_rbf,\n", "                features_type='dist',\n\t                direction='forward'\n\t        )\n\t        self.node_in, self.edge_in = self.features.feature_dimensions['dist']\n\t        self.O_nei = nn.Sequential(\n\t                nn.Linear(args.hidden_size * 2 + 16, args.hidden_size),\n\t                nn.ReLU(),\n\t                nn.Linear(args.hidden_size, 1),\n\t        )\n\t        self.O_dist = nn.Sequential(\n", "                nn.Linear(args.hidden_size * 2 + 16, args.hidden_size),\n\t                nn.ReLU(),\n\t                nn.Linear(args.hidden_size, 1),\n\t        )\n\t        self.O_s = nn.Linear(args.hidden_size, args.vocab_size)\n\t        self.O_v = nn.Linear(args.hidden_size, self.node_in)\n\t        self.O_e = nn.Linear(args.hidden_size, self.edge_in - self.features.num_positional_embeddings)\n\t        self.struct_mpn = MPNEncoder(args, self.node_in, self.edge_in)\n\t        self.seq_mpn = MPNEncoder(args, self.node_in, self.edge_in)\n\t        if args.context:\n", "            self.W_stc = nn.Sequential(\n\t                    nn.Linear(args.hidden_size * 2, args.hidden_size),\n\t                    nn.ReLU(),\n\t            )\n\t            self.W_seq = nn.Sequential(\n\t                    nn.Linear(args.hidden_size * 2, args.hidden_size),\n\t                    nn.ReLU(),\n\t            )\n\t            self.crnn = nn.GRU(\n\t                    len(alphabet), args.hidden_size, \n", "                    batch_first=True, num_layers=1,\n\t                    dropout=args.dropout\n\t            )\n\t        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\t        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n\t        self.mse_loss = nn.MSELoss(reduction='none')\n\t        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    # Q: [B, N, H], K, V: [B, M, H]\n", "    def attention(self, Q, context, W):\n\t        context, cmask = context  # cmask: [B, M]\n\t        att = torch.bmm(Q, context.transpose(1, 2))  # [B, N, M]\n\t        att = att - 1e6 * (1 - cmask.unsqueeze(1))\n\t        att = F.softmax(att, dim=-1)\n\t        out = torch.bmm(att, context)  # [B, N, M] * [B, M, H]\n\t        out = torch.cat([Q, out], dim=-1)\n\t        return W(out)\n\t    def encode_context(self, context):\n\t        cS, cmask, crange = context\n", "        cS = F.one_hot(cS, num_classes=len(alphabet)).float()\n\t        cH, _ = self.crnn(cS)\n\t        return (cH, cmask)\n\t    def forward(self, X, S, L, mask, context=None, debug=False):\n\t        # X: [B, N, 4, 3], S: [B, N], mask: [B, N] \n\t        true_V, _, _ = self.features(X, mask)\n\t        N, K = S.size(1), self.k_neighbors\n\t        # data augmentation\n\t        V, E, E_idx = self.features(\n\t                X + self.augment_eps * torch.randn_like(X), \n", "                mask\n\t        )\n\t        # run struct MPN\n\t        h = self.struct_mpn(V, E, S, E_idx, mask)\n\t        if self.context:\n\t            context = self.encode_context(context)\n\t            h = self.attention(h, context, self.W_stc)\n\t        # predict node feature with h_{v-1}\n\t        vout = self.O_v(h[:, :-1])\n\t        vloss = self.mse_loss(vout, true_V[:, 1:]).mean(dim=-1)\n", "        vloss = torch.sum(vloss * mask[:, 1:]) / mask[:, 1:].sum()\n\t        # predict neighbors with h_{v-1}, h_u, E_pos\n\t        E_next, nlabel, dlabel, nmask = get_nei_label(X, mask, K)  # [B, N-1, N]\n\t        h_cur = h[:, :-1].unsqueeze(2).expand(-1,-1,N,-1)  # [B, N-1, N, H]\n\t        h_pre = gather_nodes(h, E_next)  # [B, N-1, N, H]\n\t        pos = torch.arange(1, N).cuda().view(1, -1, 1) - E_next  # [B, N-1, N]\n\t        E_pos = self.pos_embedding(pos)  # [B, N-1, N, H]\n\t        h_nei = torch.cat([h_cur, h_pre, E_pos], dim=-1)\n\t        nout = self.O_nei(h_nei).squeeze(-1)  # [B, N-1, N]\n\t        nloss = self.bce_loss(nout, nlabel.float())\n", "        nloss = torch.sum(nloss * nmask) / nmask.sum()\n\t        # predict neighbors distance\n\t        dout = self.O_dist(h_nei).squeeze(-1)  # [B, N-1, N]\n\t        dout = dout[:, :, :K]  # [B, N-1, K]\n\t        dmask = nmask[:, :, :K]  # [B, N-1, K]\n\t        dlabel = dlabel.clamp(max=20)\n\t        dlabel = (dlabel[:, :, :K] - 10) / 10  # D in [0, 20]\n\t        dloss = self.mse_loss(dout, dlabel)\n\t        dloss = torch.sum(dloss * dmask) / dmask.sum()\n\t        # sequence prediction\n", "        h = self.seq_mpn(V, E, S, E_idx, mask)\n\t        if self.context:\n\t            h = self.attention(h, context, self.W_seq)\n\t        sout = self.O_s(h)\n\t        sloss = self.ce_loss(sout.view(-1, sout.size(-1)), S.view(-1))\n\t        sloss = torch.sum(sloss * mask.view(-1)) / mask.sum()\n\t        loss = sloss + nloss + vloss + dloss\n\t        dout = dout * 10 + 10\n\t        return (sout, vout, nout, dout) if debug else loss\n\t    def expand_one_residue(self, h, V, E, E_idx, t):\n", "        # predict node feature for t+1\n\t        B, K = len(h), self.k_neighbors\n\t        V[:, t+1] = self.O_v(h[:, t])\n\t        # predict neighbors for t+1\n\t        h_cur = h[:, t:t+1].expand(-1, t+1, -1)  # [B, t+1, H]\n\t        h_pre = h[:, :t+1]  # [B, t+1, H]\n\t        pos = t + 1 - torch.arange(t + 1).view(1, -1, 1).expand(B, -1, -1)  # [B, t+1, 1]\n\t        E_pos = self.pos_embedding(pos.cuda()).squeeze(2)  # [B, t+1, H]\n\t        h_nei = torch.cat([h_cur, h_pre, E_pos], dim=-1)\n\t        nout = self.O_nei(h_nei).squeeze(-1)  # [B, t+1]\n", "        if K <= t + 1:\n\t            _, E_idx[:, t+1] = nout.topk(dim=-1, k=K, largest=True)\n\t            nei_topk = E_idx[:, t+1]  # [B, K]\n\t        else:\n\t            E_idx[:, t+1, :t+1] *= 0\n\t            E_idx[:, t+1, :t+1] += torch.arange(t, -1, -1).view(1,-1).cuda()\n\t            nei_topk = E_idx[:, t+1, :t+1]  # [B, t+1]\n\t        # predict neighbors distance\n\t        # Positional encoding is relative!\n\t        dout = self.O_dist(h_nei).squeeze(-1)  # [B, t+1]\n", "        dout = dout * 10 + 10\n\t        dout = gather_2d(dout, nei_topk)  # [B, t+1]\n\t        rbf_vecs = self.features._rbf(dout.unsqueeze(1))  # [B, 1, t+1, H]\n\t        pos_vecs = self.pos_embedding(nei_topk.unsqueeze(1) - t - 1)  # [B, 1, t+1] => [B, 1, t+1, H]\n\t        E[:, t+1, :t+1] = torch.cat([pos_vecs, rbf_vecs], dim=-1).squeeze(1)  # [B, t+1, H]\n\t        return nout, dout\n\t    def log_prob(self, S, mask, context=None, debug=None):\n\t        B, N = S.size(0), S.size(1)\n\t        K = self.k_neighbors\n\t        V = torch.zeros(B, N+1, self.node_in).cuda()\n", "        V[:, :, :self.node_in // 2] = 1.  # cos(0) = 1\n\t        E = torch.zeros(B, N+1, K, self.edge_in).cuda()\n\t        E_idx = torch.zeros(B, N+1, K).long().cuda() + N - 1\n\t        h_stc = [torch.zeros(B, N, self.hidden_size, requires_grad=True).cuda() for _ in range(self.depth + 1)]\n\t        h_seq = [torch.zeros(B, N, self.hidden_size, requires_grad=True).cuda() for _ in range(self.depth + 1)]\n\t        D = torch.zeros(B, N+1, K).cuda()\n\t        log_prob = []\n\t        if self.context:\n\t            context = self.encode_context(context)\n\t        for t in range(N):\n", "            # run MPN\n\t            h_seq = self.seq_mpn.inc_forward(V, E, S, E_idx, mask, h_seq, t)\n\t            h_stc = self.struct_mpn.inc_forward(V, E, S, E_idx, mask, h_stc, t)\n\t            h = h_seq[-1][:, t:t+1]\n\t            if self.context:\n\t                h = self.attention(h, context, self.W_seq)\n\t            # predict residue for t\n\t            logits = self.O_s(h.squeeze(1))\n\t            lprob = F.log_softmax(logits, dim=-1)\n\t            nll = F.nll_loss(lprob, S[:, t], reduction='none')\n", "            log_prob.append(nll)\n\t            # predict position for t + 1\n\t            h = self.attention(h_stc[-1], context, self.W_stc) if self.context else h_stc[-1]\n\t            V, E, E_idx = V.clone(), E.clone(), E_idx.clone()  # avoid inplace autograd error\n\t            nout, dout = self.expand_one_residue(h, V, E, E_idx, t)\n\t            V, E, E_idx = V.clone(), E.clone(), E_idx.clone()  # avoid inplace autograd error\n\t            D[:, t+1, :dout.size(-1)] = dout\n\t            if debug and t < N - 1:\n\t                self.debug_decode(debug, logits, V, E, E_idx, mask, nout, dout, t)\n\t        log_prob = torch.stack(log_prob, dim=1)  # [B, N]\n", "        ppl = torch.sum(log_prob * mask, dim=-1) / mask.sum(dim=-1)\n\t        log_prob = torch.sum(log_prob * mask) / mask.sum()\n\t        if self.return_coords:\n\t            X = fit_coords(D[:, :-1, :].detach(), E_idx[:, :-1, :].detach(), mask)\n\t            X = X.unsqueeze(2).expand(-1,-1,4,-1)\n\t            return ReturnType(nll=log_prob, ppl=ppl, X_cdr=X)\n\t        else:\n\t            return ReturnType(nll=log_prob, ppl=ppl, X_cdr=None)\n\t    def generate(self, B, N, context=None, return_ppl=False):\n\t        K = self.k_neighbors\n", "        S = torch.zeros(B, N).long().cuda()\n\t        mask = torch.ones(B, N).cuda()\n\t        V = torch.zeros(B, N+1, self.node_in).cuda()\n\t        V[:, :, :self.node_in // 2] = 1.  # cos(0) = 1\n\t        E = torch.zeros(B, N+1, K, self.edge_in).cuda()\n\t        E_idx = torch.zeros(B, N+1, K).long().cuda() + N - 1\n\t        h_stc = [torch.zeros(B, N, self.hidden_size).cuda() for _ in range(self.depth + 1)]\n\t        h_seq = [torch.zeros(B, N, self.hidden_size).cuda() for _ in range(self.depth + 1)]\n\t        if self.context:\n\t            context = self.encode_context(context)\n", "        sloss = 0.\n\t        for t in range(N):\n\t            # run MPN\n\t            h_seq = self.seq_mpn.inc_forward(V, E, S, E_idx, mask, h_seq, t)\n\t            h_stc = self.struct_mpn.inc_forward(V, E, S, E_idx, mask, h_stc, t)\n\t            h = h_seq[-1][:, t:t+1]\n\t            if self.context:\n\t                h = self.attention(h, context, self.W_seq)\n\t            # predict residue for t\n\t            logits = self.O_s(h.squeeze(1))\n", "            prob = F.softmax(logits, dim=-1)  # [B, 20]\n\t            S[:, t] = torch.multinomial(prob, num_samples=1).squeeze(-1)  # [B, 1]\n\t            sloss = sloss + self.ce_loss(logits, S[:, t])\n\t            # predict position for t + 1\n\t            h = self.attention(h_stc[-1], context, self.W_stc) if self.context else h_stc[-1]\n\t            nout, dout = self.expand_one_residue(h, V, E, E_idx, t)\n\t        S = S.tolist()\n\t        S = [''.join([alphabet[S[i][j]] for j in range(N)]) for i in range(B)]\n\t        ppl = torch.exp(sloss / N)\n\t        return (S, ppl) if return_ppl else S\n", "    def debug_decode(self, debug_info, logits, V, E, E_idx, mask, nout, dout, t):\n\t        X, L, true_logits, true_vout, true_nout, true_dout = debug_info[:7]\n\t        true_V, true_E, true_E_idx = self.features(X, mask)\n\t        print(t)\n\t        ll = min(t + 1, self.k_neighbors)\n\t        print('-------S-------')\n\t        print(logits - true_logits[:, t])\n\t        print('-------N-------')\n\t        print(E_idx[:, t+1])\n\t        print(true_E_idx[:, t+1])\n", "        print(nout[:, :ll].sum() - true_nout[:, t, :ll].sum())\n\t        print('-------V-------')\n\t        print(V[:, t+1] - true_vout[:, t])\n\t        print('-------E-------')\n\t        print(dout[:, :ll].sum() - true_dout[:, t, :ll].sum())\n\t        #print(E[:, t+1] - true_E[:, t+1])\n\t        print('---------------')\n\t        V[:, t+1] = true_V[:, t+1]\n\t        E[:, t+1] = true_E[:, t+1]\n\t        E_idx[:, t+1] = true_E_idx[:, t+1]\n", "        input(\"Press Enter to continue...\")\n"]}
{"filename": "structgen/hierarchical.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom structgen.encoder import MPNEncoder\n\tfrom structgen.data import alphabet\n\tfrom structgen.utils import *\n\tfrom structgen.protein_features import ProteinFeatures\n\tclass HierarchicalEncoder(nn.Module):\n\t    def __init__(self, args, node_in, edge_in):\n", "        super(HierarchicalEncoder, self).__init__()\n\t        self.node_in, self.edge_in = node_in, edge_in\n\t        self.W_v = nn.Sequential(\n\t                nn.Linear(self.node_in, args.hidden_size, bias=True),\n\t                Normalize(args.hidden_size)\n\t        )\n\t        self.W_e = nn.Sequential(\n\t                nn.Linear(self.edge_in, args.hidden_size, bias=True),\n\t                Normalize(args.hidden_size)\n\t        )\n", "        self.layers = nn.ModuleList([\n\t                MPNNLayer(args.hidden_size, args.hidden_size * 3, dropout=args.dropout)\n\t                for _ in range(args.depth)\n\t        ])\n\t        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    def forward(self, V, E, hS, E_idx, mask):\n\t        h_v = self.W_v(V)  # [B, N, H] \n\t        h_e = self.W_e(E)  # [B, N, K, H] \n", "        nei_s = gather_nodes(hS, E_idx)  # [B, N, K, H]\n\t        # [B, N, 1] -> [B, N, K, 1] -> [B, N, K]\n\t        vmask = gather_nodes(mask.unsqueeze(-1), E_idx).squeeze(-1)\n\t        h = h_v\n\t        for layer in self.layers:\n\t            nei_v = gather_nodes(h, E_idx)  # [B, N, K, H]\n\t            nei_h = torch.cat([nei_v, nei_s, h_e], dim=-1)\n\t            h = layer(h, nei_h, mask_attend=vmask)  # [B, N, H]\n\t            h = h * mask.unsqueeze(-1)  # [B, N, H]\n\t        return h\n", "class HierarchicalDecoder(nn.Module):\n\t    def __init__(self, args):\n\t        super(HierarchicalDecoder, self).__init__()\n\t        self.cdr_type = args.cdr_type\n\t        self.k_neighbors = args.k_neighbors\n\t        self.block_size = args.block_size\n\t        self.update_freq = args.update_freq\n\t        self.hidden_size = args.hidden_size\n\t        self.pos_embedding = PosEmbedding(16)\n\t        self.features = ProteinFeatures(\n", "                top_k=args.k_neighbors, num_rbf=args.num_rbf,\n\t                features_type='full',\n\t                direction='bidirectional'\n\t        )\n\t        self.node_in, self.edge_in = self.features.feature_dimensions['full']\n\t        self.O_d0 = nn.Linear(args.hidden_size, 12)\n\t        self.O_d = nn.Linear(args.hidden_size, 12)\n\t        self.O_s = nn.Linear(args.hidden_size, args.vocab_size)\n\t        self.W_s = nn.Embedding(args.vocab_size, args.hidden_size)\n\t        self.struct_mpn = HierarchicalEncoder(args, self.node_in, self.edge_in)\n", "        self.seq_mpn = HierarchicalEncoder(args, self.node_in, self.edge_in)\n\t        self.init_mpn = HierarchicalEncoder(args, 16, 32)\n\t        self.rnn = nn.GRU(\n\t                args.hidden_size, args.hidden_size, batch_first=True, \n\t                num_layers=1, bidirectional=True\n\t        ) \n\t        self.W_stc = nn.Sequential(\n\t                nn.Linear(args.hidden_size * 2, args.hidden_size),\n\t                nn.ReLU(),\n\t        )\n", "        self.W_seq = nn.Sequential(\n\t                nn.Linear(args.hidden_size * 2, args.hidden_size),\n\t                nn.ReLU(),\n\t        )\n\t        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\t        self.huber_loss = nn.SmoothL1Loss(reduction='none')\n\t        self.mse_loss = nn.MSELoss(reduction='none')\n\t        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n", "    def init_struct(self, B, N, K):\n\t        # initial V\n\t        pos = torch.arange(N).cuda()\n\t        V = self.pos_embedding(pos.view(1, N, 1))  # [1, N, 1, 16]\n\t        V = V.squeeze(2).expand(B, -1, -1)  # [B, N, 6]\n\t        # initial E_idx\n\t        pos = pos.unsqueeze(0) - pos.unsqueeze(1)     # [N, N]\n\t        D_idx, E_idx = pos.abs().topk(k=K, dim=-1, largest=False)    # [N, K]\n\t        E_idx = E_idx.unsqueeze(0).expand(B, -1, -1)  # [B, N, K]\n\t        D_idx = D_idx.unsqueeze(0).expand(B, -1, -1)  # [B, N, K]\n", "        # initial E\n\t        E_rbf = self.features._rbf(3 * D_idx)\n\t        E_pos = self.features.embeddings(E_idx)\n\t        E = torch.cat((E_pos, E_rbf), dim=-1)\n\t        return V, E, E_idx\n\t    def init_coords(self, S, mask):\n\t        B, N = S.size(0), S.size(1)\n\t        K = min(self.k_neighbors, N)\n\t        V, E, E_idx = self.init_struct(B, N, K)\n\t        h = self.init_mpn(V, E, S, E_idx, mask)\n", "        return self.predict_dist(self.O_d0(h))\n\t    # Q: [B, N, H], K, V: [B, M, H]\n\t    def attention(self, Q, context, cmask, W):\n\t        att = torch.bmm(Q, context.transpose(1, 2))  # [B, N, M]\n\t        att = att - 1e6 * (1 - cmask.unsqueeze(1))\n\t        att = F.softmax(att, dim=-1)\n\t        out = torch.bmm(att, context)  # [B, N, M] * [B, M, H]\n\t        out = torch.cat([Q, out], dim=-1)\n\t        return W(out)\n\t    def predict_dist(self, X):\n", "        X = X.view(X.size(0), X.size(1), 4, 3)\n\t        X_ca = X[:, :, 1, :]\n\t        dX = X_ca[:, None, :, :] - X_ca[:, :, None, :]\n\t        D = torch.sum(dX ** 2, dim=-1)\n\t        V = self.features._dihedrals(X)\n\t        AD = self.features._AD_features(X[:,:,1,:])\n\t        return X.detach().clone(), D, V, AD\n\t    def mask_mean(self, X, mask, i):\n\t        # [B, N, 4, 3] -> [B, 1, 4, 3] / [B, 1, 1, 1]\n\t        X = X[:, i:i+self.block_size]\n", "        if X.dim() == 4:\n\t            mask = mask[:, i:i+self.block_size].unsqueeze(-1).unsqueeze(-1)\n\t        else:\n\t            mask = mask[:, i:i+self.block_size].unsqueeze(-1)\n\t        return torch.sum(X * mask, dim=1, keepdims=True) / (mask.sum(dim=1, keepdims=True) + 1e-8)\n\t    def make_X_blocks(self, X, l, r, mask):\n\t        N = X.size(1)\n\t        lblocks = [self.mask_mean(X, mask, i) for i in range(0, l, self.block_size)]\n\t        rblocks = [self.mask_mean(X, mask, i) for i in range(r + 1, N, self.block_size)]\n\t        bX = torch.cat(lblocks + [X[:, l:r+1]] + rblocks, dim=1)\n", "        return bX.detach()\n\t    def make_S_blocks(self, LS, S, RS, l, r, mask):\n\t        N = S.size(1)\n\t        hS = self.W_s(S)\n\t        LS = [self.mask_mean(hS, mask, i) for i in range(0, l, self.block_size)]\n\t        RS = [self.mask_mean(hS, mask, i) for i in range(r + 1, N, self.block_size)]\n\t        bS = torch.cat(LS + [hS[:, l:r+1]] + RS, dim=1)\n\t        lmask = [mask[:, i:i+self.block_size].amax(dim=1, keepdims=True) for i in range(0, l, self.block_size)]\n\t        rmask = [mask[:, i:i+self.block_size].amax(dim=1, keepdims=True) for i in range(r + 1, N, self.block_size)]\n\t        bmask = torch.cat(lmask + [mask[:, l:r+1]] + rmask, dim=1)\n", "        return bS, bmask, len(LS), len(RS)\n\t    def get_completion_mask(self, B, N, cdr_range):\n\t        cmask = torch.zeros(B, N).cuda()\n\t        for i, (l,r) in enumerate(cdr_range):\n\t            cmask[i, l:r+1] = 1\n\t        return cmask\n\t    def remove_cdr_coords(self, X, cdr_range):\n\t        X = X.clone()\n\t        for i, (l,r) in enumerate(cdr_range):\n\t            X[i, l:r+1, :, :] = 0\n", "        return X.clone()\n\t    def forward(self, true_X, true_S, true_cdr, mask):\n\t        B, N = mask.size(0), mask.size(1)\n\t        K = min(self.k_neighbors, N)\n\t        cdr_range = [(cdr.index(self.cdr_type), cdr.rindex(self.cdr_type)) for cdr in true_cdr]\n\t        T_min = min([l for l,r in cdr_range])\n\t        T_max = max([r for l,r in cdr_range])\n\t        cmask = self.get_completion_mask(B, N, cdr_range)\n\t        smask = mask.clone()\n\t        # make blocks and encode framework\n", "        S = true_S.clone() * (1 - cmask.long())\n\t        hS, _ = self.rnn(self.W_s(S))\n\t        LS, RS = hS[:, :, :self.hidden_size], hS[:, :, self.hidden_size:]\n\t        hS, mask, offset, suffix = self.make_S_blocks(LS, S, RS, T_min, T_max, mask)\n\t        cmask = torch.cat([cmask.new_zeros(B, offset), cmask[:, T_min:T_max+1], cmask.new_zeros(B, suffix)], dim=1)\n\t        # Ground truth \n\t        true_X = self.make_X_blocks(true_X, T_min, T_max, smask)\n\t        true_V = self.features._dihedrals(true_X)\n\t        true_AD = self.features._AD_features(true_X[:,:,1,:])\n\t        true_D, mask_2D = pairwise_distance(true_X, mask)\n", "        true_D = true_D ** 2\n\t        # initial loss\n\t        sloss = 0.\n\t        X, D, V, AD = self.init_coords(hS, mask)\n\t        X = X.detach().clone()\n\t        dloss = self.huber_loss(D, true_D)\n\t        vloss = self.mse_loss(V, true_V)\n\t        aloss = self.mse_loss(AD, true_AD)\n\t        for t in range(T_min, T_max + 1):\n\t            # Prepare input\n", "            V, E, E_idx = self.features(X, mask)\n\t            hS = self.make_S_blocks(LS, S, RS, T_min, T_max, smask)[0]\n\t            # Predict residue t\n\t            h = self.seq_mpn(V, E, hS, E_idx, mask)\n\t            h = self.attention(h, LS, smask, self.W_seq)\n\t            logits = self.O_s(h[:, offset + t - T_min])\n\t            snll = self.ce_loss(logits, true_S[:, t])\n\t            sloss = sloss + torch.sum(snll * cmask[:, offset + t - T_min])\n\t            # Teacher forcing on S\n\t            S = S.clone()\n", "            S[:, t] = true_S[:, t]\n\t            S = S.clone()\n\t            # Iterative refinement\n\t            if t % self.update_freq == 0:\n\t                h = self.struct_mpn(V, E, hS, E_idx, mask)\n\t                h = self.attention(h, LS, smask, self.W_stc)\n\t                X, D, V, AD = self.predict_dist(self.O_d(h))\n\t                X = X.detach().clone()\n\t                dloss = dloss + self.huber_loss(D, true_D)\n\t                vloss = vloss + self.mse_loss(V, true_V)\n", "                aloss = aloss + self.mse_loss(AD, true_AD)\n\t        dloss = torch.sum(dloss * mask_2D) / mask_2D.sum()\n\t        vloss = torch.sum(vloss * mask.unsqueeze(-1)) / mask.sum()\n\t        aloss = torch.sum(aloss * mask.unsqueeze(-1)) / mask.sum()\n\t        sloss = sloss.sum() / cmask.sum()\n\t        loss = sloss + dloss + vloss + aloss\n\t        return loss, sloss\n\t    def log_prob(self, true_S, true_cdr, mask):\n\t        B, N = mask.size(0), mask.size(1)\n\t        K = min(self.k_neighbors, N)\n", "        cdr_range = [(cdr.index(self.cdr_type), cdr.rindex(self.cdr_type)) for cdr in true_cdr]\n\t        T_min = min([l for l,r in cdr_range])\n\t        T_max = max([r for l,r in cdr_range])\n\t        cmask = self.get_completion_mask(B, N, cdr_range)\n\t        smask = mask.clone()\n\t        # initialize\n\t        S = true_S.clone() * (1 - cmask.long())\n\t        hS, _ = self.rnn(self.W_s(S))\n\t        LS, RS = hS[:, :, :self.hidden_size], hS[:, :, self.hidden_size:]\n\t        hS, mask, offset, suffix = self.make_S_blocks(LS, S, RS, T_min, T_max, mask)\n", "        cmask = torch.cat([cmask.new_zeros(B, offset), cmask[:, T_min:T_max+1], cmask.new_zeros(B, suffix)], dim=1)\n\t        sloss = 0.\n\t        X = self.init_coords(hS, mask)[0]\n\t        X = X.detach().clone()\n\t        for t in range(T_min, T_max + 1):\n\t            # Prepare input\n\t            V, E, E_idx = self.features(X, mask)\n\t            hS = self.make_S_blocks(LS, S, RS, T_min, T_max, smask)[0]\n\t            # Predict residue t\n\t            h = self.seq_mpn(V, E, hS, E_idx, mask)\n", "            h = self.attention(h, LS, smask, self.W_seq)\n\t            logits = self.O_s(h[:, offset + t - T_min])\n\t            snll = self.ce_loss(logits, true_S[:, t])\n\t            sloss = sloss + snll * cmask[:, offset + t - T_min]\n\t            # Teacher forcing on S\n\t            S = S.clone()\n\t            S[:, t] = true_S[:, t]\n\t            S = S.clone()\n\t            # Iterative refinement\n\t            if t % self.update_freq == 0:\n", "                h = self.struct_mpn(V, E, hS, E_idx, mask)\n\t                h = self.attention(h, LS, smask, self.W_stc)\n\t                X = self.predict_dist(self.O_d(h))[0]\n\t                X = X.detach().clone()\n\t        ppl = sloss / cmask.sum(dim=-1)\n\t        sloss = sloss.sum() / cmask.sum()\n\t        return ReturnType(nll=sloss, ppl=ppl, X=X, X_cdr=X[:, offset:offset+T_max-T_min+1])\n\t    def generate(self, true_S, true_cdr, mask, return_ppl=False):\n\t        B, N = mask.size(0), mask.size(1)\n\t        K = min(self.k_neighbors, N)\n", "        cdr_range = [(cdr.index(self.cdr_type), cdr.rindex(self.cdr_type)) for cdr in true_cdr]\n\t        T_min = min([l for l,r in cdr_range])\n\t        T_max = max([r for l,r in cdr_range])\n\t        cmask = self.get_completion_mask(B, N, cdr_range)\n\t        smask = mask.clone()\n\t        # initialize\n\t        S = true_S.clone() * (1 - cmask.long())\n\t        hS, _ = self.rnn(self.W_s(S))\n\t        LS, RS = hS[:, :, :self.hidden_size], hS[:, :, self.hidden_size:]\n\t        hS, mask, offset, suffix = self.make_S_blocks(LS, S, RS, T_min, T_max, mask)\n", "        cmask = torch.cat([cmask.new_zeros(B, offset), cmask[:, T_min:T_max+1], cmask.new_zeros(B, suffix)], dim=1)\n\t        X = self.init_coords(hS, mask)[0]\n\t        X = X.detach().clone()\n\t        sloss = 0\n\t        for t in range(T_min, T_max + 1):\n\t            # Prepare input\n\t            V, E, E_idx = self.features(X, mask)\n\t            hS = self.make_S_blocks(LS, S, RS, T_min, T_max, smask)[0]\n\t            # Predict residue t\n\t            h = self.seq_mpn(V, E, hS, E_idx, mask)\n", "            h = self.attention(h, LS, smask, self.W_seq)\n\t            logits = self.O_s(h[:, offset + t - T_min])\n\t            prob = F.softmax(logits, dim=-1)  # [B, 20]\n\t            S[:, t] = torch.multinomial(prob, num_samples=1).squeeze(-1)  # [B, 1]\n\t            sloss = sloss + self.ce_loss(logits, S[:, t]) * cmask[:, offset + t - T_min]\n\t            # Iterative refinement\n\t            h = self.struct_mpn(V, E, hS, E_idx, mask)\n\t            h = self.attention(h, LS, smask, self.W_stc)\n\t            X = self.predict_dist(self.O_d(h))[0]\n\t            X = X.detach().clone()\n", "        S = S.tolist()\n\t        S = [''.join([alphabet[S[i][j]] for j in range(cdr_range[i][0], cdr_range[i][1] + 1)]) for i in range(B)]\n\t        ppl = torch.exp(sloss / cmask.sum(dim=-1))\n\t        return (S, ppl, X[:, offset:offset+T_max-T_min+1]) if return_ppl else S\n"]}
{"filename": "structgen/protein_features.py", "chunked_list": ["from __future__ import print_function\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\timport copy\n\tfrom matplotlib import pyplot as plt\n\tfrom structgen.utils import gather_edges, gather_nodes, Normalize\n\tclass PositionalEncodings(nn.Module):\n\t    def __init__(self, num_embeddings, period_range=[2,1000]):\n", "        super(PositionalEncodings, self).__init__()\n\t        self.num_embeddings = num_embeddings\n\t        self.period_range = period_range \n\t    def forward(self, E_idx):\n\t        # i-j\n\t        N_batch = E_idx.size(0)\n\t        N_nodes = E_idx.size(1)\n\t        N_neighbors = E_idx.size(2)\n\t        ii = torch.arange(N_nodes, dtype=torch.float32).view((1, -1, 1)).cuda()\n\t        d = (E_idx.float() - ii).unsqueeze(-1)\n", "        # Original Transformer frequencies\n\t        frequency = torch.exp(\n\t            torch.arange(0, self.num_embeddings, 2, dtype=torch.float32)\n\t            * -(np.log(10000.0) / self.num_embeddings)\n\t        ).cuda()\n\t        # Grid-aligned\n\t        # frequency = 2. * np.pi * torch.exp(\n\t        #     -torch.linspace(\n\t        #         np.log(self.period_range[0]), \n\t        #         np.log(self.period_range[1]),\n", "        #         self.num_embeddings / 2\n\t        #     )\n\t        # )\n\t        angles = d * frequency.view((1,1,1,-1))\n\t        E = torch.cat((torch.cos(angles), torch.sin(angles)), -1)\n\t        return E\n\tclass ProteinFeatures(nn.Module):\n\t    def __init__(self, num_positional_embeddings=16, num_rbf=16, top_k=30, features_type='full', direction='forward'):\n\t        \"\"\" Extract protein features \"\"\"\n\t        super(ProteinFeatures, self).__init__()\n", "        self.top_k = top_k\n\t        self.num_rbf = num_rbf\n\t        self.num_positional_embeddings = num_positional_embeddings\n\t        self.direction = direction\n\t        # Feature types\n\t        self.features_type = features_type\n\t        self.feature_dimensions = {\n\t            'frame': (6, num_positional_embeddings + num_rbf + 7),\n\t            'full': (6, num_positional_embeddings + num_rbf + 7),\n\t            'dist': (6, num_positional_embeddings + num_rbf),\n", "            'hbonds': (3, 2 * num_positional_embeddings),\n\t        }\n\t        # Positional encoding\n\t        self.embeddings = PositionalEncodings(num_positional_embeddings)\n\t    def _dist(self, X, mask, eps=1E-6):\n\t        \"\"\" Pairwise euclidean distances \"\"\"\n\t        N = X.size(1)\n\t        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n\t        if self.direction == 'bidirectional':\n\t            mask_2D = mask_2D - torch.eye(N).unsqueeze(0).cuda()  # remove self\n", "            mask_2D = mask_2D.clamp(min=0)\n\t        elif self.direction == 'forward':\n\t            nmask = torch.arange(X.size(1)).cuda()\n\t            nmask = nmask.view(1,-1,1) > nmask.view(1,1,-1)\n\t            mask_2D = nmask.float() * mask_2D  # [B, N, N]\n\t        else:\n\t            raise ValueError('invalid direction', direction)\n\t        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n\t        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n\t        # Identify k nearest neighbors (not including self)\n", "        D_adjust = D + (1. - mask_2D) * 10000\n\t        top_k = min(self.top_k, N)\n\t        D_neighbors, E_idx = torch.topk(D_adjust, top_k, dim=-1, largest=False)\n\t        mask_neighbors = gather_edges(mask_2D.unsqueeze(-1), E_idx)\n\t        # Debug plot KNN\n\t        # print(E_idx[:10,:10])\n\t        # D_simple = mask_2D * torch.zeros(D.size()).scatter(-1, E_idx, torch.ones_like(knn_D))\n\t        # print(D_simple)\n\t        # fig = plt.figure(figsize=(4,4))\n\t        # ax = fig.add_subplot(111)\n", "        # D_simple = D.data.numpy()[0,:,:]\n\t        # plt.imshow(D_simple, aspect='equal')\n\t        # plt.axis('off')\n\t        # plt.tight_layout()\n\t        # plt.savefig('D_knn.pdf')\n\t        # exit(0)\n\t        return D_neighbors, E_idx, mask_neighbors\n\t    def _rbf(self, D):\n\t        # Distance radial basis function\n\t        D_min, D_max, D_count = 0., 20., self.num_rbf\n", "        D_mu = torch.linspace(D_min, D_max, D_count).cuda()\n\t        D_mu = D_mu.view([1,1,1,-1])\n\t        D_sigma = (D_max - D_min) / D_count\n\t        D_expand = torch.unsqueeze(D, -1)\n\t        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n\t        # for i in range(D_count):\n\t        #     fig = plt.figure(figsize=(4,4))\n\t        #     ax = fig.add_subplot(111)\n\t        #     rbf_i = RBF.data.numpy()[0,i,:,:]\n\t        #     # rbf_i = D.data.numpy()[0,0,:,:]\n", "        #     plt.imshow(rbf_i, aspect='equal')\n\t        #     plt.axis('off')\n\t        #     plt.tight_layout()\n\t        #     plt.savefig('rbf{}.pdf'.format(i))\n\t        #     print(np.min(rbf_i), np.max(rbf_i), np.mean(rbf_i))\n\t        # exit(0)\n\t        return RBF\n\t    def _quaternions(self, R):\n\t        \"\"\" Convert a batch of 3D rotations [R] to quaternions [Q]\n\t            R [...,3,3]\n", "            Q [...,4]\n\t        \"\"\"\n\t        # Simple Wikipedia version\n\t        # en.wikipedia.org/wiki/Rotation_matrix#Quaternion\n\t        # For other options see math.stackexchange.com/questions/2074316/calculating-rotation-axis-from-rotation-matrix\n\t        diag = torch.diagonal(R, dim1=-2, dim2=-1)\n\t        Rxx, Ryy, Rzz = diag.unbind(-1)\n\t        magnitudes = 0.5 * torch.sqrt(torch.abs(1 + torch.stack([\n\t              Rxx - Ryy - Rzz, \n\t            - Rxx + Ryy - Rzz, \n", "            - Rxx - Ryy + Rzz\n\t        ], -1)))\n\t        _R = lambda i,j: R[:,:,:,i,j]\n\t        signs = torch.sign(torch.stack([\n\t            _R(2,1) - _R(1,2),\n\t            _R(0,2) - _R(2,0),\n\t            _R(1,0) - _R(0,1)\n\t        ], -1))\n\t        xyz = signs * magnitudes\n\t        # The relu enforces a non-negative trace\n", "        w = torch.sqrt(F.relu(1 + diag.sum(-1, keepdim=True))) / 2.\n\t        Q = torch.cat((xyz, w), -1)\n\t        Q = F.normalize(Q, dim=-1)\n\t        # Axis of rotation\n\t        # Replace bad rotation matrices with identity\n\t        # I = torch.eye(3).view((1,1,1,3,3))\n\t        # I = I.expand(*(list(R.shape[:3]) + [-1,-1]))\n\t        # det = (\n\t        #     R[:,:,:,0,0] * (R[:,:,:,1,1] * R[:,:,:,2,2] - R[:,:,:,1,2] * R[:,:,:,2,1])\n\t        #     - R[:,:,:,0,1] * (R[:,:,:,1,0] * R[:,:,:,2,2] - R[:,:,:,1,2] * R[:,:,:,2,0])\n", "        #     + R[:,:,:,0,2] * (R[:,:,:,1,0] * R[:,:,:,2,1] - R[:,:,:,1,1] * R[:,:,:,2,0])\n\t        # )\n\t        # det_mask = torch.abs(det.unsqueeze(-1).unsqueeze(-1))\n\t        # R = det_mask * R + (1 - det_mask) * I\n\t        # DEBUG\n\t        # https://math.stackexchange.com/questions/2074316/calculating-rotation-axis-from-rotation-matrix\n\t        # Columns of this are in rotation plane\n\t        # A = R - I\n\t        # v1, v2 = A[:,:,:,:,0], A[:,:,:,:,1]\n\t        # axis = F.normalize(torch.cross(v1, v2), dim=-1)\n", "        return Q\n\t    def _contacts(self, D_neighbors, E_idx, mask_neighbors, cutoff=8):\n\t        \"\"\" Contacts \"\"\"\n\t        D_neighbors = D_neighbors.unsqueeze(-1)\n\t        neighbor_C = mask_neighbors * (D_neighbors < cutoff).type(torch.float32)\n\t        return neighbor_C\n\t    def _hbonds(self, X, E_idx, mask_neighbors, eps=1E-3):\n\t        \"\"\" Hydrogen bonds and contact map\n\t        \"\"\"\n\t        X_atoms = dict(zip(['N', 'CA', 'C', 'O'], torch.unbind(X, 2)))\n", "        # Virtual hydrogens\n\t        X_atoms['C_prev'] = F.pad(X_atoms['C'][:,1:,:], (0,0,0,1), 'constant', 0)\n\t        X_atoms['H'] = X_atoms['N'] + F.normalize(\n\t             F.normalize(X_atoms['N'] - X_atoms['C_prev'], -1)\n\t          +  F.normalize(X_atoms['N'] - X_atoms['CA'], -1)\n\t        , -1)\n\t        def _distance(X_a, X_b):\n\t            return torch.norm(X_a[:,None,:,:] - X_b[:,:,None,:], dim=-1)\n\t        def _inv_distance(X_a, X_b):\n\t            return 1. / (_distance(X_a, X_b) + eps)\n", "        # DSSP vacuum electrostatics model\n\t        U = (0.084 * 332) * (\n\t              _inv_distance(X_atoms['O'], X_atoms['N'])\n\t            + _inv_distance(X_atoms['C'], X_atoms['H'])\n\t            - _inv_distance(X_atoms['O'], X_atoms['H'])\n\t            - _inv_distance(X_atoms['C'], X_atoms['N'])\n\t        )\n\t        HB = (U < -0.5).type(torch.float32)\n\t        neighbor_HB = mask_neighbors * gather_edges(HB.unsqueeze(-1),  E_idx)\n\t        # print(HB)\n", "        # HB = F.sigmoid(U)\n\t        # U_np = U.cpu().data.numpy()\n\t        # # plt.matshow(np.mean(U_np < -0.5, axis=0))\n\t        # plt.matshow(HB[0,:,:])\n\t        # plt.colorbar()\n\t        # plt.show()\n\t        # D_CA = _distance(X_atoms['CA'], X_atoms['CA'])\n\t        # D_CA = D_CA.cpu().data.numpy()\n\t        # plt.matshow(D_CA[0,:,:] < contact_D)\n\t        # # plt.colorbar()\n", "        # plt.show()\n\t        # exit(0)\n\t        return neighbor_HB\n\t    def _AD_features(self, X, eps=1e-6):\n\t        # Shifted slices of unit vectors\n\t        dX = X[:,1:,:] - X[:,:-1,:]\n\t        U = F.normalize(dX, dim=-1)\n\t        u_2 = U[:,:-2,:]\n\t        u_1 = U[:,1:-1,:]\n\t        u_0 = U[:,2:,:]\n", "        # Backbone normals\n\t        n_2 = F.normalize(torch.cross(u_2, u_1), dim=-1)\n\t        n_1 = F.normalize(torch.cross(u_1, u_0), dim=-1)\n\t        # Bond angle calculation\n\t        cosA = -(u_1 * u_0).sum(-1)\n\t        cosA = torch.clamp(cosA, -1+eps, 1-eps)\n\t        A = torch.acos(cosA)\n\t        # Angle between normals\n\t        cosD = (n_2 * n_1).sum(-1)\n\t        cosD = torch.clamp(cosD, -1+eps, 1-eps)\n", "        D = torch.sign((u_2 * n_1).sum(-1)) * torch.acos(cosD)\n\t        # Backbone features\n\t        AD_features = torch.stack((torch.cos(A), torch.sin(A) * torch.cos(D), torch.sin(A) * torch.sin(D)), 2)\n\t        return F.pad(AD_features, (0,0,1,2), 'constant', 0)\n\t    def _orientations_coarse(self, X, E_idx, eps=1e-6):\n\t        # Shifted slices of unit vectors\n\t        dX = X[:,1:,:] - X[:,:-1,:]\n\t        U = F.normalize(dX, dim=-1)\n\t        u_2 = U[:,:-2,:]\n\t        u_1 = U[:,1:-1,:]\n", "        u_0 = U[:,2:,:]\n\t        # Backbone normals\n\t        n_2 = F.normalize(torch.cross(u_2, u_1), dim=-1)\n\t        n_1 = F.normalize(torch.cross(u_1, u_0), dim=-1)\n\t        # Build relative orientations\n\t        o_1 = F.normalize(u_2 - u_1, dim=-1)\n\t        O = torch.stack((o_1, n_2, torch.cross(o_1, n_2)), 2)\n\t        O = O.view(list(O.shape[:2]) + [9])\n\t        O = F.pad(O, (0,0,1,2), 'constant', 0)\n\t        O_neighbors = gather_nodes(O, E_idx)\n", "        X_neighbors = gather_nodes(X, E_idx)\n\t        # Re-view as rotation matrices\n\t        O = O.view(list(O.shape[:2]) + [3,3])\n\t        O_neighbors = O_neighbors.view(list(O_neighbors.shape[:3]) + [3,3])\n\t        # Rotate into local reference frames\n\t        dX = X_neighbors - X.unsqueeze(-2)\n\t        dU = torch.matmul(O.unsqueeze(2), dX.unsqueeze(-1)).squeeze(-1)\n\t        dU = F.normalize(dU, dim=-1)\n\t        R = torch.matmul(O.unsqueeze(2).transpose(-1,-2), O_neighbors)\n\t        Q = self._quaternions(R)\n", "        # Orientation features\n\t        O_features = torch.cat((dU,Q), dim=-1)\n\t        # Frame features (neighbors sorted)\n\t        X_neighbors = gather_nodes(X, E_idx.sort(dim=-1).values)\n\t        dX = X_neighbors - X.unsqueeze(-2)\n\t        F_vectors = torch.cross(dX[:, :, 1:], dX[:, :, :-1], dim=-1)\n\t        F_norms = torch.norm(F_vectors, dim=-1)\n\t        F_vectors = F.normalize(F_vectors, dim=-1)\n\t        F_vectors = torch.matmul(O.unsqueeze(2), F_vectors.unsqueeze(-1)).squeeze(-1)\n\t        return O_features, F_norms, F_vectors\n", "    def _dihedrals(self, X, eps=1e-7):\n\t        # First 3 coordinates are N, CA, C\n\t        X = X[:,:,:3,:].reshape(X.shape[0], 3*X.shape[1], 3)\n\t        # Shifted slices of unit vectors\n\t        dX = X[:,1:,:] - X[:,:-1,:]\n\t        U = F.normalize(dX, dim=-1)\n\t        u_2 = U[:,:-2,:]\n\t        u_1 = U[:,1:-1,:]\n\t        u_0 = U[:,2:,:]\n\t        # Backbone normals\n", "        n_2 = F.normalize(torch.cross(u_2, u_1), dim=-1)\n\t        n_1 = F.normalize(torch.cross(u_1, u_0), dim=-1)\n\t        # Angle between normals\n\t        cosD = (n_2 * n_1).sum(-1)\n\t        cosD = torch.clamp(cosD, -1+eps, 1-eps)\n\t        D = torch.sign((u_2 * n_1).sum(-1)) * torch.acos(cosD)\n\t        D = F.pad(D, (3,0), 'constant', 0)\n\t        D = D.view((D.size(0), int(D.size(1)/3), 3))\n\t        phi, psi, omega = torch.unbind(D,-1)\n\t        # print(cosD.cpu().data.numpy().flatten())\n", "        # print(omega.sum().cpu().data.numpy().flatten())\n\t        # Bond angle calculation\n\t        # A = torch.acos(-(u_1 * u_0).sum(-1))\n\t        # DEBUG: Ramachandran plot\n\t        # x = phi.cpu().data.numpy().flatten()\n\t        # y = psi.cpu().data.numpy().flatten()\n\t        # plt.scatter(x * 180 / np.pi, y * 180 / np.pi, s=1, marker='.')\n\t        # plt.xlabel('phi')\n\t        # plt.ylabel('psi')\n\t        # plt.axis('square')\n", "        # plt.grid()\n\t        # plt.axis([-180,180,-180,180])\n\t        # plt.show()\n\t        # Lift angle representations to the circle\n\t        D_features = torch.cat((torch.cos(D), torch.sin(D)), 2)\n\t        return D_features\n\t    def forward(self, X, mask):\n\t        \"\"\" Featurize coordinates as an attributed graph \"\"\"\n\t        # Build k-Nearest Neighbors graph\n\t        X_ca = X[:,:,1,:]\n", "        D_neighbors, E_idx, mask_neighbors = self._dist(X_ca, mask)\n\t        RBF = self._rbf(D_neighbors)\n\t        E_positional = self.embeddings(E_idx)\n\t        # Pairwise and triplet features\n\t        O_features, F_norms, F_features = self._orientations_coarse(X_ca, E_idx)\n\t        F_RBF = self._rbf(F_norms)\n\t        if self.features_type == 'frame':\n\t            # Coarse backbone features\n\t            V = self._dihedrals(X)\n\t            E2 = torch.cat((E_positional, RBF, O_features), -1)\n", "            E_sorted = self.embeddings(E_idx.sort(dim=-1).values)\n\t            E3 = torch.cat((E_sorted[:,:,:-1], F_RBF, F_features), -1)\n\t            E = (E2, E3)\n\t        elif self.features_type == 'hbonds':\n\t            # Hydrogen bonds and contacts\n\t            neighbor_HB = self._hbonds(X, E_idx, mask_neighbors)\n\t            neighbor_C = self._contacts(D_neighbors, E_idx, mask_neighbors)\n\t            # Pack\n\t            V = mask.unsqueeze(-1) * torch.ones_like(AD_features)\n\t            neighbor_C = neighbor_C.expand(-1,-1,-1, int(self.num_positional_embeddings / 2))\n", "            neighbor_HB = neighbor_HB.expand(-1,-1,-1, int(self.num_positional_embeddings / 2))\n\t            E = torch.cat((E_positional, neighbor_C, neighbor_HB), -1)\n\t        elif self.features_type == 'full':\n\t            # Full backbone angles\n\t            V = self._dihedrals(X)\n\t            E = torch.cat((E_positional, RBF, O_features), -1)\n\t        elif self.features_type == 'dist':\n\t            # Full backbone angles\n\t            V = self._dihedrals(X)\n\t            E = torch.cat((E_positional, RBF), -1)\n", "        return V, E, E_idx\n\t        # DEBUG\n\t        # U = (np.nan * torch.zeros(X.size(0),X.size(1),X.size(1),3)).scatter(2, E_idx.unsqueeze(-1).expand(-1,-1,-1,3), E[:,:,:,:3])\n\t        # plt.imshow(U.data.numpy()[0,:,:,0])\n\t        # plt.show()\n\t        # exit(0)\n"]}
{"filename": "structgen/sequence.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\tfrom structgen.data import alphabet\n\tfrom structgen.utils import ReturnType\n\tclass SeqModel(nn.Module):\n\t    def __init__(self, args):\n\t        super(SeqModel, self).__init__()\n\t        self.hidden_size = args.hidden_size\n", "        self.W_s = nn.Embedding(args.vocab_size, args.hidden_size)\n\t        self.lstm = nn.LSTM(\n\t                args.hidden_size, args.hidden_size, \n\t                batch_first=True, num_layers=args.depth,\n\t                dropout=args.dropout\n\t        )\n\t        self.W_out = nn.Linear(args.hidden_size, args.vocab_size, bias=True)\n\t        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\t        for p in self.parameters():\n\t            if p.dim() > 1:\n", "                nn.init.xavier_uniform_(p)\n\t    def forward(self, S, mask):\n\t        h_S = self.W_s(S)\n\t        h_S_shift = F.pad(h_S[:,0:-1], (0,0,1,0), 'constant', 0)\n\t        h_V, _ = self.lstm(h_S_shift)\n\t        logits = self.W_out(h_V)\n\t        loss = self.ce_loss(logits.view(-1, logits.size(-1)), S.view(-1))\n\t        loss = torch.sum(loss * mask.view(-1)) / mask.sum()\n\t        return loss\n\t    def log_prob(self, S, mask):\n", "        return ReturnType(nll=self(S, mask))\n\t    def generate(self, B, N):\n\t        h = torch.zeros(self.lstm.num_layers, B, self.hidden_size).cuda()\n\t        c = torch.zeros(self.lstm.num_layers, B, self.hidden_size).cuda()\n\t        S = torch.zeros(B, N + 1).long().cuda()\n\t        for t in range(N):\n\t            h_S = self.W_s(S[:, t:t+1])\n\t            h_V, (h, c) = self.lstm(h_S, (h, c))\n\t            logits = self.W_out(h_V)\n\t            prob = F.softmax(logits, dim=-1).squeeze(1)\n", "            S[:, t+1] = torch.multinomial(prob, num_samples=1).squeeze(-1)\n\t        S = S[:, 1:].tolist()\n\t        S = [''.join([alphabet[S[i][j]] for j in range(N)]) for i in range(B)]\n\t        return S\n\tclass Seq2Seq(nn.Module):\n\t    def __init__(self, args):\n\t        super(Seq2Seq, self).__init__()\n\t        self.hidden_size = args.hidden_size\n\t        self.W_s = nn.Embedding(args.vocab_size, args.hidden_size)\n\t        self.W_a = nn.Embedding(args.vocab_size, args.hidden_size)\n", "        self.encoder = nn.LSTM(\n\t                args.hidden_size, args.hidden_size, \n\t                batch_first=True, num_layers=args.depth,\n\t                dropout=args.dropout\n\t        )\n\t        self.decoder = nn.LSTM(\n\t                args.hidden_size, args.hidden_size, \n\t                batch_first=True, num_layers=args.depth,\n\t                dropout=args.dropout\n\t        )\n", "        self.W_out = nn.Linear(args.hidden_size * 2, args.vocab_size, bias=True)\n\t        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\t        for p in self.parameters():\n\t            if p.dim() > 1:\n\t                nn.init.xavier_uniform_(p)\n\t    def RL_parameters(self):\n\t        return self.parameters()\n\t    def encode(self, aS, amask):\n\t        h_S = self.W_a(aS)\n\t        h_V, _ = self.encoder(h_S)  # [B, M, H]\n", "        return h_V * amask.unsqueeze(-1)\n\t    def forward(self, S, mask, context):\n\t        h_S = self.W_s(S)\n\t        h_S_shift = F.pad(h_S[:,0:-1], (0,0,1,0), 'constant', 0)\n\t        h_V, _ = self.decoder(h_S_shift)  # [B, N, H]\n\t        # attention\n\t        aS, amask, _ = context\n\t        h_A = self.encode(aS, amask)  # [B, M, H]\n\t        att = torch.bmm(h_V, h_A.transpose(1, 2))  # [B, N, M]\n\t        att_mask = mask.unsqueeze(2) * amask.unsqueeze(1)  # [B, N, 1] * [B, 1, M]\n", "        att = att - (1 - att_mask) * 1e6  # attention mask\n\t        att = F.softmax(att, dim=-1)  # [B, N, M]\n\t        h_att = torch.bmm(att, h_A)\n\t        h_out = torch.cat([h_V, h_att], dim=-1)\n\t        logits = self.W_out(h_out)\n\t        loss = self.ce_loss(logits.view(-1, logits.size(-1)), S.view(-1))\n\t        loss = torch.sum(loss * mask.view(-1)) / mask.sum()\n\t        return loss\n\t    def log_prob(self, S, mask, context):\n\t        B, N = S.size(0), S.size(1)\n", "        h_S = self.W_s(S)\n\t        h_S_shift = F.pad(h_S[:,0:-1], (0,0,1,0), 'constant', 0)\n\t        h_V, _ = self.decoder(h_S_shift)  # [B, N, H]\n\t        # attention\n\t        aS, amask, _ = context\n\t        h_A = self.encode(aS, amask)  # [B, M, H]\n\t        att = torch.bmm(h_V, h_A.transpose(1, 2))  # [B, N, M]\n\t        att_mask = mask.unsqueeze(2) * amask.unsqueeze(1)  # [B, N, 1] * [B, 1, M]\n\t        att = att - (1 - att_mask) * 1e6  # attention mask\n\t        att = F.softmax(att, dim=-1)  # [B, N, M]\n", "        h_att = torch.bmm(att, h_A)\n\t        h_out = torch.cat([h_V, h_att], dim=-1)\n\t        logits = self.W_out(h_out)\n\t        loss = self.ce_loss(logits.view(-1, logits.size(-1)), S.view(-1))\n\t        loss = loss.view(B, N)\n\t        ppl = torch.sum(loss * mask, dim=-1) / mask.sum(dim=-1)\n\t        nll = torch.sum(loss * mask) / mask.sum()\n\t        return ReturnType(nll=nll, ppl=ppl)\n\t    def generate(self, B, N, context, return_ppl=False):\n\t        aS, amask, _ = context\n", "        h_A = self.encode(aS, amask)  # [B, M, H]\n\t        h = torch.zeros(self.decoder.num_layers, B, self.hidden_size).cuda()\n\t        c = torch.zeros(self.decoder.num_layers, B, self.hidden_size).cuda()\n\t        S = torch.zeros(B, N + 1).long().cuda()\n\t        sloss = 0.\n\t        for t in range(N):\n\t            h_S = self.W_s(S[:, t:t+1])\n\t            h_V, (h, c) = self.decoder(h_S, (h, c))\n\t            att = torch.bmm(h_V, h_A.transpose(1, 2))  # [B, 1, M]\n\t            att_mask = amask.unsqueeze(1)  # [B, 1, M]\n", "            att = att - (1 - att_mask) * 1e6  # attention mask\n\t            att = F.softmax(att, dim=-1)  # [B, 1, M]\n\t            h_att = torch.bmm(att, h_A)   # [B, 1, H]\n\t            h_out = torch.cat([h_V, h_att], dim=-1)\n\t            logits = self.W_out(h_out).squeeze(1)\n\t            prob = F.softmax(logits, dim=-1)\n\t            S[:, t+1] = torch.multinomial(prob, num_samples=1).squeeze(-1)\n\t            sloss = sloss + self.ce_loss(logits, S[:, t+1])\n\t        S = S[:, 1:].tolist()\n\t        S = [''.join([alphabet[S[i][j]] for j in range(N)]) for i in range(B)]\n", "        ppl = torch.exp(sloss / N)\n\t        return (S, ppl) if return_ppl else S\n"]}
{"filename": "structgen/__init__.py", "chunked_list": ["from structgen.data import *\n\tfrom structgen.decoder import Decoder\n\tfrom structgen.revision import RevisionDecoder\n\tfrom structgen.encoder import MPNEncoder\n\tfrom structgen.hierarchical import HierarchicalDecoder\n\tfrom structgen.sequence import SeqModel, Seq2Seq\n\tfrom structgen.utils import compute_rmsd\n"]}
{"filename": "structgen/utils.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom collections import namedtuple\n\tReturnType = namedtuple('ReturnType',('nll','ppl','X','X_cdr'), defaults=(None, None, None, None))\n\t# problem: hard to add mask in SVD\n\tdef kabsch(A, B):\n\t    a_mean = A.mean(dim=1, keepdims=True)\n\t    b_mean = B.mean(dim=1, keepdims=True)\n", "    A_c = A - a_mean\n\t    B_c = B - b_mean\n\t    # Covariance matrix\n\t    H = torch.bmm(A_c.transpose(1,2), B_c)  # [B, 3, 3]\n\t    U, S, V = torch.svd(H)\n\t    # Rotation matrix\n\t    R = torch.bmm(V, U.transpose(1,2))  # [B, 3, 3]\n\t    # Translation vector\n\t    t = b_mean - torch.bmm(R, a_mean.transpose(1,2)).transpose(1,2)\n\t    A_aligned = torch.bmm(R, A.transpose(1,2)).transpose(1,2) + t\n", "    return A_aligned, R, t\n\t# A: [B, N, 3], B: [B, N, 3], mask: [B, N]\n\tdef compute_rmsd(A, B, mask):\n\t    A_aligned, _, _ = kabsch(A, B)\n\t    rmsd = ((A_aligned - B) ** 2).sum(dim=-1)\n\t    rmsd = torch.sum(rmsd * mask, dim=-1) / (mask.sum(dim=-1) + 1e-6)\n\t    return rmsd.sqrt()\n\tdef autoregressive_mask(E_idx):\n\t    N_nodes = E_idx.size(1)\n\t    ii = torch.arange(N_nodes).cuda()\n", "    ii = ii.view((1, -1, 1))\n\t    mask = E_idx - ii < 0\n\t    return mask.float()\n\tdef fit_coords(D, E_idx, mask, lr=2.0, num_steps=200):\n\t    with torch.enable_grad():\n\t        pred_xyz = torch.randn(D.size(0), D.size(1), 3).cuda()\n\t        pred_xyz = pred_xyz.requires_grad_()\n\t        optimizer = torch.optim.Adam([pred_xyz], lr=lr)\n\t        vmask = autoregressive_mask(E_idx) * mask.unsqueeze(-1)\n\t        for _ in range(num_steps):\n", "            optimizer.zero_grad()\n\t            cur_D = (pred_xyz.unsqueeze(2) - pred_xyz.unsqueeze(1)).norm(dim=-1, p=2)  # [B, N, N]\n\t            cur_D = gather_edges(cur_D.unsqueeze(-1), E_idx).squeeze(-1)\n\t            loss = (D - cur_D) ** 2\n\t            loss = torch.sum(loss * vmask) / vmask.sum()\n\t            loss.backward()\n\t            optimizer.step()\n\t    return pred_xyz.detach().clone()\n\t# The following gather functions\n\tdef gather_edges(edges, neighbor_idx):\n", "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n\t    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n\t    edge_features = torch.gather(edges, 2, neighbors)\n\t    return edge_features\n\tdef gather_nodes(nodes, neighbor_idx):\n\t    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n\t    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n\t    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n\t    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n\t    # Gather and re-pack\n", "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n\t    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n\t    return neighbor_features\n\tdef cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n\t    h_nodes = gather_nodes(h_nodes, E_idx)\n\t    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n\t    return h_nn\n\tdef gather_2d(x, idx):\n\t    # x: [B, N], idx: [B, K]\n\t    batch_size, nei_size = idx.size(0), idx.size(1)\n", "    idx_flat1 = idx.reshape(-1)\n\t    idx_flat0 = torch.cat([torch.arange(batch_size)] * nei_size, dim=0)\n\t    new_x = x[idx_flat0, idx_flat1]\n\t    return new_x.view(batch_size, nei_size)\n\t# h: [B, N, H], x: [B, 1, H]\n\tdef insert_tensor(h, x, t):\n\t    if t == 0:\n\t        return torch.cat((x, h[:, 1:]), dim=1)\n\t    elif t == h.size(1) - 1:\n\t        return torch.cat((h[:, :-1], x), dim=1)\n", "    else:\n\t        return torch.cat((h[:, :t], x, h[:, t+1:]), dim=1)\n\tdef pairwise_distance(X, mask):\n\t    X_ca = X[:, :, 1, :]  # alpha carbon\n\t    mask_2D = mask.unsqueeze(1) * mask.unsqueeze(2)\n\t    dX = X_ca.unsqueeze(1) - X_ca.unsqueeze(2)\n\t    D = mask_2D * torch.sqrt(torch.sum(dX**2, dim=3))\n\t    return D, mask_2D\n\tdef self_square_dist(X, mask):\n\t    X = X[:, :, 1] \n", "    dX = X.unsqueeze(1) - X.unsqueeze(2)  # [B, 1, N, 3] - [B, N, 1, 3]\n\t    D = torch.sum(dX**2, dim=-1)\n\t    mask_2D = mask.unsqueeze(1) * mask.unsqueeze(2)  # [B, 1, N] x [B, N, 1]\n\t    mask_2D = mask_2D - torch.eye(mask.size(1))[None,:,:].cuda()\n\t    return D, mask_2D\n\tdef get_nei_label(X, mask, K):\n\t    D, mask_2D = pairwise_distance(X, mask)\n\t    nmask = torch.arange(X.size(1)).cuda()\n\t    nmask = nmask.view(1,-1,1) > nmask.view(1,1,-1)\n\t    nmask = nmask.float() * mask_2D  # [B, N, N]\n", "    # Identify k nearest neighbors (including self)\n\t    D_adjust = D + (1. - nmask) * 100000\n\t    D_sorted, E_idx = torch.topk(D_adjust, D.size(1), dim=-1, largest=False)\n\t    E_next = E_idx[:, 1:]\n\t    D_next = D_sorted[:, 1:]\n\t    nmask = gather_edges(nmask.unsqueeze(-1), E_next)  # [B, N-1, N, 1]\n\t    nlabel = torch.zeros_like(E_next)\n\t    nlabel[:, :, :K] = 1\n\t    return E_next, nlabel, D_next, nmask.squeeze(-1)\n\tclass Normalize(nn.Module):\n", "    def __init__(self, features, epsilon=1e-6):\n\t        super(Normalize, self).__init__()\n\t        self.gain = nn.Parameter(torch.ones(features))\n\t        self.bias = nn.Parameter(torch.zeros(features))\n\t        self.epsilon = epsilon\n\t    def forward(self, x, dim=-1):\n\t        mu = x.mean(dim, keepdim=True)\n\t        sigma = torch.sqrt(x.var(dim, keepdim=True) + self.epsilon)\n\t        gain = self.gain\n\t        bias = self.bias\n", "        # Reshape\n\t        if dim != -1:\n\t            shape = [1] * len(mu.size())\n\t            shape[dim] = self.gain.size()[0]\n\t            gain = gain.view(shape)\n\t            bias = bias.view(shape)\n\t        return gain * (x - mu) / (sigma + self.epsilon) + bias\n\tclass MPNNLayer(nn.Module):\n\t    def __init__(self, num_hidden, num_in, dropout):\n\t        super(MPNNLayer, self).__init__()\n", "        self.num_hidden = num_hidden\n\t        self.num_in = num_in\n\t        self.dropout = nn.Dropout(dropout)\n\t        self.norm = Normalize(num_hidden)\n\t        self.W = nn.Sequential(\n\t                nn.Linear(num_hidden + num_in, num_hidden),\n\t                nn.ReLU(),\n\t                nn.Linear(num_hidden, num_hidden),\n\t                nn.ReLU(),\n\t                nn.Linear(num_hidden, num_hidden),\n", "        )\n\t    def forward(self, h_V, h_E, mask_attend):\n\t        # h_V: [B, N, H]; h_E: [B, N, K, H]\n\t        # mask_attend: [B, N, K]\n\t        h_V_expand = h_V.unsqueeze(-2).expand(-1, -1, h_E.size(-2), -1)\n\t        h_EV = torch.cat([h_V_expand, h_E], dim=-1)  # [B, N, K, H]\n\t        h_message = self.W(h_EV) * mask_attend.unsqueeze(-1)\n\t        dh = torch.mean(h_message, dim=-2)\n\t        h_V = self.norm(h_V + self.dropout(dh))\n\t        return h_V\n", "class FrameMPNNLayer(nn.Module):\n\t    def __init__(self, num_hidden, num_in, dropout):\n\t        super(FrameMPNNLayer, self).__init__()\n\t        self.num_hidden = num_hidden\n\t        self.num_in = num_in\n\t        self.dropout = nn.Dropout(dropout)\n\t        self.norm = Normalize(num_hidden)\n\t        self.W = nn.Sequential(\n\t                nn.Linear(num_hidden + num_in, num_hidden),\n\t                nn.ReLU(),\n", "                nn.Linear(num_hidden, num_hidden),\n\t                nn.ReLU(),\n\t                nn.Linear(num_hidden, num_hidden),\n\t        )\n\t        self.U = nn.Sequential(\n\t                nn.Linear(num_hidden + num_in, num_hidden),\n\t                nn.ReLU(),\n\t                nn.Linear(num_hidden, num_hidden),\n\t                nn.ReLU(),\n\t                nn.Linear(num_hidden, num_hidden),\n", "        )\n\t    def forward(self, h_V, h_E2, h_E3, mask2, mask3):\n\t        # h_V: [B, N, H]; h_E: [B, N, K, H]\n\t        # mask_attend: [B, N, K]\n\t        h_V_expand = h_V.unsqueeze(-2).expand(-1, -1, h_E2.size(-2), -1)\n\t        h_EV = torch.cat([h_V_expand, h_E2], dim=-1)  # [B, N, K, H]\n\t        h_message = self.W(h_EV) * mask2.unsqueeze(-1)\n\t        dh = torch.mean(h_message, dim=-2)\n\t        h_V_expand = h_V.unsqueeze(-2).expand(-1, -1, h_E3.size(-2), -1)\n\t        h_EV = torch.cat([h_V_expand, h_E3], dim=-1)  # [B, N, K, H]\n", "        mask3 = mask3[:,:,:-1] * mask3[:,:,1:]\n\t        u_message = self.U(h_EV) * mask3.unsqueeze(-1)\n\t        du = torch.mean(u_message, dim=-2)\n\t        h_V = self.norm(h_V + self.dropout(dh) + self.dropout(du))\n\t        return h_V\n\tclass PosEmbedding(nn.Module):\n\t    def __init__(self, num_embeddings):\n\t        super(PosEmbedding, self).__init__()\n\t        self.num_embeddings = num_embeddings\n\t    def forward(self, E_idx):\n", "        # Original Transformer frequencies\n\t        frequency = torch.exp(\n\t            torch.arange(0, self.num_embeddings, 2, dtype=torch.float32)\n\t            * -(np.log(10000.0) / self.num_embeddings)\n\t        ).cuda()\n\t        angles = E_idx.unsqueeze(-1) * frequency.view((1,1,1,-1))\n\t        E = torch.cat((torch.cos(angles), torch.sin(angles)), -1)\n\t        return E\n\tif __name__ == \"__main__\":\n\t    # Test RMSD calculation\n", "    A = torch.tensor([[1., 1.], [2., 2.], [1.5, 3.]], dtype=torch.float32)\n\t    R0 = torch.tensor([[np.cos(60), -np.sin(60)], [np.sin(60), np.cos(60)]], dtype=torch.float32)\n\t    B = (R0.mm(A.T)).T\n\t    t0 = torch.tensor([3., 3.])\n\t    B += t0\n\t    C = B * torch.tensor([-1., 1.])\n\t    rmsd = compute_rmsd(\n\t            torch.stack([A, A], dim=0),\n\t            torch.stack([B, C], dim=0),\n\t            mask=torch.ones(2, 3)\n", "    )\n\t    print(rmsd)\n"]}
{"filename": "structgen/data.py", "chunked_list": ["import torch\n\tfrom torch.utils.data import Dataset\n\timport numpy as np\n\timport json, time, copy\n\timport random\n\tDUMMY = {'pdb': None, 'seq': '#' * 10,\n\t        'coords': {\n\t            \"N\": np.zeros((10, 3)) + np.nan,\n\t            \"CA\":np.zeros((10, 3)) + np.nan,\n\t            \"C\": np.zeros((10, 3)) + np.nan,\n", "            \"O\": np.zeros((10, 3)) + np.nan,\n\t        }\n\t}\n\talphabet = '#ACDEFGHIKLMNPQRSTVWY'  # 0 is padding\n\tHYDROPATHY = {'#': 0, \"I\":4.5, \"V\":4.2, \"L\":3.8, \"F\":2.8, \"C\":2.5, \"M\":1.9, \"A\":1.8, \"W\":-0.9, \"G\":-0.4, \"T\":-0.7, \"S\":-0.8, \"Y\":-1.3, \"P\":-1.6, \"H\":-3.2, \"N\":-3.5, \"D\":-3.5, \"Q\":-3.5, \"E\":-3.5, \"K\":-3.9, \"R\":-4.5}\n\tVOLUME = {'#': 0, \"G\":60.1, \"A\":88.6, \"S\":89.0, \"C\":108.5, \"D\":111.1, \"P\":112.7, \"N\":114.1, \"T\":116.1, \"E\":138.4, \"V\":140.0, \"Q\":143.8, \"H\":153.2, \"M\":162.9, \"I\":166.7, \"L\":166.7, \"K\":168.6, \"R\":173.4, \"F\":189.9, \"Y\":193.6, \"W\":227.8}\n\tCHARGE = {**{'R':1, 'K':1, 'D':-1, 'E':-1, 'H':0.1}, **{x:0 for x in 'ABCFGIJLMNOPQSTUVWXYZ#'}}\n\tPOLARITY = {**{x:1 for x in 'RNDQEHKSTY'}, **{x:0 for x in \"ACGILMFPWV#\"}}\n\tACCEPTOR = {**{x:1 for x in 'DENQHSTY'}, **{x:0 for x in \"RKWACGILMFPV#\"}}\n\tDONOR = {**{x:1 for x in 'RKWNQHSTY'}, **{x:0 for x in \"DEACGILMFPV#\"}}\n", "PMAP = lambda x: [HYDROPATHY[x] / 5, VOLUME[x] / 200, CHARGE[x], POLARITY[x], ACCEPTOR[x], DONOR[x]]\n\tclass AntibodyDataset():\n\t    def __init__(self, jsonl_file, cdr_type='3', max_len=130):\n\t        alphabet_set = set([a for a in alphabet])\n\t        self.data = []\n\t        with open(jsonl_file) as f:\n\t            lines = f.readlines()\n\t            for i in range(len(lines)):\n\t                entry = json.loads(lines[i])\n\t                if entry['cdr'] is None or cdr_type not in entry['cdr']:\n", "                    continue\n\t                last_cdr = entry['cdr'].rindex(cdr_type)\n\t                if last_cdr >= max_len - 1:\n\t                    entry['seq'] = entry['seq'][last_cdr - max_len + 10 : last_cdr + 10]\n\t                    entry['cdr'] = entry['cdr'][last_cdr - max_len + 10 : last_cdr + 10]\n\t                    for key, val in entry['coords'].items():\n\t                        entry['coords'][key] = np.asarray(val)[last_cdr - max_len + 10 : last_cdr + 10]\n\t                else:\n\t                    entry['seq'] = entry['seq'][:max_len]\n\t                    entry['cdr'] = entry['cdr'][:max_len]\n", "                    for key, val in entry['coords'].items():\n\t                        entry['coords'][key] = np.asarray(val)[:max_len]\n\t                if entry is not None and len(entry['seq']) > 0:\n\t                    self.data.append(entry)\n\t    def __len__(self):\n\t        return len(self.data)\n\t    def __getitem__(self, idx):\n\t        return self.data[idx]\n\tclass CDRDataset():\n\t    def __init__(self, jsonl_file, hcdr):\n", "        alphabet_set = set([a for a in alphabet])\n\t        self.cdrs = []\n\t        self.atgs = []\n\t        with open(jsonl_file) as f:\n\t            lines = f.readlines()\n\t            for i in range(len(lines)):\n\t                for cdr_type in hcdr:\n\t                    entry = self.get_cdr(lines[i], cdr_type)\n\t                    if entry is not None and len(entry['seq']) > 0:\n\t                        self.cdrs.append(entry)\n", "                        self.atgs.append(None)\n\t    def get_cdr(self, s, cdr_type):\n\t        entry = json.loads(s)\n\t        seq = entry['seq']\n\t        if seq is None or len(cdr_type) == 0: \n\t            return None\n\t        if 'cdr' in entry:\n\t            cdr = entry['cdr']\n\t            entry['chain'] = entry['seq']\n\t            entry['context'] = ''.join(\n", "                    [(alphabet[0] if y == cdr_type else x) for x,y in zip(seq, cdr)]\n\t            )\n\t            entry['seq'] = ''.join(\n\t                    [x for x,y in zip(seq, cdr) if y == cdr_type]\n\t            )\n\t            cdr_mask = np.array([(y == cdr_type) for y in cdr])\n\t        else:\n\t            cdr_mask = np.array([True] * len(seq))\n\t        for key, val in entry['coords'].items():\n\t            val = np.asarray(val)\n", "            val = val[:len(cdr_mask)]\n\t            entry['coords'][key] = val[cdr_mask] if len(cdr_mask) <= len(val) else val\n\t        return entry\n\t    def __len__(self):\n\t        return len(self.cdrs)\n\t    def __getitem__(self, idx):\n\t        return (self.cdrs[idx], self.atgs[idx])\n\tclass StructureDataset():\n\t    def __init__(self, jsonl_file, max_length=100):\n\t        alphabet_set = set([a for a in alphabet])\n", "        with open(jsonl_file) as f:\n\t            self.data = []\n\t            lines = f.readlines()\n\t            for i, line in enumerate(lines):\n\t                entry = json.loads(line)\n\t                seq = entry['seq']\n\t                for key, val in entry['coords'].items():\n\t                    entry['coords'][key] = np.asarray(val)\n\t                # Check if in alphabet\n\t                bad_chars = set([s for s in seq]).difference(alphabet_set)\n", "                if len(bad_chars) == 0 and len(seq) <= max_length:\n\t                    self.data.append(entry)\n\t    def __len__(self):\n\t        return len(self.data)\n\t    def __getitem__(self, idx):\n\t        return self.data[idx]\n\tclass StructureLoader():\n\t    def __init__(self, dataset, batch_tokens, binder_data=None, interval_sort=0):\n\t        self.dataset = dataset\n\t        self.size = len(dataset)\n", "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n\t        self.batch_tokens = batch_tokens\n\t        self.binder_data = binder_data\n\t        if interval_sort > 0:\n\t            cdr_type = str(interval_sort)\n\t            self.lengths = [dataset[i]['cdr'].count(cdr_type) for i in range(self.size)]\n\t            self.intervals = [(dataset[i]['cdr'].index(cdr_type), dataset[i]['cdr'].rindex(cdr_type)) for i in range(self.size)]\n\t            sorted_ix = sorted(range(self.size), key=self.intervals.__getitem__)\n\t        else:\n\t            sorted_ix = np.argsort(self.lengths)\n", "        # Cluster into batches of similar sizes\n\t        clusters, batch = [], []\n\t        for ix in sorted_ix:\n\t            size = self.lengths[ix]\n\t            if size * (len(batch) + 1) <= self.batch_tokens:\n\t                batch.append(ix)\n\t            else:\n\t                clusters.append(batch)\n\t                batch = [ix]\n\t        if len(batch) > 0:\n", "            clusters.append(batch)\n\t        self.clusters = clusters\n\t    def __len__(self):\n\t        return len(self.clusters)\n\t    def __iter__(self):\n\t        np.random.shuffle(self.clusters)\n\t        for b_idx in self.clusters:\n\t            batch = [self.dataset[i] for i in b_idx]\n\t            if self.binder_data:\n\t                abatch = [self.binder_data[i] for i in b_idx]\n", "                yield (batch, abatch)\n\t            else:\n\t                yield batch\n\tdef completize(batch):\n\t    B = len(batch)\n\t    L = [b['cdr'] for b in batch]\n\t    L_max = max([len(b['seq']) for b in batch])\n\t    X = np.zeros([B, L_max, 4, 3])\n\t    S = np.zeros([B, L_max], dtype=np.int32)\n\t    mask = np.zeros([B, L_max], dtype=np.float32)\n", "    # Build the batch\n\t    for i, b in enumerate(batch):\n\t        x = np.stack([b['coords'][c] for c in ['N', 'CA', 'C', 'O']], 1)\n\t        X[i,:len(x),:,:] = x\n\t        l = len(b['seq'])\n\t        indices = np.asarray([alphabet.index(a) for a in b['seq']], dtype=np.int32)\n\t        S[i, :l] = indices\n\t        mask[i, :l] = 1.\n\t    # Remove NaN coords\n\t    mask = mask * np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n", "    isnan = np.isnan(X)\n\t    X[isnan] = 0.\n\t    # Conversion\n\t    S = torch.from_numpy(S).long().cuda()\n\t    X = torch.from_numpy(X).float().cuda()\n\t    mask = torch.from_numpy(mask).float().cuda()\n\t    return X, S, L, mask\n\tdef featurize(batch, context=True):\n\t    B = len(batch)\n\t    L_max = max([len(b['seq']) for b in batch])\n", "    X = np.zeros([B, L_max, 4, 3])\n\t    S = np.zeros([B, L_max], dtype=np.int32)\n\t    P = np.zeros([B, L_max, 6])\n\t    mask = np.zeros([B, L_max], dtype=np.float32)\n\t    # Build the batch\n\t    for i, b in enumerate(batch):\n\t        x = np.stack([b['coords'][c] for c in ['N', 'CA', 'C', 'O']], 1)\n\t        if len(x) <= L_max:\n\t            X[i,:len(x),:,:] = x\n\t        l = len(b['seq'])\n", "        indices = np.asarray([alphabet.index(a) for a in b['seq']], dtype=np.int32)\n\t        S[i, :l] = indices\n\t        P[i, :l] = np.array([PMAP(a) for a in b['seq']])\n\t        mask[i, :l] = 1.\n\t    # Remove NaN coords\n\t    mask = mask * np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n\t    isnan = np.isnan(X)\n\t    X[isnan] = 0.\n\t    # Conversion\n\t    S = torch.from_numpy(S).long().cuda()\n", "    X = torch.from_numpy(X).float().cuda()\n\t    P = torch.from_numpy(P).float().cuda()\n\t    mask = torch.from_numpy(mask).float().cuda()\n\t    if context:  # extract context\n\t        L_max = max([len(b['context']) for b in batch])\n\t        cS = np.zeros([B, L_max], dtype=np.int32)\n\t        cmask = np.zeros([B, L_max], dtype=np.float32)\n\t        crange = [None] * B\n\t        for i, b in enumerate(batch):\n\t            l = len(b['context'])\n", "            indices = np.asarray([alphabet.index(a) for a in b['context']], dtype=np.int32)\n\t            cS[i, :l] = indices\n\t            cmask[i, :l] = 1.\n\t            crange[i] = (b['context'].index('#'), b['context'].rindex('#'))\n\t        cmask = torch.from_numpy(cmask).float().cuda()\n\t        cS = torch.from_numpy(cS).long().cuda()\n\t        context = (cS, cmask, crange)\n\t    return (X, S, P, mask), context\n"]}
{"filename": "structgen/revision.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom structgen.encoder import MPNEncoder\n\tfrom structgen.data import alphabet\n\tfrom structgen.utils import *\n\tfrom structgen.protein_features import ProteinFeatures\n\tclass RevisionDecoder(nn.Module):\n\t    def __init__(self, args):\n", "        super(RevisionDecoder, self).__init__()\n\t        self.k_neighbors = args.k_neighbors\n\t        self.hidden_size = args.hidden_size\n\t        self.pos_embedding = PosEmbedding(16)\n\t        self.context = args.context\n\t        self.features = ProteinFeatures(\n\t                top_k=args.k_neighbors, num_rbf=args.num_rbf,\n\t                features_type='full',\n\t                direction='bidirectional'\n\t        )\n", "        self.node_in, self.edge_in = self.features.feature_dimensions['full']\n\t        self.O_d0 = nn.Linear(args.hidden_size, 12)\n\t        self.O_d = nn.Linear(args.hidden_size, 12)\n\t        self.O_s = nn.Linear(args.hidden_size, args.vocab_size)\n\t        self.struct_mpn = MPNEncoder(args, self.node_in, self.edge_in, direction='bidirectional')\n\t        self.seq_mpn = MPNEncoder(args, self.node_in, self.edge_in, direction='bidirectional')\n\t        if args.context:\n\t            self.crnn = nn.GRU(\n\t                    len(alphabet), args.hidden_size, \n\t                    batch_first=True, num_layers=1,\n", "                    dropout=args.dropout\n\t            )\n\t            self.W_stc = nn.Sequential(\n\t                    nn.Linear(args.hidden_size * 2, args.hidden_size),\n\t                    nn.ReLU(),\n\t            )\n\t            self.W_seq = nn.Sequential(\n\t                    nn.Linear(args.hidden_size * 2, args.hidden_size),\n\t                    nn.ReLU(),\n\t            )\n", "        else:\n\t            self.init_mpn = MPNEncoder(args, 16, 32, direction='bidirectional')\n\t            self.W_stc = self.W_seq = None\n\t        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\t        self.huber_loss = nn.SmoothL1Loss(reduction='none')\n\t        self.mse_loss = nn.MSELoss(reduction='none')\n\t        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    def init_struct(self, B, N, K):\n", "        # initial S and V\n\t        S = torch.zeros(B, N).cuda().long()\n\t        pos = torch.arange(N).cuda()\n\t        V = self.pos_embedding(pos.view(1, N, 1))  # [1, N, 1, 16]\n\t        V = V.squeeze(2).expand(B, -1, -1)  # [B, N, 6]\n\t        # initial E_idx\n\t        pos = pos.unsqueeze(0) - pos.unsqueeze(1)     # [N, N]\n\t        D_idx, E_idx = pos.abs().topk(k=K, dim=-1, largest=False)    # [N, K]\n\t        E_idx = E_idx.unsqueeze(0).expand(B, -1, -1)  # [B, N, K]\n\t        D_idx = D_idx.unsqueeze(0).expand(B, -1, -1)  # [B, N, K]\n", "        # initial E\n\t        E_rbf = self.features._rbf(3 * D_idx)\n\t        E_pos = self.features.embeddings(E_idx)\n\t        E = torch.cat((E_pos, E_rbf), dim=-1)\n\t        return V, E, S, E_idx\n\t    def encode_context(self, cS, cmask, crange):\n\t        cS = F.one_hot(cS, num_classes=len(alphabet)).float()\n\t        cH, _ = self.crnn(cS)\n\t        max_len = max([right - left + 1 for left,right in crange])\n\t        cdr_h = [cH[i, left:right+1] for i,(left,right) in enumerate(crange)]\n", "        cdr_h = [F.pad(h, (0,0,0,max_len-len(h))) for h in cdr_h]\n\t        return torch.stack(cdr_h, dim=0), cH, cmask, crange\n\t    def init_coords(self, mask):\n\t        B, N = mask.size(0), mask.size(1)\n\t        K = min(self.k_neighbors, N)\n\t        V, E, S, E_idx = self.init_struct(B, N, K)\n\t        h = self.init_mpn(V, E, S, E_idx, mask)\n\t        return self.predict_dist(self.O_d0(h))\n\t    # Q: [B, N, H], K, V: [B, M, H]\n\t    def attention(self, Q, context, cmask, W):\n", "        if self.context:\n\t            att = torch.bmm(Q, context.transpose(1, 2))  # [B, N, M]\n\t            att = att - 1e6 * (1 - cmask.unsqueeze(1))\n\t            att = F.softmax(att, dim=-1)\n\t            out = torch.bmm(att, context)  # [B, N, M] * [B, M, H]\n\t            out = torch.cat([Q, out], dim=-1)\n\t            return W(out)\n\t        else:\n\t            return Q\n\t    def predict_dist(self, X):\n", "        X = X.view(X.size(0), X.size(1), 4, 3)\n\t        X_ca = X[:, :, 1, :]\n\t        dX = X_ca[:, None, :, :] - X_ca[:, :, None, :]\n\t        D = torch.sum(dX ** 2, dim=-1)\n\t        V = self.features._dihedrals(X)\n\t        AD = self.features._AD_features(X[:,:,1,:])\n\t        return X.detach().clone(), D, V, AD\n\t    def forward(self, true_X, true_S, L, mask, context=None):\n\t        B, N = mask.size(0), mask.size(1)\n\t        K = min(self.k_neighbors, N)\n", "        # Ground truth \n\t        true_V = self.features._dihedrals(true_X)\n\t        true_AD = self.features._AD_features(true_X[:,:,1,:])\n\t        true_D, mask_2D = pairwise_distance(true_X, mask)\n\t        true_D = true_D ** 2\n\t        # initialize\n\t        sloss = 0.\n\t        S = torch.zeros(B, N).cuda().long()\n\t        if self.context:\n\t            h, cH, cmask, crange = self.encode_context(*context)\n", "            X, D, V, AD = self.predict_dist(self.O_d0(h))\n\t        else:\n\t            X, D, V, AD = self.init_coords(mask)\n\t            cH = cmask = None\n\t        dloss = self.huber_loss(D, true_D)\n\t        vloss = self.mse_loss(V, true_V)\n\t        aloss = self.mse_loss(AD, true_AD)\n\t        for t in range(N):\n\t            # Predict residue t\n\t            V, E, E_idx = self.features(X, mask)\n", "            h = self.seq_mpn(V, E, S, E_idx, mask)\n\t            h = self.attention(h, cH, cmask, self.W_seq)\n\t            logits = self.O_s(h[:, t])\n\t            snll = self.ce_loss(logits, true_S[:, t])\n\t            sloss = sloss + torch.sum(snll * mask[:, t])\n\t            # Teacher forcing on S\n\t            S = S.clone()\n\t            S[:, t] = true_S[:, t]\n\t            S = S.clone()\n\t            # Iterative refinement\n", "            h = self.struct_mpn(V, E, S, E_idx, mask)\n\t            h = self.attention(h, cH, cmask, self.W_stc)\n\t            X, D, V, AD = self.predict_dist(self.O_d(h))\n\t            dloss = dloss + self.huber_loss(D, true_D)\n\t            vloss = vloss + self.mse_loss(V, true_V)\n\t            aloss = aloss + self.mse_loss(AD, true_AD)\n\t        dloss = torch.sum(dloss * mask_2D) / mask_2D.sum()\n\t        vloss = torch.sum(vloss * mask.unsqueeze(-1)) / mask.sum()\n\t        aloss = torch.sum(aloss * mask.unsqueeze(-1)) / mask.sum()\n\t        sloss = sloss.sum() / mask.sum()\n", "        return sloss + dloss + vloss + aloss\n\t    def log_prob(self, true_S, mask, context=None):\n\t        B, N = true_S.size(0), true_S.size(1)\n\t        K = min(self.k_neighbors, N)\n\t        mask_2D = mask.unsqueeze(1) * mask.unsqueeze(2)\n\t        # initialize\n\t        sloss = 0.\n\t        S = torch.zeros(B, N).cuda().long()\n\t        if self.context:\n\t            h, cH, cmask, crange = self.encode_context(*context)\n", "            X = self.predict_dist(self.O_d0(h))[0]\n\t        else:\n\t            X = self.init_coords(mask)[0]\n\t            cH = cmask = None\n\t        for t in range(N):\n\t            # Predict residue t\n\t            V, E, E_idx = self.features(X, mask)\n\t            h = self.seq_mpn(V, E, S, E_idx, mask)\n\t            h = self.attention(h, cH, cmask, self.W_seq)\n\t            logits = self.O_s(h[:, t])\n", "            prob = F.softmax(logits, dim=-1)  # [B, 20]\n\t            snll = self.ce_loss(logits, true_S[:, t])\n\t            sloss = sloss + torch.sum(snll * mask[:, t])\n\t            # Teacher forcing on S\n\t            S = S.clone()\n\t            S[:, t] = true_S[:, t]\n\t            S = S.clone()\n\t            # Iterative refinement\n\t            h = self.struct_mpn(V, E, S, E_idx, mask)\n\t            h = self.attention(h, cH, cmask, self.W_stc)\n", "            X = self.predict_dist(self.O_d(h))[0]\n\t        sloss = sloss / mask.sum()\n\t        return ReturnType(nll=sloss, X_cdr=X)\n\t    def generate(self, B, N, context=None, return_ppl=False):\n\t        K = min(self.k_neighbors, N)\n\t        mask = torch.ones(B, N).cuda()\n\t        S = torch.zeros(B, N).cuda().long()\n\t        if self.context:\n\t            h, cH, cmask, crange = self.encode_context(*context)\n\t            X = self.predict_dist(self.O_d0(h))[0]\n", "        else:\n\t            X = self.init_coords(mask)[0]\n\t            cH = cmask = None\n\t        sloss = 0.\n\t        for t in range(N):\n\t            # Predict residue t\n\t            V, E, E_idx = self.features(X, mask)\n\t            h = self.seq_mpn(V, E, S, E_idx, mask)\n\t            h = self.attention(h, cH, cmask, self.W_seq)\n\t            logits = self.O_s(h[:, t])\n", "            prob = F.softmax(logits, dim=-1)  # [B, 20]\n\t            S[:, t] = torch.multinomial(prob, num_samples=1).squeeze(-1)  # [B, 1]\n\t            sloss = sloss + self.ce_loss(logits, S[:, t])\n\t            # Iterative refinement\n\t            h = self.struct_mpn(V, E, S, E_idx, mask)\n\t            h = self.attention(h, cH, cmask, self.W_stc)\n\t            X = self.predict_dist(self.O_d(h))[0]\n\t        S = S.tolist()\n\t        S = [''.join([alphabet[S[i][j]] for j in range(N)]) for i in range(B)]\n\t        ppl = torch.exp(sloss / N)\n", "        return (S, ppl) if return_ppl else S\n"]}
{"filename": "structgen/encoder.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\timport numpy as np\n\tfrom structgen.utils import *\n\tclass MPNEncoder(nn.Module):\n\t    def __init__(self, args, node_in, edge_in, direction='forward'):\n\t        super(MPNEncoder, self).__init__()\n\t        self.node_in, self.edge_in = node_in, edge_in\n\t        self.direction = direction\n", "        self.W_v = nn.Sequential(\n\t                nn.Linear(self.node_in, args.hidden_size, bias=True),\n\t                Normalize(args.hidden_size)\n\t        )\n\t        self.W_e = nn.Sequential(\n\t                nn.Linear(self.edge_in, args.hidden_size, bias=True),\n\t                Normalize(args.hidden_size)\n\t        )\n\t        self.W_s = nn.Embedding(args.vocab_size, args.hidden_size)\n\t        self.layers = nn.ModuleList([\n", "                MPNNLayer(args.hidden_size, args.hidden_size * 3, dropout=args.dropout)\n\t                for _ in range(args.depth)\n\t        ])\n\t        for param in self.parameters():\n\t            if param.dim() > 1:\n\t                nn.init.xavier_uniform_(param)\n\t    def autoregressive_mask(self, E_idx):\n\t        N_nodes = E_idx.size(1)\n\t        ii = torch.arange(N_nodes).cuda()\n\t        ii = ii.view((1, -1, 1))\n", "        mask = E_idx - ii < 0\n\t        return mask.float()\n\t    def forward(self, V, E, S, E_idx, mask):\n\t        h_v = self.W_v(V)  # [B, N, H] \n\t        h_e = self.W_e(E)  # [B, N, K, H] \n\t        h_s = self.W_s(S)  # [B, N, H] \n\t        nei_s = gather_nodes(h_s, E_idx)  # [B, N, K, H]\n\t        if self.direction == 'forward':\n\t            vmask = self.autoregressive_mask(E_idx)  # [B, N, K]\n\t            vmask = mask.unsqueeze(-1) * vmask\n", "        elif self.direction == 'bidirectional':\n\t            # [B, N, 1] -> [B, N, K, 1] -> [B, N, K]\n\t            vmask = gather_nodes(mask.unsqueeze(-1), E_idx).squeeze(-1)\n\t        else:\n\t            raise ValueError('invalid direction', self.direction)\n\t        h = h_v\n\t        for layer in self.layers:\n\t            nei_v = gather_nodes(h, E_idx)  # [B, N, K, H]\n\t            nei_h = torch.cat([nei_v, nei_s, h_e], dim=-1)\n\t            h = layer(h, nei_h, mask_attend=vmask)  # [B, N, H]\n", "            h = h * mask.unsqueeze(-1)  # [B, N, H]\n\t        return h\n\t    # incremental forward for unidirectional model\n\t    def inc_forward(self, V, E, S, E_idx, mask, h_all, t):\n\t        assert self.direction == 'forward'\n\t        h_v = self.W_v(V[:, t:t+1])  # [B, 1, H] \n\t        h_e = self.W_e(E[:, t:t+1])  # [B, 1, K, H] \n\t        nei_s = gather_nodes(S.unsqueeze(-1), E_idx[:, t:t+1])  # [B, 1, K, 1]\n\t        nei_s = self.W_s(nei_s.squeeze(-1))  # [B, 1, K, H]\n\t        # sequence prediction\n", "        h_all[0] = insert_tensor(h_all[0], h_v, t)  # h_all[0][:, t:t+1] = h_v\n\t        for i, layer in enumerate(self.layers):\n\t            nei_v = gather_nodes(h_all[i], E_idx[:, t:t+1])  # [B, 1, K, H]\n\t            vmask = (E_idx[:, t:t+1] < t).float()  # [B, 1, K]\n\t            nei_h = torch.cat([nei_v, nei_s, h_e], dim=-1)\n\t            cur_h = h_all[i][:, t:t+1]\n\t            h = layer(cur_h, nei_h, mask_attend=vmask)  # [B, 1, H]\n\t            new_h = h * mask[:, t:t+1].unsqueeze(-1)  # [B, 1, H]\n\t            h_all[i + 1] = insert_tensor(h_all[i + 1], new_h, t)\n\t        return h_all\n"]}
