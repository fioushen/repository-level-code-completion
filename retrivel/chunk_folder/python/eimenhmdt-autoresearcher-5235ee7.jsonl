{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\twith open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n\t    long_description = fh.read()\n\tsetup(\n\t    name=\"autoresearcher\",\n\t    version=\"0.0.6\",\n\t    author=\"Eimen Hamedat\",\n\t    author_email=\"eimen.hamedat@gmail.com\",\n\t    description=\"Automating scientic workflows with AI\",\n\t    long_description=long_description,\n", "    long_description_content_type=\"text/markdown\",\n\t    url=\"https://github.com/eimenhmdt/autoresearcher\",\n\t    classifiers=[\n\t        \"Programming Language :: Python :: 3\",\n\t        \"License :: OSI Approved :: MIT License\",\n\t        \"Operating System :: OS Independent\",\n\t    ],\n\t    packages=find_packages(),\n\t    python_requires=\">=3.8\",\n\t    include_package_data=True,\n", "    install_requires=[\n\t        \"openai==0.27.0\",\n\t        \"python-dotenv==1.0.0\",\n\t        \"requests==2.26.0\",\n\t        \"termcolor==1.1.0\",\n\t        \"jellyfish==0.11.2\",\n\t        \"tiktoken==0.3.3\",\n\t        \"setuptools>=42\",\n\t        \"wheel\"\n\t    ],\n", ")\n"]}
{"filename": "autoresearcher/__init__.py", "chunked_list": ["from .workflows.literature_review.literature_review import literature_review\n"]}
{"filename": "autoresearcher/utils/generate_keyword_combinations.py", "chunked_list": ["from autoresearcher.llms.openai import openai_call\n\tfrom autoresearcher.utils.prompts import keyword_combination_prompt\n\t# Generate keyword combinations for a given research question\n\tdef generate_keyword_combinations(research_question):\n\t    \"\"\"\n\t    Generates keyword combinations for a given research question.\n\t    Args:\n\t      research_question (str): The research question to generate keyword combinations for.\n\t    Returns:\n\t      list: A list of keyword combinations for the given research question.\n", "    Examples:\n\t      >>> generate_keyword_combinations(\"What is the impact of AI on healthcare?\")\n\t      [\"AI healthcare\", \"impact AI healthcare\", \"AI healthcare impact\"]\n\t    \"\"\"\n\t    prompt = keyword_combination_prompt.format(research_question=research_question)\n\t    response = openai_call(prompt, use_gpt4=False, temperature=0, max_tokens=200)\n\t    combinations = response.split(\"\\n\")\n\t    return [\n\t        combination.split(\": \")[1]\n\t        for combination in combinations\n", "        if \": \" in combination\n\t    ]\n"]}
{"filename": "autoresearcher/utils/get_citations.py", "chunked_list": ["import os\n\timport requests\n\tfrom dotenv import load_dotenv\n\tload_dotenv()\n\tEMAIL = os.getenv(\"EMAIL\", \"\")\n\tassert EMAIL, \"EMAIL environment variable is missing from .env\"\n\tdef get_citation_by_doi(doi):\n\t    \"\"\"\n\t    Retrieves a citation for a given DOI.\n\t    Args:\n", "      doi (str): The DOI of the citation to retrieve.\n\t    Returns:\n\t      str: The citation for the given DOI.\n\t    Raises:\n\t      ValueError: If the response is not valid JSON.\n\t    Notes:\n\t      Requires an email address to be set in the EMAIL environment variable.\n\t    Examples:\n\t      >>> get_citation_by_doi(\"10.1038/s41586-020-2003-7\")\n\t      \"Liu, Y., Chen, X., Han, M., Li, Y., Li, L., Zhang, J., ... & Zhang, Y. (2020). A SARS-CoV-2 protein interaction map reveals targets for drug repurposing. Nature, 581(7809), 561-570.\"\n", "    \"\"\"\n\t    url = f\"https://api.citeas.org/product/{doi}?email={EMAIL}\"\n\t    response = requests.get(url)\n\t    try:\n\t        data = response.json()\n\t        return data[\"citations\"][0][\"citation\"]\n\t    except ValueError:\n\t        return response.text\n"]}
{"filename": "autoresearcher/utils/__init__.py", "chunked_list": []}
{"filename": "autoresearcher/utils/prompts.py", "chunked_list": ["literature_review_prompt =  \"\"\"\"\n\t`reset`\n\t`no quotes`\n\t`no explanations`\n\t`no prompt`\n\t`no self-reference`\n\t`no apologies`\n\t`no filler`\n\t`just answer`\n\tI will give you a list of research findings and a research question.\n", "Synthesize the list of research findings to generate a scientific literature review. Also, identify knowledge gaps and future research directions.\n\tMake sure to always reference every research finding you use with in-text citations in APA format using the source provided. \n\tOnly use the research findings I provide you with to create your literature review. Only give me the output and nothing else.\n\tNow, using the concepts above, create a literature review for this research question '{research_question}' using the following research findings:\n\t{answer_list}\n\t\"\"\"\n\textract_answer_prompt = \"\"\"\n\t`reset`\n\t`no quotes`\n\t`no explanations`\n", "`no prompt`\n\t`no self-reference`\n\t`no apologies`\n\t`no filler`\n\t`just answer`\n\tI will give you the abstract of an academic paper. Extract the answer to this research question: {research_question} from the abstract.\n\tIf the answer is not in the abstract, then you are only allowed to respond with 'No answer found'.\n\tThis is the abstract: {abstract}\n\t\"\"\"\n\tkeyword_combination_prompt = \"\"\"\n", "`reset`\n\t`no quotes`\n\t`no explanations`\n\t`no prompt`\n\t`no self-reference`\n\t`no apologies`\n\t`no filler`\n\t`just answer`\n\tGenerate several keyword combinations based on the following research question: {research_question}. \n\tDon't generate more than 5 keyword combinations.\n", "The output should be structured like this:\n\tWrite \"KeywordCombination:\" and then list the keywords like so \"Keyword,Keyword,Keyword\"\n\t\"\"\""]}
{"filename": "autoresearcher/utils/count_tokens.py", "chunked_list": ["import tiktoken\n\tdef count_tokens(text):\n\t    \"\"\"\n\t    Counts the number of tokens in a given text.\n\t    Args:\n\t      text (str): The text to tokenize.\n\t    Returns:\n\t      int: The number of tokens in `text`.\n\t    Examples:\n\t      >>> count_tokens(\"This is a sentence.\")\n", "      6\n\t    Notes:\n\t      The encoding used is determined by the `tiktoken.encoding_for_model` function.\n\t    \"\"\"\n\t    # encoding = tiktoken.get_encoding(\"cl100k_base\")\n\t    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n\t    tokens = encoding.encode(text)\n\t    return len(tokens)\n"]}
{"filename": "autoresearcher/llms/openai.py", "chunked_list": ["import openai\n\timport os\n\tfrom dotenv import load_dotenv\n\tload_dotenv()\n\tOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n\tassert OPENAI_API_KEY, \"OPENAI_API_KEY environment variable is missing from .env\"\n\t# Configure OpenAI\n\topenai.api_key = OPENAI_API_KEY\n\tdef openai_call(\n\t    prompt: str, use_gpt4: bool = False, temperature: float = 0.5, max_tokens: int = 100\n", "):\n\t    \"\"\"\n\t    Calls OpenAI API to generate a response to a given prompt.\n\t    Args:\n\t      prompt (str): The prompt to generate a response to.\n\t      use_gpt4 (bool, optional): Whether to use GPT-4 or GPT-3.5. Defaults to False.\n\t      temperature (float, optional): The temperature of the response. Defaults to 0.5.\n\t      max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 100.\n\t    Returns:\n\t      str: The generated response.\n", "    Examples:\n\t      >>> openai_call(\"Hello, how are you?\")\n\t      \"I'm doing great, thanks for asking!\"\n\t    Notes:\n\t      The OpenAI API key must be set in the environment variable OPENAI_API_KEY.\n\t    \"\"\"\n\t    if not use_gpt4:\n\t        # Call GPT-3.5 turbo model\n\t        messages = [{\"role\": \"user\", \"content\": prompt}]\n\t        response = openai.ChatCompletion.create(\n", "            model=\"gpt-3.5-turbo\",\n\t            messages=messages,\n\t            temperature=temperature,\n\t            max_tokens=max_tokens,\n\t            top_p=1,\n\t            frequency_penalty=0,\n\t            presence_penalty=0,\n\t        )\n\t        return response.choices[0].message.content.strip()\n\t    else:\n", "        # Call GPT-4 chat model\n\t        messages = [{\"role\": \"user\", \"content\": prompt}]\n\t        response = openai.ChatCompletion.create(\n\t            model=\"gpt-4\",\n\t            messages=messages,\n\t            temperature=temperature,\n\t            max_tokens=max_tokens,\n\t            n=1,\n\t            stop=None,\n\t        )\n", "        return response.choices[0].message.content.strip()\n"]}
{"filename": "autoresearcher/llms/__init__.py", "chunked_list": []}
{"filename": "autoresearcher/workflows/__init__.py", "chunked_list": []}
{"filename": "autoresearcher/workflows/literature_review/combine_answers.py", "chunked_list": ["from autoresearcher.llms.openai import openai_call\n\tfrom autoresearcher.utils.prompts import literature_review_prompt\n\tfrom autoresearcher.utils.count_tokens import count_tokens\n\t# Combine answers into a concise literature review using OpenAI API\n\tdef combine_answers(answers, research_question, use_gpt4=False, temperature=0.1):\n\t    \"\"\"\n\t    Combines a list of answers into a concise literature review using OpenAI API.\n\t    Args:\n\t      answers (list): A list of answers to combine.\n\t      research_question (str): The research question to use in the literature review.\n", "      use_gpt4 (bool, optional): Whether to use GPT-4 for the literature review. Defaults to False.\n\t      temperature (float, optional): The temperature to use for the OpenAI API. Defaults to 0.1.\n\t    Returns:\n\t      str: The literature review.\n\t    Examples:\n\t      >>> answers = [\"Answer 1\", \"Answer 2\"]\n\t      >>> research_question = \"What is the impact of AI on society?\"\n\t      >>> combine_answers(answers, research_question)\n\t      \"The impact of AI on society is significant. Answer 1...Answer 2...\"\n\t    \"\"\"\n", "    answer_list = \"\\n\\n\".join(answers)\n\t    prompt = literature_review_prompt.format(\n\t        research_question=research_question, answer_list=answer_list\n\t    )\n\t    # Calculate the tokens in the input\n\t    input_tokens = count_tokens(prompt)\n\t    # Calculate the remaining tokens for the response\n\t    remaining_tokens = 4080 - input_tokens\n\t    max_tokens = max(remaining_tokens, 0)\n\t    literature_review = openai_call(\n", "        prompt, use_gpt4=use_gpt4, temperature=temperature, max_tokens=max_tokens\n\t    )\n\t    return literature_review\n"]}
{"filename": "autoresearcher/workflows/literature_review/literature_review.py", "chunked_list": ["#!/usr/bin/env python3\n\tfrom termcolor import colored\n\tfrom autoresearcher.llms.openai import openai_call\n\tfrom autoresearcher.workflows.literature_review.extract_citations import (\n\t    extract_citations,\n\t)\n\tfrom autoresearcher.utils.generate_keyword_combinations import (\n\t    generate_keyword_combinations,\n\t)\n\tfrom autoresearcher.workflows.literature_review.combine_answers import combine_answers\n", "from autoresearcher.workflows.literature_review.extract_answers_from_papers import (\n\t    extract_answers_from_papers,\n\t)\n\tfrom autoresearcher.data_sources.web_apis.semantic_scholar_loader import (\n\t    SemanticScholarLoader,\n\t)\n\tdef literature_review(research_question, output_file=None):\n\t    \"\"\"\n\t    Generates an academic literature review for a given research question.\n\t    Args:\n", "      research_question (str): The research question to generate a literature review for.\n\t      output_file (str, optional): The file path to save the literature review to.\n\t    Returns:\n\t      str: The generated literature review.\n\t    Examples:\n\t      >>> literature_review('What is the impact of AI on healthcare?')\n\t      Research question: What is the impact of AI on healthcare?\n\t      Auto Researcher initiated!\n\t      Generating keyword combinations...\n\t      Keyword combinations generated!\n", "      Fetching top 20 papers...\n\t      Top 20 papers fetched!\n\t      Extracting research findings from papers...\n\t      Research findings extracted!\n\t      Synthesizing answers...\n\t      Literature review generated!\n\t      Academic Literature Review: ...\n\t      References:\n\t      1. ...\n\t      Keyword combinations used to search for papers: 1. AI healthcare, 2. impact AI healthcare\n", "    \"\"\"\n\t    SemanticScholar = SemanticScholarLoader()\n\t    print(\n\t        colored(\n\t            f\"Research question: {research_question}\", \"yellow\", attrs=[\"bold\", \"blink\"]\n\t        )\n\t    )\n\t    print(colored(\"Auto Researcher initiated!\", \"yellow\"))\n\t    # Generate keyword combinations\n\t    print(colored(\"Generating keyword combinations...\", \"yellow\"))\n", "    keyword_combinations = generate_keyword_combinations(research_question)\n\t    print(colored(\"Keyword combinations generated!\", \"green\"))\n\t    # Fetch the top 20 papers for the research question\n\t    search_query = research_question\n\t    print(colored(\"Fetching top 20 papers...\", \"yellow\"))\n\t    top_papers = SemanticScholar.fetch_and_sort_papers(\n\t        search_query, keyword_combinations=keyword_combinations, year_range=\"2000-2023\"\n\t    )\n\t    print(colored(\"Top 20 papers fetched!\", \"green\"))\n\t    # Extract answers and from the top 20 papers\n", "    print(colored(\"Extracting research findings from papers...\", \"yellow\"))\n\t    answers = extract_answers_from_papers(top_papers, research_question)\n\t    print(colored(\"Research findings extracted!\", \"green\"))\n\t    # Combine answers into a concise academic literature review\n\t    print(colored(\"Synthesizing answers...\", \"yellow\"))\n\t    literature_review = combine_answers(answers, research_question)\n\t    print(colored(\"Literature review generated!\", \"green\"))\n\t    # Extract citations from answers and append a references list to the literature review\n\t    citations = extract_citations(answers)\n\t    references_list = \"\\n\".join(\n", "        [f\"{idx + 1}. {citation}\" for idx, citation in enumerate(citations)]\n\t    )\n\t    literature_review += \"\\n\\nReferences:\\n\" + references_list\n\t    # Append the keyword combinations to the literature review\n\t    literature_review += \"\\n\\nKeyword combinations used to search for papers: \"\n\t    literature_review += \", \".join(\n\t        [f\"{i+1}. {combination}\" for i, combination in enumerate(keyword_combinations)]\n\t    )\n\t    # Print the academic literature review\n\t    print(colored(\"Academic Literature Review:\", \"cyan\"), literature_review, \"\\n\")\n", "    # Save the literature review to a file if the output_file argument is provided\n\t    if output_file:\n\t        with open(output_file, \"w\") as f:\n\t            f.write(literature_review)\n\t        print(colored(f\"Literature review saved to {output_file}\", \"green\"))\n\t    return literature_review\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) > 2:\n\t        research_question = sys.argv[1]\n", "        output_file = sys.argv[2]\n\t    elif len(sys.argv) > 1:\n\t        research_question = sys.argv[1]\n\t        output_file = None\n\t    else:\n\t        raise ValueError(\n\t            \"No research question provided. Usage: python literature_review.py 'My research question' 'optional_output_file.txt'\"\n\t        )\n\t    literature_review(research_question, output_file)\n"]}
{"filename": "autoresearcher/workflows/literature_review/extract_citations.py", "chunked_list": ["# Extract bibliographical citations from answers\n\tdef extract_citations(answers):\n\t    \"\"\"\n\t    Extracts bibliographical citations from a list of answers.\n\t    Args:\n\t      answers (list): A list of strings containing answers.\n\t    Returns:\n\t      list: A list of strings containing bibliographical citations.\n\t    Examples:\n\t      >>> answers = [\"This is an answer. SOURCE: Smith, J. (2020).\",\n", "      ...            \"This is another answer. SOURCE: Jones, A. (2021).\"]\n\t      >>> extract_citations(answers)\n\t      [\"Smith, J. (2020)\", \"Jones, A. (2021)\"]\n\t    \"\"\"\n\t    citations = []\n\t    for answer in answers:\n\t        citation_start = answer.rfind(\"SOURCE: \")\n\t        if citation_start != -1:\n\t            citation = answer[citation_start + len(\"SOURCE: \") :]\n\t            citations.append(citation)\n", "    return citations\n"]}
{"filename": "autoresearcher/workflows/literature_review/__init__.py", "chunked_list": []}
{"filename": "autoresearcher/workflows/literature_review/extract_answers_from_papers.py", "chunked_list": ["#!/usr/bin/env python3\n\tfrom autoresearcher.utils.get_citations import get_citation_by_doi\n\tfrom termcolor import colored\n\tfrom autoresearcher.utils.prompts import extract_answer_prompt\n\tfrom autoresearcher.llms.openai import openai_call\n\t# Extract answers from paper abstracts\n\tdef extract_answers_from_papers(\n\t    papers, research_question, use_gpt4=False, temperature=0, max_tokens=150\n\t):\n\t    \"\"\"\n", "    Extracts answers from paper abstracts.\n\t    Args:\n\t      papers (list): A list of papers.\n\t      research_question (str): The research question to answer.\n\t      use_gpt4 (bool, optional): Whether to use GPT-4 for answer extraction. Defaults to False.\n\t      temperature (float, optional): The temperature for GPT-4 answer extraction. Defaults to 0.\n\t      max_tokens (int, optional): The maximum number of tokens for GPT-4 answer extraction. Defaults to 150.\n\t    Returns:\n\t      list: A list of answers extracted from the paper abstracts.\n\t    Examples:\n", "      >>> extract_answers_from_papers(papers, research_question)\n\t      ['Answer 1 SOURCE: Citation 1', 'Answer 2 SOURCE: Citation 2']\n\t    \"\"\"\n\t    answers = []\n\t    default_answer = \"No answer found.\"\n\t    for paper in papers:\n\t        abstract = paper.get(\"abstract\", \"\")\n\t        title = colored(paper.get(\"title\", \"\"), \"magenta\", attrs=[\"bold\"])\n\t        if \"externalIds\" in paper and \"DOI\" in paper[\"externalIds\"]:\n\t            citation = get_citation_by_doi(paper[\"externalIds\"][\"DOI\"])\n", "        else:\n\t            citation = paper[\"url\"]\n\t        prompt = extract_answer_prompt.format(\n\t            research_question=research_question, abstract=abstract\n\t        )\n\t        answer = openai_call(\n\t            prompt, use_gpt4=use_gpt4, temperature=temperature, max_tokens=max_tokens\n\t        )\n\t        print(f\"Processing paper: {title}\")\n\t        answer_with_citation = f\"{answer}\\n{citation}\"\n", "        if answer != default_answer:\n\t            answer_with_citation = f\"{answer} SOURCE: {citation}\"\n\t            answers.append(answer_with_citation)\n\t            print(colored(f\"Answer found!\", \"green\"))\n\t            print(colored(f\"{answer_with_citation}\", \"cyan\"))\n\t    return answers\n"]}
{"filename": "autoresearcher/data_sources/__init__.py", "chunked_list": []}
{"filename": "autoresearcher/data_sources/web_apis/__init__.py", "chunked_list": []}
{"filename": "autoresearcher/data_sources/web_apis/wikipedia_loader.py", "chunked_list": ["import wikipedia\n\tfrom autoresearcher.data_sources.web_apis.base_web_api_data_loader import (\n\t    BaseWebAPIDataLoader,\n\t)\n\tclass WikipediaLoader(BaseWebAPIDataLoader):\n\t    def __init__(self):\n\t        super().__init__(\"https://en.wikipedia.org/w/api.php\")\n\t    def fetch_data(self, search_query, results=10, language=\"en\"):\n\t        \"\"\"\n\t        Fetches data from the Wikipedia API.\n", "        Args:\n\t          search_query (str): The query to search for.\n\t          results (int, optional): The maximum number of results to return. Defaults to 10.\n\t          language (str, optional): The language to search in. Defaults to \"en\".\n\t        Returns:\n\t          list: A list of dictionaries containing the data for each result.\n\t        Raises:\n\t          wikipedia.exceptions.DisambiguationError: If the search query returns a disambiguation page.\n\t        Examples:\n\t          >>> loader = WikipediaLoader()\n", "          >>> loader.fetch_data(\"Python\")\n\t          [\n\t            {\n\t              \"title\": \"Python (programming language)\",\n\t              \"url\": \"https://en.wikipedia.org/wiki/Python_(programming_language)\",\n\t              \"summary\": \"Python is an interpreted, high-level, general-purpose programming language.\",\n\t              \"content\": \"Python is an interpreted, high-level, general-purpose programming language...\",\n\t              \"categories\": [\"Programming languages\"],\n\t              \"references\": [\"https://www.python.org/\"]\n\t            }\n", "          ]\n\t        \"\"\"\n\t        wikipedia.set_lang(language)\n\t        wikipedia.set_rate_limiting(True)\n\t        search_results = wikipedia.search(search_query, results=results)\n\t        data = []\n\t        for result in search_results:\n\t            try:\n\t                page = wikipedia.page(result)\n\t                data.append(\n", "                    {\n\t                        \"title\": page.title,\n\t                        \"url\": page.url,\n\t                        \"summary\": page.summary,\n\t                        \"content\": page.content,\n\t                        \"categories\": page.categories,\n\t                        \"references\": page.references,\n\t                    }\n\t                )\n\t            except wikipedia.exceptions.DisambiguationError as e:\n", "                # Handle disambiguation pages by selecting the first option\n\t                if e.options:\n\t                    page = wikipedia.page(e.options[0])\n\t                    data.append(\n\t                        {\n\t                            \"title\": page.title,\n\t                            \"url\": page.url,\n\t                            \"summary\": page.summary,\n\t                            \"content\": page.content,\n\t                            \"categories\": page.categories,\n", "                            \"references\": page.references,\n\t                        }\n\t                    )\n\t            except wikipedia.exceptions.PageError:\n\t                # Skip pages that cannot be found\n\t                continue\n\t        return data\n"]}
{"filename": "autoresearcher/data_sources/web_apis/semantic_scholar_loader.py", "chunked_list": ["from autoresearcher.data_sources.web_apis.base_web_api_data_loader import (\n\t    BaseWebAPIDataLoader,\n\t)\n\timport jellyfish\n\tclass SemanticScholarLoader(BaseWebAPIDataLoader):\n\t    def __init__(self):\n\t        \"\"\"\n\t        Initializes the SemanticScholarLoader class.\n\t        Args:\n\t          None\n", "        Returns:\n\t          None\n\t        Notes:\n\t          Calls the superclass constructor with the SemanticScholar API URL.\n\t        \"\"\"\n\t        super().__init__(\"https://api.semanticscholar.org/graph/v1/paper/search\")\n\t    def fetch_data(self, search_query, limit=100, year_range=None):\n\t        \"\"\"\n\t        Fetches data from the SemanticScholar API.\n\t        Args:\n", "          search_query (str): The query to search for.\n\t          limit (int, optional): The maximum number of results to return. Defaults to 100.\n\t          year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None.\n\t        Returns:\n\t          list: A list of paper objects.\n\t        Examples:\n\t          >>> fetch_data(\"machine learning\", limit=50, year_range=(2010, 2020))\n\t          [{...}, {...}, ...]\n\t        \"\"\"\n\t        params = {\n", "            \"query\": search_query,\n\t            \"limit\": limit,\n\t            \"fields\": \"title,url,abstract,authors,citationStyles,journal,citationCount,year,externalIds\",\n\t        }\n\t        if year_range is not None:\n\t            params[\"year\"] = year_range\n\t        data = self.make_request(\"\", params=params)\n\t        return data.get(\"data\", [])\n\t    def fetch_and_sort_papers(\n\t        self,\n", "        search_query,\n\t        limit=100,\n\t        top_n=20,\n\t        year_range=None,\n\t        keyword_combinations=None,\n\t        weight_similarity=0.5,\n\t    ):\n\t        \"\"\"\n\t        Fetches and sorts papers from the SemanticScholar API.\n\t        Args:\n", "          search_query (str): The query to search for.\n\t          limit (int, optional): The maximum number of results to return. Defaults to 100.\n\t          top_n (int, optional): The maximum number of results to return after sorting. Defaults to 20.\n\t          year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None.\n\t          keyword_combinations (list, optional): A list of keyword combinations to search for. Defaults to None.\n\t          weight_similarity (float, optional): The weight to give to the similarity score when sorting. Defaults to 0.5.\n\t        Returns:\n\t          list: A list of the top `top_n` paper objects sorted by combined score.\n\t        Examples:\n\t          >>> fetch_and_sort_papers(\"machine learning\", limit=50, top_n=10, year_range=(2010, 2020))\n", "          [{...}, {...}, ...]\n\t        \"\"\"\n\t        papers = []\n\t        if keyword_combinations is None:\n\t            keyword_combinations = [search_query]\n\t        for combination in keyword_combinations:\n\t            papers.extend(self.fetch_data(combination, limit, year_range))\n\t        max_citations = max(papers, key=lambda x: x[\"citationCount\"])[\"citationCount\"]\n\t        for paper in papers:\n\t            similarity = jellyfish.jaro_similarity(search_query, paper[\"title\"])\n", "            normalized_citation_count = paper[\"citationCount\"] / max_citations\n\t            paper[\"combined_score\"] = (weight_similarity * similarity) + (\n\t                (1 - weight_similarity) * normalized_citation_count\n\t            )\n\t        sorted_papers = sorted(papers, key=lambda x: x[\"combined_score\"], reverse=True)\n\t        # deduplicate paper entries prior to taking top n results\n\t        sorted_dedup_papers = list(\n\t            {each_paper[\"paperId\"]: each_paper for each_paper in sorted_papers}.values()\n\t        )\n\t        return sorted_dedup_papers[:top_n]\n"]}
{"filename": "autoresearcher/data_sources/web_apis/base_web_api_data_loader.py", "chunked_list": ["import requests\n\tfrom abc import ABC, abstractmethod\n\tclass BaseWebAPIDataLoader(ABC):\n\t    def __init__(self, base_url):\n\t        self.base_url = base_url\n\t    @abstractmethod\n\t    def fetch_data(self, search_query, **kwargs):\n\t        \"\"\"\n\t        Fetches data from the API.\n\t        Args:\n", "          search_query (str): The search query to use.\n\t          **kwargs: Additional keyword arguments to pass to the API.\n\t        Returns:\n\t          dict: The response from the API.\n\t        Raises:\n\t          NotImplementedError: If the method is not implemented.\n\t        \"\"\"\n\t        pass\n\t    def make_request(self, endpoint, params=None):\n\t        \"\"\"\n", "        Makes a request to the API.\n\t        Args:\n\t          endpoint (str): The API endpoint to make the request to.\n\t          params (dict, optional): Additional parameters to pass to the API. Defaults to None.\n\t        Returns:\n\t          dict: The response from the API.\n\t        Raises:\n\t          Exception: If the request fails.\n\t        \"\"\"\n\t        url = f\"{self.base_url}{endpoint}\"\n", "        response = requests.get(url, params=params)\n\t        if response.status_code == 200:\n\t            data = response.json()\n\t            return data\n\t        else:\n\t            raise Exception(f\"Failed to fetch data from API: {response.status_code}\")\n"]}
{"filename": "api/main.py", "chunked_list": ["import asyncio\n\tfrom fastapi import FastAPI, Response, Request\n\tfrom fastapi.middleware.cors import CORSMiddleware\n\tfrom pydantic import BaseModel\n\tfrom autoresearcher import literature_review\n\t# Placeholder function for literature_review for fast testing\n\t# async def literature_review(q: str):\n\t#     return \"answer to: \" + q\n\tapp = FastAPI()\n\t# List of allowed origins (you can replace these with your own domain names)\n", "allowed_origins = [\n\t    \"*\",\n\t    \"https://restfox.dev\",  # Testing\n\t    \"http://localhost:3000\",  # Local development\n\t    \"https://example.com\",    # Production domain\n\t]\n\t# Add CORS middleware to the FastAPI application\n\tapp.add_middleware(\n\t    CORSMiddleware,\n\t    allow_origins=allowed_origins,\n", "    allow_credentials=True,\n\t    allow_methods=[\"*\"],  # Allow all HTTP methods (GET, POST, PUT, DELETE, etc.)\n\t    allow_headers=[\"*\"],  # Allow all headers\n\t)\n\t# Placeholder class for BrowserError (replace with your implementation)\n\tclass BrowserError(Exception):\n\t    pass\n\t# Define a Pydantic model for the POST request body\n\t# this should be for ALL tools + workflows\n\tclass QuestionModel(BaseModel):\n", "    research_question: str\n\t# this is purely for testing and memes\n\t# return a text response @ get\n\t# @app.get(\"/literature-review\")\n\t@app.get(\"/q/{q}\")\n\tasync def get_literature_review(q: str):\n\t    print('[GET] New Question:', q)\n\t    try:\n\t        if q is None:\n\t           return \"type a question after /q/type your question here \"\n", "        researcher = literature_review(q)\n\t        return researcher\n\t    except BrowserError as e:\n\t        return {\"error\": str(e)}\n\t# return a JSON response @ POST\n\t# optionally return a streamed response\n\t# Define the POST endpoint and accept the JSON request body\n\t@app.post(\"/\")\n\tasync def get_literature_review(request: QuestionModel):\n\t    q = request.research_question\n", "    print('[POST] New Question:', q)\n\t    try:\n\t        researcher = literature_review(q)\n\t        return {\"researcher\": researcher}\n\t    except BrowserError as e:\n\t        return {\"error\": str(e)}\n\t# to support plugins\n\t@app.get(\"/.well-known/ai-plugin.json\")\n\tasync def load_plugin(request: Request):\n\t    host = request.headers[\"host\"]\n", "    try:\n\t        with open(\"./.well-known/ai-plugin.json\") as file:\n\t            text = file.read()\n\t    except FileNotFoundError:\n\t        return Response(status_code=404, content=\"Not found\")\n\t    text = text.replace(\"PLUGIN_HOSTNAME\", f\"http://{host}\")\n\t    return Response(content=text, media_type=\"text/json\")\n\t@app.get(\"/openapi.yaml\")\n\tasync def load_openapi(request: Request):\n\t    host = request.headers[\"host\"]\n", "    try:\n\t        with open(\"openapi.yaml\") as file:\n\t            text = file.read()\n\t    except FileNotFoundError:\n\t        return Response(status_code=404, content=\"Not found\")\n\t    text = text.replace(\"PLUGIN_HOSTNAME\", f\"http://{host}\")\n\t    return Response(content=text, media_type=\"text/yaml\")\n\tif __name__ == \"__main__\":\n\t    import uvicorn\n\t    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"]}
