{"filename": "setup.py", "chunked_list": ["import io\n\timport os\n\timport fnmatch\n\timport platform\n\timport sys\n\timport re\n\timport sysconfig\n\timport importlib.metadata as ilm\n\tfrom skbuild import setup\n\tfrom pathlib import Path\n", "from setuptools import find_packages\n\tPROJECT_ROOT = Path(__file__).parent.absolute()\n\tREADME_PATH = PROJECT_ROOT / \"README.md\"\n\tCHANGELOG_PATH = PROJECT_ROOT / \"CHANGELOG\"\n\tDESCRIPTION = README_PATH.read_text()\n\tDESCRIPTION += \"\\n\\n\\n## Changelog\\n\"\n\tDESCRIPTION += CHANGELOG_PATH.read_text()\n\tVERSION = \"0.0.1\"\n\tif \"VCPKG_INSTALLATION_ROOT\" in os.environ:\n\t    vcpkg = Path(os.environ[\"VCPKG_INSTALLATION_ROOT\"], \"scripts\", \"buildsystems\", \"vcpkg.cmake\").resolve()\n", "else:\n\t    if not Path(\"vcpkg\").exists():\n\t        import subprocess as sp\n\t        sp.run([\"git\", \"clone\", \"https://github.com/Microsoft/vcpkg.git\"])\n\t    bootstrap_end = \"bat\" if platform.system() == \"Windows\" else \"sh\"\n\t    sp.run([f\"vcpkg/bootstrap-vcpkg.{bootstrap_end}\"], shell=True, check=True)\n\t    vcpkg = Path(\"vcpkg\", \"scripts\", \"buildsystems\", \"vcpkg.cmake\").resolve()\n\tprefix_path = []\n\tif \"CMAKE_PREFIX_PATH\" in os.environ:\n\t    prefix_path.extend(os.environ[\"CMAKE_PREFIX_PATH\"].split(os.pathsep))\n", "CMAKE_SETTINGS = [\n\t    \"-DROUGHPY_BUILD_TESTS:BOOL=OFF\",\n\t    \"-DROUGHPY_BUILD_LA_CONTEXTS:BOOL=OFF\",  # Temporarily\n\t    \"-DROUGHPY_GENERATE_DEVICE_CODE:BOOL=OFF\",  # Until it's finished\n\t    f\"-DCMAKE_TOOLCHAIN_FILE={vcpkg}\",\n\t    \"-DVCPKG_BUILD_TYPE=release\",\n\t    # \"--debug-find\", \"--debug-output\"\n\t]\n\tif platform.system() == \"MacOs\" and \"CMAKE_OMP_ROOT\" in os.environ:\n\t    CMAKE_SETTINGS.extend([\n", "        f\"-DCMAKE_LIBRARY_PATH={os.environ['CMAKE_OMP_ROOT']}/lib\",\n\t        f\"-DCMAKE_INCLUDE_PATH={os.environ['CMAKE_OMP_ROOT']}/include\",\n\t    ])\n\ttry:\n\t    mkl = ilm.distribution(\"mkl-devel\")\n\t    # locate the cmake folder\n\t    cmake_files = [f for f in mkl.files if f.name.endswith(\"cmake\")]\n\t    # should be {root}/lib/cmake/mkl/{f}\n\t    cmake = cmake_files[0].locate().resolve().parent.parent\n\t    # append {root} to prefix_path\n", "    prefix_path.append(str(cmake.parent.parent))\n\t    CMAKE_SETTINGS.append(f\"-DMKL_DIR={cmake}\")\n\texcept ilm.PackageNotFoundError:\n\t    # pass\n\t    raise\n\tCMAKE_SETTINGS.append(\n\t    f\"-DCMAKE_PREFIX_PATH={os.pathsep.join(prefix_path)}\"\n\t)\n\tos.environ[\"CMAKE_PREFIX_PATH\"] = os.pathsep.join(prefix_path)\n\tdef filter_cmake_manifests(items):\n", "    def _filter(item):\n\t        item = str(item)\n\t        if item.endswith(\".pc\"):\n\t            return False\n\t        if item.endswith(\".cmake\"):\n\t            return False\n\t        if item.endswith(\".cpp\"):\n\t            return False\n\t        if item.endswith(\".h\"):\n\t            return False\n", "        if item.endswith(\".a\"):\n\t            return False\n\t        # m = re.search(r\"[a-zA-Z0-9_]+\\.so(?:\\.\\d+\\.\\d+\\.\\d+)?$\", item)\n\t        # if m is not None:\n\t        #     return False\n\t        if item.endswith(\"recombine.so\") or item.endswith(\"recombine.so.2.0.2\"):\n\t            return False\n\t        return True\n\t    manifest = list(filter(_filter, items))\n\t    return manifest\n", "setup(\n\t    name=\"RoughPy\",\n\t    version=VERSION,\n\t    author=\"The RoughPy Authors\",\n\t    author_email=\"info@datasig.ac.uk\",\n\t    license=\"BSD-3-Clause\",\n\t    keywords=[\"data\", \"streams\", \"rough paths\", \"signatures\"],\n\t    long_description=DESCRIPTION,\n\t    long_description_content_type=\"text/markdown\",\n\t    include_package_data=True,\n", "    packages=[\"roughpy\"],\n\t    package_data={\n\t        \"roughpy\": [\"py.typed\"]\n\t    },\n\t    cmake_process_manifest_hook=filter_cmake_manifests,\n\t    cmake_args=CMAKE_SETTINGS,\n\t    classifiers=[\n\t        \"Development Status :: 3 - Alpha\",\n\t        \"Intended Audience :: Science/Research\",\n\t        \"Intended Audience :: Developers\",\n", "        \"Topic :: Scientific/Engineering :: Mathematics\",\n\t        \"License :: OSI Approved :: BSD License\",\n\t        \"Programming Language :: C++\",\n\t        \"Programming Language :: Python :: 3\",\n\t        \"Programming Language :: Python :: 3.8\",\n\t        \"Programming Language :: Python :: 3.9\",\n\t        \"Programming Language :: Python :: 3.10\",\n\t        \"Programming Language :: Python :: 3.11\",\n\t        \"Operating System :: Microsoft :: Windows\",\n\t        \"Operating System :: POSIX\",\n", "        \"Operating System :: Unix\",\n\t        \"Operating System :: MacOS\"\n\t    ]\n\t)\n"]}
{"filename": "tools/version_from_file.py", "chunked_list": ["#  Copyright (c) 2023 the RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\tfrom __future__ import annotations\n\timport re\n", "from pathlib import Path\n\t__all__ = [\"dynamic_metadata\"]\n\tdef __dir__() -> list[str]:\n\t    return __all__\n\tdef dynamic_metadata(\n\t        fields: frozenset[str],\n\t        settings: dict[str, object] | None\n\t) -> dict[str, str | dict[str, str | None]]:\n\t    if \"version\" not in fields:\n\t        raise ValueError(\"This plugin gets the version\")\n", "    print(fields, settings)\n\t    if \"regex\" in settings:\n\t        regex = settings[\"regex\"]\n\t    else:\n\t        regex = r\"(?P<version>\\d+\\.\\d+\\.\\d+)\"\n\t    version_path = Path(\"VERSION.txt\")\n\t    if version_path.exists():\n\t        version_text = version_path.read_text().strip()\n\t        if (match := re.match(regex, version_text)) is not None:\n\t            version = match.group(\"version\")\n", "        else:\n\t            raise ValueError(\n\t                \"Could not get version from string \" + version_text)\n\t    else:\n\t        version = \"0.0.1\"\n\t    return version\n"]}
{"filename": "tools/python-get-binary-obj-path.py", "chunked_list": ["#  Copyright (c) 2023 Datasig Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\tfrom __future__ import annotations\n\timport importlib.metadata as ilm\n", "from argparse import ArgumentParser\n\tfrom pathlib import Path\n\tfrom typing import Callable, Generator, Iterable\n\tCMAKE_LIST_SEP = ';'\n\tMatcher = Callable[[ilm.PackagePath], bool]\n\tdef find_component(package: str, matcher: Matcher) -> Generator[Path]:\n\t    try:\n\t        dist = ilm.distribution(package)\n\t        yield from (f.locate().resolve() for f in dist.files\n\t                    if matcher(f))\n", "    except ilm.PackageNotFoundError:\n\t        pass\n\tdef _flatten(gens: Iterable[Generator[Path]]) -> Generator[Path]:\n\t    for gen in gens:\n\t        yield from gen\n\tdef _trim_to_path_dir(path: Path, fragment: Path) -> Path:\n\t    prefix = path\n\t    for l, _ in zip(path.parents, fragment.parents):\n\t        prefix = l\n\t    return prefix\n", "def _trim_to_directory(paths: Generator[Path], pat: Path) -> Generator[Path]:\n\t    for p in paths:\n\t        yield _trim_to_path_dir(p, pat)\n\tdef make_name_matcher(name: str) -> Matcher:\n\t    def matcher(path: ilm.PackagePath) -> bool:\n\t        return path.stem == name\n\t    return matcher\n\tdef make_fragment_matcher(fragment: str) -> Matcher:\n\t    def matcher(path: ilm.PackagePath) -> bool:\n\t        return path.match(fragment)\n", "    return matcher\n\tdef make_matcher(pattern: str, match_name: bool) -> Matcher:\n\t    if match_name:\n\t        return make_name_matcher(pattern)\n\t    return make_fragment_matcher(pattern)\n\tdef trim_count(count: int, paths: Generator[Path]) -> Generator[Path]:\n\t    for _, p in zip(range(count), paths):\n\t        yield p\n\tdef main():\n\t    parser = ArgumentParser()\n", "    parser.add_argument(\"package\", type=str)\n\t    parser.add_argument(\"pattern\", nargs=\"+\")\n\t    parser.add_argument(\n\t        \"-e\", \"--exitcode\",\n\t        action=\"store_true\",\n\t        help=\"Return exit code on failure\"\n\t    )\n\t    parser.add_argument(\n\t        \"-n\", \"--name\",\n\t        action=\"store_true\",\n", "        help=\"Find by file name\"\n\t    )\n\t    parser.add_argument(\n\t        \"-d\", \"--directory\",\n\t        action=\"store_true\",\n\t        help=\"Find the containing directory\"\n\t    )\n\t    parser.add_argument(\n\t        \"-c\", \"--count\",\n\t        type=int,\n", "        default=0,\n\t        nargs=1,\n\t        required=False,\n\t        help=\"Limit the number of entries returned\"\n\t    )\n\t    args = parser.parse_args()\n\t    paths = []\n\t    for pat in args.pattern:\n\t        matcher = make_matcher(pat, args.name)\n\t        found = find_component(args.package, matcher)\n", "        if not found and args.exitcode:\n\t            parser.exit(1)\n\t        if args.count > 0:\n\t            found = trim_count(args.count, found)\n\t        if args.directory:\n\t            found = _trim_to_directory(found, Path(pat))\n\t        paths.extend(found)\n\t    if not paths and args.exitcode:\n\t        parser.exit(1)\n\t    print(CMAKE_LIST_SEP.join(map(str, paths)))\n", "if __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["import pytest\n\tfrom numpy.random import default_rng\n\tfrom roughpy import _roughpy\n\t@pytest.fixture(params=range(2, 6))\n\tdef width(request):\n\t    return request.param\n\t@pytest.fixture(params=range(2, 6))\n\tdef depth(request):\n\t    return request.param\n\t@pytest.fixture\n", "def rng():\n\t    return default_rng(12345)\n\t@pytest.fixture\n\tdef tensor_size(width, depth):\n\t    s = depth\n\t    r = 1\n\t    while s:\n\t        r *= width\n\t        r += 1\n\t        s -= 1\n", "    return r\n\t@pytest.fixture(params=[_roughpy.DenseVector, _roughpy.SparseVector])\n\tdef vec_type(request):\n\t    return request.param\n\t@pytest.fixture(params=[_roughpy.DPReal, _roughpy.SPReal])\n\tdef coeff_type(request):\n\t    return request.param\n"]}
{"filename": "tests/streams/test_tick_stream.py", "chunked_list": ["#  Copyright (c) 2023 the RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\timport pytest\n\tfrom roughpy import DPReal, Lie, RealInterval, TickStream\n", "DATA_FORMATS = [\n\t    {\n\t        1.0: [\n\t            (\"first\", \"increment\", 1.0),\n\t            (\"second\", \"increment\", 1.0)\n\t        ]\n\t    },\n\t    {\n\t        1.0: {\n\t            \"first\": (\"increment\", 1.0),\n", "            \"second\": (\"increment\", 1.0)\n\t        }\n\t    },\n\t    {\n\t        1.0: [\n\t            {\"label\": \"first\", \"type\": \"increment\", \"data\": 1.0},\n\t            {\"label\": \"second\", \"type\": \"increment\", \"data\": 1.0},\n\t        ]\n\t    },\n\t    {\n", "        1.0: {\n\t            \"first\": {\"type\": \"increment\", \"data\": 1.0},\n\t            \"second\": {\"type\": \"increment\", \"data\": 1.0},\n\t        }\n\t    },\n\t    [\n\t        (1.0, \"first\", \"increment\", 1.0),\n\t        (1.0, \"second\", \"increment\", 1.0),\n\t    ],\n\t    [\n", "        (1.0, (\"first\", \"increment\", 1.0)),\n\t        (1.0, (\"second\", \"increment\", 1.0)),\n\t    ],\n\t    [\n\t        (1.0, {\"label\": \"first\", \"type\": \"increment\", \"data\": 1.0}),\n\t        (1.0, {\"label\": \"second\", \"type\": \"increment\", \"data\": 1.0}),\n\t    ],\n\t    [\n\t        (1.0, [\n\t            (\"first\", \"increment\", 1.0),\n", "            (\"second\", \"increment\", 1.0),\n\t        ])\n\t    ],\n\t    [\n\t        (1.0, [\n\t            {\"label\": \"first\", \"type\": \"increment\", \"data\": 1.0},\n\t            {\"label\": \"second\", \"type\": \"increment\", \"data\": 1.0},\n\t        ])\n\t    ],\n\t    [\n", "        (1.0, {\n\t            \"first\": (\"increment\", 1.0),\n\t            \"second\": (\"increment\", 1.0),\n\t        })\n\t    ],\n\t    {\n\t        1.0: [\n\t            (\"first\", \"increment\", 1.0),\n\t            {\n\t                \"label\": \"second\",\n", "                \"type\": \"increment\",\n\t                \"data\": 1.0\n\t            }\n\t        ]\n\t    },\n\t    {\n\t        1.0: [\n\t            (\"first\", \"increment\", 1.0),\n\t            {\n\t                \"second\": (\"increment\", 1.0)\n", "            }\n\t        ]\n\t    },\n\t    {\n\t        1.0: [\n\t            (\"first\", \"increment\", 1.0),\n\t            {\n\t                \"second\": {\n\t                    \"type\": \"increment\",\n\t                    \"data\": 1.0\n", "                }\n\t            }\n\t        ]\n\t    },\n\t    {\n\t        1.0: {\n\t            \"first\": (\"increment\", 1.0),\n\t            \"second\": {\n\t                \"type\": \"increment\",\n\t                \"data\": 1.0\n", "            }\n\t        }\n\t    }\n\t]\n\t@pytest.mark.parametrize(\"data\", DATA_FORMATS)\n\tdef test_construct_tick_path_from_data(data):\n\t    stream = TickStream.from_data(data, width=2, depth=2, dtype=DPReal)\n\t    assert stream.width == 2\n\t    lsig = stream.log_signature(RealInterval(0.0, 2.0), 2)\n\t    expected = Lie([1.0, 1.0, 0.5], width=2, depth=2, dtype=DPReal)\n", "    assert lsig == expected, f\"{lsig} == {expected}\"\n\tdef test_construct_tick_stream_with_time(rng):\n\t    data = DATA_FORMATS[0]\n\t    stream = TickStream.from_data(data, width=2, depth=2, include_time=True,\n\t                                  dtype=DPReal)\n\t    assert stream.width == 3\n"]}
{"filename": "tests/streams/test_lie_increment_path.py", "chunked_list": ["import functools\n\timport itertools\n\timport operator\n\timport numpy as np\n\timport pytest\n\tfrom numpy.testing import assert_array_almost_equal, assert_array_equal\n\timport roughpy\n\tfrom roughpy import FreeTensor, Lie, RealInterval\n\tfrom roughpy import LieIncrementStream\n\tdef path(*args, **kwargs):\n", "    return LieIncrementStream.from_increments(*args, **kwargs)\n\t@pytest.fixture(params=[0, 1, 5, 10, 20, 50, 100])\n\tdef length(request):\n\t    return request.param\n\t@pytest.fixture\n\tdef tick_indices(length):\n\t    return np.linspace(0.0, 1.0, length)\n\t@pytest.fixture\n\tdef tick_data(rng, length, width):\n\t    return rng.normal(0.0, 1.0, size=(length, width))\n", "# @pytest.fixture\n\t# def tick_data_w_indices(rng, tick_indices, width, length):\n\t#     if length == 0:\n\t#         return np.array([[]])\n\t#\n\t#     return np.concatenate([\n\t#         tick_indices.reshape((length, 1)),\n\t#         rng.normal(0.0, 1.0, size=(length, width))\n\t#     ], axis=1)\n\t# def test_path_width_depth_with_data(tick_data_w_indices, width, depth):\n", "#     p = path(tick_data_w_indices, width=width, depth=depth)\n\t#\n\t#     assert p.width == width\n\t#     assert p.depth == depth\n\t#     assert isinstance(p.domain(), esig.real_interval)\n\t#     assert p.domain() == RealInterval(-float(\"inf\"), float(\"inf\"))\n\t@pytest.mark.parametrize(\"data\",\n\t                         [np.array([]), np.array([[]]), np.array([[], []])])\n\tdef test_path_creation_odd_data(data):\n\t    p = path(data, width=2, depth=2)\n", "    assert p.width == 2\n\t# def test_path_creation_flat_length_1_path(width):\n\t#     width + 1 because we do not supply indices\n\t# data = np.array([1.0] * (width + 1))\n\t# p = path(data, width=width, depth=2)\n\t#\n\t# assert p.width == width\n\t# assert p.depth == 2\n\t# needs fix for broadcasting to the correct shape in function\n\t# assert data.shape == (width+1,)\n", "# def test_path_creation_flat_length_1_path_no_depth(width):\n\t#     width + 1 because we do not supply indices\n\t# data = np.array([1.0] * (width + 1))\n\t# p = path(data, width=width)\n\t#\n\t# assert p.width == width\n\t# assert p.depth == 2\n\t# needs fix for broadcasting to the correct shape in function\n\t# assert data.shape == (width+1,)\n\t# @pytest.mark.skip(\"Broken?\")\n", "# def test_path_restrict_tick_path(tick_data_w_indices, width):\n\t#     p = path(tick_data_w_indices, width=width, depth=2)\n\t#\n\t#     if p.domain() != RealInterval(0.0, 1.0):\n\t#         pytest.skip(\"Non-standard domain\")\n\t#\n\t#     p.restrict(RealInterval(0.0, 0.5))\n\t#\n\t#     assert p.domain() == RealInterval(0.0, 0.5)\n\tdef test_tick_path_signature_calc_accuracy():\n", "    data = np.array([[1.0, 2.5]])\n\t    p = path(data, width=2, depth=2, indices=np.array([0.7]))\n\t    r1 = p.signature(0.0, 0.8, 0.5)\n\t    expected1 = FreeTensor(np.array([1.0]), width=2, depth=2)\n\t    assert r1 == expected1, f\"expected {expected1} but was {r1}\"\n\t    r2 = p.signature(0.0, 0.8, 0.25)\n\t    expected2 = FreeTensor(np.array([0.0, 1.0, 2.5]), width=2, depth=2).exp()\n\t    assert r2 == expected2, f\"expected {expected2} but was {r2}\"\n\t# def test_tick_path_with_time(tick_data_w_indices, width):\n\t#     if not tick_data_w_indices.size:\n", "#         pytest.skip(\"empty array not valid data.\")\n\t#     p = path(tick_data_w_indices, depth=2, include_time=True)\n\t#\n\t#     assert p.width == width + 1\n\t# def test_tick_path_with_time_no_depth(tick_data_w_indices, width):\n\t#     if not tick_data_w_indices.size:\n\t#         pytest.skip(\"empty array not valid data.\")\n\t#     p = path(tick_data_w_indices, include_time=True)\n\t#\n\t#     assert p.width == width + 1\n", "#     assert p.depth == 2\n\t@pytest.fixture(params=[2, 5, 10, 25, 100])\n\tdef t_values(request):\n\t    return np.arange(0.0, 2.0, 2.0 / request.param) + 2.0 / request.param\n\t@pytest.fixture\n\tdef known_path_data(t_values, width):\n\t    t = np.arange(1.0, width + 1) * (2.0 / len(t_values))\n\t    return np.tensordot(np.ones(len(t_values)), t, axes=0)\n\t@pytest.fixture\n\tdef solution_signature(width, depth, tensor_size):\n", "    letters = list(range(1, width + 1))\n\t    def sig_func(a, b):\n\t        rv = np.zeros(tensor_size)\n\t        rv[0] = 1.0\n\t        for let in letters:\n\t            rv[let] = let * (b - a)\n\t        idx = width\n\t        factor = 1.0\n\t        for d in range(2, depth + 1):\n\t            factor /= d\n", "            for data in itertools.product(letters, repeat=d):\n\t                idx += 1\n\t                rv[idx] = factor * functools.reduce(operator.mul, data, 1) * (\n\t                        b - a) ** d\n\t        return rv\n\t    return sig_func\n\tdef test_tpath_known_signature_calc(width, depth, t_values, known_path_data,\n\t                                    solution_signature):\n\t    p = path(known_path_data, indices=t_values, width=width, depth=depth)\n\t    expected = FreeTensor(solution_signature(0.0, 2.0), width=width,\n", "                          depth=depth)\n\t    assert_array_almost_equal(p.signature(0.0, 3.125), expected)\n\tdef test_tpath_known_signature_calc_with_context(width, depth, t_values,\n\t                                                 known_path_data,\n\t                                                 solution_signature):\n\t    p = path(known_path_data, indices=t_values, width=width, depth=2)\n\t    expected = FreeTensor(solution_signature(0.0, 2.0), width=width,\n\t                          depth=depth)\n\t    assert_array_almost_equal(\n\t        np.array(p.signature(0.0, 3.125, depth=depth)),\n", "        np.array(expected))\n\tdef test_tick_sig_deriv_width_3_depth_1_let_2_perturb():\n\t    p = path(np.array([[0.2, 0.4, 0.6]]), indices=np.array([0.0]), width=3,\n\t             depth=1)\n\t    perturbation = Lie(np.array([0.0, 1.0, 0.0]), width=3, depth=1)\n\t    interval = RealInterval(0.0, 1.0)\n\t    d = p.signature_derivative(interval, perturbation, 1)\n\t    expected = FreeTensor(np.array([0.0, 0.0, 1.0, 0.0]), width=3, depth=1)\n\t    assert d == expected, f\"expected {expected} but got {d}\"\n\tdef test_tick_sig_deriv_width_3_depth_2_let_2_perturb():\n", "    p = path(np.array([[0.2, 0.4, 0.6]]), indices=np.array([0.0]), width=3,\n\t             depth=2)\n\t    perturbation = Lie(np.array([0.0, 1.0, 0.0]), width=3, depth=2)\n\t    interval = RealInterval(0.0, 1.0)\n\t    d = p.signature_derivative(interval, perturbation, 1)\n\t    expected = FreeTensor(np.array([0.0, 0.0, 1.0, 0.0,\n\t                                    0.0, 0.1, 0.0,\n\t                                    0.1, 0.4, 0.3,\n\t                                    0.0, 0.3, 0.0\n\t                                    ]), width=3, depth=2)\n", "    assert d == expected, f\"expected {expected} but got {d}\"\n\tdef test_tick_sig_deriv_width_3_depth_2_let_2_perturb_with_context():\n\t    p = path(np.array([[0.2, 0.4, 0.6]]), indices=np.array([0.0]), width=3,\n\t             depth=2)\n\t    perturbation = Lie(np.array([0.0, 1.0, 0.0]), width=3, depth=2)\n\t    interval = RealInterval(0.0, 1.0)\n\t    d = p.signature_derivative(interval, perturbation, 1, depth=2)\n\t    expected = FreeTensor(np.array([0.0, 0.0, 1.0, 0.0,\n\t                                    0.0, 0.1, 0.0,\n\t                                    0.1, 0.4, 0.3,\n", "                                    0.0, 0.3, 0.0\n\t                                    ]), width=3, depth=2)\n\t    assert d == expected, f\"expected {expected} but got {d}\"\n\tdef test_tick_path_sig_derivative(width, depth, tick_data, tick_indices, rng):\n\t    p = path(tick_data, indices=tick_indices, width=width, depth=depth)\n\t    def lie():\n\t        return Lie(rng.uniform(0.0, 5.0, size=(width,)), width=width,\n\t                   depth=depth)\n\t    perturbations = [\n\t        (RealInterval(0.0, 0.3), lie()),\n", "        (RealInterval(0.3, 0.6), lie()),\n\t        (RealInterval(0.6, 1.1), lie()),\n\t    ]\n\t    result = p.signature_derivative(perturbations, 5)\n\t    expected = FreeTensor(np.array([0.0]), width=width, depth=depth)\n\t    for ivl, per in perturbations:\n\t        expected *= p.signature(ivl, 5)\n\t        expected += p.signature_derivative(ivl, per, 5)\n\t    # assert result == expected\n\t    assert_array_almost_equal(result, expected)\n", "def test_lie_incr_stream_from_randints(rng):\n\t    array = rng.integers(0, 5, size=(4, 3))\n\t    stream = LieIncrementStream.from_increments(array, width=3, depth=2)\n\t    sig = stream.signature(RealInterval(0.0, 5.0), 2)\n\t    assert_array_equal(np.array(sig)[:4],\n\t                       np.hstack([[1.0], np.sum(array, axis=0)[:]]))\n\tdef test_lie_incr_stream_from_randints_no_deduction(rng):\n\t    array = rng.integers(0, 5, size=(4, 3))\n\t    stream = LieIncrementStream.from_increments(array, width=3, depth=2,\n\t                                                dtype=roughpy.DPReal)\n", "    sig = stream.signature(RealInterval(0.0, 5.0), 2)\n\t    assert_array_equal(np.array(sig)[:4],\n\t                       np.hstack([[1.0], np.sum(array, axis=0)[:]]))\n\tdef test_lie_incr_stream_from_randints_transposed(rng):\n\t    array = rng.integers(0, 5, size=(4, 3))\n\t    stream = LieIncrementStream.from_increments(array.T, width=3, depth=2)\n\t    sig = stream.signature(RealInterval(0.0, 5.0), 2)\n\t    assert_array_equal(np.array(sig)[:4],\n\t                       np.hstack([[1.0], np.sum(array, axis=0)[:]]))\n\tdef test_lie_incr_stream_from_randints_no_deduction_transposed(rng):\n", "    array = rng.integers(0, 5, size=(4, 3))\n\t    stream = LieIncrementStream.from_increments(array.T, width=3, depth=2,\n\t                                                dtype=roughpy.DPReal)\n\t    sig = stream.signature(RealInterval(0.0, 5.0), 2)\n\t    assert_array_equal(np.array(sig)[:4],\n\t                       np.hstack([[1.0], np.sum(array, axis=0)[:]]))\n"]}
{"filename": "tests/streams/__init__.py", "chunked_list": []}
{"filename": "tests/streams/test_schema.py", "chunked_list": ["#  Copyright (c) 2023 Datasig Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\timport pytest\n\tfrom roughpy import StreamSchema\n", "@pytest.fixture\n\tdef sample_data_dict():\n\t    return {\n\t        1.0: (\"first\", 1.0),\n\t        2.0: (\"first\", 2.0),\n\t        3.0: (\"second\", \"cat1\"),\n\t        4.0: (\"second\", \"cat2\"),\n\t        5.0: (\"third\", \"value\", 1.0),\n\t    }\n\t@pytest.fixture\n", "def sample_data_seq(sample_data_dict):\n\t    return [(ts, *args) for ts, args in sample_data_dict.items()]\n\tdef test_schema_from_dict(sample_data_dict):\n\t    schema = StreamSchema.from_data(sample_data_dict)\n\t    assert schema.get_labels() == [\n\t        \"first\",\n\t        \"second:cat1\",\n\t        \"second:cat2\",\n\t        \"third\",\n\t    ]\n", "def test_schema_from_seq(sample_data_seq):\n\t    schema = StreamSchema.from_data(sample_data_seq)\n\t    assert schema.get_labels() == [\n\t        \"first\",\n\t        \"second:cat1\",\n\t        \"second:cat2\",\n\t        \"third\",\n\t    ]\n\t@pytest.fixture\n\tdef json_like_schema():\n", "    return [\n\t        {\n\t            \"label\": \"first\",\n\t            \"type\": \"increment\"\n\t        },\n\t        {\n\t            \"label\": \"second\",\n\t            \"type\": \"value\",\n\t        },\n\t        {\n", "            \"label\": \"third\",\n\t            \"type\": \"categorical\",\n\t            \"categories\": [\"cat1\", \"cat2\"]\n\t        },\n\t    ]\n\tdef test_parse_jsonlike(json_like_schema):\n\t    schema = StreamSchema.parse(json_like_schema)\n\t    assert schema.get_labels() == [\n\t        \"first\",\n\t        # \"second:lead\",\n", "        # \"second:lag\",\n\t        \"second\",\n\t        \"third:cat1\",\n\t        \"third:cat2\",\n\t    ]\n\tDATA_FORMATS = [\n\t    {\n\t        1.0: [\n\t            (\"first\", \"increment\", 1.0),\n\t            (\"second\", \"increment\", 1.0)\n", "        ]\n\t    },\n\t    {\n\t        1.0: {\n\t            \"first\": (\"increment\", 1.0),\n\t            \"second\": (\"increment\", 1.0)\n\t        }\n\t    },\n\t    {\n\t        1.0: [\n", "            {\"label\": \"first\", \"type\": \"increment\", \"data\": 1.0},\n\t            {\"label\": \"second\", \"type\": \"increment\", \"data\": 1.0},\n\t        ]\n\t    },\n\t    {\n\t        1.0: {\n\t            \"first\": {\"type\": \"increment\", \"data\": 1.0},\n\t            \"second\": {\"type\": \"increment\", \"data\": 1.0},\n\t        }\n\t    },\n", "    [\n\t        (1.0, \"first\", \"increment\", 1.0),\n\t        (1.0, \"second\", \"increment\", 1.0),\n\t    ],\n\t    [\n\t        (1.0, (\"first\", \"increment\", 1.0)),\n\t        (1.0, (\"second\", \"increment\", 1.0)),\n\t    ],\n\t    [\n\t        (1.0, {\"label\": \"first\", \"type\": \"increment\", \"data\": 1.0}),\n", "        (1.0, {\"label\": \"second\", \"type\": \"increment\", \"data\": 1.0}),\n\t    ],\n\t    [\n\t        (1.0, [\n\t            (\"first\", \"increment\", 1.0),\n\t            (\"second\", \"increment\", 1.0),\n\t        ])\n\t    ],\n\t    [\n\t        (1.0, [\n", "            {\"label\": \"first\", \"type\": \"increment\", \"data\": 1.0},\n\t            {\"label\": \"second\", \"type\": \"increment\", \"data\": 1.0},\n\t        ])\n\t    ],\n\t    [\n\t        (1.0, {\n\t            \"first\": (\"increment\", 1.0),\n\t            \"second\": (\"increment\", 1.0),\n\t        })\n\t    ],\n", "    {\n\t        1.0: [\n\t            (\"first\", \"increment\", 1.0),\n\t            {\n\t                \"label\": \"second\",\n\t                \"type\": \"increment\",\n\t                \"data\": 1.0\n\t            }\n\t        ]\n\t    },\n", "    {\n\t        1.0: [\n\t            (\"first\", \"increment\", 1.0),\n\t            {\n\t                \"second\": (\"increment\", 1.0)\n\t            }\n\t        ]\n\t    },\n\t    {\n\t        1.0: [\n", "            (\"first\", \"increment\", 1.0),\n\t            {\n\t                \"second\": {\n\t                    \"type\": \"increment\",\n\t                    \"data\": 1.0\n\t                }\n\t            }\n\t        ]\n\t    },\n\t    {\n", "        1.0: {\n\t            \"first\": (\"increment\", 1.0),\n\t            \"second\": {\n\t                \"type\": \"increment\",\n\t                \"data\": 1.0\n\t            }\n\t        }\n\t    }\n\t]\n\t@pytest.fixture(params=DATA_FORMATS)\n", "def tick_data(request):\n\t    return request.param\n\tdef test_parse_schema_from_data(tick_data):\n\t    schema = StreamSchema.from_data(tick_data)\n\t    assert schema.width() == 2\n\t    assert schema.get_labels() == [\"first\", \"second\"]\n\tSCHEMA_SPEC_WITH_OPTIONS = [\n\t    [\n\t        {\n\t            \"label\": \"first\",\n", "            \"type\": \"value\",\n\t            \"lead_lag\": True\n\t        },\n\t        {\n\t            \"label\": \"second\",\n\t            \"type\": \"value\",\n\t            \"lead_lag\": False\n\t        }\n\t    ],\n\t    {\n", "        \"first\": {\n\t            \"type\": \"value\",\n\t            \"lead_lag\": True\n\t        },\n\t        \"second\": {\n\t            \"type\": \"value\",\n\t            \"lead_lag\": False\n\t        }\n\t    },\n\t    [\n", "        (\"first\", \"value\", {\"lead_lag\": True}),\n\t        (\"second\", \"value\", {\"lead_lag\": False}),\n\t    ]\n\t]\n\t@pytest.mark.parametrize(\"spec\", SCHEMA_SPEC_WITH_OPTIONS)\n\tdef test_schema_construction_with_options(spec):\n\t    schema = StreamSchema.parse(spec)\n\t    assert schema.width() == 3\n\t    assert schema.get_labels() == [\"first:lead\", \"first:lag\", \"second\"]\n"]}
{"filename": "tests/streams/test_sound_path.py", "chunked_list": ["#  Copyright (c) 2023 RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\timport os\n\timport pytest\n", "import roughpy\n\t@pytest.fixture(params=[\"test.flac\", \"test.mp3\", \"test.wav\"])\n\tdef sound_file(request):\n\t    return os.path.join(os.path.dirname(__file__), \"audio\", request.param)\n\t@pytest.fixture\n\tdef sound_stream(sound_file):\n\t    return roughpy.ExternalDataStream.from_uri(sound_file, depth=2)\n\tdef test_sound_stream_width_deduction(sound_stream):\n\t    assert sound_stream.width == 2\n\tdef test_sound_stream_ctype_deduction(sound_stream):\n", "    assert sound_stream.dtype == roughpy.DPReal\n\tdef test_sound_stream_support_deduction(sound_stream):\n\t    assert sound_stream.support.inf() == 0.0\n\t    assert sound_stream.support.sup() == pytest.approx(1.764, abs=0.0005)\n\tdef test_sound_stream_logsig(sound_stream):\n\t    lsig = sound_stream.log_signature(5)\n\t    assert lsig.size() == sound_stream.ctx.lie_size(2)\n\tdef test_sound_stream_value_channels_logsig(sound_file):\n\t    sound_stream = roughpy.ExternalDataStream.from_uri(\n\t        sound_file,\n", "        channel_types=[roughpy.ValueChannel, roughpy.ValueChannel],\n\t        depth=2\n\t    )\n\t    lsig = sound_stream.log_signature(5)\n\t    assert lsig.size() == sound_stream.ctx.lie_size(2)\n"]}
{"filename": "tests/streams/test_function_path.py", "chunked_list": ["import functools\n\timport itertools\n\timport operator\n\timport numpy as np\n\timport pytest\n\tfrom numpy.testing import assert_array_almost_equal\n\tskip = True\n\tfrom roughpy import RealInterval, FreeTensor, Lie\n\timport roughpy as rp\n\tdef path(*args, **kwargs):\n", "    return rp.FunctionStream.from_function(*args, **kwargs)\n\t# @pytest.mark.skipif(skip, reason=\"path type not available\")\n\tdef test_function_path_signature_calc_accuracy():\n\t    def func(t, ctx):\n\t        if t >= 0.5:\n\t            return Lie(np.array([t - 0.5, t - 0.5]), ctx=ctx)\n\t        return Lie(np.array([0.0, 0.0]), ctx=ctx)\n\t    p = path(func, width=2, depth=2, dtype=rp.DPReal)\n\t    r1 = p.signature(0.0, 0.8, 1)\n\t    expected1 = FreeTensor(np.array([1.0]), width=2, depth=2)\n", "    assert r1 == expected1\n\t    r2 = p.signature(0.0, 0.8, 2)  # [0, 0.5), [0.5, 0.75)\n\t    expected2 = p.ctx.lie_to_tensor(func(0.75, p.ctx)).exp()\n\t    assert r2 == expected2, f\"{r2} {expected2}\"\n\t@pytest.fixture\n\tdef solution_signature(width, depth, tensor_size):\n\t    letters = list(range(1, width + 1))\n\t    def sig_func(a, b):\n\t        rv = np.zeros(tensor_size)\n\t        rv[0] = 1.0\n", "        for let in letters:\n\t            rv[let] = let * (b - a)\n\t        idx = width\n\t        factor = 1.0\n\t        for d in range(2, depth + 1):\n\t            factor /= d\n\t            for data in itertools.product(letters, repeat=d):\n\t                idx += 1\n\t                rv[idx] = factor * functools.reduce(operator.mul, data, 1) * (\n\t                            b - a) ** d\n", "        return rv\n\t    return sig_func\n\tdef test_fpath_known_signature_calc(width, depth, solution_signature):\n\t    def func(t, ctx):\n\t        return Lie(np.arange(1.0, width + 1) * t, ctx=ctx)\n\t    p = path(func, width=width, depth=depth, dtype=rp.DPReal)\n\t    expected = FreeTensor(solution_signature(0.0, 2.0), ctx=p.ctx)\n\t    assert_array_almost_equal(p.signature(0.0, 2.0, 0.0), expected)\n\t@pytest.fixture\n\tdef deriv_function_path():\n", "    def func(t, ctx):\n\t        if t > 0.0:\n\t            return Lie(np.array([0.2, 0.4, 0.6]), ctx=ctx)\n\t        return Lie(np.array([0.0, 0.0, 0.0]), ctx=ctx)\n\t    return func\n\tdef test_func_sig_deriv_s_width_3_depth_1_let_2_perturb(deriv_function_path):\n\t    p = path(deriv_function_path, width=3, depth=1, dtype=rp.DPReal)\n\t    perturbation = Lie(np.array([0.0, 1.0, 0.0]), ctx=p.ctx)\n\t    interval = RealInterval(0.0, 1.0)\n\t    d = p.signature_derivative(interval, perturbation, 1)\n", "    expected = FreeTensor(np.array([0.0, 0.0, 1.0, 0.0]), ctx=p.ctx)\n\t    assert d == expected\n\tdef test_func_sig_deriv_s_width_3_depth_2_let_2_perturb(deriv_function_path):\n\t    p = path(deriv_function_path, width=3, depth=2, dtype=rp.DPReal)\n\t    perturbation = Lie(np.array([0.0, 1.0, 0.0]), ctx=p.ctx)\n\t    interval = RealInterval(0.0, 1.0)\n\t    d = p.signature_derivative(interval, perturbation, 1)\n\t    expected = FreeTensor(np.array([0.0, 0.0, 1.0, 0.0,\n\t                                    0.0, 0.1, 0.0,\n\t                                    0.1, 0.4, 0.3,\n", "                                    0.0, 0.3, 0.0\n\t                                    ]), ctx=p.ctx)\n\t    assert_array_almost_equal(p.log_signature(interval, 1),\n\t                              np.array([0.2, 0.4, 0.6, 0.0, 0.0, 0.0]))\n\t    assert_array_almost_equal(d, expected)\n\tdef test_func_sig_deriv_m_width_3_depth_1_let_2_perturb(deriv_function_path):\n\t    p = path(deriv_function_path, width=3, depth=1, dtype=rp.DPReal)\n\t    perturbation = Lie(np.array([0.0, 1.0, 0.0]), ctx=p.ctx)\n\t    interval = RealInterval(0.0, 1.0)\n\t    d = p.signature_derivative([(interval, perturbation)], 1)\n", "    expected = FreeTensor(np.array([0.0, 0.0, 1.0, 0.0]), ctx=p.ctx)\n\t    assert_array_almost_equal(d, expected)\n\t    # assert d == expected\n\tdef test_func_sig_deriv_m_width_3_depth_2_let_2_perturb(deriv_function_path):\n\t    p = path(deriv_function_path, width=3, depth=2, dtype=rp.DPReal)\n\t    perturbation = Lie(np.array([0.0, 1.0, 0.0]), ctx=p.ctx)\n\t    interval = RealInterval(0.0, 1.0)\n\t    d = p.signature_derivative([(interval, perturbation)], 1)\n\t    expected = FreeTensor(np.array([0.0, 0.0, 1.0, 0.0,\n\t                                    0.0, 0.1, 0.0,\n", "                                    0.1, 0.4, 0.3,\n\t                                    0.0, 0.3, 0.0\n\t                                    ]), ctx=p.ctx)\n\t    assert_array_almost_equal(d, expected)\n\t    # assert d == expected\n"]}
{"filename": "tests/streams/test_brownian_stream.py", "chunked_list": ["#  Copyright (c) 2023 the RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\timport pytest\n\tfrom numpy.testing import assert_array_almost_equal\n", "from roughpy import BrownianStream, DPReal, DyadicInterval\n\tCONFIGURATIONS = [\n\t    (2, 2),\n\t    (2, 5),\n\t    (5, 2),\n\t    (10, 2)\n\t]\n\t@pytest.mark.parametrize(\"config\", CONFIGURATIONS)\n\tdef test_brownian_stream_signature_multiplicative(config):\n\t    stream = BrownianStream.with_generator(width=config[0], depth=config[1],\n", "                                           dtype=DPReal)\n\t    di1 = DyadicInterval(0, 0)\n\t    di2 = DyadicInterval(1, 0)\n\t    di3 = DyadicInterval(0, -1)\n\t    left = stream.signature(di1, 5)\n\t    right = stream.signature(di2, 5)\n\t    top = stream.signature(di3, 5)\n\t    assert_array_almost_equal(left * right, top), f\"!={top - left * right}\"\n"]}
{"filename": "tests/streams/test_piecewise_lie_path.py", "chunked_list": ["import pytest\n\tfrom numpy.testing import assert_array_almost_equal\n\tfrom roughpy import DPReal, Lie, PiecewiseAbelianStream, RealInterval, \\\n\t    VectorType, get_context\n\t# skip = True\n\tskip = False\n\tWIDTH = 5\n\tDEPTH = 3\n\t@pytest.fixture(params=[1, 2, 5])\n\tdef count(request):\n", "    return request.param\n\t@pytest.fixture\n\tdef piecewise_intervals(count):\n\t    return [RealInterval(float(i), float(i + 1)) for i in range(count)]\n\t@pytest.fixture\n\tdef piecewise_lie_data(piecewise_intervals, rng):\n\t    return [\n\t        (interval,\n\t         Lie(rng.normal(0.0, 1.0, size=(WIDTH,)), width=WIDTH, depth=DEPTH))\n\t        for interval in piecewise_intervals\n", "    ]\n\t@pytest.fixture\n\tdef piecewise_lie(piecewise_lie_data):\n\t    return PiecewiseAbelianStream.construct(piecewise_lie_data, width=WIDTH,\n\t                                            depth=DEPTH)\n\t@pytest.mark.skipif(skip, reason=\"path type not available\")\n\tdef test_log_signature_full_data(piecewise_lie_data):\n\t    ctx = get_context(WIDTH, DEPTH, DPReal)\n\t    piecewise_lie = PiecewiseAbelianStream.construct(piecewise_lie_data,\n\t                                                     width=WIDTH, depth=DEPTH,\n", "                                                     dtype=DPReal)\n\t    result = piecewise_lie.log_signature(5)\n\t    expected = ctx.cbh([d[1] for d in piecewise_lie_data],\n\t                       vec_type=VectorType.DenseVector)\n\t    # assert result == expected, f\"{expected}\\n{result}\"\n\t    assert_array_almost_equal(expected, result)\n"]}
{"filename": "tests/algebra/test_lie.py", "chunked_list": ["import numpy as np\n\timport pytest\n\tfrom numpy.testing import assert_array_equal\n\timport roughpy\n\tfrom roughpy import DPReal, Lie, get_context\n\t@pytest.fixture\n\tdef rng():\n\t    return np.random.default_rng(12345)\n\t@pytest.fixture\n\tdef lie_size(width, depth):\n", "    ctx = get_context(width, depth, DPReal)\n\t    def func(d=depth):\n\t        return ctx.lie_size(d)\n\t    return func\n\t@pytest.fixture\n\tdef data1(rng, width, depth, lie_size):\n\t    return rng.uniform(0.0, 1.0, size=lie_size())\n\t@pytest.fixture\n\tdef data2(rng, width, depth, lie_size):\n\t    return rng.uniform(1.0, 2.0, size=lie_size())\n", "def test_create_Lie_width_deduction(width, rng):\n\t    l = Lie(rng.uniform(0.0, 1.0, size=width))\n\t    assert l.width == width\n\t    assert l.degree() == 1\n\t    assert l.size() == width\n\tdef test_create_Lie_specified_width(rng, width):\n\t    ctx = get_context(width, 2, DPReal)\n\t    l = Lie(rng.uniform(0.0, 1.0, size=ctx.lie_size(2)), width=width)\n\t    assert l.width == width\n\t    assert l.size() == ctx.lie_size(2)\n", "    assert l.degree() == 2\n\tdef test_lie_create_single_float_fails():\n\t    with pytest.raises(ValueError):\n\t        l = Lie(1.0, width=2, depth=2)\n\tdef test_lie_create_single_int_fails():\n\t    with pytest.raises(ValueError):\n\t        l = Lie(1, width=2, depth=2)\n\tdef test_lie_create_list_ints():\n\t    result = Lie([1, 2, 3], width=3, depth=2)\n\t    assert result.width == 3\n", "    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.DenseVector\n\tdef test_lie_create_list_floats():\n\t    result = Lie([1.0, 2.0, 3.0], width=3, depth=2)\n\t    assert result.width == 3\n\t    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.DenseVector\n\tdef test_Lie_array_roundtrip(width, depth, data1):\n\t    l = Lie(data1, width=width, depth=depth)\n\t    assert_array_equal(data1, l)\n", "def test_Lie_repr(width, depth, data1, lie_size):\n\t    l = Lie(data1, width=width, depth=depth)\n\t    assert repr(l) == f\"Lie({width=}, depth={depth}, ctype=DPReal)\"\n\tdef test_Lie_str():\n\t    width = depth = 2\n\t    l = Lie(np.array([1.0, 2.0, 3.0]), width=width, depth=depth)\n\t    terms = [\n\t        \"1(1)\", \"2(2)\",\n\t        \"3([1,2])\"\n\t    ]\n", "    inner = \" \".join(terms)\n\t    assert str(l) == \"{ \" + inner + \" }\"\n\tdef test_Lie_addition(width, depth, data1, data2):\n\t    l1 = Lie(data1, width=width, depth=depth)\n\t    l2 = Lie(data2, width=width, depth=depth)\n\t    expected = Lie(data1 + data2, width=width, depth=depth)\n\t    assert l1 + l2 == expected\n\tdef test_Lie_subraction(width, depth, data1, data2):\n\t    l1 = Lie(data1, width=width, depth=depth)\n\t    l2 = Lie(data2, width=width, depth=depth)\n", "    expected = Lie(data1 - data2, width=width, depth=depth)\n\t    assert l1 - l2 == expected\n\tdef test_Lie_smul(width, depth, data1):\n\t    l1 = Lie(data1, width=width, depth=depth)\n\t    expected = Lie(2.0 * data1, width=width, depth=depth)\n\t    assert l1 * 2.0 == expected\n\tdef test_Lie_sdiv(width, depth, data1):\n\t    l1 = Lie(data1, width=width, depth=depth)\n\t    expected = Lie(data1 / 2.0, width=width, depth=depth)\n\t    assert l1 / 2.0 == expected\n", "def test_Lie_mul(width):\n\t    ctx = get_context(width, 2, DPReal)\n\t    l1 = Lie(np.array([1.0] + [0.0] * (width - 1)), width=width)\n\t    l2 = Lie(np.array([0.0, 1.0] + [0.0] * (width - 2)), width=width)\n\t    exp_data = np.zeros(ctx.lie_size(2))\n\t    exp_data[width] = 1.0\n\t    expected = Lie(exp_data, width=width)\n\t    assert l1 * l2 == expected\n\tdef test_Lie_iadd(width, depth, data1, data2):\n\t    l1 = Lie(data1, width=width, depth=depth)\n", "    l2 = Lie(data2, width=width, depth=depth)\n\t    expected = Lie(data1 + data2, width=width, depth=depth)\n\t    l1 += l2\n\t    assert l1 == expected\n\tdef test_Lie_isub(width, depth, data1, data2):\n\t    l1 = Lie(data1, width=width, depth=depth)\n\t    l2 = Lie(data2, width=width, depth=depth)\n\t    expected = Lie(data1 - data2, width=width, depth=depth)\n\t    l1 -= l2\n\t    assert l1 == expected\n", "def test_Lie_ismul(width, depth, data1):\n\t    l1 = Lie(data1, width=width, depth=depth)\n\t    expected = Lie(2.0 * data1, width=width, depth=depth)\n\t    l1 *= 2.0\n\t    assert l1 == expected\n\tdef test_Lie_isdiv(width, depth, data1):\n\t    l1 = Lie(data1, width=width, depth=depth)\n\t    expected = Lie(data1 / 2.0, width=width, depth=depth)\n\t    l1 /= 2.0\n\t    assert l1 == expected\n", "def test_Lie_imul(width):\n\t    ctx = get_context(width, 2, DPReal)\n\t    l1 = Lie(np.array([1.0] + [0.0] * (width - 1)), width=width)\n\t    l2 = Lie(np.array([0.0, 1.0] + [0.0] * (width - 2)), width=width)\n\t    exp_data = np.zeros(ctx.lie_size(2))\n\t    exp_data[width] = 1.0\n\t    expected = Lie(exp_data, width=width)\n\t    l1 *= l2\n\t    assert l1 == expected\n"]}
{"filename": "tests/algebra/test_algebra_context.py", "chunked_list": ["import numpy as np\n\timport pytest\n\tfrom roughpy import DPReal, FreeTensor, Lie, get_context as _get_context\n\tdef get_context(width, depth):\n\t    return _get_context(width, depth, DPReal)\n\tdef test_get_context_valid_range(width, depth):\n\t    ctx = get_context(width, depth)\n\t    assert ctx.width == width\n\t    assert ctx.depth == depth\n\t@pytest.mark.skip(\"Currently won't fail\")\n", "def test_get_context_out_of_bounds():\n\t    with pytest.raises(ValueError):\n\t        # utterly absurd values. In the future, we might support arbitrary\n\t        # alphabets but not now.\n\t        ctx = get_context(10000, 10000)\n\tdef test_lie_size(width, depth):\n\t    ctx = get_context(width, depth)\n\t    assert ctx.lie_size(1) == width\n\tdef test_tensor_size(width, depth):\n\t    ctx = get_context(width, depth)\n", "    assert ctx.tensor_size(1) == 1 + width\n\t# @pytest.mark.skip(\"not yet implemented\")\n\tdef test_make_zero_lie(width, depth):\n\t    ctx = get_context(width, depth)\n\t    l = ctx.zero_lie()\n\t    assert isinstance(l, Lie)\n\t    assert l.width == width\n\t    assert l.max_degree == depth\n\t    assert l.size() == 0\n\t    assert l.degree() == 0\n", "# @pytest.mark.skip(\"not yet implemented\")\n\tdef test_lie_to_tensor(width, depth):\n\t    l = Lie(np.array(range(1, width + 1), dtype=np.float64), width=width,\n\t            depth=depth)\n\t    ctx = get_context(width, depth)\n\t    t = ctx.lie_to_tensor(l)\n\t    assert isinstance(t, FreeTensor)\n\t    assert t == FreeTensor(np.array(range(width + 1), dtype=np.float64),\n\t                           width=width,\n\t                           depth=depth)\n", "# @pytest.mark.skip(\"not yet implemented\")\n\tdef test_tensor_to_lie(width, depth):\n\t    t = FreeTensor(np.array(range(width + 1), dtype=np.float64), width=width,\n\t                   depth=depth)\n\t    ctx = get_context(width, depth)\n\t    l = ctx.tensor_to_lie(t)\n\t    assert isinstance(l, Lie)\n\t    assert l == Lie(np.array(range(1, width + 1), dtype=np.float64),\n\t                    width=width,\n\t                    depth=depth)\n"]}
{"filename": "tests/algebra/test_lie_basis.py", "chunked_list": ["import pytest\n\timport roughpy as rp\n\tdef test_lie_basis_iteration():\n\t    ctx = rp.get_context(2, 2, rp.DPReal)\n\t    basis = ctx.lie_basis\n\t    keys = list(basis)\n\t    assert len(keys) == 3\n"]}
{"filename": "tests/algebra/test_tensor_keys.py", "chunked_list": ["import numpy as np\n\timport pytest\n\tfrom roughpy import TensorKey\n\tdef tensor_size_impl(width, depth):\n\t    s = depth\n\t    r = 1\n\t    while s:\n\t        r *= width\n\t        r += 1\n\t        s -= 1\n", "    return r\n\tdef test_TensorKey_str_empty(width, depth):\n\t    key = TensorKey(width=width, depth=depth)\n\t    assert str(key) == \"()\"\n\tdef test_TensorKey_str_letter(width, depth):\n\t    key = TensorKey(1, width=width, depth=depth)\n\t    assert str(key) == \"(1)\"\n\tdef test_TensorKey_str_n_letters(width, depth):\n\t    lets = [1] * depth\n\t    key = TensorKey(lets, width=width, depth=depth)\n", "    assert str(key) == \"(\" + \",\".join(map(str, lets)) + \")\"\n\t@pytest.mark.parametrize(\"wdth, dpth, lttrs\",\n\t                         [(w, d, np.arange(1, w + 1)) for w in range(2, 6) for d\n\t                          in range(2, 6)])\n\tdef test_TensorKey_width_derivation(wdth, dpth, lttrs, rng):\n\t    letters = np.concatenate([[wdth], rng.choice(lttrs, size=(dpth - 1,))])\n\t    rng.shuffle(letters)\n\t    key = TensorKey(letters)\n\t    assert key.width == wdth\n\t    assert key.degree() == dpth\n", "def test_TensorKey_out_of_bounds_fail_single_letter(width):\n\t    with pytest.raises(ValueError):\n\t        key = TensorKey(width + 1, width=width)\n\tdef test_TensorKey_out_of_bounds_fail_multiple_letter(width, depth):\n\t    with pytest.raises(ValueError):\n\t        key = TensorKey([width + 1] + [1] * (depth - 1), width=width)\n\t@pytest.mark.parametrize(\"d, data\", [(d, [1] * d) for d in range(1, 6)])\n\tdef test_TensorKey_depth_derivation(d, data, width):\n\t    key = TensorKey(data, width=width)\n\t    assert key.degree() == d\n", "    assert key.max_degree == d\n\t@pytest.mark.parametrize(\"d, data\", [(d, [1] * (d + 1)) for d in range(1, 6)])\n\tdef test_TensorKey_depth_out_of_bounds_fail(d, data, width):\n\t    with pytest.raises(ValueError):\n\t        key = TensorKey(data, width=width, depth=d)\n\tdef test_TensorKey_from_index(width, depth, tensor_size):\n\t    key = TensorKey(index=tensor_size - 1, width=width, depth=depth)\n\t    assert key == TensorKey([width] * depth, width=width, depth=depth)\n"]}
{"filename": "tests/algebra/__init__.py", "chunked_list": []}
{"filename": "tests/algebra/test_tensor_iterator.py", "chunked_list": ["import itertools\n\timport numpy as np\n\timport pytest\n\tfrom roughpy import FreeTensor, TensorKey\n\t@pytest.fixture\n\tdef TensorKey_iter(width, depth):\n\t    def itr():\n\t        yield TensorKey(width=width, depth=depth)\n\t        for let in range(1, width + 1):\n\t            yield TensorKey(let, width=width, depth=depth)\n", "        for d in range(2, depth + 1):\n\t            for data in itertools.product(range(1, width + 1), repeat=d):\n\t                yield TensorKey(data, width=width, depth=depth)\n\t    return itr\n\t# @pytest.mark.xfail\n\tdef test_FreeTensor_iterator(width, depth, tensor_size, TensorKey_iter):\n\t    data = np.arange(1.0, float(tensor_size + 1))\n\t    tens = FreeTensor(data, width=width, depth=depth)\n\t    result = [(i.key(), i.value()) for i in tens]\n\t    expected = list(zip(TensorKey_iter(), data))\n", "    assert result == expected\n"]}
{"filename": "tests/algebra/test_free_multiply_functions.py", "chunked_list": ["import pytest\n\timport roughpy as rp\n\timport numpy as np\n\tfrom numpy.testing import assert_array_equal, assert_array_almost_equal\n\t@pytest.fixture\n\tdef tensor_context():\n\t    return rp.get_context(2, 2, rp.DPReal)\n\t@pytest.fixture\n\tdef tensor_data(rng, tensor_context):\n\t    def generator():\n", "        return rng.uniform(-1.0, 1.0, size=tensor_context.tensor_size(\n\t            tensor_context.depth))\n\t    return generator\n\tdef test_free_tensor_multiply_shuffles(tensor_data, tensor_context):\n\t    d1 = tensor_data()\n\t    d2 = tensor_data()\n\t    sh1 = rp.ShuffleTensor(d1, ctx=tensor_context)\n\t    sh2 = rp.ShuffleTensor(d2, ctx=tensor_context)\n\t    result = rp.free_multiply(sh1, sh2)\n\t    ft1 = rp.FreeTensor(d1, ctx=tensor_context)\n", "    ft2 = rp.FreeTensor(d2, ctx=tensor_context)\n\t    expected = ft1 * ft2\n\t    assert_array_equal(result, expected)\n\tdef test_shuffle_multiply_two_frees(tensor_data, tensor_context):\n\t    d1 = tensor_data()\n\t    d2 = tensor_data()\n\t    ft1 = rp.FreeTensor(d1, ctx=tensor_context)\n\t    ft2 = rp.FreeTensor(d2, ctx=tensor_context)\n\t    result = rp.shuffle_multiply(ft1, ft2)\n\t    sh1 = rp.ShuffleTensor(d1, ctx=tensor_context)\n", "    sh2 = rp.ShuffleTensor(d2, ctx=tensor_context)\n\t    expected = sh1 * sh2\n\t    assert_array_equal(result, expected)\n\tdef test_adjoint_of_left_multiplication(tensor_data, tensor_context):\n\t    d1 = tensor_data()\n\t    d2 = tensor_data()\n\t    width = tensor_context.width\n\t    depth = tensor_context.depth\n\t    sizes = [0, 1]\n\t    for i in range(depth):\n", "        sizes.append(sizes[-1]*width)\n\t    t1 = rp.FreeTensor(d1, ctx=tensor_context)\n\t    t2 = rp.FreeTensor(d2, ctx=tensor_context)\n\t    result = rp.adjoint_to_free_multiply(t1, t2)\n\t    expected_data = np.zeros(tensor_context.tensor_size(tensor_context.depth))\n\t    for entry in t2:\n\t        key = entry.key()\n\t        for i in range(key.degree()+1):\n\t            left, right = entry.key().split_n(i)\n\t            expected_data[right.to_index()] += d1[left.to_index()]*entry.value().to_float()\n", "    expected = rp.FreeTensor(expected_data, ctx=tensor_context)\n\t    assert_array_equal(result, expected)\n\t    #assert result.size() == t1.size()"]}
{"filename": "tests/algebra/test_lie_keys.py", "chunked_list": ["from roughpy import LieKey\n\tdef test_construct_int():\n\t    key = LieKey(1, width=2, depth=4)\n\t    assert str(key) == \"1\"\n\tdef test_construct_list_pair():\n\t    key = LieKey([1, 2], width=2, depth=4)\n\t    assert str(key) == \"[1,2]\"\n\tdef test_construct_nested_list():\n\t    key = LieKey([1, [1, 2]], width=2, depth=4);\n\t    assert str(key) == \"[1,[1,2]]\"\n", "def test_construct_two_nested_lists():\n\t    key = LieKey([[1, 2], [1, 3]], width=3, depth=4)\n\t    assert str(key) == \"[[1,2],[1,3]]\"\n\tdef test_construct_lots_of_nesting_nesting():\n\t    key = LieKey([[1, [1, 2]], [[1, 2], [1, [1, 3]]]], width=3, depth=4)\n\t    assert str(key) == \"[[1,[1,2]],[[1,2],[1,[1,3]]]]\"\n"]}
{"filename": "tests/algebra/test_free_tensor.py", "chunked_list": ["import numpy as np\n\timport pytest\n\tfrom numpy.testing import assert_array_almost_equal, assert_array_equal\n\timport roughpy\n\tfrom roughpy import FreeTensor, TensorKey\n\tDEPTH_LIMITS = {\n\t    2: range(2, 26),\n\t    3: range(2, 16),\n\t    4: range(2, 11),\n\t    5: range(2, 11),\n", "}\n\t@pytest.fixture\n\tdef rng():\n\t    return np.random.default_rng(12345)\n\t@pytest.fixture\n\tdef rdata(rng, width):\n\t    return rng.uniform(0.0, 1.0, size=1 + width)\n\t@pytest.fixture\n\tdef rtensor(width, rdata):\n\t    return FreeTensor(rdata, width=width)\n", "@pytest.fixture\n\tdef data1(tensor_size, rng):\n\t    return rng.uniform(0.0, 1.0, size=tensor_size)\n\t@pytest.fixture\n\tdef data2(tensor_size, rng):\n\t    return rng.uniform(1.0, 2.0, size=tensor_size)\n\tdef test_create_single_float_no_ctype():\n\t    result = FreeTensor(1.0, width=2, depth=2)\n\t    np_result = np.array(result)\n\t    assert np_result.shape == (1,)\n", "    assert_array_equal(np_result, np.array([1.]))\n\t    assert result.width == 2\n\t    assert result.max_degree == 2\n\tdef test_create_single_int_no_ctype():\n\t    result = FreeTensor(1, width=2, depth=2)\n\t    np_result = np.array(result)\n\t    assert np_result.shape == (1,)\n\t    assert_array_equal(np_result, np.array([1.]))\n\t    assert result.width == 2\n\t    assert result.max_degree == 2\n", "def test_create_list_floats_no_ctype():\n\t    result = FreeTensor([0., 1., 2., 3.], width=3, depth=2)\n\t    np_result = np.array(result)\n\t    assert np_result.shape == (4,)\n\t    assert np_result.dtype == np.float64\n\t    assert_array_equal(np_result, np.array([0., 1., 2., 3.]))\n\t    assert result.width == 3\n\t    assert result.max_degree == 2\n\tdef test_create_list_ints_no_ctype():\n\t    result = FreeTensor([0, 1, 2, 3], width=3, depth=2)\n", "    np_result = np.array(result)\n\t    assert np_result.shape == (4,)\n\t    assert np_result.dtype == np.float64\n\t    assert_array_equal(np_result, np.array([0., 1., 2., 3.]))\n\t    assert result.width == 3\n\t    assert result.max_degree == 2\n\tdef test_create_nested_list_ints_no_ctype():\n\t    with pytest.raises(ValueError):\n\t        result = FreeTensor([[0, 1, 2, 3]], width=3, depth=3)\n\tdef test_create_list_width_deduction():\n", "    result = FreeTensor([0, 1, 2, 3], depth=2)\n\t    assert result.width == 3\n\tclass DLCreateDummy:\n\t    def __init__(self, array):\n\t        self.array = array\n\t    def __dlpack__(self, stream=None):\n\t        return self.array.__dlpack__(stream=stream)\n\t@pytest.mark.skipif(tuple(map(int, np.__version__.split(\".\"))) < (1, 22, 0),\n\t                    reason=\"dlpack support was added in NumPy 1.22\")\n\tdef test_create_dlpack():\n", "    dummy = DLCreateDummy(np.array([0., 1., 2., 3]))\n\t    result = FreeTensor(dummy, width=3, depth=2)\n\t    assert result.width == 3\n\t    assert result.max_degree == 2\n\t    assert_array_equal(result, np.array([0., 1., 2., 3.]))\n\tdef test_create_buffer_doubles():\n\t    from array import array\n\t    data = array('d', [0., 1., 2., 3.])\n\t    result = FreeTensor(data, width=3, depth=2)\n\t    assert result.width == 3\n", "    assert result.max_degree == 2\n\t    assert_array_equal(result, np.array([0., 1., 2., 3.]))\n\tdef test_create_buffer_floats():\n\t    from array import array\n\t    data = array('f', [0., 1., 2., 3.])\n\t    result = FreeTensor(data, width=3, depth=2)\n\t    assert result.width == 3\n\t    assert result.max_degree == 2\n\t    assert_array_equal(result, np.array([0., 1., 2., 3.], dtype=np.float32))\n\tdef test_create_intv_pair():\n", "    result = FreeTensor((1, 1.0), width=2, depth=2)\n\t    assert result.width == 2\n\t    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.SparseVector\n\t    # assert_array_equal(result, np.array([0., 1., 0.]))\n\tdef test_create_list_intv_pairs():\n\t    result = FreeTensor([(1, 1.0), (2, 2.0)], width=2, depth=2)\n\t    assert result.width == 2\n\t    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.SparseVector\n", "    # assert_array_equal(result, np.array([0., 1., 2.]))\n\tdef test_create_tkey_val_pair():\n\t    k1 = TensorKey(1, width=2, depth=2)\n\t    result = FreeTensor((k1, 1.0), width=2, depth=2)\n\t    assert result.width == 2\n\t    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.SparseVector\n\t    # assert result[1] == 1.0\n\tdef test_create_list_tkey_val_pairs():\n\t    data = [\n", "        (TensorKey(1, width=2, depth=2), 1.0),\n\t        (TensorKey(2, width=2, depth=2), 2.0)\n\t    ]\n\t    result = FreeTensor(data, width=2, depth=2)\n\t    assert result.width == 2\n\t    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.SparseVector\n\tdef test_create_list_intv_pairs_dense():\n\t    result = FreeTensor([(1, 1.0), (2, 2.0)], width=2, depth=2,\n\t                        vector_type=roughpy.VectorType.DenseVector)\n", "    assert result.width == 2\n\t    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.DenseVector\n\t    assert_array_equal(result, np.array([0., 1., 2.]))\n\tdef test_create_dict_args():\n\t    result = FreeTensor({1: 1., 2: 2.}, width=2, depth=2)\n\t    assert result.width == 2\n\t    assert result.max_degree == 2\n\t    assert result.storage_type == roughpy.VectorType.SparseVector\n\tdef test_create_list_dicts():\n", "    data = [\n\t        {1: 1., 2: 2.},\n\t        {0: 1., 2: 1.}\n\t    ]\n\t    with pytest.raises(ValueError):\n\t        result = FreeTensor(data, width=2, depth=2)\n\tdef test_create_FreeTensor_width_deduction(width, rdata):\n\t    # Tensor of width n has n+1 elements up to degree 1\n\t    tens = FreeTensor(rdata)\n\t    assert tens.width == width\n", "    assert tens.degree() == 1\n\t    assert tens.size() == rdata.size\n\tdef test_create_FreeTensor_specified_width(rng, width):\n\t    data = rng.uniform(0.0, 1.0, size=1 + width * (1 + width))\n\t    tens = FreeTensor(data, width=width)\n\t    assert tens.width == width\n\t    assert tens.degree() == 2\n\t    assert tens.size() == data.size\n\tdef test_create_FreeTensor_specified_width_incomplete_degree_range(rng, width):\n\t    data = rng.uniform(1.0, 2.0, size=1 + width + 1)\n", "    tens = FreeTensor(data, width=width, depth=2)\n\t    assert tens.width == width\n\t    assert tens.degree() == 2\n\t    assert tens.size() == data.size\n\t    atens = np.array(tens)\n\t    assert atens.size == 1 + width * (1 + width)\n\t    assert_array_almost_equal(tens,\n\t                              np.concatenate((data, np.zeros(width ** 2 - 1))))\n\tdef test_FreeTensor_array_roundtrip(width, rdata, rtensor):\n\t    assert rtensor.width == width\n", "    assert_array_equal(rdata, np.array(rtensor))\n\tdef test_FreeTensor_repr(rng, width, depth, tensor_size):\n\t    data = rng.uniform(0.0, 1.0, size=tensor_size)\n\t    t = FreeTensor(data, width=width, depth=depth)\n\t    assert repr(t) == f\"FreeTensor({width=}, depth={depth}, ctype=DPReal)\"\n\tdef test_FreeTensor_str():\n\t    width = 2\n\t    depth = 2\n\t    t = FreeTensor(np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]), width=width,\n\t                   depth=depth)\n", "    terms = [\n\t        \"1()\",\n\t        \"2(1)\", \"3(2)\",\n\t        \"4(1,1)\", \"5(1,2)\", \"6(2,1)\", \"7(2,2)\"\n\t    ]\n\t    inner = \" \".join(terms)\n\t    assert str(t) == \"{ \" + inner + \" }\"\n\tdef test_FreeTensor_addition(width, depth, data1, data2):\n\t    t1 = FreeTensor(data1, width=width, depth=depth)\n\t    t2 = FreeTensor(data2, width=width, depth=depth)\n", "    expected = FreeTensor(data1 + data2, width=width, depth=depth)\n\t    assert t1 + t2 == expected\n\tdef test_FreeTensor_subraction(width, depth, data1, data2):\n\t    t1 = FreeTensor(data1, width=width, depth=depth)\n\t    t2 = FreeTensor(data2, width=width, depth=depth)\n\t    expected = FreeTensor(data1 - data2, width=width, depth=depth)\n\t    assert t1 - t2 == expected\n\tdef test_FreeTensor_smul(width, rdata):\n\t    t1 = FreeTensor(rdata, width=width)\n\t    expected = FreeTensor(2.0 * rdata, width=width)\n", "    assert t1 * 2.0 == expected\n\tdef test_FreeTensor_rdiv(width, rdata):\n\t    t1 = FreeTensor(rdata, width=width)\n\t    expected = FreeTensor(rdata / 2.0, width=width)\n\t    assert t1 / 2.0 == expected\n\tdef test_FreeTensor_iadd(width, depth, data1, data2):\n\t    t1 = FreeTensor(data1, width=width, depth=depth)\n\t    t2 = FreeTensor(data2, width=width, depth=depth)\n\t    expected = FreeTensor(data1 + data2, width=width, depth=depth)\n\t    t1 += t2\n", "    assert t1 == expected\n\tdef test_FreeTensor_isub(width, depth, data1, data2):\n\t    t1 = FreeTensor(data1, width=width, depth=depth)\n\t    t2 = FreeTensor(data2, width=width, depth=depth)\n\t    expected = FreeTensor(data1 - data2, width=width, depth=depth)\n\t    t1 -= t2\n\t    assert t1 == expected\n\tdef test_FreeTensor_ismul(width, rdata):\n\t    t1 = FreeTensor(rdata, width=width)\n\t    expected = FreeTensor(2.0 * rdata, width=width)\n", "    t1 *= 2.0\n\t    assert t1 == expected\n\tdef test_FreeTensor_irdiv(width, rdata):\n\t    t1 = FreeTensor(rdata, width=width)\n\t    expected = FreeTensor(rdata / 2.0, width=width)\n\t    t1 /= 2.0\n\t    assert t1 == expected\n\tdef test_FreeTensor_mul():\n\t    t1 = FreeTensor(np.array([1.0, 2.0, 3.0]), width=2, depth=2)\n\t    t2 = FreeTensor(np.array([1.0, -1.0, -1.0]), width=2, depth=2)\n", "    expected = FreeTensor(np.array([1.0, 1.0, 2.0, -2.0, -2.0, -3.0, -3.0]),\n\t                          width=2, depth=2)\n\t    assert t1 * t2 == expected\n\tdef test_FreeTensor_imul():\n\t    t1 = FreeTensor(np.array([1.0, 2.0, 3.0]), width=2, depth=2)\n\t    t2 = FreeTensor(np.array([1.0, -1.0, -1.0]), width=2, depth=2)\n\t    expected = FreeTensor(np.array([1.0, 1.0, 2.0, -2.0, -2.0, -3.0, -3.0]),\n\t                          width=2, depth=2)\n\t    t1 *= t2\n\t    assert t1 == expected\n", "def test_FreeTensor_mul_single_letter(width):\n\t    depth = 3\n\t    t = FreeTensor(np.array([0.0, 1.0] + [0.0] * (width - 1)), width=width,\n\t                   depth=depth)\n\t    expected = FreeTensor(np.array(\n\t        [1.0, 1.0] + [0.0] * (width - 1) + [0.5] + [0.0] * (width ** 2 - 1) + [\n\t            1.0 / 6.0] + [0.0] * (width ** 3 - 1)),\n\t                          width=width, depth=depth)\n\t    assert t.exp() == expected\n\tdef test_FreeTensor_exp(width):\n", "    depth = 3\n\t    t = FreeTensor(np.array([1.0] * (1 + width)), width=width, depth=depth)\n\t    tunit = FreeTensor(np.array([1.0]), width=width, depth=depth)\n\t    i = float(t.max_degree)\n\t    expected = FreeTensor(np.array([1.0]), width=width, depth=depth)\n\t    assert expected.degree() == 0\n\t    while i:\n\t        expected *= (t / i)\n\t        expected += tunit\n\t        i -= 1.0\n", "    assert expected.degree() == depth\n\t    assert_array_almost_equal(t.exp(), expected)\n\tdef test_FreeTensor_fmexp(width, depth, data1, data2):\n\t    t1 = FreeTensor(data1, width=width, depth=depth)\n\t    data2[0] = 0.0\n\t    t2 = FreeTensor(data2, width=width, depth=depth)\n\t    expected = t1 * t2.exp()\n\t    t1.fmexp(t2)\n\t    assert_array_almost_equal(t1, expected)\n\tdef test_FreeTensor_log_exp_roundtrip(width, depth, data1):\n", "    data1[0] = 0.0\n\t    t = FreeTensor(data1, width=width, depth=depth)\n\t    assert_array_almost_equal(t.exp().log(), t)\n\tdef _tensor_size(width, depth):\n\t    s = depth\n\t    r = 1\n\t    while s:\n\t        r *= width\n\t        r += 1\n\t        s -= 1\n", "    return r\n\t# def test_FreeTensor_view_into_degree(width, depth, data1):\n\t#     t = FreeTensor(data1, width=width, depth=depth)\n\t#\n\t#     r0 = t.degree_array(0)\n\t#     assert r0 == data1[0]\n\t#\n\t#     for d in range(1, depth+1):\n\t#         r = t.degree_array(d)\n\t#         assert r.shape == tuple([width]*d)\n", "#\n\t#         start, end = _tensor_size(width, d-1), _tensor_size(width, d)\n\t#         assert r.size == end - start\n\t#\n\t#         v = data1[start:end].reshape([width]*d)\n\t#\n\t#         assert_array_equal(r, v)\n\tdef test_coeff_and_vec_type(width, depth, data1, coeff_type, vec_type):\n\t    t = FreeTensor(data1, width=width, depth=depth, dtype=coeff_type,\n\t                   vector_type=vec_type)\n", "    assert t.storage_type == vec_type\n\t    assert t.dtype == coeff_type\n\tdef test_antipode(width, depth, data1, coeff_type, vec_type):\n\t    t = FreeTensor(data1, width=width, depth=depth, dtype=coeff_type,\n\t                   vector_type=vec_type)\n\t    result = t.antipode().antipode()\n\t    assert result == t, f\"{result} {t} {result - t}\"\n"]}
{"filename": "tests/algebra/test_alg_poly_coeffs.py", "chunked_list": ["#  Copyright (c) 2023 the RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\timport roughpy\n\tfrom roughpy import FreeTensor, Monomial, ShuffleTensor\n", "def test_construct_tensor_poly_coeffs():\n\t    data = [1 * Monomial(f\"x{i}\") for i in range(3)]\n\t    ft = FreeTensor(data, width=2, depth=2, dtype=roughpy.RationalPoly)\n\t    assert str(ft) == \"{ { 1(x0) }() { 1(x1) }(1) { 1(x2) }(2) }\"\n\tdef test_exp_log_roundtrip_poly_coeffs():\n\t    data = [0, 1 * Monomial('x1'), 1 * Monomial('x2')]\n\t    ft = FreeTensor(data, width=2, depth=2, dtype=roughpy.RationalPoly)\n\t    assert ft.exp().log() == ft\n\tdef test_shuffle_product_poly_coeffs():\n\t    lhs = ShuffleTensor([1 * Monomial(f\"x{i}\") for i in range(7)], width=2,\n", "                        depth=2, dtype=roughpy.RationalPoly)\n\t    rhs = ShuffleTensor([1 * Monomial(f\"y{i}\") for i in range(7)], width=2,\n\t                        depth=2, dtype=roughpy.RationalPoly)\n\t    result = lhs * rhs\n\t    expected_data = [\n\t        1 * Monomial('x0') * Monomial('y0'),\n\t        Monomial('x0') * Monomial('y1')\n\t        + Monomial('x1') * Monomial('y0'),\n\t        Monomial('x0') * Monomial('y2')\n\t        + Monomial('x2') * Monomial('y0'),\n", "        Monomial(['x0', 'y3'])\n\t        + 2 * Monomial(['x1', 'y1'])\n\t        + Monomial(['x3', 'y0']),\n\t        Monomial(['x0', 'y4'])\n\t        + Monomial(['x1', 'y2'])\n\t        + Monomial(['y1', 'x2'])\n\t        + Monomial(['x4', 'y0']),\n\t        Monomial(['x0', 'y5'])\n\t        + Monomial(['x2', 'y1'])\n\t        + Monomial(['y2', 'x1'])\n", "        + Monomial(['x5', 'y0']),\n\t        Monomial(['x0', 'y6'])\n\t        + 2 * Monomial(['x2', 'y2'])\n\t        + Monomial(['x6', 'y0'])\n\t    ]\n\t    expected = ShuffleTensor(expected_data, width=2, depth=2,\n\t                             dtype=roughpy.RationalPoly)\n\t    assert result == expected, f\"{expected - result} != 0\"\n"]}
{"filename": "tests/scalars/test_polynomial.py", "chunked_list": ["import pytest\n\timport roughpy\n\tfrom roughpy import PolynomialScalar, Monomial\n\tdef test_polynomial_construct_from_dict():\n\t    data = {\n\t        Monomial('x1'): 1,\n\t        Monomial('x2'): 2\n\t    }\n\t    p = PolynomialScalar(data)\n\t    assert str(p) == \"{ 1(x1) 2(x2) }\"\n"]}
{"filename": "tests/scalars/__init__.py", "chunked_list": []}
{"filename": "tests/scalars/test_monomial.py", "chunked_list": ["from fractions import Fraction\n\timport pytest\n\timport roughpy\n\tfrom roughpy import Monomial\n\t@pytest.fixture(params=[3, 3.1415, Fraction(22, 7)])\n\tdef scalar_val(request):\n\t    return request.param\n\tdef test_construct_single_str():\n\t    m = Monomial(\"x1\")\n\t    assert str(m) == 'x1'\n", "def test_mul_monomials():\n\t    m1 = Monomial('x1')\n\t    m2 = Monomial('x2')\n\t    assert str(m1*m2) == 'x1 x2'\n\tdef test_add_monomials_gives_polynomial():\n\t    m1 = Monomial('x1')\n\t    m2 = Monomial('x2')\n\t    p = m1 + m2\n\t    assert type(p) == roughpy.PolynomialScalar\n\tdef test_sub_monomials_gives_polynomial():\n", "    m1 = Monomial('x1')\n\t    m2 = Monomial('x2')\n\t    p = m1 - m2\n\t    assert type(p) == roughpy.PolynomialScalar\n\tdef test_scalar_plus_monomial(scalar_val):\n\t    m = Monomial('x')\n\t    p = scalar_val + m\n\t    assert type(p) == roughpy.PolynomialScalar\n\tdef test_monomial_plus_scalar(scalar_val):\n\t    m = Monomial('x')\n", "    p = m + scalar_val\n\t    assert type(p) == roughpy.PolynomialScalar\n\tdef test_scalar_mul_monomial(scalar_val):\n\t    m = Monomial('x')\n\t    p = scalar_val * m\n\t    assert type(p) == roughpy.PolynomialScalar\n\tdef test_monomial_mul_scalar(scalar_val):\n\t    m = Monomial('x')\n\t    p = m * scalar_val\n\t    assert type(p) == roughpy.PolynomialScalar\n", "def test_monomial_div_scalar(scalar_val):\n\t    m = Monomial('x')\n\t    p = m / scalar_val\n\t    assert type(p) == roughpy.PolynomialScalar\n"]}
{"filename": "tests/scalars/dlpack/__init__.py", "chunked_list": []}
{"filename": "tests/scalars/dlpack/test_construct_from_jax.py", "chunked_list": ["import pytest\n\ttry:\n\t    import jax\n\t    from jax import numpy as jnp\n\texcept ImportError:\n\t    jax = None\n\t    jnp = None\n\timport roughpy as rp\n\timport numpy as np\n\tfrom numpy.testing import assert_array_equal\n", "@pytest.mark.skipif(jax is None, reason=\"JAX test require jax to be installed\")\n\tclass TestJaxArrayCreation:\n\t    @pytest.fixture(scope=\"class\")\n\t    def context(self):\n\t        return rp.get_context(2, 2, rp.SPReal)\n\t    @pytest.fixture(scope=\"class\")\n\t    def prng_key(self):\n\t        return jax.random.PRNGKey(12345)\n\t    def test_increment_stream_from_jax_array(self):\n\t        array = jnp.array([\n", "            [-0.25860816, -0.36977386, 0.6619457, -0.50442713, 0.08028925, -1.06701028],\n\t               [-0.26208243, 0.22464547, 0.39521545, -0.62663144, -0.34344956, -1.67293704],\n\t               [-0.55824, -0.19376263, 0.86616075, -0.58314389, -0.69254208, -1.53291035],\n\t               [-0.52306908, -0.09234464, 1.17564034, -0.7388621, -0.91333717, -1.50844121],\n\t               [-0.80696738, -0.09417236, 0.75135314, -1.20548987, -1.42038512, -1.86834741],\n\t               [-0.6642682, -0.12166289, 1.04914618, -1.01415539, -1.58841276, -2.54356289]\n\t        ])\n\t        stream = rp.LieIncrementStream.from_increments(np.array(array), width=6, depth=2, dtype=rp.SPReal)\n\t        lsig01 = stream.log_signature(rp.RealInterval(0, 1))\n\t        lsig12 = stream.log_signature(rp.RealInterval(1, 2))\n", "        lsig24 = stream.log_signature(rp.RealInterval(2, 4))\n\t        lsig46 = stream.log_signature(rp.RealInterval(4, 6))\n\t        assert_array_equal(np.array(lsig01)[:6], array[0, :])\n\t        assert not np.any(np.isnan(lsig12))\n\t        assert not np.any(np.isnan(lsig24))\n\t        assert not np.any(np.isnan(lsig46))\n\t    @pytest.mark.xfail(condition=True, reason=\"No device support is currently available\")\n\t    def test_create_tensor_from_jax_array(self, prng_key, context):\n\t        array = jax.random.uniform(prng_key, shape=(context.tensor_size(2),), dtype=\"float32\", minval=-1.0, maxval=1.0)\n\t        ts = rp.FreeTensor(array, ctx=context)\n", "        assert_array_equal(np.array(ts), np.array(jax.device_get(array), copy=True))\n"]}
{"filename": "tests/intervals/__init__.py", "chunked_list": []}
{"filename": "tests/intervals/test_dyadic.py", "chunked_list": ["import itertools\n\timport math\n\timport pytest\n\tfrom roughpy import Dyadic\n\t@pytest.mark.parametrize(\"k, n\",\n\t                         itertools.product(range(-10, 10), range(0, 10)))\n\tdef test_dyadic_to_float(k, n):\n\t    d = Dyadic(k, n)\n\t    assert float(d) == math.ldexp(k, -n)\n\t@pytest.mark.parametrize(\"n\", range(1, 15))\n", "def test_rebase_dyadic(n):\n\t    d = Dyadic(1, 0)\n\t    d.rebase(n)\n\t    assert float(d) == 1.0\n\t    assert d.n == n\n\t    assert d.k == 1 << n\n"]}
{"filename": "tests/intervals/test_intervals.py", "chunked_list": ["import pytest\n\tfrom roughpy import IntervalType, RealInterval\n\t@pytest.fixture(params=[IntervalType.Clopen])\n\tdef interval_type(request):\n\t    return request.param\n\t@pytest.mark.parametrize(\"inf, sup\", [(0.0, 1.0), (-5.0, 2.0),\n\t                                      (-float(\"inf\"), float(\"inf\"))])\n\tdef test_interval_repr(inf, sup, interval_type):\n\t    ivl = RealInterval(inf, sup, interval_type)\n\t    type_str = \"clopen\" if interval_type == IntervalType.Clopen else \"opencl\"\n", "    assert repr(\n\t        ivl) == f\"RealInterval({inf=:0.6f}, {sup=:0.6f}, type={type_str})\"\n\tdef test_interval_equality_unit_intervals(interval_type):\n\t    i1 = RealInterval(0.0, 1.0, interval_type)\n\t    i2 = RealInterval(0.0, 1.0, interval_type)\n\t    assert i1 == i2\n\t@pytest.mark.skip(\"OpenCL disabled\")\n\tdef test_interval_equality_fails_different_types():\n\t    i1 = RealInterval(0.0, 1.0, IntervalType.Clopen)\n\t    i2 = RealInterval(0.0, 1.0, IntervalType.Opencl)\n", "    assert i1 != i2\n\tdef test_interval_equality_fails_mismatched_endpoints(interval_type):\n\t    i1 = RealInterval(-1.0, 1.0, interval_type)\n\t    i2 = RealInterval(0.0, 2.0, interval_type)\n\t    assert i1 != i2\n\tdef test_intersects_with_same_interval(interval_type):\n\t    i1 = RealInterval(0.0, 1.0, interval_type)\n\t    i2 = RealInterval(0.0, 1.0, interval_type)\n\t    assert i1.intersects_with(i2)\n\tdef test_intersects_with_overlapping(interval_type):\n", "    i1 = RealInterval(0.0, 1.0, interval_type)\n\t    i2 = RealInterval(-1.0, 0.5, interval_type)\n\t    assert i1.intersects_with(i2)\n\t@pytest.mark.skip(\"OpenCL disabled\")\n\tdef test_intersects_with_common_endpoints():\n\t    i1 = RealInterval(0.0, 1.0, IntervalType.Clopen)\n\t    i2 = RealInterval(-1.0, 0.0, IntervalType.Opencl)\n\t    # (-1.0, 0.0] [0.0, 1.0)\n\t    assert i1.intersects_with(i2)\n\tdef test_intersects_with_fails_disjoint(interval_type):\n", "    i1 = RealInterval(0.0, 1.0, interval_type)\n\t    i2 = RealInterval(2.0, 3.0, interval_type)\n\t    assert not i1.intersects_with(i2)\n\tdef test_intersects_with_fails_common_endpoints_same_type(interval_type):\n\t    i1 = RealInterval(0.0, 1.0, interval_type)\n\t    i2 = RealInterval(-1.0, 0.0, interval_type)\n\t    # [-1.0, 0.0) [0.0, 1.0) or (-1.0, 0.0] (0.0, 1.0]\n\t    assert not i1.intersects_with(i2)\n\t@pytest.mark.skip(\"OpenCL disabled\")\n\tdef test_intersects_with_fails_common_endpoint_opposite_type():\n", "    i1 = RealInterval(0.0, 1.0, IntervalType.Opencl)\n\t    i2 = RealInterval(-1.0, 0.0, IntervalType.Clopen)\n\t    # [-1.0, 0.0) (0.0, 1.0]\n\t    assert not i1.intersects_with(i2)\n"]}
{"filename": "roughpy/__init__.py", "chunked_list": ["import importlib.metadata as _ilm\n\timport os\n\timport platform\n\tfrom pathlib import Path\n\ttry:\n\t    __version__ = _ilm.version(\"RoughPy\")\n\texcept _ilm.PackageNotFoundError:\n\t    __version__ = \"0.0.0\"\n\tdef _add_dynload_location(path: Path):\n\t    if platform.system() == \"Windows\":\n", "        os.add_dll_directory(str(path))\n\t        return\n\tif platform.system() == \"Windows\":\n\t    LIBS_DIR = Path(__file__).parent.parent / \"roughpy.libs\"\n\t    if LIBS_DIR.exists():\n\t        os.add_dll_directory(str(LIBS_DIR))\n\ttry:\n\t    iomp = _ilm.distribution(\"intel-openmp\")\n\t    libs = [f for f in iomp.files if f.name.startswith(\"libiomp5\")]\n\t    if libs:\n", "        _add_dynload_location(libs[0].locate().resolve().parent)\n\t    del iomp\n\t    del libs\n\texcept _ilm.PackageNotFoundError:\n\t    pass\n\timport roughpy._roughpy\n\tfrom roughpy._roughpy import *\n"]}
{"filename": "roughpy/streams/tick_stream.py", "chunked_list": ["#  Copyright (c) 2023 the RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n\t#  this list of conditions and the following disclaimer in the documentation\n", "#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n\t#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n", "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\tfrom __future__ import annotations\n\tfrom abc import abstractmethod, ABC\n\tfrom typing import Optional, Any, NamedTuple\n\tfrom roughpy._roughpy import TickStreamConstructionHelper, StreamSchema, ChannelType\n", "class BaseTickDataParser(ABC):\n\t    helper: TickStreamConstructionHelper\n\t    class TickItem(NamedTuple):\n\t        timestamp: Any\n\t        label: str\n\t        type: ChannelType\n\t        data: Any\n\t    def __init__(self, schema: Optional[StreamSchema] = None, schema_only: bool = False):\n\t        if schema is not None:\n\t            self.helper = TickStreamConstructionHelper(schema, schema_only)\n", "        else:\n\t            self.helper = TickStreamConstructionHelper(schema_only)\n\t    @abstractmethod\n\t    def parse_data(self, data: Any):\n\t        pass\n\t    def convert_channel_type(self, ch_type: Any) -> ChannelType:\n\t        if isinstance(ch_type, ChannelType):\n\t            return ch_type\n\t        if not isinstance(ch_type, str):\n\t            raise TypeError(f\"cannot convert {ch_type.__name__} to channel type\")\n", "        if ch_type == \"increment\":\n\t            return ChannelType.IncrementChannel\n\t        if ch_type == \"value\":\n\t            return ChannelType.ValueChannel\n\t        if ch_type == \"categorical\":\n\t            return ChannelType.CategoricalChannel\n\t    def insert(self, item: TickItem):\n\t        type = self.convert_channel_type(item.type)\n\t        if type == ChannelType.IncrementChannel:\n\t            self.helper.add_increment(item.label, item.timestamp, item.data)\n", "        elif type == ChannelType.ValueChannel:\n\t            self.helper.add_value(item.label, item.timestamp, item.data)\n\t        elif type == ChannelType.CategoricalChannel:\n\t            self.helper.add_categorical(item.label, item.timestamp, item.data)\n\tclass StandardTickDataParser(BaseTickDataParser):\n\t    def parse_data(self, data: Any):\n\t        for item in self.visit(data, [\"timestamp\", \"label\", \"type\", \"data\"], None):\n\t            self.insert(item)\n\t    def visit(self,\n\t              data: Any,\n", "              labels_remaining: list[str],\n\t              current: Optional[dict]\n\t              ):\n\t        yield from getattr(self, f\"handle_{type(data).__name__}\", self.handle_any)(data, labels_remaining,\n\t                                                                                   current or {})\n\t    def handle_dict(self,\n\t                    data: dict,\n\t                    labels_remaining: list[str],\n\t                    current: dict\n\t                    ):\n", "        if all(label in data for label in labels_remaining):\n\t            yield self.TickItem(**current, **{label: data[label] for label in labels_remaining})\n\t            return\n\t        key_type, *value_types = labels_remaining\n\t        if key_type == \"data\":\n\t            yield self.TickItem(**current, data=data)\n\t            return\n\t        for key, value in data.items():\n\t            yield from self.visit(value, value_types, {key_type: key, **current})\n\t    def handle_list(self,\n", "                    data: Any,\n\t                    labels_remaining: list[str],\n\t                    current: dict):\n\t        first_type, *remaining = labels_remaining\n\t        if first_type == \"data\":\n\t            yield self.TickItem(**current, data=data)\n\t            return\n\t        for value in data:\n\t            yield from self.visit(value, labels_remaining, current)\n\t    def handle_tuple(self,\n", "                     data: Any,\n\t                     labels_remaining: list[str],\n\t                     current: dict):\n\t        if len(data) == len(labels_remaining):\n\t            yield self.TickItem(\n\t                **(current or {}), **dict(zip(labels_remaining, data))\n\t            )\n\t            return\n\t        first_label, *other_labels = labels_remaining\n\t        if len(data) == 2:\n", "            yield from self.visit(data[1], other_labels, {**current, first_label: data[0]})\n\t        else:\n\t            yield from self.visit(data[1:], other_labels, {**current, first_label: data[0]})\n\t    def handle_any(self, data, labels_remaining, current):\n\t        if len(labels_remaining) == 1:\n\t            yield self.TickItem(**current, data=data)\n\t            return\n\t        if \"label\" in labels_remaining or \"timestamp\" in labels_remaining:\n\t            raise ValueError(\"cannot infer timestamp or label from a single data value\")\n\t        if isinstance(data, (float, int)):\n", "            # infer value type\n\t            yield self.TickItem(**current, type=\"increment\", data=data)\n\t        elif isinstance(data, str):\n\t            # infer categorical\n\t            yield self.TickItem(**current, type=\"categorical\", data=data)\n\t        else:\n\t            raise ValueError(\"other types cannot be used for anything but data value\")\n"]}
{"filename": "roughpy/streams/__init__.py", "chunked_list": ["#  Copyright (c) 2023 the RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n\t#  this list of conditions and the following disclaimer in the documentation\n", "#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n\t#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n", "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"]}
{"filename": "examples/signature-kernel-by-signature-dot.py", "chunked_list": ["import numpy as np\n\timport roughpy as rp\n\trng = np.random.default_rng(1635134)\n\t# Sample times\n\t# should be approximately in [0, 1)\n\ttimes = np.cumsum(rng.exponential(0.1, 10))\n\t# Moderate length 2D paths\n\tp1_data = rng.uniform(-1, 1, (10, 2))\n\tp2_data = rng.uniform(-1, 1, (10, 2))\n\tinterval = rp.RealInterval(0, 1)\n", "print(\"The interval of definition\", interval)\n\tctx = rp.get_context(width=2, depth=6, coeffs=rp.DPReal)\n\tstream1 = rp.LieIncrementStream.from_increments(p1_data, indices=times, ctx=ctx)\n\tstream2 = rp.LieIncrementStream.from_increments(p2_data, indices=times, ctx=ctx)\n\tsig1 = stream1.signature(interval)\n\tsig2 = stream2.signature(interval)\n\tprint(np.inner(np.array(sig1), np.array(sig2)))\n"]}
{"filename": "examples/list_basis_keys.py", "chunked_list": ["\"\"\"\n\tThis example shows how to generate a list of keys associated with a\n\tparticular basis.\n\t\"\"\"\n\timport roughpy as rp\n\t# Basis objects are tied to contexts, since different backends might provide\n\t# different bases for the various algebras. For this reason, we must first\n\t# get a context object using rp.get_context - the scalar type doesn't matter\n\t# - and then access the basis attribute. Note though, that RoughPy requires\n\t# that all tensor bases have the same ordering.\n", "context = rp.get_context(2, 3, rp.DPReal)\n\tbasis = context.tensor_basis\n\t# The basis object is iterable, so we can use it in a for-loop to walk\n\t# through all keys - in order - associated with the basis\n\tfor key in basis:\n\t    print(key)\n\t# ()\n\t# (1)\n\t# (2)\n\t# (1,1)\n", "# (1,2)\n\t# (2,1)\n\t# (2,2)\n\t# etc.\n\t# Somtimes you might want to write out a list of keys as a string. The\n\t# easiest way to do this is with str.join, and map.\n\tall_keys_string = \" \".join(map(str, basis))\n\t# \"() (1) (2) (1,1) (1,2) (2,1) (2,2) ...\"\n"]}
{"filename": "examples/lie_to_tensor_formulae.py", "chunked_list": ["#  Copyright (c) 2023 the RoughPy Developers. All rights reserved.\n\t#\n\t#  Redistribution and use in source and binary forms, with or without\n\t#  modification,\n\t#  are permitted provided that the following conditions are met:\n\t#\n\t#  1. Redistributions of source code must retain the above copyright notice,\n\t#  this list of conditions and the following disclaimer.\n\t#\n\t#  2. Redistributions in binary form must reproduce the above copyright notice,\n", "#  this list of conditions and the following disclaimer in the documentation\n\t#  and/or other materials provided with the distribution.\n\t#\n\t#  3. Neither the name of the copyright holder nor the names of its contributors\n\t#  may be used to endorse or promote products derived from this software without\n\t#  specific prior written permission.\n\t#\n\t#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n\t#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n\t#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n", "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n\t#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n\t#  OR CONSEQUENTIAL\n\t#  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\t#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\t#  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\t#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n\t#  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\t\"\"\"\n\tThis example shows how to use RoughPy's polynomial coefficient types to\n", "derive formulae for the Lie-to-tensor map.\n\t\"\"\"\n\timport roughpy as rp\n\t# Construct the initial Lie object data. The coefficients here are polynomials,\n\t# which each channel of the Lie algebra space has a unique indeterminate.\n\tlie_data = [\n\t    1 * rp.Monomial(\"x1\"),  # channel (1)\n\t    1 * rp.Monomial(\"x2\"),  # channel (2)\n\t    1 * rp.Monomial(\"x3\"),  # channel (3)\n\t    1 * rp.Monomial(\"x4\"),  # channel ([1, 2])\n", "    1 * rp.Monomial(\"x5\"),  # channel ([1, 3])\n\t    1 * rp.Monomial(\"x6\"),  # channel ([2, 3])\n\t]\n\t# rp.Monomial creates a monomial object (in this case, a single indeterminate),\n\t# and multiplying this by 1 makes this monomial into a polynomial.\n\t# Now create the Lie object, with width 3 and depth 2\n\tlie = rp.Lie(lie_data, width=3, depth=2, dtype=rp.RationalPoly)\n\t# The Lie element constructed here has level 1 data, given by the polynomials\n\t# constructed above\n\tprint(lie)\n", "# { { 1(x1) }(1) { 1(x2) }(2) { 1(x3) }(3) }\n\t# Get a compatible context for access to the lie_to_tensor map.\n\tctx = rp.get_context(3, 2, rp.RationalPoly)\n\t# perform the lie-to-tensor operation.\n\ttensor = ctx.lie_to_tensor(lie)\n\t# Print out the result to get the formulae for the Lie-to-tensor map with\n\t# respect to the original input data.\n\tprint(tensor)\n\t# { { 1(x1) }(1) { 1(x2) }(2) { 1(x3) }(3)\n\t# { 1(x4) }(1,2) { 1(x5) }(1,3) { -1(x4) }(2,1)\n", "# { 1(x6) }(2,3) { -1(x5) }(3,1) { -1(x6) }(3,2) }\n\t# Now let's repeat the same operation but where we select compute only the\n\t# channel corresponding to the Lie bracket [1, 2]. This has index 3 in the\n\t# basis order\n\tsingle_lie = rp.Lie({3: 1*rp.Monomial(\"x4\")}, width=3, depth=2,\n\t                    dtype=rp.RationalPoly)\n\t# Just one element this time\n\tprint(single_lie)\n\t# { { 1(x4) }([1, 2]) }\n\t# As before, use the context to perform the Lie-to-tensor operation\n", "single_tensor = ctx.lie_to_tensor(single_lie)\n\t# Now there are only two elements in the result.\n\tprint(single_tensor)\n\t# { { 1(x4) }(1, 2) { -1(x4) }(2, 1) }\n"]}
{"filename": "docs/source/conf.py", "chunked_list": ["# Configuration file for the Sphinx documentation builder.\n\t#\n\t# For the full list of built-in configuration values, see the documentation:\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\t# -- Project information -----------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n\tproject = 'RoughPy'\n\tcopyright = '2023, The RoughPy Authors'\n\tauthor = 'The RoughPy Authors'\n\trelease = '0.0.2'\n", "# -- General configuration ---------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\textensions = [\n\t    \"sphinx.ext.intersphinx\"\n\t]\n\tsource_suffix = {\n\t    '.rst': 'restructuredtext',\n\t    '.txt': 'restructuredtext',\n\t    '.md': 'markdown'\n\t}\n", "templates_path = ['_templates']\n\texclude_patterns = []\n\t# -- Options for HTML output -------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n\thtml_theme = 'alabaster'\n\thtml_static_path = ['_static']\n\tintersphinx_mapping = {\n\t    \"python\": (\"https://python.org/3\", None)\n\t}\n"]}
