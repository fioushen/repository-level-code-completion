{"filename": "tests/test_workers.py", "chunked_list": ["# Standard Library Imports\n\tfrom threading import Event\n\tfrom dramatiq.brokers.stub import StubBroker\n\t# Local Application Imports\n\tfrom async_dramatiq.worker import AsyncWorker\n\tdef test_async_worker(broker: StubBroker) -> None:\n\t    startup_event = Event()\n\t    async_worker = AsyncWorker(startup_event, broker)\n\t    async_worker.start()\n\t    startup_event.wait()  # Asyncio IO loop has started\n", "    assert async_worker.event_loop.is_running()\n\t    async_worker.stop()\n\t    async_worker.join()\n\t    assert not async_worker.event_loop.is_running()\n\t    async_worker.pause()\n\t    async_worker.resume()\n"]}
{"filename": "tests/test_backends.py", "chunked_list": ["# Standard Library Imports\n\timport os\n\timport time\n\tfrom threading import Thread\n\timport pytest\n\tfrom dramatiq import Message\n\tfrom dramatiq.actor import actor\n\tfrom dramatiq.results.backend import ResultMissing, ResultTimeout\n\t# Local Application Imports\n\tfrom async_dramatiq.backends import AsyncRedisBackend, AsyncStubBackend, set_backend\n", "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\")\n\tREDIS_PORT = os.getenv(\"REDIS_PORT\", 6379)\n\tdef get_message() -> Message:\n\t    @actor(queue_name=\"test_queue\", store_results=True)\n\t    def my_func():\n\t        pass\n\t    return my_func.message()\n\tasync def assert_result(\n\t    backend: AsyncRedisBackend | AsyncStubBackend,\n\t    msg: Message,\n", "    result: str,\n\t    timeout: int = 3000,\n\t) -> None:\n\t    returned_result = await backend.get_result(msg, block=True, timeout=timeout)\n\t    assert returned_result == result\n\tdef delayed_store(\n\t    backend: AsyncRedisBackend | AsyncStubBackend, msg: Message, result: str, ttl: int\n\t) -> None:\n\t    time.sleep(0.1)\n\t    backend.store_result(message=msg, result=result, ttl=ttl)\n", "@pytest.mark.parametrize(\n\t    \"backend\", [AsyncRedisBackend(host=REDIS_HOST, port=REDIS_PORT), AsyncStubBackend()]\n\t)\n\tasync def test_get_result_happy_path(\n\t    backend: AsyncRedisBackend | AsyncStubBackend,\n\t) -> None:\n\t    set_backend(backend)\n\t    msg = get_message()\n\t    result = \"this is a result\"\n\t    backend.store_result(message=msg, result=result, ttl=100000)\n", "    returned_result = await backend.get_result(msg)\n\t    assert returned_result == result\n\t@pytest.mark.parametrize(\n\t    \"backend\", [AsyncRedisBackend(host=REDIS_HOST, port=REDIS_PORT), AsyncStubBackend()]\n\t)\n\tasync def test_get_result_result_missing(\n\t    backend: AsyncRedisBackend | AsyncStubBackend,\n\t) -> None:\n\t    set_backend(backend)\n\t    msg = get_message()\n", "    with pytest.raises(ResultMissing):\n\t        await backend.get_result(msg)\n\t@pytest.mark.parametrize(\n\t    \"backend\", [AsyncRedisBackend(host=REDIS_HOST, port=REDIS_PORT), AsyncStubBackend()]\n\t)\n\tasync def test_get_result_blocking_happy_path(\n\t    backend: AsyncRedisBackend | AsyncStubBackend,\n\t) -> None:\n\t    set_backend(backend)\n\t    msg = get_message()\n", "    result = \"this is a result\"\n\t    t1 = Thread(target=delayed_store, args=[backend, msg, result, 5000])\n\t    t1.start()\n\t    await assert_result(backend, msg, result)\n\t    t1.join()\n\t@pytest.mark.parametrize(\n\t    \"backend\", [AsyncRedisBackend(host=REDIS_HOST, port=REDIS_PORT), AsyncStubBackend()]\n\t)\n\tasync def test_get_result_blocking_timeout(\n\t    backend: AsyncRedisBackend | AsyncStubBackend,\n", ") -> None:\n\t    set_backend(backend)\n\t    msg = get_message()\n\t    result = \"this is a result\"\n\t    t1 = Thread(target=delayed_store, args=[backend, msg, result, 10000])\n\t    t1.start()\n\t    with pytest.raises(ResultTimeout):\n\t        await assert_result(backend, msg, result, 0)\n\t    t1.join()\n"]}
{"filename": "tests/test_scheduler.py", "chunked_list": ["# Standard Library Imports\n\tfrom datetime import timedelta\n\tfrom apscheduler.triggers.cron import CronTrigger\n\tfrom apscheduler.triggers.interval import IntervalTrigger\n\t# Local Application Imports\n\tfrom async_dramatiq.scheduler import register_cron, register_interval\n\tfrom async_dramatiq.scheduler import scheduled_jobs\n\tdef test_register_jobs() -> None:\n\t    def test_func() -> None:\n\t        return None\n", "    crontab = \"* * * * *\"\n\t    register_cron(test_func, crontab)\n\t    assert isinstance(scheduled_jobs[-1].trigger, CronTrigger)\n\t    assert scheduled_jobs[-1].module_path == test_func.__module__\n\t    assert scheduled_jobs[-1].func_name == test_func.__name__\n\tdef test_register_interval() -> None:\n\t    def test_func() -> None:\n\t        return None\n\t    interval = timedelta(seconds=60)\n\t    register_interval(test_func, interval)\n", "    assert isinstance(scheduled_jobs[-1].trigger, IntervalTrigger)\n\t    assert scheduled_jobs[-1].module_path == test_func.__module__\n\t    assert scheduled_jobs[-1].func_name == test_func.__name__\n"]}
{"filename": "tests/test_actors.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\tfrom datetime import timedelta\n\tfrom typing import Any, Callable, TypeVar\n\timport pytest\n\tfrom apscheduler.triggers.cron import CronTrigger\n\tfrom apscheduler.triggers.interval import IntervalTrigger\n\tfrom dramatiq import Worker\n\t# Local Application Imports\n\tfrom async_dramatiq.actor import async_actor\n", "from async_dramatiq.backends import AsyncStubBackend, get_backend\n\tfrom async_dramatiq.scheduler import scheduled_jobs\n\tF = TypeVar(\"F\", bound=Callable[..., Any])\n\tdef test_async_actor() -> None:\n\t    scheduled_jobs_len = len(scheduled_jobs)\n\t    @async_actor(interval=timedelta(seconds=5))\n\t    def test_interval():\n\t        return None\n\t    @async_actor(crontab=\"* * * * *\")\n\t    def test_cron():\n", "        return None\n\t    @async_actor()\n\t    async def test_async():\n\t        return None\n\t    assert len(scheduled_jobs) == scheduled_jobs_len + 2\n\t    assert isinstance(scheduled_jobs[-1].trigger, CronTrigger)\n\t    assert scheduled_jobs[-1].module_path, test_cron.__module__\n\t    assert scheduled_jobs[-1].func_name, test_cron.__name__\n\t    assert isinstance(scheduled_jobs[-2].trigger, IntervalTrigger)\n\t    assert scheduled_jobs[-2].module_path, test_interval.__module__\n", "    assert scheduled_jobs[-2].func_name, test_interval.__name__\n\tasync def test_async_actor_func(event_loop: asyncio.BaseEventLoop) -> None:\n\t    result = \"generic result\"\n\t    @async_actor()\n\t    async def test_async():\n\t        return result\n\t    # Test generic run\n\t    assert result == await test_async()\n\tdef test_async_actor_func_no_loop() -> None:\n\t    result = \"generic result\"\n", "    @async_actor()\n\t    async def test_async():\n\t        return result\n\t    # Test generic run\n\t    with pytest.raises(RuntimeError):\n\t        test_async()\n\tasync def test_async_actor_func_in_thread(\n\t    worker: Worker, async_stub_backend: AsyncStubBackend\n\t) -> None:\n\t    result = \"generic result\"\n", "    @async_actor(store_results=True)\n\t    async def test_async():\n\t        return result\n\t    # Setup actor event loop\n\t    loop = (w.event_loop for w in worker.workers if hasattr(w, \"event_loop\"))\n\t    test_async.event_loop = next(loop, None)\n\t    # Send actor to worker\n\t    msg = test_async.send()\n\t    worker.join()\n\t    return_result = await get_backend().get_result(msg, block=True)\n", "    assert return_result == result\n\tasync def test_sync_actor_func() -> None:\n\t    result = \"generic result\"\n\t    @async_actor()\n\t    def test_sync():\n\t        return result\n\t    assert result == test_sync()\n\tdef test_sync_actor_func_no_loop() -> None:\n\t    result = \"generic result\"\n\t    @async_actor()\n", "    def test_sync():\n\t        return result\n\t    assert result == test_sync()\n\tasync def test_sync_actor_func_in_thread(\n\t    worker: Worker, async_stub_backend: AsyncStubBackend\n\t) -> None:\n\t    result = \"generic result\"\n\t    @async_actor(store_results=True)\n\t    def test_async():\n\t        return result\n", "    # Send actor to worker\n\t    msg = test_async.send()\n\t    worker.join()\n\t    return_result = await get_backend().get_result(msg, block=True)\n\t    assert return_result == result\n\tasync def test_async_request(\n\t    worker: Worker, async_stub_backend: AsyncStubBackend\n\t) -> None:\n\t    @async_actor(store_results=True)\n\t    async def test_async():\n", "        await asyncio.sleep(0.25)\n\t        return True\n\t    # Setup actor event loop\n\t    loop = (w.event_loop for w in worker.workers if hasattr(w, \"event_loop\"))\n\t    test_async.event_loop = next(loop, None)\n\t    # Send actor to worker\n\t    msg = test_async.send()\n\t    worker.join()\n\t    assert await get_backend().get_result(msg, block=True) is True\n\t    # Send actor to worker\n", "    msg = test_async.send()\n\t    worker.join()\n\t    assert await get_backend().get_result(msg, block=True) is True\n"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/conftest.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\tfrom typing import Generator\n\timport pytest\n\timport redis\n\tfrom dramatiq import Worker\n\tfrom dramatiq.brokers.stub import StubBroker\n\t# Local Application Imports\n\tfrom async_dramatiq import set_broker\n\tfrom async_dramatiq.backends import AsyncRedisBackend, AsyncStubBackend, set_backend\n", "from async_dramatiq.middleware import AsyncMiddleware\n\tdef check_redis(client: redis.Redis) -> None:\n\t    try:\n\t        client.ping()\n\t    except redis.ConnectionError as e:\n\t        raise e\n\t@pytest.fixture\n\tdef event_loop() -> Generator[asyncio.BaseEventLoop, None, None]:\n\t    loop = asyncio.get_event_loop_policy().new_event_loop()\n\t    yield loop\n", "    loop.close()\n\t@pytest.fixture\n\tdef broker() -> Generator[StubBroker, None, None]:\n\t    broker = StubBroker()\n\t    set_broker(broker)\n\t    yield broker\n\t@pytest.fixture\n\tdef async_stub_backend() -> Generator[AsyncStubBackend, None, None]:\n\t    backend = AsyncStubBackend()\n\t    set_backend(backend)\n", "    yield backend\n\t@pytest.fixture\n\tdef async_redis_result_backend() -> Generator[AsyncRedisBackend, None, None]:\n\t    backend = AsyncRedisBackend()\n\t    check_redis(backend.client)\n\t    backend.client.flushall()\n\t    yield backend\n\t    backend.client.flushall()\n\t@pytest.fixture\n\tdef worker(broker: StubBroker) -> Worker:\n", "    broker.add_middleware(AsyncMiddleware())\n\t    worker = Worker(broker, worker_timeout=100, worker_threads=2)\n\t    worker.start()\n\t    yield worker\n\t    worker.stop()\n\t    worker.join()\n"]}
{"filename": "examples/worker_heartbeat/run_scheduler.py", "chunked_list": ["# Standard Library Imports\n\timport signal\n\timport sys\n\tfrom apscheduler.schedulers.blocking import BlockingScheduler\n\tfrom worker_heartbeat import tasks  # noqa : F401\n\t# Local Application Imports\n\tfrom async_dramatiq import scheduler as tasks_scheduler\n\tdef main() -> None:\n\t    \"\"\"Run the apscheduler in a seperate process.\"\"\"\n\t    scheduler = BlockingScheduler()\n", "    for job in tasks_scheduler.scheduled_jobs:\n\t        job_path = f\"{job.module_path}:{job.func_name}.send\"\n\t        job_name = f\"{job.module_path}.{job.func_name}\"\n\t        scheduler.add_job(job_path, trigger=job.trigger, name=job_name)\n\t    def shutdown(signum, frame):\n\t        scheduler.shutdown()\n\t    signal.signal(signal.SIGINT, shutdown)\n\t    signal.signal(signal.SIGTERM, shutdown)\n\t    scheduler.start()\n\t    return 0\n", "if __name__ == \"__main__\":\n\t    sys.exit(main())\n"]}
{"filename": "examples/worker_heartbeat/cli.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\timport click\n\tfrom worker_heartbeat.tasks import async_worker_sleep, worker_heartbeat\n\t# Local Application Imports\n\timport async_dramatiq as adtq\n\tasync def heartbeat() -> None:\n\t    msg = worker_heartbeat.send()\n\t    print(f\"Sending heartbeat task {msg}...\")\n\t    result = await adtq.get_backend().get_result(msg, block=True)\n", "    print(f\"Worker heartbeat @ {result}\")\n\tasync def sleep(sleep_for: float) -> None:\n\t    msg = async_worker_sleep.send(sleep_for)\n\t    print(f\"Sending sleep task {msg}...\")\n\t    result = await adtq.get_backend().get_result(msg, block=True)\n\t    print(f\"Worker slept for {result} seconds\")\n\t@click.command()\n\t@click.option(\"--send_heartbeat\", is_flag=True, help=\"Send a heartbeat\")\n\t@click.option(\"--sleep_for\", default=0, type=float, help=\"Sleep for N seconds\")\n\tdef run(send_heartbeat: bool, sleep_for: float) -> None:\n", "    \"\"\"Test Async Dramatiq Functionality\"\"\"\n\t    loop = asyncio.get_event_loop()\n\t    if send_heartbeat:\n\t        loop.run_until_complete(heartbeat())\n\t    elif sleep_for > 0:\n\t        loop.run_until_complete(sleep(sleep_for))\n\t    loop.close()\n\tif __name__ == \"__main__\":\n\t    run()\n"]}
{"filename": "examples/worker_heartbeat/worker_heartbeat/tasks.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\timport logging\n\timport time\n\tfrom datetime import timedelta\n\tfrom .worker import bg_task, lr_task\n\t@bg_task(store_results=True, interval=timedelta(seconds=5))\n\tdef worker_heartbeat() -> float:\n\t    t = time.time()\n\t    logging.info(f\"Worker Heartbeat @ {t}\")\n", "    return t\n\t@lr_task(store_results=True)\n\tasync def async_worker_sleep(sleep_for: float) -> float:\n\t    logging.info(f\"Worker Sleeping for {sleep_for} seconds\")\n\t    await asyncio.sleep(sleep_for)\n\t    logging.info(\"Worker is awake\")\n\t    return sleep_for\n"]}
{"filename": "examples/worker_heartbeat/worker_heartbeat/config.py", "chunked_list": ["# Standard Library Imports\n\timport logging\n\timport os\n\tfrom distutils.util import strtobool\n\timport pika\n\t# Environment Variables\n\ttesting: bool = strtobool(os.getenv(\"TESTING\", \"false\"))\n\tbroker_host: str = os.getenv(\"BROKER_HOST\", \"localhost\")\n\tbroker_port: int = os.getenv(\"BROKER_PORT\", 5672)\n\tbroker_credentials: pika.PlainCredentials = pika.PlainCredentials(\n", "    os.getenv(\"BROKER_USER\", \"guest\"), os.getenv(\"BROKER_PASSWORD\", \"guest\")\n\t)\n\tredis_host: str = os.getenv(\"REDIS_HOST\", \"localhost\")\n\tredis_port: int = os.getenv(\"REDIS_PORT\", 6379)\n\t# Setup\n\tlogging.basicConfig(level=logging.DEBUG if testing else logging.WARNING)\n"]}
{"filename": "examples/worker_heartbeat/worker_heartbeat/__init__.py", "chunked_list": []}
{"filename": "examples/worker_heartbeat/worker_heartbeat/worker.py", "chunked_list": ["# Standard Library Imports\n\timport logging\n\tfrom functools import partial\n\tfrom typing import Any\n\timport worker_heartbeat.config as config\n\tfrom dramatiq.brokers.rabbitmq import RabbitmqBroker\n\tfrom dramatiq.brokers.stub import StubBroker\n\t# Local Application Imports\n\timport async_dramatiq as adtq\n\tfrom async_dramatiq.actor import async_actor\n", "from async_dramatiq.backends import AsyncRedisBackend, AsyncStubBackend\n\tfrom async_dramatiq.middleware import AsyncMiddleware, StubAsyncMiddleware\n\tfrom async_dramatiq.types import DramatiqWorkerPriority, TaskQueue\n\tfrom async_dramatiq.worker import AsyncWorker\n\t# Declare the queues\n\tbg_queue = TaskQueue(queue=\"background_tasks\")\n\tlr_queue = TaskQueue(queue=\"long_running_tasks\")\n\tqueues = {bg_queue.queue: bg_queue, lr_queue.queue: lr_queue}\n\t# Decorator for background tasks\n\tbg_task = partial(\n", "    async_actor, priority=DramatiqWorkerPriority.HIGH, queue_name=bg_queue.queue\n\t)\n\tlr_task = partial(\n\t    async_actor, priority=DramatiqWorkerPriority.MEDIUM, queue_name=lr_queue.queue\n\t)\n\tasync def startup() -> None:\n\t    \"\"\"This function should contain your resource initialization code.\"\"\"\n\t    logging.info(\"Starting up\")\n\tasync def shutdown() -> None:\n\t    \"\"\"This function should contain your resource teardown code.\"\"\"\n", "    logging.info(\"Shutting down\")\n\tclass MyAsyncMiddleware(AsyncMiddleware):\n\t    \"\"\"Middleware to run the startup/shutdown functions on worker start/stop.\"\"\"\n\t    def before_async_worker_thread_startup(\n\t        self, _: RabbitmqBroker, thread: AsyncWorker, **kwargs: dict[str, Any]\n\t    ) -> None:\n\t        thread.event_loop.run_until_complete(startup())\n\t    def after_async_worker_thread_shutdown(\n\t        self, _: RabbitmqBroker, thread: AsyncWorker, **kwargs: dict[str, Any]\n\t    ) -> None:\n", "        thread.event_loop.run_until_complete(shutdown())\n\t        thread.event_loop.close()\n\tdef configure() -> None:\n\t    # Configure Backend and Broker\n\t    if config.testing:\n\t        broker = StubBroker()\n\t        backend = AsyncStubBackend()\n\t        logging.info(\"Testing\")\n\t    else:\n\t        broker = RabbitmqBroker(\n", "            host=config.broker_host,\n\t            port=config.broker_port,\n\t            credentials=config.broker_credentials,\n\t        )\n\t        backend = AsyncRedisBackend(host=config.redis_host, port=config.redis_port)\n\t        logging.info(f\"Broker: {config.broker_host}:{config.broker_port}\")\n\t        logging.info(f\"Backend: {config.redis_host}:{config.redis_port}\")\n\t    adtq.set_broker(broker)\n\t    adtq.set_backend(backend)\n\t    # Setup Middleware\n", "    if config.testing:\n\t        adtq.get_broker().add_middleware(StubAsyncMiddleware())\n\t    else:\n\t        adtq.get_broker().add_middleware(MyAsyncMiddleware())\n\t    # Setup Queues\n\t    for queue_name in queues.keys():\n\t        kwargs = {\"ensure\": True} if not config.testing else {}\n\t        adtq.get_broker().declare_queue(queue_name, **kwargs)\n\t        logging.info(f\"Declared queue: {queue_name}\")\n\t    logging.info(\"Configured Dramatiq\")\n", "configure()\n"]}
{"filename": "src/async_dramatiq/types.py", "chunked_list": ["# Standard Library Imports\n\timport sys\n\tfrom dataclasses import dataclass\n\t# Use IntEnum if Python version is greater than 3.11\n\tif sys.version_info < (3, 11):\n\t    from enum import Enum as IntEnum\n\telse:\n\t    from enum import IntEnum\n\tclass DramatiqWorkerPriority(IntEnum):\n\t    CRITICAL = 0\n", "    VERY_HIGH = 1\n\t    HIGH = 3\n\t    MEDIUM = 4\n\t    LOW = 5\n\t    VERY_LOW = 6\n\t@dataclass\n\tclass TaskQueue:\n\t    queue: str\n\t    message_ttl: int | None = 60 * 60  # Max time a task can sit in the queue\n"]}
{"filename": "src/async_dramatiq/scheduler.py", "chunked_list": ["# Standard Library Imports\n\tfrom dataclasses import dataclass\n\tfrom datetime import timedelta\n\tfrom typing import Any, Callable\n\tfrom apscheduler.triggers.cron import CronTrigger\n\tfrom apscheduler.triggers.interval import IntervalTrigger\n\t@dataclass\n\tclass ScheduledFunction:\n\t    trigger: CronTrigger | IntervalTrigger\n\t    module_path: str\n", "    func_name: str\n\t# Global list of scheduled jobs\n\tscheduled_jobs: list[ScheduledFunction] = []\n\tdef _add_trigger(\n\t    trigger: CronTrigger | IntervalTrigger, func: Callable[..., Any]\n\t) -> None:\n\t    global scheduled_jobs\n\t    scheduled_jobs.append(\n\t        ScheduledFunction(\n\t            trigger=trigger, module_path=func.__module__, func_name=func.__name__\n", "        )\n\t    )\n\tdef register_cron(func: Callable[..., Any], crontab: str) -> None:\n\t    \"\"\"Register a function to be called on a cron schedule.\n\t    :param func: The function to call.\n\t    :param crontab: The cron schedule at which to call the function at.\n\t        Check out https://crontab.guru/ for help.\n\t    \"\"\"\n\t    _add_trigger(CronTrigger.from_crontab(crontab), func)\n\tdef register_interval(func: Callable[..., Any], interval: timedelta) -> None:\n", "    \"\"\"Register a function to be called on an interval.\n\t    :param func: The function to call.\n\t    :param interval: The interval at which to call the function at. This is a timedelta.\n\t    \"\"\"\n\t    _add_trigger(IntervalTrigger(seconds=interval.total_seconds()), func)\n"]}
{"filename": "src/async_dramatiq/actor.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\timport inspect\n\tfrom datetime import timedelta\n\tfrom typing import Any, Callable\n\timport dramatiq as dq\n\tfrom .scheduler import register_cron, register_interval\n\tfrom .types import DramatiqWorkerPriority\n\tclass AsyncActor(dq.Actor):\n\t    def __init__(self, *args: Any, **kwargs: dict[str, Any]) -> None:\n", "        super().__init__(*args, **kwargs)\n\t        self.event_loop: asyncio.BaseEventLoop | None = None\n\t    def __call__(self, *args: Any, **kwargs: dict[str, Any]) -> Any:\n\t        \"\"\"Call this function apropriately depending on its type.\n\t        :param *args: Positional arguments to send to the actor.\n\t        :param **kwargs: Keyword arguments to send to the actor.\n\t        :return: Whatever the underlying function backing this actor returns.\n\t        \"\"\"\n\t        try:\n\t            running_event_loop = asyncio.get_running_loop()\n", "        except RuntimeError:\n\t            running_event_loop = None\n\t        if inspect.iscoroutinefunction(self.fn):\n\t            if running_event_loop:  # Call function directly on running event loop\n\t                result = self.fn(*args, **kwargs)\n\t            elif (  # Run function async worker thread event loop\n\t                self.event_loop and self.event_loop.is_running()\n\t            ):\n\t                future = asyncio.run_coroutine_threadsafe(\n\t                    self.fn(*args, **kwargs), self.event_loop\n", "                )\n\t                result = future.result()\n\t            else:  # This should not happen\n\t                raise RuntimeError(\"No event\")\n\t        else:  # Call function directly\n\t            result = self.fn(*args, **kwargs)\n\t        return result\n\t    def set_event_loop(self, loop: asyncio.BaseEventLoop | None) -> None:\n\t        self.event_loop = loop\n\tdef async_actor(\n", "    *,\n\t    interval: timedelta | None = None,\n\t    crontab: str | None = None,\n\t    priority: DramatiqWorkerPriority = DramatiqWorkerPriority.MEDIUM,\n\t    actor_class: type[AsyncActor] = AsyncActor,\n\t    queue_name: str = \"default\",\n\t    **kwargs: Any,\n\t) -> Any:\n\t    \"\"\"Thin wrapper which turns a function into a dramatiq actor.\n\t    :param interval: Run this function at a defined interval\n", "    :param crontab: Run this function as a cron job. See https://crontab.guru/.\n\t    :param priority: The actor's global priority.  If two tasks have\n\t        been pulled on a worker concurrently and one has a higher\n\t        priority than the other then it will be processed first.\n\t        Lower numbers represent higher priorities.\n\t    :param actor_class: The actor class to use\n\t    :param queue_name: The name of the queue to send messages to\n\t    :param kwargs: Input parameters for the dramatiq actor\n\t    Dramatiq Actor: https://dramatiq.io/_modules/dramatiq/actor.html\n\t    \"\"\"\n", "    def decorator(func: Callable[..., Any]) -> dq.Actor:\n\t        actor = dq.actor(\n\t            func,\n\t            actor_class=actor_class,\n\t            priority=priority,\n\t            queue_name=queue_name,\n\t            **kwargs,\n\t        )\n\t        if crontab:\n\t            register_cron(actor.fn, crontab)\n", "        if interval:\n\t            register_interval(actor.fn, interval)\n\t        return actor\n\t    return decorator\n"]}
{"filename": "src/async_dramatiq/__init__.py", "chunked_list": ["from dramatiq import get_broker, set_broker  # noqa: F401\n\tfrom .actor import AsyncActor, async_actor  # noqa: F401\n\tfrom .backends import get_backend, set_backend  # noqa: F401\n\tfrom .types import DramatiqWorkerPriority, TaskQueue  # noqa: F401\n"]}
{"filename": "src/async_dramatiq/worker.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\tfrom threading import Event, Thread\n\timport dramatiq as dq\n\tclass AsyncWorker(Thread):\n\t    \"\"\"Worker thread that runs and manages the Asyncio Event Loop.\"\"\"\n\t    def __init__(self, startup_event: Event, broker: dq.broker.Broker) -> None:\n\t        Thread.__init__(self)\n\t        self.startup_event = startup_event\n\t        self.broker = broker\n", "    def run(self) -> None:\n\t        self.event_loop = asyncio.new_event_loop()\n\t        asyncio.set_event_loop(self.event_loop)\n\t        self.broker.emit_before(\"async_worker_thread_startup\", self)\n\t        for actor in [  # Set event loop of actors to this loop\n\t            self.broker.get_actor(a) for a in self.broker.get_declared_actors()\n\t        ]:\n\t            actor.set_event_loop(self.event_loop)\n\t        # Signal that the event loop has started\n\t        self.event_loop.call_soon_threadsafe(self.startup_event.set)\n", "        self.event_loop.run_forever()\n\t        self.broker.emit_after(\"async_worker_thread_shutdown\", self)\n\t    def stop(self) -> None:\n\t        self.event_loop.call_soon_threadsafe(self.event_loop.stop)\n\t    def pause(self) -> None:\n\t        pass\n\t    def resume(self) -> None:\n\t        pass\n"]}
{"filename": "src/async_dramatiq/backends/async_stub.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\timport time\n\timport dramatiq as dq\n\tfrom dramatiq.results.backend import (\n\t    BACKOFF_FACTOR,\n\t    DEFAULT_TIMEOUT,\n\t    Missing,\n\t    Result,\n\t    ResultMissing,\n", "    ResultTimeout,\n\t    compute_backoff,\n\t)\n\tfrom dramatiq.results.backends import StubBackend\n\tclass AsyncStubBackend(StubBackend):\n\t    async def get_result(\n\t        self, message: dq.Message, *, block: bool = False, timeout: int | None = None\n\t    ) -> Result:\n\t        \"\"\"Get a result from the backend.\n\t        Sub-second timeouts are not respected by this backend.\n", "        :param message: The dramatiq message object\n\t        :param block: Whether or not to block until a result is set.\n\t        :param timeout: The maximum amount of time, in ms, to wait for\n\t          a result when block is True.  Defaults to 10 seconds.\n\t        :raise ResultMissing: When block is False and the result isn't set.\n\t        :raise ResultTimeout: When waiting for a result times out.\n\t        :return: The result object.\n\t        \"\"\"\n\t        if timeout is None:\n\t            timeout = DEFAULT_TIMEOUT\n", "        end_time = time.monotonic() + timeout / 1000\n\t        message_key = self.build_message_key(message)\n\t        attempts = 0\n\t        while True:\n\t            result = self._get(message_key)\n\t            if result is Missing and block:\n\t                attempts, delay = compute_backoff(attempts, factor=BACKOFF_FACTOR)\n\t                delay /= 1000\n\t                if time.monotonic() + delay > end_time:\n\t                    raise ResultTimeout(message)\n", "                await asyncio.sleep(delay)\n\t                continue\n\t            elif result is Missing:\n\t                raise ResultMissing(message)\n\t            else:\n\t                return self.unwrap_result(result)\n"]}
{"filename": "src/async_dramatiq/backends/async_redis.py", "chunked_list": ["import dramatiq as dq\n\tfrom dramatiq.results.backend import (\n\t    DEFAULT_TIMEOUT,\n\t    Result,\n\t    ResultMissing,\n\t    ResultTimeout,\n\t)\n\tfrom dramatiq.results.backends.redis import RedisBackend\n\tclass AsyncRedisBackend(RedisBackend):\n\t    \"\"\"A Redis backend that supports async redis client.\n", "    TODO: Use async redis client instead of sync client\n\t    \"\"\"\n\t    async def get_result(\n\t        self, message: dq.Message, *, block: bool = False, timeout: int | None = None\n\t    ) -> Result:\n\t        \"\"\"Get a result from the backend. Sub-second timeouts are not respected by\n\t        this backend.\n\t        :param message: The dramatiq message object\n\t        :param block: Whether or not to block until a result is set.\n\t        :param timeout: The maximum amount of time, in ms, to wait for\n", "          a result when block is True.  Defaults to 10 seconds.\n\t        :raise ResultMissing: When block is False and the result isn't set.\n\t        :raise ResultTimeout: When waiting for a result times out.\n\t        :return: The result object.\n\t        \"\"\"\n\t        if timeout is None:\n\t            timeout = DEFAULT_TIMEOUT\n\t        message_key = self.build_message_key(message)\n\t        if block:\n\t            timeout = int(timeout / 1000)\n", "            if timeout == 0:\n\t                data = self.client.rpoplpush(message_key, message_key)\n\t            else:\n\t                data = self.client.brpoplpush(message_key, message_key, timeout)\n\t            if data is None:\n\t                raise ResultTimeout(message)\n\t        else:\n\t            data = self.client.lindex(message_key, 0)\n\t            if data is None:\n\t                raise ResultMissing(message)\n", "        return self.unwrap_result(self.encoder.decode(data))\n"]}
{"filename": "src/async_dramatiq/backends/__init__.py", "chunked_list": ["from dramatiq import get_broker\n\tfrom dramatiq.results import Results\n\tfrom dramatiq.results.backend import ResultBackend\n\tfrom .async_redis import AsyncRedisBackend  # noqa: F401\n\tfrom .async_stub import AsyncStubBackend  # noqa: F401\n\tbackend: ResultBackend | None = None\n\tdef get_backend() -> ResultBackend:\n\t    global backend\n\t    return backend\n\tdef set_backend(input: ResultBackend) -> None:\n", "    global backend\n\t    backend = input\n\t    get_broker().add_middleware(Results(backend=input))\n"]}
{"filename": "src/async_dramatiq/middleware/async_base.py", "chunked_list": ["# Standard Library Imports\n\tfrom threading import Event\n\tfrom typing import Any\n\timport dramatiq as dq\n\t# Local Application Imports\n\tfrom async_dramatiq.worker import AsyncWorker\n\tclass AsyncMiddleware(dq.Middleware):\n\t    \"\"\"Middleware that runs the Asyncio Event Loop in a separate worker.\"\"\"\n\t    def before_worker_boot(self, broker: dq.Broker, worker: dq.Worker) -> None:\n\t        startup_event = Event()\n", "        async_worker = AsyncWorker(startup_event, broker)\n\t        async_worker.start()\n\t        startup_event.wait()  # Wait until the Asyncio Event Loop has started\n\t        worker.workers.append(async_worker)\n\t    def before_async_worker_thread_startup(\n\t        self, broker: dq.Broker, thread: AsyncWorker, **kwargs: dict[str, Any]  # noqa\n\t    ) -> None:\n\t        pass\n\t    def after_async_worker_thread_shutdown(\n\t        self, broker: dq.Broker, thread: AsyncWorker, **kwargs: dict[str, Any]  # noqa\n", "    ) -> None:\n\t        pass\n"]}
{"filename": "src/async_dramatiq/middleware/async_stub.py", "chunked_list": ["# Standard Library Imports\n\timport asyncio\n\timport dramatiq as dq\n\tclass StubAsyncMiddleware(dq.Middleware):\n\t    \"\"\"Stub middleware that sets the event loop of actors to the current loop.\n\t    This is used for testing. Standard use case would be to add the following\n\t    fixture in your conftest.py:\n\t        @pytest.fixture(scope=\"session\")\n\t        def event_loop() -> Generator[asyncio.BaseEventLoop, None, None]:\n\t            loop = asyncio.get_event_loop_policy().new_event_loop()\n", "            yield loop\n\t            loop.close()\n\t    \"\"\"\n\t    event_loop: asyncio.BaseEventLoop\n\t    def before_worker_boot(self, broker: dq.Broker, worker: dq.Worker) -> None:\n\t        event_loop = asyncio.get_event_loop()\n\t        for actor in [  # Set event loop of actors to this loop\n\t            broker.get_actor(a) for a in broker.get_declared_actors()\n\t        ]:\n\t            actor.set_event_loop(event_loop)\n", "    def before_worker_shutdown(self, broker: dq.Broker, _: dq.Worker) -> None:\n\t        for actor in [  # Set event loop of actors to this loop\n\t            broker.get_actor(a) for a in broker.get_declared_actors()\n\t        ]:\n\t            actor.set_event_loop(None)\n"]}
{"filename": "src/async_dramatiq/middleware/__init__.py", "chunked_list": ["from .async_base import AsyncMiddleware  # noqa: F401\n\tfrom .async_stub import StubAsyncMiddleware  # noqa: F401\n"]}
