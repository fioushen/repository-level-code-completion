{"filename": "aiofauna/typedefs.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import Any, Dict, Generic, Iterable, List, Type, TypeVar, Union, cast\n\tfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\n\tVector = List[float]\n\tMetaData = Dict[str, str]\n\tT = TypeVar(\"T\")\n\tclass LazyProxy(Generic[T], ABC):\n\t    def __init__(self) -> None:\n\t        self.__proxied: Union[T, None] = None\n\t    def __getattr__(self, attr: str) -> object:\n", "        return getattr(self.__get_proxied__(), attr)\n\t    def __repr__(self) -> str:\n\t        return repr(self.__get_proxied__())\n\t    def __dir__(self) -> Iterable[str]:\n\t        return self.__get_proxied__().__dir__()\n\t    def __get_proxied__(self) -> T:\n\t        proxied = self.__proxied\n\t        if proxied is not None:\n\t            return proxied\n\t        self.__proxied = proxied = self.__load__()\n", "        return proxied\n\t    def __set_proxied__(self, value: T) -> None:\n\t        self.__proxied = value\n\t    def __as_proxied__(self) -> T:\n\t        \"\"\"Helper method that returns the current proxy, typed as the loaded object\"\"\"\n\t        return cast(T, self)\n\t    @abstractmethod\n\t    def __load__(self) -> T:\n\t        ...\n\tclass FunctionType(BaseModel, ABC):\n", "    _subclasses: List[Type[\"FunctionType\"]] = []\n\t    @classmethod\n\t    def __init_subclass__(cls, **kwargs):\n\t        super().__init_subclass__(**kwargs)\n\t        _schema = cls.schema()\n\t        if cls.__doc__ is None:\n\t            raise ValueError(\n\t                f\"FunctionType subclass {cls.__name__} must have a docstring\"\n\t            )\n\t        cls.openaischema = {\n", "            \"name\": cls.__name__,\n\t            \"description\": cls.__doc__,\n\t            \"parameters\": {\n\t                \"type\": \"object\",\n\t                \"properties\": _schema[\"properties\"],\n\t                \"required\": _schema[\"required\"],\n\t            },\n\t        }\n\t        cls._subclasses.append(cls)\n\t    @abstractmethod\n", "    async def run(self) -> Any:\n\t        ...\n\tF = TypeVar(\"F\", bound=FunctionType)\n"]}
{"filename": "aiofauna/__main__.py", "chunked_list": ["import os\n\timport subprocess\n\timport click\n\tfrom .utils import setup_logging\n\tlogger = setup_logging(__name__)\n\t@click.group()\n\tdef main():\n\t    pass\n\tdef print_tree(dirname, pref=\"\"):\n\t    for item in os.listdir(dirname):\n", "        if item.startswith(\".\"):\n\t            continue\n\t        print(pref + item)\n\t        if os.path.isdir(os.path.join(dirname, item)):\n\t            logger.info(\n\t                os.path.join(dirname, item), \" \" * len(pref) + \"|\" + (\"_\" * 5) + \" \"\n\t            )\n\t@main.command()\n\tdef tree():\n\t    print_tree(os.getcwd())\n", "@main.command()\n\t@click.option(\"--port\", default=5000)\n\t@click.option(\"--host\", default=\"0.0.0.0\")\n\t@click.option(\"--reload\", default=True)\n\t@click.option(\"--worker\", default=1)\n\t@click.option(\"--threads\", default=1)\n\t@click.argument(\"name\")\n\tdef run(name, port, host, reload, worker, threads):\n\t    subprocess.run(\n\t        [\n", "            \"gunicorn\",\n\t            \"-b\",\n\t            f\"{host}:{port}\",\n\t            \"--reload\" if reload else \"\",\n\t            \"--workers\",\n\t            str(worker),\n\t            \"--threads\",\n\t            str(threads),\n\t            name,\n\t        ],\n", "        check=True,\n\t    )\n"]}
{"filename": "aiofauna/docs.py", "chunked_list": ["\"\"\"Automatically generate OpenAPI documentation for your AioFauna API.\"\"\"\n\tfrom json import JSONDecoder, loads\n\tfrom typing import Any, Dict\n\tfrom aiohttp.web import Request\n\tfrom aiohttp.web_request import FileField\n\tfrom multidict import CIMultiDict\n\tfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\n\tfrom .json import parse_json\n\tdef extract(params: dict, path: str):\n\t    \"\"\"\n", "    Extract OpenAPI parameters from the function parameters.\n\t    Args:\n\t        params (dict): The parameters of the function.\n\t        path (str): The URL path of the endpoint.\n\t    Returns:\n\t        Dict[str, Any]: The extracted OpenAPI parameters.\n\t    \"\"\"\n\t    open_api_params = {}\n\t    for name, param in params.items():\n\t        type_ = param.annotation\n", "        if type_ in (str, int, float, bool) and name:\n\t            if f\"{{{name}}}\" in path:\n\t                param_location = \"path\"\n\t            else:\n\t                param_location = \"query\"\n\t            open_api_params[name] = {\n\t                \"in\": param_location,\n\t                \"name\": name,\n\t                \"required\": True,\n\t                \"schema\": {\"type\": type_, \"default\": param.default, \"required\": True},\n", "            }\n\t        elif type_ in [FileField]:\n\t            open_api_params[name] = {\n\t                \"in\": \"formData\",\n\t                \"name\": name,\n\t                \"required\": True,\n\t                \"schema\": {\"type\": \"file\", \"format\": \"binary\"},\n\t                \"consumes\": [\"multipart/form-data\"],\n\t                \"headers\": {\n\t                    \"Content-Type\": {\"type\": \"string\", \"default\": \"multipart/form-data\"}\n", "                },\n\t            }\n\t        elif issubclass(type_, (BaseModel)):\n\t            open_api_params[name] = {\n\t                \"in\": \"body\",\n\t                \"name\": name,\n\t                \"required\": True,\n\t                \"schema\": type_.schema(),\n\t            }\n\t        else:\n", "            continue\n\t    return open_api_params\n\tdef transform(\n\t    open_api: Dict[str, Any],\n\t    path: str,\n\t    method: str,\n\t    func: Any,\n\t    open_api_params: Dict[str, Any],\n\t):\n\t    \"\"\"\n", "    Update the OpenAPI documentation with the endpoint information.\n\t    Args:\n\t        open_api (Dict[str, Any]): The OpenAPI documentation.\n\t        path (str): The URL path of the endpoint.\n\t        method (str): The HTTP method of the endpoint.\n\t        func (Any): The function being documented.\n\t        open_api_params (Dict[str, Any]): The OpenAPI parameters of the function.\n\t    \"\"\"\n\t    if path in [\"/openapi.json\", \"/docs\"]:\n\t        return\n", "    _scalars = []\n\t    _body = None\n\t    _is_file_upload = False\n\t    for param in open_api_params.values():\n\t        if isinstance(param[\"schema\"], dict):\n\t            if \"type\" in param[\"schema\"] and param[\"schema\"][\"type\"] != \"object\":\n\t                _scalars.append(param)\n\t            else:\n\t                _body = {\"content\": {\"application/json\": {\"schema\": param[\"schema\"]}}}\n\t        elif param[\"in\"] == \"formData\" and param[\"schema\"][\"type\"] == \"file\":\n", "            _is_file_upload = True\n\t            _scalars.append(param)\n\t        else:\n\t            continue\n\t    if _body:\n\t        open_api[\"paths\"].setdefault(path, {})[method.lower()] = {\n\t            \"summary\": func.__name__,\n\t            \"description\": func.__doc__,\n\t            \"parameters\": _scalars,\n\t            \"requestBody\": _body\n", "            if not _is_file_upload\n\t            else {\n\t                \"content\": {\n\t                    \"multipart/form-data\": {\n\t                        \"schema\": {\n\t                            \"properties\": {\n\t                                \"file\": {\n\t                                    \"type\": \"array\",\n\t                                    \"items\": {\"type\": \"string\", \"format\": \"binary\"},\n\t                                }\n", "                            }\n\t                        }\n\t                    }\n\t                }\n\t            },\n\t            \"responses\": {\"200\": {\"description\": \"OK\"}},\n\t        }\n\t    else:\n\t        open_api[\"paths\"].setdefault(path, {})[method.lower()] = {\n\t            \"summary\": func.__name__,\n", "            \"description\": func.__doc__,\n\t            \"parameters\": _scalars,\n\t            \"responses\": {\"200\": {\"description\": \"OK\"}},\n\t        }\n\tasync def load(request: Request, params: dict):\n\t    \"\"\"\n\t    Shape the endpoint function parameters to match the request.\n\t    Args:\n\t        request (Request): The HTTP request.\n\t        params (dict): The parameters of the function.\n", "    Returns:\n\t        Dict[str, Any]: The updated parameters to apply to the function.\n\t    \"\"\"\n\t    args_to_apply = {}\n\t    for name, param in params.items():\n\t        annotation = param.annotation\n\t        if annotation in (str, int, float, bool) and name in request.match_info:\n\t            args_to_apply[name] = request.match_info[name]\n\t        elif annotation in (str, int, float, bool) and name in request.query:\n\t            args_to_apply[name] = annotation(request.query[name])\n", "        elif annotation in [FileField]:\n\t            headers = dict(request.headers)\n\t            new_headers = CIMultiDict(\n\t                **headers, **{\"content-type\": \"multipart/form-data\"}  # type: ignore\n\t            )\n\t            new_request = request.clone(headers=new_headers)\n\t            args_to_apply[name] = new_request\n\t        elif issubclass(annotation, BaseModel):\n\t            data = await request.json(loads=JSONDecoder().decode)\n\t            if isinstance(data, (str, bytes)):\n", "                data = loads(data, object_hook=parse_json)\n\t            args_to_apply[name] = annotation(**data)\n\t        else:\n\t            args_to_apply[name] = request\n\t    return args_to_apply\n\thtml = \"\"\"<!DOCTYPE html>\n\t            <html lang=\"en\">\n\t            <head>\n\t                <meta charset=\"UTF-8\">\n\t                <title>AioFauna</title>\n", "                <link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui.css\" >\n\t                <link rel=\"icon\" type=\"image/png\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/favicon-32x32.png\" sizes=\"32x32\" />\n\t                <link rel=\"icon\" type=\"image/png\" href=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/favicon-16x16.png\" sizes=\"16x16\" />\n\t                <style>\n\t                html\n\t                {\n\t                    box-sizing: border-box;\n\t                    overflow: -moz-scrollbars-vertical;\n\t                    overflow-y: scroll;\n\t                }\n", "                .swagger-ui .topbar\n\t                {\n\t                    display: none;\n\t                }\n\t                *,\n\t                *:before,\n\t                *:after\n\t                {\n\t                    box-sizing: inherit;\n\t                }\n", "                body\n\t                {\n\t                    margin:0;\n\t                    background: #fafafa;\n\t                }\n\t                </style>\n\t            </head>\n\t            <body>\n\t                <script src=\"https://cdn.jsdelivr.net/npm/@unocss/runtime/mini.global.js\"></script>\n\t                <nav class=\"bg-gray-800 text-white w-full\">\n", "                    <div class=\"container mx-auto px-6 py-3\">\n\t                        <div class=\"flex flex-col md:flex-row md:justify-between md:items-center\">\n\t                            <div class=\"flex justify-between items-center\">\n\t                                My API\n\t                            </div>\n\t                            <div class=\"flex mt-2 md:mt-0\">\n\t                                <a class=\"block md:inline-block mt-0 text-gray-200 hover:text-white mr-4\" href=\"/docs\">Documentation</a>\n\t                            </div>\n\t                        </div>\n\t                    </div>\n", "                </nav>\n\t                <div id=\"swagger-ui\"></div>\n\t                <script src=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui-bundle.js\"> </script>\n\t                <script src=\"https://cdn.jsdelivr.net/npm/swagger-ui-dist@3.20.3/swagger-ui-standalone-preset.js\"> </script>\n\t                <script>\n\t                window.onload = function() {\n\t                const ui = SwaggerUIBundle({\n\t                    url: \"/openapi.json\",\n\t                    dom_id: '#swagger-ui',\n\t                    deepLinking: true,\n", "                    presets: [\n\t                    SwaggerUIBundle.presets.apis,\n\t                    SwaggerUIStandalonePreset\n\t                    ],\n\t                    plugins: [\n\t                    SwaggerUIBundle.plugins.DownloadUrl\n\t                    ],\n\t                    layout: \"StandaloneLayout\"\n\t                })\n\t                window.ui = ui\n", "                }\n\t            </script>\n\t            </body>\n\t            </html>\n\t            \"\"\"\n"]}
{"filename": "aiofauna/client.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport json\n\timport logging\n\timport os\n\timport typing\n\tfrom dataclasses import dataclass, field\n\tfrom functools import wraps\n\tfrom re import T\n\tfrom threading import Lock\n", "from typing import Any, AsyncGenerator, Dict, List, Literal, Optional, Type, Union\n\tfrom aiohttp import (\n\t    ClientConnectionError,\n\t    ClientConnectorSSLError,\n\t    ClientResponse,\n\t    ClientSession,\n\t    ClientTimeout,\n\t    TCPConnector,\n\t)\n\tfrom aiohttp.web_exceptions import HTTPException\n", "from dotenv import load_dotenv\n\tfrom multidict import CIMultiDict\n\tfrom pydantic import BaseModel\n\tfrom aiofauna.faunadb.query import sin\n\tfrom .faunadb.errors import FaunaException\n\tfrom .faunadb.objects import Expr\n\tfrom .json import to_json\n\tfrom .typedefs import LazyProxy\n\tfrom .utils import setup_logging\n\tload_dotenv()\n", "Method = Literal[\"GET\", \"POST\", \"PUT\", \"PATCH\", \"DELETE\"]\n\tJson = Union[Dict[str, Any], List[Dict[str, Any]]]\n\tMaybeJson = Optional[Json]\n\tHeaders = Dict[str, str]\n\tMaybeHeaders = Optional[Headers]\n\tclass MissingEnvironmentVariable(Exception):\n\t    \"\"\"Exception for missing environment variable.\"\"\"\n\t    ...\n\tif \"FAUNA_SECRET\" not in os.environ:\n\t    raise MissingEnvironmentVariable(\n", "        \"The FAUNA_SECRET environment variable is not set.\"\n\t    )\n\tFAUNA_SECRET = os.environ[\"FAUNA_SECRET\"]\n\tHEADERS = {\n\t    \"Authorization\": f\"Bearer {FAUNA_SECRET}\",\n\t    \"Content-type\": \"application/json\",\n\t    \"Accept\": \"application/json\",\n\t    \"User-Agent\": \"aiofauna-framework\",\n\t}\n\tT = typing.TypeVar(\"T\")\n", "logger = setup_logging(__name__)\n\tFAUNA_EXCEPTIONS = (\n\t    HTTPException,\n\t    FaunaException,\n\t    ValueError,\n\t    KeyError,\n\t    TypeError,\n\t    Exception,\n\t    UnicodeError,\n\t    json.JSONDecodeError,\n", "    RuntimeError,\n\t    ClientConnectionError,\n\t    ClientConnectorSSLError,\n\t)\n\tHTTP_EXCEPTIONS = (\n\t    HTTPException,\n\t    FaunaException,\n\t    ValueError,\n\t    KeyError,\n\t    TypeError,\n", "    Exception,\n\t)\n\tdef singleton(cls: typing.Type[T]) -> typing.Callable[..., T]:  # type: ignore\n\t    instance = None\n\t    lock = Lock()\n\t    @wraps(cls)\n\t    def wrapper(*args, **kwargs):\n\t        nonlocal instance\n\t        if instance is None:\n\t            with lock:\n", "                if instance is None:\n\t                    instance = cls(*args, **kwargs)\n\t        return instance\n\t    return wrapper\n\tclass APIException(HTTPException):\n\t    \"\"\"Base class for all exceptions raised by an API client.\"\"\"\n\t    def __init__(self, message: str, status_code: int = 500) -> None:\n\t        self.message = message\n\t        self.status_code = status_code\n\t        super().__init__(\n", "            text=json.dumps({\"message\": message, \"status\": status_code}),\n\t            content_type=\"application/json\",\n\t        )\n\t@dataclass(frozen=True)\n\tclass ConnectorConfig:\n\t    ssl: bool = field(default=False)\n\t    limit: int = field(default=1000)\n\t    keepalive_timeout: int = field(default=10)\n\t@dataclass(init=True, repr=True, unsafe_hash=False, frozen=False)\n\tclass APIConfig:\n", "    base_url: str\n\t    headers: Headers\n\t    logger: logging.Logger = field(default=setup_logging(__name__))\n\t    exception_class: Type[HTTPException] = field(default=APIException)\n\t    session: Optional[ClientSession] = field(default=None)\n\t    connector_config: ConnectorConfig = field(default_factory=ConnectorConfig)\n\t    read_bufsize: int = field(default=2**16)\n\t    connector_owner: bool = field(default=True)\n\t    trust_env: bool = field(default=True)\n\t@dataclass(init=True, repr=True, unsafe_hash=False, frozen=False)\n", "class FaunaClient(LazyProxy[ClientSession]):\n\t    \"\"\"\n\t    FaunaDB Client\n\t    Args:\n\t        config (APIConfig): APIConfig object\n\t    \"\"\"\n\t    config: APIConfig = APIConfig(\n\t        base_url=\"https://db.fauna.com\",\n\t        headers=HEADERS,\n\t        logger=setup_logging(__name__),\n", "        exception_class=APIException,\n\t        session=None,\n\t        connector_config=ConnectorConfig(),\n\t    )\n\t    session_creation_lock = asyncio.Lock()\n\t    def __load__(self) -> ClientSession:\n\t        if self.config.session is None:\n\t            return ClientSession(\n\t                \"https://db.fauna.com\",\n\t                headers=CIMultiDict(self.config.headers),  # type: ignore\n", "                connector=TCPConnector(\n\t                    keepalive_timeout=self.config.connector_config.keepalive_timeout,\n\t                    ssl=self.config.connector_config.ssl,\n\t                    limit=self.config.connector_config.limit,\n\t                ),\n\t                connector_owner=self.config.connector_owner,\n\t                trust_env=self.config.trust_env,\n\t                read_bufsize=self.config.read_bufsize,\n\t            )\n\t        return self.config.session\n", "    async def query(self, expr: Expr) -> Any:\n\t        async with self.session_creation_lock:\n\t            if self.config.session is None:\n\t                self.config.session = self.__load__()\n\t        session = self.config.session\n\t        async with session.post(\n\t            \"/\",\n\t            data=to_json(expr),\n\t        ) as response:\n\t            try:\n", "                data = await response.json()\n\t                self.config.logger.info(data)\n\t                if data.get(\"resource\") is not None:\n\t                    return data[\"resource\"]\n\t                if data.get(\"error\") is not None:\n\t                    return data[\"error\"]\n\t                return data\n\t            except FAUNA_EXCEPTIONS as exc:  # pylint:disable=all\n\t                self.config.logger.error(exc)\n\t                raise self.config.exception_class from exc\n", "    async def stream(self, expr: Expr) -> AsyncGenerator[str, None]:\n\t        session = self.__load__()\n\t        async with session.post(\n\t            \"\",\n\t            data=to_json(expr),\n\t            headers={\n\t                \"Authorization\": f\"Bearer {self.secret}\",\n\t                \"Content-type\": \"application/json\",\n\t                \"Accept\": \"text/event-stream\",\n\t                \"Keep-Alive\": \"timeout=5, max=900\",\n", "                \"Connection\": \"keep-alive\",\n\t                \"Cache-Control\": \"no-cache\",\n\t                \"X-Last-Seen-Txn\": \"0\",\n\t                \"X-Request-By\": \"aiofauna\",\n\t                \"X-Query-By\": \"@obahamonde\",\n\t            },\n\t        ) as response:\n\t            async for chunk in response.content.iter_any():\n\t                try:\n\t                    yield chunk.decode()\n", "                except FAUNA_EXCEPTIONS as exc:\n\t                    self.config.logger.error(exc)\n\t                    yield str(exc)\n\t    async def cleanup(self):\n\t        if self.config.session is not None:\n\t            await self.config.session.close()\n\t@dataclass(init=True, repr=True, unsafe_hash=False, frozen=False)\n\tclass APIClient(LazyProxy[ClientSession]):\n\t    \"\"\"\n\t    HTTP Client:\n", "    Base class to create HTTP clients that wrap `aiohttp.ClientSession`.\n\t    Provides Lazy Loading through proxy objects and session reuse using the singleton pattern.\n\t    Constructor Signature:\n\t    `base_url` (str): Base URL of the API. For example: `https://api.openai.com`. Must the an absolute URL.\n\t    `headers` (dict): Headers that will proxide the authentication credentials, content_type, etc.\n\t    \"\"\"\n\t    base_url: str = field(init=True, repr=True)\n\t    headers: Dict[str, str] = field(default_factory=dict)\n\t    _subclasses: Optional[List[Type[APIClient]]] = None\n\t    _session_creation_lock = asyncio.Lock()\n", "    _session: Optional[ClientSession] = None\n\t    @classmethod\n\t    def __init_subclass__(cls, **kwargs):\n\t        super().__init_subclass__(**kwargs)\n\t        if cls._subclasses is None:\n\t            cls._subclasses = []\n\t        cls._subclasses.append(cls)\n\t    @classmethod\n\t    async def cleanup(cls):\n\t        if hasattr(cls, \"_subclasses\") and cls._subclasses is not None:\n", "            tasks = []\n\t            for subclass in cls._subclasses:\n\t                if subclass._session is not None:\n\t                    tasks.append(subclass._session.close())\n\t            await asyncio.gather(*tasks)\n\t            cls._subclasses = None\n\t    async def __load__(self) -> ClientSession:\n\t        async with self._session_creation_lock:\n\t            if self._session is None:\n\t                self._session = ClientSession(\n", "                    base_url=self.base_url,\n\t                    headers=CIMultiDict(self.headers),\n\t                    response_class=ClientResponse,\n\t                    connector=TCPConnector(\n\t                        keepalive_timeout=60,\n\t                        ssl=False,\n\t                        limit=1000,\n\t                    ),\n\t                    timeout=ClientTimeout(total=60),\n\t                    connector_owner=False,\n", "                    trust_env=False,\n\t                    read_bufsize=2**18,\n\t                )\n\t        return self._session\n\t    def __repr__(self) -> str:\n\t        return f\"<{self.__class__.__name__} {self.base_url}>\"\n\t    async def fetch(\n\t        self,\n\t        url: str,\n\t        method: Method = \"GET\",\n", "        json: MaybeJson = None,\n\t    ):\n\t        session = await self.__load__()\n\t        async with session.request(\n\t            method, url, headers=self.headers, json=json\n\t        ) as response:\n\t            try:\n\t                return await response.json()\n\t            except (\n\t                HTTP_EXCEPTIONS\n", "            ) as exc:  # pylint:disable=broad-exception-caught, unused-variable\n\t                logger.error(exc)\n\t                raise APIException(str(exc)) from exc\n\t    async def text(self, url: str, method: Method = \"GET\", json: MaybeJson = None):\n\t        session = await self.__load__()\n\t        async with session.request(\n\t            method, url, headers=self.headers, json=json\n\t        ) as response:\n\t            try:\n\t                return await response.text()\n", "            except (\n\t                HTTP_EXCEPTIONS\n\t            ) as exc:  # pylint:disable=broad-exception-caught, unused-variable\n\t                logger.error(exc)\n\t                raise APIException(str(exc)) from exc\n\t    async def stream(\n\t        self,\n\t        url: str,\n\t        method: Method = \"GET\",\n\t        json: MaybeJson = None,\n", "    ):\n\t        session = await self.__load__()\n\t        async with session.request(\n\t            method, url, headers=self.headers, json=json\n\t        ) as response:\n\t            async for chunk in response.content.iter_any():\n\t                try:\n\t                    yield chunk.decode()\n\t                except HTTP_EXCEPTIONS as exc:\n\t                    logger.error(exc)\n", "                    yield str(exc)\n\t                    raise APIException(str(exc)) from exc\n\t    async def get(self, url: str):\n\t        return await self.fetch(url=url, method=\"GET\")\n\t    async def post(self, url: str, json: MaybeJson = None):\n\t        return await self.fetch(url=url, method=\"POST\", json=json)\n\t    async def put(self, url: str, json: MaybeJson = None):\n\t        return await self.fetch(url=url, method=\"PUT\", json=json)\n\t    async def patch(self, url: str, json: MaybeJson = None):\n\t        return await self.fetch(url=url, method=\"PATCH\", json=json)\n", "    async def delete(self, url: str, json: MaybeJson = None):\n\t        return await self.fetch(url=url, method=\"DELETE\", json=json)\n\t    def update_headers(self, headers: Dict[str, str]):\n\t        \"\"\"\n\t        Update the headers used by this API client.\n\t        Returns:\n\t            self: Allows method chaining.\n\t        \"\"\"\n\t        self.headers.update(headers)\n\t        return self\n"]}
{"filename": "aiofauna/__init__.py", "chunked_list": ["\"\"\"\n\tAioFauna\n\t\"\"\"\n\t__version__ = (0, 2, 0)\n\t__author__ = \"obahamonde\"\n\t__license__ = \"MIT\"\n\t__doc__ = \"\"\"\n\t---\n\ttitle: AioFauna\n\t---\n", "# AioFauna\n\t🚀 Introducing aiofauna: A full-stack framework built on top of Aiohttp, Pydantic and Faun\n\t🔥 Inspired by FastAPI focuses on Developer Experience, Productivity and Versatil\n\t🌟 Featu\n\t✅ Supports Python 3.7+, comes with an opinionated ODM (Object Document Mapper) out of the box for FaunaDB that abstracts out complex FQL expressions into pythonic, fully typed asynchronous methods for all CRUD operations.\n\t✅ Performant and scalable: Built on top of Aiohttp a powerful http server and client and FaunaDB an scalable serverless database for modern applications.\n\t✅ Async/await coroutines: Leverage the power of async programming for enhanced performance and responsiveness, being ASGI compliant is compatible with most async python frameworks.\n\t✅ Automatic Swagger UI generation: Automatic generation of interactive Swagger UI documentation for instant testing of your API.\n\t✅ SSE (Server Sent Events): Built-in support for SSE (Server Sent Events) for real-time streaming of data from FaunaDB to your application.\n\t✅ Robust data validation: Built-in support for Pydantic models for robust data validation and serialization.\n", "✅ Auto-provisioning: Automatic management of indexes, unique indexes, and collections with FaunaModel ODM.\n\t✅ Full JSON communication: Custom encoder to ensure seamless data exchange between your application and FaunaDB backend.\n\t✅ Markdown and Jinja support with live reload: experiment an smooth frontend devserver experience without leaving your backend code.\n\t✅ Inspired by fastapi, you will work with almost the same syntax and features like path operations, path parameters, query parameters, request body, status codes and more.\n\t💡 With aiofauna, you can build fast, scalable, and reliable modern applications, while building seamless integrations thanks to the fastest http client aiohttp and the most versatile database FaunaDB, you will enjoy integrating with third party services such as APIs, Data Sources and Cloud Servi\n\t📚 Check out the aiofauna library, and start building your next-gen applications tod\n\t#Python #FaunaDB #Async #Pydantic #aiofauna\n\t⚙️ If you are using a synchronous framework check out [Faudantic](https://github.com/obahamonde/faudantic) for a similar experience with FaunaDB and Pydantic.\n\t📚 [Documentation](https://obahamonde-aiofauna-docs.smartpro.solutions) (Built with aiofa\n\t📦 [PyPi](https://pypi.org/project/aiofau\n", "📦 [GitHub](https://github.com/obahamonde/aiofa\n\t📦 [Demo](https://aiofaunastreams-fwuw7gz7oq-uc.a.run.app/) (Real time Latency Monitoring between FaunaDB and Google Cloud \n\t)\n\t\"\"\"\n\tfrom typing import *  # pylint: disable=wildcard-import,unused-wildcard-import\n\tfrom aiohttp.web import Request, Response\n\tfrom aiohttp.web_request import FileField\n\tfrom aiohttp.web_ws import WebSocketResponse\n\tfrom aiohttp_sse import EventSourceResponse\n\tfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\n", "from .client import APIClient, APIConfig, FaunaClient\n\tfrom .faunadb import query as q\n\tfrom .fields import Field\n\tfrom .helpers import aio, asyncify\n\tfrom .json import FaunaJSONEncoder as JSONEncoder\n\tfrom .json import _parse_json_hook as default\n\tfrom .json import parse_json as loads\n\tfrom .json import to_json as dumps\n\tfrom .odm import FaunaModel\n\tfrom .server import APIServer\n", "from .typedefs import LazyProxy\n\tfrom .utils import setup_logging\n"]}
{"filename": "aiofauna/utils.py", "chunked_list": ["\"\"\"Logging and error handling utilities for the OpenAI Function Python package.\"\"\"\n\timport logging\n\tfrom typing import Any, Callable, Coroutine, TypeVar, cast\n\tfrom aiohttp.web_exceptions import HTTPException\n\tfrom rich.console import Console\n\tfrom rich.logging import RichHandler\n\tfrom rich.pretty import install\n\tfrom rich.traceback import install as ins\n\tT = TypeVar(\"T\")\n\tdef setup_logging(name: str) -> logging.Logger:\n", "    \"\"\"\n\t    Set's up logging using the Rich library for pretty and informative terminal logs.\n\t    Arguments:\n\t    name -- Name for the logger instance. It's best practice to use the name of the module where logger is defined. # pylint: disable=line-too-long\n\t    \"\"\"\n\t    # Install pretty representations of data structures using Rich library.\n\t    install()\n\t    # Install Rich traceback handler.\n\t    ins()\n\t    # Create a Console object that can record terminal output.\n", "    console = Console(record=True, force_terminal=True)\n\t    # Create a RichHandler for rich logging.\n\t    console_handler = RichHandler(\n\t        console=console,\n\t        show_time=True,\n\t        show_path=True,\n\t        markup=True,\n\t        rich_tracebacks=True,\n\t        tracebacks_show_locals=True,\n\t        tracebacks_extra_lines=5,\n", "        tracebacks_theme=\"solarized\",\n\t    )\n\t    # Set the log level and formatter for the console handler.\n\t    console_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n\t    console_handler.setLevel(logging.INFO)\n\t    # Setup basic configuration for logging.\n\t    logging.basicConfig(level=logging.INFO, handlers=[console_handler])\n\t    # Create and return a logger with the specified name.\n\t    logger_ = logging.getLogger(name)\n\t    logger_.setLevel(logging.INFO)\n", "    return logger_\n\t# Set up a logger for this module.\n\tlogger = setup_logging(__name__)\n\tdef handle_errors(\n\t    func: Callable[..., Coroutine[Any, Any, T]]\n\t) -> Callable[..., Coroutine[Any, Any, T]]:  # pylint: disable=line-too-long\n\t    \"\"\"\n\t    A decorator to handle errors in an asynchronous function.\n\t    Arguments:\n\t    func -- The asynchronous function whose errors are to be handled.\n", "    \"\"\"\n\t    async def wrapper(*args: Any, **kwargs: Any) -> T:\n\t        \"\"\"\n\t        Wrapper function to handle errors in the function call.\n\t        \"\"\"\n\t        try:\n\t            logger.info(\"Calling %s\", func.__name__)\n\t            return await func(*args, **kwargs)\n\t        except HTTPException as exc:\n\t            logger.error(exc.__class__.__name__)\n", "            logger.error(exc.reason)\n\t            raise exc from exc\n\t        except Exception as exc:\n\t            logger.error(exc.__class__.__name__)\n\t            logger.error(str(exc))\n\t            raise exc from exc\n\t    return wrapper\n\tdef chunker(seq, size):\n\t    return (seq[pos : pos + size] for pos in range(0, len(seq), size))\n\tdef gen_emptystr() -> str:\n", "    return cast(str, None)\n"]}
{"filename": "aiofauna/json.py", "chunked_list": ["import base64\n\tfrom base64 import urlsafe_b64decode, urlsafe_b64encode\n\tfrom datetime import date, datetime\n\tfrom enum import Enum\n\tfrom json import JSONEncoder, dumps, loads\n\tfrom time import time\n\tfrom typing import Any, Dict, List, Literal, TypeVar\n\tfrom uuid import UUID\n\tfrom iso8601 import parse_date\n\tfrom pydantic import BaseModel  # pylint: disable=no-name-in-module\n", "from typing_extensions import override\n\tfrom .faunadb.objects import FaunaTime, Native, Query, Ref, SetRef\n\tfrom .faunadb.query import Expr\n\tT = TypeVar(\"T\")\n\tFaunaKey = Literal[\n\t    \"@ref\", \"@obj\", \"@set\", \"@query\", \"@ts\", \"@date\", \"@bytes\", \"@index\", \"@class\"\n\t]\n\tdef _parse_json_hook(dct: Dict[FaunaKey, Any]):\n\t    if \"@ref\" in dct:\n\t        ref = dct[\"@ref\"]\n", "        if not \"collection\" in ref and not \"database\" in ref:\n\t            return Native.from_name(ref[\"id\"])\n\t        return Ref(ref[\"id\"], ref.get(\"collection\"), ref.get(\"database\"))\n\t    if \"@obj\" in dct:\n\t        return dct[\"@obj\"]\n\t    if \"@set\" in dct:\n\t        return SetRef(dct[\"@set\"])\n\t    if \"@query\" in dct:\n\t        return Query(dct[\"@query\"])\n\t    if \"@ts\" in dct:\n", "        return FaunaTime(dct[\"@ts\"])\n\t    if \"@date\" in dct:\n\t        return parse_date(dct[\"@date\"]).date()\n\t    if \"@bytes\" in dct:\n\t        return bytearray(urlsafe_b64decode(dct[\"@bytes\"].encode()))\n\t    return dct\n\tdef parse_json(json_string):\n\t    try:\n\t        return loads(json_string, object_hook=_parse_json_hook)\n\t    except ValueError:\n", "        pass\n\tdef to_json(dct, pretty=True, sort_keys=True):\n\t    if pretty:\n\t        return dumps(\n\t            dct,\n\t            cls=FaunaJSONEncoder,\n\t            sort_keys=True,\n\t            indent=4,\n\t            separators=(\", \", \": \"),\n\t            allow_nan=False,\n", "            ensure_ascii=True,\n\t        )\n\t    return dumps(\n\t        dct,\n\t        cls=FaunaJSONEncoder,\n\t        sort_keys=sort_keys,\n\t        separators=(\",\", \":\"),\n\t        allow_nan=False,\n\t        ensure_ascii=True,\n\t        exclude_none=True,\n", "    )\n\tclass FaunaJSONEncoder(JSONEncoder):\n\t    @override\n\t    def default(self, obj):\n\t        if isinstance(obj, (Ref, SetRef, FaunaTime, Query)):\n\t            return obj.to_fauna_json()\n\t        if isinstance(obj, Expr):\n\t            return obj.to_fauna_json()\n\t        elif isinstance(obj, datetime):\n\t            return obj.astimezone().isoformat()\n", "        elif isinstance(obj, date):\n\t            return {\"@date\": obj.isoformat()}\n\t        elif isinstance(obj, (bytes, bytearray)):\n\t            _val = None\n\t            try:\n\t                _val = obj.decode()\n\t            except:\n\t                _val = urlsafe_b64encode(obj).decode()  # pylint: disable=all\n\t            return {\"@bytes\": _val}\n\t        elif isinstance(obj, BaseModel):\n", "            return obj.dict()\n\t        elif isinstance(obj, Enum):\n\t            return obj.value\n\t        elif isinstance(obj, UUID):\n\t            return {\"@uuid\": str(obj)}\n\t        else:\n\t            return super().default(obj)\n\tclass JSONModel(BaseModel):\n\t    def to_dict(self, **kwargs):\n\t        return parse_json(self.to_json(**kwargs))\n", "    def to_json(self, **kwargs) -> str:\n\t        return to_json(super().dict(exclude_none=True, **kwargs))\n\t    @override\n\t    def dict(self, **kwargs):\n\t        return self.to_dict(**kwargs)\n\t    @override\n\t    def json(self, **kwargs) -> str:\n\t        return self.to_json(exclude_none=True, **kwargs)\n\tdef jsonable_encoder(\n\t    obj: Any,\n", "    *,\n\t    include: List[str] = [],\n\t    exclude: List[str] = [],\n\t    by_alias: bool = False,\n\t    skip_defaults: bool = False,\n\t    custom_encoder: Any = None,\n\t) -> Any:\n\t    \"\"\"\n\t    Convert any object to a JSON-serializable object.\n\t    This function is used by Aiofauna to convert objects to JSON-serializable objects.\n", "    It supports all the types supported by the standard json library, plus:\n\t    * datetime.datetime\n\t    * datetime.date\n\t    * datetime.time\n\t    * uuid.UUID\n\t    * enum.Enum\n\t    * pydantic.BaseModel\n\t    \"\"\"\n\t    if custom_encoder is None:\n\t        custom_encoder = FaunaJSONEncoder\n", "    if obj is str:\n\t        return \"string\"\n\t    if obj is int or obj is float:\n\t        return \"integer\"\n\t    if obj is bool:\n\t        return \"boolean\"\n\t    if obj is None:\n\t        return \"null\"\n\t    if obj is list:\n\t        return \"array\"\n", "    if obj is dict:\n\t        return \"object\"\n\t    if obj is bytes:\n\t        return \"binary\"\n\t    if obj is datetime:\n\t        return \"date-time\"\n\t    if obj is date:\n\t        return \"date\"\n\t    if obj is time:\n\t        return \"time\"\n", "    if obj is UUID:\n\t        return \"uuid\"\n\t    if obj is Enum:\n\t        return \"enum\"\n\t    if isinstance(obj, (str, int, float, bool, type(None))):\n\t        return obj\n\t    if isinstance(obj, (list, tuple, set, frozenset)):\n\t        return [\n\t            jsonable_encoder(\n\t                v,\n", "                include=include,\n\t                exclude=exclude,\n\t                by_alias=by_alias,\n\t                skip_defaults=skip_defaults,\n\t                custom_encoder=custom_encoder,\n\t            )\n\t            for v in obj\n\t        ]\n\t    if isinstance(obj, dict):\n\t        return {\n", "            jsonable_encoder(\n\t                k,\n\t                include=include,\n\t                exclude=exclude,\n\t                by_alias=by_alias,\n\t                skip_defaults=skip_defaults,\n\t                custom_encoder=custom_encoder,\n\t            ): jsonable_encoder(\n\t                v,\n\t                include=include,\n", "                exclude=exclude,\n\t                by_alias=by_alias,\n\t                skip_defaults=skip_defaults,\n\t                custom_encoder=custom_encoder,\n\t            )\n\t            for k, v in obj.items()\n\t        }\n\t    if isinstance(obj, bytes):\n\t        return base64.b64encode(obj).decode()\n\t    if isinstance(obj, (set, frozenset)):\n", "        return [\n\t            jsonable_encoder(\n\t                v,\n\t                include=include,\n\t                exclude=exclude,\n\t                by_alias=by_alias,\n\t                skip_defaults=skip_defaults,\n\t                custom_encoder=custom_encoder,\n\t            )\n\t            for v in obj\n", "        ]\n\t    if isinstance(obj, datetime):\n\t        return obj.isoformat()\n\t    if isinstance(obj, Enum):\n\t        return obj.value\n\t    if isinstance(obj, UUID):\n\t        return str(obj)\n\t    if isinstance(obj, type):\n\t        return jsonable_encoder(\n\t            obj.__name__,\n", "            include=include,\n\t            exclude=exclude,\n\t            by_alias=by_alias,\n\t            skip_defaults=skip_defaults,\n\t            custom_encoder=custom_encoder,\n\t        )\n\t    return custom_encoder().default(obj)\n"]}
{"filename": "aiofauna/fields.py", "chunked_list": ["from pydantic.fields import Field as F  # pylint: disable=no-name-in-module\n\tdef Field(*args, index: bool = False, unique: bool = False, **kwargs):\n\t    \"\"\"Field Factory\"\"\"\n\t    return F(*args, index=index, unique=unique, **kwargs)\n"]}
{"filename": "aiofauna/odm.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\tfrom typing import Any, List, Optional, Type, TypeVar\n\tfrom dotenv import load_dotenv\n\tfrom pydantic import Field\n\tfrom pydantic.main import ModelMetaclass\n\tfrom .client import FaunaClient\n\tfrom .faunadb import query as q\n\tfrom .faunadb.errors import FaunaException\n\tfrom .json import JSONModel\n", "from .utils import gen_emptystr, setup_logging\n\tload_dotenv()\n\tT = TypeVar(\"T\", bound=\"FaunaModel\")\n\tclass FaunaModelMetaclass(ModelMetaclass):\n\t    def __new__(cls, name, bases, attrs):\n\t        new_cls = super().__new__(cls, name, bases, attrs)\n\t        cls.Metadata.__subclasses__.append(new_cls)\n\t        return new_cls\n\t    class Metadata:\n\t        __subclasses__: List[Type[FaunaModel]] = []\n", "class FaunaModel(JSONModel, metaclass=FaunaModelMetaclass):\n\t    ref: str = Field(default_factory=gen_emptystr)\n\t    ts: str = Field(default_factory=gen_emptystr)\n\t    @classmethod\n\t    @property\n\t    def logger(cls):\n\t        return setup_logging(cls.__name__)\n\t    @classmethod\n\t    async def create_all(cls):\n\t        await asyncio.gather(\n", "            *[model.provision() for model in cls.Metadata.__subclasses__]\n\t        )\n\t    @classmethod\n\t    def client(cls):\n\t        return FaunaClient()\n\t    @classmethod\n\t    def q(cls):\n\t        return cls.client().query\n\t    @classmethod\n\t    async def provision(cls) -> bool:\n", "        _q = cls.q()\n\t        try:\n\t            if not await _q(q.exists(q.collection(cls.__name__.lower()))):\n\t                await _q(q.create_collection({\"name\": cls.__name__.lower()}))\n\t                cls.logger.info(\"Created collection %s\", cls.__name__.lower())\n\t            if not await _q(q.exists(q.index(cls.__name__.lower()))):\n\t                await _q(\n\t                    q.create_index(\n\t                        {\n\t                            \"name\": cls.__name__.lower(),\n", "                            \"source\": q.collection(cls.__name__.lower()),\n\t                        }\n\t                    )\n\t                )\n\t                cls.logger.info(\"Created index %s\", cls.__name__.lower())\n\t            for field in cls.__fields__.values():\n\t                if field.field_info.extra.get(\"unique\"):\n\t                    if not await _q(\n\t                        q.exists(q.index(f\"{cls.__name__.lower()}_{field.name}_unique\"))\n\t                    ):\n", "                        await _q(\n\t                            q.create_index(\n\t                                {\n\t                                    \"name\": f\"{cls.__name__.lower()}_{field.name}_unique\",\n\t                                    \"source\": q.collection(cls.__name__.lower()),\n\t                                    \"terms\": [{\"field\": [\"data\", field.name]}],\n\t                                    \"unique\": True,\n\t                                }\n\t                            )\n\t                        )\n", "                        cls.logger.info(\n\t                            \"Created unique index %s_%s\",\n\t                            cls.__name__.lower(),\n\t                            field.name,\n\t                        )\n\t                    continue\n\t                if field.field_info.extra.get(\"index\"):\n\t                    if not await _q(\n\t                        q.exists(q.index(f\"{cls.__name__.lower()}_{field.name}\"))\n\t                    ):\n", "                        await _q(\n\t                            q.create_index(\n\t                                {\n\t                                    \"name\": f\"{cls.__name__.lower()}_{field.name}\",\n\t                                    \"source\": q.collection(cls.__name__.lower()),\n\t                                    \"terms\": [{\"field\": [\"data\", field.name]}],\n\t                                }\n\t                            )\n\t                        )\n\t                        cls.logger.info(\n", "                            \"Created index %s_%s\", cls.__name__.lower(), field.name\n\t                        )\n\t                        continue\n\t            return True\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n\t            cls.logger.error(exc)\n\t            return False\n\t    @classmethod\n\t    async def find_unique(cls: Type[T], **kwargs: Any) -> T:\n", "        try:\n\t            field, value = list(kwargs.items())[0]\n\t            data = await cls.q()(\n\t                q.get(q.match(q.index(f\"{cls.__name__.lower()}_{field}_unique\"), value))\n\t            )\n\t            return cls(\n\t                **{\n\t                    **data[\"data\"],  # type: ignore\n\t                    \"ref\": data[\"ref\"][\"@ref\"][\"id\"],  # type: ignore\n\t                    \"ts\": data[\"ts\"] / 1000,  # type: ignore\n", "                }\n\t            )\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n\t            cls.logger.error(exc)\n\t            return None  # type: ignore\n\t    @classmethod\n\t    async def find_many(cls: Type[T], limit: int = 50, **kwargs: Any) -> List[T]:\n\t        try:\n\t            _q = cls.q()\n", "            field, value = list(kwargs.items())[0]\n\t            refs = await _q(\n\t                q.paginate(q.match(q.index(f\"{cls.__name__.lower()}_{field}\"), value))\n\t            )\n\t            refs = refs[\"data\"][:limit]\n\t            return await asyncio.gather(*[cls.get(item[\"@ref\"][\"id\"]) for item in refs])\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n\t            cls.logger.error(exc)\n\t            return []\n", "    @classmethod\n\t    async def get(cls: Type[T], ref: str) -> T:\n\t        try:\n\t            data = await cls.q()(q.get(q.ref(q.collection(cls.__name__.lower()), ref)))\n\t            return cls(\n\t                **{\n\t                    **data[\"data\"],  # type: ignore\n\t                    \"ref\": data[\"ref\"][\"@ref\"][\"id\"],  # type: ignore\n\t                    \"ts\": data[\"ts\"] / 1000,  # type: ignore\n\t                }\n", "            )\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n\t            cls.logger.error(exc)\n\t            raise exc\n\t    @classmethod\n\t    async def all(cls: Type[T], limit: int = 100, offset: int = 0) -> List[T]:\n\t        try:\n\t            _q = cls.q()\n\t            query = q.paginate(q.match(q.index(f\"{cls.__name__.lower()}\")))\n", "            refs = (await _q(query))[\"data\"][offset:limit]\n\t            return await asyncio.gather(*[cls.get(item[\"@ref\"][\"id\"]) for item in refs])\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n\t            cls.logger.error(exc)\n\t            raise exc\n\t    @classmethod\n\t    async def delete_one(cls: Type[T], **kwargs: Any) -> bool:\n\t        try:\n\t            field, value = list(kwargs.items())[0]\n", "            _q = cls.q()\n\t            ref = await _q(\n\t                q.get(q.match(q.index(f\"{cls.__name__.lower()}_{field}_unique\"), value))\n\t            )\n\t            await _q(q.delete(ref))\n\t            return True\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n\t            cls.logger.error(exc)\n\t            return False\n", "    @classmethod\n\t    async def delete(cls, ref: str) -> bool:\n\t        try:\n\t            await cls.q()(q.delete(q.ref(q.collection(cls.__name__.lower()), ref)))\n\t            return True\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n\t            cls.logger.error(exc)\n\t            return False\n\t    async def create(self: T) -> T:\n", "        try:\n\t            for field in self.__fields__.values():\n\t                if field.field_info.extra.get(\"unique\"):\n\t                    instance = await self.find_unique(\n\t                        **{field.name: self.__dict__[field.name]}\n\t                    )\n\t                    if instance is None:\n\t                        continue\n\t                    if issubclass(instance.__class__, FaunaModel):\n\t                        return instance\n", "            data = await self.__class__.q()(\n\t                q.create(\n\t                    q.collection(self.__class__.__name__.lower()), {\"data\": self.dict()}\n\t                )\n\t            )\n\t            self.ref = data[\"ref\"][\"@ref\"][\"id\"]  # type: ignore\n\t            self.ts = data[\"ts\"] / 1000  # type: ignore\n\t            return self\n\t        except (FaunaException, KeyError, TypeError, ValueError, Exception) as exc:\n\t            self.logger.error(exc.__class__.__name__)\n", "            self.logger.error(exc)\n\t            raise exc\n\t    @classmethod\n\t    async def update(cls: Type[T], ref: str, **kwargs: Any) -> T:\n\t        try:\n\t            instance = await cls.q()(\n\t                q.update(\n\t                    q.ref(q.collection(cls.__name__.lower()), ref),\n\t                    {\"data\": kwargs.get(\"kwargs\", kwargs)},\n\t                )\n", "            )\n\t            return cls(\n\t                **{\n\t                    **instance[\"data\"],  # type: ignore\n\t                    \"ref\": instance[\"ref\"][\"@ref\"][\"id\"],  # type: ignore\n\t                    \"ts\": instance[\"ts\"] / 1000,  # type: ignore\n\t                }\n\t            )\n\t        except (FaunaException, KeyError, TypeError) as exc:\n\t            cls.logger.error(exc.__class__.__name__)\n", "            cls.logger.error(exc)\n\t            raise ValueError(f\"Field {ref} not found\")  # pylint: disable=all\n\t    async def save(self: T) -> Optional[T]:\n\t        if isinstance(self.ref, str) and len(self.ref) == 18:\n\t            return await self.update(self.ref, kwargs=self.dict())\n\t        return await self.create()\n\t    @classmethod\n\t    async def cleanup(cls):\n\t        await cls.client().cleanup()\n"]}
{"filename": "aiofauna/server.py", "chunked_list": ["\"\"\"REST API Module with automatic OpenAPI generation.\"\"\"\n\timport asyncio\n\timport os\n\tfrom functools import wraps\n\tfrom inspect import signature\n\tfrom typing import Awaitable, Callable\n\tfrom aiohttp.typedefs import Handler\n\tfrom aiohttp.web import Application, FileResponse, Request, Response, StreamResponse\n\tfrom aiohttp.web_middlewares import middleware\n\tfrom aiohttp.web_ws import WebSocketResponse\n", "from aiohttp_sse import EventSourceResponse, sse_response\n\tfrom .client import APIClient\n\tfrom .docs import extract, html, load, transform\n\tfrom .helpers import do_response\n\tfrom .json import jsonable_encoder\n\tfrom .odm import FaunaModel\n\tfrom .utils import setup_logging\n\tMiddleware = Callable[[Request, Handler], Awaitable[StreamResponse]]\n\tclass APIServer(Application):\n\t    \"\"\"Aiohttp Application with automatic OpenAPI generation.\"\"\"\n", "    def __init__(self, *args, **kwargs):\n\t        super().__init__(*args, logger=setup_logging(self.__class__.__name__), **kwargs)\n\t        self.openapi = {\n\t            \"openapi\": \"3.0.0\",\n\t            \"info\": {\"title\": \"AioFauna\", \"version\": \"1.0.0\"},\n\t            \"paths\": {},\n\t            \"components\": {\"schemas\": {}},\n\t            \"description\": \"AioFauna API\",\n\t        }\n\t        self._route_open_api_params = {}\n", "        @self.get(\"/openapi.json\")\n\t        async def openapi():\n\t            response = jsonable_encoder(self.openapi)\n\t            return response\n\t        @self.get(\"/docs\")\n\t        async def docs():\n\t            return Response(text=html, content_type=\"text/html\")\n\t        @self.on_event(\"startup\")\n\t        async def startup(_):\n\t            await FaunaModel.create_all()\n", "        @self.on_event(\"shutdown\")\n\t        async def shutdown(_):\n\t            await APIClient.cleanup()\n\t            await FaunaModel.cleanup()\n\t    def document(self, path: str, method: str):\n\t        \"\"\"\n\t        Decorator to document a function.\n\t        \"\"\"\n\t        def decorator(func):\n\t            sig = signature(func)\n", "            params = sig.parameters\n\t            open_api_params = extract(params.copy(), path)\n\t            self._route_open_api_params[(path, method)] = open_api_params\n\t            transform(self.openapi, path, method, func, open_api_params)\n\t            async def wrapper(*args, **kwargs):\n\t                request: Request = args[0]\n\t                args = args[1:]\n\t                args_to_apply = await load(request, params.copy())\n\t                definitive_args = {}\n\t                for name, param in params.items():\n", "                    if name in args_to_apply:\n\t                        definitive_args[name] = args_to_apply[name]\n\t                    elif param.default is not param.empty:\n\t                        definitive_args[name] = param.default\n\t                    else:\n\t                        raise ValueError(\n\t                            f\"Missing parameter {name} for {func.__name__}\"\n\t                        )\n\t                if asyncio.iscoroutinefunction(func):\n\t                    response = await func(*args, **kwargs, **definitive_args)\n", "                else:\n\t                    response = func(*args, **kwargs, **definitive_args)\n\t                return do_response(response)\n\t            func.injectable = True\n\t            wrapper._handler = func\n\t            return wrapper\n\t        return decorator\n\t    def get(self, path: str, **kwargs):\n\t        \"\"\"GET decorator\"\"\"\n\t        def decorator(func):\n", "            self.router.add_get(path, self.document(path, \"GET\")(func), **kwargs)\n\t            return func\n\t        return decorator\n\t    def post(self, path: str, **kwargs):\n\t        \"\"\"POST decorator\"\"\"\n\t        def decorator(func):\n\t            self.router.add_post(path, self.document(path, \"POST\")(func), **kwargs)\n\t            return func\n\t        return decorator\n\t    def put(self, path: str, **kwargs):\n", "        \"\"\"PUT decorator\"\"\"\n\t        def decorator(func):\n\t            self.router.add_put(path, self.document(path, \"PUT\")(func), **kwargs)\n\t            return func\n\t        return decorator\n\t    def delete(self, path: str, **kwargs):\n\t        \"\"\"DELETE decorator\"\"\"\n\t        def decorator(func):\n\t            self.router.add_delete(path, self.document(path, \"DELETE\")(func), **kwargs)\n\t            return func\n", "        return decorator\n\t    def patch(self, path: str, **kwargs):\n\t        \"\"\"PATCH decorator\"\"\"\n\t        def decorator(func):\n\t            self.router.add_patch(path, self.document(path, \"PATCH\")(func), **kwargs)\n\t            return func\n\t        return decorator\n\t    def head(self, path: str, **kwargs):\n\t        \"\"\"HEAD decorator\"\"\"\n\t        def decorator(func):\n", "            self.router.add_head(path, self.document(path, \"HEAD\")(func), **kwargs)\n\t            return func\n\t        return decorator\n\t    def options(self, path: str, **kwargs):\n\t        \"\"\"OPTIONS decorator\"\"\"\n\t        def decorator(func):\n\t            self.router.add_options(\n\t                path, self.document(path, \"OPTIONS\")(func), **kwargs\n\t            )\n\t            return func\n", "        return decorator\n\t    def on_event(self, event: str):\n\t        \"\"\"On event handler\"\"\"\n\t        def decorator(func):\n\t            if event not in (\"startup\", \"shutdown\"):\n\t                raise ValueError(\"Event must be startup or shutdown\")\n\t            elif event == \"startup\":\n\t                self.on_startup.append(func)\n\t            else:\n\t                self.on_shutdown.append(func)\n", "            return func\n\t        return decorator\n\t    def sse(self, path: str) -> Callable:  # pylint: disable=invalid-name\n\t        \"\"\"Server-Sent Events decorator\"\"\"\n\t        def decorator(func: Callable) -> Callable:\n\t            @wraps(func)\n\t            async def wrapper(request: Request) -> EventSourceResponse:\n\t                async with sse_response(request) as resp:\n\t                    args_to_apply = await load(\n\t                        request, signature(func).parameters.copy()\n", "                    )\n\t                    definitive_args = {}\n\t                    for name, param in signature(func).parameters.items():\n\t                        if param.annotation == EventSourceResponse:\n\t                            definitive_args[name] = resp\n\t                        elif name in args_to_apply:\n\t                            definitive_args[name] = args_to_apply[name]\n\t                            args_to_apply.pop(name)\n\t                        elif param.default is not param.empty:\n\t                            definitive_args[name] = param.default\n", "                        else:\n\t                            raise ValueError(\n\t                                f\"Missing parameter {name} for {func.__name__}\"\n\t                            )\n\t                    await func(**definitive_args)\n\t                    return resp\n\t            self.router.add_get(path, wrapper)\n\t            return wrapper\n\t        return decorator\n\t    def websocket(self, path: str) -> Callable:  # pylint: disable=invalid-name\n", "        \"\"\"Websocket decorator\"\"\"\n\t        def decorator(func: Callable) -> Callable:\n\t            @wraps(func)\n\t            async def wrapper(request: Request):\n\t                args_to_apply = await load(request, signature(func).parameters.copy())\n\t                ws = WebSocketResponse()\n\t                await ws.prepare(request)\n\t                definitive_args = {}\n\t                for name, param in signature(func).parameters.items():\n\t                    if param.annotation == WebSocketResponse:\n", "                        definitive_args[name] = ws\n\t                    elif name in args_to_apply:\n\t                        definitive_args[name] = args_to_apply[name]\n\t                        args_to_apply.pop(name)\n\t                    elif param.default is not param.empty:\n\t                        definitive_args[name] = param.default\n\t                    else:\n\t                        raise ValueError(\n\t                            f\"Missing parameter {name} for {func.__name__}\"\n\t                        )\n", "                await func(**definitive_args)\n\t                return ws\n\t            self.router.add_get(path, wrapper)\n\t            return wrapper\n\t        return decorator\n\t    def static(self):\n\t        \"\"\"Static folder creation and serving\"\"\"\n\t        try:\n\t            os.makedirs(\"static\", exist_ok=True)\n\t        except OSError:\n", "            pass\n\t        self.router.add_static(\"/\", \"static\")\n\t        @self.get(\"/\")\n\t        def index():\n\t            return FileResponse(\"static/index.html\")\n\t        return self\n\t    def middleware(self, func: Middleware) -> Middleware:\n\t        @wraps(func)\n\t        @middleware\n\t        async def wrapper(request: Request, handler: Handler) -> Response:\n", "            response = await func(request, handler)\n\t            if isinstance(response, Response):\n\t                return response\n\t            return do_response(response)\n\t        self.middlewares.append(wrapper)\n\t        return wrapper\n"]}
{"filename": "aiofauna/helpers.py", "chunked_list": ["\"\"\"\n\tFlaskaesque helper functions for aiohttp.\n\t\"\"\"\n\timport asyncio\n\timport functools\n\timport json\n\timport types\n\timport typing\n\tfrom concurrent.futures import ThreadPoolExecutor\n\tfrom functools import singledispatch\n", "from typing import Any, List, Union\n\tfrom aiohttp.web import HTTPException, Request, Response, json_response\n\tfrom pydantic import BaseModel\n\tfrom aiofauna.json import FaunaJSONEncoder\n\tfrom .json import parse_json, to_json\n\tfrom .odm import FaunaModel\n\tT = typing.TypeVar(\"T\")\n\tdef asyncify(\n\t    func: typing.Callable[..., typing.Any],\n\t) -> typing.Callable[..., typing.Awaitable[typing.Any]]:\n", "    @functools.wraps(func)\n\t    def wrapper(self, *args, **kwargs):\n\t        bound = functools.partial(func, self, *args, **kwargs)\n\t        if asyncio.get_event_loop().is_running():\n\t            loop = asyncio.get_event_loop()\n\t            return loop.run_in_executor(self.executor, bound)\n\t        loop = asyncio.new_event_loop()\n\t        asyncio.set_event_loop(loop)\n\t        return loop.run_in_executor(self.executor, bound)\n\t    return typing.cast(typing.Callable[..., typing.Awaitable[typing.Any]], wrapper)\n", "def aio(max_workers: int = 5) -> typing.Callable[[typing.Type], typing.Type]:\n\t    \"\"\"Decorator that converts all the methods of a class into async methods.\"\"\"\n\t    def decorator(cls: typing.Type) -> typing.Type:\n\t        attrs: typing.Dict[str, typing.Any] = {}\n\t        attrs[\"executor\"] = ThreadPoolExecutor(max_workers=max_workers)\n\t        for attr_name, attr_value in cls.__dict__.items():\n\t            if (\n\t                isinstance(attr_value, types.FunctionType)\n\t                and attr_name.startswith(\"__\") is False\n\t            ):\n", "                attrs[attr_name] = asyncify(attr_value)\n\t            else:\n\t                attrs[attr_name] = attr_value\n\t        return type(cls.__name__, cls.__bases__, attrs)\n\t    return decorator\n\t@singledispatch\n\tdef do_response(response: Any) -> Response:\n\t    \"\"\"\n\t    Flask-esque function to make a response from a function.\n\t    \"\"\"\n", "    return response\n\t@do_response.register(BaseModel)\n\tdef _(response: BaseModel) -> Response:\n\t    return json_response(response.dict(exclude_none=True), dumps=to_json)\n\t@do_response.register(FaunaModel)\n\tdef _(response: FaunaModel) -> Response:\n\t    return json_response(response.dict(), dumps=to_json)\n\t@do_response.register(dict)\n\tdef _(response: dict) -> Response:\n\t    return json_response(response, dumps=to_json)\n", "@do_response.register(str)\n\tdef _(response: str) -> Response:\n\t    if response.startswith(\"<\") and response.endswith(\">\"):\n\t        return Response(status=200, text=response, content_type=\"text/html\")\n\t    return Response(status=200, text=response, content_type=\"text/plain\")\n\t@do_response.register(bytes)\n\tdef _(response: bytes) -> Response:\n\t    return Response(status=200, body=response, content_type=\"application/octet-stream\")\n\t@do_response.register(int)\n\tdef _(response: int) -> Response:\n", "    return Response(status=200, text=str(response), content_type=\"text/plain\")\n\t@do_response.register(float)\n\tdef _(response: float) -> Response:\n\t    return Response(status=200, text=str(response), content_type=\"text/plain\")\n\t@do_response.register(bool)\n\tdef _(response: bool) -> Response:\n\t    return Response(status=200, text=str(response), content_type=\"text/plain\")\n\t@do_response.register(list)\n\tdef _(response: List[Union[FaunaModel, BaseModel, dict, str, int, float]]) -> Response:\n\t    return json_response([x for x in response], dumps=to_json)\n"]}
{"filename": "aiofauna/llm/schemas.py", "chunked_list": ["\"\"\"Chat Completions Schemas\"\"\"\n\tfrom typing import List, Literal, NamedTuple, Union\n\timport numpy as np\n\tfrom ..odm import FaunaModel\n\tVector = Union[np.ndarray, List[float]]\n\tRole = Literal[\"assistant\", \"user\", \"system\", \"function\"]\n\tModel = Literal[\"gpt-4-0613\", \"gpt-3.5-turbo-16k-0613\"]\n\tclass Message(NamedTuple):\n\t    \"\"\"Defines a message within a conversation.\"\"\"\n\t    role: Role\n", "    content: str\n\tclass ChatCompletionRequest(NamedTuple):\n\t    \"\"\"Defines a request for a chat completion.\"\"\"\n\t    model: Model\n\t    messages: List[Message]\n\t    temperature: float\n\t    max_tokens: int\n\t    stream: bool\n\tclass ChatCompletionUssage(NamedTuple):\n\t    \"\"\"Defines the usage of the tokens for a chat completion.\"\"\"\n", "    prompt_tokens: int\n\t    completion_tokens: int\n\t    total_tokens: int\n\tclass ChatCompletionChoice(NamedTuple):\n\t    \"\"\"Defines a choice in a chat completion.\"\"\"\n\t    index: int\n\t    message: Message\n\t    finish_reason: str\n\tclass ChatCompletionResponse(NamedTuple):\n\t    \"\"\"Defines a response for a chat completion.\"\"\"\n", "    id: str\n\t    object: str\n\t    created: int\n\t    model: Model\n\t    choices: List[ChatCompletionChoice]\n\t    usage: ChatCompletionUssage\n\t    stream: bool\n\tclass VectorResponse(NamedTuple):\n\t    text: str\n\t    score: float\n", "class Embedding(FaunaModel):\n\t    \"\"\"Defines an embedding.\"\"\"\n\t    vector: Vector\n\t    namespace: str\n\t    text: str\n\t    async def similarity_search(\n\t        self, vector: Vector, namespace: str, limit: int = 1000, k: int = 10\n\t    ) -> List[VectorResponse]:\n\t        \"\"\"\n\t        Searches for similar embeddings.\n", "        Args:\n\t            vector: The vector to search for.\n\t            namespace: The namespace to search in.\n\t            limit: The maximum number of results to return.\n\t            k: The number of results to return per query.\n\t        Returns:\n\t            A list of VectorResponse.\n\t        \"\"\"\n\t        results = await self.find_many(limit=limit, namespace=namespace)\n\t        similarities = [\n", "            VectorResponse(text=result.text, score=result.similarity(vector))\n\t            for result in results\n\t        ]\n\t        return sorted(similarities, key=lambda x: x.score, reverse=True)[:k]\n\t    def similarity(self, vector: Vector):\n\t        return (np.dot(self.vector, vector)) / (\n\t            (np.linalg.norm(self.vector) * np.linalg.norm(vector))\n\t        )\n"]}
{"filename": "aiofauna/llm/llm.py", "chunked_list": ["import json\n\timport os\n\tfrom dataclasses import dataclass, field\n\tfrom typing import Any, AsyncGenerator, Dict, List, NamedTuple, Optional, Type\n\tfrom uuid import uuid4\n\timport openai\n\tfrom pydantic import Field  # pylint: disable=no-name-in-module\n\tfrom tqdm import tqdm\n\tfrom ..client import APIClient, APIException\n\tfrom ..typedefs import F, FunctionType, MetaData, Vector\n", "from ..utils import chunker, handle_errors, setup_logging\n\tfrom .schemas import List, Model\n\tlogger = setup_logging(__name__)\n\tclass Greet(FunctionType):\n\t    \"\"\"Placeholder function for greeting the user.\"\"\"\n\t    prompt: str = Field(..., description=\"The prompt to use for the completion.\")\n\t    async def run(self):\n\t        return \"Hello, I am a chatbot. How are you?\"\n\tclass UpsertVector(NamedTuple):\n\t    id: str = Field(default_factory=lambda: str(uuid4()))\n", "    values: Vector = Field(...)\n\t    metadata: MetaData = Field(...)\n\tclass UpsertRequest(NamedTuple):\n\t    vectors: List[UpsertVector]\n\t    namespace: str\n\tclass UpsertResponse(NamedTuple):\n\t    upsertedCount: int\n\tclass QueryRequest(NamedTuple):\n\t    topK: int\n\t    namespace: str\n", "    vector: Vector\n\t    includeMetadata: bool\n\tclass QueryMatch(NamedTuple):\n\t    id: str\n\t    score: float\n\t    values: Vector\n\t    metadata: MetaData\n\tclass QueryResponse(NamedTuple):\n\t    matches: List[QueryMatch]\n\t    namespace: str\n", "    results: int\n\tclass IngestRequest(NamedTuple):\n\t    namespace: str\n\t    texts: List[str]\n\t@dataclass\n\tclass LLMStack(APIClient):\n\t    base_url: str = field(default_factory=lambda: os.environ.get(\"PINECONE_URL\"))  # type: ignore\n\t    headers: Dict[str, str] = field(default_factory=lambda: {\"api-key\": os.environ.get(\"PINECONE_API_KEY\")})  # type: ignore\n\t    model:Model = field(default_factory=lambda:\"gpt-3.5-turbo-16k-0613\")\n\t    @handle_errors\n", "    async def upsert_vectors(self, request: UpsertRequest) -> UpsertResponse:\n\t        response = await self.fetch(\n\t            \"/vectors/upsert\", method=\"POST\", json=request._asdict()\n\t        )\n\t        return UpsertResponse(**response)\n\t    @handle_errors\n\t    async def query_vectors(self, request: QueryRequest) -> QueryResponse:\n\t        response = await self.fetch(\"/query\", method=\"POST\", json=request._asdict())\n\t        return QueryResponse(**response)\n\t    @handle_errors\n", "    async def upsert_messages(\n\t        self,\n\t        user_embedding: Vector,\n\t        openai_embedding: Vector,\n\t        prompt: str,\n\t        text: str,\n\t        namespace: str,\n\t    ) -> None:\n\t        upsert_request = UpsertRequest(\n\t            vectors=[\n", "                UpsertVector(values=user_embedding, metadata={\"text\": prompt}),\n\t                UpsertVector(values=openai_embedding, metadata={\"text\": text}),\n\t            ],\n\t            namespace=namespace,\n\t        )\n\t        await self.upsert_vectors(upsert_request)\n\t    @handle_errors\n\t    async def chat(self, text: str, context: str) -> str:\n\t        \"\"\"Chat completion with no functions.\"\"\"\n\t        messages = [\n", "            {\"role\": \"user\", \"content\": text},\n\t            {\"role\": \"system\", \"content\": context},\n\t        ]\n\t        logger.info(\"Chat messages: %s\", messages)\n\t        response = await openai.ChatCompletion.acreate(\n\t            model=self.model, messages=messages\n\t        )\n\t        logger.info(\"Chat response: %s\", response)\n\t        assert isinstance(response, dict)\n\t        return response[\"choices\"][0][\"message\"][\"content\"]\n", "    @handle_errors\n\t    async def chat_with_memory(self, text: str, namespace: str, context: str) -> str:\n\t        \"\"\"Chat completion with similarity search retrieval from pinecone\"\"\"\n\t        try:\n\t            embedding = await self.create_embeddings(text)\n\t            query_request = QueryRequest(\n\t                vector=embedding, namespace=namespace, topK=3, includeMetadata=True\n\t            )\n\t            query_response = await self.query_vectors(query_request)\n\t            similar_text_chunks = [\n", "                i.get(\"metadata\", {}).get(\"text\", \"\") for i in query_response.matches  # type: ignore\n\t            ]\n\t            similar_text = \"Previous Similar results:\" + \"\\n\".join(similar_text_chunks)\n\t            messages = [\n\t                {\"role\": \"user\", \"content\": text},\n\t                {\"role\": \"system\", \"content\": similar_text},\n\t                {\"role\": \"system\", \"content\": context},\n\t            ]\n\t            response = await openai.ChatCompletion.acreate(\n\t                model=self.model,\n", "                messages=messages,\n\t            )\n\t            return response[\"choices\"][0][\"message\"][\"content\"]  # type: ignore\n\t        except Exception as exc:\n\t            logger.exception(exc)\n\t            raise APIException(message=str(exc)) from exc\n\t    @handle_errors\n\t    async def chat_with_functions(\n\t        self,\n\t        text: str,\n", "        context: Optional[str] = None,\n\t        functions: List[Type[F]] = FunctionType._subclasses,\n\t    ) -> Any:\n\t        \"\"\"Chat completion with functions.\"\"\"\n\t        return await function_call(text, context=context, functions=functions)\n\t    @handle_errors\n\t    async def create_embeddings(self, text: str) -> Vector:\n\t        \"\"\"Creates embeddings for the given texts.\"\"\"\n\t        response = await openai.Embedding.acreate(\n\t            model=\"text-embedding-ada-002\",\n", "            input=text,\n\t        )\n\t        return response[\"data\"][0][\"embedding\"]  # type: ignore\n\t    async def chat_stream(self, text: str) -> AsyncGenerator[str, None]:\n\t        \"\"\"Chat completion stream with no functions.\"\"\"\n\t        response = openai.ChatCompletion.acreate(\n\t            model=self.model,\n\t            messages=[{\"role\": \"user\", \"content\": text}],\n\t            stream=True,\n\t        )\n", "        async for i in response:  # type: ignore\n\t            assert isinstance(i, dict)\n\t            delta = i[\"choices\"][0][\"delta\"]\n\t            if \"content\" in delta:\n\t                yield delta[\"content\"]\n\t    async def chat_stream_with_memory(\n\t        self, text: str, namespace: str = \"default\"\n\t    ) -> AsyncGenerator[str, None]:\n\t        \"\"\"Chat completion stream with similarity search retrieval from pinecone\"\"\"\n\t        try:\n", "            embedding = await self.create_embeddings(text)\n\t            query_response: QueryResponse = await self.query_vectors(\n\t                QueryRequest(\n\t                    vector=embedding, namespace=namespace, topK=3, includeMetadata=True\n\t                )\n\t            )\n\t            similar_text_chunks = [\n\t                i.metadata.get(\"text\", \"\") for i in query_response.matches\n\t            ]\n\t            similar_text = \"Previous Similar results:\" + \"\\n\".join(similar_text_chunks)\n", "            response = openai.ChatCompletion.acreate(\n\t                model=self.model,\n\t                messages=[\n\t                    {\"role\": \"user\", \"content\": text},\n\t                    {\"role\": \"system\", \"content\": similar_text},\n\t                ],\n\t                stream=True,\n\t            )\n\t            assert isinstance(response, AsyncGenerator)\n\t            async for i in response:\n", "                assert isinstance(i, dict)\n\t                delta = i[\"choices\"][0][\"delta\"]\n\t                if \"content\" in delta:\n\t                    yield delta[\"content\"]\n\t        except Exception as exc:\n\t            logger.exception(exc.__class__.__name__)\n\t            logger.exception(exc)\n\t            raise APIException(message=str(exc)) from exc\n\t    @handle_errors\n\t    async def chatgpt(\n", "        self, text: str, context: str, namespace: str = \"default\", memory: bool = False\n\t    ):\n\t        \"\"\"ChatGPT4 is a function that allows you to chat with GPT-4, with the option of using memory or functions.\"\"\"\n\t        if memory:\n\t            return await self.chat_with_memory(\n\t                text=text, namespace=namespace, context=context\n\t            )\n\t        return await self.chat(text=text, context=context)\n\t    @handle_errors\n\t    async def ingest_bulk(self, data: IngestRequest, chunksize: int = 32):\n", "        total_chunks = len(data.texts) // chunksize + (len(data.texts) % chunksize > 0)\n\t        for chunk in tqdm(\n\t            chunker(data.texts, chunksize),\n\t            total=total_chunks,\n\t            desc=\"Ingesting\",\n\t            unit=\"chunks\",\n\t        ):\n\t            await self.upsert_vectors(\n\t                UpsertRequest(\n\t                    vectors=[\n", "                        UpsertVector(\n\t                            values=await self.create_embeddings(text),\n\t                            metadata={\"text\": text},\n\t                        )\n\t                        for text in chunk\n\t                    ],\n\t                    namespace=data.namespace,\n\t                )\n\t            )\n\tasync def parse_openai_response(  # pylint: disable=dangerous-default-value\n", "    response: dict,\n\t    functions: List[\n\t        Type[F]\n\t    ] = FunctionType._subclasses,  # pylint: disable=protected-access\n\t) -> Any:\n\t    \"\"\"Parse the response from OpenAI and return the result.\"\"\"\n\t    choice = response[\"choices\"][0][\"message\"]\n\t    if \"function_call\" in choice:\n\t        function_call_ = choice[\"function_call\"]\n\t        name = function_call_[\"name\"]\n", "        arguments = function_call_[\"arguments\"]\n\t        for i in functions:\n\t            if i.__name__ == name:\n\t                result = await i.run(i(**json.loads(arguments)))\n\t                break\n\t        else:\n\t            raise ValueError(f\"Function {name} not found\")\n\t        return result\n\t    return choice[\"content\"]\n\t@handle_errors\n", "async def function_call(  # pylint: disable=dangerous-default-value\n\t    text: str,\n\t    context: Optional[str] = None,\n\t    model: Model = \"gpt-3.5-turbo-16k-0613\",\n\t    functions: List[\n\t        Type[F]\n\t    ] = FunctionType._subclasses,  # pylint: disable=protected-access\n\t) -> Any:\n\t    \"\"\"\n\t    Function to call a OpenAI function with given text and context.\n", "    Arguments:\n\t    text -- Input text for the function\n\t    context -- Optional context for the function\n\t    model -- Model to be used. Defaults to \"gpt-4-0613\"\n\t    functions -- List of function types. Defaults to all subclasses of FunctionType.\n\t    \"\"\"\n\t    if context is not None:\n\t        messages = [\n\t            {\"role\": \"user\", \"content\": text},\n\t            {\"role\": \"system\", \"content\": context},\n", "        ]\n\t    else:\n\t        messages = [{\"role\": \"user\", \"content\": text}]\n\t    response = await openai.ChatCompletion.acreate(\n\t        model=model, messages=messages, functions=[i.openaischema for i in functions]\n\t    )\n\t    return await parse_openai_response(response, functions=functions)  # type: ignore\n"]}
{"filename": "aiofauna/llm/__init__.py", "chunked_list": ["from .llm import LLMStack, function_call\n"]}
{"filename": "aiofauna/faunadb/page.py", "chunked_list": ["from . import query\n\tclass Page:\n\t    @staticmethod\n\t    def from_raw(raw):\n\t        return Page(raw[\"data\"], raw.get(\"before\"), raw.get(\"after\"))\n\t    def __init__(self, data, before=None, after=None):\n\t        self.data = data\n\t        self.before = before\n\t        self.after = after\n\t    def map_data(self, func):\n", "        return Page([func(x) for x in self.data], self.before, self.after)\n\t    def __repr__(self):\n\t        return \"Page(data=%s, before=%s, after=%s)\" % (\n\t            self.data,\n\t            self.before,\n\t            self.after,\n\t        )\n\t    def __eq__(self, other):\n\t        return (\n\t            isinstance(other, Page)\n", "            and self.data == other.data\n\t            and self.before == other.before\n\t            and self.after == other.after\n\t        )\n\t    @staticmethod\n\t    def set_iterator(client, set_query, map_lambda=None, mapper=None, page_size=None):\n\t        def get_page(**kwargs):\n\t            queried = query.paginate(set_query, **kwargs)\n\t            if map_lambda is not None:\n\t                queried = query.map_(map_lambda, queried)\n", "            return Page.from_raw(client.query(queried))\n\t        page = get_page(size=page_size)\n\t        for val in page.data:\n\t            yield val if mapper is None else mapper(val)\n\t        next_cursor = \"after\" if page.after is not None else \"before\"\n\t        while getattr(page, next_cursor) is not None:\n\t            page = get_page(\n\t                **{\"size\": page_size, next_cursor: getattr(page, next_cursor)}\n\t            )\n\t            for val in page.data:\n", "                yield val if mapper is None else mapper(val)\n"]}
{"filename": "aiofauna/faunadb/objects.py", "chunked_list": ["\"\"\"\n\tTypes used in queries and responses.\n\tSee the `docs <https://app.fauna.com/documentation/reference/queryapi#simple-type>`__.\n\t\"\"\"\n\tfrom datetime import datetime\n\tfrom iso8601 import parse_date\n\tfrom .query import Expr\n\tclass Ref(Expr):\n\t    \"\"\"\n\t    ```python\n", "    Ref(id, cls=None, db=None)\n\t    ```\n\t    A reference to a document in a collection or index.\n\t    :param id: The document's ID.\n\t    :param cls: The collection or index class.\n\t    :param db: The database.\n\t    `Ref`\n\t    Is a special type in FaunaDB. It is used to represent a document in a collection or index.\n\t    It is serialized to JSON as an object with the `@ref` key. Passing the `id` to the response.\n\t    \"\"\"\n", "    def __init__(self, id, cls=None, db=None):\n\t        if id is None:\n\t            raise ValueError(\"The Ref must have an id.\")\n\t        value = {\"id\": id}\n\t        if cls != None:\n\t            value[\"collection\"] = cls\n\t        if db != None:\n\t            value[\"database\"] = db\n\t        super(Ref, self).__init__(value)\n\t    def collection(self):\n", "        \"\"\"\n\t        Gets the collection part out of the Ref.\n\t        \"\"\"\n\t        return self.value.get(\"collection\")\n\t    def database(self):\n\t        \"\"\"\n\t        Gets the database part out of the Ref.\n\t        \"\"\"\n\t        return self.value.get(\"database\")\n\t    def id(self):\n", "        \"\"\"\n\t        Gets the id part out of the Ref.\n\t        \"\"\"\n\t        return self.value[\"id\"]\n\t    def to_fauna_json(self):\n\t        return {\"@ref\": self.value}\n\t    def __str__(self):\n\t        col = (\n\t            f\", collection={self.value['collection']}\"\n\t            if \"collection\" in self.value\n", "            else \"\"\n\t        )\n\t        db = (\n\t            f\", database={self.value.get('database')}\"\n\t            if \"database\" in self.value\n\t            else \"\"\n\t        )\n\t        return \"Ref(id=%s%s%s)\" % (self.value[\"id\"], col, db)\n\t    def __repr__(self):\n\t        col = (\n", "            f\", collection={self.value['collection']}\"\n\t            if \"collection\" in self.value\n\t            else \"\"\n\t        )\n\t        db = (\n\t            f\", database={self.value.get('database')}\"\n\t            if \"database\" in self.value\n\t            else \"\"\n\t        )\n\t        return \"Ref(id=%s%s%s)\" % (self.value[\"id\"], col, db)\n", "    def __eq__(self, other):\n\t        return isinstance(other, Ref) and self.value == other.value\n\t    def __ne__(self, other):\n\t        # pylint: disable=unneeded-not\n\t        return not self == other\n\tclass Native(object):\n\t    COLLECTIONS = Ref(\"collections\")\n\t    INDEXES = Ref(\"indexes\")\n\t    DATABASES = Ref(\"databases\")\n\t    FUNCTIONS = Ref(\"functions\")\n", "    KEYS = Ref(\"keys\")\n\t    TOKENS = Ref(\"tokens\")\n\t    CREDENTIALS = Ref(\"credentials\")\n\t    ROLES = Ref(\"roles\")\n\t    ACCESS_PROVIDERS = Ref(\"access_providers\")\n\t    def __init__(self):\n\t        raise TypeError\n\t    @classmethod\n\t    def from_name(cls, name):\n\t        return getattr(cls, name.upper(), Ref(name))\n", "class SetRef(Expr):\n\t    \"\"\"\n\t    FaunaDB Set.\n\t    This represents a set returned as part of a response.\n\t    For query sets see :doc:`query`.\n\t    \"\"\"\n\t    def __init__(self, set_ref):\n\t        if isinstance(set_ref, Expr):\n\t            value = set_ref.value\n\t        else:\n", "            value = set_ref\n\t        super(SetRef, self).__init__(value)\n\t    def to_fauna_json(self):\n\t        return {\"@set\": self.value}\n\t    def __repr__(self):\n\t        return f\"SetRef({repr(self.value)})\"\n\t    def __eq__(self, other):\n\t        return isinstance(other, SetRef) and self.value == other.value\n\t    def __ne__(self, other):\n\t        # pylint: disable=unneeded-not\n", "        return not self == other\n\tclass FaunaTime(Expr):\n\t    \"\"\"\n\t    FaunaDB time. See the `docs <https://app.fauna.com/documentation/reference/queryapi#special-type>`__.\n\t    For dates, regular :class:`datetime.date` objects are used.\n\t    \"\"\"\n\t    def __init__(self, value):\n\t        \"\"\"\n\t        :param value:\n\t          If a :class:`datetime.datetime` is passed, it is converted to a string.\n", "          Must include an offset.\n\t        \"\"\"\n\t        if isinstance(value, datetime):\n\t            if value.utcoffset() is None:\n\t                raise ValueError(\"FaunaTime requires offset-aware datetimes\")\n\t            value = value.isoformat()\n\t        # Convert +00:00 offset to zulu for comparison equality\n\t        # We don't check for +0000 or +00 as they are not valid in FaunaDB\n\t        super(FaunaTime, self).__init__(value.replace(\"+00:00\", \"Z\"))\n\t    def to_datetime(self):\n", "        \"\"\"\n\t        Convert to an offset-aware datetime object.\n\t        This is lossy as datetimes have microsecond rather than nanosecond precision.\n\t        \"\"\"\n\t        return parse_date(self.value)\n\t    def to_fauna_json(self):\n\t        return {\"@ts\": self.value}\n\t    def __repr__(self):\n\t        return \"FaunaTime(%s)\" % repr(self.value)\n\t    def __eq__(self, other):\n", "        return isinstance(other, FaunaTime) and self.value == other.value\n\t    def __ne__(self, other):\n\t        # pylint: disable=unneeded-not\n\t        return not self == other\n\tclass Query(Expr):\n\t    \"\"\"\n\t    Represents a `@query` type in FaunaDB.\n\t    See the `docs <https://app.fauna.com/documentation/reference/queryapi#special-type>`__.\n\t    \"\"\"\n\t    def to_fauna_json(self):\n", "        return {\"@query\": self.value}\n\t    def __repr__(self):\n\t        return \"Query(%s)\" % repr(self.value)\n\t    def __eq__(self, other):\n\t        return isinstance(other, Query) and self.value == other.value\n\t    def __ne__(self, other):\n\t        # pylint: disable=unneeded-not\n\t        return not self == other\n"]}
{"filename": "aiofauna/faunadb/errors.py", "chunked_list": ["\"\"\"Error types that methods in the FaunaDB client throw.\"\"\"\n\tclass codes:\n\t    \"\"\"HTTP status codes.\"\"\"\n\t    bad_request = 400\n\t    unauthorized = 401\n\t    forbidden = 403\n\t    not_found = 404\n\t    internal_server_error = 500\n\t    unavailable = 503\n\tdef _get_or_raise(request_result, dct, key):\n", "    if isinstance(dct, dict) and key in dct:\n\t        return dct[key]\n\t    else:\n\t        raise UnexpectedError(\n\t            \"Response JSON does not contain expected key %s\" % key, request_result\n\t        )\n\t# region FaunaError\n\tclass FaunaError(Exception):\n\t    \"\"\"\n\t    Error returned by the FaunaDB server.\n", "    For documentation of error types, see the `docs <https://fauna.com/documentation#errors>`__.\n\t    \"\"\"\n\t    @staticmethod\n\t    def raise_for_status_code(request_result):\n\t        code = request_result.status_code\n\t        # pylint: disable=no-member, too-many-return-statements\n\t        if 200 <= code <= 299:\n\t            pass\n\t        elif code == codes.bad_request:\n\t            raise BadRequest(request_result)\n", "        elif code == codes.unauthorized:\n\t            raise Unauthorized(request_result)\n\t        elif code == codes.forbidden:\n\t            raise PermissionDenied(request_result)\n\t        elif code == codes.not_found:\n\t            raise NotFound(request_result)\n\t        elif code == codes.internal_server_error:\n\t            raise InternalError(request_result)\n\t        elif code == codes.unavailable:\n\t            raise UnavailableError(request_result)\n", "        else:\n\t            raise UnexpectedError(\"Unexpected status code.\", request_result)\n\t    def __init__(self, description, request_result):\n\t        super(FaunaError, self).__init__(description)\n\t        self.request_result = request_result\n\t        \"\"\":any:`RequestResult` for the request that caused this error.\"\"\"\n\tclass UnexpectedError(FaunaError):\n\t    \"\"\"Error for when the server returns an unexpected kind of response.\"\"\"\n\t    pass\n\tclass HttpError(FaunaError):\n", "    def __init__(self, request_result):\n\t        self.errors = HttpError._get_errors(request_result)\n\t        \"\"\"List of all :py:class:`ErrorData` objects sent by the server.\"\"\"\n\t        super(HttpError, self).__init__(self._get_description(), request_result)\n\t    @staticmethod\n\t    def _get_errors(request_result):\n\t        response = request_result.response_content\n\t        errors = _get_or_raise(request_result, response, \"errors\")\n\t        return [ErrorData.from_dict(error, request_result) for error in errors]\n\t    def __str__(self):\n", "        return repr(self.errors[0])\n\t    def _get_description(self):\n\t        return self.errors[0].description if self.errors else \"(empty `errors`)\"\n\tclass BadRequest(HttpError):\n\t    \"\"\"HTTP 400 error.\"\"\"\n\t    pass\n\tclass Unauthorized(HttpError):\n\t    def __init__(self, request_result):\n\t        super(Unauthorized, self).__init__(request_result)\n\t        self.errors[\n", "            0\n\t        ].description = \"Unauthorized. Check that endpoint, schema, port and secret are correct during client’s instantiation\"\n\tclass PermissionDenied(HttpError):\n\t    \"\"\"HTTP 403 error.\"\"\"\n\t    pass\n\tclass NotFound(HttpError):\n\t    \"\"\"HTTP 404 error.\"\"\"\n\t    pass\n\tclass InternalError(HttpError):\n\t    \"\"\"HTTP 500 error.\"\"\"\n", "    pass\n\tclass UnavailableError(HttpError):\n\t    \"\"\"HTTP 503 error.\"\"\"\n\t    pass\n\t# endregion\n\tclass ErrorData(object):\n\t    \"\"\"\n\t    Data for one error returned by the server.\n\t    \"\"\"\n\t    @staticmethod\n", "    def from_dict(dct, request_result):\n\t        return ErrorData(\n\t            _get_or_raise(request_result, dct, \"code\"),\n\t            _get_or_raise(request_result, dct, \"description\"),\n\t            dct.get(\"position\"),\n\t            ErrorData.get_failures(dct, request_result),\n\t            ErrorData.get_cause(dct, request_result),\n\t        )\n\t    @staticmethod\n\t    def get_failures(dct, request_result):\n", "        if \"failures\" in dct:\n\t            return [\n\t                Failure.from_dict(failure, request_result)\n\t                for failure in dct[\"failures\"]\n\t            ]\n\t        return None\n\t    @staticmethod\n\t    def get_cause(dct, request_result):\n\t        if \"cause\" in dct:\n\t            return [\n", "                ErrorData.from_dict(cause, request_result) for cause in dct[\"cause\"]\n\t            ]\n\t        return None\n\t    def __init__(self, code, description, position, failures, cause=None):\n\t        self.code = code\n\t        \"\"\"Error code. See all error codes `here <https://fauna.com/documentation#errors>`__.\"\"\"\n\t        self.description = description\n\t        \"\"\"Error description.\"\"\"\n\t        self.position = position\n\t        \"\"\"Position of the error in a query. May be None.\"\"\"\n", "        self.failures = failures\n\t        \"\"\"Cause of the error. May be None.\"\"\"\n\t        self.cause = cause\n\t        \"\"\"\n\t    List of all :py:class:`Failure` objects returned by the server.\n\t    None unless code == \"validation failed\".\n\t    \"\"\"\n\t    def __repr__(self):\n\t        return (\n\t            \"ErrorData(code=%s, description=%s, position=%s, failures=%s, cause=%s)\"\n", "            % (\n\t                repr(self.code),\n\t                repr(self.description),\n\t                repr(self.position),\n\t                repr(self.failures),\n\t                repr(self.cause),\n\t            )\n\t        )\n\t    def __eq__(self, other):\n\t        return (\n", "            self.__class__ == other.__class__\n\t            and self.description == other.description\n\t            and self.position == other.position\n\t            and self.failures == other.failures\n\t            and self.cause == other.cause\n\t        )\n\t    def __ne__(self, other):\n\t        # pylint: disable=unneeded-not\n\t        return not self == other\n\tclass Failure(object):\n", "    \"\"\"\n\t    Part of the ``failures`` of an :py:class:`ErrorData`.\n\t    See the ``Invalid Data`` section of the `docs <https://fauna.com/documentation#errors>`__.\n\t    \"\"\"\n\t    @staticmethod\n\t    def from_dict(dct, request_result):\n\t        return Failure(\n\t            _get_or_raise(request_result, dct, \"code\"),\n\t            _get_or_raise(request_result, dct, \"description\"),\n\t            _get_or_raise(request_result, dct, \"field\"),\n", "        )\n\t    def __init__(self, code, description, field):\n\t        self.code = code\n\t        \"\"\"Failure code.\"\"\"\n\t        self.description = description\n\t        \"\"\"Failure description.\"\"\"\n\t        self.field = field\n\t        \"\"\"Field of the failure in the instance.\"\"\"\n\t    def __repr__(self):\n\t        return \"Failure(code=%s, description=%s, field=%s)\" % (\n", "            repr(self.code),\n\t            repr(self.description),\n\t            repr(self.field),\n\t        )\n\t    def __eq__(self, other):\n\t        return (\n\t            self.code == other.code\n\t            and self.description == other.description\n\t            and self.field == other.field\n\t        )\n", "    def __ne__(self, other):\n\t        # pylint: disable=unneeded-not\n\t        return not self == other\n\tclass FaunaException(Exception):\n\t    STATUS_MAP = {\n\t        100: \"primary\",\n\t        200: \"success\",\n\t        300: \"info\",\n\t        400: \"warning\",\n\t        500: \"error\",\n", "    }\n\t    def __init__(self, status: int, message: str, request_result):\n\t        super(FaunaException, self).__init__(message, request_result)\n\t        self.status = status\n\t        self.message = message\n\t    def json(self):\n\t        return {\"status\": self.raise_for_status(), \"message\": self.message}\n\t    def raise_for_status(self) -> str:\n\t        for key, value in self.STATUS_MAP.items():\n\t            if self.status < key + 100:\n", "                return value\n\t        return \"error\"\n"]}
{"filename": "aiofauna/faunadb/query.py", "chunked_list": ["from types import FunctionType\n\tdef abort(msg):\n\t    return _fn({\"abort\": msg})\n\tdef ref(collection_ref, id=None):\n\t    if id is None:\n\t        return _fn({\"@ref\": collection_ref})\n\t    return _fn({\"ref\": collection_ref, \"id\": id})\n\tdef collections(scope=None):\n\t    return _fn({\"collections\": scope})\n\tdef documents(collections):\n", "    return _fn({\"documents\": collections})\n\tdef databases(scope=None):\n\t    return _fn({\"databases\": scope})\n\tdef indexes(scope=None):\n\t    return _fn({\"indexes\": scope})\n\tdef functions(scope=None):\n\t    return _fn({\"functions\": scope})\n\tdef roles(scope=None):\n\t    return _fn({\"roles\": scope})\n\tdef access_providers(scope=None):\n", "    return _fn({\"access_providers\": scope})\n\tdef keys(scope=None):\n\t    return _fn({\"keys\": scope})\n\tdef tokens(scope=None):\n\t    return _fn({\"tokens\": scope})\n\tdef credentials(scope=None):\n\t    return _fn({\"credentials\": scope})\n\tdef at(timestamp, expr):\n\t    return _fn({\"at\": timestamp, \"expr\": expr})\n\tclass LetBindings:\n", "    def __init__(self, bindings):\n\t        self._bindings = bindings\n\t    def in_(self, inExpr):\n\t        return _fn({\"let\": self._bindings, \"in\": inExpr})\n\tdef let(*args, **kwargs):\n\t    if kwargs:\n\t        return LetBindings([_fn({k: v}) for (k, v) in kwargs.items()])\n\t    else:\n\t        bindings = [_fn({k: v}) for (k, v) in args[0].items()]\n\t        inExpr = args[1]\n", "        return _fn({\"let\": bindings, \"in\": inExpr})\n\tdef var(var_name):\n\t    return _fn({\"var\": var_name})\n\tdef if_(condition, then, else_):\n\t    return _fn({\"if\": condition, \"then\": then, \"else\": else_})\n\tdef do(*expressions):\n\t    return _fn({\"do\": expressions})\n\tdef lambda_query(func):\n\t    vars = func.__code__.co_varnames\n\t    n_args = len(vars)\n", "    if n_args == 0:\n\t        raise ValueError(\"Function must take at least 1 argument.\")\n\t    elif n_args == 1:\n\t        v = vars[0]\n\t        return lambda_(v, func(var(v)))\n\t    else:\n\t        return lambda_(vars, func(*[var(v) for v in vars]))\n\tdef lambda_(var_name_or_pattern, expr):\n\t    return _fn({\"lambda\": var_name_or_pattern, \"expr\": expr})\n\tdef call(ref_, *arguments):\n", "    return _fn({\"call\": ref_, \"arguments\": _varargs(arguments)})\n\tdef query(_lambda):\n\t    if isinstance(_lambda, FunctionType):\n\t        _lambda = lambda_query(_lambda)\n\t    return _fn({\"query\": _lambda})\n\tdef map_(expr, collection):\n\t    return _fn({\"map\": expr, \"collection\": collection})\n\tdef foreach(expr, collection):\n\t    return _fn({\"foreach\": expr, \"collection\": collection})\n\tdef filter_(expr, collection):\n", "    return _fn({\"filter\": expr, \"collection\": collection})\n\tdef take(number, collection):\n\t    return _fn({\"take\": number, \"collection\": collection})\n\tdef drop(number, collection):\n\t    return _fn({\"drop\": number, \"collection\": collection})\n\tdef prepend(elements, collection):\n\t    return _fn({\"prepend\": elements, \"collection\": collection})\n\tdef append(elements, collection):\n\t    return _fn({\"append\": elements, \"collection\": collection})\n\tdef is_empty(collection):\n", "    return _fn({\"is_empty\": collection})\n\tdef is_nonempty(collection):\n\t    return _fn({\"is_nonempty\": collection})\n\tdef is_number(expr):\n\t    return _fn({\"is_number\": expr})\n\tdef is_double(expr):\n\t    return _fn({\"is_double\": expr})\n\tdef is_integer(expr):\n\t    return _fn({\"is_integer\": expr})\n\tdef is_boolean(expr):\n", "    return _fn({\"is_boolean\": expr})\n\tdef is_null(expr):\n\t    return _fn({\"is_null\": expr})\n\tdef is_bytes(expr):\n\t    return _fn({\"is_bytes\": expr})\n\tdef is_timestamp(expr):\n\t    return _fn({\"is_timestamp\": expr})\n\tdef is_date(expr):\n\t    return _fn({\"is_date\": expr})\n\tdef is_string(expr):\n", "    return _fn({\"is_string\": expr})\n\tdef is_array(expr):\n\t    return _fn({\"is_array\": expr})\n\tdef is_object(expr):\n\t    return _fn({\"is_object\": expr})\n\tdef is_ref(expr):\n\t    return _fn({\"is_ref\": expr})\n\tdef is_set(expr):\n\t    return _fn({\"is_set\": expr})\n\tdef is_doc(expr):\n", "    return _fn({\"is_doc\": expr})\n\tdef is_lambda(expr):\n\t    return _fn({\"is_lambda\": expr})\n\tdef is_collection(expr):\n\t    return _fn({\"is_collection\": expr})\n\tdef is_database(expr):\n\t    return _fn({\"is_database\": expr})\n\tdef is_index(expr):\n\t    return _fn({\"is_index\": expr})\n\tdef is_function(expr):\n", "    return _fn({\"is_function\": expr})\n\tdef is_key(expr):\n\t    return _fn({\"is_key\": expr})\n\tdef is_token(expr):\n\t    return _fn({\"is_token\": expr})\n\tdef is_credentials(expr):\n\t    return _fn({\"is_credentials\": expr})\n\tdef is_role(expr):\n\t    return _fn({\"is_role\": expr})\n\tdef get(ref_, ts=None):\n", "    return _params({\"get\": ref_}, {\"ts\": ts})\n\tdef key_from_secret(secret):\n\t    return _fn({\"key_from_secret\": secret})\n\tdef paginate(\n\t    set, size=None, ts=None, after=None, before=None, events=None, sources=None\n\t):\n\t    opts = {\n\t        \"size\": size,\n\t        \"ts\": ts,\n\t        \"after\": after,\n", "        \"before\": before,\n\t        \"events\": events,\n\t        \"sources\": sources,\n\t    }\n\t    return _params({\"paginate\": set}, opts)\n\tdef exists(ref_, ts=None):\n\t    return _params({\"exists\": ref_}, {\"ts\": ts})\n\tdef create(collection_ref, params):\n\t    return _fn({\"create\": collection_ref, \"params\": params})\n\tdef update(ref_, params):\n", "    return _fn({\"update\": ref_, \"params\": params})\n\tdef replace(ref_, params):\n\t    return _fn({\"replace\": ref_, \"params\": params})\n\tdef delete(ref_):\n\t    return _fn({\"delete\": ref_})\n\tdef insert(ref_, ts, action, params):\n\t    return _fn({\"insert\": ref_, \"ts\": ts, \"action\": action, \"params\": params})\n\tdef remove(ref_, ts, action):\n\t    return _fn({\"remove\": ref_, \"ts\": ts, \"action\": action})\n\tdef create_collection(collection_params):\n", "    return _fn({\"create_collection\": collection_params})\n\tdef create_database(db_params):\n\t    return _fn({\"create_database\": db_params})\n\tdef create_index(index_params):\n\t    return _fn({\"create_index\": index_params})\n\tdef create_function(func_params):\n\t    return _fn({\"create_function\": func_params})\n\tdef create_role(func_params):\n\t    return _fn({\"create_role\": func_params})\n\tdef create_access_provider(provider_params):\n", "    return _fn({\"create_access_provider\": provider_params})\n\tdef move_database(from_, to):\n\t    return _fn({\"move_database\": from_, \"to\": to})\n\tdef create_key(key_params):\n\t    return _fn({\"create_key\": key_params})\n\tdef singleton(ref_):\n\t    return _fn({\"singleton\": ref_})\n\tdef events(ref_set):\n\t    return _fn({\"events\": ref_set})\n\tdef match(index, *terms):\n", "    m = {\"match\": index}\n\t    if len(terms) >= 1:\n\t        m[\"terms\"] = _varargs(terms)\n\t    return _fn(m)\n\tdef reverse(set_array_or_page):\n\t    return _fn({\"reverse\": set_array_or_page})\n\tdef merge(merge, with_, lambda_=None):\n\t    return _params({\"merge\": merge, \"with\": with_}, {\"lambda\": lambda_})\n\tdef union(*sets):\n\t    return _fn({\"union\": _varargs(sets)})\n", "def reduce(lambda_, initial, collection):\n\t    return _fn({\"reduce\": lambda_, \"initial\": initial, \"collection\": collection})\n\tdef intersection(*sets):\n\t    return _fn({\"intersection\": _varargs(sets)})\n\tdef difference(*sets):\n\t    return _fn({\"difference\": _varargs(sets)})\n\tdef distinct(set):\n\t    return _fn({\"distinct\": set})\n\tdef join(source, target):\n\t    return _fn({\"join\": source, \"with\": target})\n", "def range(set, from_, to):\n\t    return _fn({\"range\": set, \"from\": from_, \"to\": to})\n\tdef login(ref_, params):\n\t    return _fn({\"login\": ref_, \"params\": params})\n\tdef logout(delete_tokens):\n\t    return _fn({\"logout\": delete_tokens})\n\tdef identify(ref_, password):\n\t    return _fn({\"identify\": ref_, \"password\": password})\n\tdef current_identity():\n\t    return _fn({\"current_identity\": None})\n", "def has_current_identity():\n\t    return _fn({\"has_current_identity\": None})\n\tdef current_token():\n\t    return _fn({\"current_token\": None})\n\tdef has_current_token():\n\t    return _fn({\"has_current_token\": None})\n\tdef has_identity():\n\t    return _fn({\"has_identity\": None})\n\tdef format(string, *values):\n\t    return _fn({\"format\": string, \"values\": _varargs(values)})\n", "def concat(strings, separator=None):\n\t    return _params({\"concat\": strings}, {\"separator\": separator})\n\tdef casefold(string, normalizer=None):\n\t    return _params({\"casefold\": string}, {\"normalizer\": normalizer})\n\tdef starts_with(value, search):\n\t    return _fn({\"startswith\": value, \"search\": search})\n\tdef ends_with(value, search):\n\t    return _fn({\"endswith\": value, \"search\": search})\n\tdef contains_str(value, search):\n\t    return _fn({\"containsstr\": value, \"search\": search})\n", "def contains_str_regex(value, pattern):\n\t    return _fn({\"containsstrregex\": value, \"pattern\": pattern})\n\tdef regex_escape(value):\n\t    return _fn({\"regexescape\": value})\n\tdef ngram(terms, min=None, max=None):\n\t    return _params({\"ngram\": terms}, {\"min\": min, \"max\": max})\n\tdef find_str(value, find, start=None):\n\t    return _params({\"findstr\": value, \"find\": find}, {\"start\": start})\n\tdef find_str_regex(value, pattern, start=None, numResults=None):\n\t    return _params(\n", "        {\"findstrregex\": value, \"pattern\": pattern},\n\t        {\"start\": start, \"num_results\": numResults},\n\t    )\n\tdef replace_str(value, find, replace):\n\t    return _fn({\"replacestr\": value, \"find\": find, \"replace\": replace})\n\tdef replace_str_regex(value, pattern, replace, first=None):\n\t    return _params(\n\t        {\"replacestrregex\": value, \"pattern\": pattern, \"replace\": replace},\n\t        {\"first\": first},\n\t    )\n", "def length(value):\n\t    return _fn({\"length\": value})\n\tdef lowercase(value):\n\t    return _fn({\"lowercase\": value})\n\tdef uppercase(value):\n\t    return _fn({\"uppercase\": value})\n\tdef titlecase(value):\n\t    return _fn({\"titlecase\": value})\n\tdef trim(value):\n\t    return _fn({\"trim\": value})\n", "def ltrim(value):\n\t    return _fn({\"ltrim\": value})\n\tdef rtrim(value):\n\t    return _fn({\"rtrim\": value})\n\tdef space(count):\n\t    return _fn({\"space\": count})\n\tdef substring(value, start, length=None):\n\t    return _params({\"substring\": value, \"start\": start}, {\"length\": length})\n\tdef repeat(value, number=None):\n\t    return _params({\"repeat\": value}, {\"number\": number})\n", "def time(string):\n\t    return _fn({\"time\": string})\n\tdef epoch(number, unit):\n\t    return _fn({\"epoch\": number, \"unit\": unit})\n\tdef now():\n\t    return _fn({\"now\": None})\n\tdef date(string):\n\t    return _fn({\"date\": string})\n\tdef time_add(base, offset, unit):\n\t    return _fn({\"time_add\": base, \"offset\": offset, \"unit\": unit})\n", "def time_subtract(base, offset, unit):\n\t    return _fn({\"time_subtract\": base, \"offset\": offset, \"unit\": unit})\n\tdef time_diff(start, finish, unit):\n\t    return _fn({\"time_diff\": start, \"other\": finish, \"unit\": unit})\n\tdef new_id():\n\t    return _fn({\"new_id\": None})\n\tdef database(db_name, scope=None):\n\t    return _params({\"database\": db_name}, {\"scope\": scope})\n\tdef index(index_name, scope=None):\n\t    return _params({\"index\": index_name}, {\"scope\": scope})\n", "def collection(collection_name, scope=None):\n\t    return _params({\"collection\": collection_name}, {\"scope\": scope})\n\tdef function(fn_name, scope=None):\n\t    return _params({\"function\": fn_name}, {\"scope\": scope})\n\tdef role(role_name, scope=None):\n\t    return _params({\"role\": role_name}, {\"scope\": scope})\n\tdef access_provider(access_provider_name, scope=None):\n\t    return _params({\"access_provider\": access_provider_name}, {\"scope\": scope})\n\tdef equals(*values):\n\t    return _fn({\"equals\": _varargs(values)})\n", "def contains_path(path, in_):\n\t    return _fn({\"contains_path\": path, \"in\": in_})\n\tdef contains_field(field, in_):\n\t    return _fn({\"contains_field\": field, \"in\": in_})\n\tdef contains_value(value, in_):\n\t    return _fn({\"contains_value\": value, \"in\": in_})\n\t_NO_DEFAULT = object()\n\tdef select(path, from_, default=_NO_DEFAULT):\n\t    _dict = {\"select\": path, \"from\": from_}\n\t    if default is not _NO_DEFAULT:\n", "        _dict[\"default\"] = default\n\t    return _fn(_dict)\n\tdef select_all(path, from_):\n\t    return _fn({\"select_all\": path, \"from\": from_})\n\tdef add(*numbers):\n\t    return _fn({\"add\": _varargs(numbers)})\n\tdef multiply(*numbers):\n\t    return _fn({\"multiply\": _varargs(numbers)})\n\tdef subtract(*numbers):\n\t    return _fn({\"subtract\": _varargs(numbers)})\n", "def divide(*numbers):\n\t    return _fn({\"divide\": _varargs(numbers)})\n\tdef pow(base, exp):\n\t    return _fn({\"pow\": base, \"exp\": exp})\n\tdef max(*numbers):\n\t    return _fn({\"max\": _varargs(numbers)})\n\tdef min(*numbers):\n\t    return _fn({\"min\": _varargs(numbers)})\n\tdef abs(num):\n\t    return _fn({\"abs\": num})\n", "def trunc(num, precision=None):\n\t    return _params({\"trunc\": num}, {\"precision\": precision})\n\tdef bitor(*numbers):\n\t    return _fn({\"bitor\": _varargs(numbers)})\n\tdef cosh(num):\n\t    return _fn({\"cosh\": num})\n\tdef hypot(num, b):\n\t    return _fn({\"hypot\": num, \"b\": b})\n\tdef atan(num):\n\t    return _fn({\"atan\": num})\n", "def log(num):\n\t    return _fn({\"log\": num})\n\tdef bitnot(*num):\n\t    return _fn({\"bitnot\": _varargs(num)})\n\tdef bitxor(*num):\n\t    return _fn({\"bitxor\": _varargs(num)})\n\tdef bitand(*num):\n\t    return _fn({\"bitand\": _varargs(num)})\n\tdef ceil(num):\n\t    return _fn({\"ceil\": num})\n", "def degrees(num):\n\t    return _fn({\"degrees\": num})\n\tdef cos(num):\n\t    return _fn({\"cos\": num})\n\tdef acos(num):\n\t    return _fn({\"acos\": num})\n\tdef sqrt(num):\n\t    return _fn({\"sqrt\": num})\n\tdef tan(num):\n\t    return _fn({\"tan\": num})\n", "def tanh(num):\n\t    return _fn({\"tanh\": num})\n\tdef sin(num):\n\t    return _fn({\"sin\": num})\n\tdef asin(num):\n\t    return _fn({\"asin\": num})\n\tdef round(num, precision=None):\n\t    return _params({\"round\": num}, {\"precision\": precision})\n\tdef radians(num):\n\t    return _fn({\"radians\": num})\n", "def floor(num):\n\t    return _fn({\"floor\": num})\n\tdef sign(num):\n\t    return _fn({\"sign\": num})\n\tdef exp(num):\n\t    return _fn({\"exp\": num})\n\tdef ln(num):\n\t    return _fn({\"ln\": num})\n\tdef any(collection):\n\t    return _fn({\"any\": collection})\n", "def all(collection):\n\t    return _fn({\"all\": collection})\n\tdef modulo(*numbers):\n\t    return _fn({\"modulo\": _varargs(numbers)})\n\tdef count(collection):\n\t    return _fn({\"count\": collection})\n\tdef sum(collection):\n\t    return _fn({\"sum\": collection})\n\tdef mean(collection):\n\t    return _fn({\"mean\": collection})\n", "def lt(*values):\n\t    return _fn({\"lt\": _varargs(values)})\n\tdef lte(*values):\n\t    return _fn({\"lte\": _varargs(values)})\n\tdef gt(*values):\n\t    return _fn({\"gt\": _varargs(values)})\n\tdef gte(*values):\n\t    return _fn({\"gte\": _varargs(values)})\n\tdef and_(*booleans):\n\t    return _fn({\"and\": _varargs(booleans)})\n", "def or_(*booleans):\n\t    return _fn({\"or\": _varargs(booleans)})\n\tdef not_(boolean):\n\t    return _fn({\"not\": boolean})\n\tdef to_string(expr):\n\t    return _fn({\"to_string\": expr})\n\tdef to_array(expr):\n\t    return _fn({\"to_array\": expr})\n\tdef to_object(expr):\n\t    return _fn({\"to_object\": expr})\n", "def to_double(expr):\n\t    return _fn({\"to_double\": expr})\n\tdef to_integer(expr):\n\t    return _fn({\"to_integer\": expr})\n\tdef to_number(expr):\n\t    return _fn({\"to_number\": expr})\n\tdef to_time(expr):\n\t    return _fn({\"to_time\": expr})\n\tdef to_seconds(expr):\n\t    return _fn({\"to_seconds\": expr})\n", "def to_millis(expr):\n\t    return _fn({\"to_millis\": expr})\n\tdef to_micros(expr):\n\t    return _fn({\"to_micros\": expr})\n\tdef day_of_month(expr):\n\t    return _fn({\"day_of_month\": expr})\n\tdef day_of_week(expr):\n\t    return _fn({\"day_of_week\": expr})\n\tdef day_of_year(expr):\n\t    return _fn({\"day_of_year\": expr})\n", "def year(expr):\n\t    return _fn({\"year\": expr})\n\tdef month(expr):\n\t    return _fn({\"month\": expr})\n\tdef hour(expr):\n\t    return _fn({\"hour\": expr})\n\tdef minute(expr):\n\t    return _fn({\"minute\": expr})\n\tdef second(expr):\n\t    return _fn({\"second\": expr})\n", "def to_date(expr):\n\t    return _fn({\"to_date\": expr})\n\tclass Expr:\n\t    def __init__(self, value):\n\t        self.value = value\n\t    def to_fauna_json(self):\n\t        return self.value\n\t    def __repr__(self):\n\t        return \"Expr(%s)\" % repr(self.value)\n\t    def __eq__(self, other):\n", "        return isinstance(other, Expr) and self.value == other.value\n\tdef _wrap(value):\n\t    if isinstance(value, Expr):\n\t        return value\n\t    elif isinstance(value, FunctionType):\n\t        return lambda_query(value)\n\t    elif isinstance(value, dict):\n\t        return Expr({\"object\": _wrap_values(value)})\n\t    elif isinstance(value, (list, tuple)):\n\t        return Expr([_wrap(sub_value) for sub_value in value])\n", "    return value\n\tdef _wrap_values(dct):\n\t    return {key: _wrap(val) for (key, val) in dct.items()}\n\tdef _fn(dct):\n\t    return Expr(_wrap_values(dct))\n\tdef _params(main_params, optional_params):\n\t    for key, val in optional_params.items():\n\t        if val is not None:\n\t            main_params[key] = val\n\t    return _fn(main_params)\n", "def _varargs(values):\n\t    return values[0] if len(values) == 1 else values\n"]}
{"filename": "aiofauna/faunadb/__init__.py", "chunked_list": []}
{"filename": "aiofauna/ssr/ssr.py", "chunked_list": ["import functools\n\tfrom typing import Optional\n\tfrom aiohttp.web import HTTPException, Request, Response, StreamResponse\n\tfrom jinja2 import Environment, FileSystemLoader, select_autoescape\n\tfrom jinja2.exceptions import (\n\t    TemplateAssertionError,\n\t    TemplateError,\n\t    TemplateNotFound,\n\t    TemplateSyntaxError,\n\t    UndefinedError,\n", ")\n\tfrom markdown_it import MarkdownIt\n\tfrom markdown_it.renderer import RendererHTML\n\tfrom markdown_it.rules_block import StateBlock\n\tfrom pygments import highlight\n\tfrom pygments.formatters import HtmlFormatter\n\tfrom pygments.lexers import MarkdownLexer, get_lexer_by_name\n\tfrom ..utils import setup_logging\n\tEXCEPTIONS = (\n\t    TemplateAssertionError,\n", "    TemplateError,\n\t    TemplateNotFound,\n\t    TemplateSyntaxError,\n\t    UndefinedError,\n\t    Exception,\n\t)\n\tlogger = setup_logging(__name__)\n\tdef handle_template(func):\n\t    @functools.wraps(func)\n\t    async def wrapper(*args, **kwargs):\n", "        try:\n\t            return await func(*args, **kwargs)\n\t        except EXCEPTIONS as e:\n\t            logger.error(e)\n\t            raise HTTPException(reason=str(e)) from e\n\t    return wrapper\n\tclass HighlightRenderer(RendererHTML):\n\t    def code_block(self, tokens, idx, options, env):\n\t        token = tokens[idx]\n\t        lexer = get_lexer_by_name(token.info.strip() if token.info else \"text\")\n", "        formatter = HtmlFormatter()\n\t        return highlight(token.content, lexer, formatter)\n\tdef highlight_code(code, name, attrs):\n\t    \"\"\"Highlight a block of code\"\"\"\n\t    lexer = get_lexer_by_name(name)\n\t    formatter = HtmlFormatter()\n\t    return highlight(code, lexer, formatter)\n\tclass ServerSideRenderer(StreamResponse):\n\t    def __init__(\n\t        self,\n", "        headers={\"Content-Type\": \"text/html\"},\n\t        *args,\n\t        **kwargs,\n\t    ) -> None:\n\t        super().__init__(*args, headers=headers, **kwargs)\n\t        self.env = Environment(\n\t            loader=FileSystemLoader(\"templates\"),\n\t            autoescape=select_autoescape([\"html\", \"xml\", \"jinja2\", \"md\"]),\n\t            enable_async=True,\n\t        )\n", "        self.md = MarkdownIt(\n\t            \"js-default\",\n\t            options_update={\n\t                \"html\": True,\n\t                \"linkify\": True,\n\t                \"typographer\": True,\n\t                \"highlight\": highlight_code,\n\t            },\n\t        )\n\t    @handle_template\n", "    async def render_markdown(self, template_name: str, request: Request, **context):\n\t        await self.prepare(request)\n\t        template = self.env.get_template(template_name)\n\t        response = self.md.render(await template.render_async(**context))\n\t        for chunk in response:\n\t            await self.write(chunk.encode())\n\t        await self.write_eof()\n\t        return self\n\t    @handle_template\n\t    async def stream_markdown(self, template_name: str, request: Request, **context):\n", "        await self.prepare(request)\n\t        template = self.env.get_template(template_name)\n\t        async for chunk in template.generate_async(**context):\n\t            await self.write(self.md.render(chunk).encode())\n\t        await self.write_eof()\n\t        return self\n\t    @handle_template\n\t    async def render_template(self, template_name: str, request: Request, **context):\n\t        await self.prepare(request)\n\t        template = self.env.get_template(template_name)\n", "        response = await template.render_async(**context)\n\t        for chunk in response:\n\t            await self.write(chunk.encode())\n\t        await self.write_eof()\n\t        return self\n\t    @handle_template\n\t    async def stream_template(self, template_name: str, request: Request, **context):\n\t        await self.prepare(request)\n\t        template = self.env.get_template(template_name)\n\t        async for chunk in template.generate_async(**context):\n", "            await self.write(chunk.encode())\n\t        await self.write_eof()\n\t        return self\n\t    @handle_template\n\t    async def markdown_string(self, string: str, request: Request):\n\t        await self.prepare(request)\n\t        response = self.md.render(string)\n\t        for chunk in response:\n\t            await self.write(chunk.encode())\n\t        await self.write_eof()\n", "        return self\n\t    @handle_template\n\t    async def stream_markdown_string(self, string: str, request: Request):\n\t        await self.prepare(request)\n\t        for chunk in string:\n\t            await self.write(self.md.render(chunk).encode())\n\t        await self.write_eof()\n\t        return self\n\t    @handle_template\n\t    async def render_html(self, string: str, request: Request):\n", "        await self.prepare(request)\n\t        for chunk in string:\n\t            await self.write(chunk.encode())\n\t        await self.write_eof()\n\t        return self\n"]}
{"filename": "aiofauna/ssr/__init__.py", "chunked_list": ["from .ssr import ServerSideRenderer\n"]}
