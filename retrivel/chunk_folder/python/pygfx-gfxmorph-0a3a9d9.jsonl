{"filename": "setup.py", "chunked_list": ["import re\n\tfrom setuptools import find_packages, setup\n\tNAME = \"gfxmorph\"\n\tSUMMARY = \"Morphing meshes\"\n\twith open(f\"{NAME}/__init__.py\", \"rb\") as fh:\n\t    init_text = fh.read().decode()\n\t    VERSION = re.search(r\"__version__ = \\\"(.*?)\\\"\", init_text).group(1)\n\truntime_deps = [\n\t    \"numpy\",\n\t    \"pygfx\",\n", "]\n\textras_require = {\n\t    \"dev\": [\n\t        \"black\",\n\t        \"flake8\",\n\t        \"flake8-black\",\n\t        \"pep8-naming\",\n\t        \"pytest\",\n\t    ],\n\t}\n", "setup(\n\t    name=NAME,\n\t    version=VERSION,\n\t    packages=find_packages(\n\t        exclude=[\"tests\", \"tests.*\", \"examples\", \"examples.*\", \"exp\", \"exp.*\"]\n\t    ),\n\t    # package_data={f\"{NAME}.data_files\": resources_globs},\n\t    python_requires=\">=3.8.0\",\n\t    install_requires=runtime_deps,\n\t    extras_require=extras_require,\n", "    license=\"BSD 2-Clause\",\n\t    description=SUMMARY,\n\t    long_description=open(\"README.md\").read(),\n\t    long_description_content_type=\"text/markdown\",\n\t    author=\"Almar Klein\",\n\t    author_email=\"almar.klein@gmail.com\",\n\t    url=\"https://github.com/pygfx/gfxmorph\",\n\t    data_files=[(\"\", [\"LICENSE\"])],\n\t    zip_safe=True,\n\t    classifiers=[\n", "        \"Development Status :: 3 - Alpha\",\n\t        \"Intended Audience :: Developers\",\n\t        \"License :: OSI Approved :: BSD License\",\n\t        \"Programming Language :: Python :: 3\",\n\t        \"Topic :: Software Development :: Libraries :: Python Modules\",\n\t        \"Topic :: Scientific/Engineering :: Visualization\",\n\t    ],\n\t    # entry_points={\n\t    #     \"pyinstaller40\": [\n\t    #         \"hook-dirs = pygfx.__pyinstaller:get_hook_dirs\",\n", "    #         \"tests = pygfx.__pyinstaller:get_test_dirs\",\n\t    #     ],\n\t    # },\n\t)\n"]}
{"filename": "example_morph.py", "chunked_list": ["\"\"\"\n\tExample morphing.\n\t\"\"\"\n\timport json\n\timport numpy as np\n\tfrom wgpu.gui.auto import WgpuCanvas, run\n\timport pygfx as gfx\n\timport pylinalg as la\n\tfrom gfxmorph.maybe_pygfx import smooth_sphere_geometry, DynamicMeshGeometry\n\tfrom gfxmorph import DynamicMesh, MeshUndoTracker\n", "from gfxmorph.meshfuncs import vertex_get_neighbours\n\t# %% Morph logic\n\tclass DynamicMeshGeometryWithSizes(DynamicMeshGeometry):\n\t    # This is a subclass of both gfx.Geometry and MeshChangeTracker.\n\t    # This illustrates how we can relatively easily associate additional\n\t    # buffers with the mesh. In this case we add a buffer for points\n\t    # sizes to show the selected vertices. If we'd instead use colors\n\t    # to show selected vertices, that'd work in much the same way.\n\t    def new_vertices_buffer(self, mesh):\n\t        super().new_vertices_buffer(mesh)\n", "        self.sizes = gfx.Buffer(np.zeros((self.positions.nitems,), np.float32))\n\tdef softlimit(i, limit):\n\t    \"\"\"Make i be withing <-limit, +limit>, but using soft slopes.\"\"\"\n\t    f = np.exp(-np.abs(i) / limit)\n\t    return -limit * (f - 1) * np.sign(i)\n\tdef gaussian_weights(f):\n\t    return np.exp(-0.5 * f * f)  # Gaussian kernel (sigma 1, mu 0)\n\tclass Morpher:\n\t    \"\"\"Container class for everything related to the mesh and morphing it.\"\"\"\n\t    def __init__(self):\n", "        # The object that stores & manages the data\n\t        self.m = DynamicMesh(None, None)\n\t        # Tracker that implement a redo stack\n\t        self.undo_tracker = MeshUndoTracker()\n\t        self.m.track_changes(self.undo_tracker)\n\t        # Tracker that maps the mesh to a gfx Geometry (with live updates)\n\t        self.geometry = DynamicMeshGeometryWithSizes()\n\t        self.m.track_changes(self.geometry)\n\t        self.state = None\n\t        self.radius = 0.3\n", "        self._create_world_objects()\n\t    def _create_world_objects(self):\n\t        # The front, to show the mesh itself.\n\t        self.wob_front = gfx.Mesh(\n\t            self.geometry,\n\t            gfx.materials.MeshPhongMaterial(\n\t                color=\"#6ff\", flat_shading=False, side=\"FRONT\"\n\t            ),\n\t        )\n\t        # The back, to show holes and protrusions.\n", "        self.wob_back = gfx.Mesh(\n\t            self.geometry,\n\t            gfx.materials.MeshPhongMaterial(\n\t                color=\"#900\", flat_shading=False, side=\"BACK\"\n\t            ),\n\t        )\n\t        # The wireframe, to show edges.\n\t        self.wob_wire = gfx.Mesh(\n\t            self.geometry,\n\t            gfx.materials.MeshPhongMaterial(\n", "                color=\"#777\",\n\t                opacity=0.05,\n\t                wireframe=True,\n\t                wireframe_thickness=2,\n\t                side=\"FRONT\",\n\t            ),\n\t        )\n\t        # Helper to show points being grabbed\n\t        self.wob_points = gfx.Points(\n\t            self.geometry,\n", "            gfx.PointsMaterial(color=\"yellow\", vertex_sizes=True),\n\t        )\n\t        # A gizmo to show the direction of movement.\n\t        self.wob_gizmo = gfx.Mesh(\n\t            gfx.cylinder_geometry(0.05, 0.05, 0.5, radial_segments=16),\n\t            gfx.MeshPhongMaterial(color=\"yellow\"),\n\t        )\n\t        self.wob_gizmo.visible = False\n\t        # Radius helper\n\t        self.wob_radius = gfx.Mesh(\n", "            smooth_sphere_geometry(subdivisions=2),\n\t            gfx.MeshPhongMaterial(color=\"yellow\", opacity=0.2, side=\"front\"),\n\t        )\n\t        self.wob_radius.visible = False\n\t        self.world_objects = gfx.Group()\n\t        self.world_objects.add(\n\t            self.wob_front,\n\t            self.wob_back,\n\t            self.wob_wire,\n\t            self.wob_points,\n", "            self.wob_gizmo,\n\t            self.wob_radius,\n\t        )\n\t    def cancel(self):\n\t        self.undo_tracker.cancel(self.m)\n\t    def commit(self):\n\t        self.undo_tracker.commit()\n\t    def undo(self):\n\t        self.undo_tracker.undo(self.m)\n\t    def redo(self):\n", "        self.undo_tracker.redo(self.m)\n\t    def highlight(self, highlight):\n\t        if highlight:\n\t            # self.wob_radius.visible = True\n\t            self.wob_wire.material.opacity = 0.075\n\t        else:\n\t            self.wob_radius.visible = False\n\t            self.wob_wire.material.opacity = 0.05\n\t    def show_morph_grab(self, fi, coord):\n\t        # Get pos\n", "        coordvec = np.array(coord).reshape(3, 1)\n\t        vii = self.m.faces[fi]\n\t        pos = (self.m.positions[vii] * coordvec).sum(axis=0) / np.sum(coordvec)\n\t        # Adjust world objects\n\t        self.wob_radius.local.position = pos\n\t        self.wob_radius.local.scale = self.radius\n\t        self.wob_radius.visible = True\n\t    def start_morph_from_vertex(self, xy, vi):\n\t        \"\"\"Initiate a drag, based on a vertex index.\n\t        This method may feel less precise than using ``start_morph_from_face``,\n", "        but is included for cases where picking capabilities are limited.\n\t        \"\"\"\n\t        assert isinstance(vi, int)\n\t        vii = [vi]\n\t        distances = [0]\n\t        pos = self.m.positions[vi].copy()\n\t        normal = self.m.normals[vi].copy()\n\t        return self._start_morph(xy, vii, distances, pos, normal)\n\t    def start_morph_from_face(self, xy, fi, coord):\n\t        \"\"\"Initiate a drag, based on a face index and face coordinates.\n", "        This allows precise grabbing of the mesh. The face coordinates\n\t        are barycentric coordinates; for each vertex it indicates how\n\t        close the grab-point is to that vertex, with 1 being on the\n\t        vertex and 0 being somewhere on the edge between the other two\n\t        vertices. A value of (0.5, 0.5, 0.5) represents the center of\n\t        the face.\n\t        \"\"\"\n\t        assert isinstance(fi, int)\n\t        assert isinstance(coord, (tuple, list)) and len(coord) == 3\n\t        vii = self.m.faces[fi]\n", "        coord_vec = np.array(coord).reshape(3, 1)\n\t        pos = (self.m.positions[vii] * coord_vec).sum(axis=0) / np.sum(coord)\n\t        normal = (self.m.normals[vii] * coord_vec).sum(axis=0)\n\t        normal = normal / np.linalg.norm(normal)\n\t        distances = np.linalg.norm(self.m.positions[vii] - pos, axis=1)\n\t        return self._start_morph(xy, vii, distances, pos, normal)\n\t    def _start_morph(self, xy, vii, ref_distances, pos, normal):\n\t        # Select vertices\n\t        self._select_vertices(vii, ref_distances)\n\t        if not self.state:\n", "            return\n\t        # Add more state\n\t        more_state = {\n\t            \"action\": \"morph\",\n\t            \"pos\": pos,\n\t            \"normal\": normal,\n\t            \"xy\": xy,\n\t        }\n\t        self.state.update(more_state)\n\t        # Bring gizmo into place\n", "        self.wob_gizmo.visible = True\n\t        self.wob_gizmo.world.position = pos\n\t        self.wob_gizmo.local.rotation = la.quat_from_vecs((0, 0, 1), normal)\n\t    def _select_vertices(self, vii, ref_distances):\n\t        # Cancel any pending changes to the mesh. If we were already dragging,\n\t        # that operation is cancelled. If other code made uncomitted changes,\n\t        # these are discarted too (code should have comitted).\n\t        self.cancel()\n\t        self.finish()\n\t        # Select vertices\n", "        search_distance = self.radius * 3  # 3 x std\n\t        indices, geodesic_distances = self.m.select_vertices_over_surface(\n\t            vii, ref_distances, search_distance\n\t        )\n\t        positions = self.m.positions[indices]\n\t        # Pre-calculate deformation weights\n\t        weights = gaussian_weights(geodesic_distances / self.radius).reshape(-1, 1)\n\t        # If for some (future) reason, the selection is empty, cancel\n\t        if len(indices) == 0:\n\t            return\n", "        # Update data for points that highlight the selection\n\t        self.geometry.sizes.data[indices] = 7  # 2 + 20*weights.flatten()\n\t        self.geometry.sizes.update_range(indices.min(), indices.max() + 1)\n\t        # Store state\n\t        self.state = {\n\t            \"action\": \"\",\n\t            \"indices\": indices,\n\t            \"positions\": positions,\n\t            \"weights\": weights,\n\t        }\n", "    def start_smooth(self, xy, fi, coord):\n\t        \"\"\"Start a smooth action.\"\"\"\n\t        assert isinstance(fi, int)\n\t        assert isinstance(coord, (tuple, list)) and len(coord) == 3\n\t        vii = self.m.faces[fi]\n\t        coord_vec = np.array(coord).reshape(3, 1)\n\t        pos = (self.m.positions[vii] * coord_vec).sum(axis=0) / np.sum(coord)\n\t        ref_distances = np.linalg.norm(self.m.positions[vii] - pos, axis=1)\n\t        # Select vertices\n\t        self._select_vertices(vii, ref_distances)\n", "        if not self.state:\n\t            return\n\t        # Add more state\n\t        more_state = {\n\t            \"action\": \"brush_smooth\",\n\t            \"xy\": xy,\n\t        }\n\t        self.state.update(more_state)\n\t    def move(self, xy):\n\t        if not self.state:\n", "            return\n\t        elif self.state[\"action\"] == \"morph\":\n\t            self.move_morph(xy)\n\t        elif self.state[\"action\"] == \"brush_smooth\":\n\t            self.move_smooth(xy)\n\t    def move_morph(self, xy):\n\t        if self.state is None or self.state[\"action\"] != \"morph\":\n\t            return\n\t        # Don't show radius during the drag\n\t        self.wob_radius.visible = False\n", "        # Get delta movement, and express in world coordinates\n\t        dxy = np.array(xy) - self.state[\"xy\"]\n\t        delta = self.state[\"normal\"] * (dxy[1] / 100)\n\t        # Limit the displacement, so it can never be pulled beyond the vertices participarting in the morph.\n\t        # We limit it to 2 sigma. Vertices up to 3 sigma are displaced.\n\t        delta_norm = np.linalg.norm(delta)\n\t        if delta_norm > 0:  # avoid zerodivision\n\t            delta_norm_limited = softlimit(delta_norm, 2 * self.radius)\n\t            delta *= delta_norm_limited / delta_norm\n\t        delta.shape = (1, 3)\n", "        # Apply delta to gizmo\n\t        self.wob_gizmo.world.position = self.state[\"pos\"] + delta\n\t        # Apply delta\n\t        self.m.update_vertices(\n\t            self.state[\"indices\"],\n\t            self.state[\"positions\"] + delta * self.state[\"weights\"],\n\t        )\n\t    def move_smooth(self, xy):\n\t        if self.state is None or self.state[\"action\"] != \"brush_smooth\":\n\t            return\n", "        # Get delta movement, and express in world coordinates.\n\t        # Do a smooth \"tick\" when the mouse has moved 10 px.\n\t        moved_pixel_dist = np.linalg.norm(np.array(xy) - self.state[\"xy\"])\n\t        if moved_pixel_dist > 10:\n\t            self._smooth_some()\n\t            self.state[\"xy\"] = xy\n\t    def _smooth_some(self):\n\t        # We only smooth each vertex with its direct neighbours, but\n\t        # when these little smooth operations are applied recursively,\n\t        # we end up with a pretty Gaussian smooth. Selecting multiple\n", "        # neighbouring vertices (for each vertex), and applying an\n\t        # actual Gaussian kernel is problematic, because we may select\n\t        # zero vertices at low scales (woops nothing happens), or many\n\t        # at high scales (woops performance).\n\t        smooth_factor = 0.5  # <-- can be a parameter\n\t        smooth_factor = max(0.0, min(1.0, smooth_factor))\n\t        faces = self.m.faces\n\t        positions = self.m.positions\n\t        vertex2faces = self.m.vertex2faces\n\t        s_indices = self.state[\"indices\"]\n", "        s_weights = self.state[\"weights\"]\n\t        new_positions = np.zeros((len(s_indices), 3), np.float32)\n\t        for i in range(len(s_indices)):\n\t            vi = s_indices[i]\n\t            w = s_weights[i]\n\t            p = positions[vi]\n\t            vii = list(vertex_get_neighbours(faces, vertex2faces, vi))\n\t            p_delta = (positions[vii] - p).sum(axis=0) / len(vii)\n\t            new_positions[i] = p + p_delta * (w * smooth_factor)\n\t        # Apply new positions\n", "        self.m.update_vertices(s_indices, new_positions)\n\t    def finish(self):\n\t        \"\"\"Stop the morph or smooth action and commit the result.\"\"\"\n\t        self.wob_gizmo.visible = False\n\t        if self.state:\n\t            indices = self.state[\"indices\"]\n\t            self.geometry.sizes.data[indices] = 0\n\t            self.geometry.sizes.update_range(indices.min(), indices.max() + 1)\n\t            self.state = None\n\t            self.commit()\n", "morpher = Morpher()\n\t# %% Setup the viz\n\trenderer = gfx.WgpuRenderer(WgpuCanvas())\n\tcamera = gfx.PerspectiveCamera()\n\tcamera.show_object((0, 0, 0, 8))\n\tscene = gfx.Scene()\n\tscene.add(gfx.Background(None, gfx.BackgroundMaterial(0.4, 0.6)))\n\tscene.add(camera.add(gfx.DirectionalLight()), gfx.AmbientLight())\n\tscene.add(morpher.world_objects)\n\t# %% Functions to modify the mesh\n", "def add_sphere(dx=0, dy=0, dz=0):\n\t    geo = smooth_sphere_geometry(subdivisions=1)\n\t    positions, faces = geo.positions.data, geo.indices.data\n\t    positions += (dx, dy, dz)\n\t    morpher.m.add_mesh(positions, faces)\n\t    morpher.commit()\n\t    camera.show_object(scene)\n\t    renderer.request_draw()\n\t# %% Create key and mouse bindings\n\tprint(__doc__)\n", "# Create controller, also bind it to shift, so we can always hit shift and use the camera\n\tcontroller = gfx.OrbitController(camera, register_events=renderer)\n\tfor k in list(controller.controls.keys()):\n\t    controller.controls[\"shift+\" + k] = controller.controls[k]\n\t@renderer.add_event_handler(\"key_down\")\n\tdef on_key(e):\n\t    if e.key == \"1\":\n\t        print(\"Adding a sphere.\")\n\t        add_sphere()\n\t    elif e.key == \"m\":\n", "        print(\"Metadata:\")\n\t        print(json.dumps(morpher.m.metadata, indent=2))\n\t    elif e.key.lower() == \"z\" and (\"Control\" in e.modifiers or \"Meta\" in e.modifiers):\n\t        if \"Shift\" in e.modifiers:\n\t            morpher.redo()\n\t        else:\n\t            morpher.undo()\n\t        renderer.request_draw()\n\t@morpher.wob_front.add_event_handler(\n\t    \"pointer_down\",\n", "    \"pointer_up\",\n\t    \"pointer_move\",\n\t    \"pointer_enter\",\n\t    \"pointer_leave\",\n\t    \"wheel\",\n\t)\n\tdef on_mouse(e):\n\t    if \"Shift\" in e.modifiers:\n\t        # Don't react when shift is down, so that the controller can work\n\t        morpher.highlight(None)\n", "        renderer.request_draw()\n\t    elif e.type == \"pointer_down\" and e.button == 1:\n\t        face_index = e.pick_info[\"face_index\"]\n\t        face_coord = e.pick_info[\"face_coord\"]\n\t        morpher.start_morph_from_face((e.x, e.y), face_index, face_coord)\n\t        renderer.request_draw()\n\t        e.target.set_pointer_capture(e.pointer_id, e.root)\n\t    elif e.type == \"pointer_down\" and e.button == 2:\n\t        face_index = e.pick_info[\"face_index\"]\n\t        face_coord = e.pick_info[\"face_coord\"]\n", "        morpher.start_smooth((e.x, e.y), face_index, face_coord)\n\t        renderer.request_draw()\n\t        e.target.set_pointer_capture(e.pointer_id, e.root)\n\t    elif e.type == \"pointer_up\":\n\t        morpher.finish()\n\t        renderer.request_draw()\n\t    elif e.type == \"pointer_move\":\n\t        if morpher.state:\n\t            morpher.move((e.x, e.y))\n\t        else:\n", "            face_index = e.pick_info[\"face_index\"]\n\t            face_coord = e.pick_info[\"face_coord\"]\n\t            morpher.show_morph_grab(face_index, face_coord)\n\t        renderer.request_draw()\n\t    elif e.type == \"pointer_enter\":\n\t        morpher.highlight(True)\n\t        renderer.request_draw()\n\t    elif e.type == \"pointer_leave\":\n\t        morpher.highlight(False)\n\t        renderer.request_draw()\n", "    elif e.type == \"wheel\":\n\t        if not morpher.state:\n\t            morpher.radius *= 2 ** (e.dy / 500)\n\t            face_index = e.pick_info[\"face_index\"]\n\t            face_coord = e.pick_info[\"face_coord\"]\n\t            morpher.show_morph_grab(face_index, face_coord)\n\t            renderer.request_draw()\n\t            e.cancel()\n\t# %% Run\n\tadd_sphere()\n", "add_sphere(3, 0, 0)\n\tdef animate():\n\t    renderer.render(scene, camera)\n\trenderer.request_draw(animate)\n\trun()\n"]}
{"filename": "example_undo.py", "chunked_list": ["\"\"\"\n\tExample for demonstrating the dynamic mesh.\n\tKey bindings:\n\t* 1: add sphere mesh\n\t* 2: add 2 spheres connected by a corrupt face\n\t* h: remove a random face, creating a hole\n\t* r: repair (note, can only repair small holes)\n\t* m: print metadata\n\t\"\"\"\n\timport json\n", "import numpy as np\n\tfrom wgpu.gui.auto import WgpuCanvas\n\timport pygfx as gfx\n\tfrom gfxmorph.maybe_pygfx import smooth_sphere_geometry, DynamicMeshGeometry\n\tfrom gfxmorph import DynamicMesh, MeshUndoTracker\n\timport observ.store\n\t# --- Setup the mesh\n\tclass MeshContainer:\n\t    \"\"\"Just a container to keep all stuff related to the mesh together.\"\"\"\n\t    def __init__(self):\n", "        # The object that stores & manages the data\n\t        self.dynamic_mesh = DynamicMesh(None, None)\n\t        # Tracker that implement a redo stack\n\t        self.undo_tracker = MeshUndoTracker()\n\t        self.dynamic_mesh.track_changes(self.undo_tracker)\n\t        # Tracker that maps the mesh to a gfx Geometry (with live updates)\n\t        self.geometry = DynamicMeshGeometry()\n\t        self.dynamic_mesh.track_changes(self.geometry)\n\t        # Two world objects, one for the front and one for the back (so we can clearly see holes)\n\t        self.ob1 = gfx.Mesh(\n", "            self.geometry,\n\t            gfx.materials.MeshPhongMaterial(\n\t                color=\"green\", flat_shading=False, side=\"FRONT\"\n\t            ),\n\t        )\n\t        self.ob2 = gfx.Mesh(\n\t            self.geometry,\n\t            gfx.materials.MeshPhongMaterial(\n\t                color=\"red\", flat_shading=False, side=\"BACK\"\n\t            ),\n", "        )\n\t    def get_state(self):\n\t        return self.undo_tracker.commit()\n\t    def set_state(self, state):\n\t        self.undo_tracker.apply_version(self.dynamic_mesh, state)\n\tmesh = MeshContainer()\n\t# --- Setup the store\n\tclass Store(observ.store.Store):\n\t    \"\"\"The observ store to track thet mesh state. In real applications\n\t    the store will also contain other state.\n", "    \"\"\"\n\t    @observ.store.mutation\n\t    def set_mesh_state(self, state):\n\t        self.state[\"mesh_state\"] = state\n\tstore = Store({\"mesh_state\": 0})\n\t# The watch() function re-calls the first function whenever any\n\t# observables that it uses change, and then passes the result to the\n\t# second function.\n\t_ = observ.watch(\n\t    lambda: store.state[\"mesh_state\"],\n", "    mesh.set_state,\n\t    sync=True,\n\t    immediate=True,\n\t)\n\t# --- Functions to modify the mesh\n\t# Convenience function to take a snapshot of the mesh\n\tdef save_mesh_state():\n\t    store.set_mesh_state(mesh.get_state())\n\tdef add_mesh():\n\t    geo = smooth_sphere_geometry(subdivisions=1)\n", "    positions, faces = geo.positions.data, geo.indices.data\n\t    positions += np.random.normal(0, 5, size=(3,))\n\t    mesh.dynamic_mesh.add_mesh(positions, faces)\n\t    save_mesh_state()\n\t    camera.show_object(scene)\n\t    renderer.request_draw()\n\tdef add_broken_mesh():\n\t    geo = smooth_sphere_geometry()\n\t    positions1, faces1 = geo.positions.data, geo.indices.data\n\t    positions1 += np.random.normal(0, 5, size=(3,))\n", "    positions2 = positions1 + (2.2, 0, 0)\n\t    faces2 = faces1 + len(positions1)\n\t    faces3 = [[faces2[10][0], faces2[10][1], faces1[20][0]]]\n\t    mesh.dynamic_mesh.add_mesh(\n\t        np.concatenate([positions1, positions2]),\n\t        np.concatenate([faces1, faces2, faces3]),\n\t    )\n\t    camera.show_object(scene)\n\t    renderer.request_draw()\n\t    save_mesh_state()\n", "def breakit():\n\t    nfaces = len(mesh.dynamic_mesh.faces)\n\t    mesh.dynamic_mesh.delete_faces(np.random.randint(0, nfaces))\n\t    save_mesh_state()\n\tdef repair():\n\t    mesh.dynamic_mesh.repair(True)\n\t    # Only store new state if there was indeed a change\n\t    if mesh.undo_tracker.has_pending_changes():\n\t        save_mesh_state()\n\t# --- Setup the viz\n", "renderer = gfx.WgpuRenderer(WgpuCanvas())\n\tcamera = gfx.OrthographicCamera()\n\tcamera.show_object((0, 0, 0, 8))\n\tscene = gfx.Scene()\n\tscene.add(gfx.Background(None, gfx.BackgroundMaterial(0.4, 0.6)))\n\tscene.add(camera.add(gfx.DirectionalLight()), gfx.AmbientLight())\n\tscene.add(mesh.ob1, mesh.ob2)\n\t# --- Create key bindings\n\tprint(__doc__)\n\t@renderer.add_event_handler(\"key_down\")\n", "def on_key(e):\n\t    if e.key == \"1\":\n\t        print(\"Adding a sphere.\")\n\t        add_mesh()\n\t    elif e.key == \"2\":\n\t        print(\"Adding 2 spheres connected with a corrupt face.\")\n\t        add_broken_mesh()\n\t    elif e.key == \"h\":\n\t        print(\"Creating a hole.\")\n\t        breakit()\n", "    elif e.key == \"r\":\n\t        print(\"Repairing.\")\n\t        repair()\n\t    elif e.key == \"m\":\n\t        print(\"Metadata:\")\n\t        print(json.dumps(mesh.dynamic_mesh.metadata, indent=2))\n\t    elif e.key.lower() == \"z\" and (\"Control\" in e.modifiers or \"Meta\" in e.modifiers):\n\t        if \"Shift\" in e.modifiers:\n\t            store.redo()\n\t        else:\n", "            store.undo()\n\t# --- Run\n\tgfx.show(scene, camera=camera, renderer=renderer)\n"]}
{"filename": "tests/test_pygfx.py", "chunked_list": ["import numpy as np\n\timport pylinalg as la\n\tfrom gfxmorph.maybe_pygfx import smooth_sphere_geometry\n\tfrom gfxmorph.maybe_pylinalg import volume_of_closed_mesh\n\tfrom testutils import run_tests\n\tdef test_smooth_sphere_geometry():\n\t    # subdivisions\n\t    g = smooth_sphere_geometry(1)\n\t    assert g.indices.data.shape == (60, 3)\n\t    assert g.positions.data.shape == (32, 3)\n", "    g = smooth_sphere_geometry(1, subdivisions=1)\n\t    assert g.indices.data.shape == (60 * 4, 3)\n\t    assert g.positions.data.shape == (60 * 4 / 2 + 2, 3)\n\t    g = smooth_sphere_geometry(1, subdivisions=2)\n\t    assert g.indices.data.shape == (60 * 16, 3)\n\t    assert g.positions.data.shape == (60 * 16 / 2 + 2, 3)\n\t    # max_edge_length\n\t    def get_edge_length(g):\n\t        ia, ib, _ = g.indices.data[0]\n\t        a, b = g.positions.data[[ia, ib]]\n", "        return la.vec_dist(a, b)\n\t    g = smooth_sphere_geometry(1, max_edge_length=1)\n\t    assert g.indices.data.shape == (60, 3)\n\t    assert get_edge_length(g) < 1\n\t    g = smooth_sphere_geometry(0.5, max_edge_length=0.5)\n\t    assert g.indices.data.shape == (60, 3)\n\t    assert get_edge_length(g) < 0.5\n\t    g = smooth_sphere_geometry(1, max_edge_length=0.5)\n\t    assert g.indices.data.shape == (60 * 4, 3)\n\t    assert get_edge_length(g) < 0.5\n", "    g = smooth_sphere_geometry(2, max_edge_length=1)\n\t    assert g.indices.data.shape == (60 * 4, 3)\n\t    assert get_edge_length(g) < 1\n\t    g = smooth_sphere_geometry(2, max_edge_length=0.5)\n\t    assert g.indices.data.shape == (60 * 16, 3)\n\t    assert get_edge_length(g) < 0.5\n\t    # radius, volume, and max_edge_length\n\t    for radius in (0.4, 0.8, 1.2, 1.4):\n\t        volume_errors = []\n\t        for el in (0.4, 0.3, 0.2, 0.1):\n", "            g = smooth_sphere_geometry(radius, max_edge_length=el)\n\t            assert get_edge_length(g) < el\n\t            assert np.allclose(np.linalg.norm(g.positions.data, axis=1), radius)\n\t            expected_v = (4 / 3) * np.pi * radius**3\n\t            v = volume_of_closed_mesh(g.positions.data, g.indices.data)\n\t            assert np.allclose(v, expected_v, atol=0.5 * el)\n\t            volume_errors.append(expected_v - v)\n\t        # Check that more subdivisions produces a better approximation os a sphere\n\t        assert volume_errors[0] > volume_errors[-1]\n\tif __name__ == \"__main__\":\n", "    run_tests(globals())\n"]}
{"filename": "tests/test_dynamicmesh.py", "chunked_list": ["import numpy as np\n\timport pytest\n\tfrom gfxmorph import maybe_pygfx\n\tfrom gfxmorph import DynamicMesh\n\tfrom testutils import run_tests\n\tfrom gfxmorph.mesh import MeshPathSmooth1, MeshPathSmooth2\n\tdef test_mesh_basics():\n\t    geo = maybe_pygfx.smooth_sphere_geometry(1, subdivisions=3)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n", "    # Create a silly mesh consisting of a single triangle\n\t    triangle = [[0, 0, 0], [0, 0, 1], [0, 1, 0]]\n\t    m = DynamicMesh(triangle, [[0, 1, 2]])\n\t    assert not m.is_closed\n\t    assert m.get_surface_area() == 0.5\n\t    with pytest.raises(RuntimeError):\n\t        m.get_volume()  # cannot be calculated on an open mesh\n\t    # Cannot creata a null mesh\n\t    with pytest.raises(ValueError):\n\t        DynamicMesh(np.zeros((0, 3), np.float32), np.zeros((0, 3), np.int32))\n", "    with pytest.raises(ValueError):\n\t        DynamicMesh(triangle, np.zeros((0, 3), np.int32))\n\t    with pytest.raises(ValueError):\n\t        DynamicMesh(np.zeros((0, 3), np.float32), [[0, 1, 2]])\n\t    # Empty mesh\n\t    m = DynamicMesh(None, None)\n\t    assert m.get_volume() == 0.0\n\t    assert m.get_surface_area() == 0.0\n\t    # Creat mesh and check its volume and surface\n\t    m = DynamicMesh(vertices, faces)\n", "    expected_volume = (4 / 3) * np.pi\n\t    expected_area = 4 * np.pi\n\t    assert 0.99 * expected_area < m.get_surface_area() < expected_area\n\t    assert 0.99 * expected_volume < m.get_volume() < expected_volume\n\t    assert m.is_closed\n\t    assert m.component_count == 1\n\t    assert m.is_connected\n\t    # Metadata\n\t    d = m.metadata\n\t    assert isinstance(d, dict)\n", "    assert \"is_edge_manifold\" in d\n\t    assert \"approx_mem\" in d\n\t    # Create a mesh with two objects\n\t    vertices2 = np.row_stack([vertices + 10, vertices + 20])\n\t    faces2 = np.row_stack([faces, faces + len(vertices)])\n\t    # Check its volume\n\t    m = DynamicMesh(vertices2, faces2)\n\t    expected_volume = 2 * (4 / 3) * np.pi\n\t    assert 0.9 * expected_volume < m.get_volume() < expected_volume\n\t    assert m.is_closed\n", "    assert m.component_count == 2\n\t    assert not m.is_connected\n\t    # Now turn the meshes inside out\n\t    faces2[:, 1], faces2[:, 2] = faces2[:, 2].copy(), faces2[:, 1].copy()\n\t    # The repair mechanism will flip exactly what's needed to fix up the mesh!\n\t    m = DynamicMesh(vertices2, faces2)\n\t    expected_volume = 2 * (4 / 3) * np.pi\n\t    assert m.get_volume() < 0\n\t    m.repair()\n\t    assert 0.9 * expected_volume < m.get_volume() < expected_volume\n", "    assert m.is_closed\n\t    assert m.component_count == 2\n\tdef test_mesh_edges():\n\t    vertices = np.zeros((4, 3), np.float32)\n\t    faces = [(0, 1, 2), (0, 2, 3)]\n\t    m = DynamicMesh(vertices, faces)\n\t    assert m.edges.tolist() == [[0, 1], [1, 2], [2, 0], [0, 2], [2, 3], [3, 0]]\n\tdef test_mesh_selection_basics():\n\t    # Create a mesh\n\t    geo = maybe_pygfx.smooth_sphere_geometry(1, subdivisions=1)\n", "    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = DynamicMesh(vertices, faces)\n\t    # Select a vertex, twice\n\t    i1, d1 = m.get_closest_vertex((-2, 0, 0))\n\t    i2, d2 = m.get_closest_vertex((+2, 0, 0))\n\t    assert i1 != i2\n\t    assert d1 == 1.0\n\t    assert d2 == 1.0\n\t    # Select over surface\n", "    selected1, _ = m.select_vertices_over_surface(i1, 0, 0.5)\n\t    selected2, _ = m.select_vertices_over_surface(i2, 0, 0.5)\n\t    # Since this mesh is very regular, the selected number must be the same\n\t    assert len(selected1) == 7\n\t    assert len(selected2) == 7\n\t    # Select over surface, with very high distance, so that the whole mesh is selected\n\t    selected1, _ = m.select_vertices_over_surface(i1, 0, 4)\n\t    selected2, _ = m.select_vertices_over_surface(i2, 0, 4)\n\t    assert np.all(selected1 == selected2)\n\t    assert len(selected1) == len(vertices)\n", "def test_mesh_path_distance():\n\t    \"\"\"This test validates the test_MeshPathSmooth2 class directly.\"\"\"\n\t    def follow_points1(points):\n\t        path = MeshPathSmooth1()\n\t        for p, n in zip(points, normals):\n\t            new_path = path.add(p, n)\n\t            assert new_path.dist >= path.dist\n\t            path = new_path\n\t        return path\n\t    def follow_points2(points):\n", "        path = MeshPathSmooth2()\n\t        for p, n in zip(points, normals):\n\t            new_path = path.add(p, n)\n\t            assert new_path.dist >= path.dist\n\t            assert new_path.dist <= new_path.edist * 1.0000001\n\t            path = new_path\n\t        return path\n\t    # Create a bunch of points on a semi-circle. The points are on a curved line,\n\t    # but from the surface pov this is a straight line, i.e. a geodesic.\n\t    # We make the distance between each two points 0.1, for easy math.\n", "    t = np.linspace(0, np.pi, 11)\n\t    points1 = np.zeros((11, 3), np.float32)\n\t    points1[:, 0] = np.sin(t)\n\t    points1[:, 1] = np.cos(t)\n\t    points1 /= 3.1286892  # precalculated\n\t    assert 0.1, np.linalg.norm(points1[0] - points1[1]) < 0.10001\n\t    # Since we rotate around the origin, we can easily calculate the surface normals\n\t    normals = points1 / np.linalg.norm(points1, axis=1).reshape(-1, 1)\n\t    # Follow this straight line with the smooth1 approach,\n\t    # just to show that it does cut corners. Not good!\n", "    path = follow_points1(points1)\n\t    assert 0.99999 < path.edist < 1.000001\n\t    assert 0.93 < path.dist < 0.94  # 6% shorter\n\t    # Follow the same straight line but with the smooth2 approach,\n\t    # that attempt to follow the surface. Much better!\n\t    path = follow_points2(points1)\n\t    assert 0.99999 < path.edist < 1.000001\n\t    assert 0.99999 < path.dist < 1.000001  # 0% error\n\t    # Now displace the points, simulating the irregular patterns of triangles on a mesh ...\n\t    # A subtle zig-zag\n", "    points2 = points1.copy()\n\t    points2[1:-1:2, 2] = -0.02\n\t    points2[2:-1:2, 2] = +0.02\n\t    # The path is a bit longer, but we manage to bring it back!\n\t    path = follow_points2(points2)\n\t    assert 1.06 < path.edist < 1.07  # The path is 6% longer\n\t    assert 1.00 < path.dist < 1.01  # Less than 1% left\n\t    # A moderate zig-zag.\n\t    # This represents a worst-case path through a mesh with normally sized triangles.\n\t    points2 = points1.copy()\n", "    points2[1:-1:2, 2] = -0.05\n\t    points2[2:-1:2, 2] = +0.05\n\t    # The path is much longer, but we manage to bring it back!\n\t    path = follow_points2(points2)\n\t    assert 1.35 < path.edist < 1.36  # The path is 36% longer\n\t    assert 1.03 < path.dist < 1.04  # Just about 3% left\n\t    # A big zig-zag.\n\t    # This represents a very worst-case path through very narrow triangles.\n\t    points2 = points1.copy()\n\t    points2[1:-1:2, 2] = -0.2\n", "    points2[2:-1:2, 2] = +0.2\n\t    # The path is MUCH longer, but we manage to bring it back!\n\t    path = follow_points2(points2)\n\t    assert 3.74 < path.edist < 3.75  # The path is 274% longer\n\t    assert 1.27 < path.dist < 1.28  # Just 27% left\n\t    # A straight line with a few points moved to the side.\n\t    # Depending on how the surface-distance is calculated, the opposing\n\t    # sides of the zig-zag may help iron out the line. This use-case\n\t    # does not have this effect. The current implementation does not\n\t    # really suffer from this effect and is able to \"straighten\"  this\n", "    # line just as well.\n\t    points2 = points1.copy()\n\t    points2[1:-1:4, 2] = -0.1\n\t    # The path is longer and we can straighten it out.\n\t    path = follow_points2(points2)\n\t    assert 1.24 < path.edist < 1.25  # The path is 25% longer\n\t    assert 1.02 < path.dist < 1.03  # Just 3% left\n\tdef test_mesh_selection_precision():\n\t    \"\"\"This test validates the precision of the mesh selection.\n\t    It implicitly tests the MeshPathSmooth2 class on real mesh data.\n", "    \"\"\"\n\t    # Create a mesh\n\t    radius = 1\n\t    geo = maybe_pygfx.smooth_sphere_geometry(radius, subdivisions=1)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = DynamicMesh(vertices, faces)\n\t    # Select top vertex, and vertices at the middle of the sphere. There\n\t    # is a nice line of vertices at exactly the equator of the sphere\n\t    # (with just a few interruptions). There are no straight lines of\n", "    # vertices going from the top to the equator (meridians), therefore\n\t    # we observe pretty uniform distance-errors.\n\t    assert len(vertices) == 122\n\t    vii_top = np.where(vertices[:, 2] == 1)[0]\n\t    assert len(vii_top) == 1\n\t    vi_top = vii_top[0]\n\t    vii_middle = np.where(vertices[:, 2] == 0)[0]\n\t    assert len(vii_middle) == 16\n\t    # The distance to each of the middle points (from the top) is ideally ...\n\t    circumference = 2 * np.pi * radius\n", "    ideal_dist = circumference / 4  # i.e. a quarter pi, numnum\n\t    # Select vertices EDGE\n\t    max_dist = ideal_dist * 1.1\n\t    selected, distances = m.select_vertices_over_surface(vi_top, 0, max_dist, \"edge\")\n\t    assert len(selected) < 80\n\t    assert not set(vii_middle).difference(selected)  # all middle points are selected\n\t    # The most awkward path to the equator costs about 8% more distance\n\t    vii_dists = [(vi, d) for vi, d in zip(selected, distances) if vi in vii_middle]\n\t    d = max(d for _, d in vii_dists)\n\t    assert 1.08 < d / ideal_dist < 1.09\n", "    # Select vertices SURFACE\n\t    max_dist = ideal_dist * 1.1\n\t    selected, distances = m.select_vertices_over_surface(vi_top, 0, max_dist, \"smooth2\")\n\t    assert len(selected) < 80\n\t    assert not set(vii_middle).difference(selected)  # all middle points are selected\n\t    # Now just 3% more distance\n\t    vii_dists = [(vi, d) for vi, d in zip(selected, distances) if vi in vii_middle]\n\t    d = max(d for _, d in vii_dists)\n\t    assert 1.02 < d / ideal_dist < 1.03\n\t    # Now flatten the sphere. In the above, because the surface is curved,\n", "    # the distances \"cut the corner\" and are smaller, which hides some\n\t    # of the error in distance. By creating a flat surface we can measure\n\t    # the distance of the error without this effect.\n\t    # Upate mesh\n\t    vertices[:, 2] = 0\n\t    m.update_vertices(np.arange(len(vertices)), vertices)\n\t    # The distance to each of the middle points (from the center) is ideally ...\n\t    ideal_dist = radius  # i.e. 1\n\t    # Select vertices EDGE\n\t    max_dist = ideal_dist * 1.3\n", "    selected, distances = m.select_vertices_over_surface(vi_top, 0, max_dist, \"edge\")\n\t    assert len(selected) < 102\n\t    assert not set(vii_middle).difference(selected)  # all middle points are selected\n\t    # The most awkward path to the equator costs about 26% more distance\n\t    vii_dists = [(vi, d) for vi, d in zip(selected, distances) if vi in vii_middle]\n\t    d = max(d for _, d in vii_dists)\n\t    assert 1.25 < d / ideal_dist < 1.26\n\t    # Select vertices SURFACE\n\t    max_dist = ideal_dist * 1.3\n\t    selected, distances = m.select_vertices_over_surface(vi_top, 0, max_dist, \"smooth2\")\n", "    assert len(selected) < 102\n\t    assert not set(vii_middle).difference(selected)  # all middle points are selected\n\t    # Now just 7% more distance\n\t    vii_dists = [(vi, d) for vi, d in zip(selected, distances) if vi in vii_middle]\n\t    d = max(d for _, d in vii_dists)\n\t    assert 1.06 < d / ideal_dist < 1.07\n\tif __name__ == \"__main__\":\n\t    run_tests(globals())\n"]}
{"filename": "tests/test_corrupt.py", "chunked_list": ["\"\"\"\n\tTest on adverserial cases. The word corrupt is used very generous here,\n\te.g. it's also used for open manifolds.\n\t\"\"\"\n\timport numpy as np\n\timport pygfx as gfx\n\timport pytest\n\timport gfxmorph\n\tfrom testutils import (\n\t    run_tests,\n", "    iter_test_meshes,\n\t    iter_closed_meshes,\n\t    get_quad,\n\t    get_sphere,\n\t    iter_fans,\n\t)\n\t# Set to 1 to perform these tests on skcg, as a validation check\n\tUSE_SKCG = 0\n\tif USE_SKCG:\n\t    import skcg\n", "    MeshClass = skcg.Mesh\n\telse:\n\t    MeshClass = gfxmorph.DynamicMesh\n\t# %% Some basic tests first\n\tdef test_raw_meshes():\n\t    \"\"\"Test that the raw meshes, unchanged, are what we expect them to be.\"\"\"\n\t    count = 0\n\t    for vertices, faces, is_closed in iter_test_meshes():\n\t        count += 1\n\t        m = MeshClass(vertices, faces)\n", "        assert m.is_manifold\n\t        assert m.is_closed == is_closed\n\t        assert m.is_oriented\n\t    assert count == 6\n\tdef test_a_single_triangle():\n\t    \"\"\"A single triangle is an open oriented manifold.\"\"\"\n\t    vertices = [\n\t        [-1, -1, 0],\n\t        [+1, -1, 0],\n\t        [+1, +1, 0],\n", "    ]\n\t    faces = [\n\t        [0, 2, 1],\n\t    ]\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\tdef test_a_null_mesh():\n\t    m = MeshClass(None, None)\n", "    # I'm not sure what would be correct, but  I guess with zero faces all conditions are valid?\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert m.is_oriented\n\tdef test_invalid_faces():\n\t    \"\"\"Test to check that faces must have valid indices for the vertices\"\"\"\n\t    # Copied from skcg\n\t    with pytest.raises(ValueError):\n\t        MeshClass(\n\t            [[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]], [[0, 1, 9999]]\n", "        )\n\t    with pytest.raises(ValueError):\n\t        MeshClass([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]], [[0, 1, -1]])\n\t# %% Test is_manifold\n\tdef test_non_manifold_collapse_face_1():\n\t    \"\"\"Collapse a face. Now the mesh is open, and one edge has 3 faces.\"\"\"\n\t    for vertices, faces, is_closed in iter_test_meshes():\n\t        faces[1][1] = faces[1][0]\n\t        m = MeshClass(vertices, faces)\n\t        assert not m.is_edge_manifold\n", "        assert not m.is_vertex_manifold  # cannot have sound fans with 3-face edges\n\t        assert not m.is_closed  # cannot be closed if not edge manifold\n\t        assert not m.is_oriented  # cannot be oriented if not edge manifold\n\t        # Collapsing this face the small meshes makes it non-manifold even after repair\n\t        if len(faces) <= 4:\n\t            continue\n\t        m.repair_manifold()  # We can detect and remove collapsed faces!\n\t        assert m.is_manifold\n\t        assert not m.is_closed  # there's a hole in the mesh\n\t        assert m.is_oriented\n", "        m.repair_holes()\n\t        assert m.is_manifold\n\t        assert m.is_closed\n\t        assert m.is_oriented\n\tdef test_non_manifold_collapse_face_2():\n\t    \"\"\"Collapse a face, but at the edge, so its still edge-manifold.\"\"\"\n\t    vertices, faces, _ = get_quad()\n\t    faces[1][0] = faces[1][1]\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_edge_manifold\n", "    assert not m.is_vertex_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented  # the collapsed face maket is non-orientable\n\t    m.repair_manifold()  # We can detect and remove collapsed faces!\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\tdef test_non_manifold_add_face_1():\n\t    \"\"\"Add one face to the mesh. Some edges will now have 3 faces.\"\"\"\n\t    for vertices, faces, _ in iter_test_meshes():\n", "        # Cannot do this on quad and tetrahedron\n\t        if len(vertices) <= 4:\n\t            continue\n\t        extra_face = faces[1].copy()\n\t        extra_face[1] = len(vertices) - 1\n\t        assert not any(set(face) == set(extra_face) for face in faces)\n\t        faces.append(extra_face)\n\t        m = MeshClass(vertices, faces)\n\t        assert not m.is_edge_manifold\n\t        assert not m.is_manifold  # double-check\n", "        assert not m.is_closed\n\t        assert not m.is_oriented\n\t        m.repair_manifold()\n\t        assert m.is_manifold\n\t        assert m.is_closed == (False if len(m.faces) > 0 else True)\n\t        assert m.is_oriented\n\tdef test_non_manifold_add_face_2():\n\t    \"\"\"Add a duplicate face to the mesh. Some edges will now have 3 faces.\"\"\"\n\t    for vertices, faces, is_closed in iter_test_meshes():\n\t        faces.append(faces[0])\n", "        faces.append(faces[0])  # add two, to make sure both are removed\n\t        m = MeshClass(vertices, faces)\n\t        assert not m.is_edge_manifold\n\t        assert not m.is_vertex_manifold\n\t        assert not m.is_closed\n\t        assert not m.is_oriented\n\t        m.repair_manifold()  # We can detect and remove duplicate faces!\n\t        assert m.is_edge_manifold\n\t        assert m.is_manifold\n\t        assert m.is_closed == is_closed\n", "        assert m.is_oriented\n\tdef test_non_manifold_add_face_3():\n\t    \"\"\"Add one face to the mesh, using one extra vertex. One edge will now have 3 faces.\"\"\"\n\t    for vertices, faces, _ in iter_test_meshes():\n\t        vertices.append([1, 2, 3])\n\t        faces.append([faces[0][0], faces[0][1], len(vertices) - 1])\n\t        m = MeshClass(vertices, faces)\n\t        assert not m.is_edge_manifold\n\t        assert not m.is_vertex_manifold\n\t        assert not m.is_closed\n", "        assert not m.is_oriented\n\t        m.repair_manifold()\n\t        assert m.is_manifold\n\t        assert m.is_closed == (False if len(m.faces) > 0 else True)\n\t        assert m.is_oriented\n\tdef test_non_manifold_add_face_4():\n\t    \"\"\"Add one face to the mesh, using two extra vertices. There now is connectivity via a vertex.\"\"\"\n\t    # Note (AK): this case is excluded from skcg.Mesh, because its\n\t    # implementation is very slow. I have changed my local version of\n\t    # skcg to turn the test on.\n", "    for vertices, faces, is_closed in iter_test_meshes():\n\t        # Break it\n\t        vertices.append([1, 2, 3])\n\t        vertices.append([2, 3, 4])\n\t        faces.append([faces[0][0], len(vertices) - 2, len(vertices) - 1])\n\t        m = MeshClass(vertices, faces)\n\t        assert m.is_edge_manifold\n\t        assert not m.is_vertex_manifold\n\t        assert not m.is_manifold\n\t        assert not m.is_closed  # not closed because the added face is not\n", "        assert m.is_oriented\n\t        # Repair it\n\t        m.repair_manifold()\n\t        assert m.is_manifold\n\t        assert not m.is_closed\n\t        assert m.is_oriented\n\t        # Repair harder\n\t        if is_closed:\n\t            m.repair_holes()\n\t            assert m.is_manifold\n", "            assert m.is_closed\n\t            assert m.is_oriented\n\tdef test_non_manifold_add_face_5():\n\t    \"\"\"Add one face to the mesh, using one extra vertex, connected via two vertices (no edges).\"\"\"\n\t    for vertices, faces, is_closed in iter_test_meshes():\n\t        # Cannot do this on quad and tetrahedron\n\t        if len(vertices) <= 4:\n\t            continue\n\t        # Break it\n\t        vertices.append([1, 2, 3])\n", "        extra_vi = 3 if len(vertices) == 6 else 10\n\t        extra_face = [1, extra_vi, len(vertices) - 1]\n\t        assert not any(len(set(face).intersection(extra_face)) > 1 for face in faces)\n\t        faces.append(extra_face)\n\t        m = MeshClass(vertices, faces)\n\t        assert m.is_edge_manifold\n\t        assert not m.is_vertex_manifold\n\t        assert not m.is_manifold\n\t        assert not m.is_closed\n\t        assert m.is_oriented\n", "        # Repair it\n\t        m.repair_manifold()\n\t        assert m.is_manifold\n\t        assert not m.is_closed\n\t        assert m.is_oriented\n\t        m.remove_small_components(2)\n\t        assert m.is_manifold\n\t        assert m.is_closed == is_closed\n\t        assert m.is_oriented\n\tdef test_non_manifold_weakly_connected_1():\n", "    \"\"\"Attach one part of the mesh to another part, using just one vertex.\"\"\"\n\t    # Note: This is a single connected component that *also* has a\n\t    # one-vertex connection. A case that I initially overlooked.\n\t    # Some hand-picked vertex pairs to connect\n\t    vertex_pairs = [\n\t        (12, 29),  # about opposite the sphere\n\t        (0, 21),  # one vertex in between\n\t    ]\n\t    vertices, faces, _ = get_sphere()\n\t    for index_to_start_from in range(len(faces)):\n", "        for vi1, vi2 in vertex_pairs:\n\t            vertices, faces, _ = get_sphere()\n\t            # Break it\n\t            faces = np.asarray(faces, np.int32)\n\t            faces[faces == vi2] = vi1\n\t            faces[0], faces[index_to_start_from] = tuple(\n\t                faces[index_to_start_from]\n\t            ), tuple(faces[0])\n\t            m = MeshClass(vertices, faces)\n\t            assert m.is_edge_manifold\n", "            assert not m.is_vertex_manifold\n\t            assert m.is_closed  # still closed!\n\t            assert m.is_oriented\n\t            # Repair it\n\t            m.repair_manifold()\n\t            assert m.is_manifold\n\t            assert m.is_closed\n\t            assert m.is_oriented\n\tdef test_non_manifold_weakly_connected_2():\n\t    \"\"\"Attach two meshes, using just one vertex.\"\"\"\n", "    # Stitch the test meshes together, some are open, some closed.\n\t    for vertices1, faces1, closed1 in iter_test_meshes():\n\t        for vertices2, faces2, closed2 in iter_test_meshes():\n\t            faces1 = np.array(faces1)\n\t            faces2 = np.array(faces2)\n\t            offset2 = faces1.max() + 1\n\t            faces = np.concatenate([faces1, faces2 + offset2])\n\t            vertices = vertices1 + vertices2\n\t            # Sanity check: adding individual meshes is manifold\n\t            m = MeshClass(vertices, faces)\n", "            assert m.is_edge_manifold\n\t            assert m.is_vertex_manifold\n\t            assert m.is_oriented\n\t            assert m.is_closed == (closed1 and closed2)\n\t            # Try this for a couple of different vertices\n\t            for iter in range(4):\n\t                # Break it (stitch together)\n\t                i1 = np.random.randint(faces1.max() + 1)\n\t                i2 = np.random.randint(faces2.max() + 1) + offset2\n\t                stitched_faces = faces.copy()\n", "                stitched_faces[faces == i2] = i1\n\t                m = MeshClass(vertices, stitched_faces)\n\t                assert m.is_edge_manifold\n\t                assert not m.is_vertex_manifold\n\t                assert m.is_oriented\n\t                assert m.is_closed == (closed1 and closed2)\n\t                # Repair it\n\t                m.repair_manifold()\n\t                assert m.is_manifold\n\t                assert m.is_closed == (closed1 and closed2)\n", "                assert m.is_oriented\n\tdef test_non_manifold_weakly_connected_3():\n\t    \"\"\"Attatch two fans in many different configurations, using one vertex.\"\"\"\n\t    # This tests a variety of fan topologies, and combinations\n\t    # thereof, to help ensure that the vertex-manifold detection is sound.\n\t    # Note that in this test we assume that the algorithm to detect\n\t    # vertex-manifoldness only looks at the faces incident to the vertex\n\t    # in question, and e.g. does not consider neighbours of these faces\n\t    # (except the ones incident to the same vertex).\n\t    for faces1 in iter_fans():\n", "        for faces2 in iter_fans():\n\t            faces1 = np.array(faces1)\n\t            faces2 = np.array(faces2)\n\t            offset2 = faces1.max() + 1\n\t            faces = np.concatenate([faces1, faces2 + offset2])\n\t            # Stub vertices\n\t            vertices = np.zeros((faces.max() + 1, 3), np.float32)\n\t            # Sanity check: adding individual meshes is manifold\n\t            m = MeshClass(vertices, faces)\n\t            assert m.is_edge_manifold\n", "            assert m.is_vertex_manifold\n\t            assert m.is_oriented\n\t            assert not m.is_closed\n\t            # Break it (stitch them together)\n\t            faces[faces == offset2] = 0\n\t            m = MeshClass(vertices, faces)\n\t            assert m.is_edge_manifold\n\t            assert not m.is_vertex_manifold\n\t            assert m.is_oriented\n\t            assert not m.is_closed  # none of these fans are closed\n", "            # Repair it\n\t            m.repair_manifold()\n\t            assert m.is_manifold\n\t            assert not m.is_closed\n\t            assert m.is_oriented\n\t# %% Test is_closed\n\tdef test_non_closed_remove_face():\n\t    \"\"\"Remove a face, opening up the mesh.\"\"\"\n\t    for vertices, faces, is_closed in iter_test_meshes():\n\t        # Does not work for quad and strip\n", "        if not is_closed:\n\t            continue\n\t        faces.pop(1)\n\t        m = MeshClass(vertices, faces)\n\t        assert m.is_manifold\n\t        assert not m.is_closed\n\t        assert m.is_oriented\n\t        m.repair_holes()\n\t        assert m.is_manifold\n\t        assert m.is_closed\n", "        assert m.is_oriented\n\tdef test_non_closed_planes_1():\n\t    \"\"\"A plane is an open mesh.\"\"\"\n\t    geo = gfx.geometries.plane_geometry()\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n", "def test_non_closed_planes_2():\n\t    \"\"\"A Pygfx isohedron consists of a series of planes.\"\"\"\n\t    # Note: multiple components in these meshes.\n\t    # Note: this secretly is also a test for pygfx.\n\t    for isohedron in \"tetrahedron\", \"octahedron\", \"icosahedron\", \"dodecahedron\":\n\t        geo = getattr(gfx.geometries, f\"{isohedron}_geometry\")()\n\t        vertices = geo.positions.data\n\t        faces = geo.indices.data\n\t        m = MeshClass(vertices, faces)\n\t        assert m.is_manifold\n", "        assert not m.is_closed\n\t        assert m.is_oriented\n\t        # We can stitch the individual planes together!\n\t        m.repair_touching_boundaries(atol=1e-6)\n\t        assert m.is_manifold\n\t        assert m.is_closed\n\t        assert m.is_oriented\n\tdef test_non_closed_knot():\n\t    \"\"\"Pygfx can produce open and closed torus knots.\"\"\"\n\t    # Stitched\n", "    geo = gfx.geometries.torus_knot_geometry(stitch=True)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert m.is_oriented\n\t    # Not stitched\n\t    geo = gfx.geometries.torus_knot_geometry(stitch=False)\n\t    vertices = geo.positions.data\n", "    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\t    # Stitch the mesh back up\n\t    m.repair_touching_boundaries()\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert m.is_oriented\n", "def test_non_closed_cube():\n\t    \"\"\"Pygfx can produce a cube, but it's open.\"\"\"\n\t    for iter in range(2):\n\t        if iter == 0:\n\t            geo = gfx.geometries.box_geometry()\n\t        else:\n\t            geo = gfx.geometries.box_geometry(\n\t                width_segments=12, height_segments=12, depth_segments=12\n\t            )\n\t        vertices = geo.positions.data\n", "        faces = geo.indices.data\n\t        m = MeshClass(vertices, faces)\n\t        assert m.is_manifold\n\t        assert not m.is_closed\n\t        assert m.is_oriented\n\t        # This shape is easy to stitch into a closed manifold by deduping vertices.\n\t        m.repair_touching_boundaries()\n\t        assert m.is_manifold\n\t        assert m.is_closed\n\t        assert m.is_oriented\n", "def test_non_closed_sphere():\n\t    \"\"\"Pygfx can produce a sphere, but it's open.\"\"\"\n\t    geo = gfx.geometries.sphere_geometry(1)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\t    # We can can stitch up the top, bottom and the seam that runs from\n", "    # top to bottom, by deduping vertices. However, this introduces\n\t    # some collapsed faces, which we'll need to remove.\n\t    m.repair_touching_boundaries()\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert m.is_oriented\n\t# %% Test is_oriented\n\tdef test_non_oriented_change_winding_1():\n\t    \"\"\"Change the winding of one face.\"\"\"\n\t    for face_idx in [0, 1, 2, 11, 29, -3, -2, -1]:\n", "        for vertices, faces, is_closed in iter_test_meshes():\n\t            # For some face indices, the mesh has too little faces\n\t            face_idx = face_idx if face_idx >= 0 else len(faces) + face_idx\n\t            if face_idx >= len(faces):\n\t                continue\n\t            face = faces[face_idx]\n\t            faces[face_idx] = face[0], face[2], face[1]\n\t            m = MeshClass(vertices, faces)\n\t            assert m.is_manifold\n\t            assert m.is_closed == is_closed\n", "            assert not m.is_oriented\n\t            n_reversed = m.repair_orientation()\n\t            assert n_reversed == 1\n\t            assert m.is_manifold\n\t            assert m.is_closed == is_closed\n\t            assert m.is_oriented\n\tdef test_non_oriented_change_winding_2():\n\t    \"\"\"Change the winding of two adjacent faces.\"\"\"\n\t    for face_idx1 in [0, 1, 2, 11, 29, -3, -2, -1]:\n\t        for vertices, faces, is_closed in iter_test_meshes():\n", "            # If we reverse all faces, it will still be oriented\n\t            if len(faces) <= 2:\n\t                continue\n\t            # For some face indices, the mesh has too little faces\n\t            face_idx1 = face_idx1 if face_idx1 >= 0 else len(faces) + face_idx1\n\t            if face_idx1 >= len(faces):\n\t                continue\n\t            face1 = faces[face_idx1]\n\t            faces[face_idx1] = face1[0], face1[2], face1[1]\n\t            for face_idx2 in range(len(faces)):\n", "                if face_idx2 == face_idx1:\n\t                    continue\n\t                face2 = faces[face_idx2]\n\t                if face2[0] in face1:\n\t                    break\n\t            else:\n\t                assert False, \"WTF\"\n\t            face2 = faces[face_idx2]\n\t            faces[face_idx2] = face2[0], face2[2], face2[1]\n\t            m = MeshClass(vertices, faces)\n", "            assert m.is_manifold\n\t            assert m.is_closed == is_closed\n\t            assert not m.is_oriented\n\t            n_reversed = m.repair_orientation()\n\t            if len(faces) > 4:\n\t                assert n_reversed == 2\n\t            assert m.is_manifold\n\t            assert m.is_closed == is_closed\n\t            assert m.is_oriented\n\tdef test_non_oriented_inside_out():\n", "    for vertices, faces, _ in iter_closed_meshes():\n\t        # Turn the mesh inside-out\n\t        faces = np.asarray(faces)\n\t        tmp = faces[:, 0].copy()\n\t        faces[:, 0] = faces[:, 1]\n\t        faces[:, 1] = tmp\n\t        m = MeshClass(vertices, faces)\n\t        assert m.is_closed\n\t        assert m.get_volume() < 0\n\t        assert m.is_oriented  # still oriented ...\n", "        n_reversed = m.repair_orientation()\n\t        assert n_reversed == len(faces)  # ... but inside out\n\t        assert m.is_closed\n\t        assert m.get_volume() > 0  # now its all good!\n\t        assert m.is_oriented\n\tdef test_non_oriented_mobius():\n\t    \"\"\"A Möbius strip!\"\"\"\n\t    # This one is just a surface, really\n\t    geo = gfx.geometries.mobius_strip_geometry(stitch=False)\n\t    vertices = geo.positions.data\n", "    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\t    # This is the real deal\n\t    geo = gfx.geometries.mobius_strip_geometry(stitch=True)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n", "    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert not m.is_oriented\n\t    m.repair_orientation()\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert not m.is_oriented  # cannot repair this topology\n\tdef test_non_oriented_klein_bottle():\n\t    \"\"\"A Klein bottle!\"\"\"\n\t    # This one is just a surface, really\n", "    geo = gfx.geometries.klein_bottle_geometry(stitch=False)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\t    # This is the real deal\n\t    geo = gfx.geometries.klein_bottle_geometry(stitch=True)\n\t    vertices = geo.positions.data\n", "    faces = geo.indices.data\n\t    m = MeshClass(vertices, faces)\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert not m.is_oriented\n\t    m.repair_orientation()\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert not m.is_oriented  # cannot repair this topology\n\t# %% Test specific repairs\n", "def test_repair_touching_boundaries1():\n\t    # We don't want repairs to break anything. Achieving that requies\n\t    # a bit of work for this particular method.\n\t    # In this test we create two exact same spheres (on the same\n\t    # positions). Except one has a hole, so that the mesh is open and\n\t    # the de-dupe alg does not exit early. The spheres should not be connected.\n\t    m = MeshClass(None, None)\n\t    vertices, faces, _ = get_sphere()\n\t    m.add_mesh(vertices, faces)\n\t    faces.pop(-1)\n", "    m.add_mesh(vertices, faces)\n\t    m.repair_touching_boundaries()\n\t    assert m.is_manifold\n\t    assert m.is_oriented\n\t    assert not m.is_closed\n\t    assert m.component_count == 2\n\t    m.repair_holes()\n\t    assert m.is_manifold\n\t    assert m.is_oriented\n\t    assert m.is_closed\n", "    assert m.component_count == 2\n\tdef test_repair_touching_boundaries2():\n\t    # In this test we place 3 planes that share one edge. It's a bit similar\n\t    # for stitching up a box geometry, except the stitching would create an\n\t    # edge with 3 incident faces, which would result in a non-manifold mesh.\n\t    # The algorithm should therefore deny this change.\n\t    m = MeshClass(None, None)\n\t    # Add 3 planes - should not be stitched\n\t    vertices, faces = [], []\n\t    for i in range(3):\n", "        vertices += [(0, 0, 0), (0, 0, 1), (i, 1, 1)]\n\t        faces.append([i * 3 + 0, i * 3 + 1, i * 3 + 2])\n\t    m = MeshClass(vertices, faces)\n\t    # Add 2 planes - should be stitched\n\t    vertices, faces = [], []\n\t    for i in range(2):\n\t        vertices += [(10, 10, 10), (10, 10, 11), (10 + i, 11, 11)]\n\t        faces.append([i * 3 + 0, i * 3 + 1, i * 3 + 2])\n\t    m.add_mesh(vertices, faces)\n\t    assert m.is_manifold\n", "    assert not m.is_closed\n\t    assert m.component_count == 5\n\t    assert len(m.positions) == 3 * 3 + 2 * 3\n\t    m.repair_touching_boundaries()\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.component_count == 4\n\t    assert len(m.positions) == 3 * 3 + 2 * 3 - 2\n\tif __name__ == \"__main__\":\n\t    run_tests(globals())\n"]}
{"filename": "tests/testutils.py", "chunked_list": ["from gfxmorph import maybe_pygfx\n\timport pygfx as gfx\n\tdef run_tests(scope):\n\t    \"\"\"Run all test functions in the given scope.\"\"\"\n\t    for func in list(scope.values()):\n\t        if callable(func) and func.__name__.startswith(\"test_\"):\n\t            print(f\"Running {func.__name__} ...\")\n\t            func()\n\t    print(\"Done\")\n\tdef get_tetrahedron():\n", "    \"\"\"A closed tetrahedron as simple list objects, so we can easily add stuff to create corrupt meshes.\"\"\"\n\t    vertices = [\n\t        [-1, 0, -1 / 2**0.5],\n\t        [+1, 0, -1 / 2**0.5],\n\t        [0, -1, 1 / 2**0.5],\n\t        [0, +1, 1 / 2**0.5],\n\t    ]\n\t    faces = [\n\t        [2, 0, 1],\n\t        [0, 2, 3],\n", "        [1, 0, 3],\n\t        [2, 1, 3],\n\t    ]\n\t    return vertices, faces, True\n\tdef get_sphere():\n\t    geo = maybe_pygfx.smooth_sphere_geometry()\n\t    return geo.positions.data.tolist(), geo.indices.data.tolist(), True\n\tdef get_knot():\n\t    geo = gfx.geometries.torus_knot_geometry(\n\t        tubular_segments=16, radial_segments=5, stitch=True\n", "    )\n\t    return geo.positions.data.tolist(), geo.indices.data.tolist(), True\n\tdef get_quad():\n\t    vertices = [\n\t        [-1, -1, 0],\n\t        [+1, -1, 0],\n\t        [+1, +1, 0],\n\t        [-1, +1, 0],\n\t    ]\n\t    faces = [\n", "        [0, 2, 1],\n\t        [0, 3, 2],\n\t    ]\n\t    return vertices, faces, False\n\tdef get_fan():\n\t    vertices = [\n\t        [0, 0, 0],\n\t        [-1, -1, 0],\n\t        [+1, -1, 0],\n\t        [+1, +1, 0],\n", "        [-1, +1, 0],\n\t    ]\n\t    faces = [\n\t        [0, 2, 1],\n\t        [0, 3, 2],\n\t        [0, 4, 3],\n\t        [0, 1, 4],\n\t    ]\n\t    return vertices, faces, False\n\tdef get_strip():\n", "    # A strip of 3 triangles\n\t    vertices, faces, _ = get_fan()\n\t    faces.pop(-1)\n\t    return vertices, faces, False\n\tdef iter_fans():\n\t    \"\"\"Produce a series of fans to test stuff on.\"\"\"\n\t    # An open fan with 10 faces\n\t    open_fan = [\n\t        [0, 2, 1],\n\t        [0, 3, 2],\n", "        [0, 4, 3],\n\t        [0, 5, 4],\n\t        [0, 6, 5],\n\t        [0, 7, 6],\n\t        [0, 8, 7],\n\t        [0, 9, 8],\n\t        [0, 10, 9],\n\t        [0, 11, 10],\n\t    ]\n\t    # Open fans\n", "    for i in range(1, 11):\n\t        yield [x for x in open_fan[:i]]\n\t    # Closed fans\n\t    for i in range(2, 11):\n\t        fan = [x for x in open_fan[:i]]\n\t        fan.append([0, 1, fan[-1][1]])\n\t        yield fan\n\tdef iter_test_meshes():\n\t    yield get_tetrahedron()  # 4 vertices, 4 faces\n\t    yield get_sphere()  # 32 vertices, 60 faces\n", "    yield get_knot()  # 80 vertices, 160 faces\n\t    yield get_quad()  # 4 vertices, 2 faces\n\t    yield get_fan()  # 5 vertices, 4 faces\n\t    yield get_strip()  # 5 vertices, 3 faces\n\tdef iter_closed_meshes():\n\t    yield get_tetrahedron()  # 4 vertices, 4 faces\n\t    yield get_sphere()  # 32 vertices, 60 faces\n\t    yield get_knot()  # 80 vertices, 160 faces\n"]}
{"filename": "tests/test_basedynamicmesh.py", "chunked_list": ["import numpy as np\n\tfrom testutils import run_tests, get_sphere\n\tfrom gfxmorph import (\n\t    BaseDynamicMesh as OriDynamicMesh,\n\t    MeshLogger,\n\t    MeshChangeTracker,\n\t)\n\timport pytest\n\tclass IntendedRuntimeError(RuntimeError):\n\t    pass\n", "class CustomChangeTracker(MeshChangeTracker):\n\t    \"\"\"During these tests, we also track changes, to make sure that\n\t    the change tracking mechanism works as it should.\n\t    \"\"\"\n\t    # If MeshChangeTracker implementation raises an error it is reported\n\t    # but should not affect the mesh. This flag allows this class to produce errors\n\t    BROKEN_TRACKER = False\n\t    def init(self, mesh):\n\t        self.new_vertices_buffer(mesh)\n\t        self.new_faces_buffer(mesh)\n", "        nverts, nfaces = len(mesh.positions), len(mesh.faces)\n\t        self.positions = self.positions_buf2[:nverts]\n\t        self.normals = self.normals_buf2[:nverts]\n\t        self.faces = self.faces_buf2[:nfaces]\n\t    def new_faces_buffer(self, mesh):\n\t        self.faces_buf1 = mesh.faces.base\n\t        self.faces_buf2 = self.faces_buf1.copy()\n\t    def new_vertices_buffer(self, mesh):\n\t        self.positions_buf1 = mesh.positions.base\n\t        self.positions_buf2 = self.positions_buf1.copy()\n", "        self.normals_buf1 = mesh.normals.base\n\t        self.normals_buf2 = self.normals_buf1.copy()\n\t    def add_faces(self, faces):\n\t        new_n = len(self.faces) + len(faces)\n\t        self.faces = self.faces_buf2[:new_n]\n\t        self.faces[-len(faces) :] = faces\n\t        if self.BROKEN_TRACKER:\n\t            raise IntendedRuntimeError()\n\t    def pop_faces(self, n, old):\n\t        assert isinstance(n, int)\n", "        new_n = len(self.faces) - n\n\t        self.faces = self.faces_buf2[:new_n]\n\t        if self.BROKEN_TRACKER:\n\t            raise IntendedRuntimeError()\n\t    def swap_faces(self, indices1, indices2):\n\t        self.faces[indices1], self.faces[indices2] = (\n\t            self.faces[indices2],\n\t            self.faces[indices1],\n\t        )\n\t    def update_faces(self, indices, faces, old):\n", "        assert isinstance(indices, np.ndarray)\n\t        self.faces[indices] = faces\n\t        if self.BROKEN_TRACKER:\n\t            raise IntendedRuntimeError()\n\t    def add_vertices(self, positions):\n\t        old_n = len(self.positions)\n\t        new_n = old_n + len(positions)\n\t        self.positions = self.positions_buf2[:new_n]\n\t        self.normals = self.normals_buf2[:new_n]\n\t        self.positions[old_n:] = positions\n", "        self.normals[old_n:] = self.normals_buf1[old_n:new_n]\n\t        if self.BROKEN_TRACKER:\n\t            raise IntendedRuntimeError()\n\t    def pop_vertices(self, n, old):\n\t        assert isinstance(n, int)\n\t        new_len = len(self.positions) - n\n\t        self.positions = self.positions_buf2[:new_len]\n\t        self.normals = self.normals_buf2[:new_len]\n\t        if self.BROKEN_TRACKER:\n\t            raise IntendedRuntimeError()\n", "    def swap_vertices(self, indices1, indices2):\n\t        self.positions[indices1], self.positions[indices2] = (\n\t            self.positions[indices2],\n\t            self.positions[indices1],\n\t        )\n\t        self.normals[indices1], self.normals[indices2] = (\n\t            self.normals[indices2],\n\t            self.normals[indices1],\n\t        )\n\t    def update_vertices(self, indices, positions, old):\n", "        assert isinstance(indices, np.ndarray)\n\t        self.positions[indices] = positions\n\t        if self.BROKEN_TRACKER:\n\t            raise IntendedRuntimeError()\n\t    def update_normals(self, indices):\n\t        assert isinstance(indices, np.ndarray)\n\t        self.normals[indices] = self.normals_buf1[indices]\n\t        if self.BROKEN_TRACKER:\n\t            raise IntendedRuntimeError()\n\tclass ReplicatingMesh(OriDynamicMesh, MeshChangeTracker):\n", "    \"\"\"Since the API's of the change tracker matches that of the core\n\t    changes-api of the BaseDynamicMesh, this is all you need to\n\t    replicate a mesh. That in itself is a silly arguement (because when\n\t    would you want to replicate a mesh?) but it does look elegant.\n\t    \"\"\"\n\t    pass\n\tclass DynamicMesh(OriDynamicMesh):\n\t    \"\"\"A custom mesh subclass that has debug mode on, so that the\n\t    internal state is validated at each change. Plus we track changes\n\t    and check them at each step too.\"\"\"\n", "    def __init__(self):\n\t        super().__init__()\n\t        # Add a simple replicating tracker, to test that the overlapping API does proper replications\n\t        self.tracker1 = ReplicatingMesh()\n\t        self.track_changes(self.tracker1)\n\t        # A custom change tracker that replicates the data via the buffers.\n\t        self.tracker2 = CustomChangeTracker()\n\t        self.track_changes(self.tracker2)\n\t        # Installing the abstract class does nothing, but this way we\n\t        # check that the API of the base class is complete and compatible.\n", "        self.tracker3 = MeshChangeTracker()\n\t        self.track_changes(self.tracker3)\n\t    def _after_change(self):\n\t        self.check_internal_state()\n\t        if self.tracker1:\n\t            assert np.all(self.faces == self.tracker1.faces)\n\t            assert np.all(self.positions == self.tracker1.positions)\n\t            assert np.all(self.normals == self.tracker1.normals)\n\t        if not self.tracker2.BROKEN_TRACKER:\n\t            assert np.all(self.faces == self.tracker2.faces)\n", "            assert np.all(self.positions == self.tracker2.positions)\n\t            assert np.all(self.normals == self.tracker2.normals)\n\tdef check_mesh(m, nverts, nfaces):\n\t    assert isinstance(m.positions, np.ndarray)\n\t    assert m.positions.flags.c_contiguous\n\t    assert m.positions.dtype == np.float32 and m.positions.shape == (nverts, 3)\n\t    assert isinstance(m.faces, np.ndarray)\n\t    assert m.faces.flags.c_contiguous\n\t    assert m.faces.dtype == np.int32 and m.faces.shape == (nfaces, 3)\n\tdef test_dynamicmesh_init():\n", "    vertices, faces, _ = get_sphere()\n\t    # Create a new (empty) mesh\n\t    m = DynamicMesh()\n\t    check_mesh(m, 0, 0)\n\t    # Add data\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    check_mesh(m, len(vertices), len(faces))\n\t    # Add another mesh\n\t    m.add_vertices(vertices)\n", "    m.add_faces(faces)\n\t    check_mesh(m, len(vertices) * 2, len(faces) * 2)\n\tdef test_dynamicmesh_broken_tracker():\n\t    vertices, faces, _ = get_sphere()\n\t    # Create a new (empty) mesh\n\t    m = DynamicMesh()\n\t    # Make the tracker raise errors\n\t    m.tracker2.BROKEN_TRACKER = True\n\t    # And why not add a logger too!\n\t    logger = MeshLogger(print)\n", "    m.track_changes(logger)\n\t    check_mesh(m, 0, 0)\n\t    # Add data\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    check_mesh(m, len(vertices), len(faces))\n\t    # Add another mesh\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    # Update some verts and faces\n", "    m.update_vertices([0, 1], m.positions[[0, 1]] * 1.1)\n\t    m.update_faces([10, 11], m.faces[[0, 1]])\n\t    check_mesh(m, len(vertices) * 2, len(faces) * 2)\n\t    # Remove the second mesh again\n\t    m.delete_faces(np.arange(len(faces), 2 * len(faces)))\n\t    m.delete_vertices(np.arange(len(vertices), 2 * len(vertices)))\n\t    check_mesh(m, len(vertices), len(faces))\n\tdef test_dynamicmesh_tracker_mechanics():\n\t    # Create a new (empty) mesh\n\t    m = DynamicMesh()\n", "    # Trackers must inherit from MeshChangeTracker\n\t    with pytest.raises(TypeError):\n\t        m.track_changes(list())\n\t    class Tracker(MeshChangeTracker):\n\t        def __init__(self):\n\t            self.count = 0\n\t            self.nvertices = 0\n\t        def init(self, mesh):\n\t            self.nvertices = len(mesh.positions)\n\t        def add_vertices(self, indices):\n", "            self.count += 1\n\t            self.nvertices += len(indices)\n\t        def pop_vertices(self, n):\n\t            self.nvertices -= n\n\t    t1 = Tracker()\n\t    t2 = Tracker()\n\t    # Add t1\n\t    m.track_changes(t1)\n\t    m.add_vertices([(1, 1, 1)])\n\t    m.add_vertices([(1, 1, 1)])\n", "    assert t1.count == 2\n\t    assert t2.count == 0\n\t    assert t1.nvertices == 2\n\t    assert t2.nvertices == 0\n\t    # Also add t2\n\t    m.track_changes(t2)\n\t    m.add_vertices([(2, 2, 2), (2, 2, 2)])\n\t    assert t1.count == 3\n\t    assert t2.count == 1\n\t    assert t1.nvertices == 4\n", "    assert t2.nvertices == 4\n\t    # Remove t1, so only tracking with t2\n\t    m.track_changes(t1, remove=True)\n\t    m.add_vertices([(3, 3, 3), (3, 3, 3)])\n\t    assert t1.count == 3\n\t    assert t2.count == 2\n\t    assert t1.nvertices == 4\n\t    assert t2.nvertices == 6\n\t    # Adding t1, twice (should not track twice as hard)\n\t    m.track_changes(t1)\n", "    m.track_changes(t1)\n\t    m.add_vertices([(4, 4, 4), (4, 4, 4)])\n\t    assert t1.count == 4\n\t    assert t2.count == 3\n\t    assert t1.nvertices == 8\n\t    assert t2.nvertices == 8\n\t    # Remove both trackers\n\t    m.track_changes(t1, remove=True)\n\t    m.track_changes(t2, remove=True)\n\t    m.add_vertices([(5, 5, 5), (5, 5, 5)])\n", "    assert t1.count == 4\n\t    assert t2.count == 3\n\t    assert t1.nvertices == 8\n\t    assert t2.nvertices == 8\n\tdef test_dynamicmesh_reset():\n\t    vertices, faces, _ = get_sphere()\n\t    # Create a new (empty) mesh\n\t    m = DynamicMesh()\n\t    # Init using reset\n\t    m.reset(vertices, faces)\n", "    check_mesh(m, len(vertices), len(faces))\n\t    # Modify\n\t    m.delete_faces([1, 2, 3])\n\t    m.add_vertices([(0, 0, 0), (1, 1, 1)])\n\t    # Make a snapshot\n\t    vertices2 = m.positions.copy()\n\t    faces2 = m.faces.copy()\n\t    # Clear\n\t    m.clear()\n\t    check_mesh(m, 0, 0)\n", "    # Restore snapshot\n\t    m.reset(vertices2, faces2)\n\t    check_mesh(m, len(vertices2), len(faces2))\n\tdef test_dynamicmesh_readonly():\n\t    vertices, faces, _ = get_sphere()\n\t    m = DynamicMesh()\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    with pytest.raises(ValueError):\n\t        m.faces[0] = (0, 0, 0)\n", "    with pytest.raises(ValueError):\n\t        m.positions[0] = (0, 0, 0)\n\t    with pytest.raises(ValueError):\n\t        m.normals[0] = (0, 0, 0)\n\tdef test_dynamicmesh_verts_before_faces():\n\t    vertices, faces, _ = get_sphere()\n\t    # Cannot load faces before vertices\n\t    m = DynamicMesh()\n\t    with pytest.raises(ValueError):\n\t        m.add_faces(faces)\n", "    # Vertices first!\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    # Cannot remove vertices before faces\n\t    with pytest.raises(ValueError):\n\t        m.delete_vertices(list(range(len(vertices))))\n\t    # Faces first!\n\t    m.delete_faces(list(range(len(faces))))\n\t    m.delete_vertices(list(range(len(vertices))))\n\tdef test_dynamicmesh_add_and_delete_faces():\n", "    # Deleting faces can change the order of other faces due to the\n\t    # defragmentation process.\n\t    vertices = [[i, i, i] for i in range(9)]\n\t    faces = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n\t    m = DynamicMesh()\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    check_mesh(m, 9, 3)\n\t    assert [tuple(x) for x in m.faces] == [(0, 1, 2), (3, 4, 5), (6, 7, 8)]\n\t    # Fail add\n", "    with pytest.raises(ValueError):\n\t        m.add_faces([1, 2, 3, 4])  # Must be (castable to) Nx3\n\t    with pytest.raises(ValueError):\n\t        m.add_faces([(0, -1, 2)])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.add_faces([(0, 999, 2)])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.add_faces(np.zeros((0, 3), np.int32))  # Cannot add zero faces\n\t    # Fail delete\n\t    with pytest.raises(TypeError):\n", "        m.delete_faces({1, 2, 3})  # Need list or ndarray\n\t    with pytest.raises(ValueError):\n\t        m.delete_faces([0, -1])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.delete_faces([0, 999])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.delete_faces([])  # Cannot be empty\n\t    with pytest.raises(ValueError):\n\t        m.delete_faces(np.array([], np.int32))  # Cannot be empty\n\t    # Fail pop\n", "    with pytest.raises(ValueError):\n\t        m.pop_faces(-1)  # Must be positive\n\t    with pytest.raises(ValueError):\n\t        m.pop_faces(0)  # and nonzero\n\t    with pytest.raises(ValueError):\n\t        m.pop_faces(999)  # and within bounds\n\t    # Fail swap\n\t    with pytest.raises(ValueError):\n\t        m.swap_faces([0, 1], [2])  # Unequal lengths\n\t    with pytest.raises(ValueError):\n", "        m.swap_faces([0], [1, 2])  # Unequal lengths\n\t    # Should still be the same (or atomicity would be broken)\n\t    assert [tuple(x) for x in m.faces] == [(0, 1, 2), (3, 4, 5), (6, 7, 8)]\n\t    # 0\n\t    m.delete_faces([0])\n\t    assert [tuple(x) for x in m.faces] == [(6, 7, 8), (3, 4, 5)]\n\t    m.add_faces([(0, 1, 2)])\n\t    assert [tuple(x) for x in m.faces] == [(6, 7, 8), (3, 4, 5), (0, 1, 2)]\n\t    # 1\n\t    m.delete_faces([1, 1, 1, 1])  # duplicates should not matter\n", "    assert [tuple(x) for x in m.faces] == [(6, 7, 8), (0, 1, 2)]\n\t    m.add_faces([(3, 4, 5)])\n\t    assert [tuple(x) for x in m.faces] == [(6, 7, 8), (0, 1, 2), (3, 4, 5)]\n\t    # 2\n\t    m.delete_faces(2)  # int is allowed\n\t    assert [tuple(x) for x in m.faces] == [(6, 7, 8), (0, 1, 2)]\n\t    m.add_faces([(3, 4, 5)])\n\t    assert [tuple(x) for x in m.faces] == [(6, 7, 8), (0, 1, 2), (3, 4, 5)]\n\t    # all\n\t    m.delete_faces([2, 0, 1])\n", "    assert [tuple(x) for x in m.faces] == []\n\tdef test_dynamicmesh_update_faces():\n\t    vertices = [[i, i, i] for i in range(12)]\n\t    faces = [[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3]]\n\t    m = DynamicMesh()\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    check_mesh(m, 12, 4)\n\t    m.update_faces([1, 3], [(7, 7, 7), (8, 8, 8)])\n\t    assert [tuple(x) for x in m.faces] == [(0, 0, 0), (7, 7, 7), (2, 2, 2), (8, 8, 8)]\n", "    # Fail matching indices and faces\n\t    with pytest.raises(ValueError):\n\t        m.update_faces([1, 3, 4], [(0, 0, 0), (0, -1, 2)])  # Unequal lengths\n\t    with pytest.raises(ValueError):\n\t        m.update_faces([1], [(0, 0, 0), (0, -1, 2)])  # Unequal lengths\n\t    # Fail indices\n\t    with pytest.raises(ValueError):\n\t        m.update_faces([-1, 0], [(7, 7, 7), (8, 8, 8)])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.update_faces([0, 99], [(7, 7, 7), (8, 8, 8)])  # Out of bounds\n", "    # Fail faces\n\t    with pytest.raises(ValueError):\n\t        m.update_faces([1, 3], [(0, 0, 0), (0, -1, 2)])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.update_faces([1, 3], [(0, 0, 0), (0, 999, 2)])  # Out of bounds\n\tdef test_dynamicmesh_update_vertices():\n\t    vertices = [[i, i, i] for i in range(10)]\n\t    m = DynamicMesh()\n\t    m.add_vertices(vertices)\n\t    check_mesh(m, 10, 0)\n", "    assert [x[0] for x in m.positions] == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\t    m.update_vertices([1, 3], [(7, 7, 7), (8, 8, 8)])\n\t    assert [x[0] for x in m.positions] == [0, 7, 2, 8, 4, 5, 6, 7, 8, 9]\n\t    # Fail matching indices and faces\n\t    with pytest.raises(ValueError):\n\t        m.update_vertices([1, 3, 4], [(0, 0, 0), (0, -1, 2)])  # Unequal lengths\n\t    with pytest.raises(ValueError):\n\t        m.update_vertices([1], [(0, 0, 0), (0, -1, 2)])  # Unequal lengths\n\t    # Fail indices\n\t    with pytest.raises(ValueError):\n", "        m.update_vertices([-1, 0], [(7, 7, 7), (8, 8, 8)])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.update_vertices([0, 99], [(7, 7, 7), (8, 8, 8)])  # Out of bounds\n\tdef test_dynamicmesh_add_and_delete_verts():\n\t    vertices = [[i, i, i] for i in range(10)]\n\t    faces = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n\t    m = DynamicMesh()\n\t    m.add_vertices(vertices)\n\t    m.add_faces(faces)\n\t    check_mesh(m, 10, 3)\n", "    assert [x[0] for x in m.positions] == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\t    # Fail add\n\t    with pytest.raises(ValueError):\n\t        m.add_vertices([1, 2, 3, 4])  # Must be (castable to) Nx3\n\t    with pytest.raises(ValueError):\n\t        m.add_vertices(np.zeros((0, 3), np.float32))  # Cannot add zero verts\n\t    # Fail delete\n\t    with pytest.raises(TypeError):\n\t        m.delete_vertices({1, 2, 3})  # Need list or ndarray\n\t    with pytest.raises(ValueError):\n", "        m.delete_vertices([0, -1])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.delete_vertices([0, 999])  # Out of bounds\n\t    with pytest.raises(ValueError):\n\t        m.delete_vertices([])  # Cannot be empty\n\t    with pytest.raises(ValueError):\n\t        m.delete_vertices(np.array([], np.float32))  # Cannot be empty\n\t    # Fail pop\n\t    with pytest.raises(ValueError):\n\t        m.pop_vertices(-1)  # Must be positive\n", "    with pytest.raises(ValueError):\n\t        m.pop_vertices(0)  # and nonzero\n\t    with pytest.raises(ValueError):\n\t        m.pop_vertices(999)  # and within bounds\n\t    # Fail swap\n\t    with pytest.raises(ValueError):\n\t        m.swap_vertices([1, 2, 3], [4, 5])  # Unequal lengths\n\t    with pytest.raises(ValueError):\n\t        m.swap_vertices([1, 2], [4, 5, 6])  # Unequal lengths\n\t    # Should still be the same (or atomicity would be broken)\n", "    assert [x[0] for x in m.positions] == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\t    # Delete unused\n\t    m.delete_vertices([9])\n\t    assert [x[0] for x in m.positions] == [0, 1, 2, 3, 4, 5, 6, 7, 8]\n\t    # Cannot delete vertex that is in use\n\t    with pytest.raises(ValueError):\n\t        m.delete_vertices([0])\n\t    with pytest.raises(ValueError):\n\t        m.delete_vertices([8])\n\t    with pytest.raises(ValueError):\n", "        m.pop_vertices(3)\n\t    m.delete_faces([0, 1, 2])\n\t    m.delete_vertices(8)\n\t    assert [x[0] for x in m.positions] == [0, 1, 2, 3, 4, 5, 6, 7]\n\t    m.delete_vertices([2, 3])\n\t    assert [x[0] for x in m.positions] == [0, 1, 6, 7, 4, 5]\n\t    m.delete_vertices([0, 1, 2, 3, 4])\n\t    assert [x[0] for x in m.positions] == [5]\n\tdef test_dynamicmesh_alloc_and_dealloc_vertices():\n\t    m = DynamicMesh()\n", "    # Put in a few vertices\n\t    for i in range(8):\n\t        m.add_vertices([(i, i, i)])\n\t    assert len(m.positions) == 8\n\t    assert len(m._positions_buf) == 8\n\t    # It uses factors of 2\n\t    m.add_vertices([(0, 0, 0)])\n\t    assert len(m.positions) == 9\n\t    assert len(m._positions_buf) == 16\n\t    # Another round\n", "    for i in range(8):\n\t        m.add_vertices([(0, 0, 0)])\n\t    assert len(m.positions) == 17\n\t    assert len(m._positions_buf) == 32\n\t    # Fill it all the way up ...\n\t    for i in range(15):\n\t        m.add_vertices([(0, 0, 0)])\n\t    assert len(m.positions) == 32\n\t    assert len(m._positions_buf) == 32\n\t    # Now it re-allocates\n", "    m.add_vertices([(0, 0, 0)])\n\t    assert len(m.positions) == 33\n\t    assert len(m._positions_buf) == 64\n\t    # When deleting one vertex, shrinking the buffer back to 32 makes\n\t    # sense from a memory pov, but if we add/remove vertices around\n\t    # such a point, it's a waste of time, so we apply a hysteresis\n\t    # threshold.\n\t    m.delete_vertices(32)\n\t    assert len(m.positions) == 32\n\t    assert len(m._positions_buf) == 64\n", "    # All the way down to 1/4 th of the total size\n\t    m.delete_vertices(list(range(17, 32)))\n\t    assert len(m.positions) == 17\n\t    assert len(m._positions_buf) == 64\n\t    # Bumping one more will re-allocate, still leaving 2x the size\n\t    m.delete_vertices([16])\n\t    assert len(m.positions) == 16\n\t    assert len(m._positions_buf) == 32\n\t    # Again...\n\t    m.delete_vertices(list(range(9, 16)))\n", "    assert len(m.positions) == 9\n\t    assert len(m._positions_buf) == 32\n\t    # Bump\n\t    m.delete_vertices([8])\n\t    assert len(m.positions) == 8\n\t    assert len(m._positions_buf) == 16\n\t    # Check if the original values survived\n\t    for i in range(8):\n\t        assert m.positions[i].tolist() == [i, i, i]\n\tdef test_dynamicmesh_alloc_and_dealloc_faces():\n", "    m = DynamicMesh()\n\t    # Add some vertices to reference in the faces\n\t    m.add_vertices([(0, 0, 0) for i in range(100)])\n\t    # Put in a few faces\n\t    for i in range(8):\n\t        m.add_faces([(i, i, i)])\n\t    assert len(m.faces) == 8\n\t    assert len(m._faces_buf) == 8\n\t    # It uses factors of 2\n\t    m.add_faces([(0, 0, 0)])\n", "    assert len(m.faces) == 9\n\t    assert len(m._faces_buf) == 16\n\t    # Another round\n\t    for i in range(8):\n\t        m.add_faces([(0, 0, 0)])\n\t    assert len(m.faces) == 17\n\t    assert len(m._faces_buf) == 32\n\t    # Fill it all the way up ...\n\t    for i in range(15):\n\t        m.add_faces([(0, 0, 0)])\n", "    assert len(m.faces) == 32\n\t    assert len(m._faces_buf) == 32\n\t    # Now it re-allocates\n\t    m.add_faces([(0, 0, 0)])\n\t    assert len(m.faces) == 33\n\t    assert len(m._faces_buf) == 64\n\t    # When deleting one face, shrinking the buffer back to 32 makes\n\t    # sense from a memory pov, but if we add/remove faces around\n\t    # such a point, it's a waste of time, so we apply a hysteresis\n\t    # threshold.\n", "    m.delete_faces([32])\n\t    assert len(m.faces) == 32\n\t    assert len(m._faces_buf) == 64\n\t    # All the way down to 1/4 th of the total size\n\t    m.delete_faces(list(range(17, 32)))\n\t    assert len(m.faces) == 17\n\t    assert len(m._faces_buf) == 64\n\t    # Bumping one more will re-allocate, still leaving 2x the size\n\t    m.delete_faces([16])\n\t    assert len(m.faces) == 16\n", "    assert len(m._faces_buf) == 32\n\t    # Again...\n\t    m.delete_faces(list(range(9, 16)))\n\t    assert len(m.faces) == 9\n\t    assert len(m._faces_buf) == 32\n\t    # Bump\n\t    m.delete_faces([8])\n\t    assert len(m.faces) == 8\n\t    assert len(m._faces_buf) == 16\n\t    # Check if the original values survived\n", "    for i in range(8):\n\t        assert m.faces[i].tolist() == [i, i, i]\n\tif __name__ == \"__main__\":\n\t    test_dynamicmesh_alloc_and_dealloc_faces()\n\t    run_tests(globals())\n"]}
{"filename": "tests/test_undo.py", "chunked_list": ["import random\n\timport numpy as np\n\timport pygfx as gfx\n\tfrom gfxmorph import DynamicMesh, MeshUndoTracker\n\tfrom testutils import run_tests\n\timport pytest\n\tdef test_undo_single_changes():\n\t    m = DynamicMesh(None, None)\n\t    undo = MeshUndoTracker()\n\t    m.track_changes(undo)\n", "    # Three actions\n\t    with undo:\n\t        m.add_vertices([[0, 0, 0]])\n\t    with undo:\n\t        m.add_vertices([[0, 0, 0]])\n\t    with undo:\n\t        m.add_vertices([[0, 0, 0]])\n\t    # Undo\n\t    assert len(m.positions) == 3\n\t    undo.undo(m)\n", "    assert len(m.positions) == 2\n\t    undo.undo(m)\n\t    assert len(m.positions) == 1\n\t    undo.undo(m)\n\t    assert len(m.positions) == 0\n\t    # Further undo does nothing\n\t    undo.undo(m)\n\t    assert len(m.positions) == 0\n\t    # Redo\n\t    undo.redo(m)\n", "    assert len(m.positions) == 1\n\t    undo.redo(m)\n\t    undo.redo(m)\n\t    assert len(m.positions) == 3\n\t    # Further redo does nothing\n\t    undo.redo(m)\n\t    assert len(m.positions) == 3\n\t    # Clean up\n\t    undo.undo(m)\n\t    undo.undo(m)\n", "    undo.undo(m)\n\t    assert len(m.positions) == 0\n\tdef test_undo_with_context():\n\t    m = DynamicMesh(None, None)\n\t    undo = MeshUndoTracker()\n\t    m.track_changes(undo)\n\t    # Three actions resulting in one undo\n\t    with undo:\n\t        m.add_vertices([[0, 0, 0]])\n\t        m.add_vertices([[0, 0, 0]])\n", "        m.add_vertices([[0, 0, 0]])\n\t    # Undo / redo\n\t    assert len(m.positions) == 3\n\t    undo.undo(m)\n\t    assert len(m.positions) == 0\n\t    undo.undo(m)\n\t    assert len(m.positions) == 0\n\t    undo.redo(m)\n\t    assert len(m.positions) == 3\n\t    undo.redo(m)\n", "    assert len(m.positions) == 3\n\t    undo.undo(m)\n\t    assert len(m.positions) == 0\n\t    # Can be stacked ...\n\t    with undo:\n\t        m.add_vertices([[0, 0, 0]])\n\t        with undo:\n\t            m.add_vertices([[0, 0, 0]])\n\t            m.add_vertices([[0, 0, 0]])\n\t            undo.commit()  # <--  See a commit here\n", "    # ... but ignores anything but the top level, including (accidental) commits\n\t    assert len(m.positions) == 3\n\t    undo.undo(m)\n\t    assert len(m.positions) == 0\n\t    undo.redo(m)\n\t    assert len(m.positions) == 3\n\t    # Cannot undo under a context\n\t    with pytest.raises(RuntimeError):\n\t        with undo:\n\t            undo.undo(m)\n", "    undo.undo(m)\n\t    # Neither can redo\n\t    with pytest.raises(RuntimeError):\n\t        with undo:\n\t            undo.redo(m)\n\tdef test_undo_cancel():\n\t    m = DynamicMesh(None, None)\n\t    undo = MeshUndoTracker()\n\t    m.track_changes(undo)\n\t    # Commit 2 actions\n", "    m.add_vertices([[0, 0, 0]])\n\t    m.add_vertices([[0, 0, 0]])\n\t    v = undo.commit()\n\t    assert v == 1\n\t    assert undo.get_version() == 1\n\t    assert not undo.has_pending_changes()\n\t    # Make an action, no commit\n\t    m.add_vertices([[0, 0, 0]])\n\t    assert undo.get_version() == 1\n\t    assert undo.has_pending_changes()\n", "    # Can cancel\n\t    undo.cancel(m)\n\t    assert undo.get_version() == 1\n\t    assert not undo.has_pending_changes()\n\t    # Undo discarts pending changes\n\t    m.add_vertices([[0, 0, 0]])\n\t    undo.undo(m)\n\t    assert undo.get_version() == 0\n\t    assert not undo.has_pending_changes()\n\t    # Redo does too\n", "    m.add_vertices([[0, 0, 0]])\n\t    undo.redo(m)\n\t    assert undo.get_version() == 1\n\t    assert not undo.has_pending_changes()\n\tdef test_undo_repairs():\n\t    snapshots = []\n\t    def snapshot():\n\t        undo.commit()\n\t        vertices, faces = m.export()\n\t        v = undo.get_version()\n", "        snapshots.append((v, vertices, faces))\n\t    geo = gfx.geometries.torus_knot_geometry(stitch=False)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    m = DynamicMesh(None, None)\n\t    undo = MeshUndoTracker()\n\t    m.track_changes(undo)\n\t    snapshot()\n\t    m.add_mesh(vertices, faces)\n\t    snapshot()\n", "    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\t    # Stitch the mesh back up\n\t    m.repair_touching_boundaries()\n\t    snapshot()\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert m.is_oriented\n\t    # Create some holes\n", "    m.delete_faces([1, 123, 250, 312])\n\t    snapshot()\n\t    assert m.is_manifold\n\t    assert not m.is_closed\n\t    assert m.is_oriented\n\t    # Close the holes\n\t    m.repair(True)\n\t    snapshot()\n\t    assert m.is_manifold\n\t    assert m.is_closed\n", "    assert m.is_oriented\n\t    # Also move some vertices\n\t    ii = np.arange(10, dtype=np.int32)\n\t    m.update_vertices(ii, m.positions[ii] * 1.1)\n\t    snapshot()\n\t    assert m.is_manifold\n\t    assert m.is_closed\n\t    assert m.is_oriented\n\t    # Now backtrack all the way to the empty map\n\t    assert len(m.faces) > 0\n", "    for v, vertices, faces in reversed(snapshots):\n\t        undo.apply_version(m, v)\n\t        assert np.all(m.positions == vertices)\n\t        assert np.all(m.faces == faces)\n\t    assert len(m.faces) == 0\n\t    # And redo all the steps!\n\t    for v, vertices, faces in snapshots:\n\t        undo.apply_version(m, v)\n\t        assert np.all(m.positions == vertices)\n\t        assert np.all(m.faces == faces)\n", "    assert len(m.faces) > 0\n\t    # The order can be anything!\n\t    shuffled_snapshots = snapshots.copy()\n\t    random.shuffle(shuffled_snapshots)\n\t    assert [x[0] for x in shuffled_snapshots] != [x[0] for x in snapshots]\n\t    for v, vertices, faces in shuffled_snapshots:\n\t        undo.apply_version(m, v)\n\t        assert np.all(m.positions == vertices)\n\t        assert np.all(m.faces == faces)\n\t    # We can also do a step by step by step undo\n", "    for i in range(20):\n\t        undo.undo(m)\n\t    assert np.all(m.positions == snapshots[0][1])\n\t    assert np.all(m.faces == snapshots[0][2])\n\t    for i in range(20):\n\t        undo.redo(m)\n\t    assert np.all(m.positions == snapshots[-1][1])\n\t    assert np.all(m.faces == snapshots[-1][2])\n\tdef test_undo_repeated_vertex_updates():\n\t    m = DynamicMesh(None, None)\n", "    undo = MeshUndoTracker()\n\t    m.track_changes(undo)\n\t    # Add some vertices\n\t    m.add_vertices([[1, 1, 1] for i in range(10)])\n\t    v = undo.commit()\n\t    assert v == 1\n\t    # Update a bunch of vertices. This is a common case when making\n\t    # interactive modifications to a mesh, e.g. displacing (part of) a mesh.\n\t    indices = np.array([0, 2, 3], np.int32)\n\t    positions = m.positions[indices]\n", "    for i in range(20):\n\t        m.update_vertices(indices, positions * i)\n\t    v = undo.commit()\n\t    assert v == 2\n\t    # Check that the above resulted in a single undo-step!\n\t    steps = undo._undo[-1]\n\t    step = steps[0]\n\t    assert isinstance(steps, list) and len(steps) == 1\n\t    assert step[0] == \"update_vertices\"\n\t    assert np.all(step[1] == indices)\n", "    # Check the mesh\n\t    assert np.all(\n\t        m.positions[:4] == [[19, 19, 19], [1, 1, 1], [19, 19, 19], [19, 19, 19]]\n\t    )\n\t    # And undo\n\t    undo.undo(m)\n\t    assert np.all(m.positions[:4] == [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]])\n\t    # Now do it again, but use a list for indices.\n\t    # The reason is an implementation detail ...\n\t    indices = [0, 2, 3]\n", "    positions = m.positions[indices]\n\t    for i in range(20):\n\t        m.update_vertices(indices, positions * i)\n\t    v = undo.commit()\n\t    assert v == 2\n\t    # Check the mesh\n\t    assert np.all(\n\t        m.positions[:4] == [[19, 19, 19], [1, 1, 1], [19, 19, 19], [19, 19, 19]]\n\t    )\n\t    # And undo\n", "    undo.undo(m)\n\t    assert np.all(m.positions[:4] == [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]])\n\tif __name__ == \"__main__\":\n\t    run_tests(globals())\n"]}
{"filename": "tests/test_meshfuncs.py", "chunked_list": ["\"\"\"\n\tWe cover most mesh funcs via e.g. test_corrupt.py.\n\tHere we have a few more tests to test some functions more directly.\n\t\"\"\"\n\tfrom gfxmorph import meshfuncs\n\tfrom testutils import run_tests, iter_fans, get_sphere\n\tdef test_face_get_neighbours():\n\t    faces = [(0, 1, 2), (0, 2, 3), (0, 4, 5), (6, 7, 8)]\n\t    vertex2faces = meshfuncs.make_vertex2faces(faces)\n\t    # Check face groups for vertex 0\n", "    res = meshfuncs.vertex_get_incident_face_groups(faces, vertex2faces, 0)\n\t    assert res == [[0, 1], [2]]\n\t    # Neighbours via both edges and vertices\n\t    n1 = meshfuncs.face_get_neighbours1(faces, vertex2faces, 0)\n\t    assert n1 == {1, 2}\n\t    # Get both\n\t    n1, n2 = meshfuncs.face_get_neighbours2(faces, vertex2faces, 0)\n\t    assert n1 == {1, 2}\n\t    assert n2 == {1}\n\tdef test_mesh_boundaries():\n", "    # An empty mesg has no boundaries (but should not fail)\n\t    assert meshfuncs.mesh_get_boundaries([]) == []\n\t    # Test boundaries on a bunch of fans\n\t    for faces in iter_fans():\n\t        is_closed = len(faces) >= 3 and faces[-1][1] == 1\n\t        boundaries = meshfuncs.mesh_get_boundaries(faces)\n\t        assert len(boundaries) == 1\n\t        boundary = boundaries[0]\n\t        nr_vertices_on_boundary = 3 * len(faces) - 2 * (len(faces) - 1)\n\t        if is_closed:\n", "            nr_vertices_on_boundary -= 2\n\t        assert len(boundary) == nr_vertices_on_boundary\n\t    # Next we'll work with a sphere. We create two holes in the sphere,\n\t    # with increasing size. The primary faces to remove should be far\n\t    # away from each-other, so that when we create larger holes, the\n\t    # hole's won't touch, otherwise the mesh becomes non-manifold.\n\t    _, faces_original, _ = get_sphere()\n\t    vertex2faces = meshfuncs.make_vertex2faces(faces_original)\n\t    for n_faces_to_remove_per_hole in [1, 2, 3, 4]:\n\t        faces = [face for face in faces_original]\n", "        faces2pop = []\n\t        for fi in (2, 30):\n\t            faces2pop.append(fi)\n\t            _, fii = meshfuncs.face_get_neighbours2(faces, vertex2faces, fi)\n\t            for _ in range(n_faces_to_remove_per_hole - 1):\n\t                faces2pop.append(fii.pop())\n\t        assert len(faces2pop) == len(set(faces2pop))  # no overlap between holes\n\t        for fi in reversed(sorted(faces2pop)):\n\t            faces.pop(fi)\n\t        boundaries = meshfuncs.mesh_get_boundaries(faces)\n", "        nr_vertices_on_boundary = [0, 3, 4, 5, 6, 7][n_faces_to_remove_per_hole]\n\t        assert len(boundaries) == 2\n\t        assert len(boundaries[0]) == nr_vertices_on_boundary\n\t        assert len(boundaries[1]) == nr_vertices_on_boundary\n\tdef test_mesh_get_component_labels():\n\t    faces = [(0, 1, 2), (0, 2, 3), (0, 4, 5), (6, 7, 8)]\n\t    vertex2faces = meshfuncs.make_vertex2faces(faces)\n\t    # Connected via edges\n\t    labels = meshfuncs.mesh_get_component_labels(faces, vertex2faces)\n\t    assert labels.tolist() == [0, 0, 1, 2]\n", "    # Connected via faces\n\t    labels = meshfuncs.mesh_get_component_labels(\n\t        faces, vertex2faces, via_edges_only=False\n\t    )\n\t    assert labels.tolist() == [0, 0, 0, 1]\n\tdef test_mesh_stitch_boundaries():\n\t    vertices = [\n\t        # triangle 1\n\t        (0.0, 0.0, 0.0),\n\t        (0.0, 1.0, 0.0),\n", "        (0.0, 2.0, 0.0),\n\t        # triangle 2\n\t        (0.0, 0.0, 0.0),\n\t        (0.0, 2.0, 0.0),\n\t        (0.0, 3.0, 0.0),\n\t        # triangle 3\n\t        (0.0, 0.0, 1.0),\n\t        (0.0, 1.0, 1.0),\n\t        (0.0, 2.0, 1.0),\n\t        # triangle 4\n", "        (0.0, 0.0, 1.0),\n\t        (0.0, 2.0001, 1.0),\n\t        (0.0, 3.0, 1.0),\n\t    ]\n\t    faces = [(0, 1, 2), (3, 4, 5), (6, 7, 8), (9, 10, 11)]\n\t    # Stitch without tolerance -> 3 components.\n\t    # Note that the last two triangles are not attached at all. Even\n\t    # though the (0.0, 0.0, 1.0) is a match, stitching only that vertex\n\t    # would make the mesh non-manifold, so its not done.\n\t    faces2 = meshfuncs.mesh_stitch_boundaries(vertices, faces, atol=0)\n", "    assert faces2.tolist() == [[0, 1, 2], [0, 2, 5], [6, 7, 8], [9, 10, 11]]\n\t    # Stitch with tolerances -> 2 components.\n\t    faces2 = meshfuncs.mesh_stitch_boundaries(vertices, faces, atol=0.001)\n\t    assert faces2.tolist() == [[0, 1, 2], [0, 2, 5], [6, 7, 8], [6, 8, 11]]\n\tif __name__ == \"__main__\":\n\t    run_tests(globals())\n"]}
{"filename": "tests/test_speed.py", "chunked_list": ["import time\n\timport numpy as np\n\timport pygfx as gfx\n\tfrom gfxmorph.maybe_pygfx import smooth_sphere_geometry\n\tfrom gfxmorph import DynamicMesh\n\tfrom gfxmorph import meshfuncs\n\tfrom skcg.core.mesh import Mesh\n\tclass Timer:\n\t    def __init__(self):\n\t        self.measurements = []\n", "    def tic(self):\n\t        self.t0 = time.perf_counter()\n\t    def toc(self, title):\n\t        elapsed = time.perf_counter() - self.t0\n\t        self.add_data(title, f\"{elapsed:0.3f}\")\n\t    def add_data(self, title, value):\n\t        self.measurements.append((title, str(value)))\n\tdef iter_big_meshes():\n\t    geo = smooth_sphere_geometry(100, subdivisions=6)\n\t    vertices = geo.positions.data\n", "    faces = geo.indices.data\n\t    yield \"sphere\", vertices, faces\n\t    geo = gfx.geometries.torus_knot_geometry(100, 20, 10000, 12, stitch=True)\n\t    vertices = geo.positions.data\n\t    faces = geo.indices.data\n\t    yield \"knot\", vertices, faces\n\tdef benchmark():\n\t    columns = []\n\t    for name, vertices, faces in iter_big_meshes():\n\t        t = Timer()\n", "        t.add_data(\"MESH\", \"\")\n\t        t.add_data(\"name\", name)\n\t        t.add_data(\"nvertices\", len(vertices))\n\t        t.add_data(\"nfaces\", len(faces))\n\t        t.add_data(\"\", \"\")\n\t        if True:\n\t            t.add_data(\"NEW\", \"\")\n\t            t.tic()\n\t            m = DynamicMesh(vertices, faces)\n\t            t.toc(\"init\")\n", "            t.add_data(\"nbytes\", m.metadata[\"approx_mem\"])\n\t            t.tic()\n\t            # m.check_edge_manifold_and_closed()\n\t            meshfuncs.mesh_is_edge_manifold_and_closed(m.faces)\n\t            t.toc(\"check e-manifold & closed\")\n\t            t.tic()\n\t            # m.check_oriented()\n\t            meshfuncs.mesh_is_oriented(m.faces)\n\t            t.toc(\"check oriented\")\n\t            t.tic()\n", "            meshfuncs.mesh_get_component_labels(m.faces, m.vertex2faces)\n\t            t.toc(\"split components\")\n\t            t.tic()\n\t            meshfuncs.mesh_get_non_manifold_vertices(m.faces, m.vertex2faces)\n\t            t.toc(\"check v-manifold\")\n\t            t.tic()\n\t            # v = m.get_volume() -> slow because it checks for manifoldness, because a volume of a nonmanifold or nonmanifold mesh means nothing.\n\t            v = meshfuncs.mesh_get_volume(m.positions, m.faces)\n\t            t.toc(\"volume\")\n\t            t.tic()\n", "            vertices, faces = m.export()\n\t            t.toc(\"export\")\n\t            t.tic()\n\t            m.reset(None, None)\n\t            m.reset(vertices, faces)\n\t            t.toc(f\"reset\")\n\t            t.tic()\n\t            m.delete_faces(np.arange(0, len(m.faces), 2, np.int32))\n\t            t.toc(f\"delete 50% faces\")\n\t            m.reset(vertices, None)\n", "            t.tic()\n\t            m.delete_vertices(np.arange(0, len(m.positions), 2, np.int32))\n\t            t.toc(f\"delete 50% vertices\")\n\t            t.add_data(\"\", \"\")\n\t            # t.tic()\n\t            # i, d = m.get_closest_vertex((0, 0, 0))\n\t            # verts = m.select_vertices_over_surface(i, 65)\n\t            # t.toc(\"Select vertices\")\n\t            # t.add_data(\"\", len(verts))\n\t        if False:\n", "            t.add_data(\"\", \"\")\n\t            t.add_data(\"--\", \"--\")\n\t            t.add_data(\"SKCG\", \"\")\n\t            t.tic()\n\t            m2 = Mesh(vertices, faces)\n\t            t.toc(\"init\")\n\t            t.tic()\n\t            m2.is_manifold\n\t            t.toc(\"is_manifold\")\n\t            t.tic()\n", "            # m2.is_really_manifold\n\t            t.toc(\"is_manifold full\")\n\t            t.tic()\n\t            m2.is_closed\n\t            t.toc(\"is_closed\")\n\t            t.tic()\n\t            m2.is_oriented\n\t            t.toc(\"is_oriented\")\n\t            m2 = Mesh(vertices, faces)\n\t            t.tic()\n", "            m2.split_connected_components()\n\t            t.toc(\"Split components\")\n\t            t.tic()\n\t            v = m2.computed_interior_volume\n\t            t.toc(\"Volume\")\n\t            t.add_data(\"\", v)\n\t        columns.append(t.measurements)\n\t    for row in zip(*columns):\n\t        titles = [x[0] for x in row]\n\t        assert len(set(titles)) == 1, \"expected titles to match\"\n", "        print(titles[0].rjust(32), *[x[1].rjust(10) for x in row])\n\tdef benchmark_sphere():\n\t    t = Timer()\n\t    t.tic()\n\t    smooth_sphere_geometry(100, subdivisions=7)\n\t    t.toc(\"Create smooth spere\")\n\t    print(t.measurements)\n\tif __name__ == \"__main__\":\n\t    benchmark()\n\t    # benchmark_sphere()\n"]}
{"filename": "tests/test_pylinalg.py", "chunked_list": ["import numpy as np\n\tfrom gfxmorph.maybe_pylinalg import (\n\t    volume_of_triangle,\n\t    volume_of_closed_mesh,\n\t)\n\tfrom testutils import run_tests, get_tetrahedron\n\tdef test_volume_of_triangle():\n\t    triangles = [\n\t        [(0, 0, 1), (0, 1, 1), (1, 1, 1)],\n\t        [(0, 0, 2), (0, 1, 2), (1, 1, 2)],\n", "        [(0, 0, 1), (0, -1, 1), (1, -1, 1)],\n\t        [(0, 0, 1), (0, -1, 1), (-1, 1, 1)],\n\t    ]\n\t    expected = [-1 / 6, -1 / 3, 1 / 6, -1 / 6]\n\t    # Test individual calls\n\t    for triangle, expect in zip(triangles, expected):\n\t        v = volume_of_triangle(triangle[0], triangle[1], triangle[2])\n\t        assert np.allclose(v, expect)\n\t    # Test batch call\n\t    triangles_array = np.array(triangles, np.float32)\n", "    v1 = triangles_array[:, 0, :]\n\t    v2 = triangles_array[:, 1, :]\n\t    v3 = triangles_array[:, 2, :]\n\t    volumes = volume_of_triangle(v1, v2, v3)\n\t    assert np.allclose(volumes, expected)\n\tdef test_volume_of_closed_mesh():\n\t    # Create a regular tetrahedron\n\t    vertices, faces, _ = get_tetrahedron()\n\t    vertices = np.asarray(vertices)\n\t    faces = np.asarray(faces)\n", "    edge = 2\n\t    expected_volume = edge**3 / (6 * 2**0.5)\n\t    # Make sure the tetrahedron is not inside-out\n\t    for face in faces:\n\t        a, b, c = vertices[face]\n\t        assert volume_of_triangle(a, b, c) > 0\n\t    # Measure the volume of this tetrahedron\n\t    v = volume_of_closed_mesh(vertices, faces)\n\t    assert np.allclose(v, expected_volume)\n\t    # Make it twice as large (in three dimensions, so it's 4x the volume)\n", "    vertices *= 2\n\t    v = volume_of_closed_mesh(vertices, faces)\n\t    assert np.allclose(v, expected_volume * 8)\n\t    # Move it\n\t    vertices += 10\n\t    v = volume_of_closed_mesh(vertices, faces)\n\t    assert np.allclose(v, expected_volume * 8)\n\t    # Duplicate it, using faces\n\t    faces2 = np.row_stack([faces, faces])\n\t    v = volume_of_closed_mesh(vertices, faces2)\n", "    assert np.allclose(v, expected_volume * 16)\n\t    # Really duplicate it\n\t    vertices2 = np.row_stack([vertices, vertices + 10])\n\t    faces2 = np.row_stack([faces, faces + 4])\n\t    v = volume_of_closed_mesh(vertices2, faces2)\n\t    assert np.allclose(v, expected_volume * (8 + 8), atol=0.001)\n\t    # Reduce size of the first one\n\t    vertices2[:4] -= 10\n\t    vertices2[:4] *= 0.5\n\t    v = volume_of_closed_mesh(vertices2, faces2)\n", "    assert np.allclose(v, expected_volume * (8 + 1), atol=0.001)\n\t    # Reduce size of the second one\n\t    vertices2[4:] -= 20\n\t    vertices2[4:] *= 0.5\n\t    v = volume_of_closed_mesh(vertices2, faces2)\n\t    assert np.allclose(v, expected_volume * (1 + 1), atol=0.001)\n\t    # Move one inside out\n\t    faces2[:4, 1], faces2[:4, 2] = faces2[:4, 2].copy(), faces2[:4, 1].copy()\n\t    v = volume_of_closed_mesh(vertices2, faces2)\n\t    assert np.allclose(v, expected_volume * 0, atol=0.001)\n", "    # Move the other inside out too, now the volume is negative\n\t    faces2[4:, 1], faces2[4:, 2] = faces2[4:, 2].copy(), faces2[4:, 1].copy()\n\t    v = volume_of_closed_mesh(vertices2, faces2)\n\t    assert np.allclose(v, -expected_volume * 2, atol=0.001)\n\tif __name__ == \"__main__\":\n\t    run_tests(globals())\n"]}
{"filename": "gfxmorph/maybe_pygfx.py", "chunked_list": ["import numpy as np\n\timport pylinalg as la\n\timport pygfx as gfx\n\tfrom .basedynamicmesh import MeshChangeTracker\n\tclass DynamicMeshGeometry(gfx.Geometry, MeshChangeTracker):\n\t    \"\"\"A geometry class specifically for representing dynamic meshes.\n\t    This class also inherits from ``gfxmorph.MeshChangeTracker`` so\n\t    that the geometry can do precise updates to the GPU buffers when\n\t    the mesh is changed dynamically.\n\t    \"\"\"\n", "    def init(self, mesh):\n\t        self._nverts = len(mesh.positions)\n\t        self._nfaces = len(mesh.faces)\n\t        self.new_vertices_buffer(mesh)\n\t        self.new_faces_buffer(mesh)\n\t    def new_vertices_buffer(self, mesh):\n\t        self.positions = gfx.Buffer(mesh.positions.base)\n\t        self.normals = gfx.Buffer(mesh.normals.base)\n\t    def new_faces_buffer(self, mesh):\n\t        self.indices = gfx.Buffer(mesh.faces.base)\n", "    def add_faces(self, faces):\n\t        old_n = self._nfaces\n\t        self._nfaces += len(faces)\n\t        self.indices.update_range(old_n, self._nfaces)\n\t        self.indices.draw_range = 0, self._nfaces\n\t    def pop_faces(self, n, old):\n\t        self._nfaces -= n\n\t        self.indices.draw_range = 0, self._nfaces\n\t    def swap_faces(self, indices1, indices2):\n\t        self.indices.update_range(indices1.min(), indices1.max() + 1)\n", "        self.indices.update_range(indices2.min(), indices2.max() + 1)\n\t    def update_faces(self, indices, faces, old):\n\t        self.indices.update_range(indices.min(), indices.max() + 1)\n\t    def add_vertices(self, positions):\n\t        old_n = self._nverts\n\t        self._nverts += len(positions)\n\t        self.positions.update_range(old_n, self._nverts)\n\t    def pop_vertices(self, n, old):\n\t        self._nverts -= n\n\t    def swap_vertices(self, indices1, indices2):\n", "        self.positions.update_range(indices1.min(), indices1.max() + 1)\n\t        self.positions.update_range(indices2.min(), indices2.max() + 1)\n\t    def update_vertices(self, indices, positions, old):\n\t        # todo: Optimize this, both here and on the pygfx side.\n\t        # - We can update positions more fine-grained (using chunking).\n\t        # - Consider an API where a mask is passed (e.g. positions.update_mask()),\n\t        #   maybe this would be more efficient than using indices?\n\t        # - If we render with flat_shading, we don't need the normals!\n\t        #   So if the normal-updates are a bottleneck, it could be made optional.\n\t        self.positions.update_range(indices.min(), indices.max() + 1)\n", "    def update_normals(self, indices):\n\t        self.normals.update_range(indices.min(), indices.max() + 1)\n\tdef solid_tetrahedon():\n\t    \"\"\"The smallest/simplest possible mesh that contains a volume.\n\t    It is a closed orientable manifold.\n\t    \"\"\"\n\t    vertices = np.array(\n\t        [\n\t            [-1, 0, -1 / 2**0.5],\n\t            [+1, 0, -1 / 2**0.5],\n", "            [0, -1, 1 / 2**0.5],\n\t            [0, +1, 1 / 2**0.5],\n\t        ],\n\t        dtype=np.float32,\n\t    )\n\t    vertices /= np.linalg.norm(vertices, axis=1)[..., None]\n\t    faces = np.array(\n\t        [\n\t            [2, 0, 1],\n\t            [0, 2, 3],\n", "            [1, 0, 3],\n\t            [2, 1, 3],\n\t        ],\n\t        dtype=np.int32,\n\t    )\n\t    return vertices, faces\n\tdef subdivide_faces(vertices, faces):\n\t    r\"\"\" Subdivide a mesh.\n\t    This function subdivides the given faces, by dividing each triangle\n\t    into 4 new triangles, as in the image below:\n", "             /\\\n\t            /__\\\n\t           /\\  /\\\n\t          /__\\/__\\\n\t    The returned arrays must be processed by the caller. This is\n\t    intentional, because it depends on the use-case how this is best\n\t    done. E.g. the new vertices may be re-positioned a bit, or perhaps\n\t    the subdivision was applied on a subset of the total faces, and\n\t    merging the result requires some special indexing.\n\t    Returns\n", "    -------\n\t        new_vertices : ndarray\n\t            The new vertices that lie in the middle of the edges of the\n\t            original faces. It is the responsibility of the caller to\n\t            ``row_stack`` these to the original vertices.\n\t        new_faces : ndarray\n\t            The new faces. These should replace the given faces.\n\t    \"\"\"\n\t    # First collect unique edges. We will create one new vertex in\n\t    # the middle of each edge.\n", "    edges = faces[:, [[0, 1], [1, 2], [2, 0]]]\n\t    all_edges = edges.reshape(-1, 2)\n\t    all_edges.sort(axis=1)\n\t    # Find unique edges. We use a trick to get a 25% performance boost\n\t    # unique_edges, reverse_index = np.unique(all_edges, axis=0, return_inverse=True)\n\t    all_edges_buf = np.frombuffer(all_edges, dtype=\"V8\")\n\t    unique_edges_buf, reverse_index = np.unique(\n\t        all_edges_buf, axis=0, return_inverse=True\n\t    )\n\t    unique_edges = np.frombuffer(unique_edges_buf, dtype=np.int32).reshape(-1, 2)\n", "    # The most tricky step in this algorithm is finding the new\n\t    # indices (on the new faces) based on the edges on which these\n\t    # new vertices are placed. Using a Python dict (where the keys\n\t    # are edges, represented as tuples of 2 indices) works, but\n\t    # makes things slow.\n\t    #\n\t    # The trick: we use the reverse_index produced by `np.unique`\n\t    # to create a map that has the same shape as the faces array,\n\t    # but the indices along axis 1 represent edges instead of\n\t    # vertices.\n", "    indices_to_new_vertices = np.arange(len(unique_edges), dtype=np.int32) + len(\n\t        vertices\n\t    )\n\t    face_edges_to_new_indices = indices_to_new_vertices[reverse_index]\n\t    face_edges_to_new_indices.shape = -1, 3\n\t    # Create new vertices on the middle of the edges.\n\t    new_vertices = 0.5 * (vertices[unique_edges[:, 0]] + vertices[unique_edges[:, 1]])\n\t    # We replace each triangle with 4 new triangles, like this.\n\t    #\n\t    #      v2\n", "    #      /\\\n\t    #  e2 /__\\ e1\n\t    #    /\\  /\\\n\t    #   /__\\/__\\\n\t    # v0   e0   v1\n\t    #\n\t    smaller_faces = [\n\t        # face 1\n\t        faces[:, 0],\n\t        face_edges_to_new_indices[:, 0],\n", "        face_edges_to_new_indices[:, 2],\n\t        # face 2\n\t        faces[:, 1],\n\t        face_edges_to_new_indices[:, 1],\n\t        face_edges_to_new_indices[:, 0],\n\t        # face 3\n\t        faces[:, 2],\n\t        face_edges_to_new_indices[:, 2],\n\t        face_edges_to_new_indices[:, 1],\n\t        # face 4\n", "        face_edges_to_new_indices[:, 0],\n\t        face_edges_to_new_indices[:, 1],\n\t        face_edges_to_new_indices[:, 2],\n\t    ]\n\t    new_faces = np.column_stack(smaller_faces).reshape(-1, 3)\n\t    return new_vertices, new_faces\n\tdef smooth_sphere_geometry(radius=1.0, max_edge_length=None, subdivisions=None):\n\t    \"\"\"Generate a sphere consisting of homogenous triangles.\n\t    Creates a sphere that has its center in the local origin. The sphere\n\t    consists of 60 regular triangular faces and 32 vertices (a Pentakis\n", "    Dodecahedron). The triangles are subdivided if necessary to create\n\t    a smoother surface.\n\t    This geometry differs from the `sphere_geometry` in that it's\n\t    mathematically closed; it consists of a single contiguous surface\n\t    that encloses the space inside. The faces are also distributed\n\t    evenly over the surface, all edges have the same length, and each\n\t    triangle has the same number of incident faces. This means less\n\t    vertices are needed to create a smoother surface. The downside is\n\t    that one cannot easily apply a 2D texture map to this geometry.\n\t    Parameters\n", "    ----------\n\t    radius : float\n\t        The radius of the sphere. Vertices are placed at this distance around\n\t        the local origin.\n\t    max_edge_length : float | None\n\t        If given and not None, it is used to calculate the `subdivisions`.\n\t        The faces will be recursively subdivided until the length of each edge\n\t        is no more than this value (taking the given radius into account).\n\t    subdivisions : int | None\n\t        The number of times to recursively subdivide the faces. The total number of faces\n", "        will be ``60 * 4 ** subdivisions``. Default 0.\n\t    Returns\n\t    -------\n\t    sphere : Geometry\n\t        A geometry object that represents a sphere. Mathematically, the\n\t        mesh is an orientable closed manifold.\n\t    \"\"\"\n\t    # Dev notes:\n\t    #\n\t    # The idea of this function is to take a polyhedron, and subdivide it by\n", "    # splitting each edge in two, turning each face into 4 smaller faces.\n\t    # In the image below the triangle a-b-c is subdivided:\n\t    #\n\t    #     c\n\t    #     /\\\n\t    # ca /__\\ bc\n\t    #   /\\  /\\\n\t    #  /__\\/__\\\n\t    # a   ab   b\n\t    #\n", "    # Imagine this to be one triangle on a polyhedron. One can see that\n\t    # the new vertices are surrounded by 6 faces (3 in triangle a-b-c,\n\t    # and 3 more in the neighbouring triangle). One can also see that\n\t    # for the original vertices (e.g. a), the number of surrounding\n\t    # faces does not change by the subdividing process. It will only\n\t    # be defined by the original geometry.\n\t    #\n\t    # Therefore, in order to create a geometry that remains truely\n\t    # regular after subdividing it, we need to start with a polyhedron,\n\t    # consisting of triangles, where each vertex is shared by 6 faces.\n", "    # As far as I know, the Pentakis Dodecahedron (a.k.a.\n\t    # Kisdodecahedron) is the smallest polyhedron that meets these\n\t    # criteria. E.g. subdividing a Tetrahedron will result in rings\n\t    # around the original vertices. An Icosahedron (which has 5 faces\n\t    # around each vertex) would produce similar artifacts.\n\t    #\n\t    # The values of vertices and faces was taken from:\n\t    # Source: http://dmccooey.com/polyhedra/PentakisDodecahedron.txt\n\t    # Check radius\n\t    radius = float(radius)\n", "    if radius <= 0:\n\t        raise ValueError(\"Radius must be larger than zero.\")\n\t    # Determine the number of subdivisions\n\t    if max_edge_length is not None and subdivisions is not None:\n\t        raise ValueError(\n\t            \"Either max_edge_length or subdivisions must be given, or none, but not both.\"\n\t        )\n\t    elif max_edge_length is not None:\n\t        if max_edge_length <= 0:\n\t            raise ValueError(\"max_edge_length must be larger than zero.\")\n", "        # Emulate the effect of the subdivision process on two neighbouring vertices on the mesh\n\t        a = np.array([+0.35682207, 0.93417233, 0.0], np.float64)\n\t        b = np.array([-0.35682207, 0.93417233, 0.0], np.float64)\n\t        subdivisions = 0\n\t        while la.vec_dist(a, b) * radius > max_edge_length:\n\t            b = 0.5 * (a + b)\n\t            b /= np.linalg.norm(b)\n\t            subdivisions += 1\n\t    elif subdivisions is not None:\n\t        subdivisions = max(0, int(subdivisions))\n", "    else:\n\t        subdivisions = 0\n\t    # Calculate number of faces and vertices. Mostly to validate the result.\n\t    nfaces = 60 * 4**subdivisions\n\t    nvertices = nfaces // 2 + 2  # weird, but true\n\t    c0 = 0.927050983124842272306880251548  # == 3 * (5**0.5 - 1) / 4\n\t    c1 = 1.33058699733550141141687582919  # == 9 * (9 + 5**0.5) / 76\n\t    c2 = 2.15293498667750705708437914596  # == 9 * (7 + 5 * 5**0.5) / 76\n\t    c3 = 2.427050983124842272306880251548  # == 3 * (1 + 5**0.5) / 4\n\t    # Add vertices of the Pentakis Dodecahedron\n", "    vertices = np.array(\n\t        [\n\t            (0.0, c0, c3),\n\t            (0.0, c0, -c3),\n\t            (0.0, -c0, c3),\n\t            (0.0, -c0, -c3),\n\t            (c3, 0.0, c0),\n\t            (c3, 0.0, -c0),\n\t            (-c3, 0.0, c0),\n\t            (-c3, 0.0, -c0),\n", "            (c0, c3, 0.0),\n\t            (c0, -c3, 0.0),\n\t            (-c0, c3, 0.0),\n\t            (-c0, -c3, 0.0),\n\t            (c1, 0.0, c2),\n\t            (c1, 0.0, -c2),\n\t            (-c1, 0.0, c2),\n\t            (-c1, 0.0, -c2),\n\t            (c2, c1, 0.0),\n\t            (c2, -c1, 0.0),\n", "            (-c2, c1, 0.0),\n\t            (-c2, -c1, 0.0),\n\t            (0.0, c2, c1),\n\t            (0.0, c2, -c1),\n\t            (0.0, -c2, c1),\n\t            (0.0, -c2, -c1),\n\t            (1.5, 1.5, 1.5),\n\t            (1.5, 1.5, -1.5),\n\t            (1.5, -1.5, 1.5),\n\t            (1.5, -1.5, -1.5),\n", "            (-1.5, 1.5, 1.5),\n\t            (-1.5, 1.5, -1.5),\n\t            (-1.5, -1.5, 1.5),\n\t            (-1.5, -1.5, -1.5),\n\t        ],\n\t        np.float32,\n\t    )\n\t    # The vertices are not on the unit sphere, they seem to not even\n\t    # be exactly on the same sphere. So we push them to the unit sphere.\n\t    lengths = np.linalg.norm(vertices, axis=1)\n", "    vertices[:, 0] /= lengths\n\t    vertices[:, 1] /= lengths\n\t    vertices[:, 2] /= lengths\n\t    # Apply the faces of the Pentakis Dodecahedron.\n\t    # Except that these may recurse to create sub-faces.\n\t    faces = np.array(\n\t        [\n\t            (12, 0, 2),\n\t            (12, 2, 26),\n\t            (12, 26, 4),\n", "            (12, 4, 24),\n\t            (12, 24, 0),\n\t            (13, 3, 1),\n\t            (13, 1, 25),\n\t            (13, 25, 5),\n\t            (13, 5, 27),\n\t            (13, 27, 3),\n\t            (14, 2, 0),\n\t            (14, 0, 28),\n\t            (14, 28, 6),\n", "            (14, 6, 30),\n\t            (14, 30, 2),\n\t            (15, 1, 3),\n\t            (15, 3, 31),\n\t            (15, 31, 7),\n\t            (15, 7, 29),\n\t            (15, 29, 1),\n\t            (16, 4, 5),\n\t            (16, 5, 25),\n\t            (16, 25, 8),\n", "            (16, 8, 24),\n\t            (16, 24, 4),\n\t            (17, 5, 4),\n\t            (17, 4, 26),\n\t            (17, 26, 9),\n\t            (17, 9, 27),\n\t            (17, 27, 5),\n\t            (18, 7, 6),\n\t            (18, 6, 28),\n\t            (18, 28, 10),\n", "            (18, 10, 29),\n\t            (18, 29, 7),\n\t            (19, 6, 7),\n\t            (19, 7, 31),\n\t            (19, 31, 11),\n\t            (19, 11, 30),\n\t            (19, 30, 6),\n\t            (20, 8, 10),\n\t            (20, 10, 28),\n\t            (20, 28, 0),\n", "            (20, 0, 24),\n\t            (20, 24, 8),\n\t            (21, 10, 8),\n\t            (21, 8, 25),\n\t            (21, 25, 1),\n\t            (21, 1, 29),\n\t            (21, 29, 10),\n\t            (22, 11, 9),\n\t            (22, 9, 26),\n\t            (22, 26, 2),\n", "            (22, 2, 30),\n\t            (22, 30, 11),\n\t            (23, 9, 11),\n\t            (23, 11, 31),\n\t            (23, 31, 3),\n\t            (23, 3, 27),\n\t            (23, 27, 9),\n\t        ],\n\t        np.int32,\n\t    )\n", "    for _ in range(subdivisions):\n\t        # Subdivide!\n\t        new_vertices, new_faces = subdivide_faces(vertices, faces)\n\t        # Process new vertices\n\t        lengths = np.linalg.norm(new_vertices, axis=1)\n\t        new_vertices[:, 0] /= lengths\n\t        new_vertices[:, 1] /= lengths\n\t        new_vertices[:, 2] /= lengths\n\t        vertices = np.row_stack([vertices, new_vertices])\n\t        # The faces are simply replaced\n", "        faces = new_faces\n\t    # Double-check that the expected numbers match the real ones\n\t    assert nfaces == len(faces)\n\t    assert nvertices == len(vertices)\n\t    # Return as a geometry\n\t    return gfx.Geometry(positions=vertices * radius, indices=faces, normals=vertices)\n\tif __name__ == \"__main__\":\n\t    import time\n\t    t0 = time.perf_counter()\n\t    geo = smooth_sphere_geometry(100, None, 1)\n", "    print(time.perf_counter() - t0)\n\t    m = gfx.Mesh(\n\t        geo,\n\t        gfx.MeshPhongMaterial(wireframe=True, wireframe_thickness=3),\n\t    )\n\t    # m.material.side = \"FRONT\"\n\t    gfx.show(m)\n"]}
{"filename": "gfxmorph/maybe_pylinalg.py", "chunked_list": ["import numpy as np\n\tdef volume_of_triangle(p1, p2, p3):\n\t    \"\"\"Get the volume that a triangle has, the fourth point being the origin.\n\t    Assumes CCW winding. Negate the result for CW winded triangles.\n\t    \"\"\"\n\t    # https://stackoverflow.com/a/1568551\n\t    p1 = np.reshape(p1, (-1, 3))\n\t    p2 = np.reshape(p2, (-1, 3))\n\t    p3 = np.reshape(p3, (-1, 3))\n\t    p1x, p1y, p1z = p1[:, 0], p1[:, 1], p1[:, 2]\n", "    p2x, p2y, p2z = p2[:, 0], p2[:, 1], p2[:, 2]\n\t    p3x, p3y, p3z = p3[:, 0], p3[:, 1], p3[:, 2]\n\t    v321 = p3x * p2y * p1z\n\t    v231 = p2x * p3y * p1z\n\t    v312 = p3x * p1y * p2z\n\t    v132 = p1x * p3y * p2z\n\t    v213 = p2x * p1y * p3z\n\t    v123 = p1x * p2y * p3z\n\t    result = (1.0 / 6.0) * (-v321 + v231 + v312 - v132 - v213 + v123)\n\t    if not result.shape:\n", "        return float(result)\n\t    elif result.shape == (1,):\n\t        return float(result[0])\n\t    else:\n\t        return result\n\tdef volume_of_closed_mesh(vertices, faces):\n\t    \"\"\"Calculate the volume of the mesh.\n\t    It is assumed that all faces have consisted, and that the winding\n\t    is CCW (produces a negative volume if the winding is CW). It is\n\t    also assumed that the mesh is closed. Unclosed volumes are leaky,\n", "    resulting in an incorrect volume calculation.\n\t    \"\"\"\n\t    # Note: it's possible to get a hint on whether the volume is\n\t    # actually closed, by displacing the vertices and calculating the\n\t    # volume again. If there is a leak in the mesh, that leak will cause\n\t    # the second volume to be different. This depends a bit on the\n\t    # geometry, and it's hard to tell when errors are round-off errors,\n\t    # or may be an indication of a leak. Therefore its probably better\n\t    # to perform a proper analysis to detect the mesh being closed.\n\t    # Batch-calculate\n", "    volumes = volume_of_triangle(\n\t        vertices[faces[:, 0]], vertices[faces[:, 1]], vertices[faces[:, 2]]\n\t    )\n\t    return volumes if isinstance(volumes, float) else volumes.sum()\n"]}
{"filename": "gfxmorph/basedynamicmesh.py", "chunked_list": ["import weakref\n\timport numpy as np\n\tfrom .tracker import MeshChangeTracker\n\tfrom .utils import (\n\t    logger,\n\t    Safecall,\n\t    check_indices,\n\t    as_immutable_array,\n\t    make_vertex2faces,\n\t)\n", "EXCEPTION_IN_ATOMIC_CODE = \"Unexpected exception in code that is considered atomic!\"\n\tclass BaseDynamicMesh:\n\t    \"\"\"A mesh object that can be modified in-place.\n\t    It manages buffers that are oversized so the vertex and face array\n\t    can grow. When the buffer is full, a larger buffer is allocated.\n\t    The exposed arrays are contiguous views onto these buffers.\n\t    It also maintains a vertex2faces incidence map, and keeps the vertex\n\t    normals up to date. It can notify other object of changes, so that\n\t    any representation of the mesh  (e.g. a visualization on the GPU)\n\t    can be kept in sync.\n", "    \"\"\"\n\t    # We assume meshes with triangles (not quads).\n\t    # Note that there are a few places where loops are unrolled, and verts_per_face is thus hardcoded.\n\t    _verts_per_face = 3\n\t    def __init__(self):\n\t        # Caches that subclasses can use to cache stuff. When the\n\t        # positions/faces change, the respective caches are cleared.\n\t        self._cache_depending_on_verts = {}\n\t        self._cache_depending_on_faces = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n", "        # A list of trackers that are notified of changes.\n\t        self._change_trackers = weakref.WeakValueDictionary()\n\t        # Create the buffers that contain the data, and which are larger\n\t        # than needed. These arrays should *only* be referenced in the\n\t        # allocate- and deallocate- methods.\n\t        self._faces_buf = np.zeros((8, self._verts_per_face), np.int32)\n\t        self._faces_normals_buf = np.zeros((8, 3), np.float32)\n\t        self._positions_buf = np.zeros((8, 3), np.float32)\n\t        self._normals_buf = np.zeros((8, 3), np.float32)\n\t        # We set unused positions to nan, so that code that uses the\n", "        # full buffer does not accidentally use invalid vertex positions.\n\t        self._positions_buf.fill(np.nan)\n\t        # Create faces array views. The internals operate on the ._faces array,\n\t        # because the public .faces is readonly\n\t        self._faces = self._faces_buf[:0]\n\t        self._faces_normals = self._faces_normals_buf[:0]\n\t        # The vertex array views. Not much harm can be done to these.\n\t        self._positions = self._positions_buf[:0]\n\t        self._normals = self._normals_buf[:0]\n\t        # Reverse map\n", "        # This array is jagged, because the number of faces incident\n\t        # to one vertex can potentially be big (e.g. the top and bottom\n\t        # of a sphere sampled in lon/lat directions). We could use a\n\t        # numpy array of lists, which has the advantage that you can\n\t        # do `vertex2faces[multiple_indices].sum()`. However, benchmarks\n\t        # show that this is *slower* than a simple list of lists. A\n\t        # list of sets could also work, but is slightly slower.\n\t        #\n\t        # Other data structures are also possibe, e.g. one based on\n\t        # shifts. These structures can be build faster, but using them\n", "        # is slower due to the extra indirection.\n\t        self._vertex2faces = []  # vi -> [fi1, fi2, ..]\n\t    @property\n\t    def faces(self):\n\t        \"\"\"The faces of the mesh.\n\t        This is a C-contiguous readonly ndarray. Note that the array\n\t        may change as data is added and deleted, including faces being\n\t        moved arround to fill holes left by deleted faces.\n\t        \"\"\"\n\t        return as_immutable_array(self._faces)\n", "    @property\n\t    def positions(self):\n\t        \"\"\"The vertex positions of the mesh.\n\t        See note on ``.faces`` for details.\n\t        \"\"\"\n\t        return as_immutable_array(self._positions)\n\t    @property\n\t    def normals(self):\n\t        \"\"\"The vertex normals of the mesh.\n\t        See note on ``.faces`` for details.\n", "        \"\"\"\n\t        return as_immutable_array(self._normals)\n\t    @property\n\t    def vertex2faces(self):\n\t        \"\"\"Maps vertex indices to a list of face indices.\n\t        This map can be used to e.g. traverse the mesh over its surface.\n\t        Although technically the map is a list that can be modified in\n\t        place, you should really not do that. Note that each element\n\t        lists face indices in arbitrary order and may contain duplicate\n\t        face indices.\n", "        \"\"\"\n\t        return self._vertex2faces\n\t    def track_changes(self, tracker, *, remove=False):\n\t        \"\"\"Track changes using a MeshChangeTracker object.\n\t        The given object is notified of updates of this mesh. If\n\t        ``remove`` is True, the tracker is removed instead.\n\t        \"\"\"\n\t        if not isinstance(tracker, MeshChangeTracker):\n\t            raise TypeError(\"Expected a MeshChangeTracker subclass.\")\n\t        self._change_trackers.pop(id(tracker), None)\n", "        if not remove:\n\t            self._change_trackers[id(tracker)] = tracker\n\t            # Init the tracker state so it starts up-to-date\n\t            with Safecall():\n\t                tracker.init(self)\n\t    def export(self):\n\t        \"\"\"Get a copy of the array of vertex-positions and faces.\n\t        Note that the arrays are copied because the originals are\n\t        modified in place when e.g. faces are removed or updated.\n\t        \"\"\"\n", "        return self.positions.copy(), self.faces.copy()\n\t    def check_internal_state(self):\n\t        \"\"\"Method to validate the integrity of the internal state.\n\t        In practice this check is not be needed, but it's used\n\t        extensively during the unit tests to make sure that all methods\n\t        work as intended.\n\t        \"\"\"\n\t        # Note: some vertices not being used is technically an ok state.\n\t        # It is also unavoidable, because one first adds vertices and\n\t        # then the faces to use them. But a bug in our internals could\n", "        # make the number of unused vertices grow, so maybe we'll want\n\t        # some sort of check for it at some point.\n\t        nverts = len(self.positions)\n\t        nfaces = len(self.faces)\n\t        # Check that all faces match a vertex\n\t        if nfaces > 0:\n\t            assert self.faces.min() >= 0\n\t            assert self.faces.max() < nverts\n\t        # Check sizes of arrays\n\t        assert len(self._faces) == nfaces\n", "        assert len(self._faces_normals) == nfaces\n\t        assert len(self._positions) == nverts\n\t        assert len(self._normals) == nverts\n\t        # Check that the views are based on the corresppnding buffers\n\t        assert self._faces.base is self._faces_buf\n\t        assert self._faces_normals.base is self._faces_normals_buf\n\t        assert self._positions.base is self._positions_buf\n\t        assert self._normals.base is self._normals_buf\n\t        # Check vertex2faces map\n\t        vertex2faces = make_vertex2faces(self.faces, nverts)\n", "        assert len(vertex2faces) == len(self._vertex2faces)\n\t        for face1, face2 in zip(vertex2faces, self._vertex2faces):\n\t            assert sorted(face1) == sorted(face2)\n\t    def _after_change(self):\n\t        \"\"\"Called after each change. Does nothing by default, but subclasses can overload this.\"\"\"\n\t        pass\n\t    # %% Manage normals\n\t    def _update_face_normals(self, face_indices):\n\t        \"\"\"Update the selected face normals.\"\"\"\n\t        face_indices = np.asarray(face_indices, np.int32)\n", "        faces = self._faces[face_indices]\n\t        positions = self._positions\n\t        r1 = positions[faces[:, 0], :]\n\t        r2 = positions[faces[:, 1], :]\n\t        r3 = positions[faces[:, 2], :]\n\t        face_normals = np.cross((r2 - r1), (r3 - r1))  # assumes CCW\n\t        # faces_areas = 0.5 * np.linalg.norm(face_normals, axis=1)\n\t        self._faces_normals[face_indices] = face_normals\n\t        # The thing with vertex normals is that they depend on all\n\t        # incident faces, so doing a partial update is tricky.\n", "        # * We could first undo the contribution of the selected faces. E.g.\n\t        #   using a list of dicts: vi -> fi -> normals. Likely slow.\n\t        # * Or we first select the vertex_indices (by flattening faces), and use\n\t        #   vertex2faces to come up with a slightly larger set of face_indices,\n\t        #   which we then use to update the normals for the vertex_indices (and more)\n\t        #   and then only update vertex_indices. Also likely slow.\n\t        # * Only update the face normals and vertex normals of connected components.\n\t        # * Or we just update all vertex normals, but notify trackers\n\t        #   with the indices of vertices who's normal actually changed.\n\t        # * Note: we could implement some form of lazy computation for the\n", "        #   normals, or an option to turn all this off if no normals are needed.\n\t        self._update_vertex_normals()\n\t        # Get indices of vertices who's normal changed\n\t        vertex_mask = np.zeros((len(self._positions),), bool)\n\t        vertex_mask[faces.flatten()] = True\n\t        vertex_indices = np.where(vertex_mask)[0]\n\t        # Pass on the update\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n\t                tracker.update_normals(vertex_indices)\n", "    def _update_vertex_normals(self):\n\t        \"\"\"Update all vertex normals.\"\"\"\n\t        vertex_normals = self._normals\n\t        vertex_normals.fill(0.0)\n\t        for i in range(3):\n\t            np.add.at(vertex_normals, self._faces[:, i], self._faces_normals)\n\t        norms = np.linalg.norm(vertex_normals, axis=1)\n\t        (zeros,) = np.where(norms == 0)\n\t        norms[zeros] = 1.0  # prevent divide-by-zero\n\t        vertex_normals /= norms[:, np.newaxis]\n", "        vertex_normals[zeros] = 0.0\n\t    # %% Allocation and de-allocation of the buffers\n\t    def _allocate_faces(self, n):\n\t        \"\"\"Increase the size of the faces view to hold n free faces at\n\t        the end. If necessary the underlying buffer is re-allocated.\n\t        \"\"\"\n\t        n = int(n)\n\t        assert n >= 1\n\t        nfaces1 = len(self._faces)\n\t        nfaces2 = nfaces1 + n\n", "        # Re-allocate buffer?\n\t        new_buffers = nfaces2 > len(self._faces_buf)\n\t        if new_buffers:\n\t            new_size = max(8, nfaces2)\n\t            new_size = 2 ** int(np.ceil(np.log2(new_size)))\n\t            self._faces_buf = np.zeros((new_size, self._verts_per_face), np.int32)\n\t            self._faces_buf[:nfaces1] = self._faces\n\t            self._faces_normals_buf = np.zeros((new_size, 3), np.float32)\n\t            self._faces_normals_buf[:nfaces1] = self._faces_normals\n\t        # Reset views\n", "        self._faces = self._faces_buf[:nfaces2]\n\t        self._faces_normals = self._faces_normals_buf[:nfaces2]\n\t        # Notify\n\t        if new_buffers:\n\t            for tracker in self._change_trackers.values():\n\t                with Safecall():\n\t                    tracker.new_faces_buffer(self)\n\t    def _deallocate_faces(self, n):\n\t        \"\"\" \"Decrease the size of the faces view, discarting the n faces\n\t        at the end. If it makes sense, the underlying buffer is re-allocated.\n", "        \"\"\"\n\t        n = int(n)\n\t        assert n >= 1\n\t        nfaces = len(self._faces) - n\n\t        # Re-allocate buffer?\n\t        new_buffers = nfaces <= 0.25 * len(self._faces_buf) and len(self._faces_buf) > 8\n\t        if new_buffers:\n\t            new_size = max(8, nfaces * 2)\n\t            new_size = 2 ** int(np.ceil(np.log2(new_size)))\n\t            self._faces_buf = np.zeros((new_size, self._verts_per_face), np.int32)\n", "            self._faces_buf[:nfaces] = self._faces[:nfaces]\n\t            self._faces_normals_buf = np.zeros((new_size, 3), np.float32)\n\t            self._faces_normals_buf[:nfaces] = self._faces_normals[:nfaces]\n\t        else:\n\t            # Tidy up\n\t            self._faces_buf[nfaces:] = 0\n\t            self._faces_normals_buf[nfaces:] = 0.0\n\t        # Reset views\n\t        self._faces = self._faces_buf[:nfaces]\n\t        self._faces_normals = self._faces_normals_buf[:nfaces]\n", "        # Notify\n\t        if new_buffers:\n\t            for tracker in self._change_trackers.values():\n\t                with Safecall():\n\t                    tracker.new_faces_buffer(self)\n\t    def _allocate_vertices(self, n):\n\t        \"\"\"Increase the vertex views to hold n free vertices at the end. If\n\t        necessary the underlying buffers are re-allocated.\n\t        \"\"\"\n\t        n = int(n)\n", "        assert n >= 1\n\t        nverts1 = len(self._positions)\n\t        nverts2 = nverts1 + n\n\t        # Re-allocate buffer?\n\t        new_buffers = nverts2 > len(self._positions_buf)\n\t        if new_buffers:\n\t            new_size = max(8, nverts2)\n\t            new_size = 2 ** int(np.ceil(np.log2(new_size)))\n\t            self._positions_buf = np.zeros((new_size, 3), np.float32)\n\t            self._positions_buf[:nverts1] = self._positions\n", "            self._positions_buf[nverts2:] = np.nan\n\t            self._normals_buf = np.zeros((new_size, 3), np.float32)\n\t            self._normals_buf[:nverts1] = self._normals\n\t        # Reset views\n\t        self._positions = self._positions_buf[:nverts2]\n\t        self._normals = self._normals_buf[:nverts2]\n\t        # Notify\n\t        if new_buffers:\n\t            for tracker in self._change_trackers.values():\n\t                with Safecall():\n", "                    tracker.new_vertices_buffer(self)\n\t    def _deallocate_vertices(self, n):\n\t        \"\"\"Decrease the size of the vertices views, discarting the n vertices\n\t        at the end. If it makes sense, the underlying buffer is re-allocated.\n\t        \"\"\"\n\t        n = int(n)\n\t        assert n >= 1\n\t        nverts = len(self._positions) - n\n\t        # Re-allocate buffer?\n\t        new_buffers = (\n", "            nverts <= 0.25 * len(self._positions_buf) and len(self._positions_buf) > 8\n\t        )\n\t        if new_buffers:\n\t            new_size = max(8, nverts * 2)\n\t            new_size = 2 ** int(np.ceil(np.log2(new_size)))\n\t            self._positions_buf = np.zeros((new_size, 3), np.float32)\n\t            self._positions_buf[:nverts] = self._positions[:nverts]\n\t            self._positions_buf[nverts:] = np.nan\n\t            self._normals_buf = np.zeros((new_size, 3), np.float32)\n\t            self._normals_buf[:nverts] = self._normals[:nverts]\n", "        else:\n\t            # Tidy up\n\t            self._positions_buf[nverts:] = np.nan\n\t            self._normals_buf[nverts:] = 0\n\t        # Reset views\n\t        self._positions = self._positions_buf[:nverts]\n\t        self._normals = self._normals_buf[:nverts]\n\t        # Notify\n\t        if new_buffers:\n\t            for tracker in self._change_trackers.values():\n", "                with Safecall():\n\t                    tracker.new_vertices_buffer(self)\n\t    # %% Convenience methods to modify the mesh\n\t    def clear(self):\n\t        \"\"\"Clear the mesh, removing all vertices and faces.\"\"\"\n\t        if len(self._faces):\n\t            self.pop_faces(len(self._faces))\n\t        if len(self._positions):\n\t            self.pop_vertices(len(self._positions))\n\t    def reset(self, positions, faces):\n", "        \"\"\"Reset the vertices and faces, e.g. from an export.\"\"\"\n\t        self.clear()\n\t        if positions is not None:\n\t            self.add_vertices(positions)\n\t        if faces is not None:\n\t            self.add_faces(faces)\n\t    def delete_faces(self, face_indices):\n\t        \"\"\"Delete the faces indicated by the given face indices.\n\t        The deleted faces are replaced with faces from the end of the\n\t        array (except for deleted faces that leave no holes because\n", "        they are already at the end).\n\t        An error can be raised if e.g. the indices are out of bounds.\n\t        \"\"\"\n\t        # --- Prepare / checks\n\t        indices = check_indices(\n\t            face_indices, len(self._faces), \"face indices to delete\"\n\t        )\n\t        to_delete = set(indices)\n\t        nfaces1 = len(self._faces)\n\t        nfaces2 = nfaces1 - len(to_delete)\n", "        to_maybe_move = set(range(nfaces2, nfaces1))  # these are for filling the holes\n\t        to_just_drop = to_maybe_move & to_delete  # but some of these may be at the end\n\t        indices1 = list(to_delete - to_just_drop)\n\t        indices2 = list(to_maybe_move - to_just_drop)\n\t        assert len(indices1) == len(indices2), \"Internal error\"\n\t        # --- Apply -> delegate\n\t        # Do a move, so all faces to delete are at the end\n\t        if len(indices1):\n\t            self.swap_faces(indices1, indices2)\n\t        # Pop from the end\n", "        self.pop_faces(len(to_delete))\n\t    def delete_vertices(self, vertex_indices):\n\t        \"\"\"Delete the vertices indicated by the given vertex indices.\n\t        The deleted vertices are replaced with vertices from the end of the\n\t        array (except for deleted vertices that leave no holes because\n\t        they are already at the end).\n\t        An error can be raised if e.g. the indices are out of bounds.\n\t        \"\"\"\n\t        # Note: defragmenting when deleting vertices is somewhat\n\t        # expensive because we also need to update the faces. From a\n", "        # technical perspective it's fine to have unused vertices, so\n\t        # we could just leave them as holes, which would likely be faster.\n\t        # However, the current implementation also has advantages:\n\t        #\n\t        # - It works the same as for the faces.\n\t        # - With a contiguous vertex array it is easy to check if faces are valid.\n\t        # - No need to select vertices that are in use (e.g. for bounding boxes).\n\t        # - Getting free slots for vertices is straightforward without\n\t        #   the need for additional structures like a set of free vertices.\n\t        # - The vertices and faces can at any moment be copied and be sound.\n", "        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checcks\n\t        indices = check_indices(\n\t            vertex_indices, len(self._positions), \"vertex indices to delete\"\n\t        )\n\t        to_delete = set(indices)\n\t        nverts1 = len(self._positions)\n\t        nverts2 = nverts1 - len(to_delete)\n\t        to_maybe_move = set(range(nverts2, nverts1))\n\t        to_just_drop = to_maybe_move & to_delete\n", "        indices1 = list(to_delete - to_just_drop)\n\t        indices2 = list(to_maybe_move - to_just_drop)\n\t        assert len(indices1) == len(indices2), \"Internal error\"\n\t        # Check that none of the vertices are in use. Note that this\n\t        # check is done in pop_vertices, but we also perform it here\n\t        # to avoid swapping faces when the test fails (keep it atomic).\n\t        # The overhead for doing the test twice is not that bad.\n\t        if any(len(vertex2faces[vi]) > 0 for vi in to_delete):\n\t            raise ValueError(\"Vertex to delete is in use.\")\n\t        # --- Apply\n", "        # Do a move, so all vertices to delete are at the end\n\t        if len(indices1):\n\t            self.swap_vertices(indices1, indices2)\n\t        # Pop from the end\n\t        self.pop_vertices(len(to_delete))\n\t    # %% The core API\n\t    def add_faces(self, new_faces):\n\t        \"\"\"Add the given faces to the mesh.\n\t        The faces must reference existing vertices.\n\t        \"\"\"\n", "        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checks\n\t        # Check incoming array\n\t        faces = np.asarray(new_faces, np.int32).reshape(-1, self._verts_per_face)\n\t        # It's fine for the mesh to have zero faces, but it's likely\n\t        # an error if the user calls this with an empty array.\n\t        if len(faces) == 0:\n\t            raise ValueError(\"Cannot add zero faces.\")\n\t        # Check sanity of the faces\n\t        if faces.min() < 0 or faces.max() >= len(self._positions):\n", "            raise ValueError(\n\t                \"The faces array containes indices that are out of bounds.\"\n\t            )\n\t        n = len(faces)\n\t        n1 = len(self._faces)\n\t        indices = np.arange(n1, n1 + n, dtype=np.int32)\n\t        # --- Apply\n\t        try:\n\t            self._allocate_faces(n)\n\t            self._faces[n1:] = faces\n", "            self._update_face_normals(indices)\n\t            # Update reverse map\n\t            for i, face in enumerate(faces):\n\t                fi = i + n1\n\t                vertex2faces[face[0]].append(fi)\n\t                vertex2faces[face[1]].append(fi)\n\t                vertex2faces[face[2]].append(fi)\n\t        except Exception:  # pragma: no cover\n\t            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n\t            raise\n", "        # --- Notify\n\t        self._cache_depending_on_faces = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n\t                tracker.add_faces(faces)\n\t        self._after_change()\n\t    def pop_faces(self, n, _old=None):\n\t        \"\"\"Remove the last n faces from the mesh.\"\"\"\n\t        vertex2faces = self._vertex2faces\n", "        # --- Prepare / checks\n\t        n = int(n)\n\t        if n <= 0:\n\t            raise ValueError(\"Number of faces to pop must be larger than zero.\")\n\t        if n > len(self._faces):\n\t            raise ValueError(\n\t                \"Number of faces to pop is larger than the total number of faces.\"\n\t            )\n\t        nfaces1 = len(self.faces)\n\t        nfaces2 = nfaces1 - n\n", "        # --- Apply\n\t        old_faces = self._faces[nfaces2:].copy()\n\t        try:\n\t            # Update reverse map. If over half the faces are removed,\n\t            # its faster to re-build verte2faces from scratch after\n\t            # de-allocating the faces, but only by a bit, so lets not.\n\t            for fi in range(nfaces2, nfaces1):\n\t                face = self._faces[fi]\n\t                vertex2faces[face[0]].remove(fi)\n\t                vertex2faces[face[1]].remove(fi)\n", "                vertex2faces[face[2]].remove(fi)\n\t            # Adjust the array lengths (reset views)\n\t            self._deallocate_faces(n)\n\t        except Exception:  # pragma: no cover\n\t            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n\t            raise\n\t        # --- Notify\n\t        self._cache_depending_on_faces = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n", "            with Safecall():\n\t                tracker.pop_faces(n, old_faces)\n\t        self._after_change()\n\t    def swap_faces(self, face_indices1, face_indices2):\n\t        \"\"\"Swap the faces indicated by the given indices.\n\t        This method is public, but likely not generally useful by\n\t        itself. The ``delete_faces()`` method is a convenience\n\t        combination of ``swap_faces()`` and ``pop_faces()``.\n\t        \"\"\"\n\t        # Technically this can also be done with update_faces, but\n", "        # swapping is faster and costs significantly less memory in\n\t        # e.g. an undo stack.\n\t        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checks\n\t        indices1 = check_indices(\n\t            face_indices1, len(self._faces), \"face indices to swap (1)\"\n\t        )\n\t        indices2 = check_indices(\n\t            face_indices2, len(self._faces), \"face indices to swap (2)\"\n\t        )\n", "        if not len(indices1) == len(indices2):\n\t            raise ValueError(\"Both index arrays must have the same length.\")\n\t        # --- Apply\n\t        try:\n\t            # Update reverse map (unrolled loops for small performance bump)\n\t            for fi1, fi2 in zip(indices1, indices2):\n\t                face1 = self._faces[fi1]\n\t                fii = vertex2faces[face1[0]]\n\t                fii.remove(fi1)\n\t                fii.append(fi2)\n", "                fii = vertex2faces[face1[1]]\n\t                fii.remove(fi1)\n\t                fii.append(fi2)\n\t                fii = vertex2faces[face1[2]]\n\t                fii.remove(fi1)\n\t                fii.append(fi2)\n\t                face2 = self._faces[fi2]\n\t                fii = vertex2faces[face2[0]]\n\t                fii.remove(fi2)\n\t                fii.append(fi1)\n", "                fii = vertex2faces[face2[1]]\n\t                fii.remove(fi2)\n\t                fii.append(fi1)\n\t                fii = vertex2faces[face2[2]]\n\t                fii.remove(fi2)\n\t                fii.append(fi1)\n\t            # Swap the faces themselves\n\t            for a in [self._faces, self._faces_normals]:\n\t                a[indices1], a[indices2] = a[indices2], a[indices1]\n\t        except Exception:  # pragma: no cover\n", "            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n\t            raise\n\t        # --- Notify\n\t        self._cache_depending_on_faces = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n\t                tracker.swap_faces(indices1, indices2)\n\t        self._after_change()\n\t    def update_faces(self, face_indices, new_faces, _old=None):\n", "        \"\"\"Update the value of the given faces.\"\"\"\n\t        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checks\n\t        indices = check_indices(\n\t            face_indices, len(self._faces), \"face indices to update\"\n\t        )\n\t        faces = np.asarray(new_faces, np.int32).reshape(-1, self._verts_per_face)\n\t        if len(indices) != len(faces):\n\t            raise ValueError(\"Indices and faces to update have different lengths.\")\n\t        # Check sanity of the faces\n", "        if faces.min() < 0 or faces.max() >= len(self._positions):\n\t            raise ValueError(\n\t                \"The faces array containes indices that are out of bounds.\"\n\t            )\n\t        # --- Apply\n\t        old_faces = self._faces[indices]\n\t        try:\n\t            # Update reverse map\n\t            for fi, new_face in zip(indices, faces):\n\t                old_face = self._faces[fi]\n", "                vertex2faces[old_face[0]].remove(fi)\n\t                vertex2faces[old_face[1]].remove(fi)\n\t                vertex2faces[old_face[2]].remove(fi)\n\t                vertex2faces[new_face[0]].append(fi)\n\t                vertex2faces[new_face[1]].append(fi)\n\t                vertex2faces[new_face[2]].append(fi)\n\t            # Update\n\t            self._faces[indices] = faces\n\t            self._update_face_normals(indices)\n\t        except Exception:  # pragma: no cover\n", "            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n\t            raise\n\t        # --- Notify\n\t        self._cache_depending_on_faces = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n\t                tracker.update_faces(indices, faces, old_faces)\n\t        self._after_change()\n\t    def add_vertices(self, new_positions):\n", "        \"\"\"Add the given vertices to the mesh.\"\"\"\n\t        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checks\n\t        # Check incoming array\n\t        positions = np.asarray(new_positions, np.float32).reshape(-1, 3)\n\t        if len(positions) == 0:\n\t            raise ValueError(\"Cannot add zero vertices.\")\n\t        n = len(positions)\n\t        n1 = len(self._positions)\n\t        # --- Apply\n", "        try:\n\t            self._allocate_vertices(n)\n\t            self._positions[n1:] = positions\n\t            # Update reverse map\n\t            vertex2faces.extend([] for i in range(n))\n\t        except Exception:  # pragma: no cover\n\t            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n\t            raise\n\t        # --- Notify\n\t        self._cache_depending_on_verts = {}\n", "        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n\t                tracker.add_vertices(positions)\n\t        self._after_change()\n\t    def pop_vertices(self, n, _old=None):\n\t        \"\"\"Remove the last n vertices from the mesh.\"\"\"\n\t        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checks\n\t        n = int(n)\n", "        if n <= 0:\n\t            raise ValueError(\"Number of vertices to pop must be larger than zero.\")\n\t        if n > len(self._positions):\n\t            raise ValueError(\n\t                \"Number of vertices to pop is larger than the total number of vertices.\"\n\t            )\n\t        nverts1 = len(self._positions)\n\t        nverts2 = nverts1 - n\n\t        # Check that none of the vertices are in use.\n\t        if any(len(vertex2faces[vi]) > 0 for vi in range(nverts2, nverts1)):\n", "            raise ValueError(\"Vertex to delete is in use.\")\n\t        # --- Apply\n\t        old_positions = self._positions[nverts2:].copy()\n\t        try:\n\t            # Drop unused vertices at the end\n\t            self._deallocate_vertices(nverts1 - nverts2)\n\t            # Update reverse map\n\t            vertex2faces[nverts2:] = []\n\t        except Exception:  # pragma: no cover\n\t            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n", "            raise\n\t        # --- Notify\n\t        self._cache_depending_on_verts = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n\t                tracker.pop_vertices(n, old_positions)\n\t        self._after_change()\n\t    def swap_vertices(self, vertex_indices1, vertex_indices2):\n\t        \"\"\"Move the vertices indicated by the given indices.\n", "        This method is public, but likely not generally useful by\n\t        itself. The ``delete_vertices()`` method is a convenience\n\t        combination of ``swap_vertices()`` and ``pop_vertices()``.\n\t        \"\"\"\n\t        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checks\n\t        indices1 = check_indices(\n\t            vertex_indices1, len(self._positions), \"vertex indices to swap (1)\"\n\t        )\n\t        indices2 = check_indices(\n", "            vertex_indices2, len(self._positions), \"vertex indices to swap (2)\"\n\t        )\n\t        if not len(indices1) == len(indices2):\n\t            raise ValueError(\"Both index arrays must have the same length.\")\n\t        # --- Apply\n\t        try:\n\t            # Swap the vertices themselves\n\t            for a in [self._positions, self._normals]:\n\t                a[indices1], a[indices2] = a[indices2], a[indices1]\n\t            # Update the faces that refer to the moved indices\n", "            faces = self._faces\n\t            for vi1, vi2 in zip(indices1, indices2):\n\t                mask1 = faces == vi1\n\t                mask2 = faces == vi2\n\t                faces[mask2] = vi1\n\t                faces[mask1] = vi2\n\t            # Update reverse map\n\t            for vi1, vi2 in zip(indices1, indices2):\n\t                vertex2faces[vi1], vertex2faces[vi2] = (\n\t                    vertex2faces[vi2],\n", "                    vertex2faces[vi1],\n\t                )\n\t        except Exception:  # pragma: no cover\n\t            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n\t            raise\n\t        # --- Notify\n\t        self._cache_depending_on_verts = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n", "                tracker.swap_vertices(indices1, indices2)\n\t        self._after_change()\n\t    def update_vertices(self, vertex_indices, new_positions, _old=None):\n\t        \"\"\"Update the value of the given vertices.\"\"\"\n\t        vertex2faces = self._vertex2faces\n\t        # --- Prepare / checks\n\t        indices = check_indices(\n\t            vertex_indices, len(self._positions), \"vertex indices to update\"\n\t        )\n\t        positions = np.asarray(new_positions, np.float32).reshape(-1, 3)\n", "        if len(indices) != len(positions):\n\t            raise ValueError(\"Indices and positions to update have different lengths.\")\n\t        # --- Apply\n\t        old_positions = self._positions[indices]\n\t        try:\n\t            self._positions[indices] = positions\n\t            # Note: if the number of changed vertices is large (say 50% or more)\n\t            # it'd probably be more efficient to collect face_indices via a mask.\n\t            face_indices = set()\n\t            for vi in indices:\n", "                face_indices.update(vertex2faces[vi])\n\t            self._update_face_normals(list(face_indices))\n\t        except Exception:  # pragma: no cover\n\t            logger.warn(EXCEPTION_IN_ATOMIC_CODE)\n\t            raise\n\t        # --- Notify\n\t        self._cache_depending_on_verts = {}\n\t        self._cache_depending_on_verts_and_faces = {}\n\t        for tracker in self._change_trackers.values():\n\t            with Safecall():\n", "                tracker.update_vertices(indices, positions, old_positions)\n\t        self._after_change()\n"]}
{"filename": "gfxmorph/__init__.py", "chunked_list": ["from .basedynamicmesh import BaseDynamicMesh  # noqa: F401\n\tfrom .mesh import DynamicMesh  # noqa: F401\n\tfrom .tracker import MeshChangeTracker, MeshLogger, MeshUndoTracker  # noqa: F401\n\tfrom . import meshfuncs  # noqa: F401\n\t__version__ = \"0.0.1\"\n\tversion_info = tuple(map(int, __version__.split(\".\")))\n"]}
{"filename": "gfxmorph/utils.py", "chunked_list": ["import logging\n\timport traceback\n\timport numpy as np\n\tlogger = logging.getLogger(\"meshmorph\")\n\tclass Safecall:\n\t    \"\"\"Context manager for doing calls that should not raise. If an exception\n\t    is raised, it is caught, logged, and the context exits normally.\n\t    \"\"\"\n\t    def __enter__(self):\n\t        return self\n", "    def __exit__(self, exc_type, exc_val, exc_tb):\n\t        if exc_val:\n\t            lines = traceback.format_exception(exc_type, exc_val, exc_tb)\n\t            logger.error(\"Exception in update callback:\\n\" + \"\".join(lines))\n\t        return True  # Yes, we handled the exception\n\tdef check_indices(indices, n, what_for):\n\t    \"\"\"Check indices and convert to an in32 array (if necessary).\"\"\"\n\t    result = None\n\t    typ = type(indices).__name__\n\t    if isinstance(indices, int):\n", "        result = [indices]\n\t    elif isinstance(indices, list):\n\t        result = indices\n\t    elif isinstance(indices, np.ndarray):\n\t        typ = \"ndarray:\" + \"x\".join(str(x) for x in indices.shape)\n\t        typ += \"x\" + indices.dtype.name\n\t        if indices.size == 0:\n\t            result = []\n\t        elif indices.ndim == 1 and indices.dtype.kind == \"i\":\n\t            result = indices\n", "    if result is None:\n\t        raise TypeError(\n\t            f\"The {what_for} must be given as int, list, or 1D int array, not {typ}.\"\n\t        )\n\t    result = np.asarray(result, np.int32)\n\t    if len(result) == 0:\n\t        raise ValueError(f\"The {what_for} must not be empty.\")\n\t    elif result.min() < 0:\n\t        raise ValueError(\"Negative indices not allowed.\")\n\t    elif result.max() >= n:\n", "        raise ValueError(\"Index out of bounds.\")\n\t    return result\n\tdef as_immutable_array(array):\n\t    \"\"\"Return a read-only view of the given array.\"\"\"\n\t    v = array.view()\n\t    v.setflags(write=False)\n\t    return v\n\tdef make_vertex2faces(faces, nverts=None):\n\t    \"\"\"Create a simple map to map vertex indices to a list of face indices.\"\"\"\n\t    faces = np.asarray(faces, np.int32)\n", "    if nverts is None:\n\t        nverts = faces.max() + 1\n\t    vertex2faces = [[] for _ in range(nverts)]\n\t    for fi in range(len(faces)):\n\t        face = faces[fi]\n\t        vertex2faces[face[0]].append(fi)\n\t        vertex2faces[face[1]].append(fi)\n\t        vertex2faces[face[2]].append(fi)\n\t    return vertex2faces\n"]}
{"filename": "gfxmorph/meshfuncs.py", "chunked_list": ["import queue\n\timport numpy as np\n\tfrom . import maybe_pylinalg\n\tfrom .utils import make_vertex2faces\n\tdef vertex_get_neighbours(faces, vertex2faces, vi):\n\t    \"\"\"Get a set of vertex indices that neighbour the given vertex index.\n\t    Connectedness is via the edges.\n\t    \"\"\"\n\t    neighbour_vertices = set()\n\t    for fi in vertex2faces[vi]:\n", "        neighbour_vertices.update(faces[fi])\n\t    neighbour_vertices.remove(vi)\n\t    return neighbour_vertices\n\tdef face_get_neighbours1(faces, vertex2faces, fi):\n\t    \"\"\"Get a set of face indices that neighbour the given face index.\n\t    Connectedness is either via an edge or via a vertex.\n\t    \"\"\"\n\t    neighbour_faces = set()\n\t    for vi in faces[fi]:\n\t        neighbour_faces.update(vertex2faces[vi])\n", "    neighbour_faces.remove(fi)\n\t    return neighbour_faces\n\tdef face_get_neighbours2(faces, vertex2faces, fi):\n\t    \"\"\"Get two sets of face indices that neighbour the given face index.\n\t    The first comprises of both vertex- and edge connections, the second\n\t    only consists of faces connected via an edge.\n\t    \"\"\"\n\t    neighbour_faces1 = set()\n\t    neighbour_faces2 = set()\n\t    for vi in faces[fi]:\n", "        for fi2 in vertex2faces[vi]:\n\t            if fi2 == fi:\n\t                pass\n\t            elif fi2 in neighbour_faces1:\n\t                neighbour_faces2.add(fi2)\n\t            else:\n\t                neighbour_faces1.add(fi2)\n\t    return neighbour_faces1, neighbour_faces2\n\tdef vertex_get_incident_face_groups(\n\t    faces, vertex2faces, vi_check, *, face_adjacency=None\n", "):\n\t    \"\"\"Get the groups of faces incident to the given vertex.\n\t    If there are zero groups, the vertex has no incident faces. If there\n\t    is exactly one group, the faces incident to the given vertex form\n\t    a (closed or open) fan. If there is more than one group, the mesh\n\t    is not manifold (and can be repaired by duplicating this vertex for\n\t    each group).\n\t    \"\"\"\n\t    #\n\t    #   Diagram 1           Diagram 2\n", "    #   _________                ____\n\t    #  |\\       /|              |   /|\n\t    #  | \\  D  / |              |D / |\n\t    #  |  \\   /  |              | /  |\n\t    #  |   \\ /   |              |/ C |\n\t    #  | B  O  C |              O----|\n\t    #  |   / \\   |              |\\ B |\n\t    #  |  /   \\  |              | \\  |\n\t    #  | /  A  \\ |              |A \\ |\n\t    #  |/_______\\|              |___\\|\n", "    #\n\t    #\n\t    #   Diagram 3           Diagram 4\n\t    #   _________                ____\n\t    #  |\\       /|              |   /|\n\t    #  | \\  D  / | _      _     |D / |\n\t    #  |  \\   / _|- |    | -._  | /  |\n\t    #  |   \\ /.- | E|    |E   -.|/ C |\n\t    #  | B  O----|--|    |------O----|\n\t    #  |   / \\ C |              |\\ B |\n", "    #  |  /   \\  |              | \\  |\n\t    #  | /  A  \\ |              |A \\ |\n\t    #  |/_______\\|              |___\\|\n\t    #\n\t    #\n\t    # In the two diagrams above, the vertex indicated by the big O is\n\t    # the reference vertex. On the left (diagram 1 and 3) we see a\n\t    # closed fan, and on the right (diagram 2 and 4) an open fan. In\n\t    # the top diagrams all is well, but in the bottom diagrams (3 and\n\t    # 4) there is an additional face E attached to the vertex, breaking\n", "    # the vertex-manifold condition. Note that it does not matter\n\t    # whether E is a lose vertex, part of a strip, or part of an\n\t    # (otherwise) manifold and closed component. Note also that E can\n\t    # even be a face on the same component that faces a-d are part of.\n\t    # That component can still be edge-manifold, closed, and oriented.\n\t    # Note that the algorithm below does not detect duplicate faces or\n\t    # edges with 3 incident faces. Therefore, to be be vertex-manifold,\n\t    # a mesh must *also* be edge-manifold.\n\t    faces_to_check = set(vertex2faces[vi_check])\n\t    groups = []\n", "    while faces_to_check:\n\t        group = []\n\t        groups.append(group)\n\t        fi_next = faces_to_check.pop()\n\t        front = queue.deque()\n\t        front.append(fi_next)\n\t        while front:\n\t            fi_check = front.popleft()\n\t            group.append(fi_check)\n\t            if face_adjacency is not None:\n", "                neighbour_faces2 = face_adjacency[fi_check]\n\t            else:\n\t                _, neighbour_faces2 = face_get_neighbours2(\n\t                    faces, vertex2faces, fi_check\n\t                )\n\t            for fi in neighbour_faces2:\n\t                if fi in faces_to_check:\n\t                    faces_to_check.remove(fi)\n\t                    front.append(fi)\n\t    return groups\n", "def mesh_is_edge_manifold_and_closed(faces):\n\t    \"\"\"Check whether the mesh is edge-manifold, and whether it is closed.\n\t    This implementation is based on vectorized numpy code and therefore very fast.\n\t    \"\"\"\n\t    # Special case\n\t    if len(faces) == 0:\n\t        return True, True\n\t    # Select edges\n\t    edges = faces[:, [[0, 1], [1, 2], [2, 0]]]\n\t    edges = edges.reshape(-1, 2)\n", "    edges.sort(axis=1)  # note, sorting!\n\t    # This line is the performance bottleneck. It is not worth\n\t    # combining this method with e.g. check_oriented, because this\n\t    # line needs to be applied to different data, so the gain would\n\t    # be about zero.\n\t    edges_blob = np.frombuffer(edges, dtype=\"V8\")  # performance trick\n\t    unique_blob, edge_counts = np.unique(edges_blob, return_counts=True)\n\t    # The mesh is edge-manifold if edges are shared at most by 2 faces.\n\t    is_edge_manifold = bool(edge_counts.max() <= 2)\n\t    # The mesh is closed if it has no edges incident to just once face.\n", "    # The following is equivalent to np.all(edge_counts == 2)\n\t    is_closed = is_edge_manifold and bool(edge_counts.min() == 2)\n\t    return is_edge_manifold, is_closed\n\tdef mesh_get_non_manifold_edges(faces):\n\t    \"\"\"Detect non-manifold edges.\n\t    These are returned as a dict ``(vi1, vi2) -> [fi1, fi2, ..]``.\n\t    It maps edges (pairs of vertex indices) to a list face indices incident\n\t    to that edge. I.e. to repair the edge, the faces incidense to each\n\t    edge can be removed. Afterwards, the nonmanifold vertices can be repaired,\n\t    followed by repairing the holes.\n", "    If the returned dictionary is empty, the mesh is edge-manifold. In\n\t    other words, for each edge there are either one or two incident\n\t    faces.\n\t    \"\"\"\n\t    # Special case\n\t    if len(faces) == 0:\n\t        return {}\n\t    edges = faces[:, [[0, 1], [1, 2], [2, 0]]]\n\t    edges = edges.reshape(-1, 2)\n\t    edges.sort(axis=1)  # note, sorting!\n", "    edges_blob = np.frombuffer(edges, dtype=\"V8\")  # performance trick\n\t    unique_blob, edge_counts = np.unique(edges_blob, return_counts=True)\n\t    # Code above is same as first part in mesh_is_edge_manifold_and_closed()\n\t    # Collect faces for each corrupt unique edge. This happens one by\n\t    # one. Maybe this can be vectorized, but it only hurts performance\n\t    # for corrupt meshes, so not a big deal.\n\t    nonmanifold_edges = {}\n\t    corrupt_indices = np.where(edge_counts > 2)[0]\n\t    for i in corrupt_indices:\n\t        eii = np.where(edges_blob == unique_blob[i])[0]\n", "        edge = tuple(edges[eii[0]])  # Eeach ei in eii refers to the same edge\n\t        fii = list(set(fi for fi in eii // 3))\n\t        nonmanifold_edges[edge] = fii\n\t    return nonmanifold_edges\n\tdef mesh_is_oriented(faces):\n\t    \"\"\"Check whether  the mesh is oriented. Also implies edge-manifoldness.\n\t    This implementation is based on vectorized numpy code and therefore very fast.\n\t    \"\"\"\n\t    # Special case\n\t    if len(faces) == 0:\n", "        return True\n\t    # Select edges. Note no sorting!\n\t    edges = faces[:, [[0, 1], [1, 2], [2, 0]]]\n\t    edges = edges.reshape(-1, 2)\n\t    # The magic line\n\t    edges_blob = np.frombuffer(edges, dtype=\"V8\")  # performance trick\n\t    _, edge_counts = np.unique(edges_blob, return_counts=True)\n\t    # If neighbouring faces have consistent winding, their edges\n\t    # are in opposing directions, so the unsorted edges should have\n\t    # no duplicates. Note that ths implies edge manifoldness,\n", "    # because if an edge is incident to more than 2 faces, one of\n\t    # the edges orientations would appear twice. The reverse is not\n\t    # necessarily true though: a mesh can be edge-manifold but not\n\t    # oriented.\n\t    is_oriented = bool(edge_counts.max() == 1)\n\t    return is_oriented\n\tdef mesh_get_volume(vertices, faces):\n\t    \"\"\"Calculate the volume of the mesh.\n\t    It is assumed that the mesh is oriented and closed. If not, the result does\n\t    not mean much. If the volume is negative, it is inside out.\n", "    This implementation is based on vectorized numpy code and therefore very fast.\n\t    \"\"\"\n\t    # Special case\n\t    if len(faces) == 0:\n\t        return 0\n\t    vertices = np.asarray(vertices, np.float32)\n\t    faces = np.asarray(faces, np.int32)\n\t    # This code is surprisingly fast, over 10x faster than the other\n\t    # checks. I also checked out skcg's computed_interior_volume,\n\t    # which uses Gauss' theorem of calculus, but that is\n", "    # considerably (~8x) slower.\n\t    return maybe_pylinalg.volume_of_closed_mesh(vertices, faces)\n\tdef mesh_get_surface_area(vertices, faces):\n\t    \"\"\"Calculate the surface area of the mesh.\"\"\"\n\t    vertices = np.asarray(vertices, np.float32)\n\t    faces = np.asarray(faces, np.int32)\n\t    r1 = vertices[faces[:, 0], :]\n\t    r2 = vertices[faces[:, 1], :]\n\t    r3 = vertices[faces[:, 2], :]\n\t    face_normals = np.cross((r2 - r1), (r3 - r1))  # assumes CCW\n", "    faces_areas = 0.5 * np.linalg.norm(face_normals, axis=1)\n\t    return faces_areas.sum()\n\tdef mesh_get_component_labels(faces, vertex2faces, *, via_edges_only=True):\n\t    \"\"\"Split the mesh in one or more connected components.\n\t    Returns a 1D array that contains component indices for all faces.\n\t    \"\"\"\n\t    # Performance notes:\n\t    # * Using a deque for the front increases performance a tiny bit.\n\t    # * Using set logic makes rather then control flow does not seem to matter much.\n\t    # * The labels that we're interested in we set directly in an array\n", "    #   so we avoid the step to go from set -> list -> array labels.\n\t    faces_to_check = set(range(len(faces)))\n\t    # Array to store component labels. (Using list vs array does not seem to affect performance.)\n\t    component_labels = np.empty((len(faces),), np.int32)\n\t    component_labels.fill(-1)\n\t    component_index = -1\n\t    while len(faces_to_check) > 0:\n\t        # Create new front - once for each connected component in the mesh\n\t        component_index += 1\n\t        fi_next = faces_to_check.pop()\n", "        front = queue.deque()\n\t        front.append(fi_next)\n\t        while front:\n\t            fi_check = front.popleft()\n\t            component_labels[fi_check] = component_index\n\t            if via_edges_only:\n\t                _, neighbour_faces = face_get_neighbours2(faces, vertex2faces, fi_check)\n\t            else:\n\t                neighbour_faces = face_get_neighbours1(faces, vertex2faces, fi_check)\n\t            for fi in neighbour_faces:\n", "                if fi in faces_to_check:\n\t                    faces_to_check.remove(fi)\n\t                    front.append(fi)\n\t    return component_labels\n\tdef mesh_get_non_manifold_vertices(faces, vertex2faces):\n\t    \"\"\"Detect non-manifold vertices.\n\t    These are returned as a dict ``vi -> [[fi1, fi2, ..], [fi3, fi4, ...]]``.\n\t    It maps vertex indices to a list of face-index-groups, each\n\t    representing a fan attached to the vertex. I.e. to repair the vertex,\n\t    a duplicate vertex must be created for each group (except one).\n", "    If the returned dictionary is empty, and the mesh is edge-manifold,\n\t    the mesh is also vertex-manifold. In other words, for each vertex,\n\t    the faces incident to that vertex form a closed or an open fan.\n\t    \"\"\"\n\t    # This implementation literally performs a test for each vertex.\n\t    # Since the per-vertex test involves querying neighbours a lot, it\n\t    # is somewhat slow. I've tried a few things to check\n\t    # vertex-manifoldness faster, without success. I'll summerize here\n\t    # for furure reference and maybe help others that walk a similar path:\n\t    #\n", "    # By splitting the mesh in connected components twice, once using\n\t    # vertex-connectedness, and once using edge-connectedness, it's\n\t    # easy to spot non-manifold edges in between components. It's even\n\t    # possible to do this in a single iteration! However, it does not\n\t    # reveal non-manifold vertices within components :/\n\t    #\n\t    # Then I tried a few ways to select suspicious faces/vertices during\n\t    # the algorithm that splits connected components, and then examine\n\t    # each suspicious vertex. Since that algorithm already walks over\n\t    # the surface of the mesh and requires information on the face\n", "    # neighbours, overhead can be combined/reused, basically resulting\n\t    # in getting the split components for free. That part works, but I\n\t    # have not been able to find a way to reliably select suspicious\n\t    # faces/vertices.\n\t    #\n\t    # One approach was to mark indirect neighbours (faces connected\n\t    # with only a vertex) as they were encountered, and unmark them\n\t    # when that face was seen again, but now as a direct neighbour (and\n\t    # via an edge that includes the suspicious vertex). Unfortunately,\n\t    # depending on the implementation details, this approach was either\n", "    # too permissive (missing corrupt vertices), slower than the brute\n\t    # force, or leaving so many false positives that you might as well\n\t    # use the brute force method.\n\t    #\n\t    # I was pretty fond of the idea to score each vertex based on its\n\t    # role in connecting neighbours for each face. For an indirect\n\t    # neighbour it scored negative points, for a direct neighbour it\n\t    # scored positive points. If the net score was negative, it was a\n\t    # suspicious vertex and examined properly. It was tuned so that it\n\t    # did not generates false positives for fans of 6 faces  (by scoring\n", "    # edge-neighbours 1.5 times higher). Interestingly, this method is\n\t    # able to reliably detect non-manifold vertices in a large variety\n\t    # of topologies. Unfortunately there are a few vertex-based\n\t    # fan-to-fan connections for which it fails. The example that\n\t    # explains this best is a fan of 3 faces connected to another fan\n\t    # of 3 faces. From the viewpoint of the face (annotated with 'a'\n\t    # below) this configuration is indiscernible from a closed 6-face\n\t    # fan. This means we cannot detect this case without generating a\n\t    # false positive for a *very* common type of fan.\n\t    #   __\n", "    #  |\\ | /|\n\t    #  |_\\|/_|\n\t    #  | /|\\a|\n\t    #  |/ |_\\|\n\t    #\n\t    # Conclusion: if we want a fast vertex-manifold check, we should\n\t    # probably just use Cython ...\n\t    # suspicious_vertices = np.unique(faces)\n\t    suspicious_vertices = set(faces.flat)\n\t    # Calculate face adjecency once beforehand, instead of 3x per face\n", "    face_adjacency = [None for _ in range(len(faces))]\n\t    for fi in range(len(faces)):\n\t        _, neighbour_faces2 = face_get_neighbours2(faces, vertex2faces, fi)\n\t        face_adjacency[fi] = neighbour_faces2\n\t    nonmanifold_vertices = {}\n\t    for vi in suspicious_vertices:\n\t        groups = vertex_get_incident_face_groups(\n\t            faces, vertex2faces, vi, face_adjacency=face_adjacency\n\t        )\n\t        if len(groups) > 1:\n", "            nonmanifold_vertices[vi] = groups\n\t    return nonmanifold_vertices\n\tdef mesh_get_boundaries(faces):\n\t    \"\"\"Select the boundaries of the mesh.\n\t    Returns a list of boundaries, where each boundary is a list of\n\t    vertices. Each boundary is a loop (the first and last vertex are\n\t    connected via a boundary edge), and the order of vertices is in the\n\t    appropriate winding direction.\n\t    This function can raise a RuntimeError if it runs into a part of\n\t    the mesh that is non-manifold.\n", "    \"\"\"\n\t    # Special case\n\t    if len(faces) == 0:\n\t        return []\n\t    faces = np.asarray(faces, np.int32)\n\t    # Select edges\n\t    edges = faces[:, [[0, 1], [1, 2], [2, 0]]]\n\t    edges = edges.reshape(-1, 2)\n\t    sorted_edges = np.sort(edges, axis=1)\n\t    # Find the unique edges\n", "    edges_blob = np.frombuffer(sorted_edges, dtype=\"V8\")  # performance trick\n\t    unique_blob, unique_index, edge_counts = np.unique(\n\t        edges_blob, return_index=True, return_counts=True\n\t    )\n\t    unique_edges = np.frombuffer(unique_blob, dtype=np.int32).reshape(-1, 2)\n\t    # Find the boundary edges: those that only have one incident face\n\t    (boundary_edge_indices,) = np.where(edge_counts == 1)\n\t    # Build map vi -> eii\n\t    nvertices = faces.max() + 1\n\t    vertex2edges = [[] for _ in range(nvertices)]\n", "    for ei in boundary_edge_indices:\n\t        vi1, vi2 = unique_edges[ei]\n\t        vertex2edges[vi1].append(ei)\n\t        vertex2edges[vi2].append(ei)\n\t    # Sanity check. Note that the mesh can still be non-manifold, as\n\t    # long as it's vertex-manifold along the boundaries, it's fine.\n\t    # Edge-manifoldness is less of an issue, because it means an edge\n\t    # has more than 2 faces, which makes it not a boundary anyway.\n\t    for vi in range(nvertices):\n\t        if len(vertex2edges[vi]) > 2:  # pragma: no cover\n", "            raise RuntimeError(\"The mesh is not vertex-manifold.\")\n\t    # Now group them into boundaries ...\n\t    #\n\t    # This looks a bit like the code we use to walk over the surface\n\t    # of the mesh, e.g. to find connected components. This is similar\n\t    # except we walk over boundaries (edges with just one incident\n\t    # face).\n\t    eii_to_check = set(boundary_edge_indices)\n\t    boundaries = []\n\t    while eii_to_check:\n", "        # Select arbitrary edge as starting point, and add both its edges to\n\t        # a list that we will build up further. The order of these initial\n\t        # vertices determines the direction that we walk in.\n\t        ei = ei_first = eii_to_check.pop()\n\t        original_edge = edges[unique_index[ei]]\n\t        boundary = [original_edge[1]]\n\t        boundaries.append(boundary)\n\t        while True:\n\t            # Get the two vertex indices on the current edge.\n\t            # One is the last added vertex, the other represents the direction\n", "            # we should move in.\n\t            vi1, vi2 = unique_edges[ei]\n\t            vi = vi2 if vi1 == boundary[-1] else vi1\n\t            boundary.append(vi)\n\t            # We look up what boundary-edges are incident to this vertex.\n\t            # One is the previous edge. the other will be the next.\n\t            ei1, ei2 = vertex2edges[vi]\n\t            ei = ei2 if ei1 == ei else ei1\n\t            # We either keep going, or have gone full circle\n\t            if ei in eii_to_check:\n", "                eii_to_check.remove(ei)\n\t            else:\n\t                if not (\n\t                    ei == ei_first and boundary[0] == boundary[-1]\n\t                ):  # pragma: no cover\n\t                    raise RuntimeError(\n\t                        \"This should not happen, but if it does, I think the mesh is not manifold.\"\n\t                    )\n\t                boundary.pop(-1)\n\t                break\n", "        # Sanity check for the algorithm below. It shows the assumptions\n\t        # that we make about the result, but that are (should be) true\n\t        # by the mesh being manifold and how the algorithm works.\n\t        # Can be uncommented when developing.\n\t        # edge_index = unique_index[ei]\n\t        # assert np.all(sorted_edges[edge_index] == unique_edges[ei])\n\t        # original_edge = edges[edge_index]\n\t        # assert boundary[0] == original_edge[1]\n\t        # assert boundary[1] == original_edge[0]\n\t    return boundaries\n", "def mesh_get_consistent_face_orientation(faces, vertex2faces):\n\t    \"\"\"Make the orientation of the faces consistent.\n\t    Returns a modified copy of the faces which may have some of the\n\t    faces flipped. Faces are flipped by swapping the 2nd and 3d value.\n\t    Note that the winding of the returned array may still not be\n\t    consistent, when the mesh is not manifold or when it is not\n\t    orientable (i.e. a Mobius strip or Klein bottle).\n\t    \"\"\"\n\t    # This implementation walks over the surface using a front. The\n\t    # algorithm is similar to the one for splitting the mesh in\n", "    # connected components, except it does more work at the deepest\n\t    # nesting.\n\t    #\n\t    # It starts out from one face, and reverses the neighboring\n\t    # faces that don't match the winding of the current face. And\n\t    # so on. Faces that have been been processed cannot be reversed\n\t    # again. So the fix operates as a wave that flows over the mesh,\n\t    # with the first face defining the winding.\n\t    #\n\t    # A closed form solution for this problem does not exist. The skcg\n", "    # lib uses pycosat to find the solution. The below might be slower\n\t    # (being implemented in pure Python), but it's free of dependencies\n\t    # and speed matters less in a repair function, I suppose.\n\t    # Make a copy of the faces, so we can reverse them in-place.\n\t    faces = faces.copy()\n\t    reversed_faces = []\n\t    faces_to_check = set(range(len(faces)))\n\t    while len(faces_to_check) > 0:\n\t        # Create new front - once for each connected component in the mesh\n\t        vi_next = faces_to_check.pop()\n", "        front = queue.deque()\n\t        front.append(vi_next)\n\t        # Walk along the front\n\t        while front:\n\t            fi_check = front.popleft()\n\t            vi1, vi2, vi3 = faces[fi_check]\n\t            _, neighbours = face_get_neighbours2(faces, vertex2faces, fi_check)\n\t            for fi in neighbours:\n\t                if fi in faces_to_check:\n\t                    faces_to_check.remove(fi)\n", "                    front.append(fi)\n\t                    vj1, vj2, vj3 = faces[fi]\n\t                    matching_vertices = {vj1, vj2, vj3} & {vi1, vi2, vi3}\n\t                    if len(matching_vertices) == 2:\n\t                        if vi3 not in matching_vertices:\n\t                            # vi1 in matching_vertices and vi2 in matching_vertices\n\t                            if (\n\t                                (vi1 == vj1 and vi2 == vj2)\n\t                                or (vi1 == vj2 and vi2 == vj3)\n\t                                or (vi1 == vj3 and vi2 == vj1)\n", "                            ):\n\t                                reversed_faces.append(fi)\n\t                                faces[fi, 1], faces[fi, 2] = (\n\t                                    faces[fi, 2],\n\t                                    faces[fi, 1],\n\t                                )\n\t                        elif vi1 not in matching_vertices:\n\t                            # vi2 in matching_vertices and vi3 in matching_vertices\n\t                            if (\n\t                                (vi2 == vj1 and vi3 == vj2)\n", "                                or (vi2 == vj2 and vi3 == vj3)\n\t                                or (vi2 == vj3 and vi3 == vj1)\n\t                            ):\n\t                                reversed_faces.append(fi)\n\t                                faces[fi, 1], faces[fi, 2] = (\n\t                                    faces[fi, 2],\n\t                                    faces[fi, 1],\n\t                                )\n\t                        elif vi2 not in matching_vertices:\n\t                            # vi3 in matching_vertices and vi1 in matching_vertices\n", "                            if (\n\t                                (vi3 == vj1 and vi1 == vj2)\n\t                                or (vi3 == vj2 and vi1 == vj3)\n\t                                or (vi3 == vj3 and vi1 == vj1)\n\t                            ):\n\t                                reversed_faces.append(fi)\n\t                                faces[fi, 1], faces[fi, 2] = (\n\t                                    faces[fi, 2],\n\t                                    faces[fi, 1],\n\t                                )\n", "        # If over half the faces were flipped, we flip the hole thing.\n\t        if len(reversed_faces) > 0.5 * len(faces):\n\t            tmp = faces[:, 2].copy()\n\t            faces[:, 2] = faces[:, 1]\n\t            faces[:, 1] = tmp\n\t        return faces\n\tdef mesh_stitch_boundaries(vertices, faces, *, atol=1e-5):\n\t    \"\"\"Stitch touching boundaries together by de-deuplicating vertices.\n\t    Stitching only happens when it does not result in a non-manifold\n\t    mesh. Returns the modified faces array.\n", "    It is up to the caller to remove collapsed faces and any vertices\n\t    that are no longer used.\n\t    \"\"\"\n\t    # Make a copy of the faces that we can modify\n\t    vertices = np.asarray(vertices, np.float32)\n\t    faces = np.asarray(faces, np.int32).copy()\n\t    # Detect boundaries. A list of vertex indices (vi's)\n\t    boundaries = mesh_get_boundaries(faces)\n\t    # Combine to get a subset of vertices for faster checking.\n\t    boundary_vertices = np.concatenate(boundaries)\n", "    boundary_positions = vertices[boundary_vertices]\n\t    # Keep track of what vi's were already handled as a duplicate\n\t    duplicate_mask = np.zeros((len(vertices),), bool)\n\t    # Create a mask so we can look up the boundary index from a vi\n\t    boundary_mask = np.empty((len(vertices),), np.int32)\n\t    boundary_mask.fill(-1)\n\t    for i, boundary in enumerate(boundaries):\n\t        boundary_mask[boundary] = i\n\t    # The deduplication can cause the mesh to become non-manifold.\n\t    # To prevent this we appy the changes in chunks and validate\n", "    # the change before it is applied. These \"chunks\" are groups\n\t    # of boundaries that connect. To handle these groups we use a\n\t    # stack-based algorithm simular to those used to traverse over\n\t    # the surface of the mesh.\n\t    boundary_indices_to_check = set(range(len(boundaries)))\n\t    while boundary_indices_to_check:\n\t        boundary_indices_in_this_group = [boundary_indices_to_check.pop()]\n\t        faces_for_this_group = faces.copy()\n\t        while boundary_indices_in_this_group:\n\t            boundary = boundaries[boundary_indices_in_this_group.pop(0)]\n", "            # The next two pieces of code are the heart of the algorithm,\n\t            # most of the rest is to apply the grouping and preventing non-manifoldness.\n\t            # Collect duplicate vertices.\n\t            duplicate_map = {}\n\t            for vi in boundary:\n\t                if not duplicate_mask[vi]:\n\t                    mask3 = np.isclose(\n\t                        boundary_positions, vertices[vi], atol=atol or 0, rtol=0\n\t                    )\n\t                    mask = mask3.sum(axis=1) == 3  # all el's of a vertex must match\n", "                    if mask.sum() > 1:\n\t                        vii = boundary_vertices[mask]\n\t                        duplicate_mask[vii] = True\n\t                        duplicate_map[vi] = vii\n\t            # Now we apply them to a copy of the faces array. Some heavy iterations here ...\n\t            for vi1, vii in duplicate_map.items():\n\t                for vi2 in vii:\n\t                    if vi2 != vi1:\n\t                        faces_for_this_group[faces == vi2] = vi1\n\t            # See if we need to process more boundaries in this group\n", "            group = set()\n\t            for vii in duplicate_map.values():\n\t                group.update(boundary_mask[vii])\n\t            group = group & boundary_indices_to_check\n\t            boundary_indices_to_check.difference_update(group)\n\t            boundary_indices_in_this_group.extend(group)\n\t        # We've now processed one group of boundaries ...\n\t        # Check whether the new face array is manifold, taking collapsed faces into account\n\t        not_collapsed = np.array(\n\t            [len(set(f)) == len(f) for f in faces_for_this_group], bool\n", "        )\n\t        tmp_faces = faces_for_this_group[not_collapsed]\n\t        v2f = make_vertex2faces(tmp_faces)\n\t        is_edge_manifold, _ = mesh_is_edge_manifold_and_closed(tmp_faces)\n\t        non_manifold_verts = mesh_get_non_manifold_vertices(tmp_faces, v2f)\n\t        is_manifold = is_edge_manifold and not non_manifold_verts\n\t        # If it is, apply!\n\t        if is_manifold:\n\t            faces = faces_for_this_group\n\t    return faces\n"]}
{"filename": "gfxmorph/tracker.py", "chunked_list": ["import numpy as np\n\tclass MeshChangeTracker:\n\t    \"\"\"Base class for tracking changes of a BaseDynamicMesh.\n\t    To track changes, create a subclass and implementing (a subset of)\n\t    its methods. The instance of the subclass can then be subscribed\n\t    using ``dynamic_mesh.track_changes()`` to receive updates.\n\t    The methods of this class are called at specific events. Together\n\t    they (hopefully) provide an API to adequately track changes for a\n\t    number of use-cases. Such use-cases may include e.g. logging,\n\t    keeping an undo stack, and updating a GPU representation of the\n", "    mesh.\n\t    \"\"\"\n\t    def init(self, mesh):\n\t        \"\"\"Called when the tracker is subscribed to the mesh.\n\t        This enables a tracker to properly reset as needed, or e.g.\n\t        prevent registering to multiple meshes, etc.\n\t        You may want to take into account that the mesh already has\n\t        vertices and faces at the moment that the tracker is subscribed.\n\t        \"\"\"\n\t        pass\n", "    # API that is the same as changes to BaseDynamicMesh, except for the `old` argument\n\t    def add_faces(self, faces):\n\t        \"\"\"Called when faces are added to the mesh.\n\t        Same signature as ``DynamicMesh.add_faces``.\n\t        \"\"\"\n\t        pass\n\t    def pop_faces(self, n, old):\n\t        \"\"\"Called when faces are are removed from the mesh.\n\t        Same signature as ``DynamicMesh.pop_faces``, except for the ``old`` arg.\n\t        Note that calling ``delete_faces()`` on the mesh results in a\n", "        ``swap_faces()`` and a ``pop_faces()``.\n\t        \"\"\"\n\t        pass\n\t    def swap_faces(self, indices1, indices2):\n\t        \"\"\"Called when the mesh swaps faces (to keep the arrays contiguous).\n\t        Same signature as ``DynamicMesh.swap_faces``.\n\t        \"\"\"\n\t        pass\n\t    def update_faces(self, indices, faces, old):\n\t        \"\"\"Called when faces are are updated.\n", "        Same signature as ``DynamicMesh.update_faces``, except for the ``old`` arg.\n\t        \"\"\"\n\t        pass\n\t    def add_vertices(self, positions):\n\t        \"\"\"Called when vertices are added to the mesh.\n\t        Same signature as ``DynamicMesh.add_vertices``.\n\t        \"\"\"\n\t        pass\n\t    def pop_vertices(self, n, old):\n\t        \"\"\"Called when vertices are are removed from the mesh.\n", "        Same signature as ``DynamicMesh.pop_vertices``, except for the ``old`` arg.\n\t        Note that calling ``delete_vertices()`` on the mesh results in a\n\t        ``swap_vertices()`` and a ``pop_vertices()``.\n\t        \"\"\"\n\t        pass\n\t    def swap_vertices(self, indices1, indices2):\n\t        \"\"\"Called when the mesh swaps vertices (to keep the arrays contiguous).\n\t        Same signature as ``DynamicMesh.swap_vertices``.\n\t        \"\"\"\n\t        pass\n", "    def update_vertices(self, indices, positions, old):\n\t        \"\"\"Called when vertices are are updated.\n\t        Same signature as ``DynamicMesh.update_vertices``, except for the ``old`` arg.\n\t        \"\"\"\n\t        pass\n\t    # Bit of additional API, leaning somewhat towards GPU usage\n\t    def new_faces_buffer(self, mesh):\n\t        \"\"\"Called when a new buffer is allocated to store the faces.\n\t        This happens when more memory is needed to store the faces, or\n\t        when faces are deleted and the buffer can be made smaller.\n", "        The mesh is passed as an argument so the tracker has full access\n\t        to it to address this situation. The new buffer array can be\n\t        obtained via ``mesh.faces.base``.\n\t        \"\"\"\n\t        pass\n\t    def new_vertices_buffer(self, mesh):\n\t        \"\"\"Called when new buffers are allocated to store the vertices.\n\t        This happens when more memory is needed to store the vertices\n\t        (positions and normals), or when vertices are deleted and the\n\t        buffers can be made smaller.\n", "        The mesh is passed as an argument so the tracker has full access\n\t        to it to address this situation. The new buffer array can be\n\t        obtained via ``mesh.positions.base``.\n\t        \"\"\"\n\t        pass\n\t    def update_normals(self, indices):\n\t        \"\"\"Called when the given normals have changed.\n\t        It's not enought to use ``update_vertices``, because when a vertex\n\t        position changes, it also affects the normals of neighbouring vertices.\n\t        For reasons of performance and simplicity, the new normals are\n", "        not provided as an argument. If needed, store the normals buffer in\n\t        ``new_vertices_buffer`` and then sample the values from that.\n\t        \"\"\"\n\t        pass\n\tclass MeshLogger(MeshChangeTracker):\n\t    \"\"\"A simple logger that produces textual messages about changes to the mesh.\"\"\"\n\t    def __init__(self, print_func):\n\t        self.print = print_func\n\t    def add_faces(self, faces):\n\t        self.print(f\"Adding {len(faces)} faces.\")\n", "    def pop_faces(self, n, old):\n\t        self.print(f\"Removing {n} faces.\")\n\t    def update_faces(self, indices, faces, old):\n\t        self.print(f\"Updating {len(indices)} faces.\")\n\t    def add_vertices(self, positions):\n\t        self.print(f\"Adding {len(positions)} vertices.\")\n\t    def pop_vertices(self, n, old):\n\t        self.print(f\"Removing {n} vertices.\")\n\t    def update_vertices(self, indices, positions, old):\n\t        self.print(f\"Updating {len(indices)} vertices.\")\n", "class MeshUndoTracker(MeshChangeTracker):\n\t    \"\"\"A mesh change tracker functioning as an undo stack.\n\t    To create a new version, call ``commit()``. The new version contains\n\t    all changes since the last commit. It is recommended to make commits\n\t    by using this object as a context manager. It will then prevent\n\t    (unintended) commits until the context exits.\n\t    \"\"\"\n\t    def init(self, mesh):\n\t        self._work_in_progress = False\n\t        self._pending = []\n", "        self._undo = []\n\t        self._redo = []\n\t        self._stack_level = 0\n\t    def __enter__(self):\n\t        # Can re-enter, but only the first context counts\n\t        self._stack_level += 1\n\t        return self\n\t    def __exit__(self, *args):\n\t        self._stack_level -= 1\n\t        if self._stack_level <= 0:\n", "            self._stack_level = 0\n\t            self.commit()\n\t    def add_faces(self, faces):\n\t        self._append((\"pop_faces\", len(faces)))\n\t    def pop_faces(self, n, old):\n\t        self._append((\"add_faces\", old))\n\t    def swap_faces(self, indices1, indices2):\n\t        self._append((\"swap_faces\", indices2, indices1))\n\t    def update_faces(self, indices, faces, old):\n\t        self._append((\"update_faces\", indices, old))\n", "    def add_vertices(self, positions):\n\t        self._append((\"pop_vertices\", len(positions)))\n\t    def pop_vertices(self, n, old):\n\t        self._append((\"add_vertices\", old))\n\t    def swap_vertices(self, indices1, indices2):\n\t        self._append((\"swap_vertices\", indices2, indices1))\n\t    def update_vertices(self, indices, positions, old):\n\t        self._append((\"update_vertices\", indices, old))\n\t    def _append(self, step):\n\t        # See if we can merge.\n", "        # A common case is that the mesh is deformed interactively,\n\t        # resulting in many updates to the same set of vertices. We can\n\t        # easily detect this case. We can then simply drop the new\n\t        # update, because the previous undo-step undoes it up to the\n\t        # beginning.\n\t        if len(self._pending) > 0:\n\t            last_step = self._pending[-1]\n\t            if step[0] == \"update_vertices\" and last_step[0] == \"update_vertices\":\n\t                indices, last_indices = step[1], last_step[1]\n\t                # If the application uses the same i32 ndarray to update the vertices,\n", "                # we can make this test fast. Otherwise, we need to testa bit more.\n\t                if indices is last_indices:\n\t                    return\n\t                elif len(indices) == len(last_indices):\n\t                    if np.all(indices == last_indices):\n\t                        return\n\t        # Add to staging list\n\t        self._pending.append(step)\n\t    def get_version(self):\n\t        \"\"\"Get the current 'version' of the mesh.\n", "        The version is an integer that increases with each version.\n\t        \"\"\"\n\t        return len(self._undo)\n\t    def has_pending_changes(self):\n\t        \"\"\"Get whether there are pending changes that can be comitted or cancelled.\"\"\"\n\t        return len(self._pending) > 0\n\t    def commit(self):\n\t        \"\"\"Save the current state as a new version, and return the new version number.\n\t        In other words, this commits the pending changes to the undo stack.\n\t        If the object is currently used as a context, this does nothing.\n", "        \"\"\"\n\t        if not (self._work_in_progress or self._stack_level > 0):\n\t            self._undo.append(self._pending)\n\t            self._pending = []\n\t            self._redo.clear()\n\t        return self.get_version()\n\t    def cancel(self, dynamic_mesh):\n\t        \"\"\"Cancel any uncommited changes.\n\t        Pending changes are lost.\n\t        \"\"\"\n", "        if self._pending and not self._work_in_progress:\n\t            dummy_target = []\n\t            steps = self._pending\n\t            self._pending = []\n\t            self._do(dynamic_mesh, steps, dummy_target)\n\t        else:\n\t            self._pending = []\n\t    def undo(self, dynamic_mesh):\n\t        \"\"\"Undo the changes of the last comitted version.\n\t        If there are pending changes, these are cancelled first. The\n", "        mesh is then reverted to the previous version (the version\n\t        before the last committed version). If the undo-stack is empty\n\t        (i.e. there are no changes to undo), this step does nothing.\n\t        \"\"\"\n\t        self.apply_version(dynamic_mesh, self.get_version() - 1)\n\t    def redo(self, dynamic_mesh):\n\t        \"\"\"Redo the last undone change.\n\t        If there are pending changes, these are cancelled first. The\n\t        mesh is then reverted to the version that was last undo. If the\n\t        redo-stack is empty (i.e. if a new commit has been made since\n", "        the last undo) this step does nothing.\n\t        \"\"\"\n\t        self.apply_version(dynamic_mesh, self.get_version() + 1)\n\t    def apply_version(self, dynamic_mesh, version):\n\t        \"\"\"Apply the given version.\n\t        If there are pending changes, these are cancelled first. If the\n\t        version is either the current version or out of range, this\n\t        step does nothing. The given mesh must be the same as the mesh\n\t        being tracked.\n\t        \"\"\"\n", "        if self._stack_level > 0:\n\t            raise RuntimeError(\n\t                \"Cannot undo/redo while the MeshUndoTracker is used as a context.\"\n\t            )\n\t        self.cancel(dynamic_mesh)\n\t        while self._undo and version < len(self._undo):\n\t            self._do(dynamic_mesh, self._undo.pop(-1), self._redo)\n\t        while self._redo and version > len(self._undo):\n\t            self._do(dynamic_mesh, self._redo.pop(-1), self._undo)\n\t    def _do(self, dynamic_mesh, steps, target):\n", "        assert len(self._pending) == 0\n\t        self._work_in_progress = True\n\t        try:\n\t            for step in reversed(steps):\n\t                method_name, *args = step\n\t                f = getattr(dynamic_mesh, method_name)\n\t                f(*args)\n\t        finally:\n\t            target.append(self._pending)\n\t            self._pending = []\n", "            self._work_in_progress = False\n\t# class MeshUndoTracker(MeshChangeTracker):\n\t#     \"\"\"A mesh change tracker functioning as an undo stack.\"\"\"\n\t#\n\t#     def init(self, mesh):\n\t#         # self._doing = None\n\t#         self._undo = []\n\t#         self._redo = []\n\t#         self._stack = None\n\t#         self._stack_level = 0\n", "#\n\t#     def __enter__(self):\n\t#         # Can re-enter, but only the first context counts\n\t#         self._stack_level += 1\n\t#         if self._stack is None:\n\t#             self._stack = []\n\t#         return self\n\t#\n\t#     def __exit__(self, *args):\n\t#         self._stack_level -= 1\n", "#         if self._stack_level <= 0:\n\t#             self._stack_level = 0\n\t#             if self._stack is not None:\n\t#                 if len(self._stack):\n\t#                     self._undo.append(self._stack)\n\t#                     self._redo.clear()\n\t#                 self._stack = None\n\t#\n\t#     def add_faces(self, faces):\n\t#         self._append((\"pop_faces\", len(faces)))\n", "#\n\t#     def pop_faces(self, n, old):\n\t#         self._append((\"add_faces\", old))\n\t#\n\t#     def swap_faces(self, indices1, indices2):\n\t#         self._append((\"swap_faces\", indices2, indices1))\n\t#\n\t#     def update_faces(self, indices, faces, old):\n\t#         self._append((\"update_faces\", indices, old))\n\t#\n", "#     def add_vertices(self, positions):\n\t#         self._append((\"pop_vertices\", len(positions)))\n\t#\n\t#     def pop_vertices(self, n, old):\n\t#         self._append((\"add_vertices\", old))\n\t#\n\t#     def swap_vertices(self, indices1, indices2):\n\t#         self._append((\"swap_vertices\", indices2, indices1))\n\t#\n\t#     def update_vertices(self, indices, positions, old):\n", "#         self._append((\"update_vertices\", indices, old))\n\t#\n\t#     def _append(self, step):\n\t#         if self._stack is None:\n\t#             # If there is no active stack, we simply add the one step to the undo list.\n\t#             # create a new stack, add to that, add to undo.\n\t#             self._undo.append([step])\n\t#             self._redo.clear()\n\t#\n\t#         else:\n", "#             # See if we can merge\n\t#             if len(self._stack) > 0:\n\t#                 last_step = self._stack[-1]\n\t#                 if last_step[0] == \"update_vertices\" and step[0] == \"update_vertices\":\n\t#                     print(last_step[1].__class__.__name__, step[1].__class__.__name__, last_step[1] is step[1])\n\t#\n\t#             self._stack.append(step)\n\t#\n\t#     def get_version(self):\n\t#         \"\"\"Get the current 'version' of the mesh.\"\"\"\n", "#         return len(self._undo)\n\t#\n\t#     def apply_version(self, dynamic_mesh, version):\n\t#         \"\"\"Apply the given version. The given mesh must be the same as the mesh being tracked.\"\"\"\n\t#         if self._stack is not None:\n\t#             raise RuntimeError(\"Cannot undo/redo while under a context.\")\n\t#         while self._undo and version < len(self._undo):\n\t#             self._do(dynamic_mesh, self._undo.pop(-1), self._redo)\n\t#         while self._redo and version > len(self._undo):\n\t#             self._do(dynamic_mesh, self._redo.pop(-1), self._undo)\n", "#\n\t#     def _do(self, dynamic_mesh, steps, target):\n\t#         assert self._stack is None\n\t#         self._stack = []\n\t#         try:\n\t#             for step in reversed(steps):\n\t#                 method_name, *args = step\n\t#                 f = getattr(dynamic_mesh, method_name)\n\t#                 f(*args)\n\t#         finally:\n", "#             target.append(self._stack)\n\t#             self._stack = None\n\t#\n\t#     def undo(self, dynamic_mesh):\n\t#         \"\"\"Undo the last change.\n\t#\n\t#         This is more of an example, because in practice one \"step\" from\n\t#         the application point of view likely consists of multiple raw steps.\n\t#         \"\"\"\n\t#         self.apply_version(dynamic_mesh, self.get_version() - 1)\n", "#\n\t#     def redo(self, dynamic_mesh):\n\t#         \"\"\"Redo the last undone change.\"\"\"\n\t#         self.apply_version(dynamic_mesh, self.get_version() + 1)\n\t#\n\t#\n\t#     def collect(self):\n\t#         self._stack = []\n\t#\n\t#     def append_last(self):\n", "#         if self._undo:\n\t#             self._stack = self._undo.pop()\n\t#\n\t#     def merge_last(self):\n\t#         if len(self._undo) < 2:\n\t#             return\n\t#\n\t#         steps1 = self._undo[-2]  # Second to last -> the new last\n\t#         steps2 = self._undo.pop(-1)  # Last\n\t#\n", "#         laststep = steps1[-1]\n\t#         # for step in steps2:\n\t#\n\t#         steps1.extend(steps2)\n\t#         print(len(steps1))\n\t# Commented, because we cannot have a reference to DynamicMesh because\n\t# of circular imports. But this is all we need to create a mesh that\n\t# replicates another. Probably a useless use-case, but it does\n\t# illustrate the elegance of the change tracker API.\n\t#\n", "# class ReplicatingMesh(DynamicMesh, MeshChangeTracker):\n\t#     pass\n"]}
{"filename": "gfxmorph/mesh.py", "chunked_list": ["# ## Developer notes\n\t#\n\t# Our internal arrays are larger than needed - we have free slots. This\n\t# is because we must be able to dynamically add and remove vertices and\n\t# faces.\n\t# We always make a copy of the given data:\n\t# - so we control the dtype.\n\t# - we will change the values, avoid surprises by modifying given arrays.\n\t# - we need the first vertex to be empty. ---> not anymore\n\t# - we may want to initialize with some extra size.\n", "#\n\t# Vertex indices are denoted with vi, face indices with fi.\n\timport numpy as np\n\tfrom .basedynamicmesh import BaseDynamicMesh\n\t# from .maybe_pylinalg import ()\n\t# from .maybe_pygfx import ()\n\tfrom . import meshfuncs\n\tclass DynamicMesh(BaseDynamicMesh):\n\t    \"\"\"Representation of a mesh, with utilities to modify it.\n\t    In addition to BaseDynamicMesh, this class adds higher level logic\n", "    to detect certain properties of the mesh, make repairs, and other\n\t    (higher level) modifications.\n\t    \"\"\"\n\t    def __init__(self, positions, faces):\n\t        super().__init__()\n\t        # Delegate initialization\n\t        if positions is not None or faces is not None:\n\t            self.add_mesh(positions, faces)\n\t    @property\n\t    def component_labels(self):\n", "        \"\"\"A tuple of connected components that this mesh consists of.\"\"\"\n\t        cache = self._cache_depending_on_faces\n\t        key = \"component_labels\"\n\t        if key not in cache:\n\t            cache[key] = meshfuncs.mesh_get_component_labels(\n\t                self.faces, self.vertex2faces\n\t            )\n\t        return cache[key]\n\t    @property\n\t    def component_count(self):\n", "        \"\"\"The number of components that this mesh consists of.\"\"\"\n\t        # Note that connectedness is defined as going via edges, not vertices.\n\t        return self.component_labels.max() + 1\n\t    @property\n\t    def is_connected(self):\n\t        \"\"\"Whether the mesh is a single connected component.\"\"\"\n\t        return self.component_count == 1\n\t    @property\n\t    def is_edge_manifold(self):\n\t        \"\"\"Whether the mesh is edge-manifold.\n", "        A mesh being edge-manifold means that each edge is part of\n\t        either 1 or 2 faces. It is one of the two condition for a mesh\n\t        to be manifold.\n\t        \"\"\"\n\t        cache = self._cache_depending_on_faces\n\t        key = \"nonmanifold_edges\"\n\t        if key not in cache:\n\t            cache[key] = meshfuncs.mesh_get_non_manifold_edges(self.faces)\n\t        return len(cache[key]) == 0\n\t    @property\n", "    def is_vertex_manifold(self):\n\t        \"\"\"Whether the mesh is vertex-manifold.\n\t        A mesh being vertex-manifold means that for each vertex, the\n\t        faces incident to that vertex form a single (closed or open)\n\t        fan. It is one of the two condition for a mesh to be manifold.\n\t        In contrast to edge-manifoldness, a mesh being non-vertex-manifold,\n\t        can still be closed and oriented.\n\t        \"\"\"\n\t        cache = self._cache_depending_on_faces\n\t        key = \"nonmanifold_vertices\"\n", "        if key not in cache:\n\t            cache[key] = meshfuncs.mesh_get_non_manifold_vertices(\n\t                self.faces, self.vertex2faces\n\t            )\n\t        return self.is_edge_manifold and len(cache[key]) == 0\n\t    @property\n\t    def is_manifold(self):\n\t        \"\"\"Whether the mesh is manifold (both edge- and vertex-manifold).\"\"\"\n\t        return self.is_edge_manifold and self.is_vertex_manifold\n\t    @property\n", "    def is_closed(self):\n\t        \"\"\"Whether the mesh is closed.\n\t        A closed mesh has 2 faces incident to all its edges. This\n\t        implies that the mesh is edge-manifold, and has no boundary\n\t        edges.\n\t        \"\"\"\n\t        cache = self._cache_depending_on_faces\n\t        key = \"is_closed\"\n\t        if key not in cache:\n\t            _, is_closed = meshfuncs.mesh_is_edge_manifold_and_closed(self.faces)\n", "            cache[key] = is_closed\n\t        return cache[key]\n\t    @property\n\t    def is_oriented(self):\n\t        \"\"\"Whether the mesh is orientable.\n\t        The mesh being orientable means that the face orientation (i.e.\n\t        winding) is consistent - each two neighbouring faces have the\n\t        same orientation. This can only be true if the mesh is edge-manifold.\n\t        \"\"\"\n\t        cache = self._cache_depending_on_faces\n", "        key = \"is_oriented\"\n\t        if key not in cache:\n\t            cache[key] = meshfuncs.mesh_is_oriented(self.faces)\n\t        return cache[key]\n\t    @property\n\t    def edges(self):\n\t        \"\"\"All edges of this mesh as pairs of vertex indices\n\t        Returns\n\t        -------\n\t        ndarray, [n_faces, 3, 2]\n", "            pairs of vertex-indices specifying an edge.\n\t            the ith edge is the edge opposite from the ith vertex of the face\n\t        \"\"\"\n\t        array = self.faces[:, [[0, 1], [1, 2], [2, 0]]].reshape(-1, 2)\n\t        array.setflags(write=False)\n\t        return array\n\t    @property\n\t    def metadata(self):\n\t        \"\"\"A dict with metadata about the mesh.\"\"\"\n\t        arrays = (\n", "            self._faces_buf,\n\t            self._positions_buf,\n\t            self._normals_buf,\n\t        )\n\t        nb = sum([a.nbytes for a in arrays if a is not None])\n\t        mem = f\"{nb/2**20:0.2f} MiB\" if nb > 2**20 else f\"{nb/2**10:0.2f} KiB\"\n\t        return {\n\t            \"is_edge_manifold\": self.is_edge_manifold,\n\t            \"is_vertex_manifold\": self.is_vertex_manifold,\n\t            \"is_closed\": self.is_closed,\n", "            \"is_oriented\": self.is_oriented,\n\t            \"nfaces\": len(self._faces),\n\t            \"nvertices\": len(self._positions),\n\t            \"free_vertices\": len(self._positions_buf) - len(self._positions),\n\t            \"free_faces\": len(self._faces_buf) - len(self._faces),\n\t            \"approx_mem\": mem,\n\t        }\n\t    # %%\n\t    def get_surface_area(self):\n\t        \"\"\"Get the surface area of the mesh.\"\"\"\n", "        return meshfuncs.mesh_get_surface_area(self.positions, self.faces)\n\t    def get_volume(self):\n\t        \"\"\"Get the volume of the mesh.\n\t        CCW winding is assumed. If this is negative, the mesh is\n\t        probably inside-out. If the mesh is not manifold, oriented, and closed,\n\t        this method raises an error.\n\t        \"\"\"\n\t        if not (self.is_manifold and self.is_oriented and self.is_closed):\n\t            raise RuntimeError(\n\t                \"Cannot get volume of a mesh that is not manifold, oriented and closed.\"\n", "            )\n\t        return meshfuncs.mesh_get_volume(self.positions, self.faces)\n\t    def add_mesh(self, positions, faces):\n\t        \"\"\"Add a (partial) mesh.\n\t        The vertices and faces are appended to the end. The values of\n\t        the faces are modified to still target the appropriate vertices\n\t        (which may now have an offset).\n\t        \"\"\"\n\t        faces = np.asarray(faces, np.int32)\n\t        # The DynamicMesh class also does some checks, but it will\n", "        # only check if incoming faces match any vertex, not just the\n\t        # ones we add here, so we perform that check here.\n\t        if faces.min() < 0 or faces.max() >= len(positions):\n\t            raise ValueError(\n\t                \"The faces array containes indices that are out of bounds.\"\n\t            )\n\t        vertex_index_offset = len(self._positions)\n\t        self.add_vertices(positions)\n\t        self.add_faces(faces + vertex_index_offset)\n\t    # %% Repairs\n", "    def repair(self, close=False):\n\t        \"\"\"Perform various repairs to the mesh.\n\t        If close is given and True, also try to close the mesh. The\n\t        resulting mesh is guaranteed to be manifold, but may not be\n\t        closed. It will be oriented if the topology allows it (e.g. not\n\t        a Klein bottle).\n\t        \"\"\"\n\t        self.repair_manifold()\n\t        if close:\n\t            self.repair_touching_boundaries()\n", "            self.repair_holes()\n\t        self.repair_orientation()\n\t        self.remove_unused_vertices()\n\t    def repair_manifold(self):\n\t        \"\"\"Repair the mesh to make it manifold.\n\t        This method includes a number of steps:\n\t        * Remove collapsed faces.\n\t        * Remove duplicate faces.\n\t        * Remove faces incident to edges that have more than 2 incident faces.\n\t        * Duplicate non-manifold vertices and assign them to the respective faces.\n", "        The result is always a manifold mesh, but it may have less faces\n\t        (it could even be empty) and the mesh may have holes where it\n\t        previously attached to other parts of the mesh.\n\t        Returns the number of deleted/updated faces.\n\t        \"\"\"\n\t        n_updated = 0\n\t        if self.is_manifold:\n\t            return n_updated\n\t        # Remove collapsed faces. A collapsed face results in the mesh\n\t        # being either not vertex- or not edge- manifold, depending on\n", "        # whether it is at a boundary.\n\t        collapsed_faces = np.array([len(set(f)) != len(f) for f in self.faces], bool)\n\t        (indices,) = np.where(collapsed_faces)\n\t        if len(indices):\n\t            self.delete_faces(indices)\n\t            n_updated += len(indices)\n\t        # Remove duplicate faces.\n\t        sorted_buf = np.frombuffer(np.sort(self.faces, axis=1), dtype=\"V12\")\n\t        unique_buf, counts = np.unique(sorted_buf, axis=0, return_counts=True)\n\t        duplicate_values = unique_buf[counts > 1]\n", "        indices = []\n\t        for value in duplicate_values:\n\t            (indices_for_value,) = np.where(sorted_buf == value)\n\t            indices.extend(indices_for_value[1:])\n\t        if len(indices):\n\t            self.delete_faces(indices)\n\t            n_updated += len(indices)\n\t        # Remove non-manifold edges.\n\t        # Use the is_edge_manifold prop to trigger 'nonmanifold_edges' to be up to date.\n\t        if not self.is_edge_manifold:\n", "            nonmanifold_edges = self._cache_depending_on_faces[\"nonmanifold_edges\"]\n\t            indices = []\n\t            for edge, fii in nonmanifold_edges.items():\n\t                indices.extend(fii)\n\t            if len(indices):\n\t                self.delete_faces(indices)\n\t                n_updated += len(indices)\n\t        # Fix non-manifold vertices.\n\t        # Non-manifold vertices are vertices who's incident faces do not\n\t        # form a single (open or closed) fan. It's tricky to find such\n", "        # vertices, but it's easy to repair them, once found. The vertices\n\t        # are duplicated and assigned to the respective fans.\n\t        # Use the is_vertex_manifold prop to trigger 'nonmanifold_edges' to be up to date.\n\t        if not self.is_vertex_manifold:\n\t            # We update each group individually. It may be more efficient\n\t            # to collect changes, but it'd also make the code more complex.\n\t            # Note that we can safely do this because no vertices/faces are\n\t            # deleted in this process, so the indices in\n\t            # 'nonmanifold_vertices' remain valid.\n\t            nonmanifold_vertices = self._cache_depending_on_faces[\n", "                \"nonmanifold_vertices\"\n\t            ]\n\t            for vi, groups in nonmanifold_vertices.items():\n\t                assert len(groups) >= 2\n\t                for face_indices in groups[1:]:\n\t                    # Add vertex\n\t                    self.add_vertices([self._positions[vi]])\n\t                    vi2 = len(self._positions) - 1\n\t                    # Update faces\n\t                    faces = self.faces[face_indices, :]\n", "                    faces[faces == vi] = vi2\n\t                    self.update_faces(face_indices, faces)\n\t                    n_updated += len(face_indices)\n\t        return n_updated\n\t    def repair_orientation(self):\n\t        \"\"\"Repair the winding of individual faces to make the mesh oriented.\n\t        Faces that do not match the winding of their neighbours are\n\t        flipped in a recursive algorithm. If the mesh is a close and\n\t        oriented manifold, but it has a negative volume, all faces are\n\t        flipped.\n", "        The repair can only fail if the mesh is not manifold or when\n\t        it is not orientable (i.e. a Mobius strip or Klein bottle).\n\t        Returns the number of faces that are flipped.\n\t        \"\"\"\n\t        n_flipped = 0\n\t        if not self.is_oriented:\n\t            # Try making the winding consistent\n\t            modified_faces = meshfuncs.mesh_get_consistent_face_orientation(\n\t                self.faces, self.vertex2faces\n\t            )\n", "            (indices,) = np.where(modified_faces[:, 2] != self.faces[:, 2])\n\t            if len(indices) > 0:\n\t                self.update_faces(indices, modified_faces[indices])\n\t            n_flipped = len(indices)\n\t        # Reverse all the faces if this is an oriented closed manifold with a negative volume.\n\t        if self.is_manifold and self.is_oriented and self.is_closed:\n\t            if self.get_volume() < 0:\n\t                new_faces = self.faces.copy()\n\t                tmp = new_faces[:, 2].copy()\n\t                new_faces[:, 2] = new_faces[:, 1]\n", "                new_faces[:, 1] = tmp\n\t                indices = np.arange(len(new_faces), dtype=np.int32)\n\t                self.update_faces(indices, new_faces)\n\t                n_flipped = len(new_faces)\n\t        return n_flipped\n\t    def repair_touching_boundaries(self, *, atol=1e-5):\n\t        \"\"\"Repair open meshes by stitching boundary vertices that are close together.\n\t        Vertices (on boundaries) that are the same or close together\n\t        (according to the given tolerance) are de-duplicated, thereby\n\t        stitching the mesh parts together. The purpose is for meshes\n", "        that are visually closed but mathematically open, to become\n\t        mathematically closed.\n\t        There is no guarantee that this results in a closed mesh,\n\t        because that depends entirely on the presence of near-touching\n\t        boundaries. If the stitching of a group of boundaries would\n\t        result in a non-manifold mesh, it is skipped. (So it should be\n\t        safe to call this method.)\n\t        Returns the number of updated faces.\n\t        \"\"\"\n\t        if self.is_closed:\n", "            return 0\n\t        # Stitch, getting a copy of the faces\n\t        faces = meshfuncs.mesh_stitch_boundaries(self.positions, self.faces, atol=atol)\n\t        # Check what faces have been changed in our copy.\n\t        changed = faces != self.faces  # Nx3\n\t        changed_count = changed.sum(axis=1)\n\t        (indices,) = np.where(changed_count > 0)\n\t        if len(indices) == 0:\n\t            return 0\n\t        # Update the faces\n", "        self.update_faces(indices, faces[indices])\n\t        # Clean up collapsed faces\n\t        collapsed_faces = np.array([len(set(f)) != len(f) for f in self.faces], bool)\n\t        if np.any(collapsed_faces):\n\t            self.delete_faces(np.where(collapsed_faces)[0])\n\t        # Clean up any vertices that are no longer in use\n\t        self.remove_unused_vertices()\n\t        return len(indices)\n\t    def repair_holes(self):\n\t        \"\"\"Repair holes in the mesh.\n", "        Small boundaries are removed by filling these holes with new faces.\n\t        At the moment this only repairs holes of 3 or 4 vertices (i.e.\n\t        1  or 2 faces), but this can later be improved. So if only small\n\t        holes are present, the result will be a closed mesh. However,\n\t        if the mesh is not manifold, this method may not be able to\n\t        repair all holes. Also note that e.g. the four courners of a\n\t        rectangular surface would be connected with new faces.\n\t        Returns the number of added faces.\n\t        \"\"\"\n\t        if self.is_closed:\n", "            return 0\n\t        # Detect boundaries.\n\t        try:\n\t            boundaries = meshfuncs.mesh_get_boundaries(self.faces)\n\t        except RuntimeError:\n\t            # The mesh probably has non-manifold edges/vertices near the boundaries,\n\t            # causing the algorithm in `mesh_get_boundaries()` to fail.\n\t            return 0\n\t        # Now we check all boundaries\n\t        new_faces = []\n", "        for boundary in boundaries:\n\t            assert len(boundary) >= 3  # I don't think they can be smaller, right?\n\t            if len(boundary) == 3:\n\t                new_faces.append(boundary)\n\t            elif len(boundary) == 4:\n\t                new_faces.append(boundary[:3])\n\t                new_faces.append(boundary[2:] + boundary[:1])\n\t            else:\n\t                pass\n\t                # We can apply the earcut algororithm to fill larger\n", "                # holes as well. Leaving this open for now.\n\t        if new_faces:\n\t            self.add_faces(new_faces)\n\t        return len(new_faces)\n\t    def remove_unused_vertices(self):\n\t        \"\"\"Delete vertices that are not used by the faces.\n\t        This is a cleanup step that is safe to apply. Though it should\n\t        not be necessary to call this after doing processing steps -\n\t        these should clean up after themselves (though they could use\n\t        this method for that).\n", "        \"\"\"\n\t        faces = self.faces\n\t        vertices_mask = np.zeros((len(self.positions),), bool)\n\t        vii = np.unique(faces.flatten())\n\t        vertices_mask[vii] = True\n\t        indices = np.where(~vertices_mask)[0]\n\t        if len(indices) > 0:\n\t            self.delete_vertices(indices)\n\t    def remove_small_components(self, min_faces=4):\n\t        \"\"\"Remove small connected components from the mesh.\"\"\"\n", "        # We need the mesh to be manifold to do this\n\t        self.repair_manifold()\n\t        assert self.is_manifold\n\t        # Get labels and their counts\n\t        component_labels = self.component_labels\n\t        labels, counts = np.unique(component_labels, return_counts=True)\n\t        # Determine what faces to remove\n\t        faces_to_remove = []\n\t        for label, count in zip(labels, counts):\n\t            if count < min_faces:\n", "                faces_to_remove.extend(np.where(component_labels == label)[0])\n\t        # Determine what vertices to remove - important to be vertex-manifold!\n\t        vertices_to_remove = np.unique(self.faces[faces_to_remove].flatten())\n\t        # check\n\t        for vi in vertices_to_remove:\n\t            fii, _ = np.where(self.faces == vi)\n\t            for fi in fii:\n\t                assert fi in faces_to_remove\n\t        # Apply\n\t        if len(faces_to_remove):\n", "            self.delete_faces(faces_to_remove)\n\t            self.delete_vertices(vertices_to_remove)\n\t    def split(self):\n\t        \"\"\"Return a list of Mesh objects, one for each connected component.\"\"\"\n\t        # I don't think we need this for our purpose, but this class is capable\n\t        # of doing something like this, so it could be a nice util.\n\t        raise NotImplementedError()\n\t    def merge(self, other):\n\t        raise NotImplementedError()\n\t    # %% Walk over the surface\n", "    def get_closest_vertex(self, ref_pos):\n\t        \"\"\"Get the vertex index closest to the given 3D point, and its distance.\"\"\"\n\t        ref_pos = np.asarray(ref_pos, np.float32)\n\t        if ref_pos.shape != (3,):\n\t            raise ValueError(\"ref_pos must be a position (3 values).\")\n\t        distances = np.linalg.norm(self.positions - ref_pos, axis=1)\n\t        vi = np.nanargmin(distances)\n\t        return vi, distances[vi]\n\t    def select_vertices_over_surface(\n\t        self, ref_vertices, ref_distances, max_distance, distance_measure=\"smooth2\"\n", "    ):\n\t        \"\"\"Select nearby vertices, starting from the given reference vertices.\n\t        Walks over the surface from the reference vertices to include\n\t        more vertices until the distance to a vertex (by walking over\n\t        the surface) exceeds the max_distance. Each reference vertex is\n\t        also associated with a starting distance.\n\t        By allowing multiple reference vertices it is possible to \"grab\n\t        the mesh\" on a precise point within a face, or using specific\n\t        shapes (e.g. a line piece) to grab the mesh.\n\t        Parameters\n", "        ----------\n\t        ref_vertices : int or list or ndarray\n\t            A single vertex index, or a set of vertex indices, to start\n\t            the selection from.\n\t        ref_distances : float or list or ndarray\n\t            The initial distance, or distances, corresponding to the\n\t            reference vertices.\n\t        max_distance : float\n\t            The maximum (geodesic) distance that a vertex can have to\n\t            be included in the selection.\n", "        distance_measure : str\n\t            The method to calculate the geodesic distance. With \"edge\"\n\t            it sums the edge lengths, with \"smooth1\" it smooths the\n\t            path to compensate for zig-zag patterns, with \"smooth2\" it\n\t            does this smarter to avoid deviating from the surface.\n\t            Default \"smooth2\".\n\t        Returns\n\t        -------\n\t        vertices : ndarray\n\t            The selected vertex indices.\n", "        distances : ndarray\n\t            The corresponding (geodesic) distances.\n\t        \"\"\"\n\t        # Init\n\t        positions = self.positions\n\t        normals = self.normals\n\t        faces = self.faces\n\t        vertex2faces = self.vertex2faces\n\t        # Allow singleton use\n\t        if isinstance(ref_vertices, (int, np.int32, np.int64)):\n", "            ref_vertices = [ref_vertices]\n\t        if isinstance(ref_distances, (float, int, np.float32, np.float64)):\n\t            ref_distances = [ref_distances]\n\t        # Select path class\n\t        if distance_measure == \"edge\":\n\t            MeshPath = MeshPathEdge  # noqa\n\t        elif distance_measure == \"smooth1\":\n\t            MeshPath = MeshPathSmooth1  # noqa\n\t        elif distance_measure == \"smooth2\":\n\t            MeshPath = MeshPathSmooth2  # noqa\n", "        else:\n\t            raise ValueError(\n\t                \"The distance_measure arg must be 'edge' 'smooth1' or 'smooth2'.\"\n\t            )\n\t        # The list of vertices to check for neighbours\n\t        vertices2check = []\n\t        selected_vertices = {}\n\t        for vi, dist in zip(ref_vertices, ref_distances):\n\t            vertices2check.append((vi, dist))\n\t            selected_vertices[vi] = MeshPath().add(positions[vi], normals[vi])\n", "        # Walk over the surface\n\t        while len(vertices2check) > 0:\n\t            vi1, cumdist = vertices2check.pop(0)\n\t            path1 = selected_vertices[vi1]\n\t            for vi2 in meshfuncs.vertex_get_neighbours(faces, vertex2faces, vi1):\n\t                p2 = positions[vi2]\n\t                n2 = normals[vi2]\n\t                path2 = path1.add(p2, n2)\n\t                if path2.dist < max_distance:\n\t                    # We will have a closer look if we have not yet selected this\n", "                    # vertex, but also if we did but found a shorter route to it.\n\t                    # This means that we may sometimes do duplicate work. To avoid\n\t                    # this, we'd need a binary heap to store the front.\n\t                    path2_prev = selected_vertices.get(vi2, None)\n\t                    if path2_prev is None or path2.dist < path2_prev.dist:\n\t                        selected_vertices[vi2] = path2\n\t                        vertices2check.append((vi2, path2.dist))\n\t        vertices = np.array(sorted(selected_vertices.keys()), np.int32)\n\t        distances = np.array([selected_vertices[vi].dist for vi in vertices], \"f4\")\n\t        return vertices, distances\n", "class BaseMeshPath:\n\t    \"\"\"Base class to help calculate the geodesic distance of a path over a surface.\"\"\"\n\t    __slots__ = [\"positions\", \"normals\", \"edist\", \"dist\"]\n\t    mode = \"\"\n\t    def __init__(self):\n\t        self.positions = []\n\t        self.normals = []\n\t        self.edist = 0.0  # edge distance\n\t        self.dist = 0.0  # the processed distance\n\t    def add(self, p, n):\n", "        new = self.__class__()\n\t        new.positions = self.positions[-3:] + [p]\n\t        new.normals = self.normals[-3:] + [n]\n\t        new.edist = self.edist\n\t        new.dist = self.dist\n\t        d = np.linalg.norm(self.positions[-1] - p) if self.positions else 0\n\t        new._process_new_position(d)\n\t        return new\n\t    def _process_new_position(self, d):\n\t        self.edist += d\n", "class MeshPathEdge(BaseMeshPath):\n\t    \"\"\"Calculate the geodesic distance by simply summing the lengths\n\t    of edges that the path goes over.\n\t    \"\"\"\n\t    __slots__ = []\n\t    def _process_new_position(self, d):\n\t        self.edist += d\n\t        self.dist += d\n\tclass MeshPathSmooth1(BaseMeshPath):\n\t    \"\"\"Calculate the geodesic distance by (virtually) repositioning\n", "    visited points over the surface. Simply by putting it in between\n\t    the neighboring points. Simple, but it (quite literally) cuts corners.\n\t    \"\"\"\n\t    __slots__ = []\n\t    def _process_new_position(self, d):\n\t        self.edist += d\n\t        self.dist += d\n\t        if len(self.positions) >= 3:\n\t            p, delta_dist = self._refine_position(\n\t                *self.positions[-3:], *self.normals[-3:]\n", "            )\n\t            self.positions[-2] = p\n\t            self.dist += delta_dist\n\t    def _refine_position(self, p1, p2, p3, n1, n2, n3):\n\t        # Get current distance\n\t        dist1 = np.linalg.norm(p1 - p2)\n\t        dist3 = np.linalg.norm(p2 - p3)\n\t        dist_before = dist1 + dist3\n\t        if dist1 == 0 or dist3 == 0:\n\t            return p2, 0\n", "        # Get the point on the line between p1 and p3, but positioned relatively\n\t        f1 = 1 - dist1 / dist_before\n\t        f3 = 1 - dist3 / dist_before\n\t        assert 0.999 < (f1 + f3) < 1.001\n\t        p = f1 * p1 + f3 * p3\n\t        # Calculate new distance\n\t        dist_after = np.linalg.norm(p1 - p) + np.linalg.norm(p - p3)\n\t        delta_dist = dist_after - dist_before\n\t        return p, delta_dist\n\tclass MeshPathSmooth2(MeshPathSmooth1):\n", "    \"\"\"Calculate the geodesic distance by (virtually) repositioning\n\t    visited points over the surface. This is still a pretty crude\n\t    estimate of the \"real\" geodesic distance, but quite a bit more\n\t    precise than simply summing the edge lenghts.\n\t    \"\"\"\n\t    __slots__ = []\n\t    def _refine_position(self, p1, p2, p3, n1, n2, n3):\n\t        # Get current distance\n\t        dist1 = np.linalg.norm(p1 - p2)\n\t        dist3 = np.linalg.norm(p2 - p3)\n", "        dist_before = dist1 + dist3\n\t        if dist1 == 0 or dist3 == 0:\n\t            return p2, 0\n\t        # Normalize the normal, make sure its nonzero\n\t        n2_len = np.linalg.norm(n2)\n\t        if n2_len == 0:\n\t            return p2, 0\n\t        n2 = n2 / n2_len\n\t        # Get the point on the line between p1 and p3, but positioned relatively\n\t        f1 = 1 - dist1 / dist_before\n", "        f3 = 1 - dist3 / dist_before\n\t        assert 0.999 < (f1 + f3) < 1.001\n\t        p_between = f1 * p1 + f3 * p3\n\t        # Define a plane through p2, with a normal that is a combination.\n\t        # Just using n2 does not seem right, since we move the point towards\n\t        # p1 and p3, it makes sense to include contributions of these normals.\n\t        plane_pos = p2\n\t        plane_normal = n1 + n2 + n2 + n3\n\t        length = np.linalg.norm(plane_normal)\n\t        plane_normal = n2 if length == 0 else plane_normal / length\n", "        # Project the point on the surface. The surface is estimated using the plane avove.\n\t        p = p_between - np.dot(plane_normal, (p_between - plane_pos)) * plane_normal\n\t        # Calculate new distance\n\t        dist_after = np.linalg.norm(p1 - p) + np.linalg.norm(p - p3)\n\t        delta_dist = dist_after - dist_before\n\t        return p, delta_dist\n"]}
