{"filename": "oneringcore.py", "chunked_list": ["from typing import Optional\n\tfrom jaa import JaaCore\n\tfrom termcolor import colored, cprint\n\timport os\n\timport json\n\tversion = \"7.3.0\"\n\tclass OneRingCore(JaaCore):\n\t    def __init__(self):\n\t        JaaCore.__init__(self)\n\t        self.translators:dict = {\n", "        }\n\t        self.default_translator:str = \"\"\n\t        self.default_from_lang:str = \"\"\n\t        self.default_to_lang:str = \"\"\n\t        self.default_translate_router:dict[str,str] = {}\n\t        self.api_keys_allowed:list = []\n\t        self.is_debug_input_output:bool = False\n\t        self.is_multithread:bool = True\n\t        self.init_on_start:str = \"\"\n\t        self.user_lang:str = \"\"\n", "        self.cache_is_use = False\n\t        self.cache_save_every = 5\n\t        self.cache_per_model = True\n\t        self.cache_dict:dict[str,dict[str,str]] = {}\n\t        self.inited_translator_engines = []\n\t        self.dict_lang_to_2let = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n\t        self.dict_2let_to_lang = {}\n\t        for i in self.dict_lang_to_2let.keys():\n\t            self.dict_2let_to_lang[self.dict_lang_to_2let[i]] = i\n\t    # ----------- process plugins functions ------\n", "    def process_plugin_manifest(self, modname, manifest):\n\t        # is req online?\n\t        # adding tts engines from plugin manifest\n\t        if \"translate\" in manifest:  # process commands\n\t            for cmd in manifest[\"translate\"].keys():\n\t                self.translators[cmd] = manifest[\"translate\"][cmd]\n\t        return manifest\n\t    def init_with_plugins(self):\n\t        self.init_plugins([\"core\"])\n\t        #self.init_plugins()\n", "        self.display_init_info()\n\t        self.init_translator_engine(self.default_translator)\n\t        ar_init_on_start = self.init_on_start.split(\",\")\n\t        for translator in ar_init_on_start:\n\t            if translator != \"\":\n\t                self.init_translator_engine(translator)\n\t    # ------------ formatting stuff -------------------\n\t    def display_init_info(self):\n\t        cprint(\"OneRingCore v{0}:\".format(version), \"blue\", end=' ')\n\t        self.format_print_key_list(\"translate engines\", self.translators.keys())\n", "        print(\"Default translator:\",self.default_translator)\n\t    def format_print_key_list(self, key:str, value:list):\n\t        print(colored(key+\": \", \"blue\")+\", \".join(value))\n\t    def print_error(self,err_txt,e:Exception = None):\n\t        cprint(err_txt,\"red\")\n\t        # if e != None:\n\t        #     cprint(e,\"red\")\n\t        import traceback\n\t        traceback.print_exc()\n\t    def print_red(self,txt):\n", "        cprint(txt,\"red\")\n\t    def print_blue(self, txt):\n\t        cprint(txt, \"blue\")\n\t    # ---------------- init translation stuff ----------------\n\t    def init_translator_engine(self, translator_engine:str):\n\t        if translator_engine in self.inited_translator_engines:\n\t            # already inited\n\t            return\n\t        try:\n\t            self.print_blue(\"TRY: init translation plugin '{0}'...\".format(translator_engine))\n", "            self.translators[translator_engine][0](self)\n\t            self.inited_translator_engines.append(translator_engine)\n\t            self.print_blue(\"SUCCESS: '{0}' inited!\".format(translator_engine))\n\t        except Exception as e:\n\t            self.print_error(\"Error init translation plugin {0}...\".format(translator_engine), e)\n\t    def translate(self, text:str, from_lang:str = \"\", to_lang:str = \"\", translator_plugin:str = \"\", add_params:str = \"\"):\n\t        if self.is_debug_input_output:\n\t            print(\"Input: {0}\".format(text))\n\t        # 1. Calculating translator plugin\n\t        if translator_plugin == \"\":\n", "            router_trans = self.default_translate_router.get(f\"{from_lang}->{to_lang}\")\n\t            router_ast1 = self.default_translate_router.get(f\"*->{to_lang}\")\n\t            router_ast2 = self.default_translate_router.get(f\"{from_lang}->*\")\n\t            if router_trans is not None:\n\t                if self.is_debug_input_output:\n\t                    print(\"Calculated ROUTER -> translator: {0}\".format(router_trans))\n\t                translator_plugin = router_trans\n\t            elif router_ast1 is not None:\n\t                if self.is_debug_input_output:\n\t                    print(\"Calculated ROUTER *-> translator: {0}\".format(router_ast1))\n", "                translator_plugin = router_ast1\n\t            elif router_ast2 is not None:\n\t                if self.is_debug_input_output:\n\t                    print(\"Calculated ROUTER ->* translator: {0}\".format(router_ast2))\n\t                translator_plugin = router_ast2\n\t            else:\n\t                if self.is_debug_input_output:\n\t                    print(\"Calculated default_translator translator: {0}\".format(self.default_translator))\n\t                translator_plugin = self.default_translator\n\t        # 2. Special case - if \":\" in translator_plugin, then try to setup model for this plugin\n", "        # usually works OK only with online translators\n\t        if \":\" in translator_plugin:\n\t            translator_plugin,new_model = translator_plugin.split(\":\",1)\n\t            self.plugin_options(\"plugin_\"+translator_plugin)[\"model\"] = new_model\n\t        # 3. Calc from_lang and to_lang if they are blank\n\t        if from_lang == \"\":\n\t            from_lang = self.default_from_lang\n\t        if to_lang == \"\":\n\t            to_lang = self.default_to_lang\n\t        if from_lang == \"user\":\n", "            from_lang = self.user_lang\n\t            if self.user_lang == \"\":\n\t                return {\"error\": \"user_lang is blank. Please, setup it in options/core.json file\"}\n\t        if to_lang == \"user\":\n\t            to_lang = self.user_lang\n\t            if self.user_lang == \"\":\n\t                return {\"error\": \"user_lang is blank. Please, setup it in options/core.json file\"}\n\t        # 4. Calculating cache_id. Get result from cache if it exists\n\t        cache_id = self.cache_calc_id(from_lang,to_lang,translator_plugin)\n\t        if self.cache_is_use:\n", "            cache_res = self.cache_get(text,cache_id)\n\t            if cache_res is not None:\n\t                if self.is_debug_input_output:\n\t                    print(\"Output from CACHE: {0}\".format(cache_res))\n\t                return {\"result\": cache_res, \"cache\": True}\n\t        # init after cache\n\t        if translator_plugin != \"\":\n\t            self.init_translator_engine(translator_plugin)\n\t            if translator_plugin not in self.inited_translator_engines:\n\t                return {\"error\": \"Translator plugin not inited\"}\n", "        # Actual call translation plugin\n\t        res = self.translators[translator_plugin][1](self, text, from_lang, to_lang, add_params)\n\t        if self.is_debug_input_output:\n\t            print(\"Output: {0}\".format(res))\n\t        if self.cache_is_use:\n\t            self.cache_set(text,cache_id,res)\n\t        return {\"result\": res, \"cache\": False}\n\t    # -------------- caching functions ----------------\n\t    def cache_calc_id(self, from_lang:str, to_lang:str, translator_plugin:str) -> str:\n\t        res = translator_plugin+\"__\"+from_lang+\"__\"+to_lang\n", "        #print(self.cache_per_model)\n\t        if self.cache_per_model:\n\t            # params = self.plugin_manifest(translator_plugin)\n\t            # if params is not None:\n\t            options = self.plugin_options(\"plugin_\"+translator_plugin)\n\t            #print(translator_plugin,options)\n\t            if options is not None:\n\t                model = options.get(\"model\")\n\t                if model is not None:\n\t                    model_normalized = str(model)\\\n", "                        .replace(\"/\",\"_\")\\\n\t                        .replace(\"\\\\\",\"_\")\\\n\t                        .replace(\":\",\"_\")\\\n\t                        .replace(\">\",\"_\")\\\n\t                        .replace(\"<\", \"_\")\n\t                    res += \"__\"+model_normalized\n\t        return res\n\t    def cache_calc_filepath(self, cache_id:str) -> str:\n\t        return os.path.dirname(__file__)+os.path.sep+\"cache\"+os.path.sep+cache_id+\".json\"\n\t    def cache_load_if_not_exists(self, cache_id:str):\n", "        if self.cache_dict.get(cache_id) is None:\n\t            if os.path.exists(self.cache_calc_filepath(cache_id)):\n\t                with open(self.cache_calc_filepath(cache_id), 'r', encoding=\"utf-8\") as f:\n\t                    # Load the JSON data from the file into a Python dictionary\n\t                    data = json.load(f)\n\t                    self.cache_dict[cache_id] = data\n\t            else:\n\t                self.cache_dict[cache_id] = {}\n\t    def cache_get(self, text:str, cache_id:str) -> Optional[str]:\n\t        self.cache_load_if_not_exists(cache_id)\n", "        return self.cache_dict.get(cache_id).get(text)\n\t    def cache_set(self, text:str, cache_id:str, text_translated:str):\n\t        self.cache_load_if_not_exists(cache_id)\n\t        self.cache_dict[cache_id][text] = text_translated\n\t        #print(cache_id,self.cache_dict[cache_id])\n\t        if len(self.cache_dict[cache_id]) % self.cache_save_every == 0:\n\t            self.cache_save(cache_id)\n\t            #print(\"saved!\")\n\t    def cache_save(self, cache_id:str):\n\t        with open(self.cache_calc_filepath(cache_id), 'w', encoding=\"utf-8\") as f:\n", "            json.dump(self.cache_dict[cache_id], f, indent=2, ensure_ascii=False)\n"]}
{"filename": "run_cmdline.py", "chunked_list": ["from oneringcore import OneRingCore\n\tcore = OneRingCore()\n\tcore.init_with_plugins()\n\tres = core.translate(\"Hello! How are you?\", \"en\", \"ru\", \"openrouter_chat\")\n\tprint(res.get(\"result\"))"]}
{"filename": "run_webapi.py", "chunked_list": ["# ----------\n\tfrom fastapi import FastAPI, HTTPException\n\tfrom starlette.responses import Response, HTMLResponse\n\timport uvicorn\n\timport multiprocessing\n\tfrom starlette.staticfiles import StaticFiles\n\tfrom oneringcore import OneRingCore, version\n\timport asyncio\n\tapp = FastAPI()\n\twebapi_version = \"2.1\"\n", "core:OneRingCore = None\n\tapp.mount(\"/webapi_client\", StaticFiles(directory=\"webapi_client\", html = True), name=\"webapi_client\")\n\t@app.get(\"/\", response_class=HTMLResponse)\n\tasync def read_items():\n\t    html_content = f\"\"\"\n\t    <html>\n\t        <head>\n\t            <meta charset=\"utf-8\" />\n\t            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n\t            <title>OneRingTranslator</title>\n", "            <link rel=\"stylesheet\" href=\"/webapi_client/chota.min.css\">\n\t        </head>\n\t        <body>\n\t            <div id=\"top\" class=\"container\" role=\"document\">\n\t                <h1>OneRingTranslator {version}</h1>\n\t                <a href=\"/webapi_client\" class=\"button\">Web interface (simple)</a><br /><br />\n\t                <a href=\"/docs\" class=\"button\">API and docs</a><br /><br />\n\t                <a href=\"https://github.com/janvarev/OneRingTranslator\" class=\"button\" target=\"_blank\">Github</a><br /><br />\n\t            </div>\n\t        </body>\n", "    </html>\n\t    \"\"\"\n\t    return HTMLResponse(content=html_content, status_code=200)\n\t@app.on_event(\"startup\")\n\tasync def startup_event():\n\t    global core\n\t    core = OneRingCore()\n\t    core.init_with_plugins()\n\t    pass\n\t@app.get(\n", "    \"/translate\",\n\t    # Set what the media type will be in the autogenerated OpenAPI specification.\n\t    # fastapi.tiangolo.com/advanced/additional-responses/#additional-media-types-for-the-main-response\n\t    # responses = {\n\t    #     200: {\n\t    #         \"content\": {\"text\": {}}\n\t    #     }\n\t    # },\n\t    # Prevent FastAPI from adding \"application/json\" as an additional\n\t    # response media type in the autogenerated OpenAPI specification.\n", "    # https://github.com/tiangolo/fastapi/issues/3258\n\t    # response_class=Response\n\t)\n\tasync def translate(text:str, from_lang:str = \"\", to_lang:str = \"\", translator_plugin:str = \"\", add_params:str = \"\", api_key:str = \"\"):\n\t    \"\"\"\n\t       Return translation\n\t       :param str text: text to translate\n\t       :param str from_lang: from language (2 symbols, like \"en\"). May be \"user\" (will be replaced to \"user_lang\" from options)\n\t       :param str to_lang: to language (2 symbols, like \"en\"). May be \"user\" (will be replaced to \"user_lang\" from options)\n\t       :param str translator_plugin: to use. If blank, default will be used. If not inited plugin will call, core try to init plugin\n", "       :param str add_params: additional params for translation (depends on plugin)\n\t       :param str api_key: api key for access (if service setup in security mode with api keys)\n\t       :return: dict (result: text)\n\t       \"\"\"\n\t    #return Response(content=data, media_type=\"text/wav\")\n\t    if len(core.api_keys_allowed) > 0: # there are some api keys\n\t        if api_key == \"\":\n\t            return {\"error\": \"API key required\"}\n\t        if not (api_key in core.api_keys_allowed):\n\t            return {\"error\": \"No valid API key provided\"}\n", "    if core.is_multithread:\n\t        #print(\"Multithread\")\n\t        #res = await asyncio.to_thread(core.translators[translator_plugin][1], core, text, from_lang, to_lang, add_params)\n\t        # init before other threads will run\n\t        if translator_plugin != \"\":\n\t            core.init_translator_engine(translator_plugin)\n\t            if translator_plugin not in core.inited_translator_engines:\n\t                return {\"error\": \"Translator plugin not inited\"}\n\t        res = await asyncio.to_thread(core.translate, text, from_lang, to_lang, translator_plugin,\n\t                                      add_params)\n", "    else:\n\t        res = core.translate(text,from_lang,to_lang,translator_plugin,add_params)\n\t    # import time\n\t    # time.sleep(1)\n\t    return res #{\"result\": res}\n\t@app.get(\n\t    \"/translator_plugin_info\",\n\t)\n\tasync def translator_plugin_info(api_key:str = \"\"):\n\t    \"\"\"\n", "       Return list of available translator plugins\n\t       :param int api_key: api key for access (if service setup in security mode with api keys)\n\t       :return: dict with info\n\t       \"\"\"\n\t    if len(core.api_keys_allowed) > 0: # there are some api keys\n\t        if api_key == \"\":\n\t            return {\"error\": \"API key required\"}\n\t        if not (api_key in core.api_keys_allowed):\n\t            return {\"error\": \"No valid API key provided\"}\n\t    full_list = list(core.translators.keys())\n", "    inited_list = core.inited_translator_engines\n\t    return {\"result\": {\n\t        \"default\": core.default_translator,\n\t        \"all_translator\": full_list,\n\t        \"inited_translator\": inited_list,\n\t        \"user_lang\": core.user_lang\n\t    }}\n\t@app.get(\n\t    \"/whois\",\n\t)\n", "async def whois():\n\t    \"\"\"\n\t       Return whois service info\n\t       :return: dict with info\n\t       \"\"\"\n\t    from oneringcore import version\n\t    return {\"result\": {\n\t        \"service\": \"OneRingTranslator\",\n\t        \"version\": version,\n\t    }}\n", "if __name__ == \"__main__\":\n\t    #multiprocessing.freeze_support()\n\t    print(\"Running OneRingTranslator v{0}, web server v{1}...\".format(version, webapi_version))\n\t    uvicorn.run(\"run_webapi:app\", host=\"127.0.0.1\", port=4990, log_level=\"info\")"]}
{"filename": "run_estimate_bleu.py", "chunked_list": ["import time\n\timport random\n\tfrom nltk.translate.bleu_score import sentence_bleu\n\t# ----------\n\tfrom oneringcore import OneRingCore\n\t# ----------------- key settings params ----------------\n\tBLEU_PAIRS = \"fra->eng,eng->fra,rus->eng,eng->rus\" # pairs of language in terms of FLORES dataset https://huggingface.co/datasets/gsarti/flores_101/viewer\n\tBLEU_PAIRS_2LETTERS = \"fr->en,en->fr,ru->en,en->ru\" # pairs of language codes that will be passed to plugin (from_lang, to_lang params)\n\t# BLEU_PAIRS = \"jpn->rus\" # pairs of language in terms of FLORES dataset https://huggingface.co/datasets/gsarti/flores_101/viewer\n\t# BLEU_PAIRS_2LETTERS = \"ja->ru\" # pairs of language codes that will be passed to plugin (from_lang, to_lang params)\n", "#BLEU_PLUGINS = \"no_translate2,google_translate,fb_nllb_ctranslate2,openrouter_chat,multi_sources,use_mid_lang\" # plugins to estimate, old version\n\tBLEU_PLUGINS_AR = [\"google_translate\", \"deepl\", \"multi_sources:google_translate,deepl\"]\n\t    # plugins to estimate, array\n\t    # now you can run them in format \"plugin:model\", that works only if plugin support \"on-the-fly\" model change (usually YES for synthetic and online plugins, and NO for offline)\n\t#BLEU_PLUGINS_AR = [\"multi_sources:google_translate,deepl,use_mid_lang:deepl->deepl,use_mid_lang:google_translate->deepl,use_mid_lang:google_translate->google_translate,use_mid_lang:deepl->google_translate\"]\n\t#BLEU_PLUGINS_AR = [\"use_mid_lang:deepl->yandex_dev\"]\n\tBLEU_NUM_PHRASES = 100 # num of phrases to estimate. Between 1 and 100 for now.\n\tBLEU_START_PHRASE = 150 # offset from FLORES dataset to get NUM phrases\n\tBLEU_METRIC = \"comet\" # bleu | comet\n\tcore:OneRingCore = None\n", "def load_dataset(lang, split, start, num):\n\t    import requests\n\t    req_url = f\"https://datasets-server.huggingface.co/rows?dataset=gsarti%2Fflores_101&config={lang}&split={split}&offset={start}&limit={num}\"\n\t    #print(req_url)\n\t    #return \"\"\n\t    r = requests.get(req_url)\n\t    if r.status_code != 200:\n\t        print(f\"Error {r.status_code} during get dataset {req_url}\")\n\t        quit()\n\t    j = r.json()\n", "    #return j[\"rows\"]\n\t    # we have problems with NUM param when getting results from server, so try to fix it\n\t    rows = j[\"rows\"]\n\t    if len(rows) > num:\n\t        rows = rows[:num]\n\t    return rows\n\tdef translate(text:str, from_lang:str = \"\", to_lang:str = \"\", translator_plugin:str = \"\", add_params:str = \"\"):\n\t    res = core.translate(text,from_lang,to_lang,translator_plugin,add_params)\n\t    if res.get(\"error\") is not None:\n\t        raise ValueError(\"Error in translate: \"+res.get(\"error\"))\n", "    return res.get(\"result\"), res.get(\"cache\")\n\tif __name__ == \"__main__\":\n\t    from tqdm import trange\n\t    import tqdm\n\t    #multiprocessing.freeze_support()\n\t    core = OneRingCore()\n\t    core.init_with_plugins()\n\t    pairs_ar = BLEU_PAIRS.split(\",\")\n\t    pairs_ar2 = BLEU_PAIRS_2LETTERS.split(\",\")\n\t    #bleu_plugins_ar = BLEU_PLUGINS.split(\",\")\n", "    bleu_plugins_ar = BLEU_PLUGINS_AR\n\t    # adding model in info on final table\n\t    bleu_plugins_ar_model = []\n\t    for plugin_str in bleu_plugins_ar:\n\t        res = plugin_str\n\t        if \":\" in plugin_str: # \":\" set, so it will be actual model in translation\n\t            plugin_str, new_model = plugin_str.split(\":\", 1)\n\t            res = f\"{plugin_str} {new_model}\"\n\t        else: # try to calc model name usual way\n\t            options = core.plugin_options(\"plugin_\" + plugin_str)\n", "            if options is not None:\n\t                model = options.get(\"model\")\n\t                if model is not None:\n\t                    res += \" \" + model\n\t        bleu_plugins_ar_model.append(res)\n\t    table_bleu = [([bleu_plugins_ar_model[i]] + ([\"-\"] * len(pairs_ar))) for i in range(len(bleu_plugins_ar))]\n\t    if BLEU_METRIC == \"comet\":\n\t        from comet import download_model, load_from_checkpoint\n\t        print(\"Activating COMET model...\")\n\t        model_path = download_model(\"Unbabel/wmt22-comet-da\")\n", "        model = load_from_checkpoint(model_path)\n\t        print(\"COMET model activated!\")\n\t    for j in range(len(pairs_ar)):\n\t        pair = pairs_ar[j]\n\t        pair2 = pairs_ar2[j]\n\t        from_lang, to_lang = pair.split(\"->\")\n\t        from_lang_let2, to_lang_let2 = pair2.split(\"->\") # we usually needs 2letter lang codes to transfer to plugins\n\t        from_lines = load_dataset(from_lang, \"devtest\", BLEU_START_PHRASE, BLEU_NUM_PHRASES)\n\t        to_lines = load_dataset(to_lang, \"devtest\", BLEU_START_PHRASE, BLEU_NUM_PHRASES)\n\t        for k in range(len(bleu_plugins_ar)):\n", "            plugin = bleu_plugins_ar[k]\n\t            #print(f\"--------------\\n{plugin} plugin\\n--------------\\n\")\n\t            bleu_sum = 0.0\n\t            bleu_cnt = 0\n\t            print(f\"---- Estimating {plugin} for pair {pair}....\")\n\t            tqdm_bar = trange(len(from_lines))\n\t            data_comet = []\n\t            for i in tqdm_bar: # tqdm range\n\t                text_need_translate = from_lines[i][\"row\"][\"sentence\"]\n\t                text_reference = to_lines[i][\"row\"][\"sentence\"]\n", "                text_candidate, is_from_cache = translate(text_need_translate,from_lang_let2,to_lang_let2, plugin)\n\t                if BLEU_METRIC == \"bleu\":\n\t                    score = sentence_bleu([text_reference.strip().split()],text_candidate.strip().split(),weights=(0.5, 0.5))\n\t                    bleu_sum += score\n\t                    bleu_cnt += 1\n\t                    tqdm_bar.set_description(\n\t                        f\"'{plugin}' on '{pair}' pair average {BLEU_METRIC.upper()} score: {'{:8.2f}'.format(bleu_sum * 100 / bleu_cnt)}\")\n\t                elif BLEU_METRIC == \"comet\":\n\t                    data_comet.append(\n\t                        {\n", "                            \"src\": text_need_translate,\n\t                            \"mt\": text_candidate,\n\t                            \"ref\": text_reference\n\t                        }\n\t                    )\n\t                    #score_pred = model.predict(data, batch_size=8, gpus=0)\n\t                    #print(score_pred)\n\t                    tqdm_bar.set_description(\n\t                        f\"'{plugin}' on '{pair}' pair, {BLEU_METRIC.upper()} score, getting translations...: \")\n\t                #print(f\"Original: {text_need_translate}\\nTranslation: {text_candidate}\\nReference: {text_reference}\\nScore: {score}\\n\\n\")\n", "                # on some web plugin and not from cache result we need delay\n\t                # (cache results must pass without delay)\n\t                if plugin == \"openai_chat\" and not is_from_cache:\n\t                    import time\n\t                    import random\n\t                    time.sleep(20 + random.random()*3)\n\t                # if not is_from_cache:\n\t                #     time.sleep(1 + random.random() * 2)\n\t            if BLEU_METRIC == \"bleu\":\n\t                bleu_score = bleu_sum / len(from_lines)\n", "            elif BLEU_METRIC == \"comet\":\n\t                print(\"Calculating COMET model...\")\n\t                score_pred = model.predict(data_comet, batch_size=8, gpus=0)\n\t                #print(score_pred)\n\t                bleu_score = score_pred.get(\"system_score\")\n\t            print(f\"****** Average {BLEU_METRIC.upper()} score for '{plugin}' on '{pair.upper()}' pair ({len(to_lines)} samples): {bleu_score}\")\n\t            table_bleu[k][j+1] = \"{:8.2f}\".format(bleu_score*100)\n\t    from tabulate import tabulate\n\t    res_print_table = tabulate(table_bleu,headers=[\" \"*70]+pairs_ar,tablefmt=\"github\")\n\t    print(\"*\" * 70)\n", "    print(f\"{BLEU_METRIC.upper()} scores\")\n\t    print(\"*\" * 70)\n\t    print(res_print_table)\n"]}
{"filename": "jaa.py", "chunked_list": ["\"\"\"\n\tJaa.py Plugin Framework\n\tAuthor: Janvarev Vladislav\n\tJaa.py - minimalistic one-file plugin framework with no dependencies.\n\tMain functions:\n\t- run all plugins files from \"plugins\" folder, base on filename\n\t- save each plugin options in \"options\" folder in JSON text files for further editing\n\t- Plugins\n\tmust located in plugins/ folder\n\tmust have \"start(core)\" function, that returns manifest dict\n", "manifest must contain keys \"name\" and \"version\"\n\tcan contain \"default_options\"\n\t- if contain - options will be saved in \"options\" folder and reload instead next time\n\t- if contain - \"start_with_options(core,manifest)\" function will run with manifest with \"options\" key\n\tmanifest will be processed in \"process_plugin_manifest\" function if you override it\n\t- Options (for plugins)\n\tare saved under \"options\" folder in JSON format\n\tcreated at first run plugin with \"default_options\"\n\tupdated when plugin change \"version\"\n\t- Example usage:\n", "class VoiceAssCore(JaaCore): # class must override JaaCore\n\t    def __init__(self):\n\t        JaaCore.__init__(self,__file__)\n\t  ...\n\tmain = VoiceAssCore()\n\tmain.init_plugins([\"core\"]) # 1 param - first plugins to be initialized\n\t                            # Good if you need some \"core\" options/plugin to be loaded before others\n\t                            # not necessary starts with \"plugin_\" prefix\n\talso can be run like\n\tmain.init_plugins()\n", "- Requirements\n\tPython 3.5+ (due to dict mix in final_options calc), can be relaxed\n\t\"\"\"\n\timport os\n\timport traceback\n\timport json\n\t# here we trying to use termcolor to highlight plugin info and errors during load\n\ttry:\n\t    from termcolor import cprint\n\texcept Exception as e:\n", "    # not found? making a stub!\n\t    def cprint(p,color=None):\n\t        if color == None:\n\t            print(p)\n\t        else:\n\t            print(str(color).upper(),p)\n\tversion = \"1.7.1\"\n\tclass JaaCore:\n\t    def __init__(self,root_file = __file__):\n\t        self.jaaPluginPrefix = \"plugin_\"\n", "        self.jaaVersion = version\n\t        self.jaaRootFolder = os.path.dirname(root_file)\n\t        self.jaaOptionsPath = self.jaaRootFolder+os.path.sep+\"options\"\n\t        self.jaaShowTracebackOnPluginErrors = False\n\t        cprint(\"JAA.PY v{0} class created!\".format(version),\"blue\")\n\t    # ------------- plugins -----------------\n\t    def init_plugins(self, list_first_plugins = []):\n\t        self.plugin_manifests = {}\n\t        # 1. run first plugins first!\n\t        for modname in list_first_plugins:\n", "            self.init_plugin(modname)\n\t        # 2. run all plugins from plugins folder\n\t        from os import listdir\n\t        from os.path import isfile, join\n\t        pluginpath = self.jaaRootFolder+\"/plugins\"\n\t        files = [f for f in listdir(pluginpath) if isfile(join(pluginpath, f))]\n\t        for fil in files:\n\t            # print fil[:-3]\n\t            if fil.startswith(self.jaaPluginPrefix) and fil.endswith(\".py\"):\n\t                modfile = fil[:-3]\n", "                self.init_plugin(modfile)\n\t    def init_plugin(self,modname):\n\t        # import\n\t        try:\n\t            mod = self.import_plugin(\"plugins.\"+modname)\n\t        except Exception as e:\n\t            self.print_error(\"JAA PLUGIN ERROR: {0} error on load: {1}\".format(modname, str(e)))\n\t            return False\n\t        # run start function\n\t        try:\n", "            res = mod.start(self)\n\t        except Exception as e:\n\t            self.print_error(\"JAA PLUGIN ERROR: {0} error on start: {1}\".format(modname, str(e)))\n\t            return False\n\t        # if plugin has an options\n\t        if \"default_options\" in res:\n\t            try:\n\t                # saved options try to read\n\t                saved_options = {}\n\t                try:\n", "                    with open(self.jaaOptionsPath+'/'+modname+'.json', 'r', encoding=\"utf-8\") as f:\n\t                        s = f.read()\n\t                    saved_options = json.loads(s)\n\t                    #print(\"Saved options\", saved_options)\n\t                except Exception as e:\n\t                    pass\n\t                res[\"default_options\"][\"v\"] = res[\"version\"]\n\t                # only string needs Python 3.5\n\t                final_options = {**res[\"default_options\"], **saved_options}\n\t                # if no option found or version is differ from mod version\n", "                if len(saved_options) == 0 or saved_options[\"v\"] != res[\"version\"]:\n\t                    final_options[\"v\"] = res[\"version\"]\n\t                    self.save_plugin_options(modname,final_options)\n\t                res[\"options\"] = final_options\n\t                try:\n\t                    res2 = mod.start_with_options(self,res)\n\t                    if res2 != None:\n\t                        res = res2\n\t                except Exception as e:\n\t                    self.print_error(\"JAA PLUGIN ERROR: {0} error on start_with_options processing: {1}\".format(modname, str(e)))\n", "                    return False\n\t            except Exception as e:\n\t                self.print_error(\"JAA PLUGIN ERROR: {0} error on options processing: {1}\".format(modname, str(e)))\n\t                return False\n\t        # processing plugin manifest\n\t        try:\n\t            # set up name and version\n\t            plugin_name = res[\"name\"]\n\t            plugin_version = res[\"version\"]\n\t            self.process_plugin_manifest(modname,res)\n", "        except Exception as e:\n\t            print(\"JAA PLUGIN ERROR: {0} error on process startup options: {1}\".format(modname, str(e)))\n\t            return False\n\t        self.plugin_manifests[modname] = res\n\t        self.on_succ_plugin_start(modname,plugin_name,plugin_version)\n\t        return True\n\t    def on_succ_plugin_start(self, modname, plugin_name, plugin_version):\n\t        cprint(\"JAA PLUGIN: {1} {2} ({0}) started!\".format(modname, plugin_name, plugin_version))\n\t    def print_error(self,p):\n\t        cprint(p,\"red\")\n", "        if self.jaaShowTracebackOnPluginErrors:\n\t            traceback.print_exc()\n\t    def import_plugin(self, module_name):\n\t        import sys\n\t        __import__(module_name)\n\t        if module_name in sys.modules:\n\t            return sys.modules[module_name]\n\t        return None\n\t    def save_plugin_options(self,modname,options):\n\t        # check folder exists\n", "        if not os.path.exists(self.jaaOptionsPath):\n\t            os.makedirs(self.jaaOptionsPath)\n\t        str_options = json.dumps(options, sort_keys=True, indent=4, ensure_ascii=False)\n\t        with open(self.jaaOptionsPath+'/'+modname+'.json', 'w', encoding=\"utf-8\") as f:\n\t            f.write(str_options)\n\t            f.close()\n\t    # process manifest must be overrided in inherit class\n\t    def process_plugin_manifest(self,modname,manifest):\n\t        print(\"JAA PLUGIN: {0} manifest dummy procession (override 'process_plugin_manifest' function)\".format(modname))\n\t        return\n", "    def plugin_manifest(self,pluginname):\n\t        if pluginname in self.plugin_manifests:\n\t            return self.plugin_manifests[pluginname]\n\t        return {}\n\t    def plugin_options(self,pluginname):\n\t        manifest = self.plugin_manifest(pluginname)\n\t        if \"options\" in manifest:\n\t            return manifest[\"options\"]\n\t        return None\n\tdef load_options(options_file=None,py_file=None,default_options={}):\n", "    # 1. calculating options filename\n\t    if options_file == None:\n\t        if py_file == None:\n\t            raise Exception('JAA: Options or PY file is not defined, cant calc options filename')\n\t        else:\n\t            options_file = py_file[:-3]+'.json'\n\t    # 2. try to read saved options\n\t    saved_options = {}\n\t    try:\n\t        with open(options_file, 'r', encoding=\"utf-8\") as f:\n", "            s = f.read()\n\t        saved_options = json.loads(s)\n\t        #print(\"Saved options\", saved_options)\n\t    except Exception as e:\n\t        pass\n\t    # 3. calculating final options\n\t    # only string needs Python 3.5\n\t    final_options = {**default_options, **saved_options}\n\t    # 4. calculating hash from def options to check - is file rewrite needed?\n\t    import hashlib\n", "    hash = hashlib.md5((json.dumps(default_options, sort_keys=True)).encode('utf-8')).hexdigest()\n\t    # 5. if no option file found or hash was from other default options\n\t    if len(saved_options) == 0 or not (\"hash\" in saved_options.keys()) or saved_options[\"hash\"] != hash:\n\t        final_options[\"hash\"] = hash\n\t        #self.save_plugin_options(modname,final_options)\n\t        # saving in file\n\t        str_options = json.dumps(final_options, sort_keys=True, indent=4, ensure_ascii=False)\n\t        with open(options_file, 'w', encoding=\"utf-8\") as f:\n\t            f.write(str_options)\n\t            f.close()\n", "    return final_options\n\t\"\"\"\n\tThe MIT License (MIT)\n\tCopyright (c) 2021 Janvarev Vladislav\n\tPermission is hereby granted, free of charge, to any person obtaining a copy \n\tof this software and associated documentation files (the “Software”), to deal \n\tin the Software without restriction, including without limitation the rights to use, \n\tcopy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, \n\tand to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\tThe above copyright notice and this permission notice shall be included in all copies or \n", "substantial portions of the Software.\n\tTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, \n\tINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR \n\tPURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE \n\tFOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, \n\tARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\t\"\"\""]}
{"filename": "plugins/plugin_no_translate.py", "chunked_list": ["# No Translate dummy plugin\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"No Translate dummy plugin\", # name\n\t        \"version\": \"1.0\", # version\n", "        \"translate\": {\n\t            \"no_translate\": (init,translate) # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n\tdef init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    return text\n"]}
{"filename": "plugins/plugin_use_mid_lang.py", "chunked_list": ["# Use mid (mediator) language\n\t# Translate in two phases: from lang->mediator lang, mediator lang->to lang\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\timport time\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n", "        \"name\": \"Use mediator language\", # name\n\t        \"version\": \"1.1\", # version\n\t        \"default_options\": {\n\t            \"model\": \"google_translate->deepl\",  # 1 phase plugin, 2 phase plugin\n\t            #  1 phase from lang->mediator lang,\n\t            #  2 phase mediator lang->to lang\n\t            \"mid_lang\": \"en\",\n\t        },\n\t        \"translate\": {\n\t            \"use_mid_lang\": (init,translate) # 1 function - init, 2 - translate\n", "        }\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n\tdef init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    plugins: str = core.plugin_options(modname).get(\"model\").split(\"->\")\n\t    mid_lang: str = core.plugin_options(modname).get(\"mid_lang\")\n", "    res1 = core.translate(text,from_lang,mid_lang,plugins[0]).get(\"result\")\n\t    #print(from_lang,mid_lang,res1)\n\t    #time.sleep(0.02)\n\t    res2 = core.translate(res1,mid_lang,to_lang,plugins[1]).get(\"result\")\n\t    #print(mid_lang,to_lang,res2)\n\t    return res2\n"]}
{"filename": "plugins/plugin_google_translate.py", "chunked_list": ["# Google Translate plugin\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"Google Translate\", # name\n\t        \"version\": \"1.0\", # version\n", "        \"translate\": {\n\t            \"google_translate\": (init,translate) # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n\tdef init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    # просто выводим текст в консоль\n\t    from deep_translator import GoogleTranslator\n", "    res = GoogleTranslator(source=from_lang, target=to_lang).translate(text)\n\t    return res\n"]}
{"filename": "plugins/plugin_deepl.py", "chunked_list": ["# Deepl Translate plugin\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"Deepl Translator\", # name\n\t        \"version\": \"1.1\", # version\n", "        \"default_options\": {\n\t            \"api_key\": \"\",  #\n\t            \"is_free_api\": True, # use Free version or not\n\t        },\n\t        \"translate\": {\n\t            \"deepl\": (init, translate),  # 1 function - init, 2 - translate\n\t            # deprecated\n\t            \"deepl_translate\": (init, translate)  # 1 function - init, 2 - translate\n\t        }\n\t    }\n", "    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n\tdef init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    from deep_translator import DeeplTranslator\n\t    #custom_url = core.plugin_options(modname).get(\"custom_url\")\n\t    is_free:bool = core.plugin_options(modname).get(\"is_free_api\")\n\t    api_key:str = core.plugin_options(modname).get(\"api_key\")\n", "    #print(custom_url)\n\t    #res = LibreTranslator(source=from_lang, target=to_lang, custom_url=custom_url).translate(text)\n\t    res = DeeplTranslator(api_key, use_free_api=is_free, source=from_lang, target=to_lang).translate(text)\n\t    return res\n"]}
{"filename": "plugins/plugin_no_translate2.py", "chunked_list": ["# No Translate dummy plugin - return blank\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"No Translate2 dummy plugin\", # name\n\t        \"version\": \"1.0\", # version\n", "        \"translate\": {\n\t            \"no_translate2\": (init,translate) # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n\tdef init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    return \"\"\n"]}
{"filename": "plugins/plugin_lingvanex.py", "chunked_list": ["# lingvanex Translate plugin\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"lingvanex Translator\", # name\n\t        \"version\": \"1.1\", # version\n", "        \"default_options\": {\n\t            \"api_key\": \"\",  #\n\t        },\n\t        \"translate\": {\n\t            \"lingvanex\": (init, translate)  # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n", "def init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    api_key:str = core.plugin_options(modname).get(\"api_key\")\n\t    import requests\n\t    url = \"https://api-b2b.backenster.com/b1/api/v3/translate\"\n\t    payload = {\n\t        \"platform\": \"api\",\n\t        \"from\": from_lang,\n\t        \"to\": to_lang,\n", "        \"data\": text\n\t    }\n\t    headers = {\n\t        \"accept\": \"application/json\",\n\t        \"content-type\": \"application/json\",\n\t        \"Authorization\": api_key\n\t    }\n\t    response = requests.post(url, json=payload, headers=headers)\n\t    #print(respons*e.text)\n\t    response_json = response.json()\n", "    if response_json.get(\"err\") is not None:\n\t        raise ValueError(\"ERR in ligvanex server call: \"+response_json.get(\"err\"))\n\t    #print(response_json)\n\t    return response_json[\"result\"]\n"]}
{"filename": "plugins/plugin_opus_mt.py", "chunked_list": ["# opus mt\n\t# author: Vladislav Janvarev\n\t# from https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-hu-en\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\tmodel = None\n\ttokenizer = None\n\tcuda_opt = -1\n\tto_device = \"cpu\"\n", "# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"Opus MT Translate\", # name\n\t        \"version\": \"1.0\", # version\n\t        \"translate\": {\n\t            \"opus_mt\": (init,translate) # 1 function - init, 2 - translate\n\t        },\n\t        \"default_options\": {\n\t            \"model\": \"Helsinki-NLP/opus-mt-en-ru\",  # key model\n", "            \"cuda\": -1, # -1 if you want run on CPU, 0 - if on CUDA\n\t            \"text_prefix\": \"\" # for models like https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-he-itc\n\t            # be like >>hbs<< etc.\n\t        },\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    global cuda_opt\n\t    global to_device\n\t    cuda_opt = manifest[\"options\"].get(\"cuda\")\n", "    if cuda_opt == -1:\n\t        to_device = \"cpu\"\n\t    else:\n\t        to_device = \"cuda:{0}\".format(cuda_opt)\n\t    pass\n\tdef init(core:OneRingCore):\n\t    from transformers import MarianMTModel, MarianTokenizer\n\t    global model, tokenizer\n\t    #print(to_device)\n\t    model_name = core.plugin_options(modname).get(\"model\")\n", "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n\t    model = MarianMTModel.from_pretrained(model_name).to(to_device)\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    src_text = [core.plugin_options(modname).get(\"text_prefix\")+text]\n\t    translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True).to(to_device))\n\t    res = tokenizer.decode(translated[0], skip_special_tokens=True)\n\t    return res"]}
{"filename": "plugins/core.py", "chunked_list": ["# Core plugin\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = {\n\t        \"name\": \"Core plugin\",\n\t        \"version\": \"1.5\",\n\t        # this is DEFAULT options\n\t        # ACTUAL options is in options/<plugin_name>.json after first run\n", "        \"default_options\": {\n\t            \"default_translate_plugin\": \"google_translate\", # default translation engine. Will be auto inited on start\n\t            \"init_on_start\": \"\",  # additional list of engines, that must be init on start, separated by \",\"\n\t            \"default_from_lang\": \"es\", # default from language\n\t            \"default_to_lang\": \"en\", # default to language\n\t            \"api_keys_allowed\": [], # set of API keys. If empty - no API key required.\n\t            \"debug_input_output\": False, # allow debug print input and output in console\n\t            \"allow_multithread\": True, # allow multithread run of translation engine\n\t            \"user_lang\": \"\", # standart user language. Replaces \"user\" in to_lang or from_lang API params\n\t            \"cache_is_use\": True, # use cache?\n", "            \"cache_save_every\": 5,  # every X elements save cache to disk\n\t            \"cache_per_model\": True, # differentiate cache per model\n\t            \"default_translate_router\": { # routing for default translation engine on different language pairs\n\t                \"fr->es\": \"no_translate\", # this is just an example, adjust in to your needs\n\t                \"fr->fn\": \"no_translate2\", # asterisk supported like *->fr\n\t            }\n\t        },\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n", "    #print(manifest[\"options\"])\n\t    options = manifest[\"options\"]\n\t    core.default_translator = options[\"default_translate_plugin\"]\n\t    core.default_from_lang = options[\"default_from_lang\"]\n\t    core.default_to_lang = options[\"default_to_lang\"]\n\t    core.default_translate_router = options[\"default_translate_router\"]\n\t    core.api_keys_allowed = options[\"api_keys_allowed\"]\n\t    core.is_multithread = options[\"allow_multithread\"]\n\t    core.is_debug_input_output = options[\"debug_input_output\"]\n\t    core.user_lang = options[\"user_lang\"]\n", "    core.cache_is_use = options[\"cache_is_use\"]\n\t    core.cache_save_every = options[\"cache_save_every\"]\n\t    core.cache_per_model = options[\"cache_per_model\"]\n\t    core.init_on_start = options[\"init_on_start\"]\n\t    return manifest\n"]}
{"filename": "plugins/plugin_openai_chat.py", "chunked_list": ["# Translation throw ChatGPT\n\t# author: Vladislav Janvarev\n\timport os\n\timport openai\n\tfrom oneringcore import OneRingCore\n\timport json\n\timport os\n\timport openai\n\t# ---------- from https://github.com/stancsz/chatgpt ----------\n\tclass ChatApp:\n", "    def __init__(self, model=\"gpt-3.5-turbo\", load_file='', system=''):\n\t        # Setting the API key to use the OpenAI API\n\t        self.model = model\n\t        self.messages = []\n\t        if system != '':\n\t            self.messages.append({\"role\": \"system\", \"content\" : system})\n\t        if load_file != '':\n\t            self.load(load_file)\n\t    def chat(self, message):\n\t        if message == \"exit\":\n", "            self.save()\n\t            os._exit(1)\n\t        elif message == \"save\":\n\t            self.save()\n\t            return \"(saved)\"\n\t        self.messages.append({\"role\": \"user\", \"content\": message})\n\t        print(self.messages)\n\t        response = openai.ChatCompletion.create(\n\t            model=self.model,\n\t            messages=self.messages,\n", "            temperature=0.7,\n\t            n=1,\n\t            max_tokens=int(len(message)*1.5),\n\t            #headers=\n\t        )\n\t        self.messages.append({\"role\": \"assistant\", \"content\": response[\"choices\"][0][\"message\"].content})\n\t        return response[\"choices\"][0][\"message\"]\n\t    def save(self):\n\t        try:\n\t            import time\n", "            import re\n\t            import json\n\t            ts = time.time()\n\t            json_object = json.dumps(self.messages, indent=4)\n\t            filename_prefix=self.messages[0]['content'][0:30]\n\t            filename_prefix = re.sub('[^0-9a-zA-Z]+', '-', f\"{filename_prefix}_{ts}\")\n\t            with open(f\"models/chat_model_{filename_prefix}.json\", \"w\") as outfile:\n\t                outfile.write(json_object)\n\t        except:\n\t            os._exit(1)\n", "    def load(self, load_file):\n\t        with open(load_file) as f:\n\t            data = json.load(f)\n\t            self.messages = data\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# функция на старте\n\tdef start(core:OneRingCore):\n\t    manifest = {\n\t        \"name\": \"Translation through ChatGPT\",\n\t        \"version\": \"3.1\",\n", "        \"description\": \"After define apiKey allow to translate through ChatGPT.\",\n\t        \"options_label\": {\n\t            \"apiKey\": \"API-key OpenAI\", #\n\t            \"apiBaseUrl\": \"URL for OpenAI (allow OpenAI emulation servers)\",  #\n\t            \"system\": \"System input string.\"\n\t        },\n\t        \"default_options\": {\n\t            \"apiKey\": \"\", #\n\t            \"apiBaseUrl\": \"\",  #\n\t            \"system\": \"You are a professional translator.\",\n", "            \"prompt\": \"Instruction: Translate this text from {0} to {1}:\\n\\n{2}\",\n\t            \"model\": \"gpt-3.5-turbo\",\n\t        },\n\t        \"translate\": {\n\t            \"openai_chat\": (init, translate)  # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n", "def init(core:OneRingCore):\n\t    options = core.plugin_options(modname)\n\t    if options[\"apiKey\"] == \"\" and options[\"apiBaseUrl\"] == \"\":\n\t        raise ValueError(\"Needed API KEY for access\")\n\t    openai.api_key = options[\"apiKey\"]\n\t    if options[\"apiBaseUrl\"] != \"\":\n\t        openai.api_base = options[\"apiBaseUrl\"]\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    options = core.plugin_options(modname)\n\t    from_full_lang = core.dict_2let_to_lang.get(from_lang)\n", "    to_full_lang = core.dict_2let_to_lang.get(to_lang)\n\t    #prompt = f\"Instruction: Translate this text from {from_full_lang} to {to_full_lang}:\\n\\n{text}\"\n\t    prompt = str(options[\"prompt\"]).format(from_full_lang,to_full_lang,text)\n\t    system_text = str(options[\"system\"]).format(from_full_lang,to_full_lang,text)\n\t    core.chatapp = ChatApp(model=str(options[\"model\"]),system=system_text) # create new chat\n\t    response = core.chatapp.chat(prompt)  # generate_response(phrase)\n\t    #print(response)\n\t    return response[\"content\"]\n"]}
{"filename": "plugins/plugin_koboldapi_translate.py", "chunked_list": ["# Translate plugin throw KoboldAPI interface\n\t# KoboldAPI is a REST interface for lots of LLM servers (like koboldcpp, text-generation-webui)\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"KoboldAPI Translator\", # name\n", "        \"version\": \"2.0\", # version\n\t        \"default_options\": {\n\t            \"custom_url\": \"http://localhost:5000/\",  #\n\t            \"prompt\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n### Instruction:\\nTranslate this text from {0} to {1}:\\n\\n{2}\\n\\n\\n### Response:\"\n\t        },\n\t        \"translate\": {\n\t            \"koboldapi_translate\": (init,translate) # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n", "def start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n\tdef init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    options = core.plugin_options(modname)\n\t    import json\n\t    custom_stopping_strings = [\"\\n\\n\",\"\\n### \"]\n\t    params = {\n\t        'max_new_tokens': int(len(text)*1.5),\n", "        'max_length': int(len(text)*1.5),\n\t        'do_sample': True,\n\t        'temperature': 0.7,\n\t        'top_p': 0.2,\n\t        'typical_p': 1,\n\t        'repetition_penalty': 1.18,\n\t        'encoder_repetition_penalty': 1.0,\n\t        'top_k': 40,\n\t        'min_length': 0,\n\t        'no_repeat_ngram_size': 0,\n", "        'num_beams': 1,\n\t        'penalty_alpha': 0,\n\t        'length_penalty': 1,\n\t        'early_stopping': True,\n\t        'seed': -1,\n\t        'add_bos_token': True,\n\t        'custom_stopping_strings': custom_stopping_strings,\n\t        'stop_sequence': custom_stopping_strings,\n\t        'truncation_length': 2048,\n\t        'ban_eos_token': False,\n", "    }\n\t    from_full_lang = core.dict_2let_to_lang.get(from_lang)\n\t    to_full_lang = core.dict_2let_to_lang.get(to_lang)\n\t    from time import time\n\t    start = time()\n\t    # # Input prompt for Alpaca\n\t    # tpl = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\"\n\t    # tpl += f\"### Instruction:\\nTranslate this text from {from_full_lang} to {to_full_lang}:\\n\\n\"\n\t    # #tpl += \"### Input:\\n{0}\\n\\n\\n\\n\"\n\t    # tpl += \"{0}\\n\\n\\n\"\n", "    # tpl += \"### Response:\"\n\t    prompt = str(options[\"prompt\"]).format(from_full_lang,to_full_lang,text)\n\t    print(prompt)\n\t    params[\"prompt\"] = prompt\n\t    #print(params)\n\t    import requests\n\t    url = f\"{core.plugin_options(modname).get('custom_url')}api/v1/generate\"\n\t    #print(url)\n\t    response = requests.post(url, json=params)\n\t    if response.status_code != 200:\n", "        return \"ERROR in call KoboldAPI url: status code {0}\".format(response.status_code)\n\t    #print(response)\n\t    reply:str = response.json()[\"results\"][0]['text']\n\t    reply = reply.strip()\n\t    end = time()\n\t    #print(\"Duration: {0}\".format(end - start))\n\t    for stop_string in custom_stopping_strings:\n\t        if stop_string in reply:\n\t            res = reply.split(stop_string)\n\t            reply = res[0]\n", "    #print(reply)\n\t    return reply"]}
{"filename": "plugins/plugin_libre_translate.py", "chunked_list": ["# Libre Translate plugin\n\t# author: Vladislav Janvarev\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"Libre Translator\", # name\n\t        \"version\": \"1.0\", # version\n", "        \"default_options\": {\n\t            \"custom_url\": \"https://translate.argosopentech.com/\",  # mirror for LibreTranslator service\n\t        },\n\t        \"translate\": {\n\t            \"libre_translate\": (init,translate) # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n", "def init(core:OneRingCore):\n\t    pass\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    from deep_translator import LibreTranslator\n\t    custom_url = core.plugin_options(modname).get(\"custom_url\")\n\t    #print(custom_url)\n\t    res = LibreTranslator(source=from_lang, target=to_lang, custom_url=custom_url).translate(text)\n\t    return res\n"]}
{"filename": "plugins/plugin_fb_nllb_ctranslate2.py", "chunked_list": ["# nllb plugin with https://opennmt.net/CTranslate2/index.html support\n\t# author: Vladislav Janvarev\n\t# from https://github.com/facebookresearch/fairseq/tree/nllb\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\tmodel = None\n\ttokenizers:dict = {}\n\t# -------- lang list\n\tlanglist_str = \"\"\"\n", "ace_Arab    | Acehnese (Arabic script)\n\tace_Latn    | Acehnese (Latin script)\n\tacm_Arab    | Mesopotamian Arabic\n\tacq_Arab    | Ta’izzi-Adeni Arabic\n\taeb_Arab    | Tunisian Arabic\n\tafr_Latn    | Afrikaans\n\tajp_Arab    | South Levantine Arabic\n\taka_Latn    | Akan\n\tals_Latn    | Tosk Albanian\n\tamh_Ethi    | Amharic\n", "apc_Arab    | North Levantine Arabic\n\tarb_Arab    | Modern Standard Arabic\n\tarb_Latn    | Modern Standard Arabic (Romanized)\n\tars_Arab    | Najdi Arabic\n\tary_Arab    | Moroccan Arabic\n\tarz_Arab    | Egyptian Arabic\n\tasm_Beng    | Assamese\n\tast_Latn    | Asturian\n\tawa_Deva    | Awadhi\n\tayr_Latn    | Central Aymara\n", "azb_Arab    | South Azerbaijani\n\tazj_Latn    | North Azerbaijani\n\tbak_Cyrl    | Bashkir\n\tbam_Latn    | Bambara\n\tban_Latn    | Balinese\n\tbel_Cyrl    | Belarusian\n\tbem_Latn    | Bemba\n\tben_Beng    | Bengali\n\tbho_Deva    | Bhojpuri\n\tbjn_Arab    | Banjar (Arabic script)\n", "bjn_Latn    | Banjar (Latin script)\n\tbod_Tibt    | Standard Tibetan\n\tbos_Latn    | Bosnian\n\tbug_Latn    | Buginese\n\tbul_Cyrl    | Bulgarian\n\tcat_Latn    | Catalan\n\tceb_Latn    | Cebuano\n\tces_Latn    | Czech\n\tcjk_Latn    | Chokwe\n\tckb_Arab    | Central Kurdish\n", "crh_Latn    | Crimean Tatar\n\tcym_Latn    | Welsh\n\tdan_Latn    | Danish\n\tdeu_Latn    | German\n\tdik_Latn    | Southwestern Dinka\n\tdyu_Latn    | Dyula\n\tdzo_Tibt    | Dzongkha\n\tell_Grek    | Greek\n\teng_Latn    | English\n\tepo_Latn    | Esperanto\n", "est_Latn    | Estonian\n\teus_Latn    | Basque\n\tewe_Latn    | Ewe\n\tfao_Latn    | Faroese\n\tfij_Latn    | Fijian\n\tfin_Latn    | Finnish\n\tfon_Latn    | Fon\n\tfra_Latn    | French\n\tfur_Latn    | Friulian\n\tfuv_Latn    | Nigerian Fulfulde\n", "gaz_Latn    | West Central Oromo\n\tgla_Latn    | Scottish Gaelic\n\tgle_Latn    | Irish\n\tglg_Latn    | Galician\n\tgrn_Latn    | Guarani\n\tguj_Gujr    | Gujarati\n\that_Latn    | Haitian Creole\n\thau_Latn    | Hausa\n\theb_Hebr    | Hebrew\n\thin_Deva    | Hindi\n", "hne_Deva    | Chhattisgarhi\n\thrv_Latn    | Croatian\n\thun_Latn    | Hungarian\n\thye_Armn    | Armenian\n\tibo_Latn    | Igbo\n\tilo_Latn    | Ilocano\n\tind_Latn    | Indonesian\n\tisl_Latn    | Icelandic\n\tita_Latn    | Italian\n\tjav_Latn    | Javanese\n", "jpn_Jpan    | Japanese\n\tkab_Latn    | Kabyle\n\tkac_Latn    | Jingpho\n\tkam_Latn    | Kamba\n\tkan_Knda    | Kannada\n\tkas_Arab    | Kashmiri (Arabic script)\n\tkas_Deva    | Kashmiri (Devanagari script)\n\tkat_Geor    | Georgian\n\tkaz_Cyrl    | Kazakh\n\tkbp_Latn    | Kabiyè\n", "kea_Latn    | Kabuverdianu\n\tkhk_Cyrl    | Halh Mongolian\n\tkhm_Khmr    | Khmer\n\tkik_Latn    | Kikuyu\n\tkin_Latn    | Kinyarwanda\n\tkir_Cyrl    | Kyrgyz\n\tkmb_Latn    | Kimbundu\n\tkmr_Latn    | Northern Kurdish\n\tknc_Arab    | Central Kanuri (Arabic script)\n\tknc_Latn    | Central Kanuri (Latin script)\n", "kon_Latn    | Kikongo\n\tkor_Hang    | Korean\n\tlao_Laoo    | Lao\n\tlij_Latn    | Ligurian\n\tlim_Latn    | Limburgish\n\tlin_Latn    | Lingala\n\tlit_Latn    | Lithuanian\n\tlmo_Latn    | Lombard\n\tltg_Latn    | Latgalian\n\tltz_Latn    | Luxembourgish\n", "lua_Latn    | Luba-Kasai\n\tlug_Latn    | Ganda\n\tluo_Latn    | Luo\n\tlus_Latn    | Mizo\n\tlvs_Latn    | Standard Latvian\n\tmag_Deva    | Magahi\n\tmai_Deva    | Maithili\n\tmal_Mlym    | Malayalam\n\tmar_Deva    | Marathi\n\tmin_Arab    | Minangkabau (Arabic script)\n", "min_Latn    | Minangkabau (Latin script)\n\tmkd_Cyrl    | Macedonian\n\tmlt_Latn    | Maltese\n\tmni_Beng    | Meitei (Bengali script)\n\tmos_Latn    | Mossi\n\tmri_Latn    | Maori\n\tmya_Mymr    | Burmese\n\tnld_Latn    | Dutch\n\tnno_Latn    | Norwegian Nynorsk\n\tnob_Latn    | Norwegian Bokmål\n", "npi_Deva    | Nepali\n\tnso_Latn    | Northern Sotho\n\tnus_Latn    | Nuer\n\tnya_Latn    | Nyanja\n\toci_Latn    | Occitan\n\tory_Orya    | Odia\n\tpag_Latn    | Pangasinan\n\tpan_Guru    | Eastern Panjabi\n\tpap_Latn    | Papiamento\n\tpbt_Arab    | Southern Pashto\n", "pes_Arab    | Western Persian\n\tplt_Latn    | Plateau Malagasy\n\tpol_Latn    | Polish\n\tpor_Latn    | Portuguese\n\tprs_Arab    | Dari\n\tquy_Latn    | Ayacucho Quechua\n\tron_Latn    | Romanian\n\trun_Latn    | Rundi\n\trus_Cyrl    | Russian\n\tsag_Latn    | Sango\n", "san_Deva    | Sanskrit\n\tsat_Olck    | Santali\n\tscn_Latn    | Sicilian\n\tshn_Mymr    | Shan\n\tsin_Sinh    | Sinhala\n\tslk_Latn    | Slovak\n\tslv_Latn    | Slovenian\n\tsmo_Latn    | Samoan\n\tsna_Latn    | Shona\n\tsnd_Arab    | Sindhi\n", "som_Latn    | Somali\n\tsot_Latn    | Southern Sotho\n\tspa_Latn    | Spanish\n\tsrd_Latn    | Sardinian\n\tsrp_Cyrl    | Serbian\n\tssw_Latn    | Swati\n\tsun_Latn    | Sundanese\n\tswe_Latn    | Swedish\n\tswh_Latn    | Swahili\n\tszl_Latn    | Silesian\n", "tam_Taml    | Tamil\n\ttaq_Latn    | Tamasheq (Latin script)\n\ttaq_Tfng    | Tamasheq (Tifinagh script)\n\ttat_Cyrl    | Tatar\n\ttel_Telu    | Telugu\n\ttgk_Cyrl    | Tajik\n\ttgl_Latn    | Tagalog\n\ttha_Thai    | Thai\n\ttir_Ethi    | Tigrinya\n\ttpi_Latn    | Tok Pisin\n", "tsn_Latn    | Tswana\n\ttso_Latn    | Tsonga\n\ttuk_Latn    | Turkmen\n\ttum_Latn    | Tumbuka\n\ttur_Latn    | Turkish\n\ttwi_Latn    | Twi\n\ttzm_Tfng    | Central Atlas Tamazight\n\tuig_Arab    | Uyghur\n\tukr_Cyrl    | Ukrainian\n\tumb_Latn    | Umbundu\n", "urd_Arab    | Urdu\n\tuzn_Latn    | Northern Uzbek\n\tvec_Latn    | Venetian\n\tvie_Latn    | Vietnamese\n\twar_Latn    | Waray\n\twol_Latn    | Wolof\n\txho_Latn    | Xhosa\n\tydd_Hebr    | Eastern Yiddish\n\tyor_Latn    | Yoruba\n\tyue_Hant    | Yue Chinese\n", "zho_Hans    | Chinese (Simplified)\n\tzho_Hant    | Chinese (Traditional)\n\tzsm_Latn    | Standard Malay\n\tzul_Latn    | Zulu\n\t\"\"\"\n\tl = langlist_str.split(\"\\n\")\n\tlanglist = []\n\tfor k in l:\n\t    if k != \"\":\n\t        langlist.append(k[0:8])\n", "#print(langlist)\n\tcuda_opt = -1\n\tto_device = \"cpu\"\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"NLLB Translate with CTranslate2\", # name\n\t        \"version\": \"2.0\", # version\n\t        \"translate\": {\n\t            \"fb_nllb_ctranslate2\": (init,translate) # 1 function - init, 2 - translate\n", "        },\n\t        \"default_options\": {\n\t            \"model\": \"facebook/nllb-200-distilled-600M\",  # key model\n\t            \"cuda\": -1, # -1 if you want run on CPU, 0 - if on CUDA\n\t        },\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    global cuda_opt\n\t    global to_device\n", "    cuda_opt = manifest[\"options\"].get(\"cuda\")\n\t    if cuda_opt == -1:\n\t        to_device = \"cpu\"\n\t    else:\n\t        #to_device = \"cuda:{0}\".format(cuda_opt)\n\t        to_device = \"cuda\".format(cuda_opt)\n\t    pass\n\tdef init(core:OneRingCore):\n\t    from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\t    import ctranslate2\n", "    global model\n\t    #print(to_device)\n\t    #model = AutoModelForSeq2SeqLM.from_pretrained(core.plugin_options(modname).get(\"model\")).to(to_device)\n\t    model = ctranslate2.Translator(core.plugin_options(modname).get(\"model\"), device=to_device)\n\t    pass\n\tdef convert_lang(input_lang:str) -> str:\n\t    if len(input_lang) == 2 or len(input_lang) == 3:\n\t        if input_lang == \"en\" or input_lang == \"eng\":\n\t            return \"eng_Latn\"\n\t        if input_lang == \"ru\":\n", "            return \"rus_Cyrl\"\n\t        for lang in langlist:\n\t            if lang.startswith(input_lang):\n\t                return lang\n\t    else:\n\t        return input_lang\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\t    from_lang_tr = convert_lang(from_lang)\n\t    to_lang_tr = convert_lang(to_lang)\n", "    if tokenizers.get(from_lang_tr) is None:\n\t        tokenizers[from_lang_tr] = AutoTokenizer.from_pretrained(core.plugin_options(modname).get(\"model\"), src_lang=from_lang_tr)\n\t    # if tokenizers.get(to_lang_tr) is None:\n\t    #     tokenizers[to_lang_tr] = AutoTokenizer.from_pretrained(core.plugin_options(modname).get(\"model\"), src_lang=to_lang_tr)\n\t    tokenizer_from = tokenizers.get(from_lang_tr)\n\t    #source = tokenizer_from(text, return_tensors=\"pt\").to(to_device)\n\t    source = tokenizer_from.convert_ids_to_tokens(tokenizer_from.encode(text))\n\t    #source = tokenizer.convert_ids_to_tokens(tokenizer.encode(\"Hello world!\"))\n\t    target_prefix = [to_lang_tr]\n\t    results = model.translate_batch([source], target_prefix=[target_prefix])\n", "    translated_tokens = results[0].hypotheses[0][1:]\n\t    #res = tokenizer_from.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n\t    res = tokenizer_from.decode(tokenizer_from.convert_tokens_to_ids(translated_tokens))\n\t    return res\n"]}
{"filename": "plugins/plugin_fb_mbart50.py", "chunked_list": ["# mbart plugin\n\t# author: Vladislav Janvarev\n\t# from https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\tmodel = None\n\ttokenizers:dict = {}\n\t# -------- lang list\n\t#langlist_str = \"ar_AR,cs_CZ,de_DE,en_XX,es_XX,et_EE,fi_FI,fr_XX,gu_IN,hi_IN,it_IT,ja_XX,kk_KZ,ko_KR,lt_LT,lv_LV,my_MM,ne_NP,nl_XX,ro_RO,ru_RU,si_LK,tr_TR,vi_VN,zh_CN\"\n", "#langlist = langlist_str.split(\",\")\n\tlanglist_str = \"Arabic (ar_AR), Czech (cs_CZ), German (de_DE), English (en_XX), Spanish (es_XX), Estonian (et_EE), Finnish (fi_FI), French (fr_XX), Gujarati (gu_IN), Hindi (hi_IN), Italian (it_IT), Japanese (ja_XX), Kazakh (kk_KZ), Korean (ko_KR), Lithuanian (lt_LT), Latvian (lv_LV), Burmese (my_MM), Nepali (ne_NP), Dutch (nl_XX), Romanian (ro_RO), Russian (ru_RU), Sinhala (si_LK), Turkish (tr_TR), Vietnamese (vi_VN), Chinese (zh_CN), Afrikaans (af_ZA), Azerbaijani (az_AZ), Bengali (bn_IN), Persian (fa_IR), Hebrew (he_IL), Croatian (hr_HR), Indonesian (id_ID), Georgian (ka_GE), Khmer (km_KH), Macedonian (mk_MK), Malayalam (ml_IN), Mongolian (mn_MN), Marathi (mr_IN), Polish (pl_PL), Pashto (ps_AF), Portuguese (pt_XX), Swedish (sv_SE), Swahili (sw_KE), Tamil (ta_IN), Telugu (te_IN), Thai (th_TH), Tagalog (tl_XX), Ukrainian (uk_UA), Urdu (ur_PK), Xhosa (xh_ZA), Galician (gl_ES), Slovene (sl_SI)\"\n\tl = langlist_str.split(\", \")\n\tlanglist = []\n\tfor k in l:\n\t    if k != \"\":\n\t        langlist.append(k[-6:-1])\n\t#print(langlist)\n\tcuda_opt = -1\n\tto_device = \"cpu\"\n", "# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"MBART 50 Translate\", # name\n\t        \"version\": \"2.0\", # version\n\t        \"translate\": {\n\t            \"fb_mbart50\": (init,translate) # 1 function - init, 2 - translate\n\t        },\n\t        \"default_options\": {\n\t            \"model\": \"facebook/mbart-large-50-many-to-many-mmt\",  # key model\n", "            \"cuda\": -1, # -1 if you want run on CPU, 0 - if on CUDA\n\t        },\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    global cuda_opt\n\t    global to_device\n\t    cuda_opt = manifest[\"options\"].get(\"cuda\")\n\t    if cuda_opt == -1:\n\t        to_device = \"cpu\"\n", "    else:\n\t        to_device = \"cuda:{0}\".format(cuda_opt)\n\t    pass\n\tdef init(core:OneRingCore):\n\t    from transformers import MBartForConditionalGeneration\n\t    global model\n\t    #print(to_device)\n\t    model = MBartForConditionalGeneration.from_pretrained(core.plugin_options(modname).get(\"model\")).to(to_device)\n\t    pass\n\tdef convert_lang(input_lang:str) -> str:\n", "    if len(input_lang) == 2:\n\t        # if input_lang == \"en\" or input_lang == \"eng\":\n\t        #     return \"eng_Latn\"\n\t        # if input_lang == \"ru\":\n\t        #     return \"rus_Cyrl\"\n\t        for lang in langlist:\n\t            if lang.startswith(input_lang):\n\t                return lang\n\t    else:\n\t        return input_lang\n", "def translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    from transformers import MBartForConditionalGeneration, MBart50Tokenizer\n\t    from_lang_tr = convert_lang(from_lang)\n\t    to_lang_tr = convert_lang(to_lang)\n\t    full_id = f\"{from_lang_tr}__{to_lang_tr}\"\n\t    # print(from_lang_tr)\n\t    # print(to_lang_tr)\n\t    if tokenizers.get(full_id) is None:\n\t        tokenizers[full_id] = MBart50Tokenizer.from_pretrained(core.plugin_options(modname).get(\"model\"), src_lang=from_lang_tr, tgt_lang=to_lang_tr)\n\t    # if tokenizers.get(to_lang_tr) is None:\n", "    #     tokenizers[to_lang_tr] = AutoTokenizer.from_pretrained(core.plugin_options(modname).get(\"model\"), src_lang=to_lang_tr)\n\t    tokenizer_from = tokenizers.get(full_id)\n\t    inputs = tokenizer_from(text, return_tensors=\"pt\").to(to_device)\n\t    translated_tokens = model.generate(\n\t                            #**inputs, forced_bos_token_id=tokenizer_from.lang_code_to_id[to_lang_tr], max_length=int(len(text)*5)\n\t                            **inputs, forced_bos_token_id=tokenizer_from.lang_code_to_id[to_lang_tr], max_length=int(len(text) * 5)\n\t                        )\n\t    res = tokenizer_from.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n\t    return res\n"]}
{"filename": "plugins/plugin_multi_sources.py", "chunked_list": ["# Multisources\n\t# gain translations from different sources and try to select one best\n\t# author: Vladislav Janvarev\n\timport asyncio\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n", "        \"name\": \"Multi sources plugin\", # name\n\t        \"version\": \"1.3\", # version\n\t        # this is DEFAULT options\n\t        # ACTUAL options is in options/<plugin_name>.json after first run\n\t        \"default_options\": {\n\t            \"model\": \"google_translate,deepl\",  # plugins that will be processed\n\t            \"min_symbols_to_full_model\": 30,\n\t            \"min_plugin\": \"google_translate\", # if symbols less than min, this will be used\n\t            \"multithread_model\": True, # use this if you use different plugins in model - this speedup by multithread tasks\n\t        },\n", "        \"translate\": {\n\t            \"multi_sources\": (init,translate) # 1 function - init, 2 - translate\n\t        }\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n\tdef init(core:OneRingCore):\n\t    from comet import download_model, load_from_checkpoint\n\t    print(\"Activating COMET model...\")\n", "    model_path = download_model(\"Unbabel/wmt20-comet-qe-da\")\n\t    core.comet_model_multi_sources = load_from_checkpoint(model_path)\n\t    print(\"COMET model activated!\")\n\t    pass\n\tasync def run_list(tasks_lists):\n\t    return await asyncio.gather(*tasks_lists)\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    plugins: str = core.plugin_options(modname).get(\"model\").split(\",\")\n\t    min_plugin: str = core.plugin_options(modname).get(\"min_plugin\")\n\t    min_symbols: int = core.plugin_options(modname).get(\"min_symbols_to_full_model\")\n", "    is_multithread_model: bool = core.plugin_options(modname).get(\"multithread_model\")\n\t    #print(len(text), min_symbols)\n\t    if len(text) < min_symbols:\n\t        res_text = core.translate(text, from_lang, to_lang, min_plugin, add_params).get(\"result\")\n\t        print(f\"Min transl {min_plugin}: {res_text}\")\n\t        return res_text\n\t    data0 = []\n\t    if not is_multithread_model:\n\t        data0 = []\n\t        for plugin in plugins:\n", "            data0.append(core.translate(text,from_lang,to_lang,plugin))\n\t    else:\n\t        # ---------- async version - not work inside FastAPI\n\t        # data_async_tasks = []\n\t        # for plugin in plugins:\n\t        #     data_async_tasks.append(asyncio.to_thread(core.translate, text, from_lang, to_lang, plugin,\n\t        #                               add_params))\n\t        #\n\t        # #data0 = asyncio.run(run_list(data_async_tasks))\n\t        # loop = asyncio.new_event_loop()\n", "        # data0 = loop.run_until_complete(run_list(data_async_tasks))\n\t        # ----------- multithread version -----------\n\t        import concurrent.futures\n\t        data0 = []\n\t        with concurrent.futures.ThreadPoolExecutor() as executor:\n\t            futures = [executor.submit(core.translate, text, from_lang, to_lang, plugin) for plugin in plugins]\n\t            for future in concurrent.futures.as_completed(futures):\n\t                result = future.result()\n\t                data0.append(result)\n\t    data = []\n", "    for mt_res in data0:\n\t        data.append({\"src\":text,\"mt\":mt_res.get(\"result\")})\n\t    #print(data)\n\t    pred = core.comet_model_multi_sources.predict(data, batch_size=8, gpus=0)\n\t    #print(model_output)\n\t    scores = pred.get(\"scores\")\n\t    max_ind = scores.index(max(scores))\n\t    #print('Scores:',scores, max_ind)\n\t    return data[max_ind][\"mt\"]\n"]}
{"filename": "plugins/plugin_fb_nllb_translate.py", "chunked_list": ["# nllb plugin\n\t# author: Vladislav Janvarev\n\t# from https://github.com/facebookresearch/fairseq/tree/nllb\n\tfrom oneringcore import OneRingCore\n\timport os\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\tmodel = None\n\ttokenizers:dict = {}\n\t# -------- lang list\n\tlanglist_str = \"\"\"\n", "ace_Arab    | Acehnese (Arabic script)\n\tace_Latn    | Acehnese (Latin script)\n\tacm_Arab    | Mesopotamian Arabic\n\tacq_Arab    | Ta’izzi-Adeni Arabic\n\taeb_Arab    | Tunisian Arabic\n\tafr_Latn    | Afrikaans\n\tajp_Arab    | South Levantine Arabic\n\taka_Latn    | Akan\n\tals_Latn    | Tosk Albanian\n\tamh_Ethi    | Amharic\n", "apc_Arab    | North Levantine Arabic\n\tarb_Arab    | Modern Standard Arabic\n\tarb_Latn    | Modern Standard Arabic (Romanized)\n\tars_Arab    | Najdi Arabic\n\tary_Arab    | Moroccan Arabic\n\tarz_Arab    | Egyptian Arabic\n\tasm_Beng    | Assamese\n\tast_Latn    | Asturian\n\tawa_Deva    | Awadhi\n\tayr_Latn    | Central Aymara\n", "azb_Arab    | South Azerbaijani\n\tazj_Latn    | North Azerbaijani\n\tbak_Cyrl    | Bashkir\n\tbam_Latn    | Bambara\n\tban_Latn    | Balinese\n\tbel_Cyrl    | Belarusian\n\tbem_Latn    | Bemba\n\tben_Beng    | Bengali\n\tbho_Deva    | Bhojpuri\n\tbjn_Arab    | Banjar (Arabic script)\n", "bjn_Latn    | Banjar (Latin script)\n\tbod_Tibt    | Standard Tibetan\n\tbos_Latn    | Bosnian\n\tbug_Latn    | Buginese\n\tbul_Cyrl    | Bulgarian\n\tcat_Latn    | Catalan\n\tceb_Latn    | Cebuano\n\tces_Latn    | Czech\n\tcjk_Latn    | Chokwe\n\tckb_Arab    | Central Kurdish\n", "crh_Latn    | Crimean Tatar\n\tcym_Latn    | Welsh\n\tdan_Latn    | Danish\n\tdeu_Latn    | German\n\tdik_Latn    | Southwestern Dinka\n\tdyu_Latn    | Dyula\n\tdzo_Tibt    | Dzongkha\n\tell_Grek    | Greek\n\teng_Latn    | English\n\tepo_Latn    | Esperanto\n", "est_Latn    | Estonian\n\teus_Latn    | Basque\n\tewe_Latn    | Ewe\n\tfao_Latn    | Faroese\n\tfij_Latn    | Fijian\n\tfin_Latn    | Finnish\n\tfon_Latn    | Fon\n\tfra_Latn    | French\n\tfur_Latn    | Friulian\n\tfuv_Latn    | Nigerian Fulfulde\n", "gaz_Latn    | West Central Oromo\n\tgla_Latn    | Scottish Gaelic\n\tgle_Latn    | Irish\n\tglg_Latn    | Galician\n\tgrn_Latn    | Guarani\n\tguj_Gujr    | Gujarati\n\that_Latn    | Haitian Creole\n\thau_Latn    | Hausa\n\theb_Hebr    | Hebrew\n\thin_Deva    | Hindi\n", "hne_Deva    | Chhattisgarhi\n\thrv_Latn    | Croatian\n\thun_Latn    | Hungarian\n\thye_Armn    | Armenian\n\tibo_Latn    | Igbo\n\tilo_Latn    | Ilocano\n\tind_Latn    | Indonesian\n\tisl_Latn    | Icelandic\n\tita_Latn    | Italian\n\tjav_Latn    | Javanese\n", "jpn_Jpan    | Japanese\n\tkab_Latn    | Kabyle\n\tkac_Latn    | Jingpho\n\tkam_Latn    | Kamba\n\tkan_Knda    | Kannada\n\tkas_Arab    | Kashmiri (Arabic script)\n\tkas_Deva    | Kashmiri (Devanagari script)\n\tkat_Geor    | Georgian\n\tkaz_Cyrl    | Kazakh\n\tkbp_Latn    | Kabiyè\n", "kea_Latn    | Kabuverdianu\n\tkhk_Cyrl    | Halh Mongolian\n\tkhm_Khmr    | Khmer\n\tkik_Latn    | Kikuyu\n\tkin_Latn    | Kinyarwanda\n\tkir_Cyrl    | Kyrgyz\n\tkmb_Latn    | Kimbundu\n\tkmr_Latn    | Northern Kurdish\n\tknc_Arab    | Central Kanuri (Arabic script)\n\tknc_Latn    | Central Kanuri (Latin script)\n", "kon_Latn    | Kikongo\n\tkor_Hang    | Korean\n\tlao_Laoo    | Lao\n\tlij_Latn    | Ligurian\n\tlim_Latn    | Limburgish\n\tlin_Latn    | Lingala\n\tlit_Latn    | Lithuanian\n\tlmo_Latn    | Lombard\n\tltg_Latn    | Latgalian\n\tltz_Latn    | Luxembourgish\n", "lua_Latn    | Luba-Kasai\n\tlug_Latn    | Ganda\n\tluo_Latn    | Luo\n\tlus_Latn    | Mizo\n\tlvs_Latn    | Standard Latvian\n\tmag_Deva    | Magahi\n\tmai_Deva    | Maithili\n\tmal_Mlym    | Malayalam\n\tmar_Deva    | Marathi\n\tmin_Arab    | Minangkabau (Arabic script)\n", "min_Latn    | Minangkabau (Latin script)\n\tmkd_Cyrl    | Macedonian\n\tmlt_Latn    | Maltese\n\tmni_Beng    | Meitei (Bengali script)\n\tmos_Latn    | Mossi\n\tmri_Latn    | Maori\n\tmya_Mymr    | Burmese\n\tnld_Latn    | Dutch\n\tnno_Latn    | Norwegian Nynorsk\n\tnob_Latn    | Norwegian Bokmål\n", "npi_Deva    | Nepali\n\tnso_Latn    | Northern Sotho\n\tnus_Latn    | Nuer\n\tnya_Latn    | Nyanja\n\toci_Latn    | Occitan\n\tory_Orya    | Odia\n\tpag_Latn    | Pangasinan\n\tpan_Guru    | Eastern Panjabi\n\tpap_Latn    | Papiamento\n\tpbt_Arab    | Southern Pashto\n", "pes_Arab    | Western Persian\n\tplt_Latn    | Plateau Malagasy\n\tpol_Latn    | Polish\n\tpor_Latn    | Portuguese\n\tprs_Arab    | Dari\n\tquy_Latn    | Ayacucho Quechua\n\tron_Latn    | Romanian\n\trun_Latn    | Rundi\n\trus_Cyrl    | Russian\n\tsag_Latn    | Sango\n", "san_Deva    | Sanskrit\n\tsat_Olck    | Santali\n\tscn_Latn    | Sicilian\n\tshn_Mymr    | Shan\n\tsin_Sinh    | Sinhala\n\tslk_Latn    | Slovak\n\tslv_Latn    | Slovenian\n\tsmo_Latn    | Samoan\n\tsna_Latn    | Shona\n\tsnd_Arab    | Sindhi\n", "som_Latn    | Somali\n\tsot_Latn    | Southern Sotho\n\tspa_Latn    | Spanish\n\tsrd_Latn    | Sardinian\n\tsrp_Cyrl    | Serbian\n\tssw_Latn    | Swati\n\tsun_Latn    | Sundanese\n\tswe_Latn    | Swedish\n\tswh_Latn    | Swahili\n\tszl_Latn    | Silesian\n", "tam_Taml    | Tamil\n\ttaq_Latn    | Tamasheq (Latin script)\n\ttaq_Tfng    | Tamasheq (Tifinagh script)\n\ttat_Cyrl    | Tatar\n\ttel_Telu    | Telugu\n\ttgk_Cyrl    | Tajik\n\ttgl_Latn    | Tagalog\n\ttha_Thai    | Thai\n\ttir_Ethi    | Tigrinya\n\ttpi_Latn    | Tok Pisin\n", "tsn_Latn    | Tswana\n\ttso_Latn    | Tsonga\n\ttuk_Latn    | Turkmen\n\ttum_Latn    | Tumbuka\n\ttur_Latn    | Turkish\n\ttwi_Latn    | Twi\n\ttzm_Tfng    | Central Atlas Tamazight\n\tuig_Arab    | Uyghur\n\tukr_Cyrl    | Ukrainian\n\tumb_Latn    | Umbundu\n", "urd_Arab    | Urdu\n\tuzn_Latn    | Northern Uzbek\n\tvec_Latn    | Venetian\n\tvie_Latn    | Vietnamese\n\twar_Latn    | Waray\n\twol_Latn    | Wolof\n\txho_Latn    | Xhosa\n\tydd_Hebr    | Eastern Yiddish\n\tyor_Latn    | Yoruba\n\tyue_Hant    | Yue Chinese\n", "zho_Hans    | Chinese (Simplified)\n\tzho_Hant    | Chinese (Traditional)\n\tzsm_Latn    | Standard Malay\n\tzul_Latn    | Zulu\n\t\"\"\"\n\tl = langlist_str.split(\"\\n\")\n\tlanglist = []\n\tfor k in l:\n\t    if k != \"\":\n\t        langlist.append(k[0:8])\n", "#print(langlist)\n\tcuda_opt = -1\n\tto_device = \"cpu\"\n\t# start function\n\tdef start(core:OneRingCore):\n\t    manifest = { # plugin settings\n\t        \"name\": \"NLLB Translate\", # name\n\t        \"version\": \"2.0\", # version\n\t        \"translate\": {\n\t            \"fb_nllb_translate\": (init,translate) # 1 function - init, 2 - translate\n", "        },\n\t        \"default_options\": {\n\t            \"model\": \"facebook/nllb-200-distilled-600M\",  # key model\n\t            \"cuda\": -1, # -1 if you want run on CPU, 0 - if on CUDA\n\t        },\n\t    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    global cuda_opt\n\t    global to_device\n", "    cuda_opt = manifest[\"options\"].get(\"cuda\")\n\t    if cuda_opt == -1:\n\t        to_device = \"cpu\"\n\t    else:\n\t        to_device = \"cuda:{0}\".format(cuda_opt)\n\t    pass\n\tdef init(core:OneRingCore):\n\t    from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\t    global model\n\t    #print(to_device)\n", "    model = AutoModelForSeq2SeqLM.from_pretrained(core.plugin_options(modname).get(\"model\")).to(to_device)\n\t    pass\n\tdef convert_lang(input_lang:str) -> str:\n\t    if len(input_lang) == 2 or len(input_lang) == 3:\n\t        if input_lang == \"en\" or input_lang == \"eng\":\n\t            return \"eng_Latn\"\n\t        if input_lang == \"ru\":\n\t            return \"rus_Cyrl\"\n\t        for lang in langlist:\n\t            if lang.startswith(input_lang):\n", "                return lang\n\t    else:\n\t        return input_lang\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\t    from_lang_tr = convert_lang(from_lang)\n\t    to_lang_tr = convert_lang(to_lang)\n\t    if tokenizers.get(from_lang_tr) is None:\n\t        tokenizers[from_lang_tr] = AutoTokenizer.from_pretrained(core.plugin_options(modname).get(\"model\"), src_lang=from_lang_tr)\n\t    # if tokenizers.get(to_lang_tr) is None:\n", "    #     tokenizers[to_lang_tr] = AutoTokenizer.from_pretrained(core.plugin_options(modname).get(\"model\"), src_lang=to_lang_tr)\n\t    tokenizer_from = tokenizers.get(from_lang_tr)\n\t    inputs = tokenizer_from(text, return_tensors=\"pt\").to(to_device)\n\t    translated_tokens = model.generate(\n\t                            **inputs, forced_bos_token_id=tokenizer_from.lang_code_to_id[to_lang_tr], max_length=int(len(text)*5)\n\t                        )\n\t    res = tokenizer_from.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n\t    return res\n"]}
{"filename": "plugins/plugin_openrouter_chat.py", "chunked_list": ["# Translation throw OpenRouter\n\t# author: Vladislav Janvarev\n\timport os\n\timport openai\n\tfrom oneringcore import OneRingCore\n\timport json\n\tmodname = os.path.basename(__file__)[:-3] # calculating modname\n\t# функция на старте\n\tdef start(core:OneRingCore):\n\t    manifest = {\n", "        \"name\": \"Translation through OpenRouter\",\n\t        \"version\": \"3.1\",\n\t        \"description\": \"After define apiKey allow to translate through OpenRouter.\",\n\t        \"options_label\": {\n\t            \"apiKey\": \"API-key OpenAI\", #\n\t            \"apiBaseUrl\": \"URL for OpenAI (allow OpenAI emulation servers)\",  #\n\t            \"system\": \"System input string.\"\n\t        },\n\t        # this is DEFAULT options\n\t        # ACTUAL options is in options/<plugin_name>.json after first run\n", "        \"default_options\": {\n\t            \"apiKey\": \"\", #\n\t            \"apiBaseUrl\": \"https://openrouter.ai/api/v1\",  #\n\t            \"system\": \"Please translate the user message from {0} to {1}. Make the translation sound as natural as possible. Don't use any non-related phrases in result, answer with only translation text.\",\n\t            \"prompt\": \"{2}\",\n\t            \"model\": \"\",\n\t        },\n\t        \"translate\": {\n\t            \"openrouter_chat\": (init, translate)  # 1 function - init, 2 - translate\n\t        }\n", "    }\n\t    return manifest\n\tdef start_with_options(core:OneRingCore, manifest:dict):\n\t    pass\n\tdef init(core:OneRingCore):\n\t    options = core.plugin_options(modname)\n\t    if options[\"apiKey\"] == \"\" and options[\"apiBaseUrl\"] == \"\":\n\t        raise ValueError(\"Needed API KEY for access\")\n\t    openai.api_key = options[\"apiKey\"]\n\t    if options[\"apiBaseUrl\"] != \"\":\n", "        openai.api_base = options[\"apiBaseUrl\"]\n\tdef translate(core:OneRingCore, text:str, from_lang:str = \"\", to_lang:str = \"\", add_params:str = \"\"):\n\t    options = core.plugin_options(modname)\n\t    from_full_lang = core.dict_2let_to_lang.get(from_lang)\n\t    to_full_lang = core.dict_2let_to_lang.get(to_lang)\n\t    #prompt = f\"Instruction: Translate this text from {from_full_lang} to {to_full_lang}:\\n\\n{text}\"\n\t    prompt = str(options[\"prompt\"]).format(from_full_lang,to_full_lang,text)\n\t    system_text = str(options[\"system\"]).format(from_full_lang,to_full_lang,text)\n\t    messages = []\n\t    messages.append({\"role\": \"system\", \"content\": system_text})\n", "    messages.append({\"role\": \"user\", \"content\": prompt})\n\t    response_big = openai.ChatCompletion.create(\n\t        model=str(options[\"model\"]),\n\t        messages=messages,\n\t        temperature=0.7,\n\t        n=1,\n\t        max_tokens=int(len(prompt) * 1.5),\n\t        headers= { \"HTTP-Referer\": \"https://github.com/janvarev/OneRingTranslator\",\n\t          \"X-Title\": \"OneRingTranslator\" },\n\t    )\n", "    response = response_big[\"choices\"][0][\"message\"]\n\t    #core.chatapp = ChatApp(model=str(options[\"model\"]),system=system_text) # create new chat\n\t    #response = core.chatapp.chat(prompt)  # generate_response(phrase)\n\t    #print(response)\n\t    res = str(response[\"content\"]).strip()\n\t    #print(res)\n\t    return res\n"]}
