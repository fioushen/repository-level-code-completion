{"filename": "test/test_properties.py", "chunked_list": ["from entangled.properties import read_properties, Id, Class, Attribute\n\tdef test_id():\n\t    assert read_properties(\"#myid\") == [Id(\"myid\")]\n\t    assert str(Id(\"myid\")) == \"#myid\"\n\tdef test_class():\n\t    assert read_properties(\".myclass\") == [Class(\"myclass\")]\n\t    assert str(Class(\"myclass\") == \".myclass\")\n\tdef test_attribute():\n\t    assert read_properties(\"key=value\") == [Attribute(\"key\", \"value\")]\n\t    assert read_properties('key =   \"value\"') == [Attribute(\"key\", \"value\")]\n", "def test_properties():\n\t    assert read_properties(\".class #id key=value\") == [\n\t        Class(\"class\"),\n\t        Id(\"id\"),\n\t        Attribute(\"key\", \"value\"),\n\t    ]\n"]}
{"filename": "test/test_cycles.py", "chunked_list": ["from pathlib import Path\n\timport pytest\n\tfrom entangled.tangle import tangle_ref\n\tfrom entangled.markdown_reader import MarkdownReader\n\tfrom entangled.errors.user import CyclicReference\n\tfrom entangled.document import AnnotationMethod\n\tmd_source = \"\"\"\n\tThis should raise a `CyclicReference` error.\n\t``` {.python #hello}\n\t<<hello>>\n", "```\n\tSo should this:\n\t``` {.python #phobos}\n\t<<deimos>>\n\t```\n\t``` {.python #deimos}\n\t<<phobos>>\n\t```\n\talso when tangling from something else:\n\t``` {.python #mars}\n", "<<phobos>>\n\t```\n\tWhat should not throw an error is doubling a reference:\n\t``` {.python #helium}\n\t<<electron>>\n\t<<electron>>\n\t```\n\t``` {.python #electron}\n\tnegative charge\n\t```\n", "\"\"\"\n\tdef test_cycles():\n\t    mr = MarkdownReader(\"-\")\n\t    mr.run(md_source)\n\t    refs = mr.reference_map\n\t    with pytest.raises(CyclicReference):\n\t        tangle_ref(refs, \"hello\")\n\t    with pytest.raises(CyclicReference):\n\t        result, _ = tangle_ref(refs, \"phobos\")\n\t        print(result)\n", "    try:\n\t        tangle_ref(refs, \"mars\")\n\t    except CyclicReference as e:\n\t        assert e.cycle == [\"mars\", \"phobos\", \"deimos\"]\n\t    result, _ = tangle_ref(refs, \"helium\", AnnotationMethod.NAKED)\n\t    assert result == \"negative charge\\nnegative charge\"\n"]}
{"filename": "test/test_markdown_reader.py", "chunked_list": ["from entangled.markdown_reader import MarkdownReader\n\tfrom entangled.commands.stitch import stitch_markdown\n\tfrom entangled.main import configure\n\tdef test_retrieve_same_content(data):\n\t    file = data / \"hello-world\" / \"hello-world.md\"\n\t    with open(file, \"r\") as f:\n\t        md = MarkdownReader(str(file))\n\t        markdown = f.read()\n\t        md.run(markdown)\n\t        assert stitch_markdown(md.reference_map, md.content) == markdown\n", "md_ignore = \"\"\"\n\thello\n\t~~~markdown\n\tThis should be ignored.\n\t``` {.python #hello}\n\t```\n\t~~~\n\tThis shouldn't\n\t``` {.python #goodbye}\n\t```\n", "\"\"\"\n\tdef test_ignore():\n\t    mr = MarkdownReader(\"-\")\n\t    mr.run(md_ignore)\n\t    assert \"hello\" not in mr.reference_map\n\t    assert \"goodbye\" in mr.reference_map\n\tmd_backtics = \"\"\"\n\t``` {.python #hello}\n\t  ```\n\t```\n", "\"\"\"\n\tdef test_backtic_content():\n\t    mr = MarkdownReader(\"-\")\n\t    mr.run(md_backtics)\n\t    assert next(mr.reference_map[\"hello\"]).source == \"  ```\"\n\tmd_unknown_lang = \"\"\"\n\t``` {.too_obscure #hello}\n\t```\n\t\"\"\"\n\tdef test_unknown_language():\n", "    mr = MarkdownReader(\"-\")\n\t    mr.run(md_unknown_lang)\n\t    assert len(mr.reference_map.map) == 0\n"]}
{"filename": "test/test_watch_dir.py", "chunked_list": ["from entangled.config import config\n\tfrom entangled.status import find_watch_dirs, list_input_files\n\tfrom contextlib import chdir\n\tfrom entangled.commands.tangle import tangle\n\tfrom pathlib import Path\n\tindex_md_1 = \"\"\"\n\t# Test\n\t``` {.c file=src/test.c}\n\t#include <stdio.h>\n\tint main() { printf(\"Hello, World!\\\\n\"); return 0; }\n", "```\n\t\"\"\"\n\tindex_md_2 = \"\"\"\n\t``` {.makefile file=Makefile}\n\t.RECIPEPREFIX = >\n\t%.o: %.c\n\t> gcc -c $< -o $@\n\thello: test.o\n\t> gcc $^ -o $@\n\t```\n", "\"\"\"\n\tdata_md = \"\"\"\n\tDon't tangle me!\n\t\"\"\"\n\tdef test_watch_dirs(tmp_path):\n\t    with chdir(tmp_path):\n\t        Path(\"./docs\").mkdir()\n\t        Path(\"./data\").mkdir()\n\t        Path(\"./docs/index.md\").write_text(index_md_1)\n\t        Path(\"./data/data.md\").write_text(data_md)\n", "        with config(watch_list=[\"docs/*.md\"]):\n\t            assert set(find_watch_dirs()) == set([Path(\"./docs\")])\n\t            tangle()\n\t            assert set(find_watch_dirs()) == set([Path(\"./docs\"), Path(\"./src\")])\n\t            Path(\"./docs/index.md\").write_text(index_md_1 + \"\\n\" + index_md_2)\n\t            tangle()\n\t            assert set(find_watch_dirs()) == set([Path(\".\"), Path(\"./docs\"), Path(\"./src\")])\n\t            assert sorted(list_input_files()) == [Path(\"./docs/index.md\")]\n"]}
{"filename": "test/test_modes.py", "chunked_list": ["from contextlib import chdir\n\tfrom entangled.commands import tangle, stitch\n\tfrom entangled.config import config\n\tfrom entangled.filedb import stat\n\tfrom entangled.errors.user import UserError\n\timport pytest\n\tfrom time import sleep\n\tfrom pathlib import Path\n\tdef test_modes(tmp_path: Path):\n\t    with chdir(tmp_path):\n", "        (tmp_path / \"entangled.toml\").write_text(\n\t            'version = \"2.0\"\\n' 'watch_list = [\"docs/**/*.md\"]\\n'\n\t        )\n\t        config.read()\n\t        md = tmp_path / \"docs\" / \"index.md\"\n\t        md.parent.mkdir(parents=True, exist_ok=True)\n\t        md.write_text(\"``` {.python file=src/hello.py}\\n\" 'print(\"hello\")\\n' \"```\\n\")\n\t        tangle()\n\t        sleep(0.1)\n\t        target = tmp_path / \"src\" / \"hello.py\"\n", "        assert target.exists()\n\t        hello_stat1 = stat(target)\n\t        hello_src = target.read_text().splitlines()\n\t        assert hello_src[1] == 'print(\"hello\")'\n\t        md.write_text(\"``` {.python file=src/hello.py}\\n\" 'print(\"goodbye\")\\n' \"```\\n\")\n\t        sleep(0.1)\n\t        md_stat1 = stat(md)\n\t        tangle(show=True)\n\t        sleep(0.1)\n\t        hello_stat2 = stat(target)\n", "        assert hello_stat2 == hello_stat1\n\t        assert not (hello_stat2 > hello_stat1)\n\t        hello_src[1] = 'print(\"bonjour\")'\n\t        (tmp_path / \"src\" / \"hello.py\").write_text(\"\\n\".join(hello_src))\n\t        sleep(0.1)\n\t        hello_stat1 = stat(target)\n\t        # with pytest.raises(UserError):\n\t        tangle()\n\t        sleep(0.1)\n\t        hello_stat2 = stat(target)\n", "        assert hello_stat2 == hello_stat1\n\t        assert not (hello_stat2 > hello_stat1)\n\t        # with pytest.raises(UserError):\n\t        stitch()\n\t        sleep(0.1)\n\t        md_stat2 = stat(md)\n\t        print(md.read_text())\n\t        assert md_stat1 == md_stat2\n\t        assert not (md_stat2 > md_stat1)\n\t        stitch(force=True)\n", "        sleep(0.1)\n\t        md_stat2 = stat(md)\n\t        assert md_stat1 != md_stat2\n\t        assert md_stat2 > md_stat1\n"]}
{"filename": "test/__init__.py", "chunked_list": []}
{"filename": "test/test_config.py", "chunked_list": ["from entangled.config.version import Version\n\tfrom entangled.config.language import Language, Comment\n\tfrom entangled.config import config, Config, AnnotationMethod, default\n\tfrom entangled.commands import tangle\n\tfrom entangled.construct import construct\n\tfrom contextlib import chdir\n\tfrom time import sleep\n\tfrom pathlib import Path\n\tdef test_config_constructable():\n\t    assert construct(Version, \"1.2.3\") == Version((1, 2, 3))\n", "    assert construct(\n\t        Language,\n\t        {\"name\": \"French\", \"identifiers\": [\"fr\"], \"comment\": {\"open\": \"excusez moi\"}},\n\t    ) == Language(\"French\", [\"fr\"], Comment(\"excusez moi\"))\n\t    assert construct(Config, {\"version\": \"2.0\"}) == Config(version=Version((2, 0)))\n\t    assert construct(Config, {\"version\": \"2.0\", \"annotation\": \"naked\"}) == Config(\n\t        version=Version((2, 0)), annotation=AnnotationMethod.NAKED\n\t    )\n\tconfig_with_language = \"\"\"\n\tversion = \"2.0\"\n", "annotation = \"naked\"\n\t[[languages]]\n\tname = \"Fish\"\n\tidentifiers = [\"fish\"]\n\tcomment = { open = \"#\" }\n\t\"\"\"\n\tmd_source = \"\"\"\n\t``` {.fish file=test.fish}\n\techo hello world\n\t```\n", "\"\"\"\n\tdef test_new_language(tmp_path):\n\t    with chdir(tmp_path):\n\t        Path(\"entangled.toml\").write_text(config_with_language)\n\t        Path(\"test.md\").write_text(md_source)\n\t        sleep(0.1)\n\t        config.read()\n\t        assert config.annotation == AnnotationMethod.NAKED\n\t        tangle()\n\t        sleep(0.1)\n", "        assert Path(\"test.fish\").exists()\n\t        assert Path(\"test.fish\").read_text() == \"echo hello world\"\n\tconfig_with_more = \"\"\"\n\t# required: the minimum version of Entangled\n\tversion = \"2.0\"            \n\t# default watch_list is [\"**/*.md\"]\n\twatch_list = [\"docs/**/*.md\"]\n\t[[languages]]\n\tname = \"Custom Java\"\n\tidentifiers = [\"java\"]\n", "comment = { open = \"//\" }\n\t[[languages]]\n\tname = \"XML\"\n\tidentifiers = [\"xml\", \"html\", \"svg\"]\n\tcomment = { open = \"<!--\", close = \"-->\" }\n\t\"\"\"\n\tdef test_more_language(tmp_path):\n\t    with chdir(tmp_path):\n\t        Path(\"entangled.toml\").write_text(config_with_more)\n\t        sleep(0.1)\n", "        config.read()\n\t        assert config.get_language(\"html\").name == \"XML\"\n\t        assert config.get_language(\"java\").name == \"Custom Java\"\n\tconfig_in_pyproject = \"\"\"\n\t[tool.entangled]\n\tversion = \"2.0\"\n\twatch_list = [\"docs/*.md\"]\n\t\"\"\"\n\tdef test_pyproject_toml(tmp_path):\n\t    with chdir(tmp_path):\n", "        Path(\"pyproject.toml\").write_text(\"answer=42\")\n\t        sleep(0.1)\n\t        config.read()\n\t        assert config.config == default\n\t        Path(\"pyproject.toml\").write_text(config_in_pyproject)\n\t        sleep(0.1)\n\t        config.read()\n\t        assert config.watch_list == [\"docs/*.md\"]\n"]}
{"filename": "test/test_cli.py", "chunked_list": ["from entangled.main import cli\n\tfrom entangled.version import __version__\n\tfrom contextlib import contextmanager, chdir\n\timport sys\n\timport pytest\n\tfrom pathlib import Path\n\tfrom time import sleep\n\t@contextmanager\n\tdef argv(*args):\n\t    old = sys.argv\n", "    sys.argv = [\"entangled\"] + list(args)\n\t    yield\n\t    sys.argv = old\n\tdef test_version(capsys):\n\t    with argv(\"--version\"):\n\t        with pytest.raises(SystemExit):\n\t            cli()\n\t        captured = capsys.readouterr()\n\t        assert captured.out.strip() == f\"Entangled {__version__}\"\n\tdef test_watch(tmp_path):\n", "    with chdir(tmp_path):\n\t        Path(\"./entangled.toml\").write_text(\"\\n\".join(['version=\"2.0\"']))\n\t        Path(\"./test.md\").write_text(\n\t            \"\\n\".join([\"``` {.python file=test.py}\", 'print(\"hello\")', \"```\"])\n\t        )\n\t        with argv(\"--debug\", \"tangle\"):\n\t            cli()\n\t            assert Path(\"./test.py\").exists()\n"]}
{"filename": "test/test_missing_ref.py", "chunked_list": ["from entangled.tangle import tangle_ref\n\tfrom entangled.config import AnnotationMethod\n\tfrom entangled.markdown_reader import MarkdownReader\n\tfrom entangled.errors.user import MissingReference\n\timport pytest\n\tmd_source = \"\"\"\n\t``` {.scheme #hello}\n\t(display \"hello\") (newline)\n\t<<goodbye>>\n\t```\n", "\"\"\"\n\tdef test_missing_ref(tmp_path):\n\t    with pytest.raises(MissingReference):\n\t        mr = MarkdownReader(\"-\")\n\t        mr.run(md_source)\n\t        tangle_ref(mr.reference_map, \"hello\", AnnotationMethod.NAKED)\n"]}
{"filename": "test/test_daemon.py", "chunked_list": ["from pathlib import Path\n\timport time\n\timport os\n\tfrom entangled.config import config\n\tfrom entangled.filedb import stat\n\timport threading\n\tfrom entangled.commands.watch import _watch\n\tfrom entangled.main import configure\n\tfrom contextlib import chdir\n\tdef test_daemon(tmp_path: Path):\n", "    config.read()\n\t    with chdir(tmp_path):\n\t        try:\n\t            configure(debug=True)\n\t            stop = threading.Event()\n\t            t = threading.Thread(target=_watch, args=(stop,))\n\t            t.start()\n\t            Path(\"main.md\").write_text(\n\t                \"``` {.scheme file=hello.scm}\\n\" '(display \"hello\") (newline)\\n' \"```\\n\"\n\t            )\n", "            time.sleep(0.1)\n\t            md_stat1 = stat(Path(\"main.md\"))\n\t            assert Path(\"hello.scm\").exists()\n\t            lines = Path(\"hello.scm\").read_text().splitlines()\n\t            goodbye = '(display \"goodbye\") (newline)'\n\t            lines.insert(2, goodbye)\n\t            Path(\"hello.scm\").write_text(\"\\n\".join(lines))\n\t            time.sleep(0.2)\n\t            md_stat2 = stat(Path(\"main.md\"))\n\t            assert md_stat1 != md_stat2\n", "            assert md_stat1 < md_stat2\n\t            lines = Path(\"main.md\").read_text().splitlines()\n\t            assert lines[2] == goodbye\n\t            lines[0] = \"``` {.scheme file=foo.scm}\"\n\t            Path(\"main.md\").write_text(\"\\n\".join(lines))\n\t            time.sleep(0.1)\n\t            assert not Path(\"hello.scm\").exists()\n\t            assert Path(\"foo.scm\").exists()\n\t        finally:\n\t            stop.set()\n", "            t.join()\n\t            time.sleep(0.1)\n"]}
{"filename": "test/test_transaction.py", "chunked_list": ["from contextlib import chdir\n\tfrom pathlib import Path\n\tfrom entangled.transaction import Transaction, Create, Write, Delete\n\tfrom entangled.filedb import file_db\n\tdef test_transaction(tmp_path: Path):\n\t    with chdir(tmp_path):\n\t        with file_db() as db:\n\t            t = Transaction(db)\n\t            t.write(Path(\"a\"), \"hello\", [])\n\t            t.write(Path(\"b\"), \"goodbye\", [Path(\"a\")])\n", "            assert all(isinstance(a, Create) for a in t.actions)\n\t            t.run()\n\t            assert Path(\"a\").exists()\n\t            assert Path(\"b\").exists()\n\t        with open(Path(\"a\"), \"w\") as f:\n\t            f.write(\"ciao\")\n\t        with file_db() as db:\n\t            assert Path(\"a\") in db\n\t            assert Path(\"b\") in db\n\t            assert list(db.changed()) == [Path(\"a\")]\n", "            t = Transaction(db)\n\t            t.write(Path(\"b\"), \"goodbye\", [])\n\t            assert t.actions == []\n\t            t.write(Path(\"a\"), \"buongiorno\", [])\n\t            assert isinstance(t.actions[0], Write)\n\t            assert not t.all_ok()\n\t        with file_db() as db:\n\t            t = Transaction(db)\n\t            t.write(Path(\"a\"), \"goodbye\", [])\n\t            assert isinstance(t.actions[0], Write)\n", "            t.clear_orphans()\n\t            assert isinstance(t.actions[1], Delete)\n\t            t.run()\n\t            assert not Path(\"b\").exists()\n"]}
{"filename": "test/test_build_hook.py", "chunked_list": ["from contextlib import chdir\n\tfrom entangled.config import config\n\tfrom entangled.commands import tangle\n\tfrom uuid import uuid4\n\tfrom time import sleep\n\tfrom pathlib import Path\n\timport os\n\tmd_input = \"\"\"\n\tCreate a file:\n\t``` {{.python file=script.py}}\n", "print(\"{message}\", end=\"\")\n\t```\n\t``` {{.makefile #build target=test.dat}}\n\ttest.dat: script.py\n\t> python $< > $@\n\t```\n\t\"\"\"\n\tdef test_build(tmp_path):\n\t    message = uuid4().hex\n\t    with chdir(tmp_path):\n", "        with open(\"test.md\", \"w\") as f:\n\t            f.write(md_input.format(message=message))\n\t        with config(hooks=[\"build\"]):\n\t            # normally, build hooks are disabled in CI,\n\t            # here we need to make an exception\n\t            if \"CI\" in os.environ:\n\t                del os.environ[\"CI\"]\n\t                tangle()\n\t                os.environ[\"CI\"] = \"true\"\n\t            else:\n", "                tangle()\n\t        sleep(0.1)\n\t        tgt = Path(\"test.dat\")\n\t        assert tgt.exists()\n\t        contents = open(tgt, \"r\").read()\n\t        assert contents == message\n"]}
{"filename": "test/test_filedb.py", "chunked_list": ["from entangled.filedb import file_db, stat\n\tfrom time import sleep\n\tfrom pathlib import Path\n\timport pytest\n\tfrom contextlib import chdir\n\t@pytest.fixture(scope=\"session\")\n\tdef example_files(tmp_path_factory: pytest.TempPathFactory):\n\t    tmp_path = tmp_path_factory.mktemp(\"test-filedb\")\n\t    with open(tmp_path / \"a\", \"w\") as f:\n\t        f.write(\"hello\")\n", "    sleep(0.01)\n\t    with open(tmp_path / \"b\", \"w\") as f:\n\t        f.write(\"hello\")\n\t    with open(tmp_path / \"c\", \"w\") as f:\n\t        f.write(\"goodbye\")\n\t    with open(tmp_path / \"d\", \"w\") as f:\n\t        f.write(\"earth\")\n\t    return tmp_path\n\tdef test_stat(example_files: Path):\n\t    with chdir(example_files):\n", "        stat_a = stat(example_files / \"a\")\n\t        stat_b = stat(example_files / \"b\")\n\t        stat_c = stat(example_files / \"c\")\n\t        assert stat_a == stat_b\n\t        assert stat_c != stat_b\n\t        assert stat_a < stat_b\n\tdef test_filedb(example_files: Path):\n\t    with chdir(example_files):\n\t        with file_db() as db:\n\t            for n in \"abcd\":\n", "                db.update(Path(n))\n\t        with open(example_files / \"d\", \"w\") as f:\n\t            f.write(\"mars\")\n\t        with file_db() as db:\n\t            assert db.changed() == [Path(\"d\")]\n\t            db.update(Path(\"d\"))\n\t            assert db.changed() == []\n"]}
{"filename": "test/conftest.py", "chunked_list": ["import pytest\n\tfrom pathlib import Path\n\t@pytest.fixture\n\tdef data():\n\t    return Path(__file__).parent / \"data\"\n\t@pytest.fixture(params=list((Path(__file__).parent / \"data\").glob(\"*.md\")))\n\tdef markdown(request):\n\t    with open(request.param, \"r\") as f:\n\t        yield f.read()\n"]}
{"filename": "test/test_tangle.py", "chunked_list": ["from entangled.markdown_reader import read_markdown\n\tfrom entangled.tangle import tangle_ref\n\tfrom entangled.code_reader import CodeReader\n\tfrom pathlib import Path\n\timport os\n\tfrom shutil import copytree, move\n\tfrom contextlib import chdir\n\tdef test_tangle_ref(data, tmp_path):\n\t    copytree(data / \"hello-world\", tmp_path / \"hello-world\")\n\t    with chdir(tmp_path / \"hello-world\"):\n", "        refs, _ = read_markdown(Path(\"hello-world.md\"))\n\t        tangled, deps = tangle_ref(refs, \"hello_world.cc\")\n\t        assert deps == {\"hello-world.md\"}\n\t        with open(\"hello_world.cc\", \"r\") as f:\n\t            assert f.read() == tangled\n\t        cb_old = next(refs[\"hello-world\"]).source\n\t        cr = CodeReader(\"-\", refs).run(Path(\"hello_universe.cc\").read_text())\n\t        cb_new = next(refs[\"hello-world\"]).source\n\t        assert cb_old != cb_new\n"]}
{"filename": "test/test_indentation_errors.py", "chunked_list": ["from entangled.commands import tangle, stitch\n\tfrom entangled.markdown_reader import MarkdownReader, read_markdown\n\tfrom entangled.code_reader import CodeReader\n\tfrom entangled.errors.user import IndentationError\n\tfrom contextlib import chdir\n\tfrom pathlib import Path\n\tfrom time import sleep\n\timport pytest\n\tmd_source = \"\"\"\n\t``` {.scheme file=hello.scm}\n", "(display \"hello\") (newline)\n\t(let (x 42)\n\t  <<print-x>>\n\t)\n\t```\n\t``` {.scheme #print-x}\n\t(display x)\n\t  <<newline>>\n\t```\n\t``` {.scheme #newline}\n", "(newline)\n\t```\n\t\"\"\"\n\tscm_output1 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n\t(display \"hello\") (newline)\n\t(let (x 42)\n\t  ; ~/~ begin <<test.md#print-x>>[init]\n\t  (display x)\n\t    ; ~/~ begin <<test.md#newline>>[init]\n\t    (newline)\n", "    ; ~/~ end\n\t  ; ~/~ end\n\t)\n\t; ~/~ end\"\"\"\n\tscm_changed1 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n\t(display \"goodbye\") (newline)\n\t(let (x 42)\n\t  ; ~/~ begin <<test.md#print-x>>[init]\n\t  (display x)\n\t    ; ~/~ begin <<test.md#newline>>[init]\n", "    (newline)\n\t    ; ~/~ end\n\t  ; ~/~ end\n\t)\n\t    ; ~/~ end\"\"\"\n\tscm_changed2 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n\t(display \"hello\") (newline)\n\t(let (x 42)\n\t  ; ~/~ begin <<test.md#print-x>>[init]\n\t  (display x)\n", ";   ; ~/~ begin <<test.md#newline>>[init]\n\t    (newline)\n\t    ; ~/~ end\n\t  ; ~/~ end\n\t)\n\t; ~/~ end\"\"\"\n\tscm_changed3 = \"\"\"; ~/~ begin <<test.md#hello.scm>>[init]\n\t(display \"hello\") (newline)\n\t(let (x 42)\n\t  ; ~/~ begin <<test.md#print-x>>[init]\n", "  (display x)\n\t    ; ~/~ begin <<test.md#newline>>[init]\n\t  (newline)\n\t    ; ~/~ end\n\t  ; ~/~ end\n\t)\n\t; ~/~ end\"\"\"\n\tdef test_code_indentation(tmp_path):\n\t    with chdir(tmp_path):\n\t        src = Path(\"test.md\")\n", "        src.write_text(md_source)\n\t        sleep(0.1)\n\t        tangle()\n\t        sleep(0.1)\n\t        tgt = Path(\"hello.scm\")\n\t        assert tgt.exists() and tgt.read_text() == scm_output1\n\t        refs, _ = read_markdown(src)\n\t        tgt.write_text(scm_changed1)\n\t        sleep(0.1)\n\t        with pytest.raises(IndentationError):\n", "            CodeReader(tgt, refs).run(tgt.read_text())\n\t        stitch()\n\t        sleep(0.1)\n\t        assert src.read_text() == md_source\n\t        for errs in [scm_changed1, scm_changed2, scm_changed3]:\n\t            with pytest.raises(IndentationError):\n\t                CodeReader(\"-\", refs).run(errs)\n\tmd_source_error = \"\"\"\n\t  ``` {.scheme file=hello.scm}\n\t(display \"hello\") (newline)\n", "```\n\t\"\"\"\n\tdef test_md_indentation():\n\t    with pytest.raises(IndentationError):\n\t        MarkdownReader(\"-\").run(md_source_error)\n"]}
{"filename": "entangled/code_reader.py", "chunked_list": ["from dataclasses import dataclass, field\n\tfrom pathlib import Path\n\timport mawk\n\timport re\n\tfrom .document import ReferenceId, TextLocation, ReferenceMap\n\tfrom .errors.user import IndentationError\n\t@dataclass\n\tclass Frame:\n\t    ref: ReferenceId\n\t    indent: str\n", "    content: list[str] = field(default_factory=list)\n\tclass CodeReader(mawk.RuleSet):\n\t    \"\"\"Reads an annotated code file.\"\"\"\n\t    def __init__(self, path: str, refs: ReferenceMap):\n\t        self.location = TextLocation(path, 0)\n\t        self.stack: list[Frame] = [Frame(ReferenceId(\"root\", \"\", -1), \"\")]\n\t        self.refs: ReferenceMap = refs\n\t    @property\n\t    def current(self) -> Frame:\n\t        return self.stack[-1]\n", "    @mawk.always\n\t    def increase_line_number(self, _):\n\t        self.location.line_number += 1\n\t    @mawk.on_match(\n\t        r\"^(?P<indent>\\s*).* ~/~ begin <<(?P<source>[^#<>]+)#(?P<ref_name>[^#<>]+)>>\\[(?P<ref_count>init|\\d+)\\]\"\n\t    )\n\t    def on_block_begin(self, m: re.Match):\n\t        ref_name = m[\"ref_name\"]\n\t        if m[\"ref_count\"] == \"init\":\n\t            ref_count = 0\n", "            if not m[\"indent\"].startswith(self.current.indent):\n\t                raise IndentationError(self.location)\n\t            indent = m[\"indent\"].removeprefix(self.current.indent)\n\t            self.current.content.append(f\"{indent}<<{ref_name}>>\")\n\t        else:\n\t            ref_count = int(m[\"ref_count\"])\n\t        self.stack.append(\n\t            Frame(ReferenceId(m[\"ref_name\"], m[\"source\"], ref_count), m[\"indent\"])\n\t        )\n\t        return []\n", "    @mawk.on_match(r\"^(?P<indent>\\s*).* ~/~ end\")\n\t    def on_block_end(self, m: re.Match):\n\t        if m[\"indent\"] != self.current.indent:\n\t            raise IndentationError(self.location)\n\t        self.refs[self.current.ref].source = \"\\n\".join(self.current.content)\n\t        self.stack.pop()\n\t        return []\n\t    @mawk.always\n\t    def otherwise(self, line: str):\n\t        if line.strip() == \"\":\n", "            self.current.content.append(\"\")\n\t            return []\n\t        if not line.startswith(self.current.indent):\n\t            raise IndentationError(self.location)\n\t        self.current.content.append(line.removeprefix(self.current.indent))\n\t        return []\n"]}
{"filename": "entangled/markdown_reader.py", "chunked_list": ["from typing import Optional\n\tfrom copy import copy\n\tfrom pathlib import Path\n\timport re\n\timport mawk\n\timport logging\n\tfrom .config import config\n\tfrom .utility import first\n\tfrom .document import TextLocation, CodeBlock, ReferenceMap, Content, PlainText\n\tfrom .properties import read_properties, get_attribute, get_classes, get_id\n", "from .hooks.base import HookBase\n\tfrom .errors.user import ParseError, IndentationError\n\tfrom . import parsing\n\tclass MarkdownReader(mawk.RuleSet):\n\t    \"\"\"Reads a Markdown file, and splits it up into code blocks and other\n\t    content. The contents of the code blocks get stored in `reference_map`.\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        filename: str,\n", "        refs: Optional[ReferenceMap] = None,\n\t        hooks: Optional[list[HookBase]] = None,\n\t    ):\n\t        self.location = TextLocation(filename)\n\t        self.reference_map = refs or ReferenceMap()\n\t        self.content: list[Content] = []\n\t        self.inside_codeblock: bool = False\n\t        self.current_content: list[str] = []\n\t        self.ignore = False\n\t        self.hooks = hooks or []\n", "    def flush_plain_text(self):\n\t        self.content.append(PlainText(\"\\n\".join(self.current_content)))\n\t        self.current_content = []\n\t    @mawk.always\n\t    def on_next_line(self, _):\n\t        self.location.line_number += 1\n\t    @mawk.on_match(config.markers.begin_ignore)\n\t    def on_begin_ignore(self, _):\n\t        self.ignore = True\n\t        logging.debug(\"ignoring markdown block %s\", self.location)\n", "    @mawk.on_match(config.markers.end_ignore)\n\t    def on_end_ignore(self, _):\n\t        self.ignore = False\n\t        logging.debug(\"end of ignore\")\n\t    @mawk.on_match(config.markers.open)\n\t    def on_open_codeblock(self, m: re.Match) -> Optional[list[str]]:\n\t        if self.ignore:\n\t            return None\n\t        if self.inside_codeblock:\n\t            return None\n", "        self.current_codeblock_indent = m[\"indent\"]\n\t        self.current_codeblock_location = copy(self.location)\n\t        self.current_content.append(m[0])\n\t        try:\n\t            self.current_codeblock_properties = read_properties(m[\"properties\"])\n\t            self.flush_plain_text()\n\t            self.inside_codeblock = True\n\t        except parsing.Failure as f:\n\t            logging.error(\"Parsing error at %s: %s\", self.location, f)\n\t            logging.error(\"Continuing parsing rest of document.\")\n", "        return []\n\t    @mawk.on_match(config.markers.close)\n\t    def on_close_codeblock(self, m: re.Match):\n\t        if self.ignore:\n\t            return\n\t        if not self.inside_codeblock:\n\t            return\n\t        if len(m[\"indent\"]) < len(self.current_codeblock_indent):\n\t            raise IndentationError(self.location)\n\t        if m[\"indent\"] != self.current_codeblock_indent:\n", "            return  # treat this as code-block content\n\t        # add block to reference-map\n\t        language_class = first(get_classes(self.current_codeblock_properties))\n\t        block_id = get_id(self.current_codeblock_properties)\n\t        target_file = get_attribute(self.current_codeblock_properties, \"file\")\n\t        ref_name = block_id or target_file\n\t        language = config.get_language(language_class) if language_class else None\n\t        if ref_name is None or language is None:\n\t            self.flush_plain_text()\n\t        else:\n", "            ref = self.reference_map.new_id(\n\t                self.current_codeblock_location.filename, ref_name\n\t            )\n\t            code = CodeBlock(\n\t                language,\n\t                self.current_codeblock_properties,\n\t                self.current_codeblock_indent,\n\t                \"\\n\".join(\n\t                    line.removeprefix(self.current_codeblock_indent)\n\t                    for line in self.current_content\n", "                ),\n\t                self.current_codeblock_location,\n\t            )\n\t            # logging.debug(repr(code))\n\t            self.reference_map[ref] = code\n\t            if target_file is not None:\n\t                self.reference_map.targets.add(target_file)\n\t            self.content.append(ref)\n\t            self.current_content = []\n\t            for h in self.hooks:\n", "                if h.condition(self.current_codeblock_properties):\n\t                    h.on_read(ref, code)\n\t        self.current_content.append(m[0])\n\t        self.inside_codeblock = False\n\t        return []\n\t    @mawk.always\n\t    def add_line(self, line: str):\n\t        self.current_content.append(line)\n\t        return []\n\t    def on_eof(self):\n", "        self.flush_plain_text()\n\t        return []\n\tdef read_markdown(path: Path) -> tuple[ReferenceMap, list[Content]]:\n\t    with open(path, \"r\") as f:\n\t        path_str = str(path.resolve().relative_to(Path.cwd()))\n\t        md = MarkdownReader(path_str)\n\t        md.run(f.read())\n\t    return md.reference_map, md.content\n"]}
{"filename": "entangled/status.py", "chunked_list": ["from .config import config\n\tfrom .filedb import file_db\n\tfrom itertools import chain\n\tfrom pathlib import Path\n\tdef find_watch_dirs():\n\t    \"\"\"List all directories that contain files that need watching.\"\"\"\n\t    input_file_list = list_input_files()\n\t    markdown_dirs = set(p.parent for p in input_file_list)\n\t    with file_db(readonly=True) as db:\n\t        code_dirs = set(p.parent for p in db.managed)\n", "    return code_dirs.union(markdown_dirs)\n\tdef list_input_files():\n\t    \"\"\"List all input files.\"\"\"\n\t    return chain.from_iterable(map(Path(\".\").glob, config.watch_list))\n\tdef list_dependent_files():\n\t    with file_db(readonly=True) as db:\n\t        result = list(db.managed)\n\t    return result\n"]}
{"filename": "entangled/version.py", "chunked_list": ["import importlib.metadata\n\t__version__ = importlib.metadata.version(\"entangled-cli\")\n"]}
{"filename": "entangled/utility.py", "chunked_list": ["from typing import Iterable, Optional, TypeVar, TypeGuard, Union\n\tfrom dataclasses import is_dataclass\n\tfrom contextlib import contextmanager\n\timport os\n\tfrom pathlib import Path\n\timport typing\n\timport types\n\tT = TypeVar(\"T\")\n\tdef first(it: Iterable[T]) -> Optional[T]:\n\t    try:\n", "        return next(iter(it))\n\t    except StopIteration:\n\t        return None\n\tdef normal_relative(path: Path) -> Path:\n\t    return path.resolve().relative_to(Path.cwd())\n\tdef ensure_parent(path: Path) -> Path:\n\t    path.parent.mkdir(parents=True, exist_ok=True)\n\t    return path\n\tdef cat_maybes(it: Iterable[Optional[T]]) -> Iterable[T]:\n\t    def pred(x: Optional[T]) -> TypeGuard[T]:\n", "        return x is not None\n\t    return filter(pred, it)\n"]}
{"filename": "entangled/construct.py", "chunked_list": ["from typing import Union\n\tfrom dataclasses import is_dataclass\n\tfrom enum import Enum\n\timport typing\n\timport types\n\tfrom .parsing import Parser\n\tdef isgeneric(annot):\n\t    return hasattr(annot, \"__origin__\") and hasattr(annot, \"__args__\")\n\tdef construct(annot, json):\n\t    \"\"\"Construct an object from a given type from a JSON stream.\n", "    The `annot` type should be one of: str, int, list[T], Optional[T],\n\t    or a dataclass, and the JSON data should match exactly the given\n\t    definitions in the dataclass hierarchy.\n\t    \"\"\"\n\t    if annot is str:\n\t        assert isinstance(json, str)\n\t        return json\n\t    if annot is int:\n\t        assert isinstance(json, int)\n\t        return json\n", "    if isinstance(json, str) and isinstance(annot, Parser):\n\t        result, _ = annot.read(json)\n\t        return result\n\t    if isgeneric(annot) and typing.get_origin(annot) is list:\n\t        assert isinstance(json, list)\n\t        return [construct(typing.get_args(annot)[0], item) for item in json]\n\t    if (\n\t        isgeneric(annot)\n\t        and typing.get_origin(annot) is Union\n\t        and typing.get_args(annot)[1] is types.NoneType\n", "    ):\n\t        if json is None:\n\t            return None\n\t        else:\n\t            return construct(typing.get_args(annot)[0], json)\n\t    if is_dataclass(annot):\n\t        assert isinstance(json, dict)\n\t        arg_annot = typing.get_type_hints(annot)\n\t        # assert all(k in json for k in arg_annot)\n\t        args = {k: construct(arg_annot[k], json[k]) for k in json}\n", "        return annot(**args)\n\t    if isinstance(json, str) and issubclass(annot, Enum):\n\t        options = {opt.name.lower(): opt for opt in annot}\n\t        assert json.lower() in options\n\t        return options[json.lower()]\n\t    raise ValueError(f\"Couldn't construct {annot} from {repr(json)}\")\n"]}
{"filename": "entangled/tangle.py", "chunked_list": ["from typing import Optional, TypeVar, Generic, Union\n\tfrom dataclasses import dataclass, field\n\tfrom textwrap import indent\n\tfrom contextlib import contextmanager\n\tfrom copy import copy\n\timport re\n\timport mawk\n\tfrom .document import (\n\t    ReferenceMap,\n\t    AnnotationMethod,\n", "    TextLocation,\n\t    ReferenceId,\n\t    CodeBlock,\n\t)\n\tfrom .errors.user import CyclicReference, MissingReference\n\tfrom .config import config\n\tT = TypeVar(\"T\")\n\t@dataclass\n\tclass Visitor(Generic[T]):\n\t    _visited: dict[T, int] = field(default_factory=dict)\n", "    def in_order(self) -> list[T]:\n\t        return [k for k, v in sorted(self._visited.items(), key=lambda kv: kv[1])]\n\t    @contextmanager\n\t    def visit(self, x: T):\n\t        if x in self._visited:\n\t            raise CyclicReference(str(x), list(map(str, self.in_order())))\n\t        self._visited[x] = len(self._visited)\n\t        yield\n\t        del self._visited[x]\n\t@dataclass\n", "class Tangler(mawk.RuleSet):\n\t    refs: ReferenceMap\n\t    ref: ReferenceId\n\t    init: bool\n\t    visited: Visitor[str]\n\t    deps: set[str] = field(init=False)\n\t    cb: CodeBlock = field(init=False)\n\t    location: TextLocation = field(init=False)\n\t    def __post_init__(self):\n\t        self.cb = self.refs[self.ref]\n", "        self.location = copy(self.cb.origin)\n\t        self.deps = set((self.cb.origin.filename,))\n\t    @mawk.always\n\t    def lineno(self, _):\n\t        self.location.line_number += 1\n\t    @mawk.on_match(r\"^(?P<indent>\\s*)<<(?P<refname>[\\w-]+)>>\\s*$\")\n\t    def on_noweb(self, m: re.Match):\n\t        try:\n\t            result, deps = tangle_ref(self.refs, m[\"refname\"], type(self), self.visited)\n\t        except KeyError:\n", "            raise MissingReference(m[\"refname\"], self.location)\n\t        self.deps.update(deps)\n\t        return [indent(result, m[\"indent\"])]\n\t    def run(self):\n\t        return super().run(self.cb.source)\n\t@dataclass\n\tclass AnnotatedTangler(Tangler):\n\t    close_comment: str = field(init=False)\n\t    def __post_init__(self):\n\t        super().__post_init__()\n", "        self.close_comment = (\n\t            \"\"\n\t            if self.cb.language.comment.close is None\n\t            else f\" {self.cb.language.comment.close}\"\n\t        )\n\t    def on_begin(self):\n\t        count = \"init\" if self.init else str(self.ref.ref_count)\n\t        return [\n\t            f\"{self.cb.language.comment.open} ~/~ begin <<{self.ref.file}#{self.ref.name}>>[{count}]{self.close_comment}\"\n\t        ]\n", "    def on_eof(self):\n\t        return [f\"{self.cb.language.comment.open} ~/~ end{self.close_comment}\"]\n\ttanglers = {\n\t    AnnotationMethod.NAKED: Tangler,\n\t    AnnotationMethod.STANDARD: AnnotatedTangler,\n\t    AnnotationMethod.SUPPLEMENTED: AnnotatedTangler,\n\t}\n\tdef tangle_ref(\n\t    refs: ReferenceMap,\n\t    ref_name: str,\n", "    annotation: Union[type[Tangler], AnnotationMethod] = config.annotation,\n\t    _visited: Optional[Visitor[str]] = None,\n\t) -> tuple[str, set[str]]:\n\t    if ref_name not in refs:\n\t        raise KeyError(ref_name)\n\t    v = _visited or Visitor()\n\t    if isinstance(annotation, AnnotationMethod):\n\t        tangler = tanglers[annotation]\n\t    else:\n\t        tangler = annotation\n", "    with v.visit(ref_name):\n\t        init = True\n\t        result = []\n\t        deps = set()\n\t        for ref in refs.index[ref_name]:\n\t            t = tangler(refs, ref, init, v)\n\t            result.append(t.run())\n\t            deps.update(t.deps)\n\t            init = False\n\t    return \"\\n\".join(result), deps\n"]}
{"filename": "entangled/main.py", "chunked_list": ["import argh  # type: ignore\n\timport logging\n\timport sys\n\ttry:\n\t    from rich.logging import RichHandler\n\t    from rich.highlighter import RegexHighlighter\n\t    WITH_RICH = True\n\texcept ImportError:\n\t    WITH_RICH = False\n\tfrom .commands import tangle, stitch, sync, watch, status\n", "from .errors.internal import bug_contact\n\tfrom .errors.user import UserError\n\tfrom .version import __version__\n\tif WITH_RICH:\n\t    class BackTickHighlighter(RegexHighlighter):\n\t        highlights = [r\"`(?P<bold>[^`]*)`\"]\n\tdef configure(debug=False):\n\t    if debug:\n\t        level = logging.DEBUG\n\t    else:\n", "        level = logging.INFO\n\t    if WITH_RICH:\n\t        FORMAT = \"%(message)s\"\n\t        logging.basicConfig(\n\t            level=level,\n\t            format=FORMAT,\n\t            datefmt=\"[%X]\",\n\t            handlers=[RichHandler(show_path=debug, highlighter=BackTickHighlighter())],\n\t        )\n\t        logging.debug(\"Rich logging enabled\")\n", "    else:\n\t        logging.basicConfig(level=level)\n\t        logging.debug(\"Plain logging enabled\")\n\t    logging.info(f\"Entangled {__version__} (https://entangled.github.io/)\")\n\tdef cli():\n\t    import argparse\n\t    try:\n\t        parser = argparse.ArgumentParser()\n\t        parser.add_argument(\n\t            \"-d\", \"--debug\", action=\"store_true\", help=\"enable debug messages\"\n", "        )\n\t        parser.add_argument(\n\t            \"-v\", \"--version\", action=\"store_true\", help=\"show version number\"\n\t        )\n\t        argh.add_commands(parser, [tangle, stitch, sync, watch, status])\n\t        args = parser.parse_args()\n\t        if args.version:\n\t            print(f\"Entangled {__version__}\")\n\t            sys.exit(0)\n\t        configure(args.debug)\n", "        argh.dispatch(parser)\n\t    except KeyboardInterrupt:\n\t        logging.info(\"Goodbye\")\n\t        sys.exit(0)\n\t    except UserError as e:\n\t        logging.info(str(e))\n\t        sys.exit(0)\n\t    except Exception as e:\n\t        logging.error(str(e))\n\t        bug_contact(e)\n", "        sys.exit(1)\n\tif __name__ == \"__main__\":\n\t    cli()\n"]}
{"filename": "entangled/properties.py", "chunked_list": ["\"\"\"Properties of code blocks. These properties are the same as CSS selector\n\tproperties: id, class and attribute.\"\"\"\n\tfrom __future__ import annotations\n\tfrom typing import Optional, Union, ClassVar, Iterable\n\tfrom dataclasses import dataclass\n\timport re\n\tfrom .parsing import (\n\t    Parser,\n\t    many,\n\t    choice,\n", "    tokenize,\n\t    matching,\n\t    Parsable,\n\t    starmap,\n\t    Failure,\n\t)\n\t@dataclass\n\tclass Id(Parsable):\n\t    value: str\n\t    _pattern: ClassVar[Parser] = matching(r\"#([a-zA-Z]\\S*)\")\n", "    def __str__(self):\n\t        return f\"#{self.value}\"\n\t    @staticmethod\n\t    def __parser__():\n\t        return Id._pattern >> starmap(Id)\n\t@dataclass\n\tclass Class(Parsable):\n\t    value: str\n\t    _pattern: ClassVar[Parser] = matching(r\"\\.([a-zA-Z]\\S*)\")\n\t    def __str__(self):\n", "        return f\".{self.value}\"\n\t    @staticmethod\n\t    def __parser__():\n\t        return Class._pattern >> starmap(Class)\n\t@dataclass\n\tclass Attribute(Parsable):\n\t    key: str\n\t    value: str\n\t    _pattern1: ClassVar[Parser] = matching(\n\t        r\"([a-zA-Z]\\S*)\\s*=\\s*\\\"([^\\\"\\\\]*(?:\\\\.[^\\\"\\\\]*)*)\\\"\"\n", "    )\n\t    _pattern2: ClassVar[Parser] = matching(r\"([a-zA-Z]\\S*)\\s*=\\s*(\\S+)\")\n\t    def __str__(self):\n\t        return f'{self.key}=\"{self.value}\"'\n\t    @staticmethod\n\t    def __parser__():\n\t        return choice(Attribute._pattern1, Attribute._pattern2) >> starmap(Attribute)\n\tProperty = Union[Attribute, Class, Id]\n\tdef read_properties(inp: str) -> list[Property]:\n\t    \"\"\"Read properties from a string. Example:\n", "    >>> read_properties(\".python #foo file=bar.py\")\n\t    [Id(\"python\"), Class(\"foo\"), Attribute(\"file\", \"bar.py\")]\n\t    \"\"\"\n\t    # Explicit typing is needed to convince MyPy of correctness\n\t    # parsers: list[Parser[Property]] = [Id, Class, Attribute]\n\t    result, _ = many(tokenize(choice(Id, Class, Attribute))).read(inp)\n\t    return result\n\tdef get_id(props: list[Property]) -> Optional[str]:\n\t    \"\"\"Get the first given Id in a property list.\"\"\"\n\t    try:\n", "        return next(p.value for p in props if isinstance(p, Id))\n\t    except StopIteration:\n\t        return None\n\tdef get_classes(props: list[Property]) -> Iterable[str]:\n\t    \"\"\"Get all given Classes in a property list.\"\"\"\n\t    return (p.value for p in props if isinstance(p, Class))\n\tdef get_attribute(props: list[Property], key: str) -> Optional[str]:\n\t    \"\"\"Get the value of an Attribute in a property list.\"\"\"\n\t    try:\n\t        return next(p.value for p in props if isinstance(p, Attribute) and p.key == key)\n", "    except StopIteration:\n\t        return None\n"]}
{"filename": "entangled/document.py", "chunked_list": ["from typing import Union, Iterable, Any\n\tfrom dataclasses import dataclass, field\n\tfrom collections import defaultdict\n\tfrom functools import singledispatchmethod\n\tfrom itertools import chain\n\tfrom .config import Language, AnnotationMethod, config\n\tfrom .properties import Property, get_attribute\n\tfrom .errors.internal import InternalError\n\tdef length(iter: Iterable[Any]) -> int:\n\t    return sum(1 for _ in iter)\n", "@dataclass\n\tclass ReferenceId:\n\t    name: str\n\t    file: str\n\t    ref_count: int\n\t    def __hash__(self):\n\t        return hash((self.name, self.file, self.ref_count))\n\t@dataclass\n\tclass PlainText:\n\t    content: str\n", "Content = Union[PlainText, ReferenceId]\n\t@dataclass\n\tclass TextLocation:\n\t    filename: str\n\t    line_number: int = 0\n\t    def __str__(self):\n\t        return f\"{self.filename}:{self.line_number}\"\n\t@dataclass\n\tclass CodeBlock:\n\t    language: Language\n", "    properties: list[Property]\n\t    indent: str\n\t    source: str\n\t    origin: TextLocation\n\t@dataclass\n\tclass ReferenceMap:\n\t    map: dict[ReferenceId, CodeBlock] = field(default_factory=dict)\n\t    index: defaultdict[str, list[ReferenceId]] = field(\n\t        default_factory=lambda: defaultdict(list)\n\t    )\n", "    targets: set[str] = field(default_factory=set)\n\t    def names(self) -> Iterable[str]:\n\t        return self.index.keys()\n\t    def by_name(self, n: str) -> Iterable[CodeBlock]:\n\t        return (self.map[r] for r in self.index[n])\n\t    def new_id(self, filename: str, name: str) -> ReferenceId:\n\t        c = length(filter(lambda r: r.file == filename, self.index[name]))\n\t        return ReferenceId(name, filename, c)\n\t    def __setitem__(self, key: ReferenceId, value: CodeBlock):\n\t        if key in self.map:\n", "            raise InternalError(\"Duplicate key in ReferenceMap\", [key])\n\t        self.map[key] = value\n\t        self.index[key.name].append(key)\n\t    def __contains__(self, key: str) -> bool:\n\t        return key in self.index\n\t    @singledispatchmethod\n\t    def __getitem__(self, key):\n\t        raise NotImplementedError(f\"Invalid key: {type(key)}\")\n\t    @__getitem__.register\n\t    def _(self, key: ReferenceId) -> CodeBlock:\n", "        return self.map[key]\n\t    @__getitem__.register\n\t    def _(self, key: str) -> Iterable[CodeBlock]:\n\t        return self.by_name(key)\n"]}
{"filename": "entangled/__init__.py", "chunked_list": []}
{"filename": "entangled/transaction.py", "chunked_list": ["from typing import Optional, Iterable\n\tfrom dataclasses import dataclass, field\n\tfrom pathlib import Path\n\tfrom contextlib import contextmanager\n\tfrom enum import Enum\n\timport logging\n\ttry:\n\t    import rich\n\t    WITH_RICH = True\n\texcept ImportError:\n", "    WITH_RICH = False\n\tfrom .utility import cat_maybes\n\tfrom .filedb import FileDB, stat, file_db\n\tfrom .errors.internal import InternalError\n\t@dataclass\n\tclass Action:\n\t    target: Path\n\t    def conflict(self, _: FileDB) -> Optional[str]:\n\t        \"\"\"Indicate wether the action might have conflicts. This could be\n\t        inconsistency in the modification times of files, or overwriting\n", "        a file that is not managed by Entangled.\"\"\"\n\t        raise NotImplementedError()\n\t    def run(self, _: FileDB):\n\t        \"\"\"Run the action, if `interact` is `True` then confirmation is\n\t        asked in case of a conflict.\"\"\"\n\t        raise NotImplementedError()\n\t@dataclass\n\tclass Create(Action):\n\t    content: str\n\t    sources: list[Path]\n", "    def conflict(self, _) -> Optional[str]:\n\t        if self.target.exists():\n\t            return f\"{self.target} already exists and is not managed by Entangled\"\n\t        return None\n\t    def run(self, db: FileDB):\n\t        self.target.parent.mkdir(parents=True, exist_ok=True)\n\t        with open(self.target, \"w\") as f:\n\t            f.write(self.content)\n\t        db.update(self.target, self.sources)\n\t        if self.sources != []:\n", "            db.managed.add(self.target)\n\t    def __str__(self):\n\t        return f\"create `{self.target}`\"\n\t@dataclass\n\tclass Write(Action):\n\t    content: str\n\t    sources: list[Path]\n\t    def conflict(self, db: FileDB) -> Optional[str]:\n\t        st = stat(self.target)\n\t        if st != db[self.target]:\n", "            return f\"`{self.target}` seems to have changed outside the control of Entangled\"\n\t        if self.sources:\n\t            newest_src = max(stat(s) for s in self.sources)\n\t            if st > newest_src:\n\t                return f\"`{self.target}` seems to be newer than `{newest_src.path}`\"\n\t        return None\n\t    def run(self, db: FileDB):\n\t        with open(self.target, \"w\") as f:\n\t            f.write(self.content)\n\t        db.update(self.target, self.sources)\n", "    def __str__(self):\n\t        return f\"write `{self.target}`\"\n\t@dataclass\n\tclass Delete(Action):\n\t    def conflict(self, db: FileDB) -> Optional[str]:\n\t        st = stat(self.target)\n\t        if st != db[self.target]:\n\t            return (\n\t                f\"{self.target} seems to have changed outside the control of Entangled\"\n\t            )\n", "        return None\n\t    def run(self, db: FileDB):\n\t        self.target.unlink()\n\t        parent = self.target.parent\n\t        while list(parent.iterdir()) == []:\n\t            parent.rmdir()\n\t            parent = parent.parent\n\t        del db[self.target]\n\t    def __str__(self):\n\t        return f\"delete `{self.target}`\"\n", "@dataclass\n\tclass Transaction:\n\t    db: FileDB\n\t    updates: list[Path] = field(default_factory=list)\n\t    actions: list[Action] = field(default_factory=list)\n\t    passed: set[Path] = field(default_factory=set)\n\t    def update(self, path: Path):\n\t        self.updates.append(path)\n\t    def write(self, path: Path, content: str, sources: list[Path]):\n\t        if path in self.passed:\n", "            raise InternalError(\"Path is being written to twice\", [path])\n\t        self.passed.add(path)\n\t        if path not in self.db:\n\t            logging.debug(\"creating target `%s`\", path)\n\t            self.actions.append(Create(path, content, sources))\n\t        elif not self.db.check(path, content):\n\t            logging.debug(\"target `%s` changed\", path)\n\t            self.actions.append(Write(path, content, sources))\n\t        else:\n\t            logging.debug(\"target `%s` unchanged\", path)\n", "    def clear_orphans(self):\n\t        orphans = self.db.managed - self.passed\n\t        if not orphans:\n\t            return\n\t        logging.info(\"orphans found: `%s`\", \", \".join(map(str, orphans)))\n\t        for p in orphans:\n\t            self.actions.append(Delete(p))\n\t    def check_conflicts(self) -> list[str]:\n\t        return list(cat_maybes(a.conflict(self.db) for a in self.actions))\n\t    def all_ok(self) -> bool:\n", "        return all(a.conflict(self.db) is None for a in self.actions)\n\t    def print_plan(self):\n\t        if not self.actions:\n\t            logging.info(\"Nothing to be done.\")\n\t        for a in self.actions:\n\t            logging.info(str(a))\n\t        for c in self.check_conflicts():\n\t            logging.warning(str(c))\n\t    def run(self):\n\t        for a in self.actions:\n", "            a.run(self.db)\n\t        for f in self.updates:\n\t            self.db.update(f)\n\tclass TransactionMode(Enum):\n\t    SHOW = 1\n\t    FAIL = 2\n\t    CONFIRM = 3\n\t    FORCE = 4\n\t@contextmanager\n\tdef transaction(mode: TransactionMode = TransactionMode.FAIL):\n", "    with file_db() as db:\n\t        tr = Transaction(db)\n\t        logging.debug(\"Open transaction\")\n\t        yield tr\n\t        tr.print_plan()\n\t        match mode:\n\t            case TransactionMode.SHOW:\n\t                logging.info(\"nothing is done\")\n\t                return\n\t            case TransactionMode.FAIL:\n", "                if not tr.all_ok():\n\t                    logging.error(\n\t                        \"conflicts found, breaking off (use `--force` to run anyway)\"\n\t                    )\n\t                    return\n\t            case TransactionMode.CONFIRM:\n\t                if not tr.all_ok():\n\t                    reply = input(\"Ok to continue? (y/n) \")\n\t                    if not (reply == \"y\" or reply == \"yes\"):\n\t                        return\n", "            case TransactionMode.FORCE:\n\t                logging.warning(\"conflicts found, but continuing anyway\")\n\t        logging.debug(\"Executing transaction\")\n\t        tr.run()\n"]}
{"filename": "entangled/filedb.py", "chunked_list": ["from __future__ import annotations\n\tfrom typing import Optional, Iterable\n\tfrom dataclasses import dataclass\n\tfrom datetime import datetime\n\tfrom contextlib import contextmanager\n\tfrom pathlib import Path\n\timport hashlib\n\timport json\n\timport os\n\timport logging\n", "from filelock import FileLock\n\tfrom .version import __version__\n\tfrom .utility import normal_relative, ensure_parent\n\t@dataclass\n\tclass FileStat:\n\t    path: Path\n\t    deps: Optional[list[Path]]\n\t    modified: datetime\n\t    hexdigest: str\n\t    @staticmethod\n", "    def from_path(path: Path, deps: Optional[list[Path]]):\n\t        stat = os.stat(path)\n\t        with open(path, \"rb\") as f:\n\t            hash = hashlib.sha256(f.read())\n\t        return FileStat(\n\t            path, deps, datetime.fromtimestamp(stat.st_mtime), hash.hexdigest()\n\t        )\n\t    def __lt__(self, other: FileStat) -> bool:\n\t        return self.modified < other.modified\n\t    def __eq__(self, other: object) -> bool:\n", "        return isinstance(other, FileStat) and self.hexdigest == other.hexdigest\n\t    @staticmethod\n\t    def from_json(data) -> FileStat:\n\t        return FileStat(\n\t            Path(data[\"path\"]),\n\t            None if data[\"deps\"] is None else [Path(d) for d in data[\"deps\"]],\n\t            datetime.fromisoformat(data[\"modified\"]),\n\t            data[\"hexdigest\"],\n\t        )\n\t    def to_json(self):\n", "        return {\n\t            \"path\": str(self.path),\n\t            \"deps\": None if self.deps is None else [str(p) for p in self.deps],\n\t            \"modified\": self.modified.isoformat(),\n\t            \"hexdigest\": self.hexdigest,\n\t        }\n\tdef stat(path: Path, deps: Optional[list[Path]] = None) -> FileStat:\n\t    path = normal_relative(path)\n\t    deps = None if deps is None else [normal_relative(d) for d in deps]\n\t    return FileStat.from_path(path, deps)\n", "@dataclass\n\tclass FileDB:\n\t    \"\"\"Persistent storage for file stats of both Markdown and generated\n\t    files. We can use this to detect conflicts.\n\t    This data is stored in `.entangled/files.json`. It is recommended to\n\t    keep this file under version control. That way entangled shouldn't get\n\t    too confused when switching branches.\n\t    All files are stored in a single dictionary, the distinction between\n\t    source and target files is made in two separate indices.\"\"\"\n\t    _files: dict[Path, FileStat]\n", "    _source: set[Path]\n\t    _target: set[Path]\n\t    @staticmethod\n\t    def path():\n\t        return Path(\".\") / \".entangled\" / \"filedb.json\"\n\t    @staticmethod\n\t    def read() -> FileDB:\n\t        logging.debug(\"Reading FileDB\")\n\t        raw = json.load(open(FileDB.path()))\n\t        return FileDB(\n", "            {stat.path: stat for stat in (FileStat.from_json(r) for r in raw[\"files\"])},\n\t            set(map(Path, raw[\"source\"])),\n\t            set(map(Path, raw[\"target\"])),\n\t        )\n\t    @property\n\t    def managed(self) -> set[Path]:\n\t        return self._target\n\t    def write(self):\n\t        logging.debug(\"Writing FileDB\")\n\t        raw = {\n", "            \"version\": __version__,\n\t            \"files\": [stat.to_json() for stat in self._files.values()],\n\t            \"source\": list(map(str, self._source)),\n\t            \"target\": list(map(str, self._target)),\n\t        }\n\t        json.dump(raw, open(FileDB.path(), \"w\"), indent=2)\n\t    def changed(self) -> list[Path]:\n\t        \"\"\"List all target files that have changed w.r.t. the database.\"\"\"\n\t        return [p for p, s in self._files.items() if s != stat(p)]\n\t    def has_changed(self, path: Path) -> bool:\n", "        return stat(path) != self[path]\n\t    def update(self, path: Path, deps: Optional[list[Path]] = None):\n\t        \"\"\"Update the given path to a new stat.\"\"\"\n\t        path = normal_relative(path)\n\t        if path in self.managed and deps is None:\n\t            deps = self[path].deps\n\t        self._files[path] = stat(path, deps)\n\t    def __contains__(self, path: Path) -> bool:\n\t        return path in self._files\n\t    def __getitem__(self, path: Path) -> FileStat:\n", "        return self._files[path]\n\t    def __delitem__(self, path: Path):\n\t        if path in self._target:\n\t            self._target.remove(path)\n\t        del self._files[path]\n\t    @property\n\t    def files(self) -> Iterable[Path]:\n\t        return self._files.keys()\n\t    def check(self, path: Path, content: str) -> bool:\n\t        return (\n", "            hashlib.sha256(content.encode()).hexdigest() == self._files[path].hexdigest\n\t        )\n\t    @staticmethod\n\t    def initialize() -> FileDB:\n\t        if FileDB.path().exists():\n\t            db = FileDB.read()\n\t            undead = list(filter(lambda p: not p.exists(), db.files))\n\t            for path in undead:\n\t                logging.warning(\n\t                    \"File `%s` in DB doesn't exist. Removing entry from DB.\", path\n", "                )\n\t                del db[path]\n\t            return db\n\t        FileDB.path().parent.mkdir(parents=True, exist_ok=True)\n\t        data = {\"version\": __version__, \"files\": [], \"source\": [], \"target\": []}\n\t        json.dump(data, open(FileDB.path(), \"w\"))\n\t        return FileDB.read()\n\t@contextmanager\n\tdef file_db(readonly=False):\n\t    lock = FileLock(ensure_parent(Path.cwd() / \".entangled\" / \"filedb.lock\"))\n", "    with lock:\n\t        db = FileDB.initialize()\n\t        yield db\n\t        if not readonly:\n\t            db.write()\n"]}
{"filename": "entangled/parsing.py", "chunked_list": ["\"\"\"Monadic recursive descent parser combinator. This is used to custom \n\tlight weight parsing within Entangled, mainly parsing the class, id and\n\tattribute properties of code blocks in markdown.\"\"\"\n\tfrom __future__ import annotations\n\tfrom dataclasses import dataclass\n\tfrom typing import (\n\t    TypeVar,\n\t    TypeVarTuple,\n\t    Generic,\n\t    Callable,\n", "    Union,\n\t    Any,\n\t    Optional,\n\t    ParamSpec,\n\t)\n\timport re\n\tT = TypeVar(\"T\")\n\tTs = TypeVarTuple(\"Ts\")\n\tU = TypeVar(\"U\")\n\tP = ParamSpec(\"P\")\n", "T_co = TypeVar(\"T_co\", covariant=True)\n\t@dataclass\n\tclass Failure(Exception):\n\t    \"\"\"Base class for parser failures.\"\"\"\n\t    msg: str\n\t    def __str__(self):\n\t        return self.msg\n\tclass EndOfInput(Failure):\n\t    \"\"\"Raised at end of input.\"\"\"\n\t    def __init__(self):\n", "        super().__init__(\"end of input\")\n\t@dataclass\n\tclass Expected(Failure):\n\t    \"\"\"Input was different than expected.\"\"\"\n\t    inp: str\n\t    @property\n\t    def expected(self):\n\t        return self.msg\n\t    def __str__(self):\n\t        if len(inp) > 20:\n", "            inp = f\"{inp[:20]} ...\"\n\t        return f'expected: {self.expected}, got: \"{self.inp}\"'\n\t@dataclass\n\tclass ChoiceFailure(Expected):\n\t    \"\"\"All options of a choice parser failed.\"\"\"\n\t    failures: list[Failure]\n\t    @property\n\t    def expected(self):\n\t        return \" | \".join(str(f) for f in self.failures)\n\tclass Parser(Generic[T]):\n", "    \"\"\"Base class for parsers.\"\"\"\n\t    def read(self, inp: str) -> tuple[T, str]:\n\t        \"\"\"Read a string and return an object the remainder of the string.\"\"\"\n\t        raise NotImplementedError()\n\t    def __rshift__(self, f: Callable[[T], Parser[U]]) -> Parser[U]:\n\t        return bind(self, f)\n\t    def then(self, p: Parser[U]) -> Parser[U]:\n\t        return bind(self, lambda _: p)\n\tdef starmap(f: Callable[..., U]) -> Callable[[tuple], Parser[U]]:\n\t    return lambda args: pure(f(*args))\n", "class ParserMeta(Generic[T], Parser[T], type):\n\t    def read(cls, inp: str) -> tuple[T, str]:\n\t        return cls.__parser__().read(inp)  # type: ignore\n\tclass Parsable(Generic[T], metaclass=ParserMeta):\n\t    \"\"\"Base class for Parsable objects. Parsables need to define a\n\t    `__parser__()` method that should return a `Parser[Self]`. That\n\t    way a Parsable class is also a `Parser` object for itself.\n\t    This allows for nicely expressive grammars.\"\"\"\n\t    pass\n\t@dataclass\n", "class ParserWrapper(Generic[T], Parser[T]):\n\t    \"\"\"Wrapper class for functional parser.\"\"\"\n\t    f: Callable[[str], tuple[T, str]]\n\t    def read(self, inp: str) -> tuple[T, str]:\n\t        return self.f(inp)\n\tdef fmap(f: Callable[[T], U]) -> Callable[[T], Parser[U]]:\n\t    \"\"\"Map a parser action over a function.\"\"\"\n\t    return lambda x: pure(f(x))\n\tdef parser(f: Callable[[str], tuple[T, str]]) -> Parser[T]:\n\t    \"\"\"Parser decorator.\"\"\"\n", "    return ParserWrapper(f)\n\tdef pure(x: T) -> Parser[T]:\n\t    \"\"\"Parser that always succeeds and returns value `x`.\"\"\"\n\t    return parser(lambda inp: (x, inp))\n\tdef fail(msg: str) -> Parser[Any]:\n\t    \"\"\"Parser that always fails with a message `msg`.\"\"\"\n\t    @parser\n\t    def _fail(_: str) -> tuple[Any, str]:\n\t        raise Failure(msg)\n\t    return _fail\n", "@parser\n\tdef item(inp: str) -> tuple[str, str]:\n\t    \"\"\"Parser that takes a single character from a string.\"\"\"\n\t    if len(inp) == 0:\n\t        raise EndOfInput\n\t    return inp[0], inp[1:]\n\tdef bind(p: Parser[T], f: Callable[[T], Parser[U]]) -> Parser[U]:\n\t    \"\"\"Fundamental monadic combinator. First parses `p`, then passes\n\t    the value to `f`, giving a new parser that also knows the result\n\t    of the first one.\"\"\"\n", "    @parser\n\t    def bound(inp: str):\n\t        x, inp = p.read(inp)\n\t        return f(x).read(inp)\n\t    return bound\n\t# class Sequence(Generic[*Ts], ParserWrapper[tuple[*Ts]]):\n\t#     \"\"\"Parses a sequence of parsers to a tuple of results. A Sequence\n\t#     parser can be extended using the `*` operator.\"\"\"\n\t#     def __mul__(self, q: Parser[U]):\n\t#         return Sequence(self >> (lambda t: q >> (lambda x: pure(t + (x,)))))\n", "# seq = Sequence(pure(()))\n\tdef choice(*options: Parser[Any]) -> Parser[Any]:\n\t    @parser\n\t    def _choice(inp: str) -> tuple[T, str]:\n\t        failures = []\n\t        for o in options:\n\t            try:\n\t                return o.read(inp)\n\t            except Failure as f:\n\t                failures.append(f)\n", "                continue\n\t        raise ChoiceFailure(\"\", inp, failures)\n\t    return _choice\n\tdef optional(p: Parser[T], default: Optional[U] = None) -> Parser[Union[T, U]]:\n\t    return choice(p, pure(default))\n\tdef many(p: Parser[T]) -> Parser[list[T]]:\n\t    @parser\n\t    def _many(inp: str) -> tuple[list[T], str]:\n\t        result: list[T] = []\n\t        while True:\n", "            try:\n\t                value, inp = p.read(inp)\n\t                result.append(value)\n\t            except Failure:\n\t                break\n\t        return result, inp\n\t    return _many\n\tdef matching(regex: str) -> Parser[re.Match]:\n\t    pattern = re.compile(f\"^{regex}\")\n\t    @parser\n", "    def _matching(inp: str):\n\t        if m := pattern.match(inp):\n\t            return m.groups(), inp[m.end() :]\n\t        raise Expected(f\"/^{regex}/\", inp)\n\t    return _matching\n\tdef fullmatch(regex: str) -> Parser[str]:\n\t    pattern = re.compile(f\"^{regex}\")\n\t    @parser\n\t    def _fullmatch(inp: str):\n\t        if m := pattern.match(inp):\n", "            return m[0], inp[m.end() :]\n\t        raise Expected(f\"/^{regex}/\", inp)\n\t    return _fullmatch\n\tspace = matching(r\"\\s+\")\n\tdef tokenize(p: Parser[T]) -> Parser[T]:\n\t    return optional(space).then(p)\n"]}
{"filename": "entangled/commands/status.py", "chunked_list": ["from __future__ import annotations\n\tfrom ..status import find_watch_dirs, list_input_files, list_dependent_files\n\tfrom ..config import config\n\tfrom pathlib import Path\n\ttry:\n\t    from rich.console import Console, Group\n\t    from rich.columns import Columns\n\t    from rich.table import Table\n\t    from rich.panel import Panel\n\t    from rich.tree import Tree\n", "    WITH_RICH = True\n\texcept ImportError:\n\t    WITH_RICH = False\n\tdef tree_from_files(files):\n\t    tree = Tree(label=\".\")\n\t    dirs = { Path(\".\"): tree }\n\t    for f in sorted(files):\n\t        for p in reversed(f.parents):\n\t            if p not in dirs:\n\t                dirs[p] = dirs[p.parent].add(p.name, style=\"repr.path\")\n", "        dirs[f.parent].add(f.name, style=\"repr.filename\")\n\t    return tree\n\tdef files_panel(file_list: list[str], title: str) -> Panel:\n\t    tree = tree_from_files(file_list)\n\t    return Panel(tree, title=title, border_style=\"dark_cyan\")\n\tdef rich_status():\n\t    cfg = config.config\n\t    config_table = Table()\n\t    config_table.add_column(\"name\")\n\t    config_table.add_column(\"value\")\n", "    config_table.add_row(\"Watch list\", \", \".join(f\"'{pat}'\" for pat in cfg.watch_list))\n\t    config_table.add_row(\"Hooks enabled\", \", \".join(cfg.hooks))\n\t    console = Console(color_system=\"auto\")\n\t    group = Group(\n\t        Panel(config_table, title=\"config\", border_style=\"dark_cyan\"),\n\t        Columns([\n\t            files_panel(list_input_files(), \"input files\"),\n\t            files_panel(list_dependent_files(), \"dependent files\"),\n\t        ]),\n\t    )\n", "    console.print(group)\n\tdef status():\n\t    if WITH_RICH:\n\t        rich_status()\n\t    else:\n\t        print(config)\n\t        print(\"---\")\n\t        print(\"input files:\", sorted(list_input_files()))\n"]}
{"filename": "entangled/commands/tangle.py", "chunked_list": ["from typing import Optional\n\tfrom itertools import chain\n\tfrom pathlib import Path\n\timport argh  # type: ignore\n\timport logging\n\tfrom ..document import ReferenceMap\n\tfrom ..config import config, AnnotationMethod\n\tfrom ..markdown_reader import MarkdownReader\n\tfrom ..transaction import transaction, TransactionMode\n\tfrom ..tangle import tangle_ref\n", "from ..hooks import get_hooks\n\tfrom ..errors.user import UserError\n\t@argh.arg(\n\t    \"-a\",\n\t    \"--annotate\",\n\t    choices=[m.name.lower() for m in AnnotationMethod],\n\t    help=\"annotation method\",\n\t)\n\t@argh.arg(\"--force\", help=\"force overwrite on conflict\")\n\t@argh.arg(\"-s\", \"--show\", help=\"only show, don't act\")\n", "def tangle(*, annotate: Optional[str] = None, force: bool = False, show: bool = False):\n\t    \"\"\"Tangle codes from Markdown\"\"\"\n\t    if annotate is None:\n\t        annotation_method = config.annotation\n\t    else:\n\t        annotation_method = AnnotationMethod[annotate.upper()]\n\t    input_file_list = chain.from_iterable(map(Path(\".\").glob, config.watch_list))\n\t    refs = ReferenceMap()\n\t    hooks = get_hooks()\n\t    if show:\n", "        mode = TransactionMode.SHOW\n\t    elif force:\n\t        mode = TransactionMode.FORCE\n\t    else:\n\t        mode = TransactionMode.FAIL\n\t    try:\n\t        with transaction(mode) as t:\n\t            for path in input_file_list:\n\t                logging.debug(\"reading `%s`\", path)\n\t                t.update(path)\n", "                with open(path, \"r\") as f:\n\t                    MarkdownReader(str(path), refs, hooks).run(f.read())\n\t            for tgt in refs.targets:\n\t                result, deps = tangle_ref(refs, tgt, annotation_method)\n\t                t.write(Path(tgt), result, list(map(Path, deps)))\n\t            t.clear_orphans()\n\t        for h in hooks:\n\t            h.post_tangle(refs)\n\t    except UserError as e:\n\t        logging.error(str(e))\n"]}
{"filename": "entangled/commands/stitch.py", "chunked_list": ["from itertools import chain\n\tfrom pathlib import Path\n\tfrom textwrap import indent\n\timport logging\n\timport argh  # type: ignore\n\tfrom ..config import config\n\tfrom ..code_reader import CodeReader\n\tfrom ..markdown_reader import MarkdownReader\n\tfrom ..document import ReferenceMap, Content, PlainText, ReferenceId\n\tfrom ..transaction import transaction, TransactionMode\n", "from ..errors.user import UserError\n\tdef stitch_markdown(reference_map: ReferenceMap, content: list[Content]) -> str:\n\t    def get(item: Content):\n\t        match item:\n\t            case PlainText(s):\n\t                return s\n\t            case ReferenceId():\n\t                return indent(reference_map[item].source, reference_map[item].indent)\n\t    return \"\\n\".join(get(i) for i in content) + \"\\n\"\n\t@argh.arg(\"--force\", help=\"force overwrite on conflict\")\n", "@argh.arg(\"-s\", \"--show\", help=\"only show, don't act\")\n\tdef stitch(*, force: bool = False, show: bool = False):\n\t    \"\"\"Stitch code changes back into the Markdown\"\"\"\n\t    input_file_list = list(chain.from_iterable(map(Path(\".\").glob, config.watch_list)))\n\t    if show:\n\t        mode = TransactionMode.SHOW\n\t    elif force:\n\t        mode = TransactionMode.FORCE\n\t    else:\n\t        mode = TransactionMode.FAIL\n", "    refs = ReferenceMap()\n\t    content: dict[Path, list[Content]] = {}\n\t    try:\n\t        for path in input_file_list:\n\t            logging.debug(\"reading `%s`\", path)\n\t            with open(path, \"r\") as f:\n\t                mr = MarkdownReader(str(path), refs)\n\t                mr.run(f.read())\n\t                content[path] = mr.content\n\t        with transaction(mode) as t:\n", "            for path in t.db.managed:\n\t                logging.debug(\"reading `%s`\", path)\n\t                t.update(path)\n\t                with open(path, \"r\") as f:\n\t                    CodeReader(str(path), refs).run(f.read())\n\t            for path in input_file_list:\n\t                t.write(path, stitch_markdown(refs, content[path]), [])\n\t    except UserError as e:\n\t        logging.error(str(e))\n"]}
{"filename": "entangled/commands/__init__.py", "chunked_list": ["from .tangle import tangle\n\tfrom .stitch import stitch\n\tfrom .sync import sync\n\tfrom .watch import watch\n\tfrom .status import status\n\t__all__ = [\"tangle\", \"stitch\", \"sync\", \"watch\", \"status\"]\n"]}
{"filename": "entangled/commands/watch.py", "chunked_list": ["from typing import Optional\n\tfrom pathlib import Path\n\tfrom itertools import chain\n\tfrom threading import Event\n\tfrom watchdog.observers import Observer\n\tfrom watchdog.events import FileSystemEventHandler, FileSystemEvent\n\tfrom .sync import sync\n\tfrom ..config import config\n\tfrom ..status import find_watch_dirs\n\tclass EventHandler(FileSystemEventHandler):\n", "    def __init__(self):\n\t        self.update_watched()\n\t    def update_watched(self):\n\t        self.watched = find_watch_dirs()\n\t    def on_any_event(self, event: FileSystemEvent):\n\t        if event.event_type == \"opened\":\n\t            return\n\t        config.read()\n\t        path = Path(event.src_path)\n\t        if path.is_relative_to(Path(\"./.entangled\")):\n", "            return\n\t        if any(path.is_relative_to(p) for p in self.watched):\n\t            sync()\n\t        self.update_watched()\n\tdef _watch(_stop_event: Optional[Event] = None):\n\t    \"\"\"Keep a loop running, watching for changes. This interface is separated\n\t    from the CLI one, so that it can be tested using threading instead of\n\t    subprocess.\"\"\"\n\t    def stop() -> bool:\n\t        return _stop_event is not None and _stop_event.is_set()\n", "    sync()\n\t    event_handler = EventHandler()\n\t    observer = Observer()\n\t    observer.schedule(event_handler, \".\", recursive=True)\n\t    observer.start()\n\t    try:\n\t        while observer.is_alive() and not stop():\n\t            observer.join(0.1)\n\t    finally:\n\t        observer.stop()\n", "        observer.join()\n\tdef watch():\n\t    \"\"\"Keep a loop running, watching for changes.\"\"\"\n\t    _watch()\n"]}
{"filename": "entangled/commands/init.py", "chunked_list": []}
{"filename": "entangled/commands/sync.py", "chunked_list": ["from typing import Optional, Callable\n\tfrom itertools import chain\n\tfrom pathlib import Path\n\timport logging\n\tfrom ..filedb import file_db\n\tfrom ..config import config\n\tfrom .stitch import stitch\n\tfrom .tangle import tangle\n\tdef _stitch_then_tangle():\n\t    stitch()\n", "    tangle()\n\tdef sync_action() -> Optional[Callable[[], None]]:\n\t    input_file_list = list(chain.from_iterable(map(Path(\".\").glob, config.watch_list)))\n\t    with file_db(readonly=True) as db:\n\t        changed = set(db.changed())\n\t        if not all(f in db for f in input_file_list):\n\t            return tangle\n\t        if not changed:\n\t            return None\n\t        if changed.isdisjoint(db.managed):\n", "            logging.info(\"Tangling\")\n\t            return tangle\n\t        if changed.issubset(db.managed):\n\t            logging.info(\"Stitching\")\n\t            return _stitch_then_tangle\n\t        logging.error(\"changed: %s\", [str(p) for p in changed])\n\t        logging.error(\n\t            \"Both markdown and code seem to have changed. \" \"Don't know what to do now.\"\n\t        )\n\t        return None\n", "def sync():\n\t    \"\"\"Be smart wether to tangle or stich\"\"\"\n\t    action = sync_action()\n\t    if action is not None:\n\t        action()\n"]}
{"filename": "entangled/config/version.py", "chunked_list": ["from __future__ import annotations\n\tfrom typing import ClassVar\n\tfrom dataclasses import dataclass\n\tfrom ..parsing import Parser, Parsable, fmap, fullmatch\n\t@dataclass\n\tclass Version(Parsable):\n\t    numbers: tuple[int, ...]\n\t    _pattern: ClassVar[Parser] = fullmatch(r\"[0-9]+(\\.[0-9]+)*\")\n\t    def __str__(self):\n\t        return \".\".join(str(i) for i in self.numbers)\n", "    @staticmethod\n\t    def from_string(s: str) -> Version:\n\t        return Version(tuple(int(sv) for sv in s.split(\".\")))\n\t    @staticmethod\n\t    def __parser__() -> Parser[Version]:\n\t        return Version._pattern >> fmap(Version.from_string)\n"]}
{"filename": "entangled/config/language.py", "chunked_list": ["from typing import Optional\n\tfrom dataclasses import dataclass\n\t@dataclass\n\tclass Comment:\n\t    \"\"\"Comment method for a language. For example: `Comment(\"/*\", \"*/\")` works\n\t    for C/C++ etc, `Comment(\"#\")` works for Python, and so on.\n\t    \"\"\"\n\t    open: str\n\t    close: Optional[str] = None\n\t@dataclass\n", "class Language:\n\t    \"\"\"Language information. Given a language we may have any number of short-hands\n\t    to indicate a code block is written in that language. If a language supports\n\t    line directives this can be used to redirect compiler messages directly to the\n\t    markdown files.\"\"\"\n\t    name: str\n\t    identifiers: list[str]\n\t    comment: Comment\n\t    line_directive: Optional[str] = None\n\tlanguages = [\n", "    Language(\"Shell\", [\"sh\", \"bash\", \"fish\", \"zsh\"], Comment(\"#\")),\n\t    Language(\"C\", [\"c\", \"cpp\", \"c++\"], Comment(\"/*\", \"*/\")),\n\t    Language(\"Python\", [\"python\"], Comment(\"#\")),\n\t    Language(\"Rust\", [\"rust\"], Comment(\"//\")),\n\t    Language(\"Haskell\", [\"haskell\"], Comment(\"--\")),\n\t    Language(\n\t        \"Lisp\", [\"scheme\", \"r5rs\", \"r6rs\", \"r7rs\", \"racket\", \"clojure\"], Comment(\";\")\n\t    ),\n\t    Language(\"Julia\", [\"julia\"], Comment(\"#\")),\n\t    Language(\"Java\", [\"java\"], Comment(\"//\")),\n", "    Language(\"PureScript\", [\"pure\", \"purs\", \"purescript\"], Comment(\"--\")),\n\t    Language(\"CSS\", [\"css\"], Comment(\"/*\", \"*/\")),\n\t    Language(\"Lua\", [\"lua\"], Comment(\"--\")),\n\t    Language(\"Make\", [\"make\", \"makefile\"], Comment(\"#\")),\n\t    Language(\"Gnuplot\", [\"gnuplot\"], Comment(\"#\")),\n\t    Language(\"TOML\", [\"toml\"], Comment(\"#\")),\n\t]\n"]}
{"filename": "entangled/config/__init__.py", "chunked_list": ["\"\"\"Configuration. The variable `config` should be automatically populated with\n\tdefaults and config loaded from `entangled.toml` in the work directory.\n\t\"\"\"\n\tfrom __future__ import annotations\n\tfrom typing import Optional, ClassVar, TypeVar\n\tfrom enum import Enum\n\tfrom dataclasses import dataclass, field\n\tfrom copy import copy\n\tfrom pathlib import Path\n\tfrom contextlib import contextmanager\n", "from ..construct import construct\n\tfrom .version import Version\n\tfrom .language import Language, languages\n\timport threading\n\timport tomllib\n\timport logging\n\tclass AnnotationMethod(Enum):\n\t    \"\"\"Annotation methods.\n\t    - `STANDARD` is the default. Comments tell where a piece of code\n\t       came from in enough detail to reconstruct the markdown if some\n", "       of the code is changed.\n\t    - `NAKED` adds no comments to the tangled files. Stitching is not\n\t       possible with this setting.\n\t    - `SUPPLEMENTED` adds extra information to the comment lines.\n\t    \"\"\"\n\t    STANDARD = 1\n\t    NAKED = 2\n\t    SUPPLEMENTED = 3\n\t@dataclass\n\tclass Markers:\n", "    \"\"\"Markers can be used to configure the Markdown dialect. Currently not used.\"\"\"\n\t    open: str\n\t    close: str\n\t    begin_ignore: str\n\t    end_ignore: str\n\tmarkers = Markers(\n\t    r\"^(?P<indent>\\s*)```\\s*{(?P<properties>[^{}]*)}\\s*$\",\n\t    r\"^(?P<indent>\\s*)```\\s*$\",\n\t    r\"^\\s*\\~\\~\\~markdown\\s*$\",\n\t    r\"^\\s*\\~\\~\\~\\s*$\",\n", ")\n\t@dataclass\n\tclass Config(threading.local):\n\t    \"\"\"Main config class. This class is made thread-local to make\n\t    it possible to test in parallel.\"\"\"\n\t    version: Version\n\t    languages: list[Language] = field(default_factory=list)\n\t    markers: Markers = field(default_factory=lambda: copy(markers))\n\t    watch_list: list[str] = field(default_factory=lambda: [\"**/*.md\"])\n\t    annotation_format: Optional[str] = None\n", "    annotation: AnnotationMethod = AnnotationMethod.STANDARD\n\t    use_line_directives: bool = False\n\t    hooks: list[str] = field(default_factory=list)\n\t    def __post_init__(self):\n\t        self.languages = languages + self.languages\n\t        self.make_language_index()\n\t    def make_language_index(self):\n\t        self.language_index = dict()\n\t        for l in self.languages:\n\t            for i in l.identifiers:\n", "                self.language_index[i] = l\n\tdefault = Config(Version.from_string(\"2.0\"))\n\tdef read_config_from_toml(path: Path, section: Optional[str] = None) -> Optional[Config]:\n\t    \"\"\"Read a config from given `path` in given `section`. The path should refer to\n\t    a TOML file that should decode to a `Config` object. If `section` is given, only\n\t    that section is decoded to a `Config` object. The `section` string may contain\n\t    periods to indicate deeper nesting.\n\t    Example:\n\t    ```python\n\t    read_config_from_toml(Path(\"./pyproject.toml\"), \"tool.entangled\")\n", "    ```\n\t    \"\"\"\n\t    if not path.exists():\n\t        return None\n\t    try:\n\t        with open(path, \"rb\") as f:\n\t            json = tomllib.load(f)\n\t            if section is not None:\n\t                for s in section.split(\".\"):\n\t                    json = json[s]\n", "            return construct(Config, json)\n\t    except ValueError as e:\n\t        logging.error(\"Could not read config: %s\", e)\n\t        return None\n\t    except KeyError as e:\n\t        logging.debug(\"%s\", e)\n\t        logging.debug(\"The config file %s should contain a section %s\", path, section)\n\t        return None\n\tdef read_config():\n\t    if Path(\"./entangled.toml\").exists():\n", "        return read_config_from_toml(Path(\"./entangled.toml\")) or default\n\t    if Path(\"./pyproject.toml\").exists():\n\t        return read_config_from_toml(Path(\"./pyproject.toml\"), \"tool.entangled\") or default\n\t    return default\n\tclass ConfigWrapper:\n\t    def __init__(self, config):\n\t        self.config = config\n\t    def read(self):\n\t        self.config = read_config()\n\t    def __getattr__(self, attr):\n", "        return getattr(self.config, attr)\n\t    @contextmanager\n\t    def __call__(self, **kwargs):\n\t        backup = {k: getattr(self.config, k) for k in kwargs}\n\t        for k, v in kwargs.items():\n\t            setattr(self.config, k, v)\n\t        yield\n\t        for k in kwargs.keys():\n\t            setattr(self.config, k, backup[k])\n\t    def get_language(self, lang_name: str) -> Optional[Language]:\n", "        return self.config.language_index.get(lang_name, None)\n\tconfig = ConfigWrapper(read_config())\n\t\"\"\"The `config.config` variable is changed when the `config` module is loaded.\n\tConfig is read from `entangled.toml` file.\"\"\"\n"]}
{"filename": "entangled/hooks/base.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom ..properties import Property\n\tfrom ..document import ReferenceMap, ReferenceId, CodeBlock\n\t@dataclass\n\tclass PrerequisitesFailed(Exception):\n\t    msg: str\n\t    def __str__(self):\n\t        return self.msg\n\tclass HookBase:\n\t    @staticmethod\n", "    def check_prerequisites():\n\t        \"\"\"When prerequisites aren't met, raise PrerequisitesFailed.\"\"\"\n\t        return\n\t    def condition(self, props: list[Property]):\n\t        raise NotImplementedError()\n\t    def on_read(self, refs: ReferenceId, code: CodeBlock):\n\t        raise NotImplementedError()\n\t    def post_tangle(self, refs: ReferenceMap):\n\t        pass\n"]}
{"filename": "entangled/hooks/__init__.py", "chunked_list": ["import logging\n\tfrom .base import HookBase\n\tfrom .build import BuildHook, PrerequisitesFailed\n\tfrom ..config import config\n\thooks: dict[str, type[HookBase]] = {\"build\": BuildHook}\n\tdef get_hooks() -> list[HookBase]:\n\t    active_hooks = []\n\t    for h in config.hooks:\n\t        if h in hooks:\n\t            try:\n", "                hooks[h].check_prerequisites()\n\t                active_hooks.append(hooks[h]())\n\t            except PrerequisitesFailed as e:\n\t                logging.error(\"hook `%s`: %s\", h, str(e))\n\t        else:\n\t            logging.error(\"no such hook available: `%s`\", h)\n\t    return active_hooks\n\t__all__ = [\"hooks\", \"PrerequisitesFailed\"]\n"]}
{"filename": "entangled/hooks/build.py", "chunked_list": ["\"\"\"\n\tThe `build` hook collects code blocks that are tagged with the `#build`\n\tidentifier and have a `target=` attribute defined.  These code blocks are put\n\ttogether into a temporary Makefile that is run from the current working\n\tdirectory.\n\t\"\"\"\n\tfrom tempfile import TemporaryDirectory\n\tfrom pathlib import Path\n\tfrom subprocess import run, SubprocessError, DEVNULL\n\timport logging\n", "import os\n\tfrom ..properties import Property, get_id, get_attribute\n\tfrom ..tangle import tangle_ref, Tangler\n\tfrom ..document import ReferenceMap, CodeBlock\n\tfrom .base import HookBase, PrerequisitesFailed\n\t\"\"\"\n\tThe Makefile is generated with `preamble` as a format string.  The\n\t`.RECIPEPREFIX` is set to `>` , and `target` attributes are collected into an\n\t`all` target.\n\t\"\"\"\n", "preamble = \"\"\"\n\t.RECIPEPREFIX = >\n\t.PHONY = all\n\tall: {targets}\n\t{rules}\n\t\"\"\"\n\tclass BuildHook(HookBase):\n\t    def __init__(self):\n\t        self.targets = []\n\t    @staticmethod\n", "    def check_prerequisites():\n\t        \"\"\"Check that `make` is installed.\"\"\"\n\t        try:\n\t            run([\"make\", \"--version\"], stdout=DEVNULL)\n\t        except (SubprocessError, FileNotFoundError):\n\t            raise PrerequisitesFailed(\"GNU Make needs to be installed\")\n\t    def condition(self, props: list[Property]):\n\t        \"\"\"Condition by which a CodeBlock is processed: should have `#build` id\n\t        and `target=` attribute.\"\"\"\n\t        return get_id(props) == \"build\" and get_attribute(props, \"target\") is not None\n", "    def on_read(self, _, code: CodeBlock):\n\t        \"\"\"Add a CodeBlock's target attribute to the list of targets.\"\"\"\n\t        target = get_attribute(code.properties, \"target\")\n\t        if target is None:\n\t            return\n\t        self.targets.append(target)\n\t    def post_tangle(self, refs: ReferenceMap):\n\t        \"\"\"After all code is tangled: retrieve the `#build` script and run it.\"\"\"\n\t        if \"CI\" in os.environ:\n\t            logging.info(\"CI run detected, skipping `build` hook.\")\n", "            return\n\t        try:\n\t            rules = tangle_ref(refs, \"build\", Tangler)[0]\n\t        except KeyError:\n\t            logging.warning(\"No targets specified, skipping `build` hook.\")\n\t            return\n\t        logging.info(\"Building artifacts with `make`.\")\n\t        with TemporaryDirectory() as _pwd:\n\t            pwd = Path(_pwd)\n\t            script = preamble.format(targets=\" \".join(self.targets), rules=rules)\n", "            (pwd / \"Makefile\").write_text(script)\n\t            run([\"make\", \"-f\", str(pwd / \"Makefile\")], stdout=DEVNULL)\n"]}
{"filename": "entangled/errors/internal.py", "chunked_list": ["from typing import Any\n\tfrom dataclasses import dataclass, field\n\tfrom textwrap import wrap\n\timport logging\n\t@dataclass\n\tclass InternalError(Exception):\n\t    msg: str\n\t    irritants: list[Any] = field(default_factory=list)\n\t    def __str__(self):\n\t        return f\"Internal error: {self.msg}\"\n", "def bug_contact():\n\t    logging.error(\n\t        \"This error is due to an internal bug in Entangled. Please file an \"\n\t        \"issue including the above stack trace \"\n\t        \"and example content to \"\n\t        \"reproduce the exception at https://github.com/entangled/entangled.py/.\"\n\t    )\n"]}
{"filename": "entangled/errors/__init__.py", "chunked_list": []}
{"filename": "entangled/errors/user.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom textwrap import wrap\n\tfrom ..document import TextLocation\n\tclass UserError(Exception):\n\t    def __str__(self):\n\t        return \"Unknown user error.\"\n\t@dataclass\n\tclass IndentationError(UserError):\n\t    location: TextLocation\n\t    def __str__(self):\n", "        return f\"indentation error at `{self.location}`\"\n\t@dataclass\n\tclass ParseError(UserError):\n\t    location: TextLocation\n\t    msg: str\n\t    def __str__(self):\n\t        return f\"parse error at {self.location}: {self.msg}\"\n\t@dataclass\n\tclass CyclicReference(UserError):\n\t    ref_name: str\n", "    cycle: list[str]\n\t    def __str__(self):\n\t        cycle_str = \" -> \".join(self.cycle)\n\t        return f\"Cyclic reference in <<{self.ref_name}>>: {cycle_str}\"\n\t@dataclass\n\tclass MissingReference(UserError):\n\t    ref_name: str\n\t    location: TextLocation\n\t    def __str__(self):\n\t        return f\"Missing reference `{self.ref_name}` at `{self.location}`\"\n"]}
