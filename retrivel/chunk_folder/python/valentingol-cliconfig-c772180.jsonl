{"filename": "setup.py", "chunked_list": ["\"\"\"Setup file for the package.\"\"\"\n\tfrom setuptools import setup\n\tsetup()\n"]}
{"filename": "github_actions_utils/color.py", "chunked_list": ["\"\"\"Color utils for GitHub actions.\"\"\"\n\tfrom colorsys import hsv_to_rgb\n\tdef score_to_hex_color(score: float, score_min: float, score_max: float) -> str:\n\t    \"\"\"Convert score to hex color red > bright green.\"\"\"\n\t    norm_score = max(0, (score - score_min) / (score_max - score_min))\n\t    hsv = (1 / 3 * norm_score, 1, 1)\n\t    rgb = hsv_to_rgb(*hsv)\n\t    rgb_tuple = tuple(int(255 * value) for value in rgb)\n\t    hex_color = f\"#{rgb_tuple[0]:02x}{rgb_tuple[1]:02x}{rgb_tuple[2]:02x}\"\n\t    return hex_color\n"]}
{"filename": "github_actions_utils/pylint_manager.py", "chunked_list": ["\"\"\"Manage Pylint output on workflow.\"\"\"\n\timport sys\n\tfrom github_actions_utils.color import score_to_hex_color\n\tdef check_output() -> float:\n\t    \"\"\"Check output of Pylint.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If Pylint score is below SCORE_MIN.\n\t    Returns\n", "    -------\n\t    score: float\n\t        Score of Pylint.\n\t    \"\"\"\n\t    args = sys.argv[1:]\n\t    score = -10000.0  # A default value\n\t    for arg in args:\n\t        if arg.startswith(\"--score=\"):\n\t            score = float(arg.split(\"=\")[1])\n\t    if score == -10000.0:\n", "        raise ValueError(\"Please specify the score of Pylint using the flag --score=N.\")\n\t    if score < PYLINT_SCORE_MIN:\n\t        raise ValueError(\n\t            f\"Pylint score {score} is lower than minimum ({PYLINT_SCORE_MIN})\"\n\t        )\n\t    return score\n\tdef main() -> None:\n\t    \"\"\"Check score and print it.\"\"\"\n\t    score = check_output()\n\t    # Print color to be used in GitHub Actions\n", "    print(score_to_hex_color(score, PYLINT_SCORE_MIN, PYLINT_SCORE_MAX))\n\tif __name__ == \"__main__\":\n\t    # PYLINT_SCORE_MIN can be changed safely depending on your needs.\n\t    PYLINT_SCORE_MIN = 8.5\n\t    PYLINT_SCORE_MAX = 10.0\n\t    main()\n"]}
{"filename": "github_actions_utils/__init__.py", "chunked_list": ["\"\"\"GitHub actions utilities.\"\"\"\n"]}
{"filename": "github_actions_utils/pydocstyle_manager.py", "chunked_list": ["\"\"\"Manage Pydocstyle output on workflow.\"\"\"\n\timport sys\n\tdef check_output() -> None:\n\t    \"\"\"Check output of Pydocstyle.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If Pydocstyle find errors.\n\t    \"\"\"\n\t    args = sys.argv[1:]\n", "    n_errors = -1  # A default value\n\t    for arg in args:\n\t        if arg.startswith(\"--n_errors=\"):\n\t            n_errors = int(arg.split(\"=\")[1])\n\t    if n_errors == -1:\n\t        raise ValueError(\n\t            \"Please specify the number of errors found by Pydocstyle \"\n\t            \"using the flag --n_errors=N.\"\n\t        )\n\t    if n_errors > 0:\n", "        raise ValueError(\n\t            f\"Pydocstyle found {n_errors} errors in python \"\n\t            \"docstrings. Please fix them.\",\n\t        )\n\tif __name__ == \"__main__\":\n\t    check_output()\n"]}
{"filename": "github_actions_utils/pytest_manager.py", "chunked_list": ["\"\"\"Manage Pytest-cov output on workflow.\"\"\"\n\timport sys\n\tfrom github_actions_utils.color import score_to_hex_color\n\tdef check_output() -> float:\n\t    \"\"\"Check output of Pytest-cov.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If Pytest find failures.\n\t    ValueError\n", "        If coverage is below SCORE_MIN.\n\t    Returns\n\t    -------\n\t    score: float\n\t        Score of coverage.\n\t    \"\"\"\n\t    args = sys.argv[1:]\n\t    n_failures, score = -1, -1.0  # Default values\n\t    for arg in args:\n\t        if arg.startswith(\"--score=\"):\n", "            score_percent = arg.split(\"=\")[1]\n\t            score = float(score_percent.split(\"%\")[0])\n\t        if arg.startswith(\"--n_failures=\"):\n\t            n_failures_str = arg.split(\"=\")[1]\n\t            n_failures = 0 if n_failures_str == \"\" else int(n_failures_str)\n\t    if n_failures == -1:\n\t        raise ValueError(\n\t            \"Please specify the number of failures found by Pytest \"\n\t            \"using the flag --n_failures=N.\",\n\t        )\n", "    if score == -1:\n\t        raise ValueError(\n\t            \"Please specify the score of coverage using the flag --score=N (in %).\",\n\t        )\n\t    if n_failures > 0:\n\t        raise ValueError(f\"Pytest finds {n_failures} failure(s) on tests.\")\n\t    if score < COV_SCORE_MIN:\n\t        raise ValueError(\n\t            f\"Pytest coverage {score}% is lower than minimum ({COV_SCORE_MIN}%)\",\n\t        )\n", "    return score\n\tdef main() -> None:\n\t    \"\"\"Check score and print it.\"\"\"\n\t    score = check_output()\n\t    # Print color to be used in GitHub Actions\n\t    print(score_to_hex_color(score, COV_SCORE_MIN, COV_SCORE_MAX))\n\tif __name__ == \"__main__\":\n\t    # COV_SCORE_MIN can be changed safely depending on your needs.\n\t    # NOTE: score on %\n\t    COV_SCORE_MIN = 0\n", "    COV_SCORE_MAX = 100\n\t    main()\n"]}
{"filename": "tests/__init__.py", "chunked_list": ["\"\"\"Tests for CLI Config.\"\"\"\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["\"\"\"Shared pytest fixtures.\"\"\"\n\tfrom typing import Any, Dict\n\timport pytest\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.processing.base import Processing\n\tfrom cliconfig.tag_routines import clean_all_tags, clean_tag, is_tag_in\n\tclass ProcessAdd1(Processing):\n\t    \"\"\"Add 1 to values with tag \"@add1\".\"\"\"\n\t    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\"\"\"\n", "        items = list(flat_config.dict.items())\n\t        for flat_key, value in items:\n\t            if is_tag_in(flat_key, \"add1\"):\n\t                flat_config.dict[clean_tag(flat_key, \"add1\")] = value + 1\n\t                del flat_config.dict[flat_key]\n\t        return flat_config\n\t    def endbuild(self, flat_config: Config) -> Config:\n\t        \"\"\"End-build processing.\"\"\"\n\t        flat_config.dict[\"processing name\"] = \"ProcessAdd1\"\n\t        return flat_config\n", "    def presave(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-save processing.\"\"\"\n\t        return self.premerge(flat_config)\n\tclass ProcessKeep(Processing):\n\t    \"\"\"Prevent a value from being changed after the merge.\"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.keep_vals: Dict[str, Any] = {}\n\t    # pylint: disable=unused-argument\n\t    def premerge(self, flat_config: Config) -> Config:\n", "        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, value in items:\n\t            if is_tag_in(flat_key, \"keep\"):\n\t                new_key = clean_tag(flat_key, \"keep\")\n\t                flat_config.dict[new_key] = value\n\t                del flat_config.dict[flat_key]\n\t                self.keep_vals[clean_all_tags(flat_key)] = value\n\t        return flat_config\n\t    # pylint: disable=unused-argument\n", "    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\"\"\"\n\t        for key, value in self.keep_vals.items():\n\t            if key in flat_config.dict:\n\t                flat_config.dict[key] = value\n\t        self.keep_vals = {}\n\t        return flat_config\n\t    # pylint: disable=unused-argument\n\t    def postload(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-load processing.\"\"\"\n", "        for key, value in self.keep_vals.items():\n\t            flat_config.dict[key] = value\n\t        self.keep_vals = {}\n\t        return flat_config\n\t@pytest.fixture()\n\tdef process_add1() -> ProcessAdd1:\n\t    \"\"\"Return a processing object that adds 1 on tag \"@add1\".\"\"\"\n\t    return ProcessAdd1()\n\t@pytest.fixture()\n\tdef process_keep() -> ProcessKeep:\n", "    \"\"\"Return a processing object that keep a value unchanged after the merge.\"\"\"\n\t    return ProcessKeep()\n"]}
{"filename": "tests/integration/test_ex_docs.py", "chunked_list": ["\"\"\"Test ProcessBypassTyping.\"\"\"\n\tfrom typing import Dict, Set\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig import Config\n\tfrom cliconfig.process_routines import merge_flat_processing\n\tfrom cliconfig.processing.base import Processing\n\tfrom cliconfig.processing.builtin import ProcessTyping\n\tfrom cliconfig.tag_routines import clean_all_tags, clean_tag, is_tag_in\n\tclass ProcessPrintSorted(Processing):\n", "    \"\"\"Print the parameters tagged with \"@look\", sorted by value on post-merge.\"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.looked_keys: Set[str] = set()\n\t        # Pre-merge just look for the tag so order is not important\n\t        self.premerge_order = 0.0\n\t        # Post-merge should be after the copy processing if we want the final values\n\t        # on post-merge\n\t        self.postmerge_order = 15.0\n\t    def premerge(self, flat_config: Config) -> Config:\n", "        \"\"\"Pre-merge processing.\"\"\"\n\t        # Browse a freeze version of the dict (because we will modify it to remove tags)\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, value in items:\n\t            if is_tag_in(flat_key, \"look\"):  # Check if the key contains the tag\n\t                # Remove the tag and update the dict\n\t                new_key = clean_tag(flat_key, \"look\")\n\t                flat_config.dict[new_key] = value\n\t                del flat_config.dict[flat_key]\n\t                # Store the key\n", "                # remove all tags = true parameter name\n\t                clean_key = clean_all_tags(flat_key)\n\t                self.looked_keys.add(clean_key)\n\t        return flat_config\n\t    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\"\"\"\n\t        values = []\n\t        for key in self.looked_keys:\n\t            # IMPORTANT\n\t            # (\"if key in flat_config.dict:\" is important in case of some keys were\n", "            # removed or if multiple dicts with different parameters are seen by\n\t            # the processing)\n\t            if key in flat_config.dict:\n\t                values.append(flat_config.dict[key])\n\t        print(\"The sorted looked values are: \", sorted(values))\n\t        # If we don't want to keep the looked keys for further print:\n\t        self.looked_keys = set()\n\t        return flat_config\n\tclass ProcessBypassTyping(Processing):\n\t    \"\"\"Bypass type check of ProcessTyping for parameters tagged with \"@bypass_typing\".\n", "    In pre-merge it looks for a parameter with the tag \"@bypass_typing\",\n\t    removes it and change the internal ProcessTyping variables to avoid\n\t    checking the type of the parameter with ProcessTyping.\n\t    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.bypassed_forced_types: Dict[str, tuple] = {}\n\t        # Before ProcessTyping pre-merge to let it change the type\n\t        self.premerge_order = -1.0\n\t    def premerge(self, flat_config: Config) -> Config:\n", "        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, value in items:\n\t            if is_tag_in(flat_key, \"bypass_typing\"):\n\t                new_key = clean_tag(flat_key, \"bypass_typing\")\n\t                flat_config.dict[new_key] = value\n\t                del flat_config.dict[flat_key]\n\t                clean_key = clean_all_tags(flat_key)\n\t                for processing in flat_config.process_list:\n\t                    if (\n", "                        isinstance(processing, ProcessTyping)\n\t                        and clean_key in processing.forced_types\n\t                    ):\n\t                        forced_type = processing.forced_types.pop(clean_key)\n\t                        self.bypassed_forced_types[clean_key] = forced_type\n\t        return flat_config\n\tdef test_process_print_sorted(capsys: pytest.CaptureFixture) -> None:\n\t    \"\"\"Test ProcessPrintSorted.\"\"\"\n\t    config1 = Config({\"a@look\": 0, \"b@look\": 2, \"c\": 3}, [ProcessPrintSorted()])\n\t    config2 = Config({\"a@look\": 1, \"d@look\": 4}, [])\n", "    capsys.readouterr()\n\t    merge_flat_processing(config1, config2)\n\t    out = capsys.readouterr().out\n\t    check.equal(out, \"The sorted looked values are:  [1, 2, 4]\\n\")\n\tdef test_process_bypass_typing() -> None:\n\t    \"\"\"Test ProcessBypassTyping.\"\"\"\n\t    config1 = Config({\"a@type:int\": 0}, [ProcessBypassTyping(), ProcessTyping()])\n\t    config2 = Config({\"a@bypass_typing@type:str\": \"a\"}, [])\n\t    merge_flat_processing(config1, config2)\n\t    config1 = Config({\"a@type:int\": 0}, [ProcessBypassTyping(), ProcessTyping()])\n", "    config2 = Config({\"a@type:str\": \"a\"}, [])\n\t    # Reset ProcessTyping\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=(\n\t            \"Find the tag '@type:str' on a key that has already \"\n\t            \"been associated to an other type: int.*\"\n\t        ),\n\t    ):\n\t        merge_flat_processing(config1, config2)\n"]}
{"filename": "tests/integration/test_inte_multiple_tags.py", "chunked_list": ["\"\"\"Integration test for multiple tags.\"\"\"\n\timport random\n\timport shutil\n\timport sys\n\tfrom copy import deepcopy\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig import (\n\t    Config,\n\t    create_processing_keep_property,\n", "    create_processing_value,\n\t    load_config,\n\t    make_config,\n\t    save_config,\n\t)\n\tfrom cliconfig.dict_routines import load_dict\n\tfrom cliconfig.process_routines import merge_flat_processing\n\tdef test_multiple_tags() -> None:\n\t    \"\"\"Integration test for multiple tags.\"\"\"\n\t    sys_argv = sys.argv.copy()\n", "    sys.argv = [\"test_inte_multiple_tags.py\"]\n\t    config = make_config(\"tests/configs/integration/test1/main.yaml\")\n\t    expected_config = {\n\t        \"path_1\": \"tests/configs/integration/test1/sub1.yaml\",\n\t        \"path_2\": \"tests/configs/integration/test1/sub2.yaml\",\n\t        \"config1\": {\n\t            \"param\": 2,\n\t            \"param2\": 1,\n\t        },\n\t        \"config2\": {\n", "            \"param\": 2,\n\t        },\n\t        \"config3\": {\n\t            \"select\": \"config3.param1\",\n\t            \"param1\": 0,\n\t        },\n\t    }\n\t    check.equal(config.dict, expected_config)\n\t    config = merge_flat_processing(\n\t        config,\n", "        Config({\"config2.param\": 5.6}, []),\n\t        preprocess_first=False,\n\t    )\n\t    with pytest.raises(\n\t        ValueError, match=\"Key previously tagged with '@type:None|int'.*\"\n\t    ):\n\t        config.process_list[3].endbuild(config)\n\t    sys.argv = sys_argv\n\tdef test_multiple_tags2() -> None:\n\t    \"\"\"2nd integration test for multiple tags.\"\"\"\n", "    sys_argv = sys.argv.copy()\n\t    sys.argv = [\n\t        \"test_inte_multiple_tags2.py\",\n\t        \"--config\",\n\t        \"[tests/configs/integration/test2/exp1.yaml, \"\n\t        \"tests/configs/integration/test2/exp2.yaml]\",\n\t        \"--train.n_epochs=20\",\n\t        \"--train.optimizer.momentum=0\",\n\t        \"--train.optimizer.type=Adam\",\n\t    ]\n", "    def func_pos_enc_type(x: str) -> str:\n\t        if x in [\"absolute\", \"relative\", \"embed\"]:\n\t            return x\n\t        raise ValueError(f\"Invalid value for pos_enc_type: {x}\")\n\t    def func_optim_type(x: str) -> str:\n\t        if x in [\"SGD\", \"Adam\"]:\n\t            return x\n\t        raise ValueError(f\"Invalid value for optim_type: {x}\")\n\t    proc_pos_enc_type = create_processing_value(\n\t        func_pos_enc_type,\n", "        tag_name=\"pos_enc\",\n\t        order=20,\n\t        persistent=True,\n\t    )\n\t    proc_optim_type = create_processing_value(\n\t        func_optim_type,\n\t        tag_name=\"optim_type\",\n\t        order=20,\n\t        persistent=True,\n\t    )\n", "    proc_protect = create_processing_keep_property(\n\t        func=lambda x: x,\n\t        tag_name=\"protect\",\n\t        premerge_order=-15,\n\t        postmerge_order=15,\n\t    )\n\t    proc_run_id = create_processing_value(\n\t        lambda run_id: run_id if run_id is not None else random.randint(0, 1000000),\n\t        regex=\"run_id.*\",\n\t    )\n", "    config = make_config(\n\t        \"tests/configs/integration/test2/default.yaml\",\n\t        process_list=[proc_pos_enc_type, proc_optim_type, proc_protect, proc_run_id],\n\t        add_default_processing=True,\n\t    )\n\t    expected_dict = {\n\t        \"project_name\": \"ImageClassif\",\n\t        \"models\": {\n\t            \"archi_name\": \"models.vit_b16\",\n\t            \"vit_b16\": {\n", "                \"pos_enc_type\": \"absolute\",\n\t                \"attn_dropout\": 0.2,\n\t                \"dropout\": 0.1,\n\t                \"in_size\": 512,\n\t                \"n_blocks\": 12,\n\t            },\n\t        },\n\t        \"data\": {\n\t            \"data_size\": 512,\n\t            \"dataset_path\": \"../../mydata\",\n", "            \"standardization\": True,\n\t            \"augmentation\": [\"RandomHorizontalFlip\", \"RandomVerticalFlip\"],\n\t            \"dataset_cfg_path\": \"tests/configs/integration/test2/data.yaml\",\n\t        },\n\t        \"train\": {\n\t            \"n_epochs\": 20,\n\t            \"optimizer\": {\n\t                \"type\": \"Adam\",\n\t                \"lr\": 0.001,\n\t                \"momentum\": 0,\n", "            },\n\t        },\n\t        \"metadata\": {\n\t            \"exp_details\": {\n\t                \"goal\": \"Test multiple processings\",\n\t                \"config_folder\": \"tests/configs/integration/test2\",\n\t            }\n\t        },\n\t    }\n\t    check.is_instance(config.dict[\"run_id\"], int)\n", "    config_dict = deepcopy(config.dict)\n\t    del config_dict[\"run_id\"]\n\t    check.equal(config_dict, expected_dict)\n\t    save_config(config, \"tests/tmp/config.yaml\")\n\t    saved_dict = load_dict(\"tests/tmp/config.yaml\")\n\t    check.equal(\n\t        saved_dict[\"data\"][\"augmentation@type:List[str]\"],\n\t        [\"RandomHorizontalFlip\", \"RandomVerticalFlip\"],\n\t    )\n\t    check.equal(\n", "        saved_dict[\"models\"][\"archi_name@type:None|str@select\"], \"models.vit_b16\"\n\t    )\n\t    check.equal(\n\t        saved_dict[\"models\"][\"vit_b16\"][\"in_size@copy@type:int\"], \"data.data_size\"\n\t    )\n\t    config = load_config(\n\t        \"tests/tmp/config.yaml\",\n\t        [\"tests/configs/integration/test2/default.yaml\"],\n\t        config.process_list,\n\t    )\n", "    del config.dict[\"run_id\"]\n\t    check.equal(config.dict, expected_dict)\n\t    with pytest.raises(ValueError, match=\"Key previously tagged with '@type:int.*\"):\n\t        config.process_list[7].endbuild(\n\t            Config({\"models.vit_b16.n_blocks\": 5.6}, config.process_list)\n\t        )\n\t    with pytest.raises(\n\t        ValueError, match=\"Found attempt to modify a key with '@copy' tag.*\"\n\t    ):\n\t        merge_flat_processing(config, Config({\"models.vit_b16.in_size\": 224}, []))\n", "    shutil.rmtree(\"tests/tmp\")\n\t    sys.argv = sys_argv\n"]}
{"filename": "tests/unit/test_cli_parser.py", "chunked_list": ["\"\"\"Test for cli_parser.py.\"\"\"\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig.cli_parser import parse_cli\n\tdef test_parse_cli() -> None:\n\t    \"\"\"Test for parse_cli.\"\"\"\n\t    config_paths, config_cli_params = parse_cli(\n\t        [\"main.py\", \"--config\", \"config1.yaml,config2.yaml\", \"--a=1\", \"--b=2\"]\n\t    )\n\t    check.equal(config_paths, [\"config1.yaml\", \"config2.yaml\"])\n", "    config_paths, config_cli_params = parse_cli(\n\t        [\"main.py\", \"--config\", \"[config1.yaml, config2.yaml]\", \"--a=1\", \"--b=2\"]\n\t    )\n\t    check.equal(config_paths, [\"config1.yaml\", \"config2.yaml\"])\n\t    check.equal(config_cli_params, {\"a\": 1, \"b\": 2})\n\t    b_str = \"{'2': {'3': 4, '5': [6.3], '7': True, '8': Null, '9': [2, {'a': 1}]}}\"\n\t    config_paths, config_cli_params = parse_cli(\n\t        [\"main.py\", \"--a='b=c'\", f\"--b={b_str}\"]\n\t    )\n\t    val = {\n", "        \"a\": \"b=c\",\n\t        \"b\": {\"2\": {\"3\": 4, \"5\": [6.3], \"7\": True, \"8\": None, \"9\": [2, {\"a\": 1}]}},\n\t    }\n\t    check.equal(config_paths, [])\n\t    check.equal(config_cli_params, val)\n\t    config_paths, config_cli_params = parse_cli(\n\t        [\"main.py\", \"--unknown\", \"--a=1\", \"--unknwon2=2\", \"--b=3\"]\n\t    )\n\t    val2 = {\"unknown\": True, \"a\": 1, \"unknwon2\": 2, \"b\": 3}\n\t    check.equal(config_paths, [])\n", "    check.equal(config_cli_params, val2)\n\t    with pytest.raises(ValueError, match=\"Only one '--config ' argument is allowed.*\"):\n\t        parse_cli([\"main.py\", \"--config\", \"config1.yaml\", \"--config\", \"config2.yaml\"])\n"]}
{"filename": "tests/unit/test_process_routines.py", "chunked_list": ["\"\"\"Tests for dict routines with preprocessing.\"\"\"\n\timport re\n\timport shutil\n\timport pytest\n\timport pytest_check as check\n\timport yaml\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.process_routines import (\n\t    end_build_processing,\n\t    load_processing,\n", "    merge_flat_paths_processing,\n\t    merge_flat_processing,\n\t    save_processing,\n\t)\n\tfrom cliconfig.processing.base import Processing\n\tfrom tests.conftest import ProcessAdd1, ProcessKeep\n\tdef test_merge_flat_processing(\n\t    process_add1: ProcessAdd1,\n\t    process_keep: ProcessKeep,\n\t) -> None:\n", "    \"\"\"Test merge_flat_processing.\"\"\"\n\t    class _ProcessingTest(Processing):\n\t        def __init__(self) -> None:\n\t            super().__init__()\n\t            self.attr = 0\n\t    proc1 = _ProcessingTest()\n\t    proc2 = _ProcessingTest()\n\t    proc2.attr = 1\n\t    proc3 = _ProcessingTest()\n\t    config1 = Config({\"a\": {\"b\": 1, \"c\": 2, \"d@keep\": 3}}, [proc1, proc2, process_add1])\n", "    config2 = Config({\"a\": {\"b\": 2, \"c@add1\": 3, \"d\": 4}}, [proc3, process_keep])\n\t    config = merge_flat_processing(\n\t        config1,\n\t        config2,\n\t        allow_new_keys=False,\n\t    )\n\t    check.equal(\n\t        config.dict,\n\t        {\"a.b\": 2, \"a.c\": 4, \"a.d\": 3},\n\t    )\n", "    check.equal(config.process_list, [proc1, proc2, process_add1, process_keep])\n\t    check.equal(process_keep.keep_vals, {})\n\tdef test_merge_flat_paths_processing(\n\t    process_add1: ProcessAdd1,\n\t    process_keep: ProcessKeep,\n\t) -> None:\n\t    \"\"\"Test merge_flat_paths_processing.\"\"\"\n\t    config1 = Config(\n\t        {\"param1@add1\": 0, \"param2.param3@keep\": 1}, [process_add1, process_keep]\n\t    )\n", "    config2 = Config({\"param2.param3\": 3}, [])\n\t    expected_dict = {\"param1\": 1, \"param2.param3\": 1}\n\t    check.equal(\n\t        merge_flat_paths_processing(\n\t            \"tests/configs/configtag1.yaml\",\n\t            \"tests/configs/configtag2.yaml\",\n\t            allow_new_keys=False,\n\t            additional_process=[process_add1, process_keep],\n\t        ),\n\t        Config(expected_dict, [process_add1, process_keep]),\n", "    )\n\t    check.equal(\n\t        merge_flat_paths_processing(\n\t            config1,\n\t            config2,\n\t            allow_new_keys=False,\n\t        ),\n\t        Config(expected_dict, [process_add1, process_keep]),\n\t    )\n\t    check.equal(process_keep.keep_vals, {})\n", "    # Case with dict in input\n\tdef test_save_processing(\n\t    process_add1: ProcessAdd1,\n\t    process_keep: ProcessKeep,\n\t) -> None:\n\t    \"\"\"Test save_processing.\"\"\"\n\t    config = Config(\n\t        {\"param1@add1\": 0, \"param2.param3@add1\": 1}, [process_add1, process_keep]\n\t    )\n\t    save_processing(config, \"tests/tmp/config.yaml\")\n", "    with open(\"tests/tmp/config.yaml\", \"r\", encoding=\"utf-8\") as yaml_file:\n\t        loaded_dict = yaml.safe_load(yaml_file)\n\t    check.equal(loaded_dict, {\"param1\": 1, \"param2\": {\"param3\": 2}})\n\t    check.equal(process_keep.keep_vals, {})\n\t    shutil.rmtree(\"tests/tmp\")\n\tdef test_load_processing(\n\t    process_add1: ProcessAdd1,\n\t    process_keep: ProcessKeep,\n\t) -> None:\n\t    \"\"\"Test load_processing.\"\"\"\n", "    process_keep.keep_vals = {\"param2.param3\": 0}\n\t    config = load_processing(\n\t        \"tests/configs/configtag2.yaml\",\n\t        [process_add1, process_keep],\n\t    )\n\t    check.equal(config.dict, {\"param2.param3\": 0})\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"config_or_path must be a Config instance or a path to a yaml file \"\n", "            \"but you passed a dict. If you want to use it as a valid input, \"\n\t            \"you should use Config(<input dict>, []) instead.\"\n\t        ),\n\t    ):\n\t        merge_flat_paths_processing(\n\t            {\"a\": 2},  # type: ignore\n\t            Config({\"a\": 1}, []),\n\t        )\n\t    with pytest.raises(\n\t        ValueError,\n", "        match=(\"config_or_path must be a Config instance or a path to a yaml file.\"),\n\t    ):\n\t        merge_flat_paths_processing(\n\t            Config({\"a\": 1}, []),\n\t            (\"not a path\",),  # type: ignore\n\t        )\n\tdef test_end_build_processing(process_add1: ProcessAdd1) -> None:\n\t    \"\"\"Test end_build_processing.\"\"\"\n\t    config = Config({\"param1@add1\": 0}, [process_add1])\n\t    config = end_build_processing(config)\n", "    check.equal(config.dict, {\"param1@add1\": 0, \"processing name\": \"ProcessAdd1\"})\n"]}
{"filename": "tests/unit/test_config_routines.py", "chunked_list": ["\"\"\"Tests for config.py.\"\"\"\n\timport os\n\timport shutil\n\timport sys\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.config_routines import load_config, make_config, save_config, show_config\n\tfrom cliconfig.processing.base import Processing\n\tdef test_make_config(capsys: pytest.CaptureFixture, process_add1: Processing) -> None:\n", "    \"\"\"Test make_config.\"\"\"\n\t    sys_argv = sys.argv.copy()\n\t    sys.argv = [\n\t        \"tests/test_make_config.py.py\",\n\t        \"--config\",\n\t        \"tests/configs/config1.yaml,tests/configs/config2.yaml\",\n\t        \"--unknown\",\n\t        \"--param2@add1=6\",\n\t        \"--unknown2=8\",  # check that not error but a warning in console\n\t    ]\n", "    capsys.readouterr()  # Clear stdout and stderr\n\t    config = make_config(\n\t        \"tests/configs/default1.yaml\",\n\t        \"tests/configs/default2.yaml\",\n\t        process_list=[process_add1],\n\t        fallback=\"tests/configs/fallback.yaml\",\n\t    )\n\t    captured = capsys.readouterr()\n\t    out = captured.out\n\t    expected_config = {\n", "        \"param1\": 4,\n\t        \"param2\": 7,\n\t        \"param3\": 3,\n\t        \"letters\": {\n\t            \"letter1\": \"f\",\n\t            \"letter2\": \"e\",\n\t            \"letter3\": \"c\",\n\t            \"letter4\": \"d\",\n\t        },\n\t        \"processing name\": \"ProcessAdd1\",\n", "    }\n\t    expected_out = (\n\t        \"[CONFIG] Warning: New keys found in CLI parameters that will not be merged:\\n\"\n\t        \"  - unknown\\n\"\n\t        \"  - unknown2\\n\"\n\t        \"[CONFIG] Info: Merged 2 default config(s), \"\n\t        \"2 additional config(s) and 1 CLI parameter(s).\\n\"\n\t    )\n\t    check.equal(config.dict, expected_config)\n\t    check.equal(out, expected_out)\n", "    # No additional configs and fallback\n\t    sys.argv = [\n\t        \"tests/test_make_config.py.py\",\n\t    ]\n\t    config = make_config(\n\t        \"tests/configs/default1.yaml\",\n\t        \"tests/configs/default2.yaml\",\n\t        fallback=\"tests/configs/fallback.yaml\",\n\t    )\n\t    expected_config = {\n", "        \"param1\": 1,\n\t        \"param2\": -1,\n\t        \"param3\": 3,\n\t        \"letters\": {\n\t            \"letter1\": \"z\",\n\t            \"letter2\": \"b\",\n\t            \"letter3\": \"c\",\n\t            \"letter4\": \"d\",\n\t        },\n\t    }\n", "    check.equal(config.dict, expected_config)\n\t    config = make_config(add_default_processing=False)\n\t    check.equal(config.dict, {})\n\t    check.equal(config.process_list, [])\n\t    # No CLI\n\t    sys.argv = [\n\t        \"tests/test_make_config.py.py\",\n\t        \"--config\",\n\t        \"tests/configs/config1.yaml\",\n\t        \"--param2=6\",\n", "    ]\n\t    config = make_config(\n\t        \"tests/configs/default1.yaml\",\n\t        \"tests/configs/default2.yaml\",\n\t        fallback=\"tests/configs/fallback.yaml\",\n\t        no_cli=True,\n\t    )\n\t    expected_config = {\n\t        \"param1\": 1,\n\t        \"param2\": 2,\n", "        \"param3\": 3,\n\t        \"letters\": {\n\t            \"letter1\": \"a\",\n\t            \"letter2\": \"b\",\n\t            \"letter3\": \"c\",\n\t            \"letter4\": \"d\",\n\t        },\n\t    }\n\t    sys.argv = sys_argv.copy()\n\tdef test_load_config(process_add1: Processing) -> None:\n", "    \"\"\"Test and load_config.\"\"\"\n\t    # With default configs\n\t    config = load_config(\n\t        \"tests/configs/config2.yaml\",\n\t        default_config_paths=[\n\t            \"tests/configs/default1.yaml\",\n\t            \"tests/configs/default2.yaml\",\n\t        ],\n\t        process_list=[process_add1],\n\t    )\n", "    expected_config = {\n\t        \"param1\": 4,\n\t        \"param2\": 2,\n\t        \"param3\": 3,\n\t        \"letters\": {\n\t            \"letter1\": \"a\",\n\t            \"letter2\": \"e\",\n\t            \"letter3\": \"c\",\n\t            \"letter4\": \"d\",\n\t        },\n", "        \"processing name\": \"ProcessAdd1\",\n\t    }\n\t    check.equal(config.dict, expected_config)\n\t    # Additional keys when allow_new_keys=False\n\t    with pytest.raises(ValueError, match=\"New parameter found 'param3'.*\"):\n\t        load_config(\n\t            \"tests/configs/default2.yaml\",\n\t            default_config_paths=[\n\t                \"tests/configs/default1.yaml\",\n\t            ],\n", "        )\n\tdef test_show_config() -> None:\n\t    \"\"\"Test show_config.\"\"\"\n\t    show_config(Config({\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}, \"e\": \"f\"}, []))\n\tdef test_save_config() -> None:\n\t    \"\"\"Test save_config.\"\"\"\n\t    config = Config({\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}, \"e\": \"f\"}, [])\n\t    save_config(config, \"tests/tmp/config.yaml\")\n\t    check.is_true(os.path.exists(\"tests/tmp/config.yaml\"))\n\t    shutil.rmtree(\"tests/tmp\")\n"]}
{"filename": "tests/unit/test_tag_routines.py", "chunked_list": ["\"\"\"Test the tag routines.\"\"\"\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig.tag_routines import clean_all_tags, clean_tag, dict_clean_tags, is_tag_in\n\t@pytest.fixture()\n\tdef key1() -> str:\n\t    \"\"\"Return a key with many tags.\"\"\"\n\t    return \"abc@tag.def@tag_2.ghi@tag\"\n\t@pytest.fixture()\n\tdef key2() -> str:\n", "    \"\"\"Return a key with many many tags.\"\"\"\n\t    return \"abc@hashtag@tagg@tag@tag 2@tag@ag.def@tag _.jkl@tag.mno@tag\"\n\tdef test_clean_tag(key1: str, key2: str) -> None:\n\t    \"\"\"Test clean_tag.\"\"\"\n\t    check.equal(\n\t        clean_tag(key1, \"tag\"),\n\t        \"abc.def@tag_2.ghi\",\n\t    )\n\t    check.equal(\n\t        clean_tag(key1, \"@tag\"),\n", "        \"abc.def@tag_2.ghi\",\n\t    )\n\t    check.equal(clean_tag(key2, \"tag\"), \"abc@hashtag@tagg@tag 2@ag.def@tag _.jkl.mno\")\n\t    check.equal(clean_tag(key2, \"@tag\"), \"abc@hashtag@tagg@tag 2@ag.def@tag _.jkl.mno\")\n\tdef test_clean_all_tags(key1: str, key2: str) -> None:\n\t    \"\"\"Test clean_all_tags.\"\"\"\n\t    check.equal(\n\t        clean_all_tags(key1),\n\t        \"abc.def.ghi\",\n\t    )\n", "    check.equal(\n\t        clean_all_tags(key2),\n\t        \"abc.def.jkl.mno\",\n\t    )\n\tdef test_dict_clean_tags(key1: str, key2: str) -> None:\n\t    \"\"\"Test dict_clean_tag.\"\"\"\n\t    in_dict = {\n\t        \"abc.def.pqr\": 0,\n\t        key1: 1,\n\t        key2: 2,\n", "    }\n\t    out_dict, tagged_keys = dict_clean_tags(in_dict)\n\t    check.equal(out_dict, {\"abc.def.pqr\": 0, \"abc.def.ghi\": 1, \"abc.def.jkl.mno\": 2})\n\t    check.is_true(key1 in tagged_keys)\n\t    check.is_true(key1 in tagged_keys)\n\tdef test_is_tag_in() -> None:\n\t    \"\"\"Test is_tag_in.\"\"\"\n\t    check.is_true(is_tag_in(\"config.config2.config3@tag\", \"tag\"))\n\t    check.is_false(is_tag_in(\"config.config2.config3@tag\", \"tog\"))\n\t    check.is_false(is_tag_in(\"config.config2.config3@tag_2\", \"tag\"))\n", "    check.is_false(is_tag_in(\"config.config2.config3@tag_2@tog\", \"tag\"))\n\t    check.is_true(is_tag_in(\"config.config2.config3@tag@tog\", \"@tag\"))\n\t    check.is_true(is_tag_in(\"config.config2.config3@tag@tog\", \"@tog\"))\n\t    check.is_true(is_tag_in(\"config.config2@tag.config3@tog\", \"tag\", full_key=True))\n\t    check.is_false(is_tag_in(\"config.config2@tag.config3@tog\", \"tag\", full_key=False))\n"]}
{"filename": "tests/unit/test_base_config.py", "chunked_list": ["\"\"\"Test base class of configuration.\"\"\"\n\timport pytest_check as check\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.dict_routines import unflatten\n\tfrom cliconfig.processing.base import Processing\n\tdef test_config(process_add1: Processing) -> None:\n\t    \"\"\"Test base class of configuration.\"\"\"\n\t    config_dict = {\"a.b\": 1, \"b\": 2, \"c.d.e\": 3, \"c.d.f\": [2, 3]}\n\t    config_dict = unflatten(config_dict)\n\t    config = Config(config_dict, [process_add1])\n", "    check.equal(config.dict, config_dict)\n\t    check.equal(config.process_list, [process_add1])\n\t    check.equal(repr(config), f\"Config({config_dict}, ['ProcessAdd1'])\")\n\t    config_dict2 = {\"c.d.e\": 3, \"a.b\": 1, \"b\": 2, \"c.d.f\": [2, 3]}\n\t    config_dict2 = unflatten(config_dict2)\n\t    config2 = Config(config_dict2, [process_add1])\n\t    check.equal(config, config2)\n\t    config3 = Config(config_dict2, [process_add1, process_add1])\n\t    check.not_equal(config, config3)\n\t    config4 = Config(config_dict2, [])\n", "    check.not_equal(config, config4)\n\t    # Test get/set attribute\n\t    config = Config(config_dict, [process_add1])\n\t    check.equal(config.a.b, 1)\n\t    check.equal(config.c.d.f, [2, 3])\n\t    check.equal(config.c.d, Config({\"e\": 3, \"f\": [2, 3]}, [process_add1]))\n\t    config.a.b = 2\n\t    check.equal(config.a.b, 2)\n\t    config.c.d.f = [3, 4]\n\t    check.equal(config.c.d.f, [3, 4])\n", "    config.c.d.f.append(5)\n\t    check.equal(config.c.d.f, [3, 4, 5])\n\t    # Test delete attribute\n\t    del config.a.b\n\t    check.equal(config.dict, {\"a\": {}, \"b\": 2, \"c\": {\"d\": {\"e\": 3, \"f\": [3, 4, 5]}}})\n\t    del config.c.d\n\t    check.equal(config.dict, {\"a\": {}, \"b\": 2, \"c\": {}})\n\t    # Should no raise error\n\t    del config.dict\n\t    del config.process_list\n"]}
{"filename": "tests/unit/test_dict_routines.py", "chunked_list": ["\"\"\"Tests for dict routines.\"\"\"\n\timport os\n\timport shutil\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig.dict_routines import (\n\t    _del_key,\n\t    clean_pre_flat,\n\t    flatten,\n\t    load_dict,\n", "    merge_flat,\n\t    merge_flat_paths,\n\t    save_dict,\n\t    show_dict,\n\t    unflatten,\n\t)\n\tdef test_flatten() -> None:\n\t    \"\"\"Test flatten(.\"\"\"\n\t    check.equal(\n\t        flatten({\"a.b\": 1, \"a\": {\"c\": 2}, \"d\": 3}),\n", "        {\"a.b\": 1, \"a.c\": 2, \"d\": 3},\n\t    )\n\t    check.equal(\n\t        flatten({\"a.b\": {\"c\": 1}, \"a\": {\"b.d\": 2}, \"a.e\": {\"f.g\": 3}}),\n\t        {\"a.b.c\": 1, \"a.b.d\": 2, \"a.e.f.g\": 3},\n\t    )\n\t    check.equal(\n\t        flatten({\"a.b\": 1, \"a\": {\"c\": {}}, \"a.c\": 3}),\n\t        {\"a.b\": 1, \"a.c\": 3},\n\t    )\n", "    with pytest.raises(ValueError, match=\"duplicated key 'a.b'\"):\n\t        flatten({\"a.b\": 1, \"a\": {\"b\": 1}})\n\tdef test_unflatten() -> None:\n\t    \"\"\"Test unflatten.\"\"\"\n\t    check.equal(\n\t        unflatten({\"a.b\": 1, \"a.c\": 2, \"c\": 3}),\n\t        {\"a\": {\"b\": 1, \"c\": 2}, \"c\": 3},\n\t    )\n\t    with pytest.raises(ValueError, match=\"The dict must be flatten.*\"):\n\t        unflatten({\"a.b\": 1, \"a\": {\"c\": 2}})\n", "def test_merge_flat() -> None:\n\t    \"\"\"Test merge_flat.\"\"\"\n\t    dict1 = {\"a.b\": 1, \"a\": {\"c\": 2}}\n\t    dict2 = {\"c\": 3}\n\t    check.equal(\n\t        merge_flat(dict1, dict2, allow_new_keys=True),\n\t        {\"a.b\": 1, \"a.c\": 2, \"c\": 3},\n\t    )\n\t    with pytest.raises(ValueError, match=\"New parameter found 'c'.*\"):\n\t        merge_flat(dict1, dict2, allow_new_keys=False)\n", "    dict1 = {\"a.b\": 1, \"a\": {\"b\": 1, \"c\": 2}}\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=\"Duplicated key found.*You may consider calling 'clean_pre_flat'.*\",\n\t    ):\n\t        merge_flat(dict1, dict2, allow_new_keys=True)\n\tdef test_merge_flat_paths() -> None:\n\t    \"\"\"Test merge_flat_paths.\"\"\"\n\t    dict1 = {\n\t        \"param1\": 1,\n", "        \"param2\": 2,\n\t        \"letters\": {\n\t            \"letter1\": \"a\",\n\t            \"letter2\": \"b\",\n\t        },\n\t    }\n\t    dict2 = {\n\t        \"param3\": 3,\n\t        \"letters\": {\n\t            \"letter3\": \"c\",\n", "            \"letter4\": \"d\",\n\t        },\n\t    }\n\t    expected_dict = {\n\t        \"param1\": 1,\n\t        \"param2\": 2,\n\t        \"param3\": 3,\n\t        \"letters.letter1\": \"a\",\n\t        \"letters.letter2\": \"b\",\n\t        \"letters.letter3\": \"c\",\n", "        \"letters.letter4\": \"d\",\n\t    }\n\t    flat_dict = merge_flat_paths(\n\t        \"tests/configs/default1.yaml\",\n\t        \"tests/configs/default2.yaml\",\n\t        allow_new_keys=True,\n\t    )\n\t    check.equal(flat_dict, expected_dict)\n\t    flat_dict = merge_flat_paths(dict1, dict2, allow_new_keys=True)\n\t    check.equal(flat_dict, expected_dict)\n", "    flat_dict = merge_flat_paths(\n\t        dict1, \"tests/configs/default2.yaml\", allow_new_keys=True\n\t    )\n\t    check.equal(flat_dict, expected_dict)\n\t    with pytest.raises(ValueError, match=\"New parameter found 'param3'.*\"):\n\t        merge_flat_paths(\n\t            \"tests/configs/default1.yaml\",\n\t            \"tests/configs/default2.yaml\",\n\t            allow_new_keys=False,\n\t        )\n", "def test_del_key() -> None:\n\t    \"\"\"Test _del_key.\"\"\"\n\t    in_dict = {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}\n\t    _del_key(in_dict, \"a.b.c\")\n\t    check.equal(in_dict, {\"a\": {\"d\": 2}, \"a.e\": 3})\n\t    in_dict = {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}\n\t    _del_key(in_dict, \"a.b.c\", keep_flat=True)\n\t    check.equal(in_dict, {\"a\": {\"d\": 2}, \"a.e\": 3, \"a.b.c\": 4})\n\t    in_dict = {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}\n\t    _del_key(in_dict, \"a.b.c\", keep_unflat=True)\n", "    check.equal(in_dict, {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3})\n\t    with pytest.raises(ValueError, match=\"Key 'a.b.z' not found in dict.\"):\n\t        _del_key({\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}, \"a.b.z\")\n\t    with pytest.raises(ValueError, match=\"Key 'a.z.c' not found in dict.\"):\n\t        _del_key({\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}, \"a.z.c\")\n\tdef test_clean_pre_flat() -> None:\n\t    \"\"\"Test clean_pre_flat.\"\"\"\n\t    check.equal(\n\t        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"flat\"),\n\t        {\"a.b\": 1, \"c\": 3},\n", "    )\n\t    check.equal(\n\t        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"unflat\"),\n\t        {\"a\": {\"b\": 2}, \"c\": 3},\n\t    )\n\t    with pytest.raises(ValueError, match=\"duplicated key 'a.b'\"):\n\t        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"error\")\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=(\n", "            \"priority argument must be one of 'flat', 'unflat' or 'error' but \"\n\t            \"found 'UNKNOWN'\"\n\t        ),\n\t    ):\n\t        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"UNKNOWN\")\n\tdef test_save_load_dict() -> None:\n\t    \"\"\"Test save_dict and load_dict.\"\"\"\n\t    dict1 = {\"a\": 1, \"b\": {\"c\": 2}, \"d\": [2, 3.0], \"e\": [{\"f\": 4}]}\n\t    save_dict(dict1, \"tests/tmp/config.yaml\")\n\t    check.is_true(os.path.isfile(\"tests/tmp/config.yaml\"))\n", "    dict2 = load_dict(\"tests/tmp/config.yaml\")\n\t    check.equal(dict1, dict2)\n\t    # Case multiple files and yaml tags\n\t    out_dict = load_dict(\"tests/configs/multi_files_with_tags.yaml\")\n\t    expected_dict = {\n\t        \"config@cfg\": {\n\t            \"param1@par@other\": 1,\n\t            \"param2\": {\"a\": 1.0, \"b@par2\": \"2.1\"},\n\t        },\n\t        \"config2\": {\n", "            \"param3@par3\": 3.2,\n\t            \"param4@par4\": [4, 5, {\"6\": 6}],\n\t            \"param5\": [True, 8],\n\t        },\n\t        \"config3@cfg3\": {\"param6\": {\"param7@par7\": None}, \"param8\": \"True\"},\n\t        \"config4@cfg4\": {\"config5@cfg5\": {\"param9\": \"11\"}},\n\t    }\n\t    check.equal(out_dict, expected_dict)\n\t    shutil.rmtree(\"tests/tmp\")\n\tdef test_show_dict() -> None:\n", "    \"\"\"Test show_dict.\"\"\"\n\t    in_dict = {\n\t        \"model\": {\n\t            \"s1_ae_config\": {\n\t                \"in_dim\": 2,\n\t                \"out_dim\": 1,\n\t                \"layer_channels\": [16, 32, 64],\n\t                \"conv_per_layer\": 1,\n\t                \"residual\": False,\n\t                \"dropout_rate\": 0.0,\n", "            },\n\t            \"mask_module_dim\": [6, 2],\n\t            \"glob_module_dims\": [2, 8, 2],\n\t            \"conv_block_dims\": [32, 64, 128],\n\t        },\n\t        \"train\": {\n\t            \"n_epochs\": 100,\n\t            \"optimizer\": {\n\t                \"name\": \"Adam\",\n\t                \"lr\": 0.001,\n", "                \"weight_decay\": 0.0,\n\t                \"warmup_steps\": 0,\n\t            },\n\t        },\n\t        \"data\": {\n\t            \"dataset\": \"mnist\",\n\t            \"batch_size\": 128,\n\t            \"num_workers\": 6,\n\t        },\n\t    }\n", "    show_dict(in_dict)\n"]}
{"filename": "tests/unit/processing/test_base_processing.py", "chunked_list": ["\"\"\"Test base class of processing.\"\"\"\n\timport pytest_check as check\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.processing.base import Processing\n\tdef test_processing() -> None:\n\t    \"\"\"Test Processing.\"\"\"\n\t    class _ProcessingTest(Processing):\n\t        def __init__(self) -> None:\n\t            super().__init__()\n\t            self.attr = 0\n", "    config = Config({\"a.b\": 1, \"b\": 2, \"c.d.e\": 3, \"c.d.f\": [2, 3]}, [])\n\t    base_process = Processing()\n\t    check.equal(\n\t        (\n\t            base_process.premerge(config),\n\t            base_process.postmerge(config),\n\t            base_process.endbuild(config),\n\t            base_process.presave(config),\n\t            base_process.postload(config),\n\t        ),\n", "        (config, config, config, config, config),\n\t    )\n\t    # Check equality of Processing objects\n\t    proc1 = _ProcessingTest()\n\t    proc1.attr = 0\n\t    proc2 = _ProcessingTest()\n\t    proc2.attr = 0\n\t    check.equal(proc1, proc2)\n\t    proc2.attr = 1\n\t    check.not_equal(proc1, proc2)\n"]}
{"filename": "tests/unit/processing/test_builtin.py", "chunked_list": ["\"\"\"Test built-in processing classes.\"\"\"\n\timport re\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.dict_routines import flatten\n\tfrom cliconfig.processing.builtin import (\n\t    DefaultProcessings,\n\t    ProcessCheckTags,\n\t    ProcessCopy,\n", "    ProcessDelete,\n\t    ProcessMerge,\n\t    ProcessNew,\n\t    ProcessSelect,\n\t    ProcessTyping,\n\t)\n\tdef test_process_merge() -> None:\n\t    \"\"\"Test ProcessMerge.\"\"\"\n\t    # Test @merge_add\n\t    processing = ProcessMerge()\n", "    flat_dict = {\n\t        \"config1.param1\": 0,\n\t        \"config1.param2\": 1,\n\t        \"config2_path@merge_add\": \"tests/configs/merge/default2.yaml\",\n\t    }\n\t    flat_config = Config(flat_dict, [processing])\n\t    flat_config = processing.premerge(flat_config)\n\t    expected_dict = {\n\t        \"config1.param1\": 0,\n\t        \"config1.param2\": 1,\n", "        \"config2.param1\": 2,\n\t        \"config2.param2\": 3,\n\t        \"config3.param1\": 4,\n\t        \"config3.param2\": 5,\n\t        \"config2_path\": \"tests/configs/merge/default2.yaml\",\n\t        \"config3_path\": \"tests/configs/merge/default3.yaml\",\n\t    }\n\t    check.equal(flat_config.dict, expected_dict)\n\t    # Case of introducing a new key\n\t    flat_dict = {\n", "        \"config1.param1\": 0,\n\t        \"config1.param2\": 1,\n\t        \"config3.param1\": 4,\n\t        \"config2_path@merge_add\": \"tests/configs/merge/default2.yaml\",\n\t    }\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=(\n\t            \"@merge_add doest not allow to add \"\n\t            \"already existing keys but key 'config3.param1'.*\"\n", "        ),\n\t    ):\n\t        processing.premerge(Config(flat_dict, [processing]))\n\t    # Test @merge_before and @merge_after\n\t    flat_dict = {\n\t        \"a.b\": 1,\n\t        \"a.b_path@merge_after\": \"tests/configs/merge/additional2.yaml\",\n\t    }\n\t    flat_config = Config(flat_dict, [processing])\n\t    flat_config = processing.premerge(flat_config)\n", "    expected_dict = {\n\t        \"a.b\": 2,\n\t        \"a.b_path\": \"tests/configs/merge/additional2.yaml\",\n\t        \"c_path\": \"tests/configs/merge/additional3.yaml\",\n\t        \"c\": 3,\n\t    }\n\t    check.equal(flat_config.dict, expected_dict)\n\t    flat_dict = {\n\t        \"a.b\": 1,\n\t        \"a.b_path@merge_before\": \"tests/configs/merge/additional2.yaml\",\n", "        \"c\": 3,\n\t    }\n\t    flat_config = Config(flat_dict, [processing])\n\t    flat_config = processing.premerge(flat_config)\n\t    expected_dict = {\n\t        \"a.b\": 1,\n\t        \"a.b_path\": \"tests/configs/merge/additional2.yaml\",\n\t        \"c_path\": \"tests/configs/merge/additional3.yaml\",\n\t        \"c\": 3,\n\t    }\n", "    check.equal(flat_config.dict, expected_dict)\n\t    check.equal(flat_config.process_list, [processing])\n\t    # Not valid path\n\t    for tag in [\"merge_before\", \"merge_after\", \"merge_add\"]:\n\t        with pytest.raises(\n\t            ValueError,\n\t            match=re.escape(\n\t                f\"Key with '@{tag}' tag must be associated \"\n\t                \"to a string corresponding to a *yaml* file.\"\n\t                f\"The problem occurs at key: a@{tag}\"\n", "            ),\n\t        ):\n\t            processing.premerge(Config({f\"a@{tag}\": \"no_yaml\"}, [processing]))\n\tdef test_process_copy() -> None:\n\t    \"\"\"Test ProcessCopy.\"\"\"\n\t    processing = ProcessCopy()\n\t    flat_dict = {\n\t        \"config1.param1\": 1,\n\t        \"config2.param2@copy\": \"config1.param1\",\n\t    }\n", "    flat_config = Config(flat_dict, [processing])\n\t    flat_config = processing.premerge(flat_config)\n\t    check.equal(\n\t        flat_config.dict, {\"config1.param1\": 1, \"config2.param2\": \"config1.param1\"}\n\t    )\n\t    flat_config.dict[\"config1.param1\"] = 2\n\t    flat_config = processing.postmerge(flat_config)\n\t    check.equal(flat_config.dict, {\"config1.param1\": 2, \"config2.param2\": 2})\n\t    check.equal(processing.copied_keys, {\"config2.param2\"})\n\t    flat_config = processing.presave(flat_config)\n", "    check.equal(processing.current_value, {\"config2.param2\": 2})\n\t    check.equal(\n\t        flat_config.dict, {\"config1.param1\": 2, \"config2.param2@copy\": \"config1.param1\"}\n\t    )\n\t    check.equal(processing.keys_to_copy, {\"config2.param2\": \"config1.param1\"})\n\t    check.equal(flat_config.process_list, [processing])\n\t    # Reset copy processing\n\t    processing.keys_to_copy = {}\n\t    # Case of wrong key\n\t    with pytest.raises(\n", "        ValueError,\n\t        match=(\n\t            \"Key with '@copy' tag must be associated \"\n\t            \"to a string corresponding to a flat key. \"\n\t            \"The problem occurs at key: a@copy with value: True\"\n\t        ),\n\t    ):\n\t        processing.premerge(Config({\"a@copy\": True}, [processing]))\n\t    # Case of already existing @copy but associated to an other key\n\t    processing.keys_to_copy = {\"a\": \"b\"}\n", "    with pytest.raises(\n\t        ValueError,\n\t        match=(\n\t            \"Key with '@copy' has change its value to copy. Found key: a@copy@tag \"\n\t            \"with value: c, previous value to copy: b\"\n\t        ),\n\t    ):\n\t        processing.premerge(Config({\"a@copy@tag\": \"c\"}, [processing]))\n\t    # Case of non-existing key (on post-merge): do not raise error\n\t    processing.keys_to_copy = {\"a\": \"b\"}\n", "    processing.postmerge(Config({\"a\": \"b\"}, [processing]))\n\t    # Case of non-existing key (on end-build): raise error\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"A key with '@copy' tag has been found but the key to copy does not \"\n\t            \"exist at the end of the build and it has been never copied. Found key: \"\n\t            \"a that would copy the key: b.\"\n\t        ),\n\t    ):\n", "        processing.endbuild(Config({\"a\": \"b\"}, [processing]))\n\t    # Copy if it appears on end-build\n\t    config = processing.endbuild(Config({\"a\": \"b\", \"b\": 3}, [processing]))\n\t    check.equal(config.dict[\"a\"], 3)\n\t    # Case overwriting a key\n\t    processing.current_value = {\"a\": 2}\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=(\n\t            \"Found attempt to modify a key with '@copy' tag. The key is \"\n", "            \"protected against direct updates. Found key: a of value c that copy \"\n\t            \"b of value 1\"\n\t        ),\n\t    ):\n\t        processing.postmerge(Config({\"a\": \"c\", \"b\": 1}, [processing]))\n\tdef test_process_typing() -> None:\n\t    \"\"\"Test ProcessTyping.\"\"\"\n\t    processing = ProcessTyping()\n\t    flat_dict = {\n\t        \"param1@type:int\": 1,\n", "        \"param2@type:List[Optional[Dict[str, int|float]]]\": [{\"a\": [0.0]}],\n\t    }\n\t    flat_config = Config(flat_dict, [processing])\n\t    flat_config = processing.premerge(flat_config)\n\t    flat_config.dict[\"param1\"] = 3\n\t    flat_config.dict[\"param2\"] = {\"a\": None, \"b\": [{\"c\": 1}]}\n\t    flat_config.dict = flatten(flat_config.dict)\n\t    flat_config = processing.postmerge(flat_config)\n\t    check.equal(\n\t        flat_config.dict, {\"param1\": 3, \"param2.a\": None, \"param2.b\": [{\"c\": 1}]}\n", "    )\n\t    check.equal(\n\t        flat_config.process_list[0].forced_types,  # type: ignore\n\t        {\n\t            \"param1\": (int,),\n\t            \"param2\": ((\"list\", ((type(None), (\"dict\", (str,), (int, float))),)),),\n\t        },\n\t    )\n\t    check.equal(\n\t        flat_config.process_list[0].type_desc,  # type: ignore\n", "        {\"param1\": \"int\", \"param2\": \"List[Optional[Dict[str, int|float]]]\"},\n\t    )\n\t    flat_config = processing.endbuild(flat_config)  # no error\n\t    flat_config = processing.presave(flat_config)\n\t    check.equal(\n\t        flat_config.dict,\n\t        {\"param1@type:int\": 3, \"param2.a\": None, \"param2.b\": [{\"c\": 1}]},\n\t    )\n\t    processing.forced_types = {}  # Reset forced types\n\t    processing.type_desc = {}  # Reset type description\n", "    # Case of different type on pre-merge: do not raise error!\n\t    processing.premerge(Config({\"param@type:int\": \"str\"}, [processing]))\n\t    # Case of already existing type and othere in premerge\n\t    processing.forced_types = {\"param\": (int,)}\n\t    processing.type_desc = {\"param\": \"int\"}\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=(\n\t            \"Find the tag '@type:str' on a key that has already been associated \"\n\t            \"to an other type: int. Find problem at key: param@type:str\"\n", "        ),\n\t    ):\n\t        processing.premerge(Config({\"param@type:str\": \"str\"}, [processing]))\n\t    # Case of wrong type in post-merge: no error\n\t    processing.forced_types = {\"param\": (int,)}\n\t    processing.type_desc = {\"param\": \"int\"}\n\t    processing.postmerge(Config({\"param\": \"mystr\"}, [processing]))\n\t    # Case of wrong type in end-build: raise error\n\t    with pytest.raises(\n\t        ValueError,\n", "        match=(\n\t            \"Key previously tagged with '@type:int' must be \"\n\t            \"associated to a value of type int. Find the \"\n\t            \"value: mystr of type <class 'str'> at key: param\"\n\t        ),\n\t    ):\n\t        processing.endbuild(Config({\"param\": \"mystr\"}, [processing]))\n\tdef test_process_select() -> None:\n\t    \"\"\"Test ProcessSelect.\"\"\"\n\t    processing = ProcessSelect()\n", "    flat_dict = {\n\t        \"models.model_names@select\": [\"models.model1\", \"models.model3\"],\n\t        \"models.model1.param1\": 1,\n\t        \"models.model1.param2\": 2,\n\t        \"models.model2.param1\": 3,\n\t        \"models.model2.param2\": 4,\n\t        \"models.model3.submodel.param\": 5,\n\t        \"models.model4.param\": 6,\n\t    }\n\t    expected_dict = {\n", "        \"models.model_names\": [\"models.model1\", \"models.model3\"],\n\t        \"models.model1.param1\": 1,\n\t        \"models.model1.param2\": 2,\n\t        \"models.model3.submodel.param\": 5,\n\t    }\n\t    config = Config(flat_dict, [])\n\t    config = processing.premerge(config)\n\t    config = processing.postmerge(config)\n\t    check.equal(config.dict, expected_dict)\n\t    config = processing.presave(config)\n", "    check.is_in(\"models.model_names@select\", config.dict)\n\t    check.equal(\n\t        config.dict[\"models.model_names@select\"], [\"models.model1\", \"models.model3\"]\n\t    )\n\t    check.is_not_in(\"models.model_names\", config.dict)\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"The keys in the list of parameters tagged with '@select' must be \"\n\t            \"identical before the last dot (= on the same subconfig). Find: \"\n", "            \"abab and dede before the last dot.\"\n\t        ),\n\t    ):\n\t        processing.premerge(Config({\"p@select\": [\"abab.cdcd\", \"dede.fgfg\"]}, []))\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"The value of parameters tagged with '@select' must be a string or a \"\n\t            \"list of strings representing flat key(s). \"\n\t        ),\n", "    ):\n\t        processing.premerge(Config({\"p@select\": 0}, []))\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=(\n\t            \"Find attempt to delete the configuration at the root. You must pass a \"\n\t            \"flat key with a least one dot on parameter tagged with @select. \"\n\t            \"Find key: p@select with value: root\"\n\t        ),\n\t    ):\n", "        processing.premerge(Config({\"p@select\": \"root\"}, []))\n\tdef test_process_delete() -> None:\n\t    \"\"\"Test ProcessDelete.\"\"\"\n\t    processing = ProcessDelete()\n\t    config = Config(\n\t        {\n\t            \"@select@delete\": \"configs.config1\",\n\t            \"1@merge_add@delete\": \"config1.yaml\",\n\t            \"2@merge_add@delete\": \"config2.yaml\",\n\t        },\n", "        [processing],\n\t    )\n\t    config = processing.premerge(config)\n\t    check.equal(config.dict, {})\n\tdef test_process_new() -> None:\n\t    \"\"\"Test ProcessNew.\"\"\"\n\t    processing = ProcessNew()\n\t    flat_dict = {\n\t        \"param1\": 1,\n\t        \"config1\": {\n", "            \"param2\": 2,\n\t            \"subconfig@new\": {\"param3\": 3, \"param4\": 4},\n\t        },\n\t        \"config2@new@tag.subconfig.param3\": 3,\n\t        \"config3.subconfig@new.param4\": 4,\n\t    }\n\t    flat_dict = flatten(flat_dict)\n\t    config = Config(flat_dict, [processing])\n\t    check.equal(\n\t        processing.premerge(config).dict,\n", "        {\n\t            \"param1\": 1,\n\t            \"config1.param2\": 2,\n\t        },\n\t    )\n\t    check.equal(\n\t        processing.postmerge(config).dict,\n\t        {\n\t            \"param1\": 1,\n\t            \"config1.param2\": 2,\n", "            \"config1.subconfig.param3\": 3,\n\t            \"config1.subconfig.param4\": 4,\n\t            \"config2.subconfig.param3\": 3,\n\t            \"config3.subconfig.param4\": 4,\n\t        },\n\t    )\n\t    check.equal(\n\t        processing.presave(config).dict,\n\t        {\n\t            \"param1\": 1,\n", "            \"config1.param2\": 2,\n\t            \"config1.subconfig.param3@new\": 3,\n\t            \"config1.subconfig.param4@new\": 4,\n\t            \"config2.subconfig.param3@new\": 3,\n\t            \"config3.subconfig.param4@new\": 4,\n\t        },\n\t    )\n\tdef test_process_check_tags() -> None:\n\t    \"\"\"Test ProcessCheckTags.\"\"\"\n\t    processing = ProcessCheckTags()\n", "    flat_dict = {\n\t        \"config.param1\": 1,\n\t        \"param1\": 2,\n\t    }\n\t    config = Config(flat_dict, [processing])\n\t    check.equal(processing.premerge(config).dict, flat_dict)\n\t    flat_dicts = [{\"param1@tag\": 1}, {\"@foo\": 2}, {\"@\": 3}]\n\t    for flat_dict in flat_dicts:\n\t        with pytest.raises(\n\t            ValueError,\n", "            match=(\n\t                \"Keys with tags are encountered at the end of \"\n\t                \"the pre-merge process.*\"\n\t            ),\n\t        ):\n\t            processing.premerge(Config(flat_dict, [processing]))\n\tdef test_default_processings() -> None:\n\t    \"\"\"Test DefaultProcessings.\"\"\"\n\t    config = Config({}, DefaultProcessings().list)\n\t    for proc in [\n", "        ProcessCheckTags(),\n\t        ProcessMerge(),\n\t        ProcessCopy(),\n\t        ProcessTyping(),\n\t        ProcessDelete(),\n\t        ProcessSelect(),\n\t        ProcessNew(),\n\t    ]:\n\t        check.is_in(proc, config.process_list)\n"]}
{"filename": "tests/unit/processing/test_type_parser.py", "chunked_list": ["\"\"\"Test the type parser module.\"\"\"\n\timport re\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig.processing._type_parser import (\n\t    _isinstance,\n\t    _parse_dict,\n\t    _parse_list,\n\t    _parse_optional,\n\t    _parse_type,\n", "    _parse_union,\n\t)\n\tdef test_type_parser_isinstance() -> None:\n\t    \"\"\"Test _parse_type and _isinstance.\"\"\"\n\t    type_ = _parse_type(\"None\")\n\t    check.equal(type_, (type(None),))\n\t    check.is_true(_isinstance(None, type_))\n\t    check.is_false(_isinstance([None], type_))\n\t    type_ = _parse_type(\"List[float]\")\n\t    check.equal(type_, ((\"list\", (float,)),))\n", "    type_ = _parse_type(\"list|dict\")\n\t    check.equal(type_, (list, dict))\n\t    check.is_true(_isinstance([2.0, True], type_))\n\t    type_ = _parse_type(\"Dict[str, List[float]]\")\n\t    check.equal(type_, ((\"dict\", (str,), ((\"list\", (float,)),)),))\n\t    check.is_true(_isinstance({\"a\": [1.0, 2.0]}, type_))\n\t    check.is_false(_isinstance({\"a\": [1.0, 2.0], \"b\": [1.0, 2]}, type_))\n\t    type_ = _parse_type(\"Dict[str|bool, int|float]\")\n\t    check.equal(type_, ((\"dict\", (str, bool), (int, float)),))\n\t    type_ = _parse_type(\"Union[Optional[float], Any]\")\n", "    check.equal(type_, ((type(None), float), object))\n\t    check.is_true(_isinstance(\"2\", type_))\n\t    type_ = _parse_type(\n\t        \"Dict[str, Union[List[None|float], Dict[bool, Optional[list]]]]|List[Any]|\"\n\t        \"Dict[int, Optional[Dict[str, float]]]|Optional[float]\"\n\t    )\n\t    check.equal(\n\t        (\n\t            (\n\t                \"dict\",\n", "                (str,),\n\t                (\n\t                    (\"list\", (type(None), float)),\n\t                    (\"dict\", (bool,), ((type(None), list),)),\n\t                ),\n\t            ),\n\t            (\"list\", (object,)),\n\t            (\"dict\", (int,), ((type(None), (\"dict\", (str,), (float,))),)),\n\t            (type(None), float),\n\t        ),\n", "        type_,\n\t    )\n\t    check.is_true(_isinstance({\"a\": [None, 1.0], \"b\": {True: None}}, type_))\n\t    check.is_true(_isinstance([[]], type_))\n\t    check.is_true(_isinstance({1: {\"a\": 2.0}}, type_))\n\t    check.is_false(_isinstance({\"a\": [None, 1.0], \"b\": {False: 1, True: \"1\"}}, type_))\n\t    # Wrong type description\n\t    with pytest.raises(ValueError, match=\"Unknown type: 'unknown'\"):\n\t        _parse_type(\"unknown\")\n\t    desc = \"str, List[float]\"\n", "    with pytest.raises(ValueError, match=re.escape(f\"Unknown type: '{desc}'\")):\n\t        _parse_type(desc)\n\t    desc = \"None||float\"\n\t    with pytest.raises(ValueError, match=f\"Unknown type: '{desc}'\"):\n\t        _parse_type(desc)\n\t    desc = (\n\t        \"Dict[str, Union[List[None|float], Dict[bool, Optionnal[int]]]]|List[Any]|\"\n\t        \"Dict[List[int], Optional[Dict[str, float]]]|float\"\n\t    )  # Optionnal with 2 n\n\t    with pytest.raises(ValueError, match=f\"Unknown type: '{desc}'\"):\n", "        _parse_type(desc)\n\t    # Wrong type in isinstance (here a 'dict' tuple has 3 elements instead of 2)\n\t    wrong_type = (\n\t        (\n\t            \"dict\",\n\t            (str,),\n\t            (\n\t                (\"list\", (type(None), float)),\n\t                (\"dict\", (bool,), ((type(None), list),), str),\n\t            ),\n", "        ),\n\t        (\"list\", (object,)),\n\t        (\"dict\", (int,), ((type(None), (\"dict\", (str,), (float,))),)),\n\t        (type(None), float),\n\t    )\n\t    with pytest.raises(ValueError, match=\"Invalid type for _isinstance:.*\"):\n\t        _isinstance({\"a\": {True: \"a\"}}, wrong_type)\n\tdef test_errors_in_parse() -> None:\n\t    \"\"\"Test error raised in _parse_X functions.\"\"\"\n\t    with pytest.raises(ValueError, match=\"Invalid List type:.*\"):\n", "        _parse_list(\"List[bool, str]\")\n\t    with pytest.raises(ValueError, match=\"Invalid Dict type:.*\"):\n\t        _parse_dict(\"Dict[str, bool, int]]\")\n\t    with pytest.raises(ValueError, match=\"Invalid Union type:.*\"):\n\t        _parse_union(\"Union[str]\")\n\t    with pytest.raises(ValueError, match=\"Invalid Optional type:.*\"):\n\t        _parse_optional(\"Optional[str, int]\")\n"]}
{"filename": "tests/unit/processing/test_create.py", "chunked_list": ["\"\"\"Test helpers to create processing functions.\"\"\"\n\timport re\n\timport pytest\n\timport pytest_check as check\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.processing.create import (\n\t    _is_matched,\n\t    create_processing_keep_property,\n\t    create_processing_value,\n\t)\n", "def test_is_matched() -> None:\n\t    \"\"\"Test _is_matched.\"\"\"\n\t    check.is_true(_is_matched(\"foo.bar.test\", regex=\".*st\", tag_name=None))\n\t    check.is_false(_is_matched(\"test.bar.foo\", regex=\".*st\", tag_name=None))\n\t    check.is_true(_is_matched(\"foo.bar.test@tag\", regex=None, tag_name=\"tag\"))\n\t    check.is_false(_is_matched(\"foo.bar@tag.test\", regex=None, tag_name=\"tag\"))\n\t    check.is_false(_is_matched(\"foo.bar.test@tag2\", regex=None, tag_name=\"tag\"))\n\t    with pytest.raises(\n\t        ValueError, match=\"Either regex or tag_name must be defined but not both.\"\n\t    ):\n", "        _is_matched(\"foo.bar\", \".*\", \"tag\")\n\t    with pytest.raises(\n\t        ValueError, match=\"Either regex or tag_name must be defined.\"\n\t    ):\n\t        _is_matched(\"foo.bar\", None, None)\n\tdef test_create_processing_value() -> None:\n\t    \"\"\"Test create_processing_value.\"\"\"\n\t    # Persistent, premerge\n\t    proc1 = create_processing_value(\n\t        lambda x: x + 1, tag_name=\"add1\", order=1.0, persistent=True\n", "    )\n\t    proc2 = create_processing_value(\n\t        lambda x: -x, regex=\"neg_number.*\", order=0.0, persistent=True\n\t    )\n\t    in_dict = {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3@add1\": 1}\n\t    config = Config(in_dict, [proc1, proc2])\n\t    config = config.process_list[1].premerge(config)\n\t    config = config.process_list[0].premerge(config)\n\t    check.equal(config.dict, {\"neg_number1\": -1, \"neg_number2\": -1, \"neg_number3\": 0})\n\t    config = config.process_list[1].premerge(config)\n", "    config = config.process_list[0].premerge(config)\n\t    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n\t    config = config.process_list[1].postmerge(config)\n\t    config = config.process_list[0].postmerge(config)\n\t    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n\t    config = config.process_list[1].endbuild(config)\n\t    config = config.process_list[0].endbuild(config)\n\t    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n\t    config = config.process_list[1].presave(config)\n\t    config = config.process_list[0].presave(config)\n", "    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n\t    config = config.process_list[1].postload(config)\n\t    config = config.process_list[0].postload(config)\n\t    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n\t    # Non persistent, postmerge\n\t    proc2 = create_processing_value(\n\t        lambda x: -x, \"postmerge\", regex=\"neg_number.*\", order=0.0, persistent=False\n\t    )\n\t    proc1 = create_processing_value(\n\t        lambda x: x + 1, \"postmerge\", tag_name=\"add1\", order=1.0, persistent=False\n", "    )\n\t    in_dict = {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3@add1\": 1}\n\t    config = Config(in_dict, [proc1, proc2])\n\t    config = config.process_list[1].premerge(config)\n\t    config = config.process_list[0].premerge(config)\n\t    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n\t    config = config.process_list[1].postmerge(config)\n\t    config = config.process_list[0].postmerge(config)\n\t    check.equal(config.dict, {\"neg_number1\": -1, \"neg_number2\": -1, \"neg_number3\": 0})\n\t    config = config.process_list[1].premerge(config)\n", "    config = config.process_list[0].premerge(config)\n\t    config = config.process_list[1].postmerge(config)\n\t    config = config.process_list[0].postmerge(config)\n\t    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 0})\n\t    # No signature, endbuild, presave, postload\n\t    proc1 = create_processing_value(type, \"endbuild\", tag_name=\"get_type\")\n\t    proc2 = create_processing_value(str, \"presave\", tag_name=\"to_str\")\n\t    proc3 = create_processing_value(\n\t        lambda *args: 0,  # noqa\n\t        \"postload\",\n", "        tag_name=\"zero\"\n\t    )\n\t    in_dict2 = {\n\t        \"type1@get_type@to_str@zero\": 1,\n\t        \"type2@get_type@to_str@zero\": \"2\",\n\t        \"type3@get_type@to_str@zero\": True\n\t    }\n\t    config = Config(in_dict2, [proc1, proc2, proc3])\n\t    config = config.process_list[0].premerge(config)\n\t    config = config.process_list[1].premerge(config)\n", "    config = config.process_list[2].premerge(config)\n\t    check.equal(config.dict, {\"type1\": 1, \"type2\": \"2\", \"type3\": True})\n\t    config = config.process_list[0].endbuild(config)\n\t    check.equal(config.dict, {\"type1\": int, \"type2\": str, \"type3\": bool})\n\t    config = config.process_list[1].presave(config)\n\t    check.equal(config.dict, {\n\t        \"type1\": \"<class 'int'>\",\n\t        \"type2\": \"<class 'str'>\",\n\t        \"type3\": \"<class 'bool'>\"\n\t    })\n", "    config = config.process_list[2].postload(config)\n\t    check.equal(config.dict, {\"type1\": 0, \"type2\": 0, \"type3\": 0})\n\t    # Config in input\n\t    proc = create_processing_value(\n\t        lambda x, flat_config: eval(  # pylint: disable=eval-used\n\t            x, {\"config\": flat_config}\n\t        ),\n\t        tag_name=\"eval\",\n\t        persistent=False,\n\t    )\n", "    eval_dict = {\"param1\": 1, \"param2@eval\": \"config.param1 + 1\"}\n\t    config = Config(eval_dict, [proc])\n\t    config = config.process_list[0].premerge(config)\n\t    check.equal(config.dict, {\"param1\": 1, \"param2\": 2})\n\t    # Failing cases\n\t    with pytest.raises(\n\t        ValueError, match=\"Processing type 'UNKNOWN' not recognized.*\"\n\t    ):\n\t        create_processing_value(lambda x: x + 1, \"UNKNOWN\", tag_name=\"tag\")\n\t    with pytest.raises(\n", "        ValueError, match=\"You must provide a tag or a regex but not both.\"\n\t    ):\n\t        create_processing_value(lambda x: x + 1, tag_name=\"add1\", regex=\"neg_number.*\")\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"You must provide a tag or a regex (to trigger the value update).\"\n\t        ),\n\t    ):\n\t        create_processing_value(lambda x: x + 1, order=0.0)\n", "def test_create_processing_keep_property() -> None:\n\t    \"\"\"Test create_processing_keep_property.\"\"\"\n\t    proc1 = create_processing_keep_property(type, regex=\".*\")\n\t    proc2 = create_processing_keep_property(lambda x: x, tag_name=\"protect\")\n\t    proc3 = create_processing_keep_property(\n\t        lambda x, config: len(x + config.dict[\"list\"]),\n\t        tag_name=\"len\",\n\t    )\n\t    in_dict = {\"str\": \"foo\", \"int\": 2, \"list@protect\": [1, 2, 3], \"list2@len\": [1, 2]}\n\t    config = Config(in_dict, [proc1, proc2, proc3])\n", "    config = config.process_list[0].premerge(config)\n\t    config = config.process_list[1].premerge(config)\n\t    config = config.process_list[2].premerge(config)\n\t    check.equal(\n\t        config.dict,\n\t        {\"str\": \"foo\", \"int\": 2, \"list\": [1, 2, 3], \"list2\": [1, 2]}\n\t    )\n\t    config.dict = {\"str\": \"foo\", \"int\": -1, \"list\": [1, 2, 3], \"list2\": [4, 5]}\n\t    config = config.process_list[0].postmerge(config)\n\t    config = config.process_list[1].postmerge(config)\n", "    config = config.process_list[2].postmerge(config)\n\t    config.dict = {\"str\": \"foo2\", \"int\": 6, \"list\": [1, 2, 3], \"list2\": [8, 9]}\n\t    config = config.process_list[0].endbuild(config)\n\t    config = config.process_list[1].endbuild(config)\n\t    config = config.process_list[2].endbuild(config)\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"Property of key str has changed from <class 'str'> to <class 'int'> \"\n\t            \"while it is protected by a keep-property processing (problem found on \"\n", "            \"end-build).\"\n\t        ),\n\t    ):\n\t        config.process_list[0].endbuild(Config({\"str\": 0}, []))\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"Property of key list has changed from [1, 2, 3] to [1, 2] while \"\n\t            \"it is protected by a keep-property processing (problem found on \"\n\t            \"post-merge).\"\n", "        ),\n\t    ):\n\t        config.process_list[1].postmerge(Config({\"list\": [1, 2]}, []))\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"Property of key list2 has changed from 5 to 3 while \"\n\t            \"it is protected by a keep-property processing (problem found on \"\n\t            \"post-merge).\"\n\t        ),\n", "    ):\n\t        config.process_list[2].postmerge(Config({\"list\": [1, 2], \"list2\": [3]}, []))\n\t    # Should not raise on pre-merge:\n\t    config.process_list[0].premerge(Config({\"str\": 0}, []))\n\t    config.process_list[1].premerge(Config({\"list\": [1, 2]}, []))\n\t    config.process_list[2].premerge(Config({\"list\": [1, 2], \"list2\": []}, []))\n\t    # Failing cases\n\t    with pytest.raises(\n\t        ValueError, match=\"You must provide a tag or a regex but not both.\"\n\t    ):\n", "        create_processing_keep_property(lambda x: x, tag_name=\"protect\", regex=\".*\")\n\t    with pytest.raises(\n\t        ValueError,\n\t        match=re.escape(\n\t            \"You must provide a tag or a regex (to trigger the value update).\"\n\t        ),\n\t    ):\n\t        create_processing_keep_property(lambda x: x, premerge_order=0.0)\n"]}
{"filename": "docs/conf.py", "chunked_list": ["\"\"\"Configuration file for the Sphinx documentation builder.\"\"\"\n\t# pylint: disable=all\n\t# For the full list of built-in configuration values, see the documentation:\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\timport os\n\timport sys\n\tfrom setuptools_scm import get_version\n\tsys.path.insert(0, os.path.abspath(\"../\"))\n\t# -- Project information -----------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n", "project = \"CLI Config\"\n\tcopyright = \"2023, Valentin Goldite\"  # noqa A001\n\tauthor = \"Valentin Goldite\"\n\ttry:\n\t    release = get_version()\n\texcept:  # noqa E722\n\t    release = get_version(root=\"..\", relative_to=__file__)\n\t# -- General configuration ---------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\textensions = [\n", "    \"myst_parser\",\n\t    \"sphinx.ext.autodoc\",\n\t    \"sphinx.ext.inheritance_diagram\",\n\t    \"sphinx.ext.intersphinx\",\n\t    \"sphinx.ext.napoleon\",\n\t    \"sphinx_autodoc_typehints\",\n\t]\n\tmaster_doc = \"index\"\n\tautoapi_type = \"python\"\n\tautoapi_dirs = [\"cliconfig\"]\n", "autodoc_default_options = {\n\t    \"member-order\": \"bysource\",\n\t    \"undoc-members\": True,\n\t}\n\tadd_module_names = False\n\tautoclass_content = \"both\"\n\tnapoleon_use_param = True\n\tintersphinx_mapping = {\n\t    \"python\": (\"https://docs.python.org/\", None),\n\t    \"numpy\": (\"http://docs.scipy.org/doc/numpy/\", None),\n", "}\n\ttemplates_path = [\"_templates\"]\n\texclude_patterns = [\"_build\"]\n\t# -- Options for HTML output -------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n\thtml_theme = \"sphinx_rtd_theme\"\n\thtml_theme_options = {\n\t    \"canonical_url\": \"\",\n\t    \"analytics_id\": \"UA-XXXXXXX-1\",\n\t    \"logo_only\": False,\n", "    \"display_version\": True,\n\t    \"prev_next_buttons_location\": \"both\",\n\t    \"style_external_links\": \"#ff9900\",\n\t    \"style_nav_header_background\": \"#ff9900\",\n\t    # Toc options\n\t    \"collapse_navigation\": False,\n\t    \"sticky_navigation\": True,\n\t    \"navigation_depth\": 4,\n\t    \"includehidden\": True,\n\t    \"titles_only\": False,\n", "}\n\thtml_context = {\n\t    \"display_github\": True,  # Integrate GitHub\n\t    \"github_user\": \"valentingol\",  # Username\n\t    \"github_repo\": \"cliconfig\",  # Repo name\n\t    \"github_version\": \"main\",  # Version\n\t    \"conf_py_path\": \"/docs/\",  # Path in the checkout to the docs root\n\t}\n"]}
{"filename": "cliconfig/dict_routines.py", "chunked_list": ["\"\"\"Routines to manipulate nested and flat dictionaries (and mix of both).\n\tUsed by :mod:`.process_routines` and :mod:`.config_routines`.\n\t\"\"\"\n\timport os\n\tfrom typing import Any, Dict, Tuple, Union\n\timport yaml\n\tfrom flatten_dict import flatten as _flatten\n\tfrom flatten_dict import unflatten as _unflatten\n\tfrom cliconfig.yaml_tags._yaml_tags import get_yaml_loader, insert_tags\n\tdef merge_flat(\n", "    dict1: Dict[str, Any],\n\t    dict2: Dict[str, Any],\n\t    *,\n\t    allow_new_keys: bool = True,\n\t) -> Dict[str, Any]:\n\t    \"\"\"Flatten then merge dict2 into dict1. The result is flat.\n\t    Work even if dict1 and dict2 have a mix of nested and flat\n\t    dictionaries. For instance like this:\n\t    .. code-block:: python\n\t        dict1 = {'a.b': 1, 'a': {'c': 2}, 'a.d': {'e.f': 3}}\n", "    Parameters\n\t    ----------\n\t    dict1 : Dict[str, Any]\n\t        The first dict. It can be nested, flat or a mix of both.\n\t    dict2 : Dict[str, Any]\n\t        The second dict to merge into first dict.\n\t    allow_new_keys : bool, optional\n\t        If True, new keys (that are not in dict1) are allowed in dict2.\n\t        By default True.\n\t    Raises\n", "    ------\n\t    ValueError\n\t        If allow_new_keys is False and dict2 has new keys that are not in dict1.\n\t    ValueError\n\t        If there are conflicting keys when flatten one of the dicts.\n\t        See last example. You may consider calling :func:`clean_pre_flat` on the input\n\t        dicts in that case.\n\t    Returns\n\t    -------\n\t    flat_dict : Dict[str, Any]\n", "        The flat dict (all keys are at the root and separated by dots).\n\t    Examples\n\t    --------\n\t    ::\n\t        >>> merge_dict({'a.b': 1, 'a': {'c': 2}},  {'c': 3}, allow_new_keys=True)\n\t        {'a.b': 1, 'a.c': 2, 'c': 3}\n\t        >>> merge_dict({'a.b': 1, 'a': {'c': 2}},  {'c': 3}, allow_new_keys=False)\n\t        ValueError: New parameter found 'c' that is not in the original dict.\n\t        >>> merge_dict({'a.b': 1, 'a': {'b': 1}},  {'c': 3}, allow_new_keys=True)\n\t        ValueError: duplicated key 'a.b'.\n", "        The above exception was the direct cause of the following exception:\n\t        ValueError: You may consider calling 'clean_pre_flat' on dict 1 before merging.\n\t    \"\"\"\n\t    # Flatten dicts\n\t    flat_dict1, flat_dict2 = _flat_before_merge(dict1, dict2)\n\t    if not allow_new_keys:\n\t        # Check that there are no new keys in dict2\n\t        for key in flat_dict2:\n\t            if key not in flat_dict1.keys():\n\t                raise ValueError(\n", "                    f\"New parameter found '{key}' in that is not in the original \"\n\t                    \"dict.\"\n\t                )\n\t    # Merge flat dicts\n\t    flat_dict = {**flat_dict1, **flat_dict2}\n\t    return flat_dict\n\tdef _flat_before_merge(\n\t    dict1: Dict[str, Any], dict2: Dict[str, Any]\n\t) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n\t    \"\"\"Flatten two dicts to merge them later.\"\"\"\n", "    # Flatten dicts\n\t    flat_dicts = []\n\t    for i, _dict in enumerate([dict1, dict2]):\n\t        # Check if already flat\n\t        is_flat = all(not isinstance(val, dict) for val in _dict.values())\n\t        if not is_flat:\n\t            try:\n\t                flat_dict = flatten(_dict)\n\t            except ValueError as exc:\n\t                raise ValueError(\n", "                    f\"Duplicated key found in dict {i + 1} when flattening. \"\n\t                    f\"You may consider calling 'clean_pre_flat' before merging.\"\n\t                ) from exc\n\t        else:\n\t            flat_dict = _dict\n\t        flat_dicts.append(flat_dict)\n\t    return flat_dicts[0], flat_dicts[1]\n\tdef merge_flat_paths(\n\t    dict_or_path1: Union[str, Dict[str, Any]],\n\t    dict_or_path2: Union[str, Dict[str, Any]],\n", "    *,\n\t    allow_new_keys: bool = True,\n\t) -> Dict[str, Any]:\n\t    \"\"\"Flatten then merge two dict eventually loaded from yaml file paths.\n\t    Similar to :func:`.merge_flat` but allow passing the paths of dicts\n\t    as inputs. It merges the second dict into the first one.\n\t    Parameters\n\t    ----------\n\t    dict_or_path1 : Union[str, Dict[str, Any]]\n\t        The first dict or its path.\n", "    dict_or_path2 : Union[str, Dict[str, Any]]\n\t        The second dict or its path, to merge into first dict.\n\t    allow_new_keys : bool, optional\n\t        If True, new keys (that are not in dict1) are allowed in dict2.\n\t        By default True.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If allow_new_keys is False and dict2 has new keys that are not in dict1.\n\t    ValueError\n", "        If there are conflicting keys when flatten one of the dicts.\n\t        See last example. You may consider calling :func:`clean_pre_flat` on the input\n\t        dicts in that case.\n\t    Returns\n\t    -------\n\t    flat_dict : Dict[str, Any]\n\t        The flat dict (all keys are at the root and separated by dots).\n\t    \"\"\"\n\t    dicts = []\n\t    for dict_or_path in [dict_or_path1, dict_or_path2]:\n", "        if isinstance(dict_or_path, str):\n\t            _dict = load_dict(dict_or_path)\n\t        else:\n\t            _dict = dict_or_path\n\t        dicts.append(_dict)\n\t    dict1, dict2 = dicts[0], dicts[1]\n\t    flat_dict = merge_flat(\n\t        dict1,\n\t        dict2,\n\t        allow_new_keys=allow_new_keys,\n", "    )\n\t    return flat_dict\n\tdef flatten(in_dict: Dict[str, Any]) -> Dict[str, Any]:\n\t    \"\"\"Flatten dict then return it (flat keys are built with dots).\n\t    Work even if in_dict is a mix of nested and flat dictionaries.\n\t    For instance like this:\n\t    .. code-block:: python\n\t        >>> flatten({'a.b': {'c': 1}, 'a': {'b.d': 2}, 'a.e': {'f.g': 3}})\n\t        {'a.b.c': 1, 'a.b.d': 2, 'a.e.f.g': 3}\n\t    Parameters\n", "    ----------\n\t    in_dict : Dict[str, Any]\n\t        The dict to flatten. It can be nested, already flat or a mix of both.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If dict has some conflicting keys (like ``{'a.b': <x>, 'a': {'b': <y>}}``).\n\t    Returns\n\t    -------\n\t    flat_dict : Dict[str, Any]\n", "        The flattened dict.\n\t    Note\n\t    ----\n\t        Nested empty dict are ignored even if they are conflicting (see last example).\n\t    Examples\n\t    --------\n\t    ::\n\t        >>> flatten({'a.b': 1, 'a': {'c': 2}, 'd': 3})\n\t        {'a.b': 1, 'a.c': 2, 'd': 3}\n\t        >>> flatten({'a.b': {'c': 1}, 'a': {'b.d': 2}, 'a.e': {'f.g': 3}})\n", "        {'a.b.c': 1, 'a.b.d': 2, 'a.e.f.g': 3}\n\t        >>> flatten({'a.b': 1, 'a': {'b': 1}})\n\t        ValueError: duplicated key 'a.b'\n\t        >>> flatten({'a.b': 1, 'a': {'c': {}}, 'a.c': 3})\n\t        {'a.b': 1, 'a.c': 3}\n\t    \"\"\"\n\t    flat_dict = _flatten(in_dict, reducer=\"dot\")\n\t    return flat_dict\n\tdef unflatten(flat_dict: Dict[str, Any]) -> Dict[str, Any]:\n\t    \"\"\"Unflatten a flat dict then return it.\n", "    Parameters\n\t    ----------\n\t    flat_dict : Dict[str, Any]\n\t        The dict to unflatten. Must be a fully flat dict (depth of 1 with keys\n\t        separated by dots).\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If flat_dict is not flat and then found conflicts.\n\t    Returns\n", "    -------\n\t    unflat_dict : Dict[str, Any]\n\t        The output nested dict.\n\t    Examples\n\t    --------\n\t    ::\n\t        >>> unflatten({'a.b': 1, 'a.c': 2, 'c': 3})\n\t        {'a': {'b': 1, 'c': 2}, 'c': 3}\n\t        >>> unflatten({'a.b': 1, 'a': {'c': 2}})\n\t        ValueError: duplicated key 'a'\n", "        The dict must be flatten before calling unflatten function.\n\t    \"\"\"\n\t    try:\n\t        unflat_dict = _unflatten(flat_dict, splitter=\"dot\")\n\t    except ValueError as exc:\n\t        raise ValueError(\n\t            \"The dict must be flatten before calling unflatten function.\"\n\t        ) from exc\n\t    return unflat_dict\n\tdef clean_pre_flat(in_dict: Dict[str, Any], priority: str) -> Dict[str, Any]:\n", "    \"\"\"Remove keys in input dict that may cause conflicts when flattening.\n\t    Parameters\n\t    ----------\n\t    in_dict : Dict[str, Any]\n\t        The dict to clean. It must be the union of a fully flat dict\n\t        (no nested dict i values) and a fully nested dict (without dots in keys).\n\t        See warning section below.\n\t    priority: str\n\t        One of 'flat' or 'unflat', 'error'.\n\t        If 'flat', keys with dots at the root like ``{'a.b': ...}`` (flat keys) have\n", "        priority over nested keys like ``{'a': {'b': ...}}`` when there are conflicts.\n\t        If 'unflat', nested keys have priority over flat keys when there are conflicts.\n\t        If 'error', raise an error when there are conflicts.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If priority is not one of 'flat', 'unflat' or 'error'.\n\t    Returns\n\t    -------\n\t    Dict[str, Any]\n", "        The cleansed dict.\n\t    Warning\n\t    -------\n\t        * No flat key can contain a dict. Then, dicts like ``{'a.b': {'c': 1}}``\n\t          are not supported.\n\t        * All the keys that contain dots (the flat keys) must be at the root.\n\t          Then, dicts like ``{a: {'b.c': 1}}`` are not supported.\n\t        * To summarize, the dict must contain only fully flat dicts\n\t          and/or fully nested dicts.\n\t    Examples\n", "    --------\n\t    ::\n\t        >>> clean_pre_flat({'a.b': 1, 'a': {'b': 2}, 'c': 3}, priority='flat')\n\t        {'a.b': 1, 'c': 3}\n\t        >>> clean_pre_flat({'a.b': 1, 'a': {'b': 2}, 'c': 3}, priority='unflat')\n\t        {'a': {'b': 2}, 'c': 3}\n\t        >>> clean_pre_flat({'a.b': 1, 'a': {'b': 2}, 'c': 3}, priority='error')\n\t        ValueError: duplicated key 'a.b'\n\t    \"\"\"\n\t    if priority in (\"flat\", \"unflat\"):\n", "        # Check that there are no conflicts\n\t        flat_part = dict(filter(lambda items: \".\" in items[0], in_dict.items()))\n\t        unflat_part = dict(filter(lambda items: \".\" not in items[0], in_dict.items()))\n\t        unflat_part_flat = flatten(unflat_part)\n\t        if priority == \"unflat\":\n\t            for key in flat_part:\n\t                if key in unflat_part_flat:\n\t                    _del_key(in_dict, key, keep_flat=False, keep_unflat=True)\n\t        else:\n\t            for key in unflat_part_flat:\n", "                if key in flat_part:\n\t                    _del_key(in_dict, key, keep_flat=True, keep_unflat=False)\n\t    elif priority == \"error\":\n\t        flatten(in_dict)  # Will raise an error if there are conflicts\n\t    else:\n\t        raise ValueError(\n\t            \"priority argument must be one of 'flat', 'unflat' or 'error' but \"\n\t            f\"found '{priority}'.\"\n\t        )\n\t    return in_dict\n", "def _del_key(\n\t    in_dict: Dict[str, Any],\n\t    flat_key: str,\n\t    *,\n\t    keep_flat: bool = False,\n\t    keep_unflat: bool = False,\n\t) -> None:\n\t    \"\"\"Remove in place a value in dict corresponding to a flat key (e.g. 'a.b.c').\n\t    Parameters\n\t    ----------\n", "    in_dict : Dict[str, Any]\n\t        The dict to clean. It must be the union of a fully flat dict\n\t        (no nested dict i values) and a fully nested dict (without dots in keys).\n\t        See warning section below.\n\t    flat_key: str\n\t        The flat key to remove. E.g. 'a.b.c'.\n\t    keep_flat: bool, optional\n\t        If True, keep the flat key in the dict. By default False.\n\t    keep_unflat: bool, optional\n\t        If True, keep the unflat key in the dict. By default False.\n", "    Raises\n\t    ------\n\t    ValueError\n\t        If the key is not found in the dict.\n\t    Warning\n\t    -------\n\t        * No flat key can contain a dict. Then, dicts like ``{'a.b': {'c': 1}}``\n\t          are not supported.\n\t        * All the keys that contain dots (the flat keys) must be at the root.\n\t          Then, dicts like ``{a: {'b.c': 1}}`` are not supported.\n", "        * To summarize, the dict must contain only fully flat dicts\n\t          and fully nested dicts.\n\t    Examples\n\t    --------\n\t    ::\n\t        >>> in_dict = {'a': {'b': {'c': 1}, 'd': 2}, 'a.b.c': 4}\n\t        >>> _del_key(in_dict, 'a.b.c'); in_dict\n\t        {'a': {'d': 2}}\n\t        >>> _del_key(in_dict, 'a.b.c', keep_flat=True); in_dict\n\t        {'a': {'d': 2}, 'a.b.c': 4}\n", "        >>> _del_key(in_dict, 'a.b.c', keep_unflat=True); in_dict\n\t        {'a': {'b': {'c': 1}, 'd': 2}}\n\t        >>> _del_key(in_dict, 'a.b.z')\n\t        ValueError: Key 'a.b.z' not found in dict.\n\t        >>> _del_key(in_dict, 'a.z.c')\n\t        ValueError: Key 'a.z.c' not found in dict.\n\t    \"\"\"\n\t    found_key = False\n\t    if not keep_flat and flat_key in in_dict:\n\t        # Remove flat_key if it exists at the root\n", "        found_key = True\n\t        del in_dict[flat_key]\n\t    def recursive_del_key(\n\t        in_dict: Dict[str, Any], key: str, *, found_key: bool\n\t    ) -> bool:\n\t        first_key, *other_keys = key.split(\".\", 1)\n\t        if other_keys:\n\t            if first_key in in_dict:\n\t                # Delete key in sub-dict\n\t                new_key = recursive_del_key(\n", "                    in_dict[first_key],\n\t                    \".\".join(other_keys),\n\t                    found_key=found_key,\n\t                )\n\t                found_key = found_key or new_key\n\t                # Remove if empty\n\t                if in_dict[first_key] == {}:\n\t                    del in_dict[first_key]\n\t            else:\n\t                # No key found, return input found_key\n", "                return found_key\n\t        else:\n\t            if first_key in in_dict:\n\t                found_key = True\n\t                del in_dict[first_key]\n\t            else:\n\t                # No key found, return input found_key\n\t                return found_key\n\t        return found_key\n\t    if not keep_unflat:\n", "        # Remove flat_key if it exists in a nested dict\n\t        found_key = recursive_del_key(in_dict, flat_key, found_key=found_key)\n\t    # Raise error if key not found\n\t    if not found_key:\n\t        raise ValueError(f\"Key '{flat_key}' not found in dict.\")\n\tdef save_dict(in_dict: Dict[str, Any], path: str) -> None:\n\t    \"\"\"Save a dict to a yaml file (with yaml.dump).\n\t    Parameters\n\t    ----------\n\t    in_dict : Dict[str, Any]\n", "        The dict to save.\n\t    path : str\n\t        The path to the yaml file to save the dict.\n\t    \"\"\"\n\t    dir_path = os.path.dirname(path)\n\t    os.makedirs(dir_path, exist_ok=True)\n\t    with open(path, \"w\", encoding=\"utf-8\") as cfg_file:\n\t        yaml.dump(in_dict, cfg_file, default_flow_style=False)\n\tdef load_dict(path: str) -> Dict[str, Any]:\n\t    \"\"\"Load dict from a yaml file path.\n", "     Support multiple files in the same document and yaml tags.\n\t    Parameters\n\t    ----------\n\t    path : str\n\t        The path to the file to load the dict.\n\t    Returns\n\t    -------\n\t    out_dict : Dict[str, Any]\n\t        The nested (unflatten) loaded dict.\n\t    Note\n", "    ----\n\t        * If multiple yaml files are in the same document, they are merged\n\t        from the first to the last.\n\t        * To use multiple yaml tags, separate them with \"@\". E.g. ``!tag1@tag2``.\n\t        * You can combine any number of yaml and cliconfig tags together.\n\t    \"\"\"\n\t    with open(path, \"r\", encoding=\"utf-8\") as cfg_file:\n\t        file_dicts = yaml.load_all(cfg_file, Loader=get_yaml_loader())\n\t        out_dict: Dict[str, Any] = {}\n\t        for file_dict in file_dicts:\n", "            new_dict, _ = insert_tags(file_dict)\n\t            out_dict = merge_flat(out_dict, new_dict, allow_new_keys=True)\n\t    return unflatten(out_dict)\n\tdef show_dict(in_dict: Dict[str, Any], start_indent: int = 0) -> None:\n\t    \"\"\"Show the input dict in a pretty way.\n\t    The config dict is automatically unflattened before printing.\n\t    Parameters\n\t    ----------\n\t    in_dict : Dict[str, Any]\n\t        The dict to show.\n", "    start_indent : int, optional\n\t        The number of starting tab indent (4 spaces), by default 0.\n\t    \"\"\"\n\t    def pretty_print(in_dict: Dict[str, Any], indent: int) -> None:\n\t        \"\"\"Pretty print the dict recursively.\"\"\"\n\t        for key, value in in_dict.items():\n\t            print(f\"{'    ' * indent}{key}: \", end=\"\")\n\t            if isinstance(value, dict):\n\t                print()\n\t                pretty_print(value, indent + 1)\n", "            elif isinstance(value, str):\n\t                print(f\"'{value}'\")\n\t            else:\n\t                print(value)\n\t    pretty_print(unflatten(in_dict), start_indent)\n"]}
{"filename": "cliconfig/cli_parser.py", "chunked_list": ["\"\"\"Parser for CLI commands.\"\"\"\n\tfrom typing import Any, Dict, List, Tuple\n\timport yaml\n\tdef parse_cli(sys_argv: List[str]) -> Tuple[List[str], Dict[str, Any]]:\n\t    \"\"\"Parser for CLI commands.\n\t    Return list of config path(s) that are detected with ``--config`` followed\n\t    by a space. If multiple paths are provided, they must be separated by a comma\n\t    and no space around the comma. It also possible to provide a list of paths.\n\t    Return also a dictionary of parameters from CLI detected with ``--<key>=<value>``\n\t    (with \"=\" and without spaces around). If no value is provided,\n", "    it is True by default (like for a flag).\n\t    Parameters\n\t    ----------\n\t    sys_argv : List[str]\n\t        List of arguments from sys.argv.\n\t    Raises\n\t    ------\n\t    Value Error\n\t        If the ``--config`` argument (with space) is used more than once.\n\t    Returns\n", "    -------\n\t    config_paths : List[str]\n\t        List of paths to config files to merge.\n\t    cli_params_dict : Dict[str, Any]\n\t        Dictionary of parameters from CLI.\n\t    Examples\n\t    --------\n\t    .. code-block:: text\n\t        $ python my_script.py --config config.yaml --foo.bar.param=[1, 2, 3]\n\t    Will be parsed as ``config_paths=['config.yaml']``\n", "    and ``cli_params={'foo.bar.param': [1, 2, 3]}``.\n\t    It is equivalent to: ``{'foo': {'bar': {'param': [1, 2, 3]}}`` for\n\t    :func:`.merge_flat` and :func:`.make_config`.\n\t    \"\"\"\n\t    cli_params_dict: Dict[str, Any] = {}\n\t    config_paths: List[str] = []\n\t    i = 0\n\t    while i < len(sys_argv):\n\t        elem = sys_argv[i]\n\t        if elem == \"--config\":\n", "            if config_paths:\n\t                raise ValueError(\n\t                    \"Only one '--config ' argument is allowed in CLI (used for \"\n\t                    \"config merging).\"\n\t                )\n\t            configs = yaml.safe_load(sys_argv[i + 1])\n\t            if isinstance(configs, list):\n\t                config_paths = configs\n\t            if isinstance(configs, str):\n\t                config_paths = sys_argv[i + 1].split(\",\")\n", "            i += 2\n\t        elif elem.startswith(\"--\"):\n\t            splits = elem.split(\"=\", maxsplit=1)\n\t            if len(splits) == 2:\n\t                key, value_str = splits\n\t            else:\n\t                key = splits[0]\n\t                # If no value is provided, use True because it could\n\t                # be seen as a flag\n\t                value_str = \"true\"\n", "            key = key[2:]\n\t            value = yaml.safe_load(value_str)\n\t            cli_params_dict[key] = value\n\t            i += 1\n\t        else:  # Not a config parameter\n\t            i += 1\n\t    return config_paths, cli_params_dict\n"]}
{"filename": "cliconfig/base.py", "chunked_list": ["\"\"\"Base classes of Config object.\"\"\"\n\tfrom typing import TYPE_CHECKING, Any, Dict, List, Optional\n\t# Imports Processing for mypy type checking only\n\tif TYPE_CHECKING:\n\t    from cliconfig.processing.base import Processing\n\tclass Config:\n\t    \"\"\"Class for configuration.\n\t    Config object contain the config dict and the processing list\n\t    and no methods except ``__init__``, ``__repr__``, ``__eq__``,\n\t    ``__getattribute__``, ``__setattr__`` and ``__delattr__``.\n", "    The Config objects are mutable and not hashable.\n\t    Parameters\n\t    ----------\n\t    config_dict : Dict[str, Any]\n\t        The config dict.\n\t    process_list : Optional[List[Processing]], optional\n\t        The list of Processing objects. If None, an empty list is used.\n\t        The default is None.\n\t    \"\"\"\n\t    def __init__(\n", "        self,\n\t        config_dict: Dict[str, Any],\n\t        process_list: Optional[List[\"Processing\"]] = None,\n\t    ) -> None:\n\t        self.dict = config_dict\n\t        self.process_list = process_list if process_list else []\n\t    def __repr__(self) -> str:\n\t        \"\"\"Representation of Config object.\"\"\"\n\t        process_classes = [process.__class__.__name__ for process in self.process_list]\n\t        return f\"Config({self.dict}, {process_classes})\"\n", "    def __eq__(self, other: Any) -> bool:\n\t        \"\"\"Equality operator.\n\t        Two Config objects are equal if their dicts are equal and their\n\t        lists of Processing objects are equal (order doesn't matter).\n\t        \"\"\"\n\t        if (\n\t            isinstance(other, Config)\n\t            and self.dict == other.dict\n\t            and len(self.process_list) == len(other.process_list)\n\t        ):\n", "            equal = True\n\t            for processing in self.process_list:\n\t                equal = equal and processing in other.process_list\n\t            for processing in other.process_list:\n\t                equal = equal and processing in self.process_list\n\t            return equal\n\t        return False\n\t    def __getattribute__(self, __name: str) -> Any:\n\t        \"\"\"Get attribute, sub-configuration or parameter.\n\t        The dict should be nested (unflattened). If it is not the case,\n", "        you can apply :func:`dict_routines.flatten` on ``config.dict``\n\t        to unflatten it.\n\t        \"\"\"\n\t        if __name in [\"dict\", \"process_list\"]:\n\t            return super().__getattribute__(__name)\n\t        if __name not in self.dict:\n\t            keys = \", \".join(self.dict.keys())\n\t            raise AttributeError(  # pylint: disable=raise-missing-from\n\t                f\"Config has no attribute '{__name}'. Available keys are: {keys}.\"\n\t            )\n", "        if isinstance(self.dict[__name], dict):\n\t            # If the attribute is a dict, return a Config object\n\t            # so that we can access the nested keys with multiple dots\n\t            return Config(self.dict[__name], process_list=self.process_list)\n\t        return self.dict[__name]\n\t    def __setattr__(self, __name: str, value: Any) -> None:\n\t        \"\"\"Set attribute, sub-configuration or parameter.\n\t        The dict should be nested (unflattened). If it is not the case,\n\t        you can apply :func:`dict_routines.flatten` on ``config.dict``\n\t        to unflatten it.\n", "        \"\"\"\n\t        if __name in [\"dict\", \"process_list\"]:\n\t            super().__setattr__(__name, value)\n\t        else:\n\t            self.dict[__name] = value\n\t    def __delattr__(self, __name: str) -> None:\n\t        \"\"\"Delete attribute, sub-configuration or parameter.\n\t        The dict should be nested (unflattened). If it is not the case,\n\t        you can apply :func:`dict_routines.flatten` on ``config.dict``\n\t        to unflatten it.\n", "        \"\"\"\n\t        if __name in [\"dict\", \"process_list\"]:\n\t            super().__delattr__(__name)\n\t        else:\n\t            del self.dict[__name]\n"]}
{"filename": "cliconfig/config_routines.py", "chunked_list": ["\"\"\"Functions to manipulate config as dict with yaml files and CLI.\"\"\"\n\timport sys\n\tfrom typing import Any, Dict, List, Optional\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.cli_parser import parse_cli\n\tfrom cliconfig.dict_routines import flatten, show_dict, unflatten\n\tfrom cliconfig.process_routines import (\n\t    end_build_processing,\n\t    load_processing,\n\t    merge_flat_paths_processing,\n", "    merge_flat_processing,\n\t    save_processing,\n\t)\n\tfrom cliconfig.processing.base import Processing\n\tfrom cliconfig.processing.builtin import DefaultProcessings\n\tfrom cliconfig.tag_routines import clean_all_tags\n\tdef make_config(\n\t    *default_config_paths: str,\n\t    process_list: Optional[List[Processing]] = None,\n\t    add_default_processing: bool = True,\n", "    fallback: str = \"\",\n\t    no_cli: bool = False,\n\t) -> Config:\n\t    r\"\"\"Make a config from default config(s) and CLI argument(s) with processing.\n\t    The function uses the CLI Config routines :func:`.parse_cli` to parse the CLI\n\t    arguments and merge them with :func:`.merge_flat_paths_processing`, applying\n\t    the pre-merge and post-merge processing functions on each merge.\n\t    Parameters\n\t    ----------\n\t    default_config_paths : Tuple[str]\n", "        Paths to default configs. They are merged in order and new keys\n\t        are allowed.\n\t    process_list: Optional[List[Processing]], optional\n\t        The list of processing to apply during each merge. None for empty list.\n\t        By default None.\n\t    add_default_processing : bool, optional\n\t        If add_default_processing is True, the default processings\n\t        (found on :class:`.DefaultProcessings`) are added to the list of\n\t        processings. By default True.\n\t    fallback : str, optional\n", "        Path of the configuration to use if no additional config is provided\n\t        with ``--config``. No fallback config if empty string (default),\n\t        in that case, the config is the default configs plus the CLI arguments.\n\t    no_cli : bool, optional\n\t        If True, the CLI arguments are not parsed and the config is only\n\t        built from the default_config_paths in input and the\n\t        fallback argument is ignored. By default False.\n\t    Raises\n\t    ------\n\t    ValueError\n", "        If additional configs have new keys that are not in default configs.\n\t    Returns\n\t    -------\n\t    config : Config\n\t        The nested built config. Contains the config dict (config.dict) and\n\t        the processing list (config.process_list) which can be used to apply\n\t        further processing routines.\n\t    Note\n\t    ----\n\t        Setting additional arguments from CLI that are not in default configs\n", "        does NOT raise an error but only a warning. This ensures the compatibility\n\t        with other CLI usage (e.g notebook, argparse, etc.)\n\t    Examples\n\t    --------\n\t    ::\n\t        # main.py\n\t        config = make_config('data.yaml', 'model.yaml', 'train.yaml')\n\t    .. code-block:: text\n\t        $ python main.py -- config [bestmodel.yaml,mydata.yaml] \\\n\t              --architecture.layers.hidden_dim=64\n", "    \"\"\"\n\t    # Create the processing list\n\t    process_list_: List[Processing] = [] if process_list is None else process_list\n\t    if add_default_processing:\n\t        process_list_ += DefaultProcessings().list\n\t    config = Config({}, process_list_)\n\t    if no_cli:\n\t        additional_config_paths: List[str] = []\n\t        cli_params_dict: Dict[str, Any] = {}\n\t    else:\n", "        additional_config_paths, cli_params_dict = parse_cli(sys.argv)\n\t        if not additional_config_paths and fallback:\n\t            # Add fallback config\n\t            additional_config_paths = [fallback]\n\t    # Merge default configs and additional configs\n\t    for i, paths in enumerate([default_config_paths, additional_config_paths]):\n\t        # Allow new keys for default configs only\n\t        allow_new_keys = i == 0\n\t        for path in paths:\n\t            config = merge_flat_paths_processing(\n", "                config,\n\t                path,\n\t                allow_new_keys=allow_new_keys,\n\t                preprocess_first=False,  # Already processed\n\t            )\n\t    # Allow new keys for CLI parameters but do not merge them and raise\n\t    # warning.\n\t    cli_params_dict = flatten(cli_params_dict)\n\t    new_keys, keys = [], list(cli_params_dict.keys())\n\t    for key in keys:\n", "        if clean_all_tags(key) not in config.dict:\n\t            # New key: delete it\n\t            new_keys.append(clean_all_tags(key))\n\t            del cli_params_dict[key]\n\t    if new_keys:\n\t        new_keys_message = \"  - \" + \"\\n  - \".join(new_keys)\n\t        print(\n\t            \"[CONFIG] Warning: New keys found in CLI parameters \"\n\t            f\"that will not be merged:\\n{new_keys_message}\"\n\t        )\n", "    # Merge CLI parameters\n\t    cli_params_config = Config(cli_params_dict, [])\n\t    config = merge_flat_processing(\n\t        config, cli_params_config, allow_new_keys=False, preprocess_first=False\n\t    )\n\t    print(\n\t        f\"[CONFIG] Info: Merged {len(default_config_paths)} default config(s), \"\n\t        f\"{len(additional_config_paths)} additional config(s) and \"\n\t        f\"{len(cli_params_dict)} CLI parameter(s).\"\n\t    )\n", "    # Apply end-build processing\n\t    config = end_build_processing(config)\n\t    # Unflatten the config dict\n\t    config.dict = unflatten(config.dict)\n\t    return config\n\tdef load_config(\n\t    path: str,\n\t    default_config_paths: Optional[List[str]] = None,\n\t    process_list: Optional[List[Processing]] = None,\n\t    *,\n", "    add_default_processing: bool = True,\n\t) -> Config:\n\t    \"\"\"Load config from a file and merge into optional default configs.\n\t    First merge the default configs together (if any), then load the config\n\t    from path, apply the post-load processing, and finally merge the loaded\n\t    config.\n\t    Parameters\n\t    ----------\n\t    path : str\n\t        The path to the file to load the configuration.\n", "    default_config_paths : Optional[List[str]], optional\n\t        Paths to default configs. They are merged in order, new keys are allowed.\n\t        Then, the loaded config is merged into the result. None for no default configs.\n\t        By default None.\n\t    process_list: Optional[List[Processing]]\n\t        The list of processing to apply after loading and for the merges.\n\t        If None, no processing is applied. By default None.\n\t    add_default_processing : bool, optional\n\t        If add_default_processing is True, the default processings\n\t        (found on :class:`.DefaultProcessings`) are added to the list of\n", "        processings. By default True.\n\t    Returns\n\t    -------\n\t    config: Dict[str, Any]\n\t        The nested loaded config. Contains the config dict (config.dict) and\n\t        the processing list (config.process_list) which can be used to apply\n\t        further processing routines.\n\t    Note\n\t    ----\n\t        If default configs are provided, the function does not allow new keys\n", "        for the loaded config. This is for helping the user to see how to\n\t        adapt the config file if the default configs have changed.\n\t    \"\"\"\n\t    # Crate process_list\n\t    process_list_: List[Processing] = [] if process_list is None else process_list\n\t    if add_default_processing:\n\t        process_list_ += DefaultProcessings().list\n\t    config = Config({}, process_list_)\n\t    if default_config_paths:\n\t        for config_path in default_config_paths:\n", "            config = merge_flat_paths_processing(\n\t                config,\n\t                config_path,\n\t                allow_new_keys=True,\n\t                preprocess_first=False,  # Already processed\n\t            )\n\t    loaded_config = load_processing(path, config.process_list)\n\t    # Update the config list from loaded_config in config\n\t    config.process_list = loaded_config.process_list\n\t    # Merge the loaded config into the config and\n", "    # disallow new keys for loaded config\n\t    # if default configs are provided\n\t    config = merge_flat_processing(\n\t        config,\n\t        loaded_config,\n\t        allow_new_keys=default_config_paths is None,\n\t        preprocess_first=False,\n\t    )\n\t    # Apply end-build processing\n\t    config = end_build_processing(config)\n", "    # Unflatten the config\n\t    config.dict = unflatten(config.dict)\n\t    return config\n\tdef save_config(config: Config, path: str) -> None:\n\t    \"\"\"Save a config and apply pre-save processing before saving.\n\t    Alias for :func:`.save_processing`.\n\t    Parameters\n\t    ----------\n\t    config : Dict[str, Any]\n\t        The config to save.\n", "    path : str\n\t        The path to the yaml file to save the dict.\n\t    \"\"\"\n\t    save_processing(config, path)\n\tdef show_config(config: Config) -> None:\n\t    \"\"\"Show the config dict in a pretty way.\n\t    The config dict is automatically unflattened before printing.\n\t    Parameters\n\t    ----------\n\t    config : Config\n", "        The config to show.\n\t    \"\"\"\n\t    print(\"Config:\")\n\t    show_dict(config.dict, start_indent=1)\n"]}
{"filename": "cliconfig/tag_routines.py", "chunked_list": ["\"\"\"Routines to manipulate the tags on the keys of a dict.\n\tUsed by the processing functions.\n\t\"\"\"\n\timport copy\n\timport re\n\tfrom typing import Any, Dict, List, Tuple\n\tdef clean_tag(flat_key: str, tag_name: str) -> str:\n\t    \"\"\"Clean a tag from a flat key.\n\t    It removes all occurrences of the tag with the exact name.\n\t    Parameters\n", "    ----------\n\t    flat_key : str\n\t        The flat key to clean.\n\t    tag_name : str\n\t        The name of the tag to remove, with or without the '@' prefix.\n\t    Returns\n\t    -------\n\t    flat_key : str\n\t        The cleaned flat key.\n\t    Note\n", "    ----\n\t        ``tag_name`` is supposed to be the exact name of the tag.\n\t    Examples\n\t    --------\n\t    ::\n\t        >>> clean_tag('abc@tag.def@tag_2.ghi@tag', 'tag')\n\t        abc.def@tag_2.ghi\n\t    \"\"\"\n\t    if tag_name[0] == \"@\":\n\t        tag_name = tag_name[1:]\n", "    # Replace \"@tag@other_tag\" by \"@other_tag\"\n\t    parts = flat_key.split(f\"@{tag_name}@\")\n\t    flat_key = \"@\".join(parts)\n\t    # Replace \"@tag.\" by \".\"\n\t    parts = flat_key.split(f\"@{tag_name}.\")\n\t    flat_key = \".\".join(parts)\n\t    # Remove \"@tag\" at the end of the string\n\t    if flat_key.endswith(f\"@{tag_name}\"):\n\t        flat_key = flat_key[: -len(f\"@{tag_name}\")]\n\t    return flat_key\n", "def clean_all_tags(flat_key: str) -> str:\n\t    \"\"\"Clean all tags from a flat key.\n\t    Parameters\n\t    ----------\n\t    flat_key : str\n\t        The flat key to clean.\n\t    Returns\n\t    -------\n\t    flat_key : str\n\t        The cleaned flat key.\n", "    \"\"\"\n\t    list_keys = flat_key.split(\".\")\n\t    for i, key in enumerate(list_keys):\n\t        key = re.sub(r\"@.*\", \"\", key)\n\t        list_keys[i] = key\n\t    flat_key = \".\".join(list_keys)\n\t    return flat_key\n\tdef dict_clean_tags(flat_dict: Dict[str, Any]) -> Tuple[Dict[str, Any], List[str]]:\n\t    \"\"\"Clean a dict from all tags and return the list of keys with tags.\n\t    Parameters\n", "    ----------\n\t    flat_dict : Dict[str, Any]\n\t        The flat dict to clean.\n\t    Returns\n\t    -------\n\t    clean_dict : Dict[str, Any]\n\t        The cleaned flat dict without tags in the keys.\n\t    tagged_keys : List[str]\n\t        The list of keys with tags that have been cleaned.\n\t    \"\"\"\n", "    items = list(flat_dict.items())\n\t    clean_dict = copy.deepcopy(flat_dict)\n\t    tagged_keys = []\n\t    for key, value in items:\n\t        if \"@\" in key:\n\t            del clean_dict[key]\n\t            clean_dict[clean_all_tags(key)] = value\n\t            tagged_keys.append(key)\n\t    return clean_dict, tagged_keys\n\tdef is_tag_in(flat_key: str, tag_name: str, *, full_key: bool = False) -> bool:\n", "    \"\"\"Check if a tag is in a flat key.\n\t    The tag name must be the exact name, with or without the \"@\".\n\t    It supports the case where there are other tags that are prefixes\n\t    or suffixes of the considered tag.\n\t    Parameters\n\t    ----------\n\t    flat_key : str\n\t        The flat key to check.\n\t    tag_name : str\n\t        The name of the tag to check, with or without the '@' prefix.\n", "    full_key : bool, optional\n\t        If True, check for the full key. If False, check for the last part of\n\t        the flat key (after the last dot) that correspond to the parameter name.\n\t        By default, False.\n\t    Returns\n\t    -------\n\t    bool\n\t        True if the tag is in the flat key, False otherwise.\n\t    \"\"\"\n\t    if tag_name[0] == \"@\":\n", "        tag_name = tag_name[1:]\n\t    if not full_key:\n\t        flat_key = flat_key.split(\".\")[-1]\n\t    is_in = (\n\t        flat_key.endswith(f\"@{tag_name}\")\n\t        or f\"@{tag_name}@\" in flat_key\n\t        or f\"@{tag_name}.\" in flat_key\n\t    )\n\t    return is_in\n"]}
{"filename": "cliconfig/__init__.py", "chunked_list": ["\"\"\"CLI Config: build your configuration from CLI by merging with processing.\n\tCopyright © 2023  Valentin Goldité\n\t    This program is free software: you can redistribute it and/or modify\n\t    it under the terms of the MIT License.\n\t    This program is distributed in the hope that it will be useful,\n\t    but WITHOUT ANY WARRANTY; without even the implied warranty of\n\t    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\t    This project is free to use for COMMERCIAL USE, MODIFICATION,\n\t    DISTRIBUTION and PRIVATE USE as long as the original license is\n\t    include as well as this copy right notice.\n", "\"\"\"\n\tfrom cliconfig._version import __version__, __version_tuple__\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.config_routines import load_config, make_config, save_config, show_config\n\tfrom cliconfig.process_routines import (\n\t    merge_flat_paths_processing,\n\t    merge_flat_processing,\n\t)\n\tfrom cliconfig.processing.base import Processing\n\tfrom cliconfig.processing.builtin import DefaultProcessings\n", "from cliconfig.processing.create import (\n\t    create_processing_keep_property,\n\t    create_processing_value,\n\t)\n\t__all__ = [\n\t    \"__version__\",\n\t    \"__version_tuple__\",\n\t    \"Config\",\n\t    \"DefaultProcessings\",\n\t    \"Processing\",\n", "    \"create_processing_keep_property\",\n\t    \"create_processing_value\",\n\t    \"make_config\",\n\t    \"load_config\",\n\t    \"merge_flat_paths_processing\",\n\t    \"merge_flat_processing\",\n\t    \"save_config\",\n\t    \"show_config\",\n\t]\n"]}
{"filename": "cliconfig/process_routines.py", "chunked_list": ["\"\"\"Routines to manipulate dictionaries with processing.\n\tUsed by :mod:`.config_routines`.\n\t\"\"\"\n\tfrom typing import List, Optional, Union\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.dict_routines import (\n\t    _flat_before_merge,\n\t    flatten,\n\t    load_dict,\n\t    merge_flat,\n", "    save_dict,\n\t    unflatten,\n\t)\n\tfrom cliconfig.processing.base import Processing\n\tdef merge_flat_processing(\n\t    config1: Config,\n\t    config2: Config,\n\t    *,\n\t    allow_new_keys: bool = True,\n\t    preprocess_first: bool = True,\n", "    preprocess_second: bool = True,\n\t    postprocess: bool = True,\n\t) -> Config:\n\t    \"\"\"Flatten, merge config2 into config1 and apply pre and post processing.\n\t    Work even if the config dicts have a mix of nested and flat dictionaries.\n\t    If both arguments are configs, the process lists are merged before applying\n\t    the processing. The duplicate processings (with same internal variables)\n\t    are removed.\n\t    Parameters\n\t    ----------\n", "    config1 : Config\n\t        The first config.\n\t    config2 : Config\n\t        The second dict to merge into config1.\n\t    allow_new_keys : bool, optional\n\t        If True, new keys (that are not in config1) are allowed in config2.\n\t        Otherwise, it raises an error. By default True.\n\t    preprocess_first : bool, optional\n\t        If True, apply pre-merge processing to config1. By default True.\n\t    preprocess_second : bool, optional\n", "        If True, apply pre-merge processing to config2. By default True.\n\t    postprocess : bool, optional\n\t        If True, apply post-merge processing to the merged config. By default True.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If allow_new_keys is False and config2 has new keys that are not in config1.\n\t    ValueError\n\t        If there are conflicting keys when flatten one of the dicts.\n\t    Returns\n", "    -------\n\t    flat_config : Config\n\t        The merged flat config.\n\t    \"\"\"\n\t    # Flatten the dictionaries\n\t    config1.dict, config2.dict = _flat_before_merge(config1.dict, config2.dict)\n\t    # Get the process list of the merge\n\t    process_list = config1.process_list\n\t    for process in config2.process_list:\n\t        # NOTE 2 processings are equal if they are the same class and add the same\n", "        # attributes.\n\t        if process not in process_list:\n\t            process_list.append(process)\n\t    # Apply the pre-merge processing\n\t    if preprocess_first:\n\t        config1.process_list = process_list\n\t        pre_order_list = sorted(process_list, key=lambda x: x.premerge_order)\n\t        for processing in pre_order_list:\n\t            config1 = processing.premerge(config1)\n\t        process_list = config1.process_list\n", "    if preprocess_second:\n\t        config2.process_list = process_list\n\t        pre_order_list = sorted(process_list, key=lambda x: x.premerge_order)\n\t        for processing in pre_order_list:\n\t            config2 = processing.premerge(config2)\n\t        process_list = config2.process_list\n\t    # Merge the dictionaries\n\t    flat_dict = merge_flat(config1.dict, config2.dict, allow_new_keys=allow_new_keys)\n\t    # Create the new config\n\t    flat_config = Config(flat_dict, process_list)\n", "    # Apply the postmerge processing\n\t    if postprocess:\n\t        post_order_list = sorted(process_list, key=lambda x: x.postmerge_order)\n\t        for processing in post_order_list:\n\t            flat_config = processing.postmerge(flat_config)\n\t    return flat_config\n\tdef merge_flat_paths_processing(\n\t    config_or_path1: Union[str, Config],\n\t    config_or_path2: Union[str, Config],\n\t    *,\n", "    additional_process: Optional[List[Processing]] = None,\n\t    allow_new_keys: bool = True,\n\t    preprocess_first: bool = True,\n\t    preprocess_second: bool = True,\n\t    postprocess: bool = True,\n\t) -> Config:\n\t    \"\"\"Flatten, merge and apply processing to two configs or their yaml paths.\n\t    Similar to :func:`merge_flat_processing` but allows to pass configs\n\t    or their yaml paths. Work even if the configs have a mix of nested and flat dicts.\n\t    If both arguments are configs, the process lists are merged before applying\n", "    the processing. The duplicate processings (with same internal variables)\n\t    are removed.\n\t    Parameters\n\t    ----------\n\t    config_or_path1 : Union[str, Config]\n\t        The first config or its path.\n\t    config_or_path2 : Union[str, Config]\n\t        The second config or its path, to merge into first config.\n\t    additional_process : Optional[List[Processing]], optional\n\t        Additional processings to apply to the merged config. It can\n", "        be useful to merge a config from its path while it has some specific\n\t        processings.\n\t    allow_new_keys : bool, optional\n\t        If True, new keys (that are not in config1) are allowed in config2.\n\t        Otherwise, it raises an error. By default True.\n\t    preprocess_first : bool, optional\n\t        If True, apply pre-merge processing to config1. By default True.\n\t    preprocess_second : bool, optional\n\t        If True, apply pre-merge processing to config2. By default True.\n\t    postprocess : bool, optional\n", "        If True, apply post-merge processing to the merged config. By default True.\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If allow_new_keys is False and config2 has new keys that are not in config1.\n\t    ValueError\n\t        If there are conflicting keys when flatten one of the dicts.\n\t    Returns\n\t    -------\n\t    flat_config : Config\n", "        The merged flat config.\n\t    \"\"\"\n\t    configs = []\n\t    for config_or_path in [config_or_path1, config_or_path2]:\n\t        if isinstance(config_or_path, str):\n\t            config_dict = load_dict(config_or_path)\n\t            config = Config(config_dict, [])\n\t        elif isinstance(config_or_path, Config):\n\t            config = config_or_path\n\t        elif isinstance(config_or_path, dict):\n", "            raise ValueError(\n\t                \"config_or_path must be a Config instance or a path to a yaml file \"\n\t                \"but you passed a dict. If you want to use it as a valid input, \"\n\t                \"you should use Config(<input dict>, []) instead.\"\n\t            )\n\t        else:\n\t            raise ValueError(\n\t                \"config_or_path must be a Config instance or a path to a yaml file.\"\n\t            )\n\t        configs.append(config)\n", "    config1, config2 = configs[0], configs[1]\n\t    if additional_process is not None:\n\t        config1.process_list.extend(additional_process)\n\t        config2.process_list.extend(additional_process)\n\t    flat_config = merge_flat_processing(\n\t        config1,\n\t        config2,\n\t        allow_new_keys=allow_new_keys,\n\t        preprocess_first=preprocess_first,\n\t        preprocess_second=preprocess_second,\n", "        postprocess=postprocess,\n\t    )\n\t    return flat_config\n\tdef save_processing(config: Config, path: str) -> None:\n\t    \"\"\"Save a config and apply pre-save processing before saving.\n\t    Parameters\n\t    ----------\n\t    config : Config\n\t        The config to save.\n\t    path : str\n", "        The path to the yaml file to save the config dict.\n\t    \"\"\"\n\t    config.dict = flatten(config.dict)\n\t    # Get the pre-save order\n\t    order_list = sorted(config.process_list, key=lambda x: x.presave_order)\n\t    # Apply the pre-save processing\n\t    for processing in order_list:\n\t        config = processing.presave(config)\n\t    # Unflatten and save the dict\n\t    config.dict = unflatten(config.dict)\n", "    save_dict(config.dict, path)\n\tdef load_processing(path: str, process_list: List[Processing]) -> Config:\n\t    \"\"\"Load a dict from yaml file path and apply post-load processing.\n\t    Parameters\n\t    ----------\n\t    path : str\n\t        The path to the file to load the dict.\n\t    process_list: List[Processing]\n\t        The list of processing to apply after loading. Only post-load\n\t        processing is applied. The order of the processing is given\n", "        by the postload_order attribute of the processing.\n\t    Returns\n\t    -------\n\t    flat_config : Config\n\t        The loaded flat config.\n\t    \"\"\"\n\t    # Load the dict and flatten it\n\t    out_dict = flatten(load_dict(path))\n\t    flat_config = Config(out_dict, process_list)\n\t    # Get the post-load order\n", "    order_list = sorted(process_list, key=lambda x: x.postload_order)\n\t    # Apply the post-load processing\n\t    for processing in order_list:\n\t        flat_config = processing.postload(flat_config)\n\t    return flat_config\n\tdef end_build_processing(flat_config: Config) -> Config:\n\t    \"\"\"Apply end-build processings to a flat config.\n\t    Parameters\n\t    ----------\n\t    flat_config : Config\n", "        The flat config to apply the end-build processings.\n\t    Returns\n\t    -------\n\t    flat_config : Config\n\t        The flat config after applying the end-build processings.\n\t    \"\"\"\n\t    order_list = sorted(flat_config.process_list, key=lambda x: x.endbuild_order)\n\t    for processing in order_list:\n\t        flat_config = processing.endbuild(flat_config)\n\t    return flat_config\n"]}
{"filename": "cliconfig/processing/base.py", "chunked_list": ["\"\"\"Base class for processing.\n\tUsed to make configuration object and run the routines in :mod:`.process_routines`\n\tand :mod:`.config_routines`.\n\t\"\"\"\n\tfrom cliconfig.base import Config\n\tclass Processing:\n\t    \"\"\"Processing base class.\n\t    Each processing classes contains pre-merge, post-merge, pre-save\n\t    and post-load processing. They are used with routines that apply\n\t    processing in :mod:`.process_routines` and\n", "    :mod:`.config_routines`.\n\t    That are applied in the order defined\n\t    by the order attribute in case of multiple processing.\n\t    \"\"\"\n\t    def __init__(self) -> None:\n\t        self.premerge_order = 0.0\n\t        self.postmerge_order = 0.0\n\t        self.endbuild_order = 0.0\n\t        self.presave_order = 0.0\n\t        self.postload_order = 0.0\n", "    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\n\t        Function applied to the flat config to modify it\n\t        before merging. It takes a flat config and returns a flat config.\n\t        \"\"\"\n\t        return flat_config\n\t    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\n\t        Function applied to the flat config to modify it\n\t        after merging . It takes a flat config and returns a flat config.\n", "        \"\"\"\n\t        return flat_config\n\t    def endbuild(self, flat_config: Config) -> Config:\n\t        \"\"\"End-build processing.\n\t        Function applied to the flat config to modify it at the end of\n\t        a building process (typically :func:`.make_config` or :func:`.load_config`).\n\t        It takes a flat config and returns a flat config.\n\t        \"\"\"\n\t        return flat_config\n\t    def presave(self, flat_config: Config) -> Config:\n", "        \"\"\"Pre-save processing.\n\t        Function applied to the flat config to modify it before\n\t        saving. It takes a flat config and returns a flat config.\n\t        \"\"\"\n\t        return flat_config\n\t    def postload(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-load processing.\n\t        Function applied to the flat config to modify it after\n\t        loading. It takes a flat config and returns a flat config.\n\t        \"\"\"\n", "        return flat_config\n\t    def __eq__(self, __value: object) -> bool:\n\t        \"\"\"Equality operator.\n\t        Two processing are equal if they are the same class and add the same\n\t        attributes (accessed with ``__dict__``).\n\t        \"\"\"\n\t        equal = (\n\t            isinstance(__value, self.__class__) and self.__dict__ == __value.__dict__\n\t        )\n\t        return equal\n"]}
{"filename": "cliconfig/processing/__init__.py", "chunked_list": ["\"\"\"Processing module to apply functions on merge (before and after), save and load.\"\"\"\n\tfrom cliconfig.processing.base import Processing\n\t__all__ = [\"Processing\"]\n"]}
{"filename": "cliconfig/processing/builtin.py", "chunked_list": ["\"\"\"Built-in processing classes.\n\tBuilt-in classes to apply pre-merge, post-merge, pre-save and post-load modifications\n\tto dict with processing routines :mod:`.process_routines`.\n\tThey are the default processing used by the config routines :func:`.load_config`\n\tand :func:`.make_config`.\n\t\"\"\"\n\tfrom typing import Any, Dict, List, Set\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.process_routines import (\n\t    merge_flat_paths_processing,\n", "    merge_flat_processing,\n\t)\n\tfrom cliconfig.processing._type_parser import _isinstance, _parse_type\n\tfrom cliconfig.processing.base import Processing\n\tfrom cliconfig.tag_routines import clean_all_tags, clean_tag, dict_clean_tags, is_tag_in\n\tclass ProcessMerge(Processing):\n\t    \"\"\"Merge dicts just in time with ``@merge_after/_before/_add`` tags.\n\t    Tag your key with ``@merge_after``, ``@merge_before`` or ``@merge_add``\n\t    to load the config corresponding to the value (which is a yaml path) and\n\t    merge it just before or after the current config. The merged dicts will be\n", "    processed with pre-merge but not post-merge to ensure that merged\n\t    configurations are recursively processed with pre-merge before applying a\n\t    post-merge processing. It allows the merged configs to make references to\n\t    each other (typically for copy) even without containing the merge tags\n\t    itself.\n\t    * '@merge_add' merges the dict corresponding to the path by allowing ONLY new keys\n\t      It is a security check when you want to add a dict completely new,\n\t      the typical usage for a default config splitted in several files.\n\t    * '@merge_after' merge the dict corresponding to the path on the current dict\n\t    * '@merge_before' merge the current dict on the dict corresponding to the path\n", "    The processing is a pre-merge processing only and occurs before\n\t    almost all of the other processings.\n\t    Pre-merge order: -20.0\n\t    Examples\n\t    --------\n\t    .. code-block:: yaml\n\t        # config1.yaml\n\t        a:\n\t          b: 1\n\t          b_path@merge_after: dict2.yaml\n", "        # config2.yaml\n\t        a.b: 2\n\t        c_path@merge_add: config3.yaml\n\t        # config3.yaml\n\t        c: 3\n\t    Before merging, the config1 is interpreted as the dict:\n\t    ::\n\t        {'a': {'b': 2, 'b_path': 'config2.yaml'}, 'c_path': 'config3.yaml', 'c': 3}\n\t    If you replace '@merge_after' by '@merge_before', it will be:\n\t    ::\n", "        {'a': {'b': 1, 'b_path': 'config2.yaml'}, 'c_path': 'config3.yaml', 'c': 3}\n\t    Finally, if you replace ``@merge_after`` by ``@merge_add``, it will raises an\n\t    error because the key ``a.b`` already exists in the dict.\n\t    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.premerge_order = -20.0\n\t    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n", "        for flat_key, val in items:\n\t            if is_tag_in(flat_key, \"merge_after\"):\n\t                if not isinstance(val, str) or not val.endswith(\".yaml\"):\n\t                    raise ValueError(\n\t                        \"Key with '@merge_after' tag must be associated \"\n\t                        \"to a string corresponding to a *yaml* file.\"\n\t                        f\"The problem occurs at key: {flat_key}\"\n\t                    )\n\t                # Remove the tag in the dict\n\t                del flat_config.dict[flat_key]\n", "                flat_config.dict[clean_tag(flat_key, \"merge_after\")] = val\n\t                # Merge + process the dicts\n\t                # NOTE: we allow new keys with security because the merge\n\t                # following this pre-merge will avoid the creation of\n\t                # new keys if needed.\n\t                flat_config = merge_flat_paths_processing(\n\t                    flat_config,\n\t                    val,\n\t                    allow_new_keys=True,\n\t                    preprocess_first=False,  # Already processed\n", "                    postprocess=False,\n\t                )\n\t            elif is_tag_in(flat_key, \"merge_before\"):\n\t                if not isinstance(val, str) or not val.endswith(\".yaml\"):\n\t                    raise ValueError(\n\t                        \"Key with '@merge_before' tag must be associated \"\n\t                        \"to a string corresponding to a *yaml* file.\"\n\t                        f\"The problem occurs at key: {flat_key}\"\n\t                    )\n\t                # Remove the tag in the dict\n", "                del flat_config.dict[flat_key]\n\t                flat_config.dict[clean_tag(flat_key, \"merge_before\")] = val\n\t                # Merge + process the dicts\n\t                flat_config = merge_flat_paths_processing(\n\t                    val,\n\t                    flat_config,\n\t                    allow_new_keys=True,\n\t                    preprocess_second=False,  # Already processed\n\t                    postprocess=False,\n\t                )\n", "            elif is_tag_in(flat_key, \"merge_add\"):\n\t                if not isinstance(val, str) or not val.endswith(\".yaml\"):\n\t                    raise ValueError(\n\t                        \"Key with '@merge_add' tag must be associated \"\n\t                        \"to a string corresponding to a *yaml* file.\"\n\t                        f\"The problem occurs at key: {flat_key}\"\n\t                    )\n\t                # Remove the tag in the dict\n\t                del flat_config.dict[flat_key]\n\t                flat_config.dict[clean_tag(flat_key, \"merge_add\")] = val\n", "                # Pre-merge process the dict with the process list of\n\t                # the current config\n\t                flat_config_to_merge = merge_flat_paths_processing(\n\t                    Config({}, []),\n\t                    val,\n\t                    additional_process=flat_config.process_list,\n\t                    allow_new_keys=True,\n\t                    preprocess_first=False,  # Already processed\n\t                    postprocess=False,\n\t                )\n", "                clean_dict, _ = dict_clean_tags(flat_config.dict)\n\t                clean_dict_to_merge, _ = dict_clean_tags(flat_config_to_merge.dict)\n\t                for key in clean_dict_to_merge:\n\t                    if clean_all_tags(key) in clean_dict:\n\t                        raise ValueError(\n\t                            f\"@merge_add doest not allow to add already \"\n\t                            f\"existing keys but key '{key}' is found in both \"\n\t                            \"dicts. Use @merge_after or @merge_before if you \"\n\t                            \"want to merge this key, or check your key names.\"\n\t                        )\n", "                # Merge the dicts (order is not important by construction)\n\t                # NOTE: we delete the process list of the current config\n\t                # to speed up the process by avoiding redundant processing\n\t                flat_config = merge_flat_processing(\n\t                    Config(flat_config.dict, []),\n\t                    flat_config_to_merge,\n\t                    allow_new_keys=True,\n\t                    preprocess_first=False,  # Already processed\n\t                    preprocess_second=False,  # Already processed\n\t                    postprocess=False,\n", "                )\n\t        return flat_config\n\tclass ProcessCopy(Processing):\n\t    \"\"\"Copy a value with ``@copy`` tag. The copy is protected from direct updates.\n\t    Tag your key with ``@copy`` and with value the name of the flat key to copy.\n\t    The pre-merge processing removes the tag. The post-merge processing\n\t    sets the value (if the copied key exists). The end-build processing checks\n\t    that the copied key exists or was already copied once. The pre-save processing\n\t    restore the tag and the key to copy to keep the information on future loads.\n\t    The post-merge and the end-build processings occurs after most processings to\n", "    allow the user to modify or add the copied key before the copy.\n\t    Pre-merge order: 0.0\n\t    Post-merge order: 10.0\n\t    End-build order: 10.0\n\t    Pre-save order: 0.0\n\t    Examples\n\t    --------\n\t    .. code-block:: yaml\n\t        # config.yaml\n\t        a:\n", "          b: 1\n\t          c@copy: a.b\n\t    Before merging, the config is interpreted as the dict\n\t    .. code-block:: python\n\t        {'a': {'b': 1, 'c': 1}}\n\t    Note\n\t    ----\n\t        * The copy key is protected against any modification and will raise an error\n\t          if you try to modify it but will be updated if the copied key is updated.\n\t        * If the key to copy does not exist in the config on post-merge, no error\n", "          is raised to let the user the possibility to add the key later via merge.\n\t          However, if the key still does not exist at the end of the build\n\t          (and the key was never copied), an error is raised.\n\t    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.premerge_order = 0.0\n\t        self.postmerge_order = 10.0\n\t        self.endbuild_order = 10.0\n\t        self.presave_order = 0.0\n", "        self.keys_to_copy: Dict[str, str] = {}\n\t        self.copied_keys: Set[str] = set()\n\t        self.current_value: Dict[str, Any] = {}\n\t    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, val in items:\n\t            if is_tag_in(flat_key, \"copy\"):\n\t                if not isinstance(val, str):\n\t                    raise ValueError(\n", "                        \"Key with '@copy' tag must be associated \"\n\t                        \"to a string corresponding to a flat key. \"\n\t                        f\"The problem occurs at key: {flat_key} with value: {val}\"\n\t                    )\n\t                clean_key = clean_all_tags(flat_key)\n\t                if (\n\t                    clean_key in self.keys_to_copy\n\t                    and self.keys_to_copy[clean_key] != val\n\t                ):\n\t                    raise ValueError(\n", "                        \"Key with '@copy' has change its value to copy. Found key: \"\n\t                        f\"{flat_key} with value: {val}, previous value to copy: \"\n\t                        f\"{self.keys_to_copy[clean_key]}\"\n\t                    )\n\t                # Store the key to copy and value\n\t                self.keys_to_copy[clean_key] = val\n\t                self.current_value[clean_key] = val\n\t                # Remove the tag and update the dict\n\t                flat_config.dict[clean_tag(flat_key, \"copy\")] = val\n\t                del flat_config.dict[flat_key]\n", "        return flat_config\n\t    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\"\"\"\n\t        for key, val in self.keys_to_copy.items():\n\t            # NOTE: Do not raise an error if the key to copy does not exist\n\t            # yet because it can be added later in a future merge\n\t            if key in flat_config.dict and val in flat_config.dict:\n\t                if flat_config.dict[key] != self.current_value[key]:\n\t                    # The key has been modified\n\t                    raise ValueError(\n", "                        \"Found attempt to modify a key with '@copy' tag. The key \"\n\t                        f\"is protected against direct updates. Found key: {key} of \"\n\t                        f\"value {flat_config.dict[key]} that copy {val} of value \"\n\t                        f\"{flat_config.dict[val]}\"\n\t                    )\n\t                # Copy the value\n\t                flat_config.dict[key] = flat_config.dict[val]\n\t                self.copied_keys.add(key)\n\t                # Update the current value\n\t                self.current_value[key] = flat_config.dict[val]\n", "        return flat_config\n\t    def endbuild(self, flat_config: Config) -> Config:\n\t        \"\"\"End-build processing.\"\"\"\n\t        for key, val in self.keys_to_copy.items():\n\t            if key in flat_config.dict and key not in self.copied_keys:\n\t                if val in flat_config.dict:\n\t                    # Copy the value\n\t                    flat_config.dict[key] = flat_config.dict[val]\n\t                    self.copied_keys.add(key)\n\t                else:\n", "                    raise ValueError(\n\t                        \"A key with '@copy' tag has been found but the key to copy \"\n\t                        \"does not exist at the end of the build and it has been \"\n\t                        f\"never copied. Found key: {key} that would copy the \"\n\t                        f\"key: {val}.\"\n\t                    )\n\t        return flat_config\n\t    def presave(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-save processing.\"\"\"\n\t        # Restore the tag with the key to copy to keep the information\n", "        # on further loading\n\t        keys = list(flat_config.dict.keys())\n\t        for key in keys:\n\t            clean_key = clean_all_tags(key)\n\t            if clean_key in self.keys_to_copy:\n\t                new_key = key + \"@copy\"\n\t                del flat_config.dict[key]\n\t                flat_config.dict[new_key] = self.keys_to_copy[clean_key]\n\t        return flat_config\n\tclass ProcessTyping(Processing):\n", "    \"\"\"Force a type with ``@type:<mytype>`` tag. The type is then forced forever.\n\t    Allow basic types (none, any, bool, int, float, str, list, dict), nested lists,\n\t    nested dicts, unions (with Union or the '|' symbol) and Optional.\n\t    The type description is lowercased and spaces are removed.\n\t    For instance: ``@type:None|List[Dict[str, int|float]]`` is valid and force\n\t    the type to be None or a list containing dicts with str keys and int or float\n\t    values.\n\t    The processing stores the type in pre-merge and check alls forced types on\n\t    end-build. It restore the tag in pre-save to keep the information on\n\t    future loads. The end-build processing occurs after almost all processings.\n", "    Pre-merge order: 0.0\n\t    End-build order: 20.0\n\t    Pre-save order: 0.0\n\t    Note\n\t    ----\n\t        The type is not checked on pre-merge or ost-merge to allow the parameter\n\t        to be updated (by a copy or a merge for instance). The goal of this\n\t        processing is to ensure the type at the end of the build.\n\t    Examples\n\t    --------\n", "    ::\n\t        in_dict = {\"param@type:None|List[int|float]\": None}\n\t        dict1 = {param: [0, 1, 2.0]}  # no error\n\t        dict2 = {param: [0, 1, 2.0, 'a']}  # error\n\t    Merging configs with dictionaries ``in_dict`` and ``dict1`` raises no\n\t    error and ``param`` is forced to be None or a list of int or float forever.\n\t    Merging config with ``in_dict`` and ``dict3`` raises an error on post-merge\n\t    due to the 'a' value (which is a string).\n\t    Note that removing \"None|\" in the type description of ``param`` still\n\t    doesn't raise an error in the first case because the type checking is\n", "    evaluated after the merge with ``dict2``.\n\t    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.premerge_order = 0.0\n\t        self.endbuild_order = 20.0\n\t        self.presave_order = 0.0\n\t        self.forced_types: Dict[str, tuple] = {}\n\t        self.type_desc: Dict[str, str] = {}  # For error messages\n\t    def premerge(self, flat_config: Config) -> Config:\n", "        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, val in items:\n\t            end_key = flat_key.split(\".\")[-1]\n\t            if \"@type:\" in end_key:\n\t                # Get the type description\n\t                trail = end_key.split(\"@type:\")[-1]\n\t                type_desc = trail.split(\"@\")[0]  # (in case of multiple tags)\n\t                expected_type = tuple(_parse_type(type_desc))\n\t                clean_key = clean_all_tags(flat_key)\n", "                if clean_key in self.forced_types and set(\n\t                    self.forced_types[clean_key]\n\t                ) != set(expected_type):\n\t                    raise ValueError(\n\t                        f\"Find the tag '@type:{type_desc}' on a key that has already \"\n\t                        \"been associated to an other type: \"\n\t                        f\"{self.type_desc[clean_key]}. \"\n\t                        f\"Find problem at key: {flat_key}\"\n\t                    )\n\t                # Remove the tag\n", "                del flat_config.dict[flat_key]\n\t                flat_config.dict[clean_tag(flat_key, f\"type:{type_desc}\")] = val\n\t                # Store the forced type\n\t                self.forced_types[clean_key] = expected_type\n\t                self.type_desc[clean_key] = type_desc\n\t        return flat_config\n\t    def endbuild(self, flat_config: Config) -> Config:\n\t        \"\"\"End-build processing.\"\"\"\n\t        for key, expected_type in self.forced_types.items():\n\t            if key in flat_config.dict and not _isinstance(\n", "                flat_config.dict[key], expected_type\n\t            ):\n\t                type_desc = self.type_desc[key]\n\t                raise ValueError(\n\t                    f\"Key previously tagged with '@type:{type_desc}' must be \"\n\t                    f\"associated to a value of type {type_desc}. Find the \"\n\t                    f\"value: {flat_config.dict[key]} of type \"\n\t                    f\"{type(flat_config.dict[key])} at key: {key}\"\n\t                )\n\t        return flat_config\n", "    def presave(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-save processing.\"\"\"\n\t        # Restore the tag with the type to keep the information\n\t        # on further loading\n\t        keys = list(flat_config.dict.keys())\n\t        for key in keys:\n\t            clean_key = clean_all_tags(key)\n\t            if clean_key in self.type_desc:\n\t                new_key = key + f\"@type:{self.type_desc[clean_key]}\"\n\t                flat_config.dict[new_key] = flat_config.dict[key]\n", "                del flat_config.dict[key]\n\t        return flat_config\n\tclass ProcessSelect(Processing):\n\t    \"\"\"Select a sub-config with ``@select`` and delete the rest of its parent config.\n\t    First look in pre-merge for a parameter tagged with ``@select`` containing a\n\t    flat key corresponding to a sub-configurations to keep. The parent configuration\n\t    is then deleted on post-merge, except the selected sub-configuration\n\t    and eventually the tagged parameter (if it is in the same sub-configuration).\n\t    It is also possible to select multiple keys of a same sub-configuration\n\t    (meaning that the part before the last dot must be equal) by passing a\n", "    list of flat keys.\n\t    Pre-merge order: 0.0\n\t    Post-merge order: 0.0\n\t    Examples\n\t    --------\n\t    .. code-block:: yaml\n\t        models:\n\t            model_names@select: [models.model1, models.model3]\n\t            model1:\n\t                param1: 1\n", "                param2: 2\n\t            model2:\n\t                param1: 3\n\t                param2: 4\n\t            model3:\n\t                submodel:\n\t                    param: 5\n\t            model4:\n\t                param: 6\n\t    Result in deleting ``models.model2`` (``param1`` and ``param2``) and\n", "    ``models.model4.param``, and keeping the rest.\n\t    Warning\n\t    -------\n\t        For security reasons, this processing prevents from deleting\n\t        the configuration at the root, which is the case when the\n\t        selected key doesn't contain a dot. It raises an error in this case.\n\t    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.keys_that_select: Set[str] = set()\n", "        self.subconfigs_to_delete: Set[str] = set()\n\t        self.keys_to_keep: Set[str] = set()\n\t    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, val in items:\n\t            if is_tag_in(flat_key, \"select\"):\n\t                # Remove the tag\n\t                clean_key = clean_all_tags(flat_key)\n\t                del flat_config.dict[flat_key]\n", "                flat_config.dict[clean_tag(flat_key, \"select\")] = val\n\t                self.keys_that_select.add(clean_key)\n\t                if isinstance(val, str):\n\t                    subconfig = \".\".join(flat_key.split(\".\")[:-1])\n\t                    keys_to_keep = [clean_key, val]\n\t                elif isinstance(val, list):\n\t                    subconfig = \".\".join(val[0].split(\".\")[:-1])\n\t                    for key in val[1:]:\n\t                        subconfig2 = \".\".join(key.split(\".\")[:-1])\n\t                        if subconfig != subconfig2:\n", "                            raise ValueError(\n\t                                \"The keys in the list of parameters tagged with \"\n\t                                \"'@select' must be identical before the last dot \"\n\t                                f\"(= on the same subconfig). Find: {subconfig} and \"\n\t                                f\"{subconfig2} before the last dot.\"\n\t                            )\n\t                    keys_to_keep = [clean_key] + val\n\t                else:\n\t                    raise ValueError(\n\t                        \"The value of parameters tagged with '@select' must be a \"\n", "                        \"string or a list of strings representing flat key(s). \"\n\t                    )\n\t                subconfig = clean_all_tags(subconfig)\n\t                if subconfig == \"\":\n\t                    raise ValueError(\n\t                        \"Find attempt to delete the configuration at the root. You \"\n\t                        \"must pass a flat key with a least one dot on parameter \"\n\t                        f\"tagged with @select. Find key: {flat_key} with value: {val}\"\n\t                    )\n\t                self.subconfigs_to_delete.add(subconfig)\n", "                self.keys_to_keep.update(keys_to_keep)\n\t        return flat_config\n\t    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\"\"\"\n\t        def _is_in_subconfig(key: str, subconfig: str) -> bool:\n\t            \"\"\"Check if a key is in a subconfig with the exact name.\"\"\"\n\t            return key == subconfig or key.startswith(subconfig + \".\")\n\t        # Delete all keys on the subconfigs except the ones to keep\n\t        for subconfig in self.subconfigs_to_delete:\n\t            for key in list(flat_config.dict.keys()):\n", "                if _is_in_subconfig(key, subconfig) and not any(\n\t                    _is_in_subconfig(key, key_to_keep)\n\t                    for key_to_keep in self.keys_to_keep\n\t                ):\n\t                    del flat_config.dict[key]\n\t        return super().postmerge(flat_config)\n\t    def presave(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-save processing.\"\"\"\n\t        # Restore the tag with the type to keep the information\n\t        # on further loading\n", "        keys = list(flat_config.dict.keys())\n\t        for key in keys:\n\t            clean_key = clean_all_tags(key)\n\t            if clean_key in self.keys_that_select:\n\t                new_key = key + \"@select\"\n\t                flat_config.dict[new_key] = flat_config.dict[key]\n\t                del flat_config.dict[key]\n\t        return flat_config\n\tclass ProcessDelete(Processing):\n\t    \"\"\"Delete the parameters tagged with ``@delete`` on pre-merge.\n", "    This processing is useful to activate a processing without adding\n\t    an additional parameter in the default configuration to avoid the error\n\t    on merge with ``allow_new_keys=False``. This processing is applied very\n\t    late on pre-merge to allow the others processing to be applied before\n\t    deleting the parameters.\n\t    Pre-merge order: 30.0\n\t    Examples\n\t    --------\n\t    .. code-block:: yaml\n\t        # main.yaml\n", "        1@select@delete: configs.config1\n\t        2@merge_add@delete: config1.yaml\n\t        3@merge_add@delete: config2.yaml\n\t        # config1.yaml\n\t        configs.config1.param: 1\n\t        configs.config1.param2: 2\n\t        # config2.yaml\n\t        configs.config2.param: 3\n\t        configs.config2.param: 4\n\t    Here we want to merge two config files and select one sub-config.\n", "    We use the corresponding tags but we don't have a good name for the keys\n\t    and instead of adding a new parameter in the default configuration with\n\t    random names like \"1\", \"2\", \"3\", we use the ``@delete`` tag to delete the\n\t    keys after the pre-merge processing.\n\t    Warning\n\t    -------\n\t        The parameter is deleted on pre-merge. Therefore, if the parameter\n\t        also exists on the other configuration during merge (without the tag),\n\t        this parameter will be remain as it is. This processing is more used\n\t        to delete parameter that is NOT present in the default configuration.\n", "    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        # After all pre-merge processing\n\t        self.premerge_order = 30.0\n\t    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\"\"\"\n\t        keys = list(flat_config.dict.keys())\n\t        for key in keys:\n\t            if is_tag_in(key, \"delete\"):\n", "                del flat_config.dict[key]\n\t        return flat_config\n\tclass ProcessNew(Processing):\n\t    \"\"\"Allow new sub-config/parameter absent from default config with tag ``@new``.\n\t    The tagged sub-config/parameter and its value is stored during pre-merge and\n\t    is deleted to avoid error on merge due to new key. It is then restored on\n\t    post-merge. Finally, the tag is restored on pre-save for further loading.\n\t    This processing is applied very late on pre-merge to allow\n\t    the others processing to be applied before deleting the parameters.\n\t    The post-merge processing is applied very early to allow the other processing\n", "    to use this new parameter.\n\t    Pre-merge order: 30.0\n\t    Post-merge order: -20.0\n\t    Pre-save order: 0.0\n\t    Disclaimer: It is preferable to have an exhaustive default configuration instead\n\t    of abusing this processing to improve the readability and to avoid typos errors\n\t    in the name of the parameters or their sub-configs.\n\t    Examples\n\t    --------\n\t    .. code-block:: yaml\n", "        # default.yaml\n\t        param1: 1\n\t        # additional.yaml\n\t        param2@new: 2\n\t        subconfig@new.subsubconfig:\n\t            param3: 3\n\t            param4: 4\n\t    Use default.yaml as default configuration and add additional.yaml as additional\n\t    configuration via CLI results on the configuration containing param1, param2\n\t    and the nested config containing param3 and param4.\n", "    Without the ``@new`` tag, an error is raised because param2 is not present in\n\t    the default configuration.\n\t    Note\n\t    ----\n\t        * Tag a subconfig by adding ``@new`` at the end of the key containing\n\t          the sub-config dict in your yaml file.\n\t        * When a parameter is added with this processing, it is possible to modify it\n\t          later via config merge without the tag because the parameter is then present\n\t          in the current configuration.\n\t        * If the tagged parameter or sub-config is already present in the current\n", "          configuration, no error are raised and the value is still updated on\n\t          post-merge. It may no have influence in practice.\n\t    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.premerge_order = 30.0\n\t        self.postmerge_order = -20.0\n\t        self.new_vals: Dict[str, Any] = {}\n\t        self.new_vals_backup: Dict[str, Any] = {}\n\t    def premerge(self, flat_config: Config) -> Config:\n", "        \"\"\"Pre-merge processing.\"\"\"\n\t        keys = list(flat_config.dict.keys())\n\t        for key in keys:\n\t            # NOTE: we don't use is_tag_in because we want to look\n\t            # for tags in the sub-configs too.\n\t            if \"@new@\" in key or \"@new.\" in key or key.endswith(\"@new\"):\n\t                clean_key = clean_all_tags(key)\n\t                self.new_vals[clean_key] = flat_config.dict[key]\n\t                self.new_vals_backup[clean_key] = flat_config.dict[key]\n\t                del flat_config.dict[key]\n", "        return flat_config\n\t    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\"\"\"\n\t        flat_config.dict.update(self.new_vals)\n\t        # Reset the new values to avoid re-adding them later\n\t        self.new_vals = {}\n\t        return flat_config\n\t    def presave(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-save processing.\"\"\"\n\t        # Restore the tag @new to allow loading the config later by allowing\n", "        # these new parameters.\n\t        for key, value in self.new_vals_backup.items():\n\t            if key in flat_config.dict:\n\t                flat_config.dict[key + \"@new\"] = value\n\t                del flat_config.dict[key]\n\t        return flat_config\n\tclass ProcessCheckTags(Processing):\n\t    \"\"\"Raise an error if a tag is present in a key after pre-merging processes.\n\t    This security processing is always applied after all pre-merge process and\n\t    checks for '@' in the keys. It raises an error if one is found.\n", "    \"\"\"\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        # NOTE: this processing is a special meta-processing that must be\n\t        # applied after all other pre-merge processing to ensure security.\n\t        # That why it has a very high pre-merge order and it is not a\n\t        # good idea to make pre-merge processing with higher order.\n\t        self.premerge_order = 1000.0\n\t    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\"\"\"\n", "        _, tagged_keys = dict_clean_tags(flat_config.dict)\n\t        if tagged_keys:\n\t            keys_message = \"\\n\".join(tagged_keys[:5])\n\t            raise ValueError(\n\t                \"Keys with tags are encountered at the end of \"\n\t                \"the pre-merge process. It is probably a mistake due to:\\n\"\n\t                \"- a typo in tag name\\n\"\n\t                \"- a missing processing in process_list\\n\"\n\t                \"- the use of an 'at' ('@') in a parameter name\\n\"\n\t                \"- the use of a custom processing that does not remove a tag\\n\\n\"\n", "                \"The tagged keys encountered (5 first if more than 5) are:\\n\"\n\t                f\"{keys_message}\"\n\t            )\n\t        return flat_config\n\tclass DefaultProcessings:\n\t    \"\"\"Default list of built-in processings.\n\t    To add these processings to a Config instance, use:\n\t    ::\n\t        config.process_list += DefaultProcessings().list\n\t    The current default processing list contains:\n", "     * ProcessCheckTags: protect against '@' in keys at the end of pre-merge)\n\t     * ProcessMerge (@merge_all, @merge_before, @merge_after): merge multiple\n\t       files into one.\n\t     * ProcessCopy (@copy): persistently copy a value from one key to an other\n\t       and protect it\n\t     * ProcessTyping (@type:X): force the type of parameter to any type X.\n\t     * ProcessSelect (@select): select sub-config(s) to keep and delete the\n\t       other sub-configs in the same parent config.\n\t     * ProcessDelete (@delete): delete the parameter tagged with @delete on\n\t       pre-merge.\n", "    \"\"\"\n\t    def __init__(self) -> None:\n\t        self.list: List[Processing] = [\n\t            ProcessCheckTags(),\n\t            ProcessMerge(),\n\t            ProcessCopy(),\n\t            ProcessTyping(),\n\t            ProcessSelect(),\n\t            ProcessDelete(),\n\t            ProcessNew(),\n", "        ]\n"]}
{"filename": "cliconfig/processing/_type_parser.py", "chunked_list": ["\"\"\"Private module with type parser for processing module with type manipulation.\"\"\"\n\tfrom pydoc import locate\n\tfrom typing import List, Optional, Tuple, Type, Union\n\tdef _parse_type(type_desc: str) -> Tuple:\n\t    \"\"\"Parse a type description.\n\t    Allow basic types (none, any, bool, int, float, str, list, dict), nested lists,\n\t    nested dicts, unions (with Union or the '|' symbol) and Optional.\n\t    Examples of representation:\n\t     * \"str\" -> (str,)\n\t     * \"None|Any\" -> (type(None), object)\n", "     * \"list|float\" -> (list, float)\n\t     * \"List[float]\" -> ((\"list\", (float,)),)\n\t     * \"Dict[str, Any]\" -> ((\"dict\", (str,), (object,)),)\n\t     * \"Dict[str, List[float]]\" -> ((\"dict\", (str,), (((\"list\", (float,)),),)),)\n\t     * \"Dict[str|bool, int|float]\" -> ((\"dict\", (str, bool), (int, float)),)\n\t     * ...\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If the type description is not valid or not recognized.\n", "    Note\n\t    ----\n\t        The type description is lowercased and spaces are removed before parsing.\n\t    \"\"\"\n\t    # Clean up\n\t    old_type_desc = type_desc\n\t    type_desc = type_desc.replace(\" \", \"\").lower()\n\t    try:\n\t        # Base typeParseType\n\t        base_type = _parse_base_type(type_desc)\n", "        if base_type is not None:\n\t            return (base_type,)\n\t        # Split the external blocks enclosed by brackets\n\t        blocks = _split_brackets(type_desc, delimiter=\"|\")\n\t        types: Tuple = ()\n\t        for block in blocks:\n\t            if block[:5] == \"list[\":\n\t                types += _parse_list(block)\n\t            elif block[:5] == \"dict[\":\n\t                types += _parse_dict(block)\n", "            elif block[:9] == \"optional[\":\n\t                types += _parse_optional(block)\n\t            elif block[:6] == \"union[\":\n\t                types += _parse_union(block)\n\t            else:  # Should be a base type\n\t                base_type = _parse_base_type(block)\n\t                if base_type is not None:\n\t                    types += (base_type,)\n\t                else:\n\t                    raise ValueError(f\"Unknown type: '{block}'\")\n", "        return types\n\t    except ValueError as err:\n\t        # Revert the traceback to show the original type description\n\t        raise ValueError(f\"Unknown type: '{old_type_desc}'\") from err\n\tdef _parse_base_type(type_desc: str) -> Optional[Type]:\n\t    \"\"\"Parse a base type description.\n\t    Base types are: none, any, bool, int, float and str, list, dict.\n\t    Return None if the type is not a base type.\n\t    \"\"\"\n\t    if type_desc == \"none\":\n", "        return type(None)\n\t    if type_desc == \"any\":\n\t        # Match any type\n\t        return object\n\t    if type_desc in (\"bool\", \"int\", \"float\", \"str\", \"list\", \"dict\"):\n\t        return locate(type_desc)  # type: ignore\n\t    return None\n\tdef _parse_list(type_desc: str) -> Tuple:\n\t    \"\"\"Parse a \"list\" type description.\"\"\"\n\t    sub_desc = type_desc[5:-1]\n", "    if len(_split_brackets(sub_desc, delimiter=\",\")) > 1:\n\t        raise ValueError(f\"Invalid List type: '{type_desc}'\")\n\t    return ((\"list\",) + (_parse_type(sub_desc),),)\n\tdef _parse_dict(type_desc: str) -> Tuple:\n\t    \"\"\"Parse an \"dict\" type description.\"\"\"\n\t    sub_desc = type_desc[5:-1]\n\t    sub_blocks = _split_brackets(sub_desc, delimiter=\",\")\n\t    if len(sub_blocks) != 2:\n\t        raise ValueError(f\"Invalid Dict type: '{type_desc}'\")\n\t    key_type = _parse_type(sub_blocks[0])\n", "    value_type = _parse_type(sub_blocks[1])\n\t    return ((\"dict\",) + (key_type,) + ((value_type),),)\n\tdef _parse_optional(type_desc: str) -> Tuple:\n\t    \"\"\"Parse an \"optional\" type description.\"\"\"\n\t    sub_desc = type_desc[9:-1]\n\t    if len(_split_brackets(sub_desc, delimiter=\",\")) > 1:\n\t        raise ValueError(f\"Invalid Optional type: '{type_desc}'\")\n\t    return ((type(None),) + _parse_type(sub_desc),)\n\tdef _parse_union(type_desc: str) -> Tuple:\n\t    \"\"\"Parse an \"union\" type description.\"\"\"\n", "    sub_desc = type_desc[6:-1]\n\t    # Split by comma\n\t    sub_blocks = _split_brackets(sub_desc, delimiter=\",\")\n\t    if len(sub_blocks) < 2:\n\t        raise ValueError(f\"Invalid Union type: '{type_desc}'\")\n\t    types: Tuple = ()\n\t    union_types = [_parse_type(sub_block) for sub_block in sub_blocks]\n\t    for union_type in union_types:\n\t        types += union_type\n\t    return types\n", "def _split_brackets(type_desc: str, delimiter: str) -> List[str]:\n\t    \"\"\"Split a type description in blocks enclosed by brackets.\"\"\"\n\t    blocks = []\n\t    bracket_count = 0\n\t    i, j = 0, 0\n\t    while j < len(type_desc):\n\t        char = type_desc[j]\n\t        if char == \"[\":\n\t            bracket_count += 1\n\t        elif char == \"]\":\n", "            bracket_count -= 1\n\t        if bracket_count == 0 and char == delimiter:\n\t            blocks.append(type_desc[i:j])\n\t            i = j + 1\n\t            j += 2\n\t        else:\n\t            j += 1\n\t    blocks.append(type_desc[i:j])\n\t    return blocks\n\tdef _isinstance(obj: object, types: Union[Type, Tuple]) -> bool:\n", "    \"\"\"Check if an object is an instance of a type or a tuple of types.\n\t    Intended to work with the outputs of _parse_type.\n\t    \"\"\"\n\t    if isinstance(types, type):\n\t        return isinstance(obj, types)\n\t    if types[0] == \"list\" and len(types) == 2:\n\t        return isinstance(obj, list) and all(\n\t            _isinstance(elem, types[1]) for elem in obj\n\t        )\n\t    if types[0] == \"dict\" and len(types) == 3:\n", "        return (\n\t            isinstance(obj, dict)\n\t            and all(_isinstance(key, types[1]) for key in obj)\n\t            and all(_isinstance(value, types[2]) for value in obj.values())\n\t        )\n\t    if isinstance(types[0], (type, tuple)):\n\t        return any(_isinstance(obj, sub_types) for sub_types in types)\n\t    raise ValueError(f\"Invalid type for _isinstance: '{types}'\")\n"]}
{"filename": "cliconfig/processing/create.py", "chunked_list": ["\"\"\"Functions to create new processing quickly.\"\"\"\n\t# pylint: disable=unused-argument\n\timport re\n\tfrom inspect import signature\n\tfrom typing import Any, Callable, Dict, Optional, Set, Union\n\tfrom cliconfig.base import Config\n\tfrom cliconfig.processing.base import Processing\n\tfrom cliconfig.tag_routines import clean_all_tags, clean_tag, is_tag_in\n\tdef _is_matched(key: str, tag_name: Optional[str], regex: Optional[str]) -> bool:\n\t    \"\"\"Check if key match the regex or contain the tag.\"\"\"\n", "    if tag_name is not None and regex is not None:\n\t        raise ValueError(\"Either regex or tag_name must be defined but not both.\")\n\t    # Case defined with tag\n\t    if tag_name is not None:\n\t        return is_tag_in(key, tag_name)\n\t    # Case defined with regex\n\t    if regex is not None:\n\t        param_name = key.split(\".\")[-1].split(\"@\")[0]\n\t        return re.match(regex, param_name) is not None\n\t    raise ValueError(\"Either regex or tag_name must be defined.\")\n", "class _ProcessingValue(Processing):\n\t    \"\"\"Processing class for make_processing_value.\"\"\"\n\t    def __init__(\n\t        self,\n\t        func: Union[Callable[[Any], Any], Callable[[Any, Config], Any]],\n\t        processing_type: str,\n\t        *,\n\t        regex: Optional[str],\n\t        tag_name: Optional[str],\n\t        order: float,\n", "        persistent: bool,\n\t    ) -> None:\n\t        super().__init__()\n\t        self.func = func\n\t        self.processing_type = processing_type\n\t        self.regex = regex\n\t        self.tag_name = tag_name\n\t        if processing_type == \"premerge\":\n\t            self.premerge_order = order\n\t        elif processing_type == \"postmerge\":\n", "            self.postmerge_order = order\n\t        elif processing_type == \"endbuild\":\n\t            self.endbuild_order = order\n\t        elif processing_type == \"presave\":\n\t            self.presave_order = order\n\t        elif processing_type == \"postload\":\n\t            self.postload_order = order\n\t        else:\n\t            raise ValueError(\n\t                f\"Processing type '{processing_type}' not recognized. Must be\"\n", "                \"one of 'premerge', 'postmerge', 'endbuild', 'presave' or\"\n\t                \"'postload'.\"\n\t            )\n\t        self.persistent = persistent\n\t        # matched_keys: store keys that match the regex or contain the tag\n\t        self.matched_keys: Set[str] = set()\n\t    def _apply_update(self, flat_config: Config) -> Config:\n\t        \"\"\"Apply value updates to matching parameters.\n\t        Does not assume that the keys are clean (it is not always the case\n\t        on pre-merge and post-load for instance).\n", "        \"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for key, value in items:\n\t            clean_key = clean_all_tags(key)\n\t            if clean_key in self.matched_keys:\n\t                # Remove clean_key from match_keys if not persistent\n\t                if not self.persistent:\n\t                    self.matched_keys.remove(clean_key)\n\t                # Apply update\n\t                value = flat_config.dict[key]\n", "                try:\n\t                    # Case one argument\n\t                    if len(signature(self.func).parameters) == 1:\n\t                        flat_config.dict[key] = self.func(value)  # type: ignore\n\t                    # Case two arguments\n\t                    else:\n\t                        flat_config.dict[key] = self.func(  # type: ignore\n\t                            value, flat_config\n\t                        )\n\t                except ValueError:\n", "                    # Case no signature, trying to call with one argument\n\t                    flat_config.dict[key] = self.func(value)  # type: ignore\n\t        return flat_config\n\t    def premerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, value in items:\n\t            if _is_matched(flat_key, self.tag_name, self.regex):\n\t                # Store the key\n\t                self.matched_keys.add(clean_all_tags(flat_key))\n", "                # Remove the tag if any\n\t                if self.tag_name:\n\t                    del flat_config.dict[flat_key]\n\t                    new_key = clean_tag(flat_key, self.tag_name)\n\t                    flat_config.dict[new_key] = value\n\t        if self.processing_type == \"premerge\":\n\t            return self._apply_update(flat_config)\n\t        return flat_config\n\t    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\"\"\"\n", "        if self.processing_type == \"postmerge\":\n\t            return self._apply_update(flat_config)\n\t        return flat_config\n\t    def endbuild(self, flat_config: Config) -> Config:\n\t        \"\"\"End-build processing.\"\"\"\n\t        if self.processing_type == \"endbuild\":\n\t            return self._apply_update(flat_config)\n\t        return flat_config\n\t    def presave(self, flat_config: Config) -> Config:\n\t        \"\"\"Pre-save processing.\"\"\"\n", "        if self.processing_type == \"presave\":\n\t            return self._apply_update(flat_config)\n\t        return flat_config\n\t    def postload(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-load processing.\"\"\"\n\t        if self.processing_type == \"postload\":\n\t            return self._apply_update(flat_config)\n\t        return flat_config\n\tclass _ProcessingKeepProperty(Processing):\n\t    \"\"\"Processing class for make_processing_keep_property.\"\"\"\n", "    def __init__(\n\t        self,\n\t        func: Union[Callable[[Any], Any], Callable[[Any, Config], Any]],\n\t        *,\n\t        regex: Optional[str],\n\t        tag_name: Optional[str],\n\t        premerge_order: float,\n\t        postmerge_order: float,\n\t        endbuild_order: float,\n\t    ) -> None:\n", "        super().__init__()\n\t        self.func = func\n\t        self.regex = regex\n\t        self.tag_name = tag_name\n\t        self.premerge_order = premerge_order\n\t        self.postmerge_order = postmerge_order\n\t        self.endbuild_order = endbuild_order\n\t        self.properties: Dict[str, Any] = {}\n\t    def _eval_property(self, key: str, flat_config: Config) -> Any:\n\t        \"\"\"Evaluate property.\"\"\"\n", "        try:\n\t            # Case one argument\n\t            if len(signature(self.func).parameters) == 1:\n\t                return self.func(flat_config.dict[key])  # type: ignore\n\t            # Case two arguments\n\t            return self.func(flat_config.dict[key], flat_config)  # type: ignore\n\t        except ValueError:\n\t            # Case no signature, trying to call with one argument\n\t            return self.func(flat_config.dict[key])  # type: ignore\n\t    def premerge(self, flat_config: Config) -> Config:\n", "        \"\"\"Pre-merge processing.\"\"\"\n\t        items = list(flat_config.dict.items())\n\t        for flat_key, value in items:\n\t            if _is_matched(flat_key, self.tag_name, self.regex):\n\t                clean_key = clean_all_tags(flat_key)\n\t                if clean_key not in self.properties:\n\t                    property_ = self._eval_property(flat_key, flat_config)\n\t                    self.properties[clean_key] = property_\n\t                if self.tag_name:\n\t                    del flat_config.dict[flat_key]\n", "                    new_key = clean_tag(flat_key, self.tag_name)\n\t                    flat_config.dict[new_key] = value\n\t        return flat_config\n\t    def _check_properties(self, flat_config: Config, processing_timing: str) -> None:\n\t        \"\"\"Check if all properties are still the same.\"\"\"\n\t        for flat_key, expected_property in self.properties.items():\n\t            if flat_key in flat_config.dict:\n\t                property_ = self._eval_property(flat_key, flat_config)\n\t                if property_ != expected_property:\n\t                    raise ValueError(\n", "                        f\"Property of key {flat_key} has changed from \"\n\t                        f\"{expected_property} to \"\n\t                        f\"{property_} while it is protected by a keep-property \"\n\t                        f\"processing (problem found on {processing_timing}).\"\n\t                    )\n\t    def postmerge(self, flat_config: Config) -> Config:\n\t        \"\"\"Post-merge processing.\"\"\"\n\t        self._check_properties(flat_config, \"post-merge\")\n\t        return flat_config\n\t    def endbuild(self, flat_config: Config) -> Config:\n", "        \"\"\"End-build processing.\"\"\"\n\t        self._check_properties(flat_config, \"end-build\")\n\t        return flat_config\n\tdef create_processing_value(\n\t    func: Union[Callable[[Any], Any], Callable[[Any, Config], Any]],\n\t    processing_type: str = \"premerge\",\n\t    *,\n\t    regex: Optional[str] = None,\n\t    tag_name: Optional[str] = None,\n\t    order: float = 0.0,\n", "    persistent: bool = False,\n\t) -> Processing:\n\t    r\"\"\"Create a processing object that modifies a value in config using tag or regex.\n\t    The processing is applied on pre-merge. It triggers when the key matches\n\t    the tag or the regex. The function apply ``flat_dict[key] = func(flat_dict[key])``.\n\t    You must only provide one of tag or regex. If tag is provided, the tag will be\n\t    removed from the key during pre-merge.\n\t    It also possible to pass the flat config as a second argument of the function\n\t    ``func``. In this case, the function apply\n\t    ``flat_dict[key] = func(flat_dict[key], flat_config)``.\n", "    Parameters\n\t    ----------\n\t    func : Callable\n\t        The function to apply to the value (and eventually the flat config)\n\t        to make the new value so that:\n\t        flat_dict[key] = func(flat_dict[key]) or func(flat_dict[key], flat_config)\n\t    processing_type : str, optional\n\t        One of \"premerge\", \"postmerge\", \"presave\", \"postload\" or \"endbuild\".\n\t        Timing to apply the value update. In all cases the tag is removed on pre-merge.\n\t        By default \"premerge\".\n", "    regex : Optional[str]\n\t        The regex to match the key.\n\t    tag_name : Optional[str]\n\t        The tag (without \"@\") to match the key. The tag is removed on pre-merge.\n\t    order : int, optional\n\t        The pre-merge order. By default 0.0.\n\t    persistent : bool, optional\n\t        If True, the processing will be applied on all keys that have already\n\t        matched the tag before. By nature, using regex make the processing\n\t        always persistent. By default, False.\n", "    Raises\n\t    ------\n\t    ValueError\n\t        If both tag and regex are provided or if none of them are provided.\n\t    ValueError\n\t        If the processing type is not one of \"premerge\", \"postmerge\", \"presave\",\n\t        \"postload\" or \"endbuild\".\n\t    Returns\n\t    -------\n\t    processing : Processing\n", "        The processing object with the pre-merge method.\n\t    Examples\n\t    --------\n\t    With the following config and 2 processings:\n\t    .. code_block: yaml\n\t        # config.yaml\n\t        neg_number1: 1\n\t        neg_number2: 1\n\t        neg_number3@add1: 1\n\t    ::\n", "        proc2 = create_processing_value(lambda val: -val, regex=\"neg_number.*\",\n\t            order=0.0)\n\t        proc1 = create_processing_value(lambda val: val + 1, tag_name=\"add1\",\n\t            order=1.0)\n\t    When config.yaml is merged with an other config, it will be considered\n\t    before merging as:\n\t    ::\n\t        {'number1': -1, 'number2': -1, 'number3': 0}\n\t    Using the config as a second argument of the function:\n\t    .. code_block: yaml\n", "        # config.yaml\n\t        param1: 1\n\t        param2@eval: \"config.param1 + 1\"\n\t    ::\n\t        proc = create_processing_value(\n\t            lambda val, config: eval(val, {'config': config}),\n\t            processing_type='postmerge', tag_name='eval', persistent=False\n\t        )\n\t    After config.yaml is merged with another config, param2 will be evaluated\n\t    as 2 (except if config.param1 has changed with a processing before).\n", "    \"\"\"\n\t    if tag_name is not None:\n\t        if regex is not None:\n\t            raise ValueError(\"You must provide a tag or a regex but not both.\")\n\t    else:\n\t        if regex is None:\n\t            raise ValueError(\n\t                \"You must provide a tag or a regex (to trigger the value update).\"\n\t            )\n\t    proc = _ProcessingValue(func, processing_type, regex=regex,\n", "                            tag_name=tag_name, order=order, persistent=persistent)\n\t    return proc\n\tdef create_processing_keep_property(\n\t    func: Callable,\n\t    regex: Optional[str] = None,\n\t    tag_name: Optional[str] = None,\n\t    premerge_order: float = 0.0,\n\t    postmerge_order: float = 0.0,\n\t    endbuild_order: float = 0.0,\n\t) -> Processing:\n", "    \"\"\"Create a processing object that keep a property from a value using tag or regex.\n\t    The pre-merge processing looks for keys that match the tag or the regex, apply\n\t    the function func on the value and store the result (= the \"property\"):\n\t    ``property = func(flat_dict[key])``.\n\t    The post-merge processing will check that the property is the same as the one\n\t    stored during pre-merge. If not, it will raise a ValueError.\n\t    It also possible to pass the flat config as a second argument of the function\n\t    ``func``. In this case, the function apply\n\t    ``property = func(flat_dict[key], flat_config)``.\n\t    Parameters\n", "    ----------\n\t    func : Callable\n\t        The function to apply to the value (and eventually the flat config)\n\t        to define the property to keep.\n\t        property = func(flat_dict[key]) or func(flat_dict[key], flat_config)\n\t    regex : Optional[str]\n\t        The regex to match the key.\n\t    tag_name : Optional[str]\n\t        The tag (without \"@\") to match the key. The values are modified when\n\t        triggering the pattern \".*@<tag_name>.*\" and the tag is removed from the key.\n", "    premerge_order : float, optional\n\t        The pre-merge order, by default 0.0\n\t    postmerge_order : float, optional\n\t        The post-merge order, by default 0.0\n\t    endbuild_order : float, optional\n\t        The end-build order, by default 0.0\n\t    Raises\n\t    ------\n\t    ValueError\n\t        If both tag and regex are provided or if none of them are provided.\n", "    Returns\n\t    -------\n\t    Processing\n\t        The processing object with the pre-merge and post-merge methods.\n\t    Examples\n\t    --------\n\t    A processing that enforce the types of all the parameters to be constant\n\t    (equal to the type of the first value encountered):\n\t    ::\n\t        create_processing_keep_property(type, regex=\".*\", premerge_order=15.0,\n", "                                        postmerge_order=15.0, endbuild_order=15.0)\n\t    A processing that protect parameters tagged with @protect from being changed:\n\t    ::\n\t        create_processing_keep_property(lambda x: x, tag_name=\"protect\",\n\t                                        premerge_order=15.0, postmerge_order=15.0)\n\t    \"\"\"\n\t    if tag_name is not None:\n\t        if regex is not None:\n\t            raise ValueError(\"You must provide a tag or a regex but not both.\")\n\t    else:\n", "        if regex is None:\n\t            raise ValueError(\n\t                \"You must provide a tag or a regex (to trigger the value update).\"\n\t            )\n\t    processing = _ProcessingKeepProperty(\n\t        func,\n\t        regex=regex,\n\t        tag_name=tag_name,\n\t        premerge_order=premerge_order,\n\t        postmerge_order=postmerge_order,\n", "        endbuild_order=endbuild_order,\n\t    )\n\t    return processing\n"]}
{"filename": "cliconfig/yaml_tags/_yaml_tags.py", "chunked_list": ["\"\"\"Module to convert yaml tags in yaml file to python dict with  cliconfig tags.\"\"\"\n\tfrom typing import Any, Dict, Optional, Tuple\n\timport yaml\n\tclass TaggedNode:\n\t    \"\"\"Node class for tagged tree (with yaml tags).\"\"\"\n\t    def __init__(self, value: Any, tag: str, *, is_config: bool) -> None:\n\t        self.tag = tag\n\t        self.value = value\n\t        self.is_config = is_config\n\tdef tagged_constructor(\n", "    loader: yaml.SafeLoader, tag_suffix: str, node: yaml.Node\n\t) -> Any:\n\t    \"\"\"Build a tagged tree node from yaml node.\"\"\"\n\t    if isinstance(node, yaml.ScalarNode):\n\t        return TaggedNode(loader.construct_scalar(node), tag_suffix, is_config=False)\n\t    if isinstance(node, yaml.SequenceNode):\n\t        return TaggedNode(loader.construct_sequence(node), tag_suffix, is_config=False)\n\t    return TaggedNode(\n\t        loader.construct_mapping(node), tag_suffix, is_config=True  # type: ignore\n\t    )\n", "def get_yaml_loader() -> Any:\n\t    \"\"\"Return a yaml loader to parse tags and build tagged tree.\"\"\"\n\t    loader = yaml.SafeLoader\n\t    loader.add_multi_constructor(\"\", tagged_constructor)  # type: ignore\n\t    return loader\n\tdef insert_tags(tagged_tree: Any) -> Tuple[Any, Optional[str]]:\n\t    \"\"\"Build dict with cliconfig tag from tagged tree (with yaml tags).\"\"\"\n\t    if isinstance(tagged_tree, TaggedNode) and tagged_tree.is_config:\n\t        tag = tagged_tree.tag\n\t        if tag:\n", "            tag = tag.replace(\"!\", \"\")\n\t        out_dict = build_tree_from_dict(tagged_tree.value)\n\t        return out_dict, tag\n\t    if isinstance(tagged_tree, dict):\n\t        out_dict = build_tree_from_dict(tagged_tree)\n\t        return out_dict, None\n\t    if isinstance(tagged_tree, TaggedNode):\n\t        tag = tagged_tree.tag\n\t        if tag:\n\t            tag = tag.replace(\"!\", \"\")\n", "        if isinstance(tagged_tree.value, str):\n\t            value = yaml.safe_load(tagged_tree.value)\n\t        else:\n\t            value = tagged_tree.value\n\t        return value, tag\n\t    return tagged_tree, None\n\tdef build_tree_from_dict(in_dict: Dict) -> Dict[str, Any]:\n\t    \"\"\"Build a dict with cliconfig tag from a dict of tagged trees.\"\"\"\n\t    out_dict: Dict[str, Any] = {}\n\t    for key, value in in_dict.items():\n", "        tree, tag = insert_tags(value)\n\t        if tag:\n\t            subtag = tag.replace(\"!\", \"\")\n\t            key = f\"{key}@{subtag}\"\n\t        out_dict[key] = tree\n\t    return out_dict\n"]}
