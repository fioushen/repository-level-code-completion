{"filename": "decodable/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "decodable/config/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "decodable/config/client_config.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom dataclasses import dataclass\n\t@dataclass\n\tclass DecodableClientConfig:\n\t    account_name: str\n\t    access_token: str\n", "    api_url: str\n\t    def decodable_api_url(self) -> str:\n\t        return f\"https://{self.account_name}.{self.api_url}\"\n"]}
{"filename": "decodable/config/profile_reader.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\timport os\n\tfrom pathlib import Path\n\tfrom yaml import SafeLoader, load\n\tfrom typing import Optional\n\tfrom decodable.config.profile import DecodableAccessTokens\n", "DEFAULT_PROFILE_PATH = f\"{str(Path.home())}/.decodable/auth\"\n\tPROFILE_ENV_VARIABLE_NAME = \"DECODABLE_PROFILE\"\n\tclass DecodableProfileReader:\n\t    @staticmethod\n\t    def load_profiles(default_profile_path: str = DEFAULT_PROFILE_PATH) -> DecodableAccessTokens:\n\t        profiles_path = Path(default_profile_path)\n\t        if profiles_path.is_file() is False:\n\t            raise Exception(\n\t                f\"No decodable profile under path: {profiles_path}. Execute 'decodable login' command first\"\n\t            )\n", "        with open(profiles_path, \"r\") as file:\n\t            content = file.read()\n\t            return DecodableProfileReader._load_profile_access_tokens(content)\n\t    @staticmethod\n\t    def get_profile_name(profile_name: Optional[str]) -> Optional[str]:\n\t        if profile_name is not None:\n\t            return profile_name\n\t        else:\n\t            return os.getenv(PROFILE_ENV_VARIABLE_NAME)\n\t    @staticmethod\n", "    def _load_profile_access_tokens(yaml: str) -> DecodableAccessTokens:\n\t        config_data = load(yaml, Loader=SafeLoader)\n\t        access_tokens = {}\n\t        for profile_name in config_data[\"tokens\"]:\n\t            access_tokens[profile_name] = config_data[\"tokens\"][profile_name][\"access_token\"]\n\t        return DecodableAccessTokens(profile_tokens=access_tokens)\n"]}
{"filename": "decodable/config/profile.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom typing import Dict\n\tfrom dataclasses import dataclass\n\t@dataclass(init=True)\n\tclass DecodableAccessTokens:\n\t    profile_tokens: Dict[str, str]\n"]}
{"filename": "decodable/client/types.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom __future__ import annotations\n\timport re\n\tfrom dataclasses import dataclass, field\n\tfrom enum import Enum\n\tfrom typing import List, Optional, Type\n", "@dataclass(frozen=True)\n\tclass FieldType:\n\t    synonyms: List[FieldType] = field(init=False, repr=False, default_factory=lambda: [])\n\t    def __eq__(self, __o: object) -> bool:\n\t        if not issubclass(__o.__class__, FieldType):\n\t            return False\n\t        if __o in self.synonyms:\n\t            return True\n\t        return self.__repr__() == __o.__repr__()\n\t    def __hash__(self) -> int:\n", "        return hash(repr(self))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [\n\t            NotNull,\n\t            StringType,\n\t            BinaryType,\n\t            NumericType,\n\t            DateTimeType,\n\t            CompoundType,\n", "            Boolean,\n\t            Interval,\n\t            Multiset,\n\t            PrimaryKey,\n\t        ]\n\t        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n\t            found = candidate.from_str(type)\n\t            if found:\n\t                break\n", "        return found\n\t@dataclass(frozen=True, eq=False)\n\tclass NotNull(FieldType):\n\t    inner_type: FieldType\n\t    def __repr__(self) -> str:\n\t        return f\"{repr(self.inner_type)} NOT NULL\"\n\t    def __eq__(self, __o: object) -> bool:\n\t        if not isinstance(__o, NotNull):\n\t            return False\n\t        return self.inner_type == __o.inner_type\n", "    def __hash__(self) -> int:\n\t        return super().__hash__()\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"(?P<inner>.*) NOT NULL\", type)\n\t        if not found:\n\t            return None\n\t        inner_type = FieldType.from_str(found[\"inner\"])\n\t        if not inner_type:\n\t            return None\n", "        return cls(inner_type)\n\t@dataclass(frozen=True, eq=False)\n\tclass StringType(FieldType):\n\t    length: int\n\t    is_synonym: bool = False\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [Char, Varchar, String]\n\t        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n", "            found = candidate.from_str(type)\n\t            if found:\n\t                break\n\t        return found\n\t@dataclass(frozen=True, eq=False)\n\tclass Char(StringType):\n\t    def __repr__(self) -> str:\n\t        return f\"CHAR({self.length})\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n", "        found = re.fullmatch(r\"CHAR\\((?P<length>\\d+)\\)\", type)\n\t        if not found:\n\t            return None\n\t        return cls(int(found[\"length\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass Varchar(StringType):\n\t    def __repr__(self) -> str:\n\t        return f\"VARCHAR({self.length})\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym and self.length == String.length:\n", "            self.synonyms.append(String(is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"VARCHAR\\((?P<length>\\d+)\\)\", type)\n\t        if not found:\n\t            return None\n\t        return cls(int(found[\"length\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass String(StringType):\n\t    length: int = 2147483647\n", "    def __repr__(self) -> str:\n\t        return \"STRING\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym:\n\t            self.synonyms.append(Varchar(self.length, is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"STRING\", type)\n\t        if not found:\n\t            return None\n", "        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass BinaryType(FieldType):\n\t    length: int\n\t    is_synonym: bool = False\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [Binary, Varbinary, Bytes]\n\t        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n", "            found = candidate.from_str(type)\n\t            if found:\n\t                break\n\t        return found\n\t@dataclass(frozen=True, eq=False)\n\tclass Binary(BinaryType):\n\t    def __repr__(self) -> str:\n\t        return f\"BINARY({self.length})\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n", "        found = re.fullmatch(r\"BINARY\\((?P<length>\\d+)\\)\", type)\n\t        if not found:\n\t            return None\n\t        return cls(int(found[\"length\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass Varbinary(BinaryType):\n\t    def __repr__(self) -> str:\n\t        return f\"VARBINARY({self.length})\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym and self.length == Bytes.length:\n", "            self.synonyms.append(Bytes(is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"VARBINARY\\((?P<length>\\d+)\\)\", type)\n\t        if not found:\n\t            return None\n\t        return cls(int(found[\"length\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass Bytes(BinaryType):\n\t    length: int = 2147483647\n", "    def __repr__(self) -> str:\n\t        return \"BYTES\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym:\n\t            self.synonyms.append(Varbinary(self.length, is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"BYTES\", type)\n\t        if not found:\n\t            return None\n", "        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass NumericType(FieldType):\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [\n\t            ExactNumericType,\n\t            TinyInt,\n\t            SmallInt,\n\t            Int,\n", "            BigInt,\n\t            Float,\n\t            Double,\n\t        ]\n\t        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n\t            found = candidate.from_str(type)\n\t            if found:\n\t                break\n\t        return found\n", "@dataclass(frozen=True, eq=False)\n\tclass ExactNumericType(NumericType):\n\t    precision: int\n\t    scale: int\n\t    is_synonym: bool = False\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [Decimal, Dec, Numeric]\n\t        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n", "            found = candidate.from_str(type)\n\t            if found:\n\t                break\n\t        return found\n\t@dataclass(frozen=True, eq=False)\n\tclass Decimal(ExactNumericType):\n\t    precision: int = 10\n\t    scale: int = 0\n\t    def __repr__(self) -> str:\n\t        return f\"DECIMAL({self.precision}, {self.scale})\"\n", "    def __post_init__(self):\n\t        if not self.is_synonym:\n\t            self.synonyms.append(Dec(self.precision, self.scale, is_synonym=True))\n\t            self.synonyms.append(Numeric(self.precision, self.scale, is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"DECIMAL(\\((?P<precision>\\d+)(, (?P<scale>\\d+))?\\))?\", type)\n\t        if not found:\n\t            return None\n\t        if not found[\"precision\"]:\n", "            return cls()\n\t        elif not found[\"scale\"]:\n\t            return cls(precision=int(found[\"precision\"]))\n\t        else:\n\t            return cls(precision=int(found[\"precision\"]), scale=int(found[\"scale\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass Dec(ExactNumericType):\n\t    precision: int = 10\n\t    scale: int = 0\n\t    def __repr__(self) -> str:\n", "        return f\"DEC({self.precision}, {self.scale})\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym:\n\t            self.synonyms.append(Decimal(self.precision, self.scale, is_synonym=True))\n\t            self.synonyms.append(Numeric(self.precision, self.scale, is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"DEC(\\((?P<precision>\\d+)(, (?P<scale>\\d+))?\\))?\", type)\n\t        if not found:\n\t            return None\n", "        if not found[\"precision\"]:\n\t            return cls()\n\t        elif not found[\"scale\"]:\n\t            return cls(precision=int(found[\"precision\"]))\n\t        else:\n\t            return cls(precision=int(found[\"precision\"]), scale=int(found[\"scale\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass Numeric(ExactNumericType):\n\t    precision: int = 10\n\t    scale: int = 0\n", "    def __repr__(self) -> str:\n\t        return f\"NUMERIC({self.precision}, {self.scale})\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym:\n\t            self.synonyms.append(Dec(self.precision, self.scale, is_synonym=True))\n\t            self.synonyms.append(Decimal(self.precision, self.scale, is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"NUMERIC(\\((?P<precision>\\d+)(, (?P<scale>\\d+))?\\))?\", type)\n\t        if not found:\n", "            return None\n\t        if not found[\"precision\"]:\n\t            return cls()\n\t        elif not found[\"scale\"]:\n\t            return cls(precision=int(found[\"precision\"]))\n\t        else:\n\t            return cls(precision=int(found[\"precision\"]), scale=int(found[\"scale\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass TinyInt(NumericType):\n\t    def __repr__(self) -> str:\n", "        return \"TINYINT\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"TINYINT\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass SmallInt(NumericType):\n\t    def __repr__(self) -> str:\n", "        return \"SMALLINT\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"SMALLINT\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass Int(NumericType):\n\t    def __repr__(self) -> str:\n", "        return \"INT\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"INT\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass BigInt(NumericType):\n\t    def __repr__(self) -> str:\n", "        return \"BIGINT\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"BIGINT\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass Float(NumericType):\n\t    is_synonym: bool = False\n", "    def __repr__(self) -> str:\n\t        return \"FLOAT\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym:\n\t            self.synonyms.append(Double(is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"FLOAT\", type)\n\t        if not found:\n\t            return None\n", "        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass Double(NumericType):\n\t    is_synonym: bool = False\n\t    def __repr__(self) -> str:\n\t        return \"DOUBLE\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym:\n\t            self.synonyms.append(Float(is_synonym=True))\n\t    @classmethod\n", "    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"DOUBLE\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass DateTimeType(FieldType):\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [Date, Time, TimestampType]\n", "        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n\t            found = candidate.from_str(type)\n\t            if found:\n\t                break\n\t        return found\n\t@dataclass(frozen=True, eq=False)\n\tclass Date(DateTimeType):\n\t    def __repr__(self) -> str:\n\t        return \"DATE\"\n", "    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"DATE\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass Time(DateTimeType):\n\t    precision: int\n\t    def __repr__(self) -> str:\n", "        return f\"TIME({self.precision})\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"TIME\\((?P<precision>\\d+)\\)\", type)\n\t        if not found:\n\t            return None\n\t        return cls(int(found[\"precision\"]))\n\t@dataclass(frozen=True, eq=False)\n\tclass TimestampType(DateTimeType):\n\t    precision: int\n", "    timezone: bool\n\t    is_synonym: bool = False\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [Timestamp, TimestampLocal]\n\t        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n\t            found = candidate.from_str(type)\n\t            if found:\n\t                break\n", "        return found\n\t@dataclass(frozen=True, eq=False)\n\tclass Timestamp(TimestampType):\n\t    timezone: bool = False\n\t    def __repr__(self) -> str:\n\t        if self.timezone:\n\t            w = \"WITH\"\n\t        else:\n\t            w = \"WITHOUT\"\n\t        return f\"TIMESTAMP({self.precision}) {w} TIME ZONE\"\n", "    def __post_init__(self):\n\t        if not self.is_synonym and self.timezone:\n\t            self.synonyms.append(TimestampLocal(self.precision, is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(\n\t            r\"TIMESTAMP\\((?P<precision>\\d+)\\)(?P<timezone_clause> (?P<with_clause>WITH|WITHOUT) TIME ZONE)?\",\n\t            type,\n\t        )\n\t        if not found:\n", "            return None\n\t        timezone: bool\n\t        if not found[\"timezone_clause\"]:\n\t            timezone = False\n\t        else:\n\t            if found[\"with_clause\"] == \"WITH\":\n\t                timezone = True\n\t            else:\n\t                timezone = False\n\t        return cls(precision=int(found[\"precision\"]), timezone=timezone)\n", "@dataclass(frozen=True, eq=False)\n\tclass TimestampLocal(TimestampType):\n\t    timezone: bool = True\n\t    def __repr__(self) -> str:\n\t        return f\"TIMESTAMP_LTZ({self.precision})\"\n\t    def __post_init__(self):\n\t        if not self.is_synonym and self.timezone:\n\t            self.synonyms.append(Timestamp(self.precision, timezone=True, is_synonym=True))\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n", "        found_shorthand = re.fullmatch(r\"TIMESTAMP_LTZ\\((?P<precision>\\d+)\\)\", type)\n\t        found_full_version = re.fullmatch(\n\t            r\"TIMESTAMP\\((?P<precision>\\d+)\\) WITH LOCAL TIME ZONE\", type\n\t        )\n\t        if found_shorthand:\n\t            return cls(int(found_shorthand[\"precision\"]))\n\t        if found_full_version:\n\t            return cls(int(found_full_version[\"precision\"]))\n\t        return None\n\t@dataclass(frozen=True)\n", "class CompoundType(FieldType):\n\t    class ContainerType(Enum):\n\t        ARRAY = 0\n\t        MAP = 1\n\t        ROW = 2\n\t    container_type: ContainerType = field(init=False, repr=False)\n\t    internal_types: List[FieldType] = field(init=False, repr=False, default_factory=lambda: [])\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [ArrayType, Map, Row]\n", "        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n\t            found = candidate.from_str(type)\n\t            if found:\n\t                break\n\t        return found\n\t    def __eq__(self, __o: object) -> bool:\n\t        if not issubclass(__o.__class__, CompoundType):\n\t            return False\n\t        return (\n", "            self.container_type\n\t            == __o.container_type  # pyright: ignore [reportGeneralTypeIssues], we know __o is a CompoundType\n\t            and self.internal_types\n\t            == __o.internal_types  # pyright: ignore [reportGeneralTypeIssues], we know __o is a CompoundType\n\t        )\n\t    def __hash__(self) -> int:\n\t        return super().__hash__()\n\t@dataclass(frozen=True, eq=False)\n\tclass ArrayType(CompoundType):\n\t    container_type: CompoundType.ContainerType = field(\n", "        init=False, repr=False, default=CompoundType.ContainerType.ARRAY\n\t    )\n\t    type: FieldType\n\t    def __post_init__(self):\n\t        self.internal_types.append(self.type)\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        candidates: List[Type[FieldType]] = [Array, TArray]\n\t        found: Optional[FieldType] = None\n\t        for candidate in candidates:\n", "            found = candidate.from_str(type)\n\t            if found:\n\t                break\n\t        return found\n\t@dataclass(frozen=True, eq=False)\n\tclass Array(ArrayType):\n\t    def __repr__(self) -> str:\n\t        return f\"ARRAY<{self.type}>\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n", "        found = re.fullmatch(r\"ARRAY<(?P<inner>.*)>\", type)\n\t        if not found:\n\t            return None\n\t        inner_type = FieldType.from_str(found[\"inner\"])\n\t        if not inner_type:\n\t            return None\n\t        return cls(inner_type)\n\t@dataclass(frozen=True, eq=False)\n\tclass TArray(ArrayType):\n\t    def __repr__(self) -> str:\n", "        return f\"{self.type} ARRAY\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"(?P<inner>.*) ARRAY\", type)\n\t        if not found:\n\t            return None\n\t        inner_type = FieldType.from_str(found[\"inner\"])\n\t        if not inner_type:\n\t            return None\n\t        return cls(inner_type)\n", "@dataclass(frozen=True, eq=False)\n\tclass Map(CompoundType):\n\t    container_type: CompoundType.ContainerType = field(\n\t        init=False, repr=False, default=CompoundType.ContainerType.MAP\n\t    )\n\t    key: FieldType\n\t    value: FieldType\n\t    def __post_init__(self):\n\t        self.internal_types.append(self.key)\n\t        self.internal_types.append(self.value)\n", "    def __repr__(self) -> str:\n\t        return f\"MAP<{self.key}, {self.value}>\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"MAP<(?P<key>.*), (?P<value>.*)>\", type)\n\t        if not found:\n\t            return None\n\t        key_type = FieldType.from_str(found[\"key\"])\n\t        value_type = FieldType.from_str(found[\"value\"])\n\t        if not key_type or not value_type:\n", "            return None\n\t        return cls(key_type, value_type)\n\t@dataclass(frozen=True, eq=False)\n\tclass Row(CompoundType):\n\t    # TODO: Handle ROW types\n\t    container_type: CompoundType.ContainerType = field(\n\t        init=False, repr=False, default=CompoundType.ContainerType.ROW\n\t    )\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n", "        return None\n\t@dataclass(frozen=True, eq=False)\n\tclass PrimaryKey(FieldType):\n\t    inner_type: FieldType\n\t    def __repr__(self) -> str:\n\t        return f\"{self.inner_type} PRIMARY KEY\"\n\t    @classmethod\n\t    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"(?P<type>.*) PRIMARY KEY\", type)\n\t        if not found:\n", "            return None\n\t        inner_type = FieldType.from_str(found[\"type\"])\n\t        if not inner_type:\n\t            return None\n\t        return cls(inner_type)\n\t@dataclass(frozen=True, eq=False)\n\tclass Boolean(FieldType):\n\t    def __repr__(self) -> str:\n\t        return \"BOOLEAN\"\n\t    @classmethod\n", "    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"BOOLEAN\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass Interval(FieldType):\n\t    def __repr__(self) -> str:\n\t        return \"INTERVAL\"\n\t    @classmethod\n", "    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"INTERVAL\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n\t@dataclass(frozen=True, eq=False)\n\tclass Multiset(FieldType):\n\t    def __repr__(self) -> str:\n\t        return \"MULTISET\"\n\t    @classmethod\n", "    def from_str(cls, type: str) -> Optional[FieldType]:\n\t        found = re.fullmatch(r\"MULTISET\", type)\n\t        if not found:\n\t            return None\n\t        return cls()\n"]}
{"filename": "decodable/client/client.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom __future__ import annotations\n\tfrom typing import Any, Dict, Optional, List\n\tfrom typing_extensions import override\n\timport requests\n\tfrom dataclasses import dataclass\n", "from decodable.client.api import Connector, ConnectionType, StartPosition\n\tfrom decodable.client.types import FieldType\n\tfrom decodable.config.client_config import DecodableClientConfig\n\t@dataclass\n\tclass ApiResponse:\n\t    items: List[Any]\n\t    next_page_token: Optional[str]\n\t@dataclass\n\tclass PreviewResponse:\n\t    id: str\n", "    output_stream_type: str\n\t    results: List[Dict[str, Any]]\n\t    next_token: str\n\t    @classmethod\n\t    def from_dict(cls, response: Dict[str, Any]) -> PreviewResponse:\n\t        return cls(\n\t            id=response[\"id\"],\n\t            output_stream_type=response[\"output_stream_type\"],\n\t            results=response[\"results\"],\n\t            next_token=response[\"next_token\"],\n", "        )\n\tclass DecodableAPIException(Exception):\n\t    @classmethod\n\t    def category(cls) -> str:\n\t        return \"DecodableAPIException\"\n\t    @override\n\t    def __str__(self) -> str:\n\t        return f\"Decodable: {self.category()}: {self.args[0]}\"\n\tclass InvalidRequest(DecodableAPIException):\n\t    @classmethod\n", "    def category(cls) -> str:\n\t        return \"InvalidRequest\"\n\tclass ResourceAlreadyExists(DecodableAPIException):\n\t    @classmethod\n\t    def category(cls) -> str:\n\t        return \"ResourceAlreadyExists\"\n\tclass ResourceNotFound(DecodableAPIException):\n\t    @classmethod\n\t    def category(cls) -> str:\n\t        return \"ResourceNotFound\"\n", "def raise_api_exception(code: int, reason: str):\n\t    if code == 400:\n\t        raise InvalidRequest(reason)\n\t    elif code == 404:\n\t        raise ResourceNotFound(reason)\n\t    elif code == 409:\n\t        raise ResourceAlreadyExists(reason)\n\t    else:\n\t        raise DecodableAPIException(reason)\n\t@dataclass\n", "class SchemaField:\n\t    name: str\n\t    type: FieldType\n\t    def __hash__(self) -> int:\n\t        res = hash(self.name)\n\t        res ^= hash(self.type)\n\t        return res\n\tclass DecodableApiClient:\n\t    config: DecodableClientConfig\n\t    def __init__(self, config: DecodableClientConfig):\n", "        self.config = config\n\t    def test_connection(self) -> requests.Response:\n\t        response = requests.get(\n\t            url=f\"{self.config.decodable_api_url()}/streams\",\n\t            headers={\n\t                \"accept\": \"application/json\",\n\t                \"authorization\": f\"Bearer {self.config.access_token}\",\n\t            },\n\t        )\n\t        return response\n", "    def list_streams(self) -> ApiResponse:\n\t        response = self._get_api_request(\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/streams\",\n\t        )\n\t        return self._parse_response(response.json())\n\t    def get_stream_id(self, name: str) -> Optional[str]:\n\t        streams = self.list_streams().items\n\t        stream_id = None\n\t        for stream in streams:\n\t            if stream[\"name\"] == name:\n", "                stream_id = stream[\"id\"]\n\t        return stream_id\n\t    def get_stream_information(self, stream_id: str) -> Dict[str, Any]:\n\t        endpoint_url = f\"{self.config.decodable_api_url()}/streams/{stream_id}\"\n\t        response = requests.get(\n\t            url=endpoint_url,\n\t            headers={\n\t                \"accept\": \"application/json\",\n\t                \"authorization\": f\"Bearer {self.config.access_token}\",\n\t            },\n", "        )\n\t        if response.ok:\n\t            return response.json()\n\t        else:\n\t            raise_api_exception(response.status_code, response.json())\n\t    def get_stream_from_sql(self, sql: str) -> Dict[str, Any]:\n\t        payload = {\"sql\": sql}\n\t        return self._post_api_request(\n\t            payload=payload,\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/pipelines/outputStream\",\n", "        ).json()\n\t    def create_stream(\n\t        self, name: str, schema_fields: List[SchemaField], watermark: Optional[str] = None\n\t    ) -> ApiResponse:\n\t        payload = {\n\t            \"schema\": [{\"name\": field.name, \"type\": repr(field.type)} for field in schema_fields],\n\t            \"name\": name,\n\t        }\n\t        if watermark:\n\t            payload[\"watermark\"] = watermark\n", "        return self._post_api_request(\n\t            payload=payload, endpoint_url=f\"{self.config.decodable_api_url()}/streams\"\n\t        ).json()\n\t    def update_stream(self, stream_id: str, props: Dict[str, Any]) -> ApiResponse:\n\t        endpoint_url = f\"{self.config.decodable_api_url()}/streams/{stream_id}\"\n\t        return self._patch_api_request(payload=props, endpoint_url=endpoint_url).json()\n\t    def delete_stream(self, stream_id: str) -> None:\n\t        return self._delete_api_request(\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/streams/{stream_id}\"\n\t        )\n", "    def clear_stream(self, stream_id: str) -> None:\n\t        self._post_api_request(\n\t            payload={}, endpoint_url=f\"{self.config.decodable_api_url()}/streams/{stream_id}/clear\"\n\t        )\n\t    def list_pipelines(self) -> ApiResponse:\n\t        response = self._get_api_request(\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/pipelines\",\n\t        )\n\t        return self._parse_response(response.json())\n\t    def get_pipeline_id(self, name: str) -> Optional[str]:\n", "        pipelines = self.list_pipelines().items\n\t        pipeline_id = None\n\t        for pipeline in pipelines:\n\t            if pipeline[\"name\"] == name:\n\t                pipeline_id = pipeline[\"id\"]\n\t        return pipeline_id\n\t    def get_pipeline_information(self, pipeline_id: str) -> Dict[str, Any]:\n\t        endpoint_url = f\"{self.config.decodable_api_url()}/pipelines/{pipeline_id}\"\n\t        response = requests.get(\n\t            url=endpoint_url,\n", "            headers={\n\t                \"accept\": \"application/json\",\n\t                \"authorization\": f\"Bearer {self.config.access_token}\",\n\t            },\n\t        )\n\t        if response.ok:\n\t            return response.json()\n\t        else:\n\t            raise_api_exception(response.status_code, response.json())\n\t    def get_associated_streams(self, pipeline_id: str) -> ApiResponse:\n", "        response = self._get_api_request(\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/pipelines/{pipeline_id}/streams\"\n\t        )\n\t        return self._parse_response(response.json())\n\t    def create_pipeline(self, sql: str, name: str, description: str) -> Dict[str, Any]:\n\t        payload = {\n\t            \"sql\": sql,\n\t            \"name\": name,\n\t            \"description\": description,\n\t        }\n", "        return self._post_api_request(\n\t            payload=payload, endpoint_url=f\"{self.config.decodable_api_url()}/pipelines\"\n\t        ).json()\n\t    def update_pipeline(self, pipeline_id: str, props: Dict[str, Any]) -> Any:\n\t        return self._patch_api_request(\n\t            payload=props,\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/pipelines/{pipeline_id}\",\n\t        ).json()\n\t    def activate_pipeline(self, pipeline_id: str) -> Dict[str, Any]:\n\t        return self._post_api_request(\n", "            payload={},\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/pipelines/{pipeline_id}/activate\",\n\t        ).json()\n\t    def deactivate_pipeline(self, pipeline_id: str) -> Dict[str, Any]:\n\t        return self._post_api_request(\n\t            payload={},\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/pipelines/{pipeline_id}/deactivate\",\n\t        ).json()\n\t    def delete_pipeline(self, pipeline_id: str) -> None:\n\t        return self._delete_api_request(\n", "            endpoint_url=f\"{self.config.decodable_api_url()}/pipelines/{pipeline_id}\"\n\t        )\n\t    def create_preview(\n\t        self,\n\t        sql: str,\n\t        preview_start: StartPosition = StartPosition.LATEST,\n\t        input_streams: List[str] = [],\n\t    ) -> PreviewResponse:\n\t        payload = {\n\t            \"sql\": sql,\n", "            \"support_change_stream\": True,\n\t            \"start_positions\": {\n\t                stream: {\"type\": \"TAG\", \"value\": preview_start.value} for stream in input_streams\n\t            },\n\t        }\n\t        response = self._post_api_request(\n\t            payload=payload, endpoint_url=f\"{self.config.decodable_api_url()}/preview\"\n\t        )\n\t        return PreviewResponse.from_dict(response.json())\n\t    def run_preview(self, id: str, token: str) -> PreviewResponse:\n", "        response = self._get_api_request(\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/preview/{id}?token={token}\"\n\t        )\n\t        return PreviewResponse.from_dict(response.json())\n\t    def get_preview_dependencies(self, sql: str) -> Dict[str, Any]:\n\t        payload = {\"sql\": sql}\n\t        return self._post_api_request(\n\t            payload=payload, endpoint_url=f\"{self.config.decodable_api_url()}/preview/dependencies\"\n\t        ).json()\n\t    def list_connections(self) -> ApiResponse:\n", "        response = self._get_api_request(\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/connections\",\n\t        )\n\t        return self._parse_response(response.json())\n\t    def get_connection_id(self, name: str) -> Optional[str]:\n\t        connections = self.list_connections().items\n\t        conn_id = None\n\t        for conn in connections:\n\t            if conn[\"name\"] == name:\n\t                conn_id = conn[\"id\"]\n", "                break\n\t        return conn_id\n\t    def create_connection(\n\t        self,\n\t        name: str,\n\t        schema: List[SchemaField],\n\t        stream: Optional[str] = None,\n\t        connector: Connector = Connector.REST,\n\t        connection_type: ConnectionType = ConnectionType.SOURCE,\n\t    ) -> Dict[str, Any]:\n", "        if not stream:\n\t            stream = name\n\t        payload = {\n\t            \"name\": name,\n\t            \"connector\": connector.value,\n\t            \"type\": connection_type.value,\n\t            \"schema\": [{\"name\": field.name, \"type\": repr(field.type)} for field in schema],\n\t        }\n\t        return self._post_api_request(\n\t            payload=payload,\n", "            endpoint_url=f\"{self.config.decodable_api_url()}/connections?stream_name={stream}\",\n\t        ).json()\n\t    def activate_connection(self, conn_id: str) -> Dict[str, Any]:\n\t        return self._post_api_request(\n\t            payload={},\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/connections/{conn_id}/activate\",\n\t        ).json()\n\t    def deactivate_connection(self, conn_id: str) -> Dict[str, Any]:\n\t        return self._post_api_request(\n\t            payload={},\n", "            endpoint_url=f\"{self.config.decodable_api_url()}/connections/{conn_id}/deactivate\",\n\t        ).json()\n\t    def delete_connection(self, conn_id: str):\n\t        self._delete_api_request(\n\t            endpoint_url=f\"{self.config.decodable_api_url()}/connections/{conn_id}\"\n\t        )\n\t    def send_events(self, id: str, events: List[Dict[str, Any]]) -> int:\n\t        payload = {\"events\": events}\n\t        response = self._post_api_request(\n\t            payload=payload,\n", "            endpoint_url=f\"{self.config.decodable_api_url()}/connections/{id}/events\",\n\t        ).json()\n\t        return response[\"count\"]\n\t    def _parse_response(self, result: Any) -> ApiResponse:\n\t        return ApiResponse(items=result[\"items\"], next_page_token=result[\"next_page_token\"])\n\t    def _post_api_request(self, payload: Any, endpoint_url: str) -> requests.Response:\n\t        response = requests.post(\n\t            url=endpoint_url,\n\t            json=payload,\n\t            headers={\n", "                \"accept\": \"application/json\",\n\t                \"content-type\": \"application/json\",\n\t                \"authorization\": f\"Bearer {self.config.access_token}\",\n\t            },\n\t        )\n\t        if response.ok:\n\t            return response\n\t        else:\n\t            raise_api_exception(response.status_code, response.json())\n\t    def _patch_api_request(self, payload: Any, endpoint_url: str) -> requests.Response:\n", "        response = requests.patch(\n\t            url=endpoint_url,\n\t            json=payload,\n\t            headers={\n\t                \"accept\": \"application/json\",\n\t                \"content-type\": \"application/json\",\n\t                \"authorization\": f\"Bearer {self.config.access_token}\",\n\t            },\n\t        )\n\t        if response.ok:\n", "            return response\n\t        else:\n\t            raise_api_exception(response.status_code, response.json())\n\t    def _get_api_request(self, endpoint_url: str) -> requests.Response:\n\t        response = requests.get(\n\t            url=endpoint_url,\n\t            headers={\n\t                \"accept\": \"application/json\",\n\t                \"authorization\": f\"Bearer {self.config.access_token}\",\n\t            },\n", "        )\n\t        if response.ok:\n\t            return response\n\t        else:\n\t            raise_api_exception(response.status_code, response.json())\n\t    def _delete_api_request(self, endpoint_url: str) -> None:\n\t        response = requests.delete(\n\t            url=endpoint_url,\n\t            headers={\n\t                \"accept\": \"application/json\",\n", "                \"authorization\": f\"Bearer {self.config.access_token}\",\n\t            },\n\t        )\n\t        if not response.ok:\n\t            raise_api_exception(response.status_code, response.json())\n"]}
{"filename": "decodable/client/client_factory.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom typing import Optional\n\tfrom decodable.client.client import DecodableApiClient\n\tfrom decodable.config.client_config import DecodableClientConfig\n\tfrom decodable.config.profile_reader import DecodableProfileReader\n\tclass DecodableClientFactory:\n", "    @staticmethod\n\t    def create_client(\n\t        api_url: str,\n\t        profile_name: Optional[str] = \"default\",\n\t        decodable_account_name: Optional[str] = None,\n\t    ) -> DecodableApiClient:\n\t        if decodable_account_name is None:\n\t            raise Exception(\"Undefined Decodable account name. Update DBT profile\")\n\t        profile_access_tokens = DecodableProfileReader.load_profiles()\n\t        if profile_name not in profile_access_tokens.profile_tokens:\n", "            raise Exception(\n\t                f\"Undefined '{profile_name} in decodable profile file ~/.decodable/auth\"\n\t            )\n\t        access_token = profile_access_tokens.profile_tokens[profile_name]\n\t        return DecodableApiClient(\n\t            config=DecodableClientConfig(\n\t                access_token=access_token, account_name=decodable_account_name, api_url=api_url\n\t            )\n\t        )\n"]}
{"filename": "decodable/client/api.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom enum import Enum\n\tclass StartPosition(Enum):\n\t    EARLIEST = \"earliest\"\n\t    LATEST = \"latest\"\n\tclass Connector(Enum):\n", "    DATAGEN = \"datagen\"\n\t    KAFKA = \"kafka\"\n\t    KINESIS = \"kinesis\"\n\t    REST = \"rest\"\n\t    S3 = \"s3\"\n\tclass ConnectionType(Enum):\n\t    SOURCE = \"source\"\n\t    SINK = \"sink\"\n"]}
{"filename": "decodable/client/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "tests/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\timport pytest\n\timport os\n\tpytest_plugins = [\"dbt.tests.fixtures.project\"]\n\t# The profile dictionary, used to write out profiles.yml\n\t@pytest.fixture(scope=\"class\")  # pyright: ignore [reportUntypedFunctionDecorator]\n", "def dbt_profile_target():\n\t    return {\n\t        \"type\": \"decodable\",\n\t        \"database\": \"\",\n\t        \"schema\": \"\",\n\t        \"account_name\": os.getenv(\"DECODABLE_ACCOUNT_NAME\", \"test_account\"),\n\t        \"profile_name\": os.getenv(\"DECODABLE_PROFILE_NAME\", \"test_profile\"),\n\t        \"local_namespace\": \"functional_tests\",\n\t    }\n"]}
{"filename": "tests/functional/adapter/simple/test_simple_project.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom typing import Any, List\n\timport pytest\n\tfrom dbt.tests.util import run_dbt  # pyright: ignore [reportMissingImports]\n\tfrom fixtures import (\n\t    my_seed_csv,\n", "    my_model_sql,\n\t    my_model_yml,\n\t)\n\tclass TestSimpleProject:\n\t    @pytest.fixture(scope=\"class\")\n\t    def project_config_update(self):\n\t        return {\"name\": \"simple\", \"models\": {\"+materialized\": \"table\"}}\n\t    @pytest.fixture(scope=\"class\")\n\t    def seeds(self):\n\t        return {\n", "            \"my_seed.csv\": my_seed_csv,\n\t        }\n\t    @pytest.fixture(scope=\"class\")\n\t    def models(self):\n\t        return {\n\t            \"my_model.sql\": my_model_sql,\n\t            \"my_model.yml\": my_model_yml,\n\t        }\n\t    def test_run_seed_test(self, project: Any):\n\t        \"\"\"\n", "        Seed, then run, then test. Perform cleanup at the end,\n\t        so that nothing persists on Decodbale.\n\t        \"\"\"\n\t        # seed seeds\n\t        results: List[Any] = run_dbt([\"seed\"])\n\t        assert len(results) == 1\n\t        # run models\n\t        results = run_dbt([\"run\"])\n\t        assert len(results) == 1\n\t        # test tests\n", "        results = run_dbt([\"test\"])\n\t        assert len(results) == 1\n\t        # validate that the results include one pass and one failure\n\t        assert results[0].status == \"pass\"\n\t        # Decodable cleanup\n\t        run_dbt([\"run-operation\", \"cleanup\"])\n"]}
{"filename": "tests/functional/adapter/simple/fixtures.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\t# seeds/my_seed.csv\n\tmy_seed_csv = \"\"\"\n\tname,age\n\tAdam,31\n\tGeorge,27\n", "Lily,59\n\t\"\"\".lstrip()\n\t# models/my_model.sql\n\tmy_model_sql = \"\"\"\n\tselect CHAR_LENGTH(name) as name_length from {{ ref('my_seed') }}\n\t\"\"\"\n\t# models/my_model.yml\n\tmy_model_yml = \"\"\"\n\tversion: 2\n\tmodels:\n", "  - name: my_model\n\t    columns:\n\t      - name: name_length\n\t        tests:\n\t          - not_null\n\t\"\"\"\n"]}
{"filename": "tests/unit/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "tests/unit/decodable/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "tests/unit/decodable/config/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "tests/unit/decodable/config/test_profile_reader.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\timport os\n\tfrom unittest import mock\n\tfrom decodable.config.profile import DecodableAccessTokens\n\tfrom decodable.config.profile_reader import DecodableProfileReader, PROFILE_ENV_VARIABLE_NAME\n\tTEST_PROFILE_NAME = \"default\"\n", "TEST_PROFILE_ACCESS_TOKEN = \"yyy\"\n\tclass TestProfileAdapter:\n\t    \"\"\"Test getting profile name from env variable\"\"\"\n\t    @mock.patch.dict(os.environ, {PROFILE_ENV_VARIABLE_NAME: \"test\"})\n\t    def test_get_profile_name(self):\n\t        assert DecodableProfileReader.get_profile_name(profile_name=None) == \"test\"\n\t        assert DecodableProfileReader.get_profile_name(profile_name=\"default\") == \"default\"\n\t    \"\"\"Test loading default profile\"\"\"\n\t    def test_load_default_profile(self):\n\t        test_profile: DecodableAccessTokens = DecodableProfileReader.load_profiles(\n", "            f\"{os.path.dirname(__file__)}/test_profile.yml\"\n\t        )\n\t        assert test_profile.profile_tokens[TEST_PROFILE_NAME] == TEST_PROFILE_ACCESS_TOKEN\n"]}
{"filename": "tests/unit/decodable/client/test_types.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom decodable.client import types\n\tclass TestTypes:\n\t    def test_concrete_type_from_str(self):\n\t        t = types.Char.from_str(\"CHAR(15)\")\n\t        assert t == types.Char(15)\n", "        t = types.Char.from_str(\"CHAR()\")\n\t        assert t is None\n\t        t = types.Char.from_str(\"Char(10)\")\n\t        assert t is None\n\t        t = types.Timestamp.from_str(\"TIMESTAMP(15) WITH TIME ZONE\")\n\t        assert t == types.Timestamp(precision=15, timezone=True)\n\t        t = types.TimestampLocal.from_str(\"TIMESTAMP(3) WITH LOCAL TIME ZONE\")\n\t        assert t == types.TimestampLocal(precision=3)\n\t    def test_from_str_dispatch(self):\n\t        str_types = [\"DECIMAL\", \"STRING\", \"ARRAY<CHAR(1)>\", \"VARBINAR\", \"TIMESTAMP(3)\"]\n", "        expected = [\n\t            types.Decimal(),\n\t            types.String(),\n\t            types.Array(types.Char(1)),\n\t            None,\n\t            types.Timestamp(precision=3, timezone=False),\n\t        ]\n\t        for a, b in zip(str_types, expected):\n\t            assert types.FieldType.from_str(a) == b\n\t    def test_from_str_defaults(self):\n", "        a = types.FieldType.from_str(\"DECIMAL\")\n\t        b = types.FieldType.from_str(\"DECIMAL(10)\")\n\t        c = types.FieldType.from_str(\"DECIMAL(10, 0)\")\n\t        assert a == b\n\t        assert b == c\n\t        assert c == a\n\t    def test_synonyms_equality(self):\n\t        assert types.Decimal() == types.Dec()\n\t        assert types.Numeric(15, 3) == types.Decimal(15, 3)\n\t        assert types.Decimal(5, 1) != types.Numeric(3, 1)\n", "        assert types.Varbinary(types.Bytes.length) == types.Bytes()\n\t        assert types.Varbinary(100) != types.Bytes()\n\t        assert types.Array(types.Decimal()) == types.TArray(types.Decimal())\n\t        assert types.Array(types.Decimal()) != types.TArray(types.String())\n\t        assert types.Array(types.Decimal()) == types.Array(types.Numeric())\n\t        assert types.Array(types.Decimal()) == types.TArray(types.Numeric())\n\t        assert types.NotNull(types.Decimal()) == types.NotNull(types.Numeric())\n\t        assert types.NotNull(types.Array(types.Dec())) == types.NotNull(\n\t            types.TArray(types.Decimal())\n\t        )\n", "        assert types.NotNull(types.Array(types.String())) != types.NotNull(\n\t            types.Array(types.Boolean())\n\t        )\n\t        assert types.NotNull(types.Array(types.Bytes())) != types.Bytes()\n"]}
{"filename": "tests/unit/decodable/client/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
{"filename": "dbt/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom pkgutil import extend_path\n\t__path__ = extend_path(__path__, __name__)\n"]}
{"filename": "dbt/adapters/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom pkgutil import extend_path\n\t__path__ = extend_path(__path__, __name__)\n"]}
{"filename": "dbt/adapters/decodable/impl.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom dataclasses import dataclass\n\tfrom typing import Any, ContextManager, Dict, Hashable, List, Optional, Set, Type\n\tfrom agate.table import Table as AgateTable\n\tfrom dbt.adapters.base import BaseAdapter, BaseRelation, Column\n\tfrom dbt.contracts.connection import Connection\n", "from dbt.contracts.graph.manifest import Manifest\n\tfrom dbt.contracts.graph.parsed import ParsedNode\n\tfrom dbt.adapters.base.meta import available\n\tfrom dbt.contracts.relation import RelationType\n\tfrom dbt.events import AdapterLogger\n\tfrom dbt.exceptions import (\n\t    NotImplementedException,\n\t    raise_compiler_error,\n\t    raise_database_error,\n\t    raise_parsing_error,\n", ")\n\tfrom dbt.adapters.decodable.connections import (\n\t    DecodableAdapterConnectionManager,\n\t    DecodableAdapterCredentials,\n\t)\n\tfrom dbt.adapters.decodable.handler import DecodableHandler\n\tfrom dbt.adapters.decodable.relation import DecodableRelation\n\tfrom dbt.adapters.protocol import AdapterConfig\n\tfrom decodable.client.client import DecodableApiClient, SchemaField\n\tfrom decodable.client.types import (\n", "    FieldType,\n\t    PrimaryKey,\n\t    String,\n\t    Boolean,\n\t    TimestampLocal,\n\t    Date,\n\t    Time,\n\t    Decimal,\n\t)\n\t@dataclass\n", "class DecodableConfig(AdapterConfig):\n\t    watermark: Optional[str] = None\n\tclass DecodableAdapter(BaseAdapter):\n\t    \"\"\"\n\t    Controls actual implmentation of adapter, and ability to override certain methods.\n\t    \"\"\"\n\t    Relation: Type[DecodableRelation] = DecodableRelation\n\t    AdapterSpecificConfigs: Type[AdapterConfig] = DecodableConfig\n\t    ConnectionManager = DecodableAdapterConnectionManager\n\t    connections: DecodableAdapterConnectionManager\n", "    logger = AdapterLogger(\"Decodable\")\n\t    # AdapterProtocol impl\n\t    def set_query_header(self, manifest: Manifest) -> None:\n\t        raise NotImplementedError()\n\t    @staticmethod\n\t    def get_thread_identifier() -> Hashable:\n\t        raise NotImplementedError()\n\t    def get_thread_connection(self) -> Connection:\n\t        return self.connections.get_thread_connection()\n\t    def set_thread_connection(self, conn: Connection) -> None:\n", "        self.set_thread_connection(conn)\n\t    def get_if_exists(self) -> Optional[Connection]:\n\t        raise NotImplementedError()\n\t    def clear_thread_connection(self) -> None:\n\t        self.connections.clear_thread_connection()\n\t    def exception_handler(self, sql: str) -> ContextManager[Any]:\n\t        raise NotImplementedError()\n\t    def set_connection_name(self, name: Optional[str] = None) -> Connection:\n\t        return self.connections.set_connection_name(name)\n\t    def cancel_open(self) -> Optional[List[str]]:\n", "        raise NotImplementedError()\n\t    @classmethod\n\t    def open(cls, connection: Connection) -> Connection:\n\t        raise NotImplementedError()\n\t    def release(self) -> None:\n\t        raise NotImplementedError()\n\t    def cleanup_all(self) -> None:\n\t        raise NotImplementedError()\n\t    def begin(self) -> None:\n\t        raise NotImplementedError()\n", "    def commit(self) -> None:\n\t        raise NotImplementedError()\n\t    @classmethod\n\t    def close(cls, connection: Connection) -> Connection:\n\t        raise NotImplementedError()\n\t    # AdapterProtocol impl end\n\t    @classmethod\n\t    def date_function(cls):\n\t        \"\"\"\n\t        Returns canonical date func\n", "        \"\"\"\n\t        return \"datenow()\"\n\t    @classmethod\n\t    def convert_text_type(cls, agate_table: AgateTable, col_idx: int) -> str:\n\t        return repr(String())\n\t    @classmethod\n\t    def convert_number_type(cls, agate_table: AgateTable, col_idx: int) -> str:\n\t        return repr(Decimal())\n\t    @classmethod\n\t    def convert_boolean_type(cls, agate_table: AgateTable, col_idx: int) -> str:\n", "        return repr(Boolean())\n\t    @classmethod\n\t    def convert_datetime_type(cls, agate_table: AgateTable, col_idx: int) -> str:\n\t        return repr(TimestampLocal(3))\n\t    @classmethod\n\t    def convert_date_type(cls, agate_table: AgateTable, col_idx: int) -> str:\n\t        return repr(Date())\n\t    @classmethod\n\t    def convert_time_type(cls, agate_table: AgateTable, col_idx: int) -> str:\n\t        return repr(Time(3))\n", "    @classmethod\n\t    def is_cancelable(cls) -> bool:\n\t        return False\n\t    def list_schemas(self, database: str) -> List[str]:\n\t        return []\n\t    @available.parse_none\n\t    def create_schema(self, relation: BaseRelation):\n\t        pass\n\t    @available.parse_none\n\t    def drop_schema(self, relation: BaseRelation):\n", "        \"\"\"Drop the given schema (and everything in it) if it exists.\"\"\"\n\t        pass\n\t        # raise NotImplementedException(\"`drop_schema` is not implemented for this adapter!\")\n\t    @available\n\t    @classmethod\n\t    def quote(cls, identifier: str) -> str:\n\t        \"\"\"Quote the given identifier, as appropriate for the database.\"\"\"\n\t        return f\"`{identifier}`\"\n\t    @available.parse_none\n\t    def drop_relation(self, relation: BaseRelation) -> None:\n", "        \"\"\"Drop the given relation.\n\t        *Implementors must call self.cache.drop() to preserve cache state!*\n\t        \"\"\"\n\t        self.cache_dropped(relation)\n\t        if relation.type is None:\n\t            raise_compiler_error(f\"Tried to drop relation {relation}, but its type is null.\")\n\t        if relation.identifier is None:\n\t            return\n\t        client = self._client()\n\t        self.logger.debug(f\"Dropping pipeline '{relation}'...\")\n", "        pipeline_id = client.get_pipeline_id(relation.render())\n\t        if pipeline_id:\n\t            pipe_info = client.get_pipeline_information(pipeline_id)\n\t            if pipe_info[\"actual_state\"] == \"RUNNING\" or pipe_info[\"target_state\"] == \"RUNNING\":\n\t                client.deactivate_pipeline(pipeline_id)\n\t            client.delete_pipeline(pipeline_id)\n\t            self.logger.debug(f\"Pipeline '{relation}' deleted successfully\")\n\t        self.logger.debug(f\"Dropping stream '{relation}'...\")\n\t        stream_id = client.get_stream_id(relation.render())\n\t        if not stream_id:\n", "            return\n\t        # We need to first delete any pipelines that rely on this stream as their source\n\t        pipelines = client.list_pipelines().items\n\t        for pipeline in pipelines:\n\t            pipe_id = pipeline[\"id\"]\n\t            streams = client.get_associated_streams(pipe_id).items\n\t            should_delete = False\n\t            for stream in streams:\n\t                if stream[\"is_source\"] and stream[\"stream_id\"] == stream_id:\n\t                    should_delete = True\n", "                    break\n\t            if not should_delete:\n\t                continue\n\t            pipe_info = client.get_pipeline_information(pipe_id)\n\t            # TODO: Reference cache\n\t            self.drop_relation(\n\t                self.Relation.create(\n\t                    database=relation.database,\n\t                    schema=relation.schema,\n\t                    identifier=pipe_info[\"name\"],\n", "                    type=RelationType.Table,\n\t                )\n\t            )\n\t        client.delete_stream(stream_id)\n\t        self.logger.debug(f\"Stream '{relation}' deleted successfully\")\n\t    @available.parse_none\n\t    def truncate_relation(self, relation: BaseRelation) -> None:\n\t        \"\"\"Truncate the given relation.\"\"\"\n\t        if not relation.identifier:\n\t            raise_compiler_error(\"Cannot truncate an unnamed relation\")\n", "        client = self._client()\n\t        stream_id = client.get_stream_id(relation.render())\n\t        if not stream_id:\n\t            raise_database_error(\n\t                f\"Error clearing stream `{relation.render()}`: stream doesn't exist\"\n\t            )\n\t        client.clear_stream(stream_id)\n\t    @available.parse_none\n\t    def rename_relation(self, from_relation: BaseRelation, to_relation: BaseRelation) -> None:\n\t        \"\"\"Rename the relation from from_relation to to_relation.\n", "        Implementors must call self.cache.rename() to preserve cache state.\n\t        \"\"\"\n\t        client = self._client()\n\t        self.cache_renamed(from_relation, to_relation)\n\t        if not from_relation.identifier:\n\t            raise_compiler_error(\"Cannot rename an unnamed relation\")\n\t        stream_id = client.get_stream_id(from_relation.render())\n\t        if not stream_id:\n\t            raise_database_error(f\"Cannot rename '{from_relation}': stream does not exist\")\n\t        if not to_relation.identifier:\n", "            raise_compiler_error(f\"Cannot rename relation {from_relation} to nothing\")\n\t        client.update_stream(stream_id=stream_id, props={\"name\": to_relation.render()})\n\t        self.logger.debug(f\"Renamed stream '{from_relation}' to '{to_relation}'\")\n\t        pipeline_id = client.get_pipeline_id(from_relation.render())\n\t        if not pipeline_id:\n\t            raise_database_error(\n\t                f\"Cannot rename '{from_relation.render()}': pipeline does not exist\"\n\t            )\n\t        pipe_info = client.get_pipeline_information(pipeline_id)\n\t        if not pipe_info[\"sql\"]:\n", "            raise_database_error(\n\t                f\"Cannot rename relation '{from_relation}': pipeline returned no sql\"\n\t            )\n\t        sql: str = pipe_info[\"sql\"]\n\t        client.update_pipeline(\n\t            pipeline_id=pipeline_id,\n\t            props={\n\t                \"name\": to_relation.render(),\n\t                \"sql\": self._replace_sink(from_relation, to_relation, sql),\n\t                \"description\": self._pipeline_description(to_relation),\n", "            },\n\t        )\n\t        self.logger.debug(f\"Renamed pipeline '{from_relation}' to '{to_relation}'\")\n\t        # Update the sql for any pipelines that had `from_relation` as an inbound stream\n\t        renamed_sources: int = 0\n\t        pipelines = client.list_pipelines().items\n\t        for pipeline in pipelines:\n\t            pipe_id = pipeline[\"id\"]\n\t            streams = client.get_associated_streams(pipe_id).items\n\t            should_update = False\n", "            for stream in streams:\n\t                if stream[\"is_source\"] and stream[\"stream_id\"] == stream_id:\n\t                    should_update = True\n\t                    break\n\t            if not should_update:\n\t                continue\n\t            pipe_info = client.get_pipeline_information(pipe_id)\n\t            if pipe_info[\"sql\"]:\n\t                client.update_pipeline(\n\t                    pipeline_id=pipe_id,\n", "                    props={\n\t                        \"sql\": self._replace_source(from_relation, to_relation, pipe_info[\"sql\"])\n\t                    },\n\t                )\n\t                renamed_sources += 1\n\t        self.logger.debug(\n\t            f\"Renamed sources from '{from_relation}' to '{to_relation}' in {renamed_sources} pipelines\"\n\t        )\n\t    def expand_column_types(self, goal: BaseRelation, current: BaseRelation) -> None:\n\t        \"\"\"Expand the current table's types to match the goal table. (passable)\n", "        :param self.Relation goal: A relation that currently exists in the\n\t            database with columns of the desired types.\n\t        :param self.Relation current: A relation that currently exists in the\n\t            database with columns of unspecified types.\n\t        \"\"\"\n\t        raise NotImplementedException(\n\t            \"`expand_target_column_types` is not implemented for this adapter!\"\n\t        )\n\t    def list_relations_without_caching(self, schema_relation: BaseRelation) -> List[BaseRelation]:\n\t        relations: List[BaseRelation] = []\n", "        stream_list: List[Dict[str, Any]] = self._client().list_streams().items\n\t        for stream in stream_list:\n\t            relations.append(\n\t                self.Relation.create(\n\t                    database=schema_relation.database,\n\t                    schema=schema_relation.schema,\n\t                    identifier=stream[\"name\"],\n\t                    type=RelationType.Table,\n\t                )\n\t            )\n", "        return relations\n\t    @available.parse_list\n\t    def get_columns_in_relation(\n\t        self,\n\t        relation: BaseRelation,\n\t    ) -> List[Column]:\n\t        columns: List[Column] = []\n\t        if not relation.identifier:\n\t            return []\n\t        stream_info = self._client().get_stream_information(stream_id=relation.render())\n", "        for schema_column in stream_info[\"schema\"]:\n\t            columns.append(\n\t                Column.create(name=schema_column[\"name\"], label_or_dtype=schema_column[\"type\"])\n\t            )\n\t        return columns\n\t    @available\n\t    def has_changed(\n\t        self,\n\t        sql: str,\n\t        relation: BaseRelation,\n", "        watermark: Optional[str] = None,\n\t        primary_key: Optional[str] = None,\n\t    ) -> bool:\n\t        client = self._client()\n\t        new_pipe_sql = self._wrap_as_pipeline(relation.render(), sql)\n\t        fields: List[Dict[str, str]] = client.get_stream_from_sql(new_pipe_sql)[\"schema\"]\n\t        schema: List[SchemaField]\n\t        try:\n\t            schema = self._schema_from_json(fields)\n\t            # The API returns the current primary key field. For the to-be value in this comparison, we set it to\n", "            # the field specified via config.\n\t            self._remove_primary_key(schema)\n\t            if primary_key:\n\t                self._set_primary_key(primary_key, schema)\n\t        except Exception as err:\n\t            raise_compiler_error(f\"Error checking changes to the '{relation}' stream: {err}\")\n\t        pipe_id = client.get_pipeline_id(relation.render())\n\t        if not pipe_id:\n\t            return True\n\t        pipe_info = client.get_pipeline_information(pipe_id)\n", "        stream_id = client.get_stream_id(relation.render())\n\t        if not stream_id:\n\t            return True\n\t        stream_info = client.get_stream_information(stream_id)\n\t        if pipe_info[\"sql\"] != new_pipe_sql:\n\t            return True\n\t        if stream_info[\"watermark\"] != watermark:\n\t            return True\n\t        existing_schema: List[SchemaField]\n\t        existing_schema_fields = stream_info[\"schema\"]\n", "        try:\n\t            existing_schema = self._schema_from_json(existing_schema_fields)\n\t        except Exception as err:\n\t            raise_compiler_error(f\"Error checking changes to the '{relation}' stream: {err}\")\n\t        if existing_schema != schema:\n\t            return True\n\t        return False\n\t    @available\n\t    def create_table(\n\t        self,\n", "        sql: str,\n\t        temporary: bool,\n\t        relation: BaseRelation,\n\t        nodes: Dict[str, Any],\n\t        watermark: Optional[str] = None,\n\t        primary_key: Optional[str] = None,\n\t    ) -> None:\n\t        if not relation.identifier:\n\t            raise_compiler_error(\"Cannot create an unnamed relation\")\n\t        self.logger.debug(f\"Creating table {relation}\")\n", "        name: str = relation.identifier.split(\"__\")[0]  # strip any suffixes added by dbt\n\t        model: Optional[ParsedNode] = None\n\t        for node, info in nodes.items():\n\t            if info[\"alias\"] == name:\n\t                model = ParsedNode.from_dict(nodes[node])\n\t        if not model:\n\t            self.logger.debug(f\"Model {relation.render()} not found in dbt graph\")\n\t        client = self._client()\n\t        fields: List[Dict[str, str]] = client.get_stream_from_sql(\n\t            self._wrap_as_pipeline(relation.render(), sql)\n", "        )[\"schema\"]\n\t        if not fields:\n\t            raise_database_error(\n\t                f\"Error creating the {relation} stream: empty schema returned for sql:\\n{sql}\"\n\t            )\n\t        schema: List[SchemaField]\n\t        try:\n\t            schema = self._schema_from_json(fields)\n\t        except Exception as err:\n\t            raise_compiler_error(f\"Error creating the {relation} stream: {err}\")\n", "        schema_hints: Set[SchemaField]\n\t        try:\n\t            if model:\n\t                schema_hints = self._get_model_schema_hints(model)\n\t            else:\n\t                schema_hints = set()\n\t        except Exception as err:\n\t            raise_parsing_error(f\"Error creating the {relation} stream: {err}\")\n\t        if not schema_hints.issubset(schema):\n\t            self.logger.warning(\n", "                f\"Column hints for '{name}' don't match the resulting schema:\\n{self._pretty_schema(list(schema_hints), 1, 'hints')}\\n{self._pretty_schema(schema, 1, 'schema')}\"\n\t            )\n\t        if primary_key:\n\t            for field in schema:\n\t                if field.name == primary_key:\n\t                    field.type = PrimaryKey(field.type)\n\t        stream_id = client.get_stream_id(relation.render())\n\t        if not stream_id:\n\t            client.create_stream(relation.render(), schema, watermark)\n\t            self.logger.debug(f\"Stream '{relation}' successfully created!\")\n", "        else:\n\t            raise_database_error(f\"Error creating the {relation} stream: stream already exists!\")\n\t        # Both stream and source should exist now, so we can create the pipeline\n\t        pipeline = client.create_pipeline(\n\t            sql=self._wrap_as_pipeline(relation.render(), sql),\n\t            name=relation.render(),\n\t            description=self._pipeline_description(relation),\n\t        )\n\t        client.activate_pipeline(pipeline_id=pipeline[\"id\"])\n\t        self.logger.debug(f\"Pipeline '{relation}' successfully created!\")\n", "    @available\n\t    def create_seed_table(\n\t        self, table_name: str, agate_table: AgateTable, column_override: Dict[str, str]\n\t    ):\n\t        schema: List[SchemaField] = []\n\t        column_names: tuple[str] = agate_table.column_names\n\t        for ix, col_name in enumerate(column_names):\n\t            type: Optional[str] = self.convert_type(agate_table, ix)\n\t            if not type:\n\t                raise_compiler_error(\n", "                    f\"Couldn't infer type for column `{col_name}` in seed `{table_name}`\"\n\t                )\n\t            field_type = FieldType.from_str(type)\n\t            override = column_override.get(col_name, \"\")\n\t            if override:\n\t                override_field_type = FieldType.from_str(override)\n\t                if not override_field_type:\n\t                    self.logger.warning(\n\t                        f\"Type override `{override}` for column `{col_name}` in seed `{table_name}` doesn't match any of Decodable's known types. Falling back to inferred type.\"\n\t                    )\n", "                else:\n\t                    field_type = override_field_type\n\t            if not field_type:\n\t                raise_compiler_error(\n\t                    f\"Inferred type `{type}` for column `{col_name}` doesn't match any of Decodable's known types\"\n\t                )\n\t            schema.append(SchemaField(name=col_name, type=field_type))\n\t        client = self._client()\n\t        self.logger.debug(f\"Creating connection and stream for seed `{table_name}`...\")\n\t        response = client.create_connection(name=table_name, schema=schema)\n", "        self.logger.debug(f\"Connection and stream `{table_name}` successfully created!\")\n\t        self.logger.debug(f\"Activating connection `{table_name}`...\")\n\t        client.activate_connection(conn_id=response[\"id\"])\n\t        self.logger.debug(f\"Connection `{table_name}` activated!\")\n\t    @available\n\t    def send_seed_as_events(self, seed_name: str, data: AgateTable):\n\t        self.logger.debug(f\"Sending data to connection `{seed_name}`\")\n\t        client = self._client()\n\t        conn_id = client.get_connection_id(seed_name)\n\t        if not conn_id:\n", "            raise_database_error(\n\t                f\"Trying to send seed events to a non-existing connection `{seed_name}`\"\n\t            )\n\t        events: List[Dict[str, Any]] = []\n\t        for row in data.rows:\n\t            event: Dict[str, Any] = {\n\t                col_name: str(row[col_name])  # pyright: ignore [reportUnknownArgumentType]\n\t                for col_name in data.column_names\n\t            }\n\t            events.append(event)\n", "        events_received = client.send_events(conn_id, events)\n\t        if len(events) != events_received:\n\t            self.logger.warning(\n\t                f\"While seeding data for `{seed_name}`: sent {len(events)} but connection reported only {events_received} events received.\"\n\t            )\n\t        client.deactivate_connection(conn_id)\n\t    @available\n\t    def reactivate_connection(self, connection: Relation):\n\t        client = self._client()\n\t        conn_id = client.get_connection_id(connection.render())\n", "        if not conn_id:\n\t            raise_database_error(f\"Unable to reactivate connection: '{connection}' does not exist\")\n\t        client.activate_connection(conn_id)\n\t    @available\n\t    def stop_pipeline(self, pipe: Relation):\n\t        client = self._client()\n\t        pipe_id = client.get_pipeline_id(pipe.render())\n\t        if not pipe_id:\n\t            raise_database_error(f\"Unable to deactivate pipeline: '{pipe}' does not exist\")\n\t        client.deactivate_pipeline(pipe_id)\n", "    @available\n\t    def delete_pipeline(self, pipe: Relation):\n\t        client = self._client()\n\t        pipeline_id = client.get_pipeline_id(pipe.render())\n\t        if pipeline_id:\n\t            pipe_info = client.get_pipeline_information(pipeline_id)\n\t            if pipe_info[\"actual_state\"] == \"RUNNING\" or pipe_info[\"target_state\"] == \"RUNNING\":\n\t                client.deactivate_pipeline(pipeline_id)\n\t            client.delete_pipeline(pipeline_id)\n\t    @available\n", "    def delete_stream(self, stream: Relation, skip_errors: bool = False):\n\t        client = self._client()\n\t        stream_id = client.get_stream_id(stream.render())\n\t        if not stream_id:\n\t            raise_database_error(f\"Unable to delete stream: `{stream}` does not exist\")\n\t        try:\n\t            client.delete_stream(stream_id)\n\t        except Exception as e:\n\t            if skip_errors:\n\t                self.logger.warning(f\"Deleting stream `{stream}` failed: {e}\")\n", "            else:\n\t                raise_database_error(f\"Deleting stream `{stream}` failed: {e}\")\n\t    @available\n\t    def delete_connection(self, conn: Relation):\n\t        client = self._client()\n\t        conn_id = client.get_connection_id(conn.render())\n\t        if not conn_id:\n\t            raise_database_error(f\"Unable to delete connection: `{conn}` does not exist\")\n\t        client.deactivate_connection(conn_id)\n\t        client.delete_connection(conn_id)\n", "    @available\n\t    def replace_disallowed_operations(self, sql: str) -> str:\n\t        return sql.replace(\"!=\", \"<>\")\n\t    @available\n\t    def should_materialize_tests(self) -> bool:\n\t        credentials: Optional[\n\t            DecodableAdapterCredentials\n\t        ] = self.get_thread_connection().credentials\n\t        if not credentials:\n\t            return False\n", "        return credentials.materialize_tests\n\t    def _client(self) -> DecodableApiClient:\n\t        handle: DecodableHandler = (\n\t            self.get_thread_connection().handle\n\t        )  # pyright: ignore [reportGeneralTypeIssues]\n\t        return handle.client\n\t    @classmethod\n\t    def _get_model_schema_hints(cls, model: ParsedNode) -> Set[SchemaField]:\n\t        schema: Set[SchemaField] = set()\n\t        for column in model.columns.values():\n", "            name: str = column.name\n\t            data_type: Optional[str] = column.data_type\n\t            if not data_type:\n\t                continue\n\t            t = FieldType.from_str(data_type)\n\t            if not t:\n\t                raise_compiler_error(f\"Type '{data_type}' not recognized\")\n\t            schema.add(SchemaField(name=name, type=t))\n\t        return schema\n\t    @staticmethod\n", "    def _set_primary_key(primary_key_field: str, schema: List[SchemaField]) -> None:\n\t        \"\"\"\n\t        Sets the primary key to the specified field in the provided schema. Does nothing if the schema does not contain\n\t        the specified field.\n\t        \"\"\"\n\t        for field in schema:\n\t            if isinstance(field.type, PrimaryKey):\n\t                raise ValueError(\n\t                    f\"Trying to set primary key to {primary_key_field}, but schema already has a primary \"\n\t                    f\"key assigned to {field.name}\"\n", "                )\n\t            if field.name == primary_key_field:\n\t                field.type = PrimaryKey(field.type)\n\t    @staticmethod\n\t    def _remove_primary_key(schema: List[SchemaField]) -> None:\n\t        \"\"\"\n\t        Removes the primary key from the provided schema (if present).\n\t        \"\"\"\n\t        for field in schema:\n\t            if isinstance(field.type, PrimaryKey):\n", "                field.type = field.type.inner_type\n\t    @staticmethod\n\t    def _pretty_schema(\n\t        schema: List[SchemaField], indent: int = 0, name: Optional[str] = None\n\t    ) -> str:\n\t        fields = \"\"\n\t        for field in sorted(schema, key=lambda sf: sf.name):\n\t            i = \"\\t\" * (indent + 1)\n\t            fields += f\"{i}{field.name}: {field.type},\\n\"\n\t        i = \"\\t\" * indent\n", "        prefix = f\"{i}{{\"\n\t        if name:\n\t            prefix = f\"{i}{name} = {{\"\n\t        suffix = f\"{i}}}\"\n\t        if not fields:\n\t            suffix = \"}\"\n\t        return f\"{prefix}\\n{fields}{suffix}\"\n\t    @classmethod\n\t    def _schema_from_json(cls, json: List[Dict[str, str]]) -> List[SchemaField]:\n\t        schema: List[SchemaField] = []\n", "        for field in json:\n\t            t = FieldType.from_str(field[\"type\"])\n\t            if not t:\n\t                raise_compiler_error(f\"Type '{field['type']}' not recognized\")\n\t            schema.append(SchemaField(name=field[\"name\"], type=t))\n\t        return schema\n\t    @classmethod\n\t    def _wrap_as_pipeline(cls, sink: str, sql: str) -> str:\n\t        return f\"INSERT INTO {sink} {sql}\"\n\t    @classmethod\n", "    def _replace_sink(cls, old_sink: BaseRelation, new_sink: BaseRelation, sql: str) -> str:\n\t        return sql.replace(f\"INSERT INTO {old_sink}\", f\"INSERT INTO {new_sink}\", 1)\n\t    @classmethod\n\t    def _replace_source(cls, old_source: BaseRelation, new_source: BaseRelation, sql: str) -> str:\n\t        sql = sql.replace(f\"from {old_source}\", f\"from {new_source}\")\n\t        return sql.replace(f\"FROM {old_source}\", f\"FROM {new_source}\")\n\t    @classmethod\n\t    def _pipeline_description(cls, relation: BaseRelation) -> str:\n\t        return f\"Pipeline for the '{relation}' dbt model\"\n"]}
{"filename": "dbt/adapters/decodable/relation.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom dataclasses import dataclass\n\tfrom dbt.adapters.base import BaseRelation\n\tfrom dbt.contracts.relation import Policy\n\t@dataclass\n\tclass DecodableQuotePolicy(Policy):\n", "    database: bool = False\n\t    schema: bool = False\n\t    identifier: bool = False\n\t@dataclass\n\tclass DecodableIncludePolicy(Policy):\n\t    database: bool = False\n\t    schema: bool = False\n\t    identifier: bool = True\n\t@dataclass(frozen=True, eq=False, repr=False)\n\tclass DecodableRelation(BaseRelation):\n", "    quote_policy: Policy = DecodableQuotePolicy()\n\t    include_policy: Policy = DecodableIncludePolicy()\n\t    dbt_created: bool = True\n"]}
{"filename": "dbt/adapters/decodable/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom dbt.adapters.decodable.connections import DecodableAdapterCredentials\n\tfrom dbt.adapters.decodable.impl import DecodableAdapter\n\tfrom dbt.adapters.base import AdapterPlugin\n\timport dbt.include.decodable as decodable\n\tPlugin = AdapterPlugin(\n", "    adapter=DecodableAdapter,\n\t    credentials=DecodableAdapterCredentials,\n\t    include_path=decodable.PACKAGE_PATH,\n\t)\n"]}
{"filename": "dbt/adapters/decodable/connections.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom typing import Any, Optional, Tuple\n\tfrom contextlib import contextmanager\n\tfrom dataclasses import dataclass\n\tfrom agate.table import Table\n\tfrom dbt.adapters.sql.connections import SQLConnectionManager\n", "from dbt.contracts.connection import (\n\t    AdapterResponse,\n\t    Connection,\n\t    Credentials,\n\t)\n\tfrom dbt.events import AdapterLogger\n\tfrom dbt.exceptions import RuntimeException\n\tfrom dbt.adapters.decodable.handler import DecodableCursor, DecodableHandler\n\tfrom decodable.client.client_factory import DecodableClientFactory\n\tfrom decodable.client.api import StartPosition\n", "@dataclass\n\tclass DecodableAdapterCredentials(Credentials):\n\t    \"\"\"\n\t    Defines database specific credentials that get added to\n\t    profiles.yml to connect to new adapter\n\t    \"\"\"\n\t    profile_name: str\n\t    account_name: str\n\t    materialize_tests: bool = False\n\t    preview_start: StartPosition = StartPosition.EARLIEST\n", "    request_timeout_ms: int = 60000\n\t    local_namespace: Optional[str] = None\n\t    api_url: str = \"api.decodable.co/v1alpha2\"\n\t    _ALIASES = {\n\t        \"profile\": \"profile_name\",\n\t        \"account\": \"account_name\",\n\t        \"request_timeout\": \"request_timeout_ms\",\n\t        \"timeout_ms\": \"request_timeout_ms\",\n\t        \"timeout\": \"request_timeout_ms\",\n\t    }\n", "    @property\n\t    def unique_field(self) -> str:\n\t        return f\"{self.account_name}.{self.profile_name}\"\n\t    @property\n\t    def type(self):\n\t        \"\"\"Return name of adapter.\"\"\"\n\t        return \"decodable\"\n\t    def _connection_keys(self):\n\t        \"\"\"\n\t        List of keys to display in the `dbt debug` output.\n", "        \"\"\"\n\t        return (\n\t            \"profile_name\",\n\t            \"account_name\",\n\t            \"materialize_tests\",\n\t            \"preview_start\",\n\t            \"request_timeout_ms\",\n\t            \"local_namespace\",\n\t        )\n\tclass DecodableAdapterConnectionManager(SQLConnectionManager):\n", "    TYPE: str = \"decodable\"\n\t    logger = AdapterLogger(\"Decodable\")\n\t    @classmethod\n\t    def get_response(cls, cursor: Any) -> AdapterResponse:\n\t        \"\"\"Get the status of the cursor.\"\"\"\n\t        return AdapterResponse(\"OK\")\n\t    @contextmanager\n\t    def exception_handler(self, sql: str):\n\t        \"\"\"\n\t        Returns a context manager, that will handle exceptions raised\n", "        from queries, catch, log, and raise dbt exceptions it knows how to handle.\n\t        \"\"\"\n\t        try:\n\t            yield\n\t        except Exception as e:\n\t            self.logger.error(\"Exception thrown during execution: {}\".format(str(e)))\n\t            raise RuntimeException(str(e))\n\t    @classmethod\n\t    def open(cls, connection: Connection) -> Connection:\n\t        \"\"\"\n", "        Receives a connection object and a Credentials object\n\t        and moves it to the \"open\" state.\n\t        \"\"\"\n\t        if not connection.credentials:\n\t            raise RuntimeException(\"Cannot open a Decodable connection without credentials\")\n\t        credentials: DecodableAdapterCredentials = connection.credentials\n\t        client = DecodableClientFactory.create_client(\n\t            api_url=credentials.api_url,\n\t            profile_name=credentials.profile_name,\n\t            decodable_account_name=credentials.account_name,\n", "        )\n\t        decodable_connection_test = client.test_connection()\n\t        if not decodable_connection_test.ok:\n\t            error_message = \"\"\n\t            if (\n\t                decodable_connection_test.reason is not None\n\t                and len(decodable_connection_test.reason) > 0\n\t            ):\n\t                error_message = f\"\\nReason: {decodable_connection_test.reason}\"\n\t            raise RuntimeException(\n", "                f\"Status code: {decodable_connection_test.status_code}. Decodable connection failed. Try running 'decodable login' first{error_message}\"\n\t            )\n\t        connection.handle = DecodableHandler(\n\t            client, credentials.preview_start, credentials.request_timeout_ms / 1000\n\t        )\n\t        return connection\n\t    def cancel(self, connection: Connection):\n\t        \"\"\"\n\t        Gets a connection object and attempts to cancel any ongoing queries.\n\t        \"\"\"\n", "        pass\n\t    def begin(self) -> Connection:\n\t        return self.get_thread_connection()\n\t    def commit(self) -> Connection:\n\t        return self.get_thread_connection()\n\t    def execute(\n\t        self, sql: str, auto_begin: bool = False, fetch: bool = False\n\t    ) -> Tuple[AdapterResponse, Table]:\n\t        sql = self._add_query_comment(sql)\n\t        if fetch:\n", "            _, cursor = self.add_query(sql, auto_begin)\n\t            response = self.get_response(cursor)\n\t            table = self.get_result_from_cursor(cursor)\n\t        else:\n\t            response = AdapterResponse(\"OK\")\n\t            cursor = self._dummy_cursor()\n\t            cursor.seed_fake_results()\n\t            table = self.get_result_from_cursor(cursor)\n\t        return response, table\n\t    def _dummy_cursor(self) -> DecodableCursor:\n", "        conn = self.get_thread_connection()\n\t        return (\n\t            conn.handle.cursor()  # pyright: ignore [reportOptionalMemberAccess, reportGeneralTypeIssues]\n\t        )\n"]}
{"filename": "dbt/adapters/decodable/handler.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tfrom random import randint\n\tfrom time import sleep\n\tfrom typing import Any, Dict, Iterator, List, Optional, Sequence, Tuple\n\tfrom dbt.events import AdapterLogger\n\tfrom decodable.client.client import DecodableApiClient\n", "from decodable.client.api import StartPosition\n\tdef exponential_backoff(timeout: float) -> Iterator[float]:\n\t    epsilon = 0.001\n\t    backoff: float = 1.0\n\t    total_time: float = 0\n\t    while True:\n\t        yield total_time\n\t        stagger = randint(0, 1000) / 1000\n\t        time = min(backoff + stagger, timeout - total_time)\n\t        sleep(time)\n", "        total_time += time\n\t        backoff *= 2\n\t        if timeout - total_time < epsilon:\n\t            break\n\tclass DecodableCursor:\n\t    logger = AdapterLogger(\"Decodable\")\n\t    def __init__(self, client: DecodableApiClient, preview_start: StartPosition, timeout: float):\n\t        self.logger.debug(\n\t            f\"Creating new cursor(preview_start: {preview_start}, timeout: {timeout})\"\n\t        )\n", "        self.client = client\n\t        self.preview_start = preview_start\n\t        self.timeout = timeout\n\t        self.last_sql: Optional[str] = None\n\t        self.last_result: Optional[Sequence[Dict[str, Any]]]\n\t    def execute(self, sql: str, bindings: Optional[Sequence[Any]] = None) -> None:\n\t        self.logger.debug(f\"Execute(sql): {sql}\")\n\t        inputs: List[Dict[str, Any]] = self.client.get_preview_dependencies(sql)[\"inputs\"]\n\t        input_streams: List[str] = [i[\"resourceName\"] for i in inputs]\n\t        response = self.client.create_preview(sql, self.preview_start, input_streams)\n", "        self.logger.debug(f\"Create preview response: {response}\")\n\t        append_stream = response.output_stream_type == \"APPEND\"\n\t        self.last_result = []\n\t        for _ in exponential_backoff(self.timeout):\n\t            token = response.next_token\n\t            response = self.client.run_preview(id=response.id, token=token)\n\t            self.logger.debug(f\"Run preview response: {response}\")\n\t            if append_stream:\n\t                self.last_result.extend(response.results)\n\t            elif response.results:\n", "                last_change = response.results[-1]\n\t                if not last_change[\"after\"]:\n\t                    self.last_result = []\n\t                else:\n\t                    self.last_result = [last_change[\"after\"]]\n\t            if response.next_token is None:\n\t                break\n\t        if not self.last_result:\n\t            self.seed_fake_results()\n\t    def fetchall(self) -> Sequence[Tuple[Any]]:\n", "        results = self.last_result\n\t        self.last_result = None\n\t        tuples: Sequence[Tuple[Any]] = []\n\t        if results:\n\t            l = []\n\t            for result in results:\n\t                for val in result.values():\n\t                    l.append(val)\n\t                tuples.append(tuple(l))\n\t        return tuples\n", "    @property\n\t    def description(self) -> List[Tuple[str]]:\n\t        result: List[Tuple[str]] = []\n\t        if not self.last_result:\n\t            return [(\"failures\",), (\"should_warn\",), (\"should_error\",)]\n\t        for name in self.last_result[0].keys():\n\t            result.append((name,))\n\t        return result\n\t    def seed_fake_results(self):\n\t        self.last_result = [{\"failures\": 0, \"should_warn\": False, \"should_error\": False}]\n", "class DecodableHandler:\n\t    def __init__(self, client: DecodableApiClient, preview_start: StartPosition, timeout: float):\n\t        self.client = client\n\t        self.preview_start = preview_start\n\t        self.timeout = timeout\n\t    def cursor(self) -> DecodableCursor:\n\t        return DecodableCursor(self.client, self.preview_start, self.timeout)\n"]}
{"filename": "dbt/adapters/decodable/__version__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\tversion = \"1.3.2\"\n"]}
{"filename": "dbt/include/decodable/__init__.py", "chunked_list": ["#\n\t#  Copyright 2023 decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n\timport os\n\tPACKAGE_PATH = os.path.dirname(__file__)\n"]}
{"filename": ".github/plugin-discovery/plugin_discovery.py", "chunked_list": ["import re\n\timport subprocess\n\timport sys\n\tdef main():\n\t    out = subprocess.run([\"dbt\", \"--version\"], stderr=subprocess.PIPE, text=True)\n\t    plugin_detected = (\n\t        re.search(r\"Plugins:.*\\s- decodable: \\d+\\.\\d+\\.\\d+\", out.stderr, flags=re.DOTALL)\n\t        is not None\n\t    )\n\t    if not plugin_detected:\n", "        sys.exit(\n\t            f\"Decodable plugin not recognized by dbt! Received output of `dbt --version`:\\n{out.stderr}\"\n\t        )\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": ".github/license-check/license-header.py", "chunked_list": ["#\n\t#  Copyright %year% decodable Inc.\n\t#\n\t#  Licensed under the Apache License, Version 2.0 (the \"License\");\n\t#  you may not use this file except in compliance with the License.\n\t#  You may obtain a copy of the License at\n\t#\n\t#      http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t#  Unless required by applicable law or agreed to in writing, software\n", "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n\t#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t#  See the License for the specific language governing permissions and\n\t#  limitations under the License.\n\t#\n"]}
