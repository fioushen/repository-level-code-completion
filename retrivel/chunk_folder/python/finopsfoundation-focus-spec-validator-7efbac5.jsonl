{"filename": "focus_validator/validator.py", "chunked_list": ["from pkg_resources import resource_filename\n\tfrom focus_validator.data_loaders import data_loader\n\tfrom focus_validator.outputter.outputter import Outputter\n\tfrom focus_validator.rules.spec_rules import SpecRules\n\tDEFAULT_VERSION_SETS_PATH = resource_filename(\"focus_validator.rules\", \"version_sets\")\n\tclass Validator:\n\t    def __init__(\n\t        self,\n\t        data_filename,\n\t        output_destination,\n", "        output_type,\n\t        rule_set_path=DEFAULT_VERSION_SETS_PATH,\n\t        rules_version=\"0.5\",\n\t        override_filename=None,\n\t        column_namespace=None,\n\t    ):\n\t        self.data_filename = data_filename\n\t        self.focus_data = None\n\t        self.override_filename = override_filename\n\t        self.rules_version = rules_version\n", "        self.spec_rules = SpecRules(\n\t            override_filename=override_filename,\n\t            rule_set_path=rule_set_path,\n\t            rules_version=rules_version,\n\t            column_namespace=column_namespace,\n\t        )\n\t        self.outputter = Outputter(\n\t            output_type=output_type, output_destination=output_destination\n\t        )\n\t    def load(self):\n", "        self.focus_data = data_loader.DataLoader(\n\t            data_filename=self.data_filename\n\t        ).load()\n\t        self.spec_rules.load()\n\t    def validate(self):\n\t        self.load()\n\t        results = self.spec_rules.validate(self.focus_data)\n\t        self.outputter = self.outputter.write(results)\n\t    def get_supported_versions(self):\n\t        return self.spec_rules.supported_versions()\n"]}
{"filename": "focus_validator/main.py", "chunked_list": ["import argparse\n\timport os\n\timport sys\n\tfrom focus_validator.validator import Validator\n\tdef main():\n\t    parser = argparse.ArgumentParser(description=\"FOCUS specification validator.\")\n\t    parser.add_argument(\n\t        \"--data-file\",\n\t        help=\"Path to the data file (CSV)\",\n\t        required=\"--supported-versions\" not in sys.argv,\n", "    )\n\t    parser.add_argument(\n\t        \"--column-namespace\",\n\t        help=\"Column namespace to differentiate focus columns from vendor columns\",\n\t    )\n\t    parser.add_argument(\"--override-file\", help=\"Path to the override file (YAML)\")\n\t    parser.add_argument(\n\t        \"--output-format\", default=\"text\", help=\"Path to the output report file\"\n\t    )\n\t    parser.add_argument(\n", "        \"--supported-versions\",\n\t        action=\"store_true\",\n\t        default=False,\n\t        help=\"Return the supported FOCUS versions for validation\",\n\t    )\n\t    parser.add_argument(\n\t        \"--transitional\",\n\t        action=\"store_true\",\n\t        default=False,\n\t        help=\"Allow transitional rules in validation\",\n", "    )\n\t    parser.add_argument(\n\t        \"--validate-version\", default=\"0.5\", help=\"Version of FOCUS to validate against\"\n\t    )\n\t    parser.add_argument(\n\t        \"--rule-set-path\",\n\t        default=os.path.join(\"focus_validator\", \"rules\", \"version_sets\"),\n\t        help=\"Path to rules definitions\",\n\t    )\n\t    parser.add_argument(\n", "        \"--output-type\",\n\t        default=\"console\",\n\t        help=\"What type of output you would like\",\n\t        choices=[\"console\", \"unittest\"],\n\t    )\n\t    parser.add_argument(\n\t        \"--output-destination\",\n\t        default=None,\n\t        help=\"filename of where to output the rules\",\n\t    )\n", "    args = parser.parse_args()\n\t    if args.output_type != \"console\" and args.output_destination is None:\n\t        parser.error(\"--output-destination required {}\".format(args.output_type))\n\t        sys.exit(1)\n\t    validator = Validator(\n\t        data_filename=args.data_file,\n\t        override_filename=args.override_file,\n\t        rule_set_path=args.rule_set_path,\n\t        rules_version=args.validate_version,\n\t        output_type=args.output_type,\n", "        output_destination=args.output_destination,\n\t        column_namespace=args.column_namespace,\n\t    )\n\t    if args.supported_versions:\n\t        for version in validator.get_supported_versions():\n\t            print(version)\n\t    else:\n\t        validator.validate()\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "focus_validator/__init__.py", "chunked_list": ["# this import is needed to initialize custom pandera extensions implemented in this package\n\tfrom focus_validator.rules.checks import *  # noqa\n"]}
{"filename": "focus_validator/exceptions.py", "chunked_list": ["class FocusValidationError(Exception):\n\t    pass\n\tclass FocusNotImplementedError(FocusValidationError):\n\t    def __init__(self, msg=None):\n\t        super().__init__(msg)\n\tclass UnsupportedVersion(FocusValidationError):\n\t    pass\n"]}
{"filename": "focus_validator/data_loaders/csv_data_loader.py", "chunked_list": ["import pandas as pd\n\tclass CSVDataLoader:\n\t    def __init__(self, data_filename):\n\t        self.data_filename = data_filename\n\t    def load(self):\n\t        return pd.read_csv(self.data_filename, keep_default_na=False)\n"]}
{"filename": "focus_validator/data_loaders/parquet_data_loader.py", "chunked_list": ["import pandas as pd\n\tclass ParquetDataLoader:\n\t    def __init__(self, data_filename):\n\t        self.data_filename = data_filename\n\t    def load(self):\n\t        return pd.read_parquet(self.data_filename)\n"]}
{"filename": "focus_validator/data_loaders/__init__.py", "chunked_list": []}
{"filename": "focus_validator/data_loaders/data_loader.py", "chunked_list": ["import magic\n\tfrom focus_validator.data_loaders.csv_data_loader import CSVDataLoader\n\tfrom focus_validator.data_loaders.parquet_data_loader import ParquetDataLoader\n\tfrom focus_validator.exceptions import FocusNotImplementedError\n\tdef get_file_mime_type(filename):\n\t    f = magic.Magic(uncompress=True)\n\t    return f.from_file(filename=filename)\n\tclass DataLoader:\n\t    def __init__(self, data_filename):\n\t        self.data_filename = data_filename\n", "        self.data_loader_class = self.find_data_loader()\n\t        self.data_loader = self.data_loader_class(self.data_filename)\n\t    def find_data_loader(self):\n\t        file_mime_type = get_file_mime_type(self.data_filename)\n\t        if file_mime_type in [\"ASCII text\", \"CSV text\"]:\n\t            return CSVDataLoader\n\t        elif file_mime_type == \"Apache Parquet\":\n\t            return ParquetDataLoader\n\t        else:\n\t            raise FocusNotImplementedError(\n", "                msg=f\"Validator for file_type {file_mime_type} not implemented yet.\"\n\t            )\n\t    def load(self):\n\t        return self.data_loader.load()\n"]}
{"filename": "focus_validator/rules/checks.py", "chunked_list": ["import re\n\tfrom datetime import datetime\n\timport pandas as pd\n\tfrom pandera import extensions\n\tfrom focus_validator.utils.download_currency_codes import get_currency_codes\n\tdef is_camel_case(column_name):\n\t    return (\n\t        column_name != column_name.lower()\n\t        and column_name != column_name.upper()\n\t        and \"_\" not in column_name\n", "    )\n\t@extensions.register_check_method()\n\tdef check_not_null(pandas_obj: pd.Series, allow_nulls: bool):\n\t    # TODO: works for string type, need to verify for other data types\n\t    check_values = pandas_obj.isnull() | (pandas_obj == \"\")\n\t    if not allow_nulls:\n\t        check_values = check_values | (pandas_obj == \"NULL\")\n\t    return ~check_values\n\t@extensions.register_check_method()\n\tdef check_unique(pandas_obj: pd.Series):\n", "    return ~pandas_obj.duplicated()\n\t@extensions.register_check_method()\n\tdef check_value_in(pandas_obj: pd.Series, allowed_values):\n\t    return pandas_obj.isin(allowed_values)\n\t@extensions.register_check_method()\n\tdef check_datetime_dtype(pandas_obj: pd.Series):\n\t    pattern = re.compile(r\"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z$\")\n\t    def __validate_date_obj__(value: str):\n\t        if not (isinstance(value, str) and re.match(pattern, value)):\n\t            return False\n", "        try:\n\t            datetime.strptime(value[:-1], \"%Y-%m-%dT%H:%M:%S\")\n\t            return True\n\t        except ValueError:\n\t            return False\n\t    return pd.Series(map(__validate_date_obj__, pandas_obj.values))\n\t@extensions.register_check_method()\n\tdef check_currency_code_dtype(pandas_obj: pd.Series):\n\t    currency_codes = set(get_currency_codes())\n\t    return pd.Series(\n", "        map(lambda v: isinstance(v, str) and v in currency_codes, pandas_obj.values)\n\t    )\n"]}
{"filename": "focus_validator/rules/__init__.py", "chunked_list": []}
{"filename": "focus_validator/rules/spec_rules.py", "chunked_list": ["import os\n\tfrom typing import Dict, Optional\n\timport pandas as pd\n\tfrom pandera.errors import SchemaErrors\n\tfrom focus_validator.config_objects import (\n\t    ChecklistObject,\n\t    ChecklistObjectStatus,\n\t    Override,\n\t    Rule,\n\t)\n", "from focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.exceptions import UnsupportedVersion\n\tdef convert_missing_column_errors(df, checklist):\n\t    def process_row(row):\n\t        if (\n\t            row[\"schema_context\"] == \"DataFrameSchema\"\n\t            and row[\"check\"] == \"column_in_dataframe\"\n\t        ):\n", "            for check_name, check_obj in checklist.items():\n\t                if (\n\t                    row[\"failure_case\"] == check_obj.column_id\n\t                    and check_obj.rule_ref.check == \"column_required\"\n\t                ):\n\t                    row[\"check\"] = f\"{check_name}:::{check_obj.friendly_name}\"\n\t                    row[\"column\"] = check_obj.column_id\n\t                    row[\"failure_case\"] = None\n\t                    return row\n\t        else:\n", "            return row\n\t    filtered_df = df.apply(process_row, axis=1)\n\t    return filtered_df\n\tdef convert_dtype_column_errors(df, checklist):\n\t    def process_row(row):\n\t        if row[\"schema_context\"] == \"Column\" and row[\"check\"].startswith(\"dtype\"):\n\t            for check_name, check_obj in checklist.items():\n\t                if row[\"column\"] == check_obj.column_id:\n\t                    row[\"check\"] = f\"{check_name}:::{check_obj.friendly_name}\"\n\t                    row[\"column\"] = check_obj.column_id\n", "                    row[\"failure_case\"] = None\n\t                    return row\n\t        else:\n\t            return row\n\t    filtered_df = df.apply(process_row, axis=1)\n\t    return filtered_df\n\tdef restructure_failure_cases_df(failure_cases: pd.DataFrame, checklist):\n\t    failure_cases = convert_missing_column_errors(failure_cases, checklist)\n\t    failure_cases = convert_dtype_column_errors(failure_cases, checklist)\n\t    failure_cases = failure_cases.rename(\n", "        columns={\"column\": \"Column\", \"index\": \"Row #\", \"failure_case\": \"Values\"}\n\t    )\n\t    failure_cases[[\"Check Name\", \"Description\"]] = failure_cases[\"check\"].str.split(\n\t        \":::\", expand=True\n\t    )\n\t    failure_cases = failure_cases.drop(\"check\", axis=1)\n\t    failure_cases = failure_cases.drop(\"check_number\", axis=1)\n\t    failure_cases = failure_cases.drop(\"schema_context\", axis=1)\n\t    failure_cases = failure_cases.rename_axis(\"#\")\n\t    failure_cases.index = failure_cases.index + 1\n", "    failure_cases[\"Row #\"] = failure_cases[\"Row #\"] + 1\n\t    failure_cases = failure_cases[\n\t        [\"Column\", \"Check Name\", \"Description\", \"Values\", \"Row #\"]\n\t    ]\n\t    return failure_cases\n\tclass ValidationResult:\n\t    checklist: Dict[str, ChecklistObject]\n\t    failure_cases: Optional[pd.DataFrame]\n\t    def __init__(\n\t        self,\n", "        checklist: Dict[str, ChecklistObject],\n\t        failure_cases: Optional[pd.DataFrame] = None,\n\t    ):\n\t        self.__failure_cases__ = failure_cases\n\t        self.__checklist__ = checklist\n\t    def process_result(self):\n\t        failure_cases = self.__failure_cases__\n\t        checklist = self.__checklist__\n\t        if failure_cases is None:\n\t            self.failure_cases = None\n", "        else:\n\t            self.failure_cases = failure_cases = restructure_failure_cases_df(\n\t                failure_cases, checklist\n\t            )\n\t            failed = set(failure_cases[\"Check Name\"])\n\t            for check_name in failed:\n\t                checklist[check_name].status = ChecklistObjectStatus.FAILED\n\t        for check_list_object in checklist.values():\n\t            if check_list_object.status == ChecklistObjectStatus.PENDING:\n\t                check_list_object.status = ChecklistObjectStatus.PASSED\n", "        self.checklist = checklist\n\tclass SpecRules:\n\t    def __init__(\n\t        self, override_filename, rule_set_path, rules_version, column_namespace\n\t    ):\n\t        self.override_filename = override_filename\n\t        self.override_config = None\n\t        self.rules_version = rules_version\n\t        self.rule_set_path = rule_set_path\n\t        if self.rules_version not in self.supported_versions():\n", "            raise UnsupportedVersion(\n\t                f\"FOCUS version {self.rules_version} not supported.\"\n\t            )\n\t        self.rules_path = os.path.join(self.rule_set_path, self.rules_version)\n\t        self.rules = []\n\t        self.column_namespace = column_namespace\n\t    def supported_versions(self):\n\t        return sorted([x for x in os.walk(self.rule_set_path)][0][1])\n\t    def load(self):\n\t        self.load_overrides()\n", "        self.load_rules()\n\t    def load_overrides(self):\n\t        if not self.override_filename:\n\t            return {}\n\t        self.override_config = Override.load_yaml(self.override_filename)\n\t    def load_rules(self):\n\t        for rule_path in self.get_rule_paths():\n\t            self.rules.append(\n\t                Rule.load_yaml(rule_path, column_namespace=self.column_namespace)\n\t            )\n", "    def get_rule_paths(self):\n\t        for root, dirs, files in os.walk(self.rules_path, topdown=False):\n\t            for name in files:\n\t                yield os.path.join(root, name)\n\t    def validate(self, focus_data):\n\t        (\n\t            pandera_schema,\n\t            checklist,\n\t        ) = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=self.rules, override_config=self.override_config\n", "        )\n\t        try:\n\t            pandera_schema.validate(focus_data, lazy=True)\n\t            failure_cases = None\n\t        except SchemaErrors as e:\n\t            failure_cases = e.failure_cases\n\t        validation_result = ValidationResult(\n\t            checklist=checklist, failure_cases=failure_cases\n\t        )\n\t        validation_result.process_result()\n", "        return validation_result\n"]}
{"filename": "focus_validator/utils/download_currency_codes.py", "chunked_list": ["import xml.etree.ElementTree as ET\n\timport pandas as pd\n\timport requests\n\tDATAHUB_URL = \"https://www.six-group.com/dam/download/financial-information/data-center/iso-currrency/lists/list-one.xml\"\n\tCURRENCY_CODE_CSV_PATH = \"focus_validator/utils/currency_codes.csv\"\n\tdef download_currency_codes():\n\t    r = requests.get(DATAHUB_URL)\n\t    root = ET.fromstring(r.content.decode())\n\t    currency_codes = []\n\t    for child in root.iter():\n", "        if child.tag == \"Ccy\":\n\t            currency_codes.append(child.text)\n\t    df = pd.DataFrame(set(currency_codes), columns=[\"currency_codes\"])\n\t    df.to_csv(CURRENCY_CODE_CSV_PATH)\n\tdef get_currency_codes():\n\t    df = pd.read_csv(CURRENCY_CODE_CSV_PATH)\n\t    return set(df[\"currency_codes\"].values)\n\tif __name__ == \"__main__\":\n\t    download_currency_codes()\n"]}
{"filename": "focus_validator/utils/__init__.py", "chunked_list": []}
{"filename": "focus_validator/config_objects/focus_to_pandera_schema_converter.py", "chunked_list": ["from itertools import groupby\n\tfrom typing import Dict, List, Optional, Set, Union\n\timport pandera as pa\n\tfrom pandera.api.pandas.types import PandasDtypeInputTypes\n\tfrom focus_validator.config_objects import ChecklistObject, InvalidRule, Rule\n\tfrom focus_validator.config_objects.common import (\n\t    AllowNullsCheck,\n\t    ChecklistObjectStatus,\n\t    DataTypeCheck,\n\t    DataTypes,\n", "    ValueInCheck,\n\t)\n\tfrom focus_validator.config_objects.override import Override\n\tfrom focus_validator.exceptions import FocusNotImplementedError\n\tclass FocusToPanderaSchemaConverter:\n\t    @staticmethod\n\t    def __generate_pandera_check__(rule: Rule, check_id):\n\t        \"\"\"\n\t        Generates a single pandera check based on the check config which can then be added to the pa.Column.\n\t        :param rule:\n", "        :param check_id:\n\t        :return:\n\t        \"\"\"\n\t        check = rule.check\n\t        error_string = \"{}::: {}\".format(check_id, rule.check_friendly_name)\n\t        if isinstance(check, str):\n\t            if check == \"check_unique\":\n\t                return pa.Check.check_unique(error=error_string)\n\t            else:\n\t                raise FocusNotImplementedError(\n", "                    msg=\"Check type: {} not implemented.\".format(check)\n\t                )\n\t        elif isinstance(check, ValueInCheck):\n\t            return pa.Check.check_value_in(\n\t                allowed_values=check.value_in, error=error_string\n\t            )\n\t        elif isinstance(check, AllowNullsCheck):\n\t            return pa.Check.check_not_null(\n\t                error=error_string, ignore_na=False, allow_nulls=check.allow_nulls\n\t            )\n", "        else:\n\t            raise FocusNotImplementedError(\n\t                msg=\"Check type: {} not implemented.\".format(type(check))\n\t            )\n\t    @classmethod\n\t    def __generate_column_definition__(\n\t        cls, rule: Rule, overrides, data_type: DataTypes\n\t    ):\n\t        \"\"\"\n\t        Generates column data type validation obj and pa.Column which will contain all other checks\n", "        \"\"\"\n\t        column_checks = []\n\t        pandera_type: Optional[PandasDtypeInputTypes]\n\t        if data_type == DataTypes.DECIMAL:\n\t            pandera_type = pa.Float\n\t        elif data_type == DataTypes.DATETIME:\n\t            pandera_type = None\n\t            column_checks.append(\n\t                pa.Check.check_datetime_dtype(\n\t                    ignore_na=True,\n", "                    error=f\"{rule.check_id}:::Ensures that column is of {data_type.value} type.\",\n\t                )\n\t            )\n\t        elif data_type == DataTypes.CURRENCY_CODE:\n\t            pandera_type = None\n\t            column_checks.append(\n\t                pa.Check.check_currency_code_dtype(\n\t                    ignore_na=True,\n\t                    error=f\"{rule.check_id}:::Ensures that column is of {data_type.value} type.\",\n\t                )\n", "            )\n\t        else:\n\t            pandera_type = pa.String\n\t        check_list_object = ChecklistObject(\n\t            check_name=rule.check_id,\n\t            column_id=rule.column_id,\n\t            status=ChecklistObjectStatus.SKIPPED\n\t            if rule.check_id in overrides\n\t            else ChecklistObjectStatus.PENDING,\n\t            friendly_name=f\"Ensures that column is of {data_type.value} type.\",\n", "            rule_ref=rule,\n\t        )\n\t        pa_column = pa.Column(\n\t            pandera_type,  # type: ignore\n\t            required=False,\n\t            checks=column_checks,\n\t            nullable=True,\n\t        )\n\t        return check_list_object, pa_column\n\t    @classmethod\n", "    def __generate_non_dtype_check__(\n\t        cls,\n\t        column_id,\n\t        column_rules: List[\"Rule\"],\n\t        schema_dict: Dict[str, pa.Column],\n\t        checklist,\n\t        overrides,\n\t    ):\n\t        try:\n\t            pa_column = schema_dict[column_id]\n", "        except KeyError:\n\t            pa_column = None\n\t        for rule in column_rules:\n\t            checklist[rule.check_id] = check_list_object = ChecklistObject(\n\t                check_name=rule.check_id,\n\t                column_id=column_id,\n\t                friendly_name=rule.check_friendly_name,\n\t                status=ChecklistObjectStatus.PENDING,\n\t                rule_ref=rule,\n\t            )\n", "            if pa_column is None:\n\t                check_list_object.error = (\n\t                    \"ConfigurationError: No configuration found for column.\"\n\t                )\n\t                check_list_object.status = ChecklistObjectStatus.ERRORED\n\t            elif rule.check_id in overrides:\n\t                check_list_object.status = ChecklistObjectStatus.SKIPPED\n\t            else:\n\t                if rule.check == \"column_required\":\n\t                    pa_column.required = True\n", "                else:\n\t                    check = cls.__generate_pandera_check__(\n\t                        rule=rule, check_id=rule.check_id\n\t                    )\n\t                    pa_column.checks.append(check)\n\t    @classmethod\n\t    def generate_pandera_schema(\n\t        cls,\n\t        rules: List[Union[Rule, InvalidRule]],\n\t        override_config: Optional[Override] = None,\n", "    ):\n\t        schema_dict = {}\n\t        checklist = {}\n\t        overrides: Set[str] = set()\n\t        if override_config:\n\t            overrides = set(override_config.overrides)\n\t        validation_rules = []\n\t        for rule in rules:\n\t            if isinstance(rule, InvalidRule):\n\t                checklist[rule.rule_path] = ChecklistObject(\n", "                    check_name=rule.rule_path,\n\t                    column_id=\"Unknown\",\n\t                    error=f\"{rule.error_type}: {rule.error}\",\n\t                    status=ChecklistObjectStatus.ERRORED,\n\t                    rule_ref=rule,\n\t                )\n\t                continue\n\t            if isinstance(rule.check, DataTypeCheck):\n\t                check_list_object, pa_column = cls.__generate_column_definition__(\n\t                    rule=rule, overrides=overrides, data_type=rule.check.data_type\n", "                )\n\t                checklist[rule.check_id] = check_list_object\n\t                schema_dict[rule.column_id] = pa_column\n\t            else:\n\t                validation_rules.append(rule)\n\t        # groups check types by column id so that they can be associated with matching column\n\t        for column_id, column_rules in groupby(\n\t            sorted(validation_rules, key=lambda item: item.column_id),\n\t            key=lambda item: item.column_id,\n\t        ):\n", "            cls.__generate_non_dtype_check__(\n\t                column_id=column_id,\n\t                checklist=checklist,\n\t                column_rules=list(column_rules),\n\t                overrides=overrides,\n\t                schema_dict=schema_dict,\n\t            )\n\t        return pa.DataFrameSchema(schema_dict, strict=False), checklist\n"]}
{"filename": "focus_validator/config_objects/rule.py", "chunked_list": ["from typing import Optional, Union\n\timport yaml\n\tfrom pydantic import BaseModel, root_validator\n\tfrom focus_validator.config_objects.common import (\n\t    SIMPLE_CHECKS,\n\t    AllowNullsCheck,\n\t    ChecklistObjectStatus,\n\t    DataTypeCheck,\n\t    ValueInCheck,\n\t    generate_check_friendly_name,\n", ")\n\tclass InvalidRule(BaseModel):\n\t    rule_path: str\n\t    error: str\n\t    error_type: str\n\tclass Rule(BaseModel):\n\t    \"\"\"\n\t    Base rule class that loads spec configs and generate\n\t    a pandera rule that can be validated.\n\t    \"\"\"\n", "    check_id: str\n\t    column_id: str\n\t    check: Union[SIMPLE_CHECKS, AllowNullsCheck, ValueInCheck, DataTypeCheck]\n\t    check_friendly_name: Optional[\n\t        str\n\t    ] = None  # auto generated or else can be overwritten\n\t    check_type_friendly_name: Optional[str] = None\n\t    class Config:\n\t        extra = \"forbid\"  # prevents config from containing any undesirable keys\n\t        frozen = (\n", "            True  # prevents any modification to any attribute onces loaded from config\n\t        )\n\t    @root_validator\n\t    def root_val(cls, values):\n\t        \"\"\"\n\t        Root validator that checks for all options passed in the config and generate missing options.\n\t        \"\"\"\n\t        check = values.get(\"check\")\n\t        check_friendly_name = values.get(\"check_friendly_name\")\n\t        column_id = values.get(\"column_id\")\n", "        if check is not None:\n\t            if isinstance(check, str):\n\t                check_type_friendly_name = \"\".join(\n\t                    [word.title() for word in check.split(\"_\")]\n\t                )\n\t            else:\n\t                check_type_friendly_name = check.__class__.__name__\n\t            values[\"check_type_friendly_name\"] = check_type_friendly_name\n\t            if check_friendly_name is None and column_id is not None:\n\t                values[\"check_friendly_name\"] = generate_check_friendly_name(\n", "                    check=check, column_id=column_id\n\t                )\n\t        return values\n\t    @staticmethod\n\t    def load_yaml(\n\t        rule_path, column_namespace: Optional[str] = None\n\t    ) -> Union[\"Rule\", InvalidRule]:\n\t        try:\n\t            with open(rule_path, \"r\") as f:\n\t                rule_obj = yaml.safe_load(f)\n", "            if (\n\t                isinstance(rule_obj, dict)\n\t                and rule_obj.get(\"column\")\n\t                and column_namespace\n\t            ):\n\t                rule_obj[\"column\"] = f\"{column_namespace}:{rule_obj['column']}\"\n\t            return Rule.parse_obj(rule_obj)\n\t        except Exception as e:\n\t            return InvalidRule(\n\t                rule_path=rule_path, error=str(e), error_type=e.__class__.__name__\n", "            )\n\tclass ChecklistObject(BaseModel):\n\t    check_name: str\n\t    column_id: str\n\t    friendly_name: Optional[str] = None\n\t    error: Optional[str] = None\n\t    status: ChecklistObjectStatus\n\t    rule_ref: Union[InvalidRule, Rule]\n"]}
{"filename": "focus_validator/config_objects/__init__.py", "chunked_list": ["from .common import ChecklistObjectStatus\n\tfrom .override import Override\n\tfrom .rule import ChecklistObject, InvalidRule, Rule\n\t__all__ = [\n\t    \"ChecklistObject\",\n\t    \"ChecklistObjectStatus\",\n\t    \"Rule\",\n\t    \"InvalidRule\",\n\t    \"Override\",\n\t]\n"]}
{"filename": "focus_validator/config_objects/common.py", "chunked_list": ["from enum import Enum\n\tfrom typing import List, Literal\n\tfrom pydantic import BaseModel\n\tclass AllowNullsCheck(BaseModel):\n\t    allow_nulls: bool\n\tclass ValueInCheck(BaseModel):\n\t    value_in: List[str]\n\tSIMPLE_CHECKS = Literal[\"check_unique\", \"column_required\"]\n\tclass DataTypes(Enum):\n\t    STRING = \"string\"\n", "    DECIMAL = \"decimal\"\n\t    DATETIME = \"datetime\"\n\t    CURRENCY_CODE = \"currency-code\"\n\tclass DataTypeCheck(BaseModel):\n\t    data_type: DataTypes\n\tclass ChecklistObjectStatus(Enum):\n\t    ERRORED = \"errored\"\n\t    PASSED = \"passed\"\n\t    FAILED = \"failed\"\n\t    SKIPPED = \"skipped\"\n", "    PENDING = \"pending\"\n\tdef generate_check_friendly_name(check, column_id):\n\t    if check == \"check_unique\":\n\t        return f\"{column_id}, requires unique values.\"\n\t    elif check == \"column_required\":\n\t        return f\"{column_id} is a required column.\"\n\t    elif isinstance(check, ValueInCheck):\n\t        return (\n\t            f\"{column_id} must have a value from the list: {','.join(check.value_in)}.\"\n\t        )\n", "    elif isinstance(check, AllowNullsCheck):\n\t        if check.allow_nulls:\n\t            return f\"{column_id} allows null values.\"\n\t        else:\n\t            return f\"{column_id} does not allow null values.\"\n\t    elif isinstance(check, DataTypeCheck):\n\t        return f\"{column_id} requires values of type {check.data_type.value}.\"\n"]}
{"filename": "focus_validator/config_objects/override.py", "chunked_list": ["from typing import List\n\timport yaml\n\tfrom pydantic import BaseModel\n\tclass Override(BaseModel):\n\t    overrides: List[str]\n\t    @staticmethod\n\t    def load_yaml(override_filename):\n\t        with open(override_filename, \"r\") as file:\n\t            override_obj = yaml.safe_load(file)\n\t        return Override.parse_obj(override_obj)\n"]}
{"filename": "focus_validator/outputter/outputter.py", "chunked_list": ["from focus_validator.exceptions import FocusNotImplementedError\n\tfrom focus_validator.outputter.outputter_console import ConsoleOutputter\n\tfrom focus_validator.outputter.outputter_unittest import UnittestOutputter\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n\tclass Outputter:\n\t    def __init__(self, output_type, output_destination):\n\t        if output_type == \"console\":\n\t            self.outputter = ConsoleOutputter(output_destination=output_destination)\n\t        elif output_type == \"unittest\":\n\t            self.outputter = UnittestOutputter(output_destination=output_destination)\n", "        else:\n\t            raise FocusNotImplementedError(\"Output type not supported\")\n\t    def write(self, result_set: ValidationResult):\n\t        self.outputter.write(result_set)\n"]}
{"filename": "focus_validator/outputter/__init__.py", "chunked_list": []}
{"filename": "focus_validator/outputter/outputter_console.py", "chunked_list": ["import pandas as pd\n\tfrom tabulate import tabulate\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n\tclass ConsoleOutputter:\n\t    def __init__(self, output_destination):\n\t        self.output_destination = output_destination\n\t        self.result_set = None\n\t    @staticmethod\n\t    def __restructure_check_list__(result_set: ValidationResult):\n", "        rows = []\n\t        for value in result_set.checklist.values():\n\t            if isinstance(value.rule_ref, Rule):\n\t                check_type = value.rule_ref.check_type_friendly_name\n\t            else:\n\t                check_type = \"ERRORED\"\n\t            row_obj = value.dict()\n\t            row_obj.update(\n\t                {\n\t                    \"check_type\": check_type,\n", "                    \"status\": row_obj[\"status\"].value.title(),\n\t                }\n\t            )\n\t            rows.append(row_obj)\n\t        df = pd.DataFrame(rows)\n\t        df.rename(\n\t            columns={\n\t                \"check_name\": \"Check Name\",\n\t                \"check_type\": \"Check Type\",\n\t                \"column_id\": \"Column\",\n", "                \"friendly_name\": \"Friendly Name\",\n\t                \"error\": \"Error\",\n\t                \"status\": \"Status\",\n\t            },\n\t            inplace=True,\n\t        )\n\t        df = df.reindex(\n\t            columns=[\n\t                \"Check Name\",\n\t                \"Check Type\",\n", "                \"Column\",\n\t                \"Friendly Name\",\n\t                \"Error\",\n\t                \"Status\",\n\t            ]\n\t        )\n\t        return df\n\t    def write(self, result_set: ValidationResult):\n\t        self.result_set = result_set\n\t        checklist = self.__restructure_check_list__(result_set)\n", "        print(\"Checklist:\")\n\t        print(tabulate(checklist, headers=\"keys\", tablefmt=\"psql\"))\n\t        if result_set.failure_cases is not None:\n\t            print(\"Checks summary:\")\n\t            print(\n\t                tabulate(\n\t                    tabular_data=result_set.failure_cases,  # type: ignore\n\t                    headers=\"keys\",\n\t                    tablefmt=\"psql\",\n\t                )\n", "            )\n"]}
{"filename": "focus_validator/outputter/outputter_unittest.py", "chunked_list": ["import logging\n\timport re\n\timport sys\n\timport xml.etree.cElementTree as ET\n\tfrom datetime import datetime, timezone\n\tclass UnittestFormatter:\n\t    def __init__(\n\t        self,\n\t        name,\n\t        tests,\n", "        failures,\n\t        errors,\n\t        skipped,\n\t        assertions=None,\n\t        time=\"0\",\n\t        timestamp=None,\n\t    ):\n\t        self.name = name\n\t        self.tests = str(tests)\n\t        self.failures = str(failures)\n", "        self.errors = str(errors)\n\t        self.skipped = str(skipped)\n\t        self.assertions = str(assertions)\n\t        if not self.assertions:\n\t            self.assertions = self.tests\n\t        self.time = time\n\t        self.timestamp = timestamp\n\t        if not self.timestamp:\n\t            self.timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S\")\n\t        self.results = {}\n", "    def add_testsuite(self, name, column):\n\t        if name not in self.results:\n\t            self.results[name] = {\"tests\": {}, \"time\": \"0\", \"column\": column}\n\t    def add_testcase(self, testsuite, name, result, message, check_type_name):\n\t        self.results[testsuite][\"tests\"][name] = {\n\t            \"result\": result.lower(),\n\t            \"message\": message,\n\t            \"check_type_name\": check_type_name,\n\t        }\n\t    def generate_unittest(self):\n", "        testsuites = ET.Element(\n\t            \"testsuites\",\n\t            name=self.name,\n\t            tests=self.tests,\n\t            failures=self.failures,\n\t            errors=self.errors,\n\t            skipped=self.skipped,\n\t            assertions=self.assertions,\n\t            time=self.time,\n\t            timestamp=self.timestamp,\n", "        )\n\t        for testsuite in sorted(self.results.keys()):\n\t            ts = ET.SubElement(\n\t                testsuites,\n\t                \"testsuite\",\n\t                name=f'{testsuite}-{self.results[testsuite][\"column\"]}',\n\t                time=\"0\",\n\t            )\n\t            for testcase in sorted(self.results[testsuite][\"tests\"].keys()):\n\t                tc = ET.SubElement(\n", "                    ts,\n\t                    \"testcase\",\n\t                    name=f\"{testcase} :: {self.results[testsuite]['tests'][testcase]['check_type_name']}\",\n\t                    time=\"0\",\n\t                )\n\t                if (\n\t                    self.results[testsuite][\"tests\"][testcase][\"result\"].lower()\n\t                    == \"failed\"\n\t                ):\n\t                    ET.SubElement(\n", "                        tc,\n\t                        \"failure\",\n\t                        name=testcase,\n\t                        message=self.results[testsuite][\"tests\"][testcase][\"message\"],\n\t                        type=\"AssertionError\",\n\t                    ).text = \"Failed\"\n\t                elif (\n\t                    self.results[testsuite][\"tests\"][testcase][\"result\"].lower()\n\t                    == \"skipped\"\n\t                ):\n", "                    ET.SubElement(\n\t                        tc,\n\t                        \"skipped\",\n\t                        message=self.results[testsuite][\"tests\"][testcase][\"message\"],\n\t                    )\n\t                elif (\n\t                    self.results[testsuite][\"tests\"][testcase][\"result\"].lower()\n\t                    == \"errored\"\n\t                ):\n\t                    ET.SubElement(\n", "                        tc,\n\t                        \"error\",\n\t                        message=self.results[testsuite][\"tests\"][testcase][\"message\"],\n\t                    )\n\t        tree = ET.ElementTree(testsuites)\n\t        if sys.version_info < (3, 9):\n\t            logging.warning(\n\t                \"produced output not indent due to lack of support before 3.9\"\n\t            )\n\t        else:\n", "            ET.indent(tree)\n\t        return tree\n\tclass UnittestOutputter:\n\t    def __init__(self, output_destination):\n\t        self.output_destination = output_destination\n\t    def write(self, result_set):\n\t        # First generate the summary\n\t        result_statuses = {}\n\t        for status in [\"passed\", \"failed\", \"skipped\", \"errored\"]:\n\t            result_statuses[status] = sum(\n", "                [1 for r in result_set.checklist.values() if r.status.value == status]\n\t            )\n\t        # format the results for processing\n\t        rows = [v.dict() for v in result_set.checklist.values()]\n\t        # Setup a Formatter and initiate with result totals\n\t        formatter = UnittestFormatter(\n\t            name=\"FOCUS Validations\",\n\t            tests=len(rows),\n\t            failures=result_statuses[\"failed\"],\n\t            errors=result_statuses[\"errored\"],\n", "            skipped=result_statuses[\"skipped\"],\n\t        )\n\t        # If there are any errors load them in first\n\t        if result_statuses[\"errored\"]:\n\t            formatter.add_testsuite(name=\"Base\", column=\"Unknown\")\n\t            for testcase in [r for r in rows if r.get(\"error\", False)]:\n\t                formatter.add_testcase(\n\t                    testsuite=\"Base\",\n\t                    name=testcase[\"check_name\"],\n\t                    result=testcase[\"status\"].value,\n", "                    message=testcase[\"error\"],\n\t                    check_type_name=None,\n\t                )\n\t        # Add the testcases to the testsuites\n\t        added_testsuites = {}\n\t        for testcase in [\n\t            r for r in rows if re.match(r\"^FV-[D,M][0-9]{3}-[0-9]{4}$\", r[\"check_name\"])\n\t        ]:\n\t            test_suite_id = testcase[\"check_name\"].rsplit(\"-\", 1)[0]\n\t            if test_suite_id not in added_testsuites:\n", "                formatter.add_testsuite(\n\t                    name=test_suite_id, column=testcase[\"column_id\"]\n\t                )\n\t            formatter.add_testcase(\n\t                testsuite=test_suite_id,\n\t                name=testcase[\"check_name\"],\n\t                result=testcase[\"status\"].value,\n\t                message=testcase[\"friendly_name\"],\n\t                check_type_name=testcase[\"rule_ref\"][\"check_type_friendly_name\"],\n\t            )\n", "        tree = formatter.generate_unittest()\n\t        tree.write(self.output_destination, encoding=\"utf-8\", xml_declaration=True)\n"]}
{"filename": "tests/test_validate_default_configs.py", "chunked_list": ["import os\n\timport re\n\tfrom itertools import groupby\n\tfrom unittest import TestCase\n\timport pandas as pd\n\tfrom focus_validator.config_objects import ChecklistObjectStatus, Rule\n\tfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\n\tfrom focus_validator.rules.spec_rules import SpecRules\n\tclass TestValidateDefaultConfigs(TestCase):\n\t    def test_version_sets_have_valid_config(self):\n", "        for root, dirs, _ in os.walk(\n\t            \"focus_validator/rules/version_sets\", topdown=False\n\t        ):\n\t            for version in dirs:\n\t                spec_rules = SpecRules(\n\t                    override_filename=None,\n\t                    rule_set_path=\"focus_validator/rules/version_sets\",\n\t                    rules_version=version,\n\t                    column_namespace=None,\n\t                )\n", "                spec_rules.load_rules()\n\t                result = spec_rules.validate(focus_data=pd.DataFrame())\n\t                for check_id in result.checklist.keys():\n\t                    self.assertIsNot(\n\t                        result.checklist[check_id].status, ChecklistObjectStatus.ERRORED\n\t                    )\n\t    def test_default_rules_with_sample_data(self):\n\t        check_id_pattern = re.compile(r\"FV-[D,M]\\d{3}-\\d{4}$\")\n\t        for root, dirs, files in os.walk(\n\t            \"focus_validator/rules/version_sets\", topdown=False\n", "        ):\n\t            column_test_suites = []\n\t            for file_path in files:\n\t                rule_path = os.path.join(root, file_path)\n\t                rule = Rule.load_yaml(rule_path=rule_path)\n\t                self.assertIsInstance(rule, Rule)\n\t                column_id = rule.column_id\n\t                self.assertIsNotNone(re.match(check_id_pattern, rule.check_id))\n\t                check_column_id = rule.check_id.split(\"-\")[1]\n\t                local_check_id = rule.check_id.split(\"-\")[2]\n", "                column_test_suites.append((column_id, check_column_id, local_check_id))\n\t            # sort column test suites to allow grouping by column\n\t            column_test_suites = sorted(column_test_suites, key=lambda item: item[0])\n\t            for _, test_suites in groupby(column_test_suites, key=lambda item: item[0]):\n\t                test_suites = list(test_suites)\n\t                self.assertEqual(\n\t                    len(set([test_suite[1] for test_suite in test_suites])), 1\n\t                )\n\t                local_check_ids = [int(test_suite[2]) for test_suite in test_suites]\n\t                # check all ids are in order\n", "                self.assertEqual(\n\t                    sorted(local_check_ids), list(range(1, len(local_check_ids) + 1))\n\t                )\n\t    def test_metric_file_format_metric_vs_dimension(self):\n\t        metric_check_id_pattern = re.compile(r\"FV-M\\d{3}-\\d{4}$\")\n\t        dimension_check_id_pattern = re.compile(r\"FV-D\\d{3}-\\d{4}$\")\n\t        for root, dirs, files in os.walk(\n\t            \"focus_validator/rules/version_sets\", topdown=False\n\t        ):\n\t            for file_path in files:\n", "                rule_path = os.path.join(root, file_path)\n\t                rule = Rule.load_yaml(rule_path=rule_path)\n\t                self.assertIsInstance(rule, Rule)\n\t                if isinstance(rule.check, DataTypeCheck):\n\t                    if rule.check.data_type == DataTypes.DECIMAL:\n\t                        self.assertIsNotNone(\n\t                            re.match(metric_check_id_pattern, rule.check_id),\n\t                            \"For metric column type check_id format should be FV-MYYY-YYYY\",\n\t                        )\n\t                    else:\n", "                        self.assertIsNotNone(\n\t                            re.match(dimension_check_id_pattern, rule.check_id),\n\t                            \"For metric column type check_id format should be FV-DYYY-YYYY\",\n\t                        )\n"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/test_spec_rules_unsupported_version.py", "chunked_list": ["from unittest import TestCase\n\tfrom focus_validator.exceptions import UnsupportedVersion\n\tfrom focus_validator.rules.spec_rules import SpecRules\n\tclass TestSpecRulesUnsupportedVersion(TestCase):\n\t    def test_load_unsupported_version(self):\n\t        with self.assertRaises(UnsupportedVersion) as cm:\n\t            SpecRules(\n\t                column_namespace=None,\n\t                rule_set_path=\"focus_validator/rules/version_sets\",\n\t                rules_version=\"0.1\",\n", "                override_filename=None,\n\t            )\n\t        self.assertEqual(\"FOCUS version 0.1 not supported.\", str(cm.exception))\n"]}
{"filename": "tests/test_main_function.py", "chunked_list": ["from unittest import TestCase\n\tfrom unittest.mock import patch\n\tfrom focus_validator.main import main\n\tfrom focus_validator.validator import Validator\n\tclass TestMainFunction(TestCase):\n\t    @patch.object(Validator, \"validate\")\n\t    def test_required_data_file(self, *_args):\n\t        with patch(\"sys.argv\", [\"file.py\", \"-h\"]):\n\t            with self.assertRaises(SystemExit) as cm:\n\t                main()\n", "            self.assertEqual(cm.exception.code, 0)\n\t    def test_supported_versions(self):\n\t        with patch(\"sys.argv\", [\"prog\", \"--supported-versions\"]):\n\t            try:\n\t                main()\n\t            except SystemExit as e:\n\t                self.assertNotEqual(e.code, 2)\n\t    @patch.object(Validator, \"validate\")\n\t    def test_data_file(self, *_args):\n\t        with patch(\"sys.argv\", [\"prog\", \"--data-file\", \"path/to/data.csv\"]):\n", "            try:\n\t                main()\n\t            except SystemExit as e:\n\t                self.assertNotEqual(e.code, 2)\n\t    @patch.object(Validator, \"validate\")\n\t    def test_column_namespace(self, *_args):\n\t        with patch(\n\t            \"sys.argv\",\n\t            [\n\t                \"prog\",\n", "                \"--data-file\",\n\t                \"path/to/data.csv\",\n\t                \"--column-namespace\",\n\t                \"namespace\",\n\t            ],\n\t        ):\n\t            try:\n\t                main()\n\t            except SystemExit as e:\n\t                self.assertNotEqual(e.code, 2)\n", "    @patch.object(Validator, \"validate\")\n\t    def test_override_file(self, *_args):\n\t        with patch(\n\t            \"sys.argv\",\n\t            [\n\t                \"prog\",\n\t                \"--data-file\",\n\t                \"path/to/data.csv\",\n\t                \"--override-file\",\n\t                \"path/to/override.yaml\",\n", "            ],\n\t        ):\n\t            try:\n\t                main()\n\t            except SystemExit as e:\n\t                self.assertNotEqual(e.code, 2)\n\t    @patch.object(Validator, \"validate\")\n\t    def test_output_format(self, *_args):\n\t        with patch(\n\t            \"sys.argv\",\n", "            [\"prog\", \"--data-file\", \"path/to/data.csv\", \"--output-format\", \"json\"],\n\t        ):\n\t            try:\n\t                main()\n\t            except SystemExit as e:\n\t                self.assertNotEqual(e.code, 2)\n"]}
{"filename": "tests/test_match_check_id_rule_config_file.py", "chunked_list": ["import os\n\tfrom pathlib import Path\n\tfrom unittest import TestCase\n\tfrom focus_validator.config_objects import Rule\n\tclass TestMatchCheckIdRuleConfigFile(TestCase):\n\t    def test_match_check_id_in_base_definitions(self):\n\t        for root, dirs, files in os.walk(\n\t            \"focus_validator/rules/base_rule_definitions/\", topdown=False\n\t        ):\n\t            for name in files:\n", "                rule_path = os.path.join(root, name)\n\t                rule = Rule.load_yaml(rule_path=rule_path)\n\t                self.assertIsInstance(rule, Rule)\n\t                self.assertEqual(rule.check_id, Path(name).stem)\n\t    def test_version_sets(self):\n\t        for root, dirs, files in os.walk(\n\t            \"focus_validator/rules/version_sets\", topdown=False\n\t        ):\n\t            for name in files:\n\t                rule_path = os.path.join(root, name)\n", "                self.assertTrue(\n\t                    os.path.islink(rule_path), f\"path not a sym link, {rule_path}\"\n\t                )\n\t                self.assertTrue(\n\t                    Path(rule_path).exists(), f\"invalid sym link, {rule_path}\"\n\t                )\n"]}
{"filename": "tests/test_invoice_issuer.py", "chunked_list": []}
{"filename": "tests/attributes/test_attribute_currency_code.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\timport pandas as pd\n\tfrom pandera.errors import SchemaErrors\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import (\n\t    ChecklistObjectStatus,\n\t    DataTypeCheck,\n\t    DataTypes,\n\t)\n", "from focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n\t# noinspection DuplicatedCode\n\tclass TestAttributeCurrencyType(TestCase):\n\t    def __eval_function__(self, sample_value, should_fail):\n\t        random_column_id = str(uuid4())\n\t        random_check_id = str(uuid4())\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n", "            rules=[\n\t                Rule(\n\t                    check_id=random_check_id,\n\t                    column_id=random_column_id,\n\t                    check=DataTypeCheck(data_type=DataTypes.CURRENCY_CODE),\n\t                )\n\t            ]\n\t        )\n\t        sample_data = pd.DataFrame([{random_column_id: sample_value}])\n\t        try:\n", "            schema.validate(sample_data, lazy=True)\n\t            failure_cases = None\n\t        except SchemaErrors as e:\n\t            failure_cases = e.failure_cases\n\t        validation_result = ValidationResult(\n\t            failure_cases=failure_cases, checklist=checklist\n\t        )\n\t        validation_result.process_result()\n\t        if should_fail:\n\t            self.assertIsNotNone(validation_result.failure_cases)\n", "            records = validation_result.failure_cases.to_dict(orient=\"records\")\n\t            self.assertEqual(len(records), 1)\n\t            collected_values = [record[\"Values\"] for record in records]\n\t            self.assertEqual(collected_values, [sample_value])\n\t            self.assertEqual(\n\t                validation_result.checklist[random_check_id].status,\n\t                ChecklistObjectStatus.FAILED,\n\t            )\n\t        else:\n\t            self.assertIsNone(validation_result.failure_cases)\n", "            self.assertEqual(\n\t                validation_result.checklist[random_check_id].status,\n\t                ChecklistObjectStatus.PASSED,\n\t            )\n\t    def test_valid_currency_code(self):\n\t        self.__eval_function__(\"USD\", False)\n\t    def test_valid_currency_code_bad_data_type(self):\n\t        self.__eval_function__(0, True)\n\t    def test_valid_currency_code_null_value(self):\n\t        self.__eval_function__(None, False)\n", "    def test_valid_currency_code_empty_string(self):\n\t        self.__eval_function__(\"\", True)\n"]}
{"filename": "tests/attributes/test_attribute_datetime.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\timport pandas as pd\n\tfrom pandera.errors import SchemaErrors\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import (\n\t    ChecklistObjectStatus,\n\t    DataTypeCheck,\n\t    DataTypes,\n\t)\n", "from focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n\t# noinspection DuplicatedCode\n\tclass TestAttributeDatetime(TestCase):\n\t    def __eval_function__(self, sample_value, should_fail):\n\t        random_column_id = str(uuid4())\n\t        random_check_id = str(uuid4())\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n", "            rules=[\n\t                Rule(\n\t                    check_id=random_check_id,\n\t                    column_id=random_column_id,\n\t                    check=DataTypeCheck(data_type=DataTypes.DATETIME),\n\t                )\n\t            ]\n\t        )\n\t        sample_data = pd.DataFrame([{random_column_id: sample_value}])\n\t        try:\n", "            schema.validate(sample_data, lazy=True)\n\t            failure_cases = None\n\t        except SchemaErrors as e:\n\t            failure_cases = e.failure_cases\n\t        validation_result = ValidationResult(\n\t            failure_cases=failure_cases, checklist=checklist\n\t        )\n\t        validation_result.process_result()\n\t        if should_fail:\n\t            self.assertIsNotNone(validation_result.failure_cases)\n", "            records = validation_result.failure_cases.to_dict(orient=\"records\")\n\t            self.assertEqual(len(records), 1)\n\t            collected_values = [record[\"Values\"] for record in records]\n\t            self.assertEqual(collected_values, [sample_value])\n\t            self.assertEqual(\n\t                validation_result.checklist[random_check_id].status,\n\t                ChecklistObjectStatus.FAILED,\n\t            )\n\t        else:\n\t            self.assertIsNone(validation_result.failure_cases)\n", "            self.assertEqual(\n\t                validation_result.checklist[random_check_id].status,\n\t                ChecklistObjectStatus.PASSED,\n\t            )\n\t    def test_null_value(self):\n\t        self.__eval_function__(None, False)\n\t    def test_month_without_padding(self):\n\t        self.__eval_function__(\"2023-5-12T21:00:00Z\", True)\n\t    def test_day_without_padding(self):\n\t        self.__eval_function__(\"2023-05-1T21:00:00Z\", True)\n", "    def test_hour_without_padding(self):\n\t        self.__eval_function__(\"2023-05-01T1:00:00Z\", True)\n\t    def test_minute_without_padding(self):\n\t        self.__eval_function__(\"2023-05-01T21:0:00Z\", True)\n\t    def test_second_without_padding(self):\n\t        self.__eval_function__(\"2023-05-01T21:00:5Z\", True)\n\t    def test_bad_data_type(self):\n\t        self.__eval_function__(0, True)\n\t    def test_empty_string(self):\n\t        self.__eval_function__(\"\", True)\n", "    def test_string_without_termination_character(self):\n\t        self.__eval_function__(\"2023-05-01T21:00:05\", True)\n\t    def test_valid_iso_string(self):\n\t        self.__eval_function__(\"2023-05-01T21:00:05Z\", False)\n"]}
{"filename": "tests/checks/test_null_value_check.py", "chunked_list": ["from unittest import TestCase\n\timport pandas as pd\n\tfrom pandera.errors import SchemaErrors\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import (\n\t    AllowNullsCheck,\n\t    ChecklistObjectStatus,\n\t    DataTypeCheck,\n\t    DataTypes,\n\t)\n", "from focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n\t# noinspection DuplicatedCode\n\tclass TestNullValueCheck(TestCase):\n\t    @staticmethod\n\t    def __generate_sample_rule_type_string__(allow_nulls: bool, data_type: DataTypes):\n\t        return [\n\t            Rule(\n", "                check_id=\"allow_null\",\n\t                column_id=\"test_dimension\",\n\t                check=AllowNullsCheck(allow_nulls=allow_nulls),\n\t            ),\n\t            Rule(\n\t                check_id=\"test_dimension\",\n\t                column_id=\"test_dimension\",\n\t                check=DataTypeCheck(data_type=data_type),\n\t            ),\n\t        ]\n", "    @staticmethod\n\t    def __validate_helper__(schema, checklist, sample_data):\n\t        try:\n\t            schema.validate(sample_data, lazy=True)\n\t            failure_cases = None\n\t        except SchemaErrors as e:\n\t            failure_cases = e.failure_cases\n\t        validation_result = ValidationResult(\n\t            checklist=checklist, failure_cases=failure_cases\n\t        )\n", "        validation_result.process_result()\n\t        return validation_result\n\t    def test_null_value_allowed_valid_case(self):\n\t        rules = self.__generate_sample_rule_type_string__(\n\t            allow_nulls=True, data_type=DataTypes.STRING\n\t        )\n\t        sample_data = pd.DataFrame(\n\t            [{\"test_dimension\": \"NULL\"}, {\"test_dimension\": \"some-value\"}]\n\t        )\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n", "            rules=rules, override_config=None\n\t        )\n\t        validation_result = self.__validate_helper__(\n\t            schema=schema, checklist=checklist, sample_data=sample_data\n\t        )\n\t        self.assertIsNone(validation_result.failure_cases)\n\t    def test_null_value_not_allowed_valid_case(self):\n\t        rules = self.__generate_sample_rule_type_string__(\n\t            allow_nulls=False, data_type=DataTypes.STRING\n\t        )\n", "        sample_data = pd.DataFrame(\n\t            [{\"test_dimension\": \"val1\"}, {\"test_dimension\": \"val2\"}]\n\t        )\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules, override_config=None\n\t        )\n\t        validation_result = self.__validate_helper__(\n\t            schema=schema, checklist=checklist, sample_data=sample_data\n\t        )\n\t        self.assertIsNone(validation_result.failure_cases)\n", "    def test_null_value_not_allowed_invalid_case(self):\n\t        rules = self.__generate_sample_rule_type_string__(\n\t            allow_nulls=False, data_type=DataTypes.STRING\n\t        )\n\t        sample_data = pd.DataFrame(\n\t            [{\"test_dimension\": \"NULL\"}, {\"test_dimension\": \"val2\"}]\n\t        )\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules, override_config=None\n\t        )\n", "        validation_result = self.__validate_helper__(\n\t            schema=schema, checklist=checklist, sample_data=sample_data\n\t        )\n\t        self.assertEqual(\n\t            validation_result.checklist[\"allow_null\"].status,\n\t            ChecklistObjectStatus.FAILED,\n\t        )\n\t        self.assertIsNotNone(validation_result.failure_cases)\n\t        failure_cases_dict = validation_result.failure_cases.to_dict(orient=\"records\")\n\t        self.assertEqual(len(failure_cases_dict), 1)\n", "        self.assertEqual(\n\t            failure_cases_dict[0],\n\t            {\n\t                \"Column\": \"test_dimension\",\n\t                \"Check Name\": \"allow_null\",\n\t                \"Description\": \" test_dimension does not allow null values.\",\n\t                \"Values\": \"NULL\",\n\t                \"Row #\": 1,\n\t            },\n\t        )\n", "    def test_null_value_allowed_invalid_case_with_empty_strings(self):\n\t        rules = self.__generate_sample_rule_type_string__(\n\t            allow_nulls=True, data_type=DataTypes.STRING\n\t        )\n\t        sample_data = pd.DataFrame([{\"test_dimension\": \"NULL\"}, {\"test_dimension\": \"\"}])\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules, override_config=None\n\t        )\n\t        validation_result = self.__validate_helper__(\n\t            schema=schema, checklist=checklist, sample_data=sample_data\n", "        )\n\t        self.assertEqual(\n\t            validation_result.checklist[\"allow_null\"].status,\n\t            ChecklistObjectStatus.FAILED,\n\t        )\n\t        self.assertIsNotNone(validation_result.failure_cases)\n\t        failure_cases_dict = validation_result.failure_cases.to_dict(orient=\"records\")\n\t        self.assertEqual(len(failure_cases_dict), 1)\n\t        self.assertEqual(\n\t            failure_cases_dict[0],\n", "            {\n\t                \"Column\": \"test_dimension\",\n\t                \"Check Name\": \"allow_null\",\n\t                \"Description\": \" test_dimension allows null values.\",\n\t                \"Values\": \"\",\n\t                \"Row #\": 2,\n\t            },\n\t        )\n\t    def test_null_value_allowed_invalid_case_with_nan_values(self):\n\t        rules = self.__generate_sample_rule_type_string__(\n", "            allow_nulls=True, data_type=DataTypes.STRING\n\t        )\n\t        sample_data = pd.DataFrame(\n\t            [{\"test_dimension\": \"NULL\"}, {\"test_dimension\": None}]\n\t        )\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules, override_config=None\n\t        )\n\t        validation_result = self.__validate_helper__(\n\t            schema=schema, checklist=checklist, sample_data=sample_data\n", "        )\n\t        self.assertEqual(\n\t            validation_result.checklist[\"allow_null\"].status,\n\t            ChecklistObjectStatus.FAILED,\n\t        )\n\t        self.assertIsNotNone(validation_result.failure_cases)\n\t        failure_cases_dict = validation_result.failure_cases.to_dict(orient=\"records\")\n\t        self.assertEqual(len(failure_cases_dict), 1)\n\t        self.assertEqual(\n\t            failure_cases_dict[0],\n", "            {\n\t                \"Column\": \"test_dimension\",\n\t                \"Check Name\": \"allow_null\",\n\t                \"Description\": \" test_dimension allows null values.\",\n\t                \"Values\": None,\n\t                \"Row #\": 2,\n\t            },\n\t        )\n"]}
{"filename": "tests/checks/test_decimal_type_check.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\timport numpy\n\timport pandas as pd\n\tfrom pandera.errors import SchemaErrors\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n", "from focus_validator.rules.spec_rules import ValidationResult\n\tclass TestDecimalTypeCheck(TestCase):\n\t    def test_decimal_column(self):\n\t        random_column_id = str(uuid4())\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=[\n\t                Rule(\n\t                    check_id=random_column_id,\n\t                    column_id=random_column_id,\n\t                    check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n", "                ),\n\t            ]\n\t        )\n\t        sample_df = pd.DataFrame(\n\t            [\n\t                {random_column_id: 0.1},\n\t                {random_column_id: 1},\n\t                {random_column_id: 1.001},\n\t            ]\n\t        )\n", "        values = schema.validate(sample_df)[random_column_id].values\n\t        self.assertEqual(list(values), [0.1, 1.0, 1.001])\n\t    def test_decimal_column_bad_data_type(self):\n\t        random_column_id = str(uuid4())\n\t        random_check_name = str(uuid4())\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=[\n\t                Rule(\n\t                    check_id=\"some-check\",\n\t                    column_id=random_column_id,\n", "                    check=\"column_required\",\n\t                ),\n\t                Rule(\n\t                    check_id=random_check_name,\n\t                    column_id=random_column_id,\n\t                    check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n\t                ),\n\t            ]\n\t        )\n\t        sample_df = pd.DataFrame(\n", "            [\n\t                {random_column_id: \"a\"},\n\t                {random_column_id: 1},\n\t                {random_column_id: 1.001},\n\t            ]\n\t        )\n\t        try:\n\t            schema.validate(sample_df, lazy=True)\n\t            failure_cases = None\n\t        except SchemaErrors as e:\n", "            failure_cases = e.failure_cases\n\t        result = ValidationResult(checklist=checklist, failure_cases=failure_cases)\n\t        result.process_result()\n\t        self.assertEqual(\n\t            result.failure_cases.to_dict(orient=\"records\"),\n\t            [\n\t                {\n\t                    \"Column\": random_column_id,\n\t                    \"Check Name\": random_check_name,\n\t                    \"Description\": \"Ensures that column is of decimal type.\",\n", "                    \"Values\": None,\n\t                    \"Row #\": numpy.NaN,\n\t                }\n\t            ],\n\t        )\n"]}
{"filename": "tests/data_loaders/__init__.py", "chunked_list": []}
{"filename": "tests/data_loaders/test_null_value_loader.py", "chunked_list": ["import io\n\tfrom unittest import TestCase\n\timport pandas as pd\n\tfrom focus_validator.data_loaders.csv_data_loader import CSVDataLoader\n\tfrom focus_validator.data_loaders.parquet_data_loader import ParquetDataLoader\n\tclass TestNullValueLoader(TestCase):\n\t    def test_null_value_from_csv(self):\n\t        sample_data = pd.DataFrame([{\"value\": \"NULL\"}])\n\t        buffer = io.BytesIO()\n\t        sample_data.to_csv(buffer, index=False)\n", "        buffer.seek(0)\n\t        self.assertEqual(buffer.read(), b\"value\\nNULL\\n\")\n\t        buffer.seek(0)\n\t        loader = CSVDataLoader(buffer)\n\t        data = loader.load()\n\t        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"NULL\"})\n\t    def test_null_value_from_csv_with_missing_value(self):\n\t        sample_data = pd.DataFrame([{\"value\": None}])\n\t        buffer = io.BytesIO()\n\t        sample_data.to_csv(buffer, index=False)\n", "        buffer.seek(0)\n\t        self.assertEqual(buffer.read(), b'value\\n\"\"\\n')\n\t        buffer.seek(0)\n\t        loader = CSVDataLoader(buffer)\n\t        data = loader.load()\n\t        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"\"})\n\t    def test_null_value_from_parquet(self):\n\t        sample_data = pd.DataFrame([{\"value\": \"NULL\"}])\n\t        buffer = io.BytesIO()\n\t        sample_data.to_parquet(buffer, index=False)\n", "        buffer.seek(0)\n\t        loader = ParquetDataLoader(buffer)\n\t        data = loader.load()\n\t        self.assertEqual(data.to_dict(orient=\"records\")[0], {\"value\": \"NULL\"})\n"]}
{"filename": "tests/data_loaders/test_parquet_loader.py", "chunked_list": ["from unittest import TestCase\n\timport pandas as pd\n\tfrom focus_validator.data_loaders.data_loader import DataLoader\n\tfrom focus_validator.data_loaders.parquet_data_loader import ParquetDataLoader\n\tclass TestParquetLoader(TestCase):\n\t    def test_load_parquet_file(self):\n\t        data_loader = DataLoader(data_filename=\"tests/samples/sample.parquet\")\n\t        df = data_loader.load()\n\t        self.assertIsInstance(df, pd.DataFrame)\n\t        self.assertEqual(\n", "            list(df.columns), [\"InvoiceIssuer\", \"ResourceID\", \"ChargeType\"]\n\t        )\n\t    def test_find_data_loader(self):\n\t        data_loader = DataLoader(data_filename=\"tests/samples/sample.parquet\")\n\t        data_loader_class = data_loader.find_data_loader()\n\t        self.assertEqual(data_loader_class, ParquetDataLoader)\n"]}
{"filename": "tests/config_objects/test_load_bad_rule_config_file.py", "chunked_list": ["from unittest import TestCase\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import ChecklistObjectStatus\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.config_objects.rule import InvalidRule\n\tclass TestLoadBadRuleConfigFile(TestCase):\n\t    def test_load_empty_config(self):\n\t        rule = Rule.load_yaml(\n", "            \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n\t        )\n\t        self.assertIsInstance(rule, InvalidRule)\n\t    def test_load_incomplete_config(self):\n\t        rule = Rule.load_yaml(\n\t            \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n\t        )\n\t        self.assertIsInstance(rule, InvalidRule)\n\t    def test_load_bad_yaml(self):\n\t        rule = Rule.load_yaml(\n", "            \"tests/samples/rule_configs/bad_rule_config_invalid_yaml.yaml\"\n\t        )\n\t        self.assertIsInstance(rule, InvalidRule)\n\t    def test_load_valid_rule(self):\n\t        rule = Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\")\n\t        self.assertIsInstance(rule, Rule)\n\t    def test_load_schema(self):\n\t        rules = [\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n", "            ),\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n\t            ),\n\t            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n\t            ),\n\t        ]\n\t        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n", "            rules=rules, override_config=None\n\t        )\n\t        self.assertEqual(\n\t            checklist[\"FV-D001-0001\"].status, ChecklistObjectStatus.PENDING\n\t        )\n\t        self.assertIsNone(checklist[\"FV-D001-0001\"].error)\n\t        self.assertIsNotNone(checklist[\"FV-D001-0001\"].friendly_name)\n\t        self.assertEqual(checklist[\"FV-D001\"].column_id, \"ChargeType\")\n\t        self.assertEqual(checklist[\"FV-D001\"].status, ChecklistObjectStatus.PENDING)\n\t        self.assertIsNone(checklist[\"FV-D001\"].error)\n", "        self.assertIsNotNone(checklist[\"FV-D001\"].friendly_name)\n\t        self.assertEqual(\n\t            checklist[\"FV-D001\"].friendly_name, \"Ensures that column is of string type.\"\n\t        )\n\t        for errored_file_paths in [\n\t            \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\",\n\t            \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\",\n\t        ]:\n\t            self.assertEqual(\n\t                checklist[errored_file_paths].status, ChecklistObjectStatus.ERRORED\n", "            )\n\t            self.assertIsNotNone(checklist[errored_file_paths].error)\n\t            self.assertIsNone(checklist[errored_file_paths].friendly_name)\n\t            self.assertEqual(checklist[errored_file_paths].column_id, \"Unknown\")\n\t    def test_load_schema_without_valid_column_metadata(self):\n\t        rules = [\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/bad_rule_config_empty_file.yaml\"\n\t            ),\n\t            Rule.load_yaml(\n", "                \"tests/samples/rule_configs/bad_rule_config_missing_check.yaml\"\n\t            ),\n\t            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n\t        ]\n\t        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules, override_config=None\n\t        )\n\t        self.assertEqual(\n\t            checklist[\"FV-D001-0001\"].status, ChecklistObjectStatus.ERRORED\n\t        )\n", "        self.assertEqual(\n\t            checklist[\"FV-D001-0001\"].error,\n\t            \"ConfigurationError: No configuration found for column.\",\n\t        )\n\t        self.assertIsNotNone(checklist[\"FV-D001-0001\"].friendly_name)\n\t        self.assertEqual(checklist[\"FV-D001-0001\"].column_id, \"ChargeType\")\n"]}
{"filename": "tests/config_objects/test_check_friendly_name.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\tfrom polyfactory.factories.pydantic_factory import ModelFactory\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import (\n\t    AllowNullsCheck,\n\t    DataTypeCheck,\n\t    ValueInCheck,\n\t)\n\tclass TestCheckFriendlyName(TestCase):\n", "    def test_default_friendly_name_is_generated(self):\n\t        random_column_name = str(uuid4())\n\t        model_factory = ModelFactory.create_factory(\n\t            model=Rule, check_friendly_name=None, column_id=random_column_name\n\t        )\n\t        for _ in range(1000):  # there is no way to generate all values for a field type\n\t            random_model = model_factory.build()\n\t            if random_model.check == \"column_required\":\n\t                self.assertEqual(\n\t                    random_model.check_friendly_name,\n", "                    f\"{random_column_name} is a required column.\",\n\t                )\n\t            elif random_model.check == \"check_unique\":\n\t                self.assertEqual(\n\t                    random_model.check_friendly_name,\n\t                    f\"{random_column_name}, requires unique values.\",\n\t                )\n\t            elif isinstance(random_model.check, AllowNullsCheck):\n\t                if random_model.check.allow_nulls:\n\t                    self.assertEqual(\n", "                        random_model.check_friendly_name,\n\t                        f\"{random_column_name} allows null values.\",\n\t                    )\n\t                else:\n\t                    self.assertEqual(\n\t                        random_model.check_friendly_name,\n\t                        f\"{random_column_name} does not allow null values.\",\n\t                    )\n\t            elif isinstance(random_model.check, DataTypeCheck):\n\t                self.assertEqual(\n", "                    random_model.check_friendly_name,\n\t                    f\"{random_column_name} requires values of type {random_model.check.data_type.value}.\",\n\t                )\n\t            elif isinstance(random_model.check, ValueInCheck):\n\t                options = \",\".join(random_model.check.value_in)\n\t                self.assertEqual(\n\t                    random_model.check_friendly_name,\n\t                    f\"{random_column_name} must have a value from the list: {options}.\",\n\t                )\n\t            else:\n", "                raise NotImplementedError(\n\t                    f\"check_type: {random_model.check} not implemented\"\n\t                )\n\t    def test_override_friendly_name(self):\n\t        random_friendly_name = str(uuid4())\n\t        sample_rule = Rule(\n\t            check=\"check_unique\",\n\t            check_id=\"sample-check\",\n\t            column_id=\"sample-column\",\n\t            check_friendly_name=random_friendly_name,\n", "        )\n\t        self.assertIsNotNone(random_friendly_name, sample_rule.check_friendly_name)\n"]}
{"filename": "tests/config_objects/test_required_column.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\timport pandas as pd\n\tfrom pandera.errors import SchemaErrors\n\tfrom focus_validator.config_objects import Override, Rule\n\tfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n", "class TestRequiredColumn(TestCase):\n\t    def test_load_column_required_config(self):\n\t        rules = [\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n\t            ),\n\t            Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/valid_rule_config_required.yaml\"\n\t            ),\n", "        ]\n\t        schema, _ = FocusToPanderaSchemaConverter.generate_pandera_schema(rules=rules)\n\t        self.assertIn(\"ChargeType\", schema.columns)\n\t        self.assertTrue(schema.columns[\"ChargeType\"].required)\n\t    def test_load_column_required_config_but_ignored(self):\n\t        rules = [\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n\t            ),\n\t            Rule.load_yaml(\n", "                \"tests/samples/rule_configs/valid_rule_config_required.yaml\"\n\t            ),\n\t        ]\n\t        schema, _ = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules, override_config=Override(overrides=[\"FV-D001-0001\"])\n\t        )\n\t        self.assertIn(\"ChargeType\", schema.columns)\n\t        self.assertFalse(schema.columns[\"ChargeType\"].required)\n\t    def test_check_summary_has_correct_mappings(self):\n\t        random_column_id = str(uuid4())\n", "        random_test_name = str(uuid4())\n\t        sample_data = pd.read_csv(\"tests/samples/multiple_failure_examples.csv\")\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=[\n\t                Rule(\n\t                    check_id=str(uuid4()),\n\t                    column_id=random_column_id,\n\t                    check=DataTypeCheck(data_type=DataTypes.STRING),\n\t                ),\n\t                Rule(\n", "                    check_id=random_test_name,\n\t                    column_id=random_column_id,\n\t                    check=\"column_required\",\n\t                    check_friendly_name=\"Column required.\",\n\t                ),\n\t                Rule.load_yaml(\n\t                    \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n\t                ),\n\t                Rule.load_yaml(\"tests/samples/rule_configs/valid_rule_config.yaml\"),\n\t            ]\n", "        )\n\t        with self.assertRaises(SchemaErrors) as cm:\n\t            schema.validate(sample_data, lazy=True)\n\t        failure_cases = cm.exception.failure_cases\n\t        result = ValidationResult(failure_cases=failure_cases, checklist=checklist)\n\t        result.process_result()\n\t        self.assertEqual(result.failure_cases.shape[0], 4)\n\t        missing_column_errors = result.failure_cases[\n\t            result.failure_cases[\"Column\"] == random_column_id\n\t        ]\n", "        raw_values = missing_column_errors.to_dict()\n\t        self.assertEqual(raw_values[\"Column\"], {1: random_column_id})\n\t        self.assertEqual(raw_values[\"Check Name\"], {1: random_test_name})\n\t        self.assertEqual(\n\t            raw_values[\"Description\"],\n\t            {1: \"Column required.\"},\n\t        )\n\t        self.assertEqual(raw_values[\"Values\"], {1: None})\n"]}
{"filename": "tests/config_objects/test_friendly_name_in_values_template.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\timport pandera as pa\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import ValueInCheck\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tclass TestFriendlyNameInValuesTemplate(TestCase):\n\t    def test_check_value_in(self):\n", "        rule = Rule(\n\t            check_id=str(uuid4()),\n\t            column_id=str(uuid4()),\n\t            check=ValueInCheck(value_in=[\"foo\", \"bar\"]),\n\t            check_friendly_name=\"Values in {values}\",\n\t        )\n\t        pa_check = FocusToPanderaSchemaConverter.__generate_pandera_check__(\n\t            rule=rule, check_id=str(uuid4())\n\t        )\n\t        self.assertIsInstance(pa_check, pa.Check)\n"]}
{"filename": "tests/config_objects/__init__.py", "chunked_list": []}
{"filename": "tests/config_objects/test_column_namespace.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\timport pandas as pd\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import (\n\t    AllowNullsCheck,\n\t    DataTypeCheck,\n\t    DataTypes,\n\t)\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n", "    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.validator import Validator\n\tclass TestColumnNamespace(TestCase):\n\t    def test_load_rule_config_with_namespace(self):\n\t        validator = Validator(\n\t            data_filename=\"tests/samples/multiple_failure_example_namespaced.csv\",\n\t            output_type=\"console\",\n\t            output_destination=None,\n\t            column_namespace=\"F\",\n", "        )\n\t        validator.load()\n\t        result = validator.spec_rules.validate(focus_data=validator.focus_data)\n\t        self.assertIsNotNone(result.failure_cases)\n\t    def test_load_rule_config_without_namespace(self):\n\t        random_column_id = str(uuid4())\n\t        random_test_name = str(uuid4())\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=[\n\t                Rule(\n", "                    check_id=random_test_name,\n\t                    column_id=random_column_id,\n\t                    check=DataTypeCheck(data_type=DataTypes.STRING),\n\t                ),\n\t                Rule(\n\t                    check_id=random_test_name,\n\t                    column_id=random_column_id,\n\t                    check=AllowNullsCheck(allow_nulls=False),\n\t                ),\n\t            ]\n", "        )\n\t        sample_data = pd.read_csv(\n\t            \"tests/samples/multiple_failure_example_namespaced.csv\"\n\t        )\n\t        result = schema.validate(\n\t            sample_data\n\t        )  # should not fail as columns are namespaced\n\t        self.assertIsNotNone(result)\n"]}
{"filename": "tests/config_objects/test_load_base_rules_only.py", "chunked_list": ["from unittest import TestCase\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tclass TestLoadBaseRulesOnly(TestCase):\n\t    \"\"\"\n\t    Ensures column config with only base config can enforce validations.\n\t    \"\"\"\n\t    def test_load_without_any_subsequent_rules(self):\n", "        rules = [\n\t            Rule.load_yaml(\n\t                \"tests/samples/rule_configs/valid_rule_config_column_metadata.yaml\"\n\t            )\n\t        ]\n\t        schema, _ = FocusToPanderaSchemaConverter.generate_pandera_schema(rules=rules)\n\t        self.assertIn(\"ChargeType\", schema.columns)\n"]}
{"filename": "tests/config_objects/test_check_type_friendly_name.py", "chunked_list": ["from unittest import TestCase\n\tfrom uuid import uuid4\n\tfrom polyfactory.factories.pydantic_factory import ModelFactory\n\tfrom pydantic import ValidationError\n\tfrom focus_validator.config_objects import Rule\n\tfrom focus_validator.config_objects.common import DataTypes, DataTypeCheck\n\tclass TestCheckTypeFriendlyName(TestCase):\n\t    def test_generate_name_for_check_types(self):\n\t        \"\"\"\n\t        there is no way to generate all values for a field type hence generating random instances\n", "        in hope of catching any validation error\n\t        :return:\n\t        \"\"\"\n\t        model_factory = ModelFactory.create_factory(model=Rule)\n\t        for _ in range(1000):  # there is no way to generate all values for a field type\n\t            random_model = model_factory.build()\n\t            self.assertIn(\n\t                random_model.check_type_friendly_name,\n\t                [\n\t                    \"CheckUnique\",\n", "                    \"AllowNullsCheck\",\n\t                    \"ValueInCheck\",\n\t                    \"ColumnRequired\",\n\t                    \"DataTypeCheck\",\n\t                ],  # needs to be updated as more checks are introduced\n\t            )\n\t    def test_random_value_is_ignored(self):\n\t        sample = Rule(\n\t            check_id=str(uuid4()),\n\t            column_id=str(uuid4()),\n", "            check=\"check_unique\",\n\t            check_friendly_name=\"some-check\",\n\t            check_type_friendly_name=\"some-name\",\n\t        )\n\t        self.assertEqual(sample.check_type_friendly_name, \"CheckUnique\")\n\t    def test_data_type_config(self):\n\t        model_factory = ModelFactory.create_factory(model=Rule)\n\t        sample_data_type = model_factory.build(\n\t            **{\"check\": DataTypeCheck(data_type=DataTypes.STRING)}\n\t        )\n", "        self.assertEqual(sample_data_type.check_type_friendly_name, \"DataTypeCheck\")\n\t    def test_check_type_config_deny_update(self):\n\t        model_factory = ModelFactory.create_factory(model=Rule)\n\t        sample_data_type = model_factory.build()\n\t        with self.assertRaises(TypeError) as cm:\n\t            sample_data_type.check_type_friendly_name = \"new_value\"\n\t        self.assertIn(\n\t            '\"Rule\" is immutable and does not support item assignment',\n\t            str(cm.exception),\n\t        )\n", "    def test_assign_bad_type(self):\n\t        with self.assertRaises(ValidationError) as cm:\n\t            Rule(\n\t                check_id=str(uuid4()),\n\t                column_id=str(uuid4()),\n\t                check=DataTypeCheck(data_type=\"bad-type\"),\n\t                check_type_friendly_name=\"some-check\",\n\t            )\n\t        self.assertEqual(len(cm.exception.errors()), 1)\n\t        self.assertIn(\n", "            \"value is not a valid enumeration member; permitted:\", str(cm.exception)\n\t        )\n"]}
{"filename": "tests/outputter/test_outputter_unittest.py", "chunked_list": ["import io\n\timport xml.etree.cElementTree as ET\n\tfrom random import randint\n\tfrom unittest import TestCase\n\tfrom uuid import uuid4\n\tfrom focus_validator.config_objects import InvalidRule, Rule\n\tfrom focus_validator.config_objects.common import DataTypeCheck, DataTypes\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n", "from focus_validator.outputter.outputter_unittest import UnittestOutputter\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n\t# noinspection DuplicatedCode\n\tclass TestOutputterUnittest(TestCase):\n\t    def test_unittest_output_all_valid_rules(self):\n\t        random_check_id = f\"FV-D00{randint(0, 9)}\"\n\t        random_column_id = str(uuid4())\n\t        rules = [\n\t            Rule(\n\t                check_id=f\"{random_check_id}-0001\",\n", "                column_id=random_column_id,\n\t                check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n\t            ),\n\t            Rule(\n\t                check_id=f\"{random_check_id}-0002\",\n\t                column_id=random_column_id,\n\t                check=\"column_required\",\n\t            ),\n\t        ]\n\t        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n", "            rules=rules\n\t        )\n\t        result = ValidationResult(checklist=checklist)\n\t        result.process_result()\n\t        buffer = io.BytesIO()\n\t        outputter = UnittestOutputter(output_destination=buffer)\n\t        outputter.write(result_set=result)\n\t        buffer.seek(0)\n\t        output = buffer.read()\n\t        testsuites = ET.fromstring(output)\n", "        self.assertEqual(len(testsuites), 1)  # assert one column in sample rules config\n\t        self.assertEqual(testsuites.get(\"name\"), \"FOCUS Validations\")\n\t        for testsuite in testsuites:\n\t            self.assertEqual(\n\t                testsuite.get(\"name\"), f\"{random_check_id}-{random_column_id}\"\n\t            )\n\t            self.assertEqual(\n\t                len(testsuite), 2\n\t            )  # assert two tests in sample rules config\n\t            self.assertEqual(\n", "                testsuite[0].get(\"name\"), f\"{random_check_id}-0001 :: DataTypeCheck\"\n\t            )\n\t            self.assertEqual(\n\t                testsuite[1].get(\"name\"), f\"{random_check_id}-0002 :: ColumnRequired\"\n\t            )\n\t    def test_unittest_output_with_bad_rule(self):\n\t        random_path = str(uuid4())\n\t        random_error = str(uuid4())\n\t        random_error_type = str(uuid4())\n\t        rules = [\n", "            InvalidRule(\n\t                error=random_error, error_type=random_error_type, rule_path=random_path\n\t            )\n\t        ]\n\t        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules\n\t        )\n\t        result = ValidationResult(checklist=checklist)\n\t        result.process_result()\n\t        buffer = io.BytesIO()\n", "        outputter = UnittestOutputter(output_destination=buffer)\n\t        outputter.write(result_set=result)\n\t        buffer.seek(0)\n\t        output = buffer.read()\n\t        testsuites = ET.fromstring(output)\n\t        self.assertEqual(testsuites.get(\"tests\"), \"1\")\n\t        self.assertEqual(testsuites.get(\"failures\"), \"0\")\n\t        self.assertEqual(testsuites.get(\"skipped\"), \"0\")\n\t        self.assertEqual(testsuites.get(\"errors\"), \"1\")\n\t    def test_outputter_with_metric_dimension(self):\n", "        random_check_id = f\"FV-M00{randint(0, 9)}\"\n\t        random_column_id = str(uuid4())\n\t        rules = [\n\t            Rule(\n\t                check_id=f\"{random_check_id}-0001\",\n\t                column_id=random_column_id,\n\t                check=DataTypeCheck(data_type=DataTypes.DECIMAL),\n\t            ),\n\t            Rule(\n\t                check_id=f\"{random_check_id}-0002\",\n", "                column_id=random_column_id,\n\t                check=\"column_required\",\n\t            ),\n\t        ]\n\t        _, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=rules\n\t        )\n\t        result = ValidationResult(checklist=checklist)\n\t        result.process_result()\n\t        buffer = io.BytesIO()\n", "        outputter = UnittestOutputter(output_destination=buffer)\n\t        outputter.write(result_set=result)\n\t        buffer.seek(0)\n\t        output = buffer.read()\n\t        testsuites = ET.fromstring(output)\n\t        self.assertEqual(len(testsuites), 1)  # assert one column in sample rules config\n\t        self.assertEqual(testsuites.get(\"name\"), \"FOCUS Validations\")\n\t        for testsuite in testsuites:\n\t            self.assertEqual(\n\t                testsuite.get(\"name\"), f\"{random_check_id}-{random_column_id}\"\n", "            )\n\t            self.assertEqual(\n\t                len(testsuite), 2\n\t            )  # assert two tests in sample rules config\n\t            self.assertEqual(\n\t                testsuite[0].get(\"name\"), f\"{random_check_id}-0001 :: DataTypeCheck\"\n\t            )\n\t            self.assertEqual(\n\t                testsuite[1].get(\"name\"), f\"{random_check_id}-0002 :: ColumnRequired\"\n\t            )\n"]}
{"filename": "tests/outputter/__init__.py", "chunked_list": []}
{"filename": "tests/outputter/test_outputter_console.py", "chunked_list": ["from unittest import TestCase\n\tfrom focus_validator.config_objects import InvalidRule\n\tfrom focus_validator.config_objects.focus_to_pandera_schema_converter import (\n\t    FocusToPanderaSchemaConverter,\n\t)\n\tfrom focus_validator.outputter.outputter_console import ConsoleOutputter\n\tfrom focus_validator.rules.spec_rules import ValidationResult\n\tfrom focus_validator.validator import Validator\n\tclass TestOutputterConsole(TestCase):\n\t    def test_failure_output(self):\n", "        validator = Validator(\n\t            data_filename=\"tests/samples/multiple_failure_example_namespaced.csv\",\n\t            output_type=\"console\",\n\t            output_destination=None,\n\t            column_namespace=\"F\",\n\t        )\n\t        validator.load()\n\t        result = validator.spec_rules.validate(focus_data=validator.focus_data)\n\t        outputter = ConsoleOutputter(output_destination=None)\n\t        checklist = outputter.__restructure_check_list__(result_set=result)\n", "        self.assertEqual(\n\t            list(checklist.columns),\n\t            [\n\t                \"Check Name\",\n\t                \"Check Type\",\n\t                \"Column\",\n\t                \"Friendly Name\",\n\t                \"Error\",\n\t                \"Status\",\n\t            ],\n", "        )\n\t    def test_output_with_bad_configs_loaded(self):\n\t        schema, checklist = FocusToPanderaSchemaConverter.generate_pandera_schema(\n\t            rules=[\n\t                InvalidRule(\n\t                    rule_path=\"bad_rule_path\",\n\t                    error=\"random-error\",\n\t                    error_type=\"ValueError\",\n\t                )\n\t            ]\n", "        )\n\t        validation_result = ValidationResult(failure_cases=None, checklist=checklist)\n\t        validation_result.process_result()\n\t        outputter = ConsoleOutputter(output_destination=None)\n\t        checklist = outputter.__restructure_check_list__(result_set=validation_result)\n\t        self.assertEqual(\n\t            checklist.to_dict(orient=\"records\"),\n\t            [\n\t                {\n\t                    \"Check Name\": \"bad_rule_path\",\n", "                    \"Check Type\": \"ERRORED\",\n\t                    \"Column\": \"Unknown\",\n\t                    \"Friendly Name\": None,\n\t                    \"Error\": \"ValueError: random-error\",\n\t                    \"Status\": \"Errored\",\n\t                }\n\t            ],\n\t        )\n"]}
