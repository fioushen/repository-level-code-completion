{"filename": "us_lat/cluster_latency.py", "chunked_list": ["from pathlib import Path\n\timport paramiko\n\timport sys\n\tclass bcolors:\n\t    HEADER = '\\033[95m'\n\t    OKBLUE = '\\033[94m'\n\t    OKGREEN = '\\033[92m'\n\t    WARNING = '\\033[93m'\n\t    FAIL = '\\033[91m'\n\t    ENDC = '\\033[0m'\n", "    BOLD = '\\033[1m'\n\t    UNDERLINE = '\\033[4m'\n\tif (len(sys.argv) != 4) :\n\t    print(bcolors.WARNING + 'Usage:')\n\t    print('python3 cluster_latency.py compute_node_num epoch_start epoch_num' + bcolors.ENDC)\n\t    exit(0)\n\tnode_num = int(sys.argv[1])\n\tepoch_start = int(sys.argv[2])\n\tepoch_num = int(sys.argv[3])\n\t# epoch_start = 1\n", "# epoch_num = 10\n\tcluster_ips = [\n\t  '10.10.1.1',\n\t  '10.10.1.2',\n\t  '10.10.1.3',\n\t  '10.10.1.4',\n\t  '10.10.1.5',\n\t  '10.10.1.6',\n\t  '10.10.1.7',\n\t  '10.10.1.8',\n", "  '10.10.1.9',\n\t  '10.10.1.10',\n\t  '10.10.1.11',\n\t  '10.10.1.12',\n\t  '10.10.1.13',\n\t  '10.10.1.14',\n\t  '10.10.1.15',\n\t  '10.10.1.16',\n\t][:node_num]\n\tlat_cnt = dict()\n", "lat_dir = Path(__file__).resolve().parent\n\tprint(f'latency_dir: {lat_dir}')\n\tdef get_sftp_client(hostname):\n\t  port = 22\n\t  client = paramiko.SSHClient()\n\t  client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\t  client.connect(hostname, port, compress=True)\n\t  return client.open_sftp()\n\tdef load_remote_lat(sftp_client : paramiko.SFTPClient, file_path):\n\t  remote_file = sftp_client.open(file_path)\n", "  try:\n\t    for line in remote_file:\n\t      lat, cnt = line.strip().split('\\t', 1)\n\t      if int(cnt):\n\t        if lat not in lat_cnt:\n\t          lat_cnt[lat] = 0\n\t        lat_cnt[lat] += int(cnt)\n\t  finally:\n\t    remote_file.close()\n\tdef cal_lat(e_id):\n", "  print(f'### epoch-{e_id} ###')\n\t  all_lat = sum(lat_cnt.values())\n\t  th50 = all_lat / 2\n\t  th90 = all_lat * 9 / 10\n\t  th95 = all_lat * 95 / 100\n\t  th99 = all_lat * 99 / 100\n\t  th999 = all_lat * 999 / 1000\n\t  cum = 0\n\t  for lat, cnt in sorted(lat_cnt.items(), key=lambda s:float(s[0])):\n\t    cum += cnt\n", "    if cum >= th50:\n\t      print(f'p50 {lat}', end='\\t')\n\t      th50 = all_lat + 1\n\t    if cum >= th90:\n\t      print(f'p90 {lat}', end='\\t')\n\t      th90 = all_lat + 1\n\t    if cum >= th95:\n\t      print(f'p95 {lat}', end='\\t')\n\t      th95 = all_lat + 1\n\t    if cum >= th99:\n", "      print(f'p99 {lat}', end='\\t')\n\t      th99 = all_lat + 1\n\t    if cum >= th999:\n\t      print(f'p999 {lat}')\n\t      th999 = all_lat + 1\n\tif __name__ == '__main__':\n\t  sftp_clients = [get_sftp_client(hostname) for hostname in cluster_ips]\n\t  for e_id in range(epoch_start, epoch_start + epoch_num):\n\t    lat_cnt.clear()\n\t    for client in sftp_clients:\n", "      load_remote_lat(client, str(lat_dir / f'epoch_{e_id}.lat'))\n\t    cal_lat(e_id)\n"]}
{"filename": "exp/fig_12.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '12'\n\tsmall_fig_num = {'YCSB LOAD': 'a', 'YCSB A': 'b', 'YCSB B': 'c', 'YCSB C': 'd', 'YCSB D': 'e'}\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n", "master_ip     = params['master_ip']\n\tcmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods            = fig_params['methods']\n\tworkload_names     = fig_params['workload_names']\n\ttarget_epochs      = fig_params['target_epoch']\n\tCN_and_client_nums = fig_params['client_num']  # as Sherman/ART saturates the network more easily than SMART, we test them with fewer clients\n\tMN_num             = fig_params['MN_num']\n", "key_type           = fig_params['key_size']\n\tvalue_size         = fig_params['value_size']\n\tcache_size         = fig_params['cache_size']\n\tspan_size          = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    for workload, workload_name in workload_names.items():\n\t        plot_data = {\n\t            'methods': methods,\n\t            'X_data': {method: [] for method in methods},\n", "            'Y_data': {method: [] for method in methods}\n\t        }\n\t        for method in methods:\n\t            project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t            work_dir = f\"{project_dir}/build\"\n\t            env_cmd = f\"cd {work_dir}\"\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t            cmake_option = cmake_options[method]\n\t            if workload != 'YCSB LOAD':\n", "                cmake_option = cmake_option.replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t            cmd.all_execute(BUILD_PROJECT)\n\t            for CN_num, client_num_per_CN in CN_and_client_nums[method][workload]:\n\t                CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t                SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t                YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t                KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t                cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t                while True:\n", "                    try:\n\t                        cmd.one_execute(CLEAR_MEMC)\n\t                        cmd.all_execute(KILL_PROCESS, CN_num)\n\t                        logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                        _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epochs[workload])\n\t                        tpt, _, _, _ = tp.get_statistics(logs, target_epochs[workload])\n\t                        break\n\t                    except (FunctionTimedOut, Exception) as e:\n\t                        print_WARNING(f\"Error! Retry... {e}\")\n\t                print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n", "                plot_data['X_data'][method].append(tpt)\n\t                plot_data['Y_data'][method].append(p99_lat)\n\t        # save data\n\t        Path(output_path).mkdir(exist_ok=True)\n\t        with (Path(output_path) / f'fig_{fig_num}{small_fig_num[workload]}.json').open(mode='w') as f:\n\t            json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n", "    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    for small_num in small_fig_num.values():\n\t        pg.generate(fig_num + small_num)\n"]}
{"filename": "exp/fig_18a.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '18a'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tzipfians, read_ratio      = fig_params['zipfian'], fig_params['read_ratio']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\tspan_size                 = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    plot_data = {\n\t        'methods': methods,\n\t        'X_data': zipfians,\n\t        'Y_data': {method: [] for method in methods}\n\t    }\n", "    for method in methods:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        # change config\n\t        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\t        cmd.all_execute(BUILD_PROJECT, CN_num)\n\t        for zipfian in zipfians:\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n", "            ZIPFIAN_TEST = f\"{env_cmd} && ./zipfian_test {CN_num} {read_ratio} {client_num_per_CN} {zipfian} 2\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 zipfian_test\"\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(ZIPFIAN_TEST, CN_num)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n", "                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} zipfian={zipfian} tpt={tpt}\")\n\t            plot_data['Y_data'][method].append(tpt)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n", "    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_18c.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '18c'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_sizes               = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\tspan_size                 = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t        fig_params = json.load(f)\n\t    CN_num, client_num_per_CN = fig_params['client_num']\n\t    key_type = fig_params['key_size']\n\t    value_sizes = fig_params['value_size']\n", "    cache_size = fig_params['cache_size']\n\t    plot_data = {\n\t        'methods': methods,\n\t        'X_data': value_sizes,\n\t        'Y_data': {method: [] for method in methods}\n\t    }\n\t    for method in methods:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n", "        for value_size in value_sizes:\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(BUILD_PROJECT, CN_num)\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n", "            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} value_size={value_size} tpt={tpt}\")\n", "            plot_data['Y_data'][method].append(tpt)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n", "        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_4a.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '4a'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethod                    = fig_params['methods']\n\twrite_ratios              = fig_params['write_ratio']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    plot_data = {\n\t        'methods': ['Throughput', 'P99 Latency'],\n\t        'X_data': write_ratios,\n\t        'Y_data': {'Throughput': [], 'P99 Latency': []}\n\t    }\n\t    project_dir = f\"{home_dir}/SMART\"\n", "    work_dir = f\"{project_dir}/build\"\n\t    env_cmd = f\"cd {work_dir}\"\n\t    # change config\n\t    sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n\t    cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n\t    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t    cmd.all_execute(BUILD_PROJECT, CN_num)\n\t    for write_ratio in write_ratios:\n\t        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {write_ratio}- {key_type} {CN_num} {client_num_per_CN}\"\n", "        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {write_ratio}-\"\n\t        KILL_PROCESS = f\"{env_cmd} && killall -9 zipfian_test\"\n\t        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t        while True:\n\t            try:\n\t                cmd.one_execute(CLEAR_MEMC)\n\t                cmd.all_execute(KILL_PROCESS, CN_num)\n\t                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n\t                tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n", "                break\n\t            except (FunctionTimedOut, Exception) as e:\n\t                print_WARNING(f\"Error! Retry... {e}\")\n\t        print_GOOD(f\"[FINISHED POINT] method={method} write_ratio={write_ratio} tpt={tpt} p99_lat={p99_lat}\")\n\t        plot_data['Y_data']['Throughput'].append(tpt)\n\t        plot_data['Y_data']['P99 Latency'].append(p99_lat)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n", "if __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_3b.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '3b'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_types                 = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\tspan_sizes                = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    def get_legend(method, span_size):\n\t        return method if span_size is None else f'{method} ({span_size}-span)'\n\t    def get_xlabel(key_type):\n\t        return 'int (8 byte)' if key_type == 'randint' else 'string (32 byte)'\n\t    plot_methods = [(method, None) for method in methods if method != 'Sherman'] + [(method, span_size) for method in methods if method == 'Sherman' for span_size in span_sizes]\n", "    plot_data = {\n\t        'methods': [get_legend(method, span_size) for method, span_size in plot_methods],\n\t        'bar_groups' : [get_xlabel(key_type) for key_type in ['randint', 'email']],\n\t        'Y_data' : {\n\t            get_legend(method, span_size): {}  # store tpt with int, string key, respectively\n\t            for method, span_size in plot_methods\n\t        }\n\t    }\n\t    for method, span_size in plot_methods:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n", "        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        for key_type in key_types:\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t            cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n\t            if method == 'ART':\n\t                cmake_option = cmake_option.replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n", "            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(BUILD_PROJECT, CN_num)\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n", "                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} span_size={span_size} tpt={tpt}\")\n\t            plot_data['Y_data'][get_legend(method, span_size)][get_xlabel(key_type)] = tpt\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n", "if __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_3c.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '3c'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_sizes               = fig_params['cache_size']\n\tspan_size                 = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    plot_data = {\n\t        'methods': methods,\n\t        'X_data': cache_sizes,\n\t        'Y_data': {method: [] for method in methods}\n\t    }\n", "    for method in methods:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        for cache_size in cache_sizes:\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t            cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n\t            if method == 'Sherman':\n\t                cmake_option = cmake_option.replace('-DENABLE_CACHE_EVICTION=off', '-DENABLE_CACHE_EVICTION=on')\n", "            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(BUILD_PROJECT, CN_num)\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n", "                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} cache_size={cache_size} tpt={tpt}\")\n\t            plot_data['Y_data'][method].append(tpt)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n", "    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_14.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '14'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_sizes               = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\tspan_size                 = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    metrics = ['Throughput', 'P50 Latency', 'P99 Latency']\n\t    plot_data = {\n\t        'methods': methods,\n\t        'bar_groups': list(map(str, value_sizes)),\n\t        'metrics': metrics,\n", "        'Y_data': {\n\t            method: {\n\t                str(value_size): {}  # store tpt, p50, p99, respectively\n\t                for value_size in value_sizes\n\t            }\n\t            for method in methods\n\t        }\n\t    }\n\t    for method in methods:\n\t        project_dir = f\"{home_dir}/{method}\"\n", "        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        for value_size in value_sizes:\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n", "            cmd.all_execute(BUILD_PROJECT, CN_num)\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    p50_lat, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n\t                    break\n", "                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] value_size={value_size} method={method} tpt={tpt} p50_lat={p50_lat} p99_lat={p99_lat}\")\n\t            plot_data['Y_data'][method][str(value_size)] = {metrics[0]: tpt, metrics[1]: p50_lat, metrics[2]: p99_lat}\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n", "    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_3a.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '3a'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                 = fig_params['methods']\n\tworkload, workload_name = fig_params['workload_names']\n\ttarget_epoch            = fig_params['target_epoch']\n\tclient_nums             = fig_params['client_num']\n\tMN_nums                 = fig_params['MN_num']\n\tkey_type                = fig_params['key_size']\n", "value_size              = fig_params['value_size']\n\tcache_size              = fig_params['cache_size']\n\tspan_size               = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    def get_legend(method, MN_num):\n\t        return f'{method} ({MN_num}MN)'\n\t    plot_lines = [(method, MN_num) for method in methods for MN_num in MN_nums]\n\t    legends = [get_legend(method, MN_num) for method, MN_num in plot_lines]\n\t    plot_data = {\n", "        'methods': legends,\n\t        'X_data': [0] + [t[0] * t[1] for t in client_nums],\n\t        'Y_data': {legend: [0] for legend in legends}\n\t    }\n\t    for method, MN_num in plot_lines:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        # change config\n\t        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n", "        cmake_option = cmake_options[method].replace('-DENABLE_CACHE=on', '-DENABLE_CACHE=off') if cache_size == 0 else cmake_options[method]\n\t        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t        cmd.all_execute(BUILD_PROJECT)\n\t        for CN_num, client_num_per_CN in client_nums:\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t            while True:\n", "                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} MN_num={MN_num} client_num={CN_num*client_num_per_CN} tpt={tpt}\")\n\t            plot_data['Y_data'][get_legend(method, MN_num)].append(tpt)\n", "    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n", "    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_18b.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '18b'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type, key_sizes       = 'randint', fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\tspan_size                 = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t        fig_params = json.load(f)\n\t    CN_num, client_num_per_CN = fig_params['client_num']\n\t    key_type, key_sizes = 'randint', fig_params['key_size']\n\t    value_size = fig_params['value_size']\n", "    cache_size = fig_params['cache_size']\n\t    plot_data = {\n\t        'methods': methods,\n\t        'X_data': key_sizes,\n\t        'Y_data': {method: [] for method in methods}\n\t    }\n\t    for method in methods:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n", "        for key_size in key_sizes:\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', key_size, value_size, cache_size, MN_num, span_size)\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(BUILD_PROJECT, CN_num)\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n", "            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} key_size={key_size} tpt={tpt}\")\n", "            plot_data['Y_data'][method].append(tpt)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n", "        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_17.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '17'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_sizes               = fig_params['cache_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    metrics = ['Throughput', 'Cache Hit Ratio']\n\t    plot_data = {\n\t        'methods': methods,\n\t        'bar_groups': list(map(str, cache_sizes)),\n\t        'metrics': metrics,\n\t        'Y_data': {\n", "            method: {\n\t                str(cache_size): {}  # store tpt, cache-hit rate, respectively\n\t                for cache_size in cache_sizes\n\t            }\n\t            for method in methods\n\t        }\n\t    }\n\t    for method in methods:\n\t        project_dir = f\"{home_dir}/SMART\"\n\t        work_dir = f\"{project_dir}/build\"\n", "        env_cmd = f\"cd {work_dir}\"\n\t        for cache_size in cache_sizes:\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n\t            cmake_option = cmake_options[method].replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n", "            cmd.all_execute(BUILD_PROJECT, CN_num)\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    tpt, cache_hit_rate, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n", "                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} cache_size={cache_size} tpt={tpt} cache_hit_rate={cache_hit_rate}\")\n\t            plot_data['Y_data'][method][str(cache_size)] = {metrics[0]: tpt, metrics[1]: cache_hit_rate}\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n", "    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_13.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '13'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                 = fig_params['methods']\n\tworkload, workload_name = fig_params['workload_names']\n\ttarget_epoch            = fig_params['target_epoch']\n\tclient_nums             = fig_params['client_num']\n\tMN_num                  = fig_params['MN_num']\n\tkey_type                = fig_params['key_size']\n", "value_size              = fig_params['value_size']\n\tcache_size              = fig_params['cache_size']\n\tspan_size               = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    plot_data = {\n\t        'methods': methods,\n\t        'X_data': [0] + [t[0] * t[1] for t in client_nums],\n\t        'Y_data': {method: [0] for method in methods}\n\t    }\n", "    for method in methods:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        # change config\n\t        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_options[method]} .. && make clean && make -j\"\n\t        cmd.all_execute(BUILD_PROJECT)\n\t        for CN_num, client_num_per_CN in client_nums:\n\t            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n", "            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n", "                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt}\")\n\t            plot_data['Y_data'][method].append(tpt)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n", "    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_4b.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '4b'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethod                    = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    legends = ['Throughput', 'Invalid Ratio']\n\t    udpate_schemes = ['out-of-place', 'in-place']\n\t    plot_data = {\n\t        'methods': legends,\n\t        'bar_groups': udpate_schemes,\n\t        'Y_data': {\n", "            legend: {}  # store out-of-place, in-place, respectively\n\t            for legend in legends\n\t        }\n\t    }\n\t    project_dir = f\"{home_dir}/SMART\"\n\t    work_dir = f\"{project_dir}/build\"\n\t    env_cmd = f\"cd {work_dir}\"\n\t    for udpate_scheme in udpate_schemes:\n\t        # change config\n\t        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n", "        cmake_option = cmake_options[method]\n\t        if udpate_scheme == 'in-place':\n\t            cmake_option = cmake_option.replace('-DUPDATE_IN_PLACE_LEAF_NODE=off', '-DUPDATE_IN_PLACE_LEAF_NODE=on')\n\t        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name} 1\"  # 1 --> rm_write_conflict\n\t        KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t        cmd.all_execute(BUILD_PROJECT, CN_num)\n\t        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n", "        while True:\n\t            try:\n\t                cmd.one_execute(CLEAR_MEMC)\n\t                cmd.all_execute(KILL_PROCESS, CN_num)\n\t                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                tpt, _, _, leaf_invalid_rate = tp.get_statistics(logs, target_epoch)\n\t                break\n\t            except (FunctionTimedOut, Exception) as e:\n\t                print_WARNING(f\"Error! Retry... {e}\")\n\t        print_GOOD(f\"[FINISHED POINT] method={method} udpate_scheme={udpate_scheme} tpt={tpt} cache_invalid_rate={leaf_invalid_rate}\")\n", "        plot_data['Y_data'][legends[0]][udpate_scheme] = tpt\n\t        plot_data['Y_data'][legends[1]][udpate_scheme] = leaf_invalid_rate\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n", "    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_3d.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '3d'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                 = fig_params['methods']\n\tworkload, workload_name = fig_params['workload_names']\n\ttarget_epoch            = fig_params['target_epoch']\n\tCN_and_client_nums      = fig_params['client_num']\n\tMN_num                  = fig_params['MN_num']\n\tkey_type                = fig_params['key_size']\n", "value_size              = fig_params['value_size']\n\tcache_size              = fig_params['cache_size']\n\tspan_size               = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    plot_data = {\n\t        'methods': methods,\n\t        'X_data': {method: [] for method in methods},\n\t        'Y_data': {method: [] for method in methods}\n\t    }\n", "    for method in methods:\n\t        project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        # change config\n\t        sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t        cmake_option = cmake_options[method].replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n\t        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t        cmd.all_execute(BUILD_PROJECT)\n\t        for CN_num, client_num_per_CN in CN_and_client_nums[method]:\n", "            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n", "                    _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch)\n\t                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n\t            plot_data['X_data'][method].append(tpt)\n\t            plot_data['Y_data'][method].append(p99_lat)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n", "    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_4d.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import sed_MN_num\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '4d'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n\t# fig params\n", "with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tzipfian, read_ratio       = fig_params['zipfian'], fig_params['read_ratio']\n\tclient_num_per_CNs        = fig_params['client_num_per_CN']\n\tMN_num                    = fig_params['MN_num']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    CN_num = 1\n\t    plot_data = {\n\t        'methods': ['RDMA_WRITE', 'RDMA_CAS'],\n", "        'X_data': [1] + client_num_per_CNs,\n\t        'Y_data': {'RDMA_WRITE': [0], 'RDMA_CAS': [0]}\n\t    }\n\t    project_dir = f\"{home_dir}/SMART\"\n\t    work_dir = f\"{project_dir}/build\"\n\t    env_cmd = f\"cd {work_dir}\"\n\t    # change config\n\t    sed_cmd = sed_MN_num('./include/Common.h', MN_num)\n\t    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake .. && make clean && make -j\"\n\t    cmd.all_execute(BUILD_PROJECT, CN_num)\n", "    for client_num_per_CN in client_num_per_CNs:\n\t        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t        REDUNDANT_TEST = f\"{env_cmd} && ./redundant_test {read_ratio} {client_num_per_CN} {zipfian}\"\n\t        KILL_PROCESS = f\"{env_cmd} && killall -9 redundant_test\"\n\t        while True:\n\t            try:\n\t                cmd.one_execute(CLEAR_MEMC)\n\t                cmd.all_execute(KILL_PROCESS, CN_num)\n\t                logs = cmd.all_long_execute(REDUNDANT_TEST, CN_num)\n\t                _, redundant_write, redundant_cas = tp.get_redundant_statistics(list(logs.values())[0])  # CN_num = 1\n", "                break\n\t            except (FunctionTimedOut, Exception) as e:\n\t                print_WARNING(f\"Error! Retry... {e}\")\n\t        print_GOOD(f\"[FINISHED POINT] RDMA_READ zipfian={zipfian} avg.redundant_write={redundant_write} avg.redundant_cas={redundant_cas}\")\n\t        plot_data['Y_data']['RDMA_WRITE'].append(redundant_write)\n\t        plot_data['Y_data']['RDMA_CAS'].append(redundant_cas)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n", "if __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_15.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '15'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload_names            = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    metrics = ['Throughput', 'P50 Latency', 'P99 Latency']\n\t    plot_data = {\n\t        'methods': methods,\n\t        'bar_groups': list(workload_names.keys()),\n\t        'metrics': metrics,\n\t        'Y_data': {\n", "            method: {\n\t                workload: {}  # store tpt, p50, p99, respectively\n\t                for workload in workload_names.keys()\n\t            }\n\t            for method in methods\n\t        }\n\t    }\n\t    for workload, workload_name in workload_names.items():\n\t        project_dir = f\"{home_dir}/SMART\"\n\t        work_dir = f\"{project_dir}/build\"\n", "        env_cmd = f\"cd {work_dir}\"\n\t        # change config\n\t        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n\t        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t        for method in methods:\n\t            cmake_option = cmake_options[method]\n\t            if workload != 'YCSB LOAD' and method in ['+Read Delegation', '+Write Combining']:\n\t                cmake_option = cmake_option.replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n", "            CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t            YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t            KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t            cmd.all_execute(BUILD_PROJECT, CN_num)\n\t            while True:\n\t                try:\n\t                    cmd.one_execute(CLEAR_MEMC)\n\t                    cmd.all_execute(KILL_PROCESS, CN_num)\n\t                    logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                    p50_lat, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epoch, get_avg=True)\n", "                    tpt, _, _, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n\t                    break\n\t                except (FunctionTimedOut, Exception) as e:\n\t                    print_WARNING(f\"Error! Retry... {e}\")\n\t            print_GOOD(f\"[FINISHED POINT] method={method} workload={workload} tpt={tpt} p50_lat={p50_lat} p99_lat={p99_lat}\")\n\t            plot_data['Y_data'][method][workload] = {metrics[0]: tpt, metrics[1]: p50_lat, metrics[2]: p99_lat}\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n", "if __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_16.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '16'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n", "cmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods                   = fig_params['methods']\n\tworkload, workload_name   = fig_params['workload_names']\n\ttarget_epoch              = fig_params['target_epoch']\n\tCN_num, client_num_per_CN = fig_params['client_num']\n\tMN_num                    = fig_params['MN_num']\n\tkey_type                  = fig_params['key_size']\n", "value_size                = fig_params['value_size']\n\tcache_size                = fig_params['cache_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    legends = ['Throughput', 'Lock-fail']\n\t    plot_data = {\n\t        'methods': legends,\n\t        'bar_groups': methods,\n\t        'Y_data': {\n\t            legend: {}  # store HOCL. E-HOCL, RDWC, respectively\n", "            for legend in legends\n\t        }\n\t    }\n\t    for method in methods:\n\t        project_dir = f\"{home_dir}/SMART\"\n\t        work_dir = f\"{project_dir}/build\"\n\t        env_cmd = f\"cd {work_dir}\"\n\t        # change config\n\t        sed_cmd = generate_sed_cmd('./include/Common.h', False, 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num)\n\t        cmake_option = cmake_options[method].replace('-DMIDDLE_TEST_EPOCH=off', '-DMIDDLE_TEST_EPOCH=on')\n", "        BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t        SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t        YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t        KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t        cmd.all_execute(BUILD_PROJECT, CN_num)\n\t        cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t        while True:\n\t            try:\n\t                cmd.one_execute(CLEAR_MEMC)\n", "                cmd.all_execute(KILL_PROCESS, CN_num)\n\t                logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                tpt, _, avg_lock_fail_cnt, _ = tp.get_statistics(logs, target_epoch, get_avg=True)\n\t                break\n\t            except (FunctionTimedOut, Exception) as e:\n\t                print_WARNING(f\"Error! Retry... {e}\")\n\t        print_GOOD(f\"[FINISHED POINT] method={method} workload={workload} tpt={tpt} avg_lock_fail_cnt={avg_lock_fail_cnt}\")\n\t        plot_data['Y_data'][legends[0]][method] = tpt\n\t        plot_data['Y_data'][legends[1]][method] = avg_lock_fail_cnt\n\t    # save data\n", "    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n", "    pg.generate(fig_num)\n"]}
{"filename": "exp/fig_11.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import generate_sed_cmd\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '11'\n\tsmall_fig_num = {'YCSB LOAD': 'a', 'YCSB A': 'b', 'YCSB B': 'c', 'YCSB C': 'd', 'YCSB D': 'e'}\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tycsb_dir      = f'{home_dir}/SMART/ycsb'\n\tcluster_ips   = params['cluster_ips']\n", "master_ip     = params['master_ip']\n\tcmake_options = params['cmake_options']\n\t# fig params\n\twith (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tmethods            = fig_params['methods']\n\tworkload_names     = fig_params['workload_names']\n\ttarget_epochs      = fig_params['target_epoch']\n\tCN_and_client_nums = fig_params['client_num']  # as Sherman/ART saturates the network more easily than SMART, we test them with fewer clients\n\tMN_num             = fig_params['MN_num']\n", "key_type           = fig_params['key_size']\n\tvalue_size         = fig_params['value_size']\n\tcache_size         = fig_params['cache_size']\n\tspan_size          = fig_params['span_size']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    for workload, workload_name in workload_names.items():\n\t        plot_data = {\n\t            'methods': methods,\n\t            'X_data': {method: [] for method in methods},\n", "            'Y_data': {method: [] for method in methods}\n\t        }\n\t        for method in methods:\n\t            project_dir = f\"{home_dir}/{method if method == 'Sherman' else 'SMART'}\"\n\t            work_dir = f\"{project_dir}/build\"\n\t            env_cmd = f\"cd {work_dir}\"\n\t            # change config\n\t            sed_cmd = generate_sed_cmd('./include/Common.h', method == 'Sherman', 8 if key_type == 'randint' else 32, value_size, cache_size, MN_num, span_size)\n\t            cmake_option = cmake_options[method]\n\t            if workload != 'YCSB LOAD':\n", "                cmake_option = cmake_option.replace('-DLONG_TEST_EPOCH=off', '-DLONG_TEST_EPOCH=on')\n\t            BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake {cmake_option} .. && make clean && make -j\"\n\t            cmd.all_execute(BUILD_PROJECT)\n\t            for CN_num, client_num_per_CN in CN_and_client_nums[method][workload]:\n\t                CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t                SPLIT_WORKLOADS = f\"{env_cmd} && python3 {ycsb_dir}/split_workload.py {workload_name} {key_type} {CN_num} {client_num_per_CN}\"\n\t                YCSB_TEST = f\"{env_cmd} && ./ycsb_test {CN_num} {client_num_per_CN} 2 {key_type} {workload_name}\"\n\t                KILL_PROCESS = f\"{env_cmd} && killall -9 ycsb_test\"\n\t                cmd.all_execute(SPLIT_WORKLOADS, CN_num)\n\t                while True:\n", "                    try:\n\t                        cmd.one_execute(CLEAR_MEMC)\n\t                        cmd.all_execute(KILL_PROCESS, CN_num)\n\t                        logs = cmd.all_long_execute(YCSB_TEST, CN_num)\n\t                        _, p99_lat = cmd.get_cluster_lats(str(Path(project_dir) / 'us_lat'), CN_num, target_epochs[workload])\n\t                        tpt, _, _, _ = tp.get_statistics(logs, target_epochs[workload])\n\t                        break\n\t                    except (FunctionTimedOut, Exception) as e:\n\t                        print_WARNING(f\"Error! Retry... {e}\")\n\t                print_GOOD(f\"[FINISHED POINT] workload={workload} method={method} client_num={CN_num*client_num_per_CN} tpt={tpt} p99_lat={p99_lat}\")\n", "                plot_data['X_data'][method].append(tpt)\n\t                plot_data['Y_data'][method].append(p99_lat)\n\t        # save data\n\t        Path(output_path).mkdir(exist_ok=True)\n\t        with (Path(output_path) / f'fig_{fig_num}{small_fig_num[workload]}.json').open(mode='w') as f:\n\t            json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n\t    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n", "    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    for small_num in small_fig_num.values():\n\t        pg.generate(fig_num + small_num)\n"]}
{"filename": "exp/fig_4c.py", "chunked_list": ["from func_timeout import FunctionTimedOut\n\tfrom pathlib import Path\n\timport json\n\tfrom utils.cmd_manager import CMDManager\n\tfrom utils.log_parser import LogParser\n\tfrom utils.sed_generator import sed_MN_num\n\tfrom utils.color_printer import print_GOOD, print_WARNING\n\tfrom utils.func_timer import print_func_time\n\tfrom utils.pic_generator import PicGenerator\n\tinput_path = './params'\n", "style_path = \"./styles\"\n\toutput_path = './results'\n\tfig_num = '4c'\n\t# common params\n\twith (Path(input_path) / f'common.json').open(mode='r') as f:\n\t    params = json.load(f)\n\thome_dir      = params['home_dir']\n\tcluster_ips   = params['cluster_ips']\n\tmaster_ip     = params['master_ip']\n\t# fig params\n", "with (Path(input_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t    fig_params = json.load(f)\n\tzipfian, read_ratio       = fig_params['zipfian'], fig_params['read_ratio']\n\tclient_num_per_CNs        = fig_params['client_num_per_CN']\n\tMN_num                    = fig_params['MN_num']\n\t@print_func_time\n\tdef main(cmd: CMDManager, tp: LogParser):\n\t    CN_num = 1\n\t    plot_data = {\n\t        'methods': ['RDMA_READ'],\n", "        'X_data': [1] + client_num_per_CNs,\n\t        'Y_data': {'RDMA_READ': [0]}  # avg.redundant READ\n\t    }\n\t    project_dir = f\"{home_dir}/SMART\"\n\t    work_dir = f\"{project_dir}/build\"\n\t    env_cmd = f\"cd {work_dir}\"\n\t    # change config\n\t    sed_cmd = sed_MN_num('./include/Common.h', MN_num)\n\t    BUILD_PROJECT = f\"cd {project_dir} && {sed_cmd} && mkdir -p build && cd build && cmake .. && make clean && make -j\"\n\t    cmd.all_execute(BUILD_PROJECT, CN_num)\n", "    for client_num_per_CN in client_num_per_CNs:\n\t        CLEAR_MEMC = f\"{env_cmd} && /bin/bash ../script/restartMemc.sh\"\n\t        REDUNDANT_TEST = f\"{env_cmd} && ./redundant_test {read_ratio} {client_num_per_CN} {zipfian}\"\n\t        KILL_PROCESS = f\"{env_cmd} && killall -9 redundant_test\"\n\t        while True:\n\t            try:\n\t                cmd.one_execute(CLEAR_MEMC)\n\t                cmd.all_execute(KILL_PROCESS, CN_num)\n\t                logs = cmd.all_long_execute(REDUNDANT_TEST, CN_num)\n\t                redundant_read, _, _ = tp.get_redundant_statistics(list(logs.values())[0])  # CN_num = 1\n", "                break\n\t            except (FunctionTimedOut, Exception) as e:\n\t                print_WARNING(f\"Error! Retry... {e}\")\n\t        print_GOOD(f\"[FINISHED POINT] RDMA_READ zipfian={zipfian} avg.redundant_read={redundant_read}\")\n\t        plot_data['Y_data']['RDMA_READ'].append(redundant_read)\n\t    # save data\n\t    Path(output_path).mkdir(exist_ok=True)\n\t    with (Path(output_path) / f'fig_{fig_num}.json').open(mode='w') as f:\n\t        json.dump(plot_data, f, indent=2)\n\tif __name__ == '__main__':\n", "    cmd = CMDManager(cluster_ips, master_ip)\n\t    tp = LogParser()\n\t    t = main(cmd, tp)\n\t    with (Path(output_path) / 'time.log').open(mode=\"a+\") as f:\n\t        f.write(f\"fig_{fig_num}.py execution time: {int(t//60)} min {int(t%60)} s\\n\")\n\t    pg = PicGenerator(output_path, style_path)\n\t    pg.generate(fig_num)\n"]}
{"filename": "exp/utils/color_printer.py", "chunked_list": ["class bcolors:\n\t    HEADER = '\\033[95m'\n\t    OKBLUE = '\\033[94m'\n\t    OKGREEN = '\\033[92m'\n\t    WARNING = '\\033[93m'\n\t    FAIL = '\\033[91m'\n\t    ENDC = '\\033[0m'\n\t    BOLD = '\\033[1m'\n\t    UNDERLINE = '\\033[4m'\n\tdef print_GOOD(msg):\n", "    print(bcolors.OKGREEN + msg + bcolors.ENDC)\n\tdef print_OK(msg):\n\t    print(bcolors.OKBLUE + msg + bcolors.ENDC)\n\tdef print_WARNING(msg):\n\t    print(bcolors.WARNING + msg + bcolors.ENDC)\n\tdef print_FAIL(msg):\n\t    print(bcolors.FAIL + msg + bcolors.ENDC)\n"]}
{"filename": "exp/utils/log_parser.py", "chunked_list": ["from typing import Optional\n\tfrom utils.color_printer import print_FAIL\n\tclass LogParser(object):\n\t    def __init__(self):\n\t        pass\n\t    def get_statistics(self, logs: dict, target_epoch: int, get_avg: bool=False):\n\t        for log in logs.values():\n\t            if get_avg:\n\t                tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = self.__parse_log_avg(log, target_epoch)\n\t            else:\n", "                tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = self.__parse_log(log, target_epoch)\n\t            if tpt is not None:\n\t                break\n\t        assert(tpt is not None)\n\t        return tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate\n\t    def __parse_log(self, log, target_epoch):\n\t        tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = None, 0, 0, 0\n\t        flag = False\n\t        for line in log:\n\t            if f\"epoch {target_epoch} passed!\" in line:\n", "                flag = True\n\t            elif flag and \"cluster throughput\" in line:\n\t                tpt = float(line.strip().split(' ')[2])\n\t            elif flag and \"cache hit rate\" in line:\n\t                data = line.strip().split(' ')[3]\n\t                if data.replace('.', '').isdigit():\n\t                    cache_hit_rate = float(data)\n\t            elif flag and \"avg. lock/cas fail cnt\" in line:\n\t                data = line.strip().split(' ')[4]\n\t                if data.replace('.', '').isdigit():\n", "                    lock_fail_cnt = float(data)\n\t            elif flag and \"read invalid leaf rate\" in line:\n\t                data = line.strip().split(' ')[4]\n\t                if data.replace('.', '').isdigit():\n\t                    leaf_invalid_rate = float(data) * 100\n\t                break\n\t        return tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate\n\t    def __parse_log_avg(self, log, target_epoch):\n\t        tpt, cache_hit_rate, lock_fail_cnt, leaf_invalid_rate = [], [], [], []\n\t        flag = False\n", "        start_epoch = max(target_epoch // 2, target_epoch - 4)\n\t        cnt = start_epoch\n\t        for line in log:\n\t            if f\"epoch {start_epoch} passed!\" in line:\n\t                flag = True\n\t            elif flag and \"cluster throughput\" in line:\n\t                tpt.append(float(line.strip().split(' ')[2]))\n\t            elif flag and \"cache hit rate\" in line:\n\t                data = line.strip().split(' ')[3]\n\t                if data.replace('.', '').isdigit():\n", "                    cache_hit_rate.append(float(data))\n\t            elif flag and \"avg. lock/cas fail cnt\" in line:\n\t                data = line.strip().split(' ')[4]\n\t                if data.replace('.', '').isdigit():\n\t                    lock_fail_cnt.append(float(data))\n\t            elif flag and \"read invalid leaf rate\" in line:\n\t                data = line.strip().split(' ')[4]\n\t                if data.replace('.', '').isdigit():\n\t                    leaf_invalid_rate.append(float(data) * 100)\n\t                cnt += 1\n", "                if cnt == target_epoch:\n\t                    break\n\t        def get_avg(l):\n\t            return sum(l) / len(l) if l else 0\n\t        return get_avg(tpt) if tpt else None, get_avg(cache_hit_rate), get_avg(lock_fail_cnt), get_avg(leaf_invalid_rate)\n\t    def get_redundant_statistics(self, log):\n\t        redundant_read, redundant_write, redundant_cas = None, None, None\n\t        flag = False\n\t        for line in log:\n\t            if \"Calculation done!\" in line:\n", "                flag = True\n\t            elif flag and \"Avg. redundant rdma_read\" in line:\n\t                data = line.strip().split(' ')[3]\n\t                if data.replace('.', '').isdigit():\n\t                    redundant_read = float(data)\n\t            elif flag and \"Avg. redundant rdma_write\" in line:\n\t                data = line.strip().split(' ')[3]\n\t                if data.replace('.', '').isdigit():\n\t                    redundant_write = float(data)\n\t            elif flag and \"Avg. redundant rdma_cas\" in line:\n", "                data = line.strip().split(' ')[3]\n\t                if data.replace('.', '').isdigit():\n\t                    redundant_cas = float(data)\n\t                break\n\t        return redundant_read, redundant_write, redundant_cas\n"]}
{"filename": "exp/utils/sed_generator.py", "chunked_list": ["from typing import Optional\n\tdef sed_key_len(config_path: str, key_size: int):\n\t    old_key_code   = \"^constexpr uint32_t keyLen = .*\"\n\t    new_key_code   = f\"constexpr uint32_t keyLen = {key_size};\"\n\t    return f\"sed -i 's/{old_key_code}/{new_key_code}/g' {config_path}\"\n\tdef sed_val_len(config_path: str, value_size: int):\n\t    old_val_code   = \"^constexpr uint32_t simulatedValLen =.*\"\n\t    new_val_code   = f\"constexpr uint32_t simulatedValLen = {value_size};\"\n\t    return f\"sed -i 's/{old_val_code}/{new_val_code}/g' {config_path}\"\n\tdef sed_cache_size(config_path: str, cache_size: int):\n", "    old_cache_code = \"^constexpr int kIndexCacheSize = .*\"\n\t    new_cache_node = f\"constexpr int kIndexCacheSize = {cache_size};\"\n\t    return f\"sed -i 's/{old_cache_code}/{new_cache_node}/g' {config_path}\"\n\tdef sed_MN_num(config_path: str, MN_num: int):\n\t    old_MN_code = \"^#define MEMORY_NODE_NUM .*\"\n\t    new_MN_node = f\"#define MEMORY_NODE_NUM {MN_num}\"\n\t    return f\"sed -i 's/{old_MN_code}/{new_MN_node}/g' {config_path}\"\n\tdef sed_span_size(config_path: str, span_size: int):  # only for Sherman\n\t    old_span_code = \"^constexpr int spanSize = .*\"\n\t    new_span_node = f\"constexpr int spanSize = {span_size};\"\n", "    return f\"sed -i 's/{old_span_code}/{new_span_node}/g' {config_path}\"\n\tdef generate_sed_cmd(config_path: str, is_Btree: bool, key_size: int, value_size: int, cache_size: int, MN_num: int, span_size: Optional[int] = None):\n\t    cmd = f\"{sed_key_len(config_path, key_size)} && {sed_val_len(config_path, value_size)} && {sed_cache_size(config_path, cache_size)} && {sed_MN_num(config_path, MN_num)}\"\n\t    if is_Btree:  # change span size for Sherman\n\t        assert(span_size is not None)\n\t        cmd += f\"&& {sed_span_size(config_path, span_size)}\"\n\t    return cmd\n"]}
{"filename": "exp/utils/func_timer.py", "chunked_list": ["import time\n\tfrom utils.color_printer import print_OK\n\tdef print_func_time(func):\n\t    def fun(*args, **kwargs):\n\t        t = time.perf_counter()\n\t        func(*args, **kwargs)\n\t        execute_time = time.perf_counter() - t\n\t        print_OK(f'Execution Time: {execute_time:.2f} s')\n\t        return execute_time\n\t    return fun\n"]}
{"filename": "exp/utils/pic_line_drawer.py", "chunked_list": ["import matplotlib.pyplot as plt\n\tfrom matplotlib.ticker import FormatStrFormatter\n\tfrom pathlib import Path\n\timport numpy as np\n\tclass LineDrawer(object):\n\t    def __init__(self, pic_dir: str):\n\t        Path(pic_dir).mkdir(exist_ok=True)\n\t        self.pic_dir = pic_dir\n\t    def __load_default_style(self):\n\t        # line\n", "        self.lineStyleDict = {\n\t            'Sherman (2MN)'    : (0, (5, 3)),\n\t            'Sherman (1MN)'    : (0, ()),\n\t            'ART (2MN)'        : (0, (5, 3)),\n\t            'ART (1MN)'        : (0, ()),\n\t            'ART'            : (0, ()),\n\t            'Sherman'        : (0, ()),\n\t            'SMART'          : (0, ()),\n\t            'Throughput': (0, ()),\n\t            'P99 Latency': (0, ()),\n", "            'RDMA_READ' : (0, ()),\n\t            'RDMA_WRITE': (0, ()),\n\t            'RDMA_CAS'  : (0, ()),\n\t        }\n\t        self.lineColorDict = {\n\t            'Sherman (2MN)'    : '#4575B5',\n\t            'Sherman (1MN)'    : '#4575B5',\n\t            'ART (2MN)'        : '#D63026',\n\t            'ART (1MN)'        : '#D63026',\n\t            'ART'            : '#D63026',\n", "            'Sherman'        : '#4575B5',\n\t            'SMART'          : '#82B366',\n\t            'Throughput': '#4575B5',\n\t            'P99 Latency': '#D63026',\n\t            'RDMA_READ' : '#D63026',\n\t            'RDMA_WRITE': '#D63026',\n\t            'RDMA_CAS'  : '#82B366',\n\t        }\n\t        self.lineMarkerDict = {\n\t            'Sherman (2MN)'    : 'x',\n", "            'Sherman (1MN)'    : 'x',\n\t            'ART (2MN)'        : 'o',\n\t            'ART (1MN)'        : 'o',\n\t            'ART'            : 'o',\n\t            'Sherman'        : 'x',\n\t            'SMART'          : 's',\n\t            'Throughput': 'x',\n\t            'P99 Latency': '^',\n\t            'RDMA_READ' : 'x',\n\t            'RDMA_WRITE': 'x',\n", "            'RDMA_CAS'  : '^',\n\t        }\n\t        self.zorderDict = {\n\t            'Sherman (2MN)'    : 1100,\n\t            'Sherman (1MN)'    : 1100,\n\t            'ART (2MN)'        : 1200,\n\t            'ART (1MN)'        : 1200,\n\t            'ART'            : 1200,\n\t            'Sherman'        : 1150,\n\t            'SMART'          : 1250,\n", "            'Throughput': 1000,\n\t            'P99 Latency': 1000,\n\t            'RDMA_READ' : 1000,\n\t            'RDMA_WRITE': 1000,\n\t            'RDMA_CAS'  : 1100,\n\t        }\n\t        # size\n\t        self.figsize=(4, 2.5)\n\t        self.font_size = 15\n\t        self.legend_size = 15\n", "        self.tick_size = 14\n\t        self.linewidth = 0.8\n\t        self.markersize = 6\n\t        # grid\n\t        self.grid_type = {'axis': 'y', 'lw': 0.3}\n\t        self.y_major_num = self.x_major_num = 0\n\t        self.grid_minor = False\n\t        # edge\n\t        self.hide_half_edge = False\n\t        self.hide_ylabel = False\n", "        self.clip_on = True\n\t        # legend\n\t        self.legend_location = ''\n\t        self.legend_anchor = ()\n\t        self.legendL_anchor = self.legendR_anchor = ()\n\t        self.legend_ncol = 1\n\t        # tick\n\t        self.x_ticklabel = False\n\t        self.y_lim = self.x_lim = ()\n\t        self.ylim = self.xlim = ()\n", "        self.yL_lim = self.yR_lim = ()\n\t        self.x_tick = self.y_tick = []\n\t        self.yL_tick = self.yR_tick = []\n\t        self.yscale = ''\n\t        self.yfloat = False\n\t        # label\n\t        self.x_label = ''\n\t        self.y_label = ''\n\t        self.yL_label = ''\n\t        self.yR_label = ''\n", "        # func\n\t        self.aux_plt_func = None\n\t        self.annotation_func = None\n\t    def plot_with_one_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}):\n\t        self.__load_default_style()\n\t        # load custom style\n\t        for k, v in custom_style.items():\n\t            setattr(self, k, v)\n\t        fig, ax = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n\t        if self.hide_half_edge:\n", "            ax.spines['right'].set_visible(False)\n\t            ax.spines['top'].set_visible(False)\n\t        legend_handles = []\n\t        legend_labels  = []\n\t        if not method_legend:\n\t            method_legend = {method: method for method in data['methods']}\n\t        X_data = data['X_data']\n\t        Y_data = data['Y_data']\n\t        for method in data['methods']:\n\t            l, = ax.plot(X_data[method] if isinstance(X_data, dict) else X_data,\n", "                         Y_data[method],\n\t                         linestyle=self.lineStyleDict[method],\n\t                         color=self.lineColorDict[method],\n\t                         marker=self.lineMarkerDict[method],\n\t                         markerfacecolor='none',\n\t                         mew=self.linewidth,\n\t                         clip_on=self.clip_on,\n\t                         linewidth=self.linewidth,\n\t                         markersize=self.markersize + 1.5 if self.lineMarkerDict[method] == '+' else\n\t                                    self.markersize + 0.5 if self.lineMarkerDict[method] == 'x' else self.markersize,\n", "                         zorder=self.zorderDict[method])\n\t            if method in method_legend:\n\t                legend_handles.append(l)\n\t                legend_labels.append(method_legend[method])\n\t        ax.set_xlabel(self.x_label, fontsize=self.font_size)\n\t        if not self.hide_ylabel:\n\t            ax.set_ylabel(self.y_label, fontsize=self.font_size)\n\t        if self.yscale:\n\t            ax.set_yscale(self.yscale)\n\t        if self.yfloat:\n", "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n\t        if self.ylim:\n\t            ytick       = list(np.linspace(self.ylim[0], self.ylim[1], self.y_major_num))\n\t            ytick_minor = list(np.linspace(self.ylim[0], self.ylim[1], 0 if self.grid_minor is False else self.y_major_num * 2 - 1))\n\t            ax.set_yticks(ytick)\n\t            ax.set_yticks(ytick_minor, minor=True)\n\t        if self.xlim:\n\t            xtick       = list(np.linspace(self.xlim[0], self.xlim[1], self.x_major_num))\n\t            xtick_minor = list(np.linspace(self.xlim[0], self.xlim[1], 0 if self.grid_minor is False else self.x_major_num * 2 - 1))\n\t            ax.set_xticks(xtick)\n", "            ax.set_xticks(xtick_minor, minor=True)\n\t        if self.y_tick:\n\t            ax.set_yticks(self.y_tick)\n\t        if self.x_tick:\n\t            ax.set_xticks(self.x_tick)\n\t            if self.x_ticklabel:\n\t                ax.set_xticklabels(self.x_ticklabel, fontsize=self.tick_size)\n\t        if self.y_lim:  # x, y limitation, use when xlim/ylim is not enough\n\t            ax.set_ylim(*self.y_lim)\n\t        if self.x_lim:\n", "            ax.set_xlim(*self.x_lim)\n\t        ax.tick_params(labelsize=self.tick_size)\n\t        # ax.set_xscale('log')\n\t        if self.annotation_func:\n\t            self.annotation_func(ax)\n\t        ax.grid(color='#dbdbdb', **self.grid_type, which='both' if self.grid_minor else 'major', zorder=0)\n\t        if self.legend_location or self.legend_anchor:\n\t            if self.legend_anchor:\n\t                ax.legend(legend_handles, legend_labels, fontsize=self.legend_size, bbox_to_anchor=self.legend_anchor, frameon=False, ncol=self.legend_ncol)\n\t            else:\n", "                ax.legend(legend_handles, legend_labels, fontsize=self.legend_size, loc=self.legend_location, frameon=False, ncol=self.legend_ncol) # labelspacing=0.1\n\t        if self.aux_plt_func:\n\t            self.aux_plt_func(ax)\n\t        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n\t        plt.close()\n\t    def plot_with_two_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}, method_ax: dict = {}):\n\t        self.__load_default_style()\n\t        # load custom style\n\t        for k, v in custom_style.items():\n\t            setattr(self, k, v)\n", "        fig, ax_L = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n\t        ax_R = ax_L.twinx()\n\t        # legend_list = []\n\t        if not method_legend:\n\t            method_legend = {method: method for method in data['methods']}\n\t        if not method_ax:\n\t            method_ax = dict(zip(data['methods'], ['left', 'right']))\n\t        X_data = data['X_data']\n\t        Y_data = data['Y_data']\n\t        for method in data['methods']:\n", "            ax = ax_L if method_ax[method] == 'left' else ax_R\n\t            ax.plot(X_data[method] if isinstance(X_data, dict) else X_data,\n\t                    Y_data[method],\n\t                    label=method_legend[method],\n\t                    linestyle=self.lineStyleDict[method],\n\t                    color=self.lineColorDict[method],\n\t                    marker=self.lineMarkerDict[method],\n\t                    markerfacecolor='none',\n\t                    clip_on=False,\n\t                    linewidth=self.linewidth,\n", "                    markersize=self.markersize + 1.5 if self.lineMarkerDict[method] == '+' else\n\t                               self.markersize + 0.5 if self.lineMarkerDict[method] == 'x' else self.markersize)\n\t            # if method in method_legend:\n\t            #     legend_list.append(method_legend[method])\n\t        ax_L.set_xlabel(self.x_label, fontsize=self.font_size)\n\t        ax_L.set_ylabel(self.yL_label, fontsize=self.font_size)\n\t        ax_R.set_ylabel(self.yR_label, fontsize=self.font_size)\n\t        if self.yL_tick:\n\t            ax_L.set_yticks(self.yL_tick)\n\t            ax_L.set_yticklabels(self.yL_tick, fontsize=self.tick_size)\n", "        if self.yR_tick:\n\t            ax_R.set_yticks(self.yR_tick)\n\t            ax_R.set_yticklabels(self.yR_tick, fontsize=self.tick_size)\n\t        if self.yfloat:\n\t            ax_L.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n\t        if self.x_tick:\n\t            ax_L.set_xticks(self.x_tick)\n\t            ax_L.set_xticklabels(self.x_tick, fontsize=self.tick_size)\n\t        if self.yL_lim:\n\t            ax_L.set_ylim(*self.yL_lim)\n", "        if self.yR_lim:\n\t            ax_R.set_ylim(*self.yR_lim)\n\t        if self.x_lim:\n\t            ax.set_xlim(*self.x_lim)\n\t        ax_L.grid(color='#dbdbdb', **self.grid_type, which='both', zorder=0)\n\t        ax_L.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendL_anchor, frameon=False, ncol=self.legend_ncol)\n\t        ax_R.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendR_anchor, frameon=False, ncol=self.legend_ncol)\n\t        if self.aux_plt_func:\n\t            self.aux_plt_func(ax)\n\t        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n", "        plt.close()"]}
{"filename": "exp/utils/lat_parser.py", "chunked_list": ["from typing import List\n\tfrom pathlib import Path\n\timport paramiko\n\tclass LatParser(object):\n\t    def __init__(self, clients: List[paramiko.SSHClient]):\n\t        self.__sftps = [cli.open_sftp() for cli in clients]\n\t        self.__lat_cnt = dict()\n\t    def load_remote_lats(self, lat_dir_path: str, CN_num: int, epoch_start: int = 1, epoch_num: int = 10):\n\t        p50_p99_lats = {}\n\t        for e_id in range(epoch_start, epoch_start + epoch_num):\n", "            self.__lat_cnt.clear()\n\t            for sftp in self.__sftps[:CN_num]:\n\t                remote_file = sftp.open(str(Path(lat_dir_path) / f'epoch_{e_id}.lat'))\n\t                try:\n\t                    for line in remote_file:\n\t                        lat, cnt = line.strip().split('\\t', 1)\n\t                        if int(cnt):\n\t                            if lat not in self.__lat_cnt:\n\t                                self.__lat_cnt[lat] = 0\n\t                            self.__lat_cnt[lat] += int(cnt)\n", "                finally:\n\t                    remote_file.close()\n\t            if self.__lat_cnt:\n\t                p50_p99_lats[e_id] = self.__cal_lat()\n\t                print(f'epoch_id={e_id} p50_lat={p50_p99_lats[e_id][0]} p99_lat={p50_p99_lats[e_id][1]}')\n\t        return p50_p99_lats\n\t    def __cal_lat(self):\n\t        all_lat = sum(self.__lat_cnt.values())\n\t        th50 = all_lat / 2\n\t        th99 = all_lat * 99 / 100\n", "        cum = 0\n\t        p50, p99 = None, None\n\t        for lat, cnt in sorted(self.__lat_cnt.items(), key=lambda s:float(s[0])):\n\t            cum += cnt\n\t            if cum >= th50:\n\t                p50 = float(lat)\n\t                th50 = all_lat + 1\n\t            if cum >= th99:\n\t                p99 = float(lat)\n\t                break\n", "        assert(p50 is not None and p99 is not None)\n\t        return p50, p99\n"]}
{"filename": "exp/utils/cmd_manager.py", "chunked_list": ["import paramiko\n\timport time\n\timport socket\n\tfrom func_timeout import func_set_timeout\n\tfrom utils.lat_parser import LatParser\n\tfrom utils.color_printer import print_OK, print_FAIL\n\tBUFFER_SIZE = 16 * 1024 * 1024\n\tEND_PROMPT = '[END]'\n\tOOM_PROMPT = 'shared memory space run out'\n\tDEADLOCK_PROMPT = 'Deadlock'\n", "class CMDManager(object):\n\t    def __init__(self, cluster_ips: list, master_ip: str):\n\t        super().__init__()\n\t        self.__cluster_ips = cluster_ips\n\t        self.__master_idx = cluster_ips.index(master_ip)\n\t        self.__CNs = [self.__get_ssh_CNs(hostname) for hostname in cluster_ips]\n\t        self.__shells = [cli.invoke_shell() for cli in self.__CNs]\n\t        for shell in self.__shells:\n\t            shell.setblocking(False)\n\t            self.__clear_shell(shell)\n", "        self.__lat_parser = LatParser(self.__CNs)\n\t    def __del__(self):\n\t        for cli in self.__CNs:\n\t            cli.close()\n\t    def __clear_shell(self, shell):\n\t        shell.send('\\n')\n\t        while True:\n\t            try:\n\t                shell.recv(BUFFER_SIZE)\n\t                break\n", "            except socket.timeout:\n\t                continue\n\t    def __match_prompt(self, content: str, end: str):\n\t        if end in content:\n\t            return True\n\t        return False\n\t    def __get_ssh_CNs(self, hostname: str):\n\t        port = 22\n\t        cli = paramiko.SSHClient()\n\t        cli.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n", "        cli.connect(hostname, port, compress=True)\n\t        return cli\n\t    @func_set_timeout(60)\n\t    def all_execute(self, command: str, CN_num: int = -1):\n\t        if CN_num < 0:  # -1 means use all CNs\n\t            CN_num = len(self.__CNs)\n\t        outs = {}\n\t        errs = {}\n\t        stdouts = {}\n\t        stderrs = {}\n", "        print_OK(f'COMMAND=\"{command}\"')\n\t        print_OK(f'EXECUTE_IPs={self.__cluster_ips[:CN_num]}')\n\t        for i in range(CN_num):\n\t            cli_ip = self.__cluster_ips[i]\n\t            _, stdouts[cli_ip], stderrs[cli_ip] = self.__CNs[i].exec_command(command, get_pty=True)\n\t        for i in range(CN_num):\n\t            cli_ip = self.__cluster_ips[i]\n\t            outs[cli_ip] = stdouts[cli_ip].readlines()  # block here\n\t            errs[cli_ip] = stderrs[cli_ip].readlines()  # TODO: Retry\n\t            for line in outs[cli_ip]:\n", "                print(f'[CN {cli_ip} OUTPUT] {line.strip()}')\n\t            for line in errs[cli_ip]:\n\t                print_FAIL(f'[CN {cli_ip} ERROR] {line.strip()}')\n\t        return outs\n\t    def one_execute(self, command: str):\n\t        # one of the nodes (i.e., master node) will do some special task\n\t        cli = self.__CNs[self.__master_idx]\n\t        cli_ip = self.__cluster_ips[self.__master_idx]\n\t        print_OK(f'COMMAND=\"{command}\"')\n\t        print_OK(f'EXECUTE_IP={cli_ip}')\n", "        try:\n\t            _, stdout, stderr = cli.exec_command(command, get_pty=True)\n\t            out = stdout.readlines()  # block here\n\t            err = stderr.readlines()\n\t            for line in out:\n\t                print(f'[CN {cli_ip} OUTPUT] {line.strip()}')\n\t            for line in err:\n\t                print_FAIL(f'[CN {cli_ip} OUTPUT] {line.strip()}')\n\t        except:\n\t            print_FAIL(f'[CN {cli_ip}] FAILURE: {command}')\n", "        return out\n\t    @func_set_timeout(600)\n\t    def all_long_execute(self, command: str, CN_num: int = -1):\n\t        if CN_num < 0:  # -1 means use all CNs\n\t            CN_num = len(self.__CNs)\n\t        print_OK(f'COMMAND=\"{command}\"')\n\t        print_OK(f'EXECUTE_IPs={self.__cluster_ips[:CN_num]}')\n\t        if not command.endswith('\\n'):\n\t            command += '\\n'\n\t        for i in range(CN_num):\n", "            self.__shells[i].send(command)\n\t        for i in range(CN_num):\n\t            while not self.__shells[i].recv_ready():\n\t                time.sleep(0.2)\n\t        outs = {self.__cluster_ips[i]: '' for i in range(CN_num)}\n\t        for i in range(CN_num):\n\t            cli_ip = self.__cluster_ips[i]\n\t            while not self.__match_prompt(outs[cli_ip], END_PROMPT):\n\t                try:\n\t                    msg = self.__shells[i].recv(BUFFER_SIZE).decode()\n", "                    if msg:\n\t                        print(f'[CN {cli_ip} OUTPUT] {msg.strip()}')\n\t                        outs[cli_ip] += msg\n\t                    if self.__match_prompt(outs[cli_ip], OOM_PROMPT):\n\t                        raise Exception(OOM_PROMPT)\n\t                    if self.__match_prompt(outs[cli_ip], DEADLOCK_PROMPT):\n\t                        raise Exception(DEADLOCK_PROMPT)\n\t                except socket.timeout:\n\t                    continue\n\t        for ip in outs.keys():\n", "            outs[ip] = outs[ip].strip().split('\\n')\n\t        return outs\n\t    def get_cluster_lats(self, lat_dir_path: str, CN_num: int, target_epoch: int, get_avg: bool=False):\n\t        if get_avg:\n\t            start_epoch = max(target_epoch // 2, target_epoch - 4)\n\t            p50_p99_lats = self.__lat_parser.load_remote_lats(lat_dir_path, CN_num, start_epoch, target_epoch - start_epoch + 1)\n\t            assert(p50_p99_lats)\n\t            p50s, p99s = zip(*list(p50_p99_lats.values()))\n\t            p50 = sum(p50s) / len(p50s)\n\t            p99 = sum(p99s) / len(p99s)\n", "        else:\n\t            p50, p99 = self.__lat_parser.load_remote_lats(lat_dir_path, CN_num, target_epoch, 1)[target_epoch]  # to save time, we simply use the latency result in one epoch\n\t        assert(p50 is not None and p99 is not None)\n\t        return p50, p99\n"]}
{"filename": "exp/utils/pic_bar_drawer.py", "chunked_list": ["import matplotlib.pyplot as plt\n\tfrom matplotlib.ticker import FormatStrFormatter\n\tfrom pathlib import Path\n\timport numpy as np\n\tclass BarDrawer(object):\n\t    def __init__(self, pic_dir: str):\n\t        Path(pic_dir).mkdir(exist_ok=True)\n\t        self.pic_dir = pic_dir\n\t    def __load_default_style(self):\n\t        # bar\n", "        self.barHatchDict = {\n\t            'Throughput'        : '/',\n\t            'Invalid Ratio'     : '\\\\',\n\t            'Delegated Ratio'   : '\\\\',\n\t            'Combined Ratio'    : '\\\\',\n\t            'P99 Latency'       : '\\\\',\n\t            'Lock-fail'         : 'x',\n\t            'SMART'            : '',\n\t            'ART'              : '//',\n\t            'Sherman'          : '\\\\\\\\',\n", "            'Sherman (8-span)' : 'x',\n\t            'Sherman (16-span)': '+',\n\t            'Sherman (32-span)': '\\\\\\\\',\n\t            'Sherman (64-span)': '',\n\t            \"+Lock-free Internal Node\"  : \"\\\\\\\\\",\n\t            '+Update-in-place Leaf Node': '||',\n\t            '+Rear Embedded Lock'       : '-',\n\t            '+Read Delegation'          : '++',\n\t            '+Write Combining'          : 'xx',\n\t            \"Baseline\"                           : \"//\",\n", "            \"+Homogeneous Adaptive Internal Node\": \"\\\\\\\\\",\n\t            '+ART-indexed Cache'                 : 'xx',\n\t        }\n\t        self.barColorDict = {\n\t            'Throughput'        : '#F8CECC',\n\t            'Invalid Ratio'     : '#DAE8FC',\n\t            'Delegated Ratio'   : '#DAE8FC',\n\t            'Combined Ratio'    : '#DAE8FC',\n\t            'P99 Latency'       : '#DAE8FC',\n\t            'Lock-fail'         : '#D5E8D4',\n", "            'SMART'            : '#D5E8D4',\n\t            'ART'              : '#F8CECC',\n\t            'Sherman'          : '#DAE8FC',\n\t            'Sherman (8-span)' : '#F5F5F5',\n\t            'Sherman (16-span)': '#F5F5F5',\n\t            'Sherman (32-span)': '#DAE8FC',\n\t            'Sherman (64-span)': '#F5F5F5',\n\t            \"+Lock-free Internal Node\"  : \"#DAE8FC\",\n\t            '+Update-in-place Leaf Node': '#DAE8FC',\n\t            '+Rear Embedded Lock'       : '#DAE8FC',\n", "            '+Read Delegation'          : '#D5E8D4',\n\t            '+Write Combining'          : '#D5E8D4',\n\t            \"Baseline\"                           : \"#F8CECC\",\n\t            \"+Homogeneous Adaptive Internal Node\": \"#DAE8FC\",\n\t            '+ART-indexed Cache'                 : '#D5E8D4',\n\t        }\n\t        # line\n\t        self.lineStyleDict = {\n\t            'P50 Latency'    : (0, ()),\n\t            'P99 Latency'    : (0, (3, 1)),\n", "            'Cache Hit Ratio': (0, ())\n\t        }\n\t        self.lineColorDict = {\n\t            'P50 Latency'    : '#333333',\n\t            'P99 Latency'    : '#333333',\n\t            'Cache Hit Ratio': '#333333',\n\t        }\n\t        self.lineMarkerDict = {\n\t            'P50 Latency'    : 'o',\n\t            'P99 Latency'    : '^',\n", "            'Cache Hit Ratio': 'o',\n\t        }\n\t        self.zorderDict = {\n\t            'P50 Latency'    : 1200,\n\t            'P99 Latency'    : 1250,\n\t            'Cache Hit Ratio': 1250,\n\t        }\n\t        # size\n\t        self.figsize=(4, 2.5)\n\t        self.font_size = 15\n", "        self.legend_size = 15\n\t        self.tick_size = 14\n\t        self.linewidth = 0.8\n\t        plt.rcParams['hatch.linewidth'] = 0.4\n\t        self.markersize = 6\n\t        # edge\n\t        self.line_clip_on=False\n\t        # tick\n\t        self.yRfloat = False\n\t        # bar size\n", "        self.group_width = 0.8\n\t        self.bar_offset = 0.5\n\t        self.bar_padding = 0\n\t        # legend\n\t        self.legend_location = ''\n\t        self.legend_anchor = ()\n\t        self.legendL_location = self.legendR_location = ''\n\t        self.legendL_anchor = self.legendR_anchor = ()\n\t        self.legend_ncol = 1\n\t        self.legendL_ncol = self.legendR_ncol = 2\n", "        self.legend_param = {}\n\t        self.legendL_param = self.legendR_param = {}\n\t        # tick\n\t        self.x_ticklabel = False\n\t        self.y_lim = self.x_lim = ()\n\t        self.yL_lim = self.yR_lim = ()\n\t        self.x_tick = self.y_tick = []\n\t        self.yL_tick = self.yR_tick = []\n\t        self.yscale = ''\n\t        self.yfloat = False\n", "        self.yR_scale = ''\n\t        # label\n\t        self.x_label = ''\n\t        self.y_label = ''\n\t        self.yL_label = ''\n\t        self.yR_label = ''\n\t        # func\n\t        self.aux_plt_func = None\n\t        self.annotation_func = None\n\t    def plot_with_one_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}):\n", "        self.__load_default_style()\n\t        # load custom style\n\t        for k, v in custom_style.items():\n\t            setattr(self, k, v)\n\t        fig, ax = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n\t        methods = data['methods']\n\t        bar_groups = data['bar_groups']\n\t        if not method_legend:\n\t            method_legend = {method: method for method in data['methods']}\n\t        bar_width = self.group_width / len(methods)\n", "        for i, method in enumerate(methods):\n\t            ax.bar(np.arange(len(bar_groups)) + (i - self.bar_offset) * bar_width,\n\t                   [data['Y_data'][method][g] for g in bar_groups],\n\t                   width=bar_width,\n\t                   label=method_legend[method],\n\t                   color=self.barColorDict[method],\n\t                   edgecolor='black',\n\t                   linewidth=self.linewidth,\n\t                   fill=True,\n\t                   hatch=self.barHatchDict[method],\n", "                   zorder=100)\n\t        if self.x_label:\n\t            ax.set_xlabel(self.x_label, fontsize=self.font_size)\n\t        ax.set_xticks([i for i in range(len(bar_groups))])\n\t        ax.set_xticklabels(bar_groups, fontsize=self.tick_size)\n\t        ax.grid(axis='y', color='#dbdbdb', lw=0.3, zorder=0)\n\t        ax.set_ylabel(self.y_label, fontsize=self.font_size)\n\t        if self.y_tick:\n\t            ax.set_yticks(self.y_tick)\n\t            ax.set_yticklabels(self.y_tick, fontsize=self.tick_size)\n", "        if self.y_lim:\n\t            ax.set_ylim(*self.y_lim)\n\t        if self.legend_anchor:\n\t            ax.legend(fontsize=self.legend_size, bbox_to_anchor=self.legend_anchor, frameon=False)\n\t        else:\n\t            ax.legend(fontsize=self.legend_size, loc=self.legend_location, frameon=False)\n\t        if self.aux_plt_func:\n\t            self.aux_plt_func(ax)\n\t        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n\t        plt.close()\n", "    def plot_with_two_ax(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}, method_ax: dict = {}):\n\t        self.__load_default_style()\n\t        # load custom style\n\t        for k, v in custom_style.items():\n\t            setattr(self, k, v)\n\t        fig, ax_L = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n\t        methods = data['methods']\n\t        bar_groups = data['bar_groups']\n\t        if not method_legend:\n\t            method_legend = {method: method for method in data['methods']}\n", "        if not method_ax:\n\t            method_ax = dict(zip(data['methods'], ['left', 'right']))\n\t        ax_R = ax_L.twinx()\n\t        bar_width = self.group_width / len(methods)\n\t        for i, method in enumerate(methods):\n\t            ax = ax_L if method_ax[method] == 'left' else ax_R\n\t            ax.bar(np.arange(len(bar_groups)) + (i - self.bar_offset) * bar_width,\n\t                   [data['Y_data'][method][g] for g in bar_groups],\n\t                   width=bar_width,\n\t                   label=method_legend[method],\n", "                   color=self.barColorDict[method],\n\t                   edgecolor='black',\n\t                   linewidth=self.linewidth,\n\t                   fill=True,\n\t                   hatch=self.barHatchDict[method],\n\t                   zorder=100)\n\t        if self.x_label:\n\t            ax_L.set_xlabel(self.x_label, fontsize=self.font_size)\n\t        ax_L.set_xticks([i for i in range(len(bar_groups))])\n\t        ax_L.set_xticklabels(bar_groups, fontsize=self.tick_size)\n", "        ax_L.grid(axis='y', color='#dbdbdb', lw=0.3, zorder=0)\n\t        ax_L.set_ylabel(self.yL_label, fontsize=self.font_size)\n\t        ax_L.set_yticks(self.yL_tick)\n\t        ax_L.set_yticklabels(self.yL_tick, fontsize=self.font_size)\n\t        if self.legendL_anchor:\n\t            if self.legendL_param:\n\t                ax_L.legend(bbox_to_anchor=self.legendL_anchor, frameon=False, **self.legendL_param)\n\t            else:\n\t                ax_L.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendL_anchor, frameon=False)\n\t        else:\n", "            ax_L.legend(fontsize=self.legend_size, loc=self.legendL_location, frameon=False)\n\t        ax_R.set_ylabel(self.yR_label, fontsize=self.font_size)\n\t        ax_R.set_yticks(self.yR_tick)\n\t        ax_R.set_yticklabels(self.yR_tick, fontsize=self.tick_size)\n\t        if self.legendR_anchor:\n\t            if self.legendR_param:\n\t                ax_R.legend(bbox_to_anchor=self.legendR_anchor, frameon=False, **self.legendR_param)\n\t            else:\n\t                ax_R.legend(fontsize=self.legend_size, bbox_to_anchor=self.legendR_anchor, frameon=False)\n\t        else:\n", "            ax_R.legend(fontsize=self.legend_size, loc=self.legendR_location, frameon=False)\n\t        if self.yRfloat:\n\t            ax_R.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n\t        if self.aux_plt_func:\n\t            self.aux_plt_func(ax)\n\t        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n\t        plt.close()\n\t    def plot_with_line(self, data: dict, fig_name: str, custom_style: dict = {}, method_legend: dict = {}, method_ax: dict = {}):\n\t        self.__load_default_style()\n\t        # load custom style\n", "        for k, v in custom_style.items():\n\t            setattr(self, k, v)\n\t        fig, ax_L = plt.subplots(1, 1, figsize=self.figsize, dpi=300)\n\t        methods = data['methods']\n\t        bar_groups = data['bar_groups']\n\t        if not method_legend:\n\t            method_legend = {method: method for method in data['methods']}\n\t        if not method_ax:\n\t            method_ax = dict(zip(data['methods'], ['left', 'right']))\n\t        line_x_data = {g : [] for g in bar_groups}\n", "        # plot bar\n\t        bar_metric = data['metrics'][0]\n\t        totalWidth = self.group_width\n\t        barWidth = totalWidth / len(methods)\n\t        for i, method in enumerate(methods):\n\t            bar_x_data = np.arange(len(bar_groups)) + (i - self.bar_offset) * barWidth\n\t            for x, g in zip(bar_x_data, bar_groups):\n\t                line_x_data[g].append(x)\n\t            ax_L.bar(bar_x_data,\n\t                     [data['Y_data'][method][g][bar_metric] for g in bar_groups],\n", "                     width=barWidth*(1-self.bar_padding),\n\t                     label=method_legend[method],\n\t                     color=self.barColorDict[method],\n\t                     edgecolor='black',\n\t                     linewidth=self.linewidth,\n\t                     fill=True,\n\t                     hatch=self.barHatchDict[method],\n\t                     zorder=100)\n\t        if self.x_label:\n\t            ax_L.set_xlabel(self.x_label, fontsize=self.font_size)\n", "        ax_L.set_xticks([i for i in range(len(bar_groups))])\n\t        ax_L.set_xticklabels(bar_groups, fontsize=self.font_size)\n\t        ax_L.grid(axis='y', color='#dbdbdb', lw=0.3, zorder=0)\n\t        ax_L.set_ylabel(self.y_label, fontsize=self.font_size)\n\t        if self.y_tick:\n\t            ax_L.set_yticks(self.y_tick)\n\t        if self.y_lim:\n\t            ax_L.set_ylim(*self.y_lim)\n\t        if self.legend_anchor:\n\t            if self.legend_param:\n", "                ax_L.legend(bbox_to_anchor=self.legend_anchor, frameon=False, **self.legend_param)\n\t            else:\n\t                ax_L.legend(fontsize=self.legend_size, bbox_to_anchor=self.legend_anchor, frameon=False, ncol=self.legend_ncol)\n\t        else:\n\t            ax_L.legend(fontsize=self.legend_size, loc=self.legend_location, frameon=False, ncol=self.legend_ncol, columnspacing=0.8)\n\t        ax_L.tick_params(labelsize=self.tick_size)\n\t        # plot line\n\t        line_metrics = data['metrics'][1:]\n\t        lines_data = []\n\t        for g in bar_groups:\n", "            for m in line_metrics:\n\t                lines_data.append((g, m, [data['Y_data'][method][g][m] for method in methods]))\n\t        ax_R = ax_L.twinx()\n\t        legend_handles = {}\n\t        if len(methods) > 1:\n\t            for g, metric, line_data in lines_data:\n\t                l, = ax_R.plot(line_x_data[g],\n\t                               line_data,\n\t                               linestyle=self.lineStyleDict[metric],\n\t                               color=self.lineColorDict[metric],\n", "                               marker=self.lineMarkerDict[metric],\n\t                               markerfacecolor='white',\n\t                               mew=self.linewidth,\n\t                               clip_on=self.line_clip_on,\n\t                               linewidth=self.linewidth,\n\t                               markersize=self.markersize + 1.5 if self.lineMarkerDict[metric] == '+' else\n\t                                          self.markersize + 0.5 if self.lineMarkerDict[metric] in ['x', '^'] else self.markersize,\n\t                               zorder=self.zorderDict[metric])\n\t                legend_handles[metric] = l\n\t        else:\n", "            for metric, line_data in lines_data:\n\t                l, = ax_R.plot([a[0] for a in line_x_data.values()],\n\t                               line_data,\n\t                               linestyle=self.lineStyleDict[metric],\n\t                               color=self.lineColorDict[metric],\n\t                               marker=self.lineMarkerDict[metric],\n\t                               markerfacecolor='white',\n\t                               mew=self.linewidth,\n\t                               clip_on=self.line_clip_on,\n\t                               linewidth=self.linewidth,\n", "                               markersize=self.markersize + 1.5 if self.lineMarkerDict[metric] == '+' else\n\t                                          self.markersize + 0.5 if self.lineMarkerDict[metric] in ['x', '^'] else self.markersize,\n\t                               zorder=self.zorderDict[metric])\n\t                legend_handles[metric] = l\n\t        ax_R.set_ylabel(self.yR_label, fontsize=self.font_size)\n\t        if self.yR_tick:\n\t            ax_R.set_yticks(self.yR_tick)\n\t        if self.yR_lim:\n\t            ax_R.set_ylim(*self.yR_lim)\n\t        if self.yR_scale:\n", "            ax_R.set_yscale(self.yR_scale)\n\t        ax_R.tick_params(labelsize=self.tick_size)\n\t        if self.legendR_location:\n\t            if self.legendR_param:\n\t                ax_R.legend(legend_handles.values(), legend_handles.keys(), loc=self.legendR_location, frameon=False, **self.legendR_param)\n\t            else:\n\t                ax_R.legend(legend_handles.values(), legend_handles.keys(), fontsize=self.legend_size, loc=self.legendR_location, frameon=False, ncol=self.legendR_ncol)\n\t        else:\n\t            if self.legendR_param:\n\t                ax_R.legend(legend_handles.values(), legend_handles.keys(), bbox_to_anchor=self.legendR_anchor, frameon=False, **self.legendR_param)\n", "            else:\n\t                ax_R.legend(legend_handles.values(), legend_handles.keys(), fontsize=self.legend_size, bbox_to_anchor=self.legendR_anchor, frameon=False, ncol=self.legendR_ncol)\n\t        plt.savefig(str(Path(self.pic_dir) / fig_name), format='pdf', bbox_inches='tight')\n\t        plt.close()"]}
{"filename": "exp/utils/pic_generator.py", "chunked_list": ["from pathlib import Path\n\timport json\n\tfrom utils.pic_line_drawer import LineDrawer\n\tfrom utils.pic_bar_drawer import BarDrawer\n\tfrom utils.color_printer import print_OK\n\tclass PicGenerator(object):\n\t    def __init__(self, data_path: str, style_path: str):\n\t        self.__data_path = data_path\n\t        self.__style_path = style_path\n\t        self.__ld = LineDrawer(data_path)\n", "        self.__bd = BarDrawer(data_path)\n\t        self.__figs_type = {\n\t            '3a' : 'line_one_ax', '3b' : 'bar_one_ax'   , '3c' : 'line_one_ax'  , '3d' : 'line_one_ax',\n\t            '4a' : 'line_two_ax', '4b' : 'bar_two_ax'   , '4c' : 'line_one_ax'  , '4d' : 'line_two_ax',\n\t            '11a': 'line_one_ax', '11b': 'line_one_ax'  , '11c': 'line_one_ax'  , '11d': 'line_one_ax', '11e': 'line_one_ax'  ,\n\t            '12a': 'line_one_ax', '12b': 'line_one_ax'  , '12c': 'line_one_ax'  , '12d': 'line_one_ax', '12e': 'line_one_ax'  ,\n\t            '13' : 'line_one_ax', '14' : 'bar_with_line', '15' : 'bar_with_line', '16' : 'bar_two_ax' , '17' : 'bar_with_line',\n\t            '18a': 'line_one_ax', '18b': 'line_one_ax'  , '18c': 'line_one_ax'\n\t        }\n\t        self.__axhlineColor = '#00007c'\n", "        self.__linewidth = 0.8\n\t        self.__font_size = 15\n\t    def __aux_plt(self, ax):\n\t        ax.axhline(y=45, ls=(0, (5, 3)), c=self.__axhlineColor, lw=self.__linewidth)\n\t        ax.text(200, 47, 'IOPS Upper Bound', fontsize=self.__font_size-1, color=self.__axhlineColor)\n\t        ax.axhline(y=7, ls=(0, (5, 3)), c=self.__axhlineColor, lw=self.__linewidth)\n\t        ax.text(120, 9, 'Bandwidth Bottleneck', fontsize=self.__font_size-1, color=self.__axhlineColor)\n\t    def __annotation(self, ax):\n\t        ax.annotate('', xy=(4, 14), xytext=(40, 14), arrowprops=dict(arrowstyle=\"<->\", color=self.__axhlineColor, ls=(0, (5, 3))), fontsize=self.__font_size-1)\n\t        ax.text(12.5, 16, '4M vs. 40M', fontsize=self.__font_size-1, color=self.__axhlineColor)\n", "    def generate(self, fig_num: str):\n\t        fig_name = f\"fig_{fig_num}.pdf\"\n\t        fig_type = self.__figs_type[fig_num]\n\t        # load data\n\t        with (Path(self.__data_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t            data = json.load(f)\n\t        # load style\n\t        with (Path(self.__style_path) / f'fig_{fig_num}.json').open(mode='r') as f:\n\t            custom_style = json.load(f)\n\t        # load func\n", "        if fig_num == '3c':\n\t            custom_style['aux_plt_func'] = self.__aux_plt\n\t        if fig_num == '3d':\n\t            custom_style['aux_plt_func'] = self.__annotation\n\t        # draw\n\t        if fig_type == 'line_one_ax':\n\t            self.__ld.plot_with_one_ax(data, fig_name, custom_style=custom_style)\n\t        elif fig_type == 'line_two_ax':\n\t            self.__ld.plot_with_two_ax(data, fig_name, custom_style=custom_style)\n\t        elif fig_type == 'bar_one_ax':\n", "            self.__bd.plot_with_one_ax(data, fig_name, custom_style=custom_style)\n\t        elif fig_type == 'bar_two_ax':\n\t            self.__bd.plot_with_two_ax(data, fig_name, custom_style=custom_style)\n\t        elif fig_type == 'bar_with_line':\n\t            self.__bd.plot_with_line(data, fig_name, custom_style=custom_style)\n\t        print_OK(f\"Draw {fig_name} done!\")\n"]}
{"filename": "ycsb/gen_workload.py", "chunked_list": ["import sys\n\timport os\n\tclass bcolors:\n\t    HEADER = '\\033[95m'\n\t    OKBLUE = '\\033[94m'\n\t    OKGREEN = '\\033[92m'\n\t    WARNING = '\\033[93m'\n\t    FAIL = '\\033[91m'\n\t    ENDC = '\\033[0m'\n\t    BOLD = '\\033[1m'\n", "    UNDERLINE = '\\033[4m'\n\t#####################################################################################\n\tdef reverseHostName ( email ) :\n\t    name, sep, host = email.partition('@')\n\t    hostparts = host.strip().split('.')\n\t    r_host = '.'.join(reversed(hostparts))\n\t    # for part in hostparts :\n\t    #     r_host = part + '.' + r_host\n\t    return (r_host + sep + name).replace(\" \", \"\").strip()\n\t#####################################################################################\n", "if (len(sys.argv) != 4) :\n\t    print(bcolors.WARNING + 'Usage:')\n\t    print('python3 gen_workload.py workload_name key_type full_or_small' + bcolors.ENDC)\n\t    exit(0)\n\t# config_file = sys.argv[1]\n\t# args = []\n\t# f_config = open (config_file, 'r')\n\t# for line in f_config :\n\t#     args.append(line[:-1])\n\tworkload = sys.argv[1]\n", "key_type = sys.argv[2]\n\tycsb_dir = 'YCSB/'\n\tworkload_dir = f'{sys.argv[3]}_workload_spec/'\n\toutput_dir= 'workloads/'\n\tif not os.path.exists(output_dir):\n\t    os.mkdir(output_dir)\n\tprint(bcolors.OKGREEN + 'workload = ' + workload)\n\tprint('key type = ' + key_type + bcolors.ENDC)\n\temail_list = 'emails.txt'            # NOTE: To generate email-key workloads, an email list is needed\n\temail_list_size = 125050709          # NOTE: change to the size of your email list (p.s. should be larger than twice of your YCSB LOAD size)\n", "out_ycsb_load = output_dir + 'ycsb_load_' + key_type + '_' + workload\n\tout_ycsb_txn = output_dir + 'ycsb_txn_' + key_type + '_' + workload\n\tout_load_ycsbkey = output_dir + 'load_' + 'ycsbkey' + '_' + workload\n\tout_txn_ycsbkey = output_dir + 'txn_' + 'ycsbkey' + '_' + workload\n\tout_load = output_dir + 'load_' + key_type + '_' + workload\n\tout_txn = output_dir + 'txn_' + key_type + '_' + workload\n\tcmd_ycsb_load = ycsb_dir + 'bin/ycsb load basic -P ' + workload_dir + workload + ' -s > ' + out_ycsb_load\n\tcmd_ycsb_txn = ycsb_dir + 'bin/ycsb run basic -P ' + workload_dir + workload + ' -s > ' + out_ycsb_txn\n\tos.system(cmd_ycsb_load)\n\tos.system(cmd_ycsb_txn)\n", "#####################################################################################\n\tf_load = open (out_ycsb_load, 'r')\n\tf_load_out = open (out_load_ycsbkey, 'w')\n\tfor line in f_load :\n\t    cols = line.split()\n\t    if len(cols) > 0 and cols[0] == \"INSERT\":\n\t        f_load_out.write (cols[0] + \" \" + cols[2][4:] + \"\\n\")\n\tf_load.close()\n\tf_load_out.close()\n\tf_txn = open (out_ycsb_txn, 'r')\n", "f_txn_out = open (out_txn_ycsbkey, 'w')\n\tfor line in f_txn :\n\t    cols = line.split()\n\t    if (cols[0] == 'SCAN') or (cols[0] == 'INSERT') or (cols[0] == 'READ') or (cols[0] == 'UPDATE'):\n\t        startkey = cols[2][4:]\n\t        if cols[0] == 'SCAN' :\n\t            numkeys = cols[3]\n\t            f_txn_out.write (cols[0] + ' ' + startkey + ' ' + numkeys + '\\n')\n\t        else :\n\t            f_txn_out.write (cols[0] + ' ' + startkey + '\\n')\n", "f_txn.close()\n\tf_txn_out.close()\n\tcmd = 'rm -f ' + out_ycsb_load\n\tos.system(cmd)\n\tcmd = 'rm -f ' + out_ycsb_txn\n\tos.system(cmd)\n\t#####################################################################################\n\tif key_type == 'randint' :\n\t    f_load = open (out_load_ycsbkey, 'r')\n\t    f_load_out = open (out_load, 'w')\n", "    for line in f_load :\n\t        f_load_out.write (line)\n\t    f_txn = open (out_txn_ycsbkey, 'r')\n\t    f_txn_out = open (out_txn, 'w')\n\t    for line in f_txn :\n\t        f_txn_out.write (line)\n\telif key_type == 'monoint' :\n\t    keymap = {}\n\t    f_load = open (out_load_ycsbkey, 'r')\n\t    f_load_out = open (out_load, 'w')\n", "    count = 0\n\t    for line in f_load :\n\t        cols = line.split()\n\t        keymap[int(cols[1])] = count\n\t        f_load_out.write (cols[0] + ' ' + str(count) + '\\n')\n\t        count += 1\n\t    f_txn = open (out_txn_ycsbkey, 'r')\n\t    f_txn_out = open (out_txn, 'w')\n\t    for line in f_txn :\n\t        cols = line.split()\n", "        if cols[0] == 'SCAN' :\n\t            f_txn_out.write (cols[0] + ' ' + str(keymap[int(cols[1])]) + ' ' + cols[2] + '\\n')\n\t        elif cols[0] == 'INSERT' :\n\t            keymap[int(cols[1])] = count\n\t            f_txn_out.write (cols[0] + ' ' + str(count) + '\\n')\n\t            count += 1\n\t        else :\n\t            f_txn_out.write (cols[0] + ' ' + str(keymap[int(cols[1])]) + '\\n')\n\telif key_type == 'email' :\n\t    keymap = {}\n", "    f_email = open (email_list, 'r')\n\t    emails = f_email.readlines()\n\t    f_load = open (out_load_ycsbkey, 'r')\n\t    f_load_out = open (out_load, 'w')\n\t    sample_size = len(f_load.readlines())\n\t    gap = email_list_size // sample_size\n\t    if workload in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)]:\n\t        gap = 1\n\t    else:\n\t        assert(gap >= 2)\n", "    f_load.close()\n\t    f_load = open (out_load_ycsbkey, 'r')\n\t    count = 0\n\t    for line in f_load :\n\t        cols = line.split()\n\t        email = reverseHostName(emails[count * gap])\n\t        keymap[int(cols[1])] = email\n\t        f_load_out.write (cols[0] + ' ' + email + '\\n')\n\t        count += 1\n\t    if workload not in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)]:\n", "        count = 0\n\t    f_txn = open (out_txn_ycsbkey, 'r')\n\t    f_txn_out = open (out_txn, 'w')\n\t    for line in f_txn :\n\t        cols = line.split()\n\t        if cols[0] == 'SCAN' :\n\t            f_txn_out.write (cols[0] + ' ' + keymap[int(cols[1])] + ' ' + cols[2] + '\\n')\n\t        elif cols[0] == 'INSERT' :\n\t            email = reverseHostName(emails[count if workload in ['workloadla'] + ['workload' + str(i) + '-' for i in range(0, 101, 10)] else (count * gap + 1)])\n\t            keymap[int(cols[1])] = email\n", "            f_txn_out.write (cols[0] + ' ' + email + '\\n')\n\t            count += 1\n\t        else :\n\t            f_txn_out.write (cols[0] + ' ' + keymap[int(cols[1])] + '\\n')\n\tf_load.close()\n\tf_load_out.close()\n\tf_txn.close()\n\tf_txn_out.close()\n\tcmd = 'rm -f ' + out_load_ycsbkey\n\tos.system(cmd)\n", "cmd = 'rm -f ' + out_txn_ycsbkey\n\tos.system(cmd)\n"]}
{"filename": "ycsb/split_workload.py", "chunked_list": ["import sys\n\tclass bcolors:\n\t    HEADER = '\\033[95m'\n\t    OKBLUE = '\\033[94m'\n\t    OKGREEN = '\\033[92m'\n\t    WARNING = '\\033[93m'\n\t    FAIL = '\\033[91m'\n\t    ENDC = '\\033[0m'\n\t    BOLD = '\\033[1m'\n\t    UNDERLINE = '\\033[4m'\n", "if (len(sys.argv) != 5) and (len(sys.argv) != 6):\n\t    print(bcolors.WARNING + 'Usage:')\n\t    print('python3 split_workload.py workload_name[a/b/c/d/e] key_type[randint/email] CN_num client_per_CN (loader_num)' + bcolors.ENDC)\n\t    exit(0)\n\tworkload = sys.argv[1]\n\tkeyType = sys.argv[2]\n\tCNum = sys.argv[3]\n\tclientPerNode = sys.argv[4]\n\tloader_num = '8' if len(sys.argv) == 5 else sys.argv[5]\n\tprint(bcolors.OKGREEN + 'workload = ' + workload)\n", "print('key type = ' + keyType)\n\tprint('CN num = ' + CNum)\n\tprint('client-num/CN = ' + clientPerNode)\n\tprint('loader_num = ' + loader_num + bcolors.ENDC)\n\tCNum = int(CNum)\n\tclientPerNode = int(clientPerNode)\n\tloader_num = int(loader_num)\n\tsplitNums = {\n\t    \"load\": CNum * min(clientPerNode, loader_num),\n\t    \"txn\": CNum * clientPerNode\n", "}\n\tfor op in [\"load\", \"txn\"]:\n\t    splitNum = splitNums[op]\n\t    fname = f\"{sys.path[0]}/workloads/{op}_{keyType}_workload{workload}\"\n\t    print(\"spliting: \", fname)\n\t    with open(fname, \"r\") as wlFile:\n\t        lines = wlFile.readlines()\n\t        lineNum = len(lines)\n\t        splitSize = lineNum // splitNum\n\t        for i in range(splitNum):\n", "            print(i * splitSize, (i + 1) * splitSize)\n\t            slines = lines[int(i * splitSize): int((i + 1) * splitSize)]\n\t            splitFname = fname + str(i)\n\t            with open(splitFname, \"w\") as outFile:\n\t                outFile.writelines(slines)\n"]}
