{"filename": "spectreCNVPopulation.py", "chunked_list": ["import gzip\n\timport os\n\timport logging as logger\n\timport traceback\n\timport json\n\tfrom util.outputWriter import VCFOutput\n\tfrom analysis.cnv_candidate import CNVCandidate\n\tclass SpectrePopulation(object):\n\t    def __init__(self, sample_id, output_dir, genome_info):\n\t        self.logger = logger\n", "        self.sample_id = sample_id\n\t        self.output_dir = output_dir\n\t        self.final_candidates = {}  # Holds all CNVs calls that have been analyzed and filtered by Spectre\n\t        self.raw_candidates = {}  # Holds all raw CNVs calls before any filtering was applied by Spectre\n\t        self.cnv_call_list = {}  # Holds resulting cNV calls.\n\t        self.genome_info = genome_info\n\t        self.as_dev = False  # TODO get outside propagation\n\t    def merge_genome_info(self, new_genome_info: dict) -> None:\n\t        \"\"\"\n\t        Merging genome information incase different genomic information is stored in the .spc files.\n", "         This ensures the correct metadata information in the resulting population output VCF.\n\t        :param new_genome_info: dict of genome information\n\t        :return: None\n\t        \"\"\"\n\t        if not self.genome_info:\n\t            self.genome_info = new_genome_info.copy()\n\t        else:\n\t            if self.genome_info.keys() != new_genome_info.keys():\n\t                logger.warning(\"Genomics information of provided samples are not matching!\")\n\t            for key1, values1 in self.genome_info.items():\n", "                for key2, values2 in new_genome_info.items():\n\t                    if key1 == key2:\n\t                        for value2 in values2:\n\t                            if value2 not in values1:\n\t                                values1.append(value2)\n\t    def load_files(self, files: list) -> None:\n\t        \"\"\"\n\t        Determination of loading process for the candidate generation.\n\t        :param files: list of paths to the .spc\n\t        :return: None\n", "        \"\"\"\n\t        for file in files:\n\t            try:\n\t                if os.path.exists(file):\n\t                    if str(file).__contains__(\".spc\") or str(file).__contains__(\".spc.gz\"):\n\t                        self.load_candidates_from_intermediate_file_spc(file)\n\t                else:\n\t                    raise\n\t            except:\n\t                self.logger.error(f\"File does not exist! Provided : {file}\")\n", "    def load_candidates_from_intermediate_file_spc(self, file) -> None:\n\t        \"\"\"\n\t        Load candidates from a json format file and converting the content to candidates.\n\t        :param file: path to pickled file\n\t        :return: None\n\t        \"\"\"\n\t        spc_dict = dict()\n\t        try:\n\t            if '.gz' in file:\n\t                with gzip.open(file, \"rt\", encoding=\"UTF-8\") as input_file:\n", "                    spc_dict = json.load(input_file)\n\t            else:\n\t                with open(file, \"rt\") as input_file:\n\t                    spc_dict = json.load(input_file)\n\t            # Convert dictionary to candidates\n\t            filename = os.path.basename(file).split(\".spc\")[0]\n\t            self.convert_spc_to_candidate_list(filename, spc_dict)\n\t        except:\n\t            self.logger.error(traceback.print_exc())\n\t            self.logger.error(f\"Check if file meets the JSON standard. Error in file {file}\")\n", "        pass\n\t    def convert_dict_to_candidate_list(self,filename, candidates_dict):\n\t        result = dict([(chrom, []) for chrom in candidates_dict.keys()])\n\t        for chrom, candidates in candidates_dict.items():\n\t            new_candidate = CNVCandidate()\n\t            for candidate in candidates:\n\t                for candidate_key, candidate_value in candidate.items():\n\t                    if candidate_key in new_candidate.__dict__.keys():\n\t                        new_candidate.__setattr__(candidate_key, candidate_value)\n\t                        new_candidate.__setattr__('sample_origin', filename)  # update source to filename\n", "                        pass\n\t                new_candidate.reinitialize_candidate_values()\n\t                result[chrom].append(new_candidate)\n\t        return result\n\t    def convert_spc_to_candidate_list(self, filename, candidate_dict: dict):\n\t        if \"spectre\" not in candidate_dict[\"metadata\"][\"source\"]:\n\t            self.logger.warning(\"Provided .spc file does not originate from Spectre.\")\n\t            self.logger.warning(\"Trying to convert the provided file\")\n\t        # Get genome information\n\t        if \"genome_info\" in candidate_dict.keys():\n", "            self.merge_genome_info(candidate_dict['genome_info'])\n\t        # Get final/refined cnvs\n\t        if 'refined_cnvs' in candidate_dict.keys():\n\t            # Init candidate dictionary\n\t            if filename not in self.final_candidates.keys():\n\t                self.final_candidates[filename] = dict()\n\t            self.final_candidates[filename] = self.convert_dict_to_candidate_list(filename, candidate_dict['refined_cnvs'])\n\t        # Get raw cnvs\n\t        if 'raw_cnvs' in candidate_dict.keys():\n\t            if filename not in self.raw_candidates.keys():\n", "                self.raw_candidates[filename] = dict()\n\t            self.raw_candidates[filename] = self.convert_dict_to_candidate_list(filename, candidate_dict['raw_cnvs'])\n\t        pass\n\t    def cnv_call_population(self) -> None:\n\t        \"\"\"\n\t        Starts CNV population calling\n\t        :return: None\n\t        \"\"\"\n\t        self.logger.info(\"Starting population CNV calls\")\n\t        self.call_cnv()\n", "    @staticmethod\n\t    def candidate_overlapping(cnv1: CNVCandidate, cnv2: CNVCandidate) -> bool:\n\t        \"\"\"\n\t        Checking if two CNV candidates are overlapping\n\t        :param cnv1: CNV candidate 1\n\t        :param cnv2: CNV candidate 2\n\t        :return: True if candidates are overlapping.\n\t        \"\"\"\n\t        return cnv1.start <= cnv2.start <= cnv1.end or cnv1.start <= cnv2.end <= cnv1.end\n\t    @staticmethod\n", "    def candidate_same_cn(cnv1: CNVCandidate, cnv2: CNVCandidate) -> bool:\n\t        \"\"\"\n\t        Checking if two CNV candidates have the same copy number status\n\t        :param cnv1: CNV candidate 1\n\t        :param cnv2: CNV candidate 2\n\t        :return: True if the copy number status matches.\n\t        \"\"\"\n\t        return cnv1.cn_status == cnv2.cn_status\n\t    @staticmethod\n\t    def candidate_same_cn_type(cnv1: CNVCandidate, cnv2: CNVCandidate) -> bool:\n", "        \"\"\"\n\t        Checking if two CNV candidates have the same copy number type\n\t        :param cnv1: CNV candidate 1\n\t        :param cnv2: CNV candidate 2\n\t        :return: True if the copy number type matches.\n\t        \"\"\"\n\t        return cnv1.type == cnv2.type\n\t    def call_cnv_final_candidates(self) -> None:\n\t        \"\"\"\n\t        Creating a structure which holds all overlapping CNVs of the final CNV candidates.\n", "        :return: None\n\t        \"\"\"\n\t        # everything against everything\n\t        for samples_key1, samples_values1 in self.final_candidates.items():\n\t            for samples_key2, samples_values2 in self.final_candidates.items():\n\t                for sample_chrom1, sample_values1 in samples_values1.items():\n\t                    for sample_chrom2, sample_values2 in samples_values2.items():\n\t                        # check for same chromosome\n\t                        if sample_chrom1 == sample_chrom2:\n\t                            # all individual samples against each other\n", "                            for sample1 in sample_values1:\n\t                                for sample2 in sample_values2:\n\t                                    is_overlapping = self.candidate_overlapping(sample1, sample2)\n\t                                    is_same_cn = self.candidate_same_cn(sample1, sample2)\n\t                                    is_same_cn_type = self.candidate_same_cn_type(sample1, sample2)\n\t                                    if is_overlapping and is_same_cn and is_same_cn_type:\n\t                                        # check if chromosome exists in cnv_call_list\n\t                                        if sample_chrom1 not in self.cnv_call_list.keys():\n\t                                            self.cnv_call_list[sample_chrom1] = []  # create list for\n\t                                        # check if sample1 is in the list\n", "                                        if sample1 not in self.cnv_call_list[sample_chrom1]:\n\t                                            self.cnv_call_list[sample_chrom1].append(sample1)\n\t                                        # check if all keys are available in sampel1\n\t                                        if sample1.support_cnv_calls.keys() != self.final_candidates.keys():\n\t                                            for key in self.final_candidates.keys():\n\t                                                if key not in sample1.support_cnv_calls.keys():\n\t                                                    sample1.support_cnv_calls[key] = set()\n\t                                            sample1.support_cnv_calls = dict(sorted(sample1.support_cnv_calls.items()))\n\t                                        # add sample2 to the support cnvs in sample1\n\t                                        sample1.support_cnv_calls[samples_key2].add(sample2)\n", "    def cnv_lookup_in_raw_candidates(self) -> None:\n\t        \"\"\"\n\t        Check if any of the final CNVs are supported by any non-refined CNVs. If a CNV is found it will be\n\t        added to the candidate.\n\t        :return: None\n\t        \"\"\"\n\t        missed_cnt = 0\n\t        for variant_key, variants in self.cnv_call_list.items():\n\t            for variant in variants:\n\t                for raw_sample_key, value in self.raw_candidates.items():\n", "                    for chrom_key, candidates in value.items():\n\t                        for candidate in candidates:\n\t                            if variant.sample_origin != candidate.sample_origin:\n\t                                # qualification checks\n\t                                is_overlapping = self.candidate_overlapping(variant, candidate)\n\t                                is_same_cn = self.candidate_same_cn(variant, candidate)\n\t                                is_same_cn_type = self.candidate_same_cn_type(variant, candidate)\n\t                                if is_overlapping and is_same_cn and is_same_cn_type:\n\t                                    variant.support_cnv_calls[candidate.sample_origin].add(candidate)\n\t                                    missed_cnt += 1\n", "    def call_cnv(self) -> None:\n\t        \"\"\"\n\t        Starts CNV calling with CNVs from multiple samples.\n\t        :return: None\n\t        \"\"\"\n\t        self.logger.info(f\"Starting population mode with samples: {', '.join(list(self.final_candidates.keys()))}\")\n\t        # generating union table of final overlaps\n\t        self.call_cnv_final_candidates()\n\t        # look up if all missing fields are covered by any raw cnv call\n\t        self.cnv_lookup_in_raw_candidates()\n", "        # Writing results to disk\n\t        output_file = f\"{self.output_dir}/population_mode_{self.sample_id}.vcf\"\n\t        self.logger.info(f\"Writing population VCF @: {output_file}\")\n\t        vcf_output = VCFOutput(output_file=output_file, genome_info=self.genome_info)\n\t        vcf_output.make_vcf(\n\t            chromosome_list=self.cnv_call_list.keys(), cnv_candidate_list=self.cnv_call_list,\n\t            sample_id=self.final_candidates.keys(), population_sample_ids=list(self.final_candidates.keys()))\n"]}
{"filename": "spectreCNV.py", "chunked_list": ["import os\n\timport logging as logger\n\timport util.mosdepthReader\n\tfrom analysis.analysis import CNVAnalysis\n\tclass SpectreCNV:\n\t    def __init__(self, coverage_dir, bin_size, out_dir, metadata_file_fasta, genome_info, sample_id=\"\",\n\t                 snv_file_vcf=\"\", only_chr_list=\"\", ploidy=2, min_cnv_len=1000000, as_dev=False, dev_params=None,\n\t                 debug_dir=\"\"):\n\t        self.as_dev = as_dev\n\t        # logger\n", "        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        self.genome_info = genome_info\n\t        self.metadata_reference = metadata_file_fasta\n\t        self.sample_id = sample_id if sample_id != \"\" else \"sample-\"  # TODO: random string\n\t        self.snv_file_vcf = snv_file_vcf\n\t        self.only_chr_list = only_chr_list\n\t        self.min_cnv_len = min_cnv_len\n\t        self.ploidy = ploidy\n\t        self.snv_file_bed_af = \"\"\n", "        self.mosdepth_data = None\n\t        self.out_bed = \"out.bed\"\n\t        self.out_vcf = \"out.vcf\"\n\t        self.bin_size = bin_size\n\t        self.out_dir = out_dir\n\t        self.__get_config(coverage_dir)  # fill 'self.operation_dict' working variable\n\t        # population\n\t        self.population = {}\n\t        # self.__get_population_config(population)\n\t        # dev\n", "        self.dev_params = dev_params  # all params from spectre_args obj (SpectreCallParam)\n\t        self.debug_dir = debug_dir\n\t        # self.cnv_analysis = None  # TODO init by using CNVAnalysis\n\t        self.cnv_analysis = CNVAnalysis(coverage_file=self.mosdepth_data.coverage_file,\n\t                                        coverage_mosdepth_data=self.mosdepth_data.mosdepth_summary_data,\n\t                                        output_directory=self.out_dir, outbed=self.out_bed, outvcf=self.out_vcf,\n\t                                        bin_size=self.bin_size, genome_info=self.genome_info, sample_id=self.sample_id,\n\t                                        metadata_ref=self.metadata_reference, snv_file=self.snv_file_vcf,\n\t                                        only_chr_list=self.only_chr_list, ploidy=self.ploidy, min_cnv_len=min_cnv_len,\n\t                                        as_dev=self.as_dev, dev_params=self.dev_params, debug_dir=self.debug_dir)\n", "    def coverage_dir_files(self, coverage_dir):\n\t        coverage_dir = os.path.abspath(os.path.expanduser(coverage_dir))\n\t        coverage_file = \"\"\n\t        coverage_summary_file = \"\"\n\t        for each_dir in os.listdir(coverage_dir):\n\t            if \"mosdepth.summary.txt\" in each_dir:\n\t                coverage_summary_file = f'{coverage_dir}/{each_dir}'\n\t            elif \".regions.bed.gz\" in each_dir and (\"csi\" not in each_dir and \"tbi\" not in each_dir):\n\t                coverage_file = f'{coverage_dir}/{each_dir}'\n\t            else:\n", "                pass\n\t        if coverage_file != \"\" and coverage_summary_file != \"\":\n\t            return [coverage_file, coverage_summary_file]\n\t        else:\n\t            self.logger.error(f'coverage file or summary not found, directory {coverage_dir} has the following files:\\n'\n\t                              f'  {os.listdir(coverage_dir)}')\n\t        return [\"\", \"\"]\n\t    def __get_config(self, coverage_dir):\n\t        self.logger.info(f'Spectre calculating for: {str(coverage_dir)} and bin size: {self.bin_size}')\n\t        # input coverage\n", "        [coverage_file, cov_summary_file] = self.coverage_dir_files(coverage_dir)\n\t        self.mosdepth_data = util.mosdepthReader.MosdepthReader(coverage_file, cov_summary_file)\n\t        self.mosdepth_data.summary_data()\n\t        # output bed dir/file\n\t        self.out_bed = os.path.join(os.path.join(self.out_dir, f'{self.sample_id}_cnv.bed'))\n\t        # output VCF dir/file\n\t        self.out_vcf = os.path.join(os.path.join(self.out_dir, f'{self.sample_id}_cnv.vcf'))\n\t    def __get_config_dict(self, coverage_dir) -> dict:\n\t        # get basic mosdepth coverage for the provided population sample\n\t        result = {}\n", "        self.logger.info(f\"Spectre calculating population sample for: {str(coverage_dir)} and bin size {self.bin_size}\")\n\t        [coverage_file, cov_summary_file] = self.coverage_dir_files(coverage_dir)\n\t        result[\"mosdepth_data\"] = util.mosdepthReader.MosdepthReader(coverage_file, cov_summary_file)\n\t        result[\"mosdepth_data\"].summary_data()  # calculate summary\n\t        return result\n\t    def __get_population_config(self, population_coverage_dirs):\n\t        # get config for the provided population samples\n\t        for population_coverage_dir in population_coverage_dirs:\n\t            population_sample = os.path.join(population_coverage_dir).split(\"/\")[-2]\n\t            self.logger.info(f\"{population_sample}\\t{population_coverage_dir}\")\n", "            self.population[population_sample] = self.__get_config_dict(population_coverage_dir)\n\t    def cnv_call(self):\n\t        # Data normalization\n\t        self.logger.info(\"Data normalization and outlier removal (right tail)\")\n\t        self.cnv_analysis.data_normalization()\n\t        # Coverage analysis\n\t        self.logger.info(f\"CNV calling - Coverage for sample: {self.sample_id}\")\n\t        # get raw CNV for original sample\n\t        self.cnv_analysis.call_cnv_coverage(write_csv=self.as_dev)\n\t        self.cnv_analysis.get_cnv_metrics()\n", "        # self.cnv_analysis.write_intermediate_candidates(\"raw\")\n\t        # refine cnvs\n\t        self.cnv_analysis.refine_cnv_calls(self.as_dev)  # set to self.as_dev\n\t        # SNV analysis\n\t        if self.snv_file_vcf != \"\":\n\t            self.logger.info(\"CNV candidates by SNV\")\n\t            snv_file_basename_no_dot = \"_\".join(os.path.basename(self.snv_file_vcf).split('.'))\n\t            self.snv_file_bed_af = f'{self.out_dir}/{snv_file_basename_no_dot}.bed'\n\t            self.cnv_analysis.convert_vcf_to_tabular(self.snv_file_bed_af)\n\t            self.cnv_analysis.call_cnv_af_region()\n", "        # CNV metrics\n\t        # self.logger.warning(\"Disabled CNV metrics\")\n\t        self.logger.info(\"Calculate CNV metrics\")\n\t        self.cnv_analysis.get_cnv_metrics(refined_cnvs=True)\n\t        # Make output files\n\t        self.logger.info(\"Final candidates are written to spc file\")\n\t        self.cnv_analysis.write_intermediate_candidates()\n\t        self.logger.info(\"Results are writen to bed file\")\n\t        self.cnv_analysis.cnv_result_bed()\n\t        self.logger.info(\"Results are writen to VCF file\")\n", "        self.cnv_analysis.cnv_result_vcf()\n\t        self.logger.info(\"Result plot in progress\")\n\t        self.cnv_analysis.cnv_plot()\n\t        # End\n\t        self.logger.info(f\"Output dir: {self.out_dir}\")\n\t        self.logger.info(f\"Done with sample {self.sample_id}\")\n\t        # sys.exit(0)\n"]}
{"filename": "spectre.py", "chunked_list": ["#!/usr/bin/env python3\n\timport argparse\n\timport sys\n\timport spectreCNV\n\timport spectreCNVPopulation\n\timport os\n\timport pysam\n\timport logging as logger\n\tfrom util.metadata.metadataCollector import FastaRef\n\tfrom multiprocessing import Pool\n", "class SpectreCallParam(object):\n\t    def __init__(self):\n\t        self.bin_size = 1  # in kb\n\t        self.coverage_dir = \"\"\n\t        self.sample_id = \"\"\n\t        self.out_dir = \"\"\n\t        self.reference = \"\"\n\t        self.metadata = \"\"\n\t        self.snv = \"\"\n\t        self.n_size = 5\n", "        self.save_only = False  # this one is not updated as we need the return to occur\n\t        self.black_list = \"\"\n\t        self.only_chr_list = \"\"\n\t        self.ploidy = 2\n\t        self.min_cnv_len = 1000000\n\t        self.call_from_console = False\n\t        # dev/debug + hidden params\n\t        self.as_dev = False\n\t        self.max_std_outlier_rm = 5\n\t        self.mosdepth_cov_genome_chr_diff = 0.10  # 10%\n", "        self.lower_2n_threshold = 1.5\n\t        self.upper_2n_threshold = 2.5\n\t        self.cov_diff_threshold = 0.80\n\t        self.dist_proportion = 0.25\n\t        self.candidate_final_threshold = 100000  # 100kb\n\t        self.population_mosdepth = []\n\t        self.threads = 1\n\t        self.run_population_mode = False\n\t    def set_params_from_args(self, user_args):\n\t        self.bin_size = user_args.bin_size\n", "        self.coverage_dir = user_args.coverage_dir\n\t        self.sample_id = user_args.sample_id\n\t        self.out_dir = user_args.output_dir\n\t        self.reference = user_args.reference\n\t        self.metadata = user_args.metadata\n\t        self.snv = user_args.snv_file\n\t        self.black_list = user_args.black_list_file\n\t        self.only_chr_list = user_args.only_chr_list\n\t        self.ploidy = user_args.ploidy\n\t        self.min_cnv_len = user_args.min_cnv_len\n", "        self.n_size = user_args.n_size\n\t        self.threads = user_args.threads\n\t        self.run_population_mode = user_args.run_population_mode\n\t        # dev/debug + hidden params\n\t        self.as_dev = user_args.as_dev\n\t        self.max_std_outlier_rm = user_args.max_std_outlier_rm  # 5\n\t        self.mosdepth_cov_genome_chr_diff = user_args.mosdepth_cov_genome_chr_diff  # 0.10  # 10%\n\t        self.lower_2n_threshold = user_args.lower_2n_threshold  # 1.5\n\t        self.upper_2n_threshold = user_args.upper_2n_threshold  # 2.5\n\t        self.cov_diff_threshold = user_args.cov_diff_threshold  # 0.80\n", "        self.dist_proportion = user_args.dist_proportion  # 0.25\n\t        self.candidate_final_threshold = user_args.candidate_final_threshold  # 100000  # 100kb\n\tclass SpectreMetadataParam(object):\n\t    def __init__(self):\n\t        self.reference = \"\"\n\t        self.bin_size = 1\n\t        self.metadata = \"\"\n\t        self.out_dir = \"\"\n\t        self.n_size = 5\n\t        self.save_only = False\n", "        self.as_dev = False\n\t        self.black_list = \"\"\n\t        self.call_from_console = False\n\t    def set_params_from_args(self, user_args, metadata_from_console=False):\n\t        self.reference = user_args.reference\n\t        self.bin_size = user_args.bin_size\n\t        self.metadata = user_args.metadata\n\t        self.out_dir = user_args.output_dir\n\t        self.n_size = user_args.n_size\n\t        self.save_only = user_args.save_only\n", "        self.black_list = user_args.black_list_file\n\t        self.as_dev = user_args.as_dev\n\t        self.call_from_console = metadata_from_console\n\tclass SpectrePopulationMode(object):\n\t    def __init__(self):\n\t        self.candidates = []\n\t        self.sample_id = \"\"\n\t        self.out_dir = \"\"\n\t        self.reference = \"\"\n\t        self.as_dev = False\n", "    def set_params_from_args(self, user_args):\n\t        self.candidates = user_args.population_candidates\n\t        self.sample_id = user_args.sample_id\n\t        self.out_dir = user_args.output_dir\n\t        self.reference = user_args.reference\n\t        self.as_dev = user_args.as_dev\n\tdef outside_spectre_worker(si: dict):\n\t    worker = spectreCNV.SpectreCNV(coverage_dir=si[\"coverage_dir\"], bin_size=si[\"bin_size\"],\n\t                                   out_dir=si[\"out_dir\"], metadata_file_fasta=si[\"metadata_file_fasta\"],\n\t                                   genome_info=si[\"genome_info\"], sample_id=si[\"sample_id\"],\n", "                                   snv_file_vcf=si[\"snv_file_vcf\"], only_chr_list=si[\"only_chr_list\"],\n\t                                   ploidy=si[\"ploidy_arg\"],min_cnv_len=si[\"min_cnv_len\"], as_dev=si[\"as_dev\"],\n\t                                   dev_params=si[\"dev_params\"], debug_dir=si[\"debug_dir\"])\n\t    worker.cnv_call()\n\t    return worker.cnv_analysis.intermediate_candidates_file_location\n\tclass Spectre:\n\t    def __init__(self, as_dev=False):\n\t        # version\n\t        self.version = \"0.1-alpha\"\n\t        self.logger = logger\n", "        self.debug_dir = \"\"\n\t        # for spectre cnv caller\n\t        self.spectre_args = SpectreCallParam()\n\t        self.sample_dir_list = []\n\t        # for metadata/removeNs\n\t        self.metadata_args = SpectreMetadataParam()\n\t        # metadata from reference genome (Ns)\n\t        self.__mdr = dict()\n\t        # metadata from reference genome for VCF\n\t        self.genome = dict()\n", "        # for benchmark\n\t        self.benchmark = {\n\t            \"1\": 1\n\t        }\n\t        # for population mode\n\t        self.population_args = SpectrePopulationMode()\n\t    def display_version(self):\n\t        self.logger.info(f'Spectre version: {self.version}')\n\t    @staticmethod\n\t    def make_genome_info(genome_info_pysam):\n", "        genome_info = {\"chromosomes\": genome_info_pysam.references,\n\t                       \"chr_lengths\": genome_info_pysam.lengths,\n\t                       \"chr_lengths_by_name\": {}}\n\t        for chr_name, chr_len in zip(genome_info_pysam.references, genome_info_pysam.lengths):\n\t            genome_info[\"chr_lengths_by_name\"][chr_name] = chr_len\n\t        return genome_info\n\t    def meta_data_extraction(self):\n\t        # ----------- Metadata extraction from ref file  -----------\n\t        # self.metadata_args.as_dev  # Note: this is not used\n\t        reference_fas = self.metadata_args.reference\n", "        bin_size = self.metadata_args.bin_size\n\t        output_dir = os.path.abspath(os.path.expanduser(self.metadata_args.out_dir))\n\t        threshold = self.metadata_args.n_size\n\t        # if \"call_from_console\" then the meta_data_report serves as output only, otherwise as both\n\t        meta_data_report = self.metadata_args.metadata if not self.metadata_args.call_from_console \\\n\t            else f'{output_dir}/{self.metadata_args.metadata}'\n\t        default_metadata_name = f'{output_dir}/metadata.mdr'  # default\n\t        save_only = self.metadata_args.save_only\n\t        fasta_metadata = FastaRef()\n\t        blacklist_data_bed = self.metadata_args.black_list  # bed format\n", "        self.logger.info(\"Extraction of metadata is activated\")\n\t        # metadata parameter given?\n\t        if meta_data_report != \"\":\n\t            meta_data_report = os.path.abspath(os.path.expanduser(meta_data_report))\n\t        else:\n\t            self.logger.info(\"Looking for default metadata.mdr\")\n\t            meta_data_report = os.path.abspath(os.path.expanduser(default_metadata_name))\n\t        # metadata file exists\n\t        if not os.path.exists(meta_data_report):\n\t            self.logger.info(f'Extracting metadata from {reference_fas}')\n", "            metadata_result = fasta_metadata.get_n_regions(filepath=reference_fas, report_output_dir=output_dir,\n\t                                                           out_file_name=meta_data_report, threshold=threshold,\n\t                                                           bin_size=bin_size, save_only=save_only)\n\t        else:\n\t            self.logger.info(f'Extracting metadata from {meta_data_report}')\n\t            metadata_result = fasta_metadata.extract_n_regions_from_report(meta_data_report)\n\t        if blacklist_data_bed != \"\":\n\t            self.logger.debug(\"Using blacklist\")\n\t            blacklist_results = fasta_metadata.extract_blacklisted_regions(blacklist_data_bed)\n\t            metadata_result = fasta_metadata.merge_metadata(metadata_result, blacklist_results)\n", "        # return metadata object (dict) after writing to file?\n\t        if save_only:\n\t            pass\n\t        else:\n\t            self.logger.debug(\"returned meta Object\")\n\t            return metadata_result\n\t    def __set_genome_info(self, reference):\n\t        pysam_genome = pysam.FastaFile(reference)\n\t        self.genome = self.make_genome_info(pysam_genome)\n\t        pysam_genome.close()\n", "    def spectre_exe(self):\n\t        # Parameters\n\t        self.display_version()\n\t        self.logger.info(\"Spectre enabled\")\n\t        bin_size = self.spectre_args.bin_size\n\t        coverage_dirs = [os.path.abspath(os.path.expanduser(directory)) for directory in self.spectre_args.coverage_dir]\n\t        sample_ids = self.spectre_args.sample_id\n\t        output_dir = os.path.abspath(os.path.expanduser(self.spectre_args.out_dir))\n\t        reference = os.path.abspath(os.path.expanduser(self.spectre_args.reference))\n\t        metadata = self.spectre_args.metadata\n", "        snv_file = self.spectre_args.snv\n\t        black_list_bed = self.spectre_args.black_list\n\t        only_chr_list = self.spectre_args.only_chr_list\n\t        ploidy_arg = self.spectre_args.ploidy\n\t        min_cnv_len = self.spectre_args.min_cnv_len\n\t        threads = self.spectre_args.threads\n\t        as_dev = self.spectre_args.as_dev\n\t        run_population_mode = self.spectre_args.run_population_mode\n\t        # get the metadata\n\t        self.metadata_args.reference = reference\n", "        self.metadata_args.bin_size = bin_size\n\t        self.metadata_args.metadata = metadata\n\t        self.metadata_args.black_list = black_list_bed\n\t        self.metadata_args.out_dir = output_dir\n\t        self.metadata_args.n_size = self.spectre_args.n_size\n\t        self.metadata_args.save_only = self.spectre_args.save_only\n\t        self.__mdr = self.meta_data_extraction()\n\t        self.__set_genome_info(reference)  # genome information\n\t        # Setting up directories\n\t        if not os.path.exists(output_dir):\n", "            os.makedirs(output_dir)\n\t        if as_dev:\n\t            self.debug_dir = f\"{output_dir}/debug\"\n\t            if not os.path.exists(self.debug_dir):\n\t                os.makedirs(self.debug_dir)\n\t        else:\n\t            self.debug_dir = output_dir\n\t        # Preparing spectre instructions for multiprocess\n\t        spectre_instructions = []\n\t        for sample_id, coverage_dir in zip(sample_ids, coverage_dirs):\n", "            instructions = {\"coverage_dir\": coverage_dir, \"bin_size\": bin_size,\n\t                            \"metadata_file_fasta\": self.__mdr.copy(),\n\t                            \"out_dir\": output_dir, \"genome_info\": self.genome.copy(),\n\t                            \"sample_id\": sample_id, \"snv_file_vcf\": snv_file, \"only_chr_list\": only_chr_list,\n\t                            \"ploidy_arg\": ploidy_arg, \"as_dev\": as_dev, \"dev_params\": self.spectre_args,\n\t                            \"debug_dir\": self.debug_dir, \"min_cnv_len\":min_cnv_len}\n\t            spectre_instructions.append(instructions.copy())\n\t        # Distribute Samples over cores/threads\n\t        with Pool(processes=threads) as pool:\n\t            results = pool.map(outside_spectre_worker, tuple(spectre_instructions))\n", "        intermediate_file_paths = [x for x in results]\n\t        if run_population_mode and len(intermediate_file_paths) > 1:\n\t            self.population_exe(\"population_file\", intermediate_file_paths, output_dir, reference, as_dev)\n\t        self.logger.info(\"Spectre finished\")\n\t        sys.exit(0)\n\t    def population_exe(self, population_sample_name=\"\", population_intermediate_files=None, outputdir=\"\",reference=\"\", as_dev=False):\n\t        self.logger.info(\"Starting Spectre population mode\")\n\t        # Adjusting parameters\n\t        sample_ids = self.population_args.sample_id if population_sample_name == \"\" else population_sample_name\n\t        population_paths = self.population_args.candidates if not population_intermediate_files else population_intermediate_files\n", "        output_dir = os.path.abspath(os.path.expanduser(self.population_args.out_dir)) if outputdir == \"\" else outputdir\n\t        as_dev = self.population_args.as_dev if not as_dev else as_dev\n\t        reference = self.population_args.reference if not reference else reference\n\t        # Required to load the genome information, if any other file format than .spc is provided\n\t        if not any(\".spc\" in s for s in population_paths):\n\t            if not self.genome:\n\t                self.__set_genome_info(reference)\n\t        self.logger.info(f\"Population mode: Loaded samples {population_paths}\")\n\t        # Directory setup\n\t        if not os.path.exists(output_dir):\n", "            os.makedirs(output_dir)\n\t        if as_dev:\n\t            debug_dir = f\"{output_dir}/debug\"\n\t            if not os.path.exists(debug_dir):\n\t                os.makedirs(debug_dir)\n\t        # Population mode setup\n\t        __spectre_population_worker = spectreCNVPopulation.SpectrePopulation(sample_id=sample_ids,\n\t                                                                             output_dir=output_dir,\n\t                                                                             genome_info=self.genome)\n\t        __spectre_population_worker.load_files(population_paths)  # Loading files for population mode\n", "        __spectre_population_worker.cnv_call_population()  # Starting the population CNV calculations\n\t# Arguments\n\tdef get_arguments():\n\t    spectre_help = \"\"\"\n\t    vcf_utils <command> [<args>]\n\t    Spectre:\n\t        CNVCaller:\n\t            Required\n\t                --bin-size     Bin/Window size (same as Mosdepth)\n\t                --coverage     Coverage directory from Mosdepth output. Expects the following files:\n", "                                   <prefix>.mosdepth.summary.txt\n\t                                   <prefix>.regions.bed.gz\n\t                                   <prefix>.regions.bed.gz.csi\n\t                               Can be one or more directories. Example:\n\t                                    --coverage /path/dir1/ /path/dir2/\n\t                --sample-id    Sample name/ID. Can be one or more ID. Example:\n\t                                    --sample-id id1 id2\n\t                --output-dir   Output directory\n\t                --reference    Reference sequence used for mapping (for N removal)\n\t            Optional, if missing it will be created\n", "                --metadata     Metadata file for Ns removal\n\t            Optional\n\t                --blacklist    Blacklist in bed format for sites that will be ignored (Default = \"\")\n\t                --only-chr     Comma separated list of chromosomes to use\n\t                --ploidy       Set the ploidy for the analysis, useful for sex chromosomes (Default = 2)\n\t                --snv          VCF file containing the SNV for the same sample CNV want to be called\n\t                --n-size       Length of consecutive Ns (Default = 5)\n\t                --min_cnv_len  Minimum length of CNV (Default 1mb)\n\t                --population   Runs the population mode on all provided samples\n\t                --threads      Amount of threads (This will boost performance if multiple samples are provided)\n", "        removeNs:\n\t            Required\n\t                --reference    Reference genome used for mapping\n\t                --output-dir   Output dir\n\t                --output-file  Output file for results\n\t                --bin-size     Bin/Window size (same as Mosdepth)\n\t            Optional\n\t                --blacklist    Blacklist in bed format for sites that will be ignored (Default = \"\")\n\t                --n-size       Length of consecutive Ns (Default = 5)\n\t                --save-only    Will only save the metadata file and not show the results in screen (Default = False)\n", "        population:\n\t            Required\n\t                --candidates   At least 2 candidate files (.spc or .vcf) which should be taken into consideration for the population mode.\n\t                --sample-id    Name of the output file\n\t                --output-dir   Output directory\n\t            Optional\n\t                --reference    Reference sequence (Required if VCF files are used!)\n\t        Version:\n\t            version    Shows current version/build\n\t    \"\"\"\n", "    parser = argparse.ArgumentParser(\n\t        description=\"Spectre CNV caller\",\n\t        usage=spectre_help\n\t    )\n\t    subparsers = parser.add_subparsers(help=spectre_help, dest=\"command\")\n\t    # ############################################################################################ #\n\t    # Version\n\t    version_help = \"Gives the version number\"\n\t    subparser_version = subparsers.add_parser(\"version\", help=version_help)\n\t    subparser_version.add_argument('-0', '--0', action='store_true', required=False, dest='_0', default=False, help='')\n", "    # ############################################################################################ #\n\t    # CNV caller\n\t    cnv_caller_help = \"...\"\n\t    subparser_cnv_caller = subparsers.add_parser(\"CNVCaller\", help=cnv_caller_help)\n\t    # Required\n\t    subparser_cnv_caller.add_argument('-b', '--bin-size', type=int, required=True, dest='bin_size', default=500,\n\t                                      help='..., default = 1kb')\n\t    subparser_cnv_caller.add_argument('-c', '--coverage', type=str, required=True, dest='coverage_dir', default=\"\",\n\t                                      help='..., default = None', nargs='+')\n\t    subparser_cnv_caller.add_argument('-s', '--sample-id', type=str, required=True, dest='sample_id', default=\"\",\n", "                                      help='..., default = None', nargs='+')\n\t    subparser_cnv_caller.add_argument('-d', '--output-dir', type=str, required=True, dest='output_dir', default=\".\",\n\t                                      help='..., default = None')\n\t    subparser_cnv_caller.add_argument('-r', '--reference', type=str, required=True, dest='reference', default=\"\",\n\t                                      help='..., default = None')\n\t    # Optional, if missing will be created\n\t    subparser_cnv_caller.add_argument('-m', '--metadata', type=str, required=False, dest='metadata', default=\"\",\n\t                                      help='..., default = None')\n\t    # Optional\n\t    subparser_cnv_caller.add_argument('-v', '--snv', type=str, required=False, dest='snv_file', default=\"\",\n", "                                      help='...')\n\t    subparser_cnv_caller.add_argument('-l', '--blacklist', type=str, required=False, dest='black_list_file',\n\t                                      default=\"\",\n\t                                      help='...')\n\t    subparser_cnv_caller.add_argument('-o', '--only-chr', type=str, required=False, dest='only_chr_list', default=\"\",\n\t                                      help='...')\n\t    subparser_cnv_caller.add_argument('-p', '--ploidy', type=int, required=False, dest='ploidy', default=2,\n\t                                      help='..., default = 2')\n\t    subparser_cnv_caller.add_argument('-n', '--n-size', type=int, required=False, dest='n_size', default=5,\n\t                                      help='..., default = 5')\n", "    subparser_cnv_caller.add_argument('-mcl', '--min-cnv-len', type=int, required=False, dest='min_cnv_len', default=1000000,\n\t                                      help='..., default = 1000000')\n\t    subparser_cnv_caller.add_argument('-t', '--threads', type=int, required=False, dest='threads', default=1,\n\t                                      help='..., default = 1')\n\t    subparser_cnv_caller.add_argument('-i', '--population', action='store_true', required=False,\n\t                                      dest='run_population_mode', default=False, help='...s, default = False')\n\t    # Dev\n\t    subparser_cnv_caller.add_argument('-0', '--dev', action='store_true', required=False, dest='as_dev', default=False,\n\t                                      help='dev, default = False')\n\t    subparser_cnv_caller.add_argument('-01', '--dev-max-std-outlier-rm', type=int, required=False,\n", "                                      dest='max_std_outlier_rm', default=5, help='..., default = 5')\n\t    subparser_cnv_caller.add_argument('-02', '--mosdepth-cov-genome-chr-diff', type=float, required=False,\n\t                                      dest='mosdepth_cov_genome_chr_diff', default=0.10, help='..., default = 0.10')\n\t    subparser_cnv_caller.add_argument('-03', '--lower-2n-threshold', type=float, required=False,\n\t                                      dest='lower_2n_threshold', default=1.5, help='..., default = 2.5')\n\t    subparser_cnv_caller.add_argument('-04', '--upper-2n-threshold', type=float, required=False,\n\t                                      dest='upper_2n_threshold', default=2.5, help='..., default = 2.5')\n\t    subparser_cnv_caller.add_argument('-05', '--cov-diff-threshold', type=float, required=False,\n\t                                      dest='cov_diff_threshold', default=0.80, help='..., default = 0.80')\n\t    subparser_cnv_caller.add_argument('-06', '--dist-proportion', type=float, required=False, dest='dist_proportion',\n", "                                      default=0.25, help='..., default = 0.25')\n\t    subparser_cnv_caller.add_argument('-07', '--candidate-final-threshold', type=int, required=False,\n\t                                      dest='candidate_final_threshold', default=100000,\n\t                                      help='..., default = 100,000')  # 100kb\n\t    # ############################################################################################ #\n\t    # Metadata to remove Ns\n\t    metadata_help = \"...\"\n\t    subparser_metadata = subparsers.add_parser(\"removeNs\", help=metadata_help)\n\t    # Required\n\t    subparser_metadata.add_argument('-r', '--reference', type=str, required=True, dest='reference', default=\"\",\n", "                                    help='..., default = None')\n\t    subparser_metadata.add_argument('-d', '--output-dir', type=str, required=True, dest='output_dir', default=\"\",\n\t                                    help='..., default = None')\n\t    subparser_metadata.add_argument('-f', '--output-file', type=str, required=True, dest='metadata', default=\"\",\n\t                                    help='..., default = None')\n\t    subparser_metadata.add_argument('-b', '--bin-size', type=int, required=True, dest='bin_size', default=\"\",\n\t                                    help='..., default = None')\n\t    # Optional\n\t    subparser_metadata.add_argument('-n', '--n-size', type=int, required=False, dest='n_size', default=5,\n\t                                    help='..., default = 5')\n", "    subparser_metadata.add_argument('-s', '--save-only', action='store_true', required=False, dest='save_only',\n\t                                    default=False, help='save_only, default = False')\n\t    subparser_metadata.add_argument('-l', '--blacklist', type=str, required=False, dest='black_list_file', default=\"\",\n\t                                    help='...')\n\t    # Dev\n\t    subparser_metadata.add_argument('-0', '--dev', action='store_true', required=False, dest='as_dev', default=False,\n\t                                    help='dev, default = False')\n\t    # ############################################################################################ #\n\t    # Population mode\n\t    cnv_population_help = \"...\"\n", "    subparser_cnv_population = subparsers.add_parser(\"population\", help=cnv_population_help)\n\t    # Required\n\t    subparser_cnv_population.add_argument('-c', '--candidates', type=str, required=True, dest='population_candidates',\n\t                                          default=\"\", help='..., default = None', nargs='+')\n\t    subparser_cnv_population.add_argument('-s', '--sample-id', type=str, required=True, dest='sample_id', default=\"\",\n\t                                          help='..., default = None')\n\t    subparser_cnv_population.add_argument('-d', '--output-dir', type=str, required=True, dest='output_dir', default=\".\",\n\t                                          help='..., default = None')\n\t    subparser_cnv_population.add_argument('-0', '--dev', action='store_true', required=False, dest='as_dev',\n\t                                          default=False,\n", "                                          help='dev, default = False')\n\t    # Optional\n\t    subparser_cnv_population.add_argument('-r', '--reference', type=str, required=False, dest='reference', default=\"\",\n\t                                          help='..., default = None')\n\t    # ############################################################################################ #\n\t    args = parser.parse_args()\n\t    return args, spectre_help\n\tdef main():\n\t    spectre_args, spectre_help = get_arguments()\n\t    command = spectre_args.command\n", "    try:\n\t        run_as_dev = spectre_args.as_dev\n\t    except AttributeError:\n\t        run_as_dev = False\n\t    # logger init\n\t    logger.basicConfig(\n\t        format='spectre::%(process)d:%(levelname)s> %(message)s', level=logger.DEBUG, force=True) if run_as_dev else \\\n\t        logger.basicConfig(format='spectre::%(levelname)s> %(message)s', level=logger.INFO, force=True)\n\t    logger.debug(f' Debug output is enabled') if run_as_dev else None\n\t    spectre_run = Spectre(run_as_dev)\n", "    min_bin_size = 500\n\t    if command == \"CNVCaller\":\n\t        logger.error(\"Bin size too small\") if spectre_args.bin_size < min_bin_size else \"\"\n\t        # ARGS:  bin_size, coverage_file_bed, sample_id, output_dir, reference=\"\", metadata=\"\", ...\n\t        spectre_run.spectre_args.set_params_from_args(spectre_args)\n\t        spectre_run.spectre_exe()\n\t    elif command == \"removeNs\":\n\t        logger.error(\"Bin size too small\") if spectre_args.bin_size < min_bin_size else \"\"\n\t        # ARGS:  reference_fas, output_dir, meta_data_report, bin_size=500, threshold=5\n\t        metadata_call_from_console = True\n", "        spectre_run.metadata_args.set_params_from_args(spectre_args, metadata_call_from_console)\n\t        spectre_run.meta_data_extraction()\n\t    elif command == \"population\":\n\t        logger.error(\"at least two candidates are required\") if len(spectre_args.population_candidates) < 2 else \"\"\n\t        spectre_run.population_args.set_params_from_args(spectre_args)\n\t        spectre_run.population_exe()\n\t    elif command == \"version\":\n\t        spectre_run.display_version()\n\t    else:\n\t        logger.error(spectre_help)\n", "if __name__ == '__main__':\n\t    main()\n"]}
{"filename": "plots/plot.py", "chunked_list": ["import logging as logger\n\timport matplotlib.pyplot as plot_engine\n\tfrom matplotlib import gridspec\n\timport numpy as np\n\tclass CoveragePlot:\n\t    def __init__(self, as_dev=False):\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        # the plot\n\t        self.figure = plot_engine.figure(figsize=(8, 4))\n", "        gs = gridspec.GridSpec(1, 1)\n\t        self.main_plot = plot_engine.subplot(gs[0])        # colors\n\t        self.coverage_color = \"#67a9cf\"\n\t        # legends\n\t        self.main = \"\"\n\t        self.x_axis = \"\"\n\t        self.y_axis = \"\"\n\t        self.file_prefix = \"test\"\n\t        self.output_directory = \"./\"\n\t    def plot_coverage(self, current_chromosome=\"\", coverage=None):\n", "        self.logger.debug(\"plotting coverage\")\n\t        # main plot\n\t        self.main_plot.plot(np.array(coverage[\"pos\"]), np.array(coverage[\"cov\"]), color=self.coverage_color,\n\t                            linewidth='0.5')\n\t        # save and close\n\t        self.figure.savefig(f'{self.output_directory}/{self.file_prefix}-{current_chromosome}.png', dpi=300)\n\t        self.logger.info(f'Plot saved: {self.file_prefix}-{current_chromosome}.png')\n\t        self.figure.clf()\n\tclass CNVPlot:\n\t    def __init__(self, as_dev=False):\n", "        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        # the plot\n\t        self.figure = plot_engine.figure(figsize=(8, 4))\n\t        gs = gridspec.GridSpec(2, 1, height_ratios=[5, 1])\n\t        self.main_plot = plot_engine.subplot(gs[0])\n\t        self.candidates_plot = plot_engine.subplot(gs[1])\n\t        self.candidates_plot.axes.get_yaxis().set_visible(False)\n\t        # colors\n\t        self.coverage_color = \"#67a9cf\"\n", "        self.cnv_color = {\"DUP\": \"#d73027\", \"DEL\": \"#1a9850\"}\n\t        # legends\n\t        self.main = \"\"\n\t        self.x_axis = \"\"\n\t        self.y_axis = \"\"\n\t        self.axis_ylim = {\"bottom\": 0, \"top\": 6}  # not showing over 6x coverage, min can not be lower than 0\n\t        self.file_prefix = \"test\"\n\t        self.output_directory = \"./\"\n\t    def plot_coverage_cnv(self, current_chromosome=\"\", stats=None, coverage=None, cnv_cand_list=None, bounds=None):\n\t        if stats is None or coverage is None:\n", "            self.logger.error(\"bot parameters are needed\")\n\t        self.logger.debug(\"plotting coverage + CNV\")\n\t        # main plot\n\t        self.main_plot.plot(np.array(coverage[\"pos\"]), np.array(coverage[\"cov\"]), color=self.coverage_color,\n\t                            linewidth='0.5')\n\t        self.main_plot.axes.set_ylim(bottom=self.axis_ylim[\"bottom\"], top=self.axis_ylim[\"top\"])\n\t        start = coverage[\"pos\"][0]\n\t        end = coverage[\"pos\"][-1]\n\t        self.candidates_plot.plot(np.array([start, end]), np.array([0, 0]), linewidth='0', color=\"#ffffff\")\n\t        # add CNV candidates\n", "        self.logger.info(f\"CNVs in chromosome: {current_chromosome}\")\n\t        if cnv_cand_list is not None:\n\t            for cnv in cnv_cand_list:\n\t                start = cnv.start\n\t                end = cnv.end\n\t                cnv_color = self.cnv_color[cnv.type]\n\t                self.candidates_plot.plot(np.array([start, end]), np.array([0, 0]), linewidth='5', color=cnv_color)\n\t        # save and close\n\t        self.main_plot.plot(np.array([1, stats.chromosome_len]), np.array([stats.median, stats.median]),\n\t                            linewidth='1', color=\"#000000\")\n", "        if bounds is not None:\n\t            [upperb, lowerb] = bounds if len(bounds) == 2 else [np.NaN, np.NaN]\n\t            self.main_plot.plot(np.array([1, stats.chromosome_len]), np.array([lowerb, lowerb]),\n\t                                linewidth='1', color=\"#dd3497\")\n\t            self.main_plot.plot(np.array([1, stats.chromosome_len]), np.array([upperb, upperb]),\n\t                                linewidth='1', color=\"#dd3497\")\n\t        self.figure.suptitle(f'{self.file_prefix} chromosome: {current_chromosome}')\n\t        self.figure.savefig(f'{self.output_directory}/plot-coverage-{self.file_prefix}-{current_chromosome}.png', dpi=300)\n\t        self.logger.info(f'Plot saved: plot-coverage-{self.file_prefix}-{current_chromosome}.png')\n\t        self.figure.clf()\n"]}
{"filename": "plots/__init__.py", "chunked_list": []}
{"filename": "util/__init__.py", "chunked_list": []}
{"filename": "util/vcf_parser.py", "chunked_list": ["import pandas as pd\n\timport re\n\timport logging as logger\n\timport os\n\timport pysam\n\timport gzip\n\tfrom analysis.cnv_candidate import CNVCandidate\n\tclass VCFSNVParser(object):\n\t    def __init__(self, min_chromosome_len=1e6, as_dev=False):\n\t        self.as_dev = as_dev\n", "        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        self.min_chromosome_len = min_chromosome_len\n\t    @staticmethod\n\t    def __get_absolute_path(input_path):\n\t        return os.path.abspath(os.path.expanduser(input_path))\n\t    def __create_tabix_file(self, input_path):\n\t        self.logger.info(f\"No index file found - Creating new one at {input_path}.tbi\")\n\t        pysam.tabix_index(input_path, preset=\"bed\", force=True)\n\t    def vcf_pysam(self, path):\n", "        # setup\n\t        vcf_path = self.__get_absolute_path(path)\n\t        vcf_tabix_path = vcf_path + \".tbi\"\n\t        # checking for index file\n\t        if not os.path.isfile(vcf_tabix_path):\n\t            self.__create_tabix_file(vcf_path)\n\t        vcf_file = pysam.VariantFile(vcf_path)  # loading vcf file\n\t        records = vcf_file.fetch()\n\t        for record in records:\n\t            x = record.samples.values()\n", "            print()\n\t        for uid, x in enumerate(vcf_file.fetch()):\n\t            print(x.format.keys())\n\t            af = x.format.values()[4].number\n\t    def vcf_to_dataframe(self, path):\n\t        self.logger.debug(\"Converting vcf to dataframe\")\n\t        vcf_path = self.__get_absolute_path(path)\n\t        # pre allocation\n\t        vcf_entries = list()\n\t        vcf_file = open(vcf_path, \"r\") if \"gz\" not in vcf_path else gzip.open(vcf_path, \"rt\")\n", "        chrom_, start_, quality_, filter_, info_, format_, sample_ = \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n\t        # how AF is described by tool:\n\t        #   clair3   -> AF in FORMAT/SAMPLE\n\t        #   longshot -> AF not present, AC contains the number of reads for REF,ALT: AF=ALT/(REF+ALT)\n\t        #   p-m-deep -> AF not present, VAF in FORMAT/SAMPLE\n\t        #  if in info --- af = float(list(filter(lambda x: \"VAF\" in x, info_.split(\";\")))[0].split(\"=\")[1])\n\t        use_chromosomes = []\n\t        for line in vcf_file:\n\t            line = line.rstrip(\"\\n\")\n\t            # skip header\n", "            if line.startswith(\"#\"):\n\t                if line.__contains__(\"contig\"):\n\t                    # example:  ##contig=<ID=chr1_KI270706v1_random,length=175055>\n\t                    try:\n\t                        chr_id_len = re.search('.*<ID=(.*),length=(.*)>', line)\n\t                        [chr_id, chr_len] = [chr_id_len.group(1), int(chr_id_len.group(2))]\n\t                        if chr_len >= self.min_chromosome_len:\n\t                            use_chromosomes.append(chr_id)\n\t                    except AttributeError:\n\t                        self.logger.debug(line)\n", "            else:\n\t                [chrom_, start_, _, _, _, quality_, filter_, info_, format_, sample_] = line.split(\"\\t\")\n\t                if chrom_ in use_chromosomes:\n\t                    # searching in INFO for AF\n\t                    if format_.__contains__(\"AF\"):\n\t                        # clair3 or pepper-margin-deepvariant\n\t                        try:\n\t                            # clair3\n\t                            format_.split(\":\").index(\"AF\")\n\t                            af_index = format_.split(\":\").index(\"AF\")\n", "                            af = float(sample_.split(\":\")[af_index])\n\t                            # self.logger.debug(\"like clair3\")\n\t                        except ValueError:\n\t                            if format_.__contains__(\"VAF\"):\n\t                                # pepper-margin-deepvariant\n\t                                af_index = format_.split(\":\").index(\"VAF\")\n\t                                af = float(sample_.split(\":\")[af_index])\n\t                                # self.logger.debug(\"like pepper-margin-deepvariant\")\n\t                            else:\n\t                                pass\n", "                    elif info_.__contains__(\"AC\"):\n\t                        # longshot\n\t                        ac = list(filter(lambda x: \"AC\" in x, info_.split(\";\")))[0].split(\"=\")[1]\n\t                        [ref_count, alt_count] = ac.split(\",\")\n\t                        af = float(alt_count) / (float(ref_count) + float(alt_count))\n\t                        # self.logger.debug(\"like longshot\")\n\t                    else:\n\t                        # TODO use: DR/DV for calculating\n\t                        af = \"NA\"\n\t                    vcf_entries.append([chrom_, int(start_), None, af])\n", "        vcf_file.close()\n\t        return pd.DataFrame(data=vcf_entries, columns=[\"chrom_\", \"start_\", \"end_\", \"af_\"])\n\t    def get_mosdepth_chromosome_borders(self, mosdepth_file: str = \"\"):\n\t        in_path = self.__get_absolute_path(mosdepth_file)\n\t        file = pd.read_csv(in_path, sep=\"\\t\", header=None, names=[\"chrom_\", \"start_\", \"end_\", \"af_\"])\n\t        return file\n\t    def dataframe_to_tabular_file(self, df_snv: pd.DataFrame = None, mosdepth_input: str = \"\", out_path: str = \"\"):\n\t        self.logger.debug(\"Writing dataframe to tabular\")\n\t        df_mosdepth = self.get_mosdepth_chromosome_borders(mosdepth_input)\n\t        df_mosdepth_grouped = df_mosdepth.groupby(\"chrom_\")\n", "        df_snps_grouped = df_snv.groupby(\"chrom_\")\n\t        df_final = pd.DataFrame()\n\t        for mosdepth_chrom_key in df_mosdepth_grouped.indices.keys():\n\t            if mosdepth_chrom_key in df_snps_grouped.indices.keys():\n\t                df_mosdepth_chrom = df_mosdepth.loc[df_mosdepth_grouped.indices[mosdepth_chrom_key]]\n\t                bins = list(df_mosdepth_chrom.start_)\n\t                labels = list(df_mosdepth_chrom.start_)[:-1]  # must be len(bins)-1\n\t                df_snps_chrom = df_snv.iloc[df_snps_grouped.indices[mosdepth_chrom_key]]\n\t                df_snps_chrom[\"startbin_\"] = pd.cut(x=df_snps_chrom.start_, bins=bins, labels=labels,\n\t                                                    include_lowest=False)\n", "                df_snps_chrom[\"startbin_af_\"] = df_snps_chrom.groupby(\"startbin_\")[\"af_\"].transform('mean')\n\t                df_snps_chrom.sort_values(by=[\"startbin_\"], inplace=True)\n\t                df_snps_chrom.drop_duplicates(\"startbin_\", inplace=True)\n\t                df_snps_chrom.drop([\"start_\", \"end_\", \"af_\"], axis=1, inplace=True)  # clean\n\t                df_merged = pd.merge(df_mosdepth_chrom, df_snps_chrom,\n\t                                     left_on=[\"chrom_\", \"start_\"],\n\t                                     right_on=[\"chrom_\", \"startbin_\"],\n\t                                     how=\"left\")\n\t                df_merged[\"startbin_\"] = df_merged[\"start_\"] + 1\n\t                df_merged[\"startend_\"] = df_merged[\"end_\"]\n", "                df_merged[\"startbin_af_\"].fillna(value=0, inplace=True)\n\t                df_final = pd.concat([df_final, df_merged[[\"chrom_\", \"startbin_\", \"startend_\", \"startbin_af_\"]]],\n\t                                     ignore_index=True)\n\t                # df_final = pd.concat([df_final,df_snps_chrom],ignore_index=True)\n\t            pass\n\t        df_final.to_csv(out_path, sep=\"\\t\", index=False, header=None)\n\t        return df_final\n\tclass VCFtoCandidate(object):\n\t    def __init__(self):\n\t        pass\n", "    def vcf_to_candidates(self,vcf_path):\n\t        df = self.vcf_ot_dataframe(vcf_path)\n\t        cnv_candidate_list = self.dataframe_to_candidates(df)\n\t        return cnv_candidate_list\n\t    def vcf_ot_dataframe(self, vcf_path: str = ''):\n\t        # Loading VCF file\n\t        vcf_file = open(vcf_path, \"r\") if \"gz\" not in vcf_path else gzip.open(vcf_path, \"rt\")\n\t        lines = [line.strip() for line in vcf_file.readlines()]\n\t        vcf_file.close()\n\t        # Creating dataframe\n", "        df = pd.DataFrame(lines, columns=['input'])\n\t        df = df.input.str.split('\\t', expand=True)\n\t        df = df[~df.iloc[:, 0].str.contains('##')]  # header definitions starting with ##\n\t        df.iloc[0, 0] = df.iloc[0, 0][1:]  # first line is header line of vcf entries removing the # in the first col\n\t        df.columns = df.iloc[0]\n\t        df = df[1:]  # removing first row which is used for the column names\n\t        return df\n\t    def dataframe_to_candidates(self, df: pd.DataFrame):\n\t        cnv_candidate_list = {}\n\t        for cnv in df.itertuples():\n", "            # Parse basics\n\t            candidate = CNVCandidate()\n\t            candidate.chromosome = cnv.CHROM\n\t            candidate.start = int(cnv.POS)\n\t            candidate.id = cnv.ID\n\t            info_dict = {i.split('=')[0]: i.split('=')[1] for i in cnv.INFO.split(';')}\n\t            candidate.end = int(info_dict['END'])\n\t            candidate.cn_status = int(info_dict['CN'])\n\t            candidate.type = info_dict['SVTYPE']\n\t            candidate.size = int(info_dict['SVLEN'])\n", "            population_mode = len(df.columns[9:]) < 2  # TRUE more than 2 samples are present in the VCF\n\t            # Form\n\t            format_set = [i for i in cnv.FORMAT.split(':')]\n\t            for sample_id, sample in zip(list(df.columns[9:]), list(cnv[9 + 1:])):  # +1 due to the index column\n\t                sample_gq = 0\n\t                if not population_mode:  # without special flags it is not possible\n\t                    candidate.sample_origin = sample_id\n\t                sample_cells = sample.split(':')\n\t                if \"GQ\" in format_set:\n\t                    gq_idx = format_set.index('GQ')  # get gene quality score\n", "                    sample_gq = int(sample_cells[gq_idx])\n\t                    candidate.statistics['z-score'] = {}\n\t                    candidate.statistics['z-score']['sample_score'] = sample_gq\n\t                if \"GT\" in format_set:\n\t                    gt_idx = format_set.index('GT')\n\t                    candidate.gt = sample_cells[gt_idx]\n\t                # Could be left black as only details for the known variant are known and loaded from VCF\n\t                if \"ID\" in format_set:\n\t                    id_idx = format_set.index('ID')\n\t                    support_samples = sample_cells[id_idx].split(',')\n", "                    # Get all supporting cnvs from a given sample\n\t                    for support_sample_id in support_samples:\n\t                        # add only not NULL supports\n\t                        if support_sample_id != 'NULL':\n\t                            if sample_id not in candidate.support_cnv_calls.keys():\n\t                                candidate.support_cnv_calls[sample_id] = set()\n\t                            support_candidate = CNVCandidate(sample_id)\n\t                            support_candidate.id = support_sample_id\n\t                            support_candidate.statistics['z-score'] = {}\n\t                            support_candidate.statistics['z-score']['sample_score'] = sample_gq\n", "                            candidate.support_cnv_calls[sample_id].add(support_candidate)\n\t            if cnv.CHROM not in cnv_candidate_list.keys():\n\t                cnv_candidate_list[cnv.CHROM] = []\n\t            cnv_candidate_list[cnv.CHROM].append(candidate)\n\t        return cnv_candidate_list\n"]}
{"filename": "util/OSUtil.py", "chunked_list": ["import os\n\timport gzip\n\tclass OSUtil:\n\t    @classmethod\n\t    def get_absolute_path(cls, relative_user_path) -> str:\n\t        \"\"\"\n\t        Extends a relative path to an absolute user path\n\t        :param relative_user_path: relative path\n\t        :return: absolute user path\n\t        \"\"\"\n", "        return os.path.abspath(os.path.expanduser(relative_user_path))\n\t    @classmethod\n\t    def get_lines_by_chromosome(cls, filepath):\n\t        filepath = cls.get_absolute_path(filepath)\n\t        lines_by_chromosome = {}\n\t        file_handler_read = gzip.open(filepath, \"rt\") if \"gz\" in filepath else open(filepath, \"r\")\n\t        current_chromosome = \"\"\n\t        for line in file_handler_read:\n\t            chromosome = line.rstrip(\"\\n\").split(\"\\t\")[0]\n\t            if current_chromosome == \"\":\n", "                current_chromosome = chromosome\n\t                lines_by_chromosome[chromosome] = 1\n\t            elif current_chromosome != chromosome:\n\t                current_chromosome = chromosome\n\t                lines_by_chromosome[chromosome] = 1\n\t            else:\n\t                lines_by_chromosome[chromosome] += 1\n\t        file_handler_read.close()\n\t        return lines_by_chromosome\n\t    @classmethod\n", "    def get_lines_of_file(cls, filepath):\n\t        filepath = cls.get_absolute_path(filepath)\n\t        file_handler_read = open(filepath, \"r\") if \"gz\" not in filepath else gzip.open(filepath, \"rt\")\n\t        cnt = 0\n\t        for line in file_handler_read:\n\t            cnt += 1\n\t        file_handler_read.close()\n\t        return cnt"]}
{"filename": "util/outputWriter.py", "chunked_list": ["import gzip\n\timport string\n\timport random\n\timport numpy as np\n\timport json\n\tfrom collections import Counter\n\tclass BedOutput(object):\n\t    def __init__(self, output_file):\n\t        self.output_bed = output_file\n\t    def make_bed(self, chromosome_list, cnv_candidate_list):\n", "        file_handler = open(self.output_bed, \"w\")\n\t        for each_chromosome in chromosome_list:\n\t            for each_candidate in cnv_candidate_list[each_chromosome]:\n\t                result_list = [each_candidate.chromosome, str(each_candidate.start), str(each_candidate.end),\n\t                               each_candidate.type, str(each_candidate.size),\n\t                               str(round(each_candidate.median_cov_norm, 2))]\n\t                bed_line = \"\\t\".join(result_list)\n\t                file_handler.write(f'{bed_line}\\n')\n\t        file_handler.close()\n\tclass VCFLine(object):\n", "    def __init__(self):\n\t        self.CHROM = \"\"\n\t        self.POS = 0\n\t        self.ID = \".\"\n\t        self.REF = \"N\"\n\t        self.ALT = \".\"  # DEL/DUP\n\t        self.QUAL = \".\"\n\t        self.FILTER = \".\"\n\t        self.INFO = \".\"\n\t        self.FORMAT = \"GT:HO:GQ\"\n", "        self.format_data = []\n\t        self.sample_format_data = {}\n\t        self.supp_vec = {}\n\t    def format_vcf_line(self):\n\t        sample_format_list = []\n\t        if len(self.format_data) > 0:\n\t            sample_format_list = [\":\".join(self.format_data)]\n\t        for key, value in self.sample_format_data.items():\n\t            sample_format_list.append(\":\".join([str(s) for s in value]))\n\t        return \"\\t\".join([self.CHROM, str(self.POS), self.ID, self.REF, self.ALT, self.QUAL, self.FILTER,\n", "                          self.INFO, self.FORMAT] + sample_format_list)\n\tclass VCFOutput(object):\n\t    def __init__(self, output_file, genome_info):\n\t        self.supp_vec = {}\n\t        self.output_vcf = output_file\n\t        self.population_sample_ids = []\n\t        self.genome_info = genome_info\n\t        # example {'chromosomes': ['chr6'], 'chr_lengths': [170805979], 'chr_lengths_by_name': {'chr6': 170805979}}\n\t    @staticmethod\n\t    def id_generator(size=8, chars=string.ascii_uppercase + string.digits):\n", "        return ''.join(random.choice(chars) for _ in range(size))\n\t    def make_vcf_contigs(self):\n\t        vcf_contigs = []\n\t        for contig_name in self.genome_info[\"chromosomes\"]:\n\t            contig_length = self.genome_info[\"chr_lengths_by_name\"][contig_name]\n\t            vcf_contigs.append(f'##contig=<ID={contig_name},length={contig_length}>')\n\t        return \"\\n\".join(vcf_contigs)\n\t    def make_vcf_header(self):\n\t        population_mode = False\n\t        if self.population_sample_ids:\n", "            if len(self.population_sample_ids) > 1:\n\t                population_mode = True\n\t        contigs = self.make_vcf_contigs()\n\t        vcf_header = ['##fileformat=VCFv4.4', '##FILTER=<ID=PASS,Description=\"All filters passed\">',\n\t                      '##source=Spectre', contigs,\n\t                      '##ALT=<ID=DEL,Description=\"Deletion\">',\n\t                      '##ALT=<ID=DUP,Description=\"Duplications\">',\n\t                      '##FILTER=<ID=UNRESOLVED,Description=\"An insertion that is longer than the '\n\t                      'read and thus we cannot predict the full size.\">'\n\t                      ]\n", "        # Add Info section\n\t        vcf_header += ['##INFO=<ID=END,Number=1,Type=Integer,Description=\"End position of the structural variant\">',\n\t                       '##INFO=<ID=SVLEN,Number=1,Type=Integer,Description=\"Length of the SV\">',\n\t                       '##INFO=<ID=SVTYPE,Number=1,Type=String,Description=\"Type of copy number variant\">',\n\t                       '##INFO=<ID=CN,Number=1,Type=Integer,Description=\"Estimated copy number status\">', ]\n\t        if population_mode:\n\t            vcf_header += ['##INFO=<ID=SUPP_VEC,Number=1,Type=String,Description=\"Support vector\">']\n\t        # Add Format section\n\t        vcf_header += ['##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">',\n\t                       '##FORMAT=<ID=HO,Number=2,Type=Float,Description=\"Homozygosity proportion\">',\n", "                       '##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype quality\">',\n\t                       '##FORMAT=<ID=ID,Number=1,Type=String,Description=\"Population ID of supporting CNV calls\">']\n\t        if self.population_sample_ids:\n\t            if population_mode:\n\t                s = f\"##Spectre_population_samples={','.join(self.population_sample_ids)}\"\n\t            else:\n\t                s = f\"##Spectre_sample={','.join(self.population_sample_ids)}\"\n\t            vcf_header.append(s)\n\t        return \"\\n\".join(vcf_header)\n\t    @staticmethod\n", "    def make_vcf_sample_header(sample_id: list):\n\t        return \"\\t\".join([\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\", \"FORMAT\"] + sample_id)\n\t    @staticmethod\n\t    def set_svtype(candidate_type):\n\t        sv_types = {\"DEL\": \"<DEL>\", \"DUP\": \"<DUP>\"}\n\t        if candidate_type in sv_types:\n\t            return sv_types[candidate_type]\n\t        else:\n\t            return \".\"\n\t    def vcf_result(self, chromosome_list, cnv_candidate_list):\n", "        vcf_lines = []\n\t        for each_chromosome in chromosome_list:\n\t            for each_candidate in cnv_candidate_list[each_chromosome]:\n\t                vcf_line = VCFLine()\n\t                vcf_line.CHROM = each_candidate.chromosome\n\t                vcf_line.POS = each_candidate.start\n\t                vcf_line.ID = each_candidate.id\n\t                vcf_line.ALT = self.set_svtype(each_candidate.type)\n\t                vcf_line.INFO = f\"END={each_candidate.end};SVLEN={each_candidate.size};SVTYPE={each_candidate.type};\" \\\n\t                                f\"CN={each_candidate.cn_status}\"\n", "                # checking if any other CNV through merging supported the given CNV\n\t                vcf_line.supp_vec = self.supp_vec.copy()\n\t                if not each_candidate.support_cnv_calls:\n\t                    vcf_line.format_data = [each_candidate.gt, f'{round(each_candidate.het_score, 2)}',\n\t                                            f\"{int(each_candidate.statistics['z-score']['sample_score'])}\"]\n\t                else:\n\t                    vcf_line.format_data = []\n\t                    vcf_line.FORMAT += \":ID\"  # ADD ID tag in format as everything that is following are IDs\n\t                    vcf_line.supp_vec = dict(\n\t                        [(str(sample_key), 0) for sample_key in each_candidate.support_cnv_calls.keys()])\n", "                    for sample_key, sample_value in each_candidate.support_cnv_calls.items():\n\t                        if sample_value:\n\t                            ids = []\n\t                            scores = []\n\t                            gts = []\n\t                            # sample_id =\"\"\n\t                            for candidate in list(sample_value):\n\t                                ids.append(candidate.id)\n\t                                scores.append(candidate.statistics['z-score']['sample_score'])\n\t                                gts.append(candidate.gt)\n", "                            gt = Counter(gts).most_common(1)[0][0]\n\t                            score = np.mean(scores)\n\t                            vcf_line.sample_format_data[sample_key] = [gt, \"0.0\", int(score), \",\".join(ids)]\n\t                            vcf_line.supp_vec[sample_key] = 1\n\t                        else:\n\t                            vcf_line.sample_format_data[sample_key] = [\"./.\", \"0.0\", 0, \"NULL\"]\n\t                    # add support vector only if population mode is active\n\t                    vcf_line.INFO += \";SUPP_VEC=\" + \"\".join([str(s) for s in vcf_line.supp_vec.values()])\n\t                vcf_lines.append(vcf_line.format_vcf_line())\n\t        return \"\\n\".join(vcf_lines)\n", "    def make_vcf(self, chromosome_list, cnv_candidate_list, sample_id, population_sample_ids=None):\n\t        # converting population sample ids from set to list\n\t        if not population_sample_ids:\n\t            population_sample_ids = [sample_id]\n\t        self.population_sample_ids = list(population_sample_ids)\n\t        self.supp_vec = dict([(i, 0) for i in self.population_sample_ids])\n\t        file_handler = open(self.output_vcf, \"w\") if \"gz\" not in self.output_vcf else gzip.open(self.output_vcf, \"wt\")\n\t        vcf_header = self.make_vcf_header()\n\t        vcf_sample_header = self.make_vcf_sample_header(self.population_sample_ids)\n\t        vcf_lines = self.vcf_result(chromosome_list, cnv_candidate_list)\n", "        file_handler.write(f'{vcf_header}\\n')\n\t        file_handler.write(f'{vcf_sample_header}\\n')\n\t        file_handler.write(f'{vcf_lines}\\n')\n\t        file_handler.close()\n\tclass IntermediateFile(object):\n\t    def __init__(self, output_dir: str):\n\t        self.output_dir = output_dir\n\t    @staticmethod\n\t    def convert_genome_info_to_dictionary(genome_info: dict):\n\t        tmp_genome_inf = dict([(key, []) for key in genome_info.keys()])\n", "        return \"\"\n\t        # for info in genome_info;\n\t    @staticmethod\n\t    def convert_candidates_to_dictionary(candidates: dict):\n\t        tmp_candidates_dict = dict([(key, []) for key in candidates.keys()])\n\t        for key, candidates in candidates.items():\n\t            tmp_candidates = []\n\t            tmp_candidates_dict[key] = tmp_candidates\n\t            for candidate in candidates:\n\t                tmp_dict = dict(candidate.__dict__)\n", "                tmp_dict = {k: v for k, v in tmp_dict.items() if v}\n\t                for key, value in tmp_dict.items():\n\t                    if isinstance(value, set):\n\t                        tmp_dict[key] = list(value)\n\t                tmp_dict.pop('logger')\n\t                tmp_candidates.append(tmp_dict)\n\t        return tmp_candidates_dict\n\t    def write_intermediate_file(self, output_object, filename: str) -> str:\n\t        output_path = f\"{self.output_dir}/{filename}.spc.gz\"\n\t        with gzip.open(output_path, 'wt', encoding='UTF-8') as out_file:\n", "            json.dump(output_object, out_file, indent=\"\\t\")\n\t        return output_path\n"]}
{"filename": "util/mosdepthReader.py", "chunked_list": ["import gzip\n\timport numpy as np\n\tclass MosdepthSummary(object):\n\t    def __init__(self):\n\t        self.chromosomes = []\n\t        self.chr_mean_coverage = {}\n\t        self.genome_mean_coverage = None\n\t        self.genome_bases = None\n\t    def add_chromosome(self, new_chr):\n\t        self.chromosomes.append(new_chr)\n", "    def add_coverage(self, new_chr, new_cov):\n\t        self.chr_mean_coverage[new_chr] = float(new_cov)\n\t    def add_genome_summary(self, genome_mean_coverage, genome_bases):\n\t        self.genome_mean_coverage = float(genome_mean_coverage)\n\t        self.genome_bases = int(genome_bases)\n\t    def update_genome_mean(self):\n\t        self.genome_mean_coverage = np.mean([value for index, value in self.chr_mean_coverage.items()])\n\tclass MosdepthReader(object):\n\t    def __init__(self, coverage_file, summary_file):\n\t        self.coverage_file = coverage_file\n", "        self.summary_file = summary_file\n\t        self.mosdepth_summary_data = MosdepthSummary()\n\t        self.min_chr_lengh = 1e6  # 1mb to remove alts\n\t    def summary_data(self):\n\t        found_total_flag = False\n\t        summary_file_handler = open(self.summary_file, \"r\") if \"gz\" not in self.summary_file \\\n\t            else gzip.open(self.summary_file, \"rt\")\n\t        for line in summary_file_handler:\n\t            # skip header\n\t            if \"chrom\" not in line:\n", "                if \"_region\" not in line:\n\t                    # chrom  length  bases  mean  min  max\n\t                    [chromosome, chr_length, bases, mean_cov, _, _] = line.rstrip(\"\\n\").split(\"\\t\")\n\t                    if float(chr_length) > self.min_chr_lengh:\n\t                        if chromosome == \"total\":\n\t                            self.mosdepth_summary_data.add_genome_summary(mean_cov, bases)\n\t                            found_total_flag = True\n\t                        else:\n\t                            self.mosdepth_summary_data.add_chromosome(chromosome)\n\t                            self.mosdepth_summary_data.add_coverage(chromosome, mean_cov)\n", "        if not found_total_flag:\n\t            self.mosdepth_summary_data.update_genome_mean()\n\t        summary_file_handler.close()\n"]}
{"filename": "util/dataAnalyzer.py", "chunked_list": ["import numpy as np\n\tclass NormaldataAnalyser:\n\t    @classmethod\n\t    def get_candidate_statistics(cls, normalized_candidates) -> tuple:\n\t        \"\"\"\n\t        :param normalized_candidates:\n\t        :return:\n\t        \"\"\"\n\t        min_val = np.nanmin(normalized_candidates)\n\t        max_val = np.nanmax(normalized_candidates)\n", "        avg = np.nanmean(normalized_candidates)\n\t        std = np.nanstd(normalized_candidates)\n\t        med = np.nanmedian(normalized_candidates)\n\t        return avg, std, min_val, max_val, med\n\t    @classmethod\n\t    def normalize_candidates(cls, candidates: np.array(list), use_value: float) -> np.array(list):\n\t        \"\"\"\n\t        Normalizes an i\n\t        :param candidates:\n\t        :param use_value: can be median or mean\n", "        :return:\n\t        \"\"\"\n\t        # return candidates/use_value\n\t        return candidates/use_value  # the median will be CN2, we derive the rest from them\n\t    @classmethod\n\t    def get_slope(cls, n:int, normalized_candidates: np.array(list)) -> np.array(list):\n\t        x = np.array(range(0, n))\n\t        y = np.array(list)\n\t        slope_array = np.zeros(normalized_candidates.size)\n\t        l = 0\n", "        slope = 0\n\t        for i in range(0,normalized_candidates.size,1):\n\t            if float(normalized_candidates[i]) != 0:\n\t                l = i - n\n\t                if i > n:\n\t                    y = normalized_candidates[l:i].astype(np.float)\n\t                    slope = cls.get_slope_from_values(x,y)\n\t                else:\n\t                    slope = 0\n\t                slope_array[i] = float(slope)\n", "        return slope_array\n\t    @classmethod\n\t    def get_slope_from_values(cls, x, y) -> float:\n\t        \"\"\"\n\t        Calculates the slope of the regression of the given x and y values.\n\t        :param x: Numpy array with walues in the X-axis\n\t        :param y: Numpy array with values in the Y-axis\n\t        :return: float of the slope value.\n\t        \"\"\"\n\t        return ((x*y).mean(axis=0) - x.mean()*y.mean(axis=0)) / ((x**2).mean() - (x.mean())**2)\n"]}
{"filename": "util/cnv_id.py", "chunked_list": ["import random\n\timport string\n\tclass CNV_ID(object):\n\t    def id_generator(self, size=8, chars=string.ascii_uppercase + string.digits):\n\t        \"\"\"\n\t        Generates a random ID\n\t        :param size: size of the ID\n\t        :param chars: vocabulary (default only upper case chars)\n\t        :return: random generated id with given size\n\t        \"\"\"\n", "        return ''.join(random.choice(chars) for _ in range(size))\n\t    @classmethod\n\t    def n_id_generator(cls, n=1, existing_ids=None, size=8, chars=string.ascii_uppercase + string.digits):\n\t        \"\"\"\n\t        Generates n amounts of unique ids with given size\n\t        :param n: amount of new unique ids\n\t        :param existing_ids: list of already existing ids\n\t        :param size:  sie of the ID\n\t        :param chars: vocabulary (default only upper case chars)\n\t        :return: list of random generated id with given size\n", "        \"\"\"\n\t        new_ids = []\n\t        if existing_ids is None:\n\t            existing_ids = []\n\t        for i in range(0, n):\n\t            while True:\n\t                id = cls.id_generator(n, size, chars)\n\t                if id not in existing_ids:\n\t                    new_ids.append(id)\n\t                    existing_ids.append(id)\n", "                    break\n\t        return new_ids\n"]}
{"filename": "util/metadata/metadataCollector.py", "chunked_list": ["import mmap\n\timport os\n\timport gzip\n\timport logging as logger\n\tclass FastaRef:\n\t    def __init__(self, as_dev=False):\n\t        # logger\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        # ... TODO\n", "        self.__nList = list()\n\t        self.__nFrom = 0\n\t        self.__nTo = 0\n\t        self.__gCnt = 0\n\t        self.__cCnt = 0\n\t        self.__aCnt = 0\n\t        self.__tCnt = 0\n\t        # report\n\t        self.static_report = \"\"\n\t    def get_n_regions(self, filepath, report_output_dir, out_file_name, threshold=5, bin_size=500,\n", "                      save_only=False) -> dict:\n\t        ref_dict = dict()\n\t        i = 0\n\t        j = 0\n\t        g_cnt = 0\n\t        c_cnt = 0\n\t        a_cnt = 0\n\t        t_cnt = 0\n\t        chromosome_cnt = 0\n\t        chromosome = \"\"\n", "        # assure abs paths\n\t        path = os.path.abspath(os.path.expanduser(filepath))\n\t        report_output_dir = os.path.abspath(os.path.expanduser(report_output_dir))\n\t        file_handler_fasta = open(path, \"r\") if \"gz\" not in path else gzip.open(path, \"rt\")\n\t        for line in file_handler_fasta:\n\t            term = line.rstrip(\"\\n\")  # cut away the newline from line (\\n)\n\t            # check if line is not a comment or header\n\t            if not (term[:1] == '>' or term[:1] == ';'):\n\t                for t in term:\n\t                    c = t.upper()\n", "                    if c == \"N\":\n\t                        j += 1\n\t                    else:\n\t                        if (j - i) >= threshold:\n\t                            start = i + 1\n\t                            end = j - 1\n\t                            # check if values are not on mod binSize = 0 position\n\t                            if (start % bin_size) != 0:\n\t                                start = start - (start % bin_size)\n\t                            if (end % bin_size) != 0:\n", "                                end = end + (bin_size - (end % bin_size))\n\t                            ref_dict[str(chromosome)].append((start, end))\n\t                        i = j\n\t                        j += 1\n\t                        # grab bp for gc statistic\n\t                        if c == \"G\":\n\t                            g_cnt += 1\n\t                        elif c == \"C\":\n\t                            c_cnt += 1\n\t                        elif c == \"A\":\n", "                            a_cnt += 1\n\t                        elif c == \"T\":\n\t                            t_cnt += 1\n\t                    chromosome_cnt += 1\n\t            else:\n\t                # allocate space in dict for current chromosome\n\t                if chromosome != \"\":\n\t                    # pre-print before new chrom is select\n\t                    self.logger.info(f'length: {str(chromosome_cnt)}\\t{ref_dict[str(chromosome)]}')\n\t                chromosome = str(term[1:]).split(\" \")[0]\n", "                ref_dict[str(chromosome)] = list()\n\t                self.logger.info(f'Reading {term}')\n\t                i = 0\n\t                j = 0\n\t                chromosome_cnt = 0\n\t        self.__nList = ref_dict\n\t        self.__nTo = j\n\t        self.__cCnt = c_cnt\n\t        self.__gCnt = g_cnt\n\t        self.__aCnt = a_cnt\n", "        self.__tCnt = t_cnt\n\t        self.__get_statistic_report(report_output_dir, out_file_name)\n\t        if not save_only:\n\t            return ref_dict\n\t        return {}\n\t    def __get_statistic_report(self, output_dir, filename):\n\t        # static_report is a long string of text\n\t        self.static_report = \"#####\\tStatistic report\\n\"\n\t        # gc coverage\n\t        self.logger.info(\"Calculating bp statistics\")\n", "        self.static_report += \"#####\\tBasepair statistic\\n\"\n\t        self.static_report += \"BPDEF\\tA\\tT\\tC\\tG\\tGC%\\tTotal bp\\n\"\n\t        self.static_report += \"BPSTA\\t\" + str(self.__aCnt) + \"\\t\" + str(self.__tCnt) + \"\\t\" + str(self.__cCnt) + \\\n\t                              \"\\t\" + str(self.__gCnt) + \"\\t\" + str((self.__gCnt + self.__cCnt) / self.__nTo * 100) + \\\n\t                              \"\\t\" + str(self.__nTo) + \"\\n\"\n\t        # positions of n in sequence\n\t        self.logger.info(\"Calculating N positions\")\n\t        self.static_report += \"#####\\tN-Sequence positions in given reference file\\n\"\n\t        self.static_report += \"NSDEF\\tFrom\\tTo\\n\"\n\t        for chromosome in self.__nList:\n", "            for start, end in self.__nList[chromosome]:\n\t                self.static_report += \"NSPOS\\t\" + str(chromosome) + \"\\t\" + str(start) + \"\\t\" + str(end) + \"\\n\"\n\t        # write statistic report to file\n\t        self.logger.info(\"Writing report\")\n\t        self.__write_report(output_dir, filename)\n\t    @classmethod\n\t    def extract_n_regions_from_report(cls, input_file: str) -> dict:\n\t        \"\"\"\n\t        Loads all N regions that previously have been extracted from the reference genome and stored in a .mdr file\n\t        :param input_file: /path/to/<file_name>.mdr\n", "        :return: dict with all N regions according to the chromosome\n\t        \"\"\"\n\t        result = dict()\n\t        # assure abs paths\n\t        path = os.path.abspath(os.path.expanduser(input_file))\n\t        with open(path, \"r\") as fp:\n\t            # map file into memory\n\t            mm = mmap.mmap(fp.fileno(), 0, prot=mmap.PROT_READ)\n\t            for line in iter(mm.readline, b\"\"):\n\t                # decode line and cut away last char from line (\\n)\n", "                term = line.decode(\"utf-8\")[:-1]\n\t                if term[:5].__eq__(\"NSPOS\"):\n\t                    cells = term.strip().split(\"\\t\")\n\t                    if str(cells[1]) not in result:  # [1] = chromosome name\n\t                        result[str(cells[1])] = []\n\t                    result[str(cells[1])].append((cells[2], cells[3]))  # [2] start, [3] end\n\t        return result\n\t    @classmethod\n\t    def extract_blacklisted_regions(cls, input_file: str) -> dict:\n\t        result = dict()\n", "        path = os.path.abspath(os.path.expanduser(input_file))\n\t        with open(path, \"r\") as fp:\n\t            mm = mmap.mmap(fp.fileno(), 0, prot=mmap.PROT_READ)\n\t            for line in iter(mm.readline, b\"\"):\n\t                # decode line and cut away last char from line (\\n)\n\t                term = line.decode(\"utf-8\")[:-1]\n\t                chrom, start, end = term.split(\"\\t\")[:3]\n\t                if str(chrom) not in result:\n\t                    result[str(chrom)] = []\n\t                result[str(chrom)].append((start,end))\n", "        return result\n\t    @classmethod\n\t    def merge_metadata(cls, m1:dict, m2:dict)->dict:\n\t        \"\"\"\n\t        Merges two dictionaries with the structure str:list\n\t        :param m1: dict m1 with structure str:list\n\t        :param m2: dict m2 with structure str:list\n\t        :return: merged dict with structure str:list\n\t        \"\"\"\n\t        result = m1.copy()\n", "        for key2 in m2.keys():\n\t            # check if key in results\n\t            if key2 in result:\n\t                # check if values are in it\n\t                for value2 in m2[key2]:\n\t                    # add if value2 not in result\n\t                    if value2 not in result[key2]:\n\t                        result[key2].append(value2)\n\t            else:\n\t                # if not in results -> add whole d2[key2] into it\n", "                result[key2] = m2[key2]\n\t        return result\n\t    def __write_report(self, output_dir, filename):\n\t        self.logger.info(output_dir)\n\t        if not os.path.exists(output_dir):\n\t            os.makedirs(output_dir)\n\t        with open(os.path.join(output_dir, filename), \"w\") as file:\n\t            file.writelines(self.static_report)\n"]}
{"filename": "util/metadata/__init__.py", "chunked_list": []}
{"filename": "analysis/call_cnv_coverage.py", "chunked_list": ["import numpy as np\n\tfrom analysis.cnv_candidate import CNVCandidate\n\timport pandas as pd\n\timport logging as logger\n\tclass CNVCall(object):\n\t    def __init__(self, as_dev=False):\n\t        self.as_dev = as_dev\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t    def cnv_coverage(self, chromosome_coverage_data, bin_size, chromosome_name, sample_origin=\"\",\n", "                     lower_bound: float = None,\n\t                     upper_bound: float = None):\n\t        # get chromosome_coverage_data (\"self.genome_analysis\"), for each chromosome, \"cov_data:\n\t        # * .position: list size n\n\t        #   .coverage_raw = np.NaN\n\t        #   .positions = np.NaN\n\t        #   .coverage_log2 = np.NaN         # log2(x)\n\t        #   .normalized_cov = np.NaN        # x/median\n\t        # * .normalized_cov_ploidy = np.NaN   # x/median * 2 -> for diploid\n\t        candidate_list = []\n", "        # local\n\t        min_run = 10\n\t        run = 0\n\t        cnv_pos_cand_list = []\n\t        cnv_cov_cand_list = []\n\t        run_current_pos = 0\n\t        run_start = 0\n\t        cnv_type = \"\"\n\t        current_cnv_type = \"\"\n\t        # lower_bound, upper_bound = 1.5, 2.5  # values outside the CN2\n", "        if not isinstance(chromosome_coverage_data.normalized_cov_ploidy, np.ndarray) or \\\n\t                not isinstance(chromosome_coverage_data.positions, np.ndarray):\n\t            self.logger.debug(type(chromosome_coverage_data.normalized_cov_ploidy))\n\t            self.logger.debug(type(chromosome_coverage_data.positions))\n\t            self.logger.error(f'No data is available, check that the mosdepth.region.bed.gz file is not empty '\n\t                              f'or that the selected chromosome (--only-chr <CHR>) exists')\n\t        for (cov, pos) in zip(chromosome_coverage_data.normalized_cov_ploidy, chromosome_coverage_data.positions):\n\t            # start/continue run\n\t            if not np.isnan(cov):\n\t                # Determine CNV Type\n", "                if cov > upper_bound or cov < lower_bound:\n\t                    cnv_type = \"DUP\" if cov > upper_bound else \"DEL\"\n\t                    # start run\n\t                    if run_start == 0:\n\t                        current_cnv_type = cnv_type\n\t                        run_start = pos\n\t                    else:\n\t                        # continue run if not in the chromosome end\n\t                        if pos - run_current_pos < bin_size + 1 and current_cnv_type == cnv_type:\n\t                            run += 1\n", "                            cnv_pos_cand_list.append(pos)\n\t                            cnv_cov_cand_list.append(cov)\n\t                        # break run end of chromosome\n\t                        else:\n\t                            if len(cnv_pos_cand_list) > 1:\n\t                                cnv_candidates = CNVCandidate(sample_origin, self.as_dev)\n\t                                cnv_candidates.push_candidates(chromosome_name, cnv_pos_cand_list, cnv_cov_cand_list,\n\t                                                               current_cnv_type)\n\t                                if len(cnv_pos_cand_list) >= min_run:\n\t                                    candidate_list.append(cnv_candidates)\n", "                            # restart run\n\t                            run = 1\n\t                            cnv_pos_cand_list = [pos]\n\t                            cnv_cov_cand_list = [cov]\n\t                            run_start = pos\n\t                            current_cnv_type = cnv_type\n\t                # break run\n\t                else:\n\t                    if len(cnv_pos_cand_list) > 1:\n\t                        cnv_candidates = CNVCandidate(sample_origin, self.as_dev)\n", "                        cnv_candidates.push_candidates(chromosome_name, cnv_pos_cand_list, cnv_cov_cand_list,\n\t                                                       current_cnv_type)\n\t                        if len(cnv_pos_cand_list) >= min_run:\n\t                            candidate_list.append(cnv_candidates)\n\t                    # restart run\n\t                    run = 1\n\t                    cnv_pos_cand_list = []\n\t                    cnv_cov_cand_list = []\n\t                    run_start = pos\n\t                    current_cnv_type = \"\"\n", "                run_current_pos = pos\n\t        return candidate_list\n"]}
{"filename": "analysis/analysis.py", "chunked_list": ["import os\n\timport gzip\n\timport pysam\n\timport numpy as np\n\timport pandas as pd\n\timport logging as logger\n\timport util.outputWriter\n\timport util.vcf_parser as vcf\n\tfrom util.OSUtil import OSUtil as OSUt\n\tfrom util.dataAnalyzer import NormaldataAnalyser as NorAn\n", "from util.cnv_id import CNV_ID\n\tfrom plots.plot import CNVPlot\n\tfrom plots.plot import CoveragePlot\n\tfrom analysis.coverage_stats import CoverageStatistics\n\tfrom analysis.coverage_stats import CoverageData\n\tfrom analysis.call_cnv_coverage import CNVCall\n\tfrom analysis.call_cnv_AF import CNVCall as CNVAnalysisSNP\n\tfrom analysis.cnv_metrics import CNVMetrics\n\tclass CNVAnalysis(object):\n\t    def __init__(self, coverage_file, coverage_mosdepth_data, bin_size, output_directory, outbed, outvcf, genome_info,\n", "                 sample_id, metadata_ref, snv_file, only_chr_list=\"\", ploidy=2,min_cnv_len=1000000, as_dev=False,\n\t                 dev_params=None, debug_dir=\"\"):\n\t        # input\n\t        self.coverage_file = coverage_file\n\t        self.mosdepth_data = coverage_mosdepth_data  # has chr_mean_coverage, genome_mean_coverage, genome_bases\n\t        self.output_directory = output_directory\n\t        self.output_bed = outbed\n\t        self.output_vcf = outvcf\n\t        self.sample_id = sample_id\n\t        self.snv_file = snv_file\n", "        self.population_sample_ids = set()  # hold the filename of the population samples\n\t        # bin size !important\n\t        self.bin_size = int(bin_size)\n\t        self.genome_info = genome_info\n\t        self.metadata = metadata_ref\n\t        # whitelist, only this chr\n\t        self.only_chr_list = str(only_chr_list).split(\",\") if only_chr_list != \"\" else genome_info[\"chromosomes\"]\n\t        self.ploidy = ploidy\n\t        # logger\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n", "        self.logger = logger\n\t        # work variables\n\t        self.positions = np.zeros(0)\n\t        self.coverage = np.zeros(0)\n\t        self.coverage_log2 = np.zeros(0)\n\t        # results by chromosome\n\t        self.genome_analysis = {}  # use this for CNV call NOTE: here is the coverage data under \"cov_data\"\n\t        self.cnv_calls_list = {}  # use this for CNV call\n\t        self.raw_cnv_calls_list = {}  # use this for storing raw CNV call\n\t        self.intermediate_candidates_file_location = \"\"  # holds output path of serialized cnv object\n", "        self.cnv_merged = {}  # use this for CNV call\n\t        self.existing_cnv_ids = []  # holds all already used cnv IDs\n\t        # snv data\n\t        self.snv_af_bed = \"\"\n\t        self.snv_af_df = None\n\t        # dev/debug + hidden params\n\t        self.as_dev = as_dev\n\t        self.debug_dir = debug_dir\n\t        # cnv metrics\n\t        self.cnv_metrics = None\n", "        # TODO\n\t        self.min_chr_length = 1e6\n\t        self.max_std_outlier_rm = 5\n\t        self.mosdepth_cov_genome_chr_diff = 0.10  # 10%\n\t        self.lower_2n_threshold = 0.0  # are overwritten after data_normalization was called\n\t        self.upper_2n_threshold = 0.0  # are overwritten after data_normalization was called\n\t        self.cov_diff_threshold = 0.80\n\t        self.dist_proportion = 0.25\n\t        self.dist_min_overwrite = 10000  # 10kb\n\t        self.candidate_final_threshold = min_cnv_len #100000  # 100kb\n", "    # Data normalization\n\t    def data_normalization(self):\n\t        \"\"\"\n\t        Normalize single chromosome bins\n\t        \"\"\"\n\t        self.logger.debug(self.coverage_file)\n\t        file_size_lines = OSUt.get_lines_by_chromosome(self.coverage_file)\n\t        if len(file_size_lines) == 0:\n\t            self.logger.error(\"Empty file\")\n\t        coverage_full_path = os.path.abspath(os.path.expanduser(self.coverage_file))\n", "        coverage_file_handler = gzip.open(coverage_full_path, \"rt\") if \"gz\" in self.coverage_file \\\n\t            else open(coverage_full_path, \"r\")\n\t        list_index = 0\n\t        previous_chromosome = \"\"\n\t        for line in coverage_file_handler:\n\t            [chromosome, start, _, coverage] = line.rstrip(\"\\n\").split(\"\\t\")\n\t            if chromosome in self.only_chr_list:\n\t                start = int(start)\n\t                coverage = float(coverage)\n\t                if previous_chromosome == \"\":\n", "                    # init\n\t                    self.positions = np.zeros(file_size_lines[chromosome])\n\t                    self.coverage = np.zeros(file_size_lines[chromosome])\n\t                    self.coverage_log2 = np.zeros(file_size_lines[chromosome])\n\t                    list_index = 0\n\t                    previous_chromosome = chromosome\n\t                    # first elem\n\t                    self.positions[list_index] = start\n\t                    self.coverage[list_index] = coverage\n\t                    self.coverage_log2[list_index] = np.log2(coverage) if coverage != 0 else np.NaN  # use np.nanFUN\n", "                    list_index += 1\n\t                elif previous_chromosome != chromosome:\n\t                    # analysis here\n\t                    self.logger.debug(previous_chromosome)\n\t                    self.__remove_n_region_by_chromosome(previous_chromosome)\n\t                    cov_stats, norm_stats, cov_data = self.__normalization_and_statistics(previous_chromosome)\n\t                    self.genome_analysis[previous_chromosome] = {\"cov_data\": cov_data,\n\t                                                                 \"statistics\": cov_stats,\n\t                                                                 \"norm_statistics\": norm_stats}\n\t                    # init new chromosome\n", "                    self.positions = np.zeros(file_size_lines[chromosome])\n\t                    self.coverage = np.zeros(file_size_lines[chromosome])\n\t                    self.coverage_log2 = np.zeros(file_size_lines[chromosome])\n\t                    list_index = 0\n\t                    previous_chromosome = chromosome\n\t                    # first elem\n\t                    self.positions[list_index] = start\n\t                    self.coverage[list_index] = coverage\n\t                    self.coverage_log2[list_index] = np.log2(coverage) if coverage != 0 else np.NaN  # use np.nanFUN\n\t                    list_index += 1\n", "                else:\n\t                    self.positions[list_index] = start\n\t                    self.coverage[list_index] = coverage\n\t                    self.coverage_log2[list_index] = np.log2(coverage) if coverage != 0 else np.NaN  # use np.nanFUN\n\t                    list_index += 1\n\t        coverage_file_handler.close()\n\t        # compute leftover chromosome\n\t        self.__remove_n_region_by_chromosome(previous_chromosome)\n\t        cov_stats, norm_stats, cov_data = self.__normalization_and_statistics(previous_chromosome)\n\t        self.genome_analysis[previous_chromosome] = {\"cov_data\": cov_data,\n", "                                                     \"statistics\": cov_stats,\n\t                                                     \"norm_statistics\": norm_stats}\n\t        # setup, calculating border for deletion and duplications\n\t        self.cnv_metrics = CNVMetrics(genome_analysis=self.genome_analysis,\n\t                                      cnv_calls=self.cnv_calls_list,\n\t                                      exclusion_zones=self.metadata,\n\t                                      hashname=self.sample_id,\n\t                                      ploidy=self.ploidy,\n\t                                      output_dir=self.output_directory,\n\t                                      as_dev=self.as_dev, debug_dir=self.debug_dir)\n", "        # self.cnv_metrics.get_del_dup_borders()\n\t        self.lower_2n_threshold = self.cnv_metrics.del_border\n\t        self.upper_2n_threshold = self.cnv_metrics.dup_border\n\t        # clean up\n\t        self.positions = np.zeros(0)\n\t        self.coverage = np.zeros(0)\n\t        self.coverage_log2 = np.zeros(0)\n\t    def __normalization_and_statistics(self, chromosome) -> tuple:\n\t        self.logger.info(f'Number positions to be tested on chromosome {chromosome}: {self.coverage.size}')\n\t        # clean up\n", "        cov_stats = CoverageStatistics()\n\t        norm_stats = CoverageStatistics()\n\t        cov_data = CoverageData()\n\t        cov_data.normalized_cov = np.array(0)\n\t        if self.coverage.size > 0:\n\t            # calculate avg, std, median and remove outliers (right tail)\n\t            # use genome-wide average\n\t            # NOTE: select average coverage from genome-wide or chromosome depending on how different they are\n\t            genome_avg_cov = self.mosdepth_data.genome_mean_coverage\n\t            chromosome_avg_coverage = np.nanmean(self.coverage)\n", "            diff_genome_chr_coverage = abs(\n\t                genome_avg_cov - chromosome_avg_coverage) < genome_avg_cov * self.mosdepth_cov_genome_chr_diff\n\t            use_this_avg_cov = genome_avg_cov if diff_genome_chr_coverage else chromosome_avg_coverage\n\t            [avg, std] = [float(use_this_avg_cov), np.nanstd(self.coverage)]\n\t            for idx in range(0, self.coverage.size, 1):\n\t                cov = self.coverage[idx]\n\t                if cov > avg + (self.max_std_outlier_rm * std):\n\t                    self.coverage[idx] = np.NaN\n\t            # re-calculate avg, std, median without outliers (right tail)\n\t            chromosome_avg_coverage = np.nanmean(self.coverage)\n", "            use_this_avg_cov = genome_avg_cov  # if diff_genome_chr_coverage else chromosome_avg_coverage\n\t            [avg, std, med] = [float(use_this_avg_cov), np.nanstd(self.coverage), np.nanmedian(self.coverage)]\n\t            self.logger.debug([f'avg: {genome_avg_cov}|{chromosome_avg_coverage}, std: {std}, med: {med}'])\n\t            if chromosome in self.genome_info[\"chr_lengths_by_name\"]:\n\t                # data\n\t                cov_data.positions = self.positions\n\t                cov_data.coverage_raw = self.coverage\n\t                cov_data.coverage_log2 = self.coverage_log2\n\t                # stats\n\t                cov_stats.chromosome_len = self.genome_info[\"chr_lengths_by_name\"][chromosome]\n", "                cov_stats.chromosome_name = chromosome\n\t                cov_stats.average = avg\n\t                cov_stats.std_dev = std\n\t                cov_stats.median = med\n\t                cov_stats.min = np.nanmin(self.coverage)\n\t                cov_stats.max = np.nanmax(self.coverage)\n\t                # normalization, based on diploid organisms\n\t                normalize_by = med  # med:median | avg:average\n\t                normalized_candidates = NorAn.normalize_candidates(self.coverage, normalize_by)\n\t                normalized_candidates_ploidy = normalized_candidates * self.ploidy\n", "                if len(normalized_candidates) < 1:\n\t                    normalized_candidates_ploidy = normalized_candidates\n\t                # statistics for normalized bin\n\t                avg, std, min_val, max_val, med = NorAn.get_candidate_statistics(normalized_candidates)\n\t                norm_stats.chromosome_len = self.genome_info[\"chr_lengths_by_name\"][chromosome]\n\t                norm_stats.chromosome_name = chromosome\n\t                norm_stats.median = med\n\t                norm_stats.average = avg\n\t                norm_stats.std_dev = std\n\t                norm_stats.min = min_val\n", "                norm_stats.max = max_val\n\t                # norm data\n\t                cov_data.normalized_cov = normalized_candidates\n\t                cov_data.normalized_cov_ploidy = normalized_candidates_ploidy\n\t            else:\n\t                self.logger.warning(f\"Chromosome:{chromosome} not found in gene info!\")\n\t        return cov_stats, norm_stats, cov_data\n\t    def __remove_n_region_by_chromosome(self, chrom) -> None:\n\t        \"\"\"\n\t        Compare CNV candidates with \"N\" regions from the reference genome. If the candidate starts or ends inside a\n", "        \"N\" region, the candidate will is removed by assigning a np.nan value.\n\t        :param chrom: current chromosome\n\t        :return: None\n\t        \"\"\"\n\t        # we use two variables which contain all the current chromosome info\n\t        # self.positions\n\t        # self.coverage\n\t        if chrom in self.metadata:\n\t            for meta_start, meta_end in self.metadata[chrom]:\n\t                meta_start = int(meta_start)\n", "                meta_end = int(meta_end)\n\t                overlap_n = np.logical_and(self.positions >= meta_start, self.positions <= meta_end)\n\t                self.coverage[overlap_n] = np.nan\n\t    # *** MAIN ***\n\t    def call_cnv_coverage(self, cnv_id_list=None, write_csv=False):\n\t        if cnv_id_list is None:\n\t            cnv_id_list = []\n\t        # unique CNV IDs\n\t        for each_chromosome in self.genome_analysis.keys():\n\t            # global\n", "            # Section 1: Generating raw CNV candidates\n\t            self.logger.info(f\"Calculating CNVs for {self.sample_id} @ chromosome {each_chromosome}\")\n\t            cnv_caller = CNVCall(self.as_dev)\n\t            candidates_cnv_list = cnv_caller.cnv_coverage(self.genome_analysis[each_chromosome][\"cov_data\"],\n\t                                                          self.bin_size, each_chromosome, self.sample_id,\n\t                                                          self.cnv_metrics.del_border, self.cnv_metrics.dup_border)\n\t            # Generating CNV IDs\n\t            new_ids = CNV_ID.n_id_generator(len(candidates_cnv_list), cnv_id_list)\n\t            self.existing_cnv_ids = self.existing_cnv_ids + new_ids\n\t            for candidate, id in zip(candidates_cnv_list, new_ids):\n", "                candidate.set_id(id)\n\t            # save candidates for each chromosome\n\t            self.cnv_calls_list[each_chromosome] = candidates_cnv_list\n\t        self.raw_cnv_calls_list = self.cnv_calls_list.copy()\n\t    def refine_cnv_calls(self, write_csv=False):\n\t        self.logger.info(\"refining cnv calls\")\n\t        for each_chromosome in self.genome_analysis.keys():\n\t            candidates_cnv_list = self.cnv_calls_list[each_chromosome]\n\t            if write_csv:\n\t                self.dev_write_csv(each_chromosome)\n", "            self.logger.debug(f'total cnv candidates in {each_chromosome}: {len(candidates_cnv_list)} before merge')\n\t            final_cnv_candidates = self.merge_candidates(candidates_cnv_list, each_chromosome)\n\t            cnv_call_list = self.scaffold_candidates(final_cnv_candidates, each_chromosome) \\\n\t                if len(final_cnv_candidates) >= 2 else final_cnv_candidates\n\t            self.cnv_calls_list[each_chromosome] = cnv_call_list\n\t        pass\n\t    # Candidate CNV merge by distance and CNV type\n\t    def merge_candidates(self, candidates_cnv_list, chromosome_name):\n\t        if len(candidates_cnv_list) > 1:\n\t            dev_candidates_string = \"\"\n", "            merge_rounds = 1\n\t            self.logger.debug(f'Current merge cycle {merge_rounds}')\n\t            [n_merges, merged_candidates, _] = self.cnv_candidate_merge(candidates_cnv_list)\n\t            while n_merges > 0:\n\t                merge_rounds += 1\n\t                self.logger.debug(f'Current merge cycle {merge_rounds}')\n\t                # self.logger.info(f'n candidates in {chromosome_name}: {len(merged_candidates)}')\n\t                [n_merges, merged_candidates, dev_candidates_string] = self.cnv_candidate_merge(merged_candidates)\n\t            # self.logger.debug(dev_candidates_string)\n\t            self.logger.debug(f'Total merge rounds: {merge_rounds}')\n", "            candidates_cnv_list = self.clean_merged_candidates(merged_candidates)\n\t            # self.logger.debug(f'n candidates {chromosome_name}: {len(candidates_cnv_list)}')\n\t        return candidates_cnv_list\n\t    def cnv_candidate_merge(self, cnv_candidates):\n\t        def dev_candidates_merge(header=False):  # dev\n\t            if header:\n\t                return f'chr\\tleft\\tright\\tleft_size\\tright_size\\tcov_left\\tcov_right\\tdist_OK\\ttype_OK\\tCN_OK'\n\t            else:\n\t                return (f'{cnv_candidates[idx].chromosome}\\t{end0}\\t{start1}\\t'\n\t                        f'{cnv_cand.size}\\t{cnv_candidates[idx + 1].size}\\t'\n", "                        f'{cnv_candidates[idx].median_cov_norm}\\t{cnv_candidates[idx + 1].median_cov_norm}\\t'\n\t                        f'{(start1 - end0) < max_merge_distance}\\t{same_type}\\t{same_cnv_status}')\n\t        n_candidates = len(cnv_candidates)\n\t        # distance between end of i to start of i+1\n\t        # first on is given\n\t        idx = 0\n\t        n_merges = 0\n\t        merges_candidates = []\n\t        cnv_cand = cnv_candidates[idx]\n\t        cov_diff_threshold = self.cov_diff_threshold  # selected by trial and error in simulations\n", "        # dist => distance\n\t        dist_proportion = self.dist_proportion  # selected by trial and error, max distance proportion for merge\n\t        dist_min_overwrite = self.dist_min_overwrite\n\t        dev_candidates_string = [dev_candidates_merge(header=True)]\n\t        while idx < n_candidates - 1:\n\t            end0 = cnv_candidates[idx].end\n\t            start1 = cnv_candidates[idx + 1].start\n\t            same_type = cnv_candidates[idx].type == cnv_candidates[idx + 1].type\n\t            # copy number status difference\n\t            same_cnv_status = abs(\n", "                cnv_candidates[idx].median_cov_norm - cnv_candidates[idx + 1].median_cov_norm) <= cov_diff_threshold\n\t            # distance between merging windows is a % of the average length of the windows to be merged\n\t            max_merge_distance = max(np.mean([cnv_cand.size, cnv_candidates[idx + 1].size]) * dist_proportion,\n\t                                     dist_min_overwrite)\n\t            dev_candidates_string.append(dev_candidates_merge())\n\t            # Evaluate if the new span is covered by any blacklisted region\n\t            # Check if span_over_blacklisted_region = true if no overlap exists\n\t            span_over_blacklisted_region = any(\n\t                any(end0 <= int(val) <= start1 for val in tup) for tup in self.metadata[cnv_cand.chromosome])\n\t            if (start1 - end0) < max_merge_distance and same_type and same_cnv_status and \\\n", "                    not span_over_blacklisted_region:\n\t                # merge and extend\n\t                n_merges += 1\n\t                cnv_cand.add_candidates(\n\t                    cnv_candidates[idx + 1].pos,\n\t                    cnv_candidates[idx + 1].cov,\n\t                    cnv_candidates[idx + 1].id,\n\t                    cnv_candidates[idx + 1].merged_sample_references\n\t                )\n\t            else:\n", "                # save and show\n\t                cnv_cand.median_coverage_candidates_merged()\n\t                merges_candidates.append(cnv_cand)\n\t                # cnv_cand.show_candidates()  # DEV\n\t                # init\n\t                cnv_cand = cnv_candidates[idx + 1]\n\t            idx += 1\n\t        # one last time for the remaining ones\n\t        merges_candidates.append(cnv_cand)\n\t        # cnv_cand.show_candidates()  # DEV\n", "        return [n_merges, merges_candidates, \"\\n\".join(dev_candidates_string)]\n\t    def clean_merged_candidates(self, merged_candidates):\n\t        # current threshold is 100kb\n\t        clean_merged = []\n\t        for each_cand in merged_candidates:\n\t            if each_cand.size >= self.candidate_final_threshold:\n\t                clean_merged.append(each_cand)\n\t        return clean_merged\n\t    # Fill in the gaps after merge\n\t    def scaffold_candidates(self, final_candidates_list, chromosome_name):\n", "        cnv_list = []\n\t        n_scaffolds = 0\n\t        cov_data_chr = self.genome_analysis[chromosome_name][\"cov_data\"]\n\t        _index = 0\n\t        _cand = final_candidates_list[_index]\n\t        while _index < len(final_candidates_list) - 1:\n\t            _cand_next = final_candidates_list[_index + 1]\n\t            if _cand.type == _cand_next.type:\n\t                gap_start = np.where(cov_data_chr.positions == _cand.end)\n\t                gap_end = np.where(cov_data_chr.positions == _cand_next.start)\n", "                gap_data = cov_data_chr.normalized_cov_ploidy[gap_start[0][0]:gap_end[0][0]]\n\t                scaf_cov = np.nanmedian(gap_data)\n\t                # Restricting cnv scaffolding merge over 100 following N regions (NaN values)\n\t                scaf_cov_nan_overflow = np.count_nonzero(np.isnan(np.array(gap_data))) > 0\n\t                if abs(\n\t                        scaf_cov - np.nanmedian(list(_cand.cov) + list(_cand_next.cov))\n\t                ) <= self.cov_diff_threshold and not scaf_cov_nan_overflow:\n\t                    _cand.add_candidates(_cand_next.pos, _cand_next.cov, _cand_next.id,\n\t                                         _cand_next.merged_sample_references)\n\t                    n_scaffolds += 1\n", "                else:\n\t                    _cand.median_coverage_candidates_merged()\n\t                    cnv_list.append(_cand)\n\t                    _cand = _cand_next\n\t            else:\n\t                _cand.median_coverage_candidates_merged()\n\t                cnv_list.append(_cand)\n\t                # init with next\n\t                _cand = _cand_next\n\t            _index += 1\n", "        # one final\n\t        _cand.median_coverage_candidates_merged()\n\t        cnv_list.append(_cand)\n\t        return cnv_list\n\t    # Output results\n\t    def cnv_result_bed(self, method=\"\"):\n\t        if method == \"\":\n\t            output_bed = self.output_bed\n\t        else:\n\t            output_bed = os.path.join(os.path.join(self.output_directory, f'{method}{self.sample_id}.bed'))\n", "        bed_output = util.outputWriter.BedOutput(output_bed)\n\t        bed_output.make_bed(self.genome_analysis.keys(), self.cnv_calls_list)\n\t    def cnv_result_vcf(self, method=\"\"):\n\t        output_vcf = os.path.join(os.path.join(self.output_directory, f'{method}{self.sample_id}.vcf'))\n\t        vcf_output = util.outputWriter.VCFOutput(output_vcf, self.genome_info)\n\t        vcf_output.make_vcf(self.genome_analysis.keys(), self.cnv_calls_list, self.sample_id)\n\t    # Plots\n\t    def coverage_plot(self):\n\t        for each_chromosome in self.genome_analysis.keys():\n\t            plot_cnv = CoveragePlot()\n", "            plot_cnv.file_prefix = f'plot1-coverage-{self.sample_id}'\n\t            plot_cnv.output_directory = self.output_directory\n\t            chr_cov_data = self.genome_analysis[each_chromosome][\"cov_data\"]\n\t            plot_cnv.plot_coverage(each_chromosome, {\"pos\": chr_cov_data.positions, \"cov\": chr_cov_data.raw_coverage})\n\t    def cnv_plot(self, methode=\"\"):\n\t        for each_chromosome in self.genome_analysis.keys():\n\t            chr_cov_data = self.genome_analysis[each_chromosome][\"cov_data\"]\n\t            cov_stats = self.genome_analysis[each_chromosome][\"norm_statistics\"]\n\t            lower_bound = self.lower_2n_threshold\n\t            upper_bound = self.upper_2n_threshold\n", "            cov_stats.median = cov_stats.median * self.ploidy  # for diploid\n\t            new_plot_device = CNVPlot()\n\t            new_plot_device.output_directory = self.output_directory\n\t            new_plot_device.file_prefix = methode + self.sample_id\n\t            new_plot_device.plot_coverage_cnv(each_chromosome, cov_stats,\n\t                                              {\"pos\": chr_cov_data.positions,\n\t                                               \"cov\": chr_cov_data.normalized_cov_ploidy},\n\t                                              self.cnv_calls_list[each_chromosome], [lower_bound, upper_bound])\n\t    def convert_vcf_to_tabular(self, snv_af_bed_output):\n\t        self.logger.info(\"Parsing VCF to BED file\")\n", "        vcf_parser = vcf.VCFSNVParser(self.min_chr_length, self.as_dev)\n\t        self.logger.debug(\"Parsing: VCF -> DataFrame\")\n\t        vcf_df = vcf_parser.vcf_to_dataframe(self.snv_file)\n\t        self.logger.debug(\"Parsing: DataFrame -> BED\")\n\t        self.snv_af_df = vcf_parser.dataframe_to_tabular_file(vcf_df, self.coverage_file, snv_af_bed_output)\n\t        self.snv_af_bed = snv_af_bed_output\n\t    def call_cnv_af_region(self):\n\t        # self.cnv_calls_list[each_chromosome]\n\t        cnv_by_af = CNVAnalysisSNP(genome_info=self.genome_info,\n\t                                   output_directory=self.output_directory,\n", "                                   sample_id=self.sample_id,\n\t                                   as_dev=self.as_dev)\n\t        self.logger.info(\"Calculating CNV events based on SNV data\")\n\t        self.cnv_calls_list = cnv_by_af.af_cnv_call_region(self.cnv_calls_list, self.snv_af_bed)\n\t        cnv_by_af.call_cnv_af(self.snv_af_df, write_csv=True)\n\t    def get_cnv_metrics(self, refined_cnvs: bool = False):\n\t        \"\"\"\n\t        Calculates for every CNV call a metrics like the p value with statistical tests\n\t        :return:\n\t        \"\"\"\n", "        self.cnv_metrics.evaluate_cnvs(self.cnv_calls_list, refined_cnvs)\n\t    def write_intermediate_candidates(self, candidate_type: str = \"\") -> str:\n\t        \"\"\"\n\t        Writing intermediate object files out\n\t        :param candidate_type:\n\t        :return:\n\t        \"\"\"\n\t        intermediate_output_writer = util.outputWriter.IntermediateFile(self.output_directory)\n\t        #genome_info = intermediate_output_writer.convert_candidates_to_dictionary(self.genome_info)\n\t        cnv_calls_list_dict = intermediate_output_writer.convert_candidates_to_dictionary(self.cnv_calls_list)\n", "        raw_cnv_calls_list_dict = intermediate_output_writer.convert_candidates_to_dictionary(self.raw_cnv_calls_list)\n\t        analysis_dict = {\n\t                \"metadata\": {\"source\":\"spectre\",\"spectre_version\": \"0.1\"},\n\t                \"genome_info\": self.genome_info,\n\t                \"raw_cnvs\": raw_cnv_calls_list_dict,\n\t                \"refined_cnvs\": cnv_calls_list_dict,\n\t                \"analysis_metrics\": {\n\t                    \"min_chr_length\": self.min_chr_length,\n\t                    \"max_std_outlier_rm\": self.max_std_outlier_rm,\n\t                    \"mosdepth_cov_genome_chr_diff\": self.mosdepth_cov_genome_chr_diff,\n", "                    \"lower_2n_threshold\": self.lower_2n_threshold,\n\t                    \"upper_2n_threshold\": self.upper_2n_threshold,\n\t                    \"cov_diff_threshold\": self.cov_diff_threshold,\n\t                    \"dist_proportion\": self.dist_proportion,\n\t                    \"dist_min_overwrite\": self.dist_min_overwrite,\n\t                    \"candidate_final_threshold\": self.candidate_final_threshold,\n\t                    \"genome_mean\": np.mean(self.cnv_metrics.df_coverage_candidate_no_excl_zone_random_samples['coverage']),\n\t                    \"genome_sd\": np.std(self.cnv_metrics.df_coverage_candidate_no_excl_zone_random_samples['coverage']),\n\t                    \"genome_var\": np.var(self.cnv_metrics.df_coverage_candidate_no_excl_zone_random_samples['coverage'])\n\t                }\n", "            }\n\t        output_path = intermediate_output_writer.write_intermediate_file(analysis_dict, f\"{self.sample_id}\")\n\t        self.intermediate_candidates_file_location = output_path\n\t        return output_path\n\t    # ############################################\n\t    # dev\n\t    def dev_write_csv(self, each_chromosome):\n\t        csv_results = pd.DataFrame(\n\t            data={\"position\": self.genome_analysis[each_chromosome][\"cov_data\"].positions,\n\t                  \"mosdepth_cov\": self.genome_analysis[each_chromosome][\"cov_data\"].coverage_raw,\n", "                  \"norm_cov\": self.genome_analysis[each_chromosome][\"cov_data\"].normalized_cov,\n\t                  \"ploidy_cov\": self.genome_analysis[each_chromosome][\"cov_data\"].normalized_cov_ploidy\n\t                  }\n\t        )\n\t        csv_results[\"chr\"] = each_chromosome\n\t        output_file = f\"{self.debug_dir}/cnv_{self.sample_id}_byCoverage_chr{each_chromosome}.csv\"\n\t        self.logger.debug(f\"Writing coverage to {output_file}\")\n\t        csv_results.to_csv(output_file, index=False)\n"]}
{"filename": "analysis/__init__.py", "chunked_list": []}
{"filename": "analysis/cnv_metrics.py", "chunked_list": ["import matplotlib.pyplot as plt\n\timport numpy as np\n\timport pandas as pd\n\timport hashlib\n\timport random\n\tfrom scipy.stats import ks_2samp, norm\n\timport logging as logger\n\tclass CNVMetrics(object):\n\t    def __init__(self, genome_analysis, exclusion_zones, cnv_calls=None,\n\t                 hashname: str = \"mock_dataname_of_coverage.csv\",ploidy:float=2.0,\n", "                 output_dir: str = \"\", as_dev: bool = False, debug_dir=\"\"):\n\t        self.genome_analysis = genome_analysis\n\t        self.cnv_calls = cnv_calls\n\t        self.hashname = hashname\n\t        self.ploidy = ploidy\n\t        self.output_dir = output_dir\n\t        self.as_dev = as_dev\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        # conversion\n", "        self.df_mosdepth_coverage = self.__convert_genome_analysis_to_coverage_dataframe(genome_analysis)\n\t        self.blacklist_exclusions = self.__convert_blacklist_exclusion_zone(exclusion_zones)\n\t        # if cnv_calls:  # check if cnv_calls is emtpy\n\t        #    self.cnv_exclusion = self.__convert_cnv_calls_to_exclusions(cnv_calls)\n\t        #    self.blacklist_cnv_exclusion = self.__merge_dict_with_lists_as_value(self.blacklist_exclusions,\n\t        #                                                                         self.cnv_exclusion)\n\t        self.__prepare_cnv_evaluation()\n\t        # calculate borders\n\t        self.del_border, self.dup_border = self.calculate_del_dup_borders(1.0, 1.0, self.ploidy)\n\t        self.debug_dir = debug_dir\n", "    def __convert_genome_analysis_to_coverage_dataframe(self, genome_analysis):\n\t        \"\"\"\n\t        Convert the standard Spectre genome_analysis into a pandas dataframe, using the minimal required fields\n\t        to evaluate the CNV calls.\n\t        :param genome_analysis: standard Spectre genome_analysis dictionary\n\t        :return: pandas dataframe holding at least column values [\"chr\", \"position\", \"coverage\"]\n\t        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Convert Genome analysis to coverage dataframe\")\n\t        list_modsepth_coverage = [[key, genome_analysis[key][\"cov_data\"].positions,\n\t                                   genome_analysis[key][\"cov_data\"].normalized_cov_ploidy] for key in\n", "                                  genome_analysis.keys()]\n\t        df_mosdepth_coverage = pd.DataFrame(list_modsepth_coverage)\n\t        df_mosdepth_coverage.columns = [\"chr\", \"position\", \"coverage\"]\n\t        df_mosdepth_coverage = df_mosdepth_coverage.explode([\"position\", \"coverage\"])\n\t        df_mosdepth_coverage.reset_index(inplace=True)\n\t        return df_mosdepth_coverage\n\t    def __convert_cnv_calls_to_exclusions(self, cnv_call_list: dict):\n\t        \"\"\"\n\t        Converts the Spectre into a specific form of dictionary, which will be used to perform the statistical\n\t        analysis. Furthermore, the cnv calls play a role in randomly sampling coverage values which will be used\n", "        in the statistical analysis.\n\t        :param cnv_call_list: standard Spectre cnv_call_list\n\t        :return: Dictionary with a list of Dictionaries entries\n\t        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Converting cnv calls to exclusion zone\")\n\t        result = {}\n\t        for key in cnv_call_list.keys():\n\t            if key not in result.keys():\n\t                result[key] = []\n\t            for candidate in cnv_call_list[key]:\n", "                result[key].append({\"start\": candidate.start, \"end\": candidate.end, \"info\": \"cnv\"})\n\t        return result\n\t    def __convert_blacklist_exclusion_zone(self, blacklist: dict):\n\t        \"\"\"\n\t        Converts the given blacklist which contains a dict with lists of tupels into a dict with lists\n\t        and items as dicts.\n\t        :param blacklist: standard Spectre blacklist\n\t        :return:\n\t        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Converting blacklist to exclusion zone\")\n", "        result = {}\n\t        for key in blacklist.keys():\n\t            if key not in result.keys():\n\t                result[key] = []\n\t            # convert tupel into dictionary\n\t            for start, end in blacklist[key]:\n\t                result[key].append({\"start\": start, \"end\": end, \"info\": \"blacklist\"})\n\t        return result\n\t    def __merge_dict_with_lists_as_value(self, dict_1: dict, dict_2: dict) -> dict:\n\t        \"\"\"\n", "        Merges two dictionaries which hold a list as value and creating a completely new dictionary\n\t        in which the lists are appended to the other one.\n\t        :param dict_1: primary dictionary. (values will be first in the merged list)\n\t        :param dict_2: secondary dictionary. (values will be appended to the dict_1 values)\n\t        :return: merged and newly created dictionary\n\t        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Merging exclusion zones\")\n\t        dict_result = dict_1.copy()\n\t        for key in dict_2:\n\t            if key not in dict_1.keys():\n", "                dict_result[key] = dict_2[key].copy()\n\t            else:\n\t                dict_result[key] = [*dict_result[key], *dict_2[key].copy()]\n\t        return dict_result\n\t    def get_exclusion_zones_indices_in_coverage_data(self, df_mosdepth_coverage, dict_excl_zone):\n\t        \"\"\"\n\t        Gets all mosdepth coverage dataframe indices, which are within the exclusion zone.\n\t        :param df_mosdepth_coverage: dataframe with mosdepth coverage\n\t        :param dict_excl_zone: list of indices\n\t        :return:\n", "        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Getting exclusion zone indices in mosdepth coverage data\")\n\t        excl_indices = []\n\t        for excl_key in dict_excl_zone.keys():\n\t            df_chr = df_mosdepth_coverage.loc[df_mosdepth_coverage.chr == excl_key]\n\t            for excl_zone in dict_excl_zone[excl_key]:\n\t                in_excl_zone = df_chr.loc[\n\t                    df_chr.position.between((int(excl_zone[\"start\"]) - 1), int(excl_zone[\"end\"]))].index  # [\"index\"]\n\t                if len(in_excl_zone) > 0:\n\t                    excl_indices = excl_indices + list(in_excl_zone)\n", "        return excl_indices\n\t    def random_sample_selection(self, df_source, amount: float = 0.1):\n\t        \"\"\"\n\t        Selecting random samples outside any exclusion zone (blacklist, cnv, ...)\n\t        :param df_source:\n\t        :param amount:\n\t        :return:\n\t        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Generating random coverage sample indices\")\n\t        result_hash_of_filename = hashlib.md5(self.hashname.encode()).hexdigest()  # used for the random samples\n", "        random.seed(result_hash_of_filename)\n\t        fraction = amount\n\t        last_index = len(df_source.index) - 1  # len(df.index)\n\t        # last_index = df_source[\"excl_zone\"].size - 1\n\t        cov_window_amount = int(last_index * fraction)\n\t        samples_indices = random.sample(range(0, last_index), cov_window_amount)\n\t        sorted_samples_indices = sorted(samples_indices)\n\t        return sorted_samples_indices\n\t    def get_ks_test(self, cnv_coverage, df_random_sample_coverage):\n\t        \"\"\"\n", "        Calculating the ks-Score for given cnv coverage values and comparing the mean and sd to the distribution of\n\t        randomly samples coverage datasets\n\t        :param cnv_coverage: list of coverage values\n\t        :param df_random_sample_coverage: dataframe holding randomly selected coverage data\n\t        :return: dictionary with: cnv_call_mean, score (z-score), pvalue, ...\n\t        \"\"\"\n\t        # self.logger.debug(\"CNV-Metrics: Performing the KS-test\")\n\t        result = {}\n\t        cnv_coverage = np.array(cnv_coverage)\n\t        cnv_coverage = cnv_coverage[~np.isnan(cnv_coverage)]\n", "        random_sample_coverage = df_random_sample_coverage[\"coverage\"]\n\t        random_sample_coverage = random_sample_coverage.dropna()\n\t        statistic, pvalue = ks_2samp(cnv_coverage, random_sample_coverage)\n\t        result[\"cnv_call_mean\"] = round(np.nanmean(cnv_coverage), 3)\n\t        result[\"pvalue\"] = pvalue\n\t        result[\"sample_score\"] = abs(pvalue * 255)\n\t        result[\"score\"] = np.nan\n\t        result[\"statistics\"] = statistic\n\t        result[\"test_type\"] = \"ks-score\"\n\t        return result\n", "    def get_z_score(self, cnv_coverage, df_random_sample_coverage):\n\t        \"\"\"\n\t        Calculating the Z-Score for given cnv coverage values and comparing the mean and sd to the distribution of\n\t        randomly samples coverage datasets\n\t        :param cnv_coverage: list of coverage values\n\t        :param df_random_sample_coverage: dataframe holding randomly selected coverage data\n\t        :return: dictionary with: cnv_call_mean, score (z-score), pvalue, ...\n\t        \"\"\"\n\t        # self.logger.debug(\"CNV-Metrics: Performing the Z-Test\")\n\t        result = {}\n", "        cnv_coverage = np.array(cnv_coverage)\n\t        cnv_coverage = cnv_coverage[~np.isnan(cnv_coverage)]  # exclude NaN values\n\t        cnv_coverage = cnv_coverage[~np.isinf(cnv_coverage)]  # exclude -inf/inf values\n\t        random_sample_coverage = df_random_sample_coverage[\"coverage\"]\n\t        random_sample_coverage.replace([np.inf, -np.inf], np.nan, inplace=True)  # replace -inf/inf values with nan\n\t        random_sample_coverage = random_sample_coverage.dropna()  # exclude all nan values\n\t        mean = np.mean(cnv_coverage)\n\t        sd = np.std(cnv_coverage)\n\t        # Z score\n\t        z = (np.mean(random_sample_coverage) - mean) / (sd / np.sqrt(len(random_sample_coverage)))\n", "        # pvalue\n\t        z_capped = min(z, 10) if z > 1 else max(-10, z)\n\t        # pvalue = 2 * (1 - norm.cdf(abs(z_capped)))  # Two-tailed test\n\t        pvalue = norm.sf(abs(z_capped)) * 2\n\t        # pvalue = 2 * (1 - norm.cdf(abs(z)))  # Two-tailed test\n\t        gq = -np.log10(pvalue) * 10\n\t        gq_capped = min(60, int(gq))\n\t        result[\"cnv_call_mean\"] = np.nanmean(cnv_coverage)\n\t        result[\"score\"] = z_capped\n\t        result[\"pvalue\"] = pvalue\n", "        result[\"sample_score\"] = gq_capped\n\t        result[\"statistics\"] = None\n\t        result[\"test_type\"] = \"z-score\"\n\t        return result\n\t    def __prepare_cnv_evaluation(self) -> None:\n\t        \"\"\"\n\t        Preparing all the necessary variables, to performe the CNV evaluation on the cnv candidates\n\t        :return: None\n\t        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Preparing all parameters for the cnv evaluation\")\n", "        df_coverage_candidate = self.df_mosdepth_coverage.copy()\n\t        df_coverage_candidate[\"blacklist\"] = False  # holds only the values if row is in blacklist\n\t        # df_coverage_candidate[\"cnv\"] = False  # holds only values that are in cnv_events\n\t        # df_coverage_candidate[\"excl_zone\"] = False  # holds the combination of blacklist and cnv\n\t        df_coverage_candidate.replace([np.inf, -np.inf], np.nan, inplace=True)\n\t        df_coverage_candidate_no_Nans = df_coverage_candidate.dropna(subset=[\"coverage\"])  # contains no nan values\n\t        # get exclusion indices\n\t        excl_zone_blacklist_indices = self.get_exclusion_zones_indices_in_coverage_data(df_coverage_candidate_no_Nans,\n\t                                                                                        self.blacklist_exclusions)\n\t        # Add exclusion indices\n", "        # if len(excl_zone_blacklist_indices) > 0:\n\t        # df_coverage_candidate_no_Nans.loc[excl_zone_blacklist_indices, \"blacklist\"] = True\n\t        # df_coverage_candidate_no_Nans.loc[df_coverage_candidate_no_Nans.index.isin(excl_zone_blacklist_indices), \"blacklist\"] = True\n\t        df_coverage_candidate_no_Nans.iloc[\n\t            excl_zone_blacklist_indices, df_coverage_candidate_no_Nans.columns.get_loc(\"blacklist\")] = True\n\t        # load curated data\n\t        df_coverage_candidate_no_blacklist = df_coverage_candidate_no_Nans.loc[df_coverage_candidate.blacklist == False]\n\t        # get random samples\n\t        no_blacklist_indices = self.random_sample_selection(df_coverage_candidate_no_blacklist, 0.1)\n\t        self.df_coverage_candidate_no_blacklist_random_samples = df_coverage_candidate_no_blacklist.iloc[\n", "            no_blacklist_indices]\n\t        # add for later use\n\t        if self.cnv_calls:\n\t            self.__recalculate_exlustion_zone(self.cnv_calls)\n\t        else:\n\t            self.df_coverage_candidate_no_excl_zone_random_samples = self.df_coverage_candidate_no_blacklist_random_samples.copy()\n\t    def __recalculate_exlustion_zone(self, cnv_calls) -> None:\n\t        \"\"\"\n\t        Recalculates the random sample coverage, based on new cnv_calls. This ensures that no coverage sample from\n\t        the blacklist or an existing CNV call will be used to give the CNV calls a score.\n", "        :param cnv_calls:\n\t        :return: None\n\t        \"\"\"\n\t        # setup\n\t        self.cnv_exclusion = self.__convert_cnv_calls_to_exclusions(cnv_calls)\n\t        self.blacklist_cnv_exclusion = self.__merge_dict_with_lists_as_value(self.blacklist_exclusions,\n\t                                                                             self.cnv_exclusion)\n\t        df_coverage_candidate = self.df_mosdepth_coverage.copy()\n\t        # df_coverage_candidate[\"blacklist\"] = False  # holds only the values if row is in blacklist\n\t        # df_coverage_candidate[\"cnv\"] = False  # holds only values that are in cnv_events\n", "        df_coverage_candidate[\"excl_zone\"] = False  # holds the combination of blacklist and cnv\n\t        df_coverage_candidate.replace([np.inf, -np.inf], np.nan, inplace=True)\n\t        df_coverage_candidate_no_Nans = df_coverage_candidate.dropna(subset=[\"coverage\"])  # contains no nan values\n\t        # get inclustio\n\t        # excl_zone_cnv_indices = self.get_exclusion_zones_indices_in_coverage_data(\n\t        #    df_coverage_candidate_no_Nans,self.cnv_exclusion)\n\t        excl_zone_backlist_cnv_indices = self.get_exclusion_zones_indices_in_coverage_data(\n\t            df_coverage_candidate_no_Nans, self.blacklist_cnv_exclusion)\n\t        # Add exclusion indices\n\t        # df_coverage_candidate_no_Nans.loc[excl_zone_cnv_indices, [\"cnv\"]] = True\n", "        if len(excl_zone_backlist_cnv_indices) > 0:\n\t            df_coverage_candidate_no_Nans.loc[excl_zone_backlist_cnv_indices, \"excl_zone\"] = True\n\t        # df_coverage_candidate_no_cnv = df_coverage_candidate_no_Nans.loc[df_coverage_candidate.cnv == False]\n\t        df_coverage_candidate_no_excl_zone = df_coverage_candidate_no_Nans.loc[df_coverage_candidate.excl_zone == False]\n\t        # Get random samples for samples with the same random\n\t        # no_cnv_indices = self.random_sample_selection(df_coverage_candidate_no_cnv, 0.1)\n\t        # self.df_coverage_candidate_no_cnv_random_samples = df_coverage_candidate_no_cnv.iloc[no_cnv_indices]\n\t        no_excl_zone_indices = self.random_sample_selection(df_coverage_candidate_no_excl_zone, 0.1)\n\t        self.df_coverage_candidate_no_excl_zone_random_samples = df_coverage_candidate_no_excl_zone.iloc[\n\t            no_excl_zone_indices]\n", "        pass\n\t    @staticmethod\n\t    def get_lower_border(mean: float, sd: float, sd_multiplier: float, epsilon: float = 0.01,\n\t                         epsilon_multiplier: float = 0):\n\t        return mean - (sd * sd_multiplier + (epsilon * epsilon_multiplier))\n\t    @staticmethod\n\t    def get_upper_border(mean: float, sd: float, sd_multiplier: float, epsilon: float = 0.01,\n\t                         epsilon_multiplier: float = 0):\n\t        return mean + (sd * sd_multiplier + (epsilon * epsilon_multiplier))\n\t    def calculate_del_dup_borders(self, del_border_multiplier: float = 1.0, dup_border_multiplier: float = 1.0,\n", "                                  ploidy: float = 2.0) -> tuple:\n\t        \"\"\"\n\t        Calculate dynamic borders for deletions (DEL) and duplications (DUP), based on the randomly selected coverage\n\t        samples.\n\t        :param del_border_multiplier: Multiplier for the tightness of the lower (deletion) border\n\t        :param dup_border_multiplier: Multiplier for the tightness of the upper (duplication) border\n\t        :return: Tupel with deletion border and duplication border (DEL,DUP)\n\t        \"\"\"\n\t        mean = float(np.mean(self.df_coverage_candidate_no_excl_zone_random_samples['coverage']))\n\t        sd = float(np.std(self.df_coverage_candidate_no_excl_zone_random_samples['coverage']))\n", "        var = np.var(self.df_coverage_candidate_no_excl_zone_random_samples['coverage'])\n\t        # Rough border estimation\n\t        lower_border = mean - (sd * del_border_multiplier)\n\t        upper_border = mean + (sd * dup_border_multiplier)\n\t        # Find optimal border\n\t        ploidy_offset_deletion_border = ploidy - 1\n\t        offset_duplication_border = ploidy + 1\n\t        epsilon = 0.01\n\t        step_cnt = 1\n\t        max_steps = 1000\n", "        found_new_deletion_border = False\n\t        found_new_duplication_border = False\n\t        ratio = 0.4\n\t        while step_cnt < max_steps:\n\t            # Calculate DEL border\n\t            if not found_new_deletion_border:\n\t                del_border_to_ploidy_offset = abs(lower_border - ploidy_offset_deletion_border) * (1 - ratio)\n\t                del_border_to_ploidy = abs(lower_border - ploidy) * ratio\n\t                if del_border_to_ploidy_offset > del_border_to_ploidy:\n\t                    lower_border = self.get_lower_border(mean, sd, del_border_multiplier, epsilon, step_cnt)\n", "                else:\n\t                    found_new_deletion_border = True\n\t            # Calculate DUP border\n\t            if not found_new_duplication_border:\n\t                dup_border_to_ploidy_offset = abs(upper_border - offset_duplication_border) * (1 - ratio)\n\t                dup_border_to_ploidy = abs(upper_border - ploidy) * ratio\n\t                if dup_border_to_ploidy_offset > dup_border_to_ploidy:\n\t                    upper_border = self.get_upper_border(mean, sd, dup_border_multiplier, epsilon, step_cnt)\n\t                else:\n\t                    found_new_duplication_border = True\n", "            step_cnt += 1\n\t        return lower_border, upper_border\n\t    def evaluate_cnvs(self, cnv_calls=None, refined_cnvs: bool = False) -> dict:\n\t        \"\"\"\n\t        Evaluating all submitted CNV calls, by applying statistical tests. Optionally, plotting the location of the CNVs\n\t        on the global coverage samples per chr.\n\t        :return: Modified CNVCandidates\n\t        \"\"\"\n\t        self.logger.debug(\"CNV-Metrics: Evaluating all CNVs\")\n\t        if cnv_calls is not None:\n", "            self.logger.debug(\"CNV-Metrics: Recalculating\")\n\t            self.__recalculate_exlustion_zone(cnv_calls)\n\t        self.logger.info(f\"CNV-Metrics: DEL border:{self.del_border} \\t DUP border:{self.dup_border}\")\n\t        border_del = self.del_border\n\t        border_dup = self.dup_border\n\t        for cnv_chr in self.cnv_calls.keys():\n\t            if self.as_dev:\n\t                self.logger.debug(f\"CNV-Metrics: Creating a new plot at chromosome {cnv_chr}\")\n\t                fig, ax = plt.subplots()\n\t                x, bins, p = ax.hist(self.df_coverage_candidate_no_excl_zone_random_samples['coverage'], bins=100,\n", "                                     range=[0.0, 5.0])\n\t                width = p.patches[0].get_width()\n\t                ax.axvline(border_del, ymax=1, color=\"red\", linestyle=\":\")\n\t                ax.axvline(border_dup, ymax=1, color=\"green\", linestyle=\":\")\n\t                ax.axhline()\n\t                ax.text(1.2 - 0.65, max(x), f\"DEL: {round(self.del_border)}\")\n\t                ax.text(2.7 - 0.65, max(x), f\"DUP: {round(self.dup_border)}\")\n\t                ax.set_title(f\"Mean coverage position of CNVs at {cnv_chr} based on random global coverage samples\")\n\t                ax.set_xlabel('Coverage')\n\t                ax.set_ylabel('Count')\n", "            for cnv in self.cnv_calls[cnv_chr]:\n\t                # Z-Test 2 - DIY\n\t                if refined_cnvs:\n\t                    cnv_metrics_Z = self.get_z_score(cnv.cov, self.df_coverage_candidate_no_excl_zone_random_samples)\n\t                else:\n\t                    cnv_metrics_Z = {}\n\t                    cnv_metrics_Z[\"statistics\"] = None\n\t                    cnv_metrics_Z[\"score\"] = 0\n\t                    cnv_metrics_Z[\"pvalue\"] = 0\n\t                    cnv_metrics_Z[\"sample_score\"] = 0\n", "                    cnv_metrics_Z[\"cnv_call_mean\"] = np.nanmean(cnv.cov)\n\t                cnv.statistics[\"z-score\"] = {\"statistics\": cnv_metrics_Z[\"statistics\"],\n\t                                             \"score\": cnv_metrics_Z[\"score\"],\n\t                                             \"pvalue\": cnv_metrics_Z[\"pvalue\"],\n\t                                             \"sample_score\": cnv_metrics_Z[\"sample_score\"]}\n\t                if self.as_dev:\n\t                    if not np.isnan(cnv_metrics_Z[\"cnv_call_mean\"]):\n\t                        # pre check --> avoide div by 0\n\t                        if cnv_metrics_Z[\"cnv_call_mean\"] == 0:\n\t                            x_index = 0\n", "                        else:\n\t                            if not np.isinf(cnv_metrics_Z[\"cnv_call_mean\"]):\n\t                                x_index = int(cnv_metrics_Z[\"cnv_call_mean\"] / width)\n\t                            else:\n\t                                x_index = int(x[-1])\n\t                        # check if out of bounds\n\t                        if x_index >= len(x):\n\t                            cnv_y = x[-1]\n\t                        else:\n\t                            cnv_y = int(x[x_index])\n", "                        cnv_y = int(cnv_y)\n\t                        annotation_endpoint_offset = 5 * (100 - x_index) * (\n\t                                1 - (cnv_y / 150)) + (max(x) / 10)  # np.random.randint(100,300)\n\t                        # Add\n\t                        ax.annotate(f\"{cnv.id}\", xy=(cnv_metrics_Z[\"cnv_call_mean\"], cnv_y),\n\t                                    xytext=(cnv_metrics_Z[\"cnv_call_mean\"], cnv_y + annotation_endpoint_offset),\n\t                                    rotation=60,\n\t                                    fontsize=12, arrowprops=dict(facecolor='green', shrink=0.05))\n\t            if self.as_dev:\n\t                plot_path = f\"{self.debug_dir}/cnv-calls-{self.hashname}-at_chr-{cnv_chr}.png\"\n", "                self.logger.debug(f\"CNV-Metrics:{plot_path}\")\n\t                fig.savefig(plot_path)\n\t        return self.cnv_calls\n"]}
{"filename": "analysis/call_cnv_AF.py", "chunked_list": ["import pandas as pd\n\timport numpy as np\n\timport pysam\n\timport logging as logger\n\tclass CNVCall(object):\n\t    def __init__(self, genome_info:dict, output_directory=\"\", sample_id=\"\", as_dev:bool = False):\n\t        self.as_dev = as_dev\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        self.output_directory = output_directory\n", "        self.sample_id = sample_id\n\t        self.genome_info = genome_info\n\t        # snv bed\n\t        self.snv_af_bed_bgzip = None\n\t        # candidates coverage\n\t        self.cnv_candidates_by_coverage = None\n\t        # AF to CN state concordance\n\t        # difference between the \"expected AF\" and \"computed AF\" for a given CN state\n\t        self.af_diff_buffer_default = 0.1  # will be min(default, 20% min ratio); e.g. if 4:1, then min(0.5, 1/5 * 0.2)\n\t        self.default_proportion_min_af = 0.3  # 30%\n", "        # all AF are MAF meaning if AF > 0.5, then AF = 1 - AF\n\t        self.cn_state_to_af = {\n\t            0: 0,                # complete DEL then we should not have data, init = 0\n\t            1: 0,                # 0 or 1, as we use MAF, then only 0\n\t            3: 1/3,              # 2:1 ratio, as we use MAF then 1/3\n\t            4: [1/4, 2/4],       # 3:1 or 2:2 ratio, then 1/4 or 2/4\n\t            5: [1/5, 2/5],       # 4:1 or 3:2 ratio, then 1/5 or 2/5\n\t            6: [1/6, 2/6, 3/6],  # 5:1 or 4:2 or 3:3 ratio, then 1/6 or 2/6 or 3/6\n\t        }\n\t    # CN states and CNV calls\n", "    def get_CNV_type_from_af(self,af,slack):\n\t        maf = af if af < 0.5 else 1 - af  # minor allele frequency\n\t        upper_boundaries = 0.7\n\t        lower_boundaries = 0.3\n\t        if maf == 0.0 or maf == 1.0:\n\t            return \"DEL\"\n\t        elif upper_boundaries - slack < maf < upper_boundaries + slack or lower_boundaries - slack < maf < lower_boundaries + slack:\n\t            # if maf is beteen 0.7+/-slack (upper_boundaries) or 0.3+/-slack DUP\n\t            return \"DUP\"\n\t        else:\n", "            return \"\"\n\t    def check_af_duplication(self, cn, maf, slack) -> bool:\n\t        \"\"\"\n\t        Determines if the combination of copy number and minor allele frequency corresponds to a duplication.\n\t        :param cn: copy number\n\t        :param maf: minor allele frequency\n\t        :param slack: +/- off set from target allele frequency\n\t        :return: true = Duplication\n\t        \"\"\"\n\t        dr = cn % 2\n", "        # check for whole chromosome duplication\n\t        if dr == 0:  # duplication residual\n\t            if 0.5 - slack < maf < 0.5 + slack:  # one copy got duplicated\n\t                return True\n\t            else:\n\t                return False\n\t        # calculate upper and lower boundaries\n\t        lower_target_af = (dr / cn)  # CN = 3 -> lower_target_af = 1/3\n\t        upper_target_af = ((cn - dr) / cn)  # CN = 3 -> upper_target_af = 2/3\n\t        if lower_target_af - slack < maf < lower_target_af + slack or upper_target_af - slack < maf < upper_target_af + slack:\n", "            return True\n\t        return np.nan()\n\t    def af_cnv_call_region(self, cnv_candidates, snv_af_bed):\n\t        cnv_calls = {}\n\t        self.cnv_candidates_by_coverage = cnv_candidates\n\t        self.snv_af_bed_bgzip = f'{snv_af_bed}.gz'\n\t        pysam.tabix_compress(filename_in=snv_af_bed, filename_out=self.snv_af_bed_bgzip, force=True)\n\t        pysam.tabix_index(filename=self.snv_af_bed_bgzip, force=True, preset=\"bed\")\n\t        tabix_file = pysam.TabixFile(self.snv_af_bed_bgzip)\n\t        for each_chromosome in cnv_candidates.keys():\n", "            self.logger.debug(each_chromosome)\n\t            cnv_calls[each_chromosome] = []\n\t            for each_candidate in cnv_candidates[each_chromosome]:\n\t                af_list = []\n\t                for af_overlap_candidate in tabix_file.fetch(each_chromosome, each_candidate.start, each_candidate.end):\n\t                    [_, _, _, af_bin] = af_overlap_candidate.split(\"\\t\")\n\t                    af_list.append(float(af_bin))\n\t                af = np.mean(np.array(af_list))\n\t                if self.af_cn_state_concordance(af, each_candidate.cn_status):\n\t                    cnv_calls[each_chromosome].append(each_candidate)\n", "                else:\n\t                    self.logger.debug(f'FP,{each_candidate.chromosome},{each_candidate.start},{each_candidate.end},'\n\t                                    f'{each_candidate.cn_status},{each_candidate.type},{af}')\n\t        return cnv_calls\n\t    def af_cn_state_concordance(self, af, cn_state):\n\t        def af_cn_concordance(_af, _e_af, _af_diff_threshold):\n\t            self.logger.debug([abs(_af - _e_af), _af_diff_threshold])\n\t            if abs(_af - _e_af) <= _af_diff_threshold:\n\t                return 1\n\t            else:\n", "                return 0\n\t        score = 0\n\t        if int(cn_state) > 6:\n\t            # cn_state = \"6\"\n\t            score += 1\n\t        else:\n\t            expected_af = self.cn_state_to_af[cn_state]\n\t            if isinstance(expected_af, list):\n\t                for each_expected_af in expected_af:\n\t                    af_diff_threshold = each_expected_af * self.default_proportion_min_af\n", "                    score += af_cn_concordance(af, each_expected_af, af_diff_threshold)\n\t            else:\n\t                af_diff_threshold = expected_af*self.default_proportion_min_af if cn_state > 1 \\\n\t                    else self.af_diff_buffer_default\n\t                score += af_cn_concordance(af, expected_af, af_diff_threshold)\n\t            # if score == 0 then it is a false positive (FP) call, else we cannot decide, adn we do not decide\n\t        self.logger.debug(f'score: {score}')\n\t        return score != 0\n\t    ### DEV\n\t    def call_cnv_af(self, snv_af_df:pd.DataFrame,write_csv=False):\n", "        self.snv_af_df = snv_af_df\n\t        self.snv_af_df.columns = [\"chrom\",\"start\",\"stop\",\"af\"]\n\t        self.snv_af_df[\"cnvtype\"] = self.snv_af_df.apply(lambda row: self.get_CNV_type_from_af(row[\"af\"], 0.1), axis=1)\n\t        if write_csv:\n\t            self.logger.debug(\"writing CSV\"+ self.output_directory+\"/snv_af_df.csv\")\n\t            self.snv_af_df.to_csv(self.output_directory+\"/snv_af_df.csv\",sep=\"\\t\",index_label=False)\n\t        for each_chromosome in self.genome_info[\"chromosomes\"]:\n\t            print(each_chromosome)\n\t        pass\n"]}
{"filename": "analysis/cnv_candidate.py", "chunked_list": ["import numpy as np\n\timport logging as logger\n\tclass CNVCandidate(object):\n\t    def __init__(self, sample_origin=\"\", as_dev=False):\n\t        self.chromosome = \"\"\n\t        self.start = 0\n\t        self.end = 0\n\t        self.size = 0\n\t        self.pos = []\n\t        self.cov = []\n", "        self.type = \"\"\n\t        self.cn_status = np.nan\n\t        self.gt = \"./.\"\n\t        self.median_cov_norm = np.nan\n\t        self.size_kb = np.nan\n\t        self.het_score = float()  # makes sense from 0-1\n\t        self.as_dev = as_dev\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        self.statistics = {}\n", "        self.support_cnv_calls = {}\n\t        self.id = \"\"\n\t        self.sample_origin = sample_origin  # e.g. hg002\n\t        self.merged_sample_references = set()\n\t        self.median_cov_norm = 0.0\n\t    def push_candidates(self, chromosome, cnv_cand_list, cnv_cov_cand_list, cnv_type):\n\t        self.chromosome = chromosome\n\t        self.pos = cnv_cand_list\n\t        self.start = int(self.pos[0])\n\t        self.end = int(self.pos[-1])\n", "        self.size = self.end - self.start\n\t        self.size_kb = int((self.end - self.start) / 1000)\n\t        self.cov = cnv_cov_cand_list\n\t        [self.cn_status, self.median_cov_norm] = self.set_copy_number_status(cnv_cov_cand_list)\n\t        self.set_gt()\n\t        self.type = cnv_type\n\t    def add_candidates(self, cnv_cand_pos, cnv_cand_cov, cnv_id, cnv_merged_ids):\n\t        self.pos = list(self.pos) + list(cnv_cand_pos)\n\t        self.start = int(self.pos[0])\n\t        self.end = int(self.pos[-1])\n", "        self.size = self.end - self.start\n\t        self.size_kb = int((self.end - self.start) / 1000)\n\t        self.cov = list(self.cov) + list(cnv_cand_cov)\n\t        self.merged_sample_references.add(cnv_id)\n\t        self.merged_sample_references |= cnv_merged_ids  # \"|\" joins sets\n\t    def set_gt(self):\n\t        if self.cn_status == 0:\n\t            self.gt = \"1/1\"\n\t        elif self.cn_status == 1 or self.cn_status == 3:\n\t            self.gt = \"0/1\"\n", "        elif self.cn_status == 2:\n\t            self.gt = \"0/0\"\n\t        else:\n\t            self.gt = \"./.\"\n\t    def median_coverage_candidates_merged(self):\n\t        if len(self.cov) > 0:\n\t            self.median_cov_norm = np.nanmedian(self.cov)\n\t        else:\n\t            self.median_cov_norm = 0.0\n\t    def set_id(self, id: str):\n", "        self.id = f\"Spectre.{self.type}.{id}\"\n\t    def reinitialize_candidate_values(self) -> None:\n\t        \"\"\"\n\t        Used after loading data from .spc file\n\t        :return: None\n\t        \"\"\"\n\t        self.cn_status = self.set_copy_number_status(self.cov)[0]  # set copy number status\n\t        self.median_coverage_candidates_merged()  # median of normalized coverage\n\t        self.merged_sample_references = set(self.merged_sample_references)  # convert list to set\n\t    @staticmethod\n", "    def set_copy_number_status(candidate_coverage):\n\t        median_candidates_coverage = np.nanmedian(candidate_coverage)\n\t        if median_candidates_coverage == np.inf or median_candidates_coverage == np.nan:\n\t            return [2, 2.0]  # we are working with diploid data\n\t            # one for regular signal ... inf can not be a valid CN state\n\t        # copy number state is given by integer type conversion of the float value median coverage, e.g. 1.51-> 1\n\t        return [int(round(median_candidates_coverage, 0)), median_candidates_coverage]\n\t    # functions required to use this object as a key in a dictionary\n\t    def __hash__(self):\n\t        return hash(self.id)\n", "    def __eq__(self, other):\n\t        return hash(self.id) == hash(other.id)\n"]}
{"filename": "analysis/coverage_stats.py", "chunked_list": ["import numpy as np\n\timport logging as logger\n\tclass CoverageStatistics(object):\n\t    # should have \"get\" and \"set\" func but just use them directly\n\t    def __init__(self, as_dev=False):\n\t        # {\"average\": np.NaN, \"std_dev\": np.NaN, \"min\": np.NaN, \"max\": np.NaN}\n\t        # Stats\n\t        logger.basicConfig(level=logger.DEBUG) if as_dev else logger.basicConfig(level=logger.INFO)\n\t        self.logger = logger\n\t        self.chromosome_len = 0\n", "        self.chromosome_name = \"\"\n\t        self.average = np.NaN\n\t        self.std_dev = np.NaN\n\t        self.min = np.NaN\n\t        self.max = np.NaN\n\t        self.median = np.NaN\n\t    def print(self):\n\t        print_me = f'Statistics of chromosome {self.chromosome_name}' \\\n\t                   f'  chromosome length: {self.chromosome_len}\\n' \\\n\t                   f'  average coverage: {self.average}\\n' \\\n", "                   f'  median coverage: {self.median}\\n' \\\n\t                   f'  standard deviation: {np.round(self.std_dev, 3)}\\n' \\\n\t                   f'  min, max coverage: {np.round(self.min, 3)}, {np.round(self.max, 3)}\\n'\n\t        logger.info(print_me)\n\tclass CoverageData(object):\n\t    # should have \"get\" and \"set\" func but just use them directly\n\t    def __init__(self):\n\t        # raw data\n\t        self.coverage_raw = np.NaN\n\t        self.positions = np.NaN\n", "        self.coverage_log2 = np.NaN         # log2(x)\n\t        self.normalized_cov = np.NaN        # x/median\n\t        self.normalized_cov_ploidy = np.NaN   # x/median * 2 -> for diploid\n"]}
