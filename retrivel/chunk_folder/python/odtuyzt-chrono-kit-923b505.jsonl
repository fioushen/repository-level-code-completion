{"filename": "chronokit/__init__.py", "chunked_list": ["from . import decomposition, exponential_smoothing, preprocessing, utils"]}
{"filename": "chronokit/utils/__init__.py", "chunked_list": ["from . import vis_utils, evaluation_utils"]}
{"filename": "chronokit/utils/evaluation_utils/metrics.py", "chunked_list": ["import torch\n\tfrom chronokit.preprocessing.dataloader import DataLoader\n\t\"\"\"Performance evaluation metrics for model predictions\"\"\"\n\tdef mae(y_pred, y_true):\n\t    \"\"\"\n\t    Mean Absolute Error\n\t    Arguments:\n\t    *y_pred (array_like): Predicted values\n\t    *y_true (array_like): Ground truth values\n\t    \"\"\"\n", "    y_pred = DataLoader(y_pred).to_tensor()\n\t    y_true = DataLoader(y_true).to_tensor()      \n\t    return torch.mean(torch.abs(torch.sub(y_pred, y_true)))\n\tdef mse(y_pred, y_true):\n\t    \"\"\"\n\t    Mean Squared Error\n\t    Arguments:\n\t    *y_pred (array_like): Predicted values\n\t    *y_true (array_like): Ground truth values\n\t    \"\"\"\n", "    y_pred = DataLoader(y_pred).to_tensor()\n\t    y_true = DataLoader(y_true).to_tensor()      \n\t    return torch.mean((torch.square(torch.sub(y_pred, y_true))))\n\tdef rmse(y_pred, y_true):\n\t    \"\"\"\n\t    Root Mean Squared Error\n\t    Arguments:\n\t    *y_pred (array_like): Predicted values\n\t    *y_true (array_like): Ground truth values\n\t    \"\"\"\n", "    y_pred = DataLoader(y_pred).to_tensor()\n\t    y_true = DataLoader(y_true).to_tensor()  \n\t    return torch.sqrt(torch.mean((torch.square(torch.sub(y_pred, y_true)))))"]}
{"filename": "chronokit/utils/evaluation_utils/__init__.py", "chunked_list": ["from .metrics import * "]}
{"filename": "chronokit/utils/vis_utils/data_plots.py", "chunked_list": ["import matplotlib\n\timport matplotlib.style\n\timport matplotlib.pyplot as plt\n\tfrom chronokit.preprocessing.dataloader import DataLoader\n\tdef plot_decomp(trend, seasonal, remainder, figsize=(12,8), colors=None, style=None):\n\t    \"\"\"\n\t    Utility function for plotting time series decomposition results\n\t    Arguments:\n\t    *trend (array_like): Trend component of the decomposition\n\t    *seasonal (array_like): Seasonal component of the decomposition\n", "    *remainer (array_like): Remainders of the decomposition\n\t    *figsize (Optional[tuple]): Size of the plot\n\t    *colors (Optional[iterable]): Colors of the lines/points on the plot\n\t    *style (Optional[str]): Style of the plot 'https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html'\n\t    \"\"\"\n\t    if style:\n\t        assert(type(style) == str), \"Provide style as a string\"\n\t        matplotlib.style.use(style)\n\t    use_colors = {\"trend\": \"blue\", \"seasonal\": \"blue\", \"remainder\": \"blue\"}\n\t    if colors:\n", "        try:\n\t            iter(colors)\n\t        except TypeError:\n\t            raise TypeError(\"Provide colors as an iterable\")\n\t        if type(colors) == dict:\n\t            for key in colors:\n\t                assert(key in list(use_colors.keys())), f\"Ensure that keys in colours dictionary are {list(use_colors.keys())}\"\n\t                use_colors[key] = colors[key]\n\t        else:\n\t            for ind, c in enumerate(colors):\n", "                use_colors[list(use_colors.keys())[ind]] = c\n\t    trend = DataLoader(trend).to_numpy()\n\t    seasonal = DataLoader(seasonal).to_numpy()\n\t    remainder = DataLoader(remainder).to_numpy()\n\t    fig, axes = plt.subplots(3, 1, figsize=figsize)\n\t    ax1, ax2, ax3 = axes     \n\t    ax1.plot(range(len(trend)), trend, color=use_colors[\"trend\"])\n\t    ax1.set_ylabel(\"Trend\")\n\t    ax2.plot(range(len(seasonal)), seasonal, color=use_colors[\"seasonal\"])\n\t    ax2.set_ylabel(\"Seasonal\")\n", "    ax3.scatter(range(len(remainder)), remainder, color=use_colors[\"remainder\"])\n\t    ax3.set_ylabel(\"Remainder\")\n\t    plt.show()\n\tdef plot_train_test_split(train_data, test_data, val_data=None, figsize=(12,8), title: str =None, colors=None, style=None):\n\t    \"\"\"\n\t    Utility function for plotting train test split\n\t    Arguments:\n\t    *train_data (array_like): Training data of the split\n\t    *test_data (array_like): Test data of the split\n\t    *val_data (Optional[array_like]): Val data of the split if data is splitted as train/val/test\n", "    *figsize (Optional[tuple]): Size of the plot\n\t    *title (Optional[str]): Title of the plot\n\t    *colors (Optional[iterable]): Colors of the lines/points on the plot\n\t    *style (Optional[str]): Style of the plot 'https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html'\n\t    \"\"\"\n\t    assert (type(title) == \"str\" or title is None), \"Plot title must be a string\"\n\t    if style:\n\t        assert(type(style) == str), \"Provide style as a string\"\n\t        matplotlib.style.use(style)\n\t    use_colors = {\"train\": \"blue\", \"val\": \"orange\", \"test\": \"red\"}\n", "    if colors:\n\t        try:\n\t            iter(colors)\n\t        except TypeError:\n\t            raise TypeError(\"Provide colors as an iterable\")\n\t        if type(colors) == dict:\n\t            for key in colors:\n\t                assert(key in list(use_colors.keys())), f\"Ensure that keys in colours dictionary are {list(use_colors.keys())}\"\n\t                use_colors[key] = colors[key]\n\t        else:\n", "            for ind, c in enumerate(colors):\n\t                use_colors[list(use_colors.keys())[ind]] = c\n\t    train = DataLoader(train_data).to_numpy()\n\t    test = DataLoader(test_data).to_numpy()\n\t    if val_data:\n\t        val = DataLoader(val_data).to_numpy()\n\t        plt.figure(figsize=figsize)\n\t        plt.plot(range(len(train)), train, label=\"Train\", color=use_colors[\"train\"])\n\t        plt.plot(range(len(train), len(train)+len(val_data)), val, label=\"Validation\", color=use_colors[\"val\"])\n\t        plt.plot(range(len(train+val_data), len(train)+len(val_data)+len(test_data)), test, label=\"Test\", color=use_colors[\"test\"])\n", "        plt.legend(loc=\"best\")\n\t        plt.title(title)\n\t        plt.show()\n\t    else:\n\t        plt.figure(figsize=figsize)\n\t        plt.plot(range(len(train)), train, label=\"Train\", color=use_colors[\"train\"])\n\t        plt.plot(range(len(train), len(train)+len(test)), test, label=\"Test\", color=use_colors[\"test\"])\n\t        plt.legend(loc=\"best\")\n\t        plt.title(title)\n\t        plt.show()\n"]}
{"filename": "chronokit/utils/vis_utils/__init__.py", "chunked_list": ["from .data_plots import *\n\tfrom .model_plots import *\n"]}
{"filename": "chronokit/utils/vis_utils/model_plots.py", "chunked_list": ["import matplotlib\n\timport matplotlib.style\n\timport matplotlib.pyplot as plt\n\tfrom chronokit.preprocessing.dataloader import DataLoader\n\tfrom chronokit.utils.evaluation_utils.metrics import * \n\tdef plot_predictions(y_true, y_pred, bounds=None, pre_vals=None, figsize=(12,8), colors=None, bounds_fill_alpha=0.7, title=None, style=None, metrics=None):\n\t    \"\"\"\n\t    Utility function for plotting prediction results of the time series model\n\t    Arguments:\n\t    *y_true (array_like): Ground truth values\n", "    *y_pred (array_like): Predicted values\n\t    *bounds (Optional[iterable]): Confidence bounds for the prediction interval\n\t    *pre_vals (Optional[array_like]): Values that come before the predicted values i.e; last n-points of the training data\n\t    *figsize (Optional[tuple]): Size of the plot\n\t    *colors (Optional[iterable]): Colors of the lines/points on the plot\n\t    *bounds_fill_alpha (Optional[float]): Alpha for the transparency of the filled values between confidence bounds\n\t    *title (Optional[str]): Title of the plot\n\t    *style (Optional[str]): Style of the plot 'https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html'\n\t    *metrics (Optional[iterable]): Evaluation metrics to use for the predictions to report on the plot\n\t    \"\"\"\n", "    y_true = DataLoader(y_true).to_numpy()\n\t    y_pred = DataLoader(y_pred).to_numpy()\n\t    use_colors = {\"y_true\": \"blue\", \"y_pred\": \"orange\", \"bounds\": \"gray\", \"pre_vals\": \"black\"}\n\t    if colors:\n\t        try:\n\t            iter(colors)\n\t        except TypeError:\n\t            raise TypeError(\"Provide colors as an iterable\")\n\t        if type(colors) == dict:\n\t            for key in colors:\n", "                assert(key in list(use_colors.keys())), f\"Ensure that keys in colours dictionary are {list(use_colors.keys())}\"\n\t                use_colors[key] = colors[key]\n\t        else:\n\t            for ind, c in enumerate(colors):\n\t                use_colors[list(use_colors.keys())[ind]] = c\n\t    error_bounds = None\n\t    if bounds:\n\t        try:\n\t            iter(bounds)\n\t        except TypeError:\n", "            raise TypeError(\"Provide bounds as an iterable of length 2\")\n\t        assert (len(bounds) == 2), \"Provide bounds as an iterable of length 2\"\n\t        if type(bounds) == dict:\n\t            assert (list(bounds.keys()) == [\"upper\", \"lower\"]), \"Provide bounds dictionary keys as ['upper', 'lower']\"\n\t            for val in list(bounds.values()):\n\t                assert (len(val) == len(y_pred)), \"Length of bounds must match length of predictions\"\n\t            error_bounds = {\"upper\": DataLoader(bounds[\"upper\"]).to_numpy(), \"lower\": DataLoader(bounds[\"lower\"]).to_numpy()}\n\t        else:\n\t            for val in bounds:\n\t                assert (len(val) == len(y_pred)), \"Length of bounds must match length of predictions\"\n", "            error_bounds = {\"upper\": DataLoader(bounds[0]).to_numpy(), \"lower\": DataLoader(bounds[1]).to_numpy()}\n\t    plt_metrics = None\n\t    if metrics:\n\t        plt_metrics = {}\n\t        try:\n\t            iter(metrics)\n\t            if type(metrics) == dict:\n\t                raise TypeError(\"Metrics argument cannot be a dictionary\")\n\t        except TypeError:\n\t            raise TypeError(\"Provide metrics as an iterable of length 2\")\n", "        for i in metrics:\n\t            assert (type(i) == str), \"Provide metrics as an iterable with string entries\"\n\t            assert (i in [\"rmse\", \"mse\", \"mae\"]), \"Supported metrics are: ['rmse', 'mse' and 'mae']\"\n\t            if i == \"rmse\":\n\t                plt_metrics[\"RMSE\"] = rmse(y_pred, y_true).item()\n\t            if i == \"mse\":\n\t                plt_metrics[\"MSE\"] = mse(y_pred, y_true).item()\n\t            if i == \"mae\":\n\t                plt_metrics[\"MAE\"] = mae(y_pred, y_true).item()\n\t    assert (type(title) == str or title is None), \"Plot title must be a string\"\n", "    if style:\n\t        assert(type(style) == str), \"Provide style as a string\"\n\t        matplotlib.style.use(style)\n\t    plt.figure(figsize=figsize)\n\t    if pre_vals is not None:\n\t        pre_vals = DataLoader(pre_vals).to_numpy()\n\t        main_plt_range = range(len(pre_vals), len(pre_vals)+len(y_pred))\n\t        plt.plot(range(len(pre_vals)), pre_vals, color=use_colors[\"pre_vals\"])\n\t    else:\n\t        main_plt_range = range(len(y_pred))\n", "    plt.plot(main_plt_range, y_true, color=use_colors[\"y_true\"], label=\"Y True\")\n\t    plt.plot(main_plt_range, y_pred, color=use_colors[\"y_pred\"], label=\"Y Predicted\")\n\t    if error_bounds:\n\t        plt.fill_between(main_plt_range, error_bounds[\"upper\"], error_bounds[\"lower\"], \n\t                         color=use_colors[\"bounds\"], alpha=bounds_fill_alpha, label=\"Prediction Error Bounds\")\n\t    if plt_metrics:\n\t        append_title = \"\"\n\t        for metric in plt_metrics:\n\t            score = plt_metrics[metric]\n\t            append_title += metric + f\":{score:.3f} \"\n", "        if title:\n\t            title = title + \"\\n\" + append_title\n\t        else:\n\t            title = append_title\n\t    plt.title(title)\n\t    plt.legend(loc=\"best\")\n\t    plt.show()\n"]}
{"filename": "chronokit/preprocessing/dataloader.py", "chunked_list": ["import numpy as np\n\timport pandas as pd\n\timport torch\n\tclass DataLoader:\n\t    def __init__(self, data):\n\t        \"\"\" A class to transform given data into desirable types\n\t            Currently accepted data types are: 'pd.DataFrame', 'pd.Series', 'np.ndarray', 'torch.Tensor\"\"\"\n\t        self.accepted_types = [pd.DataFrame,\n\t                               pd.Series,\n\t                               np.ndarray,\n", "                               torch.Tensor]\n\t        self.data_type = type(data)\n\t        assert (self.data_type in self.accepted_types), f\"{type(data).__name__} is not an accepted data type\"\n\t        if self.data_type == pd.DataFrame:\n\t            self.original_df = data\n\t            self.data = self.organize_df(data)\n\t        else:\n\t            self.data = data\n\t    def organize_df(self, df: pd.DataFrame):\n\t        \"\"\" Method for organizing a possibly unorganized dataframe while also making sure all entries are convertible to tensors\n", "            and keeping track of the operations done on the original dataframe\"\"\"\n\t        self.organized_df = df.copy()\n\t        self.operations = []\n\t        self.dates = None\n\t        self.data_columns = list(df.columns)\n\t        for ind, dtype in enumerate(df.dtypes):\n\t            col = df.dtypes.index[ind]\n\t            if dtype == object:\n\t                try:\n\t                    self.dates = pd.to_datetime(df[col])\n", "                    self.operations.append(f\"Turned entries of column'{col}' into datetime\")\n\t                    self.data_columns.remove(col)\n\t                    self.organized_df.pop(col)\n\t                    self.organized_df = self.organized_df.set_index(self.dates)\n\t                    self.organized_df.index.name = \"Dates\"\n\t                    self.operations.append(\"Set dates as an index\")\n\t                except:\n\t                    try:\n\t                        float_vals = df[col].values.astype(np.float32)\n\t                        self.organized_df[col] = float_vals\n", "                        self.operations.append(f\"Turned {col} entries into floats\")\n\t                    except:\n\t                        raise Exception(f\"Could not handle entries of column: '{col}' \")\n\t        return self.organized_df.values\n\t    def to_tensor(self):\n\t        \"\"\"Turn self.data into tensors\"\"\"\n\t        if type(self.data) == torch.Tensor:\n\t            return self.data\n\t        else:\n\t            return torch.tensor(self.data)\n", "    def to_numpy(self):\n\t        \"\"\"Turn self.data into numpy arrays\"\"\"\n\t        if type(self.data) == np.ndarray:\n\t            return self.data\n\t        else:\n\t            return np.array(self.data)\n"]}
{"filename": "chronokit/preprocessing/data_transforms.py", "chunked_list": ["import numpy as np\n\timport pandas as pd\n\timport torch\n\tfrom .dataloader import DataLoader\n\tfrom scipy.stats import boxcox_normmax\n\tclass DataTransform:\n\t    def __init__(self):\n\t        \"\"\"Base class for all data transformation class to inherit from\"\"\"\n\t        pass\n\t    def transform_assert(self, loader: DataLoader, axis: int, scales: dict):\n", "        \"\"\"Make necessary assertions for transforming the data\"\"\"\n\t        for scale_key in scales:\n\t            scale_dict = scales[scale_key]\n\t            assert(type(scale_dict) == dict), f\"Provide {scale_key} as a dict\"\n\t        assert (loader.to_tensor().numpy().size != 0), \"Size of data must be > 0\"\n\t        if loader.data_type == pd.DataFrame:\n\t            data_names = list(loader.organized_df.columns)\n\t            for scale_dict in list(scales.values()):\n\t                if scale_dict != {}:                \n\t                    assert (len(list(scale_dict.keys())) == len(data_names)), f\"Provide same amount of entries as columns\"\n", "                    assert (set(list(scale_dict.keys())) == set(data_names)), \"Provide with the same keys as column names\"\n\t        else:\n\t            assert (loader.data.ndim <= 2), \"Dimension of the data must be <= 2\"\n\t            assert (axis in [0, 1, -1, -2]), f\"{axis} is not a valid axis\"\n\t            if loader.data.ndim == 1:\n\t                assert (axis in [0,-1]), f\"{axis} is not a valid axis of data of ndim == 1\"\n\t                for scale_key in scales:    \n\t                    scale_dict = scales[scale_key]\n\t                    if scale_dict != {}:\n\t                        assert (list(scale_dict.keys()) == [scale_key]), \"For data with ndim == 1, scales should be\\\n", " provided as {}\".format({f'{scale_key}': 'value'})\n\t            else:\n\t                hmap = {0: \"row\", 1: \"col\", -1: \"col\", -2: \"row\"}\n\t                data_names = [f\"{hmap[axis]}{i}\" for i in range(loader.data.shape[1-  axis % 2])]\n\t                for scale_dict in list(scales.values()):\n\t                    if scale_dict != {}:\n\t                        assert (len(list(scale_dict.keys())) == len(data_names)), f\"Provide same amount of entries as {hmap[axis]}s\"\n\t                        assert (set(list(scale_dict.keys())) == set(data_names)), f\"Provide keys as {hmap[axis]}0 for {hmap[axis]} of index 0 etc...\"\n\t    def inv_transform_assert(self, loader: DataLoader, names, scales: dict):\n\t        \"\"\"Make necessary assertions to inverse transforming the data\"\"\"\n", "        assert(type(names) == list), \"Provide names argument as a list\"\n\t        try:\n\t            if self.transformed_axis:\n\t                pass\n\t        except NameError:\n\t            raise NameError(\"Must call '.transform()' before calling '.inverse_transform()'\")\n\t        assert(type(names) == list), \"Provide names argument as a list\"\n\t        assert (loader.to_tensor().numpy().size != 0), \"Size of data must be > 0\"\n\t        transform_data = loader.to_tensor()\n\t        if names != []:\n", "            for scale_dict in list(scales.values()):\n\t                for name in names:\n\t                    assert(name in list(scale_dict())), f\"{name} was not in transformed data\"\n\t        else:\n\t            assert (len(loader.to_tensor().shape) == 2), \"Data must be 2 dimensional if the names argument is not provided\"\n\t            for scale_dict in list(scales.values()):\n\t                assert (loader.data.shape[1-  self.transformed_axis % 2] == len(list(scale_dict.keys()))), f\"Expecting\\\n\t size of axis {self.transformed_axis} = {len(list(scale_dict))} if the names argument is not provided\"\n\tclass BoxCox(DataTransform):\n\t    def __init__(self):\n", "        \"\"\"Box-Cox transformation for time series data\"\"\"\n\t        super().__init__()\n\t        self.lambdas = {}\n\t    def transform(self, data, axis=0, lambda_values: dict = {}):\n\t        \"\"\"\n\t        Transform given data with box-cox method\n\t        Arguments:\n\t        *data (array_like): Time series data to transform\n\t        *axis (int): Axis to perform the transformation on\n\t        *lambda_values (Optional[dict]): Lambda values for the transformation; will be estimated if given as an empty dict \n", "        \"\"\"\n\t        loader = DataLoader(data)\n\t        self.transform_assert(loader, axis, scales={\"lambda\": lambda_values})\n\t        if loader.data_type == pd.DataFrame:\n\t            data_names = list(loader.organized_df.columns)\n\t            if lambda_values == {}:\n\t                lambda_values = {name: None for name in data_names}\n\t        else:\n\t            if loader.data.ndim == 1:\n\t                if lambda_values == {}:\n", "                    lambda_values = {\"lambda\": None}\n\t            else:\n\t                hmap = {0: \"col\", 1: \"row\", -1: \"row\", -2: \"col\"}\n\t                data_names = [f\"{hmap[axis]}{i}\" for i in range(loader.data.shape[1-  axis % 2])]\n\t                if lambda_values == {}:\n\t                    lambda_values = {name: None for name in data_names}\n\t        self.transformed_axis = axis\n\t        transform_data = loader.to_tensor()\n\t        transformed = np.zeros(transform_data.shape)\n\t        for ind in range(len(data_names)):\n", "            if transform_data.ndim == 1:\n\t                current_data = transform_data\n\t            elif axis in [0,-2]:\n\t                current_data = transform_data[:, ind]\n\t            else:\n\t                current_data = transform_data[ind, :]\n\t            name = data_names[ind]\n\t            lambd = lambda_values[name]\n\t            boxcoxed = self.__box_cox(current_data, lambd, name)\n\t            if transform_data.ndim == 1:\n", "                transformed = boxcoxed\n\t            elif axis in [0,-2]:\n\t                transformed[:, ind] = boxcoxed\n\t            else:\n\t                transformed[ind, :] = boxcoxed\n\t        return transformed\n\t    def inverse_transform(self, data, names: list = []):\n\t        \"\"\"\n\t        Inverse transform given data\n\t        Arguments:\n", "        *data (array_like): Time series data to inverse transform\n\t        *names (Optional[list]): Keys for data to inverse transform if partial transformation is desired  \n\t        \"\"\"\n\t        loader = DataLoader(data)\n\t        self.inv_transform_assert(loader, names, scales={\"lambda\": self.lambdas})\n\t        transform_data = loader.to_tensor()\n\t        transformed = np.zeros(transform_data.shape)\n\t        if names == []:\n\t            names = list(self.lambdas.keys())\n\t        for ind in range(len(names)):\n", "            if transform_data.ndim == 1:\n\t                current_data = transform_data\n\t            elif self.transformed_axis in [0,-2]:\n\t                current_data = transform_data[:, ind]\n\t            else:\n\t                current_data = transform_data[ind, :]\n\t            name = names[ind]\n\t            lambd = self.lambdas[name]\n\t            inversed = torch.exp(current_data) if lambd == 0 else torch.pow(torch.add(torch.mul(lambd, current_data), 1), 1/lambd)\n\t            if transform_data.ndim == 1:\n", "                transformed = inversed\n\t            elif self.transformed_axis in [0,-2]:\n\t                transformed[:, ind] = inversed\n\t            else:\n\t                transformed[ind, :] = inversed\n\t        return transformed\n\t    def __box_cox(self, data, lambd=None, data_name=\"col0\"):\n\t        \"\"\"Perform the box-cox transformation\"\"\"\n\t        box_coxed = data.detach().clone()\n\t        if lambd:\n", "            assert(type(lambd) == float or type(lambd) == int), \"Provide lambda value as a float\"\n\t        else:  \n\t            lambd = boxcox_normmax(box_coxed.numpy())\n\t        box_coxed = torch.log(box_coxed) if lambd == 0 else torch.div(torch.sub(torch.pow(box_coxed, lambd), 1), lambd)\n\t        self.lambdas[data_name] = lambd\n\t        return box_coxed\n\tclass StandardScaling(DataTransform):\n\t    def __init__(self):\n\t        \"\"\"Standard Scaling for time series data\"\"\"\n\t        self.locations = {}\n", "        self.scales = {}\n\t    def transform(self, data, axis=0, locations: dict = {}, scales: dict = {}):\n\t        \"\"\"\n\t        Standard scale the given data\n\t        Arguments:\n\t        *data (array_like): Time series data to transform\n\t        *axis (int): Axis to perform the transformation on\n\t        *locations (Optional[dict]): Location values to be used for scaling the data; will be taken as the mean if not given\n\t        *scales (Optional[dict]): Scale values to be used for scaling the data; will be taken as the std if not given\n\t        \"\"\"\n", "        loader = DataLoader(data)\n\t        self.transform_assert(loader, axis, scales={\"location\": locations, \"scale\": scales})\n\t        if loader.data_type == pd.DataFrame:\n\t            data_names = list(loader.organized_df.columns)\n\t            if locations == {}:\n\t                locations = {name: loader.organized_df[name].mean() for name in data_names}\n\t            if scales == {}:\n\t                scales = {name: loader.organized_df[name].std() for name in data_names}\n\t                for s in list(scales.values()):\n\t                    if s == 0:\n", "                        raise ValueError(\"cannot scale data with std = 0\")\n\t        else:\n\t            if loader.data.ndim == 1:\n\t                if locations == {}:\n\t                    locations = {\"loc\": loader.to_tensor().mean().item()}\n\t                if scales == {}:\n\t                    scales = {\"scale\": loader.to_tensor().std().item()}\n\t                    for s in list(scales.values()):\n\t                        if s == 0:\n\t                            raise ValueError(\"cannot scale data with std = 0\")\n", "            else:\n\t                hmap = {0: \"row\", 1: \"col\", -1: \"col\", -2: \"row\"}\n\t                data_names = [f\"{hmap[axis]}{i}\" for i in range(loader.data.shape[1-  axis % 2])]\n\t                if locations == {}:\n\t                    locs = loader.to_tensor().mean(axis)\n\t                    locations = {data_names[ind]: locs[ind].item() for ind in range(len(data_names))}\n\t                if scales == {}:\n\t                    stds = loader.to_tensor().std(axis)\n\t                    scales = {data_names[ind]: stds[ind].item() for ind in range(len(data_names))}\n\t                    for s in list(scales.values()):\n", "                        if s == 0:\n\t                            raise ValueError(\"cannot scale data with std = 0\")\n\t        self.locations = locations\n\t        self.scales = scales\n\t        self.transformed_axis = axis\n\t        transform_data = loader.to_tensor()\n\t        transformed = np.zeros(transform_data.shape)\n\t        for ind in range(len(data_names)):\n\t            if transform_data.ndim == 1:\n\t                current_data = transform_data\n", "            elif axis in [0,-2]:\n\t                current_data = transform_data[:, ind]\n\t            else:\n\t                current_data = transform_data[ind, :]\n\t            name = data_names[ind]\n\t            mu = self.locations[name]\n\t            sigma = self.scales[name]\n\t            x = current_data.detach().clone()\n\t            standard_scaled = torch.div(torch.sub(x,mu), sigma)\n\t            if transform_data.ndim == 1:\n", "                transformed = standard_scaled\n\t            elif axis in [0,-2]:\n\t                transformed[:, ind] = standard_scaled\n\t            else:\n\t                transformed[ind, :] = standard_scaled\n\t        return transformed\n\t    def inverse_transform(self, data, names: list = []):\n\t        \"\"\"\n\t        Inverse transform given data\n\t        Arguments:\n", "        *data (array_like): Time series data to transform\n\t        *names (Optional[list]): Keys for data to inverse transform if partial transformation is desired  \n\t        \"\"\"\n\t        loader = DataLoader(data)\n\t        self.inv_transform_assert(loader, names, scales={\"location\": self.locations, \"scale\": self.scales})\n\t        transform_data = loader.to_tensor()\n\t        transformed = np.zeros(transform_data.shape)\n\t        for ind in range(len(names)):\n\t            if transform_data.ndim == 1:\n\t                current_data = transform_data\n", "            elif self.transformed_axis in [0,-2]:\n\t                current_data = transform_data[:, ind]\n\t            else:\n\t                current_data = transform_data[ind, :]\n\t            name = names[ind]\n\t            mu = self.locations[name]\n\t            sigma = self.scales[name]\n\t            x = current_data.detach().clone()\n\t            inversed = torch.add(torch.mul(x, sigma), mu)\n\t            if transform_data.ndim == 1:\n", "                transformed = inversed\n\t            elif self.transformed_axis in [0,-2]:\n\t                transformed[:, ind] = inversed\n\t            else:\n\t                transformed[ind, :] = inversed\n\t        return transformed\n\tclass MinMaxScaling(DataTransform):\n\t    def __init__(self, feature_range=(0,1)):\n\t        \"\"\"\n\t        MinMax Scaling for time series data\n", "        Arguments:\n\t        *feature_range (Optional[iterable]): Value bounds for the data to be scaled on\n\t        \"\"\"\n\t        try:\n\t            iter(feature_range)\n\t        except TypeError:\n\t            raise TypeError(\"Provide feature_range as an iterable\")\n\t        assert(len(feature_range) == 2), \"Provide feature_range as an iterable of length 2\"\n\t        self.lb, self.ub = feature_range\n\t        assert(self.ub > self.lb), \"Provide feature_range as (a,b) where b > a\"\n", "        self.mins = {}\n\t        self.maxes = {}\n\t    def transform(self, data, axis=0):\n\t        \"\"\"\n\t        MinMax scale the given data\n\t        Arguments:\n\t        *data (array_like): Time series data to transform\n\t        *axis (int): Axis to perform the transformation on\n\t        \"\"\"\n\t        loader = DataLoader(data)\n", "        self.transform_assert(loader, axis, scales={})\n\t        if loader.data_type == pd.DataFrame:\n\t            data_names = list(loader.organized_df.columns)\n\t            mins = {name: loader.organized_df[name].min() for name in data_names}\n\t            maxes = {name: loader.organized_df[name].max() for name in data_names}\n\t            for key in mins:\n\t                if mins[key] == maxes[key]:\n\t                    raise ValueError(\"Cannot scale with min(data)=max(data)\")\n\t        else:\n\t            if loader.data.ndim == 1:\n", "                mins = {\"min\": loader.to_numpy().min()}\n\t                maxes = {\"max\": loader.to_numpy().max()}\n\t                if mins[\"min\"] == maxes[\"max\"]:\n\t                    raise ValueError(\"Cannot scale with min(data)=max(data)\")\n\t            else:\n\t                hmap = {0: \"row\", 1: \"col\", -1: \"col\", -2: \"row\"}\n\t                data_names = [f\"{hmap[axis]}{i}\" for i in range(loader.data.shape[1-  axis % 2])]\n\t                mins_ = loader.to_tensor().min(axis)\n\t                mins = {data_names[ind]: mins_[ind] for ind in range(len(data_names))}\n\t                maxes_ = loader.to_tensor().max(axis)\n", "                maxes = {data_names[ind]: maxes_[ind] for ind in range(len(data_names))}\n\t                for key in mins:\n\t                    if mins[key] == maxes[key]:\n\t                        raise ValueError(\"Cannot scale with min(data)=max(data)\")\n\t        self.mins = mins\n\t        self.maxes = maxes\n\t        self.transformed_axis = axis\n\t        transform_data = loader.to_tensor()\n\t        transformed = np.zeros(transform_data.shape)\n\t        for ind in range(len(data_names)):\n", "            if transform_data.ndim == 1:\n\t                current_data = transform_data\n\t            elif axis in [0,-2]:\n\t                current_data = transform_data[:, ind]\n\t            else:\n\t                current_data = transform_data[ind, :]\n\t            name = data_names[ind]\n\t            xmin = self.mins[name]\n\t            xmax = self.maxes[name]\n\t            x = current_data.detach().clone()\n", "            minmax_scaled = torch.div(torch.sub(x,xmin), torch.sub(xmax, xmin))\n\t            minmax_scaled = torch.add(torch.mul(minmax_scaled, (self.ub-self.lb)), self.lb)\n\t            if transform_data.ndim == 1:\n\t                transformed = minmax_scaled\n\t            elif axis in [0,-2]:\n\t                transformed[:, ind] = minmax_scaled\n\t            else:\n\t                transformed[ind, :] = minmax_scaled\n\t        return transformed\n\t    def inverse_transform(self, data, names: list = []):\n", "        \"\"\"\n\t        Inverse transform given data\n\t        Arguments:\n\t        *data (array_like): Time series data to transform\n\t        *names (Optional[list]): Keys for data to inverse transform if partial transformation is desired  \n\t        \"\"\"\n\t        loader = DataLoader(data)\n\t        self.inv_transform_assert(loader, names, scales={})\n\t        transform_data = loader.to_tensor()\n\t        transformed = np.zeros(transform_data.shape)\n", "        for ind in range(len(names)):\n\t            if transform_data.ndim == 1:\n\t                current_data = transform_data\n\t            elif self.transformed_axis in [0,-2]:\n\t                current_data = transform_data[:, ind]\n\t            else:\n\t                current_data = transform_data[ind, :]\n\t            name = names[ind]\n\t            xmin = self.mins[name]\n\t            xmax = self.maxes[name]\n", "            x = current_data.detach().clone()\n\t            inversed = torch.div(torch.add(x, self.lb), (self.ub-self.lb))\n\t            inversed = torch.add(torch.mul(inversed, torch.sub(xmax-xmin)), xmin)\n\t            if transform_data.ndim == 1:\n\t                transformed = inversed\n\t            elif self.transformed_axis in [0,-2]:\n\t                transformed[:, ind] = inversed\n\t            else:\n\t                transformed[ind, :] = inversed"]}
{"filename": "chronokit/preprocessing/__init__.py", "chunked_list": ["from .dataloader import *\n\tfrom .data_transforms import *"]}
{"filename": "chronokit/decomposition/__init__.py", "chunked_list": ["from .decompositions import *\n"]}
{"filename": "chronokit/decomposition/decompositions.py", "chunked_list": ["from chronokit.preprocessing.dataloader import DataLoader\n\tfrom chronokit.utils.vis_utils import plot_decomp\n\timport numpy as np\n\timport pandas as pd\n\tdef classical_decomposition(data, seasonal_period, method = 'add', show = True):\n\t    \"\"\"\n\t    Classical Decomposition for univariate time series data\n\t    Arguments:\n\t    *data (array_like): Time series data to perform decomposition on\n\t    *seasonal_period (int): Seasonal period of the given data\n", "    *method (Optional[str]): Decomposition method to be used; \"add\" or \"mul\"\n\t    *show (Optional[bool]): Whether to plot the decomposition results\n\t    Chapter 6.3 of the textbook is taken as a reference:\n\t    'Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n\t    and practice. OTexts, 2014.'\n\t    \"\"\"\n\t    data = DataLoader(data).to_numpy().copy()\n\t    if data.ndim >= 1:\n\t        data = np.squeeze(data)\n\t    number_of_cycles = len(data) // seasonal_period\n", "    assert (number_of_cycles >= 2), \"Data must have at least 2 full seasonal cycles\"\n\t    # Computing the trend-cycle component using moving averages\n\t    trend = pd.Series(data).rolling(seasonal_period,center=True).mean()\n\t    if seasonal_period % 2 == 0:\n\t        trend = trend.shift(-1).rolling(2).mean()\n\t    # Detrending\n\t    if method == 'add':\n\t        detrended = data - trend.values\n\t    elif method == 'mul':\n\t        detrended = data / trend.values\n", "    # Calculating the seasonal component\n\t    seasonal = np.zeros(shape=(seasonal_period, number_of_cycles))*np.nan\n\t    for i in range(0, number_of_cycles):\n\t            seasonal[:, i] = detrended[i*seasonal_period:(i+1)*seasonal_period]\n\t    seasonal = np.nanmean(seasonal, axis=1)\n\t    # Putting seasonality component in a numpy array same length as the original data\n\t    seasonal = np.array([seasonal[i%seasonal_period] for i in range(len(data))])\n\t    # Deseasoning (Calculating remainder)\n\t    if method == 'add' :\n\t        remainder = detrended - seasonal\n", "    elif method == 'mul':\n\t        remainder = detrended / seasonal\n\t    if show:\n\t        plot_decomp(trend, seasonal, remainder)\n\t    return trend, seasonal, remainder\n"]}
{"filename": "chronokit/exponential_smoothing/model.py", "chunked_list": ["import numpy as np\n\timport torch\n\tfrom scipy.optimize import least_squares\n\timport pandas as pd\n\tfrom chronokit.preprocessing.dataloader import DataLoader\n\tfrom .initialization import get_init_method, get_smooth_method\n\timport scipy.stats as stats\n\tclass Model():\n\t    def __init__(self,dep_var, **kwargs):\n\t        \"\"\"\n", "        Base model class for all model classes to inherit from.\n\t        Child classes are expected to implement their own .fit() and .predict() methods\n\t        \"\"\"\n\t        self.dep_var = DataLoader(dep_var).to_tensor()\n\t        self.set_kwargs(kwargs)\n\t    def set_allowed_kwargs(self, kwargs: list):\n\t        \"\"\"This function sets the allowed keyword arguments for the model.\"\"\"\n\t        self.allowed_kwargs = kwargs\n\t    def __check_kwargs(self, kwargs: dict):\n\t          \"\"\"This function checks if the keyword arguments are valid.\"\"\"\n", "          for (k,v) in kwargs.items():\n\t              if k not in self.allowed_kwargs:\n\t                  raise ValueError(\"{key} is not a valid keyword for this model\".format(key = k))\n\t    def set_kwargs(self, kwargs: dict):\n\t        \"\"\"This function sets the keyword arguments for the model.\"\"\"\n\t        self.__check_kwargs(kwargs)\n\t        for (k,v) in kwargs.items():\n\t            self.__setattr__(k,v)\n\tclass Smoothing_Model(Model):\n\t    def __init__(self, dep_var, trend=None,  seasonal=None,  seasonal_periods=None, damped=False, initialization_method=\"heuristic\", **kwargs):\n", "        \"\"\"\n\t        Base class for exponential smoothing methods.\n\t        All smoothing methods inherit from this class and is used for parameter initialization.\n\t        Arguments:\n\t        *dep_var (array_like): Univariate time series data\n\t        *trend (Optional[str]): Trend component; None or \"add\"\n\t        *seasonal (Optional[str]): Seasonal component; None, \"add\" or \"mul\"\n\t        *seasonal_periods (Optional[int]): Cyclic period of the seasonal component; int or None if seasonal is None\n\t        *damped (bool): Damp factor of the trend component; False if trend is None\n\t        *initialization_method (str): Initialization method to use for the model parameters; \"heuristic\" or \"mle\"\n", "        Keyword Arguments:\n\t        ** alpha (float): Smoothing parameter for level component; takes values in (0,1)\n\t        ** beta (float): Smoothing parameter for trend component; takes values in (0,1)\n\t        ** phi (float): Damp factor for trend component; takes values in (0,1]\n\t        ** gamma (float): Smoothing parameter for seasonal component; takes values in (0,1)\n\t        All of the smoothing methods have been written as the below textbook as a reference:\n\t        'Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n\t        and practice. OTexts, 2014.'\n\t        \"\"\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n", "        super().__init__(dep_var, **kwargs)\n\t        self.trend = trend\n\t        self.damped = damped\n\t        self.seasonal = seasonal\n\t        self.seasonal_periods = seasonal_periods\n\t        self.init_method = initialization_method\n\t        self.method = get_smooth_method(error=None, trend=trend, damped=damped, seasonal=seasonal)\n\t        self.params = {\"alpha\": 0.1, \"beta\": 0.01, \"gamma\": 0.01, \"phi\": 0.99}\n\t        self.init_components = {\"level\": None, \"trend\": None, \"seasonal\": None}\n\t    def __estimate_params(self, init_components, params):\n", "        \"\"\"Estimate the best parameters to use during fitting and forecasting for the smoothing model\"\"\"\n\t        def func(x):\n\t            if self.dep_var.ndim == 1:\n\t                dep_var = torch.unsqueeze(self.dep_var, axis=-1)\n\t            else:\n\t                dep_var = self.dep_var\n\t            errs = self.method(dep_var, init_components=init_components, params=x)\n\t            return np.mean(np.square(np.array(errs)))\n\t        estimated_params = least_squares(fun=func, x0 = params, bounds=(0,1)).x\n\t        return estimated_params\n", "    def initialize_params(self, initialize_params):\n\t        \"\"\"Initialize the components and the parameters to use during fitting and forecasting for the smoothing model\"\"\"\n\t        self.initial_level, self.initial_trend, self.initial_seasonals = get_init_method(method=self.init_method)(self.dep_var,trend=self.trend, \n\t                                                                                                                  seasonal=self.seasonal, \n\t                                                                                                                  seasonal_periods=self.seasonal_periods)\n\t        self.init_components[\"level\"] = self.initial_level,\n\t        self.init_components[\"trend\"] = self.initial_trend,\n\t        self.init_components[\"seasonal\"] = np.expand_dims(self.initial_seasonals, axis=-1)\n\t        init_params = {param: self.params[param] for param in initialize_params}\n\t        params = self.__estimate_params(\n", "                        init_components = [self.initial_level, self.initial_trend, self.initial_seasonals, self.seasonal_periods],\n\t                        params = list(init_params.values()))\n\t        for index, param in enumerate(params):\n\t            init_params[list(init_params.keys())[index]] = param\n\t        for param in self.params:\n\t            if param in init_params:\n\t                self.params[param] = init_params[param]\n\t        if not self.damped:\n\t            self.params[\"phi\"] = 1\n\t    def fit(self):\n", "        #This function will be overriden by the child class.\n\t        raise NotImplementedError(\"This function is not implemented yet.\")\n\t    def predict(self, h: int):\n\t        # This function will be overriden by the child class.\n\t        raise NotImplementedError(\"This function is not implemented yet.\")\n\tclass ETS_Model(Model):\n\t    def __init__(self, dep_var, error_type=\"add\", trend=None,  seasonal=None, seasonal_periods=None, damped=False, initialization_method=\"heuristic\", **kwargs):\n\t        \"\"\"\n\t        Base class for ETS models\n\t        All smoothing methods inherit from this class and is used for parameter initialization.\n", "        Arguments:\n\t        *dep_var (array_like): Univariate time series data\n\t        *error_type (str): Type of error of the ETS model; \"add\" or \"mul\"\n\t        *trend (Optional[str]): Trend component; None or \"add\"\n\t        *seasonal (Optional[str]): Seasonal component; None, \"add\" or \"mul\"\n\t        *seasonal_periods (Optional[int]): Cyclic period of the seasonal component; int or None if seasonal is None\n\t        *damped (bool): Damp factor of the trend component; False if trend is None\n\t        *initialization_method (str): Initialization method to use for the model parameters; \"heuristic\" or \"mle\"\n\t        Keyword Arguments:\n\t        ** alpha (float): Smoothing parameter for level component; takes values in (0,1)\n", "        ** beta (float): Smoothing parameter for trend component; takes values in (0,1)\n\t        ** phi (float): Damp factor for trend component; takes values in (0,1]\n\t        ** gamma (float): Smoothing parameter for seasonal component; takes values in (0,1)\n\t        All of the smoothing methods have been written as the below textbook as a reference:\n\t        'Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n\t        and practice. OTexts, 2014.'\n\t        \"\"\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var,  **kwargs)\n\t        self.trend = trend\n", "        self.damped = damped\n\t        self.seasonal = seasonal\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = error_type\n\t        self.init_method = initialization_method\n\t        self.method = get_smooth_method(error=error_type, trend=trend, damped=damped, seasonal=seasonal)\n\t        self.params = {\"alpha\": 0.1, \"beta\": 0.01, \"gamma\": 0.01, \"phi\": 0.99}\n\t        self.init_components = {\"level\": None, \"trend\": None, \"seasonal\": None}\n\t    def __estimate_params(self, init_components, params):\n\t        \"\"\"Estimate the best parameters to use during fitting and forecasting for the smoothing model\"\"\"\n", "        def func(x):\n\t            if self.dep_var.ndim == 1:\n\t                dep_var = torch.unsqueeze(self.dep_var, axis=-1)\n\t            else:\n\t                dep_var = self.dep_var\n\t            errs = self.method(dep_var, init_components=init_components, params=x)\n\t            return np.mean(np.square(np.array(errs)))\n\t        estimated_params = least_squares(fun=func, x0 = params, bounds=(0,1)).x\n\t        return estimated_params\n\t    def initialize_params(self, initialize_params):\n", "        \"\"\"Initialize the components and the parameters to use during fitting and forecasting for the smoothing model\"\"\"\n\t        self.initial_level, self.initial_trend, self.initial_seasonals = get_init_method(method=self.init_method)(self.dep_var,trend=self.trend, \n\t                                                                                                                  seasonal=self.seasonal, \n\t                                                                                                                  seasonal_periods=self.seasonal_periods)\n\t        self.init_components[\"level\"] = self.initial_level,\n\t        self.init_components[\"trend\"] = self.initial_trend,\n\t        self.init_components[\"seasonal\"] = np.expand_dims(self.initial_seasonals, axis=-1)\n\t        init_params = {param: self.params[param] for param in initialize_params}\n\t        params = self.__estimate_params(\n\t                        init_components = [self.initial_level, self.initial_trend, self.initial_seasonals, self.seasonal_periods],\n", "                        params = list(init_params.values()))\n\t        for index, param in enumerate(params):\n\t            init_params[list(init_params.keys())[index]] = param\n\t        for param in self.params:\n\t            if param in init_params:\n\t                self.params[param] = init_params[param]\n\t        if not self.damped:\n\t            self.params[\"phi\"] = 1\n\t    def calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the confidence level to be used for prediction intervals\"\"\"\n", "        return round(stats.norm.ppf(1 - ((1 - conf) / 2)), 2)\n\t    def update_res_variance(self, residuals, error):\n\t        \"\"\"Update the variance of the residuals during fitting\"\"\"\n\t        residuals = torch.cat((residuals, torch.reshape(error, (1,1))))\n\t        res_mean = torch.sum(residuals)/residuals.shape[0]\n\t        residual_variance = torch.sum(torch.square(torch.sub(residuals, res_mean)))\n\t        residual_variance = torch.divide(residual_variance, residuals.shape[0]-1)\n\t        return residuals, res_mean, residual_variance\n\t    def future_sample_paths(self, h, confidence):\n\t        \"\"\"\n", "        Future path sampling for ETS models with no known equations for generating prediction intervals\n\t        Errors are assumed to be normally distributed and random future paths are sampled from the normal distribution\n\t        with mean and variance calculated by the residuals during fitting \n\t        \"\"\"\n\t        q1 = (1-confidence)/2\n\t        q2 = 1 - q1\n\t        loc = self.residual_mean\n\t        scale = torch.sqrt(self.residual_variance)\n\t        sample_paths = torch.tensor([])\n\t        for iter in range(5000):\n", "            sample = torch.normal(loc, scale, size=(1,h))\n\t            sample_paths = torch.cat((sample_paths, sample))\n\t        q1_sample = torch.quantile(sample_paths, q1, dim=0, interpolation=\"nearest\")\n\t        q2_sample = torch.quantile(sample_paths, q2, dim=0, interpolation=\"nearest\")\n\t        bounds = torch.abs(torch.sub(q1_sample, q2_sample))\n\t        return bounds\n\t    def fit(self):\n\t        #This function will be overriden by the child class.\n\t        raise NotImplementedError(\"This function is not implemented yet.\")\n\t    def predict(self, h: int, confidence: float = None):\n", "        # This function will be overriden by the child class.\n\t        raise NotImplementedError(\"This function is not implemented yet.\")\n"]}
{"filename": "chronokit/exponential_smoothing/__init__.py", "chunked_list": ["from .ETS import *\n\tfrom .ExponentialSmoothing import *\n\tfrom .model import *\n\tfrom .initialization import *\n\tfrom .models import * "]}
{"filename": "chronokit/exponential_smoothing/ExponentialSmoothing.py", "chunked_list": ["from .model import Smoothing_Model\n\tfrom chronokit.exponential_smoothing.models.smoothing import *\n\tclass ExponentialSmoothing:\n\t    def __new__(self, dep_var, trend=None, damped=False, seasonal=None, seasonal_periods=None, initialization_method=\"heuristic\", **kwargs):\n\t        \"\"\"\n\t        Exponential Smoothing model for time series data\n\t        Arguments:\n\t        *dep_var (array_like): Univariate time series data\n\t        *trend (Optional[str]): Trend component; None or \"add\"\n\t        *damped (bool): Damp factor of the trend component; False if trend is None\n", "        *seasonal (Optional[str]): Seasonal component; None, \"add\" or \"mul\"\n\t        *seasonal_periods (Optional[int]): Cyclic period of the seasonal component; int or None if seasonal is None\n\t        *initialization_method (str): Initialization method to use for the model parameters; \"heuristic\" or \"mle\"\n\t        Keyword Arguments:\n\t        ** alpha (float): Smoothing parameter for level component; takes values in (0,1)\n\t        ** beta (float): Smoothing parameter for trend component; takes values in (0,1)\n\t        ** phi (float): Damp factor for trend component; takes values in (0,1]\n\t        ** gamma (float): Smoothing parameter for seasonal component; takes values in (0,1)\n\t        ETS models are implemented by the below textbook as a reference:\n\t        'Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n", "        and practice. OTexts, 2014.'\n\t        \"\"\"\n\t        smoothing_class = { \n\t                        (None, None): SES,\n\t                        (\"add\", None): HoltTrend,\n\t                        (\"add\", \"add\"): HoltWinters,\n\t                        (\"add\", \"mul\"): HoltWinters,\n\t                                                    }[trend, seasonal]\n\t        return smoothing_class(dep_var, trend=trend, seasonal=seasonal, damped=damped, \n\t                               seasonal_periods=seasonal_periods, initialization_method=initialization_method, **kwargs)\n"]}
{"filename": "chronokit/exponential_smoothing/ETS.py", "chunked_list": ["from .model import ETS_Model\n\tfrom chronokit.exponential_smoothing.models.ets_models import *\n\tclass ETS(ETS_Model):\n\t    def __new__(self, dep_var, error_type=\"add\", trend=None, damped=False, seasonal=None, seasonal_periods=None, initialization_method=\"heuristic\", **kwargs):\n\t        \"\"\"\n\t        ETS (Error,Trend,Seasonality) model for time series data\n\t        Arguments:\n\t        *dep_var (array_like): Univariate time series data\n\t        *error_type (str): Type of error of the ETS model; \"add\" or \"mul\"\n\t        *trend (Optional[str]): Trend component; None or \"add\"\n", "        *damped (bool): Damp factor of the trend component; False if trend is None\n\t        *seasonal (Optional[str]): Seasonal component; None, \"add\" or \"mul\"\n\t        *seasonal_periods (Optional[int]): Cyclic period of the seasonal component; int or None if seasonal is None\n\t        *initialization_method (str): Initialization method to use for the model parameters; \"heuristic\" or \"mle\"\n\t        Keyword Arguments:\n\t        ** alpha (float): Smoothing parameter for level component; takes values in (0,1)\n\t        ** beta (float): Smoothing parameter for trend component; takes values in (0,1)\n\t        ** phi (float): Damp factor for trend component; takes values in (0,1]\n\t        ** gamma (float): Smoothing parameter for seasonal component; takes values in (0,1)\n\t        ETS models are implemented by the below textbook as a reference:\n", "        'Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n\t        and practice. OTexts, 2014.'\n\t        \"\"\"\n\t        ets_class = { \n\t                        (None, None, \"add\"): ETS_ANN,\n\t                        (None, \"add\", \"add\"): ETS_ANA,\n\t                        (None, \"mul\", \"add\"): ETS_ANM,\n\t                        (\"add\",  None, \"add\"): ETS_AAN,\n\t                        (\"add\", \"add\", \"add\"): ETS_AAA,\n\t                        (\"add\", \"mul\", \"add\"): ETS_AAM,\n", "                        (None,  None, \"mul\"): ETS_MNN,\n\t                        (None,  \"add\", \"mul\"): ETS_MNA,\n\t                        (None, \"mul\", \"mul\"): ETS_MNM,\n\t                        (\"add\",  None, \"mul\"): ETS_MAN,\n\t                        (\"add\", \"add\", \"mul\"): ETS_MAA,\n\t                        (\"add\", \"mul\", \"mul\"): ETS_MAM,\n\t                                                            }[trend, seasonal, error_type]\n\t        return ets_class(dep_var, trend=trend, seasonal=seasonal, error_type=error_type, damped=damped, \n\t                         seasonal_periods=seasonal_periods, initialization_method=initialization_method, **kwargs)\n"]}
{"filename": "chronokit/exponential_smoothing/models/ets_models.py", "chunked_list": ["import numpy as np\n\timport torch\n\tfrom chronokit.exponential_smoothing.model import ETS_Model\n\t\"\"\"\n\tETS (Error,Trend,Seasonality) models for time series forecasting.\n\tAll methods have been implemented from chapter 7 of the textbook as a reference.\n\t'Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n\tand practice. OTexts, 2014.'\n\t\"\"\"\n\tclass ETS_ANN(ETS_Model):\n", "    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Additive Errors, No Trend and No Seasonality\"\"\"\n\t        self.trend = None\n\t        self.damped = False\n\t        self.seasonal = None\n\t        self.seasonal_periods = None\n\t        self.error_type = \"add\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n", "        initialize_params = [\"alpha\"]\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n", "        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n\t        fc_var = torch.add(1 ,torch.mul(torch.square(self.alpha),  h-1))\n\t        fc_var = torch.mul(self.residual_variance, fc_var)\n\t        return torch.mul(self.c, torch.sqrt(fc_var))\n", "    def __smooth_level(self, lprev):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(lprev, torch.mul(self.alpha, self.error))\n\t    def __smooth_error(self, y, y_hat):\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.sub(y, y_hat)\n\t    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = l_{t-1} + e_t\n", "        l_t = l_{t-1} + alpha*e_t\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                self.fitted[0] = row\n\t            else:\n", "                y_hat = self.level\n\t                self.__smooth_error(row, y_hat)\n\t                lprev = self.level\n\t                self.__smooth_level(lprev)\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n", "        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        if confidence:\n\t            self.__calculate_conf_level(confidence)\n\t        self.forecast = torch.tensor([])\n\t        upper_bounds = torch.tensor([])\n\t        lower_bounds = torch.tensor([])\n\t        for i in range(1,h+1):\n\t            step_forecast = self.level\n", "            self.forecast = torch.cat((self.forecast, step_forecast))\n\t            if confidence:\n\t                fc_var = self.__get_confidence_interval(h=i)\n\t                upper_bounds = torch.cat((upper_bounds, torch.add(step_forecast, torch.abs(fc_var))))\n\t                lower_bounds = torch.cat((lower_bounds, torch.sub(step_forecast, torch.abs(fc_var))))\n\t        if confidence:\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_AAN(ETS_Model):\n", "    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Additive Errors, Additive Trend and No Seasonality\"\"\"\n\t        self.trend = \"add\"\n\t        self.damped = damped\n\t        self.seasonal = None\n\t        self.seasonal_periods = None\n\t        self.error_type = \"add\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n", "        initialize_params = [\"alpha\", \"beta\"]\n\t        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n", "        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\" \n", "        if not self.damped:\n\t            fc_var = torch.add(torch.square(self.alpha), torch.mul(torch.mul(self.alpha, self.beta), h))\n\t            fc_var = torch.add(fc_var, torch.divide(torch.mul(torch.square(self.beta), h*(2*h-1)), 6))\n\t            fc_var = torch.mul(h-1, fc_var)\n\t            fc_var = torch.add(1, fc_var)\n\t            fc_var = torch.mul(self.residual_variance, fc_var)\n\t        if self.damped:\n\t            part1 = torch.mul(torch.square(self.alpha), h-1)\n\t            part3_1 = torch.mul(torch.mul(self.beta, self.phi), h)\n\t            part3_1 = torch.divide(part3_1, torch.square(torch.sub(1, self.phi)))\n", "            part3_2 = torch.add(torch.mul(torch.mul(2, self.alpha), torch.sub(1, self.phi)), torch.mul(self.beta, self.phi))\n\t            part3 = torch.mul(part3_1, part3_2)\n\t            part4_1 =  torch.mul(torch.mul(self.beta, self.phi), torch.sub(1, torch.pow(self.phi, h)))\n\t            part4_1 = torch.divide(part4_1, torch.mul(torch.square(torch.sub(1, self.phi)), torch.sub(1, torch.square(self.phi))))\n\t            part4_2 = torch.mul(torch.mul(self.beta, self.phi), torch.add(1, torch.sub(torch.mul(2, self.phi), torch.pow(self.phi, h))))\n\t            part4_2 = torch.add(torch.mul(torch.mul(2, self.alpha), torch.sub(1, torch.square(self.phi))), part4_2)\n\t            part4 = torch.mul(part4_1, part4_2)\n\t            fc_var = torch.add(part1, part3)\n\t            fc_var = torch.sub(fc_var, part4)\n\t            fc_var = torch.add(1, fc_var)\n", "            fc_var = torch.mul(self.residual_variance, fc_var)\n\t        return torch.mul(self.c, torch.sqrt(fc_var))\n\t    def __smooth_level(self, lprev,bprev): \n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(torch.add(lprev,torch.mul(bprev, self.phi)), torch.mul(self.alpha, self.error))\n\t    def __smooth_error(self, y, y_hat):  \n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.sub(y, y_hat)\n\t    def __smooth_trend(self, bprev):\n\t        \"\"\"Calculate the level\"\"\"\n", "        self.trend = torch.add(torch.mul(bprev, self.phi), torch.mul(self.beta, self.error))\n\t    def fit(self):               \n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = l_{t-1} + phi*b_{t-1} + e_t\n\t        l_t = l_{t-1} + phi*b_{t-1} + alpha*e_t\n\t        b_t = phi*b_{t-1} + beta*e_t\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n", "            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.trend = self.initial_trend\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                self.fitted[0] = row\n\t            else:\n\t                y_hat = torch.add(self.level, torch.mul(self.phi,self.trend))\n\t                self.__smooth_error(row, y_hat)\n\t                lprev, bprev = self.level, self.trend\n", "                self.__smooth_level(lprev, bprev)\n\t                self.__smooth_trend(bprev)\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n", "        \"\"\"\n\t        if confidence:\n\t            self.__calculate_conf_level(confidence)\n\t        self.forecast = torch.tensor([])\n\t        upper_bounds = torch.tensor([])\n\t        lower_bounds = torch.tensor([])\n\t        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i+1)]))\n\t            step_forecast = torch.add(self.level, torch.mul(damp_factor, self.trend))\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n", "            if confidence:\n\t                fc_var = self.__get_confidence_interval(h=i)\n\t                upper_bounds = torch.cat((upper_bounds, torch.add(step_forecast, torch.abs(fc_var))))\n\t                lower_bounds = torch.cat((lower_bounds, torch.sub(step_forecast, torch.abs(fc_var))))\n\t        if confidence:\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_ANA(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n", "        \"\"\"Implementation of ETS method with Additive Errors, No Trend and Additive Seasonality\"\"\"\n\t        self.trend = None\n\t        self.damped = False\n\t        self.seasonal = \"add\"\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"add\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"gamma\"]\n", "        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n", "        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n\t        k = int((h-1)/self.seasonal_periods)\n\t        fc_var = torch.add(1 ,torch.mul(torch.square(self.alpha),  h-1))\n\t        fc_var = torch.add(fc_var, torch.mul(torch.mul(self.gamma, k), torch.add(torch.mul(2, self.alpha), self.gamma)))\n", "        fc_var = torch.mul(self.residual_variance, fc_var)\n\t        return torch.mul(self.c, fc_var)\n\t    def __smooth_level(self,lprev): \n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(lprev, torch.mul(self.alpha, self.error))\n\t    def __smooth_error(self, y, y_hat): \n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.sub(y, y_hat)\n\t    def __smooth_seasonal(self, seasonal):\n\t        \"\"\"Calculate the level\"\"\"\n", "        seasonal = torch.add(seasonal, torch.mul(self.gamma, self.error))\n\t        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def fit(self): \n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = l_{t-1} + s_{t-m} + e_t\n\t        l_t = l_{t-1} + alpha*e_t\n\t        s_t = s_{t-m} + gamma*e_t\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n", "        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = torch.tensor([seasonal])\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n", "                y_hat = torch.add(self.level, seasonal)\n\t                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n\t                y_hat = torch.add(self.level, seasonal)\n\t                lprev = self.level\n", "                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev)\n\t                self.__smooth_seasonal(seasonal)\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n", "        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        if confidence:\n\t            self.__calculate_conf_level(confidence)\n\t        self.forecast = torch.tensor([])\n\t        upper_bounds = torch.tensor([])\n\t        lower_bounds = torch.tensor([])\n\t        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            k = int((h-1)/self.seasonal_periods)\n", "            step_forecast = torch.add(self.level, self.seasonals[len_s+i-self.seasonal_periods*(k+1)])\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n\t            if confidence:\n\t                fc_var = self.__get_confidence_interval(h=i)\n\t                upper_bounds = torch.cat((upper_bounds, torch.add(step_forecast, torch.abs(fc_var))))\n\t                lower_bounds = torch.cat((lower_bounds, torch.sub(step_forecast, torch.abs(fc_var))))\n\t        if confidence:\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n", "class ETS_AAA(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Additive Errors, Additive Trend and Additive Seasonality\"\"\"\n\t        self.trend = \"add\"\n\t        self.damped = damped\n\t        self.seasonal = \"add\"\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"add\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n", "                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"beta\", \"gamma\"]\n\t        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n", "        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n", "    def __get_confidence_interval(self, h):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n\t        k = int((h-1)/self.seasonal_periods)\n\t        if not self.damped:\n\t            part1 = torch.add(torch.square(self.alpha), torch.mul(torch.mul(self.alpha, self.beta), h))\n\t            part1 = torch.add(part1, torch.divide(torch.mul(torch.square(self.beta), h*(2*h-1)), 6))\n\t            part1 = torch.mul(h-1, part1)\n\t            part2 = torch.add(torch.mul(2,self.alpha), self.gamma)\n\t            part2= torch.add(part2, torch.mul(torch.mul(self.beta, self.seasonal_periods), k+1))\n\t            part2 = torch.mul(part2, torch.mul(self.gamma, k))\n", "            fc_var = torch.add(part1, part2)\n\t            fc_var = torch.add(1, fc_var)\n\t            fc_var = torch.mul(self.residual_variance, fc_var)\n\t        if self.damped:\n\t            part1 = torch.mul(torch.square(self.alpha), h-1)\n\t            part2 = torch.mul(torch.mul(self.gamma, k), torch.add(torch.mul(2, self.alpha), self.gamma))\n\t            part3_1 = torch.mul(torch.mul(self.beta, self.phi), h)\n\t            part3_1 = torch.divide(part3_1, torch.square(torch.sub(1, self.phi)))\n\t            part3_2 = torch.add(torch.mul(torch.mul(2, self.alpha), torch.sub(1, self.phi)), torch.mul(self.beta, self.phi))\n\t            part3 = torch.mul(part3_1, part3_2)\n", "            part4_1 =  torch.mul(torch.mul(self.beta, self.phi), torch.sub(1, torch.pow(self.phi, h)))\n\t            part4_1 = torch.divide(part4_1, torch.mul(torch.square(torch.sub(1, self.phi)), torch.sub(1, torch.square(self.phi))))\n\t            part4_2 = torch.mul(torch.mul(self.beta, self.phi), torch.add(1, torch.sub(torch.mul(2, self.phi), torch.pow(self.phi, h))))\n\t            part4_2 = torch.add(torch.mul(torch.mul(2, self.alpha), torch.sub(1, torch.square(self.phi))), part4_2)\n\t            part4 = torch.mul(part4_1, part4_2)\n\t            part5_1 = torch.mul(torch.mul(2, self.beta), torch.mul(self.gamma, self.phi))\n\t            part5_1 = torch.divide(part5_1, torch.mul(torch.sub(1, self.phi), torch.sub(1, torch.pow(self.phi, self.seasonal_periods))))\n\t            part5_2 = torch.mul(torch.pow(self.phi, self.seasonal_periods), torch.sub(1, torch.pow(self.phi, torch.mul(self.seasonal_periods, k))))\n\t            part5_2 = torch.sub(torch.mul(k, torch.sub(1, torch.pow(self.phi, self.seasonal_periods))), part5_2)\n\t            part5 = torch.mul(part5_1, part5_2)\n", "            fc_var = torch.add(part1, part2)\n\t            fc_var = torch.add(fc_var, part3)\n\t            fc_var = torch.sub(fc_var, part4)\n\t            fc_var = torch.add(fc_var, part5)\n\t            fc_var = torch.add(1, fc_var)\n\t            fc_var = torch.mul(self.residual_variance, fc_var)\n\t        return torch.mul(self.c, torch.sqrt(fc_var))\n\t    def __smooth_level(self, lprev,bprev):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(lprev, torch.mul(self.phi, bprev))\n", "        self.level = torch.add(self.level, torch.mul(self.alpha, self.error))\n\t    def __smooth_error(self, y, y_hat):\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.sub(y, y_hat)\n\t    def __smooth_seasonal(self, seasonal):\n\t        \"\"\"Calculate seasonal\"\"\"\n\t        seasonal = torch.add(seasonal, torch.mul(self.gamma, self.error))\n\t        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def __smooth_trend(self, bprev):\n\t        \"\"\"Calculate trend\"\"\"\n", "        self.trend = torch.add(torch.mul(self.error, self.beta), torch.mul(self.phi, bprev))\n\t    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = l_{t-1} + phi*b_{t-1} + s_{t-m} + e_t\n\t        l_t = l_{t-1} + phi*b_{t-1} + alpha*e_t\n\t        b_t = phi*b_{t-1} + beta*e_t\n\t        s_t = s_{t-m} + gamma*e_t\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n", "        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.trend = self.initial_trend\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = torch.tensor([seasonal])\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n", "                seasonal = self.initial_seasonals[index]\n\t                y_hat = torch.add(self.level, torch.add(torch.mul(self.phi, self.trend), seasonal))\n\t                self.__smooth_error(row, y_hat)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_level(lprev, bprev)\n\t                self.__smooth_trend(bprev)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n", "                y_hat = torch.add(self.level, torch.add(torch.mul(self.phi, self.trend), seasonal))\n\t                self.__smooth_error(row, y_hat)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_level(lprev, bprev)\n\t                self.__smooth_trend(bprev)\n\t                self.__smooth_seasonal(seasonal)\n\t                self.fitted[index] =y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n", "        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        if confidence:\n\t            self.__calculate_conf_level(confidence)\n\t        self.forecast = torch.tensor([])\n\t        upper_bounds = torch.tensor([])\n\t        lower_bounds = torch.tensor([])\n", "        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i+1)]))\n\t            k = int((h-1)/self.seasonal_periods)\n\t            step_forecast = torch.add(self.level, torch.mul(damp_factor, self.trend))\n\t            step_forecast = torch.add(step_forecast, self.seasonals[len_s+i-self.seasonal_periods*(k+1)])\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n\t            if confidence:\n\t                fc_var = self.__get_confidence_interval(h=i)\n\t                upper_bounds = torch.cat((upper_bounds, torch.add(step_forecast, torch.abs(fc_var))))\n", "                lower_bounds = torch.cat((lower_bounds, torch.sub(step_forecast, torch.abs(fc_var))))\n\t        if confidence:\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_ANM(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Additive Errors, No Trend and Multiplicative Seasonality\"\"\"\n\t        self.trend = None\n\t        self.damped = False\n", "        self.seasonal = \"mul\"\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"add\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"gamma\"]\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n", "        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n", "        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n\t        return super().future_sample_paths(h, conf)\n\t    def __smooth_level(self,lprev, seasonal):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(lprev, torch.divide(torch.mul(self.alpha, self.error), seasonal))\n\t    def __smooth_error(self, y, y_hat):  \n\t        \"\"\"Calculate error\"\"\"\n", "        self.error = torch.sub(y,y_hat)\n\t    def __smooth_seasonal(self, seasonal, lprev):\n\t        \"\"\"Calculate the level\"\"\"\n\t        seasonal = torch.add(seasonal, torch.divide(torch.mul(self.gamma, self.error),lprev))\n\t        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = l_{t-1}*s_{t-m} + e_t\n\t        l_t = l_{t-1} + alpha*e_t/s_{t-m}\n", "        s_t = s_{t-m} + gamma*e_t/l_{t-1}\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = seasonal\n", "                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n\t                y_hat = torch.mul(self.level,seasonal)\n\t                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev, seasonal)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n", "                seasonal = self.seasonals[-self.seasonal_periods]\n\t                y_hat = torch.mul(self.level,seasonal)\n\t                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev, seasonal)\n\t                self.__smooth_seasonal(seasonal,lprev)\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n", "        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            k = int((h-1)/self.seasonal_periods)\n\t            step_forecast = torch.mul(self.level, self.seasonals[len_s+i-self.seasonal_periods*(k+1)])\n", "            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n\t            upper_bounds = torch.add(self.forecast, bounds)\n\t            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_AAM(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n", "        \"\"\"Implementation of ETS method with Additive Errors, Additive Trend and Multiplicative Seasonality\"\"\"\n\t        self.trend = \"add\"\n\t        self.damped = damped\n\t        self.seasonal = \"mul\"\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"add\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"beta\", \"gamma\"]\n", "        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n", "        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"        \n", "        return super().future_sample_paths(h, conf)\n\t    def __smooth_level(self, lprev, bprev, seasonal):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(torch.mul(self.phi, bprev), torch.divide(torch.mul(self.alpha, self.error), seasonal))\n\t        self.level = torch.add(self.level, lprev)\n\t    def __smooth_trend(self, bprev, seasonal):\n\t        \"\"\"Calculate trend\"\"\"\n\t        self.trend = torch.divide(torch.mul(self.beta, self.error), seasonal)\n\t        self.trend = torch.add(self.trend, torch.mul(self.phi, bprev))\n\t    def __smooth_seasonal(self, lprev, bprev):\n", "        \"\"\"Calculate seasonal\"\"\"\n\t        seasonal = torch.divide(torch.mul(self.gamma, self.error), torch.add(lprev, torch.mul(self.phi, bprev)))\n\t        seasonal = torch.add(seasonal, self.seasonals[-self.seasonal_periods])\n\t        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def __smooth_error(self, y, y_hat):\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.sub(y, y_hat)\n\t    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n", "        y_t = (l_{t-1} + phi*b_{t-1})*s_{t-m} + e_t\n\t        l_t = l_{t-1} + phi*b_{t-1} + alpha*e_t/s_{t-m}\n\t        b_t = phi*b_{t-1} + beta*e_t/s_{t-m}\n\t        s_t = s_{t-m} + gamma*e_t/(l_{t-1} + phi*b_{t-1})\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n", "                self.trend = self.initial_trend\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = seasonal\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n\t                y_hat = torch.mul(torch.add(self.level, torch.mul(self.phi, self.trend)), seasonal)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_error(row, y_hat)\n", "                self.__smooth_level(lprev, bprev, seasonal)\n\t                self.__smooth_trend(bprev, seasonal)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n\t                y_hat = torch.mul(torch.add(self.level, torch.mul(self.phi, self.trend)), seasonal)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev, bprev, seasonal)\n", "                self.__smooth_trend(bprev, seasonal)\n\t                self.__smooth_seasonal(lprev, bprev)\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n", "        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i+1)]))\n\t            k = int((h-1)/self.seasonal_periods)\n\t            step_forecast = torch.mul(self.seasonals[len_s+i-self.seasonal_periods*(k+1)], torch.add(self.level, torch.mul(damp_factor, self.trend)))\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n", "            upper_bounds = torch.add(self.forecast, bounds)\n\t            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_MNN(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Multiplicative Errors, No Trend and No Seasonality\"\"\"\n\t        self.trend = None\n\t        self.damped = False\n", "        self.seasonal = None\n\t        self.seasonal_periods = None\n\t        self.error_type = \"mul\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\"]\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n", "        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n", "        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"        \n\t        return super().future_sample_paths(h, conf)\n\t    def __smooth_level(self, lprev):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.mul(lprev, torch.add(1, torch.mul(self.alpha, self.error)))\n\t    def __smooth_error(self, y, y_hat):\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.divide(torch.sub(y, y_hat), y_hat)\n", "    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = l_{t-1}*(1 + e_t)\n\t        l_t = l_{t-1}*(1 + alpha*e_t)\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n", "                self.level = self.initial_level\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                self.fitted[0] = row\n\t            else:\n\t                y_hat = self.level\n\t                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev)\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n", "    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        for i in range(1,h+1):\n\t            step_forecast = self.level\n", "            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n\t            upper_bounds = torch.add(self.forecast, bounds)\n\t            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_MAN(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n", "        \"\"\"Implementation of ETS method with Multiplicative Errors, Additive Trend and No Seasonality\"\"\"\n\t        self.trend = \"add\"\n\t        self.damped = damped\n\t        self.seasonal = None\n\t        self.seasonal_periods = None\n\t        self.error_type = \"mul\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"beta\"]\n", "        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n", "        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf): \n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n\t        return super().future_sample_paths(h, conf)\n", "    def __smooth_level(self, lprev,bprev): #done\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.mul(torch.add(lprev,torch.mul(self.phi, bprev)), torch.add(1, torch.mul(self.alpha, self.error)))\n\t    def __smooth_error(self, y, y_hat):  #done\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.divide(torch.sub(y, y_hat), y_hat)\n\t    def __smooth_trend(self, bprev,lprev): ##done\n\t        \"\"\"Calculate the trend\"\"\"\n\t        self.trend = torch.add(torch.mul(self.phi, bprev), torch.mul(self.beta, torch.mul(torch.add(lprev,torch.mul(self.phi, bprev)),self.error)))\n\t    def fit(self):\n", "        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = (l_{t-1} + phi*b_{t-1})*(1 + e_t)\n\t        l_t = (l_{t-1} + phi*b_{t-1})*(1 + alpha*e_t)\n\t        b_t = phi*b_{t-1} + beta*(l_{t-1} + phi*b_{t-1})*e_t\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n", "                self.level = self.initial_level\n\t                self.trend = self.initial_trend\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                self.fitted[0] = row\n\t            else:\n\t                y_hat = torch.add(self.level, torch.mul(self.phi,self.trend))\n\t                self.__smooth_error(row, y_hat)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_level(lprev, bprev)\n\t                self.__smooth_trend(bprev, lprev)\n", "                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n", "        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i+1)]))\n\t            step_forecast = torch.add(self.level, torch.mul(damp_factor, self.trend))\n\t            self.forecast = torch.cat((self.forecast, step_forecast))            \n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n\t            upper_bounds = torch.add(self.forecast, bounds)\n\t            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n", "            return self.forecast\n\tclass ETS_MNA(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Multiplicative Errors, No Trend and Additive Seasonality\"\"\"\n\t        self.trend = None\n\t        self.damped = False\n\t        self.seasonal = \"add\"\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"add\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n", "        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"gamma\"]\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n", "        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf): \n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n", "        return super().future_sample_paths(h, conf)\n\t    def __smooth_level(self,lprev,seasonal):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(lprev, torch.mul(self.alpha, torch.mul(torch.add(lprev,seasonal),self.error)))\n\t    def __smooth_error(self, y, y_hat):\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.divide(torch.sub(y,y_hat),y_hat)\n\t    def __smooth_seasonal(self, lprev,seasonal):\n\t        \"\"\"Calculate the level\"\"\"\n\t        seasonal = torch.add(seasonal, torch.mul(self.gamma, torch.mul(torch.add(lprev,seasonal),self.error)))\n", "        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def fit(self): \n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = (l_{t-1} + s_{t-m})*(1 + e_t)\n\t        l_t = l_{t-1} + alpha*(l_{t-1} + s_{t-m})*e_t\n\t        s_t = s_{t-m} + gamma*(l_{t-1} + s_{t-m})*e_t\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n", "            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = torch.tensor([seasonal])\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n\t                y_hat = torch.add(self.level, seasonal)\n", "                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev, seasonal)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat     \n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n\t                y_hat = torch.add(self.level, seasonal)\n\t                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n", "                self.__smooth_level(lprev, seasonal)\n\t                self.__smooth_seasonal(lprev, seasonal)\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n", "        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            k = int((h-1)/self.seasonal_periods)\n\t            step_forecast = torch.add(self.level, self.seasonals[len_s+i-self.seasonal_periods*(k+1)])\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n\t            upper_bounds = torch.add(self.forecast, bounds)\n", "            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_MAA(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Multiplicative Errors, Additive Trend and Additive Seasonality\"\"\"\n\t        self.trend = \"add\"\n\t        self.damped = damped\n\t        self.seasonal = \"add\"\n", "        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"mul\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"beta\", \"gamma\"]\n\t        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n", "    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n", "    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n\t        return super().future_sample_paths(h, conf)\n\t    def __smooth_level(self, lprev,bprev,seasonal):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.mul(self.alpha,torch.add(seasonal,torch.add(lprev,torch.mul(self.phi, bprev))))\n", "        self.level = torch.mul(self.error,self.level)\n\t        self.level = torch.add(self.level,torch.add(lprev,torch.mul(self.phi, bprev)))\n\t    def __smooth_error(self, y, y_hat):\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.divide(torch.sub(y, y_hat), y_hat)\n\t    def __smooth_seasonal(self, seasonal, lprev,bprev):\n\t        seasonal = torch.add(seasonal, torch.mul(self.error,torch.mul(self.gamma,torch.add(seasonal,torch.add(lprev, torch.mul(self.phi,bprev))))))\n\t        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def __smooth_trend(self, lprev, bprev,seasonal):\n\t        self.trend = torch.add(torch.mul(self.phi, bprev), torch.mul(self.error,torch.mul(self.beta,torch.add(seasonal,torch.add(lprev,torch.mul(self.phi,bprev))))))\n", "    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = (l_{t-1} + phi*b_{t-1} + s_{t-m})*(1 + e_t)\n\t        l_t = l_{t-1} + phi*b_{t-1} + alpha*(l_{t-1} + s_{t-m})*e_t\n\t        b_t = phi*b_{t-1} + beta*(l_{t-1} + phi*b_{t-1} + s_{t-m})*e_t\n\t        s_t = s_{t-m} + gamma*(l_{t-1} + phi*b_{t-1} + s_{t-m})*e_t\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n", "            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.trend = self.initial_trend\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = torch.tensor([seasonal])\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n", "                y_hat = torch.add(self.level, torch.add(torch.mul(self.phi, self.trend), seasonal))\n\t                self.__smooth_error(row, y_hat)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_level(lprev, bprev, seasonal)\n\t                self.__smooth_trend(lprev, bprev, seasonal)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n\t                y_hat = torch.add(self.level, torch.add(torch.mul(self.phi, self.trend), seasonal))\n", "                self.__smooth_error(row, y_hat)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_level(lprev, bprev, seasonal)\n\t                self.__smooth_trend(lprev, bprev, seasonal)\n\t                self.__smooth_seasonal(seasonal, lprev, bprev)\n\t                self.fitted[index] =y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n", "        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i+1)]))\n\t            k = int((h-1)/self.seasonal_periods)\n\t            step_forecast = torch.add(self.level, torch.mul(damp_factor, self.trend))\n", "            step_forecast = torch.add(step_forecast, self.seasonals[len_s+i-self.seasonal_periods*(k+1)])\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n\t            upper_bounds = torch.add(self.forecast, bounds)\n\t            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast\n\tclass ETS_MNM(ETS_Model):\n", "    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Multiplicative Errors, No Trend and Multiplicative Seasonality\"\"\"\n\t        self.trend = None\n\t        self.damped = False\n\t        self.seasonal = \"mul\"\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"mul\"\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n", "        initialize_params = [\"alpha\", \"gamma\"]\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n\t        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n", "        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n\t        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"\n\t        return super().future_sample_paths(h, conf)\n\t    def __smooth_level(self, lprev, seasonal):\n", "        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.mul(lprev, torch.add(1, torch.mul(self.alpha, self.error)))\n\t    def __smooth_error(self, y, y_hat):  \n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.divide(torch.sub(y, y_hat), y_hat)\n\t    def __smooth_seasonal(self, seasonal, lprev):\n\t        \"\"\"Calculate the level\"\"\"\n\t        seasonal = torch.mul(seasonal, torch.add(1, torch.mul(self.gamma, self.error)))\n\t        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def fit(self):\n", "        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = l_{t-1}*s_{t-m}*(1 + e_t)\n\t        l_t = l_{t-1}*(1 + alpha*e_t)\n\t        s_t = s_{t-m}*(1 + gamma*e_t)\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                y_hat = row\n", "                self.level = self.initial_level\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = seasonal\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n\t                y_hat = torch.mul(self.level,seasonal)\n\t                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n", "                self.__smooth_level(lprev, seasonal)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n\t                y_hat = torch.mul(self.level,seasonal)\n\t                lprev = self.level\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev, seasonal)\n\t                self.__smooth_seasonal(seasonal,lprev)\n", "                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n", "        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            k = int((h-1)/self.seasonal_periods)\n\t            step_forecast = torch.mul(self.level, self.seasonals[len_s+i-self.seasonal_periods*(k+1)])\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n\t            upper_bounds = torch.add(self.forecast, bounds)\n\t            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n", "        else:\n\t            return self.forecast\n\tclass ETS_MAM(ETS_Model):\n\t    def __init__(self, dep_var, trend=None, seasonal=None, error_type=None, damped=False, seasonal_periods=None, **kwargs):\n\t        \"\"\"Implementation of ETS method with Multiplicative Errors, Additive Trend and Multiplicative Seasonality\"\"\"\n\t        self.trend = \"add\"\n\t        self.damped = damped\n\t        self.seasonal = \"mul\"\n\t        self.seasonal_periods = seasonal_periods\n\t        self.error_type = \"mul\"\n", "        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, trend=self.trend,  seasonal=self.seasonal, error_type=self.error_type, seasonal_periods=self.seasonal_periods, \n\t                                damped=self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"beta\", \"gamma\"]\n\t        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t        self.residuals = torch.tensor([])\n\t    def __calculate_conf_level(self, conf):\n\t        \"\"\"Calculate the multiplier for prediction interval\"\"\"\n", "        self.c = super().calculate_conf_level(conf)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __update_res_variance(self, y, y_hat):\n\t        \"\"\"Update the residual variance\"\"\"\n", "        resid = torch.sub(y, y_hat)\n\t        self.residuals, self.residual_mean, self.residual_variance = super().update_res_variance(self.residuals, resid)\n\t    def __get_confidence_interval(self, h, conf):\n\t        \"\"\"Get the confidence interval of the predictions\"\"\"        \n\t        return super().future_sample_paths(h, conf)\n\t    def __smooth_level(self, lprev, bprev):\n\t        \"\"\"Calculate the level\"\"\"\n\t        self.level = torch.add(lprev, torch.mul(self.phi, bprev))\n\t        self.level = torch.mul(self.level, torch.add(1, torch.mul(self.alpha, self.error)))\n\t    def __smooth_trend(self, lprev, bprev):\n", "        \"\"\"Calculate trend\"\"\"\n\t        self.trend = torch.mul(torch.mul(self.error, self.beta), torch.add(lprev , torch.mul(self.phi, bprev)))\n\t        self.trend = torch.add(self.trend, torch.mul(self.phi, bprev))\n\t    def __smooth_seasonal(self):\n\t        \"\"\"Calculate seasonal\"\"\"\n\t        seasonal = torch.mul(self.seasonals[-self.seasonal_periods], torch.add(1, torch.mul(self.gamma, self.error)))\n\t        self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def __smooth_error(self, y, y_hat):\n\t        \"\"\"Calculate error\"\"\"\n\t        self.error = torch.divide(torch.sub(y, y_hat), y_hat)\n", "    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        y_t = (l_{t-1} + phi*b_{t-1})*s_{t-m}*(1 + e_t)\n\t        l_t = (l_{t-1} + phi*b_{t-1})*(1 + alpha*e_t)\n\t        b_t = phi*b_{t-1} + beta*(l_{t-1} + phi*b_{t-1})*e_t\n\t        s_t = s_{t-m}*(1 + gamma*e_t)\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n", "            if index == 0:\n\t                y_hat = row\n\t                self.level = self.initial_level\n\t                self.trend = self.initial_trend\n\t                self.error = torch.tensor(0, dtype=torch.float32)\n\t                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = seasonal\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n", "                y_hat = torch.mul(torch.add(self.level, torch.mul(self.phi, self.trend)), seasonal)\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev, bprev)\n\t                self.__smooth_trend(lprev, bprev)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n\t                y_hat = torch.mul(torch.add(self.level, torch.mul(self.phi, self.trend)), seasonal)\n", "                lprev, bprev = self.level, self.trend\n\t                self.__smooth_error(row, y_hat)\n\t                self.__smooth_level(lprev, bprev)\n\t                self.__smooth_trend(lprev, bprev)\n\t                self.__smooth_seasonal()\n\t                self.fitted[index] = y_hat\n\t            self.__update_res_variance(row, y_hat)\n\t    def predict(self, h, confidence = None):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n", "        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        *confidence (Optional[float]): Confidence level to generate prediction intervals; None or values between (0,1)\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        len_s = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i+1)]))\n\t            k = int((h-1)/self.seasonal_periods)\n\t            step_forecast = torch.mul(self.seasonals[len_s+i-self.seasonal_periods*(k+1)], torch.add(self.level, torch.mul(damp_factor, self.trend)))\n", "            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        if confidence:\n\t            bounds = self.__get_confidence_interval(h, conf=confidence)\n\t            upper_bounds = torch.add(self.forecast, bounds)\n\t            lower_bounds = torch.sub(self.forecast, bounds)\n\t            return self.forecast, (upper_bounds, lower_bounds)\n\t        else:\n\t            return self.forecast"]}
{"filename": "chronokit/exponential_smoothing/models/__init__.py", "chunked_list": ["from .ets_models import *\n\tfrom .smoothing import *"]}
{"filename": "chronokit/exponential_smoothing/models/smoothing.py", "chunked_list": ["import numpy as np\n\timport torch\n\tfrom chronokit.exponential_smoothing.model import Smoothing_Model\n\t\"\"\"\n\tExponential Smoothing models for time series forecasting.\n\tAll methods have been implemented from chapter 7 of the textbook as a reference.\n\t'Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n\tand practice. OTexts, 2014.'\n\t\"\"\"\n\tclass SES(Smoothing_Model):\n", "    def __init__(self, dep_var, trend=None, seasonal=None, seasonal_periods=None, damped=False, indep_var=None, **kwargs):\n\t        \"\"\"Implementation of Simple Exponential Smoothing\"\"\"\n\t        self.trend = None\n\t        self.damped = False\n\t        self.seasonal = None\n\t        self.seasonal_periods = None\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, self.trend, self.seasonal, self.seasonal_periods, self.damped, **kwargs)\n\t        initialize_params = [\"alpha\"]\n\t        self.__initialize_params(initialize_params)\n", "    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize the model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __smooth_level(self, y, lprev):\n\t        \"\"\"Calculate level\"\"\"\n\t        self.level =  torch.add(torch.mul(self.alpha, y),torch.mul((1 - self.alpha), lprev))\n\t    def fit(self):\n\t        \"\"\"\n", "        Fit the model to the data according to the equations:\n\t        l_t =  alpha*y_t + (1 - alpha)*l_{t-1}\n\t        \"\"\"\n\t        self.fitted = torch.zeros(self.dep_var.shape[0])\n\t        for index,row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                self.level = self.initial_level\n\t                self.fitted[0] = row\n\t            else:\n\t                y_hat = self.level\n", "                lprev = self.level\n\t                self.__smooth_level(row, lprev)\n\t                self.fitted[index] = y_hat  \n\t    def predict(self,h):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n", "        for i in range(1,h+1):\n\t            step_forecast = self.level\n\t            self.forecast = torch.cat((self.forecast,step_forecast))\n\t        return self.forecast\n\tclass HoltTrend(Smoothing_Model):\n\t    def __init__(self, dep_var, trend=\"add\", seasonal=None, seasonal_periods=None, damped=False, indep_var=None, **kwargs):\n\t        \"\"\"Implementation of Holt's Trend Method\"\"\"\n\t        self.trend = \"add\"\n\t        self.damped = damped\n\t        self.seasonal = None\n", "        self.seasonal_periods = None\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, self.trend, self.seasonal, self.seasonal_periods, self.damped, **kwargs)\n\t        initialize_params = [\"alpha\", \"beta\"]\n\t        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize the model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n", "        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __smooth_level(self, y, lprev, bprev):\n\t        \"\"\"Calculate level\"\"\"\n\t        self.level = torch.mul(torch.sub(1,self.alpha),torch.add(lprev, torch.mul(self.phi, bprev)))\n\t        self.level = torch.add(torch.mul(self.alpha, y), self.level)\n\t    def __smooth_trend(self, lprev, bprev):\n\t        \"Calculate trend\"\n\t        self.trend = torch.mul(self.beta, torch.sub(self.level, lprev))\n", "        self.trend = torch.add(self.trend, torch.mul(torch.sub(1, self.beta), torch.mul(self.phi, bprev)))\n\t    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        l_t = alpha * y_t + (1 - alpha) * (l_{t-1} + b_{t-1})\n\t        b_t = beta * (l_t - l_{t-1}) + (1 - beta)*phi*b_{t-1}\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n", "                self.level = self.initial_level\n\t                self.trend = self.initial_trend\n\t                self.fitted[0] = row[0]\n\t            else:\n\t                y_hat = torch.add(self.level, torch.mul(self.phi, self.trend))\n\t                lprev, bprev = self.level, self.trend\n\t                self.__smooth_level(row, lprev, bprev)\n\t                self.__smooth_trend(lprev, bprev)\n\t                self.fitted[index] = y_hat\n\t    def predict(self, h):\n", "        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n\t        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i)]))\n\t            step_forecast = torch.add(self.level, torch.mul(damp_factor, self.trend))\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n", "        return self.forecast\n\tclass HoltWinters(Smoothing_Model):\n\t    def __init__(self, dep_var, trend=\"add\", seasonal=\"add\", seasonal_periods=4, damped=False, indep_var=None, **kwargs):\n\t        \"Implementation of Holt-Winters' Seasonal Method\"\n\t        self.trend = trend\n\t        self.damped = damped\n\t        self.seasonal = seasonal\n\t        self.seasonal_periods = seasonal_periods\n\t        super().set_allowed_kwargs([\"alpha\", \"beta\", \"phi\", \"gamma\"])\n\t        super().__init__(dep_var, self.trend, self.seasonal, self.seasonal_periods, self.damped, **kwargs)\n", "        initialize_params = [\"alpha\", \"beta\", \"gamma\"]\n\t        if self.damped:\n\t            initialize_params.append(\"phi\")\n\t        self.__initialize_params(initialize_params)\n\t    def __initialize_params(self, initialize_params):\n\t        \"\"\"Initialize the model parameters\"\"\"\n\t        super().initialize_params(initialize_params)\n\t        self.initial_level = torch.tensor(self.init_components[\"level\"])\n\t        self.initial_trend = torch.tensor(self.init_components[\"trend\"])\n\t        self.initial_seasonals = torch.tensor(self.init_components[\"seasonal\"])\n", "        self.alpha, self.beta, self.gamma, self.phi = torch.tensor(list(self.params.values()), dtype=torch.float32)\n\t    def __smooth_level(self, y, lprev, bprev, seasonal):\n\t        \"\"\"Calculate level\"\"\"\n\t        if self.seasonal == \"add\":\n\t            self.level = torch.mul(torch.sub(1,self.alpha),torch.add(lprev, torch.mul(self.phi, bprev)))\n\t            self.level = torch.add(torch.mul(self.alpha, torch.sub(y, seasonal)), self.level)\n\t        elif self.seasonal == \"mul\":\n\t            self.level = torch.mul(torch.sub(1,self.alpha),torch.add(lprev, torch.mul(self.phi, bprev)))\n\t            self.level = torch.add(torch.mul(self.alpha, torch.divide(y, seasonal)), self.level)\n\t    def __smooth_trend(self, lprev, bprev):\n", "        \"\"\"Calculate trend\"\"\"\n\t        self.trend = torch.mul(self.beta, torch.sub(self.level, lprev))\n\t        self.trend = torch.add(self.trend, torch.mul(torch.sub(1, self.beta), torch.mul(self.phi, bprev)))\n\t    def __smooth_seasonal(self,  y, lprev, bprev, seasonal):\n\t        '''This function calculates the smoothed trend for a given beta and level values'''\n\t        if self.seasonal == \"add\":\n\t            seasonal = torch.mul(torch.sub(1,self.gamma), seasonal)\n\t            seasonal = torch.add(seasonal, torch.mul(self.gamma, torch.sub(torch.sub(y, lprev), torch.mul(self.phi, bprev))))\n\t            self.seasonals = torch.cat((self.seasonals, seasonal))\n\t        elif self.seasonal == \"mul\":\n", "            seasonal = torch.mul(torch.sub(1,self.gamma), seasonal)\n\t            seasonal = torch.add(seasonal, torch.mul(self.gamma, torch.divide(y, torch.add(lprev,torch.mul(self.phi, bprev)))))\n\t            self.seasonals = torch.cat((self.seasonals, seasonal))\n\t    def fit(self):\n\t        \"\"\"\n\t        Fit the model to the data according to the equations:\n\t        If seasonal is additive:\n\t        l_t = alpha*(y_t - s_{t-m}) + (1 - alpha)*(l_{t-1} + b_{t-1})\n\t        b_t = beta * (l_t - l_{t-1}) + (1 - beta)*phi*b_{t-1}\n\t        s_t = gamma*(y_t - l_{t-1} - phi*b_{t-1}) + (1 - y)*s_{t-m}\n", "        If seasonal is multiplicative:\n\t        l_t = alpha*(y_t/s_{t-m}) + (1 - alpha)*(l_{t-1} + b_{t-1})\n\t        b_t = beta * (l_t - l_{t-1}) + (1 - beta)*phi*b_{t-1}\n\t        s_t = gamma*(y_t/(l_{t-1} + phi*b_{t-1})) + (1 - y)*s_{t-m}\n\t        \"\"\"\n\t        self.fitted = torch.zeros(size=self.dep_var.shape)\n\t        for index, row in enumerate(self.dep_var):\n\t            if index == 0:\n\t                self.level = self.initial_level\n\t                self.trend = self.initial_trend\n", "                seasonal = self.initial_seasonals[0]\n\t                self.seasonals = torch.tensor([seasonal])\n\t                self.fitted[0] = row\n\t            elif index < self.seasonal_periods:\n\t                seasonal = self.initial_seasonals[index]\n\t                if self.seasonal == \"add\":\n\t                    y_hat = torch.add(seasonal, torch.add(self.level, torch.mul(self.phi, self.trend)))\n\t                elif self.seasonal == \"mul\":\n\t                    y_hat = torch.mul(seasonal, torch.add(self.level, torch.mul(self.phi, self.trend)))\n\t                lprev, bprev = self.level, self.trend\n", "                self.__smooth_level(row, lprev, bprev, seasonal)\n\t                self.__smooth_trend(lprev, bprev)\n\t                self.seasonals = torch.cat((self.seasonals, seasonal))\n\t                self.fitted[index] = y_hat\n\t            else:\n\t                seasonal = self.seasonals[-self.seasonal_periods]\n\t                if self.seasonal == \"add\":\n\t                    y_hat = torch.add(seasonal, torch.add(self.level, torch.mul(self.phi, self.trend)))\n\t                elif self.seasonal == \"mul\":\n\t                    y_hat = torch.mul(seasonal, torch.add(self.level, torch.mul(self.phi, self.trend)))\n", "                lprev, bprev = self.level, self.trend\n\t                self.__smooth_level(row, lprev, bprev, seasonal)\n\t                self.__smooth_trend(lprev, bprev)\n\t                self.__smooth_seasonal(row, lprev, bprev, seasonal)\n\t                self.fitted[index] = y_hat\n\t    def predict(self, h):\n\t        \"\"\"\n\t        Predict the next h values of the target variable.\n\t        Arguments:\n\t        *h (int): Future time-steps to forecast\n", "        \"\"\"\n\t        self.forecast = torch.tensor([])\n\t        len_seasonal = self.seasonals.shape[0]\n\t        for i in range(1,h+1):\n\t            damp_factor = torch.sum(torch.tensor([torch.pow(self.phi, x+1) for x in range(i)]))\n\t            k = int((i-1)/self.seasonal_periods)\n\t            step_forecast = torch.add(self.level, torch.mul(damp_factor, self.trend))\n\t            if self.seasonal == \"mul\":\n\t                step_forecast = torch.mul(step_forecast, self.seasonals[len_seasonal+i-self.seasonal_periods*(k+1)])\n\t            elif self.seasonal == \"add\":\n", "                step_forecast = torch.add(step_forecast, self.seasonals[len_seasonal+i-self.seasonal_periods*(k+1)])\n\t            self.forecast = torch.cat((self.forecast, step_forecast))\n\t        return self.forecast\n"]}
{"filename": "chronokit/exponential_smoothing/initialization/smoothing_methods.py", "chunked_list": ["import numpy as np\n\t\"\"\"ETS methods to use for initialization of parameters\"\"\"\n\tdef simple_exp(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components          \n\t    alpha = params[0]\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            errors.append(0)\n", "        else:               \n\t            y_hat = lvl\n\t            error = row.numpy()[0] - y_hat\n\t            lprev = lvl\n\t            lvl = alpha*row.numpy()[0] + (1-alpha)*lprev\n\t            errors.append(error)\n\t    return errors\n\tdef holt_trend(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta = params\n", "    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            errors.append(0) \n\t        else:               \n\t            y_hat = lvl + trend \n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n", "            lvl = alpha*row.numpy()[0] + (1-alpha)*(lprev+bprev)\n\t            trend = beta*(lvl-lprev) + (1-beta)*bprev\n\t            errors.append(error)\n\t    return errors\n\tdef holt_damped_trend(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, phi = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n", "            lvl = init_lvl\n\t            trend = init_trend\n\t            errors.append(0) \n\t        else:               \n\t            y_hat = lvl + phi*trend \n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            lvl = alpha*row.numpy()[0] + (1-alpha)*(lprev+phi*bprev)\n\t            trend = beta*(lvl-lprev) + (1-beta)*phi*bprev\n\t            errors.append(error)\n", "    return errors\n\tdef hw_add(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n", "            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl + trend + seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]-lprev-bprev)\n\t            lvl = alpha*(row.numpy()[0]-seasonal) + (1-alpha)*(lprev+ bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*bprev\n", "            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + trend + seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]-lprev-bprev)\n\t            lvl = alpha*(row.numpy()[0]-seasonal) + (1-alpha)*(lprev+ bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*bprev\n", "            seasonals.append(seasonal_t)\n\t            errors.append(error)         \n\t    return errors\n\tdef hw_damped_add(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma, phi = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n", "            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl + phi*trend + seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]-lprev-phi*bprev)\n", "            lvl = alpha*(row.numpy()[0]-seasonal) + (1-alpha)*(lprev + phi*bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*phi*bprev\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + phi*trend + seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]-lprev-phi*bprev)\n", "            lvl = alpha*(row.numpy()[0]-seasonal) + (1-alpha)*(lprev + phi*bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*phi*bprev\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)             \n\t    return errors\n\tdef hw_mul(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n", "        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = (lvl + trend)*seasonal\n\t            error = row.numpy()[0] - y_hat\n", "            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]/(lprev+bprev))\n\t            lvl = alpha*(row.numpy()[0]/seasonal) + (1-alpha)*(lprev + bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*bprev\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = (lvl + trend)*seasonal\n\t            error = row.numpy()[0] - y_hat\n", "            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]/(lprev+bprev))\n\t            lvl = alpha*(row.numpy()[0]/seasonal) + (1-alpha)*(lprev + bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*bprev\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t    return errors\n\tdef hw_damped_mul(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma, phi = params\n", "    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n", "            y_hat = (lvl + phi*trend)*seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]/(lprev+phi*bprev))\n\t            lvl = alpha*(row.numpy()[0]/seasonal) + (1-alpha)*(lprev + phi*bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*phi*bprev\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n", "            y_hat = (lvl + phi*trend)*seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = (1-gamma)*seasonal + gamma*(row.numpy()[0]/(lprev+phi*bprev))\n\t            lvl = alpha*(row.numpy()[0]/seasonal) + (1-alpha)*(lprev + phi*bprev)\n\t            trend = beta*(lvl - lprev) + (1-beta)*phi*bprev\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)                     \n\t    return errors"]}
{"filename": "chronokit/exponential_smoothing/initialization/ets_methods.py", "chunked_list": ["import numpy as np\n\t\"\"\"ETS methods to use for initialization of parameters\"\"\"\n\tdef ANN(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components\n\t    alpha = params[0]\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            errors.append(0)\n", "        else:               \n\t            y_hat = lvl\n\t            error = row.numpy()[0] - y_hat\n\t            lvl = lvl + alpha*error\n\t            errors.append(error)\n\t    return errors\n\tdef ANA(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components      \n\t    alpha, gamma = params\n\t    errors = []\n", "    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl +seasonal\n\t            error = row.numpy()[0] - y_hat\n", "            lprev = lvl\n\t            seasonal_t = seasonal+(gamma*error)\n\t            lvl = lprev + alpha*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev = lvl\n", "            seasonal_t = seasonal+(gamma*error)\n\t            lvl = lprev + alpha*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors\n\tdef ANM(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components          \n\t    alpha, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n", "        if index == 0:\n\t            lvl = init_lvl\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl*seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev = lvl\n", "            seasonal_t = seasonal+ gamma*error/lprev\n\t            lvl = lprev + alpha*error/seasonal\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl*seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev = lvl\n\t            seasonal_t = seasonal+ gamma*error/lprev\n", "            lvl = lprev + alpha*error/seasonal\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t    return errors\n\tdef MNM(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n", "            lvl = init_lvl\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl*seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev = lvl\n\t            seasonal_t = seasonal*(1 + gamma*error)\n", "            lvl = lprev*(1 + alpha*error)\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl*seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev = lvl\n\t            seasonal_t = seasonal*(1 + gamma*error)\n\t            lvl = lprev*(1 + alpha*error)\n", "            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t    return errors\n\tdef MNA(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n", "            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl + seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev = lvl\n\t            seasonal_t = seasonal + gamma*error*(lprev+seasonal)\n\t            lvl = lprev + alpha*error*(lprev+ seasonal)\n", "            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev = lvl\n\t            seasonal_t = seasonal + gamma*error*(lprev+seasonal)\n\t            lvl = lprev + alpha*error*(lprev+ seasonal)\n\t            seasonals.append(seasonal_t)\n", "            errors.append(error)\n\t    return errors\n\tdef MNN(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components            \n\t    alpha = params[0]\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            errors.append(0)\n", "        else:               \n\t            y_hat = lvl\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lvl = lvl*(1+alpha*error)\n\t            errors.append(error)\n\t    return errors\n\tdef AAdA(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma, phi = params\n\t    errors = []\n", "    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl + phi*trend + seasonal\n", "            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal + gamma*error\n\t            lvl = lprev + phi*bprev + alpha*error\n\t            trend = phi*bprev + beta*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + phi*trend + seasonal\n", "            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal + gamma*error\n\t            lvl = lprev + phi*bprev + alpha*error\n\t            trend = phi*bprev + beta*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors\n\tdef MAdA(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n", "    alpha, beta, gamma, phi = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n", "            seasonal = init_seasonals[index]     \n\t            y_hat = lvl + phi*trend + seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal + gamma*error\n\t            lvl = lprev + phi*bprev + alpha*error*(lprev + phi*bprev + seasonal)\n\t            trend = phi*bprev + beta*error*(lprev + phi*bprev + seasonal)\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n", "            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + phi*trend + seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal + gamma*error\n\t            lvl = lprev + phi*bprev + alpha*error*(lprev + phi*bprev + seasonal)\n\t            trend = phi*bprev + beta*error*(lprev + phi*bprev + seasonal)\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors\n", "def AAdM(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma, phi = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n", "            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = (lvl + phi*trend)*seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            seasonal_t = seasonal + (gamma*error)/(lvl + phi*trend)\n\t            lvl = lvl + phi*trend + alpha*error/seasonal\n\t            trend = phi*trend + beta*error/seasonal\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n", "        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = (lvl + phi*trend)*seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            seasonal_t = seasonal + (gamma*error)/(lvl + phi*trend)\n\t            lvl = lvl + phi*trend + alpha*error/seasonal\n\t            trend = phi*trend + beta*error/seasonal\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors\n", "def MAdM(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma, phi = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n", "            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = (lvl + phi*trend)*seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal*(gamma*error + 1)\n\t            lvl = (lprev + phi*bprev)*(1+alpha*error)\n\t            trend = phi*bprev + beta*(lprev + phi*bprev)*error\n\t            seasonals.append(seasonal_t)\n", "            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = (lvl + phi*trend)*seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal*(gamma*error + 1)\n\t            lvl = (lprev + phi*bprev)*(1+alpha*error)\n\t            trend = phi*bprev + beta*(lprev + phi*bprev)*error\n\t            seasonals.append(seasonal_t)\n", "            errors.append(error)\n\t    return errors\n\tdef AAA(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n", "            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl + trend +seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal+ gamma*error\n\t            lvl = lprev + bprev+ alpha*error\n", "            trend = bprev + beta*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + trend +seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal+ gamma*error\n\t            lvl = lprev + bprev+ alpha*error\n", "            trend = bprev + beta*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors\n\tdef MAA(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n", "            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = lvl + trend + seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n", "            seasonal_t = seasonal+gamma*error*(lprev+bprev+seasonal)\n\t            lvl = lprev+bprev+alpha*(lprev+bprev+seasonal)*error\n\t            trend = bprev+ beta*(lprev+bprev+seasonal)*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = lvl + trend + seasonal\n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n", "            seasonal_t = seasonal+gamma*error*(lprev+bprev+seasonal)\n\t            lvl = lprev+bprev+alpha*(lprev+bprev+seasonal)*error\n\t            trend = bprev+ beta*(lprev+bprev+seasonal)*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors\n\tdef AAN(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta = params\n\t    errors = []\n", "    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            errors.append(0) \n\t        else:               \n\t            y_hat = lvl + trend \n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            lvl = lprev + bprev + alpha*error\n", "            trend = bprev+ beta*error\n\t            errors.append(error)\n\t    return errors\n\tdef AAdN(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components            \n\t    alpha, beta, phi = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n", "            trend = init_trend\n\t            errors.append(0) \n\t        else:               \n\t            y_hat = lvl + phi*trend \n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n\t            lvl = lprev + phi*bprev + alpha*error\n\t            trend = phi*bprev+ beta*error\n\t            errors.append(error)\n\t    return errors\n", "def MAN(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components            \n\t    alpha, beta = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            errors.append(0) \n\t        else:               \n", "            y_hat = lvl + trend \n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n\t            lvl = (lprev+bprev)*(1+alpha*error)\n\t            trend = bprev+ beta*(lprev+bprev)*error\n\t            errors.append(error)\n\t    return errors\n\tdef MAdN(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components            \n\t    alpha, beta, phi = params\n", "    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            errors.append(0) \n\t        else:               \n\t            y_hat = lvl + phi*trend \n\t            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n", "            lvl = (lprev+phi*bprev)*(1+alpha*error)\n\t            trend = phi*bprev+ beta*(lprev+phi*bprev)*error\n\t            errors.append(error)\n\t    return errors\n\tdef AAM(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma = params\n\t    errors = []\n\t    for index, row in enumerate(dep_var):\n\t        if index == 0:\n", "            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = (lvl + trend)* seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n", "            seasonal_t = seasonal + gamma*error/(lprev+bprev)\n\t            lvl = lprev+bprev + alpha*error/seasonal\n\t            trend = bprev+ beta*error/seasonal\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = (lvl + trend)* seasonal\n\t            error = row.numpy()[0] - y_hat\n\t            lprev, bprev = lvl, trend\n", "            seasonal_t = seasonal + gamma*error/(lprev+bprev)\n\t            lvl = lprev+bprev + alpha*error/seasonal\n\t            trend = bprev+ beta*error/seasonal\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors\n\tdef MAM(dep_var, init_components, params):\n\t    init_lvl, init_trend, init_seasonals, seasonal_periods = init_components           \n\t    alpha, beta, gamma = params\n\t    errors = []\n", "    for index, row in enumerate(dep_var):\n\t        if index == 0:\n\t            lvl = init_lvl\n\t            trend = init_trend\n\t            seasonal = init_seasonals[0]\n\t            seasonals = [seasonal]\n\t            errors.append(0)\n\t        elif index < seasonal_periods:            \n\t            seasonal = init_seasonals[index]     \n\t            y_hat = (lvl + trend)*seasonal\n", "            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal*(gamma*error + 1)\n\t            lvl = (lprev + bprev)*(1+alpha*error)\n\t            trend = bprev + beta*(lprev + bprev)*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)            \n\t        else:               \n\t            seasonal = seasonals[index-seasonal_periods]  \n\t            y_hat = (lvl + trend)*seasonal\n", "            error = (row.numpy()[0] - y_hat)/y_hat\n\t            lprev, bprev = lvl, trend\n\t            seasonal_t = seasonal*(gamma*error + 1)\n\t            lvl = (lprev + bprev)*(1+alpha*error)\n\t            trend = bprev + beta*(lprev + bprev)*error\n\t            seasonals.append(seasonal_t)\n\t            errors.append(error)\n\t    return errors"]}
{"filename": "chronokit/exponential_smoothing/initialization/__init__.py", "chunked_list": ["from .ets_methods import *\n\tfrom .initialization_methods import *\n\tfrom .smoothing_methods import *\n"]}
{"filename": "chronokit/exponential_smoothing/initialization/initialization_methods.py", "chunked_list": ["import numpy as np\n\timport pandas as pd\n\timport torch\n\timport scipy.optimize as opt\n\tfrom scipy.stats import norm\n\tfrom scipy.stats import linregress\n\tfrom chronokit.exponential_smoothing.initialization import ets_methods, smoothing_methods\n\tfrom chronokit.preprocessing.dataloader import DataLoader\n\tdef get_init_method(method):\n\t    init_method = {\"heuristic\": heuristic_initialization,\n", "                    \"mle\": mle_initialization}[method]\n\t    return init_method\n\tdef get_smooth_method(error, trend, seasonal, damped):\n\t    if error:\n\t        smooth_method = { \n\t                            (None, False, None, \"add\"): ets_methods.ANN,\n\t                            (None, False, \"add\", \"add\"): ets_methods.ANA,\n\t                            (None, False, \"mul\", \"add\"): ets_methods.ANM,\n\t                            (\"add\", False, None, \"add\"): ets_methods.AAN,\n\t                            (\"add\", False, \"add\", \"add\"): ets_methods.AAA,\n", "                            (\"add\", False, \"mul\", \"add\"): ets_methods.AAM,\n\t                            (\"add\", True, None, \"add\"): ets_methods.AAdN,\n\t                            (\"add\", True, \"add\", \"add\"): ets_methods.AAdA,\n\t                            (\"add\", True, \"mul\", \"add\"): ets_methods.AAdM,\n\t                            (None, False, None, \"mul\"): ets_methods.MNN,\n\t                            (None, False, \"add\", \"mul\"): ets_methods.MNA,\n\t                            (None, False, \"mul\", \"mul\"): ets_methods.MNM,\n\t                            (\"add\", False, None, \"mul\"): ets_methods.MAN,\n\t                            (\"add\", False, \"add\", \"mul\"): ets_methods.MAA,\n\t                            (\"add\", False, \"mul\", \"mul\"): ets_methods.MAM,\n", "                            (\"add\", True, None, \"mul\"): ets_methods.MAdN,\n\t                            (\"add\", True, \"add\", \"mul\"): ets_methods.MAdA,\n\t                            (\"add\", True, \"mul\", \"mul\"): ets_methods.MAdM\n\t                        }[trend, damped, seasonal, error]\n\t    else:\n\t        smooth_method = { \n\t                        (None, False, None): smoothing_methods.simple_exp,\n\t                        (\"add\", False, None): smoothing_methods.holt_trend,\n\t                        (\"add\", True, None): smoothing_methods.holt_damped_trend,\n\t                        (\"add\", False, \"add\"): smoothing_methods.hw_add,\n", "                        (\"add\", False, \"mul\"): smoothing_methods.hw_mul,\n\t                        (\"add\", True, \"add\"): smoothing_methods.hw_damped_add,\n\t                        (\"add\", True, \"mul\"): smoothing_methods.hw_damped_mul\n\t                        }[trend, damped, seasonal]\n\t    return smooth_method\n\tdef heuristic_initialization(data, trend=False, seasonal=None,\n\t                              seasonal_periods=None):\n\t    \"\"\"\n\t    Heuristic initialization method for initial components\n\t    See: Hyndman et al. section 2.6.1\n", "    \"\"\"\n\t    data = DataLoader(data).to_numpy().copy()\n\t    if data.ndim >= 1:\n\t        data = np.squeeze(data)\n\t    initial_level = None\n\t    initial_trend = None\n\t    initial_seasonal = None\n\t    assert(len(data) >= 10), \"Length of data must be >= for heuristic initialization\"\n\t    if seasonal:\n\t        #Data must have at least 2 full seasonal cycles\n", "        assert (len(data) > 2*seasonal_periods), \"Length of data must be > 2*seasonal_periods\"\n\t        #Max number of seasonal cycles to be used is 5\n\t        seasonal_cycles = min(5, len(data)//seasonal_periods)\n\t        series = pd.Series(data[:seasonal_periods*seasonal_cycles])\n\t        moving_avg = series.rolling(seasonal_periods, center=True).mean()\n\t        if seasonal_periods % 2 == 0:\n\t            moving_avg = moving_avg.shift(-1).rolling(2).mean()\n\t        if seasonal == \"add\":\n\t            detrend = series - moving_avg\n\t        elif seasonal == \"mul\":\n", "            detrend = series/moving_avg\n\t        initial_seasonal = np.zeros(shape=(seasonal_periods,seasonal_cycles))*np.nan\n\t        for i in range(0, seasonal_cycles):\n\t            initial_seasonal[:, i] = detrend[i*seasonal_periods:(i+1)*seasonal_periods]\n\t        initial_seasonal = np.nanmean(initial_seasonal, axis=1)\n\t        if seasonal == \"add\":\n\t            #normalize so that the sum is equal to 1\n\t            initial_seasonal /= np.sum(initial_seasonal)\n\t        elif seasonal == \"mul\":\n\t            #normalize so that the sum is equal to m=seasonal_periods\n", "            initial_seasonal *= seasonal_periods/np.sum(initial_seasonal)\n\t        adjusted_data = moving_avg.dropna().values\n\t    else:\n\t        adjusted_data = data.copy()\n\t    result = linregress(x=np.arange(10), y=adjusted_data[:10])\n\t    initial_level = result[1]\n\t    if trend:\n\t        initial_trend = result[0]\n\t    return initial_level, initial_trend, initial_seasonal\n\tdef mle_initialization(data, trend=None,damped=False, seasonal=None, error_type=None,seasonal_periods=12,alpha=0.1,beta=0.01,gamma=0.01,phi=0.99):\n", "    \"\"\"Maximum Likelihood Estimatin for initialization of initial components\"\"\"\n\t    data = DataLoader(data).to_numpy().copy()\n\t    selected_model = get_smooth_method(error=error_type, trend=trend, seasonal=seasonal, damped=damped)\n\t    # Find the parameters of selected model to maximize the likelihood function.\n\t    params = {\n\t        (None, False, None): [alpha],\n\t        (None, False, \"add\"): [alpha, gamma],\n\t        (None, False, \"mul\"): [alpha, gamma],\n\t        (\"add\", False, None): [alpha, beta],\n\t        (\"add\", False, \"add\"): [alpha, beta, gamma],\n", "        (\"add\", False, \"mul\"): [alpha, beta, gamma],\n\t        (\"add\", True, None): [alpha, beta, phi],\n\t        (\"add\", True, \"add\"): [alpha, beta, gamma, phi],\n\t        (\"add\", True, \"mul\"): [alpha, beta, gamma, phi],\n\t    }\n\t    model_params = params[(trend, damped, seasonal)]\n\t    seasonals = np.zeros(seasonal_periods+1).tolist() # Seasonal components are initialized as zero.\n\t    # Flattening the components and parameters to use in optimization function.\n\t    init_components = [data.mean(), 0] #level and trend\n\t    if seasonal:\n", "        for i in range(seasonal_periods):\n\t            init_components.append(1) #initialize seasonals as 1\n\t    init_components.append(seasonal_periods)\n\t    init_values = init_components + model_params\n\t    def log_likelihood(init_values,data,seasonal_periods,model):\n\t        # Split the initial values to components, seasonal components and parameters.\n\t        components = init_values[:2].tolist()\n\t        seasonal_components = init_values[2:-len(model_params)].tolist()\n\t        params = init_values[-len(model_params):]\n\t        components = components + [seasonal_components] + [seasonal_periods]\n", "        dep_var = DataLoader(data).to_tensor().detach().clone()\n\t        if dep_var.ndim == 1:\n\t            dep_var = torch.unsqueeze(dep_var, axis=1)\n\t        # Calculate the log likelihood of the model.\n\t        errors = model(dep_var,init_components=components,params=params)\n\t        loc = np.array(errors).mean()\n\t        scale = np.array(errors).std()**2\n\t        log_likelihood = np.sum(norm.logpdf(errors, loc=loc, scale=scale))\n\t        return -log_likelihood\n\t    # Use the optimization function to find the maximum likelihood estimates with random initial values\n", "    result_params = opt.minimize(log_likelihood,init_values, args=(data,seasonal_periods,selected_model,))\n\t    def parse_results(result_params):\n\t        # Unflatten the components and parameters.\n\t        results = list(result_params.x)\n\t        initial_level, initial_trend = results[:2]\n\t        initial_seasonal = np.array(results[2:-len(model_params)-1])\n\t        if not trend:\n\t            initial_trend = None\n\t        if not seasonal:\n\t            initial_seasonal = None\n", "        init_components = (initial_level, initial_trend, initial_seasonal)\n\t        return init_components\n\t    result_components = parse_results(result_params)\n\t    return result_components"]}
