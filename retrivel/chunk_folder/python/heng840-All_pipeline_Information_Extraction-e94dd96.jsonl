{"filename": "demo.py", "chunked_list": ["import os\n\t# Disable Tokenizers parallelism\n\tos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\timport pandas\n\timport gradio as gr\n\tfrom transformers import (\n\t    AutoTokenizer,\n\t    AutoModelForTokenClassification,\n\t    AutoModel,\n\t    AutoModelForSequenceClassification,\n", "    pipeline\n\t)\n\timport spacy\n\tnlp_trigger = spacy.load('en_core_web_sm')\n\t# Define a set of auxiliary verbs\n\taux_verbs = {\"be\", \"am\", \"is\", \"are\", \"was\", \"were\", \"been\", \"being\", \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"can\",\n\t             \"could\", \"will\", \"would\", \"shall\", \"should\", \"may\", \"might\", \"must\"}\n\t# load models and tokenizers\n\t# tokenizer_ie = AutoTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-BERT-120M-IE-Chinese\")\n\t# model_ie = AutoModel.from_pretrained(\"IDEA-CCNL/Erlangshen-BERT-120M-IE-Chinese\")\n", "# nlp_ie = pipeline(\"ner\", model=model_ie, tokenizer=tokenizer_ie)\n\ttokenizer_ner = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n\tmodel_ner = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n\ttokenizer_trigger = AutoTokenizer.from_pretrained(\"lfcc/bert-portuguese-event-trigger\")\n\tmodel_trigger = AutoModelForTokenClassification.from_pretrained(\"lfcc/bert-portuguese-event-trigger\")\n\ttokenizer_causal = AutoTokenizer.from_pretrained(\"noahjadallah/cause-effect-detection\")\n\tmodel_causal = AutoModelForTokenClassification.from_pretrained(\"noahjadallah/cause-effect-detection\")\n\ttokenizer_factual = AutoTokenizer.from_pretrained(\"amandakonet/climatebert-fact-checking\")\n\tmodel_factual = AutoModelForSequenceClassification.from_pretrained(\"amandakonet/climatebert-fact-checking\")\n\ttokenizer_event = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n", "model_event = AutoModel.from_pretrained(\"facebook/bart-large\")\n\t# define predict function to perform information extraction\n\tdef predict(sentence):\n\t    # extract triggers\n\t    doc = nlp_trigger(sentence)\n\t    triggers = {}\n\t    for token in doc:\n\t        if token.dep_ == \"ROOT\" or (token.pos_ == \"VERB\" and token.lemma_ not in aux_verbs):\n\t            triggers = token.text\n\t            break\n", "    # extract triggers\n\t    # trigger_nlp = pipeline(\"ner\", model=model_trigger, tokenizer=tokenizer_trigger)\n\t    # triggers = trigger_nlp(sentence)\n\t    argument_nlp = pipeline('ner', model=model_ner, tokenizer=tokenizer_ner)\n\t    arguments = argument_nlp(sentence)\n\t    arguments_new = []\n\t    for arg in arguments:\n\t        arguments_new.append(\n\t            {'entity': arg['entity'], 'word': arg['word']}\n\t        )\n", "    # extract causal relations\n\t    causal_nlp = pipeline(\"ner\", model=model_causal, tokenizer=tokenizer_causal)\n\t    causal_relations = causal_nlp(sentence)\n\t    # extract factual information\n\t    factual_nlp = pipeline(\"text-classification\", model=model_factual, tokenizer=tokenizer_factual)\n\t    factual_info = factual_nlp(sentence)\n\t    # # extract events\n\t    # event_nlp = pipeline(\"text2text-generation\", model=model_event, tokenizer=tokenizer_event)\n\t    # event_input = \"\"\n\t    # for trigger in triggers:\n", "    #     event_input += trigger['word'] + \": \"\n\t    #     event_input += sentence[trigger['start']:trigger['end']] + \" \"\n\t    #     for entity in named_entities:\n\t    #         if entity['start'] >= trigger['start'] and entity['end'] <= trigger['end']:\n\t    #             event_input += entity['word'] + \": \" + entity['entity_group'] + \" \"\n\t    #     event_input += \"\\n\"\n\t    # events = event_nlp(event_input, max_length=1024, do_sample=False)\n\t    # events = [e['generated_text'].strip() for e in events]\n\t    # combine results\n\t    causal_relations_new = []\n", "    for cau in causal_relations:\n\t        if cau['entity'] != 'OTHER':\n\t            causal_relations_new.append({'entity': cau['entity'], 'word': cau['word']})\n\t    fact_label_mapping = ['entailment', 'contradiction', 'neutral']\n\t    factual_new = []\n\t    for fact in factual_info:\n\t        if fact['label'] == 'LABEL_0':\n\t            factual_new.append(fact_label_mapping[0])\n\t        elif fact['label'] == 'LABEL_1':\n\t            factual_new.append(fact_label_mapping[1])\n", "        else:\n\t            factual_new.append(fact_label_mapping[2])\n\t    results = {\n\t        # 'entities': named_entities,\n\t        'triggers': triggers,\n\t        'arguments': arguments_new,\n\t        'causal': causal_relations_new,\n\t        'factual': factual_new,\n\t        # 'events': events\n\t    }\n", "    results = str('triggers:' + str(triggers) + '\\n\\n' + 'arguments:' + str(arguments_new) + '\\n\\n' + 'causal:' + str(\n\t        causal_relations_new) + '\\n\\n' + 'factual:' + str(factual_new))\n\t    # print(results)\n\t    # results_pd = pandas.json_normalize(results)\n\t    # return results_pd\n\t    return results\n\tsentence = 'Bob, I think that the reason everybody in the south -- you know, first of all, we were -- when Franklin ' \\\n\t           'Roosevelt was elected president, ' \\\n\t           'we had been living what we thought was still a conquered nation after the Civil War'\n\tx = predict(sentence)\n", "print(x)\n\twith gr.Blocks() as demo:\n\t    name = gr.Textbox(label=\"Enter a sentence or a document\")\n\t    output = gr.Textbox(label=\"Output Box\")\n\t    greet_btn = gr.Button(\"Extract\")\n\t    greet_btn.click(fn=predict, inputs=name, outputs=output)\n\tdemo.launch(share=True)\n\t# fixme done 总是出现numpy.float的原因在score上。\n"]}
{"filename": "demostrations/demo_ee.py", "chunked_list": ["import nltk\n\timport numpy as np\n\timport torch\n\timport gradio as gr\n\t# from consts import test_event1, test_event2,\n\tfrom torch.utils import data\n\tNONE = 'O'\n\tPAD = \"[PAD]\"\n\tUNK = \"[UNK]\"\n\t# for BERT\n", "CLS = '[CLS]'\n\tSEP = '[SEP]'\n\tmax_length = 400\n\tall_triggers, trigger2idx, idx2trigger = build_vocab(TRIGGERS)\n\tall_arguments, argument2idx, idx2argument = build_vocab(ARGUMENTS, BIO_tagging=False)\n\thparams = get_hparams()\n\ttokenizer = BertTokenizer.from_pretrained(hparams.model_name, do_lower_case=False, never_split=(PAD, CLS, SEP, UNK))\n\tclass Data_input(data.Dataset):\n\t    def __init__(self, document):\n\t        self.sent_li = []\n", "        self.entities_li = []\n\t        self.postags_li = []\n\t        self.triggers_li = []\n\t        self.arguments_li = []\n\t        self.entities_li = []\n\t        words = nltk.word_tokenize(document)\n\t        split_num = len(words) // max_length\n\t        for i in range(split_num + 1):\n\t            if i < split_num:\n\t                w = words[i * max_length: (i + 1) * max_length]\n", "            else:\n\t                w = words[i * max_length:]\n\t            triggers = [NONE] * len(w)\n\t            arguments = {\n\t                'candidates': [],\n\t                'events': {},\n\t            }\n\t            self.sent_li.append([CLS] + w + [SEP])\n\t            self.triggers_li.append(triggers)\n\t            self.arguments_li.append(arguments)\n", "    def __len__(self):\n\t        return len(self.sent_li)\n\t    def __getitem__(self, idx):\n\t        words = self.sent_li[idx]\n\t        triggers = self.triggers_li[idx]\n\t        arguments = self.arguments_li[idx]\n\t        # We give credits only to the first piece.\n\t        tokens_x = []\n\t        is_heads = []\n\t        for w in words:\n", "            tokens = tokenizer.tokenize(w) if w not in [CLS, SEP] else [w]\n\t            tokens_xx = tokenizer.convert_tokens_to_ids(tokens)\n\t            if w in [CLS, SEP]:\n\t                is_head = [0]\n\t            else:\n\t                is_head = [1] + [0] * (len(tokens) - 1)\n\t            tokens_x.extend(tokens_xx)\n\t            is_heads.extend(is_head)\n\t        triggers_y = [trigger2idx[t] for t in triggers]\n\t        head_indexes = []\n", "        for i in range(len(is_heads)):\n\t            if is_heads[i]:\n\t                head_indexes.append(i)\n\t        seqlen = len(tokens_x)\n\t        return tokens_x, triggers_y, arguments, seqlen, head_indexes, words, triggers\n\t    def get_samples_weight(self):\n\t        samples_weight = []\n\t        for triggers in self.triggers_li:\n\t            not_none = False\n\t            for trigger in triggers:\n", "                if trigger != NONE:\n\t                    not_none = True\n\t                    break\n\t            if not_none:\n\t                samples_weight.append(5.0)\n\t            else:\n\t                samples_weight.append(1.0)\n\t        return np.array(samples_weight)\n\tdef extract_events(user_input):\n\t    hp = get_hparams()\n", "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\t    model = torch.load(f'{hp.model_save_path}/best_model_11.pt')\n\t    if device == 'cuda':\n\t        model = model.cuda()\n\t    if hasattr(model, 'module'):\n\t        model = model.module\n\t    model.eval()\n\t    data_input = Data_input(user_input)\n\t    data_iter = data.DataLoader(dataset=data_input,\n\t                                batch_size=len(data_input.triggers_li),\n", "                                shuffle=False,\n\t                                num_workers=4,\n\t                                collate_fn=pad)\n\t    words_all = []\n\t    triggers_all = []\n\t    triggers_hat_all = []\n\t    arguments_all = []\n\t    arguments_hat_all = []\n\t    # if direct:\n\t    #     return test_event2\n", "    with torch.no_grad():\n\t        for i, batch in enumerate(data_iter):\n\t            tokens_x_2d, triggers_y_2d, arguments_2d, seqlens_1d, head_indexes_2d, words_2d, triggers_2d = batch\n\t            trigger_logits, triggers_y_2d, trigger_hat_2d, argument_hidden, argument_keys \\\n\t                = model.predict_triggers(tokens_x_2d=tokens_x_2d, head_indexes_2d=head_indexes_2d,\n\t                                         triggers_y_2d=triggers_y_2d, arguments_2d=arguments_2d)\n\t        words_all.extend(words_2d)\n\t        triggers_all.extend(triggers_2d)\n\t        triggers_hat_all.extend(trigger_hat_2d.cpu().numpy().tolist())\n\t        arguments_all.extend(arguments_2d)\n", "        if len(argument_keys) > 0:\n\t            argument_logits, arguments_y_1d, argument_hat_1d, argument_hat_2d = \\\n\t                model.predict_arguments(argument_hidden, argument_keys, arguments_2d)\n\t            arguments_hat_all.extend(argument_hat_2d)\n\t        else:\n\t            batch_size = len(arguments_2d)\n\t            argument_hat_2d = [{'events': {}} for _ in range(batch_size)]\n\t            arguments_hat_all.extend(argument_hat_2d)\n\t    triggers_pred = []\n\t    arguments_pred = []\n", "    events = []\n\t    for i, (words, triggers, triggers_hat, arguments, arguments_hat) \\\n\t            in enumerate(zip(words_all, triggers_all, triggers_hat_all, arguments_all, arguments_hat_all)):\n\t        triggers_hat = triggers_hat[:len(words)]\n\t        triggers_hat = [idx2trigger[hat] for hat in triggers_hat]\n\t        # [(ith sentence, t_start, t_end, t_type_str)]\n\t        triggers_pred.extend([(i, *item) for item in find_triggers(triggers_hat)])\n\t        for trigger in arguments_hat['events']:\n\t            t_start, t_end, t_type_str = trigger\n\t            for argument in arguments_hat['events'][trigger]:\n", "                a_start, a_end, a_type_idx = argument\n\t                arguments_pred.append((i, t_start, t_end, t_type_str, a_start, a_end, a_type_idx))\n\t        event = {\n\t            'trigger': triggers_pred,\n\t            'argument': arguments_pred,\n\t        }\n\t        events.append(event)\n\t    return events\n\tif __name__ == \"__main__\":\n\t    input_text = gr.inputs.Textbox(lines=10, label=\"Input Text\")\n", "    output_text = gr.outputs.Textbox(label=\"Output\")\n\t    gr.Interface(fn=extract_events, inputs=input_text, outputs=output_text, title=\"Event Extraction\",\n\t                 description=\"Enter some text and the model will extract events.\").launch(share=True)\n"]}
{"filename": "demostrations/demo_casaul.py", "chunked_list": ["import torch\n\timport transformers\n\timport pandas\n\timport gradio as gr\n\tfrom transformers import (\n\t    AutoTokenizer,\n\t    AutoModelForTokenClassification,\n\t    AutoModel,\n\t    AutoModelForSequenceClassification,\n\t    pipeline\n", ")\n\t# load models and tokenizers\n\ttokenizer_ie = AutoTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-BERT-120M-IE-Chinese\")\n\tmodel_ie = AutoModel.from_pretrained(\"IDEA-CCNL/Erlangshen-BERT-120M-IE-Chinese\")\n\tnlp_ie = pipeline(\"ner\", model=model_ie, tokenizer=tokenizer_ie)\n\ttokenizer_ner = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n\tmodel_ner = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n\ttokenizer_trigger = AutoTokenizer.from_pretrained(\"lfcc/bert-portuguese-event-trigger\")\n\tmodel_trigger = AutoModelForTokenClassification.from_pretrained(\"lfcc/bert-portuguese-event-trigger\")\n\ttokenizer_causal = AutoTokenizer.from_pretrained(\"noahjadallah/cause-effect-detection\")\n", "model_causal = AutoModelForTokenClassification.from_pretrained(\"noahjadallah/cause-effect-detection\")\n\ttokenizer_factual = AutoTokenizer.from_pretrained(\"amandakonet/climatebert-fact-checking\")\n\tmodel_factual = AutoModelForSequenceClassification.from_pretrained(\"amandakonet/climatebert-fact-checking\")\n\ttokenizer_event = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n\tmodel_event = AutoModel.from_pretrained(\"facebook/bart-large\")\n\t# define predict function to perform information extraction\n\tdef predict(sentence):\n\t    # extract triggers\n\t    trigger_nlp = pipeline(\"ner\", model=model_trigger, tokenizer=tokenizer_trigger)\n\t    triggers = trigger_nlp(sentence)\n", "    argument_nlp = pipeline('ner', model=model_ner, tokenizer=tokenizer_ner)\n\t    arguments = argument_nlp(sentence)\n\t    # extract causal relations\n\t    causal_nlp = pipeline(\"ner\", model=model_causal, tokenizer=tokenizer_causal)\n\t    causal_relations = causal_nlp(sentence)\n\t    # extract factual information\n\t    factual_nlp = pipeline(\"text-classification\", model=model_factual, tokenizer=tokenizer_factual)\n\t    factual_info = factual_nlp(sentence)\n\t    # # extract events\n\t    # event_nlp = pipeline(\"text2text-generation\", model=model_event, tokenizer=tokenizer_event)\n", "    # event_input = \"\"\n\t    # for trigger in triggers:\n\t    #     event_input += trigger['word'] + \": \"\n\t    #     event_input += sentence[trigger['start']:trigger['end']] + \" \"\n\t    #     for entity in named_entities:\n\t    #         if entity['start'] >= trigger['start'] and entity['end'] <= trigger['end']:\n\t    #             event_input += entity['word'] + \": \" + entity['entity_group'] + \" \"\n\t    #     event_input += \"\\n\"\n\t    # events = event_nlp(event_input, max_length=1024, do_sample=False)\n\t    # events = [e['generated_text'].strip() for e in events]\n", "    # combine results\n\t    results = {\n\t        # 'entities': named_entities,\n\t        'triggers': triggers,\n\t        'arguments': arguments,\n\t        'causal': causal_relations,\n\t        'factual': factual_info,\n\t        # 'events': events\n\t    }\n\t    print(results)\n", "    results_pd = pandas.DataFrame.from_dict(results)\n\t    return results_pd\n\tsentence = 'Bob, I think that the reason everybody in the south -- you know, first of all, we were -- when Franklin Roosevelt was elected president, we had been living what we thought was still a conquered nation after the Civil War'\n\tx = predict(sentence)\n\tprint(x)"]}
{"filename": "demostrations/demo_factual.py", "chunked_list": []}
{"filename": "demostrations/__init__.py", "chunked_list": []}
{"filename": "demostrations/demo_ner.py", "chunked_list": ["import torch\n\timport transformers\n\timport gradio as gr\n\tfrom transformers import AutoTokenizer, AutoModelForTokenClassification\n\tfrom transformers import pipeline\n\t# tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n\t# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n\ttokenizer = AutoTokenizer.from_pretrained(\"Davlan/bert-base-multilingual-cased-ner-hrl\")\n\tmodel = AutoModelForTokenClassification.from_pretrained(\"Davlan/bert-base-multilingual-cased-ner-hrl\")\n\tnlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n", "example = \"My name is Wolfgang and I live in Berlin\"\n\t#\n\t# ner_results = nlp(example)\n\t# print(ner_results)\n\t# 创建predict函数来执行信息抽取\n\tdef predict(sentence):\n\t    ner_results = nlp(sentence)\n\t    # print(ner_results)\n\t    return ner_results\n\t# predict(example)\n", "# 创建输入组件和输出组件\n\tinput_text = gr.inputs.Textbox(label=\"输入句子\")\n\toutput_df = gr.outputs.Dataframe(type='array', label=\"输出结果\")\n\t# 将输入组件和输出组件传递给Gradio接口\n\tiface = gr.Interface(fn=predict, inputs=input_text, outputs=output_df)\n\t# 启动Gradio界面\n\tiface.launch(share=True)\n"]}
{"filename": "src/Event_causality/model.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom transformers import BertModel\n\tclass BertCausalModel(nn.Module):\n\t    def __init__(self, y_num):\n\t        super(BertCausalModel, self).__init__()\n\t        self.bert = BertModel.from_pretrained('bert-base-uncased')\n\t        self.drop = nn.Dropout(0.4)\n\t        self.fc = nn.Linear(768*3, y_num)\n\t    def forward(self, sentences_s, mask_s, sentences_t, mask_t, event1, event1_mask, event2, event2_mask):\n", "        \"\"\"\n\t        :param sentences_s: source\n\t        :param mask_s:\n\t        :param sentences_t: target\n\t        :param mask_t:\n\t        :param event1:\n\t        :param event1_mask:\n\t        :param event2:\n\t        :param event2_mask:\n\t        :return:\n", "        \"\"\"\n\t        enc_s = self.bert(sentences_s, attention_mask = mask_s)\n\t        enc_t = self.bert(sentences_t, attention_mask=mask_t)\n\t        hidden_enc_s = enc_s[0]\n\t        hidden_enc_t = enc_t[0]\n\t        event1 = torch.cat([torch.index_select(a, 0, i).unsqueeze(0) for a, i in zip(hidden_enc_s, event1)], dim=0)\n\t        event2 = torch.cat([torch.index_select(a, 0, i).unsqueeze(0) for a, i in zip(hidden_enc_t, event2)], dim=0)\n\t        m1 = event1_mask.unsqueeze(-1).expand_as(event1).float()\n\t        m2 = event2_mask.unsqueeze(-1).expand_as(event2).float()\n\t        event1 = event1 * m1\n", "        event2 = event2 * m2\n\t        opt1 = torch.sum(event1, dim=1)\n\t        opt2 = torch.sum(event2, dim=1)\n\t        opt = torch.cat((enc_s[1], opt1, opt2), 1)\n\t        opt = self.fc(opt)\n\t        return opt\n"]}
{"filename": "src/Event_causality/train.py", "chunked_list": ["import os\n\timport pickle\n\timport random\n\tfrom os.path import exists\n\timport torch\n\tfrom transformers import AdamW, BertTokenizer, get_linear_schedule_with_warmup\n\tfrom dataset import Dataset\n\tfrom model import BertCausalModel\n\tfrom preprocess import make_data_pickle\n\tfrom utils import split_train_test, compute_f1, get_hparams\n", "import logging\n\tdef train(processed_files, use_scheduler=True, batch_size_train=25, batch_size_test=20, epoch_nums=100,\n\t          saved_models=None, learning_rate=2e-5, output_dir=None):\n\t    logging.basicConfig(level=logging.INFO, filename=output_dir, filemode='w')\n\t    data_pickle = f'{processed_files}/data.pickle'\n\t    debug = False\n\t    if not exists(data_pickle) or debug:\n\t        raw_pickle = f'{processed_files}/document_raw.pickle'\n\t        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\t        make_data_pickle(raw_pickle=raw_pickle, data_pickle=data_pickle, tokenizer=tokenizer, debug=True)\n", "    with open(data_pickle, 'rb') as f:\n\t        data = pickle.load(f)\n\t    train_set, test_set = split_train_test(data)\n\t    filter = []\n\t    for d in train_set:\n\t        if d[-1] == 'NULL':\n\t            if random.random() < 0.7:\n\t                continue\n\t        filter.append(d)\n\t    train_set = filter\n", "    train_dataset = Dataset(batch_size=batch_size_train, dataset=train_set)\n\t    test_dataset = Dataset(batch_size=batch_size_test, dataset=test_set)\n\t    device = torch.device(\"cuda\")\n\t    model = BertCausalModel(y_num=2).to(device)  # binary\n\t    if not exists(saved_models):\n\t        os.makedirs(saved_models)\n\t    param_optimizer = list(model.named_parameters())\n\t    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n\t    optimizer_grouped_parameters = [\n\t        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n", "        {'params': [p for n, p in param_optimizer if any(\n\t            nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n\t    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n\t    scheduler = None\n\t    if use_scheduler:\n\t        logging.info('with_scheduler')\n\t        t_total = int(len(train_set) / 25 / 1 * 60)\n\t        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * 0.1),\n\t                                                    num_training_steps=t_total)\n\t    else:\n", "        logging.info('wo_scheduler')\n\t    loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n\t    max_f1 = 0\n\t    saved_model_path = None\n\t    for epoch in range(epoch_nums):\n\t        model.train()\n\t        for batch in train_dataset.get_tqdm(device, True):\n\t            sentences_s, mask_s, sentences_t, mask_t, event1, event1_mask, event2, event2_mask, data_y = batch\n\t            opt = model(sentences_s, mask_s, sentences_t, mask_t, event1, event1_mask, event2, event2_mask)\n\t            loss = loss_fn(opt, data_y)\n", "            optimizer.zero_grad()\n\t            loss.backward()\n\t            optimizer.step()\n\t            if use_scheduler:\n\t                scheduler.step()\n\t        model.eval()\n\t        with torch.no_grad():\n\t            predicted_all = []\n\t            gold_all = []\n\t            for batch in test_dataset.reader(device, False):\n", "                sentences_s, mask_s, sentences_t, mask_t, event1, event1_mask, event2, event2_mask, data_y = batch\n\t                opt = model(sentences_s, mask_s, sentences_t, mask_t, event1, event1_mask, event2, event2_mask)\n\t                predicted = torch.argmax(opt, -1)\n\t                predicted = list(predicted.cpu().numpy())\n\t                predicted_all += predicted\n\t                gold = list(data_y.cpu().numpy())\n\t                gold_all += gold\n\t            p, r, f = compute_f1(gold_all, predicted_all)\n\t            if f > max_f1:\n\t                max_f1 = f\n", "                if saved_model_path:\n\t                    os.remove(saved_model_path)\n\t                saved_model_path = f'{saved_models}/best_model_{epoch}.pt'\n\t                torch.save(model, saved_model_path)\n\t                logging.info(f'epoch={epoch}: p={p}, r={r}, f1={f}')\n\tif __name__ == '__main__':\n\t    hparams = get_hparams()\n\t    train(processed_files=hparams.processed_files, use_scheduler=hparams.use_scheduler,\n\t          batch_size_train=hparams.batch_size_train, batch_size_test=hparams.batch_size_test,\n\t          epoch_nums=hparams.epoch_nums, saved_models=hparams.saved_models, learning_rate=hparams.learning_rate,\n", "          output_dir=hparams.output_dir)\n"]}
{"filename": "src/Event_causality/read_document.py", "chunked_list": ["import collections\n\timport os\n\timport os.path\n\timport pickle\n\tfrom lxml import etree\n\tdef read_evaluation_file(fn):\n\t    res = []\n\t    if not os.path.exists(fn):\n\t        return res\n\t    for line in open(fn):\n", "        fields = line.strip().split('\\t')\n\t        res.append(fields)\n\t    return res\n\tdef all_tokens(filename):\n\t    ecb_plus = etree.parse(filename, etree.XMLParser(remove_blank_text=True))\n\t    root_ecb_plus = ecb_plus.getroot()\n\t    root_ecb_plus.getchildren()\n\t    all_token = []\n\t    for elem in root_ecb_plus.findall('token'):\n\t        temp = (elem.get('t_id'), elem.get('sentence'),\n", "                elem.get('number'), elem.text)\n\t        all_token.append(temp)\n\t    return all_token\n\tdef extract_event_CAT(etreeRoot):\n\t    \"\"\"\n\t    :param etreeRoot: ECB+/ESC XML root\n\t    :return: dictionary with annotated events in ECB+\n\t    \"\"\"\n\t    event_dict = collections.defaultdict(list)\n\t    for elem in etreeRoot.findall('Markables/'):\n", "        if elem.tag.startswith(\"ACTION\") or elem.tag.startswith(\"NEG_ACTION\"):\n\t            for token_id in elem.findall('token_anchor'):  # the event should have at least one token\n\t                event_mention_id = elem.get('m_id', 'nothing')\n\t                token_mention_id = token_id.get('t_id', 'nothing')\n\t                event_dict[event_mention_id].append(token_mention_id)\n\t    return event_dict\n\tdef extract_plotLink(etreeRoot, d):\n\t    \"\"\"\n\t    :param etreeRoot: ESC XML root\n\t    :param d: dictionary with annotated events in ESC (event_dict)\n", "    :return:\n\t    \"\"\"\n\t    plot_dict = collections.defaultdict(list)\n\t    for elem in etreeRoot.findall('Relations/'):\n\t        if elem.tag == \"PLOT_LINK\":\n\t            source_pl = elem.find('source').get('m_id', 'null')\n\t            target_pl = elem.find('target').get('m_id', 'null')\n\t            rel_valu = elem.get('relType', 'null')\n\t            if source_pl in d:\n\t                val1 = \"_\".join(d[source_pl])\n", "                if target_pl in d:\n\t                    val2 = \"_\".join(d[target_pl])\n\t                    plot_dict[(val1, val2)] = rel_valu\n\t    return plot_dict\n\tdef read_file(ecb_start_new, evaluate_file):\n\t    ecb_star = etree.parse(ecb_start_new, etree.XMLParser(remove_blank_text=True))\n\t    ecb_star_root = ecb_star.getroot()\n\t    ecb_star_root.getchildren()\n\t    ecb_star_events = extract_event_CAT(ecb_star_root)\n\t    ecb_star_events_plotLink = extract_plotLink(ecb_star_root, ecb_star_events)\n", "    evaluation_data = read_evaluation_file(evaluate_file)\n\t    return ecb_star_events, ecb_star_events_plotLink, evaluation_data\n\tdef make_corpus(ecb_start_topic, evaluation_topic, datadict):\n\t    if os.path.isdir(ecb_start_topic):\n\t        if ecb_start_topic[-1] != '/':\n\t            ecb_start_topic += '/'\n\t        if evaluation_topic[-1] != '/':\n\t            evaluation_topic += '/'\n\t        for f in os.listdir(evaluation_topic):\n\t            if f.endswith('plus.xml'):\n", "                ecb_file = f\n\t                star_file = ecb_start_topic + f + \".xml\"\n\t                evaluate_file = evaluation_topic + f\n\t                ecb_star_events, ecb_star_events_plotLink, evaluation_data = read_file(star_file, evaluate_file)\n\t                for key in ecb_star_events:\n\t                    ecb_star_events[key] = '_'.join(ecb_star_events[key])\n\t                all_token = all_tokens(star_file)\n\t                datadict[star_file] = [all_token, ecb_star_events, ecb_star_events_plotLink, evaluation_data]\n\tdef make_raw_pickle():\n\t    version = 'v1.0'\n", "    ECB_star_Topic = '../../DataSets/annotated_data/' + version + '/'\n\t    EvaluationTopic = '../../DataSets/evaluation_format/full_corpus/' + version + '/event_mentions_extended/'\n\t    data_dict = {}\n\t    for topic in os.listdir(f'{ECB_star_Topic}'):\n\t        if os.path.isdir(f'{ECB_star_Topic}' + topic):\n\t            dir1 = ECB_star_Topic + topic\n\t            dir2 = EvaluationTopic + topic\n\t            make_corpus(dir1, dir2, data_dict)\n\t    processed_files = 'processed_files'\n\t    if not os.path.exists(processed_files):\n", "        os.makedirs(processed_files)\n\t    with open(f'{processed_files}/document_raw.pickle', 'wb') as f:\n\t        pickle.dump(data_dict, f, pickle.HIGHEST_PROTOCOL)\n"]}
{"filename": "src/Event_causality/dataset.py", "chunked_list": ["import pickle\n\timport random\n\timport sys\n\timport torch\n\tfrom allennlp.common.util import pad_sequence_to_length\n\tfrom allennlp.nn.util import get_mask_from_sequence_lengths\n\tfrom tqdm import tqdm\n\tclass Dataset(object):\n\t    def __init__(self, batch_size, dataset):\n\t        super(Dataset, self).__init__()\n", "        self.dataset = None\n\t        self.index_length = None\n\t        self.shuffle_list = None\n\t        self.batch_size = batch_size\n\t        self.y_label = {\n\t            'NULL': 0,\n\t            'null': 0,\n\t            'FALLING_ACTION': 1,\n\t            'PRECONDITION': 1,\n\t            'Coref': 1\n", "        }\n\t        self.construct_index(dataset)\n\t    def construct_index(self, dataset):\n\t        self.dataset = dataset\n\t        self.index_length = len(dataset)\n\t        self.shuffle_list = list(range(0, self.index_length))\n\t    def shuffle(self):\n\t        random.shuffle(self.shuffle_list)\n\t    def get_tqdm(self, device, shuffle=True):\n\t        return tqdm(self.reader(device, shuffle), mininterval=2, total=self.index_length // self.batch_size,\n", "                    leave=False, file=sys.stdout, ncols=80)\n\t    def reader(self, device, shuffle):\n\t        cur_idx = 0\n\t        while cur_idx < self.index_length:\n\t            end_index = min(cur_idx + self.batch_size, self.index_length)\n\t            batch = [self.dataset[self.shuffle_list[index]] for index in range(cur_idx, end_index)]\n\t            cur_idx = end_index\n\t            yield self.batchify(batch, device)\n\t        if shuffle:\n\t            self.shuffle()\n", "    def batchify(self, batch, device):\n\t        sentence_len_s = [len(tup[1]) for tup in batch]\n\t        sentence_len_t = [len(tup[2]) for tup in batch]\n\t        max_sentence_len_s = max(sentence_len_s)\n\t        max_sentence_len_t = max(sentence_len_t)\n\t        event1_lens = [len(tup[2]) for tup in batch]\n\t        event2_lens = [len(tup[3]) for tup in batch]\n\t        sentences_s = list()\n\t        sentences_t = list()\n\t        event1 = list()\n", "        event2 = list()\n\t        data_y = list()\n\t        for data in batch:\n\t            sentences_s.append(data[1])\n\t            sentences_t.append(data[2])\n\t            event1.append(data[3])\n\t            event2.append(data[4])\n\t            y = self.y_label[data[5]] if data[5] in self.y_label else 0\n\t            data_y.append(y)\n\t        sentences_s = list(map(lambda x: pad_sequence_to_length(x, max_sentence_len_s), sentences_s))\n", "        sentences_t = list(map(lambda x: pad_sequence_to_length(x, max_sentence_len_t), sentences_t))\n\t        event1 = list(map(lambda x: pad_sequence_to_length(x, 5), event1))\n\t        event2 = list(map(lambda x: pad_sequence_to_length(x, 5), event2))\n\t        mask_sentences_s = get_mask_from_sequence_lengths(torch.LongTensor(sentence_len_s), max_sentence_len_s)\n\t        mask_sentences_t = get_mask_from_sequence_lengths(torch.LongTensor(sentence_len_t), max_sentence_len_t)\n\t        mask_even1 = get_mask_from_sequence_lengths(torch.LongTensor(event1_lens), 5)\n\t        mask_even2 = get_mask_from_sequence_lengths(torch.LongTensor(event2_lens), 5)\n\t        return [torch.LongTensor(sentences_s).to(device), mask_sentences_s.to(device),\n\t                torch.LongTensor(sentences_t).to(device), mask_sentences_t.to(device),\n\t                torch.LongTensor(event1).to(device), mask_even1.to(device),\n", "                torch.LongTensor(event2).to(device), mask_even2.to(device),\n\t                torch.LongTensor(data_y).to(device)]\n\tif __name__ == '__main__':\n\t    with open('processed_files/data.pickle', 'rb') as f:\n\t        # The protocol version used is detected automatically, so we do not\n\t        # have to specify it.\n\t        data = pickle.load(f)\n\t    dataset = Dataset(10, data[:20])\n\t    for batch in dataset.reader('cpu', True):\n\t        sentences_s, \\\n", "        mask_s, \\\n\t        sentences_t,\\\n\t        mask_t, \\\n\t        event1, \\\n\t        event1_mask,\\\n\t        event2, \\\n\t        event2_mask,\\\n\t        y = \\\n\t            batch\n\t        print(sentences_s[0])\n", "        print(mask_s[0])\n\t        print(event1[0])\n\t        print(event2[0])\n\t        break\n"]}
{"filename": "src/Event_causality/utils.py", "chunked_list": ["import argparse\n\tdef get_hparams():\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument('--processed_files', type=str, default='processed_files')\n\t    parser.add_argument('--use_scheduler', default=True, action='store_false')\n\t    parser.add_argument('--batch_size_train', type=int, default=25)\n\t    parser.add_argument('--batch_size_test', type=int, default=20)\n\t    parser.add_argument('--epoch_nums', type=int, default=100)\n\t    parser.add_argument('--saved_models', type=str, default='saved_models/wo_scheduler')\n\t    parser.add_argument('--learning_rate', type=float, default=2e-5)\n", "    parser.add_argument('--output_dir', type=str, default='output_with_scheduler.txt')\n\t    hparams = parser.parse_args()\n\t    return hparams\n\tdef split_train_test(dataset):\n\t    train_set = []\n\t    test_set = []\n\t    test_topic = ['1', '3', '4', '5']\n\t    for data in dataset:\n\t        t = data[0]\n\t        if t.split('/')[-2] in test_topic:\n", "            test_set.append(data)\n\t        else:\n\t            train_set.append(data)\n\t    return train_set, test_set\n\tdef compute_f1(gold, predicted):\n\t    c_predict = 0\n\t    c_correct = 0\n\t    c_gold = 0\n\t    for g, p in zip(gold, predicted):\n\t        if g != 0:\n", "            c_gold += 1\n\t        if p != 0:\n\t            c_predict += 1\n\t        if g != 0 and p != 0:\n\t            c_correct += 1\n\t    p = c_correct / (c_predict + 1e-100)\n\t    r = c_correct / c_gold\n\t    f = 2 * p * r / (p + r + 1e-100)\n\t    # print('correct', c_correct)\n\t    # print('predicted', c_predict)\n", "    # print('golden', c_gold)\n\t    return p, r, f\n"]}
{"filename": "src/Event_causality/eval.py", "chunked_list": ["import pickle\n\tfrom os.path import exists\n\timport torch\n\tfrom transformers import BertTokenizer\n\tfrom dataset import Dataset\n\tfrom preprocess import make_data_pickle\n\tfrom utils import split_train_test, compute_f1, get_hparams\n\tdef evaluate(processed_files, batch_size_test=20, saved_models=None):\n\t    data_pickle = f'{processed_files}/data.pickle'\n\t    if not exists(data_pickle):\n", "        raw_pickle = f'{processed_files}/document_raw.pickle'\n\t        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\t        make_data_pickle(raw_pickle=raw_pickle, data_pickle=data_pickle, tokenizer=tokenizer)\n\t    with open(data_pickle, 'rb') as f:\n\t        data = pickle.load(f)\n\t    _, test_set = split_train_test(data)\n\t    test_dataset = Dataset(batch_size=batch_size_test, dataset=test_set)\n\t    device = torch.device(\"cuda\")\n\t    model = torch.load(f'{saved_models}/best_model_12.pt')\n\t    model.eval()\n", "    with torch.no_grad():\n\t        predicted_all = []\n\t        gold_all = []\n\t        for batch in test_dataset.reader(device, False):\n\t            sentences_s, mask_s, sentences_t, mask_t, event1, event1_mask, event2, event2_mask, data_y = batch\n\t            opt = model(sentences_s, mask_s, sentences_t, mask_t, event1, event1_mask, event2, event2_mask)\n\t            predicted = torch.argmax(opt, -1)\n\t            predicted = list(predicted.cpu().numpy())\n\t            predicted_all += predicted\n\t            gold = list(data_y.cpu().numpy())\n", "            gold_all += gold\n\t        p, r, f = compute_f1(gold_all, predicted_all)\n\t        print(p, r, f)\n\tif __name__ == '__main__':\n\t    hparams = get_hparams()\n\t    evaluate(processed_files=hparams.processed_files, batch_size_test=hparams.batch_size_test,\n\t             saved_models=hparams.saved_models)\n"]}
{"filename": "src/Event_causality/preprocess.py", "chunked_list": ["import pickle\n\tfrom os.path import exists\n\tfrom transformers import BertTokenizer\n\tfrom read_document import make_raw_pickle\n\tdef get_sentence_number(s, all_token):\n\t    tid = s.split('_')[0]\n\t    for token in all_token:\n\t        if token[0] == tid:\n\t            return token[1]\n\tdef nth_sentence(sen_no, all_token):\n", "    res = []\n\t    for token in all_token:\n\t        if token[1] == sen_no:\n\t            res.append(token[-1])\n\t    return res\n\tdef get_sentence_offset(s, all_token):\n\t    positions = []\n\t    for c in s.split('_'):\n\t        token = all_token[int(c) - 1]\n\t        positions.append(token[2])\n", "    return '_'.join(positions)\n\tdef make_data_pickle(raw_pickle, data_pickle, tokenizer, debug=True):\n\t    # make_raw_pickle()\n\t    if not exists(raw_pickle) or debug:\n\t        make_raw_pickle()\n\t    with open(raw_pickle, 'rb') as f:\n\t        documents = pickle.load(f)\n\t    data_set = []\n\t    count = 0\n\t    for doc in documents:\n", "        [all_token,\n\t         ecb_star_events,\n\t         ecb_star_events_plotLink,\n\t         evaluation_data] \\\n\t            = documents[doc]\n\t        for event1 in ecb_star_events:\n\t            for event2 in ecb_star_events:\n\t                if event1 == event2:  # event ID\n\t                    continue\n\t                offset1 = ecb_star_events[event1]\n", "                offset2 = ecb_star_events[event2]\n\t                rel = 'NULL'\n\t                for elem in evaluation_data:\n\t                    e1, e2, value = elem\n\t                    if e1 == offset1 and e2 == offset2:\n\t                        rel = value\n\t                sen_s = get_sentence_number(offset1, all_token)\n\t                sen_t = get_sentence_number(offset2, all_token)\n\t                if abs(int(sen_s) - int(sen_t)) == 0:  # #\n\t                    if rel != 'NULL':\n", "                        count += 1\n\t                    sentence_s = nth_sentence(sen_s, all_token)\n\t                    sentence_t = nth_sentence(sen_t, all_token)\n\t                    sen_offset1 = get_sentence_offset(offset1, all_token)\n\t                    sen_offset2 = get_sentence_offset(offset2, all_token)\n\t                    span1 = [int(x) for x in sen_offset1.split('_')]\n\t                    span2 = [int(x) for x in sen_offset2.split('_')]\n\t                    sentence_s = ['[CLS]'] + sentence_s + ['[SEP]']\n\t                    sentence_t = ['[CLS]'] + sentence_t + ['[SEP]']\n\t                    span1 = list(map(lambda x: x + 1, span1))\n", "                    span2 = list(map(lambda x: x + 1, span2))\n\t                    sentence_vec_s = []\n\t                    sentence_vec_t = []\n\t                    span1_vec = []\n\t                    span2_vec = []\n\t                    for i, w in enumerate(sentence_s):\n\t                        tokens = tokenizer.tokenize(w) if w not in (\"[CLS]\", \"[SEP]\") else [w]\n\t                        xx = tokenizer.convert_tokens_to_ids(tokens)\n\t                        if i in span1:\n\t                            span1_vec.extend(list(range(len(sentence_vec_s), len(sentence_vec_s) + len(xx))))\n", "                        sentence_vec_s.extend(xx)\n\t                    for i, w in enumerate(sentence_t):\n\t                        tokens = tokenizer.tokenize(w) if w not in (\"[CLS]\", \"[SEP]\") else [w]\n\t                        xx = tokenizer.convert_tokens_to_ids(tokens)\n\t                        if i in span2:\n\t                            span2_vec.extend(list(range(len(sentence_vec_t), len(sentence_vec_t) + len(xx))))\n\t                        sentence_vec_t.extend(xx)\n\t                    data_set.append([doc, sentence_vec_s, sentence_vec_t, span1_vec, span2_vec, rel])\n\t    # print(len(data_set))\n\t    # print(data_set[0])\n", "    # print(count)\n\t    with open(data_pickle, 'wb') as f:\n\t        pickle.dump(data_set, f, pickle.HIGHEST_PROTOCOL)\n\tif __name__ == '__main__':\n\t    # todo 可以把read_document改过来\n\t    processed_files = 'processed_files'\n\t    raw_pickle0 = f'{processed_files}/document_raw.pickle'\n\t    data_pickle0 = f'{processed_files}/data.pickle'\n\t    tokenizer0 = BertTokenizer.from_pretrained('bert-base-uncased')\n\t    make_data_pickle(raw_pickle=raw_pickle0, data_pickle=data_pickle0, tokenizer=tokenizer0)\n"]}
{"filename": "src/Event_factuality/model.py", "chunked_list": ["import torch.nn as nn\n\tfrom transformers import BertModel, BertConfig\n\timport torch\n\timport torch.nn.functional as F\n\tclass GCNLayer(nn.Module):\n\t    def __init__(self, in_dim, out_dim, acti=True):\n\t        super(GCNLayer, self).__init__()\n\t        self.linear = nn.Linear(in_dim, out_dim)\n\t        if acti:\n\t            self.acti = nn.ReLU(inplace=True)\n", "        else:\n\t            self.acti = None\n\t    def forward(self, F):\n\t        output = self.linear(F)\n\t        if not self.acti:\n\t            return output\n\t        return self.acti(output)\n\tclass UGCN(nn.Module):\n\t    def __init__(self, in_dim, hid_dim, out_dim, dropout):\n\t        super(UGCN, self).__init__()\n", "        self.gcn_layer1 = GCNLayer(in_dim, hid_dim)\n\t        self.gcn_layer2 = GCNLayer(hid_dim, out_dim)\n\t        self.gcn_layer1_var = GCNLayer(in_dim, hid_dim)\n\t        self.gcn_layer2_var = GCNLayer(hid_dim, out_dim)\n\t        self.dropout = nn.Dropout(dropout)\n\t        self.trans_mean = nn.Linear(in_dim, in_dim)\n\t        self.trans_var = nn.Linear(in_dim, in_dim)\n\t    def forward(self, adj, gcn_inputs):\n\t        # 传入图结构 adj 和输入特征 gcn_inputs\n\t        output_features = []\n", "        out_vars = []\n\t        output_features.append(gcn_inputs)\n\t        out_vars.append(gcn_inputs)\n\t        adj_list = []\n\t        adj_var_list = []\n\t        for i in range(adj.size()[0]):\n\t            adj_list.append(self.normalize(adj[i].view(adj.size()[1], adj.size()[2])))\n\t            adj_var_list.append(self.normalize1(adj[i].view(adj.size()[1], adj.size()[2])))\n\t        adj = torch.cat(adj_list, dim=0)\n\t        adj_var = torch.cat(adj_var_list, dim=0)\n", "        adj = adj.type_as(gcn_inputs)\n\t        adj_var = adj_var.type_as(gcn_inputs)\n\t        mean_vectors = F.relu(self.trans_mean(gcn_inputs))\n\t        var_vectors = F.relu(self.trans_var(gcn_inputs))\n\t        output_features.append(mean_vectors)\n\t        out_vars.append(var_vectors)\n\t        node_weight = torch.exp(-0.001 * var_vectors)\n\t        x_mean = mean_vectors.mul(node_weight)\n\t        x_var = var_vectors.mul(node_weight).mul(node_weight)\n\t        Ax_mean = adj.bmm(x_mean)\n", "        Ax_var = adj_var.bmm(x_var)\n\t        hid_output_mean = self.gcn_layer1(Ax_mean)\n\t        hid_output_var = self.gcn_layer1_var(Ax_var)\n\t        output_features.append(hid_output_mean)\n\t        out_vars.append(hid_output_var)\n\t        node_weight = torch.exp(-0.001 * hid_output_var)\n\t        x_mean = hid_output_mean.mul(node_weight)\n\t        x_var = hid_output_var.mul(node_weight).mul(node_weight)\n\t        Ax_mean = adj.bmm(x_mean)\n\t        Ax_var = adj_var.bmm(x_var)\n", "        output_mean = self.gcn_layer2(Ax_mean)\n\t        output_var = self.gcn_layer2_var(Ax_var)\n\t        sample_v = torch.randn(1, 1)[0][0]\n\t        output_mean = output_mean + (torch.sqrt(output_var + 1e-8) * sample_v)\n\t        output_features.append(output_mean)\n\t        out_vars.append(output_var)\n\t        return output_features, out_vars\n\t    def normalize(self, A, symmetric=True):\n\t        # A = A+I\n\t        A = A + torch.eye(A.size(0)).cuda()\n", "        # degree of nodes\n\t        d = A.sum(1)\n\t        D = torch.diag(torch.pow(d, -0.5))\n\t        return D.mm(A).mm(D).unsqueeze(0)\n\t    def normalize1(self, A, symmetric=True):\n\t        # A = A+I\n\t        A = A + torch.eye(A.size(0)).cuda()\n\t        # degree of nodes\n\t        d = A.sum(1)\n\t        D = torch.diag(torch.pow(d, -1))\n", "        return D.mm(A).mm(D).unsqueeze(0)\n\tclass GCN_Joint_EFP(nn.Module):\n\t    def __init__(self, config, y_num):\n\t        super(GCN_Joint_EFP, self).__init__()\n\t        self.config = config\n\t        self.y_num = y_num\n\t        if config.activation == 'tanh':\n\t            self.activation = nn.Tanh()\n\t        elif config.activation == 'relu':\n\t            self.activation = nn.ReLU()\n", "        else:\n\t            assert 1 == 2, \"you should provide activation function.\"\n\t        self.bert = BertModel.from_pretrained('bert-base-uncased')\n\t        # bert-base-uncased for english data, bert-base-chinese for chinese data\n\t        print('The number of parameters of bert: ',\n\t              sum(p.numel() for p in self.bert.parameters() if p.requires_grad))\n\t        self.gcn_in_dim = config.bert_hid_size\n\t        self.gcn_hid_dim = config.gcn_hid_dim\n\t        self.gcn_out_dim = config.gcn_out_dim\n\t        self.dropout = config.dropout\n", "        self.ugcn = UGCN(self.gcn_in_dim, self.gcn_hid_dim, self.gcn_out_dim, self.dropout)\n\t        self.bank_size = self.gcn_in_dim + self.gcn_hid_dim + self.gcn_out_dim\n\t        self.linear_dim = config.linear_dim\n\t        self.predict = nn.Linear(self.bank_size, self.y_num)\n\t        # self.trigger_predict = nn.Linear(self.bank_size, self.y_num)\n\t    def forward(self, **params):\n\t        triggers = params['triggers']\n\t        trigger_masks = params['trigger_masks']\n\t        bsz = triggers.size()[0]\n\t        doc_outputs = self.bert(triggers, attention_mask=trigger_masks)\n", "        document_cls = doc_outputs[1]\n\t        words = params['words']  # [bsz, seq_len]\n\t        masks = params['masks']  # [bsz, seq_len]\n\t        sent_outputs = self.bert(words, attention_mask=masks)  # sentence_cls: [bsz, bert_dim]\n\t        sentence_embed = sent_outputs[0]\n\t        sentence_cls = sent_outputs[1]\n\t        sent_idx = params['sent_idx']  # bsz * [trigger_num]\n\t        trigger_word_idx = params['trigger_word_idx']  # bsz * [trigger_num, seq_len]\n\t        graphs = params['graphs']\n\t        assert graphs.size()[0] == bsz, \"batch size inconsistent\"\n", "        split_sizes = params['sent_nums'].tolist()\n\t        # for i in range(bsz):\n\t        #     sentence_num = graphs[i].number_of_nodes('node') - 1 - sent_idx[i].shape[0]\n\t        #     split_sizes.append(sentence_num)\n\t        feature_list = list(torch.split(sentence_cls, split_sizes, dim=0))  # bsz * [num, bert_dim]\n\t        sentence_embed_list = list(torch.split(sentence_embed, split_sizes, dim=0))\n\t        sentence_trigger = []\n\t        trigger_nums = []\n\t        for i in range(bsz):\n\t            # extract sentences containing triggers\n", "            t = sentence_embed_list[i].index_select(0, sent_idx[i])  # [trigger_num, seq_len, bert_dim]\n\t            # extract trigger embeds\n\t            trigger_embed = torch.sum(trigger_word_idx[i].unsqueeze(-1) * t, dim=1)  # [trigger_num, bert_dim]\n\t            # assert trigger_embed.size()[0]==sent_idx[i].size()[-1]\n\t            trigger_nums.append(trigger_embed.size()[0])\n\t            fea = torch.cat((feature_list[i], trigger_embed), dim=0)\n\t            pad = torch.zeros(graphs.size()[1] - 1 - fea.size()[0], fea.size()[-1]).cuda()\n\t            fea = torch.cat((fea, pad), dim=0).unsqueeze(0)\n\t            assert fea.size()[1] == graphs.size()[1] - 1\n\t            sentence_trigger.append(fea)\n", "        sentence_trigger = torch.cat(sentence_trigger, dim=0)\n\t        features = torch.cat((document_cls.unsqueeze(1), sentence_trigger), dim=1)\n\t        assert features.size()[0] == bsz\n\t        assert features.size()[1] == graphs.size()[1]\n\t        output_features, output_means = self.ugcn(graphs, features)  # [bsz, num_node, dim]\n\t        output_feature_list = [output_features[0], output_features[2], output_features[3]]\n\t        output_feature = torch.cat(output_feature_list, dim=-1)\n\t        document_features = []\n\t        trigger_features = []\n\t        for i in range(bsz):\n", "            document_features.append(output_feature[i:i + 1, 0, :])\n\t            trigger_start = 1 + split_sizes[i]\n\t            trigger_end = trigger_start + trigger_nums[i]\n\t            trigger_features.append(\n\t                output_feature[i:i + 1, trigger_start:trigger_end, :].view(-1, output_feature.size()[-1]))\n\t        document_feature = torch.cat(document_features, dim=0).view(-1, output_feature.size()[-1])\n\t        trigger_feature = torch.cat(trigger_features, dim=0).view(-1, output_feature.size()[-1])\n\t        # classification\n\t        predictions = self.predict(document_feature)\n\t        # trigger_predictions = self.trigger_predict(trigger_feature)\n", "        trigger_predictions = trigger_feature\n\t        mean = output_features[1]  # (bsz, node_num, gcn_out_dim)\n\t        var = output_means[1]\n\t        KL_divergence = 0.5 * torch.mean(torch.square(mean) + var - torch.log(1e-8 + var) - 1, dim=-1)\n\t        KL_divergence = torch.mean(KL_divergence)\n\t        KL_loss = 5e-4 * KL_divergence\n\t        return predictions, trigger_predictions, KL_loss\n"]}
{"filename": "src/Event_factuality/main.py", "chunked_list": ["import torch\n\timport torch.utils.data as D\n\timport torch.nn.functional as F\n\tfrom dataset import Data\n\tfrom config import opt\n\tfrom model import GCN_Joint_EFP\n\tfrom transformers import AdamW\n\timport torch.nn as nn\n\timport os\n\timport numpy as np\n", "import xml.etree.ElementTree as ET\n\tfrom sklearn.model_selection import StratifiedKFold\n\tfrom sklearn.metrics import f1_score\n\tdef k_fold_split(data_path):\n\t    train_idx, test_idx = [], []\n\t    labels = []\n\t    label2idx = {}\n\t    tree = ET.parse(data_path)\n\t    root = tree.getroot()\n\t    for document_set in root:\n", "        for document in document_set:\n\t            id = document.attrib['id']\n\t            if id != 'ED1397':\n\t                label = document.attrib['document_level_value']\n\t                if label not in label2idx:\n\t                    label2idx[label] = len(label2idx)\n\t                labels.append(label2idx[label])\n\t    skf = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n\t    for train, test in skf.split(np.zeros(len(labels)), labels):\n\t        train_idx.append(train)\n", "        test_idx.append(test)\n\t    return train_idx, test_idx, label2idx\n\tdef collate(samples):\n\t    id, label, trigger, trigger_mask, data, attention, \\\n\t    sent_idx, trigger_word_idx, trigger_label, sent_num, graph = map(list, zip(*samples))\n\t    batched_ids = tuple(id)\n\t    batched_labels = torch.tensor(label)\n\t    batched_triggers = torch.cat(trigger, dim=0)\n\t    batched_trigger_mask = torch.cat(trigger_mask, dim=0)\n\t    batched_data = torch.cat(data, dim=0)\n", "    batched_attention = torch.cat(attention, dim=0)\n\t    batched_sent_idx = sent_idx\n\t    batched_trigger_word_idx = trigger_word_idx\n\t    batched_trigger_labels = torch.cat(trigger_label, dim=0)\n\t    batched_sent_num = torch.tensor(sent_num)\n\t    batched_graph = torch.cat(graph, dim=0)\n\t    return batched_ids, batched_labels, batched_triggers, batched_trigger_mask, \\\n\t           batched_data, batched_attention, \\\n\t           batched_sent_idx, batched_trigger_word_idx, batched_trigger_labels, batched_sent_num, \\\n\t           batched_graph\n", "def get_data(train_idx, test_idx, label2idx):\n\t    trainset = Data(opt.data_path, opt.saved_path, train_idx, label2idx, is_training=True)\n\t    train_loader = D.DataLoader(trainset, batch_size=opt.batch_size, shuffle=True, num_workers=10, collate_fn=collate)\n\t    testset = Data(opt.data_path, opt.saved_path, test_idx, label2idx, is_training=False)\n\t    test_loader = D.DataLoader(testset, batch_size=opt.batch_size, shuffle=False, num_workers=10, collate_fn=collate)\n\t    return train_loader, test_loader\n\tdef train(model, trainloader, optimizer, opt):\n\t    model.train()\n\t    # start_time = time.time()\n\t    loss_list = []\n", "    for batch_idx, (ids, labels, triggers, trigger_masks, words, masks, sent_idx, trigger_word_idx, trigger_labels,\n\t                    sent_nums, graphs) in enumerate(trainloader):\n\t        if opt.gpu:\n\t            triggers = triggers.cuda()\n\t            trigger_masks = trigger_masks.cuda()\n\t            words = words.cuda()\n\t            masks = masks.cuda()\n\t            # trigger_word_idx = trigger_word_idx.cuda()\n\t            graphs = graphs.cuda()\n\t            labels = labels.cuda()\n", "            sent_nums = sent_nums.cuda()\n\t            trigger_labels = trigger_labels.cuda()\n\t        sent_idx_list = []\n\t        trigger_word_idx_list = []\n\t        for i in range(len(sent_idx)):\n\t            sent_idx_list.append(sent_idx[i].cuda())\n\t            trigger_word_idx_list.append(trigger_word_idx[i].cuda())\n\t        optimizer.zero_grad()\n\t        logit, trigger_logit, kl_loss = model(ids=ids, triggers=triggers, trigger_masks=trigger_masks, words=words,\n\t                                              masks=masks,\n", "                                              sent_idx=sent_idx_list, trigger_word_idx=trigger_word_idx_list,\n\t                                              sent_nums=sent_nums, graphs=graphs)\n\t        main_loss = nn.functional.cross_entropy(logit, labels)\n\t        aux_loss = nn.functional.cross_entropy(trigger_logit, trigger_labels)\n\t        loss = main_loss + kl_loss\n\t        loss.backward()\n\t        optimizer.step()\n\t        loss_list.append(loss.item())\n\t    # print(\"time:%.3f\" % (time.time() - start_time))\n\t    return np.mean(loss_list)\n", "def evaluate(model, test_loader, filepath=None):\n\t    if filepath is not None:\n\t        f = open(filepath, 'w')\n\t    model.eval()\n\t    total = 0\n\t    correct = 0\n\t    y_true = []\n\t    y_pred = []\n\t    with torch.no_grad():\n\t        for batch_idx, (ids, labels, triggers, trigger_masks, words, masks, sent_idx, trigger_word_idx, trigger_labels,\n", "                        sent_nums, graphs) in enumerate(test_loader):\n\t            if opt.gpu:\n\t                triggers = triggers.cuda()\n\t                trigger_masks = trigger_masks.cuda()\n\t                words = words.cuda()\n\t                masks = masks.cuda()\n\t                # sent_idx = sent_idx.cuda()\n\t                # trigger_word_idx = trigger_word_idx.cuda()\n\t                graphs = graphs.cuda()\n\t                labels = labels.cuda()\n", "                sent_nums = sent_nums.cuda()\n\t                trigger_labels = trigger_labels.cuda()\n\t            sent_idx_list = []\n\t            trigger_word_idx_list = []\n\t            for i in range(len(sent_idx)):\n\t                sent_idx_list.append(sent_idx[i].cuda())\n\t                trigger_word_idx_list.append(trigger_word_idx[i].cuda())\n\t            logit, _, _ = model(ids=ids, triggers=triggers, trigger_masks=trigger_masks, words=words, masks=masks,\n\t                                sent_idx=sent_idx_list, trigger_word_idx=trigger_word_idx_list, sent_nums=sent_nums,\n\t                                graphs=graphs)\n", "            _, predicted = torch.max(logit.data, 1)\n\t            correct += predicted.data.eq(labels.data).cpu().sum()\n\t            y_true += labels.cpu().data.numpy().tolist()\n\t            y_pred += predicted.cpu().data.numpy().tolist()\n\t            if filepath is not None:\n\t                batch = labels.shape[0]\n\t                for i in range(batch):\n\t                    f.write(ids[i] + \"\\t\" + str(labels[i].item()) + \"\\t\" + str(predicted[i].item()) + \"\\n\")\n\t    f1_micro = f1_score(y_true, y_pred, labels=[0, 1, 2], average='micro')\n\t    f1_macro = f1_score(y_true, y_pred, labels=[0, 1, 2], average='macro')\n", "    if filepath is not None:\n\t        f.write(\"f1_micro: \" + str(f1_micro) + \"\\n\")\n\t        f.write(\"f1_macro: \" + str(f1_macro) + \"\\n\")\n\t        f.close()\n\t    return f1_micro, f1_macro\n\tif __name__ == '__main__':\n\t    train_idx, test_idx, label2idx = k_fold_split(opt.data_path)\n\t    f1_micro_list = []\n\t    f1_macro_list = []\n\t    if not os.path.exists('checkpoint'):\n", "        os.mkdir('checkpoint')\n\t    if not os.path.exists('result'):\n\t        os.mkdir('result')\n\t    for i in range(10):\n\t        model_path = opt.model_path + \"_\" + str(i) + \".pt\"\n\t        output_path = opt.output_path + \"_\" + str(i) + \".txt\"\n\t        train_loader, test_loader = get_data(train_idx[i], test_idx[i], label2idx)\n\t        model = GCN_Joint_EFP(opt, len(label2idx))\n\t        if opt.gpu:\n\t            model = model.cuda()\n", "        optimizer = AdamW(model.parameters(), lr=opt.lr, no_deprecation_warning=True)\n\t        max_f1 = 0\n\t        max_f1_micro = 0\n\t        max_f1_macro = 0\n\t        for epoch in range(opt.n_epochs):\n\t            train_loss = train(model, train_loader, optimizer, opt)\n\t            test_f1_micro, test_f1_macro = evaluate(model, test_loader)\n\t            print(\"Epoch:%d-%d loss:%f F1_micro:%.2f F1_macro:%.2f\" % (\n\t                i, epoch, train_loss, test_f1_micro * 100, test_f1_macro * 100))\n\t            if test_f1_micro + test_f1_macro > max_f1:\n", "                max_f1 = test_f1_micro + test_f1_macro\n\t                torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),\n\t                            'optimizer_state_dict': optimizer.state_dict()}, model_path)\n\t        checkpoint = torch.load(model_path)\n\t        model.load_state_dict(checkpoint['model_state_dict'])\n\t        test_f1_micro, test_f1_macro = evaluate(model, test_loader, filepath=output_path)\n\t        print(\"Epoch:%d-%d F1_micro:%.2f F1_macro:%.2f\" % (\n\t            i, checkpoint['epoch'], test_f1_micro * 100, test_f1_macro * 100))\n\t        f1_micro_list.append(test_f1_micro)\n\t        f1_macro_list.append(test_f1_macro)\n", "    output = open(opt.output_path + \".txt\", \"w\")\n\t    # 最终保存在这儿\n\t    f1_micro_a = np.mean(f1_micro_list)\n\t    f1_macro_a = np.mean(f1_macro_list)\n\t    output.write(\"batch_size=\" + str(opt.batch_size) + \"\\n\")\n\t    output.write(\"lr=\" + str(opt.lr) + \"\\n\")\n\t    output.write(\"f1_micro_a: \" + str(f1_micro_a) + \"\\n\")\n\t    output.write(\"f1_macro_a: \" + str(f1_macro_a) + \"\\n\")\n\t    print(\"F1_micro_a: %.2f F1_macro_a: %.2f\" % (f1_micro_a * 100, f1_macro_a * 100))\n\t    ct_p = []\n", "    ct_m = []\n\t    ps_p = []\n\t    for i in range(10):\n\t        filename = opt.output_path + \"_\" + str(i) + \".txt\"\n\t        y_true = []\n\t        y_pred = []\n\t        with open(filename, \"r\") as f:\n\t            for l in f.readlines():\n\t                line = l.split()\n\t                if len(line) < 3:\n", "                    break\n\t                y_true.append(line[1])\n\t                y_pred.append(line[2])\n\t        with open(filename, \"a\") as f:\n\t            # 'a'是打开文件的模式之一，表示以追加模式打开文件(append)\n\t            t_ct_p = f1_score(y_true, y_pred, labels=[0], average=\"macro\")\n\t            f.write(\"CT+: \" + str(t_ct_p) + \"\\n\")\n\t            ct_p.append(t_ct_p)\n\t            t_ct_m = f1_score(y_true, y_pred, labels=[1], average=\"macro\")\n\t            f.write(\"CT-: \" + str(t_ct_m) + \"\\n\")\n", "            ct_m.append(t_ct_m)\n\t            t_ps_p = f1_score(y_true, y_pred, labels=[2], average=\"macro\")\n\t            f.write(\"PS+: \" + str(t_ps_p) + \"\\n\")\n\t            ps_p.append(t_ps_p)\n\t    output.write(\"CT+: \" + str(np.mean(ct_p)) + \"\\n\")\n\t    output.write(\"CT-: \" + str(np.mean(ct_m)) + \"\\n\")\n\t    output.write(\"PS+: \" + str(np.mean(ps_p)) + \"\\n\")\n\t    output.close()\n"]}
{"filename": "src/Event_factuality/config.py", "chunked_list": ["import argparse\n\tdef parse_args():\n\t    parser = argparse.ArgumentParser(\n\t        description='train a neural network for document-level event factuality prediction')\n\t    parser.add_argument('--data_path', type=str, default='data/english.xml', help='path to the data file')\n\t    parser.add_argument('--saved_path', type=str, default='data/english_uncertain_plain_gcn_joint_doc.pkl',\n\t                        help='path to the saved_data file')\n\t    parser.add_argument('--n_epochs', type=int, default=30, help='number of epochs to train')\n\t    parser.add_argument('--lr', type=float, default=2e-5, help='learning rate')\n\t    parser.add_argument('--batch_size', type=int, default=2, help='size of the training batches')\n", "    parser.add_argument('--labmda', type=float, default=0.2)\n\t    parser.add_argument('--gpu', dest=\"gpu\", action=\"store_const\", const=True, default=True, required=False,\n\t                        help='optional flag to use GPU if available')\n\t    # 在使用 argparse 库时，dest 参数指定了将参数值存储到解析结果对象的哪个属性中。默认情况下，dest 参数的值与参数名相同，\n\t    # 但可以使用该参数来自定义名称。\n\t    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n\t                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n\t    parser.add_argument('--warmup_proportion', default=0.1, type=float,\n\t                        help=\"Proportion of training to perform linear learning rate warmup for. \")\n\t    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n", "    parser.add_argument('--bert_hid_size', type=int, default=768)\n\t    parser.add_argument('--gcn_layers', type=int, default=2, help=\"the number of gcn layers\")\n\t    parser.add_argument('--gcn_hid_dim', type=int, default=768, help='the hidden size of gcn')\n\t    parser.add_argument('--gcn_out_dim', type=int, default=768, help='the output size of gcn')\n\t    parser.add_argument('--activation', type=str, default=\"relu\")\n\t    parser.add_argument('--dropout', type=float, default=0)\n\t    parser.add_argument('--linear_dim', type=int, default=300)\n\t    # parser.add_argument('--model_path', type=str, default=\"./checkpoint/chinese_model\")\n\t    # parser.add_argument('--output_path', type=str, default=\"./result/chinese_output\")\n\t    # parser.add_argument('--output_path1', type=str, default=\"./result/chinese_output_n1\")\n", "    # parser.add_argument('--output_path2', type=str, default=\"./result/chinese_output_n2\")\n\t    parser.add_argument('--model_path', type=str, default=\"./checkpoint/english_model\")\n\t    parser.add_argument('--output_path', type=str, default=\"./result/english_output\")\n\t    parser.add_argument('--output_path1', type=str, default=\"./result/english_output_n1\")\n\t    parser.add_argument('--output_path2', type=str, default=\"./result/english_output_n2\")\n\t    args = parser.parse_args()\n\t    for arg in vars(args):\n\t        print('{}={}'.format(arg.upper(), getattr(args, arg)))\n\t    print('')\n\t    return args\n", "opt = parse_args()\n"]}
{"filename": "src/Event_factuality/dataset.py", "chunked_list": ["import torch\n\tfrom transformers import BertTokenizer\n\timport xml.etree.ElementTree as ET\n\timport numpy as np\n\timport os\n\timport pickle\n\timport re\n\tfrom torch.utils.data import Dataset\n\tclass Data(Dataset):\n\t    def __init__(self, data_path, saved_data_path, data_idx, label2idx, is_training=True):\n", "        self.is_training = is_training\n\t        self.document_data = None\n\t        self.data = []\n\t        self.document_max_length = 512\n\t        self.sentence_max_length = 150\n\t        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\t        self.debug_data = True\n\t        print('Reading data from {}.'.format(data_path))\n\t        if os.path.exists(saved_data_path) and not self.debug_data:\n\t            with open(file=saved_data_path, mode='rb') as fr:\n", "                info = pickle.load(fr)\n\t                self.document_data = info['data']\n\t            print('load preprocessed data from {}.'.format(saved_data_path))\n\t        else:\n\t            self.document_data = []\n\t            count = 0\n\t            tree = ET.parse(data_path)\n\t            root = tree.getroot()\n\t            for doc in root[0]:\n\t                id = doc.attrib['id']\n", "                label = label2idx[doc.attrib['document_level_value']]\n\t                sentence_list = []\n\t                trigger_word_list = []\n\t                flag = False\n\t                for sent in doc:\n\t                    if sent.text == '-EOP-.' or sent.text == '。':\n\t                        continue\n\t                    s = ''\n\t                    for t in sent.itertext():\n\t                        s += t\n", "                    s = s.replace('-EOP-.', '。').lower()\n\t                    if re.match(r'\\d{4}\\D\\d{2}\\D\\d{2}\\D\\d{2}:\\d{2}\\D$', s) is not None:\n\t                        flag = True\n\t                        continue\n\t                    elif flag:\n\t                        flag = False\n\t                        if len(sent) == 0:\n\t                            continue\n\t                    if len(s) <= 4:\n\t                        continue\n", "                    data = self.tokenizer(s, return_tensors='pt', padding='max_length', truncation=True, max_length=150)\n\t                    sent_info = {'trigger_num': 0,\n\t                                 'data': data['input_ids'],\n\t                                 'attention': data['attention_mask']}\n\t                    # x = len(sent)\n\t                    # if len(sent) == 0:\n\t                    #     raise AttributeError\n\t                    if len(sent) > 0:\n\t                        # has triggers 为什么？\n\t                        # done 类似于 '2017_07_26 06:37 -eop- .' ,len(sent)==0\n", "                        tmp = sent.text.lower() if sent.text is not None else ''\n\t                        for event in sent:\n\t                            tmp_subwords = self.tokenizer.tokenize(tmp)\n\t                            trigger_subwords = self.tokenizer.tokenize(event.text.lower())\n\t                            pos0 = len(tmp_subwords) + 1\n\t                            pos1 = pos0 + len(trigger_subwords)\n\t                            if pos0 >= self.sentence_max_length - 1:\n\t                                break\n\t                            if pos1 >= self.sentence_max_length - 1:\n\t                                pos1 = self.sentence_max_length - 1\n", "                            else:\n\t                                assert self.tokenizer.convert_ids_to_tokens(\n\t                                    data['input_ids'][0, pos0:pos1]) == trigger_subwords\n\t                            trigger_word_idx = torch.zeros(self.sentence_max_length)\n\t                            trigger_word_idx[pos0:pos1] = 1.0 / (pos1 - pos0)\n\t                            trigger_word_list.append({'sent_id': len(sentence_list),\n\t                                                      'idx': trigger_word_idx,\n\t                                                      'value': label2idx[event.attrib['sentence_level_value']]})\n\t                            tmp += event.text.lower()\n\t                            if event.tail is not None:\n", "                                tmp += event.tail.lower()\n\t                            sent_info['trigger_num'] += 1\n\t                    sentence_list.append(sent_info)\n\t                    if len(sentence_list) >= 35:\n\t                        break\n\t                trigger = ''\n\t                for sent in doc:\n\t                    if len(sent) > 0:\n\t                        s = ''\n\t                        for t in sent.itertext():\n", "                            s += t\n\t                        s = s.replace('-EOP-.', '。').lower()\n\t                        trigger += s\n\t                trigger_data = self.tokenizer(trigger, return_tensors='pt',\n\t                                              padding='max_length', truncation=True, max_length=260)\n\t                # construct graph\n\t                # 1 document node, 35 sentence nodes, 20 trigger nodes for english data,\n\t                # 1 document node, 35 sentence nodes, 45 trigger nodes for chinese data\n\t                graph = self.create_graph(sentence_list, trigger_word_list)\n\t                assert len(graph) == 81\n", "                # 为什么是81\n\t                if len(trigger_word_list) > 0:\n\t                    x = {\n\t                        'ids': id,\n\t                        'labels': label,\n\t                        'triggers': trigger_data['input_ids'],\n\t                        'trigger_masks': trigger_data['attention_mask'],\n\t                        'sentences': sentence_list,\n\t                        'trigger_words': trigger_word_list,\n\t                        'graphs': graph\n", "                    }\n\t                    self.document_data.append({\n\t                        'ids': id,\n\t                        'labels': label,\n\t                        'triggers': trigger_data['input_ids'],\n\t                        'trigger_masks': trigger_data['attention_mask'],\n\t                        'sentences': sentence_list,\n\t                        'trigger_words': trigger_word_list,\n\t                        'graphs': graph\n\t                    })\n", "                else:\n\t                    print(id)\n\t                    count += 1\n\t            print('count: ', count)\n\t            # save data\n\t            with open(file=saved_data_path, mode='wb') as fw:\n\t                pickle.dump({'data': self.document_data}, fw)\n\t            print('finish reading {} and save preprocessed data to {}.'.format(data_path, saved_data_path))\n\t        for i in data_idx:\n\t            self.data.append(self.document_data[i])\n", "    def __len__(self):\n\t        return len(self.data)\n\t    def __getitem__(self, idx):\n\t        sentence_list = self.data[idx]['sentences']\n\t        data_list = []\n\t        attention_list = []\n\t        for s in sentence_list:\n\t            data_list.append(s['data'])\n\t            attention_list.append(s['attention'])\n\t        data = torch.cat(data_list, dim=0)\n", "        attention = torch.cat(attention_list, dim=0)\n\t        sentence_num = len(data)\n\t        trigger_word_list = self.data[idx]['trigger_words']\n\t        sent_idx_list = []\n\t        trigger_word_idx_list = []\n\t        trigger_label_list = []\n\t        for t in trigger_word_list:\n\t            sent_idx_list.append(t['sent_id'])\n\t            trigger_word_idx_list.append(t['idx'])\n\t            trigger_label_list.append(t['value'])\n", "        sent_idx = torch.tensor(sent_idx_list)\n\t        trigger_word_idx = torch.stack(trigger_word_idx_list, dim=0)\n\t        trigger_label = torch.tensor(trigger_label_list)\n\t        graph = torch.tensor(self.data[idx]['graphs']).unsqueeze(0)\n\t        return self.data[idx]['ids'], \\\n\t               torch.tensor(self.data[idx]['labels'], dtype=torch.long), \\\n\t               self.data[idx]['triggers'], \\\n\t               self.data[idx]['trigger_masks'], \\\n\t               data, \\\n\t               attention, \\\n", "               sent_idx, \\\n\t               trigger_word_idx, \\\n\t               trigger_label, \\\n\t               sentence_num, graph\n\t    def create_graph(self, sentence_list, trigger_word_list):\n\t        graph = np.zeros((81, 81))\n\t        sent_num = len(sentence_list)\n\t        trigger_num = len(trigger_word_list)\n\t        # add neighbor edges\n\t        for i in range(1, sent_num):\n", "            graph[i][i + 1] = 1.0\n\t            graph[i + 1][i] = 1.0\n\t        # add global edges\n\t        for i in range(1, sent_num + 1):\n\t            graph[0][i] = 1.0\n\t            graph[i][0] = 1.0\n\t        for i in range(trigger_num):\n\t            j = i + sent_num + 1\n\t            graph[0][j] = 1.0\n\t            graph[j][0] = 1.0\n", "            graph[j][trigger_word_list[i]['sent_id'] + 1] = 1.0\n\t            graph[trigger_word_list[i]['sent_id'] + 1][j] = 1.0\n\t        return graph\n"]}
{"filename": "src/Event/model.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom transformers import BertModel, BertConfig\n\tfrom consts import NONE\n\tfrom data_load import idx2trigger, argument2idx\n\tfrom utils import find_triggers\n\tclass Net(nn.Module):\n\t    def __init__(self, trigger_size=None, argument_size=None, device=torch.device(\"cpu\"), hparams=None):\n\t        super().__init__()\n\t        self.bert_model = BertModel.from_pretrained(hparams.model_name).to(device)\n", "        self.bert_tokenizer = BertConfig.from_pretrained(hparams.model_name)\n\t        hidden_size = self.bert_tokenizer.hidden_size\n\t        self.fc1 = nn.Sequential(\n\t            # nn.Dropout(0.5),\n\t            nn.Linear(hidden_size, hidden_size, bias=True),\n\t            nn.ReLU(),\n\t        ).to(device)\n\t        self.fc_trigger = nn.Sequential(\n\t            nn.Linear(hidden_size, trigger_size),\n\t        ).to(device)\n", "        self.fc_argument = nn.Sequential(\n\t            nn.Linear(hidden_size * 2, argument_size),\n\t        ).to(device)\n\t        self.device = device\n\t    def predict_triggers(self, tokens_x_2d, head_indexes_2d, triggers_y_2d, arguments_2d):\n\t        tokens_x_2d = torch.LongTensor(tokens_x_2d).to(self.device)\n\t        triggers_y_2d = torch.LongTensor(triggers_y_2d).to(self.device)\n\t        head_indexes_2d = torch.LongTensor(head_indexes_2d).to(self.device)\n\t        if self.training:\n\t            self.bert_model.train()\n", "            output = self.bert_model(tokens_x_2d)\n\t            encoded_layers = output['last_hidden_state']\n\t        else:\n\t            self.bert_model.eval()\n\t            with torch.no_grad():\n\t                output = self.bert_model(tokens_x_2d)\n\t                encoded_layers = output['last_hidden_state']\n\t        batch_size = tokens_x_2d.shape[0]\n\t        for i in range(batch_size):\n\t            encoded_layers[i] = torch.index_select(encoded_layers[i], 0, head_indexes_2d[i])\n", "        trigger_logits = self.fc_trigger(encoded_layers)\n\t        trigger_hat_2d = trigger_logits.argmax(-1)\n\t        argument_hidden, argument_keys = [], []\n\t        for i in range(batch_size):\n\t            candidates = arguments_2d[i]['candidates']\n\t            golden_entity_tensors = {}\n\t            for j in range(len(candidates)):\n\t                e_start, e_end = candidates[j]\n\t                golden_entity_tensors[candidates[j]] = encoded_layers[i, e_start:e_end, ].mean(dim=0)\n\t            predicted_triggers = find_triggers([idx2trigger[trigger] for trigger in trigger_hat_2d[i].tolist()])\n", "            for predicted_trigger in predicted_triggers:\n\t                t_start, t_end, t_type_str = predicted_trigger\n\t                event_tensor = encoded_layers[i, t_start:t_end, ].mean(dim=0)\n\t                for j in range(len(candidates)):\n\t                    e_start, e_end = candidates[j]\n\t                    entity_tensor = golden_entity_tensors[candidates[j]]\n\t                    argument_hidden.append(torch.cat([event_tensor, entity_tensor]))\n\t                    argument_keys.append((i, t_start, t_end, t_type_str, e_start, e_end))\n\t        return trigger_logits, triggers_y_2d, trigger_hat_2d, argument_hidden, argument_keys\n\t    def predict_arguments(self,\n", "                          argument_hidden,\n\t                          argument_keys,\n\t                          arguments_2d):\n\t        argument_hidden = torch.stack(argument_hidden)\n\t        argument_logits = self.fc_argument(argument_hidden)\n\t        argument_hat_1d = argument_logits.argmax(-1)\n\t        arguments_y_1d = []\n\t        for i, t_start, t_end, t_type_str, \\\n\t            e_start, e_end in argument_keys:\n\t            arg_label = argument2idx[NONE]\n", "            if (t_start, t_end, t_type_str) in arguments_2d[i]['events']:\n\t                for (a_start, a_end, a_type_idx) in arguments_2d[i]['events'][(t_start, t_end, t_type_str)]:\n\t                    if e_start == a_start and e_end == a_end:\n\t                        # raise Exception\n\t                        arg_label = a_type_idx\n\t                        break\n\t            arguments_y_1d.append(arg_label)\n\t        arguments_y_1d = torch.LongTensor(arguments_y_1d).to(self.device)\n\t        batch_size = len(arguments_2d)\n\t        argument_hat_2d = [{'events': {}} for _ in range(batch_size)]\n", "        for (i, st, ed, event_type_str, e_st, e_ed), a_label in zip(argument_keys, argument_hat_1d.cpu().numpy()):\n\t            if a_label == argument2idx[NONE]:\n\t                continue\n\t            if (st, ed, event_type_str) not in argument_hat_2d[i]['events']:\n\t                argument_hat_2d[i]['events'][(st, ed, event_type_str)] = []\n\t            argument_hat_2d[i]['events'][(st, ed, event_type_str)].append((e_st, e_ed, a_label))\n\t        return argument_logits, arguments_y_1d, argument_hat_1d, argument_hat_2d\n"]}
{"filename": "src/Event/params.py", "chunked_list": ["import argparse\n\t# from transformers import set_seed\n\tdef get_hparams():\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\"--batch_size\", type=int, default=1)\n\t    parser.add_argument(\"--eval_batch_size\", type=int, default=24)\n\t    parser.add_argument(\"--lr\", type=float, default=0.00002)\n\t    parser.add_argument(\"--n_epochs\", type=int, default=1)\n\t    parser.add_argument(\"--logdir\", type=str, default=\"logdir\")\n\t    # fixme_done path problem\n", "    parser.add_argument(\"--data_class\", type=str, choices=['ace', 'wiki_src', 'wiki_info'], default='wiki_src')\n\t    parser.add_argument(\"--model_name\", type=str, default=\"bert-large-cased\")\n\t    parser.add_argument(\"--seed\", type=int, default=42)\n\t    parser.add_argument(\"--model_save_path\", type=str, default='model_saved')\n\t    hparams = parser.parse_args()\n\t    # set_seed(hparams.seed)\n\t    return hparams\n"]}
{"filename": "src/Event/train_eval.py", "chunked_list": ["import torch.nn as nn\n\timport os\n\timport torch\n\tfrom data_load import idx2trigger\n\tfrom utils import calc_metric, find_triggers\n\timport logging\n\tlogging.basicConfig(level=logging.INFO, filename='output.txt', filemode='w')\n\tdef train(model, iterator, optimizer, criterion):\n\t    if hasattr(model, 'module'):\n\t        model = model.module\n", "    model.train()\n\t    for i, batch in enumerate(iterator):\n\t        tokens_x_2d, triggers_y_2d, arguments_2d, seqlens_1d, head_indexes_2d, words_2d, triggers_2d = batch\n\t        optimizer.zero_grad()\n\t        trigger_logits, \\\n\t        triggers_y_2d, \\\n\t        trigger_hat_2d,\\\n\t        argument_hidden, \\\n\t        argument_keys = \\\n\t            model.predict_triggers(tokens_x_2d=tokens_x_2d, head_indexes_2d=head_indexes_2d,\n", "                                   triggers_y_2d=triggers_y_2d, arguments_2d=arguments_2d)\n\t        trigger_logits = trigger_logits.view(-1, trigger_logits.shape[-1])\n\t        trigger_loss = criterion(trigger_logits, triggers_y_2d.view(-1))\n\t        if len(argument_keys) > 0:\n\t            argument_logits,\\\n\t            arguments_y_1d,\\\n\t            argument_hat_1d,\\\n\t            argument_hat_2d \\\n\t                = model.predict_arguments(argument_hidden, argument_keys, arguments_2d)\n\t            argument_loss = criterion(argument_logits, arguments_y_1d)\n", "            loss = trigger_loss + 2 * argument_loss\n\t        else:\n\t            loss = trigger_loss\n\t        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\t        loss.backward()\n\t        optimizer.step()\n\t        #\n\t        # if i % 10 == 0:  # monitoring\n\t        #     print(\"step: {}, loss: {}\".format(i, loss.item()))\n\tdef evaluate(model, iterator, f_name, f1_max=0):\n", "    if hasattr(model, 'module'):\n\t        model = model.module\n\t    model.eval()\n\t    words_all = []\n\t    triggers_all = []\n\t    triggers_hat_all = []\n\t    arguments_all = []\n\t    arguments_hat_all = []\n\t    with torch.no_grad():\n\t        for i, batch in enumerate(iterator):\n", "            tokens_x_2d, triggers_y_2d, arguments_2d, seqlens_1d, head_indexes_2d, words_2d, triggers_2d = batch\n\t            trigger_logits, triggers_y_2d, trigger_hat_2d, argument_hidden, argument_keys \\\n\t                = model.predict_triggers(tokens_x_2d=tokens_x_2d, head_indexes_2d=head_indexes_2d,\n\t                                         triggers_y_2d=triggers_y_2d, arguments_2d=arguments_2d)\n\t            words_all.extend(words_2d)\n\t            triggers_all.extend(triggers_2d)\n\t            triggers_hat_all.extend(trigger_hat_2d.cpu().numpy().tolist())\n\t            arguments_all.extend(arguments_2d)\n\t            if len(argument_keys) > 0:\n\t                argument_logits, arguments_y_1d, argument_hat_1d, argument_hat_2d = \\\n", "                    model.predict_arguments(argument_hidden, argument_keys, arguments_2d)\n\t                arguments_hat_all.extend(argument_hat_2d)\n\t            else:\n\t                batch_size = len(arguments_2d)\n\t                argument_hat_2d = [{'events': {}} for _ in range(batch_size)]\n\t                arguments_hat_all.extend(argument_hat_2d)\n\t    triggers_true = []\n\t    triggers_pred = []\n\t    arguments_true = []\n\t    arguments_pred = []\n", "    with open('temp', 'w') as f_out:\n\t        for i, (words, triggers, triggers_hat, arguments, arguments_hat) \\\n\t                in enumerate(zip(words_all, triggers_all, triggers_hat_all, arguments_all, arguments_hat_all)):\n\t            triggers_hat = triggers_hat[:len(words)]\n\t            triggers_hat = [idx2trigger[hat] for hat in triggers_hat]\n\t            # [(ith sentence, t_start, t_end, t_type_str)]\n\t            triggers_true.extend([(i, *item) for item in find_triggers(triggers)])\n\t            triggers_pred.extend([(i, *item) for item in find_triggers(triggers_hat)])\n\t            # [(ith sentence, t_start, t_end, t_type_str, a_start, a_end, a_type_idx)]\n\t            for trigger in arguments['events']:\n", "                t_start, t_end, t_type_str = trigger\n\t                for argument in arguments['events'][trigger]:\n\t                    a_start, a_end, a_type_idx = argument\n\t                    arguments_true.append((i, t_start, t_end, t_type_str, a_start, a_end, a_type_idx))\n\t            for trigger in arguments_hat['events']:\n\t                t_start, t_end, t_type_str = trigger\n\t                for argument in arguments_hat['events'][trigger]:\n\t                    a_start, a_end, a_type_idx = argument\n\t                    arguments_pred.append((i, t_start, t_end, t_type_str, a_start, a_end, a_type_idx))\n\t            for w, t, t_h in zip(words[1:-1], triggers, triggers_hat):\n", "                f_out.write('{}\\t{}\\t{}\\n'.format(w, t, t_h))\n\t            f_out.write('#arguments#{}\\n'.format(arguments['events']))\n\t            f_out.write('#arguments_hat#{}\\n'.format(arguments_hat['events']))\n\t            f_out.write(\"\\n\")\n\t    # print(classification_report([idx2trigger[idx] for idx in y_true], [idx2trigger[idx] for idx in y_pred]))\n\t    trigger_p, trigger_r, trigger_f1 = calc_metric(triggers_true, triggers_pred)\n\t    argument_p, argument_r, argument_f1 = calc_metric(arguments_true, arguments_pred)\n\t    triggers_true = [(item[0], item[1], item[2]) for item in triggers_true]\n\t    triggers_pred = [(item[0], item[1], item[2]) for item in triggers_pred]\n\t    arguments_true = [(item[0], item[1], item[2], item[3], item[4], item[5]) for item in arguments_true]\n", "    arguments_pred = [(item[0], item[1], item[2], item[3], item[4], item[5]) for item in arguments_pred]\n\t    argument_p_, argument_r_, argument_f1_ = calc_metric(arguments_true, arguments_pred)\n\t    trigger_p_, trigger_r_, trigger_f1_ = calc_metric(triggers_true, triggers_pred)\n\t    f1 = argument_f1 + argument_f1_ + trigger_f1 + trigger_f1_\n\t    if f1 > f1_max:\n\t        print('[trigger classification]')\n\t        print('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(trigger_p, trigger_r, trigger_f1))\n\t        print('[argument classification]')\n\t        print('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(argument_p, argument_r, argument_f1))\n\t        print('[trigger identification]')\n", "        print('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(trigger_p_, trigger_r_, trigger_f1_))\n\t        print('[argument identification]')\n\t        print('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(argument_p_, argument_r_, argument_f1_))\n\t        logging.info('[trigger classification]')\n\t        logging.info('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(trigger_p, trigger_r, trigger_f1))\n\t        logging.info('[argument classification]')\n\t        logging.info('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(argument_p, argument_r, argument_f1))\n\t        logging.info('[trigger identification]')\n\t        logging.info('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(trigger_p_, trigger_r_, trigger_f1_))\n\t        logging.info('[argument identification]')\n", "        logging.info('P={:.3f}\\tR={:.3f}\\tF1={:.3f}'.format(argument_p_, argument_r_, argument_f1_))\n\t        metric = '[trigger classification]\\tP={:.3f}\\tR={:.3f}\\tF1={:.3f}\\n'.format(trigger_p, trigger_r,\n\t                                                                                    trigger_f1)\n\t        metric += '[argument classification]\\tP={:.3f}\\tR={:.3f}\\tF1={:.3f}\\n'.format(argument_p, argument_r,\n\t                                                                                      argument_f1)\n\t        metric += '[trigger identification]\\tP={:.3f}\\tR={:.3f}\\tF1={:.3f}\\n'.format(trigger_p_, trigger_r_,\n\t                                                                                     trigger_f1_)\n\t        metric += '[argument identification]\\tP={:.3f}\\tR={:.3f}\\tF1={:.3f}\\n'.format(argument_p_, argument_r_,\n\t                                                                                      argument_f1_)\n\t        final = f_name + \".P%.2f_R%.2f_F%.2f\" % (trigger_p, trigger_r, trigger_f1)\n", "        with open(final, 'w') as f_out:\n\t            result = open(\"temp\", \"r\").read()\n\t            f_out.write(\"{}\\n\".format(result))\n\t            f_out.write(metric)\n\t        os.remove(\"temp\")\n\t    return f1\n"]}
{"filename": "src/Event/consts.py", "chunked_list": ["import json\n\timport os\n\tfrom os.path import exists\n\tfrom utils import get_event_type, write_json, process, get_argument_role, get_entity_type, \\\n\t    get_event_type_ace, get_argument_role_ace, get_entity_type_ace\n\tfrom params import get_hparams\n\tmax_length = 400\n\tNONE = 'O'\n\tPAD = \"[PAD]\"\n\tUNK = \"[UNK]\"\n", "# for BERT\n\tCLS = '[CLS]'\n\tSEP = '[SEP]'\n\thp = get_hparams()\n\tdata_dir = None\n\tif hp.data_class == 'wiki_src':\n\t    data_dir = 'Datasets/wiki_processed_data/source/'\n\telif hp.data_class == 'wiki_info':\n\t    data_dir = 'Datasets/wiki_processed_data/info/'\n\telif hp.data_class == 'ace':\n", "    data_dir = 'Datasets/ace2005/'\n\ttrain_set = data_dir + 'train.json'\n\ttest_set = data_dir + 'test.json'\n\tdev_set = data_dir + 'dev.json'\n\t# trigger\n\tif not os.path.exists('{}/event_type_list.json'.format(data_dir)):\n\t    triggers0 = set()\n\t    if hp.data_class == 'ace':\n\t        triggers1 = get_event_type_ace(train_set, triggers0)\n\t        triggers2 = get_event_type_ace(dev_set, triggers1)\n", "        triggers3 = get_event_type_ace(test_set, triggers2)\n\t        TRIGGERS = list(triggers3)\n\t    else:\n\t        triggers1 = get_event_type(train_set, triggers0)\n\t        triggers2 = get_event_type(dev_set, triggers1)\n\t        triggers3 = get_event_type(test_set, triggers2)\n\t        TRIGGERS = list(triggers3)\n\t    write_json(data=TRIGGERS, fn='{}/event_type_list.json'.format(data_dir))\n\telse:\n\t    with open('{}/event_type_list.json'.format(data_dir), mode='r') as f:\n", "        TRIGGERS = json.load(f)\n\t# argument\n\tif not os.path.exists('{}/argument_role_list.json'.format(data_dir)):\n\t    if hp.data_class == 'ace':\n\t        argument = get_argument_role_ace(train_set)\n\t        argument1 = get_argument_role_ace(dev_set, argument)\n\t        argument2 = get_argument_role_ace(test_set, argument1)\n\t        ARGUMENTS = list(argument2)\n\t    else:\n\t        argument = get_argument_role(train_set)\n", "        argument1 = get_argument_role(dev_set, argument)\n\t        argument2 = get_argument_role(test_set, argument1)\n\t        ARGUMENTS = list(argument2)\n\t    write_json(data=ARGUMENTS, fn='{}/argument_role_list.json'.format(data_dir))\n\telse:\n\t    with open('{}/argument_role_list.json'.format(data_dir), mode='r') as f:\n\t        ARGUMENTS = json.load(f)\n\t# entity\n\tif not os.path.exists('{}/entity_type_list.json'.format(data_dir)):\n\t    if hp.data_class == 'ace':\n", "        entities = get_entity_type_ace(train_set)\n\t        entities = get_entity_type_ace(dev_set, entities)\n\t        entities = get_entity_type_ace(test_set, entities)\n\t        ENTITIES = list(entities)\n\t    else:\n\t        entities, mention_type = get_entity_type(train_set)\n\t        entities, mention_type = get_entity_type(dev_set, entities, mention_type)\n\t        entities, mention_type = get_entity_type(test_set, entities, mention_type)\n\t        ENTITIES = list(entities)\n\t    write_json(data=ENTITIES, fn='{}/entity_type_list.json'.format(data_dir))\n", "else:\n\t    with open('{}/entity_type_list.json'.format(data_dir), mode='r') as f:\n\t        ENTITIES = json.load(f)\n\t# if __name__ == \"__main__\":\n\t#     hp = get_hparams()\n\t#     data_dir = None\n\t#     if hp.data_class == 'wiki_src':\n\t#         data_dir = 'Datasets/wiki_processed_data/source/'\n\t#     elif hp.data_class == 'wiki_info':\n\t#         data_dir = 'Datasets/wiki_processed_data/info/'\n", "#     elif hp.data_class == 'ace':\n\t#         data_dir = 'Datasets/ace2005/'\n\t#     train_set = data_dir + 'train.json'\n\t#     test_set = data_dir + 'test.json'\n\t#     dev_set = data_dir + 'dev.json'\n\t    # # 在没有预处理文件时可以使用。否则，直接创建TRIGGER AND ARGUMENTS即可\n\t    # test_event1 = [{\"id\": \"scenario_en_kairos_14-E3\",\n\t    #                 \"event_type\": \"Cognitive.IdentifyCategorize.Unspecified\",\n\t    #                 \"trigger\": (30, 31, 'Cognitive.IdentifyCategorize.Unspecified'),\n\t    #                 \"arguments\": []},\n", "    #                {\"id\": \"scenario_en_kairos_14-E2\",\n\t    #                 \"event_type\": \"Cognitive.Inspection.SensoryObserve\",\n\t    #                 \"trigger\": (88, 89, 'Cognitive.Inspection.SensoryObserve'),\n\t    #                 \"arguments\": []},\n\t    #                {\"id\": \"scenario_en_kairos_14-E1\",\n\t    #                 \"event_type\": \"Cognitive.IdentifyCategorize.Unspecified\",\n\t    #                 \"trigger\": (166, 167, 'Cognitive.IdentifyCategorize.Unspecified'),\n\t    #                 \"arguments\": []}]\n\t    #\n\t    # test_event2 = [{\"id\": \"scenario_en_kairos_65-E1\", \"event_type\": \"Conflict.Attack.Unspecified\",\n", "    #                 \"trigger\": (50, 51, 'Conflict.Attack.Unspecified'),\n\t    #                 \"arguments\": []},\n\t    #                {\"id\": \"scenario_en_kairos_65-E2\", \"event_type\": \"Life.Injure.Unspecified\",\n\t    #                 \"trigger\": (62, 63, 'Life.Injure.Unspecified'),\n\t    #                 \"arguments\": [(59, 61, 'Victim')]},\n\t    #                {\"id\": \"scenario_en_kairos_65-E3\", \"event_type\": \"Conflict.Attack.DetonateExplode\",\n\t    #                 \"trigger\": (65, 66, 'Conflict.Attack.DetonateExplode'),\n\t    #                 \"arguments\": []},\n\t    #                {\"id\": \"scenario_en_kairos_65-E4\", \"event_type\": \"Conflict.Attack.DetonateExplode\",\n\t    #                 \"trigger\": (417, 419, 'Conflict.Attack.DetonateExplode'),\n", "    #                 \"arguments\": []},\n\t    #                {\"id\": \"scenario_en_kairos_65-E5\", \"event_type\": \"Conflict.Attack.DetonateExplode\",\n\t    #                 \"trigger\": (433, 434, 'Conflict.Attack.DetonateExplode'),\n\t    #                 \"arguments\": []}]\n\t#     process_data_fn = 'wiki_processed_data/source'\n\t    # train_set = \"../../wiki_events_dataset/info_data/train_info.jsonl\"\n\t    # dev_set = \"../../wiki_events_dataset/info_data/dev_info.jsonl\"\n\t    # test_set = \"../../wiki_events_dataset/info_data/test_info.jsonl\"\n\t    # process_data_fn = 'processed_data/info'\n\t    # if not exists(process_data_fn):\n", "    #     os.makedirs(process_data_fn)\n\t    # trigger\n\t    # if not os.path.exists('{}/event_type_list.json'.format(process_data_fn)):\n\t    #     triggers0 = set()\n\t    #     triggers1 = get_event_type(train_set, triggers0)\n\t    #     triggers2 = get_event_type(dev_set, triggers1)\n\t    #     triggers3 = get_event_type(test_set, triggers2)\n\t    #     TRIGGERS = list(triggers3)\n\t    #     write_json(data=TRIGGERS, fn='{}/event_type_list.json'.format(process_data_fn))\n\t    # else:\n", "    #     with open('{}/event_type_list.json'.format(process_data_fn), mode='r') as f:\n\t    #         TRIGGERS = json.load(f)\n\t    #\n\t    # # argument\n\t    # if not os.path.exists('{}/argument_role_list.json'.format(process_data_fn)):\n\t    #     argument = get_argument_role(train_set)\n\t    #     argument1 = get_argument_role(dev_set, argument)\n\t    #     argument2 = get_argument_role(test_set, argument1)\n\t    #     ARGUMENTS = list(argument2)\n\t    #     write_json(data=ARGUMENTS, fn='{}/argument_role_list.json'.format(process_data_fn))\n", "    # else:\n\t    #     with open('{}/argument_role_list.json'.format(process_data_fn), mode='r') as f:\n\t    #         ARGUMENTS = json.load(f)\n\t    #\n\t    # # entity\n\t    # if not os.path.exists('{}/entity_type_list.json'.format(process_data_fn)):\n\t    #     entities, mention_type = get_entity_type(train_set)\n\t    #     entities, mention_type = get_entity_type(dev_set, entities, mention_type)\n\t    #     entities, mention_type = get_entity_type(test_set, entities, mention_type)\n\t    #     ENTITIES = list(entities)\n", "    #     write_json(data=ENTITIES, fn='{}/entity_type_list.json'.format(process_data_fn))\n\t    # else:\n\t    #     with open('{}/entity_type_list.json'.format(process_data_fn), mode='r') as f:\n\t    #         ENTITIES = json.load(f)\n\t    #\n\t    # processed_train = '{}/train.json'.format(process_data_fn)\n\t    # processed_dev = '{}/dev.json'.format(process_data_fn)\n\t    # processed_test = '{}/test.json'.format(process_data_fn)\n\t    # chunk_test = '{}/test_chunk.json'.format(process_data_fn)\n\t    #\n", "    # over_write = False\n\t    # if not os.path.exists(processed_train) or over_write:\n\t    #     process(train_set, processed_train)\n\t    # if not os.path.exists(processed_dev) or over_write:\n\t    #     process(dev_set, processed_dev)\n\t    # if not os.path.exists(processed_test) or over_write:\n\t    #     process(test_set, processed_test)\n"]}
{"filename": "src/Event/train.py", "chunked_list": ["import os\n\timport torch\n\timport torch.nn as nn\n\timport torch.optim as optim\n\tfrom torch.utils import data\n\tfrom data_load import Dataset, pad, all_triggers, all_arguments\n\tfrom model import Net\n\tfrom params import get_hparams\n\tfrom train_eval import train, evaluate\n\timport logging\n", "logging.basicConfig(level=logging.INFO, filename='output.txt', filemode='w')\n\tif __name__ == \"__main__\":\n\t    hp = get_hparams()\n\t    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\t    model = Net(\n\t        device=device,\n\t        trigger_size=len(all_triggers),\n\t        argument_size=len(all_arguments),\n\t        hparams=hp\n\t    )\n", "    if device == 'cuda':\n\t        model = model.cuda()\n\t    model = nn.DataParallel(model)\n\t    data_dir = None\n\t    if hp.data_class == 'wiki_src':\n\t        data_dir = 'Datasets/wiki_processed_data/source/'\n\t    elif hp.data_class == 'wiki_info':\n\t        data_dir = 'Datasets/wiki_processed_data/info/'\n\t    elif hp.data_class == 'ace':\n\t        data_dir = 'Datasets/ace2005/'\n", "    train_set = data_dir + 'train.json'\n\t    test_set = data_dir + 'test.json'\n\t    dev_set = data_dir + 'dev.json'\n\t    train_dataset = Dataset(train_set)\n\t    dev_dataset = Dataset(dev_set)\n\t    test_dataset = Dataset(test_set)\n\t    samples_weight = train_dataset.get_samples_weight()\n\t    sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight))\n\t    train_iter = data.DataLoader(dataset=train_dataset,\n\t                                 batch_size=hp.batch_size,\n", "                                 shuffle=False,\n\t                                 sampler=sampler,\n\t                                 num_workers=4,\n\t                                 collate_fn=pad)\n\t    dev_iter = data.DataLoader(dataset=dev_dataset,\n\t                               batch_size=hp.batch_size,\n\t                               shuffle=False,\n\t                               num_workers=4,\n\t                               collate_fn=pad)\n\t    test_iter = data.DataLoader(dataset=test_dataset,\n", "                                batch_size=hp.batch_size,\n\t                                shuffle=False,\n\t                                num_workers=4,\n\t                                collate_fn=pad)\n\t    optimizer = optim.Adam(model.parameters(), lr=hp.lr)\n\t    # optimizer = optim.Adadelta(model.parameters(), lr=1.0, weight_decay=1e-2)\n\t    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\t    if not os.path.exists(hp.logdir):\n\t        os.makedirs(hp.logdir)\n\t    f1_max_dev = 0\n", "    f1_max_test = 0\n\t    for epoch in range(1, hp.n_epochs + 1):\n\t        train(model, train_iter, optimizer, criterion)\n\t        f_name = os.path.join(hp.logdir, str(epoch))\n\t        print(f\"=========eval dev at epoch={epoch}=========\")\n\t        logging.info(f\"=========eval dev at epoch={epoch}=========\")\n\t        f1_dev = evaluate(model, dev_iter, f_name + '_dev', f1_max_dev)\n\t        if f1_dev > f1_max_dev:\n\t            f1_max_dev = f1_dev\n\t            if not os.path.exists(hp.model_save_path):\n", "                os.makedirs(hp.model_save_path)\n\t            torch.save(model, f\"{hp.model_save_path}/best_model_{epoch}.pt\")\n\t            print('best_model has been saved')\n\t            print(f\"weights were saved to {f_name}.pt\")\n\t            logging.info('best_model has been saved')\n\t            logging.info(f\"weights were saved to {f_name}.pt\")\n\t        print(f\"=========eval test at epoch={epoch}=========\")\n\t        logging.info(f\"=========eval test at epoch={epoch}=========\")\n\t        f1_test = evaluate(model, test_iter, f_name + '_test', f1_max_test)\n\t        if f1_test > f1_max_test:\n", "            f1_max_test = f1_test\n"]}
{"filename": "src/Event/model_demo.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom transformers import BertModel, BertConfig\n\tfrom consts import NONE\n\tfrom data_load import idx2trigger, argument2idx\n\tfrom utils import find_triggers\n\tclass Net_demo(nn.Module):\n\t    def __init__(self, trigger_size=None, argument_size=None, device=torch.device(\"cpu\"), hparams=None):\n\t        super().__init__()\n\t        self.bert_model = BertModel.from_pretrained(hparams.model_name).to(device)\n", "        self.bert_tokenizer = BertConfig.from_pretrained(hparams.model_name)\n\t        hidden_size = self.bert_tokenizer.hidden_size\n\t        self.fc1 = nn.Sequential(\n\t            nn.Linear(hidden_size, hidden_size, bias=True),\n\t            nn.ReLU(),\n\t        ).to(device)\n\t        self.fc_trigger = nn.Sequential(\n\t            nn.Linear(hidden_size, trigger_size),\n\t        ).to(device)\n\t        self.fc_argument = nn.Sequential(\n", "            nn.Linear(hidden_size, argument_size),\n\t        ).to(device)\n\t        self.device = device\n\t    def predict_triggers(self, tokens_x_2d, head_indexes_2d, triggers_y_2d, arguments_2d):\n\t        tokens_x_2d = torch.LongTensor(tokens_x_2d).to(self.device)\n\t        triggers_y_2d = torch.LongTensor(triggers_y_2d).to(self.device)\n\t        head_indexes_2d = torch.LongTensor(head_indexes_2d).to(self.device)\n\t        if self.training:\n\t            self.bert_model.train()\n\t            output = self.bert_model(tokens_x_2d)\n", "            encoded_layers = output['last_hidden_state']\n\t        else:\n\t            self.bert_model.eval()\n\t            with torch.no_grad():\n\t                output = self.bert_model(tokens_x_2d)\n\t                encoded_layers = output['last_hidden_state']\n\t        batch_size = tokens_x_2d.shape[0]\n\t        for i in range(batch_size):\n\t            encoded_layers[i] = torch.index_select(encoded_layers[i], 0, head_indexes_2d[i])\n\t        trigger_logits = self.fc_trigger(encoded_layers)\n", "        trigger_hat_2d = trigger_logits.argmax(-1)\n\t        argument_hidden = []\n\t        argument_keys = []\n\t        for i in range(batch_size):\n\t            candidates = arguments_2d[i]['candidates']\n\t            golden_entity_tensors = {}\n\t            for j in range(len(candidates)):\n\t                e_start, e_end = candidates[j]\n\t                golden_entity_tensors[candidates[j]] = encoded_layers[i, e_start:e_end, ].mean(dim=0)\n\t            predicted_triggers = find_triggers([idx2trigger[trigger] for trigger in trigger_hat_2d[i].tolist()])\n", "            for predicted_trigger in predicted_triggers:\n\t                t_start, t_end, t_type_str = predicted_trigger\n\t                event_tensor = encoded_layers[i, t_start:t_end, ].mean(dim=0)\n\t                for j in range(len(candidates)):\n\t                    e_start, e_end = candidates[j]\n\t                    argument_hidden.append(torch.cat([event_tensor]))\n\t                    argument_keys.append((i, t_start, t_end, t_type_str, e_start, e_end))\n\t        return trigger_logits, triggers_y_2d, trigger_hat_2d, argument_hidden, argument_keys\n\t    def predict_arguments(self,\n\t                          argument_hidden,\n", "                          argument_keys,\n\t                          arguments_2d):\n\t        argument_hidden = torch.stack(argument_hidden)\n\t        argument_logits = self.fc_argument(argument_hidden)\n\t        argument_hat_1d = argument_logits.argmax(-1)\n\t        arguments_y_1d = []\n\t        for i, t_start, t_end, t_type_str, \\\n\t            e_start, e_end in argument_keys:\n\t            arg_label = argument2idx[NONE]\n\t            if (t_start, t_end, t_type_str) in arguments_2d[i]['events']:\n", "                for (a_start, a_end, a_type_idx) in arguments_2d[i]['events'][(t_start, t_end, t_type_str)]:\n\t                    if e_start == a_start and e_end == a_end:\n\t                        # raise Exception\n\t                        arg_label = a_type_idx\n\t                        break\n\t            arguments_y_1d.append(arg_label)\n\t        arguments_y_1d = torch.LongTensor(arguments_y_1d).to(self.device)\n\t        batch_size = len(arguments_2d)\n\t        argument_hat_2d = [{'events': {}} for _ in range(batch_size)]\n\t        for (i, st, ed, event_type_str, e_st, e_ed), a_label in zip(argument_keys, argument_hat_1d.cpu().numpy()):\n", "            if a_label == argument2idx[NONE]:\n\t                continue\n\t            if (st, ed, event_type_str) not in argument_hat_2d[i]['events']:\n\t                argument_hat_2d[i]['events'][(st, ed, event_type_str)] = []\n\t            argument_hat_2d[i]['events'][(st, ed, event_type_str)].append((e_st, e_ed, a_label))\n\t        return argument_logits, arguments_y_1d, argument_hat_1d, argument_hat_2d\n\t    def predict_triggers_demo(self, tokens_x_2d, head_indexes_2d, arguments_2d):\n\t        tokens_x_2d = torch.LongTensor(tokens_x_2d).to(self.device)\n\t        head_indexes_2d = torch.LongTensor(head_indexes_2d).to(self.device)\n\t        self.bert_model.eval()\n", "        with torch.no_grad():\n\t            output = self.bert_model(tokens_x_2d)\n\t            encoded_layers = output['last_hidden_state']\n\t        batch_size = tokens_x_2d.shape[0]\n\t        for i in range(batch_size):\n\t            encoded_layers[i] = torch.index_select(encoded_layers[i], 0, head_indexes_2d[i])\n\t        trigger_logits = self.fc_trigger(encoded_layers)\n\t        trigger_hat_2d = trigger_logits.argmax(-1)\n\t        argument_hidden = []\n\t        for i in range(batch_size):\n", "            predicted_triggers = find_triggers([idx2trigger[trigger] for trigger in trigger_hat_2d[i].tolist()])\n\t            for predicted_trigger in predicted_triggers:\n\t                t_start, t_end, t_type_str = predicted_trigger\n\t                event_tensor = encoded_layers[i, t_start:t_end, ].mean(dim=0)\n\t                for j in range(len(candidates)):\n\t                    e_start, e_end = candidates[j]\n\t                    argument_hidden.append(torch.cat([event_tensor]))\n\t                    argument_keys.append((i, t_start, t_end, t_type_str, e_start, e_end))\n\t        return trigger_logits, triggers_y_2d, trigger_hat_2d, argument_hidden, argument_keys\n\t    def predict_arguments_demo(self,\n", "                          argument_hidden,\n\t                          argument_keys,\n\t                          arguments_2d):\n\t        argument_hidden = torch.stack(argument_hidden)\n\t        argument_logits = self.fc_argument(argument_hidden)\n\t        argument_hat_1d = argument_logits.argmax(-1)\n\t        arguments_y_1d = []\n\t        for i, t_start, t_end, t_type_str, \\\n\t            e_start, e_end in argument_keys:\n\t            arg_label = argument2idx[NONE]\n", "            if (t_start, t_end, t_type_str) in arguments_2d[i]['events']:\n\t                for (a_start, a_end, a_type_idx) in arguments_2d[i]['events'][(t_start, t_end, t_type_str)]:\n\t                    if e_start == a_start and e_end == a_end:\n\t                        # raise Exception\n\t                        arg_label = a_type_idx\n\t                        break\n\t            arguments_y_1d.append(arg_label)\n\t        arguments_y_1d = torch.LongTensor(arguments_y_1d).to(self.device)\n\t        batch_size = len(arguments_2d)\n\t        argument_hat_2d = [{'events': {}} for _ in range(batch_size)]\n", "        for (i, st, ed, event_type_str, e_st, e_ed), a_label in zip(argument_keys, argument_hat_1d.cpu().numpy()):\n\t            if a_label == argument2idx[NONE]:\n\t                continue\n\t            if (st, ed, event_type_str) not in argument_hat_2d[i]['events']:\n\t                argument_hat_2d[i]['events'][(st, ed, event_type_str)] = []\n\t            argument_hat_2d[i]['events'][(st, ed, event_type_str)].append((e_st, e_ed, a_label))\n\t        return argument_logits, arguments_y_1d, argument_hat_1d, argument_hat_2d"]}
{"filename": "src/Event/utils.py", "chunked_list": ["import json\n\tmax_length = 400\n\tdef build_vocab(labels, BIO_tagging=True):\n\t    all_labels = [\"[PAD]\", 'O']\n\t    for label in labels:\n\t        if BIO_tagging:\n\t            all_labels.append('B-{}'.format(label))\n\t            all_labels.append('I-{}'.format(label))\n\t        else:\n\t            all_labels.append(label)\n", "    label2idx = {tag: idx for idx, tag in enumerate(all_labels)}\n\t    idx2label = {idx: tag for idx, tag in enumerate(all_labels)}\n\t    return all_labels, label2idx, idx2label\n\tdef calc_metric(y_true, y_pred):\n\t    \"\"\"\n\t    :param y_true: [(tuple), ...]\n\t    :param y_pred: [(tuple), ...]\n\t    :return:\n\t    \"\"\"\n\t    num_proposed = len(y_pred)\n", "    num_gold = len(y_true)\n\t    y_true_set = set(y_true)\n\t    num_correct = 0\n\t    for item in y_pred:\n\t        if item in y_true_set:\n\t            num_correct += 1\n\t    print('proposed: {}\\tcorrect: {}\\tgold: {}'.format(num_proposed, num_correct, num_gold))\n\t    if num_proposed != 0:\n\t        precision = num_correct / num_proposed\n\t    else:\n", "        precision = 1.0\n\t    if num_gold != 0:\n\t        recall = num_correct / num_gold\n\t    else:\n\t        recall = 1.0\n\t    if precision + recall != 0:\n\t        f1 = 2 * precision * recall / (precision + recall)\n\t    else:\n\t        f1 = 0\n\t    return precision, recall, f1\n", "def find_triggers(labels):\n\t    \"\"\"\n\t    :param labels: ['B-Conflict:Attack', 'I-Conflict:Attack', 'O', 'B-Life:Marry']\n\t    :return: [(0, 2, 'Conflict:Attack'), (3, 4, 'Life:Marry')]\n\t    \"\"\"\n\t    result = []\n\t    labels = [label.split('-') for label in labels]\n\t    for i in range(len(labels)):\n\t        if labels[i][0] == 'B':\n\t            result.append([i, i + 1, labels[i][1]])\n", "    for item in result:\n\t        j = item[1]\n\t        while j < len(labels):\n\t            if labels[j][0] == 'I':\n\t                j = j + 1\n\t                item[1] = j\n\t            else:\n\t                break\n\t    return [tuple(item) for item in result]\n\tdef get_pre_dict(sentence_e_mentions,  # 一个句子，包含了多个event\n", "                 sentence_before_len,\n\t                 context,\n\t                 words,\n\t                 data_new,\n\t                 sent_entity_mentions,\n\t                 entity_id_num_none=0, entity_id_num=0):\n\t    \"\"\"\n\t    sent_entity_mentions:  todo entity是可以跨句的？\n\t    \"\"\"\n\t    # label triggers and arguments\n", "    golden_event_mentions = []\n\t    for event in sentence_e_mentions:\n\t        trigger = {\"start\": event['trigger']['start'] - sentence_before_len,\n\t                   \"end\": event['trigger']['end'] - sentence_before_len,\n\t                   \"text\": event['trigger']['text']}\n\t        if trigger['start'] > max_length or trigger['end'] < 0:\n\t            continue\n\t        arguments = event['arguments']\n\t        args_list = []\n\t        for arg in arguments:\n", "            entity_id = arg['entity_id']\n\t            span = []\n\t            for entity in sent_entity_mentions:\n\t                if entity['id'] == entity_id:\n\t                    span = [entity['start'] - sentence_before_len, entity['end'] - sentence_before_len]\n\t                    break\n\t            if span:\n\t                args_dict = {\n\t                    \"role\": arg['role'],\n\t                    \"text\": arg['text'],\n", "                    \"start\": span[0],\n\t                    \"end\": span[1],\n\t                    # 'span': span\n\t                }\n\t                args_list.append(args_dict)\n\t        golden_event_mentions.append({\n\t            'trigger': trigger,\n\t            'arguments': args_list,\n\t            'event_type': event['event_type']\n\t        })\n", "    entity_mentions = []\n\t    for entity in sent_entity_mentions:\n\t        enti = {'entity_type': entity['entity_type'],\n\t                'start': entity['start'] - sentence_before_len,\n\t                'end': entity['end'] - sentence_before_len}\n\t        if enti['start'] > max_length or enti['end'] < 0:\n\t            continue\n\t        entity_mentions.append(enti)\n\t    data_dict = {\n\t        'sentence': context,\n", "        'words': words,\n\t        'golden_event_mentions': golden_event_mentions,\n\t        'golden_entity_mentions': entity_mentions\n\t    }\n\t    data_new.append(data_dict)\n\t    return entity_id_num_none, entity_id_num\n\tdef write_json(data, fn):\n\t    with open(fn, 'w', encoding='utf-8') as f:\n\t        json.dump(data, f, ensure_ascii=False)\n\tdef process(wiki_json, processed_json):\n", "    \"\"\"\n\t    return:\n\t        {'id': data_id, 'content': content, 'occur': type_occur, 'type': TYPE, 'triggers': triggers, 'index': index,\n\t        'args': trigger_args[trigger_str]}\n\t        todo 如何加上args，关键是在arg_span上，根据entity_id进行对应\n\t    \"\"\"\n\t    data_new = []\n\t    entity_id_num_none, entity_id_num = 0, 0\n\t    # source: train:22/4542, dev:2/428 , test:3/566\n\t    # info: train:1151/4413, dev:99/411 , test:152/556\n", "    with open(wiki_json, 'r') as wiki:\n\t        lines = wiki.readlines()\n\t        for line in lines:\n\t            record = json.loads(line)\n\t            idx2sentence = {idx: tag for idx, tag in enumerate(record['sentences'])}\n\t            event_mentions = record['event_mentions']\n\t            entity_mentions = record['entity_mentions']\n\t            # todo sentence_entity_mentions\n\t            for sent_idx in range(len(idx2sentence)):\n\t                sentence_before_len = 0\n", "                for k in range(sent_idx):\n\t                    sentence_before_len += len(idx2sentence[k][0])\n\t                sentence_e_mentions = []\n\t                sent_entity_mentions = []\n\t                # 一个句子多个event_mention,加入到一个list里\n\t                for e_mention in event_mentions:\n\t                    if e_mention['trigger']['sent_idx'] == sent_idx:\n\t                        sentence_e_mentions.append(e_mention)\n\t                for entity_men in entity_mentions:\n\t                    if entity_men['sent_idx'] == sent_idx:\n", "                        sent_entity_mentions.append(entity_men)\n\t                sentence_words_with_span = idx2sentence[sent_idx][0]\n\t                words = [w[0] for w in sentence_words_with_span]\n\t                context = idx2sentence[sent_idx][1]\n\t                if len(idx2sentence[sent_idx][0]) >= max_length:\n\t                    # continue\n\t                    split_nums = len(idx2sentence[sent_idx][0]) // max_length + 1\n\t                    for s_num in range(split_nums):\n\t                        if s_num < split_nums - 1:\n\t                            split_words = words[s_num * max_length: (s_num + 1) * max_length]\n", "                            split_context = ' '.join(w for w in split_words)\n\t                        else:\n\t                            split_words = words[s_num * max_length:]\n\t                            split_context = ' '.join(w for w in split_words)\n\t                            # entity_id_num_none, entity_id_num = \\\n\t                        get_pre_dict(sentence_e_mentions=sentence_e_mentions,\n\t                                     sentence_before_len=sentence_before_len,\n\t                                     context=split_context, words=split_words, data_new=data_new,\n\t                                     sent_entity_mentions=sent_entity_mentions,\n\t                                     # entity_id_num_none=entity_id_num_none, entity_id_num=entity_id_num\n", "                                     )\n\t                        sentence_before_len += max_length\n\t                else:  # 不长的句子\n\t                    # label all occurrence types\n\t                    # entity_id_num_none, entity_id_num = \\\n\t                    get_pre_dict(sentence_e_mentions=sentence_e_mentions,\n\t                                 sentence_before_len=sentence_before_len, context=context,\n\t                                 words=words,\n\t                                 data_new=data_new, sent_entity_mentions=sent_entity_mentions,\n\t                                 # entity_id_num_none=entity_id_num_none, entity_id_num=entity_id_num\n", "                                 )\n\t    x = 0\n\t    with open(processed_json, 'w', encoding='utf-8') as f:\n\t        for line in data_new:\n\t            line = json.dumps(line, ensure_ascii=False)\n\t            f.write(line + '\\n')\n\tdef process_test(wiki_json, processed_json):\n\t    \"\"\"\n\t    return:\n\t        {'id': data_id,\n", "        'content': content,\n\t        events->dict_list:\n\t        [{'type': event_type, 'triggers': {\"span\":[start, end], \"word\": text},\n\t         {'type':,'trigger':,}...}, {}...]}\n\t        'args': trigger_args[trigger_str]}  这个argument也可以加上试试效果。\n\t    \"\"\"\n\t    data_new = []\n\t    with open(wiki_json, 'r') as wiki:\n\t        lines = wiki.readlines()\n\t        for line in lines:\n", "            suf_id = 0  # 加在doc_id的后缀\n\t            record = json.loads(line)\n\t            data_id = record['doc_id']\n\t            idx2sentence = {idx: tag for idx, tag in enumerate(record['sentences'])}\n\t            event_mentions = record['event_mentions']\n\t            # 同一个sent_idx聚集到一起\n\t            for sent_idx in range(len(idx2sentence)):\n\t                sentence_before_len = 0\n\t                for k in range(sent_idx):\n\t                    sentence_before_len += len(idx2sentence[k][0])\n", "                sentence_e_mentions = []\n\t                # 一个句子多个event_mention,加入到一个list里\n\t                for e_mention in event_mentions:\n\t                    if e_mention['trigger']['sent_idx'] == sent_idx:\n\t                        sentence_e_mentions.append(e_mention)\n\t                context = idx2sentence[sent_idx][1]\n\t                sentence_words_with_span = idx2sentence[sent_idx][0]\n\t                words = [w[0] for w in sentence_words_with_span]\n\t                # # label triggers and arguments\n\t                event_dict_list = []\n", "                for sent_event in sentence_e_mentions:\n\t                    # get event_dict_list\n\t                    tri_span = [sent_event['trigger']['start'] - sentence_before_len,\n\t                                sent_event['trigger']['end'] - sentence_before_len]\n\t                    event_dict = {'type': sent_event['event_type'],\n\t                                  'triggers': {\"span\": tri_span}, \"word\": sent_event['trigger']['text']}\n\t                    event_dict_list.append(event_dict)\n\t                data_new_dict = {'id': data_id + '_' + str(suf_id), 'content': context,\n\t                                 'words': words, 'events': event_dict_list}\n\t                data_new.append(data_new_dict)\n", "                suf_id += 1\n\t    x = data_new\n\t    with open(processed_json, 'w', encoding='utf-8') as f:\n\t        for line in data_new:\n\t            line = json.dumps(line, ensure_ascii=False)\n\t            f.write(line + '\\n')\n\tdef get_event_type(wiki_json, e_type):\n\t    \"\"\"\n\t    read wikiEvents,\n\t    return:\n", "        event_type_list\n\t        event_type2arg_role\n\t        shared_args\n\t    \"\"\"\n\t    with open(wiki_json, 'r') as f:\n\t        lines = f.readlines()\n\t        for line in lines:\n\t            item = json.loads(line)\n\t            event_mentions = item['event_mentions']\n\t            for e_mention in event_mentions:\n", "                e_type.add(e_mention['event_type'])\n\t    return e_type\n\tdef get_argument_role(wiki_json, arguments=None):\n\t    if arguments is None:\n\t        arguments = set()\n\t    with open(wiki_json, 'r') as f:\n\t        lines = f.readlines()\n\t        for line in lines:\n\t            item = json.loads(line)\n\t            event_mentions = item['event_mentions']\n", "            for e_mention in event_mentions:\n\t                for i in range(len(e_mention['arguments'])):\n\t                    arguments.add(e_mention['arguments'][i]['role'])\n\t    return arguments\n\tdef get_entity_type(wiki_json, entities=None, mention_type=None):\n\t    if mention_type is None:\n\t        mention_type = set()\n\t    if entities is None:\n\t        entities = set()\n\t    with open(wiki_json, 'r') as f:\n", "        lines = f.readlines()\n\t        for line in lines:\n\t            item = json.loads(line)\n\t            entity_mentions = item['entity_mentions']\n\t            for e_mention in entity_mentions:\n\t                entities.add(e_mention['entity_type'])\n\t                mention_type.add(e_mention['mention_type'])\n\t    return entities, mention_type\n\tdef get_entity_type_ace(ace_json, entities=None):\n\t    if entities is None:\n", "        entities = set()\n\t    with open(ace_json, 'r') as f:\n\t        lines = json.load(f)\n\t        for line in lines:\n\t            entity_mentions = line['golden-entity-mentions']\n\t            for e_mention in entity_mentions:\n\t                entities.add(e_mention['entity_type'])\n\t    return entities\n\tdef get_event_type_ace(ace_json, e_type):\n\t    with open(ace_json, 'r') as f:\n", "        for line in f:\n\t            item = json.loads(line)\n\t        lines = json.load(f)\n\t        for line in lines:\n\t            event_mentions = line['golden-event-mentions']\n\t            for e_mention in event_mentions:\n\t                e_type.add(e_mention['event_type'])\n\t    return e_type\n\tdef get_argument_role_ace(ace_json, arguments=None):\n\t    if arguments is None:\n", "        arguments = set()\n\t    with open(ace_json, 'r') as f:\n\t        lines = json.load(f)\n\t        for line in lines:\n\t            event_mentions = line['golden-event-mentions']\n\t            for e_mention in event_mentions:\n\t                for i in range(len(e_mention['arguments'])):\n\t                    arguments.add(e_mention['arguments'][i]['role'])\n\t    return arguments\n"]}
{"filename": "src/Event/eval.py", "chunked_list": ["import os\n\timport torch\n\tfrom torch.utils import data\n\tfrom data_load import Dataset, pad\n\tfrom params import get_hparams\n\tfrom train_eval import evaluate\n\tif __name__ == \"__main__\":\n\t    hp = get_hparams()\n\t    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\t    model = torch.load(f'{hp.model_save_path}/best_model_12.pt')\n", "    if device == 'cuda':\n\t        model = model.cuda()\n\t    test_dataset = Dataset(hp.test_set)\n\t    test_iter = data.DataLoader(dataset=test_dataset,\n\t                                batch_size=hp.batch_size,\n\t                                shuffle=False,\n\t                                num_workers=4,\n\t                                collate_fn=pad)\n\t    dev_dataset = Dataset(hp.dev_set)\n\t    dev_iter = data.DataLoader(dataset=dev_dataset,\n", "                               batch_size=hp.batch_size,\n\t                               shuffle=False,\n\t                               num_workers=4,\n\t                               collate_fn=pad)\n\t    if not os.path.exists(hp.logdir):\n\t        os.makedirs(hp.logdir)\n\t    print(f\"=========eval test=========\")\n\t    evaluate(model, test_iter, 'eval_test')\n\t    print(f\"=========eval dev=========\")\n\t    evaluate(model, dev_iter, 'eval_dev')\n"]}
{"filename": "src/Event/demo_event.py", "chunked_list": ["import nltk\n\timport numpy as np\n\timport torch\n\timport gradio as gr\n\tfrom consts import CLS, SEP, NONE, max_length\n\t# from consts import test_event1, test_event2,\n\tfrom data_load import tokenizer, trigger2idx, pad, idx2trigger\n\tfrom params import get_hparams\n\tfrom torch.utils import data\n\tfrom utils import find_triggers\n", "class Data_input(data.Dataset):\n\t    def __init__(self, document):\n\t        self.sent_li = []\n\t        self.entities_li = []\n\t        self.postags_li = []\n\t        self.triggers_li = []\n\t        self.arguments_li = []\n\t        self.entities_li = []\n\t        words = nltk.word_tokenize(document)\n\t        split_num = len(words) // max_length\n", "        for i in range(split_num + 1):\n\t            if i < split_num:\n\t                w = words[i * max_length: (i + 1) * max_length]\n\t            else:\n\t                w = words[i * max_length:]\n\t            triggers = [NONE] * len(w)\n\t            arguments = {\n\t                'candidates': [],\n\t                'events': {},\n\t            }\n", "            self.sent_li.append([CLS] + w + [SEP])\n\t            self.triggers_li.append(triggers)\n\t            self.arguments_li.append(arguments)\n\t    def __len__(self):\n\t        return len(self.sent_li)\n\t    def __getitem__(self, idx):\n\t        words = self.sent_li[idx]\n\t        triggers = self.triggers_li[idx]\n\t        arguments = self.arguments_li[idx]\n\t        # We give credits only to the first piece.\n", "        tokens_x = []\n\t        is_heads = []\n\t        for w in words:\n\t            tokens = tokenizer.tokenize(w) if w not in [CLS, SEP] else [w]\n\t            tokens_xx = tokenizer.convert_tokens_to_ids(tokens)\n\t            if w in [CLS, SEP]:\n\t                is_head = [0]\n\t            else:\n\t                is_head = [1] + [0] * (len(tokens) - 1)\n\t            tokens_x.extend(tokens_xx)\n", "            is_heads.extend(is_head)\n\t        triggers_y = [trigger2idx[t] for t in triggers]\n\t        head_indexes = []\n\t        for i in range(len(is_heads)):\n\t            if is_heads[i]:\n\t                head_indexes.append(i)\n\t        seqlen = len(tokens_x)\n\t        return tokens_x, triggers_y, arguments, seqlen, head_indexes, words, triggers\n\t    def get_samples_weight(self):\n\t        samples_weight = []\n", "        for triggers in self.triggers_li:\n\t            not_none = False\n\t            for trigger in triggers:\n\t                if trigger != NONE:\n\t                    not_none = True\n\t                    break\n\t            if not_none:\n\t                samples_weight.append(5.0)\n\t            else:\n\t                samples_weight.append(1.0)\n", "        return np.array(samples_weight)\n\tdef extract_events(user_input):\n\t    hp = get_hparams()\n\t    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\t    model = torch.load(f'{hp.model_save_path}/best_model_11.pt')\n\t    if device == 'cuda':\n\t        model = model.cuda()\n\t    if hasattr(model, 'module'):\n\t        model = model.module\n\t    model.eval()\n", "    data_input = Data_input(user_input)\n\t    data_iter = data.DataLoader(dataset=data_input,\n\t                                batch_size=len(data_input.triggers_li),\n\t                                shuffle=False,\n\t                                num_workers=4,\n\t                                collate_fn=pad)\n\t    words_all = []\n\t    triggers_all = []\n\t    triggers_hat_all = []\n\t    arguments_all = []\n", "    arguments_hat_all = []\n\t    # if direct:\n\t    #     return test_event2\n\t    with torch.no_grad():\n\t        for i, batch in enumerate(data_iter):\n\t            tokens_x_2d, triggers_y_2d, arguments_2d, seqlens_1d, head_indexes_2d, words_2d, triggers_2d = batch\n\t            trigger_logits, triggers_y_2d, trigger_hat_2d, argument_hidden, argument_keys \\\n\t                = model.predict_triggers(tokens_x_2d=tokens_x_2d, head_indexes_2d=head_indexes_2d,\n\t                                         triggers_y_2d=triggers_y_2d, arguments_2d=arguments_2d)\n\t        words_all.extend(words_2d)\n", "        triggers_all.extend(triggers_2d)\n\t        triggers_hat_all.extend(trigger_hat_2d.cpu().numpy().tolist())\n\t        arguments_all.extend(arguments_2d)\n\t        if len(argument_keys) > 0:\n\t            argument_logits, arguments_y_1d, argument_hat_1d, argument_hat_2d = \\\n\t                model.predict_arguments(argument_hidden, argument_keys, arguments_2d)\n\t            arguments_hat_all.extend(argument_hat_2d)\n\t        else:\n\t            batch_size = len(arguments_2d)\n\t            argument_hat_2d = [{'events': {}} for _ in range(batch_size)]\n", "            arguments_hat_all.extend(argument_hat_2d)\n\t    triggers_pred = []\n\t    arguments_pred = []\n\t    events = []\n\t    for i, (words, triggers, triggers_hat, arguments, arguments_hat) \\\n\t            in enumerate(zip(words_all, triggers_all, triggers_hat_all, arguments_all, arguments_hat_all)):\n\t        triggers_hat = triggers_hat[:len(words)]\n\t        triggers_hat = [idx2trigger[hat] for hat in triggers_hat]\n\t        # [(ith sentence, t_start, t_end, t_type_str)]\n\t        triggers_pred.extend([(i, *item) for item in find_triggers(triggers_hat)])\n", "        for trigger in arguments_hat['events']:\n\t            t_start, t_end, t_type_str = trigger\n\t            for argument in arguments_hat['events'][trigger]:\n\t                a_start, a_end, a_type_idx = argument\n\t                arguments_pred.append((i, t_start, t_end, t_type_str, a_start, a_end, a_type_idx))\n\t        event = {\n\t            'trigger': triggers_pred,\n\t            'argument': arguments_pred,\n\t        }\n\t        events.append(event)\n", "    return events\n\tif __name__ == \"__main__\":\n\t    document1 = 'As of early Tuesday there was no claim of responsibility. Prayuth Chan-ocha, the head of Thailand\\u2019s military government, said that the authorities were searching for a person seen on closed-circuit footage but that it was not clear who the person was, news agencies reported.A spokesman for the police, Lt. Gen. Prawut Thavornsiri, told a Thai television interviewer that \\u201cwe haven\\u2019t concluded anything.\\u201d The authorities said they were reviewing footage from 15 security cameras in the area but that the rush-hour crowds made deciphering the video difficult.\\u201cThe shrine was very crowded,\\u201d General Prawut said. \\u201cIt\\u2019s not clear even looking at the CCTV footage.\\u201dThe bomb, General Prawut said, was placed under a bench on the outer rim of the shrine\\u2019s grounds. Initially, the police said they had discovered at least two additional devices that they suspected were unexploded bombs inside the shrine and said other bombs may have been placed in the area, yelling at bystanders: \\u201cGet out! Get out!\\u201d'\n\t    document2 = \"A settlement has been reached in a $1-million lawsuit filed by a taxi driver accusing police of negligence after he got caught up in the August 2016 take-down of ISIS-sympathizer Aaron Driver.READ MORE: FBI agent whose tip thwarted 2016 ISIS attack in Ontario says he was glad to helpTerry Duffield was injured when Driver detonated a homemade explosive in the back of his cab in August 2016.\\u201cI have to be very careful because there is an agreement to not disclose any of the terms of the settlement,\\u201d Duffield\\u2019s lawyer Kevin Egan told 980 CFPL.\\u201cThe statement of claim, I guess, speaks for itself in regard to what we alleged.\\u201dWATCH: Ontario taxi driver files $1M lawsuit against police2:18 Ontario taxi driver files $1M lawsuit against police Ontario taxi driver files $1M lawsuit against policeThat statement of claim, which Global News obtained a copy of in late March 2018, said police had more than enough time to intervene before Driver got into Duffield\\u2019s taxi. The Attorney General of Canada, the Ontario government, Strathroy-Caradoc Police Service and London Police Service were named as defendants.Story continues below advertisementOn the morning of Aug. 10, 2016, U.S. authorities notified the RCMP they had detected a so-called martyrdom video in which a Canadian man said he was about to conduct an attack.The RCMP identified the man in the video as Driver and a tactical team surrounded his house in Strathroy.At 3:45 p.m., Driver called for a cab to take him to Citi Plaza in London. The claim alleged that despite the police presence, Duffield was not stopped from pulling into Driver\\u2019s driveway. Driver then came out of the house and got into the back seat of the cab.\\u201cWhen the SWAT team approached the vehicle, [Duffield] turned to Mr. Driver and said, \\u2018I think they\\u2019re here to talk to you\\u2019 and he leaned over to get his cigarettes, it\\u2019s a bench seat in the front of the taxicab, as he put his head down below the bench seat, the bomb went off.\\u201dStory continues below advertisementThe inside of the cab where Aaron Driver detonated an explosive device on Aug. 10, 2016. Handout / RCMPEgan said Duffield had a preexisting back injury and the bomb blast triggered recurring pain. He also noted that his client was psychologically impacted by the event and is no longer able to work as a taxi driver.\\u201cHe did try it. Got in a vehicle, turned the key on and started to shake and sweat and got out of the vehicle and vomited,\\u201d said Egan. Tweet This\\u201cHe was so traumatized by the event. He realized that any time any potential passenger was approaching the vehicle with a package he would be hyper-vigilant about that and just couldn\\u2019t handle it emotionally.\\u201dDetails of the settlement will not be made public, but Egan noted that no amount of money can properly compensate someone for physical or psychological injuries, but \\u201cis the best we can do in the circumstance.\\u201d He also noted that, while he was unwilling to disclose too much of Duffield\\u2019s personal health, he has received some counselling and is \\u201ccoping better now than he was then.\\u201dStory continues below advertisement\\u2013 with files from Stewart Bell and Andrew Russell.\"\n\t    input_text = gr.inputs.Textbox(lines=10, label=\"Input Text\")\n\t    output_text = gr.outputs.Textbox(label=\"Output\")\n\t    gr.Interface(fn=extract_events, inputs=input_text, outputs=output_text, title=\"Event Extraction\",\n\t                 description=\"Enter some text and the model will extract events.\").launch(share=True)\n\t    # # todo for debug\n\t    # events = extract_events(document2)\n", "    # print(\"Triggers and Arguments:\")\n\t    # for event in events:\n\t    #     print(f\"Trigger: {event['trigger']}\")\n\t    #     print(\"Arguments:\")\n\t    #     if event['argument']:\n\t    #         for argument in event['argument']:\n\t    #             print(f\"\\t{argument}\")\n\t    #     else:\n\t    #         print('argument is None')\n\t    # while True:\n", "    #     user_input = input(\"Enter a sentence: \")\n\t    #     if user_input == \"quit\":\n\t    #         break\n\t    #     elif user_input == 'None':\n\t    #         events = extract_events(document2)\n\t    #     else:\n\t    #         events = extract_events(user_input)\n\t    #     print(\"Triggers and Arguments:\")\n\t    #     for event in events:\n\t    #         print(f\"Trigger: {event['trigger']}\")\n", "    #         print(\"Arguments:\")\n\t    #         for argument in event['arguments']:\n\t    #             print(f\"\\t{argument}\")\n"]}
{"filename": "src/Event/data_load.py", "chunked_list": ["import numpy as np\n\tfrom torch.utils import data\n\timport json\n\tfrom transformers import BertTokenizer\n\t# init vocab\n\tfrom consts import TRIGGERS, ARGUMENTS, NONE, SEP, CLS, PAD, UNK\n\tfrom params import get_hparams\n\tfrom utils import build_vocab\n\tall_triggers, trigger2idx, idx2trigger = build_vocab(TRIGGERS)\n\tall_arguments, argument2idx, idx2argument = build_vocab(ARGUMENTS, BIO_tagging=False)\n", "hparams = get_hparams()\n\ttokenizer = BertTokenizer.from_pretrained(hparams.model_name, do_lower_case=False, never_split=(PAD, CLS, SEP, UNK))\n\tclass Dataset(data.Dataset):\n\t    def __init__(self, fpath):\n\t        self.sent_li = []\n\t        self.entities_li = []\n\t        self.postags_li = []\n\t        self.triggers_li = []\n\t        self.arguments_li = []\n\t        self.entities_li = []\n", "        with open(fpath, 'r') as f:\n\t            lines = f.readlines()\n\t            for line in lines:\n\t                item = json.loads(line)\n\t                words = item['words']\n\t                triggers = [NONE] * len(words)\n\t                arguments = {\n\t                    'candidates': [\n\t                        # ex. (5, 6, \"entity_type_str\"), ...\n\t                    ],\n", "                    'events': {\n\t                        # ex. (1, 3, \"trigger_type_str\"): [(5, 6, \"argument_role_idx\"), ...]\n\t                    },\n\t                }\n\t                for entity_mention in item['golden_entity_mentions']:\n\t                    arguments['candidates'].append(\n\t                        (entity_mention['start'], entity_mention['end']))\n\t                for event_mention in item['golden_event_mentions']:\n\t                    for i in range(event_mention['trigger']['start'], event_mention['trigger']['end']):\n\t                        trigger_type = event_mention['event_type']\n", "                        if i == event_mention['trigger']['start']:\n\t                            triggers[i] = 'B-{}'.format(trigger_type)\n\t                        else:\n\t                            triggers[i] = 'I-{}'.format(trigger_type)\n\t                    event_key = (event_mention['trigger']['start'], event_mention['trigger']['end'], event_mention['event_type'])\n\t                    arguments['events'][event_key] = []\n\t                    for argument in event_mention['arguments']:\n\t                        role = argument['role']\n\t                        arguments['events'][event_key].append((argument['start'], argument['end'], argument2idx[role]))\n\t                self.sent_li.append([CLS] + words + [SEP])\n", "                self.triggers_li.append(triggers)\n\t                self.arguments_li.append(arguments)\n\t    def __len__(self):\n\t        return len(self.sent_li)\n\t    def __getitem__(self, idx):\n\t        words = self.sent_li[idx]\n\t        triggers = self.triggers_li[idx]\n\t        arguments = self.arguments_li[idx]\n\t        # We give credits only to the first piece.\n\t        tokens_x = []\n", "        is_heads = []\n\t        for w in words:\n\t            tokens = tokenizer.tokenize(w) if w not in [CLS, SEP] else [w]\n\t            tokens_xx = tokenizer.convert_tokens_to_ids(tokens)\n\t            if w in [CLS, SEP]:\n\t                is_head = [0]\n\t            else:\n\t                is_head = [1] + [0] * (len(tokens) - 1)\n\t            tokens_x.extend(tokens_xx)\n\t            is_heads.extend(is_head)\n", "        triggers_y = [trigger2idx[t] for t in triggers]\n\t        head_indexes = []\n\t        for i in range(len(is_heads)):\n\t            if is_heads[i]:\n\t                head_indexes.append(i)\n\t        seqlen = len(tokens_x)\n\t        return tokens_x, triggers_y, arguments, seqlen, head_indexes, words, triggers\n\t    def get_samples_weight(self):\n\t        samples_weight = []\n\t        for triggers in self.triggers_li:\n", "            not_none = False\n\t            for trigger in triggers:\n\t                if trigger != NONE:\n\t                    not_none = True\n\t                    break\n\t            if not_none:\n\t                samples_weight.append(5.0)\n\t            else:\n\t                samples_weight.append(1.0)\n\t        return np.array(samples_weight)\n", "def pad(batch):\n\t    tokens_x_2d, triggers_y_2d, arguments_2d, seqlens_1d, head_indexes_2d, words_2d, triggers_2d = list(map(list, zip(*batch)))\n\t    maxlen = np.array(seqlens_1d).max()\n\t    for i in range(len(tokens_x_2d)):\n\t        tokens_x_2d[i] = tokens_x_2d[i] + [0] * (maxlen - len(tokens_x_2d[i]))\n\t        head_indexes_2d[i] = head_indexes_2d[i] + [0] * (maxlen - len(head_indexes_2d[i]))\n\t        triggers_y_2d[i] = triggers_y_2d[i] + [trigger2idx[PAD]] * (maxlen - len(triggers_y_2d[i]))\n\t    return tokens_x_2d, \\\n\t           triggers_y_2d, arguments_2d, \\\n\t           seqlens_1d, head_indexes_2d, \\\n", "           words_2d, triggers_2d\n"]}
{"filename": "src/Entity/run_eval.py", "chunked_list": ["import argparse\n\tfrom shared.data_structures import Dataset, evaluate_predictions\n\tif __name__ == \"__main__\":\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument('--prediction_file', type=str, default=None, required=True)\n\t    args = parser.parse_args()\n\t    data = Dataset(args.prediction_file)\n\t    eval_result = evaluate_predictions(data)\n\t    print('Evaluation result %s' % args.prediction_file)\n\t    print('NER - P: %f, R: %f, F1: %f' % (\n", "        eval_result['ner']['precision'], eval_result['ner']['recall'], eval_result['ner']['f1']))\n\t    print('REL - P: %f, R: %f, F1: %f' % (\n\t        eval_result['relation']['precision'], eval_result['relation']['recall'], eval_result['relation']['f1']))\n\t    print('REL (strict) - P: %f, R: %f, F1: %f' % (\n\t        eval_result['strict_relation']['precision'], eval_result['strict_relation']['recall'],\n\t        eval_result['strict_relation']['f1']))\n"]}
{"filename": "src/Entity/run_entity.py", "chunked_list": ["import json\n\timport logging\n\timport os\n\timport random\n\timport sys\n\timport time\n\timport torch\n\tfrom tqdm import tqdm\n\tfrom transformers import AdamW, get_linear_schedule_with_warmup\n\tfrom entity.models import EntityModel\n", "from entity.utils import convert_dataset_to_samples, batchify, NpEncoder\n\tfrom shared.const import task_ner_labels, get_labelmap\n\tfrom shared.data_structures import Dataset\n\tfrom shared.get_hparams import get_hparams_entity\n\tlogging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n\t                    datefmt='%m/%d/%Y %H:%M:%S',\n\t                    level=logging.INFO)\n\tlogger = logging.getLogger('root')\n\tdef save_model(model, args):\n\t    \"\"\"\n", "    Save the model to the output directory\n\t    \"\"\"\n\t    logger.info('Saving model to %s...' % (args.output_dir))\n\t    model_to_save = model.bert_model.module if hasattr(model.bert_model, 'module') else model.bert_model\n\t    model_to_save.save_pretrained(args.output_dir)\n\t    model.tokenizer.save_pretrained(args.output_dir)\n\tdef output_ner_predictions(model, batches, dataset, output_file):\n\t    \"\"\"\n\t    Save the prediction as a json file\n\t    \"\"\"\n", "    ner_result = {}\n\t    span_hidden_table = {}\n\t    tot_pred_ett = 0\n\t    for i in range(len(batches)):\n\t        output_dict = model.run_batch(batches[i], training=False)\n\t        pred_ner = output_dict['pred_ner']\n\t        for sample, preds in zip(batches[i], pred_ner):\n\t            off = sample['sent_start_in_doc'] - sample['sent_start']\n\t            k = sample['doc_key'] + '-' + str(sample['sentence_ix'])\n\t            ner_result[k] = []\n", "            for span, pred in zip(sample['spans'], preds):\n\t                span_id = '%s::%d::(%d,%d)' % (sample['doc_key'], sample['sentence_ix'], span[0] + off, span[1] + off)\n\t                if pred == 0:\n\t                    continue\n\t                ner_result[k].append([span[0] + off, span[1] + off, ner_id2label[pred]])\n\t            tot_pred_ett += len(ner_result[k])\n\t    logger.info('Total pred entities: %d' % tot_pred_ett)\n\t    js = dataset.js\n\t    for i, doc in enumerate(js):\n\t        doc[\"predicted_ner\"] = []\n", "        doc[\"predicted_relations\"] = []\n\t        for j in range(len(doc[\"sentences\"])):\n\t            k = doc['doc_key'] + '-' + str(j)\n\t            if k in ner_result:\n\t                doc[\"predicted_ner\"].append(ner_result[k])\n\t            else:\n\t                logger.info('%s not in NER results!' % k)\n\t                doc[\"predicted_ner\"].append([])\n\t            doc[\"predicted_relations\"].append([])\n\t        js[i] = doc\n", "    logger.info('Output predictions to %s..' % (output_file))\n\t    with open(output_file, 'w') as f:\n\t        f.write('\\n'.join(json.dumps(doc, cls=NpEncoder) for doc in js))\n\tdef evaluate(model, batches, tot_gold):\n\t    \"\"\"\n\t    Evaluate the entity model\n\t    \"\"\"\n\t    logger.info('Evaluating...')\n\t    c_time = time.time()\n\t    cor = 0\n", "    tot_pred = 0\n\t    l_cor = 0\n\t    l_tot = 0\n\t    for i in range(len(batches)):\n\t        output_dict = model.run_batch(batches[i], training=False)\n\t        pred_ner = output_dict['pred_ner']\n\t        for sample, \\\n\t            preds in \\\n\t                zip(batches[i], pred_ner):\n\t            for gold, \\\n", "                pred in zip(sample['spans_label'], preds):\n\t                l_tot += 1\n\t                if pred == gold:\n\t                    l_cor += 1\n\t                if pred != 0 and gold != 0 and pred == gold:\n\t                    cor += 1\n\t                if pred != 0:\n\t                    tot_pred += 1\n\t    acc = l_cor / l_tot\n\t    logger.info('Accuracy: %5f' % acc)\n", "    logger.info('Cor: %d, Pred TOT: %d, Gold TOT: %d' % (cor, tot_pred, tot_gold))\n\t    p = cor / tot_pred if cor > 0 else 0.0\n\t    r = cor / tot_gold if cor > 0 else 0.0\n\t    f1 = 2 * (p * r) / (p + r) if cor > 0 else 0.0\n\t    logger.info('P: %.5f, R: %.5f, F1: %.5f' % (p, r, f1))\n\t    logger.info('Used time: %f' % (time.time() - c_time))\n\t    return f1\n\tdef setseed(seed):\n\t    random.seed(seed)\n\t    torch.manual_seed(seed)\n", "    if torch.cuda.is_available():\n\t        torch.cuda.manual_seed_all(seed)\n\tif __name__ == '__main__':\n\t    hparams = get_hparams_entity()\n\t    hparams.train_data_path = os.path.join(hparams.data_dir, 'train.json')\n\t    hparams.dev_data_path = os.path.join(hparams.data_dir, 'dev.json')\n\t    hparams.test_data_path = os.path.join(hparams.data_dir, 'test.json')\n\t    if 'albert' in hparams.model:\n\t        logger.info('Use Albert: %s' % hparams.model)\n\t        hparams.use_albert = True\n", "    setseed(hparams.seed)\n\t    if not os.path.exists(hparams.output_dir):\n\t        os.makedirs(hparams.output_dir)\n\t    if hparams.do_train:\n\t        logger.addHandler(logging.FileHandler(os.path.join(hparams.output_dir, \"train.log\"), 'w'))\n\t    else:\n\t        logger.addHandler(logging.FileHandler(os.path.join(hparams.output_dir, \"eval.log\"), 'w'))\n\t    logger.info(sys.argv)\n\t    logger.info(hparams)\n\t    ner_label2id, ner_id2label = get_labelmap(task_ner_labels[hparams.task])\n", "    num_ner_labels = len(task_ner_labels[hparams.task]) + 1\n\t    model = EntityModel(hparams, num_ner_labels=num_ner_labels)\n\t    dev_data = Dataset(hparams.dev_data_path)\n\t    dev_samples, dev_ner = convert_dataset_to_samples(dev_data, hparams.max_span_length, ner_label2id=ner_label2id,\n\t                                                      context_window=hparams.context_window)\n\t    dev_batches = batchify(dev_samples, hparams.eval_batch_size)\n\t    if hparams.do_train:\n\t        train_data = Dataset(hparams.train_data_path)\n\t        train_samples, train_ner = convert_dataset_to_samples(train_data, hparams.max_span_length,\n\t                                                              ner_label2id=ner_label2id,\n", "                                                              context_window=hparams.context_window)\n\t        train_batches = batchify(train_samples, hparams.train_batch_size)\n\t        best_result = 0.0\n\t        param_optimizer = list(model.bert_model.named_parameters())\n\t        optimizer_grouped_parameters = [\n\t            {'params': [p for n, p in param_optimizer\n\t                        if 'bert' in n]},\n\t            {'params': [p for n, p in param_optimizer\n\t                        if 'bert' not in n], 'lr': hparams.task_learning_rate}]\n\t        optimizer = AdamW(optimizer_grouped_parameters, lr=hparams.learning_rate, correct_bias=not hparams.bertadam)\n", "        t_total = len(train_batches) * hparams.num_epoch\n\t        scheduler = get_linear_schedule_with_warmup(optimizer, int(t_total * hparams.warmup_proportion), t_total)\n\t        tr_loss = 0\n\t        tr_examples = 0\n\t        global_step = 0\n\t        eval_step = len(train_batches) // hparams.eval_per_epoch\n\t        for epoch in tqdm(range(hparams.num_epoch)):\n\t            if hparams.train_shuffle:\n\t                random.shuffle(train_batches)\n\t            for i in tqdm(range(len(train_batches))):\n", "                output_dict = model.run_batch(train_batches[i], training=True)\n\t                loss = output_dict['ner_loss']\n\t                loss.backward()\n\t                tr_loss += loss.item()\n\t                tr_examples += len(train_batches[i])\n\t                global_step += 1\n\t                optimizer.step()\n\t                scheduler.step()\n\t                optimizer.zero_grad()\n\t                if global_step % hparams.print_loss_step == 0:\n", "                    logger.info('Epoch=%d, iter=%d, loss=%.5f' % (epoch, i, tr_loss / tr_examples))\n\t                    tr_loss = 0\n\t                    tr_examples = 0\n\t                if global_step % eval_step == 0:\n\t                    f1 = evaluate(model, dev_batches, dev_ner)\n\t                    if f1 > best_result:\n\t                        best_result = f1\n\t                        logger.info('!!! Best valid (epoch=%d): %.2f' % (epoch, f1 * 100))\n\t                        save_model(model, hparams)\n\t    if hparams.do_eval:\n", "        hparams.bert_model_dir = hparams.output_dir\n\t        model = EntityModel(hparams, num_ner_labels=num_ner_labels)\n\t        eval_dev_data = Dataset(hparams.dev_data_path)\n\t        prediction_file = os.path.join(hparams.output_dir, hparams.dev_pred_filename)\n\t        eval_dev_samples, eval_dev_ner = convert_dataset_to_samples(eval_dev_data, hparams.max_span_length,\n\t                                                                    ner_label2id=ner_label2id,\n\t                                                                    context_window=hparams.context_window)\n\t        eval_dev_batches = batchify(eval_dev_samples, hparams.eval_batch_size)\n\t        evaluate(model, eval_dev_batches, eval_dev_ner)\n\t        output_ner_predictions(model, eval_dev_batches, eval_dev_data, output_file=prediction_file)\n", "        if hparams.eval_test:\n\t            eval_test_data = Dataset(hparams.test_data)\n\t            prediction_file = os.path.join(hparams.output_dir, hparams.test_pred_filename)\n\t            eval_test_samples, eval_test_ner = convert_dataset_to_samples(eval_test_data, hparams.max_span_length,\n\t                                                                          ner_label2id=ner_label2id,\n\t                                                                          context_window=hparams.context_window)\n\t            eval_test_batches = batchify(eval_test_samples, hparams.eval_batch_size)\n\t            evaluate(model, eval_test_batches, eval_test_ner)\n\t            output_ner_predictions(model, eval_test_batches, eval_test_data, output_file=prediction_file)\n"]}
{"filename": "src/Entity/demo_entity.py", "chunked_list": ["import spacy\n\tnlp = spacy.load(\"en_core_web_sm\")\n\ttext = \"Apple is looking at buying U.K. startup for $1 billion\"\n\tdoc = nlp(text)\n\tfor ent in doc.ents:\n\t    print(ent.text, ent.start_char, ent.end_char, ent.label_)"]}
{"filename": "src/Entity/entity/models.py", "chunked_list": ["import logging\n\timport torch\n\timport torch.nn.functional as F\n\tfrom allennlp.modules import FeedForward\n\tfrom allennlp.nn.util import batched_index_select\n\tfrom torch import nn\n\tfrom torch.nn import CrossEntropyLoss\n\tfrom transformers import AlbertTokenizer, AlbertPreTrainedModel, AlbertModel\n\tfrom transformers import BertTokenizer, BertPreTrainedModel, BertModel\n\tlogger = logging.getLogger('root')\n", "class BertForEntity(BertPreTrainedModel):\n\t    def __init__(self, config, num_ner_labels, head_hidden_dim=150, width_embedding_dim=150, max_span_length=8):\n\t        super().__init__(config)\n\t        self.config = config\n\t        self.bert = BertModel(config)\n\t        self.hidden_dropout = nn.Dropout(config.hidden_dropout_prob)\n\t        self.width_embedding = nn.Embedding(max_span_length + 1, width_embedding_dim)\n\t        self.ner_classifier = nn.Sequential(\n\t            FeedForward(input_dim=config.hidden_size * 2 + width_embedding_dim,\n\t                        num_layers=2,\n", "                        hidden_dims=head_hidden_dim,\n\t                        activations=F.relu,\n\t                        dropout=0.2),\n\t            nn.Linear(head_hidden_dim, num_ner_labels)\n\t        )\n\t        self.init_weights()  # 这里应该是缺失定义了，没有这样的函数\n\t    def _get_span_embeddings(self, input_ids, spans, token_type_ids=None, attention_mask=None):\n\t        z = self.bert(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n\t        # sequence_output0 = z.last_hidden_state\n\t        last_hidden_state = z[0]\n", "        sequence_output = self.hidden_dropout(last_hidden_state)\n\t        \"\"\"\n\t        spans: [batch_size, num_spans, 3]; 0: left_ned, 1: right_end, 2: width\n\t        spans_mask: (batch_size, num_spans, )\n\t        \"\"\"\n\t        spans_start = spans[:, :, 0].view(spans.size(0), -1)\n\t        spans_start_embedding = batched_index_select(sequence_output, spans_start)\n\t        spans_end = spans[:, :, 1].view(spans.size(0), -1)\n\t        spans_end_embedding = batched_index_select(sequence_output, spans_end)\n\t        spans_width = spans[:, :, 2].view(spans.size(0), -1)\n", "        spans_width_embedding = self.width_embedding(spans_width)\n\t        # Concatenate embeddings of left/right points and the width embedding\n\t        spans_embedding = torch.cat((spans_start_embedding, spans_end_embedding, spans_width_embedding), dim=-1)\n\t        \"\"\"\n\t        spans_embedding: (batch_size, num_spans, hidden_size*2+embedding_dim)\n\t        \"\"\"\n\t        return spans_embedding\n\t    def forward(self, input_ids, spans, spans_mask, spans_ner_label=None, token_type_ids=None, attention_mask=None):\n\t        spans_embedding = self._get_span_embeddings(input_ids, spans, token_type_ids=token_type_ids,\n\t                                                    attention_mask=attention_mask)\n", "        ffnn_hidden = []\n\t        hidden = spans_embedding\n\t        for layer in self.ner_classifier:\n\t            hidden = layer(hidden)\n\t            ffnn_hidden.append(hidden)\n\t        logits = ffnn_hidden[-1]\n\t        if spans_ner_label is not None:\n\t            loss_fct = CrossEntropyLoss(reduction='sum')\n\t            if attention_mask is not None:\n\t                active_loss = spans_mask.view(-1) == 1\n", "                active_logits = logits.view(-1, logits.shape[-1])\n\t                active_labels = torch.where(\n\t                    active_loss, spans_ner_label.view(-1), torch.tensor(loss_fct.ignore_index).type_as(spans_ner_label)\n\t                )\n\t                loss = loss_fct(active_logits, active_labels)\n\t            else:\n\t                loss = loss_fct(logits.view(-1, logits.shape[-1]), spans_ner_label.view(-1))\n\t            return loss, logits, spans_embedding\n\t        else:\n\t            return logits, spans_embedding, spans_embedding\n", "class AlbertForEntity(AlbertPreTrainedModel):\n\t    def __init__(self, config, num_ner_labels, head_hidden_dim=150, width_embedding_dim=150, max_span_length=8):\n\t        super().__init__(config)\n\t        self.albert = AlbertModel(config)\n\t        self.hidden_dropout = nn.Dropout(config.hidden_dropout_prob)\n\t        self.width_embedding = nn.Embedding(max_span_length + 1, width_embedding_dim)\n\t        self.ner_classifier = nn.Sequential(\n\t            FeedForward(input_dim=config.hidden_size * 2 + width_embedding_dim,\n\t                        num_layers=2,\n\t                        hidden_dims=head_hidden_dim,\n", "                        activations=F.relu,\n\t                        dropout=0.2),\n\t            nn.Linear(head_hidden_dim, num_ner_labels)\n\t        )\n\t        self.init_weights()\n\t    def _get_span_embeddings(self, input_ids, spans, token_type_ids=None, attention_mask=None):\n\t        sequence_output, pooled_output = self.albert(input_ids=input_ids, token_type_ids=token_type_ids,\n\t                                                     attention_mask=attention_mask)\n\t        sequence_output = self.hidden_dropout(sequence_output)\n\t        \"\"\"\n", "        spans: [batch_size, num_spans, 3]; 0: left_ned, 1: right_end, 2: width\n\t        spans_mask: (batch_size, num_spans, )\n\t        \"\"\"\n\t        spans_start = spans[:, :, 0].view(spans.size(0), -1)\n\t        spans_start_embedding = batched_index_select(sequence_output, spans_start)\n\t        spans_end = spans[:, :, 1].view(spans.size(0), -1)\n\t        spans_end_embedding = batched_index_select(sequence_output, spans_end)\n\t        spans_width = spans[:, :, 2].view(spans.size(0), -1)\n\t        spans_width_embedding = self.width_embedding(spans_width)\n\t        spans_embedding = torch.cat((spans_start_embedding, spans_end_embedding, spans_width_embedding), dim=-1)\n", "        \"\"\"\n\t        spans_embedding: (batch_size, num_spans, hidden_size*2+embedding_dim)\n\t        \"\"\"\n\t        return spans_embedding\n\t    def forward(self, input_ids, spans, spans_mask, spans_ner_label=None, token_type_ids=None, attention_mask=None):\n\t        spans_embedding = self._get_span_embeddings(input_ids, spans, token_type_ids=token_type_ids,\n\t                                                    attention_mask=attention_mask)\n\t        ffnn_hidden = []\n\t        hidden = spans_embedding\n\t        for layer in self.ner_classifier:\n", "            hidden = layer(hidden)\n\t            ffnn_hidden.append(hidden)\n\t        logits = ffnn_hidden[-1]\n\t        if spans_ner_label is not None:\n\t            loss_fct = CrossEntropyLoss(reduction='sum')\n\t            if attention_mask is not None:\n\t                active_loss = spans_mask.view(-1) == 1\n\t                active_logits = logits.view(-1, logits.shape[-1])\n\t                active_labels = torch.where(\n\t                    active_loss, spans_ner_label.view(-1), torch.tensor(loss_fct.ignore_index).type_as(spans_ner_label)\n", "                )\n\t                loss = loss_fct(active_logits, active_labels)\n\t            else:\n\t                loss = loss_fct(logits.view(-1, logits.shape[-1]), spans_ner_label.view(-1))\n\t            return loss, logits, spans_embedding\n\t        else:\n\t            return logits, spans_embedding, spans_embedding\n\tclass EntityModel:\n\t    def __init__(self, args, num_ner_labels):\n\t        super().__init__()\n", "        bert_model_name = args.model\n\t        vocab_name = bert_model_name\n\t        if args.bert_model_dir is not None:\n\t            bert_model_name = str(args.bert_model_dir) + '/'\n\t            # vocab_name = bert_model_name + 'vocab.txt'\n\t            vocab_name = bert_model_name\n\t            logger.info('Loading BERT model from {}'.format(bert_model_name))\n\t        if args.use_albert:\n\t            self.tokenizer = AlbertTokenizer.from_pretrained(vocab_name)\n\t            self.bert_model = AlbertForEntity.from_pretrained(bert_model_name, num_ner_labels=num_ner_labels,\n", "                                                              max_span_length=args.max_span_length)\n\t        else:  # use_bert\n\t            self.tokenizer = BertTokenizer.from_pretrained(vocab_name)\n\t            self.bert_model = BertForEntity.from_pretrained(bert_model_name, num_ner_labels=num_ner_labels,\n\t                                                            max_span_length=args.max_span_length)\n\t        self._model_device = 'cpu'\n\t        self.move_model_to_cuda()\n\t    def move_model_to_cuda(self):\n\t        if not torch.cuda.is_available():\n\t            logger.error('No CUDA found!')\n", "            exit(-1)\n\t        logger.info('Moving to CUDA...')\n\t        self._model_device = 'cuda'\n\t        self.bert_model.cuda()\n\t        logger.info('# GPUs = %d' % (torch.cuda.device_count()))\n\t        if torch.cuda.device_count() > 1:\n\t            self.bert_model = torch.nn.DataParallel(self.bert_model)\n\t    def _get_input_tensors(self, tokens, spans, spans_ner_label):\n\t        start2idx = []\n\t        end2idx = []\n", "        bert_tokens = [self.tokenizer.cls_token]\n\t        for token in tokens:\n\t            start2idx.append(len(bert_tokens))\n\t            sub_tokens = self.tokenizer.tokenize(token)\n\t            bert_tokens += sub_tokens\n\t            end2idx.append(len(bert_tokens) - 1)\n\t        bert_tokens.append(self.tokenizer.sep_token)\n\t        indexed_tokens = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n\t        tokens_tensor = torch.tensor([indexed_tokens])\n\t        bert_spans = [[start2idx[span[0]], end2idx[span[1]], span[2]] for span in spans]\n", "        bert_spans_tensor = torch.tensor([bert_spans])\n\t        spans_ner_label_tensor = torch.tensor([spans_ner_label])\n\t        return tokens_tensor, bert_spans_tensor, spans_ner_label_tensor\n\t    def _get_input_tensors_batch(self, samples_list, training=True):\n\t        tokens_tensor_list = []\n\t        bert_spans_tensor_list = []\n\t        spans_ner_label_tensor_list = []\n\t        sentence_length = []\n\t        max_tokens = 0\n\t        max_spans = 0\n", "        for sample in samples_list:\n\t            tokens = sample['tokens']\n\t            spans = sample['spans']\n\t            spans_ner_label = sample['spans_label']\n\t            tokens_tensor, bert_spans_tensor, spans_ner_label_tensor = self._get_input_tensors(tokens, spans,\n\t                                                                                               spans_ner_label)\n\t            tokens_tensor_list.append(tokens_tensor)\n\t            bert_spans_tensor_list.append(bert_spans_tensor)\n\t            spans_ner_label_tensor_list.append(spans_ner_label_tensor)\n\t            assert (bert_spans_tensor.shape[1] == spans_ner_label_tensor.shape[1])\n", "            if tokens_tensor.shape[1] > max_tokens:\n\t                max_tokens = tokens_tensor.shape[1]\n\t            if bert_spans_tensor.shape[1] > max_spans:\n\t                max_spans = bert_spans_tensor.shape[1]\n\t            sentence_length.append(sample['sent_length'])\n\t        sentence_length = torch.Tensor(sentence_length)\n\t        # apply padding and concatenate tensors\n\t        final_tokens_tensor = None\n\t        final_attention_mask = None\n\t        final_bert_spans_tensor = None\n", "        final_spans_ner_label_tensor = None\n\t        final_spans_mask_tensor = None\n\t        for tokens_tensor, bert_spans_tensor, spans_ner_label_tensor in zip(tokens_tensor_list, bert_spans_tensor_list,\n\t                                                                            spans_ner_label_tensor_list):\n\t            # padding for tokens\n\t            num_tokens = tokens_tensor.shape[1]\n\t            tokens_pad_length = max_tokens - num_tokens\n\t            attention_tensor = torch.full([1, num_tokens], 1, dtype=torch.long)\n\t            if tokens_pad_length > 0:\n\t                pad = torch.full([1, tokens_pad_length], self.tokenizer.pad_token_id, dtype=torch.long)\n", "                tokens_tensor = torch.cat((tokens_tensor, pad), dim=1)\n\t                attention_pad = torch.full([1, tokens_pad_length], 0, dtype=torch.long)\n\t                attention_tensor = torch.cat((attention_tensor, attention_pad), dim=1)\n\t            # padding for spans\n\t            num_spans = bert_spans_tensor.shape[1]\n\t            spans_pad_length = max_spans - num_spans\n\t            spans_mask_tensor = torch.full([1, num_spans], 1, dtype=torch.long)\n\t            if spans_pad_length > 0:\n\t                pad = torch.full([1, spans_pad_length, bert_spans_tensor.shape[2]], 0, dtype=torch.long)\n\t                bert_spans_tensor = torch.cat((bert_spans_tensor, pad), dim=1)\n", "                mask_pad = torch.full([1, spans_pad_length], 0, dtype=torch.long)\n\t                spans_mask_tensor = torch.cat((spans_mask_tensor, mask_pad), dim=1)\n\t                spans_ner_label_tensor = torch.cat((spans_ner_label_tensor, mask_pad), dim=1)\n\t            # update final outputs\n\t            if final_tokens_tensor is None:\n\t                final_tokens_tensor = tokens_tensor\n\t                final_attention_mask = attention_tensor\n\t                final_bert_spans_tensor = bert_spans_tensor\n\t                final_spans_ner_label_tensor = spans_ner_label_tensor\n\t                final_spans_mask_tensor = spans_mask_tensor\n", "            else:\n\t                final_tokens_tensor = torch.cat((final_tokens_tensor, tokens_tensor), dim=0)\n\t                final_attention_mask = torch.cat((final_attention_mask, attention_tensor), dim=0)\n\t                final_bert_spans_tensor = torch.cat((final_bert_spans_tensor, bert_spans_tensor), dim=0)\n\t                final_spans_ner_label_tensor = torch.cat((final_spans_ner_label_tensor, spans_ner_label_tensor), dim=0)\n\t                final_spans_mask_tensor = torch.cat((final_spans_mask_tensor, spans_mask_tensor), dim=0)\n\t        # logger.info(final_tokens_tensor)\n\t        # logger.info(final_attention_mask)\n\t        # logger.info(final_bert_spans_tensor)\n\t        # logger.info(final_bert_spans_tensor.shape)\n", "        # logger.info(final_spans_mask_tensor.shape)\n\t        # logger.info(final_spans_ner_label_tensor.shape)\n\t        return final_tokens_tensor, final_attention_mask, final_bert_spans_tensor, final_spans_mask_tensor, \\\n\t               final_spans_ner_label_tensor, sentence_length\n\t    def run_batch(self, samples_list, try_cuda=True, training=True):\n\t        # convert samples to input tensors\n\t        tokens_tensor, attention_mask_tensor, \\\n\t        bert_spans_tensor, spans_mask_tensor, \\\n\t        spans_ner_label_tensor, \\\n\t        sentence_length = self._get_input_tensors_batch(samples_list, training)\n", "        output_dict = {\n\t            'ner_loss': 0,\n\t        }\n\t        if training:\n\t            self.bert_model.train()\n\t            ner_loss, \\\n\t            ner_logits, \\\n\t            spans_embedding \\\n\t                = self.bert_model(\n\t                input_ids=tokens_tensor.to(self._model_device),\n", "                spans=bert_spans_tensor.to(self._model_device),\n\t                spans_mask=spans_mask_tensor.to(self._model_device),\n\t                spans_ner_label=spans_ner_label_tensor.to(self._model_device),\n\t                attention_mask=attention_mask_tensor.to(self._model_device),\n\t            )\n\t            output_dict['ner_loss'] = ner_loss.sum()\n\t            output_dict['ner_llh'] = F.log_softmax(ner_logits, dim=-1)\n\t        else:\n\t            self.bert_model.eval()\n\t            with torch.no_grad():\n", "                ner_logits, spans_embedding, last_hidden = self.bert_model(\n\t                    input_ids=tokens_tensor.to(self._model_device),\n\t                    spans=bert_spans_tensor.to(self._model_device),\n\t                    spans_mask=spans_mask_tensor.to(self._model_device),\n\t                    spans_ner_label=None,\n\t                    attention_mask=attention_mask_tensor.to(self._model_device),\n\t                )\n\t            _, predicted_label = ner_logits.max(2)\n\t            predicted_label = predicted_label.cpu().numpy()\n\t            last_hidden = last_hidden.cpu().numpy()\n", "            predicted = []\n\t            pred_prob = []\n\t            hidden = []\n\t            for i, sample in enumerate(samples_list):\n\t                ner = []\n\t                prob = []\n\t                lh = []\n\t                for j in range(len(sample['spans'])):\n\t                    ner.append(predicted_label[i][j])\n\t                    # prob.append(F.softmax(ner_logits[i][j], dim=-1).cpu().numpy())\n", "                    prob.append(ner_logits[i][j].cpu().numpy())\n\t                    lh.append(last_hidden[i][j])\n\t                predicted.append(ner)\n\t                pred_prob.append(prob)\n\t                hidden.append(lh)\n\t            output_dict['pred_ner'] = predicted\n\t            output_dict['ner_probs'] = pred_prob\n\t            output_dict['ner_last_hidden'] = hidden\n\t        return output_dict\n"]}
{"filename": "src/Entity/entity/utils.py", "chunked_list": ["import numpy as np\n\timport json\n\timport logging\n\tlogger = logging.getLogger('root')\n\tdef batchify(samples, batch_size):\n\t    \"\"\"\n\t    Batchfy samples with a batch size\n\t    \"\"\"\n\t    num_samples = len(samples)\n\t    list_samples_batches = []\n", "    # if a sentence is too long, make itself a batch to avoid GPU OOM\n\t    to_single_batch = []\n\t    for i in range(0, len(samples)):\n\t        if len(samples[i]['tokens']) > 350:\n\t            to_single_batch.append(i)\n\t    for i in to_single_batch:\n\t        logger.info('Single batch sample.json: %s-%d', samples[i]['doc_key'], samples[i]['sentence_ix'])\n\t        list_samples_batches.append([samples[i]])\n\t    samples = [sample for i, sample in enumerate(samples) if i not in to_single_batch]\n\t    for i in range(0, len(samples), batch_size):\n", "        list_samples_batches.append(samples[i:i + batch_size])\n\t    assert (sum([len(batch) for batch in list_samples_batches]) == num_samples)\n\t    return list_samples_batches\n\tdef overlap(s1, s2):\n\t    if s2.start_sent >= s1.start_sent and s2.start_sent <= s1.end_sent:\n\t        return True\n\t    if s2.end_sent >= s1.start_sent and s2.end_sent <= s1.end_sent:\n\t        return True\n\t    return False\n\tdef convert_dataset_to_samples(dataset, max_span_length, ner_label2id=None, context_window=0, split=0):\n", "    \"\"\"\n\t    Extract sentences and gold entities from a dataset\n\t    \"\"\"\n\t    # split: split the data into train and dev (for ACE04)\n\t    # split == 0: don't split\n\t    # split == 1: return first 90% (train)\n\t    # split == 2: return last 10% (dev)\n\t    samples = []\n\t    num_ner = 0\n\t    max_len = 0\n", "    max_ner = 0\n\t    num_overlap = 0\n\t    if split == 0:\n\t        data_range = (0, len(dataset))\n\t    elif split == 1:\n\t        data_range = (0, int(len(dataset) * 0.9))\n\t    elif split == 2:\n\t        data_range = (int(len(dataset) * 0.9), len(dataset))\n\t    else:\n\t        data_range = None\n", "    for c, doc in enumerate(dataset):\n\t        if c < data_range[0] or c >= data_range[1]:\n\t            continue\n\t        for i, sent in enumerate(doc):\n\t            num_ner += len(sent.ner)\n\t            sample = {'doc_key': doc._doc_key, 'sentence_ix': sent.sentence_ix, 'tokens': sent.text,\n\t                      'sent_length': len(sent.text)}\n\t            # if context_window != 0 and len(sent.text) > context_window:\n\t            #     logger.info('Long sentence: {} {}'.format(sample.json, len(sent.text)))\n\t                # print('Exclude:', sample.json)\n", "                # continue\n\t            sent_start = 0\n\t            sent_end = len(sample['tokens'])\n\t            max_len = max(max_len, len(sent.text))\n\t            max_ner = max(max_ner, len(sent.ner))\n\t            if context_window > 0:\n\t                add_left = (context_window - len(sent.text)) // 2\n\t                add_right = (context_window - len(sent.text)) - add_left\n\t                # add left context\n\t                j = i - 1\n", "                while j >= 0 and add_left > 0:\n\t                    context_to_add = doc[j].text[-add_left:]\n\t                    sample['tokens'] = context_to_add + sample['tokens']\n\t                    add_left -= len(context_to_add)\n\t                    sent_start += len(context_to_add)\n\t                    sent_end += len(context_to_add)\n\t                    j -= 1\n\t                # add right context\n\t                j = i + 1\n\t                while j < len(doc) and add_right > 0:\n", "                    context_to_add = doc[j].text[:add_right]\n\t                    sample['tokens'] = sample['tokens'] + context_to_add\n\t                    add_right -= len(context_to_add)\n\t                    j += 1\n\t            sample['sent_start'] = sent_start\n\t            sample['sent_end'] = sent_end\n\t            sample['sent_start_in_doc'] = sent.sentence_start\n\t            sent_ner = {}\n\t            for ner in sent.ner:\n\t                sent_ner[ner.span.span_sent] = ner.label\n", "            span2id = {}\n\t            sample['spans'] = []\n\t            sample['spans_label'] = []\n\t            for i in range(len(sent.text)):\n\t                for j in range(i, min(len(sent.text), i + max_span_length)):\n\t                    # 两次循环，因为要n(n-1)/2个entity\n\t                    sample['spans'].append((i + sent_start, j + sent_start, j - i + 1))\n\t                    # start，end，len\n\t                    span2id[(i, j)] = len(sample['spans']) - 1\n\t                    if (i, j) not in sent_ner:\n", "                        sample['spans_label'].append(0)\n\t                    else:\n\t                        sample['spans_label'].append(ner_label2id[sent_ner[(i, j)]])\n\t            samples.append(sample)\n\t    avg_length = sum([len(sample['tokens']) for sample in samples]) / len(samples)\n\t    max_length = max([len(sample['tokens']) for sample in samples])\n\t    logger.info('# Overlap: %d' % num_overlap)\n\t    logger.info('Extracted %d samples from %d documents, with %d NER labels, %.3f avg input length, %d max length' % (\n\t        len(samples), data_range[1] - data_range[0], num_ner, avg_length, max_length))\n\t    logger.info('Max Length: %d, max NER: %d' % (max_len, max_ner))\n", "    return samples, num_ner\n\tclass NpEncoder(json.JSONEncoder):\n\t    def default(self, obj):\n\t        if isinstance(obj, np.integer):\n\t            return int(obj)\n\t        elif isinstance(obj, np.floating):\n\t            return float(obj)\n\t        elif isinstance(obj, np.ndarray):\n\t            return obj.tolist()\n\t        else:\n", "            return super(NpEncoder, self).default(obj)\n\tdef get_train_fold(data, fold):\n\t    print('Getting train fold %d...' % fold)\n\t    l = int(len(data) * 0.1 * fold)\n\t    r = int(len(data) * 0.1 * (fold + 1))\n\t    new_js = []\n\t    new_docs = []\n\t    for i in range(len(data)):\n\t        if i < l or i >= r:\n\t            new_js.append(data.js[i])\n", "            new_docs.append(data.documents[i])\n\t    print('# documents: %d --> %d' % (len(data), len(new_docs)))\n\t    data.js = new_js\n\t    data.documents = new_docs\n\t    return data\n\tdef get_test_fold(data, fold):\n\t    print('Getting test fold %d...' % fold)\n\t    l = int(len(data) * 0.1 * fold)\n\t    r = int(len(data) * 0.1 * (fold + 1))\n\t    new_js = []\n", "    new_docs = []\n\t    for i in range(len(data)):\n\t        if i >= l and i < r:\n\t            new_js.append(data.js[i])\n\t            new_docs.append(data.documents[i])\n\t    print('# documents: %d --> %d' % (len(data), len(new_docs)))\n\t    data.js = new_js\n\t    data.documents = new_docs\n\t    return data\n"]}
{"filename": "src/Entity/shared/data_structures.py", "chunked_list": ["\"\"\"\n\tThis code is based on DYGIE++'s codebase\n\t\"\"\"\n\timport json\n\timport copy\n\timport os\n\tfrom collections import Counter\n\timport numpy as np\n\timport torch\n\tfrom torch.utils.data import DataLoader, TensorDataset\n", "def fields_to_batches(d, keys_to_ignore=None):\n\t    if keys_to_ignore is None:\n\t        keys_to_ignore = []\n\t    keys = [key for key in d.keys() if key not in keys_to_ignore]\n\t    lengths = [len(d[k]) for k in keys]\n\t    assert len(set(lengths)) == 1\n\t    length = lengths[0]\n\t    res = [{k: d[k][i] for k in keys} for i in range(length)]\n\t    return res\n\tdef get_sentence_of_span(span, sentence_starts, doc_tokens):\n", "    \"\"\"\n\t    Return the index of the sentence that the span is part of.\n\t    \"\"\"\n\t    # Inclusive sentence ends\n\t    sentence_ends = [x - 1 for x in sentence_starts[1:]] + [doc_tokens - 1]\n\t    in_between = [span[0] >= start and span[1] <= end\n\t                  for start, end in zip(sentence_starts, sentence_ends)]\n\t    assert sum(in_between) == 1\n\t    the_sentence = in_between.index(True)\n\t    return the_sentence\n", "class Dataset:\n\t    def __init__(self, json_file,\n\t                 pred_file=None, doc_range=None):\n\t        # default设置pred_file=None\n\t        self.js = self._read(json_file, pred_file)\n\t        if doc_range is not None:\n\t            self.js = self.js[doc_range[0]:doc_range[1]]\n\t        self.documents = [Document(js) for js in self.js]\n\t    def update_from_js(self, js):\n\t        self.js = js\n", "        self.documents = [Document(js) for js in self.js]\n\t    def _read(self, json_file, pred_file=None):\n\t        with open(json_file) as f:\n\t            gold_docs = json.load(f)\n\t        # gold_docs = [json.loads(line) for line in open(json_file)]\n\t        if pred_file is None:\n\t            return gold_docs\n\t        pred_docs = [json.loads(line) for line in open(pred_file)]\n\t        merged_docs = []\n\t        for gold, pred in zip(gold_docs, pred_docs):\n", "            assert gold[\"doc_key\"] == pred[\"doc_key\"]\n\t            assert gold[\"sentences\"] == pred[\"sentences\"]\n\t            merged = copy.deepcopy(gold)\n\t            for k, v in pred.items():\n\t                if \"predicted\" in k:\n\t                    merged[k] = v\n\t            merged_docs.append(merged)\n\t        return merged_docs\n\t    def __getitem__(self, ix):\n\t        return self.documents[ix]\n", "    def __len__(self):\n\t        return len(self.documents)\n\tclass Document:\n\t    def __init__(self, js):\n\t        if 'doc_key' in js:\n\t            self._doc_key = js[\"doc_key\"]\n\t            entries = fields_to_batches(js, [\"doc_key\", \"clusters\", \"predicted_clusters\", \"section_starts\"])\n\t        else:\n\t            entries = fields_to_batches(js, [\"clusters\", \"predicted_clusters\", \"section_starts\"])\n\t        sentence_lengths = [len(entry[\"sentences\"]) for entry in entries]\n", "        sentence_starts = np.cumsum(sentence_lengths)\n\t        # 累积求和，e.g if the input array is [a, b, c], the output of numpy.cumsum will be [a, a + b, a + b + c].\n\t        sentence_starts = np.roll(sentence_starts, 1)\n\t        # 滚动，全部数字向右滚动一位\n\t        sentence_starts[0] = 0\n\t        self.sentence_starts = sentence_starts\n\t        self.sentences = [Sentence(entry, sentence_start, sentence_ix)\n\t                          for sentence_ix, (entry, sentence_start)\n\t                          in enumerate(zip(entries, sentence_starts))]\n\t        # 可以没有clusters\n", "        if \"clusters\" in js:\n\t            self.clusters = [Cluster(entry, i, self)\n\t                             for i, entry in enumerate(js[\"clusters\"])]\n\t        if \"predicted_clusters\" in js:\n\t            self.predicted_clusters = [Cluster(entry, i, self)\n\t                                       for i, entry in enumerate(js[\"predicted_clusters\"])]\n\t    def __repr__(self):\n\t        return \"\\n\".join([str(i) + \": \" + \" \".join(sent.text) for i, sent in enumerate(self.sentences)])\n\t    def __getitem__(self, ix):\n\t        return self.sentences[ix]\n", "    def __len__(self):\n\t        return len(self.sentences)\n\t    def print_plaintext(self):\n\t        for sent in self:\n\t            print(\" \".join(sent.text))\n\t    def find_cluster(self, entity, predicted=True):\n\t        \"\"\"\n\t        Search through erence clusters and return the one containing the query entity, if it's\n\t        part of a cluster. If we don't find a match, return None.\n\t        \"\"\"\n", "        clusters = self.predicted_clusters if predicted else self.clusters\n\t        for clust in clusters:\n\t            for entry in clust:\n\t                if entry.span == entity.span:\n\t                    return clust\n\t        return None\n\t    @property\n\t    def n_tokens(self):\n\t        return sum([len(sent) for sent in self.sentences])\n\tclass Sentence:\n", "    def __init__(self, entry,\n\t                 sentence_start,\n\t                 sentence_ix):\n\t        self.sentence_start = sentence_start\n\t        self.text = entry[\"sentences\"]\n\t        self.sentence_ix = sentence_ix\n\t        # Gold\n\t        if \"ner_flavor\" in entry:\n\t            self.ner = [NER(this_ner, self.text, sentence_start, flavor=this_flavor)\n\t                        for this_ner, this_flavor in zip(entry[\"ner\"], entry[\"ner_flavor\"])]\n", "        elif \"ner\" in entry:  # default\n\t            self.ner = [NER(this_ner, self.text, sentence_start)\n\t                        for this_ner in entry[\"ner\"]]\n\t        if \"relations\" in entry:\n\t            self.relations = [Relation(this_relation, self.text, sentence_start) for\n\t                              this_relation in entry[\"relations\"]]\n\t        if \"events\" in entry:\n\t            self.events = Events(entry[\"events\"], self.text, sentence_start)\n\t        # Predicted\n\t        if \"predicted_ner\" in entry:\n", "            self.predicted_ner = [NER(this_ner, self.text, sentence_start, flavor=None) for\n\t                                  this_ner in entry[\"predicted_ner\"]]\n\t        if \"predicted_relations\" in entry:\n\t            self.predicted_relations = [Relation(this_relation, self.text, sentence_start) for\n\t                                        this_relation in entry[\"predicted_relations\"]]\n\t        if \"predicted_events\" in entry:\n\t            self.predicted_events = Events(entry[\"predicted_events\"], self.text, sentence_start)\n\t        # Top spans\n\t        if \"top_spans\" in entry:\n\t            self.top_spans = [NER(this_ner, self.text, sentence_start, flavor=None) for\n", "                              this_ner in entry[\"top_spans\"]]\n\t    def __repr__(self):\n\t        the_text = \" \".join(self.text)\n\t        the_lengths = np.array([len(x) for x in self.text])\n\t        tok_ixs = \"\"\n\t        for i, offset in enumerate(the_lengths):\n\t            true_offset = offset if i < 10 else offset - 1\n\t            tok_ixs += str(i)\n\t            tok_ixs += \" \" * true_offset\n\t        return the_text + \"\\n\" + tok_ixs\n", "    def __len__(self):\n\t        return len(self.text)\n\t    def get_flavor(self, argument):\n\t        the_ner = [x for x in self.ner if x.span == argument.span]\n\t        if len(the_ner) > 1:\n\t            print(\"Weird\")\n\t        if the_ner:\n\t            the_flavor = the_ner[0].flavor\n\t        else:\n\t            the_flavor = None\n", "        return the_flavor\n\tclass Span:\n\t    def __init__(self, start, end, text, sentence_start):\n\t        self.start_doc = start\n\t        self.end_doc = end\n\t        self.span_doc = (self.start_doc, self.end_doc)\n\t        # done 是有减去start的\n\t        self.start_sent = start - sentence_start\n\t        self.end_sent = end - sentence_start\n\t        self.span_sent = (self.start_sent, self.end_sent)\n", "        self.text = text[self.start_sent:self.end_sent + 1]\n\t    def __repr__(self):\n\t        return str((self.start_sent, self.end_sent, self.text))\n\t    def __eq__(self, other):\n\t        return (self.span_doc == other.span_doc and\n\t                self.span_sent == other.span_sent and\n\t                self.text == other.text)\n\t    def __hash__(self):\n\t        tup = self.span_doc + self.span_sent + (\" \".join(self.text),)\n\t        return hash(tup)\n", "class Token:\n\t    def __init__(self, ix, text, sentence_start):\n\t        self.ix_doc = ix\n\t        self.ix_sent = ix - sentence_start\n\t        self.text = text[self.ix_sent]\n\t    def __repr__(self):\n\t        return str((self.ix_sent, self.text))\n\tclass Trigger:\n\t    def __init__(self, token, label):\n\t        self.token = token\n", "        self.label = label\n\t    def __repr__(self):\n\t        return self.token.__repr__()[:-1] + \", \" + self.label + \")\"\n\tclass Argument:\n\t    def __init__(self, span, role, event_type):\n\t        self.span = span\n\t        self.role = role\n\t        self.event_type = event_type\n\t    def __repr__(self):\n\t        return self.span.__repr__()[:-1] + \", \" + self.event_type + \", \" + self.role + \")\"\n", "    def __eq__(self, other):\n\t        return (self.span == other.span and\n\t                self.role == other.role and\n\t                self.event_type == other.event_type)\n\t    def __hash__(self):\n\t        return self.span.__hash__() + hash((self.role, self.event_type))\n\tclass NER:\n\t    def __init__(self, ner, text, sentence_start, flavor=None):\n\t        self.span = Span(ner[0], ner[1], text, sentence_start)\n\t        self.label = ner[2]\n", "        self.flavor = flavor\n\t    def __repr__(self):\n\t        return self.span.__repr__() + \": \" + self.label\n\t    def __eq__(self, other):\n\t        return (self.span == other.span and\n\t                self.label == other.label and\n\t                self.flavor == other.flavor)\n\tclass Relation:\n\t    def __init__(self, relation, text, sentence_start):\n\t        start1, end1 = relation[0], relation[1]\n", "        start2, end2 = relation[2], relation[3]\n\t        label = relation[4]\n\t        span1 = Span(start1, end1, text, sentence_start)\n\t        span2 = Span(start2, end2, text, sentence_start)\n\t        self.pair = (span1, span2)\n\t        self.label = label\n\t    def __repr__(self):\n\t        return self.pair[0].__repr__() + \", \" + self.pair[1].__repr__() + \": \" + self.label\n\t    def __eq__(self, other):\n\t        return (self.pair == other.pair) and (self.label == other.label)\n", "class AtomicRelation:\n\t    def __init__(self, ent0, ent1, label):\n\t        self.ent0 = ent0\n\t        self.ent1 = ent1\n\t        self.label = label\n\t    @classmethod\n\t    def from_relation(cls, relation):\n\t        ent0 = \" \".join(relation.pair[0].text)\n\t        ent1 = \" \".join(relation.pair[1].text)\n\t        label = relation.label\n", "        return cls(ent0, ent1, label)\n\t    def __repr__(self):\n\t        return f\"({self.ent0} | {self.ent1} | {self.label})\"\n\tclass Event:\n\t    def __init__(self, event, text, sentence_start):\n\t        trig = event[0]\n\t        args = event[1:]\n\t        trigger_token = Token(trig[0], text, sentence_start)\n\t        self.trigger = Trigger(trigger_token, trig[1])\n\t        self.arguments = []\n", "        for arg in args:\n\t            span = Span(arg[0], arg[1], text, sentence_start)\n\t            self.arguments.append(Argument(span, arg[2], self.trigger.label))\n\t    def __repr__(self):\n\t        res = \"<\"\n\t        res += self.trigger.__repr__() + \":\\n\"\n\t        for arg in self.arguments:\n\t            res += 6 * \" \" + arg.__repr__() + \";\\n\"\n\t        res = res[:-2] + \">\"\n\t        return res\n", "class Events:\n\t    def __init__(self, events_json, text, sentence_start):\n\t        self.event_list = [Event(this_event, text, sentence_start) for this_event in events_json]\n\t        self.triggers = set([event.trigger for event in self.event_list])\n\t        self.arguments = set([arg for event in self.event_list for arg in event.arguments])\n\t    def __len__(self):\n\t        return len(self.event_list)\n\t    def __getitem__(self, i):\n\t        return self.event_list[i]\n\t    def __repr__(self):\n", "        return \"\\n\\n\".join([event.__repr__() for event in self.event_list])\n\t    def span_matches(self, argument):\n\t        return set([candidate for candidate in self.arguments\n\t                    if candidate.span.span_sent == argument.span.span_sent])\n\t    def event_type_matches(self, argument):\n\t        return set([candidate for candidate in self.span_matches(argument)\n\t                    if candidate.event_type == argument.event_type])\n\t    def matches_except_event_type(self, argument):\n\t        matched = [candidate for candidate in self.span_matches(argument)\n\t                   if candidate.event_type != argument.event_type\n", "                   and candidate.role == argument.role]\n\t        return set(matched)\n\t    def exact_match(self, argument):\n\t        for candidate in self.arguments:\n\t            if candidate == argument:\n\t                return True\n\t        return False\n\tclass Cluster:\n\t    def __init__(self, cluster, cluster_id, document):\n\t        members = []\n", "        for entry in cluster:\n\t            sentence_ix = get_sentence_of_span(entry, document.sentence_starts, document.n_tokens)\n\t            sentence = document[sentence_ix]\n\t            span = Span(entry[0], entry[1], sentence.text, sentence.sentence_start)\n\t            ners = [x for x in sentence.ner if x.span == span]\n\t            assert len(ners) <= 1\n\t            ner = ners[0] if len(ners) == 1 else None\n\t            to_append = ClusterMember(span, ner, sentence, cluster_id)\n\t            members.append(to_append)\n\t        self.members = members\n", "        self.cluster_id = cluster_id\n\t    def __repr__(self):\n\t        return f\"{self.cluster_id}: \" + self.members.__repr__()\n\t    def __getitem__(self, ix):\n\t        return self.members[ix]\n\tclass ClusterMember:\n\t    def __init__(self, span, ner, sentence, cluster_id):\n\t        self.span = span\n\t        self.ner = ner\n\t        self.sentence = sentence\n", "        self.cluster_id = cluster_id\n\t    def __repr__(self):\n\t        return f\"<{self.sentence.sentence_ix}> \" + self.span.__repr__()\n\t####################\n\t# Code to do evaluation of predictions for a loaded dataset.\n\tdef safe_div(num, denom):\n\t    if denom > 0:\n\t        return num / denom\n\t    else:\n\t        return 0\n", "def compute_f1(predicted, gold, matched):\n\t    # F1 score.\n\t    precision = safe_div(matched, predicted)\n\t    recall = safe_div(matched, gold)\n\t    f1 = safe_div(2 * precision * recall, precision + recall)\n\t    return dict(precision=precision, recall=recall, f1=f1)\n\tdef evaluate_sent(sent, counts):\n\t    correct_ner = set()\n\t    # Entities.\n\t    counts[\"ner_gold\"] += len(sent.ner)\n", "    counts[\"ner_predicted\"] += len(sent.predicted_ner)\n\t    for prediction in sent.predicted_ner:\n\t        if any([prediction == actual for actual in sent.ner]):\n\t            counts[\"ner_matched\"] += 1\n\t            correct_ner.add(prediction.span)\n\t    # Relations.\n\t    counts[\"relations_gold\"] += len(sent.relations)\n\t    counts[\"relations_predicted\"] += len(sent.predicted_relations)\n\t    for prediction in sent.predicted_relations:\n\t        if any([prediction == actual for actual in sent.relations]):\n", "            counts[\"relations_matched\"] += 1\n\t            if (prediction.pair[0] in correct_ner) and (prediction.pair[1] in correct_ner):\n\t                counts[\"strict_relations_matched\"] += 1\n\t    # Return the updated counts.\n\t    return counts\n\tdef evaluate_predictions(dataset):\n\t    counts = Counter()\n\t    for doc in dataset:\n\t        for sent in doc:\n\t            counts = evaluate_sent(sent, counts)\n", "    scores_ner = compute_f1(\n\t        counts[\"ner_predicted\"], counts[\"ner_gold\"], counts[\"ner_matched\"])\n\t    scores_relations = compute_f1(\n\t        counts[\"relations_predicted\"], counts[\"relations_gold\"], counts[\"relations_matched\"])\n\t    scores_strict_relations = compute_f1(\n\t        counts[\"relations_predicted\"], counts[\"relations_gold\"], counts[\"strict_relations_matched\"])\n\t    return dict(ner=scores_ner, relation=scores_relations, strict_relation=scores_strict_relations)\n\tdef analyze_relation_coverage(dataset):\n\t    def overlap(s1, s2):\n\t        if s2.start_sent >= s1.start_sent and s2.start_sent <= s1.end_sent:\n", "            return True\n\t        if s2.end_sent >= s1.start_sent and s2.end_sent <= s1.end_sent:\n\t            return True\n\t        return False\n\t    nrel_gold = 0\n\t    nrel_pred_cover = 0\n\t    nrel_top_cover = 0\n\t    npair_pred = 0\n\t    npair_top = 0\n\t    nrel_overlap = 0\n", "    for d in dataset:\n\t        for s in d:\n\t            pred = set([ner.span for ner in s.predicted_ner])\n\t            top = set([ner.span for ner in s.top_spans])\n\t            npair_pred += len(s.predicted_ner) * (len(s.predicted_ner) - 1)\n\t            npair_top += len(s.top_spans) * (len(s.top_spans) - 1)\n\t            for r in s.relations:\n\t                nrel_gold += 1\n\t                if (r.pair[0] in pred) and (r.pair[1] in pred):\n\t                    nrel_pred_cover += 1\n", "                if (r.pair[0] in top) and (r.pair[1] in top):\n\t                    nrel_top_cover += 1\n\t                if overlap(r.pair[0], r.pair[1]):\n\t                    nrel_overlap += 1\n\t    print('Coverage by predicted entities: %.3f (%d / %d), #candidates: %d' % (\n\t        nrel_pred_cover / nrel_gold * 100.0, nrel_pred_cover, nrel_gold, npair_pred))\n\t    print('Coverage by top 0.4 spans: %.3f (%d / %d), #candidates: %d' % (\n\t        nrel_top_cover / nrel_gold * 100.0, nrel_top_cover, nrel_gold, npair_top))\n\t    print('Overlap: %.3f (%d / %d)' % (nrel_overlap / nrel_gold * 100.0, nrel_overlap, nrel_gold))\n"]}
{"filename": "src/Entity/shared/get_hparams.py", "chunked_list": ["import argparse\n\tdef get_hparams_entity():\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument('--task', type=str, default='ACE')\n\t    parser.add_argument('--data_dir', type=str,\n\t                        default='../ace2005/',\n\t                        help=\"path to the preprocessed dataset\")\n\t    parser.add_argument('--output_dir', type=str, default='entity_output_ace',\n\t                        help=\"output directory of the entity model\")\n\t    parser.add_argument('--max_span_length', type=int, default=8,\n", "                        help=\"spans w/ length up to max_span_length are considered as candidates\")\n\t    parser.add_argument('--train_batch_size', type=int, default=8,\n\t                        help=\"batch size during training\")\n\t    parser.add_argument('--eval_batch_size', type=int, default=8,\n\t                        help=\"batch size during inference\")\n\t    parser.add_argument('--learning_rate', type=float, default=1e-5,\n\t                        help=\"learning rate for the BERT encoder\")\n\t    parser.add_argument('--task_learning_rate', type=float, default=5e-4,\n\t                        help=\"learning rate for task-specific parameters, i.e., classification head\")\n\t    parser.add_argument('--warmup_proportion', type=float, default=0.1,\n", "                        help=\"the ratio of the warmup steps to the total steps\")\n\t    parser.add_argument('--num_epoch', type=int, default=100,\n\t                        help=\"number of the training epochs\")\n\t    parser.add_argument('--print_loss_step', type=int, default=100,\n\t                        help=\"how often logging the loss value during training\")\n\t    parser.add_argument('--eval_per_epoch', type=int, default=1,\n\t                        help=\"how often evaluating the trained model on dev set during training\")\n\t    parser.add_argument(\"--bertadam\", action=\"store_true\", help=\"If bertadam, then set correct_bias = False\")\n\t    parser.add_argument('--do_train', action='store_false', default=True,\n\t                        help=\"whether to run training\")\n", "    parser.add_argument('--train_shuffle', action='store_false', default=True,\n\t                        help=\"whether to train with randomly shuffled data\")\n\t    parser.add_argument('--do_eval', action='store_false', default=True,\n\t                        help=\"whether to run evaluation\")\n\t    parser.add_argument('--eval_test', action='store_true', default=False,\n\t                        help=\"whether to evaluate on test set\")\n\t    parser.add_argument('--dev_pred_filename', type=str, default=\"ent_pred_dev.json\",\n\t                        help=\"the prediction filename for the dev set\")\n\t    parser.add_argument('--test_pred_filename', type=str, default=\"ent_pred_test.json\",\n\t                        help=\"the prediction filename for the test set\")\n", "    parser.add_argument('--use_albert', action='store_true',\n\t                        help=\"whether to use ALBERT model\")\n\t    parser.add_argument('--model', type=str, default='bert-base-uncased',\n\t                        help=\"the base model name (a huggingface model)\")\n\t    parser.add_argument('--bert_model_dir', type=str, default=None,\n\t                        help=\"the base model directory\")\n\t    parser.add_argument('--seed', type=int, default=42)\n\t    parser.add_argument('--context_window', type=int, default=300,\n\t                        help=\"the context window size W for the entity model\")\n\t    args = parser.parse_args()\n", "    return args\n"]}
{"filename": "src/Entity/shared/utils.py", "chunked_list": ["max_length = 400\n\tdef get_pre_dict(sentence_e_mentions,  # 一个句子，包含了多个event\n\t                 sentence_before_len,\n\t                 context,\n\t                 words,\n\t                 data_new,\n\t                 sent_entity_mentions,\n\t                 entity_id_num_none=0, entity_id_num=0):\n\t    \"\"\"\n\t    sent_entity_mentions:  todo entity是可以跨句的？\n", "    \"\"\"\n\t    # label triggers and arguments\n\t    golden_event_mentions = []\n\t    for event in sentence_e_mentions:\n\t        trigger = {\"start\": event['trigger']['start'] - sentence_before_len,\n\t                   \"end\": event['trigger']['end'] - sentence_before_len,\n\t                   \"text\": event['trigger']['text']}\n\t        if trigger['start'] > max_length or trigger['end'] < 0:\n\t            continue\n\t        arguments = event['arguments']\n", "        args_list = []\n\t        for arg in arguments:\n\t            entity_id = arg['entity_id']\n\t            span = []\n\t            for entity in sent_entity_mentions:\n\t                if entity['id'] == entity_id:\n\t                    span = [entity['start'] - sentence_before_len, entity['end'] - sentence_before_len]\n\t                    break\n\t            if span:\n\t                args_dict = {\n", "                    \"role\": arg['role'],\n\t                    \"text\": arg['text'],\n\t                    \"start\": span[0],\n\t                    \"end\": span[1],\n\t                    # 'span': span\n\t                }\n\t                args_list.append(args_dict)\n\t        golden_event_mentions.append({\n\t            'trigger': trigger,\n\t            'arguments': args_list,\n", "            'event_type': event['event_type']\n\t        })\n\t    entity_mentions = []\n\t    for entity in sent_entity_mentions:\n\t        enti = {'entity_type': entity['entity_type'],\n\t                'start': entity['start'] - sentence_before_len,\n\t                'end': entity['end'] - sentence_before_len}\n\t        if enti['start'] > max_length or enti['end'] < 0:\n\t            continue\n\t        entity_mentions.append(enti)\n", "    data_dict = {\n\t        'sentence': context,\n\t        'words': words,\n\t        'golden_event_mentions': golden_event_mentions,\n\t        'golden_entity_mentions': entity_mentions\n\t    }\n\t    data_new.append(data_dict)\n\t    return entity_id_num_none, entity_id_num\n"]}
{"filename": "src/Entity/shared/const.py", "chunked_list": ["task_ner_labels = {\n\t    'ace04': ['FAC', 'WEA', 'LOC', 'VEH', 'GPE', 'ORG', 'PER'],\n\t    'ace05': ['FAC', 'WEA', 'LOC', 'VEH', 'GPE', 'ORG', 'PER'],\n\t    'scierc': ['Method', 'OtherScientificTerm', 'Task', 'Generic', 'Material', 'Metric'],\n\t    'WikiEvents': [\"TTL\", \"INF\", \"VAL\", \"LOC\", \"COM\", \"CRM\", \"ORG\", \"FAC\", \"MHI\", \"WEA\", \"VEH\", \"SID\", \"ABS\", \"MON\",\n\t                   \"GPE\", \"BOD\", \"PER\"],\n\t    'ACE': ['VEH:Water',\n\t            'GPE:Nation',\n\t            'ORG:Commercial',\n\t            'GPE:State-or-Province',\n", "            'Contact-Info:E-Mail',\n\t            'Crime',\n\t            'ORG:Non-Governmental',\n\t            'Contact-Info:URL',\n\t            'Sentence',\n\t            'ORG:Religious',\n\t            'VEH:Underspecified',\n\t            'WEA:Projectile',\n\t            'FAC:Building-Grounds',\n\t            'PER:Group',\n", "            'WEA:Exploding',\n\t            'WEA:Biological',\n\t            'Contact-Info:Phone-Number',\n\t            'WEA:Chemical',\n\t            'LOC:Land-Region-Natural',\n\t            'WEA:Nuclear',\n\t            'LOC:Region-General',\n\t            'PER:Individual',\n\t            'WEA:Sharp',\n\t            'ORG:Sports',\n", "            'ORG:Government',\n\t            'ORG:Media',\n\t            'LOC:Address',\n\t            'WEA:Shooting',\n\t            'LOC:Water-Body',\n\t            'LOC:Boundary',\n\t            'GPE:Population-Center',\n\t            'GPE:Special',\n\t            'LOC:Celestial',\n\t            'FAC:Subarea-Facility',\n", "            'PER:Indeterminate',\n\t            'VEH:Subarea-Vehicle',\n\t            'WEA:Blunt',\n\t            'VEH:Land',\n\t            'TIM:time',\n\t            'Numeric:Money',\n\t            'FAC:Airport',\n\t            'GPE:GPE-Cluster',\n\t            'ORG:Educational',\n\t            'Job-Title',\n", "            'GPE:County-or-District',\n\t            'ORG:Entertainment',\n\t            'Numeric:Percent',\n\t            'LOC:Region-International',\n\t            'WEA:Underspecified',\n\t            'VEH:Air',\n\t            'FAC:Path',\n\t            'ORG:Medical-Science',\n\t            'FAC:Plant',\n\t            'GPE:Continent']\n", "}\n\tdef get_labelmap(label_list):\n\t    label2id = {}\n\t    id2label = {}\n\t    for i, label in enumerate(label_list):\n\t        label2id[label] = i + 1\n\t        id2label[i + 1] = label\n\t    return label2id, id2label\n"]}
