{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages, Extension\n\tVERSION = '0.8.5'\n\tDESCRIPTION = 'Boolean Hypervectors'\n\tLONG_DESCRIPTION = 'Boolean Hypervectors with various operators for experiments in hyperdimensional computing (HDC).'\n\tnative = Extension(\"bhv.cnative\",\n\t                   sources=['bhv/cnative/bindings.cpp',\n\t                            'bhv/cnative/TurboSHAKE_opt/TurboSHAKE.cpp',\n\t                            'bhv/cnative/TurboSHAKE_opt/KeccakP-1600-opt64.cpp',\n\t                            'bhv/cnative/TurboSHAKE_AVX512/TurboSHAKE.cpp',\n\t                            'bhv/cnative/TurboSHAKE_AVX512/KeccakP-1600-AVX512.cpp',\n", "                            ],\n\t                   include_dirs=['bhv/cnative', 'bhv/cnative/TurboSHAKEopt'],\n\t                   extra_compile_args=['-std=c++2a', '-O3', '-march=native', '-Wall'],\n\t                   language='c++',\n\t                   optional=True)\n\tsetup(\n\t    name=\"bhv\",\n\t    version=VERSION,\n\t    author=\"Adam Vandervorst\",\n\t    author_email=\"contact@adamv.be\",\n", "    description=DESCRIPTION,\n\t    long_description=LONG_DESCRIPTION,\n\t    url=\"https://github.com/Adam-Vandervorst/PyBHV\",\n\t    packages=find_packages(),\n\t    install_requires=[],\n\t    extras_require={\n\t        \"pytorch\": [\"torch>=2.0.0\"],\n\t        \"np\": [\"numpy>=1.24.2\"],\n\t    },\n\t    keywords='ai binary hypervector hdc bsc',\n", "    python_requires='>=3.8',\n\t    classifiers=[\n\t        'Development Status :: 2 - Pre-Alpha',\n\t        'Intended Audience :: Developers',\n\t        'Intended Audience :: Science/Research',\n\t        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n\t        'Topic :: Software Development :: Libraries',\n\t        'License :: Free for non-commercial use',\n\t        'Environment :: GPU :: NVIDIA CUDA',\n\t        'Operating System :: POSIX :: Linux',\n", "        'Programming Language :: Python :: 3.8',\n\t        'Programming Language :: Python :: 3.9',\n\t        'Programming Language :: Python :: 3.10',\n\t        'Programming Language :: Python :: 3.11',\n\t        'Typing :: Typed',\n\t    ],\n\t    ext_modules=[native]\n\t)\n"]}
{"filename": "bhv/pytorch.py", "chunked_list": ["from .abstract import *\n\timport torch\n\t# GPT-4 wrote this code, do not use in production\n\tdef pack_bool_to_long(bool_tensor):\n\t    assert bool_tensor.dtype == torch.bool, \"Input tensor must be of dtype torch.bool\"\n\t    assert bool_tensor.numel() % 64 == 0, \"Input tensor must have a number of elements divisible by 64\"\n\t    bool_tensor = bool_tensor.view(-1, 64)\n\t    packed_tensor = torch.zeros(bool_tensor.shape[0], dtype=torch.int64)\n\t    for i in range(64):\n\t        packed_tensor |= (bool_tensor[:, i].to(torch.int64) << i)\n", "    return packed_tensor\n\t# GPT-4 wrote this code, do not use in production\n\tdef unpack_long_to_bool(packed_tensor):\n\t    assert packed_tensor.dtype == torch.int64, \"Input tensor must be of dtype torch.int64\"\n\t    bool_tensor = torch.zeros(packed_tensor.numel() * 64, dtype=torch.bool)\n\t    for i in range(64):\n\t        bool_tensor[i::64] = ((packed_tensor >> i) & 1).bool()\n\t    return bool_tensor\n\tclass TorchBoolPermutation(MemoizedPermutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n", "    def __init__(self, tensor: torch.IntTensor):\n\t        self.data: torch.BoolTensor = tensor\n\t    @classmethod\n\t    def random(cls) -> 'TorchBoolPermutation':\n\t        return TorchBoolPermutation(torch.randperm(DIMENSION))\n\t    def __mul__(self, other: 'TorchBoolPermutation') -> 'TorchBoolPermutation':\n\t        return TorchBoolPermutation(self.data[other.data])\n\t    def __invert__(self) -> 'TorchBoolPermutation':\n\t        inv_permutation = torch.empty_like(self.data)\n\t        inv_permutation[self.data] = torch.arange(DIMENSION)\n", "        return TorchBoolPermutation(inv_permutation)\n\t    def __call__(self, hv: 'TorchBoolBHV') -> 'TorchBoolBHV':\n\t        return hv.permute_bits(self)\n\tTorchBoolPermutation.IDENTITY = TorchBoolPermutation(torch.arange(DIMENSION))\n\tclass TorchBoolBHV(AbstractBHV):\n\t    def __init__(self, tensor: torch.BoolTensor):\n\t        self.data: torch.BoolTensor = tensor\n\t    @classmethod\n\t    def rand(cls) -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(torch.empty(DIMENSION, dtype=torch.bool).random_())\n", "    @classmethod\n\t    def random(cls, active: float) -> 'TorchBoolBHV':\n\t        assert 0. <= active <= 1.\n\t        return TorchBoolBHV(torch.empty(DIMENSION, dtype=torch.bool).bernoulli_(active))\n\t    def select(self, when1: 'TorchBoolBHV', when0: 'TorchBoolBHV') -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(torch.where(self.data, when1.data, when0.data))\n\t    @classmethod\n\t    def majority(cls, vs: list['TorchBoolBHV']) -> 'TorchBoolBHV':\n\t        data = [v.data for v in vs]\n\t        extra = [cls.rand().data] if len(vs) % 2 == 0 else []\n", "        tensor = torch.stack(data + extra)\n\t        counts = tensor.sum(dim=-2, dtype=torch.uint8 if len(vs) < 256 else torch.int32)\n\t        threshold = (len(vs) + len(extra))//2\n\t        return TorchBoolBHV(torch.greater(counts,  threshold).to(torch.bool))\n\t    def roll_bits(self, n: int) -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(torch.roll(self.data, n))\n\t    def permute_bits(self, permutation: TorchBoolPermutation) -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(self.data[permutation.data])\n\t    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'TorchBoolBHV':\n\t        return self.permute_bits(TorchBoolPermutation.get(permutation_id))\n", "    def swap_halves(self) -> 'TorchBoolBHV':\n\t        return self.roll_bits(DIMENSION//2)\n\t    def rehash(self) -> 'TorchBoolBHV':\n\t        # torch to bytes is broken hence custom function https://github.com/pytorch/pytorch/issues/33041\n\t        offsets = [(H & self).active() for H in self._HS]\n\t        res = self._HASH\n\t        for o in offsets:\n\t            res = res ^ self.roll_bits(o)\n\t        return res\n\t    def __eq__(self, other: 'TorchBoolBHV') -> bool:\n", "        return torch.equal(self.data, other.data)\n\t    def __xor__(self, other: 'TorchBoolBHV') -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(torch.bitwise_xor(self.data, other.data))\n\t    def __and__(self, other: 'TorchBoolBHV') -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(torch.bitwise_and(self.data, other.data))\n\t    def __or__(self, other: 'TorchBoolBHV') -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(torch.bitwise_or(self.data, other.data))\n\t    def __invert__(self) -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(torch.bitwise_not(self.data))\n\t    def active(self) -> int:\n", "        return torch.sum(self.data).item()\n\t    def pack(self) -> 'TorchPackedBHV':\n\t        return TorchPackedBHV(pack_bool_to_long(self.data))\n\tTorchBoolBHV.ZERO = TorchBoolBHV(torch.zeros(DIMENSION, dtype=torch.bool))\n\tTorchBoolBHV.ONE = TorchBoolBHV(torch.ones(DIMENSION, dtype=torch.bool))\n\tTorchBoolBHV._HASH = TorchBoolBHV.rand()\n\tTorchBoolBHV._HS = TorchBoolBHV.nrand2(5, power=2)\n\tTorchBoolBHV._FEISTAL_SUBKEYS = TorchBoolBHV.nrand2(TorchBoolBHV._FEISTAL_ROUNDS, 4)\n\t_halfb = torch.zeros(DIMENSION, dtype=torch.bool)\n\t_halfb[:DIMENSION//2] = 1\n", "TorchBoolBHV.HALF = TorchBoolBHV(_halfb)\n\tclass TorchWordPermutation(MemoizedPermutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\t    def __init__(self, tensor: torch.IntTensor):\n\t        self.data: torch.BoolTensor = tensor\n\t    @classmethod\n\t    def random(cls) -> 'TorchWordPermutation':\n\t        return TorchWordPermutation(torch.randperm(DIMENSION//64))\n\t    def __mul__(self, other: 'TorchWordPermutation') -> 'TorchWordPermutation':\n\t        return TorchWordPermutation(self.data[other.data])\n", "    def __invert__(self) -> 'TorchWordPermutation':\n\t        inv_permutation = torch.empty_like(self.data)\n\t        inv_permutation[self.data] = torch.arange(DIMENSION//64)\n\t        return TorchWordPermutation(inv_permutation)\n\t    def __call__(self, hv: 'TorchPackedBHV') -> 'TorchPackedBHV':\n\t        return hv.permute_words(self)\n\tTorchWordPermutation.IDENTITY = TorchWordPermutation(torch.arange(DIMENSION//64))\n\tclass TorchPackedBHV(AbstractBHV):\n\t    def __init__(self, tensor: torch.LongTensor):\n\t        assert DIMENSION % 64 == 0\n", "        self.data: torch.LongTensor = tensor\n\t    @classmethod\n\t    def rand(cls) -> Self:\n\t        return TorchPackedBHV(torch.randint(-9223372036854775808, 9223372036854775807, size=(DIMENSION//64,), dtype=torch.long))\n\t    @classmethod\n\t    def random(cls, active) -> Self:\n\t        assert 0. <= active <= 1.\n\t        return TorchBoolBHV.random(active).pack()\n\t    def roll_words(self, n: int) -> 'TorchPackedBHV':\n\t        return TorchPackedBHV(torch.roll(self.data, n))\n", "    def permute_words(self, permutation: TorchWordPermutation) -> 'TorchPackedBHV':\n\t        return TorchPackedBHV(self.data[permutation.data])\n\t    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'TorchPackedBHV':\n\t        return self.permute_words(TorchWordPermutation.get(permutation_id))\n\t    def swap_halves(self) -> 'TorchPackedBHV':\n\t        return self.roll_words(DIMENSION//128)\n\t    def rehash(self) -> 'TorchPackedBHV':\n\t        return self.unpack().rehash().pack()\n\t    def __eq__(self, other: 'TorchBoolBHV') -> bool:\n\t        return torch.equal(self.data, other.data)\n", "    def __xor__(self, other: 'TorchPackedBHV') -> 'TorchPackedBHV':\n\t        return TorchPackedBHV(torch.bitwise_xor(self.data, other.data))\n\t    def __and__(self, other: 'TorchPackedBHV') -> 'TorchPackedBHV':\n\t        return TorchPackedBHV(torch.bitwise_and(self.data, other.data))\n\t    def __or__(self, other: 'TorchPackedBHV') -> 'TorchPackedBHV':\n\t        return TorchPackedBHV(torch.bitwise_or(self.data, other.data))\n\t    def __invert__(self) -> 'TorchPackedBHV':\n\t        return TorchPackedBHV(torch.bitwise_not(self.data))\n\t    def active(self) -> int:\n\t        # currently no efficient implementation available for this https://github.com/pytorch/pytorch/issues/36380\n", "        x = self.data\n\t        x = x - ((x >> 1) & 0x5555555555555555)\n\t        x = (x & 0x3333333333333333) + ((x >> 2) & 0x3333333333333333)\n\t        x = (x + (x >> 4)) & 0x0f0f0f0f0f0f0f0f\n\t        x = (x * 0x0101010101010101) >> 56\n\t        return torch.sum(x).item()\n\t    def unpack(self) -> 'TorchBoolBHV':\n\t        return TorchBoolBHV(unpack_long_to_bool(self.data))\n\tTorchPackedBHV.ZERO = TorchPackedBHV(torch.zeros(DIMENSION//64, dtype=torch.long))\n\tTorchPackedBHV.ONE = TorchPackedBHV(torch.full((DIMENSION//64,), fill_value=-1, dtype=torch.long))  # -1 is all ones in torch's encoding\n", "TorchPackedBHV._FEISTAL_SUBKEYS = TorchPackedBHV.nrand2(TorchPackedBHV._FEISTAL_ROUNDS, 4)\n\t_half64 = torch.zeros(DIMENSION//64, dtype=torch.long)\n\t_half64[:DIMENSION//128] = -1\n\tTorchPackedBHV.HALF = TorchPackedBHV(_half64)\n"]}
{"filename": "bhv/np.py", "chunked_list": ["from .abstract import *\n\timport numpy as np\n\tfrom sys import byteorder, version_info\n\tclass NumPyBoolPermutation(MemoizedPermutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\t    rng = np.random.default_rng()\n\t    def __init__(self, array: np.ndarray):\n\t        self.data: np.ndarray = array\n\t    @classmethod\n\t    def random(cls) -> 'NumPyBoolPermutation':\n", "        return NumPyBoolPermutation(cls.rng.permutation(DIMENSION))\n\t    def __mul__(self, other: 'NumPyBoolPermutation') -> 'NumPyBoolPermutation':\n\t        return NumPyBoolPermutation(self.data[other.data])\n\t    def __invert__(self) -> 'NumPyBoolPermutation':\n\t        inv_permutation = np.empty_like(self.data)\n\t        inv_permutation[self.data] = np.arange(DIMENSION)\n\t        return NumPyBoolPermutation(inv_permutation)\n\t    def __call__(self, hv: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n\t        return hv.permute_bits(self)\n\tNumPyBoolPermutation.IDENTITY = NumPyBoolPermutation(np.arange(DIMENSION))\n", "class NumPyBoolBHV(AbstractBHV):\n\t    def __init__(self, array: np.ndarray):\n\t        self.data: np.ndarray = array\n\t    @classmethod\n\t    def rand(cls) -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.random.randint(0, high=2, size=DIMENSION, dtype=np.bool_))\n\t    @classmethod\n\t    def random(cls, active: float) -> 'NumPyBoolBHV':\n\t        assert 0. <= active <= 1.\n\t        return NumPyBoolBHV(np.random.binomial(1, active, DIMENSION))\n", "    def select(self, when1: 'NumPyBoolBHV', when0: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.where(self.data, when1.data, when0.data))\n\t    def swap_halves(self) -> 'NumPyBoolBHV':\n\t        return self.roll_bits(DIMENSION//2)\n\t    def rehash(self) -> 'NumPyBoolBHV':\n\t        return self.pack8().rehash().unpack()\n\t    def roll_bits(self, n: int) -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.roll(self.data, n))\n\t    def permute_bits(self, permutation: 'NumPyBoolPermutation') -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(self.data[permutation.data])\n", "    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'NumPyBoolBHV':\n\t        return self.permute_bits(NumPyBoolPermutation.get(permutation_id))\n\t    @classmethod\n\t    def majority(cls, vs: list['NumPyBoolBHV']) -> 'NumPyBoolBHV':\n\t        data = [v.data for v in vs]\n\t        extra = [cls.rand().data] if len(vs) % 2 == 0 else []\n\t        tensor = np.stack(data + extra)\n\t        counts = tensor.sum(axis=-2, dtype=np.uint8 if len(vs) < 256 else np.uint32)\n\t        threshold = (len(vs) + len(extra))//2\n\t        return NumPyBoolBHV(np.greater(counts, threshold))\n", "    def __eq__(self, other: 'NumPyBoolBHV') -> bool:\n\t        return np.array_equal(self.data, other.data)\n\t    def __xor__(self, other: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.bitwise_xor(self.data, other.data))\n\t    def __and__(self, other: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.bitwise_and(self.data, other.data))\n\t    def __or__(self, other: 'NumPyBoolBHV') -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.bitwise_or(self.data, other.data))\n\t    def __invert__(self) -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.bitwise_not(self.data))\n", "    def active(self) -> int:\n\t        return int(np.sum(self.data))\n\t    def pack8(self) -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(np.packbits(self.data))\n\t    def pack64(self) -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(np.packbits(self.data).view(dtype=np.uint64))\n\t    def to_bytes(self):\n\t        return self.pack8().to_bytes()\n\t    @classmethod\n\t    def from_bytes(cls, bs):\n", "        return NumPyPacked8BHV.from_bytes(bs).unpack()\n\t    def bits(self):\n\t        return iter(self.data.astype(np.uint8))\n\t    def bitstring(self) -> str:\n\t        b = ord('0')\n\t        return (self.data.astype(np.uint8) + b).tobytes().decode('ascii')\n\t    @classmethod\n\t    def from_bitstring(cls, s: str) -> str:\n\t        b = ord('0')\n\t        return cls((np.frombuffer(bytes(s, 'ascii'), dtype=np.uint8) - b).astype(np.bool_))\n", "NumPyBoolBHV.ZERO = NumPyBoolBHV(np.zeros(DIMENSION, dtype=np.bool_))\n\tNumPyBoolBHV.ONE = NumPyBoolBHV(np.ones(DIMENSION, dtype=np.bool_))\n\tNumPyBoolBHV._FEISTAL_SUBKEYS = NumPyBoolBHV.nrand2(NumPyBoolBHV._FEISTAL_ROUNDS, 4)\n\t_halfb = np.zeros(DIMENSION, dtype=np.bool_)\n\t_halfb[:DIMENSION//2] = np.bool_(True)\n\tNumPyBoolBHV.HALF = NumPyBoolBHV(_halfb)\n\tclass NumPyBytePermutation(MemoizedPermutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\t    rng = np.random.default_rng()\n\t    def __init__(self, array: np.ndarray):\n", "        self.data: np.ndarray = array\n\t    @classmethod\n\t    def random(cls) -> 'NumPyBytePermutation':\n\t        return NumPyBytePermutation(cls.rng.permutation(DIMENSION//8))\n\t    def __mul__(self, other: 'NumPyBytePermutation') -> 'NumPyBytePermutation':\n\t        return NumPyBytePermutation(self.data[other.data])\n\t    def __invert__(self) -> 'NumPyBytePermutation':\n\t        inv_permutation = np.empty_like(self.data)\n\t        inv_permutation[self.data] = np.arange(DIMENSION//8)\n\t        return NumPyBytePermutation(inv_permutation)\n", "    def __call__(self, hv: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n\t        return hv.permute_bytes(self)\n\tNumPyBytePermutation.IDENTITY = NumPyBytePermutation(np.arange(DIMENSION//8))\n\tclass NumPyPacked8BHV(AbstractBHV):\n\t    def __init__(self, array: np.ndarray):\n\t        self.data: np.ndarray = array\n\t    @classmethod\n\t    def rand(cls) -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(np.random.randint(0, 255, DIMENSION//8, dtype=np.uint8))\n\t    @classmethod\n", "    def random(cls, active: float) -> 'NumPyPacked8BHV':\n\t        assert 0. <= active <= 1.\n\t        return NumPyBoolBHV.random(active).pack8()\n\t    def roll_bytes(self, n: int) -> 'NumPyPacked8BHV':\n\t        assert abs(n) < DIMENSION//8, \"only supports DIMENSION/8 rolls\"\n\t        return NumPyPacked8BHV(np.roll(self.data, n))\n\t    def swap_halves(self) -> 'NumPyPacked8BHV':\n\t        return self.roll_bytes(DIMENSION//16)\n\t    def permute_bytes(self, permutation: 'NumPyBytePermutation') -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(self.data[permutation.data])\n", "    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'NumPyPacked8BHV':\n\t        return self.permute_bytes(NumPyBytePermutation.get(permutation_id))\n\t    def rehash(self) -> 'NumPyPacked8BHV':\n\t        byte_data = self.to_bytes()\n\t        rehashed_byte_data = hashlib.shake_256(byte_data).digest(DIMENSION//8)\n\t        return NumPyPacked8BHV.from_bytes(rehashed_byte_data)\n\t    def __eq__(self, other: 'NumPyPacked8BHV') -> bool:\n\t        return np.array_equal(self.data, other.data)\n\t    def __xor__(self, other: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(np.bitwise_xor(self.data, other.data))\n", "    def __and__(self, other: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(np.bitwise_and(self.data, other.data))\n\t    def __or__(self, other: 'NumPyPacked8BHV') -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(np.bitwise_or(self.data, other.data))\n\t    def __invert__(self) -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(np.bitwise_not(self.data))\n\t    if version_info[2] >= 10:\n\t        def active(self) -> int:\n\t            return int.from_bytes(self.data.tobytes(), byteorder).bit_count()\n\t    else:\n", "        lookup = np.array([bin(i).count(\"1\") for i in range(256)])\n\t        def active(self) -> int:\n\t            return self.lookup[self.data].sum()\n\t    def unpack(self) -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.unpackbits(self.data))\n\t    def repack64(self) -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(self.data.view(dtype=np.uint64))\n\t    def to_bytes(self):\n\t        return self.data.tobytes()\n\t    @classmethod\n", "    def from_bytes(cls, bs):\n\t        return cls(np.frombuffer(bs, dtype=np.uint8))\n\tNumPyPacked8BHV.ZERO = NumPyPacked8BHV(np.zeros(DIMENSION//8, dtype=np.uint8))\n\tNumPyPacked8BHV.ONE = NumPyPacked8BHV(np.full(DIMENSION//8, fill_value=255, dtype=np.uint8))\n\tNumPyPacked8BHV._FEISTAL_SUBKEYS = NumPyPacked8BHV.nrand2(NumPyPacked8BHV._FEISTAL_ROUNDS, 4)\n\t_half8 = np.zeros(DIMENSION//8, dtype=np.uint8)\n\t_half8[:DIMENSION//16] = np.uint8(255)\n\tNumPyPacked8BHV.HALF = NumPyPacked8BHV(_half8)\n\tclass NumPyWordPermutation(MemoizedPermutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n", "    rng = np.random.default_rng()\n\t    def __init__(self, array: np.ndarray):\n\t        self.data: np.ndarray = array\n\t    @classmethod\n\t    def random(cls) -> 'NumPyWordPermutation':\n\t        return NumPyWordPermutation(cls.rng.permutation(DIMENSION//64))\n\t    def __mul__(self, other: 'NumPyWordPermutation') -> 'NumPyWordPermutation':\n\t        return NumPyWordPermutation(self.data[other.data])\n\t    def __invert__(self) -> 'NumPyWordPermutation':\n\t        inv_permutation = np.empty_like(self.data)\n", "        inv_permutation[self.data] = np.arange(DIMENSION//64)\n\t        return NumPyWordPermutation(inv_permutation)\n\t    def __call__(self, hv: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n\t        return hv.permute_words(self)\n\tNumPyWordPermutation.IDENTITY = NumPyWordPermutation(np.arange(DIMENSION//64))\n\tclass NumPyPacked64BHV(AbstractBHV):\n\t    rng = np.random.SFC64()\n\t    def __init__(self, array: np.ndarray):\n\t        self.data: np.ndarray = array\n\t    @classmethod\n", "    def rand(cls) -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(cls.rng.random_raw(DIMENSION//64))\n\t    @classmethod\n\t    def random(cls, active: float) -> 'NumPyPacked64BHV':\n\t        assert 0. <= active <= 1.\n\t        return NumPyBoolBHV.random(active).pack64()\n\t    @classmethod\n\t    def majority(cls, vs: list['NumPyPacked64BHV']) -> 'NumPyPacked64BHV':\n\t        if len(vs) <= 9:\n\t            return cls._majority_via_custom(vs)\n", "        else:\n\t            return cls._majority_via_unpacked(vs)\n\t    @classmethod\n\t    def _majority_via_unpacked(cls, vs: list['NumPyPacked64BHV']) -> 'NumPyPacked64BHV':\n\t        return NumPyBoolBHV.majority([v.unpack() for v in vs]).pack64()\n\t    def swap_halves(self) -> 'NumPyPacked64BHV':\n\t        return self.roll_words(DIMENSION//128)\n\t    def rehash(self) -> 'NumPyPacked64BHV':\n\t        return self.repack8().rehash().repack64()\n\t    def roll_words(self, n: int) -> 'NumPyPacked64BHV':\n", "        assert abs(n) < DIMENSION//64, \"only supports DIMENSION/64 rolls\"\n\t        return NumPyPacked64BHV(np.roll(self.data, n))\n\t    def roll_word_bits(self, n: int) -> 'NumPyPacked64BHV':\n\t        assert abs(n) < 64, \"only supports 64 rolls\"\n\t        # https://github.com/numba/numba/issues/6381\n\t        if n == 0:\n\t            return NumPyPacked64BHV(self.data)\n\t        elif n > 0:\n\t            return NumPyPacked64BHV(np.bitwise_or(np.right_shift(self.data, np.uint64(n)), np.left_shift(self.data, np.uint64(64 - n))))\n\t        else:\n", "            return NumPyPacked64BHV(np.bitwise_or(np.left_shift(self.data, np.uint64(n)), np.right_shift(self.data, np.uint64(64 - n))))\n\t    # roll_words and roll_word_bits could be combined for more options allowing positive and negative combinations\n\t    # ((1 2 3 4) (a b c d) (α β γ δ))\n\t    # rolled by 1, -2 for example results in\n\t    # ((γ δ α β) (3 4 1 2) (c d a b))\n\t    def permute_words(self, permutation: 'NumPyWordPermutation') -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(self.data[permutation.data])\n\t    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'NumPyPacked64BHV':\n\t        return self.permute_words(NumPyWordPermutation.get(permutation_id))\n\t    def __eq__(self, other: 'NumPyPacked64BHV') -> bool:\n", "        return np.array_equal(self.data, other.data)\n\t    def __xor__(self, other: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(np.bitwise_xor(self.data, other.data))\n\t    def __and__(self, other: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(np.bitwise_and(self.data, other.data))\n\t    def __or__(self, other: 'NumPyPacked64BHV') -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(np.bitwise_or(self.data, other.data))\n\t    def __invert__(self) -> 'NumPyPacked64BHV':\n\t        return NumPyPacked64BHV(np.bitwise_not(self.data))\n\t    if version_info[2] >= 10:\n", "        def active(self) -> int:\n\t            return int.from_bytes(self.data.tobytes(), byteorder).bit_count()\n\t    else:\n\t        def active(self) -> int:\n\t            return self.repack8().active()\n\t    def unpack(self) -> 'NumPyBoolBHV':\n\t        return NumPyBoolBHV(np.unpackbits(self.data.view(np.uint8)))\n\t    def repack8(self) -> 'NumPyPacked8BHV':\n\t        return NumPyPacked8BHV(self.data.view(dtype=np.uint8))\n\t    def to_bytes(self):\n", "        return self.repack8().to_bytes()\n\t    @classmethod\n\t    def from_bytes(cls, bs):\n\t        return NumPyPacked8BHV.from_bytes(bs).repack64()\n\tNumPyPacked64BHV.ZERO = NumPyPacked64BHV(np.zeros(DIMENSION//64, dtype=np.uint64))\n\tNumPyPacked64BHV.ONE = NumPyPacked64BHV(np.full(DIMENSION//64, fill_value=-1, dtype=np.uint64))\n\tNumPyPacked64BHV._FEISTAL_SUBKEYS = NumPyPacked64BHV.nrand2(NumPyPacked64BHV._FEISTAL_ROUNDS, 4)\n\t_half64 = np.zeros(DIMENSION//64, dtype=np.uint64)\n\t_half64[:DIMENSION//128] = np.uint64(-1)\n\tNumPyPacked64BHV.HALF = NumPyPacked64BHV(_half64)\n"]}
{"filename": "bhv/embedding.py", "chunked_list": ["from bhv.abstract import AbstractBHV\n\tfrom typing import Generic, TypeVar, Type, Optional\n\tT = TypeVar('T')\n\tclass Embedding(Generic[T]):\n\t    def forward(self, x: T) -> AbstractBHV:\n\t        raise NotImplementedError()\n\t    def back(self, x: AbstractBHV) -> Optional[T]:\n\t        raise NotImplementedError()\n\tclass Random(Embedding):\n\t    def __init__(self, hvt: Type[AbstractBHV]):\n", "        self.hvt = hvt\n\t        self.hvs = {}\n\t    def forward(self, x: T) -> AbstractBHV:\n\t        if x in self.hvs:\n\t            return self.hvs[x]\n\t        else:\n\t            hv = self.hvt.rand()\n\t            self.hvs[x] = hv\n\t            return hv\n\t    def back(self, input_hv: AbstractBHV, threshold=.1) -> Optional[T]:\n", "        best_x = None\n\t        best_score = 1.\n\t        for x, hv in self.hvs.items():\n\t            score = input_hv.bit_error_rate(hv)\n\t            if score < best_score and score < threshold:\n\t                best_score = score\n\t                best_x = x\n\t        return best_x\n\tclass InterpolateBetween(Embedding):\n\t    def __init__(self, hvt: Type[AbstractBHV], begin: AbstractBHV = None, end: AbstractBHV = None):\n", "        self.hvt = hvt\n\t        self.begin = hvt.rand() if begin is None else begin\n\t        self.end = hvt.rand() if end is None else end\n\t    def forward(self, x: float) -> AbstractBHV:\n\t        return self.end.select_random(self.begin, x)\n\t    def back(self, input_hv: AbstractBHV, threshold=.1) -> Optional[float]:\n\t        beginh = self.begin.bit_error_rate(input_hv)\n\t        endh = self.end.bit_error_rate(input_hv)\n\t        totalh = endh + beginh\n\t        if abs(totalh - .5) < threshold:\n", "            return beginh/totalh\n\tdef make_mask(on, n):\n\t    ar = torch.zeros(n, dtype=torch.bool)\n\t    ar[:on] = True\n\t    perm = torch.randperm(n)\n\t    return ar[perm]\n\tdef binarize_3(x, n):\n\t    on = int(float(x)*(n+1))\n\t    if x == 1.0:\n\t        return torch.ones(n, dtype=torch.bool)\n", "    ar = torch.zeros(n, dtype=torch.bool)\n\t    ar[:on] = True\n\t    return ar\n\tdef filln(xs, n):\n\t    ar = torch.empty(len(xs)*n, dtype=torch.bool)\n\t    for i, x in enumerate(xs):\n\t        ar[i*n:(i + 1)*n] = binarize_3(x, n)\n\t    return ar\n"]}
{"filename": "bhv/poibin.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# MIT License\n\t#\n\t# Copyright (c) 2016 Mika J. Straka\n\t#\n\t# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\t#\n\t# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\t#\n\t# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n", "\"\"\"\n\tCreated on Tue Mar 29, 2016\n\tModule:\n\t    poibin - Poisson Binomial Distribution\n\tAuthor:\n\t    Mika Straka\n\tDescription:\n\t    Implementation of the Poisson Binomial distribution for the sum of\n\t    independent and not identically distributed random variables as described\n\t    in the reference [Hong2013]_.\n", "    Implemented method:\n\t        * ``pmf``: probability mass function\n\t        * ``cdf``: cumulative distribution function\n\t        * ``pval``: p-value (1 - cdf)\n\tUsage:\n\t    Be ``p`` a list or  NumPy array of success probabilities for ``n``\n\t    non-identically distributed Bernoulli random variables.\n\t    Import the module and create an instance of the distribution with::\n\t        >>> from poibin import PoiBin\n\t        >>> pb = PoiBin(p)\n", "    Be ``x`` a list or NumPy array of different number of successes.\n\t    To obtain the:\n\t    * probability mass function of x, use::\n\t        >>> pb.pmf(x)\n\t    * cumulative distribution function of x, use::\n\t        >>> pb.cdf(x)\n\t    * p-values of x, use::\n\t        >>> pb.pval(x)\n\t    The functions are applied component-wise and a NumPy array of the same\n\t    length as ``x`` is returned.\n", "References:\n\t.. [Hong2013] Yili Hong, On computing the distribution function for the Poisson\n\t    binomial distribution,\n\t    Computational Statistics & Data Analysis, Volume 59, March 2013,\n\t    Pages 41-51, ISSN 0167-9473,\n\t    http://dx.doi.org/10.1016/j.csda.2012.10.006.\n\t\"\"\"\n\timport collections\n\timport numpy as np\n\tclass PoiBin(object):\n", "    \"\"\"Poisson Binomial distribution for random variables.\n\t    This class implements the Poisson Binomial distribution for Bernoulli\n\t    trials with different success probabilities. The distribution describes\n\t    thus a random variable that is the sum of independent and not identically\n\t    distributed single Bernoulli random variables.\n\t    The class offers methods for calculating the probability mass function, the\n\t    cumulative distribution function, and p-values for right-sided testing.\n\t    \"\"\"\n\t    def __init__(self, probabilities):\n\t        \"\"\"Initialize the class and calculate the ``pmf`` and ``cdf``.\n", "        :param probabilities: sequence of success probabilities :math:`p_i \\\\in\n\t            [0, 1] \\\\forall i \\\\in [0, N]` for :math:`N` independent but not\n\t            identically distributed Bernoulli random variables\n\t        :type probabilities: numpy.array\n\t        \"\"\"\n\t        self.success_probabilities = np.array(probabilities)\n\t        self.number_trials = self.success_probabilities.size\n\t        self.check_input_prob()\n\t        self.omega = 2 * np.pi / (self.number_trials + 1)\n\t        self.pmf_list = self.get_pmf_xi()\n", "        self.cdf_list = self.get_cdf(self.pmf_list)\n\t# ------------------------------------------------------------------------------\n\t# Methods for the Poisson Binomial Distribution\n\t# ------------------------------------------------------------------------------\n\t    def pmf(self, number_successes):\n\t        \"\"\"Calculate the probability mass function ``pmf`` for the input values.\n\t        The ``pmf`` is defined as\n\t        .. math::\n\t            pmf(k) = Pr(X = k), k = 0, 1, ..., n.\n\t        :param number_successes: number of successful trials for which the\n", "            probability mass function is calculated\n\t        :type number_successes: int or list of integers\n\t        \"\"\"\n\t        self.check_rv_input(number_successes)\n\t        return self.pmf_list[number_successes]\n\t    def cdf(self, number_successes):\n\t        \"\"\"Calculate the cumulative distribution function for the input values.\n\t        The cumulative distribution function ``cdf`` for a number ``k`` of\n\t        successes is defined as\n\t        .. math::\n", "            cdf(k) = Pr(X \\\\leq k), k = 0, 1, ..., n.\n\t        :param number_successes: number of successful trials for which the\n\t            cumulative distribution function is calculated\n\t        :type number_successes: int or list of integers\n\t        \"\"\"\n\t        self.check_rv_input(number_successes)\n\t        return self.cdf_list[number_successes]\n\t    def pval(self, number_successes):\n\t        \"\"\"Return the p-values corresponding to the input numbers of successes.\n\t        The p-values for right-sided testing are defined as\n", "        .. math::\n\t            pval(k) = Pr(X \\\\geq k ),  k = 0, 1, ..., n.\n\t        .. note::\n\t            Since :math:`cdf(k) = Pr(X <= k)`, the function returns\n\t            .. math::\n\t                1 - cdf(X < k) & = 1 - cdf(X <= k - 1)\n\t                               & = 1 - cdf(X <= k) + pmf(X = k),\n\t                               k = 0, 1, .., n.\n\t        :param number_successes: number of successful trials for which the\n\t            p-value is calculated\n", "        :type number_successes: int, numpy.array, or list of integers\n\t        \"\"\"\n\t        self.check_rv_input(number_successes)\n\t        i = 0\n\t        try:\n\t            isinstance(number_successes, collections.Iterable)\n\t            pvalues = np.array(number_successes, dtype='float')\n\t            # if input is iterable (list, numpy.array):\n\t            for k in number_successes:\n\t                pvalues[i] = 1. - self.cdf(k) + self.pmf(k)\n", "                i += 1\n\t            return pvalues\n\t        except TypeError:\n\t            # if input is an integer:\n\t            if number_successes == 0:\n\t                return 1\n\t            else:\n\t                return 1 - self.cdf(number_successes - 1)\n\t# ------------------------------------------------------------------------------\n\t# Methods to obtain pmf and cdf\n", "# ------------------------------------------------------------------------------\n\t    def get_cdf(self, event_probabilities):\n\t        \"\"\"Return the values of the cumulative density function.\n\t        Return a list which contains all the values of the cumulative\n\t        density function for :math:`i = 0, 1, ..., n`.\n\t        :param event_probabilities: array of single event probabilities\n\t        :type event_probabilities: numpy.array\n\t        \"\"\"\n\t        cdf = np.empty(self.number_trials + 1)\n\t        cdf[0] = event_probabilities[0]\n", "        for i in range(1, self.number_trials + 1):\n\t            cdf[i] = cdf[i - 1] + event_probabilities[i]\n\t        return cdf\n\t    def get_pmf_xi(self):\n\t        \"\"\"Return the values of the variable ``xi``.\n\t        The components ``xi`` make up the probability mass function, i.e.\n\t        :math:`\\\\xi(k) = pmf(k) = Pr(X = k)`.\n\t        \"\"\"\n\t        chi = np.empty(self.number_trials + 1, dtype=complex)\n\t        chi[0] = 1\n", "        half_number_trials = int(\n\t            self.number_trials / 2 + self.number_trials % 2)\n\t        # set first half of chis:\n\t        chi[1:half_number_trials + 1] = self.get_chi(\n\t            np.arange(1, half_number_trials + 1))\n\t        # set second half of chis:\n\t        chi[half_number_trials + 1:self.number_trials + 1] = np.conjugate(\n\t            chi[1:self.number_trials - half_number_trials + 1] [::-1])\n\t        chi /= self.number_trials + 1\n\t        xi = np.fft.fft(chi)\n", "        if self.check_xi_are_real(xi):\n\t            xi = xi.real\n\t        else:\n\t            raise TypeError(\"pmf / xi values have to be real.\")\n\t        xi += np.finfo(type(xi[0])).eps\n\t        return xi\n\t    def get_chi(self, idx_array):\n\t        \"\"\"Return the values of ``chi`` for the specified indices.\n\t        :param idx_array: array of indices for which the ``chi`` values should\n\t            be calculated\n", "        :type idx_array: numpy.array\n\t        \"\"\"\n\t        # get_z:\n\t        exp_value = np.exp(self.omega * idx_array * 1j)\n\t        xy = 1 - self.success_probabilities + \\\n\t            self.success_probabilities * exp_value[:, np.newaxis]\n\t        # sum over the principal values of the arguments of z:\n\t        argz_sum = np.arctan2(xy.imag, xy.real).sum(axis=1)\n\t        # get d value:\n\t        exparg = np.log(np.abs(xy)).sum(axis=1)\n", "        d_value = np.exp(exparg)\n\t        # get chi values:\n\t        chi = d_value * np.exp(argz_sum * 1j)\n\t        return chi\n\t# ------------------------------------------------------------------------------\n\t# Auxiliary functions\n\t# ------------------------------------------------------------------------------\n\t    def check_rv_input(self, number_successes):\n\t        \"\"\"Assert that the input values ``number_successes`` are OK.\n\t        The input values ``number_successes`` for the random variable have to be\n", "        integers, greater or equal to 0, and smaller or equal to the total\n\t        number of trials ``self.number_trials``.\n\t        :param number_successes: number of successful trials\n\t        :type number_successes: int or list of integers \"\"\"\n\t        try:\n\t            for k in number_successes:\n\t                assert (type(k) == int or type(k) == np.int64), \\\n\t                        \"Values in input list must be integers\"\n\t                assert k >= 0, 'Values in input list cannot be negative.'\n\t                assert k <= self.number_trials, \\\n", "                    'Values in input list must be smaller or equal to the ' \\\n\t                    'number of input probabilities \"n\"'\n\t        except TypeError:\n\t            assert (type(number_successes) == int or \\\n\t                type(number_successes) == np.int64), \\\n\t                'Input value must be an integer.'\n\t            assert number_successes >= 0, \"Input value cannot be negative.\"\n\t            assert number_successes <= self.number_trials, \\\n\t                'Input value cannot be greater than ' + str(self.number_trials)\n\t        return True\n", "    @staticmethod\n\t    def check_xi_are_real(xi_values):\n\t        \"\"\"Check whether all the ``xi``s have imaginary part equal to 0.\n\t        The probabilities :math:`\\\\xi(k) = pmf(k) = Pr(X = k)` have to be\n\t        positive and must have imaginary part equal to zero.\n\t        :param xi_values: single event probabilities\n\t        :type xi_values: complex\n\t        \"\"\"\n\t        return np.all(xi_values.imag <= np.finfo(float).eps)\n\t    def check_input_prob(self):\n", "        \"\"\"Check that all the input probabilities are in the interval [0, 1].\"\"\"\n\t        if self.success_probabilities.shape != (self.number_trials,):\n\t            raise ValueError(\n\t                \"Input must be an one-dimensional array or a list.\")\n\t        if not np.all(self.success_probabilities >= 0):\n\t            raise ValueError(\"Input probabilities have to be non negative.\")\n\t        if not np.all(self.success_probabilities <= 1):\n\t            raise ValueError(\"Input probabilities have to be smaller than 1.\")\n"]}
{"filename": "bhv/lookup.py", "chunked_list": ["from .abstract import AbstractBHV\n\tfrom typing import TypeVar, Generic, Iterable, Iterator, Optional, Mapping\n\tfrom math import comb\n\tK = TypeVar(\"K\")\n\tclass Store(Generic[K]):\n\t    @classmethod\n\t    def auto_associative(cls, vs: Iterable[AbstractBHV]) -> 'Store[int]':\n\t        return cls(dict(enumerate(vs)))\n\t    def __init__(self, hvs: Mapping[K, AbstractBHV]):\n\t        self.hvs = hvs\n", "    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n\t        raise NotImplementedError()\n\t    def closest(self, v: AbstractBHV) -> Optional[K]:\n\t        raise NotImplementedError()\n\tclass StoreList(Store):\n\t    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n\t        for k, v_ in self.hvs.items():\n\t            if v_.std_apart(v) <= threshold:\n\t                yield k\n\t    def closest(self, v: AbstractBHV) -> Optional[K]:\n", "        closest = None\n\t        shortest_distance = float('inf')\n\t        for k, v_ in self.hvs.items():\n\t            d = v_.std_apart(v)\n\t            if d < shortest_distance:\n\t                closest = k\n\t                shortest_distance = d\n\t        return closest\n\tclass StoreRejectList(Store):\n\t    def __init__(self, hvs: dict[K, AbstractBHV]):\n", "        super().__init__(hvs)\n\t        vs = list(hvs.values())\n\t        representative = vs[0]\n\t        self.bundle = representative.majority(vs)\n\t        self.bundle_size = len(vs)\n\t        self.included_std = AbstractBHV.frac_to_std(AbstractBHV.maj_ber(self.bundle_size))\n\t    # expected number of bits flipped compared to the majority of N random hvs\n\t    # E[bit_error_rate(v, MAJ(v, v_0, ..v_n))]\n\t    # E[v_q != MAJ(v, v_0, ..v_n)_q] WLOG\n\t    # E[1_q != MAJ(1, v_0, ..v_n)_q]\n", "    # E[1 != MAJ(1, v_0, ..v_n)_q]\n\t    # PoiBin(1, af(v_0), ..af(v_n)).cdf(n//2)\n\t    # further assuming af(v_0) == af(v_k) == 0.5,\n\t    # for n=1,3,5,...\n\t    # E[v_q != MAJ(v, v_0, ..v_n)_q]\n\t    # E[MAJ(v, v_0, ..v_n)_q]\n\t    # E[1 | SUM(v_k) > n/2\n\t    #   0 | SUM(v_k) < n/2    # doesn't contribute\n\t    #   v | SUM(v_k) = n/2]   # using af(v) == 0.5\n\t    # in code\n", "    # sum(.5 if sum(bc) == n//2 else (sum(bc) > n//2) for bc in bitconfigs(n))\n\t    # E[SUM(v_k) > n/2] + E[V]\n\t    # (comb(n - 1, (n - 1)//2))/2**n\n\t    # n! / ((n/2)! * (n - n/2)!)\n\t    def related_reject(self, v: AbstractBHV, threshold=6, reject_safety=3) -> Iterator[K]:\n\t        if self.bundle.unrelated(v, self.included_std - reject_safety):\n\t            return\n\t        for k, v_ in self.hvs.items():\n\t            if v_.std_apart(v) <= threshold:\n\t                yield k\n", "    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n\t        for k, v_ in self.hvs.items():\n\t            if v_.std_apart(v) <= threshold:\n\t                yield k\n\t    def find_closest(self, v: AbstractBHV) -> Optional[K]:\n\t        closest = None\n\t        shortest_distance = float('inf')\n\t        for k, v_ in self.hvs.items():\n\t            d = v_.std_apart(v)\n\t            if d < shortest_distance:\n", "                closest = k\n\t                shortest_distance = d\n\t        return closest\n\tclass StoreChunks(Store):\n\t    def __init__(self, hvs: dict[K, AbstractBHV], chunk_size=50):\n\t        super().__init__(hvs)\n\t        ks = list(hvs.keys())\n\t        vs = list(hvs.values())\n\t        representative = vs[0]\n\t        self.chunks = [(representative.majority(vs[i*chunk_size:(i+1)*chunk_size]), dict(zip(ks[i*chunk_size:(i+1)*chunk_size], vs[i*chunk_size:(i+1)*chunk_size])))\n", "                       for i in range(len(vs)//chunk_size+1)]\n\t        self.total_size = len(vs)\n\t        self.chunk_size = chunk_size\n\t        self.included_std = AbstractBHV.frac_to_std(AbstractBHV.maj_ber(chunk_size))\n\t    def related(self, v: AbstractBHV, threshold=6) -> Iterator[K]:\n\t        for maj, chunk in self.chunks:\n\t            if not maj.unrelated(v, self.included_std - 3):\n\t                for k, v_ in chunk.items():\n\t                    if v_.related(v, threshold):\n\t                        yield k\n", "    def find_closest(self, v: AbstractBHV) -> Optional[K]:\n\t        closest = None\n\t        shortest_distance = float('inf')\n\t        for k, v_ in self.hvs.items():\n\t            d = v_.std_apart(v)\n\t            if d < shortest_distance:\n\t                closest = k\n\t                shortest_distance = d\n\t        return closest\n"]}
{"filename": "bhv/vanilla.py", "chunked_list": ["from .abstract import *\n\timport random\n\tfrom sys import byteorder, version_info\n\tclass VanillaPermutation(MemoizedPermutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\t    def __init__(self, indices):\n\t        self.data = indices\n\t    @classmethod\n\t    def random(cls) -> 'VanillaPermutation':\n\t        p = list(range(DIMENSION//8))\n", "        random.shuffle(p)\n\t        return VanillaPermutation(p)\n\t    def __mul__(self, other: 'VanillaPermutation') -> 'VanillaPermutation':\n\t        return VanillaPermutation([self.data[other.data[i]] for i in range(DIMENSION//8)])\n\t    def __invert__(self) -> 'VanillaPermutation':\n\t        p = [None]*(DIMENSION//8)\n\t        for i, j in enumerate(self.data):\n\t            p[j] = i\n\t        return VanillaPermutation(p)\n\t    def __call__(self, hv: 'VanillaBHV') -> 'VanillaBHV':\n", "        return hv.permute_bytes(self)\n\tVanillaPermutation.IDENTITY = VanillaPermutation(list(range(DIMENSION//8)))\n\tclass VanillaBHV(AbstractBHV):\n\t    def __init__(self, data: bytes):\n\t        self.data: bytes = data\n\t    @classmethod\n\t    def rand(cls) -> 'VanillaBHV':\n\t        return VanillaBHV(random.randbytes(DIMENSION//8))\n\t    @classmethod\n\t    def random(cls, active: float) -> 'VanillaBHV':\n", "        assert 0. <= active <= 1.\n\t        return VanillaBHV(bytes([\n\t            (random.random() < active) | (random.random() < active) << 1 | (random.random() < active) << 2 | (random.random() < active) << 3 |\n\t            (random.random() < active) << 4 | (random.random() < active) << 5 | (random.random() < active) << 6 | (random.random() < active) << 7\n\t            for _ in range(DIMENSION//8)]))\n\t    def roll_bytes(self, n: int) -> 'VanillaBHV':\n\t        assert abs(n) < DIMENSION//8, \"only supports DIMENSION/8 rolls\"\n\t        return VanillaBHV(self.data[n:] + self.data[:n])\n\t    def swap_halves(self) -> 'VanillaBHV':\n\t        return self.roll_bytes(DIMENSION//16)\n", "    def permute_bytes(self, permutation: 'VanillaPermutation') -> 'VanillaBHV':\n\t        return VanillaBHV(bytes([self.data[i] for i in permutation.data]))\n\t    def permute(self, permutation_id: 'int | tuple[int, ...]') -> 'VanillaBHV':\n\t        return self.permute_bytes(VanillaPermutation.get(permutation_id))\n\t    def rehash(self) -> 'VanillaBHV':\n\t        return VanillaBHV(hashlib.shake_256(self.data).digest(DIMENSION//8))\n\t    def __eq__(self, other: 'VanillaBHV') -> bool:\n\t        return self.data == other.data\n\t    def __xor__(self, other: 'VanillaBHV') -> 'VanillaBHV':\n\t        return self.from_int(self.to_int() ^ other.to_int())\n", "    def __and__(self, other: 'VanillaBHV') -> 'VanillaBHV':\n\t        return self.from_int(self.to_int() & other.to_int())\n\t    def __or__(self, other: 'VanillaBHV') -> 'VanillaBHV':\n\t        return self.from_int(self.to_int() | other.to_int())\n\t    if version_info[2] >= 10:\n\t        def active(self) -> int:\n\t            return self.to_int().bit_count()\n\t    else:\n\t        def active(self) -> int:\n\t            return bin(self.to_int()).count(\"1\")\n", "    def to_int(self) -> int:\n\t        return int.from_bytes(self.data, \"big\", signed=False)\n\t    @classmethod\n\t    def from_int(cls, i: int):\n\t        return VanillaBHV(i.to_bytes(DIMENSION//8, \"big\", signed=False))\n\t    def to_bytes(self):\n\t        return self.data\n\t    @classmethod\n\t    def from_bytes(cls, bs):\n\t        return cls(bs)\n", "    def bitstring(self) -> str:\n\t        return bin(self.to_int())[2:].rjust(DIMENSION, \"0\")\n\t    @classmethod\n\t    def from_bitstring(cls, s: str) -> Self:\n\t        return cls.from_int(int(s, 2))\n\tVanillaBHV.ZERO = VanillaBHV(bytes([0 for _ in range(DIMENSION//8)]))\n\tVanillaBHV.ONE = VanillaBHV(bytes([0xff for _ in range(DIMENSION//8)]))\n\tVanillaBHV._FEISTAL_SUBKEYS = VanillaBHV.nrand2(VanillaBHV._FEISTAL_ROUNDS, 4)\n\tVanillaBHV.HALF = VanillaBHV(bytes([0 for _ in range(DIMENSION//16)] + [0xff for _ in range(DIMENSION//16)]))\n"]}
{"filename": "bhv/abstract.py", "chunked_list": ["from statistics import NormalDist\n\tfrom itertools import accumulate\n\tfrom functools import cache\n\tfrom operator import or_, and_\n\tfrom math import comb, log2\n\tfrom typing import Iterator\n\tfrom .shared import *\n\tclass StoreBHV:\n\t    def __deepcopy__(self, memodict={}):\n\t        return self.from_bytes(self.to_bytes())\n", "    def to_bytes(self):\n\t        raise NotImplementedError()\n\t    @classmethod\n\t    def from_bytes(cls, bs: bytes):\n\t        raise NotImplementedError()\n\t    def bits(self):\n\t        for b in self.to_bytes():\n\t            yield (b >> 7) & 0x1\n\t            yield (b >> 6) & 0x1\n\t            yield (b >> 5) & 0x1\n", "            yield (b >> 4) & 0x1\n\t            yield (b >> 3) & 0x1\n\t            yield (b >> 2) & 0x1\n\t            yield (b >> 1) & 0x1\n\t            yield b & 0x1\n\t    @classmethod\n\t    def from_bitstream(cls, bits_s: 'Iterator[bool]') -> Self:\n\t        it = iter(bits_s)\n\t        bs = bytes(\n\t            (next(it) << 7) | (next(it) << 6) | (next(it) << 5) | (next(it) << 4) | (next(it) << 3) | (next(it) << 2) | (next(it) << 1) | next(it)\n", "            for _ in range(DIMENSION//8)\n\t        )\n\t        return cls.from_bytes(bs)\n\t    def bitstring(self) -> str:\n\t        return \"\".join(\"1\" if b else \"0\" for b in self.bits())\n\t    @classmethod\n\t    def from_bitstring(cls, s: str) -> Self:\n\t        return cls.from_bitstream(c == \"1\" for c in s)\n\tclass BaseBHV(StoreBHV):\n\t    @classmethod\n", "    def rand(cls) -> Self:\n\t        raise NotImplementedError()\n\t    @classmethod\n\t    def nrand(cls, n: int) -> list[Self]:\n\t        return [cls.rand() for _ in range(n)]\n\t    @classmethod\n\t    def majority(cls, vs: list[Self]) -> Self:\n\t        raise NotImplementedError()\n\t    @classmethod\n\t    def majority3(cls, x, y, z) -> Self:\n", "        return cls.majority([x, y, z])\n\t    def __eq__(self, other: Self) -> bool:\n\t        raise NotImplementedError()\n\t    def __xor__(self, other: Self) -> Self:\n\t        raise NotImplementedError()\n\t    def active(self) -> int:\n\t        raise NotImplementedError()\n\t    def permute(self, permutation_id: int) -> Self:\n\t        raise NotImplementedError()\n\t    def active_fraction(self) -> float:\n", "        return self.active()/DIMENSION\n\t    def hamming(self, other: Self) -> int:\n\t        return (self ^ other).active()\n\t    def bit_error_rate(self, other: Self) -> float:\n\t        return self.hamming(other)/DIMENSION\n\t    def std_apart(self, other: Self, invert=False) -> float:\n\t        return self.frac_to_std(self.bit_error_rate(other), invert)\n\t    @staticmethod\n\t    def normal(mean=0., p=.5):\n\t        return NormalDist(mean, (DIMENSION*p*(1 - p))**.5)\n", "    @staticmethod\n\t    def maj_ber(n):\n\t        return comb(n - 1, (n - 1)//2)/2**n\n\t    @staticmethod\n\t    def frac_to_std(frac, invert=False):\n\t        n = AbstractBHV.normal(0.0)\n\t        estdvs = n.zscore(0.5*DIMENSION)\n\t        stdvs = n.zscore(frac*DIMENSION)\n\t        return estdvs - stdvs if invert else stdvs\n\t    @staticmethod\n", "    def std_to_frac(std, invert=False):\n\t        n = AbstractBHV.normal(0.0)\n\t        frac = (std*n.stdev + n.mean)/DIMENSION\n\t        return 1. - frac if invert else frac\n\t    def zscore(self) -> float:\n\t        n = AbstractBHV.normal(0.5*DIMENSION)\n\t        return n.zscore(self.active())\n\t    def pvalue(self) -> float:\n\t        n = AbstractBHV.normal(0.5*DIMENSION)\n\t        s = n.cdf(self.active())\n", "        return 2.*min(s, 1. - s)\n\t    def related(self, other: Self, stdvs=6) -> bool:\n\t        return abs(self.std_apart(other)) <= stdvs\n\t    def unrelated(self, other: Self, stdvs=6) -> bool:\n\t        return abs(self.std_apart(other, invert=True)) <= stdvs\n\t    @classmethod\n\t    def _majority5_via_3(cls, a: Self, b: Self, c: Self, d: Self, e: Self) -> Self:\n\t        return cls.majority3(a, cls.majority3(b, c, d), cls.majority3(e, d, cls.majority3(c, b, a)))\n\t    @classmethod\n\t    def _majority7_via_3(cls, a: Self, b: Self, c: Self, d: Self, e: Self, f: Self, g: Self) -> Self:\n", "        mdef = cls.majority3(d, e, f)\n\t        mabc = cls.majority3(a, b, c)\n\t        return cls.majority3(g, cls.majority3(c, mdef, cls.majority3(a, b, mdef)), cls.majority3(f, mabc, cls.majority3(d, e, mabc)))\n\t    @classmethod\n\t    def _majority9_via_3(cls, a: Self, b: Self, c: Self, d: Self, e: Self, f: Self, g: Self, h: Self, i: Self) -> Self:\n\t        mabc = cls.majority3(a, b, c)\n\t        mdef = cls.majority3(d, e, f)\n\t        mghi = cls.majority3(g, h, i)\n\t        l_ = cls.majority3(cls.majority3(c, mdef, b), mdef, a)\n\t        l = cls.majority3(cls.majority3(i, l_, h), l_, g)\n", "        r_ = cls.majority3(cls.majority3(c, mghi, b), mghi, a)\n\t        r = cls.majority3(cls.majority3(f, r_, e), r_, d)\n\t        m = cls.majority3(mabc, mdef, mghi)\n\t        return cls.majority3(l, m, r)\n\tclass BooleanAlgBHV(BaseBHV):\n\t    def __and__(self, other: Self) -> Self:\n\t        raise NotImplementedError()\n\t    def __or__(self, other: Self) -> Self:\n\t        raise NotImplementedError()\n\t    def __invert__(self) -> Self:\n", "        return self ^ self.ONE\n\t    @classmethod\n\t    def rand2(cls, power: int) -> Self:\n\t        assert power >= 0\n\t        r = cls.rand()\n\t        return r if power == 0 else r & cls.rand2(power - 1)\n\t    @classmethod\n\t    def nrand2(cls, n: int, power: int) -> list[Self]:\n\t        assert power >= 0\n\t        return [cls.rand2(power) for _ in range(n)]\n", "    def select(self, when1: Self, when0: Self) -> Self:\n\t        return when0 ^ (self & (when0 ^ when1))\n\t    def select_rand(self, other: Self) -> Self:\n\t        return self.rand().select(self, other)\n\t    def select_rand2(self, other: Self, power_left: int) -> Self:\n\t        return self.rand2(power_left).select(self, other)\n\t    def randomize_half(self) -> Self:\n\t        return self.rand().select_rand(self)\n\t    def randomize_pow(self, pow_randomize: int) -> Self:\n\t        return self.rand().select_rand2(self, pow_randomize)\n", "    def flip_half(self) -> Self:\n\t        return self ^ self.rand()\n\t    def flip_pow(self, pow_flip: int) -> Self:\n\t        return self ^ self.rand2(pow_flip)\n\t    def flip_pow_on(self, pow_flip_on: int) -> Self:\n\t        return self | ~self.rand2(pow_flip_on)\n\t    def flip_pow_off(self, pow_flip_off: int) -> Self:\n\t        return self & self.rand2(pow_flip_off)\n\t    def overlap(self, other: Self) -> float:\n\t        return (self & other).active_fraction()\n", "    def jaccard(self, other: Self, distance=False) -> float:\n\t        union_active = (self | other).active()\n\t        if union_active == 0:\n\t            raise RuntimeError(\"Jaccard index where both vectors are zero\")\n\t        res = (self & other).active() / union_active\n\t        return 1. - res if distance else res\n\t    def cosine(self, other: Self, distance=False) -> float:\n\t        s_active = self.active()\n\t        o_active = other.active()\n\t        if not s_active or not o_active:\n", "            raise RuntimeError(\"Cosine similarity where one of the two vectors is zero\")\n\t        res = (self & other).active() / (s_active*o_active)**.5\n\t        return 1. - res if distance else res\n\t    def bias_rel(self, other: Self, rel: Self) -> float:\n\t        rel_l = rel.overlap(self)\n\t        rel_r = rel.overlap(other)\n\t        return rel_l/(rel_l + rel_r)\n\t    def mutual_information(self, other: Self, distance=False) -> float:\n\t        nself = ~self\n\t        nother = ~other\n", "        # Probabilities\n\t        P00 = nself.overlap(nother)\n\t        P01 = nself.overlap(other)\n\t        P10 = self.overlap(nother)\n\t        P11 = self.overlap(other)\n\t        # Marginal probabilities\n\t        PX0 = (P00 + P01)\n\t        PX1 = (P10 + P11)\n\t        PY0 = (P00 + P10)\n\t        PY1 = (P01 + P11)\n", "        # Mutual Information\n\t        MI = 0\n\t        if P00 and PX0 and PY0:\n\t            MI += P00 * log2(P00 / (PX0 * PY0))\n\t        if P01 and PX0 and PY1:\n\t            MI += P01 * log2(P01 / (PX0 * PY1))\n\t        if P10 and PX1 and PY0:\n\t            MI += P10 * log2(P10 / (PX1 * PY0))\n\t        if P11 and PX1 and PY1:\n\t            MI += P11 * log2(P11 / (PX1 * PY1))\n", "        return 1 - MI if distance else MI\n\t    def tversky(self, other: Self, l: float, r: float) -> float:\n\t        o = self.overlap(other)\n\t        lr = self.overlap(~other)\n\t        rl = other.overlap(~self)\n\t        return o/(l*lr + r*rl + o)\n\t    @classmethod\n\t    def majority(cls, vs: list[Self]) -> Self:\n\t        n = len(vs)\n\t        if n == 0:\n", "            return cls.rand()\n\t        elif n == 1:\n\t            return vs[0]\n\t        elif n % 2 == 0:\n\t            return cls.majority([cls.rand()] + vs)\n\t        else:\n\t            return cls._true_majority(vs)\n\t    @classmethod\n\t    def _true_majority(cls, vs: list[Self]) -> Self:\n\t        assert len(vs) % 2 == 1,  \"The true majority function which is only defined on uneven length inputs, see `majority`\"\n", "        half = len(vs)//2\n\t        disjunction = list(accumulate(vs[:half-1:-1], or_))[1:]\n\t        conjunction = list(accumulate(vs[:half-1:-1], and_))[1:]\n\t        @cache\n\t        def rec(ons, offs):\n\t            if ons + 1 > half:\n\t                return disjunction[-offs - 1]\n\t            if offs + 1 > half:\n\t                return conjunction[-ons - 1]\n\t            return vs[ons + offs].select(\n", "                rec(ons + 1, offs),\n\t                rec(ons, offs + 1)\n\t            )\n\t        return rec(0, 0)\n\t    # Alternative implementations\n\t    @classmethod\n\t    def _majority3_select(cls, a: Self, b: Self, c: Self) -> Self:\n\t        # C:  1 0 0 1 0 1 1\n\t        # |:  1 1 1 1 0 1 0\n\t        # &:  1 0 0 0 0 0 0\n", "        # M:  1 0 0 1 0 1 0\n\t        return a.select(b | c, b & c)\n\t    @classmethod\n\t    def _majority5_select(cls, x4: Self, x3: Self, x2: Self, x1: Self, x0: Self) -> Self:\n\t        t1 = x1 | x0\n\t        b1 = x1 & x0\n\t        m2 = x2.select(t1, b1)\n\t        t2 = x2 | t1\n\t        b2 = x2 & b1\n\t        m3h = x3.select(t2, m2)\n", "        m3l = x3.select(m2, b2)\n\t        m4 = x4.select(m3h, m3l)\n\t        return m4\n\t    @classmethod\n\t    def _majority7_select(cls, x6: Self, x5: Self, x4: Self, x3: Self, x2: Self, x1: Self, x0: Self) -> Self:\n\t        t1 = x1 | x0\n\t        b1 = x1 & x0\n\t        m2 = x2.select(t1, b1)\n\t        t2 = x2 | t1\n\t        b2 = x2 & b1\n", "        m3h = x3.select(t2, m2)\n\t        m3l = x3.select(m2, b2)\n\t        m4 = x4.select(m3h, m3l)\n\t        t3 = x3 | t2\n\t        b3 = x3 & b2\n\t        m4h = x4.select(t3, m3h)\n\t        m4l = x4.select(m3l, b3)\n\t        m5h = x5.select(m4h, m4)\n\t        m5l = x5.select(m4, m4l)\n\t        m6 = x6.select(m5h, m5l)\n", "        return m6\n\t    @classmethod\n\t    def _majority9_select(cls, x8: Self, x7: Self, x6: Self, x5: Self, x4: Self, x3: Self, x2: Self, x1: Self, x0: Self) -> Self:\n\t        t1 = x0 | x1\n\t        b1 = x0 & x1\n\t        m2 = x2.select(t1, b1)\n\t        t2 = x2 | t1\n\t        b2 = x2 & b1\n\t        m3h = x3.select(t2, m2)\n\t        m3l = x3.select(m2, b2)\n", "        t3 = x3 | t2\n\t        b3 = x3 & b2\n\t        m4h = x4.select(t3, m3h)\n\t        m4 = x4.select(m3h, m3l)\n\t        m4l = x4.select(m3l, b3)\n\t        t4 = x4 | t3\n\t        b4 = x4 & b3\n\t        m5hh = x5.select(t4, m4h)\n\t        m5h = x5.select(m4h, m4)\n\t        m5l = x5.select(m4, m4l)\n", "        m5ll = x5.select(m4l, b4)\n\t        m6h = x6.select(m5hh, m5h)\n\t        m6 = x6.select(m5h, m5l)\n\t        m6l = x6.select(m5l, m5ll)\n\t        m7h = x7.select(m6h, m6)\n\t        m7l = x7.select(m6, m6l)\n\t        m8 = x8.select(m7h, m7l)\n\t        return m8\n\t    @classmethod\n\t    def _majority3(cls, a: Self, b: Self, c: Self) -> Self:\n", "        # a:  1 0 0 1 0 1 1\n\t        # b:  1 1 0 1 0 1 0\n\t        # c:  1 0 1 0 0 0 0\n\t        # M:  1 0 0 1 0 1 0\n\t        # at least 2/3 agreeing on TRUE\n\t        abh = a & b\n\t        bch = b & c\n\t        cah = c & a\n\t        h = abh | bch | cah\n\t        return h\n", "    @classmethod\n\t    def _majority5(cls, a: Self, b: Self, c: Self, d: Self, e: Self) -> Self:\n\t        # at least 3/5 agreeing on TRUE\n\t        # 2*10 AND\n\t        # 9*1 OR\n\t        # (b ∧ d ∧ e) ∨ (a ∧ d ∧ e) ∨ (b ∧ c ∧ e) ∨ (a ∧ c ∧ e) ∨ (b ∧ c ∧ d) ∨ (a ∧ c ∧ d) ∨ (c ∧ d ∧ e) ∨ (a ∧ b ∧ e) ∨ (a ∧ b ∧ d) ∨ (a ∧ b ∧ c)\n\t        ab = a & b\n\t        cd = c & d\n\t        de = d & e\n\t        ce = c & e\n", "        bde = b & de\n\t        ade = a & de\n\t        bce = b & ce\n\t        ace = a & ce\n\t        bcd = b & cd\n\t        acd = a & cd\n\t        cde = e & cd\n\t        abe = ab & e\n\t        abd = ab & d\n\t        abc = ab & c\n", "        h = bde | ade | bce | ace | bcd | acd | cde | abe | abd | abc\n\t        return h\n\t    @classmethod\n\t    def _majority_via_custom(cls, vs: list[Self]):\n\t        n = len(vs)\n\t        if n == 0:\n\t            return cls.rand()\n\t        elif n == 1:\n\t            return vs[0]\n\t        elif n == 2:\n", "            return vs[0].select_rand(vs[1])\n\t        elif n == 3:\n\t            return cls._majority3(vs[0], vs[1], vs[2])\n\t        elif n == 4:\n\t            return cls._majority5_via_3(vs[0], vs[1], vs[2], vs[3], cls.rand())\n\t        elif n == 5:\n\t            return cls._majority5_via_3(vs[0], vs[1], vs[2], vs[3], vs[4])\n\t        elif n == 6:\n\t            return cls._majority7_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], cls.rand())\n\t        elif n == 7:\n", "            return cls._majority7_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], vs[6])\n\t        elif n == 8:\n\t            return cls._majority9_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], vs[6], vs[7], cls.rand())\n\t        elif n == 9:\n\t            return cls._majority9_via_3(vs[0], vs[1], vs[2], vs[3], vs[4], vs[5], vs[6], vs[7], vs[8])\n\t        else:\n\t            raise RuntimeError(f\"No optimal implementations beyond MAJORITY-9 (tried to take MAJORITY-{n})\")\n\t    ZERO: Self\n\t    ONE: Self\n\tclass FractionalBHV(BooleanAlgBHV):\n", "    @classmethod\n\t    def random(cls, active: float) -> Self:\n\t        raise NotImplementedError()\n\t    @classmethod\n\t    def nrandom(cls, n: int, active: float) -> list[Self]:\n\t        assert 0. <= active <= 1.\n\t        return [cls.random(active) for _ in range(n)]\n\t    def select_random(self, other: Self, frac_left: float) -> Self:\n\t        return self.random(frac_left).select(self, other)\n\t    def randomize_frac(self, frac_randomize: float) -> Self:\n", "        return self.rand().select_random(self, frac_randomize)\n\t    def flip_frac(self, frac_flip: float) -> Self:\n\t        return self ^ self.random(frac_flip)\n\t    def flip_frac_on(self, frac_flip_on: float) -> Self:\n\t        return self | self.random(frac_flip_on)\n\t    def flip_frac_off(self, frac_flip_off: float) -> Self:\n\t        return self & self.random(1. - frac_flip_off)\n\tclass CryptoBHV(FractionalBHV):\n\t    def swap_halves(self) -> Self:\n\t        raise NotImplementedError()\n", "    def rehash(self) -> Self:\n\t        raise NotImplementedError()\n\t    _FEISTAL_ROUNDS = 8\n\t    _FEISTAL_SUBKEYS: list[Self]\n\t    @classmethod\n\t    def _feistal_round(cls, block: Self, round_key: Self) -> Self:\n\t        L = block & cls.HALF\n\t        R = (block ^ (L ^ round_key).rehash().swap_halves()) & ~cls.HALF\n\t        return (L | R).swap_halves()\n\t    def feistal(self, k: Self, inv=False) -> Self:\n", "        block = self\n\t        rounds = range(self._FEISTAL_ROUNDS)\n\t        for r in reversed(rounds) if inv else rounds:\n\t            block = self._feistal_round(block, self._FEISTAL_SUBKEYS[r] & k)\n\t        return block.swap_halves()\n\t    HALF: Self\n\tclass AbstractBHV(CryptoBHV):\n\t    pass\n\tclass Permutation:\n\t    @classmethod\n", "    def nrandom(cls, n) -> list[Self]:\n\t        return [cls.random() for _ in range(n)]\n\t    @classmethod\n\t    def random(cls) -> Self:\n\t        raise NotImplementedError()\n\t    def __mul__(self, other: Self) -> Self:\n\t        raise NotImplementedError()\n\t    def __invert__(self) -> Self:\n\t        raise NotImplementedError()\n\t    def __pow__(self, power):\n", "        permutation = self\n\t        for _ in range(power - 1):\n\t            permutation = permutation*permutation\n\t        return permutation\n\t    def __call__(self, hv: 'AbstractBHV') -> 'AbstractBHV':\n\t        raise NotImplementedError()\n\t    IDENTITY: Self\n\tclass MemoizedPermutation(Permutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]'\n\t    @classmethod\n", "    def _get_singular(cls, permutation_id: int) -> Self:\n\t        if permutation_id == 0:\n\t            return cls.IDENTITY\n\t        elif permutation_id in cls._permutations:\n\t            return cls._permutations[permutation_id]\n\t        elif -permutation_id in cls._permutations:\n\t            inv_permutation = cls._permutations[-permutation_id]\n\t            permutation = ~inv_permutation\n\t            cls._permutations[permutation_id] = permutation\n\t            return permutation\n", "        else:\n\t            permutation = cls.random()\n\t            cls._permutations[permutation_id] = permutation\n\t            return permutation\n\t    @classmethod\n\t    def _get_composite(cls, permutation_id: 'tuple[int, ...]') -> Self:\n\t        # this can be optimized a lot by looking for partial compositions\n\t        composite_permutation = cls._get_singular(permutation_id[0])\n\t        for component_permutation_id in permutation_id[1:]:\n\t            component_permutation = cls.get(component_permutation_id)\n", "            composite_permutation = composite_permutation * component_permutation\n\t        cls._permutations[permutation_id] = composite_permutation\n\t        return composite_permutation\n\t    @classmethod\n\t    def get(cls, permutation_id: 'int | tuple[int, ...]') -> Self:\n\t        permutation = cls._get_singular(permutation_id) if isinstance(permutation_id, int) else \\\n\t            cls._get_composite(permutation_id)\n\t        return permutation\n"]}
{"filename": "bhv/variants.py", "chunked_list": ["from typing import Generic, TypeVar, Type\n\tfrom copy import deepcopy\n\tfrom .abstract import *\n\tHV = TypeVar(\"HV\", bound=BooleanAlgBHV, covariant=True)\n\tclass LinearBHVModel(Generic[HV]):\n\t    def __init__(self, bhv: Type[HV]):\n\t        self.bhv = bhv\n\t        self.used = IdSet()\n\t    def spawn(self, one: 'HV.ONE', zero: 'HV.ZERO') -> (HV, HV):\n\t        assert one not in self.used and zero not in self.used\n", "        self.used.add(one); self.used.add(zero)\n\t        # I O  ->  P N\n\t        # 1 0  ->  1 0  |  0 1\n\t        r = self.bhv.select_rand(one, zero)\n\t        return (r, ~r)\n\t    def xor(self, x: HV, y: HV) -> (HV, HV, HV):\n\t        assert x not in self.used and y not in self.used\n\t        self.used.add(x); self.used.add(y)\n\t        # L R  ->  X L R\n\t        # 0 0  ->  0 0 0\n", "        # 0 1  ->  1 0 0\n\t        # 1 0  ->  1 0 0\n\t        # 1 1  ->  0 1 1\n\t        b = x & y\n\t        return (x ^ y, b, deepcopy(b))\n\t    def thresholds3(self, x: 'HV', y: 'HV', z: 'HV') -> ('HV', 'HV', 'HV'):\n\t        assert x not in self.used and y not in self.used and z not in self.used\n\t        self.used.add(x); self.used.add(y); self.used.add(z)\n\t        # x y z  ->  + M -\n\t        # x y z  ->  + M -\n", "        # 0 0 0  ->  0 0 0\n\t        # 0 0 1  ->  0 0 1\n\t        # 0 1 0  ->  0 0 1\n\t        # 1 0 0  ->  0 0 1\n\t        # 0 1 1  ->  0 1 1\n\t        # 1 0 1  ->  0 1 1\n\t        # 1 1 0  ->  0 1 1\n\t        # 1 1 1  ->  1 1 1\n\t        return (x & y & z, self.bhv.majority([x, y, z]), x | y | z)\n\t    def and_or(self, x: 'HV', y: 'HV') -> ('HV', 'HV'):\n", "        assert x not in self.used and y not in self.used\n\t        self.used.add(x); self.used.add(y)\n\t        # x y  ->  & |\n\t        # 0 0  ->  0 0\n\t        # 0 1  ->  0 1\n\t        # 1 0  ->  0 1\n\t        # 1 1  ->  1 1\n\t        return (x & y, x | y)\n\t    def switch(self, cond: 'HV', left: 'HV', right: 'HV') -> ('HV', 'HV', 'HV'):\n\t        assert cond not in self.used and left not in self.used and right not in self.used\n", "        self.used.add(cond); self.used.add(left); self.used.add(right)\n\t        # C L R  ->  C P N\n\t        # 0 0 0  ->  0 0 0\n\t        # 0 0 1  ->  0 0 1\n\t        # 0 1 0  ->  0 1 0\n\t        # 0 1 1  ->  0 1 1\n\t        # 1 0 0  ->  1 0 0\n\t        # 1 0 1  ->  1 1 0\n\t        # 1 1 0  ->  1 0 1\n\t        # 1 1 1  ->  1 1 1\n", "        pos = self.bhv.select(cond, left, right)\n\t        neg = self.bhv.select(cond, right, left)\n\t        return (deepcopy(cond), pos, neg)\n\t    def invert(self, x: 'HV', one: 'HV.ONE', zero: 'HV.ZERO') -> ('HV', 'HV', 'HV'):\n\t        # P I O  ->  N A B\n\t        # 0 1 0  ->  1 0 0\n\t        # 1 1 0  ->  0 1 1\n\t        (self_1, self_2, inverted) = self.switch(x, one, zero)\n\t        return (inverted, self_1, self_2)\n\t    def permute(self, x: 'HV', permutation_id: int) -> 'HV':\n", "        assert x not in self.used\n\t        self.used.add(x)\n\t        return self.bhv.permute(permutation_id)\n\tclass Tank:\n\t    def __init__(self, capacity: float, fill=None, check=True, record=False):\n\t        self.capacity = capacity\n\t        self.level = capacity if fill is None else fill\n\t        self.check = check\n\t        self.record = record\n\t        self.updates = []\n", "    def update(self, amount: float):\n\t        if self.check:\n\t            if amount < 0:\n\t                assert self.level >= amount, \"not enough to drain\"\n\t            else:\n\t                assert amount <= self.capacity, \"too much to fill\"\n\t        if self.record:\n\t            self.updates.append(amount)\n\t        self.level += amount\n\t    def historical_levels(self):\n", "        assert self.record, \"history not recorded, please pass record=True\"\n\t        level = self.level\n\t        record = [level]\n\t        for update in reversed(self.updates):\n\t            level -= update\n\t            record.append(level)\n\t        record.reverse()\n\t        return record\n\tclass AdiabaticBHVModel:\n\t    def __init__(self, tank: Tank, bhv: Type[HV]):\n", "        self.tank = tank\n\t        self.bhv = bhv\n\t        self.used = IdSet()\n\t    def get_one(self) -> 'HV.ONE':\n\t        self.tank.update(-DIMENSION)\n\t        return deepcopy(self.bhv.ONE)\n\t    def get_zero(self) -> 'HV.ZERO':\n\t        self.tank.update(0)\n\t        return deepcopy(self.bhv.ZERO)\n\t    def spawn(self) -> ('HV', 'HV'):\n", "        # Note: maybe there's a more efficient way to generate random vectors in this context\n\t        # I O  ->  P N\n\t        # 1 0  ->  1 0  |  0 1\n\t        r = self.bhv.rand()\n\t        self.tank.update(-DIMENSION)\n\t        return (r, ~r)\n\t    def xor(self, x: 'HV', y: 'HV') -> 'HV':\n\t        assert x not in self.used and y not in self.used\n\t        self.used.add(x); self.used.add(y)\n\t        # L R  ->  X\n", "        # 0 0  ->  0\n\t        # 0 1  ->  1\n\t        # 1 0  ->  1\n\t        # 1 1  ->  0\n\t        b = (x & y).active()\n\t        self.tank.update(2*b)\n\t        return x ^ y\n\t    def majority3(self, x: 'HV', y: 'HV', z: 'HV') -> 'HV':\n\t        assert x not in self.used and y not in self.used and z not in self.used\n\t        self.used.add(x); self.used.add(y); self.used.add(z)\n", "        # x y z  ->  M\n\t        # 0 0 0  ->  0\n\t        # 0 0 1  ->  0\n\t        # 0 1 0  ->  0\n\t        # 1 0 0  ->  0\n\t        # 0 1 1  ->  1\n\t        # 1 0 1  ->  1\n\t        # 1 1 0  ->  1\n\t        # 1 1 1  ->  1\n\t        self.tank.update((x & y & z).active() + (x | y | z).active())\n", "        return self.bhv.majority([x, y, z])\n\t    def and_or(self, x: 'HV', y: 'HV') -> ('HV', 'HV'):\n\t        assert x not in self.used and y not in self.used\n\t        self.used.add(x); self.used.add(y)\n\t        # x y  ->  & |\n\t        # 0 0  ->  0 0\n\t        # 0 1  ->  0 1\n\t        # 1 0  ->  0 1\n\t        # 1 1  ->  1 1\n\t        self.tank.update(0)\n", "        return (x & y, x | y)\n\t    def switch(self, cond: 'HV', left: 'HV', right: 'HV') -> ('HV', 'HV', 'HV'):\n\t        assert cond not in self.used and left not in self.used and right not in self.used\n\t        self.used.add(cond); self.used.add(left); self.used.add(right)\n\t        # C L R  ->  C P N\n\t        # 0 0 0  ->  0 0 0\n\t        # 0 0 1  ->  0 0 1\n\t        # 0 1 0  ->  0 1 0\n\t        # 0 1 1  ->  0 1 1\n\t        # 1 0 0  ->  1 0 0\n", "        # 1 0 1  ->  1 1 0\n\t        # 1 1 0  ->  1 0 1\n\t        # 1 1 1  ->  1 1 1\n\t        pos = cond.select(left, right)\n\t        neg = cond.select(right, left)\n\t        self.tank.update(0)\n\t        return (deepcopy(cond), pos, neg)\n\t    def invert(self, x: 'HV') -> 'HV':\n\t        assert x not in self.used\n\t        self.used.add(x)\n", "        # P I O  ->  N A B\n\t        # 0 1 0  ->  1 0 0\n\t        # 1 1 0  ->  0 1 1\n\t        self.tank.update(2*(x.active() - DIMENSION//2))\n\t        return ~x\n\t    def permute(self, permutation_id: int) -> 'HV':\n\t        self.tank.update(0)\n\t        return self.bhv.permute(permutation_id)\n"]}
{"filename": "bhv/slice.py", "chunked_list": ["from .abstract import *\n\timport random\n\tclass Slice(AbstractBHV):\n\t    def __init__(self, b):\n\t        self.b = b\n\t    @classmethod\n\t    def rand(cls) -> Self:\n\t        return cls.random(.5)\n\t    @classmethod\n\t    def random(cls, active: float) -> Self:\n", "        assert 0. <= active <= 1.\n\t        return Slice(random.random() > active)\n\t    def permute(self, permutation_id: int) -> Self:\n\t        raise NotImplementedError()\n\t    def swap_halves(self) -> Self:\n\t        raise NotImplementedError()\n\t    def rehash(self) -> Self:\n\t        raise NotImplementedError()\n\t    def __eq__(self, other: Self) -> bool:\n\t        return Slice(self.b == other.b)\n", "    def __xor__(self, other: Self) -> Self:\n\t        return Slice(self.b ^ other.b)\n\t    def __and__(self, other: Self) -> Self:\n\t        return Slice(self.b & other.b)\n\t    def __or__(self, other: Self) -> Self:\n\t        return Slice(self.b | other.b)\n\t    def __invert__(self) -> Self:\n\t        return Slice(not self.b)\n\t    @classmethod\n\t    def _true_majority(cls, vs: list[Self]) -> Self:\n", "        return Slice(sum(v.b for v in vs) > len(vs)//2)\n\t    def active(self) -> int:\n\t        return int(self.b)\n\tSlice.ONE = Slice(True)\n\tSlice.ZERO = Slice(False)\n"]}
{"filename": "bhv/__init__.py", "chunked_list": ["from .abstract import AbstractBHV\n\tfrom .shared import DIMENSION\n"]}
{"filename": "bhv/shared.py", "chunked_list": ["try:\n\t    from typing import Self\n\texcept ImportError:\n\t    Self = 'AbstractBHV'\n\tDIMENSION = 8192\n\tfrom itertools import groupby\n\tfrom functools import partial\n\tfrom dataclasses import fields, is_dataclass\n\tfrom base64 import _urlsafe_encode_translation\n\timport hashlib\n", "import binascii\n\timport sys\n\tsys.setrecursionlimit(75_000)\n\tdef stable_hash(d, try_cache=False) -> bytes:\n\t    \"\"\"\n\t    Python's `hash` is not stable. That's a problem if you want to use it for persistence and inter-run consistency.\n\t    This one is hand rolled, so don't fully trust it. In fact, if you see anything suspicious, please let me know.\n\t    :param d: Something you want to hash\n\t    :return: The 16-byte md5 hash of the bytes of all (nested) items.\n\t    \"\"\"\n", "    if try_cache and hasattr(d, \"__stable_hash\"):\n\t        return d.__stable_hash\n\t    stable_hash_try_cache = partial(stable_hash, try_cache=try_cache)\n\t    t = bytes(type(d).__name__, 'utf-8')\n\t    t += bytes([2])\n\t    if isinstance(d, str):\n\t        t += bytes(d, 'utf-8')\n\t    elif isinstance(d, float):\n\t        t += bytes(d.hex(), 'ascii')\n\t    elif isinstance(d, list) or isinstance(d, tuple):\n", "        t += b''.join(map(stable_hash_try_cache, d))\n\t    elif isinstance(d, set) or isinstance(d, frozenset):\n\t        t += b''.join(sorted(map(stable_hash_try_cache, d)))\n\t    elif isinstance(d, dict):\n\t        for k, v in d.items():\n\t            t += stable_hash_try_cache(k)\n\t            t += bytes([1])\n\t            t += stable_hash_try_cache(v)\n\t    elif is_dataclass(d):\n\t        for f in fields(d):\n", "            t += bytes(f.name, 'utf-8')\n\t            t += bytes([1])\n\t            t += stable_hash_try_cache(getattr(d, f.name))\n\t    else:\n\t        t += bytes(d)\n\t    res = hashlib.md5(t, usedforsecurity=False).digest()\n\t    if try_cache:\n\t        try:\n\t            d.__stable_hash = res\n\t        except AttributeError:\n", "            pass\n\t    return res\n\tdef stable_hashcode(d, version=0, try_cache=False) -> str:\n\t    \"\"\"\n\t    A thin wrapper around `stable_hash` which returns a string and incorporates a version.\n\t    :param d: Something you want to hash\n\t    :param version: Increase this number if you want to unconditionally break all hashcodes\n\t    :return: The 24 character base64 (with - and _) string hash\n\t    \"\"\"\n\t    h = stable_hash(d, try_cache)\n", "    padded = h.rjust(18, version.to_bytes(1, \"little\"))\n\t    base64 = binascii.b2a_base64(padded, newline=False)\n\t    url_safe = base64.translate(_urlsafe_encode_translation)\n\t    return url_safe.decode()\n\tdef nbs(i, w):\n\t    k = 1\n\t    for _ in range(w):\n\t        yield i ^ k\n\t        k <<= 1\n\tdef binw(i, w):\n", "    return bin(i)[2:].rjust(w, '0')\n\tdef to_bitmask(s):\n\t    return [x == '1' for x in s]\n\tdef bin_bitmask(m):\n\t    return ''.join(\"01\"[x] for x in m)\n\tdef bitconfigs(n):\n\t    return [to_bitmask(binw(i, n)) for i in range(2**n)]\n\tdef unique_by_id(xs):\n\t    return list(reversed({id(x): x for x in reversed(xs)}.values()))\n\tdef format_multiple(xs, start=\"\", sep=\"\", end=\"\", indent=\"\", aindent=\"\", newline_threshold=40):\n", "    ss = list(map(str, xs))\n\t    maxlen = max(map(len, ss))\n\t    if maxlen >= newline_threshold:\n\t        return start + sep.rstrip(\" \").join(\"\\n\" + aindent + indent + s for s in ss) + \"\\n\" + aindent + end\n\t    else:\n\t        return start + sep.join(s for s in ss) + end\n\tdef format_list(xs, **kwargs):\n\t    return format_multiple(xs, start=\"[\", sep=\", \", end=\"]\", **kwargs)\n\tclass IdSet:\n\t    def __init__(self, iterable=()):\n", "        self.data = {id(x) for x in iterable}\n\t    def __contains__(self, item):\n\t        return id(item) in self.data\n\t    def add(self, item):\n\t        self.data.add(id(item))\n"]}
{"filename": "bhv/native.py", "chunked_list": ["from bhv.abstract import AbstractBHV, DIMENSION\n\tfrom bhv.cnative import CNativePackedBHV, _DIMENSION\n\tassert DIMENSION == _DIMENSION()\n\tclass NativePackedBHV(AbstractBHV):\n\t    def __init__(self, native_bhv):\n\t        self.ins = native_bhv\n\t    @classmethod\n\t    def rand(cls):\n\t        return NativePackedBHV(CNativePackedBHV.rand())\n\t    @classmethod\n", "    def random(cls, p):\n\t        return NativePackedBHV(CNativePackedBHV.random(p))\n\t    def __or__(self, other):\n\t        return NativePackedBHV(self.ins | other.ins)\n\t    def __and__(self, other):\n\t        return NativePackedBHV(self.ins & other.ins)\n\t    def __xor__(self, other):\n\t        return NativePackedBHV(self.ins ^ other.ins)\n\t    def __invert__(self):\n\t        return NativePackedBHV(~self.ins)\n", "    def select(self, when1, when0):\n\t        return NativePackedBHV(self.ins.select(when1.ins, when0.ins))\n\t    def ternary(self, y, z, op):\n\t        return NativePackedBHV(self.ins.ternary(y.ins, z.ins, op))\n\t    @classmethod\n\t    def majority(cls, xs):\n\t        return NativePackedBHV(CNativePackedBHV.majority([x.ins for x in xs]))\n\t    @classmethod\n\t    def representative(cls, xs):\n\t        return NativePackedBHV(CNativePackedBHV.representative([x.ins for x in xs]))\n", "    def active(self):\n\t        return self.ins.active()\n\t    def hamming(self, other):\n\t        return self.ins.hamming(other.ins)\n\t    def permute_words(self, permutation_id: int):\n\t        return NativePackedBHV(self.ins.permute_words(permutation_id))\n\t    def permute_byte_bits(self, permutation_id: int):\n\t        return NativePackedBHV(self.ins.permute_byte_bits(permutation_id))\n\t    def roll_words(self, d: int):\n\t        return NativePackedBHV(self.ins.roll_words(d))\n", "    def roll_word_bits(self, d: int):\n\t        return NativePackedBHV(self.ins.roll_word_bits(d))\n\t    def _permute_composite(self, permutation_id: 'tuple'):\n\t        v = self\n\t        for e in permutation_id:\n\t            v = v.permute(e)\n\t        return v\n\t    def permute(self, permutation_id: 'int | tuple'):\n\t        if isinstance(permutation_id, tuple):\n\t            return self._permute_composite(permutation_id)\n", "        return NativePackedBHV(self.ins.permute(permutation_id))\n\t    def rehash(self):\n\t        return NativePackedBHV(self.ins.rehash())\n\t    def swap_halves(self):\n\t        return NativePackedBHV(self.ins.swap_halves())\n\t    def __eq__(self, other):\n\t        return self.ins == other.ins\n\t    @classmethod\n\t    def from_bytes(cls, bs):\n\t        return NativePackedBHV(CNativePackedBHV.from_bytes(bs))\n", "    def to_bytes(self):\n\t        return self.ins.to_bytes()\n\t    def __getstate__(self):\n\t        return self.to_bytes()\n\t    def __setstate__(self, state):\n\t        self.ins = CNativePackedBHV.from_bytes(state)\n\tNativePackedBHV.ZERO = NativePackedBHV(CNativePackedBHV.ZERO)\n\tNativePackedBHV.ONE = NativePackedBHV(CNativePackedBHV.ONE)\n\tNativePackedBHV.HALF = NativePackedBHV(CNativePackedBHV.HALF)\n\tNativePackedBHV._FEISTAL_SUBKEYS = NativePackedBHV.nrand2(NativePackedBHV._FEISTAL_ROUNDS, 4)\n"]}
{"filename": "bhv/visualization.py", "chunked_list": ["from .abstract import AbstractBHV, DIMENSION\n\tclass DistanceGraph:\n\t    @classmethod\n\t    def from_scope(cls, local_dict):\n\t        return cls(*zip(*[(v, k) for k, v in local_dict.items() if isinstance(v, AbstractBHV)]))\n\t    def __init__(self, hvs: 'list[AbstractBHV]', labels: 'list[str]'):\n\t        self.hvs = hvs\n\t        self.labels = labels\n\t        self.adj = [[round(min(v.std_apart(w, invert=True), v.std_apart(w))) if not v.unrelated(w) else None\n\t                     for v in self.hvs]\n", "                    for w in self.hvs]\n\t    def graphviz(self):\n\t        for i, (r, l) in enumerate(zip(self.adj, self.labels)):\n\t            print(f\"{i} [label=\\\"{l}\\\"];\")\n\t            for j, d in enumerate(r):\n\t                if i < j and d is not None:\n\t                    print(f\"{i} -- {j} [label=\\\"{d}\\\"];\")\n\tclass Image:\n\t    @classmethod\n\t    def load_pbm(cls, file: 'IO[Any]', bhv: 'AbstractBHV', binary=False):\n", "        if binary:\n\t            header = file.readline().rstrip()\n\t            assert header == b\"P4\"\n\t            dimension, n = map(int, file.readline().rstrip().split(b\" \"))\n\t            assert dimension == DIMENSION\n\t            hvs = [bhv.from_bytes(file.read(DIMENSION//8)) for _ in range(n)]\n\t            return cls(hvs)\n\t        else:\n\t            header = file.readline().rstrip()\n\t            assert header == \"P1\"\n", "            dimension, n = map(int, file.readline().rstrip().split(\" \"))\n\t            assert dimension == DIMENSION\n\t            hvs = [bhv.from_bitstring(file.readline().rstrip()) for _ in range(n)]\n\t            return cls(hvs)\n\t    def __init__(self, hvs: 'list[AbstractBHV]'):\n\t        self.hvs = hvs\n\t    def pbm(self, file: 'IO[Any]', binary=False):\n\t        if binary:\n\t            file.write(b\"P4\\n\" + bytes(str(DIMENSION), \"ascii\") + b\" \" + bytes(str(len(self.hvs)), \"ascii\") + b\"\\n\")\n\t            for hv in self.hvs:\n", "                file.write(hv.to_bytes())\n\t        else:\n\t            file.write(f\"P1\\n{DIMENSION} {len(self.hvs)}\\n\")\n\t            for hv in self.hvs:\n\t                file.write(hv.bitstring())\n\t                file.write('\\n')\n"]}
{"filename": "bhv/unification.py", "chunked_list": ["from .symbolic import Var, Symbolic\n\tfrom typing import Optional\n\tKnowledge = dict[str, Symbolic]\n\t# Unify t1 with t2 using/improving the passed knowledge.\n\tdef unify(t1: Symbolic, t2: Symbolic, knowledge: Optional[Knowledge] = None) -> Optional[Knowledge]:\n\t    if knowledge is None:\n\t        knowledge = {}\n\t    if isinstance(t1, Var) and isinstance(t2, Var) and t1.name == t2.name:\n\t        return knowledge  # does global variable equality\n\t    elif isinstance(t2, Var):\n", "        return unify_variable(t2.name, t1, knowledge)\n\t    elif isinstance(t1, Var):\n\t        return unify_variable(t1.name, t2, knowledge)\n\t    else:\n\t        if t1.constant() != t2.constant():\n\t            return None\n\t        else:\n\t            cs1 = t1.children()\n\t            cs2 = t2.children()\n\t            if len(cs1) != len(cs2):\n", "                return None\n\t            else:\n\t                k = knowledge\n\t                for l, r in zip(cs1, cs2):\n\t                    k = unify(l, r, k)\n\t                    if k is None:\n\t                        return None\n\t                return k\n\tdef unify_variable(v: str, t: Symbolic, knowledge: Knowledge) -> Optional[Knowledge]:\n\t    if v in knowledge:\n", "        return unify(knowledge[v], t, knowledge)\n\t    elif isinstance(t, Var) and t.name in knowledge:\n\t        return unify(Var(v), knowledge[t.name], knowledge)\n\t    elif occurs_check(v, t, knowledge):\n\t        return None\n\t    else:\n\t        return {**knowledge, v: t}\n\tdef occurs_check(v: str, t, knowledge: Knowledge):\n\t    if isinstance(t, Var) and t.name == v:\n\t        return True\n", "    elif isinstance(t, Var) and t.name in knowledge:\n\t        return occurs_check(v, knowledge[t.name], knowledge)\n\t    else:\n\t        return any(occurs_check(v, arg, knowledge) for arg in t.children())\n"]}
{"filename": "bhv/symbolic.py", "chunked_list": ["from dataclasses import dataclass, field, fields\n\tfrom string import ascii_uppercase\n\tfrom .abstract import *\n\tfrom .shared import stable_hashcode, bitconfigs, unique_by_id, format_multiple, format_list\n\tfrom .slice import Slice\n\tclass Symbolic:\n\t    name = None\n\t    def named(self, name):\n\t        if name is not None: self.name = name\n\t        return self\n", "    def nodename(self, **kwargs):\n\t        return self.name or f\"{type(self).__name__.upper()}\"\n\t    def nodeid(self, structural=False, **kwargs):\n\t        return f\"{type(self).__name__}{stable_hashcode(self, try_cache=True).replace('-', '') if structural else str(id(self))}\"\n\t    def labeled_children(self, **kwargs):\n\t        return [(getattr(self, f.name), f.name) for f in fields(self) if type(f.type) is type and issubclass(f.type, Symbolic)]\n\t    def children(self, **kwargs):\n\t        return [c for c, _ in self.labeled_children(**kwargs)]\n\t    def vars(self) -> list[str]:\n\t        return [v.name for v in self.preorder(lambda x: isinstance(x, Var))]\n", "    def substitute(self, vars):\n\t        if isinstance(self, Var) and self.name in vars:\n\t            return vars[self.name]\n\t        else:\n\t            return self.map(lambda x: x.substitute(vars))\n\t    def substitute_term(self, f):\n\t        res = f(self)\n\t        if res:\n\t            return res\n\t        else:\n", "            return self.map(lambda x: x.substitute_term(f))\n\t    def reconstruct(self, *cs):\n\t        assert not self.labeled_children()\n\t        return self\n\t    def map(self, f):\n\t        return self.reconstruct(*map(f, self.children())).named(self.name)\n\t    def constant(self):\n\t        return self.map(lambda x: None)\n\t    def draw_node(self, **kwargs):\n\t        print(f\"{self.nodeid(**kwargs)} [label=\\\"{self.nodename(**kwargs)}\\\"];\")\n", "    def draw_edges(self, **kwargs):\n\t        for c, label in self.labeled_children(**kwargs):\n\t            print(f\"{c.nodeid(**kwargs)} -> {self.nodeid(**kwargs)} [label=\\\"{label}\\\"];\")\n\t    def draw_children(self, **kwargs):\n\t        for c, label in self.labeled_children(**kwargs):\n\t            c.graphviz(**kwargs)\n\t    def graphviz(self, structural=False, done=None, **kwargs):\n\t        noden = self.nodeid(structural, **kwargs)\n\t        if done is None:\n\t            done = set()\n", "        if noden in done:\n\t            return\n\t        done.add(noden)\n\t        kwargs |= dict(done=done, structural=structural)\n\t        self.draw_node(**kwargs)\n\t        self.draw_edges(**kwargs)\n\t        self.draw_children(**kwargs)\n\t    def show_program(self, name=\"f\", indent=\"    \", **kwargs):\n\t        kwargs[\"indent\"] = indent\n\t        kwargs[\"aindent\"] = indent\n", "        kwargs[\"toplevel\"] = True\n\t        def extracted(x: Symbolic):\n\t            return x.map(lambda x: x if isinstance(x, Var) else Var(f\"_{subexpressions.index(x)}\"))\n\t        subexpressions = unique_by_id(self.preorder(lambda x: not isinstance(x, Var))[1:])\n\t        subexpressions.reverse()\n\t        free_vars = unique_by_id(self.preorder(lambda x: isinstance(x, Var)))\n\t        arguments = [fv.show(**kwargs) for fv in free_vars]\n\t        lines = [(x.name or f\"_{i}\") + \" = \" + extracted(x).show(**kwargs) for i, x in enumerate(subexpressions)]\n\t        last = f\"return {extracted(self).show(**kwargs)}\"\n\t        code = format_multiple([*lines, last], start=f\"def {name}({format_multiple(arguments, sep=', ')}):\", indent=indent, newline_threshold=0)\n", "        return code\n\t    def show(self, **kwargs):\n\t        \"\"\"\n\t        Shows the expression tree code-style.\n\t        Only works on referentially transparent DAGs.\n\t        :param kwargs: drawing options\n\t        :return: str\n\t        \"\"\"\n\t        raise NotImplementedError()\n\t    def instantiate(self, **kwargs):\n", "        raise NotImplementedError()\n\t    def execute(self, random: 'dict[int, AbstractBHV]' = None,\n\t                rand2: 'dict[int, AbstractBHV]' = None,\n\t                rand: 'dict[int, AbstractBHV]' = None,\n\t                randomperms: 'dict[int, MemoizedPermutation]' = None,\n\t                calculated = None, **kwargs):\n\t        if random is None: random = {}\n\t        if rand2 is None: rand2 = {}\n\t        if rand is None: rand = {}\n\t        if randomperms is None: randomperms = {}\n", "        if calculated is None: calculated = {}\n\t        kwargs |= dict(random=random, rand2=rand2, rand=rand, randomperms=randomperms, calculated=calculated)\n\t        if id(self) in calculated:\n\t            return calculated[id(self)]\n\t        else:\n\t            result = self.instantiate(**kwargs)\n\t            calculated[id(self)] = result\n\t            return result\n\t    def optimal_sharing(self, form=None, **kwargs):\n\t        if form is None: form = {}\n", "        kwargs |= dict(form=form)\n\t        sh = stable_hashcode(self, try_cache=True)\n\t        if sh in form:\n\t            return form[sh]\n\t        else:\n\t            r = self.map(lambda c: c.optimal_sharing(**kwargs))\n\t            shr = stable_hashcode(r, try_cache=True)\n\t            if shr in form:\n\t                raise RuntimeError(\"Includes check failed\")\n\t            form[shr] = r\n", "            return r\n\t    def internal_size(self):\n\t        return 1\n\t    def size(self, counted=None, recount=False, **kwargs):\n\t        if counted is None: counted = {}\n\t        kwargs |= dict(counted=counted)\n\t        if id(self) in counted:\n\t            return counted[id(self)] if recount else 0\n\t        else:\n\t            t = self.internal_size()\n", "            for c in self.children():\n\t                t += c.size(**kwargs)\n\t            counted[id(self)] = t\n\t            return t\n\t    def simplify(self, **kwargs):\n\t        x = self\n\t        while True:\n\t            x_ = x.map(lambda c: c.simplify(**kwargs))\n\t            x_r = x_.reduce(**kwargs)\n\t            if x_r is not None:\n", "                x_ = x_r\n\t            if x == x_:\n\t                return x\n\t            else:\n\t                x = x_\n\t    def reduce(self, **kwargs):\n\t        return None\n\t    def preorder(self, p=lambda x: True):\n\t        return [self]*p(self) + [v for c in self.children() for v in c.preorder(p)]\n\t    def truth_assignments(self, vars):\n", "        configs = bitconfigs(len(vars))\n\t        return [self.execute(vars={v.name: Slice(b) for b, v in zip(config, vars)}, bhv=Slice).b\n\t                for config in configs]\n\t@dataclass\n\tclass List(Symbolic):\n\t    xs: list[Symbolic]\n\t    def show(self, **kwargs):\n\t        return format_list((x.show(**kwargs) for x in self.xs),\n\t                           **{k: kwargs[k] for k in [\"indent\", \"aindent\", \"newline_threshold\"] if k in kwargs})\n\t    def labeled_children(self, **kwargs):\n", "        return [(x, str(i)) for i, x in enumerate(self.xs)]\n\t    def reconstruct(self, *cs):\n\t        return List(cs)\n\t    def graphviz(self, structural=False, done=None, **kwargs):\n\t        noden = self.nodeid(structural, **kwargs)\n\t        if done is None:\n\t            done = set()\n\t        if noden in done:\n\t            return\n\t        done.add(noden)\n", "        kwargs |= dict(done=done, structural=structural)\n\t        print(f\"subgraph cluster_{self.nodename()} \" + \"{\")\n\t        print(f\"label = \\\"{self.nodename()}\\\";\")\n\t        for c in self.xs:\n\t            c.draw_node(**kwargs)\n\t        print(\"}\")\n\t        for c in self.xs:\n\t            c.draw_edges(**kwargs)\n\t            c.draw_children(**kwargs)\n\t    def instantiate(self, **kwargs):\n", "        return [x.instantiate(**kwargs) for x in self.xs]\n\t    def truth_table(self, vars):\n\t        return [x.truth_assignments(vars) for x in self.xs]\n\tclass SymbolicPermutation(Symbolic, MemoizedPermutation):\n\t    _permutations: 'dict[int | tuple[int, ...], Self]' = {}\n\t    @classmethod\n\t    def random(cls) -> 'SymbolicPermutation':\n\t        return PermRandom()\n\t    def __mul__(self, other: 'SymbolicPermutation') -> 'SymbolicPermutation':\n\t        return PermCompose(self, other)\n", "    def __invert__(self) -> 'SymbolicPermutation':\n\t        return PermInvert(self)\n\t    def __call__(self, hv: 'SymbolicBHV') -> 'SymbolicBHV':\n\t        return PermApply(self, hv)\n\t@dataclass\n\tclass PermVar(SymbolicPermutation):\n\t    name: str\n\t    def nodename(self, **kwargs):\n\t        return self.name\n\t    def show(self, **kwargs):\n", "        symbolic_var = kwargs.get(\"symbolic_var\", False)\n\t        return f\"ParmVar(\\\"{self.name}\\\")\" if symbolic_var else self.name\n\t    def instantiate(self, **kwargs):\n\t        permvars = kwargs.get(\"permvars\")\n\t        if permvars is None:\n\t            raise RuntimeError(f\"No Perm vars supplied but tried to instantiate `{self.name}`\")\n\t        elif self.name not in permvars:\n\t            raise RuntimeError(f\"Perm var `{self.name}` not in permvars ({set(permvars.keys())})\")\n\t        else:\n\t            return permvars[self.name]\n", "randpermid = 0\n\tdef next_perm_id():\n\t    global randpermid\n\t    randpermid += 1\n\t    return randpermid\n\t@dataclass\n\tclass PermRandom(SymbolicPermutation):\n\t    id: int = field(default_factory=next_perm_id)\n\t    def show(self, **kwargs):\n\t        impl = kwargs.get(\"impl\", \"\")\n", "        random_id = kwargs.get(\"random_id\", False)\n\t        return f\"<{impl}random {self.id}>\" if random_id else impl + \"random()\"\n\t    def instantiate(self, **kwargs):\n\t        randomperms = kwargs.get(\"randomperms\")\n\t        if self.id in randomperms:\n\t            return randomperms[self.id]\n\t        else:\n\t            r = kwargs.get(\"perm\").random()\n\t            randomperms[self.id] = r\n\t            return r\n", "@dataclass\n\tclass PermCompose(SymbolicPermutation):\n\t    l: SymbolicPermutation\n\t    r: SymbolicPermutation\n\t    def reconstruct(self, l, r):\n\t        return PermCompose(l, r)\n\t    def show(self, **kwargs):\n\t        brackets = not kwargs.get(\"toplevel\", False)\n\t        return \"(\"*brackets + f\"{self.l.show(**kwargs)} * {self.r.show(**kwargs)}\" + \")\"*brackets\n\t    def instantiate(self, **kwargs):\n", "        return self.l.execute(**kwargs) * self.r.execute(**kwargs)\n\t@dataclass\n\tclass PermInvert(SymbolicPermutation):\n\t    p: SymbolicPermutation\n\t    def reconstruct(self, p):\n\t        return PermInvert(p)\n\t    def show(self, **kwargs):\n\t        brackets = not kwargs.get(\"toplevel\", False)\n\t        return \"(\"*brackets + f\"~{self.p.show(**kwargs)}\" + \")\"*brackets\n\t    def instantiate(self, **kwargs):\n", "        return ~self.p.execute(**kwargs)\n\tclass SymbolicBHV(Symbolic, AbstractBHV):\n\t    @classmethod\n\t    def synth(cls, vs, t):\n\t        assert 2**len(vs) == len(t)\n\t        if vs:\n\t            return vs[0].select(\n\t                    cls.synth(vs[1:], t[:len(t)//2]),\n\t                    cls.synth(vs[1:], t[len(t)//2:]))\n\t        else:\n", "            return cls.ONE if t[0] else cls.ZERO\n\t    @classmethod\n\t    def synth_af(cls, af: float, depth=1, v_gen=lambda x: Rand(x), threshold=1e-6):\n\t        assert 0. < af < 1.\n\t        d = af - (1 / 2) ** depth\n\t        v = v_gen(depth)\n\t        if abs(d) > threshold:\n\t            if d > 0:\n\t                return v | cls.synth_af(d, depth + 1, v_gen, threshold)\n\t            else:\n", "                return v & cls.synth_af(af, depth + 1, v_gen, threshold)\n\t        else:\n\t            return v\n\t    @classmethod\n\t    def synth_af_ternary(cls, af: float, depth=1, v_gen=lambda x: Rand(x), threshold=1e-6):\n\t        assert 0. < af < 1.\n\t        da = af - (1 / 2) ** depth\n\t        va = v_gen(depth)\n\t        if abs(da) < threshold:\n\t            return va\n", "        if da > 0:\n\t            af = da\n\t        depth += 1\n\t        db = af - (1 / 2) ** depth\n\t        vb = v_gen(depth)\n\t        if db > 0:\n\t            af = db\n\t        if abs(db) > threshold:\n\t            ternary_instr = {(True, True): [0,1,1,1,1,1,1,1],\n\t                             (True, False): [0,0,0,1,1,1,1,1],\n", "                             (False, True): [0,0,0,0,0,1,1,1],\n\t                             (False, False): [0,0,0,0,0,0,0,1]}[(da > 0, db > 0)]\n\t            # TODO implement Ternary op\n\t            vr = cls.synth_af_ternary(af, depth + 1, v_gen, threshold)\n\t            return cls.synth([va, vb, vr], ternary_instr)\n\t        if da > 0:\n\t            return va | vb\n\t        else:\n\t            return va & vb\n\t    @classmethod\n", "    def rand(cls) -> Self:\n\t        return Rand()\n\t    @classmethod\n\t    def rand2(cls, power: int) -> Self:\n\t        assert power >= 0\n\t        return Rand2(power)\n\t    @classmethod\n\t    def random(cls, active: float) -> Self:\n\t        assert 0. <= active <= 1.\n\t        return Random(active)\n", "    @classmethod\n\t    def majority(cls, vs: list[Self]) -> Self:\n\t        return Majority(vs)\n\t    def permute(self, permutation_id: 'int | tuple[int, ...]') -> Self:\n\t        return Permute(permutation_id, self)\n\t    def swap_halves(self) -> Self:\n\t        return SwapHalves(self)\n\t    def rehash(self) -> Self:\n\t        return ReHash(self)\n\t    def __xor__(self, other: Self) -> Self:\n", "        return Xor(self, other)\n\t    def __and__(self, other: Self) -> Self:\n\t        return And(self, other)\n\t    def __or__(self, other: Self) -> Self:\n\t        return Or(self, other)\n\t    def __invert__(self) -> Self:\n\t        return Invert(self)\n\t    def select(self, when1: Self, when0: Self) -> Self:\n\t        return Select(self, when0, when1)\n\t    def active_fraction(self) -> int:\n", "        return ActiveFraction(self)\n\t    def bias_rel(self, other: Self, rel: Self) -> float:\n\t        return BiasRel(rel, self, other)\n\t    def unrelated(self, other: Self, stdvs=6) -> bool:\n\t        return Unrelated(self, other, stdvs)\n\t    def expected_active_fraction(self, **kwargs):\n\t        raise NotImplementedError()\n\t@dataclass\n\tclass PermApply(SymbolicBHV):\n\t    p: SymbolicPermutation\n", "    v: SymbolicBHV\n\t    def reconstruct(self, p, v):\n\t        return PermApply(p, v)\n\t    def show(self, **kwargs):\n\t        return f\"{self.p.show(**kwargs)}({self.v.show(**kwargs)})\"\n\t    def instantiate(self, **kwargs):\n\t        return self.p.execute(**kwargs)(self.v.execute(**kwargs))\n\t    def expected_active_fraction(self, **kwargs):\n\t        return self.v.expected_active(**kwargs)\n\t@dataclass\n", "class Var(SymbolicBHV):\n\t    name: str\n\t    @classmethod\n\t    def shortname(cls, i: int, letters=ascii_uppercase):\n\t        n = len(letters)\n\t        return cls(letters[i % n] + str(i // n) * (i > n))\n\t    def nodename(self, **kwards):\n\t        return self.name\n\t    def show(self, **kwargs):\n\t        symbolic_var = kwargs.get(\"symbolic_var\", False)\n", "        return f\"Var(\\\"{self.name}\\\")\" if symbolic_var else self.name\n\t    def instantiate(self, **kwargs):\n\t        vars = kwargs.get(\"vars\")\n\t        if vars is None:\n\t            raise RuntimeError(f\"No vars supplied but tried to instantiate `{self.name}`\")\n\t        elif self.name not in vars:\n\t            raise RuntimeError(f\"Var `{self.name}` not in vars ({set(vars.keys())})\")\n\t        else:\n\t            return vars[self.name]\n\t    def expected_active_fraction(self, **kwargs):\n", "        return kwargs.get(\"vars\").get(self.name)\n\t@dataclass\n\tclass Zero(SymbolicBHV):\n\t    def show(self, **kwargs):\n\t        return kwargs.get(\"impl\", \"\") + \"ZERO\"\n\t    def instantiate(self, **kwargs):\n\t        return kwargs.get(\"bhv\").ZERO\n\t    def expected_active_fraction(self, **kwargs):\n\t        return 0.\n\t@dataclass\n", "class One(SymbolicBHV):\n\t    def show(self, **kwargs):\n\t        return kwargs.get(\"impl\", \"\") + \"ONE\"\n\t    def instantiate(self, **kwargs):\n\t        return kwargs.get(\"bhv\").ONE\n\t    def expected_active_fraction(self, **kwargs):\n\t        return 1.\n\tSymbolicBHV.ZERO = Zero()\n\tSymbolicBHV.ONE = One()\n\trandid = 0\n", "def next_id():\n\t    global randid\n\t    randid += 1\n\t    return randid\n\t@dataclass\n\tclass Rand(SymbolicBHV):\n\t    id: int = field(default_factory=next_id)\n\t    def show(self, **kwargs):\n\t        impl = kwargs.get(\"impl\", \"\")\n\t        random_id = kwargs.get(\"random_id\", False)\n", "        return f\"<{impl}rand {self.id}>\" if random_id else impl + \"rand()\"\n\t    def instantiate(self, **kwargs):\n\t        rand = kwargs.get(\"rand\")\n\t        if self.id in rand:\n\t            return rand[self.id]\n\t        else:\n\t            r = kwargs.get(\"bhv\").rand()\n\t            rand[self.id] = r\n\t            return r\n\t    def expected_active_fraction(self, **kwargs):\n", "        return .5\n\t@dataclass\n\tclass Rand2(SymbolicBHV):\n\t    power: int\n\t    def show(self, **kwargs):\n\t        return kwargs.get(\"impl\", \"\") + f\"rand2({self.power})\"\n\t    def instantiate(self, **kwargs):\n\t        rand2 = kwargs.get(\"rand2\")\n\t        if self.id in rand2:\n\t            return rand2[self.id]\n", "        else:\n\t            r = kwargs.get(\"bhv\").rand2(self.power)\n\t            rand2[self.id] = r\n\t            return r\n\t    def expected_active_fraction(self, **kwargs):\n\t        return 1/self.power\n\t@dataclass\n\tclass Random(SymbolicBHV):\n\t    frac: float\n\t    def show(self, **kwargs):\n", "        return kwargs.get(\"impl\", \"\") + f\"random({self.frac})\"\n\t    def instantiate(self, **kwargs):\n\t        random = kwargs.get(\"random\")\n\t        if self.id in random:\n\t            return random[self.id]\n\t        else:\n\t            r = kwargs.get(\"bhv\").random(self.frac)\n\t            random[self.id] = r\n\t            return r\n\t    def expected_active_fraction(self, **kwargs):\n", "        return self.frac\n\t@dataclass\n\tclass Majority(SymbolicBHV):\n\t    vs: list[SymbolicBHV]\n\t    def labeled_children(self, **kwargs):\n\t        return list(zip(self.vs, map(str, range(len(self.vs)))))\n\t    def reconstruct(self, *cs):\n\t        return Majority(cs)\n\t    def show(self, **kwargs):\n\t        args = format_list((v.show(**kwargs) for v in self.vs), **{k: kwargs[k] for k in [\"indent\", \"aindent\", \"newline_threshold\"] if k in kwargs})\n", "        return kwargs.get(\"impl\", \"\") + f\"majority({args})\"\n\t    def instantiate(self, **kwargs):\n\t        return kwargs.get(\"bhv\").majority([v.execute(**kwargs) for v in self.vs])\n\t    def expected_active_fraction(self, **kwargs):\n\t        from .poibin import PoiBin\n\t        return 1. - PoiBin([v.expected_active_fraction(**kwargs) for v in self.vs]).cdf(len(self.vs)//2)\n\t@dataclass\n\tclass Permute(SymbolicBHV):\n\t    id: 'int | tuple[int, ...]'\n\t    v: SymbolicBHV\n", "    def reconstruct(self, v):\n\t        return Permute(self.id, v)\n\t    def show(self, **kwargs):\n\t        return f\"{self.v.show(**kwargs)}.permute({self.id})\"\n\t    def instantiate(self, **kwargs):\n\t        return self.v.execute(**kwargs).permute(self.id)\n\t    def expected_active_fraction(self, **kwargs):\n\t        return self.v.expected_active_fraction(**kwargs)\n\t@dataclass\n\tclass SwapHalves(SymbolicBHV):\n", "    v: SymbolicBHV\n\t    def reconstruct(self, v):\n\t        return SwapHalves(v)\n\t    def show(self, **kwargs):\n\t        return f\"{self.v.show(**kwargs)}.swap_halves()\"\n\t    def instantiate(self, **kwargs):\n\t        return self.v.execute(**kwargs).swap_halves()\n\t    def expected_active_fraction(self, **kwargs):\n\t        return self.v.expected_active_fraction(**kwargs)\n\t@dataclass\n", "class ReHash(SymbolicBHV):\n\t    v: SymbolicBHV\n\t    def reconstruct(self, v):\n\t        return ReHash(v)\n\t    def show(self, **kwargs):\n\t        return f\"{self.v.show(**kwargs)}.rehash()\"\n\t    def instantiate(self, **kwargs):\n\t        return self.v.execute(**kwargs).rehash()\n\t    def expected_active_fraction(self, **kwargs):\n\t        return .5\n", "@dataclass\n\tclass Eq(Symbolic):\n\t    l: SymbolicBHV\n\t    r: SymbolicBHV\n\t    def swap(self):\n\t        return Eq(self.r, self.l)\n\t    def reconstruct(self, l, r):\n\t        return Eq(l, r)\n\t    def show(self, toplevel=True, **kwargs):\n\t        brackets = not toplevel\n", "        kwargs[\"toplevel\"] = False\n\t        return \"(\"*brackets + f\"{self.l.show(**kwargs)} == {self.r.show(**kwargs)}\" + \")\"*brackets\n\t    def instantiate(self, **kwargs):\n\t        return self.l.execute(**kwargs) == self.r.execute(**kwargs)\n\t@dataclass\n\tclass Xor(SymbolicBHV):\n\t    l: SymbolicBHV\n\t    r: SymbolicBHV\n\t    def reconstruct(self, l, r):\n\t        return Xor(l, r)\n", "    def show(self, **kwargs):\n\t        brackets = not kwargs.get(\"toplevel\", False)\n\t        return \"(\"*brackets + f\"{self.l.show(**kwargs)} ^ {self.r.show(**kwargs)}\" + \")\"*brackets\n\t    def instantiate(self, **kwargs):\n\t        return self.l.execute(**kwargs) ^ self.r.execute(**kwargs)\n\t    def reduce(self, **kwargs):\n\t        if self.l == self.ONE:\n\t            return ~self.r\n\t        elif self.r == self.ONE:\n\t            return ~self.l\n", "        elif self.l == self.ZERO:\n\t            return self.r\n\t        elif self.r == self.ZERO:\n\t            return self.l\n\t        elif self.l == self.r:\n\t            return self.ZERO\n\t        elif self.l == ~self.r or ~self.l == self.r:\n\t            return self.ONE\n\t        elif isinstance(self.l, Invert) and isinstance(self.r, Invert):\n\t            return Xor(self.l.v, self.r.v)\n", "        elif isinstance(self.l, And) and isinstance(self.r, And):\n\t            if self.l.l == self.r.l: return And(self.l.l, Xor(self.l.r, self.r.r))\n\t            elif self.l.l == self.r.r: return And(self.l.l, Xor(self.l.r, self.r.l))\n\t            elif self.l.r == self.r.l: return And(self.l.r, Xor(self.l.l, self.r.r))\n\t            elif self.l.r == self.r.r: return And(self.l.r, Xor(self.l.l, self.r.l))\n\t    def expected_active_fraction(self, **kwargs):\n\t        afl = self.l.expected_active_fraction(**kwargs)\n\t        afr = self.r.expected_active_fraction(**kwargs)\n\t        return afl*(1. - afr) + (1. - afl)*afr\n\t@dataclass\n", "class And(SymbolicBHV):\n\t    l: SymbolicBHV\n\t    r: SymbolicBHV\n\t    def reconstruct(self, l, r):\n\t        return And(l, r)\n\t    def show(self, **kwargs):\n\t        brackets = not kwargs.get(\"toplevel\", False)\n\t        return \"(\"*brackets + f\"{self.l.show(**kwargs)} & {self.r.show(**kwargs)}\" + \")\"*brackets\n\t    def instantiate(self, **kwargs):\n\t        return self.l.execute(**kwargs) & self.r.execute(**kwargs)\n", "    def reduce(self, **kwargs):\n\t        if self.l == self.ZERO or self.r == self.ZERO:\n\t            return self.ZERO\n\t        elif self.l == self.ONE:\n\t            return self.r\n\t        elif self.r == self.ONE:\n\t            return self.l\n\t        elif isinstance(self.l, Invert) and self.l.v == self.r:\n\t            return self.ZERO\n\t        elif isinstance(self.r, Invert) and self.r.v == self.l:\n", "            return self.ZERO\n\t        elif isinstance(self.l, Invert) and isinstance(self.r, Invert):\n\t            return Invert(Or(self.l.v, self.r.v))\n\t    def expected_active_fraction(self, **kwargs):\n\t        afl = self.l.expected_active_fraction(**kwargs)\n\t        afr = self.r.expected_active_fraction(**kwargs)\n\t        return afl*afr\n\t@dataclass\n\tclass Or(SymbolicBHV):\n\t    l: SymbolicBHV\n", "    r: SymbolicBHV\n\t    def reconstruct(self, l, r):\n\t        return Or(l, r)\n\t    def show(self, **kwargs):\n\t        brackets = not kwargs.get(\"toplevel\", False)\n\t        return \"(\"*brackets + f\"{self.l.show(**kwargs)} | {self.r.show(**kwargs)}\" + \")\"*brackets\n\t    def instantiate(self, **kwargs):\n\t        return self.l.execute(**kwargs) | self.r.execute(**kwargs)\n\t    def reduce(self, **kwargs):\n\t        if self.l == self.ONE or self.r == self.ONE:\n", "            return self.ONE\n\t        elif self.l == self.ZERO:\n\t            return self.r\n\t        elif self.r == self.ZERO:\n\t            return self.l\n\t        elif isinstance(self.l, Invert) and self.l.v == self.r:\n\t            return self.ONE\n\t        elif isinstance(self.r, Invert) and self.r.v == self.l:\n\t            return self.ONE\n\t        elif isinstance(self.l, Invert) and isinstance(self.r, Invert):\n", "            return Invert(And(self.l.v, self.r.v))\n\t    def expected_active_fraction(self, **kwargs):\n\t        afl = self.l.expected_active_fraction(**kwargs)\n\t        afr = self.r.expected_active_fraction(**kwargs)\n\t        return 1. - ((1. - afl)*(1. - afr))\n\t@dataclass\n\tclass Invert(SymbolicBHV):\n\t    v: SymbolicBHV\n\t    def reconstruct(self, v):\n\t        return Invert(v)\n", "    def show(self, **kwargs):\n\t        brackets = not kwargs.get(\"toplevel\", False)\n\t        return \"(\"*brackets + f\"~{self.v.show(**kwargs)}\" + \")\"*brackets\n\t    def instantiate(self, **kwargs):\n\t        return ~self.v.execute(**kwargs)\n\t    def reduce(self, **kwargs):\n\t        if self.v == self.ONE:\n\t            return self.ZERO\n\t        elif self.v == self.ZERO:\n\t            return self.ONE\n", "        elif isinstance(self.v, Invert):\n\t            return self.v.v\n\t    def expected_active_fraction(self, **kwargs):\n\t        return 1. - self.v.expected_active_fraction(**kwargs)\n\t@dataclass\n\tclass Select(SymbolicBHV):\n\t    cond: SymbolicBHV\n\t    when1: SymbolicBHV\n\t    when0: SymbolicBHV\n\t    def reconstruct(self, c, w1, w0):\n", "        return Select(c, w1, w0)\n\t    def nodename(self, compact_select=False, **kwargs):\n\t        return f\"ON {self.cond.nodename()}\" if compact_select else super().nodename(**kwargs)\n\t    def labeled_children(self, compact_select=False, **kwargs):\n\t        return [(self.when1, \"1\"), (self.when0, \"0\")] if compact_select else super().labeled_children(**kwargs)\n\t    def show(self, **kwargs):\n\t        return f\"{self.cond.show(**kwargs)}.select({self.when1.show(**kwargs)}, {self.when0.show(**kwargs)})\"\n\t    def instantiate(self, **kwargs):\n\t        return self.cond.execute(**kwargs).select(self.when1.execute(**kwargs), self.when0.execute(**kwargs))\n\t    def internal_size(self):\n", "        return 3\n\t    def reduce(self, **kwargs):\n\t        expand_select_xor = kwargs.get(\"expand_select_xor\", False)\n\t        expand_select_and_or = kwargs.get(\"expand_select_and_or\", False)\n\t        if self.when1 == self.ONE and self.when0 == self.ZERO:\n\t            return self.cond\n\t        elif self.when1 == self.ZERO and self.when0 == self.ONE:\n\t            return ~self.cond\n\t        elif self.when0 == self.when1:\n\t            return self.when0\n", "        elif self.when1 == self.ONE:\n\t            return self.cond | self.when0\n\t        elif self.when1 == self.ZERO:\n\t            return ~self.cond & self.when0\n\t        elif self.when0 == self.ONE:\n\t            return ~self.cond | self.when1\n\t        elif self.when0 == self.ZERO:\n\t            return self.cond & self.when1\n\t        else:\n\t            if self.when1 == ~self.when0:\n", "                return self.cond ^ self.when0\n\t            elif self.when0 == ~self.when1:\n\t                return self.cond ^ self.when0\n\t            elif isinstance(self.when0, Invert) and isinstance(self.when1, Invert):\n\t                return ~Select(self.cond, self.when1.v, self.when0.v)\n\t            else:\n\t                if expand_select_xor:\n\t                    return self.when0 ^ (self.cond & (self.when0 ^ self.when1))\n\t                elif expand_select_and_or:\n\t                    return (self.cond & self.when1) | (~self.cond & self.when0)\n", "    def expected_active_fraction(self, **kwargs):\n\t        afc = self.cond.expected_active_fraction(**kwargs)\n\t        af1 = self.when1.expected_active_fraction(**kwargs)\n\t        af0 = self.when0.expected_active_fraction(**kwargs)\n\t        return afc*af1 + (1. - afc)*af0\n\t@dataclass\n\tclass ActiveFraction(Symbolic):\n\t    v: SymbolicBHV\n\t    def reconstruct(self, v):\n\t        return ActiveFraction(v)\n", "    def show(self, **kwargs):\n\t        return f\"{self.v.show(**kwargs)}.active_fraction()\"\n\t    def instantiate(self, **kwargs):\n\t        return self.v.execute(**kwargs).active_fraction()\n\t@dataclass\n\tclass BiasRel(Symbolic):\n\t    rel: SymbolicBHV\n\t    l: SymbolicBHV\n\t    r: SymbolicBHV\n\t    def reconstruct(self, rel, l, r):\n", "        return BiasRel(rel, l, r)\n\t    def show(self, **kwargs):\n\t        return f\"{self.l.show(**kwargs)}.bias_rel({self.r.show(**kwargs)}, {self.rel.show(**kwargs)})\"\n\t    def instantiate(self, **kwargs):\n\t        return self.l.execute(**kwargs).bias_rel(self.r.execute(**kwargs), self.rel.execute(**kwargs))\n\t@dataclass\n\tclass Related(Symbolic):\n\t    l: SymbolicBHV\n\t    r: SymbolicBHV\n\t    stdvs: float\n", "    def reconstruct(self, l, r):\n\t        return Related(l, r, self.stdvs)\n\t    def show(self, **kwargs):\n\t        return f\"{self.l.show(**kwargs)}.related({self.r.show(**kwargs)}, {self.stdvs})\"\n\t    def instantiate(self, **kwargs):\n\t        return self.l.execute(**kwargs).related(self.r.execute(**kwargs), self.stdvs)\n\t@dataclass\n\tclass Unrelated(Symbolic):\n\t    l: SymbolicBHV\n\t    r: SymbolicBHV\n", "    stdvs: float\n\t    def reconstruct(self, l, r):\n\t        return Unrelated(l, r, self.stdvs)\n\t    def show(self, **kwargs):\n\t        return f\"{self.l.show(**kwargs)}.unrelated({self.r.show(**kwargs)}, {self.stdvs})\"\n\t    def instantiate(self, **kwargs):\n\t        return self.l.execute(**kwargs).unrelated(self.r.execute(**kwargs), self.stdvs)\n"]}
{"filename": "tests/sym_laws.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, Var, Eq, Or, And, Xor, Invert, Majority\n\tfrom bhv.unification import unify\n\tfrom bhv.shared import stable_hashcode\n\tx = Var(\"x\")\n\ty = Var(\"y\")\n\tz = Var(\"z\")\n\tu = Var(\"u\")\n\tv = Var(\"v\")\n\tw = Var(\"w\")\n\tdef associative3(m): return Eq(m(x, u, m(y, u, z)), m(z, u, m(y, u, x)))\n", "def commutative3_1(m): return Eq(m(x, y, z), m(z, y, x))\n\tdef commutative3_2(m): return Eq(m(x, y, z), m(y, x, z))\n\tdef distributive3(m, w): return Eq(m(x, y, w(u, v, z)), w(m(x, y, u), m(x, y, v), z))\n\tdef associative(m): return Eq(m(m(x, y), z), m(x, m(y, z))).named(f\"{m.__name__} associative\")\n\tdef commutative(m): return Eq(m(x, y), m(y, x)).named(f\"{m.__name__} commutative\")\n\tdef idempotent(m): return Eq(m(x, x), x).named(f\"{m.__name__} idempotent\")\n\tdef self_inverse(m, u): return Eq(m(x, x), u).named(f\"{m.__name__} self inverse {u}\")\n\tdef involutive(f): return Eq(f(f(x)), x).named(f\"{f.__name__} involutive\")\n\tdef equals(f, a, b): return Eq(f(a), b).named(f\"{f.__name__}({a}) equals {b}\")\n\tdef right_unit(m, u): return Eq(m(x, u), x).named(f\"{m.__name__} right unit {u}\")\n", "def right_absorbing(m, z): return Eq(m(x, z), z).named(f\"{m.__name__} right absorbing {z}\")\n\tdef absorptive(m, w): return Eq(m(x, w(x, y)), x).named(f\"{m.__name__} absorbs w.r.t. {w.__name__}\")\n\tdef distributive(m, w): return Eq(m(x, w(y, z)), w(m(x, y), m(x, z))).named(f\"{m.__name__} distributes over {w.__name__}\")\n\tdef demorgan(f, m, w): return Eq(f(m(x, y)), w(f(x), f(y))).named(f\"De Morgan {f.__name__} over {m.__name__}, and {m.__name__}\")\n\tdef drop_left(f, m): return Eq(f(m(x, y)), m(f(x), y)).named(f\"Drop {f.__name__} left into {m.__name__}\")\n\tdef complement(m, f, z): return Eq(m(x, f(x)), z).named(f\"Complement by {f.__name__} under {m.__name__} is {z}\")\n\tdef propagate(f, m): return Eq(f(m(x)), m(f(x)))\n\tdef propagate2(f, m): return Eq(f(m(x, y)), m(f(x), f(y)))\n\tdef propagate3(f, m): return Eq(f(m(x, y, z)), m(f(x), f(y), f(z)))\n\tdef expand_single_inner(f, k, m, w): return Eq(k(x, y), m(w(x, f(y)), w(f(x), y)))\n", "def expand_single_outer(f, k, m, w): return Eq(k(x, y), m(w(x, y), f(m(x, y))))\n\tdef determinism(f): return Eq(f(x), f(x))\n\tdef extensionality(f, g): return Eq(f(x), g(x))\n\tdef extensionality2(f, g): return Eq(f(x, y), g(x, y))\n\tdef extensionality3(f, g): return Eq(f(x, y, z), g(x, y, z))\n\tdef extensionality4(f, g): return Eq(f(x, y, z, u), g(x, y, z, u))\n\tdef extensionality5(f, g): return Eq(f(x, y, z, u, v), g(x, y, z, u, v))\n\tdef extensionality6(f, g): return Eq(f(x, y, z, u, v, w), g(x, y, z, u, v, w))\n\tdef extensionality7(f, g): return Eq(f(x, y, z, u, v, w, r), g(x, y, z, u, v, w, r))\n\tdef extensionalityN(f, g): return Eq(f(xs), g(xs))\n", "def encode_decode(enc, dec): return Eq(x, dec(enc(x)))\n\tdef invariant_under(f, p): return Eq(f(x), f(p(x))).named(f\"{f.__name__} is invariant under {p.__name__}\")\n\tdef invariant_under2(f, p): return Eq(f(x, y), f(p(x), p(y))).named(f\"{f.__name__} is invariant under {p.__name__}\")\n\tdef identity(f): return Eq(f(x), x)\n\tdef invariant2(m): return Eq(m(x, y), y)\n\tdef invariant3(m): return Eq(m(x, y, z), z)\n\tdef invariant3_1(m): return Eq(m(x, x, z), x)\n\tdef invariant3_2(m): return Eq(m(x, x, z), z)\n\tdef lattice(join): return [associative(join), commutative(join), idempotent(join)]\n\tdef bounded_lattice(join, top, bot): return lattice(join) + [right_unit(join, bot), right_absorbing(join, top)]\n", "def xor_props(xor_, bot): return [associative(xor_), commutative(xor_), self_inverse(xor_, bot), right_unit(xor_, bot)]\n\tdef not_props(not_, bot, top): return [involutive(not_), equals(not_, top, bot), equals(not_, bot, top)]\n\tdef or_and_props(or_, and_): return [distributive(or_, and_), distributive(and_, or_), absorptive(or_, and_), absorptive(and_, or_)]\n\tdef gf2(add, mul, one, zero):\n\t    return [\n\t        right_unit(add, zero),\n\t        right_unit(mul, one),\n\t        associative(add), commutative(add),\n\t        associative(mul), commutative(mul),\n\t        idempotent(mul),\n", "        self_inverse(add, zero),\n\t        distributive(mul, add)\n\t    ]\n\tdef maj3_inv(maj3, inv):\n\t    return [\n\t        commutative3_1(maj3),\n\t        commutative3_2(maj3),\n\t        invariant3_1(maj3),\n\t        invariant3_2(maj3),\n\t        associative3(maj3),\n", "        distributive3(maj3, maj3),\n\t        propagate3(inv, maj3)\n\t    ]\n\tdef boolean_algebra(conj, disj, inv, zero, one):\n\t    return [\n\t        right_unit(disj, zero),\n\t        right_unit(conj, one),\n\t        commutative(conj),\n\t        commutative(disj),\n\t        distributive(conj, disj),\n", "        distributive(disj, conj),\n\t        associative(conj),\n\t        associative(disj),\n\t        complement(disj, inv, one),\n\t        complement(conj, inv, zero),\n\t    ]\n\tdef bhv_props():\n\t    extra = [\n\t        demorgan(Invert, Or, And),\n\t        demorgan(Invert, And, Or),\n", "        drop_left(Invert, Xor),\n\t        expand_single_inner(Invert, Xor, Or, And),\n\t        expand_single_outer(Invert, Xor, And, Or),\n\t        distributive(And, Xor),\n\t        complement(Xor, Invert, BHV.ONE),\n\t        invariant_under2(Xor, Invert),\n\t        Eq(x ^ (x & y), x & ~y),\n\t        Eq(x ^ (~x & y), x | y),\n\t        Eq((x & y) ^ (x & z), x & (y ^ z)),\n\t    ]\n", "    return (\n\t        bounded_lattice(And, BHV.ZERO, BHV.ONE) +\n\t        bounded_lattice(Or, BHV.ONE, BHV.ZERO) +\n\t        xor_props(Xor, BHV.ZERO) +\n\t        not_props(Invert, BHV.ZERO, BHV.ONE) +\n\t        or_and_props(Or, And) +\n\t        gf2(Xor, And, BHV.ONE, BHV.ZERO) +\n\t        # maj3_inv(majority3, Invert) +\n\t        boolean_algebra(And, Or, Invert, BHV.ZERO, BHV.ONE) +\n\t        extra)\n", "props = bhv_props()\n\tprops = [p.swap() if p.r.size() > p.l.size() else p for p in props]\n\tprops = list({stable_hashcode(p): p for p in props}.values())\n\tprops.sort(key=lambda p: (p.r.size() - p.l.size()) or (len(p.r.vars()) - len(p.l.vars())))\n\tsep = next(filter(lambda p: (p.r.size() - p.l.size()) >= 0, props))\n\tprops = props[:props.index(sep)]\n\tdef search(e):\n\t    fvars = set(e.vars())\n\t    for prop in props:\n\t        bindings = unify(e, prop.l)\n", "        if bindings and not set(bindings) & fvars:\n\t            print(\"applying\", prop.name, \"to\", e.show())\n\t            return prop.r.substitute(bindings)\n\t    return None\n\tdef rec(x):\n\t    cs = x.children()\n\t    for i in range(len(cs)):\n\t        res_c = search(cs[i])\n\t        if res_c is None:\n\t            continue\n", "        else:\n\t            cs[i] = res_c\n\t            return x.reconstruct(*cs)\n\t    for i in range(len(cs)):\n\t        res_c = rec(cs[i])\n\t        if res_c is None:\n\t            continue\n\t        else:\n\t            cs[i] = res_c\n\t            return x.reconstruct(*cs)\n", "def greedy(initial, iters=100):\n\t    e = initial\n\t    for i in range(iters):\n\t        res_e = search(e)\n\t        if res_e is not None:\n\t            e = res_e\n\t        else:\n\t            rec_e = rec(e)\n\t            if rec_e is not None:\n\t                e = rec_e\n", "            else:\n\t                print(\"early\", i)\n\t                return e\n\t    return e\n\tif __name__ == '__main__':\n\t    x1 = Var(\"x1\")\n\t    teste1 = (~(~(x1))) ^ (~x1 & BHV.rand())\n\t    print(greedy(teste1).show())\n\t    teste2 = ~(x1 ^ BHV.ZERO)\n\t    print(greedy(teste2).show())\n"]}
{"filename": "tests/fiestal.py", "chunked_list": ["import unittest\n\t# from bhv.np import NumPyPacked64BHV as BHV, DIMENSION\n\t# from bhv.pytorch import TorchPackedBHV as BHV, DIMENSION\n\t# from bhv.vanilla import VanillaBHV as BHV, DIMENSION\n\tfrom bhv.native import NativePackedBHV as BHV, DIMENSION\n\tfrom bhv.symbolic import Var, SymbolicBHV\n\tclass TestFeistal(unittest.TestCase):\n\t    def test_halves(self):\n\t        h1 = BHV.HALF\n\t        h2 = ~BHV.HALF\n", "        self.assertEqual(h1.active(), DIMENSION/2)\n\t        self.assertEqual(h2.active(), DIMENSION/2)\n\t        self.assertEqual(h1.hamming(h2), DIMENSION)\n\t        self.assertEqual(h1.swap_halves(), h2)\n\t        self.assertEqual(h2.swap_halves(), h1)\n\t        r = BHV.rand()\n\t        self.assertEqual(r.swap_halves().swap_halves(), r)\n\t        self.assertEqual(r.swap_halves().swap_halves().swap_halves(), r.swap_halves())\n\t    def test_keys(self):\n\t        x = BHV.rand()\n", "        ks = BHV.nrand(10)\n\t        x_enc_k = [x.feistal(k) for k in ks]\n\t        x_dec_k = [x_enc.feistal(k, inv=True) for x_enc, k in zip(x_enc_k, ks)]\n\t        for k, x_enc, x_dec in zip(ks, x_enc_k, x_dec_k):\n\t            self.assertEqual(x, x_dec, msg=\"inverse\")\n\t            self.assertNotEqual(x_enc, x_dec, msg=\"variant\")\n\t            self.assertNotEqual(x_enc, ~x_dec, msg=\"not opposite\")\n\t            self.assertNotEqual(x_enc, k, msg=\"not key\")\n\t            self.assertNotEqual(x_enc, BHV.HALF, msg=\"not half\")\n\t        for x_enc_i in x_enc_k:\n", "            eq = False\n\t            for x_enc_j in x_enc_k:\n\t                if x_enc_i == x_enc_j:\n\t                    if eq: self.fail(\"different keys produce the same result\")\n\t                    eq = True\n\t                else:\n\t                    self.assertTrue(x_enc_i.unrelated(x_enc_j))\n\tclass TestRehash(unittest.TestCase):\n\t    def test_deterministic(self):\n\t        v = BHV.rand()\n", "        h1 = v.rehash()\n\t        h2 = v.rehash()\n\t        self.assertEqual(h1, h2)\n\t    def test_random_different(self):\n\t        vs = BHV.nrand(10)\n\t        hs = [v.rehash() for v in vs]\n\t        for v in hs:\n\t            eq = False\n\t            for v_ in hs:\n\t                if v == v_:\n", "                    if eq: self.fail(\"different keys produce the same result\")\n\t                    eq = True\n\t                else:\n\t                    self.assertTrue(v.unrelated(v_))\n\t    def test_close_different(self):\n\t        seed = BHV.rand()\n\t        vs = [seed.flip_pow(8) for _ in range(10)]\n\t        for v in vs:\n\t            eq = False\n\t            for v_ in vs:\n", "                if v == v_:\n\t                    if eq: self.fail(\"flip_pow produced the same vector\")\n\t                    eq = True\n\t                else:\n\t                    self.assertTrue(v.related(v_))\n\t        hs = [v.rehash() for v in vs]\n\t        for v in hs:\n\t            eq = False\n\t            for v_ in hs:\n\t                if v == v_:\n", "                    if eq: self.fail(\"different keys produce the same result\")\n\t                    eq = True\n\t                else:\n\t                    self.assertTrue(v.unrelated(v_))\n\tif __name__ == '__main__':\n\t    unittest.main()\n"]}
{"filename": "tests/native_test.py", "chunked_list": ["from time import monotonic_ns\n\t# from bhv.np import NumPyBoolBHV as BHV\n\tfrom bhv.np import NumPyPacked64BHV as BHV\n\t# from bhv.native import CNativePackedBHV as BHV\n\tx = 0x7834d688d8827099\n\tfor i in range(5000000):\n\t    x = x + (x % 7)\n\tN = 201\n\tt0 = monotonic_ns()\n\trs = [BHV.rand() for _ in range(N)]\n", "t1 = monotonic_ns()\n\tprint(\"rand\", t1 - t0)\n\tps = [r.roll_words(42) for r in rs]\n\tt2 = monotonic_ns()\n\tprint(\"new permute\", t2 - t1)\n\tfor r, p in zip(rs, ps):\n\t    assert r == p.roll_words(-42)\n\tt3 = monotonic_ns()\n\tprint(\"rpermute eq\", t3 - t2)\n\tm = BHV.majority(rs)\n", "t4 = monotonic_ns()\n\tprint(\"majority\", t4 - t3)\n\tif False:\n\t    ds = [r ^ m for r in rs]\n\t    t5 = monotonic_ns()\n\t    print(\"xor\", t5 - t4)\n\t    qs = [d.active() for d in ds]\n\t    t6 = monotonic_ns()\n\t    print(\"active\", t6 - t5)\n\telse:\n", "    qs = [BHV.hamming(r, m) for r in rs]\n\t    t5 = monotonic_ns()\n\t    print(\"hamming\", t5 - t4)\n\tprint(sum(qs)/N)\n"]}
{"filename": "tests/composites.py", "chunked_list": ["import unittest\n\t# import torch\n\t# from bhv.np import NumPyPacked64BHV as BHV\n\tfrom bhv.vanilla import VanillaBHV as BHV\n\tDELTA = 0.015\n\tclass TestComposites(unittest.TestCase):\n\t    def test_flip_frac_on(self):\n\t        # self | BHV.random(flip_on_frac)\n\t        r = BHV.rand()\n\t        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n", "        self.assertEqual(r.flip_frac_on(.0), r)\n\t        self.assertEqual(r.flip_frac_on(1.), BHV.ONE)\n\t        for i in range(11):\n\t            k = i/10\n\t            ber = i/20\n\t            tweaked = r.flip_frac_on(k)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(r), ber, delta=DELTA)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ONE), .5 - ber, delta=DELTA)\n\t            self.assertAlmostEqual(BHV.ZERO.flip_frac_on(k).active_fraction(), k, delta=DELTA)\n\t    def test_flip_pow_on(self):\n", "        # self | ~BHV.rand2(flip_on_pow)\n\t        r = BHV.rand()\n\t        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n\t        for pow in range(20):\n\t            tweaked = r.flip_pow_on(pow)\n\t            expected = 2**(-pow - 2)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ONE), expected, delta=DELTA)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(r), .5 - expected, delta=DELTA)\n\t    def test_flip_frac_off(self):\n\t        # self & BHV.random(1. - flip_off_frac)\n", "        r = BHV.rand()\n\t        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n\t        self.assertEqual(r.flip_frac_off(.0), r)\n\t        self.assertEqual(r.flip_frac_off(1.), BHV.ZERO)\n\t        for i in range(11):\n\t            k = i/10\n\t            ber = i/20\n\t            tweaked = r.flip_frac_off(k)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(r), ber, delta=DELTA)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ZERO), .5 - ber, delta=DELTA)\n", "            self.assertAlmostEqual(BHV.ONE.flip_frac_off(k).active_fraction(), 1. - k, delta=DELTA)\n\t    def test_flip_pow_off(self):\n\t        # self & BHV.rand2(flip_off_pow)\n\t        r = BHV.rand()\n\t        self.assertLessEqual(r.zscore(), 4, \"rerun test\")\n\t        for i in range(20):\n\t            tweaked = r.flip_pow_off(i)\n\t            expected = 2**(-i - 2)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(BHV.ZERO), expected, delta=DELTA)\n\t            self.assertAlmostEqual(tweaked.bit_error_rate(r), .5 - expected, delta=DELTA)\n", "    def test_interpolate_flip_equivalence(self):\n\t        # r.select(flip_frac_on(l, f), flip_frac_off(l, f))\n\t        # equiv\n\t        # r.select_random(l, f)\n\t        a, b = BHV.nrand(2)\n\t        self.assertLessEqual(a.zscore(), 4, \"rerun test\")\n\t        self.assertLessEqual(b.zscore(), 4, \"rerun test\")\n\t        def interpolate_via_frac(l, r, f):\n\t            return r.select(l.flip_frac_on(f), l.flip_frac_off(f))\n\t        def interpolate(l, r, f):\n", "            return r.select_random(l, f)\n\t        for i in range(11):\n\t            aib = interpolate_via_frac(a, b, i/10)\n\t            aib_ref = interpolate(a, b, i/10)\n\t            self.assertLessEqual(aib.zscore(), 4)\n\t            self.assertAlmostEqual(aib.bit_error_rate(a), aib_ref.bit_error_rate(a), delta=DELTA)\n\t            self.assertAlmostEqual(aib.bit_error_rate(b), aib_ref.bit_error_rate(b), delta=DELTA)\n\t    def test_interpolate_pow_equivalence(self):\n\t        a, b = BHV.nrand(2)\n\t        self.assertLessEqual(a.zscore(), 4, \"rerun test\")\n", "        self.assertLessEqual(b.zscore(), 4, \"rerun test\")\n\t        def interpolatep(l, r, p):\n\t            if p > 0:\n\t                return r.select_rand2(l, p)\n\t            else:\n\t                return l.select_rand2(r, -p)\n\t        for i in range(-20, 20):\n\t            aib = interpolatep(a, b, i)\n\t            assert aib.zscore() < 4\n\t            expected = .5 - 2**(-abs(i) - 2) if i < 0 else 2**(-abs(i) - 2)\n", "            self.assertAlmostEqual(aib.bit_error_rate(a), expected, delta=DELTA)\n\t            self.assertAlmostEqual(aib.bit_error_rate(b), .5 - expected, delta=DELTA)\n\tif __name__ == '__main__':\n\t    unittest.main()\n"]}
{"filename": "tests/embedding.py", "chunked_list": ["import unittest\n\tfrom bhv.np import NumPyPacked64BHV as BHV\n\tfrom bhv.embedding import Random, InterpolateBetween\n\tclass TestRandomEmbedding(unittest.TestCase):\n\t    def test_random(self):\n\t        a, b, c = \"abc\"\n\t        embedding = Random(BHV)\n\t        hva = embedding.forward(a)\n\t        hvb = embedding.forward(b)\n\t        self.assertTrue(hva.unrelated(hvb))\n", "        hva_ = embedding.forward(a)\n\t        self.assertEqual(hva, hva_)\n\t        hvq = BHV.rand()\n\t        self.assertIsNone(embedding.back(hvq))\n\t        self.assertEqual(b, embedding.back(hvb))\n\tclass TestInterpolateLineEmbedding(unittest.TestCase):\n\t    def test_internal(self):\n\t        embedding = InterpolateBetween(BHV)\n\t        a, b, c = .1, .5, .68\n\t        self.assertAlmostEqual(a, embedding.back(embedding.forward(a)), 2)\n", "if __name__ == '__main__':\n\t    unittest.main()\n"]}
{"filename": "tests/test_pytorch.py", "chunked_list": ["import unittest\n\timport torch\n\tfrom bhv.pytorch import TorchPackedBHV, TorchBoolBHV\n\tclass TestTorchBoolBHV(unittest.TestCase):\n\t    def test_basic(self):\n\t        self.assertTrue(True)\n\tclass TestTorchBHVConversion(unittest.TestCase):\n\t    def test_random(self):\n\t        rp = TorchPackedBHV.rand()\n\t        self.assertTrue(torch.equal(rp.data, rp.unpack().pack().data))\n", "        ru = TorchBoolBHV.rand()\n\t        self.assertTrue(torch.equal(ru.data, ru.pack().unpack().data))\n\t    def test_extrema(self):\n\t        self.assertTrue(torch.equal(TorchPackedBHV.ZERO.unpack().data, TorchBoolBHV.ZERO.data))\n\t        self.assertTrue(torch.equal(TorchPackedBHV.ZERO.data, TorchBoolBHV.ZERO.pack().data))\n\t        self.assertTrue(torch.equal(TorchPackedBHV.ONE.unpack().data, TorchBoolBHV.ONE.data))\n\t        self.assertTrue(torch.equal(TorchPackedBHV.ONE.data, TorchBoolBHV.ONE.pack().data))\n\tif __name__ == '__main__':\n\t    unittest.main()\n"]}
{"filename": "tests/lsynthesis.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, Var\n\tfrom bhv.slice import Slice\n\tdef tos(i, b): return bin(i)[2:].rjust(b, '0')\n\tdef tomask(s): return [x == '1' for x in s]\n\tdef frommask(m): return ''.join(\"01\"[x] for x in m)\n\tdef bitconfigs(n): return [tomask(tos(i, n)) for i in range(2**n)]\n\tnames = [Var(\"a\"), Var(\"b\"), Var(\"c\")]\n\tconfigurations = bitconfigs(3)\n\toperators = 0\n\tfor target in bitconfigs(8):\n", "    f = BHV.synth(names, target)\n\t    f_ = f.simplify()\n\t    # print(f_.show())\n\t    retrieved = [f_.execute(vars=dict(a=Slice(a), b=Slice(b), c=Slice(c)), bhv=Slice).b for a, b, c in configurations]\n\t    operators += f_.size()\n\t    # print(frommask(target))\n\t    # print(frommask(retrieved))\n\t    assert target == retrieved\n\tprint(\"average operators:\", operators/256)\n\tprint(tos(184, 8), BHV.synth(names, tomask(tos(184, 8))).simplify().show())\n", "print(tos(110, 8), BHV.synth(names, tomask(tos(110, 8))).simplify().show())\n\tprint(tos(90, 8), BHV.synth(names, tomask(tos(90, 8))).simplify().show())\n\tprint(tos(30, 8), BHV.synth(names, tomask(tos(30, 8))).simplify().show())\n\tprint(tos(22, 8), BHV.synth(names, tomask(tos(22, 8))).simplify().show())\n\tmaj3 = [sum(c) >= 2 for c in configurations]\n\tprint(frommask(maj3), BHV.synth(names, maj3).simplify().show())\n"]}
{"filename": "tests/metrics.py", "chunked_list": ["from bhv.np import NumPyPacked64BHV as BHV\n\ta = BHV.rand()\n\tfor i in range(0, 21):\n\t    p = i/20\n\t    b = a.flip_frac(p)\n\t    print(p)\n\t    print(\"ber\", 1. - a.bit_error_rate(b))\n\t    print(\"cos\", a.cosine(b))\n\t    print(\"jac\", a.jaccard(b))\n\t    print(\"mut\", a.mutual_information(b, distance=True))\n", "    print(\"tve\", a.tversky(b, .5, .5))\n"]}
{"filename": "tests/laws.py", "chunked_list": ["from time import monotonic\n\tfrom itertools import product, groupby\n\tfrom bhv.abstract import AbstractBHV, DIMENSION\n\tfrom bhv.native import NativePackedBHV\n\tfrom bhv.np import NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV\n\t# from bhv.pytorch import TorchBoolBHV, TorchPackedBHV\n\tfrom bhv.vanilla import VanillaBHV\n\tdef associative(m): return lambda x, y, z: m(m(x, y), z) == m(x, m(y, z))\n\tdef associative3(m): return lambda x, y, z, u: m(x, u, m(y, u, z)) == m(z, u, m(y, u, x))\n\tdef commutative(m): return lambda x, y: m(x, y) == m(y, x)\n", "def commutative3(m): return lambda x, y, z: m(x, y, z) == m(y, x, z) == m(z, y, x)\n\tdef idempotent(m): return lambda x: m(x, x) == x\n\tdef self_inverse(m, u): return lambda x: m(x, x) == u\n\tdef self_inverse_op(f): return lambda x: f(f(x)) == x\n\tdef equals(f, a, b): return lambda: f(a) == b\n\tdef right_unit(m, u): return lambda x: m(x, u) == x\n\tdef right_absorbing(m, z): return lambda x: m(x, z) == z\n\tdef absorptive(m, w): return lambda x, y: m(x, w(x, y)) == x\n\tdef distributive(m, w): return lambda x, y, z: m(x, w(y, z)) == w(m(x, y), m(x, z))\n\tdef distributive3(m, w): return lambda x, y, z, u, v: m(x, y, w(u, v, z)) == w(m(x, y, u), m(x, y, v), z)\n", "def demorgan(f, m, w): return lambda x, y: f(m(x, y)) == w(f(x), f(y))\n\tdef drop_left(f, m): return lambda x, y: f(m(x, y)) == m(f(x), y)\n\tdef propagate(f, m): return lambda x: f(m(x)) == m(f(x))\n\tdef propagate2(f, m): return lambda x, y: f(m(x, y)) == m(f(x), f(y))\n\tdef propagate3(f, m): return lambda x, y, z: f(m(x, y, z)) == m(f(x), f(y), f(z))\n\tdef expand_single_inner(f, k, m, w): return lambda x, y: k(x, y) == m(w(x, f(y)), w(f(x), y))\n\tdef expand_single_outer(f, k, m, w): return lambda x, y: k(x, y) == m(w(x, y), f(m(x, y)))\n\tdef determinism(f): return lambda x: f(x) == f(x)\n\tdef extensionality(f, g): return lambda x: f(x) == g(x)\n\tdef extensionality2(f, g): return lambda x, y: f(x, y) == g(x, y)\n", "def extensionality3(f, g): return lambda x, y, z: f(x, y, z) == g(x, y, z)\n\tdef extensionality4(f, g): return lambda x, y, z, u: f(x, y, z, u) == g(x, y, z, u)\n\tdef extensionality5(f, g): return lambda x, y, z, u, v: f(x, y, z, u, v) == g(x, y, z, u, v)\n\tdef extensionality6(f, g): return lambda x, y, z, u, v, w: f(x, y, z, u, v, w) == g(x, y, z, u, v, w)\n\tdef extensionality7(f, g): return lambda x, y, z, u, v, w, r: f(x, y, z, u, v, w, r) == g(x, y, z, u, v, w, r)\n\tdef extensionality9(f, g): return lambda x, y, z, u, v, w, r, i, j: f(x, y, z, u, v, w, r, i, j) == g(x, y, z, u, v, w, r, i, j)\n\tdef extensionalityN(f, g): return lambda xs: f(xs) == g(xs)\n\tdef encode_decode(enc, dec): return lambda x: x == dec(enc(x))\n\tdef invariant_under(f, p): return lambda x: f(x) == f(p(x))\n\tdef invariant_under2(f, p): return lambda x, y: f(x, y) == f(p(x), p(y))\n", "def identity(f): return lambda x: f(x) == x\n\tdef invariant2(m): return lambda x, y: m(x, y) == y\n\tdef invariant3(m): return lambda x, y, z: m(x, y, z) == z\n\tdef invariant3_2(m): return lambda x, y, z: m(x, y, z) == y == z\n\tdef complement(m, f, z): return lambda x: m(x, f(x)) == z\n\tdef transport(law, l, r): return lambda f, g: law(f, lambda x: r(g(l(x))))\n\tdef transport2(law, l, r): return lambda f, g: law(f, lambda x, y: r(g(l(x), l(y))))\n\tdef transport3(law, l, r): return lambda f, g: law(f, lambda x, y, z: r(g(l(x), l(y), l(z))))\n\tdef assume2(law, p): return lambda f: lambda x, y: True if p(x, y) else law(f)(x, y)\n\tdef assume3(law, p): return lambda f: lambda x, y, z: True if p(x, y, z) else law(f)(x, y, z)\n", "def lattice(join): return [associative(join), commutative(join), idempotent(join)]\n\tdef bounded_lattice(join, top, bot): return lattice(join) + [right_unit(join, bot), right_absorbing(join, top)]\n\tdef xor_props(xor_, bot): return [associative(xor_), commutative(xor_), self_inverse(xor_, bot), right_unit(xor_, bot)]\n\tdef not_props(not_, bot, top): return [self_inverse_op(not_), equals(not_, top, bot), equals(not_, bot, top)]\n\tdef or_and_props(or_, and_): return [distributive(or_, and_), distributive(and_, or_), absorptive(or_, and_), absorptive(and_, or_)]\n\tdef gf2(add, mul, one, zero):\n\t    return [\n\t        right_unit(add, zero),\n\t        right_unit(mul, one),\n\t        associative(add), commutative(add),\n", "        associative(mul), commutative(mul),\n\t        idempotent(mul),\n\t        self_inverse(add, zero),\n\t        distributive(mul, add)\n\t    ]\n\tdef maj3_inv(maj3, inv):\n\t    return [\n\t        commutative3(maj3),\n\t        assume3(invariant3_2(lambda x, y, z: maj3(z, y, x)), lambda x, y, z: x == y),\n\t        assume3(invariant3(maj3), lambda x, y, z: x == inv(y)),\n", "        associative3(maj3),\n\t        distributive3(maj3, maj3),\n\t        propagate3(inv, maj3)\n\t    ]\n\tdef boolean_algebra(conj, disj, inv, zero, one):\n\t    return [\n\t        right_unit(disj, zero),\n\t        right_unit(conj, one),\n\t        commutative(conj),\n\t        commutative(disj),\n", "        distributive(conj, disj),\n\t        distributive(disj, conj),\n\t        associative(conj),\n\t        associative(disj),\n\t        complement(disj, inv, one),\n\t        complement(conj, inv, zero),\n\t    ]\n\tdef permute_props(permute):\n\t    π, τ, σ = 42, 13, 39\n\t    Π, Τ, Σ = lambda x: permute(x, π), lambda x: permute(x, τ), lambda x: permute(x, σ)\n", "    Πinv, Τinv, Σinv = lambda x: permute(x, -π), lambda x: permute(x, -τ), lambda x: permute(x, -σ)\n\t    return [\n\t        extensionality(lambda x: Π(Τ(x)), lambda x: permute(x, (τ, π))),\n\t        extensionality(lambda x: Π(Τ(x)), lambda x: permute(x, (0, τ, 0, π, 0))),\n\t        extensionality(lambda x: Π(Σ(Τ(x))), lambda x: permute(x, (τ, σ, π))),\n\t        identity(lambda x: permute(x, 0)),\n\t        identity(lambda x: Πinv(Π(x))),\n\t        identity(lambda x: Τinv(Τ(x))),\n\t        identity(lambda x: Σ(Σinv(x))),\n\t    ]\n", "def bhv_props(impl: AbstractBHV):\n\t    Π, Τ, Σ = lambda x: impl.permute(x, 42), lambda x: impl.permute(x, 13), lambda x: impl.permute(x, -39)\n\t    extra = [\n\t        demorgan(impl.__invert__, impl.__or__, impl.__and__),\n\t        demorgan(impl.__invert__, impl.__and__, impl.__or__),\n\t        drop_left(impl.__invert__, impl.__xor__),\n\t        expand_single_inner(impl.__invert__, impl.__xor__, impl.__or__, impl.__and__),\n\t        expand_single_outer(impl.__invert__, impl.__xor__, impl.__and__, impl.__or__),\n\t        distributive(impl.__and__, impl.__xor__),\n\t        propagate(Π, impl.__invert__),\n", "        propagate2(Π, impl.__xor__),\n\t        propagate2(Π, impl.__and__),\n\t        propagate2(Π, impl.__or__),\n\t        propagate3(Π, impl.majority3),\n\t        complement(impl.__xor__, impl.__invert__, impl.ONE),\n\t        invariant_under2(impl.__xor__, impl.__invert__),\n\t        lambda a, b: a ^ (a & b) == a & ~b,\n\t        lambda a, b: a ^ (~a & b) == a | b\n\t    ]\n\t    return (\n", "        bounded_lattice(impl.__and__, impl.ZERO, impl.ONE) +\n\t        bounded_lattice(impl.__or__, impl.ONE, impl.ZERO) +\n\t        xor_props(impl.__xor__, impl.ZERO) +\n\t        not_props(impl.__invert__, impl.ZERO, impl.ONE) +\n\t        or_and_props(impl.__or__, impl.__and__) +\n\t        gf2(impl.__xor__, impl.__and__, impl.ONE, impl.ZERO) +\n\t        maj3_inv(impl.majority3, impl.__invert__) +\n\t        boolean_algebra(impl.__and__, impl.__or__, impl.__invert__, impl.ZERO, impl.ONE) +\n\t        permute_props(impl.permute) +\n\t        bhv_conv_metrics(Π) +\n", "        extra)\n\tdef bhv_conv_ops(dom: AbstractBHV, codom: AbstractBHV, l, r):\n\t    return [\n\t        transport(extensionality, l, r)(dom.__invert__, codom.__invert__),\n\t        transport2(extensionality2, l, r)(dom.__or__, codom.__or__),\n\t        transport2(extensionality2, l, r)(dom.__and__, codom.__and__),\n\t        transport2(extensionality2, l, r)(dom.__xor__, codom.__xor__),\n\t        transport3(extensionality3, l, r)(dom.select, codom.select),\n\t    ]\n\tdef bhv_conv_metrics(under):\n", "    return [\n\t        invariant_under(lambda x: x.active(), under),\n\t        invariant_under(lambda x: x.active_fraction(), under),\n\t        invariant_under2(lambda x, y: x.hamming(y), under),\n\t        assume2(invariant_under2(lambda x, y: x.cosine(y), under), lambda x, y: x.active() != 0 and y.active() != 0),\n\t        assume2(invariant_under2(lambda x, y: x.jaccard(y), under), lambda x, y: x.active() != 0 or y.active() != 0),\n\t        invariant_under2(lambda x, y: x.std_apart(y), under),\n\t        invariant_under2(lambda x, y: x.related(y), under),\n\t        invariant_under2(lambda x, y: x.bit_error_rate(y), under),\n\t        invariant_under2(lambda x, y: x.mutual_information(y), under),\n", "    ]\n\tdef run_for(impl: AbstractBHV, ts):\n\t    argts = {}\n\t    for t in ts:\n\t        arity = t.__code__.co_argcount\n\t        argts.setdefault(arity, []).append(t)\n\t    max_depth = max(argts.keys())\n\t    extrema = [impl.ZERO, impl.ONE]\n\t    shared = extrema + impl.nrand(3)\n\t    collections = [shared + impl.nrand(1) for d in range(max_depth + 1)]\n", "    def rec(args, depth):\n\t        for tn in argts.get(depth, []):\n\t            assert tn(*args), f\"property {tn.__qualname__} failed on {args} using implementation {impl.__name__}\"\n\t        if depth <= max_depth:\n\t            for x in collections[depth]:\n\t                rec(args + (x,), depth + 1)\n\t    rec((), 0)\n\tdef run():\n\t    # all_implementations = [VanillaBHV, NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV, TorchBoolBHV, TorchPackedBHV, NativePackedBHV]\n\t    all_implementations = [VanillaBHV, NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV, NativePackedBHV]\n", "    for impl in all_implementations:\n\t        print(f\"Testing {impl.__name__}...\")\n\t        t0 = monotonic()\n\t        run_for(impl, bhv_props(impl))\n\t        t = monotonic() - t0\n\t        print(f\"took ({t:.3} s)\")\n\t    print(f\"Testing packing and unpacking NumPyBoolBHV...\")\n\t    run_for(NumPyBoolBHV, [encode_decode(NumPyBoolBHV.pack64, NumPyPacked64BHV.unpack)])\n\t    print(f\"Testing packing and unpacking NumPyPacked64BHV...\")\n\t    run_for(NumPyPacked64BHV, [encode_decode(NumPyPacked64BHV.unpack, NumPyBoolBHV.pack64)])\n", "    print(\"Testing operators equal between NumPyBoolBHV and NumPyPacked64BHV\")\n\t    run_for(NumPyBoolBHV, bhv_conv_ops(NumPyBoolBHV, NumPyPacked64BHV, NumPyBoolBHV.pack64, NumPyPacked64BHV.unpack))\n\t    print(\"Testing metrics invariant under pack64\")\n\t    run_for(NumPyBoolBHV, bhv_conv_metrics(NumPyBoolBHV.pack64))\n\t    # run_for(TorchBoolBHV, bhv_conv_metrics(TorchBoolBHV.pack))\n\t    print(\"Testing large unbalanced majority\")\n\t    rs = [~v for v in NumPyPacked64BHV.nrand2(1001, 3)]\n\t    rs_ = [r.unpack() for r in rs]\n\t    assert NumPyPacked64BHV.majority(rs) == NumPyBoolBHV.majority(rs_).pack64()\n\t    # rs = [~v for v in TorchPackedBHV.nrand2(1001, 3)]\n", "    # rs_ = [r.unpack() for r in rs]\n\t    # assert TorchPackedBHV.majority(rs) == TorchBoolBHV.majority(rs_).pack()\n\t    print(\"Testing bits and bytes\")\n\t    for impl in all_implementations:\n\t        r = impl.rand()\n\t        rb = r.to_bytes()\n\t        rbits = list(r.bits())\n\t        rstr = r.bitstring()\n\t        for impl_ in all_implementations:\n\t            assert impl_.from_bytes(rb).to_bytes() == rb, f\"{impl}, {impl_}\"\n", "            assert list(impl_.from_bitstream(rbits).bits()) == rbits, f\"{impl}, {impl_}\"\n\t            assert impl_.from_bytes(rb).bitstring() == rstr, f\"{impl}, {impl_}\"\n\t            assert impl_.from_bitstring(rstr).bitstring() == rstr, f\"{impl}, {impl_}\"\n\t    print(\"Testing word-level roll equivalence\")\n\t    rs_np = NumPyPacked64BHV.nrand(10)\n\t    rs_native = [NativePackedBHV.from_bytes(r.to_bytes()) for r in rs_np]\n\t    word_rot_pos_np = [r.roll_words(12) for r in rs_np]\n\t    word_rot_pos_native = [r.roll_words(12) for r in rs_native]\n\t    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_rot_pos_np, word_rot_pos_native)]\n\t    word_rot_neg_np = [r.roll_words(-12) for r in rs_np]\n", "    word_rot_neg_native = [r.roll_words(-12) for r in rs_native]\n\t    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_rot_neg_np, word_rot_neg_native)]\n\t    word_bit_rot_pos_np = [r.roll_word_bits(12) for r in rs_np]\n\t    word_bit_rot_pos_native = [r.roll_word_bits(12) for r in rs_native]\n\t    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_bit_rot_pos_np, word_bit_rot_pos_native)]\n\t    word_bit_rot_neg_np = [r.roll_word_bits(-12) for r in rs_np]\n\t    word_bit_rot_neg_native = [r.roll_word_bits(-12) for r in rs_native]\n\t    assert [r == NumPyPacked64BHV.from_bytes(r_.to_bytes()) for r, r_ in zip(word_bit_rot_neg_np, word_bit_rot_neg_native)]\n\t    print(\"Testing NumPyPacked64BHV majority equivalence\")\n\t    run_for(NumPyPacked64BHV, [\n", "        extensionality3(NumPyPacked64BHV._majority3, lambda x, y, z: NumPyPacked64BHV._majority_via_unpacked([x, y, z])),\n\t        extensionality5(NumPyPacked64BHV._majority5, lambda x, y, z, u, v: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v])),\n\t        extensionality5(NumPyPacked64BHV._majority5_via_3, NumPyPacked64BHV._majority5),\n\t        # this is slow, obviously\n\t        # extensionality7(NumPyPacked64BHV._majority7_via_3, lambda x, y, z, u, v, w, r: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r])),\n\t        # extensionality7(NumPyPacked64BHV._majority7_via_ite, lambda x, y, z, u, v, w, r: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r])),\n\t        # extensionality7(NumPyPacked64BHV._majority7_via_3, lambda x, y, z, u, v, w, r: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r])),\n\t        # extensionality9(NumPyPacked64BHV._majority9_via_3, lambda x, y, z, u, v, w, r, i, j: NumPyPacked64BHV._majority_via_unpacked([x, y, z, u, v, w, r, i, j])),\n\t    ])\n\t    t0 = monotonic()\n", "    for s in range(3, 55, 2):\n\t        rs = NumPyPacked64BHV.nrand(s)\n\t        assert NumPyPacked64BHV.majority(rs) == NumPyPacked64BHV._majority_via_unpacked(rs), f\"mismatch for size {s}\"\n\t    t = monotonic() - t0\n\t    print(f\"took ({t:.3} s)\")\n\tif __name__ == '__main__':\n\t    run()\n"]}
{"filename": "tests/reconstruct_program.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, List, Var\n\tfrom bhv.vanilla import VanillaBHV\n\ta, b, c, d = Var(\"a\"), Var(\"b\"), Var(\"c\"), Var(\"d\")\n\tabc = BHV.majority([a, b, c]).named(\"test\")\n\ta1 = a.flip_frac_on(.1)\n\ta0 = a.flip_frac_off(.1)\n\tcq = c.select(a0, a1).named(\"mix\")\n\tb_d = b ^ d\n\tabc_d = abc ^ d\n\tcode = List([cq, b_d, abc_d]).named(\"O\").graphviz()#.show_program(name=\"run\", impl=\"VanillaBHV.\")\n", "# .simplify(expand_select_and_or=True)\n\t# print(code)\n\t# assert code == \"\"\"\n\t# def run(a, b, c, d):\n\t#     _0 = VanillaBHV.majority([a, b, c])\n\t#     _1 = _0 ^ d\n\t#     _2 = b ^ d\n\t#     _3 = VanillaBHV.random(0.2)\n\t#     _4 = a ^ _3\n\t#     _5 = a & _4\n", "#     _6 = ~c\n\t#     _7 = _6 & _5\n\t#     _8 = VanillaBHV.random(0.2)\n\t#     _9 = a ^ _3\n\t#     _10 = a | _4\n\t#     _11 = c & _10\n\t#     _12 = _11 | _7\n\t#     return [_12, _2, _1]\n\t# \"\"\".lstrip()\n"]}
{"filename": "tests/marshalling.py", "chunked_list": ["import io\n\tfrom time import monotonic_ns\n\tfrom bhv.abstract import AbstractBHV, DIMENSION\n\tfrom bhv.native import NativePackedBHV\n\tfrom bhv.np import NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV\n\t# from bhv.pytorch import TorchBoolBHV, TorchPackedBHV\n\tfrom bhv.vanilla import VanillaBHV\n\tfrom bhv.visualization import Image\n\tall_implementations = [VanillaBHV, NumPyBoolBHV, NumPyPacked8BHV, NumPyPacked64BHV, NativePackedBHV]\n\tN = 5\n", "for impl in all_implementations:\n\t    rs = impl.nrand(N)\n\t    print(impl.__name__)\n\t    print(\" binary\")\n\t    with io.BytesIO() as f:\n\t        t0 = monotonic_ns()\n\t        Image(rs).pbm(f, binary=True)\n\t        print(\"  serializing\", monotonic_ns() - t0)\n\t        contents = f.getvalue()\n\t    with io.BytesIO(contents) as f:\n", "        t0 = monotonic_ns()\n\t        rs_ = Image.load_pbm(f, impl, binary=True).hvs\n\t        print(\"  deserializing\", monotonic_ns() - t0)\n\t    assert len(rs) == len(rs_)\n\t    for r, r_ in zip(rs, rs_):\n\t        assert r == r_\n\t    print(\" string\")\n\t    with io.StringIO() as f:\n\t        t0 = monotonic_ns()\n\t        Image(rs).pbm(f, binary=False)\n", "        print(\"  serializing\", monotonic_ns() - t0)\n\t        string = f.getvalue()\n\t    with io.StringIO(string) as f:\n\t        t0 = monotonic_ns()\n\t        rs_ = Image.load_pbm(f, impl, binary=False).hvs\n\t        print(\"  deserializing\", monotonic_ns() - t0)\n\t    assert len(rs) == len(rs_)\n\t    for r, r_ in zip(rs, rs_):\n\t        assert r == r_\n"]}
{"filename": "tests/inspect_random.py", "chunked_list": ["from statistics import fmean, stdev\n\tfrom scipy.stats import kstest, shapiro, anderson, probplot\n\timport matplotlib\n\tmatplotlib.use(\"cairo\")\n\timport matplotlib.pyplot as plt\n\tfrom bhv.native import NativePackedBHV as BHV, DIMENSION\n\tN = 100_000\n\tdef test_unbiased_variance():\n\t    rs = BHV.nrand(N)\n\t    afs = [int(r.active()) for r in rs]\n", "    af = fmean(afs)\n\t    sd = stdev(afs)\n\t    mn = min(afs)\n\t    mx = max(afs)\n\t    print(af, sd, mn, mx)\n\t    print(shapiro(afs), kstest(afs, 'norm'), anderson(afs))\n\t    probplot(afs, dist=\"norm\", plot=plt)\n\t    with open(f\"rand_{BHV.__name__}.svg\", 'wb') as f:\n\t        plt.savefig(f, format=\"svg\")\n\t    with open(f\"rand_{BHV.__name__}.bin\", \"wb\") as f:\n", "        for r in rs:\n\t            f.write(r.to_bytes())\n\tdef test_unrelated():\n\t    rs = BHV.nrand(int(N**.5))\n\t    afs = [int(r.hamming(r_)) for r in rs for r_ in rs if r is not r_]\n\t    af = fmean(afs)\n\t    sd = stdev(afs)\n\t    mn = min(afs)\n\t    mx = max(afs)\n\t    print(af, sd, mn, mx)\n", "    print(shapiro(afs), kstest(afs, 'norm'), anderson(afs))\n\t    probplot(afs, dist=\"norm\", plot=plt)\n\t    with open(f\"hamming_{BHV.__name__}.svg\", 'wb') as f:\n\t        plt.savefig(f, format=\"svg\")\n\ttest_unbiased_variance()\n"]}
{"filename": "tests/sym.py", "chunked_list": ["from bhv.abstract import AbstractBHV\n\tfrom bhv.symbolic import Var, SymbolicBHV, Rand\n\tdef large_majority_plot():\n\t    print(\"digraph {\")\n\t    all_vars = [Var.shortname(i) for i in range(8, -1, -1)]\n\t    AbstractBHV.majority(all_vars).graphviz(structural=False, compact_select=True)\n\t    print(\"}\")\n\tdef active_fraction():\n\t    rfs = [1/2, 1/4, 3/4, 5/8, 3/8, 9/16, 11/16, 31/32, 61/128, 123/256]\n\t    for rf in rfs:\n", "        res = SymbolicBHV.synth_af(rf)\n\t        print(res.show())\n\t        print(*[r.nodename() for r in res.preorder() if not isinstance(r, Rand)])\n\t        assert rf == res.expected_active_fraction()\n\tdef mock(T, **fields):\n\t    return type(f\"Mocked{T.__name__}\", (T,), fields)\n\tif __name__ == '__main__':\n\t    print(SymbolicBHV.random(.25).select((Var(\"X\") & ~Var(\"Y\")), (Var(\"X\") | ~Var(\"Y\")))\n\t          .show(impl=\"SymbolicBHV.\", symbolic_var=True))\n\t    print(mock(SymbolicBHV, majority=vars(AbstractBHV)['majority']).majority([Var(\"X\"), Var(\"Y\")])\n", "          .show(random_id=True))\n"]}
{"filename": "tests/blocklsynth.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV as BHV, Var, List\n\tfrom bhv.slice import Slice\n\tfrom bhv.shared import bin_bitmask, nbs\n\tfrom string import ascii_lowercase\n\tfrom random import shuffle, sample, random, randrange\n\tfrom statistics import pstdev, fmean\n\tI = 8\n\tO = 16\n\tnames = [Var(x) for x in ascii_lowercase[:I]]\n\tfs = []\n", "for j in range(O):\n\t    target = [i % 2 == 0 for i in range(2**I)]\n\t    shuffle(target)\n\t    f = BHV.synth(names, target).simplify()\n\t    assert target == f.truth_assignments(names)\n\t    fs.append(f)\n\t# print([f.expected_active_fraction(vars={x: .5 for x in ascii_lowercase[:I]}) for f in fs])\n\t# print(List(\"O\", fs).show())\n\t# List(\"O\", fs).graphviz(structural=True)\n\tinitial = names\n", "layers = [initial]\n\t# sizes = [20, 20, 20, 20, O]\n\tsizes = [1]*30 + [O]\n\t# for size in sizes:\n\t#     layer = []\n\t#     for elem in range(size):\n\t#         r = random()\n\t#         i, j, k = sample(layers[-1], k=3)\n\t#\n\t#         layer.append(BHV.majority3(\n", "#                 i if random() < .666 else ~i,\n\t#                 j if random() < .666 else ~j,\n\t#                 k if random() < .666 else ~k))\n\t#\n\t#     layers.append(layer)\n\t# for size in sizes:\n\t#     layer = []\n\t#     for elem in range(size):\n\t#         r = random()\n\t#         if r < .75:\n", "#             i, j = sample(layers[-1], k=2)\n\t#             layer.append(i ^ j)\n\t#         else:\n\t#             i, = sample(layers[-1], k=1)\n\t#             layer.append(~i)\n\t#     layers.append(layer)\n\t# for size in sizes:\n\t#     layer = []\n\t#     for elem in range(size):\n\t#         i, j, k = sample(layers[-1], k=3)\n", "#         layer.append(BHV.select(i, ~j, k))\n\t#     layers.append(layer)\n\tprint([f.expected_active_fraction(vars={x: .5 for x in ascii_lowercase[:I]}) for f in layers[-1]])\n\tprint(List(layers[-1]).size())\n\t# List(\"O\", layers[-1]).graphviz(compact_select=False)\n\tfor fk in [fs, layers[-1]]:\n\t    truth_table = [fi.truth_assignments(names) for fi in fk]\n\t    truth_tables_sims = [[sum(a ^ a_ for a, a_ in zip(ta, ta_)) for ta_ in truth_table] for ta in truth_table]\n\t    mean_stdev = [(abs(.5 - fmean(diffs)/2**I), pstdev(diffs)/2**I) for diffs in truth_tables_sims]\n\t    print(max(x for x, _ in mean_stdev), max(y for _, y in mean_stdev))\n", "    truth_tables_sens = [fmean(sum(ta[i] ^ ta[j] for j in nbs(i, I))/I for i in range(2**I)) for ta in truth_table]\n\t    print(abs(.5 - fmean(truth_tables_sens)), pstdev(truth_tables_sens))\n\t    # for assignments in truth_table:\n\t    #     print(bin_bitmask(assignments))\n\t\"\"\"\n\t8, 16\n\tref\n\t0.04296875 0.125760625250041\n\t0.0008544921875 0.019445229885344226\n\tmaj3 not [20, 20, 20, 20, O]\n", "0.12060546875 0.2121091726734187\n\t0.162841796875 0.03379297840161043\n\tmaj3 not [200, 200, 200, 200, O]\n\t0.080078125 0.15209000803614153\n\t0.120849609375 0.030429560571682487\n\txor not [20, 20, 20, 20, O]\n\t0.0625 0.16535945694153692\n\t0.0078125 0.12077831901359615\n\txor not [200, 200, 200, 200, O]\n\t0.03125 0.12103072956898178\n", "0.0 0.1875\n\tite not [200, 200, 200, 200, O]\n\t0.05029296875 0.13149097664047601\n\t0.0791015625 0.025633603024231812\n\tite not [20, 20, 20, 20, O]\n\t0.1044921875 0.1579708702179055\n\t0.124267578125 0.030601447254438183\n\tmaj3-9 1/3not [20, 20, 20, 20, O]\n\t0.07861328125 0.18325514715650032\n\t0.091552734375 0.03555998508028247\n", "\"\"\""]}
{"filename": "tests/symbolic.py", "chunked_list": ["import unittest\n\tfrom bhv.symbolic import Var, SymbolicBHV\n\tfrom bhv.shared import stable_hashcode\n\tclass TestReduction(unittest.TestCase):\n\t    def test_optimal_sharing(self):\n\t        x = Var(\"x\")\n\t        y = Var(\"y\")\n\t        se = (x ^ y)\n\t        e = se | ~se\n\t        e_ = (x ^ y) | ~(x ^ y)\n", "        self.assertEqual(stable_hashcode(e), stable_hashcode(se | ~se))\n\t        self.assertNotEqual(stable_hashcode(e), e_)\n\t        self.assertEqual(stable_hashcode(e), stable_hashcode(e_.optimal_sharing()))\n\t    def test_reduce(self):\n\t        x = Var(\"x\")\n\t        y = Var(\"y\")\n\t        e = ~(~((x & y) ^ (x & (y & ~y))))\n\t        self.assertEqual(e.simplify(), (x & y))\n\tif __name__ == '__main__':\n\t    unittest.main()\n"]}
{"filename": "benchmarks/lookup.py", "chunked_list": ["# Similarity search\n\t# from bhv.np import NumPyPacked64BHV as BHV\n\tfrom bhv.native import NativePackedBHV as BHV\n\tfrom bhv.lookup import StoreList, StoreRejectList, StoreChunks\n\tfrom time import monotonic\n\tfrom random import shuffle, random, randrange, sample\n\tfrom statistics import pstdev, fmean\n\trepeat_pipeline = 1\n\trepeat_lookup = 10\n\tthresholds = [0, 3, 6]\n", "deviations = [0, 1, 2, 4]\n\tsizes = [20, 1000]\n\t# e.g.\n\t# hvs=[10, 20, 30, 50, 100]\n\t# v=20 + 5\n\t# threshold=10\n\t# returns 20, 30\n\tindex_times = {s: [] for s in sizes}\n\tlookup_times = {s: {t: [] for t in thresholds} for s in sizes}\n\tdistances = {s: {t: {d: [] for d in deviations} for t in thresholds} for s in sizes}\n", "for _ in range(repeat_pipeline):\n\t    for size in sizes:\n\t        rs = BHV.nrand(size)\n\t        ps = {deviation: [r.flip_frac(BHV.std_to_frac(deviation))\n\t                          for r in sample(rs, repeat_lookup)]\n\t              for deviation in deviations}\n\t        t_index = monotonic()\n\t        index = StoreChunks.auto_associative(rs)\n\t        index_times[size].append(monotonic() - t_index)\n\t        for threshold in thresholds:\n", "            t_lookup = monotonic()\n\t            for deviation in deviations:\n\t                for p in ps[deviation]:\n\t                    ms = list(index.related(p, threshold))\n\t                    distances[size][threshold][deviation].append([index.hvs[m].std_apart(p) for m in ms])\n\t            lookup_times[size][threshold].append(monotonic() - t_lookup)\n\tfor size in sizes:\n\t    print(\"size\", size)\n\t    for threshold in thresholds:\n\t        print(\" threshold\", threshold)\n", "        print(\" lookup\", fmean(lookup_times[size][threshold]), \"+-\", pstdev(lookup_times[size][threshold]))\n\t        for deviation in deviations:\n\t            print(\"  deviation\", deviation)\n\t            print(\"  results\", distances[size][threshold][deviation])\n"]}
{"filename": "benchmarks/exact_synthesis.py", "chunked_list": ["# execution of generated N-input M-output boolean functions\n\t# currently the synthesis and reduction rules make the program consist of\n\t# XOR, NOT, AND, OR\n\t# NOTE: takes about a minute and doesn't show intermediate results\n\tfrom bhv.np import NumPyPacked64BHV as BHV\n\t# from bhv.native import NativePackedBHV as BHV\n\tfrom bhv.symbolic import SymbolicBHV, Var, List\n\tfrom time import monotonic\n\tfrom string import ascii_lowercase\n\tfrom random import shuffle\n", "from statistics import pstdev, fmean\n\trepeat_pipeline = 3\n\trepeat_executions = 10\n\tI = 8\n\tO = 16\n\tnames = [Var(x) for x in ascii_lowercase[:I]]\n\tsynthesis_times = []\n\toptimization_times = []\n\texecution_times = []\n\tfor _ in range(repeat_pipeline):\n", "    t_synth = monotonic()\n\t    fs = []\n\t    for j in range(O):\n\t        target = [i % 2 == 0 for i in range(2**I)]\n\t        shuffle(target)\n\t        f = SymbolicBHV.synth(names, target)\n\t        assert target == f.truth_assignments(names)\n\t        fs.append(f)\n\t    t_opt = monotonic()\n\t    synthesis_times.append(t_opt - t_synth)\n", "    cf = List(fs)\n\t    print(cf.size())\n\t    # could be commented out for more load on execution\n\t    cf = cf.simplify(expand_select_and_or=True)\n\t    print(cf.size())\n\t    # could be commented out for more load on execution\n\t    cf = cf.optimal_sharing()\n\t    print(cf.size())\n\t    t_exec = monotonic()\n\t    optimization_times.append(t_exec - t_opt)\n", "    for _ in range(repeat_executions):\n\t        # the random vector gen could be separated out from the timing\n\t        inputs = {x: BHV.rand() for x in ascii_lowercase[:I]}\n\t        result = cf.execute(vars=inputs, bhv=BHV)\n\t        # the checking below should be separated out from the timing\n\t        # since it boils down to `active`\n\t        for v in result:\n\t            assert v.zscore() <= 4\n\t            for w in result:\n\t                assert v is w or not v.related(w, 9)\n", "    execution_times.append(monotonic() - t_exec)\n\tprint(\"synth:\", fmean(synthesis_times), \"+-\", pstdev(synthesis_times))\n\tprint(\"optim:\", fmean(optimization_times), \"+-\", pstdev(optimization_times))\n\t# only this actual includes hypervector computations\n\tprint(\"execu:\", fmean(execution_times), \"+-\", pstdev(execution_times))\n"]}
{"filename": "benchmarks/random_network.py", "chunked_list": ["# N-input M-output computational vat implementations using different primitives\n\t# NOTE: can fail due to tight bounds on the probabilistic properties, run multiple times\n\t# from bhv.np import NumPyPacked64BHV as BHV\n\tfrom bhv.native import NativePackedBHV as BHV\n\tfrom bhv.symbolic import SymbolicBHV, Var, List\n\tfrom time import monotonic\n\tfrom string import ascii_lowercase\n\tfrom random import shuffle, random, sample\n\tfrom statistics import pstdev, fmean\n\trepeat_pipeline = 3\n", "repeat_executions = 10\n\tI = 50\n\tO = 50\n\tsizes = [200]*20 + [O]\n\tvat_type: '\"MAJ3\" | \"XOR NOT\", \"SELECT EQ\"' = \"XOR NOT\"\n\tnames = [Var(x) for x in ascii_lowercase[:I]]\n\tconstruct_times = []\n\texecution_times = []\n\tfor _ in range(repeat_pipeline):\n\t    initial = names\n", "    layers = [initial]\n\t    t_constr = monotonic()\n\t    for size in sizes:\n\t        layer = []\n\t        for elem in range(size):\n\t            if vat_type == \"MAJ3\":\n\t                i, j, k = sample(layers[-1], k=3)\n\t                layer.append(SymbolicBHV.majority3(\n\t                        i if random() < 2/3 else ~i,\n\t                        j if random() < 2/3 else ~j,\n", "                        k if random() < 2/3 else ~k))\n\t            elif vat_type == \"XOR NOT\":\n\t                r = random()\n\t                if r < .8:\n\t                    i, j = sample(layers[-1], k=2)\n\t                    layer.append(i ^ j)\n\t                else:\n\t                    i, = sample(layers[-1], k=1)\n\t                    layer.append(~i)\n\t            elif vat_type == \"SELECT EQ\":\n", "                r = random()\n\t                if r < 1/3:\n\t                    i, j, k = sample(layers[-1], k=3)\n\t                    layer.append(SymbolicBHV.select(i, j, k))\n\t                else:\n\t                    i, j = sample(layers[-1], k=2)\n\t                    layer.append(~(i ^ j))\n\t        layers.append(layer)\n\t    cf = List(layers[-1])\n\t    t_exec = monotonic()\n", "    construct_times.append(t_exec - t_constr)\n\t    for _ in range(repeat_executions):\n\t        # the random vector gen could be separated out from the timing\n\t        inputs = {x: BHV.rand() for x in ascii_lowercase[:I]}\n\t        result = cf.execute(vars=inputs, bhv=BHV)\n\t        # the checking below should be separated out from the timing\n\t        # since it boils down to `active`\n\t        for v in result:\n\t            assert v.zscore() <= 4\n\t            for w in result:\n", "                assert v is w or not v.related(w, 9)\n\t    execution_times.append(monotonic() - t_exec)\n\tprint(\"construct:\", fmean(construct_times), \"+-\", pstdev(construct_times))\n\t# this actual includes hypervector computations\n\tprint(\"execution:\", fmean(execution_times), \"+-\", pstdev(execution_times))\n"]}
{"filename": "benchmarks/layerwise_random_execution.py", "chunked_list": ["# N-input M-output stack of random computation (from different families)\n\t# NOTE: can fail due to tight bounds on the probabilistic properties, run multiple times\n\t# from bhv.np import NumPyPacked64BHV as BHV\n\tfrom bhv.native import NativePackedBHV as BHV\n\tfrom time import monotonic\n\tfrom random import shuffle, random, randrange, sample\n\tfrom statistics import pstdev, fmean\n\tfrom multiprocessing import Pool\n\trepeat_pipeline = 3\n\tI = 500\n", "O = 500\n\tsizes = [10000]*100 + [O]\n\tvat_type: '\"MAJ3\" | \"XOR NOT\" | \"SELECT EQ\" | \"TERNARY\"' = \"MAJ3\"\n\tif vat_type == \"MAJ3\":\n\t    def execute(_):\n\t        i, j, k = sample(values[-1], k=3)\n\t        return BHV.majority([\n\t                i if random() < 2/3 else ~i,\n\t                j if random() < 2/3 else ~j,\n\t                k if random() < 2/3 else ~k])\n", "elif vat_type == \"XOR NOT\":\n\t    def execute(_):\n\t        r = random()\n\t        if r < .8:\n\t            i, j = sample(values[-1], k=2)\n\t            return i ^ j\n\t        else:\n\t            i, = sample(values[-1], k=1)\n\t            return ~i\n\telif vat_type == \"SELECT EQ\":\n", "    def execute(_):\n\t        r = random()\n\t        if r < 1/3:\n\t            i, j, k = sample(values[-1], k=3)\n\t            return BHV.select(i, j, k)\n\t        else:\n\t            i, j = sample(values[-1], k=2)\n\t            return ~(i ^ j)\n\telif vat_type == \"TERNARY\":\n\t    OPS = [15, 23, 27, 29, 30, 39, 43, 45, 46, 51, 53, 54, 57, 58, 60, 71, 75, 77, 78, 83, 85, 86, 89, 90, 92, 99, 101, 102, 105, 106, 108, 113, 114, 116, 120, 135, 139, 141, 142, 147, 149, 150, 153, 154, 156, 163, 165, 166, 169, 170, 172, 177, 178, 180, 184, 195, 197, 198, 201, 202, 204, 209, 210, 212, 216, 225, 226, 228, 232, 240]\n", "    def execute(_):\n\t        op, = sample(OPS, k=1)\n\t        i, j, k = sample(values[-1], k=3)\n\t        return BHV.ternary(i, j, k, op)\n\texecution_times = []\n\tfor _ in range(repeat_pipeline):\n\t    t_exec = monotonic()\n\t    value = [BHV.rand() for _ in range(I)]\n\t    values = [value]\n\t    with Pool() as p:\n", "        for size in sizes:\n\t            values.append(p.map(execute, range(size)))\n\t    # for size in sizes:\n\t    #     values.append(list(map(execute, range(size))))\n\t    result = values[-1]\n\t    for v in result:\n\t        assert v.zscore() <= 4\n\t        for w in result:\n\t            assert v is w or not v.related(w, 9)\n\t    execution_times.append(monotonic() - t_exec)\n", "print(\"execution:\", fmean(execution_times), \"+-\", pstdev(execution_times))\n"]}
{"filename": "benchmarks/majority.py", "chunked_list": ["# Majority of a various number of inputs\n\tfrom bhv import DIMENSION, AbstractBHV\n\t# from bhv.np import NumPyPacked64BHV as BHV\n\t# from bhv.np import NumPyBoolBHV as BHV\n\tfrom bhv.native import CNativePackedBHV as BHV\n\tfrom time import monotonic\n\tfrom statistics import pstdev, fmean\n\trepeat_pipeline = 5\n\tsizes = list(range(1, 2000, 2))\n\tsizes += list(range(2001, 20000, 20))\n", "sizes += list(range(20001, 200000, 200))\n\tsizes += list(range(200001, 1000001, 2000))\n\tdistances = {s: [] for s in sizes}\n\texecution_times = {s: [] for s in sizes}\n\trs = [BHV.rand() for _ in range(1000001)]\n\tfor i in range(repeat_pipeline):\n\t    print(f\"repetition {i + 1}/{repeat_pipeline}\")\n\t    for size in sizes:\n\t        s = rs[:size]\n\t        t_exec = monotonic()\n", "        maj = BHV.majority(s)\n\t        execution_times[size].append(monotonic() - t_exec)\n\t        distances[size].append(fmean(AbstractBHV.frac_to_std(r.hamming(maj)/DIMENSION, invert=True) for r in s))\n\t        del s\n\twith open(\"results/majority_2000_native_simd.csv\", 'w') as f:\n\t    f.write(\"size,distance,time\\n\")\n\t    for size in sizes:\n\t        print(size)\n\t        print(\"mean distance:\", fmean(distances[size]), \"+-\", pstdev(distances[size]))\n\t        print(\"timing:\", fmean(execution_times[size]), \"+-\", pstdev(execution_times[size]))\n", "        f.write(f\"{size},{fmean(distances[size])},{fmean(execution_times[size])}\\n\")\n"]}
{"filename": "examples/ca_rules.py", "chunked_list": ["from bhv.symbolic import SymbolicBHV, Var\n\tfrom bhv.np import NumPyBoolBHV as BHV, DIMENSION\n\tfrom bhv.visualization import Image\n\timport numpy as np\n\tdef make_rule(r: int):\n\t    mask = [b == '1' for b in bin(r)[2:].rjust(8, \"0\")]\n\t    formula = SymbolicBHV.synth([Var(\"left\"), Var(\"center\"), Var(\"right\")], mask)\n\t    formula = formula.simplify()\n\t    print(\"formula:\", formula.show())\n\t    return lambda x: formula.execute(vars={\"left\": x.roll_bits(1), \"center\": x, \"right\": x.roll_bits(-1)})\n", "RULE = 90\n\tITERATIONS = 10000\n\trule = make_rule(RULE)\n\t# completely random\n\t# last_v = BHV.rand()\n\t# low fraction of on bits\n\tlast_v = BHV.random(.03)\n\t# single on bit\n\t# initial = np.zeros(DIMENSION, dtype=np.bool_)\n\t# initial[64] = np.bool_(1)\n", "# last_v = BHV(initial)\n\tvs = [last_v]\n\tfor i in range(ITERATIONS):\n\t    vs.append(rule(vs[-1]))\n\twith open(f\"rule{RULE}.pbm\", 'wb') as f:\n\t    Image(vs).pbm(f, binary=True)\n"]}
{"filename": "examples/reasoning_by_analogy_linear.py", "chunked_list": ["# The linear variant of https://colab.research.google.com/drive/10XSpooxDAeYVMivF3W2-N0W5yEIUfdZl#scrollTo=dQ7044izy3_y\n\t# This is of theoretical interest\n\tfrom bhv.vanilla import VanillaBHV as BHV\n\tfrom bhv.variants import LinearBHVModel\n\t# Operation on linear are checked\n\tlinear = LinearBHVModel(BHV)\n\t# declare up front how many spaces and entropy we're going to use\n\t# ONE and ZERO are singletons, so using permute(0) to copy them for linearity checking\n\tsymbol_ones = [BHV.ONE.permute(0) for _ in range(9)]\n\tsymbol_zeros = [BHV.ZERO.permute(0) for _ in range(9)]\n", "copy_ones = [BHV.ONE.permute(0) for _ in range(6)]\n\tcopy_zeros = [BHV.ZERO.permute(0) for _ in range(6)]\n\t((name, neg_name), (capital_city, neg_capital_city), (money, neg_money),\n\t (united_states, _neg), (washington_dc, _neg), (dollar, neg_dollar),\n\t (mexico, _neg), (mexico_city, neg_mexico_city), (peso, _neg)) = [linear.spawn(one, zero)\n\t    for one, zero in zip(symbol_ones, symbol_zeros)]\n\t(name_is_united_states, _and, _and) = linear.xor(name, united_states)\n\t(capital_city_is_washington_dc, _and, _and) = linear.xor(capital_city, washington_dc)\n\t(money_is_dollar, _and, _and) = linear.xor(money, dollar)\n\t(_ands, USA, _ors) = linear.thresholds3(name_is_united_states, capital_city_is_washington_dc, money_is_dollar)\n", "# note to make more than on record, we need to re-use the field names\n\t# we invert the negated version we got during spawning the random vectors to obtain copies\n\t((name_copy, _id, _id),\n\t (capital_city_copy, _id, _id),\n\t (money_copy, _id, _id),\n\t (dollar_copy, _id, _id),\n\t (mexico_city_copy, _id, _id)) = [linear.invert(neg, one, zero)\n\t    for neg, one, zero in zip([neg_name, neg_capital_city, neg_money, neg_dollar, neg_mexico_city], copy_ones, copy_zeros)]\n\t(name_is_mexico, _and, _and) = linear.xor(name_copy, mexico)\n\t(capital_city_is_mexico_city, _and, _and) = linear.xor(capital_city_copy, mexico_city)\n", "(money_is_peso, _and, _and) = linear.xor(money_copy, peso)\n\t(_ands, MEX, _ors) = linear.thresholds3(name_is_mexico, capital_city_is_mexico_city, money_is_peso)\n\t(orig_pair, _and, _and) = linear.xor(USA, MEX)\n\t# another method of copying\n\t(_neg, pair_one, pair_two) = linear.invert(orig_pair, copy_ones[-1], copy_zeros[-1])\n\t(dollar_of_mexico, _and, _and) = linear.xor(dollar_copy, pair_one)\n\t# ignoring linearity for these checks, we'd have to make another copy of peso and dollar\n\tassert not peso.unrelated(dollar_of_mexico)\n\tassert peso.hamming(dollar_of_mexico) < dollar.hamming(dollar_of_mexico)\n\t(mexico_city_of_usa, _and, _and) = linear.xor(mexico_city_copy, pair_two)\n", "# ignoring linearity\n\tassert not washington_dc.unrelated(mexico_city_of_usa)\n\tassert washington_dc.hamming(mexico_city_of_usa) < mexico_city.hamming(mexico_city_of_usa)\n"]}
{"filename": "examples/viz_distances.py", "chunked_list": ["from bhv.vanilla import VanillaBHV as BHV\n\tfrom bhv.visualization import DistanceGraph\n\ta, b, c, d = BHV.nrand(4)\n\tabc = BHV.majority([a, b, c])\n\ta1 = a.flip_frac_on(.1)\n\ta0 = a.flip_frac_off(.1)\n\tcq = c.select(a0, a1)\n\tb_d = b ^ d\n\tabc_d = abc ^ d\n\tDistanceGraph.from_scope(locals()).graphviz()\n"]}
{"filename": "examples/kanerva09.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t\"\"\"\n\tFollowing along with [Kanerva 2009](http://ww.robertdick.org/iesr/papers/kanerva09jan.pdf), starting from \"Hyperdimensional Representation\". Please do open these side-by-side, while there is quite a bit of text copied over, it's mostly formulas, where as the interesting insights can only be found in the paper.\n\tAlso the booleans {0, 1} are used instead of {-1, 1}.\n\t\"\"\"\n\t# Let's install the package\n\t# pip install bhv==0.3.0\n\t# Hypervectors here are called Boolean-Hyper-Vectors or BHVs for short.\n\t# Import a BHV implementation\n\tfrom bhv.vanilla import VanillaBHV as BHV\n", "# Import the corresponding permutation datastructure, we'll get to this\n\tfrom bhv.vanilla import VanillaPermutation as Perm\n\t\"\"\"> We can measure distances between points in Euclidean\n\tor Hamming metric. For binary spaces the Hamming distance is the simplest: it is the number of places at which\n\ttwo binary vectors differ, and it is also the length of the\n\tshortest path from one corner point to the other along the\n\tedges of the hypercube. In fact, there are 2k such shortest\n\tpaths between two points that are k bits apart. Naturally,\n\tthe maximum Hamming distance is 10,000 bits, from any\n\tpoint to its opposite point.\n", "One example of opposite points is 101010... and 010101... which differs in every position.\n\tThe example of opposite points below is all zeros and all ones.\n\tThe absolute distance in number of bits can be retrieved by `hamming`.\n\t\"\"\"\n\tprint(BHV.ONE.hamming(BHV.ZERO))\n\t# Note that the hypervector dimension here is 8192 instead of 10000\n\t\"\"\"\n\t> Although the points are not concentrated or clustered\n\tanywhere in the space—because every point is just like\n\tevery other point—the distances are highly concentrated\n", "half-way into the space, or around the distance of 5,000\n\tbits, or 0.5.\n\tLet's generate two random BHVs and find their bit-error-rate (BER), this should be close to 0.5. The BER corresponds to the hamming distance over the number of dimensions. `rand`\"\"\"\n\tprint(BHV.rand().bit_error_rate(BHV.rand()))\n\t\"\"\"\n\t> It is easy to see that half the space is closer to a\n\tpoint than 0.5 and the other half is further away, but it is\n\tsomewhat surprising that less than a millionth of the space\n\tis closer than 0.476 and less than a thousand-millionth is\n\tcloser than 0.47; similarly, less than a millionth is further\n", "than 0.524 away and less than a thousand-millionth is\n\tfurther than 0.53. These figures are based on the binomial\n\tdistribution with mean 5,000 and standard deviation (STD)\n\t50, and on its approximation with the normal distribution—\n\tthe distance from any point of the space to a randomly\n\tdrawn point follows the binomial distribution. \n\tThis is a useful notion, and how likely a BHV is to occur randomly generated,\n\tcan be found by `zscore` (giving you the standard deviations) \n\tand `pvalue` (the absolute chance). \n\t\"\"\"\n", "# very likely to be randomly generated, because it is\n\t# Here -1.0 would mean \"one standard deviation less 1s than expected\"\n\tprint(BHV.rand().zscore())\n\t# flipping just 5% extra on, makes it a 6 sigma+ outlier\n\tprint(BHV.rand().flip_frac_on(0.05).zscore())\n\t\"\"\"\n\t> We can go on\n\ttaking vectors at random without needing to worry about\n\trunning out of vectors—we run out of time before we run\n\tout of vectors. We say that such vectors are unrelated.\n", "All vectors we'll practically sample are all unrelated.\n\tThere's a `related` function that takes the safety margin, 6 sigma by default.\"\"\"\n\trandom_bhvs = BHV.nrand(10)\n\tfor x in random_bhvs:\n\t    for y in random_bhvs:\n\t        if x != y:\n\t            assert x.unrelated(y)\n\t\"\"\"\n\t> Measured in standard deviations, the bulk of the space, and\n\tthe unrelated vectors, are 100 STDs away from any given\n", "vector.\n\tSo we expect two BHVs in the space to be 100 (or in our case, 90) STDs apart.\"\"\"\n\tprint(BHV.rand().std_apart(BHV.rand()))\n\t\"\"\"\n\t> This peculiar distribution of the space makes hyperdimensional representation robust. When meaningful entities\n\tare represented by 10,000-bit vectors, many of the bits can\n\tbe changed—more than a third—by natural variation in\n\tstimulus and by random errors and noise, and the resulting\n\tvector can still be identified with the correct one, in that it\n\tis closer to the original ‘‘error-free’’ vector than to any\n", "unrelated vector chosen so far, with near certainty.\n\tLet's try and flip 1/3 bits, and see how many STDs they are apart.\n\tThis is a lot less than the previous test!\"\"\"\n\tr = BHV.rand()\n\tprint(r.std_apart(r.flip_frac(1/3)))\n\t\"\"\"\n\t> The robustness is illustrated further by the following\n\texample. Let us assume that two meaningful vectors A and\n\tB are only 2,500 bits apart—when only 1/4 of their bits\n\tdiffer. The probability of this happening by chance is about\n", "zero, but a system can create such vectors when their\n\tmeanings are related; more on such relations will be said\n\tlater. So let us assume that 1/3 of the bits of A are changed\n\tat random; will the resulting ‘‘noisy’’ A vector be closer to\n\tB than to A—would it be falsely identified with B? It is\n\tpossible but most unlikely because the noisy vector would\n\tbe 4,166 bits away from B, on the average, and only 3,333\n\tbits from A; the difference is 17 STDs. The (relative)\n\tdistance from the noisy A vector to B is given by d = e -\n\t2de with d = 1/4 and e = 1/3. Thus, adding e amount of\n", "noise to the first vector increases the distance to the second\n\tvector by (1 - 2d)e on the average. Intuitively, most\n\tdirections that are away from A in hyperspace are also\n\taway from B.\n\tLet's follow the full example.\n\t\"\"\"\n\tA = BHV.rand()\n\tA_corrupted = A.flip_frac(1/3)\n\tB = A.flip_frac(1/4)\n\td = 1/4\n", "e = 1/3\n\trelative_distance = d + e - 2*d*e\n\tprint(relative_distance)\n\tprint(A_corrupted.bit_error_rate(B))\n\t# Note this is not the 17 STDs from the paper because we're working in less dimensions\n\tprint(A_corrupted.std_apart(B) - A.std_apart(A_corrupted))\n\t\"\"\"\n\t> The similarity of patterns is the flip-side of distance. We\n\tsay that two patterns, vectors, points are similar to each\n\tother when the distance between them is considerably\n", "smaller than 0.5. We can now describe points of the space\n\tand their neighborhoods as follows. Each point has a large\n\t‘‘private’’ neighborhood in terms of distance: the volume of\n\tspace within, say, 1/3 or 3,333 bits is insignificant compared to the total space. The rest of the space—all the\n\tunrelated ‘‘stuff’’—becomes significant only when the\n\tdistance approaches 0.5. In a certain probabilistic sense,\n\tthen, two points even as far as 0.45 apart are very close to\n\teach other. Furthermore, the ‘‘private’’ neighborhoods of\n\tany two unrelated points have points in common—there\n\tare patterns that are closely related to any two unrelated\n", "patterns. For example, a point C half-way between unrelated points A and B is very closely related to both, and\n\tanother half-way point D can be unrelated to the first, C.\n\tThis can be shown with as few as four dimensions:\n\tA = 0000, B = 0011, C = 0001, and D = 0010. However, the ‘‘unusual’’ probabilities implied by these relative\n\tdistances require high dimensionality. This is significant\n\twhen representing objects and concepts with points of the\n\thyperspace, and significantly different from what we are\n\taccustomed to in ordinary three-dimensional space.\n\tLet's do the same experiment (with BHVs) and verify for ourselves that while both C and D are at a halfwaypoint, they're further removed from each other than from A B.\n\t\"\"\"\n", "A = BHV.ZERO\n\tB = BHV.ONE\n\tC = BHV.rand() # random is halfway between 0 and 1 on average\n\tD = ~C # the inverse of C is unrelated to C\n\tprint(A.bit_error_rate(C), B.bit_error_rate(C))\n\tprint(A.bit_error_rate(D), B.bit_error_rate(D))\n\tprint(C.bit_error_rate(D))\n\t\"\"\"\n\t> The sum (and the mean) of random vectors has the\n\tfollowing important property: it is similar to each of the\n", "vectors being added together. The similarity is very pronounced when only a few vectors are added\n\tWe're working with BHVs so we don't have a sum with the same properties, but there is a notion of mean. The mean is a \"majority\" operation plus a tiebreaker for even numbers of BHVs.\"\"\"\n\tvs = BHV.nrand(5)\n\tvs_mean = BHV.majority(vs)\n\t# while the random vectors are pairwise unrelated\n\tfor i in range(5):\n\t    assert vs[i].unrelated(vs[(i + 1) % 5])\n\t# they're all related to the mean\n\tprint(vs[0].bit_error_rate(vs_mean))\n\tprint(vs[0].std_apart(vs_mean))\n", "#for v in vs:\n\t#    assert v.sixsigma(vs_mean)\n\t\"\"\"\n\t> A very basic and simple multiplication of binary vectors is\n\tby componentwise Exclusive-Or (XOR). The XOR of two vectors has 0s where the two agree and it has 1s where they\n\tdisagree. For example, 0011…10 XOR 0101…00 =\n\t0110…10. Mathematically, the XOR is the arithmetic sum\n\tmodulo 2. The (1, -1)-binary system, also called bipolar,\n\tis equivalent to the (0, 1)-binary system when the XOR is\n\treplaced by ordinary multiplication. We will use the\n", "notation A  B for the multiplication of the vectors A and\n\tB—for their product-vector. Here * is the XOR unless\n\totherwise noted.\n\tThe XOR commutes, A \\* B = B \\* A, and is its own\n\tinverse so that A \\* A = O, where O is the vector of all 0s\n\t(in algebra terms O is the unit vector because A \\* O \\= A).\n\tHere we'll denote XOR with the carret `^`. The laws are thoroughly tested in the library, but let's look at a few examples here.\"\"\"\n\tA = BHV.rand()\n\tB = BHV.rand()\n\t# commutative\n", "assert A ^ B == B ^ A\n\t# it's own inverse\n\tassert A ^ A == BHV.ZERO\n\t\"\"\"\n\t> Since the XOR-vector has 1s where the two vectors disagree, the number of 1s in it is the Hamming distance\n\tbetween the two vectors. By denoting the number of 1s in a\n\tbinary vector X with |X| we can write the Hamming distance d between A and B as d(A, B) = |A * B|\n\tHere we'll refrain from choosing a standard distance metric, but this fact is used everywere.\"\"\"\n\tA = BHV.rand()\n\tB = BHV.rand()\n", "assert A.hamming(B) == (A ^ B).active()\n\t\"\"\"\n\t> Multiplication can be thought of as a mapping of points\n\tin the space. Multiplying the vector X with A maps it to\n\tthe vector X_A = A \\* X which is as far from X as there are 1s\n\tin A (i.e., d(A, X) = |X_A \\* X| = |(A \\* X) \\* X| = |A \\* X \\* X| = |A|).\n\tAnother few important properties, set out in code.\"\"\"\n\tA = BHV.rand()\n\tX = BHV.rand()\n\tX_A = A ^ X\n", "assert X_A.hamming(X) == A.active()\n\t\"\"\"\n\t> If A is a typical (random) vector of the space,\n\tabout half of its bits are 1s, and so X_A is in the part of the\n\tspace that is unrelated to X in terms of the distance criterion. Thus we can say that multiplication randomizes.\n\tLet's check this \"\"\"\n\tA = BHV.rand()\n\tX = BHV.rand()\n\tX_A = A ^ X\n\tprint(X_A.std_apart(X))\n", "\"\"\"\n\t> Mapping with multiplication preserves distance. This is\n\tseen readily by considering X_A = A \\* X and Y_A = A \\* Y;\n\ttaking their XOR, and noting that the two As cancel out\n\tthus: X_A \\* Y_A = (A \\* X) \\* (A \\* Y) = A \\* X \\* A \\* Y = X \\* Y\n\tSince the XOR-vector is the same, the Hamming distance\n\tis the same: |X_A \\* Y_A| = |X \\* Y|\n\tAnd the logical extension\"\"\"\n\tA = BHV.rand()\n\tX = BHV.rand()\n", "Y = BHV.rand()\n\tX_A = A ^ X\n\tY_A = A ^ Y\n\tassert (X_A ^ Y_A) == X ^ Y\n\t\"\"\"\n\t> A very useful property of multiplication is that it\n\tdistributes over addition. That means, for example, that\n\tA \\* \\[X + Y + Z\\] = \\[A \\* X + A \\* Y + A \\* Z\\]\n\tThe brackets \\[…\\] stand for normalization. Distributivity is\n\tinvaluable in analyzing these representations and in\n", "understanding how they work and fail.\n\tThe BHVs do not support normalization in the sense that's meant here. Therefore, care has to be taken as to not introduce unwanted noise. Instead of adding multiple times, and normalizing, one should prefer the addition (here mean) of multiple items.\"\"\"\n\tA, X, Y, Z = BHV.nrand(4)\n\tLHS = A ^ BHV.majority([X, Y, Z])\n\tRHS = BHV.majority([A ^ X, A ^ Y, A ^ Z])\n\tassert LHS == RHS\n\t\"\"\"\n\t> Permutations reorder the vector components and thus are\n\tvery simple; they are also very useful in constructing a\n\tcognitive code. We will denote the permutation of a vector\n", "with a multiplication by a matrix (the permutation matrix\n\tΠ), thus X_Π = ΠX. We can also describe the permutation\n\tof n elements as the list of the integers 1, 2, 3, …, n in the\n\tpermuted order. A random permutation is then one where\n\tthe order of the list is random—it is a permutation chosen\n\trandomly from the n! possible permutations.\n\tWhen theory hits reality, it's not quite as pretty. Firstly, a 8192x8192 matrix is large (LA folks are laughing in the background) and wasteful. This can be resolved by using a denser representation (`NumPyWordPermutation` uses an array of indices, which is [still no optimal](https://hackmd.io/@dabo/rkP8Pcf9t#A-compact-data-structure-for-storing-a-permutation)). Secondly, the number of permutations 8192! is extremely large (28000+ digits). Therefore, implementions needn't support all permutations (`NumPyWordPermutation` only supports permutations on 64 bit words at the moment). Let's take a look at the basic properties with an explicit representation.\n\t\"\"\"\n\tΠ = Perm.random()\n\tX, Y = BHV.nrand(2)\n", "assert Π(X) ^ Π(Y) == Π(X ^ Y)\n\tassert Π(X).hamming(Π(Y)) == X.hamming(Y)\n\t\"\"\"\n\t> As mentioned above, we can map the same vector with two\n\tdifferent permutations and ask how similar the resulting\n\tvectors are: by permuting X with Π and Γ, what is the\n\tdistance between ΠX and ΓX (...)? Unlike above with multiplication by\n\ta vector, this depends on the vector X (e.g., the 0-vector is\n\tunaffected by permutation).\n\tLet's generate another permutation.\"\"\"\n", "Π, Γ = Perm.nrandom(2)\n\tX = BHV.rand()\n\tassert Π(X).unrelated(Γ(X))\n"]}
{"filename": "examples/majority_classification.py", "chunked_list": ["from bhv.vanilla import VanillaBHV as BHV\n\tN = 199*2\n\txs = BHV.nrand(N)\n\tys = [i % 2 == 0 for i in range(N)]\n\tpos = BHV.majority([x for x, y in zip(xs, ys) if y])\n\tneg = BHV.majority([x for x, y in zip(xs, ys) if not y])\n\tright = 0\n\tfor x, y in zip(xs, ys):\n\t    spos = x.hamming(pos)\n\t    sneg = x.hamming(neg)\n", "    prediction = spos < sneg\n\t    right += prediction == y\n\tprint(f\"acc {right/N}\")\n"]}
{"filename": "examples/reasoning_by_analogy_adiabatic.py", "chunked_list": ["# The adiabatic variant of https://colab.research.google.com/drive/10XSpooxDAeYVMivF3W2-N0W5yEIUfdZl#scrollTo=dQ7044izy3_y\n\t# This is of theoretical interest\n\tfrom bhv.vanilla import VanillaBHV as BHV, DIMENSION\n\tfrom bhv.variants import AdiabaticBHVModel, Tank\n\t# declare up front how much charge we have in our tank\n\ttank = Tank(10*DIMENSION, record=True)\n\tadiabatic = AdiabaticBHVModel(tank, BHV)\n\t((name, neg_name), (capital_city, neg_capital_city), (money, neg_money),\n\t (united_states, _neg), (washington_dc, _neg), (dollar, neg_dollar),\n\t (mexico, _neg), (mexico_city, neg_mexico_city), (peso, _neg)) = [adiabatic.spawn() for _ in range(9)]\n", "name_is_united_states = adiabatic.xor(name, united_states)\n\tcapital_city_is_washington_dc = adiabatic.xor(capital_city, washington_dc)\n\tmoney_is_dollar = adiabatic.xor(money, dollar)\n\t# majority is quite a flooding operation\n\tUSA = adiabatic.majority3(name_is_united_states, capital_city_is_washington_dc, money_is_dollar)\n\t# note to make more than on record, we need to re-use the field names\n\t# we invert the negated version we got during spawning the random vectors to obtain copies to save charge\n\t(name_copy,\n\t capital_city_copy,\n\t money_copy,\n", " dollar_copy,\n\t mexico_city_copy) = [adiabatic.invert(neg)\n\t    for neg in [neg_name, neg_capital_city, neg_money, neg_dollar, neg_mexico_city]]\n\tname_is_mexico = adiabatic.xor(name_copy, mexico)\n\tcapital_city_is_mexico_city = adiabatic.xor(capital_city_copy, mexico_city)\n\tmoney_is_peso = adiabatic.xor(money_copy, peso)\n\tMEX = adiabatic.majority3(name_is_mexico, capital_city_is_mexico_city, money_is_peso)\n\torig_pair = adiabatic.xor(USA, MEX)\n\t# another method of copying\n\t(pair_one, pair_two, _neg) = adiabatic.switch(orig_pair, adiabatic.get_one(), adiabatic.get_zero())\n", "dollar_of_mexico = adiabatic.xor(dollar_copy, pair_one)\n\t# ignoring adiabaticity for these checks, we'd have to make another copy of peso and dollar\n\tassert not peso.unrelated(dollar_of_mexico)\n\tassert peso.hamming(dollar_of_mexico) < dollar.hamming(dollar_of_mexico)\n\tmexico_city_of_usa = adiabatic.xor(mexico_city_copy, pair_two)\n\t# ignoring adiabaticity\n\tassert not washington_dc.unrelated(mexico_city_of_usa)\n\tassert washington_dc.hamming(mexico_city_of_usa) < mexico_city.hamming(mexico_city_of_usa)\n\thistorical_levels = tank.historical_levels()\n\tprint(\"final tank level:\", tank.level, \"historical min,max:\", min(historical_levels), max(historical_levels))\n"]}
{"filename": "examples/state_machine.py", "chunked_list": ["# TurnstileExample\n\t# Implementing the Turnstile state machine with Hypervectors\n\t# The state machine: https://en.wikipedia.org/wiki/Finite-state_machine#Example:_coin-operated_turnstile\n\tfrom bhv.vanilla import VanillaBHV as BHV, VanillaPermutation as Perm\n\t# states\n\tlocked = BHV.rand()\n\tunlocked = BHV.rand()\n\t# input symbols\n\ttoken = BHV.rand()\n\tpush = BHV.rand()\n", "# next state permutation\n\tPNext = Perm.random()\n\t# inverse for querying the next state\n\tQNext = ~PNext\n\ttransition = BHV.majority([\n\t    (push ^ locked ^ PNext(locked)),\n\t    (token ^ locked ^ PNext(unlocked)),\n\t    (push ^ unlocked ^ PNext(locked)),\n\t    (token ^ unlocked ^ PNext(unlocked))\n\t])\n", "# note this doesn't exactly give the right state\n\tdef next_state(state, input):\n\t    return QNext(transition ^ input ^ state)\n\t# so we make a noisy lookup table\n\ttable = [locked, unlocked]\n\tdef closest(noisy):\n\t    return min(table, key=noisy.hamming)\n\t# and check if the transition system works as expected\n\tassert closest(next_state(locked, push)) == locked\n\tassert closest(next_state(locked, token)) == unlocked\n", "assert closest(next_state(unlocked, push)) == locked\n\tassert closest(next_state(unlocked, token)) == unlocked\n"]}
{"filename": "examples/winnow_classification.py", "chunked_list": ["# require NumPy\n\tfrom bhv.np import NumPyBoolBHV as BHV, DIMENSION\n\timport numpy as np\n\tN = 22\n\tEPOCHS = 30\n\txs = BHV.nrand(N)\n\tys = [i % 2 == 0 for i in range(N)]\n\tthreshold = DIMENSION//2\n\talpha = 2\n\tws = np.ones(DIMENSION, dtype=np.uint16)\n", "for i in range(EPOCHS):\n\t    right = 0\n\t    for x, y in zip(xs, ys):\n\t        total = np.dot(x.data, ws)\n\t        prediction = total > threshold\n\t        right += prediction == y\n\t        if prediction != y:\n\t            if y:\n\t                ws = np.where(x.data == 1, ws*alpha, ws)\n\t            else:\n", "                ws = np.where(x.data == 1, ws/alpha, ws)\n\t                # ws = np.where(x.data == 1, np.zeros_like(ws), ws)\n\t    print(f\"acc {right/N}\")\n"]}
{"filename": "examples/grandmother_example.py", "chunked_list": ["# Let's try and encode some rules, and do some rule-based computing\n\t# If x is the mother of y and y is the father of z then x is the grandmother of z\n\t# from bhv.np import NumPyPacked64BHV as BHV, NumPyWordPermutation as Perm\n\tfrom bhv.vanilla import VanillaBHV as BHV, VanillaPermutation as Perm\n\t# relation utility\n\trel_subject = Perm.random()\n\trel_object = ~rel_subject\n\t# relations\n\tmother_of = BHV.rand()\n\tfather_of = BHV.rand()\n", "grandmother_of = BHV.rand()\n\t# extractors\n\tmother_of_mother = rel_subject(mother_of)\n\tmother_of_child = rel_object(mother_of)\n\tfather_of_father = rel_subject(father_of)\n\tfather_of_child = rel_object(father_of)\n\tgrandmother_of_grandmother = rel_subject(grandmother_of)\n\tgrandmother_of_child = rel_object(grandmother_of)\n\tdef apply_rel(rel, x, y):\n\t  sx = rel_subject(rel) ^ x\n", "  sy = rel_object(rel) ^ y\n\t  return BHV.majority([sx, sy])\n\t# our rule, read `xor` as \"implied by\" and `BHV.majority` as \"and\"\n\t# note this is applied to multiple \"datapoints\" ...\n\tdef generate_sample():\n\t  person_x = BHV.rand()\n\t  person_y = BHV.rand()\n\t  person_z = BHV.rand()\n\t  mxy = apply_rel(mother_of, person_x, person_y)\n\t  fyz = apply_rel(father_of, person_y, person_z)\n", "  gxz = apply_rel(grandmother_of, person_x, person_z)\n\t  return gxz ^ BHV.majority([mxy, fyz])\n\t# ... and averaged out for higher accuracy\n\tgrandmother_rule = BHV.majority([generate_sample() for _ in range(15)])\n\t# applying grandmother rule\"\n\tanna = BHV.rand()\n\tbill = BHV.rand()\n\tcid = BHV.rand()\n\tanna_mother_of_bill = apply_rel(mother_of, anna, bill)\n\tbill_father_of_cid = apply_rel(father_of, bill, cid)\n", "calculated_anna_grandmother_of_cid = grandmother_rule ^ BHV.majority([anna_mother_of_bill, bill_father_of_cid])\n\tactual_anna_grandmother_of_cid = apply_rel(grandmother_of, anna, cid)\n\tassert not calculated_anna_grandmother_of_cid.unrelated(actual_anna_grandmother_of_cid)\n"]}
