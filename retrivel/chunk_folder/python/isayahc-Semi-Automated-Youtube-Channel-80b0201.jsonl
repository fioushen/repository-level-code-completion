{"filename": "main.py", "chunked_list": ["import argparse\n\timport os\n\t# Local/application specific imports\n\tfrom src.utils import utils\n\tfrom src.audio import audio_utils\n\t#TODO:\n\t# remove hardcoded file related variables\n\tdef validate_args(args):\n\t    \"\"\"\n\t    Validates the file path arguments.\n", "    Args:\n\t        args: The command line arguments.\n\t    \"\"\"\n\t    if not os.path.isfile(args.audio_link):\n\t        raise ValueError(f\"File not found: {args.audio_link}\")\n\t    if not os.path.isfile(args.vid_link):\n\t        raise ValueError(f\"File not found: {args.vid_link}\")\n\tdef main():\n\t    \"\"\"\n\t    Main function to handle command line arguments and initiate the video generation.\n", "    \"\"\"\n\t    parser = argparse.ArgumentParser(description='Generate video with subtitles.')\n\t    parser.add_argument('--audio_link', type=str, required=True,\n\t                        help='Path to the audio file.')\n\t    parser.add_argument('--vid_link', type=str, required=True,\n\t                        help='Path to the video file.')\n\t    parser.add_argument('--swear_word_list', type=str, required=False, default=\"\",\n\t                        help='Path to the text file with a list of swear words to be filtered out.')\n\t    parser.add_argument('--video_output', type=str, required=True,\n\t                        help='Path for the output video file.')\n", "    parser.add_argument('--srtFilename', type=str, required=False, default=\"\",\n\t                        help='Path for the subtitle file. If not provided, no subtitle file will be saved.')\n\t    args = parser.parse_args()\n\t    # Validate the arguments\n\t    validate_args(args)\n\t    # If no swear word list is provided, default to the predefined list\n\t    if args.swear_word_list:\n\t        with open(args.swear_word_list, 'r') as file:\n\t            args.swear_word_list = [word.strip() for word in file.readlines()]\n\t    else:\n", "        args.swear_word_list = audio_utils.get_swear_word_list().keys()\n\t    utils.generate_video_with_subtitles(\n\t        args.audio_link, \n\t        args.vid_link, \n\t        args.swear_word_list, \n\t        args.video_output,\n\t        args.srtFilename\n\t        )\n\tif __name__ == '__main__':\n\t    try:\n", "        main()\n\t    except Exception as e:\n\t        print(f\"An error occurred: {e}\")"]}
{"filename": "gui_upload_video.py", "chunked_list": ["import tkinter as tk\n\tfrom tkinter import filedialog\n\tfrom argparse import Namespace\n\tfrom src.utils.upload_video import get_authenticated_service, initialize_upload, validate_shorts\n\tfrom googleapiclient.errors import HttpError\n\tdef browse_files(entry):\n\t    filename = filedialog.askopenfilename(initialdir = \"/\", title = \"Select a File\", filetypes = ((\"Text files\", \"*.mp4*\"), (\"all files\", \"*.*\")))\n\t    entry.delete(0, tk.END)\n\t    entry.insert(tk.END, filename)\n\tdef upload():\n", "    options = Namespace(\n\t        file=file_entry.get(),\n\t        title=title_entry.get(),\n\t        description=description_entry.get(),\n\t        category=category_entry.get(),\n\t        keywords=keywords_entry.get(),\n\t        privacyStatus=privacy_status_var.get(),\n\t        thumbnail=thumbnail_entry.get(),\n\t        madeForKids=bool(made_for_kids_var.get()),\n\t        youtubeShort=bool(youtube_short_var.get())\n", "    )\n\t    if options.youtubeShort:\n\t        validate_shorts(options)\n\t    youtube = get_authenticated_service()\n\t    try:\n\t        initialize_upload(youtube, options)\n\t    except HttpError as e:\n\t        print(f'An HTTP error {e.resp.status} occurred:\\n{e.content}')\n\troot = tk.Tk()\n\tfile_label = tk.Label(root, text=\"Video file\")\n", "file_label.pack()\n\tfile_entry = tk.Entry(root)\n\tfile_entry.pack()\n\tbrowse_button = tk.Button(root, text=\"Browse\", command=lambda: browse_files(file_entry))\n\tbrowse_button.pack()\n\ttitle_label = tk.Label(root, text=\"Title\")\n\ttitle_label.pack()\n\ttitle_entry = tk.Entry(root)\n\ttitle_entry.insert(tk.END, 'Test Title')\n\ttitle_entry.pack()\n", "description_label = tk.Label(root, text=\"Description\")\n\tdescription_label.pack()\n\tdescription_entry = tk.Entry(root)\n\tdescription_entry.insert(tk.END, 'Test Description')\n\tdescription_entry.pack()\n\tcategory_label = tk.Label(root, text=\"Category\")\n\tcategory_label.pack()\n\tcategory_entry = tk.Entry(root)\n\tcategory_entry.insert(tk.END, '27')\n\tcategory_entry.pack()\n", "keywords_label = tk.Label(root, text=\"Keywords\")\n\tkeywords_label.pack()\n\tkeywords_entry = tk.Entry(root)\n\tkeywords_entry.insert(tk.END, '')\n\tkeywords_entry.pack()\n\tprivacy_status_var = tk.StringVar(root)\n\tprivacy_status_var.set(\"private\") \n\tprivacy_status_option = tk.OptionMenu(root, privacy_status_var, \"public\", \"private\", \"unlisted\")\n\tprivacy_status_option.pack()\n\tthumbnail_label = tk.Label(root, text=\"Thumbnail\")\n", "thumbnail_label.pack()\n\tthumbnail_entry = tk.Entry(root)\n\tthumbnail_entry.insert(tk.END, '')\n\tthumbnail_entry.pack()\n\tthumbnail_browse_button = tk.Button(root, text=\"Browse\", command=lambda: browse_files(thumbnail_entry))\n\tthumbnail_browse_button.pack()\n\tmade_for_kids_var = tk.BooleanVar(root)\n\tmade_for_kids_check = tk.Checkbutton(root, text='Made for Kids', variable=made_for_kids_var)\n\tmade_for_kids_check.pack()\n\tyoutube_short_var = tk.BooleanVar(root)\n", "youtube_short_check = tk.Checkbutton(root, text='YouTube Shorts', variable=youtube_short_var)\n\tyoutube_short_check.pack()\n\tupload_button = tk.Button(root, text=\"Upload\", command=upload)\n\tupload_button.pack()\n\troot.mainloop()\n"]}
{"filename": "examples/reddit_to_video.py", "chunked_list": ["\"\"\"\n\tThis module fetches posts from a subreddit, converts one of the posts into audio,\n\tthen generates a video with subtitles from the audio and a sample video.\n\t\"\"\"\n\timport os\n\timport sys\n\timport logging\n\tfrom dotenv import load_dotenv\n\tfrom pathlib import Path\n\t# Third party imports\n", "from elevenlabs import set_api_key, generate, save\n\t# Local/application specific imports\n\tfrom src.utils import reddit_api, utils\n\tfrom src.audio import audio_utils\n\tdef check_environment_variables():\n\t    \"\"\"\n\t    Checks if necessary environment variables are set.\n\t    This function gets the 'ELEVENLABS_API_KEY' and 'STRING_AUDIO_FILE_LOCATION' \n\t    from the environment variables and checks if they are set.\n\t    Returns:\n", "        ELEVENLABS_API_KEY (str): The API key for elevenlabs.\n\t        STRING_AUDIO_FILE_LOCATION (str): The location to store the audio file.\n\t    Raises:\n\t        SystemExit: If the environment variables are not set.\n\t    \"\"\"\n\t    ELEVENLABS_API_KEY = os.getenv('ELEVENLABS_API_KEY')\n\t    if not ELEVENLABS_API_KEY:\n\t        logging.error(\"The ELEVENLABS_API_KEY environment variable is not set.\")\n\t        sys.exit(1)\n\t    STRING_AUDIO_FILE_LOCATION = os.getenv(\"STRING_AUDIO_FILE_LOCATION\")\n", "    if not STRING_AUDIO_FILE_LOCATION:\n\t        logging.error(\"The STRING_AUDIO_FILE_LOCATION environment variable is not set.\")\n\t        sys.exit(1)\n\t    return ELEVENLABS_API_KEY, STRING_AUDIO_FILE_LOCATION\n\t# This function fetches posts from the specified subreddit\n\tdef fetch_reddit_posts(subreddit):\n\t    return reddit_api.fetch_reddit_posts(subreddit)\n\t# This function creates a directory in the specified location to store the audio file\n\tdef create_audio_directory(audio_file_location):\n\t    audio_directory = utils.create_next_dir(audio_file_location)\n", "    current_directory = os.getcwd()\n\t    directory_path = os.path.join(current_directory, Path(audio_directory))\n\t    return directory_path\n\t# This function generates an audio file from the specified script using the Eleven Labs API\n\tdef generate_audio(script, voice, model):\n\t    return generate(text=script, voice=voice, model=model)\n\tdef main(api_key, audio_file_location):\n\t    subreddit = 'dndstories'\n\t    # Fetch posts from the subreddit\n\t    posts_dict = fetch_reddit_posts(subreddit)\n", "    first_story = posts_dict[-1]\n\t    # Convert the first post into a script\n\t    script_first_story = reddit_api.turn_post_into_script(\n\t        first_story['body'], first_story['title'])\n\t    # Create a directory to store the audio file\n\t    directory_path = create_audio_directory(audio_file_location)\n\t    complete_audio_path = os.path.join(directory_path, \"story_part_0.wav\")\n\t    # Fetch the list of swear words to filter\n\t    swear_word_list = [*audio_utils.get_swear_word_list().keys()]\n\t    # Generate the audio from the script\n", "    audio = generate_audio(script_first_story, voice=\"Bella\", model=\"eleven_monolingual_v1\")\n\t    save(audio, complete_audio_path)\n\t    input_video_file = r'sample_video.mp4'\n\t    output_video_file = r\"sample_0.mp4\"\n\t    # Generate the final video with subtitles, filtering out any swear words\n\t    utils.generate_video_with_subtitles(\n\t        complete_audio_path, input_video_file, swear_word_list, output_video_file)\n\tif __name__ == '__main__':\n\t    logging.basicConfig(level=logging.INFO)\n\t    load_dotenv()\n", "    # Check environment variables and proceed if all necessary variables are set\n\t    ELEVENLABS_API_KEY, STRING_AUDIO_FILE_LOCATION = check_environment_variables()\n\t    set_api_key(ELEVENLABS_API_KEY)\n\t    main(ELEVENLABS_API_KEY, STRING_AUDIO_FILE_LOCATION)\n"]}
{"filename": "src/__init__.py", "chunked_list": []}
{"filename": "src/audio/audio_utils.py", "chunked_list": ["from typing import List, Tuple, Dict, Union\n\timport re\n\timport os\n\timport csv\n\tfrom pydub import AudioSegment\n\tfrom src.audio import concate_audio\n\tfrom src.utils import (generate_subtitles, text_utils)\n\tSWEAR_WORD_LIST_FILE_LOCATION = os.getenv('SWEAR_WORD_LIST_FILE_LOCATION_FILE_LOCATION')\n\tdef silence_segments(input_file, output_file, segments):\n\t    '''silences all selected segments'''\n", "    # Load audio file\n\t    audio = AudioSegment.from_file(input_file)\n\t    # Loop over the list of segments\n\t    for segment in segments:\n\t        # Calculate the start and end times in milliseconds\n\t        start_ms = segment['start'] * 1000\n\t        end_ms = segment['end'] * 1000\n\t        # Create a silent audio segment with the same duration as the specified segment\n\t        duration = end_ms - start_ms\n\t        silent_segment = AudioSegment.silent(duration=duration)\n", "        # Replace the segment with the silent audio\n\t        audio = audio[:start_ms] + silent_segment + audio[end_ms:]\n\t    # Export the modified audio to a file\n\t    audio.export(output_file, format=\"wav\")\n\tdef make_family_friendly(input_data:str,swear_word_list:List[str],output_data:str=\"output0.wav\"):\n\t    x = generate_subtitles.transcribe_and_align(input_data)\n\t    x_word_segments = x['word_segments']\n\t    swear_word_segements = text_utils.filter_text_by_list(x_word_segments,swear_word_list)\n\t    silence_segments(input_data, output_data, swear_word_segements)\n\tdef mask_swear_segments(word_list: List[str], x_word_segments: List[Dict[str, Union[str, float]]]) -> List[Dict[str, Union[str, float]]]:\n", "    x_word_segments_copy = []\n\t    for i in x_word_segments:\n\t        segment_copy = i.copy()\n\t        segment_copy['text'] = mask_specific_words(word_list, i['text'])\n\t        x_word_segments_copy.append(segment_copy)\n\t    return x_word_segments_copy\n\tdef remove_swears(audio_script:str) ->str:\n\t    links_dict = get_swear_word_list()\n\t    for word, replacement in links_dict.items():\n\t        audio_script = audio_script.replace(word, replacement)\n", "    return audio_script\n\tdef get_swear_word_list():\n\t        with open(SWEAR_WORD_LIST_FILE_LOCATION, 'r') as f:\n\t            reader = csv.reader(f)\n\t            # create a dictionary with the first column as the keys and the second column as the values\n\t            links_dict = {rows[0]: rows[1] for rows in reader}\n\t        return links_dict\n\tdef mask_word(match):\n\t    word = match.group(0)\n\t    return word[0] + \"*\" * (len(word) - 2) + word[-1]\n", "def mask_specific_words(words_to_mask: List[str], string_to_mask: str) -> str:\n\t    \"\"\"\n\t    Mask specific words in a given string by replacing them with asterisks, while preserving the first and last characters.\n\t    Args:\n\t        words_to_mask (List[str]): List of words to mask.\n\t        string_to_mask (str): String to be masked.\n\t    Returns:\n\t        str: Masked string.\n\t    \"\"\"\n\t    # Create a set of unique words to mask for faster lookup\n", "    words_set = set(words_to_mask)\n\t    # Compile the regex pattern to match any of the words to mask\n\t    pattern = re.compile(r\"\\b(?:{})\\b\".format(\"|\".join(re.escape(word) for word in words_set)), flags=re.IGNORECASE)\n\t    # Replace the matched words with asterisks, preserving the first and last characters\n\t    # Perform the replacement using the compiled pattern and mask_word function\n\t    masked_string = pattern.sub(mask_word, string_to_mask)\n\t    return masked_string"]}
{"filename": "src/audio/concate_audio.py", "chunked_list": ["#!/usr/bin/env python3\n\timport os\n\timport random\n\timport sys\n\timport argparse\n\tfrom typing import List\n\tfrom natsort import natsorted\n\tfrom pydub import AudioSegment\n\tdef get_sorted_audio_files(directory: str) -> List[str]:\n\t    return [os.path.join(directory, f) for f in natsorted(os.listdir(directory)) if f.endswith('.wav')]\n", "def combine_audio_files_directory(directory: str, output: str) -> AudioSegment:\n\t    \"\"\"\n\t    Combines all .wav audio files in a given directory into a single audio file and exports it to the specified output file.\n\t    :param directory: Path to the directory containing the audio files to be combined.\n\t    :param output: Path to the output file where the combined audio will be saved.\n\t    :return: The combined audio as a PyDub AudioSegment object.\n\t    \"\"\"\n\t    audio_files = get_sorted_audio_files(directory)\n\t    combined_audio = AudioSegment.empty()\n\t    for audio_file in audio_files:\n", "        audio = AudioSegment.from_file(audio_file)\n\t        combined_audio += audio\n\t    combined_audio.export(output, format='wav')\n\t    return combined_audio\n\tdef combine_audio_files_with_random_pause(directory:str, output:str) -> AudioSegment:\n\t    \"\"\"\n\t    Combines all .wav audio files in a given directory into a single audio file with a random pause (300ms to 500ms) between\n\t    each file and exports it to the specified output file.\n\t    :param directory: Path to the directory containing the audio files to be combined.\n\t    :param output: Path to the output file where the combined audio will be saved.\n", "    :return: The combined audio as a PyDub AudioSegment object.\n\t    \"\"\"\n\t    combined_audio = AudioSegment.empty()\n\t    audio_files = get_sorted_audio_files(directory)\n\t    combined_audio = AudioSegment.from_file(audio_files[0])\n\t    for audio_file in audio_files[1:]:\n\t        pause_duration = random.randint(300, 500)\n\t        combined_audio += AudioSegment.silent(duration=pause_duration)\n\t        audio = AudioSegment.from_file(audio_file)\n\t        combined_audio += audio\n", "    combined_audio.export(output, format='wav')\n\t    return combined_audio\n\tdef main(args: List[str]) -> None:\n\t    parser = argparse.ArgumentParser(description='Combine multiple audio files into one')\n\t    parser.add_argument('directory', metavar='DIRECTORY', help='directory containing the audio files to combine')\n\t    parser.add_argument('-o', '--output', default='combined_audio.wav', help='output filename (default: combined_audio.wav)')\n\t    parser.add_argument('--pause', action='store_true', help='add random pause between files')\n\t    args = parser.parse_args(args)\n\t    if args.pause:\n\t        combine_audio_files_with_random_pause(args.directory, args.output)\n", "    else:\n\t        combine_audio_files_directory(args.directory, args.output)\n\tif __name__ == '__main__':\n\t    main(sys.argv[1:])\n"]}
{"filename": "src/audio/__init__.py", "chunked_list": []}
{"filename": "src/test/test_audio.py", "chunked_list": ["import os\n\timport tempfile\n\timport pytest\n\tfrom pydub import AudioSegment\n\tfrom pyttsx3 import init\n\timport shutil\n\tfrom ..audio.concate_audio import (\n\t    get_sorted_audio_files,\n\t    combine_audio_files_directory,\n\t    combine_audio_files_with_random_pause,\n", ")\n\t@pytest.fixture\n\tdef audio_files_directory():\n\t    # Create a temporary directory for the audio files\n\t    temp_dir = tempfile.mkdtemp()\n\t    # Create temporary audio files in the directory\n\t    audio_files = ['file1.wav', 'file2.wav', 'file3.wav']\n\t    for audio_file in audio_files:\n\t        file_path = os.path.join(temp_dir, audio_file)\n\t        generate_audio(\"Sample audio\", file_path)  # Generate sample audio using TTS\n", "    yield temp_dir\n\t    # Clean up the temporary directory and files after the test\n\t    for audio_file in audio_files:\n\t        file_path = os.path.join(temp_dir, audio_file)\n\t        os.remove(file_path)\n\t    shutil.rmtree(temp_dir, ignore_errors=True)\n\tdef generate_audio(text, output_file):\n\t    engine = init()\n\t    engine.save_to_file(text, output_file)\n\t    engine.runAndWait()\n", "def test_get_sorted_audio_files(audio_files_directory):\n\t    expected_files = [\n\t        os.path.join(audio_files_directory, 'file1.wav'),\n\t        os.path.join(audio_files_directory, 'file2.wav'),\n\t        os.path.join(audio_files_directory, 'file3.wav'),\n\t    ]\n\t    assert get_sorted_audio_files(audio_files_directory) == expected_files\n\tdef test_combine_audio_files_directory(audio_files_directory):\n\t    output_file = os.path.join(audio_files_directory, 'combined_audio.wav')\n\t    combined_audio = combine_audio_files_directory(audio_files_directory, output_file)\n", "    assert isinstance(combined_audio, AudioSegment)\n\t    assert os.path.isfile(output_file)\n\tdef test_combine_audio_files_with_random_pause(audio_files_directory):\n\t    output_file = os.path.join(audio_files_directory, 'combined_audio.wav')\n\t    combined_audio = combine_audio_files_with_random_pause(audio_files_directory, output_file)\n\t    assert isinstance(combined_audio, AudioSegment)\n\t    assert os.path.isfile(output_file)\n\t# Additional tests can be added as needed\n"]}
{"filename": "src/test/__init__.py", "chunked_list": []}
{"filename": "src/metadata/keyword_analysis.py", "chunked_list": ["import os\n\timport matplotlib.pyplot as plt\n\tfrom pytrends.request import TrendReq\n\timport pandas as pd\n\timport datetime\n\tfrom typing import List, Optional\n\tdef validate_inputs(keywords: List[str], timeframe: str) -> None:\n\t    \"\"\"\n\t    Validate the inputs for the get_trends function.\n\t    Parameters\n", "    ----------\n\t    keywords : list of str\n\t        List of keywords to get trends data for.\n\t    timeframe : str\n\t        Timeframe for the trends data.\n\t    \"\"\"\n\t    if not isinstance(keywords, list):\n\t        raise ValueError(\"Keywords should be a list of strings.\")\n\t    valid_timeframes = ['now 1-H', 'now 4-H', 'now 1-d', 'now 7-d', 'today 1-m', 'today 3-m', 'today 12-m', 'today 5-y', 'all']\n\t    if timeframe not in valid_timeframes:\n", "        raise ValueError(\"Invalid timeframe. Check the Google Trends API for valid timeframes.\")\n\tdef get_trends(keywords: List[str], timeframe: str = 'today 5-y') -> pd.DataFrame:\n\t    \"\"\"\n\t    Get Google Trends data for a list of keywords.\n\t    Args:\n\t        keywords (List[str]): List of keywords to get trends data for.\n\t        timeframe (str, optional): Timeframe for the trends data, defaults to 'today 5-y'.\n\t    Returns:\n\t        pd.DataFrame: DataFrame with the trends data.\n\t    \"\"\"\n", "    pytrends = TrendReq(hl='en-US', tz=360)\n\t    # Build the payload\n\t    pytrends.build_payload(keywords, timeframe=timeframe)\n\t    # Get Google Trends data\n\t    trends_data = pytrends.interest_over_time()\n\t    return trends_data\n\tdef plot_trends(trend_data: pd.DataFrame, save: bool = False, filename: Optional[str] = None) -> None:\n\t    \"\"\"\n\t    Plot Google Trends data.\n\t    Parameters\n", "    ----------\n\t    trend_data : pandas.DataFrame\n\t        DataFrame with the trends data.\n\t    save : bool, optional\n\t        Whether to save the plot as a PNG image, defaults to False.\n\t    filename : str, optional\n\t        Filename for the PNG image, defaults to None.\n\t    \"\"\"\n\t    plt.figure(figsize=(14, 8))\n\t    for keyword in trend_data.columns[:-1]:  # Exclude the 'isPartial' column\n", "        plt.plot(trend_data.index, trend_data[keyword], label=keyword)\n\t    plt.xlabel('Date')\n\t    plt.ylabel('Trends Index')\n\t    plt.title('Google Search Trends over time')\n\t    plt.grid(True)\n\t    plt.legend()\n\t    plt.show()\n\t    if save:\n\t        if filename is None:\n\t            # Create filename with current datetime if not specified\n", "            filename = f\"graph_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.png\"\n\t        plt.savefig(filename, format='png')  # Save the plot as a PNG image\n\tdef main() -> None:\n\t    \"\"\"\n\t    Main function to get and plot Google Trends data.\n\t    \"\"\"\n\t    # List of keywords to get trends data for\n\t    keywords = ['Blockchain', 'pizza', 'Australian Cattle Dog','AI',\"Chinese Food\"]\n\t    # Get the trends data\n\t    trend_data = get_trends(keywords)\n", "    # Plot the trends data\n\t    plot_trends(trend_data)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/metadata/video_engagement_metrics.py", "chunked_list": ["import os\n\timport argparse\n\tfrom googleapiclient.discovery import build\n\tfrom dotenv import load_dotenv\n\tdef get_video_engagement_metrics(video_id: str, api_key: str) -> dict:\n\t    \"\"\"\n\t    Fetch engagement metrics for a specific YouTube video.\n\t    Args:\n\t        video_id (str): The ID of the YouTube video.\n\t        api_key (str): The Google API key.\n", "    Returns:\n\t        dict: A dictionary containing engagement metrics and video metadata.\n\t    \"\"\"\n\t    # Build the YouTube API client\n\t    youtube = build('youtube', 'v3', developerKey=api_key)\n\t    # Make the API request to get video statistics and snippet (for metadata)\n\t    response = youtube.videos().list(\n\t        part='statistics,snippet',\n\t        id=video_id\n\t    ).execute()\n", "    # Extract engagement metrics and metadata from the response\n\t    engagement_metrics = response['items'][0]['statistics']\n\t    metadata = response['items'][0]['snippet']\n\t    # Add metadata to the engagement metrics dictionary\n\t    engagement_metrics.update(metadata)\n\t    return engagement_metrics\n\tdef get_video_comments(video_id: str, api_key: str, max_results: int = 20, include_replies: bool = True) -> list:\n\t    \"\"\"\n\t    Fetch comments for a specific YouTube video.\n\t    Args:\n", "        video_id (str): The ID of the YouTube video.\n\t        api_key (str): The Google API key.\n\t        max_results (int, optional): Maximum number of comments to return. Defaults to 20.\n\t        include_replies (bool, optional): If True, includes replies to comments. Defaults to True.\n\t    Returns:\n\t        list: A list containing comments, booleans indicating if it is a reply, the comment's publish datetime, \n\t              like count, and author channel Id.\n\t    \"\"\"\n\t    # Build the YouTube API client\n\t    youtube = build('youtube', 'v3', developerKey=api_key)\n", "    # Fetch comments for the video\n\t    response = youtube.commentThreads().list(\n\t        part='snippet,replies',\n\t        videoId=video_id,\n\t        textFormat='plainText',\n\t        maxResults=max_results\n\t    ).execute()\n\t    # Extract comments from the response\n\t    comments = []\n\t    for item in response['items']:\n", "        comment = item['snippet']['topLevelComment']['snippet']\n\t        comments.append(\n\t            {\n\t                'text': comment['textDisplay'],\n\t                'is_reply': False,\n\t                'like_count': comment['likeCount'],\n\t                'author_channel_id': comment['authorChannelId']['value'],\n\t                'publish_time': comment['publishedAt']\n\t            }\n\t        )\n", "        # Extract replies if any\n\t        if include_replies and 'replies' in item:\n\t            for reply in item['replies']['comments']:\n\t                reply_comment = reply['snippet']\n\t                comments.append(\n\t                    {\n\t                        'text': reply_comment['textDisplay'],\n\t                        'is_reply': True,\n\t                        'like_count': reply_comment['likeCount'],\n\t                        'author_channel_id': reply_comment['authorChannelId']['value'],\n", "                        'publish_time': reply_comment['publishedAt']\n\t                    }\n\t                )\n\t    return comments\n\tdef main():\n\t    # Load environment variables\n\t    load_dotenv()\n\t    # Get the API key from the environment variables\n\t    api_key = os.getenv(\"GOOGLE_API_KEY\")\n\t    # Setup argument parser\n", "    parser = argparse.ArgumentParser(description='Fetch engagement metrics or comments for a YouTube video.')\n\t    group = parser.add_mutually_exclusive_group(required=True)\n\t    group.add_argument('--metrics', action='store_true', help='Get engagement metrics')\n\t    group.add_argument('--comments', type=int, nargs='?', const=20, help='Get comments')\n\t    parser.add_argument('--no-replies', action='store_true', help='Exclude replies to comments')\n\t    parser.add_argument('--order', type=str, choices=['relevance', 'time', 'rating', 'videoLikes', 'videoRelevance'], default='relevance', help='Order of comments')\n\t    parser.add_argument('video_id', type=str, help='The ID of the YouTube video')\n\t    # Parse command-line arguments\n\t    args = parser.parse_args()\n\t    if args.metrics:\n", "        # Get and print engagement metrics\n\t        engagement_metrics = get_video_engagement_metrics(args.video_id, api_key)\n\t        print(engagement_metrics)\n\t    elif args.comments is not None:\n\t        # Get and print comments\n\t        comments = get_video_comments(args.video_id, api_key, args.comments, not args.no_replies, args.order)\n\t        for comment, is_reply, datetime in comments:\n\t            print(f'{\"Reply\" if is_reply else \"Comment\"} ({datetime}): {comment}')\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/metadata/text_clustering_and_keyword_extraction.py", "chunked_list": ["from sklearn.feature_extraction.text import TfidfVectorizer\n\tfrom sklearn.cluster import KMeans\n\t# Assume descriptions contains the text data of the video descriptions\n\tdescriptions = [\"Python tutorial\", \"How to bake a cake\", \"Machine learning basics\", \"...\"]\n\t# Number of clusters\n\tnum_clusters = 3\n\t# Vectorize the descriptions using TF-IDF\n\tvectorizer = TfidfVectorizer(max_features=10000)\n\ttfidf = vectorizer.fit_transform(descriptions)\n\t# Perform KMeans clustering\n", "kmeans = KMeans(n_clusters=num_clusters)\n\tkmeans.fit(tfidf)\n\t# For each cluster, print the top keywords\n\tfor i in range(num_clusters):\n\t    print(f\"Niche #{i + 1}:\")\n\t    # Get the descriptions in this cluster\n\t    cluster_descriptions = tfidf[kmeans.labels_ == i]\n\t    # Sum the TF-IDF scores for each keyword\n\t    sum_tfidf = cluster_descriptions.sum(axis=0)\n\t    # Get the top 10 keywords in this cluster\n", "    top_keywords_indices = sum_tfidf.argsort()[0, ::-1][:10]\n\t    top_keywords = [vectorizer.get_feature_names_out()[index] for index in top_keywords_indices.flat]\n\t    print(top_keywords)\n"]}
{"filename": "src/metadata/youtube_search.py", "chunked_list": ["import os\n\timport urllib.request\n\timport re\n\timport requests\n\tfrom dotenv import load_dotenv\n\tfrom typing import Union, List\n\tdef get_unique_video_ids(search_query: str) -> List[str]:\n\t    \"\"\"\n\t    Get the unique video IDs from YouTube search results.\n\t    Args:\n", "        search_query (str): The search query to use on YouTube.\n\t    Returns:\n\t        List[str]: A list of unique video IDs from the search results.\n\t    \"\"\"\n\t    # Replace white spaces with a \"+\" symbol\n\t    search_query = search_query.replace(\" \", \"+\")\n\t    # Create a URL to search on YouTube using the search query\n\t    url = f\"https://www.youtub.com/results?search_query={search_query}&sp=CAMSBAgEEAE%253D\"\n\t    # Open the URL and read the HTML response\n\t    with urllib.request.urlopen(url) as html:\n", "        html_content = html.read().decode()\n\t    # Find all video IDs in the HTML content using a regular expression\n\t    video_ids = re.findall(r\"watch\\?v=(\\S{11})\", html_content)\n\t    # Convert the list of video IDs to a set to remove duplicates and then convert it back to a list\n\t    unique_video_ids = list(set(video_ids))\n\t    return unique_video_ids\n\tdef get_video_views(video_id: str, api_key: str) -> Union[str, None]:\n\t    \"\"\"\n\t    Get the view count for a specific YouTube video.\n\t    Args:\n", "        video_id (str): The ID of the YouTube video.\n\t        api_key (str): The Google API key.\n\t    Returns:\n\t        Union[str, None]: The view count for the video as a string, or None if an error occurred.\n\t    \"\"\"\n\t    # Construct the API URL\n\t    url = f'https://www.googleapis.com/youtube/v3/videos?part=statistics&id={video_id}&key={api_key}'\n\t    # Make a GET request to the API\n\t    response = requests.get(url)\n\t    # Check if the request was successful\n", "    if response.status_code == 200:\n\t        # Load the JSON response into a Python dictionary\n\t        data = response.json()\n\t        # Get the view count from the statistics object\n\t        view_count = data['items'][0]['statistics']['viewCount']\n\t        # Return the view count\n\t        return view_count\n\t    else:\n\t        # If the request was not successful, raise an exception\n\t        raise Exception(f'Error retrieving video data: {response.text}')\n", "def main():\n\t    # Load environment variables from .env file\n\t    load_dotenv()\n\t    # Get the API key from the environment variable GOOGLE_API_KEY\n\t    API_KEY = os.getenv('GOOGLE_API_KEY')\n\t    # Check if the API key was successfully loaded\n\t    if not API_KEY:\n\t        raise Exception('Missing API key. Please set the environment variable GOOGLE_API_KEY in the .env file.')\n\t    # Example usage\n\t    search_query = \"Mozart\"\n", "    video_ids = get_unique_video_ids(search_query)\n\t    for video_id in video_ids:\n\t        view_count = get_video_views(video_id, API_KEY)\n\t        print(f'The video with ID {video_id} has {view_count} views.')\n\t# Run the main function\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/metadata/check_channel_monitization.py", "chunked_list": ["\"\"\"\n\tThis module provides a function to check whether a given YouTube channel is monetized. \n\tThe function `is_monetized` sends a GET request to a specified YouTube channel URL and then \n\tparses the HTML of the page looking for the 'is_monetization_enabled' key in the script tags. \n\tIt then returns `True` if the key's value is set to `true` and `False` otherwise.\n\t\"\"\"\n\timport argparse\n\timport requests\n\tfrom bs4 import BeautifulSoup\n\tdef is_monetized(url):\n", "    \"\"\"\n\t    Determines if the specified YouTube channel is monetized.\n\t    Args:\n\t        url (str): The URL of the YouTube channel.\n\t    Returns:\n\t        bool: True if the channel is monetized, False otherwise.\n\t    \"\"\"\n\t    response = requests.get(url)\n\t    soup = BeautifulSoup(response.text, 'html.parser')\n\t    monetization_key = '{\"key\":\"is_monetization_enabled\",\"value\":\"true\"}'\n", "    scripts = soup.find_all('script')\n\t    for script in scripts:\n\t        # Make sure script.string is not None before checking for the monetization key\n\t        if script.string and monetization_key in script.string:\n\t            return True\n\t    return False\n\tdef main():\n\t    parser = argparse.ArgumentParser(description='Check if a YouTube channel is monetized.')\n\t    parser.add_argument('url', type=str, help='The URL of the YouTube channel to check.')\n\t    args = parser.parse_args()\n", "    print(is_monetized(args.url))\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/metadata/data_collection.py", "chunked_list": ["from metadata.get_youtube_video_tags import get_video_tags\n\tfrom metadata.video_engagement_metrics import get_video_engagement_metrics\n\tdef collect_data(video_id, api_key):\n\t    # Collect metadata about the video\n\t    tags = get_video_tags(video_id, api_key)\n\t    engagement_metrics = get_video_engagement_metrics(video_id, api_key)\n\t    # Combine the tags and engagement metrics into one dictionary\n\t    data = {**tags, **engagement_metrics}\n\t    return data\n"]}
{"filename": "src/metadata/get_youtube_video_tags.py", "chunked_list": ["import argparse\n\tfrom YoutubeTags import videotags\n\tdef get_video_tags(video_url: str) -> list:\n\t    \"\"\"Get a list of tags for a YouTube video.\n\t    Args:\n\t        video_url (str): URL of the YouTube video.\n\t    Returns:\n\t        list: List of tags for the video, or an empty list if tags could not be retrieved.\n\t    \"\"\"\n\t    try:\n", "        findtags = videotags(video_url)\n\t        return [tag.strip() for tag in findtags.split(\",\")]\n\t    except Exception as e:\n\t        print(f\"An error occurred while retrieving tags for the video: {e}\")\n\t        return []\n\tdef main():\n\t    parser = argparse.ArgumentParser(description='Get YouTube video tags')\n\t    parser.add_argument('url', type=str, help='YouTube video URL')\n\t    args = parser.parse_args()\n\t    tags = get_video_tags(args.url)\n", "    print(tags)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/metadata/__init__.py", "chunked_list": ["from sklearn.feature_extraction.text import TfidfVectorizer\n\tfrom sklearn.pipeline import Pipeline\n\tfrom sklearn.linear_model import LogisticRegression\n\tfrom sklearn.model_selection import train_test_split\n\t# Assume we have some dataset of videos with their metadata and labels\n\tvideos = [\n\t    {\"title\": \"Python Tutorial for Beginners\", \"description\": \"Learn Python programming\", \"tags\": [\"Python\", \"Programming\"], \"niche\": \"technology\"},\n\t    {\"title\": \"Easy Chocolate Cake Recipe\", \"description\": \"Delicious chocolate cake\", \"tags\": [\"Baking\", \"Cake\"], \"niche\": \"cooking\"},\n\t]\n\tmetadata = [video['title'] + ' ' + video['description'] + ' ' + ' '.join(video['tags']) for video in videos]\n", "labels = [video['niche'] for video in videos]\n\t# Split the data into training and testing sets\n\tmetadata_train, metadata_test, labels_train, labels_test = train_test_split(metadata, labels, test_size=0.2, random_state=42)\n\t# Create a pipeline for data preprocessing and training\n\tpipeline = Pipeline([\n\t    ('tfidf', TfidfVectorizer()),\n\t    ('clf', LogisticRegression()),\n\t])\n\t# Train the model\n\tpipeline.fit(metadata_train, labels_train)\n", "# Test the model\n\taccuracy = pipeline.score(metadata_test, labels_test)\n\tprint(f\"Model accuracy: {accuracy}\")\n\t# Now we can use the trained model to categorize new videos\n\tvideo = {\"title\": \"How to lose weight\", \"description\": \"Effective workout routines\", \"tags\": [\"Fitness\", \"Workout\"]}\n\tmetadata = video['title'] + ' ' + video['description'] + ' ' + ' '.join(video['tags'])\n\tprint(f\"Predicted niche: {pipeline.predict([metadata])[0]}\")"]}
{"filename": "src/video/__init__.py", "chunked_list": []}
{"filename": "src/video/utils.py", "chunked_list": ["from typing import Tuple\n\tfrom moviepy.editor import VideoFileClip\n\tdef get_video_size(filename: str) -> Tuple[int, int]:\n\t    \"\"\"\n\t    Get the dimensions (width and height) of a video file.\n\t    Args:\n\t        filename (str): The path to the video file.\n\t    Returns:\n\t        Tuple[int, int]: A tuple containing the width and height of the video, in the format (width, height).\n\t    \"\"\"\n", "    video = VideoFileClip(filename)\n\t    return (video.w, video.h)\n"]}
{"filename": "src/video/cut_video.py", "chunked_list": ["import time\n\timport argparse\n\tfrom pathlib import Path\n\timport moviepy.editor as mp\n\tdef split_video(input_path: Path, output_path: Path, start_time: int, end_time: int) -> None:\n\t    \"\"\"\n\t    Split a video file into a specified section.\n\t    Args:\n\t        input_path (Path): The path to the input video file.\n\t        output_path (Path): The path to the output video file.\n", "        start_time (int): The starting time in seconds.\n\t        end_time (int): The ending time in seconds.\n\t    Raises:\n\t        ValueError: If the input video file does not exist or if the start or end times are invalid.\n\t    \"\"\"\n\t    if not input_path.exists():\n\t        raise ValueError(f\"Input file {input_path} does not exist.\")\n\t    if (\n\t        not isinstance(start_time, int) \n\t        or not isinstance(end_time, int) \n", "        or start_time < 0 or end_time < 0\n\t        ):\n\t        raise ValueError(\"Start and end times must be non-negative integers.\")\n\t    video = mp.VideoFileClip(str(input_path))\n\t    video_clip = video.subclip(start_time, end_time)\n\t    try:\n\t        video_clip.write_videofile(str(output_path), fps=24)\n\t    except OSError:\n\t        print(\"Error: Unable to write output file.\")\n\t        time.sleep(10)\n", "        output_path.unlink()\n\t        video_clip.write_videofile(str(output_path), fps=24)\n\tdef main():\n\t    # Parse the command-line arguments\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\"input_path\", type=Path, help=\"The path to the input video file\")\n\t    parser.add_argument(\"output_path\", type=Path, help=\"The path to the output video file\")\n\t    parser.add_argument(\"start_time\", type=int, help=\"The starting time in seconds\")\n\t    parser.add_argument(\"end_time\", type=int, help=\"The ending time in seconds\")\n\t    args = parser.parse_args()\n", "    # Call the cut_video function with the parsed arguments\n\t    input_path = args.input_path\n\t    output_path = args.output_path\n\t    start_time = args.start_time\n\t    end_time = args.end_time\n\t    split_video(input_path, output_path, start_time, end_time)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/video/random_sample_clip.py", "chunked_list": ["import random\n\timport argparse\n\tfrom moviepy.video.io.VideoFileClip import VideoFileClip\n\tfrom moviepy.audio.io.AudioFileClip import AudioFileClip\n\tdef create_clip_with_matching_audio(video_path: str, audio_path: str, output_path: str) -> None:\n\t    \"\"\"\n\t    Create a video clip with the same duration as the provided audio file.\n\t    The video clip is extracted from the input video file and the audio is set to the provided audio file.\n\t    The resulting clip is saved to the output path.\n\t    Args:\n", "        video_path (str): The path to the input video file.\n\t        audio_path (str): The path to the input audio file.\n\t        output_path (str): The path to the output file where the resulting video clip will be saved.\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    # Load video and audio files\n\t    video = VideoFileClip(video_path)\n\t    audio = AudioFileClip(audio_path)\n\t    # Set duration of clip to match audio file\n", "    duration = audio.duration\n\t    # Get a random start time for the clip\n\t    start_time = random.uniform(0, video.duration - duration)\n\t    # Extract clip from the video\n\t    clip = video.subclip(start_time, start_time + duration)\n\t    # Set the audio of the clip to the audio file\n\t    clip = clip.set_audio(audio)\n\t    # Save the clip\n\t    clip.write_videofile(output_path, audio_codec=\"aac\")\n\tdef main():\n", "    parser = argparse.ArgumentParser(description='Create a video clip with matching audio')\n\t    parser.add_argument('video_path', type=str, help='path to video file')\n\t    parser.add_argument('audio_path', type=str, help='path to audio file')\n\t    parser.add_argument('output_path', type=str, help='path to output file')\n\t    args = parser.parse_args()\n\t    create_clip_with_matching_audio(args.video_path, args.audio_path, args.output_path)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/video/create_video_from_single_image.py", "chunked_list": ["import argparse\n\timport pathlib\n\timport subprocess\n\tfrom typing import Tuple\n\tfrom PIL import Image\n\tdef create_video_from_single_image(input_img: str, input_audio: str, output_file: str, output_extension: str = \"mp4\", img_size: Tuple[int, int] = (1080, 1920)) -> None:\n\t    \"\"\"\n\t    Creates a video using an input image and audio, with the specified output extension and image size.\n\t    :param input_img: Path to the input image file.\n\t    :param input_audio: Path to the input audio file.\n", "    :param output_file: Name of the output video file.\n\t    :param output_extension: Extension of the output video file. Default is 'mp4'.\n\t    :param img_size: Tuple containing the desired image width and height. Default is (1080, 1920).\n\t    \"\"\"\n\t    # Resize the input image to the specified resolution\n\t    image = Image.open(input_img)\n\t    resized_image = image.resize(img_size)\n\t    resized_image.save(input_img)\n\t    # Create the video using the resized image and specified output extension\n\t    output_path = pathlib.Path(output_file)\n", "    output_path = output_path.with_suffix(f\".{output_extension}\")\n\t    command = ['ffmpeg', '-loop', '1', '-i', input_img, '-i', input_audio, \"-vcodec\", \"mpeg4\", \"-acodec\", \"aac\", '-shortest', str(output_path), \"-y\", \"-r\", \"2\"]\n\t    print(command)\n\t    subprocess.run(command)\n\tdef main():\n\t    parser = argparse.ArgumentParser(description=\"Create a video using an input image and audio.\")\n\t    parser.add_argument(\"input_img\", help=\"Path to the input image\")\n\t    parser.add_argument(\"input_audio\", help=\"Path to the input audio\")\n\t    parser.add_argument(\"output_file\", help=\"Name of the output video file\")\n\t    parser.add_argument(\"-e\", \"--output_extension\", help=\"Extension of the output video file\", default=\"mp4\")\n", "    args = parser.parse_args()\n\t    create_video_from_single_image(args.input_img, args.input_audio, args.output_file, args.output_extension)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/video/concatenate_videos.py", "chunked_list": ["import argparse\n\tfrom moviepy.editor import VideoFileClip, concatenate_videoclips\n\tfrom typing import List\n\tdef concatenate_videos(videos: List[str], output: str) -> None:\n\t    \"\"\"\n\t    Concatenate a list of video files and save the resulting video to an output file.\n\t    Args:\n\t        videos (List[str]): A list of paths to the video files to be concatenated.\n\t        output (str): The path to the output file where the concatenated video will be saved.\n\t    Returns:\n", "        None\n\t    \"\"\"\n\t    # list of video clips\n\t    video_clips = []\n\t    for path in videos:\n\t        # load video\n\t        clip = VideoFileClip(path)\n\t        clip = clip.subclip()\n\t        # append clip to the list\n\t        video_clips.append(clip)\n", "    # concatenate the clips\n\t    final_clip = concatenate_videoclips(video_clips)\n\t    # write the final clip to file\n\t    final_clip.write_videofile(output)\n\tdef main():\n\t    # create a parser object\n\t    parser = argparse.ArgumentParser(description=\"Concatenate a list of videos\")\n\t    # add an argument for the list of videos\n\t    parser.add_argument(\"videos\", nargs=\"+\", type=str, help=\"the videos to concatenate\")\n\t    # add an argument for the output file name\n", "    parser.add_argument(\"-o\", \"--output\", type=str, default=\"final_video.mp4\", help=\"the output file name\")\n\t    # parse the arguments\n\t    args = parser.parse_args()\n\t    # call the concatenate_videos function with the parsed arguments\n\t    concatenate_videos(args.videos, args.output)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/utils/text_utils.py", "chunked_list": ["import re\n\tfrom typing import List, Dict, Union\n\tdef replace_caps_with_hyphens(sentence):\n\t    pattern = r'\\b([A-Z]+)\\b'\n\t    replacement = lambda match: '-'.join(list(match.group(1)))\n\t    return re.sub(pattern, replacement, sentence)\n\tdef remove_parenthesis(text:str):\n\t    # define the pattern to match\n\t    pattern = r'\\(([^\\s()]+)\\)'\n\t    # remove the tokens from the string using regular expressions\n", "    # remove any text enclosed in parentheses if it contains only one word\n\t    text_without_single_word_parentheses = re.sub(\n\t        pattern, lambda m: m.group(1) if ' ' in m.group(1) else '', text\n\t        )\n\t    # return text_without_tokens\n\t    return text_without_single_word_parentheses\n\tdef replace_hyphens_with_single_space(text):\n\t    return re.sub(r'-\\B|\\B-', ' ', text)\n\tdef add_spaces_around_hyphen(words):\n\t    return re.sub(r'([a-zA-Z])-([a-zA-Z])', r'\\1 - \\2', words)\n", "def add_spaces_around_hyphens(input_str):\n\t    # Replace all hyphens with a space followed by a hyphen followed by another space\n\t    # Example: 'A-I-T-A' -> 'A - I - T - A'\n\t    output_str = re.sub(r'-', ' - ', input_str)\n\t    return output_str\n\tdef clean_up(text:str) -> str:\n\t    text = \" \".join(text.split())\n\t    text = remove_parenthesis(text)\n\t    text = text.replace(\"\\\\\",\" slash \")\n\t    if \"r/\" in text:\n", "        text = text.replace(\"r/\", \" R slash \")\n\t    if \"AITA\" in text:\n\t        text = text.replace(\"AITA\", \" am i the asshole  \")\n\t    text = replace_hyphens_with_single_space(text)\n\t    text = replace_caps_with_hyphens(text)\n\t    text =  add_spaces_around_hyphen(text)\n\t    return text\n\tdef join_sentences(sentences: List[str]) -> List[str]:\n\t    '''splits body of text such that it never surpases maximum token 250'''\n\t    result = []\n", "    current_sentence = \"\"\n\t    current_word_count = 0\n\t    for sentence in sentences:\n\t        # split sentence into words and add to current word count\n\t        words = sentence.split()\n\t        current_word_count += len(words)\n\t        # if adding the current sentence would result in too many words, add the current sentence to the result\n\t        if current_word_count > 249:\n\t            result.append(current_sentence)\n\t            current_sentence = \"\"\n", "            current_word_count = 0\n\t        # add current sentence and a space to the result\n\t        if len(current_sentence) > 0:\n\t            current_sentence += \" \"\n\t        # add current sentence to the result\n\t        current_sentence += sentence\n\t    # add final sentence to the result\n\t    result.append(current_sentence)\n\t    return result\n\tdef turn_post_into_script(reddit_post,reddit_title):\n", "    ending = \" . Ever been in a situation like this? Leave it in the comment section. Like and subscribe if you enjoyed this video and want to see more like them. Thank you for watching my video. I hope you enjoyed it, and please have a wonderful day.\"\n\t    opening = f\"Today's story from reddit - - ... {reddit_title} ... let's get into the story ... \"\n\t    total_script = opening + reddit_post + ending\n\t    return total_script\n\tdef filter_text_by_list(text_list: List[Dict[str, Union[str, float]]], word_list: List[str]) -> List[Dict[str, Union[str, float]]]:\n\t    '''returns segments of swear words'''\n\t    filtered_list = []\n\t    for item in text_list:\n\t        # Remove all non-alphanumeric characters from the item's text\n\t        cleaned_text = re.sub(r'[^a-zA-Z\\d\\s]', '', item['text'])\n", "        if cleaned_text.lower() in word_list:\n\t            filtered_list.append(item)\n\t    return filtered_list\n"]}
{"filename": "src/utils/generate_subtitles.py", "chunked_list": ["from pathlib import Path\n\timport argparse\n\tfrom typing import List, Dict, Union\n\timport moviepy.editor as mp\n\timport whisperx\n\timport pandas as pd\n\tfrom moviepy.video.tools.subtitles import SubtitlesClip\n\tfrom moviepy.editor import VideoFileClip\n\tfrom src.video import utils\n\tTextSegmentList = [List[Dict[str, Union[str, float]]]]\n", "def transcribe_and_align(input_path: Path, device: str = \"cpu\", model_type: str = \"medium\") -> dict:\n\t    \"\"\"Transcribe and align audio file.\n\t    Args:\n\t        input_path (Path): Path to audio file.\n\t        device (str, optional): Device to use for transcription and alignment.\n\t            Defaults to \"cpu\".\n\t        model_type (str, optional): Type of model to use for transcription.\n\t            Defaults to \"medium\".\n\t    Returns:\n\t        dict: Aligned transcriptions.\n", "    \"\"\"\n\t    model = whisperx.load_model(model_type,device)\n\t    result = model.transcribe(input_path)\n\t    model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\t    result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, input_path, device)\n\t    return result_aligned\n\tdef segment_text_by_word_length(\n\t    my_list: list,\n\t    word_length_max: int = 5\n\t) -> TextSegmentList:\n", "    \"\"\"\n\t    Segments a list of dictionaries containing text and timestamps into groups of a specified maximum word length.\n\t    Args:\n\t        my_list (TextSegmentList): A list of dictionaries containing 'text', 'start', and 'end' keys.\n\t        word_length_max (int, optional): The maximum number of words per segment. Defaults to 5.\n\t    Returns:\n\t        TextSegmentList: A list of dictionaries containing the segmented text and corresponding start and end timestamps.\n\t    \"\"\"\n\t    if not isinstance(my_list, list):\n\t        raise TypeError(\"Input 'my_list' must be a list of dictionaries.\")\n", "    if not all(isinstance(item, dict) for item in my_list):\n\t        raise TypeError(\"Each item in 'my_list' must be a dictionary.\")\n\t    if not all(\n\t        all(key in item for key in [\"text\", \"start\", \"end\"])\n\t        for item in my_list\n\t    ):\n\t        raise ValueError(\"Each dictionary in 'my_list' must have 'text', 'start', and 'end' keys.\")\n\t    if not isinstance(word_length_max, int) or word_length_max < 1:\n\t        raise ValueError(\"Invalid value for 'word_length_max'. It must be a positive integer.\")\n\t    segmented_text = []\n", "    temp_segment = []\n\t    for item in my_list:\n\t        temp_segment.append(item)\n\t        if len(temp_segment) == word_length_max:\n\t            segmented_text.append(temp_segment)\n\t            temp_segment = []\n\t    if temp_segment:\n\t        segmented_text.append(temp_segment)\n\t    complete_segments = []\n\t    for segment in segmented_text:\n", "        start_time = segment[0]['start']\n\t        end_time = segment[-1]['end']\n\t        text = \" \".join(item['text'] for item in segment)\n\t        complete_segments.append({\"text\": text, \"start\": start_time, \"end\": end_time})\n\t    return complete_segments\n\tdef add_subtitles_to_video(input_path: str, output_path: str, word_segments: TextSegmentList) -> None:\n\t    \"\"\"\n\t    Add subtitles to a video file based on word segments with start and end times.\n\t    Args:\n\t        input_path (str): The path to the input video file.\n", "        output_path (str): The path to the output video file with subtitles added.\n\t        word_segments (TextSegmentList): A list of dictionaries containing 'text', 'start', and 'end' keys\n\t            for each word segment.\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    text_clip_data = {\n\t        'start': [segment['start'] for segment in word_segments],\n\t        'end': [segment['end'] for segment in word_segments],\n\t        'text': [segment['text'] for segment in word_segments]\n", "        }\n\t    df = pd.DataFrame.from_dict(text_clip_data)\n\t    movie_width, movie_height = utils.get_video_size(input_path)\n\t    # Write the video file\n\t    video = VideoFileClip(input_path)\n\t    generator = lambda txt: mp.TextClip(txt, fontsize=80, color='black', align='center', font='P052-Bold', stroke_width=3, bg_color=\"white\",method='caption',size=(movie_width, movie_height))\n\t    generator = lambda txt: mp.TextClip(txt, fontsize=80, color='white', align='center', font='P052-Bold', stroke_width=3, method='caption',size=(movie_width/2, movie_height),stroke_color=\"black\",)\n\t    subs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\n\t    subtitles = SubtitlesClip(subs, generator,)\n\t    final_clip = mp.CompositeVideoClip([video, subtitles.set_pos(('center','center')),])\n", "    try:\n\t        final_clip.write_videofile(output_path, fps=24)\n\t    except OSError:\n\t        Path(output_path).unlink()\n\t        final_clip.write_videofile(output_path, fps=24)\n\t    return output_path\n\tdef main():\n\t    # Set up the argument parser\n\t    parser = argparse.ArgumentParser(description=\"Create a webm video using an input image and audio.\")\n\t    parser.add_argument(\"input_path\", type=Path, help=\"Path to the input audio file.\")\n", "    parser.add_argument(\"output_path\",  type=Path, default=None, help=\"Path to the output video file. If not provided, the input path will be used with a different file extension.\")\n\t    parser.add_argument(\"--device\", type=str, default=\"cpu\", help=\"Device to use for transcription and alignment (default: 'cpu')\")\n\t    parser.add_argument(\"--model_type\", type=str, default=\"medium\", help=\"Type of model to use for transcription (default: 'medium')\")\n\t    args = parser.parse_args()\n\t    # Set the output path\n\t    if args.output_path is None:\n\t        output_path = args.input_path\n\t    else:\n\t        output_path = args.output_path\n\t    input_path = args.input_path\n", "    input_path = str(input_path)\n\t    output_path = str(output_path)\n\t    #  Transcribe the audio file and align the transcript\n\t    word_segments = transcribe_and_align(input_path, args.device, args.model_type)\n\t    word_segments = word_segments['word_segments']\n\t    # Add the subtitles to the video\n\t    add_subtitles_to_video(input_path, output_path, word_segments)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/utils/play_ht_api.py", "chunked_list": ["import requests\n\timport json\n\timport os\n\timport time\n\timport urllib.request\n\tfrom dotenv import load_dotenv\n\timport math\n\t# Load the .env file\n\tload_dotenv()\n\t# Get the value of the PLAYHT_API_KEY variable\n", "PLAYHT_API_KEY = os.getenv('PLAYHT_API_KEY')\n\tPLAYHT_API_USER_ID = os.getenv('PLAYHT_API_USER_ID')\n\tdef generate_ultra_track(body, voice=\"Larry\", speed=\"0.85\"):\n\t    \"\"\"\n\t    Generate an audio track using Play.ht API with the given text, voice, and speed.\n\t    Args:\n\t        body (str): The text content to be converted to audio.\n\t        voice (str, optional): The voice to be used for the audio. Defaults to \"Larry\".\n\t        speed (str, optional): The speed of the audio playback. Defaults to \"0.85\".\n\t    Returns:\n", "        str: The transcription ID of the generated audio track.\n\t    \"\"\"\n\t    url = \"https://play.ht/api/v1/convert\"\n\t    payload = json.dumps({\n\t    \"voice\": voice,\n\t    \"content\": [\n\t        body,\n\t    ],\n\t    \"speed\": speed,\n\t    \"preset\": \"balanced\"\n", "    })\n\t    headers = {\n\t    'Authorization': PLAYHT_API_KEY,\n\t    'X-User-ID': PLAYHT_API_USER_ID,\n\t    'Content-Type': 'application/json'\n\t    }\n\t    response = requests.request(\"POST\", url, headers=headers, data=payload)\n\t    print(response.text)\n\t    return json.loads(response.text)['transcriptionId']\n\tdef download_file(file_url, file_name, directory):\n", "    \"\"\"\n\t    Download a file from the specified URL and save it to the given directory with the given file name.\n\t    Args:\n\t        file_url (str): The URL of the file to download.\n\t        file_name (str): The name to save the downloaded file as.\n\t        directory (str): The directory to save the file in.\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    if not os.path.exists(directory):\n", "        os.makedirs(directory)\n\t    file_path = os.path.join(directory, file_name)\n\t    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}  \n\t    r = requests.get(file_url,headers=headers)\n\t    url = 'https://example.com/myfile.txt'\n\t    local_filename, headers = urllib.request.urlretrieve(file_url, file_path)\n\tdef ultra_play_ht_get_id(transaction_id: str):\n\t    \"\"\"\n\t    Get the audio URL for the given transcription ID using Play.ht API.\n\t    Args:\n", "        transaction_id (str): The transcription ID to get the audio URL for.\n\t    Returns:\n\t        str: The audio URL of the generated audio track.\n\t    \"\"\"\n\t    url = f\"https://play.ht/api/v1/articleStatus?transcriptionId={transaction_id}&ultra=true\"\n\t    payload = json.dumps({\n\t    'transcriptionId': transaction_id,\n\t    })\n\t    headers = {\n\t    'Authorization': PLAYHT_API_KEY,\n", "    'X-User-ID': PLAYHT_API_USER_ID,\n\t    'Content-Type': 'application/json'\n\t    }\n\t    response = requests.request(\"GET\", url, headers=headers, data=payload)\n\t    print(response.text)\n\t    return json.loads(response.text)['audioUrl'][0]\n\tdef generate_track_on_machine(body, file_name, directory, voice=\"Larry\", speed=\"0.85\"):\n\t    \"\"\"\n\t    Generate an audio track on a local machine with the given text, voice, and speed.\n\t    Args:\n", "        body (str): The text content to be converted to audio.\n\t        file_name (str): The name to save the generated audio file as.\n\t        directory (str): The directory to save the audio file in.\n\t        voice (str, optional): The voice to be used for the audio. Defaults to \"Larry\".\n\t        speed (str, optional): The speed of the audio playback. Defaults to \"0.85\".\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    id = generate_ultra_track(body,voice,speed)\n\t    audio_url = ultra_play_ht_get_id(id)\n", "    print(audio_url)\n\t    time.sleep(45)\n\t    try:\n\t        download_file(audio_url,file_name,directory)\n\t    except:\n\t        print(\"Issue downloading audio\")\n\tif __name__ == \"__main__\":\n\t    text = 'This was a few weeks ago. I was flying to visit my best friend across the USA FL-CA. I get on and am in the back of the plane in an aisle seat 23C. Upon arrival I see a 20 something (f) sitting in my seat so I point out \"Hey sorry you are probably in the wrong seat\" and show her my ticket. With an eye roll that could have sounded like she was playing Yahtzee she says \"oh I\\'m 24C.\" I look at 24C right behind her and see why she took my seat. There is a 300-400lb (f) sitting in the middle seat. I\\'m a 6\\'1 230lb (m) ...not ideal. After a 15 second stare down I say \"well?\" and she says she is \\'comfortable already\\' and \\'not moving\\' and \\'wants to sleep\\' blah blah. OK I see how it is....real dumb to put someone upset with you in the seat behind you...I proceeded to set a silent timer on my phone that went off every two minutes to remind myself to kick her seat, violently, and then every time the seat belt sign went off I\\'d get up, grabbing the top of the seat to lift myself up pulling her seat back and forth and one time (accidental but worth) pulled her hair she put over the back of the seat. Safe to say she had lots of extra \\'turbulence\\' and got absolutely no sleep. There were MANY death stares and head turns. Each time I would just smile and wave. I knew she wouldn\\'t say anything either because she is not even supposed to be in that seat anyways. Happy travels.'\n\t    words = text.split()\n\t    chunk_size = 10\n", "    num_chunks = math.ceil(len(words) / chunk_size)\n\t    time.sleep(400)\n\t    for i in range(num_chunks):\n\t        start = i * chunk_size\n\t        end = (i + 1) * chunk_size\n\t        chunk = \" \".join(words[start:end])\n\t        filename = f\"track_{i}.wav\"\n\t        generate_track_on_machine(chunk, filename, r\"\\sample\")\n\t        time.sleep(400)"]}
{"filename": "src/utils/reddit_api.py", "chunked_list": ["import os\n\tfrom dotenv import load_dotenv\n\timport praw\n\tfrom src.utils import text_utils\n\t# Load the .env file\n\tload_dotenv()\n\tREDDIT_CLIENT_ID = os.getenv('REDDIT_CLIENT_ID')\n\tREDDIT_CLIENT_SECRET = os.getenv('REDDIT_CLIENT_SECRET')\n\tdef fetch_reddit_posts(subreddit_name:str, top_posts_limit:int=3) -> dict:\n\t    # Get the data from a selected subreddit\n", "    reddit_subreddit = get_subreddit(subreddit_name)\n\t    # Query the top posts of the given subreddit\n\t    hot_subreddit_posts = reddit_subreddit.top(\"all\", limit=top_posts_limit)\n\t    hot_subreddit_posts = [*hot_subreddit_posts]\n\t    posts_dict = [{\"title\": text_utils.clean_up(post.title), \"body\": text_utils.clean_up(post.selftext)} for post in hot_subreddit_posts]\n\t    return posts_dict\n\tdef get_subreddit(sub:str):\n\t    reddit = praw.Reddit(client_id=REDDIT_CLIENT_ID,         \n\t    client_secret=REDDIT_CLIENT_SECRET,      \n\t    user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)\")\n", "    # get the subreddit\n\t    subreddit = reddit.subreddit(sub)\n\t    return subreddit\n\tdef turn_post_into_script(reddit_post,reddit_title):\n\t    ending = \" . Ever been in a situation like this? Leave it in the comment section. Like and subscribe if you enjoyed this video and want to see more like them. Thank you for watching my video. I hope you enjoyed it, and please have a wonderful day.\"\n\t    opening = f\"Today's story from reddit - - ... {reddit_title} ... let's get into the story ... \"\n\t    total_script = opening + reddit_post + ending\n\t    return total_script\n\tdef get_sub_comments(comment, allComments, verbose=True):\n\t    allComments.append(comment)\n", "    if not hasattr(comment, \"replies\"):\n\t        replies = comment.comments()\n\t        if verbose: print(\"fetching (\" + str(len(allComments)) + \" comments fetched total)\")\n\t        else:\n\t            replies = comment.replies\n\t        for child in replies:\n\t            get_sub_comments(child, allComments, verbose=verbose)\n\tdef get_all(r, submissionId, verbose=True):\n\t    submission = r.submission(submissionId)\n\t    comments = submission.comments\n", "    commentsList = []\n\t    for comment in comments:\n\t        get_sub_comments(comment, commentsList, verbose=verbose)\n\t        return commentsList\n"]}
{"filename": "src/utils/__init__.py", "chunked_list": []}
{"filename": "src/utils/utils.py", "chunked_list": ["import os\n\timport subprocess\n\timport re\n\tfrom typing import List, Dict, Any\n\tfrom datetime import timedelta\n\tfrom pathlib import Path\n\timport argparse\n\tfrom src.video import random_sample_clip\n\tfrom src.utils import generate_subtitles, text_utils\n\tfrom src.audio import audio_utils\n", "def combine_audio_and_video(\n\t        video_path: str, \n\t        audio_path: str, \n\t        output_path: str) -> None:\n\t    \"\"\"\n\t    Combine the given audio and video files into a single output video file.\n\t    Args:\n\t        video_path (str): The path to the input video file.\n\t        audio_path (str): The path to the input audio file.\n\t        output_path (str): The path to save the combined output video file.\n", "    Returns:\n\t        None\n\t    \"\"\"\n\t    ffmpeg_cmd = [\n\t        \"ffmpeg\",\n\t        \"-i\", video_path,\n\t        \"-i\", audio_path,\n\t        \"-c:v\", \"copy\",\n\t        \"-c:a\", \"aac\",\n\t        \"-map\", \"0:v:0\",\n", "        \"-map\", \"1:a:0\",\n\t        output_path,\n\t        \"-y\"\n\t    ]\n\t    subprocess.run(ffmpeg_cmd, check=True)\n\tdef generate_video_with_subtitles(\n\t        uncensored_audio_file: str, \n\t        source_video: str, \n\t        swear_word_list: List[str], \n\t        video_output_location: str, \n", "        srtFilename: str = \"\", \n\t        whisper_model: str = \"medium\") -> None:\n\t    \"\"\"\n\t    Generate a censored video with masked audio and subtitles.\n\t    Args:\n\t        uncensored_audio_file (str): The path to the uncensored audio file.\n\t        source_video (str): The path to the source video file.\n\t        swear_word_list (List[str]): A list of swear words to be censored.\n\t        video_output_location (str): The path to save the generated video.\n\t        srtFilename (str, optional): The path to save the subtitle file. If not provided, no subtitle file will be saved.\n", "        whisper_model (str, optional): The Whisper ASR model type. Defaults to \"medium\".\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    parent_folder = os.path.dirname(video_output_location)\n\t    srtFilename = os.path.join(parent_folder, srtFilename) if srtFilename else \"\"\n\t    video_clip = Path(\"sample.mp4\")\n\t    family_friendly_audio = Path(uncensored_audio_file).with_name(\"uncensored.wav\")\n\t    #complete script generated from audio file\n\t    raw_transcript = generate_subtitles.transcribe_and_align(\n", "        uncensored_audio_file,\n\t        model_type=whisper_model\n\t        )\n\t    segments = raw_transcript['segments']\n\t    segments = audio_utils.mask_swear_segments(\n\t        swear_word_list,\n\t        segments\n\t        )\n\t    if srtFilename:\n\t        if os.path.exists(srtFilename):\n", "            os.remove(srtFilename)\n\t        #generate srt file from segments\n\t        write_srt_file(segments, srtFilename)\n\t    raw_word_segments  = raw_transcript['word_segments']\n\t    #adds mask to existing script\n\t    masked_script = audio_utils.mask_swear_segments(\n\t        swear_word_list,\n\t        raw_word_segments\n\t        )\n\t    #find times when the speaker swears\n", "    swear_segments = text_utils.filter_text_by_list(\n\t        raw_word_segments,\n\t        swear_word_list\n\t        )\n\t    n_segment = generate_subtitles.segment_text_by_word_length(masked_script,)\n\t    audio_utils.silence_segments(\n\t        uncensored_audio_file,\n\t        str(family_friendly_audio),\n\t        swear_segments\n\t        )\n", "    random_sample_clip.create_clip_with_matching_audio(\n\t        source_video,\n\t        str(family_friendly_audio),\n\t        str(video_clip)\n\t        )\n\t    generate_subtitles.add_subtitles_to_video(\n\t        str(video_clip),\n\t        video_output_location,\n\t        n_segment\n\t        )\n", "    #remove temp files\n\t    os.remove(video_clip)\n\t    os.remove(family_friendly_audio)\n\tdef create_next_dir(input_directory: str) -> str:\n\t    input_directory = Path(input_directory)\n\t    is_absolute = input_directory.is_absolute()\n\t    # pattern to match directories\n\t    dir_pattern = r'story_\\d+'\n\t    current_directory = Path(os.getcwd())\n\t    if not is_absolute:\n", "        directory_path = Path.joinpath(current_directory, input_directory)\n\t        if directory_path.exists():\n\t            dirs = [d for d in os.listdir(directory_path) if re.match(dir_pattern, d)]\n\t            # extract the numbers from the directory names and convert them to integers\n\t            dir_numbers = [int(re.search(r'\\d+', d).group()) for d in dirs]\n\t            # get the maximum number\n\t            next_num = max(dir_numbers) + 1\n\t            # create the new directory name\n\t            new_dir = f'story_{next_num}'\n\t            directory_path = Path.joinpath(current_directory, input_directory, Path(new_dir))\n", "        else:\n\t            directory_path = Path.joinpath(current_directory, input_directory, Path('story_1'))\n\t    os.makedirs(directory_path)\n\t    return directory_path\n\tdef write_srt_file(segments: List[Dict[str, Any]], srt_filename: str) -> None:\n\t    \"\"\"\n\t    Write an SRT file from a list of video segments.\n\t    This function writes the given segments into an SRT (SubRip Text) file,\n\t    which is a common format for subtitles. Each segment includes start and end times\n\t    and the associated text.\n", "    Args:\n\t        segments: A list of dictionaries representing video segments, where each\n\t                  dictionary includes 'start', 'end', and 'text' keys.\n\t        srt_filename: The filename for the resulting SRT file.\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    for i, segment in enumerate(segments):\n\t        # Convert start and end times to SRT time format (hh:mm:ss,ms)\n\t        start_time = str(0)+str(timedelta(seconds=int(segment['start'])))+',000'\n", "        end_time = str(0)+str(timedelta(seconds=int(segment['end'])))+',000'\n\t        # Get the text associated with this segment\n\t        text = segment['text']\n\t        # Create the SRT-formatted string for this segment\n\t        srt_segment = f\"{i+1}\\n{start_time} --> {end_time}\\n{text[1:] if text[0] == ' ' else text}\\n\\n\"\n\t        # Append this segment to the SRT file\n\t        with open(srt_filename, 'a', encoding='utf-8') as srt_file:\n\t            srt_file.write(srt_segment)\n\tif __name__ == \"__main__\":\n\t    # swear_word_list = [*audio.audio_utils.get_swear_word_list().keys()]\n", "    swear_word_list = []\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\"uncensored_audio_file\", type=str, help=\"Path to the uncensored audio file\")\n\t    parser.add_argument(\"source_video\", type=str, help=\"Path to the source video file\")\n\t    parser.add_argument(\"video_output_location\", type=str, help=\"Path to the output video file\")\n\t    parser.add_argument(\"--swear_word_list\", type=str, nargs=\"+\", help=\"List of swear words to mask\", default=swear_word_list)\n\t    args = parser.parse_args()\n\t    generate_video_with_subtitles(args.uncensored_audio_file, args.source_video, args.swear_word_list, args.video_output_location)"]}
{"filename": "src/utils/upload_video.py", "chunked_list": ["from argparse import Namespace\n\timport argparse\n\timport os\n\tfrom googleapiclient.http import MediaFileUpload\n\tfrom googleapiclient.errors import HttpError\n\tfrom google_auth_oauthlib.flow import InstalledAppFlow\n\tfrom googleapiclient.discovery import build\n\tfrom moviepy.editor import VideoFileClip\n\tCLIENT_SECRETS_FILE = \"client_secret.json\"\n\tSCOPES = ['https://www.googleapis.com/auth/youtube.upload']\n", "API_SERVICE_NAME = 'youtube'\n\tAPI_VERSION = 'v3'\n\tdef get_authenticated_service() -> build:\n\t    \"\"\"\n\t    Authenticate the user using OAuth2.\n\t    Returns:\n\t        The authenticated service that can be used to interact with the YouTube API.\n\t    \"\"\"\n\t    flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n\t    credentials = flow.run_console()\n", "    return build(API_SERVICE_NAME, API_VERSION, credentials=credentials)\n\tdef validate_shorts(options: Namespace) -> None:\n\t    \"\"\"\n\t    Validate that the video file meets the requirements for YouTube Shorts.\n\t    Parameters:\n\t        options (Namespace): Command line arguments.\n\t    \"\"\"\n\t    # Check the video format and duration\n\t    video = VideoFileClip(options.file)\n\t    width, height = video.size\n", "    duration = video.duration\n\t    # Check if video is vertical (aspect ratio of 9:16)\n\t    if width / height != 9 / 16:\n\t        raise ValueError(\"Video is not in the correct aspect ratio for YouTube Shorts. It must be a vertical video (aspect ratio 9:16).\")\n\t    # Check if video is no longer than 60 seconds\n\t    if duration > 60:\n\t        raise ValueError(\"Video is too long for YouTube Shorts. It must be 60 seconds or less.\")\n\tdef initialize_upload(youtube: build, options: Namespace) -> None:\n\t    \"\"\"\n\t    Initialize the video upload to YouTube.\n", "    Parameters:\n\t        youtube (build): The authenticated YouTube API service.\n\t        options (Namespace): Command line arguments.\n\t    \"\"\"\n\t    tags = None\n\t    if options.keywords:\n\t        tags = options.keywords.split(',')\n\t    # Check if the video is a YouTube short and append \"#Shorts\" to the title\n\t    title = options.title\n\t    if options.youtubeShort:\n", "        title += \" #Shorts\"\n\t    body=dict(\n\t        snippet=dict(\n\t            title=title,\n\t            description=options.description,\n\t            tags=tags,\n\t            categoryId=options.category\n\t        ),\n\t        status=dict(\n\t            privacyStatus=options.privacyStatus,\n", "            madeForKids=options.madeForKids  \n\t        )\n\t    )\n\t    insert_request = youtube.videos().insert(\n\t        part=\",\".join(body.keys()),\n\t        body=body,\n\t        media_body=MediaFileUpload(options.file, chunksize=-1, resumable=True)\n\t    )\n\t    resumable_upload(youtube, insert_request, options)\n\tdef resumable_upload(youtube: build, insert_request: object, options: Namespace) -> None:\n", "    \"\"\"\n\t    Upload the video file to YouTube and track its progress.\n\t    Parameters:\n\t        youtube (build): The authenticated YouTube API service.\n\t        insert_request (object): The insert request object.\n\t        options (Namespace): Command line arguments.\n\t    \"\"\"\n\t    response = None\n\t    while response is None:\n\t        status, response = insert_request.next_chunk()\n", "        if 'id' in response:\n\t            print(f\"Video id {response['id']} was successfully uploaded.\")\n\t            set_thumbnail(youtube, options, response['id'])\n\tdef set_thumbnail(youtube: build, options: Namespace, video_id: str) -> None:\n\t    \"\"\"\n\t    Set the thumbnail of the uploaded video.\n\t    Parameters:\n\t        youtube (build): The authenticated YouTube API service.\n\t        options (Namespace): Command line arguments.\n\t        video_id (str): The ID of the uploaded video.\n", "    \"\"\"\n\t    youtube.thumbnails().set(\n\t        videoId=video_id,\n\t        media_body=MediaFileUpload(options.thumbnail)\n\t    ).execute()\n\tdef main():\n\t    \"\"\"\n\t    Parse command line arguments and upload a video to YouTube.\n\t    \"\"\"\n\t    parser = argparse.ArgumentParser()\n", "    parser.add_argument('--file', required=True, help='Video file to upload')\n\t    parser.add_argument('--title', help='Video title', default='Test Title')\n\t    parser.add_argument('--description', help='Video description', default='Test Description')\n\t    parser.add_argument('--category', default='27', help='Numeric video category. See https://developers.google.com/youtube/v3/docs/videoCategories/list')\n\t    parser.add_argument('--keywords', help='Video keywords, comma separated', default='')\n\t    parser.add_argument('--privacyStatus', choices=['public', 'private', 'unlisted'], default='private', help='Video privacy status.')\n\t    parser.add_argument('--thumbnail', help='Thumbnail image file', default='')\n\t    parser.add_argument('--madeForKids', type=bool, default=False, help='Made for kids field.')\n\t    parser.add_argument('--youtubeShort', type=bool, default=False, help='Is this a YouTube short, if so it must have a aspect ratio of 9:16?')  # Added 'youtubeShort' argument\n\t    args = parser.parse_args()\n", "    if args.youtubeShort:\n\t        validate_shorts(args)\n\t    youtube = get_authenticated_service()\n\t    try:\n\t        initialize_upload(youtube, args)\n\t    except HttpError as e:\n\t        print(f'An HTTP error {e.resp.status} occurred:\\n{e.content}')\n\tif __name__ == '__main__':\n\t    main()"]}
{"filename": "src/images/__init__.py", "chunked_list": []}
{"filename": "src/images/thumbnail.py", "chunked_list": ["import os\n\timport requests\n\tfrom typing import List, Dict, Optional\n\tfrom PIL import Image, ImageDraw, ImageFont\n\tfrom rembg import remove\n\tdef create_thumbnail(segmented_image:str,text:List[Dict],output_image=\"thumbnail.png\"):\n\t    # load the background image\n\t    background_dimensions = (1280, 720)\n\t    background = Image.new(\"RGB\", background_dimensions, (0, 0, 0))\n\t    # load the image to be placed on the right\n", "    image = Image.open(segmented_image)\n\t    # resize the image to fit on the background\n\t    max_width = 6000\n\t    max_height = background.height\n\t    width, height = image.size\n\t    if width > max_width or height > max_height:\n\t        ratio = min(max_width/width, max_height/height)\n\t        new_width = int(width * ratio)\n\t        new_height = int(height * ratio)\n\t        image = image.resize((new_width, new_height))\n", "    padding = 0 \n\t    image_y = background.height - image.height - padding\n\t    x_edge = background.width - image.width\n\t    # place the image on the right side of the background\n\t    background.paste(image, (x_edge, image_y))\n\t    # create a draw object\n\t    draw = ImageDraw.Draw(background)\n\t    # iterate over the list of text objects and draw them on the left side of the background\n\t    for item in text:\n\t        # get the text and formatting information\n", "        text = item[\"text\"]\n\t        color = item[\"color\"]\n\t        spacingTop = item[\"spacingTop\"]\n\t        size = item[\"size\"]\n\t        font_location = item['font']\n\t        # set the font and color\n\t        draw.text((30, spacingTop), text, font=ImageFont.truetype(font_location, size), fill=color,)\n\t    # save the resulting image\n\t    background.save(output_image)\n\tdef create_thumbnail(segmented_image: str, \n", "                     text_items: List[Dict[str, object]], \n\t                     output_image: Optional[str] = None, \n\t                     text_x_pos: int = 0, \n\t                     default_font_location: str = \"arial.ttf\",\n\t                     y_spacing: int = 1) -> Image.Image:\n\t    \"\"\"\n\t    Create a thumbnail image from a background, segmented image, and text.\n\t    This function generates a thumbnail image by combining a provided segmented image with text\n\t    drawn on the left side. The text_items parameter is a list of dictionaries, each containing\n\t    the text to be drawn and its formatting options. The resulting image can be saved to disk\n", "    or returned as a PIL.Image object.\n\t    Args:\n\t        segmented_image (str): Path to the segmented image file.\n\t        text_items (List[Dict[str, object]]): A list of dictionaries containing the text and\n\t            its formatting options. Each dictionary should have the following keys:\n\t            - \"text\": The text string to be drawn.\n\t            - \"color\": The text color in RGB format.\n\t            - \"size\": The font size.\n\t            - \"font\" (optional): Path to the font file. Defaults to arial.ttf.\n\t            - \"y_spacing\" (optional): Vertical spacing between text lines. Defaults to 1.\n", "        output_image (Optional[str], optional): Path to save the output image. If not provided,\n\t            the function will return the generated image as a PIL.Image object.\n\t        text_x_pos (int, optional): The x-coordinate of the starting position for the text.\n\t            Defaults to 0.\n\t        default_font_location (str, optional): Path to the default font file. Defaults to \"arial.ttf\".\n\t        y_spacing (int, optional): Default vertical spacing between text lines. Defaults to 1.\n\t    Returns:\n\t        Image.Image: The generated thumbnail image. Returned only if output_image is not provided.\n\t    \"\"\"\n\t    # Load the background image\n", "    background_dimensions = (1280, 720)\n\t    background_color = (0, 0, 0)\n\t    background = Image.new(\"RGB\", background_dimensions, background_color)\n\t    # Load the image to be placed on the right\n\t    image = Image.open(segmented_image)\n\t    # Resize the image to fit on the background\n\t    max_width = 6000  # This value seems too high for a thumbnail\n\t    max_height = background.height\n\t    width, height = image.size\n\t    if width > max_width or height > max_height:\n", "        ratio = min(max_width/width, max_height/height)\n\t        new_width = int(width * ratio)\n\t        new_height = int(height * ratio)\n\t        image = image.resize((new_width, new_height))\n\t    # Calculate the y-coordinate of the image\n\t    image_y = background.height - image.height\n\t    # Place the image on the right side of the background\n\t    background.paste(image, (background.width - image.width, image_y))\n\t    # Create a draw object\n\t    draw = ImageDraw.Draw(background)\n", "    # Set default text position\n\t    text_y_pos = 0\n\t    # Iterate over the list of text objects and draw them on the left side of the background\n\t    for item in text:\n\t        # Get the text and formatting information\n\t        text = item[\"text\"]\n\t        color = item[\"color\"]\n\t        y_spacing = item.get(\"y_spacing\", y_spacing)\n\t        size = item[\"size\"]\n\t        font_location = item.get(\"font\", default_font_location)\n", "        # Set the font and color\n\t        font = ImageFont.truetype(font_location, size)\n\t        text_width, text_height = draw.textsize(text, font=font)\n\t        draw.text((text_x_pos, text_y_pos + y_spacing), text, font=font, fill=color)\n\t        # Update the text position\n\t        text_y_pos += text_height + y_spacing\n\t    # Save the resulting image\n\t    if output_image:\n\t        background.save(output_image)\n\t    else:\n", "        return background\n\tdef segment_image(input_path:str,output_path:str):\n\t    input = Image.open(input_path)\n\t    output = remove(input)\n\t    output.save(output_path)\n\tdef crop_png(input_data: str, output_data: str) -> None:\n\t    \"\"\"\n\t    Crop a PNG image to the non-transparent area and save it to a file.\n\t    Args:\n\t        input_data (str): The path to the input image file.\n", "        output_data (str): The path to save the cropped image file.\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    # Open the image\n\t    image = Image.open(input_data)\n\t    # Get the size of the image\n\t    width, height = image.size\n\t    # Get the alpha channel of the image\n\t    alpha = image.split()[-1]\n", "    # Find the bounding box of the non-transparent part of the image\n\t    bbox = alpha.getbbox()\n\t    # Crop the image to the bounding box\n\t    cropped_image = image.crop(bbox)\n\t    # Save the cropped image\n\t    cropped_image.save(output_data)\n\tdef crop_transparent(image_path: str, output_path: str):\n\t    \"\"\"Crop a transparent image and save to a file.\n\t    Args:\n\t        image_path (str): The path to the input image.\n", "        output_path (str): The path to save the cropped image.\n\t    Returns:\n\t        None\n\t    \"\"\"\n\t    # Open the image\n\t    image = Image.open(image_path)\n\t    # Get the size of the image\n\t    width, height = image.size\n\t    # Find the dimensions of the non-transparent part of the image\n\t    left, top, right, bottom = width, height, 0, 0\n", "    for x in range(width):\n\t        for y in range(height):\n\t            alpha = image.getpixel((x,y))[3]\n\t            if alpha != 0:\n\t                left = min(left, x)\n\t                top = min(top, y)\n\t                right = max(right, x)\n\t                bottom = max(bottom, y)\n\t    # Crop the image to the non-transparent part\n\t    image = image.crop((left, top, right, bottom))\n", "    # Save the cropped image\n\t    image.save(output_path)\n\tdef download_image(url: str, directory: str = \".\") -> str:\n\t    \"\"\"\n\t    Download an image from a URL and save it to a directory.\n\t    Args:\n\t        url (str): The URL of the image to download.\n\t        directory (str): The directory to save the image in. Defaults to the current directory.\n\t    Returns:\n\t        str: The file path of the downloaded image if successful, else None.\n", "    \"\"\"\n\t    response = requests.get(url)\n\t    if response.status_code == 200:\n\t        filename = os.path.basename(url)\n\t        filepath = os.path.join(directory, filename)\n\t        with open(filepath, \"wb\") as f:\n\t            f.write(response.content)\n\t        return filepath\n\t    else:\n\t        return None\n", "def convert_to_png(sample:str) -> str:\n\t    \"\"\"\n\t    Converts the input image file to PNG format if it is a JPEG file.\n\t    Args:\n\t        sample (str): The path to the input image file.\n\t    Returns:\n\t        str: The path to the output image file. If the input image file is already in PNG format, returns the original file path.\n\t    \"\"\"\n\t    img = Image.open(sample)\n\t    if img.format == \"JPEG\":\n", "        img = img.convert(\"RGBA\")\n\t        os.remove(sample)\n\t        # get the base file name and old extension\n\t        base_name, old_extension = os.path.splitext(sample)\n\t        # replace the old extension with \".png\"\n\t        new_file_path = base_name + \".png\"\n\t        img.save(new_file_path)\n\t    else:\n\t        new_file_path = sample\n\t    return new_file_path\n", "if __name__ == '__main__':\n\t    data = \"https://th.bing.com/th/id/R.3d79e075f692870894fc41d6304eb4f2?rik=GfJgXZ5%2b5MJCVQ&riu=http%3a%2f%2fwww.pixelstalk.net%2fwp-content%2fuploads%2f2016%2f05%2fReally-Cool-Image.jpg\"\n\t    data = \"https://www.lockheedmartin.com/content/dam/lockheed-martin/eo/photo/news/features/2021/ai/ai-small-1920.jpg.pc-adaptive.768.medium.jpeg\"\n\t    data = \"https://images.girlslife.com/posts/009/9250/shutterstock_406983616.jpg\"\n\t    data = \"https://www.aaa.com/AAA/common/AAR/images/deice1.png\"\n\t    sample = download_image(data)\n\t    ff = convert_to_png(sample)\n\t    # segment_image(ff,ff)\n\t    # crop_png(ff,ff)\n\t    # default_font_location = r\"C:\\Users\\isaya\\Downloads\\Press_Start_2P\\PressStart2P-Regular.ttf\"\n", "    # default_font_location = \"arial.ttf\"\n\t    # text = [\n\t    #     {\"text\": \"r/Petty revenge\", \"color\" : (255,255,255), \"spacingTop\": 0, \"size\" : 90, \"font\": default_font_location},\n\t    #     {\"text\": \"\", \"color\" : (255,0,0), \"spacingTop\": 90, \"size\" : 90, \"font\": default_font_location},\n\t    #     {\"text\": \"taken? I'll go to \", \"color\" : (255,255,255), \"spacingTop\": 180, \"size\" : 90, \"font\": default_font_location},\n\t    #     {\"text\": \"first class\", \"color\" : (255, 215, 0), \"spacingTop\": 270, \"size\" : 90, \"font\": default_font_location}\n\t    # ]\n\t    # input_data = r\"c:\\Users\\isaya\\code_examples\\Machine_Learning\\img_manipulation\\japanese_robot.jpg\"\n\t    # output_data = r\"c:\\Users\\isaya\\code_examples\\Machine_Learning\\img_manipulation\\_robot.png\"\n\t    # segment_image(input_data,output_data)\n", "    # crop_png(output_data,output_data)\n\t    # default_font_location = \"arial.ttf\"\n\t    # ff = r\"c:\\Users\\isaya\\code_examples\\Machine_Learning\\img_manipulation\\toy_boat_0.jpg\"\n\t    # text = [\n\t    #     {\"text\": \"r/Petty revenge\", \"color\" : (255,255,255), \"size\" : 90, \"font\": default_font_location},\n\t    #     {\"text\": \"Allow my seat to be\", \"color\" : (255,0,0), \"size\" : 90, \"font\": default_font_location},\n\t    #     {\"text\": \"taken? I'll go to \", \"color\" : (255,255,255), \"size\" : 90, \"font\": default_font_location},\n\t    #     {\"text\": \"first class\", \"color\" : (255,255,255), \"size\" : 90, \"font\": default_font_location},\n\t    # ]\n\t    # create_thumbnail(ff, text, \"thumbnail.png\",text_x_pos=20)\n", "    # create_thumbnail(ff,text,\"fuck.png\")\n\t    # create_thumbnail(output_data,text,\"fuck.png\")"]}
{"filename": "src/youtube/__init__.py", "chunked_list": []}
