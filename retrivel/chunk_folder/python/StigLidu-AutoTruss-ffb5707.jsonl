{"filename": "Stage1/continuous_uct_3d.py", "chunked_list": ["import numpy as np\n\timport logging\n\timport math, time\n\timport os, sys, contextlib, platform\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import get_base_config, make_config\n\tfrom utils.utils import readFile, readAlist, save_file_from_list, util_init\n\tfrom apps.draw import *\n\tfrom algo.UCTs import *\n", "from truss_envs.reward import *\n\tparser = get_base_config()\n\targs = parser.parse_known_args(sys.argv[1:])[0]\n\tconfig = make_config(args.config)\n\tfor k, v in config.get(\"base\", {}).items():\n\t    if f\"--{k}\" not in args:\n\t        setattr(args, k, v)\n\tprint(config)\n\tdef main():\n\t    p, e = readFile(args.input_path)\n", "    if not os.path.exists('results_3d/' + args.config):\n\t        os.mkdir('results_3d/' + args.config)\n\t    # save and load path\n\t    LOGFOLDER = args.save_path\n\t    if not os.path.exists(LOGFOLDER): os.mkdir(LOGFOLDER)\n\t    if (args.useAlist == True): Alist = readAlist(args.Alist_path)\n\t    else: Alist = None\n\t    Envs_init(args)\n\t    UCTs_init(args, arealist__ = Alist)\n\t    util_init(args)\n", "    bestreward, pbest, ebest = UCTSearch(p, e)\n\t    print(\"bestreward =\",bestreward)\n\t    print(reward_fun(pbest, ebest))\n\tif __name__ == '__main__':\n\t    if not os.path.exists('results_3d/'):\n\t        os.mkdir('results_3d/')\n\t    main()"]}
{"filename": "Stage1/noise_input_permutation_format_transfer.py", "chunked_list": ["import time\n\timport json\n\timport numpy as np\n\timport math\n\timport random\n\timport copy\n\timport matplotlib.pyplot as plt\n\timport warnings\n\timport os, sys, contextlib\n\timport openseespy.opensees as op\n", "import heapq\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import get_base_config, make_config\n\tparser = get_base_config()\n\targs = parser.parse_known_args(sys.argv[1:])[0]\n\tconfig = make_config(args.config)\n\tfor k, v in config.get(\"base\", {}).items():\n\t    if f\"--{k}\" not in args:\n\t        setattr(args, k, v)\n", "if not os.path.exists('PostResults'):\n\t    os.mkdir('PostResults')\n\tif not os.path.exists('PostResults/' + args.config):\n\t    os.mkdir('PostResults/' + args.config)\n\tOrgF = os.path.join(args.save_path, args.run_id)\n\tTarFolder = os.path.join(args.input_path_2, args.run_id)\n\tif not os.path.exists(TarFolder):\n\t    os.mkdir(TarFolder)\n\tOrgFolder = os.path.join(OrgF, args.transfer_filefold)\n\tprint(OrgFolder)\n", "permutation = [0, 1, 2, 3]\n\t    #if not os.path.exists(TarFolder):\n\t    #    os.mkdir(TarFolder)\n\tfiles = os.listdir(OrgFolder)\n\tfiles.sort(key = lambda x: int(x[:-4]))\n\tselected_files = []\n\tmax_idx = len(files)\n\t#print('max_idx', max_idx)\n\tif (args.finetune == False):\n\t    for _ in range(min(args.max_num_topo_truss, max_idx)):\n", "        _idx = _\n\t        selected_files.append(files[_idx])\n\telse: \n\t    assert(max_idx > args.max_num_topo_truss)\n\t    right = min(args.max_num_topo_truss * 2, max_idx)\n\t    for _ in range(args.max_num_topo_truss, right):\n\t        _idx = _\n\t        selected_files.append(files[_idx])\n\tprint(selected_files)\n\tfor idfile, file in enumerate(selected_files):\n", "        FILENAME = os.path.join(OrgFolder, file)\n\t        #SAVENAME = TarFolder + file\n\t        #SAVENAME = SAVENAME[:-4]\n\t        #SAVENAME += folder_name\n\t        #SAVENAME += '.txt'\n\t        if file[-4:] != '.txt': continue\n\t        with open(FILENAME, \"r\") as fle:\n\t            lines = fle.readlines()\n\t            for i in range(len(lines)):\n\t                line = lines[i]\n", "                vec = line.strip().split(' ')\n\t                if (i == 0):\n\t                    vn = int(vec[0])\n\t                    en = int(vec[1])\n\t                    Edges = [[- 1.0 for _ in range(vn)] for _ in range(vn)]\n\t                    d = [[- 1.0 for _ in range(vn)] for _ in range(vn)]\n\t                    t = [[- 1.0 for _ in range(vn)] for _ in range(vn)]\n\t                    Nodes = []\n\t                    nodes_position = []\n\t                    continue\n", "                if (1 <= i and i <= vn):\n\t                    Nodes.append(line)\n\t                    nodes_position.append([vec[0], vec[1], vec[2]])\n\t                    continue\n\t                if (vn + 1 <= i and i <= vn + en):\n\t                    node1 = int(vec[0])\n\t                    node2 = int(vec[1])\n\t                    Edges[node1][node2] = vec[2]\n\t                    Edges[node2][node1] = vec[2]\n\t                    d[node1][node2] = vec[3]\n", "                    d[node2][node1] = vec[3]\n\t                    t[node1][node2] = vec[4]\n\t                    t[node2][node1] = vec[4]\n\t        mass = 0\n\t        pho = args.pho\n\t        for v_i in range(vn):\n\t            for v_j in range(vn):\n\t                if v_i < v_j:\n\t                    i_x = float(nodes_position[v_i][0])\n\t                    i_y = float(nodes_position[v_i][1])\n", "                    i_z = float(nodes_position[v_i][2])\n\t                    j_x = float(nodes_position[v_j][0])\n\t                    j_y = float(nodes_position[v_j][1])\n\t                    j_z = float(nodes_position[v_j][2])\n\t                    area = float(Edges[v_i][v_j])\n\t                    if area == -1:\n\t                        continue\n\t                    mass += math.sqrt((i_x - j_x) ** 2 + (i_y - j_y) ** 2 + (i_z - j_z) ** 2) * area * args.pho\n\t        SAVENAME = os.path.join(TarFolder, str(round(mass * 1000)) + '_' + str(idfile).zfill(2) + '.txt')\n\t        #print(mass, SAVENAME)\n", "        PermutationEdges = [[- 1.0 for _ in range(vn)] for _ in range(vn)]\n\t        Permutationd = [[- 1.0 for _ in range(vn)] for _ in range(vn)]\n\t        Permutationt = [[- 1.0 for _ in range(vn)] for _ in range(vn)]\n\t        for i in range(vn):\n\t            for j in range(vn):\n\t                new_i = i\n\t                new_j = j\n\t                if i < len(permutation):\n\t                    new_i = permutation[i]\n\t                if j < len(permutation):\n", "                    new_j = permutation[j]\n\t                PermutationEdges[i][j] = Edges[new_i][new_j]\n\t                PermutationEdges[j][i] = Edges[new_j][new_i]\n\t                Permutationd[i][j] = d[new_i][new_j]\n\t                Permutationd[j][i] = d[new_j][new_i]\n\t                Permutationt[i][j] = t[new_i][new_j]\n\t                Permutationt[j][i] = t[new_j][new_i]\n\t        with open(SAVENAME, \"w\") as f:\n\t            print(int(vn), int(vn * (vn - 1) / 2), file=f)\n\t            for i in range(len(Nodes)):\n", "                new_i = i\n\t                if i < len(permutation):\n\t                    new_i = permutation[i]\n\t                print(Nodes[new_i], file=f, end='')\n\t            for j in range(vn):\n\t                for i in range(vn):\n\t                    if i < j:\n\t                        print(int(i), int(j), PermutationEdges[i][j], Permutationd[i][j], Permutationt[i][j], file=f)"]}
{"filename": "configs/config.py", "chunked_list": ["from typing import Dict\n\timport argparse\n\timport yaml\n\tdef get_base_config():\n\t    parser = argparse.ArgumentParser(\n\t        description='RL_truss_layout',\n\t        formatter_class=argparse.RawDescriptionHelpFormatter)\n\t    parser.add_argument('--config', type = str)\n\t# args for UCTs:\n\t    parser.add_argument(\"--c\", default = [30.0, 30.0, 30.0])\n", "    parser.add_argument(\"--rate2\", default = 0.9)\n\t    parser.add_argument(\"--prob\", default = 1.0)\n\t    parser.add_argument(\"--alpha\", default = 0.3)\n\t    parser.add_argument(\"--rate\", default = 0)\n\t    parser.add_argument(\"--pickalpha\", default = 0)\n\t    parser.add_argument(\"--sgm1\", default = 0.0005)\n\t    parser.add_argument(\"--sgm2\", default = 0.5)\n\t    parser.add_argument(\"--maxnum\", default = 25)\n\t    parser.add_argument(\"--maxson\", default = 200)\n\t    parser.add_argument(\"--UCT-maxiter\", type = int, default = 300000)\n", "    parser.add_argument(\"--UCT_extra_iter_for_point_pos\", type = int, default = 250000)\n\t    parser.add_argument(\"--initson\", default = 25)\n\t    parser.add_argument(\"--USE-VALUE-NETWORK\", type = bool, default = 0)\n\t# args for Env:\n\t    parser.add_argument(\"--bad-attempt-limit\", default = 5)\n\t    parser.add_argument(\"--maxp\", default = 10)\n\t    parser.add_argument(\"--env-dims\", default = 3, type = int)\n\t    parser.add_argument(\"--env-mode\", default='DT', choices=['Area', 'DT'])\n\t    parser.add_argument(\"--useIntersect\", default = True)\n\t    parser.add_argument('--coordinate_range', type=list, default=[(0.0, 4.634), (-0.483, 0.7725), (-0.5, 1.0)], help='points\\' range')\n", "    parser.add_argument('--area_range', type=list, default=(0.0001, 0.003028), help='edges\\' area range')\n\t    parser.add_argument(\"--len_range\", type=list, default = (0.03, 5.0), help='edges\\' length range')    \n\t    parser.add_argument('--area_delta_range', type=list, default=(-0.0005, 0.0005), help='edges\\' area delta range')\n\t    parser.add_argument('--coordinate_delta_range', type=list, default=[(-0.5715, 0.5715), (-0.5715, 0.5715), (-0.5715, 0.5715)], help='nodes\\' coordinate delta range')\n\t    parser.add_argument('--d-range', type=list, default=(0.025, 0.12))\n\t    parser.add_argument('--t-range', type=list, default=(0.0015, 0.005))\n\t    parser.add_argument('--d-delta-range', type=list, default=(-0.05, 0.05))\n\t    parser.add_argument('--t-delta-range', type=list, default=(-0.005, 0.005))\n\t    parser.add_argument(\"--usePlist\", default = False)\n\t    parser.add_argument(\"--Plist-path\", type = str, default = None)\n", "    parser.add_argument(\"--useAlist\", default = True)\n\t    parser.add_argument(\"--Alist-path\", type = str, default = 'input/sectionList3.txt')\n\t    parser.add_argument(\"--input-path\", type = str, default = 'input/kr-sundial-newinput.txt')\n\t    parser.add_argument(\"--ratio_ring\", default = 0.0)\n\t    parser.add_argument('--fixed_points', type=int, default=4, help='number of fixed nodes')\n\t    parser.add_argument('--variable_edges', type=int, default=-1, help='number of variable edges, -1 if all is variable')\n\t    parser.add_argument('--symmetry-build', type=int, default=0)\n\t# args for dynamics:\n\t    parser.add_argument('--E', type = float, default = 1.93*10**11)\n\t    parser.add_argument('--pho', type = float, default = 8.0*10**3)\n", "    parser.add_argument('--sigma-T', type = float, default = 123.0*10**6)\n\t    parser.add_argument('--sigma-C', type = float, default = 123.0*10**6)\n\t    parser.add_argument('--slenderness_ratio_c', type = float, default = 180.0)\n\t    parser.add_argument('--slenderness_ratio_t', type = float, default = 220.0)\n\t    parser.add_argument('--dislimit', type = float, default = 0.002)\n\t    parser.add_argument('--CONSTRAINT-CROSS-EDGE', type = int, default = 1)\n\t    parser.add_argument('--CONSTRAINT-STRESS', type = int, default = 1)\n\t    parser.add_argument('--CONSTRAINT-DIS', type = int, default = 1)\n\t    parser.add_argument('--CONSTRAINT-BUCKLE', type = int, default = 1)\n\t    parser.add_argument('--CONSTRAINT-SLENDERNESS', type = int, default = 1)\n", "    parser.add_argument(\"--CONSTRAINT-MAX-LENGTH\", type = int, default = 1)\n\t    parser.add_argument(\"--CONSTRAINT-MIN-LENGTH\", type = int, default = 1)\n\t    parser.add_argument(\"--CONSTRAINT-SELF-WEIGHT\", type = int, default = 1)\n\t    parser.add_argument(\"--NEW_CONST....\", type = int, default = 1)\n\t# args for save and load:\n\t    parser.add_argument(\"--save-KR\", default = False)\n\t    parser.add_argument(\"--save-diversity\", type = bool, default = True)\n\t    parser.add_argument(\"--save-path\", type = str, default = './results_3d/')\n\t    parser.add_argument(\"--input-path-2\", type = str, default = './PostResults/')\n\t    parser.add_argument(\"--save-model-path\", type = str, default = './saved_models/')\n", "    parser.add_argument(\"--finetune-model-path\", type = str, default = './saved_models/')\n\t    parser.add_argument(\"--OUTPUT_ALL_THRESHOLD\", type = float, default = 4000)\n\t    parser.add_argument(\"--MASS_OUTPUT_ALL_THRESHOLD\", type = float, default = 4000)\n\t    parser.add_argument(\"--save-invalid-factor\", type = int, default = 0)\n\t    parser.add_argument(\"--run-id\", type = str, default = '.')\n\t    parser.add_argument(\"--logfile-stage1\", type = str, default = 'log_stage1.log')\n\t    parser.add_argument(\"--logfile-stage2\", type = str, default = 'log_stage2.log')\n\t    parser.add_argument(\"--transfer-filefold\", type = str, default = 'DIVERSITY_TOPO_result')\n\t# args for Reward:\n\t    parser.add_argument(\"--reward_lambda\", default = 10 * 50 * 50)\n", "# args for RL:    \n\t    parser.add_argument('--initial_state_files', type=str, default='PostResults/', help='input file for refine')\n\t    parser.add_argument('--num_trains_per_train_loop', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--num_train_loops_per_epoch', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--hidden-dims', type=list, default=[256, 512], help='hidden layer dimensions')\n\t    parser.add_argument('--buffer-size', type=int, default=1000000, help='buffer size')\n\t    parser.add_argument('--epoch', type=int, default=40, help='epoch')\n\t    parser.add_argument('--batch-size', type=int, default=128, help='batch size')\n\t    parser.add_argument('--eval', action='store_true', default=False)\n\t    parser.add_argument('--finetune', action='store_true', default=False)\n", "    parser.add_argument('--only-position', type=bool, default = True)\n\t    parser.add_argument('--greedy-upd', type=bool, default = True)\n\t    parser.add_argument('--prev-dims', type=list, default=[128, 256], help='input dims for TransformerEmbed')\n\t    parser.add_argument('--post-dims', type=list, default=[256, 128], help='hidden dims for TransformerEmbed')\n\t    parser.add_argument('--max-refine-steps', type=int, default=20, help='maximum timesteps of an episode')\n\t    parser.add_argument('--EmbeddingBackbone', type = str, default = 'Transformer', help = 'Transformer or GNN')\n\t    parser.add_argument('--max_num_topo_truss', type = int, default = 5)\n\t# args for check:\n\t    parser.add_argument('--check-file', type=str, default=None)\n\t# args for draw:\n", "    parser.add_argument('--draw-file', type=str, default=None)\n\t# args for transfer\n\t    parser.add_argument('--trans-folder-name', type=str, default=\"\")\n\t    return parser\n\tALL_CONFIGS = {\n\t    # 3D\n\t    'kr_sundial': \"configs/input_kr_sundial.yaml\",\n\t    # 2D\n\t    'without_buckle_case1': \"configs/input_without_buckle_case1.yaml\",\n\t    'without_buckle_case2': \"configs/input_without_buckle_case2.yaml\",\n", "    '17_bar_case': \"configs/input_17_bar_case.yaml\"\n\t}\n\tdef make_config(type_) -> Dict:\n\t    with open(ALL_CONFIGS[type_]) as f:\n\t        config = yaml.load(f, Loader=yaml.FullLoader)\n\t    return config"]}
{"filename": "configs/__init__.py", "chunked_list": ["from configs.config import *"]}
{"filename": "utils/utils.py", "chunked_list": ["import math\n\timport random\n\timport os\n\timport matplotlib.pyplot as plt\n\timport shutil\n\timport numpy as np\n\tdef util_init(args__):\n\t    global args\n\t    args = args__\n\tclass Vector3:\n", "    def __init__(self, x=0.0, y=0.0, z=0.0):\n\t        self.x = float(x)\n\t        self.y = float(y)\n\t        self.z = float(z)\n\t    def __add__(self, obj):\n\t        return Vector3(self.x + obj.x, self.y + obj.y, self.z + obj.z)\n\t    def __sub__(self, obj):\n\t        return Vector3(self.x - obj.x, self.y - obj.y, self.z - obj.z)\n\t    def __mul__(self, obj):\n\t        if (type(obj) == Vector3):\n", "            return Vector3(self.y * obj.z - self.z * obj.y, self.z * obj.x - self.x * obj.z,\n\t                           self.x * obj.y - self.y * obj.x)\n\t        if (type(obj) == float or type(obj) == int):\n\t            return Vector3(self.x * obj, self.y * obj, self.z * obj)\n\t        assert (False)\n\t    def __str__(self):\n\t        return str('(' + str(self.x) + ', ' + str(self.y) + ', ' + str(self.z) + ')')\n\t    def length2(self):\n\t        return float(self.x * self.x + self.y * self.y + self.z * self.z)\n\t    def length(self):\n", "        return (self.x * self.x + self.y * self.y + self.z * self.z) ** .5\n\t    def norm(self):\n\t        l = self.length()\n\t        return Vector3(self.x / l, self.y / l, self.z / l)\n\t    def __eq__(self, other):\n\t        assert (type(other) == Vector3)\n\t        if (abs(self.x - other.x) < 1e-8 and abs(self.y - other.y) < 1e-8 and abs(self.z - other.z) < 1e-8):\n\t            return True\n\t        else:\n\t            return False\n", "class Point:\n\t    def __init__(self, vec=Vector3(), supportX = 0, supportY = 0, supportZ = 0, loadX = 0.0, loadY = 0.0, loadZ = 0.0):\n\t        self.vec = vec\n\t        self.supportX = supportX\n\t        self.supportY = supportY\n\t        self.supportZ = supportZ\n\t        self.isSupport = False\n\t        if (supportX == 1 and supportY == 1 and supportZ == 1):\n\t            self.isSupport = True\n\t        self.loadX = loadX\n", "        self.loadY = loadY\n\t        self.loadZ = loadZ\n\t        self.isLoad = False\n\t        if (abs(loadX) > 1e-7 or abs(loadY) > 1e-7 or abs(loadZ) > 1e-7):\n\t            self.isLoad = True\n\t    def Point2np(self):\n\t        return np.array([self.vec.x, self.vec.y, self.vec.z])\n\tclass Bar:\n\t    def __init__(self, u=-1, v=-1, area=1.0, leng=0.0, inertia=1.0, name_s = 'dt', d = None, t = None):\n\t        self.u = int(u)\n", "        self.v = int(v)\n\t        self.d = d\n\t        self.t = t\n\t        self._area = float(area)\n\t        self._inertia = inertia\n\t        self.force = 0.0\n\t        self.len = leng\n\t        self.stress = 0.0 # calculate in dynamic\n\t        self.name_s = name_s\n\t    @property\n", "    def area(self):\n\t        if (self.d == None): return self._area\n\t        else: return math.pi * self.d ** 2 / 4.0 - math.pi * (self.d - 2 * self.t) ** 2 / 4.0\n\t    @property\n\t    #TODO Ratio-ring\n\t    def inertia(self):\n\t        if (self.d == None): return self.area ** 2 * (1 + 0 ** 2) / (4 * math.pi * (1 - 0 ** 2))\n\t        else: return math.pi * self.d ** 4 / 64.0 - math.pi * (self.d - 2 * self.t) ** 4 / 64.0\n\tdef randpoint():\n\t    x = random.random() * 2.0 - 1.0\n", "    y = random.random() * 2.0 - 1.0\n\t    z = random.random() * 2.0 - 1.0\n\t    while(x * x + y * y + z * z > 1.0):\n\t        x = random.random() * 2.0 - 1.0\n\t        y = random.random() * 2.0 - 1.0\n\t        z = random.random() * 2.0 - 1.0\n\t    return Vector3(x, y, z)\n\tdef getrand(x, y):\n\t    if (x > y): return x\n\t    return random.uniform(x, y)\n", "def Kernel1(x1, x2, sgm):\n\t    assert(type(x1) == float and type(x2) == float)\n\t    return math.exp(-(x1 - x2) * (x1 - x2) / (2 * sgm * sgm))\n\tdef Kernel2(x1, x2, sgm):\n\t    assert(type(x1) == Vector3 and type(x2) == Vector3)\n\t    vec = x1 - x2\n\t    len2 = vec.x * vec.x + vec.y * vec.y + vec.z * vec.z\n\t    return math.exp(-(len2 / (2 * sgm * sgm)))\n\tdef getlen(vec):\n\t    return math.sqrt(vec.x * vec.x + vec.y * vec.y + vec.z * vec.z)\n", "def getlen2(u, v):\n\t    return getlen(u.vec - v.vec)\n\tdef getang(vec1, vec2):\n\t    return (vec1.x * vec2.x + vec1.y * vec2.y + vec1.z * vec2.z) / (getlen(vec1) * getlen(vec2))\n\tdef intersect(N1, N2, N3, N4):\n\t    game_stop = False\n\t    X1=N1.x\n\t    Y1=N1.y\n\t    X2=N2.x\n\t    Y2=N2.y\n", "    X3=N3.x\n\t    Y3=N3.y\n\t    X4=N4.x\n\t    Y4=N4.y\n\t    if N1 != N3 and N1 != N4 and N2 != N3 and N2 != N4:\n\t        SIN13_14=(X3-X1)*(Y4-Y1)-(X4-X1)*(Y3-Y1)\n\t        SIN23_24=(X3-X2)*(Y4-Y2)-(X4-X2)*(Y3-Y2)\n\t        SIN31_32=(X1-X3)*(Y2-Y3)-(X2-X3)*(Y1-Y3)\n\t        SIN41_42=(X1-X4)*(Y2-Y4)-(X2-X4)*(Y1-Y4)\n\t        if SIN13_14*SIN23_24<=0 and SIN31_32*SIN41_42<=0:\n", "            SIN12_23=(X2-X1)*(Y3-Y2)-(X3-X2)*(Y2-Y1)\n\t            SIN12_24=(X2-X1)*(Y4-Y2)-(X4-X2)*(Y2-Y1)\n\t            SIN23_34=(X3-X2)*(Y4-Y3)-(X4-X3)*(Y3-Y2)\n\t            SIN13_34=(X3-X1)*(Y4-Y3)-(X4-X3)*(Y3-Y1)\n\t            if SIN12_23!=0 and SIN12_24!=0 and SIN23_34!=0 and SIN13_34!=0:\n\t                game_stop=True\n\t    SIN13_14=(X3-X1)*(Y4-Y1)-(X4-X1)*(Y3-Y1)\n\t    SIN23_24=(X3-X2)*(Y4-Y2)-(X4-X2)*(Y3-Y2)\n\t    if (abs(SIN13_14) < 1e-7 and abs(SIN23_24) < 1e-7):\n\t        D13 = math.sqrt((X3 - X1) * (X3 - X1) + (Y3 - Y1) * (Y3 - Y1))\n", "        D14 = math.sqrt((X4 - X1) * (X4 - X1) + (Y4 - Y1) * (Y4 - Y1))\n\t        D23 = math.sqrt((X3 - X2) * (X3 - X2) + (Y3 - Y2) * (Y3 - Y2))\n\t        D24 = math.sqrt((X4 - X2) * (X4 - X2) + (Y4 - Y2) * (Y4 - Y2))\n\t        D1 = D13 + D24\n\t        D2 = D23 + D14\n\t        if (abs(D1 - D2) > 1e-7):\n\t            game_stop = True\n\t    return game_stop\n\tdef getang(vec1, vec2):\n\t    return (vec1.x * vec2.x + vec1.y * vec2.y + vec1.z * vec2.z) / (getlen(vec1) * getlen(vec2))\n", "def transintersect(u1, v1, u2, v2, p):\n\t    if (intersect(p[u1].vec, p[v1].vec, p[u2].vec, p[v2].vec)):\n\t        return True\n\t    return False\n\tdef readFile(input_file):\n\t    r'''\n\t    :param input_file: File name\n\t    :return: point list, edge list\n\t    '''\n\t    p = []\n", "    e = []\n\t    with open(input_file, \"r\") as fle:\n\t        lines = fle.readlines()\n\t        for i in range(len(lines)):\n\t            if len(lines[i]) < 2:\n\t                continue\n\t            line = lines[i]\n\t            vec = line.strip().split(' ')\n\t            if (i == 0):\n\t                vn = int(vec[0])\n", "                en = int(vec[1])\n\t                continue\n\t            if (1 <= i and i <= vn):\n\t                p.append(Point(Vector3(float(vec[0]), float(vec[1]), float(vec[2])), int(vec[3]), int(vec[4]), int(vec[5]), float(vec[6]), float(vec[7]), float(vec[8])))\n\t                continue\n\t            if (vn + 1 <= i and i <= vn + en):\n\t                if (len(vec) > 3 and vec[3] != 'None'):\n\t                    d = float(vec[3])\n\t                    t = float(vec[4])\n\t                else:\n", "                    d = None\n\t                    t = None\n\t                if (float(vec[2]) < 0): continue\n\t                e.append(Bar(vec[0], vec[1], float(vec[2]), getlen2(p[int(vec[0])], p[int(vec[1])]), d = d, t = t))\n\t    return p, e\n\tdef readFilewithload(input_file):\n\t    r'''\n\t    :param input_file: File name\n\t    :return: point list, edge list\n\t    '''\n", "    p = []\n\t    e = []\n\t    load = []\n\t    with open(input_file, \"r\") as fle:\n\t        lines = fle.readlines()\n\t        for i in range(len(lines)):\n\t            if len(lines[i]) < 2:\n\t                continue\n\t            line = lines[i]\n\t            vec = line.strip().split(' ')\n", "            if (i == 0):\n\t                vn = int(vec[0])\n\t                en = int(vec[1])\n\t                continue\n\t            if (1 <= i and i <= vn):\n\t                p.append(Point(Vector3(float(vec[0]), float(vec[1]), float(vec[2])), int(vec[3]), int(vec[4]), int(vec[5]), float(vec[6]), float(vec[7]), float(vec[8])))\n\t                load.append(float(vec[7]))\n\t                continue\n\t            if (vn + 1 <= i and i <= vn + en):\n\t                if (len(vec) > 3 and vec[3] != 'None'):\n", "                    d = float(vec[3])\n\t                    t = float(vec[4])\n\t                else:\n\t                    d = None\n\t                    t = None\n\t                if (float(vec[2]) < 0): continue\n\t                e.append(Bar(vec[0], vec[1], float(vec[2]), getlen2(p[int(vec[0])], p[int(vec[1])]), d = d, t = t))\n\t    return p, e, load\n\tdef readAlist(Alist_path):\n\t    AREAFILE = Alist_path\n", "    alist = []\n\t    with open(AREAFILE,'r') as ar:\n\t        section_lines = ar.readlines()\n\t        for i in range(len(section_lines)):\n\t            section_line = section_lines[i]\n\t            section_r = section_line.strip().split(' ')\n\t            if (i==0):\n\t                section_num = int(section_r[0])\n\t            if (i > 0 and i <= section_num):\n\t                name_s = 'd' + str(section_r[0]) + 't' + str(int(float(section_r[1]) * 10))\n", "                d = float(section_r[0]) / 1000.0\n\t                t = float(section_r[1]) / 1000.0\n\t                area_s = math.pi * d ** 2 / 4.0 - math.pi * (d - 2 * t) ** 2 / 4.0\n\t                I_s = math.pi * d ** 4 / 64.0 - math.pi * ( d - 2 * t) ** 4 / 64.0\n\t                i_s = math.sqrt(I_s/area_s)\n\t                alist.append((float(area_s), float(I_s), float(i_s), str(name_s), float(d), float(t)))\n\t    return alist\n\tdef save_file_stage1(OUTFILE, p, e):\n\t    with open(OUTFILE, \"w\") as f:\n\t        print(len(p), len(e), file=f)\n", "        for i in range(len(p)):\n\t            print(p[i].vec.x, p[i].vec.y, p[i].vec.z, p[i].supportX, p[i].supportY,\n\t                p[i].supportZ, p[i].loadX, p[i].loadY, p[i].loadZ, file=f)\n\t        for i in range(len(e)): print(e[i].u, e[i].v, e[i].area, e[i].d, e[i].t, file = f)\n\tdef save_file(initial_points, state, mass, path, mode = 'Area', best = False, diverse_id = None):\n\t    r'''\n\t    save state into txt\n\t    :param initial_points: initial points, for support and load information\n\t    :param state: truss state\n\t    :param mass: mass of truss\n", "    :param path: path to store\n\t    :return: None\n\t    '''\n\t    if (best == False):\n\t        if (diverse_id == None):\n\t            fo = open(os.path.join(path, str(int(mass * 1000)) + \".txt\"), \"w\")\n\t        else: \n\t            fo = open(os.path.join(path, str(int(mass * 1000)) + \"_\" + str(diverse_id).zfill(2) + \".txt\"), \"w\")\n\t    else: fo = open(os.path.join(path, '_best.txt'), \"w\")\n\t    n = state.num_points\n", "    fo.write(\"{} {}\\n\".format(n, n * (n - 1) // 2))\n\t    for i in range(n):\n\t        x = state.nodes[i][0]\n\t        y = state.nodes[i][1]\n\t        if state.dimension == 2:\n\t            z = 0.0\n\t        else:\n\t            z = state.nodes[i][2]\n\t        fo.write(\"{} {} {} {} {} {} {} {} {}\\n\".format(x, y, z,\n\t                                                       initial_points[i].supportX, initial_points[i].supportY, initial_points[i].supportZ,\n", "                                                       initial_points[i].loadX, initial_points[i].loadY, initial_points[i].loadZ))\n\t    if (mode == 'Area'):\n\t        for i in range(n):\n\t            for j in range(i):\n\t                fo.write(\"{} {} {}\\n\".format(j, i, state.edges[i][j]))\n\t    if (mode == 'DT'):\n\t        for i in range(n):\n\t            for j in range(i):\n\t                if (state.edges[i][j][0] <= 0):\n\t                    fo.write(\"{} {} {} {} {}\\n\".format(j, i, -1, -1, -1))\n", "                else:\n\t                    d = state.edges[i][j][0]\n\t                    t = state.edges[i][j][1]\n\t                    if (t == 0): \n\t                        fo.write(\"{} {} {} {} {}\\n\".format(j, i, -1, -1, -1))\n\t                    else:\n\t                        area = math.pi*state.edges[i][j][0]**2/4.0 - math.pi*(state.edges[i][j][0]-2*state.edges[i][j][1])**2/4.0\n\t                        fo.write(\"{} {} {} {} {}\\n\".format(j, i, area, state.edges[i][j][0], state.edges[i][j][1]))\n\t    fo.close()\n\tdef save_file_from_list(p, e, output_file):\n", "    with open(output_file, \"w\") as f:\n\t        print(len(p), len(e), file = f)\n\t        for i in range(len(p)):\n\t            print(p[i].vec.x, p[i].vec.y, p[i].vec.z, p[i].supportX, p[i].supportY, p[i].supportZ, p[i].loadX, p[i].loadY, p[i].loadZ, file = f)\n\t        for i in range(len(e)):\n\t            print(e[i].u, e[i].v, e[i].area, e[i].d, e[i].t, file = f)\n\tdef save_trajectory(initial_points, trajectory, mass, path):\n\t    r'''\n\t    save state into txt\n\t    :param initial_points: initial points, for support and load information\n", "    :param trajectory: history of truss states\n\t    :param mass: mass of truss\n\t    :param path: path to store\n\t    :return: None\n\t    '''\n\t    current_dir = os.getcwd()\n\t    dir = path + str(int(mass))\n\t    if os.path.exists(dir):\n\t        shutil.rmtree(dir)\n\t    os.mkdir(dir)\n", "    os.chdir(dir)\n\t    for i in range(len(trajectory)):\n\t        state = trajectory[i]\n\t        def _save_file(initial_points, state, file_name):\n\t            r'''\n\t            save state into txt\n\t            :param initial_points: initial points, for support and load information\n\t            :param state: truss state\n\t            :param mass: mass of truss\n\t            :param path: path to store\n", "            :return: None\n\t            '''\n\t            fo = open(file_name, \"w\")\n\t            n = state.num_points\n\t            fo.write(\"{} {}\\n\".format(n, n * (n - 1) // 2))\n\t            for i in range(n):\n\t                x = state.nodes[i][0]\n\t                y = state.nodes[i][1]\n\t                if state.dimension == 2:\n\t                    z = 0.0\n", "                else:\n\t                    z = state.nodes[i][2]\n\t                fo.write(\"{} {} {} {} {} {} {} {} {}\\n\".format(x, y, z,\n\t                                                               initial_points[i].supportX, initial_points[i].supportY, initial_points[i].supportZ,\n\t                                                               initial_points[i].loadX, initial_points[i].loadY, initial_points[i].loadZ))\n\t            for i in range(n):\n\t                for j in range(i):\n\t                    fo.write(\"{} {} {}\\n\".format(j, i, state.edges[i][j]))\n\t            fo.close()\n\t        def _saveGraph(p, e, file):\n", "            for i in range(len(p)):\n\t                plt.scatter([p[i].vec.x], [p[i].vec.y], color='b')\n\t            for i in range(len(e)):\n\t                x0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t                y0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n\t                if e[i].area != -1:\n\t                    plt.plot(x0, y0, color='b', linewidth=e[i].area / 0.01)\n\t            plt.axis(\"equal\")\n\t            plt.savefig(file)\n\t            plt.cla()\n", "        _save_file(initial_points, state, str(i) + \".txt\")\n\t    os.chdir(current_dir)\n\tdef is_edge_addable(u, v, points, edges, enabled=False):\n\t    r'''\n\t    Check if adding a bar between u and v is valid, only applied to 2-d case\n\t    :param u: index of one end of the edge\n\t    :param v: index of the other end of the edge\n\t    :param points: nodes\n\t    :param edges: edges\n\t    :param enabled: Whether use this function to check edge constraint, if False, always return True\n", "    :return: bool\n\t    '''\n\t    max_length = 18\n\t    minang = 10\n\t    cosminang = np.cos(minang / 180.0 * np.pi)\n\t    max_edges = 10\n\t    #判断杆件是否交叉\n\t    def _intersect(point_u1,point_v1,point_u2,point_v2): #四个点对象，其中u1v1为一根杆，u2v2为一根杆\n\t        intersected = False\n\t        u1=np.array([point_u1.vec.x,point_u1.vec.y])\n", "        v1=np.array([point_v1.vec.x,point_v1.vec.y])\n\t        u2=np.array([point_u2.vec.x,point_u2.vec.y])\n\t        v2=np.array([point_v2.vec.x,point_v2.vec.y])      #取得四个点坐标向量\n\t        u1v1=v1-u1\n\t        u2v2=v2-u2     #杆件向量\n\t        u1u2=u2-u1\n\t        u1v2=v2-u1\n\t        u2u1=u1-u2\n\t        u2v1=v1-u2\n\t        def compare(a,b):\n", "            if((a[0] < b[0]) or (a[0] == b[0] and a[1] < b[1])):\n\t                return -1\n\t            elif(a[0] == b[0] and a[1] == b[1]):\n\t                return 0\n\t            else:\n\t                return 1\n\t        #对一条线段的两端点进行排序，横坐标大的点更大，横坐标相同，纵坐标大的点更大，升序排序\n\t        po=[u1,v1,u2,v2]\n\t        if compare(po[0],po[1])>0:\n\t            temp=po[0]\n", "            po[0]=po[1]\n\t            po[1]=temp\n\t        if compare(po[2],po[3])>0:\n\t            temp=po[2]\n\t            po[2]=po[3]\n\t            po[3]=temp\n\t        #考虑一般情况\n\t        if  ((np.cross(u1v1,u1u2)*np.cross(u1v1,u1v2)<0 and np.cross(u2v2,u2u1)*np.cross(u2v2,u2v1)<0) or    #叉积均小于0，跨越交叉\n\t            (np.cross(u1v1,u1u2)*np.cross(u1v1,u1v2)==0 and np.cross(u2v2,u2u1)*np.cross(u2v2,u2v1)<0) or    #任意一方=0， 另一方<0，为一节点位于另一杆件上\n\t            (np.cross(u1v1,u1u2)*np.cross(u1v1,u1v2)<0 and np.cross(u2v2,u2u1)*np.cross(u2v2,u2v1)==0)):     #顺便排除了有公共点的情况，有公共点两方均为0\n", "            intersected = True\n\t        #考虑如果两线段共线重叠\n\t        if np.cross(u1v1,u2v2)==0 and np.cross(u1v1,u1v2)==0: #两线段共线\n\t            if(compare(po[0],po[2]) <= 0 and compare(po[1],po[2]) > 0):     #第一条起点小于第二条起点，第一条终点大于第二条起点\n\t                intersected = True\n\t            elif(compare(po[2],po[0]) <= 0 and compare(po[3],po[0]) > 0):   #第二条起点小于第一条起点，第二条终点大于第一条起点\n\t                intersected = True\n\t        return intersected\n\t    def _transintersect(\n\t        u1,v1,u2,v2,\n", "        points,\n\t    ): # ?\n\t        if (\n\t            _intersect(\n\t                points[u1], points[v1], points[u2], points[v2]\n\t            )\n\t        ):\n\t            return True\n\t        if (u1 == u2):\n\t            if (\n", "                getang(\n\t                    points[v1].vec - points[u1].vec,\n\t                    points[v2].vec - points[u2].vec,\n\t                ) > cosminang\n\t            ):\n\t                return True\n\t        if (u1 == v2):\n\t            if (\n\t                getang(\n\t                    points[v1].vec - points[u1].vec,\n", "                    points[u2].vec - points[v2].vec,\n\t                ) > cosminang\n\t            ):\n\t                return True\n\t        if (v1 == u2):\n\t            if (\n\t                getang(\n\t                    points[u1].vec - points[v1].vec,\n\t                    points[v2].vec - points[u2].vec,\n\t                ) > cosminang\n", "            ):\n\t                return True\n\t        if (v1 == v2):\n\t            if (\n\t                getang(\n\t                    points[u1].vec - points[v1].vec,\n\t                    points[u2].vec - points[v2].vec,\n\t                ) > cosminang\n\t            ):\n\t                return True\n", "        return False\n\t    def _is_too_long(point_u, point_v):\n\t        return getlen2(point_u, point_v) > max_length\n\t    # MODIFICATION: not considering EDGE_CONFIG\n\t    if not enabled:\n\t        return True\n\t    if _is_too_long(points[u], points[v]):\n\t        return False\n\t    if points[u].isSupport and points[v].isSupport:\n\t        return False\n", "    for edge in edges.values():\n\t        if (\n\t            _transintersect(\n\t                u, v, edge.u, edge.v, points\n\t            )\n\t        ):\n\t            return False\n\t    return True\n\tdef getuv(x):\n\t    x += 1\n", "    v = math.ceil(\n\t        (math.sqrt(1 + 8 * x) - 1) / 2.0\n\t    )\n\t    u = x - v * (v - 1) // 2 - 1\n\t    return u, v\n\tdef similar_position(p1, e1, p2, e2):\n\t    pts1 = []\n\t    pts2 = []\n\t    for p in p1:\n\t        pts1.append([p.vec.x, p.vec.y, p.vec.z])\n", "    for p in p2:\n\t        pts2.append([p.vec.x, p.vec.y, p.vec.z])\n\t    es1 = []\n\t    es2 = []\n\t    for e in e1:\n\t        es1.append([pts1[e.u], pts1[e.v]])\n\t        es1.append([pts1[e.v], pts1[e.u]])\n\t    for e in e2:\n\t        es2.append([pts2[e.u], pts2[e.v]])\n\t        es2.append([pts2[e.v], pts2[e.u]])\n", "    if sorted(pts1) != sorted(pts2): return False\n\t    if sorted(es1) != sorted(es2): return False\n\t    return True\n\tdef similar_topo(p1, e1, p2, e2):\n\t    pts1 = []\n\t    pts2 = []\n\t    for i in range(len(p1)): pts1.append(i)\n\t    for i in range(len(p2)): pts2.append(i)\n\t    es1 = []\n\t    es2 = []\n", "    for e in e1:\n\t        es1.append([pts1[e.u], pts1[e.v]])\n\t        es1.append([pts1[e.v], pts1[e.u]])\n\t    for e in e2:\n\t        es2.append([pts2[e.u], pts2[e.v]])\n\t        es2.append([pts2[e.v], pts2[e.u]])\n\t    if sorted(pts1) != sorted(pts2): return False\n\t    if sorted(es1) != sorted(es2): return False\n\t    return True\n\tdef closestDistanceBetweenLines(a0, a1, b0, b1, \n", "        clampAll = False, clampA0 = False,clampA1 = False,clampB0 = False,clampB1 = False):\n\t        r''' \n\t        Given two lines defined by numpy.array pairs (a0,a1,b0,b1)\n\t        Return the closest points on each segment and their distance\n\t        '''\n\t        # If clampAll=True, set all clamps to True\n\t        if clampAll:\n\t            clampA0=True\n\t            clampA1=True\n\t            clampB0=True\n", "            clampB1=True\n\t        # Calculate denomitator\n\t        A = a1 - a0\n\t        B = b1 - b0\n\t        magA = np.linalg.norm(A)\n\t        magB = np.linalg.norm(B)\n\t        _A = A / magA\n\t        _B = B / magB\n\t        cross = np.cross(_A, _B)\n\t        denom = np.linalg.norm(cross) ** 2\n", "        # If lines are parallel (denom=0) test if lines overlap.\n\t        # If they don't overlap then there is a closest point solution.\n\t        # If they do overlap, there are infinite closest positions, but there is a closest distance\n\t        if not denom:\n\t            d0 = np.dot(_A, (b0 - a0))\n\t            # Overlap only possible with clamping\n\t            if clampA0 or clampA1 or clampB0 or clampB1:\n\t                d1 = np.dot(_A, (b1 - a0))\n\t                # Is segment B before A?\n\t                if d0 <= 0 >= d1:\n", "                    if clampA0 and clampB1:\n\t                        if np.absolute(d0) < np.absolute(d1):\n\t                            return a0,b0,np.linalg.norm(a0-b0)\n\t                        return a0,b1,np.linalg.norm(a0-b1)\n\t                # Is segment B after A?\n\t                elif d0 >= magA <= d1:\n\t                    if clampA1 and clampB0:\n\t                        if np.absolute(d0) < np.absolute(d1):\n\t                            return a1,b0,np.linalg.norm(a1-b0)\n\t                        return a1,b1,np.linalg.norm(a1-b1)\n", "            # Segments overlap, return distance between parallel segments\n\t            return None,None,np.linalg.norm(((d0*_A)+a0)-b0)\n\t        # Lines criss-cross: Calculate the projected closest points\n\t        t = (b0 - a0)\n\t        detA = np.linalg.det([t, _B, cross])\n\t        detB = np.linalg.det([t, _A, cross])\n\t        t0 = detA/denom\n\t        t1 = detB/denom\n\t        pA = a0 + (_A * t0) # Projected closest point on segment A\n\t        pB = b0 + (_B * t1) # Projected closest point on segment B\n", "        # Clamp projections\n\t        if clampA0 or clampA1 or clampB0 or clampB1:\n\t            if clampA0 and t0 < 0:\n\t                pA = a0\n\t            elif clampA1 and t0 > magA:\n\t                pA = a1\n\t            if clampB0 and t1 < 0:\n\t                pB = b0\n\t            elif clampB1 and t1 > magB:\n\t                pB = b1\n", "            # Clamp projection A\n\t            if (clampA0 and t0 < 0) or (clampA1 and t0 > magA):\n\t                dot = np.dot(_B,(pA-b0))\n\t                if clampB0 and dot < 0:\n\t                    dot = 0\n\t                elif clampB1 and dot > magB:\n\t                    dot = magB\n\t                pB = b0 + (_B * dot)\n\t            # Clamp projection B\n\t            if (clampB0 and t1 < 0) or (clampB1 and t1 > magB):\n", "                dot = np.dot(_A,(pB-a0))\n\t                if clampA0 and dot < 0:\n\t                    dot = 0\n\t                elif clampA1 and dot > magA:\n\t                    dot = magA\n\t                pA = a0 + (_A * dot)\n\t        return pA, pB, np.linalg.norm(pA - pB)"]}
{"filename": "algo/UCT_deprecate.py", "chunked_list": ["from glob import glob\n\tfrom utils.utils import Vector3, Point, Bar\n\tfrom utils.utils import getrand, randpoint, Kernel1, Kernel2, getlen, getlen2\n\tfrom truss_envs.reward import *\n\timport math\n\timport copy\n\timport random\n\timport numpy as np\n\timport matplotlib.pyplot as plt\n\timport time\n", "import heapq\n\tdef intersect(N1, N2, N3, N4):\n\t    game_stop = False\n\t    X1=N1.x\n\t    Y1=N1.y\n\t    X2=N2.x\n\t    Y2=N2.y\n\t    X3=N3.x\n\t    Y3=N3.y\n\t    X4=N4.x\n", "    Y4=N4.y\n\t    if N1 != N3 and N1 != N4 and N2 != N3 and N2 != N4:\n\t        SIN13_14=(X3-X1)*(Y4-Y1)-(X4-X1)*(Y3-Y1)\n\t        SIN23_24=(X3-X2)*(Y4-Y2)-(X4-X2)*(Y3-Y2)\n\t        SIN31_32=(X1-X3)*(Y2-Y3)-(X2-X3)*(Y1-Y3)\n\t        SIN41_42=(X1-X4)*(Y2-Y4)-(X2-X4)*(Y1-Y4)\n\t        if SIN13_14*SIN23_24<=0 and SIN31_32*SIN41_42<=0:\n\t            SIN12_23=(X2-X1)*(Y3-Y2)-(X3-X2)*(Y2-Y1)\n\t            SIN12_24=(X2-X1)*(Y4-Y2)-(X4-X2)*(Y2-Y1)\n\t            SIN23_34=(X3-X2)*(Y4-Y3)-(X4-X3)*(Y3-Y2)\n", "            SIN13_34=(X3-X1)*(Y4-Y3)-(X4-X3)*(Y3-Y1)\n\t            if SIN12_23!=0 and SIN12_24!=0 and SIN23_34!=0 and SIN13_34!=0:\n\t                game_stop=True\n\t    SIN13_14=(X3-X1)*(Y4-Y1)-(X4-X1)*(Y3-Y1)\n\t    SIN23_24=(X3-X2)*(Y4-Y2)-(X4-X2)*(Y3-Y2)\n\t    if (abs(SIN13_14) < 1e-7 and abs(SIN23_24) < 1e-7):\n\t        D13 = math.sqrt((X3 - X1) * (X3 - X1) + (Y3 - Y1) * (Y3 - Y1))\n\t        D14 = math.sqrt((X4 - X1) * (X4 - X1) + (Y4 - Y1) * (Y4 - Y1))\n\t        D23 = math.sqrt((X3 - X2) * (X3 - X2) + (Y3 - Y2) * (Y3 - Y2))\n\t        D24 = math.sqrt((X4 - X2) * (X4 - X2) + (Y4 - Y2) * (Y4 - Y2))\n", "        D1 = D13 + D24\n\t        D2 = D23 + D14\n\t        if (abs(D1 - D2) > 1e-7):\n\t            game_stop = True\n\t    return game_stop\n\tdef transintersect(u1, v1, u2, v2, p):\n\t    if (intersect(p[u1].vec, p[v1].vec, p[u2].vec, p[v2].vec)):\n\t        return True\n\t    return False\n\tclass Action():\n", "    def __init__(self, args, opt, u = -1, v = -1, area = -1, vec = Vector3(), eid = 0, d = None, t = None):\n\t        self.opt = opt\n\t        self.stateid = -1\n\t        self.d = None\n\t        self.t = None\n\t        if (opt == 0): self.vec = vec   # add node\n\t        if (opt == 1):                  # add edge\n\t            self.opt = opt\n\t            self.u = u\n\t            self.v = v\n", "            if (area != -1): self.area = area\n\t            else: self.area = args.maxarea\n\t            if (args.env_mode == 'DT'):\n\t                self.d = arealist[-1][4]\n\t                self.t = arealist[-1][5]\n\t        if (opt == 2):                  # change area\n\t            if (args.env_mode == 'DT'): assert(d > 0 and t > 0)\n\t            self.eid = eid\n\t            if (area != -1): self.area = area\n\t            else: self.area = maxarea\n", "            self.d = d\n\t            self.t = t\n\t    def __str__(self):\n\t        if (self.opt == 0): return \"add node at\" + self.vec.__str__()\n\t        if (self.opt == 1):\n\t            if (self.area < 1e-8): return \"do nothing\"\n\t            else: return \"add edge between\" + str(self.u) + \"and\" + str(self.v)\n\t        if (self.opt == 2): return \"modify area of \" + str(self.eid) + \"to \" + str(self.area)\n\tclass State():\n\t    def __init__(self, p, e, opt, fa = 0, elist = set(), eid = 0):\n", "        self.opt = opt\n\t        self.sons = []\n\t        self.isEnd = False\n\t        self.n = 0\n\t        self.q = 0\n\t        self.fa = fa\n\t        self.allvisited = False\n\t        self.w = 0.0\n\t        self.sumq = 0.0\n\t        self.sumw = 0.0\n", "        self.mq = -1000\n\t        if (opt == 0):\n\t            for i in range(len(plist)):\n\t                flag = False\n\t                tmpp = plist[i]\n\t                for j in range(len(p)):\n\t                    if (inlen(Point(tmpp), p[j])):\n\t                        flag = True\n\t                        break\n\t                if (flag == True): self.sons.append(Action(0, vec = tmpp))\n", "            for i in range(len(self.sons), args.initson):\n\t                flag = False\n\t                tmpp = Vector3(getrand(minx, maxx), getrand(miny, maxy), getrand(minz, maxz))\n\t                for j in range(len(p)):\n\t                    if (inlen(Point(tmpp), p[j])):\n\t                        flag = True\n\t                        break\n\t                if (flag == True): self.sons.append(Action(0, vec = tmpp))\n\t        if (opt == 1):\n\t            self.reward = soft_reward(reward_fun(p, e), p, e)\n", "            if (self.reward > 1e-7): self.sons.append(Action(1)) # 当前结构稳定\n\t            for i in elist: \n\t                self.sons.append(Action(1, u = i[0], v = i[1]))\n\t            if (len(self.sons) == 0):\n\t                self.isEnd = True\n\t                self.reward = soft_reward(reward_fun(p, e), p, e)\n\t        if (opt == 2):\n\t            self.eid = eid\n\t            if (eid >= len(e)):\n\t                self.isEnd = True\n", "                self.reward = soft_reward(reward_fun(p, e), p, e)\n\t            else:\n\t                if (args.env_mode == 'DT'):\n\t                    for i in range(len(arealist)):\n\t                        self.sons.append(Action(2, d = arealist[i][4], t = arealist[i][5], eid = eid))\n\t                else:\n\t                    for i in range(args.initson + 1):\n\t                        self.sons.append(Action(2, area = minarea + (maxarea - minarea) / args.initson * i))\n\t    def findunvis(self): # find unvisited node\n\t        ret = -1\n", "        for i in range(len(self.sons)):\n\t            if (self.sons[i].stateid == -1):\n\t                ret = i\n\t                break\n\t        if (ret == -1): self.allvisited = True\n\t        return ret\n\tclass UCTs():\n\t    def UCTs_init(self, args, plist__ = [], arealist__ = []):\n\t        self.args = args\n\t        self.pbest = []\n", "        self.ebest = []\n\t        self.time_str = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime())\n\t        self.bestreward = 1e9\n\t        self.tempbestreward = 1e9\n\t        self.minx = args.coordinate_range[0][0]\n\t        self.maxx = args.coordinate_range[0][1]\n\t        self.miny = args.coordinate_range[1][0]\n\t        self.maxy = args.coordinate_range[1][1]\n\t        self.statelist = []\n\t        if (args.env_dims == 3):\n", "            self.minz = args.coordinate_range[2][0]\n\t            self.maxz = args.coordinate_range[2][1]\n\t        else: self.minz = self.maxz = 0\n\t        self.minlen = args.len_range[0]\n\t        self.maxlen = args.len_range[1]\n\t        self.minarea = args.area_range[0]\n\t        self.maxarea = args.area_range[1]\n\t        self.arealist = arealist__\n\t        self.plist = plist__\n\t        self.save_valid_count = 0\n", "        self.save_invalid_count = 0\n\t        self.output_dir_init()\n\t    def output_dir_init(self):\n\t        self.OUTPUT_ALL_THRESHOLD = self.args.OUTPUT_ALL_THRESHOLD\n\t        self.MASS_OUTPUT_ALL_THRESHOLD = self.args.MASS_OUTPUT_ALL_THRESHOLD\n\t        self.LOGFOLDER = self.args.save_path\n\t        if not os.path.exists(self.LOGFOLDER): os.mkdir(self.LOGFOLDER)\n\t        self.ALLFOLDER = self.LOGFOLDER + 'Reward_ALL_Result/'\n\t        if not os.path.exists(self.ALLFOLDER): os.mkdir(self.ALLFOLDER)\n\t        self.OUTPUT_ALL_MAX = 10000\n", "        print('OUTPUT_ALL_THRESHOLD:', self.OUTPUT_ALL_THRESHOLD)\n\t        self.MASS_ALLFOLDER = self.LOGFOLDER + 'MASS_ALL_Result/'\n\t        if not os.path.exists(self.MASS_ALLFOLDER): os.mkdir(self.MASS_ALLFOLDER)\n\t        self.MASS_OUTPUT_ALL_MAX = 10000\n\t        print('MASS_OUTPUT_ALL_THRESHOLD:', self.MASS_OUTPUT_ALL_THRESHOLD)\n\t    def similar(self, tup1, tup2):\n\t        p1 = tup1[2]\n\t        e1 = tup1[3]\n\t        p2 = tup2[2]\n\t        e2 = tup2[3]\n", "        pts1 = []\n\t        pts2 = []\n\t        for p in p1: pts1.append([p.vec.x, p.vec.y, p.vec.z])\n\t        for p in p2: pts2.append([p.vec.x, p.vec.y, p.vec.z])\n\t        es1 = []\n\t        es2 = []\n\t        for e in e1:\n\t            es1.append([pts1[e.u], pts1[e.v]])\n\t            es1.append([pts1[e.v], pts1[e.u]])\n\t        for e in e2:\n", "            es2.append([pts2[e.u], pts2[e.v]])\n\t            es2.append([pts2[e.v], pts2[e.u]])\n\t        if sorted(pts1) != sorted(pts2): return False\n\t        if sorted(es1) != sorted(es2): return False\n\t        return True\n\t    def save_file(self, OUTFILE, p, e, valid = True):\n\t        if (valid): self.save_valid_count += 1\n\t        else: self.save_invalid_count += 1\n\t        with open(OUTFILE, \"w\") as f:\n\t            print(len(p), len(e), file=f)\n", "            for i in range(len(p)):\n\t                print(p[i].vec.x, p[i].vec.y, p[i].vec.z, p[i].supportX, p[i].supportY,\n\t                    p[i].supportZ, p[i].loadX, p[i].loadY, p[i].loadZ, file=f)\n\t            for i in range(len(e)): print(e[i].u, e[i].v, e[i].area, e[i].d, e[i].t, file = f)\n\t    def diversity_save(self, reward, reward_count, Mass, Dis_value, Stress_value, Buckle_value, p, e):\n\t        FILES = os.listdir(self.ALLFOLDER)\n\t        if len(FILES) < self.OUTPUT_ALL_MAX and reward <= self.OUTPUT_ALL_THRESHOLD:\n\t            OUTFILE = self.ALLFOLDER + str(reward_count).zfill(len(str(self.OUTPUT_ALL_MAX))) + '_' + str(\n\t                round(Mass)) + '_' + str(round(reward)) + '.txt'\n\t            self.save_file(OUTFILE, p, e)\n", "        MASS_FILES = os.listdir(self.MASS_ALLFOLDER)\n\t        if len(MASS_FILES) < self.MASS_OUTPUT_ALL_MAX and Mass <= self.MASS_OUTPUT_ALL_THRESHOLD:\n\t            if not (Dis_value > 1e-7 or Stress_value > 1e-7 or Buckle_value > 1e-7):\n\t                OUTFILE = self.MASS_ALLFOLDER + str(round(Mass)) + '.txt'\n\t                self.save_file(OUTFILE, p, e)\n\t    def soft_reward(self, env_output, p, e):\n\t        reward, reward_cnt, Mass, Dis_value, Stress_value, Buckle_value = env_output\n\t        if (reward <= 0):\n\t            if (self.save_invalid_count * self.args.save_invalid_factor < self.save_valid_count and reward == 0):\n\t                folder = os.path.join(self.LOGFOLDER, \"invalid\")\n", "                if (not os.path.exists(folder)): os.mkdir(folder)\n\t                self.save_file(os.path.join(folder, str(self.save_invalid_count) + '.txt'), p, e)\n\t            return reward\n\t        if (self.bestreward > reward):\n\t            self.bestreward = reward\n\t            self.pbest = copy.deepcopy(p)\n\t            self.ebest = copy.deepcopy(e)\n\t        if (self.tempbestreward > reward):\n\t            self.tempbestreward = reward\n\t        if (args.save_diversity):\n", "            self.diversity_save(reward, reward_cnt, Mass, Dis_value, Stress_value, Buckle_value, p, e)\n\t        reward= self.args.reward_lambda / (reward * reward)\n\t        return reward\n\t    def inlen(self, u, v):\n\t        if (getlen2(u, v) > self.maxlen and self.args.CONSTRAINT_MAX_LENGTH): return False\n\t        if (getlen2(u, v) < self.minlen and self.args.CONSTRAINT_MIN_LENGTH): return False\n\t        return True\n\t    def canadd(self, N1, N2, p, e):\n\t        if (not self.inlen(p[N1], p[N2])): return False\n\t        if (args.env_dims == 2 and args.CONSTRAINT_CROSS_EDGE == 1):\n", "            for i in range(len(e)):\n\t                N3 = e[i].u\n\t                N4 = e[i].v\n\t                if (transintersect(N1, N2, N3, N4, p)): return False\n\t        return True\n\t    def bestchild(self, now, c, alpha):\n\t        ret = -1\n\t        actid = -1\n\t        mx = 0\n\t        if (abs(c) < 1e-7): # final find, no explore \n", "            for i in range(len(self.statelist[now].sons)):\n\t                v = self.statelist[now].sons[i].stateid\n\t                if (self.statelist[now].opt == 1):\n\t                    tmp = alpha * self.statelist[v].q / self.statelist[v].n + (1 - alpha) * self.statelist[v].mq\n\t                    print(self.statelist[v].q, self.statelist[v].n, self.statelist[v].mq, self.statelist[v].q / self.statelist[v].n, 'a')\n\t                else:\n\t                    tmp = alpha * self.statelist[v].sumq / self.statelist[v].n + (1 - alpha) * self.statelist[v].mq\n\t                    print(self.statelist[v].q, self.statelist[v].sumq, self.statelist[v].mq, self.statelist[v].w, self.statelist[v].sumq / statelist[v].n, statelist[v].n)\n\t                if (ret == -1 or tmp > mx):\n\t                    ret = v\n", "                    mx = tmp\n\t                    actid = i\n\t            print(\"**************\")\n\t            print(round(self.statelist[ret].n,2), round(self.statelist[ret].mq,2))\n\t            print(\"**************\")\n\t            return ret, self.statelist[now].sons[actid]\n\t        if (self.statelist[now].opt == 1 or self.statelist[now].opt == 2):\n\t            for i in range(len(self.statelist[now].sons)):\n\t                v = self.statelist[now].sons[i].stateid\n\t                tmp = alpha * self.statelist[v].q / self.statelist[v].n + (1 - alpha) * self.statelist[v].mq + c * math.sqrt(2 * math.log(self.statelist[now].n) / self.statelist[v].n)\n", "                if (ret == -1 or tmp > mx):\n\t                    ret = v\n\t                    mx = tmp\n\t                    actid = i\n\t        else: # use kernel\n\t            for i in range(len(self.statelist[now].sons)):\n\t                v = self.statelist[now].sons[i].stateid\n\t                if (self.statelist[v].w < 1e-7):\n\t                    ret = v\n\t                    actid = i\n", "                    break\n\t                tmp = alpha * self.statelist[v].q / self.statelist[v].w + (1 - alpha) * self.statelist[v].mq\n\t                tmp = tmp + c * (math.sqrt(2 * math.log(self.statelist[now].sumw) / self.statelist[v].w) * 0.8 + math.sqrt(2 * math.log(self.statelist[now].n) / self.statelist[v].n) * 0.2)\n\t                if (ret == -1 or tmp > mx):\n\t                    ret = v\n\t                    mx = tmp\n\t                    actid = i\n\t        return ret, self.statelist[now].sons[actid]\n\t    def take_action(self, p, e, elist, act):\n\t        if (act.opt == 0):\n", "            p.append(Point(act.vec))\n\t            if (len(p) == args.maxp):\n\t                for i in range(len(p)):\n\t                    for j in range(i + 1, len(p)):\n\t                        if (not (p[i].isSupport and p[j].isSupport)) and self.inlen(p[i], p[j]):\n\t                            elist.add((i, j))\n\t        if (act.opt == 1):\n\t            if (act.u != -1 and act.v != -1):\n\t                e.append(Bar(act.u, act.v, act.area, getlen2(p[act.u], p[act.v]), d = act.d, t = act.t))\n\t                elist.remove((act.u, act.v))\n", "                if (args.env_dims == 2 and args.CONSTRAINT_CROSS_EDGE == 1):\n\t                    dellist = []\n\t                    for i in elist:\n\t                        if (transintersect(act.u, act.v, i[0], i[1], p)):\n\t                            dellist.append(i)\n\t                    for i in dellist: elist.remove(i)\n\t            else:\n\t                elist.clear()\n\t        if (act.opt == 2):\n\t            if args.env_mode == 'DT':\n", "                e[act.eid].d = act.d\n\t                e[act.eid].t = act.t\n\t            else:\n\t                e[act.eid]._area = act.area\n\tdef isok(vec):\n\t    if (minx <= vec.x and vec.x <= maxx and miny <= vec.y and vec.y <= maxy and minz <= vec.z and vec.z <= maxz):\n\t        return True\n\t    return False\n\tdef getnewchild0(stateid, vec):\n\t    assert(statelist[stateid].opt == 0)\n", "    finvec = Vector3()\n\t    bestw = 0.0\n\t    for iter in range(args.maxnum):\n\t        newvec = vec + randpoint() * args.sgm2 * 0.5\n\t        newvec.x = max(min(newvec.x, maxx), minx)\n\t        newvec.x = max(min(newvec.y, maxy), miny)\n\t        newvec.x = max(min(newvec.z, maxz), minz)\n\t        w = 0.0\n\t        for i in range(len(statelist[stateid].sons)):\n\t            w = w + Kernel2(newvec, statelist[stateid].sons[i].vec, args.sgm2) * statelist[statelist[stateid].sons[i].stateid].n\n", "        if (iter == 0 or w < bestw):\n\t            bestw = w\n\t            finvec = newvec\n\t    statelist[stateid].sons.append(Action(0, vec = finvec))\n\t    return len(statelist[stateid].sons) - 1\n\t## gai\n\tdef getnewchild2(stateid, area):\n\t    assert(statelist[stateid].opt == 2)\n\t    finarea = maxarea\n\t    bestw = 0.0\n", "    for iter in range(args.maxnum):\n\t        newarea = getrand(max(minarea, area - args.sgm1 * 3), min(maxarea, area + args.sgm1 * 3))\n\t        w = 0.0\n\t        for i in range(len(statelist[stateid].sons)):\n\t            w = w + Kernel1(newarea, statelist[stateid].sons[i].area, args.sgm1)\n\t        if (iter == 0 or w < bestw):\n\t            bestw = w\n\t            finarea = newarea\n\t    statelist[stateid].sons.append(Action(2, area = finarea, eid = statelist[stateid].eid))\n\t    return len(statelist[stateid].sons) - 1\n", "def treepolicy(stateid, p_, e_, elist_):\n\t    p = copy.deepcopy(p_)\n\t    e = copy.deepcopy(e_)\n\t    elist = copy.deepcopy(elist_)\n\t    global statelist\n\t    now = stateid\n\t    sonid = -1\n\t    while ((not statelist[now].isEnd) and (sonid == -1)):\n\t        opt = statelist[now].opt\n\t        ret = statelist[now].findunvis()\n", "        if (ret != -1):\n\t            sonid = ret\n\t            break\n\t        nxt, act = bestchild(now, args.c[opt], args.alpha)\n\t        if (opt == 1):\n\t            now = nxt\n\t            take_action(p, e, elist, act)\n\t        elif (opt == 0):\n\t            sizeA = len(statelist[now].sons)\n\t            if (sizeA * sizeA * 3 > statelist[now].n and (not statelist[nxt].isEnd or len(statelist[now].sons) > args.maxson)): \n", "                now = nxt\n\t                take_action(p, e, elist, act)\n\t            else: \n\t                sonid = getnewchild0(now, act.vec) #add new child\n\t        elif (opt == 2):\n\t            sizeA = len(statelist[now].sons)\n\t            if (sizeA * sizeA * 3 > statelist[now].n and (not statelist[nxt].isEnd or len(statelist[now].sons) > args.maxson)): \n\t                now = nxt\n\t                take_action(p, e, elist, act)\n\t            else: \n", "                sonid = getnewchild2(now, act.area) #add new child\n\t    if (sonid >= 0): # add new child\n\t        act = statelist[now].sons[sonid]\n\t        take_action(p, e, elist, act)\n\t        opt = statelist[now].opt\n\t        if (opt == 0):\n\t            if (len(p) == args.maxp): newstate = State(p, e, 1, fa = now, elist = elist)\n\t            else: newstate = State(p, e, 0, fa = now)\n\t            for i in range(len(statelist[now].sons)):\n\t                if (i == sonid): continue\n", "                if (opt == 0):\n\t                    KAB = Kernel2(act.vec, statelist[now].sons[i].vec, args.sgm2)\n\t                else:\n\t                    KAB = Kernel1(act.area, statelist[now].sons[i].area, args.sgm1)\n\t                sid = statelist[now].sons[i].stateid\n\t                newstate.w = newstate.w + statelist[sid].n * KAB\n\t                newstate.q = newstate.q + statelist[sid].sumq * KAB\n\t        if (opt == 1):\n\t            if (act.u < 0): newstate = State(p, e, 2, fa = now, eid = 0)\n\t            else: newstate = State(p, e, 1, fa = now, elist = elist)\n", "        if (opt == 2): \n\t            newstate = State(p, e, 2, fa = now, eid = act.eid + 1)\n\t        statelist.append(newstate)\n\t        statelist[now].sons[sonid].stateid = len(statelist) - 1\n\t        now = len(statelist) - 1\n\t    return now, p, e, elist\n\tdef defaultpolicy(stateid, p, e, elist):\n\t    opt = statelist[stateid].opt\n\t    if (opt == 0):\n\t        while (len(p) < args.maxp):\n", "            p.append(Point(Vector3(getrand(minx, maxx), getrand(miny, maxy), getrand(minz, maxz))))\n\t        opt = 1\n\t    if (opt == 1):\n\t        for i in range(len(e)):\n\t            if (args.env_mode == 'DT'):\n\t                area_random = arealist[random.randint(0, len(arealist) - 1)]\n\t                e[i].d = area_random[4]\n\t                e[i].t = area_random[5]\n\t            else: e[i]._area = getrand(minarea, maxarea)\n\t        el = []\n", "        for i in elist: el.append(i)\n\t        if (len(el) == 0 and len(e) == 0):\n\t            for i in range(len(p)):\n\t                for j in range(i + 1, len(p)):\n\t                    if (p[i].isSupport and p[j].isSupport): continue\n\t                    if (not inlen(p[i], p[j])): continue\n\t                    el.append((i, j))\n\t        random.shuffle(el)\n\t        ret = -1\n\t        for i in range(len(el)):\n", "            probnow = random.random()\n\t            if (probnow > args.prob): continue\n\t            u = el[i][0]\n\t            v = el[i][1]\n\t            if (canadd(u, v, p, e)):\n\t                if (args.env_mode == 'DT'):\n\t                    area_random = arealist[random.randint(0, len(arealist) - 1)]\n\t                    e.append(Bar(u, v, leng = getlen2(p[u], p[v]), d=area_random[4], t=area_random[5]))\n\t                else: e.append(Bar(u, v, leng = getlen2(p[u], p[v]), area = getrand(minarea, maxarea)))\n\t                ret = soft_reward(reward_fun(p, e), p, e)\n", "                if (ret > 1e-7): return ret\n\t        return ret\n\t    if (opt == 2):\n\t        for i in range(statelist[stateid].eid, len(e)):\n\t            if (args.env_mode == 'DT'):\n\t                area_random = arealist[random.randint(0, len(arealist) - 1)]\n\t                e[i].d = area_random[4]\n\t                e[i].t = area_random[5]\n\t            else: e[i]._area = getrand(minarea, maxarea)\n\t        ret = soft_reward(reward_fun(p, e), p, e)\n", "        return ret\n\t    assert(False)\n\tdef backup(now, delta, root):\n\t    fa = statelist[now].fa\n\t    while (True):\n\t        statelist[now].n = statelist[now].n + 1\n\t        statelist[now].sumq = statelist[now].sumq + delta\n\t        if (statelist[now].mq < delta):\n\t            statelist[now].mq = delta\n\t        if (now == root): break\n", "        if (statelist[fa].opt == 1 or statelist[fa].opt == 2):\n\t            statelist[now].q = statelist[now].q + delta\n\t        elif (statelist[fa].opt == 0):  \n\t            sonid = -1\n\t            for i in range(len(statelist[fa].sons)):\n\t                if (statelist[fa].sons[i].stateid == now):\n\t                    sonid = i\n\t                    break\n\t            assert(sonid != -1)\n\t            vec0 = statelist[fa].sons[sonid].vec\n", "            for i in range(len(statelist[fa].sons)):\n\t                KAB = Kernel2(vec0, statelist[fa].sons[i].vec, args.sgm2)\n\t                sid = statelist[fa].sons[i].stateid\n\t                statelist[sid].w = statelist[sid].w + KAB\n\t                statelist[sid].q = statelist[sid].q + KAB * delta\n\t                statelist[fa].sumw = statelist[fa].sumw + KAB\n\t        now = fa\n\t        fa = statelist[now].fa\n\tdef UCTSearch(p, e):\n\t    global bestreward\n", "    global tmpbestreward\n\t    global elist\n\t    elist = set()\n\t    step_node = 1\n\t    opt = 0\n\t    eidnow = 0\n\t    maxiter = args.UCT_maxiter\n\t    root = 0\n\t    while (not (opt == 2 and eidnow >= len(e))):\n\t        statelist.clear()\n", "        tmpbestreward = 1e9\n\t        tmpbestreward2 = 1e9\n\t        root = 0\n\t        if (opt == 0):\n\t            statelist.append(State(p, e, 0, -1))\n\t            if (len(pbest) > len(p)):\n\t                statelist[root].sons.append(Action(0, vec = pbest[len(p)].vec))\n\t        if (opt == 1):\n\t            statelist.append(State(p, e, 1, -1, elist = elist))\n\t        if (opt == 2):\n", "            statelist.append(State(p, e, 2, -1, eid = eidnow))\n\t        extra_iter = 0\n\t        if (opt == 0): extra_iter = args.UCT_extra_iter_for_point_pos\n\t        for iter in range(maxiter + extra_iter):\n\t            tmp, ptmp, etmp, elisttmp = treepolicy(root, p, e, elist)\n\t            delta = defaultpolicy(tmp, ptmp, etmp, elisttmp)\n\t            backup(tmp, delta, root)\n\t            if (iter % 100 == 0):\n\t                tmpbestreward2 = min(tmpbestreward2, tmpbestreward)\n\t                print(iter, bestreward, tmpbestreward2, tmpbestreward, len(statelist[root].sons))\n", "                tmpbestreward = 1e9\n\t        root2, tmpact = bestchild(root, 0.0, args.pickalpha)\n\t        if (opt == 0):\n\t            act = Action(0, vec = pbest[len(p)].vec)\n\t            # for SaveKR:\n\t            if args.save_KR == True:\n\t                KR_plist_x = []\n\t                KR_plist_y = []\n\t                KR_plist_z = []\n\t                print(len(p)+1,\"*****************************************\")\n", "#                print(len(p)+1,\"*****************************************\", file = LOG_result)\n\t                for ii in range(len(statelist[root].sons)):\n\t                    KR_plist_x.append(statelist[root].sons[ii].vec.x)\n\t                    KR_plist_y.append(statelist[root].sons[ii].vec.y)\n\t                    KR_plist_z.append(statelist[root].sons[ii].vec.z)\n\t                    print(ii,statelist[root].sons[ii].vec.x, statelist[root].sons[ii].vec.y, statelist[root].sons[ii].vec.z)\n\t#                    print(ii,statelist[root].sons[ii].vec.x, statelist[root].sons[ii].vec.y, statelist[root].sons[ii].vec.z, file = LOG_result)\n\t                print(len(p)+1,\"*****************************************\")\n\t#                print(len(p)+1,\"*****************************************\", file = LOG_result)\n\t                X1=np.ones(len(KR_plist_x))\n", "                Y1=np.ones(len(KR_plist_x))\n\t                Z1=np.ones(len(KR_plist_x))\n\t                fig1 = plt.figure()\n\t                ax1 = plt.axes(projection='3d')\n\t                for i in range(len(KR_plist_x)):\n\t                    ax1.scatter3D([KR_plist_x[i]], [KR_plist_y[i]], [KR_plist_z[i]], color='b')\n\t                    X1[i] = KR_plist_x[i]\n\t                    Y1[i] = KR_plist_y[i]\n\t                    Z1[i] = KR_plist_z[i]\n\t                # Create cubic bounding box to simulate equal aspect ratio\n", "                max_range = np.array([X1.max()-X1.min(), Y1.max()-Y1.min(), Z1.max()-Z1.min()]).max()\n\t                Xb1 = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(X1.max()+X1.min())\n\t                Yb1 = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(Y1.max()+Y1.min())\n\t                Zb1 = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(Z1.max()+Z1.min())\n\t                # Comment or uncomment following both lines to test the fake bounding box:\n\t                for xb1, yb1, zb1 in zip(Xb1, Yb1, Zb1):\n\t                    ax1.plot([xb1], [yb1], [zb1], 'w')\n\t                # plt.scatter(KR_plist_x, KR_plist_y, color='b')\n\t                # plt.axis(\"equal\")\n\t                inputname = FILENAME.replace(\".txt\",\"_\")\n", "                FILENAME_add_node_jpg = \"./results/\" + time_str + \"_\" + str(args.maxp) + \"p_\" + inputname + \"add-node-\"+str(step_node) + \".jpg\"\n\t                plt.savefig(FILENAME_add_node_jpg, dpi = 1000)\n\t                plt.close()\n\t                step_node = step_node + 1\n\t                print(len(KR_plist_x))\n\t        if (opt == 1):\n\t            if (len(e) == len(ebest)): act = Action(1)\n\t            else: act = Action(1, u = ebest[len(e)].u, v = ebest[len(e)].v)\n\t        if (opt == 2):\n\t            act = Action(2, area = ebest[eidnow].area, \n", "                eid = eidnow,\n\t                d = ebest[eidnow].d, \n\t                t = ebest[eidnow].t\n\t            )\n\t        take_action(p, e, elist, act)\n\t        print(act)\n\t        print(bestreward, tmpbestreward)\n\t        if (opt == 0):\n\t            if (len(p) == args.maxp): opt = 1\n\t        elif (opt == 1):\n", "            if (act.u == -1): opt = 2\n\t        elif (opt == 2):\n\t            eidnow = eidnow + 1\n\t    return bestreward, pbest, ebest"]}
{"filename": "algo/UCTs.py", "chunked_list": ["from utils.utils import Vector3, Point, Bar\n\tfrom utils.utils import getrand, randpoint, Kernel1, Kernel2, getlen, getlen2, save_file_stage1, readFile, transintersect, similar_position, similar_topo, closestDistanceBetweenLines\n\tfrom truss_envs.reward import *\n\tfrom algo.value_network import Value_Network\n\timport math\n\timport copy\n\timport random\n\timport numpy as np\n\timport matplotlib.pyplot as plt\n\timport time\n", "import heapq\n\tpbest = []\n\tebest = []\n\tbestreward = 1e9\n\ttmpbestreward = 1e9\n\tFILENAME = \"kr-sundial-newinput.txt\"\n\ttime_str = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime()) \n\tdef UCTs_init(args__, plist__ = [], arealist__ = []):\n\t    global args\n\t    global arealist\n", "    global plist\n\t    global minx\n\t    global maxx\n\t    global miny\n\t    global maxy\n\t    global minz\n\t    global maxz\n\t    global minlen\n\t    global maxlen\n\t    global minarea\n", "    global maxarea\n\t    global OUTPUT_ALL_THRESHOLD\n\t    global MASS_ALLFOLDER\n\t    global MASS_OUTPUT_ALL_MAX\n\t    global OUTPUT_ALL_MAX\n\t    global MASS_OUTPUT_ALL_THRESHOLD\n\t    global ALLFOLDER\n\t    global LOGFOLDER\n\t    global logfile\n\t    global DIVERSITY_FOLDER\n", "    global DIVERSITY_TOPO_FOLDER\n\t    global save_valid_count\n\t    global save_invalid_count\n\t    global v_network\n\t    global global_iteration\n\t    args = args__\n\t    minx = args.coordinate_range[0][0]\n\t    maxx = args.coordinate_range[0][1]\n\t    miny = args.coordinate_range[1][0]\n\t    maxy = args.coordinate_range[1][1]\n", "    if (args.env_dims == 3):\n\t        minz = args.coordinate_range[2][0]\n\t        maxz = args.coordinate_range[2][1]\n\t    else:\n\t        minz = maxz = 0\n\t    minlen = args.len_range[0]\n\t    maxlen = args.len_range[1]\n\t    minarea = args.area_range[0]\n\t    maxarea = args.area_range[1]\n\t    arealist = arealist__\n", "    plist = plist__\n\t    save_valid_count = 0\n\t    save_invalid_count = 0\n\t    global_iteration = 0\n\t    MASS_OUTPUT_ALL_THRESHOLD = args.MASS_OUTPUT_ALL_THRESHOLD\n\t    LOGFOLDER = os.path.join(args.save_path, args.run_id)\n\t    if not os.path.exists(LOGFOLDER): os.mkdir(LOGFOLDER)\n\t    ALLFOLDER = os.path.join(LOGFOLDER, 'Reward_ALL_Result/')\n\t    print(ALLFOLDER)\n\t    if not os.path.exists(ALLFOLDER): os.mkdir(ALLFOLDER)\n", "    OUTPUT_ALL_MAX = 10000\n\t    MASS_ALLFOLDER = os.path.join(LOGFOLDER, 'MASS_ALL_Result/')\n\t    if not os.path.exists(MASS_ALLFOLDER): os.mkdir(MASS_ALLFOLDER)\n\t    MASS_OUTPUT_ALL_MAX = 10000\n\t    DIVERSITY_FOLDER = os.path.join(LOGFOLDER, 'DIVERSITY_result/')\n\t    if not os.path.exists(DIVERSITY_FOLDER): os.mkdir(DIVERSITY_FOLDER)\n\t    DIVERSITY_TOPO_FOLDER = os.path.join(LOGFOLDER, 'DIVERSITY_TOPO_result/')\n\t    if not os.path.exists(DIVERSITY_TOPO_FOLDER): os.mkdir(DIVERSITY_TOPO_FOLDER)\n\t    logfile = open(os.path.join(LOGFOLDER, args.logfile_stage1), 'w')\n\tdef diversity_save(reward, reward_count, Mass, Dis_value, Stress_value, Buckle_value, p, e):\n", "    global save_valid_count\n\t    FILES = os.listdir(ALLFOLDER)\n\t    if (Mass > MASS_OUTPUT_ALL_THRESHOLD): return\n\t    MASS_FILES = os.listdir(MASS_ALLFOLDER)\n\t    if len(MASS_FILES) < MASS_OUTPUT_ALL_MAX:\n\t        OUTFILE = MASS_ALLFOLDER + str(round(Mass)) + '.txt'\n\t        if (not os.path.exists(OUTFILE)):\n\t            save_file_stage1(OUTFILE, p, e)\n\t            save_valid_count += 1\n\t    DIVERSITY_FILES = os.listdir(DIVERSITY_FOLDER)\n", "    d_flag = True\n\t    for d_file in DIVERSITY_FILES:\n\t        p_tmp, e_tmp = readFile(os.path.join(DIVERSITY_FOLDER, d_file))\n\t        mass_tmp = int(d_file[:-4])\n\t        if (similar_position(p, e, p_tmp, e_tmp)):\n\t            d_flag = False\n\t            if (mass_tmp <= Mass): continue\n\t            os.remove(os.path.join(DIVERSITY_FOLDER, d_file))\n\t            OUTFILE = DIVERSITY_FOLDER + str(round(Mass)) + '.txt'\n\t            if (not os.path.exists(OUTFILE)):\n", "                save_file_stage1(OUTFILE, p, e)\n\t    if (d_flag):\n\t        OUTFILE = DIVERSITY_FOLDER + str(round(Mass)) + '.txt'\n\t        if (not os.path.exists(OUTFILE)):\n\t            save_file_stage1(OUTFILE, p, e)\n\t    DIVERSITY_TOPO_FILES = os.listdir(DIVERSITY_TOPO_FOLDER)\n\t    d_flag = True\n\t    for d_file in DIVERSITY_TOPO_FILES:\n\t        p_tmp, e_tmp = readFile(os.path.join(DIVERSITY_TOPO_FOLDER, d_file))\n\t        mass_tmp = int(d_file[:-4])\n", "        if (similar_topo(p, e, p_tmp, e_tmp)):\n\t            d_flag = False\n\t            if (mass_tmp > Mass):\n\t                os.remove(os.path.join(DIVERSITY_TOPO_FOLDER, d_file))\n\t                OUTFILE = DIVERSITY_TOPO_FOLDER + str(round(Mass)) + '.txt'\n\t                if (not os.path.exists(OUTFILE)): save_file_stage1(OUTFILE, p, e)\n\t            break\n\t    if (d_flag):\n\t        OUTFILE = DIVERSITY_TOPO_FOLDER + str(round(Mass)) + '.txt'\n\t        if (not os.path.exists(OUTFILE)):\n", "            save_file_stage1(OUTFILE, p, e)\n\tdef soft_reward(env_output, p, e):\n\t    reward, reward_cnt, Mass, Dis_value, Stress_value, Buckle_value = env_output\n\t    global pbest\n\t    global ebest\n\t    global bestreward\n\t    global tmpbestreward\n\t    global save_invalid_count\n\t    if (reward <= 0):\n\t        if (save_invalid_count < save_valid_count * args.save_invalid_factor and reward == 0):\n", "            folder = os.path.join(LOGFOLDER, \"invalid\")\n\t            if (not os.path.exists(folder)): os.mkdir(folder)\n\t            save_file_stage1(os.path.join(folder, str(save_invalid_count) + '.txt'), p, e)\n\t            save_invalid_count += 1\n\t        return reward\n\t    if (bestreward > reward):\n\t        bestreward = reward\n\t        pbest = copy.deepcopy(p)\n\t        ebest = copy.deepcopy(e)\n\t    if (tmpbestreward > reward):\n", "        tmpbestreward = reward\n\t    if (args.save_diversity):\n\t        diversity_save(reward, reward_cnt, Mass, Dis_value, Stress_value, Buckle_value, p, e)\n\t    reward= args.reward_lambda / (reward * reward)\n\t    return reward\n\tdef inlen(u, v):\n\t    if (getlen2(u, v) > maxlen and args.CONSTRAINT_MAX_LENGTH):\n\t        return False\n\t    if (getlen2(u, v) < minlen and args.CONSTRAINT_MIN_LENGTH):\n\t        return False\n", "    return True\n\tdef canadd(N1, N2, p, e, area = None, d = None, t = None):\n\t    if (not inlen(p[N1], p[N2])): return False\n\t    if (args.CONSTRAINT_CROSS_EDGE == 1):\n\t        if (area == None and d == None and t == None):\n\t            if (args.env_dims == 2):\n\t                for i in range(len(e)):\n\t                    N3 = e[i].u\n\t                    N4 = e[i].v\n\t                    if (transintersect(N1, N2, N3, N4, p)): return False\n", "            return True\n\t        for i in range(len(e)):\n\t            if (N1 == e[i].v or N1 == e[i].u or N2 == e[i].v or N2 == e[i].u): continue\n\t            _, _, dis = closestDistanceBetweenLines(p[N1].Point2np(), p[N2].Point2np(), p[e[i].u].Point2np(), p[e[i].v].Point2np(), clampAll = True)\n\t            if (d != None):\n\t                r1, r2 = d / 2, e[i].d / 2\n\t            else:\n\t                if (args.env_dims == 2):\n\t                    r1, r2 = area / 2, e[i].area / 2\n\t                elif (args.env_dims == 3):\n", "                    r1, r2 = np.sqrt(area / np.pi), np.sqrt(e[i].area / np.pi)\n\t            if (dis <= r1 + r2): return False\n\t    return True\n\tdef max_can_add_area(new_e, p, e):\n\t    if (args.CONSTRAINT_CROSS_EDGE == 0): \n\t        if (args.env_mode == 'DT'):\n\t            return None, arealist[-1][4]\n\t        elif (args.env_mode == 'Area'):\n\t            return maxarea, None\n\t    if (args.env_mode == 'DT'):\n", "        mind = arealist[-1][4]\n\t        for i in range(len(e)):\n\t            if (new_e.u == e[i].v or new_e.u == e[i].u or new_e.v == e[i].v or new_e.v == e[i].u): continue\n\t            _, _, dis = closestDistanceBetweenLines(p[new_e.u].Point2np(), p[new_e.v].Point2np(), p[e[i].u].Point2np(), p[e[i].v].Point2np(), clampAll = True)\n\t            mind = min(mind, (dis - e[i].d / 2) * 2)\n\t        return None, mind\n\t    elif (args.env_mode == 'Area'):\n\t        mina = maxarea\n\t        for i in range(len(e)):\n\t            if (new_e.u == e[i].v or new_e.u == e[i].u or new_e.v == e[i].v or new_e.v == e[i].u): continue\n", "            _, _, dis = closestDistanceBetweenLines(p[new_e.u].Point2np(), p[new_e.v].Point2np(), p[e[i].u].Point2np(), p[e[i].v].Point2np(), clampAll = True)\n\t            if (args.env_dims == 2):\n\t                mina = min(mina, (dis - e[i].area / 2) * 2)\n\t            elif (args.env_dims == 3):\n\t                mina = min(mina, np.pi * ((dis - np.sqrt(e[i].area / np.pi)) ** 2))\n\t        return mina, None\n\tclass Action():\n\t    def __init__(self, opt, u = -1, v = -1, area = -1, vec = Vector3(), eid = 0, d = None, t = None):\n\t        self.opt = opt\n\t        self.stateid = -1\n", "        self.d = None\n\t        self.t = None\n\t        if (opt == 0): self.vec = vec           #add node\n\t        if (opt == 1):                          #add edge\n\t            self.opt = opt\n\t            self.u = u\n\t            self.v = v\n\t            if (area != -1): self.area = area\n\t            else: self.area = maxarea\n\t            if (args.env_mode == 'DT'):\n", "                self.d = arealist[-1][4]\n\t                self.t = arealist[-1][5]\n\t        if (opt == 2):                          #change area\n\t            if (args.env_mode == 'DT'): assert(d > 0 and t > 0)\n\t            self.eid = eid\n\t            if (area != -1): self.area = area\n\t            else: self.area = maxarea\n\t            self.d = d\n\t            self.t = t\n\t    def __str__(self):\n", "        if (self.opt == 0): return \"add node at\" + self.vec.__str__()\n\t        if (self.opt == 1):\n\t            if (self.area < 1e-8): return \"do nothing\"\n\t            else: return \"add edge between\" + str(self.u) + \"and\" + str(self.v)\n\t        if (self.opt == 2): return \"modify area of \" + str(self.eid) + \"to \" + str(self.area)\n\tclass State():\n\t    def __init__(self, p, e, opt, fa = 0, elist = set(), eid = 0):\n\t        self.opt = opt\n\t        self.sons = []\n\t        self.isEnd = False\n", "        self.n = 0\n\t        self.q = 0\n\t        self.fa = fa\n\t        self.allvisited = False\n\t        self.w = 0.0\n\t        self.sumq = 0.0\n\t        self.sumw = 0.0\n\t        self.mq = -1000\n\t        if (opt == 0):\n\t            for i in range(len(plist)):\n", "                flag = False\n\t                tmpp = plist[i]\n\t                for j in range(len(p)):\n\t                    if (inlen(Point(tmpp), p[j])):\n\t                        flag = True\n\t                        break\n\t                if (flag == True): self.sons.append(Action(0, vec = tmpp))\n\t            for i in range(len(self.sons), args.initson):\n\t                flag = False\n\t                tmpp = Vector3(getrand(minx, maxx), getrand(miny, maxy), getrand(minz, maxz))\n", "                for j in range(len(p)):\n\t                    if (inlen(Point(tmpp), p[j])):\n\t                        flag = True\n\t                        break\n\t                if (flag == True): self.sons.append(Action(0, vec = tmpp))\n\t        if (opt == 1):\n\t            self.reward = soft_reward(reward_fun(p, e), p, e)\n\t            if (self.reward > 1e-7): self.sons.append(Action(1)) # 当前结构稳定\n\t            for i in elist: \n\t                self.sons.append(Action(1, u = i[0], v = i[1]))\n", "            if (len(self.sons) == 0):\n\t                self.isEnd = True\n\t                self.reward = soft_reward(reward_fun(p, e), p, e)\n\t        if (opt == 2):\n\t            self.eid = eid\n\t            if (eid >= len(e)):\n\t                self.isEnd = True\n\t                self.reward = soft_reward(reward_fun(p, e), p, e)\n\t            else:\n\t                if (args.env_mode == 'DT'):\n", "                    for i in range(len(arealist)):\n\t                        self.sons.append(Action(2, d = arealist[i][4], t = arealist[i][5], eid = eid))\n\t                else:\n\t                    for i in range(args.initson + 1):\n\t                        self.sons.append(Action(2, area = minarea + (maxarea - minarea) / args.initson * i))\n\t    def findunvis(self): # find unvisited node\n\t        ret = -1\n\t        for i in range(len(self.sons)):\n\t            if (self.sons[i].stateid == -1):\n\t                ret = i\n", "                break\n\t        if (ret == -1): self.allvisited = True\n\t        return ret\n\tdef bestchild(now, c, alpha):\n\t    global statelist\n\t    ret = -1\n\t    actid = -1\n\t    mx = 0\n\t    if (abs(c) < 1e-7): # final find, no explore \n\t        for i in range(len(statelist[now].sons)):\n", "            v = statelist[now].sons[i].stateid\n\t            if (statelist[now].opt == 1):\n\t                tmp = alpha * statelist[v].q / statelist[v].n + (1 - alpha) * statelist[v].mq\n\t                print(statelist[v].q, statelist[v].n, statelist[v].mq, statelist[v].q / statelist[v].n, 'a')\n\t            else:\n\t                tmp = alpha * statelist[v].sumq / statelist[v].n + (1 - alpha) * statelist[v].mq\n\t                print(statelist[v].q, statelist[v].sumq, statelist[v].mq, statelist[v].w, statelist[v].sumq / statelist[v].n, statelist[v].n)\n\t            if (ret == -1 or tmp > mx):\n\t                ret = v\n\t                mx = tmp\n", "                actid = i\n\t        print(\"**************\")\n\t        print(round(statelist[ret].n,2), round(statelist[ret].mq,2))\n\t        print(\"**************\")\n\t        return ret, statelist[now].sons[actid]\n\t    if (statelist[now].opt == 1 or statelist[now].opt == 2):\n\t        for i in range(len(statelist[now].sons)):\n\t            v = statelist[now].sons[i].stateid\n\t            tmp = alpha * statelist[v].q / statelist[v].n + (1 - alpha) * statelist[v].mq + c * math.sqrt(2 * math.log(statelist[now].n) / statelist[v].n)\n\t            if (ret == -1 or tmp > mx):\n", "                ret = v\n\t                mx = tmp\n\t                actid = i\n\t    else: # use kernel\n\t        for i in range(len(statelist[now].sons)):\n\t            v = statelist[now].sons[i].stateid\n\t            if (statelist[v].w < 1e-7):\n\t                ret = v\n\t                actid = i\n\t                break\n", "            tmp = alpha * statelist[v].q / statelist[v].w + (1 - alpha) * statelist[v].mq\n\t            tmp = tmp + c * (math.sqrt(2 * math.log(statelist[now].sumw) / statelist[v].w) * 0.8 + math.sqrt(2 * math.log(statelist[now].n) / statelist[v].n) * 0.2)\n\t            if (ret == -1 or tmp > mx):\n\t                ret = v\n\t                mx = tmp\n\t                actid = i\n\t    return ret, statelist[now].sons[actid]\n\tdef take_action(p, e, elist, act):\n\t    if (act.opt == 0):\n\t        p.append(Point(act.vec))\n", "        if (len(p) == args.maxp):\n\t            for i in range(len(p)):\n\t                for j in range(i + 1, len(p)):\n\t                    if (not (p[i].isSupport and p[j].isSupport)) and inlen(p[i], p[j]):\n\t                        elist.add((i, j))\n\t    if (act.opt == 1):\n\t        if (act.u != -1 and act.v != -1):\n\t            e.append(Bar(act.u, act.v, act.area, getlen2(p[act.u], p[act.v]), d = act.d, t = act.t))\n\t            elist.remove((act.u, act.v))\n\t            dellist = []\n", "            if (args.env_dims == 2 and args.CONSTRAINT_CROSS_EDGE == 1):\n\t                for i in elist:\n\t                    if (transintersect(act.u, act.v, i[0], i[1], p)):\n\t                        dellist.append(i)\n\t                for i in dellist:\n\t                    elist.remove(i)\n\t        else: elist.clear()\n\t    if (act.opt == 2):\n\t        if args.env_mode == 'DT':\n\t            e[act.eid].d = act.d\n", "            e[act.eid].t = act.t\n\t        else: e[act.eid]._area = act.area\n\tdef isok(vec):\n\t    if (minx <= vec.x and vec.x <= maxx and miny <= vec.y and vec.y <= maxy and minz <= vec.z and vec.z <= maxz):\n\t        return True\n\t    return False\n\tdef getnewchild0(stateid, vec):\n\t    assert(statelist[stateid].opt == 0)\n\t    finvec = Vector3()\n\t    bestw = 0.0\n", "    for iter in range(args.maxnum):\n\t        newvec = vec + randpoint() * args.sgm2 * 0.5\n\t        newvec.x = max(min(newvec.x, maxx), minx)\n\t        newvec.y = max(min(newvec.y, maxy), miny)\n\t        newvec.z = max(min(newvec.z, maxz), minz)\n\t        w = 0.0\n\t        for i in range(len(statelist[stateid].sons)):\n\t            w = w + Kernel2(newvec, statelist[stateid].sons[i].vec, args.sgm2) * statelist[statelist[stateid].sons[i].stateid].n\n\t        if (iter == 0 or w < bestw):\n\t            bestw = w\n", "            finvec = newvec\n\t    statelist[stateid].sons.append(Action(0, vec = finvec))\n\t    return len(statelist[stateid].sons) - 1\n\tdef getnewchild2(stateid, area):\n\t    assert(statelist[stateid].opt == 2)\n\t    finarea = maxarea\n\t    bestw = 0.0\n\t    for iter in range(args.maxnum):\n\t        newarea = getrand(max(minarea, area - args.sgm1 * 3), min(maxarea, area + args.sgm1 * 3))\n\t        w = 0.0\n", "        for i in range(len(statelist[stateid].sons)):\n\t            w = w + Kernel1(newarea, statelist[stateid].sons[i].area, args.sgm1)\n\t        if (iter == 0 or w < bestw):\n\t            bestw = w\n\t            finarea = newarea\n\t    statelist[stateid].sons.append(Action(2, area = finarea, eid = statelist[stateid].eid))\n\t    return len(statelist[stateid].sons) - 1\n\tdef treepolicy(stateid, p_, e_, elist_):\n\t    p = copy.deepcopy(p_)\n\t    e = copy.deepcopy(e_)\n", "    elist = copy.deepcopy(elist_)\n\t    global statelist\n\t    now = stateid\n\t    sonid = -1\n\t    while ((not statelist[now].isEnd) and (sonid == -1)):\n\t        opt = statelist[now].opt\n\t        ret = statelist[now].findunvis()\n\t        if (ret != -1):\n\t            sonid = ret\n\t            break\n", "        nxt, act = bestchild(now, args.c[opt], args.alpha)\n\t        if (opt == 1):\n\t            now = nxt\n\t            take_action(p, e, elist, act)\n\t        elif (opt == 0):\n\t            sizeA = len(statelist[now].sons)\n\t            if (sizeA * sizeA * 3 > statelist[now].n and (not statelist[nxt].isEnd or len(statelist[now].sons) > args.maxson)): \n\t                now = nxt\n\t                take_action(p, e, elist, act)\n\t            else: \n", "                sonid = getnewchild0(now, act.vec) #add new child\n\t        elif (opt == 2):\n\t            sizeA = len(statelist[now].sons)\n\t            if (sizeA * sizeA * 3 > statelist[now].n and (not statelist[nxt].isEnd or len(statelist[now].sons) > args.maxson)) or (args.env_mode == 'DT'): \n\t                now = nxt\n\t                take_action(p, e, elist, act)\n\t            else: \n\t                sonid = getnewchild2(now, act.area) #add new child\n\t    if (sonid >= 0): # add new child\n\t        act = statelist[now].sons[sonid]\n", "        take_action(p, e, elist, act)\n\t        opt = statelist[now].opt\n\t        if (opt == 0):\n\t            if (len(p) == args.maxp): newstate = State(p, e, 1, fa = now, elist = elist)\n\t            else: newstate = State(p, e, 0, fa = now)\n\t            for i in range(len(statelist[now].sons)):\n\t                if (i == sonid): continue\n\t                if (opt == 0):\n\t                    KAB = Kernel2(act.vec, statelist[now].sons[i].vec, args.sgm2)\n\t                else:\n", "                    KAB = Kernel1(act.area, statelist[now].sons[i].area, args.sgm1)\n\t                sid = statelist[now].sons[i].stateid\n\t                newstate.w = newstate.w + statelist[sid].n * KAB\n\t                newstate.q = newstate.q + statelist[sid].sumq * KAB\n\t        if (opt == 1):\n\t            if (act.u < 0): newstate = State(p, e, 2, fa = now, eid = 0)\n\t            else: newstate = State(p, e, 1, fa = now, elist = elist)\n\t        if (opt == 2): \n\t            newstate = State(p, e, 2, fa = now, eid = act.eid + 1)\n\t        statelist.append(newstate)\n", "        statelist[now].sons[sonid].stateid = len(statelist) - 1\n\t        now = len(statelist) - 1\n\t    return now, p, e, elist\n\tdef defaultpolicy(stateid, p, e, elist):\n\t    opt = statelist[stateid].opt\n\t    if (opt == 0):\n\t        while (len(p) < args.maxp):\n\t            p.append(Point(Vector3(getrand(minx, maxx), getrand(miny, maxy), getrand(minz, maxz))))\n\t        opt = 1\n\t    if (opt == 1):\n", "        for i in range(len(e)):\n\t            area, d = max_can_add_area(e[i], p, e[0 : i])\n\t            if (args.env_mode == 'DT'):\n\t                can_id = 0\n\t                while (can_id < len(arealist) - 1 and arealist[can_id + 1][4] <= d): can_id += 1\n\t                area_random = arealist[random.randint(0, can_id)]\n\t                e[i].d = area_random[4]\n\t                e[i].t = area_random[5]\n\t            else: e[i]._area = getrand(minarea, area)\n\t        el = []\n", "        for i in elist: el.append(i)\n\t        if (len(el) == 0 and len(e) == 0):\n\t            for i in range(len(p)):\n\t                for j in range(i + 1, len(p)):\n\t                    if (p[i].isSupport and p[j].isSupport): continue\n\t                    if (not inlen(p[i], p[j])): continue\n\t                    el.append((i, j))\n\t        random.shuffle(el)\n\t        ret = -1\n\t        for i in range(len(el)):\n", "            probnow = random.random()\n\t            if (probnow > args.prob): continue\n\t            u = el[i][0]\n\t            v = el[i][1]\n\t            if (args.env_mode == 'DT'): \n\t                area = 1.0\n\t                area_random = arealist[random.randint(0, len(arealist) - 1)]\n\t                d, t = area_random[4], area_random[5]\n\t            elif (args.env_mode == 'Area'):\n\t                area = getrand(minarea, maxarea)\n", "                d, t = None, None\n\t            if (canadd(u, v, p, e, area, d, t)):\n\t                e.append(Bar(u, v, leng = getlen2(p[u], p[v]), area = area, d = d, t = t))\n\t                ret = soft_reward(reward_fun(p, e), p, e)\n\t                if (ret > 1e-7): return ret\n\t        return ret\n\t    if (opt == 2):\n\t        for i in range(statelist[stateid].eid, len(e)):\n\t            area, d = max_can_add_area(e[i], p, e[0 : i])\n\t            if (args.env_mode == 'DT'):\n", "                can_id = 0\n\t                while (can_id < len(arealist) - 1 and arealist[can_id + 1][4] <= d): can_id += 1\n\t                area_random = arealist[random.randint(0, can_id)]\n\t                e[i].d = area_random[4]\n\t                e[i].t = area_random[5]\n\t            else: e[i]._area = getrand(minarea, area)\n\t        ret = soft_reward(reward_fun(p, e), p, e)\n\t        return ret\n\t    assert(False)\n\tdef backup(now, delta, root):\n", "    fa = statelist[now].fa\n\t    while (True):\n\t        statelist[now].n = statelist[now].n + 1\n\t        statelist[now].sumq = statelist[now].sumq + delta\n\t        if (statelist[now].mq < delta):\n\t            statelist[now].mq = delta\n\t        if (now == root): break\n\t        if (statelist[fa].opt == 1 or statelist[fa].opt == 2):\n\t            statelist[now].q = statelist[now].q + delta\n\t        elif (statelist[fa].opt == 0):  \n", "            sonid = -1\n\t            for i in range(len(statelist[fa].sons)):\n\t                if (statelist[fa].sons[i].stateid == now):\n\t                    sonid = i\n\t                    break\n\t            assert(sonid != -1)\n\t            vec0 = statelist[fa].sons[sonid].vec\n\t            for i in range(len(statelist[fa].sons)):\n\t                KAB = Kernel2(vec0, statelist[fa].sons[i].vec, args.sgm2)\n\t                sid = statelist[fa].sons[i].stateid\n", "                statelist[sid].w = statelist[sid].w + KAB\n\t                statelist[sid].q = statelist[sid].q + KAB * delta\n\t                statelist[fa].sumw = statelist[fa].sumw + KAB\n\t        now = fa\n\t        fa = statelist[now].fa\n\tdef UCTSearch(p, e):\n\t    global statelist\n\t    global bestreward\n\t    global tmpbestreward\n\t    global elist\n", "    global global_iteration\n\t    elist = set()\n\t    statelist = []\n\t    step_node = 1\n\t    opt = 0\n\t    eidnow = 0\n\t    maxiter = args.UCT_maxiter\n\t    root = 0\n\t    while (not (opt == 2 and eidnow >= len(e))):\n\t        statelist.clear()\n", "        tmpbestreward = 1e9\n\t        tmpbestreward2 = 1e9\n\t        root = 0\n\t        if (opt == 0):\n\t            statelist.append(State(p, e, 0, -1))\n\t            if (len(pbest) > len(p)):\n\t                statelist[root].sons.append(Action(0, vec = pbest[len(p)].vec))\n\t        if (opt == 1):\n\t            statelist.append(State(p, e, 1, -1, elist = elist))\n\t        if (opt == 2):\n", "            statelist.append(State(p, e, 2, -1, eid = eidnow))\n\t        extra_iter = 0\n\t        if (opt == 0): extra_iter = args.UCT_extra_iter_for_point_pos\n\t        for iter in range(maxiter + extra_iter):\n\t            tmp, ptmp, etmp, elisttmp = treepolicy(root, p, e, elist)\n\t            delta = defaultpolicy(tmp, ptmp, etmp, elisttmp)\n\t            backup(tmp, delta, root)\n\t            if (iter % 200 == 0):\n\t                tmpbestreward2 = min(tmpbestreward2, tmpbestreward)\n\t                print(global_iteration + iter, iter, bestreward, tmpbestreward2, tmpbestreward, len(statelist[root].sons))\n", "                print(global_iteration + iter, iter, bestreward, tmpbestreward2, tmpbestreward, len(statelist[root].sons), file = logfile)\n\t                tmpbestreward = 1e9\n\t        global_iteration += maxiter + extra_iter\n\t        if (opt == 0):\n\t            act = Action(0, vec = pbest[len(p)].vec)\n\t            # for SaveKR:\n\t            if args.save_KR == True:\n\t                KR_plist_x = []\n\t                KR_plist_y = []\n\t                KR_plist_z = []\n", "                print(len(p)+1,\"*****************************************\")\n\t#                print(len(p)+1,\"*****************************************\", file = LOG_result)\n\t                for ii in range(len(statelist[root].sons)):\n\t                    KR_plist_x.append(statelist[root].sons[ii].vec.x)\n\t                    KR_plist_y.append(statelist[root].sons[ii].vec.y)\n\t                    KR_plist_z.append(statelist[root].sons[ii].vec.z)\n\t                    print(ii,statelist[root].sons[ii].vec.x, statelist[root].sons[ii].vec.y, statelist[root].sons[ii].vec.z)\n\t#                    print(ii,statelist[root].sons[ii].vec.x, statelist[root].sons[ii].vec.y, statelist[root].sons[ii].vec.z, file = LOG_result)\n\t                print(len(p)+1,\"*****************************************\")\n\t#                print(len(p)+1,\"*****************************************\", file = LOG_result)\n", "                X1=np.ones(len(KR_plist_x))\n\t                Y1=np.ones(len(KR_plist_x))\n\t                Z1=np.ones(len(KR_plist_x))\n\t                fig1 = plt.figure()\n\t                ax1 = plt.axes(projection='3d')\n\t                for i in range(len(KR_plist_x)):\n\t                    ax1.scatter3D([KR_plist_x[i]], [KR_plist_y[i]], [KR_plist_z[i]], color='b')\n\t                    X1[i] = KR_plist_x[i]\n\t                    Y1[i] = KR_plist_y[i]\n\t                    Z1[i] = KR_plist_z[i]\n", "                # Create cubic bounding box to simulate equal aspect ratio\n\t                max_range = np.array([X1.max()-X1.min(), Y1.max()-Y1.min(), Z1.max()-Z1.min()]).max()\n\t                Xb1 = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(X1.max()+X1.min())\n\t                Yb1 = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(Y1.max()+Y1.min())\n\t                Zb1 = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(Z1.max()+Z1.min())\n\t                # Comment or uncomment following both lines to test the fake bounding box:\n\t                for xb1, yb1, zb1 in zip(Xb1, Yb1, Zb1):\n\t                    ax1.plot([xb1], [yb1], [zb1], 'w')\n\t                # plt.scatter(KR_plist_x, KR_plist_y, color='b')\n\t                # plt.axis(\"equal\")\n", "                inputname = FILENAME.replace(\".txt\",\"_\")\n\t                FILENAME_add_node_jpg = \"./results/\" + time_str + \"_\" + str(args.maxp) + \"p_\" + inputname + \"add-node-\"+str(step_node) + \".jpg\"\n\t                plt.savefig(FILENAME_add_node_jpg, dpi = 1000)\n\t                plt.close()\n\t                step_node = step_node + 1\n\t                print(len(KR_plist_x))\n\t        if (opt == 1):\n\t            if (len(e) == len(ebest)): act = Action(1)\n\t            else: act = Action(1, u = ebest[len(e)].u, v = ebest[len(e)].v)\n\t        if (opt == 2):\n", "            act = Action(2, area = ebest[eidnow].area, \n\t                eid = eidnow,\n\t                d = ebest[eidnow].d, \n\t                t = ebest[eidnow].t\n\t            )\n\t        take_action(p, e, elist, act)\n\t        print(act)\n\t        print(bestreward, tmpbestreward)\n\t        if (opt == 0):\n\t            if (len(p) == args.maxp): opt = 1\n", "        elif (opt == 1):\n\t            if (act.u == -1): opt = 2\n\t        elif (opt == 2):\n\t            eidnow = eidnow + 1\n\t    return bestreward, pbest, ebest"]}
{"filename": "algo/__init__.py", "chunked_list": ["from algo.value_network import Value_Network, Truss_Dataset\n\tfrom algo.UCTs import UCTSearch, UCTs_init"]}
{"filename": "algo/value_network.py", "chunked_list": ["import os, sys, torch\n\timport torch.nn as nn\n\timport numpy as np\n\tfrom tqdm import tqdm\n\tfrom torch.utils.data import Dataset, DataLoader\n\tfrom collections import deque\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom Stage2.models import Transformer_Value_Network, Toy_Value_Network\n\tfrom Stage2.envs.state import State\n", "from utils.utils import readFile, readFilewithload\n\tfrom configs.config import get_base_config, make_config\n\tclass Truss_Dataset(Dataset):\n\t    def __init__(self, storage, scale_value_max = None, max_value = None, \n\t                start_index = None, end_index = None):\n\t        self.storage = storage\n\t        self.scale_value_max = scale_value_max\n\t        self.max_value = max_value     \n\t        self.start_index = start_index\n\t        if (self.start_index == None): self.start_index = 0\n", "        self.end_index = end_index\n\t        if (self.end_index == None): self.end_index = len(self.storage)\n\t    def __getitem__(self, index):\n\t        return self.storage[index + self.start_index]\n\t    def __len__(self):\n\t        return self.end_index - self.start_index\n\t    def collate_fn(self, samples):\n\t        bz = len(samples)\n\t        truss_input = torch.zeros(bz, len(samples[0]['truss_input']))\n\t        truss_valid = torch.zeros(bz, dtype=int)\n", "        truss_value = torch.zeros(bz, len(samples[0]['truss_value']))\n\t        for i in range(len(samples)):\n\t            truss_input[i] = torch.from_numpy(samples[i]['truss_input'])\n\t            truss_valid[i] = torch.from_numpy(samples[i]['truss_valid'])[0]\n\t            if (self.scale_value_max != None):\n\t                truss_value[i] = torch.from_numpy(samples[i]['truss_value'] / self.max_value * self.scale_value_max)\n\t            else:\n\t                truss_value[i] = torch.from_numpy(samples[i]['truss_value'])\n\t        truss_input = truss_input.to('cuda:0')\n\t        truss_valid = truss_valid.to('cuda:0')\n", "        truss_value = truss_value.to('cuda:0')\n\t        return {\n\t            'truss_input' : truss_input,\n\t            'truss_valid' : truss_valid,\n\t            'truss_value' : truss_value\n\t        }\n\tclass Value_Network:\n\t    def __init__(self, args, storage_size = 1000000, batch_size = 32, lr = 1e-3):\n\t        self.value_network = Transformer_Value_Network(args.prev_dims, args.hidden_dims, args.env_dims, args.env_mode, num_node = args.maxp).to('cuda:0')\n\t        #self.value_network = Toy_Value_Network(args.maxp * 3 + args.maxp * (args.maxp - 1) // 2, 2048)\n", "        self.storage_size = storage_size\n\t        self.batch_size = batch_size\n\t        self.storage = deque(maxlen = self.storage_size)\n\t        self.valid_loss_fc = nn.CrossEntropyLoss()\n\t        self.value_loss_fc = nn.MSELoss()\n\t        self.value_loss_alpha = 1\n\t        self.lr = lr\n\t        self.max_value = -1\n\t        self.valid_count = 0\n\t        self.invalid_count = 0\n", "        self.save_model_path = os.path.join(args.save_model_path, args.run_id)\n\t    def pred(self, input):\n\t        self.value_network.eval()\n\t        return self.value_network(input)\n\t    def one_dim_presentation(self, points, edges, block_rate = 0):\n\t        r'''\n\t        block_rate: how much of the Edges will be remove.\n\t        '''\n\t        state = State(args.maxp, args.env_dims, args.env_mode)\n\t        for i in range(args.maxp):\n", "            state.nodes[i][0] = points[i].vec.x\n\t            state.nodes[i][1] = points[i].vec.y\n\t            if args.env_dims == 3:\n\t                state.nodes[i][2] = points[i].vec.z\n\t        for e in edges:\n\t            if (np.random.random() > block_rate):\n\t                i, j = e.u, e.v\n\t                if (args.env_mode == 'Area'):\n\t                    state.edges[i][j] = e.area\n\t                    state.edges[j][i] = e.area\n", "                if (args.env_mode == 'DT'):\n\t                    state.edges[i][j][0] = e.d\n\t                    state.edges[j][i][0] = e.d\n\t                    state.edges[i][j][1] = e.t\n\t                    state.edges[j][i][1] = e.t\n\t        return state\n\t    def upd_from_storage(self, steps = 50000, scale_value_max = 10, train_ratio = 0.8):\n\t        num_train_data = int(train_ratio * len(self.storage) + 0.5)\n\t        choose = np.arange(len(self.storage))\n\t        np.random.shuffle(choose)\n", "        training_storage = [self.storage[choose[i]] for i in range(num_train_data)]\n\t        valid_storage = [self.storage[choose[i]] for i in range(num_train_data, len(self.storage))]\n\t        train_dataset = Truss_Dataset(training_storage, scale_value_max = scale_value_max, max_value = self.max_value)\n\t        train_dataloader = DataLoader(train_dataset, collate_fn=train_dataset.collate_fn, batch_size = self.batch_size, shuffle = True)\n\t        optimizer = torch.optim.Adam(self.value_network.parameters(), lr = self.lr)\n\t        current_step = 0\n\t        current_epoch = 0\n\t        min_valid_loss = 1e9\n\t        while (current_step < steps):\n\t            train_losses_valid = []\n", "            train_losses_value = []   \n\t            with tqdm(train_dataloader, desc = \"training\") as pbar:\n\t              self.value_network.train()\n\t              for samples in pbar:\n\t                ### Training ###\n\t                optimizer.zero_grad()\n\t                valid_pred, value_pred = self.value_network(samples['truss_input'])\n\t                value_pred[samples['truss_valid'] == 0] = 0\n\t                loss_valid = self.valid_loss_fc(valid_pred, samples['truss_valid'])\n\t                loss_value = self.value_loss_fc(value_pred, samples['truss_value'])\n", "                #print(loss_valid, loss_value)\n\t                loss = loss_valid + self.value_loss_alpha * loss_value\n\t                loss.backward()\n\t                optimizer.step()\n\t                ### Logging ###\n\t                train_losses_valid.append(loss_valid.item())\n\t                train_losses_value.append(loss_value.item())\n\t                current_step += 1\n\t                if (current_step >= steps): break\n\t                pbar.set_description(\"Epoch: %d, losses_valid: %0.8f, losses_value: %0.8f, lr: %0.6f\" %\n", "                                     (current_epoch + 1, np.mean(train_losses_valid), np.mean(train_losses_value),\n\t                                      optimizer.param_groups[0]['lr']))\n\t            current_epoch += 1\n\t            print('##### epoch.{} #####'.format(current_epoch))\n\t            print('train_loss_valid:', np.mean(train_losses_valid))\n\t            print('train_loss_value:', np.mean(train_losses_value))\n\t            now_valid_loss = self.eval_storage(valid_storage, descending = 'valid')\n\t            if (now_valid_loss < min_valid_loss):\n\t                self.save_model(\"value_network_best.pt\")\n\t                min_valid_loss = now_valid_loss\n", "            self.save_model(\"value_network_{}.pt\".format(current_epoch))\n\t            print('min_valid_loss:', min_valid_loss)\n\t            print('now_valid_loss:', now_valid_loss)\n\t            print(\"#\" * 19)\n\t    def eval_storage(self, eval_storage = None, scale_value_max = 10, descending = 'eval'):\n\t        r'''\n\t        evaluate the value network in a given storage\n\t        '''\n\t        if (eval_storage == None): eval_storage = self.storage\n\t        eval_dataset = Truss_Dataset(eval_storage, scale_value_max = scale_value_max, max_value = self.max_value)\n", "        eval_dataloader = DataLoader(eval_dataset, collate_fn=eval_dataset.collate_fn, batch_size = self.batch_size, shuffle = True)\n\t        eval_losses_valid = []\n\t        eval_losses_value = []\n\t        correct_pred_num = 0\n\t        total_pred_num = 0\n\t        with tqdm(eval_dataloader, desc = descending) as pbar:\n\t              self.value_network.eval()  \n\t              for samples in pbar:\n\t                ### validing ###\n\t                with torch.no_grad():\n", "                    valid_pred, value_pred = self.value_network(samples['truss_input'])\n\t                    value_pred[samples['truss_valid'] == 0] = 0\n\t                    loss_valid = self.valid_loss_fc(valid_pred, samples['truss_valid'])\n\t                    loss_value = self.value_loss_fc(value_pred, samples['truss_value'])\n\t                    valid_pred_label = torch.argmax(valid_pred, dim = -1, keepdim = False)\n\t                    correct_pred_num += torch.sum(valid_pred_label == samples['truss_valid']).item()\n\t                    total_pred_num += valid_pred_label.shape[0]\n\t                ### Logging ###\n\t                eval_losses_valid.append(loss_valid.item())\n\t                eval_losses_value.append(loss_value.item())\n", "                pbar.set_description(\"losses_eval: %0.8f, losses_eval: %0.8f\" %\n\t                                     (np.mean(eval_losses_valid), np.mean(eval_losses_value)))\n\t        now_eval_loss = np.mean(eval_losses_valid) + self.value_loss_alpha * np.mean(eval_losses_value)\n\t        print('{}_loss_valid:'.format(descending), np.mean(eval_losses_valid))\n\t        print('{}_loss_value:'.format(descending), np.mean(eval_losses_value))\n\t        print(\"predict ratio:\", correct_pred_num / total_pred_num, correct_pred_num, '/', total_pred_num)\n\t        return now_eval_loss\n\t    def upd_storage(self, data):\n\t        self.storage.append(data)\n\t    def init_storage(self, data_path, invalid_data_path = None, threshold = None, copy_num = 1, invalid_copy_num = 1, clear = False):\n", "        r'''\n\t        threshold: only use the data with value smaller than the threshold\n\t        copy_num: remove some Edges in the Truss; \n\t                  set to 1 means no remove\n\t        '''\n\t        if (clear): \n\t            self.storage.clear()\n\t            self.valid_count = self.invalid_count = 0\n\t        files = os.listdir(data_path)\n\t        if (files[0][:-4] == '.txt'):\n", "            files.sort(key = lambda x: int(x[:-4]))\n\t        else: files.sort()\n\t        for file in files:\n\t            if (not(threshold == None or int(file[:-4]) <= threshold)): continue\n\t            points, edges, load = readFilewithload(data_path + file)\n\t            load = np.array(load)\n\t            for i in range(copy_num):\n\t                if (i == 0): state = self.one_dim_presentation(points, edges)\n\t                else: state = self.one_dim_presentation(points, edges, block_rate = np.random.random())\n\t                data = {\n", "                    'truss_input' : np.concatenate([state.obs(nonexistent_edge = 0), load]),\n\t                    'truss_valid' : np.array([1]),\n\t                    'truss_value' : np.array([int(file[:-4])])\n\t                }\n\t                self.max_value = max(self.max_value, int(file[:-4]))\n\t                self.valid_count += 1\n\t                self.storage.append(data)\n\t        if (invalid_data_path != None):\n\t            files = os.listdir(invalid_data_path)\n\t            for file in files:\n", "                points, edges, load = readFilewithload(invalid_data_path + file)\n\t                load = np.array(load)\n\t                for i in range(invalid_copy_num):\n\t                    if (i == 0): state = self.one_dim_presentation(points, edges)\n\t                    else: state = self.one_dim_presentation(points, edges, block_rate = np.random.random())\n\t                    data = {\n\t                        'truss_input' : np.concatenate([state.obs(nonexistent_edge = 0), load]),\n\t                        'truss_valid' : np.array([0]),\n\t                        'truss_value' : np.array([0])\n\t                    }\n", "                    self.invalid_count += 1\n\t                    self.storage.append(data)\n\t        print(self.valid_count, self.invalid_count)\n\t    def save_model(self, network_name = 'value_network.pt'):\n\t        if (not os.path.exists(self.save_model_path)):\n\t            os.mkdir(self.save_model_path)\n\t        torch.save(self.value_network, os.path.join(self.save_model_path, network_name))\n\t    def load_model(self, model_load_path = None):\n\t        if (model_load_path == None): model_load_path = os.path.join(self.save_model_path, \"value_network_best.pt\")\n\t        self.value_network = torch.load(model_load_path)\n", "        print(\"load from\", model_load_path)\n\tif __name__ == '__main__':\n\t    parser = get_base_config()\n\t    args = parser.parse_known_args(sys.argv[1:])[0]\n\t    config = make_config(args.config)\n\t    for k, v in config.get(\"base\", {}).items():\n\t        if f\"--{k}\" not in args:\n\t            setattr(args, k, v)\n\t    Value_Net = Value_Network(args, batch_size = 32)\n\t    Value_Net.init_storage(data_path = './results_3d/without_buckle_case1/buckle_fixed0/MASS_ALL_Result/', invalid_data_path = './results_3d/without_buckle_case1/buckle_fixed0/invalid/', copy_num = 10, invalid_copy_num = 1)\n", "    Value_Net.upd_from_storage()\n\t    Value_Net.eval_storage()\n\t    #print(len(Value_Net.storage))"]}
{"filename": "algo/rl_algo.py", "chunked_list": ["import numpy as np\n\timport warnings\n\timport abc\n\timport gtimer as gt\n\tfrom rlkit.data_management.env_replay_buffer import EnvReplayBuffer\n\tfrom rlkit.data_management.replay_buffer import ReplayBuffer\n\tfrom rlkit.samplers.data_collector import PathCollector\n\tfrom rlkit.core import logger, eval_util\n\tfrom rlkit.samplers.data_collector import DataCollector\n\tclass NewBaseRLAlgorithm(object, metaclass=abc.ABCMeta):\n", "    def __init__(\n\t            self,\n\t            trainer,\n\t            exploration_env,\n\t            evaluation_env,\n\t            exploration_data_collector: DataCollector,\n\t            evaluation_data_collector: DataCollector,\n\t            replay_buffer: ReplayBuffer,\n\t    ):\n\t        self.trainer = trainer\n", "        self.expl_env = exploration_env\n\t        self.eval_env = evaluation_env\n\t        self.expl_data_collector = exploration_data_collector\n\t        self.eval_data_collector = evaluation_data_collector\n\t        self.replay_buffer = replay_buffer\n\t        self._start_epoch = 0\n\t        self.post_epoch_funcs = []\n\t    def train(self, start_epoch=0):\n\t        self._start_epoch = start_epoch\n\t        self._train()\n", "    def _train(self):\n\t        \"\"\"\n\t        Train model.\n\t        \"\"\"\n\t        raise NotImplementedError('_train must implemented by inherited class')\n\t    def _begin_epoch(self, epoch):\n\t        pass\n\t    def _end_epoch(self, epoch):\n\t        snapshot = self._get_snapshot()\n\t        logger.save_itr_params(epoch, snapshot)\n", "        gt.stamp('saving')\n\t        self._log_stats(epoch)\n\t        self.expl_data_collector.end_epoch(epoch)\n\t        self.eval_data_collector.end_epoch(epoch)\n\t        self.replay_buffer.end_epoch(epoch)\n\t        self.trainer.end_epoch(epoch)\n\t        for post_epoch_func in self.post_epoch_funcs:\n\t            post_epoch_func(self, epoch)\n\t    def _get_snapshot(self):\n\t        snapshot = {}\n", "        for k, v in self.trainer.get_snapshot().items():\n\t            snapshot['trainer/' + k] = v\n\t        for k, v in self.expl_data_collector.get_snapshot().items():\n\t            snapshot['exploration/' + k] = v\n\t        for k, v in self.eval_data_collector.get_snapshot().items():\n\t            snapshot['evaluation/' + k] = v\n\t        for k, v in self.replay_buffer.get_snapshot().items():\n\t            snapshot['replay_buffer/' + k] = v\n\t        return snapshot\n\t    def _log_stats(self, epoch):\n", "        logger.log(\"Epoch {} finished\".format(epoch), with_timestamp=True)\n\t        logger.record_dict({\"epoch\": epoch})\n\t        \"\"\"\n\t        Replay Buffer\n\t        \"\"\"\n\t        logger.record_dict(\n\t            self.replay_buffer.get_diagnostics(),\n\t            prefix='replay_buffer/'\n\t        )\n\t        \"\"\"\n", "        Trainer\n\t        \"\"\"\n\t        logger.record_dict(self.trainer.get_diagnostics(), prefix='trainer/')\n\t        \"\"\"\n\t        Exploration\n\t        \"\"\"\n\t        logger.record_dict(\n\t            self.expl_data_collector.get_diagnostics(),\n\t            prefix='expl/'\n\t        )\n", "        expl_paths = self.expl_data_collector.get_epoch_paths()\n\t        if hasattr(self.expl_env, 'get_diagnostics'):\n\t            logger.record_dict(\n\t                self.expl_env.get_diagnostics(expl_paths),\n\t                prefix='expl/',\n\t            )\n\t        logger.record_dict(\n\t            eval_util.get_generic_path_information(expl_paths),\n\t            prefix=\"expl/\",\n\t        )\n", "        \"\"\"\n\t        Evaluation\n\t        \"\"\"\n\t        logger.record_dict(\n\t            self.eval_data_collector.get_diagnostics(),\n\t            prefix='eval/',\n\t        )\n\t        eval_paths = self.eval_data_collector.get_epoch_paths()\n\t        if hasattr(self.eval_env, 'get_diagnostics'):\n\t            logger.record_dict(\n", "                self.eval_env.get_diagnostics(eval_paths),\n\t                prefix='eval/',\n\t            )\n\t        logger.record_dict(\n\t            eval_util.get_generic_path_information(eval_paths),\n\t            prefix=\"eval/\",\n\t        )\n\t        \"\"\"\n\t        Misc\n\t        \"\"\"\n", "        gt.stamp('logging')\n\t        logger.record_dict(_get_epoch_timings())\n\t        logger.record_tabular('Epoch', epoch)\n\t        logger.dump_tabular(with_prefix=False, with_timestamp=False)\n\t    @abc.abstractmethod\n\t    def training_mode(self, mode):\n\t        \"\"\"\n\t        Set training mode to `mode`.\n\t        :param mode: If True, training will happen (e.g. set the dropout\n\t        probabilities to not all ones).\n", "        \"\"\"\n\t        pass\n\tclass NewBatchRLAlgorithm(NewBaseRLAlgorithm, metaclass=abc.ABCMeta):\n\t    def __init__(\n\t            self,\n\t            trainer,\n\t            exploration_env,\n\t            evaluation_env,\n\t            exploration_data_collector: PathCollector,\n\t            evaluation_data_collector: PathCollector,\n", "            replay_buffer: ReplayBuffer,\n\t            batch_size,\n\t            max_path_length,\n\t            num_epochs,\n\t            num_eval_steps_per_epoch,\n\t            num_expl_steps_per_train_loop,\n\t            num_trains_per_train_loop,\n\t            num_train_loops_per_epoch=1,\n\t            min_num_steps_before_training=0,\n\t            start_epoch=0, # negative epochs are offline, positive epochs are online\n", "    ):\n\t        super().__init__(\n\t            trainer,\n\t            exploration_env,\n\t            evaluation_env,\n\t            exploration_data_collector,\n\t            evaluation_data_collector,\n\t            replay_buffer,\n\t        )\n\t        self.batch_size = batch_size\n", "        self.max_path_length = max_path_length\n\t        self.num_epochs = num_epochs\n\t        self.num_eval_steps_per_epoch = num_eval_steps_per_epoch\n\t        self.num_trains_per_train_loop = num_trains_per_train_loop\n\t        self.num_train_loops_per_epoch = num_train_loops_per_epoch\n\t        self.num_expl_steps_per_train_loop = num_expl_steps_per_train_loop\n\t        self.min_num_steps_before_training = min_num_steps_before_training\n\t        self._start_epoch = start_epoch\n\t        gt.reset_root()\n\t    def train(self):\n", "        \"\"\"Negative epochs are offline, positive epochs are online\"\"\"\n\t        for self.epoch in gt.timed_for(\n\t                range(self._start_epoch, self.num_epochs),\n\t                save_itrs=True,\n\t        ):\n\t            self.offline_rl = self.epoch < 0\n\t            self._begin_epoch(self.epoch)\n\t            self._train()\n\t            self._end_epoch(self.epoch)\n\t    def _train(self):\n", "        if self.epoch == 0 and self.min_num_steps_before_training > 0:\n\t            init_expl_paths = self.expl_data_collector.collect_new_paths(\n\t                self.max_path_length,\n\t                self.min_num_steps_before_training,\n\t                discard_incomplete_paths=False,\n\t            )\n\t            if not self.offline_rl:\n\t                self.replay_buffer.add_paths(init_expl_paths)\n\t            self.expl_data_collector.end_epoch(-1)\n\t        self.eval_data_collector.collect_new_paths(\n", "            self.max_path_length,\n\t            self.num_eval_steps_per_epoch,\n\t            discard_incomplete_paths=True,\n\t        )\n\t        gt.stamp('evaluation sampling')\n\t        for _ in range(self.num_train_loops_per_epoch):\n\t            new_expl_paths = self.expl_data_collector.collect_new_paths(\n\t                self.max_path_length,\n\t                self.num_expl_steps_per_train_loop,\n\t                discard_incomplete_paths=False,\n", "            )\n\t            gt.stamp('exploration sampling', unique=False)\n\t            if not self.offline_rl:\n\t                self.replay_buffer.add_paths(new_expl_paths)\n\t            gt.stamp('data storing', unique=False)\n\t            self.training_mode(True)\n\t            for _ in range(self.num_trains_per_train_loop):\n\t                train_data = self.replay_buffer.random_batch(self.batch_size)\n\t                self.trainer.train(train_data)\n\t            gt.stamp('training', unique=False)\n", "            self.training_mode(False)\n\tclass NewTorchBatchRLAlgorithm(NewBatchRLAlgorithm):\n\t    def to(self, device):\n\t        for net in self.trainer.networks:\n\t            net.to(device)\n\t    def training_mode(self, mode):\n\t        for net in self.trainer.networks:\n\t            net.train(mode)\n\tclass SizeEnvReplayBuffer(EnvReplayBuffer):\n\t    def __init__(self, *args, **kwargs):\n", "        super().__init__(*args, **kwargs)\n\t    def random_batch(self, batch_size):\n\t        indices = np.random.choice(self._size, size=batch_size, replace=self._replace or self._size < batch_size)\n\t        if not self._replace and self._size < batch_size:\n\t            warnings.warn('Replace was set to false, but is temporarily set to true because batch size is larger than current size of replay.')\n\t        batch = dict(\n\t            observations=self._observations[indices],\n\t            actions=self._actions[indices],\n\t            rewards=self._rewards[indices],\n\t            terminals=self._terminals[indices],\n", "            next_observations=self._next_obs[indices],\n\t        )\n\t        for key in self._env_info_keys:\n\t            assert key not in batch.keys()\n\t            batch[key] = self._env_infos[key][indices]\n\t        return batch"]}
{"filename": "apps/wandb_record.py", "chunked_list": ["import matplotlib.pyplot as plt\n\timport wandb\n\timport numpy as np\n\timport sys, os\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import get_base_config, make_config\n\tfrom utils.utils import *\n\tif __name__ == '__main__':\n\t    parser = get_base_config()\n", "    args = parser.parse_known_args(sys.argv[1:])[0]\n\t    from truss_envs.reward import Envs_init, reward_fun\n\t    config = make_config(args.config)\n\t    for k, v in config.get(\"base\", {}).items():\n\t        if f\"--{k}\" not in args:\n\t            setattr(args, k, v)\n\t    Envs_init(args)\n\t    run_dir = os.path.join(args.save_path, args.run_id)\n\t    wandb.init(\n\t        config = args,\n", "        project = 'Truss_plot_fixed',\n\t        group = args.config,\n\t        dir = run_dir,\n\t        job_type = 'check',\n\t        name = args.config + args.run_id\n\t    )\n\t    Envs_init(args)\n\t    log_file1 = np.loadtxt(os.path.join(args.save_path, args.run_id, args.logfile_stage1))\n\t    print(log_file1.shape)\n\t    log_file2 = np.loadtxt(os.path.join(args.input_path_2, args.run_id, args.logfile_stage2))\n", "    begin_index = 0\n\t    while (log_file1[begin_index][2] > 1000000): begin_index += 1\n\t    for i in range(0, begin_index):\n\t        wandb.log({'mass_stage1': log_file1[begin_index][2], \n\t            'mass_stage2': log_file2[i][1]}, \n\t        step = int(log_file2[i][0]))\n\t    for i in range(begin_index, len(log_file1)):\n\t        if (i < len(log_file2)):\n\t            wandb.log({'mass_stage1': log_file1[i][2], \n\t                'mass_stage2': log_file2[i][1]}, step = int(log_file1[i][0]))\n", "        else:\n\t            wandb.log({'mass_stage1': log_file1[i][2]}, step = int(log_file1[i][0]))"]}
{"filename": "apps/discretize.py", "chunked_list": ["import os\n\timport sys\n\timport math\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom utils.utils import *\n\tfrom configs.config import *\n\tparser = get_base_config()\n\targs = parser.parse_known_args(sys.argv[1:])[0]\n\tfrom truss_envs.reward import *\n", "Envs_init(args)\n\tif __name__ == '__main__':\n\t    p = []\n\t    e = []\n\t    alist = []\n\t    AREAFILE = args.Alist_path\n\t    FILENAME = args.check_file\n\t    with open(FILENAME, \"r\") as fle:\n\t        lines = fle.readlines()\n\t        for i in range(len(lines)):\n", "            line = lines[i]\n\t            vec = line.strip().split(' ')\n\t            if (i == 0):\n\t                vn = int(vec[0])\n\t                en = int(vec[1])\n\t            if (1 <= i and i <= vn):\n\t                p.append(Point(Vector3(float(vec[0]), float(vec[1]), float(vec[2])), int(vec[3]), int(vec[4]), int(vec[5]), float(vec[6]), float(vec[7]), float(vec[8])))            \n\t            if (vn + 1 <= i and i <= vn + en):\n\t                if (len(vec) > 3):\n\t                    d = float(vec[3])\n", "                    t = float(vec[4])\n\t                else:\n\t                    d = None\n\t                    t = None\n\t                if (float(vec[2]) < 0): continue\n\t                e.append(Bar(vec[0], vec[1], float(vec[2]), getlen2(p[int(vec[0])], p[int(vec[1])]), d = d, t = t))\n\t    with open(AREAFILE,'r') as ar:\n\t        section_lines = ar.readlines()\n\t        for i in range(len(section_lines)):\n\t            section_line = section_lines[i]\n", "            section_r = section_line.strip().split(' ')\n\t            if (i==0):\n\t                section_num = int(section_r[0])\n\t                continue\n\t            if (i > 0 and i <= section_num):\n\t                name_s = 'd'+str(section_r[0])+'t'+str(int(float(section_r[1])*10))\n\t                d = float(section_r[0])/1000.0\n\t                t = float(section_r[1])/1000.0\n\t                area_s =  math.pi*d**2/4.0 - math.pi*(d-2*t)**2/4.0\n\t                I_s = math.pi*d**4/64.0 - math.pi*(d-2*t)**4/64.0\n", "                i_s = math.sqrt(I_s/area_s)\n\t                alist.append((float(area_s), float(I_s), float(i_s), str(name_s), float(d), float(t)))\n\t    print(reward_fun(p, e))\n\t    for j in range(5):\n\t      for i in range(len(e)):\n\t        minaera = 1e9\n\t        for d_edge in alist:\n\t            e[i] = Bar(e[i].u, e[i].v, leng = getlen2(p[e[i].u], p[e[i].v]), area=d_edge[0], I_s = d_edge[1], i_s = d_edge[2], name_s = d_edge[3], d = d_edge[4], t = d_edge[5])\n\t            if (reward_fun(p, e)[0] > 0 and d_edge[0] < minaera):\n\t                final_edge = d_edge\n", "                minaera = d_edge[0]\n\t        if (minaera == 1e9):\n\t            print('no valid truss')\n\t        e[i] = Bar(e[i].u, e[i].v, leng = getlen2(p[e[i].u], p[e[i].v]), area=final_edge[0], I_s = final_edge[1], i_s = final_edge[2], name_s = final_edge[3], d = final_edge[4], t = final_edge[5])\n\t    print(reward_fun(p, e))\n\t    OUTFILE = 'D' + str(reward_fun(p, e)[0]) + '.txt'\n\t    with open(OUTFILE, \"w\") as f:\n\t        print(len(p), len(e), file=f)\n\t        for i in range(len(p)):\n\t            print(p[i].vec.x, p[i].vec.y, p[i].vec.z, p[i].supportX, p[i].supportY,\n", "                p[i].supportZ, p[i].loadX, p[i].loadY, p[i].loadZ, file=f)\n\t        for i in range(len(e)):\n\t            print(e[i].u, e[i].v, e[i].area, e[i].d, e[i].t, file=f)\n"]}
{"filename": "apps/plot_truss_layout.py", "chunked_list": ["import matplotlib.pyplot as plt\n\timport math, os\n\tclass Vector3:\n\t\tdef __init__(self, x=0.0, y=0.0, z=0.0):\n\t\t\tself.x = float(x)\n\t\t\tself.y = float(y)\n\t\t\tself.z = float(z)\n\t\tdef __add__(self, obj):\n\t\t\treturn Vector3(self.x + obj.x, self.y + obj.y, self.z + obj.z)\n\t\tdef __sub__(self, obj):\n", "\t\treturn Vector3(self.x - obj.x, self.y - obj.y, self.z - obj.z)\n\t\tdef __mul__(self, obj):\n\t\t\tif (type(obj) == Vector3):\n\t\t\t\treturn Vector3(self.y * obj.z - self.z * obj.y, self.z * obj.x - self.x * obj.z,\n\t\t\t\t\t\t\t   self.x * obj.y - self.y * obj.x)\n\t\t\tif (type(obj) == float or type(obj) == int):\n\t\t\t\treturn Vector3(self.x * obj, self.y * obj, self.z * obj)\n\t\t\tassert (False)\n\t\tdef __str__(self):\n\t\t\treturn str('(' + str(self.x) + ', ' + str(self.y) + ', ' + str(self.z) + ')')\n", "\tdef length2(self):\n\t\t\treturn float(self.x * self.x + self.y * self.y + self.z * self.z)\n\t\tdef length(self):\n\t\t\treturn math.sqrt(self.x * self.x + self.y * self.y + self.z * self.z)\n\t\tdef norm(self):\n\t\t\tl = self.length()\n\t\t\treturn Vector3(self.x / l, self.y / l, self.z / l)\n\t\tdef __eq__(self, other):\n\t\t\tassert (type(other) == Vector3)\n\t\t\tif (abs(self.x - other.x) < 1e-8 and abs(self.y - other.y) < 1e-8 and abs(self.z - other.z) < 1e-8):\n", "\t\t\treturn True\n\t\t\telse:\n\t\t\t\treturn False\n\tclass Point:\n\t\tdef __init__(self, vec=Vector3(), supportX=0, supportY=0, supportZ=1, loadX=0.0, loadY=0.0, loadZ=0.0):\n\t\t\tself.vec = vec\n\t\t\tself.supportX = supportX\n\t\t\tself.supportY = supportY\n\t\t\tself.supportZ = supportZ\n\t\t\tself.isSupport = False\n", "\t\t# 2D\n\t\t\tif (supportX == 1 or supportY == 1):\n\t\t\t\tself.isSupport = True\n\t\t\t# #3D\n\t\t\t# if (supportX == 1 or supportY == 1 or supportZ == 1):\n\t\t\t# \tself.isSupport = True\n\t\t\tself.loadX = loadX\n\t\t\tself.loadY = loadY\n\t\t\tself.loadZ = loadZ\n\t\t\tself.isLoad = False\n", "\t\tif (abs(loadX) > 1e-7 or abs(loadY) > 1e-7 or abs(loadZ) > 1e-7):\n\t\t\t\tself.isLoad = True\n\tclass Bar:\n\t\tdef __init__(self, u=-1, v=-1, area=1.0, leng=0.0, inertia=1.0):\n\t\t\tself.u = int(u)\n\t\t\tself.v = int(v)\n\t\t\tself.area = float(area)\n\t\t\tself.force = float(0.0)\n\t\t\tself.len = leng\n\t\t\tself.stress = 0.0\n", "\t\tself.inertia = float(inertia)\n\tclass Load:\n\t\tdef __init__(self, u=-1, fx=0.0, fy=0.0, fz=0.0):\n\t\t\tself.u = int(u)\n\t\t\tself.fx = float(fx)\n\t\t\tself.fy = float(fy)\n\t\t\tself.fz = float(fz)\n\tdef getlen2(u, v):\n\t\treturn math.sqrt((u.vec.x-v.vec.x)**2+(u.vec.y-v.vec.y)**2+(u.vec.z-v.vec.z)**2)\n\tdef readFile(FILENAME):\n", "\tp = []\n\t\te = []\n\t\tpload = []\n\t\twith open(FILENAME, \"r\") as fle:\n\t\t\tlines = fle.readlines()\n\t\t\tfor i in range(len(lines)):\n\t\t\t\tline = lines[i]\n\t\t\t\tvec = line.strip().split(' ')\n\t\t\t\tif (i == 0):\n\t\t\t\t\tvn = int(vec[0])\n", "\t\t\t\ten = int(vec[1])\n\t\t\t\t\tcontinue\n\t\t\t\tif (1 <= i and i <= vn):\n\t\t\t\t\tp.append(Point(Vector3(float(vec[0]), float(vec[1]), float(vec[2])), int(vec[3]), int(vec[4]), int(vec[5]), float(vec[6]), float(vec[7]), float(vec[8])))\n\t\t\t\t\tpload.append(Load(i-1, float(vec[6]), float(vec[7]), float(vec[8])))\n\t\t\t\t\tcontinue\n\t\t\t\tif (vn + 1 <= i and i <= vn + en):\n\t\t\t\t\te.append(Bar(vec[0], vec[1], float(vec[2]), getlen2(p[int(vec[0])], p[int(vec[1])])))\n\t\t\t\t\tcontinue\n\t\treturn p, e, pload\n", "def saveGraph(p, e):\n\t\tfor i in range(len(p)):\n\t\t\tplt.scatter([p[i].vec.x], [p[i].vec.y], color='b')\n\t\tfor i in range(len(e)):\n\t\t\tx0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t\t\ty0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n\t\t\t# plt.scatter(x0, y0, color='b')\n\t\t\t# plt.text((x0[0] + x0[1]) / 2, (y0[0] + y0[1]) / 2, '%.3f'%e[i]['len'], ha = 'center',va = 'bottom',fontsize=7)\n\t\t\t# plt.plot(x0, y0, color='g')\n\t\t\t#if (e[i].stress < 0):\n", "\t\t#\tplt.plot(x0, y0, color='g', linewidth=e[i].area / 0.01)\n\t\t\t#else:\n\t\t\t#\tplt.plot(x0, y0, color='r', linewidth=e[i].area / 0.01)\n\t\t\tif e[i].area != -1:\n\t\t\t\tplt.plot(x0, y0, color='b', linewidth=e[i].area / 0.01)\n\t\t#plt.figure()\n\t\tplt.axis(\"equal\")\n\t\t# FILENAME = \".\\\\\" + str(len(p)) + \"p_case1_\" + str(reward) + \".jpg\"\n\t\tinputname = FILENAME.replace(\".txt\", \"\")\n\t\tFILENAME_jpg = inputname + \".jpg\"\n", "\t# FILENAME = \".\\\\\" + str(len(p)) + \"p_case1_\" + str(round(reward, 2)) + \".jpg\"\n\t\tplt.savefig(FILENAME_jpg, dpi=1000)\n\t\tplt.clf()\n\tif __name__ == '__main__':\n\t\t#FILENAME = '../results/20211107/generate-tg-reward_v2-keep_policy-brute_force-nn-s1ts100-s2ts100-area0.0001x0.02-cdl37x17-1107_mp_7_cdl_37_17/stage_1_best_2822_obs.txt'\n\t\t#FILENAME = '../thu_wsy/truss_refine-master_v2/best_results/2139/2139.txt'\n\t\t#FILENAME = './MasterTransformerEmbedding_v1/ExperiementResult/Max9p_2/2523997.txt'\n\t\t#FILENAME = './AllExperiment/AlphaTrussStage1/6p_2305.txt'\n\t\t#FILENAME = './Stage1/PostResults/Eval_noise/9p_1/'\n\t\t#p, e, pload = readFile(FILENAME)\n", "\t#saveGraph(p, e)\n\t\tFILEfolder = './AllExperiment/Noise/'\n\t\tfilelist = os.listdir(FILEfolder)\n\t\tfor file in filelist:\n\t\t\tif file[-4:] == '.txt':\n\t\t\t\tprint(file)\n\t\t\t\tFILENAME = FILEfolder + file\n\t\t\t\tp, e, pload = readFile(FILENAME)\n\t\t\t\tsaveGraph(p, e)\n"]}
{"filename": "apps/draw_log.py", "chunked_list": ["import matplotlib.pyplot as plt\n\timport numpy as np\n\timport sys, os\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import get_base_config, make_config\n\tfrom utils.utils import *\n\tif __name__ == '__main__':\n\t    parser = get_base_config()\n\t    args = parser.parse_known_args(sys.argv[1:])[0]\n", "    from truss_envs.reward import Envs_init, reward_fun\n\t    config = make_config(args.config)\n\t    for k, v in config.get(\"base\", {}).items():\n\t        if f\"--{k}\" not in args:\n\t            setattr(args, k, v)\n\t    Envs_init(args)\n\t    log_file1 = np.loadtxt(os.path.join(args.save_path, args.run_id, args.logfile_stage1))\n\t    print(log_file1.shape)\n\t    begin_index = 0\n\t    while (log_file1[begin_index][2] > 1000000): begin_index += 1\n", "    plt.plot(log_file1[begin_index:, 0], log_file1[begin_index:, 2])\n\t    plt.savefig(os.path.join(args.save_path, args.run_id, 'graph_stage1.jpg'), dpi = 1000)\n\t    plt.clf()\n\t    log_file2 = np.loadtxt(os.path.join(args.input_path_2, args.run_id, args.logfile_stage2))\n\t    print(log_file2.shape)\n\t    begin_index = 0\n\t    while (log_file2[begin_index][1] > 1000000): begin_index += 1\n\t    plt.plot(log_file2[begin_index:, 0], log_file2[begin_index:, 1])\n\t    plt.savefig(os.path.join(args.save_path, args.run_id, 'graph_stage2.jpg'), dpi = 1000)"]}
{"filename": "apps/diversity_check.py", "chunked_list": ["import matplotlib.pyplot as plt\n\timport numpy as np\n\timport matplotlib.animation as animation\n\timport sys, os\n\timport time\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import get_base_config, make_config\n\tfrom utils.utils import *\n\tfrom truss_envs.reward import reward_fun\n", "#change 3D作图\n\ttime_str = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime()) \n\tif __name__ == '__main__':\n\t    parser = get_base_config()\n\t    args = parser.parse_known_args(sys.argv[1:])[0]\n\t    from truss_envs.reward import Envs_init, reward_fun\n\t    config = make_config(args.config)\n\t    for k, v in config.get(\"base\", {}).items():\n\t        if f\"--{k}\" not in args:\n\t            setattr(args, k, v)\n", "    Envs_init(args)\n\tdef check_diversity_map(truss_list):\n\t    distinct = []\n\t    distinct_count = []\n\t    for truss in truss_list:\n\t        unique = True\n\t        for i in range(len(distinct)):\n\t            ref_truss = distinct[i]\n\t            if (similar_topo(truss[0], truss[1], ref_truss[0], ref_truss[1])):\n\t                unique = False\n", "                distinct_count[i] += 1\n\t                break\n\t        if (unique):\n\t            distinct.append(truss)\n\t            distinct_count.append(1)\n\t    for i in range(len(distinct)):\n\t        distinct[i] = (distinct[i], distinct_count[i])\n\t    distinct.sort(key = lambda x1: x1[1], reverse = True)\n\t    distinct_count.sort(reverse = True)\n\t    return len(distinct), distinct_count, distinct\n", "if __name__ == '__main__':\n\t    check_path = os.path.join(args.save_path, args.run_id, 'DIVERSITY_TOPO_result')\n\t    files = os.listdir(check_path)\n\t    truss_list = []\n\t    for file in files:\n\t        if (file[-4:] == '.txt'):\n\t            p, e = readFile(os.path.join(check_path, file))\n\t            truss_list.append((p, e))\n\t    print(check_diversity_map(truss_list)[0 : 2])\n\t    check_path = os.path.join(args.input_path_2, args.run_id)\n", "    files = os.listdir(check_path)\n\t    truss_list = []\n\t    for file in files:\n\t        if (file[-4:] == '.txt'):\n\t            p, e = readFile(os.path.join(check_path, file))\n\t            truss_list.append((p, e))\n\t    print(check_diversity_map(truss_list)[0 : 2])\n"]}
{"filename": "apps/check.py", "chunked_list": ["import os, sys\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import *\n\tparser = get_base_config()\n\targs = parser.parse_known_args(sys.argv[1:])[0]\n\tfrom collections import OrderedDict\n\tfrom truss_envs.reward import *\n\tfrom utils.utils import *\n\tfrom Stage2.envs.dynamic2 import DynamicModel\n", "Envs_init(args)\n\tFILENAME = args.check_file\n\tp = OrderedDict()\n\te = OrderedDict()\n\twith open(FILENAME, \"r\") as fle:\n\t    lines = fle.readlines()\n\t    edge_cnt = 0\n\t    for i in range(len(lines)):\n\t        line = lines[i]\n\t        vec = line.strip().split(' ')\n", "        if (i == 0):\n\t            vn = int(vec[0])\n\t            en = int(vec[1])\n\t            continue\n\t        if (1 <= i and i <= vn):\n\t            p[i - 1] = Point(Vector3(float(vec[0]), float(vec[1]), float(vec[2])), int(vec[3]), int(vec[4]), int(vec[5]), float(vec[6]), float(vec[7]), float(vec[8]))\n\t        if (vn + 1 <= i and i <= vn + en and float(vec[2]) != -1):\n\t            e[edge_cnt] = Bar(vec[0], vec[1], float(vec[2]), getlen2(p[int(vec[0])], p[int(vec[1])]), d = float(vec[3]), t = float(vec[4]))\n\t            edge_cnt += 1\n\t#print(len(p), len(e))\n", "model = DynamicModel(dimension = 3)\n\tprint(model.run(p, e, mode = 'check'))\n\tprint(reward_fun(p, e,sanity_check = False))"]}
{"filename": "apps/eval.py", "chunked_list": ["import matplotlib.pyplot as plt\n\timport numpy as np\n\timport matplotlib.animation as animation\n\timport sys, os\n\timport time\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import get_base_config, make_config\n\tfrom utils.utils import *\n\tfrom truss_envs.reward import reward_fun\n", "#change 3D作图\n\ttime_str = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime()) \n\tif __name__ == '__main__':\n\t    parser = get_base_config()\n\t    args = parser.parse_known_args(sys.argv[1:])[0]\n\t    from truss_envs.reward import Envs_init, reward_fun\n\t    config = make_config(args.config)\n\t    for k, v in config.get(\"base\", {}).items():\n\t        if f\"--{k}\" not in args:\n\t            setattr(args, k, v)\n", "    Envs_init(args)\n\tdef drawGraph(p, e, args, canshow = 1, reward = 0.0, FILENAME = \"output\"):\n\t    print(reward_fun(p, e, mode = 'check'))\n\t    if (reward == 0.0): reward, _, _, _, _, _ = reward_fun(p, e)\n\t    if (args.env_dims == 3):\n\t        fig = plt.figure()\n\t        ax = plt.axes(projection='3d')\n\t        X=np.ones(len(p))\n\t        Y=np.ones(len(p))\n\t        Z=np.ones(len(p))\n", "        def rotate(angle): ax.view_init(azim=angle)\n\t        for i in range(len(p)):\n\t            ax.scatter3D([p[i].vec.x], [p[i].vec.y], [p[i].vec.z], color='b')\n\t            X[i]=p[i].vec.x\n\t            Y[i]=p[i].vec.y\n\t            Z[i]=p[i].vec.z\n\t        for i in range(len(e)):\n\t            x0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t            y0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n\t            z0 = [p[e[i].u].vec.z, p[e[i].v].vec.z]\n", "            if (e[i].area < 0): continue\n\t            if (e[i].stress < 0):\n\t                # ax.plot3D(x0, y0, z0, color='g', linewidth = e[i].area / 0.001)\n\t                ax.plot3D(x0, y0, z0, color='g', linewidth = 1)\n\t            elif (e[i].stress > 0):\n\t                # ax.plot3D(x0, y0, z0, color='r', linewidth = e[i].area / 0.001)\n\t                ax.plot3D(x0, y0, z0, color='r', linewidth = 1)\n\t            else:\n\t                ax.plot3D(x0, y0, z0, color='k', linewidth = 1)\n\t            # scat = ax.scatter(X, Y, Z)\n", "            # Create cubic bounding box to simulate equal aspect ratio\n\t            max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max()\n\t            Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(X.max()+X.min())\n\t            Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(Y.max()+Y.min())\n\t            Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(Z.max()+Z.min())\n\t            # Comment or uncomment following both lines to test the fake bounding box:\n\t            for xb, yb, zb in zip(Xb, Yb, Zb): ax.plot([xb], [yb], [zb], 'w')\n\t        # plt.axis(\"auto\")\n\t        # NotImplementedError: Axes3D currently only supports the aspect argument 'auto'. You passed in 'equal'.\n\t        plt.title(str(reward))\n", "        #plot animation gif\n\t        rot_animation = animation.FuncAnimation(fig, rotate, frames=np.arange(0,362,2),interval=100)\n\t        FILENAME = os.path.join(args.config + \"_\" + str(len(p)) + \"p\" + str(round(reward, 2)) + '_3d' + \".gif\")\n\t        print('Save img to', FILENAME)\n\t        rot_animation.save(FILENAME, dpi=100)\n\t        if (canshow == 1): plt.show()\n\t    elif args.env_dims == 2:\n\t        for i in range(len(e)):\n\t            x0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t            y0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n", "            if (e[i].stress < 0): plt.plot(x0, y0, color='g', linewidth = min(max(e[i].area / 0.005, 2), 6))\n\t            else: plt.plot(x0, y0, color='b', linewidth = min(max(e[i].area / 0.005, 2), 6))\n\t        for i in range(len(p)):\n\t            plt.scatter([p[i].vec.x], [p[i].vec.y], color='b', linewidths = 5)\n\t        plt.axis(\"equal\")\n\t        plt.title(str(reward))\n\t        FILENAME = os.path.join(args.config + \"_\" + str(len(p)) + \"p\" + str(round(reward, 2)) + '_2d' + \".jpg\")\n\t        print('Save img to', FILENAME)\n\t        plt.savefig(FILENAME, dpi = 1000)\n\tdef saveGraph(p, e, reward = 0.0):\n", "    print(reward_fun(p, e))\n\t    if (reward == 0.0): reward, _, _, _, _, _ = reward_fun(p, e, mode = 'check')\n\t    for i in range(len(p)):\n\t        plt.scatter([p[i].vec.x], [p[i].vec.y], color='b')\n\t    for i in range(len(e)):\n\t        x0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t        y0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n\t        if (e[i].stress < 0):\n\t            plt.plot(x0, y0, color='g', linewidth = e[i].area / 0.01)\n\t        else:\n", "            plt.plot(x0, y0, color='r', linewidth = e[i].area / 0.01)\n\t    plt.axis(\"equal\")\n\t    plt.title(str(reward))\n\t    FILENAME = str(args.config) + \"_\" + str(len(p)) + \"p\" + str(round(reward, 2)) + '_2d' + \".jpg\"\n\t    plt.savefig(FILENAME, dpi = 1000)\n\tdef draw2Graph(p1, e1, p2, e2, canshow = 1):\n\t    sub1 = plt.subplot(1, 2, 1)\n\t    sub2 = plt.subplot(1, 2, 2)\n\t    plt.sca(sub1)\n\t    drawGraph(p1, e1, 0)\n", "    plt.sca(sub2)\n\t    drawGraph(p2, e2, 0)\n\t    if (canshow == 1):\n\t        plt.show()\n\tif __name__ == '__main__':\n\t    FILENAME = args.draw_file\n\t    p, e = readFile(FILENAME)\n\t    drawGraph(p, e, args = args)"]}
{"filename": "apps/draw.py", "chunked_list": ["import matplotlib.pyplot as plt\n\timport numpy as np\n\timport matplotlib.animation as animation\n\timport sys, os\n\timport time\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import get_base_config, make_config\n\tfrom utils.utils import *\n\tfrom truss_envs.reward import reward_fun\n", "#change 3D作图\n\ttime_str = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime()) \n\tif __name__ == '__main__':\n\t    parser = get_base_config()\n\t    args = parser.parse_known_args(sys.argv[1:])[0]\n\t    from truss_envs.reward import Envs_init, reward_fun\n\t    config = make_config(args.config)\n\t    for k, v in config.get(\"base\", {}).items():\n\t        if f\"--{k}\" not in args:\n\t            setattr(args, k, v)\n", "    Envs_init(args)\n\tdef drawGraph(p, e, args, canshow = 1, reward = 0.0, FILENAME = \"output\"):\n\t    print(reward_fun(p, e, mode = 'check'))\n\t    if (reward == 0.0): reward, _, _, _, _, _ = reward_fun(p, e)\n\t    if (args.env_dims == 3):\n\t        fig = plt.figure()\n\t        ax = plt.axes(projection='3d')\n\t        X=np.ones(len(p))\n\t        Y=np.ones(len(p))\n\t        Z=np.ones(len(p))\n", "        def rotate(angle): ax.view_init(azim=angle)\n\t        for i in range(len(p)):\n\t            ax.scatter3D([p[i].vec.x], [p[i].vec.y], [p[i].vec.z], color='b')\n\t            X[i]=p[i].vec.x\n\t            Y[i]=p[i].vec.y\n\t            Z[i]=p[i].vec.z\n\t        for i in range(len(e)):\n\t            x0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t            y0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n\t            z0 = [p[e[i].u].vec.z, p[e[i].v].vec.z]\n", "            if (e[i].area < 0): continue\n\t            if (e[i].stress < 0):\n\t                # ax.plot3D(x0, y0, z0, color='g', linewidth = e[i].area / 0.001)\n\t                ax.plot3D(x0, y0, z0, color='g', linewidth = 1)\n\t            elif (e[i].stress > 0):\n\t                # ax.plot3D(x0, y0, z0, color='r', linewidth = e[i].area / 0.001)\n\t                ax.plot3D(x0, y0, z0, color='r', linewidth = 1)\n\t            else:\n\t                ax.plot3D(x0, y0, z0, color='k', linewidth = 1)\n\t            # scat = ax.scatter(X, Y, Z)\n", "            # Create cubic bounding box to simulate equal aspect ratio\n\t            max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max()\n\t            Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(X.max()+X.min())\n\t            Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(Y.max()+Y.min())\n\t            Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(Z.max()+Z.min())\n\t            # Comment or uncomment following both lines to test the fake bounding box:\n\t            for xb, yb, zb in zip(Xb, Yb, Zb): ax.plot([xb], [yb], [zb], 'w')\n\t        # plt.axis(\"auto\")\n\t        # NotImplementedError: Axes3D currently only supports the aspect argument 'auto'. You passed in 'equal'.\n\t        plt.title(str(reward))\n", "        #plot animation gif\n\t        rot_animation = animation.FuncAnimation(fig, rotate, frames=np.arange(0,362,2),interval=100)\n\t        FILENAME = os.path.join(args.save_path, args.run_id, args.config + \"_\" + str(len(p)) + \"p\" + str(round(reward, 2)) + '_3d' + \".gif\")\n\t        print(FILENAME)\n\t        rot_animation.save(FILENAME, dpi=100)\n\t        if (canshow == 1): plt.show()\n\t    elif args.env_dims == 2:\n\t        for i in range(len(e)):\n\t            x0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t            y0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n", "            if (e[i].stress < 0): plt.plot(x0, y0, color='g', linewidth = min(max(e[i].area / 0.005, 2), 6))\n\t            else: plt.plot(x0, y0, color='b', linewidth = min(max(e[i].area / 0.005, 2), 6))\n\t        for i in range(len(p)):\n\t            plt.scatter([p[i].vec.x], [p[i].vec.y], color='b', linewidths = 5)\n\t        plt.axis(\"equal\")\n\t        plt.title(str(reward))\n\t        FILENAME = os.path.join(args.save_path, args.run_id, args.config + \"_\" + str(len(p)) + \"p\" + str(round(reward, 2)) + '_2d' + \".jpg\")\n\t        print(FILENAME)\n\t        plt.savefig(FILENAME, dpi = 1000)\n\tdef saveGraph(p, e, reward = 0.0):\n", "    print(reward_fun(p, e))\n\t    if (reward == 0.0): reward, _, _, _, _, _ = reward_fun(p, e, mode = 'check')\n\t    for i in range(len(p)):\n\t        plt.scatter([p[i].vec.x], [p[i].vec.y], color='b')\n\t    for i in range(len(e)):\n\t        x0 = [p[e[i].u].vec.x, p[e[i].v].vec.x]\n\t        y0 = [p[e[i].u].vec.y, p[e[i].v].vec.y]\n\t        if (e[i].stress < 0):\n\t            plt.plot(x0, y0, color='g', linewidth = e[i].area / 0.01)\n\t        else:\n", "            plt.plot(x0, y0, color='r', linewidth = e[i].area / 0.01)\n\t    plt.axis(\"equal\")\n\t    plt.title(str(reward))\n\t    FILENAME = \"./results_3d/\" + str(args.config) + \"_\" + str(len(p)) + \"p\" + str(round(reward, 2)) + '_2d' + \".jpg\"\n\t    plt.savefig(FILENAME, dpi = 1000)\n\tdef draw2Graph(p1, e1, p2, e2, canshow = 1):\n\t    sub1 = plt.subplot(1, 2, 1)\n\t    sub2 = plt.subplot(1, 2, 2)\n\t    plt.sca(sub1)\n\t    drawGraph(p1, e1, 0)\n", "    plt.sca(sub2)\n\t    drawGraph(p2, e2, 0)\n\t    if (canshow == 1):\n\t        plt.show()\n\tif __name__ == '__main__':\n\t    FILENAME = args.draw_file\n\t    p, e = readFile(FILENAME)\n\t    drawGraph(p, e, args = args)"]}
{"filename": "apps/checker.py", "chunked_list": ["import numpy as np\n\timport math\n\timport os, sys\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\timport openseespy.opensees as op\n\timport matplotlib.pyplot as plt\n\tfrom utils.utils import readFile\n\tclass DynamicModel:\n\t    #构造函数\n", "    def __init__(self,\n\t                dimension,\n\t                E=193*10**9,          #N/m2\n\t                pho=8.0*10**3,        #kg/m3\n\t                sigma_T=123*10**6,    #N/m2\n\t                sigma_C=213*10**6,    #N/m2\n\t                dislimit=0.002,       #m\n\t                slenderness_ratio_T=220,\n\t                slenderness_ratio_C=180,\n\t                max_len=5,            #m\n", "                min_len=0.03,         #m\n\t                use_self_weight=True,\n\t                use_dis_constraint=True,\n\t                use_stress_constraint=True,\n\t                use_buckle_constraint=True,\n\t                use_slenderness_constraint=True,\n\t                use_longer_constraint=True,\n\t                use_shorter_constraint=True\n\t                ): \n\t        self._dimension = dimension    #结构维度\n", "        self._E = E                    #弹性模量\n\t        self._pho = pho                #材料密度\n\t        self._sigma_T = sigma_T        #容许拉应力\n\t        self._sigma_C = sigma_C        #容许压应力\n\t        self._limit_dis = dislimit     #容许位移\n\t        self.slenderness_ratio_T=slenderness_ratio_T #容许受拉长细比\n\t        self.slenderness_ratio_C=slenderness_ratio_C #容许受压长细比\n\t        self.max_len=max_len                         #最大长度\n\t        self.min_len=min_len                         #最小长度\n\t        self._use_self_weight = use_self_weight              #是否计算自重\n", "        self._use_dis_constraint = use_dis_constraint        #是否启用位移约束\n\t        self._use_stress_constraint = use_stress_constraint         #是否启用应力约束\n\t        self._use_buckle_constraint = use_buckle_constraint         #是否启用屈曲约束\n\t        self._use_slenderness_constraint=use_slenderness_constraint #是否启用长细比约束\n\t        self._use_longer_constraint=use_longer_constraint           #是否启用超长约束\n\t        self._use_shorter_constraint=use_shorter_constraint         #是否启用过短约束\n\t    #判定结构的几何不变性+分析计算\n\t    def _is_struct(self, points, edges):\n\t        ########计算自由度初判结构几何不变性##########\n\t        total_support = 0             #保存支座约束数\n", "        for p in points.values():\n\t            if self._dimension == 2:  #平面桁架\n\t                total_support += (\n\t                    p.supportX\n\t                    + p.supportY\n\t                )\n\t            else:                     #空间桁架\n\t                total_support += (\n\t                    p.supportX\n\t                    + p.supportY\n", "                    + p.supportZ\n\t                )\n\t        if len(points) * self._dimension - len(edges) - total_support > 0:\n\t            return (False)   #计算自由度>0，结构不稳定直接返回False\n\t        #######以下基于点和边集建立有限元模形分析########\n\t        op.wipe()   # 清除所有已有结构\n\t        op.model('basic', '-ndm', self._dimension, '-ndf', self._dimension)  #设置建模器\n\t        for i, point in points.items():   #建立节点\n\t            if self._dimension == 2:\n\t                op.node(\n", "                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n\t                )\n\t            else:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n\t                    point.vec.z,\n", "                )\n\t        for i, point in points.items():  #施加节点支座约束\n\t            if point.isSupport:\n\t                if self._dimension == 2:\n\t                    op.fix(\n\t                        i,\n\t                        point.supportX,\n\t                        point.supportY,\n\t                    )\n\t                else:\n", "                    op.fix(\n\t                        i,\n\t                        point.supportX,\n\t                        point.supportY,\n\t                        point.supportZ,\n\t                    )\n\t        op.timeSeries(\"Linear\", 1)\n\t        op.pattern(\"Plain\", 1, 1)\n\t        for i, point in points.items():  #添加节点荷载\n\t            if point.isLoad:\n", "                if self._dimension == 2:\n\t                    op.load(\n\t                        i,\n\t                        point.loadX,\n\t                        point.loadY,\n\t                    )\n\t                else:\n\t                    op.load(\n\t                        i,\n\t                        point.loadX,\n", "                        point.loadY,\n\t                        point.loadZ,\n\t                    )\n\t        op.uniaxialMaterial(\"Elastic\", 1, self._E)   #定义材料\n\t        for i, edge in enumerate(edges.values()):\n\t            op.element(\"Truss\", i, edge.u, edge.v, edge.area, 1)  #赋予杆件截面属性\n\t        if self._use_self_weight:  #如果计算自重时\n\t            gravity = 9.8   #重力加速度\n\t            load_gravity = [0 for _ in range(len(points))]  #初始化了一个load_gravity列表，表征杆件自重的等效结点力，len(points)个元素均为0\n\t            for i, edge in edges.items():\n", "                edge_mass = edge.len * edge.area * self._pho       #每根杆件质量\n\t                load_gravity[edge.u] += edge_mass * gravity * 0.5\n\t                load_gravity[edge.v] += edge_mass * gravity * 0.5  #每根杆件的重力向两端分一半到节点上\n\t            for i in range(len(points)):        #将重力荷载等效施加于节点上\n\t                if self._dimension == 2:        #如果是平面结构\n\t                    op.load(i, 0.0, -1 * load_gravity[i])\n\t                else:                           #如果是空间结构\n\t                    op.load(i, 0.0, 0.0, -1 * load_gravity[i])\t\n\t        op.system(\"BandSPD\")\n\t        op.numberer(\"RCM\")\n", "        op.constraints(\"Plain\")\n\t        op.integrator(\"LoadControl\", 1.0)\n\t        op.algorithm(\"Newton\")\n\t        op.analysis(\"Static\")\n\t        ok = op.analyze(1)  #运行分析，ok表征是否成功运行，返回0代表成功，返回<0失败。（注:这里对结构的几何不变性进行了充分判断）\n\t        if ok < 0:\n\t            ok = False\n\t        else:\n\t            ok = True\n\t        return ok\n", "    #评估节点位移\n\t    def _get_dis_value(self, points):\n\t        displacement_weight = np.zeros((len(points), 1))  #初始化一个0数组，用于存放位移数据\n\t        for i in range(len(points)):\n\t            if self._dimension == 2:\n\t                weight = max(   \n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                )                                  #只考虑x,y,(z)方向上的最大的一个线位移\n\t            else:\n", "                weight = max(\n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                    abs(op.nodeDisp(i, 3)),\n\t                )\n\t            print(\"第{:}结点位移为{:}mm\".format(i,weight*10**3))\n\t            displacement_weight[i] = max(weight / self._limit_dis - 1, 0)  #判定节点位移是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为位移评估参照\n\t        return displacement_weight\n\t    #评估杆件应力\n\t    def _get_stress_value(self, edges):\n", "        stress_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放应力数据\n\t        for tag, i in enumerate(edges.keys()):\n\t            edges[i].force = op.basicForce(tag)   #从有限元得到杆件轴力\n\t            edges[i].stress = edges[i].force[0] / edges[i].area  #根据轴力、截面积求正应力\n\t            print(\"第{:}杆件应力为{:}MPa\".format(i,edges[i].stress*10**(-6)))\n\t            if edges[i].stress < 0:                                  #压杆\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_C - 1.0,\n\t                    0.0\n\t                )\n", "            else:                                                    #拉杆\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_T - 1.0,\n\t                    0.0\n\t                )\n\t        return stress_weight  #判定节点应力是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为应力评估参照\n\t    #评估杆件屈曲\n\t    def _get_buckle_value(self, edges):\n\t        buckle_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放屈曲数据\n\t        miu_buckle = 1.0                           #杆件计算长度系数，桁架两端铰接取1\n", "        for tag, i in enumerate(edges.keys()):\n\t            edges[i].force = op.basicForce(tag)    #存放轴力数据\n\t            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n\t            if edges[i].stress < 0:    #仅压杆才考虑屈曲\n\t                #计算欧拉临界力\n\t                force_cr = (\n\t                    math.pi ** 2 \n\t                    * self._E * edges[i].inertia\n\t                ) / (miu_buckle * edges[i].len) ** 2\n\t                #计算欧拉临界应力\n", "                buckle_stress_max = force_cr / edges[i].area\n\t                buckle_weight[tag] = max(\n\t                    abs(edges[i].stress) / abs(buckle_stress_max) - 1.0,\n\t                    0.0\n\t                )#判定杆件压应力是否超过屈曲临界应力：超出则比例存入数组，否则记为0\n\t        return buckle_weight\n\t    #评估杆件长细比\n\t    def _get_slenderness_ratio(self, edges):\n\t        lambda_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放长细比数据\n\t        for tag, i in enumerate(edges.keys()):\n", "            edges[i].force = op.basicForce(tag)    #存放轴力数据\n\t            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n\t            print(edges[i].len, edges[i].inertia, edges[i].area)\n\t            lambda_weight[tag] = max(\n\t                # self.len/(self.inertia/self.area)**0.5\n\t                abs(edges[i].len / (edges[i].inertia / edges[i].area) ** 0.5) / abs(self.slenderness_ratio_C if edges[i].stress < 0 else self.slenderness_ratio_T) - 1.0,\n\t                0.0\n\t            )#判定杆件长细比是否超过限制：超出则比例存入数组，否则记为0\n\t        return lambda_weight\n\t    #评估杆件超长\n", "    def _get_length_longer(self, edges):\n\t        longer_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放长细比数据\n\t        for tag, i in enumerate(edges.keys()):   \n\t            longer_weight[tag] = max(\n\t                abs(edges[i].len) / abs(self.max_len) - 1.0,\n\t                0.0\n\t            )#判定杆件长度是否超过限制：超出则比例存入数组，否则记为0\n\t        return longer_weight\n\t    #评估杆件超长\n\t    def _get_length_shorter(self, edges):\n", "        shorter_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放长细比数据\n\t        for tag, i in enumerate(edges.keys()):   \n\t            if edges[i].len<self.min_len:\n\t                shorter_weight[tag] = 1.0-edges[i].len / self.min_len\n\t                #判定杆件长度是否过短：超出则比例存入数组，否则记为0\n\t        return shorter_weight\n\t    #调用以上函数运行结构分析\n\t    def run(self, points, edges):\n\t        is_struct = self._is_struct(points, edges) #运行结构建模与分析，is_struct返回结构是否正常完成分析\n\t        mass, dis_value, stress_value, buckle_value, slenderness_vlaue, longer_value, shorter_value= 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n", "        if is_struct: #如果结构成功完成分析，即结构是几何不变的\n\t            for i, edge in edges.items():\n\t                mass += edge.len * edge.area * self._pho      #计算结构总质量\n\t            if self._use_dis_constraint:\n\t                dis_value = self._get_dis_value(points)       #若启用，获取结构位移评估结果\n\t            if self._use_stress_constraint:\n\t                stress_value = self._get_stress_value(edges)  #若启用，获取结构应力评估结果\n\t            if self._use_buckle_constraint:\n\t                buckle_value = self._get_buckle_value(edges)  #若启用，获取结构屈曲评估结果\n\t            if self._use_slenderness_constraint:\n", "                slenderness_vlaue = self._get_slenderness_ratio(edges)  #若启用，获取结构长细比评估结果    \n\t            if self._use_longer_constraint:\n\t                longer_value = self._get_length_longer(edges)  #若启用，获取结构长细比评估结果\n\t            if self._use_shorter_constraint:\n\t                shorter_value = self._get_length_shorter(edges)  #若启用，获取结构长细比评估结果 \n\t        return (\n\t            is_struct, mass, dis_value, stress_value, buckle_value, slenderness_vlaue, longer_value, shorter_value\n\t        )\n\t    #绘制平面桁架\n\t    def render(self, points, edges):\n", "        _ax = plt.axes(projection='3d')\n\t        for point in points.values():   #绘制节点，scatter()绘制散点\n\t            if point.isSupport:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='g') #支座点为绿色\n\t            elif point.isLoad:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='r') #荷载作用的节点为红色\n\t            else:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='b') #其余节点蓝色\n\t        for edge in edges.values():    #绘制杆件\n\t            x0 = [points[edge.u].vec.x, points[edge.v].vec.x]   #杆件起点\n", "            y0 = [points[edge.u].vec.y, points[edge.v].vec.y]   #杆件终点\n\t            z0 = [points[edge.u].vec.z, points[edge.v].vec.z]   #杆件起点\n\t            if edge.stress < -1e-7:\n\t                _ax.plot(x0, y0, z0, color='g', linewidth=(edge.area / math.pi)**0.5*500)    #压杆绿色\n\t            elif edge.stress > 1e-7:\n\t                _ax.plot(x0, y0, z0, color='r', linewidth=(edge.area / math.pi)**0.5*500)    #拉杆红色\n\t            else:\n\t                _ax.plot(x0, y0, z0, color='k', linewidth=(edge.area / math.pi)**0.5*500)    #零杆黑色\n\t        plt.show() #显示图像\n\tif __name__=='__main__':\n", "    truss=DynamicModel(3)    #创建结构对象\n\t    point_list, edge_list = readFile(\"input_file_3d.txt\") #读取数据输入文件中的预设点和边\n\t    #将point_list, edge_list转换成truss.run的数据结构\n\t    points = {}\n\t    edges = {}\n\t    for i, point in enumerate(point_list):  #将预设点对象加入点集\n\t        points[i] = point\n\t    for i, edge in enumerate(edge_list):    #将预设边对象加入边集\n\t        if edge.u > edge.v:                 #边端点重新编号\n\t            tmp = edge.u\n", "            edge.u = edge.v\n\t            edge.v = tmp\n\t        edges[(edge.u, edge.v)] = edge        \n\t    #运行模型分析                                 \n\t    is_struct, mass, dis_value, stress_value, buckle_value, slenderness_vlaue, longer_value, shorter_value  = truss.run(points, edges) \n\t    #后处理，输出结构设计结果的提示信息\n\t    print(np.sum(dis_value), np.sum(stress_value), np.sum(buckle_value), np.sum(slenderness_vlaue), np.sum(longer_value), np.sum(shorter_value))\n\t    if not is_struct:\n\t        print(\"结构几何不稳定\")\n\t    elif np.sum(dis_value) > 0.0 or np.sum(stress_value) > 0.0 or np.sum(buckle_value) > 0.0 or np.sum(slenderness_vlaue) or np.sum(longer_value) or np.sum(shorter_value):\n", "        for i in range(len(dis_value)):\n\t            if dis_value[i]>0.0:\n\t                print(\"第{:}结点位移超出限值{:}%\".format(i,dis_value[i]*100))\n\t        for i in range(len(stress_value)):\n\t            if stress_value[i]>0.0:\n\t                print(\"第{:}杆件应力超出限值{:}%\".format(i,stress_value[i]*100))\n\t        for i in range(len(buckle_value)):\n\t            if buckle_value[i]>0.0:\n\t                print(\"第{:}杆件屈曲应力超出限值{:}%\".format(i,buckle_value[i]*100))\n\t        for i in range(len(slenderness_vlaue)):\n", "            if slenderness_vlaue[i][0]>0.0:\n\t                print(\"第{:}杆件长细比超出限值{:}%\".format(i,slenderness_vlaue[i]*100))\n\t        for i in range(len(longer_value)):\n\t            if longer_value[i]>0.0:\n\t                print(\"第{:}杆件长度超出限值{:}%\".format(i,longer_value[i]*100))\n\t        for i in range(len(shorter_value)):\n\t            if shorter_value[i]>0.0:\n\t                print(\"第{:}杆件长度短过限值{:}%\".format(i,shorter_value[i]*100))                 \n\t    else:\n\t        print(\"结构几何稳定，且所有约束满足。当前结构总质量为：{:.3f}kg\".format(mass))\n", "    truss.render(points, edges) #显示桁架图像\n"]}
{"filename": "apps/checker/结构验算/dynamic.py", "chunked_list": ["import numpy as np\n\timport math\n\timport openseespy.opensees as op\n\timport matplotlib.pyplot as plt\n\tfrom utils import *\n\tclass DynamicModel:\n\t    #构造函数\n\t    def __init__(self,\n\t                dimension,\n\t                E=193*10**9,          #N/m2\n", "                pho=8.0*10**3,        #kg/m3\n\t                sigma_T=123*10**6,    #N/m2\n\t                sigma_C=213*10**6,    #N/m2\n\t                dislimit=0.002,       #m\n\t                slenderness_ratio_T=220,\n\t                slenderness_ratio_C=180,\n\t                max_len=5.0,            #m\n\t                min_len=0.03,         #m\n\t                use_self_weight=True,\n\t                use_dis_constraint=True,\n", "                use_stress_constraint=True,\n\t                use_buckle_constraint=True,\n\t                use_slenderness_constraint=True,\n\t                use_longer_constraint=True,\n\t                use_shorter_constraint=True\n\t                ): \n\t        self._dimension = dimension    #结构维度\n\t        self._E = E                    #弹性模量\n\t        self._pho = pho                #材料密度\n\t        self._sigma_T = sigma_T        #容许拉应力\n", "        self._sigma_C = sigma_C        #容许压应力\n\t        self._limit_dis = dislimit     #容许位移\n\t        self.slenderness_ratio_T=slenderness_ratio_T #容许受拉长细比\n\t        self.slenderness_ratio_C=slenderness_ratio_C #容许受压长细比\n\t        self.max_len=max_len                         #最大长度\n\t        self.min_len=min_len                         #最小长度\n\t        self._use_self_weight = use_self_weight              #是否计算自重\n\t        self._use_dis_constraint = use_dis_constraint        #是否启用位移约束\n\t        self._use_stress_constraint = use_stress_constraint         #是否启用应力约束\n\t        self._use_buckle_constraint = use_buckle_constraint         #是否启用屈曲约束\n", "        self._use_slenderness_constraint=use_slenderness_constraint #是否启用长细比约束\n\t        self._use_longer_constraint=use_longer_constraint           #是否启用超长约束\n\t        self._use_shorter_constraint=use_shorter_constraint         #是否启用过短约束\n\t    #判定结构的几何不变性+分析计算\n\t    def _is_struct(self, points, edges):\n\t        ########计算自由度初判结构几何不变性##########\n\t        total_support = 0             #保存支座约束数\n\t        for p in points.values():\n\t            if self._dimension == 2:  #平面桁架\n\t                total_support += (\n", "                    p.supportX\n\t                    + p.supportY\n\t                )\n\t            else:                     #空间桁架\n\t                total_support += (\n\t                    p.supportX\n\t                    + p.supportY\n\t                    + p.supportZ\n\t                )\n\t        if len(points) * self._dimension - len(edges) - total_support > 0:\n", "            return (False)   #计算自由度>0，结构不稳定直接返回False\n\t        #######以下基于点和边集建立有限元模形分析########\n\t        op.wipe()   # 清除所有已有结构\n\t        op.model('basic', '-ndm', self._dimension, '-ndf', self._dimension)  #设置建模器\n\t        for i, point in points.items():   #建立节点\n\t            if self._dimension == 2:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n", "                )\n\t            else:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n\t                    point.vec.z,\n\t                )\n\t        for i, point in points.items():  #施加节点支座约束\n\t            if point.isSupport:\n", "                if self._dimension == 2:\n\t                    op.fix(\n\t                        i,\n\t                        point.supportX,\n\t                        point.supportY,\n\t                    )\n\t                else:\n\t                    op.fix(\n\t                        i,\n\t                        point.supportX,\n", "                        point.supportY,\n\t                        point.supportZ,\n\t                    )\n\t        op.timeSeries(\"Linear\", 1)\n\t        op.pattern(\"Plain\", 1, 1)\n\t        for i, point in points.items():  #添加节点荷载\n\t            if point.isLoad:\n\t                if self._dimension == 2:\n\t                    op.load(\n\t                        i,\n", "                        point.loadX,\n\t                        point.loadY,\n\t                    )\n\t                else:\n\t                    op.load(\n\t                        i,\n\t                        point.loadX,\n\t                        point.loadY,\n\t                        point.loadZ,\n\t                    )\n", "        op.uniaxialMaterial(\"Elastic\", 1, self._E)   #定义材料\n\t        for i, edge in enumerate(edges.values()):\n\t            op.element(\"Truss\", i, edge.u, edge.v, edge.area, 1)  #赋予杆件截面属性\n\t        if self._use_self_weight:  #如果计算自重时\n\t            gravity = 9.8   #重力加速度\n\t            load_gravity = [0 for _ in range(len(points))]  #初始化了一个load_gravity列表，表征杆件自重的等效结点力，len(points)个元素均为0\n\t            for i, edge in edges.items():\n\t                edge_mass = edge.len * edge.area * self._pho       #每根杆件质量\n\t                load_gravity[edge.u] += edge_mass * gravity * 0.5\n\t                load_gravity[edge.v] += edge_mass * gravity * 0.5  #每根杆件的重力向两端分一半到节点上\n", "            for i in range(len(points)):        #将重力荷载等效施加于节点上\n\t                if self._dimension == 2:        #如果是平面结构\n\t                    op.load(i, 0.0, -1 * load_gravity[i])\n\t                else:                           #如果是空间结构\n\t                    op.load(i, 0.0, 0.0, -1 * load_gravity[i])\t\n\t        op.system(\"BandSPD\")\n\t        op.numberer(\"RCM\")\n\t        op.constraints(\"Plain\")\n\t        op.integrator(\"LoadControl\", 1.0)\n\t        op.algorithm(\"Newton\")\n", "        op.analysis(\"Static\")\n\t        ok = op.analyze(1)  #运行分析，ok表征是否成功运行，返回0代表成功，返回<0失败。（注:这里对结构的几何不变性进行了充分判断）\n\t        if ok < 0:\n\t            ok = False\n\t        else:\n\t            ok = True\n\t        return ok\n\t    #评估节点位移\n\t    def _get_dis_value(self, points):\n\t        displacement_weight = np.zeros((len(points), 1))  #初始化一个0数组，用于存放位移数据\n", "        for i in range(len(points)):\n\t            if self._dimension == 2:\n\t                weight = max(   \n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                )                                  #只考虑x,y,(z)方向上的最大的一个线位移\n\t            else:\n\t                weight = max(\n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n", "                    abs(op.nodeDisp(i, 3)),\n\t                )\n\t            print(\"第{:}结点位移为{:}mm\".format(i,weight*10**3))\n\t            displacement_weight[i] = max(weight / self._limit_dis - 1, 0)  #判定节点位移是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为位移评估参照\n\t        return displacement_weight\n\t    #评估杆件应力\n\t    def _get_stress_value(self, edges):\n\t        stress_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放应力数据\n\t        for tag, i in enumerate(edges.keys()):\n\t            edges[i].force = op.basicForce(tag)   #从有限元得到杆件轴力\n", "            edges[i].stress = edges[i].force[0] / edges[i].area  #根据轴力、截面积求正应力\n\t            print(\"第{:}杆件应力为{:}MPa\".format(i,edges[i].stress*10**(-6)))\n\t            if edges[i].stress < 0:                                  #压杆\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_C - 1.0,\n\t                    0.0\n\t                )\n\t            else:                                                    #拉杆\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_T - 1.0,\n", "                    0.0\n\t                )\n\t        return stress_weight  #判定节点应力是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为应力评估参照\n\t    #评估杆件屈曲\n\t    def _get_buckle_value(self, edges):\n\t        buckle_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放屈曲数据\n\t        miu_buckle = 1.0                           #杆件计算长度系数，桁架两端铰接取1\n\t        for tag, i in enumerate(edges.keys()):\n\t            edges[i].force = op.basicForce(tag)    #存放轴力数据\n\t            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n", "            if edges[i].stress < 0:    #仅压杆才考虑屈曲\n\t                #计算欧拉临界力\n\t                force_cr = (\n\t                    math.pi ** 2 \n\t                    * self._E * edges[i].inertia\n\t                ) / (miu_buckle * edges[i].len) ** 2\n\t                #计算欧拉临界应力\n\t                buckle_stress_max = force_cr / edges[i].area\n\t                buckle_weight[tag] = max(\n\t                    abs(edges[i].stress) / abs(buckle_stress_max) - 1.0,\n", "                    0.0\n\t                )#判定杆件压应力是否超过屈曲临界应力：超出则比例存入数组，否则记为0\n\t        return buckle_weight\n\t    #评估杆件长细比\n\t    def _get_slenderness_ratio(self, edges):\n\t        lambda_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放长细比数据\n\t        for tag, i in enumerate(edges.keys()):\n\t            edges[i].force = op.basicForce(tag)    #存放轴力数据\n\t            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n\t            lambda_weight[tag] = max(\n", "                abs(edges[i].slenderness_ratio) / abs(self.slenderness_ratio_C if edges[i].stress < 0 else self.slenderness_ratio_T) - 1.0,\n\t                0.0\n\t            )#判定杆件长细比是否超过限制：超出则比例存入数组，否则记为0\n\t        return lambda_weight\n\t    #评估杆件超长\n\t    def _get_length_longer(self, edges):\n\t        longer_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放长细比数据\n\t        for tag, i in enumerate(edges.keys()):   \n\t            longer_weight[tag] = max(\n\t                abs(edges[i].len) / abs(self.max_len) - 1.0,\n", "                0.0\n\t            )#判定杆件长度是否超过限制：超出则比例存入数组，否则记为0\n\t        return longer_weight\n\t    #评估杆件过短\n\t    def _get_length_shorter(self, edges):\n\t        shorter_weight = np.zeros((len(edges), 1))  #初始化一个0数组，用于存放长细比数据\n\t        for tag, i in enumerate(edges.keys()): \n\t            if edges[i].len < self.min_len:\n\t                shorter_weight[tag] = 1.0-edges[i].len / self.min_len\n\t                #判定杆件长度是否过短：超出则比例存入数组，否则记为0\n", "        return shorter_weight\n\t    #调用以上函数运行结构分析\n\t    def run(self, points, edges):\n\t        is_struct = self._is_struct(points, edges) #运行结构建模与分析，is_struct返回结构是否正常完成分析\n\t        mass, dis_value, stress_value, buckle_value, slenderness_vlaue, longer_value, shorter_value= 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n\t        if is_struct: #如果结构成功完成分析，即结构是几何不变的\n\t            for i, edge in edges.items():\n\t                mass += edge.len * edge.area * self._pho      #计算结构总质量\n\t            if self._use_dis_constraint:\n\t                dis_value = self._get_dis_value(points)       #若启用，获取结构位移评估结果\n", "            if self._use_stress_constraint:\n\t                stress_value = self._get_stress_value(edges)  #若启用，获取结构应力评估结果\n\t            if self._use_buckle_constraint:\n\t                buckle_value = self._get_buckle_value(edges)  #若启用，获取结构屈曲评估结果\n\t            if self._use_slenderness_constraint:\n\t                slenderness_vlaue = self._get_slenderness_ratio(edges)  #若启用，获取结构长细比评估结果    \n\t            if self._use_longer_constraint:\n\t                longer_value = self._get_length_longer(edges)  #若启用，获取结构长细比评估结果\n\t            if self._use_shorter_constraint:\n\t                shorter_value = self._get_length_shorter(edges)  #若启用，获取结构长细比评估结果 \n", "        return (\n\t            is_struct, mass, dis_value, stress_value, buckle_value, slenderness_vlaue, longer_value, shorter_value\n\t        )\n\t    #绘制平面桁架\n\t    def render(self, points, edges):\n\t        _ax = plt.axes(projection='3d')\n\t        for point in points.values():   #绘制节点，scatter()绘制散点\n\t            if point.isSupport:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='g') #支座点为绿色\n\t            elif point.isLoad:\n", "                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='r') #荷载作用的节点为红色\n\t            else:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='b') #其余节点蓝色\n\t        for edge in edges.values():    #绘制杆件\n\t            x0 = [points[edge.u].vec.x, points[edge.v].vec.x]   #杆件起点\n\t            y0 = [points[edge.u].vec.y, points[edge.v].vec.y]   #杆件终点\n\t            z0 = [points[edge.u].vec.z, points[edge.v].vec.z]   #杆件起点\n\t            if edge.stress < -1e-7:\n\t                _ax.plot(x0, y0, z0, color='g', linewidth=(edge.area / math.pi)**0.5*500)    #压杆绿色\n\t            elif edge.stress > 1e-7:\n", "                _ax.plot(x0, y0, z0, color='r', linewidth=(edge.area / math.pi)**0.5*500)    #拉杆红色\n\t            else:\n\t                _ax.plot(x0, y0, z0, color='k', linewidth=(edge.area / math.pi)**0.5*500)    #零杆黑色\n\t        plt.show() #显示图像\n\tif __name__=='__main__':\n\t    truss=DynamicModel(3)    #创建结构对象\n\t    point_list, edge_list = readFile(\"input_file_3d.txt\") #读取数据输入文件中的预设点和边\n\t    #将point_list, edge_list转换成truss.run的数据结构\n\t    points = {}\n\t    edges = {}\n", "    for i, point in enumerate(point_list):  #将预设点对象加入点集\n\t        points[i] = point\n\t    for i, edge in enumerate(edge_list):    #将预设边对象加入边集\n\t        if edge.u > edge.v:                 #边端点重新编号\n\t            tmp = edge.u\n\t            edge.u = edge.v\n\t            edge.v = tmp\n\t        edges[(edge.u, edge.v)] = edge        \n\t    #运行模型分析                                 \n\t    is_struct, mass, dis_value, stress_value, buckle_value, slenderness_vlaue, longer_value, shorter_value  = truss.run(points, edges) \n", "    #后处理，输出结构设计结果的提示信息\n\t    if not is_struct:\n\t        print(\"结构几何不稳定\")\n\t    elif np.sum(dis_value) > 0.0 or np.sum(stress_value) > 0.0 or np.sum(buckle_value) > 0.0 or np.sum(slenderness_vlaue) or np.sum(longer_value) or np.sum(shorter_value):\n\t        for i in range(len(dis_value)):\n\t            if dis_value[i]>0.0:\n\t                print(\"第{:}结点位移超出限值{:}%\".format(i,dis_value[i]*100))\n\t        for i in range(len(stress_value)):\n\t            if stress_value[i]>0.0:\n\t                print(\"第{:}杆件应力超出限值{:}%\".format(i,stress_value[i]*100))\n", "        for i in range(len(buckle_value)):\n\t            if buckle_value[i]>0.0:\n\t                print(\"第{:}杆件屈曲应力超出限值{:}%\".format(i,buckle_value[i]*100))\n\t        for i in range(len(slenderness_vlaue)):\n\t            if slenderness_vlaue[i][0]>0.0:\n\t                print(\"第{:}杆件长细比超出限值{:}%\".format(i,slenderness_vlaue[i]*100))\n\t        for i in range(len(longer_value)):\n\t            if longer_value[i]>0.0:\n\t                print(\"第{:}杆件长度超出限值{:}%\".format(i,longer_value[i]*100))\n\t        for i in range(len(shorter_value)):\n", "            if shorter_value[i]>0.0:\n\t                print(\"第{:}杆件长度短过限值{:}%\".format(i,shorter_value[i]*100))                 \n\t    else:\n\t        print(\"结构几何稳定，且所有约束满足。当前结构总质量为：{:.3f}kg\".format(mass))\n\t    truss.render(points, edges) #显示桁架图像\n"]}
{"filename": "apps/checker/结构验算/utils.py", "chunked_list": ["import math\n\t#定义空间向量类及其运算\n\tclass Vector3:\n\t\t#构造函数\n\t\tdef __init__(self, x = 0.0, y = 0.0, z = 0.0):\n\t\t\tself.x = float(x)\n\t\t\tself.y = float(y)\n\t\t\tself.z = float(z)   #空间坐标\n\t\t#向量加运算\n\t\tdef __add__(self, obj):\n", "\t\treturn Vector3(self.x + obj.x, self.y + obj.y, self.z + obj.z)\n\t\t#向量减运算\n\t\tdef __sub__(self, obj):\n\t\t\treturn Vector3(self.x - obj.x, self.y - obj.y, self.z - obj.z)\n\t\t#向量数乘及叉乘\n\t\tdef __mul__(self, obj):\n\t\t\tif (type(obj) == Vector3):\n\t\t\t\treturn Vector3(self.y*obj.z-self.z*obj.y, self.z*obj.x-self.x*obj.z, self.x*obj.y-self.y*obj.x)#向量叉乘\n\t\t\tif (type(obj) == float or type(obj) == int):\n\t\t\t\treturn Vector3(self.x * obj, self.y * obj, self.z * obj)#数乘向量\n", "\t\tassert(False)\n\t\t#向量文本化表示(x,y,z)\n\t\tdef __str__(self):\n\t\t\treturn str('(' + str(self.x) + ', ' + str(self.y) + ', ' + str(self.z) + ')')\n\t\t#向量模长的平方\n\t\tdef length2(self):\n\t\t\treturn float(self.x * self.x + self.y * self.y + self.z * self.z)\n\t\t#向量模长\n\t\tdef length(self):\n\t\t\treturn math.sqrt(self.x * self.x + self.y * self.y + self.z * self.z)\n", "\t#向量单位化\n\t\tdef norm(self):\n\t\t\tl = self.length()\n\t\t\treturn Vector3(self.x / l, self.y / l, self.z / l)\n\t\t#判断向量是否相等\n\t\tdef __eq__(self, other):\n\t\t\tassert(type(other) == Vector3)\n\t\t\tif (abs(self.x - other.x) < 1e-8 and abs(self.y - other.y) < 1e-8 and abs(self.z - other.z) < 1e-8):\n\t\t\t\treturn True\n\t\t\telse:\n", "\t\t\treturn False\n\t#节点类\n\tclass Point:\n\t\t#构造函数\n\t\tdef __init__(self, vec = Vector3(), supportX = 0, supportY = 0, supportZ = 0, loadX = 0.0, loadY = 0.0, loadZ = 0.0):\n\t\t\tself.vec = vec  #用空间向量类创建位置\n\t\t\tself.supportX = supportX       #表征节点某方向支座约束，1是0否\n\t\t\tself.supportY = supportY\n\t\t\tself.supportZ = supportZ\n\t\t\tself.isSupport = False\n", "\t\tif (supportX == 1 or supportY == 1 or supportZ == 1):\n\t\t\t\tself.isSupport = True\n\t\t\tself.loadX = loadX            #表征节点某方向的点荷载的大小\n\t\t\tself.loadY = loadY\n\t\t\tself.loadZ = loadZ\n\t\t\tself.isLoad = False\n\t\t\tif (abs(loadX) > 1e-7 or abs(loadY) > 1e-7 or abs(loadZ) > 1e-7):\n\t\t\t\tself.isLoad = True\n\t#杆件类\n\tclass Bar:\n", "\t#构造函数\n\t\tdef __init__(self, u = -1, v = -1, area = 1.0, leng = 0.0, inertia=1.0):\n\t\t\tself.u = int(u)\n\t\t\tself.v = int(v)             #杆件两端的节点编号\n\t\t\tself.area = float(area)     #杆件截面积\n\t\t\tself.force = float(0.0)     #杆件轴力\n\t\t\tself.len = leng             #杆件长度\n\t\t\tself.stress = 0.0           #杆件应力\n\t\t\tself.inertia=float(inertia) #杆件惯性矩\n\t\t\tself.slenderness_ratio=self.len/(self.inertia/self.area)**0.5\n", "#求空间向量的模长\n\tdef getlen(vec):\n\t\treturn math.sqrt(vec.x * vec.x + vec.y * vec.y + vec.z * vec.z)\n\t#求两点间杆件长度\n\tdef getlen2(u, v):\n\t\treturn getlen(u.vec - v.vec)\n\t#两向量夹角的余弦\n\tdef getang(vec1, vec2):\n\t\treturn (vec1.x * vec2.x + vec1.y * vec2.y + vec1.z * vec2.z) / (getlen(vec1) * getlen(vec2))\n\t#从文件读取设计数据\n", "def readFile(input_file):\n\t\tp = []  #点集\n\t\te = []  #边集\n\t\twith open(input_file, \"r\") as fle:\n\t\t\tlines = fle.readlines()        #读取文件全部行，返回一个字符串列表，每个元素为文件的一行内容\n\t\t\tfor i in range(len(lines)):\n\t\t\t\tline = lines[i]            #第i行内容\n\t\t\t\tvec = line.strip().split(' ')  #strip()用于移除字符串头尾指定的字符（默认为空格）或字符序列，split(' ')通过指定分隔符对字符串进行切片，sep默认为所有的空字符，包括空格、换行(\\n)、制表符(\\t)\n\t\t\t\tif (i == 0):               #第一行\n\t\t\t\t\tvn = int(vec[0])       #预设节点数量\n", "\t\t\t\ten = int(vec[1])       #预设边数量\n\t\t\t\t\tcontinue\n\t\t\t\tif (1 <= i and i <= vn):   #预设节点信息\n\t\t\t\t\tp.append(Point(Vector3(float(vec[0]), float(vec[1]), float(vec[2])), int(vec[3]), int(vec[4]), int(vec[5]), float(vec[6]), float(vec[7]), float(vec[8])))\n\t\t\t\t\tcontinue               #点集p里每个元素为Point类对象：{点坐标3+支座约束+荷载}\n\t\t\t\tif (vn + 1 <= i and i <= vn + en):\n\t\t\t\t\te.append(Bar(vec[0], vec[1], float(vec[2]), getlen2(p[int(vec[0])], p[int(vec[1])]),math.pi*(float(vec[3])**4-(float(vec[3])-2*float(vec[4]))**4)/64))\n\t\t\t\t\tcontinue               #边集里每个元素为bar类对象：{两端节点编号2+截面积+长度+(惯性矩缺省)}\n\t\treturn p, e\n"]}
{"filename": "Stage2/__init__.py", "chunked_list": ["from Stage2.models import *"]}
{"filename": "Stage2/main_3d.py", "chunked_list": ["import argparse\n\timport os\n\timport sys\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom configs.config import *\n\timport copy\n\timport torch as th\n\timport rlkit.torch.pytorch_util as ptu\n\timport numpy as np\n", "import warnings\n\tfrom rlkit.envs.wrappers import NormalizedBoxEnv\n\tfrom rlkit.samplers.data_collector import MdpPathCollector\n\tfrom rlkit.data_management.env_replay_buffer import EnvReplayBuffer\n\tfrom rlkit.torch.sac.sac import SACTrainer\n\tfrom rlkit.torch.torch_rl_algorithm import TorchBatchRLAlgorithm\n\tfrom Stage2.envs import Truss\n\tfrom models import MLP, TanhGaussianPolicy, MakeDeterministic, TRANSFORMEREMBED, GNNEMBED, TRANSFORMEREMBED_policy, GNNEMBED_policy\n\tclass SizeEnvReplayBuffer(EnvReplayBuffer):\n\t    def __init__(self, *args, **kwargs):\n", "        super().__init__(*args, **kwargs)\n\t    def random_batch(self, batch_size):\n\t        indices = np.random.choice(self._size, size=batch_size, replace=self._replace or self._size < batch_size)\n\t        if not self._replace and self._size < batch_size:\n\t            warnings.warn('Replace was set to false, but is temporarily set to true because batch size is larger than current size of replay.')\n\t        batch = dict(\n\t            observations=self._observations[indices],\n\t            actions=self._actions[indices],\n\t            rewards=self._rewards[indices],\n\t            terminals=self._terminals[indices],\n", "            next_observations=self._next_obs[indices],\n\t        )\n\t        for key in self._env_info_keys:\n\t            assert key not in batch.keys()\n\t            batch[key] = self._env_infos[key][indices]\n\t        return batch\n\tif __name__ == '__main__':\n\t    parser = get_base_config()\n\t    args = parser.parse_known_args(sys.argv[1:])[0]\n\t    config = make_config(args.config)\n", "    for k, v in config.get(\"base\", {}).items():\n\t        if f\"--{k}\" not in args:\n\t            setattr(args, k, v)\n\t    print(args)\n\t    print(args.save_model_path)\n\t    if not os.path.exists('saved_models'):\n\t        os.mkdir('saved_models')\n\t    if not os.path.exists(args.save_model_path):\n\t        os.mkdir(args.save_model_path)\n\t    args.save_model_path = os.path.join(args.save_model_path, args.run_id)\n", "    if not os.path.exists(args.save_model_path):\n\t        os.mkdir(args.save_model_path)\n\t    if th.cuda.is_available():\n\t        ptu.set_gpu_mode(True)\n\t    env = NormalizedBoxEnv(Truss(args, args.maxp, os.path.join(args.input_path_2, args.run_id),\n\t                                 args.coordinate_range, args.area_range,\n\t                                 args.coordinate_delta_range, args.area_delta_range,\n\t                                 args.fixed_points, args.variable_edges,\n\t                                 args.max_refine_steps, dimension=args.env_dims, reward_lambda=args.reward_lambda))\n\t    obs_dim = env.observation_space.low.size\n", "    action_dim = env.action_space.low.size\n\t    #qf1 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t    #qf2 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t    if (args.EmbeddingBackbone == 'Transformer'):\n\t        qf1 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims, args.env_dims, args.env_mode, src_mask=True)\n\t        qf2 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims, args.env_dims, args.env_mode, src_mask=True)\n\t    elif (args.EmbeddingBackbone == 'GNN'):\n\t        qf1 = GNNEMBED(args.prev_dims, args.hidden_dims, args.env_dims, args.env_mode, args.maxp)\n\t        qf2 = GNNEMBED(args.prev_dims, args.hidden_dims, args.env_dims, args.env_mode, args.maxp)\n\t    target_qf1 = copy.deepcopy(qf1)\n", "    target_qf2 = copy.deepcopy(qf2)\n\t    if (args.EmbeddingBackbone == 'Transformer'):\n\t        expl_policy = TRANSFORMEREMBED_policy(args.prev_dims, action_dim, args.hidden_dims, args.env_dims, args.env_mode, num_point=args.maxp, src_mask=True)\n\t    elif (args.EmbeddingBackbone == 'GNN'):\n\t        expl_policy = GNNEMBED_policy(args.prev_dims, action_dim, args.hidden_dims, args.env_dims, args.env_mode, num_point=args.maxp)\n\t    #expl_policy = TanhGaussianPolicy(obs_dim=obs_dim, action_dim=action_dim, hidden_sizes=args.hidden_dims)\n\t    if args.finetune:\n\t        print(\"load pretrain\")\n\t        expl_policy.load_state_dict(th.load(\"{}/policy.th\".format(args.finetune_model_path)))\n\t        qf1.load_state_dict(th.load(\"{}/qf1.th\".format(args.finetune_model_path)))\n", "        qf2.load_state_dict(th.load(\"{}/qf2.th\".format(args.finetune_model_path)))\n\t        target_qf1.load_state_dict(th.load(\"{}/target_qf1.th\".format(args.finetune_model_path)))\n\t        target_qf2.load_state_dict(th.load(\"{}/target_qf2.th\".format(args.finetune_model_path)))\n\t    eval_policy = MakeDeterministic(expl_policy)\n\t    if args.eval:\n\t        expl_policy = MakeDeterministic(expl_policy)\n\t        trainer = SACTrainer(env=env, policy=expl_policy, qf1=qf1, qf2=qf2, target_qf1=target_qf1, target_qf2=target_qf2,\n\t                         soft_target_tau=0.005, reward_scale=1, policy_lr=0.0000, qf_lr=0.0000)\n\t    else: trainer = SACTrainer(env=env, policy=expl_policy, qf1=qf1, qf2=qf2, target_qf1=target_qf1, target_qf2=target_qf2,\n\t                         soft_target_tau=0.005, reward_scale=1, policy_lr=0.0003, qf_lr=0.0003)\n", "    expl_path_collector = MdpPathCollector(env, expl_policy)\n\t    eval_path_collector = MdpPathCollector(env, eval_policy)\n\t    replay_buffer = EnvReplayBuffer(args.buffer_size, env)\n\t    algorithm = TorchBatchRLAlgorithm(trainer=trainer, exploration_env=env, evaluation_env=env,\n\t                                      exploration_data_collector=expl_path_collector,\n\t                                      evaluation_data_collector=eval_path_collector,\n\t                                      replay_buffer=replay_buffer,\n\t                                      num_epochs=args.epoch,\n\t                                      num_eval_steps_per_epoch=2000,\n\t                                      num_trains_per_train_loop=args.num_trains_per_train_loop,\n", "                                      num_train_loops_per_epoch=args.num_train_loops_per_epoch,\n\t                                      num_expl_steps_per_train_loop=1000,\n\t                                      min_num_steps_before_training=1000,\n\t                                      max_path_length=500,\n\t                                      batch_size=args.batch_size, eval = args.eval)\n\t    algorithm.to(ptu.device)\n\t    algorithm.train()\n\t    trained_network = algorithm.trainer.networks\n\t    th.save(trained_network[0].state_dict(), \"{}/policy.th\".format(args.save_model_path))\n\t    th.save(trained_network[1].state_dict(), \"{}/qf1.th\".format(args.save_model_path))\n", "    th.save(trained_network[2].state_dict(), \"{}/qf2.th\".format(args.save_model_path))\n\t    th.save(trained_network[3].state_dict(), \"{}/target_qf1.th\".format(args.save_model_path))\n\t    th.save(trained_network[4].state_dict(), \"{}/target_qf2.th\".format(args.save_model_path))\n"]}
{"filename": "Stage2/models/__init__.py", "chunked_list": ["from .policy import TanhGaussianPolicy, MakeDeterministic, EmbedTanhGaussianPolicy\n\tfrom .value_function import MLP, TRANSFORMEREMBED, Transformer_Value_Network, Toy_Value_Network, GNNEMBED, TRANSFORMEREMBED_policy, GNNEMBED_policy\n"]}
{"filename": "Stage2/models/policy/__init__.py", "chunked_list": ["from .TanhGaussian import TanhGaussianPolicy, MakeDeterministic, EmbedTanhGaussianPolicy"]}
{"filename": "Stage2/models/policy/TanhGaussian_autoregression.py", "chunked_list": ["from rlkit.torch.sac.policies import TanhGaussianPolicy, MakeDeterministic\n"]}
{"filename": "Stage2/models/policy/TanhGaussian.py", "chunked_list": ["from rlkit.torch.sac.policies import TanhGaussianPolicy, MakeDeterministic\n\timport abc\n\timport logging\n\timport os\n\timport math\n\timport numpy as np\n\timport torch\n\timport torch.nn.functional as F\n\tfrom torch import nn as nn\n\timport rlkit.torch.pytorch_util as ptu\n", "from rlkit.policies.base import ExplorationPolicy\n\tfrom rlkit.torch.core import torch_ify, elem_or_tuple_to_numpy\n\tfrom rlkit.torch.distributions import (\n\t    Delta, TanhNormal, MultivariateDiagonalNormal, GaussianMixture, GaussianMixtureFull,\n\t)\n\tfrom rlkit.torch.networks import Mlp, CNN\n\tfrom rlkit.torch.networks.basic import MultiInputSequential\n\tfrom rlkit.torch.networks.stochastic.distribution_generator import (\n\t    DistributionGenerator\n\t)\n", "from rlkit.torch.sac.policies.base import (\n\t    TorchStochasticPolicy,\n\t    PolicyFromDistributionGenerator,\n\t    MakeDeterministic,\n\t)\n\tLOG_SIG_MAX = 2\n\tLOG_SIG_MIN = -20\n\tclass EmbedTanhGaussianPolicy(Mlp, TorchStochasticPolicy):\n\t    \"\"\"\n\t    Usage:\n", "    ```\n\t    policy = TanhGaussianPolicy(...)\n\t    \"\"\"\n\t    def __init__(\n\t            self,\n\t            hidden_sizes,\n\t            obs_dim,\n\t            action_dim,\n\t            input_dims,\n\t            std=None,\n", "            init_w=1e-3,\n\t            **kwargs\n\t    ):\n\t        super().__init__(\n\t            hidden_sizes,\n\t            input_size=obs_dim,\n\t            output_size=action_dim,\n\t            init_w=init_w,\n\t            **kwargs\n\t        )\n", "        self.log_std = None\n\t        self.std = std\n\t        if std is None:\n\t            last_hidden_size = obs_dim\n\t            if len(hidden_sizes) > 0:\n\t                last_hidden_size = hidden_sizes[-1]\n\t            self.last_fc_log_std = nn.Linear(last_hidden_size, action_dim)\n\t            self.last_fc_log_std.weight.data.uniform_(-init_w, init_w)\n\t            self.last_fc_log_std.bias.data.uniform_(-init_w, init_w)\n\t        else:\n", "            self.log_std = np.log(std)\n\t            assert LOG_SIG_MIN <= self.log_std <= LOG_SIG_MAX\n\t        self.embed_dim = input_dims[-1]\n\t        # print(input_dims[-1])\n\t        # print(input_dims[:-1])\n\t        self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n\t        self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5)\n\t        self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=2)\n\t        self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n\t        self.transformer = nn.Transformer(d_model=self.embed_dim, nhead=4, num_encoder_layers=2)\n", "    def forward(self, obs):\n\t        inputs = [obs, torch.ones(obs.shape[0], 3).cuda()]\n\t        flat_inputs = torch.cat(inputs, dim=-1).cuda()\n\t        # print(flat_inputs.shape)\n\t        flat_dim = flat_inputs.shape[1]\n\t        act_inputs = flat_inputs[..., -3:]\n\t        id_inputs = flat_inputs[..., -5: -3]\n\t        num_points = int((math.sqrt(25 + 8 * (flat_dim - 5)) - 5) / 2)\n\t        # print(num_points)\n\t        pos_inputs = flat_inputs[..., :2 * num_points]\n", "        force_inputs = flat_inputs[..., -5 - num_points: -5]\n\t        edge_inputs = flat_inputs[..., 2 * num_points: -5 - num_points]\n\t        node_outputs = NodeEmbedding(pos_inputs, force_inputs, num_points).cuda()\n\t        embed_node_outputs = self.embed_node(node_outputs)\n\t        # print(node_outputs.shape, embed_node_outputs.shape)\n\t        edge_outputs = EdgeEmbedding(pos_inputs, edge_inputs, num_points).cuda()\n\t        embed_edge_outputs = self.embed_edge(edge_outputs)\n\t        # print(edge_outputs.shape, embed_edge_outputs.shape)\n\t        embed_id_outputs = self.embed_id(id_inputs).unsqueeze(1)\n\t        embed_act_outputs = self.embed_act(act_inputs).unsqueeze(1)\n", "        # print(embed_id_outputs.shape, embed_act_outputs.shape)\n\t        src = torch.cat([embed_node_outputs, embed_edge_outputs, embed_id_outputs], dim=1).transpose(0, 1)\n\t        # print(src.shape)\n\t        tgt = embed_act_outputs.transpose(0, 1)\n\t        # print(tgt.shape)\n\t        outs = self.transformer(src, tgt).transpose(0, 1).squeeze(dim=1)\n\t        #print(outs.shape)\n\t        h = outs\n\t        for i, fc in enumerate(self.fcs):\n\t            h = self.hidden_activation(fc(h))\n", "        mean = self.last_fc(h)\n\t        if self.std is None:\n\t            log_std = self.last_fc_log_std(h)\n\t            log_std = torch.clamp(log_std, LOG_SIG_MIN, LOG_SIG_MAX)\n\t            std = torch.exp(log_std)\n\t        else:\n\t            std = torch.from_numpy(np.array([self.std, ])).float().to(\n\t                ptu.device)\n\t        return TanhNormal(mean, std)\n\t    def logprob(self, action, mean, std):\n", "        tanh_normal = TanhNormal(mean, std)\n\t        log_prob = tanh_normal.log_prob(\n\t            action,\n\t        )\n\t        log_prob = log_prob.sum(dim=1, keepdim=True)\n\t        return log_prob\n\tdef EdgeEmbedding(pos_inputs, edge_inputs, num_points):\n\t    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, 2)\n\t    outputs = []\n\t    for k in range(_pos_inputs.shape[0]):\n", "        one_output = []\n\t        idx = 0\n\t        i = 0\n\t        j = 1\n\t        while idx < num_points * (num_points - 1) / 2:\n\t            one_edge = []\n\t            v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1]]\n\t            v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1]]\n\t            area_ij = edge_inputs[k][idx]\n\t            one_edge += v_i\n", "            one_edge += v_j\n\t            one_edge.append(area_ij)\n\t            idx += 1\n\t            i += 1\n\t            if i == j:\n\t                i = 0\n\t                j += 1\n\t            one_output.append(one_edge)\n\t        outputs.append(one_output)\n\t    return torch.Tensor(outputs)\n", "def NodeEmbedding(pos_inputs, force_inputs, num_points):\n\t    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, 2)\n\t    _force_inputs = force_inputs.reshape(force_inputs.shape[0], num_points, 1)\n\t    return torch.cat([_pos_inputs, _force_inputs], dim=-1)"]}
{"filename": "Stage2/models/value_function/mlp.py", "chunked_list": ["import torch, os, math\n\timport numpy as np\n\tfrom torch import nn\n\tfrom torch.nn import functional as F\n\tfrom rlkit.policies.base import Policy\n\tfrom rlkit.pythonplusplus import identity\n\tfrom rlkit.torch import pytorch_util as ptu\n\tfrom rlkit.torch.core import PyTorchModule, eval_np\n\tfrom rlkit.torch.data_management.normalizer import TorchFixedNormalizer\n\tfrom rlkit.torch.networks import LayerNorm, ConcatMlp, Mlp\n", "from rlkit.torch.pytorch_util import activation_from_string\n\tfrom rlkit.torch.sac.policies import TanhGaussianPolicy\n\tclass MLP(ConcatMlp):\n\t    def __init__(self, input_dim, hidden_dims):\n\t        super().__init__(input_size=input_dim, output_size=1, hidden_sizes=hidden_dims)\n\tclass _Mlp(Mlp):\n\t    def __init__(self, *args, dim=1, **kwargs):\n\t        super().__init__(*args, **kwargs)\n\t        self.dim = dim\n\tclass Transformer_Value_Network(nn.Module):\n", "    \"\"\"\n\t        value network for UCTs\n\t        hidden dims: hidden_dims for Mlp\n\t        input dims: [... -1]: ... for Mlp for input size, -1 for enbedding size \n\t    \"\"\"\n\t    def __init__(self, input_dims, hidden_dims, env_dims, env_mode, num_node):\n\t        super(Transformer_Value_Network, self).__init__()\n\t        self.embed_dim = input_dims[-1]\n\t        self.env_dims = env_dims\n\t        self.env_mode = env_mode\n", "        self.num_node = num_node\n\t        self.num_edge = self.num_node * (self.num_node - 1) // 2\n\t        # print(self.num_node * (self.env_dims + 1) + self.num_edge * (1 + 2 * self.env_dims))\n\t        self.query_valid_embed = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 1)\n\t        self.query_value_embed = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 1)\n\t        if (env_dims == 2):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 3) #2 pos + 1 force = 3\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 5) #2 * 2 pos + 1 Area = 5\n\t        if (env_dims == 3 and env_mode == 'Area'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 4) #3 pos + 1 force = 4\n", "            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 7) #2 * 3 pos + 1 Area = 7\n\t        if (env_dims == 3 and env_mode == 'DT'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size = 8) #2 * 3 pos + 2 dt = 8\n\t        self.transformer = nn.Transformer(d_model=self.embed_dim, nhead = 1, num_encoder_layers = 6)\n\t        self.valid_head = Mlp(input_size = input_dims[-1], output_size = 2, hidden_sizes = hidden_dims)\n\t        self.value_head = Mlp(input_size = input_dims[-1], output_size = 1, hidden_sizes = hidden_dims)\n\t    def forward(self, *inputs, **kwargs): \n\t        flat_inputs = torch.cat(inputs, dim = -1).cuda()\n\t        flat_dim = flat_inputs.shape[1]\n", "        #print(flat_dim)\n\t        #print(self.env_dims)\n\t        #print(flat_inputs.shape)\n\t        if (self.env_dims == 2):\n\t            num_points = int((math.sqrt(25 + 8 * (flat_dim)) - 5) / 2) # check!!!\n\t            pos_inputs = flat_inputs[..., :2 * num_points]\n\t            force_inputs = flat_inputs[..., -num_points: ]\n\t            edge_inputs = flat_inputs[..., 2 * num_points: -num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'Area'):\n\t            num_points = int((math.sqrt(49 + 8 * (flat_dim)) - 7) / 2) # check!!!\n", "            #1/2 * (-7 + sqrt(49 + 8n))\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., num_points: ]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'DT'):\n\t            num_points = int((math.sqrt(9 + 4 * (flat_dim)) - 3) / 2) # check!!!\n\t            #1 / 2 * (-3 + sqrt(9 + 4n))\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -num_points: ]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -num_points]\n", "        #print(pos_inputs[0])\n\t        #print(force_inputs[0])\n\t        #print(edge_inputs[0])\n\t        node_outputs = NodeEmbedding(pos_inputs, force_inputs, num_points).cuda()\n\t        #print(node_outputs[0])\n\t        embed_node_outputs = self.embed_node(node_outputs)\n\t        #print(node_outputs.shape, embed_node_outputs.shape)\n\t        edge_outputs, src_mask = EdgeEmbedding_with_Mask(pos_inputs, edge_inputs, num_points, self.env_dims, self.env_mode)\n\t        #print(edge_outputs[0])\n\t        embed_edge_outputs = self.embed_edge(edge_outputs)\n", "        #print(edge_outputs.shape, embed_edge_outputs.shape)\n\t        #print(embed_id_outputs.shape, embed_act_outputs.shape)\n\t        src = torch.cat([embed_node_outputs, embed_edge_outputs], dim=1).transpose(0, 1)\n\t        #print(src.shape)\n\t        query_input = torch.ones(flat_inputs.shape[0]).unsqueeze(-1).unsqueeze(0).to(src.device)\n\t        tgt = torch.cat((self.query_valid_embed(query_input), self.query_value_embed(query_input)), dim = 0)\n\t        #print(src.shape, tgt.shape)\n\t        #print(src_mask.shape)\n\t        #print(src_mask)\n\t        #print(src_mask[1])\n", "        src_mask = ~src_mask\n\t        outs = self.transformer(src, tgt, src_mask = src_mask)\n\t        #print(outs.shape)\n\t        valid = self.valid_head(outs[0])\n\t        value = self.value_head(outs[1])\n\t        return valid, value\n\tclass TRANSFORMEREMBED(_Mlp):\n\t    \"\"\"\n\t        represented by edge sequences --> MLP embed to high dim --> transformer --> MLP to dim 1\n\t    \"\"\"\n", "    def __init__(self, input_dims, hidden_dims, env_dims, env_mode, num_point = None, src_mask = False):\n\t        super().__init__(input_size=input_dims[-1], output_size=1, hidden_sizes=hidden_dims)\n\t        self.embed_dim = input_dims[-1]\n\t        self.env_dims = env_dims\n\t        self.env_mode = env_mode\n\t        self.src_mask = src_mask\n\t        if (env_dims == 2):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) #2 pos + 1 force = 3\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) #2 * 2 pos + 1 Area = 5\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n", "            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) # 2 pos + 1 Area = 3\n\t        if (env_dims == 3 and env_mode == 'Area'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=7) #2 * 3 pos + 1 Area = 7\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) \n\t            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) # 3 pos + 1 Area = 4  \n\t        if (env_dims == 3 and env_mode == 'DT'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=8) #2 * 3 pos + 2 dt = 8\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) \n", "            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) # 3 pos + 2 dt = 5  \n\t        if (src_mask):\n\t            self.transformer = nn.Transformer(d_model=self.embed_dim, nhead=1, num_encoder_layers=6)\n\t        else: \n\t            self.transformer = nn.Transformer(d_model=self.embed_dim, nhead=4, num_encoder_layers=2)\n\t    def forward(self, *inputs, **kwargs):\n\t        flat_inputs = torch.cat(inputs, dim=self.dim).cuda()\n\t        flat_dim = flat_inputs.shape[1]\n\t        #print(flat_dim)\n\t        #print(self.env_dims)\n", "        #print(flat_inputs.shape)\n\t        if (self.env_dims == 2):\n\t            act_inputs = flat_inputs[..., -3:]\n\t            id_inputs = flat_inputs[..., -6: -3]\n\t            num_points = int((math.sqrt(25 + 8 * (flat_dim - 6)) - 5) / 2)\n\t            pos_inputs = flat_inputs[..., :2 * num_points]\n\t            force_inputs = flat_inputs[..., -6 - num_points: -6]\n\t            edge_inputs = flat_inputs[..., 2 * num_points: -6 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'Area'):\n\t            act_inputs = flat_inputs[..., -4:]\n", "            id_inputs = flat_inputs[..., -7: -4]\n\t            num_points = int((math.sqrt(49 + 8 * (flat_dim - 7)) - 7) / 2)\n\t            #1/2 * (-7 + sqrt(49 + 8n))\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -7 - num_points: -7]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -7 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'DT'):\n\t            act_inputs = flat_inputs[..., -5:]\n\t            id_inputs = flat_inputs[..., -8: -5]\n\t            num_points = int((math.sqrt(9 + 4 * (flat_dim - 8)) - 3) / 2)\n", "            #1 / 2 * (-3 + sqrt(9 + 4n))\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -8 - num_points: -8]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -8 - num_points]\n\t        node_outputs = NodeEmbedding(pos_inputs, force_inputs, num_points).cuda()\n\t        embed_node_outputs = self.embed_node(node_outputs)\n\t        #print(node_outputs.shape, embed_node_outputs.shape)\n\t        edge_outputs, src_mask = EdgeEmbedding_with_Mask(pos_inputs, edge_inputs, num_points, self.env_dims, self.env_mode, with_act_id = True)\n\t        edge_outputs.cuda() \n\t        src_mask.cuda()\n", "        embed_edge_outputs = self.embed_edge(edge_outputs)\n\t        #print(edge_outputs.shape, embed_edge_outputs.shape)\n\t        embed_id_outputs = self.embed_id(id_inputs).unsqueeze(1)\n\t        embed_act_outputs = self.embed_act(act_inputs).unsqueeze(1)\n\t        #print(embed_id_outputs.shape, embed_act_outputs.shape)\n\t        src = torch.cat([embed_node_outputs, embed_edge_outputs, embed_id_outputs], dim=1).transpose(0, 1)\n\t        #print(src.shape)\n\t        tgt = embed_act_outputs.transpose(0, 1)\n\t        #print(tgt.shape)\n\t        #print(src_mask.shape)\n", "        #print(src_mask[0])\n\t        if (not self.src_mask): src_mask = None\n\t        if (src_mask != None): src_mask = ~src_mask\n\t        outs = self.transformer(src, tgt, src_mask = src_mask).transpose(0, 1).squeeze(dim=1)\n\t        #print(outs[0])\n\t        return super().forward(outs, **kwargs)\n\tdef EdgeEmbedding(pos_inputs, edge_inputs, num_points, env_dims = 2, env_mode = 'Area'):# TODO:check it\n\t    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, -1)\n\t    outputs = []\n\t    for k in range(_pos_inputs.shape[0]):\n", "        one_output = []\n\t        idx = 0\n\t        i = 0\n\t        j = 1\n\t        while idx < num_points * (num_points - 1) / 2:\n\t            one_edge = []\n\t            v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1]]\n\t            v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1]]\n\t            if (env_dims == 3):\n\t                v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1], _pos_inputs[k][i][2]]\n", "                v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1], _pos_inputs[k][j][2]]\n\t            one_edge += v_i\n\t            one_edge += v_j\n\t            if (env_mode == 'Area'):\n\t                area_ij = edge_inputs[k][idx]\n\t                one_edge.append(area_ij)\n\t            if (env_mode == 'DT'):\n\t                d_ij = edge_inputs[k][idx * 2]\n\t                t_ij = edge_inputs[k][idx * 2 + 1]\n\t                one_edge.append(d_ij)\n", "                one_edge.append(t_ij)\n\t            idx += 1\n\t            i += 1\n\t            if i == j:\n\t                i = 0\n\t                j += 1\n\t            one_output.append(one_edge)\n\t        outputs.append(one_output)\n\t    return torch.Tensor(outputs) # k * (num * (num - 1) / 2) * 8\n\tdef EdgeEmbedding_with_Mask(pos_inputs, edge_inputs, num_points, env_dims = 2, env_mode = 'Area', with_act_id = False):\n", "    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, -1)\n\t    outputs = []\n\t    src_len = num_points + num_points * (num_points - 1) // 2\n\t    if (not with_act_id):\n\t        masks = torch.zeros((pos_inputs.shape[0], src_len, src_len), dtype = bool)\n\t    else:\n\t        masks = torch.zeros((pos_inputs.shape[0], src_len + 1, src_len + 1), dtype = bool)\n\t    for k in range(_pos_inputs.shape[0]):\n\t        if (not with_act_id):\n\t            mask = torch.zeros((src_len, src_len), dtype = bool)\n", "        else:\n\t            mask = torch.zeros((src_len + 1, src_len + 1), dtype = bool)\n\t        one_output = []\n\t        idx = 0\n\t        i, j = 0, 1\n\t        while idx < num_points * (num_points - 1) // 2:\n\t            one_edge = []\n\t            v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1]]\n\t            v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1]]\n\t            if (env_dims == 3):\n", "                v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1], _pos_inputs[k][i][2]]\n\t                v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1], _pos_inputs[k][j][2]]\n\t            one_edge += v_i\n\t            one_edge += v_j\n\t            if (env_mode == 'Area'):\n\t                area_ij = edge_inputs[k][idx]\n\t                one_edge.append(area_ij)\n\t                if (area_ij > 0): \n\t                    mask[i, idx + num_points], mask[j, idx + num_points] = True, True\n\t                    mask[idx + num_points, i], mask[idx + num_points, j] = True, True\n", "            if (env_mode == 'DT'):\n\t                d_ij = edge_inputs[k][idx * 2]\n\t                t_ij = edge_inputs[k][idx * 2 + 1]\n\t                one_edge.append(d_ij)\n\t                one_edge.append(t_ij)\n\t                if (d_ij > 0): \n\t                    mask[i, idx + num_points], mask[j, idx + num_points] = True, True\n\t                    mask[idx + num_points, i], mask[idx + num_points, j] = True, True\n\t            idx += 1\n\t            i += 1\n", "            if i == j:\n\t                i = 0\n\t                j += 1\n\t            one_output.append(one_edge)\n\t        outputs.append(one_output)\n\t        masks[k] = mask\n\t    if (with_act_id):\n\t        for i in range(masks.shape[1]): masks[..., i, src_len], masks[..., src_len, i] = True, True\n\t    for i in range(mask.shape[1]): masks[..., i, i] = True\n\t    return torch.Tensor(outputs).cuda(), masks.cuda()\n", "def NodeEmbedding(pos_inputs, force_inputs, num_points):\n\t    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, -1) \n\t    _force_inputs = force_inputs.reshape(force_inputs.shape[0], num_points, -1)\n\t    return torch.cat([_pos_inputs, _force_inputs], dim=-1)\n\t# for flat_input, output is a sequence of tuple with size 5, each one is (P1.x, P1.y, P2.x, P2.y, area)\n\tdef Dim2EdgeEmbedding(flat_input, num_points): #UNUSED\n\t    UseNormalizationEdge = False\n\t    if UseNormalizationEdge:\n\t        NormalizationEdge = 1000\n\t    else:\n", "        NormalizationEdge = 1\n\t    output = []\n\t    obs_action_dim = flat_input.size()[1]\n\t    num_edges = int(num_points * (num_points - 1) / 2)\n\t    obs_dim = num_points * 2 + num_edges\n\t    act_dim = obs_action_dim - obs_dim\n\t    fixed_points = int((obs_dim - act_dim) / 2)\n\t    for one_input in flat_input:\n\t        points = []\n\t        changed_points = []\n", "        for i in range(num_points):\n\t            points.append([one_input[2 * i], one_input[2 * i + 1]])\n\t        for i in range(num_points):\n\t            if i < fixed_points:\n\t                changed_points.append(points[i])\n\t            else:\n\t                changed_points.append([points[i][0] + one_input[(i - fixed_points) * 2 + obs_dim], points[i][1] + one_input[(i - fixed_points) * 2 + obs_dim + 1]])\n\t        together_edges = []\n\t        edges = []\n\t        changed_edges = []\n", "        idx = 2 * num_points\n\t        changed_idx = obs_dim + 2 * (num_points - fixed_points)\n\t        i = 0\n\t        j = 1\n\t        while idx < obs_dim:\n\t            one_edge = []\n\t            one_edge += points[i]\n\t            one_edge += points[j]\n\t            one_edge.append(one_input[idx] * NormalizationEdge)\n\t            edges.append(one_edge)\n", "            one_changed_edge = []\n\t            one_changed_edge += changed_points[i]\n\t            one_changed_edge += changed_points[j]\n\t            one_changed_edge.append(one_input[changed_idx] * NormalizationEdge + one_input[idx] * NormalizationEdge)\n\t            changed_edges.append(one_changed_edge)\n\t            together_edges.append(one_edge)\n\t            together_edges.append(one_changed_edge)\n\t            idx += 1\n\t            changed_idx += 1\n\t            i += 1\n", "            if i >= j:\n\t                j += 1\n\t                i = 0\n\t        output.append(edges + [[-1, -1, -1, -1, -1],] + changed_edges)\n\t    return torch.Tensor(output)\n\tclass Toy_Value_Network(nn.Module):\n\t    def __init__(self, input_dims, hidden_dims):\n\t        super(Toy_Value_Network, self).__init__()\n\t        self.linear1 = nn.Linear(input_dims, hidden_dims)\n\t        self.ReLU = nn.ReLU()\n", "        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n\t        self.dropout = nn.Dropout(0.2)\n\t        self.valid_head = nn.Linear(hidden_dims, 2)\n\t        self.value_head = nn.Linear(hidden_dims, 1)\n\t    def forward(self, *inputs, **kwargs): \n\t        flat_inputs = torch.cat(inputs, dim = -1).cuda()\n\t        hidden = self.linear1(flat_inputs)\n\t        hidden = self.ReLU(self.dropout(hidden))\n\t        hidden = self.linear2(hidden)\n\t        hidden = self.ReLU(self.dropout(hidden))\n", "        valid = self.valid_head(hidden)\n\t        value = self.value_head(hidden)\n\t        return valid, value\n\tclass TRANSFORMEREMBED_policy(TanhGaussianPolicy):\n\t    def __init__(self, input_dims, action_dim, hidden_dims, env_dims, env_mode, num_point = None, src_mask = False):\n\t        super().__init__(obs_dim=input_dims[-1], action_dim = action_dim, hidden_sizes=hidden_dims)\n\t        self.embed_dim = input_dims[-1]\n\t        self.env_dims = env_dims\n\t        self.env_mode = env_mode\n\t        self.src_mask = src_mask\n", "        self.num_point = num_point\n\t        if (env_dims == 2):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) #2 pos + 1 force = 3\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) #2 * 2 pos + 1 Area = 5\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n\t            #self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) # 2 pos + 1 Area = 3\n\t        if (env_dims == 3 and env_mode == 'Area'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=7) #2 * 3 pos + 1 Area = 7\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) \n", "            #self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) # 3 pos + 1 Area = 4  \n\t        if (env_dims == 3 and env_mode == 'DT'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=8) #2 * 3 pos + 2 dt = 8\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) \n\t            #self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) # 3 pos + 2 dt = 5  \n\t        if (src_mask):\n\t            self.transformer = nn.Transformer(d_model=self.embed_dim, nhead=1, num_encoder_layers=4)\n\t        else: \n\t            self.transformer = nn.Transformer(d_model=self.embed_dim, nhead=4, num_encoder_layers=2)\n", "    def forward(self, obs):\n\t        flat_inputs = obs\n\t        #print(flat_dim)\n\t        #print(self.env_dims)\n\t        #print(flat_inputs.shape)\n\t        assert(self.num_point != None)\n\t        if (self.num_point != None): num_points = self.num_point\n\t        if (self.env_dims == 2):\n\t            id_inputs = flat_inputs[..., -3:]\n\t            pos_inputs = flat_inputs[..., :2 * num_points]\n", "            force_inputs = flat_inputs[..., -3 - num_points: -3]\n\t            edge_inputs = flat_inputs[..., 2 * num_points: -3 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'Area'):\n\t            id_inputs = flat_inputs[..., -3:]\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -3 - num_points: -3]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -3 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'DT'):\n\t            id_inputs = flat_inputs[..., -3:]\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n", "            force_inputs = flat_inputs[..., -3 - num_points: -3]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -3 - num_points]\n\t        node_outputs = NodeEmbedding(pos_inputs, force_inputs, num_points).cuda()\n\t        embed_node_outputs = self.embed_node(node_outputs)\n\t        #print(node_outputs.shape, embed_node_outputs.shape)\n\t        edge_outputs, src_mask = EdgeEmbedding_with_Mask(pos_inputs, edge_inputs, num_points, self.env_dims, self.env_mode, with_act_id = True)\n\t        edge_outputs.cuda() \n\t        src_mask.cuda()\n\t        embed_edge_outputs = self.embed_edge(edge_outputs)\n\t        #print(edge_outputs.shape, embed_edge_outputs.shape)\n", "        embed_id_outputs = self.embed_id(id_inputs).unsqueeze(1)\n\t        #embed_act_outputs = self.embed_act(act_inputs).unsqueeze(1)\n\t        #print(embed_id_outputs.shape, embed_act_outputs.shape)\n\t        src = torch.cat([embed_node_outputs, embed_edge_outputs, embed_id_outputs], dim=1).transpose(0, 1)\n\t        #print(src.shape)\n\t        tgt = embed_id_outputs.transpose(0, 1)\n\t        #print(tgt.shape)\n\t        #print(src_mask.shape)\n\t        #print(src_mask[0])\n\t        if (not self.src_mask): src_mask = None\n", "        if (src_mask != None): src_mask = ~src_mask\n\t        outs = self.transformer(src, tgt, src_mask = src_mask).transpose(0, 1).squeeze(dim=1)\n\t        #print(outs[0])\n\t        return super().forward(outs)\n\tif __name__ == '__main__':\n\t    qf = TRANSFORMEREMBED([128, 256], [256, 512], 3, 'Area', 7).cuda()\n\t    qf(torch.ones(1, 39).cuda())\n"]}
{"filename": "Stage2/models/value_function/__init__.py", "chunked_list": ["from .mlp import MLP, TRANSFORMEREMBED, Transformer_Value_Network, Toy_Value_Network, TRANSFORMEREMBED_policy\n\tfrom .mlp_GNN import GNNEMBED, GNNEMBED_policy"]}
{"filename": "Stage2/models/value_function/mlp_GNN.py", "chunked_list": ["import torch, os, math\n\timport numpy as np\n\tfrom torch_geometric.nn import GCNConv\n\tfrom torch import nn\n\tfrom torch.nn import functional as F\n\tfrom rlkit.policies.base import Policy\n\tfrom rlkit.pythonplusplus import identity\n\tfrom rlkit.torch import pytorch_util as ptu\n\tfrom rlkit.torch.core import PyTorchModule, eval_np\n\tfrom rlkit.torch.data_management.normalizer import TorchFixedNormalizer\n", "from rlkit.torch.networks import LayerNorm, ConcatMlp, Mlp\n\tfrom rlkit.torch.pytorch_util import activation_from_string\n\tfrom torch_geometric.nn import CGConv\n\tfrom rlkit.torch.sac.policies import TanhGaussianPolicy\n\tfrom torch_geometric.data import Data\n\tclass MLP(ConcatMlp):\n\t    def __init__(self, input_dim, hidden_dims):\n\t        super().__init__(input_size=input_dim, output_size=1, hidden_sizes=hidden_dims)\n\tclass _Mlp(Mlp):\n\t    def __init__(self, *args, dim=1, **kwargs):\n", "        super().__init__(*args, **kwargs)\n\t        self.dim = dim\n\tclass id_to_point:\n\t    def __init__(self, num_point):\n\t        self.trans = []\n\t        u, v = 0, 1\n\t        while (v < num_point):\n\t            self.trans.append([u, v])\n\t            v += 1\n\t            if (v == num_point): u, v = u + 1, u + 2\n", "    def convert(self, id):\n\t        return self.trans[id]\n\tclass GNNEMBED(_Mlp):\n\t    r\"\"\"\n\t        represented by graph --> GCN --> MLP to dim 1\n\t    \"\"\"\n\t    def __init__(self, input_dims, hidden_dims, env_dims, env_mode, num_point):\n\t        super().__init__(input_size=input_dims[-1], output_size=1, hidden_sizes=hidden_dims)\n\t        self.trans = id_to_point(num_point)\n\t        self.embed_dim = input_dims[-1]\n", "        self.env_dims = env_dims\n\t        self.env_mode = env_mode\n\t        #print(input_dims[-1])\n\t        #print(input_dims[:-1])\n\t        if (env_dims == 2):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) #2 pos + 1 force = 3\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) #2 * 2 pos + 1 Area = 5\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n\t            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) # 2 pos + 1 Area = 3\n\t        if (env_dims == 3 and env_mode == 'Area'):\n", "            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=7) #2 * 3 pos + 1 Area = 7\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) # No change!!!\n\t            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) # 3 pos + 1 Area = 4     \n\t        if (env_dims == 3 and env_mode == 'DT'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=8) #2 * 3 pos + 2 dt = 8\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) # No change!!!\n\t            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) # 3 pos + 2 dt = 5     \n\t        if (env_mode == 'DT'):\n", "            dim = 2\n\t        else: dim = 1\n\t        self.gcn1 = CGConv(channels=self.embed_dim, dim = dim)\n\t        self.gcn2 = CGConv(channels=self.embed_dim, dim = dim)\n\t        self.gcn3 = CGConv(channels=self.embed_dim, dim = dim)\n\t        self.point_query = nn.Linear(self.embed_dim, self.embed_dim)\n\t        self.edge_query = nn.Linear(2 * self.embed_dim, self.embed_dim)\n\t        self.greedy_query = nn.Linear(self.embed_dim, self.embed_dim)\n\t        self.mix_graph_action = nn.Linear(2 * self.embed_dim, self.embed_dim)\n\t    def forward(self, *inputs, **kwargs):\n", "        flat_inputs = torch.cat(inputs, dim=self.dim).cuda()\n\t        flat_dim = flat_inputs.shape[1]\n\t        if (self.env_dims == 2):\n\t            act_inputs = flat_inputs[..., -3:]\n\t            id_inputs = flat_inputs[..., -6: -3]\n\t            num_points = int((math.sqrt(25 + 8 * (flat_dim - 6)) - 5) / 2)\n\t            pos_inputs = flat_inputs[..., :2 * num_points]\n\t            force_inputs = flat_inputs[..., -6 - num_points: -6]\n\t            edge_inputs = flat_inputs[..., 2 * num_points: -6 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'Area'):\n", "            act_inputs = flat_inputs[..., -4:]\n\t            id_inputs = flat_inputs[..., -7: -4]\n\t            num_points = int((math.sqrt(49 + 8 * (flat_dim - 7)) - 7) / 2)\n\t            #1/2 * (-7 + sqrt(49 + 8n))\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -7 - num_points: -7]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -7 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'DT'):\n\t            act_inputs = flat_inputs[..., -5:]\n\t            id_inputs = flat_inputs[..., -8: -5]\n", "            num_points = int((math.sqrt(9 + 4 * (flat_dim - 8)) - 3) / 2)\n\t            #1 / 2 * (-3 + sqrt(9 + 4n))\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -8 - num_points: -8]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -8 - num_points]\n\t        node_outputs = NodeEmbedding(pos_inputs, force_inputs, num_points).cuda()\n\t        embed_node_outputs = self.embed_node(node_outputs)\n\t        edge_id, edge_feature = Edge_IndexEmbedding(pos_inputs, edge_inputs, num_points, self.env_dims, self.env_mode)\n\t        embed_graph_outs = torch.zeros(flat_inputs.shape[0], self.embed_dim).cuda()\n\t        for i in range(flat_inputs.shape[0]):\n", "            graph_data = Data(x = embed_node_outputs[i], edge_index = edge_id[i].transpose(0, 1), edge_attr = edge_feature[i])\n\t            graph_out = self.gcn1(x=graph_data.x, edge_index=graph_data.edge_index, edge_attr=graph_data.edge_attr)\n\t            graph_data = Data(x = graph_out, edge_index = edge_id[i].transpose(0, 1), edge_attr = edge_feature[i])\n\t            graph_out = self.gcn2(x=graph_data.x, edge_index=graph_data.edge_index, edge_attr=graph_data.edge_attr)\n\t            graph_data = Data(x = graph_out, edge_index = edge_id[i].transpose(0, 1), edge_attr = edge_feature[i])\n\t            graph_out = self.gcn3(x=graph_data.x, edge_index=graph_data.edge_index, edge_attr=graph_data.edge_attr)\n\t            #print(edge_outputs.shape, embed_edge_outputs.shape)\n\t            if (id_inputs[i, 0] != -1):\n\t                embed_graph_out = self.point_query(graph_out[int(id_inputs[i, 0])])\n\t            if (id_inputs[i, 1] != -1):\n", "                u, v = self.trans.convert(int(id_inputs[i, 1]))\n\t                embed_graph_out = self.edge_query(torch.cat((graph_out[u], graph_out[v])))\n\t            if (id_inputs[i, 2] != -1):\n\t                embed_graph_out = self.greedy_query(torch.max(graph_out, dim = -2)[0])\n\t            embed_graph_outs[i] = embed_graph_out\n\t        embed_act_outputs = self.embed_act(act_inputs)\n\t        feature = self.mix_graph_action(torch.cat((embed_graph_outs, embed_act_outputs), dim = -1))\n\t        x = super().forward(feature, **kwargs)\n\t        return x\n\tclass GNNEMBED_policy(TanhGaussianPolicy):\n", "    r\"\"\"\n\t        represented by graph --> GCN --> MLP to dim 1\n\t    \"\"\"\n\t    def __init__(self, input_dims, action_dim, hidden_dims, env_dims, env_mode, num_point):\n\t        super().__init__(obs_dim=input_dims[-1], action_dim = action_dim, hidden_sizes=hidden_dims)\n\t        self.trans = id_to_point(num_point)\n\t        self.embed_dim = input_dims[-1]\n\t        self.env_dims = env_dims\n\t        self.env_mode = env_mode\n\t        self.num_point = num_point\n", "        if (env_dims == 2):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) #2 pos + 1 force = 3\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) #2 * 2 pos + 1 Area = 5\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n\t            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3) # 2 pos + 1 Area = 3\n\t        if (env_dims == 3 and env_mode == 'Area'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=7) #2 * 3 pos + 1 Area = 7\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n\t            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) # 3 pos + 1 Area = 4     \n", "        if (env_dims == 3 and env_mode == 'DT'):\n\t            self.embed_node = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=4) #3 pos + 1 force = 4\n\t            self.embed_edge = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=8) #2 * 3 pos + 2 dt = 8\n\t            self.embed_id = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=3)\n\t            self.embed_act = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5) # 3 pos + 2 dt = 5\n\t        if (env_mode == 'DT'):\n\t            dim = 2\n\t        else: dim = 1\n\t        self.gcn1 = CGConv(channels=self.embed_dim, dim = dim)\n\t        self.gcn2 = CGConv(channels=self.embed_dim, dim = dim)\n", "        self.gcn3 = CGConv(channels=self.embed_dim, dim = dim)\n\t        self.point_query = nn.Linear(self.embed_dim, self.embed_dim)\n\t        self.edge_query = nn.Linear(2 * self.embed_dim, self.embed_dim)\n\t        self.greedy_query = nn.Linear(self.embed_dim, self.embed_dim)\n\t        self.mix_graph_action = nn.Linear(self.embed_dim, self.embed_dim)\n\t    def forward(self, obs):\n\t        flat_inputs = obs\n\t        num_points  = self.num_point\n\t        if (self.env_dims == 2):\n\t            id_inputs = flat_inputs[..., -3:]\n", "            pos_inputs = flat_inputs[..., :2 * num_points]\n\t            force_inputs = flat_inputs[..., -3 - num_points: -3]\n\t            edge_inputs = flat_inputs[..., 2 * num_points: -3 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'Area'):\n\t            id_inputs = flat_inputs[..., -3:]\n\t            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -3 - num_points: -3]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -3 - num_points]\n\t        if (self.env_dims == 3 and self.env_mode == 'DT'):\n\t            id_inputs = flat_inputs[..., -3:]\n", "            pos_inputs = flat_inputs[..., :3 * num_points]\n\t            force_inputs = flat_inputs[..., -3 - num_points: -3]\n\t            edge_inputs = flat_inputs[..., 3 * num_points: -3 - num_points]\n\t        node_outputs = NodeEmbedding(pos_inputs, force_inputs, num_points).cuda()\n\t        embed_node_outputs = self.embed_node(node_outputs)\n\t        edge_id, edge_feature = Edge_IndexEmbedding(pos_inputs, edge_inputs, num_points, self.env_dims, self.env_mode)\n\t        embed_graph_outs = torch.zeros(flat_inputs.shape[0], self.embed_dim).cuda()\n\t        for i in range(flat_inputs.shape[0]):\n\t            graph_data = Data(x = embed_node_outputs[i], edge_index = edge_id[i].transpose(0, 1), edge_attr = edge_feature[i])\n\t            graph_out = self.gcn1(x=graph_data.x, edge_index=graph_data.edge_index, edge_attr=graph_data.edge_attr)\n", "            graph_data = Data(x = graph_out, edge_index = edge_id[i].transpose(0, 1), edge_attr = edge_feature[i])\n\t            graph_out = self.gcn2(x=graph_data.x, edge_index=graph_data.edge_index, edge_attr=graph_data.edge_attr)\n\t            graph_data = Data(x = graph_out, edge_index = edge_id[i].transpose(0, 1), edge_attr = edge_feature[i])\n\t            graph_out = self.gcn3(x=graph_data.x, edge_index=graph_data.edge_index, edge_attr=graph_data.edge_attr)\n\t            #print(edge_outputs.shape, embed_edge_outputs.shape)\n\t            if (id_inputs[i, 0] != -1):\n\t                embed_graph_out = self.point_query(graph_out[int(id_inputs[i, 0])])\n\t            if (id_inputs[i, 1] != -1):\n\t                u, v = self.trans.convert(int(id_inputs[i, 1]))\n\t                embed_graph_out = self.edge_query(torch.cat((graph_out[u], graph_out[v])))\n", "            if (id_inputs[i, 2] != -1):\n\t                embed_graph_out = self.greedy_query(torch.max(graph_out, dim = -2)[0])\n\t            embed_graph_outs[i] = embed_graph_out\n\t        feature = self.mix_graph_action(embed_graph_outs)\n\t        x = super().forward(feature)\n\t        return x\n\tdef EdgeEmbedding(pos_inputs, edge_inputs, num_points, env_dims = 2, env_mode = 'Area'):# TODO:check it\n\t    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, -1)\n\t    outputs = []\n\t    for k in range(_pos_inputs.shape[0]):\n", "        one_output = []\n\t        idx = 0\n\t        i = 0\n\t        j = 1\n\t        while idx < num_points * (num_points - 1) / 2:\n\t            one_edge = []\n\t            v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1]]\n\t            v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1]]\n\t            if (env_dims == 3):\n\t                v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1], _pos_inputs[k][i][2]]\n", "                v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1], _pos_inputs[k][j][2]]\n\t            one_edge += v_i\n\t            one_edge += v_j\n\t            if (env_mode == 'Area'):\n\t                area_ij = edge_inputs[k][idx]\n\t                one_edge.append(area_ij)\n\t            if (env_mode == 'DT'):\n\t                d_ij = edge_inputs[k][idx * 2]\n\t                t_ij = edge_inputs[k][idx * 2 + 1]\n\t                one_edge.append(d_ij)\n", "                one_edge.append(t_ij)\n\t            idx += 1\n\t            j += 1\n\t            if j == num_points:\n\t                i += 1\n\t                j = i + 1\n\t            one_output.append(one_edge)\n\t        outputs.append(one_output)\n\t    return torch.Tensor(outputs) # k * (num * (num - 1) / 2) * 8\n\tdef Edge_IndexEmbedding(pos_inputs, edge_inputs, num_points, env_dims = 2, env_mode = 'Area'):# TODO:check it\n", "    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, -1)\n\t    outputs = []\n\t    feature_outputs = []\n\t    for k in range(_pos_inputs.shape[0]):\n\t        one_output = []\n\t        one_feature_output = []\n\t        idx = 0\n\t        i = 0\n\t        j = 1\n\t        while idx < num_points * (num_points - 1) / 2:\n", "            if (env_mode == 'Area' and edge_inputs[k][idx] > 0): \n\t                one_output.append([i, j])\n\t                one_feature_output.append([edge_inputs[k][idx]])\n\t            if (env_mode == 'DT' and edge_inputs[k][idx * 2] > 0): \n\t                one_output.append([i, j])\n\t                one_feature_output.append([edge_inputs[k][idx * 2], edge_inputs[k][idx * 2 + 1]])\n\t            idx += 1\n\t            j += 1\n\t            if j == num_points:\n\t                i += 1\n", "                j = i + 1\n\t        outputs.append(torch.tensor(one_output).cuda())\n\t        feature_outputs.append(torch.tensor(one_feature_output).cuda())\n\t    return outputs, feature_outputs\n\tdef EdgeEmbedding_with_Mask(pos_inputs, edge_inputs, num_points, env_dims = 2, env_mode = 'Area'):\n\t    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, -1)\n\t    outputs = []\n\t    src_len = num_points + num_points * (num_points - 1) // 2\n\t    masks = torch.zeros((pos_inputs.shape[0], src_len, src_len), dtype = bool)\n\t    for k in range(_pos_inputs.shape[0]):\n", "        mask = torch.zeros((src_len, src_len), dtype = bool)\n\t        one_output = []\n\t        idx = 0\n\t        i, j = 0, 1\n\t        while idx < num_points * (num_points - 1) // 2:\n\t            one_edge = []\n\t            v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1]]\n\t            v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1]]\n\t            if (env_dims == 3):\n\t                v_i = [_pos_inputs[k][i][0], _pos_inputs[k][i][1], _pos_inputs[k][i][2]]\n", "                v_j = [_pos_inputs[k][j][0], _pos_inputs[k][j][1], _pos_inputs[k][j][2]]\n\t            one_edge += v_i\n\t            one_edge += v_j\n\t            if (env_mode == 'Area'):\n\t                area_ij = edge_inputs[k][idx]\n\t                one_edge.append(area_ij)\n\t                if (area_ij > 0): \n\t                    mask[i, idx + num_points], mask[j, idx + num_points] = True, True\n\t                    mask[idx + num_points, i], mask[idx + num_points, j] = True, True\n\t            if (env_mode == 'DT'):\n", "                d_ij = edge_inputs[k][idx * 2]\n\t                t_ij = edge_inputs[k][idx * 2 + 1]\n\t                one_edge.append(d_ij)\n\t                one_edge.append(t_ij)\n\t                if (d_ij > 0): \n\t                    mask[i, idx + num_points], mask[j, idx + num_points] = True, True\n\t                    mask[idx + num_points, i], mask[idx + num_points, j] = True, True\n\t            idx += 1\n\t            i += 1\n\t            if i == j:\n", "                i = 0\n\t                j += 1\n\t            one_output.append(one_edge)\n\t        outputs.append(one_output)\n\t        masks[k] = mask\n\t    return torch.Tensor(outputs).cuda(), masks.cuda()\n\tdef NodeEmbedding(pos_inputs, force_inputs, num_points): #TODO: check it \n\t    _pos_inputs = pos_inputs.reshape(pos_inputs.shape[0], num_points, -1) \n\t    _force_inputs = force_inputs.reshape(force_inputs.shape[0], num_points, -1)\n\t    return torch.cat([_pos_inputs, _force_inputs], dim=-1)\n", "# for flat_input, output is a sequence of tuple with size 5, each one is (P1.x, P1.y, P2.x, P2.y, area)\n\tdef Dim2EdgeEmbedding(flat_input, num_points): #UNUSED\n\t    UseNormalizationEdge = False\n\t    if UseNormalizationEdge:\n\t        NormalizationEdge = 1000\n\t    else:\n\t        NormalizationEdge = 1\n\t    output = []\n\t    obs_action_dim = flat_input.size()[1]\n\t    num_edges = int(num_points * (num_points - 1) / 2)\n", "    obs_dim = num_points * 2 + num_edges\n\t    act_dim = obs_action_dim - obs_dim\n\t    fixed_points = int((obs_dim - act_dim) / 2)\n\t    for one_input in flat_input:\n\t        points = []\n\t        changed_points = []\n\t        for i in range(num_points):\n\t            points.append([one_input[2 * i], one_input[2 * i + 1]])\n\t        for i in range(num_points):\n\t            if i < fixed_points:\n", "                changed_points.append(points[i])\n\t            else:\n\t                changed_points.append([points[i][0] + one_input[(i - fixed_points) * 2 + obs_dim], points[i][1] + one_input[(i - fixed_points) * 2 + obs_dim + 1]])\n\t        together_edges = []\n\t        edges = []\n\t        changed_edges = []\n\t        idx = 2 * num_points\n\t        changed_idx = obs_dim + 2 * (num_points - fixed_points)\n\t        i = 0\n\t        j = 1\n", "        while idx < obs_dim:\n\t            one_edge = []\n\t            one_edge += points[i]\n\t            one_edge += points[j]\n\t            one_edge.append(one_input[idx] * NormalizationEdge)\n\t            edges.append(one_edge)\n\t            one_changed_edge = []\n\t            one_changed_edge += changed_points[i]\n\t            one_changed_edge += changed_points[j]\n\t            one_changed_edge.append(one_input[changed_idx] * NormalizationEdge + one_input[idx] * NormalizationEdge)\n", "            changed_edges.append(one_changed_edge)\n\t            together_edges.append(one_edge)\n\t            together_edges.append(one_changed_edge)\n\t            idx += 1\n\t            changed_idx += 1\n\t            i += 1\n\t            if i >= j:\n\t                j += 1\n\t                i = 0\n\t        output.append(edges + [[-1, -1, -1, -1, -1],] + changed_edges)\n", "        #output.append(together_edges)\n\t    return torch.Tensor(output)\n\tclass Toy_Value_Network(nn.Module):\n\t    def __init__(self, input_dims, hidden_dims):\n\t        super(Toy_Value_Network, self).__init__()\n\t        self.linear1 = nn.Linear(input_dims, hidden_dims)\n\t        self.ReLU = nn.ReLU()\n\t        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n\t        self.dropout = nn.Dropout(0.2)\n\t        self.valid_head = nn.Linear(hidden_dims, 2)\n", "        self.value_head = nn.Linear(hidden_dims, 1)\n\t    def forward(self, *inputs, **kwargs): \n\t        flat_inputs = torch.cat(inputs, dim = -1).cuda()\n\t        hidden = self.linear1(flat_inputs)\n\t        hidden = self.ReLU(self.dropout(hidden))\n\t        hidden = self.linear2(hidden)\n\t        hidden = self.ReLU(self.dropout(hidden))\n\t        valid = self.valid_head(hidden)\n\t        value = self.value_head(hidden)\n\t        return valid, value\n", "if __name__ == '__main__':\n\t    qf = GNNEMBED([128, 256], [256, 512], 3, 'Area', 7).cuda()\n\t    qf(torch.ones(1, 39).cuda())\n"]}
{"filename": "Stage2/models/value_function/mlp_autoregression.py", "chunked_list": ["import torch, os, math\n\timport numpy as np\n\tfrom torch import nn\n\tfrom torch.nn import functional as F\n\tfrom rlkit.policies.base import Policy\n\tfrom rlkit.pythonplusplus import identity\n\tfrom rlkit.torch import pytorch_util as ptu\n\tfrom rlkit.torch.core import PyTorchModule, eval_np\n\tfrom rlkit.torch.data_management.normalizer import TorchFixedNormalizer\n\tfrom rlkit.torch.networks import LayerNorm, ConcatMlp, Mlp\n", "from rlkit.torch.pytorch_util import activation_from_string\n\tclass MLP(ConcatMlp):\n\t    def __init__(self, input_dim, hidden_dims):\n\t        super().__init__(input_size=input_dim, output_size=1, hidden_sizes=hidden_dims)\n\tclass _Mlp(Mlp):\n\t    def __init__(self, *args, dim=1, **kwargs):\n\t        super().__init__(*args, **kwargs)\n\t        self.dim = dim\n\tclass TRANSFORMEREMBED(_Mlp):\n\t    \"\"\"\n", "        represented by edge sequences --> MLP embed to high dim --> transformer --> MLP to dim 1\n\t    \"\"\"\n\t    def __init__(self, input_dims, hidden_dims):\n\t        super().__init__(input_size=input_dims[-1], output_size=1, hidden_sizes=hidden_dims)\n\t        self.embed_dim = input_dims[-1]\n\t        #print(input_dims[-1])\n\t        #print(input_dims[:-1])\n\t        self.embed = Mlp(hidden_sizes=input_dims[:-1], output_size=self.embed_dim, input_size=5)\n\t        self.transformer = nn.Transformer(d_model=self.embed_dim, nhead=4, num_encoder_layers=2)\n\t    def forward(self, *inputs, **kwargs):\n", "        flat_inputs = torch.cat(inputs, dim=self.dim)\n\t        obs_dim = inputs[0].shape[1]\n\t        num_points = int((math.sqrt(9 + 8 * (obs_dim - 2)) -  3) / 2)\n\t        outputs = Dim2EdgeEmbedding(flat_inputs, num_points).transpose(0, 1).cuda()\n\t        #print('1', outputs.shape)\n\t        outputs = self.embed(outputs)\n\t        #print('2', outputs.shape)\n\t        tgt = (torch.ones((outputs.shape[1], 1, self.embed_dim)).transpose(0, 1) / math.sqrt(self.embed_dim)).cuda()\n\t        #print('3', tgt)\n\t        outs = self.transformer(outputs, tgt).transpose(0, 1).squeeze(dim=1)\n", "        #print('4', outs)\n\t        #print('outs shape', outs.shape)\n\t        return super().forward(outs, **kwargs)\n\t# for flat_input, output is a sequence of tuple with size 5, each one is (P1.x, P1.y, P2.x, P2.y, area)\n\tdef Dim2EdgeEmbedding(flat_input, num_points):\n\t    output = []\n\t    obs_action_dim = flat_input.size()[1]\n\t    num_edges = int(num_points * (num_points - 1) / 2)\n\t    obs_dim = num_points * 2 + num_edges\n\t    act_dim = obs_action_dim - obs_dim\n", "    fixed_points = int((obs_dim - act_dim) / 2)\n\t    for one_input in flat_input:\n\t        for i in one_input:\n\t            print(i)\n\t        os._exit(0)\n\t        points = []\n\t        changed_points = []\n\t        for i in range(num_points):\n\t            points.append([one_input[2 * i], one_input[2 * i + 1]])\n\t        for i in range(num_points):\n", "            if i < fixed_points:\n\t                changed_points.append(points[i])\n\t            else:\n\t                changed_points.append([points[i][0] + one_input[(i - fixed_points) * 2 + obs_dim], points[i][1] + one_input[(i - fixed_points) * 2 + obs_dim + 1]])\n\t        together_edges = []\n\t        edges = []\n\t        changed_edges = []\n\t        idx = 2 * num_points\n\t        changed_idx = obs_dim + 2 * (num_points - fixed_points)\n\t        i = 0\n", "        j = 1\n\t        while idx < obs_dim:\n\t            one_edge = []\n\t            one_edge += points[i]\n\t            one_edge += points[j]\n\t            one_edge.append(one_input[idx])\n\t            edges.append(one_edge)\n\t            one_changed_edge = []\n\t            one_changed_edge += changed_points[i]\n\t            one_changed_edge += changed_points[j]\n", "            one_changed_edge.append(one_input[changed_idx] + one_input[idx])\n\t            changed_edges.append(one_changed_edge)\n\t            together_edges.append(one_edge)\n\t            together_edges.append(one_changed_edge)\n\t            idx += 1\n\t            changed_idx += 1\n\t            i += 1\n\t            if i >= j:\n\t                j += 1\n\t                i = 0\n", "        output.append(edges + [[-1, -1, -1, -1, -1],] + changed_edges)\n\t        #output.append(together_edges)\n\t    return torch.Tensor(output)\n"]}
{"filename": "Stage2/envs/env_test.py", "chunked_list": ["from .env import Truss\n\tif __name__ == '__main__':\n\t    num_points = 6\n\t    initial_state_files = 'best_results'\n\t    coordinate_range = [(0.0, 18.288), (0.0, 9.144)]\n\t    area_range = (6.452e-05, 0.02)\n\t    coordinate_delta_range = [(-0.5715, 0.5715), (-0.5715, 0.5715)]\n\t    area_delta_range = (-0.0005, 0.0005)\n\t    fixed_points = 4\n\t    variable_edges = -1\n", "    max_refine_steps = 1000\n\t    env = Truss(num_points, initial_state_files, coordinate_range, area_range, coordinate_delta_range, area_delta_range, fixed_points, variable_edges, max_refine_steps)\n\t    while True:\n\t        env.reset()\n"]}
{"filename": "Stage2/envs/space.py", "chunked_list": ["import numpy as np\n\timport gym\n\tclass ActionSpace(gym.spaces.Box):\n\t    def __init__(\n\t        self,\n\t        num_points,\n\t        coordinate_delta_range,\n\t        area_delta_range,\n\t        fixed_points,\n\t        variable_edges,\n", "    ):\n\t        r'''\n\t        :param num_points: Total number of points\n\t        :param coordinate_delta_range: Actions' coordinate delta range, a list of length D, where D is the dimension of the environment, each element is a tuple of (low, high)\n\t        :param area_delta_range: Actions' area delta range (low, high)\n\t        :param fixed_points: Number of points whose coordinate cannot be modified (first #fixed_points nodes)\n\t        :param variable_edges: Number of edges whose area can be modified, -1 if all can be modified (first #variable_edges edges)\n\t        '''\n\t        single_low = [cr[0] for cr in coordinate_delta_range]\n\t        single_high = [cr[1] for cr in coordinate_delta_range]\n", "        low = []\n\t        high = []\n\t        edge_num = num_points * (num_points - 1) // 2\n\t        if variable_edges != -1:\n\t            edge_num = variable_edges\n\t        for _ in range(num_points - fixed_points):\n\t            low += single_low\n\t            high += single_high\n\t        for _ in range(edge_num):\n\t            low.append(area_delta_range[0])\n", "            high.append(area_delta_range[1])\n\t        super().__init__(low=np.array(low), high=np.array(high), dtype=np.float64)\n\tclass AutoregressiveEnvActionSpace(gym.spaces.Box): #TODO: change area into d, t \n\t    def __init__(\n\t        self,\n\t        coordinate_delta_range,\n\t        range1,\n\t        range2 = None,\n\t    ):\n\t        r'''\n", "        :param coordinate_delta_range: Actions' coordinate delta range, a list of length D, where D is the dimension of the environment, each element is a tuple of (low, high)\n\t        :param area_delta_range: Actions' area delta range (low, high)\n\t        '''\n\t        low = [cr[0] for cr in coordinate_delta_range]\n\t        high = [cr[1] for cr in coordinate_delta_range]\n\t        low.append(range1[0])\n\t        high.append(range1[1])\n\t        if (range2 != None):\n\t            low.append(range2[0])\n\t            high.append(range2[1])\n", "        super().__init__(low=np.array(low), high=np.array(high), dtype=np.float64)\n\tclass StateObservationSpace(gym.spaces.Box):\n\t    def __init__(\n\t        self,\n\t        num_points,\n\t        coordinate_range,\n\t        range1,\n\t        range2 = None,\n\t    ):\n\t        r'''\n", "        :param num_points: Total number of points\n\t        :param coordinate_range: nodes' coordinate range, a list of length D, where D is the dimension of the environment, each element is a tuple of (low, high)\n\t        :param area_range: edges' area range (low, high)\n\t        '''\n\t        single_low = [cr[0] for cr in coordinate_range]\n\t        single_high = [cr[1] for cr in coordinate_range]\n\t        low = []\n\t        high = []\n\t        edge_num = num_points * (num_points - 1) // 2\n\t        for _ in range(num_points):\n", "            low += single_low\n\t            high += single_high\n\t        for _ in range(edge_num):\n\t            low.append(range1[0])\n\t            high.append(range1[1])\n\t            if (range2 != None):\n\t                low.append(range2[0])\n\t                high.append(range2[1])\n\t        super().__init__(low=np.array(low), high=np.array(high), dtype=np.float64)\n\tclass AutoregressiveEnvObservationSpace(gym.spaces.Box):\n", "    def __init__(\n\t        self,\n\t        num_points,\n\t        coordinate_range,\n\t        range1,\n\t        range2 = None,\n\t    ):\n\t        r'''\n\t        :param num_points: Total number of points\n\t        :param coordinate_range: nodes' coordinate range, a list of length D, where D is the dimension of the environment, each element is a tuple of (low, high)\n", "        :param area_range: edges' area range (low, high)\n\t        '''\n\t        single_low = [cr[0] for cr in coordinate_range]\n\t        single_high = [cr[1] for cr in coordinate_range]\n\t        low = []\n\t        high = []\n\t        edge_num = num_points * (num_points - 1) // 2\n\t        for _ in range(num_points):\n\t            low += single_low\n\t            high += single_high\n", "        for _ in range(edge_num):\n\t            low.append(range1[0])\n\t            high.append(range1[1])\n\t            if (range2 != None):\n\t                low.append(range2[0])\n\t                high.append(range2[1])\n\t        for _ in range(num_points):\n\t            low.append(-1000000)\n\t            high.append(1000000)\n\t        low.append(-1)\n", "        high.append(num_points)\n\t        low.append(-1)\n\t        high.append(num_points * (num_points - 1) // 2)\n\t        low.append(-1)\n\t        high.append(1)\n\t        super().__init__(low=np.array(low), high=np.array(high), dtype=np.float64)"]}
{"filename": "Stage2/envs/state.py", "chunked_list": ["import numpy as np\n\tclass State:\n\t    def __init__(self, num_points, dimension, env_mode):\n\t        self.num_points = num_points\n\t        self.dimension = dimension\n\t        self.env_mode = env_mode\n\t        self.nodes = -np.ones((num_points, dimension), dtype=np.float64)\n\t        if (env_mode == 'Area'):\n\t            self.edges = -np.ones((num_points, num_points), dtype=np.float64)\n\t        if (env_mode == 'DT'):\n", "            self.edges = -np.ones((num_points, num_points, 2), dtype=np.float64)\n\t    def obs(self, nonexistent_edge = -1):\n\t        r'''\n\t        transfer self.state to observation\n\t        :param nonexistent_edge: area value of nonexistent edge\n\t        :return: list, a tuple containing nodes coordinates and edges area\n\t        '''\n\t        if (self.env_mode == 'Area'):\n\t            obs = np.zeros(self.num_points * self.dimension + self.num_points * (self.num_points - 1) // 2, dtype=np.float64)\n\t            for i in range(self.num_points):\n", "                obs[i * self.dimension: (i + 1) * self.dimension] = self.nodes[i]\n\t            loc = self.num_points * self.dimension\n\t            for i in range(self.num_points):\n\t                for j in range(i + 1, self.num_points):\n\t                    obs[loc] = nonexistent_edge if self.edges[i][j] < 0 else self.edges[i][j]\n\t                    loc += 1\n\t        elif (self.env_mode == 'DT'):\n\t            obs = np.zeros(self.num_points * self.dimension + self.num_points * (self.num_points - 1), dtype=np.float64)\n\t            for i in range(self.num_points):\n\t                obs[i * self.dimension: (i + 1) * self.dimension] = self.nodes[i]\n", "            loc = self.num_points * self.dimension\n\t            for i in range(self.num_points):\n\t                for j in range(i + 1, self.num_points):\n\t                    obs[loc: loc + 2] = nonexistent_edge if self.edges[i][j][0] < 0 else self.edges[i][j][0 : 2]\n\t                    loc += 2\n\t        return obs\n\t    def set(self, obs):\n\t        r'''\n\t        set self.state according to obs, do not set nonexistent edges. Warning: obs must set 1 for nonexistent edges\n\t        :param obs: observation\n", "        :return: None\n\t        '''\n\t        for i in range(self.num_points):\n\t            self.nodes[i] = obs[i * self.dimension: (i + 1) * self.dimension]\n\t        loc = self.num_points * self.dimension\n\t        if (self.env_mode == 'Area'):\n\t            for i in range(self.num_points):\n\t                for j in range(i + 1, self.num_points):\n\t                    self.edges[i][j] = obs[loc]\n\t                    self.edges[j][i] = obs[loc]\n", "                    loc += 1\n\t        elif (self.env_mode == 'DT'):\n\t            for i in range(self.num_points):\n\t                for j in range(i + 1, self.num_points):\n\t                    self.edges[i][j][0] = obs[loc]\n\t                    self.edges[j][i][0] = obs[loc]\n\t                    self.edges[i][j][1] = obs[loc + 1]\n\t                    self.edges[j][i][1] = obs[loc + 1]\n\t                    loc += 2\n\t    def print(self):\n", "        for i in range(self.num_points):\n\t            print(self.nodes[i])\n\t        if (self.env_mode == 'Area'):\n\t            for i in range(self.num_points):\n\t                for j in range(i + 1, self.num_points):\n\t                    print(i, j, self.edges[i][j])\n\t        if (self.env_mode == 'DT'):\n\t            for i in range(self.num_points):\n\t                for j in range(i + 1, self.num_points):\n\t                    print(i, j, self.edges[i][j][0], self.edges[i][j][1])\n"]}
{"filename": "Stage2/envs/__init__.py", "chunked_list": ["from .env import Truss\n"]}
{"filename": "Stage2/envs/env.py", "chunked_list": ["import gym\n\timport copy\n\timport os\n\timport numpy as np\n\timport random\n\tfrom collections import OrderedDict\n\tfrom .space import StateObservationSpace, AutoregressiveEnvObservationSpace, AutoregressiveEnvActionSpace, ActionSpace\n\tfrom utils.utils import is_edge_addable, readFile, getlen2, save_file, save_trajectory\n\tfrom truss_envs.dynamic import DynamicModel\n\tfrom .state import State\n", "class Truss(gym.Env):\n\t    def __init__(self, args, num_points, initial_state_files,\n\t                 coordinate_range, area_range, coordinate_delta_range, area_delta_range, fixed_points, variable_edges,\n\t                 max_refine_steps,\n\t                 min_refine_steps=10,\n\t                 dimension=2, constraint_threshold=1e-7, best_n_results=5,\n\t                 structure_fail_reward=-50., constraint_fail_reward=-10., reward_lambda=169000000,\n\t                 best=10000, save_good_threshold=0, normalize_magnitude=False):\n\t        r'''\n\t        Create a Truss Refine environment instance.\n", "        :param num_points: number of nodes\n\t        :param initial_state_files: locations where initial states are stored\n\t        :param coordinate_range: nodes' coordinate range\n\t        :param area_range: edges' area range\n\t        :param coordinate_delta_range: nodes' modification range\n\t        :param area_delta_range: edges' modification range\n\t        :param max_refine_steps: max refine steps\n\t        :param min_refine_steps: another refine steps threshold\n\t        :param edge_constraint: intersection of edges\n\t        :param dis_constraint: nodes' displacement weight\n", "        :param stress_constraint: edges' stress\n\t        :param buckle_constraint: buckle constraint\n\t        :param self_weight: edge's weight\n\t        :param dimension: dimension\n\t        :param constraint_threshold: eps to check constraint\n\t        :param best_n_results: choose best_n_results from initial_state_files\n\t        :param structure_fail_reward: structure fail reward\n\t        :param constraint_fail_reward: constraint fail reward\n\t        :param reward_lambda: reward lambda\n\t        :param best: initial best weight\n", "        :param save_good_threshold: threshold over best weight to best\n\t        :param normalize_magnitude: normalize observation's magnitude\n\t        '''\n\t        if dimension != 2 and dimension != 3:\n\t            raise NotImplementedError(\"only support 2D / 3D dimension for now\")\n\t        # Env Config\n\t        self.num_points = num_points\n\t        self.dimension = dimension\n\t        self.fixed_points = fixed_points\n\t        self.normalize_magnitude = normalize_magnitude\n", "        self.only_position = args.only_position # if True, do not change edges' area unless greedy upd step.\n\t        self.greedy_upd = args.greedy_upd\n\t        self.global_env_step = 0\n\t        if (args.useAlist): # only 3d case\n\t            self.alist = []\n\t            AREAFILE = args.Alist_path\n\t            with open(AREAFILE,'r') as ar:\n\t                section_lines = ar.readlines()\n\t                for i in range(len(section_lines)):\n\t                    section_line = section_lines[i]\n", "                    section_r = section_line.strip().split(' ')\n\t                    if (i==0):\n\t                        section_num = int(section_r[0])\n\t                        continue\n\t                    if (i > 0 and i <= section_num):\n\t                        d = float(section_r[0]) / 1000.0\n\t                        t = float(section_r[1]) / 1000.0\n\t                        self.alist.append((d, t))\n\t        else: # only 2d case\n\t            area_range = args.area_range\n", "            delta = (area_range[1] - area_range[0]) / 50\n\t            self.alist = [area_range[0] + delta * i for i in range(51)]\n\t        if args.env_mode == 'Area':\n\t            self.state_observation_space = StateObservationSpace(num_points, coordinate_range, area_range)\n\t            self.env_observation_space = AutoregressiveEnvObservationSpace(num_points, coordinate_range, area_range)\n\t            self.action_space = AutoregressiveEnvActionSpace(coordinate_delta_range, area_delta_range)\n\t        elif args.env_mode == 'DT':\n\t            self.state_observation_space = StateObservationSpace(num_points, coordinate_range, args.d_range, args.t_range)\n\t            self.env_observation_space = AutoregressiveEnvObservationSpace(num_points, coordinate_range, args.d_range, args.t_range)\n\t            self.action_space = AutoregressiveEnvActionSpace(coordinate_delta_range, args.d_delta_range, args.t_delta_range)\n", "        else: raise NotImplementedError\n\t        # Initial State\n\t        self.initial_state_files = initial_state_files\n\t        self.logfile = open(os.path.join(self.initial_state_files, args.logfile_stage2), 'w')\n\t        self.best_n_results = best_n_results\n\t        # Done\n\t        self.refine_step = None\n\t        self.max_refine_steps = max_refine_steps\n\t        self.min_refine_steps = min_refine_steps\n\t        # Dynamics\n", "        self.args = args\n\t        self.env_mode = args.env_mode\n\t        self.bad_attempt_limit = args.bad_attempt_limit\n\t        self.use_edge_constraint = args.CONSTRAINT_CROSS_EDGE\n\t        self.use_dis_constraint = args.CONSTRAINT_DIS\n\t        self.use_stress_constraint = args.CONSTRAINT_STRESS\n\t        self.use_buckle_constraint = args.CONSTRAINT_BUCKLE\n\t        self.use_slenderness_constraint = args.CONSTRAINT_SLENDERNESS\n\t        self.use_max_length_constraint = args.CONSTRAINT_MAX_LENGTH\n\t        self.use_min_length_constraint = args.CONSTRAINT_MIN_LENGTH\n", "        self.use_self_weight = args.CONSTRAINT_SELF_WEIGHT\n\t        self.constraint_threshold = constraint_threshold\n\t        self.dynamic_model = DynamicModel(\n\t            dimension = self.dimension, \n\t            use_cross_constraint = self.use_edge_constraint,\n\t            use_self_weight = self.use_self_weight, \n\t            use_dis_constraint = self.use_dis_constraint, \n\t            use_buckle_constraint = self.use_buckle_constraint, \n\t            use_stress_constraint = self.use_stress_constraint,\n\t            use_slenderness_constraint = self.use_slenderness_constraint,\n", "            use_longer_constraint = self.use_max_length_constraint,\n\t            use_shorter_constraint = self.use_min_length_constraint,\n\t            E = args.E,\n\t            pho = args.pho,\n\t            sigma_T = args.sigma_T,\n\t            sigma_C = args.sigma_C,\n\t            dislimit = args.dislimit,\n\t            slenderness_ratio_T = args.slenderness_ratio_t,\n\t            slenderness_ratio_C = args.slenderness_ratio_c,\n\t            max_len = args.len_range[1],\n", "            min_len = args.len_range[0],\n\t        )\n\t        # State\n\t        self.initial_state_file = None\n\t        self.initial_state_point = None\n\t        self.initial_state_bar = None\n\t        self.initial_state_mass = None\n\t        self.state = State(num_points, dimension, args.env_mode)\n\t        self.state_dynamics = None\n\t        self.prev_mass = None\n", "        self.prev_reward = None\n\t        self.action_id = None\n\t        self.trajectory = None\n\t        self.loads = None\n\t        self.normalize_factor = None\n\t        self.last_id = 0\n\t        # Reward\n\t        self.structure_fail_reward = structure_fail_reward\n\t        self.constraint_fail_reward = constraint_fail_reward\n\t        self.reward_lambda = reward_lambda\n", "        # Result\n\t        self.best = best\n\t        self.save_good_threshold = save_good_threshold\n\t    @property\n\t    def observation_space(self):\n\t        return self.env_observation_space\n\t    def _reward_fn(self):\n\t        is_struct, mass, dis_value, stress_value, buckle_value = self.state_dynamics\n\t        extra_reward = 0\n\t        if not is_struct:\n", "            extra_reward += self.structure_fail_reward\n\t        if max(dis_value, stress_value, buckle_value) > self.constraint_threshold:\n\t            extra_reward += self.constraint_fail_reward\n\t        reward = self.reward_lambda / ((mass * (1 + dis_value + stress_value + buckle_value)) ** 2)\n\t        return reward, extra_reward\n\t    def _stop_fn(self, reward_step):\n\t        if (self.refine_step >= self.max_refine_steps): return True\n\t        if (reward_step <= self.constraint_fail_reward):\n\t            self.bad_attempt += 1\n\t        return self.bad_attempt >= self.bad_attempt_limit #and self.refine_step >= self.min_refine_steps\n", "    def valid_truss(self):\n\t        r'''\n\t        check whether self.state is valid\n\t        :return: a list of four bools, a tuple of dynamics\n\t        '''\n\t        ret = [True for _ in range(4)]\n\t        if (self.env_mode == 'Area'):\n\t            if not self.state_observation_space.contains(self.state.obs(nonexistent_edge=self.state_observation_space.low[-1])):\n\t                ret[0] = False  # Not in valid observation\n\t        if (self.env_mode == 'DT'):\n", "            if not self.state_observation_space.contains(self.state.obs(nonexistent_edge=self.state_observation_space.low[-2:])):\n\t                ret[0] = False  # Not in valid observation\n\t        for i in range(self.num_points):\n\t            for j in range(i):\n\t                if (self.state.nodes[i] == self.state.nodes[j]).all():\n\t                    ret[1] = False  # Duplicate nodes location\n\t        points = copy.deepcopy(self.initial_state_point)\n\t        for i in range(self.num_points):\n\t            points[i].vec.x = self.state.nodes[i][0]\n\t            points[i].vec.y = self.state.nodes[i][1]\n", "            if self.dimension == 3:\n\t                points[i].vec.z = self.state.nodes[i][2]\n\t        edges = copy.deepcopy(self.initial_state_bar)\n\t        edges_list = []\n\t        for i in range(self.num_points):\n\t            for j in range(i):\n\t                if (self.env_mode == 'Area'):\n\t                    if self.state.edges[i][j] > 0:\n\t                        edges[(j, i)]._area = self.state.edges[i][j]\n\t                        edges[(j, i)].len = getlen2(points[j], points[i])\n", "                        edges_list.append((j, i))\n\t                if (self.env_mode == 'DT'):\n\t                    if self.state.edges[i][j][0] > 0:\n\t                        d = self.state.edges[i][j][0]\n\t                        t = self.state.edges[i][j][1]\n\t                        assert (d - 2 * t >= 0)\n\t                        if (d - 2 * t == 0 or t == 0): continue\n\t                        edges[(j, i)].d = d\n\t                        edges[(j, i)].t = t\n\t                        edges[(j, i)].len = getlen2(points[j], points[i])\n", "                        edges_list.append((j, i))\n\t        if self.use_edge_constraint and self.dimension == 2:\n\t            for _ in edges_list:\n\t                i, j = _\n\t                left_edges = copy.deepcopy(edges)\n\t                left_edges.pop((i, j))\n\t                if not is_edge_addable(i, j, points, left_edges):\n\t                    ret[2] = False  # Edges intersect\n\t        is_struct, mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value = self.dynamic_model.run(points, edges, mode = 'train')\n\t        ret[3] = is_struct and max(dis_value, stress_value, buckle_value) < self.constraint_threshold and max(slenderness_value, longer_value, shorter_value, cross_value) <= 0 # Dynamic constraints\n", "        return ret, (is_struct, mass, dis_value, stress_value, buckle_value)\n\t    def reset(self, file_name=None):\n\t        _ = random.random()\n\t        if _ > 0.5:\n\t            best_n_results = self.best_n_results\n\t        else:\n\t            best_n_results = -1\n\t        if file_name is None:\n\t            _input_file_list = os.listdir(self.initial_state_files)\n\t            input_file_list = []\n", "            self.total_diverse_count = dict()\n\t            for s in _input_file_list:\n\t                if s[-3:] == 'txt' and s[0] != '_':\n\t                    input_file_list.append(s)\n\t                    if (self.total_diverse_count.get(int(s[-6: -4])) == None):\n\t                        self.total_diverse_count[int(s[-6: -4])] = 0\n\t                    self.total_diverse_count[int(s[-6: -4])] += 1\n\t            input_file_list.sort(key = lambda x: int(x[:-7]))\n\t            if best_n_results != -1: # maybe a bug, fixed #\n\t                if len(input_file_list) > self.best_n_results:\n", "                    input_file_list = input_file_list[:self.best_n_results]\n\t            choise_id = np.random.randint(len(input_file_list))\n\t            file_name = os.path.join(self.initial_state_files, input_file_list[choise_id])\n\t            self.diverse_id = int(input_file_list[choise_id][-6 : -4])\n\t        #    print(file_name, self.diverse_id)\n\t        #print(\"file_name =\", file_name)\n\t        self.initial_state_file = file_name\n\t        points, edges = readFile(file_name)\n\t        self.initial_state_point = OrderedDict()\n\t        self.initial_state_bar = OrderedDict()\n", "        for i in range(self.num_points):\n\t            self.initial_state_point[i] = points[i]\n\t        for e in edges:\n\t            if e.area < 0:\n\t                continue\n\t            u = e.u\n\t            v = e.v\n\t            if u > v:\n\t                tmp = u\n\t                u = v\n", "                v = tmp\n\t            self.initial_state_bar[(u, v)] = e\n\t        self.state = State(self.num_points, self.dimension, self.env_mode)\n\t        for i in range(self.num_points):\n\t            self.state.nodes[i][0] = points[i].vec.x\n\t            self.state.nodes[i][1] = points[i].vec.y\n\t            if self.dimension == 3:\n\t                self.state.nodes[i][2] = points[i].vec.z\n\t        if (self.env_mode == 'Area'):\n\t            for e in edges:\n", "                i = e.u\n\t                j = e.v\n\t                self.state.edges[i][j] = e.area\n\t                self.state.edges[j][i] = e.area\n\t        if (self.env_mode == 'DT'):\n\t            for e in edges:\n\t                i = e.u\n\t                j = e.v\n\t                self.state.edges[i][j][0] = e.d\n\t                self.state.edges[j][i][0] = e.d\n", "                self.state.edges[i][j][1] = e.t\n\t                self.state.edges[j][i][1] = e.t\n\t        _ = self.valid_truss()\n\t        assert _[0][0] and _[0][1] and _[0][2] and _[0][3], \"Initial state {} not valid\".format(file_name)\n\t        self.state_dynamics = _[1]\n\t        self.prev_mass = _[1][1]\n\t        self.initial_state_mass = _[1][1]\n\t        self.prev_reward, __ = self._reward_fn()\n\t        self.refine_step = 0\n\t        self.total_reward = 0\n", "        self.bad_attempt = 0\n\t        self.trajectory = [copy.deepcopy(self.state)]\n\t        self.loads = []\n\t        for i in range(self.num_points):\n\t            self.loads.append(self.initial_state_point[i].loadY)\n\t        self.normalize_factor = np.array([1. for _ in range(self.num_points * self.dimension)] +\n\t                                         [100. for _ in range(self.num_points * (self.num_points - 1) // 2)] +\n\t                                         [1. for _ in range(2)] +\n\t                                         [1e-5 for _ in range(self.num_points)])\n\t        return self._observation()\n", "    def _observation(self):\n\t        state_obs = self.state.obs()\n\t        self.action_id, self.action_id_one_hot = self._generate_action_id()\n\t        ret = np.concatenate((state_obs, np.array(self.loads), self.action_id))\n\t        if self.normalize_magnitude:\n\t            print(\"ret:\", ret)\n\t            print(\"normalize_factor:\", self.normalize_factor)\n\t            ret = ret * self.normalize_factor\n\t            print(\"new_ret:\", ret)\n\t        return ret\n", "    def _generate_action_id(self):\n\t        point_action = np.zeros(self.num_points, dtype = np.float64)\n\t        edge_action = np.zeros(self.num_points * (self.num_points - 1) // 2, dtype = np.float64)\n\t        greedy_action = np.zeros(1, dtype = np.float64)\n\t        choose = np.random.randint(0, 20)\n\t        if (choose == 0): # now use greedy update\n\t            greedy_action[0] = 1\n\t            return np.array([-1, -1, 1]), np.concatenate([point_action, edge_action, greedy_action])\n\t        if (not self.args.eval):\n\t            id = np.random.randint(self.num_points - self.fixed_points + len(self.initial_state_bar))\n", "        else: \n\t            id = (self.last_id + 1) % self.num_points - self.fixed_points + len(self.initial_state_bar)\n\t            self.last_id += 1\n\t        if id < self.num_points - self.fixed_points or self.only_position == True:\n\t            i = id % (self.num_points - self.fixed_points) + self.fixed_points\n\t            j = -1\n\t            point_action[i] = 1\n\t        else:\n\t            i = -1\n\t            u, v = list(self.initial_state_bar)[id - (self.num_points - self.fixed_points)]\n", "            j = (u * ((self.num_points - 1) + (self.num_points - u)) // 2) + (v - u - 1)\n\t            edge_action[j] = 1\n\t        return np.array([i, j, -1]), np.concatenate([point_action, edge_action, greedy_action])\n\t    def greedy_update(self, obs):\n\t        n_obs = copy.deepcopy(obs)\n\t        for i in range(len(self.initial_state_bar)):\n\t                u, v = list(self.initial_state_bar)[i]\n\t                j = (u * ((self.num_points - 1) + (self.num_points - u)) // 2) + (v - u - 1)\n\t                if (self.env_mode == 'DT'):\n\t                    pos = j * 2 + self.num_points * self.dimension\n", "                else: pos = j + self.num_points * self.dimension\n\t                if (self.env_mode == 'DT'): ori = n_obs[pos: pos + 2].copy()\n\t                if (self.env_mode == 'Area'): ori = n_obs[pos: pos + 1].copy()\n\t                minaera = 1e9\n\t                if (self.alist != None):\n\t                    for j in range(len(self.alist)):\n\t                        if (self.env_mode == 'DT'): n_obs[pos: pos + 2] = self.alist[j]\n\t                        if (self.env_mode == 'Aera'): n_obs[pos: pos + 1] = self.alist[j]\n\t                        self.state.set(n_obs)\n\t                        valid, temp_state_dynamics = self.valid_truss()\n", "                        if (valid[0] and valid[1] and valid[2] and valid[3] and temp_state_dynamics[1] < minaera):\n\t                            minaera = temp_state_dynamics[1]\n\t                            if (self.env_mode == 'DT'): \n\t                                ori[0] = n_obs[pos: pos + 2][0]\n\t                                ori[1] = n_obs[pos: pos + 2][1]\n\t                            else: ori = n_obs[pos: pos + 1].copy()\n\t                    if (self.env_mode == 'DT'): n_obs[pos: pos + 2] = ori.copy()\n\t                    if (self.env_mode == 'Area'): n_obs[pos: pos + 1] = ori.copy()\n\t                else:\n\t                    raise NotImplementedError()\n", "        return n_obs\n\t    def fit_diverse(self, area):\n\t        assert self.env_mode == 'DT'\n\t        min_area = 1e9\n\t        chosed_area = self.alist[-1]\n\t        for d_area in self.alist:\n\t            if (area[0] <= d_area[0] and area[1] <= d_area[1]):\n\t                if (min_area > d_area[0] ** 2 - (d_area[0] - 2 * d_area[1]) ** 2):\n\t                    chosed_area = d_area\n\t                    min_area = d_area[0] ** 2 - (d_area[0] - 2 * d_area[1]) ** 2\n", "        return chosed_area\n\t    def step(self, action):\n\t        self.global_env_step += 1\n\t        if (self.global_env_step % 4000 == 0):\n\t            print(self.global_env_step, self.best, file = self.logfile)\n\t            print(self.global_env_step, self.best)\n\t#            best_path = os.path.join(self.initial_state_files, '_best.txt')\n\t#            save_log_path = os.path.join(self.initial_state_files, '_best_{}.txt'.format(str(self.global_env_step)))\n\t#            os.system('cp {} {}'.format(best_path, save_log_path))\n\t        assert self.action_space.contains(action), \"actions({}) not in action space({})\".format(action, self.action_space)\n", "        obs = self.state.obs(nonexistent_edge=-1)\n\t        n_obs = copy.deepcopy(obs)\n\t        if (self.action_id[2] == 1): # Greedy update\n\t            n_obs = self.greedy_update(n_obs)\n\t        if (self.env_mode == 'Area'):\n\t            if self.action_id[1] != -1:\n\t                _i = int(self.action_id[1]) + self.num_points * self.dimension\n\t                n_obs[_i] += action[-1]\n\t                n_obs[_i] = max(min(n_obs[_i], self.state_observation_space.high[_i]), self.state_observation_space.low[_i])\n\t            if self.action_id[0] != -1:\n", "                n_obs[int(self.action_id[0]) * self.dimension: int(self.action_id[0] + 1) * self.dimension] += action[:-1] # act = [(a, b, c), d]\n\t                for _i in range(int(self.action_id[0]) * self.dimension, int(self.action_id[0] + 1) * self.dimension):\n\t                    n_obs[_i] = max(min(n_obs[_i], self.state_observation_space.high[_i]), self.state_observation_space.low[_i])\n\t        if (self.env_mode == 'DT'):\n\t            if self.action_id[1] != -1:\n\t                _i = int(self.action_id[1]) * 2 + self.num_points * self.dimension\n\t                n_obs[_i: _i + 2] += action[-2:]\n\t                n_obs[_i] = max(min(n_obs[_i], self.state_observation_space.high[_i]), self.state_observation_space.low[_i])\n\t                n_obs[_i + 1] = max(min(n_obs[_i + 1], self.state_observation_space.high[_i + 1]), self.state_observation_space.low[_i + 1])\n\t                n_obs[_i: _i + 2] = self.fit_diverse(n_obs[_i: _i + 2])\n", "                n_obs[_i + 1] = min(n_obs[_i + 1], n_obs[_i] / 2)\n\t            if self.action_id[0] != -1:\n\t                n_obs[int(self.action_id[0]) * self.dimension: int(self.action_id[0] + 1) * self.dimension] += action[:-2] # act = [(a, b, c), (d, e)]\n\t                for _i in range(int(self.action_id[0]) * self.dimension, int(self.action_id[0] + 1) * self.dimension):\n\t                    n_obs[_i] = max(min(n_obs[_i], self.state_observation_space.high[_i]), self.state_observation_space.low[_i])                \n\t        self.state.set(n_obs)\n\t        self.trajectory.append(copy.deepcopy(self.state))\n\t        info = {}\n\t        info['illegal action'] = 0\n\t        valid, self.state_dynamics = self.valid_truss()\n", "        reward, extra_reward = self._reward_fn()\n\t        if not (valid[0] and valid[1] and valid[2]):\n\t            info['illegal action'] = 1\n\t            extra_reward += self.structure_fail_reward # check whether go out the boundary\n\t        if (extra_reward != 0):\n\t            reward_step = extra_reward # not satisfy the constraint\n\t        else: \n\t            reward_step = reward - self.prev_reward\n\t            self.prev_reward = reward # delta reward\n\t        mass = self.state_dynamics[1]\n", "        self.prev_mass = mass\n\t        if not (valid[0] and valid[1] and valid[2] and valid[3]): mass = 10000\n\t        done = self._stop_fn(reward_step)\n\t        info['is struct'] = self.state_dynamics[0]\n\t        info['mass'] = mass # if illegal, set to 10000\n\t        info['displacement'] = self.state_dynamics[2]\n\t        info['stress'] = self.state_dynamics[3]\n\t        info['buckle'] = self.state_dynamics[4]\n\t        info['initial_state_file'] = self.initial_state_file\n\t        self.refine_step += 1\n", "        self.total_reward += reward_step\n\t        if (valid[0] and valid[1] and valid[2] and valid[3]):\n\t            if mass < self.best + self.save_good_threshold:\n\t                self.total_diverse_count[self.diverse_id] += 1\n\t                if mass < self.best:\n\t                    # if mass < self.best - 1:\n\t                    #     save_trajectory(self.initial_state_point, self.trajectory, mass, self.initial_state_files)\n\t                    print(\"best:\", mass)\n\t                    self.best = mass\n\t                    save_file(self.initial_state_point, self.state, mass, self.initial_state_files, self.env_mode, best = True)\n", "                max_count = self.best_n_results\n\t                if (self.args.eval): max_count = 1\n\t                if (self.total_diverse_count[self.diverse_id] > max_count):\n\t                    self.total_diverse_count[self.diverse_id] -= 1\n\t                    os.remove(self.initial_state_file)\n\t                    save_file(self.initial_state_point, self.state, mass, self.initial_state_files, self.env_mode, diverse_id = self.diverse_id)\n\t                    self.initial_state_file = os.path.join(self.initial_state_files, str(int(mass * 1000)) + \"_\" + str(self.diverse_id).zfill(2) + \".txt\")\n\t                    self.initial_state_mass = mass\n\t                    points, edges = readFile(self.initial_state_file)\n\t                    self.initial_state_point = OrderedDict()\n", "                    self.initial_state_bar = OrderedDict()\n\t                    for i in range(self.num_points): self.initial_state_point[i] = points[i]\n\t                    for e in edges:\n\t                        if e.area < 0: continue\n\t                        u = e.u\n\t                        v = e.v\n\t                        if u > v:\n\t                            tmp = u\n\t                            u = v\n\t                            v = tmp\n", "                        self.initial_state_bar[(u, v)] = e\n\t                else:\n\t                    save_file(self.initial_state_point, self.state, mass, self.initial_state_files, self.env_mode, diverse_id = self.diverse_id)\n\t            elif mass + 0.01 < self.initial_state_mass: \n\t                os.remove(self.initial_state_file)\n\t                save_file(self.initial_state_point, self.state, mass, self.initial_state_files, self.env_mode, diverse_id = self.diverse_id)\n\t                self.initial_state_file = os.path.join(self.initial_state_files, str(int(mass * 1000)) + \"_\" + str(self.diverse_id).zfill(2) + \".txt\")\n\t                self.initial_state_mass = mass\n\t                points, edges = readFile(self.initial_state_file)\n\t                self.initial_state_point = OrderedDict()\n", "                self.initial_state_bar = OrderedDict()\n\t                for i in range(self.num_points):\n\t                    self.initial_state_point[i] = points[i]\n\t                for e in edges:\n\t                    if e.area < 0: continue\n\t                    u = e.u\n\t                    v = e.v\n\t                    if u > v:\n\t                        tmp = u\n\t                        u = v\n", "                        v = tmp\n\t                    self.initial_state_bar[(u, v)] = e\n\t        return self._observation(), reward_step, done, info\n"]}
{"filename": "Stage2/envs/dynamic2.py", "chunked_list": ["import numpy as np\n\tfrom collections import OrderedDict\n\timport math\n\timport sys, os, time\n\timport openseespy.opensees as op\n\timport matplotlib.pyplot as plt\n\tfrom utils.utils import readFile\n\tdef blockPrint():\n\t    sys.stdout = open(os.devnull, 'w')\n\t    sys.stderr = open(os.devnull, 'w')\n", "def enablePrint():\n\t    sys.stdout = sys.__stdout__\n\t    sys.stderr = sys.__stderr__\n\tclass DynamicModel:\n\t    #构造函数\n\t    def __init__(self,\n\t                dimension,\n\t                E=193*10**9,          #N/m2\n\t                pho=8.0*10**3,        #kg/m3\n\t                sigma_T=123*10**6,    #N/m2\n", "                sigma_C=213*10**6,    #N/m2\n\t                dislimit=0.002,       #m\n\t                slenderness_ratio_T=220,\n\t                slenderness_ratio_C=180,\n\t                max_len=5.0,            #m\n\t                min_len=0.03,         #m\n\t                use_self_weight=True,\n\t                use_dis_constraint=True,\n\t                use_stress_constraint=True,\n\t                use_buckle_constraint=True,\n", "                use_slenderness_constraint=True,\n\t                use_longer_constraint=True,\n\t                use_shorter_constraint=True,\n\t                use_cross_constraint=True,\n\t                ): \n\t        self._dimension = dimension    #结构维度\n\t        self._E = E                    #弹性模量\n\t        self._pho = pho                #材料密度\n\t        self._sigma_T = sigma_T        #容许拉应力\n\t        self._sigma_C = sigma_C        #容许压应力\n", "        self._limit_dis = dislimit     #容许位移\n\t        self.slenderness_ratio_T=slenderness_ratio_T #容许受拉长细比\n\t        self.slenderness_ratio_C=slenderness_ratio_C #容许受压长细比\n\t        self.max_len=max_len                         #最大长度\n\t        self.min_len=min_len                         #最小长度\n\t        self._use_self_weight = use_self_weight              #是否计算自重\n\t        self._use_dis_constraint = use_dis_constraint        #是否启用位移约束\n\t        self._use_stress_constraint = use_stress_constraint         #是否启用应力约束\n\t        self._use_buckle_constraint = use_buckle_constraint         #是否启用屈曲约束\n\t        self._use_slenderness_constraint=use_slenderness_constraint #是否启用长细比约束\n", "        self._use_longer_constraint=use_longer_constraint           #是否启用超长约束\n\t        self._use_shorter_constraint=use_shorter_constraint         #是否启用过短约束\n\t        self._use_cross_constraint=use_cross_constraint             #是否启用杆件交叉约束\n\t    #判定结构的几何不变性+分析计算\n\t    def _is_struct(self, points, edges):\n\t        ########计算自由度初判结构几何不变性##########\n\t        total_support = 0             #保存支座约束数\n\t        for p in points:\n\t            if self._dimension == 2:  #平面桁架\n\t                total_support += (\n", "                    p.supportX\n\t                    + p.supportY\n\t                )\n\t            else:                     #空间桁架\n\t                total_support += (\n\t                    p.supportX\n\t                    + p.supportY\n\t                    + p.supportZ\n\t                )\n\t        if len(points) * self._dimension - len(edges) - total_support > 0:\n", "            return (False)   #计算自由度>0，结构不稳定直接返回False\n\t        blockPrint()\n\t        #######以下基于点和边集建立有限元模形分析########\n\t        op.wipe()   # 清除所有已有结构\n\t        op.model('basic', '-ndm', self._dimension, '-ndf', self._dimension)  #设置建模器\n\t        for i, point in enumerate(points):   #建立节点\n\t            if self._dimension == 2:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n", "                    point.vec.y,\n\t                )\n\t            else:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n\t                    point.vec.z,\n\t                )\n\t        for i, point in enumerate(points):  #施加节点支座约束\n", "            if point.isSupport:\n\t                if self._dimension == 2:\n\t                    op.fix(\n\t                        i,\n\t                        point.supportX,\n\t                        point.supportY,\n\t                    )\n\t                else:\n\t                    op.fix(\n\t                        i,\n", "                        point.supportX,\n\t                        point.supportY,\n\t                        point.supportZ,\n\t                    )\n\t        op.timeSeries(\"Linear\", 1)\n\t        op.pattern(\"Plain\", 1, 1)\n\t        for i, point in enumerate(points):  #添加节点荷载\n\t            if point.isLoad:\n\t                if self._dimension == 2:\n\t                    op.load(\n", "                        i,\n\t                        point.loadX,\n\t                        point.loadY,\n\t                    )\n\t                else:\n\t                    op.load(\n\t                        i,\n\t                        point.loadX,\n\t                        point.loadY,\n\t                        point.loadZ,\n", "                    )\n\t        op.uniaxialMaterial(\"Elastic\", 1, self._E)   #定义材料\n\t        for i, edge in enumerate(edges):\n\t            op.element(\"Truss\", i, edge.u, edge.v, edge.area, 1)  #赋予杆件截面属性\n\t        if self._use_self_weight:  #如果计算自重时\n\t            gravity = 9.8   #重力加速度\n\t            load_gravity = [0 for _ in range(len(points))]  #初始化了一个load_gravity列表，表征杆件自重的等效结点力，len(points)个元素均为0\n\t            for i, edge in enumerate(edges):\n\t                edge_mass = edge.len * edge.area * self._pho       #每根杆件质量\n\t                load_gravity[edge.u] += edge_mass * gravity * 0.5\n", "                load_gravity[edge.v] += edge_mass * gravity * 0.5  #每根杆件的重力向两端分一半到节点上\n\t            for i in range(len(points)):        #将重力荷载等效施加于节点上\n\t                if self._dimension == 2:        #如果是平面结构\n\t                    op.load(i, 0.0, -1 * load_gravity[i])\n\t                else:                           #如果是空间结构\n\t                    op.load(i, 0.0, 0.0, -1 * load_gravity[i])\n\t        op.system(\"BandSPD\")\n\t        op.numberer(\"RCM\")\n\t        op.constraints(\"Plain\")\n\t        op.integrator(\"LoadControl\", 1.0)\n", "        op.algorithm(\"Newton\")\n\t        op.analysis(\"Static\")\n\t        ok = op.analyze(1)  #运行分析，ok表征是否成功运行，返回0代表成功，返回<0失败。（注:这里对结构的几何不变性进行了充分判断）\n\t        if ok < 0:\n\t            ok = False\n\t        else:\n\t            ok = True\n\t        enablePrint()\n\t        return ok\n\t    #评估节点位移\n", "    def _get_dis_value(self, points, mode = 'check'):\n\t        displacement_weight = np.zeros((len(points), 1))  #初始化一个0数组，用于存放位移数据\n\t        for i in range(len(points)):\n\t            if self._dimension == 2:\n\t                weight = max(   \n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                )                                  #只考虑x,y,(z)方向上的最大的一个线位移\n\t            else:\n\t                weight = max(\n", "                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                    abs(op.nodeDisp(i, 3)),\n\t                )\n\t            if (mode == 'check'): print(\"第{:}结点位移为{:}mm\".format(i,weight*10**3))\n\t            displacement_weight[i] = max(weight / self._limit_dis - 1, 0)  #判定节点位移是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为位移评估参照\n\t        return displacement_weight\n\t    #评估杆件应力\n\t    def _get_stress_value(self, edges, mode = 'check'):\n\t        stress_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放应力数据\n", "        for tag, i in enumerate(range(len(edges))):\n\t            edges[i].force = op.basicForce(tag)   #从有限元得到杆件轴力\n\t            edges[i].stress = edges[i].force[0] / edges[i].area  #根据轴力、截面积求正应力\n\t            if (mode == 'check'): print(\"第{:}杆件应力为{:}MPa\".format(i,edges[i].stress*10**(-6)))\n\t            if edges[i].stress < 0:                                  #压杆\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_C - 1.0,\n\t                    0.0\n\t                )\n\t            else:                                                    #拉杆\n", "                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_T - 1.0,\n\t                    0.0\n\t                )\n\t        return stress_weight  #判定节点应力是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为应力评估参照\n\t    #评估杆件屈曲\n\t    def _get_buckle_value(self, edges):\n\t        buckle_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放屈曲数据\n\t        miu_buckle = 1.0                           #杆件计算长度系数，桁架两端铰接取1\n\t        for i in range(len(edges)):\n", "            edges[i].force = op.basicForce(i)    #存放轴力数据\n\t            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n\t            if edges[i].stress < 0:    #仅压杆才考虑屈曲\n\t                #计算欧拉临界力\n\t                force_cr = (\n\t                    math.pi ** 2 \n\t                    * self._E * edges[i].inertia\n\t                ) / (miu_buckle * edges[i].len) ** 2\n\t                #计算欧拉临界应力\n\t                buckle_stress_max = force_cr / edges[i].area\n", "                buckle_weight[i] = max(\n\t                    abs(edges[i].stress) / abs(buckle_stress_max) - 1.0,\n\t                    0.0\n\t                )#判定杆件压应力是否超过屈曲临界应力：超出则比例存入数组，否则记为0\n\t        return buckle_weight\n\t    #评估杆件长细比\n\t    def _get_slenderness_ratio(self, edges):\n\t        lambda_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放长细比数据\n\t        for i in range(len(edges)):\n\t            edges[i].force = op.basicForce(i)    #存放轴力数据\n", "            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n\t            lambda_weight[i] = max(\n\t                # self.len/(self.inertia/self.area)**0.5\n\t                abs(edges[i].len / (edges[i].inertia / edges[i].area) ** 0.5) / abs(self.slenderness_ratio_C if edges[i].stress < 0 else self.slenderness_ratio_T) - 1.0,\n\t                0.0\n\t            )#判定杆件长细比是否超过限制：超出则比例存入数组，否则记为0\n\t        return lambda_weight\n\t    #评估杆件超长\n\t    def _get_length_longer(self, edges):\n\t        longer_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放长细比数据\n", "        for i in range(len(edges)):   \n\t            longer_weight[i] = max(\n\t                abs(edges[i].len) / abs(self.max_len) - 1.0,\n\t                0.0\n\t            )#判定杆件长度是否超过限制：超出则比例存入数组，否则记为0\n\t        return longer_weight\n\t    #评估杆件过短\n\t    def _get_length_shorter(self, edges):\n\t        shorter_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放长细比数据\n\t        for i in range(len(edges)): \n", "            if edges[i].len < self.min_len:\n\t                shorter_weight[i] = 1.0-edges[i].len / self.min_len\n\t                #判定杆件长度是否过短：超出则比例存入数组，否则记为0\n\t        return shorter_weight\n\t    def _get_cross_value(self, points, edges):\n\t        cross_value = 0\n\t        for i in range(len(edges)):\n\t            for j in range(len(edges)):\n\t                if (edges[i].u == edges[j].v or edges[i].u == edges[j].u or edges[i].v == edges[j].v or edges[i].v == edges[j].u):\n\t                    continue\n", "                _, _, dis = self.closestDistanceBetweenLines(points[edges[i].u].Point2np(), points[edges[i].v].Point2np(), points[edges[j].u].Point2np(), points[edges[j].v].Point2np(), clampAll = True)\n\t                if (edges[i].d != None):\n\t                    r1, r2 = edges[i].d, edges[j].d\n\t                else:\n\t                    if (self._dimension == 2):\n\t                        r1, r2 = edges[i].area, edges[j].area\n\t                    elif (self._dimension == 3):\n\t                        r1, r2 = np.sqrt(edges[i].area / np.pi), np.sqrt(edges[j].area / np.pi)\n\t                if (dis <= r1 + r2): cross_value += 1\n\t        return cross_value\n", "    def closestDistanceBetweenLines(self, a0, a1, b0, b1, \n\t        clampAll = False, clampA0 = False,clampA1 = False,clampB0 = False,clampB1 = False):\n\t        ''' \n\t        Given two lines defined by numpy.array pairs (a0,a1,b0,b1)\n\t        Return the closest points on each segment and their distance\n\t        '''\n\t        # If clampAll=True, set all clamps to True\n\t        if clampAll:\n\t            clampA0=True\n\t            clampA1=True\n", "            clampB0=True\n\t            clampB1=True\n\t        # Calculate denomitator\n\t        A = a1 - a0\n\t        B = b1 - b0\n\t        magA = np.linalg.norm(A)\n\t        magB = np.linalg.norm(B)\n\t        _A = A / magA\n\t        _B = B / magB\n\t        cross = np.cross(_A, _B)\n", "        denom = np.linalg.norm(cross) ** 2\n\t        # If lines are parallel (denom=0) test if lines overlap.\n\t        # If they don't overlap then there is a closest point solution.\n\t        # If they do overlap, there are infinite closest positions, but there is a closest distance\n\t        if not denom:\n\t            d0 = np.dot(_A, (b0 - a0))\n\t            # Overlap only possible with clamping\n\t            if clampA0 or clampA1 or clampB0 or clampB1:\n\t                d1 = np.dot(_A, (b1 - a0))\n\t                # Is segment B before A?\n", "                if d0 <= 0 >= d1:\n\t                    if clampA0 and clampB1:\n\t                        if np.absolute(d0) < np.absolute(d1):\n\t                            return a0,b0,np.linalg.norm(a0-b0)\n\t                        return a0,b1,np.linalg.norm(a0-b1)\n\t                # Is segment B after A?\n\t                elif d0 >= magA <= d1:\n\t                    if clampA1 and clampB0:\n\t                        if np.absolute(d0) < np.absolute(d1):\n\t                            return a1,b0,np.linalg.norm(a1-b0)\n", "                        return a1,b1,np.linalg.norm(a1-b1)\n\t            # Segments overlap, return distance between parallel segments\n\t            return None,None,np.linalg.norm(((d0*_A)+a0)-b0)\n\t        # Lines criss-cross: Calculate the projected closest points\n\t        t = (b0 - a0)\n\t        detA = np.linalg.det([t, _B, cross])\n\t        detB = np.linalg.det([t, _A, cross])\n\t        t0 = detA/denom\n\t        t1 = detB/denom\n\t        pA = a0 + (_A * t0) # Projected closest point on segment A\n", "        pB = b0 + (_B * t1) # Projected closest point on segment B\n\t        # Clamp projections\n\t        if clampA0 or clampA1 or clampB0 or clampB1:\n\t            if clampA0 and t0 < 0:\n\t                pA = a0\n\t            elif clampA1 and t0 > magA:\n\t                pA = a1\n\t            if clampB0 and t1 < 0:\n\t                pB = b0\n\t            elif clampB1 and t1 > magB:\n", "                pB = b1\n\t            # Clamp projection A\n\t            if (clampA0 and t0 < 0) or (clampA1 and t0 > magA):\n\t                dot = np.dot(_B,(pA-b0))\n\t                if clampB0 and dot < 0:\n\t                    dot = 0\n\t                elif clampB1 and dot > magB:\n\t                    dot = magB\n\t                pB = b0 + (_B * dot)\n\t            # Clamp projection B\n", "            if (clampB0 and t1 < 0) or (clampB1 and t1 > magB):\n\t                dot = np.dot(_A,(pB-a0))\n\t                if clampA0 and dot < 0:\n\t                    dot = 0\n\t                elif clampA1 and dot > magA:\n\t                    dot = magA\n\t                pA = a0 + (_A * dot)\n\t        return pA, pB, np.linalg.norm(pA - pB)\n\t    #调用以上函数运行结构分析\n\t    def run(self, points, edges, mode = 'check'):\n", "        # if mode = check, return a list\n\t        # else, return value\n\t        if 'IS_RUNNING_DYNAMIC' not in os.environ:\n\t            os.environ['IS_RUNNING_DYNAMIC'] = 'no'\n\t        while os.environ['IS_RUNNING_DYNAMIC'] == 'yes':\n\t            print('waiting for dynamics to be enabled')\n\t            time.sleep(0.1)\n\t        os.environ['IS_RUNNING_DYNAMIC'] = 'yes'\n\t        if (type(points) == dict or type(points) == OrderedDict):\n\t            _points = []\n", "            for i, point in points.items():\n\t                _points.append(point)\n\t            points = _points\n\t        if (type(edges) == dict or type(edges) == OrderedDict):\n\t            _edges = []\n\t            for i, edge in edges.items():\n\t                _edges.append(edge)\n\t            edges = _edges\n\t        is_struct = self._is_struct(points, edges) #运行结构建模与分析，is_struct返回结构是否正常完成分析\n\t        mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value = 0, 0, 0, 0, 0, 0, 0, 0\n", "        for edge in edges: mass += edge.len * edge.area * self._pho      #计算结构总质量\n\t        if is_struct: #如果结构成功完成分析，即结构是几何不变的\n\t            if self._use_dis_constraint:\n\t                dis_value = self._get_dis_value(points, mode)       #若启用，获取结构位移评估结果\n\t            if self._use_stress_constraint:\n\t                stress_value = self._get_stress_value(edges, mode)  #若启用，获取结构应力评估结果\n\t            if self._use_buckle_constraint:\n\t                buckle_value = self._get_buckle_value(edges)  #若启用，获取结构屈曲评估结果\n\t            if self._use_slenderness_constraint:\n\t                slenderness_value = self._get_slenderness_ratio(edges)  #若启用，获取结构长细比评估结果    \n", "            if self._use_longer_constraint:\n\t                longer_value = self._get_length_longer(edges)  #若启用，获取结构长细比评估结果\n\t            if self._use_shorter_constraint:\n\t                shorter_value = self._get_length_shorter(edges)  #若启用，获取结构长细比评估结果\n\t        if self._use_cross_constraint:\n\t            cross_value = self._get_cross_value(points, edges)\n\t        if (mode != 'check'):\n\t            if (is_struct and self._use_dis_constraint): dis_value = dis_value.sum()\n\t            if (is_struct and self._use_buckle_constraint): buckle_value = buckle_value.sum()\n\t            if (is_struct and self._use_slenderness_constraint): slenderness_value = slenderness_value.sum()\n", "            if (is_struct and self._use_stress_constraint): stress_value = stress_value.sum()\n\t            if (is_struct and self._use_longer_constraint): longer_value = longer_value.sum()\n\t            if (is_struct and self._use_shorter_constraint): shorter_value = shorter_value.sum()\n\t        os.environ['IS_RUNNING_DYNAMIC'] = 'no'\n\t        return (\n\t            is_struct, mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value\n\t        )\n\t    #绘制平面桁架\n\t    def render(self, points, edges):\n\t        _ax = plt.axes(projection='3d')\n", "        for point in points.values():   #绘制节点，scatter()绘制散点\n\t            if point.isSupport:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='g') #支座点为绿色\n\t            elif point.isLoad:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='r') #荷载作用的节点为红色\n\t            else:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='b') #其余节点蓝色\n\t        for edge in edges.values():    #绘制杆件\n\t            x0 = [points[edge.u].vec.x, points[edge.v].vec.x]   #杆件起点\n\t            y0 = [points[edge.u].vec.y, points[edge.v].vec.y]   #杆件终点\n", "            z0 = [points[edge.u].vec.z, points[edge.v].vec.z]   #杆件起点\n\t            if edge.stress < -1e-7:\n\t                _ax.plot(x0, y0, z0, color='g', linewidth=(edge.area / math.pi)**0.5*500)    #压杆绿色\n\t            elif edge.stress > 1e-7:\n\t                _ax.plot(x0, y0, z0, color='r', linewidth=(edge.area / math.pi)**0.5*500)    #拉杆红色\n\t            else:\n\t                _ax.plot(x0, y0, z0, color='k', linewidth=(edge.area / math.pi)**0.5*500)    #零杆黑色\n\t        plt.show() #显示图像\n\tif __name__=='__main__':\n\t    truss=DynamicModel(3)    #创建结构对象\n", "    point_list, edge_list = readFile(\"25.txt\") #读取数据输入文件中的预设点和边\n\t    #将point_list, edge_list转换成truss.run的数据结构\n\t    points = {}\n\t    edges = {}\n\t    for i, point in enumerate(point_list):  #将预设点对象加入点集\n\t        points[i] = point\n\t    for i, edge in enumerate(edge_list):    #将预设边对象加入边集\n\t        if edge.u > edge.v:                 #边端点重新编号\n\t            tmp = edge.u\n\t            edge.u = edge.v\n", "            edge.v = tmp\n\t        edges[(edge.u, edge.v)] = edge        \n\t    #运行模型分析                                 \n\t    is_struct, mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value  = truss.run(points, edges) \n\t    #后处理，输出结构设计结果的提示信息\n\t    if not is_struct:\n\t        print(\"结构几何不稳定\")\n\t    elif np.sum(dis_value) > 0.0 or np.sum(stress_value) > 0.0 or np.sum(buckle_value) > 0.0 or np.sum(slenderness_value) or np.sum(longer_value) or np.sum(shorter_value):\n\t        for i in range(len(dis_value)):\n\t            if dis_value[i]>0.0:\n", "                print(\"第{:}结点位移超出限值{:}%\".format(i,dis_value[i]*100))\n\t        for i in range(len(stress_value)):\n\t            if stress_value[i]>0.0:\n\t                print(\"第{:}杆件应力超出限值{:}%\".format(i,stress_value[i]*100))\n\t        for i in range(len(buckle_value)):\n\t            if buckle_value[i]>0.0:\n\t                print(\"第{:}杆件屈曲应力超出限值{:}%\".format(i,buckle_value[i]*100))\n\t        for i in range(len(slenderness_value)):\n\t            if slenderness_value[i]>0.0:\n\t                print(\"第{:}杆件长细比超出限值{:}%\".format(i,slenderness_value[i]*100))\n", "        for i in range(len(longer_value)):\n\t            if longer_value[i]>0.0:\n\t                print(\"第{:}杆件长度超出限值{:}%\".format(i,longer_value[i]*100))\n\t        for i in range(len(shorter_value)):\n\t            if shorter_value[i]>0.0:\n\t                print(\"第{:}杆件长度短过限值{:}%\".format(i,shorter_value[i]*100))                 \n\t    else:\n\t        print(\"结构几何稳定，且所有约束满足。当前结构总质量为：{:.3f}kg\".format(mass))\n\t    truss.render(points, edges) #显示桁架图像"]}
{"filename": "Stage2/envs/dynamic_.py", "chunked_list": ["import gym\n\timport time\n\timport json\n\timport numpy as np\n\timport math\n\timport random\n\timport copy\n\timport matplotlib.pyplot as plt\n\timport matplotlib.animation as animation\n\timport warnings\n", "import os, sys, contextlib, platform\n\tsysstr = platform.system()\n\tif sysstr == \"Windows\" or sysstr == \"Linux\":\n\t    isMac = False\n\telse:\n\t    isMac = True\n\tif isMac:\n\t    import openseespymac.opensees as op\n\telse:\n\t    import openseespy.opensees as op\n", "from utils.utils import readFile, Point, Bar, getlen2, Vector3, getang\n\tdef blockPrint():\n\t    sys.stdout = open(os.devnull, 'w')\n\t    sys.stderr = open(os.devnull, 'w')\n\tdef enablePrint():\n\t    sys.stdout = sys.__stdout__\n\t    sys.stderr = sys.__stderr__\n\tclass DynamicModel:\n\t    def __init__(self,\n\t                 dimension,\n", "                 E=6.895 * 10 ** 10,\n\t                 pho=2.76799 * 10 ** 3,\n\t                 sigma_T=172.3 * 10 ** 6,\n\t                 sigma_C=172.3 * 10 ** 6,\n\t                 dislimit=0.0508,\n\t                 ratio_ring=0.0,\n\t                 use_self_weight=True,\n\t                 use_dis_constraint=True,\n\t                 use_stress_constraint=True,\n\t                 use_buckle_constraint=True,\n", "                 ):\n\t        self._dimension = dimension\n\t        self._E = E\n\t        self._pho = pho\n\t        self._sigma_T = sigma_T\n\t        self._sigma_C = sigma_C\n\t        self._limit_dis = dislimit\n\t        self._ratio_ring = ratio_ring\n\t        self._use_self_weight = use_self_weight\n\t        self._use_dis_constraint = use_dis_constraint\n", "        self._use_stress_constraint = use_stress_constraint\n\t        self._use_buckle_constraint = use_buckle_constraint\n\t    def _is_struct(self, points, edges):\n\t        total_support = 0\n\t        for p in points.values():\n\t            if self._dimension == 2:\n\t                total_support += (\n\t                        p.supportX\n\t                        + p.supportY\n\t                )\n", "            else:\n\t                total_support += (\n\t                        p.supportX\n\t                        + p.supportY\n\t                        + p.supportZ\n\t                )\n\t        if len(points) * self._dimension - len(edges) - total_support > 0:\n\t            return (False)  # 计算自由度>0，结构不稳定直接返回False\n\t        blockPrint()\n\t        op.wipe()\n", "        op.model('basic', '-ndm', self._dimension, '-ndf', self._dimension)\n\t        for i, point in points.items():\n\t            if self._dimension == 2:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n\t                )\n\t            else:\n\t                op.node(\n", "                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n\t                    point.vec.z,\n\t                )\n\t        for i, point in points.items():\n\t            if point.isSupport:\n\t                if self._dimension == 2:\n\t                    op.fix(\n\t                        i,\n", "                        point.supportX,\n\t                        point.supportY,\n\t                    )\n\t                else:\n\t                    op.fix(\n\t                        i,\n\t                        point.supportX,\n\t                        point.supportY,\n\t                        point.supportZ,\n\t                    )\n", "        op.uniaxialMaterial(\"Elastic\", 1, self._E)\n\t        for i, edge in enumerate(edges.values()):\n\t            op.element(\"Truss\", i, edge.u, edge.v, edge.area, 1)\n\t        op.timeSeries(\"Linear\", 1)\n\t        op.pattern(\"Plain\", 1, 1)\n\t        for i, point in points.items():\n\t            if point.isLoad:\n\t                if self._dimension == 2:\n\t                    op.load(\n\t                        i,\n", "                        point.loadX,\n\t                        point.loadY,\n\t                    )\n\t                else:\n\t                    op.load(\n\t                        i,\n\t                        point.loadX,\n\t                        point.loadY,\n\t                        point.loadZ,\n\t                    )\n", "        if self._use_self_weight:\n\t            gravity = 9.8\n\t            load_gravity = [0 for _ in range(len(points))]\n\t            for i, edge in edges.items():\n\t                edge_mass = edge.len * edge.area * self._pho\n\t                load_gravity[edge.u] += edge_mass * gravity * 0.5\n\t                load_gravity[edge.v] += edge_mass * gravity * 0.5\n\t            for i in range(len(points)):\n\t                if self._dimension == 2:  # 如果是平面结构\n\t                    op.load(i, 0.0, -1 * load_gravity[i])\n", "                else:  # 如果是空间结构\n\t                    op.load(i, 0.0, 0.0, -1 * load_gravity[i])\n\t        op.system(\"BandSPD\")\n\t        op.numberer(\"RCM\")\n\t        op.constraints(\"Plain\")\n\t        op.integrator(\"LoadControl\", 1.0)\n\t        op.algorithm(\"Newton\")\n\t        op.analysis(\"Static\")\n\t        ok = op.analyze(1)\n\t        enablePrint()\n", "        if ok < 0:\n\t            ok = False\n\t        else:\n\t            ok = True\n\t        return ok\n\t    def _get_dis_value(self, points):\n\t        displacement_weight = np.zeros((len(points), 1))\n\t        for i in range(len(points)):\n\t            if self._dimension == 2:\n\t                weight = max(\n", "                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                )\n\t            else:\n\t                weight = max(\n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                    abs(op.nodeDisp(i, 3)),\n\t                )\n\t            displacement_weight[i] = max(weight / self._limit_dis - 1.0, 0)\n", "        return np.sum(displacement_weight)\n\t    def _get_stress_value(self, edges):\n\t        stress_weight = np.zeros((len(edges), 1))\n\t        for tag, i in enumerate(edges.keys()):\n\t            edges[i].force = op.basicForce(tag)\n\t            if isMac:\n\t                edges[i].stress = edges[i].force / edges[i].area\n\t            else:\n\t                edges[i].stress = edges[i].force[0] / edges[i].area\n\t            if edges[i].stress < 0:\n", "                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_C - 1.0,\n\t                    0.0\n\t                )\n\t            else:\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_T - 1.0,\n\t                    0.0\n\t                )\n\t        return np.sum(stress_weight)\n", "    def _get_buckle_value(self, edges):\n\t        buckle_weight = np.zeros((len(edges), 1))\n\t        miu_buckle = 1.0\n\t        for tag, i in enumerate(edges.keys()):\n\t            edges[i].force = op.basicForce(tag)\n\t            if isMac:\n\t                edges[i].stress = edges[i].force / edges[i].area\n\t            else:\n\t                edges[i].stress = edges[i].force[0] / edges[i].area\n\t            if edges[i].stress < 0:\n", "                edges[i].inertia = (\n\t                        edges[i].area ** 2\n\t                        * (1 + self._ratio_ring ** 2)\n\t                        / (\n\t                                4 * math.pi\n\t                                * (1 - self._ratio_ring ** 2)\n\t                        )\n\t                )\n\t                force_cr = (\n\t                                   math.pi ** 2\n", "                                   * self._E * edges[i].inertia\n\t                           ) / (miu_buckle * edges[i].len) ** 2\n\t                buckle_stress_max = force_cr / edges[i].area\n\t                buckle_weight[tag] = max(\n\t                    abs(edges[i].stress) / abs(buckle_stress_max) - 1.0,\n\t                    0.0\n\t                )\n\t        return np.sum(buckle_weight)\n\t    def run(self, points, edges):\n\t        if 'IS_RUNNING_DYNAMIC' not in os.environ:\n", "            os.environ['IS_RUNNING_DYNAMIC'] = 'no'\n\t        while os.environ['IS_RUNNING_DYNAMIC'] == 'yes':\n\t            print('waiting for dynamics to be enabled')\n\t            time.sleep(0.1)\n\t        os.environ['IS_RUNNING_DYNAMIC'] = 'yes'\n\t        is_struct = self._is_struct(points, edges)\n\t        mass, dis_value, stress_value, buckle_value = 0.0, 0.0, 0.0, 0.0\n\t        if is_struct:\n\t            for i, edge in edges.items():\n\t                mass += edge.len * edge.area * self._pho\n", "            if self._use_dis_constraint:\n\t                dis_value = self._get_dis_value(points)\n\t            if self._use_stress_constraint:\n\t                stress_value = self._get_stress_value(edges)\n\t            if self._use_buckle_constraint:\n\t                buckle_value = self._get_buckle_value(edges)\n\t        os.environ['IS_RUNNING_DYNAMIC'] = 'no'\n\t        return (\n\t            is_struct,\n\t            mass, dis_value, stress_value, buckle_value\n", "        )\n"]}
{"filename": "Stage2/noise/noise_main.py", "chunked_list": ["import argparse\n\timport copy\n\timport os\n\timport random\n\timport torch as th\n\timport rlkit.torch.pytorch_util as ptu\n\tfrom rlkit.envs.wrappers import NormalizedBoxEnv\n\tfrom rlkit.samplers.data_collector import MdpPathCollector\n\tfrom rlkit.data_management.env_replay_buffer import EnvReplayBuffer\n\tfrom rlkit.torch.sac.sac import SACTrainer\n", "from rlkit.torch.torch_rl_algorithm import TorchBatchRLAlgorithm\n\tfrom envs import Truss\n\tfrom models import MLP, TanhGaussianPolicy, MakeDeterministic, TRANSFORMEREMBED, EmbedTanhGaussianPolicy\n\timport gtimer as gt\n\tdef get_args():\n\t    parser = argparse.ArgumentParser(description='Alpha Truss')\n\t    # Training args\n\t    parser.add_argument('--num_trains_per_train_loop', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--num_train_loops_per_epoch', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--hidden_dims', type=list, default=[256, 1024], help='hidden layer dimensions')\n", "    parser.add_argument('--buffer_size', type=int, default=1000000, help='buffer size')\n\t    parser.add_argument('--epoch', type=int, default=1, help='epoch')\n\t    parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n\t    parser.add_argument('--evaluation', action='store_true', default=False)\n\t    parser.add_argument('--save_model_path', type=str, default='.')\n\t    parser.add_argument('--prev_dims', type=list, default=[8, 32], help='input dims for TransformerEmbed')\n\t    parser.add_argument('--post_dims', type=list, default=[256, 128], help='hidden dims for TransformerEmbed')\n\t    # Env args\n\t    parser.add_argument('--num_points', type=int, default=6, help='number of nodes')\n\t    parser.add_argument('--initial_state_files', type=str, default='best_results/Noise6789p_2/', help='input file for refine')\n", "    parser.add_argument('--coordinate_range', type=list, default=[(0.0, 18.288), (0.0, 9.144)], help='nodes\\' coordinate range')\n\t    parser.add_argument('--area_range', type=list, default=(6.452e-05, 0.04), help='edges\\' area range')\n\t    parser.add_argument('--coordinate_delta_range', type=list, default=[(-0.5715, 0.5715), (-0.5715, 0.5715)], help='nodes\\' coordinate delta range')\n\t    parser.add_argument('--area_delta_range', type=list, default=(-0.0005, 0.0005), help='edges\\' area delta range')\n\t    parser.add_argument('--fixed_points', type=int, default=4, help='number of fixed nodes')\n\t    parser.add_argument('--variable_edges', type=int, default=-1, help='number of variable edges, -1 if all is variable')\n\t    parser.add_argument('--max_refine_steps', type=int, default=200, help='maximum timesteps of an episode')\n\t    args = parser.parse_args()\n\t    return args\n\tif __name__ == '__main__':\n", "    for loop in range(50):\n\t        for point_num in range(6, 10):\n\t            print('loop:', loop, 'point_num:', point_num)\n\t            args = get_args()\n\t            #args.save_model_path = args.initial_state_files.replace('best_results', 'saved_models')\n\t            #args.save_model_path = args.save_model_path[:-1]\n\t            args.save_model_path = 'saved_models/Noise6789p_2'\n\t            args.num_points = int(point_num)\n\t            args.initial_state_files = 'best_results/Noise6789p_2/New' + str(point_num) + 'pointsNoise/'\n\t            if not os.path.exists(args.save_model_path):\n", "                os.mkdir(args.save_model_path)\n\t            UseEvalModel = False\n\t            if UseEvalModel:\n\t                args.save_model_path = 'saved_models/test6points'\n\t            if th.cuda.is_available():\n\t                ptu.set_gpu_mode(True)\n\t            _ = random.random()\n\t            if _ > 0.5:\n\t                best_n_results = 200\n\t            else:\n", "                best_n_results = -1\n\t            print('best_n_results:', best_n_results)\n\t            env = NormalizedBoxEnv(Truss(args.num_points, args.initial_state_files,\n\t                                         args.coordinate_range, args.area_range,\n\t                                         args.coordinate_delta_range, args.area_delta_range,\n\t                                         args.fixed_points, args.variable_edges,\n\t                                         args.max_refine_steps, best_n_results=best_n_results))\n\t            obs_dim = env.observation_space.low.size\n\t            action_dim = env.action_space.low.size\n\t            print(obs_dim, action_dim)\n", "            #qf1 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t            #qf2 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t            qf1 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims)\n\t            qf2 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims)\n\t            target_qf1 = copy.deepcopy(qf1)\n\t            target_qf2 = copy.deepcopy(qf2)\n\t            expl_policy = EmbedTanhGaussianPolicy(obs_dim=args.prev_dims[-1], action_dim=action_dim, hidden_sizes=args.hidden_dims, input_dims=args.prev_dims)\n\t            eval_policy = MakeDeterministic(expl_policy)\n\t            if os.path.exists(\"{}/qf1.th\".format(args.save_model_path)):\n\t                args.evaluation = True\n", "            if args.evaluation:\n\t                print(\"load pretrain\")\n\t                expl_policy.load_state_dict(th.load(\"{}/policy.th\".format(args.save_model_path)))\n\t                qf1.load_state_dict(th.load(\"{}/qf1.th\".format(args.save_model_path)))\n\t                qf2.load_state_dict(th.load(\"{}/qf2.th\".format(args.save_model_path)))\n\t                target_qf1.load_state_dict(th.load(\"{}/target_qf1.th\".format(args.save_model_path)))\n\t                target_qf2.load_state_dict(th.load(\"{}/target_qf2.th\".format(args.save_model_path)))\n\t            expl_path_collector = MdpPathCollector(env, expl_policy)\n\t            eval_path_collector = MdpPathCollector(env, eval_policy)\n\t            replay_buffer = EnvReplayBuffer(args.buffer_size, env)\n", "            trainer = SACTrainer(env=env, policy=expl_policy, qf1=qf1, qf2=qf2, target_qf1=target_qf1, target_qf2=target_qf2,\n\t                                 soft_target_tau=0.005, reward_scale=10., policy_lr=0.0003, qf_lr=0.0003)\n\t            algorithm = TorchBatchRLAlgorithm(trainer=trainer, exploration_env=env, evaluation_env=env,\n\t                                              exploration_data_collector=expl_path_collector,\n\t                                              evaluation_data_collector=eval_path_collector,\n\t                                              replay_buffer=replay_buffer,\n\t                                              num_epochs=args.epoch,\n\t                                              num_eval_steps_per_epoch=2000,\n\t                                              num_trains_per_train_loop=args.num_trains_per_train_loop,\n\t                                              num_train_loops_per_epoch=args.num_train_loops_per_epoch,\n", "                                              num_expl_steps_per_train_loop=1000,\n\t                                              min_num_steps_before_training=1000,\n\t                                              max_path_length=500,\n\t                                              batch_size=args.batch_size)\n\t            if not UseEvalModel:\n\t                gt.reset_root()\n\t            algorithm.to(ptu.device)\n\t            algorithm.train()\n\t            if not UseEvalModel:\n\t                trained_network = algorithm.trainer.networks\n", "                th.save(trained_network[0].state_dict(), \"{}/policy.th\".format(args.save_model_path))\n\t                th.save(trained_network[1].state_dict(), \"{}/qf1.th\".format(args.save_model_path))\n\t                th.save(trained_network[2].state_dict(), \"{}/qf2.th\".format(args.save_model_path))\n\t                th.save(trained_network[3].state_dict(), \"{}/target_qf1.th\".format(args.save_model_path))\n\t                th.save(trained_network[4].state_dict(), \"{}/target_qf2.th\".format(args.save_model_path))\n"]}
{"filename": "Stage2/noise/eval_noise.py", "chunked_list": ["import argparse\n\timport copy\n\timport os\n\timport torch as th\n\timport rlkit.torch.pytorch_util as ptu\n\tfrom rlkit.envs.wrappers import NormalizedBoxEnv\n\tfrom rlkit.samplers.data_collector import MdpPathCollector\n\tfrom rlkit.data_management.env_replay_buffer import EnvReplayBuffer\n\tfrom rlkit.torch.sac.sac import SACTrainer\n\tfrom rlkit.torch.torch_rl_algorithm import TorchBatchRLAlgorithm\n", "from envs import Truss\n\tfrom models import MLP, TanhGaussianPolicy, MakeDeterministic, TRANSFORMEREMBED, EmbedTanhGaussianPolicy\n\timport gtimer as gt\n\tdef get_args():\n\t    parser = argparse.ArgumentParser(description='Alpha Truss')\n\t    # Training args\n\t    parser.add_argument('--num_trains_per_train_loop', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--num_train_loops_per_epoch', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--hidden_dims', type=list, default=[256, 1024], help='hidden layer dimensions')\n\t    parser.add_argument('--buffer_size', type=int, default=1000000, help='buffer size')\n", "    parser.add_argument('--epoch', type=int, default=50, help='epoch')\n\t    parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n\t    parser.add_argument('--evaluation', action='store_true', default=False)\n\t    parser.add_argument('--save_model_path', type=str, default='.')\n\t    parser.add_argument('--prev_dims', type=list, default=[8, 32], help='input dims for TransformerEmbed')\n\t    parser.add_argument('--post_dims', type=list, default=[256, 128], help='hidden dims for TransformerEmbed')\n\t    # Env args\n\t    parser.add_argument('--num_points', type=int, default=9, help='number of nodes')\n\t    parser.add_argument('--initial_state_files', type=str, default='best_results/NoSoft/NoSoft9p/', help='input file for refine')\n\t    parser.add_argument('--coordinate_range', type=list, default=[(0.0, 18.288), (0.0, 9.144)], help='nodes\\' coordinate range')\n", "    parser.add_argument('--area_range', type=list, default=(6.452e-05, 0.04), help='edges\\' area range')\n\t    parser.add_argument('--coordinate_delta_range', type=list, default=[(-0.5715, 0.5715), (-0.5715, 0.5715)], help='nodes\\' coordinate delta range')\n\t    parser.add_argument('--area_delta_range', type=list, default=(-0.0005, 0.0005), help='edges\\' area delta range')\n\t    parser.add_argument('--fixed_points', type=int, default=4, help='number of fixed nodes')\n\t    parser.add_argument('--variable_edges', type=int, default=-1, help='number of variable edges, -1 if all is variable')\n\t    parser.add_argument('--max_refine_steps', type=int, default=200, help='maximum timesteps of an episode')\n\t    args = parser.parse_args()\n\t    return args\n\tif __name__ == '__main__':\n\t    args = get_args()\n", "    point_num = args.num_points\n\t    #args.save_model_path = args.initial_state_files.replace('best_results', 'saved_models')\n\t    #args.save_model_path = args.save_model_path[:-1]\n\t    #args.save_model_path = 'saved_models/NewMixedNoise'\n\t    #args.num_points = int(point_num)\n\t    #if not os.path.exists(args.save_model_path):\n\t    #    os.mkdir(args.save_model_path)\n\t    UseEvalModel = True\n\t    if UseEvalModel:\n\t        args.save_model_path = 'saved_models/Noise6789p_2'\n", "    if th.cuda.is_available():\n\t        ptu.set_gpu_mode(True)\n\t    env = NormalizedBoxEnv(Truss(args.num_points, args.initial_state_files,\n\t                                 args.coordinate_range, args.area_range,\n\t                                 args.coordinate_delta_range, args.area_delta_range,\n\t                                 args.fixed_points, args.variable_edges,\n\t                                 args.max_refine_steps))\n\t    obs_dim = env.observation_space.low.size\n\t    action_dim = env.action_space.low.size\n\t    print(obs_dim, action_dim)\n", "    #qf1 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t    #qf2 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t    qf1 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims)\n\t    qf2 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims)\n\t    target_qf1 = copy.deepcopy(qf1)\n\t    target_qf2 = copy.deepcopy(qf2)\n\t    expl_policy = EmbedTanhGaussianPolicy(obs_dim=args.prev_dims[-1], action_dim=action_dim, hidden_sizes=args.hidden_dims, input_dims=args.prev_dims)\n\t    eval_policy = MakeDeterministic(expl_policy)\n\t    if os.path.exists(\"{}/qf1.th\".format(args.save_model_path)):\n\t        args.evaluation = True\n", "    if args.evaluation:\n\t        print(\"load pretrain\")\n\t        expl_policy.load_state_dict(th.load(\"{}/policy.th\".format(args.save_model_path)))\n\t        qf1.load_state_dict(th.load(\"{}/qf1.th\".format(args.save_model_path)))\n\t        qf2.load_state_dict(th.load(\"{}/qf2.th\".format(args.save_model_path)))\n\t        target_qf1.load_state_dict(th.load(\"{}/target_qf1.th\".format(args.save_model_path)))\n\t        target_qf2.load_state_dict(th.load(\"{}/target_qf2.th\".format(args.save_model_path)))\n\t    expl_path_collector = MdpPathCollector(env, expl_policy)\n\t    eval_path_collector = MdpPathCollector(env, eval_policy)\n\t    replay_buffer = EnvReplayBuffer(args.buffer_size, env)\n", "    trainer = SACTrainer(env=env, policy=expl_policy, qf1=qf1, qf2=qf2, target_qf1=target_qf1, target_qf2=target_qf2,\n\t                         soft_target_tau=0.005, reward_scale=10., policy_lr=0.0003, qf_lr=0.0003)\n\t    algorithm = TorchBatchRLAlgorithm(trainer=trainer, exploration_env=env, evaluation_env=env,\n\t                                      exploration_data_collector=expl_path_collector,\n\t                                      evaluation_data_collector=eval_path_collector,\n\t                                      replay_buffer=replay_buffer,\n\t                                      num_epochs=args.epoch,\n\t                                      num_eval_steps_per_epoch=2000,\n\t                                      num_trains_per_train_loop=args.num_trains_per_train_loop,\n\t                                      num_train_loops_per_epoch=args.num_train_loops_per_epoch,\n", "                                      num_expl_steps_per_train_loop=1000,\n\t                                      min_num_steps_before_training=1000,\n\t                                      max_path_length=500,\n\t                                      batch_size=args.batch_size)\n\t    if not UseEvalModel:\n\t        gt.reset_root()\n\t    algorithm.to(ptu.device)\n\t    algorithm.train()\n\t    if not UseEvalModel:\n\t        trained_network = algorithm.trainer.networks\n", "        th.save(trained_network[0].state_dict(), \"{}/policy.th\".format(args.save_model_path))\n\t        th.save(trained_network[1].state_dict(), \"{}/qf1.th\".format(args.save_model_path))\n\t        th.save(trained_network[2].state_dict(), \"{}/qf2.th\".format(args.save_model_path))\n\t        th.save(trained_network[3].state_dict(), \"{}/target_qf1.th\".format(args.save_model_path))\n\t        th.save(trained_network[4].state_dict(), \"{}/target_qf2.th\".format(args.save_model_path))\n"]}
{"filename": "Stage2/noise/train_noise.py", "chunked_list": ["import argparse\n\timport copy\n\timport os\n\timport torch as th\n\timport rlkit.torch.pytorch_util as ptu\n\tfrom rlkit.envs.wrappers import NormalizedBoxEnv\n\tfrom rlkit.samplers.data_collector import MdpPathCollector\n\tfrom rlkit.data_management.env_replay_buffer import EnvReplayBuffer\n\tfrom rlkit.torch.sac.sac import SACTrainer\n\tfrom rlkit.torch.torch_rl_algorithm import TorchBatchRLAlgorithm\n", "from envs import Truss\n\tfrom models import MLP, TanhGaussianPolicy, MakeDeterministic, TRANSFORMEREMBED, EmbedTanhGaussianPolicy\n\timport gtimer as gt\n\tdef get_args():\n\t    parser = argparse.ArgumentParser(description='Alpha Truss')\n\t    # Training args\n\t    parser.add_argument('--num_trains_per_train_loop', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--num_train_loops_per_epoch', type=int, default=5, help='for sac training')\n\t    parser.add_argument('--hidden_dims', type=list, default=[256, 1024], help='hidden layer dimensions')\n\t    parser.add_argument('--buffer_size', type=int, default=1000000, help='buffer size')\n", "    parser.add_argument('--epoch', type=int, default=50, help='epoch')\n\t    parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n\t    parser.add_argument('--evaluation', action='store_true', default=False)\n\t    parser.add_argument('--save_model_path', type=str, default='.')\n\t    parser.add_argument('--prev_dims', type=list, default=[8, 32], help='input dims for TransformerEmbed')\n\t    parser.add_argument('--post_dims', type=list, default=[256, 128], help='hidden dims for TransformerEmbed')\n\t    # Env args\n\t    parser.add_argument('--num_points', type=int, default=9, help='number of nodes')\n\t    parser.add_argument('--initial_state_files', type=str, default='best_results/TrainMax9p_1/', help='input file for refine')\n\t    parser.add_argument('--coordinate_range', type=list, default=[(0.0, 18.288), (0.0, 9.144)], help='nodes\\' coordinate range')\n", "    parser.add_argument('--area_range', type=list, default=(6.452e-05, 0.04), help='edges\\' area range')\n\t    parser.add_argument('--coordinate_delta_range', type=list, default=[(-0.5715, 0.5715), (-0.5715, 0.5715)], help='nodes\\' coordinate delta range')\n\t    parser.add_argument('--area_delta_range', type=list, default=(-0.0005, 0.0005), help='edges\\' area delta range')\n\t    parser.add_argument('--fixed_points', type=int, default=4, help='number of fixed nodes')\n\t    parser.add_argument('--variable_edges', type=int, default=-1, help='number of variable edges, -1 if all is variable')\n\t    parser.add_argument('--max_refine_steps', type=int, default=200, help='maximum timesteps of an episode')\n\t    args = parser.parse_args()\n\t    return args\n\tif __name__ == '__main__':\n\t    args = get_args()\n", "    point_num = args.num_points\n\t    #args.save_model_path = args.initial_state_files.replace('best_results', 'saved_models')\n\t    #args.save_model_path = args.save_model_path[:-1]\n\t    args.save_model_path = 'saved_models/TrainMax9p_1'\n\t    #args.num_points = int(point_num)\n\t    if not os.path.exists(args.save_model_path):\n\t        os.mkdir(args.save_model_path)\n\t    UseEvalModel = False\n\t    if UseEvalModel:\n\t        args.save_model_path = 'saved_models/Noise6789p_2'\n", "    if th.cuda.is_available():\n\t        ptu.set_gpu_mode(True)\n\t    env = NormalizedBoxEnv(Truss(args.num_points, args.initial_state_files,\n\t                                 args.coordinate_range, args.area_range,\n\t                                 args.coordinate_delta_range, args.area_delta_range,\n\t                                 args.fixed_points, args.variable_edges,\n\t                                 args.max_refine_steps))\n\t    obs_dim = env.observation_space.low.size\n\t    action_dim = env.action_space.low.size\n\t    print(obs_dim, action_dim)\n", "    #qf1 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t    #qf2 = MLP(obs_dim + action_dim, args.hidden_dims)\n\t    qf1 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims)\n\t    qf2 = TRANSFORMEREMBED(args.prev_dims, args.hidden_dims)\n\t    target_qf1 = copy.deepcopy(qf1)\n\t    target_qf2 = copy.deepcopy(qf2)\n\t    expl_policy = EmbedTanhGaussianPolicy(obs_dim=args.prev_dims[-1], action_dim=action_dim, hidden_sizes=args.hidden_dims, input_dims=args.prev_dims)\n\t    eval_policy = MakeDeterministic(expl_policy)\n\t    if os.path.exists(\"{}/qf1.th\".format(args.save_model_path)):\n\t        args.evaluation = True\n", "    if args.evaluation:\n\t        print(\"load pretrain\")\n\t        expl_policy.load_state_dict(th.load(\"{}/policy.th\".format(args.save_model_path)))\n\t        qf1.load_state_dict(th.load(\"{}/qf1.th\".format(args.save_model_path)))\n\t        qf2.load_state_dict(th.load(\"{}/qf2.th\".format(args.save_model_path)))\n\t        target_qf1.load_state_dict(th.load(\"{}/target_qf1.th\".format(args.save_model_path)))\n\t        target_qf2.load_state_dict(th.load(\"{}/target_qf2.th\".format(args.save_model_path)))\n\t    expl_path_collector = MdpPathCollector(env, expl_policy)\n\t    eval_path_collector = MdpPathCollector(env, eval_policy)\n\t    replay_buffer = EnvReplayBuffer(args.buffer_size, env)\n", "    trainer = SACTrainer(env=env, policy=expl_policy, qf1=qf1, qf2=qf2, target_qf1=target_qf1, target_qf2=target_qf2,\n\t                         soft_target_tau=0.005, reward_scale=10., policy_lr=0.0003, qf_lr=0.0003)\n\t    algorithm = TorchBatchRLAlgorithm(trainer=trainer, exploration_env=env, evaluation_env=env,\n\t                                      exploration_data_collector=expl_path_collector,\n\t                                      evaluation_data_collector=eval_path_collector,\n\t                                      replay_buffer=replay_buffer,\n\t                                      num_epochs=args.epoch,\n\t                                      num_eval_steps_per_epoch=2000,\n\t                                      num_trains_per_train_loop=args.num_trains_per_train_loop,\n\t                                      num_train_loops_per_epoch=args.num_train_loops_per_epoch,\n", "                                      num_expl_steps_per_train_loop=1000,\n\t                                      min_num_steps_before_training=1000,\n\t                                      max_path_length=500,\n\t                                      batch_size=args.batch_size)\n\t    if not UseEvalModel:\n\t        gt.reset_root()\n\t    algorithm.to(ptu.device)\n\t    algorithm.train()\n\t    if not UseEvalModel:\n\t        trained_network = algorithm.trainer.networks\n", "        th.save(trained_network[0].state_dict(), \"{}/policy.th\".format(args.save_model_path))\n\t        th.save(trained_network[1].state_dict(), \"{}/qf1.th\".format(args.save_model_path))\n\t        th.save(trained_network[2].state_dict(), \"{}/qf2.th\".format(args.save_model_path))\n\t        th.save(trained_network[3].state_dict(), \"{}/target_qf1.th\".format(args.save_model_path))\n\t        th.save(trained_network[4].state_dict(), \"{}/target_qf2.th\".format(args.save_model_path))\n"]}
{"filename": "truss_envs/dynamic.py", "chunked_list": ["import numpy as np\n\timport math, time\n\timport sys, os\n\timport openseespy.opensees as op\n\timport matplotlib.pyplot as plt\n\tfrom collections import OrderedDict\n\tbase_path = os.getcwd()\n\tsys.path.append(base_path)\n\tfrom utils.utils import readFile, closestDistanceBetweenLines\n\tdef blockPrint():\n", "    sys.stdout = open(os.devnull, 'w')\n\t    sys.stderr = open(os.devnull, 'w')\n\tdef enablePrint():\n\t    sys.stdout = sys.__stdout__\n\t    sys.stderr = sys.__stderr__\n\tclass DynamicModel:\n\t    #构造函数\n\t    def __init__(self,\n\t                dimension,\n\t                E=193*10**9,          #N/m2\n", "                pho=8.0*10**3,        #kg/m3\n\t                sigma_T=123*10**6,    #N/m2\n\t                sigma_C=213*10**6,    #N/m2\n\t                dislimit=0.002,       #m\n\t                slenderness_ratio_T=220,\n\t                slenderness_ratio_C=180,\n\t                max_len=5.0,            #m\n\t                min_len=0.03,         #m\n\t                use_self_weight=True,\n\t                use_dis_constraint=True,\n", "                use_stress_constraint=True,\n\t                use_buckle_constraint=True,\n\t                use_slenderness_constraint=True,\n\t                use_longer_constraint=True,\n\t                use_shorter_constraint=True,\n\t                use_cross_constraint=True,\n\t                ): \n\t        self._dimension = dimension    #结构维度\n\t        self._E = E                    #弹性模量\n\t        self._pho = pho                #材料密度\n", "        self._sigma_T = sigma_T        #容许拉应力\n\t        self._sigma_C = sigma_C        #容许压应力\n\t        self._limit_dis = dislimit     #容许位移\n\t        self.slenderness_ratio_T=slenderness_ratio_T #容许受拉长细比\n\t        self.slenderness_ratio_C=slenderness_ratio_C #容许受压长细比\n\t        self.max_len=max_len                         #最大长度\n\t        self.min_len=min_len                         #最小长度\n\t        self._use_self_weight = use_self_weight              #是否计算自重\n\t        self._use_dis_constraint = use_dis_constraint        #是否启用位移约束\n\t        self._use_stress_constraint = use_stress_constraint         #是否启用应力约束\n", "        self._use_buckle_constraint = use_buckle_constraint         #是否启用屈曲约束\n\t        self._use_slenderness_constraint=use_slenderness_constraint #是否启用长细比约束\n\t        self._use_longer_constraint=use_longer_constraint           #是否启用超长约束\n\t        self._use_shorter_constraint=use_shorter_constraint         #是否启用过短约束\n\t        self._use_cross_constraint=use_cross_constraint             #是否启用杆件交叉约束\n\t        print(self._use_self_weight)\n\t        print(self._use_buckle_constraint)\n\t    #判定结构的几何不变性+分析计算\n\t    def _is_struct(self, points, edges):\n\t        ########计算自由度初判结构几何不变性##########\n", "        total_support = 0             #保存支座约束数\n\t        for p in points:\n\t            if self._dimension == 2:  #平面桁架\n\t                total_support += (\n\t                    p.supportX\n\t                    + p.supportY\n\t                )\n\t            else:                     #空间桁架\n\t                total_support += (\n\t                    p.supportX\n", "                    + p.supportY\n\t                    + p.supportZ\n\t                )\n\t        if len(points) * self._dimension - len(edges) - total_support > 0:\n\t            return (False)   #计算自由度>0，结构不稳定直接返回False\n\t        blockPrint()\n\t        #######以下基于点和边集建立有限元模形分析########\n\t        op.wipe()   # 清除所有已有结构\n\t        op.model('basic', '-ndm', self._dimension, '-ndf', self._dimension)  #设置建模器\n\t        for i, point in enumerate(points):   #建立节点\n", "            if self._dimension == 2:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n\t                    point.vec.y,\n\t                )\n\t            else:\n\t                op.node(\n\t                    i,\n\t                    point.vec.x,\n", "                    point.vec.y,\n\t                    point.vec.z,\n\t                )\n\t        for i, point in enumerate(points):  #施加节点支座约束\n\t                if self._dimension == 2:\n\t                    op.fix(\n\t                        i,\n\t                        point.supportX,\n\t                        point.supportY,\n\t                    )\n", "                else:\n\t                    op.fix(\n\t                        i,\n\t                        point.supportX,\n\t                        point.supportY,\n\t                        point.supportZ,\n\t                    )\n\t        op.timeSeries(\"Linear\", 1)\n\t        op.pattern(\"Plain\", 1, 1)\n\t        for i, point in enumerate(points):  #添加节点荷载\n", "            if point.isLoad:\n\t                if self._dimension == 2:\n\t                    op.load(\n\t                        i,\n\t                        point.loadX,\n\t                        point.loadY,\n\t                    )\n\t                else:\n\t                    op.load(\n\t                        i,\n", "                        point.loadX,\n\t                        point.loadY,\n\t                        point.loadZ,\n\t                    )\n\t        op.uniaxialMaterial(\"Elastic\", 1, self._E)   #定义材料\n\t        for i, edge in enumerate(edges):\n\t            op.element(\"Truss\", i, edge.u, edge.v, edge.area, 1)  #赋予杆件截面属性\n\t        if self._use_self_weight:  #如果计算自重时\n\t            gravity = 9.8   #重力加速度\n\t            load_gravity = [0 for _ in range(len(points))]  #初始化了一个load_gravity列表，表征杆件自重的等效结点力，len(points)个元素均为0\n", "            for i, edge in enumerate(edges):\n\t                edge_mass = edge.len * edge.area * self._pho       #每根杆件质量\n\t                load_gravity[edge.u] += edge_mass * gravity * 0.5\n\t                load_gravity[edge.v] += edge_mass * gravity * 0.5  #每根杆件的重力向两端分一半到节点上\n\t            for i in range(len(points)):        #将重力荷载等效施加于节点上\n\t                if self._dimension == 2:        #如果是平面结构\n\t                    op.load(i, 0.0, -1 * load_gravity[i])\n\t                else:                           #如果是空间结构\n\t                    op.load(i, 0.0, 0.0, -1 * load_gravity[i])\n\t        op.system(\"BandSPD\")\n", "        op.numberer(\"RCM\")\n\t        op.constraints(\"Plain\")\n\t        op.integrator(\"LoadControl\", 1.0)\n\t        op.algorithm(\"Newton\")\n\t        op.analysis(\"Static\")\n\t        ok = op.analyze(1)  #运行分析，ok表征是否成功运行，返回0代表成功，返回<0失败。（注:这里对结构的几何不变性进行了充分判断）\n\t        if ok < 0:\n\t            ok = False\n\t        else:\n\t            ok = True\n", "        enablePrint()\n\t        return ok\n\t    #评估节点位移\n\t    def _get_dis_value(self, points, mode = 'check'):\n\t        displacement_weight = np.zeros((len(points), 1))  #初始化一个0数组，用于存放位移数据\n\t        for i in range(len(points)):\n\t            if self._dimension == 2:\n\t                weight = max(   \n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n", "                )                                  #只考虑x,y,(z)方向上的最大的一个线位移\n\t            else:\n\t                weight = max(\n\t                    abs(op.nodeDisp(i, 1)),\n\t                    abs(op.nodeDisp(i, 2)),\n\t                    abs(op.nodeDisp(i, 3)),\n\t                )\n\t            if (mode == 'check'): print(\"第{:}结点位移为{:}mm\".format(i,weight*10**3))\n\t            displacement_weight[i] = max(weight / self._limit_dis - 1, 0)  #判定节点位移是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为位移评估参照\n\t        return displacement_weight\n", "    #评估杆件应力\n\t    def _get_stress_value(self, edges, mode = 'check'):\n\t        stress_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放应力数据\n\t        for tag, i in enumerate(range(len(edges))):\n\t            edges[i].force = op.basicForce(tag)   #从有限元得到杆件轴力\n\t            edges[i].stress = edges[i].force[0] / edges[i].area  #根据轴力、截面积求正应力\n\t            if (mode == 'check'): print(\"第{:}杆件应力为{:}MPa\".format(i,edges[i].stress*10**(-6)))\n\t            if edges[i].stress < 0:                                  #压杆\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_C - 1.0,\n", "                    0.0\n\t                )\n\t            else:                                                    #拉杆\n\t                stress_weight[tag] = max(\n\t                    abs(edges[i].stress) / self._sigma_T - 1.0,\n\t                    0.0\n\t                )\n\t        return stress_weight  #判定节点应力是否超限：超出则比例存入数组，否则记为0，最后累加数组中的数值作为应力评估参照\n\t    #评估杆件屈曲\n\t    def _get_buckle_value(self, edges):\n", "        buckle_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放屈曲数据\n\t        miu_buckle = 1.0                           #杆件计算长度系数，桁架两端铰接取1\n\t        for i in range(len(edges)):\n\t            edges[i].force = op.basicForce(i)    #存放轴力数据\n\t            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n\t            if edges[i].stress < 0:    #仅压杆才考虑屈曲\n\t                #计算欧拉临界力\n\t                force_cr = (\n\t                    math.pi ** 2 \n\t                    * self._E * edges[i].inertia\n", "                ) / (miu_buckle * edges[i].len) ** 2\n\t                #计算欧拉临界应力\n\t                buckle_stress_max = force_cr / edges[i].area\n\t                buckle_weight[i] = max(\n\t                    abs(edges[i].stress) / abs(buckle_stress_max) - 1.0,\n\t                    0.0\n\t                )#判定杆件压应力是否超过屈曲临界应力：超出则比例存入数组，否则记为0\n\t        return buckle_weight\n\t    #评估杆件长细比\n\t    def _get_slenderness_ratio(self, edges):\n", "        lambda_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放长细比数据\n\t        for i in range(len(edges)):\n\t            edges[i].force = op.basicForce(i)    #存放轴力数据\n\t            edges[i].stress = edges[i].force[0] / edges[i].area #根据轴力、截面积求正应力\n\t            lambda_weight[i] = max(\n\t                # self.len/(self.inertia/self.area)**0.5\n\t                abs(edges[i].len / (edges[i].inertia / edges[i].area) ** 0.5) / abs(self.slenderness_ratio_C if edges[i].stress < 0 else self.slenderness_ratio_T) - 1.0,\n\t                0.0\n\t            )#判定杆件长细比是否超过限制：超出则比例存入数组，否则记为0\n\t        return lambda_weight\n", "    #评估杆件超长\n\t    def _get_length_longer(self, edges):\n\t        longer_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放长细比数据\n\t        for i in range(len(edges)):   \n\t            longer_weight[i] = max(\n\t                abs(edges[i].len) / abs(self.max_len) - 1.0,\n\t                0.0\n\t            )#判定杆件长度是否超过限制：超出则比例存入数组，否则记为0\n\t        return longer_weight\n\t    #评估杆件过短\n", "    def _get_length_shorter(self, edges):\n\t        shorter_weight = np.zeros(len(edges))  #初始化一个0数组，用于存放长细比数据\n\t        for i in range(len(edges)): \n\t            if edges[i].len < self.min_len:\n\t                shorter_weight[i] = 1.0-edges[i].len / self.min_len\n\t                #判定杆件长度是否过短：超出则比例存入数组，否则记为0\n\t        return shorter_weight\n\t    def _get_cross_value(self, points, edges):\n\t        cross_value = 0\n\t        for i in range(len(edges)):\n", "            for j in range(len(edges)):\n\t                if (edges[i].u == edges[j].v or edges[i].u == edges[j].u or edges[i].v == edges[j].v or edges[i].v == edges[j].u): continue\n\t                _, _, dis = closestDistanceBetweenLines(points[edges[i].u].Point2np(), points[edges[i].v].Point2np(), points[edges[j].u].Point2np(), points[edges[j].v].Point2np(), clampAll = True)\n\t                if (edges[i].d != None):\n\t                    r1, r2 = edges[i].d / 2, edges[j].d / 2\n\t                else:\n\t                    if (self._dimension == 2):\n\t                        r1, r2 = edges[i].area / 2, edges[j].area / 2\n\t                    elif (self._dimension == 3):\n\t                        r1, r2 = np.sqrt(edges[i].area / np.pi), np.sqrt(edges[j].area / np.pi)\n", "                if (dis <= r1 + r2): cross_value += 1\n\t        return cross_value\n\t    #调用以上函数运行结构分析\n\t    def run(self, points, edges, mode = 'check'):\n\t        # if mode = check, return a list\n\t        # else, return value\n\t        if 'IS_RUNNING_DYNAMIC' not in os.environ:\n\t            os.environ['IS_RUNNING_DYNAMIC'] = 'no'\n\t        while os.environ['IS_RUNNING_DYNAMIC'] == 'yes':\n\t            print('waiting for dynamics to be enabled')\n", "            time.sleep(0.1)\n\t        os.environ['IS_RUNNING_DYNAMIC'] = 'yes'\n\t        if (type(points) == dict or type(points) == OrderedDict):\n\t            _points = []\n\t            for i, point in points.items():\n\t                _points.append(point)\n\t            points = _points\n\t        if (type(edges) == dict or type(edges) == OrderedDict):\n\t            _edges = []\n\t            for i, edge in edges.items():\n", "                _edges.append(edge)\n\t            edges = _edges\n\t        is_struct = self._is_struct(points, edges) #运行结构建模与分析，is_struct返回结构是否正常完成分析\n\t        mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value = 0, 0, 0, 0, 0, 0, 0, 0\n\t        for edge in edges: mass += edge.len * edge.area * self._pho      #计算结构总质量\n\t        if is_struct: #如果结构成功完成分析，即结构是几何不变的\n\t            if self._use_dis_constraint:\n\t                dis_value = self._get_dis_value(points, mode)       #若启用，获取结构位移评估结果\n\t            if self._use_stress_constraint:\n\t                stress_value = self._get_stress_value(edges, mode)  #若启用，获取结构应力评估结果\n", "            if self._use_buckle_constraint:\n\t                buckle_value = self._get_buckle_value(edges)  #若启用，获取结构屈曲评估结果\n\t            if self._use_slenderness_constraint:\n\t                slenderness_value = self._get_slenderness_ratio(edges)  #若启用，获取结构长细比评估结果    \n\t            if self._use_longer_constraint:\n\t                longer_value = self._get_length_longer(edges)  #若启用，获取结构长细比评估结果\n\t            if self._use_shorter_constraint:\n\t                shorter_value = self._get_length_shorter(edges)  #若启用，获取结构长细比评估结果\n\t        if self._use_cross_constraint:\n\t            cross_value = self._get_cross_value(points, edges)\n", "        if (mode != 'check'):\n\t            if (is_struct and self._use_dis_constraint): dis_value = dis_value.sum()\n\t            if (is_struct and self._use_buckle_constraint): buckle_value = buckle_value.sum()\n\t            if (is_struct and self._use_slenderness_constraint): slenderness_value = slenderness_value.sum()\n\t            if (is_struct and self._use_stress_constraint): stress_value = stress_value.sum()\n\t            if (is_struct and self._use_longer_constraint): longer_value = longer_value.sum()\n\t            if (is_struct and self._use_shorter_constraint): shorter_value = shorter_value.sum()\n\t        os.environ['IS_RUNNING_DYNAMIC'] = 'no'\n\t        return (\n\t            is_struct, mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value\n", "        )\n\t    #绘制平面桁架\n\t    def render(self, points, edges):\n\t        _ax = plt.axes(projection='3d')\n\t        for point in points.values():   #绘制节点，scatter()绘制散点\n\t            if point.isSupport:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='g') #支座点为绿色\n\t            elif point.isLoad:\n\t                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='r') #荷载作用的节点为红色\n\t            else:\n", "                _ax.scatter([point.vec.x], [point.vec.y],[point.vec.z], color='b') #其余节点蓝色\n\t        for edge in edges.values():    #绘制杆件\n\t            x0 = [points[edge.u].vec.x, points[edge.v].vec.x]   #杆件起点\n\t            y0 = [points[edge.u].vec.y, points[edge.v].vec.y]   #杆件终点\n\t            z0 = [points[edge.u].vec.z, points[edge.v].vec.z]   #杆件起点\n\t            if edge.stress < -1e-7:\n\t                _ax.plot(x0, y0, z0, color='g', linewidth=(edge.area / math.pi)**0.5*500)    #压杆绿色\n\t            elif edge.stress > 1e-7:\n\t                _ax.plot(x0, y0, z0, color='r', linewidth=(edge.area / math.pi)**0.5*500)    #拉杆红色\n\t            else:\n", "                _ax.plot(x0, y0, z0, color='k', linewidth=(edge.area / math.pi)**0.5*500)    #零杆黑色\n\t        plt.show() #显示图像\n\tif __name__=='__main__':\n\t    truss=DynamicModel(3)    #创建结构对象\n\t    point_list, edge_list = readFile(\"PostResults/with_buckle_case1/1918656.txt\") #读取数据输入文件中的预设点和边\n\t    #将point_list, edge_list转换成truss.run的数据结构\n\t    points = {}\n\t    edges = {}\n\t    for i, point in enumerate(point_list):  #将预设点对象加入点集\n\t        points[i] = point\n", "    for i, edge in enumerate(edge_list):    #将预设边对象加入边集\n\t        if edge.u > edge.v:                 #边端点重新编号\n\t            tmp = edge.u\n\t            edge.u = edge.v\n\t            edge.v = tmp\n\t        edges[(edge.u, edge.v)] = edge        \n\t    print(points)\n\t    print(edges)\n\t    #运行模型分析                                 \n\t    is_struct, mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value = truss.run(points, edges) \n", "    #后处理，输出结构设计结果的提示信息\n\t    if not is_struct:\n\t        print(\"结构几何不稳定\")\n\t    elif np.sum(dis_value) > 0.0 or np.sum(stress_value) > 0.0 or np.sum(buckle_value) > 0.0 or np.sum(slenderness_value) or np.sum(longer_value) or np.sum(shorter_value):\n\t        for i in range(len(dis_value)):\n\t            if dis_value[i]>0.0:\n\t                print(\"第{:}结点位移超出限值{:}%\".format(i,dis_value[i]*100))\n\t        for i in range(len(stress_value)):\n\t            if stress_value[i]>0.0:\n\t                print(\"第{:}杆件应力超出限值{:}%\".format(i,stress_value[i]*100))\n", "        for i in range(len(buckle_value)):\n\t            if buckle_value[i]>0.0:\n\t                print(\"第{:}杆件屈曲应力超出限值{:}%\".format(i,buckle_value[i]*100))\n\t        for i in range(len(slenderness_value)):\n\t            if slenderness_value[i]>0.0:\n\t                print(\"第{:}杆件长细比超出限值{:}%\".format(i,slenderness_value[i]*100))\n\t        for i in range(len(longer_value)):\n\t            if longer_value[i]>0.0:\n\t                print(\"第{:}杆件长度超出限值{:}%\".format(i,longer_value[i]*100))\n\t        for i in range(len(shorter_value)):\n", "            if shorter_value[i]>0.0:\n\t                print(\"第{:}杆件长度短过限值{:}%\".format(i,shorter_value[i]*100))                 \n\t    else:\n\t        print(\"结构几何稳定，且所有约束满足。当前结构总质量为：{:.3f}kg\".format(mass))\n\t    truss.render(points, edges) #显示桁架图像\n"]}
{"filename": "truss_envs/reward.py", "chunked_list": ["import sys, os\n\timport openseespy.opensees as op\n\timport numpy as np\n\timport math\n\tfrom truss_envs.dynamic import DynamicModel\n\tfrom utils.utils import Bar, getlen2\n\tdef Envs_init(args__):\n\t    global args\n\t    global truss_env\n\t    args = args__\n", "    '''\n\t    global E\n\t    global pho\n\t    global Sigma_T\n\t    global Sigma_C\n\t    global slenderness_ratio_c\n\t    global slenderness_ratio_t\n\t    global dislimit\n\t    global maxlen\n\t    global minlen\n", "    global CONSTRAINT_STRESS\n\t    global CONSTRAINT_DIS\n\t    global CONSTRAINT_BUCKLE\n\t    global CONSTRAINT_SLENDERNESS\n\t    #Elasticity modulus\n\t    E = args.E #1.93*10**11\n\t    pho = args.pho #8.0*10**3\n\t    Sigma_T = args.sigma_T #123.0*10**6\n\t    Sigma_C = args.sigma_C #123.0*10**6\n\t    slenderness_ratio_c = args.slenderness_ratio_c #180.0\n", "    slenderness_ratio_t = args.slenderness_ratio_t #220.0\n\t    dislimit = args.dislimit #0.002\n\t    maxlen = args.len_range[1]\n\t    minlen = args.len_range[0]\n\t    #constraints\n\t    CONSTRAINT_STRESS = args.CONSTRAINT_STRESS\n\t    CONSTRAINT_DIS = args.CONSTRAINT_DIS\n\t    CONSTRAINT_BUCKLE = args.CONSTRAINT_BUCKLEd\n\t    CONSTRAINT_SLENDERNESS = args.CONSTRAINT_SLENDERNESS\n\t    '''\n", "    truss_env = DynamicModel(\n\t            dimension = args.env_dims,\n\t            E = args.E,\n\t            pho = args.pho,\n\t            sigma_T = args.sigma_T,\n\t            sigma_C = args.sigma_C,\n\t            dislimit = args.dislimit,\n\t            slenderness_ratio_C = args.slenderness_ratio_c,\n\t            slenderness_ratio_T = args.slenderness_ratio_t,\n\t            max_len = args.len_range[1],\n", "            min_len = args.len_range[0],\n\t            use_self_weight = args.CONSTRAINT_SELF_WEIGHT,\n\t            use_dis_constraint = args.CONSTRAINT_DIS,\n\t            use_stress_constraint = args.CONSTRAINT_STRESS,\n\t            use_buckle_constraint = args.CONSTRAINT_BUCKLE,\n\t            use_slenderness_constraint = args.CONSTRAINT_SLENDERNESS,\n\t            use_longer_constraint = args.CONSTRAINT_MAX_LENGTH,\n\t            use_shorter_constraint = args.CONSTRAINT_MIN_LENGTH,\n\t            use_cross_constraint = args.CONSTRAINT_CROSS_EDGE,\n\t        )\n", "Reward_cnt = 0\n\tdef reward_fun(p, e, sanity_check = True, mode = 'train'):\n\t    global Reward_cnt\n\t    Reward_cnt += 1\n\t    if (sanity_check):\n\t        for se in e:\n\t            new_e = Bar(se.u, se.v, se._area, leng = getlen2(p[se.u], p[se.v]), d = se.d, t = se.t)\n\t            assert(new_e.area == se.area)\n\t            assert(new_e.len == se.len)\n\t            assert(new_e.v == se.v)\n", "            assert(new_e.t == se.t)\n\t    is_struct, mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value = truss_env.run(p, e, mode = mode) \n\t    dis_value = np.sum(dis_value)\n\t    stress_value = np.sum(stress_value)\n\t    buckle_value = np.sum(buckle_value)\n\t    slenderness_value = np.sum(slenderness_value)\n\t    longer_value = np.sum(longer_value)\n\t    shorter_value = np.sum(shorter_value)\n\t    cross_value = np.sum(cross_value)\n\t    if (mode == 'check'):\n", "        print(is_struct, mass, dis_value, stress_value, buckle_value, slenderness_value, longer_value, shorter_value, cross_value)\n\t    #check_geometruc_stability\n\t    if ((not is_struct) or cross_value > 0):\n\t        return -1.0, Reward_cnt, mass, 0, 0, 0\n\t    # check slenderness ratio / longer_value / shorter_value\n\t    if (slenderness_value > 0 or longer_value > 0 or shorter_value > 0):\n\t        return 0, Reward_cnt, mass, 0, 0, 0\n\t    # check displacement / Stress_value / Buckle_value\n\t    if (dis_value > 1e-7 or stress_value > 1e-7 or buckle_value > 1e-7):\n\t        return 0, Reward_cnt, mass, dis_value, stress_value, buckle_value\n", "    # pass check\n\t    reward = mass * (1 + dis_value + stress_value + buckle_value)\n\t    return reward, Reward_cnt, mass, dis_value, stress_value, buckle_value"]}
