{"filename": "autopr/main.py", "chunked_list": ["from typing import Optional, Any, Type\n\tfrom git.repo import Repo\n\tfrom pydantic import BaseSettings\n\tfrom .models.events import EventUnion, IssueLabelEvent\n\tfrom .repos.completions_repo import get_completions_repo\n\tfrom .services.action_service import ActionService\n\tfrom .services.agent_service import AgentService\n\tfrom .services.chain_service import ChainService\n\tfrom .services.commit_service import CommitService\n\tfrom .services.diff_service import GitApplyService\n", "from .services.publish_service import PublishService\n\tfrom .services.rail_service import RailService\n\timport structlog\n\tclass Settings(BaseSettings):\n\t    agent_id: str = 'plan_and_code'\n\t    agent_config: Optional[dict[str, Any]] = None\n\t    base_branch: str = 'main'\n\t    target_branch_name_template: str = 'autopr/{issue_number}'\n\t    overwrite_existing: bool = False\n\t    loading_gif_url: str = \"https://media0.giphy.com/media/l3nWhI38IWDofyDrW/giphy.gif\"\n", "    model: str = \"gpt-4\"\n\t    temperature: float = 0.8\n\t    rail_temperature: float = 0.4\n\t    context_limit: int = 8192\n\t    min_tokens: int = 1000\n\t    max_tokens: int = 2000\n\t    num_reasks: int = 2\n\tclass MainService:\n\t    settings_class: Type[Settings] = Settings\n\t    publish_service_class: Type[PublishService] = PublishService\n", "    def __init__(self):\n\t        self.log = structlog.get_logger()\n\t        self.settings = settings = self.settings_class.parse_obj({})  # pyright workaround\n\t        self.event = self.get_event()\n\t        self.repo_path = self.get_repo_path()\n\t        self.repo = Repo(self.repo_path)\n\t        self.branch_name = self.get_branch_name()\n\t        self.base_branch_name = self.get_base_branch_name()\n\t        self.publish_service = self.get_publish_service()\n\t        # Create commit service\n", "        commit_service = CommitService(\n\t            repo=self.repo,\n\t            repo_path=self.repo_path,\n\t            branch_name=self.branch_name,\n\t            base_branch_name=self.base_branch_name,\n\t        )\n\t        commit_service.ensure_branch_exists()\n\t        # Create completions repo\n\t        completions_repo = get_completions_repo(\n\t            publish_service=self.publish_service,\n", "            model=settings.model,\n\t            context_limit=settings.context_limit,\n\t            min_tokens=settings.min_tokens,\n\t            max_tokens=settings.max_tokens,\n\t            temperature=settings.temperature,\n\t        )\n\t        # Create rail and chain service\n\t        rail_service = RailService(\n\t            completions_repo=completions_repo,\n\t            min_tokens=settings.min_tokens,\n", "            context_limit=settings.context_limit,\n\t            num_reasks=settings.num_reasks,\n\t            temperature=settings.rail_temperature,\n\t            publish_service=self.publish_service,\n\t        )\n\t        chain_service = ChainService(\n\t            completions_repo=completions_repo,\n\t            publish_service=self.publish_service,\n\t            context_limit=settings.context_limit,\n\t            min_tokens=settings.min_tokens,\n", "        )\n\t        # Create diff service\n\t        diff_service = GitApplyService(repo=self.repo)\n\t        # Create action service and agent service\n\t        action_service = ActionService(\n\t            repo=self.repo,\n\t            completions_repo=completions_repo,\n\t            rail_service=rail_service,\n\t            publish_service=self.publish_service,\n\t            chain_service=chain_service,\n", "        )\n\t        self.agent_service = AgentService(\n\t            repo=self.repo,\n\t            publish_service=self.publish_service,\n\t            rail_service=rail_service,\n\t            chain_service=chain_service,\n\t            diff_service=diff_service,\n\t            commit_service=commit_service,\n\t            action_service=action_service,\n\t        )\n", "    def run(self):\n\t        # Generate the PR\n\t        self.agent_service.run_agent(self.settings.agent_id, self.settings.agent_config, self.event)\n\t    def get_repo_path(self):\n\t        raise NotImplementedError\n\t    def get_event(self) -> EventUnion:\n\t        raise NotImplementedError\n\t    def get_publish_service(self, **additional_kwargs):\n\t        # Get repo owner and name from remote URL\n\t        remote_url = self.repo.remotes.origin.url\n", "        owner, repo_name = remote_url.removesuffix(\".git\").split('/')[-2:]\n\t        if isinstance(self.event, IssueLabelEvent):\n\t            issue = self.event.issue\n\t            pull_request_number = None\n\t        else:\n\t            issue = None\n\t            pull_request_number = self.event.pull_request.number\n\t        return self.publish_service_class(\n\t            owner=owner,\n\t            repo_name=repo_name,\n", "            head_branch=self.branch_name,\n\t            base_branch=self.base_branch_name,\n\t            issue=issue,\n\t            pull_request_number=pull_request_number,\n\t            loading_gif_url=self.settings.loading_gif_url,\n\t            overwrite_existing=self.settings.overwrite_existing,\n\t            **additional_kwargs,\n\t        )\n\t    def get_branch_name(self):\n\t        if isinstance(self.event, IssueLabelEvent):\n", "            branch_name = self.settings.target_branch_name_template.format(issue_number=self.event.issue.number)\n\t            if not self.settings.overwrite_existing:\n\t                # check if branch exists, if so, append a number to the end\n\t                remote = self.repo.remote()\n\t                references = remote.fetch()\n\t                i = 2\n\t                while f'{remote.name}/{branch_name}' in [ref.name for ref in references]:\n\t                    branch_name = self.settings.target_branch_name_template.format(\n\t                        issue_number=self.event.issue.number) + f'-{i}'\n\t                    i += 1\n", "            return branch_name\n\t        else:\n\t            return self.event.pull_request.head_branch\n\t    def get_base_branch_name(self):\n\t        if isinstance(self.event, IssueLabelEvent):\n\t            return self.settings.base_branch\n\t        else:\n\t            return self.event.pull_request.base_branch\n"]}
{"filename": "autopr/validators.py", "chunked_list": ["import os\n\timport re\n\tfrom typing import Union, Any, Dict, List, Optional\n\tfrom git import GitCommandError, Tree, Blob\n\tfrom autopr.services.diff_service import DiffService\n\tfrom guardrails import register_validator, Validator\n\tfrom guardrails.validators import EventDetail, Filter\n\tfrom git.repo import Repo\n\timport structlog\n\tlog = structlog.get_logger()\n", "@register_validator(name=\"filepath\", data_type=\"string\")\n\tclass FilePath(Validator):\n\t    \"\"\"Validate value is a valid file path.\n\t    - Name for `format` attribute: `filepath`\n\t    - Supported data types: `string`\n\t    \"\"\"\n\t    def validate(self, key: str, value: Any, schema: Dict) -> Union[Dict, List]:\n\t        log.debug(\"Validating filepath...\", key=key, value=value)\n\t        # Check if filepath is a string\n\t        if not isinstance(value, str):\n", "            raise EventDetail(\n\t                key,\n\t                value,\n\t                schema,\n\t                f\"File path '{value}' is not a string.\",\n\t                None,\n\t            )\n\t        # Is it normalized?\n\t        if value != os.path.normpath(value):\n\t            raise EventDetail(\n", "                key,\n\t                value,\n\t                schema,\n\t                f\"File path '{value}' is not normalized.\",\n\t                None,\n\t            )\n\t        # Check that it's not a directory\n\t        # The directory does not need to exist, so we can't use os.path.isdir\n\t        if value.endswith(os.sep):\n\t            raise EventDetail(\n", "                key,\n\t                value,\n\t                schema,\n\t                f\"File path '{value}' is a directory.\",\n\t                None,\n\t            )\n\t        return schema\n\t    def fix(self, error: EventDetail) -> Dict:\n\t        value = error.value\n\t        # Check if filepath is a string\n", "        if not isinstance(value, str):\n\t            error.schema[error.key] = Filter()\n\t            return error.schema\n\t        # Fix paths like \\\\dir\\file.txt to /dir/file.txt\n\t        value = os.path.normpath(value)\n\t        error.schema[error.key] = value\n\t        # Check that it's not a directory\n\t        try:\n\t            self.validate(error.key, value, error.schema)\n\t        except EventDetail:\n", "            error.schema[error.key] = Filter()\n\t            return error.schema\n\t        return error.schema\n"]}
{"filename": "autopr/__init__.py", "chunked_list": []}
{"filename": "autopr/gh_actions_entrypoint.py", "chunked_list": ["import json\n\timport os\n\tfrom typing import Any\n\tfrom autopr.main import Settings, MainService\n\timport yaml\n\tfrom autopr.log_config import configure_logging\n\tfrom autopr.services.event_service import GitHubEventService\n\tfrom autopr.services.publish_service import GitHubPublishService\n\tconfigure_logging()\n\timport structlog\n", "log = structlog.get_logger()\n\tclass GitHubActionSettings(Settings):\n\t    class Config:\n\t        env_prefix = 'INPUT_'\n\t        @classmethod\n\t        def parse_env_var(cls, field_name: str, raw_val: str) -> Any:\n\t            if field_name.endswith('agent_config'):\n\t                return yaml.safe_load(raw_val)\n\t            return cls.json_loads(raw_val)  # type: ignore\n\tclass GithubMainService(MainService):\n", "    settings_class = GitHubActionSettings\n\t    publish_service_class = GitHubPublishService\n\t    def get_repo_path(self):\n\t        return os.environ['GITHUB_WORKSPACE']\n\t    def get_event(self):\n\t        github_token = os.environ['INPUT_GITHUB_TOKEN']\n\t        event_name = os.environ['GITHUB_EVENT_NAME']\n\t        event_path = os.environ['GITHUB_EVENT_PATH']\n\t        # Load event\n\t        with open(event_path, 'r') as f:\n", "            event_json = json.load(f)\n\t        print(json.dumps(event_json, indent=2))\n\t        # Extract event\n\t        event_service = GitHubEventService(\n\t            github_token=github_token,\n\t        )\n\t        return event_service.parse_event(event_name, event_json)\n\t    def get_publish_service(self, **additional_kwargs):\n\t        github_token = os.environ['INPUT_GITHUB_TOKEN']\n\t        run_id = os.environ['GITHUB_RUN_ID']\n", "        return super().get_publish_service(\n\t            token=github_token,\n\t            run_id=run_id,\n\t            **additional_kwargs,\n\t        )\n\tif __name__ == '__main__':\n\t    log.info(\"Starting gh_actions_entrypoint.py\")\n\t    main_service = GithubMainService()\n\t    main_service.run()\n"]}
{"filename": "autopr/log_config.py", "chunked_list": ["def configure_logging(pretty=True):\n\t    import logging\n\t    import structlog\n\t    logging.basicConfig(\n\t        level=logging.INFO\n\t    )\n\t    if pretty:\n\t        processors = [\n\t            structlog.dev.ConsoleRenderer(colors=True),\n\t        ]\n", "    else:\n\t        processors = []\n\t    structlog.configure(\n\t        processors=processors,\n\t        cache_logger_on_first_use=True,\n\t    )\n"]}
{"filename": "autopr/agents/base.py", "chunked_list": ["import traceback\n\tfrom typing import ClassVar, Collection, Type\n\tfrom git.repo import Repo\n\tfrom autopr.models.events import EventUnion\n\tfrom autopr.services.action_service import ActionService\n\tfrom autopr.services.chain_service import ChainService\n\tfrom autopr.services.commit_service import CommitService\n\tfrom autopr.services.diff_service import DiffService\n\tfrom autopr.services.publish_service import PublishService\n\tfrom autopr.services.rail_service import RailService\n", "import structlog\n\tclass Agent:\n\t    \"\"\"\n\t    Base class for agents.\n\t    An agent is responsible for orchestrating the entire process of generating a pull request by invoking actions.\n\t    \"\"\"\n\t    #: The ID of the agent, used to identify it in the settings.\n\t    id: ClassVar[str]\n\t    def __init__(\n\t        self,\n", "        rail_service: RailService,\n\t        chain_service: ChainService,\n\t        diff_service: DiffService,\n\t        commit_service: CommitService,\n\t        publish_service: PublishService,\n\t        action_service: ActionService,\n\t        repo: Repo,\n\t        **kwargs,\n\t    ):\n\t        self.rail_service = rail_service\n", "        self.chain_service = chain_service\n\t        self.diff_service = diff_service\n\t        self.commit_service = commit_service\n\t        self.publish_service = publish_service\n\t        self.action_service = action_service\n\t        self.repo = repo\n\t        self.log = structlog.get_logger(service=\"brain\",\n\t                                        id=self.id)\n\t        if kwargs:\n\t            self.log.warning(\"Agent did not use additional options\", kwargs=kwargs)\n", "    def handle_event(\n\t        self,\n\t        event: EventUnion,\n\t    ) -> None:\n\t        \"\"\"\n\t        Override this method to implement your own logic of the agent.\n\t        This method should orchestrate the entire process of generating a pull request.\n\t        \"\"\"\n\t        raise NotImplementedError\n\tdef get_all_agents(parent=Agent) -> Collection[Type[Agent]]:\n", "    # import to initialize Action subclasses\n\t    import autopr.agents\n\t    descendants = set()\n\t    for subclass in parent.__subclasses__():\n\t        descendants.add(subclass)\n\t        # get subclasses of subclasses\n\t        descendants.update(get_all_agents(subclass))\n\t    return descendants\n"]}
{"filename": "autopr/agents/__init__.py", "chunked_list": ["from os.path import dirname, basename, isfile, join\n\timport glob\n\t# Import all modules in this directory\n\tfile_modules = glob.glob(join(dirname(__file__), \"*.py\"))\n\tfile_basenames = [basename(f)[:-3] for f in file_modules if isfile(f) and not f.endswith('__init__.py')]\n\tdirectory_module_inits = glob.glob(join(dirname(__file__), \"*\", \"__init__.py\"))\n\tdirectory_modules = [dirname(f) for f in directory_module_inits]\n\tdirectory_module_basenames = [basename(f) for f in directory_modules]\n\t__all__ = file_basenames + directory_module_basenames\n\tfrom . import *\n"]}
{"filename": "autopr/agents/plan_and_code.py", "chunked_list": ["from typing import Collection\n\timport structlog\n\tfrom autopr.actions.base import ContextDict\n\tfrom autopr.actions.utils.commit import PullRequestDescription, CommitPlan, PullRequestAmendment\n\tfrom autopr.agents.base import Agent\n\tfrom autopr.models.events import EventUnion, PullRequestCommentEvent, IssueLabelEvent\n\tlog = structlog.get_logger()\n\tclass PlanAndCode(Agent):\n\t    \"\"\"\n\t    A simple agent that:\n", "    - plans commits from issues or pull request comments,\n\t    - opens and responds to pull requests,\n\t    - writes commits to the pull request.\n\t    \"\"\"\n\t    #: The ID of the agent, used to identify it in the settings\n\t    id = \"plan_and_code\"\n\t    def __init__(\n\t        self,\n\t        *args,\n\t        inspection_actions: Collection[str] = (\n", "            \"look_at_files\",\n\t        ),\n\t        planning_actions: Collection[str] = (\n\t            \"plan_pull_request\",\n\t            \"request_more_information\"\n\t        ),\n\t        response_actions: Collection[str] = (\n\t            \"plan_commits\",\n\t            \"request_more_information\",\n\t        ),\n", "        codegen_actions: Collection[str] = (\n\t            'new_file',\n\t            'edit_file',\n\t        ),\n\t        max_codegen_iterations: int = 5,\n\t        **kwargs,\n\t    ):\n\t        super().__init__(*args, **kwargs)\n\t        self.inspection_actions = inspection_actions\n\t        self.planning_actions = planning_actions\n", "        self.response_actions = response_actions\n\t        self.codegen_actions = codegen_actions\n\t        self.max_codegen_iterations = max_codegen_iterations\n\t    def write_commit(\n\t        self,\n\t        commit_plan: CommitPlan,\n\t        context: ContextDict,\n\t        context_headings: dict[str, str]\n\t    ) -> ContextDict:\n\t        self.publish_service.start_section(f\"🔨 Writing commit {commit_plan.commit_message}\")\n", "        # Set the current commit in the context\n\t        context['current_commit'] = commit_plan\n\t        # Clear action_history in the context for each commit\n\t        context['action_history'] = []\n\t        # Generate the changes\n\t        context = self.action_service.run_actions_iteratively(\n\t            self.codegen_actions,\n\t            context,\n\t            context_headings={\n\t                'current_commit': 'Commit we are currently generating',\n", "                'action_history': 'Actions that have been run so far',\n\t                **context_headings,\n\t            },\n\t            max_iterations=self.max_codegen_iterations,\n\t            include_finished=True,\n\t        )\n\t        # Show the diff in the progress report\n\t        diff = self.diff_service.get_diff()\n\t        if diff:\n\t            self.publish_service.publish_code_block(\n", "                heading=\"Diff\",\n\t                code=diff,\n\t                language=\"diff\",\n\t            )\n\t            self.publish_service.end_section(f\"✅ Committed {commit_plan.commit_message}\")\n\t        else:\n\t            self.publish_service.end_section(f\"⚠️ Empty commit {commit_plan.commit_message}\")\n\t        # Commit and push the changes\n\t        self.commit_service.commit(commit_plan.commit_message, push=True)\n\t        return context\n", "    def respond_to_pr_comment(\n\t        self,\n\t        event: PullRequestCommentEvent,\n\t    ):\n\t        # Checkout the head branch\n\t        head_branch = event.pull_request.head_branch\n\t        base_branch = event.pull_request.base_branch\n\t        self.repo.heads[head_branch].checkout()\n\t        # Get list of commits on the branch\n\t        commits = [\n", "            commit.message\n\t            for commit in self.repo.iter_commits(f\"origin/{base_branch}..{head_branch}\")\n\t        ]\n\t        # Initialize the context\n\t        context = ContextDict(\n\t            commits_in_pull_request=commits,\n\t            request=event.new_comment,\n\t        )\n\t        # Run the inspection actions\n\t        context = self.action_service.run_actions_iteratively(\n", "            self.inspection_actions,\n\t            context,\n\t            max_iterations=1,\n\t        )\n\t        # Run the response actions\n\t        context = self.action_service.run_actions_iteratively(\n\t            self.response_actions,\n\t            context,\n\t            max_iterations=1,\n\t        )\n", "        # Get the pull request description from the context\n\t        if 'pull_request_amendment' not in context:\n\t            # Stop the agent if the action did not return a pull request description\n\t            return\n\t        pull_request_amendment = context['pull_request_amendment']\n\t        if not isinstance(pull_request_amendment, PullRequestAmendment):\n\t            raise ValueError(f\"Action returned a pull request amendment that is not a PullRequestDescription object\")\n\t        if pull_request_amendment.comment:\n\t            # Comment on the pull request\n\t            self.publish_service.publish_comment(pull_request_amendment.comment)\n", "        if pull_request_amendment.commits:\n\t            # Stop the agent if the action did not return a pull request description\n\t            commits = pull_request_amendment.commits\n\t            if not all(isinstance(commit, CommitPlan)\n\t                       for commit in commits):\n\t                raise ValueError(f\"Action returned commits that are not CommitPlan objects\")\n\t            for current_commit in commits:\n\t                context = self.write_commit(\n\t                    current_commit,\n\t                    context,\n", "                    context_headings={\n\t                        'pull_request': \"Pull request that we are adding commits to\",\n\t                        'request': \"Request that we are responding to\",\n\t                    }\n\t                )\n\t                self.log.info(f\"Committed {current_commit.commit_message}\")\n\t    def create_pull_request(\n\t        self,\n\t        event: IssueLabelEvent,\n\t    ) -> None:\n", "        # Create new branch\n\t        self.commit_service.overwrite_new_branch()\n\t        issue = event.issue\n\t        # Initialize the context\n\t        context = ContextDict(\n\t            issue=issue,\n\t        )\n\t        # Run the inspection actions\n\t        context = self.action_service.run_actions_iteratively(\n\t            self.inspection_actions,\n", "            context,\n\t            max_iterations=1,\n\t        )\n\t        # Generate the pull request plan (commit messages and relevant filepaths)\n\t        context = self.action_service.run_actions_iteratively(\n\t            self.planning_actions,\n\t            context,\n\t            max_iterations=1,\n\t        )\n\t        # Get the pull request description from the context\n", "        if 'pull_request_description' not in context:\n\t            # Stop the agent if the action did not return a pull request description\n\t            return\n\t        pr_desc = context['pull_request_description']\n\t        if not isinstance(pr_desc, PullRequestDescription):\n\t            raise TypeError(f\"Actions returned a pull request description of type \"\n\t                            f\"{type(pr_desc)} instead of PullRequestDescription\")\n\t        # Publish the description\n\t        self.publish_service.set_title(pr_desc.title)\n\t        self.publish_service.publish_comment(pr_desc.body)\n", "        for current_commit in pr_desc.commits:\n\t            context = self.write_commit(\n\t                current_commit,\n\t                context,\n\t                context_headings={\n\t                    'pull_request_description': 'Plan for the pull request',\n\t                },\n\t            )\n\t    def handle_event(\n\t        self,\n", "        event: EventUnion,\n\t    ) -> None:\n\t        if isinstance(event, IssueLabelEvent):\n\t            self.create_pull_request(event)\n\t        elif isinstance(event, PullRequestCommentEvent):\n\t            self.respond_to_pr_comment(event)\n\t        else:\n\t            raise NotImplementedError(f\"Event type {type(event)} not supported\")\n"]}
{"filename": "autopr/repos/completions_repo.py", "chunked_list": ["from typing import Optional\n\timport openai\n\timport openai.error\n\timport structlog\n\tfrom tenacity import retry, retry_if_exception_type, wait_random_exponential, stop_after_attempt\n\tfrom autopr.services.publish_service import PublishService\n\tfrom autopr.utils import tokenizer\n\tclass CompletionsRepo:\n\t    \"\"\"\n\t    Repository that handles running completions through a language model.\n", "    \"\"\"\n\t    #: A list of models that this repo implements. Set this in the subclass.\n\t    models: list[str]\n\t    def __init__(\n\t        self,\n\t        publish_service: PublishService,\n\t        model: str,\n\t        max_tokens: int = 2000,\n\t        min_tokens: int = 1000,\n\t        context_limit: int = 8192,\n", "        temperature: float = 0.8,\n\t    ):\n\t        self.publish_service = publish_service\n\t        self.model = model\n\t        self.max_tokens = max_tokens\n\t        self.min_tokens = min_tokens\n\t        self.context_limit = context_limit\n\t        self.temperature = temperature\n\t        self.tokenizer = tokenizer.get_tokenizer()\n\t        self.log = structlog.get_logger(repo=self.__class__.__name__)\n", "    def complete(\n\t        self,\n\t        prompt: str,\n\t        system_prompt: Optional[str] = None,\n\t        examples: Optional[list[tuple[str, str]]] = None,\n\t        temperature: Optional[float] = None,\n\t    ) -> str:\n\t        log = self.log.bind(\n\t            model=self.model,\n\t            prompt=prompt,\n", "        )\n\t        if examples is None:\n\t            examples = []\n\t        if system_prompt is None:\n\t            system_prompt = \"You are a helpful assistant.\"\n\t        if temperature is None:\n\t            temperature = self.temperature\n\t        length = len(self.tokenizer.encode(prompt))\n\t        max_tokens = min(self.max_tokens, self.context_limit - length)\n\t        self.log.info(\n", "            \"Running completion\",\n\t            prompt=prompt,\n\t        )\n\t        try:\n\t            result = self._complete(\n\t                system_prompt=system_prompt,\n\t                examples=examples,\n\t                prompt=prompt,\n\t                max_tokens=max_tokens,\n\t                temperature=temperature,\n", "            )\n\t        except openai.error.InvalidRequestError as e:\n\t            if \"`gpt-4` does not exist\" not in str(e):\n\t                raise e\n\t            # Warn that the user doesn't have access to gpt-4\n\t            while len(self.publish_service.sections_stack) > 1:\n\t                self.publish_service.end_section()\n\t            self.publish_service.publish_update(\n\t                \"⚠️⚠️⚠️ Your OpenAI API key does not have access to the `gpt-4` model. \"\n\t                \"Please note that ChatGPT Plus does not give you access to the `gpt-4` API; \" \n", "                \"you need to sign up on [the GPT-4 API waitlist](https://openai.com/waitlist/gpt-4-api). \"\n\t            )\n\t            raise e\n\t        log.info(\n\t            \"Completed\",\n\t            result=result,\n\t        )\n\t        return result\n\t    def _complete(\n\t        self,\n", "        system_prompt: str,\n\t        examples: list[tuple[str, str]],\n\t        prompt: str,\n\t        max_tokens: int,\n\t        temperature: float,\n\t    ) -> str:\n\t        \"\"\"\n\t        Subclass this method to implement the language model call.\n\t        \"\"\"\n\t        raise NotImplementedError\n", "openai_retry_if_union = (\n\t    retry_if_exception_type(openai.error.Timeout)\n\t    | retry_if_exception_type(openai.error.APIError)\n\t    | retry_if_exception_type(openai.error.APIConnectionError)\n\t    | retry_if_exception_type(openai.error.RateLimitError)\n\t    | retry_if_exception_type(openai.error.ServiceUnavailableError)\n\t)\n\tclass OpenAIChatCompletionsRepo(CompletionsRepo):\n\t    models = [\n\t        'gpt-4',\n", "        'gpt-3.5-turbo',\n\t    ]\n\t    @retry(\n\t        retry=openai_retry_if_union,\n\t        wait=wait_random_exponential(min=1, max=240),\n\t        stop=stop_after_attempt(8)\n\t    )\n\t    def _complete(\n\t        self,\n\t        prompt: str,\n", "        system_prompt: str,\n\t        examples: list[tuple[str, str]],\n\t        max_tokens: int,\n\t        temperature: float,\n\t    ) -> str:\n\t        messages = [\n\t            {\"role\": \"system\", \"content\": system_prompt},\n\t        ]\n\t        for example in examples:\n\t            messages.append({\"role\": \"user\", \"content\": example[0]})\n", "            messages.append({\"role\": \"assistant\", \"content\": example[1]})\n\t        messages.append({\"role\": \"user\", \"content\": prompt})\n\t        openai_response = openai.ChatCompletion.create(\n\t            model=self.model,\n\t            messages=messages,\n\t            temperature=temperature,\n\t            max_tokens=max_tokens,\n\t        )\n\t        if openai_response is None or not isinstance(openai_response, dict):\n\t            self.log.error(\n", "                \"OpenAI chat completion returned invalid response\",\n\t                openai_response=openai_response,\n\t            )\n\t            return \"\"\n\t        self.log.info(\n\t            \"Ran OpenAI chat completion\",\n\t            openai_response=openai_response,\n\t        )\n\t        return openai_response[\"choices\"][0][\"message\"][\"content\"]\n\tclass OpenAICompletionsRepo(CompletionsRepo):\n", "    models = [\n\t        'text-davinci-003',\n\t    ]\n\t    @retry(\n\t        retry=openai_retry_if_union,\n\t        wait=wait_random_exponential(min=1, max=240),\n\t        stop=stop_after_attempt(8)\n\t    )\n\t    def _complete(\n\t        self,\n", "        prompt: str,\n\t        system_prompt: str,\n\t        examples: list[tuple[str, str]],\n\t        max_tokens: int,\n\t        temperature: float,\n\t    ) -> str:\n\t        prompt = system_prompt\n\t        for example in examples:\n\t            prompt += f\"\\n\\n{example[0]}\\n{example[1]}\"\n\t        prompt += f\"\\n\\n{prompt}\"\n", "        openai_response = openai.Completion.create(\n\t            model=self.model,\n\t            prompt=prompt,\n\t            temperature=temperature,\n\t            max_tokens=max_tokens,\n\t        )\n\t        self.log.info(\n\t            \"Ran OpenAI completion\",\n\t            openai_response=openai_response,\n\t        )\n", "        if openai_response is None or not isinstance(openai_response, dict):\n\t            self.log.error(\n\t                \"OpenAI chat completion returned invalid response\",\n\t                openai_response=openai_response,\n\t            )\n\t            return \"\"\n\t        return openai_response[\"choices\"][0][\"text\"]\n\tdef get_completions_repo(\n\t    publish_service: PublishService,\n\t    model: str = \"gpt-4\",\n", "    max_tokens: int = 2000,\n\t    min_tokens: int = 1000,\n\t    context_limit: int = 8192,\n\t    temperature: float = 0.8,\n\t):\n\t    repo_implementations = CompletionsRepo.__subclasses__()\n\t    for repo_implementation in repo_implementations:\n\t        if model in repo_implementation.models:\n\t            return repo_implementation(\n\t                publish_service=publish_service,\n", "                model=model,\n\t                max_tokens=max_tokens,\n\t                min_tokens=min_tokens,\n\t                context_limit=context_limit,\n\t                temperature=temperature,\n\t            )\n\t    raise ValueError(f\"Model {model} not implemented\")\n"]}
{"filename": "autopr/repos/__init__.py", "chunked_list": []}
{"filename": "autopr/actions/new_file.py", "chunked_list": ["import os\n\tfrom typing import Optional, Any\n\tfrom autopr.actions.base import Action, ContextDict\n\tfrom autopr.actions.utils.file import GeneratedHunkOutputParser, ContextFile, GeneratedFileHunk, make_file_context, \\\n\t    add_element_to_context_list\n\tfrom autopr.actions.utils.commit import CommitPlan\n\tfrom autopr.models.prompt_chains import PromptChain\n\tclass NewFileChain(PromptChain):\n\t    output_parser = GeneratedHunkOutputParser()\n\t    prompt_template = f\"\"\"Hey, we've got a new file to create.\n", "{{context}}\n\tThis is the codebase subset we decided to look at:\n\t```\n\t{{context_hunks}}\n\t```\n\tThis is the plan for the file we're creating:\n\t```\n\t{{plan}}\n\t```\n\tPlease send me the contents of the file.\n", "{{format_instructions}}\"\"\"\n\t    context: ContextDict\n\t    context_hunks: list[ContextFile]\n\t    plan: str\n\tclass NewFile(Action):\n\t    id = \"new_file\"\n\t    description = \"Make a new file.\"\n\t    class Arguments(Action.Arguments):\n\t        filepath: str\n\t        description: str\n", "        output_spec = f\"\"\"\n\t<string\n\t    name=\"filepath\"\n\t    description=\"Path to the newly created file.\"\n\t    required=\"true\"\n\t/>\n\t<string\n\t    name=\"description\"\n\t    description=\"Description of the contents of the new file.\"\n\t    required=\"true\"\n", "/>\n\t\"\"\"\n\t    def run(\n\t        self,\n\t        args: Arguments,\n\t        context: ContextDict,\n\t    ) -> ContextDict:\n\t        self.publish_service.update_section(title=f\"📄 Creating new file: {args.filepath}\")\n\t        # Check if file exists\n\t        repo_path = self.repo.working_tree_dir\n", "        assert repo_path is not None\n\t        filepath = os.path.join(repo_path, args.filepath)\n\t        if os.path.exists(filepath):\n\t            self.publish_service.update_section(title=f\"❌ Failed to create new file: {args.filepath} \"\n\t                                                      f\"(file already exists)\")\n\t            return add_element_to_context_list(\n\t                context,\n\t                \"action_history\",\n\t                f\"Failed to create new file: {args.filepath} (file already exists)\"\n\t            )\n", "        # Check if filename is a directory (doesnt exist yet)\n\t        if os.path.basename(filepath) == \"\":\n\t            self.publish_service.update_section(title=f\"❌ Failed to create new file: {args.filepath} \"\n\t                                                      f\"(filename is a directory)\")\n\t            return add_element_to_context_list(\n\t                context,\n\t                \"action_history\",\n\t                f\"Failed to create new file: {args.filepath} (filename is a directory)\"\n\t            )\n\t        # Get the other relevant hunks\n", "        if \"current_commit\" not in context:\n\t            self.log.error(\"Context does not specify current_commit\")\n\t            context_hunks = []\n\t        elif not isinstance(current_commit := context[\"current_commit\"], CommitPlan):\n\t            self.log.error(\"Context current_commit is not a CommitPlan\")\n\t            context_hunks = []\n\t        else:\n\t            # TODO remove the hunk that's being edited, but leave surrounding context\n\t            #  or rather, build better context by iteratively asking about it\n\t            context_hunks = make_file_context(self.repo, current_commit)\n", "        # Run new file langchain\n\t        new_file_chain = NewFileChain(\n\t            context=context,\n\t            context_hunks=context_hunks,\n\t            plan=args.description,\n\t        )\n\t        new_file_hunk: Optional[GeneratedFileHunk] = self.chain_service.run_chain(new_file_chain)\n\t        if new_file_hunk is None:\n\t            self.publish_service.update_section(title=f\"❌ Failed to create new file: {args.filepath}\")\n\t            return add_element_to_context_list(\n", "                context,\n\t                \"action_history\",\n\t                f\"Failed to create new file: {args.filepath}\"\n\t            )\n\t        # Create dirs\n\t        dirpath = os.path.dirname(filepath)\n\t        os.makedirs(dirpath, exist_ok=True)\n\t        # Write file\n\t        path = os.path.join(repo_path, filepath)\n\t        with open(path, \"w\") as f:\n", "            f.write(new_file_hunk.contents)\n\t        self.publish_service.update_section(title=f\"📄 Created new file: {args.filepath}\")\n\t        if outcome := new_file_hunk.outcome:\n\t            outcome = \" with outcome: \" + outcome\n\t        return add_element_to_context_list(\n\t            context,\n\t            \"action_history\",\n\t            f\"Created {args.filepath}{outcome}\"\n\t        )\n"]}
{"filename": "autopr/actions/base.py", "chunked_list": ["from typing import ClassVar, List, Type, Collection, Any, Optional\n\timport pydantic\n\timport structlog\n\tfrom git.repo import Repo\n\tfrom pydantic import Extra\n\tfrom autopr.models.rail_objects import RailObject\n\tfrom autopr.services.chain_service import ChainService\n\tfrom autopr.services.publish_service import PublishService\n\tfrom autopr.services.rail_service import RailService\n\tclass ContextDict(dict[str, Any]):\n", "    \"\"\"\n\t    A dictionary of context variables passed between actions.\n\t    Overrides `__str__` to format the context in a prompt-friendly way.\n\t    \"\"\"\n\t    def select_keys(self, keys: Collection[str]) -> \"ContextDict\":\n\t        \"\"\"\n\t        Select a subset of keys from the context.\n\t        \"\"\"\n\t        for key in keys:\n\t            if key not in self:\n", "                raise KeyError(f\"Key {key} not found in context\")\n\t        return ContextDict({key: self[key] for key in keys})\n\t    @staticmethod\n\t    def key_to_heading(key: str) -> str:\n\t        \"\"\"\n\t        Convert a context key to a heading.\n\t        \"\"\"\n\t        return key.replace(\"_\", \" \").title()\n\t    def as_string(\n\t        self,\n", "        variable_headings: Optional[dict[str, str]] = None,\n\t        enclosure_mark: str = \"+-+\",\n\t    ):\n\t        \"\"\"\n\t        Format the context as a string.\n\t        Parameters\n\t        ----------\n\t        variable_headings\n\t            A dictionary mapping context keys to headings.\n\t            If not provided, the keys will be used as headings.\n", "        enclosure_mark\n\t            The string to use to enclose each variable.\n\t        \"\"\"\n\t        if variable_headings is None:\n\t            variable_headings = {}\n\t        # Add any missing keys to the variable headings\n\t        for key in self:\n\t            if key not in variable_headings:\n\t                variable_headings[key] = self.key_to_heading(key)\n\t        context_string = \"Given context variables enclosed by \" + enclosure_mark + \":\"\n", "        for key, value in self.items():\n\t            # Format the value as a string\n\t            if isinstance(value, list):\n\t                valstr = \"\\n\".join(str(item) for item in value)\n\t            else:\n\t                valstr = str(value)\n\t            # Add the variable to the context string\n\t            context_string += f\"\"\"\\n\\n{variable_headings[key]}:\n\t{enclosure_mark}\n\t{valstr}\n", "{enclosure_mark}\"\"\"\n\t        return context_string\n\t    def __str__(self):\n\t        return self.as_string()\n\tclass Action:\n\t    \"\"\"\n\t    Base class for all actions.\n\t    Actions are the basic unit of work in the autonomous agent.\n\t    They are responsible for performing a single task, affecting the environment in some way,\n\t    and returning a string describing the result of the action.\n", "    \"\"\"\n\t    # The ID of the action, used to identify it in the AutoPR configuration. `finished` is a reserved ID. Required.\n\t    id: ClassVar[str]\n\t    # The description of the action, used to describe it to the LLM upon action selection.\n\t    description: ClassVar[str] = \"\"\n\t    class Arguments(RailObject):\n\t        \"\"\"\n\t        Arguments for the action.\n\t        If the action takes arguments that should be queried by the LLM (e.g., filename),\n\t        subclass and override this class in your Action subclass,\n", "        defining the arguments as pydantic fields.\n\t        Example:\n\t            ```\n\t            class Arguments(Action.Arguments):\n\t                filepaths: list[str]\n\t                output_spec = \"<list name='filepaths'><string/></list>\"\n\t            ```\n\t        \"\"\"\n\t        # `output_spec` describes the structure of the arguments for guardrails,\n\t        # to be mapped into the model subclass.\n", "        # Soon to be deprecated, as guardrails adopts pydantic Field parameters.\n\t        output_spec: ClassVar[str] = \"\"\n\t    def run(\n\t        self,\n\t        args: Arguments,\n\t        context: ContextDict,\n\t    ) -> ContextDict:\n\t        \"\"\"\n\t        Run the action.\n\t        The return value should be a string describing the action's result.\n", "        Parameters\n\t        ----------\n\t        args : Arguments\n\t            The arguments provided by the LLM, as per the overridden `Arguments` class.\n\t        context : ContextDict\n\t            The context for the action,\n\t            containing information about e.g., the issue, the current commit, and other actions' results.\n\t        Returns\n\t        -------\n\t        ContextDict\n", "            The updated context, adding any new information to the context.\n\t        \"\"\"\n\t        raise NotImplementedError\n\t    def __init__(\n\t        self,\n\t        repo: Repo,\n\t        rail_service: RailService,\n\t        chain_service: ChainService,\n\t        publish_service: PublishService,\n\t        **kwargs,\n", "    ):\n\t        # Use repo for git operations\n\t        self.repo = repo\n\t        # Use rail and chain services to run LLM calls\n\t        self.rail_service = rail_service\n\t        self.chain_service = chain_service\n\t        # Use publish service for in-progress updates\n\t        self.publish_service = publish_service\n\t        # Use log for more detailed debug messages\n\t        self.log = structlog.get_logger(service=\"action\",\n", "                                        id=self.id)\n\t        # Define kwargs to pass configuration to actions via `action_config`\n\t        if kwargs:\n\t            self.log.warning(\"Action received unexpected kwargs that it will ignore\",\n\t                             kwargs=kwargs)\n\tdef get_all_actions(parent=Action) -> Collection[Type[Action]]:\n\t    # import to initialize Action subclasses\n\t    import autopr.actions\n\t    descendants = set()\n\t    for subclass in parent.__subclasses__():\n", "        descendants.add(subclass)\n\t        # get subclasses of subclasses\n\t        descendants.update(get_all_actions(subclass))\n\t    return descendants\n"]}
{"filename": "autopr/actions/look_at_files.py", "chunked_list": ["from typing import Union, Optional\n\timport pydantic\n\tfrom git.repo import Repo\n\tfrom autopr.actions.base import Action, ContextDict\n\tfrom autopr.actions.utils.commit import PullRequestDescription\n\tfrom autopr.models.artifacts import Issue\n\tfrom autopr.models.prompt_rails import PromptRail\n\tfrom autopr.models.rail_objects import RailObject\n\tfrom autopr.utils.repo import repo_to_file_descriptors, trim_chunk, filter_seen_chunks, FileDescriptor\n\tclass InitialFileSelectResponse(RailObject):\n", "    output_spec = \"\"\"<list name=\"filepaths\">\n\t    <string\n\t        description=\"Files in this repository that we should look at.\"\n\t    />\n\t</list>\"\"\"\n\t    filepaths: list[str]\n\t    @classmethod\n\t    def get_rail_spec(cls):\n\t        return f\"\"\"\n\t<rail version=\"0.1\">\n", "<output>\n\t{cls.output_spec}\n\t</output>\n\t<instructions>\n\tYou are a helpful assistant only capable of communicating with valid JSON, and no other text.\n\t@json_suffix_prompt_examples\n\t</instructions>\n\t<prompt>\n\tGiven the following document surrounded by `+++++`, answer the following questions. \n\tIf the answer doesn't exist in the document, enter `null`.\n", "+++++\n\t{{{{raw_document}}}}\n\t+++++\n\tExtract information from this document and return a JSON that follows the correct schema.\n\tIf looking at files would be a waste of time, please submit an empty list.\n\t@xml_prefix_prompt\n\t{{output_schema}}\n\t</prompt>\n\t</rail>\n\t\"\"\"\n", "class InitialFileSelect(PromptRail):\n\t    # Select files given issue and files in repo\n\t    prompt_template = f\"\"\"Hey, somebody just opened an issue in my repo, could you help me write a pull request?\n\t{{context}}\n\tThe list of files in the repo is:\n\t```{{filepaths_with_token_lengths}}```\n\tShould we take a look at any files? If so, pick only a few files (max {{token_limit}} tokens). \n\tRespond with a very short rationale, and a list of files.\n\tIf looking at files would be a waste of time with regard to the issue, respond with an empty list.\"\"\"\n\t    output_type = InitialFileSelectResponse\n", "    # extra_params = {\n\t    #     'temperature': 0,\n\t    # }\n\t    context: ContextDict\n\t    file_descriptors: list[FileDescriptor]\n\t    token_limit: int\n\t    def get_string_params(self) -> dict[str, str]:\n\t        return {\n\t            'context': str(self.context),\n\t            'filepaths_with_token_lengths': '\\n'.join([\n", "                file_descriptor.filepaths_with_token_lengths_to_str()\n\t                for file_descriptor in self.file_descriptors\n\t            ]),\n\t            'token_limit': str(self.token_limit),\n\t        }\n\tclass LookAtFilesResponse(RailObject):\n\t    output_spec = \"\"\"<string \n\t    name=\"notes\" \n\t    description=\"Notes relevant to solving the issue, that we will use to plan our code commits.\" \n\t    length=\"1 1000\"\n", "    on-fail=\"noop\" \n\t/>\n\t<list name=\"filepaths_we_should_look_at\">\n\t    <string\n\t        description=\"The paths to files we should look at next in the repo. Drop any files that are a waste of time with regard to the issue.\"\n\t    />\n\t</list>\"\"\"\n\t    filepaths_we_should_look_at: Optional[list[str]] = None\n\t    notes: str\n\t    @classmethod\n", "    def get_rail_spec(cls):\n\t        return f\"\"\"\n\t<rail version=\"0.1\">\n\t<output>\n\t{cls.output_spec}\n\t</output>\n\t<instructions>\n\tYou are a helpful assistant only capable of communicating with valid JSON, and no other text.\n\t@json_suffix_prompt_examples\n\t</instructions>\n", "<prompt>\n\tGiven the following document surrounded by `+++++`, answer the following questions. \n\tIf the answer doesn't exist in the document, enter `null`.\n\t+++++\n\t{{{{raw_document}}}}\n\t+++++\n\tExtract information from this document and return a JSON that follows the correct schema.\n\tIf looking at files would be a waste of time, please submit an empty list.\n\t@xml_prefix_prompt\n\t{{output_schema}}\n", "</prompt>\n\t</rail>\n\t\"\"\"\n\tclass LookAtFiles(PromptRail):\n\t    # Select files given issue, unseen files in repo, and notes\n\t    prompt_template = f\"\"\"Hey, somebody just submitted an issue, could you own it, and write a pull request?\n\t{{context}}\n\tWe've decided to look at these files:\n\t```{{codebase}}```\n\tThe list of files in the repo that we haven't taken a look at yet:\n", "```{{filepaths_with_token_lengths}}```\n\tTake some notes that will help us plan our code commits, in an effort to close the issue. \n\tAlso, should we take a look at any other files? If so, pick only a few files (max {{token_limit}} tokens).\n\tRespond with some very brief notes, and a list of files to continue looking at. \n\tIf looking at files would be a waste of time with regard to the issue, respond with an empty list.\"\"\"\n\t    output_type = LookAtFilesResponse\n\t    # extra_params = {\n\t    #     'temperature': 0.2,\n\t    # }\n\t    context: ContextDict\n", "    selected_file_contents: list[FileDescriptor]\n\t    prospective_file_descriptors: list[FileDescriptor]\n\t    token_limit: int\n\t    _filtered_prospective_file_descriptors: list[FileDescriptor] = pydantic.PrivateAttr(default_factory=list)\n\t    def get_string_params(self) -> dict[str, str]:\n\t        self._filtered_prospective_file_descriptors = filter_seen_chunks(\n\t            self.selected_file_contents, self.prospective_file_descriptors\n\t        )\n\t        return {\n\t            'context': str(self.context),\n", "            'codebase': '\\n'.join([\n\t                file_descriptor.filenames_and_contents_to_str()\n\t                for file_descriptor in self.selected_file_contents\n\t            ]),\n\t            'filepaths_with_token_lengths': '\\n'.join([\n\t                file_descriptor.filepaths_with_token_lengths_to_str()\n\t                for file_descriptor in self._filtered_prospective_file_descriptors\n\t            ]),\n\t            'token_limit': str(self.token_limit),\n\t        }\n", "    def trim_params(self) -> bool:\n\t        if trim_chunk(self.selected_file_contents):\n\t            return True\n\t        return super().trim_params()\n\tclass ContinueLookingAtFiles(PromptRail):\n\t    # Continue selecting files and generating fp_notes given issue, unseen files in repo, and notes\n\t    prompt_template = f\"\"\"Hey, somebody just submitted an issue, could you own it, and write a pull request?\n\t{{context}}\n\tSome notes we've taken while looking at files so far:\n\t```{{notes}}```\n", "We've decided to look at these files:\n\t```{{codebase}}```\n\tThe list of files in the repo that we haven't taken a look at yet:\n\t```{{filepaths_with_token_lengths}}```\n\tTake some notes that will help us plan commits and write code to fix the issue. \n\tAlso, let me know if we should take a look at any other files – our budget is {{token_limit}} tokens.\"\"\"\n\t    output_type = LookAtFilesResponse\n\t    # extra_params = {\n\t    #     'temperature': 0.2,\n\t    # }\n", "    context: ContextDict\n\t    notes: str\n\t    selected_file_contents: list[FileDescriptor]\n\t    prospective_file_descriptors: list[FileDescriptor]\n\t    token_limit: int\n\t    _filtered_prospective_file_descriptors: list[FileDescriptor] = pydantic.PrivateAttr(default_factory=list)\n\t    def get_string_params(self) -> dict[str, str]:\n\t        self._filtered_prospective_file_descriptors = filter_seen_chunks(\n\t            self.selected_file_contents, self.prospective_file_descriptors\n\t        )\n", "        return {\n\t            'context': str(self.context),\n\t            'notes': self.notes,\n\t            'codebase': '\\n'.join([\n\t                file_descriptor.filenames_and_contents_to_str()\n\t                for file_descriptor in self.selected_file_contents\n\t            ]),\n\t            'filepaths_with_token_lengths': '\\n'.join([\n\t                file_descriptor.filepaths_with_token_lengths_to_str()\n\t                for file_descriptor in self._filtered_prospective_file_descriptors\n", "            ]),\n\t            'token_limit': str(self.token_limit),\n\t        }\n\t    def trim_params(self) -> bool:\n\t        if trim_chunk(self.selected_file_contents):\n\t            return True\n\t        return super().trim_params()\n\tclass InspectFiles(Action):\n\t    \"\"\"\n\t    Iteratively select files to look at, taking notes while looking at them.\n", "    File selection is performed by giving the agent a list of filenames, and asking it to select a subset of them.\n\t    Parameters\n\t    ----------\n\t    file_context_token_limit: int\n\t        The maximum size taken up by the file context (concatenated file chunks) in the prompt.\n\t    file_chunk_size: int\n\t        The maximum token size of each chunk that a file is split into.\n\t    \"\"\"\n\t    id = 'look_at_files'\n\t    def __init__(\n", "        self,\n\t        *args,\n\t        file_context_token_limit: int = 5000,\n\t        file_chunk_size: int = 500,\n\t        **kwargs,\n\t    ):\n\t        super().__init__(*args, **kwargs)\n\t        self.file_context_token_limit = file_context_token_limit\n\t        self.file_chunk_size = file_chunk_size\n\t    def get_initial_filepaths(\n", "        self,\n\t        files: list[FileDescriptor],\n\t        context: ContextDict,\n\t    ) -> list[str]:\n\t        self.log.debug('Getting filepaths to look at...')\n\t        response = self.rail_service.run_prompt_rail(\n\t            InitialFileSelect(\n\t                context=context,\n\t                file_descriptors=files,\n\t                token_limit=self.file_context_token_limit\n", "            )\n\t        )\n\t        if response is None or not isinstance(response, InitialFileSelectResponse):\n\t            real_filepaths = []\n\t        else:\n\t            real_filepaths = [fp for fp in response.filepaths if fp is not None]\n\t            if len(response.filepaths) != len(real_filepaths):\n\t                self.log.debug(f'Got hallucinated filepaths: {set(response.filepaths) - set(real_filepaths)}')\n\t            if real_filepaths:\n\t                self.log.debug(f'Got filepaths:')\n", "                for filepath in real_filepaths:\n\t                    self.log.debug(f' -  {filepath}')\n\t        return real_filepaths\n\t    def write_notes_about_files(\n\t        self,\n\t        files: list[FileDescriptor],\n\t        context: ContextDict,\n\t        filepaths: list[str]\n\t    ) -> str:\n\t        self.log.debug('Looking at files...')\n", "        file_contents = [\n\t            f.copy(deep=True) for f in files\n\t            if f.path in filepaths\n\t        ]\n\t        rail = LookAtFiles(\n\t            context=context,\n\t            selected_file_contents=file_contents,\n\t            prospective_file_descriptors=[f.copy(deep=True) for f in files],\n\t            token_limit=self.file_context_token_limit,\n\t        )\n", "        response = self.rail_service.run_prompt_rail(rail)\n\t        if response is None or not isinstance(response, LookAtFilesResponse):\n\t            raise ValueError('Error looking at files')\n\t        filepaths = response.filepaths_we_should_look_at or []\n\t        notes = response.notes\n\t        viewed_filepaths_up_to_chunk: dict[str, int] = {}\n\t        reasks = self.rail_service.num_reasks\n\t        while filepaths and reasks > 0:\n\t            reasks -= 1\n\t            # See if all requested files have already been viewed\n", "            for fp in rail.selected_file_contents:\n\t                viewed_filepaths_up_to_chunk[fp.path] = fp.end_chunk\n\t            file_contents = []\n\t            for f in files:\n\t                if f.path not in filepaths:\n\t                    continue\n\t                if f.path in viewed_filepaths_up_to_chunk:\n\t                    chunk_num = viewed_filepaths_up_to_chunk[f.path]\n\t                    if chunk_num == f.end_chunk:\n\t                        continue\n", "                    new_f = f.copy(deep=True)\n\t                    new_f.start_chunk = chunk_num\n\t                else:\n\t                    new_f = f.copy(deep=True)\n\t                file_contents.append(new_f)\n\t            if not file_contents:\n\t                break\n\t            self.log.debug(f'Looking at more files... ({reasks} reasks left)')\n\t            for fp in filepaths:\n\t                self.log.debug(f' - {fp}')\n", "            rail = ContinueLookingAtFiles(\n\t                context=context,\n\t                notes=notes,\n\t                selected_file_contents=file_contents,\n\t                prospective_file_descriptors=rail._filtered_prospective_file_descriptors,\n\t                token_limit=self.file_context_token_limit,\n\t            )\n\t            response = self.rail_service.run_prompt_rail(rail)\n\t            if response is None or not isinstance(response, LookAtFilesResponse):\n\t                filepaths = []\n", "            else:\n\t                filepaths = response.filepaths_we_should_look_at or []\n\t                notes += f'\\n{response.notes}'\n\t        return notes\n\t    def run(\n\t        self,\n\t        args: Action.Arguments,\n\t        context: ContextDict,\n\t    ) -> ContextDict:\n\t        self.publish_service.update_section(\"📖 Looking at files\")\n", "        # Get files\n\t        files = repo_to_file_descriptors(self.repo, self.file_context_token_limit, self.file_chunk_size)\n\t        # Get the filepaths to look at\n\t        filepaths = self.get_initial_filepaths(files, context)\n\t        if filepaths:\n\t            # Look at the files\n\t            notes = self.write_notes_about_files(files, context, filepaths)\n\t        else:\n\t            notes = \"The repository's contents were irrelevant, only create new files to address the issue.\"\n\t        context['notes'] = notes\n", "        self.publish_service.update_section(\"📖 Looked at files\")\n\t        return context\n"]}
{"filename": "autopr/actions/plan_commits.py", "chunked_list": ["from autopr.actions.base import Action, ContextDict\n\tfrom autopr.actions.utils.commit import CommitPlan, PullRequestAmendment\n\tfrom autopr.models.artifacts import Issue, PullRequest\n\tclass PlanCommits(Action):\n\t    id = \"plan_commits\"\n\t    description = \"Plan commits to add to the pull request.\"\n\t    class Arguments(Action.Arguments):\n\t        pull_request_amendment: PullRequestAmendment\n\t        output_spec = f\"\"\"<object\n\t    name='pull_request_amendment'\n", ">\n\t{PullRequestAmendment.output_spec}\n\t</object>\"\"\"\n\t    def run(self, arguments: Arguments, context: ContextDict) -> ContextDict:\n\t        self.publish_service.update_section(\"📝 Planning commits\")\n\t        # Add the commits to the pull request\n\t        context['pull_request_amendment'] = arguments.pull_request_amendment\n\t        # If there is a comment, add it to the issue\n\t        if arguments.pull_request_amendment.comment:\n\t            self.publish_service.publish_comment(arguments.pull_request_amendment.comment)\n", "        self.publish_service.update_section(\"📝 Planned commits\")\n\t        # Return the context\n\t        return context\n"]}
{"filename": "autopr/actions/edit_file.py", "chunked_list": ["import os\n\timport re\n\tfrom typing import Optional\n\tfrom autopr.actions.base import Action, ContextDict\n\tfrom autopr.actions.new_file import NewFile\n\tfrom autopr.actions.utils.commit import CommitPlan\n\tfrom autopr.actions.utils.file import add_element_to_context_list, GeneratedHunkOutputParser, ContextFile, \\\n\t    ContextCodeHunk, make_file_context, GeneratedFileHunk\n\tfrom autopr.models.prompt_chains import PromptChain\n\tclass RewriteCodeHunkChain(PromptChain):\n", "    output_parser = GeneratedHunkOutputParser()\n\t    prompt_template = f\"\"\"Hey, we've got a new code hunk to diff.\n\t{{context}}\n\tThis is the codebase subset we decided to look at:\n\t```\n\t{{context_hunks}}\n\t```\n\tThis is the hunk we're rewriting:\n\t```\n\t{{hunk_contents}}\n", "```\n\tThis is the plan for how we want to rewrite the hunk:\n\t```\n\t{{plan}}\n\t```\n\tPlease rewrite the hunk to match the plan, but do not include any lines prefixed with | in the result.\n\tRULES:\n\t- ONLY rewrite the lines prefixed with *, \n\t- submit only the lines without the * prefix,\n\t- do not preserve the relative leading indentation of the lines (start the hunk's indentation at 0).\n", "{{format_instructions}}\"\"\"\n\t    context: ContextDict\n\t    context_hunks: list[ContextFile]\n\t    hunk_contents: ContextCodeHunk\n\t    plan: str\n\tclass EditFile(Action):\n\t    id = \"edit_file\"\n\t    description = \"Rewrite a code hunk in a file.\"\n\t    class Arguments(Action.Arguments):\n\t        filepath: str\n", "        description: str\n\t        start_line: Optional[int] = None\n\t        end_line: Optional[int] = None\n\t        output_spec = f\"\"\"\n\t<string\n\t    name=\"filepath\"\n\t    description=\"Path to the file to be edited.\"\n\t    required=\"true\"\n\t/>\n\t<string\n", "    name=\"description\"\n\t    description=\"Description of the changes to be made to the file.\"\n\t    required=\"true\"\n\t/>\n\t<integer\n\t    name=\"start_line\"\n\t    description=\"The line number of the first line of the hunk to be edited.\"\n\t    format=\"positive\"\n\t    required=\"false\"\n\t    on-fail=\"noop\"\n", "/>\n\t<integer\n\t    name=\"end_line\"\n\t    description=\"The line number of the last line of the hunk to be edited. Keep the hunk as short as possible while fulfilling the description.\"\n\t    format=\"positive\"\n\t    required=\"false\"\n\t    on-fail=\"noop\"\n\t/>\n\t\"\"\"\n\t    def __init__(\n", "        self,\n\t        *args,\n\t        num_context_lines: int = 3,\n\t        **kwargs,\n\t    ):\n\t        super().__init__(*args, **kwargs)\n\t        # num_context_lines is the number of lines of context to show around the hunk being edited\n\t        self.num_context_lines = num_context_lines\n\t    @staticmethod\n\t    def _split_into_lines(text: str) -> list[str]:\n", "        lines = text.splitlines()\n\t        # If text ends with a newline, we want to keep that as a line\n\t        if text.rstrip() != text:\n\t            lines.append(\"\")\n\t        return lines\n\t    def run(\n\t        self,\n\t        args: Arguments,\n\t        context: ContextDict,\n\t    ) -> ContextDict:\n", "        # Check if file exists\n\t        repo_path = self.repo.working_tree_dir\n\t        assert repo_path\n\t        filepath = os.path.join(repo_path, args.filepath)\n\t        if not os.path.exists(filepath):\n\t            create_file_action = NewFile(\n\t                repo=self.repo,\n\t                rail_service=self.rail_service,\n\t                chain_service=self.chain_service,\n\t                publish_service=self.publish_service,\n", "            )\n\t            create_args = NewFile.Arguments(\n\t                filepath=args.filepath,\n\t                description=args.description,\n\t            )\n\t            self.log.warning(f\"File {filepath} does not exist, creating it instead.\")\n\t            return create_file_action.run(create_args, context)\n\t        self.publish_service.update_section(title=f\"✍️ Editing file: {args.filepath}\")\n\t        # Grab file contents\n\t        with open(filepath, \"r\") as f:\n", "            lines = self._split_into_lines(f.read())\n\t        # Get relevant hunk\n\t        start_line, end_line = args.start_line, args.end_line\n\t        if not lines:\n\t            code_hunk = ContextCodeHunk(\n\t                code_hunk=[],\n\t            )\n\t            indent = 0\n\t        elif start_line is None or end_line is None:\n\t            line_nums = list(range(1, len(lines) + 1))\n", "            code_hunk = ContextCodeHunk(\n\t                code_hunk=list(zip(line_nums, lines)),\n\t                highlight_line_numbers=line_nums,\n\t            )\n\t            indent = 0\n\t        else:\n\t            # Limit line numbers\n\t            start_line, end_line = min(max(start_line, 1), len(lines)), min(max(end_line, 1), len(lines))\n\t            end_line = max(start_line, end_line)\n\t            code_hunk_lines: list[tuple[int, str]] = []\n", "            context_start_line = max(1, start_line - self.num_context_lines)\n\t            context_end_line = min(len(lines), end_line + self.num_context_lines)\n\t            for line_num in range(context_start_line, context_end_line + 1):\n\t                code_hunk_lines.append((line_num, lines[line_num - 1]))\n\t            highlight_line_nums = list(range(start_line, end_line + 1))\n\t            code_hunk = ContextCodeHunk(\n\t                code_hunk=code_hunk_lines,\n\t                highlight_line_numbers=highlight_line_nums,\n\t            )\n\t            # Find the indentation common to all highlighted lines in the hunk\n", "            highlighted_lines = [\n\t                lines[line_num - 1]\n\t                for line_num in highlight_line_nums\n\t            ]\n\t            lines_for_indent = [\n\t                len(line) - len(line.lstrip())\n\t                for line in highlighted_lines\n\t                if line.strip()\n\t            ]\n\t            if not lines_for_indent:\n", "                indent = 0\n\t            else:\n\t                indent = min(lines_for_indent)\n\t        # Get the other relevant hunks\n\t        if \"current_commit\" not in context:\n\t            self.log.error(\"Context does not specify current_commit\")\n\t            context_hunks = []\n\t        elif not isinstance(current_commit := context[\"current_commit\"], CommitPlan):\n\t            self.log.error(\"Context current_commit is not a CommitPlan\")\n\t            context_hunks = []\n", "        else:\n\t            # TODO remove the hunk that's being edited, but leave surrounding context\n\t            #  or rather, build better context by iteratively asking about it\n\t            context_hunks = make_file_context(self.repo, current_commit)\n\t        # Run edit file langchain\n\t        edit_file_chain = RewriteCodeHunkChain(\n\t            context=context,\n\t            context_hunks=context_hunks,\n\t            hunk_contents=code_hunk,\n\t            plan=args.description,\n", "        )\n\t        edit_file_hunk: Optional[GeneratedFileHunk] = self.chain_service.run_chain(edit_file_chain)\n\t        if edit_file_hunk is None:\n\t            self.publish_service.update_section(title=f\"❌ Failed to edit file: {args.filepath}\")\n\t            return add_element_to_context_list(\n\t                context,\n\t                \"action_history\",\n\t                f\"Failed to edit file {args.filepath}\",\n\t            )\n\t        new_lines = edit_file_hunk.contents\n", "        # if all lines start with \"<int> | \" or \"<int> * \"\n\t        if all(re.match(r\"^\\s*\\d+\\s*[|*]\\s*\", line)\n\t               for line in new_lines.splitlines()):\n\t            # Remove the prefix from all lines\n\t            new_lines = \"\\n\".join(\n\t                re.sub(r\"^\\s*\\d+\\s*[|*]\\s*\", \"\", line)\n\t                for line in new_lines.splitlines()\n\t            )\n\t        # Add indentation to new lines\n\t        indented_lines = []\n", "        for line in self._split_into_lines(new_lines):\n\t            if not line.strip():\n\t                indented_lines.append(\"\")\n\t                continue\n\t            indented_lines.append(\" \" * indent + line)\n\t        # Replace lines in file\n\t        if start_line is not None and end_line is not None:\n\t            lines = lines[:start_line - 1] + indented_lines + lines[end_line:]\n\t        else:\n\t            lines = indented_lines\n", "        # Write file\n\t        path = os.path.join(repo_path, filepath)\n\t        with open(path, \"w\") as f:\n\t            f.write(\"\\n\".join(lines))\n\t        self.publish_service.update_section(title=f\"✍️ Edited file: {args.filepath}\")\n\t        return add_element_to_context_list(\n\t            context,\n\t            \"action_history\",\n\t            f\"Edited file, with outcome: {edit_file_hunk.outcome}\"\n\t        )\n"]}
{"filename": "autopr/actions/__init__.py", "chunked_list": ["from os.path import dirname, basename, isfile, join\n\timport glob\n\t# Import all modules in this directory\n\tfile_modules = glob.glob(join(dirname(__file__), \"*.py\"))\n\tfile_basenames = [basename(f)[:-3] for f in file_modules if isfile(f) and not f.endswith('__init__.py')]\n\tdirectory_module_inits = glob.glob(join(dirname(__file__), \"*\", \"__init__.py\"))\n\tdirectory_modules = [dirname(f) for f in directory_module_inits]\n\tdirectory_module_basenames = [basename(f) for f in directory_modules]\n\t__all__ = file_basenames + directory_module_basenames\n\tfrom . import *\n"]}
{"filename": "autopr/actions/request_more_info.py", "chunked_list": ["from autopr.actions.base import Action, ContextDict\n\tfrom autopr.models.artifacts import Issue\n\tclass RequestMoreInfo(Action):\n\t    id = \"request_more_information\"\n\t    description = \"Request more information from the user.\"\n\t    class Arguments(Action.Arguments):\n\t        message: str\n\t        output_spec = \"<string name='message'/>\"\n\t    def run(self, arguments: Arguments, context: ContextDict) -> ContextDict:\n\t        # Get the issue from the context\n", "        if 'issue' in context:\n\t            issue = context['issue']\n\t            if not isinstance(issue, Issue):\n\t                self.log.error(f\"Expected issue to be of type Issue, got {type(issue)}\")\n\t                raise TypeError(f\"Expected issue to be of type Issue, got {type(issue)}\")\n\t            issue_number = issue.number\n\t        else:\n\t            issue_number = None\n\t        # Get the message from the arguments\n\t        message = arguments.message\n", "        # Add a comment to the issue\n\t        success = self.publish_service.publish_comment(message, issue_number)\n\t        if not success:\n\t            self.log.error(f\"Failed to comment on issue\")\n\t            raise RuntimeError(f\"Failed to comment on issue\")\n\t        # Return the context\n\t        return context\n"]}
{"filename": "autopr/actions/plan_pr.py", "chunked_list": ["from autopr.actions.base import Action, ContextDict\n\tfrom autopr.actions.utils.commit import PullRequestDescription\n\tfrom autopr.models.artifacts import Issue\n\tfrom autopr.models.prompt_rails import PromptRail\n\tclass ProposePullRequestRail(PromptRail):\n\t    # Generate proposed list of commit messages, given notes and issue\n\t    prompt_template = f\"\"\"Hey somebody just submitted an issue, could you own it, write some commits, and a pull request?\n\tThese are notes we took while looking at the repo:\n\t```{{notes_taken_while_looking_at_files}}```\n\tThis is the issue that was opened:\n", "```{{issue}}```\n\tWhen you're done, send me the pull request title, body, and a list of commits, each coupled with which files we should be looking at to write the commit's code.\n\tEnsure you specify the files relevant to the commit, especially if the commit is a refactor.\n\tFolders are created automatically; do not make them in their own commit.\"\"\"\n\t    output_type = PullRequestDescription\n\t    # extra_params = {\n\t    #     'temperature': 0.1,\n\t    # }\n\t    notes_taken_while_looking_at_files: str\n\t    issue: Issue\n", "class PlanPullRequest(Action):\n\t    id = \"plan_pull_request\"\n\t    description = \"Propose a pull request to the user.\"\n\t    def propose_pull_request(self, issue: Issue, notes: str) -> PullRequestDescription:\n\t        self.log.debug('Getting commit messages...')\n\t        pr_desc = self.rail_service.run_prompt_rail(\n\t            ProposePullRequestRail(\n\t                issue=issue,\n\t                notes_taken_while_looking_at_files=notes,\n\t            )\n", "        )\n\t        if pr_desc is None or not isinstance(pr_desc, PullRequestDescription):\n\t            raise ValueError('Error proposing pull request')\n\t        return pr_desc\n\t    def run(\n\t        self,\n\t        args: Action.Arguments,\n\t        context: ContextDict,\n\t    ) -> ContextDict:\n\t        self.publish_service.update_section('📝 Planning pull request')\n", "        # Get issue\n\t        if 'issue' not in context:\n\t            raise ValueError('No `issue` key in context')\n\t        issue = context['issue']\n\t        if not isinstance(issue, Issue):\n\t            raise ValueError(f'Context `issue` is type {type(issue)}, not Issue')\n\t        # Get notes\n\t        if 'notes' not in context:\n\t            raise ValueError('No `notes` key in context')\n\t        notes = context['notes']\n", "        if not isinstance(notes, str):\n\t            raise ValueError(f'Context `notes` is type {type(notes)}, not str')\n\t        # Write pull request description\n\t        pr_desc = self.propose_pull_request(issue, notes)\n\t        # Save the pull request description to the context\n\t        context['pull_request_description'] = pr_desc\n\t        self.publish_service.update_section('📝 Planned pull request')\n\t        return context\n"]}
{"filename": "autopr/actions/utils/__init__.py", "chunked_list": []}
{"filename": "autopr/actions/utils/file.py", "chunked_list": ["import json\n\timport os\n\tfrom collections import defaultdict\n\tfrom typing import Optional, Any\n\tfrom git.repo import Repo\n\tfrom autopr.actions.base import ContextDict\n\tfrom autopr.actions.utils.commit import CommitPlan\n\tfrom autopr.models.prompt_chains import PromptChain\n\timport pydantic\n\tfrom langchain.schema import BaseOutputParser\n", "import structlog\n\tlog = structlog.get_logger()\n\t###\n\t# File hunk generation\n\t###\n\tclass GeneratedFileHunk(pydantic.BaseModel):\n\t    \"\"\"\n\t    A generated hunk of code, followed by the outcome of the generation.\n\t    TODO explore better ways of reflecting on the output of the generation than `outcome`.\n\t    \"\"\"\n", "    contents: str\n\t    outcome: str\n\tclass GeneratedHunkOutputParser(BaseOutputParser):\n\t    \"\"\"\n\t    An output parser for the generated hunk, in the format of:\n\t        ```\n\t        <string>\n\t        ```\n\t        {\n\t            \"outcome\": <string>\n", "        }\n\t    \"\"\"\n\t    def parse(self, output: str) -> Optional[GeneratedFileHunk]:\n\t        output_lines = output.split(\"\\n\")\n\t        try:\n\t            # Filter through the output until the first ``` is found\n\t            while not output_lines[0].startswith(\"```\"):\n\t                output_lines.pop(0)\n\t            output_lines.pop(0)\n\t            # Find the last ``` line\n", "            reversed_lines = output_lines[::-1]\n\t            while not reversed_lines[0].startswith(\"```\"):\n\t                reversed_lines.pop(0)\n\t            reversed_lines.pop(0)\n\t            lines = reversed_lines[::-1]\n\t            code = \"\\n\".join(lines)\n\t            # Retrieve the JSON\n\t            json_lines = output_lines[len(lines) + 1:]\n\t            try:\n\t                outcome = json.loads(\"\\n\".join(json_lines))[\"outcome\"]\n", "            except json.JSONDecodeError:\n\t                outcome = \"\"\n\t        except:\n\t            # TODO reask to fix the output\n\t            return None\n\t        return GeneratedFileHunk(\n\t            contents=code,\n\t            outcome=outcome,\n\t        )\n\t    def get_format_instructions(self) -> str:\n", "        return \"\"\"RESPONSE FORMAT INSTRUCTIONS\n\t----------------------------\n\tWhen responding to me, please use the following format. Make sure you return both the code enclosed in backticks and the JSON immediately after.\n\t```\n\t<string>\n\t```\n\t{\n\t    \"outcome\": string  # A description of the outcome of the attempt to rewrite the file hunk according to the problem statement.\n\t}\n\t\"\"\"\n", "###\n\t# File context creation\n\t###\n\tclass ContextCodeHunk(pydantic.BaseModel):\n\t    \"\"\"\n\t    A hunk of code that is part of the context for code generation.\n\t    \"\"\"\n\t    highlight_line_numbers: list[int] = pydantic.Field(default_factory=list)\n\t    code_hunk: list[tuple[int, str]]\n\t    def __str__(self):\n", "        if not self.code_hunk:\n\t            return ''\n\t        max_line_num_width = len(str(self.code_hunk[-1][0]))\n\t        lines = []\n\t        for num, line_content in self.code_hunk:\n\t            num_width = len(str(num))\n\t            line = ' ' * (max_line_num_width - num_width) + str(num)\n\t            if num in self.highlight_line_numbers:\n\t                line += ' * '\n\t            else:\n", "                line += ' | '\n\t            line += line_content\n\t            lines.append(line)\n\t        return '\\n'.join(lines)\n\tclass ContextFile(pydantic.BaseModel):\n\t    \"\"\"\n\t    A file that is part of the context for code generation.\n\t    \"\"\"\n\t    filepath: str\n\t    code_hunks: list[ContextCodeHunk]\n", "    def __str__(self):\n\t        code_hunks_s = '\\n\\n'.join(\n\t            [str(code_hunk) for code_hunk in self.code_hunks]\n\t        )\n\t        return f\">>> File: {self.filepath}\\n\\n\" + code_hunks_s\n\tdef split_into_lines(text: str) -> list[str]:\n\t    lines = text.splitlines()\n\t    # If text ends with a newline, we want to keep that as a line\n\t    if text.rstrip() != text:\n\t        lines.append(\"\")\n", "    return lines\n\tdef get_lines(\n\t    repo: Repo,\n\t    filepath: str,\n\t    start_line: Optional[int] = None,\n\t    end_line: Optional[int] = None,\n\t) -> Optional[list[tuple[int, str]]]:\n\t    working_dir = repo.working_tree_dir\n\t    assert working_dir is not None\n\t    path = os.path.join(working_dir, filepath)\n", "    if not os.path.exists(path):\n\t        log.error(f\"File {filepath} not in repo\")\n\t        return None\n\t    if not os.path.isfile(path):\n\t        log.error(f\"{filepath} is not a file\")\n\t        return None\n\t    with open(path, 'r') as f:\n\t        lines = split_into_lines(f.read())\n\t    code_hunk: list[tuple[int, str]] = []\n\t    # Get and limit line numbers\n", "    start_line = start_line or 1\n\t    start_line = min(max(start_line, 1), len(lines))\n\t    end_line = end_line or len(lines)\n\t    end_line = min(max(end_line, 1), len(lines))\n\t    end_line = max(start_line, end_line)\n\t    for line_num in range(start_line, end_line + 1):\n\t        code_hunk.append((line_num, lines[line_num - 1]))\n\t    return code_hunk\n\tdef make_file_context(\n\t    repo: Repo,\n", "    commit: CommitPlan,\n\t) -> list[ContextFile]:\n\t    hunks_by_filepath = defaultdict(list)\n\t    for hunk in commit.relevant_file_hunks:\n\t        fp = hunk.filepath\n\t        hunks_by_filepath[fp].append(hunk)\n\t    context = []\n\t    for fp, hunks in hunks_by_filepath.items():\n\t        code_hunks = []\n\t        for hunk in hunks:\n", "            lines = get_lines(\n\t                repo=repo,\n\t                filepath=fp,\n\t                start_line=hunk.start_line,\n\t                end_line=hunk.end_line,\n\t            )\n\t            if lines is None:\n\t                continue\n\t            code_hunks.append(\n\t                ContextCodeHunk(\n", "                    code_hunk=lines,\n\t                )\n\t            )\n\t        if code_hunks:\n\t            context.append(\n\t                ContextFile(\n\t                    filepath=fp,\n\t                    code_hunks=code_hunks,\n\t                )\n\t            )\n", "    return context\n\tdef add_element_to_context_list(\n\t    context: ContextDict,\n\t    key: str,\n\t    element: Any,\n\t) -> ContextDict:\n\t    if key not in context:\n\t        context[key] = []\n\t    context[key].append(element)\n\t    return context\n"]}
{"filename": "autopr/actions/utils/commit.py", "chunked_list": ["from typing import Optional\n\timport pydantic\n\tfrom autopr.models.rail_objects import RailObject\n\tclass FileReference(RailObject):\n\t    output_spec = \"\"\"<string\n\t    name=\"filepath\"\n\t    description=\"The path to the file we are looking at.\"\n\t    format=\"filepath\"\n\t    on-fail=\"fix\"\n\t/>\n", "<integer\n\t    name=\"start_line\"\n\t    description=\"The line number of the first line of the hunk.\"\n\t    format=\"positive\"\n\t    required=\"false\"\n\t    on-fail=\"noop\"\n\t/>\n\t<integer\n\t    name=\"end_line\"\n\t    description=\"The line number of the last line of the hunk.\"\n", "    format=\"positive\"\n\t    required=\"false\"\n\t    on-fail=\"noop\"\n\t/>\"\"\"\n\t    filepath: str\n\t    start_line: Optional[int] = None\n\t    end_line: Optional[int] = None\n\t    def __str__(self):\n\t        s = self.filepath\n\t        if self.start_line is not None:\n", "            s += f\":L{self.start_line}\"\n\t            if self.end_line is not None:\n\t                s += f\"-L{self.end_line}\"\n\t        return s\n\tclass CommitPlan(RailObject):\n\t    output_spec = f\"\"\"<string\n\t    name=\"commit_message\"\n\t    description=\"The commit message, concisely describing the changes made.\"\n\t    length=\"1 100\"\n\t    on-fail=\"noop\"\n", "/>\n\t<list\n\t    name=\"relevant_file_hunks\"\n\t    description=\"The files we should be looking at while writing this commit. Include files that whose contents will be called by the code in this commit, and files that will be changed by this commit.\"\n\t>\n\t<object>\n\t{FileReference.output_spec}\n\t</object>\n\t</list>\n\t<string\n", "    name=\"commit_changes_description\"\n\t    description=\"A description of the changes made in this commit, in the form of a list of bullet points.\"\n\t    required=\"true\"\n\t    length=\"1 1000\"\n\t/>\"\"\"\n\t    commit_message: str\n\t    relevant_file_hunks: list[FileReference] = pydantic.Field(default_factory=list)\n\t    commit_changes_description: str = \"\"\n\t    def __str__(self):\n\t        return self.commit_message + '\\n\\n' + self.commit_changes_description\n", "class PullRequestDescription(RailObject):\n\t    output_spec = f\"\"\"<string \n\t    name=\"title\" \n\t    description=\"The title of the pull request.\"\n\t/>\n\t<string \n\t    name=\"body\" \n\t    description=\"The body of the pull request.\"\n\t/>\n\t<list \n", "    name=\"commits\"\n\t    on-fail=\"reask\"\n\t    description=\"The commits that will be made in this pull request. Commits must change the code in the repository, and must not be empty.\"\n\t>\n\t<object>\n\t{CommitPlan.output_spec}\n\t</object>\n\t</list>\"\"\"\n\t    title: str\n\t    body: str\n", "    commits: list[CommitPlan]\n\t    def __str__(self):\n\t        pr_text_description = f\"Title: {self.title}\\n\\n{self.body}\\n\\n\"\n\t        for i, commit_plan in enumerate(self.commits):\n\t            prefix = f\" {' ' * len(str(i + 1))}  \"\n\t            changes_prefix = f\"\\n{prefix}  \"\n\t            pr_text_description += (\n\t                f\"{str(i + 1)}. Commit: {commit_plan.commit_message}\\n\"\n\t                f\"{prefix}Files: \"\n\t                f\"{', '.join([str(fh) for fh in commit_plan.relevant_file_hunks])}\\n\"\n", "                f\"{prefix}Changes:\"\n\t                f\"{changes_prefix}{changes_prefix.join(commit_plan.commit_changes_description.splitlines())}\\n\"\n\t            )\n\t        return pr_text_description\n\tclass PullRequestAmendment(RailObject):\n\t    output_spec = f\"\"\"<string\n\t    name=\"comment\"\n\t    description=\"A comment to add to the pull request.\"\n\t    required=\"false\"\n\t    on-fail=\"noop\"\n", "/>\n\t<list\n\t    name=\"commits\"\n\t    required=\"false\"\n\t    on-fail=\"reask\"\n\t    description=\"Additional commits to add to the pull request. Commits must change the code in the repository, and must not be empty.\"\n\t>\n\t<object>\n\t{CommitPlan.output_spec}\n\t</object>\n", "</list>\"\"\"\n\t    comment: Optional[str] = None\n\t    commits: list[CommitPlan] = pydantic.Field(default_factory=list)\n"]}
{"filename": "autopr/utils/tokenizer.py", "chunked_list": ["from typing import Optional\n\timport transformers\n\t# FIXME use tiktoken instead\n\t_cached_tokenizer = None\n\tdef get_tokenizer():\n\t    global _cached_tokenizer\n\t    if _cached_tokenizer is None:\n\t        _cached_tokenizer = transformers.GPT2TokenizerFast.from_pretrained('gpt2')\n\t    return _cached_tokenizer\n"]}
{"filename": "autopr/utils/repo.py", "chunked_list": ["from typing import Optional\n\tfrom git import Blob\n\tfrom git.repo import Repo\n\timport pydantic\n\timport structlog\n\timport os\n\tfrom pathspec import PathSpec\n\tfrom pathspec.patterns.gitwildmatch import GitWildMatchPattern\n\tfrom autopr.utils.tokenizer import get_tokenizer\n\tlog = structlog.get_logger()\n", "class FileDescriptor(pydantic.BaseModel):\n\t    path: str\n\t    token_length: int\n\t    chunks: list[list[tuple[int, str]]]  # list of (line number, line content) pairs\n\t    start_chunk: int = 0\n\t    end_chunk: int = -1  # this will be overwritten by the root validator\n\t    @pydantic.root_validator(pre=True)\n\t    def validate_end_chunk(cls, values):\n\t        if 'end_chunk' not in values:\n\t            values['end_chunk'] = len(values['chunks'])\n", "        return values\n\t    def filepaths_with_token_lengths_to_str(self) -> str:\n\t        # TODO give info on what chunks we've already seen\n\t        return f'{self.path} ({str(self.token_length)} tokens)'\n\t        # chunks_left = self.end_chunk - self.start_chunk\n\t        # return f'{self.path} ({str(self.token_length)} tokens) ({str(chunks_left)} chunks left)'\n\t    def filenames_and_contents_to_str(self) -> str:\n\t        contents = ''\n\t        if self.start_chunk > 0:\n\t            contents += f'... #  (omitting {self.start_chunk} chunks)\\n'\n", "        # TODO make the line numbers right-aligned with padded spaces,\n\t        #  so that the line numbers don't change the start of the line\n\t        contents += '\\n'.join([\n\t            f'{str(line_number)} {line_content}'\n\t            for chunk in self.chunks[self.start_chunk:self.end_chunk]\n\t            for line_number, line_content in chunk\n\t        ])\n\t        if self.end_chunk < len(self.chunks):\n\t            contents += f'\\n... #  (omitting {len(self.chunks) - self.end_chunk} chunks)'\n\t        return f'>>> Path: {self.path}:\\n\\n{contents}'\n", "def trim_chunk(file_desc_with_chunk_start_end: list[FileDescriptor]) -> bool:\n\t    if file_desc_with_chunk_start_end:\n\t        # Find file with most chunks\n\t        longest_num = 0\n\t        longest_i = 0\n\t        for i, desc in enumerate(file_desc_with_chunk_start_end):\n\t            num_chunks = desc.end_chunk - desc.start_chunk\n\t            if num_chunks > longest_num:\n\t                longest_num = num_chunks\n\t                longest_i = i\n", "        desc = file_desc_with_chunk_start_end[longest_i]\n\t        # If we've already looked at the whole file, remove it from the list\n\t        if desc.start_chunk == desc.end_chunk - 1:\n\t            del file_desc_with_chunk_start_end[longest_i]\n\t            return True\n\t        # Otherwise, shave a chunk off the end\n\t        desc.end_chunk -= 1\n\t        file_desc_with_chunk_start_end[longest_i] = desc\n\t        return True\n\t    return False\n", "def filter_seen_chunks(seen_fds: list[FileDescriptor], prospective_fds: list[FileDescriptor]) -> list[FileDescriptor]:\n\t    fds_copy = [f.copy(deep=True) for f in prospective_fds]\n\t    omit_prospective_fd_indices = []\n\t    for selected_fd in seen_fds:\n\t        # If it's in prospective_file_descriptors, update its start_chunk\n\t        for prospective_fd in fds_copy:\n\t            if prospective_fd.path == selected_fd.path:\n\t                # If we've already looked at the whole file, remove it from the list\n\t                if prospective_fd.end_chunk == selected_fd.end_chunk:\n\t                    omit_prospective_fd_indices.append(fds_copy.index(prospective_fd))\n", "                else:\n\t                    prospective_fd.start_chunk = selected_fd.end_chunk\n\t                break\n\t    for i in sorted(omit_prospective_fd_indices, reverse=True):\n\t        del fds_copy[i]\n\t    return fds_copy\n\t_file_descriptor_cache: dict[tuple[bytes, int, int], list[FileDescriptor]] = {}\n\tdef repo_to_file_descriptors(repo: Repo, context_window: int, file_chunk_size: int) -> list[FileDescriptor]:\n\t    repo_tree = repo.head.commit.tree\n\t    key = (repo_tree.binsha, context_window, file_chunk_size)\n", "    ignore_patterns = parse_gptignore(repo)\n\t    if key in _file_descriptor_cache:\n\t        return [fd.copy(deep=True) for fd in _file_descriptor_cache[key]]\n\t    file_descriptor_list = []\n\t    for blob in repo_tree.traverse():\n\t        if not isinstance(blob, Blob):\n\t            continue\n\t        if blob.type == 'tree':\n\t            continue\n\t        if is_path_ignored(blob.path, ignore_patterns):\n", "            continue\n\t        try:\n\t            content = blob.data_stream.read().decode()\n\t        except UnicodeDecodeError:\n\t            log.debug(f\"Error decoding file: {blob.path}\")\n\t            continue\n\t        tokenizer = get_tokenizer()\n\t        tokens = tokenizer.encode(content)\n\t        # Split into chunks up to the last newline\n\t        chunks: list[list[tuple[int, str]]] = []\n", "        line_buffer = []\n\t        for i, line in enumerate(content.splitlines()):\n\t            line_buffer.append((i, line))\n\t            # FIXME speed this up\n\t            token_length = len(tokenizer.encode(\n\t                '\\n'.join([l[1] for l in line_buffer])\n\t            ))\n\t            if token_length >= file_chunk_size:\n\t                chunks.append(line_buffer)\n\t                line_buffer = []\n", "        if line_buffer:\n\t            chunks.append(line_buffer)\n\t        token_length = len(tokens)\n\t        file_descriptor_list.append(FileDescriptor(\n\t            path=blob.path,\n\t            token_length=token_length,\n\t            chunks=chunks,\n\t        ))\n\t    _file_descriptor_cache[key] = file_descriptor_list\n\t    return file_descriptor_list\n", "def is_path_ignored(path: str, ignore_patterns: list[str]) -> bool:\n\t    # Ensure we're working with a relative path\n\t    relative_path = os.path.relpath(path)\n\t    pathspec = PathSpec.from_lines(GitWildMatchPattern, ignore_patterns)\n\t    return pathspec.match_file(relative_path)\n\tdef parse_gptignore(repo: Repo, gptignore_file: str = \".gptignore\") -> list[str]:\n\t    if gptignore_file not in repo.head.commit.tree:\n\t        return []\n\t    gptignore_blob = repo.head.commit.tree / gptignore_file\n\t    gptignore_content = gptignore_blob.data_stream.read().decode()\n", "    ignore_patterns = []\n\t    for line in gptignore_content.splitlines():\n\t        line = line.strip()\n\t        if line and not line.startswith(\"#\"):\n\t            ignore_patterns.append(line)\n\t    return ignore_patterns\n"]}
{"filename": "autopr/tests/test_rail_specs.py", "chunked_list": ["from unittest.mock import MagicMock\n\timport pytest\n\timport guardrails as gr\n\tfrom autopr.actions.base import Action, ContextDict, get_all_actions\n\tfrom autopr.models.rail_objects import RailObject\n\t# Make sure to import, so all rail objects initialize\n\timport autopr.actions\n\tfrom autopr.services.action_service import ActionService\n\t@pytest.mark.parametrize(\n\t    \"rail_type\",\n", "    RailObject.__subclasses__()\n\t)\n\tdef test_guardrails_spec_validity(rail_type):\n\t    \"\"\"Test that all guardrails specs are valid.\"\"\"\n\t    rail_spec = rail_type.get_rail_spec()\n\t    print(rail_spec)\n\t    gr.Guard.from_rail_string(rail_spec)\n\tclass A(Action):\n\t    id = \"a\"\n\t    description = \"i am a\"\n", "    class Arguments(Action.Arguments):\n\t        a: str\n\t        b: str\n\t        output_spec = \"<string name='a'/><string name='b'/>\"\n\t    def run(self, arguments: Arguments, context: ContextDict) -> ContextDict:\n\t        return context\n\tclass B(Action):\n\t    id = \"b\"\n\t    def run(self, arguments: Action.Arguments, context: ContextDict) -> ContextDict:\n\t        return context\n", "action_service = ActionService(\n\t    repo=MagicMock(),\n\t    completions_repo=MagicMock(),\n\t    publish_service=MagicMock(),\n\t    rail_service=MagicMock(),\n\t    chain_service=MagicMock(),\n\t)\n\tall_actions = get_all_actions()\n\tall_action_ids = [a.id for a in all_actions]\n\t@pytest.mark.parametrize(\n", "    \"rail_spec\",\n\t    [\n\t        action_service._write_action_selection_rail_spec(['a'], include_finished=True),\n\t        action_service._write_action_selection_rail_spec(['b'], include_finished=False),\n\t        action_service._write_action_selection_rail_spec(['a', 'b'], include_finished=True),\n\t        action_service._write_action_selection_rail_spec(['a', 'b'], include_finished=False),\n\t        action_service._write_action_args_query_rail_spec(A.Arguments),\n\t    ]\n\t)\n\tdef test_mock_action_service_spec_validity(rail_spec):\n", "    \"\"\"Test that all action service specs are valid.\"\"\"\n\t    print(rail_spec)\n\t    gr.Guard.from_rail_string(rail_spec)\n\t@pytest.mark.parametrize(\n\t    \"rail_spec\",\n\t    [\n\t        action_service._write_action_selection_rail_spec(all_action_ids, include_finished=True),\n\t    ] + [\n\t        action_service._write_action_selection_rail_spec([a_id], include_finished=True)\n\t        for a_id in all_action_ids\n", "    ]\n\t)\n\tdef test_real_action_service_spec_validity(rail_spec):\n\t    print(rail_spec)\n\t    gr.Guard.from_rail_string(rail_spec)"]}
{"filename": "autopr/tests/__init__.py", "chunked_list": []}
{"filename": "autopr/tests/test_publish_service.py", "chunked_list": ["from unittest.mock import patch, Mock\n\tfrom autopr.services.publish_service import GitHubPublishService\n\t@patch('requests.get')\n\t@patch('requests.post')\n\t@patch('requests.patch')\n\tdef test_github_publish_service(mock_patch, mock_post, mock_get):\n\t    # Mock responses for each request call\n\t    mock_get.return_value = Mock(status_code=200, json=lambda: [{'number': 1, 'node_id': 'node1'}])\n\t    mock_post.return_value = Mock(status_code=201, json=lambda: {'number': 2, 'id': 'comment1'})\n\t    mock_patch.return_value = Mock(status_code=200, json=lambda: {})\n", "    service = GitHubPublishService(\n\t        token='my_token',\n\t        run_id='123',\n\t        owner='user',\n\t        repo_name='repo',\n\t        head_branch='branch1',\n\t        base_branch='branch2',\n\t        issue=None,\n\t        pull_request_number=None,\n\t        loading_gif_url=\"https://media.giphy.com/media/3oEjI6SIIHBdRxXI40/giphy.gif\",\n", "        overwrite_existing=False,\n\t    )\n\t    # Test _find_existing_pr\n\t    pr = service._find_existing_pr()\n\t    assert pr is not None\n\t    assert pr['number'] == 1\n\t    assert pr['node_id'] == 'node1'\n\t    # Test _create_pr\n\t    pr = service._create_pr('title', ['body1', 'body2'], True)\n\t    assert pr is not None\n", "    assert pr['number'] == 2\n\t    assert service._comment_ids == [service.PRBodySentinel, 'comment1']\n\t    # Test _update_pr_body\n\t    service._update_pr_body(1, 'new body')\n\t    mock_patch.assert_called_with(\n\t        'https://api.github.com/repos/user/repo/pulls/1',\n\t        headers=service._get_headers(),\n\t        json={'body': 'new body'}\n\t    )\n\t    # Test _update_pr_comment\n", "    service._update_pr_comment('comment1', 'new comment')\n\t    mock_patch.assert_called_with(\n\t        'https://api.github.com/repos/user/repo/issues/comments/comment1',\n\t        headers=service._get_headers(),\n\t        json={'body': 'new comment'}\n\t    )\n\t    # Test _publish_comment\n\t    comment_id = service._publish_comment('new comment', 1)\n\t    assert comment_id == 'comment1'\n"]}
{"filename": "autopr/models/rail_objects.py", "chunked_list": ["import json\n\tfrom typing import List, ClassVar, Optional, Union\n\tfrom typing_extensions import TypeAlias\n\timport pydantic\n\tfrom autopr.models.artifacts import DiffStr\n\tclass RailObject(pydantic.BaseModel):\n\t    \"\"\"\n\t    A RailObject is a pydantic model that represents the output of a guardrails call.\n\t    See PromptRail and RailService, and [Guardrails docs](https://docs.guardrails.io/) for more information.\n\t    To define your own RailObject:\n", "    - write an XML string compatible with the guardrails XML spec in the `output_spec` class variable\n\t    - define your parameters as pydantic instance attributes\n\t    \"\"\"\n\t    output_spec: ClassVar[str]\n\t    @classmethod\n\t    def get_rail_spec(cls):\n\t        \"\"\"\n\t        Get the XML spec template used to define the guardrails output.\n\t        Should include a `{{raw_document}}` in the prompt section,\n\t        which will be replaced by the input prompt/two-step LLM output.\n", "        \"\"\"\n\t        return f\"\"\"\n\t<rail version=\"0.1\">\n\t<output>\n\t{cls.output_spec}\n\t</output>\n\t<instructions>\n\tYou are a helpful assistant only capable of communicating with valid JSON, and no other text.\n\t@json_suffix_prompt_examples\n\t</instructions>\n", "<prompt>\n\tGiven the following document surrounded by `+++++`, answer the following questions. \n\tIf the answer doesn't exist in the document, enter `null`.\n\t+++++\n\t{{{{raw_document}}}}\n\t+++++\n\tExtract information from this document and return a JSON that follows the correct schema.\n\t@xml_prefix_prompt\n\t{{output_schema}}\n\t</prompt>\n", "</rail>\n\t\"\"\"\n"]}
{"filename": "autopr/models/artifacts.py", "chunked_list": ["from typing import Literal, Optional\n\timport pydantic\n\tfrom typing_extensions import TypeAlias\n\tclass Message(pydantic.BaseModel):\n\t    body: str = \"\"\n\t    author: str\n\t    def __str__(self):\n\t        return f\"{self.author}: {self.body}\\n\\n\"\n\tclass Thread(pydantic.BaseModel):\n\t    messages: list[Message]\n", "    def __str__(self):\n\t        return \"\\n\".join(str(message) for message in self.messages)\n\tclass Issue(Thread):\n\t    number: int\n\t    title: str\n\t    author: str\n\t    def __str__(self):\n\t        return f\"#{self.number} {self.title}\\n\\n\" + super().__str__()\n\tclass PullRequest(Issue):\n\t    base_branch: str\n", "    head_branch: str\n\t    # code_review: list[CodeComment]\n\t    def __str__(self):\n\t        return f\"#{self.number} {self.title}\\n\\n\" + \"\\n\".join(\n\t            str(message) for message in self.messages\n\t        )\n\t        # ) + \"\\n\\n\" + \"\\n\".join(\n\t        #     str(thread) for thread in self.code_review\n\t        # )\n\t# class CodeComment(Thread):\n", "#     commit_sha: str\n\t#     filepath: str\n\t#     status: Literal[\"APPROVE\", \"REQUEST_CHANGES\", \"COMMENT\"]\n\t#\n\t#     start_line_number: int\n\t#     end_line_number: Optional[int] = None\n\t#\n\t#     def __str__(self):\n\t#         return f\"{self.commit_sha}\\n\" \\\n\t#                f\"{self.filepath}:L{self.start_line_number}\" + f\"{f'-L{self.end_line_number}' if self.end_line_number else ''}\\n\" \\\n", "#                f\"{self.status}\\n\\n\" + \"\\n\".join(str(message) for message in self.messages)\n\tDiffStr: TypeAlias = str\n"]}
{"filename": "autopr/models/events.py", "chunked_list": ["from typing import Literal, Union\n\timport pydantic\n\tfrom autopr.models.artifacts import Issue, Message, PullRequest  # , CodeComment\n\tclass Event(pydantic.BaseModel):\n\t    \"\"\"\n\t    Events trigger AutoPR to run in different ways.\n\t    \"\"\"\n\t    event_type: str\n\tclass IssueLabelEvent(Event):\n\t    \"\"\"\n", "    Event triggered when a label is added to an issue.\n\t    \"\"\"\n\t    event_type: Literal['issue_label'] = 'issue_label'\n\t    issue: Issue\n\t    label: str\n\tclass PullRequestCommentEvent(Event):\n\t    \"\"\"\n\t    Event triggered when a comment is added to a pull request.\n\t    \"\"\"\n\t    event_type: Literal['pull_request_comment'] = 'pull_request_comment'\n", "    pull_request: PullRequest\n\t    new_comment: Message\n\t# class CodeReviewEvent(Event):\n\t#     \"\"\"\n\t#     Event triggered when a comment is added to a code review.\n\t#     \"\"\"\n\t#     event_type: Literal['code_review'] = 'code_review'\n\t#\n\t#     pull_request: PullRequest\n\t#     new_code_comments: list[CodeComment]\n", "#     new_comment: Message\n\tEventUnion = Union[IssueLabelEvent, PullRequestCommentEvent]  # | CodeReviewEventa\n"]}
{"filename": "autopr/models/prompt_base.py", "chunked_list": ["from typing import ClassVar\n\timport pydantic\n\timport structlog\n\tfrom autopr.utils.tokenizer import get_tokenizer\n\tlog = structlog.get_logger()\n\tclass PromptBase(pydantic.BaseModel):\n\t    \"\"\"\n\t    Base class for all prompt specifications.\n\t    Prompt parameters should be specified as pydantic instance attributes.\n\t    They will be automatically filled into the `prompt_template` string,\n", "    wherever they are referenced as {param}.\n\t    \"\"\"\n\t    #: The prompt template to use for the LLM call (reference string parameters as {param}).\n\t    prompt_template: ClassVar[str] = ''\n\t    # TODO implement extra_params in rail_service and chain_service\n\t    #: Extra parameters to pass to the guardrails LLM call.\n\t    # extra_params: ClassVar[dict[str, Any]] = {}\n\t    def get_prompt_message(self) -> str:\n\t        \"\"\"\n\t        Get the prompt message that is sent the LLM call.\n", "        \"\"\"\n\t        spec = self.prompt_template\n\t        prompt_params = self.get_string_params()\n\t        return spec.format(**prompt_params)\n\t    def get_string_params(self) -> dict[str, str]:\n\t        \"\"\"\n\t        Get the parameters of the prompt as a dictionary of strings.\n\t        Override this method to specify your own parameters.\n\t        \"\"\"\n\t        prompt_params = {}\n", "        for key, value in self:\n\t            if isinstance(value, list):\n\t                prompt_params[key] = '\\n\\n'.join(\n\t                    [str(item) for item in value]\n\t                )\n\t            else:\n\t                prompt_params[key] = str(value)\n\t        return prompt_params\n\t    def calculate_prompt_token_length(self) -> int:\n\t        \"\"\"\n", "        Calculate the number of tokens in the prompt message.\n\t        \"\"\"\n\t        tokenizer = get_tokenizer()\n\t        prompt_message = self.get_prompt_message()\n\t        return len(tokenizer.encode(prompt_message))\n\t    def ensure_token_length(self, max_length: int) -> bool:\n\t        \"\"\"\n\t        Ensure that the prompt message is no longer than `max_length` tokens.\n\t        \"\"\"\n\t        # Make sure there are at least `min_tokens` tokens left\n", "        while max_length < self.calculate_prompt_token_length():\n\t            # Iteratively trim the params\n\t            if not self.trim_params():\n\t                rail_name = self.__class__.__name__\n\t                log.debug(f'Could not trim params on rail {rail_name}: {self.get_string_params()}')\n\t                return False\n\t        return True\n\t    def trim_params(self) -> bool:\n\t        \"\"\"\n\t        Override this method to trim the parameters of the prompt.\n", "        This is called when the prompt is too long. By default, this method\n\t        removes the last element of the first list it finds.\n\t        TODO give this method better heuristics for trimming, so it doesn't just\n\t         get called over and over again.\n\t        \"\"\"\n\t        log.warning(\"Naively trimming params\", rail=self)\n\t        prompt_params = dict(self)\n\t        # If there are any lists, remove the last element of the first one you find\n\t        for key, value in prompt_params.items():\n\t            if isinstance(value, list) and len(value) > 0:\n", "                setattr(self, key, value[:-1])\n\t                return True\n\t        return False\n"]}
{"filename": "autopr/models/__init__.py", "chunked_list": []}
{"filename": "autopr/models/prompt_chains.py", "chunked_list": ["from typing import ClassVar, Any, Type, Optional\n\tfrom autopr.models.prompt_base import PromptBase\n\tfrom langchain.schema import BaseOutputParser\n\timport structlog\n\tlog = structlog.get_logger()\n\tclass PromptChain(PromptBase):\n\t    \"\"\"\n\t    A prompt chain is a pydantic model used to specify a prompt for a langchain call.\n\t    See ChainService and [Langchain docs](https://docs.langchain.ai/) for more information.\n\t    To define your own prompt chain:\n", "    - write a prompt template in the `prompt_template` class variable, referencing parameters as {param}\n\t    - define your parameters as pydantic instance attributes\n\t    - optionally define an output parser as the `output_parser` class variable\n\t    \"\"\"\n\t    #: The output parser to run the response through.\n\t    output_parser: ClassVar[Optional[BaseOutputParser]] = None\n\t    def get_prompt_message(self) -> str:\n\t        \"\"\"\n\t        Get the prompt message that is sent the LLM call.\n\t        Ordinarily the format instructions are passed as a partial variable,\n", "        so this method is overridden to include them for the trimming calculation.\n\t        \"\"\"\n\t        spec = self.prompt_template\n\t        prompt_params = self.get_string_params()\n\t        if self.output_parser is not None:\n\t            prompt_params['format_instructions'] = self.output_parser.get_format_instructions()\n\t        return spec.format(**prompt_params)\n"]}
{"filename": "autopr/models/prompt_rails.py", "chunked_list": ["import typing\n\tfrom typing import ClassVar, Any\n\timport pydantic\n\tfrom autopr.models.prompt_base import PromptBase\n\tfrom autopr.models.rail_objects import RailObject\n\timport structlog\n\tlog = structlog.get_logger()\n\tclass PromptRail(PromptBase):\n\t    \"\"\"\n\t    A prompt rail is a pydantic model used to specify a prompt for a guardrails LLM call.\n", "    See RailObject, RailService, and [Guardrails docs](https://docs.guardrails.io/) for more information.\n\t    To define your own prompt rail:\n\t    - declare your output type by subclassing RailObject, and referencing it in the `output_type` class variable\n\t    - write a prompt in the `prompt_template` class variable, referencing parameters as {param}\n\t    - define your parameters as pydantic instance attributes\n\t    \"\"\"\n\t    #: Whether to invoke the guardrails LLM call on the output of an ordinary LLM call, or just by itself.\n\t    two_step: ClassVar[bool] = True\n\t    #: The RailObject type to parse the LLM response into.\n\t    output_type: ClassVar[typing.Type[RailObject]]\n"]}
{"filename": "autopr/services/agent_service.py", "chunked_list": ["from typing import Optional, Any\n\timport structlog\n\tfrom git.repo import Repo\n\tfrom autopr.agents.base import Agent, get_all_agents\n\tfrom autopr.models.events import EventUnion\n\tfrom autopr.services.action_service import ActionService\n\tfrom autopr.services.chain_service import ChainService\n\tfrom autopr.services.commit_service import CommitService\n\tfrom autopr.services.diff_service import DiffService\n\tfrom autopr.services.publish_service import PublishService\n", "from autopr.services.rail_service import RailService\n\tclass AgentService:\n\t    def __init__(\n\t        self,\n\t        rail_service: RailService,\n\t        chain_service: ChainService,\n\t        diff_service: DiffService,\n\t        commit_service: CommitService,\n\t        publish_service: PublishService,\n\t        action_service: ActionService,\n", "        repo: Repo,\n\t    ):\n\t        self.repo = repo\n\t        self.publish_service = publish_service\n\t        self.rail_service = rail_service\n\t        self.chain_service = chain_service\n\t        self.diff_service = diff_service\n\t        self.commit_service = commit_service\n\t        self.action_service = action_service\n\t        # Load all agents in the `autopr/agents` directory\n", "        self.agents: dict[str, type[Agent]] = {\n\t            agent.id: agent\n\t            for agent in get_all_agents()\n\t        }\n\t        self.log = structlog.get_logger(service=\"agent_service\")\n\t    def run_agent(\n\t        self,\n\t        agent_id: str,\n\t        agent_config: Optional[dict[str, Any]],\n\t        event: EventUnion,\n", "    ):\n\t        # Get the agent\n\t        agent_type = self.agents[agent_id]\n\t        agent = agent_type(\n\t            repo=self.repo,\n\t            rail_service=self.rail_service,\n\t            chain_service=self.chain_service,\n\t            diff_service=self.diff_service,\n\t            commit_service=self.commit_service,\n\t            publish_service=self.publish_service,\n", "            action_service=self.action_service,\n\t            **(agent_config or {}),\n\t        )\n\t        # Publish an empty pull request\n\t        self.publish_service.update()\n\t        # Publish a warning if using gpt-3.5-turbo\n\t        if self.rail_service.completions_repo.model == \"gpt-3.5-turbo\":\n\t            self.publish_service.publish_update(\n\t                \"⚠️⚠️⚠️ Warning: Using `gpt-3.5-turbo` completion model. \"\n\t                \"AutoPR is currently not optimized for this model. \"\n", "                \"See https://github.com/irgolic/AutoPR/issues/65 for more details. \"\n\t                \"In the mean time, if you have access to the `gpt-4` API, please use that instead. \"\n\t                \"Please note that ChatGPT Plus does not give you access to the `gpt-4` API; \"\n\t                \"you need to sign up on [the GPT-4 API waitlist](https://openai.com/waitlist/gpt-4-api). \"\n\t            )\n\t        self.log.info(\"Generating changes\", event_=event)\n\t        try:\n\t            agent.handle_event(event)\n\t        except Exception as e:\n\t            self.log.exception(\"Agent failed\", event_=event, exc_info=e)\n", "            self.publish_service.finalize(success=False)\n\t            raise e\n\t        self.log.info(\"Generated changes\", event_=event)\n\t        # Finalize the pull request (put progress updates in a collapsible)\n\t        self.publish_service.finalize(success=True)\n"]}
{"filename": "autopr/services/event_service.py", "chunked_list": ["from typing import Any\n\timport requests\n\timport structlog\n\tfrom autopr.models.artifacts import Issue, Message, PullRequest\n\tfrom autopr.models.events import IssueLabelEvent, EventUnion, PullRequestCommentEvent\n\tclass EventService:\n\t    \"\"\"\n\t    Service for parsing events that trigger AutoPR into one of the `EventUnion` types.\n\t    To support other platforms (Gitlab/Bitbucket/Gitea), subclass this and override `parse_event`.\n\t    See irgolic/AutoPR#46 for more details.\n", "    \"\"\"\n\t    def parse_event(self, event_name: str, event: dict[str, Any]) -> EventUnion:\n\t        raise NotImplementedError\n\tclass GitHubEventService(EventService):\n\t    \"\"\"\n\t    Service for parsing GitHub events into one of the `EventUnion` types.\n\t    Currently only supports `IssueLabelEvent`, which is triggered when a label is added to an issue.\n\t    See https://docs.github.com/en/webhooks-and-events/events/issue-event-types\n\t    \"\"\"\n\t    def __init__(\n", "        self,\n\t        github_token: str,\n\t    ):\n\t        self.github_token = github_token\n\t        self.log = structlog.get_logger()\n\t    def get_headers(self):\n\t        return {\n\t            'Accept': 'application/vnd.github.v3+json',\n\t            'Authorization': f'Bearer {self.github_token}'\n\t        }\n", "    def _to_issue_label_event(self, event: dict[str, Any]) -> IssueLabelEvent:\n\t        \"\"\"\n\t        See https://docs.github.com/en/webhooks-and-events/events/issue-event-types#labeled\n\t        \"\"\"\n\t        # Get issue comments\n\t        url = event['issue']['comments_url']\n\t        assert url.startswith('https://api.github.com/repos/'), \"Unexpected comments_url\"\n\t        self.log.info(\"Getting issue comments\", url=url)\n\t        headers = self.get_headers()\n\t        response = requests.get(url, headers=headers)\n", "        response.raise_for_status()\n\t        comments_json = response.json()\n\t        self.log.info(\"Got issue comments\", comments=comments_json)\n\t        # Get body\n\t        comments_list = []\n\t        body_message = Message(\n\t            body=event['issue']['body'] or \"\",\n\t            author=event['issue']['user']['login'],\n\t        )\n\t        comments_list.append(body_message)\n", "        # Get comments\n\t        for comment_json in comments_json:\n\t            comment = Message(\n\t                body=comment_json['body'] or \"\",\n\t                author=comment_json['user']['login'],\n\t            )\n\t            comments_list.append(comment)\n\t        # Create issue\n\t        issue = Issue(\n\t            number=event['issue']['number'],\n", "            title=event['issue']['title'],\n\t            author=event['issue']['user']['login'],\n\t            messages=comments_list,\n\t        )\n\t        return IssueLabelEvent(\n\t            issue=issue,\n\t            label=event['label']['name'],\n\t        )\n\t    def _to_pull_request_comment_event(self, event: dict[str, Any]) -> PullRequestCommentEvent:\n\t        \"\"\"\n", "        See https://docs.github.com/en/webhooks-and-events/webhooks/webhook-events-and-payloads#issue_comment\n\t        \"\"\"\n\t        headers = self.get_headers()\n\t        # Get issue comments\n\t        url = event['issue']['comments_url']\n\t        assert url.startswith('https://api.github.com/repos/'), \"Unexpected comments_url\"\n\t        self.log.info(\"Getting issue comments\", url=url)\n\t        response = requests.get(url, headers=headers)\n\t        response.raise_for_status()\n\t        comments_json = response.json()\n", "        self.log.info(\"Got issue comments\", comments=comments_json)\n\t        # Get body\n\t        comments_list = []\n\t        body_message = Message(\n\t            body=event['issue']['body'] or \"\",\n\t            author=event['issue']['user']['login'],\n\t        )\n\t        comments_list.append(body_message)\n\t        # Get comments\n\t        for comment_json in comments_json:\n", "            comment = Message(\n\t                body=comment_json['body'] or \"\",\n\t                author=comment_json['user']['login'],\n\t            )\n\t            comments_list.append(comment)\n\t        # Get pull request\n\t        url = event['issue']['pull_request']['url']\n\t        assert url.startswith('https://api.github.com/repos/'), \"Unexpected pull_request url\"\n\t        self.log.info(\"Getting pull request\", url=url)\n\t        response = requests.get(url, headers=headers)\n", "        response.raise_for_status()\n\t        pull_request_json = response.json()\n\t        self.log.info(\"Got pull request\", pull_request=pull_request_json)\n\t        # Get branch names\n\t        head_branch = pull_request_json['head']['ref']\n\t        base_branch = pull_request_json['base']['ref']\n\t        # Create pull request\n\t        pull_request = PullRequest(\n\t            number=event['issue']['number'],\n\t            title=event['issue']['title'],\n", "            author=event['issue']['user']['login'],\n\t            messages=comments_list,\n\t            head_branch=head_branch,\n\t            base_branch=base_branch,\n\t        )\n\t        return PullRequestCommentEvent(\n\t            pull_request=pull_request,\n\t            new_comment=Message(\n\t                body=event['comment']['body'] or \"\",\n\t                author=event['comment']['user']['login'],\n", "            ),\n\t        )\n\t    def parse_event(self, event_name: str, event_dict: dict[str, Any]):\n\t        if event_name == 'issues':\n\t            return self._to_issue_label_event(event_dict)\n\t        elif event_name == 'issue_comment':\n\t            return self._to_pull_request_comment_event(event_dict)\n\t        raise ValueError(f\"Unsupported event name: {event_name}\")\n"]}
{"filename": "autopr/services/action_service.py", "chunked_list": ["import traceback\n\tfrom typing import Optional, Collection, Type\n\timport pydantic\n\timport structlog\n\tfrom git.repo import Repo\n\tfrom autopr.actions.base import get_all_actions, Action\n\tfrom autopr.actions.base import ContextDict\n\tfrom autopr.models.rail_objects import RailObject\n\tfrom autopr.repos.completions_repo import CompletionsRepo\n\tfrom autopr.services.chain_service import ChainService\n", "from autopr.services.publish_service import PublishService\n\tfrom autopr.services.rail_service import RailService\n\tclass ActionService:\n\t    class Finished(Action):\n\t        id = \"finished\"\n\t        class Arguments(Action.Arguments):\n\t            reason: str\n\t            output_spec = \"\"\"<string\n\t                name=\"reason\"\n\t                required=\"true\"\n", "            />\"\"\"\n\t        def run(self, arguments: Action.Arguments, context: ContextDict) -> ContextDict:\n\t            return context\n\t    def __init__(\n\t        self,\n\t        repo: Repo,\n\t        completions_repo: CompletionsRepo,\n\t        publish_service: PublishService,\n\t        rail_service: RailService,\n\t        chain_service: ChainService,\n", "        num_reasks: int = 3\n\t    ):\n\t        self.repo = repo\n\t        self.completions_repo = completions_repo\n\t        self.publish_service = publish_service\n\t        self.rail_service = rail_service\n\t        self.chain_service = chain_service\n\t        self.num_reasks = num_reasks\n\t        # Load all actions in the `autopr/actions` directory\n\t        self.actions: dict[str, type[Action]] = {\n", "            action.id: action\n\t            for action in get_all_actions()\n\t        }\n\t        self.log = structlog.get_logger(service=\"action_service\")\n\t    def _write_action_selection_rail_spec(\n\t        self,\n\t        action_ids: Collection[str],\n\t        include_finished: bool = False,\n\t    ) -> str:\n\t        # Add finished action\n", "        if include_finished and \"finished\" not in action_ids:\n\t            action_ids = [*action_ids, \"finished\"]\n\t        # Write the \"choice\" output spec\n\t        output_spec = f\"\"\"<choice\n\t            name=\"action\"\n\t            on-fail-choice=\"reask\"\n\t        >\"\"\"\n\t        for action_id in action_ids:\n\t            action = self.actions[action_id]\n\t            output_spec += f\"\"\"<case\n", "                name=\"{action.id}\"\n\t                {f'description=\"{action.description}\"' if action.description else \"\"}\n\t            >\n\t            <object\n\t                name=\"{action.id}\"\n\t            >\"\"\"\n\t            if action.Arguments.output_spec:\n\t                output_spec += action.Arguments.output_spec\n\t            else:\n\t                if action.Arguments is not Action.Arguments:\n", "                    # Guardrails RFC (GRAIL-001) plans to generate output specs from pydantic models automatically,\n\t                    # but for now, we need to manually write them.\n\t                    raise ValueError(\n\t                        f\"{action.__name__}.Arguments ({action_id}) is missing an output spec\"\n\t                    )\n\t                output_spec += \"\"\"<string \n\t                    name=\"reason\"\n\t                />\"\"\"\n\t            output_spec += f\"\"\"\n\t            </object>\n", "            \"\"\"\n\t            output_spec += f\"\"\"</case>\"\"\"\n\t        output_spec += f\"\"\"</choice>\"\"\"\n\t        # Wrap it in a rail spec\n\t        return f\"\"\"\n\t<rail version=\"0.1\">\n\t<output>\n\t{output_spec}\n\t</output>\n\t<instructions>\n", "You are AutoPR, an autonomous pull request creator and a helpful assistant only capable of communicating with valid JSON, and no other text.\n\t@autopr_json_suffix_prompt_examples\n\t</instructions>\n\t<prompt>\n\t{{{{context}}}}\n\tYou are about to make a decision on what to do next, and return a JSON that follows the correct schema.\n\t@xml_prefix_prompt\n\t{{output_schema}}\n\t</prompt>\n\t</rail>\n", "\"\"\"\n\t    @staticmethod\n\t    def _write_action_args_query_rail_spec(\n\t        arguments: Type[Action.Arguments],\n\t    ) -> str:\n\t        return f\"\"\"\n\t<rail version=\"0.1\">\n\t<output>\n\t{arguments.output_spec}\n\t</output>\n", "<instructions>\n\tYou are AutoPR, an autonomous pull request creator and a helpful assistant only capable of communicating with valid JSON, and no other text.\n\t@autopr_json_suffix_prompt_examples\n\t</instructions>\n\t<prompt>\n\t{{{{context}}}}\n\tYou are about to make a decision on what to do next, and return a JSON that follows the correct schema.\n\t@xml_prefix_prompt\n\t{{output_schema}}\n\t</prompt>\n", "</rail>\n\t\"\"\"\n\t    def instantiate_action(\n\t        self,\n\t        action_type: Type[Action],\n\t    ):\n\t        return action_type(\n\t            repo=self.repo,\n\t            rail_service=self.rail_service,\n\t            chain_service=self.chain_service,\n", "            publish_service=self.publish_service,\n\t        )\n\t    def run_action(\n\t        self,\n\t        action_id: str,\n\t        context: ContextDict,\n\t    ) -> ContextDict:\n\t        # Get the action\n\t        action_type = self.actions[action_id]\n\t        section_title = f\"🚀 Running {action_id}\"\n", "        self.publish_service.start_section(section_title)\n\t        # If the action defines arguments, ask the LLM to fill them in\n\t        if action_type.Arguments is not Action.Arguments:\n\t            # Ask the LLM to fill in the arguments\n\t            arguments = self.ask_for_action_arguments(\n\t                action_type=action_type,\n\t                context=context,\n\t            )\n\t            if arguments is None:\n\t                self.log.error(\"Guardrails failed to specify action arguments\")\n", "                return context\n\t        else:\n\t            arguments = Action.Arguments()\n\t        # Instantiate the action\n\t        action = self.instantiate_action(action_type)\n\t        # Run the action\n\t        try:\n\t            results = action.run(arguments, context)\n\t        except Exception:\n\t            self.log.exception(f\"Failed to run action {action_id}\")\n", "            self.publish_service.publish_code_block(\n\t                heading=\"Error\",\n\t                code=traceback.format_exc(),\n\t                language=\"python\",  # FIXME\n\t                                    #  does nice syntax highlighting for tracebacks, but should be made configurable\n\t            )\n\t            self.publish_service.end_section(f\"❌ Failed {action_id}\")\n\t            raise\n\t        if self.publish_service.sections_stack[-1].title == section_title:\n\t            self.publish_service.end_section(f\"✅ Finished {action_id}\")\n", "        self.publish_service.end_section()\n\t        return results\n\t    def run_actions_iteratively(\n\t        self,\n\t        action_ids: Collection[str],\n\t        context: ContextDict,\n\t        context_headings: Optional[dict[str, str]] = None,\n\t        max_iterations: int = 5,\n\t        include_finished: bool = False,\n\t    ) -> ContextDict:\n", "        for _ in range(max_iterations):\n\t            if len(action_ids) == 1 and not include_finished:\n\t                action_id = next(iter(action_ids))\n\t                context = self.run_action(action_id, context)\n\t                continue\n\t            self.publish_service.start_section(\"❓ Choosing next action\")\n\t            # Pick an action\n\t            pick = self.pick_action(\n\t                action_ids=action_ids,\n\t                context=context,\n", "                include_finished=include_finished,\n\t                context_headings=context_headings,\n\t            )\n\t            if pick is None or pick[0].id == \"finished\":\n\t                self.publish_service.end_section(\"🏁 Finished\")\n\t                break\n\t            action_type, args = pick\n\t            # Instantiate the action\n\t            action = self.instantiate_action(action_type)\n\t            self.publish_service.update_section(f\"🚀 Running {action.id}\")\n", "            # Run the action\n\t            context = action.run(args, context)\n\t            self.publish_service.end_section()\n\t        return context\n\t    def ask_for_action_arguments(\n\t        self,\n\t        action_type: Type[Action],\n\t        context: ContextDict,\n\t    ) -> Optional[Action.Arguments]:\n\t        if action_type.Arguments is Action.Arguments:\n", "            # No arguments to fill in\n\t            return Action.Arguments()\n\t        # Generate the arguments query spec\n\t        rail_spec = self._write_action_args_query_rail_spec(\n\t            arguments=action_type.Arguments,\n\t        )\n\t        # Run the rail\n\t        dict_o = self.rail_service.run_rail_string(\n\t            rail_spec,\n\t            prompt_params={\n", "                \"context\": context.as_string(),\n\t            },\n\t            heading=\"action arguments\",\n\t        )\n\t        if dict_o is None:\n\t            self.log.error(\"Guardrails failed to specify action arguments\")\n\t            return None\n\t        # Parse the arguments\n\t        try:\n\t            args = action_type.Arguments.parse_obj(dict_o)\n", "        except pydantic.ValidationError as e:\n\t            self.log.error(\"Guardrails failed to parse action arguments\", error=e)\n\t            return None\n\t        return args\n\t    def pick_action(\n\t        self,\n\t        action_ids: Collection[str],\n\t        context: ContextDict,\n\t        include_finished: bool = False,\n\t        context_headings: Optional[dict[str, str]] = None,\n", "    ) -> Optional[tuple[type[Action], Action.Arguments]]:\n\t        \"\"\"\n\t        Pick an action to run next.\n\t        Returns a tuple of the action type and the arguments to instantiate it with.\n\t        \"\"\"\n\t        # Generate the action-select rail spec\n\t        rail_spec = self._write_action_selection_rail_spec(\n\t            action_ids=action_ids,\n\t            include_finished=include_finished,\n\t        )\n", "        self.log.debug(\"Wrote action-selection rail spec:\\n%s\", rail_spec=rail_spec)\n\t        # Instantiate the rail\n\t        dict_o = self.rail_service.run_rail_string(\n\t            rail_spec,\n\t            prompt_params={\n\t                \"context\": context.as_string(\n\t                    variable_headings=context_headings,\n\t                ),\n\t            },\n\t            heading=\"action choice\",\n", "        )\n\t        if dict_o is None:\n\t            self.log.error(\"Guardrails failed to choose an action\")\n\t            return None\n\t        # Get the action\n\t        action_id = dict_o[\"action\"]\n\t        if action_id == \"finished\":\n\t            # Done!\n\t            return None\n\t        action_args_dict = dict_o.get(action_id, {})\n", "        action = self.actions[action_id]\n\t        args = action.Arguments.parse_obj(action_args_dict)\n\t        return action, args\n"]}
{"filename": "autopr/services/__init__.py", "chunked_list": []}
{"filename": "autopr/services/publish_service.py", "chunked_list": ["import json\n\timport sys\n\timport traceback\n\tfrom typing import Optional, Union, Any, Type\n\timport pydantic\n\timport requests\n\tfrom autopr.models.artifacts import Issue\n\timport structlog\n\tclass CodeBlock(pydantic.BaseModel):\n\t    \"\"\"\n", "    A block of text to be shown as a code block in the pull request description.\n\t    \"\"\"\n\t    heading: str\n\t    code: str\n\t    language: str = \"xml\"\n\t    default_open: bool = False\n\t    def __str__(self):\n\t        return f\"\"\"<details{\" open\" if self.default_open else \"\"}>\n\t<summary>{self.heading}</summary>\n\t~~~{self.language}\n", "{self.code}\n\t~~~\n\t</details>\"\"\"\n\tclass UpdateSection(pydantic.BaseModel):\n\t    \"\"\"\n\t    A section of the pull request description, used to keep state while publishing updates.\n\t    \"\"\"\n\t    level: int\n\t    title: str\n\t    updates: list[Union[str, CodeBlock, 'UpdateSection']] = pydantic.Field(default_factory=list)\n", "class PublishService:\n\t    \"\"\"\n\t    Service for publishing updates to the pull request description.\n\t    To control update sections, call:\n\t    - `start_section` to start a new section\n\t    - `end_section` to end the current section (optionally with results and a new title)\n\t    - `update_section` to update the current section title\n\t    To publish updates to the current section, call:\n\t    - `publish_update` to publish a simple textual update\n\t    - `publish_code_block` to publish text in a triple-backtick-style code block\n", "    \"\"\"\n\t    def __init__(\n\t        self,\n\t        owner: str,\n\t        repo_name: str,\n\t        head_branch: str,\n\t        base_branch: str,\n\t        issue: Optional[Issue] = None,\n\t        pull_request_number: Optional[int] = None,\n\t        loading_gif_url: str = \"https://media.giphy.com/media/3oEjI6SIIHBdRxXI40/giphy.gif\",\n", "        overwrite_existing: bool = False,\n\t    ):\n\t        self.owner = owner\n\t        self.repo_name = repo_name\n\t        self.head_branch = head_branch\n\t        self.base_branch = base_branch\n\t        self.issue = issue\n\t        self.pr_number = pull_request_number\n\t        self.loading_gif_url = loading_gif_url\n\t        self.overwrite_existing = overwrite_existing\n", "        # GitHub comment length limit is ~262144, not 65536 as stated in the docs\n\t        self.max_comment_length = 260000\n\t        if issue is not None:\n\t            self.title: str = f\"Fix #{issue.number}: {issue.title}\"\n\t        else:\n\t            self.title: str = \"AutoPR\"\n\t        self.root_section = UpdateSection(\n\t            level=0,\n\t            title=\"root\",\n\t        )\n", "        self.sections_stack: list[UpdateSection] = [self.root_section]\n\t        self.log = structlog.get_logger(service=\"publish\")\n\t        self._last_code_block: Optional[CodeBlock] = None\n\t        self.error_report_template = \"\"\"\n\t## Traceback\n\t```\n\t{error}\n\t```\n\t\"\"\"\n\t        self.new_error_report_link_template = \"https://github.com/irgolic/AutoPR/issues/new?\" \\\n", "                                              \"title={title}&\" \\\n\t                                              \"labels=bug&\" \\\n\t                                              \"body={body}\"\n\t    def set_title(self, title: str):\n\t        \"\"\"\n\t        Set the pull request title and body.\n\t        A description heading will be added to the body.\n\t        Parameters\n\t        ----------\n\t        title: str\n", "            The title of the pull request\n\t        body: str\n\t            The body of the pull request\n\t        \"\"\"\n\t        if self.pr_number is None:\n\t            self.update()\n\t            if self.pr_number is None:\n\t                raise RuntimeError(\"Error creating pull request\")\n\t        else:\n\t            self._set_title(title)\n", "    def publish_update(\n\t        self,\n\t        text: str,\n\t        section_title: Optional[str] = None,\n\t    ):\n\t        \"\"\"\n\t        Publish a simple text update to the current section.\n\t        Parameters\n\t        ----------\n\t        text: str\n", "            The text to publish\n\t        section_title: str, optional\n\t            The title that the parent section should be updated to\n\t        \"\"\"\n\t        self.sections_stack[-1].updates.append(text)\n\t        if section_title:\n\t            if self.sections_stack is self.root_section:\n\t                raise ValueError(\"Cannot set section title on root section\")\n\t            self.sections_stack[-1].title = section_title\n\t        self.log.debug(\"Publishing update\", text=text)\n", "        self.update()\n\t    def publish_code_block(\n\t        self,\n\t        heading: str,\n\t        code: str,\n\t        default_open: bool = False,\n\t        language: str = \"xml\",\n\t        section_title: Optional[str] = None,\n\t    ):\n\t        \"\"\"\n", "        Publish a code block as a collapsible child to the current section.\n\t        Parameters\n\t        ----------\n\t        heading: str\n\t            The title of the collapsible\n\t        code: str\n\t            The contents of the collapsible\n\t        default_open: bool, optional\n\t            Whether the collapsible should be open by default\n\t        language: str, optional\n", "            The language of the code (defaults to python)\n\t        section_title: str, optional\n\t            The title that the parent section should be updated to\n\t        \"\"\"\n\t        block = CodeBlock(\n\t            heading=heading,\n\t            code=code,\n\t            language=language,\n\t            default_open=default_open,\n\t        )\n", "        self._last_code_block = block\n\t        self.sections_stack[-1].updates.append(block)\n\t        if section_title:\n\t            if self.sections_stack is self.root_section:\n\t                raise ValueError(\"Cannot set section title on root section\")\n\t            self.sections_stack[-1].title = section_title\n\t        self.update()\n\t    def start_section(\n\t        self,\n\t        title: str,\n", "    ):\n\t        \"\"\"\n\t        Start a new section.\n\t        Parameters\n\t        ----------\n\t        title: str\n\t            The title of the new section\n\t        \"\"\"\n\t        self.log.debug(\"Starting section\", title=title)\n\t        new_section = UpdateSection(\n", "            level=len(self.sections_stack),\n\t            title=title,\n\t        )\n\t        self.sections_stack[-1].updates.append(new_section)  # Add the new section as a child\n\t        self.sections_stack.append(new_section)\n\t        self.update()\n\t    def update_section(self, title: str):\n\t        \"\"\"\n\t        Update the title of the current section.\n\t        Parameters\n", "        ----------\n\t        title: str\n\t            The new title of the current section\n\t        \"\"\"\n\t        if len(self.sections_stack) == 1:\n\t            raise ValueError(\"Cannot set section title on root section\")\n\t        self.log.debug(\"Updating section\", title=title)\n\t        self.sections_stack[-1].title = title\n\t        self.update()\n\t    def end_section(\n", "        self,\n\t        title: Optional[str] = None,\n\t    ):\n\t        \"\"\"\n\t        End the current section.\n\t        Parameters\n\t        ----------\n\t        title: str, optional\n\t            The title that section should be updated to\n\t        result: str, optional\n", "            The result of the section\n\t        \"\"\"\n\t        if len(self.sections_stack) == 1:\n\t            raise ValueError(\"Cannot end root section\")\n\t        self.log.debug(\"Ending section\", title=title)\n\t        if title:\n\t            self.sections_stack[-1].title = title\n\t        self.sections_stack.pop()\n\t        self.update()\n\t    def _contains_last_code_block(self, parent: UpdateSection) -> bool:\n", "        for section in reversed(parent.updates):\n\t            if isinstance(section, CodeBlock):\n\t                return section is self._last_code_block\n\t            elif isinstance(section, UpdateSection):\n\t                return self._contains_last_code_block(section)\n\t        return False\n\t    def _build_progress_update(self, section: UpdateSection, open_default: bool = False) -> str:\n\t        progress = \"\"\n\t        # Get list of steps\n\t        updates = []\n", "        for update in section.updates:\n\t            if isinstance(update, UpdateSection):\n\t                # Recursively build updates\n\t                updates += [self._build_progress_update(\n\t                    update,\n\t                    open_default=(\n\t                        self._contains_last_code_block(update) or update is section.updates[-1]\n\t                    ),\n\t                )]\n\t                continue\n", "            if isinstance(update, CodeBlock):\n\t                # If is the last code block\n\t                if self._last_code_block is None or update is self._last_code_block or update is section.updates[-1]:\n\t                    # Clone the block and set default_open to True\n\t                    update = update.copy()\n\t                    update.default_open = True\n\t                updates += [str(update)]\n\t                continue\n\t            updates += [update]\n\t        # Prefix updates with quotation\n", "        updates = '\\n\\n'.join(updates)\n\t        updates = '\\n'.join([f\"> {line}\" for line in updates.splitlines()])\n\t        # Leave the last section open if we're not finalizing (i.e. if we're still running or errored)\n\t        progress += f\"\"\"<details{' open' if open_default else ''}>\n\t<summary>{section.title}</summary>\n\t{updates}\n\t</details>\"\"\"\n\t        return progress\n\t    def _build_bodies(self, success: Optional[bool] = None) -> list[str]:\n\t        \"\"\"\n", "        Builds the body of the pull request, splitting it into multiple bodies if necessary.\n\t        Assumes that the top-level section groups are each small enough to fit within `max_comment_length`.\n\t        \"\"\"\n\t        bodies = []\n\t        body = \"\"\n\t        if self.issue is not None:\n\t            # Add Fixes magic word\n\t            body += f\"Fixes #{self.issue.number}\\n\\n\"\n\t        # Build status\n\t        body += f\"## Status\\n\\n\"\n", "        if success is None:\n\t            body += \"This pull request is being autonomously generated by [AutoPR](https://github.com/irgolic/AutoPR).\"\n\t        elif not success:\n\t            body += f\"This pull request was being autonomously generated by \" \\\n\t                    f\"[AutoPR](https://github.com/irgolic/AutoPR), but it encountered an error.\"\n\t            if sys.exc_info()[0] is not None:\n\t                body += f\"\\n\\nError:\\n\\n```\\n{traceback.format_exc()}\\n```\"\n\t            body += f'\\n\\nPlease <a href=\"{self._build_issue_template_link()}\">open an issue</a> to report this.'\n\t        elif success:\n\t            body += f\"This pull request was autonomously generated by [AutoPR](https://github.com/irgolic/AutoPR).\\n\\n\" \\\n", "                    f\"If there's a problem with this pull request, please \" \\\n\t                    f\"[open an issue]({self._build_issue_template_link()}).\"\n\t        for section in self.root_section.updates:\n\t            if isinstance(section, UpdateSection):\n\t                progress_update = self._build_progress_update(\n\t                    section,\n\t                    open_default=(\n\t                        not success and\n\t                        (section is self.root_section.updates[-1] or self._contains_last_code_block(section))\n\t                    ),\n", "                )\n\t            else:\n\t                progress_update = str(section)\n\t            if len(body) + len('\\n\\n' + progress_update) > self.max_comment_length:\n\t                bodies += [body]\n\t                body = f\"## Status (continued)\\n\\n{progress_update}\"\n\t            else:\n\t                body += f\"\\n\\n{progress_update}\"\n\t        if success is None:\n\t            body += f\"\\n\\n\" \\\n", "                    f'<img src=\"{self.loading_gif_url}\"' \\\n\t                    f' width=\"200\" height=\"200\"/>'\n\t        bodies += [body]\n\t        # self.log.debug(\"Built bodies\", bodies=bodies)\n\t        return bodies\n\t    def _build_issue_template_link(self, **kwargs):\n\t        if sys.exc_info()[0] is not None:\n\t            error = traceback.format_exc()\n\t        else:\n\t            error = \"No traceback\"\n", "        kwargs['error'] = error\n\t        body = self.error_report_template.format(**kwargs)\n\t        if sys.exc_info()[0] is not None:\n\t            title = traceback.format_exception_only(sys.exc_info()[0], sys.exc_info()[1])[0].strip()\n\t        elif self.issue is not None:\n\t            title = f'Error fixing \"{self.issue.title}\"'\n\t        else:\n\t            title = \"Error running AutoPR\"\n\t        issue_link = self.new_error_report_link_template.format(\n\t            body=body,\n", "            title=title,\n\t        )\n\t        # Map characters to their URL-encoded equivalents\n\t        encoded_url = issue_link.replace(' ', '%20').replace('\\n', '%0A').replace('\"', '%22').replace(\"#\", \"%23\")\n\t        return encoded_url\n\t    def update(self):\n\t        \"\"\"\n\t        Update the PR body with the current progress.\n\t        \"\"\"\n\t        bodies = self._build_bodies()\n", "        self._publish_progress(bodies)\n\t    def finalize(self, success: bool):\n\t        \"\"\"\n\t        Finalize the PR, either successfully or unsuccessfully.\n\t        Will render the final PR description without the loading gif.\n\t        Parameters\n\t        ----------\n\t        success: bool\n\t            Whether the PR was successful or not\n\t        \"\"\"\n", "        bodies = self._build_bodies(success=success)\n\t        self._publish_progress(bodies, success=success)\n\t    def publish_comment(self, text: str, issue_number: Optional[int] = None) -> Optional[str]:\n\t        if issue_number is None:\n\t            if self.pr_number is None:\n\t                self.update()\n\t                if self.pr_number is None:\n\t                    raise RuntimeError(\"Error creating pull request\")\n\t            issue_number = self.pr_number\n\t        return self._publish_comment(text, issue_number)\n", "    def _publish_comment(self, text: str, issue_number: int) -> Optional[str]:\n\t        \"\"\"\n\t        Publish a comment to the issue (pull requests are also issues).\n\t        Parameters\n\t        ----------\n\t        text: str\n\t            The text to comment\n\t        issue_number: Optional[int]\n\t            The issue number to comment on. If None, should comment on the PR.\n\t        \"\"\"\n", "        raise NotImplementedError\n\t    def _set_title(self, title: str):\n\t        \"\"\"\n\t        Set the title of the pull request.\n\t        Parameters\n\t        ----------\n\t        title: str\n\t            The title to set\n\t        \"\"\"\n\t        raise NotImplementedError\n", "    def _publish_progress(\n\t        self,\n\t        bodies: list[str],\n\t        success: bool = False,\n\t    ):\n\t        \"\"\"\n\t        Publish the PR to the provider.\n\t        Parameters\n\t        ----------\n\t        title: str\n", "            The title of the PR\n\t        bodies: list[str]\n\t            The bodies of the PR (split into multiple according to `max_comment_length`)\n\t        success: bool\n\t            Whether generation was successful or not\n\t        \"\"\"\n\t        raise NotImplementedError\n\tclass GitHubPublishService(PublishService):\n\t    \"\"\"\n\t    Publishes the PR to GitHub.\n", "    Sets it as draft while it's being updated, and removes the draft status when it's finalized.\n\t    Adds a shield linking to the action logs, a \"Fixes #{issue_number}\" link.\n\t    \"\"\"\n\t    class PRBodySentinel:\n\t        pass\n\t    def __init__(\n\t        self,\n\t        token: str,\n\t        run_id: str,\n\t        owner: str,\n", "        repo_name: str,\n\t        head_branch: str,\n\t        base_branch: str,\n\t        issue: Optional[Issue] = None,\n\t        pull_request_number: Optional[int] = None,\n\t        loading_gif_url: str = \"https://media.giphy.com/media/3oEjI6SIIHBdRxXI40/giphy.gif\",\n\t        overwrite_existing: bool = False,\n\t    ):\n\t        super().__init__(\n\t            owner=owner,\n", "            repo_name=repo_name,\n\t            head_branch=head_branch,\n\t            base_branch=base_branch,\n\t            issue=issue,\n\t            pull_request_number=pull_request_number,\n\t            loading_gif_url=loading_gif_url,\n\t            overwrite_existing=overwrite_existing,\n\t        )\n\t        self.token = token\n\t        self.run_id = run_id\n", "        self.pr_node_id: Optional[str] = None\n\t        self._drafts_supported = True\n\t        # list of comment IDs, incl. PRBodySentinel to denote the body of the PR\n\t        self._comment_ids: list[Union[str, Type[GitHubPublishService.PRBodySentinel]]] = []\n\t        self.max_char_length = 65536\n\t        self.error_report_template = \"\"\"\n\t{shield}\n\tAutoPR encountered an error.  \n\tIssue: {issue_link}  \n\tPull Request: {pr_link}\n", "\"\"\" + self.error_report_template\n\t    def _log_failed_request(\n\t        self,\n\t        reason: str,\n\t        response: requests.Response,\n\t        request_url: str,\n\t        request_headers: Optional[dict[str, Any]] = None,\n\t        request_params: Optional[dict[str, Any]] = None,\n\t        request_body: Optional[dict[str, Any]] = None,\n\t    ):\n", "        try:\n\t            text = response.json()\n\t        except json.JSONDecodeError:\n\t            text = response.text\n\t        self.log.error(\n\t            reason,\n\t            request_url=request_url,\n\t            request_headers=request_headers,\n\t            request_params=request_params,\n\t            request_body=request_body,\n", "            response_text=text,\n\t            response_code=response.status_code,\n\t            response_headers=response.headers,\n\t        )\n\t    def _get_headers(self):\n\t        return {\n\t            'Authorization': f'Bearer {self.token}',\n\t            'Accept': 'application/vnd.github+json',\n\t            'X-GitHub-Api-Version': '2022-11-28',\n\t        }\n", "    def _get_shield(self, success: Optional[bool] = None):\n\t        action_url = f'https://github.com/{self.owner}/{self.repo_name}/actions/runs/{self.run_id}'\n\t        if success is None:\n\t            shield = f\"[![AutoPR Running](https://img.shields.io/badge/AutoPR-running-yellow)]({action_url})\"\n\t        elif success:\n\t            shield = f\"[![AutoPR Success](https://img.shields.io/badge/AutoPR-success-brightgreen)]({action_url})\"\n\t        else:\n\t            shield = f\"[![AutoPR Failure](https://img.shields.io/badge/AutoPR-failure-red)]({action_url})\"\n\t        return shield\n\t    def _build_issue_template_link(self, **kwargs):\n", "        shield = self._get_shield(success=False)\n\t        kwargs['shield'] = shield\n\t        if self.issue is not None:\n\t            kwargs['issue_link'] = f\"https://github.com/{self.owner}/{self.repo_name}/issues/{self.issue.number}\"\n\t        else:\n\t            kwargs['issue_link'] = \"None\"\n\t        if self.pr_number is not None:\n\t            kwargs['pr_link'] = f\"https://github.com/{self.owner}/{self.repo_name}/pull/{self.pr_number}\"\n\t        else:\n\t            kwargs['pr_link'] = \"None\"\n", "        return super()._build_issue_template_link(**kwargs)\n\t    def _build_bodies(self, success: Optional[bool] = None):\n\t        bodies = super()._build_bodies(success=success)\n\t        # Make shield\n\t        shield = self._get_shield(success=success)\n\t        bodies[0] = shield + '\\n\\n' + bodies[0]\n\t        return bodies\n\t    def _set_title(self, title: str):\n\t        self._update_pr_title(self.pr_number, title)\n\t    def _publish_progress(self, bodies: list[str], success: bool = False):\n", "        # If overwrite existing, find the PR number\n\t        if not self.pr_number and self.overwrite_existing:\n\t            pr = self._find_existing_pr()\n\t            if pr is not None:\n\t                self.pr_number = pr['number']\n\t                self.pr_node_id = pr['node_id']\n\t        # If PR does not exist yet, create it\n\t        if not self.pr_number:\n\t            pr = self._create_pr(self.title, bodies, success)\n\t            if pr is None:\n", "                raise RuntimeError(\"Failed to create PR\")\n\t            self.pr_number = pr['number']\n\t            self.pr_node_id = pr['node_id']\n\t            return\n\t        # Update the comments\n\t        for i, body in enumerate(bodies):\n\t            if i >= len(self._comment_ids):\n\t                comment_id = self.publish_comment(body, self.pr_number)\n\t                if comment_id is None:\n\t                    raise RuntimeError(\"Failed to publish progress comment\")\n", "                self._comment_ids.append(comment_id)\n\t                continue\n\t            comment_id = self._comment_ids[i]\n\t            if comment_id is self.PRBodySentinel:\n\t                self._update_pr_body(self.pr_number, body)\n\t            else:\n\t                self._update_pr_comment(str(comment_id), body)\n\t        # Update draft status\n\t        if self._drafts_supported:\n\t            if self.pr_node_id is None:\n", "                self.pr_node_id = self._get_pull_request_node_id(self.pr_number)\n\t            self._set_pr_draft_status(self.pr_node_id, not success)\n\t    def _find_existing_pr(self) -> Optional[dict[str, Any]]:\n\t        \"\"\"\n\t        Returns the PR dict of the first open pull request with the same head and base branches\n\t        \"\"\"\n\t        url = f'https://api.github.com/repos/{self.owner}/{self.repo_name}/pulls'\n\t        headers = self._get_headers()\n\t        params = {'state': 'open', 'head': f'{self.owner}:{self.head_branch}', 'base': self.base_branch}\n\t        response = requests.get(url, headers=headers, params=params)\n", "        if response.status_code == 200:\n\t            prs = response.json()\n\t            if prs:\n\t                return prs[0]  # Return the first pull request found\n\t        self._log_failed_request(\n\t            'Failed to get pull requests',\n\t            request_url=url,\n\t            request_headers=headers,\n\t            request_params=params,\n\t            response=response,\n", "        )\n\t        return None\n\t    def _create_pr(self, title: str, bodies: list[str], success: bool) -> dict[str, Any]:\n\t        url = f'https://api.github.com/repos/{self.owner}/{self.repo_name}/pulls'\n\t        headers = self._get_headers()\n\t        data = {\n\t            'head': self.head_branch,\n\t            'base': self.base_branch,\n\t            'title': title,\n\t            'body': bodies[0],\n", "        }\n\t        if self._drafts_supported:\n\t            data['draft'] = \"true\" if not success else \"false\"\n\t        response = requests.post(url, json=data, headers=headers)\n\t        if response.status_code != 201:\n\t            # if draft pull request is not supported\n\t            if self._is_draft_error(response.text):\n\t                del data['draft']\n\t                response = requests.post(url, json=data, headers=headers)\n\t                if response.status_code != 201:\n", "                    self._log_failed_request(\n\t                        'Failed to create pull request',\n\t                        request_url=url,\n\t                        request_headers=headers,\n\t                        request_body=data,\n\t                        response=response,\n\t                    )\n\t                    raise RuntimeError('Failed to create pull request')\n\t            else:\n\t                self._log_failed_request(\n", "                    'Failed to create pull request',\n\t                    request_url=url,\n\t                    request_headers=headers,\n\t                    request_body=data,\n\t                    response=response,\n\t                )\n\t                raise RuntimeError('Failed to create pull request')\n\t        self.log.debug('Pull request created successfully',\n\t                       headers=response.headers)\n\t        pr = response.json()\n", "        pr_number = pr['number']\n\t        self._comment_ids = [self.PRBodySentinel]\n\t        # Add additional bodies as comments\n\t        for body in bodies[1:]:\n\t            id_ = self.publish_comment(body, pr_number)\n\t            if id_ is None:\n\t                raise RuntimeError(\"Failed to publish progress comment\")\n\t            self._comment_ids.append(id_)\n\t        return pr\n\t    def _patch_pr(self, pr_number: int, data: dict[str, Any]):\n", "        url = f'https://api.github.com/repos/{self.owner}/{self.repo_name}/pulls/{pr_number}'\n\t        headers = self._get_headers()\n\t        response = requests.patch(url, json=data, headers=headers)\n\t        if response.status_code == 200:\n\t            self.log.debug('Pull request updated successfully')\n\t            return\n\t        self._log_failed_request(\n\t            'Failed to update pull request',\n\t            request_url=url,\n\t            request_headers=headers,\n", "            request_body=data,\n\t            response=response,\n\t        )\n\t    def _is_draft_error(self, response_text: str):\n\t        response_obj = json.loads(response_text)\n\t        is_draft_error = 'message' in response_obj and \\\n\t            'draft pull requests are not supported' in response_obj['message'].lower()\n\t        if is_draft_error:\n\t            self.log.warning(\"Pull request drafts error on this repo\")\n\t            self._drafts_supported = False\n", "        return is_draft_error\n\t    def _get_pull_request_node_id(self, pr_number: str) -> str:\n\t        url = f'https://api.github.com/repos/{self.owner}/{self.repo_name}/pulls/{pr_number}'\n\t        headers = self._get_headers()\n\t        response = requests.get(url, headers=headers)\n\t        if response.status_code == 200:\n\t            return response.json()['node_id']\n\t        self._log_failed_request(\n\t            'Failed to get pull request node id',\n\t            request_url=url,\n", "            request_headers=headers,\n\t            response=response,\n\t        )\n\t        raise RuntimeError('Failed to get pull request node id')\n\t    def _set_pr_draft_status(self, pr_node_id: str, is_draft: bool):\n\t        # sadly this is only supported by graphQL\n\t        if is_draft:\n\t            graphql_query = '''\n\t                mutation ConvertPullRequestToDraft($pullRequestId: ID!) {\n\t                  convertPullRequestToDraft(input: { pullRequestId: $pullRequestId }) {\n", "                    clientMutationId\n\t                  }\n\t                }\n\t            '''\n\t        else:\n\t            graphql_query = '''\n\t                mutation MarkPullRequestReadyForReview($pullRequestId: ID!) {\n\t                  markPullRequestReadyForReview(input: { pullRequestId: $pullRequestId }) {\n\t                    clientMutationId\n\t                  }\n", "                }\n\t            '''\n\t        headers = self._get_headers() | {\n\t            'Content-Type': 'application/json'\n\t        }\n\t        # Undraft the pull request\n\t        data = {'pullRequestId': pr_node_id}\n\t        url = 'https://api.github.com/graphql'\n\t        body = {'query': graphql_query, 'variables': data}\n\t        response = requests.post(\n", "            url,\n\t            headers=headers,\n\t            json=body,\n\t        )\n\t        if response.status_code == 200:\n\t            self.log.debug('Pull request draft status updated successfully')\n\t            return\n\t        self._log_failed_request(\n\t            'Failed to update pull request draft status',\n\t            request_url=url,\n", "            request_headers=headers,\n\t            request_body=body,\n\t            response=response,\n\t        )\n\t        self._drafts_supported = False\n\t    def _update_pr_body(self, pr_number: int, body: str):\n\t        self._patch_pr(pr_number, {'body': body})\n\t    def _update_pr_title(self, pr_number: int, title: str):\n\t        self._patch_pr(pr_number, {'title': title})\n\t    def _update_pr_comment(self, comment_id: str, body: str):\n", "        url = f'https://api.github.com/repos/{self.owner}/{self.repo_name}/issues/comments/{comment_id}'\n\t        headers = self._get_headers()\n\t        response = requests.patch(url, json={'body': body}, headers=headers)\n\t        if response.status_code == 200:\n\t            self.log.debug('Comment updated successfully')\n\t            return\n\t        self._log_failed_request(\n\t            'Failed to update comment',\n\t            request_url=url,\n\t            request_headers=headers,\n", "            request_body={'body': body},\n\t            response=response,\n\t        )\n\t    def _publish_comment(self, text: str, issue_number: int) -> Optional[str]:\n\t        url = f'https://api.github.com/repos/{self.owner}/{self.repo_name}/issues/{issue_number}/comments'\n\t        headers = self._get_headers()\n\t        data = {\n\t            'body': text,\n\t        }\n\t        response = requests.post(url, json=data, headers=headers)\n", "        if response.status_code == 201:\n\t            self.log.debug('Commented on issue successfully')\n\t            return response.json()['id']\n\t        self._log_failed_request(\n\t            'Failed to comment on issue',\n\t            request_url=url,\n\t            request_headers=headers,\n\t            request_body=data,\n\t            response=response,\n\t        )\n", "        return None\n\tclass DummyPublishService(PublishService):\n\t    def __init__(self):\n\t        super().__init__(\n\t            owner='',\n\t            repo_name='',\n\t            head_branch='',\n\t            base_branch='',\n\t        )\n\t    def _publish_progress(self, body: str, success: bool = False):\n", "        pass\n\t    def _set_title(self, title: str):\n\t        pass\n\t    def _publish_comment(self, text: str, issue_number: int) -> Optional[str]:\n\t        pass\n"]}
{"filename": "autopr/services/diff_service.py", "chunked_list": ["import tempfile\n\tfrom typing import Optional\n\timport structlog\n\tfrom git.repo import Repo\n\tfrom autopr.models.artifacts import DiffStr\n\tlog = structlog.get_logger()\n\tclass DiffService:\n\t    \"\"\"\n\t    Service for getting and applying diffs.\n\t    Diffs are represented as `DiffStr` (a type alias for `str`).\n", "    \"\"\"\n\t    def __init__(\n\t        self,\n\t        repo: Repo,\n\t    ):\n\t        self.repo = repo\n\t    def apply_diff(self, diff: DiffStr, check: bool = False) -> None:\n\t        raise NotImplementedError()\n\t    def get_diff(self, filepaths: Optional[list[str]] = None) -> DiffStr:\n\t        if not filepaths:\n", "            # Add all files in repo\n\t            self.repo.git.execute([\"git\", \"add\", \"-A\"])\n\t        else:\n\t            # Add specific files\n\t            self.repo.git.execute([\"git\", \"add\", *filepaths])\n\t        # Get diff\n\t        diff = self.repo.git.execute([\"git\", \"diff\", \"--staged\"])\n\t        # Reset staged files\n\t        self.repo.git.execute([\"git\", \"reset\", \"HEAD\"])\n\t        return DiffStr(diff)\n", "class GitApplyService(DiffService):\n\t    def apply_diff(self, diff: DiffStr, check: bool = False) -> None:\n\t        with tempfile.NamedTemporaryFile() as f:\n\t            f.write(diff.encode())\n\t            f.flush()\n\t            log.debug('Applying diff...')\n\t            self.repo.git.execute([\"git\",\n\t                                   \"apply\",\n\t                                   \"--allow-empty\",\n\t                                   f.name])\n", "class PatchService(DiffService):\n\t    def apply_diff(self, diff: DiffStr, check: bool = False) -> None:\n\t        with tempfile.NamedTemporaryFile(suffix=\".diff\") as f:\n\t            f.write(diff.encode())\n\t            f.flush()\n\t            log.debug('Applying diff...')\n\t            commands = [\n\t                \"patch\",\n\t                \"--no-backup-if-mismatch\",\n\t                \"--ignore-whitespace\",\n", "                \"-p0\",\n\t                \"--force\",\n\t                \"-i\",\n\t                f.name\n\t            ]\n\t            if check:\n\t                commands += [\"--dry-run\"]\n\t            self.repo.git.execute(commands)\n"]}
{"filename": "autopr/services/chain_service.py", "chunked_list": ["import logging\n\tfrom typing import Any, Union, Optional, Callable\n\timport openai.error\n\timport pydantic\n\timport structlog\n\tfrom tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n\tfrom autopr.services.publish_service import PublishService\n\tfrom langchain.llms.base import BaseLLM\n\tfrom langchain.chat_models.base import BaseChatModel\n\tfrom langchain.schema import BaseOutputParser, PromptValue\n", "from autopr.models.prompt_chains import PromptChain\n\tfrom autopr.repos.completions_repo import CompletionsRepo\n\tfrom langchain import PromptTemplate, OpenAI\n\tfrom langchain.chat_models import ChatOpenAI as LangChainChatOpenAI\n\tfrom langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n\tclass ChatOpenAI(LangChainChatOpenAI):\n\t    request_timeout = 240\n\t    def _create_retry_decorator(self) -> Callable[[Any], Any]:\n\t        # override langchain's retry decorator to wait up to 240 seconds instead of 10\n\t        min_seconds = 1\n", "        max_seconds = 240\n\t        return retry(\n\t            reraise=True,\n\t            stop=stop_after_attempt(self.max_retries),\n\t            wait=wait_exponential(multiplier=1, min=min_seconds, max=max_seconds),\n\t            retry=(\n\t                retry_if_exception_type(openai.error.Timeout)\n\t                | retry_if_exception_type(openai.error.APIError)\n\t                | retry_if_exception_type(openai.error.APIConnectionError)\n\t                | retry_if_exception_type(openai.error.RateLimitError)\n", "                | retry_if_exception_type(openai.error.ServiceUnavailableError)\n\t            ),\n\t        )\n\tclass ChainService:\n\t    \"\"\"\n\t    Service that handles running langchain completions according to a PromptChain subclass.\n\t    This service is responsible for:\n\t    - compiling the prompt according to `PromptChain.prompt_template` and `PromptChain.get_string_params()`\n\t    - running the prompt through langchain\n\t    - parsing the output according to `PromptChain.output_parser`\n", "    - Keeping `publish_service` informed of what's going on\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        completions_repo: CompletionsRepo,\n\t        publish_service: PublishService,\n\t        context_limit: int = 8192,\n\t        min_tokens: int = 2000,\n\t    ):\n\t        self.completions_repo = completions_repo\n", "        self.publish_service = publish_service\n\t        self.context_limit = context_limit\n\t        self.min_tokens = min_tokens\n\t        # TODO find a better way to integrate completions repo with langchain\n\t        #   can we make a BaseLanguageModel that takes a completions repo?\n\t        #   or should we replace completions repo with BaseLanguageModel?\n\t        self.model: Union[BaseChatModel, BaseLLM]\n\t        if completions_repo.model in [\n\t            \"gpt-4\",\n\t            \"gpt-3.5-turbo\"\n", "        ]:\n\t            self.model = ChatOpenAI(\n\t                model_name=completions_repo.model,\n\t                temperature=completions_repo.temperature,\n\t                max_tokens=completions_repo.max_tokens,\n\t            )  # type: ignore\n\t        elif completions_repo.model == \"text-davinci-003\":\n\t            self.model = OpenAI(\n\t                model_name=completions_repo.model,\n\t                temperature=completions_repo.temperature,\n", "                max_tokens=completions_repo.max_tokens,\n\t            )  # type: ignore\n\t        else:\n\t            raise ValueError(f\"Unsupported model {completions_repo.model}\")\n\t        self.log = structlog.get_logger().bind(\n\t            model=completions_repo.model,\n\t            service=\"ChainService\",\n\t        )\n\t    def _get_model_template(\n\t        self,\n", "        chain: PromptChain,\n\t        parser: Optional[BaseOutputParser],\n\t    ) -> PromptValue:\n\t        variables = dict(chain.get_string_params())\n\t        variable_names = list(variables.keys())\n\t        partial_variables = {}\n\t        if parser is not None:\n\t            partial_variables[\"format_instructions\"] = parser.get_format_instructions()\n\t        if isinstance(self.model, BaseChatModel):\n\t            template = ChatPromptTemplate(\n", "                messages=[\n\t                    HumanMessagePromptTemplate.from_template(chain.prompt_template)\n\t                ],\n\t                input_variables=variable_names,\n\t                partial_variables=partial_variables,\n\t            )\n\t        else:\n\t            template = PromptTemplate(\n\t                template=chain.prompt_template,\n\t                input_variables=variable_names,\n", "                partial_variables=partial_variables,\n\t            )\n\t        return template.format_prompt(**variables)\n\t    def _run_model(self, template: PromptValue) -> Any:\n\t        if isinstance(self.model, BaseChatModel):\n\t            return self.model(template.to_messages()).content\n\t        else:\n\t            return self.model(template.to_string())\n\t    def run_chain(self, chain: PromptChain) -> Any:\n\t        self.publish_service.start_section(f\"⛓ Running {chain.__class__.__name__} chain\")\n", "        # Make sure the prompt is not too long\n\t        max_length = self.context_limit - self.min_tokens\n\t        success = chain.ensure_token_length(max_length)\n\t        if not success:\n\t            return None\n\t        if chain.output_parser:\n\t            parser = chain.output_parser\n\t        else:\n\t            parser = None\n\t        prompt_value = self._get_model_template(chain, parser)\n", "        str_prompt = prompt_value.to_string()\n\t        self.publish_service.publish_code_block(\n\t            heading=\"Prompt\",\n\t            code=str_prompt,\n\t        )\n\t        self.log.info(\"Running chain\", prompt=str_prompt)\n\t        raw_output = self._run_model(prompt_value)\n\t        self.publish_service.publish_code_block(\n\t            heading=\"Output\",\n\t            code=raw_output,\n", "        )\n\t        self.log.info(\"Got result\", raw_output=raw_output)\n\t        if parser is not None:\n\t            output = parser.parse(raw_output)\n\t            self.log.info(\"Parsed output\", result=output)\n\t            if output is None:\n\t                self.publish_service.end_section(f\"❌ Chain {chain.__class__.__name__} failed to parse result\")\n\t                return None\n\t            else:\n\t                self.publish_service.publish_code_block(\n", "                    heading=\"Parsed output\",\n\t                    code=output.json(indent=2) if isinstance(output, pydantic.BaseModel) else str(output),\n\t                )\n\t        else:\n\t            output = raw_output\n\t        self.publish_service.end_section(f\"⛓ {chain.__class__.__name__} completed\")\n\t        return output\n"]}
{"filename": "autopr/services/rail_service.py", "chunked_list": ["import pkg_resources\n\timport lxml.etree as ET\n\timport json\n\timport traceback\n\tfrom typing import Callable, Any, Optional, TypeVar, Type\n\timport pydantic\n\timport guardrails as gr\n\tfrom autopr.models.rail_objects import RailObject\n\tfrom autopr.models.prompt_rails import PromptRail\n\timport structlog\n", "from autopr.repos.completions_repo import CompletionsRepo\n\tfrom autopr.services.publish_service import PublishService\n\tfrom guardrails.utils.constants import constants\n\tlog = structlog.get_logger()\n\tRailObjectSubclass = TypeVar('RailObjectSubclass', bound=RailObject)\n\tBaseModelSubclass = TypeVar('BaseModelSubclass', bound=pydantic.BaseModel)\n\tclass RailService:\n\t    \"\"\"\n\t    Service for invoking guardrails according to PromptRail and RailObject subclasses.\n\t    See PromptRail, RailObject, and [Guardrails docs](https://shreyar.github.io/guardrails/rail/) for more information.\n", "    To make a guardrails call:\n\t    - define a RailObject subclass\n\t    - define a PromptRail subclass\n\t    - instantiate the PromptRail\n\t    - call `rail_service.run_prompt_rail(rail)` with the instantiated PromptRail\n\t    For example:\n\t        class Colors(RailObject):\n\t            output_spec = '<list name=\"colors\"><string/></list>'\n\t            colors: list[str]\n\t        class MyPromptRail(PromptRail):\n", "            output_type = Colors\n\t            prompt_template = \"What colors is {something}?\"\n\t            something: str\n\t        rail = MyPromptRail(something=\"a zebra\")\n\t        colors = rail_service.run_prompt_rail(rail)\n\t        print(colors)  # colors=['black', 'white']\n\t    This service is responsible for:\n\t    - Compiling prompts according to `PromptRail.prompt_template`, `RailObject.output_spec`,\n\t      and `RailObject.get_rail_spec()`\n\t    - Invoking a guardrail LLM calls,\n", "      optionally after an ordinary LLM call if `PromptRail.two_step` is True\n\t    - Parsing the guardrail LLM response into a RailObject (pydantic) instance\n\t    - Publishing the RailObject instance to the publish service\n\t    - Keeping `publish_service` informed of what's going on\n\t    Parameters\n\t    ----------\n\t    min_tokens: int\n\t        Minimum number of tokens to leave in the context window to allow for response\n\t    context_limit: int\n\t        Context window token size limit\n", "    num_reasks: int\n\t        Number of times to re-ask the guardrail if it fails\n\t    temperature: float\n\t        Temperature to use for guardrails calls\n\t    raw_system_prompt: str\n\t        System prompt to use for ordinary LLM calls (if `PromptRail.two_step` is True)\n\t    \"\"\"\n\t    _constants_imported = False\n\t    def __init__(\n\t        self,\n", "        completions_repo: CompletionsRepo,\n\t        publish_service: PublishService,\n\t        min_tokens: int = 1000,\n\t        context_limit: int = 8192,\n\t        num_reasks: int = 2,\n\t        temperature: float = 0.8,\n\t        raw_system_prompt: str = 'You are a software developer and git nerd, a helpful planning and coding assistant.',\n\t    ):\n\t        self.completions_repo = completions_repo\n\t        self.publish_service = publish_service\n", "        self.min_tokens = min_tokens\n\t        self.context_limit = context_limit\n\t        self.num_reasks = num_reasks\n\t        self.temperature = temperature\n\t        self.raw_system_prompt = raw_system_prompt\n\t        self._import_constants()\n\t    def _import_constants(self):\n\t        if self._constants_imported:\n\t            return\n\t        constants_file = pkg_resources.resource_filename('autopr', 'constants.xml')\n", "        with open(constants_file, \"r\") as f:\n\t            xml = f.read()\n\t        parser = ET.XMLParser(encoding=\"utf-8\")\n\t        parsed_constants = ET.fromstring(xml, parser=parser)\n\t        for child in parsed_constants:\n\t            if isinstance(child, ET._Comment):\n\t                continue\n\t            if isinstance(child, str):\n\t                continue\n\t            constant_name = child.tag\n", "            constant_value = child.text\n\t            constants[constant_name] = constant_value\n\t        self._constants_imported = True\n\t    def run_rail_string(\n\t        self,\n\t        rail_spec: str,\n\t        prompt_params: dict[str, Any],\n\t        heading: str = \"\",\n\t    ) -> Optional[dict[str, Any]]:\n\t        \"\"\"\n", "        Run a guardrails call with the given rail spec and prompt parameters.\n\t        \"\"\"\n\t        title_heading = heading[0].upper() + heading[1:]\n\t        self.publish_service.start_section(f\"🛤 Running {heading} rail\")\n\t        instructions = self.get_rail_instructions(rail_spec, prompt_params)\n\t        if instructions.strip():\n\t            self.publish_service.publish_code_block(\n\t                heading='Instructions',\n\t                code=instructions,\n\t                language='xml',  # xml for nice guardrails highlighting\n", "            )\n\t        str_prompt = self.get_rail_message(rail_spec, prompt_params)\n\t        self.publish_service.publish_code_block(\n\t            heading='Prompt',\n\t            code=str_prompt,\n\t            language='xml',  # xml for nice guardrails highlighting\n\t        )\n\t        def completion_func(prompt: str, instructions: str):\n\t            return self.completions_repo.complete(\n\t                prompt=prompt,\n", "                system_prompt=instructions,\n\t                temperature=self.temperature,\n\t            )\n\t        try:\n\t            pr_guard = gr.Guard.from_rail_string(\n\t                rail_spec,  # make sure to import custom validators before this\n\t                num_reasks=self.num_reasks,\n\t            )\n\t            log.debug(\n\t                'Running rail',\n", "                rail_spec=rail_spec,\n\t                prompt_params=prompt_params,\n\t            )\n\t            # Invoke guardrails\n\t            raw_o, dict_o = pr_guard(\n\t                completion_func,\n\t                prompt_params=prompt_params\n\t            )\n\t        except Exception:\n\t            log.exception('Error running rail',\n", "                          prompt=str_prompt)\n\t            self.publish_service.publish_code_block(\n\t                heading='Error',\n\t                code=traceback.format_exc(),\n\t                language='python',\n\t            )\n\t            self.publish_service.end_section(f\"💥 {title_heading} derailed (guardrails error)\")\n\t            return None\n\t        log.debug('Ran rail',\n\t                  raw_output=raw_o,\n", "                  dict_output=dict_o)\n\t        self.publish_service.publish_code_block(\n\t            heading='Raw output',\n\t            code=raw_o,\n\t            language='json',\n\t        )\n\t        if dict_o is None:\n\t            log.warning(f'Got None from rail',\n\t                        rail_spec=rail_spec,\n\t                        prompt_params=prompt_params)\n", "            self.publish_service.end_section(f\"💥 {title_heading} derailed (guardrails returned None)\")\n\t            return None\n\t        self.publish_service.publish_code_block(\n\t            heading='Parsed output',\n\t            code=json.dumps(dict_o, indent=2),\n\t            language='json',\n\t        )\n\t        self.publish_service.end_section(f\"🛤 Ran {heading} rail\")\n\t        return dict_o\n\t    def run_rail_model(\n", "        self,\n\t        model: Type[BaseModelSubclass],\n\t        rail_spec: str,\n\t        prompt_params: dict[str, Any]\n\t    ) -> Optional[BaseModelSubclass]:\n\t        \"\"\"\n\t        Run a guardrails call with a pydantic model to parse the response into.\n\t        \"\"\"\n\t        self.publish_service.start_section(f\"🛤 Running {model.__name__} on rail\")\n\t        def completion_func(prompt: str, instructions: str):\n", "            return self.completions_repo.complete(\n\t                prompt=prompt,\n\t                system_prompt=instructions,\n\t                temperature=self.temperature,\n\t            )\n\t        pr_guard = gr.Guard.from_rail_string(\n\t            rail_spec,  # make sure to import custom validators before this\n\t            num_reasks=self.num_reasks,\n\t        )\n\t        prompt = self.get_rail_message(rail_spec, prompt_params)\n", "        log.debug('Running rail',\n\t                  rail_model=model.__name__,\n\t                  rail_message=prompt)\n\t        self.publish_service.publish_code_block(\n\t            heading='Prompt',\n\t            code=prompt,\n\t            language='xml',  # xml for nice guardrails highlighting\n\t        )\n\t        # Invoke guardrails\n\t        try:\n", "            raw_o, dict_o = pr_guard(\n\t                completion_func,\n\t                prompt_params=prompt_params,\n\t            )\n\t        except Exception:\n\t            self.publish_service.publish_code_block(\n\t                heading='Error',\n\t                code=traceback.format_exc(),\n\t                language='python',\n\t                default_open=True,\n", "            )\n\t            self.publish_service.end_section(f\"💥 {model.__name__} derailed (guardrails error)\")\n\t            log.exception(f'Guardrails threw an exception',\n\t                          rail_model=model.__name__,\n\t                          rail_message=prompt)\n\t            return None\n\t        log.debug('Ran rail',\n\t                  rail_model=model.__name__,\n\t                  raw_output=raw_o,\n\t                  dict_output=dict_o)\n", "        self.publish_service.publish_code_block(\n\t            heading='Raw output',\n\t            code=raw_o,\n\t            language='json',\n\t        )\n\t        if dict_o is None:\n\t            self.publish_service.end_section(f\"💥 {model.__name__} derailed (guardrails returned None)\")\n\t            log.warning(f'Got None from rail',\n\t                        rail_model=model.__name__,\n\t                        raw_output=raw_o)\n", "            return None\n\t        self.publish_service.publish_code_block(\n\t            heading='Parsed output',\n\t            code=json.dumps(dict_o, indent=2),\n\t            language='json',\n\t        )\n\t        # Parse the output into a pydantic object\n\t        try:\n\t            parsed_obj = model.parse_obj(dict_o)\n\t            self.publish_service.publish_code_block(\n", "                heading='Validated output',\n\t                code=parsed_obj.json(indent=2),\n\t                language='json',\n\t            )\n\t            self.publish_service.end_section(f\"🛤 Ran {model.__name__} on rail\")\n\t            return parsed_obj\n\t        except pydantic.ValidationError:\n\t            log.warning(f'Got invalid output from rail',\n\t                        rail_object=model.__name__,\n\t                        raw_output=raw_o,\n", "                        dict_output=dict_o)\n\t            self.publish_service.publish_code_block(\n\t                heading='Error',\n\t                code=traceback.format_exc(),\n\t                language='python',\n\t                default_open=True,\n\t            )\n\t            self.publish_service.end_section(f\"💥 {model.__name__} derailed (validation error)\")\n\t            return None\n\t    def run_rail_object(\n", "        self,\n\t        rail_object: Type[RailObjectSubclass],\n\t        raw_document: str\n\t    ) -> Optional[RailObjectSubclass]:\n\t        \"\"\"\n\t        Transforms the `raw_document` into a pydantic instance described by `rail_object`.\n\t        \"\"\"\n\t        rail_spec = rail_object.get_rail_spec()\n\t        return self.run_rail_model(\n\t            model=rail_object,\n", "            rail_spec=rail_spec,\n\t            prompt_params={\n\t                'raw_document': raw_document,\n\t            },\n\t        )\n\t    def run_prompt_rail(\n\t        self,\n\t        rail: PromptRail\n\t    ) -> Optional[RailObject]:\n\t        \"\"\"\n", "        Runs a PromptRail, asking the LLM a question and parsing the response into `PromptRail.output_type`.\n\t        :param rail:\n\t        :return:\n\t        \"\"\"\n\t        # Make sure the prompt is not too long\n\t        max_length = self.context_limit - self.min_tokens\n\t        success = rail.ensure_token_length(max_length)\n\t        if not success:\n\t            return None\n\t        # Run the rail\n", "        prompt = rail.get_prompt_message()\n\t        if rail.two_step:\n\t            initial_prompt = prompt\n\t            self.publish_service.start_section(f\"💬 Asking for {rail.__class__.__name__}\")\n\t            self.publish_service.publish_code_block(\n\t                heading=\"Prompt\",\n\t                code=prompt,\n\t                language=\"\",\n\t            )\n\t            prompt = self.completions_repo.complete(\n", "                prompt=initial_prompt,\n\t                system_prompt=self.raw_system_prompt,\n\t            )\n\t            self.publish_service.publish_code_block(\n\t                heading=\"Response\",\n\t                code=prompt,\n\t                language=\"\",\n\t            )\n\t            self.publish_service.end_section(f\"💬 Asked for {rail.__class__.__name__}\")\n\t        return self.run_rail_object(rail.output_type, prompt)\n", "    @staticmethod\n\t    def get_rail_instructions(\n\t        rail_spec: str,\n\t        prompt_params: dict[str, Any]\n\t    ) -> str:\n\t        pr_guard = gr.Guard.from_rail_string(rail_spec)\n\t        return str(pr_guard.instructions.format(**prompt_params))\n\t    @staticmethod\n\t    def get_rail_message(\n\t        rail_spec: str,\n", "        prompt_params: dict[str, Any]\n\t    ) -> str:\n\t        pr_guard = gr.Guard.from_rail_string(rail_spec)\n\t        return str(pr_guard.prompt.format(**prompt_params))\n"]}
{"filename": "autopr/services/commit_service.py", "chunked_list": ["import os\n\tfrom git.repo import Repo\n\timport structlog\n\tclass CommitService:\n\t    \"\"\"\n\t    Service for creating branches, committing changes, and calling `git push` on the repository.\n\t    Ensures there is always a commit on the branch.\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n", "        repo: Repo,\n\t        repo_path: str,\n\t        branch_name: str,\n\t        base_branch_name: str,\n\t    ):\n\t        self.repo = repo\n\t        self.repo_path = repo_path\n\t        self.branch_name = branch_name\n\t        self.base_branch_name = base_branch_name\n\t        self._empty_commit_message = \"[placeholder]\"\n", "        self.log = structlog.get_logger(service=\"commit\")\n\t    def overwrite_new_branch(self):\n\t        # Checkout and pull base branch\n\t        self.log.debug(f'Checking out {self.base_branch_name}...')\n\t        self.repo.heads[self.base_branch_name].checkout()\n\t        self.log.debug('Pulling latest changes...')\n\t        self.repo.remotes.origin.pull()\n\t        # If branch already exists, delete it\n\t        if self.branch_name in self.repo.heads:\n\t            self.log.debug(f'Deleting existing branch {self.branch_name}...')\n", "            self.repo.delete_head(self.branch_name, force=True)\n\t        # Create new branch with create_new_ref\n\t        self.log.debug(f'Creating new branch {self.branch_name}...')\n\t        self.repo.create_head(self.branch_name, self.base_branch_name)\n\t        # Checkout new branch\n\t        self.repo.heads[self.branch_name].checkout()\n\t        # Create empty commit\n\t        self.commit(self._empty_commit_message)\n\t    def ensure_branch_exists(self):\n\t        # Fetch\n", "        self.log.debug('Fetching...')\n\t        self.repo.remotes.origin.fetch()\n\t        remote = self.repo.remote()\n\t        references = remote.fetch()\n\t        # If branch already exists, checkout and pull\n\t        if f'{remote.name}/{self.branch_name}' in [ref.name for ref in references]:\n\t            # Check if branch exists locally\n\t            if self.branch_name in [ref.name for ref in self.repo.heads]:\n\t                self.log.debug(f'Checking out {self.branch_name}...')\n\t                self.repo.heads[self.branch_name].checkout()\n", "                self.log.debug('Pulling latest changes...')\n\t                self.repo.remotes.origin.pull()\n\t            else:\n\t                # If not, create a local branch that tracks the remote branch\n\t                self.log.debug(f'Checking out -b {self.branch_name}...')\n\t                self.repo.create_head(self.branch_name, f'{remote.name}/{self.branch_name}').checkout()\n\t        else:\n\t            self.log.debug(f'Branch {self.branch_name} does not exist, creating...')\n\t            self.overwrite_new_branch()\n\t    def commit(self, commit_message: str, push: bool = True) -> None:\n", "        # Remove empty commit if exists\n\t        if commit_message != self._empty_commit_message and \\\n\t                self.repo.head.commit.message.rstrip() == self._empty_commit_message:\n\t            self.log.debug('Removing empty commit...')\n\t            self.repo.git.execute([\"git\", \"reset\", \"HEAD^\"])\n\t        # Remove guardrails log if exists (so it's not committed later)\n\t        if 'guardrails.log' in self.repo.untracked_files:\n\t            self.log.debug('Removing guardrails.log...')\n\t            os.remove(\n\t                os.path.join(self.repo_path, 'guardrails.log')\n", "            )\n\t        # Add and commit all\n\t        self.repo.git.execute([\"git\", \"add\", \".\"])\n\t        self.repo.git.execute([\"git\", \"commit\", \"--allow-empty\", \"-m\", commit_message])\n\t        # Get the commit's diff for log\n\t        diff = self.repo.git.execute([\"git\", \"diff\", \"HEAD^\", \"HEAD\"])\n\t        self.log.info(\"Committed changes\", commit_message=commit_message, diff=diff)\n\t        # Push branch to remote\n\t        if push:\n\t            self.log.debug(f'Pushing branch {self.branch_name} to remote...')\n", "            self.repo.git.execute([\"git\", \"push\", \"-f\", \"origin\", self.branch_name])\n"]}
