{"filename": "src/main.py", "chunked_list": ["import os\n\tfrom dotenv import load_dotenv\n\tfrom agent import Agent\n\tfrom tools.base import AgentTool\n\tfrom ui.cui import CommandlineUserInterface\n\tfrom langchain.utilities import GoogleSearchAPIWrapper\n\tfrom langchain.llms import OpenAI\n\tfrom langchain.chat_models import ChatOpenAI\n\t# Set API Keys\n\tload_dotenv()\n", "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n\tassert OPENAI_API_KEY, \"OPENAI_API_KEY environment variable is missing from .env\"\n\tGOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\", \"\")\n\tassert GOOGLE_CSE_ID, \"GOOGLE_CSE_ID environment variable is missing from .env\"\n\tGOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\")\n\t# Set Agent Settings\n\tAGENT_NAME = os.getenv(\"AGENT_NAME\", \"\")\n\tassert AGENT_NAME, \"AGENT_NAME variable is missing from .env\"\n\tAGENT_ROLE = os.getenv(\"AGENT_ROLE\", \"\")\n\tassert AGENT_ROLE, \"AGENT_ROLE variable is missing from .env\"\n", "AGENT_OBJECTIVE = os.getenv(\"AGENT_OBJECTIVE\", \"\")\n\tassert AGENT_OBJECTIVE, \"AGENT_OBJECTIVE variable is missing from .env\"\n\tAGENT_DIRECTORY = os.getenv(\"AGENT_DIRECTORY\", \"\")\n\tassert AGENT_DIRECTORY, \"AGENT_DIRECTORY variable is missing from .env\"\n\tllm = OpenAI(temperature=0.0)\n\topenaichat = ChatOpenAI(temperature=0.0)  # Optional\n\t### 1.Create Agent ###\n\tdir = AGENT_DIRECTORY\n\tagent = Agent(\n\t    name=AGENT_NAME,\n", "    role=AGENT_ROLE,\n\t    goal=AGENT_OBJECTIVE,\n\t    ui=CommandlineUserInterface(),\n\t    openai_api_key=OPENAI_API_KEY,\n\t    llm=llm,\n\t    openaichat=openaichat,\n\t    dir=dir\n\t)\n\t### 2. Set up tools for agent ###\n\tsearch = GoogleSearchAPIWrapper()\n", "search_tool = AgentTool(\n\t    name=\"google_search\",\n\t    func=search.run,\n\t    description=\"\"\"\n\t        \"With this tool, you can search the web using Google search engine\"\n\t        \"It is a great way to quickly find information on the web.\"\"\",\n\t    user_permission_required=False\n\t)\n\t### 3. Momoize usage of tools to agent ###\n\tagent.prodedural_memory.memorize_tools([search_tool])\n", "### 4.Run agent ###\n\tagent.run()\n"]}
{"filename": "src/agent.py", "chunked_list": ["import os\n\timport json\n\tfrom typing import Dict, Any, Optional, Union\n\tfrom pydantic import BaseModel, Field\n\tfrom memory.procedual_memory import ProcedualMemory\n\tfrom memory.episodic_memory import EpisodicMemory, Episode\n\tfrom memory.semantic_memory import SemanticMemory\n\tfrom ui.base import BaseHumanUserInterface\n\tfrom ui.cui import CommandlineUserInterface\n\timport llm.reason.prompt as ReasonPrompt\n", "from task_manager import Task\n\tfrom task_manager import TaskManeger\n\tfrom llm.json_output_parser import LLMJsonOutputParser\n\tfrom llm.reason.schema import JsonSchema as ReasonSchema\n\tfrom langchain.llms.base import BaseLLM\n\tfrom langchain import LLMChain\n\tfrom langchain.chat_models import ChatOpenAI\n\t# Define the default values\n\tDEFAULT_AGENT_NAME = \"AI\"\n\tDEFAULT_AGENT_ROLE = \"Autonomous AI agent that uses both inference and tools to answer many things\"\n", "DEFAULT_AGENT_GOAL = \"Ending world hunger\"\n\tDEFAULT_AGENT_DIR = \"./agent_data\"\n\t# Define the schema for the llm output\n\tREASON_JSON_SCHEMA_STR = json.dumps(ReasonSchema.schema)\n\tclass Agent(BaseModel):\n\t    \"\"\"\n\t    This is the main class for the Agent. It is responsible for managing the tools and the agent.\n\t    \"\"\"\n\t    # Define the tools\n\t    dir: str = Field(\n", "        DEFAULT_AGENT_DIR, description=\"The folder path to the directory where the agent data is stored and saved\")\n\t    name: str = Field(DEFAULT_AGENT_NAME, description=\"The name of the agent\")\n\t    role: str = Field(DEFAULT_AGENT_ROLE, description=\"The role of the agent\")\n\t    goal: str = Field(DEFAULT_AGENT_GOAL, description=\"The goal of the agent\")\n\t    ui: BaseHumanUserInterface = Field(\n\t        CommandlineUserInterface(), description=\"The user interface for the agent\")\n\t    llm: BaseLLM = Field(..., description=\"llm class for the agent\")\n\t    openaichat: Optional[ChatOpenAI] = Field(\n\t        None, description=\"ChatOpenAI class for the agent\")\n\t    prodedural_memory: ProcedualMemory = Field(\n", "        ProcedualMemory(), description=\"The procedural memory about tools agent uses\")\n\t    episodic_memory: EpisodicMemory = Field(\n\t        None, description=\"The short term memory of the agent\")\n\t    semantic_memory: SemanticMemory = Field(\n\t        None, description=\"The long term memory of the agent\")\n\t    task_manager: TaskManeger = Field(\n\t        None, description=\"The task manager for the agent\")\n\t    def __init__(self, openai_api_key: str, dir: str,  **data: Any) -> None:\n\t        super().__init__(**data)\n\t        self.task_manager = TaskManeger(llm=self.llm)\n", "        self.episodic_memory = EpisodicMemory(llm=self.llm)\n\t        self.semantic_memory = SemanticMemory(llm=self.llm, openaichat=self.openaichat)\n\t        self._get_absolute_path()\n\t        self._create_dir_if_not_exists()\n\t        if self._agent_data_exists():\n\t            load_data = self.ui.get_binary_user_input(\n\t                \"Agent data already exists. Do you want to load the data?\\n\"\n\t                \"If you choose 'Yes', the data will be loaded.\\n\"\n\t                \"If you choose 'No', the data will be overwritten.\"\n\t            )\n", "            if load_data:\n\t                self.load_agent()\n\t            else:\n\t                self.ui.notify(\"INFO\", \"Agent data will be overwritten.\")\n\t        self.ui.notify(\n\t            \"START\", f\"Hello, I am {self.name}. {self.role}. My goal is {self.goal}.\")\n\t    def _get_absolute_path(self) -> None:\n\t        return os.path.abspath(self.dir)\n\t    def _create_dir_if_not_exists(self) -> None:\n\t        absolute_path = self._get_absolute_path()\n", "        if not os.path.exists(absolute_path):\n\t            os.makedirs(absolute_path)\n\t    def _agent_data_exists(self) -> bool:\n\t        absolute_path = self._get_absolute_path()\n\t        return \"agent_data.json\" in os.listdir(absolute_path)\n\t    def run(self):\n\t        with self.ui.loading(\"Generate Task Plan...\"):\n\t            self.task_manager.generate_task_plan(\n\t                name=self.name,\n\t                role=self.role,\n", "                goal=self.goal\n\t            )\n\t        self.ui.notify(title=\"ALL TASKS\",\n\t                       message=self.task_manager.get_incomplete_tasks_string(),\n\t                       title_color=\"BLUE\")\n\t        while True:\n\t            current_task = self.task_manager.get_current_task_string()\n\t            if current_task:\n\t                self.ui.notify(title=\"CURRENT TASK\",\n\t                               message=current_task,\n", "                               title_color=\"BLUE\")\n\t            else:\n\t                self.ui.notify(title=\"FINISH\",\n\t                               message=f\"All tasks are completed. {self.name} will end the operation.\",\n\t                               title_color=\"RED\")\n\t                break\n\t            # ReAct: Reasoning\n\t            with self.ui.loading(\"Thinking...\"):\n\t                try:\n\t                    reasoning_result = self._reason()\n", "                    thoughts = reasoning_result[\"thoughts\"]\n\t                    action = reasoning_result[\"action\"]\n\t                    tool_name = action[\"tool_name\"]\n\t                    args = action[\"args\"]\n\t                except Exception as e:\n\t                    raise e\n\t            self.ui.notify(title=\"TASK\", message=thoughts[\"task\"])\n\t            self.ui.notify(title=\"IDEA\", message=thoughts[\"idea\"])\n\t            self.ui.notify(title=\"REASONING\", message=thoughts[\"reasoning\"])\n\t            self.ui.notify(title=\"CRITICISM\", message=thoughts[\"criticism\"])\n", "            self.ui.notify(title=\"THOUGHT\", message=thoughts[\"summary\"])\n\t            self.ui.notify(title=\"NEXT ACTION\", message=action)\n\t            # Task Complete\n\t            if tool_name == \"task_complete\":\n\t                action_result = args[\"result\"]\n\t                self._task_complete(action_result)\n\t                # save agent data\n\t                with self.ui.loading(\"Save agent data...\"):\n\t                    self.save_agent()\n\t            # Action with tools\n", "            else:\n\t                # Ask for permission to run the action\n\t                user_permission = self.ui.get_binary_user_input(\n\t                    \"Do you want to continue?\")\n\t                if not user_permission:\n\t                    action_result = \"User Denied to run Action\"\n\t                    self.ui.notify(title=\"USER INPUT\", message=action_result)\n\t                else:\n\t                    try:\n\t                        action_result = self._act(tool_name, args)\n", "                    except Exception as e:\n\t                        raise e\n\t                    self.ui.notify(title=\"ACTION RESULT\", message=action_result)\n\t            episode = Episode(\n\t                thoughts=thoughts,\n\t                action=action,\n\t                result=action_result\n\t            )\n\t            summary = self.episodic_memory.summarize_and_memorize_episode(episode)\n\t            self.ui.notify(title=\"MEMORIZE NEW EPISODE\",\n", "                           message=summary, title_color=\"blue\")\n\t            entities = self.semantic_memory.extract_entity(action_result)\n\t            self.ui.notify(title=\"MEMORIZE NEW KNOWLEDGE\",\n\t                           message=entities, title_color=\"blue\")\n\t    def _reason(self) -> Union[str, Dict[Any, Any]]:\n\t        current_task_description = self.task_manager.get_current_task_string()\n\t        # Retrie task related memories\n\t        with self.ui.loading(\"Retrieve memory...\"):\n\t            # Retrieve memories related to the task.\n\t            related_past_episodes = self.episodic_memory.remember_related_episodes(\n", "                current_task_description,\n\t                k=2)\n\t            if len(related_past_episodes) > 0:\n\t                self.ui.notify(title=\"TASK RELATED EPISODE\",\n\t                               message=related_past_episodes)\n\t            # Retrieve concepts related to the task.\n\t            related_knowledge = self.semantic_memory.remember_related_knowledge(\n\t                current_task_description,\n\t                k=5\n\t            )\n", "            if len(related_knowledge) > 0:\n\t                self.ui.notify(title=\"TASK RELATED KNOWLEDGE\",\n\t                               message=related_knowledge)\n\t        # Get the relevant tools\n\t        # If agent has to much tools, use \"remember_relevant_tools\"\n\t        # because too many tool information will cause context windows overflow.\n\t        tools = self.prodedural_memory.remember_all_tools()\n\t        # Set up the prompt\n\t        tool_info = \"\"\n\t        for tool in tools:\n", "            tool_info += tool.get_tool_info() + \"\\n\"\n\t        # Get the recent episodes\n\t        memory = self.episodic_memory.remember_recent_episodes(2)\n\t        # If OpenAI Chat is available, it is used for higher accuracy results.\n\t        if self.openaichat:\n\t            propmt = ReasonPrompt.get_chat_template(memory=memory).format_prompt(\n\t                name=self.name,\n\t                role=self.role,\n\t                goal=self.goal,\n\t                related_past_episodes=related_past_episodes,\n", "                related_knowledge=related_knowledge,\n\t                task=current_task_description,\n\t                tool_info=tool_info\n\t            ).to_messages()\n\t            result = self.openaichat(propmt).content\n\t        else:\n\t            # Get the result from the LLM\n\t            prompt = ReasonPrompt.get_template(memory=memory)\n\t            llm_chain = LLMChain(prompt=prompt, llm=self.llm)\n\t            try:\n", "                result = llm_chain.predict(\n\t                    name=self.name,\n\t                    role=self.role,\n\t                    goal=self.goal,\n\t                    related_past_episodes=related_past_episodes,\n\t                    elated_knowledge=related_knowledge,\n\t                    task=current_task_description,\n\t                    tool_info=tool_info\n\t                )\n\t            except Exception as e:\n", "                raise Exception(f\"Error: {e}\")\n\t        # Parse and validate the result\n\t        try:\n\t            result_json_obj = LLMJsonOutputParser.parse_and_validate(\n\t                json_str=result,\n\t                json_schema=REASON_JSON_SCHEMA_STR,\n\t                llm=self.llm\n\t            )\n\t            return result_json_obj\n\t        except Exception as e:\n", "            raise Exception(f\"Error: {e}\")\n\t    def _act(self, tool_name: str, args: Dict) -> str:\n\t        # Get the tool to use from the procedural memory\n\t        try:\n\t            tool = self.prodedural_memory.remember_tool_by_name(tool_name)\n\t        except Exception as e:\n\t            raise Exception(\"Invalid command: \" + str(e))\n\t        try:\n\t            result = tool.run(**args)\n\t            return result\n", "        except Exception as e:\n\t            raise Exception(\"Could not run tool: \" + str(e))\n\t    def _task_complete(self, result: str) -> str:\n\t        current_task = self.task_manager.get_current_task_string()\n\t        self.ui.notify(title=\"COMPLETE TASK\",\n\t                       message=f\"TASK:{current_task}\\nRESULT:{result}\",\n\t                       title_color=\"BLUE\")\n\t        self.task_manager.complete_current_task(result)\n\t        return result\n\t    def save_agent(self) -> None:\n", "        episodic_memory_dir = f\"{self.dir}/episodic_memory\"\n\t        semantic_memory_dir = f\"{self.dir}/semantic_memory\"\n\t        filename = f\"{self.dir}/agent_data.json\"\n\t        self.episodic_memory.save_local(path=episodic_memory_dir)\n\t        self.semantic_memory.save_local(path=semantic_memory_dir)\n\t        data = {\"name\": self.name,\n\t                \"role\": self.role,\n\t                \"episodic_memory\": episodic_memory_dir,\n\t                \"semantic_memory\": semantic_memory_dir\n\t                }\n", "        with open(filename, \"w\") as f:\n\t            json.dump(data, f)\n\t    def load_agent(self) -> None:\n\t        absolute_path = self._get_absolute_path()\n\t        if not \"agent_data.json\" in os.listdir(absolute_path):\n\t            self.ui.notify(\"ERROR\", \"Agent data does not exist.\", title_color=\"red\")\n\t        with open(os.path.join(absolute_path, \"agent_data.json\")) as f:\n\t            agent_data = json.load(f)\n\t            self.name = agent_data[\"name\"]\n\t            self.role = agent_data[\"role\"]\n", "            try:\n\t                self.semantic_memory.load_local(agent_data[\"semantic_memory\"])\n\t            except Exception as e:\n\t                self.ui.notify(\n\t                    \"ERROR\", \"Semantic memory data is corrupted.\", title_color=\"red\")\n\t                raise e\n\t            else:\n\t                self.ui.notify(\n\t                    \"INFO\", \"Semantic memory data is loaded.\", title_color=\"GREEN\")\n\t            try:\n", "                self.episodic_memory.load_local(agent_data[\"episodic_memory\"])\n\t            except Exception as e:\n\t                self.ui.notify(\n\t                    \"ERROR\", \"Episodic memory data is corrupted.\", title_color=\"RED\")\n\t                raise e\n\t            else:\n\t                self.ui.notify(\n\t                    \"INFO\", \"Episodic memory data is loaded.\", title_color=\"GREEN\")\n"]}
{"filename": "src/task_manager.py", "chunked_list": ["import json\n\tfrom pydantic import BaseModel, Field\n\tfrom pydantic import BaseModel, Field\n\tfrom langchain.llms.base import BaseLLM\n\tfrom typing import List, Any\n\tfrom langchain import LLMChain\n\tfrom llm.generate_task_plan.prompt import get_template\n\tfrom llm.list_output_parser import LLMListOutputParser\n\tclass Task(BaseModel):\n\t    \"\"\"Task model.\"\"\"\n", "    id: int = Field(..., description=\"Task ID\")\n\t    description: str = Field(..., description=\"Task description\")\n\t    is_done: bool = Field(False, description=\"Task done or not\")\n\t    result: str = Field(\"\", description=\"The result of the task\")\n\tclass TaskManeger(BaseModel):\n\t    \"\"\"Task manager model.\"\"\"\n\t    tasks: List[Task] = Field([], description=\"The list of tasks\")\n\t    current_task_id: int = Field(1, description=\"The last task id\")\n\t    llm: BaseLLM = Field(..., description=\"llm class for the agent\")\n\t    def generate_task_plan(self, name: str, role: str, goal: str):\n", "        \"\"\"Generate a task plan for the agent.\"\"\"\n\t        propmt = get_template()\n\t        llm_chain = LLMChain(prompt=propmt, llm=self.llm)\n\t        try:\n\t            result = llm_chain.predict(\n\t                name=name,\n\t                role=role,\n\t                goal=goal\n\t            )\n\t        except Exception as e:\n", "            raise Exception(f\"Error: {e}\")\n\t        # Parse and validate the result\n\t        try:\n\t            result_list = LLMListOutputParser.parse(result, separeted_string=\"\\t\")\n\t        except Exception as e:\n\t            raise Exception(\"Error: \" + str(e))\n\t        # Add tasks with a serial number\n\t        for i, e in enumerate(result_list, start=1):\n\t            id = int(i)\n\t            description = e\n", "            self.tasks.append(Task(id=id, description=description))\n\t        self\n\t    def get_task_by_id(self, id: int) -> Task:\n\t        \"\"\"Get a task by Task id.\"\"\"\n\t        for task in self.tasks:\n\t            if task.id == id:\n\t                return task\n\t        return None\n\t    def get_current_task(self) -> Task:\n\t        \"\"\"Get the current task agent is working on.\"\"\"\n", "        return self.get_task_by_id(self.current_task_id)\n\t    def get_current_task_string(self) -> str:\n\t        \"\"\"Get the current task agent is working on as a string.\"\"\"\n\t        task = self.get_current_task()\n\t        if task is None:\n\t            return None\n\t        else:\n\t            return self._task_to_string(task)\n\t    def complete_task(self, id: int, result: str) -> None:\n\t        \"\"\"Complete a task by Task id.\"\"\"\n", "        # Complete the task specified by ID\n\t        self.tasks[id - 1].is_done = True\n\t        self.tasks[id - 1].result = result\n\t        self.current_task_id += 1\n\t    def complete_current_task(self, result: str) -> None:\n\t        \"\"\"Complete the current task agent is working on.\"\"\"\n\t        self.complete_task(self.current_task_id, result=result)\n\t    def _task_to_string(self, task: Task) -> str:\n\t        \"\"\"Convert a task to a string.\"\"\"\n\t        return f\"{task.id}: {task.description}\"\n", "    def get_incomplete_tasks(self) -> List[Task]:\n\t        \"\"\"Get the list of incomplete tasks.\"\"\"\n\t        return [task for task in self.tasks if not task.is_done]\n\t    def get_incomplete_tasks_string(self) -> str:\n\t        \"\"\"Get the list of incomplete tasks as a string.\"\"\"\n\t        result = \"\"\n\t        for task in self.get_incomplete_tasks():\n\t            result += self._task_to_string(task) + \"\\n\"\n\t        return result\n"]}
{"filename": "src/tools/base.py", "chunked_list": ["import inspect\n\tfrom pydantic import Field, Extra, validator, BaseModel\n\tfrom typing import Any, Callable, Dict\n\tclass AgentToolError(Exception):\n\t    pass\n\tclass AgentTool(BaseModel):\n\t    \"\"\"\n\t    Base class for agent tools.    \n\t    \"\"\"\n\t    name: str\n", "    description: str = Field(..., description=\"The description of the tool\")\n\t    func: Callable[[str], str] = Field(..., description=\"The function to execute\")\n\t    args: Dict[str, str] = Field(default={})\n\t    user_permission_required: bool = Field(\n\t        False, description=\"Whether the user permission is required before using this tool\")\n\t    class Config:\n\t        extra = Extra.allow\n\t    def run(self, **kwargs: Any) -> str:\n\t        \"\"\"Run the tool.\"\"\"\n\t        try:\n", "            result = self.func(**kwargs)\n\t        except (Exception, KeyboardInterrupt) as e:\n\t            raise AgentToolError(str(e))\n\t        return result\n\t    def get_tool_info(self, include_args=True) -> str:\n\t        \"\"\"Get the tool info.\"\"\"\n\t        args_str = \", \".join([f\"{k}: <{v}>\" for k, v in self.args.items()])\n\t        if include_args:\n\t            return f\"\"\"{self.name}: \"{self.description}\", args: {args_str}\"\"\"\n\t        else:\n", "            return f\"\"\"{self.name}: \"{self.description}\"\"\"\n\t    @property\n\t    def args(self) -> Dict:\n\t        \"\"\"Get the argument name and argument type from the signature\"\"\"\n\t        func_signature = inspect.signature(self.func)\n\t        required_args = {}\n\t        for param in func_signature.parameters.values():\n\t            param_name = str(param.name)\n\t            required_args[param_name] = f\"<{param_name}>\"\n\t        return required_args\n", "    @validator(\"name\")\n\t    def name_to_snake_case(name: str):\n\t        \"\"\"Convert the name to snake case.\"\"\"\n\t        if name is None:\n\t            raise AttributeError(\"NoneType object has no attribute\")\n\t        s = str(name).strip()\n\t        if not s:\n\t            raise IndexError(\"Empty string\")\n\t        # Convert all uppercase letters to lowercase.\n\t        s = s.lower()\n", "        # Replace spaces, dashes, and other separators with underscores.\n\t        s = s.replace(' ', '_')\n\t        s = s.replace('-', '_')\n\t        # Remove all characters that are not alphanumeric or underscore.\n\t        s = ''.join(c for c in s if c.isalnum() or c == '_')\n\t        # Replace multiple consecutive underscores with a single underscore.\n\t        s = '_'.join(filter(None, s.split('_')))\n\t        return s\n"]}
{"filename": "src/tools/__init__.py", "chunked_list": []}
{"filename": "src/llm/list_output_parser.py", "chunked_list": ["import re\n\tfrom typing import List\n\tfrom pydantic import BaseModel\n\tclass LLMListOutputParserException(Exception):\n\t    \"\"\"Exception for List parsing errors\"\"\"\n\t    pass\n\tclass ParseListException(LLMListOutputParserException):\n\t    \"\"\"Exception for List parsing errors\"\"\"\n\t    pass\n\tclass LLMListOutputParser(BaseModel):\n", "    @classmethod\n\t    def parse(cls, string_list: str, separeted_string=\",\") -> List[str]:\n\t        \"\"\"\n\t        Parses the string list and returns a list of strings.\n\t        \"\"\"\n\t        if not string_list:\n\t            return []\n\t        # Remove square brackets\n\t        string_list = cls._remove_square_brackets(string_list)\n\t        # Split by comma and convert to list\n", "        parsed_list = string_list.split(separeted_string)\n\t        # If the string is not comma-separated, raise ValueError\n\t        if len(parsed_list) == 1 and not parsed_list[0]:\n\t            raise ParseListException(f\"The string is not {separeted_string}-separated.\")\n\t        return parsed_list\n\t    @staticmethod\n\t    def _remove_square_brackets(string_list: str) -> str:\n\t        \"\"\"\n\t        Removes square brackets from the string.\n\t        \"\"\"\n", "        return re.sub(r\"\\[|\\]\", \"\", string_list)\n"]}
{"filename": "src/llm/json_output_parser.py", "chunked_list": ["import json\n\timport re\n\tfrom typing import Any, Dict, Union, List\n\tfrom pydantic import BaseModel\n\tfrom jsonschema import validate, ValidationError\n\tfrom langchain.llms.base import BaseLLM\n\timport contextlib\n\tfrom marvin import ai_fn\n\tclass LLMJsonOutputParserException(Exception):\n\t    \"\"\"Exception for JSON parsing errors\"\"\"\n", "    pass\n\tclass ParseJsonException(LLMJsonOutputParserException):\n\t    \"\"\"Exception for JSON parsing errors\"\"\"\n\t    pass\n\tclass ValidateJsonException(LLMJsonOutputParserException):\n\t    \"\"\"Exception for JSON validating errors\"\"\"\n\t    pass\n\tclass FixJsonException(LLMJsonOutputParserException):\n\t    \"\"\"Exception for JSON fixing errors\"\"\"\n\t    pass\n", "@ai_fn()\n\tdef auto_fix_json(json_str: str, schema: str) -> str:\n\t    \"\"\"\n\t    Fixes the provided JSON string to make it parseable and fully complient with the provided schema.\n\t    If an object or field specified in the schema isn't contained within the correct JSON,\n\t    it is ommited.\\n This function is brilliant at guessing  when the format is incorrect.\n\t    Parameters:\n\t    description: str\n\t        The description of the function\n\t    function: str\n", "        The function to run\n\t    Returns:\n\t    str\n\t        The fixed JSON string it is valid.\n\t    \"\"\"\n\tclass LLMJsonOutputParser(BaseModel):\n\t    \"\"\"Parse the output of the LLM.\"\"\"\n\t    @classmethod\n\t    def parse_and_validate(cls, json_str: str, json_schema: str, llm: BaseLLM) -> Union[str, Dict[Any, Any]]:\n\t        \"\"\"\n", "        Parses and validates the JSON string.\n\t        \"\"\"\n\t        # Parse JSON\n\t        try:\n\t            json_str = cls._parse_json(json_str, json_schema, llm)\n\t        except ParseJsonException as e:\n\t            raise ParseJsonException(str(e))\n\t        # Validate JSON\n\t        try:\n\t            return cls._validate_json(json_str, json_schema, llm)\n", "        except ValidationError as e:\n\t            raise ValidateJsonException(str(e))\n\t    @classmethod\n\t    def _remove_square_brackets(cls, json_str: str) -> str:\n\t        \"\"\"\n\t        Removes square brackets from the JSON string.\n\t        \"\"\"\n\t        return re.sub(r\"\\[|\\]\", \"\", json_str)\n\t    @classmethod\n\t    def _parse_json(cls, json_str: str,  json_schema: str, llm: BaseLLM) -> Union[str, Dict[Any, Any]]:\n", "        \"\"\"\n\t        Parses the JSON string.\n\t        \"\"\"\n\t        with contextlib.suppress(json.JSONDecodeError):\n\t            json_str = json_str.replace(\"\\t\", \"\")\n\t            return json.loads(json_str)\n\t        with contextlib.suppress(json.JSONDecodeError):\n\t            json_str = cls.correct_json(json_str)\n\t            return json.loads(json_str)\n\t        try:\n", "            json_str = cls._remove_square_brackets(json_str)\n\t            brace_index = json_str.index(\"{\")\n\t            maybe_fixed_json = json_str[brace_index:]\n\t            last_brace_index = maybe_fixed_json.rindex(\"}\")\n\t            maybe_fixed_json = maybe_fixed_json[: last_brace_index + 1]\n\t            return json.loads(maybe_fixed_json)\n\t        except (json.JSONDecodeError, ValueError):\n\t            pass\n\t        # Now try to fix this up using the ai_functions\n\t        try:\n", "            ai_fixed_json = cls._fix_json(json_str, json_schema, llm)\n\t            return json.loads(ai_fixed_json)\n\t        except FixJsonException as e:\n\t            raise ParseJsonException(\"Could not parse JSON:\" + str(e))\n\t    @classmethod\n\t    def _validate_json(cls, json_obj: Union[str, Dict[Any, Any]], json_schema: str, llm: BaseLLM) -> Union[str, Dict[Any, Any]]:\n\t        \"\"\"\n\t        Check if the given JSON string is fully complient with the provided schema.\n\t        \"\"\"\n\t        schema_obj = json.loads(json_schema)\n", "        try:\n\t            validate(json_obj, schema_obj)\n\t            return json_obj\n\t        except ValidationError:\n\t            # Now try to fix this up using the ai_functions\n\t            try:\n\t                ai_fixed_json = cls._fix_json(json.dumps(json_obj), json_schema, llm)\n\t                return json.loads(ai_fixed_json)\n\t            except FixJsonException as e:\n\t                raise ValidateJsonException(\"Could not validate JSON:\" + str(e))\n", "    @staticmethod\n\t    def _fix_json(json_str: str, schema: str, llm: BaseLLM) -> str:\n\t        \"\"\"\n\t        Fix the given JSON string to make it parseable and fully complient with the provided schema.\n\t        \"\"\"\n\t        try:\n\t            fixed_json_str = auto_fix_json(json_str, schema)\n\t        except Exception as e:\n\t            raise FixJsonException(e)\n\t        try:\n", "            json.loads(fixed_json_str)\n\t            return fixed_json_str\n\t        except Exception:\n\t            import traceback\n\t            call_stack = traceback.format_exc()\n\t            raise FixJsonException(f\"Failed to fix JSON: '{json_str}' \" + call_stack)\n\t    @staticmethod\n\t    def _extract_char_position(error_message: str) -> int:\n\t        \"\"\"\n\t        Extract the character position from the error message.\n", "        \"\"\"\n\t        char_pattern = re.compile(r'\\(char (\\d+)\\)')\n\t        if match := char_pattern.search(error_message):\n\t            return int(match[1])\n\t        else:\n\t            raise ValueError(\"Character position not found in the error message.\")\n\t    @staticmethod\n\t    def _add_quotes_to_property_names(json_string: str) -> str:\n\t        \"\"\"\n\t        Add quotes to the property names in the JSON string.\n", "        \"\"\"\n\t        def replace_func(match):\n\t            return f'\"{match.group(1)}\":'\n\t        property_name_pattern = re.compile(r'(\\w+):')\n\t        corrected_json_string = property_name_pattern.sub(\n\t            replace_func,\n\t            json_string)\n\t        try:\n\t            json.loads(corrected_json_string)\n\t            return corrected_json_string\n", "        except json.JSONDecodeError as e:\n\t            raise e\n\t    @staticmethod\n\t    def _balance_braces(json_string: str) -> str:\n\t        \"\"\"\n\t        Add missing braces to the end of the JSON string.\n\t        \"\"\"\n\t        open_braces_count = json_string.count(\"{\")\n\t        close_braces_count = json_string.count(\"}\")\n\t        while open_braces_count > close_braces_count:\n", "            json_string += \"}\"\n\t            close_braces_count += 1\n\t        while close_braces_count > open_braces_count:\n\t            json_string = json_string.rstrip(\"}\")\n\t            close_braces_count -= 1\n\t        with contextlib.suppress(json.JSONDecodeError):\n\t            json.loads(json_string)\n\t            return json_string\n\t    @classmethod\n\t    def _fix_invalid_escape(cls, json_str: str, error_message: str) -> str:\n", "        \"\"\"\n\t        Remove the invalid escape character from the JSON string.\n\t        \"\"\"\n\t        while error_message.startswith('Invalid \\\\escape'):\n\t            bad_escape_location = cls._extract_char_position(error_message)\n\t            json_str = json_str[:bad_escape_location] + \\\n\t                json_str[bad_escape_location + 1:]\n\t            try:\n\t                json.loads(json_str)\n\t                return json_str\n", "            except json.JSONDecodeError as e:\n\t                error_message = str(e)\n\t        return json_str\n\t    @classmethod\n\t    def correct_json(cls, json_str: str) -> str:\n\t        \"\"\"\n\t        Correct the given JSON string to make it parseable.\n\t        \"\"\"\n\t        try:\n\t            json.loads(json_str)\n", "            return json_str\n\t        except json.JSONDecodeError as e:\n\t            error_message = str(e)\n\t            if error_message.startswith('Invalid \\\\escape'):\n\t                json_str = cls._fix_invalid_escape(json_str, error_message)\n\t            if error_message.startswith('Expecting property name enclosed in double quotes'):\n\t                json_str = cls._add_quotes_to_property_names(json_str)\n\t                try:\n\t                    json.loads(json_str)\n\t                    return json_str\n", "                except json.JSONDecodeError as e:\n\t                    error_message = str(e)\n\t            if balanced_str := cls._balance_braces(json_str):\n\t                return balanced_str\n\t        return json_str\n"]}
{"filename": "src/llm/extract_entity/schema.py", "chunked_list": ["class JsonSchema:\n\t    schema = {\n\t        \"entity1\": \"description of entity1. Please describe the entities using sentences rather than single words.\",\n\t        \"entity2\": \"description of entity2. Please describe the entities using sentences rather than single words.\",\n\t        \"entity3\": \"description of entity3. Please describe the entities using sentences rather than single words.\"\n\t    }\n"]}
{"filename": "src/llm/extract_entity/__init__.py", "chunked_list": []}
{"filename": "src/llm/extract_entity/prompt.py", "chunked_list": ["import json\n\tfrom langchain.prompts import PromptTemplate, ChatPromptTemplate\n\tfrom llm.extract_entity.schema import JsonSchema\n\tfrom langchain.prompts.chat import (\n\t    ChatPromptTemplate,\n\t    SystemMessagePromptTemplate,\n\t)\n\t# Convert the schema object to a string\n\tJSON_SCHEMA_STR = json.dumps(JsonSchema.schema)\n\tENTITY_EXTRACTION_TEMPLATE = \"\"\"\n", "    You are an AI assistant reading a input text and trying to extract entities from it.\n\t    Extract ONLY proper nouns from the input text and return them as a JSON object.\n\t    You should definitely extract all names and places.\n\t    [EXAMPLE]\n\t    INPUT TEXT:\n\t     Apple Computer was founded on April 1, 1976, by Steve Wozniak, Steve Jobs and Ronald Wayne to develop and sell Wozniak's Apple I personal computer. \n\t     It was incorporated by Jobs and Wozniak as Apple Computer, Inc. in 1977. \n\t     The company's second computer, the Apple II, became a best seller and one of the first mass-produced microcomputers. \n\t     Apple Computer went public in 1980 to instant financial success. \n\t     The company developed computers featuring innovative graphical user interfaces, including the 1984 original Macintosh, announced that year in a critically acclaimed advertisement. \n", "     By 1985, the high cost of its products, and power struggles between executives, caused problems.\n\t     Wozniak stepped back from Apple Computer amicably and pursued other ventures, while Jobs resigned bitterly and founded NeXT, taking some Apple Computer employees with him.\n\t    RESPONCE:\n\t     {{\n\t        \"Apple Computer Company\": \"a company founded in 1976 by Steve Wozniak, Steve Jobs, and Ronald Wayne to develop and sell personal computers\",\n\t        \"Steve Wozniak\": \"an American inventor, electronics engineer, programmer, philanthropist, and technology entrepreneur who co-founded Apple Computer Company with Steve Jobs\",\n\t        \"Steve Jobs\": \"an American entrepreneur, business magnate, inventor, and industrial designer who co-founded Apple Computer Company with Steve Wozniak and Ronald Wayne, and later founded NeXT\",\n\t        \"Ronald Wayne\": \"an American retired electronics industry worker and co-founder of Apple Computer Company, who left the company after only 12 days\"\n\t    }}\n\t    [INPUT TEXT] (for reference only):\n", "    {text}\n\t    \"\"\"\n\tSCHEMA_TEMPLATE = f\"\"\"\n\t    [RULE]\n\t    Your response must be provided exclusively in the JSON format outlined below, without any exceptions. \n\t    Any additional text, explanations, or apologies outside of the JSON structure will not be accepted. \n\t    Please ensure the response adheres to the specified format and can be successfully parsed by Python's json.loads function.\n\t    Strictly adhere to this JSON RESPONSE FORMAT for your response.\n\t    Failure to comply with this format will result in an invalid response. \n\t    Please ensure your output strictly follows RESPONSE FORMAT.\n", "    [JSON RESPONSE FORMAT]\n\t    {JSON_SCHEMA_STR}\n\t    [RESPONSE]\"\"\".replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n\tdef get_template() -> PromptTemplate:\n\t    template = f\"{ENTITY_EXTRACTION_TEMPLATE}\\n{SCHEMA_TEMPLATE}\"\n\t    return PromptTemplate(input_variables=[\"text\"], template=template)\n\tdef get_chat_template() -> ChatPromptTemplate:\n\t    messages = []\n\t    messages.append(SystemMessagePromptTemplate.from_template(\n\t        ENTITY_EXTRACTION_TEMPLATE))\n", "    messages.append(SystemMessagePromptTemplate.from_template(SCHEMA_TEMPLATE))\n\t    return ChatPromptTemplate.from_messages(messages)\n"]}
{"filename": "src/llm/generate_task_plan/prompt.py", "chunked_list": ["from langchain.prompts import PromptTemplate\n\tfrom langchain.prompts.chat import (\n\t    ChatPromptTemplate,\n\t    HumanMessagePromptTemplate,\n\t    SystemMessagePromptTemplate,\n\t)\n\t# Convert the schema object to a string\n\tBASE_TEMPLATE = \"\"\"\n\tYou are {name}, {role}\n\tYour should create task that uses the result of an execution agent\n", "to create new tasks with the following GOAL:\n\t[GOAL]\n\t{goal}\n\t[YOUR MISSION]\n\tBased on the [GOAL], create new tasks to be completed by the AI system that do not overlap with incomplete tasks.\n\t- Tasks should be calculated backward from the GOAL, and effective arrangements should be made.\n\t- You can create any number of new tasks.\n\t[RESPONSE FORMAT]\n\tReturn the tasks as a list of string.\n\t- Enclose each task in double quotation marks.\n", "- Separate tasks with Tabs.\n\t- Use [] only at the beginning and end\n\t[\"Task 1 that the AI assistant should perform\"\\t\"Task 2 that the AI assistant should perform\",\\t ...]\n\t[RESPONSE]\n\t\"\"\"\n\tdef get_template() -> PromptTemplate:\n\t    template = BASE_TEMPLATE\n\t    PROMPT = PromptTemplate(\n\t        input_variables=[\"name\", \"role\", \"goal\"], template=template)\n\t    return PROMPT\n", "def get_chat_template() -> ChatPromptTemplate:\n\t    messages = []\n\t    messages.append(SystemMessagePromptTemplate.from_template(BASE_TEMPLATE))\n\t    return ChatPromptTemplate.from_messages(messages)\n"]}
{"filename": "src/llm/summarize/prompt.py", "chunked_list": ["from typing import List\n\tfrom langchain.prompts import PromptTemplate\n\tfrom langchain.prompts.chat import (\n\t    ChatPromptTemplate,\n\t    HumanMessagePromptTemplate,\n\t    SystemMessagePromptTemplate,\n\t)\n\tfrom langchain.schema import (\n\t    AIMessage,\n\t    HumanMessage,\n", "    SystemMessage\n\t)\n\t# Convert the schema object to a string\n\tBASE_TEMPLATE = \"\"\"\n\t[THOUGHTS]\n\t{thoughts}\n\t[ACTION]\n\t{action}\n\t[RESULT OF ACTION]\n\t{result}\n", "[INSTRUSCTION]\n\tUsing above [THOUGHTS], [ACTION], and [RESULT OF ACTION], please summarize the event.\n\t[SUMMARY]\n\t\"\"\"\n\tdef get_template() -> PromptTemplate:\n\t    template = BASE_TEMPLATE\n\t    prompt_template = PromptTemplate(\n\t        input_variables=[\"thoughts\", \"action\", \"result\"], template=template)\n\t    return prompt_template\n\tdef get_chat_templatez() -> ChatPromptTemplate:\n", "    messages = []\n\t    messages.append(SystemMessagePromptTemplate.from_template(BASE_TEMPLATE))\n\t    return ChatPromptTemplate.from_messages(messages)\n"]}
{"filename": "src/llm/reason/schema.py", "chunked_list": ["class JsonSchema:\n\t    schema = {\n\t        \"observation\": \"observation of [RECENT EPISODES]\",\n\t        \"thoughts\": {\n\t            \"task\": \"description of [YOUR TASK] assigned to you\",\n\t            \"knowledge\": \"if there is any helpful knowledge in [RELATED KNOWLEDGE] for the task, summarize the key points here\",\n\t            \"past_events\": \"if there is any helpful past events in [RELATED PAST EPISODES] for the task, summarize the key points here\",\n\t            \"idea\": \"thought to perform the task\",\n\t            \"reasoning\": \"reasoning of the thought\",\n\t            \"criticism\": \"constructive self-criticism\",\n", "            \"summary\": \"thoughts summary to say to user\"\n\t        },\n\t        \"action\": {\n\t            \"tool_name\": \"One of the tool names included in [TOOLS]\",\n\t            \"args\": {\n\t                \"arg name\": \"value\",\n\t                \"arg name\": \"value\"\n\t            }\n\t        }\n\t    }\n"]}
{"filename": "src/llm/reason/__init__.py", "chunked_list": []}
{"filename": "src/llm/reason/prompt.py", "chunked_list": ["# flake8: noqa\n\timport json\n\timport time\n\tfrom langchain.prompts import PromptTemplate\n\tfrom pydantic import Field\n\tfrom typing import List\n\tfrom memory.episodic_memory import Episode\n\tfrom llm.reason.schema import JsonSchema\n\tfrom langchain.prompts import PromptTemplate\n\tfrom langchain.prompts.chat import (\n", "    ChatPromptTemplate,\n\t    HumanMessagePromptTemplate,\n\t    SystemMessagePromptTemplate,\n\t)\n\tfrom langchain.schema import (\n\t    AIMessage,\n\t    HumanMessage,\n\t    SystemMessage\n\t)\n\t# Convert the schema object to a string\n", "JSON_SCHEMA_STR = json.dumps(JsonSchema.schema)\n\tBASE_TEMPLATE = \"\"\"\n\tYou are {name}, {role}\n\tYour decisions must always be made independently without seeking user assistance. \n\tPlay to your strengths as an LLM and pursue simple strategies with no legal complications.\n\t[GOAL]\n\t{goal}\n\t[PERFORMANCE EVALUATION]\n\t1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n\t2. Constructively self-criticize your big-picture behavior constantly.\n", "3. Reflect on past decisions and strategies to refine your approach.\n\t[RELATED KNOWLEDGE] \n\tThis reminds you of related knowledge:\n\t{related_knowledge}\n\t[RELATED PAST EPISODES]\n\tThis reminds you of related past events:\n\t{related_past_episodes}\n\t[YOUR TASK]\n\tYou are given the following task:\n\t{task}\n", "[TOOLS]\n\tYou can ONLY ONE TOOL at a time\n\ttool name: \"tool description\", arg1: <arg1>, arg2: <arg2>\n\t{tool_info}\n\ttask_complete: \"If you think you have completed the task, please use this tool to mark it as done and include your answer to the task in the 'args' field.\", result: <Answer to the assigned task>\n\t\"\"\"\n\tRECENT_EPISODES_TEMPLETE = \"\"\"\n\t[RECENT EPISODES]\n\tThis reminds you of recent events:\n\t\"\"\"\n", "SCHEMA_TEMPLATE = f\"\"\"\n\t[RULE]\n\tYour response must be provided exclusively in the JSON format outlined below, without any exceptions. \n\tAny additional text, explanations, or apologies outside of the JSON structure will not be accepted. \n\tPlease ensure the response adheres to the specified format and can be successfully parsed by Python's json.loads function.\n\tStrictly adhere to this JSON RESPONSE FORMAT for your response:\n\tFailure to comply with this format will result in an invalid response. \n\tPlease ensure your output strictly follows JSON RESPONSE FORMAT.\n\t[JSON RESPONSE FORMAT]\n\t{JSON_SCHEMA_STR}\n", "Determine which next command to use, and respond using the format specified above:\n\t\"\"\".replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n\tdef get_template(memory: List[Episode] = None) -> PromptTemplate:\n\t    template = BASE_TEMPLATE\n\t    # If there are past conversation logs, append them\n\t    if len(memory) > 0:\n\t        # insert current time and date\n\t        recent_episodes = RECENT_EPISODES_TEMPLETE\n\t        RECENT_EPISODES_TEMPLETE += f\"The current time and date is {time.strftime('%c')}\"\n\t        # insert past conversation logs\n", "        for episode in memory:\n\t            thoughts_str = json.dumps(episode.thoughts)\n\t            action_str = json.dumps(episode.action)\n\t            result = episode.result\n\t            recent_episodes += thoughts_str + \"/n\" + action_str + \"/n\" + result + \"/n\"\n\t        template += recent_episodes\n\t    template += SCHEMA_TEMPLATE\n\t    PROMPT = PromptTemplate(\n\t        input_variables=[\"name\", \"role\", \"goal\", \"related_knowledge\", \"related_past_episodes\", \"task\", \"tool_info\"], template=template)\n\t    return PROMPT\n", "def get_chat_template(memory: List[Episode] = None) -> ChatPromptTemplate:\n\t    messages = []\n\t    messages.append(SystemMessagePromptTemplate.from_template(BASE_TEMPLATE))\n\t    # If there are past conversation logs, append them\n\t    if len(memory) > 0:\n\t        # insert current time and date\n\t        recent_episodes = RECENT_EPISODES_TEMPLETE\n\t        recent_episodes += f\"The current time and date is {time.strftime('%c')}\"\n\t        # insert past conversation logs\n\t        for episode in memory:\n", "            thoughts_str = json.dumps(episode.thoughts)\n\t            action_str = json.dumps(episode.action)\n\t            result = episode.result\n\t            recent_episodes += thoughts_str + \"/n\" + action_str + \"/n\" + result + \"/n\"\n\t        messages.append(SystemMessage(content=recent_episodes))\n\t    messages.append(SystemMessage(content=SCHEMA_TEMPLATE))\n\t    return ChatPromptTemplate.from_messages(messages)\n"]}
{"filename": "src/ui/base.py", "chunked_list": ["from pydantic import BaseModel, Extra\n\tfrom abc import abstractmethod\n\tfrom typing import ContextManager\n\tclass BaseHumanUserInterface(BaseModel):\n\t    \"\"\" Base class for human user interface.\"\"\"\n\t    class Config:\n\t        extra = Extra.forbid\n\t    @abstractmethod\n\t    def get_user_input(self) -> str:\n\t        # waiting for user input\n", "        pass\n\t    @abstractmethod\n\t    def get_binary_user_input(self, message: str) -> bool:\n\t        # get user permission\n\t        pass\n\t    @abstractmethod\n\t    def notify(self, title: str, message: str) -> None:\n\t        # notify user\n\t        pass\n\t    @abstractmethod\n", "    def loading(self) -> ContextManager:\n\t        # waiting for AI to respond\n\t        pass\n"]}
{"filename": "src/ui/__init__.py", "chunked_list": []}
{"filename": "src/ui/cui.py", "chunked_list": ["import itertools\n\timport sys\n\timport threading\n\timport time\n\tfrom enum import Enum\n\tfrom typing import ContextManager, Union\n\tfrom ui.base import BaseHumanUserInterface\n\tclass Color(Enum):\n\t    \"\"\"Color codes for the commandline\"\"\"\n\t    BLACK = '\\033[30m'  # (Text) Black\n", "    RED = '\\033[31m'  # (Text) Red\n\t    GREEN = '\\033[32m'  # (Text) Green\n\t    YELLOW = '\\033[33m'  # (Text) Yellow\n\t    BLUE = '\\033[34m'  # (Text) Blue\n\t    MAGENTA = '\\033[35m'  # (Text) Magenta\n\t    CYAN = '\\033[36m'  # (Text) Cyan\n\t    WHITE = '\\033[37m'  # (Text) White\n\t    COLOR_DEFAULT = '\\033[39m'  # Reset text color to default\n\tclass CommandlineUserInterface(BaseHumanUserInterface):\n\t    \"\"\"Commandline user interface.\"\"\"\n", "    def get_user_input(self) -> str:\n\t        \"\"\"Get user input and return the result as a string\"\"\"\n\t        user_input = input(\"Input:\")\n\t        return str(user_input)\n\t    def get_binary_user_input(self, prompt: str) -> bool:\n\t        \"\"\"Get a binary input from the user and return the result as a bool\"\"\"\n\t        yes_patterns = [\"y\", \"yes\", \"yeah\", \"yup\", \"yep\"]\n\t        no_patterns = [\"n\", \"no\", \"nah\", \"nope\"]\n\t        while True:\n\t            response = input(prompt + \" (y/n) \").strip().lower()\n", "            if response in yes_patterns:\n\t                return True\n\t            elif response in no_patterns:\n\t                return False\n\t            else:\n\t                self.notify(\"Invalid input\", \"Please enter y or n.\",\n\t                            title_color=Color.RED)\n\t                continue\n\t    def notify(self, title: str, message: str, title_color: Union[str, Color] = Color.YELLOW) -> None:\n\t        \"\"\"Print a notification to the user\"\"\"\n", "        if isinstance(title_color, str):\n\t            try:\n\t                title_color = Color[title_color.upper()]\n\t            except KeyError:\n\t                raise ValueError(f\"{title_color} is not a valid Color\")\n\t        self._print_message(title, message, title_color)\n\t    def loading(self,\n\t                message: str = \"Thinking...\",\n\t                delay: float = 0.1) -> ContextManager:\n\t        \"\"\"Return a context manager that will display a loading spinner\"\"\"\n", "        return self.Spinner(message=message, delay=delay)\n\t    def _print_message(self, title: str, message: str, title_color: Color) -> None:\n\t        print(f\"{title_color.value}{title}{Color.COLOR_DEFAULT.value}: {message}\")\n\t    class Spinner:\n\t        \"\"\"A simple spinner class\"\"\"\n\t        def __init__(self, message=\"Loading...\", delay=0.1):\n\t            \"\"\"Initialize the spinner class\"\"\"\n\t            self.spinner = itertools.cycle(['-', '/', '|', '\\\\'])\n\t            self.delay = delay\n\t            self.message = message\n", "            self.running = False\n\t            self.spinner_thread = None\n\t        def spin(self):\n\t            \"\"\"Spin the spinner\"\"\"\n\t            while self.running:\n\t                sys.stdout.write(next(self.spinner) + \" \" + self.message + \"\\r\")\n\t                sys.stdout.flush()\n\t                time.sleep(self.delay)\n\t                sys.stdout.write('\\b' * (len(self.message) + 2))\n\t        def __enter__(self):\n", "            \"\"\"Start the spinner\"\"\"\n\t            self.running = True\n\t            self.spinner_thread = threading.Thread(target=self.spin)\n\t            self.spinner_thread.start()\n\t        def __exit__(self, exc_type, exc_value, exc_traceback):\n\t            \"\"\"Stop the spinner\"\"\"\n\t            self.running = False\n\t            self.spinner_thread.join()\n\t            sys.stdout.write('\\r' + ' ' * (len(self.message) + 2) + '\\r')\n\t            sys.stdout.flush()\n"]}
{"filename": "src/memory/semantic_memory.py", "chunked_list": ["import json\n\tfrom typing import Any, Optional\n\tfrom pydantic import BaseModel, Field\n\tfrom langchain.llms.base import BaseLLM\n\tfrom langchain import LLMChain\n\tfrom langchain.vectorstores import VectorStore, FAISS\n\tfrom langchain.embeddings import HuggingFaceEmbeddings\n\tfrom langchain.chat_models import ChatOpenAI\n\tfrom llm.extract_entity.prompt import get_template, get_chat_template\n\tfrom llm.extract_entity.schema import JsonSchema as ENTITY_EXTRACTION_SCHEMA\n", "from llm.json_output_parser import LLMJsonOutputParser, LLMJsonOutputParserException\n\tCREATE_JSON_SCHEMA_STR = json.dumps(ENTITY_EXTRACTION_SCHEMA.schema)\n\tclass SemanticMemory(BaseModel):\n\t    num_episodes: int = Field(0, description=\"The number of episodes\")\n\t    llm: BaseLLM = Field(..., description=\"llm class for the agent\")\n\t    openaichat: Optional[ChatOpenAI] = Field(\n\t        None, description=\"ChatOpenAI class for the agent\")\n\t    embeddings: HuggingFaceEmbeddings = Field(\n\t        HuggingFaceEmbeddings(), title=\"Embeddings to use for tool retrieval\")\n\t    vector_store: VectorStore = Field(\n", "        None, title=\"Vector store to use for tool retrieval\")\n\t    class Config:\n\t        arbitrary_types_allowed = True\n\t    def extract_entity(self, text: str) -> dict:\n\t        \"\"\"Extract an entity from a text using the LLM\"\"\"\n\t        if self.openaichat:\n\t            # If OpenAI Chat is available, it is used for higher accuracy results.\n\t            propmt = get_chat_template().format_prompt(text=text).to_messages()\n\t            result = self.openaichat(propmt).content\n\t        else:\n", "            # Get the result from the LLM\n\t            llm_chain = LLMChain(prompt=get_template(), llm=self.llm)\n\t            try:\n\t                result = llm_chain.predict(text=text)\n\t            except Exception as e:\n\t                raise Exception(f\"Error: {e}\")\n\t        # Parse and validate the result\n\t        try:\n\t            result_json_obj = LLMJsonOutputParser.parse_and_validate(\n\t                json_str=result,\n", "                json_schema=CREATE_JSON_SCHEMA_STR,\n\t                llm=self.llm\n\t            )\n\t        except LLMJsonOutputParserException as e:\n\t            raise LLMJsonOutputParserException(str(e))\n\t        else:\n\t            self._embed_knowledge(result_json_obj)\n\t            return result_json_obj\n\t    def remember_related_knowledge(self, query: str, k: int = 5) -> dict:\n\t        \"\"\"Remember relevant knowledge for a query.\"\"\"\n", "        if self.vector_store is None:\n\t            return {}\n\t        relevant_documents = self.vector_store.similarity_search(query, k=k)\n\t        return {d.metadata[\"entity\"]: d.metadata[\"description\"] for d in relevant_documents}\n\t    def _embed_knowledge(self, entity: dict[str:Any]) -> None:\n\t        \"\"\"Embed the knowledge into the vector store.\"\"\"\n\t        description_list = []\n\t        metadata_list = []\n\t        for entity, description in entity.items():\n\t            description_list.append(description)\n", "            metadata_list.append({\"entity\": entity, \"description\": description})\n\t        if self.vector_store is None:\n\t            self.vector_store = FAISS.from_texts(\n\t                texts=description_list,\n\t                metadatas=metadata_list,\n\t                embedding=self.embeddings\n\t            )\n\t        else:\n\t            self.vector_store.add_texts(\n\t                texts=description_list,\n", "                metadatas=metadata_list\n\t            )\n\t    def save_local(self, path: str) -> None:\n\t        \"\"\"Save the vector store to a local folder.\"\"\"\n\t        self.vector_store.save_local(folder_path=path)\n\t    def load_local(self, path: str) -> None:\n\t        \"\"\"Load the vector store from a local folder.\"\"\"\n\t        self.vector_store = FAISS.load_local(\n\t            folder_path=path, embeddings=self.embeddings)\n"]}
{"filename": "src/memory/procedual_memory.py", "chunked_list": ["from pydantic import BaseModel, Field\n\tfrom langchain.vectorstores import FAISS\n\tfrom langchain.vectorstores import VectorStore\n\tfrom langchain.schema import Document\n\tfrom pydantic import BaseModel, Field\n\tfrom langchain.vectorstores import VectorStore, FAISS\n\tfrom langchain.schema import Document\n\tfrom langchain.embeddings import HuggingFaceEmbeddings\n\tfrom typing import List\n\tfrom tools.base import AgentTool\n", "class ProcedualMemoryException(Exception):\n\t    pass\n\tclass ToolNotFoundException(ProcedualMemoryException):\n\t    pass\n\tclass ProcedualMemory(BaseModel):\n\t    tools: List[AgentTool] = Field([], title=\"hoge\")\n\t    embeddings: HuggingFaceEmbeddings = Field(\n\t        HuggingFaceEmbeddings(), title=\"Embeddings to use for tool retrieval\")\n\t    docs: List[Document] = Field([], title=\"Documents to use for tool retrieval\")\n\t    vector_store: VectorStore = Field(\n", "        None, title=\"Vector store to use for tool retrieval\")\n\t    class Config:\n\t        arbitrary_types_allowed = True\n\t    def memorize_tools(self, tools: List[AgentTool]) -> None:\n\t        \"\"\"Memorize tools and embed them.\"\"\"\n\t        for tool in tools:\n\t            self.tools.append(tool)\n\t            self.docs = [Document(page_content=t.description, metadata={\n\t                                  \"index\": i}) for i, t in enumerate(self.tools)]\n\t        self._embed_docs()\n", "    def remember_tool_by_name(self, tool_name: str) -> AgentTool:\n\t        \"\"\"Remember a tool by name and return it.\"\"\"\n\t        tool = [tool for tool in self.tools if tool.name.lower() == tool_name.lower()]\n\t        if tool:\n\t            return tool[0]\n\t        else:\n\t            raise ToolNotFoundException(f\"Tool {tool_name} not found\")\n\t    def remember_relevant_tools(self, query: str) -> List[AgentTool]:\n\t        \"\"\"Remember relevant tools for a query.\"\"\"\n\t        retriever = self.vector_store.as_retriever()\n", "        relevant_documents = retriever.get_relevant_documents(query)\n\t        return [self.tools[d.metadata[\"index\"]] for d in relevant_documents]\n\t    def remember_all_tools(self) -> List[AgentTool]:\n\t        \"\"\"Remember all tools and return them.\"\"\"\n\t        return self.tools\n\t    def _embed_docs(self) -> None:\n\t        \"\"\"Embed tools.\"\"\"\n\t        self.vector_store: FAISS = FAISS.from_documents(\n\t            self.docs, self.embeddings\n\t        )\n"]}
{"filename": "src/memory/__init__.py", "chunked_list": []}
{"filename": "src/memory/episodic_memory.py", "chunked_list": ["from typing import List, Dict, Any\n\tfrom pydantic import BaseModel, Field\n\tfrom langchain.llms.base import BaseLLM\n\tfrom langchain import LLMChain\n\tfrom langchain.vectorstores import VectorStore, FAISS\n\tfrom langchain.embeddings import HuggingFaceEmbeddings\n\tfrom llm.summarize.prompt import get_template\n\tclass Episode(BaseModel):\n\t    thoughts: Dict[str, Any] = Field(..., description=\"thoughts of the agent\")\n\t    action: Dict[str, Any] = Field(..., description=\"action of the agent\")\n", "    result: str = Field(..., description=\"The plan of the event\")\n\t    summary: str = Field(\"\", description=\"summary of the event\")\n\tclass EpisodicMemory(BaseModel):\n\t    num_episodes: int = Field(0, description=\"The number of episodes\")\n\t    store: Dict[str, Episode] = Field({}, description=\"The list of episodes\")\n\t    llm: BaseLLM = Field(..., description=\"llm class for the agent\")\n\t    embeddings: HuggingFaceEmbeddings = Field(\n\t        HuggingFaceEmbeddings(), title=\"Embeddings to use for tool retrieval\")\n\t    vector_store: VectorStore = Field(\n\t        None, title=\"Vector store to use for tool retrieval\")\n", "    class Config:\n\t        arbitrary_types_allowed = True\n\t    def memorize_episode(self, episode: Episode) -> None:\n\t        \"\"\"Memorize an episode.\"\"\"\n\t        self.num_episodes += 1\n\t        self.store[str(self.num_episodes)] = episode\n\t        self._embed_episode(episode)\n\t    def summarize_and_memorize_episode(self, episode: Episode) -> str:\n\t        \"\"\"Summarize and memorize an episode.\"\"\"\n\t        summary = self._summarize(episode.thoughts, episode.action, episode.result)\n", "        episode.summary = summary\n\t        self.memorize_episode(episode)\n\t        return summary\n\t    def _summarize(self, thoughts: Dict[str, Any], action: Dict[str, Any], result: str) -> str:\n\t        \"\"\"Summarize an episode.\"\"\"\n\t        prompt = get_template()\n\t        llm_chain = LLMChain(prompt=prompt, llm=self.llm)\n\t        try:\n\t            result = llm_chain.predict(\n\t                thoughts=thoughts,\n", "                action=action,\n\t                result=result\n\t            )\n\t        except Exception as e:\n\t            raise Exception(f\"Error: {e}\")\n\t        return result\n\t    def remember_all_episode(self) -> List[Episode]:\n\t        \"\"\"Remember all episodes.\"\"\"\n\t        return self.store\n\t    def remember_recent_episodes(self, n: int = 5) -> List[Episode]:\n", "        \"\"\"Remember recent episodes.\"\"\"\n\t        if not self.store:  # if empty\n\t            return self.store\n\t        n = min(n, len(self.store))\n\t        return list(self.store.values())[-n:]\n\t    def remember_last_episode(self) -> Episode:\n\t        \"\"\"Remember last episode.\"\"\"\n\t        if not self.store:\n\t            return None\n\t        return self.store[-1]\n", "    def remember_related_episodes(self, query: str, k: int = 5) -> List[Episode]:\n\t        \"\"\"Remember related episodes to a query.\"\"\"\n\t        if self.vector_store is None:\n\t            return []\n\t        relevant_documents = self.vector_store.similarity_search(query, k=k)\n\t        result = []\n\t        for d in relevant_documents:\n\t            episode = Episode(\n\t                thoughts=d.metadata[\"thoughts\"],\n\t                action=d.metadata[\"action\"],\n", "                result=d.metadata[\"result\"],\n\t                summary=d.metadata[\"summary\"]\n\t            )\n\t            result.append(episode)\n\t        return result\n\t    def _embed_episode(self, episode: Episode) -> None:\n\t        \"\"\"Embed an episode and add it to the vector store.\"\"\"\n\t        texts = [episode.summary]\n\t        metadatas = [{\"index\": self.num_episodes,\n\t                      \"thoughts\": episode.thoughts,\n", "                      \"action\": episode.action,\n\t                      \"result\": episode.result,\n\t                      \"summary\": episode.summary}]\n\t        if self.vector_store is None:\n\t            self.vector_store = FAISS.from_texts(\n\t                texts=texts, embedding=self.embeddings, metadatas=metadatas)\n\t        else:\n\t            self.vector_store.add_texts(texts=texts, metadatas=metadatas)\n\t    def save_local(self, path: str) -> None:\n\t        \"\"\"Save the vector store locally.\"\"\"\n", "        self.vector_store.save_local(folder_path=path)\n\t    def load_local(self, path: str) -> None:\n\t        \"\"\"Load the vector store locally.\"\"\"\n\t        self.vector_store = FAISS.load_local(\n\t            folder_path=path, embeddings=self.embeddings)\n"]}
