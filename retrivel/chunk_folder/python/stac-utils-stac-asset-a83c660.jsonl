{"filename": "tests/test_functions.py", "chunked_list": ["import os.path\n\tfrom asyncio import Queue\n\tfrom pathlib import Path\n\tfrom typing import Any\n\timport pytest\n\timport stac_asset\n\tfrom pystac import Asset, Collection, Item, ItemCollection\n\tfrom pytest import LogCaptureFixture\n\tfrom stac_asset import (\n\t    AssetOverwriteError,\n", "    Config,\n\t    ConfigError,\n\t    DownloadError,\n\t    DownloadWarning,\n\t    ErrorStrategy,\n\t    FileNameStrategy,\n\t)\n\tpytestmark = [\n\t    pytest.mark.asyncio,\n\t]\n", "async def test_download_item(tmp_path: Path, item: Item) -> None:\n\t    item = await stac_asset.download_item(item, tmp_path)\n\t    assert os.path.exists(tmp_path / \"20201211_223832_CS2.jpg\")\n\t    asset = item.assets[\"data\"]\n\t    assert asset.href == str(tmp_path / \"20201211_223832_CS2.jpg\")\n\tasync def test_download_item_with_file_name(tmp_path: Path, item: Item) -> None:\n\t    await stac_asset.download_item(item, tmp_path, file_name=\"item.json\")\n\t    item = Item.from_file(str(tmp_path / \"item.json\"))\n\t    assert item.assets[\"data\"].href == \"./20201211_223832_CS2.jpg\"\n\tasync def test_download_missing_asset_error(tmp_path: Path, item: Item) -> None:\n", "    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n\t    with pytest.raises(DownloadError):\n\t        await stac_asset.download_item(item, tmp_path, config=Config(warn=False))\n\tasync def test_download_missing_asset_warn(tmp_path: Path, item: Item) -> None:\n\t    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n\t    with pytest.warns(DownloadWarning):\n\t        await stac_asset.download_item(item, tmp_path, config=Config(warn=True))\n\tasync def test_download_missing_asset_keep(\n\t    tmp_path: Path, item: Item, data_path: Path\n\t) -> None:\n", "    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n\t    with pytest.warns(DownloadWarning):\n\t        item = await stac_asset.download_item(\n\t            item,\n\t            tmp_path,\n\t            config=Config(error_strategy=ErrorStrategy.KEEP, warn=True),\n\t        )\n\t    assert item.assets[\"does-not-exist\"].href == str(data_path / \"not-a-file.md5\")\n\tasync def test_download_missing_asset_delete(tmp_path: Path, item: Item) -> None:\n\t    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n", "    with pytest.warns(DownloadWarning):\n\t        item = await stac_asset.download_item(\n\t            item,\n\t            tmp_path,\n\t            config=Config(error_strategy=ErrorStrategy.DELETE, warn=True),\n\t        )\n\t    assert \"does-not-exist\" not in item.assets\n\tasync def test_download_missing_asset_fail_fast(\n\t    tmp_path: Path, item: Item, caplog: LogCaptureFixture\n\t) -> None:\n", "    item.assets[\"does-not-exist\"] = Asset(\"not-a-file.md5\")\n\t    with pytest.raises(FileNotFoundError):\n\t        await stac_asset.download_item(\n\t            item,\n\t            tmp_path,\n\t            config=Config(fail_fast=True),\n\t        )\n\tasync def test_download_item_collection(\n\t    tmp_path: Path, item_collection: ItemCollection\n\t) -> None:\n", "    item_collection = await stac_asset.download_item_collection(\n\t        item_collection, tmp_path\n\t    )\n\t    assert os.path.exists(tmp_path / \"test-item\" / \"20201211_223832_CS2.jpg\")\n\t    asset = item_collection.items[0].assets[\"data\"]\n\t    assert asset.href == str(tmp_path / \"test-item/20201211_223832_CS2.jpg\")\n\tasync def test_download_item_collection_with_file_name(\n\t    tmp_path: Path, item_collection: ItemCollection\n\t) -> None:\n\t    await stac_asset.download_item_collection(\n", "        item_collection, tmp_path, file_name=\"item-collection.json\"\n\t    )\n\t    item_collection = ItemCollection.from_file(str(tmp_path / \"item-collection.json\"))\n\t    assert (\n\t        item_collection.items[0].assets[\"data\"].href\n\t        == \"./test-item/20201211_223832_CS2.jpg\"\n\t    )\n\tasync def test_download_collection(tmp_path: Path, collection: Collection) -> None:\n\t    collection = await stac_asset.download_collection(\n\t        collection, tmp_path, file_name=\"collection.json\"\n", "    )\n\t    assert os.path.exists(tmp_path / \"collection.json\")\n\t    assert os.path.exists(tmp_path / \"20201211_223832_CS2.jpg\")\n\t    asset = collection.assets[\"data\"]\n\t    assert asset.href == \"./20201211_223832_CS2.jpg\"\n\tasync def test_item_download_no_directory(tmp_path: Path, item: Item) -> None:\n\t    with pytest.raises(DownloadError):\n\t        await stac_asset.download_item(\n\t            item, tmp_path / \"doesnt-exist\", config=Config(make_directory=False)\n\t        )\n", "async def test_item_download_key(tmp_path: Path, item: Item) -> None:\n\t    await stac_asset.download_item(\n\t        item, tmp_path, config=Config(file_name_strategy=FileNameStrategy.KEY)\n\t    )\n\t    assert Path(tmp_path / \"data.jpg\").exists()\n\tasync def test_item_download_same_file_name(tmp_path: Path, item: Item) -> None:\n\t    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n\t    with pytest.raises(AssetOverwriteError):\n\t        await stac_asset.download_item(item, tmp_path)\n\tasync def test_include(tmp_path: Path, item: Item) -> None:\n", "    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n\t    item = await stac_asset.download_item(\n\t        item, tmp_path, config=Config(include=[\"data\"])\n\t    )\n\t    assert len(item.assets) == 1\n\tasync def test_exclude(tmp_path: Path, item: Item) -> None:\n\t    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n\t    await stac_asset.download_item(\n\t        item, tmp_path, config=Config(exclude=[\"other-data\"])\n\t    )\n", "async def test_cant_include_and_exclude(tmp_path: Path, item: Item) -> None:\n\t    item.assets[\"other-data\"] = item.assets[\"data\"].clone()\n\t    with pytest.raises(ConfigError):\n\t        await stac_asset.download_item(\n\t            item, tmp_path, config=Config(include=[\"data\"], exclude=[\"other-data\"])\n\t        )\n\t@pytest.mark.network_access\n\tasync def test_multiple_clients(tmp_path: Path, item: Item) -> None:\n\t    item.assets[\"remote\"] = Asset(\n\t        href=\"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\",\n", "    )\n\t    item = await stac_asset.download_item(\n\t        item, tmp_path, config=Config(file_name_strategy=FileNameStrategy.KEY)\n\t    )\n\tasync def test_queue(tmp_path: Path, item: Item) -> None:\n\t    queue: Queue[Any] = Queue()\n\t    item = await stac_asset.download_item(item, tmp_path, queue=queue)\n\t    assert not queue.empty()\n"]}
{"filename": "tests/test_config.py", "chunked_list": ["import pytest\n\tfrom stac_asset import Config, ConfigError\n\tdef test_validate_default() -> None:\n\t    config = Config()\n\t    config.validate()\n\tdef test_validate_include_and_exclude() -> None:\n\t    config = Config(include=[\"foo\"], exclude=[\"bar\"])\n\t    with pytest.raises(ConfigError):\n\t        config.validate()\n\tdef test_warn_and_fail_fast() -> None:\n", "    config = Config(warn=True, fail_fast=True)\n\t    with pytest.raises(ConfigError):\n\t        config.validate()\n"]}
{"filename": "tests/test_cli.py", "chunked_list": ["import json\n\timport os\n\tfrom pathlib import Path\n\timport pytest\n\timport stac_asset._cli\n\tfrom click.testing import CliRunner\n\tfrom pystac import Item, ItemCollection\n\tdef test_download_item(tmp_path: Path, item_path: Path) -> None:\n\t    runner = CliRunner()\n\t    result = runner.invoke(\n", "        stac_asset._cli.cli,\n\t        [\"download\", str(item_path), str(tmp_path)],\n\t    )\n\t    assert result.exit_code == 0\n\tdef test_download_item_stdin_stdout(tmp_path: Path, item: Item) -> None:\n\t    previous_working_directory = os.getcwd()\n\t    os.chdir(tmp_path)\n\t    try:\n\t        item_as_str = json.dumps(\n\t            item.to_dict(include_self_link=True, transform_hrefs=False)\n", "        )\n\t        runner = CliRunner(mix_stderr=False)\n\t        result = runner.invoke(stac_asset._cli.cli, [\"download\"], input=item_as_str)\n\t        assert result.exit_code == 0, result.stdout\n\t        Item.from_dict(json.loads(result.stdout))\n\t    finally:\n\t        os.chdir(previous_working_directory)\n\tdef test_download_item_collection_stdin_stdout(\n\t    tmp_path: Path, item_collection: ItemCollection\n\t) -> None:\n", "    previous_working_directory = os.getcwd()\n\t    os.chdir(tmp_path)\n\t    try:\n\t        item_collection_as_str = json.dumps(\n\t            item_collection.to_dict(transform_hrefs=False)\n\t        )\n\t        runner = CliRunner(mix_stderr=False)\n\t        result = runner.invoke(\n\t            stac_asset._cli.cli, [\"download\"], input=item_collection_as_str\n\t        )\n", "        assert result.exit_code == 0, result.stdout\n\t        ItemCollection.from_dict(json.loads(result.stdout))\n\t    finally:\n\t        os.chdir(previous_working_directory)\n\t@pytest.mark.network_access\n\tdef test_download_item_s3_requester_pays(tmp_path: Path) -> None:\n\t    runner = CliRunner()\n\t    result = runner.invoke(\n\t        stac_asset._cli.cli,\n\t        [\n", "            \"download\",\n\t            \"https://landsatlook.usgs.gov/stac-server/collections/landsat-c2l2-sr/items/LC09_L2SP_092068_20230607_20230609_02_T1_SR\",\n\t            str(tmp_path),\n\t            \"--s3-requester-pays\",\n\t            \"-i\",\n\t            \"thumbnail\",\n\t            \"--alternate-assets\",\n\t            \"s3\",\n\t        ],\n\t    )\n", "    assert result.exit_code == 0\n"]}
{"filename": "tests/test_s3_client.py", "chunked_list": ["import os.path\n\tfrom pathlib import Path\n\tfrom typing import cast\n\timport pystac\n\timport pytest\n\timport stac_asset\n\tfrom pystac import Item\n\tfrom stac_asset import Config, S3Client\n\tpytestmark = [\n\t    pytest.mark.asyncio,\n", "    pytest.mark.network_access,\n\t]\n\t@pytest.fixture\n\tdef asset_href() -> str:\n\t    return \"s3://sentinel-cogs/sentinel-s2-l2a-cogs/42/L/TQ/2023/5/S2B_42LTQ_20230524_0_L2A/thumbnail.jpg\"\n\t@pytest.fixture\n\tdef requester_pays_asset_href() -> str:\n\t    return \"s3://usgs-landsat/collection02/level-2/standard/oli-tirs/2023/092/068/LC09_L2SP_092068_20230522_20230524_02_T2/LC09_L2SP_092068_20230522_20230524_02_T2_thumb_small.jpeg\"\n\t@pytest.fixture\n\tdef requester_pays_item(data_path: Path) -> Item:\n", "    return cast(\n\t        Item,\n\t        pystac.read_file(\n\t            str(data_path / \"LC09_L2SP_092068_20230607_20230609_02_T1_SR.json\")\n\t        ),\n\t    )\n\tasync def test_download(tmp_path: Path, asset_href: str) -> None:\n\t    async with S3Client() as client:\n\t        await client.download_href(asset_href, tmp_path / \"out.jpg\")\n\t    assert os.path.getsize(tmp_path / \"out.jpg\") == 6060\n", "async def test_download_requester_pays_asset(\n\t    tmp_path: Path, requester_pays_asset_href: str\n\t) -> None:\n\t    async with S3Client(requester_pays=True) as client:\n\t        if not await client.has_credentials():\n\t            pytest.skip(\"aws credentials are invalid or not present\")\n\t        await client.download_href(requester_pays_asset_href, tmp_path / \"out.jpg\")\n\t        assert os.path.getsize(tmp_path / \"out.jpg\") == 6114\n\tasync def test_download_requester_pays_item(\n\t    tmp_path: Path, requester_pays_item: Item\n", ") -> None:\n\t    await stac_asset.download_item(\n\t        requester_pays_item,\n\t        tmp_path,\n\t        config=Config(\n\t            include=[\"thumbnail\"], s3_requester_pays=True, alternate_assets=[\"s3\"]\n\t        ),\n\t    )\n\t    assert (\n\t        os.path.getsize(\n", "            tmp_path / \"LC09_L2SP_092068_20230607_20230609_02_T1_thumb_small.jpeg\"\n\t        )\n\t        == 19554\n\t    )\n"]}
{"filename": "tests/test_planetary_computer_client.py", "chunked_list": ["import os.path\n\tfrom pathlib import Path\n\timport pytest\n\tfrom stac_asset import Config, PlanetaryComputerClient\n\tpytestmark = [\n\t    pytest.mark.network_access,\n\t    pytest.mark.asyncio,\n\t]\n\t@pytest.fixture\n\tdef asset_href() -> str:\n", "    return \"https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/48/X/VR/2023/05/24/S2B_MSIL2A_20230524T084609_N0509_R107_T48XVR_20230524T120352.SAFE/GRANULE/L2A_T48XVR_A032451_20230524T084603/QI_DATA/T48XVR_20230524T084609_PVI.tif\"\n\tasync def test_download(tmp_path: Path, asset_href: str) -> None:\n\t    async with await PlanetaryComputerClient.from_config(Config()) as client:\n\t        await client.download_href(asset_href, tmp_path / \"out.tif\")\n\t    assert os.path.getsize(tmp_path / \"out.tif\") == 4096\n"]}
{"filename": "tests/test_filesystem_client.py", "chunked_list": ["import os.path\n\tfrom pathlib import Path\n\timport pytest\n\tfrom stac_asset import FilesystemClient\n\tpytestmark = pytest.mark.asyncio\n\t@pytest.fixture\n\tdef asset_href() -> str:\n\t    return str(Path(__file__).parent / \"data\" / \"20201211_223832_CS2.jpg\")\n\tasync def test_download(tmp_path: Path, asset_href: str) -> None:\n\t    async with FilesystemClient() as client:\n", "        await client.download_href(asset_href, tmp_path / \"out.jpg\")\n\t    assert os.path.getsize(tmp_path / \"out.jpg\") == 31367\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["from pathlib import Path\n\tfrom typing import Any\n\timport pytest\n\tfrom pystac import Collection, Item, ItemCollection\n\tfrom pytest import Config, Parser\n\t@pytest.fixture\n\tdef asset_path() -> str:\n\t    return str(Path(__file__).parent / \"data\" / \"20201211_223832_CS2.jpg\")\n\t@pytest.fixture\n\tdef item_path() -> Path:\n", "    return Path(__file__).parent / \"data\" / \"item.json\"\n\t@pytest.fixture\n\tdef data_path() -> Path:\n\t    return Path(__file__).parent / \"data\"\n\t@pytest.fixture\n\tdef item(item_path: Path) -> Item:\n\t    return Item.from_file(str(item_path))\n\t@pytest.fixture\n\tdef collection() -> Collection:\n\t    return Collection.from_file(str(Path(__file__).parent / \"data\" / \"collection.json\"))\n", "@pytest.fixture\n\tdef item_collection(item: Item) -> ItemCollection:\n\t    item.make_asset_hrefs_absolute()\n\t    return ItemCollection([item])\n\tdef pytest_addoption(parser: Parser) -> None:\n\t    parser.addoption(\n\t        \"--network-access\",\n\t        action=\"store_true\",\n\t        default=False,\n\t        help=\"run tests that access the network\",\n", "    )\n\tdef pytest_configure(config: Config) -> None:\n\t    config.addinivalue_line(\n\t        \"markers\",\n\t        \"network_access: marks tests as accessing the network, \"\n\t        \"and disables them by default (enable with --network-access)\",\n\t    )\n\tdef pytest_collection_modifyitems(config: Config, items: Any) -> None:\n\t    if config.getoption(\"--network-access\"):\n\t        return\n", "    skip_network_access = pytest.mark.skip(reason=\"need --network-access option to run\")\n\t    for item in items:\n\t        if \"network_access\" in item.keywords:\n\t            item.add_marker(skip_network_access)\n"]}
{"filename": "tests/test_validate.py", "chunked_list": ["import pytest\n\tfrom stac_asset import ContentTypeError, validate\n\tdef test_content_type() -> None:\n\t    validate.content_type(\"foo\", \"foo\")\n\t    with pytest.raises(ContentTypeError):\n\t        validate.content_type(\"foo\", \"bar\")\n\t    validate.content_type(\n\t        \"image/tiff\", \"image/tiff; application=geotiff; profile=cloud-optimized\"\n\t    )\n\t    validate.content_type(\n", "        \"image/tiff; application=geotiff; profile=cloud-optimized\", \"image/tiff\"\n\t    )\n\t    validate.content_type(\"binary/octet-stream\", \"doesn't matter\")\n\t    validate.content_type(\"application/octet-stream\", \"doesn't matter\")\n"]}
{"filename": "tests/test_earthdata_client.py", "chunked_list": ["import os.path\n\tfrom pathlib import Path\n\timport pytest\n\tfrom stac_asset import EarthdataClient\n\tpytestmark = [\n\t    pytest.mark.skipif(\n\t        os.environ.get(\"EARTHDATA_PAT\") is None,\n\t        reason=\"EARTHDATA_PAT is not set\",\n\t    ),\n\t    pytest.mark.asyncio,\n", "    pytest.mark.network_access,\n\t]\n\tasync def test_download_href(tmp_path: Path) -> None:\n\t    href = \"https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/MYD11A1.061/MYD11A1.A2023145.h14v17.061.2023146183035/MYD11A1.A2023145.h14v17.061.2023146183035.hdf\"\n\t    async with await EarthdataClient.login() as client:\n\t        await client.download_href(href, tmp_path / \"out.hdf\")\n\t        assert os.path.getsize(tmp_path / \"out.hdf\") == 197419\n"]}
{"filename": "docs/conf.py", "chunked_list": ["import importlib.metadata\n\tproject = \"stac-asset\"\n\tcopyright = \"2023, Pete Gadomski\"\n\tauthor = \"Pete Gadomski\"\n\tversion = importlib.metadata.version(\"stac_asset\")\n\trelease = importlib.metadata.version(\"stac_asset\")\n\textensions = [\n\t    \"sphinx.ext.autodoc\",\n\t    \"sphinx.ext.intersphinx\",\n\t    \"sphinx.ext.napoleon\",\n", "]\n\ttemplates_path = [\"_templates\"]\n\texclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\thtml_theme = \"pydata_sphinx_theme\"\n\thtml_static_path = [\"_static\"]\n"]}
{"filename": "src/stac_asset/filesystem_client.py", "chunked_list": ["from __future__ import annotations\n\timport os.path\n\tfrom asyncio import Queue\n\tfrom types import TracebackType\n\tfrom typing import AsyncIterator, Optional, Type\n\timport aiofiles\n\tfrom yarl import URL\n\tfrom .client import Client\n\tfrom .messages import Message, OpenUrl\n\tclass FilesystemClient(Client):\n", "    \"\"\"A simple client for moving files around on the filesystem.\n\t    Mostly used for testing, but could be useful in some real-world cases.\n\t    \"\"\"\n\t    async def open_url(\n\t        self,\n\t        url: URL,\n\t        content_type: Optional[str] = None,\n\t        messages: Optional[Queue[Message]] = None,\n\t    ) -> AsyncIterator[bytes]:\n\t        \"\"\"Iterates over data from a local url.\n", "        Args:\n\t            url: The url to read bytes from\n\t            content_type: The expected content type. Ignored by this client,\n\t                because filesystems don't have content types.\n\t            messages: An optional queue to use for progress reporting\n\t        Yields:\n\t            AsyncIterator[bytes]: An iterator over the file's bytes.\n\t        Raises:\n\t            ValueError: Raised if the url has a scheme. This behavior will\n\t                change if/when we support Windows paths.\n", "        \"\"\"\n\t        if url.scheme:\n\t            raise ValueError(\n\t                \"cannot read a file with the filesystem client if it has a url scheme: \"\n\t                + str(url)\n\t            )\n\t        if messages:\n\t            await messages.put(OpenUrl(size=os.path.getsize(url.path), url=url))\n\t        async with aiofiles.open(url.path, \"rb\") as f:\n\t            async for chunk in f:\n", "                yield chunk\n\t    async def __aenter__(self) -> FilesystemClient:\n\t        return self\n\t    async def __aexit__(\n\t        self,\n\t        exc_type: Optional[Type[BaseException]],\n\t        exc_val: Optional[BaseException],\n\t        exc_tb: Optional[TracebackType],\n\t    ) -> Optional[bool]:\n\t        return None\n"]}
{"filename": "src/stac_asset/earthdata_client.py", "chunked_list": ["from __future__ import annotations\n\timport os\n\tfrom types import TracebackType\n\tfrom typing import Optional, Type\n\tfrom aiohttp import ClientSession\n\tfrom .config import Config\n\tfrom .http_client import HttpClient\n\tclass EarthdataClient(HttpClient):\n\t    \"\"\"Access data from https://www.earthdata.nasa.gov/.\"\"\"\n\t    @classmethod\n", "    async def from_config(cls, config: Config) -> EarthdataClient:\n\t        \"\"\"Logs in to Earthdata and returns the default earthdata client.\n\t        Uses a token stored in the ``EARTHDATA_PAT`` environment variable, if\n\t        the token is not provided in the config.\n\t        Args:\n\t            config: A configuration object.\n\t        Returns:\n\t            EarthdataClient: A logged-in EarthData client.\n\t        \"\"\"\n\t        return await cls.login(config.earthdata_token)\n", "    @classmethod\n\t    async def login(cls, token: Optional[str] = None) -> EarthdataClient:\n\t        \"\"\"Logs in to Earthdata and returns a client.\n\t        If token is not provided, it is read from the ``EARTHDATA_PAT``\n\t        environment variable.\n\t        Args:\n\t            token: The Earthdata bearer token\n\t        Returns:\n\t            EarthdataClient: A client configured to use the bearer token\n\t        \"\"\"\n", "        if token is None:\n\t            try:\n\t                token = os.environ[\"EARTHDATA_PAT\"]\n\t            except KeyError:\n\t                raise ValueError(\n\t                    \"token was not provided, and EARTHDATA_PAT environment variable \"\n\t                    \"not set\"\n\t                )\n\t        session = ClientSession(headers={\"Authorization\": f\"Bearer {token}\"})\n\t        return cls(session)\n", "    async def __aenter__(self) -> EarthdataClient:\n\t        return self\n\t    async def __aexit__(\n\t        self,\n\t        exc_type: Optional[Type[BaseException]],\n\t        exc_val: Optional[BaseException],\n\t        exc_tb: Optional[TracebackType],\n\t    ) -> Optional[bool]:\n\t        await self.close()\n\t        return await super().__aexit__(exc_type, exc_val, exc_tb)\n"]}
{"filename": "src/stac_asset/types.py", "chunked_list": ["from os import PathLike\n\tfrom typing import TYPE_CHECKING, Union\n\tif TYPE_CHECKING:\n\t    from typing import Any\n\t    _PathLike = PathLike[Any]\n\telse:\n\t    _PathLike = PathLike\n\tPathLikeObject = Union[_PathLike, str]\n\t\"\"\"An object representing a file system path, except we exclude `bytes` because\n\t`Path()` doesn't accept `bytes`.\n", "A path-like object is either a str or bytes object representing a path, or an\n\tobject implementing the os.PathLike protocol. An object that supports the\n\tos.PathLike protocol can be converted to a str or bytes file system path by\n\tcalling the os.fspath() function; os.fsdecode() and os.fsencode() can be used to\n\tguarantee a str or bytes result instead, respectively. Introduced by PEP 519.\n\thttps://docs.python.org/3/glossary.html#term-path-like-object\n\t\"\"\"\n"]}
{"filename": "src/stac_asset/http_client.py", "chunked_list": ["from __future__ import annotations\n\tfrom asyncio import Queue\n\tfrom types import TracebackType\n\tfrom typing import AsyncIterator, Optional, Type, TypeVar\n\tfrom aiohttp import ClientSession\n\tfrom yarl import URL\n\tfrom . import validate\n\tfrom .client import Client\n\tfrom .config import Config\n\tfrom .messages import Message, OpenUrl\n", "T = TypeVar(\"T\", bound=\"HttpClient\")\n\tclass HttpClient(Client):\n\t    \"\"\"A simple client for making HTTP requests.\n\t    By default, doesn't do any authentication.\n\t    Configure the session to customize its behavior.\n\t    \"\"\"\n\t    session: ClientSession\n\t    \"\"\"A atiohttp session that will be used for all requests.\"\"\"\n\t    @classmethod\n\t    async def from_config(cls: Type[T], config: Config) -> T:\n", "        \"\"\"Creates the default http client with a vanilla session object.\"\"\"\n\t        # TODO add basic auth\n\t        session = ClientSession()\n\t        return cls(session)\n\t    def __init__(self, session: ClientSession, check_content_type: bool = True) -> None:\n\t        super().__init__()\n\t        self.session = session\n\t        self.check_content_type = check_content_type\n\t    async def open_url(\n\t        self,\n", "        url: URL,\n\t        content_type: Optional[str] = None,\n\t        messages: Optional[Queue[Message]] = None,\n\t    ) -> AsyncIterator[bytes]:\n\t        \"\"\"Opens a url with this client's session and iterates over its bytes.\n\t        Args:\n\t            url: The url to open\n\t            content_type: The expected content type\n\t            messages: An optional queue to use for progress reporting\n\t        Yields:\n", "            AsyncIterator[bytes]: An iterator over the file's bytes\n\t        Raises:\n\t            :py:class:`aiohttp.ClientResponseError`: Raised if the response is not OK\n\t        \"\"\"\n\t        async with self.session.get(url, allow_redirects=True) as response:\n\t            response.raise_for_status()\n\t            if self.check_content_type and content_type:\n\t                validate.content_type(\n\t                    actual=response.content_type, expected=content_type\n\t                )\n", "            if messages:\n\t                await messages.put(OpenUrl(url=url, size=response.content_length))\n\t            async for chunk, _ in response.content.iter_chunks():\n\t                yield chunk\n\t    async def close(self) -> None:\n\t        \"\"\"Close this http client.\n\t        Closes the underlying session.\n\t        \"\"\"\n\t        await self.session.close()\n\t    async def __aenter__(self) -> HttpClient:\n", "        return self\n\t    async def __aexit__(\n\t        self,\n\t        exc_type: Optional[Type[BaseException]],\n\t        exc_val: Optional[BaseException],\n\t        exc_tb: Optional[TracebackType],\n\t    ) -> Optional[bool]:\n\t        await self.close()\n\t        return await super().__aexit__(exc_type, exc_val, exc_tb)\n"]}
{"filename": "src/stac_asset/config.py", "chunked_list": ["from __future__ import annotations\n\timport copy\n\tfrom dataclasses import dataclass, field\n\tfrom typing import List, Optional\n\tfrom .errors import ConfigError\n\tfrom .strategy import ErrorStrategy, FileNameStrategy\n\tDEFAULT_S3_REGION_NAME = \"us-west-2\"\n\tDEFAULT_S3_RETRY_MODE = \"adaptive\"\n\tDEFAULT_S3_MAX_ATTEMPTS = 10\n\t@dataclass\n", "class Config:\n\t    \"\"\"Configuration for downloading items and their assets.\"\"\"\n\t    alternate_assets: List[str] = field(default_factory=list)\n\t    \"\"\"Alternate asset keys to prefer, if available.\"\"\"\n\t    file_name_strategy: FileNameStrategy = FileNameStrategy.FILE_NAME\n\t    \"\"\"The file name strategy to use when downloading assets.\"\"\"\n\t    warn: bool = False\n\t    \"\"\"If an error occurs during download, warn instead of raising the error.\"\"\"\n\t    fail_fast: bool = False\n\t    \"\"\"If an error occurs during download, fail immediately.\n", "    By default, all downloads are completed before raising/warning any errors.\n\t    Mutually exclusive with ``warn``.\n\t    \"\"\"\n\t    error_strategy: ErrorStrategy = ErrorStrategy.DELETE\n\t    \"\"\"The strategy to use when errors occur during download.\"\"\"\n\t    exclude: List[str] = field(default_factory=list)\n\t    \"\"\"Assets to exclude from the download.\n\t    Mutually exclusive with ``include``.\n\t    \"\"\"\n\t    include: List[str] = field(default_factory=list)\n", "    \"\"\"Assets to include in the download.\n\t    Mutually exclusive with ``exclude``.\n\t    \"\"\"\n\t    make_directory: bool = True\n\t    \"\"\"Whether to create the output directory.\n\t    If False, and the output directory does not exist, an error will be raised.\n\t    \"\"\"\n\t    clean: bool = True\n\t    \"\"\"If true, clean up the downloaded file if it errors.\"\"\"\n\t    overwrite: bool = False\n", "    \"\"\"Download files even if they already exist locally.\"\"\"\n\t    earthdata_token: Optional[str] = None\n\t    \"\"\"A token for logging in to Earthdata.\"\"\"\n\t    s3_region_name: str = DEFAULT_S3_REGION_NAME\n\t    \"\"\"Default s3 region.\"\"\"\n\t    s3_requester_pays: bool = False\n\t    \"\"\"If using the s3 client, enable requester pays.\"\"\"\n\t    s3_retry_mode: str = DEFAULT_S3_RETRY_MODE\n\t    \"\"\"The retry mode to use for s3 requests.\"\"\"\n\t    s3_max_attempts: int = DEFAULT_S3_MAX_ATTEMPTS\n", "    \"\"\"The maximum number of attempts when downloading assets from s3.\"\"\"\n\t    def validate(self) -> None:\n\t        \"\"\"Validates this configuration.\n\t        Raises:\n\t            CannotIncludeAndExclude: ``include`` and ``exclude`` are mutually exclusive\n\t        \"\"\"\n\t        if self.include and self.exclude:\n\t            raise ConfigError(\n\t                f\"cannot provide both include and exclude: include={self.include}, \"\n\t                \"exclude={self.exclude}\"\n", "            )\n\t        if self.warn and self.fail_fast:\n\t            raise ConfigError(\"cannot warn and fail fast as the same time\")\n\t    def copy(self) -> Config:\n\t        \"\"\"Returns a deep copy of this config.\n\t        Returns:\n\t            Config: A deep copy of this config.\n\t        \"\"\"\n\t        return copy.deepcopy(self)\n"]}
{"filename": "src/stac_asset/errors.py", "chunked_list": ["from typing import Any, List\n\tclass AssetOverwriteError(Exception):\n\t    \"\"\"Raised when an asset would be overwritten during download.\"\"\"\n\t    def __init__(self, hrefs: List[str]) -> None:\n\t        super().__init__(\n\t            f\"assets have the same file names and would overwrite each other: {hrefs}\"\n\t        )\n\tclass DownloadWarning(Warning):\n\t    \"\"\"A warning for when something couldn't be downloaded.\n\t    Used when we don't want to cancel all downloads, but still inform the user\n", "    about the problem.\n\t    \"\"\"\n\tclass ConfigError(Exception):\n\t    \"\"\"Raised if the configuration is not valid.\"\"\"\n\tclass ContentTypeError(Exception):\n\t    \"\"\"The expected content type does not match the actual content type.\"\"\"\n\t    def __init__(self, actual: str, expected: str, *args: Any, **kwargs: Any) -> None:\n\t        super().__init__(\n\t            f\"the actual content type does not match the expected: actual={actual}, \"\n\t            f\"expected={expected}\",\n", "            *args,\n\t            **kwargs,\n\t        )\n\tclass DownloadError(Exception):\n\t    \"\"\"A collection of exceptions encountered while downloading.\"\"\"\n\t    exceptions: List[Exception]\n\t    def __init__(self, exceptions: List[Exception], *args: Any, **kwargs: Any) -> None:\n\t        self.exceptions = exceptions\n\t        messages = list()\n\t        for exception in exceptions:\n", "            messages.append(str(exception))\n\t        super().__init__(\"\\n\".join(messages), *args, **kwargs)\n"]}
{"filename": "src/stac_asset/client.py", "chunked_list": ["from __future__ import annotations\n\tfrom abc import ABC, abstractmethod\n\tfrom asyncio import Lock, Queue, QueueFull\n\tfrom pathlib import Path\n\tfrom types import TracebackType\n\tfrom typing import AsyncIterator, Dict, Optional, Type, TypeVar\n\timport aiofiles\n\tfrom yarl import URL\n\tfrom .config import Config\n\tfrom .messages import (\n", "    Message,\n\t    WriteChunk,\n\t)\n\tfrom .types import PathLikeObject\n\tT = TypeVar(\"T\", bound=\"Client\")\n\tclass Client(ABC):\n\t    \"\"\"An abstract base class for all clients.\"\"\"\n\t    @classmethod\n\t    async def from_config(cls: Type[T], config: Config) -> T:\n\t        \"\"\"Creates a client using the provided configuration.\n", "        Needed because some client setups require async operations.\n\t        Returns:\n\t            T: A new client Client\n\t        \"\"\"\n\t        return cls()\n\t    def __init__(self) -> None:\n\t        pass\n\t    @abstractmethod\n\t    async def open_url(\n\t        self,\n", "        url: URL,\n\t        content_type: Optional[str] = None,\n\t        messages: Optional[Queue[Message]] = None,\n\t    ) -> AsyncIterator[bytes]:\n\t        \"\"\"Opens a url and yields an iterator over its bytes.\n\t        This is the core method that all clients must implement.\n\t        Args:\n\t            url: The input url\n\t            content_type: The expected content type, to be checked by the client\n\t                implementations\n", "            messages: An optional queue to use for progress reporting\n\t        Yields:\n\t            AsyncIterator[bytes]: An iterator over chunks of the read file\n\t        \"\"\"\n\t        # https://github.com/python/mypy/issues/5070\n\t        if False:  # pragma: no cover\n\t            yield\n\t    async def open_href(\n\t        self,\n\t        href: str,\n", "        content_type: Optional[str] = None,\n\t        messages: Optional[Queue[Message]] = None,\n\t    ) -> AsyncIterator[bytes]:\n\t        \"\"\"Opens a href and yields an iterator over its bytes.\n\t        Args:\n\t            href: The input href\n\t            content_type: The expected content type\n\t            messages: An optional queue to use for progress reporting\n\t        Yields:\n\t            AsyncIterator[bytes]: An iterator over chunks of the read file\n", "        \"\"\"\n\t        async for chunk in self.open_url(\n\t            URL(href), content_type=content_type, messages=messages\n\t        ):\n\t            yield chunk\n\t    async def download_href(\n\t        self,\n\t        href: str,\n\t        path: PathLikeObject,\n\t        clean: bool = True,\n", "        content_type: Optional[str] = None,\n\t        messages: Optional[Queue[Message]] = None,\n\t    ) -> None:\n\t        \"\"\"Downloads a file to the local filesystem.\n\t        Args:\n\t            href: The input href\n\t            path: The output file path\n\t            clean: If an error occurs, delete the output file if it exists\n\t            content_type: The expected content type\n\t            messages: An optional queue to use for progress reporting\n", "        \"\"\"\n\t        try:\n\t            async with aiofiles.open(path, mode=\"wb\") as f:\n\t                async for chunk in self.open_href(\n\t                    href, content_type=content_type, messages=messages\n\t                ):\n\t                    await f.write(chunk)\n\t                    if messages:\n\t                        try:\n\t                            messages.put_nowait(\n", "                                WriteChunk(href=href, path=Path(path), size=len(chunk))\n\t                            )\n\t                        except QueueFull:\n\t                            pass\n\t        except Exception as err:\n\t            path_as_path = Path(path)\n\t            if clean and path_as_path.exists():\n\t                try:\n\t                    path_as_path.unlink()\n\t                except Exception:\n", "                    pass\n\t            raise err\n\t    async def close(self) -> None:\n\t        \"\"\"Close this client.\"\"\"\n\t        pass\n\t    async def __aenter__(self) -> Client:\n\t        return self\n\t    async def __aexit__(\n\t        self,\n\t        exc_type: Optional[Type[BaseException]],\n", "        exc_val: Optional[BaseException],\n\t        exc_tb: Optional[TracebackType],\n\t    ) -> Optional[bool]:\n\t        return None\n\tclass Clients:\n\t    \"\"\"An async-safe cache of clients.\"\"\"\n\t    lock: Lock\n\t    clients: Dict[Type[Client], Client]\n\t    config: Config\n\t    def __init__(self, config: Config) -> None:\n", "        self.lock = Lock()\n\t        self.clients = dict()\n\t        self.config = config\n\t    async def get_client(self, href: str) -> Client:\n\t        \"\"\"Gets a client for the provided href.\n\t        Args:\n\t            href: The file href to download\n\t        Returns:\n\t            Client: An instance of that client.\n\t        \"\"\"\n", "        from .filesystem_client import FilesystemClient\n\t        from .http_client import HttpClient\n\t        from .planetary_computer_client import PlanetaryComputerClient\n\t        from .s3_client import S3Client\n\t        url = URL(href)\n\t        if not url.host:\n\t            client_class: Type[Client] = FilesystemClient\n\t        elif url.scheme == \"s3\":\n\t            client_class = S3Client\n\t        elif url.host.endswith(\"blob.core.windows.net\"):\n", "            client_class = PlanetaryComputerClient\n\t        elif url.scheme == \"http\" or url.scheme == \"https\":\n\t            client_class = HttpClient\n\t        else:\n\t            raise ValueError(f\"could not guess client class for href: {href}\")\n\t        async with self.lock:\n\t            if client_class in self.clients:\n\t                return self.clients[client_class]\n\t            else:\n\t                client = await client_class.from_config(self.config)\n", "                self.clients[client_class] = client\n\t                return client\n\t    async def close_all(self) -> None:\n\t        \"\"\"Close all clients.\"\"\"\n\t        async with self.lock:\n\t            for client in self.clients.values():\n\t                await client.close()\n"]}
{"filename": "src/stac_asset/_cli.py", "chunked_list": ["import asyncio\n\timport json\n\timport logging\n\timport os\n\timport sys\n\tfrom asyncio import Queue\n\tfrom dataclasses import dataclass\n\tfrom typing import TYPE_CHECKING, Any, List, Optional, Union\n\timport click\n\timport click_logging\n", "import tqdm\n\tfrom pystac import Item, ItemCollection\n\tfrom . import Config, ErrorStrategy, _functions\n\tfrom .client import Clients\n\tfrom .config import DEFAULT_S3_MAX_ATTEMPTS, DEFAULT_S3_RETRY_MODE\n\tfrom .messages import (\n\t    ErrorAssetDownload,\n\t    FinishAssetDownload,\n\t    OpenUrl,\n\t    StartAssetDownload,\n", "    WriteChunk,\n\t)\n\tlogger = logging.getLogger(__name__)\n\tclick_logging.basic_config(logger)\n\t# Needed until we drop Python 3.8\n\tif TYPE_CHECKING:\n\t    AnyQueue = Queue[Any]\n\t    Tqdm = tqdm.tqdm[Any]\n\telse:\n\t    AnyQueue = Queue\n", "    Tqdm = tqdm.tqdm\n\t@click.group()\n\tdef cli() -> None:\n\t    \"\"\"Work with STAC assets.\n\t    See each subcommand's help text for more information:\n\t        $ stac-asset download --help\n\t    \"\"\"\n\t@cli.command()\n\t@click_logging.simple_verbosity_option(logger)  # type: ignore\n\t@click.argument(\"href\", required=False)\n", "@click.argument(\"directory\", required=False)\n\t@click.option(\n\t    \"-a\",\n\t    \"--alternate-assets\",\n\t    help=\"Alternate asset hrefs to prefer, if available\",\n\t    multiple=True,\n\t)\n\t@click.option(\"-i\", \"--include\", help=\"Asset keys to include\", multiple=True)\n\t@click.option(\n\t    \"-x\",\n", "    \"--exclude\",\n\t    help=\"Asset keys to exclude (can't be used with include)\",\n\t    multiple=True,\n\t)\n\t@click.option(\"-f\", \"--file-name\", help=\"The output file name\")\n\t@click.option(\n\t    \"-q\",\n\t    \"--quiet\",\n\t    help=\"Do not print anything to standard output.\",\n\t    default=False,\n", "    is_flag=True,\n\t    show_default=True,\n\t)\n\t@click.option(\n\t    \"--s3-requester-pays\",\n\t    help=\"If downloading via the s3 client, enable requester pays\",\n\t    default=False,\n\t    is_flag=True,\n\t    show_default=True,\n\t)\n", "@click.option(\n\t    \"--s3-retry-mode\",\n\t    help=\"If downloading via the s3 client, the retry mode (standard, legacy, and \"\n\t    \"adaptive)\",\n\t    default=DEFAULT_S3_RETRY_MODE,\n\t)\n\t@click.option(\n\t    \"--s3-max-attempts\",\n\t    help=\"If downloading via the s3 client, the max number of retries\",\n\t    default=DEFAULT_S3_MAX_ATTEMPTS,\n", ")\n\t@click.option(\n\t    \"-w\",\n\t    \"--warn\",\n\t    help=\"Warn on download errors, instead of erroring\",\n\t    default=False,\n\t    is_flag=True,\n\t    show_default=True,\n\t)\n\t@click.option(\n", "    \"-k\",\n\t    \"--keep\",\n\t    help=(\n\t        \"If warning on error, keep assets that couldn't be downloaded with their \"\n\t        \"original hrefs. If false, delete those assets from the item.\"\n\t    ),\n\t    default=False,\n\t    is_flag=True,\n\t    show_default=True,\n\t)\n", "@click.option(\n\t    \"--fail-fast\",\n\t    help=\"Fail immediately on download error, instead of waiting until all are \"\n\t    \"complete. Mutually exclusive with --warn\",\n\t    default=False,\n\t    is_flag=True,\n\t    show_default=True,\n\t)\n\t@click.option(\n\t    \"--overwrite\",\n", "    help=\"Overwrite existing files if they exist on the filesystem\",\n\t    default=False,\n\t    is_flag=True,\n\t    show_default=True,\n\t)\n\t# TODO add option to disable content type checking\n\tdef download(\n\t    href: Optional[str],\n\t    directory: Optional[str],\n\t    alternate_assets: List[str],\n", "    include: List[str],\n\t    exclude: List[str],\n\t    file_name: Optional[str],\n\t    quiet: bool,\n\t    s3_requester_pays: bool,\n\t    s3_retry_mode: str,\n\t    s3_max_attempts: int,\n\t    warn: bool,\n\t    keep: bool,\n\t    fail_fast: bool,\n", "    overwrite: bool,\n\t) -> None:\n\t    \"\"\"Download STAC assets from an item or item collection.\n\t    If href is not provided, or is ``-``, the item or item collection is parsed\n\t    as JSON from standard input. If the directory is not provided, the current\n\t    working directory is used.\n\t    These three examples are equivalent, and download the assets to the current\n\t    working directory:\n\t        $ stac-asset download item.json\n\t        $ stac-asset download item.json .\n", "        $ cat item.json | stac-asset download\n\t    To only include certain asset keys:\n\t        $ stac-asset download -i asset-key-to-include item.json\n\t    \"\"\"\n\t    asyncio.run(\n\t        download_async(\n\t            href,\n\t            directory,\n\t            alternate_assets,\n\t            include,\n", "            exclude,\n\t            file_name,\n\t            quiet,\n\t            s3_requester_pays,\n\t            s3_retry_mode,\n\t            s3_max_attempts,\n\t            warn=warn,\n\t            keep=keep,\n\t            fail_fast=fail_fast,\n\t            overwrite=overwrite,\n", "        )\n\t    )\n\tasync def download_async(\n\t    href: Optional[str],\n\t    directory: Optional[str],\n\t    alternate_assets: List[str],\n\t    include: List[str],\n\t    exclude: List[str],\n\t    file_name: Optional[str],\n\t    quiet: bool,\n", "    s3_requester_pays: bool,\n\t    s3_retry_mode: str,\n\t    s3_max_attempts: int,\n\t    warn: bool,\n\t    keep: bool,\n\t    fail_fast: bool,\n\t    overwrite: bool,\n\t) -> None:\n\t    config = Config(\n\t        alternate_assets=alternate_assets,\n", "        include=include,\n\t        exclude=exclude,\n\t        s3_requester_pays=s3_requester_pays,\n\t        s3_retry_mode=s3_retry_mode,\n\t        s3_max_attempts=s3_max_attempts,\n\t        error_strategy=ErrorStrategy.KEEP if keep else ErrorStrategy.DELETE,\n\t        warn=warn,\n\t        fail_fast=fail_fast,\n\t        overwrite=overwrite,\n\t    )\n", "    if href is None or href == \"-\":\n\t        input_dict = json.load(sys.stdin)\n\t    else:\n\t        input_dict = json.loads(await read_file(href, config))\n\t    if directory is None:\n\t        directory_str = os.getcwd()\n\t    else:\n\t        directory_str = str(directory)\n\t    if quiet:\n\t        queue = None\n", "    else:\n\t        queue = Queue()\n\t    type_ = input_dict.get(\"type\")\n\t    if type_ is None:\n\t        if not quiet:\n\t            print(\"ERROR: missing 'type' field on input dictionary\", file=sys.stderr)\n\t        sys.exit(1)\n\t    elif type_ == \"Feature\":\n\t        item = Item.from_dict(input_dict)\n\t        if href:\n", "            item.set_self_href(href)\n\t            item.make_asset_hrefs_absolute()\n\t        async def download() -> Union[Item, ItemCollection]:\n\t            return await _functions.download_item(\n\t                item,\n\t                directory_str,\n\t                file_name=file_name,\n\t                config=config,\n\t                queue=queue,\n\t            )\n", "    elif type_ == \"FeatureCollection\":\n\t        item_collection = ItemCollection.from_dict(input_dict)\n\t        async def download() -> Union[Item, ItemCollection]:\n\t            return await _functions.download_item_collection(\n\t                item_collection,\n\t                directory_str,\n\t                file_name=file_name,\n\t                config=config,\n\t                queue=queue,\n\t            )\n", "    else:\n\t        if not quiet:\n\t            print(f\"ERROR: unsupported 'type' field: {type_}\", file=sys.stderr)\n\t        sys.exit(2)\n\t    task = asyncio.create_task(report_progress(queue))\n\t    output = await download()\n\t    if queue:\n\t        await queue.put(None)\n\t    await task\n\t    if not quiet:\n", "        json.dump(output.to_dict(transform_hrefs=False), sys.stdout)\n\tasync def read_file(href: str, config: Config) -> bytes:\n\t    clients = Clients(config)\n\t    async with await clients.get_client(href) as client:\n\t        data = b\"\"\n\t        async for chunk in client.open_href(href):\n\t            data += chunk\n\t        return data\n\tasync def report_progress(queue: Optional[AnyQueue]) -> None:\n\t    if queue is None:\n", "        return\n\t    progress_bar = tqdm.tqdm(\n\t        unit=\"B\",\n\t        unit_scale=True,\n\t        unit_divisor=1024,\n\t    )\n\t    sizes = dict()\n\t    assets = 0\n\t    done = 0\n\t    errors = 0\n", "    total = 0\n\t    n = 0\n\t    progress_bar.set_postfix_str(f\"{errors} errors\")\n\t    while True:\n\t        message = await queue.get()\n\t        if isinstance(message, StartAssetDownload):\n\t            assets += 1\n\t            progress_bar.set_description(f\"{done}/{assets}\")\n\t        elif isinstance(message, OpenUrl):\n\t            if message.size:\n", "                total += message.size\n\t                sizes[str(message.url)] = message.size\n\t                progress_bar.reset(total=total)\n\t                progress_bar.update(n)\n\t        elif isinstance(message, FinishAssetDownload):\n\t            done += 1\n\t            progress_bar.set_description_str(f\"{done}/{assets}\")\n\t        elif isinstance(message, ErrorAssetDownload):\n\t            done += 1\n\t            errors += 1\n", "            if message.href in sizes:\n\t                total -= sizes[message.href]\n\t                progress_bar.reset(total=total)\n\t                progress_bar.update(n)\n\t            progress_bar.set_postfix_str(f\"{errors} errors\")\n\t            progress_bar.set_description_str(f\"{done}/{assets}\")\n\t        elif isinstance(message, WriteChunk):\n\t            n += message.size\n\t            progress_bar.update(message.size)\n\t        elif message is None:\n", "            progress_bar.close()\n\t            return\n\t@dataclass\n\tclass Download:\n\t    key: str\n\t    item_id: Optional[str]\n\t    href: str\n\t    path: str\n\t    progress_bar: Tqdm\n\tif __name__ == \"__main__\":\n", "    cli()\n"]}
{"filename": "src/stac_asset/planetary_computer_client.py", "chunked_list": ["from __future__ import annotations\n\timport datetime\n\tfrom asyncio import Lock, Queue\n\tfrom datetime import timezone\n\tfrom types import TracebackType\n\tfrom typing import Any, AsyncIterator, Dict, Optional, Type\n\timport dateutil.parser\n\tfrom aiohttp import ClientSession\n\tfrom yarl import URL\n\tfrom .http_client import HttpClient\n", "DEFAULT_SAS_TOKEN_ENDPOINT = \"https://planetarycomputer.microsoft.com/api/sas/v1/token\"\n\tclass _Token:\n\t    expiry: datetime.datetime\n\t    token: str\n\t    @classmethod\n\t    def from_dict(cls, data: Dict[str, Any]) -> _Token:\n\t        try:\n\t            expiry = dateutil.parser.isoparse(data[\"msft:expiry\"])\n\t        except KeyError:\n\t            raise ValueError(f\"missing 'msft:expiry' key in dict: {data}\")\n", "        try:\n\t            token = data[\"token\"]\n\t        except KeyError:\n\t            raise ValueError(f\"missing 'token' key in dict: {data}\")\n\t        return cls(expiry=expiry, token=token)\n\t    def __init__(self, expiry: datetime.datetime, token: str) -> None:\n\t        self.expiry = expiry\n\t        self.token = token\n\t    def ttl(self) -> float:\n\t        return (self.expiry - datetime.datetime.now(timezone.utc)).total_seconds()\n", "    def __str__(self) -> str:\n\t        return self.token\n\tclass PlanetaryComputerClient(HttpClient):\n\t    \"\"\"Open and download assets from Microsoft's Planetary Computer.\n\t    Heavily cribbed from\n\t    https://github.com/microsoft/planetary-computer-sdk-for-python/blob/main/planetary_computer/sas.py,\n\t    thanks Tom Augspurger!\n\t    \"\"\"\n\t    _cache: Dict[URL, _Token]\n\t    _cache_lock: Lock\n", "    token_request_url: URL\n\t    def __init__(\n\t        self,\n\t        session: ClientSession,\n\t        sas_token_endpoint: str = DEFAULT_SAS_TOKEN_ENDPOINT,\n\t    ) -> None:\n\t        super().__init__(session)\n\t        self._cache = dict()\n\t        self._cache_lock = Lock()\n\t        self.sas_token_endpoint = URL(sas_token_endpoint)\n", "    async def open_url(\n\t        self,\n\t        url: URL,\n\t        content_type: Optional[str] = None,\n\t        messages: Optional[Queue[Any]] = None,\n\t    ) -> AsyncIterator[bytes]:\n\t        \"\"\"Opens a url and iterates over its bytes.\n\t        Includes functionality to sign the url with a SAS token fetched from\n\t        this client's ``sas_token_endpoint``. Tokens are cached on a per-client\n\t        basis to prevent a large number of requests when fetching many assets.\n", "        Not every URL is modified with a SAS token. We only modify the url if:\n\t        - The url is in Azure blob storage\n\t        - The url is not in the public thumbnail storage account\n\t        - The url hasn't already signed (we check this by seeing if the url has\n\t            SAS-like query parameters)\n\t        Args:\n\t            url: The url to open\n\t            content_type: The expected content type\n\t            messages: An optional queue to use for progress reporting\n\t        Yields:\n", "            AsyncIterator[bytes]: An iterator over the file's bytes\n\t        \"\"\"\n\t        if (\n\t            url.host is not None\n\t            and url.host.endswith(\".blob.core.windows.net\")\n\t            and not url.host == \"ai4edatasetspublicassets.blob.core.windows.net\"\n\t            and not set(url.query) & {\"st\", \"se\", \"sp\"}\n\t        ):\n\t            url = await self._sign(url)\n\t        async for chunk in super().open_url(\n", "            url, content_type=content_type, messages=messages\n\t        ):\n\t            yield chunk\n\t    async def _sign(self, url: URL) -> URL:\n\t        assert url.host\n\t        account_name = url.host.split(\".\")[0]\n\t        container_name = url.path.split(\"/\", 2)[1]\n\t        token = await self._get_token(account_name, container_name)\n\t        return URL(str(url.with_query(None)) + \"?\" + token, encoded=False)\n\t    async def _get_token(self, account_name: str, container_name: str) -> str:\n", "        url = self.sas_token_endpoint.joinpath(account_name, container_name)\n\t        async with self._cache_lock:\n\t            token = self._cache.get(url)\n\t            if token is None or token.ttl() < 60:\n\t                response = await self.session.get(url)\n\t                response.raise_for_status()\n\t                token = _Token.from_dict(await response.json())\n\t                self._cache[url] = token\n\t        return str(token)\n\t    async def __aenter__(self) -> PlanetaryComputerClient:\n", "        return self\n\t    async def __aexit__(\n\t        self,\n\t        exc_type: Optional[Type[BaseException]],\n\t        exc_val: Optional[BaseException],\n\t        exc_tb: Optional[TracebackType],\n\t    ) -> Optional[bool]:\n\t        await self.close()\n\t        return await super().__aexit__(exc_type, exc_val, exc_tb)\n"]}
{"filename": "src/stac_asset/__init__.py", "chunked_list": ["\"\"\"Read and download STAC items, item collections, collections, and assets.\n\tThe core class is :py:class:`Client`, which defines a common interface for\n\taccessing assets. There are also some free functions, :py:func:`download_item`\n\tand :py:func:`download_item_collection`, which provide simple one-shot\n\tinterfaces for downloading assets.\n\tWriting items, item collections, collections, and assets is currently\n\tunsupported, but is on the roadmap.\n\t\"\"\"\n\tfrom ._functions import (\n\t    download_collection,\n", "    download_item,\n\t    download_item_collection,\n\t)\n\tfrom .client import Client\n\tfrom .config import Config\n\tfrom .earthdata_client import EarthdataClient\n\tfrom .errors import (\n\t    AssetOverwriteError,\n\t    ConfigError,\n\t    ContentTypeError,\n", "    DownloadError,\n\t    DownloadWarning,\n\t)\n\tfrom .filesystem_client import FilesystemClient\n\tfrom .http_client import HttpClient\n\tfrom .planetary_computer_client import PlanetaryComputerClient\n\tfrom .s3_client import S3Client\n\tfrom .strategy import ErrorStrategy, FileNameStrategy\n\t# Keep this list sorted\n\t__all__ = [\n", "    \"AssetOverwriteError\",\n\t    \"Client\",\n\t    \"Config\",\n\t    \"ConfigError\",\n\t    \"ContentTypeError\",\n\t    \"DownloadError\",\n\t    \"DownloadWarning\",\n\t    \"EarthdataClient\",\n\t    \"ErrorStrategy\",\n\t    \"FileNameStrategy\",\n", "    \"FilesystemClient\",\n\t    \"HttpClient\",\n\t    \"PlanetaryComputerClient\",\n\t    \"S3Client\",\n\t    \"download_collection\",\n\t    \"download_item\",\n\t    \"download_item_collection\",\n\t]\n"]}
{"filename": "src/stac_asset/s3_client.py", "chunked_list": ["from __future__ import annotations\n\tfrom asyncio import Queue\n\tfrom types import TracebackType\n\tfrom typing import AsyncIterator, Optional, Type\n\timport aiobotocore.session\n\timport botocore.config\n\tfrom aiobotocore.session import AioSession\n\tfrom botocore import UNSIGNED\n\tfrom yarl import URL\n\tfrom . import validate\n", "from .client import Client\n\tfrom .config import (\n\t    DEFAULT_S3_MAX_ATTEMPTS,\n\t    DEFAULT_S3_REGION_NAME,\n\t    DEFAULT_S3_RETRY_MODE,\n\t    Config,\n\t)\n\tfrom .messages import Message, OpenUrl\n\tclass S3Client(Client):\n\t    \"\"\"A client for interacting with s3 urls.\"\"\"\n", "    session: AioSession\n\t    \"\"\"The session that will be used for all s3 requests.\"\"\"\n\t    region_name: str\n\t    \"\"\"The region that all clients will be rooted in.\"\"\"\n\t    requester_pays: bool\n\t    \"\"\"If True, add `--request-payer requester` to all requests.\"\"\"\n\t    retry_mode: str\n\t    \"\"\"The retry mode.\"\"\"\n\t    max_attempts: int\n\t    \"\"\"The maximum number of attempts.\"\"\"\n", "    @classmethod\n\t    async def from_config(cls, config: Config) -> S3Client:\n\t        \"\"\"Creates an s3 client from a config.\n\t        Args:\n\t            config: The config object\n\t        Returns:\n\t            S3Client: A new s3 client\n\t        \"\"\"\n\t        return cls(\n\t            requester_pays=config.s3_requester_pays,\n", "            region_name=config.s3_region_name,\n\t            retry_mode=config.s3_retry_mode,\n\t            max_attempts=config.s3_max_attempts,\n\t        )\n\t    def __init__(\n\t        self,\n\t        requester_pays: bool = False,\n\t        region_name: str = DEFAULT_S3_REGION_NAME,\n\t        retry_mode: str = DEFAULT_S3_RETRY_MODE,\n\t        max_attempts: int = DEFAULT_S3_MAX_ATTEMPTS,\n", "    ) -> None:\n\t        super().__init__()\n\t        self.session = aiobotocore.session.get_session()\n\t        self.region_name = region_name\n\t        self.requester_pays = requester_pays\n\t        self.retry_mode = retry_mode\n\t        self.max_attempts = max_attempts\n\t    async def open_url(\n\t        self,\n\t        url: URL,\n", "        content_type: Optional[str] = None,\n\t        messages: Optional[Queue[Message]] = None,\n\t    ) -> AsyncIterator[bytes]:\n\t        \"\"\"Opens an s3 url and iterates over its bytes.\n\t        Args:\n\t            url: The url to open\n\t            content_type: The expected content type\n\t            messages: An optional queue to use for progress reporting\n\t        Yields:\n\t            AsyncIterator[bytes]: An iterator over the file's bytes\n", "        Raises:\n\t            SchemeError: Raised if the url's scheme is not ``s3``\n\t        \"\"\"\n\t        retries = {\n\t            \"max_attempts\": self.max_attempts,\n\t            \"mode\": self.retry_mode,\n\t        }\n\t        if self.requester_pays:\n\t            config = botocore.config.Config(retries=retries)\n\t        else:\n", "            config = botocore.config.Config(signature_version=UNSIGNED, retries=retries)\n\t        async with self.session.create_client(\n\t            \"s3\",\n\t            region_name=self.region_name,\n\t            config=config,\n\t        ) as client:\n\t            bucket = url.host\n\t            key = url.path[1:]\n\t            params = {\n\t                \"Bucket\": bucket,\n", "                \"Key\": key,\n\t            }\n\t            if self.requester_pays:\n\t                params[\"RequestPayer\"] = \"requester\"\n\t            response = await client.get_object(**params)\n\t            if content_type:\n\t                validate.content_type(response[\"ContentType\"], content_type)\n\t            if messages:\n\t                await messages.put(OpenUrl(url=url, size=response[\"ContentLength\"]))\n\t            async for chunk in response[\"Body\"]:\n", "                yield chunk\n\t    async def has_credentials(self) -> bool:\n\t        \"\"\"Returns true if the sessions has credentials.\"\"\"\n\t        return await self.session.get_credentials() is not None\n\t    async def __aenter__(self) -> S3Client:\n\t        return self\n\t    async def __aexit__(\n\t        self,\n\t        exc_type: Optional[Type[BaseException]],\n\t        exc_val: Optional[BaseException],\n", "        exc_tb: Optional[TracebackType],\n\t    ) -> Optional[bool]:\n\t        return None\n"]}
{"filename": "src/stac_asset/_functions.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport json\n\timport os.path\n\timport warnings\n\tfrom asyncio import Queue, Task\n\tfrom dataclasses import dataclass\n\tfrom pathlib import Path\n\tfrom types import TracebackType\n\tfrom typing import (\n", "    TYPE_CHECKING,\n\t    Any,\n\t    List,\n\t    Optional,\n\t    Set,\n\t    Type,\n\t    Union,\n\t)\n\timport pystac.utils\n\tfrom pystac import Asset, Collection, Item, ItemCollection, STACError\n", "from yarl import URL\n\tfrom .client import Clients\n\tfrom .config import Config\n\tfrom .errors import AssetOverwriteError, DownloadError, DownloadWarning\n\tfrom .messages import (\n\t    ErrorAssetDownload,\n\t    FinishAssetDownload,\n\t    Message,\n\t    StartAssetDownload,\n\t)\n", "from .strategy import ErrorStrategy, FileNameStrategy\n\tfrom .types import PathLikeObject\n\t# Needed until we drop Python 3.8\n\tif TYPE_CHECKING:\n\t    AnyQueue = Queue[Any]\n\telse:\n\t    AnyQueue = Queue\n\t@dataclass\n\tclass Download:\n\t    owner: Union[Item, Collection]\n", "    key: str\n\t    asset: Asset\n\t    path: Path\n\t    clients: Clients\n\t    config: Config\n\t    async def download(\n\t        self,\n\t        messages: Optional[AnyQueue],\n\t    ) -> Union[Download, WrappedError]:\n\t        if not os.path.exists(self.path) or self.config.overwrite:\n", "            try:\n\t                await download_asset(\n\t                    self.key,\n\t                    self.asset,\n\t                    self.path,\n\t                    config=self.config,\n\t                    messages=messages,\n\t                    clients=self.clients,\n\t                )\n\t            except Exception as error:\n", "                if self.config.fail_fast:\n\t                    raise error\n\t                else:\n\t                    return WrappedError(self, error)\n\t        self.asset.href = str(self.path)\n\t        return self\n\tclass Downloads:\n\t    clients: Clients\n\t    config: Config\n\t    downloads: List[Download]\n", "    def __init__(self, config: Config) -> None:\n\t        config.validate()\n\t        self.config = config\n\t        self.downloads = list()\n\t        self.clients = Clients(config)\n\t    async def add(\n\t        self, stac_object: Union[Item, Collection], root: Path, file_name: Optional[str]\n\t    ) -> None:\n\t        stac_object = make_link_hrefs_absolute(stac_object)\n\t        # Will fail if the stac object doesn't have a self href and there's\n", "        # relative asset hrefs\n\t        stac_object = make_asset_hrefs_absolute(stac_object)\n\t        if file_name:\n\t            stac_object.set_self_href(str(Path(root) / file_name))\n\t        else:\n\t            stac_object.set_self_href(None)\n\t        asset_file_names: Set[str] = set()\n\t        assets = dict()\n\t        for key, asset in (\n\t            (k, a)\n", "            for k, a in stac_object.assets.items()\n\t            if (not self.config.include or k in self.config.include)\n\t            and (not self.config.exclude or k not in self.config.exclude)\n\t        ):\n\t            if self.config.file_name_strategy == FileNameStrategy.FILE_NAME:\n\t                asset_file_name = os.path.basename(URL(asset.href).path)\n\t            elif self.config.file_name_strategy == FileNameStrategy.KEY:\n\t                asset_file_name = key + Path(asset.href).suffix\n\t            else:\n\t                raise ValueError(\n", "                    f\"unexpected file name strategy: {self.config.file_name_strategy}\"\n\t                )\n\t            if asset_file_name in asset_file_names:\n\t                raise AssetOverwriteError(list(asset_file_names))\n\t            asset_file_names.add(asset_file_name)\n\t            assets[key] = asset\n\t            self.downloads.append(\n\t                Download(\n\t                    owner=stac_object,\n\t                    key=key,\n", "                    asset=asset,\n\t                    path=root / asset_file_name,\n\t                    clients=self.clients,\n\t                    config=self.config,\n\t                )\n\t            )\n\t        stac_object.assets = assets\n\t    async def download(self, messages: Optional[AnyQueue]) -> None:\n\t        tasks: Set[Task[Union[Download, WrappedError]]] = set()\n\t        for download in self.downloads:\n", "            task = asyncio.create_task(\n\t                download.download(\n\t                    messages=messages,\n\t                )\n\t            )\n\t            tasks.add(task)\n\t            task.add_done_callback(tasks.discard)\n\t        try:\n\t            results = await asyncio.gather(*tasks)\n\t        except Exception as error:\n", "            # We failed fast\n\t            for task in tasks:\n\t                if not task.done():\n\t                    task.cancel()\n\t            await asyncio.gather(*tasks, return_exceptions=True)\n\t            raise error\n\t        exceptions = list()\n\t        for result in results:\n\t            if isinstance(result, WrappedError):\n\t                if self.config.error_strategy == ErrorStrategy.DELETE:\n", "                    del result.download.owner.assets[result.download.key]\n\t                else:\n\t                    # Simple check to make sure we haven't added other\n\t                    # strategies that we're not handling\n\t                    assert self.config.error_strategy == ErrorStrategy.KEEP\n\t                if self.config.warn:\n\t                    warnings.warn(str(result.error), DownloadWarning)\n\t                else:\n\t                    exceptions.append(result.error)\n\t        if exceptions:\n", "            raise DownloadError(exceptions)\n\t    async def __aenter__(self) -> Downloads:\n\t        return self\n\t    async def __aexit__(\n\t        self,\n\t        exc_type: Optional[Type[BaseException]],\n\t        exc_val: Optional[BaseException],\n\t        exc_tb: Optional[TracebackType],\n\t    ) -> None:\n\t        await self.clients.close_all()\n", "class WrappedError:\n\t    download: Download\n\t    error: Exception\n\t    def __init__(self, download: Download, error: Exception) -> None:\n\t        self.download = download\n\t        self.error = error\n\tasync def download_item(\n\t    item: Item,\n\t    directory: PathLikeObject,\n\t    file_name: Optional[str] = None,\n", "    config: Optional[Config] = None,\n\t    queue: Optional[AnyQueue] = None,\n\t) -> Item:\n\t    \"\"\"Downloads an item to the local filesystem.\n\t    Args:\n\t        item: The :py:class:`pystac.Item`.\n\t        directory: The output directory that will hold the items and assets.\n\t        file_name: The name of the item file to save. If not provided, will not\n\t            be saved.\n\t        config: The download configuration\n", "        queue: An optional queue to use for progress reporting\n\t    Returns:\n\t        Item: The `~pystac.Item`, with the updated asset hrefs and self href.\n\t    Raises:\n\t        ValueError: Raised if the item doesn't have any assets.\n\t    \"\"\"\n\t    async with Downloads(config or Config()) as downloads:\n\t        await downloads.add(item, Path(directory), file_name)\n\t        await downloads.download(queue)\n\t    self_href = item.get_self_href()\n", "    if self_href:\n\t        make_asset_hrefs_relative(item)\n\t        d = item.to_dict(include_self_link=True, transform_hrefs=False)\n\t        with open(self_href, \"w\") as f:\n\t            json.dump(d, f)\n\t    return item\n\tasync def download_collection(\n\t    collection: Collection,\n\t    directory: PathLikeObject,\n\t    file_name: Optional[str] = None,\n", "    config: Optional[Config] = None,\n\t    queue: Optional[AnyQueue] = None,\n\t) -> Collection:\n\t    \"\"\"Downloads a collection to the local filesystem.\n\t    Does not download the collection's items' assets -- use\n\t    :py:func:`download_item_collection` to download multiple items.\n\t    Args:\n\t        collection: A pystac collection\n\t        directory: The destination directory\n\t        file_name: The name of the collection file to save. If not provided,\n", "            will not be saved.\n\t        config: The download configuration\n\t        queue: An optional queue to use for progress reporting\n\t    Returns:\n\t        Collection: The collection, with updated asset hrefs\n\t    Raises:\n\t        CantIncludeAndExclude: Raised if both include and exclude are not None.\n\t    \"\"\"\n\t    async with Downloads(config or Config()) as downloads:\n\t        await downloads.add(collection, Path(directory), file_name)\n", "        await downloads.download(queue)\n\t    self_href = collection.get_self_href()\n\t    if self_href:\n\t        make_asset_hrefs_relative(collection)\n\t        d = collection.to_dict(include_self_link=True, transform_hrefs=False)\n\t        with open(self_href, \"w\") as f:\n\t            json.dump(d, f)\n\t    return collection\n\tasync def download_item_collection(\n\t    item_collection: ItemCollection,\n", "    directory: PathLikeObject,\n\t    file_name: Optional[str] = None,\n\t    config: Optional[Config] = None,\n\t    queue: Optional[AnyQueue] = None,\n\t) -> ItemCollection:\n\t    \"\"\"Downloads an item collection to the local filesystem.\n\t    Args:\n\t        item_collection: The item collection to download\n\t        directory: The destination directory\n\t        file_name: The name of the item collection file to save. If not\n", "            provided, will not be saved.\n\t        config: The download configuration\n\t        queue: An optional queue to use for progress reporting\n\t    Returns:\n\t        ItemCollection: The item collection, with updated asset hrefs\n\t    Raises:\n\t        CantIncludeAndExclude: Raised if both include and exclude are not None.\n\t    \"\"\"\n\t    async with Downloads(config or Config()) as downloads:\n\t        for item in item_collection.items:\n", "            item.set_self_href(None)\n\t            root = Path(directory) / item.id\n\t            await downloads.add(item, root, None)\n\t        await downloads.download(queue)\n\t    if file_name:\n\t        dest_href = Path(directory) / file_name\n\t        for item in item_collection.items:\n\t            for asset in item.assets.values():\n\t                asset.href = pystac.utils.make_relative_href(\n\t                    asset.href, str(dest_href), start_is_dir=False\n", "                )\n\t        item_collection.save_object(dest_href=str(dest_href))\n\t    return item_collection\n\tasync def download_asset(\n\t    key: str,\n\t    asset: Asset,\n\t    path: Path,\n\t    config: Config,\n\t    messages: Optional[Queue[Message]] = None,\n\t    clients: Optional[Clients] = None,\n", ") -> Asset:\n\t    \"\"\"Downloads an asset.\n\t    Args:\n\t        key: The asset key\n\t        asset: The asset\n\t        path: The path to which the asset will be downloaded\n\t        config: The download configuration\n\t        messages: An optional queue to use for progress reporting\n\t        clients: A async-safe cache of clients. If not provided, a new one\n\t            will be created.\n", "    Returns:\n\t        Asset: The asset with an updated href\n\t    Raises:\n\t        ValueError: Raised if the asset does not have an absolute href\n\t    \"\"\"\n\t    if clients is None:\n\t        clients = Clients(config)\n\t    if not path.parent.exists():\n\t        if config.make_directory:\n\t            path.parent.mkdir(parents=True, exist_ok=True)\n", "        else:\n\t            raise FileNotFoundError(f\"output directory does not exist: {path.parent}\")\n\t    href = get_absolute_asset_href(\n\t        asset=asset, alternate_assets=config.alternate_assets\n\t    )\n\t    if href is None:\n\t        raise ValueError(f\"asset '{key}' does not have an absolute href: {asset.href}\")\n\t    client = await clients.get_client(href)\n\t    if messages:\n\t        if asset.owner:\n", "            item_id = asset.owner.id\n\t        else:\n\t            item_id = None\n\t        await messages.put(\n\t            StartAssetDownload(key=key, href=href, path=path, item_id=item_id)\n\t        )\n\t    try:\n\t        await client.download_href(\n\t            href,\n\t            path,\n", "            clean=config.clean,\n\t            content_type=asset.media_type,\n\t            messages=messages,\n\t        )\n\t    except Exception as err:\n\t        if messages:\n\t            await messages.put(ErrorAssetDownload(key=key, href=href, path=path))\n\t        raise err\n\t    if messages:\n\t        await messages.put(FinishAssetDownload(key=key, href=href, path=path))\n", "    return asset\n\tdef make_asset_hrefs_relative(\n\t    stac_object: Union[Item, Collection]\n\t) -> Union[Item, Collection]:\n\t    # Copied from\n\t    # https://github.com/stac-utils/pystac/blob/381cf89fc25c15142fb5a187d905e22681de42a2/pystac/item.py#L284C5-L298C20\n\t    # until a fix for https://github.com/stac-utils/pystac/issues/1199 is\n\t    # released.\n\t    self_href = stac_object.get_self_href()\n\t    for asset in stac_object.assets.values():\n", "        if pystac.utils.is_absolute_href(asset.href):\n\t            if self_href is None:\n\t                raise STACError(\n\t                    \"Cannot make asset HREFs relative \" \"if no self_href is set.\"\n\t                )\n\t            asset.href = pystac.utils.make_relative_href(asset.href, self_href)\n\t    return stac_object\n\tdef make_asset_hrefs_absolute(\n\t    stac_object: Union[Item, Collection]\n\t) -> Union[Item, Collection]:\n", "    # Copied from\n\t    # https://github.com/stac-utils/pystac/blob/381cf89fc25c15142fb5a187d905e22681de42a2/pystac/item.py#L309C3-L319C1\n\t    # until a fix for https://github.com/stac-utils/pystac/issues/1199 is\n\t    # released.\n\t    self_href = stac_object.get_self_href()\n\t    for asset in stac_object.assets.values():\n\t        if not pystac.utils.is_absolute_href(asset.href):\n\t            if self_href is None:\n\t                raise STACError(\n\t                    \"Cannot make asset HREFs absolute if no self_href is set.\"\n", "                )\n\t            asset.href = pystac.utils.make_absolute_href(asset.href, self_href)\n\t    return stac_object\n\tdef make_link_hrefs_absolute(\n\t    stac_object: Union[Item, Collection], drop: bool = True\n\t) -> Union[Item, Collection]:\n\t    # This could be in pystac w/ STACObject as the input+output type\n\t    links = list()\n\t    for link in stac_object.links:\n\t        absolute_href = link.get_absolute_href()\n", "        if absolute_href:\n\t            link.target = absolute_href\n\t            links.append(link)\n\t        elif not drop:\n\t            raise ValueError(f\"cannot make link's href absolute: {link}\")\n\t    stac_object.links = links\n\t    return stac_object\n\tdef get_absolute_asset_href(asset: Asset, alternate_assets: List[str]) -> Optional[str]:\n\t    alternate = asset.extra_fields.get(\"alternate\")\n\t    if not isinstance(alternate, dict):\n", "        alternate = None\n\t    if alternate and alternate_assets:\n\t        for alternate_asset in alternate_assets:\n\t            if alternate_asset in alternate:\n\t                try:\n\t                    href = alternate[alternate_asset][\"href\"]\n\t                    if asset.owner:\n\t                        start_href = asset.owner.get_self_href()\n\t                    else:\n\t                        start_href = None\n", "                    return pystac.utils.make_absolute_href(\n\t                        href, start_href, start_is_dir=False\n\t                    )\n\t                except KeyError:\n\t                    raise ValueError(\n\t                        \"invalid alternate asset definition (missing href): \"\n\t                        f\"{alternate}\"\n\t                    )\n\t    return asset.get_absolute_href()\n"]}
{"filename": "src/stac_asset/validate.py", "chunked_list": ["from .errors import ContentTypeError\n\tALLOWABLE_PAIRS = [\n\t    (\"image/tiff\", \"image/tiff; application=geotiff; profile=cloud-optimized\")\n\t]\n\tIGNORED_CONTENT_TYPES = [\"binary/octet-stream\", \"application/octet-stream\"]\n\tdef content_type(actual: str, expected: str) -> None:\n\t    \"\"\"Validates that the actual content type matches the expected.\n\t    This is more complicated than a simple string comparison, because we want to\n\t    allow TIFF when COG is expected, etc.\n\t    Args:\n", "        actual: The actual content type\n\t        expected: The expected content type\n\t    Raises:\n\t        ContentTypeError: Raised if the actual doesn't match the expected.\n\t    \"\"\"\n\t    if (\n\t        actual != expected\n\t        and actual not in IGNORED_CONTENT_TYPES\n\t        and (actual, expected) not in ALLOWABLE_PAIRS\n\t        and (expected, actual) not in ALLOWABLE_PAIRS\n", "    ):\n\t        raise ContentTypeError(actual=actual, expected=expected)\n"]}
{"filename": "src/stac_asset/strategy.py", "chunked_list": ["from enum import Enum, auto\n\tclass FileNameStrategy(Enum):\n\t    \"\"\"Strategy to use for naming files.\"\"\"\n\t    FILE_NAME = auto()\n\t    \"\"\"Save the asset with the file name in its href.\n\t    Could potentially conflict with another asset with the same file name but\n\t    different path.\n\t    \"\"\"\n\t    KEY = auto()\n\t    \"\"\"Save the asset with its key as its file name.\"\"\"\n", "class ErrorStrategy(Enum):\n\t    \"\"\"Strategy to use when encountering errors during download.\"\"\"\n\t    KEEP = auto()\n\t    \"\"\"Keep the asset on the item with its original href.\"\"\"\n\t    DELETE = auto()\n\t    \"\"\"Delete the asset from the item.\"\"\"\n"]}
{"filename": "src/stac_asset/messages.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom pathlib import Path\n\tfrom typing import Optional\n\tfrom yarl import URL\n\t@dataclass\n\tclass Message:\n\t    \"\"\"A message about downloading.\"\"\"\n\t@dataclass\n\tclass StartAssetDownload(Message):\n\t    \"\"\"Sent when an asset starts downloading.\"\"\"\n", "    key: str\n\t    \"\"\"The asset key.\"\"\"\n\t    item_id: Optional[str]\n\t    \"\"\"The item id.\"\"\"\n\t    href: str\n\t    \"\"\"The asset href.\"\"\"\n\t    path: Path\n\t    \"\"\"The local path that the asset is being downloaded to.\"\"\"\n\t@dataclass\n\tclass ErrorAssetDownload(Message):\n", "    \"\"\"Sent when an asset starts downloading.\"\"\"\n\t    key: str\n\t    \"\"\"The asset key.\"\"\"\n\t    href: str\n\t    \"\"\"The asset href.\"\"\"\n\t    path: Path\n\t    \"\"\"The local path that the asset is being downloaded to.\"\"\"\n\t@dataclass\n\tclass FinishAssetDownload(Message):\n\t    \"\"\"Sent when an asset finishes downloading.\"\"\"\n", "    key: str\n\t    \"\"\"The asset key.\"\"\"\n\t    href: str\n\t    \"\"\"The asset href.\"\"\"\n\t    path: Path\n\t    \"\"\"The local path that the asset is being downloaded to.\"\"\"\n\t@dataclass\n\tclass WriteChunk(Message):\n\t    \"\"\"Sent when a chunk is written to disk.\"\"\"\n\t    href: str\n", "    \"\"\"The asset href.\"\"\"\n\t    path: Path\n\t    \"\"\"The local path that the asset is being downloaded to.\"\"\"\n\t    size: int\n\t    \"\"\"The number of bytes written.\"\"\"\n\t@dataclass\n\tclass OpenUrl(Message):\n\t    \"\"\"Sent when a url is first opened.\"\"\"\n\t    url: URL\n\t    \"\"\"The URL\"\"\"\n", "    size: Optional[int]\n\t    \"\"\"The file size.\"\"\"\n"]}
