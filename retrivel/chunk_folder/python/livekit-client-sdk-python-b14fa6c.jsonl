{"filename": "setup.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport pathlib\n\tfrom setuptools import setup\n\there = pathlib.Path(__file__).parent.resolve()\n\tlong_description = (here / \"README.md\").read_text(encoding=\"utf-8\")\n\tsetup(\n\t    name=\"livekit\",\n\t    version=\"0.2.3\",\n", "    description=\"LiveKit Python Client SDK for LiveKit\",\n\t    long_description=long_description,\n\t    long_description_content_type=\"text/markdown\",\n\t    url=\"https://github.com/livekit/client-sdk-python\",\n\t    classifiers=[\n\t        \"Development Status :: 3 - Alpha\",\n\t        \"Intended Audience :: Developers\",\n\t        \"License :: OSI Approved :: Apache Software License\",\n\t        \"Programming Language :: Python :: 3\",\n\t        \"Programming Language :: Python :: 3.7\",\n", "        \"Programming Language :: Python :: 3.8\",\n\t        \"Programming Language :: Python :: 3.9\",\n\t        \"Programming Language :: Python :: 3.10\",\n\t        \"Programming Language :: Python :: 3 :: Only\",\n\t    ],\n\t    keywords=\"webrtc, livekit\",\n\t    license=\"Apache-2.0\",\n\t    packages=[\"livekit\"],\n\t    python_requires=\">=3.7, <4\",\n\t    install_requires=[\"pyee>=11.0.0\",\n", "                      \"protobuf>=3.1.0\", \"types-protobuf>=3.1.0\"],\n\t    package_data={\n\t        \"livekit\": ['lib/*/*/*.*', '_proto/*.py'],\n\t    },\n\t    project_urls={\n\t        \"Documentation\": \"https://docs.livekit.io\",\n\t        \"Website\": \"https://livekit.io/\",\n\t        \"Source\": \"https://github.com/livekit/client-sdk-python/\",\n\t    },\n\t)\n"]}
{"filename": "examples/publish_hue.py", "chunked_list": ["import asyncio\n\timport colorsys\n\timport logging\n\tfrom signal import SIGINT, SIGTERM\n\timport numpy as np\n\timport livekit\n\tURL = 'ws://localhost:7880'\n\tTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'  # noqa\n\tasync def publish_frames(source: livekit.VideoSource):\n\t    argb_frame = livekit.ArgbFrame(\n", "        livekit.VideoFormatType.FORMAT_ARGB, 1280, 720)\n\t    arr = np.ctypeslib.as_array(argb_frame.data)\n\t    framerate = 1 / 30\n\t    hue = 0.0\n\t    while True:\n\t        frame = livekit.VideoFrame(\n\t            0, livekit.VideoRotation.VIDEO_ROTATION_0, argb_frame.to_i420())\n\t        rgb = colorsys.hsv_to_rgb(hue, 1.0, 1.0)\n\t        rgb = [(x * 255) for x in rgb] # type: ignore\n\t        argb_color = np.array(rgb + [255], dtype=np.uint8)\n", "        arr.flat[::4] = argb_color[0]\n\t        arr.flat[1::4] = argb_color[1]\n\t        arr.flat[2::4] = argb_color[2]\n\t        arr.flat[3::4] = argb_color[3]\n\t        source.capture_frame(frame)\n\t        hue += framerate/3  # 3s for a full cycle\n\t        if hue >= 1.0:\n\t            hue = 0.0\n\t        try:\n\t            await asyncio.sleep(framerate)\n", "        except asyncio.CancelledError:\n\t            break\n\tasync def main():\n\t    room = livekit.Room()\n\t    logging.info(\"connecting to %s\", URL)\n\t    try:\n\t        await room.connect(URL, TOKEN)\n\t        logging.info(\"connected to room %s\", room.name)\n\t    except livekit.ConnectError as e:\n\t        logging.error(\"failed to connect to the room: %s\", e)\n", "        return False\n\t    # publish a track\n\t    source = livekit.VideoSource()\n\t    source_task = asyncio.create_task(publish_frames(source))\n\t    track = livekit.LocalVideoTrack.create_video_track(\"hue\", source)\n\t    options = livekit.TrackPublishOptions()\n\t    options.source = livekit.TrackSource.SOURCE_CAMERA\n\t    publication = await room.local_participant.publish_track(track, options)\n\t    logging.info(\"published track %s\", publication.sid)\n\t    try:\n", "        await room.run()\n\t    except asyncio.CancelledError:\n\t        logging.info(\"closing the room\")\n\t        source_task.cancel()\n\t        await source_task\n\t        await room.disconnect()\n\tif __name__ == \"__main__\":\n\t    logging.basicConfig(level=logging.INFO, handlers=[\n\t                        logging.FileHandler(\"publish_hue.log\"), logging.StreamHandler()])\n\t    loop = asyncio.get_event_loop()\n", "    main_task = asyncio.ensure_future(main())\n\t    for signal in [SIGINT, SIGTERM]:\n\t        loop.add_signal_handler(signal, main_task.cancel)\n\t    try:\n\t        loop.run_until_complete(main_task)\n\t    finally:\n\t        loop.close()\n"]}
{"filename": "examples/basic_room.py", "chunked_list": ["import asyncio\n\timport logging\n\tfrom signal import SIGINT, SIGTERM\n\tfrom typing import Union\n\timport livekit\n\tURL = 'ws://localhost:7880'\n\tTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'\n\tasync def main() -> None:\n\t    room = livekit.Room()\n\t    @room.listens_to(\"participant_connected\")\n", "    def on_participant_connected(participant: livekit.RemoteParticipant) -> None:\n\t        logging.info(\n\t            \"participant connected: %s %s\", participant.sid, participant.identity)\n\t    @room.listens_to(\"participant_disconnected\")\n\t    def on_participant_disconnected(participant: livekit.RemoteParticipant):\n\t        logging.info(\"participant disconnected: %s %s\",\n\t                     participant.sid, participant.identity)\n\t    @room.listens_to(\"local_track_published\")\n\t    def on_local_track_published(publication: livekit.LocalTrackPublication,\n\t                                 track: Union[livekit.LocalAudioTrack,\n", "                                              livekit.LocalVideoTrack]):\n\t        logging.info(\"local track published: %s\", publication.sid)\n\t    @room.listens_to(\"active_speakers_changed\")\n\t    def on_active_speakers_changed(speakers: list[livekit.Participant]):\n\t        logging.info(\"active speakers changed: %s\", speakers)\n\t    @room.listens_to(\"local_track_unpublished\")\n\t    def on_local_track_unpublished(publication: livekit.LocalTrackPublication):\n\t        logging.info(\"local track unpublished: %s\", publication.sid)\n\t    @room.listens_to(\"track_published\")\n\t    def on_track_published(publication: livekit.RemoteTrackPublication,\n", "                           participant: livekit.RemoteParticipant):\n\t        logging.info(\"track published: %s from participant %s (%s)\",\n\t                     publication.sid, participant.sid, participant.identity)\n\t    @room.listens_to(\"track_unpublished\")\n\t    def on_track_unpublished(publication: livekit.RemoteTrackPublication,\n\t                             participant: livekit.RemoteParticipant):\n\t        logging.info(\"track unpublished: %s\", publication.sid)\n\t    # Keep a reference to the streams, otherwise they will be disposed\n\t    audio_stream = None\n\t    video_stream = None\n", "    @room.listens_to(\"track_subscribed\")\n\t    def on_track_subscribed(track: livekit.Track,\n\t                            publication: livekit.RemoteTrackPublication,\n\t                            participant: livekit.RemoteParticipant):\n\t        logging.info(\"track subscribed: %s\", publication.sid)\n\t        if track.kind == livekit.TrackKind.KIND_VIDEO:\n\t            nonlocal video_stream\n\t            video_stream = livekit.VideoStream(track)\n\t            @video_stream.on(\"frame_received\")\n\t            def on_video_frame(frame: livekit.VideoFrame):\n", "                # received a video frame from the track\n\t                pass\n\t        elif track.kind == livekit.TrackKind.KIND_AUDIO:\n\t            print(\"Subscribed to an Audio Track\")\n\t            nonlocal audio_stream\n\t            audio_stream = livekit.AudioStream(track)\n\t            @audio_stream.on('frame_received')\n\t            def on_audio_frame(frame: livekit.AudioFrame):\n\t                # received an audio frame from the track\n\t                pass\n", "    @room.listens_to(\"track_unsubscribed\")\n\t    def on_track_unsubscribed(track: livekit.Track,\n\t                              publication: livekit.RemoteTrackPublication,\n\t                              participant: livekit.RemoteParticipant):\n\t        logging.info(\"track unsubscribed: %s\", publication.sid)\n\t    @room.listens_to(\"data_received\")\n\t    def on_data_received(data: bytes,\n\t                         kind: livekit.DataPacketKind,\n\t                         participant: livekit.Participant):\n\t        logging.info(\"received data from %s: %s\", participant.identity, data)\n", "    @room.listens_to(\"connection_quality_changed\")\n\t    def on_connection_quality_changed(participant: livekit.Participant,\n\t                                      quality: livekit.ConnectionQuality):\n\t        logging.info(\"connection quality changed for %s\", participant.identity)\n\t    @room.listens_to(\"track_subscription_failed\")\n\t    def on_track_subscription_failed(participant: livekit.RemoteParticipant,\n\t                                     track_sid: str,\n\t                                     error: str):\n\t        logging.info(\"track subscription failed: %s %s\",\n\t                     participant.identity, error)\n", "    @room.listens_to(\"connection_state_changed\")\n\t    def on_connection_state_changed(state: livekit.ConnectionState):\n\t        logging.info(\"connection state changed: %s\", state)\n\t    @room.listens_to(\"connected\")\n\t    def on_connected() -> None:\n\t        logging.info(\"connected\")\n\t    @room.listens_to(\"disconnected\")\n\t    def on_disconnected() -> None:\n\t        logging.info(\"disconnected\")\n\t    @room.listens_to(\"reconnecting\")\n", "    def on_reconnecting() -> None:\n\t        logging.info(\"reconnecting\")\n\t    @room.listens_to(\"reconnected\")\n\t    def on_reconnected() -> None:\n\t        logging.info(\"reconnected\")\n\t    try:\n\t        logging.info(\"connecting to %s\", URL)\n\t        await room.connect(URL, TOKEN)\n\t        logging.info(\"connected to room %s\", room.name)\n\t        await room.local_participant.publish_data(\"hello world\")\n", "        logging.info(\"participants: %s\", room.participants)\n\t        await room.run()\n\t    except livekit.ConnectError as e:\n\t        logging.error(\"failed to connect to the room: %s\", e)\n\t    except asyncio.CancelledError:\n\t        logging.info(\"closing the room\")\n\t        await room.disconnect()\n\tif __name__ == \"__main__\":\n\t    logging.basicConfig(level=logging.INFO, handlers=[\n\t                        logging.FileHandler(\"basic_room.log\"), logging.StreamHandler()])\n", "    loop = asyncio.get_event_loop()\n\t    main_task = asyncio.ensure_future(main())\n\t    for signal in [SIGINT, SIGTERM]:\n\t        loop.add_signal_handler(signal, main_task.cancel)\n\t    try:\n\t        loop.run_until_complete(main_task)\n\t    finally:\n\t        loop.close()\n"]}
{"filename": "examples/publish_wave.py", "chunked_list": ["import asyncio\n\timport logging\n\tfrom signal import SIGINT, SIGTERM\n\timport numpy as np\n\timport livekit\n\tURL = 'ws://localhost:7880'\n\tTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'\n\tasync def publish_frames(source: livekit.AudioSource):\n\t    sample_rate = 48000\n\t    frequency = 440\n", "    amplitude = 32767  # for 16-bit audio\n\t    num_channels = 1\n\t    samples_per_channel = 480  # 10ms at 48kHz\n\t    time = np.arange(samples_per_channel) / sample_rate\n\t    total_samples = 0\n\t    audio_frame = livekit.AudioFrame.create(\n\t        sample_rate, num_channels, samples_per_channel)\n\t    audio_data = np.ctypeslib.as_array(audio_frame.data)\n\t    while True:\n\t        time = (total_samples + np.arange(samples_per_channel)) / sample_rate\n", "        sine_wave = (amplitude * np.sin(2 * np.pi *\n\t                     frequency * time)).astype(np.int16)\n\t        np.copyto(audio_data, sine_wave)\n\t        source.capture_frame(audio_frame)\n\t        total_samples += samples_per_channel\n\t        try:\n\t            await asyncio.sleep(1 / 100)  # 10m\n\t        except asyncio.CancelledError:\n\t            break\n\tasync def main() -> None:\n", "    room = livekit.Room()\n\t    logging.info(\"connecting to %s\", URL)\n\t    try:\n\t        await room.connect(URL, TOKEN)\n\t        logging.info(\"connected to room %s\", room.name)\n\t    except livekit.ConnectError as e:\n\t        logging.error(\"failed to connect to the room: %s\", e)\n\t        return\n\t    # publish a track\n\t    source = livekit.AudioSource()\n", "    source_task = asyncio.create_task(publish_frames(source))\n\t    track = livekit.LocalAudioTrack.create_audio_track(\"sinewave\", source)\n\t    options = livekit.TrackPublishOptions()\n\t    options.source = livekit.TrackSource.SOURCE_MICROPHONE\n\t    publication = await room.local_participant.publish_track(track, options)\n\t    logging.info(\"published track %s\", publication.sid)\n\t    try:\n\t        await room.run()\n\t    except asyncio.CancelledError:\n\t        logging.info(\"closing the room\")\n", "        source_task.cancel()\n\t        await source_task\n\t        await room.disconnect()\n\tif __name__ == \"__main__\":\n\t    logging.basicConfig(level=logging.INFO, handlers=[\n\t                        logging.FileHandler(\"publish_wave.log\"), logging.StreamHandler()])\n\t    loop = asyncio.get_event_loop()\n\t    main_task = asyncio.ensure_future(main())\n\t    for signal in [SIGINT, SIGTERM]:\n\t        loop.add_signal_handler(signal, main_task.cancel)\n", "    try:\n\t        loop.run_until_complete(main_task)\n\t    finally:\n\t        loop.close()\n"]}
{"filename": "examples/whisper/whisper.py", "chunked_list": ["import asyncio\n\timport ctypes\n\timport logging\n\timport pathlib\n\timport platform\n\tfrom signal import SIGINT, SIGTERM\n\timport numpy as np\n\timport livekit\n\tos = platform.system().lower()\n\tif os == \"windows\":\n", "    lib_file = 'whisper.dll'\n\telif os == \"darwin\":\n\t    lib_file = 'libwhisper.dylib'\n\telse:\n\t    lib_file = 'libwhisper.so'\n\twhisper_dir = pathlib.Path(__file__).parent.absolute() / \"whisper.cpp\"\n\tlibname = str(whisper_dir / lib_file)\n\tfname_model = str(whisper_dir / \"models/ggml-tiny.en.bin\")\n\tURL = 'ws://localhost:7880'\n\tTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'  # noqa\n", "# declare the Whisper C API  (Only what we need, keep things simple)\n\t# also see this issue: https://github.com/ggerganov/whisper.cpp/issues/9\n\t# structure must match https://github.com/ggerganov/whisper.cpp/blob/master/whisper.h\n\tclass WhisperSamplingStrategy(ctypes.c_int):\n\t    WHISPER_SAMPLING_GREEDY = 0\n\t    WHISPER_SAMPLING_BEAM_SEARCH = 1\n\tclass WhisperFullParams(ctypes.Structure):\n\t    _fields_ = [\n\t        ('strategy', ctypes.c_int),\n\t        ('n_threads',  ctypes.c_int),\n", "        ('n_max_text_ctx', ctypes.c_int),\n\t        ('offset_ms', ctypes.c_int),\n\t        ('duration_ms', ctypes.c_int),\n\t        ('translate', ctypes.c_bool),\n\t        ('no_context', ctypes.c_bool),\n\t        ('single_segment', ctypes.c_bool),\n\t        ('print_special', ctypes.c_bool),\n\t        ('print_progress', ctypes.c_bool),\n\t        ('print_realtime', ctypes.c_bool),\n\t        ('print_timestamps', ctypes.c_bool),\n", "        ('token_timestamps', ctypes.c_bool),\n\t        ('thold_pt', ctypes.c_float),\n\t        ('thold_ptsum', ctypes.c_float),\n\t        ('max_len', ctypes.c_int),\n\t        ('split_on_word', ctypes.c_bool),\n\t        ('max_tokens', ctypes.c_int),\n\t        ('speed_up', ctypes. c_bool),\n\t        ('audio_ctx', ctypes. c_int),\n\t        ('tdrz_enable', ctypes. c_bool),\n\t        ('initial_prompt', ctypes.c_char_p),\n", "        ('prompt_tokens', ctypes.c_void_p),\n\t        ('prompt_n_tokens', ctypes.c_int),\n\t        ('language', ctypes.c_char_p),\n\t        ('detect_language', ctypes.c_bool),\n\t        ('suppress_blank', ctypes.c_bool),\n\t        ('suppress_non_speech_tokens', ctypes.c_bool),\n\t        ('temperature', ctypes.c_float),\n\t        ('max_initial_ts', ctypes.c_float),\n\t        ('length_penalty', ctypes.c_float),\n\t        ('temperature_inc', ctypes. c_float),\n", "        ('entropy_thold', ctypes. c_float),\n\t        ('logprob_thold', ctypes. c_float),\n\t        ('no_speech_thold', ctypes. c_float),\n\t        ('greedy', ctypes.c_int),\n\t        ('beam_size', ctypes.c_int),\n\t        ('patience', ctypes.c_float),\n\t        ('new_segment_callback', ctypes.c_void_p),\n\t        ('new_segment_callback_user_data', ctypes.c_void_p),\n\t        ('progress_callback', ctypes.c_void_p),\n\t        ('progress_callback_user_data', ctypes.c_void_p),\n", "        ('encoder_begin_callback', ctypes.c_void_p),\n\t        ('encoder_begin_callback_user_data', ctypes.c_void_p),\n\t        ('logits_filter_callback', ctypes.c_void_p),\n\t        ('logits_filter_callback_user_data', ctypes.c_void_p),\n\t    ]\n\tWHISPER_SAMPLE_RATE = 16000\n\tSAMPLES_30_SECS = WHISPER_SAMPLE_RATE * 30\n\tSAMPLES_KEEP = WHISPER_SAMPLE_RATE * 1  # data to keep from the old inference\n\tSAMPLES_STEP = WHISPER_SAMPLE_RATE * 3  # 3 seconds of new data\n\twhisper = ctypes.CDLL(libname)\n", "whisper.whisper_init_from_file.argtypes = [ctypes.c_char_p]\n\twhisper.whisper_init_from_file.restype = ctypes.c_void_p\n\twhisper.whisper_full_default_params.restype = WhisperFullParams\n\twhisper.whisper_full_get_segment_text.restype = ctypes.c_char_p\n\tctx = whisper.whisper_init_from_file(fname_model.encode('utf-8'))\n\tdata_30_secs = np.zeros(SAMPLES_30_SECS, dtype=np.float32)\n\twritten_samples = 0  # nb. of samples written to data_30_secs for the cur. inference\n\tdef on_audio_frame(frame: livekit.AudioFrame):\n\t    global data_30_secs, written_samples\n\t    # whisper requires 16kHz mono, so resample the data\n", "    # also convert the samples from int16 to float32\n\t    frame = frame.remix_and_resample(\n\t        WHISPER_SAMPLE_RATE, 1)\n\t    data = np.array(frame.data, dtype=np.float32) / 32768.0\n\t    # write the data inside data_30_secs at written_samples\n\t    data_start = SAMPLES_KEEP + written_samples\n\t    data_30_secs[data_start:data_start+len(data)] = data\n\t    written_samples += len(data)\n\t    if written_samples >= SAMPLES_STEP:\n\t        params = whisper.whisper_full_default_params(\n", "            WhisperSamplingStrategy.WHISPER_SAMPLING_GREEDY)\n\t        params.print_realtime = False\n\t        params.print_progress = False\n\t        ctx_ptr = ctypes.c_void_p(ctx)\n\t        data_ptr = data_30_secs.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n\t        res = whisper.whisper_full(ctx_ptr,\n\t                                   params,\n\t                                   data_ptr,\n\t                                   written_samples + SAMPLES_KEEP)\n\t        if res != 0:\n", "            logging.error(\"error while running inference: %s\", res)\n\t            return\n\t        n_segments = whisper.whisper_full_n_segments(ctx_ptr)\n\t        for i in range(n_segments):\n\t            t0 = whisper.whisper_full_get_segment_t0(ctx_ptr, i)\n\t            t1 = whisper.whisper_full_get_segment_t1(ctx_ptr, i)\n\t            txt = whisper.whisper_full_get_segment_text(ctx_ptr, i)\n\t            logging.info(\n\t                f\"{t0/1000.0:.3f} - {t1/1000.0:.3f} : {txt.decode('utf-8')}\")\n\t        # write old data to the beginning of the buffer (SAMPLES_KEEP)\n", "        data_30_secs[:SAMPLES_KEEP] = data_30_secs[data_start +\n\t                                                   written_samples - SAMPLES_KEEP:\n\t                                                   data_start + written_samples]\n\t        written_samples = 0\n\tasync def main():\n\t    room = livekit.Room()\n\t    audio_stream = None\n\t    @room.listens_to(\"track_published\")\n\t    def on_track_published(publication: livekit.RemoteTrackPublication,\n\t                           participant: livekit.RemoteParticipant):\n", "        # Only subscribe to the audio tracks coming from the microphone\n\t        if publication.kind == livekit.TrackKind.KIND_AUDIO \\\n\t                and publication.source == livekit.TrackSource.SOURCE_MICROPHONE:\n\t            logging.info(\"track published: %s from participant %s (%s), subscribing...\",\n\t                         publication.sid, participant.sid, participant.identity)\n\t            publication.set_subscribed(True)\n\t    @room.listens_to(\"track_subscribed\")\n\t    def on_track_subscribed(track: livekit.Track,\n\t                            publication: livekit.RemoteTrackPublication,\n\t                            participant: livekit.RemoteParticipant):\n", "        logging.info(\"starting listening to: %s\", participant.identity)\n\t        nonlocal audio_stream\n\t        audio_stream = livekit.AudioStream(track)\n\t        audio_stream.add_listener('frame_received', on_audio_frame)\n\t    try:\n\t        logging.info(\"connecting to %s\", URL)\n\t        await room.connect(URL, TOKEN, livekit.RoomOptions(auto_subscribe=False))\n\t        logging.info(\"connected to room %s\", room.name)\n\t        # check if there are already published audio tracks\n\t        for participant in room.participants.values():\n", "            for track in participant.tracks.values():\n\t                if track.kind == livekit.TrackKind.KIND_AUDIO \\\n\t                        and track.source == livekit.TrackSource.SOURCE_MICROPHONE:\n\t                    track.set_subscribed(True)\n\t        await room.run()\n\t    except livekit.ConnectError as e:\n\t        logging.error(\"failed to connect to the room: %s\", e)\n\t    except asyncio.CancelledError:\n\t        logging.info(\"closing the room\")\n\t        await room.disconnect()\n", "if __name__ == \"__main__\":\n\t    logging.basicConfig(level=logging.INFO, handlers=[\n\t                        logging.FileHandler(\"whisper.log\"), logging.StreamHandler()])\n\t    loop = asyncio.get_event_loop()\n\t    main_task = asyncio.ensure_future(main())\n\t    for signal in [SIGINT, SIGTERM]:\n\t        loop.add_signal_handler(signal, main_task.cancel)\n\t    try:\n\t        loop.run_until_complete(main_task)\n\t    finally:\n", "        loop.close()\n\t    whisper.whisper_free(ctypes.c_void_p(ctx))\n"]}
{"filename": "examples/face_landmark/face_landmark.py", "chunked_list": ["import asyncio\n\timport os\n\tfrom queue import Queue\n\timport cv2\n\timport mediapipe as mp\n\timport numpy as np\n\tfrom mediapipe import solutions\n\tfrom mediapipe.framework.formats import landmark_pb2\n\timport livekit\n\tURL = 'ws://localhost:7880'\n", "TOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'\n\tframe_queue = Queue()\n\targb_frame = None\n\t# You can download a face landmark model file from https://developers.google.com/mediapipe/solutions/vision/face_landmarker#models\n\tmodel_file = 'face_landmarker.task'\n\tmodel_path = os.path.dirname(os.path.realpath(__file__)) + '/' + model_file\n\tBaseOptions = mp.tasks.BaseOptions\n\tFaceLandmarker = mp.tasks.vision.FaceLandmarker\n\tFaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n\tVisionRunningMode = mp.tasks.vision.RunningMode\n", "options = FaceLandmarkerOptions(\n\t    base_options=BaseOptions(model_asset_path=model_path),\n\t    running_mode=VisionRunningMode.VIDEO)\n\t# from https://github.com/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb\n\tdef draw_landmarks_on_image(rgb_image, detection_result):\n\t    face_landmarks_list = detection_result.face_landmarks\n\t    # Loop through the detected faces to visualize.\n\t    for idx in range(len(face_landmarks_list)):\n\t        face_landmarks = face_landmarks_list[idx]\n\t        # Draw the face landmarks.\n", "        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n\t        face_landmarks_proto.landmark.extend([\n\t            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n\t        ])\n\t        solutions.drawing_utils.draw_landmarks(\n\t            image=rgb_image,\n\t            landmark_list=face_landmarks_proto,\n\t            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n\t            landmark_drawing_spec=None,\n\t            connection_drawing_spec=mp.solutions.drawing_styles\n", "            .get_default_face_mesh_tesselation_style())\n\t        solutions.drawing_utils.draw_landmarks(\n\t            image=rgb_image,\n\t            landmark_list=face_landmarks_proto,\n\t            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n\t            landmark_drawing_spec=None,\n\t            connection_drawing_spec=mp.solutions.drawing_styles\n\t            .get_default_face_mesh_contours_style())\n\t        solutions.drawing_utils.draw_landmarks(\n\t            image=rgb_image,\n", "            landmark_list=face_landmarks_proto,\n\t            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n\t            landmark_drawing_spec=None,\n\t            connection_drawing_spec=mp.solutions.drawing_styles\n\t            .get_default_face_mesh_iris_connections_style())\n\tasync def room() -> None:\n\t    room = livekit.Room()\n\t    await room.connect(URL, TOKEN)\n\t    print(\"connected to room: \" + room.name)\n\t    video_stream = None\n", "    @room.on(\"track_subscribed\")\n\t    def on_track_subscribed(track: livekit.Track,\n\t                            publication: livekit.RemoteTrackPublication,\n\t                            participant: livekit.RemoteParticipant):\n\t        if track.kind == livekit.TrackKind.KIND_VIDEO:\n\t            nonlocal video_stream\n\t            video_stream = livekit.VideoStream(track)\n\t            @video_stream.on(\"frame_received\")\n\t            def on_video_frame(frame: livekit.VideoFrame):\n\t                frame_queue.put(frame)\n", "    await room.run()\n\tdef display_frames() -> None:\n\t    cv2.namedWindow('livekit_video', cv2.WINDOW_AUTOSIZE)\n\t    cv2.startWindowThread()\n\t    global argb_frame\n\t    with FaceLandmarker.create_from_options(options) as landmarker:\n\t        while True:\n\t            frame = frame_queue.get()\n\t            buffer = frame.buffer\n\t            if argb_frame is None or argb_frame.width != buffer.width or argb_frame.height != buffer.height:\n", "                argb_frame = livekit.ArgbFrame(\n\t                    livekit.VideoFormatType.FORMAT_ABGR, buffer.width, buffer.height)\n\t            buffer.to_argb(argb_frame)\n\t            arr = np.ctypeslib.as_array(argb_frame.data)\n\t            arr = arr.reshape((argb_frame.height, argb_frame.width, 4))\n\t            arr = cv2.cvtColor(arr, cv2.COLOR_RGBA2RGB)\n\t            mp_image = mp.Image(\n\t                image_format=mp.ImageFormat.SRGB, data=arr)\n\t            detection_result = landmarker.detect_for_video(\n\t                mp_image, frame.timestamp)\n", "            draw_landmarks_on_image(arr, detection_result)\n\t            arr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n\t            cv2.imshow('livekit_video', arr)\n\t            if cv2.waitKey(1) & 0xFF == ord('q'):\n\t                break\n\t    cv2.destroyAllWindows()\n\tasync def main() -> None:\n\t    loop = asyncio.get_event_loop()\n\t    future = loop.run_in_executor(None, asyncio.run, room())\n\t    display_frames()\n", "    await future\n\tif __name__ == \"__main__\":\n\t    asyncio.run(main())\n"]}
{"filename": "livekit/track_publication.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\tfrom typing import Optional\n\tfrom livekit._proto import track_pb2 as proto_track\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom .track import Track\n\tclass TrackPublication():\n\t    def __init__(self, handle: FfiHandle, info: proto_track.TrackPublicationInfo):\n", "        self._info = info\n\t        self.track: Optional[Track] = None\n\t        self._ffi_handle = handle\n\t    @property\n\t    def sid(self) -> str:\n\t        return self._info.sid\n\t    @property\n\t    def name(self) -> str:\n\t        return self._info.name\n\t    @property\n", "    def kind(self) -> proto_track.TrackKind.ValueType:\n\t        return self._info.kind\n\t    @property\n\t    def source(self) -> proto_track.TrackSource.ValueType:\n\t        return self._info.source\n\t    @property\n\t    def simulcasted(self) -> bool:\n\t        return self._info.simulcasted\n\t    @property\n\t    def width(self) -> int:\n", "        return self._info.width\n\t    @property\n\t    def height(self) -> int:\n\t        return self._info.height\n\t    @property\n\t    def mime_type(self) -> str:\n\t        return self._info.mime_type\n\t    @property\n\t    def muted(self) -> bool:\n\t        return self._info.muted\n", "class LocalTrackPublication(TrackPublication):\n\t    def __init__(self, handle: FfiHandle, info: proto_track.TrackPublicationInfo):\n\t        super().__init__(handle, info)\n\tclass RemoteTrackPublication(TrackPublication):\n\t    def __init__(self, handle: FfiHandle, info: proto_track.TrackPublicationInfo):\n\t        super().__init__(handle, info)\n\t        self.subscribed = False\n\t    def set_subscribed(self, subscribed: bool):\n\t        req = proto_ffi.FfiRequest()\n\t        req.set_subscribed.subscribe = subscribed\n", "        req.set_subscribed.publication_handle = self._ffi_handle.handle\n\t        ffi_client.request(req)\n"]}
{"filename": "livekit/video_frame.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport ctypes\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom ._proto import video_frame_pb2 as proto_video_frame\n\tfrom ._proto.video_frame_pb2 import VideoFormatType, VideoFrameBufferType, VideoRotation\n\tclass VideoFrame():\n\t    def __init__(self, timestamp_us: int, rotation: VideoRotation.ValueType, buffer: 'VideoFrameBuffer') -> None:\n", "        self.buffer = buffer\n\t        self.timestamp_us = timestamp_us\n\t        self.rotation = rotation\n\tclass VideoFrameBuffer():\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        self._info = info\n\t        self._ffi_handle = ffi_handle\n\t    @property\n\t    def width(self) -> int:\n\t        return self._info.width\n", "    @property\n\t    def height(self) -> int:\n\t        return self._info.height\n\t    @property\n\t    def type(self) -> VideoFrameBufferType.ValueType:\n\t        return self._info.buffer_type\n\t    def to_i420(self) -> 'I420Buffer':\n\t        req = proto_ffi.FfiRequest()\n\t        req.to_i420.buffer_handle = self._ffi_handle.handle\n\t        resp = ffi_client.request(req)\n", "        new_info = resp.to_i420.buffer\n\t        ffi_handle = FfiHandle(new_info.handle.id)\n\t        return I420Buffer(ffi_handle, new_info)\n\t    def to_argb(self, dst: 'ArgbFrame') -> None:\n\t        req = proto_ffi.FfiRequest()\n\t        req.to_argb.buffer_handle = self._ffi_handle.handle\n\t        req.to_argb.dst_ptr = ctypes.addressof(dst.data)\n\t        req.to_argb.dst_format = dst.format\n\t        req.to_argb.dst_stride = dst.width * 4\n\t        req.to_argb.dst_width = dst.width\n", "        req.to_argb.dst_height = dst.height\n\t        ffi_client.request(req)\n\t    @staticmethod\n\t    def create(ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> 'VideoFrameBuffer':\n\t        \"\"\"\n\t        Create the right class instance from the VideoFrameBufferInfo\n\t        \"\"\"\n\t        if info.buffer_type == VideoFrameBufferType.NATIVE:\n\t            return NativeVideoFrameBuffer(ffi_handle, info)\n\t        elif info.buffer_type == VideoFrameBufferType.I420:\n", "            return I420Buffer(ffi_handle, info)\n\t        elif info.buffer_type == VideoFrameBufferType.I420A:\n\t            return I420ABuffer(ffi_handle, info)\n\t        elif info.buffer_type == VideoFrameBufferType.I422:\n\t            return I422Buffer(ffi_handle, info)\n\t        elif info.buffer_type == VideoFrameBufferType.I444:\n\t            return I444Buffer(ffi_handle, info)\n\t        elif info.buffer_type == VideoFrameBufferType.I010:\n\t            return I010Buffer(ffi_handle, info)\n\t        elif info.buffer_type == VideoFrameBufferType.NV12:\n", "            return NV12Buffer(ffi_handle, info)\n\t        else:\n\t            raise Exception('Unsupported VideoFrameBufferType')\n\tclass NativeVideoFrameBuffer(VideoFrameBuffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\tclass PlanarYuvBuffer(VideoFrameBuffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\t    @property\n", "    def chroma_width(self) -> int:\n\t        return self._info.yuv.chroma_width\n\t    @property\n\t    def chroma_height(self) -> int:\n\t        return self._info.yuv.chroma_height\n\t    @property\n\t    def stride_y(self) -> int:\n\t        return self._info.yuv.stride_y\n\t    @property\n\t    def stride_u(self) -> int:\n", "        return self._info.yuv.stride_u\n\t    @property\n\t    def stride_v(self) -> int:\n\t        return self._info.yuv.stride_v\n\tclass PlanarYuv8Buffer(PlanarYuvBuffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\t    @property\n\t    def data_y(self) -> ctypes.Array[ctypes.c_uint8]:\n\t        arr = ctypes.cast(self._info.yuv.data_y_ptr, ctypes.POINTER(\n", "            ctypes.c_uint8 * (self._info.yuv.stride_y * self._info.height))).contents\n\t        return arr\n\t    @property\n\t    def data_u(self) -> ctypes.Array[ctypes.c_uint8]:\n\t        arr = ctypes.cast(self._info.yuv.data_u_ptr, ctypes.POINTER(\n\t            ctypes.c_uint8 * (self._info.yuv.stride_u * self._info.yuv.chroma_height))).contents\n\t        return arr\n\t    @property\n\t    def data_v(self) -> ctypes.Array[ctypes.c_uint8]:\n\t        arr = ctypes.cast(self._info.yuv.data_v_ptr, ctypes.POINTER(\n", "            ctypes.c_uint8 * (self._info.yuv.stride_v * self._info.yuv.chroma_height))).contents\n\t        return arr\n\tclass PlanarYuv16Buffer(PlanarYuvBuffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\t    @property\n\t    def data_y(self) -> ctypes.Array[ctypes.c_uint16]:\n\t        arr = ctypes.cast(self._info.yuv.data_y_ptr, ctypes.POINTER(\n\t            ctypes.c_uint16 * (self._info.yuv.stride_y // 2 * self._info.height))).contents\n\t        return arr\n", "    @property\n\t    def data_u(self) -> ctypes.Array[ctypes.c_uint16]:\n\t        arr = ctypes.cast(self._info.yuv.data_u_ptr, ctypes.POINTER(\n\t            ctypes.c_uint16 * (self._info.yuv.stride_u // 2 * self._info.yuv.chroma_height))).contents\n\t        return arr\n\t    @property\n\t    def data_v(self) -> ctypes.Array[ctypes.c_uint16]:\n\t        arr = ctypes.cast(self._info.yuv.data_v_ptr, ctypes.POINTER(\n\t            ctypes.c_uint16 * (self._info.yuv.stride_v // 2 * self._info.yuv.chroma_height))).contents\n\t        return arr\n", "class BiplanaraYuv8Buffer(VideoFrameBuffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\t    @property\n\t    def data_y(self) -> ctypes.Array[ctypes.c_uint8]:\n\t        arr = ctypes.cast(self._info.bi_yuv.data_y_ptr, ctypes.POINTER(\n\t            ctypes.c_uint8 * (self._info.bi_yuv.stride_y * self._info.height))).contents\n\t        return arr\n\t    @property\n\t    def data_uv(self) -> ctypes.Array[ctypes.c_uint8]:\n", "        arr = ctypes.cast(self._info.bi_yuv.data_uv_ptr, ctypes.POINTER(\n\t            ctypes.c_uint8 * (self._info.bi_yuv.stride_uv * self._info.bi_yuv.chroma_height))).contents\n\t        return arr\n\tclass I420Buffer(PlanarYuv8Buffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\tclass I420ABuffer(PlanarYuv8Buffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\t    @property\n", "    def data_a(self) -> ctypes.Array[ctypes.c_uint8]:\n\t        arr = ctypes.cast(self._info.yuv.data_a_ptr, ctypes.POINTER(\n\t            ctypes.c_uint8 * (self._info.yuv.stride_a * self._info.height))).contents\n\t        return arr\n\tclass I422Buffer(PlanarYuv8Buffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\tclass I444Buffer(PlanarYuv8Buffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n", "class I010Buffer(PlanarYuv16Buffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\tclass NV12Buffer(BiplanaraYuv8Buffer):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n\t        super().__init__(ffi_handle, info)\n\tclass ArgbFrame:\n\t    \"\"\"\n\t    Mainly used to simplify the usage of to_argb method\n\t    So the users don't need to deal with ctypes\n", "    \"\"\"\n\t    def __init__(self, format: VideoFormatType.ValueType, width: int, height: int) -> None:\n\t        self._format = format\n\t        self.width = width\n\t        self.height = height\n\t        self.data = (ctypes.c_uint8 * (width * height *\n\t                     ctypes.sizeof(ctypes.c_uint32)))()  # alloc frame\n\t    def to_i420(self) -> I420Buffer:\n\t        # TODO(theomonnom): avoid unnecessary buffer allocation\n\t        req = proto_ffi.FfiRequest()\n", "        req.to_i420.argb.format = self._format\n\t        req.to_i420.argb.width = self.width\n\t        req.to_i420.argb.height = self.height\n\t        req.to_i420.argb.stride = self.width * 4\n\t        req.to_i420.argb.ptr = ctypes.addressof(self.data)\n\t        res = ffi_client.request(req)\n\t        buffer_info = res.to_i420.buffer\n\t        ffi_handle = FfiHandle(buffer_info.handle.id)\n\t        return I420Buffer(ffi_handle, buffer_info)\n\t    @property\n", "    def format(self) -> VideoFormatType.ValueType:\n\t        return self._format\n"]}
{"filename": "livekit/room.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport asyncio\n\timport ctypes\n\tfrom dataclasses import dataclass\n\tfrom typing import Optional\n\tfrom pyee.asyncio import EventEmitter\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import ffi_pb2 as proto_ffi\n", "from ._proto import participant_pb2 as proto_participant\n\tfrom ._proto import room_pb2 as proto_room\n\tfrom ._proto.room_pb2 import ConnectionState\n\tfrom ._proto.track_pb2 import TrackKind\n\tfrom .participant import LocalParticipant, Participant, RemoteParticipant\n\tfrom .track import RemoteAudioTrack, RemoteVideoTrack\n\tfrom .track_publication import RemoteTrackPublication\n\t@dataclass\n\tclass RoomOptions:\n\t    auto_subscribe: bool = True\n", "    dynacast: bool = True\n\tclass ConnectError(Exception):\n\t    def __init__(self, message: str):\n\t        self.message = message\n\tclass Room(EventEmitter):\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self.participants: dict[str, RemoteParticipant] = {}\n\t        self.connection_state = ConnectionState.CONN_DISCONNECTED\n\t        self._ffi_handle: Optional[FfiHandle] = None\n", "        ffi_client.add_listener('room_event', self._on_room_event)\n\t    def __del__(self):\n\t        ffi_client.remove_listener('room_event', self._on_room_event)\n\t    @property\n\t    def sid(self) -> str:\n\t        return self._info.sid\n\t    @property\n\t    def name(self) -> str:\n\t        return self._info.name\n\t    @property\n", "    def metadata(self) -> str:\n\t        return self._info.metadata\n\t    def isconnected(self) -> bool:\n\t        return self._ffi_handle is not None and \\\n\t            self.connection_state != ConnectionState.CONN_DISCONNECTED\n\t    async def connect(self,\n\t                      url: str,\n\t                      token: str,\n\t                      options: RoomOptions = RoomOptions()) -> None:\n\t        req = proto_ffi.FfiRequest()\n", "        req.connect.url = url\n\t        req.connect.token = token\n\t        # options\n\t        req.connect.options.auto_subscribe = options.auto_subscribe\n\t        req.connect.options.dynacast = options.dynacast\n\t        resp = ffi_client.request(req)\n\t        future: asyncio.Future[proto_room.ConnectCallback] = asyncio.Future()\n\t        @ffi_client.listens_to('connect')\n\t        def on_connect_callback(cb: proto_room.ConnectCallback):\n\t            if cb.async_id == resp.connect.async_id:\n", "                future.set_result(cb)\n\t                ffi_client.remove_listener('connect', on_connect_callback)\n\t        cb = await future\n\t        if cb.error:\n\t            raise ConnectError(cb.error)\n\t        self._close_future: asyncio.Future[None] = asyncio.Future()\n\t        self._ffi_handle = FfiHandle(cb.room.handle.id)\n\t        self._info = cb.room\n\t        self.connection_state = ConnectionState.CONN_CONNECTED\n\t        lp_handle = FfiHandle(cb.local_participant.handle.id)\n", "        self.local_participant = LocalParticipant(\n\t            lp_handle, cb.local_participant)\n\t        for pt in cb.participants:\n\t            rp_handle = FfiHandle(pt.participant.handle.id)\n\t            rp = self._create_remote_participant(rp_handle, pt.participant)\n\t            # add the initial remote participant tracks\n\t            for publication_info in pt.publications:\n\t                pub_handle = FfiHandle(publication_info.handle.id)\n\t                publication = RemoteTrackPublication(\n\t                    pub_handle, publication_info)\n", "                rp.tracks[publication.sid] = publication\n\t    async def disconnect(self) -> None:\n\t        if not self.isconnected():\n\t            return\n\t        req = proto_ffi.FfiRequest()\n\t        req.disconnect.room_handle = self._ffi_handle.handle  # type: ignore\n\t        resp = ffi_client.request(req)\n\t        future: asyncio.Future[proto_room.DisconnectCallback] = asyncio.Future(\n\t        )\n\t        @ffi_client.on('disconnect')\n", "        def on_disconnect_callback(cb: proto_room.DisconnectCallback):\n\t            if cb.async_id == resp.disconnect.async_id:\n\t                future.set_result(cb)\n\t                ffi_client.remove_listener(\n\t                    'disconnect', on_disconnect_callback)\n\t        await future\n\t        if not self._close_future.cancelled():\n\t            self._close_future.set_result(None)\n\t    async def run(self) -> None:\n\t        await self._close_future\n", "    def _on_room_event(self, event: proto_room.RoomEvent):\n\t        if self._ffi_handle is None:\n\t            return\n\t        if event.room_handle != self._ffi_handle.handle:\n\t            return\n\t        which = event.WhichOneof('message')\n\t        if which == 'participant_connected':\n\t            rp_info = event.participant_connected.info\n\t            ffi_handle = FfiHandle(rp_info.handle.id)\n\t            rparticipant = self._create_remote_participant(\n", "                ffi_handle, rp_info)\n\t            self.emit('participant_connected', rparticipant)\n\t        elif which == 'participant_disconnected':\n\t            sid = event.participant_disconnected.participant_sid\n\t            rparticipant = self.participants.pop(sid)\n\t            self.emit('participant_disconnected', rparticipant)\n\t        elif which == 'local_track_published':\n\t            sid = event.local_track_published.track_sid\n\t            # publication is created inside LocalParticipant.publish_track\n\t            # (This event is called after that)\n", "            lpublication = self.local_participant.tracks[sid]\n\t            track = lpublication.track\n\t            self.emit('local_track_published', lpublication, track)\n\t        elif which == 'local_track_unpublished':\n\t            sid = event.local_track_unpublished.publication_sid\n\t            lpublication = self.local_participant.tracks[sid]\n\t            self.emit('local_track_unpublished', lpublication)\n\t        elif which == 'track_published':\n\t            rparticipant = self.participants[event.track_published.participant_sid]\n\t            ffi_handle = FfiHandle(event.track_published.publication.handle.id)\n", "            rpublication = RemoteTrackPublication(ffi_handle,\n\t                                                  event.track_published.publication)\n\t            rparticipant.tracks[rpublication.sid] = rpublication\n\t            self.emit('track_published', rpublication, rparticipant)\n\t        elif which == 'track_unpublished':\n\t            rparticipant = self.participants[event.track_unpublished.participant_sid]\n\t            rpublication = rparticipant.tracks.pop(\n\t                event.track_unpublished.publication_sid)\n\t            self.emit('track_unpublished', rpublication, rparticipant)\n\t        elif which == 'track_subscribed':\n", "            track_info = event.track_subscribed.track\n\t            rparticipant = self.participants[event.track_subscribed.participant_sid]\n\t            rpublication = rparticipant.tracks[track_info.sid]\n\t            ffi_handle = FfiHandle(track_info.handle.id)\n\t            rpublication.subscribed = True\n\t            if track_info.kind == TrackKind.KIND_VIDEO:\n\t                remote_video_track = RemoteVideoTrack(ffi_handle, track_info)\n\t                rpublication.track = remote_video_track\n\t                self.emit('track_subscribed',\n\t                          remote_video_track, rpublication, rparticipant)\n", "            elif track_info.kind == TrackKind.KIND_AUDIO:\n\t                remote_audio_track = RemoteAudioTrack(ffi_handle, track_info)\n\t                rpublication.track = remote_audio_track\n\t                self.emit('track_subscribed', remote_audio_track,\n\t                          rpublication, rparticipant)\n\t        elif which == 'track_unsubscribed':\n\t            sid = event.track_unsubscribed.participant_sid\n\t            rparticipant = self.participants[sid]\n\t            rpublication = rparticipant.tracks[event.track_unsubscribed.track_sid]\n\t            track = rpublication.track\n", "            rpublication.track = None\n\t            rpublication.subscribed = False\n\t            self.emit('track_unsubscribed', track, rpublication, rparticipant)\n\t        elif which == 'track_subscription_failed':\n\t            sid = event.track_subscription_failed.participant_sid\n\t            rparticipant = self.participants[sid]\n\t            error = event.track_subscription_failed.error\n\t            self.emit('track_subscription_failed', rparticipant,\n\t                      event.track_subscription_failed.track_sid, error)\n\t        elif which == 'track_muted':\n", "            sid = event.track_muted.participant_sid\n\t            participant = self._retrieve_participant(sid)\n\t            publication = participant.tracks[event.track_muted.track_sid]\n\t            publication._info.muted = True\n\t            if publication.track:\n\t                publication.track._info.muted = True\n\t            self.emit('track_muted', participant, publication)\n\t        elif which == 'track_unmuted':\n\t            sid = event.track_unmuted.participant_sid\n\t            participant = self._retrieve_participant(sid)\n", "            publication = participant.tracks[event.track_unmuted.track_sid]\n\t            publication._info.muted = False\n\t            if publication.track:\n\t                publication.track._info.muted = False\n\t            self.emit('track_unmuted', participant, publication)\n\t        elif which == 'active_speakers_changed':\n\t            speakers: list[Participant] = []\n\t            for sid in event.active_speakers_changed.participant_sids:\n\t                speakers.append(self._retrieve_participant(sid))\n\t            self.emit('active_speakers_changed', speakers)\n", "        elif which == 'connection_quality_changed':\n\t            sid = event.connection_quality_changed.participant_sid\n\t            p = self._retrieve_participant(sid)\n\t            self.emit('connection_quality_changed',\n\t                      p, event.connection_quality_changed.quality)\n\t        elif which == 'data_received':\n\t            rparticipant = self.participants[event.data_received.participant_sid]\n\t            buffer_info = event.data_received.data\n\t            native_data = ctypes.cast(buffer_info.data_ptr,\n\t                                      ctypes.POINTER(ctypes.c_byte\n", "                                                     * buffer_info.data_len)).contents\n\t            data = bytearray(native_data)\n\t            FfiHandle(buffer_info.handle.id)\n\t            self.emit('data_received', data,\n\t                      event.data_received.kind, rparticipant)\n\t        elif which == 'connection_state_changed':\n\t            state = event.connection_state_changed.state\n\t            self.connection_state = state\n\t            self.emit('connection_state_changed', state)\n\t        elif which == 'connected':\n", "            self.emit('connected')\n\t        elif which == 'disconnected':\n\t            self.emit('disconnected')\n\t        elif which == 'reconnecting':\n\t            self.emit('reconnecting')\n\t        elif which == 'reconnected':\n\t            self.emit('reconnected')\n\t    def _retrieve_participant(self, sid: str) -> Participant:\n\t        \"\"\" Retrieve a participant by sid, returns the LocalParticipant\n\t          if sid matches \"\"\"\n", "        if sid == self.local_participant.sid:\n\t            return self.local_participant\n\t        else:\n\t            return self.participants[sid]\n\t    def _create_remote_participant(self, handle: FfiHandle,\n\t                                   info: proto_participant.ParticipantInfo) \\\n\t            -> RemoteParticipant:\n\t        if info.sid in self.participants:\n\t            raise Exception('participant already exists')\n\t        participant = RemoteParticipant(handle, info)\n", "        self.participants[participant.sid] = participant\n\t        return participant\n"]}
{"filename": "livekit/_ffi_client.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport asyncio\n\timport ctypes\n\timport platform\n\timport threading\n\timport pkg_resources\n\tfrom pyee.asyncio import EventEmitter\n\tfrom ._proto import ffi_pb2 as proto_ffi\n", "os = platform.system().lower()\n\tarch = platform.machine().lower()\n\tlib_path = 'lib/{}/{}'.format(os, arch)\n\tif os == \"windows\":\n\t    lib_file = 'livekit_ffi.dll'\n\telif os == \"darwin\":\n\t    lib_file = 'liblivekit_ffi.dylib'\n\telse:\n\t    lib_file = 'liblivekit_ffi.so'\n\tlibpath = pkg_resources.resource_filename('livekit', lib_path + '/' + lib_file)\n", "ffi_lib = ctypes.CDLL(libpath)\n\t# C function types\n\tffi_lib.livekit_ffi_request.argtypes = [\n\t    ctypes.POINTER(ctypes.c_ubyte),\n\t    ctypes.c_size_t,\n\t    ctypes.POINTER(ctypes.POINTER(ctypes.c_ubyte)),\n\t    ctypes.POINTER(ctypes.c_size_t)\n\t]\n\tffi_lib.livekit_ffi_request.restype = ctypes.c_uint64\n\tffi_lib.livekit_ffi_drop_handle.argtypes = [ctypes.c_uint64]\n", "ffi_lib.livekit_ffi_drop_handle.restype = ctypes.c_bool\n\tINVALID_HANDLE = 0\n\t@ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint8), ctypes.c_size_t)\n\tdef ffi_event_callback(data_ptr: ctypes.POINTER(ctypes.c_uint8),  # type: ignore\n\t                       data_len: ctypes.c_size_t) -> None:\n\t    event_data = bytes(data_ptr[:int(data_len)])\n\t    event = proto_ffi.FfiEvent()\n\t    event.ParseFromString(event_data)\n\t    with ffi_client._lock:\n\t        loop = ffi_client._event_loop\n", "    loop.call_soon_threadsafe(dispatch_event, event)\n\tdef dispatch_event(event: proto_ffi.FfiEvent) -> None:\n\t    which = str(event.WhichOneof('message'))\n\t    ffi_client.emit(which, getattr(event, which))\n\tclass FfiClient(EventEmitter):\n\t    def __init__(self) -> None:\n\t        super().__init__()\n\t        self._lock = threading.Lock()\n\t        req = proto_ffi.FfiRequest()\n\t        cb_callback = int(ctypes.cast(\n", "            ffi_event_callback, ctypes.c_void_p).value)  # type: ignore\n\t        req.initialize.event_callback_ptr = cb_callback\n\t        self.request(req)\n\t    def set_event_loop(self, loop: asyncio.AbstractEventLoop) -> None:\n\t        with self._lock:\n\t            self._event_loop = loop\n\t    def request(self, req: proto_ffi.FfiRequest) -> proto_ffi.FfiResponse:\n\t        proto_data = req.SerializeToString()\n\t        proto_len = len(proto_data)\n\t        data = (ctypes.c_ubyte * proto_len)(*proto_data)\n", "        resp_ptr = ctypes.POINTER(ctypes.c_ubyte)()\n\t        resp_len = ctypes.c_size_t()\n\t        handle = ffi_lib.livekit_ffi_request(\n\t            data, proto_len, ctypes.byref(resp_ptr), ctypes.byref(resp_len))\n\t        resp_data = bytes(resp_ptr[:resp_len.value])\n\t        resp = proto_ffi.FfiResponse()\n\t        resp.ParseFromString(resp_data)\n\t        FfiHandle(handle)\n\t        return resp\n\tclass FfiHandle:\n", "    def __init__(self, handle: int) -> None:\n\t        self.handle = handle\n\t    def __del__(self):\n\t        if self.handle != INVALID_HANDLE:\n\t            assert ffi_lib.livekit_ffi_drop_handle(\n\t                ctypes.c_uint64(self.handle))\n\tffi_client = FfiClient()\n\tffi_client.set_event_loop(asyncio.get_event_loop())\n"]}
{"filename": "livekit/audio_source.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import audio_frame_pb2 as proto_audio_frame\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom .audio_frame import AudioFrame\n\tclass AudioSource:\n\t    def __init__(self) -> None:\n\t        req = proto_ffi.FfiRequest()\n", "        req.new_audio_source.type = proto_audio_frame.AudioSourceType.AUDIO_SOURCE_NATIVE\n\t        resp = ffi_client.request(req)\n\t        self._info = resp.new_audio_source.source\n\t        self._ffi_handle = FfiHandle(self._info.handle.id)\n\t    def capture_frame(self, frame: AudioFrame) -> None:\n\t        req = proto_ffi.FfiRequest()\n\t        req.capture_audio_frame.source_handle = self._ffi_handle.handle\n\t        req.capture_audio_frame.buffer_handle = frame._ffi_handle.handle\n\t        ffi_client.request(req)\n"]}
{"filename": "livekit/__init__.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"LiveKit Client SDK\n\t\"\"\"\n\t# flake8: noqa\n\tfrom ._proto.room_pb2 import (\n\t    ConnectionQuality,\n\t    ConnectionState,\n\t    DataPacketKind,\n", "    TrackPublishOptions,\n\t)\n\tfrom ._proto.track_pb2 import StreamState, TrackKind, TrackSource\n\tfrom ._proto.video_frame_pb2 import VideoFormatType, VideoFrameBufferType, VideoRotation\n\tfrom .audio_frame import AudioFrame\n\tfrom .audio_source import AudioSource\n\tfrom .audio_stream import AudioStream\n\tfrom .participant import LocalParticipant, Participant, RemoteParticipant\n\tfrom .room import ConnectError, Room, RoomOptions\n\tfrom .track import (\n", "    LocalAudioTrack,\n\t    LocalVideoTrack,\n\t    RemoteAudioTrack,\n\t    RemoteVideoTrack,\n\t    Track,\n\t)\n\tfrom .track_publication import (\n\t    LocalTrackPublication,\n\t    RemoteTrackPublication,\n\t    TrackPublication,\n", ")\n\tfrom .video_frame import (\n\t    ArgbFrame,\n\t    I010Buffer,\n\t    I420ABuffer,\n\t    I420Buffer,\n\t    I422Buffer,\n\t    NativeVideoFrameBuffer,\n\t    NV12Buffer,\n\t    PlanarYuv8Buffer,\n", "    PlanarYuv16Buffer,\n\t    PlanarYuvBuffer,\n\t    VideoFrame,\n\t    VideoFrameBuffer,\n\t)\n\tfrom .video_source import VideoSource\n\tfrom .video_stream import VideoStream\n\t__version__ = \"0.2.0\"\n"]}
{"filename": "livekit/audio_stream.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\tfrom weakref import WeakValueDictionary\n\tfrom pyee.asyncio import EventEmitter\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import audio_frame_pb2 as proto_audio_frame\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom .audio_frame import AudioFrame\n\tfrom .track import Track\n", "class AudioStream(EventEmitter):\n\t    _streams: WeakValueDictionary[int, 'AudioStream'] = WeakValueDictionary()\n\t    _initialized = False\n\t    @classmethod\n\t    def initalize(cls) -> None:\n\t        if cls._initialized:\n\t            return\n\t        cls._initialized = True\n\t        # See VideoStream for the reason we don't use the instance method for the listener\n\t        ffi_client.add_listener('audio_stream_event',\n", "                                cls._on_audio_stream_event)\n\t    @classmethod\n\t    def _on_audio_stream_event(cls, event: proto_audio_frame.AudioStreamEvent) -> None:\n\t        stream = cls._streams.get(event.source_handle)\n\t        if stream is None:\n\t            return\n\t        which = event.WhichOneof('message')\n\t        if which == 'frame_received':\n\t            frame_info = event.frame_received.frame\n\t            ffi_handle = FfiHandle(frame_info.handle.id)\n", "            frame = AudioFrame(frame_info, ffi_handle)\n\t            stream._on_frame_received(frame)\n\t    def __init__(self, track: Track) -> None:\n\t        super().__init__()\n\t        self.__class__.initalize()\n\t        req = proto_ffi.FfiRequest()\n\t        new_audio_stream = req.new_audio_stream\n\t        new_audio_stream.track_handle = track._ffi_handle.handle\n\t        new_audio_stream.type = proto_audio_frame.AudioStreamType.AUDIO_STREAM_NATIVE\n\t        resp = ffi_client.request(req)\n", "        stream_info = resp.new_audio_stream.stream\n\t        self._streams[stream_info.handle.id] = self\n\t        self._ffi_handle = FfiHandle(stream_info.handle.id)\n\t        self._info = stream_info\n\t        self._track = track\n\t    def _on_frame_received(self, frame: AudioFrame) -> None:\n\t        self.emit('frame_received', frame)\n\t    def __del__(self):\n\t        self._streams.pop(self._ffi_handle.handle, None)\n"]}
{"filename": "livekit/audio_frame.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport ctypes\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import audio_frame_pb2 as proto_audio\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tclass AudioFrame():\n\t    def __init__(self, info: proto_audio.AudioFrameBufferInfo, ffi_handle: FfiHandle) -> None:\n\t        self._info = info\n", "        self._ffi_handle = ffi_handle\n\t        data_len = self.num_channels * self.samples_per_channel\n\t        self.data = ctypes.cast(info.data_ptr,\n\t                                ctypes.POINTER(ctypes.c_int16 * data_len)).contents\n\t    @staticmethod\n\t    def create(sample_rate: int, num_channels: int, samples_per_channel: int) -> 'AudioFrame':\n\t        # TODO(theomonnom): There should be no problem to directly send audio date from a Python created ctypes buffer\n\t        req = proto_ffi.FfiRequest()\n\t        req.alloc_audio_buffer.sample_rate = sample_rate\n\t        req.alloc_audio_buffer.num_channels = num_channels\n", "        req.alloc_audio_buffer.samples_per_channel = samples_per_channel\n\t        resp = ffi_client.request(req)\n\t        info = resp.alloc_audio_buffer.buffer\n\t        ffi_handle = FfiHandle(info.handle.id)\n\t        return AudioFrame(info, ffi_handle)\n\t    def remix_and_resample(self, sample_rate: int, num_channels: int) -> 'AudioFrame':\n\t        \"\"\" Resample the audio frame to the given sample rate and number of channels.\"\"\"\n\t        req = proto_ffi.FfiRequest()\n\t        req.new_audio_resampler.CopyFrom(\n\t            proto_audio.NewAudioResamplerRequest())\n", "        resp = ffi_client.request(req)\n\t        resampler_handle = FfiHandle(\n\t            resp.new_audio_resampler.resampler.handle.id)\n\t        resample_req = proto_ffi.FfiRequest()\n\t        resample_req.remix_and_resample.resampler_handle = resampler_handle.handle\n\t        resample_req.remix_and_resample.buffer_handle = self._ffi_handle.handle\n\t        resample_req.remix_and_resample.sample_rate = sample_rate\n\t        resample_req.remix_and_resample.num_channels = num_channels\n\t        resp = ffi_client.request(resample_req)\n\t        info = resp.remix_and_resample.buffer\n", "        ffi_handle = FfiHandle(info.handle.id)\n\t        return AudioFrame(info, ffi_handle)\n\t    @property\n\t    def sample_rate(self) -> int:\n\t        return self._info.sample_rate\n\t    @property\n\t    def num_channels(self) -> int:\n\t        return self._info.num_channels\n\t    @property\n\t    def samples_per_channel(self) -> int:\n", "        return self._info.samples_per_channel\n"]}
{"filename": "livekit/track.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\tfrom typing import TYPE_CHECKING\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom ._proto import track_pb2 as proto_track\n\tif TYPE_CHECKING:\n\t    from .audio_source import AudioSource\n\t    from .video_source import VideoSource\n", "class Track():\n\t    def __init__(self, handle: FfiHandle, info: proto_track.TrackInfo):\n\t        self._info = info\n\t        self._ffi_handle = handle\n\t    @property\n\t    def sid(self) -> str:\n\t        return self._info.sid\n\t    @property\n\t    def name(self) -> str:\n\t        return self._info.name\n", "    @property\n\t    def kind(self) -> proto_track.TrackKind.ValueType:\n\t        return self._info.kind\n\t    @property\n\t    def stream_state(self) -> proto_track.StreamState.ValueType:\n\t        return self._info.stream_state\n\t    @property\n\t    def muted(self) -> bool:\n\t        return self._info.muted\n\t    def update_info(self, info: proto_track.TrackInfo):\n", "        self._info = info\n\tclass LocalAudioTrack(Track):\n\t    def __init__(self, handle: FfiHandle, info: proto_track.TrackInfo):\n\t        super().__init__(handle, info)\n\t    @staticmethod\n\t    def create_audio_track(name: str, source: 'AudioSource') -> 'LocalAudioTrack':\n\t        req = proto_ffi.FfiRequest()\n\t        req.create_audio_track.name = name\n\t        req.create_audio_track.source_handle = source._ffi_handle.handle\n\t        resp = ffi_client.request(req)\n", "        track_info = resp.create_audio_track.track\n\t        ffi_handle = FfiHandle(track_info.handle.id)\n\t        return LocalAudioTrack(ffi_handle, track_info)\n\tclass LocalVideoTrack(Track):\n\t    def __init__(self, handle: FfiHandle, info: proto_track.TrackInfo):\n\t        super().__init__(handle, info)\n\t    @staticmethod\n\t    def create_video_track(name: str, source: 'VideoSource') -> 'LocalVideoTrack':\n\t        req = proto_ffi.FfiRequest()\n\t        req.create_video_track.name = name\n", "        req.create_video_track.source_handle = source._ffi_handle.handle\n\t        resp = ffi_client.request(req)\n\t        track_info = resp.create_video_track.track\n\t        ffi_handle = FfiHandle(track_info.handle.id)\n\t        return LocalVideoTrack(ffi_handle, track_info)\n\tclass RemoteAudioTrack(Track):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_track.TrackInfo):\n\t        super().__init__(ffi_handle, info)\n\tclass RemoteVideoTrack(Track):\n\t    def __init__(self, ffi_handle: FfiHandle, info: proto_track.TrackInfo):\n", "        super().__init__(ffi_handle, info)\n"]}
{"filename": "livekit/video_source.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom ._proto import video_frame_pb2 as proto_video_frame\n\tfrom .video_frame import VideoFrame\n\tclass VideoSource:\n\t    def __init__(self) -> None:\n\t        req = proto_ffi.FfiRequest()\n", "        req.new_video_source.type = proto_video_frame.VideoSourceType.VIDEO_SOURCE_NATIVE\n\t        resp = ffi_client.request(req)\n\t        self._info = resp.new_video_source.source\n\t        self._ffi_handle = FfiHandle(self._info.handle.id)\n\t    def capture_frame(self, frame: VideoFrame) -> None:\n\t        req = proto_ffi.FfiRequest()\n\t        req.capture_video_frame.source_handle = self._ffi_handle.handle\n\t        req.capture_video_frame.buffer_handle = frame.buffer._ffi_handle.handle\n\t        req.capture_video_frame.frame.rotation = frame.rotation\n\t        req.capture_video_frame.frame.timestamp_us = frame.timestamp_us\n", "        ffi_client.request(req)\n"]}
{"filename": "livekit/video_stream.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\tfrom weakref import WeakValueDictionary\n\tfrom pyee.asyncio import EventEmitter\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom ._proto import video_frame_pb2 as proto_video_frame\n\tfrom .track import Track\n\tfrom .video_frame import VideoFrame, VideoFrameBuffer\n", "class VideoStream(EventEmitter):\n\t    _streams: WeakValueDictionary[int, 'VideoStream'] = WeakValueDictionary()\n\t    _initialized = False\n\t    @classmethod\n\t    def initalize(cls) -> None:\n\t        if cls._initialized:\n\t            return\n\t        cls._initialized = True\n\t        # Not using the instance method the listener because it keeps a strong reference\n\t        # to the instance.\n", "        # And we rely on __del__ to determine when the instance isn't used\n\t        ffi_client.add_listener('video_stream_event',\n\t                                cls._on_video_stream_event)\n\t    @classmethod\n\t    def _on_video_stream_event(cls, event: proto_video_frame.VideoStreamEvent) -> None:\n\t        stream = cls._streams.get(event.stream_handle)\n\t        if stream is None:\n\t            return\n\t        which = event.WhichOneof('message')\n\t        if which == 'frame_received':\n", "            frame_info = event.frame_received.frame\n\t            buffer_info = event.frame_received.buffer\n\t            ffi_handle = FfiHandle(buffer_info.handle.id)\n\t            frame = VideoFrame(frame_info.timestamp_us, frame_info.rotation,\n\t                               VideoFrameBuffer.create(ffi_handle, buffer_info))\n\t            stream._on_frame_received(frame)\n\t    def __init__(self, track: Track) -> None:\n\t        super().__init__()\n\t        self.__class__.initalize()\n\t        req = proto_ffi.FfiRequest()\n", "        new_video_stream = req.new_video_stream\n\t        new_video_stream.track_handle = track._ffi_handle.handle\n\t        new_video_stream.type = proto_video_frame.VideoStreamType.VIDEO_STREAM_NATIVE\n\t        resp = ffi_client.request(req)\n\t        stream_info = resp.new_video_stream.stream\n\t        self._streams[stream_info.handle.id] = self\n\t        self._ffi_handle = FfiHandle(stream_info.handle.id)\n\t        self._info = stream_info\n\t        self._track = track\n\t    def _on_frame_received(self, frame: VideoFrame) -> None:\n", "        self.emit('frame_received', frame)\n\t    def __del__(self) -> None:\n\t        self._streams.pop(self._ffi_handle.handle, None)\n"]}
{"filename": "livekit/participant.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport asyncio\n\timport ctypes\n\tfrom typing import List, Optional, Union\n\tfrom ._ffi_client import FfiHandle, ffi_client\n\tfrom ._proto import ffi_pb2 as proto_ffi\n\tfrom ._proto import participant_pb2 as proto_participant\n\tfrom ._proto import room_pb2 as proto_room\n", "from ._proto.room_pb2 import DataPacketKind, TrackPublishOptions\n\tfrom .track import LocalAudioTrack, LocalVideoTrack, Track\n\tfrom .track_publication import (\n\t    LocalTrackPublication,\n\t    RemoteTrackPublication,\n\t    TrackPublication,\n\t)\n\tclass PublishTrackError(Exception):\n\t    def __init__(self, message: str) -> None:\n\t        self.message = message\n", "class UnpublishTrackError(Exception):\n\t    def __init__(self, message: str) -> None:\n\t        self.message = message\n\tclass PublishDataError(Exception):\n\t    def __init__(self, message: str) -> None:\n\t        self.message = message\n\tclass Participant():\n\t    def __init__(self, handle: FfiHandle, info: proto_participant.ParticipantInfo) \\\n\t            -> None:\n\t        self._info = info\n", "        self._ffi_handle = handle\n\t        self.tracks: dict[str, TrackPublication] = {}\n\t    @property\n\t    def sid(self) -> str:\n\t        return self._info.sid\n\t    @property\n\t    def name(self) -> str:\n\t        return self._info.name\n\t    @property\n\t    def identity(self) -> str:\n", "        return self._info.identity\n\t    @property\n\t    def metadata(self) -> str:\n\t        return self._info.metadata\n\tclass LocalParticipant(Participant):\n\t    def __init__(self, handle: FfiHandle, info: proto_participant.ParticipantInfo) \\\n\t            -> None:\n\t        super().__init__(handle, info)\n\t        self.tracks: dict[str, LocalTrackPublication] = {}  # type: ignore\n\t    async def publish_data(self,\n", "                           payload: Union[bytes, str],\n\t                           kind: DataPacketKind.ValueType = DataPacketKind.KIND_RELIABLE,\n\t                           destination_sids: Optional[Union[List[str], List['RemoteParticipant']]] = None) -> None:\n\t        if isinstance(payload, str):\n\t            payload = payload.encode('utf-8')\n\t        data_len = len(payload)\n\t        cdata = (ctypes.c_byte * data_len)(*payload)\n\t        req = proto_ffi.FfiRequest()\n\t        req.publish_data.local_participant_handle = self._ffi_handle.handle\n\t        req.publish_data.data_ptr = ctypes.addressof(cdata)\n", "        req.publish_data.data_len = data_len\n\t        req.publish_data.kind = kind\n\t        if destination_sids is not None:\n\t            sids = []\n\t            for p in destination_sids:\n\t                if isinstance(p, RemoteParticipant):\n\t                    sids.append(p.sid)\n\t                else:\n\t                    sids.append(p)\n\t            req.publish_data.destination_sids.extend(sids)\n", "        resp = ffi_client.request(req)\n\t        future: asyncio.Future[proto_room.PublishDataCallback] = asyncio.Future(\n\t        )\n\t        @ffi_client.on('publish_data')\n\t        def on_publish_callback(cb: proto_room.PublishDataCallback):\n\t            if cb.async_id == resp.publish_data.async_id:\n\t                future.set_result(cb)\n\t                ffi_client.remove_listener(\n\t                    'publish_data', on_publish_callback)\n\t        cb = await future\n", "        if cb.error:\n\t            raise PublishDataError(cb.error)\n\t    async def publish_track(self, track: Track, options: TrackPublishOptions) \\\n\t            -> TrackPublication:\n\t        if not isinstance(track, LocalAudioTrack) \\\n\t                and not isinstance(track, LocalVideoTrack):\n\t            raise Exception('cannot publish a remote track')\n\t        req = proto_ffi.FfiRequest()\n\t        req.publish_track.track_handle = track._ffi_handle.handle\n\t        req.publish_track.local_participant_handle = self._ffi_handle.handle\n", "        req.publish_track.options.CopyFrom(options)\n\t        resp = ffi_client.request(req)\n\t        future: asyncio.Future[proto_room.PublishTrackCallback] = asyncio.Future(\n\t        )\n\t        @ffi_client.on('publish_track')\n\t        def on_publish_callback(cb: proto_room.PublishTrackCallback):\n\t            if cb.async_id == resp.publish_track.async_id:\n\t                future.set_result(cb)\n\t                ffi_client.remove_listener(\n\t                    'publish_track', on_publish_callback)\n", "        cb = await future\n\t        if cb.error:\n\t            raise PublishTrackError(cb.error)\n\t        pub_info = cb.publication\n\t        pub_handle = FfiHandle(pub_info.handle.id)\n\t        track_publication = LocalTrackPublication(pub_handle, pub_info)\n\t        track_publication.track = track\n\t        self.tracks[track_publication.sid] = track_publication\n\t        return track_publication\n\t    async def unpublish_track(self, track_sid: str) -> None:\n", "        req = proto_ffi.FfiRequest()\n\t        req.unpublish_track.local_participant_handle = self._ffi_handle.handle\n\t        req.unpublish_track.track_sid = track_sid\n\t        resp = ffi_client.request(req)\n\t        future: asyncio.Future[proto_room.UnpublishTrackCallback] = asyncio.Future(\n\t        )\n\t        @ffi_client.on('unpublish_track')\n\t        def on_unpublish_callback(cb: proto_room.UnpublishTrackCallback):\n\t            if cb.async_id == resp.unpublish_track.async_id:\n\t                future.set_result(cb)\n", "                ffi_client.remove_listener(\n\t                    'unpublish_track', on_unpublish_callback)\n\t        cb = await future\n\t        if cb.error:\n\t            raise UnpublishTrackError(cb.error)\n\t        publication = self.tracks.pop(track_sid)\n\t        publication.track = None\n\tclass RemoteParticipant(Participant):\n\t    def __init__(self, handle: FfiHandle, info: proto_participant.ParticipantInfo) \\\n\t            -> None:\n", "        super().__init__(handle, info)\n\t        self.tracks: dict[str, RemoteTrackPublication] = {}  # type: ignore\n"]}
{"filename": "livekit/_proto/ffi_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: ffi.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "from . import track_pb2 as track__pb2\n\tfrom . import room_pb2 as room__pb2\n\tfrom . import video_frame_pb2 as video__frame__pb2\n\tfrom . import audio_frame_pb2 as audio__frame__pb2\n\tDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\tffi.proto\\x12\\rlivekit.proto\\x1a\\x0btrack.proto\\x1a\\nroom.proto\\x1a\\x11video_frame.proto\\x1a\\x11\\x61udio_frame.proto\\\"\\x83\\x0b\\n\\nFfiRequest\\x12\\x36\\n\\ninitialize\\x18\\x01 \\x01(\\x0b\\x32 .livekit.proto.InitializeRequestH\\x00\\x12\\x30\\n\\x07\\x64ispose\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.DisposeRequestH\\x00\\x12\\x30\\n\\x07\\x63onnect\\x18\\x03 \\x01(\\x0b\\x32\\x1d.livekit.proto.ConnectRequestH\\x00\\x12\\x36\\n\\ndisconnect\\x18\\x04 \\x01(\\x0b\\x32 .livekit.proto.DisconnectRequestH\\x00\\x12;\\n\\rpublish_track\\x18\\x05 \\x01(\\x0b\\x32\\\".livekit.proto.PublishTrackRequestH\\x00\\x12?\\n\\x0funpublish_track\\x18\\x06 \\x01(\\x0b\\x32$.livekit.proto.UnpublishTrackRequestH\\x00\\x12\\x39\\n\\x0cpublish_data\\x18\\x07 \\x01(\\x0b\\x32!.livekit.proto.PublishDataRequestH\\x00\\x12=\\n\\x0eset_subscribed\\x18\\x08 \\x01(\\x0b\\x32#.livekit.proto.SetSubscribedRequestH\\x00\\x12\\x44\\n\\x12\\x63reate_video_track\\x18\\t \\x01(\\x0b\\x32&.livekit.proto.CreateVideoTrackRequestH\\x00\\x12\\x44\\n\\x12\\x63reate_audio_track\\x18\\n \\x01(\\x0b\\x32&.livekit.proto.CreateAudioTrackRequestH\\x00\\x12\\x44\\n\\x12\\x61lloc_video_buffer\\x18\\x0b \\x01(\\x0b\\x32&.livekit.proto.AllocVideoBufferRequestH\\x00\\x12@\\n\\x10new_video_stream\\x18\\x0c \\x01(\\x0b\\x32$.livekit.proto.NewVideoStreamRequestH\\x00\\x12@\\n\\x10new_video_source\\x18\\r \\x01(\\x0b\\x32$.livekit.proto.NewVideoSourceRequestH\\x00\\x12\\x46\\n\\x13\\x63\\x61pture_video_frame\\x18\\x0e \\x01(\\x0b\\x32\\'.livekit.proto.CaptureVideoFrameRequestH\\x00\\x12/\\n\\x07to_i420\\x18\\x0f \\x01(\\x0b\\x32\\x1c.livekit.proto.ToI420RequestH\\x00\\x12/\\n\\x07to_argb\\x18\\x10 \\x01(\\x0b\\x32\\x1c.livekit.proto.ToArgbRequestH\\x00\\x12\\x44\\n\\x12\\x61lloc_audio_buffer\\x18\\x11 \\x01(\\x0b\\x32&.livekit.proto.AllocAudioBufferRequestH\\x00\\x12@\\n\\x10new_audio_stream\\x18\\x12 \\x01(\\x0b\\x32$.livekit.proto.NewAudioStreamRequestH\\x00\\x12@\\n\\x10new_audio_source\\x18\\x13 \\x01(\\x0b\\x32$.livekit.proto.NewAudioSourceRequestH\\x00\\x12\\x46\\n\\x13\\x63\\x61pture_audio_frame\\x18\\x14 \\x01(\\x0b\\x32\\'.livekit.proto.CaptureAudioFrameRequestH\\x00\\x12\\x46\\n\\x13new_audio_resampler\\x18\\x15 \\x01(\\x0b\\x32\\'.livekit.proto.NewAudioResamplerRequestH\\x00\\x12\\x44\\n\\x12remix_and_resample\\x18\\x16 \\x01(\\x0b\\x32&.livekit.proto.RemixAndResampleRequestH\\x00\\x42\\t\\n\\x07message\\\"\\x9a\\x0b\\n\\x0b\\x46\\x66iResponse\\x12\\x37\\n\\ninitialize\\x18\\x01 \\x01(\\x0b\\x32!.livekit.proto.InitializeResponseH\\x00\\x12\\x31\\n\\x07\\x64ispose\\x18\\x02 \\x01(\\x0b\\x32\\x1e.livekit.proto.DisposeResponseH\\x00\\x12\\x31\\n\\x07\\x63onnect\\x18\\x03 \\x01(\\x0b\\x32\\x1e.livekit.proto.ConnectResponseH\\x00\\x12\\x37\\n\\ndisconnect\\x18\\x04 \\x01(\\x0b\\x32!.livekit.proto.DisconnectResponseH\\x00\\x12<\\n\\rpublish_track\\x18\\x05 \\x01(\\x0b\\x32#.livekit.proto.PublishTrackResponseH\\x00\\x12@\\n\\x0funpublish_track\\x18\\x06 \\x01(\\x0b\\x32%.livekit.proto.UnpublishTrackResponseH\\x00\\x12:\\n\\x0cpublish_data\\x18\\x07 \\x01(\\x0b\\x32\\\".livekit.proto.PublishDataResponseH\\x00\\x12>\\n\\x0eset_subscribed\\x18\\x08 \\x01(\\x0b\\x32$.livekit.proto.SetSubscribedResponseH\\x00\\x12\\x45\\n\\x12\\x63reate_video_track\\x18\\t \\x01(\\x0b\\x32\\'.livekit.proto.CreateVideoTrackResponseH\\x00\\x12\\x45\\n\\x12\\x63reate_audio_track\\x18\\n \\x01(\\x0b\\x32\\'.livekit.proto.CreateAudioTrackResponseH\\x00\\x12\\x45\\n\\x12\\x61lloc_video_buffer\\x18\\x0b \\x01(\\x0b\\x32\\'.livekit.proto.AllocVideoBufferResponseH\\x00\\x12\\x41\\n\\x10new_video_stream\\x18\\x0c \\x01(\\x0b\\x32%.livekit.proto.NewVideoStreamResponseH\\x00\\x12\\x41\\n\\x10new_video_source\\x18\\r \\x01(\\x0b\\x32%.livekit.proto.NewVideoSourceResponseH\\x00\\x12G\\n\\x13\\x63\\x61pture_video_frame\\x18\\x0e \\x01(\\x0b\\x32(.livekit.proto.CaptureVideoFrameResponseH\\x00\\x12\\x30\\n\\x07to_i420\\x18\\x0f \\x01(\\x0b\\x32\\x1d.livekit.proto.ToI420ResponseH\\x00\\x12\\x30\\n\\x07to_argb\\x18\\x10 \\x01(\\x0b\\x32\\x1d.livekit.proto.ToArgbResponseH\\x00\\x12\\x45\\n\\x12\\x61lloc_audio_buffer\\x18\\x11 \\x01(\\x0b\\x32\\'.livekit.proto.AllocAudioBufferResponseH\\x00\\x12\\x41\\n\\x10new_audio_stream\\x18\\x12 \\x01(\\x0b\\x32%.livekit.proto.NewAudioStreamResponseH\\x00\\x12\\x41\\n\\x10new_audio_source\\x18\\x13 \\x01(\\x0b\\x32%.livekit.proto.NewAudioSourceResponseH\\x00\\x12G\\n\\x13\\x63\\x61pture_audio_frame\\x18\\x14 \\x01(\\x0b\\x32(.livekit.proto.CaptureAudioFrameResponseH\\x00\\x12G\\n\\x13new_audio_resampler\\x18\\x15 \\x01(\\x0b\\x32(.livekit.proto.NewAudioResamplerResponseH\\x00\\x12\\x45\\n\\x12remix_and_resample\\x18\\x16 \\x01(\\x0b\\x32\\'.livekit.proto.RemixAndResampleResponseH\\x00\\x42\\t\\n\\x07message\\\"\\xd0\\x04\\n\\x08\\x46\\x66iEvent\\x12.\\n\\nroom_event\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.RoomEventH\\x00\\x12\\x30\\n\\x0btrack_event\\x18\\x02 \\x01(\\x0b\\x32\\x19.livekit.proto.TrackEventH\\x00\\x12=\\n\\x12video_stream_event\\x18\\x03 \\x01(\\x0b\\x32\\x1f.livekit.proto.VideoStreamEventH\\x00\\x12=\\n\\x12\\x61udio_stream_event\\x18\\x04 \\x01(\\x0b\\x32\\x1f.livekit.proto.AudioStreamEventH\\x00\\x12\\x31\\n\\x07\\x63onnect\\x18\\x05 \\x01(\\x0b\\x32\\x1e.livekit.proto.ConnectCallbackH\\x00\\x12\\x37\\n\\ndisconnect\\x18\\x06 \\x01(\\x0b\\x32!.livekit.proto.DisconnectCallbackH\\x00\\x12\\x31\\n\\x07\\x64ispose\\x18\\x07 \\x01(\\x0b\\x32\\x1e.livekit.proto.DisposeCallbackH\\x00\\x12<\\n\\rpublish_track\\x18\\x08 \\x01(\\x0b\\x32#.livekit.proto.PublishTrackCallbackH\\x00\\x12@\\n\\x0funpublish_track\\x18\\t \\x01(\\x0b\\x32%.livekit.proto.UnpublishTrackCallbackH\\x00\\x12:\\n\\x0cpublish_data\\x18\\n \\x01(\\x0b\\x32\\\".livekit.proto.PublishDataCallbackH\\x00\\x42\\t\\n\\x07message\\\"/\\n\\x11InitializeRequest\\x12\\x1a\\n\\x12\\x65vent_callback_ptr\\x18\\x01 \\x01(\\x04\\\"\\x14\\n\\x12InitializeResponse\\\"\\x1f\\n\\x0e\\x44isposeRequest\\x12\\r\\n\\x05\\x61sync\\x18\\x01 \\x01(\\x08\\\"5\\n\\x0f\\x44isposeResponse\\x12\\x15\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04H\\x00\\x88\\x01\\x01\\x42\\x0b\\n\\t_async_id\\\"#\\n\\x0f\\x44isposeCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'ffi_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n", "  _FFIREQUEST._serialized_start=92\n\t  _FFIREQUEST._serialized_end=1503\n\t  _FFIRESPONSE._serialized_start=1506\n\t  _FFIRESPONSE._serialized_end=2940\n\t  _FFIEVENT._serialized_start=2943\n\t  _FFIEVENT._serialized_end=3535\n\t  _INITIALIZEREQUEST._serialized_start=3537\n\t  _INITIALIZEREQUEST._serialized_end=3584\n\t  _INITIALIZERESPONSE._serialized_start=3586\n\t  _INITIALIZERESPONSE._serialized_end=3606\n", "  _DISPOSEREQUEST._serialized_start=3608\n\t  _DISPOSEREQUEST._serialized_end=3639\n\t  _DISPOSERESPONSE._serialized_start=3641\n\t  _DISPOSERESPONSE._serialized_end=3694\n\t  _DISPOSECALLBACK._serialized_start=3696\n\t  _DISPOSECALLBACK._serialized_end=3731\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/track_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: track.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "from . import handle_pb2 as handle__pb2\n\tDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x0btrack.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\">\\n\\x17\\x43reateVideoTrackRequest\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rsource_handle\\x18\\x02 \\x01(\\x04\\\"C\\n\\x18\\x43reateVideoTrackResponse\\x12\\'\\n\\x05track\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\">\\n\\x17\\x43reateAudioTrackRequest\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rsource_handle\\x18\\x02 \\x01(\\x04\\\"C\\n\\x18\\x43reateAudioTrackResponse\\x12\\'\\n\\x05track\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\"\\x0c\\n\\nTrackEvent\\\"\\x9a\\x02\\n\\x14TrackPublicationInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12&\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x18.livekit.proto.TrackKind\\x12*\\n\\x06source\\x18\\x05 \\x01(\\x0e\\x32\\x1a.livekit.proto.TrackSource\\x12\\x13\\n\\x0bsimulcasted\\x18\\x06 \\x01(\\x08\\x12\\r\\n\\x05width\\x18\\x07 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x08 \\x01(\\r\\x12\\x11\\n\\tmime_type\\x18\\t \\x01(\\t\\x12\\r\\n\\x05muted\\x18\\n \\x01(\\x08\\x12\\x0e\\n\\x06remote\\x18\\x0b \\x01(\\x08\\\"\\xce\\x01\\n\\tTrackInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12&\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x18.livekit.proto.TrackKind\\x12\\x30\\n\\x0cstream_state\\x18\\x05 \\x01(\\x0e\\x32\\x1a.livekit.proto.StreamState\\x12\\r\\n\\x05muted\\x18\\x06 \\x01(\\x08\\x12\\x0e\\n\\x06remote\\x18\\x07 \\x01(\\x08*=\\n\\tTrackKind\\x12\\x10\\n\\x0cKIND_UNKNOWN\\x10\\x00\\x12\\x0e\\n\\nKIND_AUDIO\\x10\\x01\\x12\\x0e\\n\\nKIND_VIDEO\\x10\\x02*\\x81\\x01\\n\\x0bTrackSource\\x12\\x12\\n\\x0eSOURCE_UNKNOWN\\x10\\x00\\x12\\x11\\n\\rSOURCE_CAMERA\\x10\\x01\\x12\\x15\\n\\x11SOURCE_MICROPHONE\\x10\\x02\\x12\\x16\\n\\x12SOURCE_SCREENSHARE\\x10\\x03\\x12\\x1c\\n\\x18SOURCE_SCREENSHARE_AUDIO\\x10\\x04*D\\n\\x0bStreamState\\x12\\x11\\n\\rSTATE_UNKNOWN\\x10\\x00\\x12\\x10\\n\\x0cSTATE_ACTIVE\\x10\\x01\\x12\\x10\\n\\x0cSTATE_PAUSED\\x10\\x02\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'track_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n\t  _TRACKKIND._serialized_start=818\n\t  _TRACKKIND._serialized_end=879\n\t  _TRACKSOURCE._serialized_start=882\n", "  _TRACKSOURCE._serialized_end=1011\n\t  _STREAMSTATE._serialized_start=1013\n\t  _STREAMSTATE._serialized_end=1081\n\t  _CREATEVIDEOTRACKREQUEST._serialized_start=44\n\t  _CREATEVIDEOTRACKREQUEST._serialized_end=106\n\t  _CREATEVIDEOTRACKRESPONSE._serialized_start=108\n\t  _CREATEVIDEOTRACKRESPONSE._serialized_end=175\n\t  _CREATEAUDIOTRACKREQUEST._serialized_start=177\n\t  _CREATEAUDIOTRACKREQUEST._serialized_end=239\n\t  _CREATEAUDIOTRACKRESPONSE._serialized_start=241\n", "  _CREATEAUDIOTRACKRESPONSE._serialized_end=308\n\t  _TRACKEVENT._serialized_start=310\n\t  _TRACKEVENT._serialized_end=322\n\t  _TRACKPUBLICATIONINFO._serialized_start=325\n\t  _TRACKPUBLICATIONINFO._serialized_end=607\n\t  _TRACKINFO._serialized_start=610\n\t  _TRACKINFO._serialized_end=816\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/room_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: room.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "from . import handle_pb2 as handle__pb2\n\tfrom . import participant_pb2 as participant__pb2\n\tfrom . import track_pb2 as track__pb2\n\tfrom . import video_frame_pb2 as video__frame__pb2\n\tDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\nroom.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\x1a\\x11participant.proto\\x1a\\x0btrack.proto\\x1a\\x11video_frame.proto\\\"Y\\n\\x0e\\x43onnectRequest\\x12\\x0b\\n\\x03url\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05token\\x18\\x02 \\x01(\\t\\x12+\\n\\x07options\\x18\\x03 \\x01(\\x0b\\x32\\x1a.livekit.proto.RoomOptions\\\"#\\n\\x0f\\x43onnectResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"\\xf9\\x02\\n\\x0f\\x43onnectCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x12%\\n\\x04room\\x18\\x03 \\x01(\\x0b\\x32\\x17.livekit.proto.RoomInfo\\x12\\x39\\n\\x11local_participant\\x18\\x04 \\x01(\\x0b\\x32\\x1e.livekit.proto.ParticipantInfo\\x12J\\n\\x0cparticipants\\x18\\x05 \\x03(\\x0b\\x32\\x34.livekit.proto.ConnectCallback.ParticipantWithTracks\\x1a\\x87\\x01\\n\\x15ParticipantWithTracks\\x12\\x33\\n\\x0bparticipant\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.ParticipantInfo\\x12\\x39\\n\\x0cpublications\\x18\\x02 \\x03(\\x0b\\x32#.livekit.proto.TrackPublicationInfoB\\x08\\n\\x06_error\\\"(\\n\\x11\\x44isconnectRequest\\x12\\x13\\n\\x0broom_handle\\x18\\x01 \\x01(\\x04\\\"&\\n\\x12\\x44isconnectResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"&\\n\\x12\\x44isconnectCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"\\x82\\x01\\n\\x13PublishTrackRequest\\x12 \\n\\x18local_participant_handle\\x18\\x01 \\x01(\\x04\\x12\\x14\\n\\x0ctrack_handle\\x18\\x02 \\x01(\\x04\\x12\\x33\\n\\x07options\\x18\\x03 \\x01(\\x0b\\x32\\\".livekit.proto.TrackPublishOptions\\\"(\\n\\x14PublishTrackResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"\\x80\\x01\\n\\x14PublishTrackCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x12\\x38\\n\\x0bpublication\\x18\\x03 \\x01(\\x0b\\x32#.livekit.proto.TrackPublicationInfoB\\x08\\n\\x06_error\\\"g\\n\\x15UnpublishTrackRequest\\x12 \\n\\x18local_participant_handle\\x18\\x01 \\x01(\\x04\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\x12\\x19\\n\\x11stop_on_unpublish\\x18\\x03 \\x01(\\x08\\\"*\\n\\x16UnpublishTrackResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"H\\n\\x16UnpublishTrackCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x42\\x08\\n\\x06_error\\\"\\xa1\\x01\\n\\x12PublishDataRequest\\x12 \\n\\x18local_participant_handle\\x18\\x01 \\x01(\\x04\\x12\\x10\\n\\x08\\x64\\x61ta_ptr\\x18\\x02 \\x01(\\x04\\x12\\x10\\n\\x08\\x64\\x61ta_len\\x18\\x03 \\x01(\\x04\\x12+\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x1d.livekit.proto.DataPacketKind\\x12\\x18\\n\\x10\\x64\\x65stination_sids\\x18\\x05 \\x03(\\t\\\"\\'\\n\\x13PublishDataResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"E\\n\\x13PublishDataCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x42\\x08\\n\\x06_error\\\"E\\n\\x14SetSubscribedRequest\\x12\\x11\\n\\tsubscribe\\x18\\x01 \\x01(\\x08\\x12\\x1a\\n\\x12publication_handle\\x18\\x02 \\x01(\\x04\\\"\\x17\\n\\x15SetSubscribedResponse\\\";\\n\\rVideoEncoding\\x12\\x13\\n\\x0bmax_bitrate\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rmax_framerate\\x18\\x02 \\x01(\\x01\\\"$\\n\\rAudioEncoding\\x12\\x13\\n\\x0bmax_bitrate\\x18\\x01 \\x01(\\x04\\\"\\x8a\\x02\\n\\x13TrackPublishOptions\\x12\\x34\\n\\x0evideo_encoding\\x18\\x01 \\x01(\\x0b\\x32\\x1c.livekit.proto.VideoEncoding\\x12\\x34\\n\\x0e\\x61udio_encoding\\x18\\x02 \\x01(\\x0b\\x32\\x1c.livekit.proto.AudioEncoding\\x12.\\n\\x0bvideo_codec\\x18\\x03 \\x01(\\x0e\\x32\\x19.livekit.proto.VideoCodec\\x12\\x0b\\n\\x03\\x64tx\\x18\\x04 \\x01(\\x08\\x12\\x0b\\n\\x03red\\x18\\x05 \\x01(\\x08\\x12\\x11\\n\\tsimulcast\\x18\\x06 \\x01(\\x08\\x12*\\n\\x06source\\x18\\x07 \\x01(\\x0e\\x32\\x1a.livekit.proto.TrackSource\\\"P\\n\\x0bRoomOptions\\x12\\x16\\n\\x0e\\x61uto_subscribe\\x18\\x01 \\x01(\\x08\\x12\\x17\\n\\x0f\\x61\\x64\\x61ptive_stream\\x18\\x02 \\x01(\\x08\\x12\\x10\\n\\x08\\x64ynacast\\x18\\x03 \\x01(\\x08\\\"_\\n\\nBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x10\\n\\x08\\x64\\x61ta_ptr\\x18\\x02 \\x01(\\x04\\x12\\x10\\n\\x08\\x64\\x61ta_len\\x18\\x03 \\x01(\\x04\\\"\\xd9\\t\\n\\tRoomEvent\\x12\\x13\\n\\x0broom_handle\\x18\\x01 \\x01(\\x04\\x12\\x44\\n\\x15participant_connected\\x18\\x02 \\x01(\\x0b\\x32#.livekit.proto.ParticipantConnectedH\\x00\\x12J\\n\\x18participant_disconnected\\x18\\x03 \\x01(\\x0b\\x32&.livekit.proto.ParticipantDisconnectedH\\x00\\x12\\x43\\n\\x15local_track_published\\x18\\x04 \\x01(\\x0b\\x32\\\".livekit.proto.LocalTrackPublishedH\\x00\\x12G\\n\\x17local_track_unpublished\\x18\\x05 \\x01(\\x0b\\x32$.livekit.proto.LocalTrackUnpublishedH\\x00\\x12\\x38\\n\\x0ftrack_published\\x18\\x06 \\x01(\\x0b\\x32\\x1d.livekit.proto.TrackPublishedH\\x00\\x12<\\n\\x11track_unpublished\\x18\\x07 \\x01(\\x0b\\x32\\x1f.livekit.proto.TrackUnpublishedH\\x00\\x12:\\n\\x10track_subscribed\\x18\\x08 \\x01(\\x0b\\x32\\x1e.livekit.proto.TrackSubscribedH\\x00\\x12>\\n\\x12track_unsubscribed\\x18\\t \\x01(\\x0b\\x32 .livekit.proto.TrackUnsubscribedH\\x00\\x12K\\n\\x19track_subscription_failed\\x18\\n \\x01(\\x0b\\x32&.livekit.proto.TrackSubscriptionFailedH\\x00\\x12\\x30\\n\\x0btrack_muted\\x18\\x0b \\x01(\\x0b\\x32\\x19.livekit.proto.TrackMutedH\\x00\\x12\\x34\\n\\rtrack_unmuted\\x18\\x0c \\x01(\\x0b\\x32\\x1b.livekit.proto.TrackUnmutedH\\x00\\x12G\\n\\x17\\x61\\x63tive_speakers_changed\\x18\\r \\x01(\\x0b\\x32$.livekit.proto.ActiveSpeakersChangedH\\x00\\x12M\\n\\x1a\\x63onnection_quality_changed\\x18\\x0e \\x01(\\x0b\\x32\\'.livekit.proto.ConnectionQualityChangedH\\x00\\x12\\x34\\n\\rdata_received\\x18\\x0f \\x01(\\x0b\\x32\\x1b.livekit.proto.DataReceivedH\\x00\\x12I\\n\\x18\\x63onnection_state_changed\\x18\\x10 \\x01(\\x0b\\x32%.livekit.proto.ConnectionStateChangedH\\x00\\x12-\\n\\tconnected\\x18\\x11 \\x01(\\x0b\\x32\\x18.livekit.proto.ConnectedH\\x00\\x12\\x33\\n\\x0c\\x64isconnected\\x18\\x12 \\x01(\\x0b\\x32\\x1b.livekit.proto.DisconnectedH\\x00\\x12\\x33\\n\\x0creconnecting\\x18\\x13 \\x01(\\x0b\\x32\\x1b.livekit.proto.ReconnectingH\\x00\\x12\\x31\\n\\x0breconnected\\x18\\x14 \\x01(\\x0b\\x32\\x1a.livekit.proto.ReconnectedH\\x00\\x42\\t\\n\\x07message\\\"f\\n\\x08RoomInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x10\\n\\x08metadata\\x18\\x04 \\x01(\\t\\\"D\\n\\x14ParticipantConnected\\x12,\\n\\x04info\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.ParticipantInfo\\\"2\\n\\x17ParticipantDisconnected\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\\"(\\n\\x13LocalTrackPublished\\x12\\x11\\n\\ttrack_sid\\x18\\x01 \\x01(\\t\\\"0\\n\\x15LocalTrackUnpublished\\x12\\x17\\n\\x0fpublication_sid\\x18\\x01 \\x01(\\t\\\"c\\n\\x0eTrackPublished\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x38\\n\\x0bpublication\\x18\\x02 \\x01(\\x0b\\x32#.livekit.proto.TrackPublicationInfo\\\"D\\n\\x10TrackUnpublished\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x17\\n\\x0fpublication_sid\\x18\\x02 \\x01(\\t\\\"S\\n\\x0fTrackSubscribed\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\'\\n\\x05track\\x18\\x02 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\"?\\n\\x11TrackUnsubscribed\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\\"T\\n\\x17TrackSubscriptionFailed\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\x12\\r\\n\\x05\\x65rror\\x18\\x03 \\x01(\\t\\\"8\\n\\nTrackMuted\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\\":\\n\\x0cTrackUnmuted\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\\"1\\n\\x15\\x41\\x63tiveSpeakersChanged\\x12\\x18\\n\\x10participant_sids\\x18\\x01 \\x03(\\t\\\"f\\n\\x18\\x43onnectionQualityChanged\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\x07quality\\x18\\x02 \\x01(\\x0e\\x32 .livekit.proto.ConnectionQuality\\\"\\x96\\x01\\n\\x0c\\x44\\x61taReceived\\x12\\'\\n\\x04\\x64\\x61ta\\x18\\x01 \\x01(\\x0b\\x32\\x19.livekit.proto.BufferInfo\\x12\\x1c\\n\\x0fparticipant_sid\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x12+\\n\\x04kind\\x18\\x03 \\x01(\\x0e\\x32\\x1d.livekit.proto.DataPacketKindB\\x12\\n\\x10_participant_sid\\\"G\\n\\x16\\x43onnectionStateChanged\\x12-\\n\\x05state\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.ConnectionState\\\"\\x0b\\n\\tConnected\\\"\\x0e\\n\\x0c\\x44isconnected\\\"\\x0e\\n\\x0cReconnecting\\\"\\r\\n\\x0bReconnected*N\\n\\x11\\x43onnectionQuality\\x12\\x10\\n\\x0cQUALITY_POOR\\x10\\x00\\x12\\x10\\n\\x0cQUALITY_GOOD\\x10\\x01\\x12\\x15\\n\\x11QUALITY_EXCELLENT\\x10\\x02*S\\n\\x0f\\x43onnectionState\\x12\\x15\\n\\x11\\x43ONN_DISCONNECTED\\x10\\x00\\x12\\x12\\n\\x0e\\x43ONN_CONNECTED\\x10\\x01\\x12\\x15\\n\\x11\\x43ONN_RECONNECTING\\x10\\x02*3\\n\\x0e\\x44\\x61taPacketKind\\x12\\x0e\\n\\nKIND_LOSSY\\x10\\x00\\x12\\x11\\n\\rKIND_RELIABLE\\x10\\x01\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'room_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n", "  _CONNECTIONQUALITY._serialized_start=4700\n\t  _CONNECTIONQUALITY._serialized_end=4778\n\t  _CONNECTIONSTATE._serialized_start=4780\n\t  _CONNECTIONSTATE._serialized_end=4863\n\t  _DATAPACKETKIND._serialized_start=4865\n\t  _DATAPACKETKIND._serialized_end=4916\n\t  _CONNECTREQUEST._serialized_start=94\n\t  _CONNECTREQUEST._serialized_end=183\n\t  _CONNECTRESPONSE._serialized_start=185\n\t  _CONNECTRESPONSE._serialized_end=220\n", "  _CONNECTCALLBACK._serialized_start=223\n\t  _CONNECTCALLBACK._serialized_end=600\n\t  _CONNECTCALLBACK_PARTICIPANTWITHTRACKS._serialized_start=455\n\t  _CONNECTCALLBACK_PARTICIPANTWITHTRACKS._serialized_end=590\n\t  _DISCONNECTREQUEST._serialized_start=602\n\t  _DISCONNECTREQUEST._serialized_end=642\n\t  _DISCONNECTRESPONSE._serialized_start=644\n\t  _DISCONNECTRESPONSE._serialized_end=682\n\t  _DISCONNECTCALLBACK._serialized_start=684\n\t  _DISCONNECTCALLBACK._serialized_end=722\n", "  _PUBLISHTRACKREQUEST._serialized_start=725\n\t  _PUBLISHTRACKREQUEST._serialized_end=855\n\t  _PUBLISHTRACKRESPONSE._serialized_start=857\n\t  _PUBLISHTRACKRESPONSE._serialized_end=897\n\t  _PUBLISHTRACKCALLBACK._serialized_start=900\n\t  _PUBLISHTRACKCALLBACK._serialized_end=1028\n\t  _UNPUBLISHTRACKREQUEST._serialized_start=1030\n\t  _UNPUBLISHTRACKREQUEST._serialized_end=1133\n\t  _UNPUBLISHTRACKRESPONSE._serialized_start=1135\n\t  _UNPUBLISHTRACKRESPONSE._serialized_end=1177\n", "  _UNPUBLISHTRACKCALLBACK._serialized_start=1179\n\t  _UNPUBLISHTRACKCALLBACK._serialized_end=1251\n\t  _PUBLISHDATAREQUEST._serialized_start=1254\n\t  _PUBLISHDATAREQUEST._serialized_end=1415\n\t  _PUBLISHDATARESPONSE._serialized_start=1417\n\t  _PUBLISHDATARESPONSE._serialized_end=1456\n\t  _PUBLISHDATACALLBACK._serialized_start=1458\n\t  _PUBLISHDATACALLBACK._serialized_end=1527\n\t  _SETSUBSCRIBEDREQUEST._serialized_start=1529\n\t  _SETSUBSCRIBEDREQUEST._serialized_end=1598\n", "  _SETSUBSCRIBEDRESPONSE._serialized_start=1600\n\t  _SETSUBSCRIBEDRESPONSE._serialized_end=1623\n\t  _VIDEOENCODING._serialized_start=1625\n\t  _VIDEOENCODING._serialized_end=1684\n\t  _AUDIOENCODING._serialized_start=1686\n\t  _AUDIOENCODING._serialized_end=1722\n\t  _TRACKPUBLISHOPTIONS._serialized_start=1725\n\t  _TRACKPUBLISHOPTIONS._serialized_end=1991\n\t  _ROOMOPTIONS._serialized_start=1993\n\t  _ROOMOPTIONS._serialized_end=2073\n", "  _BUFFERINFO._serialized_start=2075\n\t  _BUFFERINFO._serialized_end=2170\n\t  _ROOMEVENT._serialized_start=2173\n\t  _ROOMEVENT._serialized_end=3414\n\t  _ROOMINFO._serialized_start=3416\n\t  _ROOMINFO._serialized_end=3518\n\t  _PARTICIPANTCONNECTED._serialized_start=3520\n\t  _PARTICIPANTCONNECTED._serialized_end=3588\n\t  _PARTICIPANTDISCONNECTED._serialized_start=3590\n\t  _PARTICIPANTDISCONNECTED._serialized_end=3640\n", "  _LOCALTRACKPUBLISHED._serialized_start=3642\n\t  _LOCALTRACKPUBLISHED._serialized_end=3682\n\t  _LOCALTRACKUNPUBLISHED._serialized_start=3684\n\t  _LOCALTRACKUNPUBLISHED._serialized_end=3732\n\t  _TRACKPUBLISHED._serialized_start=3734\n\t  _TRACKPUBLISHED._serialized_end=3833\n\t  _TRACKUNPUBLISHED._serialized_start=3835\n\t  _TRACKUNPUBLISHED._serialized_end=3903\n\t  _TRACKSUBSCRIBED._serialized_start=3905\n\t  _TRACKSUBSCRIBED._serialized_end=3988\n", "  _TRACKUNSUBSCRIBED._serialized_start=3990\n\t  _TRACKUNSUBSCRIBED._serialized_end=4053\n\t  _TRACKSUBSCRIPTIONFAILED._serialized_start=4055\n\t  _TRACKSUBSCRIPTIONFAILED._serialized_end=4139\n\t  _TRACKMUTED._serialized_start=4141\n\t  _TRACKMUTED._serialized_end=4197\n\t  _TRACKUNMUTED._serialized_start=4199\n\t  _TRACKUNMUTED._serialized_end=4257\n\t  _ACTIVESPEAKERSCHANGED._serialized_start=4259\n\t  _ACTIVESPEAKERSCHANGED._serialized_end=4308\n", "  _CONNECTIONQUALITYCHANGED._serialized_start=4310\n\t  _CONNECTIONQUALITYCHANGED._serialized_end=4412\n\t  _DATARECEIVED._serialized_start=4415\n\t  _DATARECEIVED._serialized_end=4565\n\t  _CONNECTIONSTATECHANGED._serialized_start=4567\n\t  _CONNECTIONSTATECHANGED._serialized_end=4638\n\t  _CONNECTED._serialized_start=4640\n\t  _CONNECTED._serialized_end=4651\n\t  _DISCONNECTED._serialized_start=4653\n\t  _DISCONNECTED._serialized_end=4667\n", "  _RECONNECTING._serialized_start=4669\n\t  _RECONNECTING._serialized_end=4683\n\t  _RECONNECTED._serialized_start=4685\n\t  _RECONNECTED._serialized_end=4698\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/__init__.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n"]}
{"filename": "livekit/_proto/participant_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: participant.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "from . import handle_pb2 as handle__pb2\n\tDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11participant.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"\\x7f\\n\\x0fParticipantInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x10\\n\\x08identity\\x18\\x04 \\x01(\\t\\x12\\x10\\n\\x08metadata\\x18\\x05 \\x01(\\tB\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'participant_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n\t  _PARTICIPANTINFO._serialized_start=50\n\t  _PARTICIPANTINFO._serialized_end=177\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/video_frame_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: video_frame.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "from . import handle_pb2 as handle__pb2\n\tDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11video_frame.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"k\\n\\x17\\x41llocVideoBufferRequest\\x12\\x31\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32#.livekit.proto.VideoFrameBufferType\\x12\\r\\n\\x05width\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\\"O\\n\\x18\\x41llocVideoBufferResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"[\\n\\x15NewVideoStreamRequest\\x12\\x14\\n\\x0ctrack_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoStreamType\\\"H\\n\\x16NewVideoStreamResponse\\x12.\\n\\x06stream\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.VideoStreamInfo\\\"\\x93\\x01\\n\\x15NewVideoSourceRequest\\x12,\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoSourceType\\x12=\\n\\nresolution\\x18\\x02 \\x01(\\x0b\\x32$.livekit.proto.VideoSourceResolutionH\\x00\\x88\\x01\\x01\\x42\\r\\n\\x0b_resolution\\\"H\\n\\x16NewVideoSourceResponse\\x12.\\n\\x06source\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.VideoSourceInfo\\\"v\\n\\x18\\x43\\x61ptureVideoFrameRequest\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x05\\x66rame\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.VideoFrameInfo\\x12\\x15\\n\\rbuffer_handle\\x18\\x03 \\x01(\\x04\\\"\\x1b\\n\\x19\\x43\\x61ptureVideoFrameResponse\\\"o\\n\\rToI420Request\\x12\\x0e\\n\\x06\\x66lip_y\\x18\\x01 \\x01(\\x08\\x12-\\n\\x04\\x61rgb\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.ARGBBufferInfoH\\x00\\x12\\x17\\n\\rbuffer_handle\\x18\\x03 \\x01(\\x04H\\x00\\x42\\x06\\n\\x04\\x66rom\\\"E\\n\\x0eToI420Response\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"\\xb6\\x01\\n\\rToArgbRequest\\x12\\x15\\n\\rbuffer_handle\\x18\\x01 \\x01(\\x04\\x12\\x0f\\n\\x07\\x64st_ptr\\x18\\x02 \\x01(\\x04\\x12\\x32\\n\\ndst_format\\x18\\x03 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoFormatType\\x12\\x12\\n\\ndst_stride\\x18\\x04 \\x01(\\r\\x12\\x11\\n\\tdst_width\\x18\\x05 \\x01(\\r\\x12\\x12\\n\\ndst_height\\x18\\x06 \\x01(\\r\\x12\\x0e\\n\\x06\\x66lip_y\\x18\\x07 \\x01(\\x08\\\"\\x10\\n\\x0eToArgbResponse\\\"D\\n\\x0fVideoResolution\\x12\\r\\n\\x05width\\x18\\x01 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\r\\x12\\x12\\n\\nframe_rate\\x18\\x03 \\x01(\\x01\\\"|\\n\\x0e\\x41RGBBufferInfo\\x12\\x0b\\n\\x03ptr\\x18\\x01 \\x01(\\x04\\x12.\\n\\x06\\x66ormat\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoFormatType\\x12\\x0e\\n\\x06stride\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x05 \\x01(\\r\\\"V\\n\\x0eVideoFrameInfo\\x12\\x14\\n\\x0ctimestamp_us\\x18\\x01 \\x01(\\x03\\x12.\\n\\x08rotation\\x18\\x02 \\x01(\\x0e\\x32\\x1c.livekit.proto.VideoRotation\\\"\\xc6\\x02\\n\\x14VideoFrameBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x38\\n\\x0b\\x62uffer_type\\x18\\x02 \\x01(\\x0e\\x32#.livekit.proto.VideoFrameBufferType\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x01(\\r\\x12\\x31\\n\\x03yuv\\x18\\x05 \\x01(\\x0b\\x32\\\".livekit.proto.PlanarYuvBufferInfoH\\x00\\x12\\x36\\n\\x06\\x62i_yuv\\x18\\x06 \\x01(\\x0b\\x32$.livekit.proto.BiplanarYuvBufferInfoH\\x00\\x12\\x31\\n\\x06native\\x18\\x07 \\x01(\\x0b\\x32\\x1f.livekit.proto.NativeBufferInfoH\\x00\\x42\\x08\\n\\x06\\x62uffer\\\"\\xda\\x01\\n\\x13PlanarYuvBufferInfo\\x12\\x14\\n\\x0c\\x63hroma_width\\x18\\x01 \\x01(\\r\\x12\\x15\\n\\rchroma_height\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08stride_y\\x18\\x03 \\x01(\\r\\x12\\x10\\n\\x08stride_u\\x18\\x04 \\x01(\\r\\x12\\x10\\n\\x08stride_v\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08stride_a\\x18\\x06 \\x01(\\r\\x12\\x12\\n\\ndata_y_ptr\\x18\\x07 \\x01(\\x04\\x12\\x12\\n\\ndata_u_ptr\\x18\\x08 \\x01(\\x04\\x12\\x12\\n\\ndata_v_ptr\\x18\\t \\x01(\\x04\\x12\\x12\\n\\ndata_a_ptr\\x18\\n \\x01(\\x04\\\"\\x92\\x01\\n\\x15\\x42iplanarYuvBufferInfo\\x12\\x14\\n\\x0c\\x63hroma_width\\x18\\x01 \\x01(\\r\\x12\\x15\\n\\rchroma_height\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08stride_y\\x18\\x03 \\x01(\\r\\x12\\x11\\n\\tstride_uv\\x18\\x04 \\x01(\\r\\x12\\x12\\n\\ndata_y_ptr\\x18\\x05 \\x01(\\x04\\x12\\x13\\n\\x0b\\x64\\x61ta_uv_ptr\\x18\\x06 \\x01(\\x04\\\"\\x12\\n\\x10NativeBufferInfo\\\"n\\n\\x0fVideoStreamInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoStreamType\\\"q\\n\\x10VideoStreamEvent\\x12\\x15\\n\\rstream_handle\\x18\\x01 \\x01(\\x04\\x12;\\n\\x0e\\x66rame_received\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.VideoFrameReceivedH\\x00\\x42\\t\\n\\x07message\\\"w\\n\\x12VideoFrameReceived\\x12,\\n\\x05\\x66rame\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.VideoFrameInfo\\x12\\x33\\n\\x06\\x62uffer\\x18\\x02 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"6\\n\\x15VideoSourceResolution\\x12\\r\\n\\x05width\\x18\\x01 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\r\\\"n\\n\\x0fVideoSourceInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoSourceType*(\\n\\nVideoCodec\\x12\\x07\\n\\x03VP8\\x10\\x00\\x12\\x08\\n\\x04H264\\x10\\x01\\x12\\x07\\n\\x03\\x41V1\\x10\\x02*l\\n\\rVideoRotation\\x12\\x14\\n\\x10VIDEO_ROTATION_0\\x10\\x00\\x12\\x15\\n\\x11VIDEO_ROTATION_90\\x10\\x01\\x12\\x16\\n\\x12VIDEO_ROTATION_180\\x10\\x02\\x12\\x16\\n\\x12VIDEO_ROTATION_270\\x10\\x03*U\\n\\x0fVideoFormatType\\x12\\x0f\\n\\x0b\\x46ORMAT_ARGB\\x10\\x00\\x12\\x0f\\n\\x0b\\x46ORMAT_BGRA\\x10\\x01\\x12\\x0f\\n\\x0b\\x46ORMAT_ABGR\\x10\\x02\\x12\\x0f\\n\\x0b\\x46ORMAT_RGBA\\x10\\x03*j\\n\\x14VideoFrameBufferType\\x12\\n\\n\\x06NATIVE\\x10\\x00\\x12\\x08\\n\\x04I420\\x10\\x01\\x12\\t\\n\\x05I420A\\x10\\x02\\x12\\x08\\n\\x04I422\\x10\\x03\\x12\\x08\\n\\x04I444\\x10\\x04\\x12\\x08\\n\\x04I010\\x10\\x05\\x12\\x08\\n\\x04NV12\\x10\\x06\\x12\\t\\n\\x05WEBGL\\x10\\x07*Y\\n\\x0fVideoStreamType\\x12\\x17\\n\\x13VIDEO_STREAM_NATIVE\\x10\\x00\\x12\\x16\\n\\x12VIDEO_STREAM_WEBGL\\x10\\x01\\x12\\x15\\n\\x11VIDEO_STREAM_HTML\\x10\\x02**\\n\\x0fVideoSourceType\\x12\\x17\\n\\x13VIDEO_SOURCE_NATIVE\\x10\\x00\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'video_frame_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n\t  _VIDEOCODEC._serialized_start=2686\n\t  _VIDEOCODEC._serialized_end=2726\n\t  _VIDEOROTATION._serialized_start=2728\n", "  _VIDEOROTATION._serialized_end=2836\n\t  _VIDEOFORMATTYPE._serialized_start=2838\n\t  _VIDEOFORMATTYPE._serialized_end=2923\n\t  _VIDEOFRAMEBUFFERTYPE._serialized_start=2925\n\t  _VIDEOFRAMEBUFFERTYPE._serialized_end=3031\n\t  _VIDEOSTREAMTYPE._serialized_start=3033\n\t  _VIDEOSTREAMTYPE._serialized_end=3122\n\t  _VIDEOSOURCETYPE._serialized_start=3124\n\t  _VIDEOSOURCETYPE._serialized_end=3166\n\t  _ALLOCVIDEOBUFFERREQUEST._serialized_start=50\n", "  _ALLOCVIDEOBUFFERREQUEST._serialized_end=157\n\t  _ALLOCVIDEOBUFFERRESPONSE._serialized_start=159\n\t  _ALLOCVIDEOBUFFERRESPONSE._serialized_end=238\n\t  _NEWVIDEOSTREAMREQUEST._serialized_start=240\n\t  _NEWVIDEOSTREAMREQUEST._serialized_end=331\n\t  _NEWVIDEOSTREAMRESPONSE._serialized_start=333\n\t  _NEWVIDEOSTREAMRESPONSE._serialized_end=405\n\t  _NEWVIDEOSOURCEREQUEST._serialized_start=408\n\t  _NEWVIDEOSOURCEREQUEST._serialized_end=555\n\t  _NEWVIDEOSOURCERESPONSE._serialized_start=557\n", "  _NEWVIDEOSOURCERESPONSE._serialized_end=629\n\t  _CAPTUREVIDEOFRAMEREQUEST._serialized_start=631\n\t  _CAPTUREVIDEOFRAMEREQUEST._serialized_end=749\n\t  _CAPTUREVIDEOFRAMERESPONSE._serialized_start=751\n\t  _CAPTUREVIDEOFRAMERESPONSE._serialized_end=778\n\t  _TOI420REQUEST._serialized_start=780\n\t  _TOI420REQUEST._serialized_end=891\n\t  _TOI420RESPONSE._serialized_start=893\n\t  _TOI420RESPONSE._serialized_end=962\n\t  _TOARGBREQUEST._serialized_start=965\n", "  _TOARGBREQUEST._serialized_end=1147\n\t  _TOARGBRESPONSE._serialized_start=1149\n\t  _TOARGBRESPONSE._serialized_end=1165\n\t  _VIDEORESOLUTION._serialized_start=1167\n\t  _VIDEORESOLUTION._serialized_end=1235\n\t  _ARGBBUFFERINFO._serialized_start=1237\n\t  _ARGBBUFFERINFO._serialized_end=1361\n\t  _VIDEOFRAMEINFO._serialized_start=1363\n\t  _VIDEOFRAMEINFO._serialized_end=1449\n\t  _VIDEOFRAMEBUFFERINFO._serialized_start=1452\n", "  _VIDEOFRAMEBUFFERINFO._serialized_end=1778\n\t  _PLANARYUVBUFFERINFO._serialized_start=1781\n\t  _PLANARYUVBUFFERINFO._serialized_end=1999\n\t  _BIPLANARYUVBUFFERINFO._serialized_start=2002\n\t  _BIPLANARYUVBUFFERINFO._serialized_end=2148\n\t  _NATIVEBUFFERINFO._serialized_start=2150\n\t  _NATIVEBUFFERINFO._serialized_end=2168\n\t  _VIDEOSTREAMINFO._serialized_start=2170\n\t  _VIDEOSTREAMINFO._serialized_end=2280\n\t  _VIDEOSTREAMEVENT._serialized_start=2282\n", "  _VIDEOSTREAMEVENT._serialized_end=2395\n\t  _VIDEOFRAMERECEIVED._serialized_start=2397\n\t  _VIDEOFRAMERECEIVED._serialized_end=2516\n\t  _VIDEOSOURCERESOLUTION._serialized_start=2518\n\t  _VIDEOSOURCERESOLUTION._serialized_end=2572\n\t  _VIDEOSOURCEINFO._serialized_start=2574\n\t  _VIDEOSOURCEINFO._serialized_end=2684\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/handle_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: handle.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x0chandle.proto\\x12\\rlivekit.proto\\\"\\x1c\\n\\x0e\\x46\\x66iOwnedHandle\\x12\\n\\n\\x02id\\x18\\x01 \\x01(\\x04\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'handle_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n\t  _FFIOWNEDHANDLE._serialized_start=31\n\t  _FFIOWNEDHANDLE._serialized_end=59\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/audio_frame_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: audio_frame.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "from . import handle_pb2 as handle__pb2\n\tDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11\\x61udio_frame.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"a\\n\\x17\\x41llocAudioBufferRequest\\x12\\x13\\n\\x0bsample_rate\\x18\\x01 \\x01(\\r\\x12\\x14\\n\\x0cnum_channels\\x18\\x02 \\x01(\\r\\x12\\x1b\\n\\x13samples_per_channel\\x18\\x03 \\x01(\\r\\\"O\\n\\x18\\x41llocAudioBufferResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"[\\n\\x15NewAudioStreamRequest\\x12\\x14\\n\\x0ctrack_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioStreamType\\\"H\\n\\x16NewAudioStreamResponse\\x12.\\n\\x06stream\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.AudioStreamInfo\\\"\\x8a\\x01\\n\\x15NewAudioSourceRequest\\x12,\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioSourceType\\x12\\x37\\n\\x07options\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.AudioSourceOptionsH\\x00\\x88\\x01\\x01\\x42\\n\\n\\x08_options\\\"H\\n\\x16NewAudioSourceResponse\\x12.\\n\\x06source\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.AudioSourceInfo\\\"H\\n\\x18\\x43\\x61ptureAudioFrameRequest\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rbuffer_handle\\x18\\x02 \\x01(\\x04\\\"\\x1b\\n\\x19\\x43\\x61ptureAudioFrameResponse\\\"\\x1a\\n\\x18NewAudioResamplerRequest\\\"Q\\n\\x19NewAudioResamplerResponse\\x12\\x34\\n\\tresampler\\x18\\x01 \\x01(\\x0b\\x32!.livekit.proto.AudioResamplerInfo\\\"u\\n\\x17RemixAndResampleRequest\\x12\\x18\\n\\x10resampler_handle\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rbuffer_handle\\x18\\x02 \\x01(\\x04\\x12\\x14\\n\\x0cnum_channels\\x18\\x03 \\x01(\\r\\x12\\x13\\n\\x0bsample_rate\\x18\\x04 \\x01(\\r\\\"O\\n\\x18RemixAndResampleResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"\\x9f\\x01\\n\\x14\\x41udioFrameBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x10\\n\\x08\\x64\\x61ta_ptr\\x18\\x02 \\x01(\\x04\\x12\\x14\\n\\x0cnum_channels\\x18\\x03 \\x01(\\r\\x12\\x13\\n\\x0bsample_rate\\x18\\x04 \\x01(\\r\\x12\\x1b\\n\\x13samples_per_channel\\x18\\x05 \\x01(\\r\\\"n\\n\\x0f\\x41udioStreamInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioStreamType\\\"q\\n\\x10\\x41udioStreamEvent\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12;\\n\\x0e\\x66rame_received\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.AudioFrameReceivedH\\x00\\x42\\t\\n\\x07message\\\"H\\n\\x12\\x41udioFrameReceived\\x12\\x32\\n\\x05\\x66rame\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"e\\n\\x12\\x41udioSourceOptions\\x12\\x19\\n\\x11\\x65\\x63ho_cancellation\\x18\\x01 \\x01(\\x08\\x12\\x19\\n\\x11noise_suppression\\x18\\x02 \\x01(\\x08\\x12\\x19\\n\\x11\\x61uto_gain_control\\x18\\x03 \\x01(\\x08\\\"n\\n\\x0f\\x41udioSourceInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioSourceType\\\"C\\n\\x12\\x41udioResamplerInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle*A\\n\\x0f\\x41udioStreamType\\x12\\x17\\n\\x13\\x41UDIO_STREAM_NATIVE\\x10\\x00\\x12\\x15\\n\\x11\\x41UDIO_STREAM_HTML\\x10\\x01**\\n\\x0f\\x41udioSourceType\\x12\\x17\\n\\x13\\x41UDIO_SOURCE_NATIVE\\x10\\x00\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'audio_frame_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n\t  _AUDIOSTREAMTYPE._serialized_start=1773\n\t  _AUDIOSTREAMTYPE._serialized_end=1838\n\t  _AUDIOSOURCETYPE._serialized_start=1840\n", "  _AUDIOSOURCETYPE._serialized_end=1882\n\t  _ALLOCAUDIOBUFFERREQUEST._serialized_start=50\n\t  _ALLOCAUDIOBUFFERREQUEST._serialized_end=147\n\t  _ALLOCAUDIOBUFFERRESPONSE._serialized_start=149\n\t  _ALLOCAUDIOBUFFERRESPONSE._serialized_end=228\n\t  _NEWAUDIOSTREAMREQUEST._serialized_start=230\n\t  _NEWAUDIOSTREAMREQUEST._serialized_end=321\n\t  _NEWAUDIOSTREAMRESPONSE._serialized_start=323\n\t  _NEWAUDIOSTREAMRESPONSE._serialized_end=395\n\t  _NEWAUDIOSOURCEREQUEST._serialized_start=398\n", "  _NEWAUDIOSOURCEREQUEST._serialized_end=536\n\t  _NEWAUDIOSOURCERESPONSE._serialized_start=538\n\t  _NEWAUDIOSOURCERESPONSE._serialized_end=610\n\t  _CAPTUREAUDIOFRAMEREQUEST._serialized_start=612\n\t  _CAPTUREAUDIOFRAMEREQUEST._serialized_end=684\n\t  _CAPTUREAUDIOFRAMERESPONSE._serialized_start=686\n\t  _CAPTUREAUDIOFRAMERESPONSE._serialized_end=713\n\t  _NEWAUDIORESAMPLERREQUEST._serialized_start=715\n\t  _NEWAUDIORESAMPLERREQUEST._serialized_end=741\n\t  _NEWAUDIORESAMPLERRESPONSE._serialized_start=743\n", "  _NEWAUDIORESAMPLERRESPONSE._serialized_end=824\n\t  _REMIXANDRESAMPLEREQUEST._serialized_start=826\n\t  _REMIXANDRESAMPLEREQUEST._serialized_end=943\n\t  _REMIXANDRESAMPLERESPONSE._serialized_start=945\n\t  _REMIXANDRESAMPLERESPONSE._serialized_end=1024\n\t  _AUDIOFRAMEBUFFERINFO._serialized_start=1027\n\t  _AUDIOFRAMEBUFFERINFO._serialized_end=1186\n\t  _AUDIOSTREAMINFO._serialized_start=1188\n\t  _AUDIOSTREAMINFO._serialized_end=1298\n\t  _AUDIOSTREAMEVENT._serialized_start=1300\n", "  _AUDIOSTREAMEVENT._serialized_end=1413\n\t  _AUDIOFRAMERECEIVED._serialized_start=1415\n\t  _AUDIOFRAMERECEIVED._serialized_end=1487\n\t  _AUDIOSOURCEOPTIONS._serialized_start=1489\n\t  _AUDIOSOURCEOPTIONS._serialized_end=1590\n\t  _AUDIOSOURCEINFO._serialized_start=1592\n\t  _AUDIOSOURCEINFO._serialized_end=1702\n\t  _AUDIORESAMPLERINFO._serialized_start=1704\n\t  _AUDIORESAMPLERINFO._serialized_end=1771\n\t# @@protoc_insertion_point(module_scope)\n"]}
