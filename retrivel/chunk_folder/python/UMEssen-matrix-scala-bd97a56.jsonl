{"filename": "src/main.py", "chunked_list": ["from pprint import pp, pprint\n\timport swagger\n\timport argparse\n\tfrom codegen.generation import GenerationConfig, PackageConfig, generate_project\n\tfrom transform import transform_swaggers\n\tdef load_package_config(path: str) -> PackageConfig:\n\t    with open(path, \"r\") as file:\n\t        return PackageConfig.from_yaml(file.read())\n\tif __name__ == \"__main__\":\n\t    parser = argparse.ArgumentParser(\n", "        prog = \"matrix-scala-generator\",\n\t        description= \"Matrix Client-Server Spec => Scala Library\"\n\t    )\n\t    parser.add_argument(\"--spec-path\", required=True, help=\"path to the Client-Server Matrix specification\")\n\t    parser.add_argument(\"--build-config\", required=True, help=\"path to a build configuration\")\n\t    parser.add_argument(\"--output\", required=True, help=\"output path\")\n\t    parser.add_argument(\"--templates\", required=True, help=\"path to templates directory\")\n\t    #parser.add_argument(\"--apis\", required=False, nargs='+', help=\"manual list of api paths\")\n\t    args = parser.parse_args()\n\t    swagger_data = swagger.load_swaggers_from_path(args.spec_path)#, args.apis)\n", "    transform_data = transform_swaggers(swagger_data)\n\t    package_config = load_package_config(args.build_config)\n\t    gen_config = GenerationConfig(\n\t        package_config=package_config,\n\t        template_path=args.templates,\n\t        ouput_path=args.output,\n\t    )\n\t    generate_project(gen_config, transform_data)\n"]}
{"filename": "src/transform.py", "chunked_list": ["from codegen.data import ContainerModel, Module\n\tfrom swagger import SwaggerData, RefPathLookup\n\tfrom transformations.category import transform_to_category\n\tfrom transformations.data import MutableContext, TransformationResult\n\tfrom transformations.eventschemas import transform_event_schemas\n\tfrom transformations.module import transform_to_module\n\tfrom dataclasses import dataclass\n\tdef transform_swaggers(data: SwaggerData) -> TransformationResult:\n\t    definitions_container = ContainerModel(\n\t        parent=None,\n", "        model_name=\"Definitions\"\n\t    ).to_polymorphic()\n\t    ctx = MutableContext(\n\t        ref_lookup=data.ref_path_lookup,\n\t        definitions_container=definitions_container,\n\t        definition_cache={},\n\t        model_pool=[],\n\t    )\n\t    categories = [\n\t        transform_to_category(ctx, swagger_category)\n", "        for swagger_category in data.categories\n\t    ]\n\t    event_schemas = transform_event_schemas(ctx, data.event_schemas)\n\t    return TransformationResult(\n\t        definitions_container=definitions_container,\n\t        categories=categories,\n\t        event_schemas=event_schemas,\n\t    )\n"]}
{"filename": "src/swagger.py", "chunked_list": ["# NOTE:\n\t# this swagger parser does NOT try to be a full implementation\n\t# it ONLY implements features used by the matrix-spec, so a few shortcuts are made\n\t# it also mostly implements spec-features which are relevant to code execution\n\t# checkout out the swagger spec: https://swagger.io/specification/v2\n\tfrom __future__ import annotations\n\tfrom enum import Enum\n\tfrom strenum import StrEnum\n\timport os\n\tfrom typing import Any, Dict, List, Mapping, Optional, Set, Type, TypeVar, Union\n", "from glob import glob\n\tfrom dataclasses import dataclass, field\n\tfrom mashumaro.mixins.yaml import DataClassYAMLMixin, Decoder, EncodedData, default_decoder\n\tfrom mashumaro import DataClassDictMixin, field_options\n\timport pathlib\n\t@dataclass\n\tclass ParseContext:\n\t    refs: Set[str]\n\t    spec_base_path: Optional[str]\n\t    swagger_path: Optional[str] = None\n", "# TODO: this is plain and utter garbage\n\tdef resolve_path(base_path: str, path: str) -> str:\n\t    path_abs = os.path.abspath(path)\n\t    base_abs = os.path.abspath(base_path)\n\t    common_prefix = os.path.relpath(path_abs, base_abs)\n\t    resolved = os.path.join(base_path, common_prefix)\n\t    return str(resolved)\n\t# global and ugly, but I got tired of hacking around with mashumaro\n\tglobal_parse_context: ParseContext = ParseContext(\n\t    swagger_path=None,\n", "    spec_base_path=None,\n\t    refs=set()\n\t)\n\tdef get_parse_context() -> ParseContext:\n\t    global global_parse_context\n\t    return global_parse_context\n\t@dataclass\n\tclass Reference(DataClassDictMixin):\n\t    ref: str= field(metadata=field_options(alias=\"$ref\"))\n\t    @classmethod\n", "    def __post_deserialize__(cls: Type[Reference], obj: Reference) -> Reference:\n\t        ctx = get_parse_context()\n\t        assert ctx.swagger_path, \"failed to set swagger path\"\n\t        assert ctx.spec_base_path, \"failed to set spec base_path\"\n\t        swagger_base_path = os.path.dirname(ctx.swagger_path)\n\t        abs = resolve_path(ctx.spec_base_path,os.path.join(swagger_base_path, obj.ref))\n\t        obj.ref = abs\n\t        ctx.refs.add(abs)\n\t        return obj\n\tclass SwaggerDataType(Enum):\n", "    String = \"string\"\n\t    Number = \"number\"\n\t    Integer = \"integer\"\n\t    Boolean = \"boolean\"\n\t    Array = \"array\"\n\t    Object = \"object\"\n\t    File = \"file\"\n\t    Null = \"null\"\n\t@dataclass\n\tclass Schema(DataClassYAMLMixin):\n", "    # http://json-schema.org/\n\t    title: Optional[str] = None\n\t    description: Optional[str] = None\n\t    type: Optional[Union[list[SwaggerDataType],SwaggerDataType]] = None\n\t    format: Optional[FormatEnum] = None\n\t    items: Optional[Union[Union[Reference, Schema],List[Union[Reference, Schema]]]] = None\n\t    allOf: Optional[list[Union[Reference, Schema]]] = None  # never references\n\t    additionalProperties: Optional[Union[Union[Reference, Schema], bool]] = None\n\t    default: Optional[Any] = None\n\t    maximum: Optional[float] = None\n", "    exclusiveMaximum: Optional[bool] = None\n\t    minimum: Optional[float] = None\n\t    exclusiveMinimum: Optional[bool] = None\n\t    maxLength: Optional[int] = None\n\t    minLength: Optional[int] = None\n\t    pattern: Optional[str] = None\n\t    maxItems: Optional[int] = None\n\t    minItems: Optional[int] = None\n\t    uniqueItems: Optional[bool] = None\n\t    properties: Optional[dict[str, Union[Reference, Schema]]] = None\n", "    required: Optional[list[str]] = None\n\t    enum: Optional[list[Any]] = None\n\t    multipleOf: Optional[float] = None\n\t    defined_in_path: str = \"PLACEHOLDER\" # will be overriden in the post_deserialize hook\n\t    @classmethod\n\t    def __post_deserialize__(cls: Type[Schema], obj: Schema) -> Schema:\n\t        ctx = get_parse_context()\n\t        assert ctx.swagger_path, \"failed to set swagger path\"\n\t        obj.defined_in_path = ctx.swagger_path\n\t        return obj\n", "class FormatEnum(StrEnum):\n\t    Int32 = \"int32\"\n\t    Int64 = \"int64\"\n\t    Float = \"float\"\n\t    Double = \"double\"\n\t    Password = \"password\"\n\t    Uri = \"uri\"\n\t    Byte = \"byte\"\n\tExample = Dict[str, Any]  # mime-type to example, incomplete for now!\n\t@dataclass\n", "class Header(DataClassDictMixin):\n\t    type: SwaggerDataType  # \"string\", \"number\", \"integer\", \"boolean\", or \"array\"\n\t    description: Optional[str] = None\n\t    format: Optional[str] = None\n\t    collectionFormat: Optional[str] = None  # \"string\", \"number\", \"integer\", \"boolean\", or \"array\"\n\t    default: Optional[Any] = None\n\t    maximum: Optional[float] = None\n\t    exclusiveMaximum: Optional[bool] = None\n\t    minimum: Optional[float] = None\n\t    exclusiveMinimum: Optional[bool] = None\n", "    maxLength: Optional[int] = None\n\t    minLength: Optional[int] = None\n\t    pattern: Optional[str] = None\n\t    maxItems: Optional[int] = None\n\t    minItems: Optional[int] = None\n\t    uniqueItems: Optional[bool] = None\n\t    enum: Optional[list[Any]] = None\n\t    multipleOf: Optional[float] = None\n\tHeaders = Dict[str, Header]\n\t@dataclass\n", "class Response(DataClassDictMixin):\n\t    description: str\n\t    schema: Optional[Union[Reference, Schema]] = None\n\t    headers: Optional[Headers] = None\n\t# TODO: does matrix ever use the default field?\n\t# responses are never a reference in the matrix doc\n\t# Sometimes wildcards such as 3xx are used as the key\n\t# NOTE: mashumaro fails to properly parse this\n\tResponses = Dict[Union[str,int], Response]\n\t@dataclass\n", "class Operation(DataClassDictMixin):\n\t    responses: Responses\n\t    tags: Optional[list[str]] = None\n\t    summary: Optional[str] = None\n\t    description: Optional[str] = None\n\t    externalDocs: Optional[ExternalDocumentation] = None\n\t    operationId: Optional[str] = None\n\t    consumes: Optional[list[str]] = None  # overrides the global definition\n\t    produces: Optional[list[str]] = None  # overrides the global definition\n\t    parameters: Optional[list[Parameter]] = None\n", "    schemes: Optional[list[str]] = None  # overrides the global definition\n\t    deprecated: Optional[bool] = None\n\t    security: Optional[List[SecurityRequirement]] = None\n\t    #@classmethod\n\t    #def __post_deserialize__(cls: Type[Operation], obj: Operation) -> Operation:\n\t    #    print(obj.security)\n\t    #    return obj\n\t@dataclass\n\tclass PathItem(DataClassDictMixin):\n\t    get: Optional[Operation] = None\n", "    put: Optional[Operation] = None\n\t    post: Optional[Operation] = None\n\t    delete: Optional[Operation] = None\n\t    options: Optional[Operation] = None\n\t    head: Optional[Operation] = None\n\t    patch: Optional[Operation] = None\n\t# PathItems are never a reference in matrix spec\n\tPaths = dict[str, PathItem]\n\tclass ParameterLocation(Enum):\n\t    Body = \"body\"\n", "    Query = \"query\"\n\t    Header = \"header\"\n\t    Path = \"path\"\n\t    FormData = \"formData\"\n\t# TODO: this should really be at least two classes, one of which being BodyParameter\n\t@dataclass\n\tclass Parameter(DataClassDictMixin):\n\t    name: str\n\t    in_: ParameterLocation = field(metadata=field_options(alias=\"in\"))\n\t    description: Optional[str] = None\n", "    required: Optional[bool] = None  # if _in==path => **must be true**, else optional and default is false\n\t    schema: Optional[Schema] = None  # _should_ hold a value if _in==body\n\t    # if _in is NOT body\n\t    type: Optional[SwaggerDataType] = None  # technically _not_ Optional, but whatever\n\t    format: Optional[str] = None  # \"string\", \"number\", \"integer\", \"boolean\", \"array\" or \"file\"\n\t    allowEmptyValues: Optional[bool] = None\n\t    items: Optional[Schema] = None  # never a ref\n\tParametersDefinitions = Dict[str, Parameter]\n\t@dataclass\n\tclass SecurityScheme(DataClassDictMixin):\n", "    name: str\n\t    in_: str = field(metadata=field_options(alias=\"in\"))# \"query\" or \"header\"\n\t    type: str  # \"basic\", \"apiKey\" or \"oauth2\" create an enum when needed!\n\t    description: Optional[str] = None\n\tDefinitions = Dict[str, Schema]\n\tResponsesDefinitions = Dict[str, Response]\n\t#SecurityRequirement = Union[]\n\t@dataclass\n\tclass HomeserverAccessSecurity(DataClassDictMixin):\n\t    homeserverAccessToken: List # empty list\n", "@dataclass\n\tclass AccessTokenSecurity(DataClassDictMixin):\n\t    accessToken: List # empty list\n\tSecurityRequirement = Union[HomeserverAccessSecurity, AccessTokenSecurity] #Dict[str, list[str]]\n\tSecurityDefinitions = Dict[str, SecurityScheme]\n\t@dataclass\n\tclass ExternalDocumentation(DataClassDictMixin):\n\t    url: str\n\t    description: Optional[str] = None\n\t@dataclass\n", "class Contact(DataClassDictMixin):\n\t    name: Optional[str] = None\n\t    url: Optional[str] = None\n\t    email: Optional[str] = None\n\t@dataclass\n\tclass License(DataClassDictMixin):\n\t    name: str\n\t    url: Optional[str] = None\n\t@dataclass\n\tclass Info(DataClassDictMixin):\n", "    title: str\n\t    version: str\n\t    #description: Optional[str] = None\n\t    #termsOfService: Optional[str] = None\n\t    #contact: Optional[Contact] = None\n\t    #license: Optional[License] = None\n\t@dataclass\n\tclass Tag(DataClassDictMixin):\n\t    name: str\n\t    description: Optional[str] = None\n", "    externalDocs: Optional[ExternalDocumentation] = None\n\t@dataclass\n\tclass Swagger(DataClassYAMLMixin):\n\t    swagger: str  # TODO: always 2.0?\n\t    info: Info\n\t    paths: Paths\n\t    host: Optional[str] = None\n\t    basePath: Optional[str] = None\n\t    schemes: Optional[list[str]] = None  # limited to \"http\", \"https\", \"ws\", \"wss\"\n\t    consumes: Optional[list[str]] = None\n", "    produces: Optional[list[str]] = None\n\t    ## not used: definitions: Optional[Definitions] = None\n\t    parameters: Optional[ParametersDefinitions] = None\n\t    responses: Optional[ResponsesDefinitions] = None\n\t    #securityDefinitions: Optional[Reference] = None\n\t    security: Optional[list[SecurityRequirement]] = None\n\t    tag: Optional[list[Tag]] = None\n\t    externalDocs: Optional[ExternalDocumentation] = None\n\t    ## extensions ignored\n\t    defined_in_path: str = \"PLACEHOLDER\" # will be overriden in the post_deserialize hook\n", "    @classmethod\n\t    def __post_deserialize__(cls: Type[Swagger], obj: Swagger) -> Swagger:\n\t        ctx = get_parse_context()\n\t        assert ctx.swagger_path, \"failed to set swagger path\"\n\t        obj.defined_in_path = ctx.swagger_path\n\t        return obj\n\t# TODO: _almost all_ references point to a schema, except security-definitions that it :/\n\tRefPathLookup = Dict[str, Schema]\n\t@dataclass\n\tclass SwaggerEventSchema:\n", "    schema: Schema\n\t    path: str\n\t#wrapper to a list, for future additions\n\t@dataclass\n\tclass SwaggerEventSchemas:\n\t    schemas: List[SwaggerEventSchema]\n\t@dataclass\n\tclass SwaggerData:\n\t    ref_path_lookup: RefPathLookup\n\t    categories: List[ApiCategory]\n", "    event_schemas: SwaggerEventSchemas\n\tclass ApiCategoryEnum(StrEnum):\n\t    ClientServer = \"client-server\"\n\t    ApplicationService = \"application-service\"\n\t    PushGateway = \"push-gateway\"\n\t    Identity = \"identity\"\n\t    ServerServer = \"server-server\"\n\tdef match_dir_to_api(dir_path: str) -> ApiCategoryEnum:\n\t    dirname = os.path.dirname(dir_path)\n\t    return ApiCategoryEnum(dirname)\n", "#class SchemaCategoryEnum(StrEnum):\n\t#    EventSchemas = \"event-schemas\"\n\t#    OtherSchemas = \"schemas\"\n\t#\n\t#@dataclass\n\t#class SchemaCategory:\n\t#    type: SchemaCategoryEnum\n\t#    schemas: List[Schema]\n\t@dataclass\n\tclass ApiCategory:\n", "    type: ApiCategoryEnum\n\t    swaggers: List[Swagger]\n\tdef load_swagger(path: str) -> Swagger:\n\t    ctx = get_parse_context()\n\t    assert ctx.spec_base_path, \"what\"\n\t    ctx.swagger_path = resolve_path(ctx.spec_base_path, path)\n\t    with open(path) as so:\n\t        yaml_data = so.read()\n\t        swagger = Swagger.from_yaml(yaml_data)\n\t        return swagger\n", "def load_schema_reference(ctx: ParseContext, path: str) -> Schema:\n\t    assert ctx.spec_base_path\n\t    ctx.swagger_path = resolve_path(ctx.spec_base_path, path)\n\t    with open(path) as sf:\n\t        yaml_data = sf.read()\n\t        schema = Schema.from_yaml(yaml_data)\n\t        return schema\n\tdef load_api_path_swaggers(api_path: str) -> List[Swagger]:\n\t    swagger_paths = glob(os.path.join(api_path, \"*.yaml\"))\n\t    swaggers = [load_swagger(swagger_path) for swagger_path in swagger_paths]\n", "    return swaggers\n\t@dataclass\n\tclass CategoryPathTuple:\n\t    category: ApiCategoryEnum\n\t    path: str\n\tdef get_category_path_tuples(base_path: str) -> List[CategoryPathTuple]:\n\t    api_path = os.path.join(base_path, \"api\")\n\t    assert os.path.isdir(api_path), f\"no api folder found in given path {base_path}\"\n\t    # TODO go through all ... eventually\n\t    #categories =  [cat for cat in ApiCategoryEnum]\n", "    categories =  [ApiCategoryEnum.ClientServer, ApiCategoryEnum.ApplicationService, ApiCategoryEnum.PushGateway, ApiCategoryEnum.Identity]\n\t    category_path_tuples = [CategoryPathTuple(cat,os.path.join(api_path, str(cat))) for cat in categories]\n\t    for tuple in category_path_tuples:\n\t        assert os.path.isdir(tuple.path), f\"api category {tuple.category} of path {tuple.path} is not a folder\"\n\t    return category_path_tuples\n\tdef accumulate_ref_lookup(ctx: ParseContext) -> RefPathLookup:\n\t    ref_acc: Set[str] = set()\n\t    ref_path_lookup = {}\n\t    # accumulate new references while new ones are found\n\t    while True:\n", "        diff = ctx.refs - ref_acc\n\t        if len(diff) == 0:\n\t            break\n\t        ref_acc = ref_acc.union(diff)\n\t        ctx.refs = set() #reset\n\t        new_lookup = {path: load_schema_reference(ctx,path) for path in diff}\n\t        ref_path_lookup |= new_lookup\n\t    return ref_path_lookup\n\tdef init_ctx(spec_base_path: str) -> ParseContext:\n\t    ctx = get_parse_context()\n", "    ctx.swagger_path = None\n\t    ctx.refs = set()\n\t    ctx.spec_base_path = spec_base_path\n\t    return ctx\n\tdef load_event_schemas(ctx: ParseContext, base_path: str) -> SwaggerEventSchemas:\n\t    schema_folder_path = os.path.join(base_path, \"event-schemas\", \"schema\")\n\t    assert os.path.isdir(schema_folder_path), f\"path {schema_folder_path} \"\n\t    schema_paths = glob(os.path.join(schema_folder_path, \"*.yaml\"))\n\t    schemas = [SwaggerEventSchema(load_schema_reference(ctx, path), path) for path in schema_paths]\n\t    event_schemas = SwaggerEventSchemas(\n", "        schemas=schemas,\n\t    )\n\t    return event_schemas\n\tdef load_swaggers_from_path(base_path: str) -> SwaggerData:\n\t    category_path_tuples = get_category_path_tuples(base_path)\n\t    ctx = init_ctx(base_path)\n\t    api_categories = [\n\t        ApiCategory(\n\t            type=cat_tuple.category,\n\t            swaggers= load_api_path_swaggers(cat_tuple.path)\n", "        )\n\t        for cat_tuple in category_path_tuples\n\t    ]\n\t    event_schemas = load_event_schemas(ctx, base_path)\n\t    ref_path_lookup = accumulate_ref_lookup(ctx)\n\t    return SwaggerData(\n\t        ref_path_lookup=ref_path_lookup,\n\t        categories=api_categories,\n\t        event_schemas=event_schemas,\n\t    )\n"]}
{"filename": "src/codegen/generation.py", "chunked_list": ["from dataclasses import dataclass\n\timport os\n\tfrom typing import Any, Callable, Dict, Generic, Iterable, List, Optional, TypeVar\n\tfrom jinja2 import Environment, FileSystemLoader\n\tfrom mashumaro.mixins.yaml import DataClassYAMLMixin\n\tfrom codegen.data import GenerationApiCategory, Module\n\tfrom transformations.data import TransformationResult\n\tfrom transformations.util import flatten_2d\n\tT = TypeVar(\"T\")\n\t@dataclass\n", "class PackageConfig(DataClassYAMLMixin):\n\t    version: str\n\t    project_name: str\n\t    package_base: str\n\t    author: str\n\t    group_id: str\n\t    scala_version: str\n\t    akka_http_version: str\n\t    akka_version: str\n\t    spray_json_version: str\n", "    scalafmt_version: str\n\t@dataclass\n\tclass GenerationConfig:\n\t    package_config: PackageConfig\n\t    template_path: str\n\t    ouput_path: str\n\t@dataclass\n\tclass GenerationEnvironment:\n\t    package_config: PackageConfig\n\t    #generate_id = ...\n", "Location = List[str]\n\t@dataclass\n\tclass GenerationTarget(Generic[T]):\n\t    template_file: str\n\t    output_location: Location\n\t    file_name: Callable[[T],str]\n\t    iterable: Iterable[T]\n\t    additional: Optional[Dict[str, Any]] = None\n\tdef OneTimeGeneration(template_file: str, output_location: Location, file_name: str, data: Optional[T] = None, additional: Optional[Dict[str, Any]]= None) -> GenerationTarget[Optional[T]]:\n\t    return GenerationTarget[Optional[T]](\n", "        template_file=template_file,\n\t        output_location=output_location,\n\t        file_name=lambda _:file_name,\n\t        iterable=[data], # dummy entry\n\t        additional=additional,\n\t    )\n\t@dataclass\n\tclass DummyDataclass:\n\t    pass\n\tdef generate_targets(config: GenerationConfig, env: GenerationEnvironment,targets: List[GenerationTarget]):\n", "    os.makedirs(config.ouput_path, exist_ok=True)\n\t    j2_loader = FileSystemLoader(config.template_path)\n\t    j2_env = Environment(loader=j2_loader)\n\t    for target in targets:\n\t        base_path = os.path.join(config.ouput_path, *target.output_location)\n\t        os.makedirs(base_path, exist_ok=True)\n\t        for data in target.iterable:\n\t            merged=(data or DummyDataclass()).__dict__ | env.__dict__ | (target.additional or {}) #HACK\n\t            output_path = os.path.join(base_path, target.file_name(data))\n\t            print(f\"generating {output_path}\")\n", "            with open(output_path, \"w\") as of:\n\t                template = j2_env.get_template(target.template_file)\n\t                rendered = template.render(data=merged)\n\t                of.write(rendered)\n\tdef package_name_to_location(pkg: str) -> Location:\n\t    return pkg.split(\".\")\n\tdef build_category_targets(package_location: Location, category: GenerationApiCategory) -> List[GenerationTarget]:\n\t    additional = {\"category\": category}\n\t    return [\n\t        GenerationTarget[Module](\n", "            template_file=\"data_module.j2\",\n\t            output_location=[*package_location, \"model\", category.display_name],\n\t            file_name=lambda m: f\"{m.module_name}Data.scala\",\n\t            iterable=category.modules,\n\t            additional=additional,\n\t        ),\n\t        GenerationTarget[Module](\n\t            template_file=\"api_module.j2\",\n\t            output_location=[*package_location, \"api\", category.display_name],\n\t            file_name=lambda m: f\"{m.module_name}Api.scala\",\n", "            iterable=category.modules,\n\t            additional=additional,\n\t        ),\n\t        GenerationTarget[Module](\n\t            template_file=\"json_module.j2\",\n\t            output_location=[*package_location, \"json\",category.display_name],\n\t            file_name=lambda m: f\"{m.module_name}JsonFormats.scala\",\n\t            iterable=category.modules,\n\t            additional=additional,\n\t        ),\n", "    ]\n\tdef generate_project(config: GenerationConfig, data: TransformationResult):\n\t    env = GenerationEnvironment(\n\t            package_config=config.package_config\n\t    )\n\t    root = []# just so it is more readable\n\t    package_location = [*root,\"src\",\"main\", \"scala\", *package_name_to_location(config.package_config.package_base)]\n\t    targets: List[GenerationTarget] = [\n\t        OneTimeGeneration(\n\t            template_file=\"README.md.j2\",\n", "            output_location=[*root,],\n\t            file_name=\"README.md\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"build.sbt.j2\",\n\t            output_location=[*root,],\n\t            file_name=\"build.sbt\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"plugins.sbt.j2\",\n", "            output_location=[*root,\"project\"],\n\t            file_name=\"plugins.sbt\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"scalafmt.conf.j2\",\n\t            output_location=[*root,],\n\t            file_name=\".scalafmt.conf\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"ApiCore.scala.j2\",\n", "            output_location=[*package_location,\"core\"],\n\t            file_name=\"ApiCore.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"QueryBuilding.scala.j2\",\n\t            output_location=[*package_location,\"core\"],\n\t            file_name=\"QueryBuilding.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"HeaderBuilding.scala.j2\",\n", "            output_location=[*package_location,\"core\"],\n\t            file_name=\"HeaderBuilding.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"InvokerActor.scala.j2\",\n\t            output_location=[*package_location,\"core\"],\n\t            file_name=\"InvokerActor.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"KnownMatrixErrors.scala.j2\",\n", "            output_location=[*package_location,\"core\"],\n\t            file_name=\"KnownMatrixErrors.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"Authentication.scala.j2\",\n\t            output_location=[*package_location,\"core\"],\n\t            file_name=\"Authentication.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"CoreJsonFormats.scala.j2\",\n", "            output_location=[*package_location,\"json\",\"core\"],\n\t            file_name=\"CoreJsonFormats.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"KnownErrorFormats.scala.j2\",\n\t            output_location=[*package_location,\"json\",\"core\"],\n\t            file_name=\"KnownErrorFormats.scala\"\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"event_schemas_data.j2\",\n", "            output_location=[*package_location,\"model\"],\n\t            file_name=\"EventSchemas.scala\",\n\t            data=data.event_schemas.container,\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"Definitions.scala.j2\",\n\t            output_location=[*package_location,\"model\"],\n\t            file_name=\"Definitions.scala\",\n\t            data=data.definitions_container\n\t        ),\n", "        OneTimeGeneration(\n\t            template_file=\"json_definitions.j2\",\n\t            output_location=[*package_location,\"json\"],\n\t            file_name=\"DefinitionFormats.scala\",\n\t            data=data.definitions_container\n\t        ),\n\t        OneTimeGeneration(\n\t            template_file=\"json_eventschemas.j2\",\n\t            output_location=[*package_location,\"json\"],\n\t            file_name=\"EventSchemaFormats.scala\",\n", "            data=data.event_schemas.container,\n\t        ),\n\t        *flatten_2d([\n\t            build_category_targets(package_location, category)\n\t            for category in data.categories\n\t        ])\n\t    ]\n\t    generate_targets(config, env,targets)\n"]}
{"filename": "src/codegen/data.py", "chunked_list": ["from __future__ import annotations # for recursive type annotations\n\tfrom dataclasses import dataclass, field, is_dataclass\n\tfrom typing import List, Optional\n\tfrom enum import Enum\n\tfrom strenum import StrEnum\n\tfrom swagger import ApiCategoryEnum\n\tdef is_reserved(ident: str) -> bool:\n\t    # should it be escaped?\n\t    # https://www.scala-lang.org/files/archive/spec/2.11/01-lexical-syntax.html#identifiers\n\t    reserved_words = [\n", "        \"abstract\", \"case\", \"catch\", \"class\", \"def\",\n\t        \"do\", \"else\", \"extends\", \"false\", \"final\",\n\t        \"finally\", \"for\", \"forSome\", \"if\", \"implicit\",\n\t        \"import\", \"lazy\", \"macro\", \"match\", \"new\",\n\t        \"null\", \"object\", \"override\", \"package\", \"private\",\n\t        \"protected\", \"return\", \"sealed\", \"super\", \"this\",\n\t        \"throw\", \"trait\", \"try\", \"true\", \"type\",\n\t        \"val\", \"var\", \"while\", \"with\", \"yield\",\n\t        \"_\", \":\", \"=\", \"=>\", \"<-\", \"<:\", \"<%\", \">:\", \"#\", \"@\",\n\t        \"⇒\", \"←\"\n", "    ]\n\t    # this is _technically_ incorrect\n\t    # python's implementation obviously differs\n\t    # but eh, good enough init?\n\t    is_reserved = (ident in reserved_words) or not ident.isidentifier() \n\t    return is_reserved\n\t# TODO: perhaps this should be determined by the templating logic\n\tclass SecurityEnum(StrEnum):\n\t    NoAuth = \"NoAuthentication\"\n\t    AccessToken = \"AccessTokenAuthentication\"\n", "    HomeserverAccessToken = \"HomeserverAccessTokenAuthentication\"\n\tclass PrimitiveTypeEnum(StrEnum):\n\t    Int = \"Int\"\n\t    Double = \"Double\"\n\t    String = \"String\"\n\t    Boolean = \"Boolean\"\n\t    Unit = \"Unit\"\n\t    # formated types\n\t    Int32 = \"Int\"\n\t    Int64 = \"Long\"\n", "    Float = \"Float\"\n\t@dataclass\n\tclass BaseType:\n\t    def to_polymorphic(self) -> PolymorphicType:\n\t        return PolymorphicType.from_basic(self)\n\t@dataclass\n\tclass OptionType(BaseType):\n\t    inner_type: PolymorphicType\n\t@dataclass\n\tclass PrimitiveType(BaseType):\n", "    type: PrimitiveTypeEnum\n\t@dataclass\n\tclass ListyType(BaseType):\n\t    inner_type: PolymorphicType\n\t@dataclass\n\tclass GenericType(BaseType):\n\t    pass\n\t@dataclass\n\tclass GenericValueType(BaseType):\n\t    pass\n", "@dataclass\n\tclass ModelType(BaseType):\n\t    model: PolymorphicModel\n\t@dataclass\n\tclass UnitType(BaseType):\n\t    pass\n\t@dataclass\n\tclass MapType(BaseType):\n\t    inner_type: PolymorphicType\n\t@dataclass\n", "class UnionType(BaseType):\n\t    inner_types: List[PolymorphicType]\n\t@dataclass\n\tclass PolymorphicType:\n\t    data: BaseType\n\t    # used for polymorphism\n\t    is_primitive: bool = False\n\t    is_model: bool = False\n\t    is_listy: bool = False\n\t    is_union: bool = False\n", "    is_option: bool = False\n\t    is_generic: bool = False\n\t    is_generic_value: bool = False\n\t    is_unit: bool = False\n\t    is_map: bool = False\n\t    @staticmethod\n\t    def from_basic(data: BaseType) -> PolymorphicType:\n\t        if isinstance(data, PrimitiveType):\n\t            return PolymorphicType(data, is_primitive=True)\n\t        if isinstance(data, GenericType):\n", "            return PolymorphicType(data, is_generic=True)\n\t        if isinstance(data, ModelType):\n\t            return PolymorphicType(data, is_model=True)\n\t        if isinstance(data, UnitType):\n\t            return PolymorphicType(data, is_unit=True)\n\t        if isinstance(data, ListyType):\n\t            return PolymorphicType(data, is_listy=True)\n\t        if isinstance(data, MapType):\n\t            return PolymorphicType(data, is_map=True)\n\t        if isinstance(data, UnionType):\n", "            return PolymorphicType(data, is_union=True)\n\t        if isinstance(data, GenericValueType):\n\t            return PolymorphicType(data, is_generic_value=True)\n\t        if isinstance(data, OptionType):\n\t            return PolymorphicType(data, is_option=True)\n\t        assert False, \"could not determine polymorphic type\"\n\t@dataclass\n\tclass Argument:\n\t    description: Optional[str]\n\t    name: str\n", "    type: PolymorphicType\n\t    escape: bool\n\t    required: bool  #should the transformer, or the template make this into an Option??\n\t@dataclass\n\tclass StatusCodeRange:\n\t    start: int\n\t    end: int\n\t@dataclass\n\tclass ResponseType:\n\t    status_code_range: StatusCodeRange\n", "    type: PolymorphicType\n\t@dataclass\n\tclass Operation:\n\t    deprecated: bool\n\t    summary: Optional[str]\n\t    description: Optional[str]\n\t    operation_id: str\n\t    endpoint: str\n\t    http_method: str\n\t    response_type: PolymorphicType # the responses trait \n", "    response_types: List[ResponseType] # the individual responses\n\t    path_args: list[Argument]\n\t    query_args: list[Argument]\n\t    header_args: list[Argument]\n\t    has_body: bool\n\t    body_type: PolymorphicType\n\t    container_model: PolymorphicModel\n\t    security: SecurityEnum\n\t@dataclass\n\tclass BaseModel:\n", "    model_name: str\n\t    inner_models: Optional[list[PolymorphicModel]] = None\n\t    parent: Optional[PolymorphicModel] = None\n\t    description: Optional[str] = None\n\t    def to_polymorphic(self) -> PolymorphicModel:\n\t        return PolymorphicModel.from_basic(self)\n\t@dataclass\n\tclass PolymorphicModel:\n\t    data: BaseModel\n\t    is_container_model: bool = False\n", "    is_data_model: bool = False\n\t    is_string_enum: bool = False\n\t    is_responses_trait: bool = False\n\t    is_response_box: bool = False\n\t    @staticmethod\n\t    def from_basic(data: BaseModel) -> PolymorphicModel:\n\t        if isinstance(data, DataModel):\n\t            return PolymorphicModel(data, is_data_model=True)\n\t        if isinstance(data, ContainerModel):\n\t            return PolymorphicModel(data, is_container_model=True)\n", "        if isinstance(data, StringEnumModel):\n\t            return PolymorphicModel(data, is_string_enum=True)\n\t        if isinstance(data, ResponseBoxModel):\n\t            return PolymorphicModel(data, is_response_box=True)\n\t        if isinstance(data, ResponsesTraitModel):\n\t            return PolymorphicModel(data, is_responses_trait=True)\n\t        assert False, \"could not determine polymorphic type\"\n\t@dataclass\n\tclass ResponsesTraitModel(BaseModel):\n\t    pass\n", "@dataclass\n\tclass ResponseBoxModel(BaseModel):\n\t    #TODO: these are NOT Optional, dataclass inheritance is weird\n\t    boxes: Optional[PolymorphicType] = None \n\t    of_response_trait: Optional[PolymorphicModel] = None \n\t@dataclass\n\tclass DataModel(BaseModel):\n\t    of_response_trait: Optional[PolymorphicModel] = None \n\t    fields: list[Argument] = field(default_factory=list) #TODO: fix dataclass composition, and make this mandatory\n\t    additional_type: Optional[PolymorphicType] = None\n", "    #composites: Optional[List[PolymorphicModel]] = None\n\t    compositions: Optional[List[Composition]] = None\n\t    composites_children: Optional[List[PolymorphicModel]] = None\n\t    defined_in_path: Optional[str] = None\n\t    def count_fields(self) -> int:\n\t        return len(self.fields) + sum([len(comp.fields) for comp in self.compositions or [] ])\n\t@dataclass\n\tclass Composition:\n\t    origin: PolymorphicModel\n\t    fields: List[Argument]\n", "@dataclass\n\tclass ContainerModel(BaseModel):\n\t    pass\n\t# PLACEHOLDER\n\t@dataclass\n\tclass StringEnumModel(BaseModel):\n\t    values: List[str] = field(default_factory=list) #TODO: fix dataclass composition, and make this mandatory\n\t@dataclass\n\tclass Definition:\n\t    name: str\n", "    model: PolymorphicModel\n\t@dataclass\n\tclass Module:\n\t    module_name: str\n\t    operations: list[Operation]\n\t    defined_in_path: str\n\t@dataclass\n\tclass EventSchemas:\n\t    container: PolymorphicModel\n\t    #models: List[PolymorphicModel]\n", "@dataclass\n\tclass GenerationApiCategory:\n\t    category: ApiCategoryEnum\n\t    modules: List[Module]\n\t    display_name: str\n\t    @staticmethod\n\t    def display_name_from_type(type: ApiCategoryEnum) -> str:\n\t        display = str(type).lower().replace('-','')\n\t        return display\n"]}
{"filename": "src/transformations/model.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom pprint import pp, pprint\n\tfrom typing import Callable, Dict, List, Optional, Union, cast\n\tfrom itertools import accumulate\n\tfrom codegen.data import Argument, Composition, DataModel, GenericValueType, ModelType, OptionType, PolymorphicModel, PrimitiveType, PrimitiveTypeEnum, is_reserved\n\tfrom swagger import Reference, Schema\n\tfrom transformations.composition import detect_transitionary_composite, transform_composites, traverse_transitory_composite\n\tfrom transformations.data import MutableContext, PolymorphicType\n\tfrom transformations.util import PLACEHOLDER, attach_model, flatten_2d, to_model_name, wrap_in_option\n\tdef is_schema_model(schema: Schema) -> bool:\n", "    return (schema.properties is not None) or (schema.allOf is not None)\n\t@dataclass\n\tclass FieldTransformation:\n\t    arg: Argument\n\tdef transform_model_field(ctx: MutableContext, field_name: str, field_schema: Union[Schema, Reference], is_required: bool,  model: PolymorphicModel) -> FieldTransformation:\n\t    from transformations.types import transform_schema # avoid circular import\n\t    t = wrap_in_option(is_required, transform_schema(ctx, field_schema, to_model_name(field_name), model))\n\t    arg = Argument(\n\t        name=field_name,\n\t        type=t,\n", "        description=None,\n\t        required=PLACEHOLDER(True),\n\t        escape=is_reserved(field_name), \n\t    )\n\t    return FieldTransformation(\n\t        arg=arg,\n\t    )\n\tdef transform_model_fields(ctx: MutableContext, properties: Dict[str, Union[Schema, Reference]], required: List[str],model: PolymorphicModel) -> List[FieldTransformation]:\n\t    return [\n\t        transform_model_field(ctx, field_name, field_schema, field_name in required,model)\n", "        for (field_name, field_schema) in properties.items()\n\t    ]\n\tdef attempt_additional_type(ctx: MutableContext, schema: Schema, parent: PolymorphicModel) -> Optional[PolymorphicType]:\n\t    from transformations.types import transform_schema # avoid circular import\n\t    if schema.additionalProperties is None:\n\t        return None\n\t    if isinstance(schema.additionalProperties, bool):\n\t        if not schema.additionalProperties:\n\t            # why specify additionalProperties just to say: \"Nope, no fields for you\"\n\t            return None\n", "        return GenericValueType().to_polymorphic()\n\t    if isinstance(schema.additionalProperties, Union[Schema, Reference]):\n\t        return transform_schema(ctx, schema.additionalProperties, \"Additional\", parent)\n\t    raise Exception(\"reached unreachable\")\n\tdef transform_schema_as_model(ctx: MutableContext, schema: Schema, suggested_name: str, parent: Optional[PolymorphicModel]) -> PolymorphicType:\n\t    assert is_schema_model(schema)\n\t    properties = schema.properties or {}\n\t    model_name = to_model_name(schema.title) if schema.title is not None else to_model_name(suggested_name)\n\t    model = DataModel(\n\t        model_name=model_name,\n", "        description=schema.description,\n\t        defined_in_path=schema.defined_in_path,\n\t    )\n\t    pmodel = model.to_polymorphic()\n\t    field_transformations = transform_model_fields(ctx, properties, schema.required or [], pmodel)\n\t    model.fields = [\n\t        transformation.arg \n\t        for transformation in field_transformations\n\t    ]\n\t    additional_type = attempt_additional_type(ctx, schema, pmodel)\n", "    if additional_type is not None:\n\t        model.additional_type = additional_type\n\t    composites = transform_composites(ctx, [ t.arg.name for t in field_transformations],schema, pmodel)\n\t    if composites:\n\t        if detect_transitionary_composite(schema, composites):\n\t            return traverse_transitory_composite(composites[0])\n\t        model.compositions = composites\n\t    model_type = ModelType(\n\t        model=pmodel\n\t    ).to_polymorphic()\n", "    if parent:\n\t        attach_model(pmodel, parent)\n\t    return model_type\n"]}
{"filename": "src/transformations/security.py", "chunked_list": ["import swagger\n\tfrom codegen.data import SecurityEnum\n\tdef transform_security_type(operation: swagger.Operation) -> SecurityEnum: \n\t    securities = operation.security\n\t    if securities is None:\n\t        return SecurityEnum.NoAuth\n\t    assert len(securities) == 1, f\"more or less than one security given in {securities}\"\n\t    security = securities[0]\n\t    if isinstance(security, swagger.HomeserverAccessSecurity):\n\t        return SecurityEnum.HomeserverAccessToken\n", "    if isinstance(security, swagger.AccessTokenSecurity):\n\t        return SecurityEnum.AccessToken\n\t    assert False, f\"unknown security scheme {security}\"\n"]}
{"filename": "src/transformations/category.py", "chunked_list": ["from codegen.data import GenerationApiCategory\n\tfrom swagger import ApiCategory\n\tfrom transformations.data import MutableContext\n\tfrom transformations.module import transform_to_module\n\tdef transform_to_category(ctx: MutableContext,swagger_category: ApiCategory) -> GenerationApiCategory:\n\t    modules = [\n\t        transform_to_module(ctx, swagger)\n\t        for swagger in swagger_category.swaggers\n\t    ]\n\t    category = GenerationApiCategory(\n", "        category=swagger_category.type,\n\t        modules=modules,\n\t        display_name=GenerationApiCategory.display_name_from_type(swagger_category.type),\n\t    )\n\t    return category\n"]}
{"filename": "src/transformations/generic.py", "chunked_list": ["from codegen.data import GenericType, PolymorphicType\n\tfrom swagger import Schema, SwaggerDataType\n\tfrom transformations.data import MutableContext\n\tdef is_schema_generic(schema: Schema) -> bool:\n\t    no_additional_properties = schema.properties is None or schema.properties == False\n\t    return (schema.type == SwaggerDataType.Object or schema.type is None) and (schema.properties is None) and no_additional_properties and schema.allOf is None\n\tdef transform_schema_as_generic(ctx: MutableContext, schema: Schema) -> PolymorphicType:\n\t    assert is_schema_generic(schema)\n\t    return GenericType().to_polymorphic()\n"]}
{"filename": "src/transformations/types.py", "chunked_list": ["from typing import Optional, Union, cast\n\tfrom transformations.array import is_schema_array, transform_schema_as_array\n\tfrom transformations.definition import transform_schema_as_definition\n\tfrom transformations.enum import is_schema_enum, transform_schema_as_enum\n\tfrom transformations.file import is_schema_file, transform_schema_as_file\n\tfrom transformations.generic import is_schema_generic, transform_schema_as_generic\n\tfrom transformations.map import is_schema_map, transform_schema_as_map\n\tfrom transformations.model import is_schema_model, transform_schema_as_model\n\tfrom transformations.primitive import is_schema_primitive, transform_schema_as_primitive\n\tfrom transformations.union import is_schema_union, transform_schema_as_union\n", "from transformations.util import to_model_name\n\tfrom codegen.data import PolymorphicModel, PolymorphicType\n\tfrom swagger import Reference, Schema\n\tfrom transformations.data import MutableContext\n\tdef is_schema_reference(schema: Union[Schema,Reference]) -> bool:\n\t    return isinstance(schema, Reference)\n\t# suggested_name is used when there is no provided name\n\tdef transform_schema(ctx: MutableContext, schema: Union[Schema,Reference], suggested_name: str, parent: Optional[PolymorphicModel]) -> PolymorphicType:\n\t    # TODO: make this more functional\n\t    # I would like each transformer to return a Optional\n", "    # there should be a list of transformers\n\t    # this function should try each transformer and return the first match\n\t    if is_schema_reference(schema): \n\t        return transform_schema_as_definition(ctx, cast(Reference,schema)  )\n\t    schema = cast(Schema, schema)\n\t    if is_schema_union(schema):\n\t        return transform_schema_as_union(ctx, schema, suggested_name, parent)\n\t    if is_schema_enum(schema):\n\t        return transform_schema_as_enum(ctx, schema, suggested_name, parent)\n\t    if is_schema_file(schema):\n", "        return transform_schema_as_file(ctx, schema)\n\t    if is_schema_primitive(schema):\n\t        return transform_schema_as_primitive(ctx, schema)\n\t    if is_schema_map(schema):\n\t        return transform_schema_as_map(ctx, schema, suggested_name, parent)\n\t    if is_schema_model(schema):\n\t        return transform_schema_as_model(ctx, schema, suggested_name, parent)\n\t    if is_schema_array(schema):\n\t        return transform_schema_as_array(ctx, schema, suggested_name, parent)\n\t    if is_schema_generic(schema):\n", "        return transform_schema_as_generic(ctx, schema)\n\t    raise Exception(\"failed to transform schema\")\n"]}
{"filename": "src/transformations/primitive.py", "chunked_list": ["from typing import Dict, Optional\n\tfrom codegen.data import PolymorphicType, PrimitiveType, PrimitiveTypeEnum\n\tfrom swagger import FormatEnum, Schema, SwaggerDataType\n\tfrom transformations.data import MutableContext\n\t# TODO: either move this to the union transformer or make something better\n\tprimitive_mapping: Dict[SwaggerDataType, PolymorphicType] = {\n\t    SwaggerDataType.String: PrimitiveType(type=PrimitiveTypeEnum.String).to_polymorphic(),\n\t    SwaggerDataType.Integer: PrimitiveType(type=PrimitiveTypeEnum.Int).to_polymorphic(),\n\t    SwaggerDataType.Boolean: PrimitiveType(type=PrimitiveTypeEnum.Boolean).to_polymorphic(),\n\t    SwaggerDataType.Number: PrimitiveType(type=PrimitiveTypeEnum.Double).to_polymorphic(),\n", "}\n\tformat_mapping = {\n\t    FormatEnum.Int64 : PrimitiveType(PrimitiveTypeEnum.Int64).to_polymorphic(),\n\t    FormatEnum.Int32 : PrimitiveType(PrimitiveTypeEnum.Int32).to_polymorphic(),\n\t    FormatEnum.Float : PrimitiveType(PrimitiveTypeEnum.Float).to_polymorphic(),\n\t}\n\tdef is_schema_primitive(schema: Schema) -> bool:\n\t    return schema.type in primitive_mapping\n\tdef transform_schema_as_primitive(ctx: MutableContext, schema: Schema) -> PolymorphicType:\n\t    assert is_schema_primitive(schema)\n", "    assert isinstance(schema.type, SwaggerDataType)\n\t    if schema.format is not None and (format_type := format_mapping.get(schema.format)) is not None:\n\t        return format_type\n\t    type = primitive_mapping[schema.type]\n\t    return type \n"]}
{"filename": "src/transformations/array.py", "chunked_list": ["from typing import List, Optional\n\tfrom codegen.data import ListyType, PolymorphicModel, PolymorphicType, UnionType\n\tfrom swagger import Schema\n\tfrom transformations.data import MutableContext\n\tdef is_schema_array(schema: Schema) -> bool:\n\t    return schema.items is not None \n\tdef transform_item_types(ctx: MutableContext, schema: Schema, suggested_name: str, parent: Optional[PolymorphicModel]) -> List[PolymorphicType]:\n\t    from transformations.types import transform_schema # avoid circular import\n\t    assert schema.items\n\t    if isinstance(schema.items, List):\n", "        return [transform_schema(ctx, item_schema, suggested_name, parent) for item_schema in schema.items]\n\t    else:\n\t        # singular type\n\t        return [transform_schema(ctx, schema.items, suggested_name, parent)]\n\tdef transform_schema_as_array(ctx: MutableContext, schema: Schema, suggested_name: str, parent: Optional[PolymorphicModel]) -> PolymorphicType:\n\t    assert is_schema_array(schema)\n\t    assert schema.items\n\t    item_types = transform_item_types(ctx, schema, suggested_name, parent)\n\t    assert len(item_types) > 0\n\t    inner_type = UnionType(item_types).to_polymorphic() if len(item_types) > 1 else item_types[0]\n", "    array_type = ListyType(\n\t        inner_type=inner_type,\n\t    )\n\t    return array_type.to_polymorphic()\n"]}
{"filename": "src/transformations/composition.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom itertools import accumulate\n\tfrom typing import Callable, List, Optional, cast\n\tfrom codegen.data import Composition, DataModel, ModelType, PolymorphicModel, PolymorphicType\n\tfrom swagger import Reference, Schema\n\tfrom transformations.data import MutableContext\n\tfrom transformations.generic import is_schema_generic\n\tdef detect_transitionary_composite(schema: Schema, compositions: List[Composition]) -> bool:\n\t    if schema.allOf is None:\n\t        return False\n", "    return len(compositions) == 1 and schema.additionalProperties is None and schema.properties is None\n\tdef traverse_transitory_composite(composition: Composition) -> PolymorphicType:\n\t    return ModelType(composition.origin).to_polymorphic()\n\t@dataclass\n\tclass RemoveDuplicationIteration:\n\t    visited: List[str]\n\t    deduplicated_composition: Optional[Composition]# None for first iteration\n\tdef remove_composition_duplicates_iter(visited: List[str], composition: Composition) -> RemoveDuplicationIteration:\n\t    new_fields =  [field for field in composition.fields if field.name not in visited]\n\t    now_visited = [field.name for field in new_fields]\n", "    deduplicated_composition = Composition(\n\t        origin=composition.origin,\n\t        fields=new_fields,\n\t    )\n\t    return RemoveDuplicationIteration(\n\t        visited=visited+now_visited,\n\t        deduplicated_composition=deduplicated_composition,\n\t    )\n\t# TODO: detect type changes, e.g.: when Composition1.a is a string and Composition2.a is a integer\n\t# when a field is declared multiple times, then remove any duplicates\n", "def remove_composition_duplicates(initial_keys: List[str], compositions: List[Composition]) -> List[Composition]:\n\t    initial = RemoveDuplicationIteration(\n\t        visited=initial_keys,\n\t        deduplicated_composition=None, #DUMMY\n\t    )\n\t    accumulate_merger: Callable[[RemoveDuplicationIteration, Composition], RemoveDuplicationIteration] = lambda acc, comp: remove_composition_duplicates_iter(acc.visited, comp)\n\t    iterations: List[RemoveDuplicationIteration] = list(\n\t        accumulate(compositions, accumulate_merger, initial=initial)\n\t    )[1:] # ignore initial value\n\t    return [\n", "        cast(Composition, i.deduplicated_composition)\n\t        for i in iterations\n\t    ]\n\t@dataclass\n\tclass CompositionTuple:\n\t    pmodel: PolymorphicModel # avoid to remake it a polymorphic\n\t    data_model: DataModel\n\tdef transform_composition_tuple(ctx: MutableContext, tuple: CompositionTuple) -> Composition:\n\t    composition = Composition(\n\t        origin=tuple.pmodel,\n", "        fields=tuple.data_model.fields,\n\t    )\n\t    return composition\n\tdef transform_composites(ctx: MutableContext, field_keys: List[str], schema: Schema, parent: PolymorphicModel) -> Optional[List[Composition]]:\n\t    if schema.allOf is None:\n\t        return None\n\t    from transformations.types import transform_schema # avoid circular import\n\t    transformations =  [\n\t        transform_schema(ctx, composite_schema, \"Composite\", parent)\n\t        for composite_schema in schema.allOf\n", "        if isinstance(composite_schema, Reference) or (isinstance(composite_schema, Schema) and not is_schema_generic(composite_schema))\n\t        #HACK: discard generic models, since the spec sometimes includes an example as an entry\n\t    ]\n\t    data_model_checks = [\n\t        (\n\t            t.is_model\n\t            and isinstance(t.data, ModelType)\n\t            and isinstance(t.data.model, PolymorphicModel)\n\t            and isinstance(t.data.model.data, DataModel)\n\t        )\n", "        for t in transformations\n\t        if not t.is_map #HACK ignore composition for additionalProperties for now\n\t    ] \n\t    if any([t.is_map for t in transformations]):\n\t        print(f\"TODO: composition of additionalProperties is not supported for now, origin: {schema.defined_in_path}\")\n\t    assert all(data_model_checks),\" non data-model as composite\"\n\t    tuples = [\n\t        CompositionTuple(\n\t            pmodel = (cast(PolymorphicModel,cast(ModelType, t.data).model)),\n\t            data_model= cast(DataModel,(cast(PolymorphicModel,cast(ModelType, t.data).model)).data)\n", "        )\n\t        for t in transformations\n\t        if not t.is_map #TODO remove this\n\t    ]\n\t    initial_compositions = [\n\t        transform_composition_tuple(ctx, tuple)\n\t        for tuple in tuples\n\t    ]\n\t    deduplicated_compositions = remove_composition_duplicates(field_keys, initial_compositions)\n\t    return deduplicated_compositions\n"]}
{"filename": "src/transformations/module.py", "chunked_list": ["import os\n\tfrom swagger import Swagger\n\tfrom transformations.data import MutableContext\n\tfrom transformations.operation import transform_to_operations\n\tfrom transformations.util import to_model_name\n\tfrom codegen.data import Module\n\t# a hacky extraction form swagger.info.title\n\t# a possible alternative could be an extraction from a path's tag\n\t#SWAGGER_MODULE_PREFIX = \"Matrix Client-Server \"\n\tdef get_module_name(swagger: Swagger) -> str:\n", "    #assert swagger.info\n\t    #assert swagger.info.title\n\t    #info_title = swagger.info.title\n\t    #assert swagger.defined_in_path != \"PLACEHOLDER\", \"fail\"\n\t    #assert info_title.startswith(SWAGGER_MODULE_PREFIX)\n\t    base_name = os.path.basename(swagger.defined_in_path)\n\t    file_name, _ = os.path.splitext(base_name)\n\t    name = to_model_name(file_name)\n\t    return name \n\tdef transform_to_module(ctx: MutableContext, swagger: Swagger) -> Module:\n", "    module_name = get_module_name(swagger)\n\t    module = Module(\n\t            module_name=module_name,\n\t            operations=transform_to_operations(ctx, swagger),\n\t            defined_in_path=swagger.defined_in_path,\n\t        )\n\t    return module\n"]}
{"filename": "src/transformations/definition.py", "chunked_list": ["import os\n\tfrom codegen.data import PolymorphicType\n\tfrom swagger import Reference, Schema\n\tfrom transformations.data import MutableContext\n\tfrom transformations.util import to_model_name\n\tdef get_suggested_name_from_ref(ref: Reference) -> str:\n\t    base_name = os.path.basename(ref.ref)\n\t    file_name, _ = os.path.splitext(base_name)\n\t    suggested_name = to_model_name(file_name)\n\t    return suggested_name\n", "def transform_schema_as_definition(ctx: MutableContext, ref: Reference) -> PolymorphicType:\n\t    from transformations.types import transform_schema # avoid circular import\n\t    # HACK: we should cache by path, not some arbitrary generated value\n\t    cache_attempt = ctx.definition_cache.get(ref.ref)\n\t    if cache_attempt:\n\t        return cache_attempt\n\t    schema = ctx.ref_lookup.get(ref.ref)\n\t    assert schema, \"invalid ref lookup\"\n\t    suggested_name = get_suggested_name_from_ref(ref)\n\t    #print(\"cache miss for: \",suggested_name, \"=>\", ref.ref)\n", "    ptype = transform_schema(ctx, schema, suggested_name, ctx.definitions_container) \n\t    # add to cache\n\t    ctx.definition_cache[ref.ref] = ptype\n\t    return ptype\n"]}
{"filename": "src/transformations/data.py", "chunked_list": ["from typing import List\n\tfrom codegen.data import EventSchemas, GenerationApiCategory, PolymorphicModel, Module, PolymorphicType\n\tfrom swagger import RefPathLookup\n\tfrom dataclasses import dataclass\n\t@dataclass\n\tclass TransformationResult:\n\t    definitions_container: PolymorphicModel\n\t    categories: List[GenerationApiCategory]\n\t    event_schemas: EventSchemas\n\t#@dataclass\n", "#class TypeTuple:\n\t#    determined_type: PolymorphicType\n\t#    transformed_models: List[PolymorphicModel]\n\t@dataclass\n\tclass MutableContext:\n\t    ref_lookup: RefPathLookup\n\t    # create a global pool for all models\n\t    # useful for optimizations\n\t    model_pool: list[PolymorphicModel]\n\t    definitions_container: PolymorphicModel\n", "    definition_cache: dict[str, PolymorphicType]\n\t    def add_to_pool(self, model: PolymorphicModel) -> PolymorphicModel:\n\t        self.model_pool.append(model)\n\t        return model\n"]}
{"filename": "src/transformations/util.py", "chunked_list": ["from typing import TypeVar\n\timport re\n\tfrom codegen.data import OptionType, PolymorphicModel, PolymorphicType\n\tT = TypeVar(\"T\")\n\tdef PLACEHOLDER(x: T) -> T:\n\t    return x\n\tdef flatten_2d(outer: list[list[T]]) -> list[T]:\n\t    return [item for sublist in outer for item in sublist]\n\t# \"Some cool name\" => \"SomeCoolName\"\n\tdef to_model_name(s: str) -> str:\n", "    word_regex =  r'[a-zA-Z][a-zA-Z0-9]*'\n\t    def capitalize_first_char(s: str) -> str:\n\t        return s[0].capitalize() + s[1:]\n\t    return \"\".join(map(capitalize_first_char, re.findall(word_regex, s)))\n\t# avoid child/parent inconsistent state\n\t# TODO: make this less imperative\n\tdef attach_model(model: PolymorphicModel, parent: PolymorphicModel):\n\t    model.data.parent = parent\n\t    if parent.data.inner_models is None:\n\t        parent.data.inner_models = [model]\n", "    else:\n\t        parent.data.inner_models.append(model)\n\tdef wrap_in_option(is_required: bool, t: PolymorphicType) -> PolymorphicType:\n\t    # wrap in option if not required\n\t    wrapped = OptionType(t).to_polymorphic() if not is_required else t\n\t    return wrapped\n"]}
{"filename": "src/transformations/map.py", "chunked_list": ["from typing import Optional, Union\n\tfrom codegen.data import MapType, PolymorphicModel, PolymorphicType\n\tfrom swagger import  Reference, Schema\n\tfrom transformations.data import MutableContext\n\tdef is_schema_map(schema: Schema) -> bool:\n\t    return isinstance(schema.additionalProperties, Union[Schema, Reference]) and schema.properties is None and schema.allOf is None\n\tdef transform_schema_as_map(ctx: MutableContext, schema: Schema, suggested_name: str, parent: Optional[PolymorphicModel]) -> PolymorphicType:\n\t    assert is_schema_map(schema)\n\t    assert isinstance(schema.additionalProperties, Union[Schema,Reference])\n\t    from transformations.types import transform_schema # avoid circular import\n", "    value_type = transform_schema(ctx, schema.additionalProperties, suggested_name, parent)\n\t    map_type = MapType(\n\t        inner_type=value_type,\n\t    ).to_polymorphic()\n\t    return map_type\n"]}
{"filename": "src/transformations/enum.py", "chunked_list": ["from os import name\n\tfrom typing import Optional\n\tfrom codegen.data import GenericType, MapType, ModelType, PolymorphicModel, PolymorphicType, StringEnumModel\n\tfrom swagger import Schema, SwaggerDataType\n\tfrom transformations.data import MutableContext\n\tfrom transformations.util import attach_model, to_model_name\n\tdef is_schema_enum(schema: Schema) -> bool:\n\t    return schema.enum is not None\n\tdef transform_schema_as_enum(ctx: MutableContext, schema: Schema, suggested_name: str, parent: Optional[PolymorphicModel]) -> PolymorphicType:\n\t    assert is_schema_enum(schema)\n", "    assert schema.enum is not None\n\t    if(schema.type != SwaggerDataType.String):\n\t        assert False, \"only stringy enums are supported for now\"\n\t    values = schema.enum\n\t    enum_name = to_model_name(schema.title) if schema.title else to_model_name(suggested_name+\"Enum\")\n\t    enum_model = StringEnumModel(\n\t        model_name=enum_name,\n\t        values = values,\n\t    ).to_polymorphic()\n\t    if parent:\n", "        attach_model(enum_model, parent)\n\t    model_type = ModelType(\n\t        model= enum_model,\n\t    ).to_polymorphic()\n\t    return model_type\n"]}
{"filename": "src/transformations/file.py", "chunked_list": ["from typing import Optional\n\tfrom codegen.data import GenericType, PolymorphicType, PrimitiveType, PrimitiveTypeEnum\n\tfrom swagger import FormatEnum, Schema, SwaggerDataType\n\tfrom transformations.data import MutableContext\n\tdef is_schema_file(schema: Schema) -> bool:\n\t    return schema.type == SwaggerDataType.File or schema.format == FormatEnum.Byte\n\tdef transform_schema_as_file(ctx: MutableContext, schema: Schema) -> PolymorphicType:\n\t    assert is_schema_file(schema)\n\t    print(f\"TODO: file arguments are not supported for now! Fallback to generic model. Origin: {schema.defined_in_path}\")\n\t    type = GenericType().to_polymorphic()\n", "    return type\n"]}
{"filename": "src/transformations/operation.py", "chunked_list": ["from logging import PlaceHolder\n\timport swagger as swagger\n\tfrom codegen.data import ContainerModel, DataModel, GenericType, Operation, Argument, PolymorphicModel, PolymorphicType, PrimitiveType, ModelType, ResponseBoxModel, ResponseType, ResponsesTraitModel, StatusCodeRange, UnitType, is_reserved\n\tfrom transformations.data import MutableContext\n\tfrom transformations.security import transform_security_type\n\tfrom transformations.util import attach_model, flatten_2d, PLACEHOLDER, wrap_in_option\n\tfrom transformations.types import transform_schema\n\tfrom transformations.util import to_model_name\n\tfrom transformations.primitive import primitive_mapping\n\tfrom typing import Container, cast\n", "from typing import Dict, List, Optional, TypeVar\n\tfrom pprint import pp, pprint\n\tfrom dataclasses import dataclass\n\tfrom dataclasses import dataclass\n\timport http.client\n\t@dataclass\n\tclass PathTuple:\n\t    endpoint: str\n\t    http_method: str\n\t    operation: swagger.Operation\n", "def get_defined_operations(item: swagger.PathItem, endpoint: str) -> List[PathTuple]:\n\t    # HACK\n\t    return [\n\t        PathTuple(endpoint, http_method, operation)\n\t        for (http_method, operation)\n\t        in filter(lambda t: t[1] is not None, item.__dict__.items())\n\t    ]\n\t# just so there is no extra transformation logic\n\tdef parameter_as_schema(p: swagger.Parameter) -> swagger.Schema:\n\t    return swagger.Schema(\n", "        title=None, description=p.description, type=p.type,format=p.format,items=p.items,allOf=None,additionalProperties=False,default=None,maximum=None,exclusiveMaximum=None,minimum=None,exclusiveMinimum=None,maxLength=None,minLength=None,pattern=None,maxItems=None,minItems=None,uniqueItems=None,properties=None,required=None,enum=None,multipleOf=None,\n\t    )\n\t@dataclass\n\tclass ParameterTuple:\n\t    location: swagger.ParameterLocation\n\t    arg: Argument\n\t# TODO: is a destinciton between simple and body needed anymore?\n\tdef transform_simple_argument(ctx: MutableContext, sp: swagger.Parameter, parent: PolymorphicModel) -> ParameterTuple:\n\t    assert sp.in_ != swagger.ParameterLocation.Body    \n\t    required = sp.required or False # \n", "    type = wrap_in_option(required,  transform_schema(ctx, parameter_as_schema(sp), sp.name, parent))\n\t    arg = Argument(\n\t        description=sp.description,\n\t        name=sp.name,\n\t        escape=is_reserved(sp.name),\n\t        required=sp.required if sp.required is not None else False,\n\t        type=type,\n\t    )\n\t    return ParameterTuple(\n\t        location=sp.in_,\n", "        arg=arg,\n\t    )\n\t@dataclass\n\tclass BodyParameterTuple:\n\t    model: Optional[PolymorphicModel] # None when it is a simple type like text\n\t    type: PolymorphicType\n\tdef suggested_response_name(status_code: StatusCodeRange) -> str:\n\t    status_string = http.client.responses.get(status_code.start)\n\t    assert status_string, f\"invalid http code {status_code}\"\n\t    return to_model_name(status_string)\n", "@dataclass\n\tclass ResponsesTuple:\n\t    responses_type: PolymorphicType\n\t    responses_type_children: List[ResponseType]\n\tT = TypeVar('T')\n\tdef inline_assert(a: T | None) -> T:\n\t    assert a is not None\n\t    return a\n\tdef transform_body(ctx: MutableContext, body_parameter: swagger.Parameter, container: PolymorphicModel) -> PolymorphicType:\n\t    assert body_parameter.in_ == swagger.ParameterLocation.Body\n", "    assert body_parameter.schema\n\t    suggested_name = to_model_name(\"Body\")\n\t    # TODO: overwrite description in model\n\t    body_type = transform_schema(ctx, body_parameter.schema, suggested_name,container)\n\t    if body_parameter.description:\n\t        inject_description(body_type, body_parameter.description)\n\t    return body_type\n\tdef inject_description(t: PolymorphicType, description: str):\n\t    # add description if not given\n\t    #if tt.determined_type.is_model and tt.determined_type.data.is_data_model:\n", "    #    body_model: PolymorphicModel = tt.determined_type.data.model\n\t    #    body_model.description = body_model.description or description \n\t    pass\n\tdef wrap_in_response_box(t: PolymorphicType, responses_trait_model: PolymorphicModel, suggested_name: str) -> PolymorphicModel:\n\t    response_box = ResponseBoxModel(model_name=f\"{suggested_name}Box\",boxes = t, of_response_trait=responses_trait_model).to_polymorphic()\n\t    return response_box\n\tdef bound_builder(str_code: str, wildcard_value: int) -> int:\n\t    return sum([\n\t        ((10**(2-i)*int(str_code[i])) # value at a given position\n\t        if str_code[i].isdigit() # check if it is not a wildcard\n", "        else wildcard_value*(10**(2-i))) # replace the wild_card\n\t        for i in range(3) # go through all three digits\n\t    ]) \n\t# some parts of the specification use wildcards as 3xx \n\t# TODO: wildcards should only be ranges, not something like 4x5\n\tdef parse_status_code_range(str_code: str) -> StatusCodeRange:\n\t    assert len(str_code) == 3, f\"invalid http code wildcard given: {str_code}\"\n\t    status_code_range = StatusCodeRange(\n\t        start=bound_builder(str_code,0), end=bound_builder(str_code,9)\n\t    )\n", "    return status_code_range\n\tdef attach_transformation_response_trait(response_type: ResponseType, responses_trait_model: PolymorphicModel,container: PolymorphicModel) -> ResponseType:\n\t    ptype, code_range = response_type.type, response_type.status_code_range\n\t    is_direct_child = ptype.is_model and  cast(ModelType, ptype.data).model.is_data_model and cast(ModelType, ptype.data).model.data.parent == container\n\t    if not is_direct_child:\n\t        suggested_name = suggested_response_name(code_range)\n\t        box = wrap_in_response_box(ptype, responses_trait_model,suggested_name)\n\t        attach_model(box, container)\n\t        return ResponseType(code_range, ModelType(box).to_polymorphic())\n\t    else:\n", "        data_model:DataModel = cast(DataModel,cast(ModelType, ptype.data).model.data)\n\t        data_model.of_response_trait = responses_trait_model\n\t        return ResponseType(code_range, ptype)\n\t#Codes used in the spec: {429, 400, 401, 403, 404, 405, 502, '3xx', 504, 409, '4xx', 501, 413}\n\t# the specification specifies some return codes, but responses are not bound to these\n\t# we preferably want to let the generated code do errorhandling\n\t# otherwise there is a ugly duality between defined errors and non-defined ones\n\tdef is_error_code(code: int) -> bool:\n\t    return not(200 <= code and 299 >= code) and not(300 <= code and 399 >= code) and not(code == 418) # :-)\n\tdef transform_to_responses_container(ctx: MutableContext, responses: swagger.Responses, container: PolymorphicModel) -> ResponsesTuple:\n", "    codes = list(responses.keys())\n\t    # TODO: headers and description are silently discarded here!\n\t    responses_trait_model = ResponsesTraitModel(model_name=\"Responses\").to_polymorphic()\n\t    schema_code_range_tuples = [\n\t        (response.schema, parse_status_code_range(str(code))) # casted to str since a code can either be a int or a wildcard str\n\t        for (code, response) in responses.items()\n\t        if isinstance(code, int) and not(is_error_code(code))\n\t    ]\n\t    response_types_plain = [\n\t        ResponseType(status_code_range=status_code_range, type =\n", "                     # either transform the given schema, or just backup with empty json Object \n\t                     transform_schema(ctx, schema, suggested_response_name(status_code_range), container) if schema is not None else GenericType().to_polymorphic()\n\t        )\n\t        for (schema, status_code_range) in schema_code_range_tuples\n\t    ]\n\t    assert len(response_types_plain) >= 1, \"no responses :(\"\n\t    # no need for pattern matching, if there is only one type\n\t    if len(response_types_plain) == 1:\n\t        head = response_types_plain[0]\n\t        return ResponsesTuple(\n", "            responses_type = head.type,\n\t            responses_type_children=[head],\n\t        )\n\t    else:\n\t        attached_types = [attach_transformation_response_trait(type, responses_trait_model, container) for type in response_types_plain ]\n\t        responses_type = ModelType(responses_trait_model).to_polymorphic()\n\t        attach_model(responses_trait_model,container)\n\t        return ResponsesTuple(\n\t            responses_type=responses_type, \n\t            responses_type_children=attached_types,\n", "        )\n\t@dataclass\n\tclass ContainerTuple:\n\t    body_type: PolymorphicType\n\t    has_body: bool\n\t    model: PolymorphicModel\n\t    response_type: PolymorphicType\n\t    response_types: List[ResponseType]\n\t# a namespace for the body and the responses\n\tdef transform_to_operation_container(ctx: MutableContext, sop: swagger.Operation) -> ContainerTuple:\n", "    assert sop.operationId\n\t    container_name=to_model_name(sop.operationId)\n\t    container_model = ContainerModel(\n\t        parent=None,\n\t        model_name=container_name,\n\t    ).to_polymorphic()\n\t    responses_tuple = transform_to_responses_container(ctx, sop.responses, container_model)    \n\t    body_parameters = [p for p in sop.parameters or [] if p.in_ == swagger.ParameterLocation.Body] \n\t    assert len(body_parameters) <= 1, \"multiple bodies defined\"\n\t    # matrix requires empty requests to send an empty json body\n", "    body_type = transform_body(ctx, body_parameters[0], container_model)if len(body_parameters) > 0 else GenericType().to_polymorphic()\n\t    return ContainerTuple(\n\t        model=container_model,\n\t        body_type=body_type,\n\t        has_body=len(body_parameters) > 0,\n\t        response_type=responses_tuple.responses_type,\n\t        response_types=responses_tuple.responses_type_children,\n\t        #default_response_type=responses_tuple.default_type,\n\t    )\n\tdef transform_to_operation(ctx: MutableContext, path: PathTuple) -> Operation:\n", "    assert path.operation.operationId\n\t    container_tuple = transform_to_operation_container(ctx, path.operation)\n\t    #assert path.operation.parameters\n\t    parameters = path.operation.parameters or []\n\t    simple_params = filter(lambda p: p.in_ !=swagger.ParameterLocation.Body, parameters)\n\t    simple_args: List[ParameterTuple] = [transform_simple_argument(ctx, p, container_tuple.model) for p in simple_params]\n\t    query_args = [a.arg for a in simple_args if a.location == swagger.ParameterLocation.Query]\n\t    header_args = [a.arg for a in simple_args if a.location == swagger.ParameterLocation.Header]\n\t    path_args = [a.arg for a in simple_args if a.location == swagger.ParameterLocation.Path]\n\t    security = transform_security_type(path.operation)\n", "    op = Operation(\n\t        operation_id=path.operation.operationId,\n\t        deprecated=path.operation.deprecated if path.operation.deprecated is not None else False, #could also be None\n\t        summary=path.operation.summary,\n\t        description=path.operation.description,\n\t        endpoint=path.endpoint,\n\t        http_method=path.http_method.upper(), # TODO: stricter types\n\t        response_type=container_tuple.response_type,\n\t        path_args=path_args,\n\t        query_args=query_args,\n", "        header_args=header_args,\n\t        has_body=container_tuple.has_body,\n\t        body_type=container_tuple.body_type,\n\t        container_model=container_tuple.model,\n\t        response_types=container_tuple.response_types,\n\t        security=security,\n\t    )\n\t    return op\n\t# NOTE: foo\n\tdef transform_to_operations(ctx: MutableContext, swagger_data: swagger.Swagger) -> list[Operation]:\n", "    assert swagger_data.basePath\n\t    path_tuples = flatten_2d([\n\t        get_defined_operations(path_item,swagger_data.basePath+relative_path)\n\t        for relative_path, path_item in swagger_data.paths.items()\n\t    ])\n\t    operations = [\n\t        transform_to_operation(ctx, tuple)\n\t        for tuple in path_tuples\n\t    ]\n\t    return operations\n"]}
{"filename": "src/transformations/eventschemas.py", "chunked_list": ["import os\n\tfrom pprint import pprint\n\tfrom typing import cast\n\tfrom codegen.data import ContainerModel, EventSchemas, ModelType, PolymorphicModel\n\tfrom swagger import RefPathLookup, SwaggerEventSchema, SwaggerEventSchemas\n\tfrom transformations.data import MutableContext\n\tfrom transformations.types import transform_schema\n\tfrom transformations.util import to_model_name\n\t# analagoues to the one from definition\n\t# but I would like to escape the name of a schema, e.g: `m̀.room.message$m.text`\n", "def suggested_name_for_event_schema(schema: SwaggerEventSchema) -> str:\n\t    base_name = os.path.basename(schema.path)\n\t    file_name, _ = os.path.splitext(base_name)\n\t    suggested_name = to_model_name(file_name)\n\t    return suggested_name\n\tdef transform_event_schemas(ctx: MutableContext, swagger_schemas: SwaggerEventSchemas) -> EventSchemas:\n\t    container = ContainerModel(model_name=\"EventSchemas\").to_polymorphic()\n\t    #ctx = MutableContext(\n\t    #    ref_lookup=ref_path_lookup,\n\t    #    model_pool=[],\n", "    #    definitions_container=container,\n\t    #    definition_cache={},\n\t    #)\n\t    transformed_types = [\n\t        (transform_schema(ctx, ses.schema, suggested_name_for_event_schema(ses), container), suggested_name_for_event_schema(ses))\n\t        for ses in swagger_schemas.schemas\n\t    ]\n\t    assert all([t[0].is_model for t in transformed_types]), \"non model as event-schema\"\n\t    for t in transformed_types:\n\t        cast(ModelType, t[0].data).model.data.model_name = t[1] \n", "    #models = [cast(ModelType, t.data).model for t in transformed_types]\n\t    return EventSchemas(\n\t        container=container,\n\t    )\n"]}
{"filename": "src/transformations/union.py", "chunked_list": ["from typing import List, Optional\n\tfrom codegen.data import ContainerModel, GenericType, ModelType, OptionType, PolymorphicModel, PolymorphicType, PrimitiveType, PrimitiveTypeEnum, UnionType\n\tfrom swagger import Schema, SwaggerDataType\n\tfrom transformations.data import MutableContext\n\tfrom transformations.util import attach_model, to_model_name\n\tfrom transformations.primitive import primitive_mapping\n\tdef is_schema_union(schema: Schema) -> bool:\n\t    return isinstance(schema.type,List)\n\tunion_mapping = primitive_mapping | {SwaggerDataType.Object: GenericType().to_polymorphic()}\n\tdef types_to_union(non_null_types: List[SwaggerDataType]) -> PolymorphicType:\n", "    types: List[PolymorphicType] = [union_mapping[type] for type in non_null_types]\n\t    return UnionType(types).to_polymorphic()\n\tdef transform_schema_as_union(ctx: MutableContext, schema: Schema, _suggested_name: str, _parent: Optional[PolymorphicModel]) -> PolymorphicType:\n\t    assert is_schema_union(schema)\n\t    assert isinstance(schema.type,List)\n\t    types = schema.type\n\t    assert len(types) > 0, \"empty type detected\"\n\t    is_nullable = SwaggerDataType.Null in types\n\t    non_null_types = [type for type in types if type != SwaggerDataType.Null]\n\t    # avoid a union for a singular type\n", "    type = types_to_union(non_null_types) if len(non_null_types) > 1 else union_mapping[non_null_types[0]]  \n\t    if is_nullable:\n\t        return OptionType(type).to_polymorphic()\n\t    else:\n\t        return type\n"]}
