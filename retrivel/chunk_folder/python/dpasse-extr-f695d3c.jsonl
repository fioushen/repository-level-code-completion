{"filename": "setup.py", "chunked_list": ["import setuptools\n\twith open('README.md', encoding='utf-8') as f:\n\t    long_description = f.read()\n\tsetuptools.setup(\n\t    name='extr',\n\t    version='0.0.44',\n\t    keywords=['Named Entity Recognition', 'Relation Extraction', 'Entity Linking', 'NER', 'RE', 'NLP'],\n\t    description='Named Entity Recognition (NER) and Relation Extraction (RE) library using Regular Expressions',\n\t    packages=setuptools.find_packages('src'),\n\t    package_dir={'': 'src'},\n", "    install_requires=[],\n\t    url='https://github.com/dpasse/extr',\n\t    long_description=long_description,\n\t    long_description_content_type='text/markdown',\n\t)\n"]}
{"filename": "tests/test_relations_viewers.py", "chunked_list": ["import os\n\timport sys\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr import Location, Entity\n\tfrom extr.relations import RelationExtractor, RegExRelationLabelBuilder\n\tfrom extr.relations.viewers import HtmlViewer\n\tdef test_html_viewer():\n\t    text = 'Ted is a Pitcher.'\n\t    annotated_text = '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'\n\t    entities = [\n", "        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n\t        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n\t    ]\n\t    ## define relationship between PERSON and POSITION    \n\t    relationship = RegExRelationLabelBuilder('is_a') \\\n\t        .add_e1_to_e2(\n\t            'PERSON', ## e1\n\t            [\n\t                ## define how the relationship exists in nature\n\t                r'\\s+is\\s+a\\s+',\n", "            ],\n\t            'POSITION' ## e2\n\t        ) \\\n\t        .build()\n\t    relations_to_extract = [relationship]\n\t    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n\t    viewer = HtmlViewer()\n\t    viewer.append_header('r(\"PERSON\", \"POSITION\")')\n\t    viewer.append_relation(text, relation=relations[0])\n\t    html = viewer.create_view()\n", "    assert html == \"\"\"<html>\n\t    <head>\n\t        <style>\n\ttable { width: 100%; }\n\tspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\n\tspan.label { font-weight: bold; padding: 3px; color: black; }\n\tspan.e1 { background-color: aqua; }\n\tspan.e2 { background-color: coral; }\n\ttr.delete { background-color: black !important; }\n\ttr.delete span { background-color: black !important; }\n", "td { line-height: 30px; border: 1px solid black; padding: 5px; }\n\ttd.header { font-weight: bold; }\n\ttd.label { font-weight: bold; text-align: center; }\n\t        </style>\n\t    </head>\n\t    <body>\n\t        <table>\n\t<tr><td class=\"header\" colspan=\"3\">r(\"PERSON\", \"POSITION\")</td></tr>\n\t<tr id=\"0\"><td>0</td><td class=\"label\">is_a</td><td><span class=\"entity lb-PERSON e1\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION e2\"><span class=\"label\">POSITION</span>Pitcher</span>.</td></tr>\n\t        </table>\n", "    </body>\n\t</html>\"\"\"\n"]}
{"filename": "tests/test_entities.py", "chunked_list": ["import os\n\timport sys\n\timport re\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr import RegEx, RegExLabel, Entity, Location\n\tfrom extr.entities import create_entity_extractor, \\\n\t                          EntityAnnotator, \\\n\t                          HtmlEntityAnnotator, \\\n\t                          KnowledgeBaseEntityLinker\n\tdef test_get_entities():\n", "    regex_labels = [\n\t        RegExLabel('PERSON', [\n\t            RegEx([r'ted'], re.IGNORECASE)\n\t        ]),\n\t        RegExLabel('POSITION', [\n\t            RegEx([r'pitcher'], re.IGNORECASE)\n\t        ]),\n\t    ]\n\t    extractor = create_entity_extractor(regex_labels)\n\t    entities = extractor.get_entities('Ted is a Pitcher.')\n", "    assert len(entities) == 2\n\tdef test_get_entities_with_overlap():\n\t    regex_labels = [\n\t        RegExLabel('PERSON', [\n\t            RegEx([r'ted'], re.IGNORECASE)\n\t        ]),\n\t        RegExLabel('POSITION', [\n\t            RegEx([r'pitch'], re.IGNORECASE),\n\t            RegEx([r'pitcher'], re.IGNORECASE)\n\t        ]),\n", "    ]\n\t    extractor = create_entity_extractor(regex_labels)\n\t    entities = extractor.get_entities('Ted is a Pitcher.')\n\t    assert len(entities) == 2\n\t    assert entities[0].text == 'Pitcher'\n\t    assert entities[1].text == 'Ted'\n\tdef test_get_entities_with_knowledge():\n\t    extractor = create_entity_extractor(\n\t        regex_labels=[\n\t            RegExLabel('POSITION', [\n", "                RegEx([r'pitcher'], re.IGNORECASE)\n\t            ]),\n\t        ],\n\t        kb={\n\t            'PERSON': [\n\t                'Ted'\n\t            ]\n\t        }\n\t    )\n\t    entities = extractor.get_entities('Ted is a Pitcher.')\n", "    assert len(entities) == 2\n\tdef test_annotate():\n\t    entities = [\n\t        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n\t        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n\t    ]\n\t    annotated_text = EntityAnnotator().annotate('Ted is a Pitcher.', entities)\n\t    assert annotated_text == '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'\n\tdef test_html_annotate():\n\t    entities = [\n", "        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n\t        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n\t    ]\n\t    annotated_text = HtmlEntityAnnotator().annotate('Ted is a Pitcher.', entities)\n\t    assert annotated_text == '<span class=\"entity lb-PERSON\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION\"><span class=\"label\">POSITION</span>Pitcher</span>.'\n\tdef test_kb_linker():\n\t    entities = [\n\t        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n\t        Entity(2, 'POSITION', 'Short Stop', Location(34, 44)),\n\t    ]\n", "    linker = KnowledgeBaseEntityLinker(\n\t        attribute_label='eid',\n\t        kb={\n\t            'Pitcher': 'BB-1',\n\t            'Catcher': 'BB-2',\n\t            'First Base': 'BB-3',\n\t            'Short Stop': 'BB-6',\n\t        }\n\t    )\n\t    entities = linker.link(entities)\n", "    assert entities[0].attributes['eid'].pop() == 'BB-1'\n\t    assert entities[1].attributes['eid'].pop() == 'BB-6'\n"]}
{"filename": "tests/test_models.py", "chunked_list": ["import os\n\timport sys\n\timport re\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr import Location\n\tdef test_location_bigger_location_contains_smaller():\n\t    big = Location(0, 10)\n\t    small = Location(3, 7)\n\t    assert big.contains(small)\n\tdef test_location_contains_returns_false_on_partial_fit_1():\n", "    big = Location(0, 10)\n\t    small = Location(7, 12)\n\t    assert not big.contains(small)\n\tdef test_location_contains_returns_false_on_partial_fit_2():\n\t    big = Location(5, 10)\n\t    small = Location(3, 8)\n\t    assert not big.contains(small)\n\tdef test_location_contains_return_false_when_given_larger():\n\t    big = Location(5, 10)\n\t    small = Location(3, 12)\n", "    assert not big.contains(small)\n\tdef test_location_is_in_returns_true_when_completely_in_other():\n\t    location1 = Location(3, 12)\n\t    location2 = Location(5, 10)\n\t    assert location2.is_in(location1)\n\tdef test_location_is_in_returns_true_when_start_is_in_other():\n\t    location1 = Location(3, 12)\n\t    location2 = Location(5, 15)\n\t    assert location2.is_in(location1)\n\tdef test_location_is_in_returns_true_when_end_is_in_other():\n", "    location1 = Location(3, 12)\n\t    location2 = Location(1, 5)\n\t    assert location2.is_in(location1)\n\tdef test_location_is_in_returns_false_when_neither_is_in_other():\n\t    location1 = Location(3, 12)\n\t    location2 = Location(1, 3)\n\t    assert not location2.is_in(location1)\n"]}
{"filename": "tests/test_end_to_end.py", "chunked_list": ["import os\n\timport sys\n\timport re\n\timport pytest\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr import RegEx, RegExLabel\n\tfrom extr.entities import EntityExtractor, EntityAnnotator\n\tfrom extr.relations import RelationExtractor, RegExRelationLabelBuilder\n\t@pytest.mark.skip\n\tdef test_end_to_end():\n", "    text = 'Walk; Mountcastle to 3B; Odor to 2B'\n\t    entity_extractor = EntityExtractor([\n\t        RegExLabel('PLAYER', [\n\t            RegEx([\n\t                r'\\b([A-Z]\\w+)(?=\\s+to\\b)'\n\t            ])\n\t        ]),\n\t        RegExLabel('BASE', [\n\t            RegEx([\n\t                r'([123]B)\\b'\n", "            ])\n\t        ]),\n\t        RegExLabel('EVENT', [\n\t            RegEx(\n\t                [\n\t                    r'\\b(Walk|Single)\\b'\n\t                ],\n\t                re.IGNORECASE\n\t            )\n\t        ]),\n", "    ])\n\t    entities = entity_extractor.get_entities(text)\n\t    print(entities)\n\t    assert len(entities) == 5\n\t    player_to_base_relationship = RegExRelationLabelBuilder('is_on') \\\n\t        .add_e1_to_e2(\n\t            'PLAYER', ## e1\n\t            [\n\t                ## define how the relationship exists in nature\n\t                r'\\s+to\\s+',\n", "            ],\n\t            'BASE' ## e2\n\t        ) \\\n\t        .build()\n\t    relations_to_extract = [\n\t        player_to_base_relationship\n\t    ]\n\t    annotated_text = EntityAnnotator().annotate(text, entities)\n\t    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n\t    print(relations)\n", "    assert len(relations) == 2\n"]}
{"filename": "tests/test_context.py", "chunked_list": ["import os\n\timport sys\n\timport re\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr import RegEx, RegExLabel\n\tfrom extr.entities import create_entity_extractor\n\tfrom extr.entities.context import ConText, ConTextRule, ConTextRuleGroup, DirectionType\n\tregex_labels=[\n\t    RegExLabel(\n\t        'LEFT_NEGATIVE',\n", "        regexes=[\n\t            RegEx([r'is ruled out'], flags=re.IGNORECASE)\n\t        ]\n\t    ),\n\t    RegExLabel(\n\t        'HISTORY_RIGHT',\n\t        regexes=[\n\t            RegEx([r'history of'], flags=re.IGNORECASE)\n\t        ]\n\t    ),\n", "    RegExLabel(\n\t        'INFECTION',\n\t        regexes=[\n\t            RegEx([r'pneumonia'], flags=re.IGNORECASE)\n\t        ]\n\t    ),\n\t]\n\trules = [\n\t    ConTextRule(\n\t        'NEGATED',\n", "        ['RIGHT_NEGATIVE'],\n\t        direction=DirectionType.RIGHT\n\t    ),\n\t    ConTextRule(\n\t        'NEGATED',\n\t        ['LEFT_NEGATIVE'],\n\t        direction=DirectionType.LEFT\n\t    ),\n\t    ConTextRule(\n\t        'HISTORICAL',\n", "        ['HISTORY_RIGHT'],\n\t        direction=DirectionType.RIGHT\n\t    ),\n\t    ConTextRule(\n\t        'HISTORICAL',\n\t        ['HISTORY_LEFT'],\n\t        direction=DirectionType.LEFT\n\t    ),\n\t    ConTextRule(\n\t        'HYPOTHETICAL',\n", "        ['HYPOTHETICAL_RIGHT'],\n\t        direction=DirectionType.RIGHT\n\t    ),\n\t    ConTextRule(\n\t        'HYPOTHETICAL',\n\t        ['HYPOTHETICAL_LEFT'],\n\t        direction=DirectionType.LEFT\n\t    )\n\t]\n\tdef test_contextor_historical_right_1():\n", "    text = 'Past history of pneumonia.'\n\t    entity_extractor = create_entity_extractor(regex_labels=regex_labels)\n\t    contextor = ConText(\n\t        rule_grouping=ConTextRuleGroup(\n\t            rules=rules\n\t        ),\n\t        word_tokenizer=lambda _: ['Past', 'history', 'of', 'pneumonia', '.']\n\t    )\n\t    entities = contextor.apply(\n\t        text,\n", "        entity_extractor.get_entities(text)\n\t    )\n\t    assert len(entities) == 1\n\t    assert list(entities[0].get_attributes_by_label('ctypes'))[0] == 'HISTORICAL'\n\t    print(\n\t        [\n\t            (entity, entity.get_attributes_by_label('ctypes'))\n\t            for entity in entities\n\t        ]\n\t    )\n", "def test_contextor_negative_left_1():\n\t    text = 'Pneumonia is ruled out.'\n\t    entity_extractor = create_entity_extractor(regex_labels=regex_labels)\n\t    contextor = ConText(\n\t        rule_grouping=ConTextRuleGroup(\n\t            rules=rules\n\t        ),\n\t        word_tokenizer=lambda _: ['Pneumonia', 'is', 'ruled', 'out', '.']\n\t    )\n\t    entities = contextor.apply(\n", "        text,\n\t        entity_extractor.get_entities(text)\n\t    )\n\t    assert len(entities) == 1\n\t    assert list(entities[0].get_attributes_by_label('ctypes'))[0] == 'NEGATED'\n\t    print(\n\t        [\n\t            (entity, entity.get_attributes_by_label('ctypes'))\n\t            for entity in entities\n\t        ]\n", "    )\n"]}
{"filename": "tests/test_entities_viewers.py", "chunked_list": ["import os\n\timport sys\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr import Entity, Location\n\tfrom extr.entities.viewers import HtmlViewer\n\tdef test_html_viewer():\n\t    entities = [\n\t        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n\t        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n\t    ]\n", "    viewer = HtmlViewer()\n\t    viewer.append('Ted is a Pitcher.', entities)\n\t    html_doc = viewer.create_view()\n\t    assert html_doc == \"\"\"<html>\n\t    <head>\n\t        <style>\n\tp { margin: 5px; line-height: 45px; }\n\tspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\n\tspan.label { font-weight: bold; padding: 3px; color: black; }\n\t        </style>\n", "    </head>\n\t    <body>\n\t<p><span class=\"entity lb-PERSON\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION\"><span class=\"label\">POSITION</span>Pitcher</span>.</p>\n\t    </body>\n\t</html>\"\"\"\n\tdef test_html_viewer_with_custom_styles():\n\t    entities = [\n\t        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n\t        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n\t    ]\n", "    viewer = HtmlViewer()\n\t    viewer.append('Ted is a Pitcher.', entities)\n\t    html_doc = viewer.create_view(\"\"\"\n\t.lb-PERSON { background-color: orange; }\n\t.lb-POSITION { background-color: yellow; }\n\t\"\"\")\n\t    assert html_doc == \"\"\"<html>\n\t    <head>\n\t        <style>\n\tp { margin: 5px; line-height: 45px; }\n", "span.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\n\tspan.label { font-weight: bold; padding: 3px; color: black; }\n\t.lb-PERSON { background-color: orange; }\n\t.lb-POSITION { background-color: yellow; }\n\t        </style>\n\t    </head>\n\t    <body>\n\t<p><span class=\"entity lb-PERSON\"><span class=\"label\">PERSON</span>Ted</span> is a <span class=\"entity lb-POSITION\"><span class=\"label\">POSITION</span>Pitcher</span>.</p>\n\t    </body>\n\t</html>\"\"\"\n"]}
{"filename": "tests/test_tokenizer.py", "chunked_list": ["import os\n\timport sys\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr.tokenizers import word_tokenizer\n\tdef test_word_tokenizer():\n\t    token_group = word_tokenizer(\n\t        'Ted is a pitcher.',\n\t        ['Ted', 'is', 'a', 'pitcher', '.']\n\t    )\n\t    assert token_group.location.start == 0\n", "    assert token_group.location.end == 17\n\t    assert len(token_group.tokens) == 5\n"]}
{"filename": "tests/test_relations.py", "chunked_list": ["import os\n\timport sys\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr import Location, Entity\n\tfrom extr.relations import RelationExtractor, RegExRelationLabelBuilder\n\tdef test_get_relations():\n\t    annotated_text = '##ENTITY_PERSON_2## is a ##ENTITY_POSITION_1##.'\n\t    entities = [\n\t        Entity(1, 'POSITION', 'Pitcher', Location(9, 16)),\n\t        Entity(2, 'PERSON', 'Ted', Location(0, 3))\n", "    ]\n\t    ## define relationship between PERSON and POSITION    \n\t    relationship = RegExRelationLabelBuilder('is_a') \\\n\t        .add_e1_to_e2(\n\t            'PERSON', ## e1\n\t            [\n\t                ## define how the relationship exists in nature\n\t                r'\\s+is\\s+a\\s+',\n\t            ],\n\t            'POSITION' ## e2\n", "        ) \\\n\t        .build()\n\t    relations_to_extract = [relationship]\n\t    relations = RelationExtractor(relations_to_extract).extract(annotated_text, entities)\n\t    assert len(relations) == 1\n\t    assert relations[0].e1.text == 'Ted'\n\t    assert relations[0].e2.text == 'Pitcher'\n\t    assert relations[0].label == 'is_a'\n"]}
{"filename": "tests/test_regex.py", "chunked_list": ["import os\n\timport sys\n\timport re\n\tsys.path.insert(0, os.path.join('../src'))\n\tfrom extr.regexes import RegEx, SlimRegEx\n\tdef test_findall():\n\t    regex = RegEx(\n\t        expressions=[\n\t            r'.+',\n\t        ]\n", "    )\n\t    text = 'Ted is a pitcher.'\n\t    matches = regex.findall(text)\n\t    assert len(matches) == 1\n\t    assert matches[0].group() == text\n\tdef test_findall_with_skip_ifs():\n\t    regex = RegEx(\n\t        expressions=[\n\t            r'.+',\n\t        ],\n", "        skip_if=[\n\t            SlimRegEx([r'is\\s+a'])\n\t        ],\n\t    )\n\t    matches = regex.findall('Ted is a pitcher.')\n\t    assert len(matches) == 0\n"]}
{"filename": "src/extr/models.py", "chunked_list": ["from typing import Set, Dict, List, TypeVar, Generator, cast\n\tfrom dataclasses import dataclass, field\n\tNOT_DEFINED_FLAG: int = -1\n\t# pylint: disable=C0103\n\tTLocation = TypeVar('TLocation', bound='Location')\n\t# pylint: enable=C0103\n\t@dataclass(frozen=True)\n\tclass Location:\n\t    start: int\n\t    end: int\n", "    @property\n\t    def actual_end(self) -> int:\n\t        return self.end - 1\n\t    def is_in(self: TLocation, other: TLocation) -> bool:\n\t        return self.start >= other.start and self.start <= other.actual_end \\\n\t            or self.actual_end >= other.start and self.actual_end <= other.actual_end\n\t    def contains(self: TLocation, other: TLocation) -> bool:\n\t        return other.start >= self.start and other.actual_end <= self.actual_end\n\t    def extract(self, text: str) -> str:\n\t        return text[self.start:self.end]\n", "    def __str__(self) -> str:\n\t        return f'({self.start}, {self.end})'\n\t    def __repr__(self) -> str:\n\t        return f'({self.start}, {self.end})'\n\t# pylint: disable=C0103\n\tTILocation = TypeVar('TILocation', bound='ILocation')\n\t# pylint: enable=C0103\n\tclass ILocation:\n\t    location: Location\n\t    def is_in(self: TILocation, other: TILocation) -> bool:\n", "        return self.location.is_in(other.location)\n\t    def contains(self: TILocation, other: TILocation) -> bool:\n\t        return self.location.contains(other.location)\n\tclass IMeta():\n\t    attributes: Dict[str, Set[str]]\n\t    def add_attribute(self, label: str, attribute: str) -> None:\n\t        if not label in self.attributes:\n\t            self.attributes[label] = set()\n\t        self.attributes[label].add(attribute)\n\t    def get_attributes_by_label(self, label: str) -> Set[str]:\n", "        if not label in self.attributes:\n\t            return set()\n\t        return self.attributes[label]\n\t    def is_a(self, label: str, attribute: str) -> bool:\n\t        if label in self.attributes:\n\t            return attribute in self.get_attributes_by_label(label)\n\t        return False\n\t@dataclass()\n\tclass Entity(ILocation, IMeta):\n\t    identifier: int\n", "    label: str\n\t    text: str\n\t    location: Location\n\t    attributes: Dict[str, Set[str]] = field(default_factory=dict)\n\t    @property\n\t    def start(self) -> int:\n\t        return self.location.start\n\t    @property\n\t    def end(self) -> int:\n\t        return self.location.end\n", "    def __str__(self) -> str:\n\t        return f'##ENTITY_{self.label}_{self.identifier}##'\n\t    def __repr__(self) -> str:\n\t        return f'<Entity label=\"{self.label}\" text=\"{self.text}\" span={repr(self.location)}>'\n\t@dataclass(frozen=True)\n\tclass Relation:\n\t    label: str\n\t    e1: Entity\n\t    e2: Entity\n\t    @property\n", "    def key(self) -> str:\n\t        return self.create_key(self.e1, self.e2)\n\t    @property\n\t    def definition(self) -> str:\n\t        return f'r(\"{self.e1.label}\", \"{self.e2.label}\")'\n\t    def __str__(self) -> str:\n\t        return f'r(\"{self.e1.text}\", \"{self.e2.text}\") == \"{self.label}\"'\n\t    def __repr__(self) -> str:\n\t        return f'<Relation e1=\"{self.e1.text}\" r=\"{self.label}\" e2=\"{self.e2.text}\">'\n\t    @staticmethod\n", "    def create_key(e1: Entity, e2: Entity) -> str:\n\t        return f'{e1.identifier}_{e2.identifier}'\n\t@dataclass(frozen=True)\n\tclass Token(ILocation):\n\t    text: str\n\t    location: Location\n\t    order: int\n\t    entities: List[Entity] = field(default_factory=lambda: [])\n\t    def add_entity(self, entity: Entity) -> None:\n\t        self.entities.append(entity)\n", "    def apply_attribute(self, label: str, attribute: str) -> None:\n\t        for entity in self.entities:\n\t            entity.add_attribute(label, attribute)\n\t    def __len__(self) -> int:\n\t        return len(self.entities)\n\t    def __str__(self) -> str:\n\t        return self.text\n\t    def __repr__(self) -> str:\n\t        return f'<Token text=\"{self.text}\", location={repr(self.location)}, order={self.order}>'\n\t@dataclass(frozen=True)\n", "class TokenGroup(ILocation):\n\t    location: Location\n\t    sentence: str\n\t    tokens: List[Token]\n\t    def find_entities(self: ILocation, entities: List[Entity]) -> Generator[Entity, None, None]:\n\t        for entity in entities:\n\t            if self.contains(entity):\n\t                yield entity\n\t    def find_relations(self: ILocation, relations: List[Relation]) -> Generator[Relation, None, None]:\n\t        for relation in relations:\n", "            if self.contains(relation.e1) and self.contains(relation.e2):\n\t                yield relation\n\t    def apply_entities(self, entities: List[Entity]) -> None:\n\t        for entity in self.find_entities(entities):\n\t            for token in self.tokens:\n\t                if not cast(ILocation, entity).is_in(token) and not cast(ILocation, entity).contains(token):\n\t                    continue\n\t                token.add_entity(entity)\n"]}
{"filename": "src/extr/__init__.py", "chunked_list": ["from .regexes import RegExLabel, RegEx\n\tfrom .models import Entity, Relation, ILocation, Location, Token, TokenGroup\n\tfrom .entities import EntityExtractor, EntityAnnotator\n\tfrom .relations import RelationExtractor, RelationAnnotator, RegExRelationLabelBuilder\n"]}
{"filename": "src/extr/regexes/regex.py", "chunked_list": ["from typing import List, Tuple, Optional\n\timport re\n\tfrom ..utils.iterutils import flatten\n\tclass SlimRegEx:\n\t    def __init__(self, expressions: List[str], flags: int = 0) -> None:\n\t        self._expressions = expressions\n\t        self._flags = flags\n\t    def findall(self, text: str) -> List[re.Match]:\n\t        def handler(expression: str) -> list:\n\t            return list(re.finditer(expression, text, self._flags))\n", "        return flatten(map(handler, self._expressions))\n\t    def search(self, text: str) -> Optional[re.Match]:\n\t        for expression in self._expressions:\n\t            match = re.search(expression, text)\n\t            if match:\n\t                return match\n\t        return None\n\tclass RegEx(SlimRegEx):\n\t    def __init__(self, expressions: List[str], flags: int = 0, skip_if: Optional[List[SlimRegEx]] = None) -> None:\n\t        super().__init__(expressions, flags)\n", "        self._skip_if = set([] if skip_if is None else skip_if)\n\t    def findall(self, text: str) -> List[re.Match]:\n\t        def handler(expression: str) -> list:\n\t            observations = []\n\t            for match in re.finditer(expression, text, self._flags):\n\t                should_skip_match = False\n\t                for skip_if in self._skip_if:\n\t                    if skip_if.search(match.group()):\n\t                        should_skip_match = True\n\t                        break\n", "                if not should_skip_match:\n\t                    observations.append(match)\n\t            return observations\n\t        return flatten(map(handler, self._expressions))\n\tclass RegExLabel:\n\t    def __init__(self, label: str, regexes: List[RegEx]) -> None:\n\t        self._label = label\n\t        self._regexes = regexes\n\t    def findall(self, text: str) -> List[Tuple[str, re.Match]]:\n\t        def handler(regex) -> list:\n", "            observations = regex.findall(text)\n\t            return list(zip([self._label] * len(observations), observations))\n\t        return flatten(map(handler, self._regexes))\n\tdef transform_knowledge(label: str, knowledge: List[str]) -> RegExLabel:\n\t    expressions = [\n\t        r'(?<!\\w)' + term + r'(?!\\w)'\n\t        for term in knowledge\n\t    ]\n\t    return RegExLabel(\n\t        label,\n", "        [\n\t            RegEx(expressions)\n\t        ]\n\t    )\n"]}
{"filename": "src/extr/regexes/__init__.py", "chunked_list": ["from .regex import SlimRegEx, RegEx, RegExLabel, transform_knowledge\n"]}
{"filename": "src/extr/pipelines/pipes.py", "chunked_list": ["from typing import Optional, List, Tuple\n\tfrom ..models import Entity, Relation\n\tfrom ..entities.extractor import AbstractEntityExtractor\n\tfrom ..entities.annotator import EntityAnnotator\n\tfrom ..entities.linkers import AbstractEntityLinker\n\tfrom ..entities.context import ConText\n\tfrom ..relations.extractor import RelationExtractor\n\tclass EntityPipeline:\n\t    def __init__(self, \\\n\t                 entity_extractor: AbstractEntityExtractor, \\\n", "                 entity_linker: Optional[AbstractEntityLinker], \\\n\t                 context: Optional[ConText]):\n\t        self._entity_extractor = entity_extractor\n\t        self._entity_linker = entity_linker\n\t        self._context = context\n\t    def extract(self, text: str) -> List[Entity]:\n\t        entities = self._entity_extractor.get_entities(text)\n\t        if self._entity_linker:\n\t            entities = self._entity_linker.link(entities)\n\t        if self._context:\n", "            entities = self._context.apply(\n\t                text,\n\t                entities,\n\t                filter_out_rule_labels=True\n\t            )\n\t        return entities\n\tclass RelationPipeline:\n\t    def __init__(self, \\\n\t                 entity_pipeline: EntityPipeline,\n\t                 entity_annotator: EntityAnnotator,\n", "                 relation_extractor: RelationExtractor):\n\t        self._entity_pipeline = entity_pipeline\n\t        self._entity_annotator = entity_annotator\n\t        self._relation_extractor = relation_extractor\n\t    def extract(self, text: str) -> Tuple[List[Entity], List[Relation]]:\n\t        entities = self._entity_pipeline.extract(text)\n\t        relations = self._relation_extractor.extract(\n\t            self._entity_annotator.annotate(text, entities),\n\t            entities\n\t        )\n", "        return entities, relations\n"]}
{"filename": "src/extr/pipelines/__init__.py", "chunked_list": ["from .pipes import EntityPipeline, RelationPipeline\n"]}
{"filename": "src/extr/utils/iterutils.py", "chunked_list": ["def flatten(items) -> list:\n\t    flat_list = []\n\t    for sublist in items:\n\t        for item in sublist:\n\t            flat_list.append(item)\n\t    return flat_list\n"]}
{"filename": "src/extr/utils/query.py", "chunked_list": ["from typing import Dict, List, TypeVar, Generic, Callable, Optional\n\tfrom copy import deepcopy\n\tT = TypeVar('T')\n\t# pylint: disable=C0103\n\tTQuery = TypeVar('TQuery', bound='Query')\n\t# pylint: enable=C0103\n\tclass Query(Generic[T]):\n\t    def __init__(self: TQuery, sequence: List[T]):\n\t        self._sequence = deepcopy(sequence)\n\t    def __filter(self: TQuery, filter_method: Callable[[T], bool]) -> List[T]:\n", "        return list(filter(filter_method, self._sequence))\n\t    def filter(self: TQuery, filter_method: Callable[[T], bool]) -> TQuery:\n\t        self._sequence = self.__filter(filter_method)\n\t        return self\n\t    def find(self: TQuery, find_method: Callable[[T], bool]) -> Optional[T]:\n\t        observations = self.__filter(find_method)\n\t        size = len(observations)\n\t        if size > 1:\n\t            raise Exception('Search was not unique.')\n\t        if size == 1:\n", "            return observations[0]\n\t        return None\n\t    def tolist(self: TQuery) -> List[T]:\n\t        return self._sequence\n\t    def todict(self: TQuery, key_method: Callable[[T], str]) -> Dict[str, T]:\n\t        mapping: Dict[str, T] = {}\n\t        for item in self._sequence:\n\t            mapping[key_method(item)] = item\n\t        return mapping\n"]}
{"filename": "src/extr/utils/__init__.py", "chunked_list": ["from .iterutils import flatten\n\tfrom .query import Query\n"]}
{"filename": "src/extr/tokenizers/tokenizer.py", "chunked_list": ["from typing import List\n\tfrom extr import Location\n\tfrom ..models import Token, TokenGroup\n\tdef word_tokenizer(text: str, tokens: List[str]) -> TokenGroup:\n\t    cache = text[:]\n\t    offset = 0\n\t    tokens_in_sentence: List[Token] = []\n\t    for term in tokens:\n\t        start = cache.find(term)\n\t        end = start + len(term)\n", "        actual_term = cache[start:end]\n\t        assert actual_term == term, f'mismatch(\"{actual_term}\", \"{term}\")'\n\t        tokens_in_sentence.append(\n\t            Token(term, Location(offset + start, offset + end), len(tokens_in_sentence) + 1)\n\t        )\n\t        cache = cache[end:]\n\t        offset += end\n\t    sentence_start = tokens_in_sentence[0].location.start\n\t    sentence_end = tokens_in_sentence[-1].location.end\n\t    token_group = TokenGroup(\n", "        Location(sentence_start, sentence_end),\n\t        text[sentence_start:sentence_end],\n\t        tokens_in_sentence\n\t    )\n\t    return token_group\n"]}
{"filename": "src/extr/tokenizers/__init__.py", "chunked_list": ["from .tokenizer import word_tokenizer\n"]}
{"filename": "src/extr/relations/__init__.py", "chunked_list": ["from .extractor import AbstractRelationExtractor, RelationExtractor\n\tfrom .annotator import RelationAnnotator, RelationAnnotatorWithEntityType, HtmlRelationAnnotator\n\tfrom .label_builder import RegExRelationLabelBuilder, RelationLabelBuilderConfig\n"]}
{"filename": "src/extr/relations/label_builder.py", "chunked_list": ["from typing import List, TypeVar\n\tfrom dataclasses import dataclass, field\n\tfrom ..regexes import RegEx, RegExLabel\n\t# pylint: disable=C0103\n\tTRegExRelationLabelBuilder = TypeVar('TRegExRelationLabelBuilder', bound='RegExRelationLabelBuilder')\n\t# pylint: enable=C0103\n\t@dataclass\n\tclass RelationLabelBuilderConfig:\n\t    flags: int = 0\n\t    skip_if: List[str] = field(default_factory=lambda: [])\n", "class RegExRelationLabelBuilder:\n\t    def __init__(self: TRegExRelationLabelBuilder, label: str) -> None:\n\t        self._label = label\n\t        self._expressions: List[RegEx] = []\n\t    @property\n\t    def label(self: TRegExRelationLabelBuilder) -> str:\n\t        return self._label\n\t    def add_e1_to_e2(self: TRegExRelationLabelBuilder, \\\n\t                     e1: str, relation_expressions: List[str], \\\n\t                     e2: str, config = RelationLabelBuilderConfig() \\\n", "    ) -> TRegExRelationLabelBuilder:\n\t        self._expressions.append(\n\t            RegEx(\n\t                expressions=list(\n\t                    map(\n\t                        lambda expression: r'(?P<e1>##ENTITY_' + e1 + r'_\\d+##)' + expression + r'(?P<e2>##ENTITY_' + e2 + r'_\\d+##)',\n\t                        relation_expressions\n\t                    )\n\t                ),\n\t                flags=config.flags,\n", "                skip_if=config.skip_if\n\t            )\n\t        )\n\t        return self\n\t    def add_e2_to_e1(self: TRegExRelationLabelBuilder, e2: str, \\\n\t                     relation_expressions: List[str], \\\n\t                     e1: str, config = RelationLabelBuilderConfig() \\\n\t    ) -> TRegExRelationLabelBuilder:\n\t        self._expressions.append(\n\t            RegEx(\n", "                expressions=list(\n\t                    map(\n\t                        lambda expression: r'(?P<e2>##ENTITY_' + e2 + r'_\\d+##)' + expression + r'(?P<e1>##ENTITY_' + e1 + r'_\\d+##)',\n\t                        relation_expressions\n\t                    )\n\t                ),\n\t                flags=config.flags,\n\t                skip_if=config.skip_if\n\t            )\n\t        )\n", "        return self\n\t    def build(self: TRegExRelationLabelBuilder) -> RegExLabel:\n\t        return RegExLabel(self.label, self._expressions)\n"]}
{"filename": "src/extr/relations/annotator.py", "chunked_list": ["import re\n\tfrom ..models import Relation, Entity\n\tclass RelationAnnotator:\n\t    def display_entity(self, entity: Entity, position: int) -> str:\n\t        return f'<e{str(position)}>{entity.text}</e{str(position)}>'\n\t    def annotate(self, text: str, relation: Relation) -> str:\n\t        annotated_text = text[:]\n\t        e1 = relation.e1\n\t        e1_start = e1.location.start\n\t        e1_end = e1.location.end\n", "        e2 = relation.e2\n\t        e2_start = e2.location.start\n\t        e2_end = e2.location.end\n\t        if e1_end < e2_start:\n\t            return annotated_text[:e1_start] + \\\n\t                self.display_entity(e1, 1) + \\\n\t                annotated_text[e1_end:e2_start] + \\\n\t                self.display_entity(e2, 2) + \\\n\t                annotated_text[e2_end:]\n\t        return annotated_text[:e2_start] + \\\n", "            self.display_entity(e2, 2) + \\\n\t            annotated_text[e2_end:e1_start] + \\\n\t            self.display_entity(e1, 1) + \\\n\t            annotated_text[e1_end:]\n\tclass RelationAnnotatorWithEntityType(RelationAnnotator):\n\t    def display_entity(self, entity: Entity, position: int) -> str:\n\t        return f'<e{str(position)}:{entity.label}>{entity.text}</e{str(position)}:{entity.label}>'\n\tclass HtmlRelationAnnotator(RelationAnnotator):\n\t    def display_entity(self, entity: Entity, position: int) -> str:\n\t        key = re.sub(r' ', '-', entity.label)\n", "        return f'<span class=\"entity lb-{key} e{position}\">' + \\\n\t            f'<span class=\"label\">{entity.label}</span>' + \\\n\t            f'{entity.text}' + \\\n\t            '</span>'\n"]}
{"filename": "src/extr/relations/extractor.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import List, Generator, cast\n\timport re\n\tfrom ..regexes import RegExLabel\n\tfrom ..models import Relation, Entity\n\tfrom ..utils import flatten\n\tclass AbstractRelationExtractor(ABC):\n\t    @abstractmethod\n\t    def extract(self, text: str, entities: List[Entity]) -> List[Relation]:\n\t        pass\n", "class RelationExtractor(AbstractRelationExtractor):\n\t    def __init__(self, relation_labels: List[RegExLabel]) -> None:\n\t        self._relation_labels = relation_labels\n\t    def extract(self, text: str, entities: List[Entity]) -> List[Relation]:\n\t        entity_lookup = { str(entity): entity for entity in entities }\n\t        def create_relation(label, match: re.Match) -> Relation:\n\t            group = match.groupdict()\n\t            e1_key = group['e1']\n\t            e2_key = group['e2']\n\t            return Relation(\n", "                label,\n\t                entity_lookup[e1_key],\n\t                entity_lookup[e2_key]\n\t            )\n\t        def handler(relationship_label: RegExLabel) -> Generator[Relation, None, None]:\n\t            return (\n\t                create_relation(label, match)\n\t                for label, match in relationship_label.findall(text)\n\t            )\n\t        return cast(List[Relation], flatten(map(handler, self._relation_labels)))\n"]}
{"filename": "src/extr/relations/viewers/__init__.py", "chunked_list": ["from .html import HtmlViewer\n"]}
{"filename": "src/extr/relations/viewers/html.py", "chunked_list": ["from typing import List, Optional\n\tfrom ...models import Relation\n\tfrom ...entities.viewers.html import __TEMPLATE__\n\tfrom ..annotator import HtmlRelationAnnotator\n\tclass HtmlViewer:\n\t    __TEMPLATE = __TEMPLATE__ \\\n\t        .replace(\n\t            '{{body}}',\n\t            \"\"\"        <table>\n\t{{body}}\n", "        </table>\"\"\"\n\t        )\n\t    __DEFAULT_STYLES = \"\"\"\n\ttable { width: 100%; }\n\tspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\n\tspan.label { font-weight: bold; padding: 3px; color: black; }\n\tspan.e1 { background-color: aqua; }\n\tspan.e2 { background-color: coral; }\n\ttr.delete { background-color: black !important; }\n\ttr.delete span { background-color: black !important; }\n", "td { line-height: 30px; border: 1px solid black; padding: 5px; }\n\ttd.header { font-weight: bold; }\n\ttd.label { font-weight: bold; text-align: center; }\n\t\"\"\"\n\t    def __init__(self, show_index=True) -> None:\n\t        self._relation_index = 0\n\t        self._show_index = show_index\n\t        self._rows: List[str] = []\n\t        self._annotator = HtmlRelationAnnotator()\n\t    def append_header(self, header: str) -> None:\n", "        colspan = 3 if self._show_index else 2\n\t        self._rows.append(\n\t            '<tr>' + \\\n\t                f'<td class=\"header\" colspan=\"{colspan}\">{header}</td>' + \\\n\t            '</tr>'\n\t        )\n\t    def append_relation(self, text: str, relation: Relation) -> None:\n\t        index = self._relation_index\n\t        annotation = self._annotator.annotate(text, relation)\n\t        self._rows.append(\n", "            f'<tr id=\"{index}\">' + \\\n\t                (f'<td>{index}</td>' if self._show_index else '') + \\\n\t                f'<td class=\"label\">{relation.label}</td>' + \\\n\t                f'<td>{annotation}</td>' + \\\n\t            '</tr>'\n\t        )\n\t        self._relation_index += 1\n\t    def create_view(self, custom_styles: Optional[str] = None) -> str:\n\t        styles = self.__DEFAULT_STYLES.strip()\n\t        if custom_styles:\n", "            styles += f'\\n{custom_styles.strip()}'\n\t        body = '\\n'.join(self._rows)\n\t        return self.__TEMPLATE \\\n\t            .replace('{{styles}}', styles) \\\n\t            .replace('{{body}}', body) \\\n\t            .strip()\n"]}
{"filename": "src/extr/entities/context.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import Callable, Generator, List, Optional, Set\n\tfrom enum import Enum\n\tfrom dataclasses import dataclass\n\tfrom ..models import Entity, Token\n\tfrom ..tokenizers import word_tokenizer as tokenizer\n\tclass DirectionType(Enum):\n\t    LEFT=0\n\t    RIGHT=1\n\t    BOTH=2\n", "class ConTextRule:\n\t    def __init__(self,\n\t                 attribute: str,\n\t                 labels: List[str],\n\t                 window_size: int = 5,\n\t                 direction: DirectionType = DirectionType.RIGHT,\n\t                 exit_labels: Optional[List[str]] = None) -> None:\n\t        self._attribute = attribute\n\t        self._labels = labels\n\t        self._window_size = window_size\n", "        self._direction = direction\n\t        self._exit_labels = labels[:] + ([] if exit_labels is None else exit_labels)\n\t    @property\n\t    def attribute(self) -> str:\n\t        return self._attribute\n\t    @property\n\t    def labels(self) -> List[str]:\n\t        return self._labels\n\t    @property\n\t    def window_size(self) -> int:\n", "        return self._window_size\n\t    @property\n\t    def direction(self) -> DirectionType:\n\t        return self._direction\n\t    @property\n\t    def exit_labels(self) -> List[str]:\n\t        return self._exit_labels\n\t@dataclass\n\tclass ConTextRuleGroup:\n\t    rules: List[ConTextRule]\n", "    def get_rules(self, token: Token) -> Generator[ConTextRule, None, None]:\n\t        entity_labels: Set[str] = set(entity.label for entity in token.entities)\n\t        for rule in self.rules:\n\t            if any(\n\t                label\n\t                for label in rule.labels\n\t                if label in entity_labels\n\t            ):\n\t                yield rule\n\tclass AbstractConText(ABC):\n", "    @abstractmethod\n\t    def apply(self, text: str, entities: List[Entity], filter_out_rule_labels: bool = True) -> List[Entity]:\n\t        pass\n\tclass ConText(AbstractConText):\n\t    def __init__(self, \\\n\t                 rule_grouping: ConTextRuleGroup, \\\n\t                 word_tokenizer: Callable[[str], List[str]], \\\n\t                 attribute_label: str = 'ctypes') -> None:\n\t        self._rule_grouping = rule_grouping\n\t        self._word_tokenizer = word_tokenizer\n", "        self._attribute_label = attribute_label\n\t    @staticmethod\n\t    def get_tokens_by_direction(current_index: int, window_size: int, direction: DirectionType, tokens: List[Token]) -> List[Token]:\n\t        if direction == DirectionType.RIGHT:\n\t            start = current_index + 1\n\t            end = min([start + window_size, len(tokens)])\n\t            return tokens[start:end]\n\t        if direction == DirectionType.LEFT:\n\t            start = max([current_index - 1 - window_size, 0])\n\t            end = current_index\n", "            return tokens[start:end][::-1]\n\t        return []\n\t    def apply(self, text: str, entities: List[Entity], filter_out_rule_labels: bool = True) -> List[Entity]:\n\t        token_group = tokenizer(text, self._word_tokenizer(text))\n\t        token_group.apply_entities(entities)\n\t        tokens = token_group.tokens\n\t        for current_index, token in enumerate(tokens):\n\t            for rule in self._rule_grouping.get_rules(token):\n\t                for tokens_by_direction in self._get_tokens_for_rule(\n\t                    current_index,\n", "                    rule,\n\t                    tokens\n\t                ):\n\t                    self._process_direction_for_rule(rule, tokens_by_direction)\n\t        if filter_out_rule_labels:\n\t            all_labels: List[str] = []\n\t            for rule in self._rule_grouping.rules:\n\t                all_labels.extend(rule.labels)\n\t                all_labels.extend(rule.exit_labels)\n\t            labels = set(all_labels)\n", "            return [\n\t                entity\n\t                for entity in entities\n\t                if not entity.label in labels\n\t            ]\n\t        return entities\n\t    def _get_tokens_for_rule(self, current_index: int, rule: ConTextRule, tokens: List[Token]) -> Generator[List[Token], None, None]:\n\t        directions = [DirectionType.RIGHT, DirectionType.LEFT] \\\n\t            if rule.direction == DirectionType.BOTH \\\n\t            else [rule.direction]\n", "        for direction in directions:\n\t            yield ConText.get_tokens_by_direction(current_index, rule.window_size, direction, tokens)\n\t    def _process_direction_for_rule(self, rule: ConTextRule, tokens: List[Token]) -> None:\n\t        for token in tokens:\n\t            exit_condition_met = any(\n\t                entity\n\t                for entity in token.entities\n\t                if entity.label in rule.exit_labels\n\t            )\n\t            if exit_condition_met:\n", "                break\n\t            token.apply_attribute(self._attribute_label, rule.attribute)\n"]}
{"filename": "src/extr/entities/factories.py", "chunked_list": ["from typing import List, Dict, Optional\n\tfrom .extractor import EntityExtractor\n\tfrom ..regexes import RegExLabel, transform_knowledge\n\tdef create_entity_extractor(regex_labels: List[RegExLabel], kb: Optional[Dict[str, List[str]]] = None):\n\t    all_regex_labels = []\n\t    if len(regex_labels) > 0:\n\t        all_regex_labels.extend(regex_labels)\n\t    if kb:\n\t        all_regex_labels.extend(\n\t            [transform_knowledge(label, expressions) for label, expressions in kb.items()]\n", "        )\n\t    return EntityExtractor(all_regex_labels)\n"]}
{"filename": "src/extr/entities/__init__.py", "chunked_list": ["from .extractor import AbstractEntityExtractor, EntityExtractor\n\tfrom .annotator import EntityAnnotator, \\\n\t                       HtmlEntityAnnotator, \\\n\t                       LabelOnlyEntityAnnotator\n\tfrom .linkers import AbstractEntityLinker, \\\n\t                     KnowledgeBaseEntityLinker\n\tfrom .factories import create_entity_extractor\n"]}
{"filename": "src/extr/entities/annotator.py", "chunked_list": ["from typing import List\n\timport re\n\tfrom ..models import Entity\n\tclass EntityAnnotator:\n\t    def display_entity(self, entity: Entity) -> str:\n\t        return str(entity)\n\t    def annotate(self, text: str, entities: List[Entity]) -> str:\n\t        def insert_entity(text: str, entity: Entity) -> str:\n\t            start = entity.start\n\t            end = entity.end\n", "            return text[:start] + self.display_entity(entity) + text[end:]\n\t        annotated_text = text[:]\n\t        for entity in entities:\n\t            annotated_text = insert_entity(annotated_text, entity)\n\t        return annotated_text\n\tclass LabelOnlyEntityAnnotator(EntityAnnotator):\n\t    def display_entity(self, entity: Entity) -> str:\n\t        return f'<{entity.label}>{entity.text}</{entity.label}>'\n\tclass HtmlEntityAnnotator(EntityAnnotator):\n\t    def display_entity(self, entity: Entity) -> str:\n", "        key = re.sub(r' ', '-', entity.label)\n\t        return f'<span class=\"entity lb-{key}\">' + \\\n\t            f'<span class=\"label\">{entity.label}</span>' + \\\n\t            f'{entity.text}' + \\\n\t            '</span>'\n"]}
{"filename": "src/extr/entities/extractor.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import List\n\tfrom ..regexes import RegExLabel\n\tfrom ..models import Location, Entity\n\tclass AbstractEntityExtractor(ABC):\n\t    @abstractmethod\n\t    def get_entities(self, text: str) -> List[Entity]:\n\t        pass\n\tclass EntityExtractor(AbstractEntityExtractor):\n\t    def __init__(self, regex_labels: List[RegExLabel]) -> None:\n", "        self._regex_labels = regex_labels\n\t    def get_entities(self, text: str) -> List[Entity]:\n\t        entities: List[Entity] = []\n\t        for regex_label in self._regex_labels:\n\t            for label, match in regex_label.findall(text):\n\t                entities.append(\n\t                    Entity(\n\t                        len(entities) + 1,\n\t                        label,\n\t                        match.group(),\n", "                        Location(*match.span())\n\t                    )\n\t                )\n\t        if len(entities) == 0:\n\t            return []\n\t        ## sort descending\n\t        all_found_entities = sorted(\n\t            entities,\n\t            key=lambda entity: (entity.end, -entity.start),\n\t            reverse=True\n", "        )\n\t        slim_entities = [\n\t            all_found_entities[0]\n\t        ]\n\t        for curr_entity in all_found_entities[1:]:\n\t            if curr_entity.is_in(slim_entities[-1]):\n\t                continue\n\t            slim_entities.append(curr_entity)\n\t        return slim_entities\n"]}
{"filename": "src/extr/entities/linkers.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import Dict, List\n\tfrom ..models import Entity\n\tclass AbstractEntityLinker(ABC):\n\t    def __init__(self, attribute_label: str) -> None:\n\t        self._attribute_label = attribute_label\n\t    @property\n\t    def attribute_label(self) -> str:\n\t        return self._attribute_label\n\t    @abstractmethod\n", "    def link(self, entities: List[Entity]) -> List[Entity]:\n\t        pass\n\tclass KnowledgeBaseEntityLinker(AbstractEntityLinker):\n\t    def __init__(self, attribute_label: str, kb: Dict[str, str]) -> None:\n\t        super().__init__(attribute_label)\n\t        self._kb = kb\n\t    def link(self, entities: List[Entity]) -> List[Entity]:\n\t        for entity in entities:\n\t            key = entity.text\n\t            if key in self._kb:\n", "                entity.add_attribute(self._attribute_label, self._kb[key])\n\t        return entities\n"]}
{"filename": "src/extr/entities/viewers/__init__.py", "chunked_list": ["from .html import HtmlViewer\n"]}
{"filename": "src/extr/entities/viewers/html.py", "chunked_list": ["from typing import List, Optional\n\tfrom ...models import Entity\n\tfrom ..annotator import HtmlEntityAnnotator\n\t__TEMPLATE__ = \"\"\"\n\t<html>\n\t    <head>\n\t        <style>\n\t{{styles}}\n\t        </style>\n\t    </head>\n", "    <body>\n\t{{body}}\n\t    </body>\n\t</html>\n\t    \"\"\"\n\tclass HtmlViewer:\n\t    __TEMPLATE = __TEMPLATE__\n\t    __DEFAULT_STYLES = \"\"\"\n\tp { margin: 5px; line-height: 45px; }\n\tspan.entity { border: 1px solid black; border-radius: 5px; padding: 5px; margin: 3px; cursor: pointer; }\n", "span.label { font-weight: bold; padding: 3px; color: black; }\n\t\"\"\"\n\t    def __init__(self, annotations: Optional[List[str]] = None) -> None:\n\t        self._rows: List[str] = annotations if annotations is not None else []\n\t        self._annotator = HtmlEntityAnnotator()\n\t    def append(self, text: str, entities: List[Entity]) -> None:\n\t        self._rows.append(\n\t            self._annotator.annotate(text, entities)\n\t        )\n\t    def create_view(self, custom_styles: Optional[str] = None, spacer='<hr />') -> str:\n", "        styles = self.__DEFAULT_STYLES.strip()\n\t        if custom_styles:\n\t            styles += f'\\n{custom_styles.strip()}'\n\t        format_annoations = (f'<p>{annotation}</p>' for annotation in self._rows)\n\t        body = f'{spacer}\\n'.join(format_annoations)\n\t        return self.__TEMPLATE \\\n\t            .replace('{{styles}}', styles) \\\n\t            .replace('{{body}}', body) \\\n\t            .strip()\n"]}
