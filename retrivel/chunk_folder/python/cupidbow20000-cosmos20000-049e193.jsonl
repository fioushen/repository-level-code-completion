{"filename": "setup.py", "chunked_list": ["import os\n\tfrom setuptools import find_packages, setup\n\tdef read(fname):\n\t    return open(os.path.join(os.path.dirname(__file__), fname)).read()\n\tlong_description = read('README.md') if os.path.isfile(\"README.md\") else \"\"\n\tsetup(\n\t    name='cosmos-etl',\n\t    version='0.0.2',\n\t    author='Bisola Olasehinde',\n\t    author_email='horlasehinde@gmail.com',\n", "    description='Tools for exporting Cosmos blockchain data to CSV or JSON',\n\t    long_description=long_description,\n\t    long_description_content_type='text/markdown',\n\t    url='https://github.com/bizzyvinci/cosmos-etl',\n\t    packages=find_packages(),\n\t    classifiers=[\n\t        'Development Status :: 4 - Beta',\n\t        'Intended Audience :: Developers',\n\t        'License :: OSI Approved :: MIT License',\n\t        'Programming Language :: Python :: 3',\n", "        'Programming Language :: Python :: 3.7',\n\t        'Programming Language :: Python :: 3.8',\n\t        'Programming Language :: Python :: 3.9'\n\t    ],\n\t    keywords=['cosmos', 'tendermint'],\n\t    python_requires='>=3.7.2,<4',\n\t    install_requires=[\n\t        'blockchain-etl-common',\n\t        'web3>=5.29,<6'\n\t    ],\n", "    entry_points={\n\t        'console_scripts': [\n\t            'cosmosetl=cosmosetl.cli:cli',\n\t        ],\n\t    },\n\t    project_urls={\n\t        'Bug Reports': 'https://github.com/bizzyvinci/cosmos-etl/issues',\n\t        'Source': 'https://github.com/bizzyvinci/cosmos-etl',\n\t    },\n\t)\n"]}
{"filename": "cosmosetl/json_rpc_requests.py", "chunked_list": ["from cosmosetl.utils import MAX_PER_PAGE\n\tdef generate_json_rpc(method, params, request_id=1):\n\t    return {\n\t        'jsonrpc': '2.0',\n\t        'method': method,\n\t        'params': params,\n\t        'id': request_id,\n\t    }\n\tdef generate_get_block_by_number_json_rpc(block_numbers):\n\t    for idx, block_number in enumerate(block_numbers):\n", "        yield generate_json_rpc(\n\t            method='block',\n\t            params=[str(block_number)],\n\t            request_id=idx\n\t        )\n\tdef generate_tx_search_by_height_json_rpc(heights, page=1, per_page=MAX_PER_PAGE):\n\t    for idx, height in enumerate(heights):\n\t        yield generate_json_rpc(\n\t            method='tx_search',\n\t            params=[\"tx.height=%d\" % height, True, str(page), str(per_page), \"asc\"],\n", "            request_id=idx\n\t        )\n"]}
{"filename": "cosmosetl/__main__.py", "chunked_list": ["from cosmosetl.cli import cli\n\tcli()\n"]}
{"filename": "cosmosetl/__init__.py", "chunked_list": []}
{"filename": "cosmosetl/utils.py", "chunked_list": ["import base64\n\timport itertools\n\timport re\n\tfrom datetime import datetime\n\tMAX_PER_PAGE = 100\n\tdef str_to_dec(num_string):\n\t    if num_string is None:\n\t        return None\n\t    try:\n\t        return int(num_string)\n", "    except ValueError:\n\t        print(\"Not a num string %s\" % num_string)\n\t        return num_string\n\tdef block_time_to_timestamp(time):\n\t    \"\"\"Convert block time to timestamp\n\t    param time: str e.g block.time\n\t    \"\"\"\n\t    # Had to use re.match because\n\t    # 1. The precision is in nanoseconds so we pick 6 digits and leave 3 out\n\t    # 2. But the genesis block time precision is seconds\n", "    # Added timezone Z because all the sample network have seen are in Z timezone\n\t    time = re.match('\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.?\\d{0,6}', time)\n\t    time = time.group(0)\n\t    format = \"%Y-%m-%dT%H:%M:%S%z\" if len(time) == 19 else \"%Y-%m-%dT%H:%M:%S.%f%z\"\n\t    return str_to_timestamp(time+'Z', format)\n\tdef str_to_timestamp(date_string, format=\"%Y-%m-%dT%H:%M:%S.%f%z\"):\n\t    if date_string is None:\n\t        return None\n\t    try:\n\t        return datetime.strptime(date_string, format).timestamp()\n", "    except ValueError:\n\t        print(\"Date string (%s) or format (%s) is incorrect\" % (date_string, format))\n\t        return date_string\n\tdef b64decode(input_string, encoding='utf-8'):\n\t    if input_string is None:\n\t        return None\n\t    try:\n\t        return base64.b64decode(input_string).decode(encoding)\n\t    except Exception:\n\t        print(\"b64 decoding failed %s\" % input_string)\n", "        return input_string\n\tdef validate_range(range_start_incl, range_end_incl):\n\t    if range_start_incl < 0 or range_end_incl < 0:\n\t        raise ValueError('range_start and range_end must be greater or equal to 0')\n\t    if range_end_incl < range_start_incl:\n\t        raise ValueError('range_end must be greater or equal to range_start')\n\tdef rpc_response_to_result(response):\n\t    result = response.get('result')\n\t    if result is None:\n\t        error_message = 'result is None in response {}.'.format(response)\n", "        # Make better error messages\n\t        raise ValueError(error_message)\n\t    return result\n\tdef rpc_response_batch_to_results(response):\n\t    # Sometimes response is dict instead of list\n\t    if isinstance(response, dict):\n\t        yield rpc_response_to_result(response)\n\t    else:\n\t        for response_item in response:\n\t            yield rpc_response_to_result(response_item)\n", "def pairwise(iterable):\n\t    \"\"\"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n\t    a, b = itertools.tee(iterable)\n\t    next(b, None)\n\t    return zip(a, b)\n"]}
{"filename": "cosmosetl/get_block.py", "chunked_list": ["import re\n\tfrom cosmosetl.mappers.block_mapper import CosmBlockMapper\n\tfrom cosmosetl.utils import rpc_response_to_result\n\tdef get_block(web3, height=None):\n\t    # height==None would return latest block\n\t    if height is not None and not isinstance(height, str):\n\t        height = str(height)\n\t    response = web3.make_request('block', [height])\n\t    result = rpc_response_to_result(response)\n\t    return CosmBlockMapper().json_dict_to_block(result)\n", "def get_genesis_block(web3):\n\t    response = web3.make_request('block', ['1'])\n\t    if 'error' in response:\n\t        search = re.search('lowest height is (\\d+)', response['error']['data'])\n\t        if search is not None:\n\t            genesis_height = search.group(1)\n\t            response = web3.make_request('block', [genesis_height])\n\t    result = rpc_response_to_result(response)\n\t    return CosmBlockMapper().json_dict_to_block(result)\n\tdef get_latest_block(web3):\n", "    return get_block(web3, None)\n"]}
{"filename": "cosmosetl/thread_local_proxy.py", "chunked_list": ["import threading\n\tclass ThreadLocalProxy:\n\t    def __init__(self, delegate_factory):\n\t        self._thread_local = threading.local()\n\t        self._delegate_factory = delegate_factory\n\t    def __getattr__(self, name):\n\t        return getattr(self._get_thread_local_delegate(), name)\n\t    def _get_thread_local_delegate(self):\n\t        if getattr(self._thread_local, '_delegate', None) is None:\n\t            self._thread_local._delegate = self._delegate_factory()\n", "        return self._thread_local._delegate\n"]}
{"filename": "cosmosetl/cli/export_transactions_and_events.py", "chunked_list": ["import click\n\tfrom blockchainetl_common.logging_utils import logging_basic_config\n\tfrom cosmosetl.jobs.export_transactions_job import ExportTransactionsJob\n\tfrom cosmosetl.jobs.exporters.transactions_and_events_item_exporter import transactions_and_events_item_exporter\n\tfrom cosmosetl.providers.auto import get_provider_from_uri\n\tfrom cosmosetl.thread_local_proxy import ThreadLocalProxy\n\tlogging_basic_config()\n\t@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n\t@click.option('-s', '--start-block', default=0, show_default=True, type=int, help='Start block')\n\t@click.option('-e', '--end-block', required=True, type=int, help='End block')\n", "@click.option('-b', '--batch-size', default=100, show_default=True, type=int, help='The number of blocks to export at a time.')\n\t@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n\t@click.option('-w', '--max-workers', default=5, show_default=True, type=int, help='The maximum number of workers.')\n\t@click.option('-to', '--transactions-output', default=None, show_default=True, type=str, help='Output file for transactions (ending with .csv or .json)')\n\t@click.option('-eo', '--events-output', default=None, show_default=True, type=str, help='Output file for events (ending with .csv or .json)')\n\tdef export_transactions_and_events(start_block, end_block, batch_size, provider_uri, max_workers, transactions_output, events_output):\n\t    job = ExportTransactionsJob(\n\t        start_block=start_block,\n\t        end_block=end_block,\n\t        batch_size=batch_size,\n", "        batch_web3_provider=ThreadLocalProxy(lambda: get_provider_from_uri(provider_uri, batch=True)),\n\t        max_workers=max_workers,\n\t        item_exporter=transactions_and_events_item_exporter(transactions_output, events_output),\n\t        export_transactions=transactions_output is not None,\n\t        export_events=events_output is not None\n\t    )\n\t    job.run()\n"]}
{"filename": "cosmosetl/cli/get_block_range_for_date.py", "chunked_list": ["import click\n\tfrom datetime import datetime\n\tfrom blockchainetl_common.file_utils import smart_open\n\tfrom blockchainetl_common.logging_utils import logging_basic_config\n\tfrom cosmosetl.providers.auto import get_provider_from_uri\n\tfrom cosmosetl.service.cosm_service import CosmService\n\tlogging_basic_config()\n\t@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n\t@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n\t@click.option('-d', '--date', required=True, type=lambda d: datetime.strptime(d, '%Y-%m-%d'),\n", "              help='The date YYYY-MM-DD e.g. 2022-02-22.')\n\t@click.option('-o', '--output', default='-', show_default=True, type=str, help='The output file. If not specified stdout is used.')\n\tdef get_block_range_for_date(provider_uri, date, output):\n\t    \"\"\"Outputs start and end blocks for given date.\"\"\"\n\t    provider = get_provider_from_uri(provider_uri)\n\t    cosm_service = CosmService(provider)\n\t    start_block, end_block = cosm_service.get_block_range_for_date(date)\n\t    with smart_open(output, 'w') as output_file:\n\t        output_file.write('{},{}\\n'.format(start_block, end_block))\n"]}
{"filename": "cosmosetl/cli/export_blocks.py", "chunked_list": ["from email.policy import default\n\timport click\n\tfrom blockchainetl_common.logging_utils import logging_basic_config\n\tfrom cosmosetl.jobs.export_blocks_job import ExportBlocksJob\n\tfrom cosmosetl.jobs.exporters.blocks_item_exporter import blocks_item_exporter\n\tfrom cosmosetl.providers.auto import get_provider_from_uri\n\tfrom cosmosetl.thread_local_proxy import ThreadLocalProxy\n\tlogging_basic_config()\n\t@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n\t@click.option('-s', '--start-block', default=0, show_default=True, type=int, help='Start block')\n", "@click.option('-e', '--end-block', required=True, type=int, help='End block')\n\t@click.option('-b', '--batch-size', default=100, show_default=True, type=int, help='The number of blocks to export at a time.')\n\t@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n\t@click.option('-w', '--max-workers', default=5, show_default=True, type=int, help='The maximum number of workers.')\n\t@click.option('-o', '--output', required=True, type=str, help='Output file for blocks (ending with .csv or .json)')\n\tdef export_blocks(start_block, end_block, batch_size, provider_uri, max_workers, output):\n\t    job = ExportBlocksJob(\n\t        start_block=start_block,\n\t        end_block=end_block,\n\t        batch_size=batch_size,\n", "        batch_web3_provider=ThreadLocalProxy(lambda: get_provider_from_uri(provider_uri, batch=True)),\n\t        max_workers=max_workers,\n\t        item_exporter=blocks_item_exporter(output)\n\t    )\n\t    job.run()\n"]}
{"filename": "cosmosetl/cli/__init__.py", "chunked_list": ["from blockchainetl_common.logging_utils import logging_basic_config\n\tlogging_basic_config()\n\timport click\n\tfrom cosmosetl.cli.export_blocks import export_blocks\n\tfrom cosmosetl.cli.export_transactions_and_events import export_transactions_and_events\n\tfrom cosmosetl.cli.get_block_range_for_date import get_block_range_for_date\n\tfrom cosmosetl.cli.get_block_range_for_timestamps import get_block_range_for_timestamps\n\t@click.group()\n\t@click.version_option(version='0.0.2')\n\t@click.pass_context\n", "def cli(ctx):\n\t    pass\n\t# export\n\tcli.add_command(export_blocks, \"export_blocks\")\n\tcli.add_command(export_transactions_and_events, \"export_transactions_and_events\")\n\tcli.add_command(get_block_range_for_date, \"get_block_range_for_date\")\n\tcli.add_command(get_block_range_for_timestamps, \"get_block_range_for_timestamps\")\n"]}
{"filename": "cosmosetl/cli/get_block_range_for_timestamps.py", "chunked_list": ["import click\n\tfrom datetime import datetime\n\tfrom blockchainetl_common.file_utils import smart_open\n\tfrom blockchainetl_common.logging_utils import logging_basic_config\n\tfrom cosmosetl.providers.auto import get_provider_from_uri\n\tfrom cosmosetl.service.cosm_service import CosmService\n\tlogging_basic_config()\n\t@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n\t@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n\t@click.option('-s', '--start-timestamp', required=True, type=int, help='Start unix timestamp, in seconds.')\n", "@click.option('-e', '--end-timestamp', required=True, type=int, help='End unix timestamp, in seconds.')\n\t@click.option('-o', '--output', default='-', show_default=True, type=str, help='The output file. If not specified stdout is used.')\n\tdef get_block_range_for_timestamps(provider_uri, start_timestamp, end_timestamp, output):\n\t    \"\"\"Outputs start and end blocks for given date.\"\"\"\n\t    provider = get_provider_from_uri(provider_uri)\n\t    cosm_service = CosmService(provider)\n\t    start_block, end_block = cosm_service.get_block_range_for_timestamps(start_timestamp, end_timestamp)\n\t    with smart_open(output, 'w') as output_file:\n\t        output_file.write('{},{}\\n'.format(start_block, end_block))\n"]}
{"filename": "cosmosetl/domain/block.py", "chunked_list": ["class CosmBlock:\n\t    def __init__(self):\n\t        self.height = None\n\t        self.hash = None\n\t        self.last_block_hash = None\n\t        self.data_hash = None\n\t        self.proposer = None\n\t        self.num_txs = None\n\t        self.time = None\n"]}
{"filename": "cosmosetl/domain/__init__.py", "chunked_list": []}
{"filename": "cosmosetl/domain/transaction.py", "chunked_list": ["class CosmTransaction:\n\t    def __init__(self):\n\t        self.hash = None\n\t        self.height = None\n\t        self.index = None\n\t        self.code = None\n\t        self.gas_used = None\n\t        self.gas_wanted = None\n\t        self.num_events = None\n\t        self.root_hash = None\n", "        self.tx = None\n\t        self.data = None\n\t        self.raw_data = None\n\t        self.raw_log = None\n\t        self.events = []\n"]}
{"filename": "cosmosetl/domain/event.py", "chunked_list": ["class CosmEvent:\n\t    def __init__(self):\n\t        self._type = None\n\t        self.attributes = None\n\t        self.tx_hash = None\n"]}
{"filename": "cosmosetl/providers/ipc.py", "chunked_list": ["import json\n\timport socket\n\tfrom web3.providers.ipc import IPCProvider\n\tfrom web3._utils.threads import (\n\t    Timeout,\n\t)\n\ttry:\n\t    from json import JSONDecodeError\n\texcept ImportError:\n\t    JSONDecodeError = ValueError\n", "# Mostly copied from web3.py/providers/ipc.py. Supports batch requests.\n\t# Will be removed once batch feature is added to web3.py https://github.com/ethereum/web3.py/issues/832\n\t# Also see this optimization https://github.com/ethereum/web3.py/pull/849\n\tclass BatchIPCProvider(IPCProvider):\n\t    _socket = None\n\t    def make_batch_request(self, text):\n\t        request = text.encode('utf-8')\n\t        with self._lock, self._socket as sock:\n\t            try:\n\t                sock.sendall(request)\n", "            except BrokenPipeError:\n\t                # one extra attempt, then give up\n\t                sock = self._socket.reset()\n\t                sock.sendall(request)\n\t            raw_response = b\"\"\n\t            with Timeout(self.timeout) as timeout:\n\t                while True:\n\t                    try:\n\t                        raw_response += sock.recv(4096)\n\t                    except socket.timeout:\n", "                        timeout.sleep(0)\n\t                        continue\n\t                    if raw_response == b\"\":\n\t                        timeout.sleep(0)\n\t                    elif has_valid_json_rpc_ending(raw_response):\n\t                        try:\n\t                            response = json.loads(raw_response.decode('utf-8'))\n\t                        except JSONDecodeError:\n\t                            timeout.sleep(0)\n\t                            continue\n", "                        else:\n\t                            return response\n\t                    else:\n\t                        timeout.sleep(0)\n\t                        continue\n\t# A valid JSON RPC response can only end in } or ] http://www.jsonrpc.org/specification\n\tdef has_valid_json_rpc_ending(raw_response):\n\t    for valid_ending in [b\"}\\n\", b\"]\\n\"]:\n\t        if raw_response.endswith(valid_ending):\n\t            return True\n", "    else:\n\t        return False\n"]}
{"filename": "cosmosetl/providers/auto.py", "chunked_list": ["from urllib.parse import urlparse\n\tfrom web3 import IPCProvider, HTTPProvider\n\tfrom cosmosetl.providers.ipc import BatchIPCProvider\n\tfrom cosmosetl.providers.rpc import BatchHTTPProvider\n\tDEFAULT_TIMEOUT = 60\n\tdef get_provider_from_uri(uri_string, timeout=DEFAULT_TIMEOUT, batch=False):\n\t    uri = urlparse(uri_string)\n\t    if uri.scheme == 'file':\n\t        if batch:\n\t            return BatchIPCProvider(uri.path, timeout=timeout)\n", "        else:\n\t            return IPCProvider(uri.path, timeout=timeout)\n\t    elif uri.scheme == 'http' or uri.scheme == 'https':\n\t        request_kwargs = {'timeout': timeout}\n\t        if batch:\n\t            return BatchHTTPProvider(uri_string, request_kwargs=request_kwargs)\n\t        else:\n\t            return HTTPProvider(uri_string, request_kwargs=request_kwargs)\n\t    else:\n\t        raise ValueError('Unknown uri scheme {}'.format(uri_string))\n"]}
{"filename": "cosmosetl/providers/__init__.py", "chunked_list": []}
{"filename": "cosmosetl/providers/rpc.py", "chunked_list": ["from web3 import HTTPProvider\n\tfrom web3._utils.request import make_post_request\n\t# Mostly copied from web3.py/providers/rpc.py. Supports batch requests.\n\t# Will be removed once batch feature is added to web3.py https://github.com/ethereum/web3.py/issues/832\n\tclass BatchHTTPProvider(HTTPProvider):\n\t    def make_batch_request(self, text):\n\t        self.logger.debug(\"Making request HTTP. URI: %s, Request: %s\",\n\t                          self.endpoint_uri, text)\n\t        request_data = text.encode('utf-8')\n\t        raw_response = make_post_request(\n", "            self.endpoint_uri,\n\t            request_data,\n\t            **self.get_request_kwargs()\n\t        )\n\t        response = self.decode_rpc_response(raw_response)\n\t        self.logger.debug(\"Getting response HTTP. URI: %s, \"\n\t                          \"Request: %s, Response: %s\",\n\t                          self.endpoint_uri, text, response)\n\t        return response\n"]}
{"filename": "cosmosetl/mappers/__init__.py", "chunked_list": []}
{"filename": "cosmosetl/mappers/event_mapper.py", "chunked_list": ["import json\n\tfrom cosmosetl.domain.event import CosmEvent\n\tfrom cosmosetl.utils import b64decode\n\tclass CosmEventMapper:\n\t    def json_dict_to_event(self, json_dict, tx_hash=None):\n\t        event = CosmEvent()\n\t        event._type = json_dict.get(\"type\")\n\t        attributes = json.dumps([\n\t            {'key': b64decode(attr.get('key')), 'value': b64decode(attr.get('value'))}\n\t            for attr in json_dict.get(\"attributes\", [])\n", "        ])\n\t        event.attributes = attributes if attributes else None\n\t        event.tx_hash = tx_hash\n\t        return event\n\t    def event_to_dict(self, event):\n\t        return {\n\t            \"type\": \"event\",\n\t            \"_type\": event._type,\n\t            \"attributes\": event.attributes,\n\t            \"tx_hash\": event.tx_hash\n", "        }\n"]}
{"filename": "cosmosetl/mappers/transaction_mapper.py", "chunked_list": ["from asyncio import events\n\timport json\n\tfrom cosmosetl.domain.transaction import CosmTransaction\n\tfrom cosmosetl.mappers.event_mapper import CosmEventMapper\n\tfrom cosmosetl.utils import str_to_dec, b64decode\n\tclass CosmTransactionMapper:\n\t    def __init__(self):\n\t        self.event_mapper = CosmEventMapper()\n\t    def json_dict_to_transaction(self, json_dict):\n\t        transaction = CosmTransaction()\n", "        transaction.hash = json_dict.get(\"hash\")\n\t        transaction.height = str_to_dec(json_dict.get(\"height\"))\n\t        transaction.index = json_dict.get(\"index\")\n\t        transaction.code = json_dict.get(\"tx_result\", {}).get(\"code\")\n\t        transaction.gas_used = json_dict.get(\"tx_result\", {}).get(\"gas_used\")\n\t        transaction.gas_wanted = json_dict.get(\"tx_result\", {}).get(\"gas_wanted\")\n\t        transaction.num_events = len(json_dict.get(\"tx_result\", {}).get(\"events\", []))\n\t        transaction.root_hash = json_dict.get(\"proof\", {}).get(\"root_hash\")\n\t        transaction.tx = json_dict.get(\"tx\")\n\t        # simple b64decoding doesn't work for data\n", "        # transaction.data = b64decode(json_dict.get(\"tx_result\", {}).get(\"data\"))\n\t        transaction.raw_data = json_dict.get(\"tx_result\", {}).get(\"data\")\n\t        transaction.raw_log = json_dict.get(\"tx_result\", {}).get(\"log\")\n\t        transaction.events = [\n\t            self.event_mapper.json_dict_to_event(evt, tx_hash=transaction.hash)\n\t            for evt in json_dict.get('tx_result', {}).get('events', [])\n\t        ]\n\t        return transaction\n\t    def transaction_to_dict(self, transaction):\n\t        return {\n", "            \"type\": \"transaction\",\n\t            \"hash\": transaction.hash,\n\t            \"height\": transaction.height,\n\t            \"index\": transaction.index,\n\t            \"code\": transaction.code,\n\t            \"gas_used\": transaction.gas_used,\n\t            \"gas_wanted\": transaction.gas_wanted,\n\t            \"num_events\": transaction.num_events,\n\t            \"root_hash\": transaction.root_hash,\n\t            \"tx\": transaction.tx,\n", "            \"data\": transaction.data,\n\t            \"raw_data\": transaction.raw_data,\n\t            \"raw_log\": transaction.raw_log,\n\t        }\n"]}
{"filename": "cosmosetl/mappers/block_mapper.py", "chunked_list": ["from cosmosetl.domain.block import CosmBlock\n\tfrom cosmosetl.utils import str_to_dec\n\tclass CosmBlockMapper:\n\t    def json_dict_to_block(self, json_dict):\n\t        block = CosmBlock()\n\t        block.height = str_to_dec(json_dict['block']['header'].get('height'))\n\t        block.hash = json_dict['block_id'].get('hash')\n\t        block.last_block_hash = json_dict['block']['header'].get('last_block_id', {}).get('hash')\n\t        block.data_hash = json_dict['block']['header'].get('data_hash')\n\t        block.proposer = json_dict['block']['header'].get('proposer_address')\n", "        block.num_txs = len(json_dict['block']['data'].get('txs', []))\n\t        block.time = json_dict['block']['header'].get('time')\n\t        return block\n\t    def block_to_dict(self, block):\n\t        return {\n\t            'type': 'block',\n\t            'height': block.height,\n\t            'hash': block.hash,\n\t            'last_block_hash': block.last_block_hash,\n\t            'data_hash': block.data_hash,\n", "            'proposer': block.proposer,\n\t            'num_txs': block.num_txs,\n\t            'time': block.time,\n\t        }"]}
{"filename": "cosmosetl/jobs/export_blocks_job.py", "chunked_list": ["import json\n\tfrom blockchainetl_common.jobs.base_job import BaseJob\n\tfrom blockchainetl_common.executors.batch_work_executor import BatchWorkExecutor\n\tfrom cosmosetl.mappers.block_mapper import CosmBlockMapper\n\tfrom cosmosetl.json_rpc_requests import generate_get_block_by_number_json_rpc\n\tfrom cosmosetl.utils import validate_range, rpc_response_batch_to_results\n\tclass ExportBlocksJob(BaseJob):\n\t    def __init__(self, start_block, end_block, batch_size, batch_web3_provider,\n\t                max_workers, item_exporter):\n\t        validate_range(start_block, end_block)\n", "        self.start_block = start_block\n\t        self.end_block = end_block\n\t        self.batch_web3_provider = batch_web3_provider\n\t        self.batch_work_executor = BatchWorkExecutor(batch_size, max_workers)\n\t        self.item_exporter = item_exporter\n\t        self.block_mapper = CosmBlockMapper()\n\t    def _start(self):\n\t        self.item_exporter.open()\n\t    def _export(self):\n\t        self.batch_work_executor.execute(\n", "            range(self.start_block, self.end_block + 1),\n\t            self._export_batch,\n\t            total_items=self.end_block - self.start_block + 1\n\t        )\n\t    def _export_batch(self, block_number_batch):\n\t        blocks_rpc = list(generate_get_block_by_number_json_rpc(block_number_batch))\n\t        response = self.batch_web3_provider.make_batch_request(json.dumps(blocks_rpc))\n\t        results = rpc_response_batch_to_results(response)\n\t        blocks = [self.block_mapper.json_dict_to_block(result) for result in results]\n\t        for block in blocks:\n", "            self._export_block(block)\n\t    def _export_block(self, block):\n\t        self.item_exporter.export_item(self.block_mapper.block_to_dict(block))\n\t    def _end(self):\n\t        self.batch_work_executor.shutdown()\n\t        self.item_exporter.close()\n"]}
{"filename": "cosmosetl/jobs/__init__.py", "chunked_list": []}
{"filename": "cosmosetl/jobs/export_transactions_job.py", "chunked_list": ["import json\n\tfrom blockchainetl_common.jobs.base_job import BaseJob\n\tfrom blockchainetl_common.executors.batch_work_executor import BatchWorkExecutor\n\tfrom cosmosetl.mappers.event_mapper import CosmEventMapper\n\tfrom cosmosetl.mappers.transaction_mapper import CosmTransactionMapper\n\tfrom cosmosetl.json_rpc_requests import generate_tx_search_by_height_json_rpc\n\tfrom cosmosetl.utils import MAX_PER_PAGE, validate_range, rpc_response_batch_to_results\n\tclass ExportTransactionsJob(BaseJob):\n\t    def __init__(self, start_block, end_block, batch_size, batch_web3_provider, max_workers, item_exporter,\n\t                export_transactions=True, export_events=True):\n", "        validate_range(start_block, end_block)\n\t        self.start_block = start_block\n\t        self.end_block = end_block\n\t        self.batch_web3_provider = batch_web3_provider\n\t        self.batch_work_executor = BatchWorkExecutor(batch_size, max_workers)\n\t        self.item_exporter = item_exporter\n\t        self.transaction_mapper = CosmTransactionMapper()\n\t        self.event_mapper = CosmEventMapper()\n\t        self.export_transactions = export_transactions\n\t        self.export_events = export_events\n", "    def _start(self):\n\t        self.item_exporter.open()\n\t    def _export(self):\n\t        self.batch_work_executor.execute(\n\t            range(self.start_block, self.end_block + 1),\n\t            self._export_batch,\n\t            total_items=self.end_block - self.start_block + 1\n\t        )\n\t    def _export_batch(self, block_number_batch, page=1):\n\t        requests = list(generate_tx_search_by_height_json_rpc(block_number_batch, page))\n", "        response = self.batch_web3_provider.make_batch_request(json.dumps(requests))\n\t        results = rpc_response_batch_to_results(response)\n\t        next_block_number_batch = []\n\t        for block in results:\n\t            self._export_block(block)\n\t            if int(block.get('total_count', 0)) > page * MAX_PER_PAGE:\n\t                next_block_number_batch.append(block)\n\t        if next_block_number_batch:\n\t            self._export_batch(next_block_number_batch, page+1)\n\t    def _export_block(self, block):\n", "        for tx in block.get('txs', []):\n\t            transaction = self.transaction_mapper.json_dict_to_transaction(tx)\n\t            self._export_transaction(transaction)\n\t    def _export_transaction(self, transaction):\n\t        if self.export_transactions:\n\t            self.item_exporter.export_item(self.transaction_mapper.transaction_to_dict(transaction))\n\t        if self.export_events:\n\t            for evt in transaction.events:\n\t                self.item_exporter.export_item(self.event_mapper.event_to_dict(evt))\n\t    def _end(self):\n", "        self.batch_work_executor.shutdown()\n\t        self.item_exporter.close()\n"]}
{"filename": "cosmosetl/jobs/exporters/transactions_and_events_item_exporter.py", "chunked_list": ["from blockchainetl_common.jobs.exporters.composite_item_exporter import CompositeItemExporter\n\tTRANSACTION_FIELDS_TO_EXPORT = [\n\t    'hash',\n\t    'height',\n\t    'index',\n\t    'code',\n\t    'gas_used',\n\t    'gas_wanted',\n\t    'num_events',\n\t    'root_hash',\n", "    'tx',\n\t    'data',\n\t    'raw_data',\n\t    'raw_log',\n\t]\n\tEVENT_FIELDS_TO_EXPORT = [\n\t    '_type',\n\t    'attributes',\n\t    'tx_hash'\n\t]\n", "def transactions_and_events_item_exporter(transactions_output=None, events_output=None):\n\t    return CompositeItemExporter(\n\t        filename_mapping={\n\t            'transaction': transactions_output,\n\t            'event': events_output\n\t        },\n\t        field_mapping={\n\t            'transaction': TRANSACTION_FIELDS_TO_EXPORT,\n\t            'event': EVENT_FIELDS_TO_EXPORT\n\t        }\n", "    )"]}
{"filename": "cosmosetl/jobs/exporters/__init__.py", "chunked_list": []}
{"filename": "cosmosetl/jobs/exporters/blocks_item_exporter.py", "chunked_list": ["from blockchainetl_common.jobs.exporters.composite_item_exporter import CompositeItemExporter\n\tBLOCK_FIELDS_TO_EXPORT = [\n\t    'height',\n\t    'hash',\n\t    'last_block_hash',\n\t    'data_hash',\n\t    'proposer',\n\t    'num_txs',\n\t    'time'\n\t]\n", "def blocks_item_exporter(blocks_output):\n\t    return CompositeItemExporter(\n\t        filename_mapping={\n\t            'block': blocks_output\n\t        },\n\t        field_mapping={\n\t            'block': BLOCK_FIELDS_TO_EXPORT\n\t        }\n\t    )\n"]}
{"filename": "cosmosetl/service/__init__.py", "chunked_list": []}
{"filename": "cosmosetl/service/cosm_service.py", "chunked_list": ["from datetime import datetime, timezone\n\tfrom cosmosetl.service.graph_operations import GraphOperations, OutOfBoundsError, Point\n\tfrom cosmosetl.utils import  block_time_to_timestamp\n\tfrom cosmosetl.get_block import get_block, get_genesis_block, get_latest_block\n\tclass CosmService(object):\n\t    def __init__(self, web3):\n\t        graph = BlockTimestampGraph(web3)\n\t        self._graph_operations = GraphOperations(graph)\n\t    def get_block_range_for_date(self, date):\n\t        start_datetime = datetime.combine(date, datetime.min.time().replace(tzinfo=timezone.utc))\n", "        end_datetime = datetime.combine(date, datetime.max.time().replace(tzinfo=timezone.utc))\n\t        return self.get_block_range_for_timestamps(start_datetime.timestamp(), end_datetime.timestamp())\n\t    def get_block_range_for_timestamps(self, start_timestamp, end_timestamp):\n\t        start_timestamp = int(start_timestamp)\n\t        end_timestamp = int(end_timestamp)\n\t        if start_timestamp > end_timestamp:\n\t            raise ValueError('start_timestamp must be greater or equal to end_timestamp')\n\t        try:\n\t            start_block_bounds = self._graph_operations.get_bounds_for_y_coordinate(start_timestamp)\n\t        except OutOfBoundsError:\n", "            start_block_bounds = (0, 0)\n\t        try:\n\t            end_block_bounds = self._graph_operations.get_bounds_for_y_coordinate(end_timestamp)\n\t        except OutOfBoundsError as e:\n\t            raise OutOfBoundsError('The existing blocks do not completely cover the given time range') from e\n\t        if start_block_bounds == end_block_bounds and start_block_bounds[0] != start_block_bounds[1]:\n\t            raise ValueError('The given timestamp range does not cover any blocks')\n\t        start_block = start_block_bounds[1]\n\t        end_block = end_block_bounds[0]\n\t        # The genesis block has timestamp 0 but we include it with the 1st block.\n", "        if start_block == 1:\n\t            start_block = 0\n\t        return start_block, end_block\n\tclass BlockTimestampGraph(object):\n\t    def __init__(self, web3):\n\t        self._web3 = web3\n\t    def get_first_point(self):\n\t        return block_to_point(get_genesis_block(self._web3))\n\t    def get_last_point(self):\n\t        return block_to_point(get_latest_block(self._web3))\n", "    def get_point(self, x):\n\t        return block_to_point(get_block(self._web3, x))\n\tdef block_to_point(block):\n\t    return Point(block.height, block_time_to_timestamp(block.time))\n"]}
{"filename": "cosmosetl/service/graph_operations.py", "chunked_list": ["from cosmosetl.utils import pairwise\n\tclass GraphOperations(object):\n\t    def __init__(self, graph):\n\t        \"\"\"x axis on the graph must be integers, y value must increase strictly monotonically with increase of x\"\"\"\n\t        self._graph = graph\n\t        self._cached_points = []\n\t    def get_bounds_for_y_coordinate(self, y):\n\t        \"\"\"given the y coordinate, outputs a pair of x coordinates for closest points that bound the y coordinate.\n\t        Left and right bounds are equal in case given y is equal to one of the points y coordinate\"\"\"\n\t        initial_bounds = find_best_bounds(y, self._cached_points)\n", "        if initial_bounds is None:\n\t            initial_bounds = self._get_first_point(), self._get_last_point()\n\t        result = self._get_bounds_for_y_coordinate_recursive(y, *initial_bounds)\n\t        return result\n\t    def _get_bounds_for_y_coordinate_recursive(self, y, start, end):\n\t        if y < start.y or y > end.y:\n\t            raise OutOfBoundsError('y coordinate {} is out of bounds for points {}-{}'.format(y, start, end))\n\t        if y == start.y:\n\t            return start.x, start.x\n\t        elif y == end.y:\n", "            return end.x, end.x\n\t        elif (end.x - start.x) <= 1:\n\t            return start.x, end.x\n\t        else:\n\t            assert start.y < y < end.y\n\t            if start.y >= end.y:\n\t                raise ValueError('y must increase strictly monotonically')\n\t            # Interpolation Search https://en.wikipedia.org/wiki/Interpolation_search, O(log(log(n)) average case.\n\t            # Improvements for worst case:\n\t            # Find the 1st estimation by linear interpolation from start and end points.\n", "            # If the 1st estimation is below the needed y coordinate (graph is concave),\n\t            # drop the next estimation by interpolating with the start and 1st estimation point\n\t            # (likely will be above the needed y).\n\t            # If 1st estimation is above the needed y coordinate (graph is convex),\n\t            # drop the next estimation by interpolating with the 1st estimation and end point\n\t            # (likely will be below the needed y).\n\t            estimation1_x = interpolate(start, end, y)\n\t            estimation1_x = bound(estimation1_x, (start.x, end.x))\n\t            estimation1 = self._get_point(estimation1_x)\n\t            if estimation1.y < y:\n", "                points = (start, estimation1)\n\t            else:\n\t                points = (estimation1, end)\n\t            estimation2_x = interpolate(*points, y)\n\t            estimation2_x = bound(estimation2_x, (start.x, end.x))\n\t            estimation2 = self._get_point(estimation2_x)\n\t            all_points = [start, estimation1, estimation2, end]\n\t            bounds = find_best_bounds(y, all_points)\n\t            if bounds is None:\n\t                raise ValueError('Unable to find bounds for points {} and y coordinate {}'.format(points, y))\n", "            return self._get_bounds_for_y_coordinate_recursive(y, *bounds)\n\t    def _get_point(self, x):\n\t        point = self._graph.get_point(x)\n\t        self._cached_points.append(point)\n\t        return point\n\t    def _get_first_point(self):\n\t        point = self._graph.get_first_point()\n\t        self._cached_points.append(point)\n\t        return point\n\t    def _get_last_point(self):\n", "        point = self._graph.get_last_point()\n\t        self._cached_points.append(point)\n\t        return point\n\tdef find_best_bounds(y, points):\n\t    sorted_points = sorted(points, key=lambda point: point.y)\n\t    for point1, point2 in pairwise(sorted_points):\n\t        if point1.y <= y <= point2.y:\n\t            return point1, point2\n\t    return None\n\tdef interpolate(point1, point2, y):\n", "    x1, y1 = point1.x, point1.y\n\t    x2, y2 = point2.x, point2.y\n\t    if y1 == y2:\n\t        raise ValueError('The y coordinate for points is the same {}, {}'.format(point1, point2))\n\t    x = int((y - y1) * (x2 - x1) / (y2 - y1) + x1)\n\t    return x\n\tdef bound(x, bounds):\n\t    x1, x2 = bounds\n\t    if x1 > x2:\n\t        x1, x2 = x2, x1\n", "    if x <= x1:\n\t        return x1 + 1\n\t    elif x >= x2:\n\t        return x2 - 1\n\t    else:\n\t        return x\n\tclass OutOfBoundsError(Exception):\n\t    pass\n\tclass Point(object):\n\t    def __init__(self, x, y):\n", "        self.x = x\n\t        self.y = y\n\t    def __str__(self):\n\t        return '({},{})'.format(self.x, self.y)\n\t    def __repr__(self):\n\t        return 'Point({},{})'.format(self.x, self.y)\n"]}
