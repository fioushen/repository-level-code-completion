{"filename": "setup.py", "chunked_list": ["\"\"\"A setuptools based setup module.\n\tSee:\n\thttps://packaging.python.org/guides/distributing-packages-using-setuptools/\n\thttps://github.com/pypa/sampleproject\n\t\"\"\"\n\t# Standard imports\n\timport pathlib\n\t# Third party imports\n\t# Always prefer setuptools over distutils\n\tfrom setuptools import find_packages, setup\n", "# Cellulose imports\n\tfrom cellulose.version import CELLULOSE_SDK_VERSION\n\there = pathlib.Path(__file__).parent.resolve()\n\t# Get the long description from the README file\n\tlong_description = (here / \"README.md\").read_text(encoding=\"utf-8\")\n\tkeywords_list = [\n\t    \"artificial intelligence\",\n\t    \"benchmarking\",\n\t    \"debugging\",\n\t    \"development\",\n", "    \"onnx\",\n\t    \"profiler\",\n\t    \"profiling\",\n\t    \"pytorch\",\n\t    \"tensorflow\",\n\t]\n\t# Arguments marked as \"Required\" below must be included for upload to PyPI.\n\t# Fields marked as \"Optional\" may be commented out.\n\tsetup(\n\t    # This is the name of your project. The first time you publish this\n", "    # package, this name will be registered for you. It will determine how\n\t    # users can install this project, e.g.:\n\t    #\n\t    # $ pip install cellulose-sdk\n\t    #\n\t    # And where it will live on PyPI: https://pypi.org/project/sampleproject/\n\t    #\n\t    # There are some restrictions on what makes a valid project name\n\t    # specification here:\n\t    # https://packaging.python.org/specifications/core-metadata/#name\n", "    name=\"cellulose-sdk\",  # Required\n\t    # Versions should comply with PEP 440:\n\t    # https://www.python.org/dev/peps/pep-0440/\n\t    #\n\t    # For a discussion on single-sourcing the version across setup.py and the\n\t    # project code, see\n\t    # https://packaging.python.org/guides/single-sourcing-package-version/\n\t    version=CELLULOSE_SDK_VERSION,  # Required\n\t    # This is a one-line description or tagline of what your project does. This\n\t    # corresponds to the \"Summary\" metadata field:\n", "    # https://packaging.python.org/specifications/core-metadata/#summary\n\t    description=\"Cellulose Python SDK\",  # Optional\n\t    # This is an optional longer description of your project that represents\n\t    # the body of text which users will see when they visit PyPI.\n\t    #\n\t    # Often, this is the same as your README, so you can just read it in from\n\t    # that file directly (as we have already done above)\n\t    #\n\t    # This field corresponds to the \"Description\" metadata field:\n\t    # https://packaging.python.org/specifications/core-metadata/#description-optional\n", "    long_description=long_description,  # Optional\n\t    # Denotes that our long_description is in Markdown; valid values are\n\t    # text/plain, text/x-rst, and text/markdown\n\t    #\n\t    # Optional if long_description is written in reStructuredText (rst) but\n\t    # required for plain-text or Markdown; if unspecified, \"applications should\n\t    # attempt to render [the long_description] as text/x-rst; charset=UTF-8 and\n\t    # fall back to text/plain if it is not valid rst\" (see link below)\n\t    #\n\t    # This field corresponds to the \"Description-Content-Type\" metadata field:\n", "    # https://packaging.python.org/specifications/core-metadata/#description-content-type-optional\n\t    long_description_content_type=\"text/markdown\",  # Optional (see note above)\n\t    # This should be a valid link to your project's main homepage.\n\t    #\n\t    # This field corresponds to the \"Home-Page\" metadata field:\n\t    # https://packaging.python.org/specifications/core-metadata/#home-page-optional\n\t    url=\"https://www.cellulose.ai\",  # Optional\n\t    # This should be your name or the name of the organization which owns the\n\t    # project.\n\t    author=\"Cellulose engineering team\",  # Optional\n", "    # This should be a valid email address corresponding to the author listed\n\t    # above.\n\t    author_email=\"zheng@cellulose.ai\",  # Optional\n\t    # Classifiers help users find your project by categorizing it.\n\t    #\n\t    # For a list of valid classifiers, see https://pypi.org/classifiers/\n\t    classifiers=[  # Optional\n\t        # How mature is this project? Common values are\n\t        #   3 - Alpha\n\t        #   4 - Beta\n", "        #   5 - Production/Stable\n\t        \"Development Status :: 3 - Alpha\",\n\t        # Indicate who your project is intended for\n\t        \"Intended Audience :: Developers\",\n\t        \"Intended Audience :: Science/Research\",\n\t        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n\t        \"Topic :: Software Development :: Build Tools\",\n\t        \"Topic :: Software Development :: Compilers\",\n\t        \"Topic :: Software Development :: Debuggers\",\n\t        # Pick your license as you wish\n", "        \"License :: OSI Approved :: Apache Software License\",\n\t        # Specify the Python versions you support here. In particular, ensure\n\t        # that you indicate you support Python 3. These classifiers are *not*\n\t        # checked by 'pip install'. See instead 'python_requires' below.\n\t        \"Programming Language :: Python :: 3\",\n\t        \"Programming Language :: Python :: 3.10\",\n\t        \"Programming Language :: Python :: 3.11\",\n\t        \"Programming Language :: Python :: 3 :: Only\",\n\t    ],\n\t    # This field adds keywords for your project which will appear on the\n", "    # project page. What does your project relate to?\n\t    #\n\t    # Note that this is a list of additional keywords, separated\n\t    # by commas, to be used to assist searching for the distribution in a\n\t    # larger catalog.\n\t    keywords=\", \".join(map(str, keywords_list)),  # Optional\n\t    # When your source code is in a subdirectory under the project root, e.g.\n\t    # `src/`, it is necessary to specify the `package_dir` argument.\n\t    # package_dir={\"\": \"cellulose\"},  # Optional\n\t    # You can just specify package directories manually here if your project is\n", "    # simple. Or you can use find_packages().\n\t    #\n\t    # Alternatively, if you just want to distribute a single Python file, use\n\t    # the `py_modules` argument instead as follows, which will expect a file\n\t    # called `my_module.py` to exist:\n\t    #\n\t    #   py_modules=[\"my_module\"],\n\t    #\n\t    packages=find_packages(),  # Required\n\t    # Specify which Python versions you support. In contrast to the\n", "    # 'Programming Language' classifiers above, 'pip install' will check this\n\t    # and refuse to install the project if the version does not match. See\n\t    # https://packaging.python.org/guides/distributing-packages-using-setuptools/#python-requires\n\t    python_requires=\">=3.10, <4\",\n\t    # This field lists other packages that your project depends on to run.\n\t    # Any package you put here will be installed by pip when your project is\n\t    # installed, so they must be valid existing projects.\n\t    #\n\t    # For an analysis of \"install_requires\" vs pip's requirements files see:\n\t    # https://packaging.python.org/discussions/install-requires-vs-requirements/\n", "    install_requires=[\n\t        \"black>=22,<24\",\n\t        \"click>=8,<9\",\n\t        \"colorama==0.4.6\",\n\t        \"flake8>=6.0.0\",\n\t        \"isort>=5.12.0\",\n\t        \"numpy>=1.24.3,<2\",\n\t        \"onnx>=1.13.0\",\n\t        \"onnxruntime>=1.15.0\",\n\t        \"pydantic==1.10.4\",\n", "        \"tf2onnx==1.13.0\",\n\t        \"tomlkit==0.11.6\",\n\t        \"torch>=1.13.1,<=2.0.1\",\n\t    ],  # Optional\n\t    # List additional groups of dependencies here (e.g. development\n\t    # dependencies). Users will be able to install these using the \"extras\"\n\t    # syntax, for example:\n\t    #\n\t    #   $ pip install sampleproject[dev]\n\t    #\n", "    # Similar to `install_requires` above, these must be valid existing\n\t    # projects.\n\t    # extras_require={  # Optional\n\t    #     \"dev\": [\"check-manifest\"],\n\t    #     \"test\": [\"coverage\"],\n\t    # },\n\t    # If there are data files included in your packages that need to be\n\t    # installed, specify them here.\n\t    package_data={\n\t        \"\": [\".cellulose_config.toml\"],\n", "    },\n\t    # Entry points. The following would provide a command called `sample` which\n\t    # executes the function `main` from this package when invoked:\n\t    # entry_points={  # Optional\n\t    #     \"console_scripts\": [\n\t    #         \"sample=sample:main\",\n\t    #     ],\n\t    # },\n\t    # List additional URLs that are relevant to your project as a dict.\n\t    #\n", "    # This field corresponds to the \"Project-URL\" metadata fields:\n\t    # https://packaging.python.org/specifications/core-metadata/#project-url-multiple-use\n\t    #\n\t    # Examples listed include a pattern for specifying where the package tracks\n\t    # issues, where the source is hosted, where to say thanks to the package\n\t    # maintainers, and where to support the project financially. The key is\n\t    # what's used to render the link text on PyPI.\n\t    project_urls={  # Optional\n\t        \"Homepage\": \"https://www.cellulose.ai\",\n\t        \"Documentation\": \"http://docs.cellulose.ai\",\n", "    },\n\t)\n"]}
{"filename": "cellulose/version.py", "chunked_list": ["CELLULOSE_SDK_VERSION = \"0.0.3\"\n"]}
{"filename": "cellulose/__init__.py", "chunked_list": []}
{"filename": "cellulose/onnx/loader.py", "chunked_list": ["# Third party imports\n\tfrom onnx import load\n\t# Cellulose imports\n\tfrom cellulose.base.loader import Loader\n\tclass ONNXLoader(Loader):\n\t    def load(self, file):\n\t        \"\"\"\n\t        This class method loads the ONNX model as specified by the file.\n\t        \"\"\"\n\t        with open(file, \"rb\") as f:\n", "            onnx_model = load(f)\n\t        return onnx_model\n\tif __name__ == \"__main__\":\n\t    loader = ONNXLoader()\n\t    onnx_model = loader.load(\"linear_regression.onnx\")\n\t    # display\n\t    print(onnx_model)\n"]}
{"filename": "cellulose/onnx/__init__.py", "chunked_list": []}
{"filename": "cellulose/onnx/benchmark.py", "chunked_list": ["# Standard imports\n\timport logging\n\timport timeit\n\tfrom pathlib import Path\n\t# Third party imports\n\timport onnxruntime\n\t# Cellulose imports\n\tfrom cellulose.base.benchmark import Benchmark\n\tfrom cellulose.utils.benchmark_results import BenchmarkResult\n\tfrom cellulose.utils.engines import Engine\n", "logger = logging.getLogger(__name__)\n\tclass ONNXRuntimeBenchmark(Benchmark):\n\t    batch_size: int\n\t    engine: Engine = Engine.ONNXRUNTIME\n\t    version: str = onnxruntime.__version__\n\t    def benchmark(\n\t        self, onnx_file: Path, input, num_iterations: int\n\t    ) -> list[BenchmarkResult]:\n\t        \"\"\"\n\t        This class method loads the given ONNX model and input, then\n", "        runs a set of benchmarks and returns them.\n\t        \"\"\"\n\t        results = []\n\t        ort_session = onnxruntime.InferenceSession(str(onnx_file))\n\t        ort_session.get_modelmeta()\n\t        first_input_name = ort_session.get_inputs()[0].name\n\t        first_output_name = ort_session.get_outputs()[0].name\n\t        logger.info(\"first input name: {}\".format(first_input_name))\n\t        logger.info(\"first output name: {}\".format(first_output_name))\n\t        # compute ONNX Runtime output prediction\n", "        ort_inputs = {ort_session.get_inputs()[0].name: input}\n\t        # ort_outs = ort_session.run(None, ort_inputs)\n\t        runtime_sec = timeit.repeat(\n\t            lambda: ort_session.run(None, ort_inputs),\n\t            repeat=num_iterations,\n\t            number=1,\n\t        )\n\t        result = self.generate_result(\n\t            runtime_sec=runtime_sec,\n\t        )\n", "        logger.info(result)\n\t        results.append(result)\n\t        return results\n"]}
{"filename": "cellulose/onnx/runtime.py", "chunked_list": ["# Standard imports\n\timport logging\n\tfrom pathlib import Path\n\t# Third party imports\n\timport onnxruntime\n\tfrom pydantic.dataclasses import dataclass\n\tlogger = logging.getLogger(__name__)\n\t@dataclass\n\tclass ONNXRuntime:\n\t    def run(self, onnx_file: Path, input):\n", "        \"\"\"\n\t        This class method loads the ONNX model as specified by the file.\n\t        \"\"\"\n\t        ort_session = onnxruntime.InferenceSession(str(onnx_file))\n\t        ort_session.get_modelmeta()\n\t        first_input_name = ort_session.get_inputs()[0].name\n\t        first_output_name = ort_session.get_outputs()[0].name\n\t        logger.info(\"first input name: {}\".format(first_input_name))\n\t        logger.info(\"first output name: {}\".format(first_output_name))\n\t        # compute ONNX Runtime output prediction\n", "        ort_inputs = {ort_session.get_inputs()[0].name: input}\n\t        ort_outs = ort_session.run(None, ort_inputs)\n\t        logger.info(\"Output: {}\".format(ort_outs))\n\t        return ort_outs\n"]}
{"filename": "cellulose/onnx/checker.py", "chunked_list": ["# Third party imports\n\tfrom onnx.checker import check_model\n\t# Cellulose imports\n\tfrom cellulose.base.checker import Checker\n\tclass ONNXChecker(Checker):\n\t    def check(self, onnx_model):\n\t        \"\"\"\n\t        This class method runs simple checks on the given ONNX model\n\t        \"\"\"\n\t        check_model(onnx_model)\n"]}
{"filename": "cellulose/validation/__init__.py", "chunked_list": []}
{"filename": "cellulose/validation/validation.py", "chunked_list": ["# Standard imports\n\timport logging\n\t# Third party imports\n\timport numpy as np\n\tfrom pydantic.dataclasses import dataclass\n\tDEFAULT_ATOL = 1e-05\n\tDEFAULT_RTOL = 1e-03\n\tlogger = logging.getLogger(__name__)\n\t@dataclass\n\tclass Validation:\n", "    atol: float = DEFAULT_ATOL\n\t    rtol: float = DEFAULT_RTOL\n\t    def compare_numpy(self, expected_outputs, actual_outputs):\n\t        # compare ONNX Runtime and PyTorch results\n\t        np.testing.assert_allclose(\n\t            expected_outputs, actual_outputs, rtol=self.rtol, atol=self.atol\n\t        )\n\t        logger.info(\n\t            \"Exported model has been tested with ONNXRuntime, and the result looks good!\"  # noqa: E501\n\t        )\n"]}
{"filename": "cellulose/dashboard/credentials.py", "chunked_list": []}
{"filename": "cellulose/dashboard/__init__.py", "chunked_list": []}
{"filename": "cellulose/dashboard/api_resources/__init__.py", "chunked_list": []}
{"filename": "cellulose/dashboard/api_resources/models/__init__.py", "chunked_list": []}
{"filename": "cellulose/dashboard/api_resources/models/onnx.py", "chunked_list": ["# Standard imports\n\timport logging\n\tfrom pathlib import Path\n\t# Third party imports\n\timport requests\n\tBASE_URL = \"https://dashboard.cellulose.ai\"\n\tlogger = logging.getLogger(__name__)\n\tdef upload_onnx_model(api_key: str, onnx_file: Path) -> requests.Response:\n\t    \"\"\"\n\t    This method uploads the ONNX model file to the Cellulose dashboard.\n", "    Params\n\t    ------\n\t    api_key: str - The API key for the Cellulose dashboard.\n\t    onnx_file: Path - The path to the ONNX model file.\n\t    Returns\n\t    -------\n\t    requests.Response - The response from the Cellulose dashboard.\n\t    \"\"\"\n\t    # Upload the ONNX model to the Cellulose dashboard.\n\t    payload = {}\n", "    files = [\n\t        (\n\t            \"onnx_model_file\",\n\t            (\n\t                onnx_file.name,\n\t                open(onnx_file, \"rb\"),\n\t                \"application/octet-stream\",\n\t            ),\n\t        )\n\t    ]\n", "    headers = {\n\t        \"X-API-Key\": api_key,\n\t    }\n\t    response = requests.request(\n\t        \"POST\",\n\t        BASE_URL + \"/v1/models/onnx/upload/sdk/\",\n\t        headers=headers,\n\t        data=payload,\n\t        files=files,\n\t    )\n", "    logger.info(response.text)\n\t    return response\n"]}
{"filename": "cellulose/configs/loader.py", "chunked_list": ["# Standard imports\n\timport logging\n\timport os\n\tfrom copy import deepcopy\n\tfrom dataclasses import asdict\n\tfrom pathlib import Path\n\tfrom typing import Any\n\t# Third party imports\n\timport tomlkit\n\tfrom pydantic.dataclasses import dataclass\n", "# Cellulose imports\n\tfrom cellulose.configs.config import (\n\t    AllConfig,\n\t    BenchmarkConfig,\n\t    DecoratorConfig,\n\t    ExportConfig,\n\t    OutputConfig,\n\t)\n\tDEFAULT_CELLULOSE_CONFIG_FILENAME = \".cellulose_config.toml\"\n\tDEFAULT_CELLULOSE_CONFIG_PATH = Path.home()\n", "logger = logging.getLogger(__name__)\n\tdef get_cellulose_config_path() -> Path:\n\t    \"\"\"\n\t    Returns the current CELLULOSE_CONFIG_PATH env variable, if defined.\n\t    Will return DEFAULT_CELLULOSE_CONFIG_PATH otherwise.\n\t    Returns\n\t    -------\n\t    CELLULOSE_CONFIG_PATH: pathlib.Path\n\t    \"\"\"\n\t    if os.getenv(\"CELLULOSE_CONFIG_PATH\") is None:\n", "        warning_msg = \"$CELLULOSE_CONFIG_PATH not set, defaulting to {default_cellulose_config_path} instead\".format(  # noqa: E501\n\t            default_cellulose_config_path=DEFAULT_CELLULOSE_CONFIG_PATH,\n\t        )\n\t        logger.warning(warning_msg)\n\t        return DEFAULT_CELLULOSE_CONFIG_PATH\n\t    else:\n\t        return Path(str(os.getenv(\"CELLULOSE_CONFIG_PATH\")))\n\t@dataclass\n\tclass ConfigLoader:\n\t    absolute_config_path: Path = get_cellulose_config_path()\n", "    cellulose_config: AllConfig | None = None\n\t    def parse_user_config(self) -> dict[str, Any]:\n\t        \"\"\"\n\t        This method parses the user specified Cellulose configs and returns\n\t        them as a dictionary.\n\t        \"\"\"\n\t        cellulose_config_toml = None\n\t        full_path = (\n\t            \"{absolute_config_path}/{cellulose_config_filename}\".format(\n\t                absolute_config_path=self.absolute_config_path,\n", "                cellulose_config_filename=DEFAULT_CELLULOSE_CONFIG_FILENAME,\n\t            )\n\t        )\n\t        try:\n\t            cellulose_config_toml = tomlkit.loads(Path(full_path).read_text())\n\t        except FileNotFoundError as e:\n\t            warning_msg = \"Could not find Cellulose config file in {full_path}, defaulting to Cellulose's default configurations\".format(  # noqa: E501\n\t                full_path=full_path\n\t            )\n\t            logger.warning(warning_msg)\n", "            logger.debug(e)\n\t        if cellulose_config_toml is None:\n\t            return dict()\n\t        return cellulose_config_toml\n\t    def parse_cellulose_internal_config(self) -> dict[str, Any]:\n\t        \"\"\"\n\t        This method parses the internal Cellulose configs and returns\n\t        them as a dictionary.\n\t        \"\"\"\n\t        cellulose_config_toml = None\n", "        full_path = os.path.join(\n\t            os.path.dirname(__file__),\n\t            \"{cellulose_config_filename}\".format(\n\t                cellulose_config_filename=DEFAULT_CELLULOSE_CONFIG_FILENAME,\n\t            ),\n\t        )\n\t        try:\n\t            cellulose_config_toml = tomlkit.loads(Path(full_path).read_text())\n\t        except FileNotFoundError as e:\n\t            error_msg = \"Could not find internal Cellulose config file!\"\n", "            logger.error(error_msg)\n\t            raise FileNotFoundError(e)\n\t        return cellulose_config_toml\n\t    def parse_decorator_config(\n\t        self, decorator_dict: dict[str, Any]\n\t    ) -> AllConfig:\n\t        if self.cellulose_config is None:\n\t            error_msg = (\n\t                \"Internal: Expected type(cellulose_config) attribute to be\"\n\t            )\n", "            error_msg += \"AllConfig, got None instead\"\n\t            logger.error(error_msg)\n\t            raise Exception(error_msg)\n\t        result_dict = deepcopy(self.cellulose_config)\n\t        # Note that decorator_dict is \"flat\", ie. no TOML config file\n\t        # \"section\" hierarchy.\n\t        # This is why we can just update the internal dicts this way.\n\t        # Update export_config\n\t        result_dict.export_config.update(decorator_dict)\n\t        # Update benchmark_config\n", "        result_dict.benchmark_config.update(decorator_dict)\n\t        # Update output_config\n\t        result_dict.output_config.update(decorator_dict)\n\t        # Create new instance of DecoratorConfig\n\t        result_dict.decorator_config = DecoratorConfig(**decorator_dict)\n\t        return result_dict\n\t    def override_with_provided_config_dict(\n\t        self, all_config: AllConfig, config_dict: dict[str, Any]\n\t    ):\n\t        \"\"\"\n", "        Internal helper method to override AllConfig instance with a provided\n\t        dict[str, Any]\n\t        \"\"\"\n\t        # Update export_config\n\t        if \"exports\" in config_dict:\n\t            user_export_config = config_dict[\"exports\"]\n\t            all_config.export_config.update(user_export_config)\n\t        # Update benchmark_config\n\t        if \"benchmarks\" in config_dict:\n\t            user_benchmark_config = config_dict[\"benchmarks\"]\n", "            all_config.benchmark_config.update(user_benchmark_config)\n\t        # Update output_config\n\t        if \"outputs\" in config_dict:\n\t            user_output_config = config_dict[\"outputs\"]\n\t            all_config.output_config.update(user_output_config)\n\t        return all_config\n\t    def override_internal_with_user_config(\n\t        self, user_config_dict: dict[str, Any]\n\t    ):\n\t        \"\"\"\n", "        This method overrides the internal, in-memory config values\n\t        with anything explicitly defined by the user_configs.\n\t        \"\"\"\n\t        if self.cellulose_config is None:\n\t            error_msg = \"Internal: Expected type(cellulose_config) attribute\"\n\t            error_msg += \"to be AllConfig, got None instead\"\n\t            logger.error(error_msg)\n\t            raise Exception(error_msg)\n\t        self.cellulose_config = self.override_with_provided_config_dict(\n\t            all_config=self.cellulose_config, config_dict=user_config_dict\n", "        )\n\t    def parse(self):\n\t        \"\"\"\n\t        This method parses the input configs based on the config path\n\t        and maintains an in memory representation of it.\n\t        \"\"\"\n\t        cellulose_internal_config_dict = self.parse_cellulose_internal_config()\n\t        # We first initialize based on Cellulose internal default\n\t        # configurations.\n\t        self.cellulose_config = AllConfig(\n", "            export_config=ExportConfig(\n\t                **cellulose_internal_config_dict[\"exports\"]\n\t            ),\n\t            benchmark_config=BenchmarkConfig(\n\t                **cellulose_internal_config_dict[\"benchmarks\"]\n\t            ),\n\t            output_config=OutputConfig(\n\t                **cellulose_internal_config_dict[\"outputs\"]\n\t            ),\n\t        )\n", "        logger.debug(\"Cellulose internal configs:\")\n\t        logger.debug(asdict(self.cellulose_config))\n\t        # Then now we parse user configs\n\t        # then override internal configs with them.\n\t        user_config_dict = self.parse_user_config()\n\t        self.override_internal_with_user_config(\n\t            user_config_dict=user_config_dict\n\t        )\n\t        logger.debug(\"Cellulose configs after user config updates:\")\n\t        logger.debug(asdict(self.cellulose_config))\n"]}
{"filename": "cellulose/configs/config.py", "chunked_list": ["# Third party imports\n\tfrom pydantic.dataclasses import dataclass\n\t@dataclass\n\tclass ConfigBase:\n\t    \"\"\"\n\t    Base dataclass for all configurations within Cellulose.\n\t    \"\"\"\n\t    def update(self, new):\n\t        for key, value in new.items():\n\t            if hasattr(self, key):\n", "                setattr(self, key, value)\n\t@dataclass\n\tclass OutputConfigInternal(ConfigBase):\n\t    \"\"\"\n\t    This internal dataclass contains internal bookkeeping attributes\n\t    \"\"\"\n\t    onnx_output_filename: str\n\t    torchscript_output_filename: str\n\t# -------------------------- PUBLIC DATACLASSES ---------------------------\n\t# NOTE: These dataclasses should have 1:1 parity with all attributes specified\n", "# in .cellulose_config.toml, with the exception of DecoratorConfig.\n\t# Those are exclusive to each Cellulose decorator use.\n\t@dataclass\n\tclass ExportConfig(ConfigBase):\n\t    batch_size: int\n\t    enable_export_validation: bool\n\t    enable_onnx_checks: bool\n\t    enable_onnx_export: bool\n\t    enable_torchscript_export: bool\n\t@dataclass\n", "class BenchmarkConfig(ConfigBase):\n\t    enable_onnxruntime: bool\n\t    enable_pytorch: bool\n\t    num_iterations: int\n\t@dataclass\n\tclass OutputConfig(ConfigBase):\n\t    enable_csv: bool\n\t    enable_stdout: bool\n\t@dataclass\n\tclass DecoratorConfig(ConfigBase):\n", "    \"\"\"\n\t    This dataclass contains minimally required attributes for\n\t    config arguments exclusive to each Cellulose() decorator use.\n\t    \"\"\"\n\t    input_names: list[str]  # The list of input_names to the underlying model.\n\t    output_names: list[\n\t        str\n\t    ]  # The list of output_names to the underlying model.\n\t@dataclass\n\tclass AllConfig(ConfigBase):\n", "    \"\"\"\n\t    Internal dataclass to store all forms of configs.\n\t    \"\"\"\n\t    export_config: ExportConfig\n\t    benchmark_config: BenchmarkConfig\n\t    output_config: OutputConfig\n\t    decorator_config: DecoratorConfig | None = None\n\t    # for Cellulose use only.\n\t    output_config_internal = OutputConfigInternal(\n\t        onnx_output_filename=\"\", torchscript_output_filename=\"\"\n", "    )\n"]}
{"filename": "cellulose/configs/__init__.py", "chunked_list": []}
{"filename": "cellulose/tensorflow/__init__.py", "chunked_list": []}
{"filename": "cellulose/utils/csv_utils.py", "chunked_list": ["# Standard imports\n\timport csv\n\timport os\n\timport tempfile\n\tfrom pathlib import Path\n\tfrom typing import Any\n\tdef generate_output_csv_name(name: str) -> str:\n\t    \"\"\"\n\t    This function takes in an arbitrary name (string) and returns it with a\n\t    .csv extension.\n", "    \"\"\"\n\t    return \"{name}.csv\".format(name=name)\n\tdef generate_output_csv_stream(\n\t    output_file_name: str, input_list: list[dict[str, Any]]\n\t) -> Path:\n\t    \"\"\"\n\t    This function takes in an output filename (.csv) and a list of dictionaries\n\t    then writes to it.\n\t    \"\"\"\n\t    temp_output_file_path = Path(\n", "        os.path.join(tempfile.gettempdir(), output_file_name)\n\t    )\n\t    if len(input_list) == 0:\n\t        return temp_output_file_path\n\t    with open(temp_output_file_path, \"w\", newline=\"\") as csvfile:\n\t        headers = input_list[0].keys()\n\t        writer = csv.DictWriter(csvfile, fieldnames=headers)\n\t        writer.writeheader()\n\t        writer.writerows(input_list)\n\t    return temp_output_file_path\n"]}
{"filename": "cellulose/utils/devices.py", "chunked_list": ["# Standard imports\n\tfrom enum import Enum\n\tclass Device(Enum):\n\t    \"\"\"\n\t    This Enum specifies the supported devices (for benchmarking).\n\t    \"\"\"\n\t    CPU = \"cpu\"\n\t    CUDA = \"cuda\"\n"]}
{"filename": "cellulose/utils/__init__.py", "chunked_list": []}
{"filename": "cellulose/utils/numpy.py", "chunked_list": ["def to_numpy(pytorch_tensor):\n\t    \"\"\"\n\t    This util method converts a PyTorch tensor to numpy then returns it.\n\t    \"\"\"\n\t    return (\n\t        pytorch_tensor.detach().cpu().numpy()\n\t        if pytorch_tensor.requires_grad\n\t        else pytorch_tensor.cpu().numpy()\n\t    )\n"]}
{"filename": "cellulose/utils/benchmark_results.py", "chunked_list": ["# Standard imports\n\tfrom dataclasses import dataclass\n\tfrom datetime import datetime, timezone\n\t# Cellulose imports\n\tfrom cellulose.metrics.latency import LatencyMetrics\n\tfrom cellulose.utils.devices import Device\n\t# return {\n\t#     # \"precision\": precision,\n\t#     \"io_binding\": \"\",\n\t#     # \"model_name\": model_name,\n", "#     \"inputs\": 1,\n\t#     # \"threads\": num_threads,\n\t#     # \"sequence_length\": sequence_length,\n\t#     # \"custom_layer_num\": config_modifier.get_layer_num(),\n\t# }\n\tUSE_GPU = False\n\t@dataclass\n\tclass BenchmarkResult:\n\t    \"\"\"\n\t    This Enum specifies the supported engines (for benchmarking).\n", "    \"\"\"\n\t    engine: str\n\t    version: str\n\t    latency_metrics: LatencyMetrics\n\t    batch_size: int\n\t    optimizer: str = \"N/A\"\n\t    providers: str = \"N/A\"\n\t    device: str = str(Device.CUDA.value) if USE_GPU else str(Device.CPU.value)\n\t    timestamp: str = str(datetime.now(timezone.utc).isoformat())\n"]}
{"filename": "cellulose/utils/engines.py", "chunked_list": ["# Standard imports\n\tfrom enum import Enum\n\tclass Engine(Enum):\n\t    \"\"\"\n\t    This Enum specifies the supported engines (for benchmarking).\n\t    \"\"\"\n\t    ONNXRUNTIME = \"onnxruntime\"\n\t    TENSORFLOW = \"tensorflow\"\n\t    TORCH = \"torch\"\n\t    TORCHSCRIPT = \"torchscript\"\n"]}
{"filename": "cellulose/scripts/__init__.py", "chunked_list": []}
{"filename": "cellulose/metrics/latency.py", "chunked_list": ["# Standard imports\n\timport logging\n\tfrom dataclasses import dataclass\n\t# Third party imports\n\tfrom numpy import float64\n\t# Cellulose imports\n\tfrom cellulose.metrics.metrics import Metrics\n\tlogger = logging.getLogger(__name__)\n\t@dataclass\n\tclass LatencyMetrics(Metrics):\n", "    num_samples: int\n\t    variance: float64\n\t    mean_ms: float\n\t    p50_ms: float\n\t    p90_ms: float\n\t    p95_ms: float\n\t    p99_ms: float\n\t    throughput_per_sec: float\n"]}
{"filename": "cellulose/metrics/metrics.py", "chunked_list": ["# Standard imports\n\tfrom dataclasses import dataclass\n\t@dataclass\n\tclass Metrics:\n\t    pass\n"]}
{"filename": "cellulose/metrics/__init__.py", "chunked_list": []}
{"filename": "cellulose/pytorch/__init__.py", "chunked_list": []}
{"filename": "cellulose/pytorch/benchmark.py", "chunked_list": ["# Standard imports\n\timport logging\n\timport timeit\n\t# Third party imports\n\timport torch\n\tfrom pydantic.dataclasses import dataclass\n\t# Cellulose imports\n\tfrom cellulose.base.benchmark import Benchmark\n\tfrom cellulose.utils.benchmark_results import BenchmarkResult\n\tfrom cellulose.utils.engines import Engine\n", "logger = logging.getLogger(__name__)\n\t@dataclass\n\tclass PyTorchBenchmark(Benchmark):\n\t    batch_size: int\n\t    engine: Engine = Engine.TORCH\n\t    version: str = torch.__version__\n\t    def benchmark(\n\t        self, torch_model, input, num_iterations: int\n\t    ) -> list[BenchmarkResult]:\n\t        results = []\n", "        \"\"\"\n\t        This class method loads the given torch_model and input, then\n\t        runs a set of benchmarks and returns them.\n\t        \"\"\"\n\t        runtime_sec = timeit.repeat(\n\t            lambda: torch_model(input), repeat=num_iterations, number=1\n\t        )\n\t        result = self.generate_result(runtime_sec=runtime_sec)\n\t        logger.info(result)\n\t        results.append(result)\n", "        return results\n"]}
{"filename": "cellulose/pytorch/export.py", "chunked_list": ["# Standard imports\n\timport logging\n\tfrom pathlib import Path\n\t# Third party imports\n\timport torch\n\tfrom pydantic.dataclasses import dataclass\n\t# Cellulose imports\n\tfrom cellulose.base.export import Export\n\tfrom cellulose.onnx.checker import ONNXChecker\n\tfrom cellulose.onnx.loader import ONNXLoader\n", "from cellulose.output.output import ExportOutput, ONNXOutput, TorchScriptOutput\n\tlogger = logging.getLogger(__name__)\n\t@dataclass\n\tclass PytorchExport(Export):\n\t    @staticmethod\n\t    def generate_absolute_tmp_directory(output_file_name: str) -> Path:\n\t        \"\"\"\n\t        This function takes in an output filename, appends a /tmp directory to\n\t        it then return the full path.\n\t        \"\"\"\n", "        return Path(\"/tmp\").joinpath(output_file_name)\n\t    def export(\n\t        self,\n\t        torch_model,\n\t        input,\n\t    ) -> ExportOutput:\n\t        \"\"\"\n\t        This method exports the model in various formats and returns the list\n\t        of outputs accordingly.\n\t        Params\n", "        ------\n\t        torch_model (nn.Module): The PyTorch model.\n\t        input: Input tensors to the PyTorch model.\n\t        \"\"\"\n\t        export_output = ExportOutput()\n\t        if self.model_config.export_config.enable_onnx_export:\n\t            msg = \"Exporting TorchScript...\"\n\t            logger.info(msg)\n\t            export_output.torchscript = self.export_torchscript(\n\t                torch_model=torch_model,\n", "            )\n\t        if self.model_config.export_config.enable_onnx_export:\n\t            msg = \"Exporting ONNX...\"\n\t            logger.info(msg)\n\t            export_output.onnx = self.export_onnx(\n\t                torch_model=torch_model,\n\t                input=input,\n\t            )\n\t        return export_output\n\t    def export_torchscript(\n", "        self,\n\t        torch_model,\n\t    ) -> TorchScriptOutput:\n\t        \"\"\"\n\t        This method exports the current PyTorch model to TorchScript.\n\t        \"\"\"\n\t        if self.model_config.decorator_config is None:\n\t            error_msg = (\n\t                \"Expected type(decorator_config) to be DecoratorConfig, \"\n\t                \"but got None instead\"\n", "            )\n\t            logger.error(error_msg)\n\t            raise Exception(error_msg)\n\t        # Generate the output TorchScript file in a /tmp directory first.\n\t        tmp_output_torchscript_file = self.generate_absolute_tmp_directory(\n\t            output_file_name=self.model_config.output_config_internal.torchscript_output_filename,  # noqa: E501\n\t        )\n\t        # Script and save the model\n\t        scripted_module = torch.jit.script(torch_model)\n\t        scripted_module.save(tmp_output_torchscript_file)\n", "        # then append it to the artifact_manager list later.\n\t        self.artifact_manager.append(file=tmp_output_torchscript_file)\n\t        # Return the output\n\t        return TorchScriptOutput(\n\t            torchscript_file=tmp_output_torchscript_file,\n\t        )\n\t    def export_onnx(\n\t        self,\n\t        torch_model,\n\t        input,\n", "    ) -> ONNXOutput:\n\t        \"\"\"\n\t        This method exports the current PyTorch model to ONNX.\n\t        Params\n\t        ------\n\t        torch_model (nn.Module): The PyTorch model.\n\t        input: Input tensors to the PyTorch model.\n\t        \"\"\"\n\t        if self.model_config.decorator_config is None:\n\t            error_msg = \"Expected type(decorator_config) to be DecoratorConfig, but got None instead\"  # noqa: E501\n", "            logger.error(error_msg)\n\t            raise Exception(error_msg)\n\t        # Generate the output ONNX file in a /tmp directory first.\n\t        tmp_output_onnx_file = self.generate_absolute_tmp_directory(\n\t            output_file_name=self.model_config.output_config_internal.onnx_output_filename,  # noqa: E501\n\t        )\n\t        # Export the model\n\t        torch.onnx.export(\n\t            torch_model,\n\t            input,  # model input or tuple\n", "            str(tmp_output_onnx_file),\n\t            export_params=True,\n\t            opset_version=10,\n\t            do_constant_folding=True,\n\t            input_names=self.model_config.decorator_config.input_names,\n\t            output_names=self.model_config.decorator_config.output_names,\n\t            dynamic_axes={\n\t                \"input\": {0: \"batch_size\"},  # variable length axes\n\t                \"output\": {0: \"batch_size\"},\n\t            },\n", "        )\n\t        # then append it to the artifact_manager list later.\n\t        self.artifact_manager.append(file=tmp_output_onnx_file)\n\t        if self.model_config.export_config.enable_onnx_checks:\n\t            msg = (\n\t                \"enable_onnx_checks set to True, \"\n\t                \"running checks on exported artifacts...\"\n\t            )\n\t            logger.info(msg)\n\t            loader = ONNXLoader()\n", "            onnx_model = loader.load(tmp_output_onnx_file)\n\t            checker = ONNXChecker()\n\t            checker.check(onnx_model)\n\t        return ONNXOutput(onnx_file=tmp_output_onnx_file)\n"]}
{"filename": "cellulose/output/__init__.py", "chunked_list": []}
{"filename": "cellulose/output/output.py", "chunked_list": ["# Standard imports\n\tfrom pathlib import Path\n\t# Third party imports\n\tfrom pydantic.dataclasses import dataclass\n\t@dataclass\n\tclass Output:\n\t    pass\n\t@dataclass\n\tclass ONNXOutput(Output):\n\t    onnx_file: Path\n", "@dataclass\n\tclass TorchScriptOutput(Output):\n\t    torchscript_file: Path\n\t@dataclass\n\tclass ExportOutput(Output):\n\t    onnx: ONNXOutput | None = None\n\t    torchscript: TorchScriptOutput | None = None\n"]}
{"filename": "cellulose/artifact/cellulose_artifact.py", "chunked_list": ["# Standard imports\n\timport logging\n\tfrom dataclasses import dataclass\n\tfrom datetime import datetime\n\tfrom pathlib import Path\n\tlogger = logging.getLogger(__name__)\n\t@dataclass\n\tclass Metadata:\n\t    title: str\n\t    created_at: datetime\n", "    updated_at: datetime\n\t@dataclass\n\tclass CelluloseArtifact:\n\t    \"\"\"\n\t    This class encapsulates all Cellulose zip artifact modules\n\t    \"\"\"\n\t    file_paths: list[Path]\n\t    metadata: Metadata\n"]}
{"filename": "cellulose/artifact/cellulose_artifact_manager.py", "chunked_list": ["# Standard imports\n\timport logging\n\timport platform\n\tfrom dataclasses import asdict\n\tfrom datetime import datetime, timezone\n\tfrom pathlib import Path\n\tfrom zipfile import ZipFile\n\t# Third party imports\n\timport click\n\timport tomlkit\n", "from pydantic.dataclasses import dataclass\n\t# Cellulose imports\n\tfrom cellulose.artifact.cellulose_artifact import CelluloseArtifact, Metadata\n\tfrom cellulose.configs.config import AllConfig\n\tfrom cellulose.version import CELLULOSE_SDK_VERSION\n\tlogger = logging.getLogger(__name__)\n\t@dataclass\n\tclass CelluloseArtifactManager:\n\t    cellulose_artifact = CelluloseArtifact(\n\t        file_paths=[],\n", "        metadata=Metadata(\n\t            title=\"\",\n\t            created_at=datetime.utcnow(),\n\t            updated_at=datetime.utcnow(),\n\t        ),\n\t    )\n\t    metadata_doc = tomlkit.document()\n\t    def initialize_artifact_metadata(self):\n\t        \"\"\"\n\t        This internal method initializes the title and created_at / updated_at\n", "        parameters in the Cellulose artifact metadata file.\n\t        \"\"\"\n\t        self.metadata_doc.add(\n\t            tomlkit.comment(\n\t                \"This is an autogenerated TOML Cellulose artifact file.\"\n\t            )\n\t        )\n\t        self.metadata_doc.add(\n\t            tomlkit.comment(\"Please do not modify it directly.\")\n\t        )\n", "        self.metadata_doc.add(tomlkit.nl())\n\t        self.metadata_doc[\"title\"] = \"unknown\"\n\t        self.metadata_doc.add(tomlkit.nl())\n\t        # Timestamps in UTC.\n\t        utcnow = str(datetime.now(timezone.utc).isoformat())\n\t        self.metadata_doc.add(\"created_at\", utcnow)  # type: ignore\n\t        self.metadata_doc.add(\"updated_at\", utcnow)  # type: ignore\n\t        self.metadata_doc[\"created_at\"].comment(\"in UTC\")  # type: ignore\n\t        self.metadata_doc[\"updated_at\"].comment(\"in UTC\")  # type: ignore\n\t        self.metadata_doc.add(tomlkit.nl())\n", "        # Cellulose versions + platform info.\n\t        env_info = tomlkit.table()\n\t        env_info.add(\"cellulose_sdk_version\", CELLULOSE_SDK_VERSION)\n\t        env_info.add(\"python_version\", platform.python_version())\n\t        env_info.add(\"system\", platform.system())\n\t        env_info.add(\"release\", platform.release())\n\t        self.metadata_doc.add(\"environment\", env_info)\n\t    def generate_cellulose_artifact_filename(self, name: str) -> Path:\n\t        \"\"\"\n\t        Internal method for generating Cellulose artifact filename.\n", "        Returns a pathlib.Path\n\t        \"\"\"\n\t        output_filename = Path(\"{name}.cellulose.zip\".format(name=name))\n\t        self.metadata_doc[\"title\"] = str(output_filename)\n\t        return output_filename\n\t    def init(self):\n\t        \"\"\"\n\t        This method initializes / reinitializes a new Cellulose file context.\n\t        \"\"\"\n\t        self.initialize_artifact_metadata()\n", "    def load(self, cellulose_artifact_path: str):\n\t        \"\"\"\n\t        This method loads a current CelluloseArtifact.\n\t        NOTE: It will also reinitialize the Cellulose file context. This means\n\t        you may lose context on unsaved / unexported Cellulose files.\n\t        \"\"\"\n\t        logger.info(\"Reinitialize the Cellulose context...\")\n\t        self.init()\n\t        # TODO: Implement proper loading of Cellulose artifact from a\n\t        #               file path.\n", "        logger.info(\n\t            \"Loading Cellulose artifact: {cellulose_artifact_path}...\".format(\n\t                cellulose_artifact_path=cellulose_artifact_path\n\t            )\n\t        )\n\t        # self.cellulose_artifact = cellulose_artifact\n\t    def append(self, file: Path):\n\t        \"\"\"\n\t        This method appends a file to the list of file paths in Cellulose\n\t        artifact.\n", "        Params\n\t        -----\n\t        file: Path - The file path to be embedded within Cellulose artifact.\n\t        \"\"\"\n\t        # TODO: Verify if .load() file path to Cellulose artifact is\n\t        # valid\n\t        self.cellulose_artifact.file_paths.append(file)\n\t        # Add metadata associated with it too.\n\t    def export(self, name: str, target_directory: str):\n\t        \"\"\"\n", "        This method takes in a name for the Cellulose output artifact and\n\t        target directory for where to place it.\n\t        Params\n\t        ------\n\t        name: str - The name of the Cellulose artifact.\n\t        For example, \"my_benchmarks\" to export a \"my_benchmarks.cellulose.zip\"\n\t        target_directory: str - The target directory for where to place this\n\t        generated \".cellulose\" artifact.\n\t        \"\"\"\n\t        cellulose_artifact_filename = (\n", "            self.generate_cellulose_artifact_filename(name=name)\n\t        )\n\t        output_cellulose_artifact_path = Path(target_directory).joinpath(\n\t            cellulose_artifact_filename\n\t        )\n\t        logger.info(\n\t            \"The following files will be zipped into {output_file}:\".format(\n\t                output_file=output_cellulose_artifact_path\n\t            )\n\t        )\n", "        for file_name in self.cellulose_artifact.file_paths:\n\t            logger.info(file_name)\n\t        # TODO: Update timestamps in the metadata file here.\n\t        click.secho(\n\t            \"Packing Cellulose output artifacts...\", fg=\"yellow\", bold=True\n\t        )\n\t        with ZipFile(output_cellulose_artifact_path, \"w\") as zip:\n\t            # writing each output file one by one\n\t            for file in self.cellulose_artifact.file_paths:\n\t                zip.write(file, Path(file).name)\n", "            # writing the metadata file too.\n\t            output_metadata_filename = \"/tmp/{name}.toml\".format(name=name)\n\t            with Path(output_metadata_filename).open(\"w\") as fout:\n\t                fout.write(tomlkit.dumps(self.metadata_doc))\n\t            zip.write(\n\t                output_metadata_filename,\n\t                Path(output_metadata_filename).name,\n\t            )\n\t        click.secho(\n\t            \"Results generated and exported to {output_cellulose_artifact_path}!\".format(  # noqa: E501\n", "                output_cellulose_artifact_path=output_cellulose_artifact_path\n\t            ),\n\t            fg=\"green\",\n\t            bold=True,\n\t        )\n\t    def update_artifact_metadata_section(\n\t        self, key: str, model_config: AllConfig\n\t    ):\n\t        section = tomlkit.table()\n\t        section.add(\"config\", asdict(model_config))\n", "        self.metadata_doc.add(key, section)\n"]}
{"filename": "cellulose/artifact/__init__.py", "chunked_list": []}
{"filename": "cellulose/artifact/tests/test_cellulose_artifact.py", "chunked_list": ["# Standard imports\n\timport logging\n\tfrom dataclasses import dataclass\n\tfrom datetime import datetime\n\tfrom pathlib import Path\n\tfrom cellulose.artifact.cellulose_artifact import CelluloseArtifact, Metadata\n\t\"\"\"\n\tWrite unit tests for all classes in cellulose/artifact/cellulose_artifact.py\n\tTest invalid cases too.\n\t\"\"\"\n", "def test_valid_cellulose_artifact():\n\t    test = CelluloseArtifact(\n\t        file_paths=[Path(\"test\")],\n\t        metadata=Metadata(\n\t            title=\"test\",\n\t            created_at=datetime.now(),\n\t            updated_at=datetime.now()\n\t        )\n\t    )\n\t    assert test.file_paths == [Path(\"test\")]\n", "    assert test.metadata.title == \"test\"\n\t    assert isinstance(test.metadata.created_at, datetime)\n\t    assert isinstance(test.metadata.updated_at, datetime)\n\tdef test_invalid_cellulose_artifact():\n\t    test = CelluloseArtifact(\n\t        file_paths=[Path(\"test\")],\n\t        metadata=Metadata(\n\t            title=\"test\",\n\t            created_at=datetime.now(),\n\t            updated_at=datetime.now()\n", "        )\n\t    )\n\t    assert test.file_paths != [Path(\"test2\")]\n\t    assert test.metadata.title != \"test2\"\n\t    assert not isinstance(test.metadata.created_at, str)\n\t    assert not isinstance(test.metadata.updated_at, str)\n\tdef test_metadata():\n\t    test = Metadata(\n\t        title=\"test\",\n\t        created_at=datetime.now(),\n", "        updated_at=datetime.now()\n\t    )\n\t    assert test.title == \"test\"\n\t    assert isinstance(test.created_at, datetime)\n\t    assert isinstance(test.updated_at, datetime)"]}
{"filename": "cellulose/artifact/tests/__init__.py", "chunked_list": []}
{"filename": "cellulose/infra/__init__.py", "chunked_list": []}
{"filename": "cellulose/base/loader.py", "chunked_list": ["# Third party imports\n\tfrom pydantic.dataclasses import dataclass\n\t@dataclass\n\tclass Loader:\n\t    pass\n"]}
{"filename": "cellulose/base/__init__.py", "chunked_list": []}
{"filename": "cellulose/base/benchmark.py", "chunked_list": ["# Standard imports\n\timport logging\n\t# Third party imports\n\timport numpy as np\n\tfrom pydantic.dataclasses import dataclass\n\t# Cellulose imports\n\tfrom cellulose.metrics.latency import LatencyMetrics\n\tfrom cellulose.utils.benchmark_results import BenchmarkResult\n\tfrom cellulose.utils.engines import Engine\n\tlogger = logging.getLogger(__name__)\n", "@dataclass\n\tclass Benchmark:\n\t    batch_size: int\n\t    engine = Engine | None\n\t    version = str | None\n\t    def calculate_latency_metrics(\n\t        self, latency_list_sec: int\n\t    ) -> LatencyMetrics:\n\t        latency_ms = (\n\t            sum(latency_list_sec) / float(len(latency_list_sec)) * 1000.0\n", "        )\n\t        variance = np.var(latency_list_sec, dtype=np.float64)\n\t        throughput = self.batch_size * (1000.0 / latency_ms)\n\t        return LatencyMetrics(\n\t            num_samples=len(latency_list_sec),\n\t            variance=variance,\n\t            mean_ms=latency_ms,\n\t            p50_ms=np.percentile(latency_list_sec, 50) * 1000.0,\n\t            p90_ms=np.percentile(latency_list_sec, 90) * 1000.0,\n\t            p95_ms=np.percentile(latency_list_sec, 95) * 1000.0,\n", "            p99_ms=np.percentile(latency_list_sec, 99) * 1000.0,\n\t            throughput_per_sec=throughput,\n\t        )\n\t    def generate_result(self, runtime_sec) -> BenchmarkResult:\n\t        \"\"\"\n\t        This method generates the results.\n\t        \"\"\"\n\t        if self.engine is None:\n\t            error_msg = (\n\t                \"Expected engine to be an Engine type, but got None instead\"\n", "            )\n\t            logger.error(error_msg)\n\t            raise Exception(error_msg)\n\t        if self.version is None or self.version == \"\":\n\t            logger.error(\n\t                \"Expected version to be a str type, but got {} instead\".format(\n\t                    type(self.version)\n\t                )\n\t            )\n\t            raise\n", "        return BenchmarkResult(\n\t            engine=self.engine.value,\n\t            version=self.version,\n\t            batch_size=self.batch_size,\n\t            latency_metrics=self.calculate_latency_metrics(\n\t                latency_list_sec=runtime_sec\n\t            ),\n\t        )\n"]}
{"filename": "cellulose/base/export.py", "chunked_list": ["# Third party imports\n\tfrom pydantic.dataclasses import dataclass\n\t# Cellulose imports\n\tfrom cellulose.artifact.cellulose_artifact_manager import (\n\t    CelluloseArtifactManager,\n\t)\n\tfrom cellulose.configs.config import AllConfig\n\t@dataclass\n\tclass Export:\n\t    model_config: AllConfig\n", "    artifact_manager: CelluloseArtifactManager\n"]}
{"filename": "cellulose/base/checker.py", "chunked_list": ["# Third party imports\n\tfrom pydantic.dataclasses import dataclass\n\t@dataclass\n\tclass Checker:\n\t    pass\n"]}
{"filename": "cellulose/api/__init__.py", "chunked_list": []}
{"filename": "cellulose/api/cellulose_context.py", "chunked_list": ["# Standard imports\n\timport logging\n\tfrom pathlib import Path\n\t# Third party imports\n\timport click\n\tfrom pydantic.dataclasses import dataclass\n\t# Cellulose imports\n\tfrom cellulose.artifact.cellulose_artifact_manager import (\n\t    CelluloseArtifactManager,\n\t)\n", "from cellulose.configs.loader import ConfigLoader\n\tfrom cellulose.dashboard.api_resources.models.onnx import upload_onnx_model\n\tlogger = logging.getLogger(__name__)\n\tDEFAULT_TARGET_DIRECTORY = Path.cwd()\n\t@dataclass\n\tclass CelluloseContext:\n\t    config_loader = ConfigLoader()\n\t    artifact_manager = CelluloseArtifactManager()\n\t    def __init__(self, api_key: str):\n\t        logger.info(\"Initializing Cellulose context...\")\n", "        logger.info(\"Loading Cellulose configs...\")\n\t        self.load_config()\n\t        logger.info(\"Initializing Cellulose artifact manager...\")\n\t        self.artifact_manager.init()\n\t        self.api_key = api_key\n\t    def load_config(self):\n\t        \"\"\"\n\t        Internal!\n\t        Loads the Cellulose configs\n\t        \"\"\"\n", "        # Initialize and parse workspace level configs.\n\t        self.config_loader.parse()\n\t    def export(self, torch_model, input, **export_args):\n\t        \"\"\"\n\t        This method exports the given PyTorch model and input. Please refer\n\t        to our documentation for full set of options.\n\t        Params\n\t        ------\n\t        torch_model (nn.Module): The PyTorch model.\n\t        input: Input tensors to the PyTorch model.\n", "        export_args: Other (both required and optional) arguments specific to\n\t        the underlying export workflow. Please read our documentation for full\n\t        details.\n\t        \"\"\"\n\t        export_output = torch_model.cellulose.export_model(\n\t            config_loader=self.config_loader,\n\t            artifact_manager=self.artifact_manager,\n\t            torch_model=torch_model,\n\t            input=input,\n\t            **export_args,\n", "        )\n\t        click.secho(\n\t            \"Uploading ONNX model to Cellulose dashboard...\", fg=\"yellow\"\n\t        )\n\t        response = upload_onnx_model(\n\t            api_key=self.api_key, onnx_file=export_output.onnx.onnx_file\n\t        )\n\t        if response.status_code == 200 or response.status_code == 201:\n\t            click.secho(\"Done!\", fg=\"green\")\n\t        else:\n", "            click.secho(\n\t                \"Failed to upload ONNX model to Cellulose dashboard\",\n\t                fg=\"red\",\n\t            )\n\t            click.secho(\"Please check your API key and try again.\", fg=\"red\")\n\t            click.secho(\n\t                \"If the problem persists, please contact us at support@cellulose.ai\",\n\t                fg=\"red\",\n\t            )\n\t    def benchmark(self, torch_model, input, **benchmark_args):\n", "        \"\"\"\n\t        This method benchmarks the given PyTorch model and input. Please refer\n\t        to our documentation for full set of options.\n\t        Params\n\t        ------\n\t        torch_model (nn.Module): The PyTorch model.\n\t        input: Input tensors to the PyTorch model.\n\t        benchmark_args: Other (both required and optional) arguments specific\n\t        to the underlying benchmarking workflow. Please read our documentation\n\t        for full details.\n", "        \"\"\"\n\t        torch_model.cellulose.benchmark_model(\n\t            config_loader=self.config_loader,\n\t            artifact_manager=self.artifact_manager,\n\t            torch_model=torch_model,\n\t            input=input,\n\t            **benchmark_args,\n\t        )\n\t    def flush(\n\t        self, name: str, target_directory: str = str(DEFAULT_TARGET_DIRECTORY)\n", "    ):\n\t        \"\"\"\n\t        This method takes in a name for the Cellulose output artifact and\n\t        target directory for where to place it.\n\t        Params\n\t        ------\n\t        name: str - The name of the Cellulose artifact.\n\t        For example, \"my_benchmarks\" to export a \"my_benchmarks.cellulose.zip\"\n\t        target_directory: str - The target directory for where to place this\n\t        generated \".cellulose\" artifact. Current directory by default.\n", "        \"\"\"\n\t        self.artifact_manager.export(\n\t            name=name,\n\t            target_directory=target_directory,\n\t        )\n"]}
{"filename": "cellulose/decorators/__init__.py", "chunked_list": []}
{"filename": "cellulose/decorators/cellulose.py", "chunked_list": ["# Standard imports\n\timport logging\n\timport time\n\tfrom dataclasses import asdict\n\tfrom functools import partial\n\t# Third party imports\n\timport click\n\t# Cellulose imports\n\tfrom cellulose.artifact.cellulose_artifact_manager import (\n\t    CelluloseArtifactManager,\n", ")\n\tfrom cellulose.configs.loader import ConfigLoader\n\tfrom cellulose.onnx.benchmark import ONNXRuntimeBenchmark\n\tfrom cellulose.onnx.runtime import ONNXRuntime\n\tfrom cellulose.pytorch.benchmark import PyTorchBenchmark\n\tfrom cellulose.pytorch.export import PytorchExport\n\tfrom cellulose.utils.benchmark_results import BenchmarkResult\n\tfrom cellulose.utils.csv_utils import (\n\t    generate_output_csv_name,\n\t    generate_output_csv_stream,\n", ")\n\tfrom cellulose.utils.numpy import to_numpy\n\tfrom cellulose.validation.validation import Validation\n\tlogger = logging.getLogger(__name__)\n\tclass _Cellulose:\n\t    def __init__(self, original_class_name, **kwargs):\n\t        self.class_name = original_class_name\n\t        self.decorator_based_dict = kwargs\n\t        self.onnx_runtime = ONNXRuntime()\n\t    def export_model(\n", "        self,\n\t        config_loader: ConfigLoader,\n\t        artifact_manager: CelluloseArtifactManager,\n\t        torch_model,\n\t        input,\n\t        **export_args,\n\t    ):\n\t        \"\"\"\n\t        This method exports the PyTorch model.\n\t        \"\"\"\n", "        # Parse and \"overwrite\" the config for this nn.Module by merging any\n\t        # decorator based args with the export_model function args\n\t        # (the decorator and \"this\" set of function\n\t        # arguments two take precedence).\n\t        export_model_config = config_loader.parse_decorator_config(\n\t            decorator_dict=self.decorator_based_dict | export_args\n\t        )\n\t        artifact_manager.update_artifact_metadata_section(\n\t            key=\"export\", model_config=export_model_config\n\t        )\n", "        # Workaround for ONNX output files for now.\n\t        export_model_config.output_config_internal.onnx_output_filename = (\n\t            self.class_name + \".onnx\"\n\t        )\n\t        # Workaround for TorchScript output files for now.\n\t        export_model_config.output_config_internal.torchscript_output_filename = (  # noqa: E501\n\t            self.class_name + \".pt\"\n\t        )\n\t        self.pytorch_export = PytorchExport(\n\t            model_config=export_model_config, artifact_manager=artifact_manager\n", "        )\n\t        start_time = time.perf_counter()\n\t        export_output = self.pytorch_export.export(\n\t            torch_model=torch_model,\n\t            input=input,\n\t        )\n\t        end_time = time.perf_counter()\n\t        run_time = end_time - start_time\n\t        click.secho(\n\t            \"Finished model export in {run_time:.4f} secs\".format(\n", "                run_time=run_time\n\t            ),\n\t            fg=\"green\",\n\t            bold=True,\n\t        )\n\t        if export_model_config.export_config.enable_export_validation:\n\t            msg = (\n\t                \"enable_export_validation is set to True, \"\n\t                \"running functional validation for torch model...\"\n\t            )\n", "            click.secho(\n\t                msg,\n\t                fg=\"yellow\",\n\t                bold=True,\n\t            )\n\t            ort_outputs = self.onnx_runtime.run(\n\t                onnx_file=export_output.onnx.onnx_file,\n\t                input=to_numpy(pytorch_tensor=input),\n\t            )\n\t            torch_out = torch_model(input)\n", "            validation = Validation()\n\t            validation.compare_numpy(\n\t                expected_outputs=to_numpy(pytorch_tensor=torch_out),\n\t                actual_outputs=ort_outputs[0],\n\t            )\n\t        return export_output\n\t    def benchmark_model(\n\t        self,\n\t        config_loader: ConfigLoader,\n\t        artifact_manager: CelluloseArtifactManager,\n", "        torch_model,\n\t        input,\n\t        **benchmark_args,\n\t    ):\n\t        \"\"\"\n\t        This method benchmarks the given PyTorch model\n\t        \"\"\"\n\t        # Parse and \"overwrite\" the config for this nn.Module by merging any\n\t        # decorator based args with the benchmark_model function args\n\t        # (the decorator and \"this\" set of function arguments two\n", "        # take precedence).\n\t        benchmark_model_config = config_loader.parse_decorator_config(\n\t            decorator_dict=self.decorator_based_dict | benchmark_args\n\t        )\n\t        artifact_manager.update_artifact_metadata_section(\n\t            key=\"benchmark\", model_config=benchmark_model_config\n\t        )\n\t        # Workaround for ONNX output files for now.\n\t        benchmark_model_config.output_config_internal.onnx_output_filename = (\n\t            self.class_name + \".onnx\"\n", "        )\n\t        # Workaround for TorchScript output files for now.\n\t        benchmark_model_config.output_config_internal.torchscript_output_filename = (  # noqa: E501\n\t            self.class_name + \".pt\"\n\t        )\n\t        self.pytorch_export = PytorchExport(\n\t            model_config=benchmark_model_config,\n\t            artifact_manager=artifact_manager,\n\t        )\n\t        all_results: list[BenchmarkResult] = []\n", "        if benchmark_model_config.benchmark_config.enable_onnxruntime:\n\t            logger.info(\n\t                \"enable_onnxruntime option enabled, running benchmarks for ONNXRuntime...\"  # noqa: E501\n\t            )\n\t            # Export the model first.\n\t            export_output = self.export_model(\n\t                config_loader=config_loader,\n\t                artifact_manager=artifact_manager,\n\t                torch_model=torch_model,\n\t                input=input,\n", "            )\n\t            onnxruntime_benchmark = ONNXRuntimeBenchmark(\n\t                batch_size=benchmark_model_config.export_config.batch_size\n\t            )\n\t            onnxruntime_results = onnxruntime_benchmark.benchmark(\n\t                onnx_file=export_output.onnx.onnx_file,\n\t                input=to_numpy(input),\n\t                num_iterations=benchmark_model_config.benchmark_config.num_iterations,  # noqa: E501\n\t            )\n\t            all_results.extend(onnxruntime_results)\n", "        if benchmark_model_config.benchmark_config.enable_pytorch:\n\t            logger.info(\n\t                \"enable_pytorch option enabled, running benchmarks for PyTorch...\"  # noqa: E501\n\t            )\n\t            pytorch_benchmark = PyTorchBenchmark(\n\t                batch_size=benchmark_model_config.export_config.batch_size\n\t            )\n\t            pytorch_results = pytorch_benchmark.benchmark(\n\t                torch_model=torch_model,\n\t                input=input,\n", "                num_iterations=benchmark_model_config.benchmark_config.num_iterations,  # noqa: E501\n\t            )\n\t            all_results.extend(pytorch_results)\n\t        result_list_dict = [asdict(x) for x in all_results]\n\t        result_list_dict_total = []\n\t        for result_dict in result_list_dict:\n\t            temp_dict = result_dict[\"latency_metrics\"]\n\t            temp_dict.update(**result_dict)\n\t            temp_dict.pop(\"latency_metrics\")\n\t            result_list_dict_total.append(temp_dict)\n", "        if benchmark_model_config.output_config.enable_csv:\n\t            logger.info(\n\t                \"enable_csv option enabled, exporting benchmarks as CSV...\"\n\t            )\n\t            output_file_name = generate_output_csv_name(\n\t                name=torch_model.__class__.__name__\n\t            )\n\t            # Generate the output CSV in a /tmp directory then append it to\n\t            # artifact_manager list.\n\t            tmp_output_file = generate_output_csv_stream(\n", "                output_file_name=output_file_name,\n\t                input_list=result_list_dict_total,\n\t            )\n\t            artifact_manager.append(file=tmp_output_file)\n\t        if benchmark_model_config.output_config.enable_stdout:\n\t            logger.info(\"enable_stdout option enabled, flushing to stdout...\")\n\t            click.secho(\"Generated results:\", fg=\"yellow\", bold=True)\n\t            click.secho(\"-------------------\", fg=\"yellow\", bold=True)\n\t            click.secho(result_list_dict_total)\n\tdef Cellulose(\n", "    original_class=None,\n\t    **cellulose_decorator_args,\n\t):\n\t    if original_class is None:\n\t        return partial(Cellulose, **cellulose_decorator_args)\n\t    orig_init = original_class.__init__\n\t    def __init__(self, *args, **kws):\n\t        self.cellulose = _Cellulose(\n\t            original_class.__name__, **cellulose_decorator_args\n\t        )\n", "        orig_init(self, *args, **kws)  # Call the original __init__\n\t    original_class.__init__ = (\n\t        __init__  # Set the class' __init__ to the new one\n\t    )\n\t    return original_class\n"]}
{"filename": "examples/super_resolution_net_example.py", "chunked_list": ["# Third party imports\n\timport torch.onnx\n\timport torch.utils.model_zoo as model_zoo\n\tfrom torch import nn\n\tfrom torch.nn import init\n\t# Cellulose imports\n\tfrom cellulose.api.cellulose_context import CelluloseContext\n\tfrom cellulose.decorators.cellulose import Cellulose\n\t@Cellulose(\n\t    input_names=[\"input\"],\n", "    output_names=[\"output\"],\n\t)\n\tclass SuperResolutionNet(nn.Module):\n\t    def __init__(self, upscale_factor, inplace=False):\n\t        super(SuperResolutionNet, self).__init__()\n\t        self.relu = nn.ReLU(inplace=inplace)\n\t        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n\t        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n\t        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n\t        self.conv4 = nn.Conv2d(32, upscale_factor**2, (3, 3), (1, 1), (1, 1))\n", "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n\t        self._initialize_weights()\n\t    def forward(self, x):\n\t        x = self.relu(self.conv1(x))\n\t        x = self.relu(self.conv2(x))\n\t        x = self.relu(self.conv3(x))\n\t        x = self.pixel_shuffle(self.conv4(x))\n\t        return x\n\t    def _initialize_weights(self):\n\t        init.orthogonal_(self.conv1.weight, init.calculate_gain(\"relu\"))\n", "        init.orthogonal_(self.conv2.weight, init.calculate_gain(\"relu\"))\n\t        init.orthogonal_(self.conv3.weight, init.calculate_gain(\"relu\"))\n\t        init.orthogonal_(self.conv4.weight)\n\tif __name__ == \"__main__\":\n\t    # ----------------------- USER CODE START ------------------------------\n\t    # Create the super-resolution model by using the above model definition.\n\t    torch_model = SuperResolutionNet(upscale_factor=3)\n\t    BATCH_SIZE = 10\n\t    # Load pretrained model weights\n\t    model_url = \"https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth\"  # noqa: E501\n", "    # Initialize model with the pretrained weights\n\t    map_location = lambda storage, loc: storage  # noqa: E731\n\t    if torch.cuda.is_available():\n\t        map_location = None\n\t    torch_model.load_state_dict(\n\t        model_zoo.load_url(model_url, map_location=map_location)\n\t    )\n\t    # set the model to inference mode\n\t    torch_model.eval()\n\t    # Input to the model\n", "    input_tensor = torch.randn(BATCH_SIZE, 1, 224, 224, requires_grad=True)\n\t    # ------------------------ USER CODE END ---------------------------------\n\t    cellulose_context = CelluloseContext(\"YOUR_API_KEY\")\n\t    cellulose_context.export(\n\t        torch_model=torch_model,\n\t        input=input_tensor,\n\t    )\n\t    # This is needed to generate the Cellulose artifact.\n\t    cellulose_context.flush(name=\"exported_artifacts\", target_directory=\".\")\n"]}
