{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\tversion = open('VERSION').read().strip()\n\tlicense = open('LICENSE').read().strip()\n\tsetup(\n\t    name=\"pointstorm\",\n\t    version=version,\n\t    license=license,\n\t    description=\"Embedding vectors for data on the move\",\n\t    author=\"xsfa\",\n\t    author_email=\"tesfaaog@gmail.com\",\n", "    url=\"https://github.com/xsfa/pointstorm\",\n\t    packages=find_packages(),\n\t    install_requires=[\n\t        'bytewax==0.16.0',\n\t        'requests>=2.28.0',\n\t        'kafka-python==2.0.2',\n\t        'confluent-kafka',\n\t        'faker',\n\t        'transformers',\n\t        'torch',\n", "        'pydantic',\n\t        'unstructured'\n\t        'numpy',\n\t        'unittest'\n\t    ],\n\t    classifiers=[\n\t        \"Development Status :: 3 - Alpha\",\n\t        \"Intended Audience :: Developers\",\n\t        \"License :: OSI Approved :: Apache Software License\",\n\t        \"Programming Language :: Python :: 3\",\n", "        \"Programming Language :: Python :: 3.6\",\n\t        \"Programming Language :: Python :: 3.7\",\n\t        \"Programming Language :: Python :: 3.8\",\n\t        \"Programming Language :: Python :: 3.9\",\n\t    ],\n\t)\n"]}
{"filename": "pointstorm/config.py", "chunked_list": ["import logging\n\tabstract_logger = logging.getLogger(\"pointstorm_log\")\n\tabstract_logger.setLevel(logging.DEBUG)\n\tconsole_handler = logging.StreamHandler()\n\tconsole_handler.setLevel(logging.DEBUG)\n\tformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s: %(message)s\")\n\tconsole_handler.setFormatter(formatter)\n\tabstract_logger.addHandler(console_handler)"]}
{"filename": "pointstorm/__init__.py", "chunked_list": []}
{"filename": "pointstorm/monitoring.py", "chunked_list": []}
{"filename": "pointstorm/ingestion/__init__.py", "chunked_list": []}
{"filename": "pointstorm/ingestion/cdc/__init__.py", "chunked_list": []}
{"filename": "pointstorm/ingestion/cdc/debezium.py", "chunked_list": ["# ingesting debezium event\n\t# matching existing record on vector entry metadata"]}
{"filename": "pointstorm/ingestion/event/__init__.py", "chunked_list": []}
{"filename": "pointstorm/ingestion/event/kafka.py", "chunked_list": ["# Generic imports\n\timport json\n\timport logging\n\timport warnings\n\timport os\n\timport uuid\n\twarnings.filterwarnings(action = 'ignore')\n\t# Ingestion Imports\n\tfrom bytewax.testing import run_main\n\tfrom bytewax.dataflow import Dataflow\n", "from bytewax.connectors.kafka import KafkaInput\n\tfrom bytewax.connectors.stdio import StdOutput\n\t# from kafka import KafkaConsumer, TopicPartition\n\t# ML imports\n\tfrom transformers import AutoTokenizer, AutoModel\n\timport torch\n\t# Local imports\n\tfrom pointstorm.config import abstract_logger as kafka_logger\n\tfrom pointstorm.embedding.text import Document, generate_embedding\n\tclass KafkaIngestionException(Exception):\n", "    pass\n\tclass KafkaTextEmbeddings():\n\t    def __init__(self, kafka_topic, kafka_bootstrap_server, kafka_config, huggingface_model_name):\n\t        self.kafka_topic = kafka_topic\n\t        self.kafka_bootstrap_server = kafka_bootstrap_server\n\t        self.kafka_config = kafka_config\n\t        self.model_name = huggingface_model_name\n\t        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n\t        self.model = AutoModel.from_pretrained(self.model_name)\n\t    def set_output(self, output):\n", "        # TODO: Add output\n\t        self.output = output\n\t    def embedding(self, message) -> Document:\n\t        \"\"\"\n\t        Generating embedding using text embedding class\n\t        \"\"\"\n\t        if \"raw_text\" in json.loads(message[1]):\n\t            message = str(json.loads(message[1])[\"raw_text\"])\n\t        else:\n\t            raise KafkaIngestionException(\"Message does not contain the specified text field: \" + self.text_field)\n", "        doc = Document(\n\t            id=str(uuid.uuid4()),\n\t            group_key=\"group1\",\n\t            metadata={},\n\t            text=[message],\n\t            embeddings=[[]]\n\t        )\n\t        doc = generate_embedding(\n\t            document=doc, \n\t            tokenizer=self.tokenizer, \n", "            model=self.model\n\t        )\n\t        kafka_logger.info(f\"Generated embeddings for message: {message} ({doc.id}): {doc.embeddings}\")\n\t        return doc\n\t    def run(self):\n\t        input_config = KafkaInput(\n\t            brokers=[self.kafka_bootstrap_server],\n\t            topics=[self.kafka_topic],\n\t            add_config=self.kafka_config\n\t        )\n", "        kafka_logger.info(\"Started KafkaTextEmbeddings for topic: \" + self.kafka_topic)\n\t        flow = Dataflow()\n\t        flow.input(self.kafka_topic, input_config)\n\t        flow.map(self.embedding)\n\t        flow.output(\"stdout\", StdOutput())\n\t        run_main(flow)"]}
{"filename": "pointstorm/inputs/__init__.py", "chunked_list": []}
{"filename": "pointstorm/destinations/__init__.py", "chunked_list": []}
{"filename": "pointstorm/producers/text_producer.py", "chunked_list": ["import json\n\timport time\n\timport logging\n\timport random \n\tfrom confluent_kafka import Producer\n\tfrom faker import Faker\n\tlogger = logging.getLogger(__name__)\n\tclass TextProducer:\n\t    \"\"\"\n\t    Produce raw text data to Kafka Topic\n", "    \"\"\"\n\t    def __init__(self, kafka_topic, config):\n\t        self.topic = kafka_topic\n\t        self.config = config\n\t        self.producer = Producer(config)\n\t    def produce(self, text):\n\t        def receipt(err, msg):\n\t            if err is not None:\n\t                logger.error('Failed to deliver message: {}'.format(err.value()))\n\t            else:\n", "                message = 'Produced message on topic {} with value of {}\\n'.format(msg.topic(), msg.value().decode('utf-8'))\n\t                logger.info(message)\n\t                print(message)\n\t        data = {\n\t            \"msg_time\": time.time(),\n\t            \"raw_text\": text,\n\t        }\n\t        self.producer.poll(1)\n\t        self.producer.produce(self.topic, json.dumps(data).encode('utf-8'), callback=receipt)\n\t        self.producer.flush()"]}
{"filename": "pointstorm/producers/__init__.py", "chunked_list": []}
{"filename": "pointstorm/examples/__init__.py", "chunked_list": []}
{"filename": "pointstorm/examples/kafka/kafka_producer.py", "chunked_list": ["from pointstorm.producers.text_producer import TextProducer\n\tfrom faker import Faker\n\tfake = Faker()\n\t# Create Kafka Producer\n\tkafka_config = {\n\t    'bootstrap.servers':'localhost:9092',\n\t}\n\tkafka_topic = \"user-tracker2\"\n\tp = TextProducer(kafka_topic, kafka_config)\n\tprint('Kafka Producer has been initiated...')\n", "# Producing 10 random sentences to Kafka topic\n\tdef produce():    \n\t    for i in range(10):\n\t        # generating fake sentence\n\t        sentence = fake.sentence(nb_words=6, variable_nb_words=True, ext_word_list=None)\n\t        p.produce(sentence)\n\tproduce()"]}
{"filename": "pointstorm/examples/kafka/__init__.py", "chunked_list": []}
{"filename": "pointstorm/examples/kafka/run_kafka.py", "chunked_list": ["import os\n\tfrom pointstorm.ingestion.event.kafka import KafkaTextEmbeddings\n\tif __name__ == \"__main__\":\n\t    kafka_consumer_config = {\n\t        'group.id': f\"kafka_text_vectorizer\",\n\t        'auto.offset.reset': 'largest',\n\t        'enable.auto.commit': True\n\t    }\n\t    kafka_embeddings = KafkaTextEmbeddings(\n\t        kafka_topic=\"user-tracker2\",\n", "        kafka_bootstrap_server=\"localhost:9092\",\n\t        kafka_config=kafka_consumer_config,\n\t        huggingface_model_name= \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n\t    )\n\t    kafka_embeddings.run()"]}
{"filename": "pointstorm/embedding/text.py", "chunked_list": ["import hashlib\n\tfrom typing import List, Optional\n\tfrom pydantic import BaseModel\n\tfrom typing import Any, Optional\n\tfrom numpy import ndarray\n\tfrom transformers import AutoTokenizer, AutoModel\n\timport json\n\tfrom unstructured.partition.html import partition_html\n\tfrom unstructured.cleaners.core import clean, replace_unicode_quotes, clean_non_ascii_chars\n\tfrom unstructured.staging.huggingface import chunk_by_attention_window\n", "from unstructured.staging.huggingface import stage_for_transformers\n\timport hashlib\n\tfrom pydantic import BaseModel\n\tfrom typing import Any, Optional\n\tclass Document(BaseModel):\n\t    \"\"\"\n\t    Document object to be used for generating embeddings.\n\t    @params:\n\t        id: Unique identifier for the document.\n\t        group_key: Group key for the document.\n", "        metadata: Metadata for the document.\n\t        text: The text.\n\t        embeddings: Generated embeddings.\n\t    \"\"\"\n\t    id: str\n\t    group_key: Optional[str] = None\n\t    metadata: Optional[dict] = {}\n\t    text: Optional[list]\n\t    embeddings: Optional[list] = []\n\tdef generate_embedding(document: Document, tokenizer: AutoTokenizer, model: AutoModel) -> Document:\n", "    \"\"\"\n\t    Generate embedding for a given document using a pretrained model.\n\t    @params: \n\t        document: Document for which to generate the embeddings.\n\t    returns: \n\t        Document: Document object with updated embeddings.\n\t    \"\"\"\n\t    try:\n\t        inputs = tokenizer(\n\t            document.text,\n", "            padding=True,\n\t            truncation=True,\n\t            return_tensors=\"pt\",\n\t            max_length=384\n\t        )\n\t        result = model(**inputs)\n\t        embeddings = result.last_hidden_state[:, 0, :].cpu().detach().numpy()\n\t        flattened_embeddings = embeddings.flatten().tolist()\n\t        document.embeddings.append(flattened_embeddings)\n\t        return document\n", "    except Exception as e:\n\t        print(f\"An error occurred: {str(e)}\")\n\t        return None"]}
{"filename": "pointstorm/embedding/text_tests.py", "chunked_list": ["import unittest\n\tfrom pointstorm.embedding.text import Document, generate_embedding\n\tfrom unittest.mock import patch, MagicMock\n\tfrom transformers import AutoTokenizer, AutoModel\n\timport torch\n\tclass TestDocumentModel(unittest.TestCase):\n\t    def test_document_model_creation(self):\n\t        doc = Document(\n\t            id=\"123\",\n\t            group_key=\"group1\",\n", "            metadata={\"author\": \"John Doe\"},\n\t            text=[\"Hello, world!\"],\n\t            embeddings=[[]]\n\t        )\n\t        self.assertEqual(doc.id, \"123\")\n\t        self.assertEqual(doc.group_key, \"group1\")\n\t        self.assertEqual(doc.metadata, {\"author\": \"John Doe\"})\n\t        self.assertEqual(doc.text, [\"Hello, world!\"])\n\t        self.assertEqual(doc.embeddings, [[]])\n\t@patch(\"builtins.print\")\n", "class TestGenerateEmbedding(unittest.TestCase):\n\t    @patch.object(AutoTokenizer, 'from_pretrained')\n\t    @patch.object(AutoModel, 'from_pretrained')\n\t    def setUp(self, mock_model, mock_tokenizer):\n\t        self.mock_model = mock_model\n\t        self.mock_tokenizer = mock_tokenizer\n\t        self.document = Document(\n\t            id=\"123\",\n\t            group_key=\"group1\",\n\t            metadata={\"author\": \"John Doe\"},\n", "            text=[\"Hello, world!\"],\n\t            embeddings=[[]]\n\t        )\n\t    def test_generate_embedding_success(self, mock_print):\n\t        # Mocking the tokenizer and model return values\n\t        self.mock_tokenizer.return_value = {\"input_ids\": [1, 2, 3], \"attention_mask\": [1, 1, 1]}\n\t        self.mock_model.return_value = MagicMock(last_hidden_state=torch.tensor([[1, 2, 3]]))\n\t        # Create fake tokenizer and model\n\t        tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n\t        model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n", "        result = generate_embedding(document=self.document, tokenizer=tokenizer, model=model)\n\t        # Check that the function returned a Document\n\t        self.assertIsInstance(result, Document)\n\t        # Check that embeddings are there\n\t        self.assertGreaterEqual(len(result.embeddings), 1)\n\t# Run the tests\n\tif __name__ == '__main__':\n\t    unittest.main()"]}
{"filename": "pointstorm/embedding/__init__.py", "chunked_list": []}
