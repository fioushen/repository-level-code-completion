{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\t# read the contents of README.md\n\tfrom pathlib import Path\n\tthis_directory = Path(__file__).parent\n\tlong_description = (this_directory / \"README.md\").read_text()\n\t__version__ = '0.3.0'\n\tsetup(\n\t    name='mountainsort5',\n\t    version=__version__,\n\t    author=\"Jeremy Magland\",\n", "    author_email=\"jmagland@flatironinstitute.org\",\n\t    url=\"https://github.com/flatironinstitute/mountainsort5\",\n\t    description=\"MountainSort 5 spike sorting algorithm\",\n\t    long_description=long_description,\n\t    long_description_content_type='text/markdown',\n\t    packages=find_packages(),\n\t    install_requires=[\n\t        'spikeinterface>=0.97.1',\n\t        'isosplit6>=0.1.0',\n\t        'scikit-learn'\n", "    ],\n\t    tests_require=[\n\t        \"pytest\",\n\t        \"pytest-cov\"\n\t    ]\n\t)"]}
{"filename": "tests/test_scheme1.py", "chunked_list": ["import time\n\timport spikeinterface as si\n\timport spikeinterface.extractors as se\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\tdef test_scheme1():\n\t    recording, sorting_true = se.toy_example(\n\t        duration=20,\n\t        num_channels=8,\n", "        num_units=16,\n\t        sampling_frequency=30000,\n\t        num_segments=2,\n\t        seed=0\n\t    )\n\t    timer = time.time()\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n", "    print('Starting MountainSort5')\n\t    sorting = ms5.sorting_scheme1(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme1SortingParameters(\n\t            snippet_mask_radius=50\n\t        )\n\t    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n", "    # commenting out because this step takes a while\n\t    # print('Comparing with truth')\n\t    # comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    # print(comparison.get_performance())"]}
{"filename": "tests/test_scheme3.py", "chunked_list": ["import time\n\timport spikeinterface as si\n\timport spikeinterface.extractors as se\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\tdef test_scheme3():\n\t    recording, sorting_true = se.toy_example(\n\t        duration=20,\n\t        num_channels=8,\n", "        num_units=16,\n\t        sampling_frequency=30000,\n\t        num_segments=2,\n\t        seed=0\n\t    )\n\t    timer = time.time()\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n", "    print('Starting MountainSort5')\n\t    sorting = ms5.sorting_scheme3(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme3SortingParameters(\n\t            block_sorting_parameters=ms5.Scheme2SortingParameters(\n\t                phase1_detect_channel_radius=150,\n\t                detect_channel_radius=50\n\t            ),\n\t            block_duration_sec=3\n\t        )\n", "    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    # commenting out because this step takes a while\n\t    # print('Comparing with truth')\n\t    # comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    # print(comparison.get_performance())"]}
{"filename": "tests/test_scheme2.py", "chunked_list": ["import time\n\timport spikeinterface as si\n\timport spikeinterface.extractors as se\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\tdef test_scheme2():\n\t    recording, sorting_true = se.toy_example(\n\t        duration=40,\n\t        num_channels=8,\n", "        num_units=16,\n\t        sampling_frequency=30000,\n\t        num_segments=2,\n\t        seed=0\n\t    )\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n\t    print('Starting MountainSort5 (sorting1)')\n", "    timer = time.time()\n\t    sorting1, classifer1 = ms5.sorting_scheme2(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme2SortingParameters(\n\t            phase1_detect_channel_radius=150,\n\t            detect_channel_radius=50,\n\t            max_num_snippets_per_training_batch=3, # for improving test coverage\n\t            snippet_mask_radius=150,\n\t            training_duration_sec=15\n\t        ),\n", "        return_snippet_classifiers=True # for coverage\n\t    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    print('Starting MountainSort5 (sorting2)')\n\t    timer = time.time()\n\t    sorting2 = ms5.sorting_scheme2(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme2SortingParameters(\n", "            phase1_detect_channel_radius=150,\n\t            detect_channel_radius=50,\n\t            training_duration_sec=25,\n\t            training_recording_sampling_mode='uniform'\n\t        )\n\t    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    # commenting out because this step takes a while\n", "    # print('Comparing with truth')\n\t    # comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    # print(comparison.get_performance())\n\t# for coverage\n\tdef test_scheme2_single_segment():\n\t    recording, sorting_true = se.toy_example(\n\t        duration=4,\n\t        num_channels=4,\n\t        num_units=4,\n\t        sampling_frequency=30000,\n", "        num_segments=1,\n\t        seed=0\n\t    )\n\t    sorting1 = ms5.sorting_scheme2(\n\t        recording,\n\t        sorting_parameters=ms5.Scheme2SortingParameters(\n\t            phase1_detect_channel_radius=150,\n\t            detect_channel_radius=50,\n\t            max_num_snippets_per_training_batch=3, # for improving test coverage\n\t            snippet_mask_radius=150,\n", "            training_duration_sec=15,\n\t            classifier_npca=4\n\t        )\n\t    )"]}
{"filename": "tests/test_core.py", "chunked_list": ["import numpy as np\n\timport spikeinterface as si\n\timport spikeinterface.extractors as se\n\tfrom mountainsort5.core.compute_pca_features import compute_pca_features\n\tfrom mountainsort5.core.compute_templates import compute_templates\n\tfrom mountainsort5.core.detect_spikes import detect_spikes\n\tfrom mountainsort5.core.extract_snippets import extract_snippets, extract_snippets_in_channel_neighborhood\n\tfrom mountainsort5.core.get_sampled_recording_for_training import get_sampled_recording_for_training\n\tfrom mountainsort5.core.get_block_recording_for_scheme3 import get_block_recording_for_scheme3\n\tfrom mountainsort5.core.isosplit6_subdivision_method import isosplit6_subdivision_method\n", "from mountainsort5.core.get_times_labels_from_sorting import get_times_labels_from_sorting\n\tdef test_compute_pca_features():\n\t    x = np.random.normal(size=(100, 20))\n\t    features = compute_pca_features(x, npca=10)\n\t    assert features.shape == (100, 10)\n\tdef test_compute_templates():\n\t    L = 1000\n\t    T = 20\n\t    M = 10\n\t    snippets = np.random.normal(size=(L, T, M))\n", "    labels = np.random.randint(1, 11, size=(L,))\n\t    templates = compute_templates(snippets, labels)\n\t    assert templates.shape == (10, T, M)\n\tdef test_detect_spikes():\n\t    N = 100\n\t    M = 3\n\t    traces= np.zeros((N, M))\n\t    channel_locations = np.zeros((M, 2))\n\t    traces[8, 0] = -10 # in margin\n\t    traces[9, 1] = -4 # in margin\n", "    traces[30, 1] = -4\n\t    traces[31, 1] = -10\n\t    traces[40, 2] = -10\n\t    traces[41, 2] = -4\n\t    traces[98, 0] = -10 # in margin\n\t    times, channel_indices = detect_spikes(\n\t        traces,\n\t        channel_locations=channel_locations,\n\t        time_radius=10,\n\t        channel_radius=50,\n", "        detect_threshold=3,\n\t        detect_sign=-1,\n\t        margin_left=10,\n\t        margin_right=10,\n\t        verbose=False\n\t    )\n\t    assert len(times) == len(channel_indices) == 2\n\t    assert times[0] == 31\n\t    assert channel_indices[0] == 1\n\t    assert times[1] == 40\n", "    assert channel_indices[1] == 2\n\tdef test_extract_snippets():\n\t    N = 1000\n\t    M = 4\n\t    L = 100\n\t    T1 = 20\n\t    T2 = 20\n\t    T = T1 + T2\n\t    traces = np.random.normal(size=(N, M))\n\t    times = np.random.randint(T1, N - T2, size=(L,))\n", "    snippets = extract_snippets(traces, times=times, channel_locations=None, mask_radius=None, channel_indices=None, T1=T1, T2=T2)\n\t    assert snippets.shape == (L, T, M)\n\tdef test_extract_snippets_in_channel_neighborhood():\n\t    N = 1000\n\t    M = 4\n\t    L = 100\n\t    T1 = 20\n\t    T2 = 20\n\t    T = T1 + T2\n\t    traces = np.random.normal(size=(N, M))\n", "    times = np.random.randint(T1, N - T2, size=(L,))\n\t    neighborhood = [0, 2]\n\t    snippets = extract_snippets_in_channel_neighborhood(\n\t        traces=traces,\n\t        times=times,\n\t        neighborhood=neighborhood,\n\t        T1=T1,\n\t        T2=T2\n\t    )\n\t    assert snippets.shape == (L, T, len(neighborhood))\n", "def test_get_sampled_recording_for_training():\n\t    recording, _ = se.toy_example(duration=60, num_channels=4, num_units=10, sampling_frequency=30000, seed=0, num_segments=1)\n\t    recording: si.BaseRecording = recording\n\t    # test case where the training duration is longer than the recording duration\n\t    recording1 = get_sampled_recording_for_training(\n\t        recording=recording,\n\t        training_duration_sec=100,\n\t        mode='initial'\n\t    )\n\t    assert np.array_equal(\n", "        recording1.get_traces(),\n\t        recording.get_traces()\n\t    )\n\t    # test case where the training recording has only one chunk\n\t    recording1b = get_sampled_recording_for_training(\n\t        recording=recording,\n\t        training_duration_sec=7,\n\t        mode='uniform'\n\t    )\n\t    assert np.array_equal(\n", "        recording1b.get_traces(),\n\t        recording.get_traces(start_frame=0, end_frame=7 * recording.sampling_frequency)\n\t    )\n\t    # Test the mode='initial' case which is easier\n\t    recording2 = get_sampled_recording_for_training(\n\t        recording=recording,\n\t        training_duration_sec=25,\n\t        mode='initial'\n\t    )\n\t    assert recording2.get_num_frames() == 25 * recording.sampling_frequency\n", "    assert np.array_equal(\n\t        recording2.get_traces(),\n\t        recording.get_traces(start_frame=0, end_frame=25 * recording.sampling_frequency)\n\t    )\n\t    # Important to test mode='uniform' which can be tricky\n\t    recording3 = get_sampled_recording_for_training(\n\t        recording=recording,\n\t        training_duration_sec=25,\n\t        mode='uniform'\n\t    )\n", "    assert recording3.get_num_frames() == 25 * recording.sampling_frequency\n\t    assert np.array_equal(\n\t        recording3.get_traces(start_frame=0, end_frame=10 * recording.sampling_frequency),\n\t        recording.get_traces(start_frame=0, end_frame=10 * recording.sampling_frequency)\n\t    )\n\t    # 60 - 25 = 35\n\t    # spacing = 35 / 2 = 17.5\n\t    assert np.array_equal(\n\t        recording3.get_traces(start_frame=10 * recording.sampling_frequency, end_frame=20 * recording.sampling_frequency),\n\t        recording.get_traces(start_frame=int(27.5 * recording.sampling_frequency), end_frame=int(37.5 * recording.sampling_frequency))\n", "    )\n\t    # 37.5 + 17.5 = 55\n\t    assert np.array_equal(\n\t        recording3.get_traces(start_frame=20 * recording.sampling_frequency, end_frame=25 * recording.sampling_frequency),\n\t        recording.get_traces(start_frame=int(55 * recording.sampling_frequency), end_frame=int(60 * recording.sampling_frequency))\n\t    )\n\tdef test_get_block_recording_for_scheme3():\n\t    recording, _ = se.toy_example(duration=60, num_channels=4, num_units=10, sampling_frequency=30000, seed=0, num_segments=1)\n\t    recording: si.BaseRecording = recording\n\t    recording2 = get_block_recording_for_scheme3(\n", "        recording=recording,\n\t        start_frame=10 * recording.sampling_frequency,\n\t        end_frame=20 * recording.sampling_frequency\n\t    )\n\t    assert np.array_equal(\n\t        recording.get_traces(start_frame=10 * recording.sampling_frequency, end_frame=20 * recording.sampling_frequency),\n\t        recording2.get_traces()\n\t    )\n\tdef test_subdivision_cluster():\n\t    N = 1000\n", "    L = 100\n\t    M = 4\n\t    T1 = 20\n\t    T2 = 20\n\t    traces = np.random.normal(size=(N, M))\n\t    traces[500:] += 10 # offset this so we get more than one cluster (important for coverage of cluster_snippets)\n\t    times = np.random.randint(T1, N - T2, size=(L,))\n\t    snippets = extract_snippets(traces, times=times, channel_locations=None, mask_radius=None, channel_indices=None, T1=T1, T2=T2)\n\t    labels = isosplit6_subdivision_method(\n\t        snippets.reshape((L, M * (T1 + T2))),\n", "        npca_per_subdivision=10\n\t    )\n\t    assert np.min(labels) == 1\n\t    assert len(labels) == L\n\tdef test_get_times_labels_from_sorting():\n\t    recording, sorting = se.toy_example(duration=6, num_channels=4, num_units=10, sampling_frequency=30000, seed=0, num_segments=1)\n\t    recording: si.BaseRecording = recording\n\t    sorting: si.BaseSorting = sorting\n\t    times, labels = get_times_labels_from_sorting(sorting)\n\t    assert len(times) == len(labels)\n", "    assert len(np.unique(labels)) == sorting.get_num_units()\n\t    # test the case of an empty sorting\n\t    sorting2 = se.NumpySorting(sampling_frequency=30000)\n\t    times2, labels2 = get_times_labels_from_sorting(sorting2)\n\t    assert len(times2) == 0\n\t    assert len(labels2) == 0"]}
{"filename": "mountainsort5/__init__.py", "chunked_list": ["import importlib.metadata\n\t__version__ = importlib.metadata.version(\"mountainsort5\")\n\tfrom .schemes.sorting_scheme1 import sorting_scheme1\n\tfrom .schemes.Scheme1SortingParameters import Scheme1SortingParameters\n\tfrom .schemes.sorting_scheme2 import sorting_scheme2\n\tfrom .schemes.Scheme2SortingParameters import Scheme2SortingParameters\n\tfrom .schemes.sorting_scheme3 import sorting_scheme3\n\tfrom .schemes.Scheme3SortingParameters import Scheme3SortingParameters"]}
{"filename": "mountainsort5/core/get_times_labels_from_sorting.py", "chunked_list": ["from typing import Tuple\n\timport numpy as np\n\timport numpy.typing as npt\n\timport spikeinterface as si\n\tdef get_times_labels_from_sorting(sorting: si.BaseSorting) -> Tuple[npt.NDArray[np.int64], npt.NDArray[np.int32]]:\n\t    \"\"\"Get times and labels from a sorting object\n\t    Inputs:\n\t        sorting: a sorting object\n\t    Returns:\n\t        times: 1D array of spike times\n", "        labels: 1D array of spike labels\n\t    Example:\n\t        times, labels = get_times_labels_from_sorting(sorting)\n\t    \"\"\"\n\t    times_list = []\n\t    labels_list = []\n\t    for unit_id in sorting.get_unit_ids():\n\t        times0 = sorting.get_unit_spike_train(unit_id=unit_id)\n\t        labels0 = np.ones(times0.shape, dtype=np.int32) * unit_id\n\t        times_list.append(times0.astype(np.int64))\n", "        labels_list.append(labels0)\n\t    if len(times_list) > 0:\n\t        times = np.concatenate(times_list).astype(np.int64)\n\t        labels = np.concatenate(labels_list)\n\t        inds = np.argsort(times)\n\t        times = times[inds]\n\t        labels = labels[inds]\n\t        return times, labels\n\t    else:\n\t        return np.array([], dtype=np.int64), np.array([], dtype=np.int32)"]}
{"filename": "mountainsort5/core/get_block_recording_for_scheme3.py", "chunked_list": ["import spikeinterface as si\n\tfrom typing import Literal\n\tdef get_block_recording_for_scheme3(\n\t    recording: si.BaseRecording, *,\n\t    start_frame: int,\n\t    end_frame: int\n\t) -> si.BaseRecording:\n\t    return BlockRecording(\n\t        recording=recording,\n\t        start_frame=start_frame,\n", "        end_frame=end_frame\n\t    )\n\tclass BlockRecording(si.BaseRecording):\n\t    def __init__(self, recording: si.BaseRecording, start_frame: int, end_frame: int):\n\t        sampling_frequency = recording.get_sampling_frequency()\n\t        dtype = recording.get_dtype()\n\t        channel_ids = recording.get_channel_ids()\n\t        si.BaseRecording.__init__(self, sampling_frequency, channel_ids, dtype)\n\t        self.start_frame = start_frame\n\t        self.end_frame = end_frame\n", "        self.set_channel_locations(recording.get_channel_locations())\n\t        self.is_dumpable = False\n\t        self.add_recording_segment(\n\t            BlockRecordingSegment(recording=recording, start_frame=start_frame, end_frame=end_frame)\n\t        )\n\t        self._kwargs = {'recording': recording, 'start_frame': start_frame, 'end_frame': end_frame}\n\tclass BlockRecordingSegment(si.BaseRecordingSegment):\n\t    def __init__(self, recording: si.BaseRecording, start_frame: int, end_frame: int):\n\t        si.BaseRecordingSegment.__init__(\n\t            self,\n", "            sampling_frequency=recording.get_sampling_frequency(),\n\t            t_start=0\n\t        )\n\t        self._recording = recording\n\t        self._start_frame = start_frame\n\t        self._end_frame = end_frame\n\t    def get_num_samples(self):\n\t        return self._end_frame - self._start_frame\n\t    def get_traces(self, start_frame, end_frame, channel_indices):\n\t        if start_frame is None:\n", "            start_frame = 0\n\t        if end_frame is None:\n\t            end_frame = self.get_num_samples()\n\t        # Get the traces from the parent recording\n\t        return self._recording._recording_segments[0].get_traces(\n\t            start_frame=start_frame + self._start_frame,\n\t            end_frame=end_frame + self._start_frame,\n\t            channel_indices=channel_indices\n\t        )"]}
{"filename": "mountainsort5/core/extract_snippets.py", "chunked_list": ["from typing import Union, List\n\timport numpy as np\n\timport numpy.typing as npt\n\tdef extract_snippets(\n\t    traces: npt.NDArray[np.float32], *,\n\t    channel_locations: Union[npt.NDArray[np.float32], None],\n\t    mask_radius: Union[float, None],\n\t    times: npt.NDArray[np.int32],\n\t    channel_indices: Union[npt.NDArray[np.int32], None],\n\t    T1: int,\n", "    T2: int\n\t) -> npt.NDArray[np.float32]:\n\t    M = traces.shape[1]\n\t    L = len(times)\n\t    if mask_radius is not None:\n\t        assert channel_locations is not None\n\t        assert channel_indices is not None\n\t        adjacency = []\n\t        for m in range(M):\n\t            adjacency.append([])\n", "            for m2 in range(M):\n\t                dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n\t                if dist0 <= mask_radius:\n\t                    adjacency[m].append(m2)\n\t    else:\n\t        adjacency = None\n\t    snippets = np.zeros((L, T1 + T2, M), dtype=np.float32)\n\t    for j in range(L):\n\t        t1 = times[j] - T1\n\t        t2 = times[j] + T2\n", "        if adjacency is not None:\n\t            assert channel_indices is not None\n\t            channel_inds = adjacency[channel_indices[j]]\n\t            snippets[j][:, channel_inds] = traces[t1:t2, channel_inds]\n\t        else:\n\t            snippets[j] = traces[t1:t2]\n\t    return snippets\n\tdef extract_snippets_in_channel_neighborhood(\n\t    traces: npt.NDArray[np.float32], *,\n\t    times: npt.NDArray[np.int32],\n", "    neighborhood: Union[List[int], None],\n\t    T1: int,\n\t    T2: int\n\t) -> np.ndarray:\n\t    L = len(times)\n\t    if neighborhood is None:\n\t        neighborhood = list(range(traces.shape[1]))\n\t    snippets = np.zeros((L, T1 + T2, len(neighborhood)), dtype=np.float32)\n\t    for j in range(L):\n\t        t1 = times[j] - T1\n", "        t2 = times[j] + T2\n\t        snippets[j] = traces[t1:t2][:, neighborhood]\n\t    return snippets"]}
{"filename": "mountainsort5/core/compute_templates.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\tdef compute_templates(snippets: npt.NDArray[np.float32], labels: np.int32):\n\t    # L = snippets.shape[0]\n\t    T = snippets.shape[1]\n\t    M = snippets.shape[2]\n\t    K = np.max(labels)\n\t    templates = np.zeros((K, T, M), dtype=np.float32)\n\t    for k in range(1, K + 1):\n\t        snippets1 = snippets[labels == k]\n", "        templates[k - 1] = np.median(snippets1, axis=0)\n\t    return templates\n"]}
{"filename": "mountainsort5/core/compute_pca_features.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\tfrom sklearn import decomposition\n\tdef compute_pca_features(X: npt.NDArray[np.float32], *, npca: int):\n\t    pca = decomposition.PCA(n_components=np.minimum(npca, X.shape[0]))\n\t    return pca.fit_transform(X)"]}
{"filename": "mountainsort5/core/remove_duplicate_events.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\tdef remove_duplicate_events(times: npt.NDArray[np.int32], labels: npt.NDArray[np.int32], *, tol: int) -> npt.NDArray[np.int32]:\n\t    new_labels = np.array(labels)\n\t    unit_ids = np.unique(new_labels)\n\t    for unit_id in unit_ids:\n\t        unit_inds = np.nonzero(new_labels == unit_id)[0]\n\t        unit_times = times[unit_inds]\n\t        inds_duplicate = find_duplicate_times(unit_times, tol=tol)\n\t        new_labels[unit_inds[inds_duplicate]] = 0\n", "    inds_nonzero = np.nonzero(new_labels)[0]\n\t    return inds_nonzero\n\tdef find_duplicate_times(times: npt.NDArray[np.int32], *, tol: int) -> npt.NDArray[np.int32]:\n\t    ret: list[np.int32] = []\n\t    deleted = np.zeros((len(times),), dtype=np.int16)\n\t    for i1 in range(len(times)):\n\t        if not deleted[i1]:\n\t            i2 = i1 + 1\n\t            while i2 < len(times) and times[i2] <= times[i1] + tol:\n\t                ret.append(i2)\n", "                deleted[i2] = True\n\t                i2 += 1\n\t    return np.array(ret, dtype=np.int32)"]}
{"filename": "mountainsort5/core/isosplit6_subdivision_method.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\timport warnings\n\tfrom scipy.cluster.hierarchy import ClusterWarning\n\tfrom isosplit6 import isosplit6\n\tfrom .compute_pca_features import compute_pca_features\n\twarnings.filterwarnings('ignore', category=ClusterWarning)\n\tfrom typing import Union\n\tdef isosplit6_subdivision_method(\n\t    X: npt.NDArray[np.float32], *,\n", "    npca_per_subdivision: int,\n\t    inds: Union[npt.NDArray[np.int32], None]=None # pass in inds so that we don't keep making copies of the array\n\t):\n\t    if inds is not None:\n\t        X_sub = X[inds]\n\t    else:\n\t        X_sub = X\n\t    L = X_sub.shape[0]\n\t    features = compute_pca_features(X_sub, npca=npca_per_subdivision)\n\t    labels = isosplit6(features)\n", "    K = np.max(labels)\n\t    if K <= 1:\n\t        return labels\n\t    centroids = np.zeros((K, X.shape[1]), dtype=np.float32)\n\t    for k in range(1, K + 1):\n\t        centroids[k - 1] = np.median(X_sub[labels == k], axis=0)\n\t    X_sub = None # free up memory\n\t    dists_between_centroids = np.sqrt(np.sum((centroids[:, None, :] - centroids[None, :, :]) ** 2, axis=2))\n\t    # hierarchical clustering\n\t    from scipy.cluster.hierarchy import linkage, cut_tree\n", "    Z = linkage(dists_between_centroids, method='single', metric='euclidean')\n\t    clusters0 = cut_tree(Z, n_clusters=2)\n\t    cluster_inds_1 = np.where(clusters0 == 0)[0] + 1\n\t    cluster_inds_2 = np.where(clusters0 == 1)[0] + 1\n\t    inds1 = np.where(np.isin(labels, cluster_inds_1))[0]\n\t    inds2 = np.where(np.isin(labels, cluster_inds_2))[0]\n\t    if inds is not None:\n\t        inds1_b = inds[inds1]\n\t        inds2_b = inds[inds2]\n\t    else:\n", "        inds1_b = inds1\n\t        inds2_b = inds2\n\t    labels1 = isosplit6_subdivision_method(X, npca_per_subdivision=npca_per_subdivision, inds=inds1_b)\n\t    labels2 = isosplit6_subdivision_method(X, npca_per_subdivision=npca_per_subdivision, inds=inds2_b)\n\t    K1 = np.max(labels1)\n\t    K2 = np.max(labels2)\n\t    ret_labels = np.zeros(L, dtype=np.int32)\n\t    ret_labels[inds1] = labels1\n\t    ret_labels[inds2] = labels2 + K1\n\t    return ret_labels"]}
{"filename": "mountainsort5/core/__init__.py", "chunked_list": []}
{"filename": "mountainsort5/core/SnippetClassifier.py", "chunked_list": ["from typing import List, Tuple, Union, Dict\n\timport numpy as np\n\timport numpy.typing as npt\n\tfrom dataclasses import dataclass\n\tfrom sklearn import decomposition\n\tfrom sklearn.neighbors import NearestNeighbors\n\tclass SnippetClassifier:\n\t    def __init__(self, npca: Union[int, None]) -> None:\n\t        self.npca = npca\n\t        self.training_batches: List[TrainingBatch] = []\n", "        self.pca_model = None\n\t    def add_training_snippets(self, snippets: npt.NDArray[np.float32], label: int, offset: int):\n\t        self.training_batches.append(TrainingBatch(snippets=snippets, label=label, offset=offset))\n\t    def fit(self):\n\t        if len(self.training_batches) == 0:\n\t            raise Exception('No training batches added for classifier.') # pragma: no cover\n\t        all_training_snippets = np.concatenate([b.snippets for b in self.training_batches], axis=0)\n\t        L = all_training_snippets.shape[0]\n\t        self.T = all_training_snippets.shape[1]\n\t        self.M = all_training_snippets.shape[2]\n", "        self.all_training_labels = np.concatenate([np.ones((b.num_snippets,), dtype=np.int32) * b.label for b in self.training_batches])\n\t        self.all_training_offsets = np.concatenate([np.ones((b.num_snippets,), dtype=np.int32) * b.offset for b in self.training_batches])\n\t        if self.npca is not None:\n\t            effective_npca = self.npca\n\t        else:\n\t            effective_npca = max(12, self.M * 3)\n\t        self.pca_model = decomposition.PCA(n_components=min(effective_npca, L))\n\t        self.pca_model.fit(all_training_snippets.reshape(L, self.T * self.M))\n\t        X = self.pca_model.transform(all_training_snippets.reshape(L, self.T * self.M))\n\t        self.nearest_neighbor_model = NearestNeighbors(n_neighbors=2)\n", "        self.nearest_neighbor_model.fit(X)\n\t    def classify_snippets(self, snippets: npt.NDArray[np.float32]) -> Tuple[Union[npt.NDArray[np.int32], None], Union[npt.NDArray[np.int32], None]]:\n\t        if self.pca_model is None:\n\t            raise Exception('self.pca_model is None, which probably means that fit() was not called.') # pragma: no cover\n\t        Y = self.pca_model.transform(snippets.reshape(snippets.shape[0], self.T * self.M))\n\t        nearest_inds = self.nearest_neighbor_model.kneighbors(Y, n_neighbors=2, return_distance=False)\n\t        inds = nearest_inds[:, 1] # don't use the first because that could be an identical match\n\t        return self.all_training_labels[inds], self.all_training_offsets[inds]\n\t    def apply_label_mapping(self, mapping: Dict[int, int]):\n\t        for k1, k2 in mapping.items():\n", "            self.all_training_labels[self.all_training_labels == k1] = k2\n\t@dataclass\n\tclass TrainingBatch:\n\t    snippets: npt.NDArray[np.float32]\n\t    label: int\n\t    offset: int\n\t    @property\n\t    def num_snippets(self):\n\t        return self.snippets.shape[0]"]}
{"filename": "mountainsort5/core/get_sampled_recording_for_training.py", "chunked_list": ["import spikeinterface as si\n\timport numpy as np\n\tfrom typing import Literal\n\tdef get_sampled_recording_for_training(\n\t    recording: si.BaseRecording, *,\n\t    training_duration_sec: float,\n\t    mode: Literal['initial', 'uniform'] = 'initial'\n\t) -> si.BaseRecording:\n\t    \"\"\"Get a sampled recording for the purpose of training\n\t    Args:\n", "        recording (si.BaseRecording): SpikeInterface recording object\n\t        training_duration_sec (float): Duration of the training in seconds\n\t        mode (str): 'initial' or 'uniform'\n\t    Returns:\n\t        si.BaseRecording: SpikeInterface recording object\n\t    \"\"\"\n\t    if training_duration_sec * recording.sampling_frequency >= recording.get_num_frames():\n\t        # if the training duration is longer than the recording, then just use the entire recording\n\t        return recording\n\t    if mode == 'initial':\n", "        traces = recording.get_traces(start_frame=0, end_frame=int(training_duration_sec * recording.sampling_frequency))\n\t    elif mode == 'uniform':\n\t        # use chunks of 10 seconds\n\t        chunk_size = int(recording.sampling_frequency * min(10, training_duration_sec))\n\t        # the number of chunks depends on the training duration\n\t        num_chunks = int(np.ceil(training_duration_sec * recording.sampling_frequency / chunk_size))\n\t        chunk_sizes = [chunk_size for i in range(num_chunks)]\n\t        chunk_sizes[-1] = int(training_duration_sec * recording.sampling_frequency - (num_chunks - 1) * chunk_size)\n\t        if num_chunks == 1:\n\t            # if only 1 chunk, then just use the initial chunk\n", "            traces = recording.get_traces(start_frame=0, end_frame=int(training_duration_sec * recording.sampling_frequency))\n\t        else:\n\t            # the spacing between the chunks\n\t            spacing = int((recording.get_num_frames() - np.sum(chunk_sizes)) / (num_chunks - 1))\n\t            traces_list: list[np.ndarray] = []\n\t            tt = 0\n\t            for i in range(num_chunks):\n\t                start_frame = tt\n\t                end_frame = int(start_frame + chunk_sizes[i])\n\t                traces_list.append(recording.get_traces(start_frame=start_frame, end_frame=end_frame))\n", "                tt += int(chunk_sizes[i] + spacing)\n\t            traces = np.concatenate(traces_list, axis=0)\n\t    else:\n\t        raise Exception('Invalid mode: ' + mode) # pragma: no cover\n\t    rec = si.NumpyRecording(\n\t        traces_list=[traces],\n\t        sampling_frequency=recording.sampling_frequency,\n\t        channel_ids=recording.get_channel_ids()\n\t    )\n\t    rec.set_channel_locations(recording.get_channel_locations())\n", "    return rec"]}
{"filename": "mountainsort5/core/detect_spikes.py", "chunked_list": ["from typing import Tuple, Union\n\timport numpy as np\n\timport numpy.typing as npt\n\tdef detect_spikes(\n\t    traces: npt.NDArray[np.float32], *,\n\t    channel_locations: npt.NDArray[np.float32],\n\t    time_radius: int,\n\t    channel_radius: Union[float, None],\n\t    detect_threshold: float,\n\t    detect_sign: int,\n", "    margin_left: int,\n\t    margin_right: int,\n\t    verbose: bool\n\t) -> Tuple[npt.NDArray[np.int32], npt.NDArray[np.int32]]:\n\t    N = traces.shape[0]\n\t    M = traces.shape[1]\n\t    if detect_sign > 0:\n\t        # todo: figure out how to avoid making a copy\n\t        traces = -traces # pragma: no cover\n\t    elif detect_sign == 0:\n", "        # todo: figure out how to avoid making a copy\n\t        traces = -np.abs(traces) # pragma: no cover\n\t    adjacency = []\n\t    for m in range(M):\n\t        adjacency.append([])\n\t        for m2 in range(M):\n\t            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n\t            if (channel_radius is None) or (dist0 <= channel_radius):\n\t                adjacency[m].append(m2)\n\t    print('')\n", "    print(f'Adjacency for detect spikes with channel radius {channel_radius}')\n\t    print(adjacency)\n\t    print('')\n\t    inds1, inds2 = np.nonzero(traces <= -detect_threshold)\n\t    candidate_times = [[] for m in range(M)]\n\t    candidate_values = [[] for m in range(M)]\n\t    for i in range(len(inds1)):\n\t        if inds1[i] >= margin_left and inds1[i] < N - margin_right:\n\t            candidate_times[inds2[i]].append(inds1[i])\n\t            candidate_values[inds2[i]].append(traces[inds1[i], inds2[i]])\n", "    times = []\n\t    channel_indices = []\n\t    for m in range(M):\n\t        nbhd = adjacency[m]\n\t        if verbose:\n\t            print(f'm = {m} (nbhd size: {len(nbhd)})')\n\t        indices = [0 for j in range(len(nbhd))]\n\t        for i in range(len(candidate_times[m])):\n\t            t = candidate_times[m][i]\n\t            v = candidate_values[m][i]\n", "            okay = True\n\t            for j in range(len(nbhd)):\n\t                if not okay:\n\t                    break\n\t                tt = candidate_times[nbhd[j]]\n\t                vv = candidate_values[nbhd[j]]\n\t                ii = indices[j]\n\t                while ii < len(tt) and tt[ii] < t - time_radius:\n\t                    ii += 1\n\t                indices[j] = ii # advance\n", "                jj = ii\n\t                while jj < len(tt) and tt[jj] <= t + time_radius:\n\t                    if vv[jj] < v:\n\t                        okay =False\n\t                        break\n\t                    jj += 1\n\t            if okay:\n\t                times.append(t)\n\t                channel_indices.append(m)\n\t    times = np.array(times, dtype=np.int32)\n", "    channel_indices = np.array(channel_indices, dtype=np.int32)\n\t    inds = np.argsort(times)\n\t    times = times[inds]\n\t    channel_indices = channel_indices[inds]\n\t    return times, channel_indices\n"]}
{"filename": "mountainsort5/schemes/Scheme3SortingParameters.py", "chunked_list": ["import numpy as np\n\tfrom typing import Union, Literal\n\tfrom dataclasses import dataclass\n\tfrom .Scheme2SortingParameters import Scheme2SortingParameters\n\t@dataclass\n\tclass Scheme3SortingParameters:\n\t    \"\"\"Parameters for MountainSort sorting scheme 3\n\t    - block_sorting_parameters: Scheme2SortingParameters for individual blocks\n\t    - block_duration_sec: duration of each block\n\t    \"\"\"\n", "    block_sorting_parameters: Scheme2SortingParameters\n\t    block_duration_sec: float\n\t    def check_valid(self, *, M: int, N: int, sampling_frequency: float, channel_locations: Union[np.ndarray, None]=None):\n\t        \"\"\"Internal function for checking validity of parameters\"\"\"\n\t        self.block_sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n\t        assert self.block_duration_sec > 0\n"]}
{"filename": "mountainsort5/schemes/sorting_scheme3.py", "chunked_list": ["from typing import Dict, Union\n\timport numpy as np\n\timport numpy.typing as npt\n\timport spikeinterface as si\n\tfrom .Scheme3SortingParameters import Scheme3SortingParameters\n\tfrom .sorting_scheme2 import get_time_chunks\n\tfrom .sorting_scheme2 import sorting_scheme2, get_times_labels_from_sorting\n\tfrom ..core.get_block_recording_for_scheme3 import get_block_recording_for_scheme3\n\tfrom ..core.SnippetClassifier import SnippetClassifier\n\tfrom ..core.get_times_labels_from_sorting import get_times_labels_from_sorting\n", "def sorting_scheme3(\n\t    recording: si.BaseRecording, *,\n\t    sorting_parameters: Scheme3SortingParameters\n\t) -> si.BaseSorting:\n\t    \"\"\"MountainSort 5 sorting scheme 3\n\t    Args:\n\t        recording (si.BaseRecording): SpikeInterface recording object\n\t        sorting_parameters (Scheme3SortingParameters): Sorting parameters\n\t    Returns:\n\t        si.BaseSorting: SpikeInterface sorting object\n", "    \"\"\"\n\t    ###################################################################\n\t    # Handle multi-segment recordings\n\t    if recording.get_num_segments() > 1:\n\t        print('Recording has multiple segments. Joining segments for sorting...')\n\t        recording_joined = si.concatenate_recordings(recording_list=[recording])\n\t        sorting_joined = sorting_scheme3(recording_joined, sorting_parameters=sorting_parameters)\n\t        print('Splitting sorting into segments to match original multisegment recording...')\n\t        sorting = si.split_sorting(sorting_joined, recording_joined)\n\t        return sorting\n", "    ###################################################################\n\t    M = recording.get_num_channels()\n\t    N = recording.get_num_frames()\n\t    sampling_frequency = recording.sampling_frequency\n\t    channel_locations = recording.get_channel_locations()\n\t    sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n\t    block_size = int(sorting_parameters.block_duration_sec * sampling_frequency) # size of chunks in samples\n\t    blocks = get_time_chunks(recording.get_num_samples(), chunk_size=block_size, padding=1000)\n\t    times_list: list[npt.NDArray[np.int64]] = []\n\t    labels_list: list[npt.NDArray[np.int32]] = []\n", "    last_label_used = 0\n\t    previous_snippet_classifiers: Union[Dict[int, SnippetClassifier], None] = None\n\t    for i, chunk in enumerate(blocks):\n\t        print('')\n\t        print('=============================================')\n\t        print(f'Processing block {i + 1} of {len(blocks)}...')\n\t        subrecording = get_block_recording_for_scheme3(recording=recording, start_frame=chunk.start - chunk.padding_left, end_frame=chunk.end + chunk.padding_right)\n\t        subsorting, snippet_classifiers = sorting_scheme2(\n\t            subrecording,\n\t            sorting_parameters=sorting_parameters.block_sorting_parameters,\n", "            return_snippet_classifiers=True,\n\t            reference_snippet_classifiers=previous_snippet_classifiers,\n\t            label_offset=last_label_used\n\t        )\n\t        previous_snippet_classifiers = snippet_classifiers\n\t        times0, labels0 = get_times_labels_from_sorting(subsorting)\n\t        valid_inds = np.where((times0 >= chunk.padding_left) & (times0 < chunk.padding_left + (chunk.end - chunk.start)))[0]\n\t        times0: npt.NDArray[np.int32] = times0[valid_inds]\n\t        labels0: npt.NDArray[np.int32] = labels0[valid_inds]\n\t        times0 = times0.astype(np.int64) + chunk.start - np.int64(chunk.padding_left)\n", "        if len(labels0) > 0:\n\t            last_label_used = max(last_label_used, np.max(labels0))\n\t        times_list.append(times0)\n\t        labels_list.append(labels0)\n\t    times_concat = np.concatenate(times_list)\n\t    labels_concat = np.concatenate(labels_list)\n\t    # Now create a new sorting object from the times and labels results\n\t    sorting2 = si.NumpySorting.from_times_labels([times_concat], [labels_concat], sampling_frequency=recording.sampling_frequency)\n\t    return sorting2"]}
{"filename": "mountainsort5/schemes/__init__.py", "chunked_list": []}
{"filename": "mountainsort5/schemes/Scheme2SortingParameters.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\tfrom typing import Union, Literal\n\tfrom dataclasses import dataclass\n\t@dataclass\n\tclass Scheme2SortingParameters:\n\t    \"\"\"Parameters for MountainSort sorting scheme 2\n\t    See Scheme1SortingParameters for more details on the parameters below.\n\t    - phase1_detect_channel_radius: detect_channel_radius in phase 1\n\t    - detect_channel_radius: detect_channel_radius in phase 2\n", "    - phase1_detect_threshold: detect_threshold in phase 1\n\t    - phase1_detect_time_radius_msec: detect_time_radius_msec in phase 1\n\t    - detect_time_radius_msec: detect_time_radius_msec in phase 2\n\t    - phase1_npca_per_channel: npca_per_channel in phase 1\n\t    - phase1_npca_per_subdivision: npca_per_subdivision in phase 1\n\t    - detect_sign\n\t    - detect_threshold: detect_threshold in phase 2\n\t    - snippet_T1\n\t    - snippet_T2\n\t    - snippet_mask_radius\n", "    - max_num_snippets_per_training_batch: the maximum number of snippets to use for training the classifier in each batch\n\t    - classifier_npca: the number of principal components to use for each neighborhood classifier\n\t    - training_duration_sec: the duration of the training data (in seconds)\n\t    - training_recording_sampling_mode: how to sample the training data. If 'initial', then the first training_duration_sec of the recording will be used. If 'uniform', then the training data will be sampled uniformly in 10-second chunks from the recording.\n\t    \"\"\"\n\t    phase1_detect_channel_radius: Union[float, None]\n\t    detect_channel_radius: Union[float, None]\n\t    phase1_detect_threshold: float=5.5\n\t    phase1_detect_time_radius_msec: float=1.5\n\t    detect_time_radius_msec: float=0.5\n", "    phase1_npca_per_channel: int=3\n\t    phase1_npca_per_subdivision: int=10\n\t    subdivision: int=10\n\t    phase1_pairwise_merge_step: bool=False # deprecated\n\t    detect_sign: int=-1\n\t    detect_threshold: float=5.5\n\t    snippet_T1: int=20\n\t    snippet_T2: int=20\n\t    snippet_mask_radius: Union[float, None]=None\n\t    max_num_snippets_per_training_batch: int=200\n", "    classifier_npca: Union[int, None]=None\n\t    training_duration_sec: Union[float, None]=None\n\t    training_recording_sampling_mode: Literal['initial', 'uniform']='initial'\n\t    def check_valid(self, *, M: int, N: int, sampling_frequency: float, channel_locations: npt.NDArray[np.float32]):\n\t        \"\"\"Internal function for checking validity of parameters\"\"\"\n\t        assert channel_locations.shape[0] == M, 'Shape mismatch between traces and channel locations'\n\t        D = channel_locations.shape[1]\n\t        assert N >= self.snippet_T1 + self.snippet_T2\n\t        if self.snippet_mask_radius is not None:\n\t            assert self.snippet_mask_radius >= 0\n", "        assert M >= 1 and M < 1e6\n\t        assert D >= 1 and D <= 3\n\t        assert sampling_frequency > 0 and sampling_frequency <= 1e7\n\t        if self.phase1_detect_channel_radius is not None:\n\t            assert self.phase1_detect_channel_radius > 0\n\t        assert self.phase1_detect_time_radius_msec > 0 and self.phase1_detect_time_radius_msec <= 1e4\n\t        assert self.phase1_detect_threshold > 0\n\t        assert self.detect_sign in [-1, 0, 1]\n\t        assert self.phase1_npca_per_channel >=1 and self.phase1_npca_per_channel <= 1e3\n\t        assert self.phase1_npca_per_subdivision >= 1 and self.phase1_npca_per_subdivision <= 1e3\n"]}
{"filename": "mountainsort5/schemes/Scheme1SortingParameters.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\tfrom typing import Union\n\tfrom dataclasses import dataclass\n\t@dataclass\n\tclass Scheme1SortingParameters:\n\t    \"\"\"Parameters for MountainSort sorting scheme 1\n\t    - detect_threshold: the threshold for detection of whitened data\n\t    - detect_channel_radius: the radius (in units of channel locations) for exluding nearby channels from detection\n\t    - detect_time_radius_msec: the radius (in msec) for excluding nearby events from detection\n", "    - detect_sign: the sign of the threshold for detection (1, -1, or 0)\n\t    - snippet_T1: the number of timepoints before the event to include in the snippet\n\t    - snippet_T2: the number of timepoints after the event to include in the snippet\n\t    - snippet_mask_radius: the radius (in units of channel locations) for making a snippet around the central channel\n\t    - npca_per_channel: the number of PCA components per channel for initial dimension reduction\n\t    - npca_per_subdivision: the number of PCA components to compute for each subdivision of clustering\n\t    \"\"\"\n\t    detect_threshold: float=5.5\n\t    detect_channel_radius: Union[float, None]=None\n\t    detect_time_radius_msec: float=0.5\n", "    detect_sign: int=-1\n\t    snippet_T1: int=20\n\t    snippet_T2: int=20\n\t    snippet_mask_radius: Union[float, None]=None\n\t    npca_per_channel: int=3\n\t    npca_per_subdivision: int=10\n\t    pairwise_merge_step: bool=False # deprecated\n\t    def check_valid(self, *, M: int, N: int, sampling_frequency: float, channel_locations: npt.NDArray[np.float32]):\n\t        \"\"\"Internal function for checking validity of parameters\"\"\"\n\t        assert channel_locations.shape[0] == M, 'Shape mismatch between traces and channel locations'\n", "        D = channel_locations.shape[1]\n\t        assert N >= self.snippet_T1 + self.snippet_T2\n\t        if self.snippet_mask_radius is not None:\n\t            assert self.snippet_mask_radius >= 0\n\t        assert M >= 1 and M < 1e6\n\t        assert D >= 1 and D <= 3\n\t        assert sampling_frequency > 0 and sampling_frequency <= 1e7\n\t        if self.detect_channel_radius is not None:\n\t            assert self.detect_channel_radius > 0\n\t        assert self.detect_time_radius_msec > 0 and self.detect_time_radius_msec <= 1e4\n", "        assert self.detect_threshold > 0\n\t        assert self.detect_sign in [-1, 0, 1]\n\t        assert self.npca_per_channel >= 1 and self.npca_per_channel <= 1e3\n\t        assert self.npca_per_subdivision >= 1 and self.npca_per_subdivision <= 1e3\n"]}
{"filename": "mountainsort5/schemes/sorting_scheme1.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\timport math\n\timport spikeinterface as si\n\tfrom .Scheme1SortingParameters import Scheme1SortingParameters\n\tfrom ..core.detect_spikes import detect_spikes\n\tfrom ..core.extract_snippets import extract_snippets\n\tfrom ..core.isosplit6_subdivision_method import isosplit6_subdivision_method\n\tfrom ..core.compute_templates import compute_templates\n\tfrom ..core.compute_pca_features import compute_pca_features\n", "def sorting_scheme1(\n\t    recording: si.BaseRecording, *,\n\t    sorting_parameters: Scheme1SortingParameters\n\t):\n\t    \"\"\"MountainSort 5 sorting scheme 1\n\t    Args:\n\t        recording (si.BaseRecording): SpikeInterface recording object\n\t        sorting_parameters (Scheme2SortingParameters): Sorting parameters\n\t    Returns:\n\t        si.BaseSorting: SpikeInterface sorting object\n", "    \"\"\"\n\t    ###################################################################\n\t    # Handle multi-segment recordings\n\t    if recording.get_num_segments() > 1:\n\t        print('Recording has multiple segments. Joining segments for sorting...')\n\t        recording_joined = si.concatenate_recordings(recording_list=[recording])\n\t        sorting_joined = sorting_scheme1(recording_joined, sorting_parameters=sorting_parameters)\n\t        print('Splitting sorting into segments to match original multisegment recording...')\n\t        sorting = si.split_sorting(sorting_joined, recording_joined)\n\t        return sorting\n", "    ###################################################################\n\t    M = recording.get_num_channels()\n\t    N = recording.get_num_frames()\n\t    sampling_frequency = recording.sampling_frequency\n\t    channel_locations = recording.get_channel_locations()\n\t    print(f'Number of channels: {M}')\n\t    print(f'Number of timepoints: {N}')\n\t    print(f'Sampling frequency: {sampling_frequency} Hz')\n\t    for m in range(M):\n\t        print(f'Channel {m}: {channel_locations[m]}')\n", "    sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n\t    print('Loading traces')\n\t    traces = recording.get_traces()\n\t    print('Detecting spikes')\n\t    time_radius = int(math.ceil(sorting_parameters.detect_time_radius_msec / 1000 * sampling_frequency))\n\t    times, channel_indices = detect_spikes(\n\t        traces=traces,\n\t        channel_locations=channel_locations,\n\t        time_radius=time_radius,\n\t        channel_radius=sorting_parameters.detect_channel_radius,\n", "        detect_threshold=sorting_parameters.detect_threshold,\n\t        detect_sign=sorting_parameters.detect_sign,\n\t        margin_left=sorting_parameters.snippet_T1,\n\t        margin_right=sorting_parameters.snippet_T2,\n\t        verbose=True\n\t    )\n\t    # this is important because isosplit does not do well with duplicate points\n\t    times, channel_indices = remove_duplicate_times(times, channel_indices)\n\t    print(f'Extracting {len(times)} snippets')\n\t    snippets = extract_snippets( # L x T x M\n", "        traces=traces,\n\t        channel_locations=channel_locations,\n\t        mask_radius=sorting_parameters.snippet_mask_radius,\n\t        times=times,\n\t        channel_indices=channel_indices,\n\t        T1=sorting_parameters.snippet_T1,\n\t        T2=sorting_parameters.snippet_T2\n\t    )\n\t    L = snippets.shape[0]\n\t    T = snippets.shape[1]\n", "    assert snippets.shape[2] == M\n\t    print('Clustering snippets')\n\t    features = compute_pca_features(snippets.reshape((L, T * M)), npca=sorting_parameters.npca_per_channel * M)\n\t    labels = isosplit6_subdivision_method(\n\t        X=features,\n\t        npca_per_subdivision=sorting_parameters.npca_per_subdivision\n\t    )\n\t    K = int(np.max(labels))\n\t    print(f'Found {K} clusters')\n\t    print('Computing templates')\n", "    templates = compute_templates(snippets=snippets, labels=labels) # K x T x M\n\t    peak_channel_indices = [np.argmin(np.min(templates[i], axis=0)) for i in range(K)]\n\t    print('Determining optimal alignment of templates')\n\t    offsets = align_templates(templates)\n\t    print('Aligning snippets')\n\t    snippets = align_snippets(snippets, offsets, labels)\n\t    # this is tricky - we need to subtract the offset to correspond to shifting the template\n\t    times = offset_times(times, -offsets, labels)\n\t    print('Clustering aligned snippets')\n\t    features = compute_pca_features(snippets.reshape((L, T * M)), npca=sorting_parameters.npca_per_channel * M)\n", "    labels = isosplit6_subdivision_method(\n\t        X=features,\n\t        npca_per_subdivision=sorting_parameters.npca_per_subdivision\n\t    )\n\t    K = int(np.max(labels))\n\t    print(f'Found {K} clusters')\n\t    print('Computing templates')\n\t    templates = compute_templates(snippets=snippets, labels=labels) # K x T x M\n\t    peak_channel_indices = [np.argmin(np.min(templates[i], axis=0)) for i in range(K)]\n\t    print('Offsetting times to peak')\n", "    # Now we need to offset the times again so that the spike times correspond to actual peaks\n\t    offsets_to_peak = determine_offsets_to_peak(templates, detect_sign=sorting_parameters.detect_sign, T1=sorting_parameters.snippet_T1)\n\t    print('Offsets to peak:', offsets_to_peak)\n\t    # This time we need to add the offset\n\t    times = offset_times(times, offsets_to_peak, labels)\n\t    # Now we need to make sure the times are in order, because we have offset them\n\t    sort_inds = np.argsort(times)\n\t    times = times[sort_inds]\n\t    labels = labels[sort_inds]\n\t    # also make sure none of the times are out of bounds now that we have offset them a couple times\n", "    inds_okay = np.where((times >= sorting_parameters.snippet_T1) & (times < N - sorting_parameters.snippet_T2))[0]\n\t    times = times[inds_okay]\n\t    labels = labels[inds_okay]\n\t    print('Reordering units')\n\t    # relabel so that units are ordered by channel\n\t    # and we also put any labels that are not used at the end\n\t    aa = peak_channel_indices\n\t    for k in range(1, K + 1):\n\t        inds = np.where(labels == k)[0]\n\t        if len(inds) == 0:\n", "            aa[k - 1] = np.Inf\n\t    new_labels_mapping = np.argsort(np.argsort(aa)) + 1 # too tricky! my head aches right now\n\t    labels = new_labels_mapping[labels - 1]\n\t    sorting = si.NumpySorting.from_times_labels(times_list=[times], labels_list=[labels], sampling_frequency=sampling_frequency)\n\t    return sorting\n\tdef remove_duplicate_times(times: npt.NDArray[np.int32], labels: npt.NDArray[np.int32]):\n\t    inds = np.where(np.diff(times) > 0)[0]\n\t    inds = np.concatenate([[0], inds + 1])\n\t    times2 = times[inds]\n\t    labels2 = labels[inds]\n", "    return times2, labels2\n\tdef align_templates(templates: npt.NDArray[np.float32]):\n\t    K = templates.shape[0]\n\t    T = templates.shape[1]\n\t    M = templates.shape[2]\n\t    offsets = np.zeros((K,), dtype=np.int32)\n\t    pairwise_optimal_offsets = np.zeros((K, K), dtype=np.int32)\n\t    pairwise_inner_products = np.zeros((K, K), dtype=np.float32)\n\t    for k1 in range(K):\n\t        for k2 in range(K):\n", "            offset, inner_product = compute_pairwise_optimal_offset(templates[k1], templates[k2])\n\t            pairwise_optimal_offsets[k1, k2] = offset\n\t            pairwise_inner_products[k1, k2] = inner_product\n\t    for passnum in range(20):\n\t        something_changed = False\n\t        for k1 in range(K):\n\t            weighted_sum = 0\n\t            total_weight = 0\n\t            for k2 in range(K):\n\t                if k1 != k2:\n", "                    offset = pairwise_optimal_offsets[k1, k2] + offsets[k2]\n\t                    weight = pairwise_inner_products[k1, k2]\n\t                    weighted_sum += weight * offset\n\t                    total_weight += weight\n\t            if total_weight > 0:\n\t                avg_offset = int(weighted_sum / total_weight)\n\t            else:\n\t                avg_offset = 0\n\t            if avg_offset != offsets[k1]:\n\t                something_changed = True\n", "                offsets[k1] = avg_offset\n\t        if not something_changed:\n\t            print('Template alignment converged.')\n\t            break\n\t    print('Align templates offsets: ', offsets)\n\t    return offsets\n\tdef compute_pairwise_optimal_offset(template1: npt.NDArray[np.float32], template2: npt.NDArray[np.float32]):\n\t    T = template1.shape[0]\n\t    best_inner_product = -np.Inf\n\t    best_offset = 0\n", "    for offset in range(T):\n\t        inner_product = np.sum(np.roll(template1, shift=offset, axis=0) * template2)\n\t        if inner_product > best_inner_product:\n\t            best_inner_product = inner_product\n\t            best_offset = offset\n\t    if best_offset > T // 2:\n\t        best_offset = best_offset - T\n\t    return best_offset, best_inner_product\n\tdef align_snippets(snippets: npt.NDArray[np.float32], offsets: npt.NDArray[np.int32], labels: npt.NDArray[np.int32]):\n\t    snippets2 = np.zeros_like(snippets)\n", "    for k in range(1, np.max(labels) + 1):\n\t        inds = np.where(labels == k)[0]\n\t        snippets2[inds] = np.roll(snippets[inds], shift=offsets[k - 1], axis=1)\n\t    return snippets2\n\tdef offset_times(times: npt.NDArray[np.int32], offsets: npt.NDArray[np.int32], labels: npt.NDArray[np.int32]):\n\t    times2 = np.zeros_like(times)\n\t    for k in range(1, np.max(labels) + 1):\n\t        inds = np.where(labels == k)[0]\n\t        times2[inds] = times[inds] + offsets[k - 1]\n\t    return times2\n", "def determine_offsets_to_peak(templates: npt.NDArray[np.float32], *, detect_sign: int, T1: int):\n\t    K = templates.shape[0]\n\t    if detect_sign < 0:\n\t        A = -templates\n\t    elif detect_sign > 0: # pragma: no cover\n\t        A = templates # pragma: no cover\n\t    else:\n\t        A = np.abs(templates) # pragma: no cover\n\t    offsets_to_peak = np.zeros((K,), dtype=np.int32)\n\t    for k in range(K):\n", "        peak_channel = np.argmax(np.max(A[k], axis=0))\n\t        peak_time = np.argmax(A[k][:, peak_channel])\n\t        offset_to_peak = peak_time - T1\n\t        offsets_to_peak[k] = offset_to_peak\n\t    return offsets_to_peak"]}
{"filename": "mountainsort5/schemes/sorting_scheme2.py", "chunked_list": ["from typing import Dict, Tuple, List, Union\n\timport numpy as np\n\timport numpy.typing as npt\n\timport math\n\timport spikeinterface as si\n\tfrom .Scheme2SortingParameters import Scheme2SortingParameters\n\tfrom .Scheme1SortingParameters import Scheme1SortingParameters\n\tfrom ..core.detect_spikes import detect_spikes\n\tfrom ..core.extract_snippets import extract_snippets, extract_snippets_in_channel_neighborhood\n\tfrom .sorting_scheme1 import sorting_scheme1\n", "from ..core.SnippetClassifier import SnippetClassifier\n\tfrom ..core.remove_duplicate_events import remove_duplicate_events\n\tfrom ..core.get_sampled_recording_for_training import get_sampled_recording_for_training\n\tfrom ..core.get_times_labels_from_sorting import get_times_labels_from_sorting\n\tdef sorting_scheme2(\n\t    recording: si.BaseRecording, *,\n\t    sorting_parameters: Scheme2SortingParameters,\n\t    return_snippet_classifiers: bool = False, # used in scheme 3\n\t    reference_snippet_classifiers: Union[Dict[int, SnippetClassifier], None] = None, # used in scheme 3\n\t    label_offset: int = 0 # used in scheme 3\n", ") -> Union[si.BaseSorting, Tuple[si.BaseSorting, Dict[int, SnippetClassifier]]]:\n\t    \"\"\"MountainSort 5 sorting scheme 2\n\t    Args:\n\t        recording (si.BaseRecording): SpikeInterface recording object\n\t        sorting_parameters (Scheme2SortingParameters): Sorting parameters\n\t        return_snippet_classifiers (bool): whether to return the snippet classifiers (used in scheme 3)\n\t        reference_snippet_classifiers: used in scheme 3\n\t        label_offset: used in scheme 3\n\t    Returns:\n\t        si.BaseSorting: SpikeInterface sorting object\n", "            or, if return_snippet_classifiers is True:\n\t        si.BaseSorting, snippet_classifiers\n\t    \"\"\"\n\t    ###################################################################\n\t    # Handle multi-segment recordings\n\t    if recording.get_num_segments() > 1:\n\t        print('Recording has multiple segments. Joining segments for sorting...')\n\t        recording_joined = si.concatenate_recordings(recording_list=[recording])\n\t        sorting_joined, snippet_classifiers = sorting_scheme2(\n\t            recording_joined,\n", "            sorting_parameters=sorting_parameters,\n\t            return_snippet_classifiers=True,\n\t            reference_snippet_classifiers=reference_snippet_classifiers,\n\t            label_offset=label_offset\n\t        )\n\t        print('Splitting sorting into segments to match original multisegment recording...')\n\t        sorting = si.split_sorting(sorting_joined, recording_joined)\n\t        if return_snippet_classifiers:\n\t            return sorting, snippet_classifiers\n\t        else:\n", "            return sorting\n\t    ###################################################################\n\t    M = recording.get_num_channels()\n\t    N = recording.get_num_frames()\n\t    sampling_frequency = recording.sampling_frequency\n\t    channel_locations = recording.get_channel_locations()\n\t    # check that the sorting parameters are valid\n\t    sorting_parameters.check_valid(M=M, N=N, sampling_frequency=sampling_frequency, channel_locations=channel_locations)\n\t    # Subsample the recording for training\n\t    if sorting_parameters.training_duration_sec is not None:\n", "        training_recording = get_sampled_recording_for_training(\n\t            recording=recording,\n\t            training_duration_sec=sorting_parameters.training_duration_sec,\n\t            mode=sorting_parameters.training_recording_sampling_mode\n\t        )\n\t    else:\n\t        training_recording = recording\n\t    # Run the first phase of spike sorting (same as sorting_scheme1)\n\t    sorting1 = sorting_scheme1(\n\t        recording=training_recording,\n", "        sorting_parameters=Scheme1SortingParameters(\n\t            detect_threshold=sorting_parameters.phase1_detect_threshold,\n\t            detect_sign=sorting_parameters.detect_sign,\n\t            detect_time_radius_msec=sorting_parameters.phase1_detect_time_radius_msec,\n\t            detect_channel_radius=sorting_parameters.phase1_detect_channel_radius,\n\t            snippet_mask_radius=sorting_parameters.snippet_mask_radius,\n\t            snippet_T1=sorting_parameters.snippet_T1,\n\t            snippet_T2=sorting_parameters.snippet_T2,\n\t            npca_per_channel=sorting_parameters.phase1_npca_per_channel,\n\t            npca_per_subdivision=sorting_parameters.phase1_npca_per_subdivision\n", "        )\n\t    )\n\t    times, labels = get_times_labels_from_sorting(sorting1)\n\t    K = np.max(labels) # number of clusters\n\t    labels = labels + label_offset # used in scheme 3\n\t    print('Loading training traces')\n\t    # Load the traces from the training recording\n\t    training_traces = training_recording.get_traces()\n\t    training_snippets = extract_snippets(\n\t        traces=training_traces,\n", "        channel_locations=None,\n\t        mask_radius=None,\n\t        times=times,\n\t        channel_indices=None,\n\t        T1=sorting_parameters.snippet_T1,\n\t        T2=sorting_parameters.snippet_T2\n\t    )\n\t    print('Training classifier')\n\t    # Train the classifier based on the labels obtained from the first phase sorting\n\t    channel_masks: Dict[int, Union[List[int], None]] = {} # by channel\n", "    for m in range(M):\n\t        channel_masks[m] = []\n\t        for m2 in range(M):\n\t            if sorting_parameters.snippet_mask_radius is not None:\n\t                if np.linalg.norm(channel_locations[m] - channel_locations[m2]) <= sorting_parameters.snippet_mask_radius:\n\t                    channel_masks[m].append(m2)\n\t            else:\n\t                channel_masks[m] = None\n\t    snippet_classifiers: Dict[int, SnippetClassifier] = {} # by channel\n\t    for m in range(M):\n", "        snippet_classifiers[m] = SnippetClassifier(npca=sorting_parameters.classifier_npca)\n\t        # Add random snippets to classifier with label 0 (a noise cluster for classification)\n\t        uniformly_spread_times = np.floor(np.linspace(sorting_parameters.snippet_T1, training_traces.shape[0] - sorting_parameters.snippet_T2 - 1, sorting_parameters.max_num_snippets_per_training_batch)).astype(np.int32)\n\t        random_snippets = extract_snippets_in_channel_neighborhood(\n\t            traces=training_traces,\n\t            times=uniformly_spread_times,\n\t            neighborhood=channel_masks[m],\n\t            T1=sorting_parameters.snippet_T1,\n\t            T2=sorting_parameters.snippet_T2\n\t        )\n", "        snippet_classifiers[m].add_training_snippets(random_snippets, label=0, offset=0)\n\t    for k in range(label_offset + 1, label_offset + K + 1):\n\t        inds0 = np.where(labels == k)[0]\n\t        snippets0 = training_snippets[inds0]\n\t        template0 = np.median(snippets0, axis=0) # T x M\n\t        if sorting_parameters.detect_sign < 0:\n\t            AA = -template0\n\t        elif sorting_parameters.detect_sign > 0: # pragma: no cover\n\t            AA = template0 # pragma: no cover\n\t        else:\n", "            AA = np.abs(template0) # pragma: no cover\n\t        peak_indices_over_channels = np.argmax(AA, axis=0)\n\t        peak_values_over_channels = np.max(AA, axis=0)\n\t        peaks_to_include: List[dict] = []\n\t        for m in range(M):\n\t            if peak_values_over_channels[m] >= sorting_parameters.detect_threshold * 0.4: # should be a parameter\n\t                peaks_to_include.append({\n\t                    'channel': m,\n\t                    'offset': peak_indices_over_channels[m] - sorting_parameters.snippet_T1\n\t                })\n", "        for peak in peaks_to_include:\n\t            m = peak['channel']\n\t            offset = peak['offset']\n\t            if channel_masks[m] is not None:\n\t                snippets0_masked = snippets0[:, :, channel_masks[m]]\n\t            else:\n\t                snippets0_masked = snippets0\n\t            snippet_classifiers[m].add_training_snippets(\n\t                snippets=subsample_snippets(np.roll(snippets0_masked, shift=-offset, axis=1), sorting_parameters.max_num_snippets_per_training_batch),\n\t                label=k,\n", "                offset=offset\n\t            )\n\t    training_snippets = None # Free up memory\n\t    print('Fitting models')\n\t    for m in range(M):\n\t        snippet_classifiers[m].fit()\n\t    # Now that we have the classifier, we can do the full sorting\n\t    # Iterate over time chunks, detect and classify all spikes, and collect the results\n\t    chunk_size = int(math.ceil(100e6 / recording.get_num_channels())) # size of chunks in samples\n\t    print(f'Chunk size: {chunk_size / recording.sampling_frequency} sec')\n", "    chunks = get_time_chunks(recording.get_num_samples(), chunk_size=chunk_size, padding=1000)\n\t    times_list: list[npt.NDArray[np.int64]] = []\n\t    labels_list: list[npt.NDArray[np.int32]] = []\n\t    labels_reference_list = [] if reference_snippet_classifiers is not None else None\n\t    for i, chunk in enumerate(chunks):\n\t        print(f'Time chunk {i + 1} of {len(chunks)}')\n\t        print('Loading traces')\n\t        traces_chunk = recording.get_traces(start_frame=chunk.start - chunk.padding_left, end_frame=chunk.end + chunk.padding_right)\n\t        print('Detecting spikes')\n\t        time_radius = int(math.ceil(sorting_parameters.detect_time_radius_msec / 1000 * sampling_frequency))\n", "        times_chunk, channel_indices_chunk = detect_spikes(\n\t            traces=traces_chunk,\n\t            channel_locations=channel_locations,\n\t            time_radius=time_radius,\n\t            channel_radius=sorting_parameters.detect_channel_radius,\n\t            detect_threshold=sorting_parameters.detect_threshold,\n\t            detect_sign=sorting_parameters.detect_sign,\n\t            margin_left=sorting_parameters.snippet_T1,\n\t            margin_right=sorting_parameters.snippet_T2,\n\t            verbose=False\n", "        )\n\t        print('Extracting and classifying snippets')\n\t        labels_chunk = np.zeros(len(times_chunk), dtype='int32')\n\t        labels_reference_chunk = np.zeros(len(times_chunk), dtype='int32') if reference_snippet_classifiers is not None else None\n\t        for m in range(M):\n\t            inds = np.where(channel_indices_chunk == m)[0]\n\t            if len(inds) > 0:\n\t                snippets2 = extract_snippets_in_channel_neighborhood(\n\t                    traces=traces_chunk,\n\t                    times=times_chunk[inds],\n", "                    neighborhood=channel_masks[m],\n\t                    T1=sorting_parameters.snippet_T1,\n\t                    T2=sorting_parameters.snippet_T2\n\t                )\n\t                labels_chunk_m, offsets_chunk_m = snippet_classifiers[m].classify_snippets(snippets2)\n\t                if labels_chunk_m is not None:\n\t                    labels_chunk[inds] = labels_chunk_m\n\t                    times_chunk[inds] = times_chunk[inds] - offsets_chunk_m\n\t                if reference_snippet_classifiers is not None:\n\t                    labels_reference_chunk_m, _ = reference_snippet_classifiers[m].classify_snippets(snippets2)\n", "                    if labels_reference_chunk_m is not None:\n\t                        labels_reference_chunk[inds] = labels_reference_chunk_m\n\t        # remove events with label 0\n\t        valid_inds = np.where(labels_chunk > 0)[0]\n\t        times_chunk: npt.NDArray[np.int32] = times_chunk[valid_inds]\n\t        labels_chunk: npt.NDArray[np.int32] = labels_chunk[valid_inds]\n\t        labels_reference_chunk = labels_reference_chunk[valid_inds] if reference_snippet_classifiers is not None else None\n\t        # now that we offset them we need to re-sort\n\t        sort_inds2 = np.argsort(times_chunk)\n\t        times_chunk: npt.NDArray[np.int32] = times_chunk[sort_inds2]\n", "        labels_chunk: npt.NDArray[np.int32] = labels_chunk[sort_inds2]\n\t        labels_reference_chunk = labels_reference_chunk[sort_inds2] if reference_snippet_classifiers is not None else None\n\t        print('Removing duplicates')\n\t        new_inds = remove_duplicate_events(times_chunk, labels_chunk, tol=time_radius)\n\t        times_chunk: npt.NDArray[np.int32] = times_chunk[new_inds]\n\t        labels_chunk: npt.NDArray[np.int32] = labels_chunk[new_inds]\n\t        labels_reference_chunk = labels_reference_chunk[new_inds] if reference_snippet_classifiers is not None else None\n\t        # remove events in the margins\n\t        valid_inds = np.where((chunk.padding_left <= times_chunk) & (times_chunk < chunk.total_size - chunk.padding_right))[0]\n\t        times_chunk: npt.NDArray[np.int32] = times_chunk[valid_inds]\n", "        labels_chunk: npt.NDArray[np.int32] = labels_chunk[valid_inds]\n\t        labels_reference_chunk = labels_reference_chunk[valid_inds] if reference_snippet_classifiers is not None else None\n\t        # don't forget to cast to int64 add the chunk start time\n\t        times_list.append(\n\t            times_chunk.astype(np.int64) + chunk.start - chunk.padding_left\n\t        )\n\t        labels_list.append(labels_chunk)\n\t        if reference_snippet_classifiers is not None:\n\t            labels_reference_list.append(labels_reference_chunk)\n\t    # Now concatenate the results\n", "    times_concat: npt.NDArray[np.int64] = np.concatenate(times_list)\n\t    labels_concat: npt.NDArray[np.int32] = np.concatenate(labels_list)\n\t    labels_reference_concat = np.concatenate(labels_reference_list) if reference_snippet_classifiers is not None else None\n\t    if reference_snippet_classifiers is not None:\n\t        mapping = get_labels_to_reference_labels_mapping(labels_concat, labels_reference_concat, label_offset=label_offset)\n\t        print('==== mapping =======================')\n\t        for k1, k2 in mapping.items():\n\t            print(f'{k1} -> {k2}')\n\t        print('====================================')\n\t        for m in range(M):\n", "            snippet_classifiers[m].apply_label_mapping(mapping)\n\t        for k1, k2 in mapping.items():\n\t            labels_concat[labels_concat == k1] = k2\n\t    # Now create a new sorting object from the times and labels results\n\t    sorting2 = si.NumpySorting.from_times_labels([times_concat], [labels_concat], sampling_frequency=recording.sampling_frequency)\n\t    if return_snippet_classifiers:\n\t        return sorting2, snippet_classifiers\n\t    else:\n\t        return sorting2\n\t# Here's what this function does:\n", "# 1. For each unit, find the matching unit in the reference (has to be a MUTUAL >0.5 overlap)\n\t# 2. If the matching unit is found, then map the unit to the matching unit\n\t# 3. If the matching unit is not found, then map it to the smallest unused label starting with label_offset+1\n\tdef get_labels_to_reference_labels_mapping(labels: npt.NDArray[np.int32], labels_reference: npt.NDArray[np.int32], *, label_offset) -> Dict[int, int]:\n\t    mapping: Dict[int, int] = {}\n\t    unique_labels = np.sort(np.unique(labels))\n\t    last_used_k = label_offset\n\t    for k in unique_labels:\n\t        mapping[k] = None # initialize to None, if it stays as None, then we will need to create a new label\n\t        inds = np.where(labels == k)[0]\n", "        a = labels_reference[inds]\n\t        k_refs, k_ref_counts = np.unique(a, return_counts=True)\n\t        for ii in range(len(k_refs)):\n\t            if k_ref_counts[ii] > 0.5 * len(inds): # the 0.5 is chosen so we don't map to the same unit twice\n\t                inds_ref = np.where(labels_reference == k_refs[ii])[0] # import to test the other way around\n\t                if k_ref_counts[ii] > 0.5 * len(inds_ref): # mutual overlap\n\t                    mapping[k] = k_refs[ii] # map to the reference label\n\t                    break\n\t        if mapping[k] is None: # if not mapped to reference label, then create a new label\n\t            mapping[k] = last_used_k + 1\n", "            last_used_k = mapping[k]\n\t    return mapping\n\tclass TimeChunk:\n\t    def __init__(self, start: np.int64, end: np.int64, padding_left: np.int32, padding_right: np.int32):\n\t        self.start = start\n\t        self.end = end\n\t        self.padding_left = padding_left\n\t        self.padding_right = padding_right\n\t        self.total_size = self.end - self.start + np.int64(padding_left) + np.int64(padding_right)\n\tdef get_time_chunks(num_samples: np.int64, chunk_size: np.int32, padding: np.int32) -> List[TimeChunk]:\n", "    \"\"\"Get time chunks\n\t    Inputs:\n\t        num_samples: number of samples in the recording\n\t        chunk_size: size of each chunk in samples\n\t        padding: padding on each side of the chunk in samples\n\t    Returns:\n\t        chunks: list of TimeChunk objects\n\t    \"\"\"\n\t    chunks = []\n\t    start = np.int64(0)\n", "    while start < num_samples:\n\t        end = np.int64(start) + np.int64(chunk_size)\n\t        if end > num_samples:\n\t            end = num_samples\n\t        padding_left = min(padding, start)\n\t        padding_right = min(padding, num_samples - end)\n\t        chunks.append(TimeChunk(start=start, end=end, padding_left=padding_left, padding_right=padding_right))\n\t        start = end\n\t    return chunks\n\tdef subsample_snippets(snippets: npt.NDArray[np.float32], max_num: int) -> np.ndarray:\n", "    \"\"\"Subsample snippets\n\t    Inputs:\n\t        snippets: 3D array of snippets (num_snippets x T x M)\n\t        max_num: maximum number of snippets to return\n\t    Returns:\n\t        snippets_out: 3D array of snippets (num_snippets x T x M)\n\t    \"\"\"\n\t    num_snippets = snippets.shape[0]\n\t    if num_snippets > max_num:\n\t        inds = np.arange(0, max_num) * num_snippets // max_num\n", "        snippets_out = snippets[inds]\n\t    else:\n\t        snippets_out = snippets\n\t    return snippets_out"]}
{"filename": "examples/scheme3/generate_visualization_output.py", "chunked_list": ["from typing import List\n\timport os\n\timport time\n\timport json\n\timport yaml\n\timport numpy as np\n\timport spikeinterface as si\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n", "import spikeforest as sf\n\timport figurl as fg\n\timport sortingview.views as vv\n\tfrom mountainsort5.core.extract_snippets import extract_snippets\n\tfrom helpers.create_autocorrelograms_view import create_autocorrelograms_view\n\tfrom helpers.compute_correlogram_data import compute_correlogram_data\n\tfrom spikeforest.load_spikeforest_recordings import SFRecording\n\tdef generate_visualization_output(*, rec: SFRecording, recording_preprocessed: si.BaseRecording, sorting: si.BaseSorting, sorting_true: si.BaseSorting):\n\t    os.environ['KACHERY_STORE_FILE_DIR'] = f'output/{rec.recording_name}'\n\t    os.environ['KACHERY_STORE_FILE_PREFIX'] = f'$dir'\n", "    if not os.path.exists('output'):\n\t        os.mkdir('output')\n\t    output_dir = os.environ['KACHERY_STORE_FILE_DIR']\n\t    if not os.path.exists(output_dir):\n\t        os.mkdir(output_dir)\n\t    if not os.path.exists(f'{output_dir}/recording'):\n\t        print('Saving preprocessed recording')\n\t        recording_preprocessed.save(folder=f'{output_dir}/recording', format='binary')\n\t    units_dict = {}\n\t    units_dict['true'] = sorting_true.get_unit_spike_train(sorting_true.unit_ids[0], segment_index=0).astype(np.int32)\n", "    for unit_id in sorting.unit_ids:\n\t        units_dict[str(unit_id)] = sorting.get_unit_spike_train(unit_id, segment_index=0).astype(np.int32)\n\t    sorting_with_true = si.NumpySorting.from_dict([units_dict], sampling_frequency=sorting.sampling_frequency)\n\t    print('Loading traces')\n\t    recording_preprocessed\n\t    traces = recording_preprocessed.get_traces()\n\t    channel_locations = recording_preprocessed.get_channel_locations()\n\t    unit_ids = sorting_with_true.unit_ids\n\t    channel_ids = recording_preprocessed.channel_ids\n\t    K = len(unit_ids)\n", "    M = len(recording_preprocessed.channel_ids)\n\t    T1 = 20\n\t    T2 = 20\n\t    T = T1 + T2\n\t    print('Compute templates')\n\t    templates = np.zeros((K, T, M), dtype=np.float32)\n\t    for i in range(K):\n\t        unit_id = unit_ids[i]\n\t        times1 = sorting_with_true.get_unit_spike_train(unit_id, segment_index=0)\n\t        snippets1 = extract_snippets(traces, channel_locations=None, mask_radius=None, times=times1, channel_indices=None, T1=T1, T2=T2)\n", "        templates[i] = np.median(snippets1, axis=0)\n\t    peak_channels = {\n\t        str(unit_ids[i]): channel_ids[np.argmin(np.min(templates[i], axis=0))]\n\t        for i in range(K)\n\t    }\n\t    sorting_data = {\n\t        'samplingFrequency': sorting_with_true.get_sampling_frequency(),\n\t        'units': [\n\t            {\n\t                'unitId': f'{unit_id}',\n", "                'peakChannelId': peak_channels[str(unit_id)],\n\t                'spikeTrain': sorting_with_true.get_unit_spike_train(unit_id).astype(np.int32)\n\t            }\n\t            for unit_id in sorting_with_true.unit_ids\n\t            if len(sorting_with_true.get_unit_spike_train(unit_id)) > 0\n\t        ]\n\t    }\n\t    with open(f'{output_dir}/sorting.json', 'w') as f:\n\t        json.dump(fg.serialize_data(sorting_data), f)\n\t    v_et = vv.EphysTraces(\n", "        format='spikeinterface.binary',\n\t        uri=f'$dir/recording',\n\t        sorting_uri=f'$dir/sorting.json'\n\t    )\n\t    # v_et_2 = vv.EphysTraces(\n\t    #     format='spikeinterface.binary',\n\t    #     uri='$dir/generated/recording',\n\t    #     sorting_uri=f'$dir/generated/test_mountainsort_sorting.json'\n\t    # )\n\t    # auto-correlograms\n", "    print('Auto correlograms')\n\t    v_ac = create_autocorrelograms_view(sorting=sorting_with_true)\n\t    adjacency_radius = 100\n\t    adjacency = {}\n\t    for m in range(M):\n\t        adjacency[str(channel_ids[m])] = []\n\t        for m2 in range(M):\n\t            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n\t            if dist0 <= adjacency_radius:\n\t                adjacency[str(channel_ids[m])].append(str(channel_ids[m2]))\n", "    # cross-correlograms\n\t    print('Cross correlograms')\n\t    cross_correlogram_items: List[vv.CrossCorrelogramItem] = []\n\t    for unit_id1 in sorting_with_true.unit_ids:\n\t        for unit_id2 in sorting_with_true.unit_ids:\n\t            if str(peak_channels[str(unit_id1)]) in adjacency[str(peak_channels[str(unit_id2)])]:\n\t                a = compute_correlogram_data(sorting=sorting_with_true, unit_id1=unit_id1, unit_id2=unit_id2, window_size_msec=80, bin_size_msec=1)\n\t                bin_edges_sec = a['bin_edges_sec']\n\t                bin_counts = a['bin_counts']\n\t                cross_correlogram_items.append(\n", "                    vv.CrossCorrelogramItem(\n\t                        unit_id1 = str(unit_id1),\n\t                        unit_id2 = str(unit_id2),\n\t                        bin_edges_sec = bin_edges_sec,\n\t                        bin_counts = bin_counts\n\t                    )\n\t                )\n\t    v_cc = vv.CrossCorrelograms(\n\t        cross_correlograms=cross_correlogram_items,\n\t        hide_unit_selector=True\n", "    )\n\t    # units table\n\t    print('Units table')\n\t    v_ut = vv.UnitsTable(\n\t        columns=[\n\t        ],\n\t        rows=[\n\t            vv.UnitsTableRow(str(unit_id), {\n\t            })\n\t            for unit_id in sorting_with_true.get_unit_ids()\n", "        ]\n\t    )\n\t    view = vv.Box(\n\t        direction='horizontal',\n\t        items=[\n\t            vv.LayoutItem(v_ut, stretch=0, min_size=150, max_size=150),\n\t            vv.LayoutItem(v_ac, stretch=0, min_size=400, max_size=400),\n\t            vv.LayoutItem(\n\t                vv.Splitter(\n\t                    direction='horizontal',\n", "                    item1=vv.LayoutItem(v_cc, stretch=1),\n\t                    item2=vv.LayoutItem(\n\t                        vv.TabLayout(\n\t                            items=[\n\t                                vv.TabLayoutItem(label='preprocessed', view=v_et),\n\t                                # vv.TabLayoutItem(label='full', view=v_et_2)\n\t                            ]\n\t                        ),\n\t                        stretch=1\n\t                    )\n", "                ), stretch=1\n\t            )\n\t        ]\n\t    )\n\t    dd = view.url_dict(label=f'{rec.recording_name}')\n\t    with open(f'{output_dir}/view.yaml', 'w') as f:\n\t        yaml.dump(dd, f)"]}
{"filename": "examples/scheme3/toy_example.py", "chunked_list": ["import os\n\timport time\n\timport shutil\n\timport spikeinterface.extractors as se\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\tfrom generate_visualization_output import generate_visualization_output\n\tfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\n\timport spikeinterface as si\n", "def main():\n\t    recording, sorting_true = se.toy_example(\n\t        duration=60 * 30,\n\t        num_channels=8,\n\t        num_units=16,\n\t        sampling_frequency=30000,\n\t        num_segments=1,\n\t        seed=0\n\t    )\n\t    timer = time.time()\n", "    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n\t    print('Starting MountainSort5 (scheme 3)')\n\t    sorting = ms5.sorting_scheme3(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme3SortingParameters(\n\t            block_sorting_parameters=ms5.Scheme2SortingParameters(\n\t                phase1_detect_channel_radius=150,\n", "                detect_channel_radius=50,\n\t                training_duration_sec=60\n\t            ),\n\t            block_duration_sec=60 * 5\n\t        )\n\t    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    print('Comparing with truth')\n", "    comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    print(comparison.get_performance())\n\t    #######################################################################\n\t    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n\t        if os.path.exists('output/toy_example'):\n\t            shutil.rmtree('output/toy_example')\n\t        rec = SFRecording({\n\t            'name': 'toy_example',\n\t            'studyName': 'toy_example',\n\t            'studySetName': 'toy_example',\n", "            'sampleRateHz': recording_preprocessed.get_sampling_frequency(),\n\t            'numChannels': recording_preprocessed.get_num_channels(),\n\t            'durationSec': recording_preprocessed.get_total_duration(),\n\t            'numTrueUnits': sorting_true.get_num_units(),\n\t            'sortingTrueObject': {},\n\t            'recordingObject': {}\n\t        })\n\t        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)\n\tif __name__ == '__main__':\n\t    main()"]}
{"filename": "examples/scheme3/helpers/compute_correlogram_data.py", "chunked_list": ["from typing import Union\n\timport spikeinterface as si\n\timport numpy as np\n\tdef compute_correlogram_data(*, sorting: si.BaseSorting, unit_id1: int, unit_id2: Union[int, None]=None, window_size_msec: float, bin_size_msec: float):\n\t    times1 = sorting.get_unit_spike_train(unit_id=unit_id1, segment_index=0)\n\t    num_bins = int(window_size_msec / bin_size_msec)\n\t    if num_bins % 2 == 0: num_bins = num_bins - 1 # odd number of bins\n\t    num_bins_half = int((num_bins + 1) / 2)\n\t    bin_edges_msec = np.array((np.arange(num_bins + 1) - num_bins / 2) * bin_size_msec, dtype=np.float32)\n\t    bin_counts = np.zeros((num_bins,), dtype=np.int32)\n", "    if unit_id2 is None or unit_id1 == unit_id2:\n\t        # autocorrelogram\n\t        offset = 1\n\t        while True:\n\t            if offset >= len(times1): break\n\t            deltas_msec = (times1[offset:] - times1[:-offset]) / sorting.get_sampling_frequency() * 1000\n\t            deltas_msec = deltas_msec[deltas_msec <= bin_edges_msec[-1]]\n\t            if len(deltas_msec) == 0: break\n\t            for i in range(num_bins_half):\n\t                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n", "                end_msec = bin_edges_msec[num_bins_half + i]\n\t                ct = len(deltas_msec[(start_msec <= deltas_msec) & (deltas_msec < end_msec)])\n\t                bin_counts[num_bins_half - 1 + i] += ct\n\t                bin_counts[num_bins_half - 1 - i] += ct\n\t            offset = offset + 1\n\t    else:\n\t        # cross-correlogram\n\t        times2 = sorting.get_unit_spike_train(segment_index=0, unit_id=unit_id2)\n\t        all_times = np.concatenate((times1, times2))\n\t        all_labels = np.concatenate((1 * np.ones(times1.shape), 2 * np.ones(times2.shape)))\n", "        sort_inds = np.argsort(all_times)\n\t        all_times = all_times[sort_inds]\n\t        all_labels = all_labels[sort_inds]\n\t        offset = 1\n\t        while True:\n\t            if offset >= len(all_times): break\n\t            deltas_msec = (all_times[offset:] - all_times[:-offset]) / sorting.get_sampling_frequency() * 1000\n\t            deltas12_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 1)]\n\t            deltas21_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 2)]\n\t            deltas11_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 1)]\n", "            deltas22_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 2)]\n\t            deltas12_msec = deltas12_msec[deltas12_msec <= bin_edges_msec[-1]]\n\t            deltas21_msec = deltas21_msec[deltas21_msec <= bin_edges_msec[-1]]\n\t            deltas11_msec = deltas11_msec[deltas11_msec <= bin_edges_msec[-1]]\n\t            deltas22_msec = deltas22_msec[deltas22_msec <= bin_edges_msec[-1]]\n\t            if (len(deltas12_msec) + len(deltas21_msec) + len(deltas11_msec) + len(deltas22_msec)) == 0: break\n\t            for i in range(num_bins_half):\n\t                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n\t                end_msec = bin_edges_msec[num_bins_half + i]\n\t                ct12 = len(deltas12_msec[(start_msec <= deltas12_msec) & (deltas12_msec < end_msec)])\n", "                ct21 = len(deltas21_msec[(start_msec <= deltas21_msec) & (deltas21_msec < end_msec)])\n\t                bin_counts[num_bins_half - 1 + i] += ct12\n\t                bin_counts[num_bins_half - 1 - i] += ct21\n\t            offset = offset + 1\n\t    return {\n\t        'bin_edges_sec': (bin_edges_msec / 1000).astype(np.float32),\n\t        'bin_counts': bin_counts.astype(np.int32)\n\t    }"]}
{"filename": "examples/scheme3/helpers/create_autocorrelograms_view.py", "chunked_list": ["from typing import List\n\timport spikeinterface as si\n\timport sortingview.views as vv\n\tfrom helpers.compute_correlogram_data import compute_correlogram_data\n\tdef create_autocorrelograms_view(*, sorting: si.BaseSorting, unit_id_prefix: str=''):\n\t    autocorrelogram_items: List[vv.AutocorrelogramItem] = []\n\t    for unit_id in sorting.get_unit_ids():\n\t        a = compute_correlogram_data(sorting=sorting, unit_id1=unit_id, unit_id2=None, window_size_msec=80, bin_size_msec=1)\n\t        bin_edges_sec = a['bin_edges_sec']\n\t        bin_counts = a['bin_counts']\n", "        autocorrelogram_items.append(\n\t            vv.AutocorrelogramItem(\n\t                unit_id=f'{unit_id_prefix}{unit_id}',\n\t                bin_edges_sec=bin_edges_sec,\n\t                bin_counts=bin_counts\n\t            )\n\t        )\n\t    view = vv.Autocorrelograms(\n\t        autocorrelograms=autocorrelogram_items\n\t    )\n", "    return view"]}
{"filename": "examples/scheme3/helpers/create_units_table.py", "chunked_list": ["from typing import List\n\timport sortingview.views as vv\n\timport spikeinterface as si\n\tdef create_units_table(*, sorting: si.BaseSorting):\n\t    columns: List[vv.UnitsTableColumn] = []\n\t    rows: List[vv.UnitsTableRow] = []\n\t    for unit_id in sorting.get_unit_ids():\n\t        rows.append(\n\t            vv.UnitsTableRow(\n\t                unit_id=unit_id,\n", "                values={\n\t                    'unitId': unit_id\n\t                }\n\t            )\n\t        )\n\t    view = vv.UnitsTable(\n\t        columns=columns,\n\t        rows=rows\n\t    )\n\t    return view\n"]}
{"filename": "examples/scheme2/generate_visualization_output.py", "chunked_list": ["from typing import List\n\timport os\n\timport time\n\timport json\n\timport yaml\n\timport numpy as np\n\timport spikeinterface as si\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n", "import spikeforest as sf\n\timport figurl as fg\n\timport sortingview.views as vv\n\tfrom mountainsort5.core.extract_snippets import extract_snippets\n\tfrom helpers.create_autocorrelograms_view import create_autocorrelograms_view\n\tfrom helpers.compute_correlogram_data import compute_correlogram_data\n\tfrom spikeforest.load_spikeforest_recordings import SFRecording\n\tdef generate_visualization_output(*, rec: SFRecording, recording_preprocessed: si.BaseRecording, sorting: si.BaseSorting, sorting_true: si.BaseSorting):\n\t    os.environ['KACHERY_STORE_FILE_DIR'] = f'output/{rec.recording_name}'\n\t    os.environ['KACHERY_STORE_FILE_PREFIX'] = f'$dir'\n", "    if not os.path.exists('output'):\n\t        os.mkdir('output')\n\t    output_dir = os.environ['KACHERY_STORE_FILE_DIR']\n\t    if not os.path.exists(output_dir):\n\t        os.mkdir(output_dir)\n\t    if not os.path.exists(f'{output_dir}/recording'):\n\t        print('Saving preprocessed recording')\n\t        recording_preprocessed.save(folder=f'{output_dir}/recording', format='binary')\n\t    units_dict = {}\n\t    units_dict['true'] = sorting_true.get_unit_spike_train(sorting_true.unit_ids[0], segment_index=0).astype(np.int32)\n", "    for unit_id in sorting.unit_ids:\n\t        units_dict[str(unit_id)] = sorting.get_unit_spike_train(unit_id, segment_index=0).astype(np.int32)\n\t    sorting_with_true = si.NumpySorting.from_dict([units_dict], sampling_frequency=sorting.sampling_frequency)\n\t    print('Loading traces')\n\t    recording_preprocessed\n\t    traces = recording_preprocessed.get_traces()\n\t    channel_locations = recording_preprocessed.get_channel_locations()\n\t    unit_ids = sorting_with_true.unit_ids\n\t    channel_ids = recording_preprocessed.channel_ids\n\t    K = len(unit_ids)\n", "    M = len(recording_preprocessed.channel_ids)\n\t    T1 = 20\n\t    T2 = 20\n\t    T = T1 + T2\n\t    print('Compute templates')\n\t    templates = np.zeros((K, T, M), dtype=np.float32)\n\t    for i in range(K):\n\t        unit_id = unit_ids[i]\n\t        times1 = sorting_with_true.get_unit_spike_train(unit_id, segment_index=0)\n\t        snippets1 = extract_snippets(traces, channel_locations=None, mask_radius=None, times=times1, channel_indices=None, T1=T1, T2=T2)\n", "        templates[i] = np.median(snippets1, axis=0)\n\t    peak_channels = {\n\t        str(unit_ids[i]): channel_ids[np.argmin(np.min(templates[i], axis=0))]\n\t        for i in range(K)\n\t    }\n\t    sorting_data = {\n\t        'samplingFrequency': sorting_with_true.get_sampling_frequency(),\n\t        'units': [\n\t            {\n\t                'unitId': f'{unit_id}',\n", "                'peakChannelId': peak_channels[str(unit_id)],\n\t                'spikeTrain': sorting_with_true.get_unit_spike_train(unit_id).astype(np.int32)\n\t            }\n\t            for unit_id in sorting_with_true.unit_ids\n\t            if len(sorting_with_true.get_unit_spike_train(unit_id)) > 0\n\t        ]\n\t    }\n\t    with open(f'{output_dir}/sorting.json', 'w') as f:\n\t        json.dump(fg.serialize_data(sorting_data), f)\n\t    v_et = vv.EphysTraces(\n", "        format='spikeinterface.binary',\n\t        uri=f'$dir/recording',\n\t        sorting_uri=f'$dir/sorting.json'\n\t    )\n\t    # v_et_2 = vv.EphysTraces(\n\t    #     format='spikeinterface.binary',\n\t    #     uri='$dir/generated/recording',\n\t    #     sorting_uri=f'$dir/generated/test_mountainsort_sorting.json'\n\t    # )\n\t    # auto-correlograms\n", "    print('Auto correlograms')\n\t    v_ac = create_autocorrelograms_view(sorting=sorting_with_true)\n\t    adjacency_radius = 100\n\t    adjacency = {}\n\t    for m in range(M):\n\t        adjacency[str(channel_ids[m])] = []\n\t        for m2 in range(M):\n\t            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n\t            if dist0 <= adjacency_radius:\n\t                adjacency[str(channel_ids[m])].append(str(channel_ids[m2]))\n", "    # cross-correlograms\n\t    print('Cross correlograms')\n\t    cross_correlogram_items: List[vv.CrossCorrelogramItem] = []\n\t    for unit_id1 in sorting_with_true.unit_ids:\n\t        for unit_id2 in sorting_with_true.unit_ids:\n\t            if str(peak_channels[str(unit_id1)]) in adjacency[str(peak_channels[str(unit_id2)])]:\n\t                a = compute_correlogram_data(sorting=sorting_with_true, unit_id1=unit_id1, unit_id2=unit_id2, window_size_msec=80, bin_size_msec=1)\n\t                bin_edges_sec = a['bin_edges_sec']\n\t                bin_counts = a['bin_counts']\n\t                cross_correlogram_items.append(\n", "                    vv.CrossCorrelogramItem(\n\t                        unit_id1 = str(unit_id1),\n\t                        unit_id2 = str(unit_id2),\n\t                        bin_edges_sec = bin_edges_sec,\n\t                        bin_counts = bin_counts\n\t                    )\n\t                )\n\t    v_cc = vv.CrossCorrelograms(\n\t        cross_correlograms=cross_correlogram_items,\n\t        hide_unit_selector=True\n", "    )\n\t    # units table\n\t    print('Units table')\n\t    v_ut = vv.UnitsTable(\n\t        columns=[\n\t        ],\n\t        rows=[\n\t            vv.UnitsTableRow(str(unit_id), {\n\t            })\n\t            for unit_id in sorting_with_true.get_unit_ids()\n", "        ]\n\t    )\n\t    view = vv.Box(\n\t        direction='horizontal',\n\t        items=[\n\t            vv.LayoutItem(v_ut, stretch=0, min_size=150, max_size=150),\n\t            vv.LayoutItem(v_ac, stretch=0, min_size=400, max_size=400),\n\t            vv.LayoutItem(\n\t                vv.Splitter(\n\t                    direction='horizontal',\n", "                    item1=vv.LayoutItem(v_cc, stretch=1),\n\t                    item2=vv.LayoutItem(\n\t                        vv.TabLayout(\n\t                            items=[\n\t                                vv.TabLayoutItem(label='preprocessed', view=v_et),\n\t                                # vv.TabLayoutItem(label='full', view=v_et_2)\n\t                            ]\n\t                        ),\n\t                        stretch=1\n\t                    )\n", "                ), stretch=1\n\t            )\n\t        ]\n\t    )\n\t    dd = view.url_dict(label=f'{rec.recording_name}')\n\t    with open(f'{output_dir}/view.yaml', 'w') as f:\n\t        yaml.dump(dd, f)"]}
{"filename": "examples/scheme2/toy_example.py", "chunked_list": ["import os\n\timport time\n\timport shutil\n\timport spikeinterface.extractors as se\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\tfrom generate_visualization_output import generate_visualization_output\n\tfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\n\timport spikeinterface as si\n", "def main():\n\t    recording, sorting_true = se.toy_example(duration=60 * 30, num_channels=16, num_units=32, sampling_frequency=30000, num_segments=1, seed=0)\n\t    timer = time.time()\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n\t    print('Starting MountainSort5 (scheme 2)')\n\t    sorting = ms5.sorting_scheme2(\n\t        recording_preprocessed,\n", "        sorting_parameters=ms5.Scheme2SortingParameters(\n\t            phase1_detect_channel_radius=150,\n\t            detect_channel_radius=50,\n\t            training_duration_sec=60\n\t        )\n\t    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    print('Comparing with truth')\n", "    comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    print(comparison.get_performance())\n\t    #######################################################################\n\t    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n\t        if os.path.exists('output/toy_example'):\n\t            shutil.rmtree('output/toy_example')\n\t        rec = SFRecording({\n\t            'name': 'toy_example',\n\t            'studyName': 'toy_example',\n\t            'studySetName': 'toy_example',\n", "            'sampleRateHz': recording_preprocessed.get_sampling_frequency(),\n\t            'numChannels': recording_preprocessed.get_num_channels(),\n\t            'durationSec': recording_preprocessed.get_total_duration(),\n\t            'numTrueUnits': sorting_true.get_num_units(),\n\t            'sortingTrueObject': {},\n\t            'recordingObject': {}\n\t        })\n\t        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)\n\tif __name__ == '__main__':\n\t    main()"]}
{"filename": "examples/scheme2/paired_english.py", "chunked_list": ["import os\n\timport time\n\timport spikeinterface as si\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\timport spikeforest as sf\n\tfrom generate_visualization_output import generate_visualization_output\n\tdef main():\n\t    paired_english_uri = 'sha1://dfb1fd134bfc209ece21fd5f8eefa992f49e8962?paired-english-spikeforest-recordings.json'\n", "    recordings = sf.load_spikeforest_recordings(paired_english_uri)\n\t    # list recordings\n\t    # for rec in recordings:\n\t    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\t    # select recording\n\t    # rec = recordings[1] # m57_191105_160026 32 channels; 343.4533333333333 sec - amplitude too low\n\t    rec = recordings[13] # m15_190315_152315_cell1 32 channels; 669.3997 sec # classic example of need for final alignment merge step\n\t    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\t    # this will download the recording/sorting_true from kachery\n\t    print('Loading recording and sorting_true')\n", "    recording = rec.get_recording_extractor()\n\t    sorting_true = rec.get_sorting_true_extractor()\n\t    channel_locations = recording.get_channel_locations()\n\t    for m in range(channel_locations.shape[0]):\n\t        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\t    timer = time.time()\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n", "    print('Starting MountainSort5')\n\t    sorting = ms5.sorting_scheme2(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme2SortingParameters(\n\t            phase1_detect_channel_radius=200,\n\t            detect_channel_radius=30,\n\t            snippet_mask_radius=150,\n\t            training_duration_sec=300\n\t        )\n\t    )\n", "    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    print('Comparing with truth')\n\t    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    print(comparison.get_performance())\n\t    #######################################################################\n\t    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n\t        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)\n\tif __name__ == '__main__':\n", "    main()"]}
{"filename": "examples/scheme2/helpers/compute_correlogram_data.py", "chunked_list": ["from typing import Union\n\timport spikeinterface as si\n\timport numpy as np\n\tdef compute_correlogram_data(*, sorting: si.BaseSorting, unit_id1: int, unit_id2: Union[int, None]=None, window_size_msec: float, bin_size_msec: float):\n\t    times1 = sorting.get_unit_spike_train(unit_id=unit_id1, segment_index=0)\n\t    num_bins = int(window_size_msec / bin_size_msec)\n\t    if num_bins % 2 == 0: num_bins = num_bins - 1 # odd number of bins\n\t    num_bins_half = int((num_bins + 1) / 2)\n\t    bin_edges_msec = np.array((np.arange(num_bins + 1) - num_bins / 2) * bin_size_msec, dtype=np.float32)\n\t    bin_counts = np.zeros((num_bins,), dtype=np.int32)\n", "    if unit_id2 is None or unit_id1 == unit_id2:\n\t        # autocorrelogram\n\t        offset = 1\n\t        while True:\n\t            if offset >= len(times1): break\n\t            deltas_msec = (times1[offset:] - times1[:-offset]) / sorting.get_sampling_frequency() * 1000\n\t            deltas_msec = deltas_msec[deltas_msec <= bin_edges_msec[-1]]\n\t            if len(deltas_msec) == 0: break\n\t            for i in range(num_bins_half):\n\t                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n", "                end_msec = bin_edges_msec[num_bins_half + i]\n\t                ct = len(deltas_msec[(start_msec <= deltas_msec) & (deltas_msec < end_msec)])\n\t                bin_counts[num_bins_half - 1 + i] += ct\n\t                bin_counts[num_bins_half - 1 - i] += ct\n\t            offset = offset + 1\n\t    else:\n\t        # cross-correlogram\n\t        times2 = sorting.get_unit_spike_train(segment_index=0, unit_id=unit_id2)\n\t        all_times = np.concatenate((times1, times2))\n\t        all_labels = np.concatenate((1 * np.ones(times1.shape), 2 * np.ones(times2.shape)))\n", "        sort_inds = np.argsort(all_times)\n\t        all_times = all_times[sort_inds]\n\t        all_labels = all_labels[sort_inds]\n\t        offset = 1\n\t        while True:\n\t            if offset >= len(all_times): break\n\t            deltas_msec = (all_times[offset:] - all_times[:-offset]) / sorting.get_sampling_frequency() * 1000\n\t            deltas12_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 1)]\n\t            deltas21_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 2)]\n\t            deltas11_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 1)]\n", "            deltas22_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 2)]\n\t            deltas12_msec = deltas12_msec[deltas12_msec <= bin_edges_msec[-1]]\n\t            deltas21_msec = deltas21_msec[deltas21_msec <= bin_edges_msec[-1]]\n\t            deltas11_msec = deltas11_msec[deltas11_msec <= bin_edges_msec[-1]]\n\t            deltas22_msec = deltas22_msec[deltas22_msec <= bin_edges_msec[-1]]\n\t            if (len(deltas12_msec) + len(deltas21_msec) + len(deltas11_msec) + len(deltas22_msec)) == 0: break\n\t            for i in range(num_bins_half):\n\t                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n\t                end_msec = bin_edges_msec[num_bins_half + i]\n\t                ct12 = len(deltas12_msec[(start_msec <= deltas12_msec) & (deltas12_msec < end_msec)])\n", "                ct21 = len(deltas21_msec[(start_msec <= deltas21_msec) & (deltas21_msec < end_msec)])\n\t                bin_counts[num_bins_half - 1 + i] += ct12\n\t                bin_counts[num_bins_half - 1 - i] += ct21\n\t            offset = offset + 1\n\t    return {\n\t        'bin_edges_sec': (bin_edges_msec / 1000).astype(np.float32),\n\t        'bin_counts': bin_counts.astype(np.int32)\n\t    }"]}
{"filename": "examples/scheme2/helpers/create_autocorrelograms_view.py", "chunked_list": ["from typing import List\n\timport spikeinterface as si\n\timport sortingview.views as vv\n\tfrom helpers.compute_correlogram_data import compute_correlogram_data\n\tdef create_autocorrelograms_view(*, sorting: si.BaseSorting, unit_id_prefix: str=''):\n\t    autocorrelogram_items: List[vv.AutocorrelogramItem] = []\n\t    for unit_id in sorting.get_unit_ids():\n\t        a = compute_correlogram_data(sorting=sorting, unit_id1=unit_id, unit_id2=None, window_size_msec=80, bin_size_msec=1)\n\t        bin_edges_sec = a['bin_edges_sec']\n\t        bin_counts = a['bin_counts']\n", "        autocorrelogram_items.append(\n\t            vv.AutocorrelogramItem(\n\t                unit_id=f'{unit_id_prefix}{unit_id}',\n\t                bin_edges_sec=bin_edges_sec,\n\t                bin_counts=bin_counts\n\t            )\n\t        )\n\t    view = vv.Autocorrelograms(\n\t        autocorrelograms=autocorrelogram_items\n\t    )\n", "    return view"]}
{"filename": "examples/scheme2/helpers/create_units_table.py", "chunked_list": ["from typing import List\n\timport sortingview.views as vv\n\timport spikeinterface as si\n\tdef create_units_table(*, sorting: si.BaseSorting):\n\t    columns: List[vv.UnitsTableColumn] = []\n\t    rows: List[vv.UnitsTableRow] = []\n\t    for unit_id in sorting.get_unit_ids():\n\t        rows.append(\n\t            vv.UnitsTableRow(\n\t                unit_id=unit_id,\n", "                values={\n\t                    'unitId': unit_id\n\t                }\n\t            )\n\t        )\n\t    view = vv.UnitsTable(\n\t        columns=columns,\n\t        rows=rows\n\t    )\n\t    return view\n"]}
{"filename": "examples/scheme1/generate_visualization_output.py", "chunked_list": ["from typing import List\n\timport os\n\timport time\n\timport json\n\timport yaml\n\timport numpy as np\n\timport spikeinterface as si\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n", "import spikeforest as sf\n\timport figurl as fg\n\timport sortingview.views as vv\n\tfrom mountainsort5.core.extract_snippets import extract_snippets\n\tfrom helpers.create_autocorrelograms_view import create_autocorrelograms_view\n\tfrom helpers.compute_correlogram_data import compute_correlogram_data\n\tfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\n\tdef generate_visualization_output(*, rec: SFRecording, recording_preprocessed: si.BaseRecording, sorting: si.BaseSorting, sorting_true: si.BaseSorting):\n\t    os.environ['KACHERY_STORE_FILE_DIR'] = f'output/{rec.recording_name}'\n\t    os.environ['KACHERY_STORE_FILE_PREFIX'] = f'$dir'\n", "    if not os.path.exists('output'):\n\t        os.mkdir('output')\n\t    output_dir = os.environ['KACHERY_STORE_FILE_DIR']\n\t    if not os.path.exists(output_dir):\n\t        os.mkdir(output_dir)\n\t    if not os.path.exists(f'{output_dir}/recording'):\n\t        print('Saving preprocessed recording')\n\t        recording_preprocessed.save(folder=f'{output_dir}/recording', format='binary')\n\t    units_dict = {}\n\t    units_dict['true'] = sorting_true.get_unit_spike_train(sorting_true.unit_ids[0], segment_index=0).astype(np.int32)\n", "    for unit_id in sorting.unit_ids:\n\t        units_dict[str(unit_id)] = sorting.get_unit_spike_train(unit_id, segment_index=0).astype(np.int32)\n\t    sorting_with_true = si.NumpySorting.from_dict([units_dict], sampling_frequency=sorting.sampling_frequency)\n\t    print('Loading traces')\n\t    recording_preprocessed\n\t    traces = recording_preprocessed.get_traces()\n\t    channel_locations = recording_preprocessed.get_channel_locations()\n\t    unit_ids = sorting_with_true.unit_ids\n\t    channel_ids = recording_preprocessed.channel_ids\n\t    K = len(unit_ids)\n", "    M = len(recording_preprocessed.channel_ids)\n\t    T1 = 20\n\t    T2 = 20\n\t    T = T1 + T2\n\t    print('Compute templates')\n\t    templates = np.zeros((K, T, M), dtype=np.float32)\n\t    for i in range(K):\n\t        unit_id = unit_ids[i]\n\t        times1 = sorting_with_true.get_unit_spike_train(unit_id, segment_index=0)\n\t        snippets1 = extract_snippets(traces, channel_locations=None, mask_radius=None, times=times1, channel_indices=None, T1=T1, T2=T2)\n", "        templates[i] = np.median(snippets1, axis=0)\n\t    peak_channels = {\n\t        str(unit_ids[i]): channel_ids[np.argmin(np.min(templates[i], axis=0))]\n\t        for i in range(K)\n\t    }\n\t    sorting_data = {\n\t        'samplingFrequency': sorting_with_true.get_sampling_frequency(),\n\t        'units': [\n\t            {\n\t                'unitId': f'{unit_id}',\n", "                'peakChannelId': peak_channels[str(unit_id)],\n\t                'spikeTrain': sorting_with_true.get_unit_spike_train(unit_id).astype(np.int32)\n\t            }\n\t            for unit_id in sorting_with_true.unit_ids\n\t            if len(sorting_with_true.get_unit_spike_train(unit_id)) > 0\n\t        ]\n\t    }\n\t    with open(f'{output_dir}/sorting.json', 'w') as f:\n\t        json.dump(fg.serialize_data(sorting_data), f)\n\t    v_et = vv.EphysTraces(\n", "        format='spikeinterface.binary',\n\t        uri=f'$dir/recording',\n\t        sorting_uri=f'$dir/sorting.json'\n\t    )\n\t    # v_et_2 = vv.EphysTraces(\n\t    #     format='spikeinterface.binary',\n\t    #     uri='$dir/generated/recording',\n\t    #     sorting_uri=f'$dir/generated/test_mountainsort_sorting.json'\n\t    # )\n\t    # auto-correlograms\n", "    print('Auto correlograms')\n\t    v_ac = create_autocorrelograms_view(sorting=sorting_with_true)\n\t    adjacency_radius = 100\n\t    adjacency = {}\n\t    for m in range(M):\n\t        adjacency[str(channel_ids[m])] = []\n\t        for m2 in range(M):\n\t            dist0 = np.sqrt(np.sum((channel_locations[m] - channel_locations[m2]) ** 2))\n\t            if dist0 <= adjacency_radius:\n\t                adjacency[str(channel_ids[m])].append(str(channel_ids[m2]))\n", "    # cross-correlograms\n\t    print('Cross correlograms')\n\t    cross_correlogram_items: List[vv.CrossCorrelogramItem] = []\n\t    for unit_id1 in sorting_with_true.unit_ids:\n\t        for unit_id2 in sorting_with_true.unit_ids:\n\t            if str(peak_channels[str(unit_id1)]) in adjacency[str(peak_channels[str(unit_id2)])]:\n\t                a = compute_correlogram_data(sorting=sorting_with_true, unit_id1=unit_id1, unit_id2=unit_id2, window_size_msec=80, bin_size_msec=1)\n\t                bin_edges_sec = a['bin_edges_sec']\n\t                bin_counts = a['bin_counts']\n\t                cross_correlogram_items.append(\n", "                    vv.CrossCorrelogramItem(\n\t                        unit_id1 = str(unit_id1),\n\t                        unit_id2 = str(unit_id2),\n\t                        bin_edges_sec = bin_edges_sec,\n\t                        bin_counts = bin_counts\n\t                    )\n\t                )\n\t    v_cc = vv.CrossCorrelograms(\n\t        cross_correlograms=cross_correlogram_items,\n\t        hide_unit_selector=True\n", "    )\n\t    # units table\n\t    print('Units table')\n\t    v_ut = vv.UnitsTable(\n\t        columns=[\n\t        ],\n\t        rows=[\n\t            vv.UnitsTableRow(str(unit_id), {\n\t            })\n\t            for unit_id in sorting_with_true.get_unit_ids()\n", "        ]\n\t    )\n\t    view = vv.Box(\n\t        direction='horizontal',\n\t        items=[\n\t            vv.LayoutItem(v_ut, stretch=0, min_size=150, max_size=150),\n\t            vv.LayoutItem(v_ac, stretch=0, min_size=400, max_size=400),\n\t            vv.LayoutItem(\n\t                vv.Splitter(\n\t                    direction='horizontal',\n", "                    item1=vv.LayoutItem(v_cc, stretch=1),\n\t                    item2=vv.LayoutItem(\n\t                        vv.TabLayout(\n\t                            items=[\n\t                                vv.TabLayoutItem(label='preprocessed', view=v_et),\n\t                                # vv.TabLayoutItem(label='full', view=v_et_2)\n\t                            ]\n\t                        ),\n\t                        stretch=1\n\t                    )\n", "                ), stretch=1\n\t            )\n\t        ]\n\t    )\n\t    dd = view.url_dict(label=f'{rec.recording_name}')\n\t    with open(f'{output_dir}/view.yaml', 'w') as f:\n\t        yaml.dump(dd, f)"]}
{"filename": "examples/scheme1/toy_example.py", "chunked_list": ["import os\n\timport time\n\timport spikeinterface.extractors as se\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\tfrom generate_visualization_output import generate_visualization_output\n\tfrom spikeforest.load_spikeforest_recordings.SFRecording import SFRecording\n\timport spikeinterface as si\n\tdef main():\n", "    recording, sorting_true = se.toy_example(duration=60 * 2, num_channels=8, num_units=16, sampling_frequency=30000, num_segments=1, seed=0)\n\t    timer = time.time()\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n\t    print('Starting MountainSort5')\n\t    sorting = ms5.sorting_scheme1(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme1SortingParameters()\n", "    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    print('Comparing with truth')\n\t    comparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    print(comparison.get_performance())\n\t    #######################################################################\n\t    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n\t        rec = SFRecording({\n", "            'name': 'toy_example',\n\t            'studyName': 'toy_example',\n\t            'studySetName': 'toy_example',\n\t            'sampleRateHz': recording_preprocessed.get_sampling_frequency(),\n\t            'numChannels': recording_preprocessed.get_num_channels(),\n\t            'durationSec': recording_preprocessed.get_total_duration(),\n\t            'numTrueUnits': sorting_true.get_num_units(),\n\t            'sortingTrueObject': {},\n\t            'recordingObject': {}\n\t        })\n", "        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)\n\tif __name__ == '__main__':\n\t    main()"]}
{"filename": "examples/scheme1/paired_kampff.py", "chunked_list": ["import os\n\timport time\n\timport spikeinterface as si\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\timport spikeforest as sf\n\tfrom generate_visualization_output import generate_visualization_output\n\tdef main():\n\t    paired_kampff_uri = 'sha1://b8b571d001f9a531040e79165e8f492d758ec5e0?paired-kampff-spikeforest-recordings.json'\n", "    recordings = sf.load_spikeforest_recordings(paired_kampff_uri)\n\t    # list recordings\n\t    # for rec in recordings:\n\t    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\t    # select recording\n\t    rec = recordings[1] # 2015_09_03_Pair_9_0A 32 channels; 593.248 sec # example of bursting with lower amplitude spikes after the initial spike\n\t    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\t    # this will download the recording/sorting_true from kachery\n\t    print('Loading recording and sorting_true')\n\t    recording = rec.get_recording_extractor()\n", "    sorting_true = rec.get_sorting_true_extractor()\n\t    channel_locations = recording.get_channel_locations()\n\t    for m in range(channel_locations.shape[0]):\n\t        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\t    timer = time.time()\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n\t    print('Starting MountainSort5')\n", "    sorting = ms5.sorting_scheme1(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme1SortingParameters(\n\t            detect_channel_radius=100,\n\t            snippet_mask_radius=100\n\t        )\n\t    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n\t    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n", "    print('Comparing with truth')\n\t    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    print(comparison.get_performance())\n\t    #######################################################################\n\t    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n\t        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)\n\tif __name__ == '__main__':\n\t    main()"]}
{"filename": "examples/scheme1/paired_english.py", "chunked_list": ["import os\n\timport time\n\timport spikeinterface as si\n\timport spikeinterface.preprocessing as spre\n\timport spikeinterface.comparison as sc\n\timport mountainsort5 as ms5\n\timport spikeforest as sf\n\tfrom generate_visualization_output import generate_visualization_output\n\tdef main():\n\t    paired_english_uri = 'sha1://dfb1fd134bfc209ece21fd5f8eefa992f49e8962?paired-english-spikeforest-recordings.json'\n", "    recordings = sf.load_spikeforest_recordings(paired_english_uri)\n\t    # list recordings\n\t    # for rec in recordings:\n\t    #     print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\t    # select recording\n\t    # rec = recordings[1] # m57_191105_160026 32 channels; 343.4533333333333 sec - amplitude too low\n\t    rec = recordings[13] # m15_190315_152315_cell1 32 channels; 669.3997 sec # classic example of need for final alignment merge step\n\t    print(f'{rec.study_name}/{rec.recording_name} {rec.num_channels} channels; {rec.duration_sec} sec')\n\t    # this will download the recording/sorting_true from kachery\n\t    print('Loading recording and sorting_true')\n", "    recording = rec.get_recording_extractor()\n\t    sorting_true = rec.get_sorting_true_extractor()\n\t    channel_locations = recording.get_channel_locations()\n\t    for m in range(channel_locations.shape[0]):\n\t        print(f'Channel {recording.channel_ids[m]}: {channel_locations[m, 0]} {channel_locations[m, 1]}')\n\t    timer = time.time()\n\t    # lazy preprocessing\n\t    recording_filtered = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)\n\t    recording_preprocessed: si.BaseRecording = spre.whiten(recording_filtered, dtype='float32')\n\t    # sorting\n", "    print('Starting MountainSort5')\n\t    sorting = ms5.sorting_scheme1(\n\t        recording_preprocessed,\n\t        sorting_parameters=ms5.Scheme1SortingParameters(\n\t            detect_channel_radius=50,\n\t            snippet_mask_radius=100\n\t        )\n\t    )\n\t    elapsed_sec = time.time() - timer\n\t    duration_sec = recording.get_total_duration()\n", "    print(f'Elapsed time for sorting: {elapsed_sec:.2f} sec -- x{(duration_sec / elapsed_sec):.2f} speed compared with real time for {recording.get_num_channels()} channels')\n\t    print('Comparing with truth')\n\t    comparison: sc.GroundTruthComparison = sc.compare_sorter_to_ground_truth(gt_sorting=sorting_true, tested_sorting=sorting)\n\t    print(comparison.get_performance())\n\t    #######################################################################\n\t    if os.getenv('GENERATE_VISUALIZATION_OUTPUT') == '1':\n\t        generate_visualization_output(rec=rec, recording_preprocessed=recording_preprocessed, sorting=sorting, sorting_true=sorting_true)\n\tif __name__ == '__main__':\n\t    main()"]}
{"filename": "examples/scheme1/helpers/compute_correlogram_data.py", "chunked_list": ["from typing import Union\n\timport spikeinterface as si\n\timport numpy as np\n\tdef compute_correlogram_data(*, sorting: si.BaseSorting, unit_id1: int, unit_id2: Union[int, None]=None, window_size_msec: float, bin_size_msec: float):\n\t    times1 = sorting.get_unit_spike_train(unit_id=unit_id1, segment_index=0)\n\t    num_bins = int(window_size_msec / bin_size_msec)\n\t    if num_bins % 2 == 0: num_bins = num_bins - 1 # odd number of bins\n\t    num_bins_half = int((num_bins + 1) / 2)\n\t    bin_edges_msec = np.array((np.arange(num_bins + 1) - num_bins / 2) * bin_size_msec, dtype=np.float32)\n\t    bin_counts = np.zeros((num_bins,), dtype=np.int32)\n", "    if unit_id2 is None or unit_id1 == unit_id2:\n\t        # autocorrelogram\n\t        offset = 1\n\t        while True:\n\t            if offset >= len(times1): break\n\t            deltas_msec = (times1[offset:] - times1[:-offset]) / sorting.get_sampling_frequency() * 1000\n\t            deltas_msec = deltas_msec[deltas_msec <= bin_edges_msec[-1]]\n\t            if len(deltas_msec) == 0: break\n\t            for i in range(num_bins_half):\n\t                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n", "                end_msec = bin_edges_msec[num_bins_half + i]\n\t                ct = len(deltas_msec[(start_msec <= deltas_msec) & (deltas_msec < end_msec)])\n\t                bin_counts[num_bins_half - 1 + i] += ct\n\t                bin_counts[num_bins_half - 1 - i] += ct\n\t            offset = offset + 1\n\t    else:\n\t        # cross-correlogram\n\t        times2 = sorting.get_unit_spike_train(segment_index=0, unit_id=unit_id2)\n\t        all_times = np.concatenate((times1, times2))\n\t        all_labels = np.concatenate((1 * np.ones(times1.shape), 2 * np.ones(times2.shape)))\n", "        sort_inds = np.argsort(all_times)\n\t        all_times = all_times[sort_inds]\n\t        all_labels = all_labels[sort_inds]\n\t        offset = 1\n\t        while True:\n\t            if offset >= len(all_times): break\n\t            deltas_msec = (all_times[offset:] - all_times[:-offset]) / sorting.get_sampling_frequency() * 1000\n\t            deltas12_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 1)]\n\t            deltas21_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 2)]\n\t            deltas11_msec = deltas_msec[(all_labels[offset:] == 1) & (all_labels[:-offset] == 1)]\n", "            deltas22_msec = deltas_msec[(all_labels[offset:] == 2) & (all_labels[:-offset] == 2)]\n\t            deltas12_msec = deltas12_msec[deltas12_msec <= bin_edges_msec[-1]]\n\t            deltas21_msec = deltas21_msec[deltas21_msec <= bin_edges_msec[-1]]\n\t            deltas11_msec = deltas11_msec[deltas11_msec <= bin_edges_msec[-1]]\n\t            deltas22_msec = deltas22_msec[deltas22_msec <= bin_edges_msec[-1]]\n\t            if (len(deltas12_msec) + len(deltas21_msec) + len(deltas11_msec) + len(deltas22_msec)) == 0: break\n\t            for i in range(num_bins_half):\n\t                start_msec = bin_edges_msec[num_bins_half - 1 + i]\n\t                end_msec = bin_edges_msec[num_bins_half + i]\n\t                ct12 = len(deltas12_msec[(start_msec <= deltas12_msec) & (deltas12_msec < end_msec)])\n", "                ct21 = len(deltas21_msec[(start_msec <= deltas21_msec) & (deltas21_msec < end_msec)])\n\t                bin_counts[num_bins_half - 1 + i] += ct12\n\t                bin_counts[num_bins_half - 1 - i] += ct21\n\t            offset = offset + 1\n\t    return {\n\t        'bin_edges_sec': (bin_edges_msec / 1000).astype(np.float32),\n\t        'bin_counts': bin_counts.astype(np.int32)\n\t    }"]}
{"filename": "examples/scheme1/helpers/create_autocorrelograms_view.py", "chunked_list": ["from typing import List\n\timport spikeinterface as si\n\timport sortingview.views as vv\n\tfrom helpers.compute_correlogram_data import compute_correlogram_data\n\tdef create_autocorrelograms_view(*, sorting: si.BaseSorting, unit_id_prefix: str=''):\n\t    autocorrelogram_items: List[vv.AutocorrelogramItem] = []\n\t    for unit_id in sorting.get_unit_ids():\n\t        a = compute_correlogram_data(sorting=sorting, unit_id1=unit_id, unit_id2=None, window_size_msec=80, bin_size_msec=1)\n\t        bin_edges_sec = a['bin_edges_sec']\n\t        bin_counts = a['bin_counts']\n", "        autocorrelogram_items.append(\n\t            vv.AutocorrelogramItem(\n\t                unit_id=f'{unit_id_prefix}{unit_id}',\n\t                bin_edges_sec=bin_edges_sec,\n\t                bin_counts=bin_counts\n\t            )\n\t        )\n\t    view = vv.Autocorrelograms(\n\t        autocorrelograms=autocorrelogram_items\n\t    )\n", "    return view"]}
{"filename": "examples/scheme1/helpers/create_units_table.py", "chunked_list": ["from typing import List\n\timport sortingview.views as vv\n\timport spikeinterface as si\n\tdef create_units_table(*, sorting: si.BaseSorting):\n\t    columns: List[vv.UnitsTableColumn] = []\n\t    rows: List[vv.UnitsTableRow] = []\n\t    for unit_id in sorting.get_unit_ids():\n\t        rows.append(\n\t            vv.UnitsTableRow(\n\t                unit_id=unit_id,\n", "                values={\n\t                    'unitId': unit_id\n\t                }\n\t            )\n\t        )\n\t    view = vv.UnitsTable(\n\t        columns=columns,\n\t        rows=rows\n\t    )\n\t    return view\n"]}
