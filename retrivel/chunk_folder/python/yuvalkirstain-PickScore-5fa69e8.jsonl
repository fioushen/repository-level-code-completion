{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\tsetup(name='trainer', version='1.0', packages=find_packages())"]}
{"filename": "trainer/slurm_scripts/slurm_train.py", "chunked_list": ["import os\n\timport random\n\timport sys\n\timport hydra\n\timport submitit\n\tfrom omegaconf import DictConfig\n\tfrom trainer.accelerators.utils import nvidia_smi_gpu_memory_stats, print_config\n\tDEEPSPEED_MULTINODE = \"<is_deepspeed_multinode>\"\n\tdef print_env():\n\t    for key in sorted(os.environ.keys()):\n", "        if not (\n\t                key.startswith((\"SLURM_\", \"SUBMITIT_\"))\n\t                or key in (\"MASTER_ADDR\", \"MASTER_PORT\", \"RANK\", \"WORLD_SIZE\", \"LOCAL_RANK\", \"LOCAL_WORLD_SIZE\")\n\t        ):\n\t            continue\n\t        value = os.environ[key]\n\t        print(f\"{key}={value}\")\n\tclass Task:\n\t    def __init__(self, cfg: DictConfig):\n\t        self.cfg = cfg\n", "    def __call__(self):\n\t        print(\"Running task on slurm\")\n\t        print(\"exporting PyTorch distributed environment variables\")\n\t        dist_env = submitit.helpers.TorchDistributedEnvironment()\n\t        rng = random.Random(dist_env._job_env.job_id)\n\t        dist_env.master_port = rng.randint(10000, 20000)\n\t        dist_env = dist_env.export()\n\t        os.environ.update(**{\n\t            \"CUDA_LAUNCH_BLOCKING\": \"0\",\n\t            \"NCCL_DEBUG\": \"info\",\n", "            \"CUDA_VISIBLE_DEVICES\": \"0,1,2,3,4,5,6,7\",\n\t            \"XDG_CACHE_HOME\": \"/fsx/yuval/.cache/\",\n\t            \"TOKENIZERS_PARALLELISM\": \"false\",\n\t            \"OMP_NUM_THREADS\": \"1\",\n\t        })\n\t        print(nvidia_smi_gpu_memory_stats())\n\t        print(f\"master: {dist_env.master_addr}:{dist_env.master_port}\")\n\t        print(f\"rank: {dist_env.rank}\")\n\t        print(f\"world size: {dist_env.world_size}\")\n\t        print(f\"local rank: {dist_env.local_rank}\")\n", "        print(f\"local world size: {dist_env.local_world_size}\")\n\t        print(\"Running training script\")\n\t        print(f\"Local rank {dist_env.local_rank}: {os.environ['CUDA_VISIBLE_DEVICES']=}\")\n\t        num_processes = self.cfg.slurm.n_processes * self.cfg.slurm.n_nodes\n\t        machine_rank = dist_env.rank // self.cfg.slurm.n_processes\n\t        cmd = f\"accelerate launch --dynamo_backend no --gpu_ids all --num_processes {num_processes} {DEEPSPEED_MULTINODE} --num_machines {self.cfg.slurm.n_nodes} --use_deepspeed --machine_rank {machine_rank} --main_process_ip {dist_env.master_addr} --main_process_port {dist_env.master_port} trainer/scripts/train.py {self.cfg.slurm.cmd}\"\n\t        if self.cfg.slurm.n_nodes > 1:\n\t            hostfile_dir = \"hostfiles\"\n\t            os.makedirs(hostfile_dir, exist_ok=True)\n\t            hostfile = os.path.realpath(f\"{hostfile_dir}/{dist_env._job_env.job_id}.txt\")\n", "            if dist_env.rank == 0:\n\t                with open(hostfile, \"w\") as f:\n\t                    for host in dist_env._job_env.hostnames:\n\t                        f.write(f\"{host} slots={self.cfg.slurm.n_processes}\\n\")\n\t                print(f\"Created hostfile: {hostfile}\")\n\t            cmd = cmd.replace(DEEPSPEED_MULTINODE, f\"--deepspeed_hostfile {hostfile} --deepspeed_multinode_launcher standard\")\n\t        else:\n\t            cmd = cmd.replace(DEEPSPEED_MULTINODE, \"\")\n\t        if dist_env.local_rank == 0:\n\t            print(f\"Running command: {cmd}\")\n", "            exit_code = os.system(cmd)\n\t        else:\n\t            exit_code = 0\n\t            print(\"Waiting for master to finish\")\n\t        if exit_code != 0:\n\t            raise RuntimeError(f\"Command {cmd} failed with exit code {exit_code}\")\n\t    def checkpoint(self):\n\t        print(\"checkpointing\")\n\t        return submitit.helpers.DelayedSubmission(self)\n\t@hydra.main(version_base=None, config_path=\"../conf\", config_name=\"slurm_config\")\n", "def main(cfg: DictConfig) -> None:\n\t    # import pydevd_pycharm\n\t    # pydevd_pycharm.settrace('localhost', port=5900, stdoutToServer=True, stderrToServer=True)\n\t    executor = submitit.AutoExecutor(folder=\"logs\")\n\t    print_config(cfg)\n\t    slurm_additional_parameters = {\n\t        \"gpus\": cfg.slurm.n_processes,\n\t        \"ntasks_per_node\": cfg.slurm.n_processes,\n\t    }\n\t    if cfg.slurm.account is not None:\n", "        slurm_additional_parameters[\"account\"] = cfg.slurm.account\n\t    print(f\"SLURM additional parameters: {slurm_additional_parameters}\")\n\t    slurm_kwargs = {\n\t        \"slurm_job_name\": cfg.slurm.job_name,\n\t        \"slurm_partition\": cfg.slurm.partition,\n\t        \"slurm_nodes\": cfg.slurm.n_nodes,\n\t        \"slurm_additional_parameters\": slurm_additional_parameters,\n\t        \"slurm_cpus_per_task\": 12,\n\t        \"slurm_time\": cfg.slurm.time_limit,\n\t        \"slurm_exclude\": cfg.slurm.exclude if cfg.slurm.exclude else \"\",\n", "        \"stderr_to_stdout\": True,\n\t        \"slurm_mem\": \"50GB\",\n\t    }\n\t    executor.update_parameters(**slurm_kwargs)\n\t    task = Task(cfg)\n\t    job = executor.submit(task)\n\t    submitit.helpers.monitor_jobs([job])\n\tif __name__ == \"__main__\":\n\t    sys.exit(main())\n"]}
{"filename": "trainer/datasetss/clip_hf_dataset.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom io import BytesIO\n\tfrom typing import Optional\n\timport torch\n\tfrom PIL import Image\n\tfrom accelerate.logging import get_logger\n\tfrom datasets import load_from_disk, load_dataset, Dataset\n\tfrom hydra.utils import instantiate\n\tfrom omegaconf import II\n\tfrom trainer.datasetss.base_dataset import BaseDataset, BaseDatasetConfig\n", "logger = get_logger(__name__)\n\tdef simple_collate(batch, column_name):\n\t    return torch.cat([item[column_name] for item in batch], dim=0)\n\t@dataclass\n\tclass ProcessorConfig:\n\t    _target_: str = \"transformers.AutoProcessor.from_pretrained\"\n\t    pretrained_model_name_or_path: str = II(\"model.pretrained_model_name_or_path\")\n\t@dataclass\n\tclass CLIPHFDatasetConfig(BaseDatasetConfig):\n\t    _target_: str = \"trainer.datasetss.clip_hf_dataset.CLIPHFDataset\"\n", "    dataset_name: str = \"yuvalkirstain/pickapic_v1\"\n\t    dataset_config_name: str = \"null\"\n\t    from_disk: bool = False\n\t    train_split_name: str = \"train\"\n\t    valid_split_name: str = \"validation_unique\"\n\t    test_split_name: str = \"test_unique\"\n\t    cache_dir: Optional[str] = None\n\t    caption_column_name: str = \"caption\"\n\t    input_ids_column_name: str = \"input_ids\"\n\t    image_0_column_name: str = \"jpg_0\"\n", "    image_1_column_name: str = \"jpg_1\"\n\t    label_0_column_name: str = \"label_0\"\n\t    label_1_column_name: str = \"label_1\"\n\t    are_different_column_name: str = \"are_different\"\n\t    has_label_column_name: str = \"has_label\"\n\t    pixels_0_column_name: str = \"pixel_values_0\"\n\t    pixels_1_column_name: str = \"pixel_values_1\"\n\t    num_examples_per_prompt_column_name: str = \"num_example_per_prompt\"\n\t    keep_only_different: bool = False\n\t    keep_only_with_label: bool = False\n", "    keep_only_with_label_in_non_train: bool = True\n\t    processor: ProcessorConfig = ProcessorConfig()\n\t    limit_examples_per_prompt: int = -1\n\t    only_on_best: bool = False\n\tclass CLIPHFDataset(BaseDataset):\n\t    def __init__(self, cfg: CLIPHFDatasetConfig, split: str = \"train\"):\n\t        self.cfg = cfg\n\t        self.split = split\n\t        logger.info(f\"Loading {self.split} dataset\")\n\t        self.dataset = self.load_hf_dataset(self.split)\n", "        logger.info(f\"Loaded {len(self.dataset)} examples from {self.split} dataset\")\n\t        if self.cfg.keep_only_different:\n\t            self.dataset = self.dataset.filter(lambda x: x[self.cfg.are_different_column_name])\n\t        if self.cfg.keep_only_with_label:\n\t            logger.info(f\"Keeping only examples with label\")\n\t            self.dataset = self.dataset.filter(lambda x: x[self.cfg.has_label_column_name])\n\t            logger.info(f\"Kept {len(self.dataset)} examples from {self.split} dataset\")\n\t        elif self.cfg.keep_only_with_label_in_non_train and self.split != self.cfg.train_split_name:\n\t            logger.info(f\"Keeping only examples with label in {self.split} split\")\n\t            self.dataset = self.dataset.filter(lambda x: x[self.cfg.has_label_column_name])\n", "            logger.info(f\"Kept {len(self.dataset)} examples from {self.split} dataset\")\n\t        if self.cfg.limit_examples_per_prompt > 0:\n\t            logger.info(f\"Limiting examples per prompt to {self.cfg.limit_examples_per_prompt}\")\n\t            df = self.dataset.to_pandas()\n\t            df = df.drop('__index_level_0__', axis=1)\n\t            logger.info(f\"Loaded {len(df)} examples from {self.split} dataset\")\n\t            df = df.groupby(self.cfg.caption_column_name).head(self.cfg.limit_examples_per_prompt)\n\t            logger.info(f\"Kept {len(df)} examples from {self.split} dataset\")\n\t            self.dataset = Dataset.from_pandas(df)\n\t        if self.cfg.only_on_best and self.split == self.cfg.train_split_name:\n", "            logger.info(f\"Keeping only best examples for training\")\n\t            train_dataset = self.dataset.remove_columns([self.cfg.image_0_column_name, self.cfg.image_1_column_name])\n\t            df = train_dataset.to_pandas()\n\t            df = df[df[self.cfg.has_label_column_name] == 1]\n\t            image_0_wins_df = df[df[self.cfg.label_0_column_name] == 1]\n\t            image_1_wins_df = df[df[self.cfg.label_0_column_name] == 0]\n\t            bad_image_0_to_good_image_1 = dict(zip(image_1_wins_df.image_0_uid, image_1_wins_df.image_1_uid))\n\t            bad_image_1_to_good_image_0 = dict(zip(image_0_wins_df.image_1_uid, image_0_wins_df.image_0_uid))\n\t            bad_images_uids2good_images_uids = bad_image_0_to_good_image_1 | bad_image_1_to_good_image_0\n\t            image_0_uid2image_col_name = dict(zip(df.image_0_uid, [self.cfg.image_0_column_name] * len(df.image_0_uid)))\n", "            image_1_uid2image_col_name = dict(zip(df.image_1_uid, [self.cfg.image_1_column_name] * len(df.image_1_uid)))\n\t            uid2image_col_name = image_0_uid2image_col_name | image_1_uid2image_col_name\n\t            bad_uids = set()\n\t            for bad_image, good_image in bad_images_uids2good_images_uids.items():\n\t                cur_good = {bad_image}\n\t                while good_image in bad_images_uids2good_images_uids:\n\t                    if good_image in cur_good:\n\t                        bad_uids.add(bad_image)\n\t                        break\n\t                    cur_good.add(good_image)\n", "                    good_image = bad_images_uids2good_images_uids[good_image]\n\t                bad_images_uids2good_images_uids[bad_image] = good_image\n\t            df = df[~(df.image_0_uid.isin(bad_uids) | df.image_1_uid.isin(bad_uids))]\n\t            keep_ids = df.index.tolist()\n\t            self.dataset = self.dataset.select(keep_ids)\n\t            new_ids = list(range(len(df)))\n\t            uid2index = dict(zip(df.image_0_uid, new_ids)) | dict(zip(df.image_1_uid, new_ids))\n\t            logger.info(f\"Kept only {len(self.dataset)} best examples for training\")\n\t            self.bad_images_uids2good_images_uids = bad_images_uids2good_images_uids\n\t            self.uid2index = uid2index\n", "            self.uid2image_col_name = uid2image_col_name\n\t        logger.info(f\"Loaded {len(self.dataset)} examples from {self.split} dataset\")\n\t        processor = instantiate(cfg.processor)\n\t        self.tokenizer = processor.tokenizer\n\t        self.image_processor = processor.image_processor\n\t    def load_hf_dataset(self, split: str) -> Dataset:\n\t        if self.cfg.from_disk:\n\t            dataset = load_from_disk(self.cfg.dataset_name)[split]\n\t        else:\n\t            dataset = load_dataset(\n", "                self.cfg.dataset_name,\n\t                self.cfg.dataset_config_name,\n\t                cache_dir=self.cfg.cache_dir,\n\t                split=split\n\t            )\n\t        return dataset\n\t    def tokenize(self, example):\n\t        caption = example[self.cfg.caption_column_name]\n\t        input_ids = self.tokenizer(\n\t            caption,\n", "            max_length=self.tokenizer.model_max_length,\n\t            padding=\"max_length\",\n\t            truncation=True,\n\t            return_tensors=\"pt\"\n\t        ).input_ids\n\t        return input_ids\n\t    def process_image(self, image):\n\t        if isinstance(image, dict):\n\t            image = image[\"bytes\"]\n\t        if isinstance(image, bytes):\n", "            image = Image.open(BytesIO(image))\n\t        image = image.convert(\"RGB\")\n\t        pixel_values = self.image_processor(image, return_tensors=\"pt\")[\"pixel_values\"]\n\t        return pixel_values\n\t    def __getitem__(self, idx):\n\t        example = self.dataset[idx]\n\t        if self.cfg.only_on_best and self.split == self.cfg.train_split_name:\n\t            if example[self.cfg.label_0_column_name]:\n\t                bad_image_uid = example[\"image_1_uid\"]\n\t                good_image_column_name = self.cfg.image_0_column_name\n", "            else:\n\t                bad_image_uid = example[\"image_0_uid\"]\n\t                good_image_column_name = self.cfg.image_1_column_name\n\t            good_image_uid = self.bad_images_uids2good_images_uids[bad_image_uid]\n\t            good_image_index = self.uid2index[good_image_uid]\n\t            example[good_image_column_name] = self.dataset[good_image_index][self.uid2image_col_name[good_image_uid]]\n\t        input_ids = self.tokenize(example)\n\t        pixel_0_values = self.process_image(example[self.cfg.image_0_column_name])\n\t        pixel_1_values = self.process_image(example[self.cfg.image_1_column_name])\n\t        item = {\n", "            self.cfg.input_ids_column_name: input_ids,\n\t            self.cfg.pixels_0_column_name: pixel_0_values,\n\t            self.cfg.pixels_1_column_name: pixel_1_values,\n\t            self.cfg.label_0_column_name: torch.tensor(example[self.cfg.label_0_column_name])[None],\n\t            self.cfg.label_1_column_name: torch.tensor(example[self.cfg.label_1_column_name])[None],\n\t            self.cfg.num_examples_per_prompt_column_name: torch.tensor(example[self.cfg.num_examples_per_prompt_column_name])[None],\n\t        }\n\t        return item\n\t    def collate_fn(self, batch):\n\t        input_ids = simple_collate(batch, self.cfg.input_ids_column_name)\n", "        pixel_0_values = simple_collate(batch, self.cfg.pixels_0_column_name)\n\t        pixel_1_values = simple_collate(batch, self.cfg.pixels_1_column_name)\n\t        label_0 = simple_collate(batch, self.cfg.label_0_column_name)\n\t        label_1 = simple_collate(batch, self.cfg.label_1_column_name)\n\t        num_examples_per_prompt = simple_collate(batch, self.cfg.num_examples_per_prompt_column_name)\n\t        pixel_0_values = pixel_0_values.to(memory_format=torch.contiguous_format).float()\n\t        pixel_1_values = pixel_1_values.to(memory_format=torch.contiguous_format).float()\n\t        collated = {\n\t            self.cfg.input_ids_column_name: input_ids,\n\t            self.cfg.pixels_0_column_name: pixel_0_values,\n", "            self.cfg.pixels_1_column_name: pixel_1_values,\n\t            self.cfg.label_0_column_name: label_0,\n\t            self.cfg.label_1_column_name: label_1,\n\t            self.cfg.num_examples_per_prompt_column_name: num_examples_per_prompt,\n\t        }\n\t        return collated\n\t    def __len__(self):\n\t        return len(self.dataset)\n"]}
{"filename": "trainer/datasetss/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.datasetss.clip_hf_dataset import CLIPHFDatasetConfig\n\tcs = ConfigStore.instance()\n\tcs.store(group=\"dataset\", name=\"clip\", node=CLIPHFDatasetConfig)\n"]}
{"filename": "trainer/datasetss/base_dataset.py", "chunked_list": ["from dataclasses import dataclass\n\timport torch\n\t@dataclass\n\tclass BaseDatasetConfig:\n\t    train_split_name: str = \"train\"\n\t    valid_split_name: str = \"validation\"\n\t    test_split_name: str = \"test\"\n\t    batch_size: int = 4\n\t    num_workers: int = 2\n\t    drop_last: bool = True\n", "class BaseDataset(torch.utils.data.Dataset):\n\t    pass\n"]}
{"filename": "trainer/configs/configs.py", "chunked_list": ["from dataclasses import dataclass, field\n\tfrom typing import List, Any, Dict\n\tfrom omegaconf import DictConfig, MISSING\n\timport trainer.accelerators\n\timport trainer.tasks\n\timport trainer.models\n\timport trainer.criterions\n\timport trainer.datasetss\n\timport trainer.optimizers\n\timport trainer.lr_schedulers\n", "from trainer.accelerators.base_accelerator import BaseAcceleratorConfig\n\tfrom trainer.models.base_model import BaseModelConfig\n\tfrom trainer.tasks.base_task import BaseTaskConfig\n\tdef _locate(path: str) -> Any:\n\t    \"\"\"\n\t    Locate an object by name or dotted path, importing as necessary.\n\t    This is similar to the pydoc function `locate`, except that it checks for\n\t    the module from the given path from back to front.\n\t    \"\"\"\n\t    if path == \"\":\n", "        raise ImportError(\"Empty path\")\n\t    from importlib import import_module\n\t    from types import ModuleType\n\t    parts = [part for part in path.split(\".\")]\n\t    for part in parts:\n\t        if not len(part):\n\t            raise ValueError(\n\t                f\"Error loading '{path}': invalid dotstring.\"\n\t                + \"\\nRelative imports are not supported.\"\n\t            )\n", "    assert len(parts) > 0\n\t    part0 = parts[0]\n\t    try:\n\t        obj = import_module(part0)\n\t    except Exception as exc_import:\n\t        raise ImportError(\n\t            f\"Error loading '{path}':\\n{repr(exc_import)}\"\n\t            + f\"\\nAre you sure that module '{part0}' is installed?\"\n\t        ) from exc_import\n\t    for m in range(1, len(parts)):\n", "        part = parts[m]\n\t        try:\n\t            obj = getattr(obj, part)\n\t        except AttributeError as exc_attr:\n\t            parent_dotpath = \".\".join(parts[:m])\n\t            if isinstance(obj, ModuleType):\n\t                mod = \".\".join(parts[: m + 1])\n\t                try:\n\t                    obj = import_module(mod)\n\t                    continue\n", "                except ModuleNotFoundError as exc_import:\n\t                    raise ImportError(\n\t                        f\"Error loading '{path}':\\n{repr(exc_import)}\"\n\t                        + f\"\\nAre you sure that '{part}' is importable from module '{parent_dotpath}'?\"\n\t                    ) from exc_import\n\t                except Exception as exc_import:\n\t                    raise ImportError(\n\t                        f\"Error loading '{path}':\\n{repr(exc_import)}\"\n\t                    ) from exc_import\n\t            raise ImportError(\n", "                f\"Error loading '{path}':\\n{repr(exc_attr)}\"\n\t                + f\"\\nAre you sure that '{part}' is an attribute of '{parent_dotpath}'?\"\n\t            ) from exc_attr\n\t    return obj\n\tdef instantiate_with_cfg(cfg: DictConfig, **kwargs):\n\t    target = _locate(cfg._target_)\n\t    return target(cfg, **kwargs)\n\tdefaults = [\n\t    {\"accelerator\": \"deepspeed\"},\n\t    {\"task\": \"clip\"},\n", "    {\"model\": \"clip\"},\n\t    {\"criterion\": \"clip\"},\n\t    {\"dataset\": \"clip\"},\n\t    {\"optimizer\": \"dummy\"},\n\t    {\"lr_scheduler\": \"dummy\"},\n\t]\n\t@dataclass\n\tclass DebugConfig:\n\t    activate: bool = False\n\t    port: int = 5900\n", "@dataclass\n\tclass TrainerConfig:\n\t    defaults: List[Any] = field(default_factory=lambda: defaults)\n\t    accelerator: BaseAcceleratorConfig = MISSING\n\t    task: BaseTaskConfig = MISSING\n\t    model: BaseModelConfig = MISSING\n\t    criterion: Any = MISSING\n\t    dataset: Any = MISSING\n\t    optimizer: Any = MISSING\n\t    lr_scheduler: Any = MISSING\n", "    debug: DebugConfig = DebugConfig()\n\t    output_dir: str = \"outputs\"\n"]}
{"filename": "trainer/configs/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.configs.configs import TrainerConfig\n\tcs = ConfigStore.instance()\n\tcs.store(name=\"base_config\", node=TrainerConfig)\n"]}
{"filename": "trainer/utils/data_utils.py", "chunked_list": ["import logging\n\tfrom glob import glob\n\tfrom io import BytesIO\n\tfrom PIL import Image\n\tfrom tqdm import tqdm\n\tfrom datasets import load_dataset, concatenate_datasets, Dataset, load_from_disk\n\tlogger = logging.getLogger(__name__)\n\tdef parquet2dataset(parquet_path: str):\n\t    datasets = []\n\t    for path in sorted(glob(f\"{parquet_path}/*.parquet\")):\n", "        datasets.append(load_dataset(\"parquet\", data_files=path)[\"train\"])\n\t    dataset = concatenate_datasets(datasets)\n\t    return dataset\n\tdef bytes2image(bytes: bytes):\n\t    image = Image.open(BytesIO(bytes))\n\t    image = image.convert(\"RGB\")\n\t    return image\n\tdef dataset2images(dataset, pool, col):\n\t    image_bytes = dataset[col]\n\t    images = list(tqdm(pool.imap(bytes2image, image_bytes), total=len(image_bytes)))\n", "    return images\n"]}
{"filename": "trainer/utils/__init__.py", "chunked_list": []}
{"filename": "trainer/utils/slurm_utils.py", "chunked_list": ["from collections import Counter\n\tfrom time import sleep\n\tfrom tqdm import tqdm\n\tdef track_jobs_with_pbar(jobs):\n\t    num_completed = 0\n\t    with tqdm(total=len(jobs)) as pbar:\n\t        while any(job.state not in [\"COMPLETED\", \"FAILED\", \"DONE\"] for job in jobs):\n\t            sleep(2)\n\t            job_infos = [j.get_info() for j in jobs]\n\t            state2count = Counter([info['State'] if 'State' in info else \"None\" for info in job_infos])\n", "            newly_completed = state2count[\"COMPLETED\"] - num_completed\n\t            pbar.update(newly_completed)\n\t            num_completed = state2count[\"COMPLETED\"]\n\t            s = [f\"{k}: {v}\" for k, v in state2count.items()]\n\t            pbar.set_description(\" | \".join(s))\n\t    return num_completed\n"]}
{"filename": "trainer/utils/FID/img_data.py", "chunked_list": ["import os\n\timport torch\n\tfrom torch.utils import data\n\timport torchvision.transforms as transforms\n\tfrom PIL import Image\n\tfrom datasets import Dataset as HFDataset\n\tclass Dataset(data.Dataset):\n\t    'Characterizes a dataset for PyTorch'\n\t    def __init__(self, path, transform=None):\n\t        'Initialization'\n", "        self.file_names = self.get_filenames(path)\n\t        self.transform = transform\n\t    def __len__(self):\n\t        'Denotes the total number of samples'\n\t        return len(self.file_names)\n\t    def __getitem__(self, index):\n\t        'Generates one sample of data'\n\t        img = Image.open(self.file_names[index]).convert('RGB')\n\t        # Convert image and label to torch tensors\n\t        if self.transform is not None:\n", "            img = self.transform(img)\n\t        return img\n\t    def get_filenames(self, data_path):\n\t        images = []\n\t        for path, subdirs, files in os.walk(data_path):\n\t            for name in files:\n\t                if name.rfind('jpg') != -1 or name.rfind('png') != -1:\n\t                    filename = os.path.join(path, name)\n\t                    if os.path.isfile(filename):\n\t                        images.append(filename)\n", "        return images\n\tclass HFImgDataset:\n\t    def __init__(self, dataset, transform=None):\n\t        self.dataset = dataset\n\t        self.transform = transform\n\t    def __len__(self):\n\t        return len(self.dataset)\n\t    def __getitem__(self, item):\n\t        example = self.dataset[item]\n\t        if self.transform is not None:\n", "            example[\"image\"] = self.transform(example[\"image\"])\n\t        return example[\"image\"]\n\tif __name__ == '__main__':\n\t    path = \"/media/twilightsnow/workspace/gan/AttnGAN/output/birds_attn2_2018_06_24_14_52_20/Model/netG_avg_epoch_300\"\n\t    batch_size = 16\n\t    dataset = Dataset(path, transforms.Compose([\n\t        transforms.Resize(299),\n\t        transforms.ToTensor(),\n\t        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\t        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n", "    ]))\n\t    print(dataset.__len__())\n\t    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n\t    for i, batch in enumerate(dataloader):\n\t        print(batch)\n\t        break\n"]}
{"filename": "trainer/utils/FID/inception.py", "chunked_list": ["import torch.nn as nn\n\timport torch.nn.functional as F\n\tfrom torchvision import models\n\tclass InceptionV3(nn.Module):\n\t    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n\t    # Index of default block of inception to return,\n\t    # corresponds to output of final average pooling\n\t    DEFAULT_BLOCK_INDEX = 3\n\t    # Maps feature dimensionality to their output blocks indices\n\t    BLOCK_INDEX_BY_DIM = {\n", "        64: 0,   # First max pooling features\n\t        192: 1,  # Second max pooling featurs\n\t        768: 2,  # Pre-aux classifier features\n\t        2048: 3  # Final average pooling features\n\t    }\n\t    def __init__(self,\n\t                 output_blocks=[DEFAULT_BLOCK_INDEX],\n\t                 resize_input=True,\n\t                 normalize_input=True,\n\t                 requires_grad=False):\n", "        \"\"\"Build pretrained InceptionV3\n\t        Parameters\n\t        ----------\n\t        output_blocks : list of int\n\t            Indices of blocks to return features of. Possible values are:\n\t                - 0: corresponds to output of first max pooling\n\t                - 1: corresponds to output of second max pooling\n\t                - 2: corresponds to output which is fed to aux classifier\n\t                - 3: corresponds to output of final average pooling\n\t        resize_input : bool\n", "            If true, bilinearly resizes input to width and height 299 before\n\t            feeding input to model. As the network without fully connected\n\t            layers is fully convolutional, it should be able to handle inputs\n\t            of arbitrary size, so resizing might not be strictly needed\n\t        normalize_input : bool\n\t            If true, normalizes the input to the statistics the pretrained\n\t            Inception network expects\n\t        requires_grad : bool\n\t            If true, parameters of the model require gradient. Possibly useful\n\t            for finetuning the network\n", "        \"\"\"\n\t        super(InceptionV3, self).__init__()\n\t        self.resize_input = resize_input\n\t        self.normalize_input = normalize_input\n\t        self.output_blocks = sorted(output_blocks)\n\t        self.last_needed_block = max(output_blocks)\n\t        assert self.last_needed_block <= 3, \\\n\t            'Last possible output block index is 3'\n\t        self.blocks = nn.ModuleList()\n\t        inception = models.inception_v3(pretrained=True)\n", "        # Block 0: input to maxpool1\n\t        block0 = [\n\t            inception.Conv2d_1a_3x3,\n\t            inception.Conv2d_2a_3x3,\n\t            inception.Conv2d_2b_3x3,\n\t            nn.MaxPool2d(kernel_size=3, stride=2)\n\t        ]\n\t        self.blocks.append(nn.Sequential(*block0))\n\t        # Block 1: maxpool1 to maxpool2\n\t        if self.last_needed_block >= 1:\n", "            block1 = [\n\t                inception.Conv2d_3b_1x1,\n\t                inception.Conv2d_4a_3x3,\n\t                nn.MaxPool2d(kernel_size=3, stride=2)\n\t            ]\n\t            self.blocks.append(nn.Sequential(*block1))\n\t        # Block 2: maxpool2 to aux classifier\n\t        if self.last_needed_block >= 2:\n\t            block2 = [\n\t                inception.Mixed_5b,\n", "                inception.Mixed_5c,\n\t                inception.Mixed_5d,\n\t                inception.Mixed_6a,\n\t                inception.Mixed_6b,\n\t                inception.Mixed_6c,\n\t                inception.Mixed_6d,\n\t                inception.Mixed_6e,\n\t            ]\n\t            self.blocks.append(nn.Sequential(*block2))\n\t        # Block 3: aux classifier to final avgpool\n", "        if self.last_needed_block >= 3:\n\t            block3 = [\n\t                inception.Mixed_7a,\n\t                inception.Mixed_7b,\n\t                inception.Mixed_7c,\n\t                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n\t            ]\n\t            self.blocks.append(nn.Sequential(*block3))\n\t        for param in self.parameters():\n\t            param.requires_grad = requires_grad\n", "    def forward(self, inp):\n\t        \"\"\"Get Inception feature maps\n\t        Parameters\n\t        ----------\n\t        inp : torch.autograd.Variable\n\t            Input tensor of shape Bx3xHxW. Values are expected to be in\n\t            range (0, 1)\n\t        Returns\n\t        -------\n\t        List of torch.autograd.Variable, corresponding to the selected output\n", "        block, sorted ascending by index\n\t        \"\"\"\n\t        outp = []\n\t        x = inp\n\t        if self.resize_input:\n\t            x = F.upsample(x, size=(299, 299), mode='bilinear', align_corners=True)\n\t        if self.normalize_input:\n\t            x = x.clone()\n\t            x[:, 0] = x[:, 0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n\t            x[:, 1] = x[:, 1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n", "            x[:, 2] = x[:, 2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n\t        for idx, block in enumerate(self.blocks):\n\t            x = block(x)\n\t            if idx in self.output_blocks:\n\t                outp.append(x)\n\t            if idx == self.last_needed_block:\n\t                break\n\t        return outp"]}
{"filename": "trainer/utils/FID/__init__.py", "chunked_list": []}
{"filename": "trainer/utils/FID/fid_score.py", "chunked_list": ["#!/usr/bin/env python3\n\t\"\"\"\n\tPorted from https://github.com/MinfengZhu/DM-GAN/blob/master/eval/FID/fid_score.py\n\tCalculates the Frechet Inception Distance (FID) to evalulate GANs\n\tThe FID metric calculates the distance between two distributions of images.\n\tTypically, we have summary statistics (mean & covariance matrix) of one\n\tof these distributions, while the 2nd distribution is given by a GAN.\n\tWhen run as a stand-alone program, it compares the distribution of\n\timages that are stored as PNG/JPEG at a specified location with a\n\tdistribution given by summary statistics (in pickle format).\n", "The FID is calculated by assuming that X_1 and X_2 are the activations of\n\tthe pool_3 layer of the inception net for generated samples and real world\n\tsamples respectivly.\n\tSee --help to see further details.\n\tCode apapted from https://github.com/bioinf-jku/TTUR to use PyTorch instead\n\tof Tensorflow\n\tCopyright 2018 Institute of Bioinformatics, JKU Linz\n\tLicensed under the Apache License, Version 2.0 (the \"License\");\n\tyou may not use this file except in compliance with the License.\n\tYou may obtain a copy of the License at\n", "   http://www.apache.org/licenses/LICENSE-2.0\n\tUnless required by applicable law or agreed to in writing, software\n\tdistributed under the License is distributed on an \"AS IS\" BASIS,\n\tWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\tSee the License for the specific language governing permissions and\n\tlimitations under the License.\n\t\"\"\"\n\timport os\n\timport pathlib\n\tfrom argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n", "from glob import glob\n\timport torch\n\timport numpy as np\n\tfrom PIL import Image\n\tfrom datasets import load_from_disk, concatenate_datasets\n\ttry:\n\t    from torchvision.transforms import InterpolationMode\n\t    BICUBIC = InterpolationMode.BICUBIC\n\texcept ImportError:\n\t    BICUBIC = Image.BICUBIC\n", "from imageio import imread\n\tfrom scipy import linalg\n\tfrom torch.autograd import Variable\n\tfrom torch.nn.functional import adaptive_avg_pool2d\n\timport torchvision.transforms as transforms\n\timport torch.utils.data\n\tfrom PIL import Image\n\tfrom torch.utils import data\n\tfrom trainer.utils.FID.inception import InceptionV3\n\timport trainer.utils.FID.img_data as img_data\n", "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n\t#parser.add_argument('path', type=str, nargs=2,\n\t#                    help=('Path to the generated images or '\n\t#                          'to .npz statistic files'))\n\tparser.add_argument('--batch-size', type=int, default=64,\n\t                    help='Batch size to use')\n\tparser.add_argument('--dims', type=int, default=2048,\n\t                    choices=list(InceptionV3.BLOCK_INDEX_BY_DIM),\n\t                    help=('Dimensionality of Inception features to use. '\n\t                          'By default, uses pool3 features'))\n", "parser.add_argument('-c', '--gpu', default='', type=str,\n\t                    help='GPU to use (leave blank for CPU only)')\n\tparser.add_argument('--path1', type=str, default=64)\n\tparser.add_argument('--path2', type=str, default=64)\n\tdef get_activations(images, model, batch_size=64, dims=2048, cuda=False, verbose=True):\n\t    \"\"\"Calculates the activations of the pool_3 layer for all images.\n\t    Params:\n\t    -- images      : Numpy array of dimension (n_images, 3, hi, wi). The values\n\t                     must lie between 0 and 1.\n\t    -- model       : Instance of inception model\n", "    -- batch_size  : the images numpy array is split into batches with\n\t                     batch size batch_size. A reasonable batch size depends\n\t                     on the hardware.\n\t    -- dims        : Dimensionality of features returned by Inception\n\t    -- cuda        : If set to True, use GPU\n\t    -- verbose     : If set to True and parameter out_step is given, the number\n\t                     of calculated batches is reported.\n\t    Returns:\n\t    -- A numpy array of dimension (num images, dims) that contains the\n\t       activations of the given tensor when feeding inception with the\n", "       query tensor.\n\t    \"\"\"\n\t    model.eval()\n\t    #d0 = images.shape[0]\n\t    d0 = images.__len__() * batch_size\n\t    if batch_size > d0:\n\t        print(('Warning: batch size is bigger than the data size. '\n\t               'Setting batch size to data size'))\n\t        batch_size = d0\n\t    n_batches = d0 // batch_size\n", "    n_used_imgs = n_batches * batch_size\n\t    pred_arr = np.empty((n_used_imgs, dims))\n\t    #for i in range(n_batches):\n\t    for i, batch in enumerate(images):\n\t        #batch = batch[0]\n\t        #if verbose:\n\t            #print('\\rPropagating batch %d/%d' % (i + 1, n_batches), end='', flush=True)\n\t        #import ipdb\n\t        #ipdb.set_trace()\n\t        start = i * batch_size\n", "        end = start + batch_size\n\t        #batch = torch.from_numpy(images[start:end]).type(torch.FloatTensor)\n\t        #batch = Variable(batch, volatile=True)\n\t        if cuda:\n\t            batch = batch.cuda()\n\t        pred = model(batch)[0]\n\t        # If model output is not scalar, apply global spatial average pooling.\n\t        # This happens if you choose a dimensionality not equal 2048.\n\t        if pred.shape[2] != 1 or pred.shape[3] != 1:\n\t            pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n", "        pred_arr[start:end] = pred.cpu().data.numpy().reshape(batch_size, -1)\n\t    if verbose:\n\t        print(' done')\n\t    return pred_arr\n\tdef calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n\t    \"\"\"Numpy implementation of the Frechet Distance.\n\t    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n\t    and X_2 ~ N(mu_2, C_2) is\n\t            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n\t    Stable version by Dougal J. Sutherland.\n", "    Params:\n\t    -- mu1   : Numpy array containing the activations of a layer of the\n\t               inception net (like returned by the function 'get_predictions')\n\t               for generated samples.\n\t    -- mu2   : The sample mean over activations, precalculated on an\n\t               representive data set.\n\t    -- sigma1: The covariance matrix over activations for generated samples.\n\t    -- sigma2: The covariance matrix over activations, precalculated on an\n\t               representive data set.\n\t    Returns:\n", "    --   : The Frechet Distance.\n\t    \"\"\"\n\t    mu1 = np.atleast_1d(mu1)\n\t    mu2 = np.atleast_1d(mu2)\n\t    sigma1 = np.atleast_2d(sigma1)\n\t    sigma2 = np.atleast_2d(sigma2)\n\t    assert mu1.shape == mu2.shape, \\\n\t        'Training and test mean vectors have different lengths'\n\t    assert sigma1.shape == sigma2.shape, \\\n\t        'Training and test covariances have different dimensions'\n", "    diff = mu1 - mu2\n\t    # Product might be almost singular\n\t    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n\t    if not np.isfinite(covmean).all():\n\t        msg = ('fid calculation produces singular product; '\n\t               'adding %s to diagonal of cov estimates') % eps\n\t        print(msg)\n\t        offset = np.eye(sigma1.shape[0]) * eps\n\t        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n\t    # Numerical error might give slight imaginary component\n", "    if np.iscomplexobj(covmean):\n\t        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n\t            m = np.max(np.abs(covmean.imag))\n\t            raise ValueError('Imaginary component {}'.format(m))\n\t        covmean = covmean.real\n\t    tr_covmean = np.trace(covmean)\n\t    return (diff.dot(diff) + np.trace(sigma1) +\n\t            np.trace(sigma2) - 2 * tr_covmean)\n\tdef calculate_activation_statistics(images, model, batch_size=64,\n\t                                    dims=2048, cuda=False, verbose=True):\n", "    \"\"\"Calculation of the statistics used by the FID.\n\t    Params:\n\t    -- images      : Numpy array of dimension (n_images, 3, hi, wi). The values\n\t                     must lie between 0 and 1.\n\t    -- model       : Instance of inception model\n\t    -- batch_size  : The images numpy array is split into batches with\n\t                     batch size batch_size. A reasonable batch size\n\t                     depends on the hardware.\n\t    -- dims        : Dimensionality of features returned by Inception\n\t    -- cuda        : If set to True, use GPU\n", "    -- verbose     : If set to True and parameter out_step is given, the\n\t                     number of calculated batches is reported.\n\t    Returns:\n\t    -- mu    : The mean over samples of the activations of the pool_3 layer of\n\t               the inception model.\n\t    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n\t               the inception model.\n\t    \"\"\"\n\t    act = get_activations(images, model, batch_size, dims, cuda, verbose)\n\t    mu = np.mean(act, axis=0)\n", "    sigma = np.cov(act, rowvar=False)\n\t    return mu, sigma\n\tdef _compute_statistics_of_path(path, model, batch_size, dims, cuda):\n\t    if path.endswith('.npz'):\n\t        f = np.load(path)\n\t        m, s = f['mu'][:], f['sigma'][:]\n\t        f.close()\n\t    else:\n\t        dataset_transforms = transforms.Compose([\n\t            transforms.Resize(256, interpolation=BICUBIC),\n", "            transforms.CenterCrop(256),\n\t            transforms.Resize((299, 299)),\n\t            transforms.ToTensor(),\n\t        ])\n\t        if path.endswith('*'):\n\t            dataset = concatenate_datasets([load_from_disk(ds_path) for ds_path in glob(path)])\n\t            dataset = img_data.HFImgDataset(dataset, dataset_transforms)\n\t        else:\n\t            dataset = img_data.Dataset(path, dataset_transforms)\n\t        print(dataset.__len__())\n", "        dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=8)\n\t        m, s = calculate_activation_statistics(dataloader, model, batch_size, dims, cuda)\n\t    return m, s\n\tdef calculate_fid_given_paths(paths, batch_size, cuda, dims):\n\t    \"\"\"Calculates the FID of two paths\"\"\"\n\t    for p in paths:\n\t        if not os.path.exists(p) and \"*\" not in p:\n\t            raise RuntimeError('Invalid path: %s' % p)\n\t    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n\t    model = InceptionV3([block_idx])\n", "    if cuda:\n\t        model.cuda()\n\t    m1, s1 = _compute_statistics_of_path(paths[0], model, batch_size, dims, cuda)\n\t    m2, s2 = _compute_statistics_of_path(paths[1], model, batch_size, dims, cuda)\n\t    fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n\t    return fid_value\n\t@torch.no_grad()\n\tdef image2pred(model, batch):\n\t    model.eval()\n\t    pred = model(batch)[0]\n", "    # If model output is not scalar, apply global spatial average pooling.\n\t    # This happens if you choose a dimensionality not equal 2048.\n\t    if pred.shape[2] != 1 or pred.shape[3] != 1:\n\t        pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n\t    pred = pred.data.view(batch.size(0), -1)\n\t    return pred\n\tif __name__ == '__main__':\n\t    args = parser.parse_args()\n\t    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n\t    paths = [\"\",\"\"]\n", "    paths[0] = args.path1\n\t    paths[1] = args.path2\n\t    print(paths)\n\t    fid_value = calculate_fid_given_paths(paths, args.batch_size,args.gpu,args.dims)\n\t    print('FID: ', fid_value)"]}
{"filename": "trainer/scripts/train.py", "chunked_list": ["import json\n\timport os\n\tfrom typing import Any\n\timport hydra\n\timport torch\n\tfrom hydra.utils import instantiate\n\tfrom accelerate.logging import get_logger\n\tfrom omegaconf import DictConfig, OmegaConf\n\tfrom torch import nn\n\tfrom trainer.accelerators.base_accelerator import BaseAccelerator\n", "from trainer.configs.configs import TrainerConfig, instantiate_with_cfg\n\tlogger = get_logger(__name__)\n\tos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\tdef load_dataloaders(cfg: DictConfig) -> Any:\n\t    dataloaders = {}\n\t    for split in [cfg.train_split_name, cfg.valid_split_name, cfg.test_split_name]:\n\t        dataset = instantiate_with_cfg(cfg, split=split)\n\t        should_shuffle = split == cfg.train_split_name\n\t        dataloaders[split] = torch.utils.data.DataLoader(\n\t            dataset,\n", "            shuffle=should_shuffle,\n\t            batch_size=cfg.batch_size,\n\t            collate_fn=dataset.collate_fn,\n\t            num_workers=cfg.num_workers\n\t        )\n\t    return dataloaders\n\tdef load_optimizer(cfg: DictConfig, model: nn.Module):\n\t    optimizer = instantiate(cfg, model=model)\n\t    return optimizer\n\tdef load_scheduler(cfg: DictConfig, optimizer):\n", "    scheduler = instantiate_with_cfg(cfg, optimizer=optimizer)\n\t    return scheduler\n\tdef load_task(cfg: DictConfig, accelerator: BaseAccelerator):\n\t    task = instantiate_with_cfg(cfg, accelerator=accelerator)\n\t    return task\n\tdef verify_or_write_config(cfg: TrainerConfig):\n\t    os.makedirs(cfg.output_dir, exist_ok=True)\n\t    yaml_path = os.path.join(cfg.output_dir, \"config.yaml\")\n\t    if not os.path.exists(yaml_path):\n\t        OmegaConf.save(cfg, yaml_path, resolve=True)\n", "    with open(yaml_path) as f:\n\t        existing_config = f.read()\n\t    if existing_config != OmegaConf.to_yaml(cfg, resolve=True):\n\t        raise ValueError(f\"Config was not saved correctly - {yaml_path}\")\n\t    logger.info(f\"Config can be found in {yaml_path}\")\n\t@hydra.main(version_base=None, config_path=\"../conf\", config_name=\"config\")\n\tdef main(cfg: TrainerConfig) -> None:\n\t    accelerator = instantiate_with_cfg(cfg.accelerator)\n\t    if cfg.debug.activate and accelerator.is_main_process:\n\t        import pydevd_pycharm\n", "        pydevd_pycharm.settrace('localhost', port=cfg.debug.port, stdoutToServer=True, stderrToServer=True)\n\t    if accelerator.is_main_process:\n\t        verify_or_write_config(cfg)\n\t    logger.info(f\"Loading task\")\n\t    task = load_task(cfg.task, accelerator)\n\t    logger.info(f\"Loading model\")\n\t    model = instantiate_with_cfg(cfg.model)\n\t    logger.info(f\"Loading criterion\")\n\t    criterion = instantiate_with_cfg(cfg.criterion)\n\t    logger.info(f\"Loading optimizer\")\n", "    optimizer = load_optimizer(cfg.optimizer, model)\n\t    logger.info(f\"Loading lr scheduler\")\n\t    lr_scheduler = load_scheduler(cfg.lr_scheduler, optimizer)\n\t    logger.info(f\"Loading dataloaders\")\n\t    split2dataloader = load_dataloaders(cfg.dataset)\n\t    dataloaders = list(split2dataloader.values())\n\t    model, optimizer, lr_scheduler, *dataloaders = accelerator.prepare(model, optimizer, lr_scheduler, *dataloaders)\n\t    split2dataloader = dict(zip(split2dataloader.keys(), dataloaders))\n\t    accelerator.load_state_if_needed()\n\t    accelerator.recalc_train_length_after_prepare(len(split2dataloader[cfg.dataset.train_split_name]))\n", "    accelerator.init_training(cfg)\n\t    def evaluate():\n\t        model.eval()\n\t        end_of_train_dataloader = accelerator.gradient_state.end_of_dataloader\n\t        logger.info(f\"*** Evaluating {cfg.dataset.valid_split_name} ***\")\n\t        metrics = task.evaluate(model, criterion, split2dataloader[cfg.dataset.valid_split_name])\n\t        accelerator.update_metrics(metrics)\n\t        accelerator.gradient_state.end_of_dataloader = end_of_train_dataloader\n\t    logger.info(f\"task: {task.__class__.__name__}\")\n\t    logger.info(f\"model: {model.__class__.__name__}\")\n", "    logger.info(f\"num. model params: {int(sum(p.numel() for p in model.parameters()) // 1e6)}M\")\n\t    logger.info(\n\t        f\"num. model trainable params: {int(sum(p.numel() for p in model.parameters() if p.requires_grad) // 1e6)}M\")\n\t    logger.info(f\"criterion: {criterion.__class__.__name__}\")\n\t    logger.info(f\"num. train examples: {len(split2dataloader[cfg.dataset.train_split_name].dataset)}\")\n\t    logger.info(f\"num. valid examples: {len(split2dataloader[cfg.dataset.valid_split_name].dataset)}\")\n\t    logger.info(f\"num. test examples: {len(split2dataloader[cfg.dataset.test_split_name].dataset)}\")\n\t    for epoch in range(accelerator.cfg.num_epochs):\n\t        train_loss, lr = 0.0, 0.0\n\t        for step, batch in enumerate(split2dataloader[cfg.dataset.train_split_name]):\n", "            if accelerator.should_skip(epoch, step):\n\t                accelerator.update_progbar_step()\n\t                continue\n\t            if accelerator.should_eval():\n\t                evaluate()\n\t            if accelerator.should_save():\n\t                accelerator.save_checkpoint()\n\t            model.train()\n\t            with accelerator.accumulate(model):\n\t                loss = task.train_step(model, criterion, batch)\n", "                avg_loss = accelerator.gather(loss).mean().item()\n\t                accelerator.backward(loss)\n\t                if accelerator.sync_gradients:\n\t                    accelerator.clip_grad_norm_(model.parameters())\n\t                optimizer.step()\n\t                lr_scheduler.step()\n\t                optimizer.zero_grad()\n\t            train_loss += avg_loss / accelerator.cfg.gradient_accumulation_steps\n\t            if accelerator.sync_gradients:\n\t                accelerator.update_global_step(train_loss)\n", "                train_loss = 0.0\n\t            if accelerator.global_step > 0:\n\t                lr = lr_scheduler.get_last_lr()[0]\n\t            accelerator.update_step(avg_loss, lr)\n\t            if accelerator.should_end():\n\t                evaluate()\n\t                accelerator.save_checkpoint()\n\t                break\n\t        if accelerator.should_end():\n\t            break\n", "        accelerator.update_epoch()\n\t    accelerator.wait_for_everyone()\n\t    accelerator.load_best_checkpoint()\n\t    logger.info(f\"*** Evaluating {cfg.dataset.valid_split_name} ***\")\n\t    metrics = task.evaluate(model, criterion, split2dataloader[cfg.dataset.valid_split_name])\n\t    accelerator.update_metrics(metrics)\n\t    logger.info(f\"*** Evaluating {cfg.dataset.test_split_name} ***\")\n\t    metrics = task.evaluate(model, criterion, split2dataloader[cfg.dataset.test_split_name])\n\t    metrics = {f\"{cfg.dataset.test_split_name}_{k}\": v for k, v in metrics.items()}\n\t    accelerator.update_metrics(metrics)\n", "    accelerator.unwrap_and_save(model)\n\t    accelerator.end_training()\n\tif __name__ == '__main__':\n\t    main()\n"]}
{"filename": "trainer/scripts/eval_preference_predictor.py", "chunked_list": ["import numpy as np\n\tfrom transformers import AutoProcessor, AutoModel\n\tfrom datasets import load_from_disk, load_dataset\n\timport torch\n\tfrom PIL import Image\n\tfrom io import BytesIO\n\tfrom tqdm.auto import tqdm\n\tfrom fire import Fire\n\tdef open_image(image):\n\t    if isinstance(image, bytes):\n", "        image = Image.open(BytesIO(image))\n\t    image = image.convert(\"RGB\")\n\t    return image\n\t@torch.no_grad()\n\tdef infer_example(images, prompt, clip_model, clip_processor, device):\n\t    images = [open_image(image) for image in images]\n\t    image_inputs = clip_processor(\n\t        images=images,\n\t        padding=True,\n\t        truncation=True,\n", "        max_length=77,\n\t        return_tensors=\"pt\",\n\t    ).to(device)\n\t    text_inputs = clip_processor(\n\t        text=prompt,\n\t        padding=True,\n\t        truncation=True,\n\t        max_length=77,\n\t        return_tensors=\"pt\",\n\t    ).to(device)\n", "    with torch.no_grad():\n\t        image_embs = clip_model.get_image_features(**image_inputs)\n\t        image_embs = image_embs / torch.norm(image_embs, dim=-1, keepdim=True)\n\t        text_embs = clip_model.get_text_features(**text_inputs)\n\t        text_embs = text_embs / torch.norm(text_embs, dim=-1, keepdim=True)\n\t        scores = clip_model.logit_scale.exp() * (text_embs @ image_embs.T)[0]\n\t        probs = torch.softmax(scores, dim=-1)\n\t    return probs.cpu().tolist()\n\tdef calc_probs_for_dataset(ds, clip_model, clip_processor, device):\n\t    probs = []\n", "    for example in tqdm(ds):\n\t        prob_0, prob_1 = infer_example(\n\t            [example[\"jpg_0\"], example[\"jpg_1\"]],\n\t            example[\"caption\"],\n\t            clip_model,\n\t            clip_processor,\n\t            device\n\t        )\n\t        probs.append((prob_0, prob_1))\n\t    return probs\n", "def get_label(example):\n\t    if example[\"label_0\"] == 0.5:\n\t        label = \"tie\"\n\t    elif example[\"label_0\"] == 1:\n\t        label = \"0\"\n\t    else:\n\t        label = \"1\"\n\t    return label\n\tdef get_pred(prob_0, prob_1, threshold):\n\t    if abs(prob_1 - prob_0) <= threshold:\n", "        pred = \"tie\"\n\t    elif prob_0 > prob_1:\n\t        pred = \"0\"\n\t    else:\n\t        pred = \"1\"\n\t    return pred\n\tdef calc_score(label, pred):\n\t    if label == pred:\n\t        score = 1\n\t    elif \"tie\" in [label, pred]:\n", "        score = 0.5\n\t    else:\n\t        score = 0\n\t    return score\n\tdef calc_acc(probs, ds, threshold):\n\t    res = []\n\t    for example, (prob_0, prob_1) in zip(ds, probs):\n\t        label = get_label(example)\n\t        pred = get_pred(prob_0, prob_1, threshold)\n\t        score = calc_score(label, pred)\n", "        res.append(score)\n\t    return sum(res) / len(res)\n\tdef calc_scores(ds, thresholds, clip_model, clip_processor, device):\n\t    if isinstance(thresholds, (float, int)):\n\t        thresholds = [thresholds]\n\t    probs = calc_probs_for_dataset(ds, clip_model, clip_processor, device)\n\t    res = []\n\t    for threshold in thresholds:\n\t        acc = calc_acc(probs, ds, threshold)\n\t        res.append(acc)\n", "    return res\n\tdef calc_random_scores(ds, thresholds):\n\t    if isinstance(thresholds, (float, int)):\n\t        thresholds = [thresholds]\n\t    total = len(ds)\n\t    num_ties = len(ds.filter(lambda x: x[\"label_0\"] == 0.5))\n\t    num_no_ties = total - num_ties\n\t    random_scores = [((threshold * 1 + ((1 - threshold) / 2)) * num_ties / total) + ((num_no_ties / total) * 0.5) for\n\t                     threshold\n\t                     in thresholds]\n", "    return random_scores\n\tdef main(processor_pretrained_name_or_path: str = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\",\n\t         model_pretrained_name_or_path: str = \"yuvalkirstain/PickScore_v1\",\n\t         dataset_name_or_path: str = \"yuvalkirstain/pickapic_v1\",\n\t         should_load_from_disk: bool = False):\n\t    device = \"cuda:0\"\n\t    print(f\"Loading dataset {dataset_name_or_path}\")\n\t    if should_load_from_disk:\n\t        dataset = load_from_disk(dataset_name_or_path)\n\t    else:\n", "        dataset = load_dataset(dataset_name_or_path)\n\t    print(f\"Loading model {model_pretrained_name_or_path}\")\n\t    clip_processor = AutoProcessor.from_pretrained(processor_pretrained_name_or_path)\n\t    clip_model = AutoModel.from_pretrained(model_pretrained_name_or_path).eval().to(device)\n\t    thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n\t    validation_split = \"validation_unique\"\n\t    test_split = \"test_unique\"\n\t    print(\"Calculating validation accuracy\")\n\t    ours_validation_results = calc_scores(dataset[validation_split], thresholds, clip_model, clip_processor, device)\n\t    best_threshold = np.argmax(ours_validation_results)\n", "    print(ours_validation_results)\n\t    print(f\"Best Threshold: {thresholds[best_threshold]} | Acc: {ours_validation_results[best_threshold]}\")\n\t    print(\"Calculating test accuracy\")\n\t    test_result = calc_scores(dataset[test_split], thresholds[best_threshold], clip_model, clip_processor, device)\n\t    print(f\"Test Acc: {test_result[0]}\")\n\tif __name__ == '__main__':\n\t    Fire(main)\n"]}
{"filename": "trainer/lr_schedulers/dummy_lr_scheduler.py", "chunked_list": ["from dataclasses import dataclass\n\timport torch\n\tfrom accelerate.utils import DummyScheduler\n\tfrom hydra.utils import instantiate\n\tfrom omegaconf import II\n\ttry:\n\t    import torch.distributed.nn\n\t    has_distributed = True\n\texcept ImportError:\n\t    has_distributed = False\n", "@dataclass\n\tclass DummyLRSchedulerConfig:\n\t    _target_: str = \"trainer.lr_schedulers.dummy_lr_scheduler.instantiate_dummy_lr_scheduler\"\n\t    lr: float = II(\"optimizer.lr\")\n\t    lr_warmup_steps: int = 500\n\t    total_num_steps: int = II(\"accelerator.max_steps\")\n\tdef instantiate_dummy_lr_scheduler(cfg: DummyLRSchedulerConfig, optimizer):\n\t    try:\n\t        num_processes = torch.distributed.get_world_size()\n\t    except RuntimeError:\n", "        num_processes = 1\n\t    return DummyScheduler(\n\t        optimizer,\n\t        total_num_steps=cfg.total_num_steps * num_processes,\n\t        warmup_num_steps=cfg.lr_warmup_steps,\n\t        warmup_max_lr=cfg.lr,\n\t    )\n"]}
{"filename": "trainer/lr_schedulers/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.lr_schedulers.constant_with_warmup import ConstantWithWarmupLRSchedulerConfig\n\tfrom trainer.lr_schedulers.dummy_lr_scheduler import DummyLRSchedulerConfig\n\tcs = ConfigStore.instance()\n\tcs.store(group=\"lr_scheduler\", name=\"dummy\", node=DummyLRSchedulerConfig)\n\tcs.store(group=\"lr_scheduler\", name=\"constant_with_warmup\", node=ConstantWithWarmupLRSchedulerConfig)\n"]}
{"filename": "trainer/lr_schedulers/constant_with_warmup.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom omegaconf import II\n\tfrom transformers import get_constant_schedule_with_warmup\n\t@dataclass\n\tclass ConstantWithWarmupLRSchedulerConfig:\n\t    _target_: str = \"trainer.lr_schedulers.constant_with_warmup.instantiate_dummy_lr_scheduler\"\n\t    lr: float = II(\"optimizer.lr\")\n\t    lr_warmup_steps: int = 500\n\t    total_num_steps: int = II(\"accelerator.max_steps\")\n\tdef instantiate_dummy_lr_scheduler(cfg: ConstantWithWarmupLRSchedulerConfig, optimizer):\n", "    return get_constant_schedule_with_warmup(\n\t        optimizer,\n\t        num_warmup_steps=cfg.lr_warmup_steps,\n\t    )\n"]}
{"filename": "trainer/models/clip_model.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom transformers import CLIPModel as HFCLIPModel\n\tfrom torch import nn\n\tfrom trainer.models.base_model import BaseModelConfig\n\t@dataclass\n\tclass ClipModelConfig(BaseModelConfig):\n\t    _target_: str = \"trainer.models.clip_model.CLIPModel\"\n\t    pretrained_model_name_or_path: str = \"openai/clip-vit-base-patch32\"\n\tclass CLIPModel(nn.Module):\n\t    def __init__(self, cfg: ClipModelConfig):\n", "        super().__init__()\n\t        self.model = HFCLIPModel.from_pretrained(cfg.pretrained_model_name_or_path)\n\t    def get_text_features(self, *args, **kwargs):\n\t        return self.model.get_text_features(*args, **kwargs)\n\t    def get_image_features(self, *args, **kwargs):\n\t        return self.model.get_image_features(*args, **kwargs)\n\t    def forward(self, text_inputs=None, image_inputs=None):\n\t        outputs = ()\n\t        if text_inputs is not None:\n\t            outputs += self.model.get_text_features(text_inputs),\n", "        if image_inputs is not None:\n\t            outputs += self.model.get_image_features(image_inputs),\n\t        return outputs\n\t    @property\n\t    def logit_scale(self):\n\t        return self.model.logit_scale\n\t    def save(self, path):\n\t        self.model.save_pretrained(path)\n"]}
{"filename": "trainer/models/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.models.clip_model import ClipModelConfig\n\tcs = ConfigStore.instance()\n\tcs.store(group=\"model\", name=\"clip\", node=ClipModelConfig)\n"]}
{"filename": "trainer/models/base_model.py", "chunked_list": ["from dataclasses import dataclass\n\t@dataclass\n\tclass BaseModelConfig:\n\t    pass\n"]}
{"filename": "trainer/optimizers/dummy_optimizer.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom accelerate.utils import DummyOptim\n\t@dataclass\n\tclass DummyOptimizerConfig:\n\t    _target_: str = \"trainer.optimizers.dummy_optimizer.BaseDummyOptim\"\n\t    lr: float = 3e-6\n\t    weight_decay: float = 0.3\n\tclass BaseDummyOptim(DummyOptim):\n\t    def __init__(self, model, lr=0.001, weight_decay=0, **kwargs):\n\t        self.params = [p for p in model.parameters() if p.requires_grad]\n", "        self.lr = lr\n\t        self.weight_decay = weight_decay\n\t        self.kwargs = kwargs\n"]}
{"filename": "trainer/optimizers/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.optimizers.adamw import AdamWOptimizerConfig\n\tfrom trainer.optimizers.dummy_optimizer import DummyOptimizerConfig\n\tcs = ConfigStore.instance()\n\tcs.store(group=\"optimizer\", name=\"dummy\", node=DummyOptimizerConfig)\n\tcs.store(group=\"optimizer\", name=\"adamw\", node=AdamWOptimizerConfig)\n"]}
{"filename": "trainer/optimizers/adamw.py", "chunked_list": ["from dataclasses import dataclass\n\t@dataclass\n\tclass AdamWOptimizerConfig:\n\t    _target_: str = \"torch.optim.adamw.AdamW\"\n\t    lr: float = 1e-6\n"]}
{"filename": "trainer/tasks/base_task.py", "chunked_list": ["from dataclasses import dataclass\n\timport torch\n\tfrom PIL import Image\n\tfrom accelerate.logging import get_logger\n\tfrom accelerate.utils import LoggerType\n\tlogger = get_logger(__name__)\n\tdef flatten(list_of_lists):\n\t    return [item for sublist in list_of_lists for item in sublist]\n\t@dataclass\n\tclass BaseTaskConfig:\n", "    limit_examples_to_wandb: int = 50\n\t    pass\n\tclass BaseTask:\n\t    def __init__(self, cfg: BaseTaskConfig, accelerator):\n\t        self.accelerator = accelerator\n\t        self.cfg = cfg\n\t    def train_step(self, model, criterion, batch):\n\t        pass\n\t    def valid_step(self, model, criterion, batch):\n\t        pass\n", "    def evaluate(self, model, criterion, dataloader):\n\t        pass\n\t    def log_to_wandb(self, eval_dict, table_name=\"test_predictions\"):\n\t        if not self.accelerator.is_main_process or not LoggerType.WANDB == self.accelerator.cfg.log_with:\n\t            logger.info(\"Not logging to wandb\")\n\t            return\n\t        import wandb\n\t        logger.info(\"Uploading to wandb\")\n\t        for key, value in eval_dict.items():\n\t            eval_dict[key] = [wandb.Image(maybe_img) if isinstance(maybe_img, Image.Image) else maybe_img for maybe_img\n", "                              in value]\n\t            if self.cfg.limit_examples_to_wandb > 0:\n\t                eval_dict[key] = eval_dict[key][:self.cfg.limit_examples_to_wandb]\n\t        columns, predictions = list(zip(*sorted(eval_dict.items())))\n\t        predictions += ([self.accelerator.global_step] * len(predictions[0]),)\n\t        columns += (\"global_step\",)\n\t        data = list(zip(*predictions))\n\t        table = wandb.Table(columns=list(columns), data=data)\n\t        wandb.log({table_name: table}, commit=False, step=self.accelerator.global_step)\n\t    @staticmethod\n", "    def gather_iterable(it, num_processes):\n\t        output_objects = [None for _ in range(num_processes)]\n\t        torch.distributed.all_gather_object(output_objects, it)\n\t        return flatten(output_objects)\n\t    @torch.no_grad()\n\t    def valid_step(self, model, criterion, batch):\n\t        loss = criterion(model, batch)\n\t        return loss\n\t    def gather_dict(self, eval_dict):\n\t        logger.info(\"Gathering dict from all processes...\")\n", "        for k, v in eval_dict.items():\n\t            eval_dict[k] = self.gather_iterable(v, self.accelerator.num_processes)\n\t        return eval_dict\n"]}
{"filename": "trainer/tasks/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.tasks.clip_task import CLIPTaskConfig\n\tcs = ConfigStore.instance()\n\tcs.store(group=\"task\", name=\"clip\", node=CLIPTaskConfig)\n"]}
{"filename": "trainer/tasks/clip_task.py", "chunked_list": ["import collections\n\tfrom dataclasses import dataclass\n\timport torch\n\tfrom PIL import Image\n\tfrom accelerate.logging import get_logger\n\tfrom accelerate.utils import LoggerType\n\tfrom omegaconf import II\n\tfrom transformers import AutoTokenizer\n\tfrom trainer.accelerators.base_accelerator import BaseAccelerator\n\tfrom trainer.tasks.base_task import BaseTaskConfig, BaseTask\n", "logger = get_logger(__name__)\n\t@dataclass\n\tclass CLIPTaskConfig(BaseTaskConfig):\n\t    _target_: str = \"trainer.tasks.clip_task.CLIPTask\"\n\t    pretrained_model_name_or_path: str = II(\"model.pretrained_model_name_or_path\")\n\t    label_0_column_name: str = II(\"dataset.label_0_column_name\")\n\t    label_1_column_name: str = II(\"dataset.label_1_column_name\")\n\t    input_ids_column_name: str = II(\"dataset.input_ids_column_name\")\n\t    pixels_0_column_name: str = II(\"dataset.pixels_0_column_name\")\n\t    pixels_1_column_name: str = II(\"dataset.pixels_1_column_name\")\n", "def numpy_to_pil(images):\n\t    images = (images * 255).round().astype(\"uint8\")\n\t    pil_images = [Image.fromarray(image) for image in images]\n\t    return pil_images\n\tclass CLIPTask(BaseTask):\n\t    def __init__(self, cfg: CLIPTaskConfig, accelerator: BaseAccelerator):\n\t        super().__init__(cfg, accelerator)\n\t        self.tokenizer = AutoTokenizer.from_pretrained(cfg.pretrained_model_name_or_path)\n\t        self.cfg = cfg\n\t    def train_step(self, model, criterion, batch):\n", "        loss = criterion(model, batch)\n\t        return loss\n\t    @staticmethod\n\t    def features2probs(model, text_features, image_0_features, image_1_features):\n\t        image_0_scores = model.logit_scale.exp() * torch.diag(\n\t            torch.einsum('bd,cd->bc', text_features, image_0_features))\n\t        image_1_scores = model.logit_scale.exp() * torch.diag(\n\t            torch.einsum('bd,cd->bc', text_features, image_1_features))\n\t        scores = torch.stack([image_0_scores, image_1_scores], dim=-1)\n\t        probs = torch.softmax(scores, dim=-1)\n", "        image_0_probs, image_1_probs = probs[:, 0], probs[:, 1]\n\t        return image_0_probs, image_1_probs\n\t    @torch.no_grad()\n\t    def valid_step(self, model, criterion, batch):\n\t        image_0_features, image_1_features, text_features = criterion.get_features(\n\t            model,\n\t            batch[self.cfg.input_ids_column_name],\n\t            batch[self.cfg.pixels_0_column_name],\n\t            batch[self.cfg.pixels_1_column_name]\n\t        )\n", "        return self.features2probs(model, text_features, image_0_features, image_1_features)\n\t    @staticmethod\n\t    def pixel_values_to_pil_images(pixel_values):\n\t        images = (pixel_values / 2 + 0.5).clamp(0, 1)\n\t        images = images.cpu().permute(0, 2, 3, 1).float().numpy()\n\t        images = numpy_to_pil(images)\n\t        return images\n\t    def run_inference(self, model, criterion, dataloader):\n\t        eval_dict = collections.defaultdict(list)\n\t        logger.info(\"Running clip score...\")\n", "        for batch in dataloader:\n\t            image_0_probs, image_1_probs = self.valid_step(model, criterion, batch)\n\t            agree_on_0 = (image_0_probs > image_1_probs) * batch[self.cfg.label_0_column_name]\n\t            agree_on_1 = (image_0_probs < image_1_probs) * batch[self.cfg.label_1_column_name]\n\t            is_correct = agree_on_0 + agree_on_1\n\t            eval_dict[\"is_correct\"] += is_correct.tolist()\n\t            eval_dict[\"captions\"] += self.tokenizer.batch_decode(\n\t                batch[self.cfg.input_ids_column_name],\n\t                skip_special_tokens=True\n\t            )\n", "            eval_dict[\"image_0\"] += self.pixel_values_to_pil_images(batch[self.cfg.pixels_0_column_name])\n\t            eval_dict[\"image_1\"] += self.pixel_values_to_pil_images(batch[self.cfg.pixels_1_column_name])\n\t            eval_dict[\"prob_0\"] += image_0_probs.tolist()\n\t            eval_dict[\"prob_1\"] += image_1_probs.tolist()\n\t            eval_dict[\"label_0\"] += batch[self.cfg.label_0_column_name].tolist()\n\t            eval_dict[\"label_1\"] += batch[self.cfg.label_1_column_name].tolist()\n\t        return eval_dict\n\t    @torch.no_grad()\n\t    def evaluate(self, model, criterion, dataloader):\n\t        eval_dict = self.run_inference(model, criterion, dataloader)\n", "        eval_dict = self.gather_dict(eval_dict)\n\t        metrics = {\n\t            \"accuracy\": sum(eval_dict[\"is_correct\"]) / len(eval_dict[\"is_correct\"]),\n\t            \"num_samples\": len(eval_dict[\"is_correct\"])\n\t        }\n\t        if LoggerType.WANDB == self.accelerator.cfg.log_with:\n\t            self.log_to_wandb(eval_dict)\n\t        return metrics\n"]}
{"filename": "trainer/criterions/clip_criterion.py", "chunked_list": ["from dataclasses import dataclass\n\timport torch\n\tfrom omegaconf import II\n\tfrom torch.nn.modules.loss import _Loss\n\t@dataclass\n\tclass CLIPCriterionConfig:\n\t    _target_: str = \"trainer.criterions.clip_criterion.CLIPCriterion\"\n\t    is_distributed: bool = True\n\t    label_0_column_name: str = II(\"dataset.label_0_column_name\")\n\t    label_1_column_name: str = II(\"dataset.label_1_column_name\")\n", "    input_ids_column_name: str = II(\"dataset.input_ids_column_name\")\n\t    pixels_0_column_name: str = II(\"dataset.pixels_0_column_name\")\n\t    pixels_1_column_name: str = II(\"dataset.pixels_1_column_name\")\n\t    num_examples_per_prompt_column_name: str = II(\"dataset.num_examples_per_prompt_column_name\")\n\t    in_batch_negatives: bool = False\n\t    pass\n\tclass CLIPCriterion(_Loss):\n\t    def __init__(self, cfg: CLIPCriterionConfig):\n\t        super().__init__()\n\t        self.cfg = cfg\n", "    @staticmethod\n\t    def get_features(model, input_ids, pixels_0_values, pixels_1_values):\n\t        all_pixel_values = torch.cat([pixels_0_values, pixels_1_values], dim=0)\n\t        text_features, all_image_features = model(text_inputs=input_ids, image_inputs=all_pixel_values)\n\t        all_image_features = all_image_features / all_image_features.norm(dim=-1, keepdim=True)\n\t        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n\t        image_0_features, image_1_features = all_image_features.chunk(2, dim=0)\n\t        return image_0_features, image_1_features, text_features\n\t    @staticmethod\n\t    def gather_features(features):\n", "        all_features = torch.cat(torch.distributed.nn.all_gather(features), dim=0)\n\t        return all_features\n\t    def calc_loss(\n\t            self,\n\t            text_features,\n\t            image_0_features,\n\t            image_1_features,\n\t            logit_scale,\n\t            label_0,\n\t            label_1,\n", "            num_examples_per_prompt,\n\t            *args,\n\t            **kwargs\n\t    ):\n\t        device = image_0_features.device\n\t        # gather features\n\t        if self.cfg.is_distributed:\n\t            image_0_features = self.gather_features(image_0_features)\n\t            image_1_features = self.gather_features(image_1_features)\n\t            text_features = self.gather_features(text_features)\n", "            label_0 = self.gather_features(label_0)\n\t            label_1 = self.gather_features(label_1)\n\t            num_examples_per_prompt = self.gather_features(num_examples_per_prompt)\n\t        # calc logits # TODO use local loss as open-clip does\n\t        all_image_features = torch.cat([image_0_features, image_1_features], dim=0)  # (2 * batch_size, dim)\n\t        logits_per_image = logit_scale * all_image_features @ text_features.T\n\t        image_0_logits, image_1_logits = logits_per_image.chunk(2, dim=0)\n\t        text_logits = logit_scale * text_features @ all_image_features.T\n\t        if self.cfg.in_batch_negatives:\n\t            # get labels\n", "            num_images = all_image_features.shape[0]\n\t            image_labels = torch.arange(num_images, device=device, dtype=torch.long)\n\t            image_0_labels, image_1_labels = image_labels.chunk(2, dim=0)\n\t            num_texts = text_features.shape[0]\n\t            text_labels = torch.arange(num_texts, device=device, dtype=torch.long)\n\t            # image loss - we want to increase the logits of the preferred image to the text\n\t            image_0_loss = torch.nn.functional.cross_entropy(image_0_logits, text_labels, reduction=\"none\")\n\t            image_1_loss = torch.nn.functional.cross_entropy(image_1_logits, text_labels, reduction=\"none\")\n\t            # if we have a tie, we will increase both images equally, and average so the image loss of each example is\n\t            # proportional\n", "            image_loss = label_0 * image_0_loss + label_1 * image_1_loss\n\t            # text loss - we want to increase the logits of the text to the preferred image\n\t            text_0_loss = torch.nn.functional.cross_entropy(text_logits, image_0_labels, reduction=\"none\")\n\t            text_1_loss = torch.nn.functional.cross_entropy(text_logits, image_1_labels, reduction=\"none\")\n\t        else:\n\t            text_0_logits, text_1_logits = text_logits.chunk(2, dim=-1)\n\t            index = torch.arange(text_0_logits.shape[0], device=device, dtype=torch.long)\n\t            text_0_logits = text_0_logits[index, index]\n\t            text_1_logits = text_1_logits[index, index]\n\t            text_logits = torch.stack([text_0_logits, text_1_logits], dim=-1)\n", "            text_0_labels = torch.zeros(text_logits.shape[0], device=device, dtype=torch.long)\n\t            text_1_labels = text_0_labels + 1\n\t            text_0_loss = torch.nn.functional.cross_entropy(text_logits, text_0_labels, reduction=\"none\")\n\t            text_1_loss = torch.nn.functional.cross_entropy(text_logits, text_1_labels, reduction=\"none\")\n\t        # if we have a tie we want the logits of for each image to be equal\n\t        text_loss = label_0 * text_0_loss + label_1 * text_1_loss\n\t        # we want the ideal loss to be 0, currently, if there is a tie, it is 0.5 * log(0.5) + 0.5 * log(0.5)\n\t        # so we add log(0.5) to the loss\n\t        is_tie = (label_0 == label_1).float()\n\t        is_tie *= torch.log(torch.tensor(0.5, device=device))\n", "        text_loss += is_tie\n\t        # we average the image and text loss\n\t        if self.cfg.in_batch_negatives:\n\t            loss = (image_loss + text_loss) / 2\n\t        else:\n\t            loss = text_loss\n\t        # some prompts have lots of interactions, we want weight them accordingly\n\t        absolute_example_weight = 1 / num_examples_per_prompt\n\t        denominator = absolute_example_weight.sum()\n\t        weight_per_example = absolute_example_weight / denominator\n", "        loss *= weight_per_example\n\t        loss = loss.sum()\n\t        return loss\n\t    def forward(self, model, batch):\n\t        image_0_features, image_1_features, text_features = self.get_features(\n\t            model,\n\t            batch[self.cfg.input_ids_column_name],\n\t            batch[self.cfg.pixels_0_column_name],\n\t            batch[self.cfg.pixels_1_column_name]\n\t        )\n", "        loss = self.calc_loss(\n\t            text_features,\n\t            image_0_features,\n\t            image_1_features,\n\t            model.logit_scale.exp(),\n\t            batch[self.cfg.label_0_column_name],\n\t            batch[self.cfg.label_1_column_name],\n\t            batch[self.cfg.num_examples_per_prompt_column_name],\n\t        )\n\t        return loss\n"]}
{"filename": "trainer/criterions/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.criterions.clip_criterion import CLIPCriterionConfig\n\tcs = ConfigStore.instance()\n\tcs.store(group=\"criterion\", name=\"clip\", node=CLIPCriterionConfig)\n"]}
{"filename": "trainer/accelerators/debug_accelerator.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom accelerate import Accelerator\n\tfrom trainer.accelerators.base_accelerator import BaseAcceleratorConfig, BaseAccelerator\n\t@dataclass\n\tclass DebugAcceleratorConfig(BaseAcceleratorConfig):\n\t    _target_: str = \"trainer.accelerators.debug_accelerator.DebugAccelerator\"\n\tclass DebugAccelerator(BaseAccelerator):\n\t    def __init__(self, cfg: DebugAcceleratorConfig):\n\t        super().__init__(cfg)\n\t        self.accelerator = Accelerator(\n", "            gradient_accumulation_steps=cfg.gradient_accumulation_steps,\n\t            mixed_precision=cfg.mixed_precision,\n\t            log_with=cfg.log_with,\n\t            project_dir=cfg.output_dir,\n\t            dynamo_backend=cfg.dynamo_backend,\n\t        )\n\t        self.post_init()\n"]}
{"filename": "trainer/accelerators/deepspeed_accelerator.py", "chunked_list": ["import os\n\tfrom dataclasses import dataclass, field\n\tfrom typing import Any\n\timport torch\n\tfrom accelerate.utils import PrecisionType\n\tfrom accelerate import Accelerator, DeepSpeedPlugin\n\tfrom omegaconf import OmegaConf, MISSING, II\n\tfrom trainer.accelerators.base_accelerator import BaseAcceleratorConfig, BaseAccelerator\n\t@dataclass\n\tclass MixedPrecisionConfig:\n", "    enabled: bool = MISSING\n\t@dataclass\n\tclass DeepSpeedConfig:\n\t    fp16: MixedPrecisionConfig = MixedPrecisionConfig(enabled=False)\n\t    bf16: MixedPrecisionConfig = MixedPrecisionConfig(enabled=False)\n\t    optimizer: dict = field(default_factory=lambda: {\n\t        \"type\": \"AdamW\",\n\t        \"params\": {\n\t            \"lr\": \"auto\",\n\t            \"weight_decay\": \"auto\",\n", "            \"torch_adam\": True,\n\t            \"adam_w_mode\": True\n\t        }\n\t    })\n\t    scheduler: dict = field(default_factory=lambda: {\n\t        \"type\": \"WarmupDecayLR\",\n\t        \"params\": {\n\t            \"warmup_min_lr\": \"auto\",\n\t            \"warmup_max_lr\": \"auto\",\n\t            \"warmup_num_steps\": \"auto\",\n", "            \"total_num_steps\": \"auto\"\n\t        }\n\t    })\n\t    zero_optimization: dict = field(default_factory=lambda: {\n\t        \"stage\": 2,\n\t        \"allgather_partitions\": True,\n\t        \"allgather_bucket_size\": 2e8,\n\t        \"overlap_comm\": True,\n\t        \"reduce_scatter\": True,\n\t        \"reduce_bucket_size\": 500000000,\n", "        \"contiguous_gradients\": True\n\t    })\n\t    gradient_accumulation_steps: int = 16\n\t    gradient_clipping: float = 1.0\n\t    steps_per_print: int = 1\n\t    train_batch_size: str = \"auto\"\n\t    train_micro_batch_size_per_gpu: str = \"auto\"\n\t    #     train_micro_batch_size_per_gpu: int = II(\"dataset.batch_size\")\n\t    wall_clock_breakdown: bool = False\n\t@dataclass\n", "class DeepSpeedAcceleratorConfig(BaseAcceleratorConfig):\n\t    _target_: str = \"trainer.accelerators.deepspeed_accelerator.DeepSpeedAccelerator\"\n\t    deepspeed: DeepSpeedConfig = DeepSpeedConfig()\n\t    deepspeed_final: Any = None\n\tclass DeepSpeedAccelerator(BaseAccelerator):\n\t    def __init__(self, cfg: DeepSpeedAcceleratorConfig):\n\t        super().__init__(cfg)\n\t        self.set_mixed_precision()\n\t        deepspeed_plugin = DeepSpeedPlugin(\n\t            hf_ds_config=OmegaConf.to_container(self.cfg.deepspeed, resolve=True),\n", "            gradient_accumulation_steps=self.cfg.gradient_accumulation_steps,\n\t        )\n\t        self.cfg.deepspeed_final = OmegaConf.create(deepspeed_plugin.deepspeed_config)\n\t        self.accelerator = Accelerator(\n\t            deepspeed_plugin=deepspeed_plugin,\n\t            gradient_accumulation_steps=self.cfg.gradient_accumulation_steps,\n\t            mixed_precision=self.cfg.mixed_precision,\n\t            log_with=self.cfg.log_with,\n\t            project_dir=self.cfg.output_dir,\n\t            dynamo_backend=self.cfg.dynamo_backend,\n", "        )\n\t        self.post_init()\n\t    def set_mixed_precision(self):\n\t        if self.cfg.mixed_precision == PrecisionType.BF16:\n\t            self.cfg.deepspeed.bf16.enabled = True\n\t            self.cfg.deepspeed.fp16.enabled = False\n\t        elif self.cfg.mixed_precision == PrecisionType.FP16:\n\t            self.cfg.deepspeed.fp16.enabled = True\n\t            self.cfg.deepspeed.bf16.enabled = False\n\t        else:\n", "            self.cfg.deepspeed.fp16.enabled = False\n\t            self.cfg.deepspeed.bf16.enabled = False\n\t    def prepare(self, *args, device_placement=None):\n\t        prepared = self.accelerator.prepare(*args, device_placement=device_placement)\n\t        for obj in prepared:\n\t            if isinstance(obj, torch.nn.Module):\n\t                if self.cfg.mixed_precision == PrecisionType.BF16:\n\t                    obj.forward = torch.autocast(device_type=self.device.type, dtype=torch.bfloat16)(obj.forward)\n\t                elif self.cfg.mixed_precision == PrecisionType.FP16:\n\t                    obj.forward = torch.autocast(device_type=self.device.type, dtype=torch.float16)(obj.forward)\n", "        return prepared\n"]}
{"filename": "trainer/accelerators/base_accelerator.py", "chunked_list": ["import abc\n\timport hashlib\n\timport json\n\timport math\n\timport os\n\timport shutil\n\tfrom dataclasses import field, dataclass\n\tfrom glob import glob\n\tfrom typing import List, Optional\n\timport datasets\n", "import torch\n\timport transformers\n\tfrom accelerate.logging import get_logger\n\tfrom accelerate.utils import set_seed as accelerate_set_seed, PrecisionType\n\tfrom accelerate.utils.dataclasses import BaseEnum, LoggerType, DynamoBackend\n\tfrom omegaconf import DictConfig, OmegaConf, II\n\tfrom tqdm import tqdm\n\tfrom trainer.accelerators.utils import get_nvidia_smi_gpu_memory_stats_str, print_config, _flatten_dict\n\tlogger = get_logger(__name__)\n\tTRAINING_STAGE_PATH = \"training_stage.json\"\n", "def debug(port):\n\t    logger.info(\"Connecting to debugger...\")\n\t    import pydevd_pycharm\n\t    pydevd_pycharm.settrace('localhost', port=port, stdoutToServer=True, stderrToServer=True)\n\t@dataclass\n\tclass DebugConfig:\n\t    activate: bool = False\n\t    port: int = 5900\n\tclass TrainingMode(BaseEnum):\n\t    SKIPPING = \"skipping\"\n", "    TRAINING = \"training\"\n\tclass MetricMode(BaseEnum):\n\t    MAX = \"max\"\n\t    MIN = \"min\"\n\t@dataclass\n\tclass BaseAcceleratorConfig:\n\t    _target_: str = \"trainer.accelerators.base_accelerator.Accelerator\"\n\t    output_dir: str = II(\"output_dir\")\n\t    mixed_precision: PrecisionType = PrecisionType.NO\n\t    gradient_accumulation_steps: int = 1\n", "    log_with: Optional[LoggerType] = LoggerType.WANDB\n\t    debug: DebugConfig = DebugConfig()\n\t    seed: int = 42\n\t    resume_from_checkpoint: bool = True\n\t    max_steps: int = 4000\n\t    num_epochs: int = 10\n\t    validate_steps: int = 100\n\t    eval_on_start: bool = True\n\t    project_name: str = \"reward\"\n\t    max_grad_norm: float = 1.0\n", "    save_steps: int = 100\n\t    metric_name: str = \"accuracy\"\n\t    metric_mode: MetricMode = MetricMode.MAX\n\t    limit_num_checkpoints: int = 1\n\t    save_only_if_best: bool = True\n\t    dynamo_backend: DynamoBackend = DynamoBackend.NO\n\t    keep_best_ckpts: bool = True\n\tclass BaseAccelerator(abc.ABC):\n\t    def __init__(self, cfg: BaseAcceleratorConfig):\n\t        self.cfg = cfg\n", "        self.accelerator = None\n\t        self.epoch = 0\n\t        self.step = 0\n\t        self.global_step = 0\n\t        self.step_loss = 0.0\n\t        self.lr = None\n\t        self.metrics = {}\n\t        self.progress_bar = None\n\t        self.mode = TrainingMode.TRAINING\n\t        self.num_update_steps_per_epoch = None\n", "        self.num_steps_per_epoch = None\n\t    def post_init(self):\n\t        self.set_seed()\n\t        self.debug()\n\t        logger.info(f\"Initialized accelerator: rank={self.accelerator.process_index}\", main_process_only=False)\n\t        self.set_logging_level()\n\t    def set_logging_level(self):\n\t        if self.accelerator.is_local_main_process:\n\t            datasets.utils.logging.set_verbosity_warning()\n\t            transformers.utils.logging.set_verbosity_warning()\n", "        else:\n\t            datasets.utils.logging.set_verbosity_error()\n\t            transformers.utils.logging.set_verbosity_error()\n\t    def debug(self):\n\t        if self.accelerator.is_main_process and self.cfg.debug.activate:\n\t            debug(self.cfg.debug.port)\n\t    def set_seed(self):\n\t        logger.info(f\"Setting seed {self.cfg.seed}\")\n\t        accelerate_set_seed(self.cfg.seed, device_specific=True)\n\t    def prepare(self, *args, device_placement=None):\n", "        return self.accelerator.prepare(*args, device_placement=device_placement)\n\t    def get_latest_checkpoint(self):\n\t        all_ckpts = list(glob(os.path.join(self.cfg.output_dir, \"checkpoint-*\")))\n\t        if len(all_ckpts) == 0:\n\t            return\n\t        all_ckpts.sort(key=os.path.getctime)\n\t        if \"final\" in all_ckpts[-1]:\n\t            all_ckpts.pop()\n\t        return all_ckpts[-1] if len(all_ckpts) > 0 else None\n\t    def load_state_if_needed(self):\n", "        if not self.cfg.resume_from_checkpoint:\n\t            return\n\t        ckpt_path = self.get_latest_checkpoint()\n\t        if ckpt_path is None:\n\t            logger.info(\"No checkpoint found, training from scratch\")\n\t            return\n\t        stage = json.load(open(os.path.join(ckpt_path, TRAINING_STAGE_PATH)))\n\t        self.epoch, self.step, self.global_step, self.metrics = stage[\"epoch\"], stage[\"step\"], stage[\"global_step\"], \\\n\t            stage[\"metrics\"]\n\t        logger.info(\n", "            f\"Resuming from checkpoint: {ckpt_path} | epoch={self.epoch} step={self.step} gstep={self.global_step}\")\n\t        self.accelerator.load_state(ckpt_path)\n\t        logger.info(\"Checkpoint loaded\")\n\t    @property\n\t    def is_main_process(self):\n\t        return self.accelerator.is_main_process\n\t    @property\n\t    def num_processes(self):\n\t        return self.accelerator.num_processes\n\t    def pre_training_log(self, cfg: DictConfig):\n", "        total_batch_size = cfg.dataset.batch_size * self.num_processes * self.cfg.gradient_accumulation_steps\n\t        logger.info(\"***** Running training *****\")\n\t        logger.info(f\"  Instantaneous batch size per device = {cfg.dataset.batch_size}\")\n\t        logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n\t        logger.info(f\"  Gradient Accumulation steps = {self.cfg.gradient_accumulation_steps}\")\n\t        logger.info(f\"  Total warmup steps = {cfg.lr_scheduler.lr_warmup_steps}\")\n\t        logger.info(f\"  Total training steps = {self.cfg.max_steps * self.cfg.gradient_accumulation_steps}\")\n\t        logger.info(f\"  Total epochs = {self.cfg.num_epochs}\")\n\t        logger.info(f\"  Steps per epoch = {self.num_steps_per_epoch}\")\n\t        logger.info(f\"  Update steps per epoch = {self.num_update_steps_per_epoch}\")\n", "        logger.info(f\"  Total optimization steps = {self.cfg.max_steps}\")\n\t        logger.info(f\"  Mixed precision = {self.cfg.mixed_precision}\")\n\t        logger.info(f\"  World size = {self.accelerator.num_processes}\")\n\t    def init_training(self, cfg: DictConfig):\n\t        if self.is_main_process:\n\t            yaml = OmegaConf.to_yaml(cfg, resolve=True, sort_keys=True)\n\t            log_cfg = _flatten_dict(OmegaConf.create(yaml))\n\t            logger.info(\"Initializing trackers\")\n\t            self.accelerator.init_trackers(self.cfg.project_name, log_cfg)\n\t            logger.info(\"Training config:\")\n", "            print_config(cfg)\n\t        logger.info(get_nvidia_smi_gpu_memory_stats_str())\n\t        self.pre_training_log(cfg)\n\t        self.progress_bar = tqdm(range(self.cfg.max_steps * self.cfg.gradient_accumulation_steps), disable=not self.accelerator.is_main_process)\n\t        self.progress_bar.set_description(\"Steps\")\n\t    def should_skip(self, epoch, step):\n\t        should = epoch < self.epoch or (epoch == self.epoch and step < self.step)\n\t        if should:\n\t            self.mode = TrainingMode.SKIPPING\n\t            self.progress_bar.set_postfix(**{\"status\": TrainingMode.SKIPPING})\n", "        else:\n\t            self.mode = TrainingMode.TRAINING\n\t        return should\n\t    def update_progbar_step(self):\n\t        self.progress_bar.update(1)\n\t    def log(self, data):\n\t        if self.is_main_process:\n\t            self.accelerator.log(data, step=self.global_step)\n\t    def recalc_train_length_after_prepare(self, num_batches):\n\t        num_update_steps_per_epoch = math.ceil(num_batches / self.cfg.gradient_accumulation_steps)\n", "        if self.cfg.max_steps is None:\n\t            self.cfg.max_steps = self.cfg.num_epochs * num_update_steps_per_epoch\n\t        self.num_update_steps_per_epoch = num_update_steps_per_epoch\n\t        self.num_steps_per_epoch = num_batches\n\t        self.cfg.num_epochs = math.ceil(self.cfg.max_steps / num_update_steps_per_epoch)\n\t    def accumulate(self, model):\n\t        return self.accelerator.accumulate(model)\n\t    def gather(self, data):\n\t        return self.accelerator.gather(data)\n\t    @property\n", "    def sync_gradients(self):\n\t        return self.accelerator.sync_gradients\n\t    def update_step_loss(self, loss):\n\t        self.step_loss = loss\n\t    def update_global_step(self, loss):\n\t        self.global_step += 1\n\t        self.log({\n\t            \"lr\": self.lr,\n\t            \"step\": self.step,\n\t            \"epoch\": self.epoch,\n", "            \"global_step\": self.global_step,\n\t            \"loss\": loss,\n\t        })\n\t    def get_allocated_cuda_memory(self):\n\t        return round(torch.cuda.max_memory_allocated(self.accelerator.device) / 1024 / 1024 / 1024, 2)\n\t    def update_step(self, loss, lr):\n\t        self.step += 1\n\t        self.lr = lr\n\t        logs = {\n\t            \"stl\": loss,\n", "            \"gstl\": loss,\n\t            \"mem\": self.get_allocated_cuda_memory(),\n\t            \"st\": self.step,\n\t            \"ep\": self.epoch,\n\t            \"gst\": self.global_step,\n\t            \"lr\": self.lr,\n\t        }\n\t        self.progress_bar.set_postfix(**logs)\n\t        self.update_progbar_step()\n\t    def wait_for_everyone(self):\n", "        self.accelerator.wait_for_everyone()\n\t    def update_epoch(self):\n\t        if self.mode == TrainingMode.SKIPPING:\n\t            return\n\t        logger.info(f\"Epoch {self.epoch} finished\")\n\t        self.epoch += 1\n\t        self.step = 0\n\t    def update_metrics(self, metrics):\n\t        self.metrics.update(metrics)\n\t        logger.info(f\"Metrics: {self.metrics}\")\n", "        self.log(metrics)\n\t    def end_training(self):\n\t        self.accelerator.wait_for_everyone()\n\t        self.accelerator.end_training()\n\t    def unwrap_and_save(self, model):\n\t        if not self.is_main_process:\n\t            return\n\t        model = self.accelerator.unwrap_model(model)\n\t        save_dir = os.path.join(self.cfg.output_dir, f\"checkpoint-final\")\n\t        logger.info(f\"Saving final checkpoint to {save_dir}\")\n", "        model.save(save_dir)\n\t        self.save_training_stage(save_dir)\n\t        logger.info(f\"Saved checkpoint to {save_dir}\")\n\t    def should_end(self):\n\t        return self.global_step >= self.cfg.max_steps\n\t    def backward(self, loss):\n\t        self.accelerator.backward(loss)\n\t    def clip_grad_norm_(self, params):\n\t        self.accelerator.clip_grad_norm_(params, self.cfg.max_grad_norm)\n\t    def should_eval(self):\n", "        if not self.mode == TrainingMode.TRAINING:\n\t            return False\n\t        if self.step == 0 and self.global_step == 0 and self.cfg.eval_on_start:\n\t            return True\n\t        if self.global_step > 0 and self.sync_gradients and self.global_step % self.cfg.validate_steps == 0:\n\t            return True\n\t        return False\n\t    def should_save(self):\n\t        return self.sync_gradients and self.global_step > 0 and self.cfg.save_steps > 0 and self.global_step % self.cfg.save_steps == 0\n\t    @property\n", "    def training_stage(self):\n\t        return {\n\t            \"epoch\": self.epoch,\n\t            \"step\": self.step,\n\t            \"global_step\": self.global_step,\n\t            \"step_loss\": self.step_loss,\n\t            \"lr\": self.lr,\n\t            \"metrics\": self.metrics,\n\t        }\n\t    def save_training_stage(self, save_dir):\n", "        json.dump(self.training_stage, open(os.path.join(save_dir, TRAINING_STAGE_PATH), \"w\"), indent=4)\n\t    def save_checkpoint(self):\n\t        if self.cfg.save_only_if_best:\n\t            all_ckpts = self.get_all_ckpts()\n\t            for ckpt in all_ckpts:\n\t                training_stage = json.load(open(os.path.join(ckpt, TRAINING_STAGE_PATH)))\n\t                metric_val = training_stage[\"metrics\"][self.cfg.metric_name]\n\t                cur_metric_val = self.training_stage[\"metrics\"][self.cfg.metric_name]\n\t                if (self.cfg.metric_mode == MetricMode.MIN and metric_val < cur_metric_val) or \\\n\t                        (self.cfg.metric_mode == MetricMode.MAX and metric_val > cur_metric_val):\n", "                    logger.info(\n\t                        f\"Metric {self.cfg.metric_name}={cur_metric_val} is not better than {metric_val} of {ckpt}, skipping checkpoint\")\n\t                    return\n\t        self.cleanup_checkpoints()\n\t        self.accelerator.wait_for_everyone()\n\t        save_dir = os.path.join(self.cfg.output_dir, f\"checkpoint-gstep{self.global_step}\")\n\t        logger.info(f\"Saving checkpoint to {save_dir}\")\n\t        self.accelerator.save_state(save_dir)\n\t        self.save_training_stage(save_dir)\n\t        logger.info(f\"Saved checkpoint to {save_dir}\")\n", "    @property\n\t    def gradient_state(self):\n\t        return self.accelerator.gradient_state\n\t    def get_all_ckpts(self):\n\t        return list(glob(os.path.join(self.cfg.output_dir, f\"checkpoint-*\")))\n\t    def load_best_checkpoint(self):\n\t        all_ckpts = self.get_all_ckpts()\n\t        if not self.cfg.keep_best_ckpts:\n\t            all_ckpts.sort(key=os.path.getctime, reverse=True)\n\t            logger.info(f\"Returning the most recent checkpoint: {all_ckpts[0]}\")\n", "            return all_ckpts[0]\n\t        logger.info(f\"Found {len(all_ckpts)} checkpoints in {self.cfg.output_dir}\")\n\t        logger.info(all_ckpts)\n\t        if len(all_ckpts) == 0:\n\t            logger.info(f\"No checkpoint found in {self.cfg.output_dir} to load. Keeping current model.\")\n\t            return\n\t        best_ckpt, best_metric_val = None, math.inf if self.cfg.metric_mode == MetricMode.MIN else -math.inf\n\t        for ckpt in all_ckpts:\n\t            training_stage = json.load(open(os.path.join(ckpt, TRAINING_STAGE_PATH)))\n\t            metric_val = training_stage[\"metrics\"][self.cfg.metric_name]\n", "            if (self.cfg.metric_mode == MetricMode.MIN and metric_val < best_metric_val) or \\\n\t                    (self.cfg.metric_mode == MetricMode.MAX and metric_val > best_metric_val):\n\t                best_ckpt, best_metric_val = ckpt, metric_val\n\t        logger.info(f\"Loading best checkpoint from {best_ckpt} with metric {self.cfg.metric_name}={best_metric_val}\")\n\t        self.accelerator.load_state(best_ckpt)\n\t    @property\n\t    def device(self):\n\t        return self.accelerator.device\n\t    def cleanup_checkpoints(self):\n\t        if self.cfg.limit_num_checkpoints <= 0 or not self.accelerator.is_main_process:\n", "            logger.info(f\"Not cleaning up checkpoints as limit_num_checkpoints={self.cfg.limit_num_checkpoints}\")\n\t            return\n\t        all_ckpts = self.get_all_ckpts()\n\t        if len(all_ckpts) <= self.cfg.limit_num_checkpoints:\n\t            logger.info(f\"Not cleaning up checkpoints as only {len(all_ckpts)} checkpoints found\")\n\t            return\n\t        logger.info(f\"Found {len(all_ckpts)} checkpoints in {self.cfg.output_dir}\")\n\t        ckpts_to_delete = self.get_ckpts_to_delete()\n\t        ckpts_to_delete.sort(key=os.path.getctime)\n\t        ckpts_to_delete = ckpts_to_delete[:-1]\n", "        for ckpt in ckpts_to_delete:\n\t            logger.info(f\"Deleting checkpoint {ckpt}\")\n\t            shutil.rmtree(ckpt)\n\t    def get_ckpts_to_delete(self):\n\t        all_ckpts = self.get_all_ckpts()\n\t        if self.cfg.keep_best_ckpts:\n\t            metric_vals = []\n\t            for ckpt in all_ckpts:\n\t                training_stage = json.load(open(os.path.join(ckpt, TRAINING_STAGE_PATH)))\n\t                metric_val = training_stage[\"metrics\"][self.cfg.metric_name]\n", "                metric_vals.append(metric_val)\n\t            metric_ckpt = list(zip(metric_vals, all_ckpts))\n\t            metric_ckpt.sort(key=lambda x: x[0], reverse=self.cfg.metric_mode == MetricMode.MAX)\n\t            ckpts_to_delete = [ckpt for _, ckpt in metric_ckpt[self.cfg.limit_num_checkpoints:]]\n\t        else:\n\t            all_ckpts.sort(key=os.path.getctime, reverse=True)\n\t            ckpts_to_delete = all_ckpts[self.cfg.limit_num_checkpoints:]\n\t        return ckpts_to_delete"]}
{"filename": "trainer/accelerators/__init__.py", "chunked_list": ["from hydra.core.config_store import ConfigStore\n\tfrom trainer.accelerators.debug_accelerator import DebugAcceleratorConfig\n\tfrom trainer.accelerators.deepspeed_accelerator import DeepSpeedAcceleratorConfig\n\tACCELERATOR_GROUP_NAME = \"accelerator\"\n\tcs = ConfigStore.instance()\n\tcs.store(group=ACCELERATOR_GROUP_NAME, name=\"deepspeed\", node=DeepSpeedAcceleratorConfig)\n\tcs.store(group=ACCELERATOR_GROUP_NAME, name=\"debug\", node=DebugAcceleratorConfig)\n"]}
{"filename": "trainer/accelerators/utils.py", "chunked_list": ["import subprocess\n\tfrom typing import MutableMapping, Any, Dict\n\timport rich.tree\n\timport rich.syntax\n\tfrom accelerate.logging import get_logger\n\tfrom omegaconf import DictConfig, OmegaConf\n\tlogger = get_logger(__name__)\n\tdef nvidia_smi_gpu_memory_stats():\n\t    \"\"\"\n\t    Parse the nvidia-smi output and extract the memory used stats.\n", "    \"\"\"\n\t    out_dict = {}\n\t    try:\n\t        sp = subprocess.Popen(\n\t            [\"nvidia-smi\", \"--query-gpu=index,memory.used\", \"--format=csv,noheader\"],\n\t            stdout=subprocess.PIPE,\n\t            stderr=subprocess.PIPE,\n\t            close_fds=True,\n\t        )\n\t        out_str = sp.communicate()\n", "        out_list = out_str[0].decode(\"utf-8\").split(\"\\n\")\n\t        out_dict = {}\n\t        for item in out_list:\n\t            if \" MiB\" in item:\n\t                gpu_idx, mem_used = item.split(',')\n\t                gpu_key = f\"gpu_{gpu_idx}_mem_used_gb\"\n\t                out_dict[gpu_key] = int(mem_used.strip().split(\" \")[0]) / 1024\n\t    except FileNotFoundError:\n\t        logger.error(\n\t            \"Failed to find the 'nvidia-smi' executable for printing GPU stats\"\n", "        )\n\t    except subprocess.CalledProcessError as e:\n\t        logger.error(f\"nvidia-smi returned non zero error code: {e.returncode}\")\n\t    return out_dict\n\tdef get_nvidia_smi_gpu_memory_stats_str():\n\t    return f\"nvidia-smi stats: {nvidia_smi_gpu_memory_stats()}\"\n\tdef print_config(cfg: DictConfig):\n\t    style = \"bright\"\n\t    tree = rich.tree.Tree(\"CONFIG\", style=style, guide_style=style)\n\t    fields = cfg.keys()\n", "    for field in fields:\n\t        branch = tree.add(field, style=style, guide_style=style)\n\t        config_section = cfg.get(field)\n\t        branch_content = str(config_section)\n\t        if isinstance(config_section, DictConfig):\n\t            branch_content = OmegaConf.to_yaml(config_section, resolve=True)\n\t        branch.add(rich.syntax.Syntax(branch_content, \"yaml\"))\n\t    rich.print(tree)\n\tdef _flatten_dict(params: MutableMapping, delimiter: str = \"/\", parent_key: str = \"\") -> Dict[str, Any]:\n\t    result: Dict[str, Any] = {}\n", "    for k, v in params.items():\n\t        new_key = parent_key + delimiter + str(k) if parent_key else str(k)\n\t        if isinstance(v, MutableMapping):\n\t            result = {**result, **_flatten_dict(v, parent_key=new_key, delimiter=delimiter)}\n\t        else:\n\t            result[new_key] = v\n\t    return result\n"]}
