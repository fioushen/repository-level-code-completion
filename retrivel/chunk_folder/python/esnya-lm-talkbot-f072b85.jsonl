{"filename": "setup.py", "chunked_list": ["from setuptools import setup\n\timport talkbot\n\tsetup(\n\t    name=\"talkbot\",\n\t    version=talkbot.__version__,\n\t)\n"]}
{"filename": "talkbot/chat_engine.py", "chunked_list": ["\"\"\"Chat Engine component.\"\"\"\n\timport asyncio\n\timport json\n\timport math\n\timport os\n\timport random\n\timport re\n\timport time\n\tfrom datetime import date\n\tfrom functools import lru_cache\n", "from typing import Any\n\timport requests\n\timport torch\n\timport zmq\n\tfrom transformers import AutoModelForCausalLM, T5Tokenizer\n\tfrom .utilities.config import Config\n\tfrom .utilities.constants import ComponentState\n\tfrom .utilities.message import (\n\t    AssistantMessage,\n\t    TextMessage,\n", "    UserMessage,\n\t    is_text_message,\n\t    is_user_message,\n\t    update_busy_time,\n\t)\n\tfrom .utilities.socket import get_sockets, send_state\n\tdef is_valid_message(message) -> bool:\n\t    \"\"\"Check if a message is valid.\"\"\"\n\t    return set(message.keys()) == {\"role\", \"content\"}\n\t@lru_cache(maxsize=1)\n", "def load_model(\n\t    model_name: str, tokenizer_name: str, device: str, fp16: bool\n\t) -> tuple[T5Tokenizer, AutoModelForCausalLM]:\n\t    \"\"\"Load model.\"\"\"\n\t    tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained(  # type: ignore\n\t        tokenizer_name or model_name,\n\t        use_fast=False,\n\t    )\n\t    tokenizer.do_lower_case = True  # type: ignore\n\t    model: AutoModelForCausalLM = AutoModelForCausalLM.from_pretrained(model_name).to(device)  # type: ignore\n", "    if fp16:\n\t        model = model.half()\n\t    model.eval()\n\t    if torch.cuda.is_available():\n\t        torch.cuda.empty_cache()\n\t    return (tokenizer, model)\n\tasync def chat_engine(config: Config = Config()):\n\t    \"\"\"Chat Engine component.\"\"\"\n\t    logger = config.get_logger(\"ChatEngine\")\n\t    logger.info(\"Initializing\")\n", "    with get_sockets(\n\t        config,\n\t        1,\n\t    ) as (write_socket, read_socket):\n\t        model_name = config.get(\"chat_engine.model\")\n\t        tokenizer_name = config.get(\"chat_engine.tokenizer\", model_name)\n\t        device = config.get(\"chat_engine.device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n\t        logger.info(\"Loading model: %s (%s)\", model_name, device)\n\t        load_model(model_name, tokenizer_name, device, config.get(\"chat_engine.fp16\", False))\n\t        def _get_history_filename() -> str:\n", "            \"\"\"Get the history filename.\"\"\"\n\t            model_name = config.get(\"chat_engine.model\", \"history\")\n\t            pattern = r\"checkpoint.*|-pruned.*\"\n\t            model_name = re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", model_name).strip(\"_\")\n\t            model_name = re.sub(pattern, \"\", model_name)\n\t            default = f\"history/{model_name}.jsonl\" if model_name else \"history.jsonl\"\n\t            return config.get(\"chat_engine.history.file\", default)\n\t        def _parse_history_line(line: str) -> TextMessage | None:\n\t            \"\"\"Parse a line from the history file.\"\"\"\n\t            try:\n", "                message = json.loads(line)\n\t                if not is_text_message(message):\n\t                    return None\n\t                return message\n\t            except json.JSONDecodeError:\n\t                return None\n\t        _history: list[TextMessage] = []\n\t        def _get_chat_history() -> list[TextMessage]:\n\t            \"\"\"Get the chat history.\"\"\"\n\t            nonlocal _history\n", "            if not _history:\n\t                if os.path.exists(_get_history_filename()):\n\t                    with open(_get_history_filename(), \"r\", encoding=\"utf-8\") as file:\n\t                        _history = [message for message in [_parse_history_line(line) for line in file] if message]\n\t                else:\n\t                    _history = []\n\t            return _history\n\t        def _append_history(message: TextMessage) -> None:\n\t            \"\"\"Append a message to the history file.\"\"\"\n\t            nonlocal _history\n", "            if not is_valid_message(message):\n\t                raise TypeError(f\"Invalid message: {message}\")\n\t            _history.append(message)\n\t            with open(_get_history_filename(), \"a+\", encoding=\"utf-8\") as file:\n\t                file.write(json.dumps(message, ensure_ascii=False))\n\t                file.write(\"\\n\")\n\t        def _format_messages(messages: list[TextMessage]) -> list[str]:\n\t            \"\"\"Format messages for the model.\"\"\"\n\t            return [\n\t                config.get(f\"chat_engine.message_formats.{message['role']}\", \"{}\").format(message[\"content\"])\n", "                for message in messages\n\t                if message[\"role\"] != \"system\"\n\t            ]\n\t        @torch.no_grad()\n\t        def _generate(\n\t            received_message: list[TextMessage],\n\t            history: list[TextMessage],\n\t        ) -> str | None:\n\t            \"\"\"Generate a response from the model.\"\"\"\n\t            tokenizer_name = config.get(\"chat_engine.tokenizer\", model_name)\n", "            device = config.get(\n\t                \"chat_engine.device\",\n\t                \"cuda\" if torch.cuda.is_available() else \"cpu\",\n\t            )\n\t            logger.debug(\"Loading model: %s (%s)\", model_name, device)\n\t            (tokenizer, model) = load_model(model_name, tokenizer_name, device, config.get(\"chat_engine.fp16\", False))\n\t            input_text = config.get(\"chat_engine.message_separator\", \"\").join(\n\t                _format_messages(history + received_message) + config.get(\"chat_engine.suffix_messages\", [])\n\t            )\n\t            logger.info(\"Generating from: %s\", input_text)\n", "            logger.debug(\"Encoding\")\n\t            input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", add_special_tokens=False).to(  # type: ignore\n\t                model.device  # type: ignore\n\t            )\n\t            logger.debug(\"Generating: input={%s}\", tokenizer.batch_decode(input_ids))\n\t            generation_config: dict[str, Any] = config.get(\n\t                \"chat_engine.generation_config\",\n\t                dict[str, Any](),\n\t            )\n\t            output_ids = model.generate(  # type: ignore\n", "                input_ids,\n\t                **generation_config,\n\t            )\n\t            loss = model(output_ids, labels=output_ids).loss.item()  # type: ignore\n\t            logger.info(\"Loss: %s\", loss)\n\t            if math.isnan(loss) or loss > config.get(\"chat_engine.max_loss\", 10):\n\t                return None\n\t            output_token_count = len(output_ids[0]) - len(input_ids[0])\n\t            logger.debug(\"Decoding %s tokens: %s\", output_token_count, tokenizer.batch_decode(output_ids))\n\t            output_text = tokenizer.decode(output_ids[0][len(input_ids[0]) :])\n", "            logger.debug(\"Formatting\")\n\t            end_match = re.search(config.get(\"chat_engine.stop_pattern\", \"</s>\"), output_text)\n\t            logger.debug(end_match)\n\t            content = output_text[: end_match.start()] if end_match else output_text\n\t            max_length = config.get(\"chat_engine.content_max_length\")\n\t            if max_length and len(content) > max_length:\n\t                return None\n\t            return content\n\t        async def _process_command(message: AssistantMessage) -> str | None:\n\t            \"\"\"Process a command.\"\"\"\n", "            try:\n\t                if not message[\"role\"] == \"assistant\":\n\t                    return\n\t                match = re.search(r\"(?<=<req>) *[A-Z]+\", message[\"content\"])\n\t                if not match:\n\t                    return None\n\t                command = match.group(0).strip()\n\t                timeout = config.get(\"chat_engine.command.http_timeout\")\n\t                match (command):\n\t                    case \"DATE\":\n", "                        return f\"{date.today()}\"\n\t                    case \"WEATHER\":\n\t                        res = requests.get(\n\t                            \"https://weather.tsukumijima.net/api/forecast?city=130010\",\n\t                            timeout=timeout,\n\t                        ).json()\n\t                        weather = (\n\t                            res[\"forecasts\"][0][\"dateLabel\"] + \"の\" + res[\"title\"] + \"は\" + res[\"forecasts\"][0][\"telop\"]\n\t                        )\n\t                        await _add_assistant_message(weather)\n", "                        return weather\n\t                    case \"NEWS\":\n\t                        rss = requests.get(\n\t                            \"https://www.nhk.or.jp/rss/news/cat0.xml\",\n\t                            timeout=timeout,\n\t                        ).text\n\t                        titles = re.findall(r\"(?<=<title>).*(?=</title>)\", rss)[1:]\n\t                        random.shuffle(titles)\n\t                        title = titles[0]\n\t                        await _add_assistant_message(title + \" （NHKニュース）\")\n", "                        return title\n\t                return None\n\t            except requests.HTTPError as err:\n\t                logger.error(err)\n\t                return None\n\t        async def _add_assistant_message(content: str) -> AssistantMessage:\n\t            assistant_message_json = AssistantMessage(\n\t                role=\"assistant\",\n\t                content=content,\n\t            )\n", "            _append_history(assistant_message_json)\n\t            logger.info(assistant_message_json)\n\t            await write_socket.send_json(assistant_message_json)\n\t            return assistant_message_json\n\t        async def _process_messages(messages: list[TextMessage]) -> AssistantMessage | None:\n\t            max_history_count = config.get(\"chat_engine.history.max_count\") or 0\n\t            history = _get_chat_history()[-max_history_count:] if max_history_count else []\n\t            for message in messages:\n\t                logger.info(\"Message: %s\", message)\n\t                _append_history(message)\n", "            for _ in range(0, 10):\n\t                logger.info(\"Generating\")\n\t                content = await asyncio.to_thread(\n\t                    _generate,\n\t                    messages,\n\t                    history,\n\t                )\n\t                if content:\n\t                    return await _add_assistant_message(content)\n\t                logger.warning(\"Failed to generate\")\n", "            return None\n\t        prev_time = time.time()\n\t        message_buffer: list[TextMessage] = []\n\t        last_stt_busy_time = 0\n\t        last_tts_busy_time = 0\n\t        logger.info(\"Started\")\n\t        await send_state(write_socket, \"ChatEngine\", ComponentState.READY)\n\t        while not write_socket.closed and not read_socket.closed:\n\t            while True:\n\t                try:\n", "                    message = await read_socket.recv_json()\n\t                    if is_user_message(message):\n\t                        message_buffer.append(message)\n\t                    else:\n\t                        last_stt_busy_time = update_busy_time(message, \"AudioToMessage\", last_stt_busy_time)\n\t                        last_tts_busy_time = update_busy_time(message, \"MessageToSpeak\", last_tts_busy_time)\n\t                except zmq.error.Again:\n\t                    break\n\t            current_time = time.time()\n\t            if (\n", "                message_buffer\n\t                and current_time - prev_time >= config.get(\"chat_engine.min_interval\", 30)\n\t                and time.time() - last_stt_busy_time > config.get(\"global.busy_timeout\", 30)\n\t                and time.time() - last_tts_busy_time > config.get(\"global.busy_timeout\", 30)\n\t            ):\n\t                await send_state(write_socket, \"ChatEngine\", ComponentState.BUSY)\n\t                prev_time = current_time\n\t                assistant_message = await _process_messages(message_buffer)\n\t                message_buffer = []\n\t                if not assistant_message:\n", "                    continue\n\t                command_result = await _process_command(assistant_message)\n\t                if command_result:\n\t                    await _process_messages([UserMessage(role=\"user\", content=\"<res>\" + command_result)])\n\t                await send_state(write_socket, \"ChatEngine\", ComponentState.READY)\n\t                await asyncio.sleep(config.get(\"chat_engine.sleep_after_completion\", 0))\n\t                if torch.cuda.is_available():\n\t                    torch.cuda.empty_cache()\n\t            else:\n\t                await asyncio.sleep(1)\n"]}
{"filename": "talkbot/__main__.py", "chunked_list": ["\"\"\"Talkbot main entry point.\"\"\"\n\timport asyncio\n\timport signal\n\tfrom typing import Any, Callable, Coroutine\n\tfrom .audio_to_message import audio_to_message\n\tfrom .bridge import bridge\n\tfrom .chat_engine import chat_engine\n\tfrom .console import console\n\tfrom .message_stream import message_stream\n\tfrom .message_to_speak import message_to_speak\n", "from .neos_connector import neos_connector\n\tfrom .prune import prune\n\tfrom .train import train\n\tfrom .utilities.asyncargh import AsyncArghParser\n\tfrom .utilities.config import Config\n\tCOMPONENTS: list[Callable[..., Coroutine[Any, Any, Any]]] = [\n\t    neos_connector,\n\t    audio_to_message,\n\t    message_to_speak,\n\t    chat_engine,\n", "    message_stream,\n\t]\n\tasync def run(config: Config = Config()):\n\t    \"\"\"Talkbot main entry point.\"\"\"\n\t    tasks = [asyncio.create_task(component(config=config)) for component in COMPONENTS]\n\t    if not tasks:\n\t        raise ValueError(\"No components to run\")\n\t    await asyncio.gather(*tasks)\n\tasync def run_bridge(\n\t    config1: Config = Config(),\n", "    config2: Config = Config(),\n\t    sleep: float = 10.0,\n\t    no_whisper: bool = False,\n\t):\n\t    \"\"\"Run a bridge between two talkbots.\"\"\"\n\t    tasks = [\n\t        bridge(config1=config1, config2=config2, sleep=sleep),\n\t        *[(component(config=config1)) for component in COMPONENTS if not no_whisper or component != audio_to_message],\n\t        *[(component(config=config2)) for component in COMPONENTS if component != audio_to_message],\n\t    ]\n", "    await asyncio.gather(*[asyncio.create_task(task) for task in tasks])\n\tdef _on_sigint(*_):\n\t    \"\"\"Handle SIGINT.\"\"\"\n\t    for task in asyncio.all_tasks():\n\t        task.cancel()\n\tsignal.signal(signal.SIGINT, _on_sigint)\n\tparser = AsyncArghParser()\n\tparser.add_async_commands(COMPONENTS)\n\tparser.add_async_commands([run])\n\tparser.add_async_commands([console])\n", "parser.add_async_commands([train])\n\tparser.add_async_commands([prune])\n\tparser.add_async_commands([run_bridge])\n\tparser.set_async_default_command(run)\n\tparser.dispatch()\n"]}
{"filename": "talkbot/train.py", "chunked_list": ["\"\"\"Train a model for chatbot.\"\"\"\n\timport torch\n\tfrom datasets import Dataset\n\tfrom transformers import (\n\t    AutoModelForCausalLM,\n\t    DataCollatorForLanguageModeling,\n\t    GPT2LMHeadModel,\n\t    T5Tokenizer,\n\t    Trainer,\n\t    TrainerCallback,\n", "    TrainingArguments,\n\t)\n\tfrom .utilities.config import Config\n\tasync def train(config: Config = Config()) -> None:\n\t    \"\"\"Train a model for chatbot.\"\"\"\n\t    logger = config.get_logger(\"Train\")\n\t    if torch.cuda.is_available():\n\t        logger.info(\"Initializing CUDA...\")\n\t        torch.cuda.init()\n\t        logger.info(\"CUDA initialized\")\n", "    logger.info(\"Loading base model...\")\n\t    model: GPT2LMHeadModel = AutoModelForCausalLM.from_pretrained(config.get(\"train.base_model\"))\n\t    logger.info(\"Base model loaded\")\n\t    logger.info(\"Loading tokenizer...\")\n\t    tokenizer = T5Tokenizer.from_pretrained(config.get(\"train.base_model\", required=True))\n\t    tokenizer.do_lower_case = True\n\t    logger.info(\"Tokenizer loaded\")\n\t    logger.info(\"Adding special tokens...\")\n\t    tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<user>\", \"<ai>\", \"<req>\", \"<res>\"]})\n\t    logger.info(tokenizer.special_tokens_map)\n", "    model.resize_token_embeddings(len(tokenizer))\n\t    logger.info(\"Special tokens added\")\n\t    logger.info(\"Generating training dataset...\")\n\t    dataset = []\n\t    with open(config.get(\"train.csv_file\", required=True), \"r\", encoding=\"utf-8\") as src:\n\t        logger.info(\"Loading training data: (header=%s)\", next(src))\n\t        for i, line in enumerate(src, 1):\n\t            if not line:\n\t                continue\n\t            try:\n", "                prompt, completion = [\n\t                    col.strip(\"「」\\n\\t 、。,.\").replace(\"「\", \"『\").replace(\"」\", \"』\") for col in line.split(\",\")\n\t                ]\n\t                if not prompt or not completion:\n\t                    continue\n\t                dataset.append((f\"<user>{prompt}\", f\"<ai>{completion}\"))\n\t            except Exception as err:\n\t                logger.fatal(\"Failed to parse line (%d): %s\", i + 1, line)\n\t                logger.fatal(err)\n\t                raise\n", "    if config.get(\"train.generate_pairs\", True):\n\t        logger.info(\"Generating pairs...\")\n\t        for i in range(len(dataset) - 1):\n\t            left_prompt, left_completion = dataset[i]\n\t            right_prompt, right_completion = dataset[i + 1]\n\t            dataset.append((left_prompt + left_completion + right_prompt, right_completion))\n\t    logger.debug(\"Dataset: %s\", dataset)\n\t    train_dataset: Dataset = Dataset.from_dict(\n\t        tokenizer.batch_encode_plus(dataset, padding=True, truncation=True, return_tensors=\"pt\")\n\t    )\n", "    logger.info(\"Training dataset generated: %s\", train_dataset)\n\t    logger.info(\"Initializing trainer...\")\n\t    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, **config.get(\"train.data_collator\", {}))\n\t    training_args = TrainingArguments(**config.get(\"train.training_args\", {}))\n\t    generation_config = config.get(\"chat_engine.generation_config\", {})\n\t    class Callback(TrainerCallback):\n\t        \"\"\"Callback to test the model after each epoch.\"\"\"\n\t        def on_epoch_end(self, *args, **kwargs):\n\t            \"\"\"Test the model after each epoch.\"\"\"\n\t            for text in config.get(\"train.test_inputs\", []):\n", "                input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n\t                output_ids = model.generate(input_ids, **generation_config)\n\t                logger.info(tokenizer.decode(output_ids[0], skip_special_tokens=False))\n\t    trainer = Trainer(\n\t        model=model,\n\t        args=training_args,\n\t        data_collator=data_collator,\n\t        train_dataset=train_dataset,  # type: ignore\n\t        callbacks=[Callback()],\n\t    )\n", "    logger.info(\"Trainer initialized\")\n\t    logger.info(\"Saving tokenizer...\")\n\t    tokenizer.save_pretrained(config.get(\"train.training_args.output_dir\"))\n\t    logger.info(\"Tokenizer saved\")\n\t    logger.info(\"Training...\")\n\t    trainer.train()\n\t    logger.info(\"Training completed\")\n\t    logger.info(\"Saving models...\")\n\t    trainer.save_state()\n\t    trainer.save_model()\n", "    logger.info(\"Model saved\")\n\t    logger.info(\"Saving tokenizer...\")\n\t    tokenizer.save_pretrained(config.get(\"train.training_args.output_dir\"))\n\t    logger.info(\"Tokenizer saved\")\n"]}
{"filename": "talkbot/audio_to_message.py", "chunked_list": ["\"\"\"Audio To Message component.\"\"\"\n\timport asyncio\n\timport math\n\tfrom functools import lru_cache\n\tfrom typing import Any, TypedDict, TypeGuard\n\timport numpy as np\n\timport pyaudio\n\timport torch\n\timport whisper\n\timport zmq\n", "from pyannote.audio.pipelines import VoiceActivityDetection\n\tfrom pyannote.core.annotation import Annotation\n\tfrom whisper.audio import N_SAMPLES, SAMPLE_RATE\n\tfrom .utilities.audio import get_device_by_name, get_pa, open_stream\n\tfrom .utilities.config import Config\n\tfrom .utilities.constants import ComponentState\n\tfrom .utilities.message import UserMessage, is_busy, update_busy_time\n\tfrom .utilities.socket import get_sockets, send_state\n\tclass DecodingResultSegment(TypedDict):\n\t    \"\"\"Decoding result segment.\"\"\"\n", "    text: str\n\t    compression_ratio: float\n\t    avg_logprob: float\n\t    no_speech_prob: float\n\t    temperature: float\n\tdef is_whisper_result_segment(value) -> TypeGuard[DecodingResultSegment]:\n\t    return isinstance(value, dict) and \"text\" in value\n\tasync def async_read_mic_input(stream: pyaudio.Stream, chunk: int) -> np.ndarray:\n\t    \"\"\"Read a chunk of audio from the microphone input stream.\"\"\"\n\t    data = await asyncio.to_thread(stream.read, chunk)\n", "    return np.frombuffer(data, dtype=np.float32)\n\tasync def audio_to_message(config: Config = Config()) -> None:\n\t    \"\"\"Convert audio to text messages.\"\"\"\n\t    logger = config.get_logger(\"AudioToMessage\")\n\t    logger.info(\"Initializing...\")\n\t    @lru_cache(maxsize=1)\n\t    def load_model(model_name: str | None = None, device: str | None = None):\n\t        logger.info(\"Loading model %s (%s) ...\", model_name, device)\n\t        if device == \"cuda\" and not torch.cuda.is_initialized():\n\t            logger.info(\"Initializing CUDA...\")\n", "            torch.cuda.init()\n\t        return whisper.load_model(model_name or \"base\", device=device)\n\t    load_model(\n\t        config.get(\"audio_to_message.whisper.model\", \"base\"),\n\t        config.get(\n\t            \"audio_to_message.whisper.device\",\n\t            \"cuda\" if torch.cuda.is_available() else \"cpu\",\n\t        ),\n\t    )\n\t    logger.info(\"Loading VAD pipeline\")\n", "    vad_pipeline = VoiceActivityDetection(**config.get(\"audio_to_message.vad.pipeline\", {}))\n\t    vad_pipeline.instantiate(config.get(\"audio_to_message.vad.hyper_parameters\", {}))\n\t    def filter_segment(\n\t        segment: Any,\n\t    ) -> TypeGuard[DecodingResultSegment]:\n\t        if not is_whisper_result_segment(segment):\n\t            return False\n\t        text: str = segment[\"text\"]\n\t        compression_ratio: float = segment[\"compression_ratio\"]\n\t        avg_logprob: float = segment[\"avg_logprob\"]\n", "        no_speech_prob: float = segment[\"no_speech_prob\"]\n\t        temperature: float = segment[\"temperature\"]\n\t        logger.info(\n\t            \"Seg: comp=%.3f logprob=%.3f no_speech=%.3f temp=%.3f %s\",\n\t            compression_ratio,\n\t            avg_logprob,\n\t            no_speech_prob,\n\t            temperature,\n\t            text,\n\t        )\n", "        return (\n\t            bool(text)\n\t            and text not in config.get(\"audio_to_message.whisper.blacklist\", [])\n\t            and math.isfinite(compression_ratio * avg_logprob * no_speech_prob)\n\t            and temperature <= config.get(\"audio_to_message.whisper.max_temperature\", 1.0)\n\t        )\n\t    _initial_prompt: str | None = None\n\t    def transcribe(data: np.ndarray) -> list[str] | None:\n\t        nonlocal _initial_prompt\n\t        if np.max(data) - np.min(data) <= config.get(\"audio_to_message.min_volume\", 0.01):\n", "            return None\n\t        model = load_model(\n\t            config.get(\"audio_to_message.whisper.model\", \"base\"),\n\t            config.get(\n\t                \"audio_to_message.whisper.device\",\n\t                \"cuda\" if torch.cuda.is_available() else \"cpu\",\n\t            ),\n\t        )\n\t        logger.info(\"Transcribing: frames=%d\", data.size)\n\t        result = whisper.transcribe(\n", "            model, data, initial_prompt=_initial_prompt, **config.get(\"audio_to_message.whisper.decode_config\", {})\n\t        )\n\t        segments = [segment.get(\"text\") for segment in result[\"segments\"] if filter_segment(segment)]\n\t        if segments:\n\t            _initial_prompt = (_initial_prompt or \"\") + \" \".join(segments)\n\t        prompt_length: int = config.get(\"audio_to_message.whisper.prompt_length\") or 0\n\t        if prompt_length is None or prompt_length == 0:\n\t            _initial_prompt = None\n\t        else:\n\t            _initial_prompt = ((_initial_prompt or \"\") + \"\\n\")[-prompt_length:]\n", "        return segments\n\t    buffer = np.empty((0,), np.float32)\n\t    device_name: str | None = config.get(\"audio_to_message.input_device.name\")\n\t    device_index = 0\n\t    if device_name is not None:\n\t        device_index = get_device_by_name(device_name, min_input_channels=1)\n\t    def stream_callback(in_data: bytes, frame_count: int, time_info, status):\n\t        nonlocal buffer\n\t        audio_data = np.frombuffer(in_data, dtype=np.float32)\n\t        buffer = np.concatenate((buffer, audio_data))\n", "        return (audio_data, pyaudio.paContinue)\n\t    _stream_frames_per_buffer = config.get(\"audio_to_message.input_device.frames_per_buffer\", 1024)\n\t    with get_sockets(config, 0.5) as (write_socket, read_socket), open_stream(\n\t        format=pyaudio.paFloat32,\n\t        channels=1,\n\t        rate=SAMPLE_RATE,\n\t        input=True,\n\t        input_device_index=device_index,\n\t        frames_per_buffer=_stream_frames_per_buffer,\n\t        stream_callback=stream_callback,\n", "    ) as stream:\n\t        last_busy_time = 0.0\n\t        logger.info(\"Initialized\")\n\t        stream.start_stream()\n\t        logger.info(\"Started: recording device i %s\", get_pa().get_device_info_by_index(device_index))\n\t        await send_state(write_socket, \"AudioToMessage\", ComponentState.READY)\n\t        while not write_socket.closed and not read_socket.closed:\n\t            try:\n\t                message = await read_socket.recv_json()\n\t                last_busy_time = update_busy_time(message, \"ChatEngine\", last_busy_time)\n", "            except zmq.error.Again:\n\t                pass\n\t            if buffer.size <= 1:\n\t                continue\n\t            silence_duration = config.get(\"message_to_message.silence_duration\", 1.0)\n\t            max_buffer_size: int = config.get(\"audio_to_message.max_buffer_size\", N_SAMPLES)\n\t            if is_busy(last_busy_time, config.get(\"global.busy_timeout\", 30.0)):\n\t                await asyncio.sleep(1)\n\t                continue\n\t            try:\n", "                vad: Annotation = vad_pipeline(\n\t                    {\"waveform\": torch.from_numpy(buffer.reshape((1, -1))), \"sample_rate\": SAMPLE_RATE}\n\t                )\n\t                timeline = vad.get_timeline(False)\n\t                segments: list[tuple[(int, int)]] = [\n\t                    (max(int((seg.start - 0.5) * SAMPLE_RATE), 0), int(math.ceil((seg.end + 0.5) * SAMPLE_RATE)))\n\t                    for seg in timeline  # type: ignore\n\t                ]\n\t                if len(segments) == 0:\n\t                    continue\n", "                left = segments[0][0]\n\t                right = segments[-2][1] if len(segments) >= 2 else segments[-1][1]\n\t                if (\n\t                    len(segments) >= 2\n\t                    or right - left >= max_buffer_size\n\t                    or buffer.size - right >= silence_duration * SAMPLE_RATE\n\t                ):\n\t                    await send_state(write_socket, \"AudioToMessage\", ComponentState.BUSY)\n\t                    results = await asyncio.to_thread(transcribe, buffer[left:right])\n\t                    buffer = buffer[right:]\n", "                    if results:\n\t                        for text in results:\n\t                            await write_socket.send_json(\n\t                                UserMessage(\n\t                                    role=\"user\",\n\t                                    content=text,\n\t                                )\n\t                            )\n\t                    await send_state(write_socket, \"AudioToMessage\", ComponentState.READY)\n\t                    if torch.cuda.is_available():\n", "                        torch.cuda.empty_cache()\n\t                elif left > 0:\n\t                    buffer = buffer[left:]\n\t            except (RuntimeError, ValueError) as err:\n\t                logger.error(\"%s: %s\", type(err), err, exc_info=True)\n\t                buffer = np.empty((0,), np.float32)\n\t                continue\n\t    logger.info(\"Terminated\")\n"]}
{"filename": "talkbot/neos_connector.py", "chunked_list": ["\"\"\"Neos Connector component\"\"\"\n\timport time\n\timport zmq\n\tfrom websockets.exceptions import ConnectionClosedError\n\tfrom websockets.server import WebSocketServerProtocol, serve\n\tfrom talkbot.utilities.message import is_state_message\n\tfrom .utilities.config import Config\n\tfrom .utilities.constants import ComponentState\n\tfrom .utilities.socket import get_read_socket\n\tasync def neos_connector(config: Config = Config()):\n", "    \"\"\"Connects to Neos and sends messages to the chat engine.\"\"\"\n\t    logger = config.get_logger(\"NeosConnector\")\n\t    logger.info(\"Initializing\")\n\t    ws_connections: set[WebSocketServerProtocol] = set()\n\t    async def _handle_socket(websocket: WebSocketServerProtocol):\n\t        await websocket.send(\"ready\")\n\t        ws_connections.add(websocket)\n\t        try:\n\t            await websocket.wait_closed()\n\t        finally:\n", "            ws_connections.remove(websocket)\n\t    async def _ws_broadcast(message: str):\n\t        logger.info(\"Expression: %s\", message)\n\t        for connection in ws_connections:\n\t            try:\n\t                await connection.send(message)\n\t            except ConnectionClosedError as e:\n\t                logger.error(e)\n\t                ws_connections.remove(connection)\n\t    component_status: dict[str, ComponentState] = {}\n", "    component_status_update_time: dict[str, float] = {}\n\t    def is_busy(component: str):\n\t        state = component_status.get(component, ComponentState.READY)\n\t        time_passed = component and time.time() - component_status_update_time.get(component, 0)\n\t        state_timeout = config.get(\"neos_connector.expressions.state_timeout\", 30)\n\t        return state == ComponentState.BUSY and time_passed < state_timeout\n\t    def get_expression():\n\t        on_busy = config.get(\"neos_connector.expressions.on_busy\", {})\n\t        for component, expression in on_busy.items():\n\t            if is_busy(component):\n", "                return expression\n\t        return config.get(\"neos_connector.expressions.default\", required=True)\n\t    async with serve(\n\t        _handle_socket,\n\t        config.get(\"neos_connector.websocket.host\"),\n\t        config.get(\"neos_connector.websocket.port\"),\n\t    ) as server:\n\t        with get_read_socket(config, config.get(\"neos_connector.max_interval\")) as read_socket:\n\t            logger.info(\"Initialized\")\n\t            logger.info(\"Started\")\n", "            while not read_socket.closed and server.is_serving():\n\t                await _ws_broadcast(get_expression())\n\t                try:\n\t                    message = await read_socket.recv_json()\n\t                    if not is_state_message(message):\n\t                        continue\n\t                    component = message.get(\"component\", \"unknown\")\n\t                    state = ComponentState(message.get(\"state\")) or ComponentState.READY\n\t                    component_status[component] = state\n\t                    component_status_update_time[component] = time.time()\n", "                    logger.debug(\n\t                        \"Status Updated: %s, %s\",\n\t                        component_status,\n\t                        component_status_update_time,\n\t                    )\n\t                except zmq.error.Again:\n\t                    pass\n\t        logger.info(\"Terminated\")\n"]}
{"filename": "talkbot/console.py", "chunked_list": ["\"\"\"Console for TalkBot.\"\"\"\n\tfrom transformers import AutoTokenizer\n\tfrom .utilities.audio import list_device_info, list_host_api_info\n\tfrom .utilities.config import Config\n\tfrom .utilities.socket import get_write_socket\n\tfrom .utilities.voicevox import speakers\n\tasync def console(config: Config = Config()):\n\t    \"\"\"Console component.\"\"\"\n\t    with get_write_socket(config) as socket:\n\t        role = \"user\"\n", "        while True:\n\t            match (input(f\"{role}> \")):\n\t                case value if value in [\"\\\\quit\", \"\\\\q\"]:\n\t                    break\n\t                case value if value in [\"\\\\user\", \"\\\\u\"]:\n\t                    role = \"user\"\n\t                case value if value in [\"\\\\system\", \"\\\\s\"]:\n\t                    role = \"system\"\n\t                case value if value in [\"\\\\api\", \"\\\\a\"]:\n\t                    print(list_host_api_info(), sep=\"\\n\")\n", "                case value if value in [\"\\\\output\", \"\\\\o\"]:\n\t                    print(\n\t                        [info for info in list_device_info() if int(info[\"maxOutputChannels\"]) > 0],\n\t                        sep=\"\\n\",\n\t                    )\n\t                case value if value in [\"\\\\input\", \"\\\\i\"]:\n\t                    print(\n\t                        [info for info in list_device_info() if int(info[\"maxInputChannels\"]) > 0],\n\t                        sep=\"\\n\",\n\t                    )\n", "                case value if value in [\"\\\\voice\", \"\\\\v\"]:\n\t                    print(await speakers())\n\t                case value if value in [\"\\\\t\", \"\\\\tokens\"]:\n\t                    tokenizer = AutoTokenizer.from_pretrained(\n\t                        config.get(\"chat_engine.tokenizer\", config.get(\"chat_engine.model\")),\n\t                    )\n\t                    print(tokenizer.special_tokens_map)\n\t                case value if value.startswith(\"\\\\e \") or value.startswith(\"\\\\encode \"):\n\t                    _, text = value.split(\" \", 1)\n\t                    print(\n", "                        AutoTokenizer.from_pretrained(\n\t                            config.get(\"chat_engine.tokenizer\", config.get(\"chat_engine.model\"))\n\t                        ).encode(text, add_special_tokens=False)\n\t                    )\n\t                case value:\n\t                    message = {\n\t                        \"role\": role,\n\t                        \"content\": value,\n\t                    }\n\t                    await socket.send_json(message)\n"]}
{"filename": "talkbot/bridge.py", "chunked_list": ["\"\"\"Bridge between two talkbots.\"\"\"\n\timport re\n\timport time\n\timport zmq.asyncio\n\tfrom .utilities.config import Config\n\tfrom .utilities.message import AssistantMessage, UserMessage, is_assistant_message\n\tfrom .utilities.socket import Socket, get_sockets\n\tasync def bridge(config1: Config = Config(), config2: Config = Config(), sleep: float = 10.0):\n\t    \"\"\"Bridge between two talkbots.\"\"\"\n\t    logger = config1.get_logger(\"Bridge\")\n", "    logger.info(\"Initializing\")\n\t    async def _bridge(\n\t        read: Socket,\n\t        write: Socket,\n\t        remove_pattern: str,\n\t        log_format: str,\n\t        sleep: float,\n\t    ):\n\t        \"\"\"Bridge from socket1 to socket2.\"\"\"\n\t        start_time = time.time()\n", "        messages: list[UserMessage] = []\n\t        def append_message(message: AssistantMessage):\n\t            messages.append(\n\t                UserMessage(\n\t                    role=\"user\",\n\t                    content=re.sub(\n\t                        remove_pattern,\n\t                        \"\",\n\t                        message[\"content\"],\n\t                    ),\n", "                )\n\t            )\n\t            logger.info(log_format.format(message[\"content\"]))\n\t        while time.time() - start_time < sleep:\n\t            try:\n\t                message = await read.recv_json()\n\t                if is_assistant_message(message):\n\t                    append_message(message)\n\t            except zmq.error.Again:\n\t                pass\n", "        for msg in messages or [{\"role\": \"user\", \"content\": \" \"}]:\n\t            await write.send_json(msg)\n\t    with get_sockets(config1, sleep) as (write_socket1, read_socket1), get_sockets(config2, sleep) as (\n\t        write_socket2,\n\t        read_socket2,\n\t    ):\n\t        logger.info(\"Initialized\")\n\t        logger.info(\"Started\")\n\t        while not (write_socket1.closed or write_socket2.closed or read_socket1.closed or read_socket2.closed):\n\t            logger.info(\"1 >>> 2\")\n", "            await _bridge(\n\t                read_socket1,\n\t                write_socket2,\n\t                config1.get(\"message_to_speak.remove_pattern\", \"\"),\n\t                \"「{}」\",\n\t                sleep,\n\t            )\n\t            logger.info(\"1 <<< 2\")\n\t            await _bridge(\n\t                read_socket2,\n", "                write_socket1,\n\t                config2.get(\"message_to_speak.remove_pattern\", \"\"),\n\t                \"『{}』\",\n\t                sleep,\n\t            )\n\t    logger.info(\"Terminated\")\n"]}
{"filename": "talkbot/__init__.py", "chunked_list": ["\"\"\"Talkbot components.\"\"\"\n\t__version__ = \"0.1.0\"\n"]}
{"filename": "talkbot/message_to_speak.py", "chunked_list": ["\"\"\"Message to speak\"\"\"\n\timport asyncio\n\timport os\n\timport re\n\tfrom abc import ABC, abstractmethod\n\tfrom contextlib import AbstractContextManager\n\timport numpy as np\n\timport pyaudio\n\timport zmq\n\tfrom talkbot.utilities.message import is_assistant_message\n", "from .utilities.audio import get_device_by_name, get_pa\n\tfrom .utilities.config import Config\n\tfrom .utilities.constants import ComponentState\n\tfrom .utilities.socket import Socket, get_context, send_state\n\tfrom .utilities.voicevox import audio_query, synthesis, version\n\tclass MessageToSpeak(AbstractContextManager, ABC):\n\t    def __init__(self, config: Config = Config()):\n\t        self.config = config\n\t        logger = self.logger = config.get_logger(\"MessageToSpeak\")\n\t        \"\"\"Message to speak component\"\"\"\n", "        logger.info(\"Initializing\")\n\t        self.english_kana_dict: dict[str, str] = {}\n\t        english_kana_dict_filename = config.get(\"message_to_speak.english_kana_dict\")\n\t        if english_kana_dict_filename and os.path.exists(english_kana_dict_filename):\n\t            logger.info(\"Loading English to Kana dictionary\")\n\t            with open(english_kana_dict_filename, \"r\", encoding=\"utf-8\") as file:\n\t                next(file)\n\t                self.english_kana_dict = {\n\t                    col[0].strip().lower(): col[1].strip()\n\t                    for col in (line.split(\",\") for line in file.readlines() if line and not line.startswith(\"#\"))\n", "                    if len(col) >= 2\n\t                }\n\t                logger.info(\"Loaded English to Kana dictionary (%d entries)\", len(self.english_kana_dict))\n\t        logger.info(\"Initialized\")\n\t    def _stream_format(self):\n\t        return {\n\t            \"format\": pyaudio.paInt16,\n\t            \"channels\": 1,\n\t            \"rate\": 24000,\n\t        }\n", "    def __enter__(self):\n\t        self.write_socket: Socket = get_context().socket(zmq.PUB)  # type: ignore\n\t        self.write_socket.connect(self.config.get(\"message_stream.write\", \"\"))\n\t        self.read_socket: Socket = get_context().socket(zmq.SUB)  # type: ignore\n\t        self.read_socket.connect(self.config.get(\"message_stream.read\", \"\"))\n\t        self.read_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\t        device_name = self.config.get(\"message_to_speak.output_device.name\")\n\t        output_device_index = 0 if device_name is None else get_device_by_name(device_name, min_output_channels=1)\n\t        self.logger.debug(\n\t            \"Playing on: %s\",\n", "            get_pa().get_device_info_by_index(output_device_index),\n\t        )\n\t        self.stream = get_pa().open(\n\t            output_device_index=output_device_index,\n\t            output=True,\n\t            **self._stream_format(),\n\t        )\n\t        return self\n\t    def __exit__(self, *args):\n\t        self.write_socket.close()\n", "        self.read_socket.close()\n\t        self.stream.close()\n\t    async def play(self, data: bytes):\n\t        await asyncio.to_thread(self.stream.write, data)\n\t    async def run(self):\n\t        logger = self.logger\n\t        config = self.config\n\t        write_socket = self.write_socket\n\t        read_socket = self.read_socket\n\t        logger.info(\"Started\")\n", "        await send_state(write_socket, \"MessageToSpeak\", ComponentState.READY)\n\t        while not write_socket.closed and not read_socket.closed:\n\t            message = await read_socket.recv_json()\n\t            if not is_assistant_message(message):\n\t                continue\n\t            match = re.search(\n\t                config.get(\"message_to_speak.talk_pattern\", r\"(.+)\"),\n\t                message[\"content\"],\n\t                re.MULTILINE,\n\t            )\n", "            if not match:\n\t                continue\n\t            text = match.group(1)\n\t            remove_pattern = config.get(\"message_to_speak.remove_pattern\")\n\t            if remove_pattern:\n\t                text = re.sub(remove_pattern, \"\", text)\n\t            if self.english_kana_dict:\n\t                text = re.sub(\n\t                    \"[a-zA-Z]+\",\n\t                    lambda m: self.english_kana_dict.get(m.group(0).lower(), m.group(0)),\n", "                    text,\n\t                )\n\t            if not text:\n\t                continue\n\t            await self.play_text(text)\n\t        logger.info(\"Terminated\")\n\t    @abstractmethod\n\t    async def play_text(self, text: str):\n\t        raise NotImplementedError()\n\tclass MessageToVoicevox(MessageToSpeak):\n", "    async def run(self):\n\t        self.logger.info(\"VOICEVOX version: %s\", await version())\n\t        await super().run()\n\t    async def play_text(self, text: str):\n\t        config = self.config\n\t        logger = self.logger\n\t        speaker = config.get(\"message_to_speak.voicevox.speaker\", 1)\n\t        segments = re.split(config.get(\"message_to_speak.split_pattern\", r\"。\"), text)\n\t        prev_task: asyncio.Task | None = None\n\t        for segment in segments:\n", "            if not segment:\n\t                continue\n\t            logger.info(\"Query: %s\", segment)\n\t            query = await audio_query(segment, speaker)\n\t            logger.info(\"Synthesis: %d\", speaker)\n\t            data = await synthesis(query, speaker)\n\t            if prev_task:\n\t                await prev_task\n\t            await send_state(self.write_socket, \"MessageToSpeak\", ComponentState.BUSY)\n\t            prev_task = asyncio.create_task(self.play(data[44:]))\n", "        if prev_task:\n\t            await prev_task\n\t        await send_state(self.write_socket, \"MessageToSpeak\", ComponentState.READY)\n\tclass MessageToRVC(MessageToVoicevox):\n\t    def __init__(self, config: Config = Config()):\n\t        from hf_rvc import RVCFeatureExtractor, RVCModel\n\t        super().__init__(config)\n\t        self.logger.info(\"Loading RVC model\")\n\t        device = \"cpu\"\n\t        rvc_model_path = config.get(\"message_to_speak.rvc.model\", True)\n", "        rvc_model = RVCModel.from_pretrained(rvc_model_path)\n\t        assert isinstance(rvc_model, RVCModel)\n\t        if self.config.get(\"message_to_speak.rvc.fp16\", device != \"cpu\"):\n\t            rvc_model = rvc_model.half()\n\t            self.fp16 = True\n\t        else:\n\t            self.fp16 = False\n\t        rvc_model = rvc_model.to(device)\n\t        rvc_model.vits = rvc_model.vits.to(device)\n\t        self.rvc_model = rvc_model\n", "        feature_extractor = RVCFeatureExtractor.from_pretrained(rvc_model_path)\n\t        assert isinstance(feature_extractor, RVCFeatureExtractor)\n\t        self.rvc_feature_extractor = feature_extractor\n\t    def _stream_format(self):\n\t        return {\n\t            \"format\": pyaudio.paFloat32,\n\t            \"channels\": 1,\n\t            \"rate\": 48000,\n\t        }\n\t    async def play_text(self, text: str):\n", "        import torch\n\t        await super().play_text(text)\n\t        torch.cuda.empty_cache()\n\t    async def play(self, data: bytes):\n\t        import resampy\n\t        import torch\n\t        if len(data) == 0:\n\t            return\n\t        with torch.no_grad():\n\t            resampled = resampy.resample(np.frombuffer(data, np.int16), 24000, 16000, axis=0)\n", "            self.rvc_feature_extractor.set_f0_method(self.config.get(\"message_to_speak.rvc.f0_method\", \"pm\"))\n\t            features = self.rvc_feature_extractor(\n\t                resampled,\n\t                f0_up_key=int(self.config.get(\"message_to_speak.rvc.f0_up_key\", 0)),\n\t                sampling_rate=16000,\n\t                return_tensors=\"pt\",\n\t            )\n\t            dtype = torch.float16 if self.fp16 else torch.float32\n\t            rvc_output = await asyncio.to_thread(\n\t                self.rvc_model,\n", "                input_values=features.input_values.to(self.rvc_model.device, dtype=dtype),\n\t                f0=features.f0.to(self.rvc_model.device, dtype=dtype),\n\t                f0_coarse=features.f0_coarse.to(self.rvc_model.device),\n\t            )\n\t            await super().play(\n\t                (rvc_output.cpu().float().numpy() * self.config.get(\"message_to_speak.rvc.volume\", 1.0)).tobytes()\n\t            )\n\tdef get_class_by_name(name: str) -> type[MessageToSpeak]:\n\t    match name:\n\t        case \"rvc\":\n", "            return MessageToRVC\n\t        case \"voicevox\":\n\t            return MessageToVoicevox\n\t        case _:\n\t            raise ValueError(f\"Unknown engine: {name}\")\n\tasync def message_to_speak(config: Config = Config()) -> None:\n\t    Impl = get_class_by_name(config.get(\"message_to_speak.engine\", \"voicevox\"))\n\t    with Impl(config) as message_to_speak:\n\t        await message_to_speak.run()\n"]}
{"filename": "talkbot/prune.py", "chunked_list": ["\"\"\"Prune a model to reduce its size.\"\"\"\n\tfrom torch.nn.utils.prune import l1_unstructured, remove\n\tfrom transformers import (\n\t    AutoModelForCausalLM,\n\t    AutoTokenizer,\n\t    PreTrainedTokenizer,\n\t    PreTrainedTokenizerFast,\n\t)\n\tasync def prune(src_model: str, save_dir: str, amount: float = 0.5):\n\t    \"\"\"Prune a model to reduce its size.\"\"\"\n", "    model: AutoModelForCausalLM = AutoModelForCausalLM.from_pretrained(src_model)\n\t    tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(src_model)\n\t    l1_unstructured(model.transformer.wte, name=\"weight\", amount=amount)\n\t    remove(model.transformer.wte, \"weight\")\n\t    tokenizer.save_pretrained(save_dir)\n\t    model.save_pretrained(save_dir)\n"]}
{"filename": "talkbot/message_stream.py", "chunked_list": ["\"\"\"MessageStream component.\"\"\"\n\tfrom typing import NoReturn\n\timport zmq\n\timport zmq.asyncio\n\tfrom .utilities.config import Config\n\tfrom .utilities.socket import get_context\n\tasync def message_stream(config: Config = Config()) -> NoReturn:\n\t    \"\"\"MessageStream component.\"\"\"\n\t    logger = config.get_logger(\"MessageStream\")\n\t    logger.info(\"Initializing\")\n", "    context = get_context()\n\t    with context.socket(zmq.SUB) as sub_socket, context.socket(zmq.PUB) as pub_socket:\n\t        sub_socket.bind(config.get(\"message_stream.write\", required=True))\n\t        sub_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\t        pub_socket.bind(config.get(\"message_stream.read\", required=True))\n\t        logger.info(\"Started\")\n\t        while True:\n\t            message = await sub_socket.recv_json()  # type: ignore\n\t            logger.debug(\"Message: %s\", message)\n\t            await pub_socket.send_json(message)  # type: ignore\n"]}
{"filename": "talkbot/utilities/asyncargh.py", "chunked_list": ["\"\"\"A module that allows async functions to be used as commands with argh.\"\"\"\n\timport asyncio\n\tfrom typing import Any, Callable, Coroutine, List, TypeVar\n\tfrom argh import ArghParser\n\tfrom argh.assembling import ATTR_NAME, _extract_command_meta_from_func\n\tT = TypeVar(\"T\")\n\tdef wrap_async(async_func: Callable[..., Coroutine[Any, Any, T]]) -> Callable[..., T]:\n\t    \"\"\"Wrap an async function so that it can be used as a command.\"\"\"\n\t    def wrapper(*args, **kwargs: Any) -> T:\n\t        return asyncio.run(async_func(*args, **kwargs))\n", "    setattr(wrapper, \"__wrapped__\", async_func)\n\t    cmd_name, _ = _extract_command_meta_from_func(async_func)\n\t    setattr(wrapper, ATTR_NAME, cmd_name)\n\t    setattr(wrapper, \"__doc__\", async_func.__doc__)\n\t    return wrapper\n\tclass AsyncArghParser(ArghParser):\n\t    \"\"\"A subclass of ArghParser that allows async functions to be added as commands.\"\"\"\n\t    def add_async_commands(self, commands: List[Callable[..., Coroutine[Any, Any, Any]]], *args, **kwargs) -> None:\n\t        \"\"\"Add a list of async functions as commands.\"\"\"\n\t        self.add_commands([wrap_async(func) for func in commands], *args, **kwargs)\n", "    def set_async_default_command(self, command: Callable[..., Coroutine[Any, Any, Any]]) -> None:\n\t        \"\"\"Set the default command to an async function.\"\"\"\n\t        self.set_default_command(wrap_async(command))\n"]}
{"filename": "talkbot/utilities/voicevox.py", "chunked_list": ["\"\"\"VoiceVox Core API wrapper.\"\"\"\n\timport asyncio\n\timport requests\n\tBASE_URL = \"http://localhost:50021\"\n\tasync def voicevox_post(\n\t    path: str,\n\t    params: dict | None = None,\n\t    data: bytes | None = None,\n\t    json: dict | None = None,\n\t    timeout: int | None = None,\n", "):\n\t    \"\"\"POST request to VoiceVox Core.\"\"\"\n\t    return await asyncio.to_thread(\n\t        requests.post, f\"{BASE_URL}{path}\", params=params, data=data, json=json, timeout=timeout\n\t    )\n\tasync def voicevox_get(path: str, params: dict | None = None, timeout: int | None = None):\n\t    \"\"\"GET request to VoiceVox Core.\"\"\"\n\t    return await asyncio.to_thread(requests.get, f\"{BASE_URL}{path}\", params=params, timeout=timeout)\n\tasync def version() -> str:\n\t    \"\"\"Get VoiceVox Core version.\"\"\"\n", "    return (await voicevox_get(\"/version\")).json()\n\tasync def engine_versions() -> str:\n\t    \"\"\"Get VoiceVox Core engine versions.\"\"\"\n\t    return (await voicevox_get(\"/engine_versions\")).json()\n\tasync def speakers() -> dict:\n\t    \"\"\"Get VoiceVox Core speakers.\"\"\"\n\t    return (await voicevox_get(\"/speakers\")).json()\n\tasync def audio_query(text: str, speaker: int = 1) -> dict:\n\t    \"\"\"Get VoiceVox Core audio query.\"\"\"\n\t    return (await voicevox_post(\"/audio_query\", params={\"text\": text, \"speaker\": speaker})).json()\n", "async def synthesis(query: dict, speaker: int = 1) -> bytes:\n\t    \"\"\"Get VoiceVox Core synthesis.\"\"\"\n\t    return (await voicevox_post(\"/synthesis\", params={\"speaker\": speaker}, json=query)).content\n"]}
{"filename": "talkbot/utilities/config.py", "chunked_list": ["\"\"\"A module for loading and accessing configuration data from YAML files.\"\"\"\n\timport logging.config\n\timport os\n\tfrom logging import Logger\n\tfrom typing import Any, TypeVar, overload\n\timport yaml\n\tfrom pydotenv import Environment\n\tT = TypeVar(\"T\")\n\tclass Config:\n\t    \"\"\"A class for loading and accessing configuration data from YAML files.\"\"\"\n", "    def __init__(self, *filepaths: str | None):\n\t        \"\"\"Initialize the Config object.\"\"\"\n\t        env = Environment().get(\"ENV\", \"development\")\n\t        self._filepaths = [\n\t            filepath\n\t            for filepath in [\n\t                \"config/default.yml\",\n\t                f\"config/{env}.yml\",\n\t                \"config/local.yml\",\n\t                f\"config/{env}-local.yml\",\n", "            ]\n\t            if os.path.isfile(filepath)\n\t        ]\n\t        if filepaths:\n\t            self._filepaths.extend([filepath for filepath in filepaths if filepath and os.path.isfile(filepath)])\n\t        self._config_data: dict[str, Any] = {}\n\t        self._timestamps: dict[str, float] = {}\n\t    def _load_yaml_file(self, filepath: str) -> dict:\n\t        if not os.path.isfile(filepath):\n\t            return {}\n", "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n\t            return yaml.safe_load(file)\n\t    def _check_and_update(self, filepath: str) -> None:\n\t        timestamp = os.path.getmtime(filepath)\n\t        if filepath not in self._timestamps or self._timestamps[filepath] != timestamp:\n\t            self._config_data[filepath] = self._load_yaml_file(filepath)\n\t            self._timestamps[filepath] = timestamp\n\t    @overload\n\t    def get(self, path: str) -> Any | None:\n\t        pass\n", "    @overload\n\t    def get(self, path: str, default=None, required=True) -> Any:\n\t        pass\n\t    @overload\n\t    def get(self, path: str, default: T) -> T:\n\t        pass\n\t    def get(self, path: str, default: Any = None, required=False) -> Any:\n\t        \"\"\"Get a value from the configuration data.\"\"\"\n\t        keys = path.split(\".\")\n\t        result = None\n", "        for filepath in reversed(self._filepaths):\n\t            self._check_and_update(filepath)\n\t            config_data = self._config_data.get(filepath, {})\n\t            current = config_data\n\t            for key in keys:\n\t                if not current or key not in current:\n\t                    break\n\t                current = current[key]\n\t            else:\n\t                if result is None:\n", "                    result = current\n\t                elif isinstance(result, dict) and isinstance(current, dict):\n\t                    result = self._deep_merge(result, current)\n\t        if result is None:\n\t            if required:\n\t                raise KeyError(f\"Missing required configuration value: {path}\")\n\t            else:\n\t                return default\n\t        return result\n\t    def _deep_merge(self, source: dict, destination: dict) -> dict:\n", "        \"\"\"Recursively merge two dictionaries.\"\"\"\n\t        for key, value in source.items():\n\t            if isinstance(value, dict):\n\t                destination[key] = self._deep_merge(destination.get(key, {}), value)\n\t            else:\n\t                destination[key] = value\n\t        return destination\n\t    def get_logger(self, name: str | None = None) -> Logger:\n\t        \"\"\"Get a logger from the configuration data.\"\"\"\n\t        logging.config.dictConfig(self.get(\"log\", dict[str, Any]()))\n", "        return logging.getLogger(name)\n\t    @classmethod\n\t    def get_instance(cls):\n\t        \"\"\"Get the singleton instance of the Config class.\"\"\"\n\t        if not hasattr(cls, \"_instance\"):\n\t            cls._instance = Config()\n\t        return cls._instance\n"]}
{"filename": "talkbot/utilities/audio.py", "chunked_list": ["\"\"\"Utilities for working with audio.\"\"\"\n\timport atexit\n\timport signal\n\timport threading\n\tfrom contextlib import contextmanager\n\tfrom typing import List\n\timport numpy as np\n\timport pyaudio\n\tfrom numpy.typing import ArrayLike\n\tdef get_device_by_name(device_name: str, min_input_channels: int = 0, min_output_channels: int = 0) -> int:\n", "    \"\"\"Get the index of the first matched device.\"\"\"\n\t    for i, info in enumerate(list_device_info()):\n\t        if (\n\t            device_name in str(info[\"name\"])\n\t            and int(info[\"maxOutputChannels\"]) >= min_output_channels\n\t            and int(info[\"maxInputChannels\"]) >= min_input_channels\n\t        ):\n\t            return i\n\t    raise ValueError(f\"No output device found with name containing '{device_name}'\")\n\tdef list_device_info() -> List[dict]:\n", "    \"\"\"Get a list of device info dictionaries.\"\"\"\n\t    return [get_pa().get_device_info_by_index(i) for i in range(get_pa().get_device_count())]  # type: ignore\n\tdef list_host_api_info() -> List[dict]:\n\t    \"\"\"Get a list of host API info dictionaries.\"\"\"\n\t    return [get_pa().get_host_api_info_by_index(i) for i in range(get_pa().get_host_api_count())]  # type: ignore\n\tdef get_volume_range(audio_data: ArrayLike) -> float:\n\t    \"\"\"Get the range of the audio data.\"\"\"\n\t    return np.max(audio_data) - np.min(audio_data)\n\t_pa_local = threading.local()\n\tdef get_pa() -> pyaudio.PyAudio:\n", "    \"\"\"Get a thread-local instance of pyaudio.PyAudio.\"\"\"\n\t    if not hasattr(_pa_local, \"pa\"):\n\t        _pa_local.pa = pyaudio.PyAudio()\n\t        atexit.register(_pa_local.pa.terminate)\n\t    return _pa_local.pa\n\t@contextmanager\n\tdef open_stream(\n\t    *args,\n\t    **kwargs,\n\t):\n", "    \"\"\"Open a stream.\"\"\"\n\t    stream = get_pa().open(*args, **kwargs)\n\t    yield stream\n\t    stream.stop_stream()\n\tdef _on_sigint(*_):\n\t    \"\"\"Handle SIGINT.\"\"\"\n\t    if hasattr(\"_pa_local\", \"pa\"):\n\t        _pa_local.pa.terminate()\n\tsignal.signal(signal.SIGINT, _on_sigint)\n"]}
{"filename": "talkbot/utilities/message.py", "chunked_list": ["\"\"\"Message types.\"\"\"\n\timport time\n\tfrom typing import Any, Literal, TypedDict, TypeGuard\n\tfrom .constants import ComponentState\n\tclass UserMessage(TypedDict):\n\t    \"\"\"A message from the user.\"\"\"\n\t    role: Literal[\"user\"]\n\t    content: str\n\tclass AssistantMessage(TypedDict):\n\t    \"\"\"A message from the assistant.\"\"\"\n", "    role: Literal[\"assistant\"]\n\t    content: str\n\tclass SystemMessage(TypedDict):\n\t    \"\"\"A message from the system.\"\"\"\n\t    role: Literal[\"system\"]\n\t    content: str\n\tclass StateMessage(TypedDict):\n\t    \"\"\"Message for local status.\"\"\"\n\t    role: Literal[\"state\"]\n\t    component: str\n", "    state: int\n\tMessage = UserMessage | AssistantMessage | SystemMessage | StateMessage\n\t\"\"\"A message from the user, assistant, or system.\"\"\"\n\tTextMessage = UserMessage | AssistantMessage | SystemMessage\n\t\"\"\"A message from the user, assistant, or system that contains text.\"\"\"\n\tdef is_message(message: Any) -> TypeGuard[Message]:\n\t    \"\"\"Check if a message is a message.\"\"\"\n\t    return isinstance(message, dict) and \"role\" in message\n\tdef is_text_message(message: Any) -> TypeGuard[TextMessage]:\n\t    \"\"\"Check if a message is a text message.\"\"\"\n", "    return is_message(message) and message[\"role\"] in (\"user\", \"assistant\", \"system\")\n\tdef is_user_message(message: Any) -> TypeGuard[UserMessage]:\n\t    \"\"\"Check if a message is a user message.\"\"\"\n\t    return is_text_message(message) and message[\"role\"] == \"user\"\n\tdef is_assistant_message(message: Any) -> TypeGuard[AssistantMessage]:\n\t    \"\"\"Check if a message is an assistant message.\"\"\"\n\t    return is_text_message(message) and message[\"role\"] == \"assistant\"\n\tdef is_state_message(message: Any) -> TypeGuard[StateMessage]:\n\t    \"\"\"Check if a message is a state message.\"\"\"\n\t    return is_message(message) and message[\"role\"] == \"state\"\n", "def update_busy_time(message: Any, component: str, current_value: float) -> float:\n\t    \"\"\"Get the busy time of a message.\"\"\"\n\t    if not is_message(message):\n\t        return current_value\n\t    if message[\"role\"] != \"state\":\n\t        return current_value\n\t    if message[\"component\"] != component:\n\t        return current_value\n\t    return time.time() if ComponentState(message[\"state\"]) == ComponentState.BUSY else 0\n\tdef is_busy(busy_time: float, timeout: float) -> bool:\n", "    \"\"\"Check if a component is busy.\"\"\"\n\t    return time.time() - busy_time < timeout\n"]}
{"filename": "talkbot/utilities/__init__.py", "chunked_list": ["\"\"\"Utiliy functions for the talkbot package.\"\"\"\n"]}
{"filename": "talkbot/utilities/constants.py", "chunked_list": ["\"\"\"Constants for the TalkBot project.\"\"\"\n\tfrom enum import Enum\n\tclass ComponentState(Enum):\n\t    \"\"\"Enum for the state of a component.\"\"\"\n\t    READY = 0\n\t    \"\"\"The component is ready to process messages.\"\"\"\n\t    BUSY = 1\n\t    \"\"\"The component is busy processing messages.\"\"\"\n"]}
{"filename": "talkbot/utilities/socket.py", "chunked_list": ["\"\"\"Provide utilities for working with ZMQ sockets.\"\"\"\n\timport asyncio\n\timport atexit\n\timport signal\n\timport sys\n\timport threading\n\tfrom abc import ABC\n\tfrom contextlib import contextmanager\n\tfrom typing import Any, Awaitable, Iterator, TypeVar\n\timport zmq\n", "import zmq.asyncio\n\tfrom .config import Config\n\tfrom .constants import ComponentState\n\tfrom .message import StateMessage\n\tif sys.platform == \"win32\":\n\t    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n\t_local = threading.local()\n\tT = TypeVar(\"T\")\n\tJsonValue = list[Any] | str | int | float | dict[Any, Any]\n\tclass Socket(ABC, zmq.asyncio.Socket):\n", "    \"\"\"A socket that can send and receive JSON messages.\"\"\"\n\t    def send_json(self, obj: Any, flags: int | None = None, **kwargs: Any) -> Awaitable[None]:  # type: ignore\n\t        \"\"\"Send a JSON-serializable object as a message.\"\"\"\n\t        raise NotImplementedError()\n\t    def recv_json(self, flags: int | None = None, **kwargs: Any) -> Awaitable[JsonValue]:  # type: ignore\n\t        \"\"\"Receive a JSON-serializable object as a message.\"\"\"\n\t        raise NotImplementedError()\n\tdef get_context() -> zmq.asyncio.Context:\n\t    \"\"\"Return a context for creating sockets.\"\"\"\n\t    if not hasattr(_local, \"context\"):\n", "        _local.context = zmq.asyncio.Context()\n\t        atexit.register(_local.context.term)\n\t    return _local.context\n\tdef _on_sigint(*_):\n\t    \"\"\"Handle SIGINT.\"\"\"\n\t    if hasattr(_local, \"context\"):\n\t        _local.context.term()\n\tsignal.signal(signal.SIGINT, _on_sigint)\n\t@contextmanager\n\tdef get_write_socket(config: Config) -> Iterator[Socket]:\n", "    \"\"\"Return a socket that sends messages to the message stream.\"\"\"\n\t    context = get_context()\n\t    with context.socket(zmq.PUB) as socket:\n\t        socket.connect(config.get(\"message_stream.write\", \"\"))\n\t        yield socket  # type: ignore\n\t@contextmanager\n\tdef get_read_socket(config: Config, timeout: float | None = None) -> Iterator[Socket]:\n\t    \"\"\"Return a socket that receives messages from the message stream.\"\"\"\n\t    context = get_context()\n\t    with context.socket(zmq.SUB) as socket:\n", "        socket.connect(config.get(\"message_stream.read\", \"\"))\n\t        socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\t        if timeout is not None:\n\t            socket.setsockopt(zmq.RCVTIMEO, int(timeout * 1000))\n\t        yield socket  # type: ignore\n\t@contextmanager\n\tdef get_sockets(\n\t    config: Config,\n\t    timeout: float | None = None,\n\t) -> Iterator[tuple[Socket, Socket]]:\n", "    \"\"\"Return a tuple of (write_socket, read_socket).\"\"\"\n\t    with get_write_socket(config) as write_socket, get_read_socket(config, timeout) as read_socket:\n\t        yield write_socket, read_socket\n\tasync def send_state(write_socket: Socket, component: str, state: ComponentState):\n\t    \"\"\"Send a state message to the message stream.\"\"\"\n\t    await write_socket.send_json(\n\t        StateMessage(\n\t            role=\"state\",\n\t            component=component,\n\t            state=state.value,\n", "        )\n\t    )\n"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/utilities/__init__.py", "chunked_list": []}
{"filename": "tests/utilities/test_config.py", "chunked_list": ["\"\"\"Tests for the Config class.\"\"\"\n\timport unittest\n\tfrom talkbot.utilities.config import Config\n\tclass TestConfig(unittest.TestCase):\n\t    \"\"\"Tests for the Config class.\"\"\"\n\t    def test_get(self) -> None:\n\t        \"\"\"Test the get method.\"\"\"\n\t        config = Config(\"tests/config/test1.yml\", \"tests/config/test2.yml\")\n\t        self.assertEqual(config.get(\"database.host\"), \"example2.com\")\n\t        self.assertEqual(config.get(\"database.port\"), 1234)\n", "        self.assertEqual(config.get(\"database.user\"), \"user2\")\n\t        self.assertEqual(config.get(\"database.password\"), \"pass1\")\n\t        self.assertEqual(config.get(\"extra.key\"), \"value\")\n\t        self.assertIsNone(config.get(\"extra.unknown\"))\n\t        self.assertEqual(config.get(\"log.version\"), 1)\n\t        self.assertIsNone(config.get(\"log.unknown\"))\n\t    def test_get_with_default(self) -> None:\n\t        \"\"\"Test the get method with a default value.\"\"\"\n\t        config = Config(\"config/test1.yml\", \"config/test2.yml\")\n\t        self.assertEqual(config.get(\"extra.unknown\", \"default_value\"), \"default_value\")\n"]}
