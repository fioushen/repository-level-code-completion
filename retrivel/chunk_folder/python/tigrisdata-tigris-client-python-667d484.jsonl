{"filename": "scripts/proto.py", "chunked_list": ["import os\n\timport sys\n\tfrom shutil import rmtree\n\tfrom subprocess import run as cmd_run\n\t\"\"\"\n\tDo not execute scripts/ directly. Only use 'poetry' tool to run them.\n\tExamples:\n\t$> poetry run make <command>\n\t\"\"\"\n\tPROJ_ROOT = os.getcwd()\n", "proj_toml = os.path.join(PROJ_ROOT, \"pyproject.toml\")\n\tif not os.path.isfile(proj_toml):\n\t    raise Exception(\n\t        \"This script should be executed from project root only using poetry.\"\n\t    )\n\tPROTO_ROOT = os.path.join(PROJ_ROOT, \"api/proto\")\n\tTIGRIS_PROTO_DIR = os.path.join(PROTO_ROOT, \"server/v1\")\n\tGENERATED_PROTO_DIR = os.path.join(PROJ_ROOT, \"api/generated\")\n\tdef generate():\n\t    if not os.path.exists(GENERATED_PROTO_DIR):\n", "        os.makedirs(GENERATED_PROTO_DIR)\n\t    proto_sources = []\n\t    for pd in [\"google/api\", \"openapiv3\"]:\n\t        pd_path = os.path.join(PROTO_ROOT, pd)\n\t        for pd_file in os.listdir(pd_path):\n\t            if pd_file.endswith(\".proto\"):\n\t                proto_sources.append(os.path.join(pd_path, pd_file))\n\t    for pf in [\"api.proto\", \"search.proto\", \"auth.proto\", \"observability.proto\"]:\n\t        pf_path = os.path.join(TIGRIS_PROTO_DIR, pf)\n\t        proto_sources.append(pf_path)\n", "    # compile proto\n\t    for proto_file in proto_sources:\n\t        cmd_run(\n\t            f\"python -m grpc_tools.protoc --proto_path={PROTO_ROOT}\"\n\t            f\" --python_out={GENERATED_PROTO_DIR}\"\n\t            f\" --grpc_python_out={GENERATED_PROTO_DIR} {proto_file}\",\n\t            shell=True,\n\t            check=True,\n\t        )\n\t    # fix imports in generated files\n", "    fixable_imports = {\n\t        \"from google.api\": \"from {rp}google.api\",\n\t        \"from openapiv3\": \"from {rp}openapiv3\",\n\t        \"from server.v1\": \"from {rp}server.v1\",\n\t    }\n\t    replace_targets = []\n\t    for subdir, _dirs, files in os.walk(GENERATED_PROTO_DIR):\n\t        for f in files:\n\t            if \"pb2\" in f and (f.endswith(\".py\") or f.endswith(\".pyi\")):\n\t                fp = os.path.join(subdir, f)\n", "                with open(fp, \"r\") as fopen:\n\t                    fdata = fopen.read()\n\t                    for find, replace in fixable_imports.items():\n\t                        replace_with = \"..\" if \"/openapiv3/\" in fp else \"...\"\n\t                        fdata = fdata.replace(find, replace.format(rp=replace_with))\n\t                    replace_targets.append((fp, fdata))\n\t    for fp, fdata in replace_targets:\n\t        with open(fp, \"w\") as f:\n\t            f.write(fdata)\n\t    print(f\"SUCCESS! Compiled proto stubs available in:\\n{GENERATED_PROTO_DIR}\")\n", "def clean():\n\t    if os.path.exists(GENERATED_PROTO_DIR):\n\t        rmtree(GENERATED_PROTO_DIR)\n\tdef main():\n\t    valid_args = {\n\t        \"generate\": \"generate api from proto\",\n\t        \"clean\": \"clean generated api\",\n\t    }\n\t    usage = [\n\t        'Not enough arguments to \"make\".',\n", "        \"\\nUSAGE:\",\n\t        \"poetry run make <command>\",\n\t        \"\\nCOMMANDS:\",\n\t    ]\n\t    usage.extend(map(lambda k: \"{:<16} {:<25}\".format(k, valid_args[k]), valid_args))\n\t    usage_str = \"\\n\".join(usage)\n\t    if not len(sys.argv) == 2 or sys.argv[1] not in valid_args:\n\t        print(usage_str)\n\t        exit(1)\n\t    arg = sys.argv[1]\n", "    if arg == \"generate\":\n\t        generate()\n\t    elif arg == \"clean\":\n\t        clean()\n\t    else:\n\t        print(usage_str)\n"]}
{"filename": "scripts/__init__.py", "chunked_list": []}
{"filename": "tests/test_types_search.py", "chunked_list": ["from datetime import datetime\n\tfrom unittest import TestCase\n\tfrom google.protobuf.timestamp_pb2 import Timestamp as ProtoTimestamp\n\tfrom api.generated.server.v1.api_pb2 import FacetCount as ProtoFacetCount\n\tfrom api.generated.server.v1.api_pb2 import FacetStats as ProtoFacetStats\n\tfrom api.generated.server.v1.api_pb2 import GroupedSearchHits as ProtoGroupedHits\n\tfrom api.generated.server.v1.api_pb2 import Match as ProtoMatch\n\tfrom api.generated.server.v1.api_pb2 import MatchField as ProtoMatchField\n\tfrom api.generated.server.v1.api_pb2 import Page as ProtoPage\n\tfrom api.generated.server.v1.api_pb2 import SearchFacet as ProtoSearchFacet\n", "from api.generated.server.v1.api_pb2 import SearchHit as ProtoSearchHit\n\tfrom api.generated.server.v1.api_pb2 import SearchHitMeta as ProtoSearchHitMeta\n\tfrom api.generated.server.v1.api_pb2 import SearchMetadata as ProtoSearchMeta\n\tfrom api.generated.server.v1.observability_pb2 import Error as ProtoError\n\tfrom api.generated.server.v1.search_pb2 import DocStatus as ProtoDocStatus\n\tfrom api.generated.server.v1.search_pb2 import SearchIndexRequest\n\tfrom api.generated.server.v1.search_pb2 import (\n\t    SearchIndexResponse as ProtoSearchIndexResponse,\n\t)\n\tfrom tigrisdb.errors import TigrisException\n", "from tigrisdb.types import sort\n\tfrom tigrisdb.types.filters import LT, And, Eq\n\tfrom tigrisdb.types.search import (\n\t    DocMeta,\n\t    DocStatus,\n\t    FacetCount,\n\t    Facets,\n\t    FacetSize,\n\t    FacetStats,\n\t    GroupedHits,\n", "    IndexedDoc,\n\t    Meta,\n\t    Page,\n\t    Query,\n\t    Result,\n\t    TextMatchInfo,\n\t    VectorField,\n\t)\n\tfrom tigrisdb.utils import marshal\n\tclass SearchQueryTest(TestCase):\n", "    def test_default_fields(self):\n\t        query, proto_req = Query(), SearchIndexRequest()\n\t        query.__build__(proto_req)\n\t        self.assertEqual(proto_req.q, \"\")\n\t        self.assertEqual(proto_req.search_fields, [])\n\t        self.assertEqual(proto_req.vector, bytearray())\n\t        self.assertEqual(proto_req.filter, bytearray())\n\t        self.assertEqual(proto_req.facet, bytearray())\n\t        self.assertEqual(proto_req.sort, bytearray())\n\t        self.assertEqual(proto_req.group_by, bytearray())\n", "        self.assertEqual(proto_req.include_fields, [])\n\t        self.assertEqual(proto_req.exclude_fields, [])\n\t        self.assertEqual(proto_req.page_size, 20)\n\t    def test_with_q(self):\n\t        query, proto_req = Query(q=\"hello world\"), SearchIndexRequest()\n\t        query.__build__(proto_req)\n\t        self.assertEqual(\"hello world\", proto_req.q)\n\t    def test_with_search_fields(self):\n\t        query, proto_req = (\n\t            Query(search_fields=[\"name.first\", \"balance\"]),\n", "            SearchIndexRequest(),\n\t        )\n\t        query.__build__(proto_req)\n\t        self.assertEqual([\"name.first\", \"balance\"], proto_req.search_fields)\n\t    def test_with_vector_query(self):\n\t        query, proto_req = (\n\t            Query(vector_query=VectorField(\"embedding\", [1.1, 2.456, 34.88])),\n\t            SearchIndexRequest(),\n\t        )\n\t        query.__build__(proto_req)\n", "        self.assertEqual(\n\t            '{\"embedding\": [1.1, 2.456, 34.88]}'.encode(), proto_req.vector\n\t        )\n\t    def test_with_filter_by(self):\n\t        query, proto_req = (\n\t            Query(\n\t                filter_by=And(\n\t                    Eq(\"name\", \"Alex\"),\n\t                    LT(\"dob\", datetime.fromisoformat(\"2023-05-05T10:00:00+00:00\")),\n\t                )\n", "            ),\n\t            SearchIndexRequest(),\n\t        )\n\t        query.__build__(proto_req)\n\t        self.assertEqual(\n\t            '{\"$and\": ['\n\t            '{\"name\": \"Alex\"}, '\n\t            '{\"dob\": {\"$lt\": \"2023-05-05T10:00:00+00:00\"}}'\n\t            \"]}\".encode(),\n\t            proto_req.filter,\n", "        )\n\t    def test_with_facet_by(self):\n\t        query, proto_req = Query(facet_by=\"field_1\"), SearchIndexRequest()\n\t        query.__build__(proto_req)\n\t        self.assertEqual(\n\t            '{\"field_1\": {\"size\": 10, \"type\": \"value\"}}'.encode(), proto_req.facet\n\t        )\n\t        query, proto_req = (\n\t            Query(facet_by=[\"f1\", FacetSize(\"f2\", 25), FacetSize(\"f3\")]),\n\t            SearchIndexRequest(),\n", "        )\n\t        query.__build__(proto_req)\n\t        self.assertEqual(\n\t            '{\"f1\": {\"size\": 10, \"type\": \"value\"}, \"f2\": {\"size\": 25, \"type\": \"value\"},'\n\t            ' \"f3\": {\"size\": 10, \"type\": \"value\"}}'.encode(),\n\t            proto_req.facet,\n\t        )\n\t    def test_with_sort_by(self):\n\t        query, proto_req = Query(sort_by=sort.Ascending(\"f1\")), SearchIndexRequest()\n\t        query.__build__(proto_req)\n", "        self.assertEqual('[{\"f1\": \"$asc\"}]'.encode(), proto_req.sort)\n\t        query, proto_req = (\n\t            Query(\n\t                sort_by=[\n\t                    sort.Descending(\"f2\"),\n\t                    sort.Ascending(\"f1\"),\n\t                    sort.Ascending(\"f3\"),\n\t                ]\n\t            ),\n\t            SearchIndexRequest(),\n", "        )\n\t        query.__build__(proto_req)\n\t        self.assertEqual(\n\t            '[{\"f2\": \"$desc\"}, {\"f1\": \"$asc\"}, {\"f3\": \"$asc\"}]'.encode(), proto_req.sort\n\t        )\n\t    def test_with_group_by(self):\n\t        query, proto_req = Query(group_by=\"f1\"), SearchIndexRequest()\n\t        query.__build__(proto_req)\n\t        self.assertEqual('[\"f1\"]'.encode(), proto_req.group_by)\n\t        query, proto_req = Query(group_by=[\"f1\", \"f2\", \"f3\"]), SearchIndexRequest()\n", "        query.__build__(proto_req)\n\t        self.assertEqual('[\"f1\", \"f2\", \"f3\"]'.encode(), proto_req.group_by)\n\t    def test_with_include_fields(self):\n\t        query, proto_req = (\n\t            Query(include_fields=[\"f1\", \"f2\", \"f3\"]),\n\t            SearchIndexRequest(),\n\t        )\n\t        query.__build__(proto_req)\n\t        self.assertEqual([\"f1\", \"f2\", \"f3\"], proto_req.include_fields)\n\t    def test_with_exclude_fields(self):\n", "        query, proto_req = (\n\t            Query(exclude_fields=[\"f1\", \"f2\", \"f3\"]),\n\t            SearchIndexRequest(),\n\t        )\n\t        query.__build__(proto_req)\n\t        self.assertEqual([\"f1\", \"f2\", \"f3\"], proto_req.exclude_fields)\n\t    def test_with_page_size(self):\n\t        query, proto_req = Query(hits_per_page=25), SearchIndexRequest()\n\t        query.__build__(proto_req)\n\t        self.assertEqual(25, proto_req.page_size)\n", "class SearchResultTestCase(TestCase):\n\t    def test_build_doc_status(self):\n\t        cases = [\n\t            (\n\t                \"with empty msg\",\n\t                ProtoDocStatus(id=\"1\", error=ProtoError(message=\"failure\")),\n\t                DocStatus(id=\"1\", error=TigrisException(\"failure\")),\n\t            ),\n\t            (\"with empty msg\", ProtoDocStatus(), DocStatus(id=None, error=None)),\n\t            (\"with None\", None, DocStatus(id=None, error=None)),\n", "        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = DocStatus(_p=proto_msg)\n\t                self.assertEqual(expected.id, actual.id)\n\t                if expected.error:\n\t                    self.assertIsNotNone(actual.error)\n\t                    self.assertEqual(proto_msg.error.message, actual.error.msg)\n\t    def test_build_text_match_info(self):\n\t        cases = [\n", "            (\n\t                \"with complete msg\",\n\t                ProtoMatch(\n\t                    score=\"25\",\n\t                    vector_distance=45.1,\n\t                    fields=[ProtoMatchField(name=\"f1\")],\n\t                ),\n\t                TextMatchInfo(score=\"25\", vector_distance=45.1, fields=[\"f1\"]),\n\t            ),\n\t            (\n", "                \"with empty msg\",\n\t                ProtoMatch(),\n\t                TextMatchInfo(score=None, vector_distance=None, fields=[]),\n\t            ),\n\t            (\n\t                \"with None\",\n\t                None,\n\t                TextMatchInfo(score=None, vector_distance=None, fields=[]),\n\t            ),\n\t        ]\n", "        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = TextMatchInfo(_p=proto_msg)\n\t                self.assertEqual(expected.score, actual.score)\n\t                self.assertEqual(expected.vector_distance, actual.vector_distance)\n\t                self.assertEqual(expected.fields, actual.fields)\n\t    def test_build_doc_meta(self):\n\t        ts, proto_ts = (\n\t            datetime.fromisoformat(\"2023-05-05T10:00:00+00:00\"),\n\t            ProtoTimestamp(),\n", "        )\n\t        proto_ts.FromDatetime(ts)\n\t        cases = [\n\t            (\n\t                \"with complete msg\",\n\t                ProtoSearchHitMeta(created_at=proto_ts, updated_at=proto_ts),\n\t                DocMeta(created_at=ts, updated_at=ts, text_match=TextMatchInfo()),\n\t            ),\n\t            (\n\t                \"with empty msg\",\n", "                ProtoSearchHitMeta(),\n\t                DocMeta(created_at=None, updated_at=None, text_match=TextMatchInfo()),\n\t            ),\n\t            (\n\t                \"with None\",\n\t                None,\n\t                DocMeta(created_at=None, updated_at=None, text_match=TextMatchInfo()),\n\t            ),\n\t        ]\n\t        for tc, proto_msg, expected in cases:\n", "            with self.subTest(tc):\n\t                actual = DocMeta(_p=proto_msg)\n\t                self.assertEqual(expected.created_at, actual.created_at)\n\t                self.assertEqual(expected.updated_at, actual.updated_at)\n\t                self.assertEqual(expected.text_match, actual.text_match)\n\t    def test_build_indexed_doc(self):\n\t        cases = [\n\t            (\n\t                \"with complete msg\",\n\t                ProtoSearchHit(data=marshal({\"f\": \"v\"}), metadata=ProtoSearchHitMeta()),\n", "                IndexedDoc(doc={\"f\": \"v\"}, meta=DocMeta()),\n\t            ),\n\t            (\"with empty msg\", ProtoSearchHit(), IndexedDoc(doc=None, meta=DocMeta())),\n\t            (\"with None\", None, IndexedDoc(doc=None, meta=DocMeta())),\n\t        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = IndexedDoc(_p=proto_msg)\n\t                self.assertEqual(actual.doc, expected.doc)\n\t                self.assertEqual(actual.meta, expected.meta)\n", "    def test_build_grouped_hits(self):\n\t        cases = [\n\t            (\n\t                \"with complete msg\",\n\t                ProtoGroupedHits(\n\t                    group_keys=[\"f1\"], hits=[ProtoSearchHit(data=marshal({\"f\": \"v\"}))]\n\t                ),\n\t                GroupedHits(keys=[\"f1\"], hits=[IndexedDoc(doc={\"f\": \"v\"})]),\n\t            ),\n\t            (\"with empty msg\", ProtoGroupedHits(), GroupedHits(keys=[], hits=[])),\n", "            (\"with None\", None, GroupedHits(keys=[], hits=[])),\n\t        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = GroupedHits(_p=proto_msg)\n\t                self.assertEqual(actual.keys, expected.keys)\n\t                self.assertEqual(actual.hits, expected.hits)\n\t    def test_build_facet_count(self):\n\t        cases = [\n\t            (\n", "                \"with complete msg\",\n\t                ProtoFacetCount(value=\"v1\", count=5),\n\t                FacetCount(count=5, value=\"v1\"),\n\t            ),\n\t            (\"with empty msg\", ProtoFacetCount(), FacetCount(count=0, value=\"\")),\n\t            (\"with None\", None, FacetCount(count=None, value=None)),\n\t        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = FacetCount(_p=proto_msg)\n", "                self.assertEqual(expected.count, actual.count)\n\t                self.assertEqual(expected.value, actual.value)\n\t    def test_build_facet_stats(self):\n\t        cases = [\n\t            (\n\t                \"with complete msg\",\n\t                ProtoFacetStats(count=12, sum=8.5, avg=3.14, max=12, min=-1.9),\n\t                FacetStats(count=12, sum=8.5, avg=3.14, max=12, min=-1.9),\n\t            ),\n\t            (\n", "                \"with empty msg\",\n\t                ProtoFacetStats(),\n\t                FacetStats(count=0, sum=None, avg=None, max=None, min=None),\n\t            ),\n\t            (\n\t                \"with None\",\n\t                None,\n\t                FacetStats(count=0, sum=None, avg=None, max=None, min=None),\n\t            ),\n\t            (\n", "                \"with missing count and avg\",\n\t                ProtoFacetStats(sum=8.5, max=12, min=-1.9),\n\t                FacetStats(count=0, sum=8.5, avg=None, max=12, min=-1.9),\n\t            ),\n\t            (\n\t                \"with zero values\",\n\t                ProtoFacetStats(count=0, sum=0, avg=0, max=0, min=-0),\n\t                FacetStats(count=0, sum=0, avg=0, max=0, min=0),\n\t            ),\n\t        ]\n", "        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = FacetStats(_p=proto_msg)\n\t                self.assertEqual(expected.count, actual.count)\n\t                self.assertEqual(expected.sum, actual.sum)\n\t                self.assertEqual(expected.avg, actual.avg)\n\t                self.assertEqual(expected.max, actual.max)\n\t                self.assertEqual(expected.min, actual.min)\n\t    def test_build_facets(self):\n\t        cases = [\n", "            (\n\t                \"with complete msg\",\n\t                ProtoSearchFacet(\n\t                    counts=[ProtoFacetCount(value=\"v1\", count=2)],\n\t                    stats=ProtoFacetStats(),\n\t                ),\n\t                Facets(counts=[FacetCount(\"v1\", 2)], stats=FacetStats()),\n\t            ),\n\t            (\n\t                \"with empty msg\",\n", "                ProtoSearchFacet(),\n\t                Facets(counts=[], stats=FacetStats()),\n\t            ),\n\t            (\"with None\", None, Facets(counts=[], stats=FacetStats())),\n\t        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = Facets(_p=proto_msg)\n\t                self.assertEqual(expected.counts, actual.counts)\n\t                self.assertEqual(expected.stats, actual.stats)\n", "    def test_build_page(self):\n\t        cases = [\n\t            (\n\t                \"with complete msg\",\n\t                ProtoPage(current=3, size=20),\n\t                Page(current=3, size=20),\n\t            ),\n\t            (\"with empty msg\", ProtoPage(), Page(current=1, size=0)),\n\t            (\"with None\", None, Page(current=1, size=20)),\n\t            (\"with partial msg\", ProtoPage(size=10), Page(current=1, size=10)),\n", "        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = Page(_p=proto_msg)\n\t                self.assertEqual(expected.current, actual.current)\n\t                self.assertEqual(expected.size, actual.size)\n\t    def test_build_meta(self):\n\t        cases = [\n\t            (\n\t                \"with complete msg\",\n", "                ProtoSearchMeta(found=25, total_pages=3, page=ProtoPage()),\n\t                Meta(found=25, total_pages=3, page=Page(_p=ProtoPage())),\n\t            ),\n\t            (\"with None\", None, Meta(found=0, total_pages=1, page=Page())),\n\t            (\"with empty msg\", ProtoSearchMeta(), Meta(found=0, total_pages=1)),\n\t        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n\t                actual = Meta(_p=proto_msg)\n\t                # if proto_msg and proto_msg.HasField(\"page\"):\n", "                self.assertEqual(expected.page, actual.page)\n\t                self.assertEqual(expected.total_pages, actual.total_pages)\n\t                self.assertEqual(expected.found, actual.found)\n\t    def test_build_result(self):\n\t        cases = [\n\t            (\n\t                \"with complete msg\",\n\t                ProtoSearchIndexResponse(\n\t                    hits=[ProtoSearchHit(data=marshal({\"f\": \"v\"}))],\n\t                    facets={\"f1\": ProtoSearchFacet()},\n", "                    meta=ProtoSearchMeta(found=25, total_pages=3),\n\t                    group=[\n\t                        ProtoGroupedHits(\n\t                            group_keys=[\"f1\"],\n\t                            hits=[ProtoSearchHit(data=marshal({\"f\": \"v\"}))],\n\t                        )\n\t                    ],\n\t                ),\n\t                Result(\n\t                    hits=[IndexedDoc(doc={\"f\": \"v\"})],\n", "                    facets={\"f1\": Facets()},\n\t                    meta=Meta(found=25, total_pages=3),\n\t                    grouped_hits=[\n\t                        GroupedHits(keys=[\"f1\"], hits=[IndexedDoc(doc={\"f\": \"v\"})])\n\t                    ],\n\t                ),\n\t            ),\n\t            (\n\t                \"with empty msg\",\n\t                ProtoSearchIndexResponse(),\n", "                Result(hits=[], facets={}, meta=Meta(), grouped_hits=[]),\n\t            ),\n\t            (\n\t                \"with None\",\n\t                None,\n\t                Result(hits=[], facets={}, meta=Meta(), grouped_hits=[]),\n\t            ),\n\t        ]\n\t        for tc, proto_msg, expected in cases:\n\t            with self.subTest(tc):\n", "                actual = Result(_p=proto_msg)\n\t                self.assertEqual(expected.hits, actual.hits)\n\t                self.assertEqual(expected.meta, actual.meta)\n\t                self.assertEqual(expected.facets, actual.facets)\n\t                self.assertEqual(expected.grouped_hits, actual.grouped_hits)\n"]}
{"filename": "tests/test_vector_store.py", "chunked_list": ["from unittest import TestCase\n\tfrom unittest.mock import Mock, call\n\tfrom tests import NotFoundRpcError\n\tfrom tigrisdb.errors import TigrisServerError\n\tfrom tigrisdb.search import Search\n\tfrom tigrisdb.search_index import SearchIndex\n\tfrom tigrisdb.types.search import (\n\t    DocMeta,\n\t    DocStatus,\n\t    IndexedDoc,\n", "    Query,\n\t    Result,\n\t    TextMatchInfo,\n\t    VectorField,\n\t)\n\tfrom tigrisdb.types.vector import Document\n\tfrom tigrisdb.vector_store import VectorStore\n\tdoc: Document = {\n\t    \"text\": \"Hello world vector embed\",\n\t    \"embeddings\": [1.2, 2.3, 4.5],\n", "    \"metadata\": {\"category\": \"shoes\"},\n\t}\n\tclass VectorStoreTest(TestCase):\n\t    def setUp(self) -> None:\n\t        self.mock_index = Mock(spec=SearchIndex)\n\t        self.mock_client = Mock(spec=Search)\n\t        self.mock_client.get_index.return_value = self.mock_index\n\t        self.store = VectorStore(self.mock_client, \"my_vectors\")\n\t    def test_add_documents_when_index_not_found(self):\n\t        # throw error on first call and succeed on second\n", "        self.mock_index.create_many.side_effect = [\n\t            TigrisServerError(\"\", NotFoundRpcError(\"search index not found\")),\n\t            [DocStatus(id=\"1\")],\n\t        ]\n\t        resp = self.store.add_documents([doc])\n\t        self.assertEqual([DocStatus(id=\"1\")], resp)\n\t        self.assertEqual(self.mock_index.create_many.call_count, 2)\n\t        self.mock_index.create_many.assert_has_calls([call([doc]), call([doc])])\n\t        # create_or_update_index gets called once\n\t        expected_schema = {\n", "            \"title\": self.store.name,\n\t            \"additionalProperties\": False,\n\t            \"type\": \"object\",\n\t            \"properties\": {\n\t                \"id\": {\"type\": \"string\"},\n\t                \"text\": {\"type\": \"string\"},\n\t                \"metadata\": {\"type\": \"object\"},\n\t                \"embeddings\": {\"type\": \"array\", \"format\": \"vector\", \"dimensions\": 3},\n\t            },\n\t        }\n", "        self.mock_client.create_or_update_index.assert_called_once_with(\n\t            name=self.store.name, schema=expected_schema\n\t        )\n\t    def test_add_documents_when_index_exists(self):\n\t        self.mock_index.create_many.return_value = [DocStatus(id=\"1\")]\n\t        resp = self.store.add_documents([doc])\n\t        self.assertEqual([DocStatus(id=\"1\")], resp)\n\t        # no calls to create_or_update_index\n\t        self.mock_client.assert_not_called()\n\t    def test_add_documents_when_project_not_found(self):\n", "        self.mock_index.create_many.side_effect = [\n\t            TigrisServerError(\"\", NotFoundRpcError(\"project not found\")),\n\t            [DocStatus(id=\"1\")],\n\t        ]\n\t        with self.assertRaisesRegex(TigrisServerError, \"project not found\"):\n\t            self.store.add_documents([doc])\n\t        self.mock_index.create_many.assert_called_once_with([doc])\n\t    def test_delete_documents(self):\n\t        self.store.delete_documents([\"id\"])\n\t        self.mock_index.delete_many.assert_called_once_with([\"id\"])\n", "    def test_get_documents(self):\n\t        self.store.get_documents([\"id\"])\n\t        self.mock_index.get_many.assert_called_once_with([\"id\"])\n\t    def test_similarity_search(self):\n\t        self.mock_index.search.return_value = Result(\n\t            hits=[\n\t                IndexedDoc(\n\t                    doc=doc,\n\t                    meta=DocMeta(text_match=TextMatchInfo(vector_distance=0.1234)),\n\t                )\n", "            ]\n\t        )\n\t        resp = self.store.similarity_search([1, 1, 1], 12)\n\t        self.assertEqual(1, len(resp))\n\t        self.assertEqual(doc, resp[0].doc)\n\t        self.assertEqual(0.1234, resp[0].score)\n\t        self.mock_index.search.assert_called_once_with(\n\t            query=Query(\n\t                vector_query=VectorField(field=\"embeddings\", vector=[1, 1, 1]),\n\t                hits_per_page=12,\n", "            )\n\t        )\n"]}
{"filename": "tests/test_search.py", "chunked_list": ["from unittest import TestCase\n\tfrom unittest.mock import patch\n\tfrom tigrisdb.search import Search\n\tfrom tigrisdb.types import ClientConfig\n\t@patch(\"api.generated.server.v1.search_pb2_grpc.SearchStub\")\n\tclass SearchTest(TestCase):\n\t    def setUp(self) -> None:\n\t        self.client_config = ClientConfig(server_url=\"localhost:5000\", project=\"db1\")\n\t    def test_get_index(self, grpc_search):\n\t        mock_grpc = grpc_search()\n", "        search = Search(mock_grpc, self.client_config)\n\t        search_index = search.get_index(\"test-index\")\n\t        self.assertEqual(\"test-index\", search_index.name)\n\t        self.assertEqual(self.client_config.project, search_index.project)\n"]}
{"filename": "tests/test_types_filters_logical.py", "chunked_list": ["from unittest import TestCase\n\tfrom tigrisdb.types.filters import GT, GTE, LTE, And, Contains, Eq, Not, Or, Regex\n\tclass LogicalFiltersTest(TestCase):\n\t    def test_or(self):\n\t        f = Or(Eq(\"f1\", True), LTE(\"f2\", 25), Contains(\"f3\", \"v1\"))\n\t        self.assertEqual(\n\t            {\"$or\": [{\"f1\": True}, {\"f2\": {\"$lte\": 25}}, {\"f3\": {\"$contains\": \"v1\"}}]},\n\t            f.query(),\n\t        )\n\t    def test_and(self):\n", "        f = And(Eq(\"f1\", True), LTE(\"f2\", 25), Contains(\"f3\", \"v1\"))\n\t        self.assertEqual(\n\t            {\"$and\": [{\"f1\": True}, {\"f2\": {\"$lte\": 25}}, {\"f3\": {\"$contains\": \"v1\"}}]},\n\t            f.query(),\n\t        )\n\t    def test_empty(self):\n\t        self.assertEqual({}, And().query())\n\t        self.assertEqual({}, Or().query())\n\t    def test_single(self):\n\t        self.assertEqual({\"f1\": {\"$gt\": 10.5}}, Or(GT(\"f1\", 10.5)).query())\n", "    def test_complex_or_filter(self):\n\t        f = Or(\n\t            Or(Eq(\"name\", \"alice\"), GTE(\"rank\", 2)),\n\t            Or(Eq(\"name\", \"emma\"), LTE(\"rank\", 6), Not(\"city\", \"sfo\")),\n\t            And(GTE(\"f1\", 1.5), LTE(\"f1\", 3.14), Contains(\"f2\", \"hello\")),\n\t            Not(\"f3\", False),\n\t            Regex(\"f4\", \"/andy/i\"),\n\t        )\n\t        self.assertEqual(\n\t            {\n", "                \"$or\": [\n\t                    {\"$or\": [{\"name\": \"alice\"}, {\"rank\": {\"$gte\": 2}}]},\n\t                    {\n\t                        \"$or\": [\n\t                            {\"name\": \"emma\"},\n\t                            {\"rank\": {\"$lte\": 6}},\n\t                            {\"city\": {\"$not\": \"sfo\"}},\n\t                        ]\n\t                    },\n\t                    {\n", "                        \"$and\": [\n\t                            {\"f1\": {\"$gte\": 1.5}},\n\t                            {\"f1\": {\"$lte\": 3.14}},\n\t                            {\"f2\": {\"$contains\": \"hello\"}},\n\t                        ]\n\t                    },\n\t                    {\"f3\": {\"$not\": False}},\n\t                    {\"f4\": {\"$regex\": \"/andy/i\"}},\n\t                ]\n\t            },\n", "            f.query(),\n\t        )\n\t    def test_complex_and_filter(self):\n\t        f = And(\n\t            Or(Eq(\"name\", \"alice\"), GTE(\"rank\", 2)),\n\t            Or(Eq(\"name\", \"emma\"), LTE(\"rank\", 6), Not(\"city\", \"sfo\")),\n\t        )\n\t        self.assertEqual(\n\t            {\n\t                \"$and\": [\n", "                    {\"$or\": [{\"name\": \"alice\"}, {\"rank\": {\"$gte\": 2}}]},\n\t                    {\n\t                        \"$or\": [\n\t                            {\"name\": \"emma\"},\n\t                            {\"rank\": {\"$lte\": 6}},\n\t                            {\"city\": {\"$not\": \"sfo\"}},\n\t                        ]\n\t                    },\n\t                ]\n\t            },\n", "            f.query(),\n\t        )\n"]}
{"filename": "tests/test_search_index.py", "chunked_list": ["import datetime\n\tfrom unittest import TestCase\n\tfrom unittest.mock import patch\n\tfrom google.protobuf.timestamp_pb2 import Timestamp as ProtoTimestamp\n\tfrom api.generated.server.v1.api_pb2 import Match, MatchField, SearchHit, SearchHitMeta\n\tfrom api.generated.server.v1.observability_pb2 import Error as ProtoError\n\tfrom api.generated.server.v1.search_pb2 import (\n\t    CreateDocumentResponse,\n\t    CreateOrReplaceDocumentResponse,\n\t    DeleteDocumentRequest,\n", "    DeleteDocumentResponse,\n\t    DocStatus,\n\t    GetDocumentResponse,\n\t    SearchIndexRequest,\n\t    SearchIndexResponse,\n\t    UpdateDocumentResponse,\n\t)\n\tfrom tests import UnavailableRpcError\n\tfrom tigrisdb.errors import TigrisServerError\n\tfrom tigrisdb.search_index import SearchIndex\n", "from tigrisdb.types import ClientConfig, Document\n\tfrom tigrisdb.types.search import Query as SearchQuery\n\tfrom tigrisdb.utils import marshal, unmarshal\n\t@patch(\"api.generated.server.v1.search_pb2_grpc.SearchStub\")\n\tclass SearchIndexTest(TestCase):\n\t    def setUp(self) -> None:\n\t        self.client_config = ClientConfig(server_url=\"localhost:5000\", project=\"db1\")\n\t        self.index_name = \"catalog\"\n\t    def test_search(self, grpc_search):\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n", "        mock_grpc = grpc_search()\n\t        mock_grpc.Search.return_value = [\n\t            SearchIndexResponse(hits=[SearchHit(data=marshal({\"f\": \"v\"}))])\n\t        ]\n\t        query = SearchQuery(q=\"hello world\")\n\t        resp = search_index.search(query, 3)\n\t        self.assertEqual(1, len(resp.hits))\n\t        self.assertEqual({\"f\": \"v\"}, resp.hits[0].doc)\n\t        mock_grpc.Search.assert_called_once()\n\t        called_with: SearchIndexRequest = mock_grpc.Search.call_args.args[0]\n", "        self.assertEqual(called_with.project, search_index.project)\n\t        self.assertEqual(called_with.index, search_index.name)\n\t        self.assertEqual(\"hello world\", called_with.q)\n\t        self.assertEqual(3, called_with.page)\n\t    def test_search_with_error(self, grpc_search):\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.Search.side_effect = UnavailableRpcError(\"operational failure\")\n\t        with self.assertRaisesRegex(TigrisServerError, \"operational failure\") as e:\n\t            search_index.search(SearchQuery())\n", "        self.assertIsNotNone(e)\n\t    def test_create_many(self, grpc_search):\n\t        docs = [{\"id\": 1, \"name\": \"shoe\"}, {\"id\": 2, \"name\": \"jacket\"}]\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.Create.return_value = CreateDocumentResponse(\n\t            status=[\n\t                DocStatus(id=\"1\"),\n\t                DocStatus(id=\"2\", error=ProtoError(message=\"conflict\")),\n\t            ]\n", "        )\n\t        resp = search_index.create_many(docs)\n\t        self.assertEqual(resp[0].id, \"1\")\n\t        self.assertIsNone(resp[0].error)\n\t        self.assertEqual(resp[1].id, \"2\")\n\t        self.assertRegex(resp[1].error.msg, \"conflict\")\n\t        mock_grpc.Create.assert_called_once()\n\t        called_with = mock_grpc.Create.call_args.args[0]\n\t        self.assertEqual(called_with.project, search_index.project)\n\t        self.assertEqual(called_with.index, search_index.name)\n", "        self.assertEqual(list(map(unmarshal, called_with.documents)), docs)\n\t    def test_create_many_with_error(self, grpc_search):\n\t        docs = [{\"id\": 1, \"name\": \"shoe\"}, {\"id\": 2, \"name\": \"jacket\"}]\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.Create.side_effect = UnavailableRpcError(\"operational failure\")\n\t        with self.assertRaisesRegex(TigrisServerError, \"operational failure\") as e:\n\t            search_index.create_many(docs)\n\t        self.assertIsNotNone(e)\n\t    def test_create_one(self, grpc_search):\n", "        doc: Document = {\"item_id\": 1, \"name\": \"shoe\", \"brand\": \"adidas\"}\n\t        with patch.object(\n\t            SearchIndex, \"create_many\", return_value=\"some_str\"\n\t        ) as mock_create_many:\n\t            search_index = SearchIndex(\n\t                self.index_name, grpc_search(), self.client_config\n\t            )\n\t            search_index.create_one(doc)\n\t        mock_create_many.assert_called_once_with([doc])\n\t    def test_delete_many(self, grpc_search):\n", "        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.Delete.return_value = DeleteDocumentResponse(\n\t            status=[\n\t                DocStatus(id=\"1\"),\n\t                DocStatus(id=\"2\", error=ProtoError(message=\"conflict\")),\n\t            ]\n\t        )\n\t        resp = search_index.delete_many([\"1\", \"2\"])\n\t        self.assertEqual(resp[0].id, \"1\")\n", "        self.assertIsNone(resp[0].error)\n\t        self.assertEqual(resp[1].id, \"2\")\n\t        self.assertRegex(resp[1].error.msg, \"conflict\")\n\t        mock_grpc.Delete.assert_called_once()\n\t        called_with: DeleteDocumentRequest = mock_grpc.Delete.call_args.args[0]\n\t        self.assertEqual(called_with.project, search_index.project)\n\t        self.assertEqual(called_with.index, search_index.name)\n\t        self.assertEqual(called_with.ids, [\"1\", \"2\"])\n\t    def test_delete_many_with_error(self, grpc_search):\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n", "        mock_grpc = grpc_search()\n\t        mock_grpc.Delete.side_effect = UnavailableRpcError(\"operational failure\")\n\t        with self.assertRaisesRegex(TigrisServerError, \"operational failure\") as e:\n\t            search_index.delete_many([\"id\"])\n\t        self.assertIsNotNone(e)\n\t    def test_delete_one(self, grpc_search):\n\t        with patch.object(\n\t            SearchIndex, \"delete_many\", return_value=\"some_str\"\n\t        ) as mock_delete_many:\n\t            search_index = SearchIndex(\n", "                self.index_name, grpc_search(), self.client_config\n\t            )\n\t            search_index.delete_one(\"id\")\n\t        mock_delete_many.assert_called_once_with([\"id\"])\n\t    def test_create_or_replace_many(self, grpc_search):\n\t        docs = [{\"id\": 1, \"name\": \"shoe\"}, {\"id\": 2, \"name\": \"jacket\"}]\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.CreateOrReplace.return_value = CreateOrReplaceDocumentResponse(\n\t            status=[\n", "                DocStatus(id=\"1\"),\n\t                DocStatus(id=\"2\", error=ProtoError(message=\"conflict\")),\n\t            ]\n\t        )\n\t        resp = search_index.create_or_replace_many(docs)\n\t        self.assertEqual(resp[0].id, \"1\")\n\t        self.assertIsNone(resp[0].error)\n\t        self.assertEqual(resp[1].id, \"2\")\n\t        self.assertRegex(resp[1].error.msg, \"conflict\")\n\t        mock_grpc.CreateOrReplace.assert_called_once()\n", "        called_with = mock_grpc.CreateOrReplace.call_args.args[0]\n\t        self.assertEqual(called_with.project, search_index.project)\n\t        self.assertEqual(called_with.index, search_index.name)\n\t        self.assertEqual(list(map(unmarshal, called_with.documents)), docs)\n\t    def test_create_or_replace_many_with_error(self, grpc_search):\n\t        docs = [{\"id\": 1, \"name\": \"shoe\"}, {\"id\": 2, \"name\": \"jacket\"}]\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.CreateOrReplace.side_effect = UnavailableRpcError(\n\t            \"operational failure\"\n", "        )\n\t        with self.assertRaisesRegex(TigrisServerError, \"operational failure\") as e:\n\t            search_index.create_or_replace_many(docs)\n\t        self.assertIsNotNone(e)\n\t    def test_create_or_replace_one(self, grpc_search):\n\t        doc: Document = {\"item_id\": 1, \"name\": \"shoe\", \"brand\": \"adidas\"}\n\t        with patch.object(\n\t            SearchIndex, \"create_or_replace_many\", return_value=\"some_str\"\n\t        ) as mock_replace_any:\n\t            search_index = SearchIndex(\n", "                self.index_name, grpc_search(), self.client_config\n\t            )\n\t            search_index.create_or_replace_one(doc)\n\t        mock_replace_any.assert_called_once_with([doc])\n\t    def test_get_many(self, grpc_search):\n\t        docs = [\n\t            {\"id\": \"1\", \"title\": \"à¤¨à¤®à¤¸à¥à¤¤à¥‡ to India\", \"tags\": [\"travel\"]},\n\t            {\"id\": \"2\", \"title\": \"reliable systems ðŸ™\", \"tags\": [\"it\"]},\n\t        ]\n\t        ts, proto_ts = (\n", "            datetime.datetime.fromisoformat(\"2023-05-05T10:00:00+00:00\"),\n\t            ProtoTimestamp(),\n\t        )\n\t        proto_ts.FromDatetime(ts)\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        expected_resp = GetDocumentResponse()\n\t        expected_resp.documents.extend(\n\t            [\n\t                SearchHit(\n", "                    data=marshal(docs[0]),\n\t                    metadata=SearchHitMeta(\n\t                        created_at=proto_ts,\n\t                        updated_at=proto_ts,\n\t                        match=Match(\n\t                            fields=[MatchField(name=\"f1\")],\n\t                            score=\"25.0\",\n\t                            vector_distance=34.35,\n\t                        ),\n\t                    ),\n", "                ),\n\t                SearchHit(data=marshal(docs[1])),\n\t            ]\n\t        )\n\t        mock_grpc.Get.return_value = expected_resp\n\t        resp = search_index.get_many(list(map(lambda d: d[\"id\"], docs)))\n\t        self.assertEqual(len(docs), len(resp))\n\t        self.assertEqual(docs[0], resp[0].doc)\n\t        self.assertEqual(ts, resp[0].meta.created_at)\n\t        self.assertEqual(ts, resp[0].meta.updated_at)\n", "        self.assertEqual(\"25.0\", resp[0].meta.text_match.score)\n\t        self.assertEqual([\"f1\"], resp[0].meta.text_match.fields)\n\t        self.assertEqual(34.35, resp[0].meta.text_match.vector_distance)\n\t        self.assertEqual(docs[1], resp[1].doc)\n\t    def test_get_many_with_error(self, grpc_search):\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.Get.side_effect = UnavailableRpcError(\"operational failure\")\n\t        with self.assertRaisesRegex(TigrisServerError, \"operational failure\") as e:\n\t            search_index.get_many([\"id\"])\n", "        self.assertIsNotNone(e)\n\t    def test_get_one(self, grpc_search):\n\t        with patch.object(\n\t            SearchIndex, \"get_many\", return_value=\"some_str\"\n\t        ) as mock_get_many:\n\t            search_index = SearchIndex(\n\t                self.index_name, grpc_search(), self.client_config\n\t            )\n\t            search_index.get_one(\"id\")\n\t        mock_get_many.assert_called_once_with([\"id\"])\n", "    def test_update_many(self, grpc_search):\n\t        docs = [{\"id\": 1, \"name\": \"shoe\"}, {\"id\": 2, \"name\": \"jacket\"}]\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.Update.return_value = UpdateDocumentResponse(\n\t            status=[\n\t                DocStatus(id=\"1\"),\n\t                DocStatus(id=\"2\", error=ProtoError(message=\"conflict\")),\n\t            ]\n\t        )\n", "        resp = search_index.update_many(docs)\n\t        self.assertEqual(resp[0].id, \"1\")\n\t        self.assertIsNone(resp[0].error)\n\t        self.assertEqual(resp[1].id, \"2\")\n\t        self.assertRegex(resp[1].error.msg, \"conflict\")\n\t        mock_grpc.Update.assert_called_once()\n\t        called_with = mock_grpc.Update.call_args.args[0]\n\t        self.assertEqual(called_with.project, search_index.project)\n\t        self.assertEqual(called_with.index, search_index.name)\n\t        self.assertEqual(list(map(unmarshal, called_with.documents)), docs)\n", "    def test_update_many_with_error(self, grpc_search):\n\t        docs = [{\"id\": 1, \"name\": \"shoe\"}, {\"id\": 2, \"name\": \"jacket\"}]\n\t        search_index = SearchIndex(self.index_name, grpc_search(), self.client_config)\n\t        mock_grpc = grpc_search()\n\t        mock_grpc.Update.side_effect = UnavailableRpcError(\"operational failure\")\n\t        with self.assertRaisesRegex(TigrisServerError, \"operational failure\") as e:\n\t            search_index.update_many(docs)\n\t        self.assertIsNotNone(e)\n\t    def test_update_one(self, grpc_search):\n\t        doc: Document = {\"item_id\": 1, \"name\": \"shoe\", \"brand\": \"adidas\"}\n", "        with patch.object(\n\t            SearchIndex, \"update_many\", return_value=\"some_str\"\n\t        ) as mock_update_many:\n\t            search_index = SearchIndex(\n\t                self.index_name, grpc_search(), self.client_config\n\t            )\n\t            search_index.update_one(doc)\n\t        mock_update_many.assert_called_once_with([doc])\n"]}
{"filename": "tests/test_types_filters_selector.py", "chunked_list": ["import datetime\n\tfrom unittest import TestCase\n\tfrom tigrisdb.types.filters import GT, GTE, LT, LTE, Contains, Eq, Not, Regex\n\tclass SelectorTestCase(TestCase):\n\t    def test_equals(self):\n\t        f = Eq(\"f1\", 25)\n\t        self.assertEqual({\"f1\": 25}, f.query())\n\t    def test_gte(self):\n\t        f = GTE(\"f1\", 25)\n\t        self.assertEqual({\"f1\": {\"$gte\": 25}}, f.query())\n", "    def test_gt(self):\n\t        dt = datetime.datetime.fromisoformat(\"2023-05-05T10:00:00+00:00\")\n\t        f = GT(\"f1\", dt)\n\t        self.assertEqual({\"f1\": {\"$gt\": dt}}, f.query())\n\t    def test_lte(self):\n\t        f = LTE(\"f1\", 25)\n\t        self.assertEqual({\"f1\": {\"$lte\": 25}}, f.query())\n\t    def test_lt(self):\n\t        f = LT(\"f1\", 25)\n\t        self.assertEqual({\"f1\": {\"$lt\": 25}}, f.query())\n", "    def test_regex(self):\n\t        f = Regex(\"f1\", \"emma*\")\n\t        self.assertEqual({\"f1\": {\"$regex\": \"emma*\"}}, f.query())\n\t    def test_contains(self):\n\t        f = Contains(\"f1\", \"cars\")\n\t        self.assertEqual({\"f1\": {\"$contains\": \"cars\"}}, f.query())\n\t    def test_not(self):\n\t        f = Not(\"f1\", \"Alex\")\n\t        self.assertEqual({\"f1\": {\"$not\": \"Alex\"}}, f.query())\n"]}
{"filename": "tests/__init__.py", "chunked_list": ["from typing import Optional\n\timport grpc\n\tclass StubRpcError(grpc.RpcError):\n\t    def __init__(self, code: grpc.StatusCode, details: Optional[str]):\n\t        self._code = code\n\t        self._details = details\n\t    def code(self):\n\t        return self._code\n\t    def details(self):\n\t        return self._details\n", "class UnavailableRpcError(StubRpcError):\n\t    def __init__(self, details: Optional[str]):\n\t        super().__init__(grpc.StatusCode.UNAVAILABLE, details)\n\tclass NotFoundRpcError(StubRpcError):\n\t    def __init__(self, details: Optional[str]):\n\t        super().__init__(grpc.StatusCode.NOT_FOUND, details)\n"]}
{"filename": "tests/test_types_sort.py", "chunked_list": ["from unittest import TestCase\n\tfrom tigrisdb.types.sort import Ascending, Descending, Sort\n\tclass SortTests(TestCase):\n\t    def test_ascending(self):\n\t        sort = Ascending(\"f1\")\n\t        self.assertEqual({\"f1\": \"$asc\"}, sort.query())\n\t    def test_descending(self):\n\t        sort = Descending(\"f1\")\n\t        self.assertEqual({\"f1\": \"$desc\"}, sort.query())\n\t    def test_base_sort_error(self):\n", "        with self.assertRaisesRegex(TypeError, \"abstract class\"):\n\t            Sort()\n"]}
{"filename": "tests/test_dependencies.py", "chunked_list": ["import os.path\n\tfrom unittest import TestCase\n\timport tomli\n\tHERE = os.path.dirname(os.path.realpath(__file__))\n\tPYPROJECT_TOML = os.path.join(HERE, \"..\", \"pyproject.toml\")\n\tclass DependenciesTest(TestCase):\n\t    def setUp(self) -> None:\n\t        with open(PYPROJECT_TOML, \"rb\") as f:\n\t            self.poetry_conf = tomli.load(f)[\"tool\"][\"poetry\"]\n\t    def test_required_dependencies(self):\n", "        deps = self.poetry_conf[\"dependencies\"].keys()\n\t        self.assertCountEqual(\n\t            [\"python\", \"protobuf\", \"grpcio-tools\"],\n\t            deps,\n\t        )\n\t    def test_dev_dependencies(self):\n\t        deps = self.poetry_conf[\"group\"][\"dev\"][\"dependencies\"].keys()\n\t        self.assertCountEqual([\"pre-commit\", \"coverage\", \"tomli\"], deps)\n"]}
{"filename": "tests/test_types_client_config.py", "chunked_list": ["import os\n\tfrom unittest import TestCase\n\tfrom unittest.mock import patch\n\tfrom tigrisdb.types import ClientConfig\n\tclass ClientConfigTest(TestCase):\n\t    def setUp(self) -> None:\n\t        pass\n\t    def test_init_with_none(self):\n\t        conf = ClientConfig()\n\t        self.assertIsNone(conf.project)\n", "        self.assertEqual(conf.server_url, \"api.preview.tigrisdata.cloud\")\n\t        self.assertIsNone(conf.client_id)\n\t        self.assertIsNone(conf.client_secret)\n\t        self.assertEqual(conf.branch, \"\")\n\t        self.assertFalse(conf.is_local_dev())\n\t    @patch.dict(\n\t        os.environ,\n\t        {\n\t            \"TIGRIS_URI\": \"uri_env\",\n\t            \"TIGRIS_PROJECT\": \"project_env\",\n", "            \"TIGRIS_CLIENT_ID\": \"client_env\",\n\t            \"TIGRIS_CLIENT_SECRET\": \"secret_env\",\n\t            \"TIGRIS_DB_BRANCH\": \"branch_env\",\n\t        },\n\t    )\n\t    def test_init_with_all_args(self):\n\t        conf = ClientConfig(\n\t            server_url=\"uri\",\n\t            project=\"project\",\n\t            client_id=\"client\",\n", "            client_secret=\"secret\",\n\t            branch=\"branch\",\n\t        )\n\t        self.assertEqual(conf.server_url, \"uri\")\n\t        self.assertEqual(conf.project, \"project\")\n\t        self.assertEqual(conf.client_id, \"client\")\n\t        self.assertEqual(conf.client_secret, \"secret\")\n\t        self.assertEqual(conf.branch, \"branch\")\n\t    @patch.dict(\n\t        os.environ,\n", "        {\n\t            \"TIGRIS_URI\": \"uri_env\",\n\t            \"TIGRIS_PROJECT\": \"project_env\",\n\t            \"TIGRIS_CLIENT_ID\": \"client_env\",\n\t            \"TIGRIS_CLIENT_SECRET\": \"secret_env\",\n\t            \"TIGRIS_DB_BRANCH\": \"branch_env\",\n\t        },\n\t    )\n\t    def test_init_with_all_env(self):\n\t        conf = ClientConfig()\n", "        self.assertEqual(conf.server_url, \"uri_env\")\n\t        self.assertEqual(conf.project, \"project_env\")\n\t        self.assertEqual(conf.client_id, \"client_env\")\n\t        self.assertEqual(conf.client_secret, \"secret_env\")\n\t        self.assertEqual(conf.branch, \"branch_env\")\n\t    @patch.dict(\n\t        os.environ,\n\t        {\n\t            \"TIGRIS_CLIENT_ID\": \"client_env\",\n\t            \"TIGRIS_DB_BRANCH\": \"branch_env\",\n", "        },\n\t    )\n\t    def test_init_with_partial_env(self):\n\t        conf = ClientConfig(project=\"project\")\n\t        self.assertEqual(conf.project, \"project\")\n\t        self.assertEqual(conf.client_id, \"client_env\")\n\t        self.assertIsNone(conf.client_secret)\n\t        self.assertEqual(conf.branch, \"branch_env\")\n\t    @patch.dict(\n\t        os.environ,\n", "        {\n\t            \"TIGRIS_URI\": \"uri_env\",\n\t            \"TIGRIS_PROJECT\": \"project_env\",\n\t            \"TIGRIS_CLIENT_ID\": \"client_env\",\n\t            \"TIGRIS_CLIENT_SECRET\": \"secret_env\",\n\t            \"TIGRIS_DB_BRANCH\": \"branch_env\",\n\t        },\n\t    )\n\t    def test_merge_override_all(self):\n\t        conf = ClientConfig(\n", "            server_url=\"uri\",\n\t            project=\"project\",\n\t            client_id=\"client\",\n\t            client_secret=\"secret\",\n\t            branch=\"branch\",\n\t        )\n\t        conf.merge(\n\t            project=\"project_dict\",\n\t            client_id=\"client_dict\",\n\t            client_secret=\"secret_dict\",\n", "            server_url=\"uri_dict\",\n\t            branch=\"branch_dict\",\n\t        )\n\t        self.assertEqual(conf.server_url, \"uri_dict\")\n\t        self.assertEqual(conf.project, \"project_dict\")\n\t        self.assertEqual(conf.client_id, \"client_dict\")\n\t        self.assertEqual(conf.client_secret, \"secret_dict\")\n\t        self.assertEqual(conf.branch, \"branch_dict\")\n\t    def test_local_dev(self):\n\t        cases = [\n", "            (ClientConfig(), False),\n\t            (ClientConfig(server_url=\"localhost:1234\"), True),\n\t            (ClientConfig(server_url=\"127.0.0.1\"), True),\n\t            (ClientConfig(server_url=\"[::1]\"), True),\n\t            (ClientConfig(server_url=\"https://tigrisdb-local-server:1234\"), True),\n\t            (ClientConfig(server_url=\"https://api.tigris.cloud\"), False),\n\t        ]\n\t        for conf, expected in cases:\n\t            with self.subTest(conf.server_url):\n\t                self.assertEqual(expected, conf.is_local_dev())\n", "    def test_validate_without_project(self):\n\t        conf = ClientConfig()\n\t        with self.assertRaisesRegex(\n\t            ValueError, \"`TIGRIS_PROJECT` environment variable\"\n\t        ):\n\t            conf.validate()\n\t    def test_validate_without_client_id(self):\n\t        conf = ClientConfig(project=\"project\")\n\t        with self.assertRaisesRegex(\n\t            ValueError, \"`TIGRIS_CLIENT_ID` environment variable\"\n", "        ):\n\t            conf.validate()\n\t    def test_validate_without_client_secret(self):\n\t        conf = ClientConfig(project=\"project\", client_id=\"id\")\n\t        with self.assertRaisesRegex(\n\t            ValueError, \"`TIGRIS_CLIENT_SECRET` environment variable\"\n\t        ):\n\t            conf.validate()\n\t    def test_validate_no_error(self):\n\t        conf = ClientConfig(project=\"project\", client_id=\"id\", client_secret=\"secret\")\n", "        conf.validate()\n\t        self.assertFalse(conf.is_local_dev())\n"]}
{"filename": "tests/test_auth.py", "chunked_list": ["import time\n\tfrom unittest import TestCase\n\tfrom unittest.mock import MagicMock, patch\n\timport grpc\n\tfrom api.generated.server.v1.auth_pb2 import (\n\t    CLIENT_CREDENTIALS,\n\t    GetAccessTokenRequest,\n\t    GetAccessTokenResponse,\n\t)\n\tfrom tests import StubRpcError\n", "from tigrisdb.auth import AuthGateway\n\tfrom tigrisdb.errors import TigrisServerError\n\tfrom tigrisdb.types import ClientConfig\n\tfrom tigrisdb.utils import obj_to_b64\n\t@patch(\"api.generated.server.v1.auth_pb2_grpc.AuthStub\")\n\t@patch(\"grpc.channel_ready_future\")\n\tclass AuthGatewayTest(TestCase):\n\t    def setUp(self) -> None:\n\t        self.done_future = MagicMock(grpc.Future)\n\t        self.client_config = ClientConfig(server_url=\"localhost:5000\", project=\"db1\")\n", "    def test_get_access_token_with_valid_token_refresh_window(\n\t        self, channel_ready_future, grpc_auth\n\t    ):\n\t        channel_ready_future.return_value = self.done_future\n\t        expiration_time = time.time()\n\t        mock_grpc_auth, expected_token = grpc_auth(), _encoded_token(expiration_time)\n\t        mock_grpc_auth.GetAccessToken.return_value = GetAccessTokenResponse(\n\t            access_token=expected_token\n\t        )\n\t        auth_gateway = AuthGateway(self.client_config)\n", "        actual_token = auth_gateway.get_access_token()\n\t        self.assertEqual(expected_token, actual_token)\n\t        next_refresh = auth_gateway.__getattribute__(\"_AuthGateway__next_refresh_time\")\n\t        # refresh time is within 11 minutes of expiration time\n\t        self.assertLessEqual(expiration_time - next_refresh, 660)\n\t        # request validation\n\t        mock_grpc_auth.GetAccessToken.assert_called_once_with(\n\t            GetAccessTokenRequest(grant_type=CLIENT_CREDENTIALS)\n\t        )\n\t    def test_get_access_token_with_rpc_failure(self, channel_ready_future, grpc_auth):\n", "        channel_ready_future.return_value = self.done_future\n\t        mock_grpc_auth = grpc_auth()\n\t        mock_grpc_auth.GetAccessToken.side_effect = StubRpcError(\n\t            code=grpc.StatusCode.UNAVAILABLE, details=\"\"\n\t        )\n\t        auth_gateway = AuthGateway(self.client_config)\n\t        with self.assertRaisesRegex(\n\t            TigrisServerError, \"failed to get access token\"\n\t        ) as e:\n\t            auth_gateway.get_access_token()\n", "        self.assertIsNotNone(e)\n\t    def test_should_refresh_with_expired_token(self, channel_ready_future, grpc_auth):\n\t        channel_ready_future.return_value = self.done_future\n\t        auth_gateway = AuthGateway(self.client_config)\n\t        self.assertTrue(auth_gateway.should_refresh())\n\t        auth_gateway.__setattr__(\"_AuthGateway__cached_token\", \"xyz\")\n\t        auth_gateway.__setattr__(\"_AuthGateway__next_refresh_time\", time.time() + 5)\n\t        self.assertFalse(auth_gateway.should_refresh())\n\t        auth_gateway.__setattr__(\"_AuthGateway__next_refresh_time\", time.time() - 5)\n\t        self.assertTrue(auth_gateway.should_refresh())\n", "    def test_should_refresh_without_cached_token(self, channel_ready_future, grpc_auth):\n\t        channel_ready_future.return_value = self.done_future\n\t        auth_gateway = AuthGateway(self.client_config)\n\t        self.assertTrue(auth_gateway.should_refresh())\n\t        auth_gateway.__setattr__(\"_AuthGateway__cached_token\", \"xyz\")\n\t        self.assertTrue(auth_gateway.should_refresh())\n\t        auth_gateway.__setattr__(\"_AuthGateway__next_refresh_time\", time.time() + 10)\n\t        self.assertFalse(auth_gateway.should_refresh())\n\t    def test_get_auth_headers(self, channel_ready_future, grpc_auth):\n\t        channel_ready_future.return_value = self.done_future\n", "        auth_gateway = AuthGateway(self.client_config)\n\t        auth_gateway.__setattr__(\"_AuthGateway__cached_token\", \"xyz\")\n\t        auth_gateway.__setattr__(\"_AuthGateway__next_refresh_time\", time.time() + 10)\n\t        self.assertFalse(auth_gateway.should_refresh())\n\t        expected_headers = [\n\t            (\"authorization\", \"Bearer xyz\"),\n\t            (\"user-agent\", \"tigris-client-python.grpc\"),\n\t            (\"destination-name\", self.client_config.server_url),\n\t        ]\n\t        self.assertCountEqual(expected_headers, auth_gateway.get_auth_headers(None))\n", "def _encoded_token(expiration: float):\n\t    return f'token.{obj_to_b64({\"exp\": expiration})}'\n"]}
{"filename": "tests/test_client.py", "chunked_list": ["import os\n\tfrom unittest import TestCase\n\tfrom unittest.mock import MagicMock, patch\n\timport grpc\n\tfrom tigrisdb.client import TigrisClient\n\tfrom tigrisdb.types import ClientConfig\n\t@patch(\"grpc.channel_ready_future\")\n\tclass TigrisClientTest(TestCase):\n\t    def setUp(self) -> None:\n\t        self.done_future = MagicMock(grpc.Future)\n", "    def test_init_with_none(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        with self.assertRaisesRegex(\n\t            ValueError, \"`TIGRIS_PROJECT` environment variable\"\n\t        ):\n\t            TigrisClient()\n\t    def test_init_with_complete_dict(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        client = TigrisClient(\n\t            {\n", "                \"server_url\": \"uri\",\n\t                \"project\": \"project\",\n\t                \"client_id\": \"client\",\n\t                \"client_secret\": \"secret\",\n\t                \"branch\": \"branch\",\n\t            }\n\t        )\n\t        self.assertEqual(\"uri:443\", client.config.server_url)\n\t        self.assertEqual(\"client\", client.config.client_id)\n\t        self.assertEqual(\"secret\", client.config.client_secret)\n", "        self.assertEqual(\"project\", client.config.project)\n\t        self.assertEqual(\"branch\", client.config.branch)\n\t    @patch.dict(\n\t        os.environ,\n\t        {\n\t            \"TIGRIS_URI\": \"localhost:5000\",\n\t            \"TIGRIS_PROJECT\": \"project_env\",\n\t        },\n\t    )\n\t    def test_init_with_partial_dict(self, ready_future):\n", "        ready_future.return_value = self.done_future\n\t        client = TigrisClient({\"project\": \"p1\"})\n\t        self.assertEqual(\"localhost:5000\", client.config.server_url)\n\t        self.assertEqual(\"p1\", client.config.project)\n\t    def test_init_with_config(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        client = TigrisClient(\n\t            conf=ClientConfig(\n\t                server_url=\"test_url\",\n\t                project=\"test_project\",\n", "                client_id=\"test_client_id\",\n\t                client_secret=\"test_client_secret\",\n\t                branch=\"test_branch\",\n\t            )\n\t        )\n\t        self.assertEqual(\"test_url:443\", client.config.server_url)\n\t        self.assertEqual(\"test_client_id\", client.config.client_id)\n\t        self.assertEqual(\"test_client_secret\", client.config.client_secret)\n\t        self.assertEqual(\"test_project\", client.config.project)\n\t        self.assertEqual(\"test_branch\", client.config.branch)\n", "    def test_init_local_dev(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        client = TigrisClient(\n\t            {\"server_url\": \"localhost:5000\", \"project\": \"test_project\"}\n\t        )\n\t        self.assertEqual(\"localhost:5000\", client.config.server_url)\n\t        self.assertEqual(\"test_project\", client.config.project)\n\t    def test_init_failing_validation(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        with self.assertRaisesRegex(\n", "            ValueError, \"`TIGRIS_PROJECT` environment variable\"\n\t        ):\n\t            TigrisClient({\"server_url\": \"localhost:5000\"})\n\t    @patch.dict(\n\t        os.environ,\n\t        {\n\t            \"TIGRIS_URI\": \"uri_env\",\n\t            \"TIGRIS_PROJECT\": \"project_env\",\n\t            \"TIGRIS_CLIENT_ID\": \"client_env\",\n\t            \"TIGRIS_CLIENT_SECRET\": \"secret_env\",\n", "            \"TIGRIS_DB_BRANCH\": \"branch_env\",\n\t        },\n\t    )\n\t    def test_with_env_vars(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        client = TigrisClient()\n\t        self.assertEqual(\"uri_env:443\", client.config.server_url)\n\t        self.assertEqual(\"client_env\", client.config.client_id)\n\t        self.assertEqual(\"secret_env\", client.config.client_secret)\n\t        self.assertEqual(\"project_env\", client.config.project)\n", "        self.assertEqual(\"branch_env\", client.config.branch)\n\t    def test_strip_https(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        conf = ClientConfig(\n\t            server_url=\"https://my.tigris.dev\",\n\t            project=\"p1\",\n\t            client_id=\"id\",\n\t            client_secret=\"secret\",\n\t        )\n\t        client = TigrisClient(conf)\n", "        self.assertEqual(\"my.tigris.dev:443\", client.config.server_url)\n\t        conf.server_url = \"http://my.tigris.dev\"\n\t        client = TigrisClient(conf)\n\t        self.assertEqual(\"my.tigris.dev:443\", client.config.server_url)\n\t    def test_get_db(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        client = TigrisClient(ClientConfig(project=\"p1\", server_url=\"localhost:5000\"))\n\t        self.assertEqual(client.config.branch, client.get_db().branch)\n\t        self.assertEqual(client.config.project, client.get_db().project)\n\t    def test_get_search(self, ready_future):\n", "        ready_future.return_value = self.done_future\n\t        client = TigrisClient(ClientConfig(project=\"p1\", server_url=\"localhost:5000\"))\n\t        self.assertEqual(client.config.project, client.get_search().project)\n\t    def test_get_vector_search(self, ready_future):\n\t        ready_future.return_value = self.done_future\n\t        client = TigrisClient(ClientConfig(project=\"p1\", server_url=\"localhost:5000\"))\n\t        self.assertEqual(\"v1\", client.get_vector_store(\"v1\").name)\n"]}
{"filename": "tigrisdb/database.py", "chunked_list": ["import grpc\n\tfrom api.generated.server.v1.api_pb2 import (\n\t    CreateOrUpdateCollectionRequest,\n\t    CreateOrUpdateCollectionResponse,\n\t    DropCollectionRequest,\n\t    DropCollectionResponse,\n\t)\n\tfrom api.generated.server.v1.api_pb2_grpc import TigrisStub\n\tfrom tigrisdb.collection import Collection\n\tfrom tigrisdb.errors import TigrisException, TigrisServerError\n", "from tigrisdb.types import ClientConfig\n\tfrom tigrisdb.utils import schema_to_bytes\n\tclass Database:\n\t    __client: TigrisStub\n\t    __config: ClientConfig\n\t    def __init__(self, client_stub: TigrisStub, config: ClientConfig):\n\t        self.__client = client_stub\n\t        self.__config = config\n\t    @property\n\t    def project(self):\n", "        return self.__config.project\n\t    @property\n\t    def branch(self):\n\t        return self.__config.branch\n\t    def create_or_update_collection(self, name: str, schema: dict) -> Collection:\n\t        req = CreateOrUpdateCollectionRequest(\n\t            project=self.project,\n\t            branch=self.branch,\n\t            collection=name,\n\t            schema=schema_to_bytes(schema),\n", "            only_create=False,\n\t        )\n\t        try:\n\t            resp: CreateOrUpdateCollectionResponse = (\n\t                self.__client.CreateOrUpdateCollection(req)\n\t            )\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to create collection\", e)\n\t        if resp.status == \"created\":\n\t            return Collection(name, self.__client, self.__config)\n", "        else:\n\t            raise TigrisException(f\"failed to create collection: {resp.message}\")\n\t    def drop_collection(self, name: str) -> bool:\n\t        req = DropCollectionRequest(\n\t            project=self.project,\n\t            branch=self.branch,\n\t            collection=name,\n\t        )\n\t        try:\n\t            resp: DropCollectionResponse = self.__client.DropCollection(req)\n", "        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to drop collection\", e)\n\t        return resp.status == \"dropped\"\n"]}
{"filename": "tigrisdb/auth.py", "chunked_list": ["from random import randint\n\tfrom time import time\n\timport grpc\n\tfrom api.generated.server.v1 import auth_pb2_grpc as tigris_auth\n\tfrom api.generated.server.v1.auth_pb2 import (\n\t    CLIENT_CREDENTIALS,\n\t    GetAccessTokenRequest,\n\t    GetAccessTokenResponse,\n\t)\n\tfrom tigrisdb.errors import TigrisException, TigrisServerError\n", "from tigrisdb.types import ClientConfig\n\tfrom tigrisdb.utils import b64_to_object\n\tclass AuthGateway(grpc.AuthMetadataPlugin):\n\t    __cached_token: str = \"\"\n\t    __next_refresh_time: float = 0.0\n\t    __config: ClientConfig\n\t    __auth_stub: tigris_auth.AuthStub\n\t    def __init__(self, config: ClientConfig):\n\t        super(grpc.AuthMetadataPlugin, self).__init__()\n\t        self.__config = config\n", "        channel = grpc.secure_channel(config.server_url, grpc.ssl_channel_credentials())\n\t        try:\n\t            grpc.channel_ready_future(channel).result(timeout=10)\n\t        except grpc.FutureTimeoutError:\n\t            raise TigrisException(f\"Auth connection timed out: {config.server_url}\")\n\t        self.__auth_stub = tigris_auth.AuthStub(channel)\n\t    def get_access_token(self):\n\t        if self.should_refresh():\n\t            req = GetAccessTokenRequest(\n\t                grant_type=CLIENT_CREDENTIALS,\n", "                client_id=self.__config.client_id,\n\t                client_secret=self.__config.client_secret,\n\t            )\n\t            try:\n\t                resp: GetAccessTokenResponse = self.__auth_stub.GetAccessToken(req)\n\t                self.__cached_token = resp.access_token\n\t                token_meta = b64_to_object(self.__cached_token.split(\".\")[1] + \"==\")\n\t                exp = float(token_meta[\"exp\"])\n\t                self.__next_refresh_time = exp - 300 - float(randint(0, 300) + 60)\n\t            except grpc.RpcError as e:\n", "                raise TigrisServerError(\"failed to get access token\", e)\n\t        return self.__cached_token\n\t    def should_refresh(self):\n\t        return (not self.__cached_token) or time() >= self.__next_refresh_time\n\t    def get_auth_headers(self, context: grpc.AuthMetadataContext):\n\t        headers = (\n\t            (\"authorization\", f\"Bearer {self.get_access_token()}\"),\n\t            (\"user-agent\", \"tigris-client-python.grpc\"),\n\t            (\"destination-name\", self.__config.server_url),\n\t        )\n", "        return headers\n\t    def __call__(self, context, callback):\n\t        \"\"\"Implements authentication by passing metadata to a callback.\n\t        This method will be invoked asynchronously in a separate thread.\n\t        Args:\n\t          context: An AuthMetadataContext providing information on the RPC that\n\t            the plugin is being called to authenticate.\n\t          callback: An AuthMetadataPluginCallback to be invoked either\n\t            synchronously or asynchronously.\n\t        \"\"\"\n", "        callback(self.get_auth_headers(context), None)\n"]}
{"filename": "tigrisdb/collection.py", "chunked_list": ["from typing import List\n\timport grpc\n\tfrom api.generated.server.v1.api_pb2 import InsertRequest, InsertResponse, ReadRequest\n\tfrom api.generated.server.v1.api_pb2_grpc import TigrisStub\n\tfrom tigrisdb.errors import TigrisException, TigrisServerError\n\tfrom tigrisdb.types import ClientConfig, Document\n\tfrom tigrisdb.utils import marshal, unmarshal\n\tclass Collection:\n\t    __client: TigrisStub\n\t    __config: ClientConfig\n", "    __name: str\n\t    def __init__(\n\t        self, collection_name: str, client_stub: TigrisStub, config: ClientConfig\n\t    ):\n\t        self.__client = client_stub\n\t        self.__config = config\n\t        self.__name = collection_name\n\t    @property\n\t    def project(self):\n\t        return self.__config.project\n", "    @property\n\t    def branch(self):\n\t        return self.__config.branch\n\t    @property\n\t    def name(self):\n\t        return self.__name\n\t    def insert_many(self, docs: List[Document]) -> bool:\n\t        doc_bytes = map(marshal, docs)\n\t        req = InsertRequest(\n\t            project=self.project,\n", "            branch=self.branch,\n\t            collection=self.name,\n\t            documents=doc_bytes,\n\t        )\n\t        try:\n\t            resp: InsertResponse = self.__client.Insert(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to insert documents\", e)\n\t        if resp.status == \"inserted\":\n\t            return True\n", "        else:\n\t            raise TigrisException(f\"failed to insert docs: {resp.status}\")\n\t    def find_many(self) -> List[Document]:\n\t        req = ReadRequest(\n\t            project=self.project,\n\t            branch=self.branch,\n\t            collection=self.name,\n\t            filter=marshal({}),\n\t        )\n\t        try:\n", "            doc_iterator = self.__client.Read(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to read documents\", e)\n\t        docs: List[Document] = []\n\t        for r in doc_iterator:\n\t            docs.append(unmarshal(r.data))\n\t        return docs\n"]}
{"filename": "tigrisdb/vector_store.py", "chunked_list": ["from typing import List, Optional\n\timport grpc\n\tfrom tigrisdb.errors import TigrisServerError\n\tfrom tigrisdb.search import Search\n\tfrom tigrisdb.types.filters import Filter\n\tfrom tigrisdb.types.search import DocStatus, IndexedDoc, Query, Result, VectorField\n\tfrom tigrisdb.types.vector import Document, DocWithScore\n\tclass VectorStore:\n\t    def __init__(self, client: Search, name: str):\n\t        self.client = client\n", "        self._index_name = name\n\t        self.index = self.client.get_index(name)\n\t    @property\n\t    def name(self):\n\t        return self._index_name\n\t    def create_index(self, dimension: int):\n\t        self.client.create_or_update_index(\n\t            name=self.name,\n\t            schema={\n\t                \"title\": self.name,\n", "                \"additionalProperties\": False,\n\t                \"type\": \"object\",\n\t                \"properties\": {\n\t                    \"id\": {\"type\": \"string\"},\n\t                    \"text\": {\"type\": \"string\"},\n\t                    \"metadata\": {\"type\": \"object\"},\n\t                    \"embeddings\": {\n\t                        \"type\": \"array\",\n\t                        \"format\": \"vector\",\n\t                        \"dimensions\": dimension,\n", "                    },\n\t                },\n\t            },\n\t        )\n\t    def add_documents(self, docs: List[Document]) -> List[DocStatus]:\n\t        \"\"\"Adds documents to index, if the index does not exist, create it. A `Document`\n\t        is a dictionary with following structure:\n\t        ```\n\t        {\n\t            \"id\": \"optional id of a document\",\n", "            \"text\": \"Actual content to store\",\n\t            \"embeddings\": \"list of float values\",\n\t            \"metadata\": \"optional metadata as dict\"\n\t        }\n\t        ```\n\t        - `id` is optional and automatically generated once documents are added to index\n\t        - If `id` is given, any existing documents with matching `id` are replaced\n\t        :param docs: list of documents to add to index\n\t        :type docs: list[Document]\n\t        :raises TigrisServerError: thrown i\n", "        :return: List of `ids` for the added documents\n\t        :rtype: list[DocStatus]\n\t        \"\"\"\n\t        try:\n\t            return self.index.create_many(docs)\n\t        except TigrisServerError as e:\n\t            if (\n\t                e.code == grpc.StatusCode.NOT_FOUND\n\t                and \"search index not found\" in e.details\n\t            ):\n", "                first_embedding = docs[0][\"embeddings\"] if docs else []\n\t                inferred_dim = len(first_embedding) if first_embedding else 16\n\t                self.create_index(inferred_dim)\n\t                return self.index.create_many(docs)\n\t            else:\n\t                raise e\n\t    def delete_documents(self, ids: List[str]) -> List[DocStatus]:\n\t        \"\"\"Delete documents from index.\n\t        :param ids: list of document ids to delete\n\t        :type ids: list[str]\n", "        :return: `ids` of documents and deletion status for each\n\t        :rtype: list[DocStatus]\n\t        \"\"\"\n\t        return self.index.delete_many(ids)\n\t    def get_documents(self, ids: List[str]) -> List[IndexedDoc]:\n\t        \"\"\"Retrieve documents from index. It will only have document `ids` found in the\n\t        index.\n\t        :param ids: list of document ids to retrieve\n\t        :type ids: list[str]\n\t        :return: list of documents and associated metadata\n", "        :rtype: list[IndexedDoc]\n\t        \"\"\"\n\t        return self.index.get_many(ids)\n\t    def similarity_search(\n\t        self, vector: List[float], k: int = 10, filter_by: Optional[Filter] = None\n\t    ) -> List[DocWithScore]:\n\t        \"\"\"Perform a similarity search and returns documents most similar to the given\n\t        vector with distance.\n\t        :param vector: Search for documents closest to this vector\n\t        :type vector: list[float]\n", "        :param k: number of documents to return, defaults to 10\n\t        :type k: int, optional\n\t        :param filter_by: apply the filter to metadata to only return a subset of\n\t                documents, defaults to None\n\t        :type filter_by: Filter, optional\n\t        :return: list of documents with similarity score (distance from given vector)\n\t        :rtype: list[DocWithScore]\n\t        \"\"\"\n\t        q = Query(\n\t            vector_query=VectorField(\"embeddings\", vector),\n", "            filter_by=filter_by,\n\t            hits_per_page=k,\n\t        )\n\t        r = self.search(q)\n\t        return [DocWithScore(_h=hit) for hit in r.hits]\n\t    def search(self, query: Query) -> Result:\n\t        return self.index.search(query=query)\n"]}
{"filename": "tigrisdb/errors.py", "chunked_list": ["from typing import cast\n\timport grpc\n\tclass TigrisException(Exception):\n\t    \"\"\"Base class for all TigrisExceptions.\"\"\"\n\t    msg: str\n\t    def __init__(self, msg: str, **kwargs):\n\t        self.msg = msg\n\t        kwargs[\"message\"] = msg\n\t        super(TigrisException, self).__init__(kwargs)\n\t# TODO: make this typesafe\n", "class TigrisServerError(TigrisException):\n\t    def __init__(self, msg: str, e: grpc.RpcError):\n\t        if isinstance(e.code(), grpc.StatusCode):\n\t            self.code = cast(grpc.StatusCode, e.code())\n\t        else:\n\t            self.code = grpc.StatusCode.UNKNOWN\n\t        self.details = e.details()\n\t        super(TigrisServerError, self).__init__(\n\t            msg, code=self.code.name, details=self.details\n\t        )\n", "        self.__suppress_context__ = True\n"]}
{"filename": "tigrisdb/client.py", "chunked_list": ["import os\n\tfrom typing import Union\n\timport grpc\n\tfrom api.generated.server.v1.api_pb2_grpc import TigrisStub\n\tfrom api.generated.server.v1.search_pb2_grpc import SearchStub\n\tfrom tigrisdb.auth import AuthGateway\n\tfrom tigrisdb.database import Database\n\tfrom tigrisdb.errors import TigrisException\n\tfrom tigrisdb.search import Search\n\tfrom tigrisdb.types import ClientConfig\n", "from tigrisdb.vector_store import VectorStore\n\tclass TigrisClient(object):\n\t    __PREVIEW_URI = \"api.preview.tigrisdata.cloud\"\n\t    __tigris_client: TigrisStub\n\t    __search_client: SearchStub\n\t    __config: ClientConfig\n\t    def __init__(self, conf: Union[ClientConfig, dict, None] = None):\n\t        os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n\t        if not conf:\n\t            config = ClientConfig()\n", "        elif isinstance(conf, dict):\n\t            config = ClientConfig()\n\t            config.merge(**conf)\n\t        else:\n\t            config = conf\n\t        if config.server_url.startswith(\"https://\"):\n\t            config.server_url = config.server_url.replace(\"https://\", \"\")\n\t        if config.server_url.startswith(\"http://\"):\n\t            config.server_url = config.server_url.replace(\"http://\", \"\")\n\t        if \":\" not in config.server_url:\n", "            config.server_url = f\"{config.server_url}:443\"\n\t        config.validate()\n\t        if config.is_local_dev():\n\t            channel = grpc.insecure_channel(config.server_url)\n\t        else:\n\t            auth_gtwy = AuthGateway(config)\n\t            channel_creds = grpc.ssl_channel_credentials()\n\t            call_creds = grpc.metadata_call_credentials(auth_gtwy, name=\"auth gateway\")\n\t            channel = grpc.secure_channel(\n\t                config.server_url,\n", "                grpc.composite_channel_credentials(channel_creds, call_creds),\n\t            )\n\t        try:\n\t            grpc.channel_ready_future(channel).result(timeout=10)\n\t        except grpc.FutureTimeoutError:\n\t            raise TigrisException(f\"Connection timed out {config.server_url}\")\n\t        self.__config = config\n\t        self.__tigris_client = TigrisStub(channel)\n\t        self._database = Database(self.__tigris_client, self.__config)\n\t        self.__search_client = SearchStub(channel)\n", "        self._search = Search(self.__search_client, self.__config)\n\t    @property\n\t    def config(self):\n\t        return self.__config\n\t    def get_db(self) -> Database:\n\t        return self._database\n\t    def get_search(self) -> Search:\n\t        return self._search\n\t    def get_vector_store(self, name: str) -> VectorStore:\n\t        return VectorStore(self._search, name)\n"]}
{"filename": "tigrisdb/__init__.py", "chunked_list": ["from tigrisdb.client import TigrisClient  # noqa: F401\n\tfrom tigrisdb.collection import Collection  # noqa: F401\n\tfrom tigrisdb.database import Database  # noqa: F401\n\tfrom tigrisdb.search import Search  # noqa: F401\n\tfrom tigrisdb.search_index import SearchIndex  # noqa: F401\n\tfrom tigrisdb.vector_store import VectorStore  # noqa: F401\n"]}
{"filename": "tigrisdb/utils.py", "chunked_list": ["import base64\n\timport datetime\n\timport json\n\tfrom typing import Any, Union\n\tfrom google.protobuf.timestamp_pb2 import Timestamp as ProtoTimestamp\n\tclass CustomJSONEncoder(json.JSONEncoder):\n\t    def default(self, obj: Any) -> Any:\n\t        if isinstance(obj, datetime.datetime):\n\t            return obj.isoformat()\n\t        return json.JSONEncoder.default(obj)\n", "def obj_to_str(doc: object) -> str:\n\t    return json.dumps(doc, cls=CustomJSONEncoder)\n\tdef str_to_bytes(doc_str: str) -> bytes:\n\t    return doc_str.encode(\"utf-8\")\n\t# todo: add date serialization tests\n\tdef marshal(doc: object) -> bytes:\n\t    return str_to_bytes(obj_to_str(doc))\n\tdef bytes_to_str(b: bytes) -> str:\n\t    return b.decode(\"utf-8\")\n\tdef str_to_obj(doc_str: str) -> object:\n", "    return json.loads(doc_str)\n\t# todo: add date deserialization tests\n\tdef unmarshal(b: bytes) -> Union[object, dict]:\n\t    return str_to_obj(bytes_to_str(b))\n\tdef b64_to_object(b64_str: str) -> object:\n\t    return unmarshal(base64.b64decode(b64_str))\n\tdef obj_to_b64(doc: object) -> str:\n\t    return bytes_to_str(base64.b64encode(marshal(doc)))\n\tdef schema_to_bytes(schema: dict) -> bytes:\n\t    return marshal(schema)\n", "_UTC_ZERO = datetime.datetime.fromtimestamp(0, tz=datetime.timezone.utc)\n\tdef datetime_from_proto_ts(p: ProtoTimestamp):\n\t    delta = datetime.timedelta(seconds=p.seconds, microseconds=p.nanos // 1000)\n\t    return _UTC_ZERO.astimezone(tz=datetime.timezone.utc) + delta\n"]}
{"filename": "tigrisdb/search_index.py", "chunked_list": ["from typing import Iterator, List\n\timport grpc\n\tfrom api.generated.server.v1.search_pb2 import (\n\t    CreateDocumentRequest,\n\t    CreateDocumentResponse,\n\t    CreateOrReplaceDocumentRequest,\n\t    CreateOrReplaceDocumentResponse,\n\t    DeleteDocumentRequest,\n\t    DeleteDocumentResponse,\n\t    GetDocumentRequest,\n", "    GetDocumentResponse,\n\t    SearchIndexRequest,\n\t    SearchIndexResponse,\n\t    UpdateDocumentRequest,\n\t    UpdateDocumentResponse,\n\t)\n\tfrom api.generated.server.v1.search_pb2_grpc import SearchStub\n\tfrom tigrisdb.errors import TigrisServerError\n\tfrom tigrisdb.types import ClientConfig, Document\n\tfrom tigrisdb.types.search import DocStatus, IndexedDoc\n", "from tigrisdb.types.search import Query as SearchQuery\n\tfrom tigrisdb.types.search import Result as SearchResult\n\tfrom tigrisdb.utils import marshal\n\tclass SearchIndex:\n\t    __client: SearchStub\n\t    __config: ClientConfig\n\t    __name: str\n\t    def __init__(self, index_name: str, client: SearchStub, config: ClientConfig):\n\t        self.__client = client\n\t        self.__name = index_name\n", "        self.__config = config\n\t    @property\n\t    def project(self):\n\t        return self.__config.project\n\t    @property\n\t    def name(self):\n\t        return self.__name\n\t    def search(self, query: SearchQuery, page: int = 1) -> SearchResult:\n\t        req = SearchIndexRequest(project=self.project, index=self.name, page=page)\n\t        query.__build__(req)\n", "        try:\n\t            result_iterator: Iterator[SearchIndexResponse] = self.__client.Search(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to search documents\", e)\n\t        # only single page of result will be returned\n\t        for res in result_iterator:\n\t            return SearchResult(_p=res)\n\t    def create_many(self, docs: List[Document]) -> List[DocStatus]:\n\t        doc_bytes = map(marshal, docs)\n\t        req = CreateDocumentRequest(\n", "            project=self.project, index=self.name, documents=doc_bytes\n\t        )\n\t        try:\n\t            resp: CreateDocumentResponse = self.__client.Create(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to index documents\", e)\n\t        return [DocStatus(_p=d) for d in resp.status]\n\t    def create_one(self, doc: Document) -> DocStatus:\n\t        return self.create_many([doc])[0]\n\t    def delete_many(self, doc_ids: List[str]) -> List[DocStatus]:\n", "        req = DeleteDocumentRequest(project=self.project, index=self.name, ids=doc_ids)\n\t        try:\n\t            resp: DeleteDocumentResponse = self.__client.Delete(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to delete documents\", e)\n\t        return [DocStatus(_p=d) for d in resp.status]\n\t    def delete_one(self, doc_id: str) -> DocStatus:\n\t        return self.delete_many([doc_id])[0]\n\t    def delete_by_query(self):\n\t        raise NotImplementedError(\"deletion by filters is not supported yet\")\n", "    def create_or_replace_many(self, docs: List[Document]) -> List[DocStatus]:\n\t        doc_bytes = map(marshal, docs)\n\t        req = CreateOrReplaceDocumentRequest(\n\t            project=self.project, index=self.name, documents=doc_bytes\n\t        )\n\t        try:\n\t            resp: CreateOrReplaceDocumentResponse = self.__client.CreateOrReplace(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to create or replace documents\", e)\n\t        return [DocStatus(_p=d) for d in resp.status]\n", "    def create_or_replace_one(self, doc: Document) -> DocStatus:\n\t        return self.create_or_replace_many([doc])[0]\n\t    def get_many(self, doc_ids: List[str]) -> List[IndexedDoc]:\n\t        req = GetDocumentRequest(project=self.project, index=self.name, ids=doc_ids)\n\t        try:\n\t            resp: GetDocumentResponse = self.__client.Get(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to get documents\", e)\n\t        return [IndexedDoc(_p=hit) for hit in resp.documents]\n\t    def get_one(self, doc_id: str) -> IndexedDoc:\n", "        return self.get_many([doc_id])[0]\n\t    def update_many(self, docs: List[Document]) -> List[DocStatus]:\n\t        doc_bytes = map(marshal, docs)\n\t        req = UpdateDocumentRequest(\n\t            project=self.project, index=self.name, documents=doc_bytes\n\t        )\n\t        try:\n\t            resp: UpdateDocumentResponse = self.__client.Update(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to update documents\", e)\n", "        return [*map(lambda d: DocStatus(_p=d), resp.status)]\n\t    def update_one(self, doc: Document) -> DocStatus:\n\t        return self.update_many([doc])[0]\n"]}
{"filename": "tigrisdb/search.py", "chunked_list": ["import grpc\n\tfrom api.generated.server.v1.search_pb2 import (\n\t    CreateOrUpdateIndexRequest,\n\t    CreateOrUpdateIndexResponse,\n\t    DeleteIndexRequest,\n\t    DeleteIndexResponse,\n\t)\n\tfrom api.generated.server.v1.search_pb2_grpc import SearchStub\n\tfrom tigrisdb.errors import TigrisException, TigrisServerError\n\tfrom tigrisdb.search_index import SearchIndex\n", "from tigrisdb.types import ClientConfig\n\tfrom tigrisdb.utils import schema_to_bytes\n\tclass Search:\n\t    __client: SearchStub\n\t    __config: ClientConfig\n\t    def __init__(self, client: SearchStub, config: ClientConfig):\n\t        self.__client = client\n\t        self.__config = config\n\t    @property\n\t    def project(self):\n", "        return self.__config.project\n\t    def create_or_update_index(self, name: str, schema: dict) -> SearchIndex:\n\t        req = CreateOrUpdateIndexRequest(\n\t            project=self.project, name=name, schema=schema_to_bytes(schema)\n\t        )\n\t        try:\n\t            resp: CreateOrUpdateIndexResponse = self.__client.CreateOrUpdateIndex(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to create search index\", e)\n\t        if resp.status == \"created\":\n", "            return SearchIndex(\n\t                index_name=name, client=self.__client, config=self.__config\n\t            )\n\t        raise TigrisException(f\"Invalid response to create search index: {resp.status}\")\n\t    def delete_index(self, name: str) -> bool:\n\t        req = DeleteIndexRequest(name=name, project=self.project)\n\t        try:\n\t            resp: DeleteIndexResponse = self.__client.DeleteIndex(req)\n\t        except grpc.RpcError as e:\n\t            raise TigrisServerError(\"failed to delete search index\", e)\n", "        return resp.status == \"deleted\"\n\t    def get_index(self, name: str) -> SearchIndex:\n\t        return SearchIndex(index_name=name, client=self.__client, config=self.__config)\n"]}
{"filename": "tigrisdb/types/sort.py", "chunked_list": ["import abc\n\tfrom tigrisdb.types import BaseOperator, Serializable\n\tclass Sort(Serializable, BaseOperator, abc.ABC):\n\t    field = \"\"\n\t    def query(self):\n\t        return {self.field: self.operator}\n\tclass Ascending(Sort):\n\t    def __init__(self, field):\n\t        self.field = field\n\t    @property\n", "    def operator(self):\n\t        return \"$asc\"\n\tclass Descending(Sort):\n\t    def __init__(self, field):\n\t        self.field = field\n\t    @property\n\t    def operator(self):\n\t        return \"$desc\"\n"]}
{"filename": "tigrisdb/types/__init__.py", "chunked_list": ["import abc\n\timport os\n\tfrom dataclasses import dataclass\n\tfrom typing import Dict, Optional, Type\n\tDocument: Type[dict] = Dict\n\t@dataclass\n\tclass ClientConfig:\n\t    project: str = \"\"\n\t    client_id: Optional[str] = None\n\t    client_secret: Optional[str] = None\n", "    branch: str = \"\"\n\t    server_url: str = \"\"\n\t    def __post_init__(self):\n\t        self.server_url = self.server_url or os.getenv(\n\t            \"TIGRIS_URI\", \"api.preview.tigrisdata.cloud\"\n\t        )\n\t        self.project = self.project or os.getenv(\"TIGRIS_PROJECT\")\n\t        self.client_id = self.client_id or os.getenv(\"TIGRIS_CLIENT_ID\")\n\t        self.client_secret = self.client_secret or os.getenv(\"TIGRIS_CLIENT_SECRET\")\n\t        self.branch = self.branch or os.getenv(\"TIGRIS_DB_BRANCH\", \"\")\n", "    def merge(self, **kwargs):\n\t        self.project = kwargs.get(\"project\", self.project)\n\t        self.server_url = kwargs.get(\"server_url\", self.server_url)\n\t        self.client_id = kwargs.get(\"client_id\", self.client_id)\n\t        self.client_secret = kwargs.get(\"client_secret\", self.client_secret)\n\t        self.branch = kwargs.get(\"branch\", self.branch)\n\t    def is_local_dev(self) -> bool:\n\t        return any(\n\t            map(\n\t                lambda k: k in self.server_url,\n", "                [\"localhost\", \"127.0.0.1\", \"tigrisdb-local-server:\", \"[::1]\"],\n\t            )\n\t        )\n\t    def validate(self):\n\t        is_remote = not self.is_local_dev()\n\t        if not self.project:\n\t            raise ValueError(\"Failed to resolve `TIGRIS_PROJECT` environment variable\")\n\t        if is_remote and not self.client_id:\n\t            raise ValueError(\n\t                \"Failed to resolve `TIGRIS_CLIENT_ID` environment variable\"\n", "            )\n\t        if is_remote and not self.client_secret:\n\t            raise ValueError(\n\t                \"Failed to resolve `TIGRIS_CLIENT_SECRET` environment variable\"\n\t            )\n\tclass Serializable(abc.ABC):\n\t    @abc.abstractmethod\n\t    def query(self) -> Dict:\n\t        raise NotImplementedError()\n\tclass BaseOperator(abc.ABC):\n", "    @property\n\t    @abc.abstractmethod\n\t    def operator(self):\n\t        raise NotImplementedError()\n"]}
{"filename": "tigrisdb/types/vector.py", "chunked_list": ["from dataclasses import InitVar, dataclass\n\tfrom typing import Dict, List, TypedDict\n\tfrom tigrisdb.types.search import IndexedDoc, dataclass_default_proto_field\n\tclass Document(TypedDict, total=False):\n\t    id: str\n\t    text: str\n\t    embeddings: List[float]\n\t    metadata: Dict\n\t@dataclass\n\tclass DocWithScore:\n", "    doc: Document = None\n\t    score: float = 0.0\n\t    _h: InitVar[IndexedDoc] = dataclass_default_proto_field\n\t    def __post_init__(self, _h: IndexedDoc):\n\t        if _h and _h.doc:\n\t            self.doc = _h.doc\n\t        if _h and _h.meta:\n\t            self.score = _h.meta.text_match.vector_distance\n"]}
{"filename": "tigrisdb/types/search.py", "chunked_list": ["from dataclasses import InitVar, dataclass, field\n\tfrom datetime import datetime\n\tfrom typing import Dict, List, Optional, Union\n\tfrom api.generated.server.v1.api_pb2 import FacetCount as ProtoFacetCount\n\tfrom api.generated.server.v1.api_pb2 import FacetStats as ProtoFacetStats\n\tfrom api.generated.server.v1.api_pb2 import GroupedSearchHits as ProtoGroupedHits\n\tfrom api.generated.server.v1.api_pb2 import Match as ProtoMatch\n\tfrom api.generated.server.v1.api_pb2 import Page as ProtoPage\n\tfrom api.generated.server.v1.api_pb2 import SearchFacet as ProtoSearchFacet\n\tfrom api.generated.server.v1.api_pb2 import SearchHit as ProtoSearchHit\n", "from api.generated.server.v1.api_pb2 import SearchHitMeta as ProtoSearchHitMeta\n\tfrom api.generated.server.v1.api_pb2 import SearchMetadata as ProtoSearchMeta\n\tfrom api.generated.server.v1.search_pb2 import DocStatus as ProtoDocStatus\n\tfrom api.generated.server.v1.search_pb2 import (\n\t    SearchIndexRequest as ProtoSearchIndexRequest,\n\t)\n\tfrom api.generated.server.v1.search_pb2 import (\n\t    SearchIndexResponse as ProtoSearchIndexResponse,\n\t)\n\tfrom tigrisdb.errors import TigrisException\n", "from tigrisdb.types import Document, Serializable\n\tfrom tigrisdb.types.filters import Filter\n\tfrom tigrisdb.types.sort import Sort\n\tfrom tigrisdb.utils import datetime_from_proto_ts, marshal, unmarshal\n\tdataclass_default_proto_field = field(\n\t    default=None, repr=False, compare=False, hash=False\n\t)\n\t@dataclass\n\tclass FacetSize(Serializable):\n\t    field: str\n", "    size: int = 10\n\t    def query(self):\n\t        return {\"size\": self.size, \"type\": \"value\"}\n\tFacetField = Union[str, FacetSize]\n\t@dataclass\n\tclass VectorField(Serializable):\n\t    field: str\n\t    vector: List[float]\n\t    def query(self):\n\t        return {self.field: self.vector}\n", "@dataclass\n\tclass Query:\n\t    q: str = \"\"\n\t    search_fields: List[str] = field(default_factory=list)\n\t    vector_query: VectorField = None\n\t    filter_by: Optional[Filter] = None\n\t    facet_by: Union[str, List[FacetField]] = field(default_factory=list)\n\t    sort_by: Union[Sort, List[Sort]] = field(default_factory=list)\n\t    group_by: Union[str, List[str]] = field(default_factory=list)\n\t    include_fields: List[str] = field(default_factory=list)\n", "    exclude_fields: List[str] = field(default_factory=list)\n\t    hits_per_page: int = 20\n\t    def __build__(self, req: ProtoSearchIndexRequest):\n\t        req.q = self.q or \"\"\n\t        if self.search_fields:\n\t            req.search_fields.extend(self.search_fields)\n\t        if self.vector_query:\n\t            req.vector = marshal(self.vector_query.query())\n\t        if self.filter_by:\n\t            req.filter = marshal(self.filter_by.query())\n", "        if self.facet_by:\n\t            f = {}\n\t            if isinstance(self.facet_by, str):\n\t                f[self.facet_by] = FacetSize(self.facet_by).query()\n\t            elif isinstance(self.facet_by, list):\n\t                for facet in self.facet_by:\n\t                    if isinstance(facet, str):\n\t                        f[facet] = FacetSize(facet).query()\n\t                    elif isinstance(facet, FacetSize):\n\t                        f[facet.field] = facet.query()\n", "            req.facet = marshal(f)\n\t        if self.sort_by:\n\t            order = []\n\t            if isinstance(self.sort_by, Sort):\n\t                order.append(self.sort_by.query())\n\t            elif isinstance(self.sort_by, list):\n\t                order = [s.query() for s in self.sort_by]\n\t            req.sort = marshal(order)\n\t        if self.group_by:\n\t            g = [self.group_by] if isinstance(self.group_by, str) else self.group_by\n", "            req.group_by = marshal(g)\n\t        if self.include_fields:\n\t            req.include_fields.extend(self.include_fields)\n\t        if self.exclude_fields:\n\t            req.exclude_fields.extend(self.exclude_fields)\n\t        req.page_size = self.hits_per_page\n\t# Search result fields\n\t@dataclass\n\tclass DocStatus:\n\t    id: str = None\n", "    error: Optional[TigrisException] = None\n\t    _p: InitVar[ProtoDocStatus] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoDocStatus):\n\t        if _p:\n\t            if _p.HasField(\"error\"):\n\t                self.error = TigrisException(_p.error.message)\n\t            if _p.id:\n\t                self.id = _p.id\n\t@dataclass\n\tclass TextMatchInfo:\n", "    score: Optional[str] = None\n\t    vector_distance: Optional[float] = None\n\t    fields: List[str] = field(default_factory=list)\n\t    _p: InitVar[ProtoMatch] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoMatch):\n\t        if _p:\n\t            self.fields = [f.name for f in _p.fields]\n\t            if _p.HasField(\"vector_distance\"):\n\t                self.vector_distance = _p.vector_distance\n\t            if _p.score:\n", "                self.score = _p.score\n\t@dataclass\n\tclass DocMeta:\n\t    created_at: Optional[datetime] = None\n\t    updated_at: Optional[datetime] = None\n\t    text_match: TextMatchInfo = field(default_factory=TextMatchInfo)\n\t    _p: InitVar[ProtoSearchHitMeta] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoSearchHitMeta):\n\t        if _p:\n\t            if _p.HasField(\"created_at\"):\n", "                self.created_at = datetime_from_proto_ts(_p.created_at)\n\t            if _p.HasField(\"updated_at\"):\n\t                self.updated_at = datetime_from_proto_ts(_p.updated_at)\n\t            if _p.HasField(\"match\"):\n\t                self.text_match = TextMatchInfo(_p=_p.match)\n\t@dataclass\n\tclass IndexedDoc:\n\t    doc: Optional[Document] = None\n\t    meta: DocMeta = field(default_factory=DocMeta)\n\t    _p: InitVar[ProtoSearchHit] = dataclass_default_proto_field\n", "    def __post_init__(self, _p: ProtoSearchHit):\n\t        if _p:\n\t            if _p.data:\n\t                self.doc = unmarshal(_p.data)\n\t            if _p.HasField(\"metadata\"):\n\t                self.meta = DocMeta(_p=_p.metadata)\n\t@dataclass\n\tclass GroupedHits:\n\t    keys: [str] = field(default_factory=list)\n\t    hits: [IndexedDoc] = field(default_factory=list)\n", "    _p: InitVar[ProtoGroupedHits] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoGroupedHits):\n\t        if _p:\n\t            self.keys = _p.group_keys\n\t            self.hits = [IndexedDoc(_p=h) for h in _p.hits]\n\t@dataclass\n\tclass FacetCount:\n\t    value: Optional[str] = None\n\t    count: Optional[int] = None\n\t    _p: InitVar[ProtoFacetCount] = dataclass_default_proto_field\n", "    def __post_init__(self, _p: ProtoFacetCount):\n\t        if _p:\n\t            self.value = _p.value\n\t            self.count = _p.count\n\t@dataclass\n\tclass FacetStats:\n\t    count: int = 0\n\t    sum: Optional[float] = None\n\t    avg: Optional[float] = None\n\t    max: Optional[float] = None\n", "    min: Optional[float] = None\n\t    _p: InitVar[ProtoFacetStats] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoFacetStats):\n\t        if _p:\n\t            self.count = _p.count\n\t            if _p.HasField(\"sum\"):\n\t                self.sum = _p.sum\n\t            if _p.HasField(\"avg\"):\n\t                self.avg = _p.avg\n\t            if _p.HasField(\"max\"):\n", "                self.max = _p.max\n\t            if _p.HasField(\"min\"):\n\t                self.min = _p.min\n\t@dataclass\n\tclass Facets:\n\t    counts: [FacetCount] = field(default_factory=list)\n\t    stats: FacetStats = field(default_factory=FacetStats)\n\t    _p: InitVar[ProtoSearchFacet] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoSearchFacet):\n\t        if _p:\n", "            if _p.HasField(\"stats\"):\n\t                self.stats = FacetStats(_p=_p.stats)\n\t            self.counts = [FacetCount(_p=fc) for fc in _p.counts]\n\t@dataclass\n\tclass Page:\n\t    current: int = 1\n\t    size: int = 20\n\t    _p: InitVar[ProtoPage] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoPage):\n\t        if _p:\n", "            if _p.current:\n\t                self.current = _p.current\n\t            self.size = _p.size\n\t@dataclass\n\tclass Meta:\n\t    found: int = 0\n\t    total_pages: int = 1\n\t    page: Page = field(default_factory=Page)\n\t    _p: InitVar[ProtoSearchMeta] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoSearchMeta):\n", "        if _p:\n\t            if _p.HasField(\"page\"):\n\t                self.page = Page(_p=_p.page)\n\t            self.found = _p.found\n\t            if _p.total_pages:\n\t                self.total_pages = _p.total_pages\n\t@dataclass\n\tclass Result:\n\t    hits: List[IndexedDoc] = field(default_factory=list)\n\t    facets: Dict[str, Facets] = field(default_factory=dict)\n", "    meta: Meta = field(default_factory=Meta)\n\t    grouped_hits: [GroupedHits] = field(default_factory=list)\n\t    _p: InitVar[ProtoSearchIndexResponse] = dataclass_default_proto_field\n\t    def __post_init__(self, _p: ProtoSearchIndexResponse):\n\t        if _p:\n\t            self.hits = [IndexedDoc(_p=h) for h in _p.hits]\n\t            self.grouped_hits = [GroupedHits(_p=g) for g in _p.group]\n\t            self.facets = {k: Facets(_p=v) for k, v in _p.facets.items()}\n\t            if _p.HasField(\"meta\"):\n\t                self.meta = Meta(_p=_p.meta)\n"]}
{"filename": "tigrisdb/types/filters/logical.py", "chunked_list": ["import abc\n\tfrom typing import Any, Dict, Union\n\tfrom tigrisdb.types import BaseOperator, Serializable\n\tfrom .selector import SelectorFilter\n\tclass LogicalFilter(Serializable, BaseOperator, abc.ABC):\n\t    def __init__(self, *args: Union[SelectorFilter, Any]):\n\t        self.filters = args\n\t    def query(self) -> Dict:\n\t        if not self.filters:\n\t            return {}\n", "        if len(self.filters) == 1:\n\t            return self.filters[0].query()\n\t        gen = [f.query() for f in self.filters]\n\t        return {self.operator: gen}\n\tclass And(LogicalFilter):\n\t    @property\n\t    def operator(self):\n\t        return \"$and\"\n\tclass Or(LogicalFilter):\n\t    @property\n", "    def operator(self):\n\t        return \"$or\"\n"]}
{"filename": "tigrisdb/types/filters/__init__.py", "chunked_list": ["from typing import Union\n\tfrom .logical import And, LogicalFilter, Or  # noqa: F401\n\tfrom .selector import (  # noqa: F401\n\t    GT,\n\t    GTE,\n\t    LT,\n\t    LTE,\n\t    Contains,\n\t    Eq,\n\t    Not,\n", "    Regex,\n\t    SelectorFilter,\n\t)\n\tFilter = Union[LogicalFilter, SelectorFilter]\n"]}
{"filename": "tigrisdb/types/filters/selector.py", "chunked_list": ["import abc\n\tfrom typing import Any, Dict\n\tfrom tigrisdb.types import BaseOperator, Serializable\n\tclass SelectorFilter(Serializable, BaseOperator, abc.ABC):\n\t    def __init__(self, field: str, value: Any):\n\t        self.field = field\n\t        self.value = value\n\t    def query(self) -> Dict:\n\t        return {self.field: {self.operator: self.value}}\n\tclass Eq(SelectorFilter):\n", "    @property\n\t    def operator(self):\n\t        return \"\"\n\t    def query(self) -> Dict:\n\t        return {self.field: self.value}\n\tclass Not(SelectorFilter):\n\t    @property\n\t    def operator(self):\n\t        return \"$not\"\n\tclass GT(SelectorFilter):\n", "    @property\n\t    def operator(self):\n\t        return \"$gt\"\n\tclass GTE(SelectorFilter):\n\t    @property\n\t    def operator(self):\n\t        return \"$gte\"\n\tclass LT(SelectorFilter):\n\t    @property\n\t    def operator(self):\n", "        return \"$lt\"\n\tclass LTE(SelectorFilter):\n\t    @property\n\t    def operator(self):\n\t        return \"$lte\"\n\tclass Regex(SelectorFilter):\n\t    @property\n\t    def operator(self):\n\t        return \"$regex\"\n\tclass Contains(SelectorFilter):\n", "    @property\n\t    def operator(self):\n\t        return \"$contains\"\n"]}
