{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\tfrom pathlib import Path\n\tthis_directory = Path(__file__).parent\n\tlong_description = (this_directory / \"README.md\").read_text()\n\tsetup(\n\t    name=\"nail\",\n\t    version=\"0.1.2\",\n\t    description=\"A CLI tool for speeding up development using LLMs\",\n\t    packages=find_packages(),\n\t    install_requires=[\n", "        \"click\",\n\t        \"openai\",\n\t        \"termcolor\",\n\t        \"PyYAML\",\n\t        \"rich\",\n\t    ],\n\t    entry_points=\"\"\"\n\t        [console_scripts]\n\t        nail=nail.main:main\n\t    \"\"\",\n", "    long_description=long_description,\n\t    long_description_content_type=\"text/markdown\",\n\t    author=\"Edward Saavedra\",\n\t    author_email=\"edsaav@gmail.com\",\n\t    url=\"https://github.com/edsaav/nail\",\n\t    classifiers=[\n\t        \"Programming Language :: Python :: 3\",\n\t        \"License :: OSI Approved :: MIT License\",\n\t        \"Operating System :: OS Independent\",\n\t    ],\n", ")\n"]}
{"filename": "nail/main.py", "chunked_list": ["import click\n\tfrom nail.tools.build_file import build_file\n\tfrom nail.tools.build_readme import build_readme\n\tfrom nail.tools.modify_file import modify_file\n\tfrom nail.tools.debug_file import debug_file\n\tfrom nail.tools.build_spec_file import build_spec_file\n\tfrom nail.tools.explain_file import explain_file\n\tfrom nail.core.config.user_config_utils import save_api_key\n\tMODEL_HELP = (\n\t    \"Optionally specify an LLM model. \"\n", "    + \"Currently defaults to gpt-3.5-turbo and supports gpt-4.\"\n\t)\n\t@click.group()\n\tdef main():\n\t    pass\n\t@main.command()\n\t@click.option(\"--api_key\", prompt=True, hide_input=True, help=\"Your OpenAI API key.\")\n\tdef configure(api_key):\n\t    save_api_key(api_key)\n\t    click.echo(\"API key saved successfully.\")\n", "@main.command()\n\t@click.argument(\"file\")\n\t@click.option(\n\t    \"--context-files\",\n\t    \"-c\",\n\t    multiple=True,\n\t    type=str,\n\t    help=\"Optional list of context file paths.\",\n\t)\n\t@click.option(\"--model\", \"-m\", type=str, help=MODEL_HELP)\n", "def build(file, context_files, model):\n\t    \"\"\"Build a new file with optional context files.\"\"\"\n\t    click.echo(f\"Building a new file: {file}\")\n\t    if context_files:\n\t        click.echo(f\"Using context files: {', '.join(context_files)}\")\n\t    build_file(file, context_files, model)\n\t@main.command()\n\t@click.option(\"--model\", \"-m\", type=str, help=MODEL_HELP)\n\tdef readme(model):\n\t    \"\"\"Build a new README file based on the currect directory.\"\"\"\n", "    click.echo(\"Generating README file.\")\n\t    build_readme(\"README.md\", model)\n\t@main.command()\n\t@click.argument(\"file\")\n\t@click.option(\n\t    \"--request\",\n\t    \"-r\",\n\t    prompt=\"Requested change\",\n\t    help=\"The modification that you are requesting.\",\n\t)\n", "@click.option(\n\t    \"--context-files\",\n\t    \"-c\",\n\t    multiple=True,\n\t    type=str,\n\t    help=\"Optional list of context file paths.\",\n\t)\n\t@click.option(\"--model\", \"-m\", type=str, help=MODEL_HELP)\n\tdef modify(file, request, context_files, model):\n\t    \"\"\"Modify an existing file.\"\"\"\n", "    click.echo(f\"Modifying file: {file}\")\n\t    if context_files:\n\t        click.echo(f\"Using context files: {', '.join(context_files)}\")\n\t    modify_file(file, request, context_files, model)\n\t@main.command()\n\t@click.argument(\"file\")\n\t@click.option(\n\t    \"--error\", \"-e\", default=None, prompt=False, help=\"Optional error message to debug.\"\n\t)\n\t@click.option(\"--model\", \"-m\", type=str, help=MODEL_HELP)\n", "def debug(file, error, model):\n\t    \"\"\"Debug an existing file. May include an optional error message\"\"\"\n\t    click.echo(f\"Debugging file: {file}\")\n\t    if error:\n\t        click.echo(f\"Error message: {error}\")\n\t    debug_file(file, error, model)\n\t@main.command()\n\t@click.argument(\"file\")\n\t@click.argument(\"target_path\")\n\t@click.option(\"--model\", \"-m\", type=str, help=MODEL_HELP)\n", "def spec(file, target_path, model):\n\t    \"\"\"Build a unit test file for an existing file.\"\"\"\n\t    click.echo(f\"Building spec file for: {file}\")\n\t    click.echo(f\"Target path: {target_path}\")\n\t    build_spec_file(file, target_path, model)\n\t@main.command()\n\t@click.argument(\"file\")\n\t@click.option(\n\t    \"--context-files\",\n\t    \"-c\",\n", "    multiple=True,\n\t    type=str,\n\t    help=\"Optional list of context file paths.\",\n\t)\n\t@click.option(\"--verbose\", \"-v\", is_flag=True, help=\"Verbose output.\")\n\t@click.option(\"--model\", \"-m\", type=str, help=MODEL_HELP)\n\tdef explain(file, context_files, verbose, model):\n\t    \"\"\"Explain the contents of a file.\"\"\"\n\t    click.echo(f\"Explaining: {file}\")\n\t    explain_file(file, context_files, {\"verbose\": verbose}, model)\n", "if __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "nail/__init__.py", "chunked_list": []}
{"filename": "nail/tools/explain_file.py", "chunked_list": ["from rich.console import Console\n\tfrom rich.markdown import Markdown\n\tfrom nail.core.chat import Chat\n\tfrom nail.core.prompt.prompt import ExplainPrompt\n\tdef explain_file(file_path, context_file_paths=None, verbose=False, model=None):\n\t    prompt = ExplainPrompt(file_path, context_file_paths, {\"verbose\": verbose}).text()\n\t    explanation = Chat(model).predict(prompt)\n\t    Console().print(Markdown(explanation))\n"]}
{"filename": "nail/tools/build_spec_file.py", "chunked_list": ["from nail.core.chat import Chat\n\tfrom nail.core.file_editor import FileEditor\n\tfrom nail.core.prompt.prompt import SpecPrompt\n\tdef build_spec_file(file_path, target_file_path, model=None):\n\t    prompt = SpecPrompt(file_path).text()\n\t    test_file_content = Chat(model).predict_code(prompt)\n\t    FileEditor(target_file_path).apply_changes(test_file_content)\n"]}
{"filename": "nail/tools/__init__.py", "chunked_list": []}
{"filename": "nail/tools/modify_file.py", "chunked_list": ["from nail.core.file_editor import FileEditor\n\tfrom nail.core.chat import Chat\n\tfrom nail.core.prompt.prompt import ModifyPrompt\n\tdef modify_file(file_path, request, context_file_paths=None, model=None):\n\t    prompt = ModifyPrompt(\n\t        file_path, context_file_paths, details={\"request\": request}\n\t    ).text()\n\t    modified_contents = Chat(model).predict_code(prompt)\n\t    FileEditor(file_path).apply_changes(modified_contents)\n"]}
{"filename": "nail/tools/build_readme.py", "chunked_list": ["from nail.core.file_editor import FileEditor\n\tfrom nail.core.chat import Chat\n\tfrom nail.core.prompt.prompt import BuildReadmePrompt\n\tdef build_readme(readme_file_path, model=None):\n\t    \"\"\"\n\t    Gathers context from all files in the current directory, builds a prompt for\n\t    OpenAI to generate a README file for the application, calls the predict_readme\n\t    method, and writes the generated file to the specified path.\n\t    :param readme_file_path: Path to save the generated README file\n\t    \"\"\"\n", "    prompt = BuildReadmePrompt().text()\n\t    readme_contents = Chat(model).predict(prompt)\n\t    FileEditor(readme_file_path).apply_changes(readme_contents)\n"]}
{"filename": "nail/tools/debug_file.py", "chunked_list": ["from nail.core.file_editor import FileEditor\n\tfrom nail.core.chat import Chat, ModelCodeGenerationError\n\tfrom nail.core.prompt.prompt import DebugPrompt\n\tNO_BUGS_MESSAGE = \"No bugs were found in the file.\"\n\tdef debug_file(file_path, error_message, model=None):\n\t    file = FileEditor(file_path)\n\t    prompt = DebugPrompt(file_path, details={\"error_message\": error_message}).text()\n\t    try:\n\t        modified_contents = Chat(model).predict_code(prompt)\n\t    except ModelCodeGenerationError:\n", "        print(NO_BUGS_MESSAGE)\n\t        return\n\t    file.apply_changes(modified_contents)\n"]}
{"filename": "nail/tools/build_file.py", "chunked_list": ["from nail.core.file_editor import FileEditor\n\tfrom nail.core.chat import Chat\n\tfrom nail.core.prompt.prompt import BuildPrompt\n\tdef build_file(file_path, context_file_paths=None, model=None):\n\t    file = FileEditor(file_path)\n\t    if not file.exists():\n\t        file.open_editor()\n\t    prompt = BuildPrompt(file_path, context_file_paths).text()\n\t    draft_contents = Chat(model).predict_code(prompt)\n\t    file.apply_changes(draft_contents)\n"]}
{"filename": "nail/core/loading_decorator.py", "chunked_list": ["import itertools\n\timport sys\n\timport time\n\tfrom threading import Event, Thread\n\tANIMATION_FRAME_SECONDS = 0.04\n\tDEFAULT_LOADING_MESSAGE = \"Loading...\"\n\tFRAMES = [\n\t    \"|==========>                    |\",\n\t    \" |==========>                   |\",\n\t    \"  |==========>                  |\",\n", "    \"   |==========>                 |\",\n\t    \"    |==========>                |\",\n\t    \"     |==========>               |\",\n\t    \"      |==========>              |\",\n\t    \"       |==========>             |\",\n\t    \"        |==========>            |\",\n\t    \"         |==========>           |\",\n\t    \"          |==========>          |\",\n\t    \"           |==========>         |\",\n\t    \"            |==========>        |\",\n", "    \"             |==========>       |\",\n\t    \"              |==========>      |\",\n\t    \"               |==========>     |\",\n\t    \"                |==========>    |\",\n\t    \"                 |==========>   |\",\n\t    \"                  |==========>  |\",\n\t    \"                   |==========> |\",\n\t    \"                    |==========>|\",\n\t    \"                     |==========|\",\n\t    \"                      |=========|\",\n", "    \"                       |========|\",\n\t    \"                        |=======|\",\n\t    \"                         |======|\",\n\t    \"                          |=====|\",\n\t    \"                           |====|\",\n\t    \"                            |===|\",\n\t    \"                             |==|\",\n\t    \"                              |=|\",\n\t    \"                               ||\",\n\t    \"                               ||\",\n", "    \"                               ||\",\n\t    \"                               ||\",\n\t    \"                               ||\",\n\t    \"                               ||\",\n\t    \">                               |\",\n\t    \"=>                              |\",\n\t    \"==>                             |\",\n\t    \"===>                            |\",\n\t    \"====>                           |\",\n\t    \"=====>                          |\",\n", "    \"======>                         |\",\n\t    \"=======>                        |\",\n\t    \"========>                       |\",\n\t    \"=========>                      |\",\n\t    \"==========>                     |\",\n\t]\n\tdef loadable(func, loading_message):\n\t    \"\"\"\n\t    This decorator is used to display a loading animation\n\t    while a function is running.\n", "    :param func: The function to be decorated\n\t    :param loading_message: The message to be displayed before the animation\n\t    \"\"\"\n\t    def wrapper(*args, **kwargs):\n\t        # Start a thread to display the loading animation\n\t        stop_loading = Event()\n\t        loader_thread = Thread(\n\t            target=_loading,\n\t            args=(\n\t                stop_loading,\n", "                loading_message,\n\t            ),\n\t        )\n\t        loader_thread.start()\n\t        try:\n\t            result = func(*args, **kwargs)\n\t        except Exception as e:\n\t            # Stop the loading animation thread if an error occurs\n\t            _clear_loader(stop_loading, loader_thread, loading_message)\n\t            raise e\n", "        _clear_loader(stop_loading, loader_thread, loading_message)\n\t        return result\n\t    return wrapper\n\tdef _loading(stop_loading, loading_message):\n\t    while not stop_loading.is_set():\n\t        _display_loader(stop_loading, loading_message)\n\tdef _display_loader(stop_loading, prefix=DEFAULT_LOADING_MESSAGE):\n\t    spinner = itertools.cycle(FRAMES)\n\t    while not stop_loading.is_set():\n\t        sys.stdout.write(f\"{prefix}{next(spinner)}\")\n", "        sys.stdout.flush()\n\t        time.sleep(ANIMATION_FRAME_SECONDS)\n\t        sys.stdout.write(\"\\r\")\n\t    sys.stdout.write(\"\\n\")\n\tdef _clear_loader(stop_loading, loader_thread, loading_message):\n\t    # Stop the loading animation thread\n\t    stop_loading.set()\n\t    # Erase the animation line after the decorated function completes\n\t    sys.stdout.write(\"\\r\" + \" \" * (len(loading_message) + len(FRAMES[-1])) + \"\\r\")\n\t    sys.stdout.flush()\n", "    loader_thread.join()\n"]}
{"filename": "nail/core/__init__.py", "chunked_list": []}
{"filename": "nail/core/file_editor.py", "chunked_list": ["import os\n\timport subprocess\n\timport difflib\n\tfrom termcolor import colored\n\tclass MissingFilePathError(ValueError):\n\t    def __str__(self):\n\t        return \"A file path is required when creating a FileEditor instance.\"\n\tclass FileEditor:\n\t    CONFIRMATION_REQUEST = \"Do you want to apply the changes? (y/n): \"\n\t    CONFIRMATION_CHARACTER = \"y\"\n", "    CHANGES_APPLIED_TEXT = \"Changes applied to: \"\n\t    CHANGES_DISCARDED_TEXT = \"Changes discarded.\"\n\t    DEFAULT_EDITOR = \"vim\"\n\t    def __init__(self, file_path=None):\n\t        if file_path is None:\n\t            raise MissingFilePathError\n\t        self.file_path = file_path\n\t    def exists(self):\n\t        \"\"\"\n\t        Returns True if the file exists, False otherwise.\n", "        \"\"\"\n\t        return os.path.exists(self.file_path)\n\t    def content(self):\n\t        \"\"\"\n\t        Reads the file and returns the content as a string.\n\t        \"\"\"\n\t        with open(self.file_path, \"r\") as file:\n\t            content = file.read()\n\t        return content\n\t    def open_editor(self):\n", "        \"\"\"\n\t        Opens the file in the default editor\n\t        \"\"\"\n\t        editor = os.environ.get(\"EDITOR\", self.DEFAULT_EDITOR)\n\t        subprocess.call([editor, self.file_path])\n\t    def apply_changes(self, content):\n\t        \"\"\"\n\t        Takes a file and content string as inputs. It generates a diff\n\t        comparing the string to the contents of the file. It then displays\n\t        the diff and asks the user to confirm the changes. If they confirm,\n", "        it writes the content to the file.\n\t        :param content: The content to be written to the file\n\t        \"\"\"\n\t        diff = self._calculate_diff(content)\n\t        confirmed = self._get_confirmation(diff)\n\t        if confirmed:\n\t            self._write(content)\n\t            print(f\"{self.CHANGES_APPLIED_TEXT}{self.file_path}\")\n\t            return True\n\t        print(self.CHANGES_DISCARDED_TEXT)\n", "        return False\n\t    def _write(self, content):\n\t        with open(self.file_path, \"w\") as file:\n\t            file.write(content)\n\t    def _get_confirmation(self, diff):\n\t        self._print_diff(diff)\n\t        response = input(self.CONFIRMATION_REQUEST)\n\t        if response.lower() == self.CONFIRMATION_CHARACTER:\n\t            return True\n\t        return False\n", "    def _calculate_diff(self, content):\n\t        if self.exists():\n\t            file_content = self.content()\n\t        else:\n\t            file_content = \"\"\n\t        return difflib.unified_diff(\n\t            file_content.splitlines(), content.splitlines(), lineterm=\"\"\n\t        )\n\t    def _print_diff(self, diff):\n\t        for line in diff:\n", "            self._print_colored_line(line)\n\t    def _print_colored_line(self, line):\n\t        if line.startswith(\"+\"):\n\t            print(colored(line, \"green\"))\n\t        elif line.startswith(\"-\"):\n\t            print(colored(line, \"red\"))\n\t        else:\n\t            print(line)\n"]}
{"filename": "nail/core/chat.py", "chunked_list": ["import re\n\tfrom nail.core.loading_decorator import loadable\n\tfrom nail.core.language_models.supported_models import SUPPORTED_MODELS, DEFAULT_MODEL\n\tfrom nail.core.config.local_config_utils import load_local_config\n\tclass InvalidModelError(Exception):\n\t    pass\n\tclass ModelCodeGenerationError(Exception):\n\t    pass\n\tclass Chat:\n\t    def __init__(self, model_name=None):\n", "        self._set_llm_model(model_name)\n\t    def predict(self, prompt):\n\t        create_completion = loadable(self.model.respond, \"Loading response...\")\n\t        return create_completion(prompt)\n\t    def predict_code(self, prompt):\n\t        create_completion = loadable(self.model.respond_with_code, \"Generating code...\")\n\t        completion = create_completion(prompt)\n\t        return self._extract_code(completion)\n\t    def _extract_code(self, text):\n\t        # regex for text wrapped in triple backticks\n", "        # and optional language identifier\n\t        code_block_pattern = r\"^```(?:\\w+)?\\n([\\s\\S]*?)\\n```\"\n\t        code_blocks = re.findall(code_block_pattern, text, re.MULTILINE)\n\t        try:\n\t            return code_blocks[0]\n\t        except IndexError:\n\t            err_msg = f\"Model ({self.model_name}) failed to respond with code\"\n\t            raise ModelCodeGenerationError(err_msg)\n\t    def _set_llm_model(self, model_name):\n\t        self.model_name = self._default_model if model_name is None else model_name\n", "        try:\n\t            self.model = SUPPORTED_MODELS[self.model_name]()\n\t        except KeyError:\n\t            raise InvalidModelError(f\"Unsupported model: {self.model_name}\")\n\t    @property\n\t    def _default_model(self):\n\t        custom_default = load_local_config().get(\"default_model\")\n\t        if custom_default is not None:\n\t            return custom_default\n\t        return DEFAULT_MODEL\n"]}
{"filename": "nail/core/config/user_config_utils.py", "chunked_list": ["import os\n\timport configparser\n\tfrom pathlib import Path\n\tUSER_CONFIG_FILE = Path.home() / \".nailrc\"\n\tdef get_api_key():\n\t    if \"OPENAI_API_KEY\" in os.environ:\n\t        return os.environ[\"OPENAI_API_KEY\"]\n\t    if USER_CONFIG_FILE.is_file():\n\t        config = configparser.ConfigParser()\n\t        config.read(USER_CONFIG_FILE)\n", "        if \"openai\" in config and \"api_key\" in config[\"openai\"]:\n\t            return config[\"openai\"][\"api_key\"]\n\t    return None\n\tdef save_api_key(api_key):\n\t    config = configparser.ConfigParser()\n\t    if USER_CONFIG_FILE.is_file():\n\t        config.read(USER_CONFIG_FILE)\n\t    if \"openai\" not in config:\n\t        config[\"openai\"] = {}\n\t    config[\"openai\"][\"api_key\"] = api_key\n", "    with USER_CONFIG_FILE.open(\"w\") as config_file:\n\t        config.write(config_file)\n"]}
{"filename": "nail/core/config/__init__.py", "chunked_list": []}
{"filename": "nail/core/config/local_config_utils.py", "chunked_list": ["import os\n\timport yaml\n\tCONFIG_FILE_NAME = \".nail.yaml\"\n\tdef load_local_config():\n\t    config = {}\n\t    if os.path.exists(CONFIG_FILE_NAME):\n\t        with open(CONFIG_FILE_NAME, \"r\") as file:\n\t            config = yaml.safe_load(file)\n\t    return config\n"]}
{"filename": "nail/core/prompt/formatting_utils.py", "chunked_list": ["# Formatting Utilities\n\tdef file_block(file_path):\n\t    \"\"\"\n\t    Returns a formatted code block containing the contents of the file at\n\t    the given file path.\n\t    :param file_path: The path to the file to be formatted.\n\t    :return: A formatted code block string containing the contents of the\n\t    file at the given file path.\n\t    \"\"\"\n\t    with open(file_path, \"r\") as file:\n", "        file_content = file.read()\n\t    return _format_file_block(file_path, file_content)\n\tdef _format_file_block(context_file_path, context_content):\n\t    label = _format_file_label(context_file_path)\n\t    formatted_file_content = f\"```\\n{context_content}\\n```\"\n\t    return f\"{label}\\n{formatted_file_content}\\n\\n\"\n\tdef _format_file_label(file_path):\n\t    return f\"[[{file_path}]]\"\n"]}
{"filename": "nail/core/prompt/__init__.py", "chunked_list": []}
{"filename": "nail/core/prompt/prompt.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom nail.core.file_editor import FileEditor\n\tfrom nail.core.prompt.context_compiler import ContextCompiler\n\tfrom nail.core.prompt.formatting_utils import file_block\n\tfrom nail.core.config.local_config_utils import load_local_config\n\tBUILD_REQUEST = \"Write code to the following specification:\"\n\tERROR_REQUEST = \"Fix the following error message:\"\n\tEXPLAIN_PREFIX = \"Explain the following code:\"\n\tGENERAL_DEBUG_REQUEST = \"Fix any bugs in the file.\"\n\tORIGINAL_FILE_TAG = \"Original file contents:\"\n", "README_REQUEST = \"Generate a README file for the application.\"\n\tREQUEST_TAG = \"Request:\"\n\tRETURN_FULL_FILE = (\n\t    \"Return the full modified file contents. Any non-code\"\n\t    + \" text should only be included as inline comments.\"\n\t)\n\tSPEC_PREFIX = \"Create a unit test file for the following code:\"\n\tLOW_VERBOSITY = \"Keep your answer succinct and to the point.\"\n\tHIGH_VERBOSITY = \"Include a high level of detail.\"\n\tclass BasePrompt(ABC):\n", "    \"\"\"\n\t    Base class for all prompts. Contains common functionality for all prompts.\n\t    All prompts should implement the text method.\n\t    :param file_path: Path to the main file to be edited, debugged, etc\n\t    :param context_file_paths: Paths to other relevant files for context\n\t    :param details: A dictionary of details to be used by specific prompts\n\t    \"\"\"\n\t    def __init__(self, file_path=None, context_file_paths=[], details={}):\n\t        self.file_path = file_path\n\t        self.context_file_paths = context_file_paths\n", "        self.details = details\n\t    @property\n\t    def _context_text(self):\n\t        if not self.context_file_paths:\n\t            return \"\"\n\t        return ContextCompiler(self.context_file_paths).compile_all()\n\t    @property\n\t    def _file_text(self):\n\t        return FileEditor(self.file_path).content()\n\t    def _custom_instructions(self, key):\n", "        instruction = load_local_config().get(\"prompt_instructions\", {}).get(key)\n\t        return \"\" if not instruction else f\"\\n{instruction}\"\n\t    @abstractmethod\n\t    def text(self):\n\t        pass\n\tclass BuildPrompt(BasePrompt):\n\t    def text(self):\n\t        return (\n\t            self._context_text\n\t            + f\"{BUILD_REQUEST}\\n\"\n", "            + self._file_text\n\t            + self._custom_instructions(\"build\")\n\t        )\n\tclass BuildReadmePrompt(BasePrompt):\n\t    def text(self):\n\t        return self._context_text + README_REQUEST + self._custom_instructions(\"readme\")\n\t    @property\n\t    def _context_text(self):\n\t        return ContextCompiler().compile_all_minus_ignored()\n\tclass DebugPrompt(BasePrompt):\n", "    def text(self):\n\t        return (\n\t            file_block(self.file_path)\n\t            + f\"{self._debug_request}\\n\"\n\t            + RETURN_FULL_FILE\n\t            + self._custom_instructions(\"debug\")\n\t        )\n\t    @property\n\t    def _debug_request(self):\n\t        error_message = self.details.get(\"error_message\")\n", "        if error_message:\n\t            return f\"{ERROR_REQUEST}\\n{error_message}\"\n\t        else:\n\t            return GENERAL_DEBUG_REQUEST\n\tclass ModifyPrompt(BasePrompt):\n\t    def text(self):\n\t        file_context = f\"{ORIGINAL_FILE_TAG}\\n{file_block(self.file_path)}\"\n\t        return (\n\t            self._context_text\n\t            + file_context\n", "            + self._modify_request\n\t            + self._custom_instructions(\"modify\")\n\t        )\n\t    @property\n\t    def _modify_request(self):\n\t        request = self.details.get(\"request\")\n\t        return f\"{REQUEST_TAG} {request}\\n{RETURN_FULL_FILE}\"\n\tclass SpecPrompt(BasePrompt):\n\t    def text(self):\n\t        return (\n", "            f\"{SPEC_PREFIX}\\n{file_block(self.file_path)}\"\n\t            + self._custom_instructions(\"spec\")\n\t        )\n\tclass ExplainPrompt(BasePrompt):\n\t    def text(self):\n\t        if self.details.get(\"verbose\") is True:\n\t            verbosity = HIGH_VERBOSITY\n\t        else:\n\t            verbosity = LOW_VERBOSITY\n\t        return (\n", "            self._context_text\n\t            + f\"{EXPLAIN_PREFIX}\\n{file_block(self.file_path)}\"\n\t            + verbosity\n\t            + self._custom_instructions(\"explain\")\n\t        )\n"]}
{"filename": "nail/core/prompt/context_compiler.py", "chunked_list": ["import os\n\timport re\n\tfrom pathlib import Path\n\tfrom typing import List\n\tfrom nail.core.prompt.formatting_utils import file_block\n\tclass ContextCompiler:\n\t    \"\"\"\n\t    Compiles prompt context from the files in the given context_file_paths.\n\t    :param context_file_paths: A list of file paths to include in the context.\n\t    :param ignore_list: A list of file names or regex patterns to ignore.\n", "    \"\"\"\n\t    CONTEXT_PREFIX = \"Existing files for context:\"\n\t    # TODO: Make this list configurable\n\t    DEFAULT_IGNORE_LIST = [\"README\", \"LICENSE\", \"^[._]\", \"^test\", \"test$\"]\n\t    def __init__(\n\t        self, context_file_paths=[os.getcwd()], ignore_list=DEFAULT_IGNORE_LIST\n\t    ):\n\t        self.context_file_paths = context_file_paths\n\t        self.ignore_list = ignore_list\n\t    def compile_all(self):\n", "        \"\"\"\n\t        Compiles prompt context from all files in the given context_file_paths.\n\t        This includes a prefix explaining the context, and a code block\n\t        and file name label for each file.\n\t        :return: A string containing the prompt context.\n\t        \"\"\"\n\t        all_files = self._list_all_files()\n\t        return self._compile_context(all_files)\n\t    def compile_all_minus_ignored(self):\n\t        \"\"\"\n", "        Compiles prompt context from given context_file_paths. Includes all\n\t        files in the given paths, minus any that are included in the\n\t        ContextCompiler's ignore_list. Context includes a prefix explaining the\n\t        context, and a code block and file name label for each file.\n\t        :return: A string containing the prompt context.\n\t        \"\"\"\n\t        relevant_files = self._filter_ignored(self._list_all_files())\n\t        return self._compile_context(relevant_files)\n\t    def _compile_context(self, files):\n\t        context = [file_block(file) for file in files]\n", "        return f\"{self.CONTEXT_PREFIX}\\n\\n{''.join(context)}\"\n\t    def _list_all_files(self):\n\t        all_file_paths = []\n\t        for path in self.context_file_paths:\n\t            file_paths = self._list_files_at_path(path)\n\t            all_file_paths.extend(file_paths)\n\t        return all_file_paths\n\t    def _list_files_at_path(self, path):\n\t        if os.path.isfile(path):\n\t            return [path]\n", "        file_paths = []\n\t        for root, dirs, files in os.walk(path):\n\t            dirs[:] = [d for d in dirs if not d.startswith(\".\")]\n\t            for file in files:\n\t                file_paths.append(os.path.join(root, file))\n\t        return file_paths\n\t    def _filter_ignored(self, file_paths):\n\t        return [\n\t            file_path for file_path in file_paths if not self._is_ignored(file_path)\n\t        ]\n", "    def _is_ignored(self, file_path):\n\t        # Generate regexes for each item in the ignore list and\n\t        # return True if any of them match the given file path\n\t        file = os.path.basename(file_path)\n\t        return any(re.compile(item).search(file) for item in self.ignore_list)\n"]}
{"filename": "nail/core/language_models/open_ai.py", "chunked_list": ["import openai\n\tfrom nail.core.config.user_config_utils import get_api_key\n\tfrom nail.core.language_models.language_model import LanguageModel\n\tDEFAULT_TEMPERATURE = 0.3\n\tDEFAULT_MAX_TOKENS = 2048\n\tclass OpenAIAPIError(Exception):\n\t    pass\n\tclass OpenAIChat(LanguageModel):\n\t    \"\"\"\n\t    Implementation for the OpenAI chat (*not completion*) API.\n", "    Reference: https://platform.openai.com/docs/guides/chat/introduction\n\t    \"\"\"\n\t    def _user_message(self, message):\n\t        return {\"role\": \"user\", \"content\": message}\n\t    def _fetch_response(self, messages):\n\t        openai.api_key = get_api_key()\n\t        response = openai.ChatCompletion.create(\n\t            model=self.model_name,\n\t            messages=messages,\n\t            temperature=DEFAULT_TEMPERATURE,\n", "            max_tokens=DEFAULT_MAX_TOKENS,\n\t        )\n\t        return response\n\t    def _parse_response(self, response):\n\t        try:\n\t            return response.choices[0].message[\"content\"]\n\t        except (AttributeError, IndexError):\n\t            raise OpenAIAPIError(\"OpenAI API response is invalid.\")\n\tclass GPT_3_5(OpenAIChat):\n\t    \"\"\"\n", "    This implementation instead prefixes the initial user message with the\n\t    system message content. This should result in more accurate instruction\n\t    following.\n\t    From the OpenAI docs:\n\t    \"gpt-3.5-turbo-0301 does not always pay strong attention to system messages.\n\t    Future models will be trained to pay stronger attention to system messages.\"\n\t    \"\"\"\n\t    model_name = \"gpt-3.5-turbo\"\n\t    def _respond_from_prompt(self, prompt, system_message):\n\t        full_prompt = f\"{system_message}\\n{prompt}\"\n", "        messages = [self._user_message(full_prompt)]\n\t        return self._parse_response(self._fetch_response(messages))\n\tclass GPT_4(OpenAIChat):\n\t    \"\"\"\n\t    The GPT-4 model makes full use of the concept of system messages, so\n\t    this implementation uses them as intended.\n\t    \"\"\"\n\t    model_name = \"gpt-4\"\n\t    def _system_message(self, message):\n\t        return {\"role\": \"system\", \"content\": message}\n", "    def _respond_from_prompt(self, prompt, system_message):\n\t        messages = [self._system_message(system_message), self._user_message(prompt)]\n\t        return self._parse_response(self._fetch_response(messages))\n"]}
{"filename": "nail/core/language_models/supported_models.py", "chunked_list": ["\"\"\"\n\tSupported LLM classes are registered here in SUPPORTED_MODELS.\n\t\"\"\"\n\tfrom nail.core.language_models.open_ai import GPT_3_5, GPT_4\n\tSUPPORTED_MODELS = {\n\t    \"gpt-3.5-turbo\": GPT_3_5,\n\t    \"gpt-4\": GPT_4,\n\t}\n\tDEFAULT_MODEL = \"gpt-3.5-turbo\"\n"]}
{"filename": "nail/core/language_models/__init__.py", "chunked_list": []}
{"filename": "nail/core/language_models/language_model.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tDEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n\tCODE_SYSTEM_MESSAGE = \"\"\"You are a code generating assistant.\n\tYou obey the following rules:\n\t- You only respond only in code.\n\t- You respond only in complete files.\n\t- Any explanation should be included only as inline comments.\n\t- Always wrap your code in triple backticks.\n\t- You do not include usage examples.\"\"\"\n\tclass LanguageModel(ABC):\n", "    \"\"\"\n\t    Abstract base class representing a large language model. Delegates\n\t    chat response logic out to implementations in model specific subclasses.\n\t    Concrete language model classes must implement _respond_from_prompt to\n\t    take a prompt string as a param and return a string as an answer.\n\t    \"\"\"\n\t    def respond(self, prompt: str) -> str:\n\t        \"\"\"\n\t        Respond to a prompt with a general instruction message prepended.\n\t        :param prompt: The prompt to respond to.\n", "        :return: The response string.\n\t        \"\"\"\n\t        return self._respond_from_prompt(prompt, DEFAULT_SYSTEM_MESSAGE)\n\t    def respond_with_code(self, prompt: str) -> str:\n\t        \"\"\"\n\t        Respond to a prompt with a code generation instruction message prepended.\n\t        :param prompt: The prompt to respond to.\n\t        :return: The response string.\n\t        \"\"\"\n\t        return self._respond_from_prompt(prompt, CODE_SYSTEM_MESSAGE)\n", "    @abstractmethod\n\t    def _respond_from_prompt(self, prompt: str, system_message: str) -> str:\n\t        pass\n"]}
{"filename": "tests/test_main.py", "chunked_list": ["from unittest.mock import patch, ANY\n\timport pytest\n\tfrom click.testing import CliRunner\n\tfrom nail.main import configure, build, readme, modify, debug, spec\n\t@pytest.fixture\n\tdef runner():\n\t    return CliRunner()\n\tdef test_configure(runner):\n\t    with patch(\"nail.main.save_api_key\") as mock_save_api_key:\n\t        result = runner.invoke(configure, input=\"test_api_key\\n\")\n", "        assert result.exit_code == 0\n\t        mock_save_api_key.assert_called_once_with(\"test_api_key\")\n\tdef test_build(runner):\n\t    with patch(\"nail.main.build_file\") as mock_build_file:\n\t        result = runner.invoke(build, [\"test_file\"])\n\t        assert result.exit_code == 0\n\t        mock_build_file.assert_called_once_with(\"test_file\", ANY, None)\n\tdef test_readme(runner):\n\t    with patch(\"nail.main.build_readme\") as mock_build_readme:\n\t        result = runner.invoke(readme)\n", "        assert result.exit_code == 0\n\t        mock_build_readme.assert_called_once_with(\"README.md\", None)\n\tdef test_modify(runner):\n\t    with patch(\"nail.main.modify_file\") as mock_modify_file:\n\t        result = runner.invoke(modify, [\"test_file\", \"-r\", \"test_request\"])\n\t        assert result.exit_code == 0\n\t        mock_modify_file.assert_called_once_with(\"test_file\", \"test_request\", ANY, None)\n\tdef test_debug(runner):\n\t    with patch(\"nail.main.debug_file\") as mock_debug_file:\n\t        result = runner.invoke(debug, [\"test_file\"])\n", "        assert result.exit_code == 0\n\t        mock_debug_file.assert_called_once_with(\"test_file\", None, None)\n\tdef test_spec(runner):\n\t    with patch(\"nail.main.build_spec_file\") as mock_build_spec_file:\n\t        result = runner.invoke(spec, [\"test_file\", \"test_target_path\"])\n\t        assert result.exit_code == 0\n\t        mock_build_spec_file.assert_called_once_with(\n\t            \"test_file\", \"test_target_path\", None\n\t        )\n"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/tools/test_explain.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import patch\n\tfrom nail.tools.explain_file import explain_file\n\t@pytest.fixture\n\tdef MockExplainPrompt():\n\t    with patch(\"nail.tools.explain_file.ExplainPrompt\", autospec=True) as mock:\n\t        mock_prompt = mock.return_value\n\t        mock_prompt.text.return_value = \"Explain the following: code\"\n\t        yield mock\n\t@pytest.fixture\n", "def MockChat():\n\t    with patch(\"nail.tools.explain_file.Chat\", autospec=True) as mock:\n\t        mock_chat = mock.return_value\n\t        mock_chat.predict_code.return_value = \"Here is the explanation\"\n\t        yield mock\n\t@pytest.fixture\n\tdef MockConsole():\n\t    with patch(\"nail.tools.explain_file.Console\", autospec=True) as mock:\n\t        yield mock\n\t@pytest.fixture\n", "def MockMarkdown():\n\t    with patch(\"nail.tools.explain_file.Markdown\", autospec=True) as mock:\n\t        mock.return_value = \"Here is the explanation\"\n\t        yield mock\n\tdef test_explain_file(MockExplainPrompt, MockChat, MockConsole, MockMarkdown):\n\t    mock_console = MockConsole.return_value\n\t    explain_file(\"initial_file.py\")\n\t    mock_console.print.assert_called_once_with(\"Here is the explanation\")\n"]}
{"filename": "tests/tools/test_modify.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import patch\n\tfrom nail.tools.modify_file import modify_file\n\t@pytest.fixture\n\tdef MockModifyPrompt():\n\t    with patch(\"nail.tools.modify_file.ModifyPrompt\", autospec=True) as mock:\n\t        yield mock\n\t@pytest.fixture\n\tdef MockFileEditor():\n\t    with patch(\"nail.tools.modify_file.FileEditor\", autospec=True) as mock:\n", "        yield mock\n\t@pytest.fixture\n\tdef MockChat():\n\t    with patch(\"nail.tools.modify_file.Chat\", autospec=True) as mock:\n\t        mock_chat = mock.return_value\n\t        mock_chat.predict_code.return_value = \"expected modified content\"\n\t        yield mock\n\tdef test_modify_file(MockModifyPrompt, MockFileEditor, MockChat):\n\t    mock_file_editor = MockFileEditor.return_value\n\t    modify_file(\"path/to/file\", \"request\", context_file_paths=None, model=None)\n", "    mock_file_editor.apply_changes.assert_called_once_with(\"expected modified content\")\n"]}
{"filename": "tests/tools/test_debug.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import patch\n\tfrom nail.tools.debug_file import debug_file\n\t# Test data\n\tTEST_PROMPT = \"Fix any bugs in the file.\"\n\tTEST_MODIFIED_CONTENT = \"def test_function():\\n    return 43\\n\"\n\t@pytest.fixture\n\tdef MockFileEditor():\n\t    with patch(\"nail.tools.debug_file.FileEditor\", autospec=True) as mock:\n\t        yield mock\n", "@pytest.fixture\n\tdef MockChat():\n\t    with patch(\"nail.tools.debug_file.Chat\", autospec=True) as mock:\n\t        mock_chat = mock.return_value\n\t        mock_chat.predict_code.return_value = TEST_MODIFIED_CONTENT\n\t        yield mock\n\t@pytest.fixture\n\tdef MockPrompt():\n\t    with patch(\"nail.tools.debug_file.DebugPrompt\", autospec=True) as mock:\n\t        mock_prompt = mock.return_value\n", "        mock_prompt.text.return_value = TEST_PROMPT\n\t        yield mock\n\t@pytest.mark.parametrize(\"error_message\", [None, \"error message\"])\n\tdef test_debug_file(MockFileEditor, MockChat, MockPrompt, error_message):\n\t    mock_file_editor = MockFileEditor.return_value\n\t    debug_file(\"test_file.py\", error_message)\n\t    mock_file_editor.apply_changes.assert_called_once_with(TEST_MODIFIED_CONTENT)\n"]}
{"filename": "tests/tools/test_build_readme.py", "chunked_list": ["import pytest\n\timport os\n\tfrom unittest.mock import patch\n\tfrom nail.tools.build_readme import build_readme\n\t# Test data\n\tTEST_CONTEXT_DIRECTORY = \"test_directory\"\n\tTEST_PROMPT = \"This is the content of the app files. Generate a README file.\"\n\tTEST_README_FILE = \"README.md\"\n\tTEST_README_CONTENTS = \"This is a generated README file.\"\n\t@pytest.fixture\n", "def MockFileEditor():\n\t    with patch(\"nail.tools.build_readme.FileEditor\", autospec=True) as mock:\n\t        yield mock\n\t@pytest.fixture\n\tdef MockChat():\n\t    with patch(\"nail.tools.build_readme.Chat\", autospec=True) as mock:\n\t        mock_chat = mock.return_value\n\t        mock_chat.predict.return_value = TEST_README_CONTENTS\n\t        yield mock\n\t@pytest.fixture\n", "def MockBuildReadmePrompt():\n\t    with patch(\"nail.tools.build_readme.BuildReadmePrompt\", autospec=True) as mock:\n\t        mock_prompt = mock.return_value\n\t        mock_prompt.text.return_value = TEST_PROMPT\n\t        yield mock\n\tdef test_build_readme(MockBuildReadmePrompt, MockChat, MockFileEditor):\n\t    readme_file_path = os.path.join(TEST_CONTEXT_DIRECTORY, TEST_README_FILE)\n\t    mock_file_editor = MockFileEditor.return_value\n\t    build_readme(readme_file_path)\n\t    mock_file_editor.apply_changes.assert_called_once_with(TEST_README_CONTENTS)\n"]}
{"filename": "tests/tools/test_build.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import patch\n\tfrom nail.tools.build_file import build_file\n\t@pytest.fixture\n\tdef MockFileEditor():\n\t    with patch(\"nail.tools.build_file.FileEditor\", autospec=True) as mock:\n\t        yield mock\n\t@pytest.fixture\n\tdef MockChat():\n\t    with patch(\"nail.tools.build_file.Chat\", autospec=True) as mock:\n", "        mock_chat = mock.return_value\n\t        mock_chat.predict_code.return_value = \"draft_contents\"\n\t        yield mock\n\t@pytest.fixture\n\tdef MockPrompt():\n\t    with patch(\"nail.tools.build_file.BuildPrompt\", autospec=True) as mock:\n\t        mock_prompt = mock.return_value\n\t        mock_prompt.text.return_value = \"prompt\"\n\t        yield mock\n\tdef test_build_file(MockFileEditor, MockChat, MockPrompt):\n", "    mock_file_editor = MockFileEditor.return_value\n\t    build_file(\"test_file_path\")\n\t    mock_file_editor.apply_changes.assert_called_once_with(\"draft_contents\")\n\t@patch(\"nail.tools.build_file.FileEditor\", autospec=True)\n\tdef test_build_file_no_file(MockFileEditor, MockChat, MockPrompt):\n\t    mock_file_editor = MockFileEditor.return_value\n\t    mock_file_editor.exists.return_value = False\n\t    build_file(\"test_file_path\", context_file_paths=None)\n\t    mock_file_editor.open_editor.assert_called_once()\n\t    mock_file_editor.apply_changes.assert_called_once_with(\"draft_contents\")\n"]}
{"filename": "tests/tools/test_spec.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import patch\n\tfrom nail.tools.build_spec_file import build_spec_file\n\t@pytest.fixture\n\tdef MockSpecPrompt():\n\t    with patch(\"nail.tools.build_spec_file.SpecPrompt\", autospec=True) as mock:\n\t        mock_prompt = mock.return_value\n\t        mock_prompt.text.return_value = \"Create unit tests for the following: code\"\n\t        yield mock\n\t@pytest.fixture\n", "def MockFileEditor():\n\t    with patch(\"nail.tools.build_spec_file.FileEditor\", autospec=True) as mock:\n\t        yield mock\n\t@pytest.fixture\n\tdef MockChat():\n\t    with patch(\"nail.tools.build_spec_file.Chat\", autospec=True) as mock:\n\t        mock_chat = mock.return_value\n\t        mock_chat.predict_code.return_value = (\n\t            \"def test_add():\\n\" \"    assert add(1, 2) == 3\\n\"\n\t        )\n", "        yield mock\n\tdef test_build_spec_file(MockSpecPrompt, MockFileEditor, MockChat):\n\t    mock_file_editor = MockFileEditor.return_value\n\t    build_spec_file(\"initial_file.py\", \"test_initial_file.py\")\n\t    mock_file_editor.apply_changes.assert_called_once_with(\n\t        \"def test_add():\\n    assert add(1, 2) == 3\\n\"\n\t    )\n"]}
{"filename": "tests/core/test_chat.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import MagicMock, patch\n\tfrom nail.core.language_models.supported_models import SUPPORTED_MODELS, DEFAULT_MODEL\n\tfrom nail.core.chat import Chat, InvalidModelError, ModelCodeGenerationError\n\tdef test_init_with_default_model():\n\t    chat = Chat()\n\t    assert chat.model_name == DEFAULT_MODEL\n\t    assert type(chat.model) == SUPPORTED_MODELS[DEFAULT_MODEL]\n\t@patch(\"nail.core.chat.load_local_config\", autospec=True)\n\tdef test_init_with_configured_default_model(mock_load_local_config):\n", "    custom_default = \"gpt-4\"\n\t    mock_load_local_config.return_value = {\"default_model\": custom_default}\n\t    chat = Chat()\n\t    assert chat.model_name == custom_default\n\t    assert type(chat.model) == SUPPORTED_MODELS[custom_default]\n\tdef test_init_with_custom_model():\n\t    custom_model_name = \"custom_model\"\n\t    SUPPORTED_MODELS[custom_model_name] = MagicMock(\n\t        return_value=\"custom_model_instance\"\n\t    )\n", "    chat = Chat(custom_model_name)\n\t    assert chat.model_name == custom_model_name\n\t    assert chat.model == \"custom_model_instance\"\n\t    del SUPPORTED_MODELS[custom_model_name]\n\tdef test_init_with_invalid_model():\n\t    with pytest.raises(InvalidModelError):\n\t        Chat(\"invalid_model\")\n\tdef test_predict():\n\t    chat = Chat()\n\t    chat.model.respond = MagicMock(return_value=\"response\")\n", "    prompt = \"test_prompt\"\n\t    with patch(\n\t        \"nail.core.loading_decorator.loadable\",\n\t        MagicMock(return_value=chat.model.respond),\n\t    ):\n\t        response = chat.predict(prompt)\n\t    chat.model.respond.assert_called_once_with(prompt)\n\t    assert response == \"response\"\n\tdef test_predict_code():\n\t    chat = Chat()\n", "    chat.model.respond_with_code = MagicMock(return_value=\"```\\ncode\\n```\")\n\t    prompt = \"test_prompt\"\n\t    with patch(\n\t        \"nail.core.loading_decorator.loadable\",\n\t        MagicMock(return_value=chat.model.respond_with_code),\n\t    ):\n\t        code = chat.predict_code(prompt)\n\t    chat.model.respond_with_code.assert_called_once_with(prompt)\n\t    assert code == \"code\"\n\tdef test_predict_code_with_invalid_response():\n", "    chat = Chat()\n\t    chat.model.respond_with_code = MagicMock(return_value=\"no code block\")\n\t    prompt = \"test_prompt\"\n\t    with patch(\n\t        \"nail.core.loading_decorator.loadable\",\n\t        MagicMock(return_value=chat.model.respond_with_code),\n\t    ):\n\t        with pytest.raises(ModelCodeGenerationError):\n\t            chat.predict_code(prompt)\n"]}
{"filename": "tests/core/__init__.py", "chunked_list": []}
{"filename": "tests/core/test_config_utils.py", "chunked_list": ["import configparser\n\tfrom unittest import mock\n\tfrom unittest.mock import patch\n\timport pytest\n\tfrom nail.core.config.user_config_utils import get_api_key, save_api_key\n\t@pytest.fixture\n\tdef temp_config_file(tmp_path):\n\t    temp_file = tmp_path / \".nailrc\"\n\t    temp_file.touch()\n\t    return temp_file\n", "def test_get_api_key_with_env_var(monkeypatch):\n\t    monkeypatch.setenv(\"OPENAI_API_KEY\", \"test_key\")\n\t    assert get_api_key() == \"test_key\"\n\tdef test_get_api_key_with_config_file(monkeypatch, temp_config_file):\n\t    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n\t    config = configparser.ConfigParser()\n\t    config[\"openai\"] = {\"api_key\": \"test_key\"}\n\t    with temp_config_file.open(\"w\") as f:\n\t        config.write(f)\n\t    with mock.patch(\n", "        \"nail.core.config.user_config_utils.USER_CONFIG_FILE\", temp_config_file\n\t    ):\n\t        assert get_api_key() == \"test_key\"\n\tdef test_get_api_key_with_no_key(monkeypatch, temp_config_file):\n\t    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n\t    with mock.patch(\n\t        \"nail.core.config.user_config_utils.USER_CONFIG_FILE\", temp_config_file\n\t    ):\n\t        assert get_api_key() is None\n\tdef test_save_api_key(tmp_path):\n", "    api_key = \"test_api_key\"\n\t    temp_config_file = tmp_path / \".nailrc\"\n\t    with patch(\"nail.core.config.user_config_utils.USER_CONFIG_FILE\", temp_config_file):\n\t        save_api_key(api_key)\n\t        config = configparser.ConfigParser()\n\t        config.read(temp_config_file)\n\t        assert config[\"openai\"][\"api_key\"] == api_key\n"]}
{"filename": "tests/core/test_file_editor.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import patch\n\tfrom nail.core.file_editor import FileEditor, MissingFilePathError\n\tdef test_missing_file_path_error():\n\t    with pytest.raises(MissingFilePathError):\n\t        FileEditor()\n\tdef test_exists(tmp_path):\n\t    file_path = tmp_path / \"test.txt\"\n\t    file_path.write_text(\"Test content\")\n\t    file_editor = FileEditor(file_path)\n", "    assert file_editor.exists() is True\n\t    non_existent_file = tmp_path / \"non_existent.txt\"\n\t    file_editor = FileEditor(non_existent_file)\n\t    assert file_editor.exists() is False\n\tdef test_content(tmp_path):\n\t    file_path = tmp_path / \"test.txt\"\n\t    file_path.write_text(\"Test content\")\n\t    file_editor = FileEditor(file_path)\n\t    assert file_editor.content() == \"Test content\"\n\t@patch(\"subprocess.call\")\n", "def test_open_editor(mock_call, tmp_path):\n\t    file_path = tmp_path / \"test.txt\"\n\t    file_path.write_text(\"Test content\")\n\t    file_editor = FileEditor(file_path)\n\t    file_editor.open_editor()\n\t    # Check if subprocess.call was called with the correct arguments\n\t    mock_call.assert_called_once_with([\"vim\", file_path])\n\tdef test_apply_changes(tmp_path, monkeypatch, capsys):\n\t    file_path = tmp_path / \"test.txt\"\n\t    file_path.write_text(\"Original content\")\n", "    file_editor = FileEditor(file_path)\n\t    # Mock input to return 'y' for confirmation\n\t    monkeypatch.setattr(\"builtins.input\", lambda _: \"y\")\n\t    assert file_editor.apply_changes(\"New content\") is True\n\t    assert file_editor.content() == \"New content\"\n\t    # Mock input to return 'n' for discard changes\n\t    monkeypatch.setattr(\"builtins.input\", lambda _: \"n\")\n\t    assert file_editor.apply_changes(\"Another content\") is False\n\t    assert file_editor.content() == \"New content\"\n\t    # Check if the diff is printed correctly\n", "    captured = capsys.readouterr()\n\t    assert \"+Another content\" in captured.out\n\t    assert \"-New content\" in captured.out\n"]}
{"filename": "tests/core/config/test_user_config_utils.py", "chunked_list": ["import configparser\n\timport pytest\n\tfrom nail.core.config.user_config_utils import (\n\t    get_api_key,\n\t    save_api_key,\n\t    USER_CONFIG_FILE,\n\t)\n\tdef test_get_api_key_from_env(monkeypatch):\n\t    monkeypatch.setenv(\"OPENAI_API_KEY\", \"test_key_from_env\")\n\t    assert get_api_key() == \"test_key_from_env\"\n", "def test_get_api_key_from_file(monkeypatch):\n\t    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n\t    config = configparser.ConfigParser()\n\t    config[\"openai\"] = {\"api_key\": \"test_key_from_file\"}\n\t    with USER_CONFIG_FILE.open(\"w\") as config_file:\n\t        config.write(config_file)\n\t    assert get_api_key() == \"test_key_from_file\"\n\tdef test_get_api_key_not_found(monkeypatch):\n\t    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n\t    if USER_CONFIG_FILE.is_file():\n", "        USER_CONFIG_FILE.unlink()\n\t    assert get_api_key() is None\n\tdef test_save_api_key():\n\t    save_api_key(\"test_key_to_save\")\n\t    config = configparser.ConfigParser()\n\t    config.read(USER_CONFIG_FILE)\n\t    assert config[\"openai\"][\"api_key\"] == \"test_key_to_save\"\n\t@pytest.fixture(autouse=True)\n\tdef cleanup():\n\t    # Remove the config file before and after each test\n", "    if USER_CONFIG_FILE.is_file():\n\t        USER_CONFIG_FILE.unlink()\n\t    yield\n\t    if USER_CONFIG_FILE.is_file():\n\t        USER_CONFIG_FILE.unlink()\n"]}
{"filename": "tests/core/config/test_local_config_utils.py", "chunked_list": ["from unittest.mock import mock_open, patch\n\tfrom nail.core.config import local_config_utils\n\tdef test_load_local_config_file_exists():\n\t    # Mock the existence of the config file and its content\n\t    config_content = \"\"\"\n\t    key: value\n\t    \"\"\"\n\t    m = mock_open(read_data=config_content)\n\t    with patch(\"builtins.open\", m):\n\t        with patch(\"os.path.exists\", return_value=True):\n", "            # Call the function and check if the content is loaded correctly\n\t            config = local_config_utils.load_local_config()\n\t            assert config == {\"key\": \"value\"}\n\tdef test_load_local_config_file_not_exists():\n\t    # Mock the non-existence of the config file\n\t    with patch(\"os.path.exists\", return_value=False):\n\t        # Call the function and check if an empty dictionary is returned\n\t        config = local_config_utils.load_local_config()\n\t        assert config == {}\n"]}
{"filename": "tests/core/prompt/test_formatting_utils.py", "chunked_list": ["from pathlib import Path\n\tfrom nail.core.prompt.formatting_utils import file_block\n\tdef test_file_block(tmp_path: Path):\n\t    # Create a temporary file with content\n\t    file_path = tmp_path / \"test_file.txt\"\n\t    file_path.write_text(\"This is a test file.\")\n\t    # Test the file_block function\n\t    expected_output = f\"[[{file_path}]]\\n```\\nThis is a test file.\\n```\\n\\n\"\n\t    assert file_block(file_path) == expected_output\n"]}
{"filename": "tests/core/prompt/test_context_compiler.py", "chunked_list": ["import pytest\n\timport tempfile\n\tfrom pathlib import Path\n\tfrom nail.core.prompt.context_compiler import ContextCompiler\n\t@pytest.fixture\n\tdef temp_files():\n\t    with tempfile.TemporaryDirectory() as temp_dir:\n\t        temp_dir_path = Path(temp_dir)\n\t        file_names = [\"file1.txt\", \"file2.py\", \"_hidden.txt\", \"test_file.py\"]\n\t        for file_name in file_names:\n", "            with open(temp_dir_path / file_name, \"w\") as f:\n\t                f.write(\"test content\")\n\t        yield temp_dir_path\n\tdef test_compile_all(temp_files):\n\t    context_compiler = ContextCompiler(context_file_paths=[temp_files])\n\t    result = context_compiler.compile_all()\n\t    assert ContextCompiler.CONTEXT_PREFIX in result\n\t    assert \"file1.txt\" in result\n\t    assert \"file2.py\" in result\n\t    assert \"_hidden.txt\" in result\n", "    assert \"test_file.py\" in result\n\tdef test_compile_all_minus_ignored(temp_files):\n\t    context_compiler = ContextCompiler(context_file_paths=[temp_files])\n\t    result = context_compiler.compile_all_minus_ignored()\n\t    assert ContextCompiler.CONTEXT_PREFIX in result\n\t    assert \"file1.txt\" in result\n\t    assert \"file2.py\" in result\n\t    assert \"_hidden.txt\" not in result\n\t    assert \"test_file.py\" not in result\n"]}
{"filename": "tests/core/prompt/test_prompt.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import patch\n\tfrom nail.core.prompt.prompt import (\n\t    BuildPrompt,\n\t    BuildReadmePrompt,\n\t    DebugPrompt,\n\t    ModifyPrompt,\n\t    SpecPrompt,\n\t    ExplainPrompt,\n\t    BUILD_REQUEST,\n", "    README_REQUEST,\n\t    ERROR_REQUEST,\n\t    RETURN_FULL_FILE,\n\t    ORIGINAL_FILE_TAG,\n\t    REQUEST_TAG,\n\t    SPEC_PREFIX,\n\t    EXPLAIN_PREFIX,\n\t    LOW_VERBOSITY,\n\t)\n\tMOCK_LOCAL_CONFIG = {\n", "    \"prompt_instructions\": {\n\t        \"build\": \"build_instructions\",\n\t        \"readme\": \"readme_instructions\",\n\t        \"debug\": \"debug_instructions\",\n\t        \"modify\": \"modify_instructions\",\n\t        \"spec\": \"spec_instructions\",\n\t        \"explain\": \"explain_instructions\",\n\t    }\n\t}\n\tFILE_TEXT = \"file_text\"\n", "CONTEXT_TEXT = \"context_file_text\"\n\tPARTIAL_CONTEXT_TEXT = \"partial_context_file_text\"\n\tFILE_BLOCK = \"\\n```file_text```\\n\"\n\t@pytest.fixture\n\tdef MockFileEditor():\n\t    with patch(\"nail.core.prompt.prompt.FileEditor\", autospec=True) as mock:\n\t        mock_file = mock.return_value\n\t        mock_file.content.return_value = FILE_TEXT\n\t        yield mock\n\t@pytest.fixture\n", "def MockContextCompiler():\n\t    with patch(\"nail.core.prompt.prompt.ContextCompiler\", autospec=True) as mock:\n\t        mock_context = mock.return_value\n\t        mock_context.compile_all.return_value = \"context_file_text\\n\"\n\t        mock_context.compile_all_minus_ignored.return_value = (\n\t            \"partial_context_file_text\\n\"\n\t        )\n\t        yield mock\n\t@pytest.fixture\n\tdef mock_file_block():\n", "    with patch(\"nail.core.prompt.prompt.file_block\", autospec=True) as mock:\n\t        mock.return_value = \"\\n```file_text```\\n\"\n\t        yield mock\n\t@pytest.fixture\n\tdef mock_load_local_config():\n\t    with patch(\"nail.core.prompt.prompt.load_local_config\", autospec=True) as mock:\n\t        mock.return_value = MOCK_LOCAL_CONFIG\n\t        yield mock\n\tdef test_build_prompt_text(MockFileEditor, MockContextCompiler, mock_load_local_config):\n\t    build_prompt = BuildPrompt(\"file_path\", [\"context_file_path\"])\n", "    expected_text = (\n\t        f\"{CONTEXT_TEXT}\\n\" f\"{BUILD_REQUEST}\\n\" f\"{FILE_TEXT}\\n\" \"build_instructions\"\n\t    )\n\t    assert build_prompt.text() == expected_text\n\tdef test_build_readme_prompt_text(\n\t    MockFileEditor, MockContextCompiler, mock_load_local_config\n\t):\n\t    build_readme_prompt = BuildReadmePrompt()\n\t    expected_text = (\n\t        f\"{PARTIAL_CONTEXT_TEXT}\\n\" f\"{README_REQUEST}\\n\" \"readme_instructions\"\n", "    )\n\t    assert build_readme_prompt.text() == expected_text\n\tdef test_debug_prompt_text(mock_file_block, mock_load_local_config):\n\t    debug_prompt = DebugPrompt(\n\t        \"file_path\", [\"context_file_path\"], {\"error_message\": \"error_message\"}\n\t    )\n\t    expected_text = (\n\t        f\"{FILE_BLOCK}\"\n\t        f\"{ERROR_REQUEST}\\n\"\n\t        \"error_message\\n\"\n", "        f\"{RETURN_FULL_FILE}\\n\"\n\t        \"debug_instructions\"\n\t    )\n\t    assert debug_prompt.text() == expected_text\n\tdef test_modify_prompt_text(\n\t    MockContextCompiler, mock_load_local_config, mock_file_block\n\t):\n\t    modify_prompt = ModifyPrompt(\n\t        \"file_path\", [\"context_file_path\"], {\"request\": \"request\"}\n\t    )\n", "    expected_text = (\n\t        f\"{CONTEXT_TEXT}\\n\"\n\t        f\"{ORIGINAL_FILE_TAG}\\n\"\n\t        f\"{FILE_BLOCK}\"\n\t        f\"{REQUEST_TAG} request\\n\"\n\t        f\"{RETURN_FULL_FILE}\\n\"\n\t        \"modify_instructions\"\n\t    )\n\t    assert modify_prompt.text() == expected_text\n\tdef test_spec_prompt_text(mock_load_local_config, mock_file_block):\n", "    spec_prompt = SpecPrompt(\"file_path\")\n\t    expected_text = f\"{SPEC_PREFIX}\\n\" f\"{FILE_BLOCK}\\n\" \"spec_instructions\"\n\t    assert spec_prompt.text() == expected_text\n\tdef test_explain_prompt_text(\n\t    MockContextCompiler, mock_load_local_config, mock_file_block\n\t):\n\t    explain_prompt = ExplainPrompt(\"file_path\", [\"context_file_path\"])\n\t    expected_text = (\n\t        f\"{CONTEXT_TEXT}\\n\"\n\t        f\"{EXPLAIN_PREFIX}\\n\"\n", "        f\"{FILE_BLOCK}\"\n\t        f\"{LOW_VERBOSITY}\\n\"\n\t        \"explain_instructions\"\n\t    )\n\t    assert explain_prompt.text() == expected_text\n"]}
{"filename": "tests/core/language_models/test_openai.py", "chunked_list": ["import pytest\n\tfrom unittest.mock import MagicMock, patch\n\tfrom nail.core.language_models.open_ai import (\n\t    OpenAIAPIError,\n\t    GPT_3_5,\n\t    GPT_4,\n\t    DEFAULT_MAX_TOKENS,\n\t    DEFAULT_TEMPERATURE,\n\t)\n\tfrom nail.core.language_models.language_model import (\n", "    DEFAULT_SYSTEM_MESSAGE,\n\t    CODE_SYSTEM_MESSAGE,\n\t)\n\tPROMPT = \"Create a python class that builds widgets.\"\n\tRESPONSE = \"This is an answer from OpenAI.\"\n\t@pytest.fixture\n\tdef mock_openai_chat_response():\n\t    mock_choice = MagicMock()\n\t    mock_choice.message = {\"content\": RESPONSE}\n\t    response = MagicMock()\n", "    response.choices = [mock_choice]\n\t    return response\n\t@pytest.fixture\n\tdef MockChatCompletion():\n\t    with patch(\"openai.ChatCompletion\") as MockChatCompletion:\n\t        yield MockChatCompletion\n\tdef test_gpt_3_5_respond(mock_openai_chat_response, MockChatCompletion):\n\t    model = GPT_3_5()\n\t    MockChatCompletion.create.return_value = mock_openai_chat_response\n\t    response = model.respond(PROMPT)\n", "    MockChatCompletion.create.assert_called_once_with(\n\t        model=\"gpt-3.5-turbo\",\n\t        messages=[{\"role\": \"user\", \"content\": f\"{DEFAULT_SYSTEM_MESSAGE}\\n{PROMPT}\"}],\n\t        temperature=DEFAULT_TEMPERATURE,\n\t        max_tokens=DEFAULT_MAX_TOKENS,\n\t    )\n\t    assert response == RESPONSE\n\tdef test_gpt_3_5_respond_with_code(mock_openai_chat_response, MockChatCompletion):\n\t    model = GPT_3_5()\n\t    MockChatCompletion.create.return_value = mock_openai_chat_response\n", "    response = model.respond_with_code(PROMPT)\n\t    MockChatCompletion.create.assert_called_once_with(\n\t        model=\"gpt-3.5-turbo\",\n\t        messages=[{\"role\": \"user\", \"content\": f\"{CODE_SYSTEM_MESSAGE}\\n{PROMPT}\"}],\n\t        temperature=DEFAULT_TEMPERATURE,\n\t        max_tokens=DEFAULT_MAX_TOKENS,\n\t    )\n\t    assert response == RESPONSE\n\tdef test_gpt_3_5_error_response(MockChatCompletion):\n\t    model = GPT_3_5()\n", "    MockChatCompletion.create.return_value = MagicMock()\n\t    MockChatCompletion.create.return_value.choices = []\n\t    with pytest.raises(OpenAIAPIError, match=\"OpenAI API response is invalid.\"):\n\t        model.respond(PROMPT)\n\tdef test_gpt_4_respond(mock_openai_chat_response, MockChatCompletion):\n\t    model = GPT_4()\n\t    MockChatCompletion.create.return_value = mock_openai_chat_response\n\t    response = model.respond(PROMPT)\n\t    MockChatCompletion.create.assert_called_once_with(\n\t        model=\"gpt-4\",\n", "        messages=[\n\t            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_MESSAGE},\n\t            {\"role\": \"user\", \"content\": PROMPT},\n\t        ],\n\t        temperature=DEFAULT_TEMPERATURE,\n\t        max_tokens=DEFAULT_MAX_TOKENS,\n\t    )\n\t    assert response == RESPONSE\n\tdef test_gpt_4_respond_with_code(mock_openai_chat_response, MockChatCompletion):\n\t    model = GPT_4()\n", "    MockChatCompletion.create.return_value = mock_openai_chat_response\n\t    response = model.respond_with_code(PROMPT)\n\t    MockChatCompletion.create.assert_called_once_with(\n\t        model=\"gpt-4\",\n\t        messages=[\n\t            {\"role\": \"system\", \"content\": CODE_SYSTEM_MESSAGE},\n\t            {\"role\": \"user\", \"content\": PROMPT},\n\t        ],\n\t        temperature=DEFAULT_TEMPERATURE,\n\t        max_tokens=DEFAULT_MAX_TOKENS,\n", "    )\n\t    assert response == RESPONSE\n\tdef test_gpt_4_error_response(MockChatCompletion):\n\t    model = GPT_4()\n\t    MockChatCompletion.create.return_value = MagicMock()\n\t    MockChatCompletion.create.return_value.choices = []\n\t    with pytest.raises(OpenAIAPIError, match=\"OpenAI API response is invalid.\"):\n\t        model.respond(PROMPT)\n"]}
