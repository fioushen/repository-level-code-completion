{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\tsetup(\n\t    name=\"aiavatar\",\n\t    version=\"0.2.1\",\n\t    url=\"https://github.com/uezo/aiavatar\",\n\t    author=\"uezo\",\n\t    author_email=\"uezo@uezo.net\",\n\t    maintainer=\"uezo\",\n\t    maintainer_email=\"uezo@uezo.net\",\n\t    description=\"ü•∞ Building AI-based conversational avatars lightning fast ‚ö°Ô∏èüí¨\",\n", "    long_description=open(\"README.md\").read(),\n\t    long_description_content_type=\"text/markdown\",\n\t    packages=find_packages(exclude=[\"examples*\", \"tests*\"]),\n\t    install_requires=[\"aiohttp\", \"numpy\", \"openai\", \"sounddevice\"],\n\t    license=\"Apache v2\",\n\t    classifiers=[\n\t        \"Programming Language :: Python :: 3\"\n\t    ]\n\t)\n"]}
{"filename": "tests/processors/test_chatgpt.py", "chunked_list": ["import pytest\n\tfrom aiavatar.processors.chatgpt import ChatGPTProcessor\n\t@pytest.fixture\n\tdef chatgpt_processor():\n\t    return ChatGPTProcessor(\"YOUR_API_KEY\", temperature=0.0)\n\t@pytest.mark.asyncio\n\tasync def test_chat(chatgpt_processor: ChatGPTProcessor):\n\t    resp_iter = chatgpt_processor.chat(\"„Åä„Åó„ÇÉ„Åπ„Çä„Åó„Çà„ÅÜ\")\n\t    async for r in resp_iter:\n\t        assert len(r) > 0\n", "    assert len(chatgpt_processor.histories) == 2\n\t@pytest.mark.asyncio\n\tasync def test_reset_histories(chatgpt_processor: ChatGPTProcessor):\n\t    chatgpt_processor.histories.append(\"a\")\n\t    chatgpt_processor.histories.append(\"b\")\n\t    assert len(chatgpt_processor.histories) == 2\n\t    chatgpt_processor.reset_histories()\n\t    assert len(chatgpt_processor.histories) == 0\n"]}
{"filename": "tests/device/test_audio.py", "chunked_list": ["from aiavatar.device import AudioDevice\n\tdef test_get_default_input_device_info():\n\t    d = AudioDevice.get_default_input_device_info()\n\t    assert d[\"index\"] >= 0\n\t    assert d[\"index\"] < 1000\n\t    assert d[\"name\"] is not None\n\tdef test_get_default_output_device_info():\n\t    d = AudioDevice.get_default_output_device_info()\n\t    assert d[\"index\"] >= 0\n\t    assert d[\"index\"] < 1000\n", "    assert d[\"name\"] is not None\n\tdef test_get_input_device_by_name():\n\t    d = AudioDevice.get_input_device_by_name(\"„Éû„Ç§„ÇØ\")\n\t    assert d is not None\n\t    assert d[\"index\"] >= 0\n\t    assert d[\"max_input_channels\"] > 0\n\t    d = AudioDevice.get_input_device_by_name(\"_aiavater_dummy_\")\n\t    assert d is None\n\tdef test_get_output_device_by_name():\n\t    d = AudioDevice.get_output_device_by_name(\"„Çπ„Éî„Éº„Ç´„Éº\")\n", "    assert d is not None\n\t    assert d[\"index\"] >= 0\n\t    assert d[\"max_output_channels\"] > 0\n\t    d = AudioDevice.get_output_device_by_name(\"_aiavater_dummy_\")\n\t    assert d is None\n\tdef test_get_audio_devices():\n\t    devices = AudioDevice.get_audio_devices()\n\t    assert len(devices) >= 2\n\t    for d in devices:\n\t        assert d[\"index\"] >= 0\n", "        assert d[\"index\"] < 1000\n\t        assert d[\"name\"] is not None\n"]}
{"filename": "tests/speech/test_voicevox.py", "chunked_list": ["import asyncio\n\timport pytest\n\tfrom time import time\n\tfrom aiavatar.speech.voicevox import VoicevoxSpeechController\n\t@pytest.fixture\n\tdef voicevox_controller():\n\t    return VoicevoxSpeechController(base_url=\"http://127.0.0.1:50021\", speaker_id=46)\n\t@pytest.mark.asyncio\n\tasync def test_prefetch_download_task_started(voicevox_controller):\n\t    text = \"„Åì„Çì„Å´„Å°„ÅØ\"\n", "    voice = voicevox_controller.prefetch(text)\n\t    assert voice.text == text\n\t    assert voice.download_task is not None\n\t    assert voice.audio_clip is None\n\t@pytest.mark.asyncio\n\tasync def test_prefetch_download_completed(voicevox_controller):\n\t    text = \"„Åì„Çì„Å´„Å°„ÅØ\"\n\t    voice = voicevox_controller.prefetch(text)\n\t    await voice.download_task\n\t    assert voice.audio_clip is not None\n", "@pytest.mark.asyncio\n\tasync def test_speak_audio_played(voicevox_controller):\n\t    text = \"„Åì„Çì„Å´„Å°„ÅØ„ÄÇ„Åì„ÅÆÈü≥Â£∞„ÅØ„ÄÅ„ÉÜ„Çπ„Éà„ÅÆ„Åü„ÇÅ„Å´ÂÜçÁîü„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\"\n\t    start_time = time()\n\t    await voicevox_controller.speak(text)\n\t    assert time() - start_time > 1\n\t@pytest.mark.asyncio\n\tasync def test_is_speaking(voicevox_controller):\n\t    text = \"„Åì„Çì„Å´„Å°„ÅØ„ÄÇ„Åì„ÅÆÈü≥Â£∞„ÅØ„ÄÅ„ÉÜ„Çπ„Éà„ÅÆ„Åü„ÇÅ„Å´ÂÜçÁîü„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\"\n\t    voice = voicevox_controller.prefetch(text)\n", "    await voice.download_task\n\t    assert voicevox_controller.is_speaking() is False\n\t    speech_task = asyncio.create_task(voicevox_controller.speak(text))\n\t    await asyncio.sleep(0.1)    # wait for starting speech\n\t    while not speech_task.done():\n\t        assert voicevox_controller.is_speaking() is True\n\t        await asyncio.sleep(0.1)\n\t    await speech_task\n\t    assert voicevox_controller.is_speaking() is False\n"]}
{"filename": "aiavatar/avatar.py", "chunked_list": ["import asyncio\n\tfrom logging import getLogger, NullHandler\n\timport re\n\tfrom typing import Callable\n\tfrom .speech import SpeechController\n\tfrom .animation import AnimationController\n\tfrom .face import FaceController\n\tclass AvatarRequest:\n\t    def __init__(self, text_to_speech: str=None, animation_name: str=None, animation_duration: float = 3.0, face_name: str=None, face_duration: float=3.0):\n\t        self.text_to_speech = text_to_speech\n", "        self.animation_name = animation_name\n\t        self.animation_duration = animation_duration\n\t        self.face_name = face_name\n\t        self.face_duration = face_duration\n\tclass AvatarController:\n\t    def __init__(self, speech_controller: SpeechController, animation_controller: AnimationController, face_controller: FaceController, parser: Callable=None):\n\t        self.logger = getLogger(__name__)\n\t        self.logger.addHandler(NullHandler())\n\t        self.speech_controller = speech_controller\n\t        self.animation_controller = animation_controller\n", "        self.animation_task = None\n\t        self.face_controller = face_controller\n\t        self.face_task = None\n\t        self.parse = parser or self.parse_default\n\t        self.requests = []\n\t    async def start(self):\n\t        # TODO: Stop exisiting tasks before start processing new requests\n\t        while True:\n\t            if len(self.requests) > 0:\n\t                req = self.requests.pop(0)\n", "                if req is None:\n\t                    break\n\t                await self.perform(req)\n\t            else:\n\t                await asyncio.sleep(0.01)\n\t    def parse_default(self, text: str) -> AvatarRequest:\n\t        avreq = AvatarRequest()\n\t        # Face\n\t        face_pattarn = r\"\\[face:(\\w+)\\]\"\n\t        faces = re.findall(face_pattarn, text)\n", "        if faces:\n\t            avreq.face_name = faces[0]\n\t            avreq.face_duration = 4.0\n\t            text = re.sub(face_pattarn, \"\", text)\n\t        # Animation\n\t        animation_pattarn = r\"\\[animation:(\\w+)\\]\"\n\t        animations = re.findall(animation_pattarn, text)\n\t        if animations:\n\t            avreq.animation_name = animations[0]\n\t            avreq.animation_duration = 4.0\n", "            text = re.sub(animation_pattarn, \"\", text)\n\t        # Speech\n\t        avreq.text_to_speech = text\n\t        return avreq\n\t    def set_text(self, text: str):\n\t        avreq = self.parse(text)\n\t        self.speech_controller.prefetch(avreq.text_to_speech)\n\t        self.requests.append(avreq)\n\t    def set_stop(self):\n\t        self.requests.append(None)\n", "    async def perform(self, avatar_request: AvatarRequest):\n\t        # Face\n\t        if avatar_request.face_name:\n\t            if self.face_task:\n\t                self.face_task.cancel()\n\t            self.face_task = asyncio.create_task(\n\t                self.face_controller.set_face(avatar_request.face_name, avatar_request.face_duration)\n\t            )\n\t        # Animation\n\t        if avatar_request.animation_name:\n", "            if self.animation_task:\n\t                self.animation_task.cancel()\n\t            self.animation_task = asyncio.create_task(\n\t                self.animation_controller.animate(avatar_request.animation_name, avatar_request.animation_duration)\n\t            )\n\t        # Speech\n\t        self.logger.info(avatar_request.text_to_speech)\n\t        await self.speech_controller.speak(avatar_request.text_to_speech)\n\t    def is_speaking(self) -> bool:\n\t        return self.speech_controller.is_speaking()\n"]}
{"filename": "aiavatar/bot.py", "chunked_list": ["import asyncio\n\tfrom logging import getLogger, NullHandler\n\timport traceback\n\tfrom typing import Callable\n\t# Device\n\tfrom .device import AudioDevice\n\t# Processor\n\tfrom .processors.chatgpt import ChatGPTProcessor\n\t# Listener\n\tfrom .listeners.voicerequest import VoiceRequestListener\n", "# Avatar\n\tfrom .speech.voicevox import VoicevoxSpeechController\n\tfrom .animation import AnimationController, AnimationControllerDummy\n\tfrom .face import FaceController, FaceControllerDummy\n\tfrom .avatar import AvatarController\n\tclass AIAvatar:\n\t    def __init__(\n\t        self,\n\t        google_api_key: str,\n\t        openai_api_key: str,\n", "        voicevox_url: str,\n\t        voicevox_speaker_id: int=46,\n\t        volume_threshold: int=3000,\n\t        start_voice: str=\"„Å©„ÅÜ„Åó„Åü„ÅÆ\",\n\t        functions: dict=None,\n\t        system_message_content: str=None,\n\t        animation_controller: AnimationController=None,\n\t        face_controller: FaceController=None,\n\t        avatar_request_parser: Callable=None,\n\t        input_device: int=-1,\n", "        output_device: int=-1\n\t    ):\n\t        self.logger = getLogger(__name__)\n\t        self.logger.addHandler(NullHandler())\n\t        self.google_api_key = google_api_key\n\t        self.openai_api_key = openai_api_key\n\t        self.voicevox_url = voicevox_url\n\t        self.voicevox_speaker_id = voicevox_speaker_id\n\t        self.volume_threshold = volume_threshold\n\t        # Audio Devices\n", "        if isinstance(input_device, int):\n\t            if input_device < 0:\n\t                input_device_info = AudioDevice.get_default_input_device_info()\n\t                input_device = input_device_info[\"index\"]\n\t            else:\n\t                input_device_info = AudioDevice.get_device_info(input_device)\n\t        elif isinstance(input_device, str):\n\t            input_device_info = AudioDevice.get_input_device_by_name(input_device)\n\t            if input_device_info is None:\n\t                input_device_info = AudioDevice.get_default_input_device_info()\n", "            input_device = input_device_info[\"index\"]\n\t        self.input_device = input_device\n\t        self.logger.info(f\"Input device: [{input_device}] {input_device_info['name']}\")\n\t        if isinstance(output_device, int):\n\t            if output_device < 0:\n\t                output_device_info = AudioDevice.get_default_output_device_info()\n\t                output_device = output_device_info[\"index\"]\n\t            else:\n\t                output_device_info = AudioDevice.get_device_info(output_device)\n\t        elif isinstance(output_device, str):\n", "            output_device_info = AudioDevice.get_output_device_by_name(output_device)\n\t            if output_device_info is None:\n\t                output_device_info = AudioDevice.get_default_output_device_info()\n\t            output_device = output_device_info[\"index\"]\n\t        self.output_device = output_device\n\t        self.logger.info(f\"Output device: [{output_device}] {output_device_info['name']}\")\n\t        # Processor\n\t        self.chat_processor = ChatGPTProcessor(self.openai_api_key, functions=functions, system_message_content=system_message_content)\n\t        # Listeners\n\t        self.request_listener = VoiceRequestListener(self.google_api_key, volume_threshold=volume_threshold, device_index=self.input_device)\n", "        # Avatar\n\t        speech_controller = VoicevoxSpeechController(self.voicevox_url, self.voicevox_speaker_id, device_index=self.output_device)\n\t        animation_controller = animation_controller or AnimationControllerDummy()\n\t        face_controller = face_controller or FaceControllerDummy()\n\t        self.avatar_controller = AvatarController(speech_controller, animation_controller, face_controller, avatar_request_parser)\n\t        # Chat\n\t        self.chat_task = None\n\t        self.start_voice = start_voice\n\t    async def chat(self, request_on_start: str=None, skip_start_voice: bool=False):\n\t        if not skip_start_voice:\n", "            try:\n\t                await self.avatar_controller.speech_controller.speak(self.start_voice)\n\t            except Exception as ex:\n\t                self.logger.error(f\"Error at starting chat: {str(ex)}\\n{traceback.format_exc()}\")\n\t        while True:\n\t            try:\n\t                if request_on_start:\n\t                    req = request_on_start\n\t                    request_on_start = None\n\t                else:\n", "                    req = await self.request_listener.get_request()\n\t                    if not req:\n\t                        break\n\t                self.logger.info(f\"User: {req}\")\n\t                self.logger.info(\"AI:\")\n\t                avatar_task = asyncio.create_task(self.avatar_controller.start())\n\t                stream_buffer = \"\"\n\t                async for t in self.chat_processor.chat(req):\n\t                    stream_buffer += t\n\t                    sp = stream_buffer.replace(\"„ÄÇ\", \"„ÄÇ|\").replace(\"„ÄÅ\", \"„ÄÅ|\").replace(\"ÔºÅ\", \"ÔºÅ|\").replace(\"Ôºü\", \"Ôºü|\").split(\"|\")\n", "                    if len(sp) > 1: # >1 means `|` is found (splited at the end of sentence)\n\t                        sentence = sp.pop(0)\n\t                        stream_buffer = \"\".join(sp)\n\t                        self.avatar_controller.set_text(sentence)\n\t                self.avatar_controller.set_stop()\n\t                await avatar_task\n\t            except Exception as ex:\n\t                self.logger.error(f\"Error at chatting loop: {str(ex)}\\n{traceback.format_exc()}\")\n\t    async def start_chat(self, request_on_start: str=None, skip_start_voice: bool=False):\n\t        self.stop_chat()\n", "        self.chat_task = asyncio.create_task(self.chat(request_on_start, skip_start_voice))\n\t        await self.chat_task\n\t    def stop_chat(self):\n\t        if self.chat_task is not None:\n\t            self.chat_task.cancel()\n"]}
{"filename": "aiavatar/__init__.py", "chunked_list": ["# Device\n\tfrom .device import AudioDevice\n\t# Processor\n\tfrom .processors.chatgpt import ChatGPTProcessor\n\t# Listener\n\tfrom .listeners.wakeword import WakewordListener\n\tfrom .listeners.voicerequest import VoiceRequestListener\n\t# Avatar\n\tfrom .speech.voicevox import VoicevoxSpeechController\n\tfrom .avatar import AvatarController\n", "# Bot\n\tfrom .bot import AIAvatar\n"]}
{"filename": "aiavatar/processors/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import Iterator\n\tclass ChatProcessor(ABC):\n\t    @abstractmethod\n\t    async def chat(self, text: str) -> Iterator[str]:\n\t        pass\n"]}
{"filename": "aiavatar/processors/chatgpt.py", "chunked_list": ["from logging import getLogger, NullHandler\n\timport traceback\n\timport json\n\tfrom typing import Iterator, Callable\n\tfrom openai import ChatCompletion\n\tfrom . import ChatProcessor\n\tclass ChatGPTFunction:\n\t    def __init__(self, name: str, description: str=None, parameters: dict=None, func: Callable=None):\n\t        self.name = name\n\t        self.description = description\n", "        self.parameters = parameters\n\t        self.func = func\n\t    def get_spec(self):\n\t        return {\n\t            \"name\": self.name,\n\t            \"description\": self.description,\n\t            \"parameters\": self.parameters\n\t        }\n\tclass ChatCompletionStreamResponse:\n\t    def __init__(self, stream: Iterator[str], function_name: str=None):\n", "        self.stream = stream\n\t        self.function_name = function_name\n\t    @property\n\t    def response_type(self):\n\t        return \"function_call\" if self.function_name else \"content\"\n\tclass ChatGPTProcessor(ChatProcessor):\n\t    def __init__(self, api_key: str, model: str=\"gpt-3.5-turbo-0613\", temperature: float=1.0, max_tokens: int=0, functions: dict=None, system_message_content: str=None, history_count: int=10):\n\t        self.logger = getLogger(__name__)\n\t        self.logger.addHandler(NullHandler())\n\t        self.api_key = api_key\n", "        self.model = model\n\t        self.temperature = temperature\n\t        self.max_tokens = max_tokens\n\t        self.functions = functions or {}\n\t        self.system_message_content = system_message_content\n\t        self.history_count = history_count\n\t        self.histories = []\n\t    def add_function(self, name: str, description: str=None, parameters: dict=None, func: Callable=None):\n\t        self.functions[name] = ChatGPTFunction(name=name, description=description, parameters=parameters, func=func)\n\t    def reset_histories(self):\n", "        self.histories.clear()\n\t    async def chat_completion_stream(self, messages, call_functions: bool=True):\n\t        params = {\n\t            \"api_key\": self.api_key,\n\t            \"messages\": messages,\n\t            \"model\": self.model,\n\t            \"temperature\": self.temperature,\n\t            \"stream\": True,\n\t        }\n\t        if self.max_tokens:\n", "            params[\"max_tokens\"] = self.max_tokens\n\t        if call_functions and self.functions:\n\t            params[\"functions\"] = [v.get_spec() for _, v in self.functions.items()]\n\t        stream_resp = ChatCompletionStreamResponse(await ChatCompletion.acreate(**params))\n\t        async for chunk in stream_resp.stream:\n\t            if chunk:\n\t                delta = chunk[\"choices\"][0][\"delta\"]\n\t                if delta.get(\"function_call\"):\n\t                    stream_resp.function_name = delta[\"function_call\"][\"name\"]\n\t                break\n", "        return stream_resp\n\t    async def chat(self, text: str) -> Iterator[str]:\n\t        try:\n\t            messages = []\n\t            if self.system_message_content:\n\t                messages.append({\"role\": \"system\", \"content\": self.system_message_content})\n\t            messages.extend(self.histories[-1 * self.history_count:])\n\t            messages.append({\"role\": \"user\", \"content\": text})\n\t            response_text = \"\"\n\t            stream_resp = await self.chat_completion_stream(messages)\n", "            async for chunk in stream_resp.stream:\n\t                delta = chunk[\"choices\"][0][\"delta\"]\n\t                if stream_resp.response_type == \"content\":\n\t                    content = delta.get(\"content\")\n\t                    if content:\n\t                        response_text += delta[\"content\"]\n\t                        yield content\n\t                elif stream_resp.response_type == \"function_call\":\n\t                    function_call = delta.get(\"function_call\")\n\t                    if function_call:\n", "                        arguments = function_call[\"arguments\"]\n\t                        response_text += arguments\n\t            if stream_resp.response_type == \"function_call\":\n\t                self.histories.append(messages[-1])\n\t                self.histories.append({\n\t                    \"role\": \"assistant\",\n\t                    \"function_call\": {\n\t                        \"name\": stream_resp.function_name,\n\t                        \"arguments\": response_text\n\t                    },\n", "                    \"content\": None\n\t                })\n\t                api_resp = await self.functions[stream_resp.function_name].func(**json.loads(response_text))\n\t                messages.append({\"role\": \"function\", \"content\": json.dumps(api_resp), \"name\": stream_resp.function_name})\n\t                response_text = \"\"\n\t                stream_resp = await self.chat_completion_stream(messages, False)\n\t                async for chunk in stream_resp.stream:\n\t                    delta = chunk[\"choices\"][0][\"delta\"]\n\t                    content = delta.get(\"content\")\n\t                    if content:\n", "                        response_text += content\n\t                        yield content\n\t            if response_text:\n\t                self.histories.append(messages[-1])\n\t                self.histories.append({\"role\": \"assistant\", \"content\": response_text})\n\t        except Exception as ex:\n\t            self.logger.error(f\"Error at chat: {str(ex)}\\n{traceback.format_exc()}\")\n\t            raise ex\n"]}
{"filename": "aiavatar/face/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom logging import getLogger, NullHandler\n\tfrom threading import Thread\n\tfrom time import time, sleep\n\tclass FaceController(ABC):\n\t    @abstractmethod\n\t    async def set_face(self, name: str, duration: float):\n\t        pass\n\t    @abstractmethod\n\t    def reset(self):\n", "        pass\n\tclass FaceControllerBase(FaceController):\n\t    def __init__(self, verbose: bool=False):\n\t        self.logger = getLogger(__name__)\n\t        self.logger.addHandler(NullHandler())\n\t        self.verbose = verbose\n\t        self.faces = {\n\t            \"neutral\": \"('_')\",\n\t            \"joy\": \"(^o^)\",\n\t            \"angry\": \"(#ÔΩÄ–î¬¥)\",\n", "            \"sorrow\": \"(; ;)\",\n\t            \"fun\": \"(*^_^*)\",\n\t        }\n\t        self.reset_at = None\n\t        self.reset_thread = Thread(target=self.reset_worker, daemon=True)\n\t        self.reset_thread.start()\n\t    def reset_worker(self):\n\t        while True:\n\t            if self.reset_at and time() >= self.reset_at:\n\t                if self.verbose:\n", "                    self.logger.info(f\"Time to reset: {self.reset_at}\")\n\t                self.reset()\n\t                self.reset_at = None\n\t            sleep(0.1)\n\t    def subscribe_reset(self, reset_at: float):\n\t        self.reset_at = reset_at\n\t        if self.verbose:\n\t            self.logger.info(f\"Reset subscribed at {self.reset_at}\")\n\t    async def set_face(self, name: str, duration: float):\n\t        self.subscribe_reset(time() + duration)\n", "        self.logger.info(f\"face: {self.faces[name]} ({name})\")\n\t    def reset(self):\n\t        self.logger.info(f\"Reset face: {self.faces['neutral']} (neutral)\")\n\tclass FaceControllerDummy(FaceControllerBase):\n\t    pass\n"]}
{"filename": "aiavatar/face/vrchat.py", "chunked_list": ["import asyncio\n\tfrom time import time\n\tfrom pythonosc import udp_client\n\tfrom . import FaceControllerBase\n\tclass VRChatFaceController(FaceControllerBase):\n\t    def __init__(self, osc_address: str=\"/avatar/parameters/FaceOSC\", faces: dict=None, neutral_key: str=\"neutral\", host: str=\"127.0.0.1\", port: int=9000, verbose: bool=False):\n\t        super().__init__(verbose)\n\t        self.osc_address = osc_address\n\t        self.faces = faces or {\n\t            \"neutral\": 0,\n", "            \"joy\": 1,\n\t            \"angry\": 2,\n\t            \"sorrow\": 3,\n\t            \"fun\": 4,\n\t            \"surprise\": 5,\n\t        }\n\t        self.neutral_key = neutral_key\n\t        self.host = host\n\t        self.port = port\n\t        self.client = udp_client.SimpleUDPClient(self.host, self.port)\n", "    async def set_face(self, name: str, duration: float):\n\t        self.subscribe_reset(time() + duration)\n\t        osc_value = self.faces.get(name)\n\t        if osc_value is None:\n\t            self.logger.warning(f\"Face '{name}' is not registered\")\n\t            return\n\t        self.logger.info(f\"face: {name} ({osc_value})\")\n\t        self.client.send_message(self.osc_address, osc_value)\n\t    def reset(self):\n\t        self.logger.info(f\"Reset face: {self.neutral_key} ({self.faces[self.neutral_key]})\")\n", "        self.client.send_message(self.osc_address, self.faces[self.neutral_key])\n\t    def test_osc(self):\n\t        while True:\n\t            self.set_face(input(\"Face name: \"), 3.0)\n\tif __name__ == \"__main__\":\n\t    vrc_face_controller = VRChatFaceController()\n\t    asyncio.run(vrc_face_controller.test_osc())\n"]}
{"filename": "aiavatar/listeners/wakeword.py", "chunked_list": ["import asyncio\n\tfrom threading import Thread\n\tfrom typing import Callable\n\tfrom . import SpeechListenerBase\n\tclass WakewordListener(SpeechListenerBase):\n\t    def __init__(self, api_key: str, wakewords: list, on_wakeword: Callable, volume_threshold: int=3000, timeout: float=0.3, min_duration: float=0.2, max_duration: float=2, lang: str=\"ja-JP\", rate: int=44100, chennels: int=1, device_index: int=-1, verbose: bool=False):\n\t        super().__init__(api_key, self.invoke_on_wakeword, volume_threshold, timeout, 0.0, min_duration, max_duration, lang, rate, chennels, device_index)\n\t        self.wakewords = wakewords\n\t        self.on_wakeword = on_wakeword\n\t        self.verbose = verbose\n", "    async def invoke_on_wakeword(self, text: str):\n\t        if self.verbose:\n\t            self.logger.info(f\"Recognized: {text}\")\n\t        if text in self.wakewords:\n\t            await self.on_wakeword(text)\n\t    def start(self):\n\t        th = Thread(target=asyncio.run, args=(self.start_listening(),), daemon=True)\n\t        th.start()\n\t        return th\n"]}
{"filename": "aiavatar/listeners/__init__.py", "chunked_list": ["import base64\n\tfrom logging import getLogger, NullHandler\n\timport numpy\n\timport time\n\timport traceback\n\tfrom typing import Callable\n\timport aiohttp\n\timport sounddevice\n\tclass SpeechListenerBase:\n\t    def __init__(self, api_key: str, on_speech_recognized: Callable, volume_threshold: int=3000, timeout: float=1.0, detection_timeout: float=0.0, min_duration: float=0.3, max_duration: float=20.0, lang: str=\"ja-JP\", rate: int=44100, channels: int=1, device_index: int=-1):\n", "        self.logger = getLogger(__name__)\n\t        self.logger.addHandler(NullHandler())\n\t        self.api_key = api_key\n\t        self.on_speech_recognized = on_speech_recognized\n\t        self.volume_threshold = volume_threshold\n\t        self.timeout = timeout\n\t        self.detection_timeout = detection_timeout\n\t        self.min_duration = min_duration\n\t        self.max_duration = max_duration\n\t        self.lang = lang\n", "        self.channels = channels\n\t        self.rate = rate\n\t        self.device_index = device_index\n\t        self.is_listening = False\n\t    def record_audio(self, device_index) -> bytes:\n\t        audio_data = []\n\t        def callback(in_data, frame_count, time_info, status):\n\t            audio_data.append(in_data.copy())\n\t        try:\n\t            stream = sounddevice.InputStream(\n", "                device=device_index,\n\t                channels=self.channels,\n\t                samplerate=self.rate,\n\t                dtype=numpy.int16,\n\t                callback=callback\n\t            )\n\t            start_time = time.time()\n\t            is_recording = False\n\t            silence_start_time = time.time()\n\t            is_silent = False\n", "            last_detected_time = time.time()\n\t            stream.start()\n\t            while stream.active:\n\t                current_time = time.time()\n\t                volume = numpy.linalg.norm(audio_data[-10:]) / 50 if audio_data else 0\n\t                if not is_recording:\n\t                    if volume > self.volume_threshold:\n\t                        audio_data = audio_data[-100:]  # Use 100ms data before start recording\n\t                        is_recording = True\n\t                        start_time = current_time\n", "                else:\n\t                    if volume <= self.volume_threshold:\n\t                        if is_silent:\n\t                            if current_time - silence_start_time > self.timeout:\n\t                                # Timeouot\n\t                                recorded_length = current_time - start_time - self.timeout\n\t                                if recorded_length < self.min_duration:\n\t                                    self.logger.info(f\"Too short: {recorded_length}\")\n\t                                    is_recording = False\n\t                                    audio_data.clear()\n", "                                else:\n\t                                    return b\"\".join(audio_data)\n\t                            else:\n\t                                # Continue silent\n\t                                pass\n\t                        else:\n\t                            # Start silent\n\t                            silence_start_time = current_time\n\t                            is_silent = True\n\t                    else:\n", "                        # Detecting voice\n\t                        is_silent = False\n\t                        last_detected_time = current_time\n\t                    if current_time - start_time > self.max_duration:\n\t                        self.logger.info(f\"Max recording duration reached: {current_time - start_time}\")\n\t                        is_recording = False\n\t                        audio_data.clear()\n\t                if self.detection_timeout > 0 and time.time() - last_detected_time > self.detection_timeout:\n\t                    self.logger.info(f\"Voice detection timeout: {self.detection_timeout}\")\n\t                    break\n", "        except Exception as ex:\n\t            self.logger.error(f\"Error at record_audio: {str(ex)}\\n{traceback.format_exc()}\")\n\t        finally:\n\t            stream.stop()\n\t            stream.close()\n\t        # Return empty bytes\n\t        return b\"\".join([])\n\t    async def transcribe(self, audio_data: list) -> str:\n\t        audio_b64 = base64.b64encode(audio_data).decode(\"utf-8\")\n\t        request_body = {\n", "            \"config\": {\n\t                \"encoding\": \"LINEAR16\",\n\t                \"sampleRateHertz\": self.rate,\n\t                \"languageCode\": self.lang,\n\t            },\n\t            \"audio\": {\n\t                \"content\": audio_b64\n\t            },\n\t        }\n\t        async with aiohttp.ClientSession() as session:\n", "            async with session.post(\n\t                f\"https://speech.googleapis.com/v1/speech:recognize?key={self.api_key}\",\n\t                json=request_body\n\t            ) as resp:\n\t                j = await resp.json()\n\t                if resp.status != 200:\n\t                    self.logger.error(f\"Failed in recognition: {resp.status}\\n{j}\")\n\t                    return None\n\t                if j.get(\"results\"):\n\t                    if j[\"results\"][0][\"alternatives\"][0].get(\"transcript\"):\n", "                        return j[\"results\"][0][\"alternatives\"][0][\"transcript\"]\n\t        return None\n\t    async def start_listening(self):\n\t        self.is_listening = True\n\t        try:\n\t            self.logger.info(f\"Listening... ({self.__class__.__name__})\")\n\t            while self.is_listening:\n\t                audio_data = self.record_audio(self.device_index)\n\t                if audio_data:\n\t                    recognized_text = await self.transcribe(audio_data)\n", "                    if recognized_text:\n\t                        await self.on_speech_recognized(recognized_text)\n\t                    else:\n\t                        self.logger.info(\"No speech recognized\")\n\t                else:\n\t                    # Stop listening when no recorded data\n\t                    break\n\t            self.logger.info(f\"Stopped listening ({self.__class__.__name__})\")\n\t        except Exception as ex:\n\t            self.logger.error(f\"Error at start_listening: {str(ex)}\\n{traceback.format_exc()}\")\n", "        finally:\n\t            self.is_listening = False\n\t    def stop_listening(self):\n\t        self.is_listening = False\n"]}
{"filename": "aiavatar/listeners/voicerequest.py", "chunked_list": ["from . import SpeechListenerBase\n\tclass VoiceRequestListener(SpeechListenerBase):\n\t    def __init__(self, api_key: str, volume_threshold: int=3000, timeout: float=1.0, detection_timeout: float=10.0, min_duration: float=0.3, max_duration: float=20.0, lang: str=\"ja-JP\", rate: int=44100, channels: int=1, device_index: int=-1):\n\t        super().__init__(api_key, self.on_request, volume_threshold, timeout, detection_timeout, min_duration, max_duration, lang, rate, channels, device_index)\n\t        self.last_recognized_text = None\n\t    async def on_request(self, text: str):\n\t        self.last_recognized_text = text\n\t        self.stop_listening()\n\t    async def get_request(self):\n\t        await self.start_listening()\n", "        resp = self.last_recognized_text\n\t        self.last_recognized_text = None\n\t        return resp\n"]}
{"filename": "aiavatar/device/audio.py", "chunked_list": ["import sounddevice\n\tclass AudioDevice:\n\t    @classmethod\n\t    def get_default_input_device_info(cls):\n\t        device_list = sounddevice.query_devices()\n\t        for idx in sounddevice.default.device:\n\t            if device_list[idx][\"max_input_channels\"] > 0:\n\t                return device_list[idx]\n\t    @classmethod\n\t    def get_default_output_device_info(cls):\n", "        device_list = sounddevice.query_devices()\n\t        for idx in sounddevice.default.device:\n\t            if device_list[idx][\"max_output_channels\"] > 0:\n\t                return device_list[idx]\n\t    @classmethod\n\t    def get_device_info(cls, index: int):\n\t        return sounddevice.query_devices(index)\n\t    @classmethod\n\t    def get_input_device_by_name(cls, name: str):\n\t        for d in sounddevice.query_devices():\n", "            if d[\"max_input_channels\"] > 0:\n\t                if name.lower() in d[\"name\"].lower():\n\t                    return d\n\t        return None\n\t    @classmethod\n\t    def get_output_device_by_name(cls, name: str):\n\t        for d in sounddevice.query_devices():\n\t            if d[\"max_output_channels\"] > 0:\n\t                if name.lower() in d[\"name\"].lower():\n\t                    return d\n", "        return None\n\t    @classmethod\n\t    def get_input_device_with_prompt(cls, prompt: str=None):\n\t        print(\"==== Input devices ====\")\n\t        for d in sounddevice.query_devices():\n\t            if d[\"max_input_channels\"] > 0:\n\t                print(f'{d[\"index\"]}: {d[\"name\"]}')\n\t        idx = input(prompt or \"Index of microphone device (Skip to use default): \")\n\t        if idx == \"\":\n\t            return cls.get_default_input_device_info()\n", "        else:\n\t            return cls.get_device_info(int(idx))\n\t    @classmethod\n\t    def get_output_device_with_prompt(cls, prompt: str=None):\n\t        print(\"==== Output devices ====\")\n\t        for d in sounddevice.query_devices():\n\t            if d[\"max_output_channels\"] > 0:\n\t                print(f'{d[\"index\"]}: {d[\"name\"]}')\n\t        idx = input(prompt or \"Index of speaker device (Skip to use default): \")\n\t        if idx == \"\":\n", "            return cls.get_default_output_device_info()\n\t        else:\n\t            return cls.get_device_info(int(idx))\n\t    @classmethod\n\t    def get_audio_devices(cls):\n\t        return sounddevice.query_devices()\n\t    @classmethod\n\t    def list_audio_devices(cls):\n\t        print(cls.get_audio_devices())\n"]}
{"filename": "aiavatar/device/__init__.py", "chunked_list": ["from .audio import AudioDevice\n"]}
{"filename": "aiavatar/speech/voicevox.py", "chunked_list": ["import aiohttp\n\timport asyncio\n\timport io\n\tfrom logging import getLogger, NullHandler\n\timport traceback\n\timport wave\n\timport numpy\n\timport sounddevice\n\tfrom . import SpeechController\n\tclass VoiceClip:\n", "    def __init__(self, text: str):\n\t        self.text = text\n\t        self.download_task = None\n\t        self.audio_clip = None\n\tclass VoicevoxSpeechController(SpeechController):\n\t    def __init__(self, base_url: str, speaker_id: int, device_index: int=-1):\n\t        self.logger = getLogger(__name__)\n\t        self.logger.addHandler(NullHandler())\n\t        self.base_url = base_url\n\t        self.speaker_id = speaker_id\n", "        self.device_index = device_index\n\t        self.voice_clips = {}\n\t        self._is_speaking = False\n\t    async def download(self, voice: VoiceClip):\n\t        params = {\"speaker\": self.speaker_id, \"text\": voice.text}\n\t        async with aiohttp.ClientSession() as session:\n\t            async with session.post(self.base_url + \"/audio_query\", params=params) as query_resp:\n\t                audio_query = await query_resp.json()\n\t                async with session.post(self.base_url + \"/synthesis\", params={\"speaker\": self.speaker_id}, json=audio_query) as audio_resp:\n\t                    voice.audio_clip = await audio_resp.read()\n", "    def prefetch(self, text: str):\n\t        v = self.voice_clips.get(text)\n\t        if v:\n\t            return v\n\t        v = VoiceClip(text)\n\t        v.download_task = asyncio.create_task(self.download(v))\n\t        self.voice_clips[text] = v\n\t        return v\n\t    async def speak(self, text: str):\n\t        voice = self.prefetch(text)\n", "        if not voice.audio_clip:\n\t            await voice.download_task\n\t        with wave.open(io.BytesIO(voice.audio_clip), \"rb\") as f:\n\t            try:\n\t                self._is_speaking = True\n\t                data = numpy.frombuffer(\n\t                    f.readframes(f.getnframes()),\n\t                    dtype=numpy.int16\n\t                )\n\t                sounddevice.play(data, f.getframerate(), device=self.device_index)\n", "                sounddevice.wait()\n\t            except Exception as ex:\n\t                self.logger.error(f\"Error at speaking: {str(ex)}\\n{traceback.format_exc()}\")\n\t            finally:\n\t                self._is_speaking = False\n\t    def is_speaking(self) -> bool:\n\t        return self._is_speaking\n"]}
{"filename": "aiavatar/speech/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tclass SpeechController(ABC):\n\t    @abstractmethod\n\t    def prefetch(self, text: str):\n\t        pass\n\t    @abstractmethod\n\t    async def speak(self, text: str):\n\t        pass\n\t    @abstractmethod\n\t    def is_speaking(self) -> bool:\n", "        pass\n"]}
{"filename": "aiavatar/animation/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tclass AnimationController(ABC):\n\t    @abstractmethod\n\t    async def animate(self, name: str, duration: float):\n\t        pass\n\tclass AnimationControllerDummy(AnimationController):\n\t    async def animate(self, name: str, duration: float):\n\t        pass\n"]}
{"filename": "examples/run.py", "chunked_list": ["import logging\n\tfrom aiavatar import AIAvatar, WakewordListener\n\tGOOGLE_API_KEY = \"YOUR_API_KEY\"\n\tOPENAI_API_KEY = \"YOUR_API_KEY\"\n\tVV_URL = \"http://127.0.0.1:50021\"\n\tVV_SPEAKER = 46\n\t# Configure root logger\n\tlogger = logging.getLogger()\n\tlogger.setLevel(logging.INFO)\n\tlog_format = logging.Formatter(\"[%(levelname)s] %(asctime)s : %(message)s\")\n", "streamHandler = logging.StreamHandler()\n\tstreamHandler.setFormatter(log_format)\n\tlogger.addHandler(streamHandler)\n\t# Prompt\n\tsystem_message_content = \"\"\"„ÅÇ„Å™„Åü„ÅØ„Äåjoy„Äç„Äåangry„Äç„Äåsorrow„Äç„Äåfun„Äç„ÅÆ4„Å§„ÅÆË°®ÊÉÖ„ÇíÊåÅ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n\tÁâπ„Å´Ë°®ÊÉÖ„ÇíË°®Áèæ„Åó„Åü„ÅÑÂ†¥Âêà„ÅØ„ÄÅÊñáÁ´†„ÅÆÂÖàÈ†≠„Å´[face:joy]„ÅÆ„Çà„ÅÜ„Å´ÊåøÂÖ•„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n\t‰æã\n\t[face:joy]„Å≠„Åà„ÄÅÊµ∑„ÅåË¶ã„Åà„Çã„ÇàÔºÅ[face:fun]Êó©„ÅèÊ≥≥„Åî„ÅÜ„Çà„ÄÇ\n\t\"\"\"\n\t# Create AIAvatar\n", "app = AIAvatar(\n\t    google_api_key=GOOGLE_API_KEY,\n\t    openai_api_key=OPENAI_API_KEY,\n\t    voicevox_url=VV_URL,\n\t    voicevox_speaker_id=VV_SPEAKER,\n\t    system_message_content=system_message_content,\n\t)\n\t# Create WakewordListener\n\twakewords = [\"„Åì„Çì„Å´„Å°„ÅØ\"]\n\tasync def on_wakeword(text):\n", "    logger.info(f\"Wakeword: {text}\")\n\t    await app.start_chat()\n\twakeword_listener = WakewordListener(\n\t    api_key=GOOGLE_API_KEY,\n\t    wakewords=wakewords,\n\t    on_wakeword=on_wakeword,\n\t    device_index=app.input_device\n\t)\n\t# Start listening\n\tww_thread = wakeword_listener.start()\n", "ww_thread.join()\n"]}
{"filename": "examples/device.py", "chunked_list": ["from aiavatar import AudioDevice\n\tAudioDevice.list_audio_devices()\n"]}
{"filename": "examples/chatgpt_functions/weather.py", "chunked_list": ["import aiohttp\n\tfrom datetime import datetime, timezone, timedelta\n\tclass WeatherFunction:\n\t    def __init__(self, google_api_key: str, weather_appid: str):\n\t        self.google_api_key = google_api_key\n\t        self.weather_appid = weather_appid\n\t        self.name = \"get_weather\"\n\t        self.description=\"Get the weather forecast in a given location\"\n\t        self.parameters = {\n\t            \"type\": \"object\",\n", "            \"properties\": {\n\t                \"location\": {\n\t                    \"type\": \"string\"\n\t                }\n\t            }\n\t        }\n\t    async def get_weather(self, location, tz_offset=9) -> dict:\n\t        ret = {\n\t            \"description\": \"Compose a summary of the `weather_forecasts` information as a response message.\",\n\t            \"weather_forecasts\": []\n", "        }\n\t        async with aiohttp.ClientSession() as session:\n\t            async with session.get(\n\t                    f\"https://maps.googleapis.com/maps/api/geocode/json?address={location}&key={self.google_api_key}\"\n\t                ) as resp:\n\t                geo = await resp.json()\n\t            lat = geo[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n\t            lon = geo[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n\t            async with session.get(\n\t                    f\"http://api.openweathermap.org/data/2.5/forecast?APPID={self.weather_appid}&lat={lat}&lon={lon}&cnt=9\"\n", "                ) as resp:\n\t                weather = await resp.json()\n\t        for v in weather[\"list\"]:\n\t            w = {}\n\t            w[\"time\"] = datetime.fromtimestamp(v[\"dt\"], timezone(timedelta(hours=tz_offset))).isoformat()\n\t            if v[\"weather\"][0][\"main\"] == \"Clear\":\n\t                w[\"weather\"] = \"clear\"\n\t            elif v[\"weather\"][0][\"main\"] == \"Clouds\":\n\t                w[\"weather\"] = \"clouds\"\n\t            elif v[\"weather\"][0][\"main\"] == \"Rain\":\n", "                w[\"weather\"] = \"rain\"\n\t            elif v[\"weather\"][0][\"main\"] == \"Snow\":\n\t                w[\"weather\"] = \"snow\"\n\t            w[\"temperature\"] = str(int(v[\"main\"][\"temp\"] - 273.15))\n\t            ret[\"weather_forecasts\"].append(w)\n\t        return ret\n"]}
