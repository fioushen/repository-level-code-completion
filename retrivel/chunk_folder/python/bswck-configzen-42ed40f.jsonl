{"filename": "noxfile.py", "chunked_list": ["import argparse\n\tfrom typing import cast\n\timport nox\n\tfrom nox.command import CommandFailed\n\t@nox.session\n\tdef release(session: nox.Session) -> None:\n\t    \"\"\"\n\t    Kicks off an automated release process by creating and pushing a new tag.\n\t    Invokes bump2version with the posarg setting the version.\n\t    Usage:\n", "    $ nox -s release -- [major|minor|patch]\n\t    \"\"\"\n\t    parser = argparse.ArgumentParser(description=\"Release a semver version.\")\n\t    parser.add_argument(\n\t        \"version\",\n\t        type=str,\n\t        nargs=1,\n\t    )\n\t    args: argparse.Namespace = parser.parse_args(args=session.posargs)\n\t    version: str = args.version.pop()\n", "    # If we get here, we should be good to go\n\t    # Let's do a final check for safety\n\t    release_confirm = (\n\t        input(f\"You are about to release {version!r} version. Are you sure? [y/n]: \")\n\t        .casefold()\n\t        .strip()\n\t    )\n\t    # Abort on anything other than 'y'\n\t    if release_confirm != \"y\":\n\t        session.error(f\"You said no when prompted to bump the {version!r} version.\")\n", "    session.run(\"poetry\", \"self\", \"add\", \"poetry-bumpversion\", external=True)\n\t    session.log(f\"Bumping the {version!r} version\")\n\t    session.run(\"poetry\", \"version\", version, external=True)\n\t    new_version = (\n\t        \"v\"\n\t        + cast(\n\t            str, session.run(\"poetry\", \"version\", \"--short\", silent=True, external=True)\n\t        ).strip()\n\t    )\n\t    session.log(f\"Creating {new_version} tag...\")\n", "    try:\n\t        session.run(\n\t            \"git\",\n\t            \"tag\",\n\t            \"-a\",\n\t            new_version,\n\t            \"-m\",\n\t            f\"Release {new_version}\",\n\t            external=True,\n\t        )\n", "    except CommandFailed:\n\t        session.log(f\"Failed to create {new_version} tag, probably already exists.\")\n\t    session.log(\"Pushing local tags...\")\n\t    session.run(\"git\", \"push\", \"--tags\", external=True)\n\t    session.run(\"git\", \"diff\", external=True)\n\t    commit_confirm = (\n\t        input(\n\t            \"You are about to commit auto-changed files due to version upgrade, \"\n\t            \"see the diff view above. Are you sure? [y/n]: \"\n\t        )\n", "        .casefold()\n\t        .strip()\n\t    )\n\t    if commit_confirm == \"y\":\n\t        session.run(\n\t            \"git\", \"commit\", \"-a\", \"-m\", f\"Release {new_version}\", external=True\n\t        )\n\t        session.run(\"git\", \"push\", external=True)\n\t    else:\n\t        session.log(\"Ok.\")\n"]}
{"filename": "configzen/decorators.py", "chunked_list": ["from __future__ import annotations\n\timport contextlib\n\timport functools\n\tfrom collections.abc import Callable, Coroutine, Iterator\n\tfrom typing import TYPE_CHECKING, Any, cast, overload\n\tfrom configzen.model import export_hook, export_model, export_model_async, field_hook\n\tif TYPE_CHECKING:\n\t    from configzen.typedefs import ConfigModelT, T\n\t__all__ = (\n\t    \"with_exporter\",\n", "    \"with_async_exporter\",\n\t    \"with_field_hook\",\n\t    \"with_export_hook\",\n\t)\n\t@overload\n\tdef with_export_hook(\n\t    func: Callable[[T], Any],\n\t    cls: None = None,\n\t) -> functools.partial[type[T]]:\n\t    ...\n", "@overload\n\tdef with_export_hook(\n\t    func: Callable[[T], Any],\n\t    cls: type[T],\n\t) -> type[T]:\n\t    ...\n\tdef with_export_hook(\n\t    func: Callable[[T], Any], cls: type[T] | None = None\n\t) -> type[T] | functools.partial[type[T]]:\n\t    \"\"\"\n", "    Register a pre-serialization converter function for a type.\n\t    Parameters\n\t    ----------\n\t    func\n\t        The converter function.\n\t    cls\n\t        The type to register the converter for.\n\t        Optional for the decoration syntax.\n\t    Returns\n\t    -------\n", "    The conversion result class.\n\t    Usage\n\t    -----\n\t    .. code-block:: python\n\t        @with_export_hook(converter_func)\n\t        class MyClass:\n\t            ...\n\t    \"\"\"\n\t    if cls is None:\n\t        return functools.partial(with_export_hook, func)\n", "    export_hook.register(cls, func)\n\t    if not hasattr(cls, \"__get_validators__\"):\n\t        def validator_gen() -> Iterator[Callable[[Any], Any]]:\n\t            hook_func = field_hook.dispatch(cls)\n\t            yield lambda value: hook_func(cls, value)\n\t        with contextlib.suppress(TypeError):\n\t            cls.__get_validators__ = validator_gen  # type: ignore[attr-defined]\n\t    return cls\n\t@overload\n\tdef with_field_hook(\n", "    func: Callable[[type[T], Any], T],\n\t    cls: type[T],\n\t) -> type[T]:\n\t    ...\n\t@overload\n\tdef with_field_hook(\n\t    func: Callable[[type[T], Any], T],\n\t    cls: None = None,\n\t) -> functools.partial[type[T]]:\n\t    ...\n", "def with_field_hook(\n\t    func: Callable[[type[T], Any], T], cls: type[T] | None = None\n\t) -> type[T] | functools.partial[type[T]]:\n\t    \"\"\"\n\t    Register a field hook for a type.\n\t    Parameters\n\t    ----------\n\t    func\n\t        The loader function.\n\t    cls\n", "        The type to register the loader for.\n\t    Returns\n\t    -------\n\t    The loading result class.\n\t    \"\"\"\n\t    if cls is None:\n\t        return functools.partial(with_field_hook, func)\n\t    field_hook.register(cls, func)\n\t    return cls\n\tdef with_exporter(\n", "    func: Callable[[ConfigModelT], Any] | None = None,\n\t    cls: type[ConfigModelT] | None = None,\n\t    **predefined_kwargs: Any,\n\t) -> type[ConfigModelT] | Any:\n\t    \"\"\"\n\t    Register a custom exporter for a configuration model class.\n\t    Parameters\n\t    ----------\n\t    func\n\t        The exporter function.\n", "    cls\n\t        The type to register the exporter for.\n\t    \"\"\"\n\t    if cls is None:\n\t        return functools.partial(with_exporter, func)\n\t    if func and predefined_kwargs:\n\t        raise NotImplementedError(\n\t            \"specifying both a function and predefined kwargs is not supported\"\n\t        )\n\t    if func is None:\n", "        def func(obj: Any, **kwargs: Any) -> Any:\n\t            kwargs |= predefined_kwargs\n\t            return obj.export(**kwargs)\n\t        export_model.register(cls, func)\n\t        if export_model_async.dispatch(cls) is export_model_async:\n\t            async def default_async_func(obj: Any, **kwargs: Any) -> Any:\n\t                kwargs |= predefined_kwargs\n\t                return await obj.export_async(**kwargs)\n\t            export_model_async.register(cls, default_async_func)\n\t    else:\n", "        export_model.register(cls, func)\n\t        if export_model_async.dispatch(cls) is export_model_async:\n\t            async def default_async_func(obj: Any, **kwargs: Any) -> Any:\n\t                nonlocal func\n\t                if TYPE_CHECKING:\n\t                    func = cast(Callable[..., dict[str, Any]], func)\n\t                return func(obj, **kwargs)\n\t            export_model_async.register(cls, default_async_func)\n\t    return cls\n\tdef with_async_exporter(\n", "    func: Callable[[ConfigModelT], Coroutine[Any, Any, Any]] | None = None,\n\t    cls: type[ConfigModelT] | None = None,\n\t    **predefined_kwargs: Any,\n\t) -> type[ConfigModelT] | Any:\n\t    \"\"\"\n\t    Register a custom exporter for a configuration model class.\n\t    Parameters\n\t    ----------\n\t    func\n\t        The exporter function.\n", "    cls\n\t        The type to register the exporter for.\n\t    \"\"\"\n\t    if cls is None:\n\t        return functools.partial(with_exporter, func)\n\t    if func and predefined_kwargs:\n\t        raise NotImplementedError(\n\t            \"specifying both a function and default kwargs is not supported\"\n\t        )\n\t    if func is None:\n", "        async def default_async_func(obj: Any, **kwargs: Any) -> Any:\n\t            kwargs |= predefined_kwargs\n\t            return await obj.export_async(**kwargs)\n\t        export_model_async.register(cls, default_async_func)\n\t    else:\n\t        export_model_async.register(cls, func)\n\t    return cls\n"]}
{"filename": "configzen/model.py", "chunked_list": ["\"\"\"\n\tThe main module of the configzen library.\n\tThis module provides an API to manage configuration files and resources\n\tin a consistent way. It also provides tools to load and save configuration\n\tfiles in various formats and within a number of advanced methods.\n\t```python\n\tfrom configzen import ConfigModel, ConfigField, ConfigMeta\n\tclass DatabaseConfig(ConfigModel):\n\t    host: str\n\t    port: int\n", "    user: str\n\t    password: str = ConfigField(exclude=True)\n\t    class Config(ConfigMeta):\n\t        resource = \"examples/database.json\"\n\tdb_config = DatabaseConfig.load()\n\tdb_config.host = \"newhost\"\n\tdb_config.port = 5432\n\tdb_config.save()\n\tdb_config = DatabaseConfig.load()\n\tprint(db_config.host)\n", "print(db_config.port)\n\t# Output:\n\t# newhost\n\t# 5432\n\tdb_config.host = \"otherhost\"\n\tdb_config.port = 5433\n\tdb_config.at(\"host\").save()\n\tprint(db_config.host)\n\tprint(db_config.port)\n\t# Output:\n", "# otherhost\n\t# 5432  # <- not 5433, because we saved only host\n\tdb_config.host = \"anotherhost\"\n\tdb_config.at(\"port\").reload()\n\tprint(db_config.host)\n\tprint(db_config.port)\n\t# Output:\n\t# otherhost  # <- not anotherhost, because we reloaded only port\n\t# 5432\n\t```\n", "\"\"\"\n\t# pyright: reportInvalidTypeVarUse=false, reportGeneralTypeIssues=false\n\tfrom __future__ import annotations\n\timport abc\n\timport asyncio\n\timport contextvars\n\timport copy\n\timport dataclasses\n\timport functools\n\timport importlib\n", "import inspect\n\timport io\n\timport itertools\n\timport os\n\timport pathlib\n\timport sys\n\timport types\n\timport urllib.parse\n\timport urllib.request\n\tfrom collections.abc import Callable, Iterator, Mapping\n", "from typing import (\n\t    TYPE_CHECKING,\n\t    Any,\n\t    ClassVar,\n\t    Generic,\n\t    Literal,\n\t    Optional,\n\t    Union,\n\t    cast,\n\t    get_args,\n", "    get_origin,\n\t    no_type_check,\n\t    overload,\n\t)\n\timport anyconfig\n\timport pydantic\n\tfrom anyconfig.utils import filter_options, is_dict_like, is_list_like\n\tfrom pydantic.fields import make_generic_validator  # type: ignore[attr-defined]\n\tfrom pydantic.fields import ModelField, Undefined\n\tfrom pydantic.main import BaseModel, ModelMetaclass\n", "from pydantic.utils import ROOT_KEY\n\tfrom configzen._detach import (\n\t    detached_context_await,\n\t    detached_context_function,\n\t    detached_context_run,\n\t)\n\tfrom configzen.errors import (\n\t    ConfigAccessError,\n\t    InterpolationError,\n\t    ResourceLookupError,\n", "    UnavailableParserError,\n\t    UnspecifiedParserError,\n\t)\n\tfrom configzen.interpolation import (\n\t    EVALUATION_ENGINE,\n\t    INTERPOLATOR,\n\t    BaseEvaluationEngine,\n\t    BaseInterpolator,\n\t    include,\n\t    include_const,\n", "    interpolate,\n\t)\n\tfrom configzen.module import MODULE, ConfigModule\n\tfrom configzen.processor import EXPORT, DirectiveContext, Processor\n\tfrom configzen.route import ConfigRoute\n\tfrom configzen.typedefs import (\n\t    AsyncConfigIO,\n\t    ConfigIO,\n\t    ConfigModelT,\n\t    ConfigRouteLike,\n", "    IncludeExcludeT,\n\t    NormalizedResourceT,\n\t    RawResourceT,\n\t    T,\n\t)\n\ttry:\n\t    import aiofiles\n\texcept ImportError:\n\t    aiofiles = None  # type: ignore[assignment]\n\t__all__ = (\n", "    \"ConfigAgent\",\n\t    \"ConfigAt\",\n\t    \"ConfigModel\",\n\t    \"ConfigMeta\",\n\t    \"export_hook\",\n\t    \"field_hook\",\n\t    \"export_model\",\n\t    \"export_model_async\",\n\t)\n\tALL_URL_SCHEMES: set[str] = set(\n", "    urllib.parse.uses_relative + urllib.parse.uses_netloc + urllib.parse.uses_params\n\t) - {\"\"}\n\tCONTEXT: str = \"__context__\"\n\tTOKEN: str = \"__context_token__\"\n\tLOCAL: str = \"__local__\"\n\tINTERPOLATION_TRACKER: str = \"__interpolation_tracker__\"\n\tINTERPOLATION_INCLUSIONS: str = \"__interpolation_inclusions__\"\n\tcurrent_context: contextvars.ContextVar[\n\t    BaseContext[Any] | None\n\t] = contextvars.ContextVar(\"current_context\", default=None)\n", "current_interpolation_tracker: contextvars.ContextVar[\n\t    dict[str, Any] | None\n\t] = contextvars.ContextVar(\"current_interpolation_tracker\", default=None)\n\t_exporting: contextvars.ContextVar[bool] = contextvars.ContextVar(\n\t    \"_exporting\", default=False\n\t)\n\tdef _get_defaults_from_model_class(\n\t    model: type[pydantic.BaseModel],\n\t) -> dict[str, Any]:\n\t    defaults = {}\n", "    for field in model.__fields__.values():\n\t        default = field.default\n\t        if not field.field_info.exclude and not field.required:\n\t            if isinstance(default, pydantic.BaseModel):\n\t                default = default.dict()\n\t            defaults[field.alias] = default\n\t    return defaults\n\tdef _get_object_state(obj: Any) -> dict[str, Any]:\n\t    state = obj\n\t    if not isinstance(obj, dict):\n", "        state = obj.__dict__  # avoidance of vars() is intended\n\t    return cast(dict[str, Any], state)\n\t@functools.singledispatch\n\tdef export_hook(obj: Any) -> Any:\n\t    \"\"\"\n\t    Convert a value to a format that can be safely serialized.\n\t    This function is used to convert values that are not supported by\n\t    `anyconfig` to a format that can be safely serialized. It is used\n\t    internally by `ConfigModel` and `AsyncConfigModel` to convert\n\t    values before saving them to a file.\n", "    Parameters\n\t    ----------\n\t    obj\n\t        The value to convert.\n\t    Returns\n\t    -------\n\t    Any\n\t    \"\"\"\n\t    if dataclasses.is_dataclass(obj):\n\t        return export_hook(dataclasses.asdict(obj))\n", "    if isinstance(obj, tuple) and hasattr(obj, \"_asdict\") and hasattr(obj, \"_fields\"):\n\t        return _export_namedtuple(obj)\n\t    return obj\n\t@functools.singledispatch\n\tdef _export_namedtuple(obj: tuple[Any, ...]) -> Any:\n\t    # Initially I wanted it to be export_hook(obj._asdict()), but\n\t    # pydantic doesn't seem to be friends with custom NamedTuple-s.\n\t    return export_hook(list(obj))\n\tfield_hook_registrars: Any = functools.singledispatch(lambda _cls, value: value)\n\tif TYPE_CHECKING:\n", "    class _FieldHookType(Generic[T]):\n\t        def __call__(self, cls: type[T], value: Any) -> Any:\n\t            ...\n\t        def register(\n\t            self,\n\t            cls: type[T],\n\t            func: Callable[[type[T], Any], Any] | None = None,\n\t        ) -> Callable[\n\t            [Callable[[type[T], Any], Any]],\n\t            Callable[[type[T] | Any, Any], Any],\n", "        ]:\n\t            ...\n\t        def dispatch(self, cls: type[T]) -> Callable[[type[T] | Any, Any], Any]:\n\t            ...\n\t    field_hook: _FieldHookType[Any] = _FieldHookType()\n\telse:\n\t    def field_hook(cls: type[Any], value: Any) -> Any:\n\t        \"\"\"\n\t        Automatically registered pre-validator for values in fields\n\t        where the outer type is `cls`.\n", "        This function is used to load values that are not supported by\n\t        `anyconfig` to a format that can be used at runtime. It is used\n\t        by pydantic while performing validation.\n\t        Parameters\n\t        ----------\n\t        cls\n\t            The type to load the value into.\n\t        value\n\t            The value to load.\n\t        Returns\n", "        -------\n\t        The loaded value.\n\t        \"\"\"\n\t        origin = get_origin(cls)\n\t        if origin in [Union] + (\n\t            [types.UnionType] if sys.version_info >= (3, 10) else []\n\t        ):\n\t            for result in itertools.starmap(\n\t                field_hook, zip(get_args(cls), itertools.repeat(value))\n\t            ):\n", "                if result != value:\n\t                    return result\n\t            return value\n\t        try:\n\t            if isinstance(value, origin or cls):\n\t                return value\n\t        except TypeError:\n\t            return value\n\t        if origin:\n\t            cls = origin\n", "        try:\n\t            cast_func = field_hook_registrars.dispatch(cls)\n\t        except KeyError:\n\t            return value\n\t        return cast_func(cls, value)\n\t    field_hook.register = field_hook_registrars.register\n\t@functools.singledispatch\n\tdef export_model(obj: Any, **kwargs: Any) -> dict[str, Any]:\n\t    \"\"\"\n\t    Export a ConfigModel to a safely-serializable format.\n", "    Register a custom exporter for a type using the `with_exporter` decorator,\n\t    which can help to exclude particular values from the export if needed.\n\t    Parameters\n\t    ----------\n\t    obj\n\t    \"\"\"\n\t    if isinstance(obj, ConfigModel) and not _exporting.get():\n\t        return obj.export(**kwargs)\n\t    return cast(dict[str, Any], obj.dict(**kwargs))\n\t@functools.singledispatch\n", "async def export_model_async(obj: Any, **kwargs: Any) -> dict[str, Any]:\n\t    \"\"\"\n\t    Export a ConfigModel to a safely-serializable format.\n\t    Register a custom exporter for a type using the `with_exporter` decorator,\n\t    which can help to exclude particular values from the export if needed.\n\t    Parameters\n\t    ----------\n\t    obj\n\t    \"\"\"\n\t    if isinstance(obj, ConfigModel) and not _exporting.get():\n", "        return await obj.export_async(**kwargs)\n\t    return cast(dict[str, Any], await obj.dict_async(**kwargs))\n\tdef _delegate_ac_options(\n\t    load_options: dict[str, Any], dump_options: dict[str, Any], options: dict[str, Any]\n\t) -> None:\n\t    for key, value in options.items():\n\t        if key.startswith(\"dump_\"):\n\t            actual_key = key.removeprefix(\"dump_\")\n\t            targets = [dump_options]\n\t        elif key.startswith(\"load_\"):\n", "            actual_key = key.removeprefix(\"load_\")\n\t            targets = [load_options]\n\t        else:\n\t            actual_key = key\n\t            targets = [load_options, dump_options]\n\t        for target in targets:\n\t            if actual_key in target:\n\t                msg = (\n\t                    f\"Option {key}={value!r} overlaps with \"\n\t                    f\"defined {actual_key}={target[actual_key]!r}\"\n", "                )\n\t                raise ValueError(msg)\n\t            target[actual_key] = value\n\tclass ConfigAgent(Generic[ConfigModelT]):\n\t    \"\"\"\n\t    Configuration resource agent: loader and saver.\n\t    This class is used to broke between the model and the home resource, which\n\t    can be a file, a URL, or a file-like object. It is used internally\n\t    by `ConfigModel` and `AsyncConfigModel` to load and save\n\t    configuration files.\n", "    Attributes\n\t    ----------\n\t    create_if_missing\n\t        Whether to create the file if it doesn't exist.\n\t    parser_name\n\t        The name of the engines to use for loading and saving the\n\t        configuration. If not specified, the processor will be guessed\n\t        from the file extension.\n\t    allowed_url_schemes\n\t        The URL schemes that are allowed to be used.\n", "    Raises\n\t    ------\n\t    ValueError\n\t    \"\"\"\n\t    processor_class: type[Processor[ConfigModelT]]\n\t    create_if_missing: bool\n\t    is_relative: bool = False\n\t    allowed_url_schemes: set[str]\n\t    use_pydantic_json: bool = True\n\t    default_load_options: ClassVar[dict[str, Any]] = {}\n", "    default_dump_options: ClassVar[dict[str, Any]] = {\n\t        # These are usually desirable for configuration files.\n\t        # If you want to change them, you can do so by monkey-patching\n\t        # these variables. You can also change `load_options` and\n\t        # `dump_options` instance attributes to make a local change.\n\t        \"allow_unicode\": True,\n\t        \"ensure_ascii\": False,\n\t        \"indent\": 2,\n\t    }\n\t    _resource: NormalizedResourceT\n", "    predefined_default_kwargs: ClassVar[dict[str, Any]] = {\"encoding\": \"UTF-8\"}\n\t    default_allowed_url_schemes: ClassVar[set[str]] = {\"file\", \"http\", \"https\"}\n\t    OPEN_KWARGS: ClassVar[set[str]] = {\n\t        \"mode\",\n\t        \"buffering\",\n\t        \"encoding\",\n\t        \"errors\",\n\t        \"newline\",\n\t    }\n\t    URLOPEN_KWARGS: ClassVar[set[str]] = {\n", "        \"data\",\n\t        \"timeout\",\n\t        \"cafile\",\n\t        \"capath\",\n\t        \"cadefault\",\n\t        \"context\",\n\t    }\n\t    JSON_KWARGS: ClassVar[set[str]] = {\n\t        \"skipkeys\",\n\t        \"ensure_ascii\",\n", "        \"check_circular\",\n\t        \"allow_nan\",\n\t        \"cls\",\n\t        \"indent\",\n\t        \"separators\",\n\t        \"default\",\n\t        \"sort_keys\",\n\t    }\n\t    EXPORT_KWARGS: ClassVar[set[str]] = {\n\t        \"by_alias\",\n", "        \"include\",\n\t        \"exclude\",\n\t        \"exclude_unset\",\n\t        \"exclude_defaults\",\n\t        \"exclude_none\",\n\t    }\n\t    EXTRA_FILE_EXTENSIONS: ClassVar[dict[str, str]] = {\n\t        \"yml\": \"yaml\",\n\t        \"conf\": \"ini\",\n\t        \"cfg\": \"ini\",\n", "        # Note: CBOR (RFC 7049) is deprecated, use CBOR (RFC 8949) instead.\n\t        \"cbor\": \"cbor2\",\n\t        # https://github.com/msgpack/msgpack/issues/291#issuecomment-1370526984\n\t        \"mpk\": \"msgpack\",\n\t        \"pkl\": \"pickle\",\n\t    }\n\t    BINARY_DATA_PARSERS: ClassVar[set[str]] = {\n\t        \"ion\",\n\t        \"bson\",\n\t        \"cbor\",\n", "        \"cbor2\",\n\t        \"msgpack\",\n\t        \"pickle\",\n\t    }\n\t    SUPPORTED_PARSERS: list[str] = anyconfig.list_types()\n\t    def __init__(\n\t        self,\n\t        resource: RawResourceT,\n\t        parser_name: str | None = None,\n\t        processor_class: type[Processor[ConfigModelT]] | None = None,\n", "        *,\n\t        create_if_missing: bool = False,\n\t        **kwargs: Any,\n\t    ) -> None:\n\t        \"\"\"Parameters\n\t        ----------\n\t        resource\n\t            The URL to the configuration file, or a file-like object.\n\t        parser_name\n\t            The name of the anyconfig parser to use\n", "            for loading and saving the configuration.\n\t        create_if_missing\n\t            Whether to automatically create missing keys when loading the configuration.\n\t        default_kwargs\n\t            Default keyword arguments to pass while opening the resource.\n\t        use_pydantic_json\n\t            Whether to use Pydantic's JSON encoder/decoder instead of the default\n\t            anyconfig one.\n\t        uses_binary_data\n\t            Whether to treat the data as binary.\n", "            Defaults to True for formats listed in `ConfigAgent.BINARY_DATA_PARSERS`.\n\t        **kwargs\n\t            Additional keyword arguments to pass to\n\t            `anyconfig.loads()` and `anyconfig.dumps()`.\n\t        \"\"\"\n\t        self._parser_name = None\n\t        self._uses_binary_data = kwargs.get(\"uses_binary_data\", False)\n\t        if processor_class is None:\n\t            processor_class = Processor[ConfigModelT]\n\t        self.processor_class = processor_class\n", "        self.parser_name = parser_name\n\t        if isinstance(resource, (str, os.PathLike)) and not (\n\t            isinstance(resource, str)\n\t            and urllib.parse.urlparse(str(resource)).scheme in ALL_URL_SCHEMES\n\t        ):\n\t            raw_path = os.fspath(resource)\n\t            resource = pathlib.Path(raw_path)\n\t            if (\n\t                raw_path.startswith(\".\")\n\t                and resource.parts\n", "                and not resource.parts[0].startswith(\".\")\n\t            ):\n\t                self.is_relative = True\n\t        self.resource = resource\n\t        self.create_if_missing = create_if_missing\n\t        self.use_pydantic_json = kwargs.pop(\"use_pydantic_json\", True)\n\t        self.default_kwargs = kwargs.pop(\n\t            \"default_kwargs\", self.predefined_default_kwargs.copy()\n\t        )\n\t        self.allowed_url_schemes = kwargs.pop(\n", "            \"allowed_url_schemes\", self.default_allowed_url_schemes.copy()\n\t        )\n\t        self.load_options = self.default_load_options.copy()\n\t        self.dump_options = self.default_dump_options.copy()\n\t        _delegate_ac_options(self.load_options, self.dump_options, kwargs)\n\t    @property\n\t    def resource(self) -> NormalizedResourceT:\n\t        \"\"\"\n\t        The resource of the configuration.\n\t        This can be a file path, a URL, or a file-like object.\n", "        Returns\n\t        -------\n\t        The resource of the configuration.\n\t        \"\"\"\n\t        return self._resource\n\t    @resource.setter\n\t    def resource(self, value: NormalizedResourceT) -> None:\n\t        \"\"\"\n\t        The resource of the configuration.\n\t        This can be a file path, a URL, or a file-like object.\n", "        .. note::\n\t            If the resource is a file path, the processor will be guessed\n\t            from the file extension.\n\t        Returns\n\t        -------\n\t        The resource of the configuration.\n\t        \"\"\"\n\t        self._resource = value\n\t        if self.parser_name is None:\n\t            self.parser_name = self._guess_parser_name()\n", "    @property\n\t    def parser_name(self) -> str | None:\n\t        return self._parser_name\n\t    @parser_name.setter\n\t    def parser_name(self, value: str | None) -> None:\n\t        if value is not None:\n\t            value = value.casefold()\n\t        self._parser_name = value\n\t    def _guess_parser_name(self) -> str | None:\n\t        parser_name = None\n", "        if isinstance(self.resource, pathlib.Path):\n\t            suffix = self.resource.suffix[1:].casefold()\n\t            supported_parsers = self.SUPPORTED_PARSERS\n\t            if not suffix:\n\t                recognized_file_extensions = supported_parsers + [\n\t                    alias + \"(-> \" + actual_parser_name + \")\"\n\t                    for alias, actual_parser_name in self.EXTRA_FILE_EXTENSIONS.items()\n\t                    if actual_parser_name in supported_parsers\n\t                ]\n\t                msg = (\n", "                    \"Could not guess the anyconfig parser to use for \"\n\t                    f\"{self.resource!r}.\\n\"\n\t                    f\"Recognized file extensions: {recognized_file_extensions}\"\n\t                )\n\t                raise UnspecifiedParserError(msg)\n\t            parser_name = self.EXTRA_FILE_EXTENSIONS.get(suffix, suffix)\n\t            if (\n\t                parser_name == \"cbor2\"\n\t                and \"cbor2\" not in supported_parsers\n\t                and \"cbor\" in supported_parsers\n", "            ):\n\t                parser_name = \"cbor\"\n\t        return parser_name\n\t    def load_into(\n\t        self,\n\t        config_class: type[ConfigModelT],\n\t        blob: str | bytes,\n\t        parser_name: str | None = None,\n\t        **kwargs: Any,\n\t    ) -> ConfigModelT:\n", "        \"\"\"\n\t        Load the configuration into a `ConfigModel` subclass.\n\t        Parameters\n\t        ----------\n\t        config_class\n\t            The `ConfigModel` subclass to load the configuration into.\n\t        blob\n\t            The configuration to load.\n\t        parser_name\n\t            The name of the engines to use for loading the configuration.\n", "        **kwargs\n\t            Additional keyword arguments to pass to `anyconfig.loads()`.\n\t        Returns\n\t        -------\n\t        The loaded configuration.\n\t        \"\"\"\n\t        dict_config = self.load_dict(blob, parser_name=parser_name, **kwargs)\n\t        if dict_config is None:\n\t            dict_config = {}\n\t        return config_class.parse_obj(dict_config)\n", "    async def async_load_into(\n\t        self,\n\t        config_class: type[ConfigModelT],\n\t        blob: str | bytes,\n\t        parser_name: str | None = None,\n\t        **kwargs: Any,\n\t    ) -> ConfigModelT:\n\t        \"\"\"\n\t        Load the configuration into a `ConfigModel` subclass asynchronously.\n\t        Parameters\n", "        ----------\n\t        config_class\n\t            The `ConfigModel` subclass to load the configuration into.\n\t        blob\n\t            The configuration to load.\n\t        parser_name\n\t            The name of the engines to use for loading the configuration.\n\t        **kwargs\n\t            Additional keyword arguments to pass to `anyconfig.loads()`.\n\t        Returns\n", "        -------\n\t        The loaded configuration.\n\t        \"\"\"\n\t        dict_config = await self.load_dict_async(\n\t            blob, parser_name=parser_name, **kwargs\n\t        )\n\t        if dict_config is None:\n\t            dict_config = {}\n\t        return config_class.parse_obj(dict_config)\n\t    def _load_dict_impl(\n", "        self,\n\t        blob: str | bytes,\n\t        parser_name: str | None = None,\n\t        **kwargs: Any,\n\t    ) -> dict[str, Any]:\n\t        parser_name = parser_name or self.parser_name or self._guess_parser_name()\n\t        if parser_name is None:\n\t            msg = \"Cannot read configuration because `parser_name` was not specified\"\n\t            raise UnspecifiedParserError(msg)\n\t        kwargs = self.load_options | kwargs\n", "        try:\n\t            loaded = anyconfig.loads(  # type: ignore[no-untyped-call]\n\t                blob, ac_parser=parser_name, **kwargs\n\t            )\n\t        except anyconfig.UnknownParserTypeError as exc:\n\t            raise UnavailableParserError(str(exc).split()[-1], self) from exc\n\t        if not isinstance(loaded, Mapping):\n\t            msg = (\n\t                f\"Expected a mapping as a result of loading {self.resource}, \"\n\t                f\"got {type(loaded).__name__}.\"\n", "            )\n\t            raise TypeError(msg)\n\t        return dict(loaded)\n\t    def load_dict(\n\t        self,\n\t        blob: str | bytes,\n\t        parser_name: str | None = None,\n\t        *,\n\t        preprocess: bool = True,\n\t        **kwargs: Any,\n", "    ) -> dict[str, Any]:\n\t        \"\"\"\n\t        Load the configuration into a dictionary. The dictionary is\n\t        usually used to initialize a `ConfigModel` subclass. If the\n\t        configuration is empty, None might be returned instead of a dictionary.\n\t        Parameters\n\t        ----------\n\t        blob\n\t            The configuration to load.\n\t        parser_name\n", "            The name of the anyconfig parser to use for loading the configuration.\n\t        preprocess\n\t        **kwargs\n\t            Additional keyword arguments to pass to `anyconfig.loads()`.\n\t        Returns\n\t        -------\n\t        The loaded configuration dictionary.\n\t        \"\"\"\n\t        loaded = self._load_dict_impl(blob, parser_name=parser_name, **kwargs)\n\t        if preprocess:\n", "            loaded = self.processor_class(self, loaded).preprocess()\n\t        return loaded\n\t    async def load_dict_async(\n\t        self,\n\t        blob: str | bytes,\n\t        parser_name: str | None = None,\n\t        *,\n\t        preprocess: bool = True,\n\t        **kwargs: Any,\n\t    ) -> dict[str, Any]:\n", "        \"\"\"\n\t        Load the configuration into a dictionary asynchronously.\n\t        Parameters\n\t        ----------\n\t        blob\n\t            The configuration to load.\n\t        parser_name\n\t            The name of the anyconfig parser to use for loading the configuration.\n\t        preprocess\n\t        **kwargs\n", "            Additional keyword arguments to pass to `anyconfig.loads()`.\n\t        Returns\n\t        -------\n\t        The loaded configuration dictionary.\n\t        \"\"\"\n\t        loaded = self._load_dict_impl(blob, parser_name, **kwargs)\n\t        if preprocess:\n\t            loaded = await self.processor_class(self, loaded).preprocess_async()\n\t        return loaded\n\t    def dump_config(\n", "        self,\n\t        config: ConfigModelT,\n\t        parser_name: str | None = None,\n\t        **kwargs: Any,\n\t    ) -> str:\n\t        \"\"\"\n\t        Dump the configuration to a string.\n\t        Parameters\n\t        ----------\n\t        config\n", "            The configuration to dump.\n\t        parser_name\n\t            The name of the anyconfig parser to use for saving the configuration.\n\t        **kwargs\n\t            Additional keyword arguments to pass to `anyconfig.dumps()`.\n\t        Returns\n\t        -------\n\t        The dumped configuration.\n\t        \"\"\"\n\t        if parser_name is None:\n", "            parser_name = self.parser_name\n\t        export_kwargs = filter_options(self.EXPORT_KWARGS, kwargs)\n\t        if parser_name == \"json\" and self.use_pydantic_json:\n\t            export_kwargs |= filter_options(\n\t                self.JSON_KWARGS, self.dump_options | kwargs\n\t            )\n\t            _exporting.set(True)  # noqa: FBT003\n\t            return detached_context_run(config.json, **export_kwargs)\n\t        data = export_model(config, **export_kwargs)\n\t        return self.dump_data(data, parser_name=parser_name, **kwargs)\n", "    async def dump_config_async(\n\t        self,\n\t        config: ConfigModelT,\n\t        parser_name: str | None = None,\n\t        **kwargs: Any,\n\t    ) -> str:\n\t        \"\"\"\n\t        Dump the configuration to a string.\n\t        Parameters\n\t        ----------\n", "        config\n\t            The configuration to dump.\n\t        parser_name\n\t            The name of the anyconfig parser to use for saving the configuration.\n\t        **kwargs\n\t            Additional keyword arguments to pass to `anyconfig.dumps()`.\n\t        Returns\n\t        -------\n\t        The dumped configuration.\n\t        \"\"\"\n", "        if parser_name is None:\n\t            parser_name = self.parser_name\n\t        export_kwargs = filter_options(self.EXPORT_KWARGS, kwargs)\n\t        if parser_name == \"json\" and self.use_pydantic_json:\n\t            export_kwargs |= filter_options(\n\t                self.JSON_KWARGS, self.dump_options | kwargs\n\t            )\n\t            _exporting.set(True)  # noqa: FBT003\n\t            return await detached_context_await(config.json_async, **export_kwargs)\n\t        data = await export_model_async(config, **export_kwargs)\n", "        return self.dump_data(data, parser_name=parser_name, **kwargs)\n\t    def dump_data(\n\t        self,\n\t        data: dict[str, Any],\n\t        parser_name: str | None = None,\n\t        **kwargs: Any,\n\t    ) -> str:\n\t        \"\"\"\n\t        Dump data to a string.\n\t        Parameters\n", "        ----------\n\t        data\n\t            The data to dump.\n\t        parser_name\n\t            The name of the anyconfig parser to use for saving the configuration.\n\t        kwargs\n\t            Additional keyword arguments to pass to `anyconfig.dumps()`.\n\t        Returns\n\t        -------\n\t        The dumped configuration.\n", "        \"\"\"\n\t        if parser_name is None:\n\t            parser_name = self.parser_name\n\t        if parser_name is None:\n\t            msg = (\n\t                \"Cannot write configuration because `parser_name` was not specified\"\n\t                f\"for agent {self}\"\n\t            )\n\t            raise UnspecifiedParserError(msg)\n\t        kwargs = self.dump_options | kwargs\n", "        return anyconfig.dumps(export_hook(data), ac_parser=parser_name, **kwargs)\n\t    @property\n\t    def is_url(self) -> bool:\n\t        \"\"\"\n\t        Whether the resource is a URL.\n\t        This simply checks if the resource object is a string, since local paths\n\t        are converted into `pathlib.Path` objects.\n\t        \"\"\"\n\t        return isinstance(self.resource, str)\n\t    @property\n", "    def uses_binary_data(self) -> bool:\n\t        \"\"\"\n\t        Whether the resource uses bytes for storing data, not str.\n\t        \"\"\"\n\t        return self._uses_binary_data or self.parser_name in self.BINARY_DATA_PARSERS\n\t    def open_resource(self, **kwds: Any) -> ConfigIO:\n\t        \"\"\"\n\t        Open the configuration file.\n\t        Parameters\n\t        ----------\n", "        **kwds\n\t            Keyword arguments to pass to the opening routine.\n\t            For URLs, these are passed to ``urllib.request.urllib.request.urlopen()``.\n\t            For local files, these are passed to ``builtins.open()``.\n\t        Returns\n\t        -------\n\t        The opened resource.\n\t        \"\"\"\n\t        if self.resource is None:\n\t            if self.uses_binary_data:\n", "                return io.BytesIO()\n\t            return io.StringIO()\n\t        if self.is_url:\n\t            url = urllib.parse.urlparse(cast(str, self.resource))\n\t            if url.scheme not in self.allowed_url_schemes:\n\t                msg = (\n\t                    f\"URL scheme {url.scheme!r} is not allowed, \"\n\t                    f\"must be one of {self.allowed_url_schemes!r}\"\n\t                )\n\t                raise ValueError(msg)\n", "            kwds = filter_options(self.URLOPEN_KWARGS, kwds)\n\t            request = urllib.request.Request(url.geturl())\n\t            return cast(ConfigIO, urllib.request.urlopen(request, **kwds))  # noqa: S310\n\t        if isinstance(self.resource, (int, pathlib.Path)):\n\t            kwds = filter_options(self.OPEN_KWARGS, kwds)\n\t            if isinstance(self.resource, int):\n\t                return cast(\n\t                    ConfigIO,\n\t                    # We intentionally do not use the context manager here\n\t                    # because we do not want to close the file.\n", "                    # Moreover, we want to allow the file to be opened\n\t                    # from a file descriptor, not supported by Path().\n\t                    open(self.resource, **kwds),  # noqa: PTH123, SIM115\n\t                )\n\t            return cast(ConfigIO, pathlib.Path(self.resource).open(**kwds))\n\t        return cast(ConfigIO, self.resource)\n\t    def open_resource_async(self, **kwds: Any) -> AsyncConfigIO:\n\t        \"\"\"\n\t        Open the configuration file asynchronously.\n\t        Parameters\n", "        ----------\n\t        **kwds\n\t            Keyword arguments to pass to the opening routine.\n\t        Returns\n\t        -------\n\t        The opened resource.\n\t        \"\"\"\n\t        if self.is_url:\n\t            msg = \"Asynchronous URL opening is not supported\"\n\t            raise NotImplementedError(msg)\n", "        if aiofiles is None:\n\t            msg = (\n\t                \"Aiofiles is not available, cannot open file \"\n\t                \"asynchronously (install with `pip install aiofiles`)\"\n\t            )\n\t            raise RuntimeError(msg)\n\t        if isinstance(self.resource, (int, pathlib.Path)):\n\t            kwds = filter_options(self.OPEN_KWARGS, kwds)\n\t            return aiofiles.open(self.resource, **kwds)\n\t        raise RuntimeError(\"cannot open resource asynchronously\")\n", "    def processor_open_resource(self, **kwargs: Any) -> ConfigIO:\n\t        \"\"\"\n\t        Called by the processor to open a configuration resource\n\t        with the reading intention.\n\t        Parameters\n\t        ----------\n\t        **kwargs\n\t            Keyword arguments to pass to the opening routine.\n\t            For URLs, these are passed to ``urllib.request.urlopen()``.\n\t            For local files, these are passed to ``builtins.open()``.\n", "        Returns\n\t        -------\n\t        The opened resource.\n\t        \"\"\"\n\t        kwargs = self._get_default_kwargs(\"read\", kwargs)\n\t        return self.open_resource(**kwargs)\n\t    def processor_open_resource_async(self, **kwargs: Any) -> AsyncConfigIO:\n\t        \"\"\"\n\t        Called by the processor to open a configuration resource asynchronously\n\t        with the reading intention.\n", "        Parameters\n\t        ----------\n\t        **kwargs\n\t            Keyword arguments to pass to the opening routine.\n\t            For URLs, these are passed to ``urllib.request.urlopen()``.\n\t            For local files, these are passed to ``builtins.open()``.\n\t        Returns\n\t        -------\n\t        The opened resource.\n\t        \"\"\"\n", "        kwargs = self._get_default_kwargs(\"read\", kwargs)\n\t        return self.open_resource_async(**kwargs)\n\t    def _get_default_kwargs(\n\t        self,\n\t        method: Literal[\"read\", \"write\"],\n\t        kwargs: dict[str, Any] | None = None,\n\t    ) -> dict[str, Any]:\n\t        if not kwargs:\n\t            kwargs = self.default_kwargs\n\t        new_kwargs = cast(dict[str, Any], kwargs).copy()\n", "        if not self.is_url:\n\t            if method == \"read\":\n\t                new_kwargs.setdefault(\"mode\", \"rb\" if self.uses_binary_data else \"r\")\n\t            elif method == \"write\":\n\t                new_kwargs.setdefault(\"mode\", \"wb\" if self.uses_binary_data else \"w\")\n\t            else:\n\t                msg = f\"Invalid resource access method: {method!r}\"\n\t                raise ValueError(msg)\n\t        if self.uses_binary_data:\n\t            new_kwargs.pop(\"encoding\", None)\n", "        return new_kwargs\n\t    def read(\n\t        self,\n\t        *,\n\t        config_class: type[ConfigModelT],\n\t        create_kwargs: dict[str, Any] | None = None,\n\t        **kwargs: Any,\n\t    ) -> ConfigModelT:\n\t        \"\"\"\n\t        Read the configuration file.\n", "        Parameters\n\t        ----------\n\t        config_class\n\t            The configuration model class to load the configuration into.\n\t        create_kwargs\n\t            Keyword arguments to pass to the open method\n\t            when optionally creating the file.\n\t        **kwargs\n\t            Keyword arguments to pass to the open method.\n\t        Returns\n", "        -------\n\t        The loaded configuration.\n\t        \"\"\"\n\t        kwargs = self._get_default_kwargs(\"read\", kwargs=kwargs)\n\t        try:\n\t            with self.open_resource(**kwargs) as fp:\n\t                blob = fp.read()\n\t        except FileNotFoundError:\n\t            if self.create_if_missing:\n\t                defaults = _get_defaults_from_model_class(config_class)\n", "                blob = self.dump_data(defaults)\n\t                self.write(blob, **(create_kwargs or {}))\n\t            else:\n\t                raise\n\t        return self.load_into(config_class, blob, **self.load_options)\n\t    def write(self, blob: str | bytes, **kwargs: Any) -> int:\n\t        \"\"\"\n\t        Write the configuration file.\n\t        Parameters\n\t        ----------\n", "        blob\n\t            The string/bytes to write into the resource.\n\t        kwargs\n\t            Keyword arguments to pass to the opening routine.\n\t        Returns\n\t        -------\n\t        The number of bytes written.\n\t        \"\"\"\n\t        kwargs = self._get_default_kwargs(\"write\", kwargs=kwargs)\n\t        with self.open_resource(**kwargs) as fp:\n", "            return fp.write(cast(str, blob))\n\t    async def read_async(\n\t        self,\n\t        *,\n\t        config_class: type[ConfigModelT],\n\t        create_kwargs: dict[str, Any] | None = None,\n\t        **kwargs: Any,\n\t    ) -> ConfigModelT:\n\t        \"\"\"\n\t        Read the configuration file asynchronously.\n", "        Parameters\n\t        ----------\n\t        config_class\n\t            The configuration model class to load the configuration into.\n\t        create_kwargs\n\t            Keyword arguments to pass to the open method\n\t            when optionally creating the file.\n\t        **kwargs\n\t            Keyword arguments to pass to the open method.\n\t        Returns\n", "        -------\n\t        The loaded configuration.\n\t        \"\"\"\n\t        kwargs = self._get_default_kwargs(\"read\", kwargs=kwargs)\n\t        try:\n\t            async with self.open_resource_async(**kwargs) as fp:\n\t                blob = await fp.read()\n\t        except FileNotFoundError:\n\t            if self.create_if_missing:\n\t                defaults = _get_defaults_from_model_class(config_class)\n", "                blob = self.dump_data(defaults)\n\t                await self.write_async(blob, **(create_kwargs or {}))\n\t            else:\n\t                raise\n\t        return await self.async_load_into(config_class, blob, **self.load_options)\n\t    async def write_async(\n\t        self,\n\t        blob: str | bytes,\n\t        **kwargs: Any,\n\t    ) -> int:\n", "        \"\"\"\n\t        Write the configuration file asynchronously.\n\t        Parameters\n\t        ----------\n\t        blob\n\t            The string/bytes to write into the resource.\n\t        kwargs\n\t            Keyword arguments to pass to the opening routine.\n\t        Returns\n\t        -------\n", "        The number of bytes written.\n\t        \"\"\"\n\t        kwargs = self._get_default_kwargs(\"write\", kwargs=kwargs)\n\t        async with self.open_resource_async(**kwargs) as fp:\n\t            # Technically those might be also bytes,\n\t            # todo(bswck): type hint it properly...\n\t            return await fp.write(cast(str, blob))\n\t    @classmethod\n\t    def from_directive_context(\n\t        cls,\n", "        ctx: DirectiveContext,\n\t        /,\n\t        route_separator: str = \":\",\n\t        route_class: type[ConfigRoute] | None = None,\n\t    ) -> tuple[ConfigAgent[ConfigModelT], ConfigRouteLike | None]:\n\t        \"\"\"\n\t        Create a configuration agent from a preprocessor directive context.\n\t        Return an optional scope that the context points to.\n\t        Parameters\n\t        ----------\n", "        route_class\n\t        route_separator\n\t        ctx\n\t        Returns\n\t        -------\n\t        The configuration agent.\n\t        \"\"\"\n\t        if route_class is None:\n\t            route_class = ConfigRoute\n\t        route: ConfigRouteLike | None = None\n", "        args: list[Any] = []\n\t        kwargs: dict[str, Any] = {}\n\t        if isinstance(ctx.snippet, str):\n\t            path, _, route = ctx.snippet.partition(route_separator)\n\t            route = ConfigRoute(\n\t                route.strip().replace(route_separator, route_class.TOK_DOT)\n\t            )\n\t            args.append(path)\n\t        elif isinstance(ctx.snippet, int):\n\t            args.append(ctx.snippet)\n", "        elif is_dict_like(ctx.snippet):\n\t            kwargs |= ctx.snippet\n\t        elif is_list_like(ctx.snippet):\n\t            args += list(ctx.snippet)\n\t        else:\n\t            msg = (\n\t                f\"Invalid snippet for the {ctx.directive!r} directive: {ctx.snippet!r}\"\n\t            )\n\t            raise ValueError(msg)\n\t        return cls(*args, **kwargs), str(route)\n", "    @classmethod\n\t    def register_file_extension(\n\t        cls,\n\t        file_extension: str,\n\t        *,\n\t        parser_name: str,\n\t    ) -> None:\n\t        \"\"\"\n\t        Register a file extension with the proper anyconfig parser to use.\n\t        Parameters\n", "        ----------\n\t        file_extension\n\t        parser_name\n\t        Returns\n\t        -------\n\t        \"\"\"\n\t        cls.EXTRA_FILE_EXTENSIONS[file_extension] = parser_name\n\t    def __repr__(self) -> str:\n\t        resource = self.resource\n\t        return f\"{type(self).__name__}({resource=!r})\"\n", "def at(\n\t    mapping: Any,\n\t    route: ConfigRouteLike,\n\t    converter_func: Callable[[Any], dict[str, Any]] = _get_object_state,\n\t    agent: ConfigAgent[ConfigModelT] | None = None,\n\t) -> Any:\n\t    \"\"\"\n\t    Get an item at a route.\n\t    Parameters\n\t    ----------\n", "    mapping\n\t        The mapping to use.\n\t    route\n\t        The route to the item.\n\t    converter_func\n\t    agent\n\t    Returns\n\t    -------\n\t    The item at the route.\n\t    \"\"\"\n", "    route = ConfigRoute(route)\n\t    route_here = []\n\t    scope = converter_func(mapping)\n\t    try:\n\t        for part in route:\n\t            route_here.append(part)\n\t            scope = converter_func(scope)[part]\n\t    except KeyError:\n\t        raise ResourceLookupError(agent, route_here) from None\n\t    return scope\n", "@dataclasses.dataclass(frozen=True)\n\tclass ConfigAt(Generic[ConfigModelT]):\n\t    \"\"\"\n\t    A configuration item at a specific location.\n\t    Attributes\n\t    ----------\n\t    owner\n\t        The configuration model instance.\n\t    mapping\n\t        The mapping to use.\n", "    route\n\t        The route to the item.\n\t    \"\"\"\n\t    owner: ConfigModelT\n\t    mapping: dict[str, Any] | None\n\t    route: ConfigRouteLike\n\t    def get(\n\t        self, route: ConfigRouteLike | None = None, default: Any = Undefined\n\t    ) -> Any:\n\t        \"\"\"\n", "        Get the value of the item.\n\t        Parameters\n\t        ----------\n\t        route\n\t            The route to the item. If not given, the sole route of this item is used.\n\t            If given, the route is appended to the sole route of this item.\n\t        default\n\t            The default value to return if the item is not found.\n\t        Returns\n\t        -------\n", "        The value of the item.\n\t        \"\"\"\n\t        base_route = ConfigRoute(self.route)\n\t        if route is None:\n\t            route = base_route\n\t        else:\n\t            route = base_route.enter(ConfigRoute(route, allow_empty=True))\n\t        try:\n\t            scope = at(self.mapping or self.owner, route)\n\t        except ResourceLookupError as err:\n", "            if default is Undefined:\n\t                route_here = err.route\n\t                raise ConfigAccessError(self.owner, route_here) from None\n\t            scope = default\n\t        return scope\n\t    def update(self, value: Any) -> Any:\n\t        \"\"\"\n\t        Update the value of the item with regard to this item mapping.\n\t        Parameters\n\t        ----------\n", "        value\n\t            The new value.\n\t        Returns\n\t        -------\n\t        The updated mapping.\n\t        \"\"\"\n\t        route = list(ConfigRoute(self.route))\n\t        mapping = self.mapping or self.owner\n\t        key = route.pop()\n\t        scope = _get_object_state(mapping)\n", "        route_here = []\n\t        try:\n\t            for part in route:\n\t                route_here.append(part)\n\t                scope = _get_object_state(scope[part])\n\t            scope[key] = value\n\t        except KeyError:\n\t            raise ConfigAccessError(self.owner, route_here) from None\n\t        return mapping\n\t    async def save_async(self, **kwargs: Any) -> int:\n", "        \"\"\"\n\t        Save the configuration asynchronously.\n\t        Parameters\n\t        ----------\n\t        **kwargs\n\t            Keyword arguments to pass to the saving function.\n\t        Returns\n\t        -------\n\t        The number of bytes written.\n\t        \"\"\"\n", "        return await _partial_save_async(self, **kwargs)\n\t    def save(self, **kwargs: Any) -> int:\n\t        \"\"\"\n\t        Save the configuration.\n\t        Parameters\n\t        ----------\n\t        **kwargs\n\t            Keyword arguments to pass to the saving function.\n\t        Returns\n\t        -------\n", "        The number of bytes written.\n\t        \"\"\"\n\t        return _partial_save(self, **kwargs)\n\t    async def reload_async(self, **kwargs: Any) -> Any:\n\t        \"\"\"\n\t        Reload the configuration asynchronously.\n\t        Parameters\n\t        ----------\n\t        kwargs\n\t            Keyword arguments to pass to the reloading function.\n", "        Returns\n\t        -------\n\t        The reloaded configuration or its belonging item.\n\t        \"\"\"\n\t        return await _partial_reload_async(self, **kwargs)\n\t    def reload(self, **kwargs: Any) -> Any:\n\t        \"\"\"\n\t        Reload the configuration.\n\t        Parameters\n\t        ----------\n", "        kwargs\n\t            Keyword arguments to pass to the reloading function.\n\t        Returns\n\t        -------\n\t        The reloaded configuration or its belonging item.\n\t        \"\"\"\n\t        return _partial_reload(self, **kwargs)\n\tdef _partial_save(\n\t    section: ConfigModelT | ConfigAt[ConfigModelT],\n\t    write_kwargs: dict[str, Any] | None = None,\n", "    **kwargs: Any,\n\t) -> int:\n\t    if isinstance(section, ConfigModel):\n\t        config = section\n\t        return config.save(write_kwargs=write_kwargs, **kwargs)\n\t    if write_kwargs is None:\n\t        write_kwargs = {}\n\t    config = section.owner\n\t    data = config.initial_state\n\t    scope = ConfigAt(config, data, section.route)\n", "    data = scope.update(section.get())\n\t    context = get_context(config)\n\t    blob = context.agent.dump_config(config.copy(update=data), **kwargs)\n\t    result = config.write(blob, **write_kwargs)\n\t    context.initial_state = data\n\t    return result\n\tasync def _partial_save_async(\n\t    section: ConfigModelT | ConfigAt[ConfigModelT],\n\t    write_kwargs: dict[str, Any] | None = None,\n\t    **kwargs: Any,\n", ") -> int:\n\t    if isinstance(section, ConfigModel):\n\t        config = section\n\t        return await config.save_async(write_kwargs=write_kwargs, **kwargs)\n\t    if write_kwargs is None:\n\t        write_kwargs = {}\n\t    config = section.owner\n\t    data = config.initial_state\n\t    scope = ConfigAt(config, data, section.route)\n\t    data = scope.update(section.get())\n", "    context = get_context(config)\n\t    blob = context.agent.dump_config(config.copy(update=data), **kwargs)\n\t    result = await config.write_async(blob, **write_kwargs)\n\t    context.initial_state = data\n\t    return result\n\tdef _partial_reload(\n\t    section: ConfigModelT | ConfigAt[ConfigModelT], **kwargs: Any\n\t) -> Any:\n\t    if isinstance(section, ConfigModel):\n\t        config = section\n", "        return config.reload()\n\t    config = section.owner\n\t    context = get_context(config)\n\t    state = config.__dict__\n\t    newest = context.agent.read(config_class=type(config), **kwargs)\n\t    section_data = ConfigAt(newest, newest.__dict__, section.route).get()\n\t    ConfigAt(config, state, section.route).update(section_data)\n\t    return section_data\n\tasync def _partial_reload_async(\n\t    section: ConfigModelT | ConfigAt[ConfigModelT], **kwargs: Any\n", ") -> Any:\n\t    if isinstance(section, ConfigModel):\n\t        config = section\n\t        return await config.reload_async()\n\t    config = section.owner\n\t    context = get_context(config)\n\t    state = config.__dict__\n\t    newest = await context.agent.read_async(config_class=type(config), **kwargs)\n\t    section_data = ConfigAt(newest, newest.__dict__, section.route).get()\n\t    ConfigAt(config, state, section.route).update(section_data)\n", "    return section_data\n\tclass BaseContext(abc.ABC, Generic[ConfigModelT]):\n\t    \"\"\"\n\t    The base class for configuration context.\n\t    Contexts are used to\n\t    - store configuration resource information,\n\t    - link configuration items to the configuration models they belong to,\n\t    - keep track of the route leading to particular configuration\n\t      items that are also ConfigModel subclasses.\n\t    Attributes\n", "    ----------\n\t    initial_state\n\t        The initial configuration state.\n\t    \"\"\"\n\t    initial_state: dict[str, Any]\n\t    interpolation_namespace: dict[str, Any]\n\t    @abc.abstractmethod\n\t    def trace_route(self) -> Iterator[str]:\n\t        \"\"\"Trace the route to where the configuration subcontext points to.\"\"\"\n\t    @property\n", "    def route(self) -> ConfigRoute:\n\t        \"\"\"The route to where the configuration subcontext points to.\"\"\"\n\t        return ConfigRoute(list(self.trace_route()))\n\t    @overload\n\t    def enter(self: BaseContext[ConfigModelT], part: None) -> BaseContext[ConfigModelT]:\n\t        ...\n\t    @overload\n\t    def enter(self, part: str) -> Subcontext[ConfigModelT]:\n\t        ...\n\t    def enter(\n", "        self, part: str | None\n\t    ) -> Subcontext[ConfigModelT] | BaseContext[ConfigModelT]:\n\t        \"\"\"\n\t        Enter a subcontext.\n\t        Parameters\n\t        ----------\n\t        part\n\t            The name of the item nested in the item this context points to.\n\t        Returns\n\t        -------\n", "        The new subcontext.\n\t        \"\"\"\n\t        if part is None:\n\t            return self\n\t        return Subcontext(self, part, self.interpolation_namespace.setdefault(part, {}))\n\t    @property\n\t    @abc.abstractmethod\n\t    def agent(self) -> ConfigAgent[ConfigModelT]:\n\t        \"\"\"The configuration agent responsible for loading and saving.\"\"\"\n\t    @property\n", "    @abc.abstractmethod\n\t    def toplevel_interpolation_namespace(self) -> dict[str, Any]:\n\t        \"\"\"Top-level interpolation namespace.\"\"\"\n\t    @property\n\t    @abc.abstractmethod\n\t    def owner(self) -> ConfigModelT | None:\n\t        \"\"\"\n\t        The top-level configuration model instance,\n\t        holding all adjacent contexts.\n\t        \"\"\"\n", "    @property\n\t    @abc.abstractmethod\n\t    def at(self) -> ConfigModelT | ConfigAt[ConfigModelT] | None:\n\t        \"\"\"\n\t        The configuration model instance or the configuration item\n\t        this context points to.\n\t        \"\"\"\n\tclass Context(BaseContext[ConfigModelT], Generic[ConfigModelT]):\n\t    \"\"\"\n\t    The context of a configuration model.\n", "    Parameters\n\t    ----------\n\t    agent\n\t        The configuration resource agent.\n\t    owner\n\t        The top-level configuration model instance,\n\t        holding all belonging subcontexts.\n\t    \"\"\"\n\t    _initial_state: dict[str, Any]\n\t    def __init__(\n", "        self,\n\t        agent: ConfigAgent[ConfigModelT],\n\t        owner: ConfigModelT | None = None,\n\t    ) -> None:\n\t        self._initial_state = {}\n\t        self._owner = None\n\t        self._agent = agent\n\t        self.interpolation_namespace = {}\n\t        self.owner = owner\n\t    def trace_route(self) -> Iterator[str]:\n", "        yield from ()\n\t    @property\n\t    def agent(self) -> ConfigAgent[ConfigModelT]:\n\t        return self._agent\n\t    @property\n\t    def toplevel_interpolation_namespace(self) -> dict[str, Any]:\n\t        return self.interpolation_namespace\n\t    @property\n\t    def at(self) -> ConfigModelT | None:\n\t        return self.owner\n", "    @property\n\t    def owner(self) -> ConfigModelT | None:\n\t        return self._owner\n\t    @owner.setter\n\t    def owner(self, config: ConfigModelT | None) -> None:\n\t        if config is None:\n\t            return\n\t        self._owner = config\n\t    @property\n\t    def initial_state(self) -> dict[str, Any]:\n", "        return copy.deepcopy(self._initial_state)\n\t    @initial_state.setter\n\t    def initial_state(self, initial_state: dict[str, Any]) -> None:\n\t        self._initial_state = copy.deepcopy(initial_state)\n\t    def __repr__(self) -> str:\n\t        agent = self.agent\n\t        return (\n\t            f\"<{type(self).__name__} \"\n\t            f\"of {type(self.owner).__name__!r} configuration \"\n\t            f\"({agent=})>\"\n", "        )\n\tclass Subcontext(BaseContext[ConfigModelT], Generic[ConfigModelT]):\n\t    \"\"\"\n\t    The subcontext of a configuration model.\n\t    Parameters\n\t    ----------\n\t    parent\n\t        The parent context.\n\t    part\n\t        The name of the item nested in the item the parent context points to.\n", "    \"\"\"\n\t    __slots__ = (\"_parent\", \"_part\", \"_interpolation_namespace\")\n\t    def __init__(\n\t        self,\n\t        parent: BaseContext[ConfigModelT],\n\t        part: str,\n\t        interpolation_namespace: dict[str, Any],\n\t    ) -> None:\n\t        self._parent = parent\n\t        self._part = part\n", "        self.interpolation_namespace = interpolation_namespace\n\t    @property\n\t    def agent(self) -> ConfigAgent[ConfigModelT]:\n\t        return self._parent.agent\n\t    @property\n\t    def toplevel_interpolation_namespace(self) -> dict[str, Any]:\n\t        return self._parent.toplevel_interpolation_namespace\n\t    def trace_route(self) -> Iterator[str]:\n\t        yield from self._parent.trace_route()\n\t        yield self._part\n", "    @property\n\t    def at(self) -> ConfigAt[ConfigModelT]:\n\t        if self.owner is None:\n\t            msg = \"Cannot get at() of a model without parent model\"\n\t            raise ValueError(msg)\n\t        return ConfigAt(self.owner, None, self.route)\n\t    @property\n\t    def owner(self) -> ConfigModelT | None:\n\t        return self._parent.owner\n\t    @property\n", "    def initial_state(self) -> dict[str, Any]:\n\t        return self._parent.initial_state\n\t    @initial_state.setter\n\t    def initial_state(self, value: dict[str, Any]) -> None:\n\t        data = self._parent.initial_state\n\t        data[self._part] = copy.deepcopy(value)\n\t        self._parent.initial_state = data\n\t    def __repr__(self) -> str:\n\t        agent = self.agent\n\t        route = self.route\n", "        return (\n\t            f\"<{type(self).__name__} \"\n\t            f\"of {type(self.owner).__name__ + '.' + str(route)!r} configuration \"\n\t            f\"({agent=})>\"\n\t        )\n\tdef get_context(config: ConfigModelT) -> BaseContext[ConfigModelT]:\n\t    \"\"\"\n\t    Get the context of the configuration model.\n\t    Parameters\n\t    ----------\n", "    config\n\t        The configuration model instance.\n\t    Returns\n\t    -------\n\t    The context of the configuration model.\n\t    \"\"\"\n\t    context = get_context_or_none(config)\n\t    if context is None:\n\t        raise RuntimeError(\n\t            \"This model is either inside a list \"\n", "            \"or was not loaded by a configuration agent.\"\n\t        )\n\t    return context\n\tdef get_context_or_none(config: ConfigModelT) -> BaseContext[ConfigModelT] | None:\n\t    \"\"\"\n\t    Get the context of the configuration model safely.\n\t    Parameters\n\t    ----------\n\t    config\n\t        The configuration model instance.\n", "    Returns\n\t    -------\n\t    The context of the configuration model.\n\t    \"\"\"\n\t    return cast(\n\t        Optional[BaseContext[ConfigModelT]], getattr(config, LOCAL).get(current_context)\n\t    )\n\t# noinspection PyUnusedLocal\n\t@make_generic_validator\n\tdef _common_field_validator(\n", "    cls: type[ConfigModelT],\n\t    v: Any,\n\t    values: dict[str, Any],\n\t    field: pydantic.fields.ModelField,\n\t    config: pydantic.BaseConfig,\n\t) -> Any:\n\t    post_hook_value = field_hook(field.outer_type_, v)\n\t    disallow_interpolation = getattr(config, \"disallow_interpolation\", False)\n\t    disallowed_interpolation_fields = set()\n\t    interpolation_tracker = current_interpolation_tracker.get()\n", "    if interpolation_tracker is None:\n\t        interpolation_tracker = {}\n\t        current_interpolation_tracker.set(interpolation_tracker)\n\t    if not isinstance(disallow_interpolation, bool):\n\t        disallowed_interpolation_fields = set(disallow_interpolation)\n\t    if (\n\t        field.field_info.extra.get(\"interpolate\", True)\n\t        and field.alias not in disallowed_interpolation_fields\n\t    ):\n\t        old_value = post_hook_value\n", "        try:\n\t            interpolated = interpolate(\n\t                post_hook_value,\n\t                cls,\n\t                values.copy(),\n\t                field.outer_type_,\n\t            )\n\t        except InterpolationError as err:\n\t            err.message += f\" (encountered in {cls.__qualname__}.{field.alias})\"\n\t            raise\n", "        new_value = field_hook(field.outer_type_, interpolated)\n\t        if old_value != new_value:\n\t            interpolation_tracker[field.alias] = (old_value, copy.copy(new_value))\n\t        post_hook_value = new_value\n\t    return post_hook_value\n\tdef _json_encoder(model_encoder: Callable[..., Any], value: Any, **kwargs: Any) -> Any:\n\t    initial_state_type = type(value)\n\t    converted_value = export_hook(value)\n\t    if isinstance(converted_value, initial_state_type):\n\t        return model_encoder(value, **kwargs)\n", "    return converted_value\n\tclass ConfigModelMetaclass(ModelMetaclass):\n\t    def __new__(\n\t        cls,\n\t        name: str,\n\t        bases: tuple[type, ...],\n\t        namespace: dict[str, Any],\n\t        **kwargs: Any,\n\t    ) -> type:\n\t        namespace |= dict.fromkeys(\n", "            (EXPORT, CONTEXT, LOCAL, TOKEN, MODULE), pydantic.PrivateAttr()\n\t        ) | {INTERPOLATION_TRACKER: pydantic.PrivateAttr(default_factory=dict)}\n\t        if namespace.get(INTERPOLATION_INCLUSIONS) is None:\n\t            namespace[INTERPOLATION_INCLUSIONS] = {}\n\t        if namespace.get(INTERPOLATOR) is None:\n\t            namespace[INTERPOLATOR] = BaseInterpolator()\n\t        if namespace.get(EVALUATION_ENGINE) is None:\n\t            namespace[EVALUATION_ENGINE] = BaseEvaluationEngine()\n\t        if kwargs.pop(\"root\", None):\n\t            return type.__new__(cls, name, bases, namespace, **kwargs)\n", "        model = super().__new__(cls, name, bases, namespace, **kwargs)\n\t        for field in model.__fields__.values():\n\t            if field.pre_validators is None:\n\t                field.pre_validators = []\n\t            field.pre_validators[:] = [_common_field_validator, *field.pre_validators]\n\t            if type(field.outer_type_) is ConfigModelMetaclass:\n\t                validator = make_generic_validator(\n\t                    field.outer_type_.__field_setup__  # type: ignore[attr-defined]\n\t                )\n\t                field.pre_validators[:] = [\n", "                    _common_field_validator,\n\t                    validator,\n\t                    *field.pre_validators,\n\t                ]\n\t        model_encoder = model.__json_encoder__\n\t        model.__json_encoder__ = functools.partial(_json_encoder, model_encoder)\n\t        return cast(type, model)\n\tclass ConfigMeta(pydantic.BaseSettings.Config):\n\t    \"\"\"\n\t    Meta-configuration for configuration models.\n", "    See https://docs.pydantic.dev/latest/usage/model_config/ for more information\n\t    on model configurations.\n\t    Attributes\n\t    ----------\n\t    resource\n\t        The configuration resource to read from/write to.\n\t        If a string, it will be interpreted as a path to a file.\n\t    parser_name\n\t        The anyconfig parser to use.\n\t    autoupdate_forward_refs\n", "        Whether to automatically update forward references\n\t        when `ConfigModel.load()` or `ConfigModel.load_async()`\n\t        methods are called. For convenience, defaults to `True`.\n\t    And all other attributes from `pydantic.BaseSettings.Config`.\n\t    \"\"\"\n\t    resource: ConfigAgent[ConfigModel] | RawResourceT | None = None\n\t    parser_name: str | None = None\n\t    validate_assignment: bool = True\n\t    autoupdate_forward_refs: bool = True\n\t    Extra = pydantic.Extra\n", "class ConfigModel(\n\t    pydantic.BaseSettings,\n\t    metaclass=ConfigModelMetaclass,\n\t    root=True,\n\t):\n\t    \"\"\"The base class for configuration models.\"\"\"\n\t    __config__ = ConfigMeta\n\t    module_wrapper_class: ClassVar[type[ConfigModule[ConfigModel]]] = ConfigModule\n\t    def __init__(self, **kwargs: Any) -> None:\n\t        # Set private attributes via the constructor\n", "        # to allow preprocessor-related instances to exist.\n\t        for private_attr in self.__private_attributes__:\n\t            value = kwargs.pop(private_attr, Undefined)\n\t            if value is not Undefined:\n\t                if private_attr == CONTEXT:\n\t                    context = current_context.get()\n\t                    if context:\n\t                        value = context\n\t                    current_context.set(value)\n\t                object.__setattr__(self, private_attr, value)\n", "        super().__init__(**kwargs)\n\t    def __deepcopy__(\n\t        self: ConfigModelT, memodict: dict[Any, Any] | None = None\n\t    ) -> ConfigModelT:\n\t        state = dict(self._iter(to_dict=False))\n\t        state.pop(LOCAL, None)\n\t        state.pop(TOKEN, None)\n\t        clone = copy.deepcopy(state)\n\t        return type(self).parse_obj(\n\t            {\n", "                field.alias: clone[field_name]\n\t                for field_name, field in self.__fields__.items()\n\t            }\n\t        )\n\t    def __setattr__(self, key: str, value: Any) -> None:\n\t        getattr(self, LOCAL).run(super().__setattr__, key, value)\n\t    def _init_private_attributes(self) -> None:\n\t        super()._init_private_attributes()\n\t        local = contextvars.copy_context()\n\t        object.__setattr__(self, LOCAL, local)\n", "        tok = getattr(self, TOKEN, None)\n\t        if tok:\n\t            context = current_context.get()\n\t            if context is not None:\n\t                context.interpolation_namespace |= self.dict()\n\t            current_context.reset(tok)\n\t    def export(self, **kwargs: Any) -> dict[str, Any]:\n\t        \"\"\"\n\t        Export the configuration model.\n\t        Returns\n", "        -------\n\t        The exported configuration model.\n\t        \"\"\"\n\t        _exporting.set(True)  # noqa: FBT003\n\t        return detached_context_run(self.dict, **kwargs)\n\t    async def export_async(self, **kwargs: Any) -> dict[str, Any]:\n\t        \"\"\"\n\t        Export the configuration model.\n\t        Returns\n\t        -------\n", "        The exported configuration model.\n\t        \"\"\"\n\t        _exporting.set(True)  # noqa: FBT003\n\t        return await detached_context_await(self.dict_async, **kwargs)\n\t    async def dict_async(self, **kwargs: Any) -> dict[str, Any]:\n\t        \"\"\"\n\t        Get the dictionary representation of the configuration model.\n\t        Returns\n\t        -------\n\t        The dictionary representation of the configuration model.\n", "        \"\"\"\n\t        return dict(await self._iter_async(to_dict=True, **kwargs))\n\t    # noinspection PyShadowingNames\n\t    async def json_async(  # noqa: PLR0913\n\t        self,\n\t        include: IncludeExcludeT = None,\n\t        exclude: IncludeExcludeT = None,\n\t        *,\n\t        by_alias: bool = False,\n\t        exclude_unset: bool = False,\n", "        exclude_defaults: bool = False,\n\t        exclude_none: bool = False,\n\t        encoder: Callable[[Any], Any] | None = None,\n\t        models_as_dict: bool = True,\n\t        **dumps_kwargs: Any,\n\t    ) -> str:\n\t        encoder = cast(Callable[[Any], Any], encoder or self.__json_encoder__)\n\t        data = dict(\n\t            await self._iter_async(\n\t                to_dict=models_as_dict,\n", "                by_alias=by_alias,\n\t                include=include,\n\t                exclude=exclude,\n\t                exclude_unset=exclude_unset,\n\t                exclude_defaults=exclude_defaults,\n\t                exclude_none=exclude_none,\n\t            )\n\t        )\n\t        if self.__custom_root_type__:\n\t            data = data[ROOT_KEY]\n", "        return self.__config__.json_dumps(data, default=encoder, **dumps_kwargs)\n\t    def _iter(  # type: ignore[override]\n\t        self, **kwargs: Any\n\t    ) -> Iterator[tuple[str, Any]]:\n\t        if kwargs.get(\"to_dict\", False) and _exporting.get():\n\t            state: dict[str, Any] = {}\n\t            for key, value in super()._iter(**kwargs):\n\t                state |= [self._export_iter_hook(key, value)]\n\t            metadata = getattr(self, EXPORT, None)\n\t            if metadata:\n", "                context = get_context(self)\n\t                context.agent.processor_class.export(state, metadata=metadata)\n\t            yield from state.items()\n\t        else:\n\t            yield from super()._iter(**kwargs)\n\t    async def _iter_async(self, **kwargs: Any) -> Iterator[tuple[str, Any]]:\n\t        if kwargs.get(\"to_dict\", False) and _exporting.get():\n\t            state: dict[str, Any] = {}\n\t            for key, value in super()._iter(**kwargs):\n\t                state |= [self._export_iter_hook(key, value)]\n", "            metadata = getattr(self, EXPORT, None)\n\t            if metadata:\n\t                context = get_context(self)\n\t                await context.agent.processor_class.export_async(\n\t                    state, metadata=metadata\n\t                )\n\t            return ((key, value) for key, value in state.items())\n\t        return super()._iter(**kwargs)\n\t    def _export_iter_hook(\n\t        self,\n", "        key: str,\n\t        value: Any,\n\t    ) -> tuple[str, Any]:\n\t        interpolation_tracker = getattr(self, LOCAL).get(current_interpolation_tracker)\n\t        field = self.__fields__.get(key)\n\t        actual_key = field.alias if field else key\n\t        if interpolation_tracker:\n\t            interpolation_track = interpolation_tracker.get(actual_key)\n\t            if interpolation_track:\n\t                old_value, new_value = interpolation_track\n", "                # if value != new_value:\n\t                #     raise InterpolationError(\n\t                #         f\"Cannot restore the value of {actual_key!r} \"\n\t                #         \"before interpolation.\"\n\t                #     )\n\t                value = old_value\n\t        return actual_key, value\n\t    @classmethod\n\t    @no_type_check\n\t    def _get_value(cls, value: Any, *, to_dict: bool, **kwds: Any) -> Any:\n", "        if _exporting.get():\n\t            exporter = export_model.dispatch(type(value))\n\t            if (\n\t                isinstance(value, BaseModel)\n\t                or exporter != export_model.dispatch(object)\n\t            ) and to_dict:\n\t                value_dict = export_model(value, **kwds)\n\t                if ROOT_KEY in value_dict:\n\t                    return value_dict[ROOT_KEY]\n\t                return value_dict\n", "        return super()._get_value(value, to_dict=to_dict, **kwds)\n\t    @classmethod\n\t    def _resolve_agent(\n\t        cls,\n\t        resource: ConfigAgent[ConfigModelT] | RawResourceT | None = None,\n\t        *,\n\t        create_if_missing: bool | None = None,\n\t        parser_name: str | None = None,\n\t    ) -> ConfigAgent[ConfigModelT]:\n\t        if resource is None:\n", "            resource = getattr(cls.__config__, \"resource\", None)\n\t        if resource is None:\n\t            raise ValueError(\"No resource specified\")\n\t        if parser_name is None:\n\t            parser_name = getattr(cls.__config__, \"parser_name\", None)\n\t        agent: ConfigAgent[ConfigModelT]\n\t        if isinstance(resource, ConfigAgent):\n\t            agent = resource\n\t        else:\n\t            agent = ConfigAgent(\n", "                resource,\n\t                parser_name=parser_name,\n\t            )\n\t        if create_if_missing is not None:\n\t            agent.create_if_missing = create_if_missing\n\t        if parser_name is not None:\n\t            agent.parser_name = cast(str, parser_name)\n\t        return agent\n\t    @property\n\t    def initial_state(self) -> dict[str, Any]:\n", "        \"\"\"\n\t        The initial configuration state.\n\t        It is a copy of the configuration state\n\t        at the last time of loading, reloading or saving.\n\t        \"\"\"\n\t        return get_context(self).initial_state\n\t    def at(\n\t        self: ConfigModelT,\n\t        route: ConfigRouteLike | None = None,\n\t    ) -> ConfigModelT | ConfigAt[ConfigModelT]:\n", "        \"\"\"\n\t        Lazily point to a specific item in the configuration.\n\t        Parameters\n\t        ----------\n\t        route\n\t            The access route to the item in this configuration.\n\t            If None, the whole configuration is returned.\n\t        Returns\n\t        -------\n\t        The configuration accessor.\n", "        \"\"\"\n\t        if route is None:\n\t            context = get_context_or_none(self)\n\t            self_at = None\n\t            if context is not None:\n\t                self_at = context.at\n\t            if self_at is not None:\n\t                return self_at\n\t            return self\n\t        return ConfigAt(self, None, route)\n", "    @overload\n\t    def get(self: ConfigModelT, route: None = None, default: Any = ...) -> ConfigModelT:\n\t        ...\n\t    @overload\n\t    def get(self, route: ConfigRouteLike = ..., default: Any = ...) -> Any:\n\t        ...\n\t    def get(\n\t        self, route: ConfigRouteLike | None = None, default: Any = Undefined\n\t    ) -> Any:\n\t        \"\"\"\n", "        Get a value from the configuration.\n\t        Parameters\n\t        ----------\n\t        route\n\t            Route to access the item. If None, the whole configuration is returned.\n\t        default\n\t        \"\"\"\n\t        if route is None:\n\t            return self\n\t        return self.at(route).get(default=default)\n", "    def update(self, kwargs: dict[str, Any]) -> None:\n\t        \"\"\"\n\t        Update the configuration with new values, in-place.\n\t        Parameters\n\t        ----------\n\t        kwargs\n\t            The new values to update the configuration with.\n\t        Returns\n\t        -------\n\t        None\n", "        \"\"\"\n\t        # Crucial difference to self.__dict__.update():\n\t        # self.__dict__.update() would not trigger the validation\n\t        # of the new values.\n\t        for key, value in kwargs.items():\n\t            setattr(self, key, value)\n\t    def rollback(self) -> None:\n\t        \"\"\"\n\t        Rollback the configuration to its initial state.\n\t        Returns\n", "        -------\n\t        None\n\t        \"\"\"\n\t        context = get_context(self)\n\t        self.__dict__.update(context.initial_state)\n\t    @classmethod\n\t    def load(\n\t        cls: type[ConfigModelT],\n\t        resource: ConfigAgent[ConfigModelT] | RawResourceT | None = None,\n\t        *,\n", "        create_if_missing: bool | None = None,\n\t        parser_name: str | None = None,\n\t        **kwargs: Any,\n\t    ) -> ConfigModelT:\n\t        \"\"\"\n\t        Load the configuration file.\n\t        To reload the configuration, use the `reload()` method.\n\t        Parameters\n\t        ----------\n\t        resource\n", "            The configuration resource to read from/write to.\n\t        parser_name\n\t            The anyconfig parser to use.\n\t        create_if_missing\n\t            Whether to create the configuration file if it does not exist.\n\t        **kwargs\n\t            Keyword arguments to pass to the read method.\n\t        Returns\n\t        -------\n\t        self\n", "        \"\"\"\n\t        agent = cls._resolve_agent(\n\t            resource,\n\t            parser_name=parser_name,\n\t            create_if_missing=create_if_missing,\n\t        )\n\t        current_context.set(Context(agent))\n\t        local = contextvars.copy_context()\n\t        if getattr(\n\t            cls.__config__,\n", "            \"autoupdate_forward_refs\",\n\t            ConfigMeta.autoupdate_forward_refs,\n\t        ):\n\t            cls.update_forward_refs()\n\t        config = local.run(agent.read, config_class=cls, **kwargs)\n\t        object.__setattr__(config, LOCAL, local)\n\t        context = cast(Context[ConfigModelT], local.get(current_context))\n\t        context.owner = config\n\t        context.initial_state = config.__dict__\n\t        return config\n", "    @classmethod\n\t    async def load_async(\n\t        cls: type[ConfigModelT],\n\t        resource: ConfigAgent[ConfigModelT] | RawResourceT | None = None,\n\t        *,\n\t        parser_name: str | None = None,\n\t        create_if_missing: bool | None = None,\n\t        **kwargs: Any,\n\t    ) -> ConfigModelT:\n\t        \"\"\"\n", "        Load the configuration file asynchronously.\n\t        To reload the configuration, use the `reload_async()` method.\n\t        Parameters\n\t        ----------\n\t        resource\n\t            The configuration resource.\n\t        parser_name\n\t            The anyconfig parser to use.\n\t        create_if_missing\n\t            Whether to create the configuration file if it does not exist.\n", "        **kwargs\n\t            Keyword arguments to pass to the read method.\n\t        Returns\n\t        -------\n\t        self\n\t        \"\"\"\n\t        agent = cls._resolve_agent(\n\t            resource, create_if_missing=create_if_missing, parser_name=parser_name\n\t        )\n\t        current_context.set(Context(agent))\n", "        local = contextvars.copy_context()\n\t        if getattr(\n\t            cls.__config__,\n\t            \"autoupdate_forward_refs\",\n\t            ConfigMeta.autoupdate_forward_refs,\n\t        ):\n\t            cls.update_forward_refs()\n\t        reader = local.run(\n\t            asyncio.create_task, agent.read_async(config_class=cls, **kwargs)\n\t        )\n", "        config = await reader\n\t        object.__setattr__(config, LOCAL, local)\n\t        context = cast(Context[ConfigModelT], local.get(current_context))\n\t        context.owner = config\n\t        return config\n\t    def reload(self: ConfigModelT, **kwargs: Any) -> ConfigModelT:\n\t        \"\"\"\n\t        Reload the configuration file.\n\t        Parameters\n\t        ----------\n", "        **kwargs\n\t            Keyword arguments to pass to the read method.\n\t        Returns\n\t        -------\n\t        self\n\t        \"\"\"\n\t        try:\n\t            context = get_context(self)\n\t        except RuntimeError:\n\t            wrapped_module = getattr(self, MODULE, None)\n", "            if wrapped_module is None:\n\t                raise\n\t            importlib.reload(wrapped_module)\n\t            self.update(\n\t                {\n\t                    key: value\n\t                    for key, value in vars(wrapped_module).items()\n\t                    if key in {field.alias for field in self.__fields__.values()}\n\t                }\n\t            )\n", "            return self\n\t        current_context.set(get_context(context.owner))\n\t        if context.owner is self:\n\t            changed = context.agent.read(config_class=type(self), **kwargs)\n\t        else:\n\t            changed = _partial_reload(cast(ConfigModelT, context.at), **kwargs)\n\t        state = changed.__dict__\n\t        context.initial_state = state\n\t        self.update(state)\n\t        return self\n", "    async def reload_async(self: ConfigModelT, **kwargs: Any) -> ConfigModelT:\n\t        \"\"\"\n\t        Reload the configuration file asynchronously.\n\t        Parameters\n\t        ----------\n\t        **kwargs\n\t            Keyword arguments to pass to the read method.\n\t        Returns\n\t        -------\n\t        self\n", "        \"\"\"\n\t        context = get_context(self)\n\t        current_context.set(get_context(context.owner))\n\t        if context.owner is self:\n\t            changed = await context.agent.read_async(config_class=type(self), **kwargs)\n\t        else:\n\t            changed = await _partial_reload_async(\n\t                cast(ConfigAt[ConfigModelT], context.at), **kwargs\n\t            )\n\t        state = changed.__dict__\n", "        context.initial_state = state\n\t        self.update(state)\n\t        return self\n\t    def save(\n\t        self: ConfigModelT, write_kwargs: dict[str, Any] | None = None, **kwargs: Any\n\t    ) -> int:\n\t        \"\"\"\n\t        Save the configuration to the configuration file.\n\t        Parameters\n\t        ----------\n", "        write_kwargs\n\t            Keyword arguments to pass to the write method.\n\t        **kwargs\n\t            Keyword arguments to pass to the dumping method.\n\t        Returns\n\t        -------\n\t        The number of bytes written.\n\t        \"\"\"\n\t        context = get_context(self)\n\t        if context.owner is self:\n", "            if write_kwargs is None:\n\t                write_kwargs = {}\n\t            blob = context.agent.dump_config(self, **kwargs)\n\t            result = self.write(blob, **write_kwargs)\n\t            context.initial_state = self.__dict__\n\t            return result\n\t        return _partial_save(\n\t            cast(ConfigAt[ConfigModelT], context.at),\n\t            write_kwargs=write_kwargs,\n\t            **kwargs,\n", "        )\n\t    async def save_async(\n\t        self: ConfigModelT, write_kwargs: dict[str, Any] | None = None, **kwargs: Any\n\t    ) -> int:\n\t        \"\"\"\n\t        Save the configuration to the configuration file asynchronously.\n\t        Parameters\n\t        ----------\n\t        write_kwargs\n\t            Keyword arguments to pass to the write method.\n", "        **kwargs\n\t            Keyword arguments to pass to the dumping method.\n\t        Returns\n\t        -------\n\t        The number of bytes written.\n\t        \"\"\"\n\t        context = get_context(self)\n\t        if context.owner is self:\n\t            if write_kwargs is None:\n\t                write_kwargs = {}\n", "            _exporting.set(True)  # noqa: FBT003\n\t            blob = await context.agent.dump_config_async(self, **kwargs)\n\t            result = await self.write_async(blob, **write_kwargs)\n\t            context.initial_state = self.__dict__\n\t            return result\n\t        return await _partial_save_async(\n\t            cast(ConfigAt[ConfigModelT], context.at),\n\t            write_kwargs=write_kwargs,\n\t            **kwargs,\n\t        )\n", "    def write(self, blob: str | bytes, **kwargs: Any) -> int:\n\t        \"\"\"\n\t        Overwrite the configuration file with the given string or bytes.\n\t        Parameters\n\t        ----------\n\t        blob\n\t            The blob to write to the configuration file.\n\t        **kwargs\n\t            Keyword arguments to pass to the open method.\n\t        Returns\n", "        -------\n\t        The number of bytes written.\n\t        \"\"\"\n\t        context = get_context(self)\n\t        if context.agent.is_url:\n\t            msg = \"Writing to URLs is not yet supported\"\n\t            raise NotImplementedError(msg)\n\t        return context.agent.write(blob, **kwargs)\n\t    async def write_async(self, blob: str | bytes, **kwargs: Any) -> int:\n\t        \"\"\"\n", "        Overwrite the configuration file asynchronously with the given string or bytes.\n\t        Parameters\n\t        ----------\n\t        blob\n\t            The blob to write to the configuration file.\n\t        **kwargs\n\t            Keyword arguments to pass to the open method.\n\t        Returns\n\t        -------\n\t        The number of bytes written.\n", "        \"\"\"\n\t        context = get_context(self)\n\t        if context.agent.is_url:\n\t            msg = \"Saving to URLs is not yet supported\"\n\t            raise NotImplementedError(msg)\n\t        return await context.agent.write_async(blob, **kwargs)\n\t    @classmethod\n\t    def _evaluate_interpolation_namespaces(cls) -> dict[str | None, dict[str, Any]]:\n\t        inclusions = getattr(cls, INTERPOLATION_INCLUSIONS)\n\t        return {\n", "            namespace_id: evaluate_namespace()\n\t            for namespace_id, evaluate_namespace in inclusions.items()\n\t        }\n\t    @classmethod\n\t    def _evaluate_interpolation_expression(\n\t        cls,\n\t        expression: str,\n\t        *,\n\t        result_namespace: dict[str, Any],\n\t        namespaces: dict[str | None, dict[str, Any]],\n", "        closest_namespace: dict[str, Any],\n\t        target_type: type[Any],\n\t    ) -> Any:\n\t        evaluation_engine: BaseEvaluationEngine = getattr(cls, EVALUATION_ENGINE)\n\t        return evaluation_engine.evaluate_expression(\n\t            expression=expression,\n\t            result_namespace=result_namespace,\n\t            namespaces=namespaces,\n\t            closest_namespace=closest_namespace,\n\t            target_type=target_type,\n", "        )\n\t    @classmethod\n\t    def wrap_module(\n\t        cls: type[ConfigModelT],\n\t        module_name: str | types.ModuleType,\n\t        package: str | None = None,\n\t        /,\n\t        **values: Any,\n\t    ) -> ConfigModelT:\n\t        module_vars = None\n", "        if isinstance(module_name, str):\n\t            module_name = module_name\n\t            if module_name not in sys.modules:\n\t                if package is None and module_name.startswith(\".\"):\n\t                    current_frame = inspect.currentframe()\n\t                    assert current_frame is not None\n\t                    frame_back = current_frame.f_back\n\t                    assert frame_back is not None\n\t                    package = frame_back.f_globals[\"__package__\"]\n\t                module_vars = vars(\n", "                    importlib.import_module(module_name, package=package)\n\t                )\n\t        else:\n\t            module_name = module_name.__name__\n\t        config_module = cls.module_wrapper_class.wrap_module(\n\t            module_name, cls, module_vars, **values\n\t        )\n\t        return cast(ConfigModelT, config_module.get_model())\n\t    @classmethod\n\t    def wrap_this_module(\n", "        cls: type[ConfigModelT],\n\t        **values: Any,\n\t    ) -> ConfigModelT:\n\t        current_frame = inspect.currentframe()\n\t        assert current_frame is not None\n\t        frame_back = current_frame.f_back\n\t        assert frame_back is not None\n\t        return cls.wrap_module(frame_back.f_globals[\"__name__\"], **values)\n\t    @classmethod\n\t    def get_interpolation_namespace(\n", "        cls,\n\t        expressions: set[str],\n\t        closest_namespace: dict[str, Any],\n\t        target_type: type[Any],\n\t    ) -> dict[str, Any]:\n\t        \"\"\"Get the interpolation namespace according to occuring expressions.\"\"\"\n\t        context = current_context.get()\n\t        result_namespace: dict[str, Any] = {}\n\t        namespaces = cls._evaluate_interpolation_namespaces()\n\t        if context is not None:\n", "            namespaces.setdefault(None, {}).update(\n\t                context.toplevel_interpolation_namespace\n\t            )\n\t        for expression in expressions:\n\t            value = cls._evaluate_interpolation_expression(\n\t                expression=expression,\n\t                result_namespace=result_namespace,\n\t                namespaces=namespaces,\n\t                closest_namespace=closest_namespace,\n\t                target_type=target_type,\n", "            )\n\t            result_namespace[expression] = value\n\t        return result_namespace\n\t    @classmethod\n\t    def __field_setup__(cls, value: dict[str, Any], field: ModelField) -> Any:\n\t        \"\"\"\n\t        Called when this configuration model is being initialized as a field\n\t        of some other configuration model.\n\t        \"\"\"\n\t        context = current_context.get()\n", "        if context is not None:\n\t            subcontext = context.enter(field.name)\n\t            tok = current_context.set(subcontext)\n\t            return _get_object_state(value) | {\n\t                TOKEN: tok,\n\t                LOCAL: contextvars.copy_context(),\n\t            }\n\t        return value\n\t    if not TYPE_CHECKING:\n\t        load = detached_context_function(load)\n", "        load_async = detached_context_function(load_async)\n\t        reload = detached_context_function(reload)\n\t        reload_async = detached_context_function(reload_async)\n\t        save = detached_context_function(save)\n\t        save_async = detached_context_function(save_async)\n\t        export = detached_context_function(export)\n\t        export_async = detached_context_function(export_async)\n\tsetattr(ConfigModel, INTERPOLATION_INCLUSIONS, None)\n\tinclude.register(ConfigModel, include_const)\n\tif os.getenv(\"CONFIGZEN_SETUP\") != \"0\":\n", "    importlib.import_module(\"._setup\", package=__package__)\n"]}
{"filename": "configzen/typedefs.py", "chunked_list": ["import contextlib\n\timport os\n\timport pathlib\n\timport sys\n\tfrom collections.abc import Mapping, Set\n\tfrom typing import TYPE_CHECKING, Any, Optional, TextIO, TypeVar, Union\n\tif sys.version_info >= (3, 10):\n\t    from typing import ParamSpec, TypeAlias\n\telse:\n\t    from typing_extensions import ParamSpec, TypeAlias\n", "if TYPE_CHECKING:\n\t    from aiofiles.base import AiofilesContextManager\n\t    from aiofiles.threadpool.text import AsyncTextIOWrapper\n\t    # noinspection PyUnresolvedReferences\n\t    from configzen.model import ConfigModel\n\t    from configzen.route import ConfigRoute\n\tT = TypeVar(\"T\")\n\tP = ParamSpec(\"P\")\n\tConfigModelT = TypeVar(\"ConfigModelT\", bound=\"ConfigModel\")\n\tConfigRouteLike: TypeAlias = Union[str, list[str], \"ConfigRoute\"]\n", "ConfigIO: TypeAlias = contextlib.AbstractContextManager[TextIO]\n\tAsyncConfigIO: TypeAlias = \"AiofilesContextManager[None, None, AsyncTextIOWrapper]\"\n\tRawResourceT: TypeAlias = Union[ConfigIO, str, int, os.PathLike, pathlib.Path]\n\tNormalizedResourceT: TypeAlias = Union[ConfigIO, str, int, pathlib.Path]\n\tIncludeExcludeT: TypeAlias = Optional[\n\t    Union[\n\t        Set[Union[int, str]],\n\t        Mapping[Union[int, str], Any],\n\t    ]\n\t]\n"]}
{"filename": "configzen/__main__.py", "chunked_list": ["import argparse\n\tfrom configzen import ConfigMeta, ConfigModel\n\tfrom configzen.model import get_context\n\tclass Store(ConfigModel):\n\t    class Config(ConfigMeta):\n\t        extra = ConfigMeta.Extra.allow\n\tif __name__ == \"__main__\":\n\t    p = argparse.ArgumentParser()\n\t    p.add_argument(\"--source\", help=\"file to load from\")\n\t    p.add_argument(\"dest\", help=\"file to save into\")\n", "    p.add_argument(\"--async\", dest=\"use_async\", action=\"store_true\", help=\"use async\")\n\t    opt = p.parse_args()\n\t    if opt.use_async:\n\t        import asyncio\n\t        store = asyncio.run(Store.load_async(opt.source))\n\t        print(store)\n\t        context = get_context(store)\n\t        context.agent.resource = opt.dest\n\t        asyncio.run(store.save_async())\n\t    else:\n", "        store = Store.load(opt.source)\n\t        print(store)\n\t        context = get_context(store)\n\t        context.agent.resource = opt.dest\n\t        store.save()\n"]}
{"filename": "configzen/errors.py", "chunked_list": ["\"\"\"This module contains all the custom errors raised by _configzen_.\"\"\"\n\tfrom __future__ import annotations\n\timport contextlib\n\tfrom collections.abc import Iterator\n\tfrom typing import TYPE_CHECKING, Any\n\tif TYPE_CHECKING:\n\t    from configzen.model import ConfigAgent\n\t    from configzen.typedefs import ConfigModelT\n\tclass ConfigError(Exception):\n\t    \"\"\"An error occurred while loading a configuration.\"\"\"\n", "    def __init__(self, message: str) -> None:\n\t        self._message = message\n\t        super().__init__(message)\n\t    @property\n\t    def message(self) -> str:\n\t        \"\"\"The error message.\"\"\"\n\t        return self._message\n\t    @message.setter\n\t    def message(self, value: str) -> None:\n\t        self._message = value\n", "        super().__init__(self.message)\n\tclass InterpolationError(ConfigError):\n\t    \"\"\"An error occurred with regard to interpolating a configuration.\"\"\"\n\tclass InterpolationLookupError(ConfigError, LookupError):\n\t    \"\"\"An error occurred with regard to interpolating a configuration.\"\"\"\n\t    def __init__(self, message: str) -> None:\n\t        super().__init__(repr(message))\n\tclass IncorrectConfigError(ConfigError):\n\t    \"\"\"An error occurred while loading a configuration.\"\"\"\n\tclass InternalSyntaxError(ConfigError):\n", "    \"\"\"Syntax error in a _configzen_ component.\"\"\"\n\t    def __init__(\n\t        self,\n\t        message: str,\n\t        index: Any = None,\n\t        prefix: str = \"\",\n\t        suffix: str = \"\",\n\t    ) -> None:\n\t        super().__init__(message)\n\t        self.index = index\n", "        self.prefix = prefix\n\t        self.suffix = suffix\n\tclass ConfigSyntaxError(ConfigError):\n\t    \"\"\"An error occurred while parsing arguments.\"\"\"\n\t@contextlib.contextmanager\n\tdef formatted_syntax_error(\n\t    source: str, error_cls: type[ConfigSyntaxError] = ConfigSyntaxError\n\t) -> Iterator[None]:\n\t    \"\"\"Raise a SyntaxError with a message and a source.\"\"\"\n\t    try:\n", "        yield\n\t    except InternalSyntaxError as exc:\n\t        idx = len(exc.prefix) + exc.index + 1\n\t        charlist = [\" \"] * len(exc.prefix + repr(source) + exc.suffix)\n\t        charlist[idx] = \"^\"\n\t        indicator = \"\".join(charlist)\n\t        msg = \"\\n\".join(\n\t            map(str, (exc, exc.prefix + repr(source) + exc.suffix, indicator))\n\t        )\n\t        raise error_cls(msg) from None\n", "class UnspecifiedParserError(ConfigError):\n\t    \"\"\"Could not determine the parser to use.\"\"\"\n\tclass UnavailableParserError(ConfigError):\n\t    MISSING_DEPENDENCIES: dict[str, str] = {\n\t        \"yaml\": \"pyyaml (or ruamel.yaml)\",\n\t        \"toml\": \"toml\",\n\t        \"ion\": \"anyconfig-ion-backend\",\n\t        \"bson\": \"anyconfig-bson-backend\",\n\t        \"msgpack\": \"anyconfig-msgpack-backend\",\n\t        \"cbor\": \"anyconfig-cbor2-backend (or anyconfig-cbor-backend)\",\n", "        \"configobj\": \"anyconfig-configobj-backend\",\n\t    }\n\t    def __init__(self, parser_name: str, agent: ConfigAgent[ConfigModelT]) -> None:\n\t        missing_dependency: str = self.MISSING_DEPENDENCIES.get(\n\t            parser_name, f\"<the proper anyconfig backend for {parser_name!r} files>\"\n\t        )\n\t        super().__init__(\n\t            f\"The {parser_name!r} parser required to load configuration \"\n\t            f\"for agent {agent} is not available.\\n\"\n\t            f\"Install it with `pip install {missing_dependency}`.\"\n", "        )\n\tclass ConfigAccessError(ConfigError, LookupError):\n\t    \"\"\"An error occurred while accessing configuration part.\"\"\"\n\t    def __init__(self, config: ConfigModelT, route: str | list[str]) -> None:\n\t        if not isinstance(route, str):\n\t            route = \".\".join(route)\n\t        self.route = route\n\t        super().__init__(\n\t            f\"Could not access {type(config).__name__}.{route}\",\n\t        )\n", "class ConfigProcessorError(ConfigError):\n\t    \"\"\"An error occurred while preprocessing/exporting a configuration.\"\"\"\n\tclass ResourceLookupError(ConfigError, LookupError):\n\t    \"\"\"An error occurred while looking up a resource.\"\"\"\n\t    def __init__(\n\t        self, resource: ConfigAgent[ConfigModelT] | None, route: list[str]\n\t    ) -> None:\n\t        resource_name = resource.resource if resource else \"the provided resource\"\n\t        self.route = route\n\t        super().__init__(f\"{route} not found in {resource_name}\")\n", "class ConfigPreprocessingError(ConfigProcessorError, ValueError):\n\t    \"\"\"An error occurred while preprocessing a configuration value.\"\"\"\n"]}
{"filename": "configzen/field.py", "chunked_list": ["from typing import Any\n\tfrom pydantic.fields import Field, Undefined\n\t__all__ = (\"ConfigField\",)\n\t# noinspection PyPep8Naming\n\tdef ConfigField(default: Any = Undefined, **kwargs: Any) -> Any:  # noqa: N802\n\t    # Since configzen involves BaseSettings implicitly,\n\t    # this would be very convenient to have.\n\t    alias = kwargs.get(\"alias\")\n\t    env = kwargs.get(\"env\")\n\t    if alias is not None and env is None:\n", "        kwargs[\"env\"] = alias\n\t    return Field(default, **kwargs)\n"]}
{"filename": "configzen/_setup.py", "chunked_list": ["\"\"\"\n\tConvenience hooks for quicker workflow with _configzen_.\n\tFor advanced use cases, you can prevent this module from executing\n\tby setting the environment variable ``CONFIGZEN_SETUP`` to ``0``.\n\t\"\"\"\n\tfrom __future__ import annotations\n\timport ast\n\timport ipaddress\n\timport pathlib\n\tfrom collections.abc import Mapping\n", "from typing import TYPE_CHECKING, Any\n\tfrom pydantic.json import ENCODERS_BY_TYPE\n\tfrom configzen.model import ConfigModel, export_hook, field_hook\n\tif TYPE_CHECKING:\n\t    from configzen.typedefs import ConfigModelT\n\tfor obj_type, obj_encoder in ENCODERS_BY_TYPE.items():\n\t    export_hook.register(obj_type, obj_encoder)\n\t@export_hook.register(pathlib.WindowsPath)\n\t@export_hook.register(pathlib.PureWindowsPath)\n\tdef _export_windows_path(obj: pathlib.WindowsPath | pathlib.PureWindowsPath) -> str:\n", "    \"\"\"\n\t    This hook makes non-absolute paths in configurations cross-platform.\n\t    Parameters\n\t    ----------\n\t    obj\n\t        The path to convert.\n\t    Returns\n\t    -------\n\t    The converted path.\n\t    \"\"\"\n", "    return obj.as_posix()\n\t@export_hook.register(list)\n\tdef _export_list(obj: list[Any]) -> list[Any]:\n\t    return [export_hook(item) for item in obj]\n\t@export_hook.register(Mapping)\n\tdef _export_mapping(obj: Mapping[Any, Any]) -> dict[Any, Any]:\n\t    return {k: export_hook(v) for k, v in obj.items()}\n\t@field_hook.register(dict)\n\t@field_hook.register(list)\n\t@field_hook.register(set)\n", "@field_hook.register(tuple)\n\tdef _eval_literals(cls: type[Any], value: Any) -> Any:\n\t    \"\"\"\n\t    Load a value using literal evaluation.\n\t    Solves nested dictionaries problem in INI files.\n\t    Parameters\n\t    ----------\n\t    cls\n\t        The type to load the value into.\n\t    value\n", "        The value to load.\n\t    Returns\n\t    -------\n\t    The loaded value.\n\t    \"\"\"\n\t    if isinstance(value, str):\n\t        try:\n\t            data = ast.literal_eval(value)\n\t        except (SyntaxError, ValueError):\n\t            # There might be some following validator, let it be like that\n", "            return value\n\t        else:\n\t            return cls(data)\n\t    return value\n\t@field_hook.register(ipaddress.IPv4Address)\n\t@field_hook.register(ipaddress.IPv6Address)\n\tdef _eval_ipaddress(\n\t    cls: type[ipaddress.IPv4Address | ipaddress.IPv6Address], value: Any\n\t) -> ipaddress.IPv4Address | ipaddress.IPv6Address | Any:\n\t    if isinstance(value, str) and value.casefold() == \"localhost\":\n", "        if issubclass(cls, ipaddress.IPv6Address):\n\t            return cls(\"::1\")\n\t        return cls(\"127.0.0.1\")\n\t    return value\n\t@field_hook.register(ConfigModel)\n\tdef _eval_model(cls: type[ConfigModelT], value: Any) -> ConfigModelT | Any:\n\t    \"\"\"\n\t    Load a model using dict literal evaluation.\n\t    Solves nested dictionaries problem in INI files.\n\t    Parameters\n", "    ----------\n\t    cls\n\t        The type to load the value into.\n\t    value\n\t        The value to load.\n\t    Returns\n\t    -------\n\t    The loaded value.\n\t    \"\"\"\n\t    data = value\n", "    if isinstance(value, str):\n\t        try:\n\t            data = ast.literal_eval(value)\n\t        except (SyntaxError, ValueError):\n\t            # Note: Strings resembling models is probably not intended\n\t            # to be used with automatic pickle/JSON parsing.\n\t            # return cls.parse_raw(value)\n\t            return data\n\t        else:\n\t            return cls.parse_obj(data)\n", "    return data\n"]}
{"filename": "configzen/processor.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport copy\n\timport dataclasses\n\timport enum\n\timport pathlib\n\tfrom collections.abc import Callable\n\tfrom typing import TYPE_CHECKING, Any, ClassVar, Generic, TypedDict, TypeVar, cast\n\tfrom anyconfig.utils import is_dict_like, is_list_like\n\tfrom pydantic.fields import Undefined\n", "from configzen.errors import ConfigPreprocessingError\n\tfrom configzen.typedefs import ConfigModelT, ConfigRouteLike\n\tif TYPE_CHECKING:\n\t    from configzen.model import BaseContext, ConfigAgent\n\t__all__ = (\n\t    \"DirectiveContext\",\n\t    \"directive\",\n\t    \"Processor\",\n\t)\n\tDirectiveT = TypeVar(\"DirectiveT\")\n", "EXPORT: str = \"__configzen_export__\"\n\tEXECUTES_DIRECTIVES: str = \"__configzen_executes_directives__\"\n\tEXECUTES_DIRECTIVES_ASYNC: str = \"__configzen_executes_directives_async__\"\n\tdef directive(\n\t    name: str | enum.Enum,\n\t    *,\n\t    asynchronous: bool | None = None,\n\t) -> Callable[..., Any]:\n\t    \"\"\"\n\t    Decorator for creating processor directives.\n", "    Parameters\n\t    ----------\n\t    name\n\t        The name of the directive.\n\t    asynchronous\n\t        Whether the decorated directive function is asynchronous.\n\t    Returns\n\t    -------\n\t    The decorated function.\n\t    \"\"\"\n", "    if isinstance(name, enum.Enum):\n\t        name = name.value.casefold()\n\t    def decorator(func: Any) -> Any:\n\t        nonlocal asynchronous\n\t        if asynchronous is None:\n\t            asynchronous = asyncio.iscoroutinefunction(func)\n\t        attr = EXECUTES_DIRECTIVES_ASYNC if asynchronous else EXECUTES_DIRECTIVES\n\t        if not hasattr(func, attr):\n\t            setattr(func, attr, set())\n\t        getattr(func, attr).add(name)\n", "        return func\n\t    return decorator\n\t@dataclasses.dataclass\n\tclass DirectiveContext:\n\t    \"\"\"\n\t    Context for processor directives.\n\t    Attributes\n\t    ----------\n\t    directive\n\t        The directive.\n", "    key\n\t        The key of the directive.\n\t    prefix\n\t        The prefix of the directive.\n\t    snippet\n\t        The config snippet where this directive was invoked.\n\t    container\n\t        The dictionary that contains the :attr:`dict`.\n\t    \"\"\"\n\t    directive: str\n", "    key: str\n\t    prefix: str\n\t    snippet: dict[str, Any]\n\t    container: dict[str, Any]\n\tdef parse_directive_call(\n\t    prefix: str,\n\t    directive_name: str,\n\t) -> str:\n\t    if directive_name.startswith(prefix):\n\t        directive_name = directive_name[len(prefix) :].casefold()\n", "        if not directive_name.isidentifier():\n\t            msg = f\"Invalid directive name: {directive_name}\"\n\t            raise ConfigPreprocessingError(msg)\n\t    return directive_name\n\tif TYPE_CHECKING:\n\t    class ExportMetadata(TypedDict, Generic[ConfigModelT]):\n\t        route: str | None\n\t        context: BaseContext[ConfigModelT]\n\t        key_order: list[str]\n\t        preprocess: bool\n", "else:\n\t    class ExportMetadata(TypedDict):\n\t        \"\"\"\n\t        Metadata for exporting.\n\t        Attributes\n\t        ----------\n\t        route\n\t            The route to import from.\n\t        context\n\t            The context attached to the import.\n", "        \"\"\"\n\t        route: str | None\n\t        context: BaseContext[ConfigModelT]\n\t        key_order: list[str]\n\t        preprocess: bool\n\tclass BaseProcessor(Generic[ConfigModelT]):\n\t    \"\"\"\n\t    Processor that executes directives.\n\t    Attributes\n\t    ----------\n", "    dict_config\n\t        The dictionary config to parse and update.\n\t    directive_prefix\n\t        The prefix for directives.\n\t    \"\"\"\n\t    _directive_handlers: dict[str, Any] = None  # type: ignore[assignment]\n\t    _async_directive_handlers: dict[str, Any] = None  # type: ignore[assignment]\n\t    directive_prefix: ClassVar[str]\n\t    extension_prefix: ClassVar[str]\n\t    def __init__(\n", "        self,\n\t        agent: ConfigAgent[ConfigModelT],\n\t        dict_config: dict[str, Any],\n\t    ) -> None:\n\t        self.agent = agent\n\t        self.dict_config = dict_config\n\t    @classmethod\n\t    def export(\n\t        cls,\n\t        state: Any,\n", "        *,\n\t        metadata: ExportMetadata[ConfigModelT] | None = None,\n\t    ) -> None:\n\t        \"\"\"\n\t        Export the state.\n\t        Parameters\n\t        ----------\n\t        state\n\t            The state to export.\n\t        metadata\n", "            The metadata of the substitution.\n\t        \"\"\"\n\t        if is_dict_like(state):\n\t            if metadata is None:\n\t                from configzen.model import CONTEXT\n\t                state.pop(CONTEXT, None)\n\t                metadata = state.pop(EXPORT, None)\n\t            if metadata:\n\t                cls._export(state, metadata)\n\t            else:\n", "                cls.export(list(state.values()))\n\t        elif is_list_like(state):\n\t            for item in state:\n\t                cls.export(item)\n\t    @classmethod\n\t    async def export_async(\n\t        cls,\n\t        state: Any,\n\t        *,\n\t        metadata: ExportMetadata[ConfigModelT] | None = None,\n", "    ) -> None:\n\t        \"\"\"\n\t        Export the state asynchronously.\n\t        Parameters\n\t        ----------\n\t        state\n\t            The state to export.\n\t        metadata\n\t            The metadata of the substitution.\n\t        \"\"\"\n", "        if is_dict_like(state):\n\t            if metadata is None:\n\t                from configzen.model import CONTEXT\n\t                state.pop(CONTEXT, None)\n\t                metadata = state.pop(EXPORT, None)\n\t            if metadata:\n\t                await cls._export_async(state, metadata)\n\t            else:\n\t                await cls.export_async(list(state.values()))\n\t        elif is_list_like(state):\n", "            for item in state:\n\t                await cls.export_async(item)\n\t    @classmethod\n\t    def _export(\n\t        cls,\n\t        state: Any,\n\t        metadata: ExportMetadata[ConfigModelT],\n\t    ) -> None:\n\t        raise NotImplementedError\n\t    @classmethod\n", "    async def _export_async(\n\t        cls,\n\t        state: Any,\n\t        metadata: ExportMetadata[ConfigModelT],\n\t    ) -> None:\n\t        raise NotImplementedError\n\t    async def preprocess_async(self) -> dict[str, Any]:\n\t        \"\"\"\n\t        Parse the dictionary config and return the parsed config,\n\t        ready for instantiating the model.\n", "        Returns\n\t        -------\n\t        The parsed config.\n\t        \"\"\"\n\t        return cast(dict[str, Any], await self._preprocess_async(self.dict_config))\n\t    def preprocess(self) -> dict[str, Any]:\n\t        \"\"\"\n\t        Parse the dictionary config and return the parsed config,\n\t        ready for instantiating the model.\n\t        Returns\n", "        -------\n\t        The parsed config.\n\t        \"\"\"\n\t        return cast(dict[str, Any], self._preprocess(self.dict_config))\n\t    def _preprocess(self, container: Any) -> Any:\n\t        if not is_dict_like(container):\n\t            if is_list_like(container):\n\t                return [self._preprocess(v) for v in container]\n\t            return container\n\t        result: dict[str, Any] = {}\n", "        for key, value in sorted(\n\t            cast(dict[str, Any], container).items(),\n\t            key=lambda item: item[0] == self.directive_prefix,\n\t        ):\n\t            if key.startswith(self.extension_prefix):\n\t                actual_key = key.lstrip(self.extension_prefix)\n\t                overridden = result.get(actual_key, {})\n\t                if not is_dict_like(overridden):\n\t                    raise ConfigPreprocessingError(\n\t                        f\"{self.extension_prefix} can be used only for overriding \"\n", "                        f\"dictionary sections but item at {actual_key!r} \"\n\t                        f\"is not a dictionary\"\n\t                    )\n\t                replacement = overridden | value\n\t                result[actual_key] = self._preprocess(replacement)\n\t            elif key.startswith(self.directive_prefix):\n\t                directive_name = parse_directive_call(self.directive_prefix, key)\n\t                context_container = container.copy()\n\t                del context_container[key]\n\t                context = DirectiveContext(\n", "                    directive=directive_name,\n\t                    key=key,\n\t                    prefix=self.directive_prefix,\n\t                    snippet=value,\n\t                    container=context_container,\n\t                )\n\t                self._call_directive(context)\n\t                new_container = self._preprocess(context.container)\n\t                result |= new_container\n\t            else:\n", "                result[key] = self._preprocess(value)\n\t        return result\n\t    async def _preprocess_async(self, container: Any) -> Any:\n\t        if not is_dict_like(container):\n\t            if is_list_like(container):\n\t                return [await self._preprocess_async(v) for v in container]\n\t            return container\n\t        result: dict[str, Any] = {}\n\t        for key, value in sorted(\n\t            cast(dict[str, Any], container).items(),\n", "            key=lambda item: item[0] == self.directive_prefix,\n\t        ):\n\t            if key.startswith(self.extension_prefix):\n\t                actual_key = key.lstrip(self.extension_prefix)\n\t                overridden = result.get(actual_key, {})\n\t                if not is_dict_like(overridden):\n\t                    raise ConfigPreprocessingError(\n\t                        f\"{self.extension_prefix} can be used only for overriding \"\n\t                        f\"dictionary sections but item at {actual_key!r} \"\n\t                        f\"is not a dictionary\"\n", "                    )\n\t                replacement = overridden | value\n\t                result[actual_key] = await self._preprocess_async(replacement)\n\t            elif key.startswith(self.directive_prefix):\n\t                directive_name = parse_directive_call(self.directive_prefix, key)\n\t                context_container = container.copy()\n\t                del context_container[key]\n\t                context = DirectiveContext(\n\t                    directive=directive_name,\n\t                    key=key,\n", "                    prefix=self.directive_prefix,\n\t                    snippet=value,\n\t                    container=context_container,\n\t                )\n\t                await self._call_directive_async(context)\n\t                new_container = await self._preprocess_async(context.container)\n\t                result |= new_container\n\t            else:\n\t                result[key] = await self._preprocess_async(value)\n\t        return result\n", "    def _call_directive(self, context: DirectiveContext) -> None:\n\t        handler = self._directive_handlers.get(context.directive)\n\t        if handler is None:\n\t            raise ConfigPreprocessingError(\n\t                f\"unknown preprocessing directive: {context.directive!r}\"\n\t            )\n\t        handler(self, context)\n\t    async def _call_directive_async(self, context: DirectiveContext) -> None:\n\t        handler = self._async_directive_handlers.get(context.directive)\n\t        if handler is None:\n", "            raise ConfigPreprocessingError(\n\t                f\"unknown preprocessing directive: {context.directive!r}\"\n\t            )\n\t        await handler(self, context)\n\t    def __init_subclass__(cls, **kwargs: Any) -> None:\n\t        super().__init_subclass__(**kwargs)\n\t        if cls._directive_handlers is None:\n\t            cls._directive_handlers = {}\n\t        else:\n\t            cls._directive_handlers = cls._directive_handlers.copy()\n", "        if cls._async_directive_handlers is None:\n\t            cls._async_directive_handlers = {}\n\t        else:\n\t            cls._async_directive_handlers = cls._async_directive_handlers.copy()\n\t        for _name, func in cls.__dict__.items():\n\t            if hasattr(func, EXECUTES_DIRECTIVES):\n\t                for directive_name in getattr(func, EXECUTES_DIRECTIVES):\n\t                    cls._directive_handlers[directive_name] = func\n\t            elif hasattr(func, EXECUTES_DIRECTIVES_ASYNC):\n\t                for directive_name in getattr(func, EXECUTES_DIRECTIVES_ASYNC):\n", "                    cls._async_directive_handlers[directive_name] = func\n\t    @classmethod\n\t    def register_directive(cls, name: str, func: Any) -> None:\n\t        if cls._directive_handlers is None:\n\t            cls._directive_handlers = {}\n\t        cls._directive_handlers[name] = func\n\t    @classmethod\n\t    def directive(cls, directive_name: str) -> str:\n\t        \"\"\"\n\t        Create a directive call.\n", "        Parameters\n\t        ----------\n\t        directive_name\n\t            The name of the directive.\n\t        Returns\n\t        -------\n\t        The directive call.\n\t        \"\"\"\n\t        if isinstance(directive_name, enum.Enum):\n\t            directive_name = directive_name.value\n", "        return cls.directive_prefix + directive_name\n\tclass Directives(str, enum.Enum):\n\t    EXTEND = \"extend\"\n\t    INCLUDE = \"include\"\n\t    COPY = \"copy\"\n\tclass Processor(BaseProcessor[ConfigModelT]):\n\t    directive_prefix = \"^\"\n\t    extension_prefix = \"+\"\n\t    route_separator: ClassVar[str] = \":\"\n\t    @directive(Directives.EXTEND)\n", "    def extend(self, ctx: DirectiveContext) -> None:\n\t        \"\"\"\n\t        Extend a configuration with another configuration.\n\t        Recursively preprocess the referenced configuration.\n\t        Preserve information about the referenced configuration.\n\t        Visual example\n\t        --------------\n\t        With `base.yaml` containing:\n\t        ```yaml\n\t        section:\n", "          foo: 1\n\t          bar: 2\n\t        ```\n\t        and `config.yaml` containing:\n\t        ```yaml\n\t        ^extend: base.yaml\n\t        +section:\n\t          foo: 3\n\t        ```\n\t        -> `load()` -> `save()` ->\n", "        ```yaml\n\t        ^extend: base.yaml\n\t        +section:\n\t          foo: 3\n\t        ```\n\t        \"\"\"\n\t        self._substitute(ctx, preprocess=True, preserve=True)\n\t    @directive(Directives.INCLUDE)\n\t    def include(self, ctx: DirectiveContext) -> None:\n\t        \"\"\"\n", "        Include a configuration in another configuration.\n\t        Recursively preprocess the referenced configuration.\n\t        Do not preserve information about the referenced configuration.\n\t        Visual example\n\t        --------------\n\t        With `biz.yaml` containing:\n\t        ```yaml\n\t        section:\n\t          biz: 3\n\t        ```\n", "        and `base.yaml` containing:\n\t        ```yaml\n\t        ^extend: biz.yaml\n\t        +section:\n\t          foo: 1\n\t          bar: 2\n\t        ```\n\t        and `config.yaml` containing:\n\t        ```yaml\n\t        ^include: base.yaml\n", "        +section:\n\t          foo: 3\n\t        ```\n\t        -> `load()` -> `save()` ->\n\t        ```yaml\n\t        ^extend: biz.yaml\n\t        +section:\n\t          bar: 2\n\t          foo: 3\n\t        ```\n", "        \"\"\"\n\t        self._substitute(ctx, preprocess=True, preserve=False)\n\t    @directive(Directives.COPY)\n\t    def copy(self, ctx: DirectiveContext) -> None:\n\t        \"\"\"\n\t        Copy a configuration and paste into another configuration.\n\t        This is just a literal copy-paste.\n\t        Do not preprocess the referenced configuration.\n\t        Do not preserve information about the referenced configuration.\n\t        Visual example\n", "        --------------\n\t        With `base.yaml` containing:\n\t        ```yaml\n\t        section:\n\t          foo: 1\n\t          bar: 2\n\t        ```\n\t        and `config.yaml` containing:\n\t        ```yaml\n\t        ^copy: base.yaml\n", "        +section:\n\t          foo: 3\n\t        ```\n\t        -> `load()` -> `save()` ->\n\t        ```yaml\n\t        section:\n\t          foo: 3\n\t          bar: 2\n\t        ```\n\t        \"\"\"\n", "        self._substitute(ctx, preprocess=False, preserve=False)\n\t    @directive(Directives.EXTEND)\n\t    async def extend_async(self, ctx: DirectiveContext) -> None:\n\t        \"\"\"\n\t        Extend a configuration with another configuration asynchronously.\n\t        For more information see `extend`.\n\t        \"\"\"\n\t        await self._substitute_async(ctx, preprocess=True, preserve=True)\n\t    @directive(Directives.INCLUDE)\n\t    async def include_async(self, ctx: DirectiveContext) -> None:\n", "        \"\"\"\n\t        Include a configuration in another configuration asynchronously.\n\t        For more information see `include`.\n\t        \"\"\"\n\t        await self._substitute_async(ctx, preprocess=True, preserve=False)\n\t    @directive(Directives.COPY)\n\t    async def copy_async(self, ctx: DirectiveContext) -> None:\n\t        \"\"\"\n\t        Copy a configuration and paste into another configuration asynchronously.\n\t        For more information see `copy`.\n", "        \"\"\"\n\t        await self._substitute_async(ctx, preprocess=False, preserve=False)\n\t    def _get_substitution_means(\n\t        self, ctx: DirectiveContext  # , *, preserve: bool\n\t    ) -> tuple[\n\t        ConfigAgent[ConfigModelT], ConfigAgent[ConfigModelT], ConfigRouteLike | None\n\t    ]:\n\t        agent_class = type(self.agent)\n\t        # todo(bswck): raise on include and extend combined\n\t        # if preserve and ???:\n", "        #     msg = (\n\t        #         \"Using more than one ??? directive \"\n\t        #         \"in the same scope is not allowed\"\n\t        #     )\n\t        #     raise ConfigPreprocessingError(msg)\n\t        agent, route = agent_class.from_directive_context(\n\t            ctx, route_separator=self.route_separator\n\t        )\n\t        if agent.resource == self.agent.resource:\n\t            raise ConfigPreprocessingError(\n", "                f\"{agent.resource} tried to {ctx.directive!r} on itself\"\n\t            )\n\t        actual_agent = agent\n\t        if agent.is_relative:\n\t            parent = cast(pathlib.Path, self.agent.resource).parent\n\t            child = cast(pathlib.Path, agent.resource)\n\t            actual_agent = copy.copy(agent)\n\t            actual_agent.resource = parent / child\n\t        return actual_agent, agent, route\n\t    def _substitute(\n", "        self, ctx: DirectiveContext, *, preprocess: bool, preserve: bool\n\t    ) -> None:\n\t        agent, orig_agent, route = self._get_substitution_means(ctx)\n\t        with agent.processor_open_resource() as reader:\n\t            source = orig_agent.load_dict(reader.read(), preprocess=preprocess)\n\t        self._substitute_impl(\n\t            ctx,\n\t            route,\n\t            source=source,\n\t            agent=orig_agent,\n", "            preprocess=preprocess,\n\t            preserve=preserve,\n\t        )\n\t    async def _substitute_async(\n\t        self, ctx: DirectiveContext, *, preprocess: bool, preserve: bool\n\t    ) -> None:\n\t        agent, orig_agent, route = self._get_substitution_means(ctx)\n\t        async with agent.processor_open_resource_async() as reader:\n\t            source = orig_agent.load_dict(await reader.read(), preprocess=preprocess)\n\t        self._substitute_impl(\n", "            ctx,\n\t            route,\n\t            source=source,\n\t            agent=orig_agent,\n\t            preprocess=preprocess,\n\t            preserve=preserve,\n\t        )\n\t    @staticmethod\n\t    def _substitute_impl(  # noqa: PLR0913\n\t        ctx: DirectiveContext,\n", "        route: ConfigRouteLike | None,\n\t        *,\n\t        source: dict[str, Any],\n\t        agent: ConfigAgent[ConfigModelT],\n\t        preprocess: bool,\n\t        preserve: bool,\n\t    ) -> None:\n\t        from configzen.model import CONTEXT, Context, at\n\t        if route:\n\t            source = at(source, route, agent=agent)\n", "            if not is_dict_like(source):\n\t                raise ConfigPreprocessingError(\n\t                    f\"imported item {route!r} \"\n\t                    f\"from {agent.resource} is not a dictionary\"\n\t                )\n\t        context: Context[ConfigModelT] = Context(agent)\n\t        ctx.container = source | ctx.container\n\t        if preserve:\n\t            ctx.container |= {\n\t                CONTEXT: context,\n", "                EXPORT: ExportMetadata(\n\t                    route=str(route),\n\t                    context=context,\n\t                    preprocess=preprocess,\n\t                    key_order=list(ctx.container),\n\t                ),\n\t            }\n\t    @classmethod\n\t    def _export(  # noqa: C901\n\t        cls,\n", "        state: dict[str, Any],\n\t        metadata: ExportMetadata[ConfigModelT],\n\t    ) -> None:\n\t        \"\"\"\n\t        Exports model state preserving substition directive calls in the model state.\n\t        Parameters\n\t        ----------\n\t        metadata\n\t        state\n\t        \"\"\"\n", "        from configzen.model import CONTEXT, at, export_hook\n\t        overrides = {}\n\t        route = metadata[\"route\"]\n\t        context = metadata[\"context\"]\n\t        key_order = metadata[\"key_order\"]\n\t        agent = context.agent\n\t        with agent.processor_open_resource() as reader:\n\t            # Here we intentionally always preprocess the loaded configuration.\n\t            loaded = agent.load_dict(reader.read())\n\t            if route:\n", "                loaded = at(loaded, route, agent=agent)\n\t        substituted_values = loaded.copy()\n\t        for key, value in loaded.items():\n\t            counterpart_value = state.pop(key, Undefined)\n\t            if counterpart_value is Undefined:\n\t                continue\n\t            counterpart_value = export_hook(counterpart_value)\n\t            if is_dict_like(value):\n\t                if EXPORT in value:\n\t                    value.pop(CONTEXT, None)\n", "                    cls.export(value, metadata=value.pop(EXPORT))\n\t                overrides_for_key = {\n\t                    sub_key: comp\n\t                    for sub_key, comp in counterpart_value.items()\n\t                    if (\n\t                        (orig := value.get(sub_key, Undefined)) is Undefined\n\t                        or orig != comp\n\t                    )\n\t                }\n\t                if overrides_for_key:\n", "                    export_key = agent.processor_class.extension_prefix + key\n\t                    overrides[export_key] = overrides_for_key\n\t            elif is_list_like(value):\n\t                cls.export(value)\n\t                if value != counterpart_value:\n\t                    overrides[key] = counterpart_value\n\t            elif value != counterpart_value:\n\t                overrides[key] = counterpart_value\n\t                del substituted_values[key]\n\t        for value in state.values():\n", "            cls.export(value)\n\t        cls._export_finalize(\n\t            context=context,\n\t            state=state,\n\t            overrides=overrides,\n\t            values=substituted_values,\n\t            route=route,\n\t            key_order=key_order,\n\t        )\n\t    @classmethod\n", "    async def _export_async(  # noqa: C901\n\t        cls,\n\t        state: dict[str, Any],\n\t        metadata: ExportMetadata[ConfigModelT],\n\t    ) -> None:\n\t        \"\"\"\n\t        Exports model state preserving substition directive calls in the model state.\n\t        Parameters\n\t        ----------\n\t        metadata\n", "        state\n\t        \"\"\"\n\t        from configzen.model import CONTEXT, at, export_hook\n\t        overrides = {}\n\t        route = metadata[\"route\"]\n\t        context = metadata[\"context\"]\n\t        key_order = metadata[\"key_order\"]\n\t        agent = context.agent\n\t        async with agent.processor_open_resource_async() as reader:\n\t            # Here we intentionally always preprocess the loaded configuration.\n", "            loaded = await agent.load_dict_async(await reader.read())\n\t            if route:\n\t                loaded = at(loaded, route, agent=agent)\n\t        substituted_values = loaded.copy()\n\t        for key, value in loaded.items():\n\t            counterpart_value = state.pop(key, Undefined)\n\t            if counterpart_value is Undefined:\n\t                continue\n\t            counterpart_value = export_hook(counterpart_value)\n\t            if is_dict_like(value):\n", "                if EXPORT in value:\n\t                    value.pop(CONTEXT, None)\n\t                    await cls.export_async(value, metadata=value.pop(EXPORT))\n\t                overrides_for_key = {\n\t                    sub_key: comp\n\t                    for sub_key, comp in counterpart_value.items()\n\t                    if (\n\t                        (orig := value.get(sub_key, Undefined)) is Undefined\n\t                        or orig != comp\n\t                    )\n", "                }\n\t                if overrides_for_key:\n\t                    export_key = agent.processor_class.extension_prefix + key\n\t                    overrides[export_key] = overrides_for_key\n\t            elif is_list_like(value):\n\t                await cls.export_async(value)\n\t                if value != counterpart_value:\n\t                    overrides[key] = counterpart_value\n\t            elif counterpart_value != value:\n\t                overrides[key] = counterpart_value\n", "                del substituted_values[key]\n\t        for value in state.values():\n\t            await cls.export_async(value)\n\t        cls._export_finalize(\n\t            context=context,\n\t            state=state,\n\t            overrides=overrides,\n\t            values=substituted_values,\n\t            route=route,\n\t            key_order=key_order,\n", "        )\n\t    @classmethod\n\t    def _export_finalize(  # noqa: PLR0913\n\t        cls,\n\t        context: BaseContext[ConfigModelT],\n\t        *,\n\t        state: dict[str, Any],\n\t        overrides: dict[str, Any],\n\t        values: dict[str, Any],\n\t        route: str | None,\n", "        key_order: list[str],\n\t    ) -> None:\n\t        from configzen.model import export_hook\n\t        state |= overrides\n\t        extras: dict[str, Any] = {\n\t            key: state.pop(key) for key in set(state) if key not in key_order\n\t        }\n\t        if values:\n\t            substitution_directive = cls.directive(Directives.EXTEND)\n\t            resource = str(export_hook(context.agent.resource))\n", "            if route:\n\t                resource = cls.route_separator.join((resource, route))\n\t            # Put the substitution directive at the beginning of the state in-place.\n\t            state |= {substitution_directive: resource} | {\n\t                key: state.pop(key) for key in set(state)\n\t            }\n\t        # Preserve the order of keys in the original configuration.\n\t        for key in filter(state.__contains__, key_order):\n\t            state[key] = state.pop(key)\n\t        state |= extras\n"]}
{"filename": "configzen/__init__.py", "chunked_list": ["# flake8: noqa\n\tfrom __future__ import annotations\n\tfrom pydantic import validator as field_validator\n\tfrom . import decorators, field, interpolation, model, module, processor, route\n\tfrom .decorators import *\n\tfrom .field import *\n\tfrom .interpolation import *\n\tfrom .model import *\n\tfrom .module import *\n\tfrom .processor import *\n", "from .route import *\n\t__all__ = (\n\t    *model.__all__,\n\t    *field.__all__,\n\t    *interpolation.__all__,\n\t    *processor.__all__,\n\t    *decorators.__all__,\n\t    *route.__all__,\n\t    *module.__all__,\n\t    \"field_validator\",\n", ")\n\tdel annotations\n"]}
{"filename": "configzen/module.py", "chunked_list": ["from __future__ import annotations\n\timport inspect\n\timport sys\n\timport types\n\tfrom typing import TYPE_CHECKING, Any, Generic, cast\n\tfrom configzen.typedefs import ConfigModelT\n\tif TYPE_CHECKING:\n\t    from configzen import ConfigModel\n\t__all__ = (\"ConfigModule\",)\n\tMODULE: str = \"__wrapped_module__\"\n", "class ConfigModule(types.ModuleType, Generic[ConfigModelT]):\n\t    __model: ConfigModelT\n\t    __vars: dict[str, Any]\n\t    def __init__(\n\t        self,\n\t        name: str,\n\t        model: ConfigModelT,\n\t        module_vars: dict[str, Any] | None = None,\n\t        doc: str | None = None,\n\t    ) -> None:\n", "        object.__setattr__(self, f\"_{ConfigModule.__name__}__model\", model)\n\t        object.__setattr__(self, f\"_{ConfigModule.__name__}__vars\", module_vars)\n\t        object.__setattr__(model, MODULE, self)\n\t        super().__init__(name=name, doc=doc)\n\t        parts = name.split(\".\")\n\t        if len(parts) > 1:\n\t            # Set the proxy module as an attribute of its parent.\n\t            parent = sys.modules[\".\".join(parts[:-1])]\n\t            setattr(parent, parts[-1], self)\n\t        # Make reusable.\n", "        sys.modules[name] = self\n\t    def __getattribute__(self, name: str) -> Any:\n\t        if name.startswith(f\"_{ConfigModule.__name__}__\"):\n\t            return object.__getattribute__(self, name)\n\t        model = self.__model\n\t        try:\n\t            return getattr(model, name)\n\t        except AttributeError:\n\t            try:\n\t                return self.__vars[name]\n", "            except KeyError:\n\t                return object.__getattribute__(self, name)\n\t    def __setattr__(self, key: str, value: Any) -> None:\n\t        model = self.get_model()\n\t        if (\n\t            not key.startswith(f\"_{ConfigModule.__name__}__\")\n\t            and key in model.__fields__\n\t        ):\n\t            setattr(model, key, value)\n\t        self.__vars[key] = value\n", "    def __repr__(self) -> str:\n\t        return super().__repr__().replace(\"module\", \"configuration module\", 1)\n\t    def get_model(self) -> ConfigModelT:\n\t        return self.__model\n\t    @classmethod\n\t    def wrap_module(\n\t        cls,\n\t        module_name: str,\n\t        model_class: type[ConfigModelT] | None = None,\n\t        module_vars: dict[str, Any] | None = None,\n", "        /,\n\t        **values: Any,\n\t    ) -> ConfigModule[ConfigModelT]:\n\t        \"\"\"Wrap a Python module to interact with a config model.\"\"\"\n\t        from configzen.model import ConfigModel\n\t        if module_vars is None:\n\t            module_vars = vars(sys.modules[module_name])\n\t        if model_class is None:\n\t            class ModuleConfigModel(ConfigModel):\n\t                __module__ = module_name\n", "                __annotations__ = module_vars[\"__annotations__\"]  # type: ignore[index]\n\t                __ns = locals()\n\t                for key in __annotations__:\n\t                    __ns[key] = module_vars[key]  # type: ignore[index]\n\t                del __ns\n\t            model_class = cast(type[ConfigModelT], ModuleConfigModel)\n\t        module_values = {}\n\t        for key, value in module_vars.items():\n\t            if key in {field.alias for field in model_class.__fields__.values()}:\n\t                module_values[key] = value\n", "        config_module = cls(\n\t            model=cast(ConfigModelT, model_class).parse_obj(module_values | values),\n\t            module_vars=module_vars,\n\t            name=module_vars[\"__name__\"],\n\t            doc=module_vars[\"__doc__\"],\n\t        )\n\t        return config_module\n\t    @classmethod\n\t    def wrap_this_module(\n\t        cls,\n", "        model_class: type[ConfigModelT] | None = None,\n\t        /,\n\t        **values: Any,\n\t    ) -> ConfigModule[ConfigModelT]:\n\t        \"\"\"Wrap the current module to interact with a config model.\"\"\"\n\t        current_frame = inspect.currentframe()\n\t        assert current_frame is not None\n\t        frame_back = current_frame.f_back\n\t        assert frame_back is not None\n\t        return cls.wrap_module(\n", "            frame_back.f_globals[\"__name__\"],\n\t            model_class,\n\t            **values,\n\t        )\n"]}
{"filename": "configzen/route.py", "chunked_list": ["from __future__ import annotations\n\timport functools\n\tfrom collections.abc import Iterator\n\tfrom typing import TYPE_CHECKING, Any, ClassVar\n\tfrom configzen.errors import InternalSyntaxError, formatted_syntax_error\n\tif TYPE_CHECKING:\n\t    from configzen.typedefs import ConfigRouteLike\n\t__all__ = (\"ConfigRoute\",)\n\tclass ConfigRoute:\n\t    TOK_DOT: ClassVar[str] = \".\"\n", "    TOK_ESCAPE: ClassVar[str] = \"\\\\\"\n\t    TOK_DOTLISTESC_ENTER: ClassVar[str] = \"[\"\n\t    TOK_DOTLISTESC_EXIT: ClassVar[str] = \"]\"\n\t    def __init__(self, route: ConfigRouteLike, *, allow_empty: bool = False) -> None:\n\t        items = self.parse(route)\n\t        if not (allow_empty or items):\n\t            raise ValueError(\"Empty configuration route\")\n\t        self.items = items\n\t    @classmethod\n\t    def parse(cls, route: ConfigRouteLike) -> list[str]:\n", "        if isinstance(route, ConfigRoute):\n\t            return route.items\n\t        if isinstance(route, list):\n\t            return route\n\t        if isinstance(route, str):\n\t            with formatted_syntax_error(route):\n\t                return cls._decompose(route)\n\t        raise TypeError(f\"Invalid route type {type(route)!r}\")\n\t    @classmethod\n\t    def _decompose(cls, route: str) -> list[str]:  # noqa: C901, PLR0912\n", "        tok_dot = cls.TOK_DOT\n\t        tok_escape = cls.TOK_ESCAPE\n\t        tok_dle_enter = cls.TOK_DOTLISTESC_ENTER\n\t        tok_dle_exit = cls.TOK_DOTLISTESC_EXIT\n\t        route = route.removesuffix(tok_dot) + tok_dot\n\t        part = \"\"\n\t        dle_ctx: int | None = None\n\t        items: list[str] = []\n\t        enter = items.append\n\t        error = functools.partial(InternalSyntaxError, prefix=\"Route(\", suffix=\")\")\n", "        escape = False\n\t        for index, char in enumerate(route):\n\t            if escape:\n\t                part += char\n\t                escape = False\n\t                continue\n\t            is_last = index == len(route) - 1\n\t            if char == tok_dot:\n\t                if dle_ctx is not None:\n\t                    part += char\n", "                else:\n\t                    enter(part)\n\t                    part = \"\"\n\t            elif char == tok_escape:\n\t                if is_last:\n\t                    part += char\n\t                else:\n\t                    escape = True\n\t            elif char == tok_dle_enter:\n\t                if dle_ctx is not None:\n", "                    # a special character at its place\n\t                    part += char\n\t                else:\n\t                    dle_ctx = index\n\t            elif char == tok_dle_exit:\n\t                if is_last or route[index + 1] == tok_dot:\n\t                    if dle_ctx is None:\n\t                        msg = (\n\t                            \"Dotlist escape sequence \"\n\t                            f\"was not opened with {tok_dle_enter!r}\"\n", "                        )\n\t                        raise error(msg, index=index)\n\t                    dle_ctx = None\n\t                else:\n\t                    # a special character at its place\n\t                    part += char\n\t            else:\n\t                part += char\n\t            if is_last and dle_ctx is not None:\n\t                msg = (\n", "                    \"Unclosed dotlist escape sequence \"\n\t                    f\"(expected {tok_dle_exit!r} token)\"\n\t                )\n\t                raise error(msg, index=dle_ctx)\n\t        return items\n\t    @classmethod\n\t    def decompose(cls, route: str) -> list[str]:\n\t        with formatted_syntax_error(route):\n\t            return cls._decompose(route)\n\t    def compose(self) -> str:\n", "        escape = (self.TOK_DOTLISTESC_ENTER, self.TOK_DOTLISTESC_EXIT)\n\t        raw = (\"\", \"\")\n\t        return self.TOK_DOT.join(\n\t            fragment.join(escape).replace(\n\t                self.TOK_DOTLISTESC_EXIT + self.TOK_DOT,\n\t                self.TOK_DOTLISTESC_EXIT + self.TOK_ESCAPE + self.TOK_DOT,\n\t            )\n\t            if self.TOK_DOT in fragment\n\t            else fragment.join(raw)\n\t            for fragment in self.items\n", "        )\n\t    def enter(self, subroute: ConfigRouteLike) -> ConfigRoute:\n\t        return type(self)(self.items + self.parse(subroute))\n\t    def __eq__(self, other: Any) -> bool:\n\t        if isinstance(other, ConfigRoute):\n\t            return self.items == other.items\n\t        if isinstance(other, str):\n\t            return self.items == self.decompose(other)\n\t        if isinstance(other, list):\n\t            return self.items == other\n", "        return NotImplemented\n\t    def __str__(self) -> str:\n\t        return self.compose()\n\t    def __iter__(self) -> Iterator[str]:\n\t        yield from self.items\n\t    def __repr__(self) -> str:\n\t        return f\"{type(self).__name__}({self.items})\"\n"]}
{"filename": "configzen/_detach.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport contextvars\n\timport functools\n\tfrom collections.abc import Callable, Coroutine\n\tfrom typing import Any, cast\n\tfrom configzen.typedefs import P, T\n\tdef detached_context_function(\n\t    func: Callable[P, T],\n\t) -> Callable[P, T]:\n", "    \"\"\"\n\t    Decorator to copy a function call context automatically (context isolation)\n\t    to prevent collisions.\n\t    This decorator will copy the current context and run the function\n\t    in this new isolated context.\n\t    \"\"\"\n\t    if isinstance(func, (classmethod, staticmethod)):\n\t        return type(func)(detached_context_function(func.__func__))\n\t    if asyncio.iscoroutinefunction(func):\n\t        @functools.wraps(func)\n", "        def _detaching_async_wrapper(*args: Any, **kwargs: Any) -> asyncio.Task[T]:\n\t            return detached_context_await(\n\t                cast(Callable[P, Coroutine[Any, Any, T]], func), *args, **kwargs\n\t            )\n\t        return cast(Callable[P, T], _detaching_async_wrapper)\n\t    @functools.wraps(func)\n\t    def _detaching_wrapper(*args: Any, **kwargs: Any) -> T:\n\t        return detached_context_run(func, *args, **kwargs)\n\t    return _detaching_wrapper\n\tdef detached_context_run(\n", "    func: Callable[..., T],\n\t    *args: Any,\n\t    **kwargs: Any,\n\t) -> T:\n\t    \"\"\"Utility for running a function in an isolated context.\"\"\"\n\t    context = contextvars.copy_context()\n\t    return context.run(func, *args, **kwargs)\n\tdef detached_context_await(\n\t    func: Callable[..., Coroutine[Any, Any, T]],\n\t    *args: Any,\n", "    **kwargs: Any,\n\t) -> asyncio.Task[T]:\n\t    \"\"\"Utility for awaiting a coroutine in an isolated context.\"\"\"\n\t    return asyncio.create_task(func(*args, **kwargs))\n"]}
{"filename": "configzen/interpolation.py", "chunked_list": ["from __future__ import annotations\n\timport functools\n\timport importlib\n\timport inspect\n\timport re\n\timport string\n\timport sys\n\tfrom collections import ChainMap\n\tfrom collections.abc import Callable, MutableMapping\n\tfrom typing import TYPE_CHECKING, Any, ClassVar, cast\n", "from pydantic.fields import Undefined, UndefinedType\n\tfrom configzen.errors import ResourceLookupError\n\tif TYPE_CHECKING:\n\t    from configzen.typedefs import ConfigModelT\n\t__all__ = (\n\t    \"interpolate\",\n\t    \"include\",\n\t)\n\tINTERPOLATOR: str = \"__interpolator__\"\n\tEVALUATES: str = \"__evaluates__\"\n", "EVALUATION_ENGINE: str = \"__evaluation_engine__\"\n\tNAMESPACE_TOKEN: str = \"::\"\n\tAT_TOKEN: str = \"@\"\n\tOR_TOKEN: str = \"||\"\n\tSTRICT_TOKEN: str = \"!\"\n\tclass ConfigInterpolationTemplate(string.Template):\n\t    delimiter = re.escape(\"$\")\n\t    idpattern = r\"[^{}\\$]+\"\n\t    # noinspection PyClassVar\n\t    pattern: ClassVar[re.Pattern[str]] = rf\"\"\"\n", "    {delimiter}(?:\n\t      (?P<escaped>{delimiter})          | # Escape sequence of two delims\n\t      (?P<named>{idpattern})            | # delimiter and a Python ident\n\t      {{(?P<sbraced>{idpattern})}}      | # delimiter and a single-braced ident\n\t      {{{{(?P<braced>{idpattern})}}}}   | # delimiter and a double-braced ident\n\t      (?P<invalid>)                       # Other ill-formed delimiter expressions\n\t    )\n\t    \"\"\"  # type: ignore[assignment]\n\t    flags = re.VERBOSE | re.IGNORECASE\n\t    def _invalid(self, mo: re.Match[str]) -> None:\n", "        i = mo.start(\"invalid\")\n\t        lines = self.template[:i].splitlines(keepends=True)\n\t        if not lines:\n\t            colno = 1\n\t            lineno = 1\n\t        else:\n\t            colno = i - len(\"\".join(lines[:-1]))\n\t            lineno = len(lines)\n\t        raise ValueError(f\"Invalid placeholder in string: line {lineno}, col {colno}\")\n\t    def interpolate(\n", "        self, mapping: MutableMapping[str, Any] | None = None, /, **kwds: Any\n\t    ) -> str:\n\t        if mapping is None:\n\t            mapping = kwds\n\t        elif kwds:\n\t            mapping = ChainMap(kwds, mapping)\n\t        # Helper function for .sub()\n\t        def convert(mo: re.Match[str]) -> str:\n\t            named = mo.group(\"named\") or mo.group(\"braced\") or mo.group(\"sbraced\")\n\t            if named is not None:\n", "                try:\n\t                    return str(mapping[named])\n\t                except KeyError:\n\t                    return mo.group()\n\t            if mo.group(\"escaped\") is not None:\n\t                return self.delimiter\n\t            if mo.group(\"invalid\") is not None:\n\t                return mo.group()\n\t            raise ValueError(\"Unrecognized named group in pattern\", self.pattern)\n\t        return self.pattern.sub(convert, self.template)\n", "    if sys.version_info < (3, 11):\n\t        def get_identifiers(self) -> list[str]:\n\t            ids = []\n\t            for mo in self.pattern.finditer(self.template):\n\t                named = mo.group(\"named\") or mo.group(\"braced\") or mo.group(\"sbraced\")\n\t                if named is not None and named not in ids:\n\t                    # add a named group only the first time it appears\n\t                    ids.append(named)\n\t                elif (\n\t                    named is None\n", "                    and mo.group(\"invalid\") is None\n\t                    and mo.group(\"escaped\") is None\n\t                ):\n\t                    # If all the groups are None, there must be\n\t                    # another group we\"re not expecting\n\t                    raise ValueError(\n\t                        \"Unrecognized named group in pattern\", self.pattern\n\t                    )\n\t            return ids\n\t@functools.singledispatch\n", "def interpolate(\n\t    value: Any,\n\t    _cls: type[ConfigModelT],\n\t    _closest_ns: dict[str, Any],\n\t    _target_type: type[Any],\n\t) -> Any:\n\t    return value\n\t@interpolate.register(str)\n\tdef _try_interpolate_str(\n\t    value: str,\n", "    cls: type[ConfigModelT],\n\t    closest_namespace: dict[str, Any],\n\t    target_type: type[Any],\n\t) -> Any:\n\t    template = ConfigInterpolationTemplate(value)\n\t    identifiers = set(template.get_identifiers())\n\t    if not identifiers:\n\t        return value\n\t    namespace = cls.get_interpolation_namespace(\n\t        expressions=identifiers,\n", "        closest_namespace=closest_namespace,\n\t        target_type=target_type,\n\t    )\n\t    interpolator: BaseInterpolator = getattr(cls, INTERPOLATOR)\n\t    if len(identifiers) == 1:\n\t        identifier = identifiers.pop()\n\t        value = namespace[identifier]\n\t        return interpolator.interpolate_one(\n\t            template=template,\n\t            identifier=identifier,\n", "            value=value,\n\t            target_type=target_type,\n\t        )\n\t    return interpolator.interpolate_many(\n\t        template=template, namespace=namespace, target_type=target_type\n\t    )\n\tdef _ensure_dispatchable_type(\n\t    target_type: type[Any],\n\t) -> type[Any]:\n\t    if not getattr(target_type, \"__mro__\", None):\n", "        target_type = object\n\t    return target_type\n\tclass BaseInterpolator:\n\t    def interpolate_many(\n\t        self,\n\t        template: ConfigInterpolationTemplate,\n\t        namespace: dict[str, Any],\n\t        target_type: type[Any],\n\t    ) -> Any:\n\t        dispatch_type = _ensure_dispatchable_type(target_type)\n", "        bulk_render = self.bulk_renderers.dispatch(dispatch_type)\n\t        return bulk_render(self, template, namespace)\n\t    # noinspection PyMethodMayBeStatic\n\t    def bulk_render_any(\n\t        self, template: ConfigInterpolationTemplate, namespace: dict[str, Any]\n\t    ) -> Any:\n\t        return template.interpolate(namespace)\n\t    def interpolate_one(\n\t        self,\n\t        template: ConfigInterpolationTemplate,\n", "        identifier: str,\n\t        value: Any,\n\t        target_type: type[Any],\n\t    ) -> Any:\n\t        dispatch_type = _ensure_dispatchable_type(target_type)\n\t        render = self.single_renderers.dispatch(dispatch_type)\n\t        return render(self, template, identifier, value)\n\t    # noinspection PyMethodMayBeStatic\n\t    def single_render_any(\n\t        self, _template: ConfigInterpolationTemplate, _identifier: str, value: Any\n", "    ) -> Any:\n\t        return value\n\t    bulk_renderers = functools.singledispatch(bulk_render_any)\n\t    single_renderers = functools.singledispatch(single_render_any)\n\tdef evaluates(\n\t    evaluator_name: str,\n\t) -> Callable[[Callable[[Any], Any]], Callable[[Any], Any]]:\n\t    def decorator(evaluator: Callable[[Any], Any]) -> Callable[[Any], Any]:\n\t        setattr(evaluator, EVALUATES, evaluator_name.casefold())\n\t        return evaluator\n", "    return decorator\n\tclass BaseEvaluationEngine:\n\t    evaluators_by_name: ClassVar[dict[str, Any]] = {}\n\t    def evaluate_expression_impl(\n\t        self,\n\t        expression: str,\n\t        result_namespace: dict[str, Any],\n\t        namespaces: dict[str | None, dict[str, Any]],\n\t        closest_namespace: dict[str, Any],\n\t        target_type: type[Any],\n", "    ) -> Any:\n\t        from configzen import field_hook\n\t        result = Undefined\n\t        final_result = Undefined\n\t        for identifier in expression.strip().split(OR_TOKEN):\n\t            identifier = identifier.strip()\n\t            if identifier:\n\t                result = self.resolve_identifier(\n\t                    identifier=identifier,\n\t                    result_namespace=result_namespace,\n", "                    namespaces=namespaces,\n\t                    closest_namespace=closest_namespace,\n\t                )\n\t                if result is not Undefined:\n\t                    result = field_hook(target_type, result)\n\t                    result_namespace[identifier] = result\n\t                if result:\n\t                    final_result = result\n\t                    break\n\t        if final_result is not Undefined:\n", "            result_namespace[expression] = final_result\n\t        return result\n\t    @staticmethod\n\t    def resolve_identifier(\n\t        identifier: str,\n\t        result_namespace: dict[str, Any],\n\t        namespaces: dict[str | None, dict[str, Any]],\n\t        closest_namespace: dict[str, Any],\n\t        strict: bool | None = None,\n\t    ) -> Any:\n", "        from configzen.model import at\n\t        if (identifier.startswith('\"') and identifier.endswith('\"')) or (\n\t            identifier.startswith(\"'\") and identifier.endswith(\"'\")\n\t        ):\n\t            return identifier[1:-1]\n\t        if strict is None:\n\t            strict = identifier.startswith(\"!\")\n\t            if strict:\n\t                identifier = identifier[1:].strip()\n\t        ns_name, uses_ns, ident = identifier.rpartition(NAMESPACE_TOKEN)\n", "        namespaces_to_use = []\n\t        ns_at_ident = \"\"\n\t        global_namespace = namespaces[None]\n\t        if uses_ns:\n\t            # [namespace[[.member]*@ns_at_ident[.member]*]]::identifier\n\t            if ns_name and uses_ns:\n\t                ns_name, _, ns_at_ident = ns_name.rpartition(AT_TOKEN)\n\t                if ns_name in namespaces:\n\t                    namespaces_to_use.append(namespaces[ns_name])\n\t            namespaces_to_use.append(global_namespace)\n", "            namespaces_to_use.append(closest_namespace)\n\t            namespaces_to_use.append(result_namespace)\n\t        else:\n\t            # identifier[.member]*\n\t            namespaces_to_use.append(closest_namespace)\n\t            namespaces_to_use.append(result_namespace)\n\t            namespaces_to_use.append(global_namespace)\n\t        ident, _, ident_at = ident.partition(AT_TOKEN)\n\t        lookup_key = ns_name if uses_ns and ns_name else ident\n\t        lookup_value: dict[str, Any] | UndefinedType = Undefined\n", "        for namespace in namespaces_to_use:\n\t            try:\n\t                lookup_value = at(namespace, lookup_key)\n\t            except ResourceLookupError:\n\t                if strict:\n\t                    raise\n\t            if lookup_value is not Undefined:\n\t                break\n\t        if lookup_value is Undefined:\n\t            return identifier\n", "        value = lookup_value\n\t        if uses_ns and ns_name:\n\t            namespace = cast(\"dict[str, Any]\", value)\n\t            if ns_at_ident:\n\t                namespace = at(namespace, ns_at_ident)\n\t            try:\n\t                value = at(namespace, ident)\n\t            except ResourceLookupError:\n\t                if strict:\n\t                    raise\n", "            if value is Undefined:\n\t                return Undefined\n\t        if ident_at:\n\t            value = at(value, ident_at)\n\t        result_namespace[identifier] = value\n\t        return value\n\t    evaluators_by_class = functools.singledispatch(evaluate_expression_impl)\n\t    def evaluate_expression(\n\t        self,\n\t        expression: str,\n", "        result_namespace: dict[str, Any],\n\t        namespaces: dict[str | None, dict[str, Any]],\n\t        closest_namespace: dict[str, Any],\n\t        target_type: type[Any],\n\t    ) -> Any:\n\t        dispatch_type = _ensure_dispatchable_type(target_type)\n\t        evaluator = self.evaluators_by_class.dispatch(dispatch_type)\n\t        return evaluator(\n\t            self,\n\t            expression,\n", "            result_namespace,\n\t            namespaces,\n\t            closest_namespace,\n\t            target_type,\n\t        )\n\t    def __init_subclass__(cls, *, register_evaluators: bool = True) -> None:\n\t        super().__init_subclass__()\n\t        if cls.evaluators_by_name is None:\n\t            cls.evaluators_by_name = {}\n\t        if register_evaluators:\n", "            # TODO: Replace with `inspect.getmembers_static()` by 2026-10.\n\t            for _, func in inspect.getmembers(cls, inspect.isfunction):\n\t                name = getattr(func, EVALUATES, None)\n\t                if name is not None:\n\t                    cls.register_evaluator(name, func)\n\t    @classmethod\n\t    def register_evaluator(cls, name: str, evaluator: Callable[[Any], Any]) -> None:\n\t        cls.evaluators_by_name[name] = evaluator\n\tBaseEvaluationEngine.__init_subclass__()\n\tdef _include_wrapper(\n", "    cls: type[ConfigModelT],\n\t    namespace_name: str | None,\n\t    namespace_factory: Callable[[], dict[str, Any]],\n\t) -> type[ConfigModelT]:\n\t    from configzen.model import INTERPOLATION_INCLUSIONS\n\t    getattr(cls, INTERPOLATION_INCLUSIONS)[namespace_name] = namespace_factory\n\t    return cls\n\t# noinspection PyUnusedLocal\n\t@functools.singledispatch\n\tdef include(\n", "    namespace: Any,\n\t    /,\n\t    *,\n\t    name: str | None = None,  # noqa: ARG001\n\t    **kwargs: Any,  # noqa: ARG001\n\t) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n\t    raise TypeError(\n\t        f\"Cannot include {namespace} (unexpected type {type(namespace).__name__})\"\n\t    )\n\t@include.register(dict)\n", "def include_const(\n\t    namespace: dict[str, Any] | ConfigModelT, /, *, name: str | None = None\n\t) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n\t    from configzen import ConfigModel\n\t    if isinstance(namespace, ConfigModel):\n\t        return lambda cls: _include_wrapper(\n\t            cls, name, lambda: namespace.dict()  # type: ignore\n\t        )\n\t    return lambda cls: _include_wrapper(cls, name, lambda: namespace)  # type: ignore\n\tdef _include_factory(\n", "    namespace_factory: Callable[[], dict[str, Any]],\n\t    /,\n\t    *,\n\t    name: str | None = None,\n\t) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n\t    return lambda cls: _include_wrapper(cls, name, namespace_factory)\n\tif not TYPE_CHECKING:\n\t    include.register(Callable, _include_factory)\n\t@include.register(str)\n\tdef _include_str(\n", "    namespace: str,\n\t    /,\n\t    *,\n\t    name: str | None = None,\n\t    stack_offset: int = 2,\n\t    module: str | None = None,\n\t    isolate_from_toplevel: bool = True,\n\t) -> Callable[[type[ConfigModelT]], type[ConfigModelT]]:\n\t    if module is None:\n\t        callers_globals = inspect.stack()[stack_offset].frame.f_globals\n", "    else:\n\t        callers_globals = None\n\t    if isolate_from_toplevel and name is None:\n\t        name = namespace\n\t    def namespace_factory() -> dict[str, Any]:\n\t        nonlocal callers_globals\n\t        from configzen import ConfigModel\n\t        if callers_globals is None:\n\t            assert module\n\t            module_obj = importlib.import_module(module)\n", "            callers_globals = module_obj.__dict__\n\t        try:\n\t            namespace_variable = callers_globals[namespace]\n\t        except KeyError:\n\t            raise NameError(\n\t                f\"Namespace {namespace!r} not found in {callers_globals['__name__']}\"\n\t            ) from None\n\t        if isinstance(namespace_variable, dict):\n\t            return namespace_variable\n\t        if isinstance(namespace_variable, ConfigModel):\n", "            return namespace_variable.dict()\n\t        raise TypeError(\n\t            f\"Cannot include {namespace!r} (unexpected type \"\n\t            f\"{type(namespace_variable).__name__})\"\n\t        )\n\t    return lambda cls: _include_wrapper(cls, name, namespace_factory)\n"]}
{"filename": "tests/test_processor.py", "chunked_list": []}
{"filename": "tests/conftest.py", "chunked_list": ["import functools\n\timport pathlib\n\ttestpath = functools.partial(pathlib.Path(__file__).parent.joinpath)\n"]}
{"filename": "tests/test_supported_formats/conftest.py", "chunked_list": ["import configparser\n\timport functools\n\timport io\n\timport json\n\timport os\n\tfrom typing import Union\n\timport bson\n\timport cbor\n\timport cbor2\n\timport configobj\n", "# import msgpack\n\timport pytest\n\timport toml\n\timport yaml\n\tfrom amazon.ion import simpleion as ion\n\tfrom anyconfig.backend import properties\n\tfrom configzen import ConfigModel\n\tfrom tests.conftest import testpath\n\tfile_dir = testpath(\"test_supported_formats/data\")\n\tfile_dir.mkdir(exist_ok=True)\n", "class IncorporatedModel(ConfigModel):\n\t    string: str\n\tclass SectionModel(ConfigModel):\n\t    integer: int\n\t    incorporated_model: IncorporatedModel = IncorporatedModel(string=\"Hello world!\")\n\t    union_value: Union[bool, float]\n\t    collection_value: list[str]\n\t    dict_value: dict[str, str] = {\"configzen\": \"is this\"}\n\tclass MockModel(ConfigModel):\n\t    main: SectionModel\n", "def ini_compose(data):\n\t    config = configparser.ConfigParser()\n\t    config.read_dict(data)\n\t    fp = io.StringIO()\n\t    config.write(fp)\n\t    return fp.getvalue()\n\tdef configobj_compose(data):\n\t    config = configobj.ConfigObj()\n\t    config.merge(data)\n\t    fp = io.BytesIO()\n", "    config.write(fp)\n\t    return fp.getvalue().decode()\n\tdef shellvars_compose(data):\n\t    output = \"\"\n\t    for key, value in data.items():\n\t        output += f\"{key}='{value}'{os.linesep}\"\n\t    return output\n\tdef properties_compose(data):\n\t    output = \"\"\n\t    for key, value in data.items():\n", "        output += f\"{key}={properties.escape(str(value))}{os.linesep}\"\n\t    return output\n\tcomposer = {\n\t    \"ini\": ini_compose,\n\t    \"configobj\": configobj_compose,\n\t    \"json\": functools.partial(json.dumps, indent=4),\n\t    \"yaml\": yaml.dump,\n\t    \"toml\": toml.dumps,\n\t    \"ion\": ion.dumps,\n\t    \"bson\": bson.encode,\n", "    \"cbor2\": cbor2.dumps,\n\t    \"cbor\": cbor.dumps,\n\t    # \"msgpack\": msgpack.dumps,\n\t    \"shellvars\": shellvars_compose,\n\t    \"properties\": properties_compose,\n\t}\n\t@pytest.fixture(\n\t    name=\"mock_data\",\n\t    scope=\"session\",\n\t    params=[\n", "        {\n\t            \"main\": {\n\t                \"integer\": 0xDEADBEEF,\n\t                \"incorporated_model\": {\"string\": \"Hello world!\"},\n\t                \"union_value\": 0.2137,\n\t                \"collection_value\": [\"this\", \"is\", \"configzen\"],\n\t                \"dict_value\": {\"configzen\": \"is this\"},\n\t            }\n\t        }\n\t    ],\n", ")\n\tdef mock_data_fixture(request):\n\t    yield request.param\n\t@pytest.fixture(\n\t    scope=\"session\",\n\t    autouse=True,\n\t    params=[\n\t        (composer[\"ini\"], file_dir / \"data.ini\", False),\n\t        (composer[\"json\"], file_dir / \"data.json\", False),\n\t        (composer[\"yaml\"], file_dir / \"data.yaml\", False),\n", "        (composer[\"toml\"], file_dir / \"data.toml\", False),\n\t        (composer[\"bson\"], file_dir / \"data.bson\", True),\n\t        (composer[\"cbor2\"], file_dir / \"data.cbor2\", True),\n\t        (composer[\"cbor\"], file_dir / \"data.cbor\", True),\n\t        (composer[\"shellvars\"], file_dir / \"data.shellvars\", False),\n\t        (composer[\"properties\"], file_dir / \"data.properties\", False),\n\t        (composer[\"ion\"], file_dir / \"data.ion\", True),\n\t        (composer[\"configobj\"], file_dir / \"data.configobj\", False),\n\t        # (composer[\"msgpack\"], file_dir / \"data.msgpack\", True),\n\t    ],\n", ")\n\tdef data_file(request, mock_data):\n\t    dumper, dest_file, uses_binary_data = request.param\n\t    if dumper in (composer[\"shellvars\"], composer[\"properties\"]):\n\t        used_mock_data = mock_data[\"main\"].copy()\n\t        mock_data = used_mock_data\n\t    dest_file.touch()\n\t    if uses_binary_data:\n\t        dest_file.write_bytes(dumper(mock_data))\n\t    else:\n", "        dest_file.write_text(dumper(mock_data))\n\t    yield dest_file\n"]}
{"filename": "tests/test_supported_formats/test_supported_formats.py", "chunked_list": ["from __future__ import annotations\n\timport pydantic\n\tfrom tests.test_supported_formats.conftest import MockModel, SectionModel\n\tdef test_load_and_recreate(data_file, mock_data):\n\t    try:\n\t        model = MockModel.load(data_file)\n\t    except pydantic.ValidationError:\n\t        # key-value pairs, little workaround\n\t        assert data_file.suffix in (\".shellvars\", \".properties\")\n\t        model = MockModel(main=SectionModel.load(data_file))\n", "    model_dict = model.dict()\n\t    assert model_dict == mock_data\n\t    recreated = MockModel.parse_obj(model_dict)\n\t    assert recreated == model\n\t    assert recreated.dict() == mock_data\n"]}
{"filename": "tests/test_module_wrapping/config.py", "chunked_list": ["# from configzen.module import ConfigModule\n\tprint(\"MODULE EXECUTED\")\n\ta: int = 1\n\tb: int = 2\n\t# ConfigModule.wrap_this_module()\n"]}
{"filename": "tests/test_module_wrapping/configempty.py", "chunked_list": []}
{"filename": "tests/test_module_wrapping/test_wrapping.py", "chunked_list": ["import importlib\n\timport sys\n\timport weakref\n\tfrom configzen import ConfigModel\n\tclass MyConfig(ConfigModel):\n\t    \"\"\"My config model\"\"\"\n\t    a: int = 5\n\t    b: int = 10\n\tdef test_module_wrapping():\n\t    from tests.test_module_wrapping import config as module\n", "    module_name = module.__name__\n\t    model = MyConfig.wrap_module(module)\n\t    ref = weakref.ref(module)\n\t    del module\n\t    assert ref() is None\n\t    module_wrapper = sys.modules[module_name]\n\t    from tests.test_module_wrapping import config as reimported_module  # reimport\n\t    assert reimported_module is module_wrapper\n\t    module_wrapper.a = \"100\"\n\t    assert reimported_module.a == model.a == 100\n", "    reimported_module.b = \"200\"\n\t    assert reimported_module.b == model.b == 200\n\t    old_wrapper = module_wrapper\n\t    reloaded_wrapper = importlib.reload(module_wrapper)\n\t    assert old_wrapper is reloaded_wrapper\n\t    assert reloaded_wrapper.a == 1  # config.py:3\n\t    assert reloaded_wrapper.b == 2  # config.py:4\n\t    MyConfig.wrap_module(\"tests.test_module_wrapping.configempty\")\n\t    wrapper = sys.modules[\"tests.test_module_wrapping.configempty\"]\n\t    model = sys.modules[\"tests.test_module_wrapping.configempty\"].get_model()\n", "    assert model == MyConfig()\n\t    assert wrapper.a == MyConfig().a\n\t    assert wrapper.b == MyConfig().b\n\t    wrapper.a = \"2137\"\n\t    wrapper.b = \"1337\"\n\t    assert wrapper.a == model.a == 2137\n\t    assert wrapper.b == model.b == 1337\n\t    model.reload()\n\t    assert wrapper.a == model.a == 2137  # config is empty, old values stay\n\t    assert wrapper.b == model.b == 1337  # config is empty, old values stay\n"]}
{"filename": "tests/test_config/test_agent.py", "chunked_list": []}
{"filename": "tests/test_config/test_hooks.py", "chunked_list": []}
{"filename": "tests/test_config/test_meta.py", "chunked_list": ["from __future__ import annotations\n\timport io\n\timport pytest\n\tfrom pydantic import ConfigError\n\tfrom configzen import ConfigAgent, ConfigMeta, ConfigModel\n\tclass NoAutoUpdateForwardRefs(ConfigModel):\n\t    item: Item\n\t    class Config(ConfigMeta):\n\t        autoupdate_forward_refs = False\n\tclass AutoUpdateForwardRefs(ConfigModel):\n", "    item: Item\n\tclass Item(ConfigModel):\n\t    foo: int\n\tdef get_agent():\n\t    resource = io.StringIO(\"item:\\n  foo: 123\")\n\t    agent = ConfigAgent(resource=resource, parser_name=\"yaml\")\n\t    return agent\n\tdef test_autoupdate_forward_refs():\n\t    assert AutoUpdateForwardRefs.load(get_agent()) == AutoUpdateForwardRefs(\n\t        item=Item(foo=123)\n", "    )\n\t    with pytest.raises(ConfigError):\n\t        NoAutoUpdateForwardRefs.load(get_agent())\n\tdef test_resource_and_parser_name():\n\t    class FixedResourceModel(ConfigModel):\n\t        class Config(ConfigMeta):\n\t            resource = io.StringIO(\"foo: 123\")\n\t            parser_name = \"yaml\"\n\t        foo: int\n\t    assert FixedResourceModel.load() == FixedResourceModel(foo=123)\n", "    overridden_resource = ConfigAgent(io.StringIO(\"foo: 456\"), parser_name=\"yaml\")\n\t    assert FixedResourceModel.load(overridden_resource) == FixedResourceModel(foo=456)\n"]}
{"filename": "tests/test_config/test_route.py", "chunked_list": ["from __future__ import annotations\n\timport pytest\n\tfrom configzen.errors import ConfigSyntaxError\n\tfrom configzen.model import ConfigRoute\n\tSTRING_DECOMPOSITION_PARAMS = [\n\t    (\"a.b.c\", [\"a\", \"b\", \"c\"]),\n\t    (r\"a\\.b.c\", [\"a.b\", \"c\"]),\n\t    (\"a.b.[c.d]\", [\"a\", \"b\", \"c.d\"]),\n\t    (\"[a.b].c.[d.e]\", [\"a.b\", \"c\", \"d.e\"]),\n\t    (r\"a.[b.[c.d]\\.e].f\", [\"a\", \"b.[c.d].e\", \"f\"]),\n", "    (r\"[a.b][c.d]\", [\"a.b][c.d\"]),\n\t]\n\t@pytest.mark.parametrize(\n\t    \"obj, expected\",\n\t    [\n\t        # List inputs\n\t        ([\"a\", \"b\", \"c\"], [\"a\", \"b\", \"c\"]),\n\t        ([\"a\", \"b\", \"c.d\"], [\"a\", \"b\", \"c.d\"]),\n\t        ([\"a.b\", \"c\", \"d.e\"], [\"a.b\", \"c\", \"d.e\"]),\n\t        # Route inputs\n", "        (ConfigRoute([\"a\", \"b\", \"c\"]), [\"a\", \"b\", \"c\"]),\n\t        (ConfigRoute([\"a\", \"b\", \"c.d\"]), [\"a\", \"b\", \"c.d\"]),\n\t        (ConfigRoute([\"a.b\", \"c\", \"d.e\"]), [\"a.b\", \"c\", \"d.e\"]),\n\t        # String inputs\n\t        *STRING_DECOMPOSITION_PARAMS,\n\t    ],\n\t)\n\tdef test_parse(obj, expected):\n\t    assert ConfigRoute.parse(obj) == expected\n\t@pytest.mark.parametrize(\"composed, decomposed\", STRING_DECOMPOSITION_PARAMS)\n", "def test_decompose(composed, decomposed):\n\t    assert ConfigRoute.decompose(composed) == decomposed\n\t@pytest.mark.parametrize(\n\t    \"illegal_input\",\n\t    [\n\t        # String inputs\n\t        \"a.b.[c.d\",\n\t        \"a.b.c]\",\n\t        \"[a.b.c\",\n\t    ],\n", ")\n\tdef test_illegal_inputs(illegal_input):\n\t    with pytest.raises(ConfigSyntaxError):\n\t        ConfigRoute(illegal_input)\n\t@pytest.mark.parametrize(\n\t    \"route, expected\",\n\t    [\n\t        (ConfigRoute(\"a.b.c\"), \"a.b.c\"),\n\t        (ConfigRoute(\"a.[b.c]\"), \"a.[b.c]\"),\n\t        (ConfigRoute(r\"a.b\\.c\"), \"a.[b.c]\"),\n", "        (ConfigRoute(r\"a.[b.[c.d]\\.e].f\"), r\"a.[b.[c.d]\\.e].f\"),\n\t        (ConfigRoute(r\"a.b\\.\\[c\\.d\\]\\.e.f\"), r\"a.[b.[c.d]\\.e].f\"),\n\t    ],\n\t)\n\tdef test_compose(route, expected):\n\t    assert route.compose() == expected\n\tdef test_enter():\n\t    assert ConfigRoute(\"a\").enter(\"b\") == ConfigRoute(\"a.b\")\n\t    assert ConfigRoute(\"a\").enter([\"b\", \"c\"]) == ConfigRoute(\"a.b.c\")\n\t    assert ConfigRoute(\"a\").enter(ConfigRoute(\"b.c\")) == ConfigRoute(\"a.b.c\")\n", "    assert ConfigRoute(\"a\").enter(ConfigRoute([\"b\", \"c\"])) == ConfigRoute(\"a.b.c\")\n\t    assert ConfigRoute(\"a\").enter(ConfigRoute(\"b.[c.d]\")) == ConfigRoute(\"a.b.[c.d]\")\n\tdef test_equality_operator():\n\t    assert ConfigRoute(\"a.b.c\") == ConfigRoute(\"a.b.c\")\n\t    assert ConfigRoute(\"a.b.c\") == [\"a\", \"b\", \"c\"]\n\t    assert ConfigRoute([\"a\", \"b\", \"c\"]) == [\"a\", \"b\", \"c\"]\n"]}
{"filename": "tests/test_config/test_model/test_load.py", "chunked_list": ["import io\n\timport os\n\timport sys\n\timport tempfile\n\timport pytest\n\tfrom configzen import ConfigAgent, ConfigModel\n\tclass Model(ConfigModel):\n\t    item: int\n\tclass ModelWithHeader(ConfigModel):\n\t    header: Model\n", "default_params = pytest.mark.parametrize(\n\t    \"blob, parser_name, expected\",\n\t    [\n\t        ('{\"item\": 123}', \"json\", Model(item=123)),\n\t        (\"item: 456\", \"yaml\", Model(item=456)),\n\t        (\"[header]\\nitem = 789\", \"toml\", ModelWithHeader(header=Model(item=789))),\n\t        (\"[header]\\nitem = 101\", \"ini\", ModelWithHeader(header=Model(item=101))),\n\t    ],\n\t)\n\t@default_params\n", "def test_load_stream(blob, parser_name, expected):\n\t    loaded_model: type[ConfigModel] = type(expected)\n\t    assert (\n\t        loaded_model.load(\n\t            ConfigAgent(resource=io.StringIO(blob), parser_name=parser_name)\n\t        )\n\t        == expected\n\t    )\n\t    loaded_model.__config__.resource = io.StringIO(blob)\n\t    loaded_model.__config__.parser_name = parser_name\n", "    assert loaded_model.load() == expected\n\t    loaded_model.__config__.resource = ConfigAgent(\n\t        resource=io.StringIO(blob), parser_name=parser_name\n\t    )\n\t    loaded_model.__config__.parser_name = None\n\t    assert loaded_model.load() == expected\n\tdef get_temp_file(blob):\n\t    file = tempfile.NamedTemporaryFile(\n\t        mode=\"w+\", encoding=sys.getdefaultencoding(), delete=False\n\t    )\n", "    file.write(blob)\n\t    file.close()\n\t    return file\n\t@default_params\n\tdef test_load_file(blob, parser_name, expected):\n\t    loaded_model: type[ConfigModel] = type(expected)\n\t    file = get_temp_file(blob)\n\t    assert (\n\t        loaded_model.load(ConfigAgent(resource=file.name, parser_name=parser_name))\n\t        == expected\n", "    )\n\t    os.unlink(file.name)\n\t    file = get_temp_file(blob)\n\t    loaded_model.__config__.resource = file.name\n\t    loaded_model.__config__.parser_name = parser_name\n\t    assert loaded_model.load() == expected\n\t    os.unlink(file.name)\n\t    file = get_temp_file(blob)\n\t    loaded_model.__config__.resource = ConfigAgent(\n\t        resource=file.name, parser_name=parser_name\n", "    )\n\t    loaded_model.__config__.parser_name = None\n\t    assert loaded_model.load() == expected\n\t    os.unlink(file.name)\n"]}
