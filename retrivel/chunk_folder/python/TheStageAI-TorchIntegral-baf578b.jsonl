{"filename": "setup.py", "chunked_list": ["import os\n\timport platform\n\timport numpy as np\n\tfrom setuptools import setup\n\tfrom setuptools.command.build_ext import build_ext\n\tfrom distutils.extension import Extension\n\tfrom Cython.Build import cythonize\n\t# --------------------------------------------------------------------------------------------\n\t# Handling compile args for Cython\n\t# --------------------------------------------------------------------------------------------\n", "if platform.system() == \"Darwin\":\n\t    compile_opts = [\n\t        \"-std=c++11\",\n\t        \"-Ofast\",  # '-fopenmp',\n\t        \"-mmacosx-version-min={:}\".format(platform.mac_ver()[0]),\n\t    ]\n\telif platform.system() == \"Linux\":\n\t    compile_opts = [\n\t        \"-std=c++11\",\n\t        \"-Ofast\",  # '-fopenmp'\n", "    ]\n\telse:\n\t    raise EnvironmentError(\n\t        \"Not supported platform: {plat}\".format(plat=platform.system())\n\t    )\n\t# --------------------------------------------------------------------------------------------\n\t# C++/Cython extesnions and packages\n\t# --------------------------------------------------------------------------------------------\n\ttsp_ext = Extension(\n\t    \"torch_integral.tsp_solver.solver\",\n", "    sources=[\"torch_integral/tsp_solver/solver.pyx\"],\n\t    extra_compile_args=compile_opts,\n\t    extra_link_args=compile_opts,\n\t    language=\"c++\",\n\t    include_dirs=[np.get_include()],\n\t)\n\text_modules = [tsp_ext]\n\tpackages = [\n\t    \"torch_integral\",\n\t    \"torch_integral.tsp_solver\",\n", "    \"torch_integral.graph\",\n\t    \"torch_integral.parametrizations\",\n\t]\n\t# --------------------------------------------------------------------------------------------\n\t# Package setup\n\t# --------------------------------------------------------------------------------------------\n\tsetup(\n\t    name=\"TorchIntegral\",\n\t    ext_modules=cythonize(ext_modules),\n\t    version=\"0.0.0.0\",\n", "    author=\"Azim Kurbanov, Solodskikh Kirill\",\n\t    author_email=\"hello@thestage.ai\",\n\t    maintainer=\"TheStage.AI\",\n\t    maintainer_email=\"hello@thestage.ai\",\n\t    install_requires=[\"cython\"],\n\t    description=\"Official Integral Neural Networks in PyTorch.\",\n\t    url=\"https://inn.thestage.ai\",\n\t    zip_safe=False,\n\t    packages=packages,\n\t    license=\"Apache License 2.0\",\n", "    long_description=\"Bla Bla\",\n\t    classifiers=[\"Programming Language :: Python :: 3\"],\n\t)\n"]}
{"filename": "tests/tsp_test.py", "chunked_list": ["import torch\n\timport time\n\timport torch_integral\n\tfrom torch_integral.tsp_solver import two_opt_find_permutation\n\ttensors = [\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n", "    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n\t]\n\tt = time.time()\n", "ind = two_opt_find_permutation(tensors, 64, 100, 0.01)\n\tt = time.time() - t\n\tprint(\"time: \", t)\n"]}
{"filename": "torch_integral/model.py", "chunked_list": ["import copy\n\tfrom typing import Any, Mapping\n\timport torch\n\timport torch.nn as nn\n\tfrom torch.nn.utils import parametrize\n\tfrom .grid import GridND\n\tfrom .graph import IntegralTracer\n\tfrom .parametrizations import IntegralParameterization\n\tfrom .parametrizations import InterpolationWeights1D\n\tfrom .parametrizations import InterpolationWeights2D\n", "from .permutation import NOptPermutation\n\tfrom .quadrature import TrapezoidalQuadrature\n\tfrom .grid import TrainableGrid1D\n\tfrom .utils import (\n\t    reset_batchnorm,\n\t    get_parent_name,\n\t    fuse_batchnorm,\n\t    get_parent_module,\n\t    get_attr_by_name,\n\t)\n", "class IntegralModel(nn.Module):\n\t    \"\"\"\n\t    Contains original model with parametrized layers and IntegralGroups list.\n\t    Parameters\n\t    ----------\n\t    model: torch.nn.Module.\n\t        Model with parametrized layers.\n\t    groups: List[IntegralGroup].\n\t        List related groups.\n\t    \"\"\"\n", "    def __init__(self, model, groups):\n\t        super(IntegralModel, self).__init__()\n\t        self.model = model\n\t        groups.sort(key=lambda g: g.count_parameters())\n\t        self.groups = nn.ModuleList(groups)\n\t        # Rename groups to integral_groups\n\t        self.original_size = None\n\t        self.original_size = self.calculate_compression()\n\t    def generate_grid(self):\n\t        \"\"\"Creates new grids in each group.\"\"\"\n", "        for group in self.groups:\n\t            group.grid.generate_grid()\n\t    def clear(self):\n\t        \"\"\"Clears cached tensors in all integral groups.\"\"\"\n\t        for group in self.groups:\n\t            group.clear()\n\t    def load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True):\n\t        out = super().load_state_dict(state_dict, strict)\n\t        self.clear()\n\t        return out\n", "    def forward(self, x):\n\t        \"\"\"\n\t        Performs forward pass of the model.\n\t        Parameters\n\t        ----------\n\t        x: the same as wrapped model's input type.\n\t            Input of the model.\n\t        Returns\n\t        -------\n\t        Model's output.\n", "        \"\"\"\n\t        self.generate_grid()\n\t        return self.model(x)\n\t    def calculate_compression(self):\n\t        \"\"\"\n\t        Returns 1 - ratio of the size of the current\n\t        model to the original size of the model.\n\t        \"\"\"\n\t        out = 0\n\t        self.generate_grid()\n", "        for group in self.groups:\n\t            group.clear()\n\t        for name, param in self.model.named_parameters():\n\t            if \"parametrizations.\" not in name:\n\t                out += param.numel()\n\t            elif name.endswith(\".original\"):\n\t                name = name.replace(\".original\", \"\")\n\t                name = name.replace(\"parametrizations.\", \"\")\n\t                tensor = get_attr_by_name(self.model, name)\n\t                out += tensor.numel()\n", "        if self.original_size is not None:\n\t            out = 1.0 - out / self.original_size\n\t        return out\n\t    def resize(self, sizes):\n\t        \"\"\"\n\t        Resizes grids in each group.\n\t        Parameters\n\t        ----------\n\t        sizes: List[int].\n\t            List of new sizes.\n", "        \"\"\"\n\t        for group, size in zip(self.groups, sizes):\n\t            group.resize(size)\n\t    def reset_grids(self, grids):\n\t        for group, grid in zip(self.groups, grids):\n\t            group.reset_grid(grid)\n\t    def reset_distributions(self, distributions):\n\t        \"\"\"\n\t        Sets new distributions in each IntegralGroup.grid.\n\t        Parameters\n", "        ----------\n\t        distributions: List[torch_integral.grid.Distribution].\n\t            List of new distributions.\n\t        \"\"\"\n\t        for group, dist in zip(self.groups, distributions):\n\t            group.reset_distribution(dist)\n\t    def grids(self):\n\t        \"\"\"Returns list of grids of each integral group.\"\"\"\n\t        return [group.grid for group in self.groups]\n\t    def __getattr__(self, item):\n", "        if item in dir(self):\n\t            out = super().__getattr__(item)\n\t        else:\n\t            out = getattr(self.model, item)\n\t        return out\n\t    def transform_to_discrete(self):\n\t        \"\"\"Samples weights, removes parameterizations and returns discrete model.\"\"\"\n\t        self.generate_grid()\n\t        parametrizations = []\n\t        for name, module in self.model.named_modules():\n", "            for attr_name in (\"weight\", \"bias\"):\n\t                if parametrize.is_parametrized(module, attr_name):\n\t                    parametrization = getattr(module.parametrizations, attr_name)[0]\n\t                    parametrizations.append((module, attr_name, parametrization))\n\t                    parametrize.remove_parametrizations(module, attr_name, True)\n\t        discrete_model = copy.deepcopy(self.model)\n\t        for p_data in parametrizations:\n\t            module, attr_name, parametrization = p_data\n\t            parametrize.register_parametrization(\n\t                module, attr_name, parametrization, unsafe=True\n", "            )\n\t        return discrete_model\n\t    def grid_tuning(self, train_bn=False, train_bias=False, use_all_grids=False):\n\t        \"\"\"\n\t        Sets requires_grad = False for all parameters except TrainableGrid's parameters,\n\t        biases and BatchNorm parameters (if corresponding flag is True).\n\t        Parameters\n\t        ----------\n\t        train_bn: bool.\n\t            Set True to train BatchNorm parameters.\n", "        train_bias: bool.\n\t            Set True to train biases.\n\t        use_all_grids: bool.\n\t            Set True to use all grids in each group.\n\t        \"\"\"\n\t        if use_all_grids:\n\t            for group in self.groups:\n\t                if group.subgroups is None:\n\t                    group.reset_grid(TrainableGrid1D(group.grid_size()))\n\t        for name, param in self.named_parameters():\n", "            parent = get_parent_module(self, name)\n\t            if isinstance(parent, TrainableGrid1D):\n\t                param.requires_grad = True\n\t            else:\n\t                param.requires_grad = False\n\t        if train_bn:\n\t            reset_batchnorm(self)\n\t        if train_bias:\n\t            for group in self.groups:\n\t                for p in group.params:\n", "                    if \"bias\" in p[\"name\"]:\n\t                        parent = get_parent_module(self.model, p[\"name\"])\n\t                        if parametrize.is_parametrized(parent, \"bias\"):\n\t                            parametrize.remove_parametrizations(parent, \"bias\", True)\n\t                        getattr(parent, \"bias\").requires_grad = True\n\tclass IntegralWrapper:\n\t    \"\"\"\n\t    Wrapper class which allows batch norm fusion,\n\t    permutation of tensor parameters to obtain continuous structure in the tensor\n\t    and convertation of discrete model to integral.\n", "    Parameters\n\t    ----------\n\t    init_from_discrete: bool.\n\t        If set True, then parametrization will be optimized with\n\t        gradient descent to approximate discrete model's weights.\n\t    fuse_bn: bool.\n\t        If True, then convolutions and batchnorms will be fused.\n\t    optimize_iters: int.\n\t        Number of optimization iterations for discerete weight tensor approximation.\n\t    start_lr: float.\n", "        Learning rate when optimizing parametrizations.\n\t    permutation_config: dict.\n\t        Arguments of permutation method.\n\t    build_functions: dict.\n\t        Dictionary with keys\n\t    permutation_iters: int.\n\t        Number of iterations of total variation optimization process.\n\t    verbose: bool.\n\t        If True, then information about model convertation process will be printed.\n\t    \"\"\"\n", "    def __init__(\n\t        self,\n\t        init_from_discrete=True,\n\t        fuse_bn=True,\n\t        optimize_iters=0,\n\t        start_lr=1e-2,\n\t        permutation_config=None,\n\t        build_functions=None,\n\t        permutation_iters=100,\n\t        verbose=True,\n", "    ):\n\t        self.init_from_discrete = init_from_discrete\n\t        self.fuse_bn = fuse_bn\n\t        self.optimize_iters = optimize_iters\n\t        self.start_lr = start_lr\n\t        self.build_functions = build_functions\n\t        self.verbose = verbose\n\t        self.rearranger = None\n\t        if permutation_config is not None:\n\t            permutation_class = permutation_config.pop(\"class\")\n", "            self.rearranger = permutation_class(**permutation_config)\n\t        elif self.init_from_discrete and permutation_iters > 0:\n\t            self.rearranger = NOptPermutation(permutation_iters, verbose)\n\t    def _rearrange(self, groups):\n\t        \"\"\"\n\t        Rearranges the tensors in each group along continuous\n\t        dimension to obtain continuous structure in tensors.\n\t        Parameters\n\t        ----------\n\t        groups: List[IntegralGroup].\n", "            List of related integral groups.\n\t        \"\"\"\n\t        for i, group in enumerate(groups):\n\t            params = list(group.params)\n\t            feature_maps = group.tensors\n\t            if self.verbose:\n\t                print(f\"Rearranging of group {i}\")\n\t            for parent in group.parents:\n\t                start = 0\n\t                for another_group in parent.subgroups:\n", "                    if group is not another_group:\n\t                        start += another_group.size\n\t                    else:\n\t                        break\n\t                for p in parent.params:\n\t                    params.append(\n\t                        {\n\t                            \"name\": p[\"name\"],\n\t                            \"value\": p[\"value\"],\n\t                            \"dim\": p[\"dim\"],\n", "                            \"start_index\": start,\n\t                        }\n\t                    )\n\t            self.rearranger(params, feature_maps, group.size)\n\t    def preprocess_model(\n\t        self,\n\t        model,\n\t        example_input,\n\t        continuous_dims,\n\t        discrete_dims=None,\n", "        custom_operations=None,\n\t        custom_hooks=None,\n\t    ):\n\t        \"\"\"\n\t        Builds dependency graph of the model, fuses BatchNorms\n\t        and permutes tensor parameters along countinuous\n\t        dimension to obtain smooth structure.\n\t        Parameters\n\t        ----------\n\t        model: torch.nn.Module.\n", "            Discrete neural network.\n\t        example_input: torch.Tensor or List[int].\n\t            Example input for the model.\n\t        continuous_dims: Dict[str, List[int]].\n\t            Dictionary with keys as names of parameters and values\n\t            as lists of continuous dimensions of corresponding parameters.\n\t        discrete_dims: Dict[str, List[int]].\n\t            Dictionary with keys as names of parameters and values\n\t            as lists of discrete dimensions of corresponding parameters.\n\t        custom_operations: Dict[Union[str, Callable], Callable].\n", "            Dictionary which contains custom tracing operations for the graph.\n\t        custom_hooks: Dict[torch.nn.Module, Callable].\n\t            Dictionary which contains custom hooks for the graph.\n\t        Returns\n\t        -------\n\t        List[IntegralGroup].\n\t            List of IntegralGroup objects.\n\t        Dict[str, List[int]].\n\t            Modified dictionary with continuous dimensions.\n\t        \"\"\"\n", "        tracer = IntegralTracer(\n\t            model, continuous_dims, discrete_dims, custom_operations, custom_hooks\n\t        )\n\t        tracer.build_groups(example_input)\n\t        if self.fuse_bn:\n\t            integral_convs = set()\n\t            for name, _ in model.named_parameters():\n\t                if name in tracer.continuous_dims:\n\t                    parent = get_parent_module(model, name)\n\t                    dims = tracer.continuous_dims[name]\n", "                    if isinstance(parent, nn.Conv2d) and 0 in dims:\n\t                        integral_convs.add(get_parent_name(name)[0])\n\t            fuse_batchnorm(model.eval(), list(integral_convs))\n\t        tracer = IntegralTracer(\n\t            model, continuous_dims, discrete_dims, custom_operations, custom_hooks\n\t        )\n\t        groups = tracer.build_groups(example_input)\n\t        if self.init_from_discrete and self.rearranger is not None:\n\t            self._rearrange(groups)\n\t        return groups, tracer.continuous_dims\n", "    def __call__(\n\t        self,\n\t        model,\n\t        example_input,\n\t        continuous_dims,\n\t        discrete_dims=None,\n\t        custom_operations=None,\n\t        custom_hooks=None,\n\t    ):\n\t        \"\"\"\n", "        Parametrizes tensor parameters of the model\n\t        and wraps the model into IntegralModel class.\n\t        Parameters\n\t        ----------\n\t        model: torch.nn.Module.\n\t            Discrete neural network.\n\t        example_input: List[int] or torch.Tensor.\n\t            Example input for the model.\n\t        continuous_dims: Dict[str, List[int]].\n\t            Dictionary with keys as names of parameters and values\n", "            as lists of continuous dimensions of corresponding parameters.\n\t        discrete_dims: Dict[str, List[int]].\n\t            Dictionary with keys as names of parameters and values\n\t            as lists of discrete dimensions of corresponding parameters.\n\t        Returns\n\t        -------\n\t        IntegralModel.\n\t            Model converted to integral form.\n\t        \"\"\"\n\t        integral_groups, continuous_dims = self.preprocess_model(\n", "            model,\n\t            example_input,\n\t            continuous_dims,\n\t            discrete_dims,\n\t            custom_operations,\n\t            custom_hooks,\n\t        )\n\t        groups = [g for g in integral_groups if g.subgroups is None]\n\t        for group in groups:\n\t            group.initialize_grids()\n", "        for group in integral_groups:\n\t            for p in group.params:\n\t                _, name = get_parent_name(p[\"name\"])\n\t                parent = get_parent_module(model, p[\"name\"])\n\t                if not parametrize.is_parametrized(parent, name) or all(\n\t                    [\n\t                        not isinstance(obj, IntegralParameterization)\n\t                        for obj in parent.parametrizations[name]\n\t                    ]\n\t                ):\n", "                    if (\n\t                        self.build_functions is not None\n\t                        and type(parent) in self.build_functions\n\t                    ):\n\t                        build_function = self.build_functions[type(parent)]\n\t                    elif isinstance(parent, (nn.Linear, nn.Conv2d, nn.Conv1d)):\n\t                        build_function = build_base_parameterization\n\t                    else:\n\t                        raise AttributeError(\n\t                            f\"Provide build function for attribute {name} of {type(parent)}\"\n", "                        )\n\t                    dims = continuous_dims[p[\"name\"]]\n\t                    w_func, quadrature = build_function(parent, name, dims)\n\t                    grids_list = []\n\t                    for g in p[\"value\"].grids:\n\t                        if hasattr(g, \"grid\") and g.grid is not None:\n\t                            if g in integral_groups:\n\t                                grids_list.append(g.grid)\n\t                    grid = GridND(grids_list)\n\t                    delattr(p[\"value\"], \"grids\")\n", "                    parametrization = IntegralParameterization(\n\t                        w_func, grid, quadrature\n\t                    ).to(p[\"value\"].device)\n\t                    target = p[\"value\"].detach().clone()\n\t                    target.requires_grad = False\n\t                    parametrize.register_parametrization(\n\t                        parent, name, parametrization, unsafe=True\n\t                    )\n\t                    if self.init_from_discrete:\n\t                        self._optimize_parameters(parent, p[\"name\"], target)\n", "                else:\n\t                    parametrization = parent.parametrizations[name][0]\n\t                p[\"function\"] = parametrization\n\t        integral_model = IntegralModel(model, integral_groups)\n\t        return integral_model\n\t    def _optimize_parameters(self, module, name, target):\n\t        \"\"\"\n\t        Optimize parametrization with Adam\n\t        to approximate tensor attribute of given module.\n\t        Parameters\n", "        ----------\n\t        module: torch.nn.Module.\n\t            Layer of the model.\n\t        name: str.\n\t            Name of the parameter.\n\t        target: torch.Tensor.\n\t            Tensor to approximate.\n\t        \"\"\"\n\t        module.train()\n\t        _, attr = get_parent_name(name)\n", "        criterion = torch.nn.MSELoss()\n\t        opt = torch.optim.Adam(module.parameters(), lr=self.start_lr, weight_decay=0.0)\n\t        scheduler = torch.optim.lr_scheduler.StepLR(\n\t            opt, step_size=self.optimize_iters // 5, gamma=0.2\n\t        )\n\t        if self.verbose:\n\t            print(name)\n\t            print(\n\t                \"loss before optimization: \",\n\t                float(criterion(getattr(module, attr), target)),\n", "            )\n\t        for i in range(self.optimize_iters):\n\t            weight = getattr(module, attr)\n\t            loss = criterion(weight, target)\n\t            loss.backward()\n\t            opt.step()\n\t            scheduler.step()\n\t            opt.zero_grad()\n\t            if i == self.optimize_iters - 1 and self.verbose:\n\t                print(\"loss after optimization: \", float(loss))\n", "def build_base_parameterization(module, name, dims, scale=1.0):\n\t    \"\"\"\n\t    Builds parametrization and quadrature objects\n\t    for parameters of Conv2d, Conv1d or Linear\n\t    Parameters\n\t    ----------\n\t    module: torhc.nn.Module.\n\t        Layer of the model.\n\t    name: str.\n\t        Name of the parameter.\n", "    dims: List[int].\n\t        List of continuous dimensions of the parameter.\n\t    scale: float.\n\t        Parametrization size multiplier.\n\t    Returns\n\t    -------\n\t    IntegralParameterization.\n\t        Parametrization of the parameter.\n\t    BaseIntegrationQuadrature.\n\t        Quadrature object for the parameter.\n", "    \"\"\"\n\t    quadrature = None\n\t    func = None\n\t    if name == \"weight\":\n\t        weight = getattr(module, name)\n\t        cont_shape = [int(scale * weight.shape[d]) for d in dims]\n\t        if weight.ndim > len(dims):\n\t            discrete_shape = [\n\t                weight.shape[d] for d in range(weight.ndim) if d not in dims\n\t            ]\n", "        else:\n\t            discrete_shape = None\n\t        if len(cont_shape) == 2:\n\t            func = InterpolationWeights2D(cont_shape, discrete_shape)\n\t        elif len(cont_shape) == 1:\n\t            func = InterpolationWeights1D(cont_shape[0], discrete_shape, dims[0])\n\t        if 1 in dims and weight.shape[1] > 3:\n\t            grid_indx = 0 if len(cont_shape) == 1 else 1\n\t            quadrature = TrapezoidalQuadrature([1], [grid_indx])\n\t    elif \"bias\" in name:\n", "        bias = getattr(module, name)\n\t        cont_shape = int(scale * bias.shape[0])\n\t        func = InterpolationWeights1D(cont_shape)\n\t    return func, quadrature\n"]}
{"filename": "torch_integral/permutation.py", "chunked_list": ["import torch\n\tfrom .tsp_solver import two_opt_find_permutation\n\tdef total_variance(tensors):\n\t    \"\"\"\n\t    Calculates total variation of tensors along given dimension.\n\t    Parameters\n\t    ----------\n\t    tensors: List[Dict[str, obj]].\n\t        List of dicts with keys 'value' and 'dim'.\n\t    Returns\n", "    -------\n\t    total_var: float.\n\t        Estimated total variation.\n\t    \"\"\"\n\t    total_var = 0.0\n\t    for t in tensors:\n\t        tensor = t[\"value\"]\n\t        dim = t[\"dim\"]\n\t        tensor = tensor.transpose(dim, 0)\n\t        diff = (tensor[1:] - tensor[:-1]).abs().mean()\n", "        total_var = total_var + diff\n\t    return total_var\n\tclass BasePermutation:\n\t    \"\"\"Base class for tensors permutaiton.\"\"\"\n\t    def __call__(self, params, feature_maps, size):\n\t        \"\"\"\n\t        Performs permutation of weight tensors along given dimension.\n\t        Parameters\n\t        ----------\n\t        params: List[Dict[str, obj]].\n", "            List of dicts with keys 'value', 'dim', 'name'.\n\t            Value is a parameter tensor.\n\t        feature_maps: List[Dict[str, obj]].\n\t            List of dicts with keys 'value', 'dim', 'name'.\n\t            Value is a feature map tensor.\n\t        size: int.\n\t            Size of tensor dimension along which permutation should be performed.\n\t        \"\"\"\n\t        permutation = self.find_permutation(params, feature_maps, size)\n\t        for t in params:\n", "            dim = t[\"dim\"]\n\t            tensor = t[\"value\"]\n\t            if \"start_index\" not in t:\n\t                start = 0\n\t            else:\n\t                start = t[\"start_index\"]\n\t            permuted = torch.index_select(tensor, dim, permutation + start)\n\t            tensor.data = torch.slice_scatter(\n\t                tensor, permuted, dim, start, start + size\n\t            )\n", "    def find_permutation(self, params, feature_maps, size):\n\t        \"\"\"Method should return list of indices.\"\"\"\n\t        raise NotImplementedError(\"Implement this method in derived class.\")\n\tclass RandomPermutation(BasePermutation):\n\t    def find_permutation(self, params, feature_maps, size):\n\t        \"\"\"Returns random permutation of given size.\"\"\"\n\t        return torch.randperm(size, device=params[0][\"value\"].device)\n\tclass NOptPermutation(BasePermutation):\n\t    \"\"\"\n\t    Class for total variation optimization using py2opt algorithm.\n", "    Parameters\n\t    ----------\n\t    iters: int.\n\t    threshold: float.\n\t    verbose: bool.\n\t    \"\"\"\n\t    def __init__(self, iters=100, threshold=0.001, verbose=True):\n\t        super(NOptPermutation, self).__init__()\n\t        self.iters = iters\n\t        self.verbose = verbose\n", "        self.threshold = threshold\n\t    def find_permutation(self, params, feature_maps, size):\n\t        \"\"\"Uses py2opt algorithm to find permutation of given tensors.\"\"\"\n\t        optimize_tensors = self._select_tensors(params, feature_maps)\n\t        indices = two_opt_find_permutation(\n\t            optimize_tensors, size, self.iters, self.threshold\n\t        )\n\t        device = params[0][\"value\"].device\n\t        indices = indices.type(torch.long).to(device)\n\t        return indices\n", "    def _select_tensors(self, params, feature_maps):\n\t        \"\"\"Returns list of tensors which total variation should be optimized.\"\"\"\n\t        return params\n\tclass NOptOutFiltersPermutation(NOptPermutation):\n\t    \"\"\"\n\t    Class implements NOptPermutation\n\t    interface for optimzation of out filters total variation.\n\t    \"\"\"\n\t    def __init__(self, iters=100, verbose=True):\n\t        super(NOptOutFiltersPermutation, self).__init__(iters, verbose)\n", "    def _select_tensors(self, params, feature_maps):\n\t        tensors = [t for t in params if \"bias\" not in t[\"name\"] and t[\"dim\"] == 0]\n\t        if len(tensors) == 0:\n\t            tensors = params\n\t        return tensors\n\tclass NOoptFeatureMapPermutation(NOptPermutation):\n\t    \"\"\"\n\t    Class implements NOptPermutation interface\n\t    for optimzation of feature maps total variation.\n\t    \"\"\"\n", "    def _select_tensors(self, params, feature_maps):\n\t        \"\"\" \"\"\"\n\t        out = []\n\t        for f in feature_maps:\n\t            if f[\"operation\"] == \"conv_linear\":\n\t                out.append(f)\n\t        if len(out) == 0:\n\t            out = feature_maps\n\t        return out\n"]}
{"filename": "torch_integral/__init__.py", "chunked_list": ["from .model import IntegralWrapper\n\tfrom .model import IntegralModel\n\tfrom .graph import IntegralTracer\n\tfrom .grid import UniformDistribution\n\tfrom .grid import NormalDistribution\n\tfrom .grid import TrainableGrid1D\n\tfrom .grid import RandomLinspace\n\tfrom .utils import grid_tuning\n\tfrom .utils import standard_continuous_dims\n"]}
{"filename": "torch_integral/utils.py", "chunked_list": ["import torch\n\tfrom typing import Tuple, Dict, Any, List\n\timport torch.fx as fx\n\timport copy\n\timport torch.nn as nn\n\tfrom collections import OrderedDict\n\tfrom .grid import TrainableGrid1D\n\tfrom contextlib import contextmanager\n\tfrom torch.nn.utils import parametrize\n\tdef get_attr_by_name(module, name):\n", "    \"\"\" \"\"\"\n\t    for s in name.split(\".\"):\n\t        module = getattr(module, s)\n\t    return module\n\tdef get_parent_name(qualname: str) -> Tuple[str, str]:\n\t    \"\"\"\n\t    Splits a ``qualname`` into parent path and last atom.\n\t    For example, `foo.bar.baz` -> (`foo.bar`, `baz`)\n\t    \"\"\"\n\t    *parent, name = qualname.rsplit(\".\", 1)\n", "    return parent[0] if parent else \"\", name\n\tdef get_parent_module(module, attr_path):\n\t    \"\"\"\n\t    Returns parent module of module.attr_path.\n\t    Parameters\n\t    ----------\n\t    module: torch.nn.Module.\n\t    attr_path: str.\n\t    \"\"\"\n\t    parent_name, attr_name = get_parent_name(attr_path)\n", "    if parent_name != \"\":\n\t        parent = get_attr_by_name(module, parent_name)\n\t    else:\n\t        parent = module\n\t    return parent\n\tdef remove_all_hooks(model: torch.nn.Module) -> None:\n\t    \"\"\" \"\"\"\n\t    for name, child in model._modules.items():\n\t        if child is not None:\n\t            if hasattr(child, \"_forward_hooks\"):\n", "                child._forward_hooks = OrderedDict()\n\t            remove_all_hooks(child)\n\tdef fuse_batchnorm(model, convs):\n\t    \"\"\"\n\t    Fuse conv and bn only if conv is in convs argument.\n\t    Parameters\n\t    ----------\n\t    model: torch.nn.Module.\n\t    convs: List[torch.nn.ConvNd].\n\t    \"\"\"\n", "    fx_model: fx.GraphModule = fx.symbolic_trace(model)\n\t    modules = dict(fx_model.named_modules())\n\t    for node in fx_model.graph.nodes:\n\t        if node.op != \"call_module\":\n\t            continue\n\t        if (\n\t            type(modules[node.target]) is nn.BatchNorm2d\n\t            and type(modules[node.args[0].target]) is nn.Conv2d\n\t        ):\n\t            if node.args[0].target in convs:\n", "                if len(node.args[0].users) > 1:\n\t                    continue\n\t                conv = modules[node.args[0].target]\n\t                bn = modules[node.target]\n\t                inplace_conv_bn_fusion(conv, bn)\n\t                parent_name, attr_name = get_parent_name(node.target)\n\t                parent = get_parent_module(model, node.target)\n\t                setattr(parent, attr_name, torch.nn.Identity())\n\tdef inplace_conv_bn_fusion(conv, bn):\n\t    \"\"\" \"\"\"\n", "    assert not (conv.training or bn.training), \"Fusion only for eval!\"\n\t    conv.weight.data, bias = fuse_conv_bn_weights(\n\t        conv.weight,\n\t        conv.bias,\n\t        bn.running_mean,\n\t        bn.running_var,\n\t        bn.eps,\n\t        bn.weight,\n\t        bn.bias,\n\t    )\n", "    if conv.bias is None:\n\t        conv.bias = torch.nn.Parameter(bias).to(conv.weight.device)\n\t    else:\n\t        conv.bias.data = bias\n\tdef fuse_conv_bn_weights(conv_w, conv_b, bn_rm, bn_rv, bn_eps, bn_w, bn_b):\n\t    \"\"\" \"\"\"\n\t    if conv_b is None:\n\t        conv_b = torch.zeros_like(bn_rm)\n\t    if bn_w is None:\n\t        bn_w = torch.ones_like(bn_rm)\n", "    if bn_b is None:\n\t        bn_b = torch.zeros_like(bn_rm)\n\t    bn_var_rsqrt = torch.rsqrt(bn_rv + bn_eps)\n\t    conv_w = conv_w * (bn_w * bn_var_rsqrt).reshape(\n\t        [-1] + [1] * (len(conv_w.shape) - 1)\n\t    )\n\t    conv_b = (conv_b - bn_rm) * bn_var_rsqrt * bn_w + bn_b\n\t    return conv_w, conv_b\n\tdef reset_batchnorm(model):\n\t    \"\"\"\n", "    Set new BatchNorm2d in place of fused batch norm layers.\n\t    Parameters\n\t    ----------\n\t    model: torch.nn.Module.\n\t    \"\"\"\n\t    fx_model = torch.fx.symbolic_trace(model)\n\t    modules = dict(model.named_modules())\n\t    for node in fx_model.graph.nodes:\n\t        if node.op != \"call_module\":\n\t            continue\n", "        if type(modules[node.target]) is nn.Identity:\n\t            conv = modules[node.args[0].target]\n\t            size = conv.weight.shape[0]\n\t            bn = nn.BatchNorm2d(size)\n\t            _, attr_name = get_parent_name(node.target)\n\t            parent = get_parent_module(model, node.target)\n\t            setattr(parent, attr_name, bn)\n\tdef standard_continuous_dims(model):\n\t    \"\"\"\n\t    Returns dict containing names of all Conv2d and Linear layer's parameters as keys\n", "    and [0, 1] / [0] as values for weight / bias.\n\t    Parameters\n\t    ----------\n\t    model: torch.nn.Module.\n\t    Returns\n\t    -------\n\t    Dict[str, List[int]].\n\t    \"\"\"\n\t    continuous_dims = {}\n\t    for name, param in model.named_parameters():\n", "        parent_name, attr_name = get_parent_name(name)\n\t        parent = get_parent_module(model, name)\n\t        if isinstance(parent, (torch.nn.Linear, torch.nn.Conv2d)):\n\t            if \"weight\" in attr_name:\n\t                continuous_dims[name] = [0, 1]\n\t            elif \"bias\" in name:\n\t                continuous_dims[name] = [0]\n\t    return continuous_dims\n\t@contextmanager\n\tdef grid_tuning(integral_model, train_bn=False, train_bias=False, use_all_grids=False):\n", "    \"\"\"\n\t    Context manager sets requires_grad=True only for TrainableGrid parameters\n\t    and batch norm and bias parameters if corresponding flag is set True.\n\t    Parameters\n\t    ----------\n\t    train_bn: bool.\n\t    train_bias: bool.\n\t    use_all_grids: bool.\n\t    \"\"\"\n\t    integral_model.grid_tuning(train_bn, train_bias, use_all_grids)\n", "    try:\n\t        yield None\n\t    finally:\n\t        for name, param in integral_model.named_parameters():\n\t            parent = get_parent_module(integral_model, name)\n\t            if isinstance(parent, TrainableGrid1D):\n\t                param.requires_grad = False\n\t            else:\n\t                param.requires_grad = True\n"]}
{"filename": "torch_integral/grid.py", "chunked_list": ["import torch\n\timport random\n\tfrom scipy.special import roots_legendre\n\tclass Distribution:\n\t    \"\"\"\n\t    Base class for grid size distribution.\n\t    Attributes\n\t    ----------\n\t    min_val: int.\n\t        Minimal possible random value.\n", "    max_val: int.\n\t        Maximal possible random value.\n\t    \"\"\"\n\t    def __init__(self, min_val, max_val):\n\t        self.min_val = min_val\n\t        self.max_val = max_val\n\t    def sample(self):\n\t        \"\"\"Samples random integer number from distribution.\"\"\"\n\t        raise NotImplementedError(\"Implement this method in derived class.\")\n\tclass UniformDistribution(Distribution):\n", "    def __init__(self, min_val, max_val):\n\t        super().__init__(min_val, max_val)\n\t    def sample(self):\n\t        return random.randint(self.min_val, self.max_val)\n\tclass NormalDistribution(Distribution):\n\t    def __init__(self, min_val, max_val):\n\t        super(NormalDistribution, self).__init__(min_val, max_val)\n\t    def sample(self):\n\t        out = random.normalvariate(0, 0.5 * (self.max_val - self.min_val))\n\t        out = self.max_val - int(abs(out))\n", "        if out < self.min_val:\n\t            out = random.randint(self.min_val, self.max_val)\n\t        return out\n\tclass IGrid(torch.nn.Module):\n\t    \"\"\"Base Grid class.\"\"\"\n\t    def __init__(self):\n\t        super(IGrid, self).__init__()\n\t        self.curr_grid = None\n\t        self.eval_size = None\n\t    def forward(self):\n", "        \"\"\"\n\t        Performs forward pass. Generates new grid if\n\t        last generated grid is not saved, else returns saved one.\n\t        Returns\n\t        -------\n\t        torch.Tensor.\n\t            Generated grid points.\n\t        \"\"\"\n\t        if self.curr_grid is None:\n\t            out = self.generate_grid()\n", "        else:\n\t            out = self.curr_grid\n\t        return out\n\t    def ndim(self):\n\t        \"\"\"Returns dimensionality of grid object.\"\"\"\n\t        return 1\n\t    def size(self):\n\t        return self.eval_size\n\t    def generate_grid(self):\n\t        \"\"\"Samples new grid points.\"\"\"\n", "        raise NotImplementedError(\"Implement this method in derived class.\")\n\tclass ConstantGrid1D(IGrid):\n\t    \"\"\"\n\t    Class implements IGrid interface for fixed grid.\n\t    Parameters\n\t    ----------\n\t    init_value: torch.Tensor.\n\t    \"\"\"\n\t    def __init__(self, init_value):\n\t        super(ConstantGrid1D, self).__init__()\n", "        self.curr_grid = init_value\n\t    def generate_grid(self):\n\t        return self.curr_grid\n\tclass TrainableGrid1D(IGrid):\n\t    \"\"\"Grid with TrainablePartition.\n\t    Parameters\n\t    ----------\n\t    size: int.\n\t    init_value: torch.Tensor.\n\t    \"\"\"\n", "    def __init__(self, size, init_value=None):\n\t        super(TrainableGrid1D, self).__init__()\n\t        self.eval_size = size\n\t        self.curr_grid = torch.nn.Parameter(torch.linspace(-1, 1, size))\n\t        if init_value is not None:\n\t            assert size == init_value.shape[0]\n\t            self.curr_grid.data = init_value\n\t    def generate_grid(self):\n\t        return self.curr_grid\n\tclass RandomLinspace(IGrid):\n", "    \"\"\"\n\t    Grid which generates random sized tensor each time,\n\t    when generate_grid method is called.\n\t    Size of tensor is sampled from ``size_distribution``.\n\t    Parameters\n\t    ----------\n\t    size_distribution: Distribution.\n\t    noise_std: float.\n\t    \"\"\"\n\t    def __init__(self, size_distribution, noise_std=0):\n", "        super(RandomLinspace, self).__init__()\n\t        self.distribution = size_distribution\n\t        self.eval_size = size_distribution.max_val\n\t        self.noise_std = noise_std\n\t        self.generate_grid()\n\t    def generate_grid(self):\n\t        if self.training:\n\t            size = self.distribution.sample()\n\t        else:\n\t            size = self.eval_size\n", "        self.curr_grid = torch.linspace(-1, 1, size)\n\t        if self.noise_std > 0:\n\t            noise = torch.normal(torch.zeros(size), self.noise_std * torch.ones(size))\n\t            self.curr_grid = self.curr_grid + noise\n\t        return self.curr_grid\n\t    def resize(self, new_size):\n\t        \"\"\"Set new value for evaluation size.\"\"\"\n\t        self.eval_size = new_size\n\t        self.generate_grid()\n\tclass RandomLegendreGrid(RandomLinspace):\n", "    def __init__(self, size_distribution):\n\t        super(RandomLinspace, self).__init__()\n\t        self.distribution = size_distribution\n\t        self.eval_size = size_distribution.max_val\n\t        self.generate_grid()\n\t    def generate_grid(self):\n\t        if self.training:\n\t            size = self.distribution.sample()\n\t        else:\n\t            size = self.eval_size\n", "        self.curr_grid, _ = roots_legendre(size)\n\t        self.curr_grid = torch.tensor(self.curr_grid, dtype=torch.float32)\n\t        return self.curr_grid\n\tclass CompositeGrid1D(IGrid):\n\t    \"\"\"Grid which consist of concatenated IGrid objects.\"\"\"\n\t    def __init__(self, grids):\n\t        super(CompositeGrid1D, self).__init__()\n\t        self.grids = torch.nn.ModuleList(grids)\n\t        size = self.size()\n\t        self.proportions = [(grid.size() - 1) / (size - 1) for grid in grids]\n", "        self.generate_grid()\n\t    def reset_grid(self, index, new_grid):\n\t        self.grids[index] = new_grid\n\t        self.generate_grid()\n\t    def generate_grid(self):\n\t        g_list = []\n\t        start = 0.0\n\t        h = 1 / (self.size() - 1)\n\t        device = None\n\t        for i, grid in enumerate(self.grids):\n", "            g = grid.generate_grid()\n\t            device = g.device if device is None else device\n\t            g = (g + 1.0) / 2.0\n\t            g = start + g * self.proportions[i]\n\t            g_list.append(g.to(device))\n\t            start += self.proportions[i] + h\n\t        self.curr_grid = 2.0 * torch.cat(g_list) - 1.0\n\t        return self.curr_grid\n\t    def size(self):\n\t        return sum([g.size() for g in self.grids])\n", "class GridND(IGrid):\n\t    \"\"\"N-dimensional grid, each dimension of which is an object of type IGrid.\"\"\"\n\t    def __init__(self, grid_objects):\n\t        super(GridND, self).__init__()\n\t        self.grid_objects = torch.nn.ModuleList(grid_objects)\n\t        self.generate_grid()\n\t    def ndim(self):\n\t        \"\"\"Returns dimensionality of grid object.\"\"\"\n\t        return sum([grid.ndim() for grid in self.grid_objects])\n\t    def reset_grid(self, dim, new_grid):\n", "        \"\"\"Replaces grid at given index.\"\"\"\n\t        self.grid_objects[dim] = new_grid\n\t        self.generate_grid()\n\t    def generate_grid(self):\n\t        self.curr_grid = [grid.generate_grid() for grid in self.grid_objects]\n\t        return self.curr_grid\n\t    def forward(self):\n\t        self.curr_grid = [grid() for grid in self.grid_objects]\n\t        return self.curr_grid\n\t    def __iter__(self):\n", "        return iter(self.grid_objects)\n"]}
{"filename": "torch_integral/quadrature.py", "chunked_list": ["import torch\n\tfrom scipy.special import roots_legendre\n\tclass BaseIntegrationQuadrature(torch.nn.Module):\n\t    \"\"\"\n\t    Base quadrature class.\n\t    Parameters\n\t    ----------\n\t    integration_dims: List[int].\n\t        Numbers of dimensions along which we multiply by the quadrature weights\n\t    grid_indices: List[int].\n", "        Indices of corresponding grids.\n\t    Attributes\n\t    ----------\n\t    integration_dims: List[int].\n\t    grid_indices: List[int].\n\t    \"\"\"\n\t    def __init__(self, integration_dims, grid_indices=None):\n\t        super().__init__()\n\t        self.integration_dims = integration_dims\n\t        if grid_indices is None:\n", "            self.grid_indices = integration_dims\n\t        else:\n\t            self.grid_indices = grid_indices\n\t            assert len(grid_indices) == len(integration_dims)\n\t    def multiply_coefficients(self, discretization, grid):\n\t        \"\"\"\n\t        Multiply discretization tensor by quadrature weights along integration_dims.\n\t        Parameters\n\t        ----------\n\t        discretization: torch.Tensor.\n", "            Tensor to be multiplied by quadrature weights.\n\t        grid: List[torch.Tensor].\n\t            List of tensors with sampling points.\n\t        Returns\n\t        -------\n\t        torch.Tensor.\n\t            ``discretization`` multiplied by quadrature weights.\n\t        \"\"\"\n\t        raise NotImplementedError(\"Implement this method in derived class.\")\n\t    def forward(self, function, grid):\n", "        \"\"\"\n\t        Performs forward pass of the Module.\n\t        Parameters\n\t        ----------\n\t        function: callable or torch.Tensor.\n\t            Function to be integrated.\n\t        grid: List[torch.Tensor].\n\t            List of tensors with sampling points.\n\t        Returns\n\t        -------\n", "        torch.Tensor.\n\t            ``function`` discretized and multiplied by quadrature weights.\n\t        \"\"\"\n\t        if callable(function):\n\t            out = function(grid)\n\t        else:\n\t            out = function\n\t        out = self.multiply_coefficients(out, grid)\n\t        return out\n\tclass TrapezoidalQuadrature(BaseIntegrationQuadrature):\n", "    \"\"\"Class for integration with trapezoidal rule.\"\"\"\n\t    def multiply_coefficients(self, discretization, grid):\n\t        \"\"\" \"\"\"\n\t        for i in range(len(self.integration_dims)):\n\t            grid_i = self.grid_indices[i]\n\t            dim = self.integration_dims[i]\n\t            x = grid[grid_i].to(discretization.device)\n\t            h = torch.zeros_like(x)\n\t            h[1:-1] = x[2:] - x[:-2]\n\t            h[0] = x[1] - x[0]\n", "            h[-1] = x[-1] - x[-2]\n\t            size = [1] * discretization.ndim\n\t            size[dim] = h.size(0)\n\t            h = h.view(size)\n\t            discretization = discretization * (h * 0.5)\n\t        return discretization\n\tclass RiemannQuadrature(BaseIntegrationQuadrature):\n\t    \"\"\"Rectangular integration rule.\"\"\"\n\t    def multiply_coefficients(self, discretization, grid):\n\t        \"\"\" \"\"\"\n", "        for i in range(len(self.integration_dims)):\n\t            grid_i = self.grid_indices[i]\n\t            dim = self.integration_dims[i]\n\t            x = grid[grid_i].to(discretization.device)\n\t            h = x[1:] - x[:-1]\n\t            h = torch.cat([0.5 * h[0], 0.5 * (h[:-1] + h[1:]), 0.5 * h[-1]])\n\t            size = [1] * discretization.ndim\n\t            size[dim] = h.size(0)\n\t            h = h.view(size)\n\t            discretization = discretization * h\n", "        return discretization\n\tclass SimpsonQuadrature(BaseIntegrationQuadrature):\n\t    \"\"\"\n\t    Integratioin of the function in propositioin\n\t    that function is quadratic between sampling points.\n\t    \"\"\"\n\t    def multiply_coefficients(self, discretization, grid):\n\t        \"\"\" \"\"\"\n\t        for i in range(len(self.integration_dims)):\n\t            grid_i = self.grid_indices[i]\n", "            dim = self.integration_dims[i]\n\t            x = grid[grid_i].to(discretization.device)\n\t            # assert x.shape[0] % 2 == 1\n\t            step = x[1] - x[0]\n\t            h = torch.ones_like(x)\n\t            h[1::2] *= 4.0\n\t            h[2:-1:2] *= 2.0\n\t            h *= step / 3.0\n\t            size = [1] * discretization.ndim\n\t            size[dim] = h.size(0)\n", "            h = h.view(size)\n\t            discretization = discretization * h\n\t        return discretization\n\tclass LegendreQuadrature(BaseIntegrationQuadrature):\n\t    \"\"\" \"\"\"\n\t    def multiply_coefficients(self, discretization, grid):\n\t        \"\"\" \"\"\"\n\t        for i in range(len(self.integration_dims)):\n\t            grid_i = self.grid_indices[i]\n\t            dim = self.integration_dims[i]\n", "            x = grid[grid_i].to(discretization.device)\n\t            _, weights = roots_legendre(x.shape[0])\n\t            h = torch.tensor(weights, dtype=torch.float32, device=discretization.device)\n\t            size = [1] * discretization.ndim\n\t            size[dim] = h.size(0)\n\t            h = h.view(size)\n\t            discretization = discretization * h\n\t        return discretization\n\tdef integrate(quadrature, function, grid):\n\t    \"\"\"\n", "    Function to integrate function with given quadrature rule.\n\t    Parameters\n\t    ----------\n\t    quadrature: BaseIntegrationQuadrature or callable or str.\n\t        Quadrature rule.\n\t    function: callable or torch.Tensor.\n\t        Function to be integrated.\n\t    grid: List[torch.Tensor].\n\t        List of tensors with sampling points.\n\t    Returns\n", "    -------\n\t    torch.Tensor.\n\t        Integral of ``function``.\n\t    \"\"\"\n\t    if callable(quadrature):\n\t        discretization = quadrature(function, grid)\n\t    elif type(quadrature) == str:\n\t        pass\n\t    out = torch.sum(discretization, quadrature.integration_dims)\n\t    return out\n"]}
{"filename": "torch_integral/graph/integral_group.py", "chunked_list": ["import torch\n\tfrom ..grid import RandomLinspace, UniformDistribution, CompositeGrid1D\n\tclass IntegralGroup(torch.nn.Module):\n\t    \"\"\"\n\t    Class for grouping tensors and parameters.\n\t    Group is a collection of paris of tensor and it's dimension.\n\t    Two parameter tensors are considered to be in the same group\n\t    if they should have the same integration grid.\n\t    Group can contain subgroups. This means that parent group's grid is a con\n\t    catenation of subgroups grids.\n", "    Parameters\n\t    ----------\n\t    size: int.\n\t        Each tensor in the group should have the same size along certain dimension.\n\t    \"\"\"\n\t    def __init__(self, size):\n\t        super(IntegralGroup, self).__init__()\n\t        self.size = size\n\t        self.subgroups = None\n\t        self.parents = []\n", "        self.grid = None\n\t        self.params = []\n\t        self.tensors = []\n\t        self.operations = []\n\t    def append_param(self, name, value, dim, operation=None):\n\t        \"\"\"\n\t        Adds parameter tensor to the group.\n\t        Parameters\n\t        ----------\n\t        name: str.\n", "        value: torch.Tensor.\n\t        dim: int.\n\t        operation: str.\n\t        \"\"\"\n\t        self.params.append(\n\t            {\"value\": value, \"name\": name, \"dim\": dim, \"operation\": operation}\n\t        )\n\t    def append_tensor(self, value, dim, operation=None):\n\t        \"\"\"\n\t        Adds tensor to the group.\n", "        Parameters\n\t        ----------\n\t        value: torch.Tensor.\n\t        dim: int.\n\t        operation: str.\n\t        \"\"\"\n\t        self.tensors.append({\"value\": value, \"dim\": dim, \"operation\": operation})\n\t    def clear_params(self):\n\t        self.params = []\n\t    def clear_tensors(self):\n", "        self.tensors = []\n\t    def set_subgroups(self, groups):\n\t        self.subgroups = groups\n\t        for subgroup in self.subgroups:\n\t            subgroup.parents.append(self)\n\t    def build_operations_set(self):\n\t        \"\"\"Builds set of operations in the group.\"\"\"\n\t        self.operations = set([t[\"operation\"] for t in self.tensors])\n\t    @staticmethod\n\t    def append_to_groups(tensor, operation=None, attr_name=\"grids\"):\n", "        if hasattr(tensor, attr_name):\n\t            for i, g in enumerate(getattr(tensor, attr_name)):\n\t                if g is not None:\n\t                    g.append_tensor(tensor, i, operation)\n\t    def grid_size(self):\n\t        \"\"\"Returns size of the grid.\"\"\"\n\t        return self.grid.size()\n\t    def clear(self, new_grid=None):\n\t        \"\"\"Resets grid and removes cached values.\"\"\"\n\t        for param_dict in self.params:\n", "            function = param_dict[\"function\"]\n\t            dim = list(function.grid).index(self.grid)\n\t            grid = new_grid if new_grid is not None else self.grid\n\t            function.grid.reset_grid(dim, grid)\n\t            function.clear()\n\t    def initialize_grids(self):\n\t        \"\"\"Sets default RandomLinspace grid.\"\"\"\n\t        if self.grid is None:\n\t            if self.subgroups is not None:\n\t                for subgroup in self.subgroups:\n", "                    if subgroup.grid is None:\n\t                        subgroup.initialize_grids()\n\t                self.grid = CompositeGrid1D([sub.grid for sub in self.subgroups])\n\t            else:\n\t                distrib = UniformDistribution(self.size, self.size)\n\t                self.grid = RandomLinspace(distrib)\n\t        for parent in self.parents:\n\t            if parent.grid is None:\n\t                parent.initialize_grids()\n\t    def reset_grid(self, new_grid):\n", "        \"\"\"\n\t        Set new integration grid for the group.\n\t        Parameters\n\t        ----------\n\t        new_grid: IntegralGrid.\n\t        \"\"\"\n\t        self.clear(new_grid)\n\t        for parent in self.parents:\n\t            parent.reset_child_grid(self, new_grid)\n\t        self.grid = new_grid\n", "    def reset_child_grid(self, child, new_grid):\n\t        \"\"\"Sets new integration grid for given child of the group.\"\"\"\n\t        i = self.subgroups.index(child)\n\t        self.grid.reset_grid(i, new_grid)\n\t        self.clear()\n\t    def resize(self, new_size):\n\t        \"\"\"If grid supports resizing, resizes it.\"\"\"\n\t        if hasattr(self.grid, \"resize\"):\n\t            self.grid.resize(new_size)\n\t        self.clear()\n", "        for parent in self.parents:\n\t            parent.clear()\n\t    def reset_distribution(self, distribution):\n\t        \"\"\"Sets new distribution for the group.\"\"\"\n\t        if hasattr(self.grid, \"distribution\"):\n\t            self.grid.distribution = distribution\n\t    def __str__(self):\n\t        result = \"\"\n\t        for p in self.params:\n\t            result += p[\"name\"] + \": \" + str(p[\"dim\"]) + \"\\n\"\n", "        return result\n\t    def count_parameters(self):\n\t        ans = 0\n\t        for p in self.params:\n\t            ans += p[\"value\"].numel()\n\t        return ans\n\tdef merge_groups(x, x_dim, y, y_dim):\n\t    \"\"\"Merges two groups of tensors ``x`` and `yy`` with indices ``x_dim`` and ``y_dim``.\"\"\"\n\t    if type(x) in (int, float):\n\t        x = torch.tensor(x)\n", "    if type(y) in (int, float):\n\t        y = torch.tensor(y)\n\t    if not hasattr(x, \"grids\"):\n\t        x.grids = [None for _ in range(x.ndim)]\n\t    if not hasattr(y, \"grids\"):\n\t        y.grids = [None for _ in range(y.ndim)]\n\t    if y.grids[y_dim] is not None:\n\t        x, x_dim, y, y_dim = y, y_dim, x, x_dim\n\t    if x.grids[x_dim] is not None:\n\t        if y.grids[y_dim] is not None:\n", "            if len(y.grids[y_dim].parents) > 0:\n\t                x, x_dim, y, y_dim = y, y_dim, x, x_dim\n\t            if y.grids[y_dim].subgroups is not None:\n\t                x, x_dim, y, y_dim = y, y_dim, x, x_dim\n\t            if x.grids[x_dim] is not y.grids[y_dim]:\n\t                for param in y.grids[y_dim].params:\n\t                    dim = param[\"dim\"]\n\t                    t = param[\"value\"]\n\t                    if t is not y:\n\t                        t.grids[dim] = x.grids[x_dim]\n", "                x.grids[x_dim].params.extend(y.grids[y_dim].params)\n\t                y.grids[y_dim].clear_params()\n\t                for tensor in y.grids[y_dim].tensors:\n\t                    dim = tensor[\"dim\"]\n\t                    t = tensor[\"value\"]\n\t                    if t is not y:\n\t                        t.grids[dim] = x.grids[x_dim]\n\t                x.grids[x_dim].tensors.extend(y.grids[y_dim].tensors)\n\t                y.grids[y_dim].clear_tensors()\n\t        y.grids[y_dim] = x.grids[x_dim]\n"]}
{"filename": "torch_integral/graph/operations.py", "chunked_list": ["import operator\n\timport torch\n\tfrom .integral_group import IntegralGroup\n\tfrom .integral_group import merge_groups\n\tfrom ..utils import get_attr_by_name\n\tdef transpose(inp, dim0, dim1):\n\t    out = torch.transpose(inp, dim0, dim1)\n\t    if hasattr(inp, \"grids\"):\n\t        out.grids = list(inp.grids)\n\t        out.grids[dim0], out.grids[dim1] = out.grids[dim1], out.grids[dim0]\n", "    IntegralGroup.append_to_groups(out, \"transpose\")\n\t    return out\n\tdef permute(inp, dims):\n\t    out = torch.permute(inp, dims)\n\t    if hasattr(inp, \"grids\"):\n\t        out.grids = [None] * inp.ndim\n\t        for i in range(len(dims)):\n\t            out.grids[i] = inp.grids[dims[i]]\n\t    IntegralGroup.append_to_groups(out, \"permute\")\n\t    return out\n", "def getitem(inp, slices):\n\t    out = operator.getitem(inp, slices)\n\t    out.grids = [None] * out.ndim\n\t    if hasattr(inp, \"grids\"):\n\t        j = 0\n\t        for i in range(inp.ndim):\n\t            if i < len(slices):  # ADD Ellipsis\n\t                if slices[i] == slice(None):\n\t                    out.grids[j] = inp.grids[i]\n\t                    j += 1\n", "    IntegralGroup.append_to_groups(out, \"getitem\")\n\t    return out\n\tdef neutral_hook(module, input, output):\n\t    if hasattr(input[0], \"grids\"):\n\t        output.grids = input[0].grids\n\t        IntegralGroup.append_to_groups(output, \"neutral\")\n\tdef neutral_decorator(call_func):\n\t    def wrapper(*args, **kwargs):\n\t        out = call_func(*args, **kwargs)\n\t        if hasattr(args[0], \"grids\"):\n", "            out.grids = args[0].grids\n\t            IntegralGroup.append_to_groups(out, \"neutral\")\n\t        return out\n\t    return wrapper\n\tdef conv_linear_decorator(function):\n\t    def conv_linear(*args):\n\t        x, weight, bias = args[:3]\n\t        out = function(*args)\n\t        if bias is not None:\n\t            merge_groups(bias, 0, weight, 0)\n", "        merge_groups(weight, 1, x, 1)\n\t        merge_groups(out, 1, weight, 0)\n\t        IntegralGroup.append_to_groups(out, \"conv_linear\")\n\t        return out\n\t    return conv_linear\n\tdef batch_norm(*args, **kwargs):\n\t    out = torch.nn.functional.batch_norm(*args, **kwargs)\n\t    inp = args[0]\n\t    weight = kwargs[\"weight\"]\n\t    bias = kwargs[\"bias\"]\n", "    merge_groups(inp, 1, weight, 0)\n\t    merge_groups(bias, 0, weight, 0)\n\t    merge_groups(out, 1, weight, 0)\n\t    IntegralGroup.append_to_groups(out, \"batch_norm\")\n\t    return out\n\tdef aggregation_decorator(func):\n\t    def wrapper(inp, *dims, **kwargs):\n\t        out = func(inp, *dims, **kwargs)\n\t        for d in range(out.ndim):\n\t            if d not in dims:\n", "                merge_groups(out, d, inp, d)\n\t        IntegralGroup.append_to_groups(out, \"aggregation\")\n\t        return out\n\t    return wrapper\n\tdef max_min_decorator(func):\n\t    def wrapper(inp, dim, **kwargs):\n\t        out = func(inp, dim, **kwargs)\n\t        values = out.values\n\t        for d in range(values.ndim):\n\t            if d != dim:\n", "                merge_groups(values, d, inp, d)\n\t        IntegralGroup.append_to_groups(values, \"min_max\")\n\t        return out\n\t    return wrapper\n\tdef view(*args, **kwargs):\n\t    inp = args[0]\n\t    out = inp.view(*args[1:])\n\t    out.grids = [None] * out.ndim\n\t    if hasattr(inp, \"grids\"):\n\t        i = 1\n", "        for g in inp.grids:\n\t            if g is not None:\n\t                while out.shape[i] != g.size:\n\t                    i += 1\n\t                out.grids[i] = g\n\t                i += 1\n\t        IntegralGroup.append_to_groups(out)\n\t    return out\n\tdef reshape(*args, **kwargs):\n\t    inp = args[0]\n", "    out = inp.reshape(*args[1:])\n\t    out.grids = [None] * out.ndim\n\t    if hasattr(inp, \"grids\"):\n\t        i = 1\n\t        for g in inp.grids:\n\t            if g is not None:\n\t                while out.shape[i] != g.size:\n\t                    i += 1\n\t                out.grids[i] = g\n\t                i += 1\n", "        IntegralGroup.append_to_groups(out)\n\t    return out\n\tdef concatenate(inputs, dim):\n\t    out = torch.cat(inputs, dim)\n\t    out.grids = [None] * out.ndim\n\t    for d in range(out.ndim):\n\t        if d != dim:\n\t            for x in inputs[1:]:\n\t                merge_groups(inputs[0], d, x, d)\n\t            out.grids[d] = inputs[0].grids[d]\n", "        else:\n\t            out.grids[d] = IntegralGroup(out.shape[d])\n\t            out.grids[d].set_subgroups([x.grids[d] for x in inputs])\n\t    IntegralGroup.append_to_groups(out, \"concat\")\n\t    return out\n\tdef operators_decorator(operator):\n\t    def wrapper(x, y):\n\t        out = operator(x, y)\n\t        if type(x) in (int, float):\n\t            x = torch.tensor(x)\n", "        if type(y) in (int, float):\n\t            y = torch.tensor(y)\n\t        if y.ndim > x.ndim:\n\t            x, y = y, x\n\t        k = x.ndim - y.ndim\n\t        for dim in range(y.ndim):\n\t            if x.shape[k + dim] != 1 and y.shape[dim] != 1:\n\t                merge_groups(x, k + dim, y, dim)\n\t        out.grids = x.grids\n\t        for dim in range(out.ndim):\n", "            if out.grids[dim] is None:\n\t                if dim - k >= 0 and y.shape[dim - k] > 1:\n\t                    out.grids[dim] = y.grids[dim - k]\n\t            if out.shape[dim] == 1:\n\t                out.grids[dim] = None\n\t        IntegralGroup.append_to_groups(out, \"operator\")\n\t        return out\n\t    return wrapper\n\tdef matmul(x, y):\n\t    out = x @ y\n", "    out.grids = [None] * out.ndim\n\t    if y.ndim > x.ndim:\n\t        y, x = x, y\n\t    k = x.ndim - y.ndim\n\t    merge_groups(y, y.ndim - 2, x, x.ndim - 1)\n\t    for i in range(y.ndim - 2):\n\t        merge_groups(x, i + k, y, i)\n\t    for d in range(x.ndim - 1):\n\t        out.grids.append(x.grids[d])\n\t    out.grids.append(y.grids[y.ndim - 1])\n", "    IntegralGroup.append_to_groups(out, \"matmul\")\n\t    return out\n\tdef interpolate(*args, **kwargs):\n\t    out = torch.nn.functional.interpolate(*args, **kwargs)\n\t    out.grids = [None] * out.ndim\n\t    if hasattr(args[0], \"grids\"):\n\t        for d in range(out.ndim):\n\t            out.grids[d] = args[0].grids[d]\n\t    IntegralGroup.append_to_groups(out, \"interpolate\")\n\t    return out\n", "# def einsum(equation, *args):\n\t#     out = torch.einsum(equation, *args)\n\t#     inp_str, out_str = equation.split('->')\n\t#     tensors = inp_str.split(',')\n\t#\n\t#     return out\n"]}
{"filename": "torch_integral/graph/__init__.py", "chunked_list": ["from .trace import IntegralTracer\n"]}
{"filename": "torch_integral/graph/trace.py", "chunked_list": ["import torch\n\tfrom .operations import *\n\tfrom .integral_group import IntegralGroup\n\tfrom ..utils import remove_all_hooks\n\tclass SymbolicFxTracer(torch.fx.Tracer):\n\t    \"\"\"torch.fx.Tracer which leaf modules are batch norm layers.\"\"\"\n\t    def is_leaf_module(self, m, qualname):\n\t        return isinstance(\n\t            m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)\n\t        )\n", "class IntegralTracer(torch.fx.Interpreter):\n\t    \"\"\"\n\t    Class for building dependency graph of the neural network.\n\t    Builds related groups of parameter tensors.\n\t    Related group is a set of pairs of tensor and dimensioin.\n\t    Two parameters belong to one related group\n\t    if they should have the same size along the corresponding dimension.\n\t    Parameters\n\t    ----------\n\t    model: torch.nn.Module.\n", "    continuous_dims: Dict[str, List[int]].\n\t        Dictionary which contains names of the model's parameters\n\t        and it's continuous dimension indices.\n\t    discrete_dims: Dict[str, List[int]].\n\t        Dictionary which contains names of the model's parameters\n\t        and dimensions that can not be continuous.\n\t        If there is the same element in discrete_dims and continuous_dims, then\n\t        the element will be removed from continuous_dims.\n\t    additional_operations: Dict[Union[str, Callable], Callable].\n\t        Dictionary which contains custom tracing operations for the graph.\n", "    additional_hooks: Dict[torch.nn.Module, Callable].\n\t        Dictionary which contains custom hooks for the graph.\n\t    Examples\n\t    --------\n\t    For example, if we have a model with two convolutional layers\n\t    and we want to make continuous only first convolutional layer's\n\t    output dimension then we can write:\n\t    .. code-block:: python\n\t        import torch\n\t        from torch_integral.graph import IntegralTracer\n", "        from torchvision.models import resnet18\n\t        model = resnet18(pretrained=True)\n\t        example_input = torch.randn(1, 3, 224, 224)\n\t        continuous_dims = {\n\t            \"layer4.0.conv1.weight\": [0],\n\t            \"layer4.0.conv1.bias\": [0],\n\t        }\n\t        IntegralTracer = IntegralTracer(model, example_input, continuous_dims)\n\t    Here  first dimension of the `layer4.0.conv1.weight`, `layer4.0.conv1.bias` and second dim\n\t    of the `conv_2.weight` are belong to the same IntegralGroup,\n", "    because it's sizes should be equal.\n\t    Note that it is not necessary to list all parameter names of the related group.\n\t    It is enough to list only one tensor of the group and all other tensors will be\n\t    added automatically. For example, in example above it was enough to write\n\t    `continuous_dims = {layer4.0.conv1.weight: [0]}`.\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        model,\n\t        continuous_dims,\n", "        discrete_dims=None,\n\t        additional_operations=None,\n\t        additional_hooks=None,\n\t    ):\n\t        graph = SymbolicFxTracer().trace(model.eval())\n\t        gm = torch.fx.GraphModule(model, graph)\n\t        super().__init__(gm, True)\n\t        self.model = model\n\t        self.groups = None\n\t        self.continuous_dims = continuous_dims\n", "        if discrete_dims is not None:\n\t            self.discrete_dims = discrete_dims\n\t        else:\n\t            self.discrete_dims = {}\n\t        self.default_operations = {\n\t            operator.add: operators_decorator(operator.add),\n\t            operator.sub: operators_decorator(operator.sub),\n\t            operator.mul: operators_decorator(operator.mul),\n\t            operator.getitem: getitem,\n\t            torch.permute: permute,\n", "            torch.transpose: transpose,\n\t            torch.matmul: matmul,\n\t            torch.nn.functional.interpolate: interpolate,\n\t            torch.mean: aggregation_decorator(torch.mean),\n\t            torch.sum: aggregation_decorator(torch.sum),\n\t            torch.max: max_min_decorator(torch.max),\n\t            torch.min: max_min_decorator(torch.min),\n\t            torch.cat: concatenate,\n\t            torch.conv1d: conv_linear_decorator(torch.conv1d),\n\t            torch.conv2d: conv_linear_decorator(torch.conv2d),\n", "            torch.conv3d: conv_linear_decorator(torch.conv3d),\n\t            torch._C._nn.linear: conv_linear_decorator(torch._C._nn.linear),\n\t            torch.nn.functional.batch_norm: batch_norm,\n\t            \"mean\": aggregation_decorator(torch.mean),\n\t            \"sum\": aggregation_decorator(torch.sum),\n\t            \"view\": view,\n\t            \"reshape\": reshape,\n\t            \"mul\": operators_decorator(operator.mul),\n\t            \"add\": operators_decorator(operator.add),\n\t        }\n", "        self.default_hooks = {\n\t            torch.nn.BatchNorm1d: neutral_hook,\n\t            torch.nn.BatchNorm2d: neutral_hook,\n\t            torch.nn.BatchNorm3d: neutral_hook,\n\t            torch.nn.Identity: neutral_hook,\n\t        }\n\t        if additional_operations is not None:\n\t            self.default_operations.update(additional_operations)\n\t        if additional_hooks is not None:\n\t            self.default_hooks.update(additional_hooks)\n", "    def build_groups(self, *args, initial_env=None, enable_io_processing=True):\n\t        \"\"\"\n\t        Builds dependency groups of the neural network.\n\t        Parameters\n\t        ----------\n\t        *args: List[torch.Tensor] or List[List[int]].\n\t            Input tensors of the model or shapes of input tensors.\n\t        initial_env: Dict[str, torch.Tensor].\n\t        enable_io_processing: bool.\n\t            If True, then input and output tensors will be processed.\n", "        Returns\n\t        -------\n\t        self.groups: List[IntegralGroup].\n\t            List of related parameters groups.\n\t        \"\"\"\n\t        self.groups = []\n\t        self.model.eval()\n\t        for name, param in self.model.named_parameters():\n\t            param.grids = [None] * param.ndim\n\t            if name in self.continuous_dims:\n", "                dims = self.continuous_dims[name]\n\t            else:\n\t                dims = list(range(param.ndim))\n\t            for dim in dims:\n\t                size = param.shape[dim]\n\t                group = IntegralGroup(size)\n\t                group.append_param(name, param, dim)\n\t                param.grids[dim] = group\n\t                self.groups.append(group)\n\t        device = next(iter(self.model.parameters())).device\n", "        args = list(args)\n\t        for i in range(len(args)):\n\t            if type(args[i]) == torch.Tensor:\n\t                args[i] = args[i].to(device)\n\t            else:\n\t                args[i] = torch.rand(args[i]).to(device)\n\t        output = self.run(*args, initial_env, enable_io_processing)\n\t        remove_all_hooks(self.model)\n\t        self.groups = [group for group in self.groups if len(group.params)]\n\t        delete_indices = []\n", "        for i, group in enumerate(self.groups):\n\t            delete_group = True\n\t            for p in group.params:\n\t                if (\n\t                    p[\"name\"] in self.continuous_dims\n\t                    and p[\"dim\"] in self.continuous_dims[p[\"name\"]]\n\t                ):\n\t                    delete_group = False\n\t                if (\n\t                    p[\"name\"] in self.discrete_dims\n", "                    and p[\"dim\"] in self.discrete_dims[p[\"name\"]]\n\t                ):\n\t                    for d in group.params:\n\t                        if (\n\t                            d[\"name\"] in self.continuous_dims\n\t                            and d[\"dim\"] in self.continuous_dims[d[\"name\"]]\n\t                        ):\n\t                            self.continuous_dims[d[\"name\"]].remove(d[\"dim\"])\n\t                            if len(self.continuous_dims[d[\"name\"]]) == 0:\n\t                                self.continuous_dims.pop(d[\"name\"])\n", "                    delete_group = True\n\t                    break\n\t            if delete_group:\n\t                delete_indices.append(i)\n\t            else:\n\t                for p in group.params:\n\t                    if p[\"name\"] in self.continuous_dims:\n\t                        dims = self.continuous_dims[p[\"name\"]]\n\t                        if p[\"dim\"] not in dims:\n\t                            dims.append(p[\"dim\"])\n", "                    else:\n\t                        self.continuous_dims[p[\"name\"]] = [p[\"dim\"]]\n\t        self.groups = [\n\t            group for i, group in enumerate(self.groups) if i not in delete_indices\n\t        ]\n\t        def add_parent_groups(group, parents):\n\t            for parent in group.parents:\n\t                if parent not in parents:\n\t                    parents.add(parent)\n\t                add_parent_groups(parent, parents)\n", "        parents = set()\n\t        for group in self.groups:\n\t            add_parent_groups(group, parents)\n\t            group.build_operations_set()\n\t        for parent in parents:\n\t            parent.build_operations_set()\n\t        self.groups.extend(list(parents))\n\t        return self.groups\n\t    def call_function(self, target, args, kwargs):\n\t        \"\"\"\n", "        Instead of usual call_function method,\n\t        this method calls decorated function to build dependency graph.\n\t        Parameters\n\t        ----------\n\t        target: Callable.\n\t            Function to call.\n\t        args: List[torch.Tensor].\n\t            Arguments of the function.\n\t        kwargs: Dict[str, torch.Tensor].\n\t            Keyword arguments of the function.\n", "        Returns\n\t        -------\n\t        result: torch.Tensor.\n\t            Result of the function.\n\t        \"\"\"\n\t        if target in self.default_operations:\n\t            return self.default_operations[target](*args, **kwargs)\n\t        else:\n\t            return neutral_decorator(target)(*args, **kwargs)\n\t    def call_method(self, target, args, kwargs):\n", "        \"\"\"\n\t        Instead of usual call_method method,\n\t        this method calls decorated function to build dependency graph.\n\t        Parameters\n\t        ----------\n\t        target: Callable.\n\t            Method to call.\n\t        args: List[torch.Tensor].\n\t            Arguments of the method.\n\t        kwargs: Dict[str, torch.Tensor].\n", "            Keyword arguments of the method.\n\t        Returns\n\t        -------\n\t        result: torch.Tensor.\n\t            Result of the method.\n\t        \"\"\"\n\t        if target in self.default_operations:\n\t            return self.default_operations[target](*args, **kwargs)\n\t        else:\n\t            return super().call_method(target, args, kwargs)\n", "    def call_module(self, target, args, kwargs):\n\t        \"\"\"\n\t        Registers tracing forward hooks before calling submodules.\n\t        Parameters\n\t        ----------\n\t        target: Callable.\n\t            Submodule to call.\n\t        args: List[torch.Tensor].\n\t            Arguments of the submodule.\n\t        kwargs: Dict[str, torch.Tensor].\n", "            Keyword arguments of the submodule.\n\t        Returns\n\t        -------\n\t        result: torch.Tensor.\n\t            Result of the submodule.\n\t        \"\"\"\n\t        submod = self.fetch_attr(target)\n\t        if type(submod) in self.default_hooks:\n\t            submod.register_forward_hook(self.default_hooks[type(submod)])\n\t        return submod(*args, **kwargs)\n"]}
{"filename": "torch_integral/tsp_solver/__init__.py", "chunked_list": ["from .solver import two_opt_find_permutation\n"]}
{"filename": "torch_integral/parametrizations/integral_weight.py", "chunked_list": ["import torch\n\tclass IntegralParameterization(torch.nn.Module):\n\t    \"\"\"\n\t    Class for weights parametrization. Can be registereg as parametrization\n\t    with torch.nn.utils.parametrize.register_parametrization\n\t    Parameters\n\t    ----------\n\t    weight_function: torch.nn.Module.\n\t    grid: torch_integral.grid.IGrid.\n\t    quadrature: torch_integral.quadrature.BaseIntegrationQuadrature.\n", "    \"\"\"\n\t    def __init__(self, weight_function, grid, quadrature):\n\t        super().__init__()\n\t        self.weight_function = weight_function\n\t        self.quadrature = quadrature\n\t        self.grid = grid\n\t        self.last_value = None\n\t        self.train_volume = 1.0\n\t    def sample_weights(self, w):\n\t        \"\"\"\n", "        Evaluate pparametrization function on grid.\n\t        Parameters\n\t        ----------\n\t        w: torch.Tensor.\n\t        Returns\n\t        -------\n\t        torch.Tensor.\n\t            Sampled weight function on grid.\n\t        \"\"\"\n\t        x = self.grid()\n", "        weight = self.weight_function(x)\n\t        if self.quadrature is not None:\n\t            weight = self.quadrature(weight, x) * self.train_volume\n\t        return weight\n\t    def reset_quadrature(self, quadrature):\n\t        \"\"\"Replaces quadrature object.\"\"\"\n\t        weight = self.sample_weights(None)\n\t        self.quadrature = quadrature\n\t        self.right_inverse(weight)\n\t    def clear(self):\n", "        self.last_value = None\n\t    def forward(self, w):\n\t        \"\"\"\n\t        Performs forward pass. Samples new weights on grid\n\t        if training or last sampled tensor is not cached.\n\t        Parameters\n\t        ----------\n\t        w: torch.Tensor.\n\t        \"\"\"\n\t        if self.training or self.last_value is None:\n", "            weight = self.sample_weights(w)\n\t            if self.training:\n\t                self.clear()\n\t            else:\n\t                self.last_value = weight\n\t        else:\n\t            weight = self.last_value\n\t        return weight.to(w.device)\n\t    def right_inverse(self, x):\n\t        \"\"\"Initialization method which is used when setattr of parametrized tensor called.\"\"\"\n", "        if hasattr(self.weight_function, \"init_values\"):\n\t            if self.quadrature is not None:\n\t                ones = torch.ones_like(x, device=x.device)\n\t                q_coeffs = self.quadrature.multiply_coefficients(ones, self.grid())\n\t                x = x / q_coeffs\n\t                for dim in self.quadrature.integration_dims:\n\t                    self.train_volume *= x.shape[dim] - 1\n\t                self.train_volume *= 0.5\n\t                x = x / self.train_volume\n\t            self.weight_function.init_values(x)\n", "        return x\n\tif __name__ == \"__main__\":\n\t    import torch\n\t    import sys\n\t    sys.path.append(\"../../\")\n\t    from interpolation_weights import InterpolationWeights1D\n\t    from interpolation_weights import InterpolationWeights2D\n\t    from torch_integral.grid import RandomUniformGrid1D\n\t    from torch_integral.grid import ConstantGrid1D\n\t    from torch_integral.grid import GridND\n", "    from torch_integral.grid import UniformDistribution\n\t    from torch.nn.utils import parametrize\n\t    from torch_integral.quadrature import TrapezoidalQuadrature\n\t    from torch_integral import IntegralWrapper\n\t    N = 64\n\t    func = InterpolationWeights2D([64, 64], [5, 5]).cuda()\n\t    conv = torch.nn.Conv2d(64, 64, 5).cuda()\n\t    target = conv.weight.data.clone()\n\t    grid = GridND(\n\t        {\n", "            # '0': ConstantGrid1D((torch.rand(64)*2-1).sort().values),\n\t            \"0\": RandomUniformGrid1D(UniformDistribution(64, 64)),\n\t            \"1\": RandomUniformGrid1D(UniformDistribution(64, 64)),\n\t        }\n\t    )\n\t    quadrature = TrapezoidalQuadrature([1])\n\t    param = IntegralParameterization(\n\t        func,\n\t        grid,\n\t        quadrature,\n", "    )\n\t    parametrize.register_parametrization(conv, \"weight\", param, unsafe=True)\n\t    wrapper = IntegralWrapper(optimize_iters=3000, start_lr=1e-2)\n\t    wrapper._optimize_parameters(conv, \"weight\", target, param.parameters())\n"]}
{"filename": "torch_integral/parametrizations/__init__.py", "chunked_list": ["from .interpolation_weights import InterpolationWeights1D\n\tfrom .interpolation_weights import InterpolationWeights2D\n\tfrom .integral_weight import IntegralParameterization\n"]}
{"filename": "torch_integral/parametrizations/interpolation_weights.py", "chunked_list": ["import torch\n\tfrom functools import reduce\n\tfrom torch.nn.functional import grid_sample, interpolate\n\tclass IWeights(torch.nn.Module):\n\t    \"\"\"\n\t    Base weight parametrization class.\n\t    Parameters\n\t    ----------\n\t    discrete_shape: List[int].\n\t        Sizes of parametrized tensor along discrete dimension.\n", "    \"\"\"\n\t    def __init__(self, discrete_shape):\n\t        super().__init__()\n\t        self._discrete_shape = discrete_shape\n\t    def init_values(self):\n\t        \"\"\" \"\"\"\n\t        raise NotImplementedError(\"Implement this method in derived class.\")\n\t    def forward(self, grid):\n\t        \"\"\"\n\t        Performs forward pass\n", "        Parameters\n\t        ----------\n\t        grid: List[torch.Tensor].\n\t            List of discretization grids along each dimension.\n\t        \"\"\"\n\t        raise NotImplementedError(\"Implement this method in derived class.\")\n\tclass InterpolationWeightsBase(IWeights):\n\t    \"\"\"\n\t    Base class for parametrization based on torch.nn.functional.grid_sample.\n\t    Parameters\n", "    ----------\n\t    cont_size: List[int].\n\t        Shape of trainable parameter along continuous dimensions.\n\t    discrete_shape: List[int].\n\t        Sizes of parametrized tensor along discrete dimension.\n\t    interpolate_mode: str.\n\t        Same modes as in torch.nn.functional.grid_sample.\n\t    padding_mode: str.\n\t    align_corners: bool.\n\t    \"\"\"\n", "    def __init__(\n\t        self,\n\t        cont_size,\n\t        discrete_shape=None,\n\t        interpolate_mode=\"bicubic\",\n\t        padding_mode=\"border\",\n\t        align_corners=True,\n\t    ):\n\t        super(InterpolationWeightsBase, self).__init__(discrete_shape)\n\t        self.iterpolate_mode = interpolate_mode\n", "        self.padding_mode = padding_mode\n\t        self.align_corners = align_corners\n\t        if discrete_shape is not None:\n\t            self.planes_num = int(reduce(lambda a, b: a * b, discrete_shape))\n\t        else:\n\t            self.planes_num = 1\n\t        self.values = torch.nn.Parameter(torch.rand(1, self.planes_num, *cont_size))\n\t    def _preprocess_grid(self, grid):\n\t        \"\"\" \"\"\"\n\t        device = self.values.device\n", "        for i in range(len(grid)):\n\t            grid[i] = grid[i].to(device)\n\t        if len(grid) == 1:\n\t            grid.append(torch.tensor(0.0, device=device))\n\t        grid = torch.stack(\n\t            torch.meshgrid(grid[::-1], indexing=\"ij\"),\n\t            dim=len(grid),\n\t        ).unsqueeze(0)\n\t        return grid\n\t    def _postprocess_output(self, out):\n", "        \"\"\" \"\"\"\n\t        raise NotImplementedError(\"Implement this method in derived class.\")\n\t    def forward(self, grid):\n\t        \"\"\"\n\t        Performs forward pass\n\t        Parameters\n\t        ----------\n\t        grid: List[torch.Tensor].\n\t            List of discretization grids along each dimension.\n\t        Returns\n", "        -------\n\t        torch.Tensor.\n\t            Sampled ``self.values`` on grid.\n\t        \"\"\"\n\t        grid = self._preprocess_grid(grid)\n\t        out = grid_sample(\n\t            self.values,\n\t            grid,\n\t            mode=self.iterpolate_mode,\n\t            padding_mode=self.padding_mode,\n", "            align_corners=self.align_corners,\n\t        )\n\t        return self._postprocess_output(out)\n\tclass InterpolationWeights1D(InterpolationWeightsBase):\n\t    \"\"\"\n\t    Class implementing InterpolationWeightsBase for parametrization\n\t    of tensor with one continuous dimension.\n\t    Parameters\n\t    ----------\n\t    cont_size: List[int].\n", "        Shape of trainable parameter along continuous dimensions.\n\t    discrete_shape: List[int].\n\t        Sizes of parametrized tensor along discrete dimension.\n\t    cont_dim: int.\n\t        Index of continuous dimension.\n\t    interpolate_mode: str.\n\t        See torch.nn.functional.grid_sample.\n\t    padding_mode: str.\n\t        See torch.nn.functional.grid_sample.\n\t    align_corners: bool.\n", "        See torch.nn.functional.grid_sample.\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        cont_size,\n\t        discrete_shape=None,\n\t        cont_dim=0,\n\t        interpolate_mode=\"bicubic\",\n\t        padding_mode=\"border\",\n\t        align_corners=True,\n", "    ):\n\t        super(InterpolationWeights1D, self).__init__(\n\t            [cont_size, 1],\n\t            discrete_shape,\n\t            interpolate_mode,\n\t            padding_mode,\n\t            align_corners,\n\t        )\n\t        self.cont_dim = cont_dim\n\t    def init_values(self, x):\n", "        \"\"\" \"\"\"\n\t        if x.ndim == 1:\n\t            x = x[None, None, :, None]\n\t        else:\n\t            permutation = [i for i in range(x.ndim) if i != self.cont_dim]\n\t            x = x.permute(*permutation, self.cont_dim)\n\t            x = x.reshape(1, -1, x.shape[-1], 1)\n\t        if x.shape[-2:] == self.values.shape[-2:]:\n\t            self.values.data = x\n\t        else:\n", "            self.values.data = interpolate(\n\t                x, self.values.shape[-2:], mode=self.iterpolate_mode\n\t            )\n\t    def _postprocess_output(self, out):\n\t        \"\"\" \"\"\"\n\t        discrete_shape = self._discrete_shape\n\t        if discrete_shape is None:\n\t            discrete_shape = []\n\t        shape = out.shape[-1:]\n\t        out = out.view(*discrete_shape, *shape)\n", "        permutation = list(range(out.ndim))\n\t        permutation[self.cont_dim] = out.ndim - 1\n\t        j = 0\n\t        for i in range(len(permutation)):\n\t            if i != self.cont_dim:\n\t                permutation[i] = j\n\t                j += 1\n\t        out = out.permute(*permutation).contiguous()\n\t        return out\n\tclass InterpolationWeights2D(InterpolationWeightsBase):\n", "    \"\"\"\n\t    Class implementing InterpolationWeightsBase for parametrization\n\t    of tensor with two continuous dimensions.\n\t    Parameters\n\t    ----------\n\t    cont_size: List[int].\n\t        Shape of trainable parameter along continuous dimensions.\n\t    discrete_shape: List[int].\n\t        Sizes of parametrized tensor along discrete dimension.\n\t    interpolate_mode: str.\n", "        See torch.nn.functional.grid_sample.\n\t    padding_mode: str.\n\t        See torch.nn.functional.grid_sample.\n\t    align_corners: bool.\n\t        See torch.nn.functional.grid_sample.\n\t    \"\"\"\n\t    def init_values(self, x):\n\t        \"\"\" \"\"\"\n\t        if x.ndim == 2:\n\t            x = x[None, None, :, :]\n", "        else:\n\t            permutation = list(range(2, x.ndim))\n\t            shape = x.shape[:2]\n\t            x = x.permute(*permutation, 0, 1)\n\t            x = x.reshape(1, -1, *shape)\n\t        if x.shape[-2:] == self.values.shape[-2:]:\n\t            self.values.data = x\n\t        else:\n\t            self.values.data = interpolate(\n\t                x, self.values.shape[-2:], mode=self.iterpolate_mode\n", "            )\n\t    def _postprocess_output(self, out):\n\t        discrete_shape = self._discrete_shape\n\t        if discrete_shape is None:\n\t            discrete_shape = []\n\t        shape = out.shape[-2:]\n\t        out = out.view(*discrete_shape, *shape)\n\t        dims = range(out.ndim - 2)\n\t        out = out.permute(out.ndim - 1, out.ndim - 2, *dims)\n\t        return out.contiguous()\n"]}
{"filename": "examples/sr/edsr.py", "chunked_list": ["import argparse\n\timport torch\n\tfrom super_image import EdsrModel, ImageLoader\n\tfrom super_image.data import EvalDataset, TrainDataset, augment_five_crop\n\tfrom super_image import Trainer, TrainingArguments\n\tfrom datasets import load_dataset\n\timport torch_integral as inn\n\tfrom torch_integral.permutation import NOptOutFiltersPermutation\n\tfrom torch_integral.utils import standard_continuous_dims\n\tfrom PIL import Image\n", "import requests\n\tparser = argparse.ArgumentParser(description=\"INN EDSR\")\n\tparser.add_argument(\n\t    \"--checkpoint\", default=None, help=\"path to model checkpoint (default: None)\"\n\t)\n\tparser.add_argument(\n\t    \"-e\",\n\t    \"--evaluate\",\n\t    dest=\"evaluate\",\n\t    action=\"store_true\",\n", "    help=\"evaluate model on validation set\",\n\t)\n\tparser.add_argument(\n\t    \"--integral\", action=\"store_true\", help=\"use integral neural network\"\n\t)\n\tparser.add_argument(\n\t    \"--grid-tuning\",\n\t    action=\"store_true\",\n\t    help=\"tune only grid of integral neural network\",\n\t)\n", "parser.add_argument(\n\t    \"--resample\", action=\"store_true\", help=\"prune integral neural network\"\n\t)\n\tparser.add_argument(\n\t    \"--scale\", default=4, type=int, help=\"super resolution scale (default: 4)\"\n\t)\n\tparser.add_argument(\"-b\", \"--batch-size\", default=32, type=int, metavar=\"N\")\n\tparser.add_argument(\"-w\", \"--workers\", default=48, type=int)\n\tparser.add_argument(\n\t    \"--epochs\", default=400, type=int, metavar=\"N\", help=\"number of total epochs to run\"\n", ")\n\targs = parser.parse_args()\n\t# DATA\n\taugmented_dataset = load_dataset(\n\t    \"eugenesiow/Div2k\", f\"bicubic_x{args.scale}\", split=\"train\"\n\t).map(augment_five_crop, batched=True, desc=\"Augmenting Dataset\")\n\ttrain_dataset = TrainDataset(augmented_dataset)\n\teval_dataset = EvalDataset(\n\t    load_dataset(\"eugenesiow/Div2k\", f\"bicubic_x{args.scale}\", split=\"validation\")\n\t)\n", "# MODEL\n\tmodel = EdsrModel.from_pretrained(\"eugenesiow/edsr\", scale=args.scale).cuda()\n\tif args.integral:\n\t    continuous_dims = standard_continuous_dims(model)\n\t    discrete_dims = {\n\t        \"sub_mean.weight\": [0, 1],\n\t        \"add_mean.weight\": [0, 1],\n\t        \"head.0.weight\": [1],\n\t        \"tail.0.0.weight\": [0],\n\t        \"tail.0.2.weight\": [0, 1],\n", "        \"tail.1.weight\": [0, 1],\n\t    }\n\t    example_input = [1, 3, 32, 32]\n\t    model = inn.IntegralWrapper(\n\t        init_from_discrete=(args.checkpoint is None),\n\t        permutation_config={\"class\": NOptOutFiltersPermutation},\n\t    )(model, example_input, continuous_dims, discrete_dims).cuda()\n\t    # RESAMPLE\n\t    for i, group in enumerate(model.groups):\n\t        if \"operator\" not in group.operations:\n", "            size = 100 if i > 3 else 256\n\t        else:\n\t            size = 200\n\t        group.reset_distribution(inn.UniformDistribution(size, 256))\n\t        new_size = size if args.resample else 256\n\t        if args.grid_tuning:\n\t            group.reset_grid(inn.TrainableGrid1D(new_size))\n\t        elif args.resample:\n\t            group.resize(new_size)\n\tif args.checkpoint is not None:\n", "    model.load_state_dict(torch.load(args.checkpoint))\n\tif args.integral:\n\t    print(\"Compression: \", model.eval().calculate_compression())\n\t# TRAIN\n\ttraining_args = TrainingArguments(\n\t    output_dir=\"./results\",\n\t    num_train_epochs=args.epochs,\n\t    learning_rate=1e-4,\n\t    per_device_train_batch_size=args.batch_size,\n\t    dataloader_num_workers=args.workers,\n", "    dataloader_pin_memory=True,\n\t)\n\ttrainer = Trainer(\n\t    model=model,\n\t    args=training_args,\n\t    train_dataset=train_dataset,\n\t    eval_dataset=eval_dataset,\n\t)\n\tif args.integral and args.grid_tuning:\n\t    model.grid_tuning(False, True, False)\n", "if not args.evaluate:\n\t    trainer.train()\n\t# EVAL\n\ttrainer.eval(1)\n\turl = 'http://people.rennes.inria.fr/Aline.Roumy/results/images_SR_BMVC12/input_groundtruth/butterfly_mini_d4_gaussian.bmp'\n\timage = Image.open(requests.get(url, stream=True).raw)\n\tinputs = ImageLoader.load_image(image).cuda()\n\tpreds = model(inputs)\n\tImageLoader.save_image(preds, f'scaled_{args.scale}x.png')\n\tImageLoader.save_compare(inputs, preds, f'scaled_{args.scale}x_compare.png')\n"]}
{"filename": "examples/classification/mnist.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torchvision\n\timport torchvision.transforms as transforms\n\tfrom catalyst import dl\n\timport sys\n\timport os\n\tfrom torch_integral import IntegralWrapper\n\tfrom torch_integral import UniformDistribution\n\tfrom torch_integral import standard_continuous_dims\n", "class MnistNet(nn.Module):\n\t    def __init__(self):\n\t        super().__init__()\n\t        self.conv_1 = nn.Conv2d(\n\t            1, 16, 3, padding=1, bias=True, padding_mode=\"replicate\"\n\t        )\n\t        self.conv_2 = nn.Conv2d(\n\t            16, 32, 5, padding=2, bias=True, padding_mode=\"replicate\"\n\t        )\n\t        self.conv_3 = nn.Conv2d(\n", "            32, 64, 5, padding=2, bias=True, padding_mode=\"replicate\"\n\t        )\n\t        self.f_1 = nn.ReLU()\n\t        self.f_2 = nn.ReLU()\n\t        self.f_3 = nn.ReLU()\n\t        self.pool = nn.AvgPool2d(2, 2)\n\t        self.linear = nn.Linear(64, 10)\n\t    def forward(self, x):\n\t        x = self.f_1(self.conv_1(x))\n\t        x = self.pool(x)\n", "        x = self.f_2(self.conv_2(x))\n\t        x = self.pool(x)\n\t        x = self.f_3(self.conv_3(x))\n\t        x = self.pool(x)\n\t        x = self.linear(x[:, :, 0, 0])\n\t        return x\n\t# ------------------------------------------------------------------------------------\n\t# Data\n\t# ------------------------------------------------------------------------------------\n\tbatch_size = 128\n", "transform = transforms.Compose(\n\t    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n\t)\n\troot = os.path.expanduser(\"~\")\n\ttrain_dataset = torchvision.datasets.MNIST(\n\t    root=root, train=True, download=True, transform=transform\n\t)\n\ttrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n\tval_dataset = torchvision.datasets.MNIST(\n\t    root=root, train=False, download=True, transform=transform\n", ")\n\tval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False)\n\tloaders = {\"train\": train_dataloader, \"valid\": val_dataloader}\n\t# ------------------------------------------------------------------------------------\n\t# Model\n\t# ------------------------------------------------------------------------------------\n\tmodel = MnistNet().cuda()\n\tcontinuous_dims = standard_continuous_dims(model)\n\tcontinuous_dims.update({\"linear.weight\": [1], \"linear.bias\": [], \"conv_1.weight\": [0]})\n\twrapper = IntegralWrapper(init_from_discrete=True)\n", "model = wrapper(model, [1, 1, 28, 28], continuous_dims)\n\tranges = [[16, 16], [32, 64], [16, 32]]\n\tmodel.reset_distributions([UniformDistribution(*r) for r in ranges])\n\t# ------------------------------------------------------------------------------------\n\t# Train\n\t# ------------------------------------------------------------------------------------\n\topt = torch.optim.Adam(\n\t    model.parameters(),\n\t    lr=2e-3,\n\t)\n", "loader_len = len(train_dataloader)\n\tsched = torch.optim.lr_scheduler.MultiStepLR(\n\t    opt, [loader_len * 3, loader_len * 5, loader_len * 7, loader_len * 9], gamma=0.5\n\t)\n\tcross_entropy = nn.CrossEntropyLoss()\n\tlog_dir = \"./logs/mnist\"\n\trunner = dl.SupervisedRunner(\n\t    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n\t)\n\tcallbacks = [\n", "    dl.AccuracyCallback(\n\t        input_key=\"logits\", target_key=\"targets\", topk=(1,), num_classes=10\n\t    ),\n\t    dl.SchedulerCallback(mode=\"batch\", loader_key=\"train\", metric_key=\"loss\"),\n\t]\n\tloggers = []\n\tepochs = 10\n\trunner.train(\n\t    model=model,\n\t    criterion=cross_entropy,\n", "    optimizer=opt,\n\t    scheduler=sched,\n\t    loaders=loaders,\n\t    num_epochs=epochs,\n\t    callbacks=callbacks,\n\t    loggers=loggers,\n\t    logdir=log_dir,\n\t    valid_loader=\"valid\",\n\t    valid_metric=\"loss\",\n\t    minimize_valid_metric=True,\n", "    cpu=False,\n\t    verbose=True,\n\t    fp16=False,\n\t)\n\t# ------------------------------------------------------------------------------------\n\t# Eval\n\t# ------------------------------------------------------------------------------------\n\tmodel.resize([16, 32, 16])\n\tprint(\"compression rate: \", model.eval().calculate_compression())\n\tmodel = model.transform_to_discrete()\n", "metrics = runner.evaluate_loader(\n\t    model=model, loader=loaders[\"valid\"], callbacks=callbacks[:-1]\n\t)\n"]}
{"filename": "examples/classification/nin_cifar.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torchvision\n\timport torchvision.transforms as transforms\n\tfrom catalyst import dl\n\tfrom pytorchcv.model_provider import get_model\n\timport os\n\tfrom torch_integral import IntegralWrapper, grid_tuning, TrainableGrid1D\n\tdef nin_cifar10(pretrained=True):\n\t    net = get_model(\"nin_cifar10\", pretrained=pretrained)\n", "    net.features.stage2.dropout2 = torch.nn.Identity()\n\t    net.features.stage3.dropout3 = torch.nn.Identity()\n\t    return net\n\t# DATA\n\tbatch_size = 128\n\taugmentation = transforms.Compose(\n\t    [\n\t        transforms.ToTensor(),\n\t        transforms.RandomHorizontalFlip(),\n\t        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n", "    ]\n\t)\n\tpreprocess = transforms.Compose(\n\t    [\n\t        transforms.ToTensor(),\n\t        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n\t    ]\n\t)\n\troot = os.path.expanduser(\"~\") + \"/datasets/\"\n\ttrain_dataset = torchvision.datasets.CIFAR10(\n", "    root=root, train=True, download=True, transform=augmentation\n\t)\n\ttrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n\tval_dataset = torchvision.datasets.CIFAR10(\n\t    root=root, train=False, download=True, transform=preprocess\n\t)\n\tval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False)\n\tloaders = {\"train\": train_dataloader, \"valid\": val_dataloader}\n\t# ------------------------------------------------------------------------------------\n\t# Model\n", "# ------------------------------------------------------------------------------------\n\tmodel = nin_cifar10().cuda()\n\tcontinuous_dims = {}\n\tfor name, mod in model.named_modules():\n\t    if \"stage3\" in name:\n\t        if not isinstance(mod, torch.nn.BatchNorm2d):\n\t            if hasattr(mod, \"weight\"):\n\t                continuous_dims[name + \".weight\"] = [0, 1]\n\t            if hasattr(mod, \"bias\"):\n\t                continuous_dims[name + \".bias\"] = [0]\n", "model = IntegralWrapper(\n\t    init_from_discrete=True,\n\t    fuse_bn=True,\n\t    permutation_iters=3000,\n\t    optimize_iters=0,\n\t    start_lr=1e-3,\n\t    verbose=True,\n\t)(model, [1, 3, 32, 32], continuous_dims)\n\t# ------------------------------------------------------------------------------------\n\t# Train\n", "# ------------------------------------------------------------------------------------\n\tcross_entropy = nn.CrossEntropyLoss()\n\tlog_dir = \"./logs/cifar\"\n\trunner = dl.SupervisedRunner(\n\t    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n\t)\n\tcallbacks = [\n\t    dl.AccuracyCallback(\n\t        input_key=\"logits\", target_key=\"targets\", topk=(1,), num_classes=10\n\t    ),\n", "    dl.SchedulerCallback(mode=\"batch\", loader_key=\"train\", metric_key=\"loss\"),\n\t]\n\tloggers = []\n\tepochs = 10\n\tfor group in model.groups:\n\t    if \"operator\" not in group.operations:\n\t        n = group.size\n\t        new_size = int(float(n) * 0.5)\n\t        group.reset_grid(TrainableGrid1D(new_size))\n\tprint(\"compression: \", model.eval().calculate_compression())\n", "with grid_tuning(model, False, True):\n\t    opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)\n\t    epoch_len = len(train_dataloader)\n\t    sched = torch.optim.lr_scheduler.MultiStepLR(\n\t        opt, [epoch_len * 2, epoch_len * 5, epoch_len * 6, epoch_len * 8], gamma=0.33\n\t    )\n\t    runner.train(\n\t        model=model,\n\t        criterion=cross_entropy,\n\t        optimizer=opt,\n", "        scheduler=sched,\n\t        loaders=loaders,\n\t        num_epochs=epochs,\n\t        callbacks=callbacks,\n\t        loggers=loggers,\n\t        logdir=log_dir,\n\t        valid_loader=\"valid\",\n\t        valid_metric=\"loss\",\n\t        verbose=True,\n\t        cpu=False,\n", "    )\n\t# ------------------------------------------------------------------------------------\n\t# Eval\n\t# ------------------------------------------------------------------------------------\n\tmetrics = runner.evaluate_loader(\n\t    model=model, loader=loaders[\"valid\"], callbacks=callbacks[:1]\n\t)\n"]}
{"filename": "examples/classification/imagenet.py", "chunked_list": ["import os\n\timport torch\n\timport argparse\n\tfrom torchvision import models\n\tfrom catalyst import dl\n\timport torchvision.transforms as transforms\n\tfrom torchvision import datasets\n\tfrom catalyst.engines import GPUEngine\n\tfrom catalyst.engines import DataParallelEngine\n\tfrom torch_integral import UniformDistribution, IntegralWrapper\n", "parser = argparse.ArgumentParser(description=\"INN IMAGENET\")\n\tparser.add_argument(\n\t    \"data\",\n\t    metavar=\"DIR\",\n\t    nargs=\"?\",\n\t    default=\"imagenet\",\n\t    help=\"path to dataset (default: imagenet)\",\n\t)\n\tparser.add_argument(\n\t    \"--checkpoint\", default=None, help=\"path to model checkpoint (default: None)\"\n", ")\n\tparser.add_argument(\n\t    \"-e\",\n\t    \"--evaluate\",\n\t    dest=\"evaluate\",\n\t    action=\"store_true\",\n\t    help=\"evaluate model on validation set\",\n\t)\n\tparser.add_argument(\n\t    \"--integral\", action=\"store_true\", help=\"use integral neural network\"\n", ")\n\tparser.add_argument(\n\t    \"--resample\", action=\"store_true\", help=\"prune integral neural network\"\n\t)\n\tparser.add_argument(\n\t    \"--data-parallel\", action=\"store_true\", help=\"use data parallel engine\"\n\t)\n\tparser.add_argument(\"-b\", \"--batch-size\", default=256, type=int, metavar=\"N\")\n\tparser.add_argument(\"-w\", \"--workers\", default=48, type=int)\n\tparser.add_argument(\n", "    \"--epochs\", default=90, type=int, metavar=\"N\", help=\"number of total epochs to run\"\n\t)\n\targs = parser.parse_args()\n\t# DATA\n\ttraindir = os.path.join(args.data, \"train\")\n\tvaldir = os.path.join(args.data, \"val\")\n\tnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\ttrain_dataset = datasets.ImageFolder(\n\t    traindir,\n\t    transforms.Compose(\n", "        [\n\t            transforms.RandomResizedCrop(224),\n\t            transforms.RandomHorizontalFlip(),\n\t            transforms.ToTensor(),\n\t            normalize,\n\t        ]\n\t    ),\n\t)\n\tval_dataset = datasets.ImageFolder(\n\t    valdir,\n", "    transforms.Compose(\n\t        [\n\t            transforms.Resize(256),\n\t            transforms.CenterCrop(224),\n\t            transforms.ToTensor(),\n\t            normalize,\n\t        ]\n\t    ),\n\t)\n\tval_dataloader = torch.utils.data.DataLoader(\n", "    val_dataset,\n\t    args.batch_size,\n\t    shuffle=False,\n\t    num_workers=args.workers,\n\t    pin_memory=True,\n\t)\n\ttrain_dataloader = torch.utils.data.DataLoader(\n\t    train_dataset,\n\t    args.batch_size,\n\t    shuffle=True,\n", "    num_workers=args.workers,\n\t    pin_memory=True,\n\t)\n\tdataloaders = {\"train\": train_dataloader, \"valid\": val_dataloader}\n\t# MODEL\n\tmodel = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).cuda()\n\tcontinuous_dims = {}\n\tif args.integral:\n\t    continuous_dims = {\n\t        \"layer4.0.conv1.weight\": [0, 1],\n", "        \"layer4.0.conv2.weight\": [0, 1],\n\t        \"layer4.0.downsample.0.weight\": [0, 1],\n\t        \"layer4.1.conv1.weight\": [0, 1],\n\t        \"layer4.1.conv2.weight\": [0, 1],\n\t    }\n\t    discrete_dims = {\"fc.weight\": [1]}\n\t    wrapper = IntegralWrapper(\n\t        init_from_discrete=(args.checkpoint is None), permutation_iters=1000\n\t    )\n\t    model = wrapper(model, [1, 3, 224, 224], continuous_dims, discrete_dims)\n", "    model.groups[-1].reset_distribution(UniformDistribution(338, 512))\n\t    model.groups[-2].reset_distribution(UniformDistribution(338, 512))\n\tif args.checkpoint is not None:\n\t    model.load_state_dict(torch.load(args.checkpoint))\n\tif args.resample:\n\t    model.groups[-1].resize(338)\n\t    model.groups[-2].resize(338)\n\t    print(\"model compression: \", model.eval().calculate_compression())\n\t# Train\n\tlog_dir = \"./logs/imagenet/\"\n", "runner = dl.SupervisedRunner(\n\t    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n\t)\n\tcallbacks = [\n\t    dl.AccuracyCallback(\n\t        input_key=\"logits\",\n\t        target_key=\"targets\",\n\t        topk=(1,),\n\t        num_classes=1000,\n\t        log_on_batch=True,\n", "    ),\n\t    dl.SchedulerCallback(mode=\"batch\", loader_key=\"train\", metric_key=\"loss\"),\n\t]\n\tif args.data_parallel:\n\t    engine = DataParallelEngine()\n\telse:\n\t    engine = GPUEngine()\n\tif not args.evaluate:\n\t    loggers = []\n\t    cross_entropy = torch.nn.CrossEntropyLoss()\n", "    opt = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-8)\n\t    epoch_len = len(dataloaders[\"train\"])\n\t    sched = torch.optim.lr_scheduler.MultiStepLR(\n\t        opt,\n\t        [epoch_len * 10, epoch_len * 20, epoch_len * 30, epoch_len * 40],\n\t        gamma=0.33,\n\t    )\n\t    runner.train(\n\t        model=model,\n\t        criterion=cross_entropy,\n", "        optimizer=opt,\n\t        scheduler=sched,\n\t        loaders=dataloaders,\n\t        num_epochs=args.epochs,\n\t        callbacks=callbacks,\n\t        loggers=loggers,\n\t        logdir=log_dir,\n\t        valid_loader=\"valid\",\n\t        valid_metric=\"loss\",\n\t        minimize_valid_metric=True,\n", "        engine=engine,\n\t        verbose=True,\n\t    )\n\tmetrics = runner.evaluate_loader(\n\t    model=model,\n\t    loader=dataloaders[\"valid\"],\n\t    callbacks=callbacks[:1],\n\t    verbose=True,\n\t    engine=engine,\n\t)\n"]}
{"filename": "docs/conf.py", "chunked_list": ["# flake8: noqa\n\t# -*- coding: utf-8 -*-\n\t#\n\t# Configuration file for the Sphinx documentation builder.\n\t#\n\t# This file does only contain a selection of the most common options. For a\n\t# full list see the documentation:\n\t# http://www.sphinx-doc.org/en/master/config\n\t# -- Path setup --------------------------------------------------------------\n\t# If extensions (or modules to document with autodoc) are in another directory,\n", "# add these directories to sys.path here. If the directory is relative to the\n\t# documentation root, use os.path.abspath to make it absolute, like shown here.\n\t#\n\timport datetime\n\timport os\n\timport re\n\timport sys\n\tsys.path.append(\"../\")\n\t# -- Project information -----------------------------------------------------\n\tproject = \"TorchIntegral v.0.0.0.0\"\n", "copyright = \"{}, TheStage.ai\".format(datetime.datetime.now().year)\n\tauthor = \"Azim Kurbanov, Kirill Solodskikh\"\n\t# -- General configuration ---------------------------------------------------\n\t# If your documentation needs a minimal Sphinx version, state it here.\n\t#\n\t# needs_sphinx = \"1.0\"\n\t# Add any Sphinx extension module names here, as strings. They can be\n\t# extensions coming with Sphinx (named \"sphinx.ext.*\") or your custom\n\t# ones.\n\textensions = [\n", "    \"sphinx.ext.autodoc\",\n\t    \"sphinx.ext.todo\",\n\t    \"sphinx.ext.coverage\",\n\t    \"sphinx.ext.mathjax\",\n\t    \"sphinx.ext.viewcode\",\n\t    \"sphinx.ext.githubpages\",\n\t    \"sphinx.ext.napoleon\",\n\t    \"sphinx.ext.autosummary\"\n\t    # \"releases\",\n\t]\n", "autodoc_inherit_docstrings = False\n\tnapoleon_google_docstring = False\n\tnapoleon_include_init_with_doc = True\n\tnapoleon_numpy_docstring = True\n\tautosummary_generate = True\n\tautodoc_default_flags = [\"members\"]\n\t# Add any paths that contain templates here, relative to this directory.\n\ttemplates_path = [\"_templates\"]\n\t# The suffix(es) of source filenames.\n\t# You can specify multiple suffix as a list of string:\n", "#\n\t# source_suffix = [\".rst\", \".md\"]\n\tsource_suffix = \".rst\"\n\t# The master toctree document.\n\tmaster_doc = \"index\"\n\t# The language for content autogenerated by Sphinx. Refer to documentation\n\t# for a list of supported languages.\n\t#\n\t# This is also used if you do content translation via gettext catalogs.\n\t# Usually you set \"language\" from the command line for these cases.\n", "language = \"Python\"\n\t# List of patterns, relative to source directory, that match files and\n\t# directories to ignore when looking for source files.\n\t# This pattern also affects html_static_path and html_extra_path.\n\texclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\t# Ignoring Third-party packages\n\tautodoc_mock_imports = [\n\t    # \"torch\",\n\t    # \"torchvision\",\n\t    \"alchemy\",\n", "    \"neptune\",\n\t    \"wandb\",\n\t    \"gym\",\n\t    \"gridfs\",\n\t    \"pymongo\",\n\t    \"redis\",\n\t]\n\t# autodoc_default_flags = [\n\t#     \"members\", \"undoc-members\", \"private-members\",\n\t#     \"special-members\", \"inherited-members\", \"show-inheritance\"\n", "# ]\n\t# The name of the Pygments (syntax highlighting) style to use.\n\tpygments_style = None\n\t# -- Options for HTML output -------------------------------------------------\n\t# The theme to use for HTML and HTML Help pages.  See the documentation for\n\t# a list of builtin themes.\n\t#\n\thtml_theme = \"integral_sphinx_theme\"\n\t# html_logo = \"integral_sphinx_theme/images/logo.png\"\n\t# Theme options are theme-specific and customize the look and feel of a theme\n", "# further.  For a list of options available for each theme, see the\n\t# documentation.\n\t#\n\thtml_theme_options = {}\n\t# html_theme_options = {\n\t#     \"display_version\": True,\n\t#     \"prev_next_buttons_location\": \"bottom\",\n\t#     \"collapse_navigation\": False,\n\t#     \"sticky_navigation\": True,\n\t#     \"navigation_depth\": 4,\n", "# }\n\t# Add any paths that contain custom static files (such as style sheets) here,\n\t# relative to this directory. They are copied after the builtin static files,\n\t# so a file named \"default.css\" will overwrite the builtin \"default.css\".\n\t# html_static_path = [\"_static\"]\n\thtml_short_title = \"Integral Nerual Networks\"\n\t# Custom sidebar templates, must be a dictionary that maps document names\n\t# to template names.\n\t#\n\t# The default sidebars (for documents that don\"t match any pattern) are\n", "# defined by theme itself.  Builtin themes are using these templates by\n\t# default: ``[\"localtoc.html\", \"relations.html\", \"sourcelink.html\",\n\t# \"searchbox.html\"]``.\n\t#\n\t# html_sidebars = {}\n\thtml_context = {\n\t    \"display_github\": True,\n\t    \"source_url_prefix\": (\"https://github.com/TheStageAI/TorchIntegral\"),\n\t    \"github_host\": \"github.com\",\n\t    # \"github_user\": docs_user,\n", "    # \"github_repo\": docs_repo,\n\t    \"github_version\": \"master\",\n\t    \"conf_py_path\": \"/docs/\",\n\t    \"source_suffix\": \".rst\",\n\t}\n\t# -- Options for HTMLHelp output ---------------------------------------------\n\t# Output file base name for HTML help builder.\n\thtmlhelp_basename = \"TorchIntegraldoc\"\n\t# -- Options for LaTeX output ------------------------------------------------\n\tlatex_elements = {\n", "    # The paper size (\"letterpaper\" or \"a4paper\").\n\t    #\n\t    # \"papersize\": \"letterpaper\",\n\t    # The font size (\"10pt\", \"11pt\" or \"12pt\").\n\t    #\n\t    # \"pointsize\": \"10pt\",\n\t    # Additional stuff for the LaTeX preamble.\n\t    #\n\t    # \"preamble\": \"\",\n\t    # Latex figure (float) alignment\n", "    #\n\t    # \"figure_align\": \"htbp\",\n\t}\n\t# Grouping the document tree into LaTeX files. List of tuples\n\t# (source start file, target name, title,\n\t#  author, documentclass [howto, manual, or own class]).\n\t# -- Options for manual page output ------------------------------------------\n\t# One entry per manual page. List of tuples\n\t# (source start file, name, description, authors, manual section).\n\tman_pages = [(master_doc, \"TorchIntegral\", \"TorchIntegral Documentation\", [author], 1)]\n", "# -- Options for Texinfo output ----------------------------------------------\n\t# Grouping the document tree into Texinfo files. List of tuples\n\t# (source start file, target name, title, author,\n\t#  dir menu entry, description, category)\n\ttexinfo_documents = [\n\t    (\n\t        master_doc,\n\t        \"TorchIntegral\",\n\t        \"TorchIntegral Documentation\",\n\t        author,\n", "        \"TorchIntegral\",\n\t        \"One line description of project.\",\n\t        \"Continuous\",\n\t    ),\n\t]\n\t# -- Options for Epub output -------------------------------------------------\n\t# Bibliographic Dublin Core info.\n\tepub_title = project\n\t# The unique identifier of the text. This can be a ISBN number\n\t# or the project homepage.\n", "#\n\t# epub_identifier = \"\"\n\t# A unique identification for the text.\n\t#\n\t# epub_uid = \"\"\n\t# A list of files that should not be packed into the epub file.\n\tepub_exclude_files = [\"search.html\"]\n\t# -- Extension configuration -------------------------------------------------\n\t# -- Options for todo extension ----------------------------------------------\n\t# If true, `todo` and `todoList` produce output, else they produce nothing.\n", "todo_include_todos = True\n"]}
