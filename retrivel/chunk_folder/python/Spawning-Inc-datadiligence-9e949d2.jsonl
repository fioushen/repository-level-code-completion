{"filename": "setup.py", "chunked_list": ["\"\"\"\n\t    Setup file for datadiligence.\n\t    Use setup.cfg to configure your project.\n\t    This file was generated with PyScaffold 4.4.\n\t    PyScaffold helps you to put up the scaffold of your new Python project.\n\t    Learn more under: https://pyscaffold.org/\n\t\"\"\"\n\tfrom setuptools import setup\n\tif __name__ == \"__main__\":\n\t    try:\n", "        setup(use_scm_version={\"version_scheme\": \"no-guess-dev\"})\n\t    except:  # noqa\n\t        print(\n\t            \"\\n\\nAn error occurred while building the project, \"\n\t            \"please ensure you have the most updated version of setuptools, \"\n\t            \"setuptools_scm and wheel with:\\n\"\n\t            \"   pip install -U setuptools setuptools_scm wheel\\n\\n\"\n\t        )\n\t        raise\n"]}
{"filename": "tests/test_cp2a.py", "chunked_list": ["from unittest import TestCase\n\tfrom datadiligence.rules import C2PAMetadataRule\n\tclass C2PATests(TestCase):\n\t    def test_c2pa(self):\n\t        rule = C2PAMetadataRule()\n\t        self.assertFalse(rule.is_ready())\n\t        self.assertTrue(rule.is_allowed(body=None))\n"]}
{"filename": "tests/test_evaluators.py", "chunked_list": ["import requests\n\timport urllib.request\n\tfrom unittest import TestCase\n\timport datadiligence as dd\n\tfrom datadiligence import HttpEvaluator, PreprocessEvaluator, PostprocessEvaluator\n\tfrom datadiligence.rules import SpawningAPI, XRobotsTagHeader\n\timport time\n\timport os\n\tfrom samples.custom import CustomEvaluator, NotReadyRule, CustomRule2\n\t# starting local server to echo back headers\n", "from werkzeug.serving import make_server\n\tfrom server.app import app\n\timport threading\n\timport datadiligence.exceptions\n\tclass EvaluatorTests(TestCase):\n\t    @classmethod\n\t    def setUpClass(cls):\n\t        cls.server = make_server('localhost', 5001, app)\n\t        cls.server_thread = threading.Thread(target=cls.server.serve_forever)\n\t        cls.server_thread.start()\n", "        time.sleep(1)  # wait for server to start\n\t    def test_http_evaluator(self):\n\t        http_evaluator = HttpEvaluator()\n\t        self.assertTrue(len(http_evaluator.rules) > 0)\n\t        response = requests.get(\"http://localhost:5001/noai\")\n\t        self.assertFalse(http_evaluator.is_allowed(response=response))\n\t        self.assertFalse(http_evaluator.is_allowed(headers=response.headers))\n\t        request = urllib.request.Request(\"http://localhost:5001/noai\", data=None)\n\t        with urllib.request.urlopen(request, timeout=3) as response:\n\t            self.assertFalse(http_evaluator.is_allowed(response=response))\n", "            self.assertFalse(http_evaluator.is_allowed(headers=response.headers))\n\t        response = requests.get(\"http://localhost:5001/ai\")\n\t        self.assertTrue(http_evaluator.is_allowed(response=response))\n\t        self.assertTrue(http_evaluator.is_allowed(headers=response.headers))\n\t        http_evaluator_2 = HttpEvaluator(respect_robots=False, respect_tdmrep=False)\n\t        self.assertEqual(len(http_evaluator_2.rules), 0)\n\t    def test_custom_evaluator(self):\n\t        # custom evaluator\n\t        custom_evaluator = CustomEvaluator()\n\t        custom_rule = CustomRule2()\n", "        not_ready_rule = NotReadyRule()\n\t        custom_evaluator.add_rule(custom_rule)\n\t        custom_evaluator.add_rule(not_ready_rule)\n\t        self.assertFalse(custom_evaluator.is_allowed(url=\"https://www.google.com\"))\n\t        self.assertTrue(custom_evaluator.is_allowed(url=\"https://www.spawning.ai\"))\n\t        len_rules = len(custom_evaluator.rules)\n\t        custom_evaluator.add_rule(None)\n\t        self.assertEqual(len(custom_evaluator.rules), len_rules)\n\t    def test_bulk_evaluator(self):\n\t        bulk_evaluator = PreprocessEvaluator()\n", "        bulk_evaluator.rules = []\n\t        # patch to point to local dev\n\t        if os.environ.get(SpawningAPI.API_KEY_ENV_VAR, None) is None:\n\t            os.environ[SpawningAPI.API_KEY_ENV_VAR] = \"SAMPLE_KEY\"\n\t        spawning_api = SpawningAPI(user_agent=\"spawningbot\")\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        self.assertEqual(len(bulk_evaluator.rules), 0)\n\t        bulk_evaluator.add_rule(spawning_api)\n\t        self.assertEqual(len(bulk_evaluator.rules), 1)\n\t        urls = bulk_evaluator.filter_allowed([\n", "            \"https://www.spawning.ai\",\n\t            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://www.youtube.com\",\n\t        ])\n\t        self.assertEqual(len(urls), 3)\n\t        urls = bulk_evaluator.filter_allowed(urls=[\n\t            \"https://www.spawning.ai\",\n", "            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://www.youtube.com\",\n\t        ])\n\t        self.assertEqual(len(urls), 3)\n\t        self.assertEqual(len(bulk_evaluator.rules), 1)\n\t        bulk_evaluator.add_rule(None)\n\t        self.assertEqual(len(bulk_evaluator.rules), 1)\n", "        bulk_evaluator = PreprocessEvaluator()\n\t        self.assertTrue(len(bulk_evaluator.rules) > 0)\n\t        self.assertEqual(bulk_evaluator.filter_allowed([]), [])\n\t        self.assertEqual(bulk_evaluator.filter_allowed(None), [])\n\t        self.assertEqual(bulk_evaluator.is_allowed(), [])\n\t    def test_bulk_evaluator_ready_state(self):\n\t        b = PreprocessEvaluator()\n\t        b.rules = []\n\t        del os.environ[SpawningAPI.API_KEY_ENV_VAR]\n\t        spawning_rule = SpawningAPI()\n", "        self.assertFalse(spawning_rule.is_ready())\n\t        b.add_rule(spawning_rule)\n\t        urls = b.filter_allowed([\n\t            \"https://www.spawning.ai\",\n\t            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://www.youtube.com\",\n\t        ])\n", "        self.assertEqual(len(urls), 6)\n\t    def test_postprocessor(self):\n\t        postprocessor = PostprocessEvaluator()\n\t        postprocessor.rules = []\n\t        not_ready_rule = NotReadyRule()\n\t        custom_rule = CustomRule2()\n\t        postprocessor.add_rule(not_ready_rule)\n\t        postprocessor.add_rule(custom_rule)\n\t        # custom rule is saying it's not ready, so we don't use it to evaluate\n\t        self.assertTrue(postprocessor.is_allowed(url=\"http://localhost:5001/noai\"))\n", "        # but later rules still work correctly\n\t        self.assertFalse(postprocessor.is_allowed(url=\"http://google.com\"))\n\t    def test_default_eval_args(self):\n\t        \"\"\"\n\t        Testing named variables to root package evaluator routing\n\t        \"\"\"\n\t        # http defaults\n\t        self.assertFalse(dd.is_allowed(url=\"http://localhost:5001/noai\"))\n\t        # patch to point to local dev\n\t        if os.environ.get(SpawningAPI.API_KEY_ENV_VAR, None) is None:\n", "            os.environ[SpawningAPI.API_KEY_ENV_VAR] = \"SAMPLE_KEY\"\n\t        spawning_api = SpawningAPI(user_agent=\"spawningbot\")\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        evaluator = dd.get_evaluator(\"preprocess\")\n\t        evaluator.rules = []\n\t        evaluator.add_rule(XRobotsTagHeader())\n\t        evaluator.add_rule(spawning_api)\n\t        dd.register_evaluator(evaluator, name=\"preprocess\", overwrite=True)\n\t        # urls defaults\n\t        urls = dd.filter_allowed(urls=[\n", "            \"https://www.spawning.ai\",\n\t            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://www.youtube.com\",\n\t        ])\n\t        self.assertEqual(len(urls), 3)\n\t        bool_urls = dd.is_allowed(urls=[\n\t            \"https://www.spawning.ai\",\n", "            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://www.youtube.com\",\n\t        ])\n\t        self.assertFalse(bool_urls[0])\n\t        self.assertTrue(bool_urls[1])\n\t        self.assertTrue(bool_urls[2])\n\t        self.assertFalse(bool_urls[3])\n", "        self.assertFalse(bool_urls[4])\n\t        self.assertTrue(bool_urls[5])\n\t        # response and headers defaults\n\t        response = requests.get(\"http://localhost:5001/noai\")\n\t        self.assertFalse(dd.is_allowed(response=response))\n\t        self.assertFalse(dd.is_allowed(headers=response.headers))\n\t        response = requests.get(\"http://localhost:5001/ai\")\n\t        self.assertTrue(dd.is_allowed(response=response))\n\t        self.assertTrue(dd.is_allowed(headers=response.headers))\n\t        urls = dd.filter_allowed(name=\"preprocess\", urls=[\n", "            \"https://www.spawning.ai\",\n\t            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://www.youtube.com\",\n\t        ])\n\t        self.assertEqual(len(urls), 3)\n\t        # reload standard evaluators\n\t        dd.load_defaults()\n", "    @classmethod\n\t    def tearDownClass(cls):\n\t        cls.server.shutdown()\n\t        cls.server_thread.join()\n"]}
{"filename": "tests/test_xrobots_header.py", "chunked_list": ["import requests\n\timport urllib.request\n\tfrom unittest import TestCase\n\timport datadiligence as dd\n\tfrom datadiligence.rules import XRobotsTagHeader\n\timport time\n\t# starting local server to echo back headers\n\tfrom werkzeug.serving import make_server\n\tfrom server.app import app\n\timport threading\n", "class XRobotsTest(TestCase):\n\t    @classmethod\n\t    def setUpClass(cls):\n\t        cls.server = make_server('localhost', 5001, app)\n\t        cls.server_thread = threading.Thread(target=cls.server.serve_forever)\n\t        cls.server_thread.start()\n\t        time.sleep(1)  # wait for server to start\n\t        cls.rule = XRobotsTagHeader(user_agent=\"spawningbot\")\n\t        cls.rule_2 = XRobotsTagHeader(user_agent=None)\n\t    def test_noheader(self):\n", "        self.assertTrue(self.rule._eval_header_value(\"\"))\n\t        self.assertTrue(self.rule._eval_header_value(None))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(None))\n\t    def test_noai(self):\n\t        self.assertFalse(self.rule._eval_header_value(\"noai\"))\n\t        self.assertFalse(self.rule._eval_header_value(\"noimageai\"))\n\t        self.assertFalse(self.rule._eval_header_value(\"other, noai\"))\n\t        self.assertFalse(self.rule_2._eval_header_value(\"noai\"))\n\t        self.assertFalse(self.rule_2._eval_header_value(\"noimageai\"))\n", "        self.assertFalse(self.rule_2._eval_header_value(\"other, noai\"))\n\t    def test_ai(self):\n\t        self.assertTrue(self.rule._eval_header_value(\"other\"))\n\t        self.assertTrue(self.rule._eval_header_value(\"noindex\"))\n\t        self.assertTrue(self.rule._eval_header_value(\"other, noindex\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"other\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"noindex\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"other, noindex\"))\n\t    def test_useragent_noai(self):\n\t        self.assertFalse(self.rule._eval_header_value(\"spawningbot: noai\"))\n", "        self.assertFalse(self.rule._eval_header_value(\"spawningbot: noimageai\"))\n\t        self.assertFalse(self.rule._eval_header_value(\"other, spawningbot: noai\"))\n\t        self.assertFalse(self.rule._eval_header_value(\"other, spawningbot:noai\"))\n\t        self.assertFalse(self.rule._eval_header_value(\"spawningbot:other, spawningbot: noai\"))\n\t        self.assertFalse(self.rule._eval_header_value(\"spawningbot:other, spawningbot:noai\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"spawningbot: noai\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"spawningbot: noimageai\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"other, spawningbot: noai\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"other, spawningbot:noai\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"spawningbot:other, spawningbot: noai\"))\n", "        self.assertTrue(self.rule_2._eval_header_value(\"spawningbot:other, spawningbot:noai\"))\n\t    def test_useragent_ai(self):\n\t        self.assertTrue(self.rule._eval_header_value(\"spawningbot: all\"))\n\t        self.assertTrue(self.rule._eval_header_value(\"spawningbot: other\"))\n\t        self.assertTrue(self.rule._eval_header_value(\"other, spawningbot: all\"))\n\t        self.assertTrue(self.rule._eval_header_value(\"spawningbot: other, spawningbot: all, test:noai\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"spawningbot: all\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"spawningbot: other\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"other, spawningbot: all\"))\n\t        self.assertTrue(self.rule_2._eval_header_value(\"spawningbot: other, spawningbot: all, test:noai\"))\n", "    def test_useragent_override(self):\n\t        pass\n\t    def test_stdlib(self):\n\t        request = urllib.request.Request(\"http://localhost:5001/noai\", data=None)\n\t        with urllib.request.urlopen(request, timeout=3) as response:\n\t            self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"noai\")\n\t            self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"noai\")\n\t            self.assertEqual(self.rule.get_header_value(response.getheaders(), self.rule.HEADER_NAME), \"noai\")\n\t            self.assertFalse(self.rule.is_allowed(response=response))\n\t            self.assertFalse(self.rule.is_allowed(headers=response.headers))\n", "        request = urllib.request.Request(\"http://localhost:5001/ai\", data=None)\n\t        with urllib.request.urlopen(request, timeout=3) as response:\n\t            self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"all\")\n\t            self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"all\")\n\t            self.assertTrue(self.rule.is_allowed(response=response))\n\t            self.assertTrue(self.rule.is_allowed(headers=response.headers))\n\t    def test_requests_lib(self):\n\t        response = requests.get(\"http://localhost:5001/noai\", timeout=3)\n\t        self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"noai\")\n\t        self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"noai\")\n", "        self.assertFalse(self.rule.is_allowed(response=response))\n\t        self.assertFalse(self.rule.is_allowed(headers=response.headers))\n\t        response = requests.get(\"http://localhost:5001/ai\")\n\t        self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"all\")\n\t        self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"all\")\n\t        self.assertTrue(self.rule.is_allowed(response=response))\n\t        self.assertTrue(self.rule.is_allowed(headers=response.headers))\n\t    def test_useragent_requests(self):\n\t        response = requests.get(\"http://localhost:5001/user_agents\")\n\t        self.assertTrue(self.rule.is_allowed(response=response))\n", "        self.assertTrue(self.rule.is_allowed(headers=response.headers))\n\t        response = requests.get(\"http://localhost:5001/user_agents_noai\")\n\t        self.assertFalse(self.rule.is_allowed(response=response))\n\t        self.assertFalse(self.rule.is_allowed(headers=response.headers))\n\t    def test_parse_useragents(self):\n\t        response = requests.get(\"http://localhost:5001/user_agents\")\n\t        self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME),\n\t                         \"demobot: noai, examplebot: noai, spawningbot: all\")\n\t    def test_malformed_headers(self):\n\t        self.assertTrue(self.rule._eval_header_value(\":,\"))\n", "        self.assertTrue(self.rule._eval_header_value(\":, :, ,;: -:: \"))\n\t    def test_exceptions(self):\n\t        self.assertRaises(dd.exceptions.XRobotsTagNoParam, self.rule.is_allowed, None, None)\n\t        self.assertRaises(dd.exceptions.HttpUnknownHeaderObject, self.rule.get_header_value, None, None)\n\t        self.assertRaises(dd.exceptions.HttpUnknownResponseObject, self.rule.get_header_value_from_response, None, None)\n\t    def test_url_arg(self):\n\t        self.assertTrue(self.rule.is_allowed(url=\"http://localhost:5001/ai\"))\n\t        self.assertFalse(self.rule.is_allowed(url=\"http://localhost:5001/noai\"))\n\t    def test_noindex(self):\n\t        rule = XRobotsTagHeader(user_agent=\"spawningbot\", respect_noindex=False)\n", "        self.assertTrue(rule.is_allowed(url=\"http://localhost:5001/noindex\"))\n\t        rule_2 = XRobotsTagHeader(user_agent=\"spawningbot\", respect_noindex=True)\n\t        self.assertFalse(rule_2.is_allowed(url=\"http://localhost:5001/noindex\"))\n\t    @classmethod\n\t    def tearDownClass(cls):\n\t        cls.server.shutdown()\n\t        cls.server_thread.join()\n"]}
{"filename": "tests/test_bootstrapper.py", "chunked_list": ["from unittest import TestCase\n\timport datadiligence as dd\n\timport datadiligence.exceptions\n\tfrom samples.custom import CustomEvaluator, CustomRule\n\timport urllib\n\timport time\n\t# starting local server to confirm api response\n\tfrom werkzeug.serving import make_server\n\tfrom server.app import app\n\timport threading\n", "import os\n\tfrom datadiligence.rules import SpawningAPI\n\tclass BootstrapTests(TestCase):\n\t    @classmethod\n\t    def setUpClass(cls):\n\t        cls.server = make_server('localhost', 5001, app)\n\t        cls.server_thread = threading.Thread(target=cls.server.serve_forever)\n\t        cls.server_thread.start()\n\t        time.sleep(2)\n\t        # set up a basic env var so most tests succeed\n", "        if os.environ.get(SpawningAPI.API_KEY_ENV_VAR, None) is None:\n\t            os.environ[SpawningAPI.API_KEY_ENV_VAR] = \"SAMPLE_KEY\"\n\t        cls.urls = [\n\t            \"https://www.spawning.ai\",\n\t            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://spawning.ai/éxample.png\"\n\t        ]\n", "    def test_exceptions(self):\n\t        self.assertRaises(dd.exceptions.EvaluatorNotRegistered, dd.is_allowed, \"x\")\n\t        self.assertRaises(dd.exceptions.NotEvaluator, dd.register_evaluator, None, \"y\")\n\t        custom_evaluator = dd.Evaluator()\n\t        dd.register_evaluator(custom_evaluator, \"custom0\")\n\t        self.assertRaises(dd.exceptions.EvaluatorAlreadyRegistered,\n\t                          dd.register_evaluator, custom_evaluator, \"custom0\")\n\t        self.assertRaises(dd.exceptions.EvaluatorNotRegistered, dd.deregister_evaluator, \"not-used\")\n\t        self.assertRaises(dd.exceptions.EvaluatorNotRegistered, dd.get_evaluator, \"not-used\")\n\t        self.assertRaises(dd.exceptions.DefaultEvaluatorNotFound, dd.is_allowed, example=\"not-used\")\n", "        with self.assertRaises(datadiligence.exceptions.EvaluatorNotRegistered):\n\t            dd.filter_allowed(name=\"none\", urls=[])\n\t        with self.assertRaises(datadiligence.exceptions.DefaultEvaluatorNotFound):\n\t            dd.filter_allowed(args=None)\n\t    def test_load_defaults(self):\n\t        # reset evaluators\n\t        for key in dd.list_evaluators():\n\t            dd.deregister_evaluator(key)\n\t        dd.load_defaults()\n\t        self.assertTrue(isinstance(dd.get_evaluator(\"preprocess\"), dd.PreprocessEvaluator))\n", "        self.assertTrue(isinstance(dd.get_evaluator(\"postprocess\"), dd.PostprocessEvaluator))\n\t        self.assertEqual(len(dd.list_evaluators()), 2)\n\t    def test_register_evaluator(self):\n\t        custom_evaluator = dd.Evaluator()\n\t        dd.register_evaluator(custom_evaluator, \"custom1\")\n\t        self.assertEqual(dd.get_evaluator(\"custom1\"), custom_evaluator)\n\t    def test_deregister_evaluator(self):\n\t        custom_evaluator = dd.Evaluator()\n\t        dd.register_evaluator(custom_evaluator, \"custom3\")\n\t        self.assertEqual(dd.get_evaluator(\"custom3\"), custom_evaluator)\n", "        dd.deregister_evaluator(\"custom3\")\n\t        self.assertRaises(dd.exceptions.EvaluatorNotRegistered, dd.deregister_evaluator, \"custom3\")\n\t    def test_is_allowed(self):\n\t        custom_evaluator = CustomEvaluator()\n\t        custom_evaluator.add_rule(CustomRule())\n\t        dd.register_evaluator(custom_evaluator, \"custom2\")\n\t        self.assertFalse(dd.is_allowed(\"custom2\", sample=\"www.google.com\"))\n\t        self.assertTrue(dd.is_allowed(\"custom2\", sample=\"www.example.com\"))\n\t        dd.load_defaults()\n\t        request = urllib.request.Request(\"http://localhost:5001/noai\", data=None)\n", "        with urllib.request.urlopen(request, timeout=3) as response:\n\t            self.assertFalse(dd.is_allowed(response=response))\n\t        # hack to reach local instance\n\t        dd.get_evaluator(\"preprocess\").rules[0].SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        url_results = dd.is_allowed(urls=self.urls)\n\t        self.assertEqual(len(url_results), 6)\n\t        # with user agent arg\n\t        url_results = dd.is_allowed(urls=self.urls, user_agent=\"UserAgent\")\n\t        self.assertEqual(len(url_results), 6)\n\t        dd.load_defaults()\n", "    def test_filter_allowed(self):\n\t        dd.load_defaults()\n\t        request = urllib.request.Request(\"http://localhost:5001/noai\", data=None)\n\t        with urllib.request.urlopen(request, timeout=3) as response:\n\t            self.assertFalse(dd.is_allowed(response=response))\n\t        # hack to reach local instance\n\t        dd.get_evaluator(\"preprocess\").rules[0].SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        filtered_urls = dd.filter_allowed(urls=self.urls)\n\t        self.assertEqual(len(filtered_urls), 3)\n\t        self.assertEqual(filtered_urls[0], self.urls[1])\n", "        self.assertEqual(filtered_urls[1], self.urls[2])\n\t        self.assertEqual(filtered_urls[2], self.urls[5])\n\t        # with user agent arg\n\t        filtered_urls = dd.filter_allowed(urls=self.urls, user_agent=\"UserAgent\")\n\t        self.assertEqual(len(filtered_urls), 3)\n\t        self.assertEqual(filtered_urls[0], self.urls[1])\n\t        self.assertEqual(filtered_urls[1], self.urls[2])\n\t        self.assertEqual(filtered_urls[2], self.urls[5])\n\t        dd.load_defaults()\n\t    @classmethod\n", "    def tearDownClass(cls):\n\t        cls.server.shutdown()\n\t        cls.server_thread.join()\n"]}
{"filename": "tests/test_tdmrep_header.py", "chunked_list": ["import requests\n\timport urllib.request\n\tfrom unittest import TestCase\n\timport datadiligence as dd\n\tfrom datadiligence.rules import TDMRepHeader\n\timport time\n\t# starting local server to echo back headers\n\tfrom werkzeug.serving import make_server\n\tfrom server.app import app\n\timport threading\n", "class TDMRepTest(TestCase):\n\t    @classmethod\n\t    def setUpClass(cls):\n\t        cls.server = make_server('localhost', 5001, app)\n\t        cls.server_thread = threading.Thread(target=cls.server.serve_forever)\n\t        cls.server_thread.start()\n\t        time.sleep(1)  # wait for server to start\n\t        cls.rule = TDMRepHeader()\n\t    def test_noheader(self):\n\t        self.assertTrue(self.rule._eval_header_value(\"\"))\n", "        self.assertTrue(self.rule._eval_header_value(None))\n\t    def test_tdm_block(self):\n\t        self.assertFalse(self.rule._eval_header_value(\"1\"))\n\t        self.assertTrue(self.rule._eval_header_value(\"0\"))\n\t        self.assertTrue(self.rule._eval_header_value(\"other\"))\n\t    def test_stdlib(self):\n\t        request = urllib.request.Request(\"http://localhost:5001/tdmrep\", data=None)\n\t        with urllib.request.urlopen(request, timeout=3) as response:\n\t            self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"0\")\n\t            self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"0\")\n", "            self.assertEqual(self.rule.get_header_value(response.getheaders(), self.rule.HEADER_NAME), \"0\")\n\t            self.assertTrue(self.rule.is_allowed(response=response))\n\t            self.assertTrue(self.rule.is_allowed(headers=response.headers))\n\t        request = urllib.request.Request(\"http://localhost:5001/blocktdmrep\", data=None)\n\t        with urllib.request.urlopen(request, timeout=3) as response:\n\t            self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"1\")\n\t            self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"1\")\n\t            self.assertFalse(self.rule.is_allowed(response=response))\n\t            self.assertFalse(self.rule.is_allowed(headers=response.headers))\n\t    def test_requests_lib(self):\n", "        response = requests.get(\"http://localhost:5001/tdmrep\", timeout=3)\n\t        self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"0\")\n\t        self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"0\")\n\t        self.assertTrue(self.rule.is_allowed(response=response))\n\t        self.assertTrue(self.rule.is_allowed(headers=response.headers))\n\t        response = requests.get(\"http://localhost:5001/blocktdmrep\")\n\t        self.assertEqual(self.rule.get_header_value_from_response(response, self.rule.HEADER_NAME), \"1\")\n\t        self.assertEqual(self.rule.get_header_value(response.headers, self.rule.HEADER_NAME), \"1\")\n\t        self.assertFalse(self.rule.is_allowed(response=response))\n\t        self.assertFalse(self.rule.is_allowed(headers=response.headers))\n", "    def test_exceptions(self):\n\t        self.assertRaises(dd.exceptions.TDMRepNoParam, self.rule.is_allowed, None, None)\n\t        self.assertRaises(dd.exceptions.HttpUnknownHeaderObject, self.rule.get_header_value, None, None)\n\t        self.assertRaises(dd.exceptions.HttpUnknownResponseObject, self.rule.get_header_value_from_response, None, None)\n\t    def test_url_arg(self):\n\t        self.assertTrue(self.rule.is_allowed(url=\"http://localhost:5001/tdmrep\"))\n\t        self.assertFalse(self.rule.is_allowed(url=\"http://localhost:5001/blocktdmrep\"))\n\t    @classmethod\n\t    def tearDownClass(cls):\n\t        cls.server.shutdown()\n", "        cls.server_thread.join()\n"]}
{"filename": "tests/test_utils.py", "chunked_list": ["from unittest import TestCase\n\tfrom datadiligence.utils import get_url\n\timport requests\n\tclass TestUtils(TestCase):\n\t    def test_get_url(self):\n\t        response = get_url(\"http://www.google.com\")\n\t        self.assertTrue(response.ok)\n\t        self.assertRaises(Exception, get_url, \"wesvadsvrwabg\")\n\t        user_agent = requests.utils.default_user_agent()\n\t        response = get_url(\"http://www.google.com\", user_agent=user_agent)\n", "        self.assertTrue(response.ok)\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["\"\"\"\n\t    Dummy conftest.py for datadiligence.\n\t    If you don't know what this is for, just leave it empty.\n\t    Read more about conftest.py under:\n\t    - https://docs.pytest.org/en/stable/fixture.html\n\t    - https://docs.pytest.org/en/stable/writing_plugins.html\n\t\"\"\"\n\t# import pytest\n"]}
{"filename": "tests/test_spawningapi.py", "chunked_list": ["from unittest import TestCase\n\timport datadiligence as dd\n\tfrom datadiligence.rules import SpawningAPI\n\timport datadiligence.exceptions\n\timport os\n\timport time\n\t# starting local server to confirm api response\n\tfrom werkzeug.serving import make_server\n\tfrom server.app import app\n\timport threading\n", "import asyncio\n\tfrom contextlib import contextmanager\n\t@contextmanager\n\tdef run_async_loop():\n\t    loop = asyncio.new_event_loop()\n\t    asyncio.set_event_loop(loop)\n\t    try:\n\t        yield loop\n\t    finally:\n\t        loop.run_until_complete(loop.shutdown_asyncgens())\n", "        loop.close()\n\t        asyncio.set_event_loop(None)\n\tdef run_async_in_sync(f, *args, **kwargs):\n\t    coro = f(*args, **kwargs)\n\t    with run_async_loop() as loop:\n\t        result = loop.run_until_complete(coro)\n\t    return result\n\tclass SpawningAPITest(TestCase):\n\t    @classmethod\n\t    def setUpClass(cls):\n", "        cls.server = make_server('localhost', 5001, app)\n\t        cls.server_thread = threading.Thread(target=cls.server.serve_forever)\n\t        cls.server_thread.start()\n\t        time.sleep(2)  # wait for server to start\n\t        # set up a basic env var so most tests succeed\n\t        if os.environ.get(SpawningAPI.API_KEY_ENV_VAR, None) is None:\n\t            os.environ[SpawningAPI.API_KEY_ENV_VAR] = \"SAMPLE_KEY\"\n\t        cls.rule = SpawningAPI(user_agent=\"spawningbot\", chunk_size=2)\n\t        cls.urls = [\n\t            \"https://www.spawning.ai\",\n", "            \"https://www.shutterstock.com\",\n\t            \"https://open.ai\",\n\t            \"https://www.google.com\",\n\t            \"https://laion.ai\",\n\t            \"https://spawning.ai/éxample.png\"\n\t        ]\n\t    def test_unicode(self):\n\t        unicode_urls = [\n\t            \"https://spawning.ai/éxample.png\",\n\t            \"https://open.ai/image.png\"\n", "        ]\n\t        spawning_api = SpawningAPI()\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/unicode/success\"\n\t        results = spawning_api.filter_allowed(urls=unicode_urls)\n\t        self.assertEqual(results, unicode_urls)\n\t    def test_chunking(self):\n\t        iter_num = 0\n\t        for chunk in self.rule._chunk(self.urls):\n\t            self.assertEqual(len(chunk), 2)\n\t            self.assertEqual(chunk[0], self.urls[iter_num * 2])\n", "            self.assertEqual(chunk[1], self.urls[iter_num * 2 + 1])\n\t            iter_num += 1\n\t    def test_init(self):\n\t        spawning_api = SpawningAPI(chunk_size=100000, timeout=-10)\n\t        self.assertEqual(spawning_api.chunk_size, SpawningAPI.MAX_CHUNK_SIZE)\n\t        self.assertEqual(spawning_api.timeout, SpawningAPI.DEFAULT_TIMEOUT)\n\t    def test_is_ready(self):\n\t        api_key = os.environ.get(SpawningAPI.API_KEY_ENV_VAR, None)\n\t        self.assertTrue(api_key)\n\t        tmp_spawning = SpawningAPI()\n", "        self.assertTrue(tmp_spawning.is_ready())\n\t        os.environ[SpawningAPI.API_KEY_ENV_VAR+\"_TMP\"] = api_key\n\t        del os.environ[SpawningAPI.API_KEY_ENV_VAR]\n\t        api_key = os.environ.get(SpawningAPI.API_KEY_ENV_VAR, None)\n\t        self.assertFalse(api_key)\n\t        tmp_spawning = SpawningAPI()\n\t        self.assertFalse(tmp_spawning.is_ready())\n\t        os.environ[SpawningAPI.API_KEY_ENV_VAR] = os.environ[SpawningAPI.API_KEY_ENV_VAR+\"_TMP\"]\n\t        del os.environ[SpawningAPI.API_KEY_ENV_VAR+\"_TMP\"]\n\t    def test_filter_allowed(self):\n", "        spawning_api = SpawningAPI(max_concurrent_requests=2000)\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        allowed = spawning_api.filter_allowed(urls=self.urls)\n\t        self.assertEqual(len(allowed), 3)\n\t        self.assertEqual(allowed[0], self.urls[1])\n\t        self.assertEqual(allowed[1], self.urls[2])\n\t        self.assertEqual(allowed[2], self.urls[5])\n\t        allowed = spawning_api.filter_allowed(urls=self.urls)\n\t        self.assertEqual(len(allowed), 3)\n\t        self.assertEqual(allowed[0], self.urls[1])\n", "        self.assertEqual(allowed[1], self.urls[2])\n\t        self.assertEqual(allowed[2], self.urls[5])\n\t        allowed = spawning_api.filter_allowed(url=self.urls[1])\n\t        self.assertEqual(allowed[0], self.urls[1])\n\t        with self.assertRaises(datadiligence.exceptions.SpawningNoParam):\n\t            spawning_api.is_allowed(args=None)\n\t    def test_is_allowed(self):\n\t        spawning_api = SpawningAPI()\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        allowed = spawning_api.is_allowed(url=self.urls[1])\n", "        self.assertTrue(allowed)\n\t        results = spawning_api.is_allowed(urls=self.urls)\n\t        self.assertEqual(len(results), 6)\n\t        self.assertFalse(results[0])\n\t        self.assertTrue(results[1])\n\t        self.assertTrue(results[2])\n\t        self.assertFalse(results[3])\n\t        self.assertFalse(results[4])\n\t        self.assertTrue(results[5])\n\t    def test_with_useragent(self):\n", "        spawning_api = SpawningAPI()\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        allowed = spawning_api.is_allowed(url=self.urls[1], user_agent=\"New User Agent\")\n\t        self.assertTrue(allowed[1])\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        allowed = spawning_api.is_allowed(url=self.urls[4], user_agent=\"New User Agent\")\n\t        self.assertFalse(allowed[4])\n\t    def test_api_exception_handling(self):\n\t        spawning_api = SpawningAPI(user_agent=\"spawningbot\")\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/fail\"\n", "        self.assertRaises(dd.exceptions.SpawningAIAPIError, spawning_api.filter_allowed, self.urls)\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/fail2\"\n\t        self.assertRaises(dd.exceptions.SpawningAIAPIError, spawning_api.filter_allowed, self.urls)\n\t        with self.assertRaises(dd.exceptions.SpawningNoParam):\n\t            spawning_api.filter_allowed(arg=None)\n\t    def test_api_exception_handling_async(self):\n\t        spawning_api = SpawningAPI()\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/opts\"\n\t        allowed = run_async_in_sync(spawning_api.filter_allowed_async, urls=self.urls)\n\t        self.assertEqual(len(allowed), 3)\n", "        allowed = run_async_in_sync(spawning_api.filter_allowed_async, url=self.urls[0])\n\t        self.assertEqual(len(allowed), 3)\n\t        allowed = run_async_in_sync(spawning_api.is_allowed_async, urls=self.urls)\n\t        self.assertEqual(len(allowed), 6)\n\t        self.assertFalse(allowed[0])\n\t        self.assertTrue(allowed[1])\n\t        self.assertTrue(allowed[2])\n\t        self.assertFalse(allowed[3])\n\t        self.assertFalse(allowed[4])\n\t        self.assertTrue(allowed[5])\n", "        allowed = run_async_in_sync(spawning_api.is_allowed_async, url=self.urls[0])\n\t        self.assertEqual(len(allowed), 6)\n\t    def test_fails_async(self):\n\t        spawning_api = SpawningAPI(user_agent=\"spawningbot\")\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/fail\"\n\t        with self.assertRaises(dd.exceptions.SpawningAIAPIError):\n\t            run_async_in_sync(spawning_api.filter_allowed_async, urls=self.urls)\n\t        spawning_api.SPAWNING_AI_API_URL = \"http://localhost:5001/fail2\"\n\t        with self.assertRaises(dd.exceptions.SpawningAIAPIError):\n\t            run_async_in_sync(spawning_api.filter_allowed_async, urls=self.urls)\n", "        with self.assertRaises(dd.exceptions.SpawningNoParam):\n\t            run_async_in_sync(spawning_api.filter_allowed_async, arg=None)\n\t        with self.assertRaises(dd.exceptions.SpawningNoParam):\n\t            run_async_in_sync(spawning_api.is_allowed_async, arg=None)\n\t    @classmethod\n\t    def tearDownClass(cls):\n\t        cls.server.shutdown()\n\t        cls.server_thread.join()\n"]}
{"filename": "tests/samples/custom.py", "chunked_list": ["from datadiligence import Evaluator\n\tfrom datadiligence.rules import Rule\n\tclass CustomEvaluator(Evaluator):\n\t    def is_allowed(self, **kwargs):\n\t        for rule in self.rules:\n\t            if rule.is_ready() and not rule.is_allowed(**kwargs):\n\t                return False\n\t        return True\n\tclass CustomRule(Rule):\n\t    def is_ready(self):\n", "        return True\n\t    def is_allowed(self, sample=\"\", **kwargs):\n\t        if \"google\" in sample:\n\t            return False\n\t        else:\n\t            return True\n\tclass NotReadyRule(Rule):\n\t    def is_ready(self):\n\t        return False\n\t    def is_allowed(self, **kwargs):\n", "        return True\n\tclass CustomRule2(Rule):\n\t    def is_ready(self):\n\t        return True\n\t    def is_allowed(self, url=\"\", **kwargs):\n\t        if \"google\" in url:\n\t            return False\n\t        else:\n\t            return True\n"]}
{"filename": "tests/server/app.py", "chunked_list": ["import json\n\tfrom flask import Flask, Response, request\n\tapp = Flask(__name__)\n\t@app.route(\"/ai\", methods=[\"GET\"])\n\tdef noai_headers():\n\t    response = Response()\n\t    response.headers[\"X-Robots-Tag\"] = \"all\"\n\t    return response\n\t@app.route(\"/noai\", methods=[\"GET\"])\n\tdef ai_headers():\n", "    response = Response()\n\t    response.headers[\"X-Robots-Tag\"] = \"noai\"\n\t    return response\n\t@app.route(\"/user_agents\", methods=[\"GET\"])\n\tdef user_agents():\n\t    response = Response()\n\t    response.headers[\"X-Robots-Tag\"] = \"demobot: noai, examplebot: noai, spawningbot: all\"\n\t    return response\n\t@app.route(\"/user_agents_noai\", methods=[\"GET\"])\n\tdef user_agents_noai():\n", "    response = Response()\n\t    response.headers[\"X-Robots-Tag\"] = \"demobot: noai, examplebot: noai, spawningbot: noai\"\n\t    return response\n\t@app.route(\"/noindex\", methods=[\"GET\"])\n\tdef user_agents_noindex():\n\t    response = Response()\n\t    response.headers[\"X-Robots-Tag\"] = \"none, noindex\"\n\t    return response\n\t@app.route(\"/opts\", methods=[\"POST\"])\n\tdef opts():\n", "    json_body = {\"urls\": [\n\t        {\"url\": \"https://www.spawning.ai\", \"optOut\": True, \"optIn\": False},\n\t        {\"url\": \"https://www.shutterstock.com\", \"optOut\": False, \"optIn\": False},\n\t        {\"url\": \"https://open.ai\", \"optOut\": False, \"optIn\": False},\n\t        {\"url\": \"https://www.google.com\", \"optOut\": True, \"optIn\": False},\n\t        {\"url\": \"https://laion.ai\", \"optOut\": True, \"optIn\": True},\n\t        {\"url\": \"https://spawning.ai/éxample.png\", \"optOut\": False, \"optIn\": False}\n\t    ]}\n\t    return Response(json.dumps(json_body), mimetype=\"application/json\")\n\t@app.route(\"/unicode/success\", methods=[\"POST\"])\n", "def unicode_failure():\n\t    # mimic Spawning API handling of unicode characters\n\t    try:\n\t        urls = request.get_data().decode(\"utf-8\").split(\"\\n\")\n\t        return Response(json.dumps({\"urls\": [{\"url\": url, \"optOut\": False, \"optIn\": False} for url in urls]}),\n\t                        status=200)\n\t    except Exception as e:\n\t        return Response(str(e), status=500)\n\t@app.route(\"/fail\", methods=[\"POST\"])\n\tdef fail():\n", "    response = Response()\n\t    response.status_code = 500\n\t    return response\n\t@app.route(\"/fail2\", methods=[\"POST\"])\n\tdef fail2():\n\t    response = Response(\"not-json\")\n\t    response.headers[\"Content-Type\"] = \"application/json\"\n\t    response.status_code = 200\n\t    return response\n\t@app.route(\"/tdmrep\", methods=[\"GET\"])\n", "def tdmrep():\n\t    response = Response()\n\t    response.headers[\"tdm-reservation\"] = \"0\"\n\t    return response\n\t@app.route(\"/blocktdmrep\", methods=[\"GET\"])\n\tdef tdmrep_none():\n\t    response = Response()\n\t    response.headers[\"tdm-reservation\"] = \"1\"\n\t    response.headers[\"tdm-policy\"] = \"http://localhost/test/policy.json\"\n\t    return response\n"]}
{"filename": "examples/http_headers.py", "chunked_list": ["import datadiligence as dd\n\timport requests\n\tresponse = requests.get(\"https://www.google.com/image\")\n\tis_allowed = dd.is_allowed(headers=response.headers)\n"]}
{"filename": "examples/pre_and_post_processing.py", "chunked_list": ["# make sure SPAWNING_OPTS_KEY environment variable is set first\n\timport datadiligence as dd\n\tfrom pyarrow import csv\n\timport requests\n\t# read csv/tsv file\n\tmd = csv.read_csv(\"/path/to/urls.tsv\", read_options=csv.ReadOptions(encoding=\"utf-8\"), parse_options=csv.ParseOptions(delimiter='\\t'))\n\t# convert it to list\n\td = md.select([\"url\"]).to_pandas()\n\turls = d.iloc[:, 0].to_list()\n\t# send through pre-process steps (only includes Spawning API currently)\n", "verified_urls = dd.filter_allowed(urls=urls)  # use dd.is_allowed to get a list of booleans instead\n\t# you'll probably be downloading these images in your pipeline, this is a placeholder for that\n\tfor url in verified_urls:\n\t    response = requests.get(url)\n\t    if response.status_code == 200:\n\t        # this is the only new code you need here\n\t        is_allowed = dd.is_allowed(response=response)\n\t        if not is_allowed:\n\t            continue\n\t        # image is allowed after this point\n"]}
{"filename": "examples/spawning_api.py", "chunked_list": ["# make sure SPAWNING_OPTS_KEY environment variable is set first\n\timport datadiligence as dd\n\tfrom pyarrow import csv\n\t# read csv/tsv file\n\tmd = csv.read_csv(\"~/Downloads/cc40k.tsv\", read_options=csv.ReadOptions(encoding=\"utf-8\"), parse_options=csv.ParseOptions(delimiter='\\t'))\n\t# convert it to list\n\td = md.select([\"url\"]).to_pandas()\n\turls = d.iloc[:, 0].to_list()\n\t# send through pre-process steps (only includes Spawning API currently)\n\tverified_urls = dd.filter_allowed(urls=urls)\n"]}
{"filename": "docs/conf.py", "chunked_list": ["# This file is execfile()d with the current directory set to its containing dir.\n\t#\n\t# This file only contains a selection of the most common options. For a full\n\t# list see the documentation:\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\t#\n\t# All configuration values have a default; values that are commented out\n\t# serve to show the default.\n\timport os\n\timport sys\n", "import shutil\n\t# -- Path setup --------------------------------------------------------------\n\t__location__ = os.path.dirname(__file__)\n\t# If extensions (or modules to document with autodoc) are in another directory,\n\t# add these directories to sys.path here. If the directory is relative to the\n\t# documentation root, use os.path.abspath to make it absolute, like shown here.\n\tsys.path.insert(0, os.path.join(__location__, \"../src\"))\n\t# -- Run sphinx-apidoc -------------------------------------------------------\n\t# This hack is necessary since RTD does not issue `sphinx-apidoc` before running\n\t# `sphinx-build -b html . _build/html`. See Issue:\n", "# https://github.com/readthedocs/readthedocs.org/issues/1139\n\t# DON'T FORGET: Check the box \"Install your project inside a virtualenv using\n\t# setup.py install\" in the RTD Advanced Settings.\n\t# Additionally it helps us to avoid running apidoc manually\n\ttry:  # for Sphinx >= 1.7\n\t    from sphinx.ext import apidoc\n\texcept ImportError:\n\t    from sphinx import apidoc\n\toutput_dir = os.path.join(__location__, \"api\")\n\tmodule_dir = os.path.join(__location__, \"../src/datadiligence\")\n", "try:\n\t    shutil.rmtree(output_dir)\n\texcept FileNotFoundError:\n\t    pass\n\ttry:\n\t    import sphinx\n\t    cmd_line = f\"sphinx-apidoc --implicit-namespaces -f -o {output_dir} {module_dir}\"\n\t    args = cmd_line.split(\" \")\n\t    if tuple(sphinx.__version__.split(\".\")) >= (\"1\", \"7\"):\n\t        # This is a rudimentary parse_version to avoid external dependencies\n", "        args = args[1:]\n\t    apidoc.main(args)\n\texcept Exception as e:\n\t    print(\"Running `sphinx-apidoc` failed!\\n{}\".format(e))\n\t# -- General configuration ---------------------------------------------------\n\t# If your documentation needs a minimal Sphinx version, state it here.\n\t# needs_sphinx = '1.0'\n\t# Add any Sphinx extension module names here, as strings. They can be extensions\n\t# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\n\textensions = [\n", "    \"sphinx.ext.autodoc\",\n\t    \"sphinx.ext.intersphinx\",\n\t    \"sphinx.ext.todo\",\n\t    \"sphinx.ext.autosummary\",\n\t    \"sphinx.ext.viewcode\",\n\t    \"sphinx.ext.coverage\",\n\t    \"sphinx.ext.doctest\",\n\t    \"sphinx.ext.ifconfig\",\n\t    \"sphinx.ext.mathjax\",\n\t    \"sphinx.ext.napoleon\",\n", "]\n\t# Add any paths that contain templates here, relative to this directory.\n\ttemplates_path = [\"_templates\"]\n\t# The suffix of source filenames.\n\tsource_suffix = \".rst\"\n\t# The encoding of source files.\n\t# source_encoding = 'utf-8-sig'\n\t# The master toctree document.\n\tmaster_doc = \"index\"\n\t# General information about the project.\n", "project = \"datadiligence\"\n\tcopyright = \"2023, Spawning Inc\"\n\t# The version info for the project you're documenting, acts as replacement for\n\t# |version| and |release|, also used in various other places throughout the\n\t# built documents.\n\t#\n\t# version: The short X.Y version.\n\t# release: The full version, including alpha/beta/rc tags.\n\t# If you don’t need the separation provided between version and release,\n\t# just set them both to the same value.\n", "try:\n\t    from datadiligence import __version__ as version\n\texcept ImportError:\n\t    version = \"\"\n\tif not version or version.lower() == \"unknown\":\n\t    version = os.getenv(\"READTHEDOCS_VERSION\", \"unknown\")  # automatically set by RTD\n\trelease = version\n\t# The language for content autogenerated by Sphinx. Refer to documentation\n\t# for a list of supported languages.\n\t# language = None\n", "# There are two options for replacing |today|: either, you set today to some\n\t# non-false value, then it is used:\n\t# today = ''\n\t# Else, today_fmt is used as the format for a strftime call.\n\t# today_fmt = '%B %d, %Y'\n\t# List of patterns, relative to source directory, that match files and\n\t# directories to ignore when looking for source files.\n\texclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\", \".venv\"]\n\t# The reST default role (used for this markup: `text`) to use for all documents.\n\t# default_role = None\n", "# If true, '()' will be appended to :func: etc. cross-reference text.\n\t# add_function_parentheses = True\n\t# If true, the current module name will be prepended to all description\n\t# unit titles (such as .. function::).\n\t# add_module_names = True\n\t# If true, sectionauthor and moduleauthor directives will be shown in the\n\t# output. They are ignored by default.\n\t# show_authors = False\n\t# The name of the Pygments (syntax highlighting) style to use.\n\tpygments_style = \"sphinx\"\n", "# A list of ignored prefixes for module index sorting.\n\t# modindex_common_prefix = []\n\t# If true, keep warnings as \"system message\" paragraphs in the built documents.\n\t# keep_warnings = False\n\t# If this is True, todo emits a warning for each TODO entries. The default is False.\n\ttodo_emit_warnings = True\n\t# -- Options for HTML output -------------------------------------------------\n\t# The theme to use for HTML and HTML Help pages.  See the documentation for\n\t# a list of builtin themes.\n\thtml_theme = \"alabaster\"\n", "# Theme options are theme-specific and customize the look and feel of a theme\n\t# further.  For a list of options available for each theme, see the\n\t# documentation.\n\thtml_theme_options = {\n\t    \"sidebar_width\": \"300px\",\n\t    \"page_width\": \"1200px\"\n\t}\n\t# Add any paths that contain custom themes here, relative to this directory.\n\t# html_theme_path = []\n\t# The name for this set of Sphinx documents.  If None, it defaults to\n", "# \"<project> v<release> documentation\".\n\t# html_title = None\n\t# A shorter title for the navigation bar.  Default is the same as html_title.\n\t# html_short_title = None\n\t# The name of an image file (relative to this directory) to place at the top\n\t# of the sidebar.\n\t# html_logo = \"\"\n\t# The name of an image file (within the static path) to use as favicon of the\n\t# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n\t# pixels large.\n", "# html_favicon = None\n\t# Add any paths that contain custom static files (such as style sheets) here,\n\t# relative to this directory. They are copied after the builtin static files,\n\t# so a file named \"default.css\" will overwrite the builtin \"default.css\".\n\thtml_static_path = [\"_static\"]\n\t# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n\t# using the given strftime format.\n\t# html_last_updated_fmt = '%b %d, %Y'\n\t# If true, SmartyPants will be used to convert quotes and dashes to\n\t# typographically correct entities.\n", "# html_use_smartypants = True\n\t# Custom sidebar templates, maps document names to template names.\n\t# html_sidebars = {}\n\t# Additional templates that should be rendered to pages, maps page names to\n\t# template names.\n\t# html_additional_pages = {}\n\t# If false, no module index is generated.\n\t# html_domain_indices = True\n\t# If false, no index is generated.\n\t# html_use_index = True\n", "# If true, the index is split into individual pages for each letter.\n\t# html_split_index = False\n\t# If true, links to the reST sources are added to the pages.\n\t# html_show_sourcelink = True\n\t# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n\t# html_show_sphinx = True\n\t# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n\t# html_show_copyright = True\n\t# If true, an OpenSearch description file will be output, and all pages will\n\t# contain a <link> tag referring to it.  The value of this option must be the\n", "# base URL from which the finished HTML is served.\n\t# html_use_opensearch = ''\n\t# This is the file name suffix for HTML files (e.g. \".xhtml\").\n\t# html_file_suffix = None\n\t# Output file base name for HTML help builder.\n\thtmlhelp_basename = \"datadiligence-doc\"\n\t# -- Options for LaTeX output ------------------------------------------------\n\tlatex_elements = {\n\t    # The paper size (\"letterpaper\" or \"a4paper\").\n\t    # \"papersize\": \"letterpaper\",\n", "    # The font size (\"10pt\", \"11pt\" or \"12pt\").\n\t    # \"pointsize\": \"10pt\",\n\t    # Additional stuff for the LaTeX preamble.\n\t    # \"preamble\": \"\",\n\t}\n\t# Grouping the document tree into LaTeX files. List of tuples\n\t# (source start file, target name, title, author, documentclass [howto/manual]).\n\tlatex_documents = [\n\t    (\"index\", \"user_guide.tex\", \"datadiligence Documentation\", \"Nick Padgett\", \"manual\")\n\t]\n", "# The name of an image file (relative to this directory) to place at the top of\n\t# the title page.\n\t# latex_logo = \"\"\n\t# For \"manual\" documents, if this is true, then toplevel headings are parts,\n\t# not chapters.\n\t# latex_use_parts = False\n\t# If true, show page references after internal links.\n\t# latex_show_pagerefs = False\n\t# If true, show URL addresses after external links.\n\t# latex_show_urls = False\n", "# Documents to append as an appendix to all manuals.\n\t# latex_appendices = []\n\t# If false, no module index is generated.\n\t# latex_domain_indices = True\n\t# -- External mapping --------------------------------------------------------\n\tpython_version = \".\".join(map(str, sys.version_info[0:2]))\n\tintersphinx_mapping = {\n\t    \"sphinx\": (\"https://www.sphinx-doc.org/en/master\", None),\n\t    \"python\": (\"https://docs.python.org/\" + python_version, None),\n\t    \"matplotlib\": (\"https://matplotlib.org\", None),\n", "    \"numpy\": (\"https://numpy.org/doc/stable\", None),\n\t    \"sklearn\": (\"https://scikit-learn.org/stable\", None),\n\t    \"pandas\": (\"https://pandas.pydata.org/pandas-docs/stable\", None),\n\t    \"scipy\": (\"https://docs.scipy.org/doc/scipy/reference\", None),\n\t    \"setuptools\": (\"https://setuptools.pypa.io/en/stable/\", None),\n\t    \"pyscaffold\": (\"https://pyscaffold.org/en/stable\", None),\n\t}\n\tprint(f\"loading configurations for {project} {version} ...\", file=sys.stderr)\n"]}
{"filename": "src/datadiligence/__init__.py", "chunked_list": ["\"\"\"\n\t    Respect generative AI opt-outs in your ML and training pipeline.\n\t\"\"\"\n\timport sys\n\tif sys.version_info[:2] >= (3, 8):\n\t    # TODO: Import directly (no need for conditional) when `python_requires = >= 3.8`\n\t    from importlib.metadata import PackageNotFoundError, version  # pragma: no cover\n\telse:\n\t    from importlib_metadata import PackageNotFoundError, version  # pragma: no cover\n\ttry:\n", "    # Change here if project is renamed and does not equal the package name\n\t    dist_name = \"datadiligence\"\n\t    __version__ = version(dist_name)\n\texcept PackageNotFoundError:  # pragma: no cover\n\t    __version__ = \"unknown\"\n\tfinally:\n\t    del version, PackageNotFoundError\n\tfrom .evaluators import HttpEvaluator, PostprocessEvaluator, PreprocessEvaluator, Evaluator\n\t# bootstrap methods\n\tfrom .bootstrap import load_defaults, register_evaluator, is_allowed, filter_allowed, get_evaluator, deregister_evaluator, list_evaluators\n"]}
{"filename": "src/datadiligence/utils.py", "chunked_list": ["\"\"\"\n\tUtility functions for package.\n\t\"\"\"\n\timport requests\n\tdef get_url(url, user_agent=None):\n\t    \"\"\"\n\t    Get the URL and return the response object.\n\t    Args:\n\t        url (str): The URL to get.\n\t        user_agent (str): The user agent to use.\n", "    Returns:\n\t        requests.Response: The response object.\n\t    \"\"\"\n\t    # TODO: add a cache so requests aren't made twice for the same URL\n\t    if not user_agent:\n\t        user_agent = requests.utils.default_user_agent()\n\t    session = requests.Session()\n\t    return session.get(url, headers={\"User-Agent\": user_agent}, timeout=10)\n"]}
{"filename": "src/datadiligence/exceptions.py", "chunked_list": ["\"\"\"\n\tExceptions for the package.\n\t\"\"\"\n\tclass XRobotsTagNoParam(Exception):\n\t    \"\"\"\n\t    Raised when XRobotsTagHeader isn't provided with either an url, response, or headers object.\n\t    \"\"\"\n\t    def __init__(self):\n\t        super().__init__(\"XRobotsTagHeader must be provided with either an url, response, or headers object.\")\n\tclass TDMRepNoParam(Exception):\n", "    \"\"\"\n\t    Raised when TDMRepHeader isn't provided with either an url, response, or headers object.\n\t    \"\"\"\n\t    def __init__(self):\n\t        super().__init__(\"TDMRepHeader must be provided with either an url, response, or headers object.\")\n\tclass HttpUnknownHeaderObject(Exception):\n\t    \"\"\"\n\t    Raised when an HTTPRule is provided with an unknown header object.\n\t    \"\"\"\n\t    def __init__(self):\n", "        super().__init__(\n\t            \"HTTPRule must be provided with a header object of types \"\n\t            \"dict|CaseInsensitiveDict|http.client.HTTPMessage.\")\n\tclass HttpUnknownResponseObject(Exception):\n\t    \"\"\"\n\t    Raised when HTTPRule is provided with an unknown response object.\n\t    \"\"\"\n\t    def __init__(self):\n\t        super().__init__(\n\t            \"HTTPRule must be provided with a response object of types \"\n", "            \"http.client.HTTPResponse|requests.Response.\")\n\tclass SpawningAIAPIError(Exception):\n\t    \"\"\"\n\t    Raised when the Spawning AI API returns an error.\n\t    \"\"\"\n\t    def __init__(self, message):\n\t        super().__init__(message)\n\tclass EvaluatorNotRegistered(Exception):\n\t    \"\"\"\n\t    Raised when an evaluator is not registered.\n", "    \"\"\"\n\t    def __init__(self, name):\n\t        super().__init__(f\"Evaluator {name} not registered.\")\n\tclass DefaultEvaluatorNotFound(Exception):\n\t    \"\"\"\n\t    Raised when aa default evaluator can't be determined.\n\t    \"\"\"\n\t    def __init__(self, args):\n\t        super().__init__(f\"No default evaluator found which can handle the following arguments {args}.\")\n\tclass NotEvaluator(Exception):\n", "    \"\"\"\n\t    Raised when an object is not an evaluator.\n\t    \"\"\"\n\t    def __init__(self):\n\t        super().__init__(\"Object must be of type Evaluator.\")\n\tclass EvaluatorAlreadyRegistered(Exception):\n\t    \"\"\"\n\t    Raised when an evaluator is already registered.\n\t    \"\"\"\n\t    def __init__(self, name):\n", "        super().__init__(f\"Evaluator {name} already registered.\")\n\tclass SpawningNoParam(Exception):\n\t    \"\"\"\n\t    Raised when SpawningAPI isn't provided with a list of urls.\n\t    \"\"\"\n\t    def __init__(self):\n\t        super().__init__(\"SpawningAPI must be provided with a list of urls.\")\n"]}
{"filename": "src/datadiligence/bootstrap.py", "chunked_list": ["\"\"\"\n\tfunctions to preload default evaluators and make accessible globally\n\t\"\"\"\n\tfrom .exceptions import EvaluatorAlreadyRegistered, EvaluatorNotRegistered, NotEvaluator, DefaultEvaluatorNotFound\n\tfrom .evaluators import Evaluator, PreprocessEvaluator, PostprocessEvaluator\n\tbootstrap_dictionary = {}\n\tdef load_defaults(user_agent=None):\n\t    \"\"\"Load the default evaluators.\"\"\"\n\t    register_evaluator(PreprocessEvaluator(user_agent=user_agent), overwrite=True)\n\t    register_evaluator(PostprocessEvaluator(user_agent=user_agent), overwrite=True)\n", "def list_evaluators():\n\t    \"\"\"List the evaluators.\"\"\"\n\t    return list(bootstrap_dictionary.keys())\n\tdef register_evaluator(evaluator, name=None, overwrite=False):\n\t    \"\"\"Register an evaluator.\n\t    Args:\n\t        evaluator (Evaluator): The evaluator object.\n\t        name (str): Key name of the evaluator.\n\t        overwrite (bool): Whether or not to overwrite the evaluator if it already exists.\n\t    \"\"\"\n", "    if not name:\n\t        name = evaluator.name\n\t    if not isinstance(evaluator, Evaluator):\n\t        raise NotEvaluator()\n\t    if name in bootstrap_dictionary and not overwrite:\n\t        raise EvaluatorAlreadyRegistered(name)\n\t    bootstrap_dictionary[name] = evaluator\n\tdef deregister_evaluator(name):\n\t    \"\"\"Deregister an evaluator.\n\t    Args:\n", "        name (str): The name of the evaluator.\n\t    \"\"\"\n\t    if name not in bootstrap_dictionary:\n\t        raise EvaluatorNotRegistered(name)\n\t    del bootstrap_dictionary[name]\n\tdef get_evaluator(name):\n\t    \"\"\"Get an evaluator.\n\t    Args:\n\t        name (str): The name of the evaluator.\n\t    \"\"\"\n", "    if name not in bootstrap_dictionary:\n\t        raise EvaluatorNotRegistered(name)\n\t    return bootstrap_dictionary[name]\n\tdef is_allowed(name=None, **kwargs):\n\t    \"\"\"\n\t    Check if the content is allowed.\n\t    Args:\n\t        name (str): The name of a specific evaluator.\n\t        **kwargs: Arbitrary keyword arguments to read args from.\n\t    \"\"\"\n", "    if name is not None:\n\t        if name not in bootstrap_dictionary:\n\t            raise EvaluatorNotRegistered(name)\n\t        return bootstrap_dictionary[name].is_allowed(**kwargs)\n\t    else:\n\t        # since we are preloading evaluators manually, we can check to see which one to call\n\t        # based on the kwargs\n\t        if \"urls\" in kwargs:\n\t            return bootstrap_dictionary[\"preprocess\"].is_allowed(**kwargs)\n\t        elif \"url\" in kwargs or \"response\" in kwargs or \"headers\" in kwargs:\n", "            return bootstrap_dictionary[\"postprocess\"].is_allowed(**kwargs)\n\t        else:\n\t            raise DefaultEvaluatorNotFound(list(kwargs.keys()))\n\tdef filter_allowed(name=None, **kwargs):\n\t    \"\"\"\n\t    Filter a list of content.\n\t    Args:\n\t        name (str): The name of a specific evaluator.\n\t        **kwargs: Arbitrary keyword arguments to read args from.\n\t    \"\"\"\n", "    if name is not None:\n\t        if name not in bootstrap_dictionary:\n\t            raise EvaluatorNotRegistered(name)\n\t        return bootstrap_dictionary[name].filter_allowed(**kwargs)\n\t    else:\n\t        # since we are preloading evaluators manually, we can check to see which one to call\n\t        # based on the kwargs\n\t        if \"urls\" in kwargs:\n\t            return bootstrap_dictionary[\"preprocess\"].filter_allowed(**kwargs)\n\t        else:\n", "            raise DefaultEvaluatorNotFound(list(kwargs.keys()))\n\tload_defaults()\n"]}
{"filename": "src/datadiligence/rules/base.py", "chunked_list": ["import http.client\n\timport requests.structures\n\tfrom ..exceptions import HttpUnknownHeaderObject, HttpUnknownResponseObject\n\tfrom ..utils import get_url\n\t\"\"\"\n\tThis module contains the base rule classes.\n\t\"\"\"\n\tclass Rule:\n\t    \"\"\"\n\t    Base class for rules. is_allowed and is_ready must be implemented.\n", "    \"\"\"\n\t    def is_allowed(self, **kwargs):\n\t        \"\"\"Check if the request is allowed. Must be implemented.\n\t        Args:\n\t            **kwargs: Arbitrary keyword arguments to read args from.\n\t        \"\"\"\n\t        raise NotImplementedError\n\t    def is_ready(self):\n\t        \"\"\"Check if the rule is ready to be used.\"\"\"\n\t        raise NotImplementedError\n", "class BulkRule(Rule):\n\t    \"\"\"\n\t    Base class for bulk rules. filter_allowed and is_ready must be implemented.\n\t    \"\"\"\n\t    def filter_allowed(self, **kwargs):\n\t        \"\"\"Filter a list of entries based on the rules in this evaluator.\"\"\"\n\t        raise NotImplementedError\n\tclass HttpRule(Rule):\n\t    def __init__(self, user_agent=None):\n\t        \"\"\"Initialize the rule with a user agent.\n", "        Args:\n\t            user_agent (str): The user agent to pass on to the rules.\n\t        \"\"\"\n\t        super().__init__()\n\t        self.user_agent = user_agent\n\t    def get_header_value(self, headers, header_name):\n\t        \"\"\"\n\t        Handle the headers object to get the header value.\n\t        Args:\n\t            headers (dict|http.client.HTTPMessage|CaseInsensitiveDict): The headers object.\n", "            header_name (str): The header name.\n\t        Returns:\n\t            str: The header value.\n\t        \"\"\"\n\t        if type(headers) == dict or type(headers) == requests.structures.CaseInsensitiveDict:\n\t            header_value = headers.get(header_name, \"\")\n\t        elif type(headers) == list and len(headers) > 0 and type(headers[0]) == tuple:\n\t            header_value = dict(headers).get(header_name, \"\")\n\t        elif type(headers) == http.client.HTTPMessage:\n\t            header_value = headers.get(header_name, \"\")\n", "        else:\n\t            raise HttpUnknownHeaderObject()\n\t        return header_value\n\t    def is_ready(self):\n\t        \"\"\"\n\t        These rules should always be ready.\n\t        \"\"\"\n\t        return True\n\t    def _handle_url(self, url):\n\t        \"\"\"\n", "        If given a raw URL, submit a request to get the image.\n\t        Args:\n\t            url (str): The URL of the resource.\n\t        Returns:\n\t            requests.Response: Response object.\n\t        \"\"\"\n\t        return get_url(url, user_agent=self.user_agent)\n\t    def get_header_value_from_response(self, response, header_name):\n\t        \"\"\"\n\t        Handle the response object to get the header value.\n", "        Args:\n\t            response (http.client.HTTPResponse|requests.Response): The response object.\n\t            header_name (str): The header name.\n\t        Returns:\n\t            str: The header value.\n\t        \"\"\"\n\t        if type(response) == http.client.HTTPResponse:\n\t            header_value = response.getheader(header_name, \"\")\n\t        elif type(response) == requests.Response:\n\t            header_value = response.headers.get(header_name, \"\")\n", "        else:\n\t            raise HttpUnknownResponseObject()\n\t        return header_value\n"]}
{"filename": "src/datadiligence/rules/c2pa.py", "chunked_list": ["\"\"\"\n\tThis module contains the C2PA Metadata Rule class.\n\t\"\"\"\n\tfrom .base import HttpRule\n\t# TODO: Implement, either with wrapper for CLI or python implementation of C2PA\n\tclass C2PAMetadataRule(HttpRule):\n\t    \"\"\"\n\t    This class wraps calls to the Adobe Content Authenticity Initiative c2pa tool. TODO.\n\t    \"\"\"\n\t    def is_allowed(self, url=None, response=None, body=None, **kwargs):\n", "        return True\n\t    def is_ready(self):\n\t        return False\n"]}
{"filename": "src/datadiligence/rules/__init__.py", "chunked_list": ["\"\"\"\n\tThis module contains default Rules.\n\t\"\"\"\n\tfrom .base import *\n\tfrom .spawning import *\n\tfrom .http import *\n\tfrom .c2pa import *\n"]}
{"filename": "src/datadiligence/rules/spawning.py", "chunked_list": ["\"\"\"\n\tThis module wraps HTTP calls to the Spawning AI API.\n\tSee Spawning API documentation here: https://opts-api.spawningaiapi.com/docs.\n\t\"\"\"\n\timport requests\n\timport requests.utils\n\tfrom requests.adapters import HTTPAdapter, Retry\n\timport aiohttp\n\timport asyncio\n\timport os\n", "from ..exceptions import SpawningAIAPIError, SpawningNoParam\n\tfrom .base import BulkRule\n\tfrom concurrent.futures import ThreadPoolExecutor, wait\n\timport itertools\n\timport sys\n\tclass SpawningAPI(BulkRule):\n\t    \"\"\"\n\t    This class wraps basic requests to the Spawning API.\n\t    \"\"\"\n\t    API_KEY_ENV_VAR = \"SPAWNING_OPTS_KEY\"\n", "    MAX_CHUNK_SIZE = 10000\n\t    SPAWNING_AI_API_URL = \"https://opts-api.spawningaiapi.com/api/v2/query/urls/\"\n\t    DEFAULT_TIMEOUT = 20\n\t    MAX_CONCURRENT_REQUESTS = 10\n\t    def __init__(self, user_agent=None, chunk_size=MAX_CHUNK_SIZE, timeout=DEFAULT_TIMEOUT, max_retries=5,\n\t                 max_concurrent_requests=MAX_CONCURRENT_REQUESTS):\n\t        \"\"\"Create a new SpawningAPI BulkRole instance.\n\t        Args:\n\t            user_agent (str): The user agent to use when making requests to the Spawning AI API.\n\t            chunk_size (int): The maximum number of URLs to submit in a single request.\n", "            timeout (int): The maximum number of seconds to wait for a response from the Spawning AI API.\n\t            max_retries (int): The maximum number of times to retry a request to the Spawning AI API.\n\t            max_concurrent_requests (int): The maximum number of concurrent requests to the Spawning AI API.\n\t        \"\"\"\n\t        super().__init__()\n\t        # check if API key is installed\n\t        self.api_key = os.environ.get(SpawningAPI.API_KEY_ENV_VAR, \"\")\n\t        if not self.api_key:\n\t            print(\n\t                \"Spawning API key not found. Please set your API key to the environment variable \"\n", "                + SpawningAPI.API_KEY_ENV_VAR\n\t            )\n\t        if user_agent is None:\n\t            self.user_agent = requests.utils.default_user_agent()\n\t        else:\n\t            self.user_agent = user_agent\n\t        self.max_retries = max_retries\n\t        if chunk_size > self.MAX_CHUNK_SIZE or chunk_size is None:\n\t            chunk_size = self.MAX_CHUNK_SIZE\n\t        self.chunk_size = chunk_size\n", "        if timeout < 0 or timeout is None:\n\t            timeout = self.DEFAULT_TIMEOUT\n\t        self.timeout = timeout\n\t        if max_concurrent_requests <= 0 \\\n\t                or max_concurrent_requests > self.MAX_CONCURRENT_REQUESTS \\\n\t                or max_concurrent_requests is None:\n\t            max_concurrent_requests = self.MAX_CONCURRENT_REQUESTS\n\t        self.max_concurrent_requests = max_concurrent_requests\n\t    def filter_allowed(self, urls=None, url=None, **kwargs):\n\t        \"\"\"Submit a list of URLs to the Spawning AI API.\n", "        Args:\n\t            urls (list): A list of URLs to submit.\n\t            url (str): A single URL to submit.\n\t        Returns:\n\t            list: A list containing the allowed urls of the submission.\n\t        \"\"\"\n\t        if urls is None:\n\t            if url is not None:\n\t                urls = [url]\n\t            else:\n", "                raise SpawningNoParam()\n\t        results = []\n\t        # thread pool executor to submit chunks in parallel\n\t        with ThreadPoolExecutor(max_workers=self.max_concurrent_requests) as executor:\n\t            futures = [executor.submit(self._submit_chunk, chunk) for chunk in self._chunk(urls)]\n\t            wait(futures)\n\t            for future in futures:\n\t                results.extend([response_url[\"url\"] for response_url in future.result() if not response_url[\"optOut\"]])\n\t        return results\n\t    def is_allowed(self, urls=None, url=None, **kwargs):\n", "        \"\"\"Submit a list of URLs to the Spawning AI API.\n\t        Args:\n\t            urls (list): A list of URLs to submit.\n\t            url (str): A single URL to submit.\n\t        Returns:\n\t            list: A list containing booleans, indicating if a respective URL is allowed.\n\t        \"\"\"\n\t        if urls is None:\n\t            if url is not None:\n\t                urls = [url]\n", "            else:\n\t                raise SpawningNoParam()\n\t        results = []\n\t        # thread pool executor to submit chunks in parallel\n\t        with ThreadPoolExecutor(max_workers=self.max_concurrent_requests) as executor:\n\t            futures = [executor.submit(self._submit_chunk, chunk) for chunk in self._chunk(urls)]\n\t            wait(futures)\n\t            for future in futures:\n\t                results.extend([not response_url[\"optOut\"] for response_url in future.result()])\n\t        return results\n", "    async def filter_allowed_async(self, urls=None, url=None, **kwargs):\n\t        \"\"\"Submit a list of URLs to the Spawning AI API.\n\t        Args:\n\t            urls (list): A list of URLs to submit.\n\t            url (str): A single URL to submit.\n\t        Returns:\n\t            list: A list containing the allowed URLs.\n\t        \"\"\"\n\t        if urls is None:\n\t            if url is not None:\n", "                urls = [url]\n\t            else:\n\t                raise SpawningNoParam()\n\t        results = await self._submit_chunks_async(urls)\n\t        results = [response_url[\"url\"] for response_url in results if not response_url[\"optOut\"]]\n\t        return results\n\t    async def is_allowed_async(self, urls=None, url=None, **kwargs):\n\t        \"\"\"Submit a list of URLs to the Spawning AI API.\n\t        Args:\n\t            urls (list): A list of URLs to submit.\n", "            url (str): A single URL to submit.\n\t        Returns:\n\t            list: A list of boolean values indicating if a URL is allowed to be used or not.\n\t        \"\"\"\n\t        if urls is None:\n\t            if url is not None:\n\t                urls = [url]\n\t            else:\n\t                raise SpawningNoParam()\n\t        results = await self._submit_chunks_async(urls)\n", "        results = [not response_url[\"optOut\"] for response_url in results]\n\t        return results\n\t    def is_ready(self):\n\t        \"\"\"Check if the Spawning AI API is ready to be used. This is determined by whether or not the API key is set.\n\t        Returns:\n\t            bool: True if the API key is set, False otherwise.\n\t        \"\"\"\n\t        return bool(self.api_key)\n\t    def _chunk(self, urls):\n\t        \"\"\"Generator to split a list of URLs into chunks.\n", "        Args:\n\t            urls (list): A list of URLs to split into chunks.\n\t        Yields:\n\t            list: A list of URLs.\n\t        \"\"\"\n\t        for i in range(0, len(urls), self.chunk_size):\n\t            yield urls[i:i + self.chunk_size]\n\t    async def _submit_chunks_async(self, urls):\n\t        \"\"\"Submit a list of URLs to the Spawning AI API.\n\t        Args:\n", "            urls (list): A list of URLs to submit.\n\t        Returns:\n\t            list: A list containing the result dicts of the submission.\n\t        \"\"\"\n\t        # build out http tasks\n\t        tasks = []\n\t        headers = {\n\t            \"User-Agent\": self.user_agent,\n\t            \"Content-Type\": \"text/plain\",\n\t            \"Authorization\": \"API \" + self.api_key\n", "        }\n\t        semaphore = asyncio.Semaphore(self.max_concurrent_requests)\n\t        async with aiohttp.ClientSession(headers=headers) as session:\n\t            # if 3.6 or earlier, run create_task from loop\n\t            if sys.version_info < (3, 7):\n\t                loop = asyncio.get_event_loop()\n\t                for chunk in self._chunk(urls):\n\t                    tasks.append(loop.create_task(self._submit_chunk_async(session, semaphore, chunk)))\n\t            else:\n\t                for chunk in self._chunk(urls):\n", "                    tasks.append(asyncio.create_task(self._submit_chunk_async(session, semaphore, chunk)))\n\t            results = await asyncio.gather(*tasks)\n\t        # flatten\n\t        return [response_url for response_url in itertools.chain(*results)]\n\t    async def _submit_chunk_async(self, session, semaphore, urls):\n\t        \"\"\"Submit a chunk of URLs to the Spawning AI API asynchronously.\n\t        Args:\n\t            session (aiohttp.ClientSession): The aiohttp session to use.\n\t            urls (list): A list of URLs to submit.\n\t        Returns:\n", "            list: A list containing the result dicts of the submission.\n\t        \"\"\"\n\t        # limit concurrent requests\n\t        async with semaphore:\n\t            # create body\n\t            body = \"\\n\".join(urls).encode(\"utf-8\")\n\t            # make request\n\t            async with session.post(self.SPAWNING_AI_API_URL, data=body) as response:\n\t                try:\n\t                    if response.status != 200:\n", "                        raise SpawningAIAPIError(\"Spawning AI API returned a non-200 status code: \" +\n\t                                                 str(response.status))\n\t                    results = await response.json()\n\t                    return results.get(\"urls\", [])\n\t                except Exception as e:\n\t                    raise SpawningAIAPIError(e)\n\t    def _submit_chunk(self, urls):\n\t        \"\"\"Submit a chunk of URLs to the Spawning AI API.\n\t        Args:\n\t            urls (list): A list of URLs to submit.\n", "        Returns:\n\t            list: A list containing the result dicts of the submission.\n\t        \"\"\"\n\t        # create body\n\t        body = \"\\n\".join(urls).encode(\"utf-8\")\n\t        # make request\n\t        try:\n\t            s = requests.Session()\n\t            retries = Retry(total=self.max_retries, backoff_factor=0.1, status_forcelist=[429, 500, 502, 503, 504])\n\t            s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n", "            response = s.post(self.SPAWNING_AI_API_URL,\n\t                              data=body,\n\t                              headers={\n\t                                  \"User-Agent\": self.user_agent,\n\t                                  \"Content-Type\": \"text/plain\",\n\t                                  \"Authorization\": \"API \" + self.api_key\n\t                              },\n\t                              timeout=self.timeout\n\t                              )\n\t            if response.status_code != 200:\n", "                raise SpawningAIAPIError(\"Spawning AI API returned a non-200 status code: \" + str(response.status_code))\n\t            return response.json().get(\"urls\", [])\n\t        except Exception as e:\n\t            raise SpawningAIAPIError(e)\n"]}
{"filename": "src/datadiligence/rules/http.py", "chunked_list": ["\"\"\"\n\tRules to manage validation using HTTP properties\n\t\"\"\"\n\tfrom ..exceptions import XRobotsTagNoParam, TDMRepNoParam\n\tfrom .base import HttpRule\n\tclass XRobotsTagHeader(HttpRule):\n\t    \"\"\"\n\t    This class wraps logic to read the X-Robots-Tag header.\n\t    \"\"\"\n\t    AI_DISALLOWED_VALUES = [\"noai\", \"noimageai\"]\n", "    INDEX_DISALLOWED_VALUES = [\"noindex\", \"none\", \"noimageindex\", \"noai\", \"noimageai\"]\n\t    HEADER_NAME = \"X-Robots-Tag\"\n\t    def __init__(self, user_agent=None, respect_noindex=False):\n\t        \"\"\"Create a new XRobotsTagHeader instance.\n\t        Args:\n\t            user_agent (str): The user agent to use when making requests to the Spawning AI API.\n\t            respect_noindex (bool): If True, index rules will be respected alongside AI rules.\n\t        \"\"\"\n\t        super().__init__(user_agent=user_agent)\n\t        # index rules aren't for AI, so we ignore them by default.\n", "        # They could have been delivered/found by any number of other means, even for internal use\n\t        if respect_noindex:\n\t            self.disallowed_headers = self.INDEX_DISALLOWED_VALUES\n\t        else:\n\t            self.disallowed_headers = self.AI_DISALLOWED_VALUES\n\t    def is_allowed(self, url=None, response=None, headers=None, **kwargs):\n\t        \"\"\"Check if the X-Robots-Tag header allows the user agent to access the resource.\n\t        Args:\n\t            url: (str): The URL of the resource.\n\t            response (http.client.HTTPResponse|requests.Response, optional): The response object. Defaults to None\n", "            headers (dict|http.client.HTTPMessage, optional): The headers dictionary. Defaults to None.\n\t        Returns:\n\t            bool: True if the user agent is allowed to access the resource, False otherwise.\n\t        \"\"\"\n\t        if headers:\n\t            header_value = self.get_header_value(headers, self.HEADER_NAME)\n\t        elif response:\n\t            header_value = self.get_header_value_from_response(response, self.HEADER_NAME)\n\t        elif url:\n\t            response = self._handle_url(url)\n", "            header_value = self.get_header_value(response.headers, self.HEADER_NAME)\n\t        else:\n\t            raise XRobotsTagNoParam()\n\t        return self._eval_header_value(header_value, **kwargs)\n\t    def _eval_header_value(self, header_value, user_agent=None, **kwargs):\n\t        \"\"\"\n\t        Evaluate the header value to determine if the user agent is allowed to access the resource.\n\t        Args:\n\t            header_value (str): The header value.\n\t            user_agent (str): Override user agent to use when making requests to the Spawning AI API.\n", "        Returns:\n\t            bool: True if the user agent is allowed to access the resource, False otherwise.\n\t        \"\"\"\n\t        if not header_value:\n\t            return True\n\t        # if we have a specific user agent\n\t        if not user_agent:\n\t            user_agent = self.user_agent\n\t        # check if blocking all user agents\n\t        for value in header_value.split(\",\"):\n", "            if value.strip() in self.disallowed_headers:\n\t                return False\n\t            # check if blocking specific user agent\n\t            if user_agent:\n\t                ua_values = value.split(\":\")\n\t                if len(ua_values) == 2 and ua_values[0].strip() == user_agent \\\n\t                        and ua_values[1].strip() in self.disallowed_headers:\n\t                    return False\n\t        return True\n\tclass TDMRepHeader(HttpRule):\n", "    \"\"\"\n\t    This class wraps logic to evaluate the TDM Reservation Protocol headers: https://www.w3.org/2022/tdmrep/.\n\t    \"\"\"\n\t    HEADER_NAME = \"tdm-reservation\"\n\t    def __init__(self):\n\t        \"\"\"Create a new TDMRepHeaders instance.\"\"\"\n\t        super().__init__()\n\t    def is_allowed(self, url=None, response=None, headers=None, **kwargs):\n\t        \"\"\"Check if the tdm-rep header allows access to the resource without a policy.\n\t        Args:\n", "            url: (str): The URL of the resource.\n\t            response (http.client.HTTPResponse|requests.Response, optional): The response object. Defaults to None\n\t            headers (dict|http.client.HTTPMessage, optional): The headers dictionary. Defaults to None.\n\t        Returns:\n\t            bool: True if access is allowed for the resource, False otherwise.\n\t        \"\"\"\n\t        if headers:\n\t            header_value = self.get_header_value(headers, self.HEADER_NAME)\n\t        elif response:\n\t            header_value = self.get_header_value_from_response(response, self.HEADER_NAME)\n", "        elif url:\n\t            response = self._handle_url(url)\n\t            header_value = self.get_header_value(response.headers, self.HEADER_NAME)\n\t        else:\n\t            raise TDMRepNoParam()\n\t        return self._eval_header_value(header_value, **kwargs)\n\t    def _eval_header_value(self, header_value, **kwargs):\n\t        \"\"\"\n\t        Evaluate the header value to determine if the resource permits anonymous access.\n\t        Args:\n", "            header_value (str): The header value.\n\t        Returns:\n\t            bool: True if resource allows access without a policy, False otherwise.\n\t        \"\"\"\n\t        if not header_value:\n\t            return True\n\t        print(\"HERE\")\n\t        print(header_value)\n\t        return header_value.strip() != \"1\"\n"]}
{"filename": "src/datadiligence/evaluators/base.py", "chunked_list": ["\"\"\"\n\tThis module contains the base Evaluator class.\n\t\"\"\"\n\tfrom ..rules import Rule\n\tclass Evaluator:\n\t    \"\"\"\n\t    Base class for evaluators. is_allowed must be implemented.\n\t    \"\"\"\n\t    name = \"base_evaluator\"\n\t    def __init__(self):\n", "        self.rules = []\n\t    def add_rule(self, rule):\n\t        \"\"\"Add a rule to the evaluator.\"\"\"\n\t        if isinstance(rule, Rule):\n\t            self.rules.append(rule)\n\t    def is_allowed(self, **kwargs):\n\t        \"\"\"Check each rule to see if the request is allowed.\n\t        Args:\n\t            **kwargs (any): Keyword args to pass to rule\n\t        Returns:\n", "            bool: True if the content is allowed, False otherwise.\n\t        \"\"\"\n\t        for rule in self.rules:\n\t            if rule.is_ready() and not rule.is_allowed(**kwargs):\n\t                return False\n\t        return True\n\t    def filter_allowed(self, **kwargs):\n\t        \"\"\"Filter a list of entries based on the rules in this evaluator.\"\"\"\n\t        raise NotImplementedError\n"]}
{"filename": "src/datadiligence/evaluators/__init__.py", "chunked_list": ["\"\"\"\n\tThis module contains default Evaluators.\n\t\"\"\"\n\tfrom .base import Evaluator\n\tfrom .http import HttpEvaluator\n\tfrom .postprocess import PostprocessEvaluator\n\tfrom .preprocess import PreprocessEvaluator\n"]}
{"filename": "src/datadiligence/evaluators/preprocess.py", "chunked_list": ["\"\"\"\n\tThis module contains the PreprocessEvaluator class.\n\t\"\"\"\n\tfrom .base import Evaluator\n\tfrom ..rules import SpawningAPI, BulkRule\n\tclass PreprocessEvaluator(Evaluator):\n\t    \"\"\"\n\t    Preprocess Evaluator class. Loads SpawningAPI rule by default.\n\t    \"\"\"\n\t    name = \"preprocess\"\n", "    def __init__(self, user_agent=None):\n\t        \"\"\" Load the default rules.\n\t        Args:\n\t            user_agent (str): The user agent to pass on to the rules.\n\t        \"\"\"\n\t        super().__init__()\n\t        self.add_rule(SpawningAPI(user_agent))\n\t    def add_rule(self, rule):\n\t        \"\"\"Add a rule to the evaluator.\"\"\"\n\t        if issubclass(rule.__class__, BulkRule):\n", "            self.rules.append(rule)\n\t    def filter_allowed(self, urls=None, **kwargs):\n\t        \"\"\"Filter a list of urls based on the rules in this evaluator.\n\t        Args:\n\t            urls (list): A list of urls to filter.\n\t            **kwargs: Arbitrary keyword arguments to read args from.\n\t        Returns:\n\t            list: A list of urls that are allowed.\n\t        \"\"\"\n\t        if urls is None:\n", "            return []\n\t        allowed = urls\n\t        for rule in self.rules:\n\t            # if everything is already filtered out, stop\n\t            if len(allowed) == 0:\n\t                break\n\t            if rule.is_ready():\n\t                allowed = rule.filter_allowed(urls=allowed, **kwargs)\n\t        return allowed\n\t    def is_allowed(self, urls=None, **kwargs):\n", "        \"\"\"\n\t        Check if the urls are allowed.\n\t        Args:\n\t            urls (list): A list of urls to check.\n\t            **kwargs: Arbitrary keyword arguments to read args from.\n\t        Returns:\n\t            bool: List of boolean values, respectively indicating if can be used or not\n\t        \"\"\"\n\t        if urls is None:\n\t            return []\n", "        allowed = [True] * len(urls)\n\t        for rule in self.rules:\n\t            if rule.is_ready():\n\t                rule_results = rule.is_allowed(urls=urls, **kwargs)\n\t                # update allowed list to False only if rule_results is False\n\t                allowed = [a and b for a, b in zip(allowed, rule_results)]\n\t        return allowed\n"]}
{"filename": "src/datadiligence/evaluators/http.py", "chunked_list": ["\"\"\"\n\tThis module contains the HttpEvaluator class.\n\t\"\"\"\n\tfrom .base import Evaluator\n\tfrom ..rules import XRobotsTagHeader, TDMRepHeader\n\tclass HttpEvaluator(Evaluator):\n\t    \"\"\"\n\t    HTTP Evaluator class. Loads XRobotsTagHeader rule by default.\n\t    \"\"\"\n\t    name = \"http\"\n", "    def __init__(self, user_agent=None, respect_robots=True, respect_tdmrep=True):\n\t        \"\"\"Load the default rules.\n\t        Args:\n\t            user_agent (str): The user agent to pass on to the rules.\n\t            respect_robots (bool): Whether to respect the X-Robots-Tag header.\n\t            respect_tdmrep (bool): Whether to respect the TDMRep header.\n\t        \"\"\"\n\t        super().__init__()\n\t        if respect_robots:\n\t            self.rules.append(XRobotsTagHeader(user_agent))\n", "        if respect_tdmrep:\n\t            self.rules.append(TDMRepHeader())\n"]}
{"filename": "src/datadiligence/evaluators/postprocess.py", "chunked_list": ["\"\"\"Postprocess evaluator module.\"\"\"\n\tfrom .base import Evaluator\n\tfrom ..rules import XRobotsTagHeader, TDMRepHeader\n\tclass PostprocessEvaluator(Evaluator):\n\t    \"\"\"\n\t    Postprocess Evaluator class. Loads XRobotsTagHeader rule by default.\n\t    \"\"\"\n\t    name = \"postprocess\"\n\t    def __init__(self, user_agent=None):\n\t        super().__init__()\n", "        self.add_rule(XRobotsTagHeader(user_agent))\n\t        self.add_rule(TDMRepHeader())\n\t    def is_allowed(self, **kwargs):\n\t        \"\"\"Check if the headers are allowed based on the rules in this evaluator.\n\t        Args:\n\t            **response (http.client.HTTPResponse|requests.Response): The response object.\n\t            **headers (dict|http.client.HTTPMessage): The headers dictionary.\n\t        Returns:\n\t            bool: True if the content is allowed, False otherwise.\n\t        \"\"\"\n", "        for rule in self.rules:\n\t            if rule.is_ready() and not rule.is_allowed(**kwargs):\n\t                return False\n\t        return True\n"]}
