{"filename": "src/inn_service/settings.py", "chunked_list": ["from typing import Optional\n\tfrom pydantic import BaseSettings\n\tclass Settings(BaseSettings):\n\t    app_name: str = 'INN service'\n\t    app_request_retry_times: int  # Количество попыток обработки внешнего запроса\n\t    app_request_retry_sec: int  # Время задержки в секундах перед повторной обработкой запроса\n\t    http_host: str\n\t    http_port: int\n\t    http_handler: str = 'asyncio'\n\t    mongo_host: str\n", "    mongo_port: str\n\t    mongo_user: str\n\t    mongo_pass: str\n\t    mongo_name: str\n\t    mongo_rs: Optional[str] = None\n\t    mongo_auth: str\n\t    mongo_timeout_server_select: int = 5000\n\t    rabbitmq_host: str\n\t    rabbitmq_port: int\n\t    rabbitmq_user: str\n", "    rabbitmq_pass: str\n\t    rabbitmq_vhost: str\n\t    rabbitmq_exchange_type: str\n\t    rabbitmq_prefetch_count: int\n\t    rabbitmq_source_queue_name: str\n\t    client_nalog_url: str  # Адрес внешнего сервиса для получения ИНН\n\t    client_nalog_timeout_sec: int  # Таймаут ожидания ответа от сервиса\n\t    client_nalog_retries: int  # Количество попыток запросов к внешнему сервису\n\t    client_nalog_wait_sec: int  # Время ожидания между попытками client_nalog_retries\n\t    @property\n", "    def mongo_dsn(self) -> str:\n\t        mongo_dsn = 'mongodb://{}:{}@{}:{}/{}'.format(\n\t            self.mongo_user,\n\t            self.mongo_pass,\n\t            self.mongo_host,\n\t            self.mongo_port,\n\t            self.mongo_auth\n\t        )\n\t        if self.mongo_rs:\n\t            mongo_dsn += f'?replicaSet={self.mongo_rs}'\n", "        return mongo_dsn\n\t    @property\n\t    def rabbitmq_dsn(self) -> str:\n\t        return 'amqp://{}:{}@{}:{}/{}'.format(\n\t            self.rabbitmq_user,\n\t            self.rabbitmq_pass,\n\t            self.rabbitmq_host,\n\t            self.rabbitmq_port,\n\t            self.rabbitmq_vhost\n\t        )\n"]}
{"filename": "src/inn_service/main.py", "chunked_list": ["import typer\n\tfrom core.application import Application\n\tfrom app_container import ApplicationContainer\n\tdef main():\n\t    try:\n\t        application = Application(ApplicationContainer)\n\t        application.run()\n\t    except BaseException as exc:\n\t        typer.echo(f'Error starting application. Details: {str(exc)}')\n\tif __name__ == \"__main__\":\n", "    typer.run(main)\n"]}
{"filename": "src/inn_service/logger.py", "chunked_list": ["import datetime\n\timport json\n\timport logging\n\timport traceback\n\tfrom collections import OrderedDict\n\tclass AppLogger:\n\t    def __init__(self, logger: logging.Logger) -> None:\n\t        self._logger = logger\n\t    def _is_jsonible(self, object_type) -> bool:\n\t        return isinstance(object_type, (list, tuple, str, int, float, bool, type(None)))\n", "    def _format_kwargs(self, kwargs):\n\t        _kwargs = {}\n\t        for k, v in kwargs.items():\n\t            if self._is_jsonible(v):\n\t                _kwargs[k] = v\n\t            elif isinstance(v, (set, frozenset)):\n\t                _kwargs[k] = list(v)\n\t            elif isinstance(v, (dict, OrderedDict)):\n\t                _kwargs[k] = self._format_kwargs(v)\n\t            elif isinstance(v, (datetime.datetime, datetime.date)):\n", "                _kwargs[k] = v.isoformat()\n\t            else:\n\t                try:\n\t                    _kwargs[k] = str(v)\n\t                except Exception as e:\n\t                    _kwargs[k] = f'format_error: {e}'\n\t        return _kwargs\n\t    def _format(self, msg: str, level, **kwargs):\n\t        try:\n\t            extras = {\n", "                **self._format_kwargs(kwargs),\n\t            }\n\t            extras_json = json.dumps(extras, ensure_ascii=False, default=str)\n\t        except Exception as e:\n\t            extras_json = json.dumps({\"logger_error\": str(e)}, ensure_ascii=False)\n\t        return json.dumps(\n\t            {\n\t                \"app\": self._logger.name,\n\t                \"timestamp\": str(datetime.datetime.utcnow()),\n\t                \"event\": msg,\n", "                \"level\": level,\n\t                \"extra\": extras_json,\n\t            },\n\t            ensure_ascii=False,\n\t        )\n\t    def critical(self, msg: str, **kwargs):\n\t        self._logger.critical(self._format(msg, level=\"critical\", **kwargs))\n\t    def error(self, msg: str, **kwargs):\n\t        self._logger.error(self._format(msg, level=\"error\", **kwargs))\n\t    def warning(self, msg: str, **kwargs):\n", "        self._logger.warning(self._format(msg, level=\"warning\", **kwargs))\n\t    def info(self, msg: str, **kwargs):\n\t        self._logger.info(self._format(msg, level=\"info\", **kwargs))\n\t    def debug(self, msg: str, **kwargs):\n\t        self._logger.debug(self._format(msg, level=\"debug\", **kwargs))\n\t    def exception(self, msg: str, **kwargs):\n\t        self._logger.error(\n\t            self._format(\n\t                msg,\n\t                level=\"exception\",\n", "                traceback=traceback.format_exc(),\n\t                **kwargs,\n\t            )\n\t        )\n"]}
{"filename": "src/inn_service/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/app_container.py", "chunked_list": ["from injector import singleton, provider\n\timport logging\n\tfrom core.container_manager import Container\n\tfrom settings import Settings\n\tfrom logger import AppLogger\n\tfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\n\tfrom connection_managers.mongo_connection_manager import MongoConnectionManager\n\tfrom services.inn_service import InnService\n\tfrom services.live_probe_service import LiveProbeService\n\tfrom infrastructure.queue_manager.queue_manager import QueueManager\n", "from infrastructure.handlers.request_handler import RequestHandler\n\tfrom clients.inn_nalog_client import NalogApiClient\n\tfrom repositories.request_mongo_repository import RequestRepository\n\tclass ApplicationContainer(Container):\n\t    @singleton\n\t    @provider\n\t    def provide_settings(self) -> Settings:\n\t        return Settings()\n\t    @singleton\n\t    @provider\n", "    def provide_logger(self, settings: Settings) -> AppLogger:\n\t        logger = logging.getLogger(settings.app_name)\n\t        logger.setLevel(logging.DEBUG)\n\t        sh = logging.StreamHandler()\n\t        sh.setLevel(logging.DEBUG)\n\t        logger.setLevel(logging.DEBUG)\n\t        logger.addHandler(sh)\n\t        return AppLogger(logger)\n\t    @singleton\n\t    @provider\n", "    def provide_mongodb_connection(self, settings: Settings, logger: AppLogger) -> MongoConnectionManager:\n\t        return MongoConnectionManager(settings, logger)\n\t    @singleton\n\t    @provider\n\t    def provide_rabbitmq_connection(self, settings: Settings, logger: AppLogger) -> RabbitConnectionManager:\n\t        return RabbitConnectionManager(settings, logger)\n\t    @singleton\n\t    @provider\n\t    def provide_nalog_api_client(self, settings: Settings, logger: AppLogger) -> NalogApiClient:\n\t        return NalogApiClient(settings, logger)\n", "    @singleton\n\t    @provider\n\t    def provide_request_repository(self, settings: Settings, mongo_connection: MongoConnectionManager) -> RequestRepository:\n\t        return RequestRepository(mongo_connection, settings)\n\t    @singleton\n\t    @provider\n\t    def provide_inn_service(\n\t            self,\n\t            settings: Settings,\n\t            logger: AppLogger,\n", "            nalog_api_client: NalogApiClient,\n\t            request_repository: RequestRepository\n\t    ) -> InnService:\n\t        return InnService(settings, logger, nalog_api_client, request_repository)\n\t    @singleton\n\t    @provider\n\t    def provide_queue_manager(\n\t            self,\n\t            settings: Settings,\n\t            logger: AppLogger,\n", "            rabbitmq: RabbitConnectionManager\n\t    ) -> QueueManager:\n\t        return QueueManager(settings, logger, rabbitmq)\n\t    @singleton\n\t    @provider\n\t    def provide_request_handler(\n\t            self,\n\t            settings: Settings,\n\t            logger: AppLogger,\n\t            inn_service: InnService,\n", "            rabbitmq_connection_manager: RabbitConnectionManager\n\t    ) -> RequestHandler:\n\t        return RequestHandler(settings, logger, rabbitmq_connection_manager, inn_service)\n\t    @singleton\n\t    @provider\n\t    def provide_live_probe_service(self, logger: AppLogger) -> LiveProbeService:\n\t        return LiveProbeService(logger)\n"]}
{"filename": "src/inn_service/connection_managers/mongo_connection_manager.py", "chunked_list": ["from typing import List, Any, Coroutine\n\tfrom motor.motor_asyncio import AsyncIOMotorClient\n\tfrom pymongo.errors import ServerSelectionTimeoutError, OperationFailure\n\tfrom pymongo.mongo_client import MongoClient\n\tfrom core.event_mixins import EventLiveProbeMixin, LiveProbeStatus, StartupEventMixin, ShutdownEventMixin\n\tfrom core.exceptions import MongoConnectionError\n\tfrom settings import Settings\n\tfrom logger import AppLogger\n\tclass MongoConnectionManager(StartupEventMixin, ShutdownEventMixin, EventLiveProbeMixin):\n\t    def __init__(self, settings: Settings, logger: AppLogger):\n", "        self.logger = logger\n\t        self._mongodb_uri = settings.mongo_dsn\n\t        self._mongo_db = settings.mongo_name\n\t        self._timeout = settings.mongo_timeout_server_select\n\t        self._connection: AsyncIOMotorClient = AsyncIOMotorClient(\n\t            self._mongodb_uri,\n\t            serverSelectionTimeoutMS=self._timeout,\n\t            connect=False\n\t        )\n\t    def shutdown(self) -> Coroutine:\n", "        return self.close_connection()\n\t    def startup(self) -> Coroutine:\n\t        return self.create_connection()\n\t    async def get_connection(self) -> AsyncIOMotorClient:\n\t        is_connected = await self.is_connected()\n\t        if is_connected.status:\n\t            return self._connection\n\t        else:\n\t            await self.create_connection()\n\t            return self._connection\n", "    async def create_connection(self) -> None:\n\t        self.logger.info('Create connection MongoDB')\n\t        try:\n\t            db = self._connection.get_database(self._mongo_db)\n\t            await db.list_collection_names()\n\t        except (ServerSelectionTimeoutError, OperationFailure) as exc:\n\t            self.logger.error('Error connected to Mongo', details=str(exc))\n\t            raise MongoConnectionError(str(exc))\n\t    async def close_connection(self):\n\t        if self._connection is not None:\n", "            self._connection.close()\n\t    async def is_connected(self) -> LiveProbeStatus:\n\t        try:\n\t            db = self._connection.get_database(self._mongo_db)\n\t            await db.list_collection_names()\n\t            status = True\n\t        except ServerSelectionTimeoutError:\n\t            status = False\n\t        return LiveProbeStatus(service_name='MongoDb', status=status)\n"]}
{"filename": "src/inn_service/connection_managers/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/connection_managers/rabbitmq_connection_manager.py", "chunked_list": ["import json\n\tfrom typing import Optional, Coroutine, Callable\n\tfrom aio_pika import Exchange, connect_robust, Message, Channel\n\tfrom aio_pika.connection import Connection\n\tfrom aiormq.exceptions import ChannelPreconditionFailed\n\tfrom core.event_mixins import EventLiveProbeMixin, LiveProbeStatus, StartupEventMixin, ShutdownEventMixin\n\tfrom settings import Settings\n\tfrom logger import AppLogger\n\tclass RabbitConnectionManager(StartupEventMixin, ShutdownEventMixin, EventLiveProbeMixin):\n\t    def __init__(self, settings: Settings, logger: AppLogger) -> None:\n", "        self._dsn = settings.rabbitmq_dsn\n\t        self.prefetch_count = settings.rabbitmq_prefetch_count\n\t        self.exchange_type = settings.rabbitmq_exchange_type\n\t        self._connection = None\n\t        self._channel = None\n\t        self._exchange = None\n\t        self.connected: bool = False\n\t        self.logger = logger\n\t    def shutdown(self) -> Coroutine:\n\t        return self.close_connection()\n", "    def startup(self) -> Coroutine:\n\t        return self.create_connection()\n\t    async def is_connected(self) -> LiveProbeStatus:\n\t        return LiveProbeStatus(service_name='RabbitMQ', status=self.connected)\n\t    async def create_connection(self) -> None:\n\t        self.logger.info('Create connection RabbitMQ')\n\t        try:\n\t            self._connection = await connect_robust(self._dsn)\n\t            self._connection.reconnect_callbacks.add(self.on_connection_restore)\n\t            self._connection.close_callbacks.add(self.on_close_connection)\n", "            self.connected = True\n\t        except ConnectionError as exc:\n\t            err_message = f'Rabbit connection problem: {exc}'\n\t            self.logger.error(err_message)\n\t            raise ConnectionError(err_message)\n\t    async def close_connection(self) -> None:\n\t        if self._connection:\n\t            await self._connection.close()\n\t    async def get_connection(self) -> Connection:\n\t        return self._connection\n", "    async def get_channel(self) -> Channel:\n\t        if not self._channel:\n\t            connection = await self.get_connection()\n\t            self._channel = await connection.channel()\n\t            await self._channel.set_qos(prefetch_count=self.prefetch_count)\n\t        return self._channel\n\t    async def get_exchange(self) -> Exchange:\n\t        if not self._exchange:\n\t            channel = await self.get_channel()\n\t            self._exchange = await channel.declare_exchange(self.exchange_type, auto_delete=False, durable=True)\n", "        return self._exchange\n\t    async def delete_dl_queue_after_error(self, dl_queue_name: str) -> None:\n\t        connection = await self.get_connection()\n\t        self._channel = await connection.channel()\n\t        channel = await self.get_channel()\n\t        await channel.queue_delete(dl_queue_name)\n\t    async def create_dl_queue(self, queue_name: str, ttl: int):\n\t        channel = await self.get_channel()\n\t        exchange = await self.get_exchange()\n\t        dead_letter_queue_arguments = {\n", "            'x-dead-letter-exchange': exchange.name,\n\t            'x-dead-letter-routing-key': queue_name,\n\t            'x-message-ttl': ttl\n\t        }\n\t        dead_queue = await channel.declare_queue(\n\t            f'dl-{queue_name}',\n\t            auto_delete=False,\n\t            durable=True,\n\t            arguments=dead_letter_queue_arguments\n\t        )\n", "        await dead_queue.bind(exchange)\n\t    async def create_queue_listener(\n\t            self,\n\t            queue_name: str,\n\t            callback_worker: Callable,\n\t            use_retry: bool = False,\n\t            retry_ttl: int = 0,\n\t    ) -> None:\n\t        channel = await self.get_channel()\n\t        exchange = await self.get_exchange()\n", "        dl_queue_name = f'dl-{queue_name}'\n\t        queue_arguments = {}\n\t        if use_retry:\n\t            queue_arguments['x-dead-letter-exchange'] = exchange.name\n\t            queue_arguments['x-dead-letter-routing-key'] = dl_queue_name\n\t            try:\n\t                await self.create_dl_queue(queue_name=queue_name, ttl=retry_ttl)\n\t            except ChannelPreconditionFailed:\n\t                self.logger.warning('PRECONDITION_FAILED - trying to reset Dead Letter queue')\n\t                await self.delete_dl_queue_after_error(dl_queue_name=dl_queue_name)\n", "                await self.create_queue_listener(queue_name, callback_worker, use_retry, retry_ttl)\n\t                self.logger.info(f'Dead Letter queue <{dl_queue_name}> recreated')\n\t                return\n\t        queue = await channel.declare_queue(queue_name, auto_delete=False, durable=True, arguments=queue_arguments)\n\t        await queue.bind(exchange)\n\t        await queue.consume(callback_worker)\n\t    async def declare_queue(\n\t            self,\n\t            name: str,\n\t            dead_exchange: Optional[str] = None,\n", "            dead_queue_name: Optional[str] = None\n\t    ) -> None:\n\t        if dead_queue_name:\n\t            queue_arguments = {\n\t                'x-dead-letter-exchange': dead_exchange,\n\t                'x-dead-letter-routing-key': dead_queue_name\n\t            }\n\t        else:\n\t            queue_arguments = {}\n\t        connection = await self.get_connection()\n", "        channel = await connection.channel()\n\t        exchange = await self.get_exchange()\n\t        queue = await channel.declare_queue(name, auto_delete=False, durable=True, arguments=queue_arguments)\n\t        await queue.bind(exchange, name)\n\t    async def send_data_in_queue(self, data: dict, queue_name: str) -> None:\n\t        data_bytes = json.dumps(data).encode()\n\t        exchange = await self.get_exchange()\n\t        self.logger.debug(f'Send message in \"{queue_name}\". Message: {data}')\n\t        await exchange.publish(Message(data_bytes), routing_key=queue_name)\n\t    def on_close_connection(self, *args):\n", "        self.logger.error('Lost connection to RabbitMQ...')\n\t        self.connected = False\n\t    def on_connection_restore(self, *args):\n\t        self.logger.info('Connection to RabbitMQ has been restored...')\n\t        self._channel = None\n\t        self._exchange = None\n\t        self.connected = True\n"]}
{"filename": "src/inn_service/infrastructure/handlers/base_handler.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import Optional\n\tfrom logger import AppLogger\n\tfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\n\tfrom settings import Settings\n\tclass BaseHandler(ABC):\n\t    \"\"\"\n\t    Базовый обработчик\n\t    \"\"\"\n\t    def __init__(\n", "            self,\n\t            settings: Settings,\n\t            logger: AppLogger,\n\t            rabbitmq_connection: RabbitConnectionManager\n\t    ) -> None:\n\t        self.settings = settings\n\t        self.logger = logger\n\t        self.rabbitmq_connection = rabbitmq_connection\n\t    def __repr__(self):\n\t        return self.handler_name()\n", "    def handler_name(self) -> str:\n\t        return 'BaseHandler'\n\t    @abstractmethod\n\t    def get_use_retry(self) -> bool:\n\t        raise NotImplementedError\n\t    def get_retry_ttl(self) -> int:\n\t        return 0\n\t    @abstractmethod\n\t    def get_source_queue(self) -> str:\n\t        raise NotImplementedError\n", "    def convert_seconds_to_mseconds(self, value: int) -> int:\n\t        return value * 1000\n\t    @abstractmethod\n\t    def get_error_response(self, request_id: str, error_message: str) -> dict:\n\t        raise NotImplementedError\n\t    @abstractmethod\n\t    async def run_handler(\n\t            self,\n\t            message: dict,\n\t            request_id: Optional[str],\n", "            result_queue: Optional[str],\n\t            count_retry: Optional[int] = 0\n\t    ) -> bool:\n\t        raise NotImplementedError\n"]}
{"filename": "src/inn_service/infrastructure/handlers/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/infrastructure/handlers/request_handler.py", "chunked_list": ["from typing import Optional\n\tfrom logger import AppLogger\n\tfrom infrastructure.handlers.base_handler import BaseHandler\n\tfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\n\tfrom settings import Settings\n\tfrom services.inn_service import InnService\n\tfrom models.model import ClientDataDTO\n\tfrom core.exceptions import HandlerNoRequestIdException\n\tfrom serializers.request_serializer import RequestMqSerializer\n\tclass RequestHandler(BaseHandler):\n", "    def __init__(\n\t            self,\n\t            settings: Settings,\n\t            logger: AppLogger,\n\t            rabbitmq_connection: RabbitConnectionManager,\n\t            service: InnService\n\t    ) -> None:\n\t        super().__init__(settings, logger, rabbitmq_connection)\n\t        self.source_queue_name = self.settings.rabbitmq_source_queue_name\n\t        self.retry_times = self.settings.app_request_retry_times\n", "        self.retry_sec = self.settings.app_request_retry_sec\n\t        self.service = service\n\t    def handler_name(self) -> str:\n\t        return 'RequestHandler'\n\t    def get_source_queue(self) -> str:\n\t        return self.source_queue_name\n\t    def get_use_retry(self) -> bool:\n\t        return True\n\t    def get_retry_ttl(self) -> int:\n\t        return self.retry_sec\n", "    def get_error_response(self, request_id: str, error_message: str) -> dict:\n\t        response = ClientDataDTO(\n\t            request_id=request_id,\n\t            inn='',\n\t            details=error_message,\n\t            elapsed_time=0\n\t        )\n\t        return response.dict(by_alias=True)\n\t    async def run_handler(\n\t            self,\n", "            message: dict,\n\t            request_id: Optional[str],\n\t            result_queue: Optional[str],\n\t            count_retry: Optional[int] = 0\n\t    ) -> bool:\n\t        if count_retry > self.retry_times:\n\t            self.logger.warning(f'Request {request_id} was rejected by excess attempts {self.retry_times} times')\n\t            return True\n\t        if not request_id:\n\t            raise HandlerNoRequestIdException\n", "        self.logger.info(f'Get request {request_id} for response {result_queue}')\n\t        client_data = RequestMqSerializer.parse_obj(message)\n\t        response = await self.service.get_client_inn(client_data)\n\t        if result_queue:\n\t            json_message = response.dict()\n\t            await self.rabbitmq_connection.send_data_in_queue(json_message, result_queue)\n\t        return True\n"]}
{"filename": "src/inn_service/infrastructure/queue_manager/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/infrastructure/queue_manager/queue_manager.py", "chunked_list": ["import json\n\tfrom typing import List, Callable\n\tfrom aio_pika import IncomingMessage\n\tfrom logger import AppLogger\n\tfrom pydantic import ValidationError\n\tfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\n\tfrom infrastructure.handlers.base_handler import BaseHandler\n\tfrom settings import Settings\n\tclass QueueManager:\n\t    \"\"\"\n", "    Менеджер mq для получения сообщений\n\t    \"\"\"\n\t    def __init__(\n\t            self,\n\t            settings: Settings,\n\t            logger: AppLogger,\n\t            queue_connection_manager: RabbitConnectionManager\n\t    ) -> None:\n\t        self.settings = settings\n\t        self.logger = logger\n", "        self.connection_manager = queue_connection_manager\n\t        self._handlers: List[BaseHandler] = []\n\t        self._exchange = None\n\t    def add_handler(self, item: BaseHandler):\n\t        self._handlers.append(item)\n\t    async def run_handlers_async(self) -> None:\n\t        \"\"\"\n\t        Инициализация обработчиков\n\t        \"\"\"\n\t        for handler in self._handlers:\n", "            await self._create_consumer(handler)\n\t    async def _create_consumer(self, item: BaseHandler) -> None:\n\t        self.logger.info(f'Create consumer for {item.get_source_queue()}')\n\t        await self.connection_manager.create_queue_listener(\n\t            item.get_source_queue(),\n\t            self.make_consumer_function(item),\n\t            item.get_use_retry(),\n\t            item.get_retry_ttl()\n\t        )\n\t    async def _send_error_response(self, response: dict, queue: str) -> None:\n", "        await self.connection_manager.send_data_in_queue(response, queue)\n\t    def _get_message_retry(self, message: IncomingMessage) -> int:\n\t        \"\"\"\n\t        Получить количество повторов пересылки сообщения\n\t        \"\"\"\n\t        count_retry = 0\n\t        x_death = message.headers.get('x-death', [])\n\t        if len(x_death) > 0:\n\t            count_retry = x_death[0].get('count', 0)\n\t        return count_retry\n", "    def make_consumer_function(self, handler: BaseHandler) -> Callable:\n\t        \"\"\"\n\t        Создание динамической функции для обработки сообщений из mq\n\t        \"\"\"\n\t        async def _function(message: IncomingMessage) -> None:\n\t            message_content = message.body.decode('utf-8')\n\t            result_queue = message.reply_to\n\t            request_id = None\n\t            try:\n\t                data = json.loads(message_content)\n", "                request_id = data.get('requestId')\n\t                count_retry = self._get_message_retry(message)\n\t                is_processed = await handler.run_handler(data, request_id, result_queue, count_retry)\n\t                if is_processed:\n\t                    await message.ack()\n\t                else:\n\t                    await message.reject()\n\t            except json.JSONDecodeError as exc:\n\t                self.logger.error('Unable to parse message.', details=str(exc), message=message_content)\n\t                await message.ack()\n", "            except ValidationError as exc:\n\t                error_message = f'Request body content error. {str(exc.errors())}'\n\t                self.logger.error(error_message)\n\t                if result_queue:\n\t                    response = handler.get_error_response(request_id, error_message)\n\t                    await self._send_error_response(response, result_queue)\n\t                await message.ack()\n\t            except Exception as ex:\n\t                error_message = f'Handler {handler=} error. Type error: {type(ex)=}, message: {str(ex)}'\n\t                self.logger.error(error_message, reply_to=result_queue, request_id=request_id)\n", "                if result_queue:\n\t                    response = handler.get_error_response(request_id, error_message)\n\t                    await self._send_error_response(response, result_queue)\n\t                await message.ack()\n\t        return _function\n"]}
{"filename": "src/inn_service/infrastructure/controllers/base_controller.py", "chunked_list": ["from fastapi import Depends\n\tfrom injector import Injector\n\tfrom core.container_manager import get_container_injector\n\tclass BaseController:\n\t    injector: Injector = Depends(get_container_injector)\n"]}
{"filename": "src/inn_service/infrastructure/controllers/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/infrastructure/controllers/liveprobe_controller.py", "chunked_list": ["from fastapi.responses import Response\n\tfrom fastapi_utils.cbv import cbv\n\tfrom fastapi_utils.inferring_router import InferringRouter\n\tfrom infrastructure.controllers.base_controller import BaseController\n\tfrom services.live_probe_service import LiveProbeService\n\trouter = InferringRouter()\n\t@cbv(router)\n\tclass CoreController(BaseController):\n\t    def __init__(self):\n\t        self.live_probe_service = self.injector.get(LiveProbeService)\n", "    @router.get('/livez')\n\t    async def check_health(self):\n\t        is_success = await self.live_probe_service.get_component_status()\n\t        status_code = 200 if is_success else 500\n\t        return Response(status_code=status_code)\n"]}
{"filename": "src/inn_service/infrastructure/http_server/http_server_manager.py", "chunked_list": ["from typing import Optional\n\tfrom fastapi import FastAPI\n\tfrom injector import Injector\n\tfrom uvicorn import Server, Config\n\tfrom services.live_probe_service import LiveProbeService\n\tfrom settings import Settings\n\tfrom infrastructure.controllers.liveprobe_controller import router as infrastructure_route\n\tclass ServerApplication(FastAPI):\n\t    def __init__(self, container: Injector) -> None:\n\t        self.container = container\n", "        settings_ = self.container.get(Settings)\n\t        super(ServerApplication, self).__init__(title=settings_.app_name)\n\t        self.live_probe_service = self.container.get(LiveProbeService)\n\t        self._include_routes()\n\t    def _include_routes(self) -> None:\n\t        self.include_router(infrastructure_route, tags=['Core'])\n\tclass ServerAPIManager:\n\t    def __init__(self, container: Injector) -> None:\n\t        self.container = container\n\t        settings = self.container.get(Settings)\n", "        self.host = settings.http_host\n\t        self.port = settings.http_port\n\t        self.http_handler = settings.http_handler\n\t        self.api_server: Optional[Server] = None\n\t        self.api_application = None\n\t        self.init_api_server()\n\t    async def serve(self) -> None:\n\t        await self.api_server.serve()\n\t    async def shutdown_server(self):\n\t        if self.api_server and self.api_server.started:\n", "            await self.api_server.shutdown()\n\t    def init_api_server(self) -> None:\n\t        self.api_application = ServerApplication(self.container)\n\t        config = Config(\n\t            app=self.api_application,\n\t            loop=self.http_handler,\n\t            host=self.host,\n\t            port=self.port,\n\t            access_log=False,\n\t            log_config=None,\n", "        )\n\t        self.api_server = Server(config)\n"]}
{"filename": "src/inn_service/infrastructure/http_server/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/repositories/request_mongo_repository.py", "chunked_list": ["from typing import Iterable, Optional\n\tfrom pymongo import ASCENDING\n\tfrom repositories.base_mongo_repository import BaseRepository\n\tfrom connection_managers.mongo_connection_manager import MongoConnectionManager\n\tfrom repositories.base_mongo_repository import IndexDef\n\tfrom models.model import ClientDataModel\n\tfrom settings import Settings\n\tclass RequestRepository(BaseRepository):\n\t    def __init__(self, connection_manager: MongoConnectionManager, settings: Settings):\n\t        super().__init__(connection_manager, settings)\n", "    @property\n\t    def collection_name(self) -> str:\n\t        return 'clients'\n\t    @property\n\t    def collection_indexes(self) -> Iterable[IndexDef]:\n\t        return [\n\t            IndexDef(name='passport_num', sort=ASCENDING),\n\t            IndexDef(name='request_id', sort=ASCENDING),\n\t        ]\n\t    async def save_client_data(self, request: ClientDataModel) -> str:\n", "        record_id = await self.save_document(request.dict())\n\t        return str(record_id)\n\t    async def find_client_data(self, passport_num: str, request_id: str) -> Optional[ClientDataModel]:\n\t        criteria = {\n\t            '$or': [\n\t                {'passport_num': passport_num},\n\t                {'request_id': request_id}\n\t            ]\n\t        }\n\t        result = await self.get_one_document(criteria)\n", "        if result:\n\t            return ClientDataModel(**result)\n\t    async def update_client_data(self, request_id: str, replacement_data: dict) -> None:\n\t        await self.update_document(\n\t            {\n\t                'request_id': request_id\n\t            },\n\t            replacement_data\n\t        )\n"]}
{"filename": "src/inn_service/repositories/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/repositories/base_mongo_repository.py", "chunked_list": ["import asyncio\n\tfrom dataclasses import dataclass\n\tfrom typing import Optional, List, Iterable, Coroutine\n\tfrom connection_managers.mongo_connection_manager import MongoConnectionManager\n\tfrom core.event_mixins import StartupEventMixin\n\tfrom settings import Settings\n\t@dataclass\n\tclass IndexDef:\n\t    name: str\n\t    sort: int\n", "class BaseRepository(StartupEventMixin):\n\t    def __init__(self, mongodb_connection_manager: MongoConnectionManager, setting: Settings) -> None:\n\t        self.mongodb_connection_manager = mongodb_connection_manager\n\t        self.db_name = setting.mongo_name\n\t    @property\n\t    def collection_name(self) -> str:\n\t        raise NotImplementedError\n\t    @property\n\t    def collection_indexes(self) -> Iterable[IndexDef]:\n\t        raise NotImplementedError\n", "    def startup(self) -> Coroutine:\n\t        return self.create_indexes()\n\t    async def create_index(self, field_name: str, sort_id: int) -> None:\n\t        \"\"\"\n\t        Создание индекса в фоне\n\t        \"\"\"\n\t        connection = await self.mongodb_connection_manager.get_connection()\n\t        collection = connection[self.db_name][self.collection_name]\n\t        await collection.create_index([(field_name, sort_id), ], background=True)\n\t    async def create_indexes(self) -> None:\n", "        \"\"\"\n\t        Создание всех необходимых индексов для каждого репозитория\n\t        \"\"\"\n\t        tasks = []\n\t        for index_item in self.collection_indexes:\n\t            tasks.append(self.create_index(index_item.name, index_item.sort))\n\t        asyncio.ensure_future(asyncio.gather(*tasks))\n\t    async def get_one_document(self, criteria: dict) -> Optional[dict]:\n\t        connection = await self.mongodb_connection_manager.get_connection()\n\t        collection = connection[self.db_name][self.collection_name]\n", "        return await collection.find_one(criteria)\n\t    async def get_list_document(\n\t            self,\n\t            criteria: dict,\n\t            sort_criteria: Optional[list] = None,\n\t            limit: Optional[int] = 0,\n\t            skip: Optional[int] = 0,\n\t    ) -> List[dict]:\n\t        if not sort_criteria:\n\t            sort_criteria = []\n", "        connection = await self.mongodb_connection_manager.get_connection()\n\t        cursor = connection[self.db_name][self.collection_name].find(\n\t            criteria,\n\t            limit=limit,\n\t            skip=skip,\n\t            sort=sort_criteria\n\t        )\n\t        result = list()\n\t        async for data in cursor:\n\t            result.append(data)\n", "        return result\n\t    async def save_document(self, data: dict) -> str:\n\t        connection = await self.mongodb_connection_manager.get_connection()\n\t        result = await connection[self.db_name][self.collection_name].insert_one(data)\n\t        return result.inserted_id\n\t    async def update_document(self, criteria: dict, data: dict) -> None:\n\t        connection = await self.mongodb_connection_manager.get_connection()\n\t        await connection[self.db_name][self.collection_name].update_one(criteria, {'$set': data})\n"]}
{"filename": "src/inn_service/serializers/request_serializer.py", "chunked_list": ["from datetime import date\n\tfrom pydantic import BaseModel, Field\n\tclass RequestMqSerializer(BaseModel):\n\t    request_id: str = Field(alias='requestId')\n\t    first_name: str = Field(alias='firstName')\n\t    last_name: str = Field(alias='lastName')\n\t    middle_name: str = Field(alias='middleName')\n\t    birth_date: date = Field(alias='birthDate')\n\t    document_serial: str = Field(alias='documentSerial')\n\t    document_number: str = Field(alias='documentNumber')\n", "    document_date: date = Field(alias='documentDate')\n"]}
{"filename": "src/inn_service/serializers/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/serializers/nalog_api_serializer.py", "chunked_list": ["from pydantic import BaseModel, Field\n\tfrom serializers.request_serializer import RequestMqSerializer\n\tclass NalogApiRequestSerializer(BaseModel):\n\t    last_name: str = Field(None, alias='fam')\n\t    first_name: str = Field(None, alias='nam')\n\t    middle_name: str = Field('нет', alias='otch')\n\t    birth_date: str = Field(None, alias='bdate')\n\t    birth_place: str = Field('', alias='bplace')\n\t    doc_type: int = Field(21, alias='doctype')\n\t    doc_number: str = Field(None, alias='docno')\n", "    doc_date: str = Field(None, alias='docdt')\n\t    type: str = Field('innMy', alias='c')\n\t    captcha: str = Field('', alias='captcha')\n\t    captchaToken: str = Field('', alias='captchaToken')\n\t    @property\n\t    def client_fullname(self):\n\t        return f'{self.last_name} {self.first_name} {self.middle_name}'\n\t    @classmethod\n\t    def create_from_request(cls, request: RequestMqSerializer) -> 'NalogApiRequestSerializer':\n\t        document_number = '{} {} {}'.format(\n", "            request.document_serial[0:2],\n\t            request.document_serial[2:4],\n\t            request.document_number\n\t        )\n\t        return NalogApiRequestSerializer(\n\t            last_name=request.last_name,\n\t            first_name=request.first_name,\n\t            middle_name=request.middle_name,\n\t            birth_date=request.birth_date.strftime('%d.%m.%Y'),\n\t            doc_number=document_number,\n", "            doc_date=request.document_date.strftime('%d.%m.%Y')\n\t        )\n\t    class Config:\n\t        allow_population_by_field_name = True\n"]}
{"filename": "src/inn_service/models/model.py", "chunked_list": ["from typing import Optional\n\tfrom pydantic import BaseModel, Field\n\tfrom datetime import date, datetime\n\tfrom serializers.request_serializer import RequestMqSerializer\n\tclass ClientDataModel(BaseModel):\n\t    created_at: datetime = Field(default_factory=datetime.utcnow)\n\t    request_id: str\n\t    first_name: str\n\t    last_name: str\n\t    middle_name: str\n", "    birth_date: datetime\n\t    birth_place: str = Field(default='')\n\t    passport_num: str\n\t    document_date: datetime\n\t    executed_at: Optional[datetime]\n\t    inn: Optional[str]\n\t    error: Optional[str]\n\t    @classmethod\n\t    def create_from_request(cls, request: RequestMqSerializer) -> 'ClientDataModel':\n\t        return ClientDataModel(\n", "            request_id=request.request_id,\n\t            first_name=request.first_name,\n\t            last_name=request.last_name,\n\t            middle_name=request.middle_name,\n\t            birth_date=datetime.combine(request.birth_date, datetime.min.time()),\n\t            passport_num='{} {}'.format(request.document_serial, request.document_number),\n\t            document_date=datetime.combine(request.document_date, datetime.min.time()),\n\t        )\n\t    @property\n\t    def elapsed_time(self) -> float:\n", "        end = self.executed_at or datetime.utcnow()\n\t        return (end - self.created_at).total_seconds()\n\tclass ClientDataDTO(BaseModel):\n\t    request_id: Optional[str] = Field(alias='requestId')\n\t    inn: str = Field(alias='inn')\n\t    details: Optional[str] = Field('', alias='details')\n\t    cashed: bool = Field(False, alias='cached')\n\t    elapsed_time: float = Field(alias='elapsedTime')\n\t    class Config:\n\t        allow_population_by_field_name = True"]}
{"filename": "src/inn_service/models/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/clients/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/clients/utils.py", "chunked_list": ["from typing import Tuple\n\tfrom asyncio import sleep\n\tfrom logger import AppLogger\n\tdef retry(exceptions: Tuple, logger: AppLogger, attempts: int = 3, wait_sec: int = 1):\n\t    def decorator(func):\n\t        async def wrapper(*args, **kwargs):\n\t            exc = None\n\t            for attempt in range(1, attempts + 1):\n\t                try:\n\t                    return await func(*args, **kwargs)\n", "                except exceptions as error:\n\t                    logger.exception('Call http query error', func=func.__name__, attempt=attempt, retriable=True)\n\t                    await sleep(wait_sec)\n\t                    exc = error\n\t                except Exception:\n\t                    logger.exception('Call http query error', func=func.__name__, attempt=attempt, retriable=False)\n\t                    raise\n\t            raise exc\n\t        return wrapper\n\t    return decorator\n"]}
{"filename": "src/inn_service/clients/inn_nalog_client.py", "chunked_list": ["import http\n\tfrom logger import AppLogger\n\tfrom typing import Optional\n\timport aiohttp\n\tfrom clients.utils import retry\n\tfrom core.exceptions import NalogApiClientException\n\tfrom serializers.nalog_api_serializer import NalogApiRequestSerializer\n\tfrom settings import Settings\n\tclass NalogApiClient:\n\t    CLIENT_EXCEPTIONS = (\n", "        NalogApiClientException,\n\t        aiohttp.ClientProxyConnectionError,\n\t        aiohttp.ServerTimeoutError,\n\t    )\n\t    def __init__(self, settings: Settings, logger: AppLogger) -> None:\n\t        self.nalog_api_service_url = settings.client_nalog_url\n\t        self.request_timeout = settings.client_nalog_timeout_sec\n\t        self.retries_times = settings.client_nalog_retries\n\t        self.retries_wait = settings.client_nalog_wait_sec\n\t        self.logger = logger\n", "        self.timeout = aiohttp.ClientTimeout(total=self.request_timeout)\n\t    @property\n\t    def _headers(self):\n\t        return {\n\t            \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n\t            \"Accept-Language\": \"ru-RU,ru\",\n\t            \"Connection\": \"keep-alive\",\n\t            \"Origin\": \"https://service.nalog.ru\",\n\t            \"Referer\": \"https://service.nalog.ru/inn.do\",\n\t            \"Sec-Fetch-Dest\": \"empty\",\n", "            \"Sec-Fetch-Mode\": \"cors\",\n\t            \"Sec-Fetch-Site\": \"same-origin\",\n\t            \"Sec-GPC\": \"1\",\n\t            \"X-Requested-With\": \"XMLHttpRequest\",\n\t        }\n\t    async def send_request_for_inn(self, nalog_api_request: NalogApiRequestSerializer) -> Optional[str]:\n\t        \"\"\"\n\t        Отправка запроса в API service.nalog.ru\n\t        \"\"\"\n\t        self.logger.debug(f'Request to nalog api service for {nalog_api_request.client_fullname}')\n", "        form_data = nalog_api_request.dict(by_alias=True)\n\t        @retry(self.CLIENT_EXCEPTIONS, logger=self.logger, attempts=self.retries_times, wait_sec=self.retries_wait)\n\t        async def make_request(client_session: aiohttp.ClientSession):\n\t            async with client_session.post(url=self.nalog_api_service_url, data=form_data) as response:\n\t                if response.status not in [http.HTTPStatus.OK, http.HTTPStatus.NOT_FOUND]:\n\t                    response_text = await response.text()\n\t                    raise NalogApiClientException(response_text)\n\t                data = await response.json()\n\t                code = data.get('code')\n\t                captcha_required = data.get('captchaRequired')\n", "                if captcha_required:\n\t                    raise NalogApiClientException(f'Captcha required for request {nalog_api_request.client_fullname}')\n\t                if code == 0:\n\t                    return 'no inn'\n\t                elif code == 1:\n\t                    return data.get('inn')\n\t                else:\n\t                    raise NalogApiClientException(f'Unable to parse response! Details: {response}')\n\t        async with aiohttp.ClientSession(timeout=self.timeout, headers=self._headers) as session:\n\t            return await make_request(session)\n"]}
{"filename": "src/inn_service/core/event_mixins.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import Coroutine\n\tfrom pydantic import BaseModel\n\tclass LiveProbeStatus(BaseModel):\n\t    service_name: str\n\t    status: bool\n\tclass EventLiveProbeMixin(ABC):\n\t    @abstractmethod\n\t    def is_connected(self) -> LiveProbeStatus:\n\t        raise NotImplementedError\n", "class StartupEventMixin(ABC):\n\t    @abstractmethod\n\t    def startup(self) -> Coroutine:\n\t        raise NotImplementedError\n\tclass ShutdownEventMixin(ABC):\n\t    @abstractmethod\n\t    def shutdown(self) -> Coroutine:\n\t        raise NotImplementedError\n"]}
{"filename": "src/inn_service/core/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/core/container_manager.py", "chunked_list": ["import asyncio\n\tfrom abc import ABC, abstractmethod\n\tfrom typing import Type, List, Callable\n\tfrom injector import singleton, provider, Injector, Module\n\tfrom starlette.requests import Request\n\tfrom core.event_mixins import EventLiveProbeMixin, StartupEventMixin, ShutdownEventMixin\n\tfrom settings import Settings\n\tclass Container(ABC, Module):\n\t    @singleton\n\t    @provider\n", "    @abstractmethod\n\t    def provide_settings(self) -> Settings:\n\t        return Settings()\n\tclass ContainerManager:\n\t    def __init__(self, cls_container: Type[Container]) -> None:\n\t        self._container = Injector(cls_container())\n\t        self._bindings = self._container.binder._bindings\n\t    def get_container(self) -> Injector:\n\t        return self._container\n\t    def get_live_probe_handlers(self) -> List[Type[Callable]]:\n", "        \"\"\"\n\t        Получить список обработчиков реализующих миксину проверка liveness probe EventLiveProbeMixin\n\t        \"\"\"\n\t        result = []\n\t        binding_collection = [binding for binding in self._bindings]\n\t        for binding in binding_collection:\n\t            if issubclass(binding, EventLiveProbeMixin):\n\t                binding_obj = self._container.get(binding)\n\t                result.append(binding_obj.is_connected)\n\t        return result\n", "    def get_startup_handlers(self):\n\t        handlers = []\n\t        binding_collection = [binding for binding in self._bindings]\n\t        for binding in binding_collection:\n\t            if issubclass(binding, StartupEventMixin):\n\t                binding_obj = self._container.get(binding)\n\t                handlers.append(binding_obj.startup())\n\t        return handlers\n\t    def get_shutdown_handlers(self):\n\t        handlers = []\n", "        binding_collection = [binding for binding in self._bindings]\n\t        for binding in binding_collection:\n\t            if issubclass(binding, ShutdownEventMixin):\n\t                binding_obj = self._container.get(binding)\n\t                handlers.append(binding_obj.shutdown())\n\t        return handlers\n\t    async def run_startup(self) -> None:\n\t        exception = None\n\t        for handler in self.get_startup_handlers():\n\t            if exception:\n", "                handler.close()\n\t            else:\n\t                try:\n\t                    await handler\n\t                except Exception as exc:\n\t                    exception = exc\n\t        if exception is not None:\n\t            raise exception\n\t    async def run_shutdown(self) -> None:\n\t        handlers = []\n", "        for handler in self.get_shutdown_handlers():\n\t            handlers.append(handler)\n\t        await asyncio.gather(*handlers)\n\tasync def get_container_injector(request: Request) -> Container:\n\t    return request.app.container\n"]}
{"filename": "src/inn_service/core/application.py", "chunked_list": ["import asyncio\n\tfrom typing import Type\n\tfrom core.container_manager import Container, ContainerManager\n\tfrom infrastructure.queue_manager.queue_manager import QueueManager\n\tfrom infrastructure.http_server.http_server_manager import ServerAPIManager\n\tfrom infrastructure.handlers.request_handler import RequestHandler\n\tfrom services.live_probe_service import LiveProbeService\n\tfrom settings import Settings\n\tfrom logger import AppLogger\n\tclass Application:\n", "    def __init__(self, cls_container: Type[Container]) -> None:\n\t        self.loop = asyncio.get_event_loop()\n\t        self.container_manager = ContainerManager(cls_container)\n\t        self.container = self.container_manager.get_container()\n\t        self.settings = self.container.get(Settings)\n\t        self.logger = self.container.get(AppLogger)\n\t        self.live_probe_service = self.container.get(LiveProbeService)\n\t        self.queue_manager = self.container.get(QueueManager)\n\t        self.app_name = self.settings.app_name\n\t        self.http_server = None\n", "    def init_application(self):\n\t        self.http_server = ServerAPIManager(self.container)\n\t        request_handler = self.container.get(RequestHandler)\n\t        self.queue_manager.add_handler(request_handler)\n\t        live_probe_handlers = self.container_manager.get_live_probe_handlers()\n\t        for handler in live_probe_handlers:\n\t            self.live_probe_service.add_component(handler)\n\t    def run(self) -> None:\n\t        self.logger.info(f'Starting application {self.app_name}')\n\t        self.init_application()\n", "        try:\n\t            self.loop.run_until_complete(self.container_manager.run_startup())\n\t            tasks = asyncio.gather(\n\t                self.http_server.serve(),\n\t                self.queue_manager.run_handlers_async(),\n\t            )\n\t            self.loop.run_until_complete(tasks)\n\t            self.loop.run_forever()\n\t        except BaseException as exception:\n\t            exit(1)\n", "        finally:\n\t            self.loop.run_until_complete(self.container_manager.run_shutdown())\n\t            self.loop.close()\n\t            self.logger.info('Application disabled')\n"]}
{"filename": "src/inn_service/core/exceptions.py", "chunked_list": ["class MongoConnectionError(Exception):\n\t    def __init__(self, message: str):\n\t        self.message = message\n\t    def __str__(self):\n\t        return f'Mongo connection problem: {self.message}'\n\tclass NalogApiClientException(Exception):\n\t    pass\n\tclass HandlerNoRequestIdException(Exception):\n\t    def __str__(self):\n\t        return 'Need to specify requestId attribute.'\n"]}
{"filename": "src/inn_service/services/__init__.py", "chunked_list": []}
{"filename": "src/inn_service/services/inn_service.py", "chunked_list": ["from typing import Optional\n\tfrom datetime import datetime\n\tfrom core.exceptions import NalogApiClientException\n\tfrom settings import Settings\n\tfrom logger import AppLogger\n\tfrom serializers.request_serializer import RequestMqSerializer\n\tfrom serializers.nalog_api_serializer import NalogApiRequestSerializer\n\tfrom clients.inn_nalog_client import NalogApiClient\n\tfrom models.model import ClientDataModel, ClientDataDTO\n\tfrom repositories.request_mongo_repository import RequestRepository\n", "class InnService:\n\t    def __init__(\n\t            self,\n\t            settings: Settings,\n\t            logger: AppLogger,\n\t            client: NalogApiClient,\n\t            storage: RequestRepository\n\t    ) -> None:\n\t        self.settings = settings\n\t        self.logger = logger\n", "        self.client = client\n\t        self.storage_repository = storage\n\t    async def get_client_inn_from_storage(self, client_data: RequestMqSerializer) -> Optional[ClientDataModel]:\n\t        client_passport = f'{client_data.document_serial} {client_data.document_number}'\n\t        client_request = await self.storage_repository.find_client_data(client_passport, client_data.request_id)\n\t        return client_request\n\t    def update_status(self, model: ClientDataModel, inn: str, error: str) -> None:\n\t        model.inn = inn\n\t        model.error = error\n\t    async def get_client_inn(self, client_data: RequestMqSerializer) -> ClientDataDTO:\n", "        \"\"\"Получение клиентского ИНН\"\"\"\n\t        start_process = datetime.utcnow()\n\t        model = ClientDataModel.create_from_request(client_data)\n\t        # Получить данные из БД\n\t        existing_data = await self.get_client_inn_from_storage(client_data)\n\t        if existing_data:\n\t            elapsed_time = (datetime.utcnow() - start_process).total_seconds()\n\t            return ClientDataDTO(\n\t                request_id=client_data.request_id,\n\t                inn=existing_data.inn,\n", "                elapsed_time=elapsed_time,\n\t                cashed=True\n\t            )\n\t        # Сделать фактический запрос в Nalog API\n\t        request = NalogApiRequestSerializer.create_from_request(client_data)\n\t        error, result = None, ''\n\t        try:\n\t            result = await self.client.send_request_for_inn(request)\n\t        except NalogApiClientException as exception:\n\t            self.logger.error('Error request to Nalog api service', details=str(exception))\n", "            error = str(exception)\n\t        self.update_status(model, result, error)\n\t        await self.storage_repository.save_client_data(model)\n\t        return ClientDataDTO(\n\t            request_id=model.request_id,\n\t            inn=model.inn,\n\t            details=model.error,\n\t            elapsed_time=model.elapsed_time\n\t        )\n"]}
{"filename": "src/inn_service/services/live_probe_service.py", "chunked_list": ["import asyncio\n\tfrom typing import List, Callable\n\tfrom logger import AppLogger\n\tclass LiveProbeService:\n\t    def __init__(\n\t            self,\n\t            logger: AppLogger\n\t    ):\n\t        self.logger = logger\n\t        self.handlers: List[Callable] = []\n", "    def add_component(self, component: Callable) -> None:\n\t        self.handlers.append(component)\n\t    async def get_component_status(self) -> bool:\n\t        tasks = []\n\t        component_status = True\n\t        for handler in self.handlers:\n\t            tasks.append(handler())\n\t        probe_results = await asyncio.gather(*tasks)\n\t        for probe_result in probe_results:\n\t            component_status = component_status and probe_result.status\n", "            if not probe_result.status:\n\t                self.logger.error(f'Service {probe_result.service_name} is down')\n\t        return component_status\n"]}
