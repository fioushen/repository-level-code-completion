{"filename": "utils/__init__.py", "chunked_list": []}
{"filename": "utils/ivim/forward_model.py", "chunked_list": ["import torch\n\tdef ivim_parameters_to_signal(D, Dp, f, S0, bvalues):\n\t    \"\"\"\n\t    converts ivim parameters to predicted signal at specified bvalues\n\t    Args:\n\t        D: diffusion coefficient\n\t        Dp: pseudo diffusion coefficient\n\t        f: perfusion fraction\n\t        S0: signal at b=0\n\t        bvalues: b-values (measures of diffusion weighting)\n", "    Returns:\n\t        relative signal: relative (when S0 = 1) signal at specified b-values\n\t        signal: signal at specified b-values\n\t    \"\"\"\n\t    # Calculate signal based on estimated parameters\n\t    relative_signal = f * torch.exp(-bvalues * Dp) + (1 - f) * torch.exp(-bvalues * D)\n\t    signal = S0 * relative_signal\n\t    return signal\n"]}
{"filename": "utils/data_simulation/ivim_simulation.py", "chunked_list": ["import torch\n\timport numpy as np\n\tfrom utils.ivim.forward_model import ivim_parameters_to_signal\n\tdef simulate_ivim_signal(D, Dp, f, S0, bvalues, SNR_array, rg):\n\t    \"\"\"\n\t    simulate ivim signal\n\t    Args:\n\t        D: diffusion coefficient\n\t        Dp: pseudo diffusion coefficient\n\t        f: perfusion fraction\n", "        S0: signal without diffusion weighting\n\t        bvalues: b-values (measure of diffusion weighting)\n\t        SNR_array: noise to be added to the simulated data\n\t        rg: random number generator\n\t    Returns:\n\t        simulated_data: simulated ivim signal\n\t    \"\"\"\n\t    bvalues.sort()\n\t    b0_bool = np.array(bvalues) == 0\n\t    simulated_data = ivim_parameters_to_signal(torch.tensor(D), torch.tensor(Dp), torch.tensor(f), torch.tensor(S0),\n", "                                               torch.tensor(np.asarray(bvalues)))\n\t    simulated_data = simulated_data.cpu().detach().numpy()\n\t    # create 2 signal arrays filled with gaussian noise\n\t    noise_real = rg.normal(0, 1 / SNR, (1, len(bvalues)))\n\t    noise_imag = rg.normal(0, 1 / SNR, (1, len(bvalues)))\n\t    # add Rician noise to the simulated data\n\t    simulated_data = np.sqrt(np.power(simulated_data + noise_real, 2) + np.power(noise_imag, 2)).squeeze()\n\t    # renormalize simulated data to noisy S0\n\t    S0_noisy = np.mean(simulated_data[b0_bool])\n\t    simulated_data /= S0_noisy\n", "    return simulated_data\n"]}
{"filename": "utils/data_simulation/GenerateData.py", "chunked_list": ["import numpy as np\n\tclass GenerateData:\n\t    \"\"\"\n\t    Generate exponential and linear data\n\t    \"\"\"\n\t    def __init__(self, operator=None):\n\t        \"\"\"\n\t        Parameters\n\t        ----------\n\t        operator : numpy or torch\n", "            Must provide mathematical operators\n\t        \"\"\"\n\t        if operator is None:\n\t            self._op = np\n\t        else:\n\t            self._op = operator\n\t    def ivim_signal(self, D, Dp, f, S0, bvalues, snr=None):\n\t        \"\"\"\n\t        Generates IVIM (biexponential) signal\n\t        Parameters\n", "        ----------\n\t        D : float\n\t            The tissue diffusion value\n\t        Dp : float\n\t            The pseudo perfusion value\n\t        f : float\n\t            The fraction of the signal from perfusion\n\t        S0 : float\n\t            The baseline signal (magnitude at no diffusion)\n\t        bvalues : list or array of float\n", "            The diffusion (b-values)\n\t        \"\"\"\n\t        signal = self.multiexponential_signal([D, Dp], [1 - f, f], S0, self._op.asarray(bvalues, dtype='float64'))\n\t        return self.add_rician_noise(signal, snr)\n\t    def exponential_signal(self, D, bvalues):\n\t        \"\"\"\n\t        Generates exponential signal\n\t        Parameters\n\t        ----------\n\t        D : float\n", "            The tissue diffusion value\n\t        bvalues : list or array of float\n\t            The diffusion (b-values)\n\t        \"\"\"\n\t        assert D >= 0, 'D must be >= 0'\n\t        return self._op.exp(-self._op.asarray(bvalues, dtype='float64') * D)\n\t    def multiexponential_signal(self, D, F, S0, bvalues):\n\t        \"\"\"\n\t        Generates multiexponential signal\n\t        The combination of exponential signals\n", "        Parameters\n\t        ----------\n\t        D : list or arrray of float\n\t            The tissue diffusion value\n\t        F : list or array of float\n\t            The fraction of the signal from perfusion\n\t        S0 : list or array of float\n\t            The baseline signal (magnitude at no diffusion)\n\t        bvalues : list or array of float\n\t            The diffusion (b-values)\n", "        \"\"\"\n\t        assert len(D) == len(F), 'D and F must be the same length'\n\t        signal = self._op.zeros_like(bvalues)\n\t        for [d, f] in zip(D, F):\n\t            signal += f * self.exponential_signal(d, bvalues)\n\t        signal *= S0\n\t        return signal\n\t    def add_rician_noise(self, real_signal, snr=None, imag_signal=None):\n\t        \"\"\"\n\t        Adds Rician noise to a real or complex signal\n", "        Parameters\n\t        ----------\n\t        real_signal : list or array of float\n\t            The real channel float\n\t        snr : float\n\t            The signal to noise ratio\n\t        imag_signal : list or array of float\n\t            The imaginary channel float\n\t        \"\"\"\n\t        if imag_signal is None:\n", "            imag_signal = self._op.zeros_like(real_signal)\n\t        if snr is None:\n\t            noisy_data = self._op.sqrt(self._op.power(real_signal, 2) + self._op.power(imag_signal, 2))\n\t        else:\n\t            real_noise = self._op.random.normal(0, 1 / snr, real_signal.shape)\n\t            imag_noise = self._op.random.normal(0, 1 / snr, imag_signal.shape)\n\t            noisy_data = self._op.sqrt(self._op.power(real_signal + real_noise, 2) + self._op.power(imag_signal + imag_noise, 2))\n\t        return noisy_data\n\t    def linear_signal(self, D, bvalues, offset=0):\n\t        \"\"\"\n", "        Generates linear signal\n\t        Parameters\n\t        ----------\n\t        D : float\n\t            The tissue diffusion value\n\t        bvalues : list or array of float\n\t            The diffusion (b-values)\n\t        offset : float\n\t            The signal offset\n\t        \"\"\"\n", "        assert D >= 0, 'D must be >= 0'\n\t        data = -D * np.asarray(bvalues)\n\t        return data + offset\n\t    def multilinear_signal(self, D, F, S0, bvalues, offset=0):\n\t        \"\"\"\n\t        Generates multilinear signal\n\t        The combination of multiple linear signals\n\t        Parameters\n\t        ----------\n\t        D : list or arrray of float\n", "            The tissue diffusion value\n\t        F : list or array of float\n\t            The fraction of the signal from perfusion\n\t        S0 : list or array of float\n\t            The baseline signal (magnitude at no diffusion)\n\t        bvalues : list or array of float\n\t            The diffusion (b-values)\n\t        offset : float\n\t            The signal offset\n\t        \"\"\"\n", "        assert len(D) == len(F), 'D and F must be the same length'\n\t        signal = self._op.zeros_like(bvalues)\n\t        for [d, f] in zip(D, F):\n\t            signal += f * self.linear_signal(d, bvalues)\n\t        signal *= S0\n\t        signal += offset\n\t        return signal"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/IVIMmodels/data/test_GenerateData.py", "chunked_list": ["import numpy as np\n\timport numpy.testing as npt\n\timport pytest\n\timport torch\n\tfrom utils.data_simulation.GenerateData import GenerateData\n\t#run using python -m pytest from the root folder\n\ttest_monoexponential_data = [\n\t    pytest.param(0, np.linspace(0, 1000, 11), id='0'),\n\t    pytest.param(0.1, np.linspace(0, 1000, 11), id='0.1'),\n\t    pytest.param(0.2, np.linspace(0, 1000, 11), id='0.2'),\n", "    pytest.param(0.3, np.linspace(0, 1000, 11), id='0.3'),\n\t    pytest.param(0.4, np.linspace(0, 1000, 11), id='0.4'),\n\t    pytest.param(0.5, np.linspace(0, 1000, 11), id='0.5'),\n\t    pytest.param(0.8, np.linspace(0, 1000, 11), id='0.8'),\n\t    pytest.param(1, np.linspace(0, 1000, 11), id='1'),\n\t]\n\t@pytest.mark.parametrize(\"D, bvals\", test_monoexponential_data)\n\tdef test_monoexponential(D, bvals):\n\t    gd = GenerateData()\n\t    gd_signal = gd.exponential_signal(D, bvals)\n", "    testing_signal = np.exp(-D * np.asarray(bvals, dtype='float64'))\n\t    npt.assert_allclose(gd_signal, testing_signal)\n\t    assert(gd_signal[0] >= testing_signal[0])\n\ttest_ivim_data = [\n\t    pytest.param(0.01, 0.0, 1, 1, np.linspace(0, 1000, 11), None),\n\t    pytest.param(0.01, 0.1, 0.05, 1, np.linspace(0, 1000, 11), None),\n\t    pytest.param(0.05, 0.2, 0.1, 1, np.linspace(0, 800, 11), None),\n\t    pytest.param(0.04, 0.15, 0.25, 1.5, np.linspace(0, 1000, 2), 10),\n\t    pytest.param(0.1, 0.5, 0.5, 0.5, np.linspace(0, 1500, 5), 100),\n\t    pytest.param(0.01, 0.2, 0.1, 1, np.linspace(10, 1500, 11), 100),\n", "    pytest.param(0.1, 0.15, 0.05, 1, np.linspace(10, 1000, 8), 5)\n\t]\n\t@pytest.mark.parametrize('D, Dp, f, S0, bvals, snr', test_ivim_data)\n\tdef test_ivim(D, Dp, f, S0, bvals, snr):\n\t    gd = GenerateData()\n\t    gd_signal = gd.ivim_signal(D, Dp, f, S0, bvals, snr)\n\t    testing_signal = S0 * ((1 - f) * np.exp(-D * bvals) + f * np.exp(-Dp * bvals))\n\t    atol = 0.0\n\t    if snr is not None:\n\t        atol = 4 / snr\n", "    npt.assert_allclose(gd_signal, testing_signal, atol=atol)\n\ttest_linear_data = [\n\t    pytest.param(0, np.linspace(0, 1000, 11), 0, id='0'),\n\t    pytest.param(0.1, np.linspace(0, 1000, 11), 10, id='0.1'),\n\t    pytest.param(0.2, np.linspace(0, 1000, 11), -10, id='0.2'),\n\t    pytest.param(0.3, np.linspace(0, 1000, 11), 0, id='0.3'),\n\t    pytest.param(0.4, np.linspace(0, 1000, 11), 0, id='0.4'),\n\t    pytest.param(0.5, np.linspace(0, 1000, 11), 0, id='0.5'),\n\t    pytest.param(0.8, np.linspace(0, 1000, 11), 0, id='0.8'),\n\t    pytest.param(1, np.linspace(0, 1000, 11), 0, id='1'),\n", "]\n\t@pytest.mark.parametrize(\"D, bvals, offset\", test_linear_data)\n\tdef test_linear(D, bvals, offset):\n\t    gd = GenerateData()\n\t    gd_signal = gd.linear_signal(D, bvals, offset)\n\t    testing_signal = -D * np.asarray(bvals, dtype='float64')\n\t    testing_signal += offset\n\t    npt.assert_allclose(gd_signal, testing_signal)\n\t    assert(gd_signal[0] >= testing_signal[0])\n\t    gd_exponential = gd.exponential_signal(D, bvals)\n", "    gd_log_exponential = np.log(gd_exponential) + offset\n\t    real_mask = np.isfinite(gd_log_exponential)\n\t    npt.assert_allclose(gd_log_exponential[real_mask], gd_signal[real_mask])\n"]}
{"filename": "tests/IVIMmodels/data/__init__.py", "chunked_list": []}
{"filename": "tests/IVIMmodels/unit_tests/test_ivim_fit_4D.py", "chunked_list": []}
{"filename": "tests/IVIMmodels/unit_tests/test_ivim_fit_linear.py", "chunked_list": ["import numpy as np\n\timport numpy.testing as npt\n\timport pytest\n\timport torch\n\tfrom utils.data_simulation.GenerateData import GenerateData\n\tfrom src.original.ETP_SRI.LinearFitting import LinearFit\n\t#run using python -m pytest from the root folder\n\ttest_linear_data = [\n\t    pytest.param(0, np.linspace(0, 1000, 11), id='0'),\n\t    pytest.param(0.01, np.linspace(0, 1000, 11), id='0.1'),\n", "    pytest.param(0.02, np.linspace(0, 1000, 11), id='0.2'),\n\t    pytest.param(0.03, np.linspace(0, 1000, 11), id='0.3'),\n\t    pytest.param(0.04, np.linspace(0, 1000, 11), id='0.4'),\n\t    pytest.param(0.05, np.linspace(0, 1000, 11), id='0.5'),\n\t    pytest.param(0.08, np.linspace(0, 1000, 11), id='0.8'),\n\t    pytest.param(0.1, np.linspace(0, 1000, 11), id='1'),\n\t]\n\t@pytest.mark.parametrize(\"D, bvals\", test_linear_data)\n\tdef test_linear_fit(D, bvals):\n\t    gd = GenerateData()\n", "    gd_signal = gd.exponential_signal(D, bvals)\n\t    print(gd_signal)\n\t    fit = LinearFit()\n\t    D_fit = fit.linear_fit(bvals, np.log(gd_signal))\n\t    npt.assert_allclose([1, D], D_fit)\n\ttest_ivim_data = [\n\t    pytest.param(0, 0.01, 0.05, np.linspace(0, 1000, 11), id='0'),\n\t    pytest.param(0.1, 0.01, 0.05, np.linspace(0, 1000, 11), id='0.1'),\n\t    pytest.param(0.2, 0.01, 0.05, np.linspace(0, 1000, 11), id='0.2'),\n\t    pytest.param(0.1, 0.05, 0.1, np.linspace(0, 1000, 11), id='0.3'),\n", "    pytest.param(0.4, 0.001, 0.05, np.linspace(0, 1000, 11), id='0.4'),\n\t    pytest.param(0.5, 0.001, 0.05, np.linspace(0, 1000, 11), id='0.5'),\n\t]\n\t@pytest.mark.parametrize(\"f, D, Dp, bvals\", test_ivim_data)\n\tdef test_ivim_fit(f, D, Dp, bvals):\n\t    gd = GenerateData()\n\t    gd_signal = gd.ivim_signal(D, Dp, f, 1, bvals)\n\t    fit = LinearFit()\n\t    [f_fit, D_fit, Dp_fit] = fit.ivim_fit(bvals, gd_signal)\n\t    npt.assert_allclose([f, D], [f_fit, D_fit], atol=1e-5)\n", "    if not np.allclose(f, 0):\n\t        npt.assert_allclose(Dp, Dp_fit, rtol=1e-2, atol=1e-3)\n"]}
{"filename": "tests/IVIMmodels/unit_tests/test_ivim_fit_2D.py", "chunked_list": ["import numpy as np\n\tclass TestIVIMFit2D:\n\t    def __init__(self):\n\t        self.b_values = None\n\t        self.signals = None\n\t        self.supervision = {'D': None,\n\t                            'Dp': None,\n\t                            'f': None,\n\t                            'S0': None}\n\t    @staticmethod\n", "    def estimation_method(b_values, signals):\n\t        D = 0.003\n\t        Dp = 0.02\n\t        f = 0.3\n\t        S0 = 1\n\t        return D, Dp, f, S0\n\t    def test_ivim_fit_2D(self):\n\t        D, Dp, f, S0 = self.estimation_method(self.b_values, self.signals)\n\t        assert np.allclose(D, self.supervision['D'])\n\t        assert np.allclose(Dp, self.supervision['Dp'])\n", "        assert np.allclose(f, self.supervision['f'])\n\t        assert np.allclose(S0, self.supervision['S0'])\n"]}
{"filename": "src/__init__.py", "chunked_list": []}
{"filename": "src/wrappers/ivim_fit.py", "chunked_list": ["# Non-osipi dependencies\n\t# osipi utilities\n\t# osipi implementations\n\tdef ivim_fit(author, signals=None, bvalues=None, data=None, initial_guess=None, bounds=None):\n\t    \"\"\"\n\t    wrapper function to use OSIPI code contributions for IVIM fit\n\t    :param author: str, can be one of []\n\t    :param signals: numpy array containing signal intensities\n\t    :param bvalues: numpy array containing corresponding b-values\n\t    :param data: object containing signals and bvalues\n", "    :param initial_guess: list of initial parameter estimates\n\t    :param bounds: list containing list of lower parameter bounds and list of upper parameter bounds\n\t    :return: numpy array of shape (signals.size, 4) with the D, Dp, f, S0 per voxel.\n\t    \"\"\"\n\t    # Unpack variables if data object is given\n\t    if not data == None:\n\t        bvalues = data.bvalues\n\t        signals = data.signals\n\t    # Some implementations can only fit a voxel at a time (i.e. all inputs must be 2-dimensional)\n\t    requires_2D = True if author in [] else False\n", "    requires_4D = True if author in [] else False\n\t    # Bounds and initial guess for parameters\n\t    initial_guess = []\n\t    bounds = []\n\t    # Create a fitting function for the chosen author/implementation\n\t    if author == \"\":\n\t        pass\n"]}
{"filename": "src/original/__init__.py", "chunked_list": []}
{"filename": "src/original/PV_MUMC/two_step_IVIM_fit.py", "chunked_list": ["\"\"\"\n\tJanuary 2022 by Paulien Voorter\n\tp.voorter@maastrichtuniversity.nl \n\thttps://www.github.com/paulienvoorter\n\trequirements:\n\tnumpy\n\ttqdm\n\tscipy\n\tjoblib\n\t\"\"\"\n", "# load relevant libraries\n\tfrom scipy.optimize import curve_fit, nnls\n\timport numpy as np\n\tfrom joblib import Parallel, delayed\n\timport tqdm\n\tdef two_exp_noS0(bvalues, Dpar, Fmv, Dmv):\n\t    \"\"\" tri-exponential IVIM function, and S0 set to 1\"\"\"\n\t    return Fmv * np.exp(-bvalues * Dmv) + (1 - Fmv ) * np.exp(-bvalues * Dpar)\n\tdef two_exp(bvalues, S0, Dpar, Fmv, Dmv):\n\t    \"\"\" tri-exponential IVIM function\"\"\"\n", "    return S0 * (Fmv * np.exp(-bvalues * Dmv) + (1 - Fmv ) * np.exp(-bvalues * Dpar))\n\tdef fit_least_squares_array(bvalues, dw_data, fitS0=True, bounds=([0.9, 0.0001, 0.0, 0.0025], [1.1, 0.0025, 0.2, 0.2]), cutoff=200):\n\t    \"\"\"\n\t    This is the LSQ implementation, in which we first estimate Dpar using a curve fit to b-values>=cutoff;\n\t    Second, we fit the other parameters using all b-values, while fixing Dpar from step 1. This fit\n\t    is done on an array.\n\t    :param bvalues: 1D Array with the b-values\n\t    :param dw_data: 2D Array with diffusion-weighted signal in different voxels at different b-values\n\t    :param bounds: Array with fit bounds ([S0min, Dparmin, Fintmin, Dintmin, Fmvmin, Dmvmin],[S0max, Dparmax, Fintmax, Dintmax, Fmvmax, Dmvmax]). default: ([0.9, 0.0001, 0.0, 0.0015, 0.0, 0.004], [1.1, 0.0015, 0.4, 0.004, 0.2, 0.2])\n\t    :param cutoff: cutoff b-value used in step 1 \n", "    :return Dpar: 1D Array with Dpar in each voxel\n\t    :return Fmv: 1D Array with Fmv in each voxel\n\t    :return Dmv: 1D Array with Dmv in each voxel\n\t    :return S0: 1D Array with S0 in each voxel\n\t    \"\"\"\n\t    # initialize empty arrays\n\t    Dpar = np.zeros(len(dw_data))\n\t    S0 = np.zeros(len(dw_data))\n\t    Dmv = np.zeros(len(dw_data))\n\t    Fmv = np.zeros(len(dw_data))\n", "    for i in tqdm.tqdm(range(len(dw_data)), position=0, leave=True):\n\t        # fill arrays with fit results on a per voxel base:\n\t        Dpar[i], Fmv[i], Dmv[i], S0[i] = fit_least_squares(bvalues, dw_data[i, :], S0_output=True, fitS0=fitS0, bounds=bounds)\n\t    return [Dpar, Fmv, Dmv, S0]\n\tdef fit_least_squares(bvalues, dw_data, IR=True, S0_output=False, fitS0=True,\n\t                      bounds=([0.9, 0.0001, 0.0, 0.0025], [1.1, 0.0025, 0.2, 0.2]), cutoff=200):\n\t    \"\"\"\n\t   This is the LSQ implementation, in which we first estimate Dpar using a curve fit to b-values>=cutoff;\n\t   Second, we fit the other parameters using all b-values, while fixing Dpar from step 1. This fit\n\t   is done on an array. It fits a single curve\n", "    :param bvalues: 1D Array with the b-values\n\t    :param dw_data: 1D Array with diffusion-weighted signal in different voxels at different b-values\n\t    :param IR: Boolean; True will fit the IVIM accounting for inversion recovery, False will fit IVIM without IR; default = True\n\t    :param S0_output: Boolean determining whether to output (often a dummy) variable S0; default = False\n\t    :param fix_S0: Boolean determining whether to fix S0 to 1; default = True\n\t    :param bounds: Array with fit bounds ([S0min, Dparmin, Fintmin, Dintmin, Fmvmin, Dmvmin],[S0max, Dparmax, Fintmax, Dintmax, Fmvmax, Dmvmax]). Default: ([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5])\n\t    :param cutoff: cutoff b-value used in step 1 \n\t    :return S0: optional 1D Array with S0 in each voxel\n\t    :return Dpar: scalar with Dpar of the specific voxel\n\t    :return Fint: scalar with Fint of the specific voxel\n", "    :return Dint: scalar with Dint of the specific voxel\n\t    :return Fmv: scalar with Fmv of the specific voxel\n\t    :return Dmv: scalar with Dmv of the specific voxel\n\t    \"\"\"\n\t    try:\n\t        def monofit(bvalues, Dpar):\n\t             return np.exp(-bvalues * Dpar)\n\t        high_b = bvalues[bvalues >= cutoff]\n\t        high_dw_data = dw_data[bvalues >= cutoff]\n\t        boundspar = ([bounds[0][1]], [bounds[1][1]])\n", "        params, _ = curve_fit(monofit, high_b, high_dw_data, p0=[(bounds[1][1]-bounds[0][1])/2], bounds=boundspar)\n\t        Dpar1 = params[0]\n\t        if not fitS0:\n\t            boundsupdated=([Dpar1 , bounds[0][2] , bounds[0][3] ],\n\t                      [Dpar1 , bounds[1][2] , bounds[1][3] ])    \n\t            params, _ = curve_fit(two_exp_noS0, bvalues, dw_data, p0=[Dpar1, (bounds[0][2]+bounds[1][2])/2, (bounds[0][3]+bounds[1][3])/2], bounds=boundsupdated)\n\t            Dpar, Fmv, Dmv = params[0], params[1], params[2]\n\t            #when the fraction of a compartment equals zero (or very very small), the corresponding diffusivity is non-existing (=NaN)\n\t            if Fmv < 1e-4:\n\t                Dmv = float(\"NaN\")\n", "        else: \n\t            boundsupdated = ([bounds[0][0] , Dpar1 , bounds[0][2] , bounds[0][3] ],\n\t                      [bounds[1][0] , Dpar1, bounds[1][2] , bounds[1][3] ])   \n\t            params, _ = curve_fit(two_exp, bvalues, dw_data, p0=[1, Dpar1, (bounds[0][2]+bounds[1][2])/2, (bounds[0][3]+bounds[1][3])/2], bounds=boundsupdated)\n\t            S0 = params[0]\n\t            Dpar, Fmv, Dmv = params[1] , params[2] , params[3]\n\t            #when the fraction of a compartment equals zero (or very very small), the corresponding diffusivity is non-existing (=NaN)\n\t            if Fmv < 1e-4:\n\t                Dmv = float(\"NaN\")     \n\t        if S0_output:\n", "            return Dpar, Fmv, Dmv, S0\n\t        else:\n\t            return Dpar, Fmv, Dmv\n\t    except:\n\t        if S0_output:\n\t            return 0, 0, 0, 0, 0, 0\n\t        else:\n\t            return 0, 0, 0, 0, 0\n"]}
{"filename": "src/original/OGC_AmsterdamUMC/LSQ_fitting.py", "chunked_list": ["\"\"\"\n\tSeptember 2020 by Oliver Gurney-Champion\n\toliver.gurney.champion@gmail.com / o.j.gurney-champion@amsterdamumc.nl\n\thttps://www.github.com/ochampion\n\trequirements:\n\tnumpy\n\ttqdm\n\tmatplotlib\n\tscipy\n\tjoblib\n", "\"\"\"\n\t# load relevant libraries\n\tfrom scipy.optimize import curve_fit, minimize\n\timport numpy as np\n\tfrom scipy import stats\n\tfrom joblib import Parallel, delayed\n\timport sys\n\tif sys.stderr.isatty():\n\t    from tqdm import tqdm\n\telse:\n", "    def tqdm(iterable, **kwargs):\n\t        return iterable\n\timport warnings\n\tdef ivimN(bvalues, Dt, Fp, Dp, S0):\n\t    # IVIM function in which we try to have equal variance in the different IVIM parameters; equal variance helps with certain fitting algorithms\n\t    return S0 * ivimN_noS0(bvalues, Dt, Fp, Dp)\n\tdef ivimN_noS0(bvalues, Dt, Fp, Dp):\n\t    # IVIM function in which we try to have equal variance in the different IVIM parameters and S0=1\n\t    return (Fp / 10 * np.exp(-bvalues * Dp / 10) + (1 - Fp / 10) * np.exp(-bvalues * Dt / 1000))\n\tdef ivim(bvalues, Dt, Fp, Dp, S0):\n", "    # regular IVIM function\n\t    return (S0 * (Fp * np.exp(-bvalues * Dp) + (1 - Fp) * np.exp(-bvalues * Dt)))\n\tdef tri_expN(bvalues, Fp0, Dt, Fp1, Dp1, Fp2, Dp2):\n\t    # tri-exp function in which we try to have equal variance in the different IVIM parameters; equal variance helps with certain fitting algorithms\n\t    return (Fp1 / 10 * np.exp(-bvalues * Dp1 / 100) + Fp2 / 10 * np.exp(-bvalues * Dp2 / 10) + (Fp0 / 10) * np.exp(-bvalues * Dt / 1000))\n\tdef tri_expN_noS0(bvalues, Dt, Fp1, Dp1, Fp2, Dp2):\n\t    # tri-exp function in which we try to have equal variance in the different IVIM parameters and S0=1\n\t    return (Fp1 / 10 * np.exp(-bvalues * Dp1 / 100) + Fp2 / 10 * np.exp(-bvalues * Dp2 / 10) + (1 - Fp1 / 10 - Fp2 / 10) * np.exp(-bvalues * Dt / 1000))\n\tdef tri_exp(bvalues, Fp0, Dt, Fp1, Dp1, Fp2, Dp2):\n\t    # tri-exp function in which we try to have equal variance in the different IVIM parameters; equal variance helps with certain fitting algorithms\n", "    return (Fp1 * np.exp(-bvalues * Dp1) + Fp2 * np.exp(-bvalues * Dp2) + (Fp0) * np.exp(-bvalues * Dt))\n\tdef order(Dt, Fp, Dp, S0=None):\n\t    # function to reorder D* and D in case they were swapped during unconstraint fitting. Forces D* > D (Dp>Dt)\n\t    if Dp < Dt:\n\t        Dp, Dt = Dt, Dp\n\t        Fp = 1 - Fp\n\t    if S0 is None:\n\t        return Dt, Fp, Dp\n\t    else:\n\t        return Dt, Fp, Dp, S0\n", "def fit_segmented_array(bvalues, dw_data, njobs=4, bounds=([0, 0, 0.005],[0.005, 0.7, 0.2]), cutoff=75):\n\t    \"\"\"\n\t    This is an implementation of the segmented fit, in which we first estimate D using a curve fit to b-values>cutoff;\n\t    then estimate f from the fitted S0 and the measured S0 and finally estimate D* while fixing D and f. This fit\n\t    is done on an array.\n\t    :param bvalues: 1D Array with the b-values\n\t    :param dw_data: 2D Array with diffusion-weighted signal in different voxels at different b-values\n\t    :param njobs: Integer determining the number of parallel processes; default = 4\n\t    :param bounds: 2D Array with fit bounds ([Dtmin, Fpmin, Dpmin, S0min],[Dtmax, Fpmax, Dpmax, S0max]). Default: ([0.005, 0, 0, 0.8], [0.2, 0.7, 0.005, 1.2])\n\t    :param cutoff: cutoff value for determining which data is taken along in fitting D\n", "    :return Dt: 1D Array with D in each voxel\n\t    :return Fp: 1D Array with f in each voxel\n\t    :return Dp: 1D Array with Dp in each voxel\n\t    :return S0: 1D Array with S0 in each voxel\n\t    \"\"\"\n\t    # first we normalise the signal to S0\n\t    S0 = np.mean(dw_data[:, bvalues == 0], axis=1)\n\t    dw_data = dw_data / S0[:, None]\n\t    # here we try parallel computing, but if fails, go back to computing one single core.\n\t    single = False\n", "    if njobs > 2:\n\t        try:\n\t            # define the parallel function\n\t            def parfun(i):\n\t                return fit_segmented(bvalues, dw_data[i, :], bounds=bounds, cutoff=cutoff)\n\t            output = Parallel(n_jobs=njobs)(delayed(parfun)(i) for i in tqdm(range(len(dw_data)), position=0, leave=True))\n\t            Dt, Fp, Dp = np.transpose(output)\n\t        except:\n\t            # if fails, retry using single core\n\t            single = True\n", "    else:\n\t        # or, if specified, immediately go to single core\n\t        single = True\n\t    if single:\n\t        # initialize empty arrays\n\t        Dp = np.zeros(len(dw_data))\n\t        Dt = np.zeros(len(dw_data))\n\t        Fp = np.zeros(len(dw_data))\n\t        for i in tqdm(range(len(dw_data)), position=0, leave=True):\n\t            # fill arrays with fit results on a per voxel base:\n", "            Dt[i], Fp[i], Dp[i] = fit_segmented(bvalues, dw_data[i, :], bounds=bounds, cutoff=cutoff)\n\t    return [Dt, Fp, Dp, S0]\n\tdef fit_segmented(bvalues, dw_data, bounds=([0, 0, 0.005],[0.005, 0.7, 0.2]), cutoff=75):\n\t    \"\"\"\n\t    This is an implementation of the segmented fit, in which we first estimate D using a curve fit to b-values>cutoff;\n\t    then estimate f from the fitted S0 and the measured S0 and finally estimate D* while fixing D and f.\n\t    :param bvalues: Array with the b-values\n\t    :param dw_data: Array with diffusion-weighted signal at different b-values\n\t    :param bounds: Array with fit bounds ([Dtmin, Fpmin, Dpmin, S0min],[Dtmax, Fpmax, Dpmax, S0max]). Default: ([0.005, 0, 0, 0.8], [0.2, 0.7, 0.005, 1.2])\n\t    :param cutoff: cutoff value for determining which data is taken along in fitting D\n", "    :return Dt: Fitted D\n\t    :return Fp: Fitted f\n\t    :return Dp: Fitted Dp\n\t    :return S0: Fitted S0\n\t    \"\"\"\n\t    try:\n\t        # determine high b-values and data for D\n\t        high_b = bvalues[bvalues >= cutoff]\n\t        high_dw_data = dw_data[bvalues >= cutoff]\n\t        # correct the bounds. Note that S0 bounds determine the max and min of f\n", "        bounds1 = ([bounds[0][0] * 1000., 1 - bounds[1][1]], [bounds[1][0] * 1000., 1. - bounds[0][\n\t            1]])  # By bounding S0 like this, we effectively insert the boundaries of f\n\t        # fit for S0' and D\n\t        params, _ = curve_fit(lambda b, Dt, int: int * np.exp(-b * Dt / 1000), high_b, high_dw_data,\n\t                              p0=(1, 1),\n\t                              bounds=bounds1)\n\t        Dt, Fp = params[0] / 1000, 1 - params[1]\n\t        # remove the diffusion part to only keep the pseudo-diffusion\n\t        dw_data_remaining = dw_data - (1 - Fp) * np.exp(-bvalues * Dt)\n\t        bounds2 = (bounds[0][2], bounds[1][2])\n", "        # fit for D*\n\t        params, _ = curve_fit(lambda b, Dp: Fp * np.exp(-b * Dp), bvalues, dw_data_remaining, p0=(0.1), bounds=bounds2)\n\t        Dp = params[0]\n\t        return Dt, Fp, Dp\n\t    except:\n\t        # if fit fails, return zeros\n\t        # print('segnetned fit failed')\n\t        return 0., 0., 0.\n\tdef fit_least_squares_array(bvalues, dw_data, S0_output=True, fitS0=True, njobs=4,\n\t                            bounds=([0, 0, 0.005, 0.7],[0.005, 0.7, 0.2, 1.3])):\n", "    \"\"\"\n\t    This is an implementation of the conventional IVIM fit. It is fitted in array form.\n\t    :param bvalues: 1D Array with the b-values\n\t    :param dw_data: 2D Array with diffusion-weighted signal in different voxels at different b-values\n\t    :param S0_output: Boolean determining whether to output (often a dummy) variable S0; default = True\n\t    :param fix_S0: Boolean determining whether to fix S0 to 1; default = False\n\t    :param njobs: Integer determining the number of parallel processes; default = 4\n\t    :param bounds: Array with fit bounds ([Dtmin, Fpmin, Dpmin, S0min],[Dtmax, Fpmax, Dpmax, S0max]). Default: ([0.005, 0, 0, 0.8], [0.2, 0.7, 0.005, 1.2])\n\t    :return Dt: 1D Array with D in each voxel\n\t    :return Fp: 1D Array with f in each voxel\n", "    :return Dp: 1D Array with Dp in each voxel\n\t    :return S0: 1D Array with S0 in each voxel\n\t    \"\"\"\n\t    # normalise the data to S(value=0)\n\t    S0 = np.mean(dw_data[:, bvalues == 0], axis=1)\n\t    dw_data = dw_data / S0[:, None]\n\t    single = False\n\t    # split up on whether we want S0 as output\n\t    if S0_output:\n\t        # check if parallel is desired\n", "        if njobs > 1:\n\t            try:\n\t                # defining parallel function\n\t                def parfun(i):\n\t                    return fit_least_squares(bvalues, dw_data[i, :], S0_output=S0_output, fitS0=fitS0, bounds=bounds)\n\t                output = Parallel(n_jobs=njobs)(delayed(parfun)(i) for i in tqdm(range(len(dw_data)), position=0, leave=True))\n\t                Dt, Fp, Dp, S0 = np.transpose(output)\n\t            except:\n\t                single = True\n\t        else:\n", "            single = True\n\t        if single:\n\t            # run on single core, instead. Defining empty arrays\n\t            Dp = np.zeros(len(dw_data))\n\t            Dt = np.zeros(len(dw_data))\n\t            Fp = np.zeros(len(dw_data))\n\t            S0 = np.zeros(len(dw_data))\n\t            # running in a single loop and filling arrays\n\t            for i in tqdm(range(len(dw_data)), position=0, leave=True):\n\t                Dt[i], Fp[i], Dp[i], S0[i] = fit_least_squares(bvalues, dw_data[i, :], S0_output=S0_output, fitS0=fitS0,\n", "                                                               bounds=bounds)\n\t        return [Dt, Fp, Dp, S0]\n\t    else:\n\t        # if S0 is not exported\n\t        if njobs > 1:\n\t            try:\n\t                def parfun(i):\n\t                    return fit_least_squares(bvalues, dw_data[i, :], fitS0=fitS0, bounds=bounds)\n\t                output = Parallel(n_jobs=njobs)(delayed(parfun)(i) for i in tqdm(range(len(dw_data)), position=0, leave=True))\n\t                Dt, Fp, Dp = np.transpose(output)\n", "            except:\n\t                single = True\n\t        else:\n\t            single = True\n\t        if single:\n\t            Dp = np.zeros(len(dw_data))\n\t            Dt = np.zeros(len(dw_data))\n\t            Fp = np.zeros(len(dw_data))\n\t            for i in range(len(dw_data)):\n\t                Dt[i], Fp[i], Dp[i] = fit_least_squares(bvalues, dw_data[i, :], S0_output=S0_output, fitS0=fitS0,\n", "                                                        bounds=bounds)\n\t        return [Dt, Fp, Dp]\n\tdef fit_least_squares(bvalues, dw_data, S0_output=False, fitS0=True,\n\t                      bounds=([0, 0, 0.005, 0.7],[0.005, 0.7, 0.2, 1.3])):\n\t    \"\"\"\n\t    This is an implementation of the conventional IVIM fit. It fits a single curve\n\t    :param bvalues: Array with the b-values\n\t    :param dw_data: Array with diffusion-weighted signal at different b-values\n\t    :param S0_output: Boolean determining whether to output (often a dummy) variable S0; default = True\n\t    :param fix_S0: Boolean determining whether to fix S0 to 1; default = False\n", "    :param bounds: Array with fit bounds ([Dtmin, Fpmin, Dpmin, S0min],[Dtmax, Fpmax, Dpmax, S0max]). Default: ([0.005, 0, 0, 0.8], [0.2, 0.7, 0.005, 1.2])\n\t    :return Dt: Array with D in each voxel\n\t    :return Fp: Array with f in each voxel\n\t    :return Dp: Array with Dp in each voxel\n\t    :return S0: Array with S0 in each voxel\n\t    \"\"\"\n\t    try:\n\t        if not fitS0:\n\t            # bounds are rescaled such that each parameter changes at roughly the same rate to help fitting.\n\t            bounds = ([bounds[0][0] * 1000, bounds[0][1] * 10, bounds[0][2] * 10],\n", "                      [bounds[1][0] * 1000, bounds[1][1] * 10, bounds[1][2] * 10])\n\t            params, _ = curve_fit(ivimN_noS0, bvalues, dw_data, p0=[1, 1, 0.1], bounds=bounds)\n\t            S0 = 1\n\t        else:\n\t            # bounds are rescaled such that each parameter changes at roughly the same rate to help fitting.\n\t            bounds = ([bounds[0][0] * 1000, bounds[0][1] * 10, bounds[0][2] * 10, bounds[0][3]],\n\t                      [bounds[1][0] * 1000, bounds[1][1] * 10, bounds[1][2] * 10, bounds[1][3]])\n\t            params, _ = curve_fit(ivimN, bvalues, dw_data, p0=[1, 1, 0.1, 1], bounds=bounds)\n\t            S0 = params[3]\n\t        # correct for the rescaling of parameters\n", "        Dt, Fp, Dp = params[0] / 1000, params[1] / 10, params[2] / 10\n\t        # reorder output in case Dp<Dt\n\t        if S0_output:\n\t            return order(Dt, Fp, Dp, S0)\n\t        else:\n\t            return order(Dt, Fp, Dp)\n\t    except:\n\t        # if fit fails, then do a segmented fit instead\n\t        # print('lsq fit failed, trying segmented')\n\t        if S0_output:\n", "            Dt, Fp, Dp = fit_segmented(bvalues, dw_data, bounds=bounds)\n\t            return Dt, Fp, Dp, 1\n\t        else:\n\t            return fit_segmented(bvalues, dw_data)\n\tdef fit_least_squares_array_tri_exp(bvalues, dw_data, S0_output=True, fitS0=True, njobs=4,\n\t                            bounds=([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5])):\n\t    \"\"\"\n\t    This is an implementation of a tri-exponential fit. It is fitted in array form.\n\t    :param bvalues: 1D Array with the b-values\n\t    :param dw_data: 2D Array with diffusion-weighted signal in different voxels at different b-values\n", "    :param S0_output: Boolean determining whether to output (often a dummy) variable S0; default = True\n\t    :param fix_S0: Boolean determining whether to fix S0 to 1; default = False\n\t    :param njobs: Integer determining the number of parallel processes; default = 4\n\t    :param bounds: Array with fit bounds ([fp0min, Dtmin, Fp1min, Dp1min, Fp2min, Dp2min],[fp0max, Dtmax, Fp1max, Dp1max, Fp2max, Dp2max]). Default: ([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5])\n\t    :return S0: optional 1D Array with S0 in each voxel\n\t    :return Dt: 1D Array with D in each voxel\n\t    :return Fp1: 1D Array with Fp1 in each voxel\n\t    :return Dp1: 1D Array with Dp1 in each voxel\n\t    :return Fp2: 1D Array with Fp2 in each voxel\n\t    :return Dp2: 1D Array with Dp2 in each voxel\n", "    \"\"\"\n\t    # normalise the data to S(value=0)\n\t    S0 = np.mean(dw_data[:, bvalues == 0], axis=1)\n\t    dw_data = dw_data / S0[:, None]\n\t    single = False\n\t    # check if parallel is desired\n\t    if njobs > 1:\n\t        try:\n\t            # defining parallel function\n\t            def parfun(i):\n", "                return fit_least_squares_tri_exp(bvalues, dw_data[i, :], S0_output=S0_output, fitS0=fitS0, bounds=bounds)\n\t            output = Parallel(n_jobs=njobs)(delayed(parfun)(i) for i in tqdm(range(len(dw_data)), position=0, leave=True))\n\t            Fp0, Dt, Fp1, Dp1, Fp2, Dp2 = np.transpose(output)\n\t        except:\n\t            single = True\n\t    else:\n\t        single = True\n\t    if single:\n\t        # run on single core, instead. Defining empty arrays\n\t        Dp1 = np.zeros(len(dw_data))\n", "        Dt = np.zeros(len(dw_data))\n\t        Fp1 = np.zeros(len(dw_data))\n\t        Fp0 = np.zeros(len(dw_data))\n\t        Fp2 = np.zeros(len(dw_data))\n\t        Dp2 = np.zeros(len(dw_data))\n\t        # running in a single loop and filling arrays\n\t        for i in tqdm(range(len(dw_data)), position=0, leave=True):\n\t            Fp0[i], Dt[i], Fp1[i], Dp1[i], Fp2[i], Dp2[i] = fit_least_squares_tri_exp(bvalues, dw_data[i, :], S0_output=S0_output, fitS0=fitS0,\n\t                                                           bounds=bounds)\n\t    if S0_output:\n", "        return [Fp0+Fp1+Fp2, Dt, Fp1/(Fp0+Fp1+Fp2), Dp1, Fp2/(Fp0+Fp1+Fp2), Dp2]\n\t    else:\n\t        return [Dt, Fp1/(Fp0+Fp1+Fp2), Dp1, Fp2/(Fp0+Fp1+Fp2), Dp2]\n\tdef fit_least_squares_tri_exp(bvalues, dw_data, S0_output=False, fitS0=True,\n\t                      bounds=([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5])):\n\t    \"\"\"\n\t    This is an implementation of the tri-exponential fit. It fits a single curve\n\t    :param bvalues: 1D Array with the b-values\n\t    :param dw_data: 2D Array with diffusion-weighted signal in different voxels at different b-values\n\t    :param S0_output: Boolean determining whether to output (often a dummy) variable S0; default = True\n", "    :param fix_S0: Boolean determining whether to fix S0 to 1; default = False\n\t    :param bounds: Array with fit bounds ([fp0min, Dtmin, Fp1min, Dp1min, Fp2min, Dp2min],[fp0max, Dtmax, Fp1max, Dp1max, Fp2max, Dp2max]). Default: ([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5])\n\t    :return Fp0: optional 1D Array with f0 in each voxel\n\t    :return Dt: 1D Array with D in each voxel\n\t    :return Fp1: 1D Array with fp1 in each voxel\n\t    :return Dp1: 1D Array with Dp1 in each voxel\n\t    :return Fp2: 1D Array with the fraciton of signal for Dp2 in each voxel\n\t    :return Dp2: 1D Array with Dp2 in each voxel\n\t    \"\"\"\n\t    try:\n", "        if not fitS0:\n\t            # bounds are rescaled such that each parameter changes at roughly the same rate to help fitting.\n\t            bounds = ([bounds[0][1] * 1000, bounds[0][2] * 10, bounds[0][3] * 100, bounds[0][4] * 10, bounds[0][5] * 10],\n\t                      [bounds[1][1] * 1000, bounds[1][2] * 10, bounds[1][3] * 100, bounds[1][4] * 10, bounds[1][5] * 10])\n\t            params, _ = curve_fit(tri_expN_noS0, bvalues, dw_data, p0=[1.5, 1, 3, 1, 1.5], bounds=bounds)\n\t            Fp0 = 1 - params[1] / 10 - params[3] / 10\n\t            Dt, Fp1, Dp1, Fp2, Dp2 = params[0] / 1000, params[1] / 10, params[2] / 100, params[3] / 10, params[4] / 10\n\t        else:\n\t            # bounds are rescaled such that each parameter changes at roughly the same rate to help fitting.\n\t            bounds = ([bounds[0][0] * 10, bounds[0][1] * 1000, bounds[0][2] * 10, bounds[0][3] * 100, bounds[0][4] * 10, bounds[0][5] * 10],\n", "                      [bounds[1][0] * 10, bounds[1][1] * 1000, bounds[1][2] * 10, bounds[1][3] * 100, bounds[1][4] * 10, bounds[1][5] * 10])\n\t            params, _ = curve_fit(tri_expN, bvalues, dw_data, p0=[8, 1.0, 1, 3, 1, 1.5], bounds=bounds)\n\t            Fp0 = params[0]/10\n\t            Dt, Fp1, Dp1, Fp2, Dp2 = params[1] / 1000, params[2] / 10, params[3] / 100, params[4] / 10, params[5] / 10\n\t        # correct for the rescaling of parameters\n\t        # reorder output in case Dp<Dt\n\t        if S0_output:\n\t            #Dt, Fp, Dp, Fp2, Dp2 = order_tri(Dt, Fp, Dp, Fp2, Dp2)\n\t            return Fp0, Dt, Fp1, Dp1, Fp2, Dp2\n\t        else:\n", "            return Dt, Fp1, Dp1, Fp2, Dp2\n\t    except:\n\t        # if fit fails, then do a segmented fit instead\n\t        # print('lsq fit failed, trying segmented')\n\t        if S0_output:\n\t            return 0, 0, 0, 0, 0, 0\n\t        else:\n\t            return 0, 0, 0, 0, 0\n\tdef fit_segmented_array_tri_exp(bvalues, dw_data, njobs=4, bounds=([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5]), cutoff=[15, 120]):\n\t    \"\"\"\n", "    This is an implementation of the segmented fit for a tri-exp model, in which we first estimate D using a curve fit to b-values>cutoff;\n\t    then estimate f from the fitted S0 and the measured S0 and finally estimate D* while fixing D and f. This fit\n\t    is done on an array.\n\t    :param bvalues: 1D Array with the b-values\n\t    :param dw_data: 2D Array with diffusion-weighted signal in different voxels at different b-values\n\t    :param njobs: Integer determining the number of parallel processes; default = 4\n\t    :param bounds: Array with fit bounds ([fp0min, Dtmin, Fp1min, Dp1min, Fp2min, Dp2min],[fp0max, Dtmax, Fp1max, Dp1max, Fp2max, Dp2max]). Default: ([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5])\n\t    :param cutoff: 2 cutoff values for determining which data is taken along in fitting D, and subsequently D* and F\n\t    :return S0: 1D Array with S0 in each voxel\n\t    :return Dt: 1D Array with D in each voxel\n", "    :return Fp1: 1D Array with Fp1 in each voxel\n\t    :return Dp1: 1D Array with Dp1 in each voxel\n\t    :return Fp2: 1D Array with Fp2 in each voxel\n\t    :return Dp2: 1D Array with Dp2 in each voxel\n\t    \"\"\"\n\t    # first we normalise the signal to S0\n\t    S0 = np.mean(dw_data[:, bvalues == 0], axis=1)\n\t    dw_data = dw_data / S0[:, None]\n\t    # here we try parallel computing, but if fails, go back to computing one single core.\n\t    single = False\n", "    if njobs > 2:\n\t        try:\n\t            # define the parallel function\n\t            def parfun(i):\n\t                return fit_segmented(bvalues, dw_data[i, :], bounds=bounds, cutoff=cutoff)\n\t            output = Parallel(n_jobs=njobs)(delayed(parfun)(i) for i in tqdm(range(len(dw_data)), position=0, leave=True))\n\t            Dt, Fp, Dp, Fp0, Fp2, Dp2 = np.transpose(output)\n\t        except:\n\t            # if fails, retry using single core\n\t            single = True\n", "    else:\n\t        # or, if specified, immediately go to single core\n\t        single = True\n\t    if single:\n\t        # initialize empty arrays\n\t        Dp1 = np.zeros(len(dw_data))\n\t        Dt = np.zeros(len(dw_data))\n\t        Fp0 = np.zeros(len(dw_data))\n\t        Fp1 = np.zeros(len(dw_data))\n\t        Dp2 = np.zeros(len(dw_data))\n", "        Fp2 = np.zeros(len(dw_data))\n\t        for i in tqdm(range(len(dw_data)), position=0, leave=True):\n\t            # fill arrays with fit results on a per voxel base:\n\t            Fp0[i], Dt[i], Fp1[i], Dp1[i], Fp2[i], Dp2[i] = fit_segmented_tri_exp(bvalues, dw_data[i, :], bounds=bounds, cutoff=cutoff)\n\t    return [Fp0+Fp1+Fp2, Dt, Fp1/(Fp0+Fp1+Fp2), Dp1, Fp2/(Fp0+Fp1+Fp2), Dp2]\n\tdef fit_segmented_tri_exp(bvalues, dw_data, bounds=([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5]), cutoff=[15, 120]):\n\t    \"\"\"\n\t    This is an implementation of the segmented fit, in which we first estimate D using a curve fit to b-values>cutoff;\n\t    then estimate f from the fitted S0 and the measured S0 and finally estimate D* while fixing D and f.\n\t    :param bvalues: Array with the b-values\n", "    :param dw_data: Array with diffusion-weighted signal at different b-values\n\t    :param bounds: Array with fit bounds ([fp0min, Dtmin, Fp1min, Dp1min, Fp2min, Dp2min],[fp0max, Dtmax, Fp1max, Dp1max, Fp2max, Dp2max]). Default: ([0, 0, 0, 0.005, 0, 0.06], [2.5, 0.005, 1, 0.06, 1, 0.5])\n\t    :param cutoff: 2 cutoff values for determining which data is taken along in fitting D, and subsequently D* and F\n\t    :return Fp0: 1D Array with Fp1 in each voxel\n\t    :return Dt: Fitted D\n\t    :return Fp1: Fitted f\n\t    :return Dp1: Fitted Dp\n\t    :return Fp2: Fitted Fp2\n\t    :return Dp2: Fitted Dp2\n\t    \"\"\"\n", "    try:\n\t        # determine high b-values and data for D\n\t        high_b = bvalues[bvalues >= cutoff[1]]\n\t        high_dw_data = dw_data[bvalues >= cutoff[1]]\n\t        bounds1 = ([bounds[0][1] * 1000., 0], [bounds[1][1] * 1000., 1])\n\t        # fit for S0' and D\n\t        params, _ = curve_fit(lambda b, Dt, int: int * np.exp(-b * Dt / 1000), high_b, high_dw_data,\n\t                              p0=(1, 1),\n\t                              bounds=bounds1)\n\t        Dt, Fp0 = params[0] / 1000, params[1]\n", "        # remove the diffusion part to only keep the pseudo-diffusion\n\t        dw_data = dw_data - Fp0 * np.exp(-bvalues * Dt)\n\t        # for another round:\n\t        high_b = bvalues[bvalues >= cutoff[0]]\n\t        high_dw_data = dw_data[bvalues >= cutoff[0]]\n\t        high_b2 = high_b[high_b <= cutoff[1]*1.5]\n\t        high_dw_data = high_dw_data[high_b <= cutoff[1]*1.5]\n\t        bounds1 = ([bounds[0][3] * 10., bounds[0][2]], [bounds[1][3] * 10., bounds[1][2]])\n\t        # fit for f0' and Dp1\n\t        params, _ = curve_fit(lambda b, Dt, int: int * np.exp(-b * Dt / 10), high_b2, high_dw_data,\n", "                              p0=(0.1, min(0.1)), bounds=bounds1)\n\t        Dp, Fp = params[0] / 10, params[1]\n\t        # remove the diffusion part to only keep the pseudo-diffusion\n\t        dw_data = dw_data - Fp * np.exp(-bvalues * Dp)\n\t        dw_data = dw_data[bvalues <= cutoff[0]*2]\n\t        bvalueslow = bvalues[bvalues <= cutoff[0]*2]\n\t        bounds1 = (bounds[0][5], bounds[1][5])\n\t        # fit for D*\n\t        Fp2 = 1 - Fp0 - Fp\n\t        params, _ = curve_fit(lambda b, Dp: Fp2 * np.exp(-b * Dp), bvalueslow, dw_data, p0=(0.1), bounds=bounds1)\n", "        Dp2 = params[0]\n\t        return Fp0, Dt, Fp, Dp, Fp2, Dp2\n\t    except:\n\t        # if fit fails, return zeros\n\t        # print('segnetned fit failed')\n\t        return 0., 0., 0., 0., 0., 0.\n\tdef empirical_neg_log_prior(Dt0, Fp0, Dp0, S00=None):\n\t    \"\"\"\n\t    This function determines the negative of the log of the empirical prior probability of the IVIM parameters\n\t    :param Dt0: 1D Array with the initial D estimates\n", "    :param Dt0: 1D Array with the initial f estimates\n\t    :param Dt0: 1D Array with the initial D* estimates\n\t    :param Dt0: 1D Array with the initial S0 estimates (optional)\n\t    \"\"\"\n\t    # Dp0, Dt0, Fp0 are flattened arrays\n\t    # only take valid voxels along, in which the initial estimates were sensible and successful\n\t    Dp_valid = (1e-8 < np.nan_to_num(Dp0)) & (np.nan_to_num(Dp0) < 1 - 1e-8)\n\t    Dt_valid = (1e-8 < np.nan_to_num(Dt0)) & (np.nan_to_num(Dt0) < 1 - 1e-8)\n\t    Fp_valid = (1e-8 < np.nan_to_num(Fp0)) & (np.nan_to_num(Fp0) < 1 - 1e-8)\n\t    # determine whether we fit S0\n", "    if S00 is not None:\n\t        S0_valid = (1e-8 < np.nan_to_num(S00)) & (np.nan_to_num(S00) < 2 - 1e-8)\n\t        valid = Dp_valid & Dt_valid & Fp_valid & S0_valid\n\t        Dp0, Dt0, Fp0, S00 = Dp0[valid], Dt0[valid], Fp0[valid], S00[valid]\n\t    else:\n\t        valid = Dp_valid & Dt_valid & Fp_valid\n\t        Dp0, Dt0, Fp0 = Dp0[valid], Dt0[valid], Fp0[valid]\n\t    # determine prior's shape. Note that D, D* and S0 are shaped as lognorm distributions whereas f is a beta distribution\n\t    Dp_shape, _, Dp_scale = stats.lognorm.fit(Dp0, floc=0)\n\t    Dt_shape, _, Dt_scale = stats.lognorm.fit(Dt0, floc=0)\n", "    Fp_a, Fp_b, _, _ = stats.beta.fit(Fp0, floc=0, fscale=1)\n\t    if S00 is not None:\n\t        S0_a, S0_b, _, _ = stats.beta.fit(S00, floc=0, fscale=2)\n\t    # define the prior\n\t    def neg_log_prior(p):\n\t        # depends on whether S0 is fitted or not\n\t        if len(p) == 4:\n\t            Dt, Fp, Dp, S0 = p[0], p[1], p[2], p[3]\n\t        else:\n\t            Dt, Fp, Dp = p[0], p[1], p[2]\n", "        # make D*<D very unlikely\n\t        if (Dp < Dt):\n\t            return 1e8\n\t        else:\n\t            eps = 1e-8\n\t            Dp_prior = stats.lognorm.pdf(Dp, Dp_shape, scale=Dp_scale)\n\t            Dt_prior = stats.lognorm.pdf(Dt, Dt_shape, scale=Dt_scale)\n\t            Fp_prior = stats.beta.pdf(Fp, Fp_a, Fp_b)\n\t            # determine and return the prior for D, f and D* (and S0)\n\t            if len(p) == 4:\n", "                S0_prior = stats.beta.pdf(S0 / 2, S0_a, S0_b)\n\t                return -np.log(Dp_prior + eps) - np.log(Dt_prior + eps) - np.log(Fp_prior + eps) - np.log(\n\t                    S0_prior + eps)\n\t            else:\n\t                return -np.log(Dp_prior + eps) - np.log(Dt_prior + eps) - np.log(Fp_prior + eps)\n\t    return neg_log_prior\n\tdef neg_log_likelihood(p, bvalues, dw_data):\n\t    \"\"\"\n\t    This function determines the negative of the log of the likelihood of parameters p, given the data dw_data for the Bayesian fit\n\t    :param p: 1D Array with the estimates of D, f, D* and (optionally) S0\n", "    :param bvalues: 1D array with b-values\n\t    :param dw_data: 1D Array diffusion-weighted data\n\t    :returns: the log-likelihood of the parameters given the data\n\t    \"\"\"\n\t    if len(p) == 4:\n\t        return 0.5 * (len(bvalues) + 1) * np.log(\n\t            np.sum((ivim(bvalues, p[0], p[1], p[2], p[3]) - dw_data) ** 2))  # 0.5*sum simplified\n\t    else:\n\t        return 0.5 * (len(bvalues) + 1) * np.log(\n\t            np.sum((ivim(bvalues, p[0], p[1], p[2], 1) - dw_data) ** 2))  # 0.5*sum simplified\n", "def neg_log_posterior(p, bvalues, dw_data, neg_log_prior):\n\t    \"\"\"\n\t    This function determines the negative of the log of the likelihood of parameters p, given the prior likelihood and the data\n\t    :param p: 1D Array with the estimates of D, f, D* and (optionally) S0\n\t    :param bvalues: 1D array with b-values\n\t    :param dw_data: 1D Array diffusion-weighted data\n\t    :param neg_log_prior: prior likelihood function (created with empirical_neg_log_prior)\n\t    :returns: the posterior probability given the data and the prior\n\t    \"\"\"\n\t    return neg_log_likelihood(p, bvalues, dw_data) + neg_log_prior(p)\n", "def fit_bayesian_array(bvalues, dw_data, paramslsq, arg):\n\t    \"\"\"\n\t    This is an implementation of the Bayesian IVIM fit for arrays. The fit is taken from Barbieri et al. which was\n\t    initially introduced in http://arxiv.org/10.1002/mrm.25765 and later further improved in\n\t    http://arxiv.org/abs/1903.00095. If found useful, please cite those papers.\n\t    :param bvalues: Array with the b-values\n\t    :param dw_data: 2D Array with diffusion-weighted signal in different voxels at different b-values\n\t    :param paramslsq: 2D Array with initial estimates for the parameters. These form the base for the Bayesian prior\n\t    distribution and are typically obtained by least squares fitting of the data\n\t    :param arg: an object with fit options, with attributes:\n", "    arg.fitS0 --> Boolean; False fixes S0 to 1, True fits S0\n\t    arg.jobs --> Integer specifying the number of parallel processes used in fitting. If <2, regular fitting is used instead\n\t    arg.bounds --> 2D Array of fit bounds ([Dtmin, Fpmin, Dpmin, S0min],[Dtmax, Fpmax, Dpmax, S0max])\n\t    :return Dt: Array with D in each voxel\n\t    :return Fp: Array with f in each voxel\n\t    :return Dp: Array with Dp in each voxel\n\t    :return S0: Array with S0 in each voxel\n\t    \"\"\"\n\t    arg = checkarg_lsq(arg)\n\t    # fill out missing args\n", "    Dt0, Fp0, Dp0, S00 = paramslsq\n\t    # determine prior\n\t    if arg.fitS0:\n\t        neg_log_prior = empirical_neg_log_prior(Dt0, Fp0, Dp0, S00)\n\t    else:\n\t        neg_log_prior = empirical_neg_log_prior(Dt0, Fp0, Dp0)\n\t    single = False\n\t    # determine whether we fit parallel or not\n\t    if arg.jobs > 1:\n\t        try:\n", "            # do parallel bayesian fit\n\t            def parfun(i):\n\t                # starting point\n\t                x0 = [Dt0[i], Fp0[i], Dp0[i], S00[i]]\n\t                return fit_bayesian(bvalues, dw_data[i, :], neg_log_prior, x0, fitS0=arg.fitS0)\n\t            output = Parallel(n_jobs=arg.jobs)(delayed(parfun)(i) for i in tqdm(range(len(dw_data)), position=0,\n\t                                                                                     leave=True))\n\t            Dt_pred, Fp_pred, Dp_pred, S0_pred = np.transpose(output)\n\t        except:\n\t            single = True\n", "    else:\n\t        single = True\n\t    if single:\n\t        # do serial; intialising arrays\n\t        Dp_pred = np.zeros(len(dw_data))\n\t        Dt_pred = np.zeros(len(dw_data))\n\t        Fp_pred = np.zeros(len(dw_data))\n\t        S0_pred = np.zeros(len(dw_data))\n\t        # fill in array while looping over voxels\n\t        for i in tqdm(range(len(dw_data)), position=0, leave=True):\n", "            # starting point\n\t            x0 = [Dt0[i], Fp0[i], Dp0[i], S00[i]]\n\t            Dt, Fp, Dp, S0 = fit_bayesian(bvalues, dw_data[i, :], neg_log_prior, x0, fitS0=arg.fitS0)\n\t            Dp_pred[i] = Dp\n\t            Dt_pred[i] = Dt\n\t            Fp_pred[i] = Fp\n\t            S0_pred[i] = S0\n\t    return Dt_pred, Fp_pred, Dp_pred, S0_pred\n\tdef fit_bayesian(bvalues, dw_data, neg_log_prior, x0=[0.001, 0.2, 0.05], fitS0=True):\n\t    '''\n", "    This is an implementation of the Bayesian IVIM fit. It returns the Maximum a posterior probability.\n\t    The fit is taken from Barbieri et al. which was initially introduced in http://arxiv.org/10.1002/mrm.25765 and\n\t    later further improved in http://arxiv.org/abs/1903.00095. If found useful, please cite those papers.\n\t    :param bvalues: Array with the b-values\n\t    :param dw_data: 1D Array with diffusion-weighted signal at different b-values\n\t    :param neg_log_prior: the prior\n\t    :param x0: 1D array with initial parameter guess\n\t    :param fitS0: boolean, if set to False, S0 is not fitted\n\t    :return Dt: estimated D\n\t    :return Fp: estimated f\n", "    :return Dp: estimated D*\n\t    :return S0: estimated S0 (optional)\n\t    '''\n\t    try:\n\t        # define fit bounds\n\t        bounds = [(0, 0.005), (0, 0.7), (0.005, 0.2), (0, 2.5)]\n\t        # Find the Maximum a posterior probability (MAP) by minimising the negative log of the posterior\n\t        if fitS0:\n\t            params = minimize(neg_log_posterior, x0=x0, args=(bvalues, dw_data, neg_log_prior), bounds=bounds)\n\t        else:\n", "            params = minimize(neg_log_posterior, x0=x0[:3], args=(bvalues, dw_data, neg_log_prior), bounds=bounds[:3])\n\t        if not params.success:\n\t            raise (params.message)\n\t        if fitS0:\n\t            Dt, Fp, Dp, S0 = params.x[0], params.x[1], params.x[2], params.x[3]\n\t        else:\n\t            Dt, Fp, Dp = params.x[0], params.x[1], params.x[2]\n\t            S0 = 1\n\t        return order(Dt, Fp, Dp, S0)\n\t    except:\n", "        # if fit fails, return regular lsq-fit result\n\t        # print('a bayes fit fialed')\n\t        return fit_least_squares(bvalues, dw_data, S0_output=True)\n\tdef goodness_of_fit(bvalues, Dt, Fp, Dp, S0, dw_data, Fp2=None, Dp2=None):\n\t    \"\"\"\n\t    Calculates the R-squared as a measure for goodness of fit.\n\t    input parameters are\n\t    :param b: 1D Array b-values\n\t    :param Dt: 1D Array with fitted D\n\t    :param Fp: 1D Array with fitted f\n", "    :param Dp: 1D Array with fitted D*\n\t    :param S0: 1D Array with fitted S0 (or ones)\n\t    :param dw_data: 2D array containing data, as voxels x b-values\n\t    :return R2: 1D Array with the R-squared for each voxel\n\t    \"\"\"\n\t    # simulate the IVIM signal given the D, f, D* and S0\n\t    try:\n\t        if Fp2 is None:\n\t            datasim = ivim(np.tile(np.expand_dims(bvalues, axis=0), (len(Dt), 1)),\n\t                           np.tile(np.expand_dims(Dt, axis=1), (1, len(bvalues))),\n", "                           np.tile(np.expand_dims(Fp, axis=1), (1, len(bvalues))),\n\t                           np.tile(np.expand_dims(Dp, axis=1), (1, len(bvalues))),\n\t                           np.tile(np.expand_dims(S0, axis=1), (1, len(bvalues)))).astype('f')\n\t        else:\n\t            datasim = tri_exp(np.tile(np.expand_dims(bvalues, axis=0), (len(Dt), 1)),\n\t                              np.tile(np.expand_dims(S0 * (1 - Fp - Fp2), axis=1), (1, len(bvalues))),\n\t                              np.tile(np.expand_dims(Dt, axis=1), (1, len(bvalues))),\n\t                              np.tile(np.expand_dims(Fp * S0, axis=1), (1, len(bvalues))),\n\t                              np.tile(np.expand_dims(Dp, axis=1), (1, len(bvalues))),\n\t                              np.tile(np.expand_dims(Fp2 * S0, axis=1), (1, len(bvalues))),\n", "                              np.tile(np.expand_dims(Dp2, axis=1), (1, len(bvalues))),\n\t                              ).astype('f')\n\t        # calculate R-squared given the estimated IVIM signal and the data\n\t        norm = np.mean(dw_data, axis=1)\n\t        ss_tot = np.sum(np.square(dw_data - norm[:, None]), axis=1)\n\t        ss_res = np.sum(np.square(dw_data - datasim), axis=1)\n\t        R2 = 1 - (ss_res / ss_tot)  # R-squared\n\t        if Fp2 is None:\n\t            adjusted_R2 = 1 - ((1 - R2) * (len(bvalues)) / (len(bvalues) - 4 - 1))\n\t        else:\n", "            adjusted_R2 = 1 - ((1 - R2) * (len(bvalues)) / (len(bvalues) - 6 - 1))\n\t        R2[R2 < 0] = 0\n\t        adjusted_R2[adjusted_R2 < 0] = 0\n\t    except:\n\t        if Fp2 is None:\n\t            datasim = ivim(bvalues, Dt, Fp, Dp, S0)\n\t        else:\n\t            datasim = tri_exp(bvalues, S0 * (1 - Fp - Fp2), Dt, Fp * S0, Dp, Fp2 * S0, Dp2)\n\t        norm = np.mean(dw_data)\n\t        ss_tot = np.sum(np.square(dw_data - norm))\n", "        ss_res = np.sum(np.square(dw_data - datasim))\n\t        R2 = 1 - (ss_res / ss_tot)  # R-squared\n\t        if Fp2 is None:\n\t            adjusted_R2 = 1 - ((1 - R2) * (len(bvalues)) / (len(bvalues) - 4 - 1))\n\t        else:\n\t            adjusted_R2 = 1 - ((1 - R2) * (len(bvalues)) / (len(bvalues) - 6 - 1))\n\t        # from matplotlib import pyplot as plt\n\t        # plt.figure(1)\n\t        # vox=58885\n\t        # plt.clf()\n", "        # plt.plot(bvalues, datasim[vox], 'rx', markersize=5)\n\t        # plt.plot(bvalues, dw_data[vox], 'bx', markersize=5)\n\t        # plt.ion()\n\t        # plt.show()\n\t        # print(R2[vox])\n\t    return R2, adjust\n\t# ed_R2\n\tdef MSE(bvalues, Dt, Fp, Dp, S0, dw_data):\n\t    \"\"\"\n\t    Calculates the MSE as a measure for goodness of fit.\n", "    input parameters are\n\t    :param b: 1D Array b-values\n\t    :param Dt: 1D Array with fitted D\n\t    :param Fp: 1D Array with fitted f\n\t    :param Dp: 1D Array with fitted D*\n\t    :param S0: 1D Array with fitted S0 (or ones)\n\t    :param dw_data: 2D array containing data, as voxels x b-values\n\t    :return MSError: 1D Array with the R-squared for each voxel\n\t    \"\"\"\n\t    # simulate the IVIM signal given the D, f, D* and S0\n", "    datasim = ivim(np.tile(np.expand_dims(bvalues, axis=0), (len(Dt), 1)),\n\t                   np.tile(np.expand_dims(Dt, axis=1), (1, len(bvalues))),\n\t                   np.tile(np.expand_dims(Fp, axis=1), (1, len(bvalues))),\n\t                   np.tile(np.expand_dims(Dp, axis=1), (1, len(bvalues))),\n\t                   np.tile(np.expand_dims(S0, axis=1), (1, len(bvalues)))).astype('f')\n\t    # calculate R-squared given the estimated IVIM signal and the data\n\t    MSError = np.mean(np.square(dw_data - datasim), axis=1)  # R-squared\n\t    return MSError"]}
{"filename": "src/original/IAR_LundUniversity/simple_test_of_fits.py", "chunked_list": ["import numpy as np\n\tfrom dipy.core.gradients import gradient_table\n\tfrom scipy.stats import norm\n\timport matplotlib.pyplot as plt\n\timport scienceplots\n\timport ivim_fit_method_biexp\n\timport ivim_fit_method_subtracted\n\timport ivim_fit_method_sivim\n\timport ivim_fit_method_linear\n\timport ivim_fit_method_segmented_3step\n", "import ivim_fit_method_segmented_2step\n\timport ivim_fit_method_modified_mix\n\timport ivim_fit_method_modified_topopro\n\tplt.style.use([\"science\", \"ieee\"])\n\tdef ivim_signal(b, S0, f, D_star, D):\n\t    return S0*(f*np.exp(-b*D_star) + (1-f)*np.exp(-b*D))\n\tdef diffusion_signal(b, S0, f, D):\n\t    return S0*(1-f)*np.exp(-b*D)\n\tdef generate_noise(loc, sigma):\n\t    real_component = norm.rvs(loc=loc, scale=sigma/loc)\n", "    imaginary_component = norm.rvs(loc=loc, scale=sigma/loc)\n\t    return np.absolute(complex(real_component, imaginary_component))\n\tdef add_rician_noise(signal, SNR):\n\t    sigma = signal[-1]/SNR\n\t    # Sample real and imaginary noise components from gaussian distributions\n\t    # Use the last b-value as the SNR baseline in order to avoid the noise floor\n\t    noise = np.array([generate_noise(signal_value, sigma) for signal_value in signal])\n\t    # Add the two components to the signal and take the magniutde of the result\n\t    noised_signal = signal + noise\n\t    noised_signal = np.absolute(noised_signal)\n", "    return noised_signal\n\t# Ground truth\n\tfactor = 1\n\tS0 = 1\n\tf = 0.1\n\tD_star = 30e-3\n\tD = 1e-3\n\trescale_units = False\n\t# Settings\n\tlower_bounds = (0, 5, 0)\n", "upper_bounds = (1, 100, 4)\n\tbounds_um = (lower_bounds, upper_bounds)\n\tlower_bounds = (0, 0.005, 0)\n\tupper_bounds = (1, 0.1, 0.004)\n\tbounds_mm = (lower_bounds, upper_bounds)\n\tinitial_guess_mm = (1, 0.2, 0.03, 0.001)\n\t# Create gtab containing b-value informations\n\tbvals = np.array([0, 50, 240, 800])/factor\n\tbvals = np.array([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, \\\n\t    150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800])\n", "bvals = np.array([0, 20, 40, 60, 80, 100, 150, 200, 300, 400, 500, 600, 700, 800])\n\t#bvals = np.array([0, 50, 240, 800])\n\tbvec = np.zeros((bvals.size, 3))\n\tbvec[:,2] = 1\n\tgtab = gradient_table(bvals, bvec, b0_threshold=0)\n\t# Signal\n\tsignal = ivim_signal(bvals, S0, f, D_star, D)\n\tnoised_signal = add_rician_noise(signal, 3)\n\tnoised_signal /= noised_signal[0]\n\tnoised_signal6 = add_rician_noise(signal, 6)\n", "noised_signal6 /= noised_signal6[0]\n\t# biexp fit\n\tbiexp_model = ivim_fit_method_biexp.IvimModelBiExp(gtab, bounds=bounds_mm, initial_guess=initial_guess_mm, rescale_units=rescale_units)\n\tbiexp_fit = biexp_model.fit(noised_signal)\n\t# sIVIM fit\n\tlower_bounds_sivim = (0, 0)\n\tupper_bounds_sivim = (1, 4/factor)\n\tbounds_mm_sivim = (lower_bounds_sivim, upper_bounds_sivim)\n\tinitial_guess_mm_sivim = (1, 0.2, 0.001)\n\tsivim_model = ivim_fit_method_sivim.IvimModelsIVIM(gtab, b_threshold=0.2, bounds=bounds_mm_sivim, initial_guess=initial_guess_mm_sivim, rescale_units=rescale_units)\n", "sivim_fit = sivim_model.fit(noised_signal)\n\t# linear fit\n\tlinear_model = ivim_fit_method_linear.IvimModelLinear(gtab, b_threshold=0.2, bounds=bounds_mm_sivim, rescale_units=rescale_units)\n\tlinear_fit = linear_model.fit(noised_signal)\n\t# Subtracted fit (Le Bihan 2019)\n\tsubtracted_model = ivim_fit_method_subtracted.IvimModelSubtracted(gtab, bounds=bounds_mm, initial_guess=initial_guess_mm, rescale_units=rescale_units)#, b_threshold_lower=0.2, b_threshold_upper=0.1)\n\tsubtracted_fit = subtracted_model.fit(noised_signal)\n\t# Segmented fit (3 step) (DIPY)\n\tsegmented_3step_model = ivim_fit_method_segmented_3step.IvimModelSegmented3Step(gtab, bounds=bounds_mm, initial_guess=initial_guess_mm, rescale_units=rescale_units)#, b_threshold_lower=0.2, b_threshold_upper=0.1)\n\tsegmented_3step_fit = segmented_3step_model.fit(noised_signal)\n", "# Segmented fit (2 step) (Conventional method)\n\tsegmented_2step_model = ivim_fit_method_segmented_2step.IvimModelSegmented2Step(gtab, bounds=bounds_mm, initial_guess=initial_guess_mm, rescale_units=rescale_units)#, b_threshold_lower=0.2)\n\tsegmented_2step_fit = segmented_2step_model.fit(noised_signal)\n\tsegmented_2step_fit6 = segmented_2step_model.fit(noised_signal6)\n\t# MIX (Farooq et al.)\n\tmix_model = ivim_fit_method_modified_mix.IvimModelVP(gtab, bounds=bounds_mm, rescale_units=rescale_units, rescale_results_to_mm2_s=True)\n\tmix_fit = mix_model.fit(noised_signal)\n\tmix_fit6 = mix_model.fit(noised_signal6)\n\t# TopoPro (Fadnavis et al.)\n\ttopopro_model = ivim_fit_method_modified_topopro.IvimModelTopoPro(gtab, bounds=bounds_mm, rescale_units=rescale_units, rescale_results_to_mm2_s=True)\n", "topopro_fit = topopro_model.fit(noised_signal)\n\ttopopro_fit6 = topopro_model.fit(noised_signal6)\n\t# Print estimates\n\tprint(f\"Bi-exponential: {biexp_fit.model_params}\")\n\tprint(f\"Linear: {linear_fit.model_params}\")\n\tprint(f\"sIVIM: {sivim_fit.model_params}\")\n\tprint(f\"Subtracted: {subtracted_fit.model_params}\")\n\tprint(f\"3-step segmented: {segmented_3step_fit.model_params}\")\n\tprint(f\"2-step segmented: {segmented_2step_fit.model_params}\")\n\tprint(f\"MIX: {mix_fit.model_params}\")\n", "print(f\"TopoPro: {topopro_fit.model_params}\")\n"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_subtracted.py", "chunked_list": ["\"\"\" Classes and functions for fitting ivim model \"\"\"\n\timport numpy as np\n\tfrom scipy.optimize import curve_fit\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tclass IvimModelSubtracted(ReconstModel):\n\t    def __init__(self, gtab, b_threshold_upper=100, b_threshold_lower=200, \\\n\t        initial_guess=None, bounds=None, rescale_units=False):\n\t        \"\"\"The subtracted method described by Le Bihan in\n", "        What can we see with IVIM MRI? NeuroImage. 2019 Feb 15;187:5667. \n\t        Args:\n\t            gtab (DIPY gtab class): \n\t                Object that holds the b-values.\n\t            b_threshold_upper (int, optional): \n\t                The upper threshold for the D* fit. Defaults to 100.\n\t            b_threshold_lower (int, optional): \n\t                The lower threshold of the D fit. Defaults to 200.\n\t            initial_guess (array-like, optional): \n\t                Initial guesses for f, D*, D repsectively. Defaults to None.\n", "            bounds (array-like, optional): \n\t                Tupple of (lower bounds, upper bounds) for f, D*, D respectively. \n\t                Defaults to None.\n\t            rescale_units (bool, optional): \n\t                Rescales the guesses and bounds to units of um2/ms. Make sure\n\t                the b-values are already in these units if used. \n\t                Defaults to False.\n\t        \"\"\"\n\t        self.bvals = gtab.bvals\n\t        self.perf_b_threshold_upper = b_threshold_upper\n", "        self.diff_b_threshold_lower = b_threshold_lower\n\t        self.set_bounds(bounds)\n\t        self.set_initial_guess(initial_guess)\n\t        self.rescale_bounds_and_initial_guess(rescale_units)\n\t    @multi_voxel_fit\n\t    def fit(self, data):\n\t        # Normalize the data\n\t        data_max = data.max()\n\t        if data_max == 0:\n\t            pass\n", "        else:\n\t            data = data / data_max\n\t        ### Fit the diffusion signal to bvals >= diff_b_threshold_lower\n\t        diff_bounds = [(self.bounds[0][0], self.bounds[0][3]), \\\n\t            (self.bounds[1][0], self.bounds[1][3])] # Bounds for S0 and D\n\t        diff_bval_indices = np.where(self.bvals >= self.diff_b_threshold_lower)[0]\n\t        diff_bvals = self.bvals[diff_bval_indices]\n\t        diff_data = data[diff_bval_indices]\n\t        S0_diff_est, D_est = curve_fit(self.diffusion_signal, diff_bvals, diff_data, \\\n\t            bounds=diff_bounds, p0=np.take(self.initial_guess, [0, 3]), maxfev=10000)[0]\n", "        ### Fit the perfusion signal to bvals <= perf_b_threshold_upper\n\t        perf_bounds = [(self.bounds[0][0], self.bounds[0][2]), \\\n\t            (self.bounds[1][0], self.bounds[1][2])] # Bounds for S0 and D*\n\t        perf_bvals = self.bvals[self.bvals <= self.perf_b_threshold_upper]\n\t        diff_data_to_be_removed = self.diffusion_signal(perf_bvals, S0_diff_est, D_est)\n\t        perf_bval_indices = np.where(self.bvals <= self.perf_b_threshold_upper)[0]\n\t        perf_bvals = self.bvals[perf_bval_indices]\n\t        perf_data = data[perf_bval_indices] - diff_data_to_be_removed # Subtract the diffusion signal from the total to get the perfusion signal\n\t        S0_perf_est, D_star_est = curve_fit(self.perfusion_signal, perf_bvals, perf_data, \\\n\t            bounds=perf_bounds, p0=np.take(self.initial_guess, [0, 2]), maxfev=10000)[0]\n", "        # Calculate the estimation of f based on the two S0 estimates\n\t        f_est = S0_perf_est/(S0_perf_est + S0_diff_est)\n\t        # Set the results and rescale S0\n\t        result = np.array([S0_perf_est+S0_diff_est, f_est, D_star_est, D_est])\n\t        result[0] *= data_max\n\t        return IvimFit(self, result)\n\t    def diffusion_signal(self, b, S0, D):\n\t        return S0*np.exp(-b*D)\n\t    def perfusion_signal(self, b, S0, D_star):\n\t        return S0*np.exp(-b*D_star)\n", "    def set_bounds(self, bounds):\n\t        # Use this function for fits that uses curve_fit\n\t        if bounds == None:\n\t            self.bounds = np.array([(0, 0, 0.005, 0), (np.inf, 1, 0.1, 0.004)])\n\t        else:\n\t            self.bounds = np.array([(0, *bounds[0]), (np.inf, *bounds[1])])\n\t    def set_initial_guess(self, initial_guess):\n\t        if initial_guess == None:\n\t            self.initial_guess = (1, 0.2, 0.03, 0.001)\n\t        else:\n", "            self.initial_guess = initial_guess\n\t    def rescale_bounds_and_initial_guess(self, rescale_units):\n\t        if rescale_units:\n\t            # Rescale the guess\n\t            self.initial_guess = (self.initial_guess[0], self.initial_guess[1], \\\n\t                self.initial_guess[2]*1000, self.initial_guess[3]*1000)\n\t            # Rescale the bounds\n\t            lower_bounds = (self.bounds[0][0], self.bounds[0][1], \\\n\t                self.bounds[0][2]*1000, self.bounds[0][3]*1000)\n\t            upper_bounds = (self.bounds[1][0], self.bounds[1][1], \\\n", "                self.bounds[1][2]*1000, self.bounds[1][3]*1000)\n\t            self.bounds = (lower_bounds, upper_bounds)\n\tclass IvimFit(object):\n\t    def __init__(self, model, model_params):\n\t        \"\"\" Initialize a IvimFit class instance.\n\t            Parameters\n\t            ----------\n\t            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n", "            array of ivim parameters. If the fitting is done\n\t            for multi_voxel data, the multi_voxel decorator will\n\t            run the fitting on all the voxels and model_params\n\t            will be an array of the dimensions (data[:-1], 4),\n\t            i.e., there will be 4 parameters for each of the voxels.\n\t        \"\"\"\n\t        self.model = model\n\t        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n", "        N = model_params.ndim\n\t        if type(index) is not tuple:\n\t            index = (index,)\n\t        elif len(index) >= model_params.ndim:\n\t            raise IndexError(\"IndexError: invalid index\")\n\t        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n\t    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n", "    @property\n\t    def perfusion_fraction(self):\n\t        return self.model_params[..., 1]\n\t    @property\n\t    def D_star(self):\n\t        return self.model_params[..., 2]\n\t    @property\n\t    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n", "    def shape(self):\n\t        return self.model_params.shape[:-1]\n"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_modified_mix.py", "chunked_list": ["import numpy as np\n\tfrom scipy.optimize import least_squares, differential_evolution\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tcvxpy, have_cvxpy, _ = optional_package(\"cvxpy\")\n\tclass IvimModelVP(ReconstModel):\n\t    def __init__(self, gtab, bounds=None, maxiter=10, xtol=1e-8, rescale_units=False, rescale_results_to_mm2_s=False):\n\t        r\"\"\" Initialize an IvimModelVP class.\n\t        This particular script was modified as the DIPY version has stringent \n", "        hard-coded bounds for the first optimizer that do not work well.\n\t        Note that he returned values are in units of m2/ms!\n\t        The IVIM model assumes that biological tissue includes a volume\n\t        fraction 'f' of water flowing with a pseudo-diffusion coefficient\n\t        D* and a fraction (1-f: treated as a separate fraction in the variable\n\t        projection method) of static (diffusion only), intra and\n\t        extracellular water, with a diffusion coefficient D. In this model\n\t        the echo attenuation of a signal in a single voxel can be written as\n\t            .. math::\n\t            S(b) = S_0*[f*e^{(-b*D\\*)} + (1-f)e^{(-b*D)}]\n", "            Where:\n\t            .. math::\n\t            S_0, f, D\\* and D are the IVIM parameters.\n\t        gtab : DIPY gtab class containing the b-values\n\t            These are automatically scaled to units of ms/m2 if given in s/mm2.\n\t        bounds : array-like, optional\n\t            Specify the bounds as [(lower f, lower D*, lower D), (upper f, upper D*, upper D)].\n\t            Default : None, default bounds are set.\n\t        maxiter: int, optional\n\t            Maximum number of iterations for the Differential Evolution in\n", "            SciPy.\n\t            default : 10\n\t        xtol : float, optional\n\t            Tolerance for convergence of minimization.\n\t            default : 1e-8\n\t        rescale_units : bool, optional\n\t            Set to True if you are inputting in units of mm2/s and want the\n\t            values automatically rescaled to m2/ms. The latter is the best\n\t            for this fitting method.\n\t            Default : False\n", "        rescale_results_to_mm2_s : bool, optional\n\t            Set to True if you have used um2/ms but want the results in mm2/s. \n\t            Default : False.\n\t        References\n\t        ----------\n\t        .. [1] Le Bihan, Denis, et al. \"Separation of diffusion and perfusion\n\t               in intravoxel incoherent motion MR imaging.\" Radiology 168.2\n\t               (1988): 497-505.\n\t        .. [2] Federau, Christian, et al. \"Quantitative measurement of brain\n\t               perfusion with intravoxel incoherent motion MR imaging.\"\n", "               Radiology 265.3 (2012): 874-881.\n\t        .. [3] Fadnavis, Shreyas et.al. \"MicroLearn: Framework for machine\n\t               learning, reconstruction, optimization and microstructure\n\t               modeling, Proceedings of: International Society of Magnetic\n\t               Resonance in Medicine (ISMRM), Montreal, Canada, 2019.\n\t        \"\"\"\n\t        self.maxiter = maxiter\n\t        self.xtol = xtol\n\t        self.bvals = gtab.bvals\n\t        self.yhat_perfusion = np.zeros(self.bvals.shape[0])\n", "        self.yhat_diffusion = np.zeros(self.bvals.shape[0])\n\t        self.exp_phi1 = np.zeros((self.bvals.shape[0], 2))\n\t        self.bounds = bounds\n\t        self.rescale_results_to_mm2_s = rescale_results_to_mm2_s\n\t        # This method works best in units of m2/ms\n\t        # Something weird happends when values are as small as they are\n\t        # expressed in mm2/s.\n\t        # The conversion is accomplished by dividing the b-value with 1000\n\t        # and multiplying the parameter values with 1000.\n\t        if gtab.bvals[-1] >= 10:\n", "            self.bvals = gtab.bvals/1000\n\t        if bounds == None:\n\t            # Bounds expressed as (lower bound, upper bound) for [f, D*, D].\n\t            self.bounds = np.array([(0, 1), (5, 100), (0, 4)])\n\t        elif (bounds[0][1] <= 1) or rescale_units: # Realistically, if mm2/s units are used, D* bound is <= 1\n\t            self.bounds = np.array([(bounds[0][0], bounds[1][0]), \\\n\t                                    (bounds[0][1]*1000, bounds[1][1]*1000), \\\n\t                                    (bounds[0][2]*1000, bounds[1][2]*1000)])\n\t        else: # Finally, if units if m2/ms are already used\n\t            self.bounds = np.array([(bounds[0][0], bounds[1][0], \\\n", "                                    (bounds[0][1], bounds[1][1]), \\\n\t                                    (bounds[0][2], bounds[1][2]))])\n\t    @multi_voxel_fit\n\t    def fit(self, data, bounds_de=None):\n\t        r\"\"\" Fit method of the IvimModelVP model class\n\t        MicroLearn framework (VarPro)[1]_.\n\t        The VarPro computes the IVIM parameters using the MIX approach.\n\t        This algorithm uses three different optimizers. It starts with a\n\t        differential evolution algorithm and fits the parameters in the\n\t        power of exponentials. Then the fitted parameters in the first step are\n", "        utilized to make a linear convex problem. Using a convex optimization,\n\t        the volume fractions are determined. Then the last step is non linear\n\t        least square fitting on all the parameters. The results of the first\n\t        and second step are utilized as the initial values for the last step\n\t        of the algorithm. (see [1]_ and [2]_ for a comparison and a through\n\t        discussion).\n\t        References\n\t        ----------\n\t        .. [1] Fadnavis, Shreyas et.al. \"MicroLearn: Framework for machine\n\t               learning, reconstruction, optimization and microstructure\n", "               modeling, Proceedings of: International Society of Magnetic\n\t               Resonance in Medicine (ISMRM), Montreal, Canada, 2019.\n\t        .. [2] Farooq, Hamza, et al. \"Microstructure Imaging of Crossing (MIX)\n\t               White Matter Fibers from diffusion MRI.\" Scientific reports 6\n\t               (2016).\n\t        \"\"\"\n\t        data_max = data.max()\n\t        data = data / data_max\n\t        b = self.bvals\n\t        # Setting up the bounds for differential_evolution\n", "        bounds_de = np.array([self.bounds[1], self.bounds[2]])\n\t        # Optimizer #1: Differential Evolution\n\t        res_one = differential_evolution(self.stoc_search_cost, bounds_de,\n\t                                         maxiter=self.maxiter, args=(data,),\n\t                                         disp=False, polish=True, popsize=28) #28\n\t        x = res_one.x\n\t        phi = self.phi(x)\n\t        # Optimizer #2: Convex Optimizer\n\t        f = self.cvx_fit(data, phi)\n\t        x_f = self.x_and_f_to_x_f(x, f)\n", "        # Setting up the bounds for least_squares\n\t        bounds_lower = (self.bounds[0][0], self.bounds[1][0], self.bounds[2][0])\n\t        bounds_upper = (self.bounds[0][1], self.bounds[1][1], self.bounds[2][1])\n\t        bounds = (bounds_lower, bounds_upper)\n\t        # Optimizer #3: Nonlinear-Least Squares\n\t        res = least_squares(self.nlls_cost, x_f, bounds=bounds,\n\t                            xtol=self.xtol, args=(data,))\n\t        result = res.x\n\t        f_est = result[0]\n\t        D_star_est = result[1]\n", "        D_est = result[2]\n\t        S0 = data / (f_est * np.exp(-b * D_star_est) + (1 - f_est) *\n\t                     np.exp(-b * D_est))\n\t        S0_est = S0 * data_max\n\t        if self.rescale_results_to_mm2_s:\n\t            result = np.array([np.mean(S0_est), f_est, D_star_est*1e-3, D_est*1e-3])\n\t        else:\n\t            result = np.insert(result, 0, np.mean(S0_est), axis=0)\n\t        # final result containing the four fit parameters: S0, f, D* and D\n\t        #result = np.insert(result, 0, np.mean(S0_est), axis=0)\n", "        return IvimFit(self, result)\n\t    def stoc_search_cost(self, x, signal):\n\t        \"\"\"\n\t        Cost function for differential evolution algorithm. Performs a\n\t        stochastic search for the non-linear parameters 'x'. The objective\n\t        function is calculated in the :func: `ivim_mix_cost_one`. The function\n\t        constructs the parameters using :func: `phi`.\n\t        Parameters\n\t        ----------\n\t        x : array\n", "            input from the Differential Evolution optimizer.\n\t        signal : array\n\t            The signal values measured for this model.\n\t        Returns\n\t        -------\n\t        :func: `ivim_mix_cost_one`\n\t        \"\"\"\n\t        phi = self.phi(x)\n\t        return self.ivim_mix_cost_one(phi, signal)\n\t    def ivim_mix_cost_one(self, phi, signal):\n", "        \"\"\"\n\t        Constructs the objective for the :func: `stoc_search_cost`.\n\t        First calculates the Moore-Penrose inverse of the input `phi` and takes\n\t        a dot product with the measured signal. The result obtained is again\n\t        multiplied with `phi` to complete the projection of the variable into\n\t        a transformed space. (see [1]_ and [2]_ for thorough discussion on\n\t        Variable Projections and relevant cost functions).\n\t        Parameters\n\t        ----------\n\t        phi : array\n", "            Returns an array calculated from :func: `Phi`.\n\t        signal : array\n\t            The signal values measured for this model.\n\t        Returns\n\t        -------\n\t        (signal -  S)^T(signal -  S)\n\t        Notes\n\t        -----\n\t        to make cost function for Differential Evolution algorithm:\n\t        .. math::\n", "            (signal -  S)^T(signal -  S)\n\t        References\n\t        ----------\n\t        .. [1] Fadnavis, Shreyas et.al. \"MicroLearn: Framework for machine\n\t               learning, reconstruction, optimization and microstructure\n\t               modeling, Proceedings of: International Society of Magnetic\n\t               Resonance in Medicine (ISMRM), Montreal, Canada, 2019.\n\t        .. [2] Farooq, Hamza, et al. \"Microstructure Imaging of Crossing (MIX)\n\t               White Matter Fibers from diffusion MRI.\" Scientific reports 6\n\t               (2016).\n", "        \"\"\"\n\t        # Moore-Penrose\n\t        phi_mp = np.dot(np.linalg.inv(np.dot(phi.T, phi)), phi.T)\n\t        f = np.dot(phi_mp, signal)\n\t        yhat = np.dot(phi, f)  # - sigma\n\t        return np.dot((signal - yhat).T, signal - yhat)\n\t    def cvx_fit(self, signal, phi):\n\t        \"\"\"\n\t        Performs the constrained search for the linear parameters `f` after\n\t        the estimation of `x` is done. Estimation of the linear parameters `f`\n", "        is a constrained linear least-squares optimization problem solved by\n\t        using a convex optimizer from cvxpy. The IVIM equation contains two\n\t        parameters that depend on the same volume fraction. Both are estimated\n\t        as separately in the convex optimizer.\n\t        Parameters\n\t        ----------\n\t        phi : array\n\t            Returns an array calculated from :func: `phi`.\n\t        signal : array\n\t            The signal values measured for this model.\n", "        Returns\n\t        -------\n\t        f1, f2 (volume fractions)\n\t        Notes\n\t        -----\n\t        cost function for differential evolution algorithm:\n\t        .. math::\n\t            minimize(norm((signal)- (phi*f)))\n\t        \"\"\"\n\t        # Create four scalar optimization variables.\n", "        f = cvxpy.Variable(2)\n\t        # Constraints have been set similar to the MIX paper's\n\t        # Supplementary Note 2: Synthetic Data Experiments, experiment 2\n\t        constraints = [cvxpy.sum(f) == 1,\n\t                       f[0] >= 0.011,\n\t                       f[1] >= 0.011,\n\t                       f[0] <= self.bounds[1][0],\n\t                       f[1] <= 0.89]\n\t        # Form objective.\n\t        obj = cvxpy.Minimize(cvxpy.sum(cvxpy.square(phi @ f - signal)))\n", "        # Form and solve problem.\n\t        prob = cvxpy.Problem(obj, constraints)\n\t        prob.solve()  # Returns the optimal value.\n\t        return np.array(f.value)\n\t    def nlls_cost(self, x_f, signal):\n\t        \"\"\"\n\t        Cost function for the least square problem. The cost function is used\n\t        in the Least Squares function of SciPy in :func: `fit`. It guarantees\n\t        that stopping point of the algorithm is at least a stationary point\n\t        with reduction in the the number of iterations required by the\n", "        differential evolution optimizer.\n\t        Parameters\n\t        ----------\n\t        x_f : array\n\t            Contains the parameters 'x' and 'f' combines in the same array.\n\t        signal : array\n\t            The signal values measured for this model.\n\t        Returns\n\t        -------\n\t        sum{(signal -  phi*f)^2}\n", "        Notes\n\t        -----\n\t        cost function for the least square problem.\n\t        .. math::\n\t            sum{(signal -  phi*f)^2}\n\t        \"\"\"\n\t        x, f = self.x_f_to_x_and_f(x_f)\n\t        f1 = np.array([f, 1 - f])\n\t        phi = self.phi(x)\n\t        return np.sum((np.dot(phi, f1) - signal) ** 2)\n", "    def x_f_to_x_and_f(self, x_f):\n\t        \"\"\"\n\t        Splits the array of parameters in x_f to 'x' and 'f' for performing\n\t        a search on the both of them independently using the Trust Region\n\t        Method.\n\t        Parameters\n\t        ----------\n\t        x_f : array\n\t            Combined array of parameters 'x' and 'f' parameters.\n\t        Returns\n", "        -------\n\t        x, f : array\n\t            Split parameters into two separate arrays\n\t        \"\"\"\n\t        x = np.zeros(2)\n\t        f = x_f[0]\n\t        x = x_f[1:3]\n\t        return x, f\n\t    def x_and_f_to_x_f(self, x, f):\n\t        \"\"\"\n", "        Combines the array of parameters 'x' and 'f' into x_f for performing\n\t        NLLS on the final stage of optimization.\n\t        Parameters\n\t        ----------\n\t         x, f : array\n\t            Split parameters into two separate arrays\n\t        Returns\n\t        -------\n\t        x_f : array\n\t            Combined array of parameters 'x' and 'f' parameters.\n", "        \"\"\"\n\t        x_f = np.zeros(3)\n\t        x_f[0] = f[0]\n\t        x_f[1:3] = x\n\t        return x_f\n\t    def phi(self, x):\n\t        \"\"\"\n\t        Creates a structure for the combining the diffusion and pseudo-\n\t        diffusion by multiplying with the bvals and then exponentiating each of\n\t        the two components for fitting as per the IVIM- two compartment model.\n", "        Parameters\n\t        ----------\n\t         x : array\n\t            input from the Differential Evolution optimizer.\n\t        Returns\n\t        -------\n\t        exp_phi1 : array\n\t            Combined array of parameters perfusion/pseudo-diffusion\n\t            and diffusion parameters.\n\t        \"\"\"\n", "        self.yhat_perfusion = self.bvals * x[0]\n\t        self.yhat_diffusion = self.bvals * x[1]\n\t        self.exp_phi1[:, 0] = np.exp(-self.yhat_perfusion)\n\t        self.exp_phi1[:, 1] = np.exp(-self.yhat_diffusion)\n\t        return self.exp_phi1\n\tclass IvimFit(object):\n\t    def __init__(self, model, model_params):\n\t        \"\"\" Initialize a IvimFit class instance.\n\t            Parameters\n\t            ----------\n", "            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n\t            array of ivim parameters. If the fitting is done\n\t            for multi_voxel data, the multi_voxel decorator will\n\t            run the fitting on all the voxels and model_params\n\t            will be an array of the dimensions (data[:-1], 4),\n\t            i.e., there will be 4 parameters for each of the voxels.\n\t        \"\"\"\n\t        self.model = model\n", "        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n\t        N = model_params.ndim\n\t        if type(index) is not tuple:\n\t            index = (index,)\n\t        elif len(index) >= model_params.ndim:\n\t            raise IndexError(\"IndexError: invalid index\")\n\t        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n", "    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n\t    @property\n\t    def perfusion_fraction(self):\n\t        return self.model_params[..., 1]\n\t    @property\n\t    def D_star(self):\n\t        return self.model_params[..., 2]\n\t    @property\n", "    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n\t    def shape(self):\n\t        return self.model_params.shape[:-1]"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_biexp.py", "chunked_list": ["\"\"\" Classes and functions for fitting ivim model \"\"\"\n\timport numpy as np\n\tfrom scipy.optimize import curve_fit\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tclass IvimModelBiExp(ReconstModel):\n\t    def __init__(self, gtab, bounds=None, initial_guess=None, rescale_units=False):\n\t        \"\"\"A simple nlls fit to the bi-exponential IVIM model. No segmentations\n\t        are performed.\n", "        Args:\n\t            gtab (DIPY gradient table): \n\t            DIPY gradient table object containing\n\t            information of the diffusion gradients, b-values, etc.\n\t            bounds (array-like, optional): \n\t            Bounds expressed as [lower bounds, upper bounds] for S0, f, D*, and\n\t            D respectively. Defaults to None.\n\t            initial_guess (array-like, optional):\n\t            The initial guess for the parameters. Defaults to None.\n\t            rescale_units (bool, optional): \n", "            Set to True if parameters are to be returned in units of m2/ms. \n\t            The conversion only works in one direction, from mm2/s to m2/ms.\n\t            Make sure the b-values in the gtab object are already in units of\n\t            m2/ms if this is used. Defaults to False.\n\t        \"\"\"\n\t        self.bvals = gtab.bvals\n\t        self.set_bounds(bounds) # Sets the bounds according to the requirements of the fits\n\t        self.set_initial_guess(initial_guess) # Sets the initial guess if the fit requires it\n\t        self.rescale_bounds_and_initial_guess(rescale_units) # Rescales the units of D* and D to m2/ms if set to True\n\t    @multi_voxel_fit\n", "    def fit(self, data):\n\t        # Normalize the data\n\t        data_max = data.max()\n\t        if data_max == 0:\n\t            pass\n\t        else:\n\t            data = data / data_max\n\t        # Perform the fit\n\t        popt, pcov = curve_fit(self.ivim_model, self.bvals, data, p0=self.initial_guess,\\\n\t            bounds=self.bounds, maxfev=10000)\n", "        # Set the results and rescale S0\n\t        result = popt\n\t        result[0] *= data_max\n\t        return IvimFit(self, result)\n\t    def ivim_model(self, b, S0, f, D_star, D):\n\t        return S0*(f*np.exp(-b*D_star) + (1-f)*np.exp(-b*D))\n\t    def set_bounds(self, bounds):\n\t        # Use this function for fits that uses curve_fit\n\t        if bounds == None:\n\t            self.bounds = np.array([(0, 0, 0.005, 0), (np.inf, 1, 0.1, 0.004)])\n", "        else:\n\t            self.bounds = np.array([(0, *bounds[0]), (np.inf, *bounds[1])])\n\t    def set_initial_guess(self, initial_guess):\n\t        if initial_guess == None:\n\t            self.initial_guess = (1, 0.2, 0.03, 0.001)\n\t        else:\n\t            self.initial_guess = initial_guess\n\t    def rescale_bounds_and_initial_guess(self, rescale_units):\n\t        if rescale_units:\n\t            # Rescale the guess\n", "            self.initial_guess = (self.initial_guess[0], self.initial_guess[1], \\\n\t                self.initial_guess[2]*1000, self.initial_guess[3]*1000)\n\t            # Rescale the bounds\n\t            lower_bounds = (self.bounds[0][0], self.bounds[0][1], \\\n\t                self.bounds[0][2]*1000, self.bounds[0][3]*1000)\n\t            upper_bounds = (self.bounds[1][0], self.bounds[1][1], \\\n\t                self.bounds[1][2]*1000, self.bounds[1][3]*1000)\n\t            self.bounds = (lower_bounds, upper_bounds)\n\tclass IvimFit(object):\n\t    def __init__(self, model, model_params):\n", "        \"\"\" Initialize a IvimFit class instance.\n\t            Parameters\n\t            ----------\n\t            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n\t            array of ivim parameters. If the fitting is done\n\t            for multi_voxel data, the multi_voxel decorator will\n\t            run the fitting on all the voxels and model_params\n\t            will be an array of the dimensions (data[:-1], 4),\n", "            i.e., there will be 4 parameters for each of the voxels.\n\t        \"\"\"\n\t        self.model = model\n\t        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n\t        N = model_params.ndim\n\t        if type(index) is not tuple:\n\t            index = (index,)\n\t        elif len(index) >= model_params.ndim:\n", "            raise IndexError(\"IndexError: invalid index\")\n\t        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n\t    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n\t    @property\n\t    def perfusion_fraction(self):\n\t        return self.model_params[..., 1]\n\t    @property\n", "    def D_star(self):\n\t        return self.model_params[..., 2]\n\t    @property\n\t    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n\t    def shape(self):\n\t        return self.model_params.shape[:-1]\n"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_segmented_3step.py", "chunked_list": ["\"\"\" Classes and functions for fitting ivim model \"\"\"\n\timport numpy as np\n\tfrom scipy.optimize import curve_fit\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tclass IvimModelSegmented3Step(ReconstModel):\n\t    def __init__(self, gtab, b_threshold_upper=100, b_threshold_lower=200, \\\n\t        initial_guess=None, bounds=None, rescale_units=False):\n\t        \"\"\"The 3-step segmented fit as described in the DIPY documentation.\n", "        https://dipy.org/documentation/1.0.0./examples_built/reconst_ivim/\n\t        Args:\n\t            gtab (DIPY gradient table):\n\t                Object that holds the diffusion encoding information. In this\n\t                case, the b-values.\n\t            b_threshold_upper (float, optional): \n\t                The upper b-value threshold of the perfusion fit. \n\t                Defaults to 100.\n\t            b_threshold_lower (float, optional): \n\t                The lower b-value threshold of the diffusion fit. \n", "                Defaults to 200.\n\t            initial_guess (tuple, optional): \n\t                The intial guess for the parameters. Defaults to None.\n\t            bounds (tuple, optional): \n\t                The bounds input as a tuple of lower bounds and upper bounds,\n\t                specified in the order f, D*, D. Defaults to None.\n\t            rescale_units (bool, optional): \n\t                Set to True if the units are to be scaled to m2/ms. Make sure\n\t                that the b-values are already specified in these units.\n\t                Defaults to False.\n", "        \"\"\"\n\t        self.bvals = gtab.bvals\n\t        self.perf_b_threshold_upper = b_threshold_upper\n\t        self.diff_b_threshold_lower = b_threshold_lower\n\t        self.set_bounds(bounds)\n\t        self.set_initial_guess(initial_guess)\n\t        self.rescale_bounds_and_initial_guess(rescale_units)\n\t    @multi_voxel_fit\n\t    def fit(self, data):\n\t        # Normalize the data\n", "        data_max = data.max()\n\t        if data_max == 0:\n\t            pass\n\t        else:\n\t            data = data / data_max\n\t        ### Fit the diffusion signal to bvals >= diff_b_threshold_lower\n\t        diff_bounds = [(self.bounds[0][0], self.bounds[0][3]), \\\n\t            (self.bounds[1][0], self.bounds[1][3])] # Bounds for S0 and D\n\t        diff_bval_indices = np.where(self.bvals >= self.diff_b_threshold_lower)[0]\n\t        diff_bvals = self.bvals[diff_bval_indices]\n", "        diff_data = data[diff_bval_indices]\n\t        S0_diff_est, D_est = curve_fit(self.diffusion_signal, diff_bvals, diff_data, \\\n\t            bounds=diff_bounds, p0=np.take(self.initial_guess, [0, 3]), maxfev=10000)[0]\n\t        ### Fit the perfusion signal to bvals <= perf_b_threshold_upper\n\t        perf_bounds = [(self.bounds[0][0], self.bounds[0][2]), \\\n\t            (self.bounds[1][0], self.bounds[1][2])] # Bounds for S0 and D*\n\t        perf_bval_indices = np.where(self.bvals <= self.perf_b_threshold_upper)[0]\n\t        perf_bvals = self.bvals[perf_bval_indices]\n\t        perf_data = data[perf_bval_indices]\n\t        S0_perf_est, D_star_est = curve_fit(self.perfusion_signal, perf_bvals, perf_data, \\\n", "            bounds=perf_bounds, p0=np.take(self.initial_guess, [0, 2]), maxfev=10000)[0]\n\t        # Calculate the estimation of f based on the two S0 estimates\n\t        f_est = S0_perf_est/(S0_perf_est + S0_diff_est)\n\t        # Fit to the full bi-exponential, f estimate as initial guess, D fixed\n\t        full_initial_guess = np.array([self.initial_guess[0], f_est, self.initial_guess[2]])\n\t        full_bounds_lower = self.bounds[0][:-1]\n\t        full_bounds_upper = self.bounds[1][:-1]\n\t        full_bounds = (full_bounds_lower, full_bounds_upper)\n\t        S0_est, f_est, D_star_est = curve_fit(lambda b, S0, f, D_star: self.ivim_signal(b, S0, f, D_star, D_est), self.bvals, data, bounds=full_bounds, p0=full_initial_guess, maxfev=10000)[0]\n\t        # Set the results and rescale S0\n", "        result = np.array([S0_est, f_est, D_star_est, D_est])\n\t        result[0] *= data_max\n\t        return IvimFit(self, result)\n\t    def diffusion_signal(self, b, S0, D):\n\t        return S0*np.exp(-b*D)\n\t    def perfusion_signal(self, b, S0, D_star):\n\t        return S0*np.exp(-b*D_star)\n\t    def ivim_signal(self, b, S0, f, D_star, D):\n\t        return S0*(f*np.exp(-b*D_star) + (1-f)*np.exp(-b*D))\n\t    def set_bounds(self, bounds):\n", "        # Use this function for fits that uses curve_fit\n\t        if bounds == None:\n\t            self.bounds = np.array([(0, 0, 0.005, 0), (np.inf, 1, 0.1, 0.004)])\n\t        else:\n\t            self.bounds = np.array([(0, *bounds[0]), (np.inf, *bounds[1])])\n\t    def set_initial_guess(self, initial_guess):\n\t        if initial_guess == None:\n\t            self.initial_guess = (1, 0.2, 0.03, 0.001)\n\t        else:\n\t            self.initial_guess = initial_guess\n", "    def rescale_bounds_and_initial_guess(self, rescale_units):\n\t        if rescale_units:\n\t            # Rescale the guess\n\t            self.initial_guess = (self.initial_guess[0], self.initial_guess[1], \\\n\t                self.initial_guess[2]*1000, self.initial_guess[3]*1000)\n\t            # Rescale the bounds\n\t            lower_bounds = (self.bounds[0][0], self.bounds[0][1], \\\n\t                self.bounds[0][2]*1000, self.bounds[0][3]*1000)\n\t            upper_bounds = (self.bounds[1][0], self.bounds[1][1], \\\n\t                self.bounds[1][2]*1000, self.bounds[1][3]*1000)\n", "            self.bounds = (lower_bounds, upper_bounds)\n\tclass IvimFit(object):\n\t    def __init__(self, model, model_params):\n\t        \"\"\" Initialize a IvimFit class instance.\n\t            Parameters\n\t            ----------\n\t            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n\t            array of ivim parameters. If the fitting is done\n", "            for multi_voxel data, the multi_voxel decorator will\n\t            run the fitting on all the voxels and model_params\n\t            will be an array of the dimensions (data[:-1], 4),\n\t            i.e., there will be 4 parameters for each of the voxels.\n\t        \"\"\"\n\t        self.model = model\n\t        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n\t        N = model_params.ndim\n", "        if type(index) is not tuple:\n\t            index = (index,)\n\t        elif len(index) >= model_params.ndim:\n\t            raise IndexError(\"IndexError: invalid index\")\n\t        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n\t    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n\t    @property\n", "    def perfusion_fraction(self):\n\t        return self.model_params[..., 1]\n\t    @property\n\t    def D_star(self):\n\t        return self.model_params[..., 2]\n\t    @property\n\t    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n\t    def shape(self):\n", "        return self.model_params.shape[:-1]\n"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_linear.py", "chunked_list": ["\"\"\" Classes and functions for fitting ivim model \"\"\"\n\timport numpy as np\n\tfrom scipy.optimize import lsq_linear\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tfrom scipy.signal import unit_impulse\n\tclass IvimModelLinear(ReconstModel):\n\t    def __init__(self, gtab, b_threshold=200, bounds=None, rescale_units=False):\n\t        \"\"\"A simple nlls fit to the bi-exponential IVIM model. No segmentations\n", "        are performed.\n\t        Args:\n\t            gtab (DIPY gradient table): \n\t            DIPY gradient table object containing\n\t            information of the diffusion gradients, b-values, etc.\n\t            bounds (array-like, optional): \n\t            Bounds expressed as [lower bounds, upper bounds] for S0, f, D*, and\n\t            D respectively. Defaults to None.\n\t            initial_guess (array-like, optional):\n\t            The initial guess for the parameters. Defaults to None.\n", "            rescale_units (bool, optional): \n\t            Set to True if parameters are to be returned in units of m2/ms. \n\t            The conversion only works in one direction, from mm2/s to m2/ms.\n\t            Make sure the b-values in the gtab object are already in units of\n\t            m2/ms if this is used. Defaults to False.\n\t        \"\"\"\n\t        self.b_threshold = b_threshold\n\t        self.bvals = gtab.bvals[gtab.bvals >= self.b_threshold]\n\t        # Get the indices for the b-values that fulfils the condition.\n\t        # Will be used to get the corresponding signals.\n", "        b_threshold_idx = np.where(self.bvals >= self.b_threshold)[0][1]\n\t        self.signal_indices = list(np.where(gtab.bvals >= self.b_threshold)[0])\n\t        self.set_bounds(bounds) # Sets the bounds according to the requirements of the fits\n\t        self.rescale_bounds_and_initial_guess(rescale_units) # Rescales the units of D* and D to m2/ms if set to True\n\t    @multi_voxel_fit\n\t    def fit(self, data):\n\t        # Normalize the data and move to the logarithmic space\n\t        data_max = data.max()\n\t        if data_max == 0:\n\t            pass\n", "        else:\n\t            data_log = np.log(data / data_max)\n\t        # Sort out the signals from non-zero b-values < b-threshold\n\t        ydata = data_log[self.signal_indices]\n\t        # Define the design matrix\n\t        A = np.vstack([self.bvals, np.ones(len(self.bvals))]).T\n\t        # Get the bounds for D and f\n\t        lsq_bounds_lower = (-self.bounds[1][2], -self.bounds[1][1])\n\t        lsq_bounds_upper = (-self.bounds[0][2], -self.bounds[0][1])\n\t        lsq_bounds = (lsq_bounds_lower, lsq_bounds_upper)\n", "        # Perform the fit\n\t        popt = lsq_linear(A, ydata, bounds=lsq_bounds).x\n\t        D, f = -popt # f is estimated as the negative of the intercept\n\t        # Set the results and rescale S0\n\t        result = np.array([data[0], f, D])\n\t        result[0] *= data_max\n\t        return IvimFit(self, result)\n\t    def sivim_model(self, b, S0, f, D):\n\t        delta = unit_impulse(b.shape, idx=0)\n\t        res = S0*(f*delta + (1-f)*np.exp(-b*D))\n", "        return res\n\t    def set_bounds(self, bounds):\n\t        # Use this function for fits that uses curve_fit\n\t        if bounds == None:\n\t            self.bounds = np.array([(0, 0, 0), (np.inf, 1, 0.004)])\n\t        else:\n\t            self.bounds = np.array([(0, *bounds[0]), (np.inf, *bounds[1])])\n\t    def set_initial_guess(self, initial_guess):\n\t        if initial_guess == None:\n\t            self.initial_guess = (1, 0.2, 0.001)\n", "        else:\n\t            self.initial_guess = initial_guess\n\t    def rescale_bounds_and_initial_guess(self, rescale_units):\n\t        if rescale_units:\n\t            # Rescale the bounds\n\t            lower_bounds = (self.bounds[0][0], self.bounds[0][1], \\\n\t                self.bounds[0][2]*1000)\n\t            upper_bounds = (self.bounds[1][0], self.bounds[1][1], \\\n\t                self.bounds[1][2]*1000)\n\t            self.bounds = (lower_bounds, upper_bounds)\n", "class IvimFit(object):\n\t    def __init__(self, model, model_params):\n\t        \"\"\" Initialize a IvimFit class instance.\n\t            Parameters\n\t            ----------\n\t            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n\t            array of ivim parameters. If the fitting is done\n\t            for multi_voxel data, the multi_voxel decorator will\n", "            run the fitting on all the voxels and model_params\n\t            will be an array of the dimensions (data[:-1], 4),\n\t            i.e., there will be 4 parameters for each of the voxels.\n\t        \"\"\"\n\t        self.model = model\n\t        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n\t        N = model_params.ndim\n\t        if type(index) is not tuple:\n", "            index = (index,)\n\t        elif len(index) >= model_params.ndim:\n\t            raise IndexError(\"IndexError: invalid index\")\n\t        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n\t    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n\t    @property\n\t    def perfusion_fraction(self):\n", "        return self.model_params[..., 1]\n\t    #@property\n\t    #def D_star(self):\n\t        #return self.model_params[..., 2]\n\t    @property\n\t    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n\t    def shape(self):\n\t        return self.model_params.shape[:-1]\n"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_modified_topopro.py", "chunked_list": ["\"\"\" Classes and functions for fitting ivim model \"\"\"\n\timport numpy as np\n\tfrom scipy.optimize import shgo\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tcvxpy, have_cvxpy, _ = optional_package(\"cvxpy\")\n\tclass IvimModelTopoPro(ReconstModel):\n\t    def __init__(self, gtab, bounds=[[0,1], [0.005, 0.1], [1e-5, 0.004]], \\\n\t        rescale_units=False, shgo_iters=5, rescale_results_to_mm2_s=False):\n", "        r\"\"\" Initialize an IvimModelTP class.\n\t        This particular script was modified as the DIPY version has stringent \n\t        hard-coded bounds for the first optimizer that do not work well.\n\t        Note that he returned values are in units of m2/ms!\n\t        gtab : DIPY gtab class containing the b-values\n\t            These are automatically scaled to units of ms/m2 if given in s/mm2.\n\t        shgo_iters : int, optional\n\t            The number of iterations done by the SHGO optimizer. 5 is recommended.\n\t            Default : 5.\n\t        rescale_units : bool, optional\n", "            Set to True if you are inputting in units of mm2/s and want the\n\t            values automatically rescaled to m2/ms. The latter is the best\n\t            for this fitting method.\n\t            Default : False\n\t        rescale_results_to_mm2_s : bool, optional\n\t            Set to True if you have used um2/ms but want the results in mm2shgo_iters : int, optional\n\t            The number of iterations done by the SHGO optimizer. 5 is recommended.\n\t            Default : False.\n\t        The original script can be found in the authours GitHub\n\t        https://github.com/ShreyasFadnavis/topopro\n", "        The IVIM model assumes that biological tissue includes a volume\n\t        fraction 'f' of water flowing with a pseudo-diffusion coefficient\n\t        D* and a fraction (1-f: treated as a separate fraction in the variable\n\t        projection method) of static (diffusion only), intra and\n\t        extracellular water, with a diffusion coefficient D. In this model\n\t        the echo attenuation of a signal in a single voxel can be written as\n\t            .. math::\n\t            S(b) = S_0*[f*e^{(-b*D\\*)} + (1-f)e^{(-b*D)}]\n\t            Where:\n\t            .. math::\n", "            S_0, f, D\\* and D are the IVIM parameters.\n\t        References\n\t        ----------\n\t        .. [1] Le Bihan, Denis, et al. \"Separation of diffusion and perfusion\n\t               in intravoxel incoherent motion MR imaging.\" Radiology 168.2\n\t               (1988): 497-505.\n\t        .. [2] Federau, Christian, et al. \"Quantitative measurement of brain\n\t               perfusion with intravoxel incoherent motion MR imaging.\"\n\t               Radiology 265.3 (2012): 874-881.\n\t        .. [3] Fadnavis, Shreyas et.al. \"MicroLearn: Framework for machine\n", "               learning, reconstruction, optimization and microstructure\n\t               modeling, Proceedings of: International Society of Magnetic\n\t               Resonance in Medicine (ISMRM), Montreal, Canada, 2019.\n\t        \"\"\"\n\t        self.bvals = gtab.bvals\n\t        self.yhat_perfusion = np.zeros(self.bvals.shape[0])\n\t        self.yhat_diffusion = np.zeros(self.bvals.shape[0])\n\t        self.exp_phi = np.zeros((self.bvals.shape[0], 2))\n\t        self.shgo_iters = shgo_iters\n\t        self.rescale_results_to_mm2_s = rescale_results_to_mm2_s\n", "        # The rescaled units arguement converts the bounds for D* and D from\n\t        # mm2/s to m2/ms.\n\t        # It is assumed that the b-vales are given in the corresponding units\n\t        # and are thus not changed.\n\t        if gtab.bvals[-1] >= 10:\n\t            self.bvals = gtab.bvals/1000\n\t        if bounds == None:\n\t            # Bounds expressed as (lower bound, upper bound) for [f, D*, D].\n\t            self.bounds = np.array([(0, 1), (5, 100), (0, 4)])\n\t        elif (bounds[0][1] <= 1) or rescale_units: # Realistically, if mm2/s units are used, D* bound is <= 1\n", "            self.bounds = np.array([(bounds[0][0], bounds[1][0]), \\\n\t                                    (bounds[0][1]*1000, bounds[1][1]*1000), \\\n\t                                    (bounds[0][2]*1000, bounds[1][2]*1000)])\n\t        else: # Finally, if units if m2/ms are already used\n\t            self.bounds = np.array([(bounds[0][0], bounds[1][0], \\\n\t                                    (bounds[0][1], bounds[1][1]), \\\n\t                                    (bounds[0][2], bounds[1][2]))])\n\t    @multi_voxel_fit\n\t    def fit(self, data):\n\t        r\"\"\" Fit method of the IvimModelTopoPro model class\n", "        Separable Homological Optimization for IVIM [1]_.\n\t        The TopoPro computes the IVIM parameters using the a bi-level\n\t        topological approach. This algorithm uses three different optimizers.\n\t        Level 1: It starts with a Simplicial Homolgy Optimization algorithm and\n\t        fits the parameters in the power of exponentials. Then the fitted\n\t        parameters in the first step are utilized to make a linear convex\n\t        problem. Using a convex optimization, the volume fractions are\n\t        determined.\n\t        Level 2: Simplicial Homolgy Optimization fitting on all the\n\t        parameters. The results of `Level 1` are utilized as\n", "        the initial values for the `Level 2` of the algorithm.\n\t        References\n\t        ----------\n\t        .. [1] Endres, Stefan et.al. \"A simplicial homology algorithm for\n\t               Lipschitz optimisation\", Journal of Global Optimization, 2018.\n\t        .. [2] Fadnavis, Shreyas et.al. \"MicroLearn: Framework for machine\n\t               learning, reconstruction, optimization and microstructure\n\t               modeling, Proceedings of: International Society of Magnetic\n\t               Resonance in Medicine (ISMRM), Montreal, Canada, 2019.\n\t        .. [3] Farooq, Hamza, et al. \"Microstructure Imaging of Crossing (MIX)\n", "               White Matter Fibers from diffusion MRI.\" Scientific reports 6\n\t               (2016).\n\t        \"\"\"\n\t        data_max = data.max()\n\t        if data_max == 0:\n\t            pass\n\t        else:\n\t            data = data / data_max\n\t        b = self.bvals\n\t        # Setting up the bounds for level-1 SHGO\n", "        bounds_sh = np.array(self.bounds[1:])\n\t        # Optimizer #1: SHGO\n\t        minimizer_kwargs_pre = {'options': {f'ftol': 1e-4},\n\t                                'method': 'SLSQP'}\n\t        res_one = shgo(self.stoc_search_cost, bounds_sh, iters=self.shgo_iters,\n\t                       sampling_method='simplicial', args=(data,))\n\t        x = res_one.x\n\t        phi = self.phi(x)\n\t        # Optimizer #2: Convex Optimizer\n\t        f = self.cvx_fit(data, phi)\n", "        x_f = self.x_and_f_to_x_f(x, f)\n\t        # Setting up the bounds for level-2 SHGO\n\t        bounds_simpl = [(x_f[0] - x_f[0]*.99, x_f[0] + x_f[0]*.99),\n\t                        (x_f[1] - x_f[1]*.7, x_f[1] + x_f[1]*.7),\n\t                        (x_f[2] - x_f[2]*.7, x_f[2] + x_f[2]*.7)]\n\t        # build simplex around x_f (bounds must be symmetric)\n\t        minimizer_kwargs = {'options': {f'ftol': 1e-4}}\n\t        res = shgo(self.nlls_cost, bounds_simpl, iters=self.shgo_iters,\n\t                   minimizer_kwargs=minimizer_kwargs,\n\t                   sampling_method='simplicial',\n", "                   args=(data,))\n\t        result = res.x\n\t        f_est = result[0]\n\t        D_star_est = result[1]\n\t        D_est = result[2]\n\t        S0 = data / (f_est * np.exp(-b * D_star_est) + (1 - f_est) *\n\t                     np.exp(-b * D_est))\n\t        S0_est = S0 * data_max\n\t        # final result containing the four fit parameters: S0, f, D* and D\n\t        if self.rescale_results_to_mm2_s:\n", "            result = np.array([np.mean(S0_est), f_est, D_star_est*1e-3, D_est*1e-3])\n\t        else:\n\t            result = np.insert(result, 0, np.mean(S0_est), axis=0)\n\t        return IvimFit(self, result)\n\t    def rescale_bounds_and_initial_guess(self, rescale_units):\n\t        if rescale_units:\n\t            # Rescale the guess\n\t            self.initial_guess = (self.initial_guess[0], self.initial_guess[1], \\\n\t                self.initial_guess[2]*1000, self.initial_guess[3]*1000)\n\t            # Rescale the bounds\n", "            lower_bounds = (self.bounds[0][0], self.bounds[0][1], \\\n\t                self.bounds[0][2]*1000, self.bounds[0][3]*1000)\n\t            upper_bounds = (self.bounds[1][0], self.bounds[1][1], \\\n\t                self.bounds[1][2]*1000, self.bounds[1][3]*1000)\n\t            self.bounds = (lower_bounds, upper_bounds)\n\t    def stoc_search_cost(self, x, signal):\n\t        \"\"\"\n\t        Cost function for SHGO algorithm. Performs an approximation of the\n\t        homology groups of a complex built on a hypersurface homeomorphic to a\n\t        complex on the objective function for the non-linear parameters 'x'.\n", "        The objective funtion is calculated in the :func: `ivim_shgo`.\n\t        The function constructs the parameters using :func: `phi`.\n\t        Parameters\n\t        ----------\n\t        x : array\n\t            input from the Simplicial Homology optimizer.\n\t        signal : array\n\t            The signal values measured for this model.\n\t        Returns\n\t        -------\n", "        :func: `ivim_shgo`\n\t        \"\"\"\n\t        phi = self.phi(x)\n\t        return self.ivim_shgo(phi, signal)\n\t    def ivim_shgo(self, phi, signal):\n\t        \"\"\"\n\t        Constructs the objective for the :func: `stoc_search_cost`.\n\t        First calculates the Moore-Penrose inverse of the input `phi` and takes\n\t        a dot product with the measured signal. The result obtained is again\n\t        multiplied with `phi` to complete the projection of the variable into\n", "        a transformed space. (see [1]_ and [2]_ for thorough discussion on\n\t        Variable Projections and relevant cost functions).\n\t        Parameters\n\t        ----------\n\t        phi : array\n\t            Returns an array calculated from :func: `Phi`.\n\t        signal : array\n\t            The signal values measured for this model.\n\t        Returns\n\t        -------\n", "        (signal -  S)^T(signal -  S)\n\t        Notes\n\t        --------\n\t        to make cost function for Differential Evolution algorithm:\n\t        .. math::\n\t            (signal -  S)^T(signal -  S)\n\t        References\n\t        ----------\n\t        .. [1] Fadnavis, Shreyas et.al. \"MicroLearn: Framework for machine\n\t               learning, reconstruction, optimization and microstructure\n", "               modeling, Proceedings of: International Society of Magnetic\n\t               Resonance in Medicine (ISMRM), Montreal, Canada, 2019.\n\t        .. [2] Farooq, Hamza, et al. \"Microstructure Imaging of Crossing (MIX)\n\t               White Matter Fibers from diffusion MRI.\" Scientific reports 6\n\t               (2016).\n\t        \"\"\"\n\t        # Moore-Penrose\n\t        phi_mp = np.dot(np.linalg.inv(np.dot(phi.T, phi)), phi.T)\n\t        f = np.dot(phi_mp, signal)\n\t        yhat = np.dot(phi, f)\n", "        return np.dot((signal - yhat).T, signal - yhat)\n\t    def cvx_fit(self, signal, phi):\n\t        \"\"\"\n\t        Performs the constrained search for the linear parameters `f` after\n\t        the estimation of `x` is done. Estimation of the linear parameters `f`\n\t        is a constrained linear least-squares optimization problem solved by\n\t        using a convex optimizer from cvxpy. The IVIM equation contains two\n\t        parameters that depend on the same volume fraction. Both are estimated\n\t        as separately in the convex optimizer.\n\t        Parameters\n", "        ----------\n\t        phi : array\n\t            Returns an array calculated from :func: `phi`.\n\t        signal : array\n\t            The signal values measured for this model.\n\t        Returns\n\t        -------\n\t        f1, f2 (volume fractions)\n\t        Notes\n\t        --------\n", "        cost function for differential evolution algorithm:\n\t        .. math::\n\t            minimize(norm((signal)- (phi*f)))\n\t        \"\"\"\n\t        # Create four scalar optimization variables.\n\t        f = cvxpy.Variable(2)\n\t        constraints = [cvxpy.sum(f) == 1,\n\t                       f[0] >= 1e-7,\n\t                       f[1] >= 1e-7,\n\t                       f[0] <= 0.9,\n", "                       f[1] <= 0.9]\n\t        # Form objective.\n\t        obj = cvxpy.Minimize(cvxpy.sum(cvxpy.square(phi @ f - signal)))\n\t        # Form and solve problem.\n\t        prob = cvxpy.Problem(obj, constraints)\n\t        prob.solve()  # Returns the optimal value.\n\t        return np.array(f.value)\n\t    def nlls_cost(self, x_f, signal):\n\t        \"\"\"\n\t        Cost function for the least square problem. The cost function is used\n", "        in the `Level 2` of TopoPro algorithm :func: `fit`.\n\t        Parameters\n\t        ----------\n\t        x_f : array\n\t            Contains the parameters 'x' and 'f' combines in the same array.\n\t        signal : array\n\t            The signal values measured for this model.\n\t        Returns\n\t        -------\n\t        sum{(signal -  phi*f)^2}\n", "        Notes\n\t        --------\n\t        cost function for the least square problem.\n\t        .. math::\n\t            sum{(signal -  phi*f)^2}\n\t        \"\"\"\n\t        x, f = self.x_f_to_x_and_f(x_f)\n\t        f1 = np.array([f, 1 - f])\n\t        phi = self.phi(x)\n\t        return np.sum((np.dot(phi, f1) - signal) ** 2)\n", "    def x_f_to_x_and_f(self, x_f):\n\t        \"\"\"\n\t        Splits the array of parameters in x_f to 'x' and 'f' for performing\n\t        a search on the both of them independently using the simplicial\n\t        homology optimizer (SHGO).\n\t        Parameters\n\t        ----------\n\t        x_f : array\n\t            Combined array of parameters 'x' and 'f' parameters.\n\t        Returns\n", "        -------\n\t        x, f : array\n\t            Splitted parameters into two separate arrays\n\t        \"\"\"\n\t        x = np.zeros(2)\n\t        f = x_f[0]\n\t        x = x_f[1:3]\n\t        return x, f\n\t    def x_and_f_to_x_f(self, x, f):\n\t        \"\"\"\n", "        Combines the array of parameters 'x' and 'f' into x_f for performing\n\t        SHGO on the `Level 2` of the optimization process.\n\t        Parameters\n\t        ----------\n\t         x, f : array\n\t            Splitted parameters into two separate arrays\n\t        Returns\n\t        -------\n\t        x_f : array\n\t            Combined array of parameters 'x' and 'f' parameters.\n", "        \"\"\"\n\t        x_f = np.zeros(3)\n\t        x_f[0] = f[0]\n\t        x_f[1:3] = x\n\t        return x_f\n\t    def phi(self, x):\n\t        \"\"\"\n\t        Creates a structure for the combining the diffusion and pseudo-\n\t        diffusion by multipling with the bvals and then exponentiating each of\n\t        the two components for fitting as per the IVIM- two compartment model.\n", "        Parameters\n\t        ----------\n\t         x : array\n\t            input from the Differential Evolution optimizer.\n\t        Returns\n\t        -------\n\t        exp_phi1 : array\n\t            Combined array of parameters perfusion/pseudo-diffusion\n\t            and diffusion parameters.\n\t        \"\"\"\n", "        self.yhat_perfusion = self.bvals * x[0]\n\t        self.yhat_diffusion = self.bvals * x[1]\n\t        self.exp_phi[:, 0] = np.exp(-self.yhat_perfusion)\n\t        self.exp_phi[:, 1] = np.exp(-self.yhat_diffusion)\n\t        return self.exp_phi\n\tclass IvimFit(object):\n\t    def __init__(self, model, model_params):\n\t        \"\"\" Initialize a IvimFit class instance.\n\t            Parameters\n\t            ----------\n", "            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n\t            array of ivim parameters. If the fitting is done\n\t            for multi_voxel data, the multi_voxel decorator will\n\t            run the fitting on all the voxels and model_params\n\t            will be an array of the dimensions (data[:-1], 4),\n\t            i.e., there will be 4 parameters for each of the voxels.\n\t        \"\"\"\n\t        self.model = model\n", "        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n\t        N = model_params.ndim\n\t        if type(index) is not tuple:\n\t            index = (index,)\n\t        elif len(index) >= model_params.ndim:\n\t            raise IndexError(\"IndexError: invalid index\")\n\t        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n", "    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n\t    @property\n\t    def perfusion_fraction(self):\n\t        return self.model_params[..., 1]\n\t    @property\n\t    def D_star(self):\n\t        return self.model_params[..., 2]\n\t    @property\n", "    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n\t    def shape(self):\n\t        return self.model_params.shape[:-1]\n"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_sivim.py", "chunked_list": ["\"\"\" Classes and functions for fitting ivim model \"\"\"\n\timport numpy as np\n\tfrom scipy.optimize import curve_fit\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tfrom scipy.signal import unit_impulse\n\tclass IvimModelsIVIM(ReconstModel):\n\t    def __init__(self, gtab, b_threshold=200, bounds=None, initial_guess=None, rescale_units=False):\n\t        \"\"\"A simple nlls fit to the bi-exponential IVIM model. No segmentations\n", "        are performed.\n\t        Args:\n\t            gtab (DIPY gradient table): \n\t            DIPY gradient table object containing\n\t            information of the diffusion gradients, b-values, etc.\n\t            bounds (array-like, optional): \n\t            Bounds expressed as [lower bounds, upper bounds] for S0, f, D*, and\n\t            D respectively. Defaults to None.\n\t            initial_guess (array-like, optional):\n\t            The initial guess for the parameters. Defaults to None.\n", "            rescale_units (bool, optional): \n\t            Set to True if parameters are to be returned in units of m2/ms. \n\t            The conversion only works in one direction, from mm2/s to m2/ms.\n\t            Make sure the b-values in the gtab object are already in units of\n\t            m2/ms if this is used. Defaults to False.\n\t        \"\"\"\n\t        self.b_threshold = b_threshold\n\t        self.bvals = gtab.bvals[gtab.bvals >= self.b_threshold]\n\t        self.bvals = np.insert(self.bvals, 0, 0)\n\t        # Get the indices for the b-values that fulfils the condition.\n", "        # Will be used to get the corresponding signals.\n\t        b_threshold_idx = np.where(self.bvals >= self.b_threshold)[0][1]\n\t        self.signal_indices = [0] + list(np.where(gtab.bvals >= self.b_threshold)[0])\n\t        self.set_bounds(bounds) # Sets the bounds according to the requirements of the fits\n\t        self.set_initial_guess(initial_guess) # Sets the initial guess if the fit requires it\n\t        self.rescale_bounds_and_initial_guess(rescale_units) # Rescales the units of D* and D to m2/ms if set to True\n\t    @multi_voxel_fit\n\t    def fit(self, data):\n\t        # Normalize the data\n\t        data_max = data.max()\n", "        if data_max == 0:\n\t            pass\n\t        else:\n\t            data = data / data_max\n\t        # Sort out the signals from non-zero b-values < b-threshold\n\t        ydata = data[self.signal_indices]\n\t        # Perform the fit\n\t        popt, pcov = curve_fit(self.sivim_model, self.bvals, ydata, p0=self.initial_guess,\\\n\t            bounds=self.bounds, maxfev=10000)\n\t        # Set the results and rescale S0\n", "        result = popt\n\t        result[0] *= data_max\n\t        return IvimFit(self, result)\n\t    def sivim_model(self, b, S0, f, D):\n\t        delta = unit_impulse(b.shape, idx=0)\n\t        res = S0*(f*delta + (1-f)*np.exp(-b*D))\n\t        return res\n\t    def set_bounds(self, bounds):\n\t        # Use this function for fits that uses curve_fit\n\t        if bounds == None:\n", "            self.bounds = np.array([(0, 0, 0), (np.inf, 1, 0.004)])\n\t        else:\n\t            self.bounds = np.array([(0, *bounds[0]), (np.inf, *bounds[1])])\n\t    def set_initial_guess(self, initial_guess):\n\t        if initial_guess == None:\n\t            self.initial_guess = (1, 0.2, 0.001)\n\t        else:\n\t            self.initial_guess = initial_guess\n\t    def rescale_bounds_and_initial_guess(self, rescale_units):\n\t        if rescale_units:\n", "            # Rescale the guess\n\t            self.initial_guess = (self.initial_guess[0], self.initial_guess[1], \\\n\t                self.initial_guess[2]*1000)\n\t            # Rescale the bounds\n\t            lower_bounds = (self.bounds[0][0], self.bounds[0][1], \\\n\t                self.bounds[0][2]*1000)\n\t            upper_bounds = (self.bounds[1][0], self.bounds[1][1], \\\n\t                self.bounds[1][2]*1000)\n\t            self.bounds = (lower_bounds, upper_bounds)\n\tclass IvimFit(object):\n", "    def __init__(self, model, model_params):\n\t        \"\"\" Initialize a IvimFit class instance.\n\t            Parameters\n\t            ----------\n\t            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n\t            array of ivim parameters. If the fitting is done\n\t            for multi_voxel data, the multi_voxel decorator will\n\t            run the fitting on all the voxels and model_params\n", "            will be an array of the dimensions (data[:-1], 4),\n\t            i.e., there will be 4 parameters for each of the voxels.\n\t        \"\"\"\n\t        self.model = model\n\t        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n\t        N = model_params.ndim\n\t        if type(index) is not tuple:\n\t            index = (index,)\n", "        elif len(index) >= model_params.ndim:\n\t            raise IndexError(\"IndexError: invalid index\")\n\t        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n\t    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n\t    @property\n\t    def perfusion_fraction(self):\n\t        return self.model_params[..., 1]\n", "    #@property\n\t    #def D_star(self):\n\t        #return self.model_params[..., 2]\n\t    @property\n\t    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n\t    def shape(self):\n\t        return self.model_params.shape[:-1]\n"]}
{"filename": "src/original/IAR_LundUniversity/ivim_fit_method_segmented_2step.py", "chunked_list": ["\"\"\" Classes and functions for fitting ivim model \"\"\"\n\timport numpy as np\n\tfrom scipy.optimize import curve_fit\n\tfrom dipy.reconst.base import ReconstModel\n\tfrom dipy.reconst.multi_voxel import multi_voxel_fit\n\tfrom dipy.utils.optpkg import optional_package\n\tclass IvimModelSegmented2Step(ReconstModel):\n\t    def __init__(self, gtab, b_threshold=200, \\\n\t        initial_guess=None, perf_initial_guess=None, bounds=None, rescale_units=False):\n\t        \"\"\"The conventional 2-step segmented fit.\n", "            1. Fit mono-expoential to large b-values above a b-threshold\n\t            2. Fix D in a NLLS fit to the diffusive bi-exponential IVIM model.\n\t        Args:\n\t            gtab (DIPY gtab class): \n\t                Object that holds the diffusion encoding information. In this\n\t                case, the b-values.\n\t            b_threshold (float, optional): \n\t                The threshold for the 2-step fit. Defaults to 200.\n\t            perf_initial_guess (array-like, optional): \n\t                The initial guess for the fit. Defaults to None.\n", "            bounds (array-like, optional): \n\t                Bounds for f, D*, and D (in that order), input as a tuple of \n\t                lower bounds and upper bounds. Defaults to None.\n\t            rescale_units (bool, optional): Set to true if you are inputting\n\t            bounds and initial guesses in mm2/s but want the returned values to\n\t            be in units of m2/ms. Make sure the b-values are already in the\n\t            latter units if set to True. Defaults to False.\n\t        \"\"\"\n\t        self.bvals = gtab.bvals\n\t        self.diff_b_threshold_lower = b_threshold\n", "        self.set_bounds(bounds)\n\t        self.set_initial_guess(initial_guess)\n\t        self.rescale_bounds_and_initial_guess(rescale_units)\n\t    @multi_voxel_fit\n\t    def fit(self, data):\n\t        # Normalize the data\n\t        data_max = data.max()\n\t        if data_max == 0:\n\t            pass\n\t        else:\n", "            data = data / data_max\n\t        ### Fit the diffusion signal to bvals >= diff_b_threshold_lower\n\t        diff_bounds = [(self.bounds[0][0], self.bounds[0][3]), \\\n\t            (self.bounds[1][0], self.bounds[1][3])] # Bounds for S0 and D\n\t        diff_bval_indices = np.where(self.bvals >= self.diff_b_threshold_lower)[0]\n\t        diff_bvals = self.bvals[diff_bval_indices]\n\t        diff_data = data[diff_bval_indices]\n\t        S0_diff_est, D_est = curve_fit(self.diffusion_signal, diff_bvals, diff_data, \\\n\t            bounds=diff_bounds, p0=np.take(self.initial_guess, [0, 3]), maxfev=10000)[0]\n\t        # Fit to the full bi-exponential, D fixed\n", "        full_initial_guess = np.array(self.initial_guess[:-1])\n\t        full_bounds_lower = self.bounds[0][:-1]\n\t        full_bounds_upper = self.bounds[1][:-1]\n\t        full_bounds = (full_bounds_lower, full_bounds_upper)\n\t        S0_est, f_est, D_star_est = curve_fit(lambda b, S0, f, D_star: self.ivim_signal(b, S0, f, D_star, D_est), self.bvals, data, bounds=full_bounds, p0=full_initial_guess, maxfev=10000)[0]\n\t        # Set the results and rescale S0\n\t        result = np.array([S0_est, f_est, D_star_est, D_est])\n\t        result[0] *= data_max\n\t        return IvimFit(self, result)\n\t    def diffusion_signal(self, b, S0, D):\n", "        return S0*np.exp(-b*D)\n\t    def perfusion_signal(self, b, S0, D_star):\n\t        return S0*np.exp(-b*D_star)\n\t    def ivim_signal(self, b, S0, f, D_star, D):\n\t        return S0*(f*np.exp(-b*D_star) + (1-f)*np.exp(-b*D))\n\t    def set_bounds(self, bounds):\n\t        # Use this function for fits that uses curve_fit\n\t        if bounds == None:\n\t            self.bounds = np.array([(0, 0, 0.005, 0), (np.inf, 1, 0.1, 0.004)])\n\t        else:\n", "            self.bounds = np.array([(0, *bounds[0]), (np.inf, *bounds[1])])\n\t    def set_initial_guess(self, initial_guess):\n\t        if initial_guess == None:\n\t            self.initial_guess = (1, 0.2, 0.03, 0.001)\n\t        else:\n\t            self.initial_guess = initial_guess\n\t    def rescale_bounds_and_initial_guess(self, rescale_units):\n\t        if rescale_units:\n\t            # Rescale the guess\n\t            self.initial_guess = (self.initial_guess[0], self.initial_guess[1], \\\n", "                self.initial_guess[2]*1000, self.initial_guess[3]*1000)\n\t            # Rescale the bounds\n\t            lower_bounds = (self.bounds[0][0], self.bounds[0][1], \\\n\t                self.bounds[0][2]*1000, self.bounds[0][3]*1000)\n\t            upper_bounds = (self.bounds[1][0], self.bounds[1][1], \\\n\t                self.bounds[1][2]*1000, self.bounds[1][3]*1000)\n\t            self.bounds = (lower_bounds, upper_bounds)\n\tclass IvimFit(object):\n\t    def __init__(self, model, model_params):\n\t        \"\"\" Initialize a IvimFit class instance.\n", "            Parameters\n\t            ----------\n\t            model : Model class\n\t            model_params : array\n\t            The parameters of the model. In this case it is an\n\t            array of ivim parameters. If the fitting is done\n\t            for multi_voxel data, the multi_voxel decorator will\n\t            run the fitting on all the voxels and model_params\n\t            will be an array of the dimensions (data[:-1], 4),\n\t            i.e., there will be 4 parameters for each of the voxels.\n", "        \"\"\"\n\t        self.model = model\n\t        self.model_params = model_params\n\t    def __getitem__(self, index):\n\t        model_params = self.model_params\n\t        N = model_params.ndim\n\t        if type(index) is not tuple:\n\t            index = (index,)\n\t        elif len(index) >= model_params.ndim:\n\t            raise IndexError(\"IndexError: invalid index\")\n", "        index = index + (slice(None),) * (N - len(index))\n\t        return type(self)(self.model, model_params[index])\n\t    @property\n\t    def S0_predicted(self):\n\t        return self.model_params[..., 0]\n\t    @property\n\t    def perfusion_fraction(self):\n\t        return self.model_params[..., 1]\n\t    @property\n\t    def D_star(self):\n", "        return self.model_params[..., 2]\n\t    @property\n\t    def D(self):\n\t        return self.model_params[..., 3]\n\t    @property\n\t    def shape(self):\n\t        return self.model_params.shape[:-1]\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/__init__.py", "chunked_list": []}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/__init__.py", "chunked_list": []}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_loading/load_ivim_subject.py", "chunked_list": ["import os\n\timport logging\n\timport torch\n\timport numpy as np\n\timport torchio as tio\n\tdef load_ivim_subject(study_subject_path):\n\t    \"\"\"\n\t    loads torchio subject with IVIM data (signals and bvalues)\n\t    Args:\n\t        study_subject_path: path in which subject data is located\n", "    Returns:\n\t    \"\"\"\n\t    subject_dict = {}\n\t    # find all files that match study path and subject id\n\t    for file in os.listdir(study_subject_path):\n\t        file_path = os.path.join(study_subject_path, file)\n\t        logging.info(f'start loading data from {file_path}')\n\t        # Check file extension for image file\n\t        if file_path[-2:] == \"gz\" or file_path[-2:] == \"ii\":\n\t            # load nifti image\n", "            image = tio.Image(file_path)\n\t            image.set_data(image.data.to(dtype=torch.float32))\n\t            subject_dict['signals'] = image\n\t        # Check if file contains bvalues\n\t        elif file_path[-2:] == \"al\":\n\t            text_file = np.genfromtxt(file_path)\n\t            bvals = np.array(text_file)\n\t            subject_dict[\"xvals\"] = tio.Image(tensor=torch.Tensor(np.reshape(bvals, (bvals.shape[0], 1, 1, 1))))\n\t        else:\n\t            logging.info(f'skipping loading of file {file_path}, no appropriate file extension. ')\n", "        # Create subject\n\t    if 'xvals' in subject_dict.keys() and 'signals' in subject_dict.keys():\n\t        return tio.Subject(subject_dict)\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_loading/__init__.py", "chunked_list": []}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/__init__.py", "chunked_list": []}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/AverageSignalsOfEqualXvals.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torchio\n\tfrom torchio.transforms import Transform\n\tclass AverageSignalsOfEqualXvals(Transform):\n\t    def __init__(self,  **kwargs):\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n\t        normalize signals\n", "        Args:\n\t            signals: signals array to normalize\n\t            xvals: xval array\n\t        Returns:\n\t            normalized_signals: normalized signals array\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict()\n\t        signals = images_dict['signals'].numpy()\n\t        xvals = np.squeeze(images_dict['xvals'].numpy())\n\t        signals, xvals = self.average_signal_of_equal_xvals(signals, xvals)\n", "        subject.add_image(torchio.Image(tensor=torch.Tensor(signals)), 'signals')\n\t        subject.add_image(torchio.Image(tensor=torch.Tensor(np.reshape(xvals, (xvals.shape[0], 1, 1, 1)))), 'xvals')\n\t        return subject\n\t    @staticmethod\n\t    def average_signal_of_equal_xvals(signals, xvals):\n\t        \"\"\"\n\t        average the signal of equal xvals\n\t        Args:\n\t            signals: signal matrix [signals X xvals]\n\t            xvals: array of xvals\n", "        Returns:\n\t            averaged_signal_matrix: averaged signal matrix [signals X unique_xvals]\n\t            unique_xval_arrays: unique xvals in averaged signal matrix\n\t        \"\"\"\n\t        unique_xvals = np.unique(xvals)\n\t        averaged_signals = np.zeros((unique_xvals.shape[0], *signals.shape[1:]))\n\t        for xval_idx, unique_xval in enumerate(unique_xvals):\n\t            averaged_signals[xval_idx, ...] = np.squeeze(np.mean(signals[np.where(xvals == unique_xval), ...], axis=1))\n\t        return averaged_signals, unique_xvals\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/SortSignalOnXval.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torchio\n\tfrom torchio.transforms import Transform\n\tclass SortSignalOnXval(Transform):\n\t    def __init__(self,  **kwargs):\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n\t        Sorts signals and xvals on ascending xvals\n", "        Args:\n\t            subject: Subject\n\t        Returns:\n\t            subject: Subject\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict()\n\t        signals = images_dict['signals'].numpy()\n\t        xvals = np.squeeze(images_dict['xvals'].numpy())\n\t        signals, xvals = self.sort_signals_on_xval_array(signals, xvals)\n\t        subject.add_image(torchio.Image(tensor=torch.Tensor(signals)), 'signals')\n", "        subject.add_image(torchio.Image(tensor=torch.Tensor(np.reshape(xvals, (xvals.shape[0], 1, 1, 1)))), 'xvals')\n\t        return subject\n\t    @staticmethod\n\t    def sort_signals_on_xval_array(signals, xvals):\n\t        \"\"\"\n\t        Sorts signals and xvals on ascending xvals\n\t        Args:\n\t            signals: signals to sort\n\t            bval: bvalues to use for sorting\n\t        Returns:\n", "            sorted_signals: sorted signals\n\t            sorted_bvals: sorted bvals\n\t        \"\"\"\n\t        sorted_xval_idcs = np.argsort(xvals)\n\t        sorted_xvals = xvals[sorted_xval_idcs]\n\t        sorted_signals = signals[sorted_xval_idcs, ...]\n\t        return sorted_signals, sorted_xvals"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/NormalizeSignals.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torchio\n\tfrom torchio.transforms import Transform\n\tclass NormalizeSignals(Transform):\n\t    def __init__(self, xval_threshold, **kwargs):\n\t        self.xval_threshold = xval_threshold\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n", "        normalize xvals Image of subject\n\t        Args:\n\t            subject: Subject\n\t        Returns:\n\t            subject: Subject\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict()\n\t        signals = images_dict['signals'].numpy()\n\t        xvals = np.squeeze(images_dict['xvals'].numpy())\n\t        signals = self.normalize_signals(signals, xvals, self.xval_threshold)\n", "        subject.add_image(torchio.Image(tensor=torch.Tensor(signals)), 'signals')\n\t        return subject\n\t    @staticmethod\n\t    def normalize_signals(signals, xvals, xval_threshold):\n\t        \"\"\"\n\t         normalize signals\n\t         Args:\n\t             signals: signals array to normalize\n\t             xvals: xval array\n\t             xval_threshold: threshold below which bvals are considered b0\n", "         Returns:\n\t             normalized_signals: normalized signals array\n\t         \"\"\"\n\t        # get average b0 signals and set signals with S0 of 0 to nan\n\t        mean_S0 = np.nanmean(signals[xvals <= xval_threshold, :, :, :], axis=0)\n\t        signals[:, mean_S0 == 0] = np.nan\n\t        # normalize signals to S0 intensity\n\t        normalized_signals = signals / mean_S0\n\t        normalized_signals[np.isnan(normalized_signals)] = 0\n\t        return normalized_signals\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/SignalMask.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torchio\n\tfrom torchio.transforms import Transform\n\tclass SignalMask(Transform):\n\t    def __init__(self, **kwargs):\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n\t        curates signals Image of subject\n", "        Args:\n\t            subject: Subject\n\t        Returns:\n\t            subject: Subject\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict()\n\t        signals = images_dict['signals'].numpy()\n\t        signal_mask = self.signal_mask(signals)\n\t        subject.add_image(torchio.Image(tensor=torch.Tensor(np.expand_dims(signal_mask, 0))), 'signal_mask')\n\t        return subject\n", "    @staticmethod\n\t    def signal_mask(signals):\n\t        \"\"\"\n\t        returns mask with nonzero element for signal vectors with nonzero entries\n\t        Args:\n\t            signals: signals\n\t        Returns:\n\t            masked_signals: signals containing nonzero elements\n\t        \"\"\"\n\t        return np.sum(signals, axis=0) > 0\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/SignalCuration.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torchio\n\tfrom torchio.transforms import Transform\n\tclass SignalCuration(Transform):\n\t    def __init__(self, qmri_application, **kwargs):\n\t        self.qmri_application = qmri_application\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n", "        curates signals Image of subject\n\t        Args:\n\t            subject: Subject\n\t        Returns:\n\t            subject: Subject\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict()\n\t        if self.qmri_application == 'IVIM' or 'ivim':\n\t            signals = images_dict['signals'].numpy()\n\t            xvals = np.squeeze(images_dict['xvals'].numpy())\n", "            valid_mask = self.ivim_selection(signals, xvals)\n\t            subject.add_image(torchio.Image(tensor=torch.Tensor(np.expand_dims(valid_mask, 0))), 'valid_mask')\n\t            return subject\n\t        else:\n\t            raise NotImplementedError\n\t    @staticmethod\n\t    def ivim_selection(signals, xvals):\n\t        \"\"\"\n\t        returns only those signals exhibiting ivim decay\n\t        Args:\n", "            signals: signals for corresponding xvals\n\t            xvals: xvals\n\t        Returns:\n\t            normalized_valid_signals: normalized_valid_signals that exhibit ivim-like decay\n\t            masked_signals: normalized_signals where signals not exhibiting ivim-like decay are set to 0\n\t        \"\"\"\n\t        # get average b0 signals and set signals with S0 of 0 to nan\n\t        mean_S0 = np.nanmean(signals[xvals <= 0.0001, ...], axis=0)\n\t        # select only those voxels with average S0 larger than half of median S0 of voxels with S0 larger than 0\n\t        valid_idcs_median_value = mean_S0 > (0.5 * np.nanmedian(mean_S0[mean_S0 > 0]))\n", "        # check if signal is ivim like\n\t        signals[signals > 1.5] = 1.5\n\t        valid_idcs_ivim_curve1 = np.percentile(signals[xvals * 100 < 50, ...], 95,\n\t                                               axis=0) < 1.3\n\t        valid_idcs_ivim_curve2 = np.percentile(signals[xvals * 100 > 50, ...], 95,\n\t                                               axis=0) < 1.2\n\t        valid_idcs_ivim_curve3 = np.percentile(signals[xvals * 100 > 150, ...], 95,\n\t                                               axis=0) < 1.0\n\t        mask_signals = valid_idcs_median_value & valid_idcs_ivim_curve1 & valid_idcs_ivim_curve2 & valid_idcs_ivim_curve3\n\t        return mask_signals\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/NormalizeXvals.py", "chunked_list": ["import torch\n\timport torchio\n\timport numpy as np\n\tfrom torchio.transforms import Transform\n\tclass NormalizeXvals(Transform):\n\t    def __init__(self, normalization_factor, **kwargs):\n\t        self.normalization_factor = normalization_factor\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n", "        normalize xvals Image of subject\n\t        Args:\n\t            subject: Subject\n\t        Returns:\n\t            subject: Subject\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict()\n\t        xvals = np.squeeze(images_dict['xvals'].numpy())\n\t        xvals = self.normalize_xvals(xvals, self.normalization_factor)\n\t        subject.add_image(torchio.Image(tensor=torch.Tensor(np.reshape(xvals, (xvals.shape[0], 1, 1, 1)))), 'xvals')\n", "        return subject\n\t    @staticmethod\n\t    def normalize_xvals(xvals, normalization_factor):\n\t        \"\"\"\n\t        normalize signals\n\t        Args:\n\t            xvals: xvalue array\n\t            normalization_factor: factor to multiply xvals with\n\t        Returns:\n\t            normalized_xvals: normalized signals array\n", "        \"\"\"\n\t        normalized_xvals = xvals * normalization_factor\n\t        return normalized_xvals\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/NormalizeMaxSignal.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torchio\n\tfrom torchio.transforms import Transform\n\tclass NormalizeMaxSignal(Transform):\n\t    def __init__(self, **kwargs):\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n\t        normalize signals Image of subject\n", "        Args:\n\t            subject: Subject\n\t        Returns:\n\t            subject: Subject\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict()\n\t        signals = images_dict['signals'].numpy()\n\t        signals = self.normalize_signals(signals)\n\t        subject.add_image(torchio.Image(tensor=torch.Tensor(signals)), 'signals')\n\t        return subject\n", "    @staticmethod\n\t    def normalize_signals(signals):\n\t        \"\"\"\n\t         normalize signals\n\t         Args:\n\t             signals: signals array to normalize\n\t         Returns:\n\t             normalized_signals: normalized signals array\n\t         \"\"\"\n\t        maxsignal = np.nanmax(signals, axis=0)\n", "        signals /= maxsignal\n\t        return signals\n"]}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/__init__.py", "chunked_list": []}
{"filename": "src/original/DK_OGC_AmsterdamUMC/utils/data_processing/processors/FlattenImageData.py", "chunked_list": ["import numpy as np\n\timport torch\n\timport torchio\n\tfrom torchio.transforms import Transform\n\tclass FlattenImageData(Transform):\n\t    def __init__(self, **kwargs):\n\t        super().__init__(**kwargs)\n\t    def apply_transform(self, subject):\n\t        \"\"\"\n\t        flattens image data of signals image of subject\n", "        Args:\n\t            signals: signals array to normalize\n\t            xvals: xval array\n\t        Returns:\n\t            normalized_signals: normalized signals array\n\t        \"\"\"\n\t        images_dict = subject.get_images_dict(include=self.include, exclude=self.exclude)\n\t        for image_key, image in images_dict.items():\n\t            flattened_array = self.flatten_image_data(image.numpy())\n\t            subject.add_image(torchio.Image(tensor=torch.Tensor(np.reshape(flattened_array,\n", "                                                                           (flattened_array.shape[0],\n\t                                                                            flattened_array.shape[1], 1, 1)))),\n\t                              image_key)\n\t        return subject\n\t    @staticmethod\n\t    def flatten_image_data(signals):\n\t        \"\"\"\n\t        Flattens 4D array into 2D array\n\t        Args:\n\t            signals: signals array to normalize\n", "        Returns:\n\t            normalized_signals: normalized signals array\n\t        \"\"\"\n\t        bvals, x, y, z = signals.shape\n\t        signals_array = np.reshape(signals, (bvals, x * y * z))\n\t        return signals_array\n"]}
{"filename": "src/original/ETP_SRI/__init__.py", "chunked_list": []}
{"filename": "src/original/ETP_SRI/LinearFitting.py", "chunked_list": ["import numpy as np\n\timport numpy.polynomial.polynomial as poly\n\tfrom utils.data_simulation.GenerateData import GenerateData\n\tclass LinearFit:\n\t    \"\"\"\n\t    Performs linear fits of exponential data\n\t    \"\"\"\n\t    def __init__(self, linear_cutoff=500):\n\t        \"\"\"\n\t        Parameters\n", "        ----------\n\t        linear_cutoff : float\n\t            The b-value after which it can be assumed that the perfusion value is negligible\n\t        \"\"\"\n\t        self.linear_cutoff = linear_cutoff\n\t    def linear_fit(self, bvalues, signal, weighting=None, stats=False):\n\t        \"\"\"\n\t        Fit a single line\n\t        Parameters\n\t        ----------\n", "        bvalues : list or array of float\n\t            The diffusion (b-values)\n\t        signal : list or array of float\n\t            The acquired signal to fit. It is assumed to be linearized at this point.\n\t        weighting : list or array fo float\n\t            Weights to pass into polyfit. None is no weighting.\n\t        stats : boolean\n\t            If true, return the polyfit statistics\n\t        \"\"\"\n\t        assert bvalues.size == signal.size, \"Signal and b-values don't have the same number of values\"\n", "        if stats:\n\t            D, stats = poly.polyfit(np.asarray(bvalues), signal, 1, full=True, w=weighting)\n\t            return [np.exp(D[0]), *-D[1:]], stats\n\t        else:\n\t            D = poly.polyfit(np.asarray(bvalues), signal, 1, w=weighting)\n\t            return [np.exp(D[0]), *-D[1:]]\n\t    def ivim_fit(self, bvalues, signal):\n\t        \"\"\"\n\t        Fit an IVIM curve\n\t        This fits a bi-exponential curve using linear fitting only\n", "        Parameters\n\t        ----------\n\t        bvalues : list or array of float\n\t            The diffusion (b-values)\n\t        signal : list or array of float\n\t            The acquired signal to fit. It is assumed to be exponential at this point\n\t        \"\"\"\n\t        bvalues = np.asarray(bvalues)\n\t        assert bvalues.size > 1, 'Too few b-values'\n\t        signal = np.asarray(signal)\n", "        assert bvalues.size == signal.size, \"Signal and b-values don't have the same number of values\"\n\t        gd = GenerateData()\n\t        lt_cutoff = bvalues <= self.linear_cutoff\n\t        gt_cutoff = bvalues >= self.linear_cutoff\n\t        linear_signal = np.log(signal)\n\t        D = self.linear_fit(bvalues[gt_cutoff], linear_signal[gt_cutoff])\n\t        if lt_cutoff.sum() > 0:\n\t            signal_Dp = linear_signal[lt_cutoff] - gd.linear_signal(D[1], bvalues[lt_cutoff], np.log(D[0]))\n\t            Dp_prime = self.linear_fit(bvalues[lt_cutoff], np.log(signal_Dp))\n\t            if np.any(np.asarray(Dp_prime) < 0) or not np.all(np.isfinite(Dp_prime)):\n", "                print('Perfusion fit failed')\n\t                Dp_prime = [0, 0]\n\t            f = signal[0] - D[0]\n\t        else:\n\t            print(\"This doesn't seem to be an IVIM set of b-values\")\n\t            f = 1\n\t            Dp_prime = [0, 0]\n\t        D = D[1]\n\t        Dp = D + Dp_prime[1]\n\t        if np.allclose(f, 0):\n", "            Dp = 0\n\t        elif np.allclose(f, 1):\n\t            D = 0\n\t        return [f, D, Dp]\n"]}
