{"filename": "test/test_extract_typed_completion.py", "chunked_list": ["import jiggybase\n\tfrom pydantic import BaseModel, Field\n\tfrom typing import Optional, List\n\tfrom datetime import date\n\tfrom pydantic import BaseModel, Field, ValidationError, validator\n\tfrom time import time\n\tjb = jiggybase.JiggyBase()\n\tgpt3_times =0 \n\tgpt4_times = 0\n\tcount  = 0\n", "# Define the pydantic model\n\tclass BookInformation(BaseModel):\n\t    title: str = Field(description=\"The title of the book\")\n\t    author: str = Field(description=\"The name of the book's author\")\n\t    publication_year: Optional[int] = Field(description=\"The publication year of the book\")\n\t    genre: Optional[str] = Field(description=\"The genre of the book\")\n\t    characters: Optional[List[str]] = Field(description=\"A list of the main characters in the book\")\n\t    summary: Optional[str] = Field(min_length=10, description=\"A brief summary of the book's plot\")\n\t# Input unstructured text\n\tunstructured_text = \"\"\"\n", "Pride and Prejudice is a novel by Jane Austen, published in 1813.\n\tThis classic novel follows the story of Elizabeth Bennet, the protagonist, as she navigates issues of manners, morality, education, and marriage in the society of the landed gentry of early 19th-century England.\n\tThe story revolves primarily around Elizabeth and her relationship with the haughty yet enigmatic Mr. Darcy.\n\tThe book is set in rural England, and it is notable for its wit and humor as well as its commentary on class distinctions, social norms, and values.\n\tSome of the main characters in the novel include Elizabeth Bennet, Mr. Darcy, Jane Bennet, Mr. Bingley, Lydia Bennet, and Mr. Wickham.\n\tPride and Prejudice is considered a classic work of English literature and has been adapted numerous times for television, film, and stage.\n\tIt is often categorized as a romantic novel, but it also has elements of satire and social commentary.\n\t\"\"\"\n\tt0 = time()\n\tmodel3 = jb.extract_typed_completion(unstructured_text, BookInformation, temperature=0, model='gpt-3.5-turbo')\n", "gpt3_times += time() - t0\n\tprint(model3)\n\tt0 = time()\n\tmodel4 = jb.extract_typed_completion(unstructured_text, BookInformation, temperature=0, model='gpt-4')\n\tgpt4_times += time() - t0\n\tprint(model4)\n\tcount += 1\n\tclass DocumentMetadata(BaseModel):\n\t    title      : Optional[str] = Field(description='The title of the content')\n\t    author     : Optional[str] = Field(description='The author of the content')\n", "    created_at : Optional[str] = Field(description='The date in the format YYYY-MM-DD that the content was created if it appears in the content')\n\t    language   : str           = Field(description='The 2 character ISO 639-1 language code of the primary language of the content')\n\tunstructured_text = \"\"\"Updated 24th March 2023\n\tGenerative AI - Chapter 1: Establishing the Investment Framework\n\tBlackLake Equity Research\n\tThe advent of cloud computing paved the way for new investment opportunities by facilitating the provision of software as a service. Generative AI takes this a step further, offering additional tools to boost end-user productivity. While traditional AI has proven useful in predicting outcomes, Generative AI specializes in creating content such as text, video, images, or computer code - a feat previously unachievable. Large Language Models (LLMs) play a crucial role as enablers of GAI, displaying an unprecedented level of expertise and intelligence. AI holds the potential to give rise to new enterprises and furnish existing players with fresh growth opportunities by greatly enhancing end-user productivity.\"\"\"\n\tt0 = time()\n\tmodel3 = jb.extract_typed_completion(unstructured_text, DocumentMetadata, temperature=0, model='gpt-3.5-turbo')\n\tgpt3_times += time() - t0\n\tprint(model3)\n", "t0 = time()\n\tmodel4 = jb.extract_typed_completion(unstructured_text, DocumentMetadata, temperature=0, model='gpt-4')\n\tgpt4_times += time() - t0\n\tprint(model4)\n\tcount += 1\n\t# Define the pydantic models\n\tclass Course(BaseModel):\n\t    title: str = Field(description=\"The title of the course\")\n\t    instructor: str = Field(description=\"The name of the course's instructor\")\n\t    duration_hours: Optional[int] = Field(description=\"The duration of the course in hours\")\n", "class Curriculum(BaseModel):\n\t    curriculum_title: str = Field(description=\"The title of the curriculum\")\n\t    description: Optional[str] = Field(description=\"A brief description of the curriculum\")\n\t    courses: List[Course] = Field(description=\"A list of the courses included in the curriculum\")\n\t# Input unstructured text\n\tunstructured_text = \"\"\"\n\tThe Data Science Bootcamp is a comprehensive curriculum designed to provide students with the fundamental knowledge and practical skills required for a career in data science.\n\tThe bootcamp includes the following four courses:\n\t1. Introduction to Python: This course, taught by John Doe, covers the basics of the Python programming language and its applications in data science. It lasts for 20 hours.\n\t2. Data Wrangling and Visualization: Led by Jane Smith, this course teaches students how to clean, manipulate, and visualize data using popular Python libraries like pandas and Matplotlib. The course duration is 30 hours.\n", "3. Machine Learning Foundations: In this 40-hour course, instructor Michael Brown introduces the core concepts and algorithms of machine learning, including supervised and unsupervised learning techniques.\n\t4. Advanced Topics in Data Science: Taught by Sarah Johnson and lasting 35 hours, this course explores advanced data science techniques such as deep learning, natural language processing, and time series analysis.\n\t\"\"\"\n\tt0 = time()\n\tmodel3 = jb.extract_typed_completion(unstructured_text, Curriculum, temperature=0, model='gpt-3.5-turbo')\n\tgpt3_times += time() - t0\n\tprint(model3)\n\tt0 = time()\n\tmodel4 = jb.extract_typed_completion(unstructured_text, Curriculum, temperature=0, model='gpt-4')\n\tgpt4_times += time() - t0\n", "print(model4)\n\tcount += 1\n\t# Define the pydantic model\n\tclass Event(BaseModel):\n\t    event_name: str = Field(description=\"The name of the event\")\n\t    start_date: date = Field(description=\"The start date of the event\")\n\t    end_date: date = Field(description=\"The end date of the event\")\n\t    @validator('end_date')\n\t    def start_date_must_be_prior_to_end_date(cls, end_date, values):\n\t        start_date = values.get('start_date')\n", "        if start_date and end_date <= start_date:\n\t            raise ValidationError(f\"End date ({end_date}) must be after start date ({start_date})\")\n\t        return end_date\n\tclass EventList(BaseModel):\n\t    events: List[Event] = Field(description=\"A list of events\")\n\t# Input unstructured text\n\tunstructured_text = \"\"\"\n\tCalendar Update\n\tTuesday, April 27, 2023\n\tWe have a series of exciting events happening over the next few weeks!\n", "1. Next Monday, the Annual AI Conference will kick off, ending on Wednesday. The event will focus on the latest advancements in artificial intelligence and machine learning, with discussions led by industry experts.\n\t2. In two weeks, the three-day Startup Showcase will take place, where new tech startups will demonstrate their innovative products and services. The event aims to foster collaboration and investment opportunities.\n\t3. The following week, we are hosting a Blockchain Summit, running from Tuesday to Thursday. The summit will explore the potential applications of blockchain technology across various industries, featuring engaging panel discussions and presentations.\n\t4. Finally, at the end of the month, a four-day Virtual Reality Festival will commence. This event celebrates the rapid progress of virtual and augmented reality technologies, with immersive exhibits and experiences available for all attendees.\n\tMake sure to mark your calendars for these thrilling events and seize the opportunity to learn more about the ever-evolving world of technology!\n\t\"\"\"\n\tt0 = time()\n\tmodel3 = jb.extract_typed_completion(unstructured_text, EventList, temperature=0, model='gpt-3.5-turbo')\n\tgpt3_times += time() - t0\n\tprint(model3)\n", "t0 = time()\n\tmodel4 = jb.extract_typed_completion(unstructured_text, EventList, temperature=0, model='gpt-4')\n\tgpt4_times += time() - t0\n\tprint(model4)\n\tcount += 1\n\t# Define the pydantic model\n\tclass MovieInformation(BaseModel):\n\t    title: str = Field(description=\"The title of the movie\")\n\t    director: str = Field(description=\"The name of the movie's director\")\n\t    release_year: Optional[int] = Field(description=\"The release year of the movie\")\n", "    cast: Optional[List[str]] = Field(description=\"A list of the main actors in the movie\")\n\t    genre: Optional[List[str]] = Field(description=\"The genres of the movie\")\n\t    duration_minutes: Optional[int] = Field(description=\"The duration of the movie in minutes\")\n\t    plot: Optional[str] = Field(min_length=10, description=\"A brief summary of the movie's plot\")\n\t    awards: Optional[List[str]] = Field(description=\"A list of the awards won by the movie\")\n\t# Input unstructured text\n\tunstructured_text = \"\"\"\n\tThe Godfather is a 1972 American crime film directed by Francis Ford Coppola, who co-wrote the screenplay with Mario Puzo, based on Puzo's best-selling 1969 novel of the same name.\n\tThe film stars Marlon Brando, Al Pacino, and James Caan, and tells the story of the powerful Italian-American crime family of Don Vito Corleone (played by Brando).\n\tWhen an organized crime dynasty's aging patriarch transfers control of his clandestine empire to his reluctant son, Michael Corleone (played by Pacino), a series of events unfold that threatens the stability of the family and the entire criminal underworld.\n", "Set in New York City and spanning the years 1945 to 1955, The Godfather is notable for its realistic depiction of the Mafia and its exploration of themes such as power, loyalty, betrayal, and family dynamics.\n\tThe film was met with widespread critical acclaim upon release and is commonly regarded as one of the greatest films in world cinema.\n\tIt won three Academy Awards, including Best Picture, Best Actor (Marlon Brando), and Best Adapted Screenplay, and has been selected for preservation in the United States National Film Registry.\n\tThe Godfather is a crime drama film and is widely regarded as one of the most influential films in the gangster genre.\n\tIts running time is approximately 175 minutes.\n\t\"\"\"\n\tt0 = time()\n\tmodel3 = jb.extract_typed_completion(unstructured_text, MovieInformation, temperature=0, model='gpt-3.5-turbo')\n\tgpt3_times += time() - t0\n\tprint(model3)\n", "t0 = time()\n\tmodel4 = jb.extract_typed_completion(unstructured_text, MovieInformation, temperature=0, model='gpt-4')\n\tgpt4_times += time() - t0\n\tprint(model4)\n\tcount += 1\n\t# The data class we wish to extract from the unstructured text\n\tclass UserDetails(BaseModel):\n\t    name: str = Field(description=\"The name of the user\")\n\t    age: Optional[int] = Field(description=\"The age of the user\")\n\t    email: Optional[str] = Field(description=\"The email address of the user\")\n", "    country: str = Field(description=\"The country the user resides in\")\n\t# Example unstructured text from which to extract the UserDetails\n\tunstructured_text = \"\"\"\n\tJohn Doe, a software engineer from San Francisco, California, started his career in the tech industry in the United States in 2010.\n\tHe initially worked for a small startup before joining a larger multinational company in 2014.\n\tJohn, currently 30 years old, is passionate about programming and solving complex problems.\n\tHe has attended multiple conferences across the world and has collaborated with colleagues from various countries on numerous projects.\n\tDespite his busy work life, John finds time for his hobbies, such as photography and hiking.\n\tHe enjoys traveling to different countries, and one of his favorite trips was to Japan in 2019.\n\tDo you need to get in touch with John? Feel free to reach out to him at john.doe@example.com.\n", "\"\"\"\n\tt0 = time()\n\tmodel3 = jb.extract_typed_completion(unstructured_text, UserDetails, temperature=0, model='gpt-3.5-turbo')\n\tgpt3_times += time() - t0\n\tprint(model3)\n\tt0 = time()\n\tmodel4 = jb.extract_typed_completion(unstructured_text, UserDetails, temperature=0, model='gpt-4')\n\tgpt4_times += time() - t0\n\tprint(model4)    \n\tcount += 1\n", "print(f\"GPT-3.5 Turbo: {gpt3_times/count} s\")\n\tprint(f\"GPT-4:         {gpt4_times/count} s\")"]}
{"filename": "test/test.py", "chunked_list": ["import jiggybase\n\tfrom jiggybase.models import (\n\t    ApiKey,\n\t    ChatModelName,\n\t    ChunkConfig,\n\t    Collection,\n\t    CollectionPatchRequest,\n\t    CollectionPostRequest,\n\t    EmbeddingConfig,\n\t    EmbeddingModelName,\n", "    ExtractMetadataConfig,\n\t    Org,\n\t    OrgMember,\n\t    OrgMemberPostRequest,\n\t    OrgPatchRequest,\n\t    OrgPostRequest,\n\t    OrgRole,\n\t    PatchPluginOAuthConfigRequest,\n\t    PluginAuthConfigOAuth,\n\t    PluginAuthType,\n", "    PluginBearerTokenConfig,\n\t    PluginConfig,\n\t    User,\n\t    UserPostPatchRequest,\n\t    UserPostRequest,\n\t    PromptTask\n\t)\n\tif __name__ == \"__main__\":\n\t    jb = jiggybase.JiggyBase()\n\t    orgs = jb.orgs()\n", "    for org in orgs:\n\t        print(f'Org: {org}')\n\t        print(org.prompt_tasks())\n\t        for c in org.collections():\n\t            print(f'   Collection: {c}')    \n\t    collections = jb.collections()"]}
{"filename": "jiggybase/ijiggy.py", "chunked_list": ["#!/usr/bin/env python3\n\timport jiggybase\n\ttry:\n\t    import IPython\n\texcept:\n\t    raise Exception(\"'pip install IPython' run this command first\")\n\tdef main():\n\t    print(\"\\nStarting JiggyBase IPython environment\\n\")\n\t    jb = jiggybase.JiggyBase()\n\t    orgs = jb.orgs()\n", "    collections = jb.collections()\n\t    print(f\"'jb'          set to jiggybase.JiggyBase() instance\")\n\t    print(f\"'orgs'        set to list of your orgs\")\n\t    print(f\"'collections' set to list of your collections\")    \n\t    print()    \n\t    IPython.start_ipython(argv=[], user_ns={\"jb\": jb, \"orgs\": orgs, \"collections\": collections})\n\tif __name__ == '__main__':\n\t    main()\n"]}
{"filename": "jiggybase/collection.py", "chunked_list": ["import os\n\tfrom typing import Optional, List, Iterator, Tuple\n\tfrom pydantic import BaseModel, Field, BaseConfig, HttpUrl\n\tfrom enum import Enum\n\tfrom .models import collection, CollectionChatConfig, PatchCollectionChatConfig\n\tfrom .jiggybase_session import JiggyBaseSession\n\tfrom .models import UpsertResponse,  Query, QueryRequest, QueryResponse, UpsertRequest, Document, DocumentChunk, DeleteRequest, DeleteResponse, DocumentMetadataFilter, DocChunksResponse\n\tfrom .models import Message, CompletionRequest, ChatCompletion \n\tfrom .chat_stream import extract_content_from_sse_bytes\n\tfrom .models import ExtractMetadataConfig\n", "from .models import CollectionPatchRequest, PluginAuthConfigOAuth, PatchPluginOAuthConfigRequest\n\tfrom .models import DocumentMetadata\n\tfrom typing import Union, List\n\tclass Collection(collection.Collection):\n\t    \"\"\"\n\t    derived from models.collection.Collection data model for purposes of adding management methods\n\t    \"\"\"\n\t    class Config(BaseConfig):\n\t        extra = \"allow\"\n\t    def __init__(self, session, *args, **kwargs):\n", "        super().__init__(*args, **kwargs)\n\t        self.session = session        \n\t        api_key = self.session.api_key\n\t        self.plugin_session = JiggyBaseSession(host=f'https://{kwargs[\"fqdn\"]}', api='', api_key=api_key)\n\t        self.chat_session = JiggyBaseSession(host=session.host, api='v1', api_key=api_key)\n\t    def set_description(self, description:str) -> \"Collection\":\n\t        \"\"\"\n\t        Update an existing collection using its ID and the provided description.\n\t        \"\"\"\n\t        patch_request = CollectionPatchRequest(description=description)\n", "        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}\", model=patch_request)\n\t        self.description = rsp.json()['description']\n\t    def set_oauth_verification_token(self, openai_verification_token: str) -> PluginAuthConfigOAuth:\n\t        \"\"\"\n\t        Set the OpenAI verification token for this collection's plugin.\n\t        This is the token that OpenAI provides during while registering a plugin configured to use Oauth.\n\t        \"\"\"\n\t        patch_request = PatchPluginOAuthConfigRequest(openai_verification_token=openai_verification_token)\n\t        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/plugin_oauth\", model=patch_request)\n\t        return PluginAuthConfigOAuth(**rsp.json())\n", "    def plugin_oauth_config(self) -> PluginAuthConfigOAuth:\n\t        \"\"\"\n\t        Get the OAuth configuration for this collection's plugin.\n\t        The client_id and client_secret returned here are configured with OpenAI while \n\t        registering a plugin configured to use Oauth.\n\t        \"\"\"\n\t        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/plugin_oauth\")\n\t        return PluginAuthConfigOAuth(**rsp.json())\n\t    def delete(self):\n\t        \"\"\"\n", "        Delete a collection.  Warning: this is permanent.\n\t        \"\"\"\n\t        self.session.delete(f\"/orgs/{self.org_id}/collections/{self.id}\")\n\t    def get_chat_config(self) -> CollectionChatConfig:\n\t        \"\"\"\n\t        Get the chat configuration for this collection.\n\t        \"\"\"\n\t        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/chat_config\")\n\t        return collection.CollectionChatConfig(**rsp.json())\n\t    def update_chat_config(self, model: str, prompt_task_id: int) -> CollectionChatConfig:\n", "        \"\"\"\n\t        Update the chat configuration for this collection.\n\t        \"\"\"\n\t        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/chat_config/{model}\", model=PatchCollectionChatConfig(prompt_task_id=prompt_task_id))\n\t        return CollectionChatConfig(**rsp.json())\n\t    def upsert_file(self, file_path: str, mimetype: str = None, id: str = None, metadata : DocumentMetadata = None) -> UpsertResponse:\n\t        \"\"\"\n\t        Add a file to the collection.\n\t        Mimetype can be specified, otherwise it will be inferred from the file extension.\n\t        The doc id can be specified, otherwise it will be generated.\n", "        Metadata can be specified, otherwise some metadata will be inferred from the file.\n\t        \"\"\"\n\t        if not os.path.exists(file_path):\n\t            raise ValueError(\"File not found\")\n\t        with open(file_path, \"rb\") as file:\n\t            files = {\"file\": (os.path.basename(file_path), file, mimetype)}\n\t            params = {'id': id} if id else {}\n\t            if metadata:\n\t                rsp = self.plugin_session.post(\"/upsert-file\", \n\t                                               files=files, \n", "                                               params=params,\n\t                                               data={'metadata': metadata.json(exclude_unset=True)})\n\t            else:\n\t                rsp = self.plugin_session.post(\"/upsert-file\", params=params, files=files)\n\t        return UpsertResponse.parse_obj(rsp.json())\n\t    def upsert(self, documents: List[Document]) -> UpsertResponse:\n\t        \"\"\"\n\t        Add a list of Document objects to the collection.\n\t        \"\"\"\n\t        upsert_request = UpsertRequest(documents=documents)\n", "        rsp = self.plugin_session.post(\"/upsert\", model=upsert_request)\n\t        return  UpsertResponse.parse_obj(rsp.json())\n\t    def query(self, queries: Union[str, List[str], Query], top_k : int = 10) -> QueryResponse:\n\t        \"\"\"\n\t        Query the collection returning the top_k results for each query.\n\t        queries can be either a single string, a list of strings, or a list of Query objects.\n\t        if it is a string or list of strings, the specified top_k will be used for each of the queries.\n\t        Returns a QueryResponse object.\n\t        \"\"\"\n\t        if isinstance(queries, str):\n", "            queries = [Query(query=queries, top_k=top_k)]\n\t        elif isinstance(queries, Query):\n\t            queries = [Query(query=q, top_k=top_k) for q in queries]\n\t        qr = QueryRequest(queries=queries)\n\t        rsp = self.plugin_session.post(\"/query\", model=qr)\n\t        return  QueryResponse.parse_obj(rsp.json())\n\t    def get_doc(self, id: str) -> list[DocumentChunk]:\n\t        \"\"\"\n\t        Get a document by id\n\t        \"\"\"\n", "        rsp = self.plugin_session.get(f\"/docs/{id}\")\n\t        return [DocumentChunk.parse_obj(c) for c in rsp.json()]\n\t    def get_chunks(self, \n\t                   start: int = 0, \n\t                   limit: int = 10, \n\t                   reverse: bool = True) -> List[DocumentChunk]:\n\t        \"\"\"\n\t        low level interface for iterating through the chunks in a collection\n\t        start - Offset of the first result to return\n\t        limit - Number of results to return starting from the offset\n", "        reverse - Reverse the order of the items returned\n\t        \"\"\"\n\t        params = {\"start\": start, \"limit\": limit, \"reverse\": reverse}\n\t        rsp = self.plugin_session.get(\"/chunks\", params=params)\n\t        return [DocumentChunk.parse_obj(chunk) for chunk in rsp.json()]\n\t    def get_doc_chunks(self, \n\t                       index: int = -1, \n\t                       limit: int = 10, \n\t                       reverse: bool = True,\n\t                       max_chunks_per_doc = 1) -> Tuple[List[List[DocumentChunk]], int]:\n", "         \"\"\"\n\t         low level interface for iterating through the initial chunks for all docs in a collection\n\t         index - index of the first result to return, should be -1 to start at the end\n\t         limit - Number of results to return starting from the offset\n\t         reverse - Reverse the order of the items returned; True to return newest first\n\t         max_chunks_per_doc - maximum number of chunks to return for each document\n\t         \"\"\"\n\t         params = {\"index\": index, \"limit\": limit, \"reverse\": reverse, \"max_chunks_per_doc\": max_chunks_per_doc}\n\t         rsp = self.plugin_session.get(\"/doc_chunks\", params=params)\n\t         dcr_rsp = DocChunksResponse.parse_obj(rsp.json())\n", "         return dcr_rsp.docs, dcr_rsp.next_index\n\t    def delete_docs(self, \n\t                    ids                      : Optional[List[str]] = None, \n\t                    document_metadata_filter : Optional[DocumentMetadataFilter] = None, \n\t                    delete_all               : Optional[bool] = False) -> DeleteResponse:\n\t        \"\"\"\n\t        Delete items in the collection by document id's or document metadata filter.\n\t        A delete_all option is also provided to delete all documents in the collection.\n\t        \"\"\"\n\t        delete_request = DeleteRequest(ids=ids, filter=document_metadata_filter, delete_all=delete_all)\n", "        rsp = self.plugin_session.delete(\"/delete\", model=delete_request)\n\t        return DeleteResponse.parse_obj(rsp.json())\n\t    def _chat_completion(self, \n\t                         messages: List[Message],\n\t                         model = 'gpt-3.5-turbo',\n\t                         max_tokens = None,\n\t                         temperature = .1) -> ChatCompletion:\n\t        \"\"\"\n\t        low level interface for chat completion\n\t        The input here mirrors openai chat completion parameters, while the output is different\n", "        \"\"\"\n\t        cr = CompletionRequest(model       = f'{self.name}_{model}', \n\t                               messages    = messages,\n\t                               max_tokens  = max_tokens,\n\t                               temperature = temperature,\n\t                               stream      = False)\n\t        rsp = self.chat_session.post(\"/chat/completions\", model=cr)          \n\t        return ChatCompletion.parse_obj(rsp.json())\n\t    def _chat_completion_stream_str(self, \n\t                         messages: List[Message],\n", "                         model = 'gpt-3.5-turbo',\n\t                         max_tokens = None,\n\t                         temperature = .1) -> Iterator[str]:\n\t        \"\"\"\n\t        low level interface for chat completion with streaming\n\t        yields the model output as an iteration of strings\n\t        \"\"\"\n\t        cr = CompletionRequest(model       = f'{self.name}_{model}', \n\t                               messages    = messages,\n\t                               max_tokens  = max_tokens,\n", "                               temperature = temperature,\n\t                               stream      = True)\n\t        rsp = self.chat_session.post(\"/chat/completions\", model=cr, stream=True)\n\t        for line in rsp.iter_lines():\n\t            if line:  # filter out keep-alive newlines        \n\t                yield extract_content_from_sse_bytes(line)\n\t    def get_extract_metadata_config(self):\n\t        \"\"\"\n\t        Get the metadata configuration for this collection.\n\t        \"\"\"\n", "        rsp = self.session.get(f\"/orgs/{self.org_id}/collections/{self.id}/extract_metadata_config\")\n\t        return ExtractMetadataConfig(**rsp.json())\n\t    def patch_extract_metadata_config(self, config: ExtractMetadataConfig):\n\t        \"\"\"\n\t        Get the metadata configuration for this collection.\n\t        \"\"\"\n\t        rsp = self.session.patch(f\"/orgs/{self.org_id}/collections/{self.id}/extract_metadata_config\", model=config)\n\t        return ExtractMetadataConfig(**rsp.json())    \n\t    def __str__(self) -> str:\n\t        return f\"Collection(id={self.id:4}, name={self.display_name:30}, hostname={self.hostname:30}, org_id={self.org_id:4},\\n\" \\\n", "               f\"           description='{self.description}')\"\n\t    def __repr__(self) -> str:\n\t        return str(self)    "]}
{"filename": "jiggybase/chat_stream.py", "chunked_list": ["from loguru import logger\n\timport json\n\tdef extract_content_from_sse_bytes(sse_bytes: bytes) -> str:\n\t    \"\"\"\n\t    Extracts the \"content\" value from the raw SSE byte string. This is the incremental model output text.\n\t    \"\"\"\n\t    sse_str = sse_bytes.decode('utf-8')\n\t    lines = sse_str.strip().split('\\n\\n')\n\t    results = \"\"\n\t    for line in lines:        \n", "        if line.startswith(\"data:\"):\n\t            event_str = line.split(\":\", 1)[1].strip()\n\t            if '[DONE]' in event_str:\n\t                continue\n\t            try:\n\t                event_data = json.loads(event_str)\n\t                content = event_data.get(\"choices\", [])[0].get(\"delta\", {}).get(\"content\", \"\")\n\t                results += content\n\t            except (json.JSONDecodeError, IndexError, KeyError, TypeError) as e:\n\t                logger.error(f\"Failed to parse SSE event data for line: '{line}'\")\n", "                logger.error(f\"Failed to parse SSE event data with err: {e}\")\n\t                continue\n\t    return results"]}
{"filename": "jiggybase/org.py", "chunked_list": ["from typing import Any, Optional, List\n\tfrom pydantic import BaseConfig, EmailStr\n\timport enum\n\tfrom .models import  CollectionPostRequest\n\tfrom .models.org import Org as OrgModel\n\tfrom .models.org import OrgRole, OrgMember, OrgPatchRequest\n\tfrom .models import PromptTask, PromptMessage, PromptTaskPostRequest, PromptTaskType\n\tfrom .collection import Collection\n\t###\n\t## Org\n", "###\n\tclass Org(OrgModel):\n\t    class Config(BaseConfig):\n\t        extra = \"allow\"\n\t    def __init__(self, session, *args, **kwargs):\n\t        super().__init__(*args, **kwargs)\n\t        self.session = session\n\t    def create_collection(self, \n\t                          display_name: str,\n\t                          description: Optional[str] = None) -> Collection:\n", "        rsp = self.session.post(f\"/orgs/{self.id}/collections\", model=CollectionPostRequest(**locals()))\n\t        print(rsp.json())\n\t        return Collection(self.session, **rsp.json())\n\t    def collections(self) -> list[Collection]:\n\t        rsp = self.session.get(f\"/orgs/{self.id}/collections\")\n\t        return [Collection(self.session, **c) for c in rsp.json()]\n\t    def collection(self, name: str) -> Collection:\n\t        collections = [c for c in self.collections() if c.name == name or c.display_name.lower() == name.lower()]\n\t        if not collections:\n\t            raise ValueError(f\"Collection {name} not found\")\n", "        return collections[0]\n\t    def members(self) -> List[OrgMember]:\n\t        return [OrgMember(**tm) for tm in self.session.get(f'/orgs/{self.id}/members').json()]\n\t    def add_member(self, email : EmailStr, role : OrgRole) -> OrgMember:\n\t        \"\"\"\n\t        Invite the specified email to this org with the corresponding OrgRole.\n\t        If the email does not have an account, the system will send an invite to this email.\n\t        \"\"\"\n\t        rsp = self.session.post(f\"/orgs/{self.id}/members\", json={\"email\": email, 'role':role})\n\t        return OrgMember(**rsp.json())\n", "    def delete_member(self, email : str):\n\t        \"\"\"\n\t        attempt to remove the specified name from this org\n\t        \"\"\"\n\t        member = [m for m in self.members() if m.email == email]\n\t        if not member:\n\t            raise Exception(f\"{email} not found in Org\")\n\t        self.session.delete(f\"/orgs/{self.id}/members/{member[0].id}\")\n\t    def update(self, name: Optional[str] = None, description: Optional[str] = None) -> 'Org':\n\t        \"\"\"\n", "        update the org name or description\n\t        \"\"\"\n\t        patch_request = OrgPatchRequest(name=name, description=description)\n\t        rsp = self.session.patch(f\"/orgs/{self.id}\", model=patch_request)\n\t        updated_org_data = rsp.json()\n\t        self.name = updated_org_data.get(\"name\", self.name)\n\t        self.description = updated_org_data.get(\"description\", self.description)\n\t        return self\n\t    def prompt_tasks(self, name=None, version=None) -> list[PromptTask]:\n\t        query = ''\n", "        if name:\n\t            query += f\"?name={name}\"\n\t            if version:\n\t                query += f\"&version={version}\"\n\t        return [PromptTask(**pt) for pt in self.session.get(f\"/orgs/{self.id}/prompt_tasks{query}\").json()]\n\t    def create_prompt_task(self, \n\t                           name       : str, \n\t                           version    : int, \n\t                           prompts    : List[PromptMessage],\n\t                           type       : Optional[PromptTaskType] = None, \n", "                           description: Optional[str] = None, \n\t                           ) -> PromptTask:\n\t        rsp = self.session.post(f\"/orgs/{self.id}/prompt_tasks\", model=PromptTaskPostRequest(**locals()))\n\t        return PromptTask(**rsp.json())\n\t    def update_prompt_task(self,\n\t                           name       : str,\n\t                           prompts    : List[PromptMessage]) -> PromptTask:\n\t        pt = self.prompt_tasks(name=name)\n\t        if not pt:\n\t            raise ValueError(f\"PromptTask {name} not found\")\n", "        pt = pt[0]\n\t        self.create_prompt_task(name        = name, \n\t                                version     = pt.version+1, \n\t                                type        = pt.type, \n\t                                description = pt.description, \n\t                                prompts     = prompts)\n\t    def get_prompt_task(self, prompt_task_id: int) -> PromptTask:\n\t        return PromptTask(**self.session.get(f\"/orgs/{self.id}/prompt_tasks/{prompt_task_id}\").json())\n\t    def delete_prompt_task(self, prompt_task_id: int):\n\t        self.session.delete(f\"/orgs/{self.id}/prompt_tasks/{prompt_task_id}\")\n", "    def __str__(self) -> str:\n\t        return f\"Org(id={self.id:4}, status={self.subscription_status:8}, gpt4_credts={self.gpt4_credits:4}, name={self.name:20}, description={self.description})\"\n\t    def __repr__(self) -> str:\n\t        return str(self)"]}
{"filename": "jiggybase/client.py", "chunked_list": ["from typing import List\n\tfrom .org import Org\n\tfrom .collection import Collection\n\tfrom .models.user import User, ApiKey\n\tfrom .jiggybase_session import JiggyBaseSession\n\tfrom .models.chat import Message, TypedCompletionRequest\n\tfrom pydantic import BaseModel    \n\tclass JiggyBase():\n\t    def __init__(self, api_key=None):\n\t        self.session = JiggyBaseSession(api_key=api_key)     \n", "    def orgs(self) -> List[Org]:\n\t        \"\"\"\n\t        return all Orgs that the user is a member of\n\t        \"\"\"\n\t        resp = self.session.get('/orgs')\n\t        return [Org(self.session, **i) for i in resp.json()]\n\t    def get_org(self, name_or_id) -> Org:\n\t        \"\"\"\n\t        get org by name or id\n\t        raises Exception if an exact match for name is not found\n", "        \"\"\"\n\t        orgs = [t for t in self.session.get('/orgs').json() if t['name'] == name_or_id or t['id'] == name_or_id]\n\t        if len(orgs):\n\t            return Org(self.session, **orgs[0])\n\t        raise Exception(f'Org \"{name_or_id}\" not found')\n\t    def api_keys(self) -> List[ApiKey]:\n\t        \"\"\"\n\t        return user's api keys\n\t        \"\"\"\n\t        return [ApiKey(**i) for i in self.session.get('/apikey').json()]\n", "    def authenticated_user(self) -> User:\n\t        \"\"\"\n\t        return the authenticated user's User object\n\t        \"\"\"\n\t        return User(**self.session.get(\"/users/current\").json())\n\t    def create_org(self, name : str) -> Org:\n\t        \"\"\"\n\t        create an Org\n\t        \"\"\"\n\t        resp = self.session.post(\"/orgs\", json={\"name\":name})\n", "        return Org(self.session, **resp.json())\n\t    def collections(self) -> List[Collection]:\n\t        \"\"\"\n\t        return all Collections in all Orgs that the user is a member of\n\t        \"\"\"\n\t        resp = self.session.get(\"/collections\")\n\t        return [Collection(self.session, **c) for c in resp.json()]\n\t    def collection_names(self) -> List[Collection]:\n\t        \"\"\"\n\t        return the collection display names for all collections in all Orgs that the user is a member of\n", "        \"\"\"\n\t        return [c.disply_name for c in self.collections()]\n\t    def collection_hostnames(self) -> List[Collection]:\n\t        \"\"\"\n\t        return the unique collection hostname for all collections in all Orgs that the user is a member of\n\t        \"\"\"\n\t        return [c.hostname for c in self.collections()]\n\t    def collection(self, name : str) -> Collection:        \n\t        \"\"\"\n\t        return a collection of the specified display name or hostname\n", "        \"\"\"\n\t        for collection in self.collections():\n\t            if collection.hostname == name or collection.display_name.lower() == name.lower():\n\t                return collection\n\t        raise ValueError(f'Collection \"{name}\" not found')\n\t    def _extract_typed_completion(self,\n\t                                 messages       : List[Message],\n\t                                 pydantic_model : BaseModel,\n\t                                 temperature    : float = 0,\n\t                                 model          : str   = 'gpt-3.5-turbo') -> BaseModel:\n", "        \"\"\"\n\t        lower-level interface to the extract_typed_completion endpoint\n\t        \"\"\"\n\t        tcr = TypedCompletionRequest(model       = model, \n\t                                     messages    = messages,\n\t                                     json_schema = pydantic_model.schema_json(),\n\t                                     temperature = temperature,\n\t                                     stream      = False)\n\t        rsp = self.session.post(\"/extract/typed_completions\", model=tcr)\n\t        return pydantic_model.parse_obj(rsp.json())\n", "    def  extract_typed_completion(self,\n\t                                  content       : str,\n\t                                  pydantic_model : BaseModel, \n\t                                  temperature    : float = 0,\n\t                                  model          : str   = 'gpt-3.5-turbo') -> BaseModel:\n\t        \"\"\"\n\t        Higher-level interface to structured extraction from unstructured content.\n\t        Just provide the unstructured text and the pydantic model to extract.\n\t        \"\"\"\n\t        # Set up messages\n", "        messages = [{\"role\": \"user\", \"content\": f\"Extract the {pydantic_model.__name__} information from the following content:\"},\n\t                    {\"role\": \"user\", \"content\": content}]\n\t        return self._extract_typed_completion(messages, pydantic_model, temperature, model)\n"]}
{"filename": "jiggybase/jiggybase_session.py", "chunked_list": ["# Jiggy Client\n\timport os\n\tfrom requests.auth import HTTPBasicAuth\n\tfrom requests.packages.urllib3 import Retry\n\tfrom requests.adapters import HTTPAdapter\n\timport requests\n\tfrom time import sleep\n\tfrom .login import window_open\n\tJIGGYBASE_HOST     = os.environ.get('JIGGYBASE_HOST', 'https://api.gpt-gateway.com')   # transition to jiggy.ai in progress\n\tJB_KEY_FILE = os.path.expanduser('~') + '/.jiggybase'   # local file to store user entered apikey \n", "\"\"\"\n\tRetry the following status codes:\n\t500 Internal Server Error: The server encountered an error while processing the request.\n\t502 Bad Gateway: The server, while acting as a gateway, received an invalid response from the upstream server.\n\t503 Service Unavailable: The server is currently unable to handle the request due to maintenance or overload.\n\t504 Gateway Timeout: The server, while acting as a gateway, did not receive a timely response from the upstream server.\n\t\"\"\"\n\tRETRY_STATUS_CODES = [500, 502, 503, 504]\n\tclass ClientError(Exception):\n\t    \"\"\"\n", "    API returned 4xx client error\n\t    \"\"\"\n\tclass ServerError(Exception):\n\t    \"\"\"\n\t    API returned 5xx Server error\n\t    \"\"\"\n\tclass JiggyBaseSession(requests.Session):\n\t    def __init__(self, host=JIGGYBASE_HOST, api='gpt-gateway-v1', bearer_token=None, api_key=None, *args, **kwargs):\n\t        \"\"\"\n\t        Extend requests.Session with common GPTG authentication, retry, and exceptions.\n", "        host: The url host prefix of the form \"https:/api.gpt-gateway.com\"\n\t              if host arg is not set, will use \n\t                    JIGGYBASE_HOST environment variable or \"api.gpt-gateway.com\" as final default.\n\t        api:  The api & version to use. defaults to 'gpt-gateway-v1'\n\t        bearer_token:  usually None, but can be specified if this is used by an endpoint has already has one handy\n\t        final url prefix are of the form \"https://{host}/{api}\"\n\t        \"\"\"\n\t        super(JiggyBaseSession, self).__init__(*args, **kwargs)\n\t        if not host.startswith('http'):\n\t            host = f\"https://{host}\" if not host.startswith('localhost') else f'http://{host}'\n", "        self.host = host\n\t        if api:\n\t            self.prefix_url = f\"{host}/{api}\"\n\t        else:\n\t            self.prefix_url = host          \n\t        self.bearer_token = None            \n\t        self.api_key = None\n\t        if api_key:\n\t            self.api_key = api_key\n\t            self._getjwt(api_key)\n", "        elif bearer_token:\n\t            self._set_bearer(bearer_token)\n\t        super(JiggyBaseSession, self).mount('https://',\n\t                                            HTTPAdapter(max_retries=Retry(connect=5,\n\t                                                                          read=5,\n\t                                                                          status=5,\n\t                                                                          redirect=2,\n\t                                                                          backoff_factor=.001,\n\t                                                                          status_forcelist=None)))\n\t    def _set_bearer(self, jwt):\n", "        self.bearer_token = jwt\n\t        self.headers['Authorization'] = f\"Bearer {jwt}\"\n\t    def _getjwt(self, key):        \n\t        resp = requests.post(f\"{JIGGYBASE_HOST}/gpt-gateway-v1/auth\", json={'key': key})\n\t        if resp.status_code == 200:\n\t            self._set_bearer(resp.json()['jwt'])\n\t        elif resp.status_code == 401:\n\t            raise ClientError(\"Invalid API Key\")\n\t        else:\n\t            raise ServerError(resp.content)\n", "    def _auth(self):\n\t        if 'JIGGYBASE_API_KEY' in os.environ:\n\t            self._getjwt(os.environ['JIGGYBASE_API_KEY'])\n\t        elif os.path.exists(JB_KEY_FILE):\n\t            self._getjwt(open(JB_KEY_FILE).read())\n\t        else: ## check interactive?\n\t            while True:\n\t                window_open(\"https://jiggy.ai/authorize\")\n\t                key_input = input(\"Enter your JiggyBase API Key: \")\n\t                if key_input[:4] == \"jgy-\":\n", "                    # try using the key to see if it is valid\n\t                    try:\n\t                        self._getjwt(key_input)\n\t                        # key validated, save to key file\n\t                        open(JB_KEY_FILE, 'w').write(key_input)\n\t                        os.chmod(JB_KEY_FILE, 0o600)  # -rw-------\n\t                        break\n\t                    except:\n\t                        pass\n\t                print(\"Invalid API Key\")\n", "    def request(self, method, url, *args, **kwargs):\n\t        if not self.bearer_token:\n\t            self._auth()\n\t        url = self.prefix_url + url\n\t        # support 'model' (pydantic BaseModel) arg which we convert to json parameter\n\t        if 'model' in kwargs:\n\t            kwargs['data'] = kwargs.pop('model').json()\n\t        max_attempts = 7\n\t        backoff_factor = 0.5\n\t        for attempt in range(max_attempts):        \n", "            try:        \n\t                resp =  super(JiggyBaseSession, self).request(method, url, *args, **kwargs)\n\t            except Exception as e:\n\t                print(f\"Exception: {e}\")\n\t                if attempt == max_attempts - 1:\n\t                    raise\n\t                continue\n\t            if resp.status_code == 401:\n\t                self.bearer_token = None\n\t                del self.headers['Authorization']\n", "                self._auth()\n\t                if attempt == max_attempts - 1:\n\t                    print(\"Unable to authenticate\")\n\t                    raise ValueError(\"Unable to authenticate\")\n\t                continue\n\t            if resp.status_code not in RETRY_STATUS_CODES:\n\t                break\n\t            sleep_duration = backoff_factor * (2 ** attempt)\n\t            sleep(sleep_duration)\n\t        if resp.status_code >= 500:\n", "            raise ServerError(resp.content)\n\t        if resp.status_code >= 400:\n\t            raise ClientError(resp.content)\n\t        return resp\n"]}
{"filename": "jiggybase/__init__.py", "chunked_list": ["from .client import JiggyBase\n"]}
{"filename": "jiggybase/login.py", "chunked_list": ["import webbrowser\n\tdef is_notebook() -> bool:\n\t    \"\"\"\n\t    Returns True if code is executed in a notebook (Jupyter, Colab, QTconsole), False otherwise.\n\t    https://stackoverflow.com/a/39662359\n\t    \"\"\"\n\t    try:\n\t        shell_class = get_ipython().__class__\n\t        for parent_class in shell_class.__mro__:\n\t            if parent_class.__name__ == \"ZMQInteractiveShell\":\n", "                return True  # Jupyter notebook, Google colab or qtconsole\n\t        return False\n\t    except NameError:\n\t        return False  # Probably standard Python interpreter\n\tdef window_open(url):    \n\t    print(f\"You can find your API Key here: {url}\")\n\t    if not is_notebook():\n\t        print(\"(Attempting to open browser window...)\")            \n\t        webbrowser.open(url)\n\t    else:\n", "        pass\n\t        # The following code seems to work to open a web page from a notebook,\n\t        # but when successful it takes the user away to this page somewhat unexpectedly\n\t        # so we will instead rely on the user clicking the above url so they\n\t        # understand what is happening.\n\t        #from IPython.display import Javascript        \n\t        #display(Javascript('window.open(\"{url}\");'.format(url=url)))\n"]}
{"filename": "jiggybase/models/auth.py", "chunked_list": ["from pydantic import BaseModel, Field, HttpUrl\n\tfrom typing import List\n\tclass PluginAuthConfigOAuth(BaseModel):\n\t    \"\"\"\n\t    The Plugin Oauth configuration when plugin_auth == PluginAuthType.oauth\n\t    \"\"\"    \n\t    client_url:                 HttpUrl     = Field(description=\"ChatGPT will direct the user’s browser to this url to log in to the plugin\")\n\t    authorization_url:          HttpUrl     = Field(description=\"After successful login ChatGPT will complete the OAuth flow by making a POST request to this URL\")\n\t    scope:                      str         = Field(description=\"The scope used for the OAuth flow\")\n\t    client_id:                  str         = Field(unique=True, index=True, description=\"The client id to send to OpenAI for the plugin\")\n", "    client_secret:              str         = Field(description=\"The client secret to send to OpenAI for the plugin\")\n\t    openai_verification_token:  str         = Field(description=\"The verification token specified by OpenAI to configure in the plugin\")\n\tclass PluginBearerTokenConfig(BaseModel):\n\t    \"\"\"\n\t    A list of bearer tokens that are authorized to access the /plugin api when plugin_auth == PluginAuthType.bearer\n\t    \"\"\"\n\t    authorized_tokens : List[str]  =  []    "]}
{"filename": "jiggybase/models/collection.py", "chunked_list": ["from typing import Optional\n\tfrom pydantic import BaseModel, Field\n\tclass CollectionPostRequest(BaseModel):\n\t    \"\"\"\n\t    Used to create a new Collection service\n\t    \"\"\"\n\t    display_name: str                      = Field(description=\"The human friendly display name for the collection.\")\n\t    description:  Optional[str]            = Field(description=\"A description of the collection.\")\n\tclass CollectionPatchRequest(BaseModel):\n\t    \"\"\"\n", "    Used to modify an existing service\n\t    \"\"\"\n\t    description:  Optional[str] = Field(description=\"A description of the collection.\")\n\t    display_name: Optional[str] = Field(description=\"The human friendly display name for the collection.\")\n\tclass Collection(BaseModel):\n\t    \"\"\"\n\t    A managed collection of searchable documents exposed via as a ChatGPT plugin and a REST API.\n\t    \"\"\"\n\t    id:           int           = Field(description=\"The unique ID of the service\")\n\t    display_name: str           = Field(description=\"The human friendly display name for the collection.\")    \n", "    description:  Optional[str] = Field(description=\"A description of the collection.\")\n\t    hostname:     str           = Field(description=\"The unique hostname for the collection service. The hostname part of the fqdn\")\n\t    fqdn:         str           = Field(description=\"The FQDN for the collection service\")\n\t    org_id:       int           = Field(description='The Org that owns this Service.')\n\t    created_by:   int           = Field(description='The user_id that created this item.')\n\t    updated_by:   int           = Field(description='The user_id that last modified this item.')\n\t    created_at:   float         = Field(description='The epoch timestamp when the collection was created.')\n\t    updated_at:   float         = Field(description='The epoch timestamp when the collection was created.')\n"]}
{"filename": "jiggybase/models/embedding.py", "chunked_list": ["from typing import Optional, List\n\tfrom pydantic import BaseModel, Field, HttpUrl, validator\n\tfrom enum import Enum\n\tclass EmbeddingModelName(str, Enum):\n\t    ada002 :str = \"text-embedding-ada-002\"\n\t    def __str__(self):\n\t        return str(self.value)    \n\tclass EmbeddingConfig(BaseModel):\n\t    model : EmbeddingModelName =  Field(EmbeddingModelName.ada002, description=\"The name of the model to use for embedding the collection content.\")\n"]}
{"filename": "jiggybase/models/plugin.py", "chunked_list": ["from typing import Optional, Union, List\n\tfrom pydantic import BaseModel, Field\n\tfrom enum import Enum\n\tfrom pydantic import BaseModel, Field, HttpUrl\n\tclass PluginAuthType(str, Enum):\n\t    \"\"\"\n\t    Note that this is for custom plugins available in the JiggyBase enterprise tier and unrelated to the main JiggyBase plugin in the OpenAI plugin store.\n\t    \"\"\"\n\t    bearer :str = \"bearer\"\n\t    none   :str = \"none\"\n", "    oauth  :str = \"oauth\"\n\tclass PluginAuthConfigOAuth(BaseModel):\n\t    \"\"\"\n\t    The Plugin Oauth configuration as managed by JiggyBase\n\t    Note that this is for custom plugins available in the JiggyBase enterprise tier and unrelated to the main JiggyBase plugin in the OpenAI plugin store.\n\t    \"\"\"    \n\t    client_url:                 HttpUrl     = Field(description=\"ChatGPT will direct the user’s browser to this url to log in to the plugin\")\n\t    authorization_url:          HttpUrl     = Field(description=\"After successful login ChatGPT will complete the OAuth flow by making a POST request to this URL\")\n\t    scope:                      str         = Field(description=\"The scope used for the OAuth flow\")\n\t    client_id:                  str         = Field(unique=True, index=True, description=\"The client id to send to OpenAI for the plugin\")\n", "    client_secret:              str         = Field(description=\"The client secret to send to OpenAI for the plugin\")\n\t    openai_verification_token:  str         = Field(description=\"The verification token specified by OpenAI to configure in the plugin\")\n\tclass PatchPluginOAuthConfigRequest(BaseModel):\n\t    openai_verification_token: str  \n\tclass Source(str, Enum):\n\t    email = \"email\"\n\t    file = \"file\"\n\t    chat = \"chat\"\n\t    web  = \"web\"\n\tclass DocumentMetadata(BaseModel):\n", "    source: Optional[Source] = None\n\t    source_id: Optional[str] = None\n\t    url: Optional[str] = None\n\t    created_at: Optional[str] = None\n\t    author: Union[str, List[str]] = None\n\t    title: Optional[str] = None\n\t    description: Optional[str] = None\n\t    language: Optional[str] = Field(description=\"The 2 character ISO 639-1 language code of the primary language of the content.\")\n\t    version: str = None\n\tclass DocumentChunkMetadata(DocumentMetadata):\n", "    document_id: Optional[str] = None\n\tclass DocumentChunk(BaseModel):\n\t    id: Optional[str] = None\n\t    text: str\n\t    metadata: DocumentChunkMetadata\n\t    embedding: Optional[list[float]] = None\n\t    token_count: Optional[int] = None\n\t    reference_url: Optional[str] = None\n\t    def __str__(self):\n\t        if len(self.text) > 100:\n", "            text = self.text[:100] + '...'\n\t        else: \n\t            text = self.text\n\t        text = text.replace('\\n', ' ')\n\t        estr = \"DocumentChunk(\"\n\t        if self.id is not None:\n\t            estr += f\"id={self.id}, \"\n\t        if self.metadata is not None:\n\t            estr += f\"metadata={str(self.metadata)}, \"\n\t        if self.embedding is not None:\n", "            estr += f\"embedding=dim{len(self.embedding)}, \"\n\t        estr += f\"text={text})\"\n\t        return estr\n\tclass DocumentChunkWithScore(DocumentChunk):\n\t    score: float\n\tclass Document(BaseModel):\n\t    id: Optional[str]\n\t    text: str\n\t    metadata: Optional[DocumentMetadata] = None\n\t    mimetype: Optional[str] = None\n", "    token_count: Optional[int] = None\n\tclass DocumentWithChunks(Document):\n\t    chunks: List[DocumentChunk]\n\tclass DocumentMetadataFilter(BaseModel):\n\t    document_id: Optional[str] = None\n\t    source: Optional[Source] = None\n\t    source_id: Optional[str] = None\n\t    author: Optional[str] = None\n\t    start_date: Optional[str] = None  # any date string format\n\t    end_date: Optional[str] = None  # any date string format\n", "    title: Optional[str] = None\n\tclass Query(BaseModel):\n\t    query: str\n\t    filter: Optional[DocumentMetadataFilter] = None\n\t    top_k: Optional[int] = 3\n\tclass QueryWithEmbedding(Query):\n\t    embedding: list[float]\n\tclass QueryResult(BaseModel):\n\t    query: str\n\t    results: list[DocumentChunkWithScore]\n", "class UpsertRequest(BaseModel):\n\t    documents: List[Document]\n\tclass UpsertResponse(BaseModel):\n\t    ids: List[str]\n\tclass QueryRequest(BaseModel):\n\t    queries: List[Query]\n\tclass QueryResponse(BaseModel):\n\t    results: List[QueryResult]\n\tclass DeleteRequest(BaseModel):\n\t    ids: Optional[List[str]] = None\n", "    filter: Optional[DocumentMetadataFilter] = None\n\t    delete_all: Optional[bool] = False\n\tclass DeleteResponse(BaseModel):\n\t    success: bool\n\tclass Accounting(BaseModel):\n\t    chunk_count: int\n\t    doc_count: int\n\t    page_count: int\n\tclass DocChunksResponse(BaseModel):\n\t    docs       : list[list[DocumentChunk]] = Field(..., description=\"A list of documents, each containing a list of chunks\")\n", "    next_index : int                       = Field(..., description=\"The index of the next document to return.  Use this value as the index parameter in the next request to get the next set of documents\")  \n"]}
{"filename": "jiggybase/models/org.py", "chunked_list": ["from typing import Optional, List\n\tfrom pydantic import BaseModel, Field, EmailStr, HttpUrl\n\tfrom enum import Enum\n\tclass OrgRole(str, Enum):\n\t    admin   = 'admin'\n\t    member  = 'member'\n\t    service = 'service'\n\t    view    = 'view'\n\tclass OrgPostRequest(BaseModel):\n\t    name:        str           = Field(min_length=1, max_length=39, description='Unique name for this org.')\n", "    description: Optional[str] = Field(default=None, description='Optional user supplied description.')\n\tclass OrgPatchRequest(BaseModel):\n\t    name:        Optional[str] = Field(max_length=39, description='Unique name for this org.')\n\t    description: Optional[str] = Field(max_length=255, description='Optional user supplied description.')\n\tclass OrgMemberPostRequest(BaseModel):\n\t    email:  EmailStr     = Field(description='The user_id of a member to invite to the org.')\n\t    role:   OrgRole      = Field(description='The users role in the org')\n\tclass OrgMember(BaseModel):\n\t    id:                  int      = Field(description=\"Unique membership id\")\n\t    name:                str      = Field(description=\"Member name\")\n", "    email:               EmailStr = Field(description=\"Member email\")    \n\t    created_at:          float    = Field(description='The epoch timestamp when the membership was created.')\n\t    updated_at:          float    = Field(description='The epoch timestamp when the membership was updated.')\n\t    invited_by_name:     str      = Field(description=\"The name that invited this member to the org.\")\n\t    role:                OrgRole  = Field(description=\"The user's role in the org\")\n\t    accepted:            bool     = Field(description='True if the user has accepted the org membership.')\n\tclass Org(BaseModel):\n\t    id:                  int           = Field(escription=\"Internal org id\")\n\t    name:                str           = Field(max_length=39, description='Unique name for this org.')\n\t    description:         Optional[str] = Field(max_length=255, description='Optional user supplied description.')\n", "    created_at:          float         = Field(description='The epoch timestamp when the org was created.')\n\t    updated_at:          float         = Field(description='The epoch timestamp when the org was updated.')\n\t    created_by:          Optional[int] = Field(description='The user_id of the user that created the org.')\n\t    subscription_id:     str           = Field(description='The subscription_id for the org.')    \n\t    gpt4_credits:        int           = Field(description='The number of GPT-4 message credits currently available to the org users for chat.jiggy.ai.')\n\t    gpt3_5_credits:      int           = Field(description='The number of GPT-3 message credits currently available to the org users for chat.jiggy.ai.')\n\t    subscription_status: str           = Field(description='The stripe subscription status.')\n"]}
{"filename": "jiggybase/models/metadata.py", "chunked_list": ["from typing import Optional, List\n\tfrom pydantic import BaseModel, Field, HttpUrl, validator\n\tfrom enum import Enum\n\tfrom .chatmodel import ChatModelName\n\tclass ExtractMetadataConfig(BaseModel):\n\t    \"\"\"\n\t    configuration for metadata extraction\n\t    \"\"\"\n\t    created_at:  bool          = Field(True, description=\"Attempt to extract the created_at metadata field\")\n\t    author:      bool          = Field(True, description=\"Attempt to extract the author metadata field\")\n", "    title:       bool          = Field(True, description=\"Attempt to extract the title metadata field\")\n\t    model:       ChatModelName = Field(ChatModelName.gpt4, description=\"The name of the model to use for metadata extraction\")\n"]}
{"filename": "jiggybase/models/__init__.py", "chunked_list": ["from .auth import *\n\tfrom .user import *\n\tfrom .org import *\n\tfrom .embedding import *\n\tfrom .metadata import *\n\tfrom .chunk import *\n\tfrom .chatmodel import *\n\tfrom .plugin_config import *\n\tfrom .plugin import *\n\tfrom .collection import *\n", "from .prompt import *\n\tfrom .chat import *\n"]}
{"filename": "jiggybase/models/prompt.py", "chunked_list": ["from typing import Optional, List\n\tfrom pydantic import BaseModel, Field, HttpUrl, validator\n\tfrom enum import Enum\n\tfrom time import time\n\tclass PromptMessageRole(str, Enum):\n\t    system              : str = \"system\"\n\t    user                : str = \"user\"\n\t    assistant           : str = \"assistant\"\n\t    collection_context  : str = \"collection_context\"   # this is a special role that pulls in collection context in subsequent system messages\n\t    def __str__(self):\n", "        return str(self.value)\n\tclass PromptMessage(BaseModel):\n\t    role      : PromptMessageRole  = Field(description=\"The role of the prompt\")\n\t    content   : str                = Field(description=\"The text of the prompt\")\n\t    position  : int                = Field(description=\"The position offset of the item in the prompt message list. 0-based, with negative values counting from the end.\")\n\tclass PromptTaskType(str, Enum):\n\t    chat            = \"chat\"             # iterative chat (e.g. chat with a model with user/assistant message history)\n\t    collection_chat = \"collection_chat\"  # iterative chat augmented with retreival from a collection\n\t    plugin_chat     = \"plugin_chat\"      # iterative chat augmented with tool use via plugin interface\n\t    read_write      = \"read_write\"       # non-iterative task that involve reading a document and producing text or data\n", "class PromptTask(BaseModel):\n\t    id          :   int                      = Field(description=\"The unique ID of the prompt task\")\n\t    org_id      :   int                      = Field(description='The Org that owns this.')    \n\t    name        :   str                      = Field(description=\"The name of the task. Unique within the org.\")    \n\t    type        :   Optional[PromptTaskType] = Field(description=\"The type of task\")\n\t    version     :   int                      = Field(description=\"The version of the task. Unique for a given org and task name.\")\n\t    description :   Optional[str]            = Field(description=\"The description of the task\")\n\t    prompts     :   List[PromptMessage]      = Field(description=\"The prompt messages used in the prompt task\")\n\t    created_at  :   float                    = Field(description='The epoch timestamp when the item was created.')\n\tclass PromptTaskPostRequest(BaseModel):\n", "    name:          str                      = Field(description=\"The name of the task. Unique within the org.\")\n\t    version:       int                      = Field(description=\"The version of the task. Unique for a given org and task name.\")\n\t    type:          Optional[PromptTaskType] = Field(description=\"The type of task\")        \n\t    description:   Optional[str]            = Field(description=\"The description of the task\")\n\t    prompts:       List[PromptMessage]      = Field(description=\"The items that make up the prompt task\")\n"]}
{"filename": "jiggybase/models/plugin_config.py", "chunked_list": ["import os\n\tfrom pydantic import BaseModel, HttpUrl, Field, validator\n\tfrom typing import List, Optional\n\tfrom enum import Enum\n\tfrom .plugin import PluginAuthType        \n\timport re\n\tMODELNAME = re.compile(\"[a-zA-Z][a-zA-Z0-9_]*\")\n\tclass PluginConfig(BaseModel): \n\t    \"\"\"\n\t    The user-customizable part of PluginConfig\n", "    \"\"\"\n\t    name_for_model:        str = Field(\"retrieval\", max_length=50, description=\"The name of the plugin as it will be appear to the model.\")\n\t    name_for_human:        str = Field(max_length=50, description=\"The name of the plugin as it will be appear to the human user.\")\n\t    description_for_model: str = Field(max_length=4000, description=\"Description of the plugin as it will appear to the model.\")\n\t    description_for_human: str = Field(max_length=120, description=\"Description of the plugin as it will appear to the human user.\")\n\t    logo:                  Optional[str] = Field(description=\"The logo for the plugin\")\n\t    logo_url:              Optional[HttpUrl] = Field(description=\"The logo url for the plugin\")\n\t    @validator('name_for_model')\n\t    def _name_for_model(cls, v):\n\t        if len(v) > 50 or not v:\n", "            raise ValueError(f'\"{v}\" is an invalid model name. It must not be empty and is limited to 50 characters.')\n\t        elif not bool(MODELNAME.match(v)):\n\t         raise ValueError(f'\"{v}\" is an invalid model name. It can only contain letters, numbers, and underscores, and must start with a letter.')\n\t        return v\n\tclass PatchPluginConfigRequest(BaseModel):\n\t    name_for_model:        Optional[str] = Field(description=\"The plugin name for the model\")\n\t    name_for_human:        Optional[str] = Field(description=\"The plugin name for human\")\n\t    description_for_model: Optional[str] = Field(description=\"The plugin description for the model\")\n\t    description_for_human: Optional[str] = Field(description=\"The plugin description for human\")\n\t    logo:                  Optional[str] = Field(description=\"The logo for the plugin\")\n", "    logo_url:              Optional[HttpUrl] = Field(description=\"The logo url for the plugin\")\n\t    @validator('name_for_model')\n\t    def _name_for_model(cls, v):\n\t        if len(v) > 50 or not v:\n\t            raise ValueError(f'\"{v}\" is an invalid model name. It must not be empty and is limited to 50 characters.')\n\t        elif not bool(MODELNAME.match(v)):\n\t         raise ValueError(f'\"{v}\" is an invalid model name. It can only contain letters, numbers, and underscores, and must start with a letter.')\n\t        return v\n\tclass OpenAIVerificationToken(BaseModel):\n\t    openai: str\n", "class OpenAIPluginAuthConfigOAuth(BaseModel):\n\t    \"\"\"\n\t    The Plugin Oauth configuration as it is presented in the ai-plugin.json \n\t    \"\"\"\n\t    type:                       str         = Field(\"oauth\", const=True)\n\t    client_url:                 HttpUrl     = Field(description=\"ChatGPT will direct the user’s browser to this url to log in to the plugin\")\n\t    authorization_url:          HttpUrl     = Field(description=\"After successful login ChatGPT will complete the OAuth flow by making a POST request to this URL\")\n\t    scope:                      str         = Field(description=\"The scope used for the OAuth flow\")    \n\t    authorization_content_type: str         = Field(\"application/json\", const=True)\n\t    verification_tokens:        OpenAIVerificationToken = Field(description=\"The verification token to send to OpenAI for the plugin\")\n"]}
{"filename": "jiggybase/models/user.py", "chunked_list": ["from typing import Optional\n\tfrom pydantic import BaseModel, Field, EmailStr\n\t###\n\t## User\n\t###\n\tclass User(BaseModel):\n\t    id:              int = Field(description='Internal user_id')\n\t    name:            str = Field(min_length=1, max_length=39, description='Unique name for the user.')\n\t    email:           EmailStr  = Field(description='Email address for the user.')    \n\t    auth0_userid:    str = Field(description='Auth0 userid.  This can be None for anonymous accounts created via api key')\n", "class UserPostRequest(BaseModel):\n\t    name:            str           = Field(min_length=1, max_length=39, description='Name for the user.')\n\t    email:           EmailStr      = Field(description='Email address for the user.')\n\tclass UserPostPatchRequest(BaseModel):\n\t    name:      Optional[str]      = Field(min_length=1, max_length=39, description='Unique name for the user.')\n\t###\n\t##  API Key Authentication\n\t###\n\tclass AuthRequest(BaseModel):\n\t    key : str = Field(description = \"The API key\")\n", "class Jwt(BaseModel):\n\t    jwt: str = Field(description='The JWT to used as bearer token')\n\t###\n\t## API Key\n\t###\n\tclass  ApiKey(BaseModel):\n\t    key:         str           = Field(default=None, description='The api key.')\n\t    description: Optional[str] = Field(default=None, description='Optional user supplied description of the key.')\n\t    created_at:  float         = Field(description='The epoch timestamp when the key was created.')\n\t    last_used :  float         = Field(description='The epoch timestamp when the key was last used to create a JWT.')\n", "class  ApiKeyRequest(BaseModel):\n\t    description: Optional[str] = Field(default=None, description='Optional user supplied description of the key.')\n\tclass AllApiKeyResponse(BaseModel):\n\t    items: list[ApiKey] = Field(description=\"List of all Api Keys\")\n"]}
{"filename": "jiggybase/models/chat.py", "chunked_list": ["\"\"\"\n\tConfig for chat-related functionality\n\t\"\"\"\n\tfrom pydantic import BaseModel, Field\n\tfrom .chatmodel import ChatModelName\n\tfrom typing import Optional, List\n\tclass CollectionChatConfig(BaseModel):\n\t    \"\"\"Config for Collection chat-related functionality\"\"\"    \n\t    model_name          : str           = Field(description=\"The model associated with this configuration\")\n\t    rate_limit_messages : int           = Field(description=\"The total number of messages allowed in the rate limit time period across all collection users\")\n", "    rate_limit_hours    : int           = Field(description=\"The number of hours in the rate limit time period\")\n\t    prompt_task_id      : Optional[int] = Field(description=\"The prompt task id of the prompt to use for chat with this collection\")\n\tclass PatchCollectionChatConfig(BaseModel):\n\t    \"\"\"Config for Collection chat-related functionality\"\"\"    \n\t    prompt_task_id      : Optional[int] = Field(description=\"The prompt task id of the prompt to use for chat with this collection\")\n\t## Chat Completion Request objects sent to the chat completion endpoint\n\tclass Message(BaseModel):\n\t    role: str\n\t    content: str\n\tclass CompletionRequest(BaseModel):\n", "    model: str\n\t    messages: list[Message]\n\t    max_tokens: Optional[int] = None\n\t    temperature: float\n\t    stream: bool\n\tclass TypedCompletionRequest(CompletionRequest):\n\t    json_schema : str\n\tclass Choice(BaseModel):\n\t    finish_reason: str\n\t    index: int\n", "    message: Message\n\tclass Usage(BaseModel):\n\t    completion_tokens: int\n\t    prompt_tokens: int\n\t    total_tokens: int\n\tclass ChatCompletion(BaseModel):\n\t    id: str\n\t    choices: List[Choice]\n\t    created: int\n\t    model: str\n", "    object: str\n\t    usage: Usage\n\t    def __str__(self):\n\t        return self.choices[0].message.content\n\tclass ChatUsage(BaseModel):\n\t    \"\"\"\n\t    JiggyBase chat completion that was temporarily used before transitioning to the OpenAI ChatCompletion\n\t    \"\"\"\n\t    collection_id:   int           = Field(description=\"The collection ID used to inform the completion\")\n\t    model:           str           = Field(description=\"The name of the model used to generate the completion\")\n", "    user_message:    str           = Field(description=\"The user's input message\")\n\t    input_tokens:    int           = Field(description=\"The number of input tokens sent to the model\")\n\t    output_tokens:   int           = Field(description=\"The number of output tokens generated by the model\")\n\t    messages_json:   Optional[str] = Field(description=\"JSON representation of the input messages sent to model endpoint\")    \n\t    completion:      Optional[str] = Field(description=\"The completion text returned by the model\")\n\t    created_at:      float         = Field(description=\"The epoch timestamp associated with the completion.\")\n\t    endpoint:        str           = Field(description=\"The JiggyBase endpoint that requested the model completion\")\n\t    def __str__(self):\n\t        return self.completion"]}
{"filename": "jiggybase/models/chatmodel.py", "chunked_list": ["from enum import Enum\n\tclass ChatModelName(str, Enum):\n\t    gpt3_5_turbo :str = \"gpt-3-5-turbo\"\n\t    gpt4         :str = \"gpt-4\"\n\t    def __str__(self):\n\t        return str(self.value)    "]}
{"filename": "jiggybase/models/chunk.py", "chunked_list": ["from pydantic import BaseModel, Field\n\tfrom typing import Optional\n\tclass ChunkConfig(BaseModel):\n\t    \"\"\"\n\t    configuration for chunking policy\n\t    \"\"\"\n\t    chunk_size:                 int = Field(200,   description=\"The target size of each text chunk in tokens\")\n\t    min_chunk_size_chars:       int = Field(350,   description=\"The minimum size of each text chunk in characters\")\n\t    min_chunk_length_to_embed:  int = Field(  5,   description=\"Discard chunks shorter than this\")\n\t    embeddings_batch_size:      int = Field(128,   description=\"The number of embeddings to request at a time\")\n", "    max_num_chunks:             int = Field(10000, description=\"The maximum number of chunks to generate from a text\")\n\tclass PatchChunkConfigRequest(BaseModel):\n\t    chunk_size:                Optional[int] = Field(description=\"The target size of each text chunk in tokens\")\n\t    min_chunk_size_chars:      Optional[int] = Field(description=\"The minimum size of each text chunk in characters\")\n\t    min_chunk_length_to_embed: Optional[int] = Field(description=\"Discard chunks shorter than this\")\n\t    embeddings_batch_size:     Optional[int] = Field(description=\"The number of embeddings to request at a time\")\n\t    max_num_chunks:            Optional[int] = Field(description=\"The maximum number of chunks to generate from a text\")\n"]}
{"filename": "jiggybase/models/providers.py", "chunked_list": ["from pydantic import BaseModel, Field\n\tfrom typing import Optional\n\tclass PineconeConfig(BaseModel):\n\t    api_key: str = Field(..., description=\"Your Pinecone API Key\")\n\t    environment: str = Field(..., description=\"Your Pinecone environment\")\n\t    index: str = Field(..., description=\"Your Pinecone index\")\n\tclass WeaviateConfig(BaseModel):\n\t    host: str = Field(..., description=\"Your Weaviate host\")\n\t    port: int = Field(..., description=\"Your Weaviate port\")\n\t    index: str = Field(..., description=\"Your Weaviate index\")\n", "    username: Optional[str] = Field(None, description=\"Your Weaviate username\")\n\t    password: Optional[str] = Field(None, description=\"Your Weaviate password\")\n\t    scopes: Optional[str] = Field(None, description=\"Your Weaviate scopes\")\n\t    batch_size: Optional[int] = Field(None, description=\"Your Weaviate batch size\")\n\t    batch_dynamic: Optional[bool] = Field(None, description=\"Your Weaviate batch dynamic\")\n\t    batch_timeout_retries: Optional[int] = Field(None, description=\"Your Weaviate batch timeout retries\")\n\t    batch_num_workers: Optional[int] = Field(None, description=\"Your Weaviate batch number of workers\")\n\tclass ZillizConfig(BaseModel):\n\t    collection: str = Field(..., description=\"Your Zilliz collection\")\n\t    uri: str = Field(..., description=\"Your Zilliz URI\")\n", "    user: str = Field(..., description=\"Your Zilliz username\")\n\t    password: str = Field(..., description=\"Your Zilliz password\")\n\tclass MilvusConfig(BaseModel):\n\t    collection: str = Field(..., description=\"Your Milvus collection\")\n\t    host: str = Field(..., description=\"Your Milvus host\")\n\t    port: str = Field(default=\"19530\", description=\"Your Milvus port\")\n\t    user: str = Field(None, description=\"Your Milvus username\")\n\t    password: str = Field(None, description=\"Your Milvus password\")\n\t    index_params: Optional[str] = Field(..., description=\"Custom index options for the collection.\")\n\t    search_params: Optional[str] = Field(..., description=\"Custom search options for the collection\")\n", "    consistency_level: Optional[str] = Field(..., description=\"Custom consistency level for the collection\")\n\tclass QdrantConfig(BaseModel):\n\t    url: str = Field(..., description=\"Your Qdrant URL\")\n\t    port: str = Field(\"6333\", description=\"Your Qdrant port\")\n\t    grpc_port: str = Field(\"6334\", description=\"Your Qdrant gRPC port\")\n\t    api_key: str = Field(..., description=\"Your Qdrant API key\")\n\t    collection: str = Field(..., description=\"Your Qdrant collection\")\n\tclass RedisConfig(BaseModel):\n\t    host: str = Field(..., description=\"Your Redis host\")\n\t    port: int = Field(..., description=\"Your Redis port\")\n", "    password: str = Field(None, description=\"Your Redis password\")\n\t    index_name: str = Field(..., description=\"Your Redis index name\")\n\t    doc_prefix: str = Field(..., description=\"Your Redis document prefix\")\n\t    distance_metric: Optional[str] = Field(None, description=\"Your Redis distance metric\")\n\t    index_type: Optional[str] = Field(None, description=\"Your Redis index type\")\n"]}
{"filename": "jiggybase/examples/chat_completion_stream.py", "chunked_list": ["import jiggybase\n\timport sys\n\tcollection = jiggybase.JiggyBase().collection('hackernews-summary')\n\tmessages = [{'role':'user',  'content': 'articles about python 3.11'}]\n\tfor outstr in collection._chat_completion_stream_str(messages, temperature=0):\n\t    sys.stdout.write(outstr)\n\t    sys.stdout.flush()\n\tprint()\n"]}
{"filename": "jiggybase/examples/qa_example.py", "chunked_list": ["import csv\n\timport os\n\timport tempfile\n\timport shutil\n\tfrom dotenv import load_dotenv\n\timport jiggybase\n\tdef get_answer(question):\n\t    messages = [{'role':'user',  'content': question}]\n\t    collection_name = os.getenv(\"JIGGYBASE_COLLECTION_NAME\")\n\t    collection = jiggybase.JiggyBase().collection(collection_name)\n", "    rsp = collection._chat_completion(messages)\n\t    return rsp\n\tdef fill_answers(input_csv):\n\t    with tempfile.NamedTemporaryFile(mode='w+', newline='', delete=False) as temp_file:\n\t        with open(input_csv, \"r\", newline='') as infile, open(temp_file.name, \"w\", newline='') as outfile:\n\t            reader = csv.reader(infile)\n\t            writer = csv.writer(outfile)\n\t            # Verify the header and write it to the output file\n\t            header = next(reader)\n\t            assert header == [\"question\", \"answer\"], \"Invalid header\"\n", "            writer.writerow(header)\n\t            # Iterate over the rows, filling in answers when needed\n\t            for row in reader:\n\t                question, answer = row\n\t                if not answer or answer.strip() == \"\":\n\t                    answer = get_answer(question)\n\t                    row = [question, answer]\n\t                writer.writerow(row)\n\t        # Replace the original input file with the updated file\n\t        shutil.move(temp_file.name, input_csv)\n", "load_dotenv()\n\tinput_csv = \"input.csv\"\n\tfill_answers(input_csv)\n"]}
{"filename": "jiggybase/examples/upload_email_example.py", "chunked_list": ["import os\n\timport json\n\timport jiggybase\n\tfrom  jiggybase.models import Document, DocumentMetadata, Source\n\tjb = jiggybase.JiggyBase()\n\tJIGGYBASE_ORG = os.environ[\"JIGGYBASE_ORG\"]\n\tJIGGYBASE_COLLECTION = os.environ[\"JIGGYBASE_COLLECTION\"]\n\torg = jb.get_org(JIGGYBASE_ORG)\n\tcollection = org.collection(JIGGYBASE_COLLECTION)\n\tother_metadata = {\"to\": ['bob@example.com'], \"cc\": ['hr@example.com', 'legal@example.com']}\n", "# Example email metadata\n\temail_metadata = DocumentMetadata(\n\t    source     = Source.email,\n\t    created_at = \"2022-02-15T10:30:00\",        # using ISO 8601 format (YYYY-MM-DDTHH:MM:SS) makes it possible to filter by date\n\t    author     = \"Alice <alice@example.com>\",  # sender name and optional email address\n\t    title      = \"Reminder: Friday Meeting\",   # subject\n\t    description = json.dumps(other_metadata)   # put any other metadata here that is associated with the entire document \n\t)\n\t# Create a Document object with the email text and metadata\n\temail_document = Document(\n", "    id       = \"XX4HJ823930JK\",   # unique ID for the document\n\t    metadata = email_metadata,\n\t    text     = \"Hello Bob, I hope you're doing well. I just wanted to remind you about the upcoming meeting on Friday. Best, Alice\",    \n\t)\n\t# Upsert the email_document into test_collection\n\tupsert_response = collection.upsert(documents=[email_document])\n\tprint(upsert_response)\n"]}
{"filename": "jiggybase/examples/jiggybase_upload.py", "chunked_list": ["#! /usr/bin/env python3\n\timport os\n\timport sys\n\timport argparse\n\timport jiggybase\n\tjb = jiggybase.JiggyBase()\n\tJIGGYBASE_ORG = os.environ.get(\"JIGGYBASE_ORG\")\n\tJIGGYBASE_COLLECTION = os.environ.get(\"JIGGYBASE_COLLECTION\")\n\tdef upload_file(collection : jiggybase.models.Collection, filename : str):\n\t    print(f'Uploading {filename}')\n", "    try:\n\t        upsert_rsp = collection.upsert_file(filename)\n\t    except Exception as e:            \n\t        print(f'error on {filename}: {e}')\n\t        return\n\t    doc_id = upsert_rsp.ids[0]\n\t    dcl =  collection.get_doc(doc_id)\n\t    text_len = len(\" \".join([dc.text for dc in dcl]))\n\t    title = dcl[0].metadata.title if dcl[0].metadata.title else \"Unnown Title\"\n\t    print(f'Processed {filename}: \"{title}\"  {text_len//1024} KB text ({len(dcl)} chunks)')\n", "def upload_directory(collection : jiggybase.models.Collection, dirname : str):\n\t    for fn in os.listdir(dirname):\n\t        fn = os.path.join(dirname, fn)\n\t        upload_file(collection, fn)\n\tepilog = \"If neither '--file' nor '--dir' options are provided, the script will automatically process other arguments as a file or directory\"\n\tdef main():\n\t    parser = argparse.ArgumentParser(description=\"Upload a file or directory to a JiggyBase collection\",  epilog=epilog )    \n\t    parser.add_argument(\"--org\", type=str, help=\"The name of your JiggyBase organization.  Alternatively, set JIGGYBASE_ORG environment variable or be a member of a single Org.\")\n\t    parser.add_argument(\"--collection\", type=str, help=\"The name of your JiggyBase collection. Alternatively, set JIGGYBASE_COLLECTION environment variable or have a single collection in your org.\")\n\t    parser.add_argument(\"--dir\", type=str, help=\"The directory you want to upload.\")\n", "    parser.add_argument(\"--file\", type=str, help=\"The file you want to upload\")\n\t    if len(sys.argv) == 1:\n\t        parser.print_help(sys.stderr)\n\t        sys.exit(1)\n\t    parsed_args, unknown_args = parser.parse_known_args(sys.argv[1:])\n\t    if not parsed_args.org:\n\t        orgs = jb.orgs()\n\t        if len(orgs) > 1:\n\t            print(\"Please provide an organization name using the --org option\")\n\t            sys.exit(1)\n", "        elif JIGGYBASE_ORG:\n\t            org = jb.get_org(JIGGYBASE_ORG)\n\t        else:\n\t            org = orgs[0]\n\t    else:\n\t        org = jb.get_org(parsed_args.org)\n\t    if not parsed_args.collection:\n\t        collections = org.collections()\n\t        if len(collections) > 1:\n\t            print(\"Please provide a collection name using the --collection option\")\n", "            sys.exit(1)\n\t        elif JIGGYBASE_COLLECTION:\n\t            collection = org.collection(JIGGYBASE_COLLECTION)\n\t        else:\n\t            collection = collections[0]\n\t    else:\n\t        collection = org.collection(parsed_args.collection)\n\t    if parsed_args.dir:\n\t        upload_directory(collection, parsed_args.dir)\n\t    elif parsed_args.file:\n", "        upload_file(collection, parsed_args.file)\n\t    elif unknown_args:\n\t        for arg in unknown_args:\n\t            if os.path.isfile(arg):\n\t                upload_file(collection, arg)\n\t            elif os.path.isdir(arg):\n\t                upload_directory(collection, arg)\n\t            else:\n\t                print(f\"Skipping unknown argument: {arg}\")\n\t    else:\n", "        print(\"Please provide a valid file or directory to upload\")\n\t        parser.print_help(sys.stderr)\n\t        sys.exit(1)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "jiggybase/examples/confluence_sync.py", "chunked_list": ["#!/usr/bin/env python3\n\t\"\"\"\n\tSpecification:\n\tSync the text content in a Confluence Space into a JiggyBase Collection\n\tTakes the following config from the command line or via environment variables:\n\t--user  or ATLASSIAN_USER   environment variable\n\t--token or ATLASSIAN_TOKEN  environment variable   \n\t--url   or CONFLUENCE_URL   environment variable   \n\t--space or CONFLUENCE_SPACE environment variable   The space key, id, or name of the space to sync\n\t--org   or JIGGYBASE_ORG    environment variable   The JiggyBase org to sync to\n", "To create an Atlassian API token go to \n\thttps://id.atlassian.com/manage-profile/security/api-tokens\n\tand click on Create API token. Save the value into an environment variable.\n\tE.g. on Macos\n\texport ATLASSIAN_TOKEN=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\tIf a JiggyBase API token is not set then the JiggyBase SDK will open a web browser on the page to copy it from the JiggyBase dashboard.\n\tImplementation notes:\n\tUses page['version']['when'] as document created_at timestamp and version indicator\n\tUses page['id'] as document id (unique within a collection)\n\tIf a given document ID exists in both confluence and jiggybase, check  \n", "Re-uploads a page if the version has changed from what is in the metadata\n\t\"\"\"\n\t# pip install atlassian-python-api\n\tfrom atlassian import Confluence\n\timport os\n\timport argparse\n\timport jiggybase\n\timport requests \n\tdef upsert_file(collection : jiggybase.models.Collection, filename : str):\n\t    print(f'Uploading {filename}')\n", "    try:\n\t        upsert_rsp = collection.upsert_file(filename)\n\t    except Exception as e:            \n\t        print(f'error on {filename}: {e}')\n\t        return\n\t    doc_id = upsert_rsp.ids[0]\n\t    dcl =  collection.get_doc(doc_id)\n\t    text_len = len(\" \".join([dc.text for dc in dcl]))\n\t    title = dcl[0].metadata.title if dcl[0].metadata.title else \"Unnown Title\"\n\t    print(f'Processed {filename}: \"{title}\"  {text_len//1024} KB text ({len(dcl)} chunks)')\n", "def save_attachment_to_file(confluence, attachment):\n\t    title = attachment['title']\n\t    download_link = attachment['_links']['download']\n\t    download_url = f'{confluence.url}{download_link}'\n\t    response = requests.get(download_url, auth=(confluence.username, confluence.password))\n\t    if response.status_code == 200:\n\t        with open(title, 'wb') as file:\n\t            file.write(response.content)\n\t        return title\n\t    else:\n", "        print(f\"Error downloading attachment '{title}': {response.status_code}\")\n\t        return None\n\tdef sync_confluence_space_to_jiggybase_collection(confluence, space, org):\n\t    \"\"\"\n\t    \"\"\"\n\t    try:\n\t        space_collection = org.collection(space['name'])\n\t        print(f\"Found existing JiggyBase collection {space['name']}\")\n\t    except:\n\t        space_collection = org.create_collection(space['name'])\n", "        print(f\"Created new JiggyBase collection {space['name']}\")\n\t    # Delete all documents in the collection\n\t    print(f\"Deleting all prior documents in JiggyBase collection {space['name']}\")\n\t    space_collection.delete_docs(delete_all=True)\n\t    # Get all pages in the space\n\t    pages = confluence.get_all_pages_from_space(space['key'])\n\t    # Loop through each page and process it\n\t    for page in pages:\n\t        # Download page as Word document\n\t        doc_content = confluence.get_page_as_word(page['id'])\n", "        doc_filename = f\"{page['title']}.doc\"\n\t        # Save the Word document locally\n\t        with open(doc_filename, 'wb') as doc_file:\n\t            doc_file.write(doc_content)\n\t        # Upload the Word document to JiggyBase collection\n\t        upsert_file(space_collection, doc_filename)\n\t        os.remove(doc_filename)\n\t        # Get all attachments from the page\n\t        attachments = confluence.get_attachments_from_content(page['id'])['results']\n\t        # Download and upload each attachment to JiggyBase collection\n", "        for attachment in attachments:\n\t            if attachment['title'].split('.')[-1] in ['svg']:\n\t                # skip unsupported file types\n\t                continue\n\t            print(f\"Downloading attachment {attachment['title']} from page {page['title']}\")\n\t            attachment_filename = save_attachment_to_file(confluence, attachment)\n\t            if attachment_filename:\n\t                upsert_file(space_collection, attachment_filename)            \n\t            os.remove(attachment_filename)\n\t        print(f\"Finished syncing {page['title']} and its attachments.\")\n", "def main():\n\t    # Handle command line arguments and environment variables\n\t    parser = argparse.ArgumentParser(description=\"Sync Confluence Space to JiggyBase Collection\")\n\t    parser.add_argument('--user', default=os.environ.get('ATLASSIAN_USER'))\n\t    parser.add_argument('--token', default=os.environ.get('ATLASSIAN_TOKEN'))\n\t    parser.add_argument('--url', default=os.environ.get('CONFLUENCE_URL'))\n\t    parser.add_argument('--space', default=os.environ.get('CONFLUENCE_SPACE'))\n\t    parser.add_argument('--org', default=os.environ.get('JIGGYBASE_ORG'))\n\t    args = parser.parse_args()\n\t    jb = jiggybase.JiggyBase()\n", "    orgs = jb.orgs()\n\t   # Check if all required arguments are provided\n\t    missing_args = []\n\t    if not args.user:\n\t        missing_args.append('--user  or ATLASSIAN_USER   environment variable')\n\t    if not args.token:\n\t        missing_args.append('--token or ATLASSIAN_TOKEN  environment variable')\n\t    if not args.url:\n\t        missing_args.append('--url   or CONFLUENCE_URL   environment variable')\n\t    if not args.org and len(orgs) > 1:\n", "        missing_args.append('--org   or JIGGYBASE_ORG   environment variable')\n\t    if missing_args:\n\t        print(\"\\nError: The following required arguments are missing:\")\n\t        for arg in missing_args:\n\t            print(f\"- {arg}\")\n\t        print()\n\t        parser.print_help()\n\t        return\n\t    # Connect to Confluence API\n\t    confluence = Confluence(args.url, username=args.user, password=args.token)\n", "    # Get all spaces and find the matching space\n\t    all_spaces = confluence.get_all_spaces()\n\t    matching_space = None\n\t    for space in all_spaces['results']:\n\t        if args.space in [space['key'], space['name'], str(space['id'])]:\n\t            matching_space = space\n\t            break\n\t    if matching_space:\n\t        print(f\"Matched Space: {matching_space['name']} (ID: {matching_space['id']})\")\n\t    else:\n", "        print(\"No matching space found. Available spaces:\")\n\t        for space in all_spaces['results']:\n\t            print(f\"- {space['name']:20}  (ID: {space['id']})  key = {space['key']}\")\n\t        return\n\t    if len(orgs) == 1:\n\t        org = orgs[0]\n\t    else:\n\t        org = jb.get_org(args.org)\n\t    print(f\"Using JiggyBase org {org.name} (ID: {org.id})\")\n\t    sync_confluence_space_to_jiggybase_collection(confluence, matching_space, org)\n", "if __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "jiggybase/examples/chat_completion.py", "chunked_list": ["import jiggybase\n\tcollection = jiggybase.JiggyBase().collection('hackernews-summary')   # replace with your collection name\n\tmessages = [{'role':'user',  'content': 'articles about python 3.11'}]\n\trsp = collection._chat_completion(messages, temperature=0, model=\"gpt-3.5-turbo\")   # note _ as this is preliminary low-level interface\n\tprint(rsp)\n\t\"\"\"\n\tHere are some articles about Python 3.11:\n\t1. Python 3.11.1, 3.10.9, 3.9.16, 3.8.16, 3.7.16, and 3.12.0 alpha 3 now available - This is a blog post from the official Python Software Foundation blog. The post is announcing the release of Python 3.11.1, 3.10.9, 3.9.16, 3.8.16, 3.7.16, and 3.12.0 alpha 3. The post goes over some of the security content in the new releases.\n\t2. Python 3.11 Is Much Faster, but Pyston and PyPy Still Show Advantages - This is a news article from the website www.phoronix.com. It discusses the recent Python 3.11 beta benchmarks and compares them to alternative Python implementations like PyPy and Pyston. It also includes Python 3.11b3 results.\n\t3. A Team at Microsoft Is Helping Make Python Faster - This is a blog post about the Faster CPython Team at Microsoft. It details the team's mission to make Python faster, the specialized knowledge and collaboration of the team, and Microsoft's commitment to the Python community. It also highlights the team's work on Python 3.11 and their plans for Python 3.12.\n", "I hope this helps!\n\t\"\"\"\n"]}
