{"filename": "channelflow2d.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# channelflow2d.py: CFD solver from shenfun\n\t#\n\t# Mikael Mortenson\n\t#\n\tfrom warnings import WarningMessage\n\tfrom shenfun import *\n", "np.warnings.filterwarnings('ignore')\n\tclass KMM:\n\t    \"\"\"Navier Stokes channel flow solver in 2D\n\t    The wall normal direction is along the x-axis, the streamwise along the y-axis.\n\t    The solver is fully spectral with Chebyshev (or Legendre) in the wall-normal\n\t    direction and Fourier in the other.\n\t    Using the equations described by Kim, Moser, Moin (https://doi.org/10.1017/S0022112087000892)\n\t    but with the spectral Galerkin method in space and a chosen time stepper.\n\t    Parameters\n\t    ----------\n", "    N : 2-tuple of ints\n\t        The global shape in physical space (quadrature points)\n\t    domain : 2-tuple of 2-tuples\n\t        The size of the three domains\n\t    nu : Viscosity coefficient\n\t    dt : Timestep\n\t    conv : Choose convection method\n\t        - 0 - Standard convection\n\t        - 1 - Vortex type\n\t    filename : str, optional\n", "        Filenames are started with this name\n\t    family : str, optional\n\t        Chebyshev is normal, but Legendre works as well\n\t    padding_factor : 2-tuple of numbers, optional\n\t        For dealiasing, backward transforms to real space are\n\t        padded with zeros in spectral space using these many points\n\t    modplot : int, optional\n\t        Plot some results every modplot timestep. If negative, no plotting\n\t    modsave : int, optional\n\t        Save results to hdf5 every modsave timestep.\n", "    moderror : int, optional\n\t        Print diagnostics every moderror timestep\n\t    checkpoint : int, optional\n\t        Save required data for restart to hdf5 every checkpoint timestep.\n\t    timestepper : str, optional\n\t        Choose timestepper\n\t    Note\n\t    ----\n\t    Simulations may be killed gracefully by placing a file named 'killshenfun'\n\t    in the folder running the solver from. The solver will then first store\n", "    the results by checkpointing, before exiting.\n\t    \"\"\"\n\t    def __init__(self,\n\t                 N=(32, 32),\n\t                 domain=((-1, 1), (0, 2*np.pi)),\n\t                 nu=0.01,\n\t                 dt=0.1,\n\t                 conv=0,\n\t                 dpdy=1,\n\t                 filename='KMM',\n", "                 family='C',\n\t                 padding_factor=(1, 1.5),\n\t                 modplot=100,\n\t                 modsave=1e8,\n\t                 moderror=100,\n\t                 checkpoint=1000,\n\t                 timestepper='IMEXRK3'):\n\t        self.N = N\n\t        self.nu = nu\n\t        self.dt = dt\n", "        self.conv = conv\n\t        self.modplot = modplot\n\t        self.modsave = modsave\n\t        self.moderror = moderror\n\t        self.filename = filename\n\t        self.padding_factor = padding_factor\n\t        self.dpdy = dpdy\n\t        self.PDE = PDE = globals().get(timestepper)\n\t        self.im1 = None\n\t        # Regular spaces\n", "        self.B0 = FunctionSpace(N[0], family, bc=(0, 0, 0, 0), domain=domain[0])\n\t        self.D0 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])\n\t        self.C0 = FunctionSpace(N[0], family, domain=domain[0])\n\t        self.F1 = FunctionSpace(N[1], 'F', dtype='d', domain=domain[1])\n\t        self.D00 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])  # Streamwise velocity, not to be in tensorproductspace\n\t        self.C00 = self.D00.get_orthogonal()\n\t        # Regular tensor product spaces\n\t        self.TB = TensorProductSpace(comm, (self.B0, self.F1), modify_spaces_inplace=True) # Wall-normal velocity\n\t        self.TD = TensorProductSpace(comm, (self.D0, self.F1), modify_spaces_inplace=True) # Streamwise velocity\n\t        self.TC = TensorProductSpace(comm, (self.C0, self.F1), modify_spaces_inplace=True) # No bc\n", "        self.BD = VectorSpace([self.TB, self.TD])  # Velocity vector space\n\t        self.CD = VectorSpace(self.TD)             # Dirichlet vector space\n\t        # Padded space for dealiasing\n\t        self.TDp = self.TD.get_dealiased(padding_factor)\n\t        self.u_ = Function(self.BD)      # Velocity vector solution\n\t        self.H_ = Function(self.CD)      # convection\n\t        self.ub = Array(self.BD)\n\t        self.v00 = Function(self.D00)   # For solving 1D problem for Fourier wavenumber 0, 0\n\t        self.w00 = Function(self.D00)\n\t        self.work = CachedArrayDict()\n", "        self.mask = self.TB.get_mask_nyquist() # Used to set the Nyquist frequency to zero\n\t        self.X = self.TD.local_mesh(bcast=True)\n\t        self.K = self.TD.local_wavenumbers(scaled=True)\n\t        # Classes for fast projections. All are not used except if self.conv=0\n\t        self.dudx = Project(Dx(self.u_[0], 0, 1), self.TD)\n\t        if self.conv == 0:\n\t            self.dudy = Project(Dx(self.u_[0], 1, 1), self.TB)\n\t            self.dvdx = Project(Dx(self.u_[1], 0, 1), self.TC)\n\t            self.dvdy = Project(Dx(self.u_[1], 1, 1), self.TD)\n\t        self.curl = Project(curl(self.u_), self.TC)\n", "        self.divu = Project(div(self.u_), self.TC)\n\t        self.solP = None # For computing pressure\n\t        # File for storing the results\n\t        self.file_u = ShenfunFile('_'.join((filename, 'U')), self.BD, backend='hdf5', mode='w', mesh='uniform')\n\t        # Create a checkpoint file used to restart simulations\n\t        self.checkpoint = Checkpoint(filename,\n\t                                     checkevery=checkpoint,\n\t                                     data={'0': {'U': [self.u_]}})\n\t        # set up equations\n\t        v = TestFunction(self.TB)\n", "        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals and can use generic solvers.\n\t        sol1 = chebyshev.la.Biharmonic if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\t        self.pdes = {\n\t            'u': PDE(v,                                   # test function\n\t                     div(grad(self.u_[0])),               # u\n\t                     lambda f: self.nu*div(grad(f)),      # linear operator on u\n\t                     Dx(Dx(self.H_[1], 0, 1), 1, 1)-Dx(self.H_[0], 1, 2),\n\t                     dt=self.dt,\n\t                     solver=sol1,\n\t                     latex=r\"\\frac{\\partial \\nabla^2 u}{\\partial t} = \\nu \\nabla^4 u + \\frac{\\partial^2 N_y}{\\partial x \\partial y} - \\frac{\\partial^2 N_x}{\\partial y^2}\"),\n", "        }\n\t        # v. Solve divergence constraint for all wavenumbers except 0\n\t        r\"\"\":math:`\\nabla \\cdot \\vec{u} = 0`\"\"\"\n\t        # v. Momentum equation for Fourier wavenumber 0\n\t        if comm.Get_rank() == 0:\n\t            v0 = TestFunction(self.D00)\n\t            self.h1 = Function(self.D00)  # Copy from H_[1, :, 0, 0] (cannot use view since not contiguous)\n\t            source = Array(self.C00)\n\t            source[:] = -self.dpdy        # dpdy set by subclass\n\t            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.Solver\n", "            self.pdes1d = {\n\t                'v0': PDE(v0,\n\t                          self.v00,\n\t                          lambda f: self.nu*div(grad(f)),\n\t                          [-Expr(self.h1), source],\n\t                          dt=self.dt,\n\t                          solver=sol,\n\t                          latex=r\"\\frac{\\partial v}{\\partial t} = \\nu \\frac{\\partial^2 v}{\\partial x^2} - N_y - \\frac{\\partial p}{\\partial y}\"),\n\t            }\n\t    def convection(self):\n", "        H = self.H_.v\n\t        self.up = self.u_.backward(padding_factor=self.padding_factor)\n\t        up = self.up.v\n\t        if self.conv == 0:\n\t            dudxp = self.dudx().backward(padding_factor=self.padding_factor).v\n\t            dudyp = self.dudy().backward(padding_factor=self.padding_factor).v\n\t            dvdxp = self.dvdx().backward(padding_factor=self.padding_factor).v\n\t            dvdyp = self.dvdy().backward(padding_factor=self.padding_factor).v\n\t            H[0] = self.TDp.forward(up[0]*dudxp+up[1]*dudyp, H[0])\n\t            H[1] = self.TDp.forward(up[0]*dvdxp+up[1]*dvdyp, H[1])\n", "        elif self.conv == 1:\n\t            curl = self.curl().backward(padding_factor=self.padding_factor)\n\t            H[0] = self.TDp.forward(-curl*up[1])\n\t            H[1] = self.TDp.forward(curl*up[0])\n\t        self.H_.mask_nyquist(self.mask)\n\t    def compute_v(self, rk):\n\t        u = self.u_.v\n\t        if comm.Get_rank() == 0:\n\t            self.v00[:] = u[1, :, 0].real\n\t            self.h1[:] = self.H_[1, :, 0].real\n", "        # Find velocity components v from div. constraint\n\t        u[1] = 1j*self.dudx()/self.K[1]\n\t        # Still have to compute for wavenumber = 0, 0\n\t        if comm.Get_rank() == 0:\n\t            # v component\n\t            self.pdes1d['v0'].compute_rhs(rk)\n\t            u[1, :, 0] = self.pdes1d['v0'].solve_step(rk)\n\t        return u\n\t    def compute_pressure(self):\n\t        if self.solP is None:\n", "            self.d2udx2 = Project(self.nu*Dx(self.u_[0], 0, 2), self.TC)\n\t            N0 = self.N0 = FunctionSpace(self.N[0], self.B0.family(), bc={'left': {'N': self.d2udx2()}, 'right': {'N': self.d2udx2()}})\n\t            TN = self.TN = TensorProductSpace(comm, (N0, self.F1), modify_spaces_inplace=True)\n\t            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\t            self.divH = Inner(TestFunction(TN), -div(self.H_))\n\t            self.solP = sol(inner(TestFunction(TN), div(grad(TrialFunction(TN)))))\n\t            self.p_ = Function(TN)\n\t        self.d2udx2()\n\t        self.N0.bc.set_tensor_bcs(self.N0, self.TN)\n\t        p_ = self.solP(self.divH(), self.p_, constraints=((0, 0),))\n", "        return p_\n\t    def print_energy_and_divergence(self, t, tstep):\n\t        if tstep % self.moderror == 0 and self.moderror > 0:\n\t            ub = self.u_.backward(self.ub)\n\t            e0 = inner(1, ub[0]*ub[0])\n\t            e1 = inner(1, ub[1]*ub[1])\n\t            divu = self.divu().backward()\n\t            e3 = np.sqrt(inner(1, divu*divu))\n\t            if comm.Get_rank() == 0:\n\t                print(\"Time %2.5f Energy %2.6e %2.6e div %2.6e\" %(t, e0, e1, e3))\n", "    def init_from_checkpoint(self):\n\t        self.checkpoint.read(self.u_, 'U', step=0)\n\t        self.checkpoint.open()\n\t        tstep = self.checkpoint.f.attrs['tstep']\n\t        t = self.checkpoint.f.attrs['t']\n\t        self.checkpoint.close()\n\t        return t, tstep\n\t    def initialize(self, from_checkpoint=False):\n\t        if from_checkpoint:\n\t            return self.init_from_checkpoint()\n", "        raise RuntimeError('Initialize solver in subclass')\n\t    def plot(self, t, tstep):\n\t        pass\n\t    def update(self, t, tstep):\n\t        self.plot(t, tstep)\n\t        self.print_energy_and_divergence(t, tstep)\n\t    def tofile(self, tstep):\n\t        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n\t    def prepare_step(self, rk):\n\t        self.convection()\n", "    def assemble(self):\n\t        for pde in self.pdes.values():\n\t            pde.assemble()\n\t        if comm.Get_rank() == 0:\n\t            for pde in self.pdes1d.values():\n\t                pde.assemble()\n\t    def solve(self, t=0, tstep=0, end_time=1000):\n\t        self.assemble()\n\t        while t < end_time-1e-8:\n\t            for rk in range(self.PDE.steps()):\n", "                self.prepare_step(rk)\n\t                for eq in self.pdes.values():\n\t                    eq.compute_rhs(rk)\n\t                for eq in self.pdes.values():\n\t                    eq.solve_step(rk)\n\t                self.compute_v(rk)\n\t            t += self.dt\n\t            tstep += 1\n\t            self.update(t, tstep)\n\t            self.checkpoint.update(t, tstep)\n", "            if tstep % self.modsave == 0:\n\t                self.tofile(tstep)\n"]}
{"filename": "rb_marl.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# rb_marl.py: Rayleigh Benard CFD environment\n\t#\n\t# Colin Vignon & Joel Vasanth\n\t#\n\t# FLOW, KTH Stockholm | 09/04/2023\n\tfrom shenfun import *\n", "import matplotlib.pyplot as plt\n\timport sympy\n\timport os, csv, numpy as np\n\timport shutil\n\timport copy\n\tfrom time import time\n\tfrom mpi4py import MPI\n\tfrom tensorforce.environments import Environment\n\tfrom mpi4py_fft import generate_xdmf\n\tfrom channelflow2d import KMM\n", "from parameters import nb_actuations, num_episodes, num_servers, \\\n\t    simu_name, nb_inv_envs, simulation_duration\n\tnp.warnings.filterwarnings('ignore')\n\tx, y, tt = sympy.symbols('x,y,t', real=True)\n\tcomm = MPI.COMM_SELF\n\tclass RayleighBenard(KMM):\n\t    def __init__(self, N=(64, 96), domain=((-1, 1), (0, 2*sympy.pi)), Ra=10000., Pr=0.7, dt=0.05, bcT=(2, 1), \\\n\t         conv=0, filename='RB_2D', family='C', padding_factor=(1, 1.5), modplot=10, obsGrid=(8,32), modsave=10,  \\\n\t            moderror=10, checkpoint=10, timestepper='IMEXRK3'):\n\t        plt.close('all')\n", "        KMM.__init__(self, N=N, domain=domain, nu=np.sqrt(Pr/Ra), dt=dt, conv=conv,\n\t                     filename=filename, family=family, padding_factor=padding_factor,\n\t                     modplot=modplot, modsave=modsave, moderror=moderror,\n\t                     checkpoint=checkpoint, timestepper=timestepper, dpdy=0)\n\t        self.kappa = 1./np.sqrt(Pr*Ra)\n\t        self.bcT = bcT\n\t        plt.close('all')\n\t        # Additional spaces and functions for Temperature equation\n\t        self.T0 = FunctionSpace(N[0], family, bc=bcT, domain=domain[0])\n\t        self.TT = TensorProductSpace(comm, (self.T0, self.F1), modify_spaces_inplace=True) # Temperature\n", "        self.uT_ = Function(self.BD)     # Velocity vector times T\n\t        self.T_ = Function(self.TT)      # Temperature solution\n\t        self.Tb = Array(self.TT)\n\t        self.file_T = ShenfunFile('_'.join((filename, 'T')), self.TT, backend='hdf5', mode='w', mesh='uniform')\n\t        # Modify checkpoint file\n\t        self.checkpoint.data['0']['T'] = [self.T_]\n\t        dt = self.dt\n\t        kappa = self.kappa\n\t        self.N = N\n\t        sol2 = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n", "        # Addition to u equation.\n\t        self.pdes['u'].N = [self.pdes['u'].N, Dx(self.T_, 1, 2)]\n\t        self.pdes['u'].latex += r'\\frac{\\partial^2 T}{\\partial y^2}'\n\t        # Remove constant pressure gradient from v0 equation\n\t        self.pdes1d['v0'].N = self.pdes1d['v0'].N[0]\n\t        # Add T equation\n\t        q = TestFunction(self.TT)\n\t        self.pdes['T'] = self.PDE(q,\n\t                                  self.T_,\n\t                                  lambda f: kappa*div(grad(f)),\n", "                                  -div(self.uT_),\n\t                                  dt=self.dt,\n\t                                  solver=sol2,\n\t                                  latex=r\"\\frac{\\partial T}{\\partial t} = \\kappa \\nabla^2 T - \\nabla \\cdot \\vec{u}T\")\n\t        self.im1 = None\n\t        self.im2 = None\n\t        # Observation outputs\n\t        self.out = []\n\t        self.out2 = []\n\t        self.instant_Nusselt = []\n", "        self.instant_kinEn = []\n\t        # Others\n\t        self.obsGrid = obsGrid\n\t        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])\n\t    def update_bc(self, t):\n\t        # Update time-dependent bcs.\n\t        self.T0.bc.update(t)\n\t        self.T_.get_dealiased_space(self.padding_factor).bases[0].bc.update(t)\n\t    def prepare_step(self, rk):\n\t        self.convection()\n", "        Tp = self.T_.backward(padding_factor=self.padding_factor)\n\t        self.uT_ = self.up.function_space().forward(self.up*Tp, self.uT_)\n\t    def tofile(self, tstep):\n\t        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n\t        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n\t    def init_from_checkpoint(self):\n\t        self.checkpoint.read(self.u_, 'U', step=0)\n\t        self.checkpoint.read(self.T_, 'T', step=0)\n\t        self.checkpoint.open()\n\t        tstep = self.checkpoint.f.attrs['tstep']\n", "        t = self.checkpoint.f.attrs['t']\n\t        self.checkpoint.close()\n\t        return t, tstep\n\t    def print_energy_and_divergence(self, t, tstep):\n\t        if tstep % self.moderror == 0 and self.moderror > 0:\n\t            ub = self.u_.backward(self.ub)\n\t            Tb = self.T_.backward(self.Tb)\n\t            e0 = inner(1, ub[0]*ub[0])\n\t            e1 = inner(1, ub[1]*ub[1])\n\t            d0 = inner(1, Tb*Tb)\n", "            divu = self.divu().backward()\n\t            e3 = np.sqrt(inner(1, divu*divu))\n\t            if comm.Get_rank() == 0:\n\t                if tstep % (10*self.moderror) == 0 or tstep == 0:\n\t                    pass\n\t    def initialize(self, rand=0.001, from_checkpoint=False):\n\t        if from_checkpoint:\n\t            self.checkpoint.read(self.u_, 'U', step=0)\n\t            self.checkpoint.read(self.T_, 'T', step=0)\n\t            self.checkpoint.open()\n", "            tstep = self.checkpoint.f.attrs['tstep']\n\t            t = self.checkpoint.f.attrs['t']\n\t            self.checkpoint.close()\n\t            self.update_bc(t)\n\t            return t, tstep\n\t        X = self.X\n\t        fun = self.bcT[0]\n\t        self.Tb[:] = 0.5*(1 + 0.5*self.bcT[1]-X[0]/(1+self.bcT[1])+ 0.125*(2-self.bcT[1])\\\n\t                          *np.sin(np.pi*X[0]))*fun + rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n\t        self.T_ = self.Tb.forward(self.T_)\n", "        self.T_.mask_nyquist(self.mask)\n\t        return 0, 0\n\t    def outputs(self, tstep, count):\n\t        if (tstep == 0 or count == 0):  # Make sure to reinitialize the outputs when a brand new simulation is launched\n\t            self.out = []\n\t            self.out2 = []\n\t            self.out_red = []\n\t            self.out_red2 = []\n\t        else:\n\t            ub = self.u_.backward(self.ub) \n", "            Tb = self.T_.backward(self.Tb)\n\t            new_out = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n\t            new_out[0] = ub[1, ::self.Nstep[0], ::self.Nstep[1]]  # horizontal (x) axis\n\t            new_out[1] = ub[0, ::self.Nstep[0], ::self.Nstep[1]]  # vertical (y) axis\n\t            new_out[2] = Tb[::self.Nstep[0], ::self.Nstep[1]]\n\t            self.out.append(new_out)\n\t            # Normalization of the data\n\t            new_out2 = copy.copy(new_out)\n\t            new_out2[0]*= 1.5\n\t            new_out2[1]*= 1.5\n", "            new_out2[2] = 2*(new_out2[2] - 0.8)\n\t            new_out2 = new_out2.reshape(3*self.obsGrid[0]*self.obsGrid[1],)\n\t            self.out2.append(new_out2)\n\t    def DRL_inputs(self):  # inputs for the DRL algo\n\t        return np.mean(np.array([self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]), axis=0)\n\t    def compute_Nusselt(self):\n\t        '''Used just to have the evolution of Nu during the baseline simulation'''\n\t        div = self.kappa*(2.-self.bcT[1])/2  # H = 2, Tb = 2.\n\t        gen_Nus = []\n\t        for i in range(1,5):\n", "            uyT_ = np.mean(np.mean(np.multiply(self.out[-i][1], self.out[-i][2]), axis=1), axis = 0)\n\t            T_ = np.mean(np.gradient(np.mean(self.out[-i][2], axis=1), axis=0))\n\t            gen_Nus.append((uyT_ - self.kappa*T_)/div)\n\t        return np.mean(np.array(gen_Nus))\n\t    def compute_kinEn(self):\n\t        '''Used just to have the evolution of kinEn during the baseline simulation'''\n\t        u2_xy = self.out[-1][1]*self.out[-1][1] + self.out[-1][0]*self.out[-1][0]\n\t        return np.sum(u2_xy)\n\t    def evolve(self, new_bcT, t_ini=None, tstep_ini = None):\n\t        self.bcT = new_bcT    \n", "        new_t, new_tstep = t_ini, tstep_ini\n\t        self.T0.bc.bc['left']['D'] = self.bcT[0]\n\t        self.T0.bc.update()\n\t        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n\t        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]\n\t        TP0.bc.bc['left']['D'] = self.bcT[0]\n\t        TP0.bc.update()\n\t        TP0.bc.set_tensor_bcs(TP0, TP0.tensorproductspace)\n\t    def solve(self, which, t=0, tstep=0, end_time=1000, end_episode = False):\n\t        c = self.pdes['u'].stages()[2]\n", "        self.assemble()\n\t        count = 0\n\t        while t < end_time-1e-8:\n\t            for rk in range(self.PDE.steps()):\n\t                self.prepare_step(rk)\n\t                for eq in ['u', 'T']:\n\t                    self.pdes[eq].compute_rhs(rk)\n\t                for eq in ['u']:\n\t                    self.pdes[eq].solve_step(rk)\n\t                self.compute_v(rk)\n", "                self.update_bc(t+self.dt*c[rk+1])\n\t                self.pdes['T'].solve_step(rk)\n\t            self.outputs(tstep, count)\n\t            count += 1\n\t            if tstep >= 4 and which == 'baseline' and tstep%10 == 0:\n\t                self.instant_Nusselt.append(self.compute_Nusselt())\n\t                self.instant_kinEn.append(self.compute_kinEn())\n\t            t += self.dt\n\t            tstep += 1\n\t            self.update(t, tstep)\n", "            self.checkpoint.update(t, tstep)\n\t            if tstep % self.modsave == 0:\n\t                self.tofile(tstep)\n\t        if end_episode:\n\t            self.tofile(tstep-1)  \n\t            self.TT.destroy()  \n\t            self.TB.destroy()\n\t            self.TD.destroy()\n\t            self.TC.destroy()\n\t            self.TDp.destroy()\n", "            self.BD.destroy()\n\t            self.CD.destroy()\n\t        return t, tstep         \n\t    def define_timeframe(self, which, Evolve = False, new_bcT = None, t_ini = None, tstep_ini = None):\n\t        if which == 'baseline':\n\t            t, tstep = self.initialize(rand=0.001, from_checkpoint=False)\n\t            #self.evolve(new_bcT, t, tstep)\n\t        else:\n\t            if Evolve:\n\t                t, tstep = t_ini, tstep_ini\n", "            else:\n\t                t, tstep = self.initialize(rand=0.001, from_checkpoint=True)\n\t            self.evolve(new_bcT, t, tstep)\n\t        return t, tstep\n\t    def launch(self, timeframe, which, t_ini = None, tstep_ini = None, Evolve = False, End_episode = False):\n\t        t_end, tstep_end = self.solve(which, t=t_ini, tstep=tstep_ini, end_time=timeframe[1], end_episode = End_episode)\n\t        if which == 'baseline':\n\t            generate_xdmf('RB_'+str(self.N[0])+'_'+str(self.N[1])+'_T.h5')\n\t            generate_xdmf('RB_'+str(self.N[0])+'_'+str(self.N[1])+'_U.h5')\n\t        return self.DRL_inputs(), t_end, tstep_end\n"]}
{"filename": "rayleighbenard2d.py", "chunked_list": ["from shenfun import *\n\timport matplotlib.pyplot as plt\n\timport sympy\n\timport os, csv, numpy as np\n\timport shutil\n\timport copy\n\tfrom time import time\n\tfrom mpi4py import MPI\n\tfrom tensorforce.environments import Environment\n\tfrom channelflow2d import KMM\n", "#from witness import read_last_wit\n\tnp.warnings.filterwarnings('ignore')\n\t# pylint: disable=attribute-defined-outside-init\n\tx, y, tt = sympy.symbols('x,y,t', real=True)\n\tcomm = MPI.COMM_SELF\n\tclass RayleighBenard(KMM):\n\t    def __init__(self, N=(64, 96), domain=((-1, 1), (0, 2*sympy.pi)), Ra=10000., Pr=0.7, dt=0.05, bcT=(2, 1), conv=0, filename='RB_2D', family='C', padding_factor=(1, 1.5), modplot=10, obsGrid=(8,32), modsave=10, moderror=10, checkpoint=10, timestepper='IMEXRK3'):\n\t        plt.close('all')\n\t        KMM.__init__(self, N=N, domain=domain, nu=np.sqrt(Pr/Ra), dt=dt, conv=conv,\n\t                     filename=filename, family=family, padding_factor=padding_factor,\n", "                     modplot=modplot, modsave=modsave, moderror=moderror,\n\t                     checkpoint=checkpoint, timestepper=timestepper, dpdy=0)\n\t        self.kappa = 1./np.sqrt(Pr*Ra)\n\t        self.bcT = bcT\n\t        plt.close('all')\n\t        # Additional spaces and functions for Temperature equation\n\t        self.T0 = FunctionSpace(N[0], family, bc=bcT, domain=domain[0])\n\t        self.TT = TensorProductSpace(comm, (self.T0, self.F1), modify_spaces_inplace=True) # Temperature\n\t        self.uT_ = Function(self.BD)     # Velocity vector times T\n\t        self.T_ = Function(self.TT)      # Temperature solution\n", "        self.Tb = Array(self.TT)\n\t        self.file_T = ShenfunFile('_'.join((filename, 'T')), self.TT, backend='hdf5', mode='w', mesh='uniform')\n\t        # Modify checkpoint file\n\t        self.checkpoint.data['0']['T'] = [self.T_]\n\t        dt = self.dt\n\t        kappa = self.kappa\n\t        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals\n\t        sol2 = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\t        # Addition to u equation.\n\t        self.pdes['u'].N = [self.pdes['u'].N, Dx(self.T_, 1, 2)]\n", "        self.pdes['u'].latex += r'\\frac{\\partial^2 T}{\\partial y^2}'\n\t        # Remove constant pressure gradient from v0 equation\n\t        self.pdes1d['v0'].N = self.pdes1d['v0'].N[0]\n\t        # Add T equation\n\t        q = TestFunction(self.TT)\n\t        self.pdes['T'] = self.PDE(q,\n\t                                  self.T_,\n\t                                  lambda f: kappa*div(grad(f)),\n\t                                  -div(self.uT_),\n\t                                  dt=self.dt,\n", "                                  solver=sol2,\n\t                                  latex=r\"\\frac{\\partial T}{\\partial t} = \\kappa \\nabla^2 T - \\nabla \\cdot \\vec{u}T\")\n\t        self.im1 = None\n\t        self.im2 = None\n\t\t# Observation outputs\n\t        self.out = []\n\t        self.out2 = []\n\t        self.instant_Nusselt = []\n\t        self.instant_kinEn = []\n\t        # Others\n", "        self.obsGrid = obsGrid\n\t        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])\n\t    def update_bc(self, t):\n\t        # Update time-dependent bcs.\n\t        self.T0.bc.update(t)\n\t        self.T_.get_dealiased_space(self.padding_factor).bases[0].bc.update(t)\n\t    def prepare_step(self, rk):\n\t        self.convection()\n\t        Tp = self.T_.backward(padding_factor=self.padding_factor)\n\t        self.uT_ = self.up.function_space().forward(self.up*Tp, self.uT_)\n", "    def tofile(self, tstep):\n\t        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n\t        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n\t    def init_from_checkpoint(self):\n\t        self.checkpoint.read(self.u_, 'U', step=0)\n\t        self.checkpoint.read(self.T_, 'T', step=0)\n\t        self.checkpoint.open()\n\t        tstep = self.checkpoint.f.attrs['tstep']\n\t        t = self.checkpoint.f.attrs['t']\n\t        self.checkpoint.close()\n", "        return t, tstep\n\t    def print_energy_and_divergence(self, t, tstep):\n\t        if tstep % self.moderror == 0 and self.moderror > 0:\n\t            ub = self.u_.backward(self.ub)\n\t            Tb = self.T_.backward(self.Tb)\n\t            e0 = inner(1, ub[0]*ub[0])\n\t            e1 = inner(1, ub[1]*ub[1])\n\t            d0 = inner(1, Tb*Tb)\n\t            divu = self.divu().backward()\n\t            e3 = np.sqrt(inner(1, divu*divu))\n", "            if comm.Get_rank() == 0:\n\t                if tstep % (10*self.moderror) == 0 or tstep == 0:\n\t                    pass\n\t                    #print(f\"{'Time':^11}{'uu':^11}{'vv':^11}{'T*T':^11}{'div':^11}\")\n\t                #print(f\"{t:2.4e} {e0:2.4e} {e1:2.4e} {d0:2.4e} {e3:2.4e}\")\n\t    def initialize(self, rand=0.001, from_checkpoint=False):\n\t        if from_checkpoint:\n\t            self.checkpoint.read(self.u_, 'U', step=0)\n\t            self.checkpoint.read(self.T_, 'T', step=0)\n\t            self.checkpoint.open()\n", "            tstep = self.checkpoint.f.attrs['tstep']\n\t            t = self.checkpoint.f.attrs['t']\n\t            self.checkpoint.close()\n\t            self.update_bc(t)\n\t            return t, tstep\n\t        X = self.X\n\t        if self.bcT[0] == 1:\n\t            funT = 1\n\t        elif int(self.bcT[0]) == 0.6:\n\t            funT = 3\n", "        elif int(self.bcT[0]) == 2:\n\t            funT = 4\n\t        else:\n\t            funT = 2\n\t        fun = {1: 1,\n\t               2: (0.9+0.1*np.sin(2*X[1])),\n\t               3: 0.6,\n\t               4: 2.}[funT]\n\t        self.Tb[:] = 0.5*(1 + 0.5*self.bcT[1]-X[0]/(1+self.bcT[1])+ 0.125*(2-self.bcT[1])*np.sin(np.pi*X[0]))*fun + rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n\t        #self.Tb[:] = 0.5*(1-X[0]+0.25*np.sin(np.pi*X[0]))*fun+rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n", "        self.T_ = self.Tb.forward(self.T_)\n\t        self.T_.mask_nyquist(self.mask)\n\t        return 0, 0\n\t    #def init_plots(self):\n\t    #    self.ub = ub = self.u_.backward()\n\t    #    Tb = self.T_.backward(self.Tb)\n\t    #    if comm.Get_rank() == 0:\n\t    #        plt.figure(1, figsize=(6, 3))\n\t    #        self.im1 = plt.quiver(self.X[1][::4, ::4], self.X[0][::4, ::4], ub[1, ::4, ::4], ub[0, ::4, ::4], pivot='mid', scale=0.01)\n\t    #        plt.draw()\n", "    #        plt.figure(2, figsize=(6, 3))\n\t    #        self.im2 = plt.contourf(self.X[1][:, :], self.X[0][:, :], Tb[:, :], 100, cmap ='plasma')\n\t    #        plt.draw()\n\t    #        plt.pause(1e-6) \n\t    #def plot(self, t, tstep):\n\t    #    if self.im1 is None and self.modplot > 0:\n\t    #        self.init_plots()\n\t    #    if tstep % self.modplot == 0 and self.modplot > 0:\n\t    #        ub = self.u_.backward(self.ub)\n\t    #        self.Tb = self.T_.backward(self.Tb)\n", "    #        if comm.Get_rank() == 0:\n\t    #            plt.figure(1)\n\t    #            self.im1.set_UVC(ub[1, ::4, ::4], ub[0, ::4, ::4])\n\t    #            self.im1.scale = np.linalg.norm(ub[1])\n\t    #            plt.pause(1e-6)\n\t    #            plt.figure(2)\n\t    #            self.im2.axes.clear()\n\t    #            self.im2.axes.contourf(self.X[1][:, :], self.X[0][:, :], self.Tb[:, :], 100, cmap ='plasma')\n\t    #            self.im2.autoscale()\n\t    #            plt.pause(1e-6)\n", "    def outputs(self, tstep):\n\t    \tif tstep == 0:  # Make sure to reinitialize the outputs when a brand new simulation is launched\n\t            self.out = []\n\t            self.out2 = []\n\t            self.out_red = []\n\t            self.out_red2 = []\n\t        else:  # Bein20 environment with probes grid 8*8. Me: 16 horizontal, 8 vertical\n\t    \t    ub = self.u_.backward(self.ub)\n\t            Tb = self.T_.backward(self.Tb)\n\t    \t    new_out = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n", "    \t    new_out[0] = ub[1, ::self.Nstep[0], ::self.Nstep[1]]  # horizontal (x) axis\n\t    \t    new_out[1] = ub[0, ::self.Nstep[0], ::self.Nstep[1]]  # vertical (y) axis\n\t    \t    new_out[2] = Tb[::self.Nstep[0], ::self.Nstep[1]]\n\t    \t    self.out.append(new_out)\n\t    \t    new_out2 = copy.copy(new_out)\n\t    \t    new_out2[0]*= 1.5\n\t    \t    new_out2[1]*= 1.5\n\t    \t    new_out2[2] = 2*(new_out2[2] - 0.8)\n\t    \t    new_out2 = new_out2.reshape(3*self.obsGrid[0]*self.obsGrid[1],)\n\t    \t    self.out2.append(new_out2)\n", "    def DRL_inputs(self):  # inputs for the DRL algo\n\t        #inputs = [self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]  # Beintama takes into account the four last states\n\t        return np.mean(np.array([self.out2[-1], self.out2[-2], self.out2[-3], self.out2[-4]]), axis=0)\n\t       # else:\n\t        #    return self.out_red2[-1]\n\t    def compute_Nusselt(self):\n\t        div = self.kappa*(2.-self.bcT[1])/2  # H = 2, Tb = 2.\n\t        uyT_ = np.mean(np.mean(np.multiply(self.out[-1][1], self.out[-1][2]), axis=1), axis = 0)\n\t        T_ = np.mean(np.gradient(np.mean(self.out[-1][2], axis=1), axis=0))\n\t        gen_Nus = (uyT_ - self.kappa*T_)/div\n", "        uyT_2 = np.mean(np.mean(np.multiply(self.out[-2][1], self.out[-2][2]), axis=1), axis = 0)\n\t        T_2 = np.mean(np.gradient(np.mean(self.out[-2][2], axis=1), axis=0))\n\t        gen_Nus2 = (uyT_ - self.kappa*T_)/div\n\t        uyT_3 = np.mean(np.mean(np.multiply(self.out[-3][1], self.out[-3][2]), axis=1), axis = 0)\n\t        T_3 = np.mean(np.gradient(np.mean(self.out[-3][2], axis=1), axis=0))\n\t        gen_Nus3 = (uyT_ - self.kappa*T_)/div\n\t        uyT_4 = np.mean(np.mean(np.multiply(self.out[-4][1], self.out[-4][2]), axis=1), axis = 0)\n\t        T_4 = np.mean(np.gradient(np.mean(self.out[-4][2], axis=1), axis=0))\n\t        gen_Nus4 = (uyT_ - self.kappa*T_)/div\n\t        return np.mean(np.array([gen_Nus, gen_Nus2, gen_Nus3, gen_Nus4]))\n", "    def compute_kinEn(self):\n\t        u2_xy = self.out[-1][1]*self.out[-1][1] + self.out[-1][0]*self.out[-1][0]\n\t        return np.sum(u2_xy)\n\t    def evolve(self, new_bcT, t_ini=None, tstep_ini = None):\n\t        self.bcT = new_bcT    \n\t        new_t, new_tstep = t_ini, tstep_ini\n\t        self.T0.bc.bc['left']['D'] = self.bcT[0]\n\t        self.T0.bc.update()\n\t        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n\t        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]\n", "        TP0.bc.bc['left']['D'] = self.bcT[0]\n\t        TP0.bc.update()\n\t        TP0.bc.set_tensor_bcs(TP0, TP0.tensorproductspace)\n\t    def solve(self, which, t=0, tstep=0, end_time=1000, end_episode = False):\n\t        c = self.pdes['u'].stages()[2]\n\t        self.assemble()\n\t        #print('Temperature values of the segments : ', self.bcT)\n\t        while t < end_time-1e-8:\n\t            for rk in range(self.PDE.steps()):\n\t                self.prepare_step(rk)\n", "                for eq in ['u', 'T']:\n\t                    self.pdes[eq].compute_rhs(rk)\n\t                for eq in ['u']:\n\t                    self.pdes[eq].solve_step(rk)\n\t                self.compute_v(rk)\n\t                self.update_bc(t+self.dt*c[rk+1])\n\t                self.pdes['T'].solve_step(rk)\n\t            self.outputs(tstep)\n\t            if tstep >= 4 and which == 'baseline' and tstep%10 == 0:\n\t                self.instant_Nusselt.append(self.compute_Nusselt())\n", "                self.instant_kinEn.append(self.compute_kinEn())\n\t                #print('Nusselt at tstep : ', tstep, ' = ', self.instant_Nusselt[-1])\n\t            #elif tstep % 20 > 4 and which != 'baseline':\n\t             #   print('Nusselt at tstep : ', tstep, ' = ', self.compute_Nusselt())\n\t            t += self.dt\n\t            tstep += 1\n\t            self.update(t, tstep)\n\t            self.checkpoint.update(t, tstep)\n\t            if tstep % self.modsave == 0:\n\t                self.tofile(tstep)\n", "        if end_episode:\n\t            self.TT.destroy()  # To solve issue #19\n\t            self.TB.destroy()\n\t            self.TD.destroy()\n\t            self.TC.destroy()\n\t            self.TDp.destroy()\n\t            self.BD.destroy()\n\t            self.CD.destroy()\n\t        return t, tstep\n\t    def launch(self, timeframe, which, Evolve = False, End_episode = False, new_bcT = None, t_ini = None, tstep_ini = None):\n", "        #t0 = time()\n\t        if which == 'baseline':\n\t            t, tstep = self.initialize(rand=0.001, from_checkpoint=False)\n\t        else:\n\t            if Evolve:\n\t                t, tstep = t_ini, tstep_ini\n\t                self.evolve(new_bcT, t, tstep)\n\t            else:\n\t                t, tstep = self.initialize(rand=0.001, from_checkpoint=True)\n\t        t_end, tstep_end = self.solve(which, t=t, tstep=tstep, end_time=timeframe[1], end_episode = End_episode)\n", "        #plt.close('all')\n\t        #print('Computing time %2.4f'%(time()-t0))\n\t        return [self.compute_Nusselt(), self.compute_kinEn(), 0], self.DRL_inputs(), t_end, tstep_end\n"]}
{"filename": "deterministic.py", "chunked_list": ["#!/usr/bin/env python3\n\t# -*- coding: utf-8 -*-\n\t'''\n\tdeterministic.py: Deterministinc runner for trained agent evaluation\n\tCreated: 2/5/2023\n\tAuthor: Pol Suarez, adapted for shenfun by Colin Vignon\n\t'''\n\timport os, time, sys\n\timport subprocess\n\timport copy as cp\n", "from tensorforce.agents import Agent\n\tfrom tensorforce.execution import Runner\n\t# Change to your case name here \n\tcase_name = 'RB_2D_multiAgent_6_4pi'\n\tgeneral_path = os.getcwd()\n\t# Set case path \n\tcase_path = general_path+'/shenfun_files/cases/'+case_name\n\tsys.path.append(case_path)\n\tfrom MARL_env import Environment2D\n\tfrom parameters import nb_actuations, num_episodes, num_servers, simu_name, nb_inv_envs, n_seg\n", "# Set to Fasle for SARL \n\tMARL = True\n\tif MARL:\n\t    nb_envs = nb_inv_envs\n\telse:\n\t    nb_envs = num_servers\n\t# Begin timer\n\tinitial_time = time.time()\n\t# Read the list of nodes\n\tfp = open('nodelist','r')\n", "nodelist = [h.strip() for h in fp.readlines()]\n\tfp.close()\n\tdef split(environment, np):  \n\t    ''' input: one of the parallel environments (np); output: a list of nb_inv_envs invariant \n\t    environments identical to np. \n\t    Their ID card: (np, ni)\n\t    np:= number of the parallel environment. e.g. between [1,4] for 4 parallel environments\n\t    ni:= env_ID[1]:= number of the 'pseudo-parallel' invariant environment. e.g. between [1, 10] for 10 invariant envs\n\t    nb_inv_envs:= total number of 'pseudo-parallel' invariant environments. e.g. 10\n\t    '''\n", "    list_inv_envs = []\n\t    for i in range(nb_inv_envs):\n\t        env = cp.copy(environment)\n\t        env.ENV_ID = [np, i+1]\n\t        env.host=\"environment{}\".format((np-1)*nb_inv_envs + (i+1))\n\t        list_inv_envs.append(env)\n\t    return list_inv_envs\n\tenvironment_base = Environment2D(simu_name = simu_name, path=general_path, do_baseline=False, ENV_ID=[1,0], deterministic=True, host=\"environment1\", node=nodelist)  # Baseline\n\tenvironments_MARL = [split(environment_base, 1)[j] for j in range(nb_inv_envs)]\n\t# Load TensorForce Agent from saved agent during training \n", "agent = Agent.load(directory=os.path.join(case_path, 'saver_data'), format='checkpoint', environment=environment_base)\n\t# Initialise TensorForce Runner\n\trunner = Runner(agent=agent, environments=environments_MARL, remote='multiprocessing', max_episode_timesteps=5000)\n\t# Run the runner\n\trunner.run(num_episodes=nb_envs, evaluation=True)\n\t# Close agent, runner and end timer \n\trunner.close()\n\tagent.close()\n\tend_time = time.time()\n\tprint(\"Deterministic Runner time :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))\n"]}
{"filename": "sarl_env.py", "chunked_list": ["from shenfun import *\n\timport matplotlib.pyplot as plt\n\timport sympy\n\timport os, csv, numpy as np\n\timport shutil\n\timport time\n\timport json\n\tfrom tensorforce.environments import Environment\n\tfrom mpi4py import MPI\n\tfrom Tfunc import Tfunc\n", "from rayleighbenard2d import RayleighBenard\n\tfrom channelflow2d import KMM\n\tfrom parameters import case, simulation_params, reward_function, optimization_params, output_params, nb_proc, nb_actuations, nb_actuations_deterministic, n_seg, simu_name\n\tfrom env_utils import run_subprocess\n\tgeneral_path = os.getcwd()\n\tcase_path = general_path+'/data/'+simu_name\n\tos.chdir(case_path)\n\tnp.warnings.filterwarnings('ignore')\n\t# pylint: disable=attribute-defined-outside-init\n\tx, y, tt = sympy.symbols('x,y,t', real=True)\n", "comm = MPI.COMM_SELF\n\tclass Environment2D(Environment):\n\t    def __init__(self, simu_name, path, number_steps_execution=1, do_baseline=True, continue_training=False, deterministic=False, ENV_ID=-1, host='', node=None, inv_ID = 1, nb_inv_envs = 1):\n\t        #cr_start('ENV.init',0)\n\t        self.simu_name = simu_name\n\t        self.general_path = path\n\t        self.case_path = self.general_path+'/data/'+self.simu_name\n\t        self.case      = case\n\t        self.ENV_ID    = ENV_ID\n\t        self.host      = host\n", "        self.node      = node\n\t        self.number_steps_execution = number_steps_execution\n\t        self.reward_function        = reward_function\n\t        self.output_params          = output_params\n\t        self.optimization_params  = optimization_params\n\t        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n\t        self.last_time            = round(self.simulation_timeframe[1],3)\n\t        self.delta_t_smooth       = simulation_params[\"delta_t_smooth\"]\n\t        #self.smooth_func          = simulation_params[\"smooth_func\"]\n\t        # Others\n", "        self.n_seg = n_seg\n\t        N = (64, 96)  # (cartesian) meshgrid\n\t        self.obsGrid = output_params['nb_probes']  # (cartesian) grid of observation probes\n\t        self.dicTemp = {'T0':1., 'T1':1., 'T2':1., 'T3':1., 'T4':1., 'T5':1., 'T6':1., 'T7':1., 'T8':1., 'T9':1.}  # starting temperatures\n\t        self.d = {\n\t     \t    'N': N,\n\t            'Ra': 10000.,\n\t     \t    'Pr': 0.7,\n\t     \t    'dt': 0.05,\n\t     \t    'filename': f'RB_{N[0]}_{N[1]}',\n", "     \t    'conv': 0,\n\t     \t    'modplot': 1000,\n\t     \t    'obsGrid':self.obsGrid,\n\t    \t    'moderror': 10000,\n\t    \t    'modsave': 10000,\n\t     \t    'bcT': (Tfunc(nb_seg=n_seg, dicTemp=self.dicTemp).apply_T(y), 1),  # Tfunc: Temperature function of the lower boundary (enforce ten different temperatures on ten segments)\n\t     \t    'family': 'C',\n\t     \t    'checkpoint': 10,\n\t     \t    #'padding_factor': 1,\n\t     \t    'timestepper': 'IMEXRK3'\n", "     \t    }\n\t        self.simu = None\n\t        #postprocess values\n\t        self.history_parameters = {}\n\t        self.history_parameters['Nusselt'] = []\n\t        self.history_parameters['kinEn'] = []\n\t        self.history_parameters[\"time\"] = []\n\t        self.history_parameters[\"episode_number\"] = []\n\t        name=\"output.csv\"\n\t        # if we start from other episode already done\n", "        last_row = None\n\t        if(os.path.exists(\"saved_models/\"+name)):\n\t            with open(\"saved_models/\"+name, 'r') as f:\n\t                for row in reversed(list(csv.reader(f, delimiter=\";\", lineterminator=\"\\n\"))):\n\t                    last_row = row\n\t                    break\n\t        if(not last_row is None):\n\t            self.episode_number = int(last_row[0])\n\t            self.last_episode_number = int(last_row[0])\n\t        else:\n", "            self.last_episode_number = 0\n\t            self.episode_number = 0\n\t        self.episode_Nusselts = np.array([])\n\t        self.episode_kinEns = np.array([])\n\t        self.do_baseline = do_baseline\n\t        self.continue_training = continue_training\n\t        self.deterministic = deterministic\n\t        self.start_class()\n\t        self.do_baseline = True\n\t        #start episodes        \n", "        super().__init__()\n\t        #cr_stop('ENV.init',0)\n\t    ## Start baseline_flow from scratch, creating cfd setup\n\t    def start_class(self):\n\t        t0 = time.time()\n\t        self.clean(True)\n\t        self.create_baseline()\n\t        #----------------------------------------------------------------------\n\t        # Run the first case\n\t        t0 = time.time()\n", "        #shenfun run in baseline\n\t        self.run(which = 'reset')\n\t        print(\"Done. time elapsed : \", time.time() - t0)\n\t        # Get the new avg drag and lift and SAVE \n\t        self.action_count=0\n\t        if self.continue_training == True or self.deterministic == True:\n\t            temp_id = '{}'.format(self.host)\n\t        else:\n\t            temp_id = ''\n\t        self.check_id = True\n", "    def clean(self,full):\n\t        if full:\n\t            if self.do_baseline == True:\n\t                if os.path.exists(\"saved_models\"):\n\t                    run_subprocess('./','rm -r','saved_models')\n\t                ## Best model at the end of each episode\n\t                if os.path.exists(\"best_model\"):\n\t                    run_subprocess('./','rm -r','best_model')\n\t        else:\n\t            self.action_count = 1\n", "    def create_baseline(self):\n\t        if self.do_baseline == True:\n\t            os.mkdir(self.case_path+'/baseline')\n\t    def run(self, which, evolve = False): \n\t        if which == 'baseline':\n\t            os.chdir(self.case_path+'/baseline')\n\t            self.base = RayleighBenard(**self.d)\n\t            if self.do_baseline == True:\n\t                data_reward, self.probes_values, self.t_end_ini, self.tstep_end_ini = self.base.launch(self.simulation_timeframe, which)\n\t                self.t_end_baseline, self.tstep_end_baseline = self.t_end_ini, self.tstep_end_ini\n", "                evo_Nusselt_baseline = self.base.instant_Nusselt\n\t                evo_kinEn_baseline = self.base.instant_kinEn\n\t                with open('evo_Nusselt_baseline.json', 'w') as f:\n\t                    json.dump(evo_Nusselt_baseline, f)\n\t                with open('evo_kinEn_baseline.json', 'w') as f2:\n\t                    json.dump(evo_kinEn_baseline, f2)\n\t                info_baseline = [data_reward[0], data_reward[1], data_reward[2], self.t_end_ini, self.tstep_end_ini]+list(self.probes_values)\n\t                with open('data_baseline.json', 'w') as f3:\n\t                    json.dump(info_baseline, f3)\n\t            else:\n", "                with open('data_baseline.json', 'r') as f3:\n\t                    info_baseline = json.load(f3)\n\t                Nusselt, kinEn, meanFlow, self.t_end_ini, self.tstep_end_ini, self.probes_values = info_baseline[0], info_baseline[1], info_baseline[2], info_baseline[3], info_baseline[4], info_baseline[5:]\n\t                data_reward = [Nusselt, kinEn, meanFlow]  \n\t                self.t_end_baseline, self.tstep_end_baseline = self.t_end_ini, self.tstep_end_ini\n\t            print('baseline run finished')\n\t            os.chdir(self.case_path)          \n\t        elif which == 'reset':\n\t            os.chdir(self.case_path+'/baseline')\n\t            os.system('mkdir -p logs') \n", "            self.run('baseline')\n\t        elif which == 'execute':\n\t            casepath = os.path.join(self.case_path,'%s'%self.host,'EP_%d'%self.episode_number)\n\t            logsrun  = os.path.join('logs','log_last_execute_run.log')\n\t            logssets = os.path.join('logs','log_sets.log')\n\t            run_subprocess(casepath,'mkdir -p','logs') \n\t            os.chdir(casepath)\n\t            if self.action_count ==1:\n\t                self.d.update({'moderror':10000, 'modsave':10000})\n\t                self.simu = RayleighBenard(**self.d)\n", "                evolve = False\n\t            end_episode = (self.action_count == nb_actuations)\n\t            data_reward, self.probes_values, self.t_end_ini, self.tstep_end_ini = self.simu.launch(self.simulation_timeframe, which, evolve, end_episode, self.d.get('bcT'), self.t_end_ini, self.tstep_end_ini)\n\t            os.chdir(self.case_path)\n\t            return data_reward, self.probes_values\n\t    def save_history_parameters(self, nb_actuations):\n\t        # Save at the end of every episode\n\t        self.episode_Nusselts = np.append(self.episode_Nusselts, self.history_parameters['Nusselt'])\n\t        self.episode_kinEns = np.append(self.episode_kinEns, self.history_parameters['kinEn'])        \n\t        if self.action_count == nb_actuations or self.episode_number == 0:\n", "            self.last_episode_number = self.episode_number\n\t            last_instant_Nusselt = self.history_parameters['Nusselt'][-1]\n\t            last_instant_kinEn = self.history_parameters['kinEn'][-1]\n\t            if self.do_baseline == True:\n\t                name = \"output.csv\"\n\t                if(not os.path.exists(\"saved_models\")):\n\t                    os.mkdir(\"saved_models\")\n\t                if(not os.path.exists(\"saved_models/\"+name)):\n\t                    with open(\"saved_models/\"+name, \"w\") as csv_file:\n\t                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n", "                        if self.reward_function == 'Nusselt': \n\t                            spam_writer.writerow([\"Episode\", \"instantNusselt\"])\n\t                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n\t                        else: \n\t                            spam_writer.writerow([\"Episode\", \"instant_kinEn\"])\n\t                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n\t                else:\n\t                    with open(\"saved_models/\"+name, \"a\") as csv_file:\n\t                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                        if self.reward_function == 'Nusselt':\n", "                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n\t                        else:\n\t                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n\t            self.episode_Nusselts = np.array([])\n\t            self.episode_kinEns = np.array([])\n\t            if self.do_baseline == True:\n\t                if(os.path.exists(\"saved_models/output.csv\")):\n\t                    if(not os.path.exists(\"best_model\")):\n\t                        shutil.copytree(\"saved_models\", \"best_model\")\n\t                    else:\n", "                        with open(\"saved_models/output.csv\", 'r') as csvfile:\n\t                            data = csv.reader(csvfile, delimiter = ';')\n\t                            for row in data:\n\t                                lastrow = row\n\t                            last_iter = lastrow[1]\n\t                        with open(\"best_model/output.csv\", 'r') as csvfile:\n\t                            data = csv.reader(csvfile, delimiter = ';')\n\t                            for row in data:\n\t                                lastrow = row\n\t                            best_iter = lastrow[1]\n", "                        if float(best_iter) < float(last_iter):\n\t                            if(os.path.exists(\"best_model\")):\n\t                                shutil.rmtree(\"best_model\")\n\t                            shutil.copytree(\"saved_models\", \"best_model\")\n\t    def save_this_action(self):\n\t        name_a = \"output_actions.csv\"\n\t        if(not os.path.exists(\"actions\")):\n\t            os.mkdir(\"actions\")    \n\t        if(not os.path.exists(\"actions/{}\".format(self.host))):\n\t            os.mkdir(\"actions/{}\".format(self.host))\n", "        if(not os.path.exists(\"actions/{}/ep_{}/\".format(self.host, self.episode_number))):\n\t            os.mkdir(\"actions/{}/ep_{}/\".format(self.host, self.episode_number))\n\t        path_a = \"actions/{}/ep_{}/\".format(self.host, self.episode_number)\n\t        action_line = \"{}\".format(self.action_count)\n\t        for i in range(self.n_seg):\n\t            action_line = action_line + \"; {}\".format(self.action[i])\n\t        if(not os.path.exists(path_a+name_a)):\n\t            header_line = \"Action\"\n\t            for i in range(self.n_seg):\n\t                header_line = header_line + \"; Segment_{}\".format(i+1)  # TODO: \"Jet\" -> modify\n", "            with open(path_a+name_a, \"w\") as csv_file:\n\t                spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n\t                spam_writer.writerow([header_line])\n\t                spam_writer.writerow([action_line])\n\t        else:\n\t            with open(path_a+name_a, \"a\") as csv_file:\n\t                spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n\t                spam_writer.writerow([action_line])\n\t    def save_reward(self,reward, Nusselt):  \n\t        name_a = \"output_rewards.csv\"\n", "        name_N = \"output_Nusselts.csv\"  \n\t        if(not os.path.exists(\"rewards\")):\n\t            os.mkdir(\"rewards\")\n\t        if(not os.path.exists(\"rewards/{}\".format(self.host))):\n\t            os.mkdir(\"rewards/{}\".format(self.host))\n\t        if(not os.path.exists(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))):\n\t            os.mkdir(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))\n\t        path_a = \"rewards/{}/ep_{}/\".format(self.host, self.episode_number)\n\t        if(not os.path.exists(path_a+name_a)):\n\t                with open(path_a+name_a, \"w\") as csv_file:\n", "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([\"Action\", \"Reward\"])\n\t                    spam_writer.writerow([self.action_count, reward])\n\t                with open(path_a+name_N, \"w\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([\"Action\", \"Nusselt\"])\n\t                    spam_writer.writerow([self.action_count, Nusselt])\n\t        else:\n\t                with open(path_a+name_a, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n", "                    spam_writer.writerow([self.action_count, reward])\n\t                with open(path_a+name_N, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([self.action_count, Nusselt])\n\t    def save_final_reward(self,reward):  # TODO: nothing to change ?\n\t        name_a = \"output_final_rewards.csv\"\n\t        if(not os.path.exists(\"final_rewards\")):\n\t            os.mkdir(\"final_rewards\")\n\t        time.sleep(0.5)\n\t        if(not os.path.exists(\"final_rewards/{}\".format(self.host))):\n", "            os.mkdir(\"final_rewards/{}\".format(self.host))\n\t        path_a = \"final_rewards/{}/\".format(self.host)\n\t        if(not os.path.exists(path_a+name_a)):\n\t            with open(path_a+name_a, \"w\") as csv_file:\n\t                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                spam_writer.writerow([\"EPISODE\", \"REWARD\"])\n\t                spam_writer.writerow([self.episode_number, reward])\n\t        else:\n\t            with open(path_a+name_a, \"a\") as csv_file:\n\t                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n", "                spam_writer.writerow([self.episode_number, reward])\n\t    def save_comms_probes(self): \n\t        name_a = \"output_probes_comms.csv\"\n\t        if(not os.path.exists(\"probes_comms\")):\n\t            os.mkdir(\"probes_comms\")\n\t        if(not os.path.exists(\"probes_comms/ep_{}/\".format(self.episode_number))):\n\t            os.mkdir(\"probes_comms/ep_{}/\".format(self.episode_number))\n\t        path_a = \"probes_comms/ep_{}/\".format(self.episode_number)\n\t        if(not os.path.exists(path_a+name_a)):\n\t                with open(path_a+name_a, \"w\") as csv_file:\n", "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    array_acts = np.linspace(1, 24, dtype=int) \n\t                    spam_writer.writerow([\"Action\", array_acts])\n\t                    spam_writer.writerow([self.action_count, self.probes_values])\n\t        else:\n\t                with open(path_a+name_a, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([self.action_count, self.probes_values])\n\t    def recover_start(self):  \n\t        runpath = self.case_path\n", "        runbin  = 'cp -r'\n\t        runargs = self.case_path+'/baseline %s'%os.path.join('%s'%self.host,'EP_%d'%self.episode_number)\n\t        logs    = os.path.join(self.case_path+'/baseline','logs','log_restore_last_episode.log')\n\t        run_subprocess(runpath,runbin,runargs,log=logs)\n\t        self.action = np.zeros(self.n_seg)\n\t        self.t_end_ini, self.tstep_end_ini = self.t_end_baseline, self.tstep_end_baseline\n\t        if(self.episode_number>1):\n\t            runbin  = 'rm -r'\n\t            runargs = os.path.join('%s'%self.host,'EP_%d'%(self.episode_number-1))\n\t            if self.deterministic == False:\n", "               run_subprocess(runpath,runbin,runargs)\n\t    def create_cpuID(self):\n\t        os.chdir(self.general_path)\n\t        runpath = self.case_path\n\t        runbin  = 'mkdir'\n\t        if self.deterministic == False:\n\t            runargs = self.host\n\t            run_subprocess(runpath,runbin,runargs)\n\t            name = \"nodes\"\n\t            if(not os.path.exists(self.case_path+\"/{}/\".format(self.host)+name)):\n", "                with open(self.case_path+\"/{}/\".format(self.host)+name, \"w\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([\"Nodes in this learning\"])\n\t                    spam_writer.writerow([self.node])\n\t            else:\n\t                with open(self.case_path+\"/{}/\".format(self.host)+name, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([\"Nodes in this learning\"])\n\t                    spam_writer.writerow([self.node])\n\t        else:\n", "            runargs = 'deterministic'\n\t            run_subprocess(runpath,runbin,runargs,check_return=False)\n\t    def close(self):\n\t        super().close()       \n\t    def states(self):\n\t        return dict(type='float',\n\t                    shape=(3*self.obsGrid[0]*self.obsGrid[1], )\n\t                    ) \n\t    def actions(self):\n\t        \"\"\"Action is a list of n_seg capped values of Temp\"\"\"\n", "        return dict(type='float',\n\t                    shape=(self.n_seg), \n\t                           min_value=self.optimization_params[\"min_ampl_temp\"],\n\t                           max_value=self.optimization_params[\"max_ampl_temp\"]\n\t                    )\n\t    def execute(self, actions):\n\t        self.action = actions        \n\t        self.last_time = self.simulation_timeframe[1]\n\t        t1 = round(self.last_time,3)\n\t        t2 = t1 + self.delta_t_smooth\n", "        self.simulation_timeframe = [t1,t2]\n\t        simu_path = os.path.join(self.case_path,'%s'%self.host,'EP_%d'%self.episode_number)\n\t        if case == 'RB_2D':\n\t            for i in range(self.n_seg):\n\t                self.dicTemp.update({'T'+str(i):self.action[i]})  \n\t        self.d.update({'bcT':(Tfunc(nb_seg=n_seg, dicTemp=self.dicTemp).apply_T(y), 1)})\n\t        t0 = time.time()\n\t        data_reward, self.probes_values = self.run('execute', evolve=True)\n\t        self.history_parameters['Nusselt'].extend([data_reward[0]])\n\t        self.history_parameters['kinEn'].extend([data_reward[1]])\n", "        self.history_parameters[\"time\"].extend([self.last_time])\n\t        self.history_parameters[\"episode_number\"].extend([self.episode_number])\n\t        self.save_history_parameters(nb_actuations)\n\t        # Write the action\n\t        self.save_this_action()\n\t        # Compute the reward\n\t        reward = self.compute_reward(data_reward)\n\t        self.save_reward(reward, data_reward[0])\n\t        self.action_count += 1\n\t        if self.deterministic == False and self.action_count <= nb_actuations:\n", "            terminal = False  \n\t        elif self.deterministic == True and self.action_count <= nb_actuations_deterministic:\n\t            terminal = False  \n\t        else:\n\t            terminal = True   \n\t            self.save_final_reward(reward)\n\t            time.sleep(0.1)\n\t        return self.probes_values, terminal, reward\n\t    def reset(self):\n\t        \"\"\"Reset state\"\"\"\n", "        # Create a folder for each environment\n\t        if self.check_id == True:\n\t            self.create_cpuID()\n\t            self.check_id = False\n\t        # Clean\n\t        self.clean(False)\n\t        # Apply new time frame\n\t        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n\t        t1 = self.simulation_timeframe[0]\n\t        t2 = self.simulation_timeframe[1]\n", "        self.simulation_timeframe = [t1,t2]\n\t        # Advance in episode\n\t        self.episode_number += 1\n\t        if self.deterministic == True:\n\t            self.host = 'deterministic'\n\t        # Copy the baseline in the environment directory     \n\t        if self.action_count == 1:\n\t            self.recover_start()\n\t        NWIT_TO_READ=1 \n\t        filename     = os.path.join('shenfun_files','%s'%self.host,'EP_%d'%self.episode_number,'%s.nsi.wit'%self.case)\n", "        probes_value = self.probes_values\n\t        return probes_value      \n\t    def compute_reward(self, data):\n\t        if self.reward_function == 'Nusselt':  \n\t            reward = self.optimization_params[\"norm_reward\"]*(-data[0] + self.optimization_params[\"offset_reward\"])\n\t        elif self.reward_function == 'kinEn':  \n\t            reward = self.optimization_params[\"norm_reward\"]*(-data[1] + self.optimization_params[\"offset_reward\"])\n\t        elif self.reward_function == 'meanFlow':  \n\t            reward = self.optimization_params[\"norm_reward\"]*(-data[2] + self.optimization_params[\"offset_reward\"])\n\t        else:\n", "            print(\"ERROR: Choose 'Nusselt' or 'kinEn' or 'meanFlow' for the reward function\") \n\t        return reward         "]}
{"filename": "wrapper.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# wrapper.py: Wrapper file that serves as a link between the DRL (tensorforce environments) and the CFD (shenfun).\n\t#\n\t# Colin Vignon\n\t#\n\t# FLOW, KTH Stockholm | 09/04/2023\n\timport matplotlib.pyplot as plt\n", "import os, csv, numpy as np\n\timport shutil\n\timport time\n\timport json\n\timport copy as cp\n\timport sympy\n\timport random\n\tfrom shenfun import *\n\tfrom Tfunc import Tfunc \n\tfrom rb_marl import RayleighBenard\n", "from channelflow2d import KMM  \n\tfrom parameters import nb_inv_envs, n_seg, simu_name, num_servers, \\\n\t    num_episodes, CFD_params, simulation_params, alphaRestart\n\tx, y, tt = sympy.symbols('x,y,t', real=True)\n\tclass Wrapper():\n\t    def __init__(self, episode, general_path):\n\t        self.ep = episode\n\t        self.local_path = general_path+'/data/'+simu_name\n\t    def run_CFD(self, simu, env_ID, act, simulation_timeframe, which, evolve, End_episode, t_end_ini, tstep_end_ini):\n\t        ''' for all the invariant environments (of one parallel env),\n", "            run_CFD() runs a unique simulation and gives the results to all of them \n\t        '''\n\t        np = env_ID[0]\n\t        ep_path = self.local_path+'/CFD_n'+str(np)+'/EP_'+str(self.ep)+'/'\n\t        os.chdir(ep_path)\n\t        self.d = CFD_params['dico_d']\n\t        if env_ID[1]==1:  # the environment(s) with ID (., 1) launches the CFD simulation(s)\n\t            if act==1:\n\t                alpha = random.random()\n\t                if alpha > alphaRestart and self.ep > 1:\n", "                    os.system('cp '+self.local_path+'/CFD_n'+str(np)+'/EP_'+str(self.ep-1)+'/*.h5 '+ep_path)\n\t                else:\n\t                     os.system('cp '+self.local_path+'/baseline/*.h5 '+ep_path)\n\t                if self.ep > 1:  \n\t                    os.system('rm -r '+self.local_path+'/CFD_n'+str(np)+'/EP_'+str(self.ep-1))\n\t                simu = RayleighBenard(**self.d)\n\t                evolve = False\n\t            # prepare the lower boundary\n\t            actions = self.pull_actions(act, env_ID)\n\t            dicTemp = {'T'+str(i):actions[i] for i in range(n_seg)}\n", "            self.d.update({'bcT':(Tfunc(nb_seg=n_seg, dicTemp=dicTemp).apply_T(y), 1)})\n\t            # Launch simulation\n\t            t_ini, tstep_ini = simu.define_timeframe(which, evolve, \\\n\t                                                     self.d.get('bcT'), t_end_ini, tstep_end_ini)\n\t            if act == 1:\n\t                simulation_timeframe = [t_ini, t_ini+simulation_params[\"delta_t_smooth\"]]\n\t            probes_values, t_end_ini, tstep_end_ini = simu.launch(simulation_timeframe, which, \\\n\t                                                                  t_ini, tstep_ini, evolve, End_episode)\n\t            # low cost mode: clean useless files\n\t            if act > 1:\n", "                os.system('rm '+ep_path+'Results_ep'+str(self.ep)+'_env_'+\\\n\t                          str(np)+'_actuation_'+str(act-1)+'.json')\n\t                os.system('rm '+ep_path+'is_finished'+'_Actuation'+str(act-1)+'.csv')\n\t            # write results  \n\t            file_w = ep_path+'Results_ep'+str(self.ep)+'_env_'+str(np)+'_actuation_'+str(act)+'.json'\n\t            push_info = [t_end_ini, float(tstep_end_ini)]+actions+list(probes_values)\n\t            with open(file_w, 'w') as f:\n\t                json.dump(push_info, f)\n\t            # tell the other environments that the results are ready-to-be-read\n\t            open(ep_path+'is_finished'+'_Actuation'+str(act)+'.csv', 'w').close()  \n", "        else:\n\t            while(not os.path.isfile(ep_path+'is_finished'+'_Actuation'+str(act)+'.csv')):  \n\t                time.sleep(0.05)\n\t            file_r = ep_path+'Results_ep'+str(self.ep)+'_env_'+str(np)+'_actuation_'+str(act)+'.json'\n\t            with open(file_r, 'r') as f:\n\t               pull_info = json.load(f)\n\t            t_end_ini, tstep_end_ini, actions, probes_values = pull_info[0], pull_info[1],\\\n\t                  pull_info[2:2+n_seg], pull_info[2+n_seg:]\n\t        return probes_values, actions, t_end_ini, tstep_end_ini, simu\n\t    def run_baseline_CFD(self, base, do_baseline, simulation_timeframe, which):\n", "        if do_baseline == True:\n\t            dico = CFD_params['dico_d']\n\t            dico.update({'moderror':10, 'modsave':10}) \n\t            base = RayleighBenard(**dico)\n\t            t_ini, tstep_ini = base.define_timeframe(which)\n\t            probes_values, t_end_ini, tstep_end_ini = base.launch(simulation_timeframe, \\\n\t                                                                  which, t_ini, tstep_ini)\n\t            evo_Nusselt_baseline, evo_kinEn_baseline = base.instant_Nusselt, base.instant_kinEn\n\t            with open('evo_Nusselt_baseline.json', 'w') as f:\n\t                json.dump(evo_Nusselt_baseline, f)\n", "            with open('evo_kinEn_baseline.json', 'w') as f2:\n\t                json.dump(evo_kinEn_baseline, f2)\n\t            info_baseline = [t_end_ini, tstep_end_ini]+list(probes_values)\n\t            with open('data_baseline.json', 'w') as f3:\n\t                json.dump(info_baseline, f3)\n\t        else:\n\t            with open('data_baseline.json', 'r') as f3:\n\t                info_baseline = json.load(f3)\n\t            t_end_ini, tstep_end_ini, probes_values = info_baseline[0], \\\n\t                info_baseline[1], info_baseline[2:]\n", "        return probes_values, t_end_ini, tstep_end_ini, base\n\t    def env1_give_answers(self, Port, env_ID):\n\t        for par_env in range(num_servers):\n\t            for inv_env in range(2,nb_inv_envs+1):\n\t                c = 0\n\t                while c<30:\n\t                    try:\n\t                        socket_client((par_env+1, inv_env), PORT=Port-\\\n\t                                      (inv_env+nb_inv_envs*par_env))\n\t                        c+=50\n", "                    except:\n\t                        time.sleep(0.1)\n\t                        c +=1\n\t    def other_wait_env1(self, Port, env_ID):\n\t        socket_server(PORT=Port-(env_ID[1]+nb_inv_envs*(env_ID[0]-1)))\n\t    def merge_actions(self, action, actuation, env_ID):\n\t        CFD_path = self.local_path+'/CFD_n'+str(env_ID[0])\n\t        ep_path = CFD_path+'/EP_'+str(self.ep)\n\t        if env_ID[1]==1:  \n\t            if actuation==1:\n", "                if self.ep==1:\n\t                    os.mkdir(CFD_path)\n\t                os.mkdir(ep_path)\n\t            act_file = ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n\t                '_actuation'+str(actuation)+'.csv'\n\t            with open(act_file, 'a') as csv_file:\n\t                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                spam_writer.writerow([env_ID[1], action])\n\t        else:\n\t            while(not os.path.exists(ep_path)):\n", "                time.sleep(0.1)\n\t            act_file = ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n\t                '_actuation'+str(actuation)+'.csv'\n\t            with open(act_file, 'a') as csv_file:\n\t                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                spam_writer.writerow([env_ID[1], action])\n\t    def pull_actions(self, actuation, env_ID):\n\t        ep_path = self.local_path+'/CFD_n'+str(env_ID[0])+'/EP_'+str(self.ep)\n\t        Flag = False\n\t        while Flag == False:\n", "            with open(ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n\t                    '_actuation'+str(actuation)+'.csv', 'r') as f:\n\t                Flag = (len(f.readlines())==n_seg)\n\t        actions = {}        \n\t        with open(ep_path+'/Actions_ep'+str(self.ep)+'_env'+str(env_ID[0])+\\\n\t                  '_actuation'+str(actuation)+'.csv', 'r') as fbis:        \n\t            for line in fbis:\n\t                segment, action = line.split(';')\n\t                action = action.strip('\\n')\n\t                action = action.strip('[]')\n", "                actions.update({segment:float(action)})\n\t        Actions = []\n\t        for i in range(n_seg): \n\t            Actions.append(actions.get(str(i+1)))\n\t        return Actions\n"]}
{"filename": "train_sarl.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# Single-Agent Reinforcement Learning launcher\n\t#\n\t# train_sarl.py: main launcher for the SARL framework. \n\t#\n\t# Pol Suarez, Francisco Alcantara, Colin Vignon & Joel Vasanth\n\t#\n", "# FLOW, KTH Stockholm | 09/04/2023\n\tfrom __future__ import print_function, division\n\timport os, sys, time\n\tfrom tensorforce.agents import Agent\n\tfrom tensorforce.execution import Runner\n\tfrom env_utils     import run_subprocess, generate_node_list, read_node_list\n\t#### Set up which case to run\n\ttraining_case = \"RB_2D_SARL\"  \n\tsimu_name = training_case\n\tgeneral_path = os.getcwd()\n", "case_path = general_path+'/data/'+simu_name\n\tsys.path.append(case_path)\n\tos.system('rm -r '+case_path)\n\tos.mkdir(case_path)\n\tos.system('cp ./parameters/parameters_{}.py '.format(training_case)+case_path+'/parameters.py')\n\tfrom sarl_env import Environment2D\n\tfrom parameters import nb_actuations, num_episodes, num_servers, simu_name\n\t#### Run\n\tinitial_time = time.time()\n\t# Generate the list of nodes\n", "generate_node_list(num_servers=num_servers) \n\t# Read the list of nodes\n\tnodelist = read_node_list()\n\tprint(\"\\n\\nDRL for 2D Rayleigh-Benard convection\\n\")\n\tprint(\"---------------------------------------\\n\")\n\tprint('Case: '+simu_name+' (Single-Agent RL)\\n')\n\tenvironment_base = Environment2D(simu_name=simu_name, path=general_path, node=nodelist[0]) # Baseline  #+simu_name\n\tnetwork = [dict(type='dense', size=512), dict(type='dense', size=512)]\n\tagent = Agent.create(\n\t    # Agent + Environment\n", "    agent='ppo', environment=environment_base, max_episode_timesteps=nb_actuations,\n\t    # Network\n\t    network=network,\n\t    # Optimization\n\t    batch_size=20, learning_rate=1e-3, subsampling_fraction=0.2, multi_step=25,\n\t    # Reward estimation\n\t    likelihood_ratio_clipping=0.2, predict_terminal_values=True,\n\t    baseline=network,\n\t    baseline_optimizer=dict(\n\t        type='multi_step', num_steps=5,\n", "        optimizer=dict(type='adam', learning_rate=1e-3)\n\t    ),\n\t    # Regularization\n\t    entropy_regularization=0.01,\n\t    parallel_interactions=num_servers,\n\t    saver=dict(directory=os.path.join(os.getcwd(), 'saver_data'), frequency=1, max_checkpoints=1),#parallel_interactions=number_servers,\n\t)\n\tenvironments = [Environment2D(simu_name=simu_name, path=general_path, do_baseline=False, ENV_ID=i, host=\"environment{}\".format(i+1), node=nodelist[i+1]) for i in range(num_servers)]\n\t#start all environments at the same time\n\trunner = Runner(agent=agent, environments=environments, remote='multiprocessing')\n", "#now start the episodes and sync_episodes is very useful to update the DANN efficiently\n\trunner.run(num_episodes=num_episodes, sync_episodes=False)\n\trunner.close()\n\t#saving all the model data in model-numpy format \n\tagent.save(directory=os.path.join(os.getcwd(),'model-numpy'), format='numpy', append='episodes')\n\tagent.close()\n\tend_time = time.time()\n\tprint(\"DRL simulation :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))\n"]}
{"filename": "reward_functions.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# reward_functions.py: computes reward, Nusselt number and kinetic energy.\n\t#\n\t# Colin Vignon\n\t#\n\t# FLOW, KTH Stockholm | 09/04/2023\n\timport copy as cp\n", "import numpy as np\n\tfrom parameters import CFD_params, nb_inv_envs, optimization_params\n\tdef compute_reward(probes_values, reward_function):\n\t    out = cp.copy(probes_values)\n\t    obsGrid = CFD_params.get('dico_d').get('obsGrid')\n\t    out2 = np.array(out).reshape(3, obsGrid[0], obsGrid[1])\n\t    #un-normalization of the data\n\t    out2[0] *= 1/1.5  # horizontal speed (ux) un-normalization\n\t    out2[1] *= 1/1.5  # vertical speed (uy)  un-normalization\n\t    out2[2] *= 1/2  # temperature un-normalization\n", "    out2[2] += 0.8\n\t    hor_inv_probes = CFD_params.get('hor_inv_probes')\n\t    out_red = np.zeros((3, obsGrid[0], hor_inv_probes))  \n\t    out_red = out2[:, :, (nb_inv_envs//2)*hor_inv_probes:((nb_inv_envs//2)+1)*hor_inv_probes]  \n\t    kappa = 1./np.sqrt(CFD_params.get('dico_d').get('Pr')*CFD_params.get('dico_d').get('Ra'))\n\t    T_up = CFD_params['dico_d'].get('bcT')[1]\n\t    div = kappa*(2.-T_up)/2  # H = 2, Tb = 2.\n\t    uyT_ = np.mean(np.mean(np.multiply(out2[1], out2[2]), axis=1), axis = 0)\n\t    T_ = np.mean(np.gradient(np.mean(out2[2], axis=1), axis=0))\n\t    gen_Nus = (uyT_ - kappa*T_)/div\n", "    uyT_loc = np.mean(np.mean(np.multiply(out_red[1], out_red[2]), axis=1), axis = 0)\n\t    T_loc = np.mean(np.gradient(np.mean(out_red[2], axis=1), axis=0))\n\t    loc_Nus = (uyT_loc - kappa*T_loc)/div\n\t    gen_kinEn = np.sum(out2[1]*out2[1] + out2[0]*out2[0])\n\t    loc_kinEn = np.sum(out_red[1]*out_red[1] + out_red[0]*out_red[0])\n\t    Reward_Nus   = 0.9985*gen_Nus + 0.0015*loc_Nus\n\t    Reward_kinEn = 0.4*gen_kinEn + 0.6*loc_kinEn\n\t    if reward_function == 'Nusselt':\n\t        reward = optimization_params[\"norm_reward\"]*(-Reward_Nus + optimization_params[\"offset_reward\"])\n\t    elif reward_function == 'kinEn':\n", "        reward = optimization_params[\"norm_reward\"]*(-Reward_kinEn + optimization_params[\"offset_reward\"])\n\t    elif reward_function == 'meanFlow':\n\t        reward = None\n\t        print(\"ERROR: 'meanFlow' not encoded yet\")\n\t    else:\n\t        print(\"ERROR: Choose 'Nusselt' or 'kinEn' or 'meanFlow' for the reward function\") \n\t    return reward, gen_Nus, gen_kinEn"]}
{"filename": "train_marl.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# Multi-Agent Reinforcement Learning launcher\n\t#\n\t# train_marl.py: main launcher for the MARL framework. \n\t#\n\t# Pol Suarez, Francisco Alcantara, Colin Vignon & Joel Vasanth\n\t#\n", "# FLOW, KTH Stockholm | 09/04/2023\n\tfrom __future__ import print_function, division\n\timport os, sys\n\timport copy as cp\n\timport time\n\tfrom tensorforce.agents import Agent\n\tfrom tensorforce.execution import Runner\n\tfrom env_utils import run_subprocess, generate_node_list, read_node_list\n\t#### Set up which case to run:\n\t# this is the name of the parameters file without the 'parameters_' prefix\n", "training_case = \"RB_2D_MARL\"  \n\tsimu_name = training_case\n\tgeneral_path = os.getcwd()\n\tcase_path = general_path+'/data/'+simu_name\n\tsys.path.append(case_path)\n\ttry:\n\t    os.system('rm -r '+case_path)\n\texcept:\n\t    print('No existing case with this name')\n\tos.mkdir(case_path)\n", "os.system('cp ./parameters/parameters_{}.py '.format(training_case)+case_path+'/parameters.py')\n\tfrom marl_env import Environment2D \n\tfrom parameters import nb_actuations, num_episodes, num_servers, simu_name, nb_inv_envs\n\t#### Run\n\tinitial_time = time.time()\n\t# Generate the list of nodes\n\tgenerate_node_list(num_servers=num_servers) \n\tnodelist = read_node_list()\n\tprint(\"\\n\\nDRL for 2D Rayleigh-Benard convection\\n\")\n\tprint(\"---------------------------------------\\n\")\n", "print('Case: '+simu_name+' (Multi-Agent RL)\\n')\n\tenvironment_base = Environment2D(simu_name=simu_name, path=general_path, node=nodelist[0])\n\tnetwork = [dict(type='dense', size=512), dict(type='dense', size=512)]\n\t# Define tensorforce agent\n\tagent = Agent.create(\n\t    # Agent + Environment\n\t    agent='ppo', environment=environment_base, max_episode_timesteps=nb_actuations,\n\t    # Network\n\t    network=network,\n\t    # Optimization\n", "    batch_size=20, learning_rate=1e-3, subsampling_fraction=0.2, multi_step=25,\n\t    # Reward estimation\n\t    likelihood_ratio_clipping=0.2, predict_terminal_values=True,\n\t    # Critic\n\t    baseline=network,\n\t    baseline_optimizer=dict(\n\t        type='multi_step', num_steps=5,\n\t        optimizer=dict(type='adam', learning_rate=1e-3)\n\t    ),\n\t    # Regularization\n", "    entropy_regularization=0.01,\n\t    parallel_interactions=num_servers*nb_inv_envs,\n\t    saver=dict(directory=os.path.join(os.getcwd(), 'saver_data'), frequency=1, max_checkpoints=1),\n\t)\n\tdef split(environment, np): \n\t    ''' input: one of the parallel environments (np); \n\t        output: a list of nb_inv_envs invariant environments identical to np. \n\t        Their ID card: (np, ni)\n\t    '''\n\t    list_inv_envs = []\n", "    for i in range(nb_inv_envs):\n\t        env = cp.copy(environment)\n\t        env.ENV_ID = [np, i+1]\n\t        env.host=\"environment{}\".format((np-1)*nb_inv_envs + (i+1))\n\t        list_inv_envs.append(env)\n\t    return list_inv_envs\n\tparallel_environments = [Environment2D(simu_name=simu_name, path=general_path, do_baseline=False, \\\n\t                                       ENV_ID=[i+1,0], host=\"environment{}\".format(i+1), node=nodelist[i+1]) \\\n\t                                        for i in range(num_servers)]\n\tenvironments = [split(parallel_environments[i], i+1)[j] for i in range(num_servers) for j in range(nb_inv_envs)]\n", "runner = Runner(agent=agent, environments=environments, remote='multiprocessing')    \n\trunner.run(num_episodes=num_episodes, sync_episodes=False)\n\trunner.close()\n\tagent.save(directory=os.path.join(os.getcwd(),'model-numpy'), format='numpy', append='episodes')\n\tagent.close()\n\tfor env in environments:\n\t    env.close()\n\tend_time = time.time()\n\tprint(\"DRL simulation :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))\n"]}
{"filename": "Tfunc.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# Tfunc.py: defines temperature profiles on bottom wall that are fed to agent for actuation \n\t#\n\t# Colin Vignon\n\t#\n\t# FLOW, KTH Stockholm | 09/04/2023\n\tfrom shenfun import *\n", "import sympy\n\tfrom sympy.parsing.sympy_parser import parse_expr\n\tdomain = ((-1, 1), (0, 2*sympy.pi))\n\tclass Tfunc():\n\t\tdef __init__(self, nb_seg = None, dicTemp = None):\n\t\t\t''' N = number of actuators/segments on the hot boundary layer\n\t\t\tdicTemp = temperature variations of the segments: Ti' = Tnormal + Ti, Tnormal = 0.6 here''' \n\t\t\tself.nb_seg = nb_seg\n\t\t\tself.dicTemp = dicTemp\n\t\t\t# Amplitude of variation of T\n", "\t\tself.ampl = 0.75  \n\t\t\t# half-length of the interval on which we do the smoothing\n\t\t\tself.dx = 0.03  \n\t\tdef apply_T(self, x):\n\t\t\tvalues = self.ampl*np.array(list(self.dicTemp.values()))\n\t\t\tMean = values.mean()\n\t\t\tK2 = max(1, np.abs(values-np.array([Mean]*self.nb_seg)).max()/self.ampl)\n\t\t\t# Position:\n\t\t\txmax = domain[1][1]\n\t\t\tind = sympy.floor(self.nb_seg*x//xmax)\n", "\t\tseq=[]\n\t\t\tcount = 0\n\t\t\twhile count<self.nb_seg-1:  # Temperatures will vary between: 2 +- 0.75\n\t\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count+1))-Mean)/K2\n\t\t\t\tif count == 0:\n\t\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(self.nb_seg-1))-Mean)/K2\n\t\t\t\telse:\n", "\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))  # cubic smoothing\t\t\n\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, x<x1))  # cubic smoothing\n\t\t\t\tcount += 1\n\t\t\t\tif count == self.nb_seg-1:\n\t\t\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n", "\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T0\")-Mean)/K2\n\t\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))\n\t\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, True))\n\t\t\treturn sympy.Piecewise(*seq)\n"]}
{"filename": "marl_env.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# marl_env.py: Defines the tensorforce environments and adapts them for use in the MARL framework.\n\t#\n\t# Colin Vignon & Joel Vasanth\n\t#\n\t# FLOW, KTH Stockholm | 09/04/2023\n\tfrom shenfun import *\n", "import matplotlib.pyplot as plt\n\timport sympy\n\timport os, csv, numpy as np\n\timport shutil\n\timport time\n\timport json\n\t# Environment\n\tfrom tensorforce.environments import Environment\n\tfrom mpi4py import MPI\n\tfrom wrapper import Wrapper\n", "from reward_functions import compute_reward\n\timport copy as cp\n\tfrom parameters import CFD_params, simulation_params, reward_function, optimization_params, \\\n\t    nb_proc, nb_actuations, nb_actuations_deterministic, simu_name, nb_inv_envs\n\tfrom env_utils import run_subprocess\n\tgeneral_path = os.getcwd()\n\tcase_path = general_path+'/data/'+simu_name\n\tos.chdir(case_path)\n\tnp.warnings.filterwarnings('ignore')\n\tx, y, tt = sympy.symbols('x,y,t', real=True)\n", "comm = MPI.COMM_SELF\n\tclass Environment2D(Environment):\n\t    def __init__(self, simu_name, path, number_steps_execution=1, do_baseline=True, \\\n\t                 continue_training=False, deterministic=False, ENV_ID=[1,1], host='', node=None):\n\t        self.simu_name = simu_name\n\t        self.general_path = path\n\t        self.case_path = self.general_path+'/data/'+self.simu_name\n\t        self.ENV_ID    = ENV_ID\n\t        self.nb_inv_envs = nb_inv_envs\n\t        self.host      = host\n", "        self.node      = node\n\t        self.number_steps_execution = number_steps_execution\n\t        self.reward_function        = reward_function\n\t        self.optimization_params  = optimization_params\n\t        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n\t        self.last_time            = round(self.simulation_timeframe[1],3)\n\t        self.delta_t_smooth       = simulation_params[\"delta_t_smooth\"]\n\t        #### CFD-related attributes\n\t         # number of segments on the lower boundary\n\t        self.n_acts = CFD_params['number_of_actuators'] \n", "        # (cartesian) grid of probes\n\t        self.obsGrid = CFD_params['dico_d'].get('obsGrid')  \n\t        # number of columns of probes per invariant environment\n\t        self.hor_inv_probes = CFD_params.get('hor_inv_probes')  \n\t        self.simu = None\n\t        self.base = None\n\t        # postprocess values\n\t        self.history_parameters = {}\n\t        self.history_parameters['Nusselt'] = []\n\t        self.history_parameters['kinEn'] = []\n", "        self.history_parameters[\"time\"] = []\n\t        self.history_parameters[\"episode_number\"] = []\n\t        name=\"output.csv\"\n\t        # if we start from other episode already done\n\t        last_row = None\n\t        if(os.path.exists(\"saved_models/\"+name)):\n\t            with open(\"saved_models/\"+name, 'r') as f:\n\t                for row in reversed(list(csv.reader(f, delimiter=\";\", lineterminator=\"\\n\"))):\n\t                    last_row = row\n\t                    break\n", "        if(not last_row is None):\n\t            self.episode_number = int(last_row[0])\n\t            self.last_episode_number = int(last_row[0])\n\t        else:\n\t            self.last_episode_number = 0\n\t            self.episode_number = 0\n\t        self.episode_Nusselts = np.array([])\n\t        self.episode_kinEns = np.array([])\n\t        self.do_baseline = do_baseline\n\t        self.continue_training = continue_training\n", "        self.deterministic = deterministic\n\t        self.start_class()\n\t        self.do_baseline = True\n\t        #start episodes        \n\t        super().__init__()\n\t    #### Start baseline_flow from scratch, creating cfd setup\n\t    def start_class(self):\n\t        self.clean(True)\n\t        self.create_baseline()\n\t        t0 = time.time()\n", "        self.run(which = 'reset', ep = None)\n\t        print(\"Done. Time elapsed : \", np.round(time.time() - t0, 3),\" seconds\\n\")\n\t        self.action_count=0\n\t        if self.continue_training == True or self.deterministic == True:\n\t            temp_id = '{}'.format(self.host)\n\t        else:\n\t            temp_id = ''\n\t        self.check_id = True\n\t    def clean(self,full):\n\t        if full:\n", "            if self.do_baseline == True:\n\t                if os.path.exists(\"saved_models\"):\n\t                    run_subprocess('./','rm -r','saved_models')        \n\t        else:\n\t            self.action_count = 1\n\t    def create_baseline(self):\n\t        if self.do_baseline == True:\n\t            os.mkdir(self.case_path+'/baseline')\n\t    def run(self, which, ep, evolve=False): \n\t         # Run a simulation with shenfun\n", "        if which == 'baseline':\n\t            os.chdir(self.case_path+'/baseline')\n\t            wrap = Wrapper(ep, self.general_path)\n\t            print(\"Running baseline simulation ... \")\n\t            self.probes_values, self.t_end_ini, self.tstep_end_ini, \\\n\t                self.base = wrap.run_baseline_CFD(self.base, self.do_baseline, \\\n\t                                                  self.simulation_timeframe, which)\n\t            self.t_end_baseline, self.tstep_end_baseline = self.t_end_ini, self.tstep_end_ini\n\t            os.chdir(self.case_path)\n\t        elif which == 'reset':\n", "            os.chdir(self.case_path+'/baseline')\n\t            os.system('mkdir -p logs') # Create logs folder\n\t            self.run('baseline', ep)\n\t        elif which == 'execute':\n\t            wrap = Wrapper(ep, self.general_path)\n\t            end_episode = (self.action_count == nb_actuations)\n\t            self.probes_values, self.actions, self.t_end_ini, self.tstep_end_ini, \\\n\t                self.simu = wrap.run_CFD(self.simu, self.ENV_ID, self.action_count, \\\n\t                                         self.simulation_timeframe, which, evolve, \\\n\t                                         end_episode, self.t_end_ini, self.tstep_end_ini)\n", "            if self.action_count == 1:\n\t                self.simulation_timeframe = [self.t_end_ini-self.delta_t_smooth, self.t_end_ini]            \n\t            os.chdir(self.case_path)\n\t            return self.probes_values\n\t    def save_history_parameters(self, nb_actuations):\n\t        # Save at the end of every episode\n\t        self.episode_Nusselts = np.append(self.episode_Nusselts, self.history_parameters['Nusselt'])\n\t        self.episode_kinEns = np.append(self.episode_kinEns, self.history_parameters['kinEn'])        \n\t        if self.action_count == nb_actuations or self.episode_number == 0:\n\t            self.last_episode_number = self.episode_number\n", "            last_instant_Nusselt = self.history_parameters['Nusselt'][-1]\n\t            last_instant_kinEn = self.history_parameters['kinEn'][-1]\n\t            if self.do_baseline == True:\n\t                name = \"output.csv\"\n\t                if(not os.path.exists(\"saved_models\")):\n\t                    try:\n\t                        os.mkdir(\"saved_models\")\n\t                    except:\n\t                        pass\n\t                if(not os.path.exists(\"saved_models/\"+name)):\n", "                    with open(\"saved_models/\"+name, \"w\") as csv_file:\n\t                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                        if self.reward_function == 'Nusselt': \n\t                            spam_writer.writerow([\"Episode\", \"instantNusselt\"])\n\t                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n\t                        else: \n\t                            spam_writer.writerow([\"Episode\", \"instant_kinEn\"])\n\t                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n\t                else:\n\t                    with open(\"saved_models/\"+name, \"a\") as csv_file:\n", "                        spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                        if self.reward_function == 'Nusselt':\n\t                            spam_writer.writerow([self.last_episode_number, last_instant_Nusselt])\n\t                        else:\n\t                            spam_writer.writerow([self.last_episode_number, last_instant_kinEn])\n\t            self.episode_Nusselts = np.array([])\n\t            self.episode_kinEns = np.array([])\n\t            if self.do_baseline == True:\n\t                pass\n\t    def save_this_action(self):\n", "        if self.ENV_ID[1] == 1:\n\t            name_a = \"output_actions.csv\"\n\t            if(not os.path.exists(\"actions\")):\n\t                try:\n\t                    os.mkdir(\"actions\")    \n\t                except:\n\t                    pass\n\t            if(not os.path.exists(\"actions/ep_{}/\".format(self.episode_number))):\n\t                os.mkdir(\"actions/ep_{}/\".format(self.episode_number))\n\t            path_a = \"actions/ep_{}/\".format(self.episode_number)\n", "            action_line = \"{}\".format(self.action_count)\n\t            for i in range(self.n_acts):\n\t                action_line = action_line + \"; {}\".format(self.actions[i])\n\t            if(not os.path.exists(path_a+name_a)):\n\t                header_line = \"Action\"\n\t                for i in range(self.n_acts):\n\t                    header_line = header_line + \"; Segment_{}\".format(i+1)\n\t                with open(path_a+name_a, \"w\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n\t                    spam_writer.writerow([header_line])\n", "                    spam_writer.writerow([action_line])\n\t            else:\n\t                with open(path_a+name_a, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n\t                    spam_writer.writerow([action_line])        \n\t    def save_reward(self,reward, Nusselt):\n\t        name_a = \"output_rewards.csv\"\n\t        name_N = \"output_Nusselts.csv\"  \n\t        if(not os.path.exists(\"rewards\")):\n\t            try:\n", "                os.mkdir(\"rewards\")\n\t            except:\n\t                pass\n\t        if(not os.path.exists(\"rewards/{}\".format(self.host))):\n\t            os.mkdir(\"rewards/{}\".format(self.host))\n\t        if(not os.path.exists(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))):\n\t            os.mkdir(\"rewards/{}/ep_{}/\".format(self.host, self.episode_number))\n\t        path_a = \"rewards/{}/ep_{}/\".format(self.host, self.episode_number)\n\t        if(not os.path.exists(path_a+name_a)):\n\t                with open(path_a+name_a, \"w\") as csv_file:\n", "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([\"Action\", \"Reward\"])\n\t                    spam_writer.writerow([self.action_count, reward])\n\t                with open(path_a+name_N, \"w\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([\"Action\", \"Nusselt\"])\n\t                    spam_writer.writerow([self.action_count, Nusselt])\n\t        else:\n\t                with open(path_a+name_a, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n", "                    spam_writer.writerow([self.action_count, reward])\n\t                with open(path_a+name_N, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([self.action_count, Nusselt])\n\t    def save_final_reward(self,reward): \n\t        name_a = \"output_final_rewards.csv\"\n\t        if(not os.path.exists(\"final_rewards\")):\n\t            try:\n\t                os.mkdir(\"final_rewards\")\n\t            except:\n", "                pass\n\t        if(not os.path.exists(\"final_rewards/{}\".format(self.host))):\n\t            os.mkdir(\"final_rewards/{}\".format(self.host))\n\t        path_a = \"final_rewards/{}/\".format(self.host)\n\t        if(not os.path.exists(path_a+name_a)):\n\t            with open(path_a+name_a, \"w\") as csv_file:\n\t                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                spam_writer.writerow([\"EPISODE\", \"REWARD\"])\n\t                spam_writer.writerow([self.episode_number, reward])\n\t        else:\n", "            with open(path_a+name_a, \"a\") as csv_file:\n\t                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                spam_writer.writerow([self.episode_number, reward])\n\t    def save_comms_probes(self): \n\t        name_a = \"output_probes_comms.csv\"\n\t        if(not os.path.exists(\"probes_comms\")):\n\t            os.mkdir(\"probes_comms\")\n\t        if(not os.path.exists(\"probes_comms/ep_{}/\".format(self.episode_number))):\n\t            os.mkdir(\"probes_comms/ep_{}/\".format(self.episode_number))\n\t        path_a = \"probes_comms/ep_{}/\".format(self.episode_number)\n", "        if(not os.path.exists(path_a+name_a)):\n\t                with open(path_a+name_a, \"w\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    array_acts = np.linspace(1, 24, dtype=int) \n\t                    spam_writer.writerow([\"Action\", array_acts])\n\t                    spam_writer.writerow([self.action_count, self.probes_values])\n\t        else:\n\t                with open(path_a+name_a, \"a\") as csv_file:\n\t                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n\t                    spam_writer.writerow([self.action_count, self.probes_values])\n", "    def recover_start(self): \n\t        runpath = self.case_path\n\t        self.actions = np.zeros(self.n_acts)\n\t        self.action = 0 \n\t        self.t_end_ini, self.tstep_end_ini = self.t_end_baseline, self.tstep_end_baseline\n\t    def create_cpuID(self):\n\t        os.chdir(self.general_path)\n\t        runpath = self.case_path\n\t        runbin  = 'mkdir'\n\t        if self.deterministic == False:\n", "            pass\n\t        else:\n\t            runargs = 'deterministic'\n\t            run_subprocess(runpath,runbin,runargs,check_return=False)\n\t    def close(self):\n\t        super().close()       \n\t    def states(self):\n\t        return dict(type='float',\n\t                    shape=(3*self.obsGrid[0]*self.obsGrid[1], )\n\t                    ) \n", "    def actions(self):\n\t        \"\"\" Actions now correspond to the temperature of one segment. \n\t            All the actions are then gathered thanks to Wrapper().merge_actions()\n\t            Return: dict_values(['float', 1, -1, 1]) (e.g)\n\t        \"\"\"\n\t        return dict(type='float',\n\t                    shape=(1), \n\t                           min_value=self.optimization_params[\"min_ampl_temp\"],\n\t                           max_value=self.optimization_params[\"max_ampl_temp\"]\n\t                    )\n", "    def execute(self, actions):\n\t        self.action = actions \n\t        wrap = Wrapper(self.episode_number, self.general_path)\n\t        wrap.merge_actions(self.action, self.action_count, self.ENV_ID)\n\t        self.last_time = self.simulation_timeframe[1]\n\t        t1 = round(self.last_time,5)\n\t        t2 = t1 + self.delta_t_smooth\n\t        self.simulation_timeframe = [t1,t2]\n\t        # Start a run\n\t        t0 = time.time()\n", "        # Run + get the new Nusselt: self.run give the global data, \n\t        # self.recentre_obs recenters the data according to the invariant env\n\t        self.probes_values = self.recentre_obs(self.run('execute', self.episode_number, evolve=True))\n\t        # Compute the reward\n\t        reward, gen_Nus, gen_kinEn = compute_reward(self.probes_values, self.reward_function)\n\t        self.history_parameters['Nusselt'].extend([gen_Nus])\n\t        self.history_parameters['kinEn'].extend([gen_kinEn])\n\t        self.history_parameters[\"time\"].extend([self.last_time])\n\t        self.history_parameters[\"episode_number\"].extend([self.episode_number])\n\t        self.save_history_parameters(nb_actuations)\n", "        # Write the action\n\t        self.save_this_action()\n\t        self.save_reward(reward, gen_Nus)\n\t        self.action_count += 1\n\t        if self.deterministic == False and self.action_count <= nb_actuations:\n\t            terminal = False  \n\t        elif self.deterministic == True and self.action_count <= nb_actuations_deterministic:\n\t            terminal = False  \n\t        else:\n\t            terminal = True   \n", "            # write the last rewards at each episode to see the improvement \n\t            self.save_final_reward(reward)\n\t        return self.probes_values, terminal, reward\n\t    def reset(self):\n\t        \"\"\"Reset state\"\"\"\n\t        # Create a folder for each environment\n\t        if self.check_id == True:\n\t            self.create_cpuID()\n\t            self.check_id = False\n\t        # Clean\n", "        self.clean(False)\n\t        # Apply new time frame\n\t        t1 = simulation_params[\"simulation_timeframe\"][0]\n\t        t2 = simulation_params[\"simulation_timeframe\"][1]\n\t        self.simulation_timeframe = [t1,t2]\n\t        # Advance in episode\n\t        self.episode_number += 1\n\t        if self.deterministic == True:\n\t            self.host = 'deterministic'\n\t        # Copy the baseline in the environment directory     \n", "        if self.action_count == 1:\n\t            self.recover_start()\n\t        return self.probes_values\n\t    def recentre_obs(self, probes_values):\n\t        ''' This function is aimed at centering the data around the environment-segment \n\t        (1 env is attached to the behaviour of 1 segment)\n\t        '''\n\t        obs_array = np.array(probes_values).reshape(3, self.obsGrid[0], self.obsGrid[1])\n\t        centered_array = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n\t        ux = obs_array[0]\n", "        uy = obs_array[1]\n\t        Temp = obs_array[2]\n\t        ind = ((self.ENV_ID[1]-(nb_inv_envs-nb_inv_envs//2))%nb_inv_envs)*self.hor_inv_probes\n\t        centered_array[0] = np.array(list(ux.T)[ind:]+list(ux.T)[:ind]).T\n\t        centered_array[1] = np.array(list(uy.T)[ind:]+list(uy.T)[:ind]).T        \n\t        centered_array[2] = np.array(list(Temp.T)[ind:]+list(Temp.T)[:ind]).T       \n\t        centered_list = list(centered_array.reshape(3*self.obsGrid[0]*self.obsGrid[1],))\n\t        return centered_list"]}
{"filename": "env_utils.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# Xavier Garcia, Pol Suarez, Arnau Miro, Francisco Alcantara\n\t#\n\t# 08/11/2022\n\tfrom __future__ import print_function, division\n\timport os, subprocess\n\tfrom configuration import NODELIST\n", "def run_subprocess(runpath,runbin,runargs,nprocs=1,host=None,log=None,srun=False,check_return=True):\n\t\t'''\n\t\tUse python to call a terminal command\n\t\t'''\n\t\t# Build command to run\n\t\tif srun:\n\t\t\t# Sometimes we will need to use srun...\n\t\t\tcmd = 'cd %s && srun -n %d %s %s'%(runpath,nprocs,runbin,runargs) if log is None else 'cd %s && srun -n %d %s %s > %s 2>&1'%(runpath,nprocs,runbin,runargs,log)\n\t\telse:\n\t\t\tif nprocs == 1:\n", "\t\t\t# Run a serial command\n\t\t\t\tcmd = 'cd %s && %s %s'%(runpath,runbin,runargs) if log is None else 'cd %s && %s %s > %s 2>&1'%(runpath,runbin,runargs,log)\n\t\t\telse:\n\t\t\t\t# Run a parallel command\n\t\t\t\tif host is None:\n\t\t\t\t\tcmd = 'cd %s && mpirun -np %d %s %s'%(runpath,nprocs,runbin,runargs) if log is None else 'cd %s && mpirun -np %d %s %s > %s 2>&1'%(runpath,nprocs,runbin,runargs,log)\n\t\t\t\telse:\n\t\t\t\t\tcmd = 'cd %s && mpirun -np %d -host %s %s %s'%(runpath,nprocs,host,runbin,runargs) if log is None else 'cd %s && mpirun -np %d -host {3} %s %s > %s 2>&1'%(runpath,nprocs,host,runbin,runargs,log)\n\t\t# Execute run\n\t\tretval = subprocess.call(cmd,shell=True)\n", "\t# Check return\n\t\tif check_return and retval != 0: raise ValueError('Error running command <%s>!'%cmd)\n\t\t# Return value\n\t\treturn retval\n\tdef detect_system():\n\t\t'''\n\t\tTest if we are in a cluster or on a local machine\n\t\t'''\n\t\t# Start assuming we are on the local machine\n\t\tout = 'LOCAL' \n", "\t# 1. Test for SRUN, if so we are in a SLURM machine\n\t\t# and hence we should use SLURM to check the available nodes\n\t#\tif (run_subprocess('./','which','srun',check_return=False) == 0): out = 'SLURM'\n\t\t# Return system value\n\t\treturn out\n\tdef _slurm_generate_node_list(outfile,num_servers = os.getenv('SLURM_NNODES'),num_cores_server = os.getenv('SLURM_NTASKS_PER_CORE')):\n\t\t'''\n\t\tGenerate the list of nodes using slurm\n\t\t'''\n\t\t# Recover some information from SLURM environmental variables\n", "\thostlist = os.getenv('SLURM_JOB_NODELIST') # List of nodes used by the job\n\t\t# Perform some sanity checks\n\t\tif not len(hostlist) == num_servers: raise ValueError('Inconsistent number of nodes in SLURM or configuration!')\n\t\trun_subprocess('./','echo','\"%s\"'%hostlist,log=outfile)\n\t#\trun_subprocess('./','scontrol','show hostnames',log=outfile) \n\tdef _localhost_generate_node_list(outfile,num_servers):\n\t\t'''\n\t\tGenerate the list of nodes for a local run\n\t\t'''\n\t\thostlist = 'localhost'\n", "\tfor iserver in range(num_servers): hostlist += '\\nlocalhost'\n\t\t# Basically write localhost as the list of nodes\n\t\t# Add n+1 nodes as required per the nodelist\n\t\trun_subprocess('./','echo','\"%s\"'%hostlist,log=outfile)\n\tdef generate_node_list(outfile=NODELIST,num_servers=1):\n\t\t'''\n\t\tDetect the system and generate the node list\n\t\t'''\n\t\tsystem  = detect_system()\n\t\tif system == 'LOCAL': _localhost_generate_node_list(outfile,num_servers)\n", "\tif system == 'SLURM': _slurm_generate_node_list(outfile,num_servers)\n\tdef read_node_list(file=NODELIST):\n\t\t'''\n\t\tRead the list of nodes\n\t\t'''\n\t\tfp = open(file,'r')\n\t\tnodelist = [h.strip() for h in fp.readlines()]\n\t\tfp.close()\n\t\treturn nodelist\n"]}
{"filename": "configuration.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# configuration.py: Path to the binaries used for the DRL tool\n\t#\n\t# Pol Suarez, Arnau Miro\n\t#\n\t# 29/09/2022\n\tfrom __future__ import print_function, division\n", "import os\n\t## PATHS\n\t# Absolute path to the DRL directory\n\tDRL_PATH  = os.path.join(os.path.dirname(os.path.abspath(__file__)))\n\t# Absolute path to the shenfun_files folder\n\tALYA_PATH = os.path.join(DRL_PATH,'shenfun_files')\n\t# Absolute path to the binaries folder\n\tBIN_PATH  = os.path.join(DRL_PATH,'shenfun_files','bin')\n\t## FILE NAMES\n\tNODELIST   = 'nodelist'\n"]}
{"filename": "Postprocess_routines/plotLearningCurve.py", "chunked_list": ["import numpy as np\n\timport os, sys, time\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\tfrom matplotlib.ticker import (MultipleLocator)\n\timport json\n\tfrom scipy.signal import savgol_filter\n\t'''\n\tThe following plots can be generated with this script, one at a time.\n\t1. Plots learning curve - instantaneous reward vs episode.\n", "2. Plots learning curve - instantaneous Nusselt number vs episode.\n\t3. Plots learning curve (Nu) from a single training episode (ep_no), along with the Nu from the baseine. Horizontal axis is time.\n\t4. Plots many learning curves (Nu) from diff episodes\n\t5. Plot of learning curves from SARL and MARL for comparison \n\t6. Plots learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time, along with the removing control \n\t7. Plots Nu after control is removed   \n\tYou can plot either one, by setting the 'cas' variable below to any index number above.\n\tAuthor: Joel Vasanth | FLOW, KTH Stockholm\n\tDate: 3/25/2023\n\t'''\n", "# Set which case to plot. See options above \n\tcas = 7\n\t# Set simulation name and path \n\tsimu_name = 'RB_2D_MARL' \n\tgeneral_path = os.getcwd()\n\tpath = general_path+'/../shenfun_files/cases/'+simu_name\n\tos.chdir(path)\n\tsys.path.append(path)\n\tfrom parameters import simulation_params, reward_function, optimization_params, nb_proc, nb_actuations, nb_actuations_deterministic, n_seg\n\t# Number of actions/actuations per episode\n", "nb_actions = 100  \n\t# CFD time duration between two actuations\n\tdt = 1.5  \n\t# duration of the baseline simulation\n\tbaseline_t = 1000  \n\t# Amplitude of variation of T\n\tampl = 0.75  \n\t# Number of segments \n\tnb_seg = 10\n\t# Number of pseudo-environments \n", "nb_envs = 10\n\t# Evolution of the reward obtained at the end of an episode, for all episodes, for all environments (list(R1, R2, R3,...))\n\ttotal_rewards = [] \n\trewards_interEps = {}  \n\t# Evolution of the reward obtained at the end of an episode, for all episodes, for all environments (dictionary {env 1: , env2: ...})\n\ttotal_rewards_averaged = []\n\trewards_interEps_averaged = {}\n\t# Evolution of the normalized actions during all the episodes, for all episodes, for all environment for all segment (actuator) (between [-1,+1])\n\tActions_interEnvs = {}  \n\t# Evolution of the actions during all the episodes, for all episodes, for all environment for all segment (actuator) (between [2-0.75,2+0.75])\n", "Actions_unN_interEnvs = {}  \n\t# Evolution of the rewards during an episode, for all episodes, for all environment ({environment i: array([[R1_ep1, R2_ep1, ...], [R1_ep2, R2_ep2, ...]])})\n\treward_in_ep = {}  \n\tNusselt_in_ep = {}  \n\t# the episodes we consider (num_episode, num_environment)\n\tepisodes = [(204,9), (234,6), (224, 2)]  \n\t# Episodes considered in the last figure (where we plot the evolution of the actions)\n\tepisodes_trace_action = [(1,1)]  \n\tcolors = ['red', 'blue', 'green', 'black']\n\tmax_ep = 1e8\n", "max_ep_arr = []\n\tif (cas == 1):\n\t    ### PLOTS INSTANTANEOUS REWARD VS EPISODES\n\t    ## the inst. reward is the reward at the end of each episode, and averaged over all environments.\n\t    ## ------------------------------------\n\t    num_eps = 451 # number of episodes you want to plot\n\t    f = plt.figure()\n\t    ax = f.add_subplot(111)\n\t    ax.tick_params(direction=\"in\")\n\t    ax.yaxis.set_ticks_position('both')\n", "    for num_env in range (1,nb_envs+1):\n\t        os.chdir(path+'/final_rewards/environment'+str(num_env))\n\t        eps, rewards = [], []\n\t        with open('output_final_rewards.csv', 'r') as f:\n\t            c = 0\n\t            for line in f:\n\t                if c == 0:\n\t                    c +=1\n\t                else:\n\t                    episode, reward = line.split(';')\n", "                    eps.append(int(episode))\n\t                    rewards.append(float(reward.strip('\\n')))\n\t                    c += 1 \n\t        rewards_interEps.update({'env'+str(num_env):rewards})\n\t    lmm = np.zeros((num_eps,),dtype=np.float64)\n\t    print(\"No. of episodes printed: \", num_eps)\n\t    # averaging over no fo envs\n\t    for envno in range(1,nb_envs+1):\n\t        ar1 = np.array(rewards_interEps['env'+str(envno)])\n\t        lmm = lmm + ar1\n", "    lmm = lmm/float(nb_envs)\n\t    # plt.rcParams[\"figure.figsize\"] = (15,6)\n\t    plt.plot(lmm)\n\t    plt.xlabel('Episode')\n\t    plt.ylabel('Reward')\n\t    # plt.xlim(0,450)\n\t    # plt.ylim(-0.2,1)\n\t    #plt.show()\n\t    os.chdir(general_path+'/../shenfun_files/cases/')\n\t    plt.savefig('FR_1_LearningCurve_reward.png')\n", "elif (cas == 2):\n\t    ## PLOTS INSTANTANEOUS NUSSELT VS EPISODE\n\t    # the Nusselt is the value at the end of each episode, and averaged over all environments.\n\t    # ------------------------------------\n\t    numeps = 446\n\t    nusselts = []\n\t    for num_epis in range (1,numeps+1):\n\t        totalEnvNusselt = 0.0\n\t        for num_env in range (1,nb_envs+1):\n\t            os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(num_epis))\n", "            eps, rewards = [], []\n\t            with open('output_Nusselts.csv', 'r') as f:\n\t                for line in f:\n\t                    pass\n\t                last_line = line\n\t            actionNumber, envNusselt = last_line.split(';')\n\t            # nusselts.append(float(envNusselt.strip('\\n')))\n\t            totalEnvNusselt += float(envNusselt.strip('\\n'))\n\t        nusselts.append(totalEnvNusselt/float(num_env))\n\t    os.chdir(path+'/baseline/')    \n", "    with open('evo_Nusselt_baseline.json', 'r') as f:\n\t        Nusselt_baseline = json.load(f)\n\t    print(\"No. of episodes printed: \", num_epis)\n\t    baselineNusselt = np.array(Nusselt_baseline)\n\t    # xax_base = np.linspace(0,400,799)-400\n\t    xax_epis = np.arange(0,300, 1.5)\n\t    # print(len(nusselts))\n\t    # plt.rcParams[\"figure.figsize\"] = (15,6)\n\t    plt.plot(nusselts, lw = 1)\n\t    # plt.plot(xax_base, baselineNusselt)\n", "    plt.xlabel('Episode')\n\t    #plt.xlim(0,numeps)\n\t    # plt.grid()\n\t    plt.ylabel('$Nu$')\n\t    # plt.xlim(0,365)\n\t    # plt.ylim(1.8,3.0)\n\t    #plt.show()\n\t    os.chdir(general_path+'/../')\n\t    print(general_path)\n\t    plt.savefig('FR_2_LearningCurve.png')\n", "elif (cas == 3):\n\t    # PLOTS learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time.\n\t    f = plt.figure()\n\t    ax = f.add_subplot(111)\n\t    ax.tick_params(direction=\"in\")\n\t    ax.yaxis.set_ticks_position('both')\n\t    ep_no = 130\n\t    total_nusselts = np.zeros((nb_actions,))\n\t    for num_env in range(1,nb_envs+1):\n\t        print(num_env)\n", "        os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep_no))\n\t        nusselts = []\n\t        c = 0\n\t        with open('output_Nusselts.csv', 'r') as f:\n\t            for line in f:\n\t                if (c > 0):\n\t                    _ , envNusselt = line.split(';')\n\t                    nusselts.append(float(envNusselt.strip('\\n')))\n\t                c += 1\n\t        if (len(nusselts) != nb_actions):\n", "            print('Length of episode wrong')\n\t        total_nusselts += np.array(nusselts)\n\t    os.chdir(path+'/baseline/')    \n\t    with open('evo_Nusselt_baseline.json', 'r') as f:\n\t        Nusselt_baseline = json.load(f)\n\t    # print(len(Nusselt_baseline))\n\t    x_bs = np.arange(1, baseline_t)-baseline_t\n\t    x_ep = np.arange(0,100)\n\t    print(np.size(x_ep))\n\t    print(len(total_nusselts))\n", "    x_ep_vid = np.arange(0,600,3)\n\t    x_join = [0.0, 1.5]\n\t    join_line = [Nusselt_baseline[-1], total_nusselts[0]]\n\t    plt.plot(x_bs,Nusselt_baseline, color='black', linewidth=1)\n\t    # plt.plot(x_join, join_line, lw = 1, color='black')\n\t    plt.plot(x_ep,total_nusselts/float(nb_envs), lw = 1, color= 'blue')\n\t    # nno = np.mean(total_nusselts[99:199])\n\t    # nno_line = [nno, nno, nno]\n\t    # rem_con = [2.0546285693099984,2.0546285693099984,2.0546285693099984]\n\t    # plt.plot([-100,0,300],nno_line,linewidth=0.8,linestyle='--', color='black', label='Actively controlled')\n", "    # plt.plot([-100,0,300],rem_con,linewidth=0.8,linestyle='--', color='red', label='Control Removed')\n\t    # x_pts = [0, 50, 100, 114, 116, 118, 135, 200]\n\t    # pts = [2.6785, 2.675, 2.587, 2.325, 2.2855, 2.3408, 2.5139, 1.9636]\n\t    # plt.scatter(x_pts,pts, lw = 1, color= 'red', marker='o')\n\t    # baseline_array = [2.675,2.675,2.675]\n\t    # plt.plot([-100,0,300],baseline_array,linewidth=0.8,linestyle='--', color='blue', label='Baseline')\n\t    # plt.axvspan(148.54, 300, color='0.8', alpha = 0.5)\n\t    # print(nno)\n\t    plt.xlabel('Time')\n\t    # plt.legend()\n", "    # plt.grid()\n\t    plt.xlim(-800,100)\n\t    # plt.ylim(1.78,3)\n\t    # plt.ylabel('$Nu$')\n\t    plt.show()\n\t    # os.chdir(general_path+'/../')\n\t    # plt.savefig('FR_8_mainEpisode.png')\n\telif (cas ==4):\n\t    # Plots many curves (Nu) from diff episodes\n\t    eps_nos = [45, 275, 357]\n", "    eps_nos_paper = [45,275,350]\n\t    colors = ['green', 'red', 'blue']\n\t    def moving_averge(a, n):\n\t        mean_array = np.zeros((a.size-n+1,))\n\t        for i in range(a.size-n+1):\n\t            mean_array[i] = np.mean(a[i:i+n-1])\n\t        return mean_array\n\t    os.chdir(path+'/baseline/')    \n\t    with open('evo_Nusselt_baseline.json', 'r') as f:\n\t        Nusselt_baseline = json.load(f)\n", "    x_bs = np.arange(0, baseline_t-0.5,0.5) - 400\n\t    x_join = [-1,0]\n\t    f = plt.figure(figsize=(10,5))\n\t    plt.rcParams.update({'font.size': 15})\n\t    ax = f.add_subplot(111)\n\t    ax.tick_params(direction=\"in\")\n\t    ax.yaxis.set_ticks_position('both')\n\t    n=0\n\t    for ep in eps_nos:\n\t        total_nusselts = np.zeros((nb_actions,))\n", "        for num_env in range(1,nb_envs+1):\n\t            os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep))\n\t            nusselts = []\n\t            c = 0\n\t            with open('output_Nusselts.csv', 'r') as f:\n\t                for line in f:\n\t                    if (c > 0):\n\t                        _ , envNusselt = line.split(';')\n\t                        nusselts.append(float(envNusselt.strip('\\n')))\n\t                    c += 1\n", "            if (len(nusselts) != nb_actions):\n\t                print('Length of episode wrong')\n\t            total_nusselts += np.array(nusselts)\n\t        x_ep = np.arange(0,300,1.5)\n\t        # x_ep_vid = np.arange(0,600,3)\n\t        # plt.plot(x_bs,Nusselt_baseline)\n\t        plt.plot(x_ep,total_nusselts, lw = 0.5, color=colors[n],)\n\t        nusavg = moving_averge(total_nusselts,20)\n\t        x_avg = moving_averge(x_ep,20)\n\t        plt.plot(x_avg,nusavg,color=colors[n], lw = 1.4,  label='Episode '+str(eps_nos_paper[n]))\n", "        join_line = [Nusselt_baseline[-1], total_nusselts[0]]\n\t        plt.plot(x_join, join_line, lw = 0.3, color=colors[n])\n\t        n += 1\n\t    plt.plot(x_bs, Nusselt_baseline, color = 'black', lw = 1,label='Baseline')\n\t    baseline_array = [2.678,2.678,2.678]\n\t    plt.plot([0,150,350],baseline_array,linewidth=1.2,linestyle='--', color='black')\n\t    nno_line = [2.0546, 2.0546, 2.0546]\n\t    nno_line2 = [2.0496, 2.0496, 2.0496]\n\t    plt.plot([-50,0,400],nno_line,linewidth=1.2,linestyle='-.', color='black', label='Control Removed')\n\t    plt.plot([-50,0,400],nno_line2,linewidth=1.2,linestyle='--', color='blue', label='Actively Controlled')\n", "    plt.xlabel('Time')\n\t    plt.legend(fontsize=12, ncol=2)\n\t    # plt.grid()\n\t    plt.xlim(-50,300)\n\t    plt.ylim(1.75,3)\n\t    plt.ylabel('$Nu$')\n\t    # plt.show()\n\t    os.chdir(general_path+'/../')\n\t    print(general_path)\n\t    plt.savefig('FR_3_multipleEpisodeLearningCurve')\n", "elif (cas == 5): \n\t    # Plot of SARL vs MARL\n\t    simu_names = ['RB_2D_MARL_2pi_drl_3', 'RB_2D_SARL']  # RB_2D_MARL_2pi_drl_2 RB_2D_SARL\n\t    colors = ['0', '0.45']\n\t    labels = ['MARL', 'SARL']\n\t    ep_nos = [365, 500] # num of total episodes in MARL (first entry) and SARL (second entry)\n\t    si = 0\n\t    def moving_averge(a, n):\n\t        mean_array = np.zeros((a.size-n+1,))\n\t        for i in range(a.size-n+1):\n", "            mean_array[i] = np.mean(a[i:i+n-1])\n\t        return mean_array\n\t    f = plt.figure()\n\t    ax = f.add_subplot(111)\n\t    ax.tick_params(direction=\"in\")\n\t    ax.yaxis.set_ticks_position('both')\n\t    for simu_name in simu_names:\n\t        path = general_path+'/../shenfun_files/cases/'+simu_name\n\t        os.chdir(path)\n\t        sys.path.append(path)\n", "        numeps = ep_nos[0]\n\t        nusselts = []\n\t        for num_epis in range (1,numeps+1):\n\t            totalEnvNusselt = 0.0\n\t            for num_env in range (1,nb_envs+1):\n\t                os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(num_epis))\n\t                eps, rewards = [], []\n\t                with open('output_Nusselts.csv', 'r') as f:\n\t                    for line in f:\n\t                        pass\n", "                    last_line = line\n\t                actionNumber, envNusselt = last_line.split(';')\n\t                # nusselts.append(float(envNusselt.strip('\\n')))\n\t                totalEnvNusselt += float(envNusselt.strip('\\n'))\n\t            nusselts.append(totalEnvNusselt/float(num_env))\n\t        # plt.rcParams[\"figure.figsize\"] = (15,6)\n\t        nusarr = np.array(nusselts)\n\t        nusavg = moving_averge(nusarr,25)\n\t        x = np.arange(1,365+1)\n\t        x_avg = moving_averge(x,25)\n", "        plt.plot(x, nusselts, lw = 0.5, linestyle='--', color = colors[si])\n\t        plt.plot(x_avg, nusavg, linewidth=1.5, color = colors[si], label=labels[si])\n\t        si += 1\n\t        # plt.plot(xax_base, baselineNusselt)\n\t    plt.xlabel('Episode')\n\t    baseline_array = [2.675,2.675,2.675]\n\t    nuc = 2.0546247073036668 # this is Nu of the controlled single RB cell, after the control has been removed\n\t    controlled_array = [nuc, nuc, nuc]\n\t    plt.plot([0,150,350],baseline_array,linewidth=2,linestyle='--', color='blue', label='Baseline')\n\t    plt.plot([0,150,350],controlled_array,linewidth=2,linestyle='--', color='black', label='Controlled')\n", "    #plt.xlim(0,numeps)\n\t    # plt.grid()\n\t    plt.ylabel('$Nu$')\n\t    plt.legend()\n\t    plt.xlim(0,350)\n\t    plt.ylim(1.8,3.0)\n\t    plt.show()\n\t    # os.chdir(general_path+'/../')\n\t    # plt.savefig('FR_4_MARLvsSARL.png')\n\telif (cas == 6):\n", "    # Plots learning curve (Nu) from a single episode (ep_no), along with the baseine. x-axis is time, along with the removing control \n\t    f = plt.figure()\n\t    ax = f.add_subplot(111)\n\t    ax.tick_params(direction=\"in\")\n\t    ax.yaxis.set_ticks_position('both')\n\t    # ax.rcParams[\"figure.figsize\"] = (10,6)\n\t    plt.figure(figsize=(10,5))\n\t    plt.rcParams.update({'font.size': 15})\n\t    ep_no = 357 # in drl2\n\t    total_nusselts = np.zeros((nb_actions,))\n", "    for num_env in range(1,nb_envs+1):\n\t        os.chdir(path+'/rewards/environment'+str(num_env)+'/ep_'+str(ep_no))\n\t        nusselts = []\n\t        c = 0\n\t        with open('output_Nusselts.csv', 'r') as f:\n\t            for line in f:\n\t                if (c > 0):\n\t                    _ , envNusselt = line.split(';')\n\t                    nusselts.append(float(envNusselt.strip('\\n')))\n\t                c += 1\n", "        if (len(nusselts) != nb_actions):\n\t            print('Length of episode wrong')\n\t        total_nusselts += np.array(nusselts)\n\t    os.chdir(path+'/baseline/')    \n\t    with open('evo_Nusselt_baseline.json', 'r') as f:\n\t        Nusselt_baseline = json.load(f)\n\t    os.chdir(general_path+'/../Postprocess_routines/drl3_ep357/removeControl/baseline/')    \n\t    with open('evo_Nusselt_baseline.json', 'r') as f:   \n\t        Nusselt_removeControl = json.load(f)\n\t    x_bs = np.arange(0, baseline_t-0.5,0.5)-baseline_t\n", "    x_ep = np.arange(1.5,300+1.5,1.5)\n\t    x_rc = np.arange(300+0.5,500,0.5)\n\t    print(\"Length 1:\", len(total_nusselts), len(x_rc))\n\t    x_ep_vid = np.arange(0,600,3)\n\t    x_join_bs = [0.0, 1.5]\n\t    join_line_bs = [Nusselt_baseline[-1], total_nusselts[0]]\n\t    x_join_rc = [300.0, 300.5]\n\t    join_line_rc = [total_nusselts[-1], Nusselt_removeControl[0]]\n\t    plt.plot(x_bs,Nusselt_baseline, color='black', linewidth=1)\n\t    plt.plot(x_rc,Nusselt_removeControl, color='black', linewidth=1)\n", "    plt.plot(x_join_bs, join_line_bs, lw = 1, color='black')\n\t    plt.plot(x_join_rc, join_line_rc, lw = 1, color='black')\n\t    plt.plot(x_ep,total_nusselts, lw = 1, color= 'black')\n\t    nno = np.mean(total_nusselts[119:199])\n\t    nno_line = [nno, nno, nno]\n\t    print(nno)\n\t    print(Nusselt_removeControl[-1])\n\t    rem_con = [Nusselt_removeControl[-1],Nusselt_removeControl[-1],Nusselt_removeControl[-1]]\n\t    plt.plot([-50,0,400],nno_line,linewidth=0.8,linestyle='--', color='black', label='Actively controlled')\n\t    plt.plot([-50,0,400],rem_con,linewidth=0.8,linestyle='--', color='red', label='Control Removed')\n", "    x_pts = [51, 102, 114, 120, 123, 126, 141, 252]\n\t    pts = [total_nusselts[33], total_nusselts[67],total_nusselts[75],total_nusselts[79],total_nusselts[81], \\\n\t           total_nusselts[83],total_nusselts[93],total_nusselts[167]]\n\t    baseline_array = [2.675,2.675,2.675]\n\t    plt.plot([-50,0,400],baseline_array,linewidth=0.8,linestyle='--', color='blue', label='Baseline')\n\t    plt.axvspan(0, 112, color='purple', alpha = 0.5)\n\t    plt.axvspan(112, 130, color='yellow', alpha = 0.5)\n\t    plt.axvspan(130, 300, color='green', alpha = 0.5)\n\t    plt.axvspan(300, 400, color='grey', alpha = 0.5)\n\t    plt.scatter(x_pts,pts, lw = 1, color= 'red', marker='o')\n", "    # print(nno)\n\t    plt.xlabel('Time')\n\t    plt.legend()\n\t    # plt.grid()\n\t    plt.xlim(-50,400)\n\t    plt.ylim(1.78,3)\n\t    plt.ylabel('$Nu$')\n\t    # plt.show()\n\t    # os.chdir(general_path+'/../')\n\t    # print(general_path)\n", "    # plt.savefig('FR_8_mainEpisode.png')\n\telif (cas == 7):\n\t    # Plots Nu after control is removed\n\t    plt.rcParams.update({'font.size': 15})\n\t    f = plt.figure(figsize=(7,3))\n\t    ax = f.add_subplot(111)\n\t    ax.tick_params(direction=\"in\")\n\t    ax.yaxis.set_ticks_position('both')\n\t    ep_no = 357 # in drl2\n\t    os.chdir(general_path+'/../Postprocess_routines/drl3_ep357/removeControl/baseline/')    \n", "    with open('evo_Nusselt_baseline.json', 'r') as f:   \n\t        Nusselt_removeControl = json.load(f)\n\t    x_rc = np.arange(300+0.5,500,0.5)\n\t    plt.plot(x_rc,Nusselt_removeControl, color='black', linewidth=1)    \n\t    plt.axvspan(300, 500, color='grey', alpha = 0.5)\n\t    # print(nno)\n\t    plt.tight_layout()\n\t    plt.xlabel('Time')\n\t    #plt.ylim(2,2.1)\n\t    plt.ylabel('$Nu$', labelpad=-1)\n", "    #plt.show()\n\t    os.chdir(general_path+'/../')\n\t    print(general_path)\n\t    plt.savefig('controlRemoved.png')\n"]}
{"filename": "Postprocess_routines/plotBaselines.py", "chunked_list": ["import numpy as np\n\timport os, sys, time\n\timport matplotlib.pyplot as plt\n\timport json\n\t'''\n\tThis script plots the baseline Nu and KE over the time of the baseline simulation.\n\tAuthor: Joel Vasanth\n\tDate: 3/20/2023\n\t'''\n\t# Set case\n", "simu_name = 'RB_3D_MARL_01'  \n\tgeneral_path = os.getcwd()\n\tpath = general_path+'/../shenfun_files/cases/'+simu_name\n\tos.chdir(path)\n\t# Set parameters\n\tbaseline_t = 400  # duration baseline simulation\n\tampl = 0.75  # Amplitude of variation of T\n\tnb_parr_envs = 1  # number of parallel environments\n\tnb_seg = 10 # number of segments\n\tMARL = True\n", "if MARL:\n\t    nb_envs = nb_parr_envs*nb_seg\n\telse:\n\t    nb_envs = nb_parr_envs\n\treward_function = 'Nusselt'  # choose 'Nusselt' or 'kinEn'\n\tos.chdir(path+'/baseline/')    \n\twith open('evo_Nusselt_baseline.json', 'r') as f:\n\t    Nusselt_baseline = json.load(f)\n\twith open('evo_kinEn_baseline.json', 'r') as f2:\n\t    kinEn_baseline = json.load(f2)\n", "# Time of simulation. 0.5 here is the dt, can be changed.\n\ttimerange = np.arange(0.5,baseline_t,0.5)\n\t# Perform plotting \n\tfig, ax = plt.subplots()\n\tp1 = ax.plot(Nusselt_baseline, 'b-', label='Nusselt Number')\n\tax2 = ax.twinx()\n\tp2 = ax2.plot(kinEn_baseline, 'r-', label='Kinetic Energy')\n\tallp = p1+p2\n\tlabs = [p.get_label() for p in allp]\n\tax.legend(allp, labs, loc = 4)\n", "ax.set_xlabel('Time')\n\tax.set_ylabel('Nusselt Number', color='b')\n\tax2.set_ylabel('Kinetic Energy', color='r')\n\t# plt.grid()\n\tsavepath = general_path+'/../baseline3D.png'\n\tprint(savepath)\n\tplt.savefig(savepath)\n\t# plt.show()\n"]}
{"filename": "Postprocess_routines/ChannelFlow2D.py", "chunked_list": ["from warnings import WarningMessage\n\tfrom shenfun import *\n\tnp.warnings.filterwarnings('ignore')\n\tclass KMM:\n\t    \"\"\"Navier Stokes channel flow solver in 2D\n\t    The wall normal direction is along the x-axis, the streamwise along the y-axis.\n\t    The solver is fully spectral with Chebyshev (or Legendre) in the wall-normal\n\t    direction and Fourier in the other.\n\t    Using the equations described by Kim, Moser, Moin (https://doi.org/10.1017/S0022112087000892)\n\t    but with the spectral Galerkin method in space and a chosen time stepper.\n", "    Parameters\n\t    ----------\n\t    N : 2-tuple of ints\n\t        The global shape in physical space (quadrature points)\n\t    domain : 2-tuple of 2-tuples\n\t        The size of the three domains\n\t    nu : Viscosity coefficient\n\t    dt : Timestep\n\t    conv : Choose convection method\n\t        - 0 - Standard convection\n", "        - 1 - Vortex type\n\t    filename : str, optional\n\t        Filenames are started with this name\n\t    family : str, optional\n\t        Chebyshev is normal, but Legendre works as well\n\t    padding_factor : 2-tuple of numbers, optional\n\t        For dealiasing, backward transforms to real space are\n\t        padded with zeros in spectral space using these many points\n\t    modplot : int, optional\n\t        Plot some results every modplot timestep. If negative, no plotting\n", "    modsave : int, optional\n\t        Save results to hdf5 every modsave timestep.\n\t    moderror : int, optional\n\t        Print diagnostics every moderror timestep\n\t    checkpoint : int, optional\n\t        Save required data for restart to hdf5 every checkpoint timestep.\n\t    timestepper : str, optional\n\t        Choose timestepper\n\t    Note\n\t    ----\n", "    Simulations may be killed gracefully by placing a file named 'killshenfun'\n\t    in the folder running the solver from. The solver will then first store\n\t    the results by checkpointing, before exiting.\n\t    \"\"\"\n\t    def __init__(self,\n\t                 N=(32, 32),\n\t                 domain=((-1, 1), (0, 2*np.pi)),\n\t                 nu=0.01,\n\t                 dt=0.1,\n\t                 conv=0,\n", "                 dpdy=1,\n\t                 filename='KMM',\n\t                 family='C',\n\t                 padding_factor=(1, 1.5),\n\t                 modplot=100,\n\t                 modsave=1e8,\n\t                 moderror=100,\n\t                 checkpoint=1000,\n\t                 timestepper='IMEXRK3'):\n\t        self.N = N\n", "        self.nu = nu\n\t        self.dt = dt\n\t        self.conv = conv\n\t        self.modplot = modplot\n\t        self.modsave = modsave\n\t        self.moderror = moderror\n\t        self.filename = filename\n\t        self.padding_factor = padding_factor\n\t        self.dpdy = dpdy\n\t        self.PDE = PDE = globals().get(timestepper)\n", "        self.im1 = None\n\t        # Regular spaces\n\t        self.B0 = FunctionSpace(N[0], family, bc=(0, 0, 0, 0), domain=domain[0])\n\t        self.D0 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])\n\t        self.C0 = FunctionSpace(N[0], family, domain=domain[0])\n\t        self.F1 = FunctionSpace(N[1], 'F', dtype='d', domain=domain[1])\n\t        self.D00 = FunctionSpace(N[0], family, bc=(0, 0), domain=domain[0])  # Streamwise velocity, not to be in tensorproductspace\n\t        self.C00 = self.D00.get_orthogonal()\n\t        # Regular tensor product spaces\n\t        self.TB = TensorProductSpace(comm, (self.B0, self.F1), modify_spaces_inplace=True) # Wall-normal velocity\n", "        self.TD = TensorProductSpace(comm, (self.D0, self.F1), modify_spaces_inplace=True) # Streamwise velocity\n\t        self.TC = TensorProductSpace(comm, (self.C0, self.F1), modify_spaces_inplace=True) # No bc\n\t        self.BD = VectorSpace([self.TB, self.TD])  # Velocity vector space\n\t        self.CD = VectorSpace(self.TD)             # Dirichlet vector space\n\t        # Padded space for dealiasing\n\t        self.TDp = self.TD.get_dealiased(padding_factor)\n\t        self.u_ = Function(self.BD)      # Velocity vector solution\n\t        self.H_ = Function(self.CD)      # convection\n\t        self.ub = Array(self.BD)\n\t        self.v00 = Function(self.D00)   # For solving 1D problem for Fourier wavenumber 0, 0\n", "        self.w00 = Function(self.D00)\n\t        self.work = CachedArrayDict()\n\t        self.mask = self.TB.get_mask_nyquist() # Used to set the Nyquist frequency to zero\n\t        self.X = self.TD.local_mesh(bcast=True)\n\t        self.K = self.TD.local_wavenumbers(scaled=True)\n\t        # Classes for fast projections. All are not used except if self.conv=0\n\t        self.dudx = Project(Dx(self.u_[0], 0, 1), self.TD)\n\t        if self.conv == 0:\n\t            self.dudy = Project(Dx(self.u_[0], 1, 1), self.TB)\n\t            self.dvdx = Project(Dx(self.u_[1], 0, 1), self.TC)\n", "            self.dvdy = Project(Dx(self.u_[1], 1, 1), self.TD)\n\t        self.curl = Project(curl(self.u_), self.TC)\n\t        self.divu = Project(div(self.u_), self.TC)\n\t        self.solP = None # For computing pressure\n\t        # File for storing the results\n\t        self.file_u = ShenfunFile('_'.join((filename, 'U')), self.BD, backend='hdf5', mode='w', mesh='uniform')\n\t        # Create a checkpoint file used to restart simulations\n\t        self.checkpoint = Checkpoint(filename,\n\t                                     checkevery=checkpoint,\n\t                                     data={'0': {'U': [self.u_]}})\n", "        # set up equations\n\t        v = TestFunction(self.TB)\n\t        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals and can use generic solvers.\n\t        sol1 = chebyshev.la.Biharmonic if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\t        self.pdes = {\n\t            'u': PDE(v,                                   # test function\n\t                     div(grad(self.u_[0])),               # u\n\t                     lambda f: self.nu*div(grad(f)),      # linear operator on u\n\t                     Dx(Dx(self.H_[1], 0, 1), 1, 1)-Dx(self.H_[0], 1, 2),\n\t                     dt=self.dt,\n", "                     solver=sol1,\n\t                     latex=r\"\\frac{\\partial \\nabla^2 u}{\\partial t} = \\nu \\nabla^4 u + \\frac{\\partial^2 N_y}{\\partial x \\partial y} - \\frac{\\partial^2 N_x}{\\partial y^2}\"),\n\t        }\n\t        # v. Solve divergence constraint for all wavenumbers except 0\n\t        r\"\"\":math:`\\nabla \\cdot \\vec{u} = 0`\"\"\"\n\t        # v. Momentum equation for Fourier wavenumber 0\n\t        if comm.Get_rank() == 0:\n\t            v0 = TestFunction(self.D00)\n\t            self.h1 = Function(self.D00)  # Copy from H_[1, :, 0, 0] (cannot use view since not contiguous)\n\t            source = Array(self.C00)\n", "            source[:] = -self.dpdy        # dpdy set by subclass\n\t            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.Solver\n\t            self.pdes1d = {\n\t                'v0': PDE(v0,\n\t                          self.v00,\n\t                          lambda f: self.nu*div(grad(f)),\n\t                          [-Expr(self.h1), source],\n\t                          dt=self.dt,\n\t                          solver=sol,\n\t                          latex=r\"\\frac{\\partial v}{\\partial t} = \\nu \\frac{\\partial^2 v}{\\partial x^2} - N_y - \\frac{\\partial p}{\\partial y}\"),\n", "            }\n\t    def convection(self):\n\t        H = self.H_.v\n\t        self.up = self.u_.backward(padding_factor=self.padding_factor)\n\t        up = self.up.v\n\t        if self.conv == 0:\n\t            dudxp = self.dudx().backward(padding_factor=self.padding_factor).v\n\t            dudyp = self.dudy().backward(padding_factor=self.padding_factor).v\n\t            dvdxp = self.dvdx().backward(padding_factor=self.padding_factor).v\n\t            dvdyp = self.dvdy().backward(padding_factor=self.padding_factor).v\n", "            H[0] = self.TDp.forward(up[0]*dudxp+up[1]*dudyp, H[0])\n\t            H[1] = self.TDp.forward(up[0]*dvdxp+up[1]*dvdyp, H[1])\n\t        elif self.conv == 1:\n\t            curl = self.curl().backward(padding_factor=self.padding_factor)\n\t            H[0] = self.TDp.forward(-curl*up[1])\n\t            H[1] = self.TDp.forward(curl*up[0])\n\t        self.H_.mask_nyquist(self.mask)\n\t    def compute_v(self, rk):\n\t        u = self.u_.v\n\t        if comm.Get_rank() == 0:\n", "            self.v00[:] = u[1, :, 0].real\n\t            self.h1[:] = self.H_[1, :, 0].real\n\t        # Find velocity components v from div. constraint\n\t        u[1] = 1j*self.dudx()/self.K[1]\n\t        # Still have to compute for wavenumber = 0, 0\n\t        if comm.Get_rank() == 0:\n\t            # v component\n\t            self.pdes1d['v0'].compute_rhs(rk)\n\t            u[1, :, 0] = self.pdes1d['v0'].solve_step(rk)\n\t        return u\n", "    def compute_pressure(self):\n\t        if self.solP is None:\n\t            self.d2udx2 = Project(self.nu*Dx(self.u_[0], 0, 2), self.TC)\n\t            N0 = self.N0 = FunctionSpace(self.N[0], self.B0.family(), bc={'left': {'N': self.d2udx2()}, 'right': {'N': self.d2udx2()}})\n\t            TN = self.TN = TensorProductSpace(comm, (N0, self.F1), modify_spaces_inplace=True)\n\t            sol = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\t            self.divH = Inner(TestFunction(TN), -div(self.H_))\n\t            self.solP = sol(inner(TestFunction(TN), div(grad(TrialFunction(TN)))))\n\t            self.p_ = Function(TN)\n\t        self.d2udx2()\n", "        self.N0.bc.set_tensor_bcs(self.N0, self.TN)\n\t        p_ = self.solP(self.divH(), self.p_, constraints=((0, 0),))\n\t        return p_\n\t    def print_energy_and_divergence(self, t, tstep):\n\t        if tstep % self.moderror == 0 and self.moderror > 0:\n\t            ub = self.u_.backward(self.ub)\n\t            e0 = inner(1, ub[0]*ub[0])\n\t            e1 = inner(1, ub[1]*ub[1])\n\t            divu = self.divu().backward()\n\t            e3 = np.sqrt(inner(1, divu*divu))\n", "            if comm.Get_rank() == 0:\n\t                print(\"Time %2.5f Energy %2.6e %2.6e div %2.6e\" %(t, e0, e1, e3))\n\t    def init_from_checkpoint(self):\n\t        self.checkpoint.read(self.u_, 'U', step=0)\n\t        self.checkpoint.open()\n\t        tstep = self.checkpoint.f.attrs['tstep']\n\t        t = self.checkpoint.f.attrs['t']\n\t        self.checkpoint.close()\n\t        return t, tstep\n\t    def initialize(self, from_checkpoint=False):\n", "        if from_checkpoint:\n\t            return self.init_from_checkpoint()\n\t        raise RuntimeError('Initialize solver in subclass')\n\t    def plot(self, t, tstep):\n\t        pass\n\t    def update(self, t, tstep):\n\t        self.plot(t, tstep)\n\t        self.print_energy_and_divergence(t, tstep)\n\t    def tofile(self, tstep):\n\t        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n", "    def prepare_step(self, rk):\n\t        self.convection()\n\t    def assemble(self):\n\t        for pde in self.pdes.values():\n\t            pde.assemble()\n\t        if comm.Get_rank() == 0:\n\t            for pde in self.pdes1d.values():\n\t                pde.assemble()\n\t    def solve(self, t=0, tstep=0, end_time=1000):\n\t        self.assemble()\n", "        while t < end_time-1e-8:\n\t            for rk in range(self.PDE.steps()):\n\t                self.prepare_step(rk)\n\t                for eq in self.pdes.values():\n\t                    eq.compute_rhs(rk)\n\t                for eq in self.pdes.values():\n\t                    eq.solve_step(rk)\n\t                self.compute_v(rk)\n\t            t += self.dt\n\t            tstep += 1\n", "            self.update(t, tstep)\n\t            self.checkpoint.update(t, tstep)\n\t            if tstep % self.modsave == 0:\n\t                self.tofile(tstep)\n"]}
{"filename": "Postprocess_routines/VisualizeSol.py", "chunked_list": ["from shenfun import *\n\tfrom ChannelFlow2D import KMM\n\timport matplotlib.pyplot as plt\n\timport sympy\n\tfrom Tfunc import Tfunc\n\tfrom mpi4py_fft import generate_xdmf\n\timport numpy as np\n\t'''\n\tVisualizeSol.py: Script aimed at visualizing the control sequence of a given episode\n\tAuthor: Colin Vignon | FLOW, KTH Stockholm\n", "Date: 3/25/2023\n\tSet parameters in the __main__ function, as desired.\n\t'''\n\tnp.warnings.filterwarnings('ignore')\n\tx, y, tt = sympy.symbols('x,y,t', real=True)\n\tcomm = MPI.COMM_WORLD\n\tclass RayleighBenard(KMM):\n\t    def __init__(self,\n\t                 N=(64, 96),\n\t                 domain=((-1, 1), (0, 2*sympy.pi)),\n", "                 Ra=10000.,\n\t                 Pr=0.7,\n\t                 dt=0.05,\n\t                 bcT=(2, 1),\n\t                 conv=0,\n\t                 filename='RB',\n\t                 family='C',\n\t                 padding_factor=(1, 1.5),\n\t                 modplot=10,\n\t                 modsave=1e8,\n", "                 moderror=10,\n\t                 checkpoint=10,\n\t                 timestepper='IMEXRK3'):\n\t        KMM.__init__(self, N=N, domain=domain, nu=np.sqrt(Pr/Ra), dt=dt, conv=conv,\n\t                     filename=filename, family=family, padding_factor=padding_factor,\n\t                     modplot=modplot, modsave=modsave, moderror=moderror,\n\t                     checkpoint=checkpoint, timestepper=timestepper, dpdy=0)\n\t        self.kappa = 1./np.sqrt(Pr*Ra)\n\t        self.bcT = bcT\n\t        plt.close('all')\n", "        # Additional spaces and functions for Temperature equation\n\t        self.T0 = FunctionSpace(N[0], family, bc=bcT, domain=domain[0])\n\t        self.TT = TensorProductSpace(comm, (self.T0, self.F1), modify_spaces_inplace=True) # Temperature\n\t        self.uT_ = Function(self.BD)     # Velocity vector times T\n\t        self.T_ = Function(self.TT)      # Temperature solution\n\t        self.Tb = Array(self.TT)\n\t        self.file_T = ShenfunFile('_'.join((filename, 'T')), self.TT, backend='hdf5', mode='w', mesh='uniform')\n\t        # Modify checkpoint file\n\t        self.checkpoint.data['0']['T'] = [self.T_]\n\t        dt = self.dt\n", "        kappa = self.kappa\n\t        # Chebyshev matrices are not sparse, so need a tailored solver. Legendre has simply 5 nonzero diagonals\n\t        sol2 = chebyshev.la.Helmholtz if self.B0.family() == 'chebyshev' else la.SolverGeneric1ND\n\t        # Addition to u equation.\n\t        self.pdes['u'].N = [self.pdes['u'].N, Dx(self.T_, 1, 2)]\n\t        self.pdes['u'].latex += r'\\frac{\\partial^2 T}{\\partial y^2}'\n\t        # Remove constant pressure gradient from v0 equation\n\t        self.pdes1d['v0'].N = self.pdes1d['v0'].N[0]\n\t        # Add T equation\n\t        q = TestFunction(self.TT)\n", "        self.pdes['T'] = self.PDE(q,\n\t                                  self.T_,\n\t                                  lambda f: kappa*div(grad(f)),\n\t                                  -div(self.uT_),\n\t                                  dt=self.dt,\n\t                                  solver=sol2,\n\t                                  latex=r\"\\frac{\\partial T}{\\partial t} = \\kappa \\nabla^2 T - \\nabla \\cdot \\vec{u}T\")\n\t        self.im1 = None\n\t        self.im2 = None\n\t\t# Observation outputs\n", "        self.out = []\n\t        self.out2 = []\n\t        self.instant_Nusselt = []\n\t        # Others\n\t        self.obsGrid = (8,32)\n\t        self.Nstep = (N[0]//self.obsGrid[0], N[1]//self.obsGrid[1])\n\t    def update_bc(self, t):\n\t        # Update time-dependent bcs.\n\t        self.T0.bc.update(t)\n\t        self.T_.get_dealiased_space(self.padding_factor).bases[0].bc.update(t)\n", "    def prepare_step(self, rk):\n\t        self.convection()\n\t        Tp = self.T_.backward(padding_factor=self.padding_factor)\n\t        self.uT_ = self.up.function_space().forward(self.up*Tp, self.uT_)\n\t    def tofile(self, tstep):\n\t        self.file_u.write(tstep, {'u': [self.u_.backward(mesh='uniform')]}, as_scalar=True)\n\t        self.file_T.write(tstep, {'T': [self.T_.backward(mesh='uniform')]})\n\t    def init_from_checkpoint(self):\n\t        self.checkpoint.read(self.u_, 'U', step=0)\n\t        self.checkpoint.read(self.T_, 'T', step=0)\n", "        self.checkpoint.open()\n\t        tstep = self.checkpoint.f.attrs['tstep']\n\t        t = self.checkpoint.f.attrs['t']\n\t        self.checkpoint.close()\n\t        return t, tstep\n\t    def print_energy_and_divergence(self, t, tstep):\n\t        if tstep % self.moderror == 0 and self.moderror > 0:\n\t            ub = self.u_.backward(self.ub)\n\t            Tb = self.T_.backward(self.Tb)\n\t            e0 = inner(1, ub[0]*ub[0])\n", "            e1 = inner(1, ub[1]*ub[1])\n\t            d0 = inner(1, Tb*Tb)\n\t            divu = self.divu().backward()\n\t            e3 = np.sqrt(inner(1, divu*divu))\n\t            if comm.Get_rank() == 0:\n\t                if tstep % (10*self.moderror) == 0 or tstep == 0:\n\t                    print(f\"{'Time':^11}{'uu':^11}{'vv':^11}{'T*T':^11}{'div':^11}\")\n\t                print(f\"{t:2.4e} {e0:2.4e} {e1:2.4e} {d0:2.4e} {e3:2.4e}\")\n\t    def initialize(self, rand=0.001, from_checkpoint=False):\n\t        if from_checkpoint:\n", "            self.checkpoint.read(self.u_, 'U', step=0)\n\t            self.checkpoint.read(self.T_, 'T', step=0)\n\t            self.checkpoint.open()\n\t            tstep = self.checkpoint.f.attrs['tstep']\n\t            t = self.checkpoint.f.attrs['t']\n\t            self.checkpoint.close()\n\t            self.update_bc(t)\n\t            return t, tstep\n\t        X = self.X\n\t        fun = self.bcT[0]\n", "        self.Tb[:] = 0.5*(1 + 0.5*self.bcT[1]-X[0]/(1+self.bcT[1])+ 0.125*(2-self.bcT[1])*np.sin(np.pi*X[0]))*fun + rand*np.random.randn(*self.Tb.shape)*(1-X[0])*(1+X[0])\n\t        self.T_ = self.Tb.forward(self.T_)\n\t        self.T_.mask_nyquist(self.mask)\n\t        return 0, 0\n\t    def outputs(self, tstep):\n\t    \tif tstep == 0:  \n\t            self.out = []\n\t            self.out2 = []\n\t    \telse:  \n\t            new_out = np.zeros((3, self.obsGrid[0], self.obsGrid[1]))\n", "            ub = self.u_.backward(self.ub)\n\t            Tb = self.T_.backward(self.Tb)\n\t            new_out[0] = ub[1, ::self.Nstep[0], ::self.Nstep[1]]  # horizontal speed\n\t            new_out[1] = ub[0, ::self.Nstep[0], ::self.Nstep[1]]  # vertical speed\n\t            new_out[2] = Tb[::self.Nstep[0], ::self.Nstep[1]]\n\t            self.out.append(new_out)\n\t            new_out2 = new_out.reshape(3*self.obsGrid[0]*self.obsGrid[1],)\n\t            self.out2.append(new_out2)\n\t    def DRL_inputs(self, D = 4):  # inputs for the DRL algo\n\t        return self.out2[-1]\n", "    def compute_Nusselt(self):\n\t        div = self.kappa*(1/2)\n\t        uyT_ = np.mean(np.mean(np.multiply(self.out[-1][1], self.out[-1][2]), axis=1), axis = 0)\n\t        T_ = np.mean(np.gradient(np.mean(self.out[-1][2], axis=1), axis=0))\n\t        return (uyT_ - self.kappa*T_)/div\n\t    def evolve(self, new_bcT, t_ini=None, tstep_ini = None):\n\t        self.bcT = new_bcT    \n\t        new_t, new_tstep = t_ini, tstep_ini\n\t        self.T0.bc.bc['left']['D'] = self.bcT[0]\n\t        self.T0.bc.update()\n", "        self.T0.bc.set_tensor_bcs(self.T0, self.T0.tensorproductspace)\n\t        TP0 = self.T_.get_dealiased_space(self.padding_factor).bases[0]\n\t        TP0.bc.bc['left']['D'] = self.bcT[0]\n\t        TP0.bc.update()\n\t        TP0.bc.set_tensor_bcs(TP0, TP0.tensorproductspace)\n\t    def solve(self, t=0, tstep=0, end_time=10000):\n\t        c = self.pdes['u'].stages()[2]\n\t        self.assemble()\n\t        while t < end_time-1e-8:\n\t            for rk in range(self.PDE.steps()):\n", "                self.prepare_step(rk)\n\t                for eq in ['u', 'T']:\n\t                    self.pdes[eq].compute_rhs(rk)\n\t                for eq in ['u']:\n\t                    self.pdes[eq].solve_step(rk)\n\t                self.compute_v(rk)\n\t                self.update_bc(t+self.dt*c[rk+1]) # modify time-dep boundary condition\n\t                self.pdes['T'].solve_step(rk)\n\t            self.outputs(tstep)\n\t            if tstep >= 1:\n", "                self.instant_Nusselt.append(self.compute_Nusselt())\n\t            t += self.dt\n\t            tstep += 1\n\t            self.update(t, tstep)\n\t            self.checkpoint.update(t, tstep)\n\t            if tstep % self.modsave == 0:\n\t                self.tofile(tstep)\n\t        return t, tstep\n\tif __name__ == '__main__':\n\t    from time import time\n", "    import csv\n\t    import os\n\t    # Set parameters here, as desired\n\t    nb_actions = 200  \n\t    duration_baseline = 400.0\n\t    duration_action = 1.5\n\t    simu_name = 'RB_2D_SARL'\n\t    num_ep = 20 # Which episode to visualise\n\t    nb_segs = 10\n\t    name = 'output_actions.csv'\n", "    # Set paths here\n\t    general_path = '/scratch/jvasanth/2022_Rayleigh_Benard_Control_DRL_Shenfun_2D_3D/shenfun_files/cases/'+simu_name\n\t    specific_path = general_path+'/actions/environment1/ep_'+str(num_ep)+'/'\n\t    move_path = general_path+'/CFD_n1/EP_'+str(num_ep)+'/'\n\t    dicTemps = {}  # dictionary with the nb_actions successive boundary conditions\n\t    with open(specific_path+name, 'r') as f:\n\t        reader = csv.reader(f, delimiter=';')\n\t        line = next(reader)\n\t        for i in range(nb_actions):\n\t            line = next(reader)\n", "            dicTi = {}\n\t            dicTi.update({'T'+str(k):float(line[k+1]) for k in range(nb_segs)})\n\t            dicTemps.update({'Action_'+str(i):dicTi})\n\t    os.system('cp '+general_path+'/baseline/*.h5 /scratch/jvasanth/2022_Rayleigh_Benard_Control_DRL_Shenfun_2D_3D/Postprocess_routines/')\n\t    os.chdir('/scratch/jvasanth/2022_Rayleigh_Benard_Control_DRL_Shenfun_2D_3D/Postprocess_routines/')\n\t    for i in range(nb_actions):\t\n\t        N = (64, 96)\n\t        d = {\n\t            'N': N,\n\t            'Ra': 10000.,\n", "            'Pr': 0.7,\n\t            'dt': 0.05,\n\t            'filename': f'RB_{N[0]}_{N[1]}',\n\t            'conv': 0,\n\t            'modplot': 10,\n\t            'moderror': 10,\n\t            'modsave': 10,\n\t            'bcT': (Tfunc(nb_seg=nb_segs, dicTemp=dicTemps.get('Action_'+str(i))).apply_T(y), 1),\n\t            'family': 'C',\n\t            'checkpoint': 10,\n", "            'timestepper': 'IMEXRK3'\n\t            }\n\t        if i == 0:\n\t            c = RayleighBenard(**d)\n\t            t, tstep = c.initialize(rand=0.001, from_checkpoint=True)\n\t            t0 = time()\n\t            new_t, new_tstep = c.solve(t=t, tstep=tstep, end_time=duration_baseline + (i+1)*duration_action)\n\t            print('Computing time %2.4f'%(time()-t0))\n\t        else:\n\t            c.evolve(d.get('bcT'), t_ini=new_t, tstep_ini = new_tstep)\n", "            new_t, new_tstep = c.solve(t=new_t, tstep=new_tstep, end_time=duration_baseline + (i+1)*duration_action)\n\t        plt.close('all')\n\t    # Produces the visualisation of Temperature and velocity. \n\t    generate_xdmf('RB_'+str(N[0])+'_'+str(N[1])+'_T.h5')\n\t    generate_xdmf('RB_'+str(N[0])+'_'+str(N[1])+'_U.h5')\n"]}
{"filename": "Postprocess_routines/Tfunc.py", "chunked_list": ["from shenfun import *\n\timport sympy\n\tfrom sympy.parsing.sympy_parser import parse_expr\n\t'''\n\tTfunc.py: script needed for the postprocess routines, that generates bounday conditions\n\tAuthor: Colin Vignon | FLOW, KTH Stockholm\n\tDate: 3/25/2023\n\t'''\n\t# IMPORTANT: redefine the domain here\n\tdomain = ((-1, 1), (0, 2*sympy.pi))\n", "class Tfunc():\n\t\tdef __init__(self, nb_seg = None, dicTemp = None):\n\t\t\t''' N = number of actuators/segments on the hot boundary layer\n\t\t\tdicTemp = temperature variations of the segments: Ti' = Tnormal + Ti, Tnormal = 0.6 here''' \n\t\t\tself.nb_seg = nb_seg\n\t\t\tself.dicTemp = dicTemp\n\t\t\tself.ampl = 0.75  # Amplitude of variation of T\n\t\t\tself.dx = 0.03  # half-length of the interval on which we do the smoothing\n\t\t\t#self.length = length  # length of the domain\n\t\tdef apply_T(self, x):\n", "\t\tvalues = self.ampl*np.array(list(self.dicTemp.values()))\n\t\t\tMean = values.mean()\n\t\t\tK2 = max(1, np.abs(values-np.array([Mean]*self.nb_seg)).max()/self.ampl)\n\t\t\t# Position:\n\t\t\txmax = domain[1][1]\n\t\t\tind = sympy.floor(self.nb_seg*x//xmax)\n\t\t\tseq=[]\n\t\t\tcount = 0\n\t\t\twhile count<self.nb_seg-1:  # Temperatures will vary between: 2 +- 0.75\n\t\t\t\tx0 = count*xmax/self.nb_seg\n", "\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count+1))-Mean)/K2\n\t\t\t\tif count == 0:\n\t\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(self.nb_seg-1))-Mean)/K2\n\t\t\t\telse:\n\t\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))  # cubic smoothing\t\t\n\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, x<x1))  # cubic smoothing\n", "\t\t\tcount += 1\n\t\t\t\tif count == self.nb_seg-1:\n\t\t\t\t\tx0 = count*xmax/self.nb_seg\n\t\t\t\t\tx1 = (count+1)*xmax/self.nb_seg\n\t\t\t\t\tT0 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count-1))-Mean)/K2\n\t\t\t\t\tT1 = 2+(self.ampl*self.dicTemp.get(\"T\"+str(count))-Mean)/K2\n\t\t\t\t\tT2 = 2+(self.ampl*self.dicTemp.get(\"T0\")-Mean)/K2\n\t\t\t\t\tseq.append((T0+((T0-T1)/(4*self.dx**3))*(x-x0-2*self.dx)*(x-x0+self.dx)**2, x<x0+self.dx))\n\t\t\t\t\tseq.append((T1, x<x1-self.dx))\n\t\t\t\t\tseq.append((T1+((T1-T2)/(4*self.dx**3))*(x-x1-2*self.dx)*(x-x1+self.dx)**2, True))\n", "\t\treturn sympy.Piecewise(*seq)\n"]}
{"filename": "parameters/parameters_RB_2D_MARL.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# parameters file for the MARL framework\n\t#\n\t#\n\t# FLOW, KTH Stockholm | 09/04/2023\n\tfrom __future__ import print_function, division\n\tfrom Tfunc import Tfunc, domain\n", "import numpy as np\n\timport math\n\timport sympy\n\t# case name - should be the same name as this file, without the prefix parameters_\n\tcase            = 'RB_2D_MARL'\n\tsimu_name       = case\n\tdimension       = '2D'\n\treward_function = 'Nusselt' \n\t# Number of calculation processors\n\tnb_proc     = 1  \n", "# Number of environments in parallNel\n\tnum_servers = 1  \n\t# Number of segments (actuators) on the lower boundary \n\tn_seg = 10  \n\t# Number of invariant parallel environments ('multi-agents') : \n\tnb_inv_envs = n_seg  \n\t# always take nb_inv_envs = n_seg for MARL\n\t# Duration of baseline simulation (in nondimensional simulation time)\n\tsimulation_duration   = 10.0   \n\tsimulation_time_start = 0.0\n", "# Duration of each actuation (in nondimensional simulation time)\n\tdelta_t_smooth   = 1.5      \n\tdelta_t_converge = 0.0       \n\tsmooth_func      = 'linear' \n\t# Total number of episodes : \n\t# CHOOSE A MULTIPLE OF nb_inv_envs*num_servers and add +1 \n\tnum_episodes = 11 \n\t# Number of actuations per episode \n\tnb_actuations = 2 \n\tnb_actuations_deterministic = nb_actuations*4\n", "# Probes\n\tprobes_location      = 'cartesian_grid'\n\tnumber_of_probes     = (8,32)\n\tN = (64,96)  # simulation mesh grid\n\t# misc\n\tpost_process_steps = 200  \n\talphaRestart = 0.9 \n\tx, y, tt = sympy.symbols('x,y,t', real=True)\n\tCFD_params = {\n\t            'number_of_actuators': n_seg, \n", "            'hor_inv_probes':number_of_probes[1]//nb_inv_envs,  \n\t            'dico_d':        {'N': N,\n\t                              'domain': domain,\n\t                              'Ra': 10000.,\n\t     \t                      'Pr': 0.7,\n\t     \t                      'dt': 0.05,\n\t     \t                      'filename': f'RB_{N[0]}_{N[1]}',\n\t     \t                      'conv': 0,\n\t     \t                      'modplot': 10,\n\t     \t                      'obsGrid': number_of_probes,  \n", "    \t                      'moderror': 10000,\n\t    \t                      'modsave': 10000,\n\t     \t                      'bcT': (Tfunc(nb_seg=n_seg, dicTemp={'T'+str(i):1. for i in range(n_seg)}).apply_T(y), 1), \n\t     \t                      'family': 'C',\n\t     \t                      'checkpoint': 10,\n\t     \t                      #'padding_factor': 1,\n\t     \t                      'timestepper': 'IMEXRK3'\n\t     \t                     }\n\t}\n\tsimulation_params = {\n", "\t'simulation_duration':  simulation_duration,  \n\t\t'simulation_timeframe': [simulation_time_start,simulation_time_start+simulation_duration],\n\t\t'delta_t_smooth':       delta_t_smooth,\n\t\t'delta_t_converge':     delta_t_converge,\n\t\t'smooth_func':          smooth_func,\n\t\t'post_process_steps' :  post_process_steps\n\t}\n\t# Optimization\n\toptimization_params = {\n\t\t\"min_ampl_temp\":             -1.,\n", "\t\"max_ampl_temp\":             1.,\n\t\t\"norm_reward\":               1.,\n\t\t\"offset_reward\":             2.6726  \n\t}\n\tinspection_params = {\n\t\t\"plot\":                False,  \n\t\t\"step\":                50,\n\t\t\"dump\":                100,\n\t\t\"show_all_at_reset\":   True,\n\t\t\"single_run\":          False\n", "}\n"]}
{"filename": "parameters/parameters_RB_2D_SARL.py", "chunked_list": ["#!/bin/env python\n\t#\n\t# DEEP REINFORCEMENT LEARNING FOR RAYLEIGH-BENARD CONVECTION\n\t#\n\t# parameters file for the SARL framework\n\t#\n\t#\n\t# FLOW, KTH Stockholm | 09/04/2023\n\tfrom __future__ import print_function, division\n\timport numpy as np\n", "import math\n\t# case name - should be the same name as this file, without the prefix parameters_\n\tcase            = 'RB_2D_SARL'\n\tsimu_name       = case\n\tdimension       = '2D'\n\treward_function = 'Nusselt' \n\t# Number of calculation processors\n\tnb_proc     = 1 \n\t# number of environment in parallel\n\tnum_servers = 1 \n", "# Number of segments (actuators) on the lower boundary  \n\tn_seg = 10   \n\t# Number of invariant parallel environments ('multi-agents' - set to one for single agent)\n\tnb_inv_envs = 1  \n\t# Duration of baseline simulation (in nondimensional simulation time)\n\tsimulation_duration   = 10.0   \n\tsimulation_time_start = 0.0\n\t# Duration of each actuation (in nondimensional simulation time)\n\tdelta_t_smooth   = 1.5      \n\tdelta_t_converge = 0.0       \n", "smooth_func      = 'linear' \n\t# post options\n\tpost_process_steps = 200 \n\t# Total number of episodes\n\tnum_episodes = 1 \n\t# Number of actuations per episode \n\tnb_actuations = 2 \n\tnb_actuations_deterministic = nb_actuations*4\n\t# Probes\n\tprobes_location      = 'cartesian_grid'\n", "number_of_probes     = (8,32)\n\t# Simulation parameters\n\tsimulation_params = {\n\t\t'simulation_duration':  simulation_duration,  \n\t\t'simulation_timeframe': [simulation_time_start,simulation_time_start+simulation_duration],\n\t\t'delta_t_smooth':       delta_t_smooth,\n\t\t'delta_t_converge':     delta_t_converge,\n\t\t'smooth_func':          smooth_func,\n\t\t'post_process_steps' :  post_process_steps\n\t}\n", "# Variational input  \n\tvariational_input = {\n\t\t'filename':        'RB_2D', \n\t\t'porous':          False, \n\t\t\"d\":               0, \n\t\t\"time\":            -0.25, \n\t\t\"initial_time\":    None, \n\t}\n\toutput_params = {\n\t\t'nb_probes':  number_of_probes,\n", "\t'probe_type': 'u_T'\n\t}\n\t# Optimization\n\toptimization_params = {\n\t\t\"min_ampl_temp\":             -1.,\n\t\t\"max_ampl_temp\":             1.,\n\t\t#\"norm_Temp\":                 0.4,  \n\t\t\"norm_reward\":               1.,  \n\t\t#\"norm_press\":                    2,  \n\t\t\"offset_reward\":                 2.6788,  \n", "}\n\tinspection_params = {\n\t\t\"plot\":                False,  \n\t\t\"step\":                50,\n\t\t\"dump\":                100,\n\t\t\"show_all_at_reset\":   True,\n\t\t\"single_run\":          False\n\t}\n"]}
