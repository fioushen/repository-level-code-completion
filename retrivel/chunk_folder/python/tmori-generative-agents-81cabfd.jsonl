{"filename": "db_manager.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom document_db import load_db_with_type, similarity_search_with_score\n\timport sys\n\timport pandas as pd\n\tdef get_qa(db_dir: str, doc_id: str):\n\t    return load_db_with_type(db_dir + \"/\" + doc_id)\n\tdef get_similarity_search_with_scores(db_dir: str, doc_id: str, terms: str, top_k: int):\n\t    return similarity_search_with_score(db_dir + \"/\" + doc_id, terms, top_k)\n\tdef get_similarity_search_with_average_score(db_dir: str, doc_id: str, terms: str, top_k: int):\n", "    doc_scores = similarity_search_with_score(db_dir + \"/\" + doc_id, terms, top_k)\n\t    scores = [score[1] for score in doc_scores]\n\t    scores_series = pd.Series(scores, dtype='float64')\n\t    average_score = scores_series.mean()\n\t    return average_score\n\tdef get_similarity_search_results(doclist: str, db_dir: str, terms: str, top_k: int):\n\t    with open(doclist, \"r\") as file:\n\t        lines = file.readlines()\n\t        total_list = [line.strip() for line in lines]\n\t    scores = []\n", "    entries = []\n\t    for entry in total_list:\n\t        score = get_similarity_search_with_average_score(db_dir, entry, terms, top_k)\n\t        scores.append(score)  \n\t        entries.append(entry)\n\t    df = pd.DataFrame({'title': entries, 'score': scores})\n\t    top = df.sort_values(by='score', ascending=True).head(top_k)['title'].tolist()\n\t    return top\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) != 5:\n", "        print(\"USAGE: \" + sys.argv[0] + \" <db_dir> <doclist> <terms> <num>\")\n\t        sys.exit(1)\n\t    db_dir=sys.argv[1]\n\t    doclist=sys.argv[2]\n\t    terms=sys.argv[3]\n\t    num=int(sys.argv[4])\n\t    docs = get_similarity_search_results(doclist, db_dir, terms, num)\n\t    for entry in docs:\n\t        print(entry)\n"]}
{"filename": "params.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport json\n\tdef get_param(param_name: str):\n\t    with open('./params.json', 'r') as file:\n\t        param = json.load(file)\n\t        return param.get(param_name)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 2:\n", "        print(\"Usage: <param_name>\")\n\t        sys.exit(1)\n\t    param_name = sys.argv[1]\n\t    print(get_param(param_name))\n"]}
{"filename": "document_db.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\t# hyper parameters\n\tllm_name=\"gpt-4-0613\"\n\t#llm_name=\"gpt-4\"\n\t#llm_name=\"gpt-3.5-turbo\"\n\t#llm_name=\"gpt-3.5-turbo-0613\"\n\t#llm_name=\"gpt-3.5-turbo-16k\"\n\tembedding_model='text-embedding-ada-002'\n", "page_chunk_size = 1024\n\tmax_token_num = 4096\n\tconversation_window_size = 3\n\tconversation_token_num = 1024\n\tconversation_history_type = \"window\" # token or window\n\tvector_db = None\n\tif __name__ == \"__main__\":\n\t    if (len(sys.argv) == 1) or (len(sys.argv) > 4):\n\t        print(\"USAGE: \" + sys.argv[0] + \" new [<doc_dir> [<db_dir>]]\")\n\t        print(\"USAGE: \" + sys.argv[0] + \" chat [<db_dir>]\")\n", "        print(\"USAGE: \" + sys.argv[0] + \" question <db_dir>\")\n\t        sys.exit(1)\n\t    mode=sys.argv[1]\n\t    db_dir = \"DB\"\n\t    doc_dir = \"documents\"\n\t    ans_dir = \"answer\"\n\t    if mode == \"chat\":\n\t        if len(sys.argv) != 2 and len(sys.argv) != 3:\n\t            print(\"USAGE: \" + sys.argv[0] + \" chat [<db_dir>]\")\n\t            sys.exit(1)\n", "        if len(sys.argv) == 3:\n\t            db_dir = sys.argv[2]\n\t    if mode == \"question\":\n\t        if len(sys.argv) != 4:\n\t            print(\"USAGE: \" + sys.argv[0] + \" question <db_dir>\")\n\t            sys.exit(1)\n\t        question = sys.argv[2]\n\t        db_dir = sys.argv[3]\n\t    if mode == \"new\":\n\t        if len(sys.argv) != 2 and len(sys.argv) != 4:\n", "            print(\"USAGE: \" + sys.argv[0] + \" new [<doc_dir> [<db_dir>]]\")\n\t            sys.exit(1)\n\t        if len(sys.argv) == 4:\n\t            doc_dir=sys.argv[2]\n\t            db_dir = sys.argv[3]\n\t    print(\"DB_DIR =\" + db_dir)\n\t    print(\"DOC_DIR=\" + doc_dir)\n\telse:\n\t    conversation_history_type=\"window\"\n\t    conversation_window_size=0\n", "import os\n\timport numpy as np\n\timport openai\n\tfrom langchain.embeddings.openai import OpenAIEmbeddings\n\tfrom langchain.vectorstores import Chroma\n\tfrom langchain.chat_models import ChatOpenAI\n\tfrom langchain.chains import ConversationalRetrievalChain\n\tfrom langchain.document_loaders import PyPDFLoader\n\tfrom langchain.document_loaders import CSVLoader\n\tfrom langchain.document_loaders import UnstructuredPowerPointLoader\n", "from langchain.document_loaders import UnstructuredURLLoader\n\tfrom langchain.document_loaders import JSONLoader\n\tfrom langchain.text_splitter import CharacterTextSplitter\n\tfrom langchain.memory import ConversationBufferWindowMemory, ConversationTokenBufferMemory\n\tdef create_db(doc_dir, db_dir, embedding_model, chunk_size):\n\t    pdf_files = [ file for file in os.listdir(doc_dir) if file.endswith(\".pdf\")]\n\t    json_files = [ file for file in os.listdir(doc_dir) if file.endswith(\".json\")]\n\t    csv_files = [ file for file in os.listdir(doc_dir) if file.endswith(\".csv\")]\n\t    pptx_files = [ file for file in os.listdir(doc_dir) if file.endswith(\".pptx\")]\n\t    url_files = [ file for file in os.listdir(doc_dir) if file.endswith(\".url\")]\n", "    text_splitter = CharacterTextSplitter(\n\t        separator = \"\\n\",\n\t        chunk_size = chunk_size,\n\t        chunk_overlap = 0,\n\t    )\n\t    files = pdf_files + csv_files + pptx_files + url_files + json_files\n\t    pages = []\n\t    for file in files:\n\t        print(\"INFO: Loading document=\" + file)\n\t        if \".pdf\" in file:\n", "            loader = PyPDFLoader(doc_dir + '/' + file)\n\t        elif \".csv\" in file:\n\t            loader = CSVLoader(doc_dir + '/' + file)\n\t        elif \".pptx\" in file:\n\t            loader = UnstructuredPowerPointLoader(doc_dir + '/' + file)\n\t        elif \".json\" in file:\n\t            loader = JSONLoader(file_path= doc_dir + '/' + file, jq_schema='.messages[].content')\n\t        elif \".url\" in file:\n\t            with open(doc_dir + '/' + file, 'r') as file:\n\t                urls = file.read().splitlines()\n", "            loader = UnstructuredURLLoader(urls = urls)\n\t        else:\n\t            print(\"WARNING: Not supported document=\" + file)\n\t            continue\n\t        #print(\"INFO: Spliting document=\" + file)\n\t        tmp_pages = loader.load_and_split()\n\t        chanked_pages = text_splitter.split_documents(tmp_pages)\n\t        pages = pages + chanked_pages\n\t    print(\"INFO: Storing Vector DB:\" + db_dir)\n\t    embeddings = OpenAIEmbeddings(deployment=embedding_model)\n", "    vectorstore = Chroma.from_documents(pages, embedding=embeddings, persist_directory=db_dir)\n\t    vectorstore.persist()\n\tdef load_db(db_dir, llm_name, embedding_model, token_num, history_type, num):\n\t    global vector_db\n\t    print(\"INFO: Setting up LLM:\" + db_dir)\n\t    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\t    llm = ChatOpenAI(\n\t        temperature=0, \n\t        model_name=llm_name, \n\t        max_tokens=token_num)\n", "    embeddings = OpenAIEmbeddings(deployment=embedding_model)\n\t    vectorstore = Chroma(persist_directory=db_dir, embedding_function=embeddings)\n\t    vector_db = vectorstore\n\t    if (history_type == \"window\"):\n\t        memory = ConversationBufferWindowMemory(k=num, memory_key=\"chat_history\", return_messages=True)\n\t    else:\n\t        memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=num, memory_key=\"chat_history\", return_messages=True)\n\t    qa = ConversationalRetrievalChain.from_llm(\n\t        llm, \n\t        vectorstore.as_retriever(), \n", "        memory=memory\n\t        )\n\t    return qa\n\tdef load_db_with_type(db_dir):\n\t    global llm_name, max_token_num, conversation_history_type, conversation_window_size, conversation_token_num\n\t    if (conversation_history_type == \"window\"):\n\t        qa = load_db(db_dir, llm_name, embedding_model, max_token_num, conversation_history_type, conversation_window_size)\n\t    else:\n\t        qa = load_db(db_dir, llm_name, embedding_model, max_token_num, conversation_history_type, conversation_token_num)\n\t    return qa\n", "def embedding(text: str) -> list[float]:\n\t    result = openai.Embedding.create(input=text, model=embedding_model)\n\t    if isinstance(result, dict):\n\t        embedding = result[\"data\"][0][\"embedding\"]\n\t        return embedding\n\t    return []\n\tdef cos_sim(a, b) -> float:\n\t    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\tdef calc_similarity(str1, str2):\n\t    try:\n", "        s1 = np.array(embedding(str1))\n\t        s2 = np.array(embedding(str2))\n\t        return cos_sim(s1, s2)\n\t    except Exception as e:\n\t        print(\"An error occurred:\", str(e))\n\t        return None\n\tdef similarity_search_with_score(db_dir: str, terms: str, top_k: int):\n\t    #print(f\"db_dir={db_dir} terms={terms} embedding_model={embedding_model}\")\n\t    embeddings = OpenAIEmbeddings(deployment=embedding_model)\n\t    vectorstore = Chroma(persist_directory=db_dir, embedding_function=embeddings)\n", "    vector_db = vectorstore\n\t    docs = vector_db.similarity_search_with_score(terms, top_k = top_k)\n\t    #print(str(docs))\n\t    #print(f\"content: {docs[0][0].page_content}\", f\"score: {docs[0][1]}\")\n\t    #print(f\"content: {docs[1][0].page_content}\", f\"score: {docs[1][1]}\")\n\t    return docs\n\tif __name__ == \"__main__\":\n\t    if mode == \"new\":\n\t        _ = create_db(doc_dir, db_dir, embedding_model, page_chunk_size)\n\t    elif mode == \"question\":\n", "        qa = load_db_with_type(db_dir)\n\t        result = qa({\"question\": question})\n\t        print(result[\"answer\"])\n\t    else:\n\t        qa = load_db_with_type(db_dir)\n\t        while True:\n\t            query = input(\"> \")\n\t            if query == 'exit' or query == 'q' or query == \"quit\":\n\t                print(\"See you again!\")\n\t                sys.exit(0)\n", "            print(\"Q: \" + query)\n\t            result = qa({\"question\": query})\n\t            print(\"A: \"+result[\"answer\"])\n\t            #docs = vector_db.similarity_search_with_score(query, top_k = 1)\n\t            #print(str(docs))\n\t            #print(f\"content: {docs[0][0].page_content}\", f\"score: {docs[0][1]}\")\n\t            #print(f\"content: {docs[1][0].page_content}\", f\"score: {docs[1][1]}\")"]}
{"filename": "prompt_template.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport os\n\tclass PromptTemplate:\n\t    def __init__(self, file_path):\n\t        try:\n\t            with open(file_path, 'r') as file:\n\t                self.template = file.read()\n\t        except FileNotFoundError:\n\t            raise FileNotFoundError(f\"File '{file_path}' not found.\")\n", "    def get_prompt(self, **kwargs) -> str:\n\t        return self.template.format(**kwargs)\n\tif __name__ == \"__main__\":\n\t    from params import get_param\n\t    prompt_template_path = get_param(\"prompt_templates_path\")\n\t    pt = PromptTemplate(prompt_template_path + \"/ptemplate_query.txt\")\n\t    while True:\n\t        target_doc_id = input(\"TargetDocID> \")\n\t        question = input(\"question> \")\n\t        reply = input(\"reply> \")\n", "        point = input(\"point> \")\n\t        prompt = pt.get_prompt(TargetDocID=target_doc_id, question=question, reply=reply, point=int(point))\n\t        print(\"PROMPT:\\n\" +prompt)\n"]}
{"filename": "reflection.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom question import get_response\n\tfrom prompt_template import PromptTemplate\n\timport json\n\timport traceback\n\timport json_utils\n\tclass Reflection:\n\t    def __init__(self, main_question: str, knowledge_path: str, plan_result_path: str, prompt_template_path: str, document_list_path: str, background_knowledge_path: str):\n\t        prompt_template =  PromptTemplate(prompt_template_path)\n", "        with open(knowledge_path, 'r') as file:\n\t            KnowledgesNeeds = file.read()\n\t        with open(plan_result_path, 'r') as file:\n\t            PlanResult = file.read()\n\t        with open(document_list_path, 'r') as file:\n\t            DocumentList = file.read()\n\t        with open(background_knowledge_path, 'r') as file:\n\t            BackgroundKnowledges = file.read()\n\t        self.query = prompt_template.get_prompt(\n\t            MainQuestion=main_question, \n", "            KnowledgesNeeds=KnowledgesNeeds,\n\t            PlanResult=PlanResult,\n\t            DocumentList=DocumentList,\n\t            BackgroundKnowledges=BackgroundKnowledges\n\t            )\n\t    def create(self):\n\t        print(self.query)\n\t        try:\n\t            self.reply_raw = get_response(self.query)\n\t        except Exception as e:\n", "            traceback_str = traceback.format_exc()\n\t            error_message = f\"ERROR: {str(e)}\"\n\t            print(traceback_str + error_message)\n\t            sys.exit(1)\n\t        print(self.reply_raw)\n\t    def save_to_raw(self, file_path):\n\t        with open(file_path, 'w') as file:\n\t            file.write(self.reply_raw)\n\t    def save_to_json(self, file_path):\n\t        with open(file_path, 'w') as file:\n", "            json.dump(json.loads(self.reply_raw), file, indent=4, ensure_ascii=False)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 6:\n\t        print(\"Usage: <MainQuestion> <DocumentList> <PreviousKnowledge> <BackgroundKnowledge> <TemplatePath>\")\n\t        sys.exit(1)\n\t    main_question = sys.argv[1]\n\t    document_list_path = sys.argv[2]\n\t    previous_knowledge_path = sys.argv[3]\n\t    background_knowledge_path = sys.argv[4]\n", "    template_path = sys.argv[5]\n\t    think = Reflection(\n\t        main_question, \n\t        previous_knowledge_path,\n\t        \"./test/result/plan_result.json\",\n\t        template_path,\n\t        document_list_path,\n\t        background_knowledge_path)\n\t    think.create()\n\t    think.save_to_raw(\"test/result/reflection.json\")\n"]}
{"filename": "planner.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport pandas as pd\n\timport json\n\tfrom prompt_template import PromptTemplate\n\tfrom question import get_response\n\tfrom plan import Plan\n\timport os\n\timport traceback\n\timport json_utils\n", "from check_recover_json import check_json_str, recover_json_str\n\tclass Planner:\n\t    def __init__(self, main_question, mission_path, strategy_path, query_plan_path, strategy_history_path, background_knowledge_path, acquired_knowledge_path):\n\t        self.main_question = main_question\n\t        self.mission_path = mission_path\n\t        self.strategy_path = strategy_path\n\t        self.query_plan_path = query_plan_path\n\t        with open(background_knowledge_path, 'r') as file:\n\t            self.background_knowledges = file.read()\n\t        with open(acquired_knowledge_path, 'r') as file:\n", "            self.acquired_knowledges = file.read()\n\t        self.strategy_history_path = strategy_history_path\n\t        if os.path.exists(strategy_history_path):\n\t            with open(strategy_history_path, 'r') as file:\n\t                self.strategy_history_json = json.load(file)\n\t        else:\n\t            self.strategy_history_json = {}\n\t        self.plan = Plan()\n\t    def generate_query(self, document_list, history):\n\t        pmission = PromptTemplate(self.mission_path)\n", "        self.mission = pmission.get_prompt()\n\t        pstrategy = PromptTemplate(self.strategy_path)\n\t        self.strategy = pstrategy.get_prompt()\n\t        pquery_plan = PromptTemplate(self.query_plan_path)\n\t        past_strategies = []\n\t        if \"Strategies\" in self.strategy_history_json:\n\t            past_strategies = self.strategy_history_json[\"Strategies\"]\n\t        self.query_plan = pquery_plan.get_prompt(\n\t            MainQuestion = self.main_question,\n\t            Mission = self.mission,\n", "            Strategy = self.strategy,\n\t            DocumentList = document_list,\n\t            History = history,\n\t            PastStrategies = past_strategies,\n\t            BackgroundKnowledges = self.background_knowledges,\n\t            AcquiredKnowledges = self.acquired_knowledges\n\t        )\n\t        print(self.query_plan)\n\t    def create_plan(self):\n\t        try:\n", "            self.reply_raw = get_response(self.query_plan)\n\t        except Exception as e:\n\t            traceback_str = traceback.format_exc()\n\t            error_message = f\"ERROR: {str(e)}\"\n\t            print(traceback_str + error_message)\n\t            sys.exit(1)\n\t        #self.reply_raw = json_utils.parse_plan(self.reply_raw)\n\t        count = 1\n\t        while True:\n\t            result, errorcode = check_json_str(self.reply_raw)\n", "            if result == False and count <= 5:\n\t                print(self.reply_raw)\n\t                print(\"ERROR: RECOVER JSON PROCESS of PLAN RETRY_COUNT=\", count)\n\t                self.reply_raw = recover_json_str(errorcode, self.reply_raw)\n\t                count += 1\n\t            else:\n\t                if result == True:\n\t                    print(self.reply_raw)\n\t                    print(\"INFO: PLAN JSON DATA IS OK\")\n\t                else:\n", "                    print(self.reply_raw)\n\t                    print(\"ERROR: SORRY CAN NOT RECOVER JSON DATA..\")\n\t                break\n\t        try:\n\t            self.reply_json = json.loads(self.reply_raw)\n\t        except json.decoder.JSONDecodeError as e:\n\t            traceback_str = traceback.format_exc()\n\t            error_message = f\"ERROR: {str(e)}\"\n\t            print(traceback_str + error_message)\n\t            sys.exit(1)\n", "        new_strategy = os.getenv(\"NEW_STARTEGY\")\n\t        print(\"NEW_STRATEGY:\" + new_strategy)\n\t        if new_strategy is None or len(new_strategy.strip()) == 0:\n\t            new_strategy = self.reply_json[\"DetailedStrategy\"]\n\t        self.plan.set_strategy(new_strategy)\n\t        if \"Strategies\" not in self.strategy_history_json:\n\t            self.strategy_history_json[\"Strategies\"] = []\n\t        self.strategy_history_json[\"Strategies\"].append(new_strategy)\n\t        for entry in self.reply_json[\"Plan\"]:\n\t            self.plan.add_data(entry[\"DocumentID\"], entry[\"Purpose\"], entry[\"Perspectives\"])\n", "    def save_to_json(self, file_path):\n\t        with open(file_path, 'w') as file:\n\t            json.dump(self.reply_json, file, indent=4, ensure_ascii=False)\n\t    def save_strategy_history(self):\n\t        with open(self.strategy_history_path, 'w') as file:\n\t            json.dump(self.strategy_history_json, file, indent=4, ensure_ascii=False)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    from params import get_param\n\t    prompt_template_path = get_param(\"prompt_templates_path\")\n", "    if len(sys.argv) != 5:\n\t        print(\"Usage: <MainQuestion> <doc_list.txt> <background_knowledge_path> <acquired_knowledge_path>\")\n\t        sys.exit(1)\n\t    main_question = sys.argv[1]\n\t    background_knowledge_path = sys.argv[3]\n\t    acquired_knowledge_path = sys.argv[4]\n\t    batch_size = 100\n\t    with open(sys.argv[2], 'r') as file:\n\t        lines = file.readlines()\n\t        total_list = [line.strip() for line in lines]\n", "        batched_list = [total_list[i:i+batch_size] for i in range(0, len(total_list), batch_size)]\n\t    planner = Planner(\n\t        main_question = main_question,\n\t        mission_path= prompt_template_path + \"/ptemplate_mission.txt\",\n\t        strategy_path= prompt_template_path + \"/ptemplate_strategy.txt\",\n\t        query_plan_path= prompt_template_path + \"/ptemplate_query_plan.txt\",\n\t        strategy_history_path=\"./test/strategy_history.json\",\n\t        background_knowledge_path = background_knowledge_path,\n\t        acquired_knowledge_path = acquired_knowledge_path\n\t    )\n", "    for doc_list in batched_list:\n\t        planner.generate_query(doc_list, \"\")\n\t        planner.create_plan()\n\t        planner.save_to_json(\"test/result/reply.json\")\n\t    planner.plan.save_to_json(\"test/result/plan.json\")\n\t    planner.save_strategy_history()\n"]}
{"filename": "history_selector.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom memory_stream import MemoryStream\n\tclass HistorySelector:\n\t    def __init__(self, memory_stream):\n\t        self.memory_stream = memory_stream\n\t        self.history = []\n\t    def select(self, threshold):\n\t        data = self.memory_stream.get_data()\n\t        high_point_data = data[data[\"Point\"] >= threshold]\n", "        self.history = high_point_data\n\t        return high_point_data\n\t    def get_history(self):\n\t        return self.history\n\tif __name__ == \"__main__\":\n\t    memory_stream = MemoryStream()\n\t    data_num = input(\"DataNum> \")\n\t    count = int(data_num)\n\t    i = 0\n\t    while i < count:\n", "        target_doc_id = input(\"TargetDocID> \")\n\t        question = input(\"question> \")\n\t        reply = input(\"reply> \")\n\t        point = input(\"point> \")\n\t        memory_stream.add_data(target_doc_id, question, reply, int(point))\n\t        print(memory_stream.get_data())\n\t        i += 1\n\t    threshold = input(\"Threshold> \")\n\t    history = HistorySelector(memory_stream)\n\t    print(history.select(int(threshold)))\n", "else:\n\t    pass\n"]}
{"filename": "evaluate_applaud.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport os\n\tfrom prompt_template import PromptTemplate\n\tfrom question import get_response\n\tdef do_applaud(name: str, document_path: str, template_path):\n\t    file_list = os.listdir(document_path)\n\t    log_data = \"\"\n\t    for file in file_list:\n\t        with open(document_path + \"/\" + file) as file:\n", "            data = file.read()\n\t            log_data += data\n\t    prompt = PromptTemplate(template_path)\n\t    p = prompt.get_prompt(\n\t        Name = name,\n\t        log_data = log_data)\n\t    print(p)\n\t    return get_response(p)\n\tif __name__ == \"__main__\":\n\t    import sys\n", "    if len(sys.argv) != 4:\n\t        print(\"Usage: <name> <document_path> <template_path>\")\n\t        sys.exit(1)\n\t    result = do_applaud(sys.argv[1], sys.argv[2], sys.argv[3])\n\t    print(result)\n"]}
{"filename": "query.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport re\n\timport openai\n\tfrom prompt_template import PromptTemplate\n\tfrom memory_stream import MemoryStream\n\tclass Query:\n\t    def __init__(self, target_doc_id: str, main_question: str, memory_stream: MemoryStream, qa):\n\t        self.target_doc_id = target_doc_id\n\t        self.main_question = main_question\n", "        self.memory_stream = memory_stream\n\t        self.qa = qa\n\t    def run(self, prompt_template_path: str, sub_question: str):\n\t        prompt_query_template = PromptTemplate(prompt_template_path)\n\t        # Generate the prompt query using the template and inputs\n\t        query = prompt_query_template.get_prompt(sub_question=sub_question)\n\t        try:\n\t            reply = self.qa({\"question\": query})\n\t        except openai.error.InvalidRequestError as e:\n\t            print(\"ERROR: can not query:\" + query)\n", "            print(\"ERROR:\" + e)\n\t            return -1\n\t        print(reply)\n\t        #calculate point of reply\n\t        if reply.get(\"answer\") == None:\n\t            match = False\n\t        else:\n\t            match = re.search(r\"Point: ?([0-9\\.]+)$\", reply[\"answer\"])\n\t        if match:\n\t            point = float(match.group(1))\n", "            # Store the information in the MemoryStream\n\t            return self._save(sub_question, reply[\"answer\"], point)\n\t        else:\n\t            point = -1.0\n\t            print(\"ERROR: can not find point in reply:\" + reply[\"answer\"])\n\t            return self._save(sub_question, reply[\"answer\"], point)\n\t    def _save(self, sub_question: str, reply: str, point: int):\n\t        # Store the information in the MemoryStream\n\t        return self.memory_stream.add_data(\n\t            target_doc_id = self.target_doc_id, \n", "            question = sub_question, \n\t            reply = reply, \n\t            point = point)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    from db_manager import get_qa\n\t    from params import get_param\n\t    param_prompt_template_path = get_param(\"prompt_templates_path\")\n\t    db_dir = \"..\"\n\t    doc_id = \"DB\"\n", "    qa = get_qa(db_dir, doc_id)\n\t    memory_stream = MemoryStream()\n\t    prompt_template_path = param_prompt_template_path + \"/ptemplate_query.txt\"\n\t    query = Query(\"1\", \"Athrillとは何ですか？\", memory_stream, qa)\n\t    while True:\n\t        question = input(\"question> \")\n\t        if question == 'exit' or question == 'q' or question == \"quit\":\n\t            print(\"See you again!\")\n\t            sys.exit(0)\n\t        query.run(prompt_template_path, question)\n", "        print(\"REPLY: \" + memory_stream.get_reply())\n\t        print(\"POINT: \" + str(memory_stream.get_point()))\n\telse:\n\t    pass"]}
{"filename": "evaluate_results.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom prompt_template import PromptTemplate\n\tfrom question import get_response\n\tdef evaluate_results(query_path: str, result1_path: str, result2_path: str, template_path):\n\t    try:\n\t        with open(query_path, 'r') as file:\n\t            query = file.read()\n\t    except FileNotFoundError:\n\t        raise FileNotFoundError(f\"File '{query_path}' not found.\")\n", "    try:\n\t        with open(result1_path, 'r') as file:\n\t            result1 = file.read()\n\t    except FileNotFoundError:\n\t        raise FileNotFoundError(f\"File '{result1_path}' not found.\")\n\t    try:\n\t        with open(result2_path, 'r') as file:\n\t            result2 = file.read()\n\t    except FileNotFoundError:\n\t        raise FileNotFoundError(f\"File '{result2_path}' not found.\")\n", "    prompt = PromptTemplate(template_path)\n\t    p = prompt.get_prompt(\n\t        MainQuestion = query,\n\t        Result1 = result1,\n\t        Result2 = result2)\n\t    print(p)\n\t    return get_response(p)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 5:\n", "        print(\"Usage: <query_path> <result1_path> <result2_path> <template_path>\")\n\t        sys.exit(1)\n\t    result = evaluate_results(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])\n\t    print(result)\n"]}
{"filename": "question.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom langchain.agents import Tool\n\tfrom langchain.memory import ConversationBufferMemory\n\tfrom langchain.chat_models import ChatOpenAI\n\tfrom langchain.utilities import SerpAPIWrapper\n\tfrom langchain.agents import initialize_agent\n\tfrom langchain.agents import AgentType\n\t#from getpass import getpass\n\timport os\n", "import openai\n\timport traceback\n\tOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n\ttools = []\n\t# OpenAI APIでモデルを指定して応答を取得する\n\tdef get_response(question):\n\t    response = openai.ChatCompletion.create(\n\t        model=\"gpt-4-0613\",\n\t#        model=\"gpt-4\",\n\t#        model=\"gpt-3.5-turbo\",\n", "#        model=\"gpt-3.5-turbo-0613\",\n\t#        model=\"gpt-3.5-turbo-16k\",\n\t        messages=[\n\t            {\"role\": \"user\", \"content\": question }\n\t        ]\n\t    )\n\t    return response[\"choices\"][0][\"message\"][\"content\"]\n\tclass TextQa:\n\t    def __init__(self, doc_dir: str, doc_id: str):\n\t        self.doc_dir = doc_dir\n", "        self.doc_id = doc_id\n\t        self.filepath = os.path.join(self.doc_dir, self.doc_id)\n\t    def get_answer(self, prompt: str):\n\t        res = get_response(prompt)\n\t        return {\n\t            \"answer\": res\n\t        }\n\t    def qa(self, question):\n\t        with open(self.filepath, \"r\") as file:\n\t            text_data = file.read()\n", "            prompt = f\"Input Question: {question}\\nInput Text Data: {text_data}\\n\"\n\t            return self.get_answer(prompt)\n\t    @staticmethod\n\t    def get_qa(doc_dir: str, doc_id: str):\n\t        text_qa = TextQa(doc_dir, doc_id)\n\t        func_ptr = text_qa.qa\n\t        return func_ptr\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if (len(sys.argv) == 1):\n", "        arg = input(\"> \")\n\t    else:\n\t        arg = sys.argv[1]\n\t    if arg == \"q\" or arg == \"quit\":\n\t        print(\"See you again!\")\n\t        sys.exit(0)\n\t    try:\n\t        ret = get_response(arg)\n\t    except Exception as e:\n\t        traceback_str = traceback.format_exc()\n", "        error_message = f\"ERROR: {str(e)}\"\n\t        print(traceback_str + error_message)\n\t        sys.exit(1)\n\t    print(ret)\n"]}
{"filename": "critical_thinking.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom question import get_response\n\tfrom prompt_template import PromptTemplate\n\timport json\n\timport traceback\n\tclass CriticalThinking:\n\t    def __init__(self, main_question: str, prompt_template_path: str, background_knowledge_path: str):\n\t        with open(background_knowledge_path, 'r') as file:\n\t            self.background_knowledge = file.read()\n", "        prompt_template =  PromptTemplate(prompt_template_path)\n\t        self.query = prompt_template.get_prompt(MainQuestion=main_question, BackgroundKnowledges = self.background_knowledge)\n\t    def create(self):\n\t        print(self.query)\n\t        try:\n\t            self.reply_raw = get_response(self.query)\n\t        except Exception as e:\n\t            traceback_str = traceback.format_exc()\n\t            error_message = f\"ERROR: {str(e)}\"\n\t            print(traceback_str + error_message)\n", "            sys.exit(1)\n\t        print(self.reply_raw)\n\t    def save_to_raw(self, file_path):\n\t        with open(file_path, 'w') as file:\n\t            file.write(self.reply_raw)\n\t    def save_to_json(self, file_path):\n\t        with open(file_path, 'w') as file:\n\t            json.dump(json.loads(self.reply_raw), file, indent=4, ensure_ascii=False)\n\tif __name__ == \"__main__\":\n\t    import sys\n", "    from params import get_param\n\t    prompt_template_path = get_param(\"prompt_templates_path\")\n\t    if len(sys.argv) != 3:\n\t        print(\"Usage: <MainQuestion> <BackgroundKnowledge>\")\n\t        sys.exit(1)\n\t    main_question = sys.argv[1]\n\t    background_knowledge_path = sys.argv[2]\n\t    think = CriticalThinking(main_question, prompt_template_path + \"/ptemplate_critical_thinking.txt\", background_knowledge_path)\n\t    think.create()\n\t    think.save_to_raw(\"test/result/critical_thinking.json\")\n"]}
{"filename": "tactical_plannig.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom plan import Plan\n\tfrom prompt_template import PromptTemplate\n\tfrom db_manager import get_qa\n\tfrom question import TextQa\n\timport sys\n\tclass TacticalPlanning:\n\t    def __init__(self, plan: Plan, db_dir: str):\n\t        self.plan = plan\n", "        self.db_dir = db_dir\n\t    def generate_question(self, prompt_templates):\n\t        prioritized_plan = self._prioritize_plan()\n\t        if (len(prioritized_plan) == 0):\n\t            return None\n\t        #print(prioritized_plan)\n\t        row = prioritized_plan.head(1).iloc[0]\n\t        #print(row)\n\t        plan_id = row[\"PlanID\"]\n\t        self.plan.update_status_doing(plan_id)\n", "        document_id = row[\"DocumentID\"]\n\t        purpose = row[\"Purpose\"]\n\t        perspectives = row[\"Perspectives\"]\n\t        return (plan_id, document_id, self._generate_document_question(prompt_templates, document_id, purpose, perspectives))\n\t    def _prioritize_plan(self):\n\t        plan_data = self.plan.get_data()\n\t        prioritized_plan = plan_data.sort_values(by=[\"PlanID\"], ascending=True)\n\t        prioritized_plan = prioritized_plan.loc[prioritized_plan[\"Status\"].isin([\"Doing\", \"None\"])]\n\t        return prioritized_plan\n\t    def _generate_document_question(self, prompt_template_path, document_id, purpose, perspectives):\n", "        prompt_query_template = PromptTemplate(prompt_template_path)\n\t        query = prompt_query_template.get_prompt(document_id=document_id, purpose=purpose, perspectives=perspectives)\n\t        return query\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) != 1 and len(sys.argv) != 2:\n\t        print(\"USAGE: \" + sys.argv[0] + \" [text]\")\n\t        sys.exit(1)\n\t    query_mode = \"db_query\"\n\t    if len(sys.argv) == 2:\n\t        query_mode = \"text_query\"\n", "    from query import Query\n\t    from memory_stream import MemoryStream\n\t    from params import get_param\n\t    param_prompt_template_path = get_param(\"prompt_templates_path\")\n\t    param_documents_path = get_param(\"documents_path\")\n\t    plan = Plan()\n\t    plan.load_from_json(\"./test/result/plan.json\")\n\t    db_dir = param_documents_path + \"/dbs\"\n\t    tactical_planning = TacticalPlanning(plan, db_dir)\n\t    memory_stream = MemoryStream()\n", "    while True:\n\t        ret = tactical_planning.generate_question(param_prompt_template_path + \"/ptemplate_subq_detail.txt\")\n\t        if ret == None:\n\t            print(\"END\")\n\t            break\n\t        plan_id = ret[0]\n\t        doc_id = ret[1]\n\t        question = ret[2]\n\t        if query_mode == \"db_query\":\n\t            qa = get_qa(db_dir, doc_id)\n", "        else:\n\t            qa = TextQa.get_qa(db_dir, doc_id)\n\t        print(\"query_mode=\", query_mode)\n\t        prompt_template_path = param_prompt_template_path + \"/ptemplate_query.txt\"\n\t        query = Query(doc_id, question, memory_stream, qa)\n\t        memory_id = query.run(prompt_template_path, question)\n\t        if memory_id < 0:\n\t            plan.update_status_done(plan_id, memory_id)\n\t            continue\n\t        print(\"REPLY: \" + memory_stream.get_reply())\n", "        print(\"POINT: \" + str(memory_stream.get_point()))\n\t        memory_stream.save_to_json(\"test/result/memory.json\")\n\t        plan.update_status_done(plan_id, memory_id)\n\t        plan.save_to_json(\"./test/result/updated_plan.json\")\n"]}
{"filename": "memory_stream.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport pandas as pd\n\timport json\n\tclass MemoryStream:\n\t    def __init__(self):\n\t        self.columns = [\"ID\", \"TargetDocID\", \"Question\", \"Reply\", \"Point\"]\n\t        self.data = pd.DataFrame(columns=self.columns)\n\t        self.current_id = 1\n\t    def add_data(self, target_doc_id, question, reply, point):\n", "        ret_id = self.current_id\n\t        data = [[self.current_id, target_doc_id, question, reply, point]]\n\t        new_data = pd.DataFrame(data, columns=self.columns)\n\t        self.data = pd.concat([self.data, new_data], ignore_index=True)\n\t        self.current_id += 1\n\t        return ret_id\n\t    def get_data(self):\n\t        return self.data\n\t    def get_reply(self, index = None):\n\t        if (index == None):\n", "            index = len(self.data) - 1\n\t        if index >= 0 and index < len(self.data):\n\t            return self.data.loc[index, \"Reply\"]\n\t        else:\n\t            return None\n\t    def get_data(self, id: int):\n\t        filtered_data = self.data.loc[self.data[\"ID\"] == id]\n\t        if filtered_data.empty:\n\t            return None\n\t        else:\n", "            return filtered_data.to_dict(orient=\"records\")[0]\n\t    def get_point(self, index = None):\n\t        if (index == None):\n\t            index = len(self.data) - 1\n\t        if index >= 0 and index < len(self.data):\n\t            return self.data.loc[index, \"Point\"]\n\t        else:\n\t            return None\n\t    def save_to_json(self, file_path):\n\t        json_data = self.data.to_dict(orient=\"records\")\n", "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n\t            json.dump(json_data, f, indent=4, ensure_ascii=False)\n\t    def load_from_json(self, file_path):\n\t        with open(file_path, 'r') as file:\n\t            json_data = json.load(file)\n\t            self.data = pd.DataFrame(json_data)\n\tif __name__ == \"__main__\":\n\t    memory_stream = MemoryStream()\n\t    while True:\n\t        target_doc_id = input(\"TargetDocID> \")\n", "        question = input(\"question> \")\n\t        reply = input(\"reply> \")\n\t        point = input(\"point> \")\n\t        memory_stream.add_data(target_doc_id, question, reply, int(point))\n\t        print(memory_stream.get_data())\n\telse:\n\t    pass\n"]}
{"filename": "json_utils.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tdef fix_quotes(line):\n\t    fixed_line = \"\"\n\t    quote_mode = False\n\t    for char in line:\n\t        if quote_mode == False:\n\t            if char == '\"':\n\t                quote_mode = True\n\t        else:\n", "            if char == '\"':\n\t                quote_mode = False\n\t            elif char == ':' or char == '\\n':\n\t                fixed_line += '\"'\n\t                quote_mode = False\n\t        fixed_line += char\n\t    return fixed_line\n\tdef fix_backslashes(json_string):\n\t    # 不正なバックスラッシュを修正する\n\t    fixed_string = json_string.replace(\"\\\\\", \"\\\\\\\\\")\n", "    return fixed_string\n\tdef parse_one_entry(line: str, key: str):\n\t    line = line.split(key)[1].strip()\n\t    string_without_quotes = line.replace('\"', '')\n\t    entries = string_without_quotes.split(\":\")\n\t    contents = []\n\t    #skip DetailedStrategy\n\t    #get contents\n\t    for entry in entries:\n\t        if line in entry:\n", "            continue\n\t        else:\n\t            contents.append(entry)\n\t    new_contents = \" \".join(contents)\n\t    #recreate line\n\t    new_line = '\"' + key + '\": ' + '\"' + new_contents + '\",'\n\t    print(new_line)\n\t    return new_line\n\tdef parse_plan(org_data: str):\n\t    lines = org_data.split(\"\\n\")\n", "    output_lines = []\n\t    start_flag = False\n\t    for line in lines:\n\t        if start_flag == False:\n\t            if \"{\" in line:\n\t                start_flag = True\n\t                output_lines.append(fix_quotes(line))\n\t            else:\n\t                pass\n\t        else:\n", "            if \"DetailedStrategy\" in line:\n\t                line = parse_one_entry(line, \"DetailedStrategy\")\n\t            output_lines.append(fix_quotes(fix_backslashes(line)))\n\t    return \"\\n\".join(output_lines)\n\tdef parse_json(org_data: str):\n\t    lines = org_data.split(\"\\n\")\n\t    output_lines = []\n\t    start_flag = False\n\t    nest_count = 0\n\t    for line in lines:\n", "        if start_flag == False:\n\t            if \"{\" in line:\n\t                start_flag = True\n\t                nest_count += 1\n\t                output_lines.append(fix_quotes(line))\n\t            else:\n\t                pass\n\t        else:\n\t            if \"{\" in line:\n\t                nest_count += 1\n", "            elif \"}\" in line:\n\t                nest_count -= 1\n\t            output_lines.append(line)\n\t            if (nest_count == 0):\n\t                break\n\t    return \"\\n\".join(output_lines)"]}
{"filename": "plan.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport pandas as pd\n\timport json\n\tclass Plan:\n\t    def __init__(self):\n\t        self.columns = [\"PlanID\", \"DocumentID\", \"Purpose\", \"Perspectives\", \"ResultID\", \"Status\"]\n\t        self.data = pd.DataFrame(columns=self.columns)\n\t        self.current_id = 1\n\t    def set_strategy(self, detailed_strategy: str):\n", "        self.detailed_strategy = detailed_strategy\n\t    def add_data(self, document_id, purpose, perspectives):\n\t        data = [[self.current_id, document_id, purpose, perspectives, \"\", \"None\"]]\n\t        new_data = pd.DataFrame(data, columns=self.columns)\n\t        self.data = pd.concat([self.data, new_data], ignore_index=True)\n\t        self.current_id += 1\n\t    def update_status_doing(self, plan_id: int):\n\t        self.data.loc[self.data[\"PlanID\"] == plan_id, \"Status\"] = \"Doing\"\n\t    def update_status_done(self, plan_id: int, memory_id: int):\n\t        self.data.loc[self.data[\"PlanID\"] == plan_id, \"Status\"] = \"Done\"\n", "        self.data.loc[self.data[\"PlanID\"] == plan_id, \"ResultID\"] = memory_id\n\t    def save_to_json(self, file_path):\n\t        json_data = dict()\n\t        json_data[\"DetailedStrategy\"] = self.detailed_strategy\n\t        json_data[\"Plan\"] = self.data.to_dict(orient=\"records\")\n\t        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n\t            json.dump(json_data, f, indent=4, ensure_ascii=False)\n\t    def get_json_data(self):\n\t        self.json_data = dict()\n\t        self.json_data[\"DetailedStrategy\"] = self.detailed_strategy\n", "        self.json_data[\"Plan\"] = self.data.to_dict(orient=\"records\")\n\t        return self.json_data\n\t    def load_from_json(self, file_path):\n\t        with open(file_path, 'r') as file:\n\t            self.json_data = json.load(file)\n\t            self.detailed_strategy = self.json_data[\"DetailedStrategy\"]\n\t            self.data = pd.DataFrame(self.json_data['Plan'])\n\t    def get_data(self):\n\t        return self.data\n\t    def get_data_by_id(self, plan_id=None):\n", "        if plan_id is None:\n\t            plan_id = self.current_id - 1\n\t        return self.data.loc[self.data[\"PlanID\"] == plan_id]\n\tif __name__ == \"__main__\":\n\t    plan = Plan()\n\t    i = 0\n\t    count = 2\n\t    while i < count:\n\t        doc_id = input(\"DocumentID> \")\n\t        purpose = input(\"Purpose> \")\n", "        perspectives = input(\"Perspectives> \")\n\t        ids = input(\"ResultID> \")\n\t        status = input(\"Status> \")\n\t        plan.add_data(doc_id, purpose, perspectives, ids, status)\n\t        print(plan.get_data_by_id())\n\t        i += 1\n\t    plan.save_to_json(\"test/result/plan.json\")\n"]}
{"filename": "check_recover_json.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom question import get_response\n\tfrom json_utils import parse_json\n\timport json\n\timport traceback\n\tdef check_json_str(json_data: str):\n\t    try:\n\t        _ = json.loads(json_data)\n\t        return (True, \"OK\")\n", "    except json.JSONDecodeError as e:\n\t        traceback_str = traceback.format_exc()\n\t        error_message = f\"ERROR: {str(e)}\"\n\t        print(traceback_str + error_message)\n\t        return (False, error_message)\n\tdef check_json(filepath: str):\n\t    try:\n\t        with open(filepath, \"r\") as file:\n\t            json_data = json.load(file)\n\t        return (True, \"OK\")\n", "    except json.JSONDecodeError as e:\n\t        traceback_str = traceback.format_exc()\n\t        error_message = f\"ERROR: {str(e)}\"\n\t        print(traceback_str + error_message)\n\t        return (False, error_message)\n\tdef recover_json_str(errcode, data: str):\n\t    res = get_response(f\"{errcode}\\nPlease fix this json data:\\n {data}\")\n\t    json_data = parse_json(res)\n\t    return json_data\n\tdef recover_json(errcode, filepath: str):\n", "    with open(filepath, \"r\") as file:\n\t        data = file.read()\n\t        json_data = recover_json_str(errcode, data)\n\t        result, _ = check_json_str(json_data)\n\t        return (result, json_data)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 2:\n\t        print(\"Usage: <filepath>\")\n\t        sys.exit(1)\n", "    filepath = sys.argv[1]\n\t    count = 1\n\t    while True:\n\t        result, errcode = check_json(filepath)\n\t        if result == False:\n\t            result, json_data = recover_json(errcode, filepath)\n\t            if result == True:\n\t                with open(filepath, \"w\") as file:\n\t                    file.write(json_data)\n\t                print(\"INFO: RECOVERED JSON DATA\")\n", "                break\n\t            elif count <= 5:\n\t                print(\"ERROR: RCOVERING JSON DATA: RETRY_COUNT=\", count)\n\t                count += 1\n\t            else:\n\t                print(json_data)\n\t                print(\"ERROR: can not recover json data...\")\n\t                sys.exit(1)\n\t        else:\n\t            break\n", "    print(\"OK\")\n\t    sys.exit(0)\n"]}
{"filename": "evaluator.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport pandas as pd\n\timport json\n\tfrom memory_stream import MemoryStream\n\tfrom plan import Plan\n\tfrom prompt_template import PromptTemplate\n\tfrom question import get_response\n\tfrom plan import Plan\n\timport copy\n", "import traceback\n\tclass Evaluator:\n\t    def __init__(self, main_question, mission_path, plan: Plan, memory_stream: MemoryStream):\n\t        self.main_question = main_question\n\t        pmission = PromptTemplate(mission_path)\n\t        self.mission = pmission.get_prompt()\n\t        self.plan = plan\n\t        self.memory_stream = memory_stream\n\t    def merge_data(self):\n\t        self.merged_data = dict()\n", "        self.merged_data[\"DetailedStrategy\"] = self.plan.detailed_strategy\n\t        self.merged_data[\"Plan\"] = []\n\t        for entry in self.plan.get_json_data()[\"Plan\"]:\n\t            tmp = copy.deepcopy(entry)\n\t            new_entry = dict()\n\t            new_entry[\"DocumentID\"] = tmp[\"DocumentID\"]\n\t            new_entry[\"Purpose\"] = tmp[\"Purpose\"]\n\t            new_entry[\"Perspectives\"] = tmp[\"Perspectives\"]\n\t            #print(new_entry)\n\t            if isinstance(entry[\"ResultID\"], int) or isinstance(entry[\"ResultID\"], float):\n", "                if entry[\"ResultID\"] >= 0:\n\t                    data = self.memory_stream.get_data(entry[\"ResultID\"])\n\t                    #print(data)\n\t                    new_entry[\"ResultID\"] = { \"Reply\": data[\"Reply\"], \"Point\": data[\"Point\"] }\n\t                else:\n\t                    new_entry[\"ResultID\"] = { \"Reply\": \"No Reply\", \"Point\": 0.0 }\n\t            else:\n\t                    new_entry[\"ResultID\"] = { \"Reply\": \"No Reply\", \"Point\": 0.0 }\n\t            self.merged_data[\"Plan\"].append(new_entry)\n\t        #print(merged_data)\n", "        with open(\"./test/result/plan_result.json\", \"w\", encoding=\"utf-8\") as f:\n\t            json.dump(self.merged_data, f, indent=4, ensure_ascii=False)\n\t    def evaluate(self, template_path, ref_json_path):\n\t        with open(ref_json_path, 'r') as file:\n\t            reflection = file.read()\n\t        with open(\"./test/result/plan_result.json\", 'r') as file:\n\t            PlanExecutedResults = file.read()\n\t        temp = PromptTemplate(template_path)\n\t        prompt = temp.get_prompt(\n\t            MainQuestion = self.main_question,\n", "            Mission = self.mission,\n\t            PastStrategies = [],\n\t            PlanExecutedResults = PlanExecutedResults,\n\t            Reflection = reflection\n\t        )\n\t        try:\n\t            reply = get_response(prompt)\n\t        except Exception as e:\n\t            traceback_str = traceback.format_exc()\n\t            error_message = f\"ERROR: {str(e)}\"\n", "            print(traceback_str + error_message)\n\t            sys.exit(1)\n\t        print(reply)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    from params import get_param\n\t    prompt_template_path = get_param(\"prompt_templates_path\")\n\t    if len(sys.argv) != 4 and len(sys.argv) != 5:\n\t        print(\"Usage: <MainQuestion> <plan> <memory> [<reflection>]\")\n\t        sys.exit(1)\n", "    main_question = sys.argv[1]\n\t    mission_path= prompt_template_path + \"/ptemplate_mission.txt\"\n\t    if len(sys.argv) == 4:\n\t        plan_json_path = sys.argv[2]\n\t        mem_json_path = sys.argv[3]\n\t        plan = Plan()\n\t        plan.load_from_json(plan_json_path)\n\t        memory_stream = MemoryStream()\n\t        memory_stream.load_from_json(mem_json_path)\n\t        evaluator = Evaluator(main_question, mission_path, plan, memory_stream)\n", "        evaluator.merge_data()\n\t    elif len(sys.argv) == 5:\n\t        ref_json_path = sys.argv[4]\n\t        evaluator = Evaluator(main_question, mission_path, None, None)\n\t        evaluator.evaluate(prompt_template_path + \"/ptemplate_evaluate.txt\", ref_json_path)"]}
{"filename": "tools/evaluate_reflection.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport json\n\tfrom deepdiff import DeepDiff\n\timport jsondiff\n\timport pandas as pd\n\tdef get_value(json: dict, term: str, key: str):\n\t    for entry in json[\"Knowledges\"]:\n\t        if term == entry[\"Term\"]:\n\t            return entry[key]\n", "def get_entry(json: dict, term: str):\n\t    for entry in json[\"Knowledges\"]:\n\t        if term == entry[\"Term\"]:\n\t            return entry\n\tdef evaluate(json_path: str):\n\t    with open(json_path, 'r') as file:\n\t        json_data = file.read()\n\t    json_value = json.loads(json_data)\n\t    #print(json_value)\n\t    json_terms = []\n", "    for entry in json_value[\"Knowledges\"]:\n\t        json_terms.append(entry[\"Term\"])\n\t    print(\"TermNum: \", len(json_terms))\n\t    knowns = []\n\t    for term in json_terms:\n\t        known = get_value(json_value, term, \"KnownInfos\")\n\t        knowns.append(len(known))\n\t    df = pd.DataFrame(knowns, columns=[\"KnownInfos\"])\n\t    ave_num = df[\"KnownInfos\"].mean()\n\t    max_num = df[\"KnownInfos\"].max()\n", "    min_num = df[\"KnownInfos\"].min()\n\t    print(\"AveKnwNum:\", ave_num, \" MaxKnwNum:\", max_num, \" MinKnwNum:\", min_num)\n\t    docnums = []\n\t    for term in json_terms:\n\t        knowns = get_value(json_value, term, \"KnownInfos\")\n\t        for known in knowns:\n\t            term_docids = known[\"DocumentIDs\"]\n\t            docnums.append(len(term_docids))\n\t    df = pd.DataFrame(docnums, columns=[\"DocNum\"])\n\t    ave_num = df[\"DocNum\"].mean()\n", "    max_num = df[\"DocNum\"].max()\n\t    min_num = df[\"DocNum\"].min()\n\t    print(\"AveDocNum:\", ave_num, \" MaxDocNum:\", max_num, \" MinDocNum:\", min_num)\n\t    points = []\n\t    for term in json_terms:\n\t        knowns = get_value(json_value, term, \"KnownInfos\")\n\t        for known in knowns:\n\t            points.append(float(known[\"Point\"]))\n\t    df = pd.DataFrame(points, columns=[\"Point\"])\n\t    ave_num = df[\"Point\"].mean()\n", "    max_num = df[\"Point\"].max()\n\t    min_num = df[\"Point\"].min()\n\t    print(\"AvePoint:\", ave_num, \" MaxPoint:\", max_num, \" MinPointm:\", min_num)\n\t    known_lens = []\n\t    for term in json_terms:\n\t        knowns = get_value(json_value, term, \"KnownInfos\")\n\t        for known in knowns:\n\t            known_lens.append(len(known[\"KnownInfo\"]))\n\t    df = pd.DataFrame(known_lens, columns=[\"KnownInfo\"])\n\t    ave_num = df[\"KnownInfo\"].mean()\n", "    max_num = df[\"KnownInfo\"].max()\n\t    min_num = df[\"KnownInfo\"].min()\n\t    print(\"AveknwLen:\", ave_num, \" MaxknwLen:\", max_num, \" MinknwLen:\", min_num)\n\t    relations = []\n\t    for term in json_terms:\n\t        term_relations = get_entry(json_value, term)\n\t        if \"Relations\" in term_relations:\n\t            #print(term_relations[\"Relations\"])\n\t            relations.append(len(term_relations[\"Relations\"]))\n\t    df = pd.DataFrame(relations, columns=[\"RelationNum\"])\n", "    ave_num = df[\"RelationNum\"].mean()\n\t    max_num = df[\"RelationNum\"].max()\n\t    min_num = df[\"RelationNum\"].min()\n\t    print(\"AveRelNum:\", ave_num, \" MaxRelNum:\", max_num, \" MinRelNum:\", min_num)\n\t    unknowns = []\n\t    for term in json_terms:\n\t        terms = get_entry(json_value, term)\n\t        if \"UnknownInfo\" in terms:\n\t            #print(term_relations[\"Relations\"])\n\t            unknowns.append(len(term_relations[\"UnknownInfo\"]))\n", "    df = pd.DataFrame(unknowns, columns=[\"UnknownInfo\"])\n\t    ave_num = df[\"UnknownInfo\"].mean()\n\t    max_num = df[\"UnknownInfo\"].max()\n\t    min_num = df[\"UnknownInfo\"].min()\n\t    print(\"AveUnkwnNum:\", ave_num, \" MaxUnkwnNum:\", max_num, \" MinUnkwnNum:\", min_num)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 2:\n\t        print(\"Usage: <reflection_path>\")\n\t        sys.exit(1)\n", "    json_path = sys.argv[1]\n\t    evaluate(json_path)\n"]}
{"filename": "data_model/reflection_data_cleaner.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\timport json\n\timport traceback\n\tfrom data_model_accessor import DataModelAccessor\n\tfrom reflection_data_model import ReflectionDataModel\n\tfrom reflection_contents_similarity_merge import merge_and_save_known_infos_json\n\tclass ReflectionDataCleaner:\n\t    def __init__(self, accessor: DataModelAccessor):\n", "        self.accessor = accessor\n\t    def clean_empty_data_models(self):\n\t        clean_names = []\n\t        for name in self.accessor.get_filelist():\n\t            filepath = self.accessor.get_data_model_filepath(name)\n\t            model = ReflectionDataModel.load_json_file(filepath)\n\t            data_model = model.get_model()\n\t            if data_model.is_empty_content() == True:\n\t                print(f\"INFO: REMOVING EMPTY MODEL({data_model.get_name()})\")\n\t                clean_names.append(name)\n", "        self.accessor.remove_models(clean_names)\n\t    def merge_same_data_models(self):\n\t        for name in self.accessor.get_filelist():\n\t            print(\"INFO: name=\", name)\n\t            filepath = self.accessor.get_data_model_filepath(name)\n\t            ret = merge_and_save_known_infos_json(filepath)\n\t            if ret == False:\n\t                print(\"INFO: skip merge...error\")\n\t                #sys.exit(1)\n\tif __name__ == \"__main__\":\n", "    if len(sys.argv) != 2:\n\t        print(\"Usage: <dir>\")\n\t        sys.exit(1)\n\t    dir = sys.argv[1]\n\t    accessor = DataModelAccessor(dir)\n\t    cleaner = ReflectionDataCleaner(accessor)\n\t    cleaner.clean_empty_data_models()\n\t    print(\"INFO: MERGING REFLECTIONS\")\n\t    cleaner.merge_same_data_models()\n"]}
{"filename": "data_model/similarity_extractor.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\tfrom data_model_accessor import DataModelAccessor\n\timport json\n\tfrom openai_libs import get_score, get_tokenlen\n\tclass SimilarityExtractor:\n\t    def __init__(self, accessor: DataModelAccessor, maxtoken_num: int):\n\t        self.maxtoken_num = maxtoken_num\n\t        self.accessor = accessor\n\t    def get_filelist(self, query: str):\n", "        scores = self._calc_scores(query, accessor.get_filelist())\n\t        result = []\n\t        token_sum = 0\n\t        for entry in scores:\n\t            if token_sum + entry[\"tokens\"] > self.maxtoken_num:\n\t                break\n\t            result.append(entry[\"file\"])\n\t            token_sum += entry[\"tokens\"]\n\t        return result\n\t    def _calc_scores(self, query: str, filelist: list):\n", "        scores = []\n\t        for entry in filelist:\n\t            #print(\"file:\", entry)\n\t            json_data = self.accessor.get_data_model(entry).get_json_data()\n\t            json_str = json.dumps(json_data)\n\t            score = get_score(query, json_str)\n\t            tokens = get_tokenlen(json_str)\n\t            scores.append({\n\t                \"file\": entry,\n\t                \"tokens\": tokens,\n", "                \"score\": score\n\t            })\n\t        scores.sort(key=lambda x: x[\"score\"], reverse=True)\n\t        return scores\n\t    def extract(self, head_name: str, filelists: list):\n\t        models = self.accessor.get_json_models(filelists)\n\t        data = {\n\t            head_name: models\n\t        }\n\t        return data\n", "if __name__ == \"__main__\":\n\t    import sys\n\t    import json\n\t    if len(sys.argv) != 3:\n\t        print(\"Usage: <query> <dir>\")\n\t        sys.exit(1)\n\t    query = sys.argv[1]\n\t    dir = sys.argv[2]\n\t    accessor = DataModelAccessor(dir)\n\t    extractor = SimilarityExtractor(accessor, 2048)\n", "    filelist = extractor.get_filelist(query)\n\t    data = extractor.extract(\"inputs\", filelist)\n\t    data_str = json.dumps(data, indent=4, ensure_ascii=False)\n\t    print(data_str)\n"]}
{"filename": "data_model/reflection_data_persistentor.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\timport json\n\timport traceback\n\tfrom data_model_accessor import DataModelAccessor\n\tfrom reflection_data_model import ReflectionDataModel\n\tclass ReflectionDataPersistentor:\n\t    def __init__(self, accessor: DataModelAccessor):\n\t        self.accessor = accessor\n", "    def save_reflection_data(self):\n\t        for model in self.models:\n\t            data_model = model.get_model()\n\t            self.accessor.add_data_model(data_model)\n\t    def load_reflection_data(self, reflection_data_path: str):\n\t        try:\n\t            #print(\"filepath=\", reflection_data_path)\n\t            with open(reflection_data_path, \"r\") as file:\n\t                json_data = json.load(file)\n\t        except json.JSONDecodeError as e:\n", "            traceback_str = traceback.format_exc()\n\t            error_message = f\"ERROR: {str(e)}\"\n\t            print(traceback_str + error_message)\n\t            return\n\t        #print(\"json_data:\", json.dumps(json_data))\n\t        if json_data.get(\"Knowledges\") is None:\n\t            return\n\t        self.models = []\n\t        for entry in json_data.get(\"Knowledges\"):\n\t            #print(\"Term:\", entry.get(\"Term\"))\n", "            model = ReflectionDataModel.create_from_entry(\n\t                        entry.get(\"Term\").replace(\" \", \"_\").replace(\"/\", \"_\"), entry)\n\t            self.models.append(model)\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) != 3:\n\t        print(\"Usage: <dir> <filepath>\")\n\t        sys.exit(1)\n\t    dir = sys.argv[1]\n\t    filepath = sys.argv[2]\n\t    accessor = DataModelAccessor(dir)\n", "    persistentor = ReflectionDataPersistentor(accessor)\n\t    persistentor.load_reflection_data(filepath)\n\t    persistentor.save_reflection_data()\n"]}
{"filename": "data_model/data_model_storage.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport os\n\timport json\n\tfrom data_model import DataModel\n\tclass DataModelStorage:\n\t    def __init__(self, directory: str):\n\t        self.directory = directory\n\t        if not os.path.exists(directory):\n\t            os.makedirs(directory)\n", "    def save_data_model(self, new_model: DataModel, merge: bool  = True):\n\t        filename = f\"{new_model.get_name()}.json\"\n\t        filepath = os.path.join(self.directory, filename)\n\t        old_model = DataModel.load_json_file(filepath)\n\t        if merge and old_model is not None:\n\t            new_model.merge(old_model)\n\t        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n\t            json.dump(new_model.get_json_data(), f, indent=4, ensure_ascii=False)\n\t    def load_data_model(self, name: str) -> DataModel:\n\t        filename = f\"{name}.json\"\n", "        filepath = os.path.join(self.directory, filename)\n\t        return DataModel.load_json_file(filepath)\n\t    def remove_data_model(self, name: str):\n\t        filename = f\"{name}.json\"\n\t        filepath = os.path.join(self.directory, filename)\n\t        os.remove(filepath)\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 4:\n\t        print(\"Usage: <dir> <name> <contents>\")\n", "        sys.exit(1)\n\t    dir = sys.argv[1]\n\t    storage = DataModelStorage(dir)\n\t    model = DataModel(sys.argv[2], sys.argv[3])\n\t    storage.save_data_model(model)\n"]}
{"filename": "data_model/document_data_persistentor.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\timport json\n\timport traceback\n\tfrom data_model_accessor import DataModelAccessor\n\tfrom document_data_model import DocumentDataModel\n\tclass DocumentDataPersistentor:\n\t    def __init__(self, accessor: DataModelAccessor):\n\t        self.accessor = accessor\n", "    def save_document_data(self):\n\t        for model in self.models:\n\t            data_model = model.get_model()\n\t            self.accessor.add_data_model(data_model)\n\t    def load_document_data(self, plan_data_path: str):\n\t        try:\n\t            with open(plan_data_path, \"r\") as file:\n\t                json_data = json.load(file)\n\t        except json.JSONDecodeError as e:\n\t            traceback_str = traceback.format_exc()\n", "            error_message = f\"ERROR: {str(e)}\"\n\t            print(traceback_str + error_message)\n\t            return\n\t        if json_data.get(\"Plan\") is None:\n\t            return\n\t        document_ids = []\n\t        for entry in json_data.get(\"Plan\"):\n\t            if entry.get(\"DocumentID\") not in document_ids:\n\t                #print(\"doc:\", entry.get(\"DocumentID\"))\n\t                document_ids.append(entry.get(\"DocumentID\"))\n", "        self.models = []\n\t        for entry in document_ids:\n\t            model = DocumentDataModel.create_from_plans(entry, json_data)\n\t            if model.is_empty() == False:\n\t                self.models.append(model)\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) != 3:\n\t        print(\"Usage: <dir> <filepath>\")\n\t        sys.exit(1)\n\t    dir = sys.argv[1]\n", "    filepath = sys.argv[2]\n\t    accessor = DataModelAccessor(dir)\n\t    persistentor = DocumentDataPersistentor(accessor)\n\t    persistentor.load_document_data(filepath)\n\t    persistentor.save_document_data()\n"]}
{"filename": "data_model/reflection_similarity_extractor.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\timport json\n\tfrom data_model_accessor import DataModelAccessor\n\tfrom reflection_data_model import ReflectionDataModel\n\tfrom openai_libs import get_score, get_tokenlen\n\tclass ReflectionSimilarityExtractor:\n\t    def __init__(self, accessor: DataModelAccessor, maxtoken_num: int):\n\t        self.maxtoken_num = maxtoken_num\n", "        self.accessor = accessor\n\t        self.load()\n\t    def load(self):\n\t        filelist = self.accessor.get_filelist()\n\t        self.models = []\n\t        for entry in filelist:\n\t            filepath = self.accessor.get_data_model_filepath(entry)\n\t            model = ReflectionDataModel.load_json_file(filepath)\n\t            self.models.append(model)\n\t    def _calc_scores(self, query: str):\n", "        self.scores = []\n\t        for model in self.models:\n\t            #print(\"entry_name:\", model.get_term())\n\t            #print(\" known_infos:\", model.get_known_infos_num())\n\t            for entry in model.get_known_infos():\n\t                #print(\"info:\", entry)\n\t                data = model.get_term() + \":\" + json.dumps(entry)\n\t                score = get_score(query, data)\n\t                tokens = get_tokenlen(data)\n\t                self.scores.append({\n", "                    \"term\": model.get_term(),\n\t                    \"info\": entry,\n\t                    \"tokens\": tokens,\n\t                    \"score\": score\n\t                })\n\t        self.scores.sort(key=lambda x: x[\"score\"], reverse=True)\n\t    def extract(self, query: str):\n\t        self._calc_scores(query)\n\t        terms = {}\n\t        token_sum = 0\n", "        for entry in self.scores:\n\t            if token_sum + entry[\"tokens\"] > self.maxtoken_num:\n\t                break\n\t            #print(\"data:\", entry[\"term\"])\n\t            if terms.get(entry[\"term\"]) is None:\n\t                terms[entry[\"term\"]] = []\n\t            terms[entry[\"term\"]].append(entry[\"info\"])\n\t            token_sum += entry[\"tokens\"]\n\t        data = {\n\t            \"Knowledges\": terms\n", "        }\n\t        return data\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) != 4:\n\t        print(\"Usage: <query> <dir> <max_tokens>\")\n\t        sys.exit(1)\n\t    query = sys.argv[1]\n\t    dir = sys.argv[2]\n\t    max_tokens = int(sys.argv[3])\n\t    accessor = DataModelAccessor(dir)\n", "    extractor = ReflectionSimilarityExtractor(accessor, max_tokens)\n\t    data = extractor.extract(query)\n\t    data_str = json.dumps(data, indent=4, ensure_ascii=False)\n\t    print(data_str)\n"]}
{"filename": "data_model/document_data_model.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\timport json\n\tfrom data_model import DataModel\n\tclass DocumentDataModel:\n\t    def __init__(self, title: str):\n\t        self.title = title\n\t        self.results = []\n\t    def get_title(self):\n", "        return self.title\n\t    def is_empty(self):\n\t        if len(self.results) == 0:\n\t            return True\n\t        else:\n\t            return False\n\t    def merge(self, old_model: DataModel):\n\t        old_contents = old_model.get_contents()\n\t        if old_contents is None:\n\t            return\n", "        exist_contents = []\n\t        for old_data in old_contents:\n\t            if all(old_data.get(\"Answer\") != entry.get(\"Answer\") for entry in self.results):\n\t                exist_contents.append(old_data)\n\t        self.results += exist_contents\n\t    def add_info(self, purpose: str, perspectives: str, answer: str, point: float):\n\t        if not isinstance(point, float) or float(point) < 60.0:\n\t            return\n\t        data = {\n\t            \"Purpose\": purpose,\n", "            \"Perspectives\": perspectives,\n\t            \"Answer\": answer,\n\t            \"Point\": point\n\t        }\n\t        self.results.append(data)           \n\t    def get_contents(self):\n\t        if self.is_empty():\n\t            return None\n\t        return self.results\n\t    def get_conents_num(self):\n", "        if self.is_empty():\n\t            return 0\n\t        return len(self.results)\n\t    def is_empty_content(self):\n\t        return self.is_empty()\n\t    def get_model(self) -> DataModel:\n\t        data_model = DataModel(self.get_title(), self.get_contents())\n\t        data_model.set_concrete_model(self)\n\t        return data_model\n\t    @staticmethod\n", "    def create_from_plans(name: str, plans: dict):\n\t        model = DocumentDataModel(name)\n\t        if plans is not None and plans.get(\"Plan\") is not None:\n\t            for plan in plans.get(\"Plan\"):\n\t                if plan.get(\"DocumentID\") == name:\n\t                    #print(plan)\n\t                    model.add_info(plan.get(\"Purpose\"), \n\t                                   plan.get(\"Perspectives\"), \n\t                                   plan.get(\"ResultID\").get(\"Reply\"),\n\t                                   plan.get(\"ResultID\").get(\"Point\"))\n", "        return model\n\t    @staticmethod\n\t    def load_plan_json_file(name: str, filepath: str):\n\t        with open(filepath, \"r\") as file:\n\t            plan_data = json.load(file)\n\t            model = DocumentDataModel.create_from_plans(name, plan_data)\n\t            return model\n\t    @staticmethod\n\t    def create_from_entry(name: str, entry: dict):\n\t        model = DocumentDataModel(name)\n", "        if entry is not None:\n\t            for result in entry:\n\t                model.add_info( result.get(\"Purpose\"), \n\t                                result.get(\"Perspectives\"), \n\t                                result.get(\"Answer\"),\n\t                                result.get(\"Point\"))\n\t        return model\n\t    @staticmethod\n\t    def load_json_file(filepath: str):\n\t        data_model = DataModel.load_json_file(filepath)\n", "        if data_model == None:\n\t            return None\n\t        model = DocumentDataModel.create_from_entry(\n\t                    data_model.get_name(), \n\t                    data_model.get_contents())\n\t        return model\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) != 3:\n\t        print(\"Usage: <name> <filepath>\")\n\t        sys.exit(1)\n", "    name = sys.argv[1]\n\t    filepath = sys.argv[2]\n\t    print(\"name=\", name)\n\t    print(\"filepath=\", filepath)\n\t    model = DocumentDataModel.load_plan_json_file(name, filepath)\n\t    with open(\"./doc.json\", \"w\", encoding=\"utf-8\") as f:\n\t        json.dump(model.get_model().get_json_data(), f, indent=4, ensure_ascii=False)\n"]}
{"filename": "data_model/document_contents_similarity_merge.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\tfrom question import get_response\n\tfrom json_utils import parse_json\n\tfrom check_recover_json import check_json_str, recover_json_str\n\tfrom document_data_model import DocumentDataModel\n\tdef merge_answers_str(data: str):\n\t    res = get_response(f\"For the given json data, compare each Answer, and if it matches the following conditions, merge them, otherwise output as is.:\\n 1. The content of the Answer is the same meaning. Let's think step by step.:\\n {data}\")\n\t    json_data = parse_json(res)\n", "    return json_data\n\tdef merge_answers_json(filepath: str):\n\t    with open(filepath, \"r\") as file:\n\t        data = file.read()\n\t        json_data = merge_answers_str(data)\n\t        return json_data\n\tdef merge_and_save_answers_json(filepath: str):\n\t    model = DocumentDataModel.load_json_file(filepath)\n\t    if model.get_conents_num() < 2:\n\t        print(f\"INFO: SKIP MERGING MODEL: {filepath} info_num={model.get_conents_num()}\")\n", "        return\n\t    print(\"INFO: MERGING MODEL: \", filepath)\n\t    json_data = merge_answers_json(filepath)\n\t    result, errcode = check_json_str(json_data)\n\t    if result == False:\n\t        json_data = recover_json_str(errcode, json_data)\n\t        result, _ = check_json_str(json_data)\n\t        if (result == False):\n\t            print(\"ERROR: can not recover json_data...\")\n\t            return False\n", "    #print(json_data)\n\t    with open(filepath, \"w\") as file:\n\t        file.write(json_data)\n\t    return True\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 2:\n\t        print(\"Usage: <filepath>\")\n\t        sys.exit(1)\n\t    filepath = sys.argv[1]\n", "    ret = merge_and_save_answers_json(filepath)\n\t    if ret == False:\n\t        sys.exit(1)\n\t    sys.exit(0)\n"]}
{"filename": "data_model/document_similarity_extractor.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\timport json\n\tfrom data_model_accessor import DataModelAccessor\n\tfrom document_data_model import DocumentDataModel\n\tfrom openai_libs import get_score, get_tokenlen\n\tclass DocumentSimilarityExtractor:\n\t    def __init__(self, accessor: DataModelAccessor, maxtoken_num: int):\n\t        self.maxtoken_num = maxtoken_num\n", "        self.accessor = accessor\n\t        self.load()\n\t    def load(self):\n\t        filelist = self.accessor.get_filelist()\n\t        self.models = []\n\t        for entry in filelist:\n\t            filepath = self.accessor.get_data_model_filepath(entry)\n\t            model = DocumentDataModel.load_json_file(filepath)\n\t            self.models.append(model)\n\t    def _calc_scores(self, query: str):\n", "        self.scores = []\n\t        for model in self.models:\n\t            contents = model.get_contents()\n\t            if contents is None:\n\t                continue\n\t            for entry in model.get_contents():\n\t                #print(\"info:\", entry)\n\t                data = json.dumps(entry[\"Answer\"])\n\t                score = get_score(query, data)\n\t                tokens = get_tokenlen(data)\n", "                self.scores.append({\n\t                    \"term\": model.get_title(),\n\t                    \"info\": entry[\"Answer\"],\n\t                    \"tokens\": tokens,\n\t                    \"score\": score\n\t                })\n\t        self.scores.sort(key=lambda x: x[\"score\"], reverse=True)\n\t    def extract(self, query: str):\n\t        self._calc_scores(query)\n\t        terms = {}\n", "        token_sum = 0\n\t        for entry in self.scores:\n\t            if token_sum + entry[\"tokens\"] > self.maxtoken_num:\n\t                break\n\t            if terms.get(entry[\"term\"]) is None:\n\t                terms[entry[\"term\"]] = []\n\t            terms[entry[\"term\"]].append(entry[\"info\"])\n\t            token_sum += entry[\"tokens\"]\n\t        data = {\n\t            \"DocumentIDs\": terms\n", "        }\n\t        return data\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) != 4:\n\t        print(\"Usage: <query> <dir> <max_tokens>\")\n\t        sys.exit(1)\n\t    query = sys.argv[1]\n\t    dir = sys.argv[2]\n\t    max_tokens = int(sys.argv[3])\n\t    accessor = DataModelAccessor(dir)\n", "    extractor = DocumentSimilarityExtractor(accessor, max_tokens)\n\t    data = extractor.extract(query)\n\t    data_str = json.dumps(data, indent=4, ensure_ascii=False)\n\t    print(data_str)\n"]}
{"filename": "data_model/openai_libs.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport openai\n\timport tiktoken\n\tfrom tiktoken.core import Encoding\n\tfrom openai.embeddings_utils import cosine_similarity\n\tllm_model = \"gpt-4-0613\"\n\tembedding_model = \"text-embedding-ada-002\"\n\t# Embedding\n\tdef get_embedding(text_input: str):\n", "    global embedding_model\n\t    # ベクトル変換\n\t    response  = openai.Embedding.create(\n\t                    input = text_input.replace(\"\\n\", \" \"),   # 入力文章\n\t                    model = embedding_model,        # GPTモデル\n\t                 )\n\t    # 出力結果取得\n\t    embeddings = response['data'][0]['embedding']\n\t    return embeddings\n\tdef get_score(text1: str, text2: str):\n", "    vec1 = get_embedding(text1)\n\t    vec2 = get_embedding(text2)\n\t    result = cosine_similarity(vec1, vec2)\n\t    return result\n\tdef get_tokenlen(data: str):\n\t    encoding: Encoding = tiktoken.encoding_for_model(llm_model)\n\t    tokens = encoding.encode(data)\n\t    return len(tokens)\n"]}
{"filename": "data_model/data_model.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport os\n\timport json\n\tclass DataModel:\n\t    def __init__(self, name: str, contents):\n\t        self._name = name\n\t        self._contents = contents\n\t        self._concrete_model = None\n\t    def set_concrete_model(self, concrete_model):\n", "        self._concrete_model = concrete_model\n\t    def merge(self, old_model):\n\t        self._concrete_model.merge(old_model)\n\t        self._contents = self._concrete_model.get_contents()\n\t    def get_name(self) -> str:\n\t        return self._name\n\t    def get_contents(self):\n\t        return self._contents\n\t    def set_content(self, content):\n\t        self._contents = content\n", "    def get_json_data(self):\n\t        return {\n\t            \"name\": self._name,\n\t            \"contents\": self._contents\n\t        }\n\t    def is_empty_content(self):\n\t        if self._contents == None:\n\t            return True\n\t        return self._concrete_model.is_empty_content()\n\t    @staticmethod\n", "    def load_json_file(filepath: str):\n\t        if os.path.exists(filepath):\n\t            #print(\"filepath=\", filepath)\n\t            with open(filepath, \"r\") as file:\n\t                data = json.load(file)\n\t                model = DataModel(data.get(\"name\"), None)\n\t                model._contents = data.get(\"contents\")\n\t                return model\n\t        else:\n\t            return None\n"]}
{"filename": "data_model/reflection_contents_similarity_merge.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\tfrom question import get_response\n\tfrom json_utils import parse_json\n\tfrom check_recover_json import check_json_str, recover_json_str\n\tfrom reflection_data_model import ReflectionDataModel\n\tdef merge_known_infos_str(data: str):\n\t    res = get_response(f\"For the given json data, compare each KnownInfo, and if it matches the following conditions, merge them, otherwise output as is.:\\n 1. The DocumentIDs are the same, and\\n2. The content of the KnownInfo is the same meaning. Let's think step by step.:\\n {data}\")\n\t    json_data = parse_json(res)\n", "    return json_data\n\tdef merge_known_infos_json(filepath: str):\n\t    with open(filepath, \"r\") as file:\n\t        data = file.read()\n\t        json_data = merge_known_infos_str(data)\n\t        return json_data\n\tdef merge_and_save_known_infos_json(filepath: str):\n\t    model = ReflectionDataModel.load_json_file(filepath)\n\t    if model.get_known_infos_num() < 2:\n\t        print(f\"INFO: SKIP MERGING MODEL: {filepath} info_num={model.get_known_infos_num()}\")\n", "        return\n\t    print(\"INFO: MERGING MODEL: \", filepath)\n\t    json_data = merge_known_infos_json(filepath)\n\t    result, errcode = check_json_str(json_data)\n\t    if result == False:\n\t        json_data = recover_json_str(errcode, json_data)\n\t        result, _ = check_json_str(json_data)\n\t        if (result == False):\n\t            print(\"ERROR: can not recover json_data...\")\n\t            return False\n", "    #print(json_data)\n\t    with open(filepath, \"w\") as file:\n\t        file.write(json_data)\n\t    return True\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 2:\n\t        print(\"Usage: <filepath>\")\n\t        sys.exit(1)\n\t    filepath = sys.argv[1]\n", "    ret = merge_and_save_known_infos_json(filepath)\n\t    if ret == False:\n\t        sys.exit(1)\n\t    sys.exit(0)\n"]}
{"filename": "data_model/document_data_cleaner.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport sys\n\timport json\n\timport traceback\n\tfrom data_model_accessor import DataModelAccessor\n\tfrom document_data_model import DocumentDataModel\n\tfrom document_contents_similarity_merge import merge_and_save_answers_json\n\tclass DocumentDataCleaner:\n\t    def __init__(self, accessor: DataModelAccessor):\n", "        self.accessor = accessor\n\t    def clean_empty_data_models(self):\n\t        clean_names = []\n\t        for name in self.accessor.get_filelist():\n\t            filepath = self.accessor.get_data_model_filepath(name)\n\t            model = DocumentDataModel.load_json_file(filepath)\n\t            data_model = model.get_model()\n\t            if data_model.is_empty_content() == True:\n\t                print(f\"INFO: REMOVING EMPTY MODEL({data_model.get_name()})\")\n\t                clean_names.append(name)\n", "        self.accessor.remove_models(clean_names)\n\t    def merge_same_data_models(self):\n\t        for name in self.accessor.get_filelist():\n\t            print(\"INFO: name=\", name)\n\t            filepath = self.accessor.get_data_model_filepath(name)\n\t            ret = merge_and_save_answers_json(filepath)\n\t            if ret == False:\n\t                print(\"INFO: skip merge...error\")\n\t                #sys.exit(1)\n\tif __name__ == \"__main__\":\n", "    if len(sys.argv) != 2:\n\t        print(\"Usage: <dir>\")\n\t        sys.exit(1)\n\t    dir = sys.argv[1]\n\t    accessor = DataModelAccessor(dir)\n\t    cleaner = DocumentDataCleaner(accessor)\n\t    cleaner.clean_empty_data_models()\n\t    print(\"INFO: MERGING REFLECTIONS\")\n\t    cleaner.merge_same_data_models()\n"]}
{"filename": "data_model/reflection_data_model.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport os\n\timport json\n\tfrom data_model import DataModel\n\tclass ReflectionDataModel:\n\t    def __init__(self, term: str):\n\t        self.term = term\n\t        self.known_infos = []\n\t        self.relations = []\n", "        self.unknown_infos = []\n\t    def is_empty(self):\n\t        if len(self.known_infos) == 0 and len(self.unknown_infos) == 0:\n\t            return True\n\t        else:\n\t            return False\n\t    def merge(self, old_model: DataModel):\n\t        # merge KnownInfos\n\t        old_contents = old_model.get_contents()\n\t        if old_contents is None:\n", "            return\n\t        if old_contents.get(\"KnownInfos\") is not None:\n\t            old_known_infos = []\n\t            for old_data in old_contents.get(\"KnownInfos\"):\n\t                if all(old_data.get(\"KnownInfo\") != entry.get(\"KnownInfo\") for entry in self.known_infos):\n\t                    old_known_info = {\n\t                        \"KnownInfo\": old_data.get(\"KnownInfo\"),\n\t                        \"DocumentIDs\": old_data.get(\"DocumentIDs\"),\n\t                        \"Point\": old_data.get(\"Point\")\n\t                    }\n", "                    old_known_infos.append(old_known_info)\n\t            self.known_infos += old_known_infos\n\t        # merge Relations\n\t        if old_contents.get(\"Relations\") is not None:\n\t            old_relations = []\n\t            for old_data in old_contents.get(\"Relations\"):\n\t                if all(old_data.get(\"Term\") != entry.get(\"Term\") for entry in self.relations):\n\t                    old_relations.append(old_data)\n\t            self.relations += old_relations\n\t    def add_info(self, known_info: str, document_ids: list, point: float):\n", "        #print(\"known_info:\", known_info)\n\t        if len(known_info) == 0:\n\t            #print(\"skip1\")\n\t            return\n\t        if document_ids is None or len(document_ids) == 0:\n\t            #unreliable info\n\t            #print(\"skip2\")\n\t            return\n\t        if point is not None and float(point) < 60.0:\n\t            #print(\"skip3:\", type(point))\n", "            #unreliable info\n\t            return\n\t        data = {\n\t            \"KnownInfo\": known_info,\n\t            \"DocumentIDs\": document_ids,\n\t            \"Point\": point\n\t        }\n\t        if all(data.get(\"KnownInfo\") != entry.get(\"KnownInfo\") for entry in self.known_infos):\n\t            self.known_infos.append(data)\n\t    def update_unknown_info(self, unknwon_infos: list):\n", "        self.unknown_infos = unknwon_infos\n\t    def get_known_infos_num(self):\n\t        return len(self.known_infos)\n\t    def add_relations(self, relations):\n\t        self.relations += relations\n\t    def get_term(self) -> str:\n\t        return self.term\n\t    def get_contents(self):\n\t        if self.is_empty():\n\t            return None\n", "        data = {\n\t            \"Term\": self.term,\n\t            \"KnownInfos\": self.known_infos,\n\t            \"UnknownInfo\": self.unknown_infos,\n\t            \"Relations\": self.relations\n\t        }\n\t        return data\n\t    def get_known_infos(self):\n\t        if self.known_infos == None:\n\t            return []\n", "        return self.known_infos\n\t    def is_empty_content(self):\n\t        if len(self.known_infos) == 0:\n\t            return True\n\t        else:\n\t            return False\n\t    def get_model(self) -> DataModel:\n\t        data_model = DataModel(self.get_term(), self.get_contents())\n\t        data_model.set_concrete_model(self)\n\t        return data_model\n", "    @staticmethod\n\t    def create_from_entry(name: str, entry: dict):\n\t        model = ReflectionDataModel(name)\n\t        if entry is not None and entry.get(\"KnownInfos\") is not None:\n\t            for known_info in entry.get(\"KnownInfos\"):\n\t                #print(\"KnownInfo:\", str(known_info.get(\"KnownInfo\")))\n\t                #print(\"DocumentIDs:\", str(known_info.get(\"DocumentIDs\")))\n\t                #print(\"Point:\", str(known_info.get(\"Point\")))\n\t                model.add_info(known_info.get(\"KnownInfo\"), known_info.get(\"DocumentIDs\"), known_info.get(\"Point\"))\n\t            if entry.get(\"Relations\") is not None:\n", "                model.add_relations(entry.get(\"Relations\"))\n\t            if entry.get(\"UnknownInfo\") is not None:\n\t                model.update_unknown_info(entry.get(\"UnknownInfo\"))\n\t            if entry.get(\"Point\") is not None:\n\t                model.point = entry.get(\"Point\")\n\t        return model\n\t    @staticmethod\n\t    def load_json_file(filepath: str):\n\t        #print(\"filepath:\", filepath)\n\t        data_model = DataModel.load_json_file(filepath)\n", "        if data_model == None:\n\t            #print(\"data_model == None\")\n\t            return None\n\t        #print(\"name:\", data_model.get_name())\n\t        #print(\"get_contents:\", data_model.get_contents())\n\t        model = ReflectionDataModel.create_from_entry(\n\t                    data_model.get_name(), \n\t                    data_model.get_contents())\n\t        return model\n"]}
{"filename": "data_model/data_model_accessor.py", "chunked_list": ["#!/usr/bin/python\n\t# -*- coding: utf-8 -*-\n\timport os\n\tfrom data_model import DataModel\n\tfrom data_model_storage import DataModelStorage\n\tclass DataModelAccessor:\n\t    def __init__(self, dir: str):\n\t        self.directory = dir\n\t        if not os.path.exists(self.directory):\n\t            os.makedirs(self.directory)\n", "        self.datamodel_path = os.path.join(self.directory, \"data_model\")\n\t        self.data_model_storage = DataModelStorage(self.datamodel_path)\n\t        self._load_file_cache()\n\t    def get_data_model_filepath(self, name: str):\n\t        return os.path.join(self.datamodel_path, name + \".json\")\n\t    def get_filelist(self):\n\t        return self.file_cache\n\t    def _load_file_cache(self):\n\t        self.file_cache = []\n\t        for file_name in os.listdir(self.datamodel_path):\n", "            if file_name.endswith(\".json\"):\n\t                name = file_name[:-5]  # .json 拡張子を除去\n\t                self.file_cache.append(name)\n\t    def remove_models(self, model_names: list):\n\t        for model_name in model_names:\n\t            self.data_model_storage.remove_data_model(model_name)\n\t        self._load_file_cache()\n\t    def add_data_model(self, name: str, contents: str):\n\t        data_model = DataModel(name, contents)\n\t        self.data_model_storage.save_data_model(data_model)\n", "        if name not in self.file_cache:\n\t            self.file_cache.append(name)\n\t    def add_data_model(self, model: DataModel):\n\t        self.data_model_storage.save_data_model(model)\n\t        if model.get_name() not in self.file_cache:\n\t            self.file_cache.append(model.get_name())\n\t    def get_data_model(self, name: str) -> DataModel:\n\t        if name in self.file_cache:\n\t            return self.data_model_storage.load_data_model(name)\n\t        else:\n", "            return None\n\t    def get_json_models(self, filelist: list):\n\t        models = []\n\t        for entry in filelist:\n\t            models.append(self.get_data_model(entry).get_json_data())\n\t        return models\n\t    def get_data_models(self, filelist: list):\n\t        models = []\n\t        for entry in filelist:\n\t            models.append(self.get_data_model(entry))\n", "        return models\n\tif __name__ == \"__main__\":\n\t    import sys\n\t    if len(sys.argv) != 2:\n\t        print(\"Usage: <dir>\")\n\t        sys.exit(1)\n\t    dir = sys.argv[1]\n\t    accessor = DataModelAccessor(dir)\n\t    #accessor.add_data_model(\"term1\", \"info1\")\n\t    #accessor.add_data_model(\"term1\", \"info2\")\n", "    #accessor.add_data_model(\"term2\", \"info1\")\n\t    model = accessor.get_data_model(\"term3\")\n\t    if model is not None:\n\t        print(model.get_json_data())\n\t    else:\n\t        print(\"Not Found\")\n"]}
