{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\tcore_requires = [\n\t    \"torch~=1.11\",\n\t    \"tensorboardX\",\n\t    \"torchdiffeq @ git+https://github.com/rtqichen/torchdiffeq\",\n\t    \"tqdm\",\n\t    \"pyyaml\",\n\t]\n\texp_requires = [\n\t    \"matplotlib\",\n", "    \"seaborn\",\n\t    \"torchvision~=0.14\",\n\t    \"scikit-learn\",\n\t    \"pygame\",\n\t    \"pymunk~=5.6.0\",\n\t    \"POT~=0.9.0\"\n\t]\n\tsetup(\n\t    name=\"ncdssm\",\n\t    description=\"Neural Continuous Discrete State Space Models\",\n", "    long_description='Neural Continuous Discrete State Space Models presented in the IMCL 2023 paper titled \"Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series\"',  # noqa\n\t    version=\"0.0.1\",\n\t    install_requires=core_requires,\n\t    extras_require={\n\t        \"exp\": exp_requires,\n\t    },\n\t    packages=find_packages(where=\"src\"),\n\t    package_dir={\"\": \"src\"},\n\t    python_requires=\">=3.8\",\n\t)\n"]}
{"filename": "train_pymunk.py", "chunked_list": ["import os\n\timport copy\n\timport yaml\n\timport torch\n\timport argparse\n\timport matplotlib\n\timport numpy as np\n\tfrom tensorboardX import SummaryWriter\n\tfrom ncdssm.torch_utils import grad_norm, torch2numpy\n\tfrom ncdssm.plotting import show_pymunk_forecast, show_wasserstein_distance\n", "from ncdssm.evaluation import evaluate_pymunk_dataset\n\timport experiments.utils\n\tfrom experiments.setups import get_model, get_dataset\n\tdef train_step(train_batch, model, optimizer, reg_scheduler, step, device, config):\n\t    batch_target = train_batch[\"past_target\"]\n\t    batch_times = train_batch[\"past_times\"]\n\t    batch_mask = train_batch[\"past_mask\"]\n\t    batch_target = batch_target.to(device)\n\t    batch_times = batch_times.to(device)\n\t    batch_mask = batch_mask.to(device)\n", "    optimizer.zero_grad()\n\t    out = model(\n\t        batch_target,\n\t        batch_mask,\n\t        batch_times,\n\t        num_samples=config.get(\"num_samples\", 1),\n\t    )\n\t    cond_ll = out[\"likelihood\"]\n\t    reg = out[\"regularizer\"]\n\t    loss = -(cond_ll + reg_scheduler.val * reg).mean(0)\n", "    loss.backward()\n\t    if step <= config.get(\"ssm_params_warmup_steps\", 0):\n\t        ctkf_lr = optimizer.param_groups[0][\"lr\"]\n\t        optimizer.param_groups[0][\"lr\"] = 0\n\t    total_grad_norm = grad_norm(model.parameters())\n\t    if float(config[\"max_grad_norm\"]) != float(\"inf\"):\n\t        torch.nn.utils.clip_grad_norm_(\n\t            model.parameters(), max_norm=config[\"max_grad_norm\"]\n\t        )\n\t    optimizer.step()\n", "    if step <= config.get(\"ssm_params_warmup_steps\", 0):\n\t        optimizer.param_groups[0][\"lr\"] = ctkf_lr\n\t    print(\n\t        f\"Step {step}: Loss={loss.item():.4f}, Grad Norm: {total_grad_norm.item():.2f},\"\n\t        f\" Reg-Coeff: {reg_scheduler.val:.2f}\"\n\t    )\n\t    return dict(\n\t        loss=loss.item(), cond_ll=cond_ll.mean(0).item(), reg=reg.mean(0).item()\n\t    )\n\tdef main():\n", "    matplotlib.use(\"Agg\")\n\t    # SET SEED\n\t    # seed = 111\n\t    # print(seed)\n\t    # np.random.seed(seed)\n\t    # torch.manual_seed(seed)\n\t    # random.seed(seed)\n\t    # COMMAND-LINE ARGS\n\t    parser = argparse.ArgumentParser()\n\t    group = parser.add_mutually_exclusive_group(required=True)\n", "    group.add_argument(\"--config\", type=str, help=\"Path to config file.\")\n\t    group.add_argument(\"--ckpt\", type=str, help=\"Path to checkpoint file.\")\n\t    args, _ = parser.parse_known_args()\n\t    # CONFIG\n\t    if args.ckpt:\n\t        ckpt = torch.load(args.ckpt, map_location=\"cpu\")\n\t        config = ckpt[\"config\"]\n\t    else:\n\t        config = experiments.utils.get_config_and_setup_dirs(args.config)\n\t        parser = experiments.utils.add_config_to_argparser(config=config, parser=parser)\n", "        args = parser.parse_args()\n\t        # Update config from command line args, if any.\n\t        updated_config_dict = vars(args)\n\t        for k in config.keys() & updated_config_dict.keys():\n\t            o_v = config[k]\n\t            u_v = updated_config_dict[k]\n\t            if u_v != o_v:\n\t                print(f\"{k}: {o_v} -> {u_v}\")\n\t        config.update(updated_config_dict)\n\t    # DATA\n", "    train_dataset, val_dataset, _ = get_dataset(config)\n\t    train_loader = torch.utils.data.DataLoader(\n\t        train_dataset,\n\t        batch_size=config[\"train_batch_size\"],\n\t        num_workers=4,\n\t        shuffle=True,\n\t        collate_fn=train_dataset.collate_fn,\n\t    )\n\t    val_loader = torch.utils.data.DataLoader(\n\t        val_dataset,\n", "        batch_size=config[\"test_batch_size\"],\n\t        collate_fn=train_dataset.collate_fn,\n\t    )\n\t    train_gen = iter(train_loader)\n\t    # test_gen = iter(test_loader)\n\t    # MODEL\n\t    device = torch.device(config[\"device\"])\n\t    model = get_model(config=config)\n\t    kf_param_names = {\n\t        name for name, _ in model.named_parameters() if \"base_ssm\" in name\n", "    }\n\t    kf_params = [\n\t        param for name, param in model.named_parameters() if name in kf_param_names\n\t    ]\n\t    non_kf_params = [\n\t        param for name, param in model.named_parameters() if name not in kf_param_names\n\t    ]\n\t    print(kf_param_names)\n\t    optim = torch.optim.Adam(\n\t        params=[\n", "            {\"params\": kf_params},\n\t            {\"params\": non_kf_params},\n\t        ],\n\t        lr=config[\"learning_rate\"],\n\t    )\n\t    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n\t        optim, gamma=config[\"lr_decay_rate\"]\n\t    )\n\t    reg_scheduler = experiments.utils.LinearScheduler(\n\t        iters=config.get(\"reg_anneal_iters\", 0),\n", "        maxval=config.get(\"reg_coeff_maxval\", 1.0),\n\t    )\n\t    start_step = 1\n\t    if args.ckpt:\n\t        model.load_state_dict(ckpt[\"model\"])\n\t        optim.load_state_dict(ckpt[\"optimizer\"])\n\t        # Hack to move optim states from CPU to GPU.\n\t        for state in optim.state.values():\n\t            for k, v in state.items():\n\t                if torch.is_tensor(v):\n", "                    state[k] = v.to(device)\n\t        lr_scheduler.load_state_dict(ckpt[\"scheduler\"])\n\t        start_step = ckpt[\"step\"] + 1\n\t    model = model.to(device)\n\t    num_params = 0\n\t    for name, param in model.named_parameters():\n\t        num_params += np.prod(param.size())\n\t        print(name, param.size())\n\t    print(f\"Total Paramaters: {num_params.item()}\")\n\t    # TRAIN & EVALUATE\n", "    num_steps = config[\"num_steps\"]\n\t    log_steps = config[\"log_steps\"]\n\t    save_steps = config[\"save_steps\"]\n\t    log_dir = config[\"log_dir\"]\n\t    writer = SummaryWriter(logdir=log_dir)\n\t    with open(os.path.join(log_dir, \"config.yaml\"), \"w\") as fp:\n\t        yaml.dump(config, fp, default_flow_style=False, sort_keys=False)\n\t    for step in range(start_step, num_steps + 1):\n\t        try:\n\t            train_batch = next(train_gen)\n", "        except StopIteration:\n\t            train_gen = iter(train_loader)\n\t            train_batch = next(train_gen)\n\t        train_result = train_step(\n\t            train_batch, model, optim, reg_scheduler, step, device, config\n\t        )\n\t        summary_items = copy.deepcopy(train_result)\n\t        if step % config[\"lr_decay_steps\"] == 0:\n\t            lr_scheduler.step()\n\t        if step % config.get(\"reg_anneal_every\", 1) == 0:\n", "            reg_scheduler.step()\n\t        if step % save_steps == 0 or step == num_steps:\n\t            model_path = os.path.join(config[\"ckpt_dir\"], f\"model_{step}.pt\")\n\t            torch.save(\n\t                {\n\t                    \"step\": step,\n\t                    \"model\": model.state_dict(),\n\t                    \"optimizer\": optim.state_dict(),\n\t                    \"scheduler\": lr_scheduler.state_dict(),\n\t                    \"config\": config,\n", "                },\n\t                model_path,\n\t            )\n\t        if step % log_steps == 0 or step == num_steps:\n\t            folder = os.path.join(log_dir, \"plots\", f\"step{step}\")\n\t            os.makedirs(folder, exist_ok=True)\n\t            (\n\t                wt_mean,\n\t                wt_conf_interval,\n\t                future_w_mean,\n", "                future_w_conf_interval,\n\t            ) = evaluate_pymunk_dataset(\n\t                val_loader,\n\t                model,\n\t                device=device,\n\t                num_samples=config[\"num_forecast\"],\n\t                max_size=100,\n\t            ).values()\n\t            writer.add_scalar(\"future_w_mean\", future_w_mean.item(), global_step=step)\n\t            writer.add_scalar(\n", "                \"future_w_conf_interval\",\n\t                future_w_conf_interval.item(),\n\t                global_step=step,\n\t            )\n\t            fig = show_wasserstein_distance(\n\t                (15, 2),\n\t                wt_mean,\n\t                conf_intervals=wt_conf_interval,\n\t                fig_title=\"Wasserstein Distance\",\n\t            )\n", "            writer.add_figure(\"w_dist\", fig, global_step=step)\n\t            plot_count = 0\n\t            for test_batch in val_loader:\n\t                past_target = test_batch[\"past_target\"].to(device)\n\t                B, T, _ = past_target.shape\n\t                mask = test_batch[\"past_mask\"].to(device)\n\t                future_target = test_batch[\"future_target\"].to(device)\n\t                past_times = test_batch[\"past_times\"].to(device)\n\t                future_times = test_batch[\"future_times\"].to(device)\n\t                predict_result = model.forecast(\n", "                    past_target,\n\t                    mask,\n\t                    past_times.view(-1),\n\t                    future_times.view(-1),\n\t                    num_samples=config[\"num_forecast\"],\n\t                )\n\t                reconstruction = predict_result[\"reconstruction\"]\n\t                forecast = predict_result[\"forecast\"]\n\t                full_prediction = torch.cat([reconstruction, forecast], dim=-2)\n\t                full_target = torch.cat([past_target, future_target], dim=-2)\n", "                for j in range(B):\n\t                    full_prediction_j = full_prediction[:, j].view(\n\t                        full_prediction.shape[0],\n\t                        full_prediction.shape[-2],\n\t                        1,\n\t                        config[\"img_size\"],\n\t                        config[\"img_size\"],\n\t                    )\n\t                    full_target_j = full_target[j].view(\n\t                        full_target.shape[1], 1, config[\"img_size\"], config[\"img_size\"]\n", "                    )\n\t                    full_target_j[:T][mask[j] == 0.0] = 0.0\n\t                    # Plot first five samples\n\t                    show_pymunk_forecast(\n\t                        torch2numpy(full_target_j),\n\t                        torch2numpy(full_prediction_j[:5]),\n\t                        os.path.join(folder, f\"series_{plot_count}.png\"),\n\t                    )\n\t                    plot_count += 1\n\t                    if plot_count == config[\"num_plots\"]:\n", "                        break\n\t                if plot_count == config[\"num_plots\"]:\n\t                    break\n\t        for k, v in summary_items.items():\n\t            writer.add_scalar(k, v, global_step=step)\n\t        writer.flush()\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "train_ts.py", "chunked_list": ["import os\n\timport copy\n\timport yaml\n\timport torch\n\timport argparse\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport numpy as np\n\tfrom tensorboardX import SummaryWriter\n\tfrom ncdssm.torch_utils import grad_norm, prepend_time_zero, torch2numpy\n", "from ncdssm.plotting import show_time_series_forecast\n\tfrom ncdssm.evaluation import evaluate_simple_ts, evaluate_sporadic\n\timport experiments.utils\n\tfrom experiments.setups import get_model, get_dataset\n\tdef train_step(train_batch, model, optimizer, reg_scheduler, step, device, config):\n\t    batch_target = train_batch[\"past_target\"].to(device)\n\t    batch_times = train_batch[\"past_times\"].to(device)\n\t    batch_mask = train_batch[\"past_mask\"].to(device)\n\t    optimizer.zero_grad()\n\t    out = model(\n", "        batch_target,\n\t        batch_mask,\n\t        batch_times,\n\t        num_samples=config.get(\"num_samples\", 1),\n\t    )\n\t    cond_ll = out[\"likelihood\"]\n\t    reg = out[\"regularizer\"]\n\t    loss = -(cond_ll + reg_scheduler.val * reg).mean(0)\n\t    loss.backward()\n\t    if step <= config.get(\"ssm_params_warmup_steps\", 0):\n", "        ctkf_lr = optimizer.param_groups[0][\"lr\"]\n\t        optimizer.param_groups[0][\"lr\"] = 0\n\t    total_grad_norm = grad_norm(model.parameters())\n\t    if total_grad_norm < float(\"inf\"):\n\t        if config[\"max_grad_norm\"] != float(\"inf\"):\n\t            torch.nn.utils.clip_grad_norm_(\n\t                model.parameters(), max_norm=config[\"max_grad_norm\"]\n\t            )\n\t        optimizer.step()\n\t    else:\n", "        print(\"Skipped gradient update!\")\n\t        optimizer.zero_grad()\n\t    if step <= config.get(\"ssm_params_warmup_steps\", 0):\n\t        optimizer.param_groups[0][\"lr\"] = ctkf_lr\n\t    print(\n\t        f\"Step {step}: Loss={loss.item():.4f},\"\n\t        f\" Grad Norm: {total_grad_norm.item():.2f},\"\n\t        f\" Reg-Coeff: {reg_scheduler.val:.2f}\"\n\t    )\n\t    return dict(\n", "        loss=loss.item(), cond_ll=cond_ll.mean(0).item(), reg=reg.mean(0).item()\n\t    )\n\tdef main():\n\t    matplotlib.use(\"Agg\")\n\t    # COMMAND-LINE ARGS\n\t    parser = argparse.ArgumentParser()\n\t    group = parser.add_mutually_exclusive_group(required=True)\n\t    group.add_argument(\"--config\", type=str, help=\"Path to config file.\")\n\t    group.add_argument(\"--ckpt\", type=str, help=\"Path to checkpoint file.\")\n\t    parser.add_argument(\n", "        \"--sporadic\",\n\t        action=\"store_true\",\n\t        help=\"Whether sporadic dataset (e.g., climate) is used.\",\n\t    )\n\t    args, _ = parser.parse_known_args()\n\t    # CONFIG\n\t    if args.ckpt:\n\t        ckpt = torch.load(args.ckpt, map_location=\"cpu\")\n\t        config = ckpt[\"config\"]\n\t    else:\n", "        config = experiments.utils.get_config_and_setup_dirs(args.config)\n\t        parser = experiments.utils.add_config_to_argparser(config=config, parser=parser)\n\t        args = parser.parse_args()\n\t        # Update config from command line args, if any.\n\t        updated_config_dict = vars(args)\n\t        for k in config.keys() & updated_config_dict.keys():\n\t            o_v = config[k]\n\t            u_v = updated_config_dict[k]\n\t            if u_v != o_v:\n\t                print(f\"{k}: {o_v} -> {u_v}\")\n", "        config.update(updated_config_dict)\n\t    if args.sporadic:\n\t        evaluate_fn = evaluate_sporadic\n\t    else:\n\t        evaluate_fn = evaluate_simple_ts\n\t    # DATA\n\t    train_dataset, val_dataset, _ = get_dataset(config)\n\t    train_loader = torch.utils.data.DataLoader(\n\t        train_dataset,\n\t        batch_size=config[\"train_batch_size\"],\n", "        num_workers=4,  # NOTE: 0 may be faster for climate dataset\n\t        shuffle=True,\n\t        collate_fn=train_dataset.collate_fn,\n\t    )\n\t    val_loader = torch.utils.data.DataLoader(\n\t        val_dataset,\n\t        batch_size=config[\"test_batch_size\"],\n\t        collate_fn=train_dataset.collate_fn,\n\t    )\n\t    train_gen = iter(train_loader)\n", "    # test_gen = iter(test_loader)\n\t    # MODEL\n\t    device = torch.device(config[\"device\"])\n\t    model = get_model(config=config)\n\t    kf_param_names = {\n\t        name for name, _ in model.named_parameters() if \"base_ssm\" in name\n\t    }\n\t    kf_params = [\n\t        param for name, param in model.named_parameters() if name in kf_param_names\n\t    ]\n", "    non_kf_params = [\n\t        param for name, param in model.named_parameters() if name not in kf_param_names\n\t    ]\n\t    print(kf_param_names)\n\t    optim = torch.optim.Adam(\n\t        params=[\n\t            {\"params\": kf_params},\n\t            {\"params\": non_kf_params},\n\t        ],\n\t        lr=config[\"learning_rate\"],\n", "        weight_decay=config.get(\"weight_decay\", 0.0),\n\t    )\n\t    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n\t        optim, gamma=config[\"lr_decay_rate\"]\n\t    )\n\t    reg_scheduler = experiments.utils.LinearScheduler(\n\t        iters=config.get(\"reg_anneal_iters\", 0),\n\t        maxval=config.get(\"reg_coeff_maxval\", 1.0),\n\t    )\n\t    start_step = 1\n", "    if args.ckpt:\n\t        model.load_state_dict(ckpt[\"model\"])\n\t        optim.load_state_dict(ckpt[\"optimizer\"])\n\t        # Hack to move optim states from CPU to GPU.\n\t        for state in optim.state.values():\n\t            for k, v in state.items():\n\t                if torch.is_tensor(v):\n\t                    state[k] = v.to(device)\n\t        lr_scheduler.load_state_dict(ckpt[\"scheduler\"])\n\t        start_step = ckpt[\"step\"] + 1\n", "    model = model.to(device)\n\t    num_params = 0\n\t    for name, param in model.named_parameters():\n\t        num_params += np.prod(param.size())\n\t        print(name, param.size())\n\t    print(f\"Total Paramaters: {num_params.item()}\")\n\t    # TRAIN & EVALUATE\n\t    num_steps = config[\"num_steps\"]\n\t    log_steps = config[\"log_steps\"]\n\t    save_steps = config[\"save_steps\"]\n", "    log_dir = config[\"log_dir\"]\n\t    writer = SummaryWriter(logdir=log_dir)\n\t    with open(os.path.join(log_dir, \"config.yaml\"), \"w\") as fp:\n\t        yaml.dump(config, fp, default_flow_style=False, sort_keys=False)\n\t    for step in range(start_step, num_steps + 1):\n\t        try:\n\t            train_batch = next(train_gen)\n\t        except StopIteration:\n\t            train_gen = iter(train_loader)\n\t            train_batch = next(train_gen)\n", "        train_result = train_step(\n\t            train_batch, model, optim, reg_scheduler, step, device, config\n\t        )\n\t        summary_items = copy.deepcopy(train_result)\n\t        if step % config[\"lr_decay_steps\"] == 0:\n\t            lr_scheduler.step()\n\t        if step % config.get(\"reg_anneal_every\", 1) == 0:\n\t            reg_scheduler.step()\n\t        if step % save_steps == 0 or step == num_steps:\n\t            model_path = os.path.join(config[\"ckpt_dir\"], f\"model_{step}.pt\")\n", "            torch.save(\n\t                {\n\t                    \"step\": step,\n\t                    \"model\": model.state_dict(),\n\t                    \"optimizer\": optim.state_dict(),\n\t                    \"scheduler\": lr_scheduler.state_dict(),\n\t                    \"config\": config,\n\t                },\n\t                model_path,\n\t            )\n", "        if step % log_steps == 0 or step == num_steps:\n\t            metrics = evaluate_fn(\n\t                val_loader, model, device, num_samples=config[\"num_forecast\"]\n\t            )\n\t            for m, v in metrics.items():\n\t                writer.add_scalar(m, v, global_step=step)\n\t            folder = os.path.join(log_dir, \"plots\", f\"step{step}\")\n\t            os.makedirs(folder, exist_ok=True)\n\t            plot_count = 0\n\t            while plot_count < config[\"num_plots\"]:\n", "                for test_batch in val_loader:\n\t                    past_target = test_batch[\"past_target\"].to(device)\n\t                    B, T, D = past_target.shape\n\t                    mask = test_batch[\"past_mask\"].to(device)\n\t                    future_target = test_batch[\"future_target\"].to(device)\n\t                    past_times = test_batch[\"past_times\"].to(device)\n\t                    future_times = test_batch[\"future_times\"].to(device)\n\t                    if past_times[0] > 0:\n\t                        past_times, past_target, mask = prepend_time_zero(\n\t                            past_times, past_target, mask\n", "                        )\n\t                    predict_result = model.forecast(\n\t                        past_target,\n\t                        mask,\n\t                        past_times.view(-1),\n\t                        future_times.view(-1),\n\t                        num_samples=config[\"num_forecast\"],\n\t                    )\n\t                    reconstruction = predict_result[\"reconstruction\"]\n\t                    forecast = predict_result[\"forecast\"]\n", "                    for j in range(B):\n\t                        masked_past_target = past_target.clone()\n\t                        masked_past_target[mask == 0.0] = float(\"nan\")\n\t                        fig = show_time_series_forecast(\n\t                            (12, 5),\n\t                            torch2numpy(past_times),\n\t                            torch2numpy(future_times),\n\t                            torch2numpy(torch.cat([past_target, future_target], 1))[j],\n\t                            torch2numpy(\n\t                                torch.cat([masked_past_target, future_target], 1)\n", "                            )[j],\n\t                            torch2numpy(reconstruction)[:, j],\n\t                            torch2numpy(forecast)[:, j],\n\t                            file_path=os.path.join(folder, f\"series_{plot_count}.png\"),\n\t                        )\n\t                        plt.close(fig)\n\t                        plot_count += 1\n\t                        if plot_count >= config[\"num_plots\"]:\n\t                            break\n\t                    if plot_count >= config[\"num_plots\"]:\n", "                        break\n\t        for k, v in summary_items.items():\n\t            writer.add_scalar(k, v, global_step=step)\n\t        writer.flush()\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "eval_pymunk.py", "chunked_list": ["import os\n\timport yaml\n\timport torch\n\timport argparse\n\timport matplotlib\n\timport numpy as np\n\tfrom ncdssm.torch_utils import torch2numpy\n\tfrom ncdssm.plotting import (\n\t    show_latents,\n\t    show_pymunk_forecast,\n", "    show_wasserstein_distance,\n\t)\n\tfrom ncdssm.evaluation import evaluate_pymunk_dataset\n\tfrom experiments.setups import get_model, get_dataset\n\tdef main():\n\t    matplotlib.use(\"Agg\")\n\t    # COMMAND-LINE ARGS\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\n\t        \"--ckpt\", required=True, type=str, help=\"Path to checkpoint file.\"\n", "    )\n\t    parser.add_argument(\"--seed\", type=int, help=\"Random seed.\")\n\t    parser.add_argument(\n\t        \"--wass\",\n\t        action=\"store_true\",\n\t        help=\"Whether to compute the Wasserstein distance.\",\n\t    )\n\t    parser.add_argument(\"--device\", type=str, help=\"Device to eval on\")\n\t    parser.add_argument(\n\t        \"--max_size\",\n", "        type=int,\n\t        default=np.inf,\n\t        help=\"Maximum number of time series to evaluate on. Only for debugging.\",\n\t    )\n\t    parser.add_argument(\n\t        \"--no_state_sampling\",\n\t        action=\"store_true\",\n\t        help=\"Use only the means of the predicted state distributions without sampling\",\n\t    )\n\t    parser.add_argument(\n", "        \"--smooth\",\n\t        action=\"store_true\",\n\t        help=\"Use smoothing for imputation\",\n\t    )\n\t    parser.add_argument(\n\t        \"--num_plots\", type=int, default=0, help=\"The number of plots to save\"\n\t    )\n\t    args, _ = parser.parse_known_args()\n\t    if args.seed is not None:\n\t        torch.manual_seed(args.seed)\n", "        np.random.seed(args.seed)\n\t    # CONFIG\n\t    ckpt = torch.load(args.ckpt, map_location=\"cpu\")\n\t    config = ckpt[\"config\"]\n\t    config[\"device\"] = args.device or config[\"device\"]\n\t    # DATA\n\t    train_dataset, _, test_dataset = get_dataset(config)\n\t    test_loader = torch.utils.data.DataLoader(\n\t        test_dataset,\n\t        batch_size=config[\"test_batch_size\"],\n", "        collate_fn=train_dataset.collate_fn,\n\t    )\n\t    # MODEL\n\t    device = torch.device(config[\"device\"])\n\t    model = get_model(config=config)\n\t    model.load_state_dict(ckpt[\"model\"])\n\t    step = ckpt[\"step\"]\n\t    model = model.to(device)\n\t    num_params = 0\n\t    for name, param in model.named_parameters():\n", "        num_params += np.prod(param.size())\n\t        print(name, param.size())\n\t    print(f\"Total Paramaters: {num_params.item()}\")\n\t    # REEVALUATE\n\t    log_dir = config[\"log_dir\"]\n\t    folder = os.path.join(log_dir, \"test_plots\", f\"step{step}\")\n\t    os.makedirs(folder, exist_ok=True)\n\t    results = {\"config\": config}\n\t    save_dict = dict(predictions=[])\n\t    if args.wass:\n", "        (\n\t            wt_mean,\n\t            wt_conf_interval,\n\t            future_w_mean,\n\t            future_w_conf_interval,\n\t        ) = evaluate_pymunk_dataset(\n\t            test_loader,\n\t            model,\n\t            device=device,\n\t            num_samples=config[\"num_forecast\"],\n", "            max_size=args.max_size,\n\t            no_state_sampling=args.no_state_sampling,\n\t            use_smooth=args.smooth,\n\t        ).values()\n\t        save_dict[\"wass_dist\"] = wt_mean\n\t        show_wasserstein_distance(\n\t            (15, 2),\n\t            wt_mean,\n\t            conf_intervals=wt_conf_interval,\n\t            fig_title=\"Wasserstein Distance\",\n", "            file_path=os.path.join(folder, \"wass.png\"),\n\t        )\n\t        print(\n\t            f\"Forecast W: {future_w_mean.item():.3f} \"\n\t            f\"+/- {future_w_conf_interval.item():.3f}\"\n\t        )\n\t        results[\"future_w_mean\"] = future_w_mean.item()\n\t        results[\"future_w_conf_interval\"] = future_w_conf_interval.item()\n\t    plot_count = 0\n\t    while plot_count < args.num_plots:\n", "        for test_batch in test_loader:\n\t            past_target = test_batch[\"past_target\"].to(device)\n\t            B, T, _ = past_target.shape\n\t            mask = test_batch[\"past_mask\"].to(device)\n\t            future_target = test_batch[\"future_target\"].to(device)\n\t            past_times = test_batch[\"past_times\"].to(device)\n\t            future_times = test_batch[\"future_times\"].to(device)\n\t            predict_result = model.forecast(\n\t                past_target,\n\t                mask,\n", "                past_times.view(-1),\n\t                future_times.view(-1),\n\t                num_samples=config[\"num_forecast\"],\n\t                no_state_sampling=args.no_state_sampling,\n\t                use_smooth=args.smooth,\n\t            )\n\t            reconstruction = predict_result[\"reconstruction\"]\n\t            forecast = predict_result[\"forecast\"]\n\t            full_times = torch.cat([past_times, future_times], 0)\n\t            full_prediction = torch.cat([reconstruction, forecast], dim=-2)\n", "            full_target = torch.cat([past_target, future_target], dim=-2)\n\t            latent_variables = dict()\n\t            if \"z_reconstruction\" in predict_result:\n\t                full_z = torch.cat(\n\t                    [predict_result[\"z_reconstruction\"], predict_result[\"z_forecast\"]],\n\t                    dim=-2,\n\t                )\n\t                latent_variables[\"z\"] = full_z\n\t            if \"alpha_reconstruction\" in predict_result:\n\t                full_alpha = torch.cat(\n", "                    [\n\t                        predict_result[\"alpha_reconstruction\"],\n\t                        predict_result[\"alpha_forecast\"],\n\t                    ],\n\t                    dim=-2,\n\t                )\n\t                latent_variables[\"alpha\"] = full_alpha\n\t            if \"aux_reconstruction\" in predict_result:\n\t                full_aux = torch.cat(\n\t                    [\n", "                        predict_result[\"aux_reconstruction\"],\n\t                        predict_result[\"aux_forecast\"],\n\t                    ],\n\t                    dim=-2,\n\t                )\n\t                latent_variables[\"aux\"] = full_aux\n\t            for j in range(B):\n\t                full_prediction_j = full_prediction[:, j].view(\n\t                    full_prediction.shape[0],\n\t                    full_prediction.shape[-2],\n", "                    1,\n\t                    config[\"img_size\"],\n\t                    config[\"img_size\"],\n\t                )\n\t                full_target_j = full_target[j].view(\n\t                    full_target.shape[1], 1, config[\"img_size\"], config[\"img_size\"]\n\t                )\n\t                # Plot first five samples\n\t                samples_dir = os.path.join(folder, f\"series_{j}\")\n\t                os.makedirs(samples_dir, exist_ok=True)\n", "                full_target_j[:T][mask[j] == 0.0] = 0.0\n\t                save_dict[\"predictions\"].append(\n\t                    dict(\n\t                        target=torch2numpy(full_target_j),\n\t                        pred=torch2numpy(full_prediction_j[0]),\n\t                    )\n\t                )\n\t                show_pymunk_forecast(\n\t                    torch2numpy(full_target_j),\n\t                    torch2numpy(full_prediction_j[:5]),\n", "                    os.path.join(samples_dir, \"prediction.png\"),\n\t                )\n\t                if len(latent_variables) > 0:\n\t                    latent_variables_j = {\n\t                        k: torch2numpy(v[:, j]) for k, v in latent_variables.items()\n\t                    }\n\t                    for m in range(5):\n\t                        latent_variables_jm = {\n\t                            k: v[m] for k, v in latent_variables_j.items()\n\t                        }\n", "                        plot_path = os.path.join(samples_dir, f\"lat_{m}.png\")\n\t                        show_latents(\n\t                            (15, 8),\n\t                            time=torch2numpy(full_times),\n\t                            latents=latent_variables_jm,\n\t                            fig_title=\"Latents\",\n\t                            file_path=plot_path,\n\t                        )\n\t                plot_count += 1\n\t                if plot_count == args.num_plots:\n", "                    break\n\t            if plot_count == args.num_plots:\n\t                break\n\t    with open(os.path.join(log_dir, \"metrics.yaml\"), \"w\") as fp:\n\t        yaml.dump(results, fp, default_flow_style=False)\n\t    np.savez(os.path.join(log_dir, \"plot_data.npz\"), **save_dict)\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "eval_ts.py", "chunked_list": ["import os\n\timport yaml\n\timport torch\n\timport argparse\n\timport matplotlib\n\timport matplotlib.pyplot as plt\n\timport numpy as np\n\tfrom ncdssm.evaluation import evaluate_simple_ts, evaluate_sporadic\n\tfrom ncdssm.plotting import show_time_series_forecast, show_latents\n\tfrom ncdssm.torch_utils import torch2numpy, prepend_time_zero\n", "from experiments.setups import get_model, get_dataset\n\tdef main():\n\t    matplotlib.use(\"Agg\")\n\t    # COMMAND-LINE ARGS\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\n\t        \"--ckpt\", required=True, type=str, help=\"Path to checkpoint file.\"\n\t    )\n\t    parser.add_argument(\n\t        \"--sporadic\",\n", "        action=\"store_true\",\n\t        help=\"Whether sporadic dataset (e.g., climate) is used.\",\n\t    )\n\t    parser.add_argument(\"--seed\", type=int, help=\"Random seed.\")\n\t    parser.add_argument(\n\t        \"--max_size\",\n\t        type=int,\n\t        default=np.inf,\n\t        help=\"Max number of time series to test.\",\n\t    )\n", "    parser.add_argument(\"--device\", type=str, help=\"Device to eval on\")\n\t    parser.add_argument(\n\t        \"--no_state_sampling\",\n\t        action=\"store_true\",\n\t        help=\"Use only the means of the predicted state distributions without sampling\",\n\t    )\n\t    parser.add_argument(\n\t        \"--smooth\",\n\t        action=\"store_true\",\n\t        help=\"Use smoothing for imputation\",\n", "    )\n\t    parser.add_argument(\n\t        \"--num_plots\", type=int, default=0, help=\"The number of plots to save\"\n\t    )\n\t    args, _ = parser.parse_known_args()\n\t    if args.seed is not None:\n\t        torch.manual_seed(args.seed)\n\t        np.random.seed(args.seed)\n\t    if args.sporadic:\n\t        evaluate_fn = evaluate_sporadic\n", "    else:\n\t        evaluate_fn = evaluate_simple_ts\n\t    # CONFIG\n\t    ckpt = torch.load(args.ckpt, map_location=\"cpu\")\n\t    config = ckpt[\"config\"]\n\t    config[\"device\"] = args.device or config[\"device\"]\n\t    # DATA\n\t    _, _, test_dataset = get_dataset(config)\n\t    test_loader = torch.utils.data.DataLoader(\n\t        test_dataset,\n", "        batch_size=config[\"test_batch_size\"],\n\t        collate_fn=test_dataset.collate_fn,\n\t    )\n\t    # MODEL\n\t    device = torch.device(config[\"device\"])\n\t    model = get_model(config=config)\n\t    model.load_state_dict(ckpt[\"model\"], strict=True)\n\t    step = ckpt[\"step\"]\n\t    model = model.to(device)\n\t    num_params = 0\n", "    for name, param in model.named_parameters():\n\t        num_params += np.prod(param.size())\n\t        print(name, param.size())\n\t    print(f\"Total Paramaters: {num_params.item()}\")\n\t    # print(model.A, model.C)\n\t    # REEVALUATE\n\t    log_dir = config[\"log_dir\"]\n\t    folder = os.path.join(log_dir, \"test_plots\", f\"step{step}\")\n\t    os.makedirs(folder, exist_ok=True)\n\t    results = {\"config\": config}\n", "    if args.max_size > 0:\n\t        metrics = evaluate_fn(\n\t            test_loader,\n\t            model,\n\t            device,\n\t            num_samples=config[\"num_forecast\"],\n\t            no_state_sampling=args.no_state_sampling,\n\t            use_smooth=args.smooth,\n\t        )\n\t        results[\"test\"] = metrics\n", "    plot_count = 0\n\t    plot_data = []\n\t    while plot_count < args.num_plots:\n\t        for test_batch in test_loader:\n\t            past_target = test_batch[\"past_target\"].to(device)\n\t            B, T, D = past_target.shape\n\t            mask = test_batch[\"past_mask\"].to(device)\n\t            future_target = test_batch[\"future_target\"].to(device)\n\t            past_times = test_batch[\"past_times\"].to(device)\n\t            future_times = test_batch[\"future_times\"].to(device)\n", "            if past_times[0] > 0:\n\t                past_times, past_target, mask = prepend_time_zero(\n\t                    past_times, past_target, mask\n\t                )\n\t            predict_result = model.forecast(\n\t                past_target,\n\t                mask,\n\t                past_times.view(-1),\n\t                future_times.view(-1),\n\t                num_samples=config[\"num_forecast\"],\n", "                no_state_sampling=args.no_state_sampling,\n\t                use_smooth=args.smooth,\n\t            )\n\t            reconstruction = predict_result[\"reconstruction\"]\n\t            forecast = predict_result[\"forecast\"]\n\t            full_times = torch.cat([past_times, future_times], 0)\n\t            latent_variables = dict()\n\t            if \"z_reconstruction\" in predict_result:\n\t                full_z = torch.cat(\n\t                    [predict_result[\"z_reconstruction\"], predict_result[\"z_forecast\"]],\n", "                    dim=-2,\n\t                )\n\t                latent_variables[\"z\"] = full_z\n\t            if \"alpha_reconstruction\" in predict_result:\n\t                full_alpha = torch.cat(\n\t                    [\n\t                        predict_result[\"alpha_reconstruction\"],\n\t                        predict_result[\"alpha_forecast\"],\n\t                    ],\n\t                    dim=-2,\n", "                )\n\t                latent_variables[\"alpha\"] = full_alpha\n\t            for j in range(B):\n\t                print(f\"Plotting {plot_count + 1}/{config['num_plots']}\")\n\t                samples_dir = os.path.join(folder, f\"series_{j}\")\n\t                os.makedirs(samples_dir, exist_ok=True)\n\t                masked_past_target = past_target.clone()\n\t                masked_past_target[mask == 0.0] = float(\"nan\")\n\t                plot_data_j = dict(\n\t                    fig_size=(12, 5),\n", "                    past_times=torch2numpy(past_times),\n\t                    future_times=torch2numpy(future_times),\n\t                    inputs=torch2numpy(torch.cat([past_target, future_target], 1))[j],\n\t                    masked_inputs=torch2numpy(\n\t                        torch.cat([masked_past_target, future_target], 1)\n\t                    )[j],\n\t                    reconstruction=torch2numpy(reconstruction)[:, j],\n\t                    forecast=torch2numpy(forecast)[:, j],\n\t                )\n\t                plot_data.append(plot_data_j)\n", "                fig = show_time_series_forecast(\n\t                    **plot_data_j,\n\t                    file_path=os.path.join(samples_dir, f\"series_{plot_count}.png\"),\n\t                )\n\t                plt.close(fig)\n\t                if len(latent_variables) > 0:\n\t                    latent_variables_j = {\n\t                        k: torch2numpy(v[:, j]) for k, v in latent_variables.items()\n\t                    }\n\t                    for m in range(5):\n", "                        latent_variables_jm = {\n\t                            k: v[m] for k, v in latent_variables_j.items()\n\t                        }\n\t                        plot_path = os.path.join(samples_dir, f\"lat_{m}.png\")\n\t                        show_latents(\n\t                            (15, 8),\n\t                            time=torch2numpy(full_times),\n\t                            latents=latent_variables_jm,\n\t                            fig_title=\"Latents\",\n\t                            file_path=plot_path,\n", "                        )\n\t                plot_count += 1\n\t                if plot_count == args.num_plots:\n\t                    break\n\t            if plot_count == args.num_plots:\n\t                break\n\t    if args.max_size > 0:\n\t        with open(os.path.join(log_dir, \"metrics.yaml\"), \"w\") as fp:\n\t            yaml.dump(results, fp, default_flow_style=False)\n\tif __name__ == \"__main__\":\n", "    main()\n"]}
{"filename": "data/pong.py", "chunked_list": ["import pygame\n\timport pymunk.pygame_util\n\timport numpy as np\n\timport os\n\tfrom pygame.color import THECOLORS as color\n\tfrom pathlib import Path\n\t# Note: This code is taken from\n\t# https://github.com/simonkamronn/kvae/blob/master/kvae/datasets/box.py\n\t# Made only minor adjustments, e.g. the saving paths,\n\t# number of time-steps for test data.\n", "scale = 1\n\tclass Pong:\n\t    def __init__(self, dt=0.2, res=(32, 32), init_pos=(3, 3), init_std=0, wall=None):\n\t        pygame.init()\n\t        self.dt = dt\n\t        self.res = res\n\t        if os.environ.get(\"SDL_VIDEODRIVER\", \"\") == \"dummy\":\n\t            pygame.display.set_mode(res, 0, 24)\n\t            self.screen = pygame.Surface(res, pygame.SRCCOLORKEY, 24)\n\t            pygame.draw.rect(self.screen, (0, 0, 0), (0, 0, res[0], res[1]), 0)\n", "        else:\n\t            self.screen = pygame.display.set_mode(res, 0, 24)\n\t        self.gravity = (0.0, 0.0)\n\t        self.initial_position = init_pos\n\t        self.initial_std = init_std\n\t        self.space = pymunk.Space()\n\t        self.space.gravity = self.gravity\n\t        self.draw_options = pymunk.pygame_util.DrawOptions(self.screen)\n\t        self.clock = pygame.time.Clock()\n\t        self.wall = wall\n", "        self.static_lines = None\n\t        self.dd = 2\n\t    def _clear(self):\n\t        self.screen.fill(color[\"black\"])\n\t    class Paddle:\n\t        def __init__(self, pong, position):\n\t            self.pong = pong\n\t            self.area = pong.res\n\t            if position == \"left\":\n\t                self.rect = pymunk.Segment(\n", "                    pong.space.static_body,\n\t                    (0, self.area[1] / 2 + 3 * scale),\n\t                    (0, self.area[1] / 2 - 3 * scale),\n\t                    1.0,\n\t                )\n\t            else:\n\t                self.rect = pymunk.Segment(\n\t                    pong.space.static_body,\n\t                    (self.area[0] - 2, self.area[1] / 2 + 3 * scale),\n\t                    (self.area[0] - 2, self.area[1] / 2 - 3 * scale),\n", "                    1.0,\n\t                )\n\t            self.speed = 2 * scale\n\t            self.rect.elasticity = 0.99\n\t            self.rect.color = color[\"white\"]\n\t            self.rect.collision_type = 1\n\t        def update(self, ball):\n\t            a, b = self.rect.a, self.rect.b\n\t            center = (a.y + b.y) / 2\n\t            if ball.body.position.y < center - self.speed / 2:\n", "                delta_y = min(b.y, self.speed)\n\t                a.y -= delta_y\n\t                b.y -= delta_y\n\t                self.rect.unsafe_set_endpoints(a, b)\n\t            if ball.body.position.y > center + self.speed / 2:\n\t                delta_y = min(self.area[1] - a.y, self.speed)\n\t                a.y += delta_y\n\t                b.y += delta_y\n\t                self.rect.unsafe_set_endpoints(a, b)\n\t            return self.rect\n", "    def add_walls(self):\n\t        self.static_lines = []\n\t        # Add floor\n\t        self.static_lines.append(\n\t            pymunk.Segment(self.space.static_body, (0, 1), (self.res[1], 1), 0.0)\n\t        )\n\t        # Add roof\n\t        self.static_lines.append(\n\t            pymunk.Segment(\n\t                self.space.static_body,\n", "                (0, self.res[1]),\n\t                (self.res[1], self.res[1]),\n\t                0.0,\n\t            )\n\t        )\n\t        # Set properties\n\t        for line in self.static_lines:\n\t            line.elasticity = 0.99\n\t            line.color = color[\"white\"]\n\t        self.space.add(self.static_lines)\n", "        return True\n\t    def create_ball(self, radius=3):\n\t        inertia = pymunk.moment_for_circle(1, 0, radius, (0, 0))\n\t        body = pymunk.Body(1, inertia)\n\t        position = np.array(\n\t            self.initial_position\n\t        ) + self.initial_std * np.random.normal(size=(2,))\n\t        position = np.clip(\n\t            position, self.dd + radius + 1, self.res[0] - self.dd - radius - 1\n\t        )\n", "        body.position = position\n\t        shape = pymunk.Circle(body, radius, (0, 0))\n\t        shape.elasticity = 0.9\n\t        shape.color = color[\"white\"]\n\t        return shape\n\t    def fire(self, angle=50, velocity=20, radius=3):\n\t        speedX = velocity * np.cos(angle * np.pi / 180)\n\t        speedY = velocity * np.sin(angle * np.pi / 180)\n\t        ball = self.create_ball(radius)\n\t        ball.body.velocity = (speedX, speedY)\n", "        self.space.add(ball, ball.body)\n\t        return ball\n\t    def run(\n\t        self,\n\t        iterations=20,\n\t        sequences=500,\n\t        angle_limits=(0, 360),\n\t        radius=3,\n\t        save=None,\n\t        filepath=\"/tmp/data/pong.npz\",\n", "        delay=None,\n\t    ):\n\t        if save:\n\t            data = np.empty(\n\t                (sequences, iterations, self.res[0], self.res[1]),\n\t                dtype=np.float32,\n\t            )\n\t        controls = None, None\n\t        # Add roof and floor\n\t        self.add_walls()\n", "        for s in range(sequences):\n\t            if s % 100 == 0:\n\t                print(f\"sequence {s}/{sequences}\")\n\t            angle = np.random.uniform(*angle_limits)\n\t            velocity = 10 * scale\n\t            ball = self.fire(angle, velocity, radius)\n\t            # Create pong paddles\n\t            paddle1 = self.Paddle(self, \"left\")\n\t            paddle2 = self.Paddle(self, \"right\")\n\t            for i in range(iterations):\n", "                self._clear()\n\t                # Add paddles\n\t                self.space.add(paddle1.update(ball))\n\t                self.space.add(paddle2.update(ball))\n\t                # Step\n\t                self.space.step(self.dt)\n\t                # Draw objects\n\t                self.space.debug_draw(self.draw_options)\n\t                pygame.display.flip()\n\t                if delay:\n", "                    self.clock.tick(delay)\n\t                if save == \"png\":\n\t                    pygame.image.save(\n\t                        self.screen,\n\t                        os.path.join(filepath, \"pong_%02d_%02d.png\" % (s, i)),\n\t                    )\n\t                elif save == \"npz\":\n\t                    data[s, i] = (\n\t                        pygame.surfarray.array2d(self.screen)\n\t                        .swapaxes(1, 0)\n", "                        .astype(np.float32)\n\t                        / 255\n\t                    )\n\t                # Remove the paddles\n\t                self.space.remove(paddle1.rect)\n\t                self.space.remove(paddle2.rect)\n\t            # Remove the ball and the wall from the space\n\t            self.space.remove(ball, ball.body)\n\t        if save == \"npz\":\n\t            np.savez(os.path.abspath(filepath), images=data, controls=controls)\n", "def generate_dataset(data_path, seed=1234, n_timesteps_train=20, n_timesteps_test=100):\n\t    os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n\t    np.random.seed(seed=seed)\n\t    # Create data dir\n\t    if not os.path.exists(data_path):\n\t        os.makedirs(data_path)\n\t    cannon = Pong(\n\t        dt=0.2,\n\t        res=(32 * scale, 32 * scale),\n\t        init_pos=(16 * scale, 16 * scale),\n", "        init_std=3,\n\t        wall=None,\n\t    )\n\t    cannon.run(\n\t        delay=None,\n\t        iterations=n_timesteps_train,\n\t        sequences=5000,\n\t        radius=3 * scale,\n\t        angle_limits=(0, 360),\n\t        filepath=os.path.join(data_path, \"train.npz\"),\n", "        save=\"npz\",\n\t    )\n\t    cannon.run(\n\t        delay=None,\n\t        iterations=n_timesteps_test,\n\t        sequences=100,\n\t        radius=3 * scale,\n\t        angle_limits=(0, 360),\n\t        filepath=os.path.join(data_path, \"val.npz\"),\n\t        save=\"npz\",\n", "    )\n\t    np.random.seed(5678)\n\t    cannon.run(\n\t        delay=None,\n\t        iterations=n_timesteps_test,\n\t        sequences=1000,\n\t        radius=3 * scale,\n\t        angle_limits=(0, 360),\n\t        filepath=os.path.join(data_path, \"test.npz\"),\n\t        save=\"npz\",\n", "    )\n\tif __name__ == \"__main__\":\n\t    data_path = str(Path(__file__).resolve().parent / \"pymunk\" / \"pong\")\n\t    print(f\"Saving dataset to: {data_path}.\")\n\t    generate_dataset(data_path)\n"]}
{"filename": "data/climate.py", "chunked_list": ["import urllib.request\n\tfrom pathlib import Path\n\timport numpy as np\n\timport pandas as pd\n\tfrom sklearn.model_selection import train_test_split\n\tCLIMATE_DATA_URL = \"https://raw.githubusercontent.com/edebrouwer/gru_ode_bayes/master/gru_ode_bayes/datasets/Climate/small_chunked_sporadic.csv\"  # noqa\n\tDATA_ROOT = Path(__file__).resolve().parent / \"climate\"\n\tLOCAL_PATH = DATA_ROOT / \"climate-data-preproc.csv\"\n\tdef download_preprocessed():\n\t    print(\"Downloading dataset.\")\n", "    DATA_ROOT.mkdir(exist_ok=True)\n\t    urllib.request.urlretrieve(CLIMATE_DATA_URL, LOCAL_PATH)\n\tdef generate_folds(num_folds=5, seed=432):\n\t    print(\"Generating folds.\")\n\t    # Modified from https://github.com/edebrouwer/gru_ode_bayes/blob/master/data_preproc/Climate/generate_folds.py # noqa\n\t    num_series = pd.read_csv(LOCAL_PATH)[\"ID\"].nunique()\n\t    np.random.seed(seed)\n\t    for fold in range(num_folds):\n\t        train_idx, test_idx = train_test_split(np.arange(num_series), test_size=0.1)\n\t        train_idx, val_idx = train_test_split(train_idx, test_size=0.2)\n", "        fold_dir = DATA_ROOT / f\"fold_idx_{fold}/\"\n\t        fold_dir.mkdir(exist_ok=True)\n\t        np.save(fold_dir / \"train_idx.npy\", train_idx)\n\t        np.save(fold_dir / \"val_idx.npy\", val_idx)\n\t        np.save(fold_dir / \"test_idx.npy\", test_idx)\n\tif __name__ == \"__main__\":\n\t    download_preprocessed()\n\t    generate_folds()\n"]}
{"filename": "data/box.py", "chunked_list": ["import pygame\n\timport pymunk.pygame_util\n\timport numpy as np\n\timport os\n\tfrom pathlib import Path\n\t# Note: This code is taken from\n\t# https://github.com/simonkamronn/kvae/blob/master/kvae/datasets/box.py\n\t# Made only minor adjustments, e.g. the saving paths,\n\t# number of time-steps for test data.\n\tclass BallBox:\n", "    def __init__(\n\t        self,\n\t        dt=0.2,\n\t        res=(32, 32),\n\t        init_pos=(3, 3),\n\t        init_std=0,\n\t        wall=None,\n\t        gravity=(0.0, 0.0),\n\t    ):\n\t        pygame.init()\n", "        self.dt = dt\n\t        self.res = res\n\t        if os.environ.get(\"SDL_VIDEODRIVER\", \"\") == \"dummy\":\n\t            pygame.display.set_mode(res, 0, 24)\n\t            self.screen = pygame.Surface(res, pygame.SRCCOLORKEY, 24)\n\t            pygame.draw.rect(self.screen, (0, 0, 0), (0, 0, res[0], res[1]), 0)\n\t        else:\n\t            self.screen = pygame.display.set_mode(res, 0, 24)\n\t        self.gravity = gravity\n\t        self.initial_position = init_pos\n", "        self.initial_std = init_std\n\t        self.space = pymunk.Space()\n\t        self.space.gravity = self.gravity\n\t        self.draw_options = pymunk.pygame_util.DrawOptions(self.screen)\n\t        self.clock = pygame.time.Clock()\n\t        self.wall = wall\n\t        self.static_lines = None\n\t        self.dd = 2\n\t    def _clear(self):\n\t        self.screen.fill(pygame.color.THECOLORS[\"black\"])\n", "    def create_ball(self, radius=3):\n\t        inertia = pymunk.moment_for_circle(1, 0, radius, (0, 0))\n\t        body = pymunk.Body(1, inertia)\n\t        position = np.array(\n\t            self.initial_position\n\t        ) + self.initial_std * np.random.normal(size=(2,))\n\t        position = np.clip(\n\t            position, self.dd + radius + 1, self.res[0] - self.dd - radius - 1\n\t        )\n\t        body.position = position\n", "        shape = pymunk.Circle(body, radius, (0, 0))\n\t        shape.elasticity = 1.0\n\t        shape.color = pygame.color.THECOLORS[\"white\"]\n\t        return shape\n\t    def fire(self, angle=50, velocity=20, radius=3):\n\t        speedX = velocity * np.cos(angle * np.pi / 180)\n\t        speedY = velocity * np.sin(angle * np.pi / 180)\n\t        ball = self.create_ball(radius)\n\t        ball.body.velocity = (speedX, speedY)\n\t        self.space.add(ball, ball.body)\n", "        return ball\n\t    def run(\n\t        self,\n\t        iterations=20,\n\t        sequences=500,\n\t        angle_limits=(0, 360),\n\t        velocity_limits=(10, 25),\n\t        radius=3,\n\t        flip_gravity=None,\n\t        save=None,\n", "        filepath=\"/tmp/data/box.npz\",\n\t        delay=None,\n\t    ):\n\t        if save:\n\t            images = np.empty(\n\t                (sequences, iterations, self.res[0], self.res[1]),\n\t                dtype=np.float32,\n\t            )\n\t            state = np.empty((sequences, iterations, 4), dtype=np.float32)\n\t        dd = self.dd\n", "        self.static_lines = [\n\t            pymunk.Segment(\n\t                self.space.static_body, (dd, dd), (dd, self.res[1] - dd), 0.0\n\t            ),\n\t            pymunk.Segment(\n\t                self.space.static_body, (dd, dd), (self.res[0] - dd, dd), 0.0\n\t            ),\n\t            pymunk.Segment(\n\t                self.space.static_body,\n\t                (self.res[0] - dd, self.res[1] - dd),\n", "                (dd, self.res[1] - dd),\n\t                0.0,\n\t            ),\n\t            pymunk.Segment(\n\t                self.space.static_body,\n\t                (self.res[0] - dd, self.res[1] - dd),\n\t                (self.res[0] - dd, dd),\n\t                0.0,\n\t            ),\n\t        ]\n", "        for line in self.static_lines:\n\t            line.elasticity = 1.0\n\t            line.color = pygame.color.THECOLORS[\"white\"]\n\t        self.space.add(self.static_lines)\n\t        for s in range(sequences):\n\t            if s % 100 == 0:\n\t                print(f\"sequence: {s}/{sequences}\")\n\t            angle = np.random.uniform(*angle_limits)\n\t            velocity = np.random.uniform(*velocity_limits)\n\t            # controls[:, s] = np.array([angle, velocity])\n", "            ball = self.fire(angle, velocity, radius)\n\t            for i in range(iterations):\n\t                self._clear()\n\t                self.space.debug_draw(self.draw_options)\n\t                self.space.step(self.dt)\n\t                pygame.display.flip()\n\t                if delay:\n\t                    self.clock.tick(delay)\n\t                if save == \"png\":\n\t                    pygame.image.save(\n", "                        self.screen,\n\t                        os.path.join(filepath, \"bouncing_balls_%02d_%02d.png\" % (s, i)),\n\t                    )\n\t                elif save == \"npz\":\n\t                    images[s, i] = pygame.surfarray.array2d(self.screen).swapaxes(\n\t                        1, 0\n\t                    ).astype(np.float32) / (2**24 - 1)\n\t                    state[s, i] = list(ball.body.position) + list(ball.body.velocity)\n\t            # Remove the ball and the wall from the space\n\t            self.space.remove(ball, ball.body)\n", "        if save == \"npz\":\n\t            np.savez(os.path.abspath(filepath), images=images, state=state)\n\tdef generate_dataset(data_path, seed=1234, n_timesteps_train=20, n_timesteps_test=100):\n\t    os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"  # Remove and add delay to see the videos\n\t    scale = 1\n\t    np.random.seed(seed=seed)\n\t    # Create data dir\n\t    if not os.path.exists(data_path):\n\t        os.makedirs(data_path)\n\t    cannon = BallBox(\n", "        dt=0.2,\n\t        res=(32 * scale, 32 * scale),\n\t        init_pos=(16 * scale, 16 * scale),\n\t        init_std=10 * scale,\n\t        wall=None,\n\t    )\n\t    print(\"Generating training sequences\")\n\t    cannon.run(\n\t        delay=None,\n\t        iterations=n_timesteps_train,\n", "        sequences=5000,\n\t        radius=3 * scale,\n\t        angle_limits=(0, 360),\n\t        velocity_limits=(10.0 * scale, 15.0 * scale),\n\t        filepath=os.path.join(data_path, \"train.npz\"),\n\t        save=\"npz\",\n\t    )\n\t    print(\"Generating val sequences\")\n\t    cannon.run(\n\t        delay=None,\n", "        iterations=n_timesteps_test,\n\t        sequences=100,\n\t        radius=3 * scale,\n\t        angle_limits=(0, 360),\n\t        velocity_limits=(10.0 * scale, 15.0 * scale),\n\t        filepath=os.path.join(data_path, \"val.npz\"),\n\t        save=\"npz\",\n\t    )\n\t    print(\"Generating test sequences\")\n\t    np.random.seed(5678)\n", "    cannon.run(\n\t        delay=None,\n\t        iterations=n_timesteps_test,\n\t        sequences=1000,\n\t        radius=3 * scale,\n\t        angle_limits=(0, 360),\n\t        velocity_limits=(10.0 * scale, 15.0 * scale),\n\t        filepath=os.path.join(data_path, \"test.npz\"),\n\t        save=\"npz\",\n\t    )\n", "if __name__ == \"__main__\":\n\t    data_path = str(Path(__file__).resolve().parent / \"pymunk\" / \"box\")\n\t    print(f\"Saving dataset to: {data_path}.\")\n\t    generate_dataset(data_path)\n"]}
{"filename": "data/bouncing_ball.py", "chunked_list": ["import os\n\timport numpy as np\n\timport argparse\n\tfrom tqdm.auto import tqdm\n\tfrom pathlib import Path\n\tdef generate_sequence(low=-1, high=1.0, vel=None, num_steps=300):\n\t    y = np.random.uniform(low=low, high=high)\n\t    if vel is None:\n\t        vel = np.random.uniform(low=0.05, high=0.5) * np.random.choice([-1, 1])\n\t    noise_scale = 0.05\n", "    points = [y + noise_scale * np.random.randn(1)]\n\t    step_size = 0.1\n\t    for i in range(num_steps - 1):\n\t        y = y + vel * step_size\n\t        points.append(y + noise_scale * np.random.randn(1))\n\t        if y <= low or y >= high:\n\t            vel = -vel\n\t    return np.stack(points)\n\tdef generate_sequences(num_samples, vels=None, num_steps=300):\n\t    all_target = []\n", "    for _ in tqdm(range(num_samples)):\n\t        chosen_v = np.random.choice(vels) if vels is not None else None\n\t        y = generate_sequence(vel=chosen_v, num_steps=num_steps)\n\t        all_target.append(y)\n\t    all_target = np.stack(all_target)\n\t    return all_target\n\tdef generate_dataset(\n\t    seed=42,\n\t    vels=None,\n\t    dataset_path=None,\n", "    n_train=5000,\n\t    n_val=500,\n\t    n_test=500,\n\t    n_timesteps=300,\n\t    file_prefix=\"\",\n\t):\n\t    if dataset_path is None:\n\t        dataset_path = \"./bouncing_ball/\"\n\t    os.makedirs(dataset_path, exist_ok=True)\n\t    np.random.seed(seed=seed)\n", "    obs_train = generate_sequences(n_train, vels=vels, num_steps=n_timesteps)\n\t    obs_val = generate_sequences(n_val, vels=vels, num_steps=n_timesteps)\n\t    obs_test = generate_sequences(n_test, vels=vels, num_steps=n_timesteps)\n\t    np.savez(os.path.join(dataset_path, f\"{file_prefix}train.npz\"), target=obs_train)\n\t    np.savez(os.path.join(dataset_path, f\"{file_prefix}val.npz\"), target=obs_val)\n\t    np.savez(os.path.join(dataset_path, f\"{file_prefix}test.npz\"), target=obs_test)\n\tif __name__ == \"__main__\":\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\n\t        \"--num_vels\",\n", "        type=int,\n\t        default=0,\n\t        help=\"Number of fixed velocities, 0 indicates ranodm velocity for every sample\",\n\t        choices=[0, 1, 2, 5],\n\t    )\n\t    args = parser.parse_args()\n\t    data_path = str(Path(__file__).resolve().parent / \"bouncing_ball\")\n\t    print(f\"Saving dataset to: {data_path}.\")\n\t    vels = None\n\t    if args.num_vels == 0:\n", "        vels = None\n\t        print(\"Generating dataset with random velocties...\")\n\t        generate_dataset(file_prefix=\"rv_\", vels=vels, dataset_path=data_path)\n\t    elif args.num_vels == 1:\n\t        vels = [0.2]\n\t        print(\"Generating dataset with 1 veloctity...\")\n\t        generate_dataset(file_prefix=\"1fv_\", vels=vels, dataset_path=data_path)\n\t    elif args.num_vels == 2:\n\t        vels = [0.2, 0.4]\n\t        print(\"Generating dataset with 2 velocties...\")\n", "        generate_dataset(file_prefix=\"2fv_\", vels=vels, dataset_path=data_path)\n\t    elif args.num_vels == 5:\n\t        vels = [0.1, 0.2, 0.3, 0.4, 0.5]\n\t        print(\"Generating dataset with 5 velocties...\")\n\t        generate_dataset(file_prefix=\"5fv_\", vels=vels, dataset_path=data_path)\n"]}
{"filename": "data/damped_pendulum.py", "chunked_list": ["import os\n\timport numpy as np\n\tfrom pathlib import Path\n\timport contextlib\n\timport torch\n\t@contextlib.contextmanager\n\tdef local_seed(seed):\n\t    state_np = np.random.get_state()\n\t    state_torch = torch.random.get_rng_state()\n\t    np.random.seed(seed)\n", "    torch.random.manual_seed(seed)\n\t    try:\n\t        yield\n\t    finally:\n\t        np.random.set_state(state_np)\n\t        torch.random.set_rng_state(state_torch)\n\tdef rungekutta4(state: np.ndarray, t: float, dt: float, f: callable):\n\t    k1 = dt * f(state=state, t=t)\n\t    k2 = dt * f(state=state + 0.5 * k1, t=t + 0.5 * dt)\n\t    k3 = dt * f(state=state + 0.5 * k2, t=t + 0.5 * dt)\n", "    k4 = dt * f(state=state + k3, t=t + dt)\n\t    next_state = state + (k1 + 2.0 * (k2 + k3) + k4) / 6.0\n\t    next_t = t + dt\n\t    return next_state, next_t\n\tclass Environment(object):\n\t    def __init__(self, n_obs, n_state, n_ctrl, dt):\n\t        self.n_obs = n_obs\n\t        self.n_state = n_state\n\t        self.n_ctrl = n_ctrl\n\t        self.dt = dt\n", "    def enter(self, *args, **kwargs):\n\t        raise NotImplementedError()\n\t    def observe(self, *args, **kwargs):\n\t        raise NotImplementedError()\n\t    def transit(self, ctrl):\n\t        raise NotImplementedError()\n\tclass Pendulum3DCoordEnvironment(Environment):\n\t    def __init__(\n\t        self,\n\t        dt=0.1,\n", "        center_pendulum=np.array((0, 0, 2.0)),\n\t        cov_pendulum=np.array((0.1, 0.2, 0.1)),\n\t        noise_std_obs=0.05,\n\t        radius=1.0,\n\t        g=9.81,\n\t        mass=1.0,\n\t        dampening=0.25,\n\t        noise_std_dyn=0.0,\n\t        f=1.0,  # focal length\n\t    ):\n", "        super().__init__(\n\t            n_obs=2,\n\t            n_state=2,\n\t            # We use first order ODE representation --> state is (angle, d/dt angle)\n\t            n_ctrl=None,  # skip ctrl for now\n\t            dt=dt,\n\t        )\n\t        self.g = g\n\t        self.mass = mass\n\t        self.dampening = dampening\n", "        self.cov_pendulum = cov_pendulum\n\t        self.noise_std_obs = noise_std_obs\n\t        self.noise_std_dyn = noise_std_dyn\n\t        self.center_pendulum = center_pendulum\n\t        # initial position of pendulum. last entry is the distance\n\t        # from the camera, assumed to\n\t        # have the same initial coordinate system,\n\t        # with just a translation in direction z.\n\t        self.r_rotation_pendulum = radius\n\t        self.f = f\n", "    def _stochastic_differential_equation(self, state, t):\n\t        w = np.random.normal(loc=0.0, scale=self.noise_std_dyn)\n\t        return np.array(\n\t            [\n\t                state[1],\n\t                -(\n\t                    (self.g / 2.0) * np.sin(state[0])\n\t                    + (self.dampening / self.mass) * state[1]\n\t                    + w\n\t                ),\n", "            ]\n\t        )\n\t    def enter(self):\n\t        self.state = np.zeros(self.n_state)\n\t        self.state[0] = np.pi + np.clip(np.random.randn(1), -2, 2) * 1.0\n\t        self.state[1] = np.clip(np.random.randn(1), -2, 2) * 4.0\n\t        self.t = 0.0\n\t    def transit(self, ctrl):\n\t        self.state, self.t = rungekutta4(\n\t            state=self.state,\n", "            t=self.t,\n\t            dt=self.dt,\n\t            f=self._stochastic_differential_equation,\n\t        )\n\t        return self.state, self.t\n\t    def observe(self, perspective):\n\t        pendulum_loc, _ = self.project_to_pixel_space(perspective=perspective)\n\t        pendulum_loc_noisy = pendulum_loc + np.random.normal(\n\t            loc=0, scale=self.noise_std_obs, size=pendulum_loc.shape\n\t        )\n", "        return pendulum_loc_noisy, pendulum_loc\n\t    def project_to_pixel_space(self, perspective):\n\t        \"\"\"\n\t        1) Rotate pendulum, represented as 3D normal distribution,\n\t        2) rotate Camera to some perspective with fixed distance to\n\t            center of pendulum rotation point,\n\t        3) project the scene into image space\n\t        4) and further into pixel space\n\t        This function works with homogenous coordinates (hom)\n\t        and assumes the initial camera location at (0, 0, 0).\n", "        The transformed covariance matrix is calculated by\n\t            transforming the vectors of variance directions.\n\t        :param angle: float, angle of pendulum, around z-axis\n\t        :param perspective: list or tuple of length 2,\n\t            rotation of camera arond x and y axis.\n\t        :return: 1D-array: pixel values of projected image\n\t        -------------------------------------------\n\t        Example:\n\t        dims_img = (16, 16, 1)\n\t        env = PendulumWithPerspectiveEnvironment(dims_img=dims_img)\n", "        env.enter()\n\t        for angle in np.linspace(0, 2 * np.pi, 20):\n\t            plt.cla()\n\t            obs = env.observe(\n\t                state=angle, perspective=[0, np.pi / 4]\n\t            ).reshape(dims_img[:2])\n\t            plt.imshow(obs, cmap='gray')\n\t            plt.pause(0.02)\n\t        \"\"\"\n\t        # 1) Rotate Pendulum around z-axis\n", "        angle = self.state[0]\n\t        M_pendulum = np.array(\n\t            [\n\t                [np.cos(angle), -np.sin(angle), 0, 0],\n\t                [np.sin(angle), np.cos(angle), 0, 0],\n\t                [0, 0, 1, 0],\n\t                [0, 0, 0, 1],\n\t            ]\n\t        )\n\t        mu_pendulum_hom = np.append(\n", "            self.center_pendulum - np.array([0, self.r_rotation_pendulum, 0]),\n\t            1,\n\t        )\n\t        cov_pendulum_hom = np.diag(np.append(self.cov_pendulum, 1))\n\t        mu_pendulum_rotated = M_pendulum.dot(mu_pendulum_hom)\n\t        cov_pendulum_rotated = M_pendulum.dot(cov_pendulum_hom).dot(M_pendulum.T)\n\t        # 2) Rotate Camera around pendulum center on x-axis and/or y-axis\n\t        x, y, z = self.center_pendulum\n\t        T_camera = np.array([[1, 0, 0, -x], [0, 1, 0, -y], [0, 0, 1, -z], [0, 0, 0, 1]])\n\t        inv_T_camera = np.array(\n", "            [[1, 0, 0, x], [0, 1, 0, y], [0, 0, 1, z], [0, 0, 0, 1]]\n\t        )\n\t        c = np.cos(perspective[0])\n\t        s = np.sin(perspective[0])\n\t        rx = np.array([[1, 0, 0, 0], [0, c, -s, 0], [0, s, c, 0], [0, 0, 0, 1]])\n\t        c = np.cos(perspective[1])\n\t        s = np.sin(perspective[1])\n\t        ry = np.array([[c, 0, s, 0], [0, 1, 0, 0], [-s, 0, c, 0], [0, 0, 0, 1]])\n\t        R_camera = rx.dot(\n\t            ry\n", "        )  # rotation around center of camera, first rotate around y, then x.\n\t        M_camera = inv_T_camera.dot(R_camera).dot(\n\t            T_camera\n\t        )  # rotation around center of pendulum\n\t        # To rotate the mean, need to project it first to origin,\n\t        # then rotate, then project back\n\t        mu_pendulum_camera = M_camera.dot(mu_pendulum_rotated)\n\t        # The vectors for cov-matrix are already vectors\n\t        # w.r.t. origin, no need to translate\n\t        cov_pendulum_camera = R_camera.dot(cov_pendulum_rotated).dot(R_camera.T)\n", "        # 3) Project 3D coordinates of mu and cov vector\n\t        # into image-space, using focal length of camera\n\t        f = self.f\n\t        F = np.array([[f, 0, 0, 0], [0, f, 0, 0], [0, 0, 1, 0]])\n\t        mu_pendulum_projected = np.dot(F, mu_pendulum_camera)\n\t        cov_pendulum_projected = np.dot(F, cov_pendulum_camera).dot(F.T)\n\t        # 4) Transform to Pixel coordinates\n\t        M_pixel = np.array(\n\t            [\n\t                [1 / mu_pendulum_projected[-1], 0, 0],\n", "                [0, 1 / mu_pendulum_projected[-1], 0],\n\t            ]\n\t        )\n\t        mu_pendulum_pixel = M_pixel.dot(mu_pendulum_projected)\n\t        cov_pendulum_pixel = M_pixel.dot(cov_pendulum_projected).dot(M_pixel.T)\n\t        return mu_pendulum_pixel, cov_pendulum_pixel\n\tdef generate_dataset(\n\t    seed=42,\n\t    dataset_path=None,\n\t    n_train=5000,\n", "    n_val=1000,\n\t    n_test=1000,\n\t    n_timesteps=150,\n\t    perspective=(0.0, 0.0),\n\t):\n\t    if dataset_path is None:\n\t        dataset_path = \"./damped_pendulum/\"\n\t    os.makedirs(dataset_path, exist_ok=True)\n\t    def generate_sequence(n_timesteps_obs, n_steps_sim_per_obs=10, dt_sim=0.01):\n\t        assert isinstance(n_steps_sim_per_obs, int) and n_steps_sim_per_obs > 0\n", "        env = Pendulum3DCoordEnvironment(dt=dt_sim)\n\t        env.enter()\n\t        observations = []\n\t        observations_gt = []\n\t        states = []\n\t        for t_obs in range(n_timesteps_obs):\n\t            obs, obs_gt = env.observe(perspective=perspective)\n\t            observations.append(obs)\n\t            observations_gt.append(obs_gt)\n\t            states.append(env.state)\n", "            for t_sim in range(n_steps_sim_per_obs):\n\t                env.transit(ctrl=None)\n\t        observations = np.stack(observations, axis=0)\n\t        observations_gt = np.stack(observations_gt, axis=0)\n\t        states = np.stack(states, axis=0)\n\t        return observations, observations_gt, states\n\t    def generate_dataset(n_data, n_timesteps):\n\t        observations_dataset = []\n\t        observations_gt_dataset = []\n\t        states_dataset = []\n", "        for idx_sample in range(n_data):\n\t            if idx_sample % 100 == 0:\n\t                print(f\"sequence {idx_sample}/{n_data}\")\n\t            observations, observations_gt, states = generate_sequence(\n\t                n_timesteps_obs=n_timesteps\n\t            )\n\t            observations_dataset.append(observations)\n\t            observations_gt_dataset.append(observations_gt)\n\t            states_dataset.append(states)\n\t        observations_dataset = np.stack(observations_dataset, axis=0)\n", "        observations_gt_dataset = np.stack(observations_gt_dataset, axis=0)\n\t        states_dataset = np.stack(states_dataset, axis=0)\n\t        return observations_dataset, observations_gt_dataset, states_dataset\n\t    with local_seed(seed=seed):\n\t        (\n\t            observations_train,\n\t            observations_gt_train,\n\t            states_train,\n\t        ) = generate_dataset(n_data=n_train, n_timesteps=n_timesteps)\n\t        (\n", "            observations_val,\n\t            observations_gt_val,\n\t            states_val,\n\t        ) = generate_dataset(n_data=n_val, n_timesteps=n_timesteps)\n\t        (\n\t            observations_test,\n\t            observations_gt_test,\n\t            states_test,\n\t        ) = generate_dataset(n_data=n_test, n_timesteps=n_timesteps)\n\t    np.savez(\n", "        os.path.join(dataset_path, \"train.npz\"),\n\t        obs=observations_train,\n\t        obs_gt=observations_gt_train,\n\t        state=states_train,\n\t    )\n\t    np.savez(\n\t        os.path.join(dataset_path, \"val.npz\"),\n\t        obs=observations_val,\n\t        obs_gt=observations_gt_val,\n\t        state=states_val,\n", "    )\n\t    np.savez(\n\t        os.path.join(dataset_path, \"test.npz\"),\n\t        obs=observations_test,\n\t        obs_gt=observations_gt_test,\n\t        state=states_test,\n\t    )\n\tif __name__ == \"__main__\":\n\t    data_path = str(Path(__file__).resolve().parent / \"damped_pendulum\")\n\t    print(f\"Saving dataset to: {data_path}.\")\n", "    generate_dataset(dataset_path=data_path)\n"]}
{"filename": "experiments/utils.py", "chunked_list": ["import re\n\tfrom argparse import ArgumentParser, ArgumentTypeError\n\tfrom torch import nn\n\timport yaml\n\timport os\n\tfrom datetime import datetime\n\tfrom ncdssm.type import Dict\n\tdef get_config_and_setup_dirs(filename: str = \"config.yaml\"):\n\t    with open(filename, \"r\") as fp:\n\t        config = yaml.load(fp, Loader=yaml.Loader)\n", "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n\t    config[\"exp_root_dir\"] = config[\"exp_root_dir\"].format(\n\t        model=config[\"model\"].lower(),\n\t        dataset=config[\"dataset\"].lower(),\n\t        timestamp=timestamp,\n\t    )\n\t    config[\"log_dir\"] = os.path.join(config[\"exp_root_dir\"], \"logs\")\n\t    config[\"ckpt_dir\"] = os.path.join(config[\"exp_root_dir\"], \"ckpts\")\n\t    os.makedirs(config[\"log_dir\"])\n\t    os.makedirs(config[\"ckpt_dir\"])\n", "    return config\n\tdef str2bool(v):\n\t    if isinstance(v, bool):\n\t        return v\n\t    if v.lower() in (\"yes\", \"true\", \"t\", \"y\", \"1\"):\n\t        return True\n\t    elif v.lower() in (\"no\", \"false\", \"f\", \"n\", \"0\"):\n\t        return False\n\t    else:\n\t        raise ArgumentTypeError(\"Boolean value expected.\")\n", "def add_config_to_argparser(config: Dict, parser: ArgumentParser):\n\t    for k, v in config.items():\n\t        sanitized_key = re.sub(r\"[^\\w\\-]\", \"\", k).replace(\"-\", \"_\")\n\t        val_type = type(v)\n\t        if val_type not in {int, float, str, bool}:\n\t            print(f\"WARNING: Skipping key {k}!\")\n\t            continue\n\t        if val_type == bool:\n\t            parser.add_argument(f\"--{sanitized_key}\", type=str2bool, default=v)\n\t        else:\n", "            parser.add_argument(f\"--{sanitized_key}\", type=val_type, default=v)\n\t    return parser\n\tdef get_activation(name: str) -> nn.Module:\n\t    name = name.lower()\n\t    if name == \"tanh\":\n\t        return nn.Tanh\n\t    elif name == \"softplus\":\n\t        return nn.Softplus\n\t    elif name == \"relu\":\n\t        return nn.ReLU\n", "    elif name == \"softmax\":\n\t        return nn.Softmax\n\t    else:\n\t        raise ValueError(f\"Unknown non-linearity {name}\")\n\tclass LinearScheduler(object):\n\t    def __init__(self, iters, maxval=1.0):\n\t        self._iters = max(1, iters)\n\t        self._val = maxval / self._iters\n\t        self._maxval = maxval\n\t    def step(self):\n", "        self._val = min(self._maxval, self._val + self._maxval / self._iters)\n\t    @property\n\t    def val(self):\n\t        return self._val\n"]}
{"filename": "experiments/setups/pendulum.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom ncdssm.models import NCDSSMLTI, NCDSSMLL, NCDSSMNL\n\tfrom ncdssm.modules import MLP\n\tfrom ncdssm.models.components import AuxInferenceModel, GaussianOutput\n\tfrom ..utils import get_activation\n\tdef build_model(config):\n\t    if config[\"model\"] == \"NCDSSMLTI\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n", "            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n", "        )\n\t        y_emission_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=True,\n\t            use_independent=False,\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLTI(\n", "            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n", "    elif config[\"model\"] == \"NCDSSMLL\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n", "            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=True,\n\t            use_independent=False,\n", "        )\n\t        alpha_net = nn.Sequential(\n\t            MLP(\n\t                in_dim=config[\"z_dim\"],\n\t                h_dim=config[\"alpha_mlp_units\"],\n\t                out_dim=config[\"K\"],\n\t                nonlinearity=get_activation(config[\"alpha_nonlinearity\"]),\n\t                n_hidden_layers=config[\"alpha_hidden_layers\"],\n\t            ),\n\t            nn.Softmax(dim=-1),\n", "        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLL(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            K=config[\"K\"],\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n", "            alpha_net=alpha_net,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    elif config[\"model\"] == \"NCDSSMNL\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n", "            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = GaussianOutput(\n", "            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=True,\n\t            use_independent=False,\n\t        )\n\t        non_linear_drift_func = MLP(\n\t            in_dim=config[\"z_dim\"],\n\t            h_dim=config[\"drift_mlp_units\"],\n\t            out_dim=config[\"z_dim\"],\n", "            nonlinearity=get_activation(config[\"drift_nonlinearity\"]),\n\t            last_nonlinearity=config[\"drift_last_nonlinearity\"],\n\t            n_hidden_layers=config[\"drift_hidden_layers\"],\n\t            zero_init_last=config[\"drift_zero_init_last\"],\n\t            apply_spectral_norm=config[\"drift_spectral_norm\"],\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMNL(\n\t            aux_inference_net,\n\t            y_emission_net,\n", "            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            f=non_linear_drift_func,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    else:\n", "        raise ValueError(f'Unknown model {config[\"model\"]}')\n\t    return model\n"]}
{"filename": "experiments/setups/mocap.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom ncdssm.models import NCDSSMLTI, NCDSSMLL, NCDSSMNL\n\tfrom ncdssm.modules import MLP\n\tfrom ncdssm.models.components import AuxInferenceModel, GaussianOutput\n\tfrom ..utils import get_activation\n\tdef build_model(config):\n\t    if config[\"model\"] == \"NCDSSMLTI\":\n\t        aux_inf_in_dim = config[\"y_dim\"]\n\t        aux_inf_base_net = MLP(\n", "            in_dim=aux_inf_in_dim,\n\t            h_dim=config[\"inference_mlp_units\"],\n\t            out_dim=config[\"inference_mlp_units\"],\n\t            nonlinearity=get_activation(config[\"inference_nonlinearity\"]),\n\t            last_nonlinearity=True,\n\t        )\n\t        inf_out_dim = (\n\t            config[\"aux_dim\"] if config[\"inference_tied_cov\"] else 2 * config[\"aux_dim\"]\n\t        )\n\t        aux_inf_dist_net = GaussianOutput(\n", "            nn.Linear(aux_inf_base_net.out_dim, inf_out_dim),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=config[\"inference_tied_cov\"],\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n", "        )\n\t        decoder_out_dim = (\n\t            config[\"y_dim\"] if config[\"emission_tied_cov\"] else 2 * config[\"y_dim\"]\n\t        )\n\t        y_emission_net = GaussianOutput(\n\t            MLP(\n\t                in_dim=config[\"aux_dim\"],\n\t                h_dim=config[\"emission_mlp_units\"],\n\t                out_dim=decoder_out_dim,\n\t                nonlinearity=get_activation(config[\"emission_nonlinearity\"]),\n", "                n_hidden_layers=config[\"emission_hidden_layers\"],\n\t            ),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=config[\"emission_tied_cov\"],\n\t            use_trainable_cov=config[\"emission_trainable_cov\"],\n\t            use_independent=False,\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLTI(\n\t            aux_inference_net,\n", "            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    elif config[\"model\"] == \"NCDSSMLL\":\n", "        aux_inf_in_dim = config[\"y_dim\"]\n\t        aux_inf_base_net = MLP(\n\t            in_dim=aux_inf_in_dim,\n\t            h_dim=config[\"inference_mlp_units\"],\n\t            out_dim=config[\"inference_mlp_units\"],\n\t            nonlinearity=get_activation(config[\"inference_nonlinearity\"]),\n\t            last_nonlinearity=True,\n\t        )\n\t        inf_out_dim = (\n\t            config[\"aux_dim\"] if config[\"inference_tied_cov\"] else 2 * config[\"aux_dim\"]\n", "        )\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Linear(aux_inf_base_net.out_dim, inf_out_dim),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=config[\"inference_tied_cov\"],\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n", "            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        decoder_out_dim = (\n\t            config[\"y_dim\"] if config[\"emission_tied_cov\"] else 2 * config[\"y_dim\"]\n\t        )\n\t        y_emission_net = GaussianOutput(\n\t            MLP(\n\t                in_dim=config[\"aux_dim\"],\n\t                h_dim=config[\"emission_mlp_units\"],\n", "                out_dim=decoder_out_dim,\n\t                nonlinearity=get_activation(config[\"emission_nonlinearity\"]),\n\t                n_hidden_layers=config[\"emission_hidden_layers\"],\n\t            ),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=config[\"emission_tied_cov\"],\n\t            use_trainable_cov=config[\"emission_trainable_cov\"],\n\t            use_independent=False,\n\t        )\n\t        alpha_net = nn.Sequential(\n", "            MLP(\n\t                in_dim=config[\"z_dim\"],\n\t                h_dim=config[\"alpha_mlp_units\"],\n\t                out_dim=config[\"K\"],\n\t                nonlinearity=get_activation(config[\"alpha_nonlinearity\"]),\n\t                n_hidden_layers=config[\"alpha_hidden_layers\"],\n\t            ),\n\t            nn.Softmax(dim=-1),\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n", "        model = NCDSSMLL(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            K=config[\"K\"],\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            alpha_net=alpha_net,\n\t            integration_step_size=config[\"integration_step_size\"],\n", "            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    elif config[\"model\"] == \"NCDSSMNL\":\n\t        aux_inf_in_dim = config[\"y_dim\"]\n\t        aux_inf_base_net = MLP(\n\t            in_dim=aux_inf_in_dim,\n\t            h_dim=config[\"inference_mlp_units\"],\n\t            out_dim=config[\"inference_mlp_units\"],\n\t            nonlinearity=get_activation(config[\"inference_nonlinearity\"]),\n", "            last_nonlinearity=True,\n\t        )\n\t        inf_out_dim = (\n\t            config[\"aux_dim\"] if config[\"inference_tied_cov\"] else 2 * config[\"aux_dim\"]\n\t        )\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Linear(aux_inf_base_net.out_dim, inf_out_dim),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=config[\"inference_tied_cov\"],\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n", "        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        decoder_out_dim = (\n\t            config[\"y_dim\"] if config[\"emission_tied_cov\"] else 2 * config[\"y_dim\"]\n\t        )\n", "        y_emission_net = GaussianOutput(\n\t            MLP(\n\t                in_dim=config[\"aux_dim\"],\n\t                h_dim=config[\"emission_mlp_units\"],\n\t                out_dim=decoder_out_dim,\n\t                nonlinearity=get_activation(config[\"emission_nonlinearity\"]),\n\t                n_hidden_layers=config[\"emission_hidden_layers\"],\n\t            ),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=config[\"emission_tied_cov\"],\n", "            use_trainable_cov=config[\"emission_trainable_cov\"],\n\t            use_independent=False,\n\t        )\n\t        drift_net = MLP(\n\t            in_dim=config[\"z_dim\"],\n\t            h_dim=config[\"drift_mlp_units\"],\n\t            out_dim=config[\"z_dim\"],\n\t            nonlinearity=get_activation(config[\"drift_nonlinearity\"]),\n\t            last_nonlinearity=config[\"drift_last_nonlinearity\"],\n\t            n_hidden_layers=config[\"drift_hidden_layers\"],\n", "            zero_init_last=config[\"drift_zero_init_last\"],\n\t            apply_spectral_norm=config[\"drift_spectral_norm\"],\n\t        )\n\t        diffusion_nets = None\n\t        if not config[\"fixed_diffusion\"]:\n\t            diffusion_nets = [\n\t                nn.Sequential(\n\t                    MLP(\n\t                        in_dim=1,\n\t                        h_dim=config[\"diffusion_mlp_units\"],\n", "                        out_dim=1,\n\t                        nonlinearity=get_activation(config[\"diffusion_nonlinearity\"]),\n\t                        n_hidden_layers=config[\"diffusion_hidden_layers\"],\n\t                        apply_spectral_norm=config[\"diffusion_spectral_norm\"],\n\t                    ),\n\t                    nn.Sigmoid(),\n\t                )\n\t                for _ in range(config[\"z_dim\"])\n\t            ]\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n", "        model = NCDSSMNL(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            f=drift_net,\n\t            gs=diffusion_nets,\n\t            integration_step_size=config[\"integration_step_size\"],\n", "            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    else:\n\t        raise ValueError(f'Unknown model {config[\"model\"]}')\n\t    return model\n"]}
{"filename": "experiments/setups/__init__.py", "chunked_list": ["from pathlib import Path\n\timport numpy as np\n\tfrom ncdssm.type import Dict\n\tDATA_ROOT = Path(__file__).resolve().parent.parent.parent / \"data\"\n\tdef get_model(config):\n\t    if config[\"dataset\"] == \"mocap\" or config[\"dataset\"] == \"mocap2\":\n\t        from .mocap import build_model\n\t    elif config[\"dataset\"] == \"bouncing_ball\":\n\t        from .bouncing_ball import build_model\n\t    elif config[\"dataset\"] == \"damped_pendulum\":\n", "        from .pendulum import build_model\n\t    elif config[\"dataset\"] in {\"box\", \"pong\"}:\n\t        from .pymunk import build_model\n\t    elif config[\"dataset\"] == \"climate\":\n\t        from .climate import build_model\n\t    else:\n\t        raise ValueError(f\"Unknown dataset {config['dataset']}\")\n\t    return build_model(config=config)\n\tdef get_dataset(config: Dict):\n\t    from ncdssm.datasets import (\n", "        PymunkDataset,\n\t        MocapDataset,\n\t        BouncingBallDataset,\n\t        DampedPendulumDataset,\n\t        ClimateDataset,\n\t    )\n\t    dataset_name = config[\"dataset\"]\n\t    if dataset_name == \"mocap\":\n\t        train_dataset = MocapDataset(\n\t            file_path=DATA_ROOT / \"mocap/mocap35.mat\",\n", "            mode=\"train\",\n\t            ctx_len=300,\n\t            pred_len=0,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n\t        val_dataset = MocapDataset(\n\t            file_path=DATA_ROOT / \"mocap/mocap35.mat\",\n\t            mode=\"val\",\n\t            ctx_len=3,\n\t            pred_len=297,\n", "        )\n\t        test_dataset = MocapDataset(\n\t            file_path=DATA_ROOT / \"mocap/mocap35.mat\",\n\t            mode=\"test\",\n\t            ctx_len=3,\n\t            pred_len=297,\n\t        )\n\t    elif dataset_name == \"mocap2\":\n\t        train_dataset = MocapDataset(\n\t            file_path=DATA_ROOT / \"mocap/mocap35.mat\",\n", "            mode=\"train\",\n\t            ctx_len=200,\n\t            pred_len=100,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n\t        val_dataset = MocapDataset(\n\t            file_path=DATA_ROOT / \"mocap/mocap35.mat\",\n\t            mode=\"val\",\n\t            ctx_len=100,\n\t            pred_len=200,\n", "        )\n\t        test_dataset = MocapDataset(\n\t            file_path=DATA_ROOT / \"mocap/mocap35.mat\",\n\t            mode=\"test\",\n\t            ctx_len=100,\n\t            pred_len=200,\n\t        )\n\t    elif dataset_name == \"bouncing_ball\":\n\t        train_dataset = BouncingBallDataset(\n\t            path=DATA_ROOT / \"bouncing_ball/rv_train.npz\",\n", "            ctx_len=100,\n\t            pred_len=200,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n\t        val_dataset = BouncingBallDataset(\n\t            path=DATA_ROOT / \"bouncing_ball/rv_val.npz\",\n\t            ctx_len=100,\n\t            pred_len=200,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n", "        test_dataset = BouncingBallDataset(\n\t            path=DATA_ROOT / \"bouncing_ball/rv_test.npz\",\n\t            ctx_len=100,\n\t            pred_len=200,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n\t    elif dataset_name == \"damped_pendulum\":\n\t        train_dataset = DampedPendulumDataset(\n\t            path=DATA_ROOT / \"damped_pendulum/train.npz\",\n\t            ctx_len=50,\n", "            pred_len=100,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n\t        val_dataset = DampedPendulumDataset(\n\t            path=DATA_ROOT / \"damped_pendulum/val.npz\",\n\t            ctx_len=50,\n\t            pred_len=100,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n\t        test_dataset = DampedPendulumDataset(\n", "            path=DATA_ROOT / \"damped_pendulum/test.npz\",\n\t            ctx_len=50,\n\t            pred_len=100,\n\t            missing_p=config[\"train_missing_p\"],\n\t        )\n\t    elif dataset_name == \"climate\":\n\t        csv_path = DATA_ROOT / \"climate/climate-data-preproc.csv\"\n\t        fold_idx = config[\"data_fold\"]\n\t        train_idx = np.load(DATA_ROOT / f\"climate/fold_idx_{fold_idx}/train_idx.npy\")\n\t        val_idx = np.load(DATA_ROOT / f\"climate/fold_idx_{fold_idx}/val_idx.npy\")\n", "        test_idx = np.load(DATA_ROOT / f\"climate/fold_idx_{fold_idx}/test_idx.npy\")\n\t        train_dataset = ClimateDataset(\n\t            csv_path=csv_path,\n\t            train=True,\n\t            ids=train_idx,\n\t        )\n\t        val_dataset = ClimateDataset(\n\t            csv_path=csv_path,\n\t            train=False,\n\t            ids=val_idx,\n", "            val_options=dict(T_val=150, forecast_steps=3),\n\t        )\n\t        test_dataset = ClimateDataset(\n\t            csv_path=csv_path,\n\t            train=False,\n\t            ids=test_idx,\n\t            val_options=dict(T_val=150, forecast_steps=3),\n\t        )\n\t    elif dataset_name in {\"pong\", \"box\"}:\n\t        data_root = DATA_ROOT / f\"pymunk/{dataset_name}\"\n", "        train_dataset = PymunkDataset(\n\t            file_path=data_root / \"train.npz\",\n\t            missing_p=config[\"train_missing_p\"],\n\t            train=True,\n\t        )\n\t        val_dataset = PymunkDataset(\n\t            file_path=data_root / \"val.npz\",\n\t            missing_p=config[\"train_missing_p\"],\n\t            train=False,\n\t        )\n", "        test_dataset = PymunkDataset(\n\t            file_path=data_root / \"test.npz\",\n\t            missing_p=config[\"train_missing_p\"],\n\t            train=False,\n\t        )\n\t    else:\n\t        raise ValueError(f\"Unknown dataset {dataset_name}!\")\n\t    return train_dataset, val_dataset, test_dataset\n"]}
{"filename": "experiments/setups/pymunk.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom ncdssm.models import NCDSSMLTI, NCDSSMLL, NCDSSMNL\n\tfrom ncdssm.modules import MLP, ImageEncoder, ImageDecoder, MergeLastDims\n\tfrom ncdssm.models.components import AuxInferenceModel, GaussianOutput, BernoulliOutput\n\tfrom ..utils import get_activation\n\tdef build_model(config):\n\t    if config[\"model\"] == \"NCDSSMLTI\":\n\t        aux_inf_base_net = ImageEncoder(\n\t            img_size=config[\"img_size\"],\n", "            channels=1,\n\t            out_dim=config[\"inference_img_enc_dim\"],\n\t        )\n\t        inf_out_dim = (\n\t            config[\"aux_dim\"] if config[\"inference_tied_cov\"] else 2 * config[\"aux_dim\"]\n\t        )\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Linear(aux_inf_base_net.out_dim, inf_out_dim),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=config[\"inference_tied_cov\"],\n", "            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = BernoulliOutput(\n\t            nn.Sequential(\n", "                ImageDecoder(\n\t                    in_dim=config[\"aux_dim\"],\n\t                    img_size=config[\"img_size\"],\n\t                    channels=1,\n\t                ),\n\t                MergeLastDims(ndims=3),\n\t            ),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_indepedent=False,\n\t        )\n", "        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLTI(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n", "            H=H,\n\t        )\n\t    elif config[\"model\"] == \"NCDSSMLL\":\n\t        aux_inf_base_net = ImageEncoder(\n\t            img_size=config[\"img_size\"],\n\t            channels=1,\n\t            out_dim=config[\"inference_img_enc_dim\"],\n\t        )\n\t        inf_out_dim = (\n\t            config[\"aux_dim\"] if config[\"inference_tied_cov\"] else 2 * config[\"aux_dim\"]\n", "        )\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Linear(aux_inf_base_net.out_dim, inf_out_dim),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=config[\"inference_tied_cov\"],\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n", "            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = BernoulliOutput(\n\t            nn.Sequential(\n\t                ImageDecoder(\n\t                    in_dim=config[\"aux_dim\"],\n\t                    img_size=config[\"img_size\"],\n\t                    channels=1,\n\t                ),\n", "                MergeLastDims(ndims=3),\n\t            ),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_indepedent=False,\n\t        )\n\t        alpha_net = nn.Sequential(\n\t            MLP(\n\t                in_dim=config[\"z_dim\"],\n\t                h_dim=config[\"alpha_mlp_units\"],\n\t                out_dim=config[\"K\"],\n", "                nonlinearity=get_activation(config[\"alpha_nonlinearity\"]),\n\t                n_hidden_layers=config[\"alpha_hidden_layers\"],\n\t            ),\n\t            nn.Softmax(dim=-1),\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLL(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            K=config[\"K\"],\n", "            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            alpha_net=alpha_net,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    elif config[\"model\"] == \"NCDSSMNL\":\n", "        aux_inf_base_net = ImageEncoder(\n\t            img_size=config[\"img_size\"],\n\t            channels=1,\n\t            out_dim=config[\"inference_img_enc_dim\"],\n\t        )\n\t        inf_out_dim = (\n\t            config[\"aux_dim\"] if config[\"inference_tied_cov\"] else 2 * config[\"aux_dim\"]\n\t        )\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Linear(aux_inf_base_net.out_dim, inf_out_dim),\n", "            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=config[\"inference_tied_cov\"],\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n", "        y_emission_net = BernoulliOutput(\n\t            nn.Sequential(\n\t                ImageDecoder(\n\t                    in_dim=config[\"aux_dim\"],\n\t                    img_size=config[\"img_size\"],\n\t                    channels=1,\n\t                ),\n\t                MergeLastDims(ndims=3),\n\t            ),\n\t            dist_dim=config[\"y_dim\"],\n", "            use_indepedent=False,\n\t        )\n\t        drift_net = MLP(\n\t            in_dim=config[\"z_dim\"],\n\t            h_dim=config[\"drift_mlp_units\"],\n\t            out_dim=config[\"z_dim\"],\n\t            nonlinearity=get_activation(config[\"drift_nonlinearity\"]),\n\t            last_nonlinearity=config[\"drift_last_nonlinearity\"],\n\t            n_hidden_layers=config[\"drift_hidden_layers\"],\n\t            zero_init_last=config[\"drift_zero_init_last\"],\n", "            apply_spectral_norm=config[\"drift_spectral_norm\"],\n\t        )\n\t        diffusion_nets = None\n\t        if not config[\"fixed_diffusion\"]:\n\t            diffusion_nets = [\n\t                nn.Sequential(\n\t                    MLP(\n\t                        in_dim=1,\n\t                        h_dim=config[\"diffusion_mlp_units\"],\n\t                        out_dim=1,\n", "                        nonlinearity=get_activation(config[\"diffusion_nonlinearity\"]),\n\t                        n_hidden_layers=config[\"diffusion_hidden_layers\"],\n\t                        apply_spectral_norm=config[\"diffusion_spectral_norm\"],\n\t                    ),\n\t                    nn.Sigmoid(),\n\t                )\n\t                for _ in range(config[\"z_dim\"])\n\t            ]\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMNL(\n", "            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            f=drift_net,\n\t            gs=diffusion_nets,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n", "            H=H,\n\t        )\n\t    else:\n\t        raise ValueError(f'Unknown model {config[\"model\"]}')\n\t    return model\n"]}
{"filename": "experiments/setups/climate.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom ncdssm.models import NCDSSMLTI, NCDSSMLL, NCDSSMNL\n\tfrom ncdssm.modules import MLP\n\tfrom ncdssm.models.components import AuxInferenceModel, GaussianOutput\n\tfrom ..utils import get_activation\n\tdef build_model(config):\n\t    if config[\"model\"] == \"NCDSSMLTI\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n", "            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t            sigma=1e-4,\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n", "            concat_mask=False,\n\t        )\n\t        y_emission_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"emission_trainable_cov\"],\n\t            use_independent=False,\n\t            sigma=1e-4,\n\t        )\n", "        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLTI(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n", "            H=H,\n\t            sporadic=True,\n\t        )\n\t    elif config[\"model\"] == \"NCDSSMLL\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n", "            sigma=1e-4,\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = GaussianOutput(\n\t            nn.Identity(),\n", "            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"emission_trainable_cov\"],\n\t            use_independent=False,\n\t            sigma=1e-4,\n\t        )\n\t        alpha_net = nn.Sequential(\n\t            MLP(\n\t                in_dim=config[\"z_dim\"],\n\t                h_dim=config[\"alpha_mlp_units\"],\n", "                out_dim=config[\"K\"],\n\t                nonlinearity=get_activation(config[\"alpha_nonlinearity\"]),\n\t                n_hidden_layers=config[\"alpha_hidden_layers\"],\n\t            ),\n\t            nn.Softmax(dim=-1),\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLL(\n\t            aux_inference_net,\n\t            y_emission_net,\n", "            K=config[\"K\"],\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            alpha_net=alpha_net,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t            sporadic=True,\n", "        )\n\t    elif config[\"model\"] == \"NCDSSMNL\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t            sigma=1e-4,\n\t        )\n", "        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n", "            use_trainable_cov=config[\"emission_trainable_cov\"],\n\t            use_independent=False,\n\t            sigma=1e-4,\n\t        )\n\t        non_linear_drift_func = MLP(\n\t            in_dim=config[\"z_dim\"],\n\t            h_dim=config[\"drift_mlp_units\"],\n\t            out_dim=config[\"z_dim\"],\n\t            nonlinearity=get_activation(config[\"drift_nonlinearity\"]),\n\t            last_nonlinearity=config[\"drift_last_nonlinearity\"],\n", "            n_hidden_layers=config[\"drift_hidden_layers\"],\n\t            zero_init_last=config[\"drift_zero_init_last\"],\n\t            apply_spectral_norm=config[\"drift_spectral_norm\"],\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMNL(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n", "            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            f=non_linear_drift_func,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t            sporadic=True,\n\t        )\n\t    else:\n\t        raise ValueError(f'Unknown model {config[\"model\"]}')\n", "    return model\n"]}
{"filename": "experiments/setups/bouncing_ball.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom ncdssm.models import NCDSSMLTI, NCDSSMLL, NCDSSMNL\n\tfrom ncdssm.modules import MLP\n\tfrom ncdssm.models.components import AuxInferenceModel, GaussianOutput\n\tfrom ..utils import get_activation\n\tdef build_model(config):\n\t    if config[\"model\"] == \"NCDSSMLTI\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n", "            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n", "        )\n\t        y_emission_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=True,\n\t            use_independent=False,\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLTI(\n", "            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n", "    elif config[\"model\"] == \"NCDSSMLL\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n", "            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=True,\n\t            use_independent=False,\n", "        )\n\t        alpha_net = nn.Sequential(\n\t            MLP(\n\t                in_dim=config[\"z_dim\"],\n\t                h_dim=config[\"alpha_mlp_units\"],\n\t                out_dim=config[\"K\"],\n\t                nonlinearity=get_activation(config[\"alpha_nonlinearity\"]),\n\t                n_hidden_layers=config[\"alpha_hidden_layers\"],\n\t            ),\n\t            nn.Softmax(dim=-1),\n", "        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMLL(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            K=config[\"K\"],\n\t            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n", "            alpha_net=alpha_net,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    elif config[\"model\"] == \"NCDSSMNL\":\n\t        aux_inf_base_net = nn.Identity()\n\t        aux_inf_dist_net = GaussianOutput(\n\t            nn.Identity(),\n\t            dist_dim=config[\"aux_dim\"],\n", "            use_tied_cov=True,\n\t            use_trainable_cov=config[\"inference_trainable_cov\"],\n\t        )\n\t        aux_inference_net = AuxInferenceModel(\n\t            aux_inf_base_net,\n\t            aux_inf_dist_net,\n\t            aux_dim=config[\"aux_dim\"],\n\t            concat_mask=False,\n\t        )\n\t        y_emission_net = GaussianOutput(\n", "            nn.Identity(),\n\t            dist_dim=config[\"y_dim\"],\n\t            use_tied_cov=True,\n\t            use_trainable_cov=True,\n\t            use_independent=False,\n\t        )\n\t        non_linear_drift_func = MLP(\n\t            in_dim=config[\"z_dim\"],\n\t            h_dim=config[\"drift_mlp_units\"],\n\t            out_dim=config[\"z_dim\"],\n", "            nonlinearity=get_activation(config[\"drift_nonlinearity\"]),\n\t            last_nonlinearity=config[\"drift_last_nonlinearity\"],\n\t            n_hidden_layers=config[\"drift_hidden_layers\"],\n\t            zero_init_last=config[\"drift_zero_init_last\"],\n\t            apply_spectral_norm=config[\"drift_spectral_norm\"],\n\t        )\n\t        H = torch.eye(config[\"aux_dim\"], config[\"z_dim\"]) if config[\"fixed_H\"] else None\n\t        model = NCDSSMNL(\n\t            aux_inference_net,\n\t            y_emission_net,\n", "            aux_dim=config[\"aux_dim\"],\n\t            z_dim=config[\"z_dim\"],\n\t            y_dim=config[\"y_dim\"],\n\t            u_dim=config[\"u_dim\"],\n\t            f=non_linear_drift_func,\n\t            integration_step_size=config[\"integration_step_size\"],\n\t            integration_method=config[\"integration_method\"],\n\t            H=H,\n\t        )\n\t    else:\n", "        raise ValueError(f'Unknown model {config[\"model\"]}')\n\t    return model\n"]}
{"filename": "src/ncdssm/torch_utils.py", "chunked_list": ["import torch\n\timport numpy as np\n\tfrom .functions import bm_t\n\tfrom .type import Tensor\n\tdef merge_leading_dims(tensor, ndims=1):\n\t    assert ndims <= tensor.ndim\n\t    shape = tensor.size()\n\t    lead_dim_size = np.prod(shape[:ndims])\n\t    tensor = tensor.view(lead_dim_size, *shape[ndims:])\n\t    return tensor\n", "def torch2numpy(tensor):\n\t    return tensor.data.cpu().numpy()\n\tdef grad_norm(parameters):\n\t    parameters = [p for p in parameters if p.grad is not None]\n\t    device = parameters[0].grad.device\n\t    total_norm = torch.norm(\n\t        torch.stack([torch.norm(p.grad.detach(), 2).to(device) for p in parameters]), 2\n\t    )\n\t    return total_norm\n\tdef prepend_time_zero(times: Tensor, target: Tensor, mask: Tensor):\n", "    \"\"\"Prepends t = 0 to the batch\n\t    Args:\n\t        times (Tensor): 1D Tensor of times without t = 0 as the first time\n\t        target (Tensor): B x T x D Tensor\n\t        mask (Tensor): Mask\n\t    \"\"\"\n\t    B, _, D = target.size()\n\t    times = torch.cat(\n\t        [torch.zeros([1], device=times.device), times],\n\t        dim=0,\n", "    )\n\t    target = torch.cat(\n\t        [\n\t            torch.zeros((B, 1, D), device=target.device),\n\t            target,\n\t        ],\n\t        dim=1,\n\t    )\n\t    if mask.ndim == 3:\n\t        mask = torch.cat([torch.zeros((B, 1, D), device=mask.device), mask], dim=1)\n", "    else:\n\t        mask = torch.cat([torch.zeros((B, 1), device=mask.device), mask], dim=1)\n\t    return times, target, mask\n\tdef skew_symmetric_init_(tensor, gain=1):\n\t    if tensor.ndim not in {2, 3}:\n\t        raise ValueError(\"Only tensors with 2 or 3 dimensions are supported\")\n\t    rand_matrix = torch.rand_like(tensor)\n\t    if tensor.ndim == 2:\n\t        rand_matrix.unsqueeze_(0)\n\t    skew_symm_matrix = (rand_matrix - bm_t(rand_matrix)) / 2\n", "    with torch.no_grad():\n\t        tensor.view_as(skew_symm_matrix).copy_(skew_symm_matrix)\n\t        tensor.mul_(gain)\n\t    return tensor\n"]}
{"filename": "src/ncdssm/evaluation.py", "chunked_list": ["import ot\n\timport torch\n\timport scipy\n\timport numpy as np\n\timport multiprocessing\n\tfrom tqdm.auto import tqdm\n\tfrom .torch_utils import torch2numpy\n\tdef student_t_conf_interval(samples, confidence_level=0.95, axis=0):\n\t    deg_free = samples.shape[axis] - 1\n\t    mean = np.mean(samples, axis=axis)\n", "    str_err = scipy.stats.sem(samples, axis=axis)\n\t    a, b = scipy.stats.t.interval(confidence_level, deg_free, mean, str_err)\n\t    return mean, a, b\n\tdef compute_wasserstein_distance(img_gt, img_model, metric=\"euclidean\"):\n\t    assert img_gt.ndim == img_model.ndim == 2\n\t    # get positions in x-y-plane for pixels that\n\t    # take value \"1\" (interpreted as our samples).\n\t    pos_gt = np.stack(np.where(img_gt == 1), axis=-1)\n\t    pos_model = np.stack(np.where(img_model == 1), axis=-1)\n\t    # assume that the binary distribution over\n", "    # pixel value taking value 1 at x-y position\n\t    # is the uniform empirical distribution.\n\t    prob_gt = ot.unif(len(pos_gt))\n\t    prob_model = ot.unif(len(pos_model))\n\t    # euclidean distance times number of pixels\n\t    #  --> *total* (not avg) number of pixel movements.\n\t    M = ot.dist(pos_gt, pos_model, metric=metric)\n\t    dist_avg = ot.emd2(prob_gt, prob_model, M)\n\t    # dist_total = dist_avg * len(pos_gt)\n\t    return dist_avg\n", "def _wasserstein_worker_function(data):\n\t    orig_data, pred_data = data\n\t    assert orig_data.ndim == 2\n\t    assert pred_data.ndim == 3\n\t    assert orig_data.shape[0] == pred_data.shape[1]\n\t    N, T, _ = pred_data.shape\n\t    w_dist = np.zeros((N, T))\n\t    for t in range(T):\n\t        for n in range(N):\n\t            gt_img = orig_data[t]\n", "            pred_img = pred_data[n, t]\n\t            wass_dist = compute_wasserstein_distance(\n\t                gt_img.reshape(32, 32), pred_img.reshape(32, 32)\n\t            )\n\t            w_dist[n, t] = wass_dist\n\t    return w_dist\n\tdef evaluate_pymunk_dataset(\n\t    dataloader,\n\t    model,\n\t    device=torch.device(\"cpu\"),\n", "    num_samples: int = 80,\n\t    max_size: int = np.inf,  # type: ignore\n\t    no_state_sampling: bool = False,\n\t    use_smooth: bool = False,\n\t):\n\t    def _binarize_image(img):\n\t        img[img < 0.5] = 0.0\n\t        img[img >= 0.5] = 1.0\n\t        return img\n\t    wass_dists = []\n", "    size = 0\n\t    for test_batch in tqdm(dataloader, desc=\"Evaluating\"):\n\t        past_target = test_batch[\"past_target\"].to(device)\n\t        mask = test_batch[\"past_mask\"].to(device)\n\t        future_target = test_batch[\"future_target\"].to(device)\n\t        past_times = test_batch[\"past_times\"].to(device)\n\t        future_times = test_batch[\"future_times\"].to(device)\n\t        predict_result = model.forecast(\n\t            past_target,\n\t            mask,\n", "            past_times.view(-1),\n\t            future_times.view(-1),\n\t            num_samples=num_samples,\n\t            no_state_sampling=no_state_sampling,\n\t            use_smooth=use_smooth,\n\t        )\n\t        reconstruction = predict_result[\"reconstruction\"]\n\t        forecast = predict_result[\"forecast\"]\n\t        full_prediction = torch.cat([reconstruction, forecast], dim=-2)\n\t        full_target = torch.cat([past_target, future_target], dim=1)\n", "        full_prediction = torch2numpy(full_prediction)\n\t        full_target = torch2numpy(full_target)\n\t        full_prediction = np.swapaxes(full_prediction, 0, 1)  # Batch first\n\t        batch_wass_dist = []\n\t        mp_pool = multiprocessing.Pool(\n\t            initializer=None, processes=multiprocessing.cpu_count()\n\t        )\n\t        batch_wass_dist = mp_pool.map(\n\t            func=_wasserstein_worker_function,\n\t            iterable=zip(full_target, full_prediction),\n", "        )\n\t        mp_pool.close()\n\t        mp_pool.join()\n\t        wass_dists.append(np.array(batch_wass_dist))\n\t        size += past_target.shape[0]\n\t        if size >= max_size:\n\t            break\n\t    # Concate on batch dim\n\t    wass_dists: np.ndarray = np.concatenate(wass_dists, axis=0)  # shape = B, N, T\n\t    # Average over the batch\n", "    batch_wass_dists = wass_dists.mean(0)\n\t    wt_mean, _, wt_conf_interval = student_t_conf_interval(\n\t        batch_wass_dists, confidence_level=0.95, axis=0\n\t    )  # Used for plotting\n\t    future_w_mean, _, future_w_conf_interval = student_t_conf_interval(\n\t        batch_wass_dists[:, past_target.size(1) :].mean(axis=-1),\n\t        confidence_level=0.95,\n\t        axis=0,\n\t    )\n\t    return dict(\n", "        wt_mean=wt_mean,\n\t        wt_conf_interval=wt_conf_interval - wt_mean,\n\t        future_w_mean=future_w_mean,\n\t        future_w_conf_interval=future_w_conf_interval - future_w_mean,\n\t    )\n\tdef evaluate_simple_ts(\n\t    dataloader,\n\t    model,\n\t    device=torch.device(\"cpu\"),\n\t    num_samples=50,\n", "    no_state_sampling=False,\n\t    use_smooth=False,\n\t    return_states=False,\n\t):\n\t    imputation_sq_errs = []\n\t    forecast_sq_errs = []\n\t    mses_mean_forecast = []\n\t    mses_mean_imputation = []\n\t    mask_sum = 0.0\n\t    states = []\n", "    for test_batch in tqdm(dataloader, desc=\"Evaluating\"):\n\t        past_target = test_batch[\"past_target\"].to(device)\n\t        B, T, F = past_target.shape\n\t        mask = test_batch[\"past_mask\"].to(device)\n\t        future_target = test_batch[\"future_target\"].to(device)\n\t        past_times = test_batch[\"past_times\"].to(device)\n\t        future_times = test_batch[\"future_times\"].to(device)\n\t        predict_result = model.forecast(\n\t            past_target,\n\t            mask,\n", "            past_times.view(-1),\n\t            future_times.view(-1),\n\t            num_samples=num_samples,\n\t            no_state_sampling=no_state_sampling,\n\t            use_smooth=use_smooth,\n\t        )\n\t        reconstruction = predict_result[\"reconstruction\"]\n\t        forecast = predict_result[\"forecast\"]\n\t        if return_states:\n\t            states.append(\n", "                torch.cat(\n\t                    [predict_result[\"z_reconstruction\"], predict_result[\"z_forecast\"]],\n\t                    dim=-2,\n\t                )\n\t            )\n\t        # Compute MSE using samples\n\t        rec_sq_err = (past_target[None] - reconstruction) ** 2\n\t        rec_sq_err = torch.einsum(\"sbtf, bt -> sbtf\", rec_sq_err, 1 - mask)\n\t        mask_sum += torch.sum(1 - mask, dim=(-1, -2))\n\t        imputation_sq_errs.append(rec_sq_err)\n", "        forecast_sq_err = (future_target[None] - forecast) ** 2\n\t        forecast_sq_errs.append(forecast_sq_err)\n\t        # Compute MSE using mean forecast\n\t        mean_rec = reconstruction.mean(0)\n\t        batch_mse_mean_rec = torch.einsum(\n\t            \"btf, bt -> b\", (past_target - mean_rec) ** 2, 1 - mask\n\t        ) / (torch.sum(1 - mask, dim=-1) * F)\n\t        mses_mean_imputation.append(batch_mse_mean_rec)\n\t        mean_forecast = forecast.mean(0)\n\t        batch_mse_mean_forecast = torch.mean(\n", "            (future_target - mean_forecast) ** 2, (1, 2)\n\t        )\n\t        mses_mean_forecast.append(batch_mse_mean_forecast)\n\t    imputation_sq_errs = torch.cat(imputation_sq_errs, 1)\n\t    imputation_msq_errs = (\n\t        (torch.sum(imputation_sq_errs, (1, 2, 3)) / (mask_sum * F))\n\t        .detach()\n\t        .cpu()\n\t        .numpy()\n\t    )\n", "    imputation_mean_mse, _, imputation_conf_interval = student_t_conf_interval(\n\t        imputation_msq_errs, confidence_level=0.95, axis=0\n\t    )\n\t    forecast_sq_errs = torch.cat(forecast_sq_errs, 1)\n\t    forecast_msq_errs = torch.mean(forecast_sq_errs, (1, 2, 3)).detach().cpu().numpy()\n\t    forecast_mean_mse, _, forecast_conf_interval = student_t_conf_interval(\n\t        forecast_msq_errs, confidence_level=0.95, axis=0\n\t    )\n\t    mse_mean_imputation = torch.cat(mses_mean_imputation, 0).mean(0)\n\t    mse_mean_forecast = torch.cat(mses_mean_forecast, 0).mean(0)\n", "    imputation_delta_ci = imputation_conf_interval - imputation_mean_mse\n\t    forecast_delta_ci = forecast_conf_interval - forecast_mean_mse\n\t    print(\n\t        f\"Imputation MSE: {imputation_mean_mse.item():.5f} +/- {imputation_delta_ci:.5f}\"  # noqa\n\t    )\n\t    print(f\"Imputation MSE (of mean rec): {mse_mean_imputation.item():.5f}\")\n\t    print(f\"MSE: {forecast_mean_mse.item():.5f} +/- {forecast_delta_ci:.5f}\")\n\t    print(f\"MSE (of mean forecast): {mse_mean_forecast.item():.5f}\")\n\t    extra_return = {}\n\t    if return_states:\n", "        states = torch.cat(states, dim=1)\n\t        extra_return = {\"states\": states}\n\t    return dict(\n\t        imputation_mse=imputation_mean_mse.item(),\n\t        mse_imputation_rec=mse_mean_imputation.item(),\n\t        imputation_conf_interval=imputation_delta_ci.item(),\n\t        forecast_mse=forecast_mean_mse.item(),\n\t        mse_mean_forecast=mse_mean_forecast.item(),\n\t        forecast_conf_interval=forecast_delta_ci.item(),\n\t        **extra_return,\n", "    )\n\tdef evaluate_sporadic(\n\t    dataloader,\n\t    model,\n\t    device=torch.device(\"cpu\"),\n\t    num_samples=50,\n\t    no_state_sampling=False,\n\t    use_smooth=False,\n\t):\n\t    sq_err_sum = 0\n", "    mask_sum = 0\n\t    forecast_sq_errs = []\n\t    mses_mean_forecast = []\n\t    for test_batch in tqdm(dataloader, desc=\"Evaluating\"):\n\t        past_target = test_batch[\"past_target\"].to(device)\n\t        B, T, F = past_target.shape\n\t        mask = test_batch[\"past_mask\"].to(device)\n\t        future_target = test_batch[\"future_target\"].to(device)\n\t        past_times = test_batch[\"past_times\"].to(device)\n\t        future_times = test_batch[\"future_times\"].to(device)\n", "        future_mask = test_batch[\"future_mask\"].to(device)\n\t        predict_result = model.forecast(\n\t            past_target,\n\t            mask,\n\t            past_times.view(-1),\n\t            future_times.view(-1),\n\t            num_samples=num_samples,\n\t            no_state_sampling=no_state_sampling,\n\t            use_smooth=use_smooth,\n\t        )\n", "        forecast = predict_result[\"forecast\"]\n\t        # Compute MSE using samples\n\t        forecast_sq_err = (future_target[None] - forecast) ** 2\n\t        forecast_sq_err = torch.einsum(\n\t            \"sbtf, btf -> sb\", forecast_sq_err, future_mask\n\t        ) / (torch.sum(future_mask, dim=(-1, -2)))\n\t        forecast_sq_errs.append(forecast_sq_err)\n\t        # Compute MSE using mean forecast\n\t        mean_forecast = forecast.mean(0)\n\t        batch_mse_mean_forecast = torch.einsum(\n", "            \"btf, btf -> b\", (future_target - mean_forecast) ** 2, future_mask\n\t        ) / (torch.sum(future_mask, dim=(-1, -2)))\n\t        mses_mean_forecast.append(batch_mse_mean_forecast)\n\t        sq_err_sum += torch.einsum(\n\t            \"btf, btf -> \", (future_target - mean_forecast) ** 2, future_mask\n\t        )\n\t        mask_sum += torch.sum(future_mask)\n\t    forecast_sq_errs = torch.cat(forecast_sq_errs, 1)\n\t    forecast_msq_errs = torch.mean(forecast_sq_errs, 1).detach().cpu().numpy()\n\t    forecast_mean_mse, _, forecast_conf_interval = student_t_conf_interval(\n", "        forecast_msq_errs, confidence_level=0.95, axis=0\n\t    )\n\t    mse_mean_forecast = torch.cat(mses_mean_forecast, 0).mean(0)\n\t    delta_ci = forecast_conf_interval - forecast_mean_mse\n\t    mse_gru_ode_style = sq_err_sum / mask_sum\n\t    print(f\"MSE (as computed in GRUODE-B): {mse_gru_ode_style:5f}\")\n\t    return dict(\n\t        forecast_mse=forecast_mean_mse.item(),\n\t        mse_mean_forecast=mse_mean_forecast.item(),\n\t        forecast_conf_interval=delta_ci.item(),\n", "        mse_gru_ode_style=mse_gru_ode_style.item(),\n\t    )\n"]}
{"filename": "src/ncdssm/functions.py", "chunked_list": ["import torch\n\timport warnings\n\tfrom .type import Tensor, Tuple\n\tdef inverse_softplus(tensor: Tensor):\n\t    return tensor + torch.log(1 - torch.exp(-tensor))\n\tdef bm_t(tensor: Tensor):\n\t    \"\"\"Batched matrix transpose. Swaps the last two axes.\n\t    Args:\n\t        tensor (torch.Tensor): N-D tensor.\n\t    Returns:\n", "        torch.Tensor: tensor with last two dims swapped.\n\t    \"\"\"\n\t    return torch.transpose(tensor, -2, -1)\n\tdef mbvp(matrix: Tensor, batched_vectors: Tensor):\n\t    \"\"\"Compute matrix-batched vector product.\n\t    Args:\n\t        matrix (Tensor): 2D tensor.\n\t        batched_vectors (Tensor): 2D tensor.\n\t    Returns:\n\t        Tensor: The matrix-batched vector product.\n", "    \"\"\"\n\t    assert (\n\t        matrix.ndim == 2 and batched_vectors.ndim == 2\n\t    ), \"matrix and batched_vectors should be 2D tensors!\"\n\t    m, n = matrix.size()\n\t    b, d = batched_vectors.size()\n\t    assert n == d, f\"dim 2 of matrix ({n}) should match dim 2 of batched_vectors ({d})!\"\n\t    batched_matrix = matrix.unsqueeze(0)\n\t    return bmbvp(batched_matrix, batched_vectors)\n\tdef bmbvp(batched_matrix: Tensor, batched_vectors: Tensor):\n", "    \"\"\"Compute batched matrix-batched vector product.\n\t    Args:\n\t        batched_matrix (Tensor): 3D tensor.\n\t        batched_vectors (Tensor): 2D tensor.\n\t    Returns:\n\t        Tensor: The batched matrix-batched vector product.\n\t    \"\"\"\n\t    assert batched_matrix.ndim == 3 and batched_vectors.ndim == 2, (\n\t        \"batched_matrix and batched_vectors should \"\n\t        \"be 3D and 2D tensors, respectively!\"\n", "    )\n\t    bm, m, n = batched_matrix.size()\n\t    bv, d = batched_vectors.size()\n\t    assert bm == bv or bm == 1 or bv == 1, (\n\t        f\"Matrix ({bm}) and vector ({bv}) batch dim should match \" \"or be singletons!\"\n\t    )\n\t    assert n == d, (\n\t        f\"dim 3 of matrix ({n}) should match dim 2 \" f\"of batched_vectors ({d})!\"\n\t    )\n\t    batched_vectors = batched_vectors.unsqueeze(-1)\n", "    output = torch.matmul(batched_matrix, batched_vectors)\n\t    output = output.squeeze(-1)\n\t    return output\n\tdef linear_interpolation(t0, x0, t1, x1, t):\n\t    assert t0 <= t <= t1, f\"Incorrect time order: t0={t0}, t={t}, t1={t1}!\"\n\t    x = (t1 - t) / (t1 - t0) * x0 + (t - t0) / (t1 - t0) * x1\n\t    return x\n\tdef symmetrize(matrix: Tensor) -> Tensor:\n\t    \"\"\"Symmetrize a matrix A by (A + A^T) / 2.\n\t    Args:\n", "        matrix (Tensor): An N-D tensor with N > 2.\n\t    Returns:\n\t        Tensor: The symmetrized matrices.\n\t    \"\"\"\n\t    return 0.5 * (matrix + matrix.transpose(-1, -2))\n\tdef regularize_matrix(\n\t    batched_matrix, regularization=1e-6, relative_regularization=True\n\t):\n\t    batch_size = batched_matrix.size(0)\n\t    batched_identity = (\n", "        torch.eye(\n\t            batched_matrix.size(-1),\n\t            dtype=batched_matrix.dtype,\n\t            device=batched_matrix.device,\n\t        )\n\t        .unsqueeze(0)\n\t        .repeat(batch_size, 1, 1)\n\t    )\n\t    if relative_regularization:\n\t        diag_mean = (\n", "            torch.einsum(\"jii->ji\", batched_matrix)\n\t            .mean(dim=-1)\n\t            .view(batch_size, 1, 1)\n\t            .detach()\n\t        )\n\t        regularized_matrix = (\n\t            batched_matrix + regularization * diag_mean * batched_identity\n\t        )\n\t    else:\n\t        regularized_matrix = batched_matrix + regularization * batched_identity\n", "    return regularized_matrix\n\tdef make_positive_definite(\n\t    batched_matrix,\n\t    regularization=1e-4,\n\t    max_regularization=1,\n\t    step_factor=10,\n\t    warn=True,\n\t    relative_regularization=True,\n\t):\n\t    assert batched_matrix.ndim == 3\n", "    if regularization > max_regularization:\n\t        raise ValueError(\n\t            \"Attempted to regularize beyond max_regularization:\" f\"{max_regularization}\"\n\t        )\n\t    if warn:\n\t        warnings.warn(f\"Regularizing matrix with factor: {regularization}!\")\n\t    regularized_matrix = regularize_matrix(\n\t        batched_matrix,\n\t        regularization=regularization,\n\t        relative_regularization=relative_regularization,\n", "    )\n\t    is_pd = torch.all(torch.linalg.cholesky_ex(regularized_matrix).info.eq(0))\n\t    if is_pd:\n\t        return regularized_matrix\n\t    else:\n\t        return make_positive_definite(\n\t            batched_matrix,\n\t            regularization=regularization * step_factor,\n\t            max_regularization=max_regularization,\n\t            step_factor=step_factor,\n", "            warn=warn,\n\t            relative_regularization=relative_regularization,\n\t        )\n\tdef cholesky(batched_matrix: Tensor):\n\t    \"\"\"Cholesky decomposition which attempts to regularize the\n\t    matrix diagonal with some salt if the decomposition fails.\n\t    Args:\n\t        batched_matrix (Tensor): A 3-D tensor.\n\t    Returns:\n\t        Tensor: The cholesky factor.\n", "    \"\"\"\n\t    try:\n\t        cholesky_factor = torch.linalg.cholesky(batched_matrix)\n\t    except RuntimeError:\n\t        regularized_matrix = make_positive_definite(batched_matrix)\n\t        cholesky_factor = torch.linalg.cholesky(regularized_matrix)\n\t    return cholesky_factor\n\tdef qr(batched_matrix, positive_diag=True) -> Tuple[Tensor, Tensor]:\n\t    \"\"\"QR decomposition with the option of making the diagonal elements\n\t    of R positive.\n", "    Args:\n\t        batched_matrix (Tensor): An N-D tensor with N > 2.\n\t        positive_diag (bool, optional): Whether to make the diagonal elements\n\t            of R positive. Defaults to True.\n\t    Returns:\n\t        Tuple[Tensor, Tensor]: The Q and R.\n\t    \"\"\"\n\t    Q, R = torch.linalg.qr(batched_matrix)\n\t    if positive_diag:\n\t        # The QR decomposition returned by pytorch does not guarantee\n", "        # that the matrix R has positive diagonal elements.\n\t        # To ensure that, we first construct a signature matrix S\n\t        # which is a diagonal matrix with diagonal elements +1 or -1\n\t        # depending on the sign of the corresponding diagonal element in R.\n\t        # If we premultiply R with S, we ensure that the diagonal is positive;\n\t        # however, the corresponding Q needs to be changed now to ensure that\n\t        # that we get back the original matrix when we multiply the new Q and\n\t        # the new R. This can be done by postmultiplying Q with S because\n\t        # then we get (Q @ S) @ (S @ R) = Q @ R as S @ S = I, where (Q @ S)\n\t        # and (S @ R) are the new Q and new R respectively.\n", "        R_diag_sign = torch.sgn(torch.diagonal(R, dim1=-2, dim2=-1))\n\t        S = torch.diag_embed(R_diag_sign, dim1=-2, dim2=-1)\n\t        Q = Q @ S\n\t        R = S @ R\n\t    return Q, R\n\tdef bm_diag_positive(A):\n\t    dim = A.size(-1)\n\t    diag = torch.abs(torch.diagonal(A, dim1=-2, dim2=-1))\n\t    mask = torch.eye(dim, device=A.device)[None]\n\t    A = mask * torch.diag_embed(diag) + (1 - mask) * A\n", "    return A\n\tdef sum_mat_sqrts(sqrt_A, sqrt_B):\n\t    tmp = bm_t(torch.cat([sqrt_A, sqrt_B], dim=-1))\n\t    _, Rtmp = qr(tmp)\n\t    return bm_t(Rtmp)\n\tdef batch_jacobian(func, x, create_graph=False, vectorize=False):\n\t    def _func_sum(x):\n\t        return func(x).sum(dim=0)\n\t    return torch.autograd.functional.jacobian(\n\t        _func_sum, x, create_graph=create_graph, vectorize=vectorize\n", "    ).permute(1, 0, 2)\n"]}
{"filename": "src/ncdssm/inference.py", "chunked_list": ["import math\n\timport torch\n\tfrom torchdiffeq._impl.rk_common import rk4_alt_step_func as rk4_step_func\n\tfrom .type import Tensor, Union\n\tfrom .functions import cholesky, mbvp, bm_t, bmbvp, qr, symmetrize, sum_mat_sqrts\n\tfrom .models.dynamics import (\n\t    ContinuousLTI,\n\t    ContinuousNL,\n\t    ContinuousLL,\n\t)\n", "def analytic_linear_step(mu: Tensor, LSigma: Tensor, t0, t1, dynamics: ContinuousLTI):\n\t    # Analytic step for homogenous linear SDE using matrix exponentials\n\t    # Based on Sarkka and Solin, Section 6.2 & 6.3\n\t    batch_size = mu.size(0)\n\t    z_dim = dynamics.z_dim\n\t    F = dynamics.F\n\t    Q = dynamics.Q\n\t    mexp_F_t1mt0 = torch.matrix_exp(F * (t1 - t0))\n\t    mu_pred = mbvp(mexp_F_t1mt0, mu)\n\t    C_t0 = LSigma @ bm_t(LSigma)\n", "    D_t0 = torch.eye(z_dim, device=C_t0.device).repeat(batch_size, 1, 1)\n\t    CD_t0 = torch.cat([C_t0, D_t0], dim=1)\n\t    tmp = torch.zeros(2 * z_dim, 2 * z_dim, device=C_t0.device)\n\t    tmp[:z_dim, :z_dim] = F\n\t    tmp[:z_dim, z_dim:] = Q\n\t    tmp[z_dim:, z_dim:] = -F.T\n\t    mexp_tmp_t1mt0 = torch.matrix_exp(tmp * (t1 - t0))\n\t    CD_t1 = mexp_tmp_t1mt0[None] @ CD_t0\n\t    C_t1 = CD_t1[:, :z_dim]\n\t    D_t1 = CD_t1[:, z_dim:]\n", "    Sigma_pred = C_t1 @ torch.inverse(D_t1)\n\t    LSigma_pred = cholesky(symmetrize(Sigma_pred))\n\t    return mu_pred, LSigma_pred\n\tdef linear_step(\n\t    mu: Tensor,\n\t    Phi: Tensor,\n\t    sqrt_Phi_sum: Tensor,\n\t    tn,\n\t    h,\n\t    dynamics: ContinuousLTI,\n", "    method: str = \"rk4\",\n\t):\n\t    assert method in {\"euler\", \"rk4\"}, f\"Unknown solver: {method}!\"\n\t    F = dynamics.F\n\t    LQ = cholesky(dynamics.Q[None])\n\t    batched_F = F[None]\n\t    def _mu_rate_func(t, z, **unused_kwargs):\n\t        dz_by_dt = mbvp(F, z)\n\t        return dz_by_dt\n\t    def _Phi_rate_func(t, z, **unused_kwargs):\n", "        return batched_F @ z\n\t    if method == \"euler\":\n\t        mu_next = mu + h * _mu_rate_func(tn, mu)\n\t        Phi_next = Phi + h * _Phi_rate_func(tn, Phi)\n\t    elif method == \"rk4\":\n\t        mu_next = mu + rk4_step_func(_mu_rate_func, tn, h, tn + h, mu)\n\t        Phi_next = Phi + rk4_step_func(_Phi_rate_func, tn, h, tn + h, Phi)\n\t    Rtmp = sum_mat_sqrts(Phi @ LQ, Phi_next @ LQ)\n\t    Rtmp = math.sqrt(h / 2) * Rtmp\n\t    Rtmp = sum_mat_sqrts(Rtmp, sqrt_Phi_sum)\n", "    sqrt_Phi_sum = Rtmp\n\t    mu = mu_next\n\t    Phi = Phi_next\n\t    return mu, Phi, sqrt_Phi_sum\n\tdef cont_disc_linear_predict(\n\t    mu: Tensor,\n\t    LSigma: Tensor,\n\t    dynamics: ContinuousLTI,\n\t    t0: float,\n\t    t1: float,\n", "    step_size: float,\n\t    method: str = \"rk4\",\n\t    cache_params: bool = False,\n\t    min_step_size: float = 1e-5,\n\t):\n\t    batch_size = mu.size(0)\n\t    z_dim = dynamics.z_dim\n\t    t = t0\n\t    mu_pred = mu\n\t    if method == \"matrix_exp\":\n", "        return *analytic_linear_step(mu, LSigma, t0, t1, dynamics), ([], [], [])\n\t    Phi = torch.eye(z_dim, device=mu.device).repeat(batch_size, 1, 1)\n\t    sqrt_Phi_sum = torch.zeros(batch_size, z_dim, z_dim, device=mu.device)\n\t    cached_mus = []\n\t    cached_LSigmas = []\n\t    cached_timestamps = []\n\t    while t < t1:\n\t        h = min(step_size, t1 - t)\n\t        if h < min_step_size:\n\t            break\n", "        mu_pred, Phi, sqrt_Phi_sum = linear_step(\n\t            mu_pred, Phi, sqrt_Phi_sum, t, h, dynamics, method\n\t        )\n\t        if cache_params:\n\t            LSigma_pred = sum_mat_sqrts(Phi @ LSigma, sqrt_Phi_sum)\n\t            cached_mus.append(mu_pred.detach().clone())\n\t            cached_LSigmas.append(LSigma_pred.detach().clone())\n\t        t += h\n\t        if cache_params:\n\t            cached_timestamps.append(t)\n", "    if cache_params:\n\t        # Remove the predicted distribution for t1\n\t        # because this will be replaced by filter distribution\n\t        cached_mus.pop()\n\t        cached_LSigmas.pop()\n\t        cached_timestamps.pop()\n\t    cache = (cached_mus, cached_LSigmas, cached_timestamps)\n\t    LSigma_pred = sum_mat_sqrts(Phi @ LSigma, sqrt_Phi_sum)\n\t    return mu_pred, LSigma_pred, cache\n\tdef cont_disc_linear_update(y, mask, mu_pred, LSigma_pred, H, R, sporadic=False):\n", "    batch_size = y.size(0)\n\t    y_dim = y.size(-1)\n\t    z_dim = mu_pred.size(-1)\n\t    if R.size(0) != batch_size:\n\t        R = R.repeat(batch_size, 1, 1)\n\t    LR = cholesky(R)\n\t    if H.size(0) != batch_size:\n\t        H = H.repeat(batch_size, 1, 1)\n\t    if sporadic:\n\t        # mask.shape = B x D\n", "        mask_mat = torch.diag_embed(mask)\n\t        inv_mask_mat = torch.diag_embed(1 - mask)\n\t        # mask_mat.shape = B x D x D\n\t        # y.shape = B x D\n\t        y = y * mask\n\t        # Sqrt factor for:\n\t        # mask_mat @ R @ mask_mat.T + inv_mask_mat @ inv_mask_mat.T\n\t        LR = sum_mat_sqrts(mask_mat @ LR, inv_mask_mat)\n\t        # H.shape = B x D x M\n\t        H = mask_mat @ H\n", "    tmp = torch.zeros(batch_size, y_dim + z_dim, y_dim + z_dim, device=mu_pred.device)\n\t    tmp[:, :y_dim, :y_dim] = LR\n\t    tmp[:, :y_dim, y_dim:] = H @ LSigma_pred\n\t    tmp[:, y_dim:, y_dim:] = LSigma_pred\n\t    _, U = qr(bm_t(tmp))\n\t    U = bm_t(U)\n\t    X = U[:, :y_dim, :y_dim]\n\t    Y = U[:, y_dim:, :y_dim]\n\t    Z = U[:, y_dim:, y_dim:]\n\t    K = Y @ torch.inverse(X)  # Kalman Gain\n", "    y_pred = bmbvp(H, mu_pred)\n\t    r = y - y_pred  # Residual\n\t    # Update mu\n\t    mu = mu_pred + bmbvp(K, r)\n\t    # Update LSigma\n\t    LSigma = Z\n\t    # Compute LS for loss\n\t    LS = sum_mat_sqrts(H @ LSigma_pred, LR)\n\t    return mu, LSigma, y_pred, LS\n\tdef locallylinear_step(\n", "    mu: Tensor,\n\t    Phi: Tensor,\n\t    sqrt_Phi_sum: Tensor,\n\t    tn: float,\n\t    h: float,\n\t    dynamics: ContinuousLL,\n\t    method: str = \"rk4\",\n\t):\n\t    assert method in {\"euler\", \"rk4\"}, f\"Unknown solver: {method}!\"\n\t    F = dynamics.F\n", "    alpha0 = dynamics.alpha_net(mu)\n\t    F0 = torch.einsum(\n\t        \"bk, knm -> bnm\", alpha0, F\n\t    )  # Assuming fixed F(t) in the interval for cov\n\t    LQ = cholesky(dynamics.Q[None])\n\t    def _mu_rate_func(t, z, **unused_kwargs):\n\t        alpha = dynamics.alpha_net(z)\n\t        Ft = torch.einsum(\"bk, knm -> bnm\", alpha, F)\n\t        dz_by_dt = bmbvp(Ft, z)\n\t        return dz_by_dt\n", "    def _Phi_rate_func(t, z, **unused_kwargs):\n\t        # NOTE: Can matrix exp be used here?\n\t        return F0 @ z\n\t    if method == \"euler\":\n\t        mu_next = mu + h * _mu_rate_func(tn, mu)\n\t        Phi_next = Phi + h * _Phi_rate_func(tn, Phi)\n\t    elif method == \"rk4\":\n\t        mu_next = mu + rk4_step_func(_mu_rate_func, tn, h, tn + h, mu)\n\t        Phi_next = Phi + rk4_step_func(_Phi_rate_func, tn, h, tn + h, Phi)\n\t    Rtmp = sum_mat_sqrts(Phi @ LQ, Phi_next @ LQ)\n", "    Rtmp = math.sqrt(h / 2) * Rtmp\n\t    Rtmp = sum_mat_sqrts(Rtmp, sqrt_Phi_sum)\n\t    sqrt_Phi_sum = Rtmp\n\t    mu = mu_next\n\t    Phi = Phi_next\n\t    return mu, Phi, sqrt_Phi_sum\n\tdef cont_disc_locallylinear_predict(\n\t    mu,\n\t    LSigma,\n\t    dynamics,\n", "    t0,\n\t    t1,\n\t    step_size,\n\t    method=\"rk4\",\n\t    cache_params: bool = False,\n\t    min_step_size: float = 1e-5,\n\t):\n\t    batch_size = mu.size(0)\n\t    z_dim = dynamics.z_dim\n\t    t = t0\n", "    mu_pred = mu\n\t    Phi = torch.eye(z_dim, device=mu.device).repeat(batch_size, 1, 1)\n\t    sqrt_Phi_sum = torch.zeros(batch_size, z_dim, z_dim, device=mu.device)\n\t    cached_mus = []\n\t    cached_LSigmas = []\n\t    cached_timestamps = []\n\t    while t < t1:\n\t        h = min(step_size, t1 - t)\n\t        if h < min_step_size:\n\t            break\n", "        mu_pred, Phi, sqrt_Phi_sum = locallylinear_step(\n\t            mu_pred, Phi, sqrt_Phi_sum, t, h, dynamics, method\n\t        )\n\t        if cache_params:\n\t            LSigma_pred = sum_mat_sqrts(Phi @ LSigma, sqrt_Phi_sum)\n\t            cached_mus.append(mu_pred.detach().clone())\n\t            cached_LSigmas.append(LSigma_pred.detach().clone())\n\t        t += h\n\t        if cache_params:\n\t            cached_timestamps.append(t)\n", "    if cache_params:\n\t        # Remove the predicted distribution for t1\n\t        # because this will be replaced by filter distribution\n\t        cached_mus.pop()\n\t        cached_LSigmas.pop()\n\t        cached_timestamps.pop()\n\t    cache = (cached_mus, cached_LSigmas, cached_timestamps)\n\t    LSigma_pred = sum_mat_sqrts(Phi @ LSigma, sqrt_Phi_sum)\n\t    return mu_pred, LSigma_pred, cache\n\tdef cont_disc_locallylinear_update(\n", "    y: Tensor,\n\t    mask: Tensor,\n\t    mu_pred: Tensor,\n\t    LSigma_pred: Tensor,\n\t    H: Tensor,\n\t    R: Tensor,\n\t    sporadic: bool = False,\n\t):\n\t    return cont_disc_linear_update(\n\t        y, mask, mu_pred, LSigma_pred, H, R, sporadic=sporadic\n", "    )\n\tdef nonlinear_step(\n\t    mu: Tensor,\n\t    Phi: Tensor,\n\t    sqrt_Phi_sum: Tensor,\n\t    tn,\n\t    h,\n\t    dynamics: ContinuousNL,\n\t    method: str = \"rk4\",\n\t):\n", "    assert method in {\"euler\", \"rk4\"}, f\"Unknown solver: {method}!\"\n\t    f = dynamics.f\n\t    J_f0 = dynamics.jac_f(mu)  # Assuming fixed Jac_f(t) in the interval for cov\n\t    LGQGt = cholesky(dynamics.GQGt(mu))\n\t    def _mu_rate_func(t, z, **unused_kwargs):\n\t        dz_by_dt = f(z)\n\t        return dz_by_dt\n\t    def _Phi_rate_func(t, z, **unused_kwargs):\n\t        # NOTE: Can matrix exp be used here?\n\t        return J_f0 @ z\n", "    if method == \"euler\":\n\t        mu_next = mu + h * _mu_rate_func(tn, mu)\n\t        Phi_next = Phi + h * _Phi_rate_func(tn, Phi)\n\t    elif method == \"rk4\":\n\t        mu_next = mu + rk4_step_func(_mu_rate_func, tn, h, tn + h, mu)\n\t        Phi_next = Phi + rk4_step_func(_Phi_rate_func, tn, h, tn + h, Phi)\n\t    Rtmp = sum_mat_sqrts(Phi @ LGQGt, Phi_next @ LGQGt)\n\t    Rtmp = math.sqrt(h / 2) * Rtmp\n\t    Rtmp = sum_mat_sqrts(Rtmp, sqrt_Phi_sum)\n\t    sqrt_Phi_sum = Rtmp\n", "    mu = mu_next\n\t    Phi = Phi_next\n\t    return mu, Phi, sqrt_Phi_sum\n\tdef cont_disc_nonlinear_predict(\n\t    mu: Tensor,\n\t    LSigma: Tensor,\n\t    dynamics: ContinuousNL,\n\t    t0: float,\n\t    t1: float,\n\t    step_size: float,\n", "    method: str = \"rk4\",\n\t    cache_params: bool = False,\n\t    min_step_size: float = 1e-5,\n\t):\n\t    batch_size = mu.size(0)\n\t    z_dim = dynamics.z_dim\n\t    t = t0\n\t    mu_pred = mu\n\t    Phi = torch.eye(z_dim, device=mu.device).repeat(batch_size, 1, 1)\n\t    sqrt_Phi_sum = torch.zeros(batch_size, z_dim, z_dim, device=mu.device)\n", "    cached_mus = []\n\t    cached_LSigmas = []\n\t    cached_timestamps = []\n\t    while t < t1:\n\t        h = min(step_size, t1 - t)\n\t        if h < min_step_size:\n\t            break\n\t        mu_pred, Phi, sqrt_Phi_sum = nonlinear_step(\n\t            mu_pred, Phi, sqrt_Phi_sum, t, h, dynamics, method\n\t        )\n", "        if cache_params:\n\t            LSigma_pred = sum_mat_sqrts(Phi @ LSigma, sqrt_Phi_sum)\n\t            cached_mus.append(mu_pred.detach().clone())\n\t            cached_LSigmas.append(LSigma_pred.detach().clone())\n\t        t += h\n\t        if cache_params:\n\t            cached_timestamps.append(t)\n\t    if cache_params:\n\t        # Remove the predicted distribution for t1\n\t        # because this will be replaced by filter distribution\n", "        cached_mus.pop()\n\t        cached_LSigmas.pop()\n\t        cached_timestamps.pop()\n\t    cache = (cached_mus, cached_LSigmas, cached_timestamps)\n\t    LSigma_pred = sum_mat_sqrts(Phi @ LSigma, sqrt_Phi_sum)\n\t    return mu_pred, LSigma_pred, cache\n\tdef cont_disc_nonlinear_update(y, mask, mu_pred, LSigma_pred, H, R, sporadic=False):\n\t    return cont_disc_linear_update(\n\t        y, mask, mu_pred, LSigma_pred, H, R, sporadic=sporadic\n\t    )\n", "def linear_smooth_step(\n\t    mu_s: Tensor,\n\t    Phi_s: Tensor,\n\t    sqrt_Phi_sum: Tensor,\n\t    mu_f: Tensor,\n\t    LSigma_f: Tensor,\n\t    tn,\n\t    h,\n\t    dynamics: ContinuousLTI,\n\t    method: str = \"rk4\",\n", "):\n\t    assert h <= 0\n\t    assert method in {\"euler\", \"rk4\"}, f\"Unknown solver: {method}!\"\n\t    F = dynamics.F\n\t    LQ = cholesky(dynamics.Q[None])\n\t    Sigma_f_inv = torch.cholesky_inverse(LSigma_f)\n\t    QSigma_f_inv = dynamics.Q[None] @ Sigma_f_inv\n\t    A = F[None] + QSigma_f_inv\n\t    def _mu_rate_func(t, z, **unused_kwargs):\n\t        dz_by_dt = mbvp(F, z) + bmbvp(QSigma_f_inv, z - mu_f)\n", "        return dz_by_dt\n\t    def _Phi_rate_func(t, z, **unused_kwargs):\n\t        # NOTE: Can matrix exp be used here?\n\t        return A @ z\n\t    if method == \"euler\":\n\t        mu_s_next = mu_s + h * _mu_rate_func(tn, mu_s)\n\t        Phi_s_next = Phi_s + h * _Phi_rate_func(tn, Phi_s)\n\t    elif method == \"rk4\":\n\t        mu_s_next = mu_s + rk4_step_func(_mu_rate_func, tn, h, tn + h, mu_s)\n\t        Phi_s_next = Phi_s + rk4_step_func(_Phi_rate_func, tn, h, tn + h, Phi_s)\n", "    Rtmp = sum_mat_sqrts(Phi_s @ LQ, Phi_s_next @ LQ)\n\t    Rtmp = math.sqrt(-h / 2) * Rtmp\n\t    Rtmp = sum_mat_sqrts(Rtmp, sqrt_Phi_sum)\n\t    sqrt_Phi_sum = Rtmp\n\t    mu_s = mu_s_next\n\t    Phi_s = Phi_s_next\n\t    return mu_s, Phi_s, sqrt_Phi_sum\n\tdef type2_locallylinear_smooth_step(\n\t    mu_s: Tensor,\n\t    Phi_s: Tensor,\n", "    sqrt_Phi_sum: Tensor,\n\t    mu_f: Tensor,\n\t    LSigma_f: Tensor,\n\t    tn,\n\t    h,\n\t    dynamics: ContinuousLL,\n\t    method: str = \"rk4\",\n\t):\n\t    assert h <= 0\n\t    assert method in {\"euler\", \"rk4\"}, f\"Unknown solver: {method}!\"\n", "    F = dynamics.F\n\t    alpha0 = dynamics.alpha_net(mu_f)\n\t    F0 = torch.einsum(\"bk, knm -> bnm\", alpha0, F)\n\t    LQ = cholesky(dynamics.Q[None])\n\t    Sigma_f_inv = torch.cholesky_inverse(LSigma_f)\n\t    QSigma_f_inv = dynamics.Q[None] @ Sigma_f_inv\n\t    A = F0 + QSigma_f_inv\n\t    def _mu_rate_func(t, z, **unused_kwargs):\n\t        dz_by_dt = bmbvp(F0, mu_f) + bmbvp(F0 + QSigma_f_inv, z - mu_f)\n\t        return dz_by_dt\n", "    def _Phi_rate_func(t, z, **unused_kwargs):\n\t        # NOTE: Can matrix exp be used here?\n\t        return A @ z\n\t    if method == \"euler\":\n\t        mu_s_next = mu_s + h * _mu_rate_func(tn, mu_s)\n\t        Phi_s_next = Phi_s + h * _Phi_rate_func(tn, Phi_s)\n\t    elif method == \"rk4\":\n\t        mu_s_next = mu_s + rk4_step_func(_mu_rate_func, tn, h, tn + h, mu_s)\n\t        Phi_s_next = Phi_s + rk4_step_func(_Phi_rate_func, tn, h, tn + h, Phi_s)\n\t    Rtmp = sum_mat_sqrts(Phi_s @ LQ, Phi_s_next @ LQ)\n", "    Rtmp = math.sqrt(-h / 2) * Rtmp\n\t    Rtmp = sum_mat_sqrts(Rtmp, sqrt_Phi_sum)\n\t    sqrt_Phi_sum = Rtmp\n\t    mu_s = mu_s_next\n\t    Phi_s = Phi_s_next\n\t    return mu_s, Phi_s, sqrt_Phi_sum\n\tdef type2_nonlinear_smooth_step(\n\t    mu_s: Tensor,\n\t    Phi_s: Tensor,\n\t    sqrt_Phi_sum: Tensor,\n", "    mu_f: Tensor,\n\t    LSigma_f: Tensor,\n\t    tn,\n\t    h,\n\t    dynamics: ContinuousNL,\n\t    method: str = \"rk4\",\n\t):\n\t    assert h <= 0\n\t    assert method in {\"euler\", \"rk4\"}, f\"Unknown solver: {method}!\"\n\t    f = dynamics.f\n", "    GQGt = dynamics.GQGt(mu_f)\n\t    LGQGt = cholesky(GQGt)\n\t    Sigma_f_inv = torch.cholesky_inverse(LSigma_f)\n\t    QSigma_f_inv = GQGt @ Sigma_f_inv\n\t    J_f0 = dynamics.jac_f(mu_f)\n\t    A = J_f0 + QSigma_f_inv\n\t    def _mu_rate_func(t, z, **unused_kwargs):\n\t        dz_by_dt = f(mu_f) + bmbvp(J_f0 + QSigma_f_inv, z - mu_f)\n\t        return dz_by_dt\n\t    def _Phi_rate_func(t, z, **unused_kwargs):\n", "        # NOTE: Can matrix exp be used here?\n\t        return A @ z\n\t    if method == \"euler\":\n\t        mu_s_next = mu_s + h * _mu_rate_func(tn, mu_s)\n\t        Phi_s_next = Phi_s + h * _Phi_rate_func(tn, Phi_s)\n\t    elif method == \"rk4\":\n\t        mu_s_next = mu_s + rk4_step_func(_mu_rate_func, tn, h, tn + h, mu_s)\n\t        Phi_s_next = Phi_s + rk4_step_func(_Phi_rate_func, tn, h, tn + h, Phi_s)\n\t    Rtmp = sum_mat_sqrts(Phi_s @ LGQGt, Phi_s_next @ LGQGt)\n\t    Rtmp = math.sqrt(-h / 2) * Rtmp\n", "    Rtmp = sum_mat_sqrts(Rtmp, sqrt_Phi_sum)\n\t    sqrt_Phi_sum = Rtmp\n\t    mu_s = mu_s_next\n\t    Phi_s = Phi_s_next\n\t    return mu_s, Phi_s, sqrt_Phi_sum\n\t@torch.no_grad()\n\tdef cont_disc_smooth(\n\t    filter_mus: Tensor,\n\t    filter_LSigmas: Tensor,\n\t    filter_timestamps,\n", "    dynamics: Union[\n\t        ContinuousLTI,\n\t        ContinuousLL,\n\t        ContinuousNL,\n\t    ],\n\t    method: str = \"rk4\",\n\t):\n\t    batch_size = filter_mus.size(1)\n\t    z_dim = dynamics.z_dim\n\t    filter_mus = torch.flip(filter_mus, dims=(0,))\n", "    filter_LSigmas = torch.flip(filter_LSigmas, dims=(0,))\n\t    filter_timestamps = torch.flip(filter_timestamps, dims=(0,))\n\t    mu_s = filter_mus[0]\n\t    LSigma_s = filter_LSigmas[0]\n\t    smoothed_mus = [mu_s]\n\t    smoothed_LSigmas = [LSigma_s]\n\t    if isinstance(dynamics, ContinuousLTI):\n\t        _smooth_step = linear_smooth_step\n\t    elif isinstance(dynamics, ContinuousLL):\n\t        _smooth_step = type2_locallylinear_smooth_step\n", "    elif isinstance(dynamics, ContinuousNL):\n\t        _smooth_step = type2_nonlinear_smooth_step\n\t    else:\n\t        raise ValueError(f\"Unknown dynamics type {type(dynamics)}!\")\n\t    for idx, t0 in enumerate(filter_timestamps[:-1]):\n\t        t1 = filter_timestamps[idx + 1]\n\t        h = t1.item() - t0.item()\n\t        mu_f = filter_mus[idx]\n\t        LSigma_f = filter_LSigmas[idx]\n\t        Phi_s = torch.eye(z_dim, device=filter_mus.device).repeat(batch_size, 1, 1)\n", "        sqrt_Phi_sum = torch.zeros(batch_size, z_dim, z_dim, device=Phi_s.device)\n\t        mu_s, Phi_s, sqrt_Phi_sum = _smooth_step(\n\t            mu_s, Phi_s, sqrt_Phi_sum, mu_f, LSigma_f, t0.item(), h, dynamics, method\n\t        )\n\t        LSigma_s = sum_mat_sqrts(Phi_s @ LSigma_s, sqrt_Phi_sum)\n\t        smoothed_mus.append(mu_s.clone())\n\t        smoothed_LSigmas.append(LSigma_s.clone())\n\t    smoothed_mus: Tensor = torch.stack(smoothed_mus)\n\t    smoothed_LSigmas: Tensor = torch.stack(smoothed_LSigmas)\n\t    smoothed_mus, smoothed_LSigmas = torch.flip(smoothed_mus, dims=(0,)), torch.flip(\n", "        smoothed_LSigmas, dims=(0,)\n\t    )\n\t    return smoothed_mus, smoothed_LSigmas\n"]}
{"filename": "src/ncdssm/plotting.py", "chunked_list": ["import torch\n\timport matplotlib.pyplot as plt\n\timport seaborn as sns\n\timport numpy as np\n\tfrom torchvision.utils import save_image\n\tsns.set(style=\"white\")\n\tcolor_names = [\n\t    \"purple\",\n\t    \"orange\",\n\t    \"windows blue\",\n", "    \"red\",\n\t    \"amber\",\n\t    \"faded green\",\n\t    \"dusty purple\",\n\t    \"clay\",\n\t    \"pink\",\n\t    \"green\",\n\t    \"greyish\",\n\t    \"light cyan\",\n\t    \"steel blue\",\n", "    \"pastel purple\",\n\t    \"mint\",\n\t    \"salmon\",\n\t]\n\txkcd_colors = colors = sns.xkcd_palette(color_names)\n\t# colors = sns.color_palette(\"muted\")\n\tdef plot_on_axis(\n\t    ax,\n\t    past_times,\n\t    future_times,\n", "    inputs,\n\t    masked_inputs,\n\t    sorted_rec_and_forecast,\n\t    prediction_intervals=[90.0],\n\t    yticks_off=True,\n\t    ylim=None,\n\t    colors=colors,\n\t    ylabel=\"\",\n\t    shade_context=False,\n\t):\n", "    all_times = np.hstack([past_times, future_times])\n\t    num_samples, _, num_feats = sorted_rec_and_forecast.shape\n\t    for c in prediction_intervals:\n\t        assert 0.0 <= c <= 100.0\n\t    ps = [50.0] + [\n\t        50.0 + f * c / 2.0 for c in prediction_intervals for f in [-1.0, +1.0]\n\t    ]\n\t    percentiles_sorted = sorted(set(ps))\n\t    def alpha_for_percentile(p):\n\t        return (p / 100.0) ** 0.6\n", "    def quantile(q):\n\t        sample_idx = int(np.round((num_samples - 1) * q))\n\t        return sorted_rec_and_forecast[sample_idx, :]\n\t    ps_data = [quantile(p / 100.0) for p in percentiles_sorted]\n\t    i_p50 = len(percentiles_sorted) // 2\n\t    p50_data = ps_data[i_p50]\n\t    if shade_context:\n\t        ax.axvspan(0, future_times[0], facecolor=xkcd_colors[-6], alpha=0.2)\n\t    for o in range(num_feats):\n\t        ax.plot(\n", "            all_times,\n\t            inputs[:, o],\n\t            ls=\"--\",\n\t            lw=1.4,\n\t            color=colors[o],\n\t            alpha=0.6,\n\t        )\n\t        # Median forecast\n\t        ax.plot(all_times, p50_data[:, o], ls=\"-\", lw=1.5, color=colors[o], alpha=1.0)\n\t        ax.scatter(\n", "            past_times,\n\t            masked_inputs[: len(past_times), o],\n\t            s=20,\n\t            marker=\"o\",\n\t            color=colors[o],\n\t            alpha=0.6,\n\t        )\n\t        ax.axvline(future_times[0], color=xkcd_colors[-6], ls=\":\")\n\t        for i in range(len(percentiles_sorted) // 2):\n\t            ptile = percentiles_sorted[i]\n", "            alpha = alpha_for_percentile(ptile)\n\t            ax.fill_between(\n\t                all_times,\n\t                ps_data[i][:, o],\n\t                ps_data[-i - 1][:, o],\n\t                facecolor=colors[o],\n\t                # edgecolor=colors[o],\n\t                alpha=alpha,\n\t                interpolate=True,\n\t                # label=f\"{prediction_intervals[i]}% PI\",\n", "            )\n\t            ax.set_ylabel(ylabel)\n\t            if ylim:\n\t                ax.set_ylim(ylim)\n\t            if yticks_off:\n\t                ax.set_yticks([])\n\t    return ax\n\tdef show_time_series_forecast(\n\t    fig_size,\n\t    past_times,\n", "    future_times,\n\t    inputs,\n\t    masked_inputs,\n\t    reconstruction,\n\t    forecast,\n\t    prediction_intervals=[90.0],\n\t    fig_title=None,\n\t    file_path=None,\n\t    max_feats=6,\n\t    single_plot=False,\n", "    yticks_off=True,\n\t    ylim=None,\n\t):\n\t    obs_dim = inputs.shape[-1]\n\t    max_feats = min(max_feats, obs_dim)\n\t    rec_and_forecast = np.concatenate([reconstruction, forecast], axis=1)\n\t    rec_and_forecast = rec_and_forecast[..., :, :max_feats]\n\t    inputs = inputs[..., :, :max_feats]\n\t    all_times = np.hstack([past_times, future_times])  # [:150]\n\t    # num_samples = rec_and_forecast.shape[0]\n", "    if single_plot:\n\t        fig_size = (12, 1.0)\n\t        fig, axn = plt.subplots(figsize=fig_size, nrows=1, sharex=True)\n\t        axn = [axn] * max_feats\n\t    else:\n\t        fig_size = (12, max_feats * 1.0)\n\t        fig, axn = plt.subplots(figsize=fig_size, nrows=max_feats, sharex=True)\n\t        if max_feats == 1:\n\t            axn = [axn]\n\t    if fig_title:\n", "        plt.title(fig_title)\n\t    sorted_rec_and_forecast = np.sort(rec_and_forecast, axis=0)\n\t    axn[0].scatter(\n\t        [],\n\t        [],\n\t        s=20,\n\t        marker=\"o\",\n\t        color=\"k\",\n\t        alpha=0.6,\n\t        label=\"Observations\",\n", "    )\n\t    axn[0].plot(\n\t        [],\n\t        [],\n\t        ls=\"--\",\n\t        lw=1.4,\n\t        color=\"k\",\n\t        alpha=0.6,\n\t        label=\"Ground Truth\",\n\t    )\n", "    axn[0].plot(\n\t        [],\n\t        [],\n\t        ls=\"-\",\n\t        lw=1.5,\n\t        color=\"k\",\n\t        label=\"Median Prediction\",\n\t    )\n\t    for o in range(max_feats):\n\t        plot_on_axis(\n", "            axn[o],\n\t            past_times,\n\t            future_times,\n\t            inputs[:, o : o + 1],\n\t            masked_inputs[:, o : o + 1],\n\t            sorted_rec_and_forecast[:, :, o : o + 1],\n\t            prediction_intervals,\n\t            yticks_off,\n\t            ylim,\n\t            colors=colors[o : o + 1],\n", "            ylabel=f\"$y_{o}$\",\n\t        )\n\t    axn[-1].set_xlabel(\"Time\")\n\t    axn[0].legend(bbox_to_anchor=(0.5, 1.6), ncol=3, loc=\"upper center\")\n\t    axn[0].set_xlim((all_times[0], all_times[-1]))\n\t    # plt.tight_layout()\n\t    if file_path:\n\t        plt.savefig(file_path, dpi=200, bbox_inches=\"tight\")\n\t    return fig\n\tdef show_pymunk_forecast(orig, pred, file_path):\n", "    assert orig.shape == pred.shape[1:]\n\t    N, T, C, H, W = pred.shape\n\t    orig = torch.as_tensor(orig)\n\t    pred = torch.as_tensor(pred)\n\t    orig = orig.unsqueeze(0)\n\t    img = torch.cat([orig, pred], 0)\n\t    img = img.view((N + 1) * T, C, H, W)\n\t    save_image(img, file_path, nrow=T, pad_value=0.5)\n\t    return img\n\tdef show_wasserstein_distance(\n", "    fig_size, w_dist, conf_intervals=None, fig_title=None, ylim=None, file_path=None\n\t):\n\t    fig = plt.figure(figsize=fig_size)\n\t    if fig_title:\n\t        plt.title(fig_title)\n\t    ax = fig.gca()\n\t    if conf_intervals is not None:\n\t        ax.errorbar(\n\t            np.arange(w_dist.shape[0]),\n\t            w_dist,\n", "            yerr=conf_intervals,\n\t            capsize=5,\n\t            color=colors[-1],\n\t        )\n\t    else:\n\t        ax.plot(w_dist, color=colors[-1])\n\t    ax.set_ylabel(\"W\")\n\t    ax.set_xlabel(\"T\")\n\t    if ylim is not None:\n\t        ax.set_ylim(ylim)\n", "    if file_path:\n\t        plt.savefig(file_path, dpi=200, bbox_inches=\"tight\")\n\t    return fig\n\tdef show_latents(fig_size, time, latents, fig_title, file_path=None):\n\t    fig, axn = plt.subplots(figsize=fig_size, nrows=len(latents), sharex=True)\n\t    if len(latents) == 1:\n\t        axn = [axn]\n\t    if fig_title:\n\t        plt.suptitle(fig_title)\n\t    for i, key in enumerate(latents):\n", "        ts = latents[key]\n\t        dims = ts.shape[-1]\n\t        for d in range(dims):\n\t            axn[i].plot(time, ts[:, d], color=colors[d])\n\t        axn[i].set_ylabel(key)\n\t    axn[-1].set_xlabel(\"time\")\n\t    if file_path:\n\t        plt.savefig(file_path, dpi=200, bbox_inches=\"tight\")\n\t        plt.close(fig)\n\t    else:\n", "        return fig\n"]}
{"filename": "src/ncdssm/type.py", "chunked_list": ["from typing import Optional, Callable, Tuple, Dict, List, Union\n\timport torch\n\timport numpy as np\n\tTensor = torch.Tensor\n\tNumpyArray = np.ndarray\n\t__all__ = [\"Optional\", \"Callable\", \"Tuple\", \"Dict\", \"List\", \"Tensor\", \"Union\"]\n"]}
{"filename": "src/ncdssm/utils.py", "chunked_list": ["from ncdssm.type import Dict\n\tdef listofdict2dictoflist(lod: Dict):\n\t    keys = lod[0].keys()\n\t    return {k: [elem[k] for elem in lod] for k in keys}\n"]}
{"filename": "src/ncdssm/modules.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport numpy as np\n\tfrom torchdiffeq import odeint\n\tfrom torch.nn.utils import spectral_norm\n\tfrom .type import Callable\n\tclass MLP(nn.Module):\n\t    def __init__(\n\t        self,\n\t        in_dim: int,\n", "        h_dim: int,\n\t        out_dim: int,\n\t        n_hidden_layers: int = 1,\n\t        nonlinearity: Callable = nn.ReLU,\n\t        last_nonlinearity: bool = False,\n\t        zero_init_last: bool = False,\n\t        apply_spectral_norm: bool = False,\n\t    ):\n\t        super().__init__()\n\t        assert n_hidden_layers >= 1\n", "        self.in_dim = in_dim\n\t        self.out_dim = h_dim\n\t        module_list = []\n\t        sn: Callable = (\n\t            spectral_norm if apply_spectral_norm else lambda x: x  # type: ignore\n\t        )\n\t        module_list.append(sn(nn.Linear(in_dim, h_dim)))\n\t        module_list.append(nonlinearity())\n\t        for _ in range(n_hidden_layers - 1):\n\t            module_list.append(sn(nn.Linear(h_dim, h_dim)))\n", "            module_list.append(nonlinearity())\n\t        module_list.append(sn(nn.Linear(h_dim, out_dim)))\n\t        if zero_init_last:\n\t            module_list[-1].weight.data.zero_()\n\t            module_list[-1].bias.data.zero_()\n\t        if last_nonlinearity:\n\t            module_list.append(nonlinearity())\n\t        self.mlp = nn.Sequential(*module_list)\n\t    def forward(self, x):\n\t        return self.mlp(x)\n", "class ODEFunc(nn.Module):\n\t    def __init__(self, ode_net: nn.Module):\n\t        super().__init__()\n\t        self.ode_net = ode_net\n\t    def forward(self, t, x):\n\t        return self.ode_net(x)\n\tclass ODEGRU(nn.Module):\n\t    def __init__(\n\t        self,\n\t        data_dim: int,\n", "        state_dim: int,\n\t        ode_h_dim: int,\n\t        ode_n_layers: int,\n\t        ode_nonlinearity: nn.Module,\n\t        integration_step_size: float = 0.1,\n\t        integration_method: str = \"rk4\",\n\t    ):\n\t        super().__init__()\n\t        self.data_dim = data_dim\n\t        self.state_dim = state_dim\n", "        self.ode_func = ODEFunc(\n\t            MLP(\n\t                in_dim=state_dim,\n\t                out_dim=state_dim,\n\t                h_dim=ode_h_dim,\n\t                n_hidden_layers=ode_n_layers,\n\t                nonlinearity=ode_nonlinearity,\n\t            )\n\t        )\n\t        self.integration_step_size = integration_step_size\n", "        self.integration_method = integration_method\n\t        self.gru_cell = nn.GRUCell(input_size=data_dim, hidden_size=state_dim)\n\t    def gru_update(self, x, h, mask):\n\t        h_next = self.gru_cell(x, h)\n\t        mask = mask.unsqueeze(-1)\n\t        h_next = mask * h_next + (1 - mask) * h\n\t        return h_next\n\t    def ode_update(self, h, t1, t2):\n\t        out = odeint(\n\t            self.ode_func,\n", "            h,\n\t            torch.tensor([t1, t2], device=h.device),\n\t            method=self.integration_method,\n\t            options={\"step_size\": self.integration_step_size},\n\t        )\n\t        return out[-1]\n\t    def forward(self, x, times, mask):\n\t        B, T, F = x.size()\n\t        out = []\n\t        if T == 1:\n", "            h = torch.zeros(B, self.state_dim, device=x.device)\n\t            h = self.gru_update(x[:, 0], h, mask[:, 0])\n\t            out.append(h)\n\t        else:\n\t            out = []\n\t            h = torch.zeros(B, self.state_dim, device=x.device)\n\t            h = self.gru_update(x[:, 0], h, mask[:, 0])\n\t            out.append(h)\n\t            for i, (t1, t2) in enumerate(zip(times[:-1], times[1:])):\n\t                h_ode = self.ode_update(h, t1.item(), t2.item())\n", "                h = self.gru_update(x[:, i + 1], h_ode, mask[:, i + 1])\n\t                out.append(h)\n\t        out = torch.stack(out)\n\t        out = out.permute(1, 0, 2)\n\t        return out\n\tclass MergeLastDims(nn.Module):\n\t    def __init__(self, ndims=1):\n\t        super().__init__()\n\t        self.ndims = ndims\n\t    def forward(self, x):\n", "        shape = x.shape\n\t        last_dim = np.prod(shape[-self.ndims :])\n\t        x = x.view(shape[: -self.ndims] + (last_dim,))\n\t        return x\n\tclass ImageEncoder(nn.Module):\n\t    def __init__(self, img_size, channels, out_dim):\n\t        super().__init__()\n\t        self.img_size = img_size\n\t        self.ch = channels\n\t        self.out_dim = out_dim\n", "        self.network = nn.Sequential(\n\t            nn.ZeroPad2d(padding=[0, 1, 0, 1]),\n\t            nn.Conv2d(\n\t                in_channels=self.ch,\n\t                out_channels=32,\n\t                kernel_size=3,\n\t                stride=2,\n\t                padding=0,\n\t            ),\n\t            nn.ReLU(),\n", "            nn.ZeroPad2d(padding=[0, 1, 0, 1]),\n\t            nn.Conv2d(\n\t                in_channels=32,\n\t                out_channels=32,\n\t                kernel_size=3,\n\t                stride=2,\n\t                padding=0,\n\t            ),\n\t            nn.ReLU(),\n\t            nn.ZeroPad2d(padding=[0, 1, 0, 1]),\n", "            nn.Conv2d(\n\t                in_channels=32,\n\t                out_channels=32,\n\t                kernel_size=3,\n\t                stride=2,\n\t                padding=0,\n\t            ),\n\t            nn.ReLU(),\n\t            MergeLastDims(ndims=3),\n\t            nn.Linear(32 * 4 * 4, self.out_dim),\n", "        )\n\t    def forward(self, x):\n\t        assert x.dim() == 3, \"Expected 3 dims B, T, C * H * W\"\n\t        B, T, _ = x.shape\n\t        x = x.view(B, T, self.ch, self.img_size, self.img_size)\n\t        B, T, C, H, W = x.shape\n\t        assert H == W\n\t        x = x.reshape(B * T, C, H, W)\n\t        h = self.network(x)\n\t        h = h.view(B, T, self.out_dim)\n", "        return h\n\tclass ImageDecoder(nn.Module):\n\t    def __init__(self, in_dim, img_size, channels):\n\t        super().__init__()\n\t        self.img_size = img_size\n\t        self.ch = channels\n\t        self.linear = nn.Linear(\n\t            in_features=in_dim,\n\t            out_features=32 * 4 * 4,\n\t        )\n", "        self.convnet = nn.Sequential(\n\t            nn.Conv2d(\n\t                in_channels=32,\n\t                out_channels=32 * 2**2,\n\t                kernel_size=3,\n\t                stride=1,\n\t                padding=1,\n\t            ),\n\t            nn.ReLU(),\n\t            nn.PixelShuffle(upscale_factor=2),\n", "            nn.Conv2d(\n\t                in_channels=32,\n\t                out_channels=32 * 2**2,\n\t                kernel_size=3,\n\t                stride=1,\n\t                padding=1,\n\t            ),\n\t            nn.ReLU(),\n\t            nn.PixelShuffle(upscale_factor=2),\n\t            nn.Conv2d(\n", "                in_channels=32,\n\t                out_channels=32 * 2**2,\n\t                kernel_size=3,\n\t                stride=1,\n\t                padding=1,\n\t            ),\n\t            nn.ReLU(),\n\t            nn.PixelShuffle(upscale_factor=2),\n\t            nn.Conv2d(\n\t                in_channels=32,\n", "                out_channels=self.ch,\n\t                kernel_size=1,\n\t                stride=1,\n\t                padding=0,\n\t            ),\n\t        )\n\t    def forward(self, x):\n\t        assert x.dim() == 3, \"Expected 3 dims B, T, D\"\n\t        B, T, _ = x.shape\n\t        h = self.linear(x)\n", "        h = h.view(B * T, 32, 4, 4)\n\t        h = self.convnet(h)\n\t        h = h.view(B, T, self.ch, self.img_size, self.img_size)\n\t        return h\n\tclass Lambda(nn.Module):\n\t    def __init__(self, func: Callable):\n\t        super().__init__()\n\t        self.func = func\n\t    def forward(self, x):\n\t        return self.func(x)\n"]}
{"filename": "src/ncdssm/models/dynamics.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tfrom ..modules import Lambda\n\tfrom ..functions import batch_jacobian, bm_t, mbvp, bmbvp\n\tfrom ..type import Tuple, Tensor, List\n\tclass ContinuousLTI(nn.Module):\n\t    def __init__(\n\t        self,\n\t        z_dim: int,\n\t        u_dim: int,\n", "        F: Tensor,\n\t        B: Tensor,\n\t        uQ: Tensor,\n\t    ):\n\t        super().__init__()\n\t        self.z_dim = z_dim\n\t        if u_dim > 0:\n\t            if B is not None:\n\t                self.register_buffer(\"B\", B)\n\t            else:\n", "                self.B = nn.Parameter(\n\t                    nn.init.xavier_uniform_(torch.empty(z_dim, u_dim))\n\t                )\n\t        self.F = nn.Parameter(F)\n\t        self.uQ = nn.Parameter(uQ)\n\t    @property\n\t    def Q(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uQ), min=1e-4))\n\t    def forward(\n\t        self,\n", "        t: Tensor,\n\t        m_and_P: Tuple[Tensor, Tensor],\n\t    ):\n\t        \"\"\"Dynamics for mean and covariance.\n\t        Args:\n\t            t (Tensor): A 1-D tensor of times.\n\t            m_and_P (Tuple[Tensor, Tensor]): A tuple of\n\t                mean and covariance.\n\t        Returns:\n\t            Tuple: Tuple of \"velocity\" of mean and covariance.\n", "        \"\"\"\n\t        m, P = m_and_P\n\t        # Dynamics for mean\n\t        velocity_m = mbvp(self.F, m)\n\t        # Dynamics for Covariance\n\t        F = self.F[None]\n\t        Q = self.Q[None]\n\t        velocity_P = F @ P + P @ bm_t(F) + Q\n\t        return velocity_m, velocity_P\n\tclass ContinuousLL(nn.Module):\n", "    def __init__(\n\t        self,\n\t        z_dim: int,\n\t        u_dim: int,\n\t        K: int,\n\t        F: Tensor,\n\t        B: Tensor,\n\t        uQ: Tensor,\n\t        alpha_net: nn.Module,\n\t    ):\n", "        super().__init__()\n\t        self.z_dim = z_dim\n\t        self.u_dim = u_dim\n\t        self.K = K\n\t        if u_dim > 0:\n\t            if B is not None:\n\t                self.register_buffer(\"B\", B)\n\t            else:\n\t                self.B = nn.Parameter(\n\t                    nn.init.xavier_uniform_(torch.empty(K, z_dim, u_dim))\n", "                )\n\t        self.F = nn.Parameter(F)\n\t        self.uQ = nn.Parameter(uQ)\n\t        self.alpha_net = alpha_net\n\t    @property\n\t    def Q(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uQ), min=1e-4))\n\t    def forward(self, t: Tensor, m_and_P: Tuple[Tensor, Tensor]):\n\t        \"\"\"Dynamics for mean and covariance.\n\t        Args:\n", "            t (Tensor): A 1-D tensor of times.\n\t            m_and_P (Tuple[Tensor, Tensor]):\n\t                A tuple of mean and covariance.\n\t        Returns:\n\t            Tuple: Tuple of \"velocity\" of mean and covariance.\n\t        \"\"\"\n\t        m, P = m_and_P\n\t        # Linear combination of base matrices\n\t        alpha = self.alpha_net(m)\n\t        F = torch.einsum(\"bk, knm -> bnm\", alpha, self.F)\n", "        # F.shape = B x z_dim x z_dim\n\t        # m.shape = B x z_dim\n\t        # Dynamics for mean\n\t        velocity_m = bmbvp(F, m)\n\t        # Dynamics for Covariance\n\t        Q = self.Q[None]\n\t        velocity_P = F @ P + P @ bm_t(F) + Q\n\t        return velocity_m, velocity_P\n\tclass ContinuousNL(nn.Module):\n\t    def __init__(\n", "        self,\n\t        z_dim: int,\n\t        u_dim: int,\n\t        f: nn.Module,\n\t        gs: List[nn.Module],\n\t        B: Tensor,\n\t    ):\n\t        super().__init__()\n\t        self.z_dim = z_dim\n\t        self.f = f\n", "        if u_dim > 0:\n\t            if B is not None:\n\t                self.register_buffer(\"B\", B)\n\t            else:\n\t                self.B = nn.Parameter(\n\t                    nn.init.xavier_uniform_(torch.empty(z_dim, u_dim))\n\t                )\n\t        self.fixed_diffusion = gs is None\n\t        if gs is None:\n\t            gs = [\n", "                nn.Sequential(\n\t                    nn.Linear(1, 1, bias=False), Lambda(lambda x: torch.exp(x))\n\t                )\n\t                for _ in range(z_dim)\n\t            ]\n\t            with torch.no_grad():\n\t                for g in gs:\n\t                    g[0].weight.data.zero_()\n\t        self.gs = nn.ModuleList(gs)\n\t    def jac_f(self, z: Tensor) -> Tensor:\n", "        J = batch_jacobian(self.f, z, create_graph=True, vectorize=True)\n\t        return J\n\t    def GQGt(self, z):\n\t        # Assuming Q = I, so GQGt = GGt\n\t        # For fixed diffusion the normalizer is Exp(), see __init__().\n\t        # For non linear diffusion, it is assumed that\n\t        # the diffusion networks normalize the scale to R+.\n\t        if self.fixed_diffusion:\n\t            z = torch.ones_like(z)\n\t        zs = torch.split(z, split_size_or_sections=1, dim=-1)\n", "        diag_G = torch.cat([g_i(z_i) for (g_i, z_i) in zip(self.gs, zs)], dim=-1)\n\t        diag_Gsq = diag_G * diag_G\n\t        return torch.diag_embed(torch.clamp(diag_Gsq, min=1e-4))\n\t    def forward(self, t: Tensor, m_P: Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tensor]:\n\t        \"\"\"Dynamics for mean and covariance.\n\t        Args:\n\t            t (Tensor): A 1-D tensor of times.\n\t            m_P (Tuple[Tensor, Tensor, Tensor]):\n\t                A tuple of mean, and covariance.\n\t        Returns:\n", "            Tuple: Tuple of \"velocity\" of mean and covariance.\n\t        \"\"\"\n\t        m, P = m_P\n\t        # Dynamics for mean\n\t        velocity_m = self.f(m)\n\t        # Dynamics for Covariance\n\t        GQGt = self.GQGt(m)\n\t        J_f = self.jac_f(m)\n\t        velocity_P = J_f @ P + P @ bm_t(J_f) + GQGt\n\t        return velocity_m, velocity_P\n"]}
{"filename": "src/ncdssm/models/base.py", "chunked_list": ["from abc import ABC, abstractmethod\n\timport torch\n\timport torch.nn as nn\n\tfrom torch.distributions.multivariate_normal import MultivariateNormal\n\tfrom .dynamics import (\n\t    ContinuousLTI,\n\t    ContinuousNL,\n\t    ContinuousLL,\n\t)\n\tfrom ..inference import (\n", "    cont_disc_linear_predict,\n\t    cont_disc_linear_update,\n\t    cont_disc_locallylinear_predict,\n\t    cont_disc_locallylinear_update,\n\t    cont_disc_nonlinear_predict,\n\t    cont_disc_nonlinear_update,\n\t    cont_disc_smooth,\n\t)\n\tfrom ..torch_utils import skew_symmetric_init_\n\tfrom ..functions import cholesky, bmbvp\n", "from ..type import Optional, Tensor, List, Dict, Union\n\tclass Base(ABC):\n\t    @abstractmethod\n\t    def predict_step(\n\t        self,\n\t        mu: Tensor,\n\t        LSigma: Tensor,\n\t        dynamics: Union[ContinuousLTI, ContinuousNL, ContinuousLL],\n\t        t0: float,\n\t        t1: float,\n", "        step_size: float,\n\t        method: str,\n\t        cache_params: bool = False,\n\t        min_step_size: float = 1e-5,\n\t    ):\n\t        pass\n\t    @abstractmethod\n\t    def update_step(\n\t        self,\n\t        y: Tensor,\n", "        mask: Tensor,\n\t        mu_pred: Tensor,\n\t        LSigma_pred: Tensor,\n\t        H: Tensor,\n\t        R: Tensor,\n\t        sporadic: bool = False,\n\t    ):\n\t        pass\n\t    def filter(\n\t        self,\n", "        y: Tensor,\n\t        mask: Tensor,\n\t        times: Tensor,\n\t        cache_params: bool = False,\n\t    ) -> Dict[str, Tensor]:\n\t        \"\"\"The filter step of the continuous-discrete model.\n\t        Parameters\n\t        ----------\n\t        y\n\t            The tensor of observations, of shape (batch_size, num_timesteps, y_dim)\n", "        mask\n\t            The mask of missing values (1: observed, 0: missing),\n\t            of shape (batch_size, num_timesteps, y_dim), if sporadic,\n\t            else (batch_size, num_timesteps)\n\t        times\n\t            The tensor observations times, of shape (num_timesteps,)\n\t        cache_params, optional\n\t            Whether to cache the intermediate distributions computed during\n\t            predict step, by default False and all distrbutions at observation ``times``\n\t            are cached in any case,\n", "            should be set to True if you're planning to use smoothing\n\t        Returns\n\t        -------\n\t            The dictionary of filter outputs, including the log-likelihood\n\t            and the parameters of filtered distributions\n\t        \"\"\"\n\t        if self.sporadic:\n\t            assert (\n\t                y.size() == mask.size()\n\t            ), f\"Shapes of y ({y.size()}) and mask ({mask.size()}) should match!\"\n", "        else:\n\t            assert y.size()[:-1] == mask.size(), (\n\t                f\"Shapes of y ({y.size()}) and mask ({mask.size()})\"\n\t                \" should match except in last dim!\"\n\t            )\n\t        batch_size = y.size(0)\n\t        # Assumes that t = 0 is in times\n\t        assert times[0] == 0.0, \"First timestep should be 0!\"\n\t        mu_pred = self.mu0[None].repeat(batch_size, 1)\n\t        LSigma_pred = cholesky(self.Sigma0[None]).repeat(batch_size, 1, 1)\n", "        log_prob = []\n\t        filtered_mus = []\n\t        filtered_LSigmas = []\n\t        cached_mus = []\n\t        cached_LSigmas = []\n\t        cached_timestamps = []\n\t        for idx, t in enumerate(times):\n\t            H = self.H[None]\n\t            R = self.R[None]\n\t            # UPDATE step\n", "            y_i = y[:, idx]\n\t            mask_i = mask[:, idx]\n\t            mu, LSigma, y_pred, LS = self.update_step(\n\t                y=y_i,\n\t                mask=mask_i,\n\t                mu_pred=mu_pred,\n\t                LSigma_pred=LSigma_pred,\n\t                H=H,\n\t                R=R,\n\t                sporadic=self.sporadic,\n", "            )\n\t            if not self.sporadic:\n\t                # Mask out updates\n\t                # For the sporadic case, masks are directly incorporated\n\t                # during the update step\n\t                # TODO: Modify update step such that masking is not required here\n\t                mu = mask_i[:, None] * mu + (1 - mask_i[:, None]) * mu_pred\n\t                LSigma = (\n\t                    mask_i[:, None, None] * LSigma\n\t                    + (1 - mask_i[:, None, None]) * LSigma_pred\n", "                )\n\t            # Calculate log_prob\n\t            if not self.sporadic:\n\t                dist = MultivariateNormal(loc=y_pred, scale_tril=LS)\n\t                log_prob.append(dist.log_prob(y_i) * mask_i)\n\t            else:\n\t                dist = MultivariateNormal(loc=y_pred * mask_i, scale_tril=LS)\n\t                log_prob.append(dist.log_prob(y_i * mask_i))\n\t            # Cache filtered distribution\n\t            filtered_mus.append(mu.clone())\n", "            filtered_LSigmas.append(LSigma.clone())\n\t            cached_mus.append(mu.detach().clone())\n\t            cached_LSigmas.append(LSigma.detach().clone())\n\t            cached_timestamps.append(t.item())\n\t            if idx == len(times) - 1:\n\t                break\n\t            # PREDICT step\n\t            (\n\t                mu_pred,\n\t                LSigma_pred,\n", "                (cached_mus_t, cached_LSigmas_t, cached_timestamps_t),\n\t            ) = self.predict_step(\n\t                mu=mu,\n\t                LSigma=LSigma,\n\t                dynamics=self.dynamics,\n\t                t0=t.item(),\n\t                t1=times[idx + 1].item(),\n\t                step_size=self.integration_step_size,\n\t                method=self.integration_method,\n\t                cache_params=cache_params,\n", "            )\n\t            cached_mus.extend(cached_mus_t)\n\t            cached_LSigmas.extend(cached_LSigmas_t)\n\t            cached_timestamps.extend(cached_timestamps_t)\n\t        filtered_mus: Tensor = torch.stack(filtered_mus)\n\t        filtered_LSigmas: Tensor = torch.stack(filtered_LSigmas)\n\t        cached_mus: Tensor = torch.stack(cached_mus)\n\t        cached_LSigmas: Tensor = torch.stack(cached_LSigmas)\n\t        cached_timestamps: Tensor = torch.tensor(\n\t            cached_timestamps, dtype=times.dtype, device=times.device\n", "        )\n\t        log_prob = torch.stack(log_prob).sum(0)\n\t        return dict(\n\t            filtered_mus=filtered_mus,\n\t            filtered_LSigmas=filtered_LSigmas,\n\t            last_filtered_dist=(mu, LSigma),\n\t            log_prob=log_prob,\n\t            cached_mus=cached_mus,\n\t            cached_LSigmas=cached_LSigmas,\n\t            cached_timestamps=cached_timestamps,\n", "        )\n\t    def emit(self, z_t: Tensor) -> Tensor:\n\t        \"\"\"Emit an observation from the latent state.\n\t        Parameters\n\t        ----------\n\t        z_t\n\t            The latent state at a specific time, of shape (batch_size, z_dim)\n\t        Returns\n\t        -------\n\t            The observation at a specific time, of shape (batch_size, y_dim)\n", "        \"\"\"\n\t        R = self.R\n\t        H = self.H[None]\n\t        p_v = MultivariateNormal(\n\t            torch.zeros(1, self.y_dim, device=z_t.device), covariance_matrix=R\n\t        )\n\t        v = p_v.sample((z_t.shape[0],)).view(z_t.shape[0], self.y_dim)\n\t        y = bmbvp(H, z_t) + v\n\t        return y\n\t    @torch.no_grad()\n", "    def forecast(\n\t        self,\n\t        y: Tensor,\n\t        mask: Tensor,\n\t        past_times: Tensor,\n\t        future_times: Tensor,\n\t        num_samples: int = 80,\n\t        no_state_sampling: bool = False,\n\t        use_smooth: bool = False,\n\t        **unused_kwargs,\n", "    ) -> Dict[str, Tensor]:\n\t        \"\"\"Make predictions (imputation and forecast) using the observed data.\n\t        Parameters\n\t        ----------\n\t        y\n\t            The tensor of observations, of shape (batch_size, num_timesteps, y_dim)\n\t        mask\n\t            The mask of missing values (1: observed, 0: missing),\n\t            of shape (batch_size, num_timesteps, y_dim), if sporadic,\n\t            else (batch_size, num_timesteps)\n", "        past_times\n\t            The times of the past observations, of shape (num_past_steps,)\n\t        future_times\n\t            The times of the forecast, of shape (num_forecast_steps,)\n\t        num_samples, optional\n\t            The number of sample paths to draw, by default 80\n\t        no_state_sampling, optional\n\t            Whether to sample from the predicted state distributions,\n\t            by default False and only uses the means of the distributions\n\t        use_smooth, optional\n", "            Whether to perform smoothing after filtering (useful for imputation),\n\t            by default False\n\t        Returns\n\t        -------\n\t            The reconstructed context (imputing values, if required) and the forecast\n\t        \"\"\"\n\t        B, _, _ = y.shape\n\t        filter_result = self.filter(y, mask, past_times, cache_params=use_smooth)\n\t        filtered_mus = filter_result[\"filtered_mus\"]\n\t        filtered_LSigmas = filter_result[\"filtered_LSigmas\"]\n", "        if use_smooth:\n\t            cached_mus = filter_result[\"cached_mus\"]\n\t            cached_LSigmas = filter_result[\"cached_LSigmas\"]\n\t            cached_timestamps = filter_result[\"cached_timestamps\"]\n\t            smoothed_mus, smoothed_LSigmas = cont_disc_smooth(\n\t                filter_mus=cached_mus,\n\t                filter_LSigmas=cached_LSigmas,\n\t                filter_timestamps=cached_timestamps,\n\t                dynamics=self.dynamics,\n\t                method=self.integration_method,\n", "            )\n\t            relevant_indices = torch.isin(cached_timestamps, past_times)\n\t            assert torch.allclose(cached_timestamps[relevant_indices], past_times)\n\t            filtered_mus, filtered_LSigmas = (\n\t                smoothed_mus[relevant_indices],\n\t                smoothed_LSigmas[relevant_indices],\n\t            )\n\t        filter_dists = MultivariateNormal(filtered_mus, scale_tril=filtered_LSigmas)\n\t        z_filtered = filter_dists.sample([num_samples])\n\t        # z_filtered.shape = num_samples x T x B x z_dim\n", "        z_reconstruction = []\n\t        y_reconstruction = []\n\t        for i, t in enumerate(past_times):\n\t            z_t = z_filtered[:, i].reshape(-1, self.z_dim)\n\t            y_t = self.emit(z_t)\n\t            z_reconstruction.append(z_t)\n\t            y_reconstruction.append(y_t)\n\t        z_reconstruction: Tensor = torch.stack(z_reconstruction)\n\t        y_reconstruction: Tensor = torch.stack(y_reconstruction)\n\t        z_reconstruction = z_reconstruction.view(\n", "            past_times.shape[0], num_samples, B, self.z_dim\n\t        )\n\t        y_reconstruction = y_reconstruction.view(\n\t            past_times.shape[0], num_samples, B, self.y_dim\n\t        )\n\t        z_reconstruction = z_reconstruction.permute(1, 2, 0, 3)\n\t        y_reconstruction = y_reconstruction.permute(1, 2, 0, 3)\n\t        (mu, LSigma) = filter_result[\"last_filtered_dist\"]\n\t        future_times = torch.cat([past_times[-1:], future_times], 0)\n\t        mu_t = mu.repeat(num_samples, 1)\n", "        LSigma_t = LSigma.repeat(num_samples, 1, 1)\n\t        y_forecast = []\n\t        z_forecast = []\n\t        for t1, t2 in zip(future_times[:-1], future_times[1:]):\n\t            mu_t2, LSigma_t2, _ = self.predict_step(\n\t                mu=mu_t,\n\t                LSigma=LSigma_t,\n\t                dynamics=self.dynamics,\n\t                t0=t1.item(),\n\t                t1=t2.item(),\n", "                step_size=self.integration_step_size,\n\t                method=self.integration_method,\n\t            )\n\t            pred_dist = MultivariateNormal(mu_t2, scale_tril=LSigma_t2)\n\t            z_t2 = pred_dist.mean if no_state_sampling else pred_dist.sample()\n\t            y_t2 = self.emit(z_t2)\n\t            z_forecast.append(z_t2)\n\t            y_forecast.append(y_t2)\n\t            mu_t = mu_t2\n\t            LSigma_t = LSigma_t2\n", "        z_forecast = torch.stack(z_forecast)\n\t        y_forecast = torch.stack(y_forecast)\n\t        z_forecast = z_forecast.view(\n\t            future_times.shape[0] - 1, num_samples, B, self.z_dim\n\t        )\n\t        y_forecast = y_forecast.view(\n\t            future_times.shape[0] - 1, num_samples, B, self.y_dim\n\t        )\n\t        z_forecast = z_forecast.permute(1, 2, 0, 3)\n\t        y_forecast = y_forecast.permute(1, 2, 0, 3)\n", "        return dict(\n\t            reconstruction=y_reconstruction,\n\t            forecast=y_forecast,\n\t            z_reconstruction=z_reconstruction,\n\t            z_forecast=z_forecast,\n\t        )\n\tclass BaseLTI(nn.Module, Base):\n\t    \"\"\"Base continuous-discrete linear time-invariant state space model.\n\t    Parameters\n\t    ----------\n", "    z_dim\n\t        The dimension of latent state z\n\t    y_dim\n\t        The dimension of observation y\n\t    u_dim\n\t        The dimension of control input u\n\t    F, optional\n\t        The linear dynamics matrix F, by default None\n\t    B, optional\n\t        The linear control matrix B, by default None\n", "    Q, optional\n\t        The state covariance matrix Q, by default None\n\t    H, optional\n\t        The observation matrix H, by default None\n\t    R, optional\n\t        The observation covariance matrix R, by default None\n\t    mu0, optional\n\t        The mean of the initial state distribution, by default None\n\t    Sigma0, optional\n\t        The covariance of the initial state distribution, by default None\n", "    integration_method, optional\n\t        The ODE integration method, should be one of \"euler\" or \"rk4\", by default \"rk4\"\n\t    integration_step_size, optional\n\t        The ODE integration step size, by default 0.1\n\t    sporadic, optional\n\t        A flag to indicate whether the dataset is sporadic,\n\t        i.e., with values missing in both time and feature dimensions, by default False\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n", "        z_dim: int,\n\t        y_dim: int,\n\t        u_dim: int,\n\t        F: Optional[Tensor] = None,\n\t        B: Optional[Tensor] = None,\n\t        Q: Optional[Tensor] = None,\n\t        H: Optional[Tensor] = None,\n\t        R: Optional[Tensor] = None,\n\t        mu0: Optional[Tensor] = None,\n\t        Sigma0: Optional[Tensor] = None,\n", "        integration_method: str = \"rk4\",\n\t        integration_step_size: float = 0.1,\n\t        sporadic: bool = False,\n\t    ):\n\t        super().__init__()\n\t        self.z_dim = z_dim\n\t        self.y_dim = y_dim\n\t        self.u_dim = u_dim\n\t        self.integration_method = integration_method\n\t        self.integration_step_size = integration_step_size\n", "        self.sporadic = sporadic\n\t        self.mu0 = nn.Parameter(\n\t            mu0\n\t            if mu0 is not None\n\t            else torch.zeros(\n\t                z_dim,\n\t            ),\n\t        )\n\t        self.uSigma0 = nn.Parameter(\n\t            torch.log(Sigma0)\n", "            if Sigma0 is not None\n\t            else torch.zeros(\n\t                z_dim,\n\t            )\n\t        )\n\t        F = (\n\t            F\n\t            if F is not None\n\t            else (\n\t                skew_symmetric_init_(torch.empty(z_dim, z_dim))\n", "                if sporadic\n\t                else nn.init.xavier_uniform_(torch.empty(z_dim, z_dim))\n\t            )\n\t        )\n\t        uQ = (\n\t            torch.log(Q)\n\t            if Q is not None\n\t            else torch.zeros(\n\t                z_dim,\n\t            )\n", "        )\n\t        self.dynamics = ContinuousLTI(z_dim=z_dim, u_dim=u_dim, F=F, B=B, uQ=uQ)\n\t        if H is not None:\n\t            self.register_buffer(\"H\", H)\n\t        else:\n\t            self.H = nn.Parameter(nn.init.xavier_uniform_(torch.empty(y_dim, z_dim)))\n\t        self.uR = nn.Parameter(\n\t            torch.log(R)\n\t            if R is not None\n\t            else torch.zeros(\n", "                y_dim,\n\t            )\n\t        )\n\t        self.register_buffer(\"I\", torch.eye(z_dim))\n\t    @property\n\t    def Sigma0(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uSigma0), min=1e-4))\n\t    @property\n\t    def R(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uR), min=1e-4))\n", "    def forward(\n\t        self, y: Tensor, mask: Tensor, times: Tensor, **unused_kwargs\n\t    ) -> Dict[str, Tensor]:\n\t        likelihood = self.filter(y, mask, times)[\"log_prob\"]\n\t        regularizer = torch.tensor(0.0)\n\t        return dict(likelihood=likelihood, regularizer=regularizer)\n\t    def predict_step(\n\t        self,\n\t        mu: Tensor,\n\t        LSigma: Tensor,\n", "        dynamics: Union[ContinuousLTI, ContinuousNL, ContinuousLL],\n\t        t0: float,\n\t        t1: float,\n\t        step_size: float,\n\t        method: str,\n\t        cache_params: bool = False,\n\t        min_step_size: float = 1e-5,\n\t    ):\n\t        return cont_disc_linear_predict(\n\t            mu,\n", "            LSigma,\n\t            dynamics,\n\t            t0,\n\t            t1,\n\t            step_size,\n\t            method,\n\t            cache_params=cache_params,\n\t            min_step_size=min_step_size,\n\t        )\n\t    def update_step(\n", "        self,\n\t        y: Tensor,\n\t        mask: Tensor,\n\t        mu_pred: Tensor,\n\t        LSigma_pred: Tensor,\n\t        H: Tensor,\n\t        R: Tensor,\n\t        sporadic: bool = False,\n\t    ):\n\t        return cont_disc_linear_update(y, mask, mu_pred, LSigma_pred, H, R, sporadic)\n", "class BaseLL(nn.Module, Base):\n\t    \"\"\"Base continuous-discrete locally-linear state space model.\n\t    Parameters\n\t    ----------\n\t    K\n\t        The number of base matrices (i.e., dynamics)\n\t    z_dim\n\t        The dimension of latent state z\n\t    y_dim\n\t        The dimension of observation y\n", "    u_dim\n\t        The dimension of control input u\n\t    alpha_net\n\t        A mixing network that takes the state `z` as input\n\t        and outputs the mixing coefficients for the base dynamics\n\t    F, optional\n\t        The linear dynamics matrix F, by default None\n\t    B, optional\n\t        The linear control matrix B, by default None\n\t    Q, optional\n", "        The state covariance matrix Q, by default None\n\t    H, optional\n\t        The observation matrix H, by default None\n\t    R, optional\n\t        The observation covariance matrix R, by default None\n\t    mu0, optional\n\t        The mean of the initial state distribution, by default None\n\t    Sigma0, optional\n\t        The covariance of the initial state distribution, by default None\n\t    integration_method, optional\n", "        The ODE integration method, should be one of \"euler\" or \"rk4\", by default \"rk4\"\n\t    integration_step_size, optional\n\t        The ODE integration step size, by default 0.1\n\t    sporadic, optional\n\t        A flag to indicate whether the dataset is sporadic,\n\t        i.e., with values missing in both time and feature dimensions, by default False\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        K: int,\n", "        z_dim: int,\n\t        y_dim: int,\n\t        u_dim: int,\n\t        alpha_net: nn.Module,\n\t        F: Optional[Tensor] = None,\n\t        B: Optional[Tensor] = None,\n\t        Q: Optional[Tensor] = None,\n\t        H: Optional[Tensor] = None,\n\t        R: Optional[Tensor] = None,\n\t        mu0: Optional[Tensor] = None,\n", "        Sigma0: Optional[Tensor] = None,\n\t        integration_method: str = \"rk4\",\n\t        integration_step_size: float = 0.1,\n\t        sporadic: bool = False,\n\t    ):\n\t        super().__init__()\n\t        self.K = K\n\t        self.z_dim = z_dim\n\t        self.y_dim = y_dim\n\t        self.u_dim = u_dim\n", "        self.integration_method = integration_method\n\t        self.integration_step_size = integration_step_size\n\t        self.sporadic = sporadic\n\t        self.mu0 = nn.Parameter(\n\t            mu0\n\t            if mu0 is not None\n\t            else torch.zeros(\n\t                z_dim,\n\t            ),\n\t        )  # shared across the K base dynamics\n", "        self.uSigma0 = nn.Parameter(\n\t            torch.log(Sigma0)\n\t            if Sigma0 is not None\n\t            else torch.zeros(\n\t                z_dim,\n\t            )\n\t        )  # shared across the K base dynamics\n\t        F = F if F is not None else nn.init.orthogonal_(torch.empty(K, z_dim, z_dim))\n\t        uQ = (\n\t            torch.log(Q)\n", "            if Q is not None\n\t            else torch.zeros(\n\t                z_dim,\n\t            )\n\t        )  # shared across the K base dynamics\n\t        self.dynamics = ContinuousLL(\n\t            z_dim=z_dim,\n\t            u_dim=u_dim,\n\t            K=K,\n\t            F=F,\n", "            B=B,\n\t            uQ=uQ,\n\t            alpha_net=alpha_net,\n\t        )\n\t        # H is shared across the K base dynamics\n\t        if H is not None:\n\t            self.register_buffer(\"H\", H)\n\t        else:\n\t            self.H = nn.Parameter(nn.init.xavier_uniform_(torch.empty(y_dim, z_dim)))\n\t        self.uR = nn.Parameter(\n", "            torch.log(R)\n\t            if R is not None\n\t            else torch.zeros(\n\t                y_dim,\n\t            )\n\t        )  # shared across the K base dynamics\n\t        self.register_buffer(\"I\", torch.eye(z_dim))\n\t    @property\n\t    def Sigma0(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uSigma0), min=1e-4))\n", "    @property\n\t    def R(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uR), min=1e-4))\n\t    def forward(self, y: Tensor, mask: Tensor, times: Tensor, **unused_kwargs):\n\t        likelihood = self.filter(y, mask, times)[\"log_prob\"]\n\t        regularizer = torch.tensor(0.0)\n\t        return dict(likelihood=likelihood, regularizer=regularizer)\n\t    def predict_step(\n\t        self,\n\t        mu: Tensor,\n", "        LSigma: Tensor,\n\t        dynamics: Union[ContinuousLTI, ContinuousNL, ContinuousLL],\n\t        t0: float,\n\t        t1: float,\n\t        step_size: float,\n\t        method: str,\n\t        cache_params: bool = False,\n\t        min_step_size: float = 1e-5,\n\t    ):\n\t        return cont_disc_locallylinear_predict(\n", "            mu,\n\t            LSigma,\n\t            dynamics,\n\t            t0,\n\t            t1,\n\t            step_size,\n\t            method,\n\t            cache_params=cache_params,\n\t            min_step_size=min_step_size,\n\t        )\n", "    def update_step(\n\t        self,\n\t        y: Tensor,\n\t        mask: Tensor,\n\t        mu_pred: Tensor,\n\t        LSigma_pred: Tensor,\n\t        H: Tensor,\n\t        R: Tensor,\n\t        sporadic: bool = False,\n\t    ):\n", "        return cont_disc_locallylinear_update(\n\t            y, mask, mu_pred, LSigma_pred, H, R, sporadic\n\t        )\n\t    @torch.no_grad()\n\t    def forecast(\n\t        self,\n\t        y: Tensor,\n\t        mask: Tensor,\n\t        past_times: Tensor,\n\t        future_times: Tensor,\n", "        num_samples: int = 80,\n\t        no_state_sampling: bool = False,\n\t        use_smooth: bool = False,\n\t        **unused_kwargs,\n\t    ):\n\t        \"\"\"Same as :func:`Base.forecast` but additionally returns\n\t        the mixing coefficients (alpha).\n\t        \"\"\"\n\t        B, T, _ = y.shape\n\t        filter_result = self.filter(y, mask, past_times, cache_params=use_smooth)\n", "        filtered_mus = filter_result[\"filtered_mus\"]\n\t        filtered_LSigmas = filter_result[\"filtered_LSigmas\"]\n\t        if use_smooth:\n\t            cached_mus = filter_result[\"cached_mus\"]\n\t            cached_LSigmas = filter_result[\"cached_LSigmas\"]\n\t            cached_timestamps = filter_result[\"cached_timestamps\"]\n\t            smoothed_mus, smoothed_LSigmas = cont_disc_smooth(\n\t                filter_mus=cached_mus,\n\t                filter_LSigmas=cached_LSigmas,\n\t                filter_timestamps=cached_timestamps,\n", "                dynamics=self.dynamics,\n\t                method=self.integration_method,\n\t            )\n\t            relevant_indices = torch.isin(cached_timestamps, past_times)\n\t            assert torch.allclose(cached_timestamps[relevant_indices], past_times)\n\t            filtered_mus, filtered_LSigmas = (\n\t                smoothed_mus[relevant_indices],\n\t                smoothed_LSigmas[relevant_indices],\n\t            )\n\t        filter_dists = MultivariateNormal(filtered_mus, scale_tril=filtered_LSigmas)\n", "        z_filtered = filter_dists.sample([num_samples])\n\t        # z_filtered.shape = num_samples x T x B x z_dim\n\t        z_reconstruction = []\n\t        y_reconstruction = []\n\t        alpha_reconstruction = []\n\t        for i, t in enumerate(past_times):\n\t            z_t = z_filtered[:, i].reshape(-1, self.z_dim)\n\t            alpha_t = self.dynamics.alpha_net(z_t)\n\t            y_t = self.emit(z_t)\n\t            z_reconstruction.append(z_t)\n", "            alpha_reconstruction.append(alpha_t)\n\t            y_reconstruction.append(y_t)\n\t        z_reconstruction = torch.stack(z_reconstruction)\n\t        alpha_reconstruction = torch.stack(alpha_reconstruction)\n\t        y_reconstruction = torch.stack(y_reconstruction)\n\t        z_reconstruction = z_reconstruction.view(\n\t            past_times.shape[0], num_samples, B, self.z_dim\n\t        )\n\t        alpha_reconstruction = alpha_reconstruction.view(\n\t            past_times.shape[0], num_samples, B, self.K\n", "        )\n\t        y_reconstruction = y_reconstruction.view(\n\t            past_times.shape[0], num_samples, B, self.y_dim\n\t        )\n\t        z_reconstruction = z_reconstruction.permute(1, 2, 0, 3)\n\t        alpha_reconstruction = alpha_reconstruction.permute(1, 2, 0, 3)\n\t        y_reconstruction = y_reconstruction.permute(1, 2, 0, 3)\n\t        (mu, LSigma) = filter_result[\"last_filtered_dist\"]\n\t        future_times = torch.cat([past_times[-1:], future_times], 0)\n\t        mu_t = mu.repeat(num_samples, 1)\n", "        LSigma_t = LSigma.repeat(num_samples, 1, 1)\n\t        y_forecast = []\n\t        alpha_forecast = []\n\t        z_forecast = []\n\t        for t1, t2 in zip(future_times[:-1], future_times[1:]):\n\t            mu_t2, LSigma_t2, _ = self.predict_step(\n\t                mu=mu_t,\n\t                LSigma=LSigma_t,\n\t                dynamics=self.dynamics,\n\t                t0=t1.item(),\n", "                t1=t2.item(),\n\t                step_size=self.integration_step_size,\n\t                method=self.integration_method,\n\t            )\n\t            pred_dist = MultivariateNormal(mu_t2, scale_tril=LSigma_t2)\n\t            z_t2 = pred_dist.mean if no_state_sampling else pred_dist.sample()\n\t            alpha_t2 = self.dynamics.alpha_net(z_t2)\n\t            y_t2 = self.emit(z_t2)\n\t            z_forecast.append(z_t2)\n\t            alpha_forecast.append(alpha_t2)\n", "            y_forecast.append(y_t2)\n\t            mu_t = mu_t2\n\t            LSigma_t = LSigma_t2\n\t        z_forecast = torch.stack(z_forecast)\n\t        alpha_forecast = torch.stack(alpha_forecast)\n\t        y_forecast = torch.stack(y_forecast)\n\t        z_forecast = z_forecast.view(\n\t            future_times.shape[0] - 1, num_samples, B, self.z_dim\n\t        )\n\t        alpha_forecast = alpha_forecast.view(\n", "            future_times.shape[0] - 1, num_samples, B, self.K\n\t        )\n\t        y_forecast = y_forecast.view(\n\t            future_times.shape[0] - 1, num_samples, B, self.y_dim\n\t        )\n\t        z_forecast = z_forecast.permute(1, 2, 0, 3)\n\t        alpha_forecast = alpha_forecast.permute(1, 2, 0, 3)\n\t        y_forecast = y_forecast.permute(1, 2, 0, 3)\n\t        return dict(\n\t            reconstruction=y_reconstruction,\n", "            forecast=y_forecast,\n\t            z_reconstruction=z_reconstruction,\n\t            z_forecast=z_forecast,\n\t            alpha_reconstruction=alpha_reconstruction,\n\t            alpha_forecast=alpha_forecast,\n\t        )\n\tclass BaseNL(nn.Module, Base):\n\t    \"\"\"Base continuous-discrete non-linear state space model.\n\t    Parameters\n\t    ----------\n", "    z_dim\n\t        The dimension of latent state z\n\t    y_dim\n\t        The dimension of observation y\n\t    u_dim\n\t        The dimension of control input u\n\t    f, optional\n\t        The dynamics/drift function f(z), by default None\n\t    gs, optional\n\t        The list of diffusion functions g(z), one for each z_dim, by default None\n", "    B, optional\n\t        The linear control matrix B, by default None\n\t    H, optional\n\t        The observation matrix H, by default None\n\t    R, optional\n\t        The observation covariance matrix R, by default None\n\t    mu0, optional\n\t        The mean of the initial state distribution, by default None\n\t    Sigma0, optional\n\t        The covariance of the initial state distribution, by default None\n", "    integration_method, optional\n\t        The ODE integration method, should be one of \"euler\" or \"rk4\", by default \"rk4\"\n\t    integration_step_size, optional\n\t        The ODE integration step size, by default 0.1\n\t    sporadic, optional\n\t        A flag to indicate whether the dataset is sporadic,\n\t        i.e., with values missing in both time and feature dimensions, by default False\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n", "        z_dim: int,\n\t        y_dim: int,\n\t        u_dim: int,\n\t        f: nn.Module,\n\t        gs: Optional[List[nn.Module]] = None,\n\t        B: Optional[Tensor] = None,\n\t        H: Optional[Tensor] = None,\n\t        R: Optional[Tensor] = None,\n\t        mu0: Optional[Tensor] = None,\n\t        Sigma0: Optional[Tensor] = None,\n", "        integration_method: str = \"rk4\",\n\t        integration_step_size: float = 0.1,\n\t        sporadic: bool = False,\n\t    ):\n\t        super().__init__()\n\t        self.z_dim = z_dim\n\t        self.y_dim = y_dim\n\t        self.u_dim = u_dim\n\t        self.integration_method = integration_method\n\t        self.integration_step_size = integration_step_size\n", "        self.sporadic = sporadic\n\t        self.mu0 = nn.Parameter(\n\t            mu0\n\t            if mu0 is not None\n\t            else nn.init.normal_(\n\t                torch.empty(\n\t                    z_dim,\n\t                ),\n\t                std=0.01,\n\t            )\n", "        )  # shared\n\t        self.uSigma0 = nn.Parameter(\n\t            torch.log(Sigma0)\n\t            if Sigma0 is not None\n\t            else torch.zeros(\n\t                z_dim,\n\t            )\n\t        )  # shared\n\t        self.dynamics = ContinuousNL(z_dim=z_dim, u_dim=u_dim, f=f, gs=gs, B=B)\n\t        # TODO: Fix initialization of params\n", "        # If passed as args, they should be fixed\n\t        if H is not None:\n\t            self.register_buffer(\"H\", H)\n\t        else:\n\t            self.H = nn.Parameter(nn.init.xavier_uniform_(torch.empty(y_dim, z_dim)))\n\t        self.uR = nn.Parameter(\n\t            torch.log(R)\n\t            if R is not None\n\t            else torch.zeros(\n\t                y_dim,\n", "            )\n\t        )  # shared\n\t        self.register_buffer(\"I\", torch.eye(z_dim))\n\t    @property\n\t    def Sigma0(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uSigma0), min=1e-4))\n\t    @property\n\t    def R(self):\n\t        return torch.diag(torch.clamp(torch.exp(self.uR), min=1e-4))\n\t    def forward(self, y: Tensor, mask: Tensor, times: Tensor, **unused_kwargs):\n", "        likelihood = self.filter(y, mask, times)[\"log_prob\"]\n\t        regularizer = torch.tensor(0.0)\n\t        return dict(likelihood=likelihood, regularizer=regularizer)\n\t    def predict_step(\n\t        self,\n\t        mu: Tensor,\n\t        LSigma: Tensor,\n\t        dynamics: Union[ContinuousLTI, ContinuousNL, ContinuousLL],\n\t        t0: float,\n\t        t1: float,\n", "        step_size: float,\n\t        method: str,\n\t        cache_params: bool = False,\n\t        min_step_size: float = 1e-5,\n\t    ):\n\t        return cont_disc_nonlinear_predict(\n\t            mu,\n\t            LSigma,\n\t            dynamics,\n\t            t0,\n", "            t1,\n\t            step_size,\n\t            method,\n\t            cache_params=cache_params,\n\t            min_step_size=min_step_size,\n\t        )\n\t    def update_step(\n\t        self,\n\t        y: Tensor,\n\t        mask: Tensor,\n", "        mu_pred: Tensor,\n\t        LSigma_pred: Tensor,\n\t        H: Tensor,\n\t        R: Tensor,\n\t        sporadic: bool = False,\n\t    ):\n\t        return cont_disc_nonlinear_update(y, mask, mu_pred, LSigma_pred, H, R, sporadic)\n"]}
{"filename": "src/ncdssm/models/components.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport torch.distributions as td\n\tfrom torch.nn.functional import softplus\n\tfrom ..functions import inverse_softplus\n\tclass GaussianOutput(nn.Module):\n\t    def __init__(\n\t        self,\n\t        network,\n\t        dist_dim,\n", "        use_tied_cov=False,\n\t        use_trainable_cov=True,\n\t        sigma=0.1,\n\t        use_independent=True,\n\t        scale_function=\"exp\",\n\t        min_scale=0.01,\n\t    ):\n\t        super().__init__()\n\t        assert scale_function in {\"exp\", \"softplus\"}\n\t        self.scale_function = scale_function\n", "        self.dist_dim = dist_dim\n\t        self.network = network\n\t        self.use_tied_cov = use_tied_cov\n\t        self.use_trainable_cov = use_trainable_cov\n\t        self.use_independent = use_independent\n\t        self.min_scale = min_scale\n\t        if not self.use_trainable_cov:\n\t            self.sigma = sigma\n\t        if self.use_trainable_cov and self.use_tied_cov:\n\t            if scale_function == \"softplus\":\n", "                init_sigma = inverse_softplus(torch.full([1, dist_dim], sigma))\n\t            else:\n\t                init_sigma = torch.zeros([1, dist_dim])\n\t            self.usigma = nn.Parameter(init_sigma)\n\t    def forward(self, tensor):\n\t        args_tensor = self.network(tensor)\n\t        mean_tensor = args_tensor[..., : self.dist_dim]\n\t        if self.use_trainable_cov:\n\t            if self.use_tied_cov:\n\t                if self.scale_function == \"softplus\":\n", "                    scale_tensor = softplus(self.usigma)\n\t                else:\n\t                    scale_tensor = torch.exp(self.usigma)\n\t                scale_tensor = torch.clamp(scale_tensor, min=self.min_scale)\n\t                out_dist = td.normal.Normal(mean_tensor, scale_tensor)\n\t                if self.use_independent:\n\t                    out_dist = td.independent.Independent(out_dist, 1)\n\t            else:\n\t                if self.scale_function == \"softplus\":\n\t                    scale_tensor = softplus(args_tensor[..., self.dist_dim :])\n", "                else:\n\t                    scale_tensor = torch.exp(args_tensor[..., self.dist_dim :])\n\t                scale_tensor = torch.clamp(scale_tensor, min=self.min_scale)\n\t                out_dist = td.normal.Normal(mean_tensor, scale_tensor)\n\t                if self.use_independent:\n\t                    out_dist = td.independent.Independent(out_dist, 1)\n\t        else:\n\t            out_dist = td.normal.Normal(mean_tensor, self.sigma)\n\t            if self.use_independent:\n\t                out_dist = td.independent.Independent(out_dist, 1)\n", "        return out_dist\n\tclass BernoulliOutput(nn.Module):\n\t    def __init__(self, network, dist_dim, use_indepedent=True):\n\t        super().__init__()\n\t        self.network = network\n\t        self.dist_dim = dist_dim\n\t        self.use_indepedent = use_indepedent\n\t    def forward(self, x):\n\t        h = self.network(x)\n\t        assert h.shape[-1] == self.dist_dim\n", "        dist = td.Bernoulli(logits=h)\n\t        if self.use_indepedent:\n\t            dist = td.Independent(dist, 1)\n\t        return dist\n\tclass AuxInferenceModel(nn.Module):\n\t    def __init__(\n\t        self,\n\t        base_network: nn.Module,\n\t        dist_network: nn.Module,\n\t        aux_dim: int,\n", "        concat_mask: bool = False,\n\t    ):\n\t        super().__init__()\n\t        self.aux_dim = aux_dim\n\t        self.base_network = base_network\n\t        self.dist_network = dist_network\n\t        self.concat_mask = concat_mask\n\t    def forward(\n\t        self,\n\t        y: torch.Tensor,\n", "        mask: torch.Tensor,\n\t        num_samples: int = 1,\n\t        deterministic: bool = False,\n\t    ):\n\t        assert y.ndim >= 3\n\t        if self.concat_mask:\n\t            assert y.size() == mask.size()\n\t            # Concatenate mask to feature dim\n\t            y = torch.cat([y, mask], dim=-1)\n\t            # Convert feature mask to at least one feature presence mask\n", "            # i.e. mask = 1 if at least one feature is present at that time\n\t            # step.\n\t            mask = (mask.sum(dim=-1) > 0).float()\n\t        sporadic = False\n\t        if y.ndim > mask.ndim:\n\t            mask = mask.unsqueeze(-1)\n\t        else:\n\t            sporadic = True\n\t        h = self.base_network(y)\n\t        h = h * mask\n", "        dist = self.dist_network(h)\n\t        if deterministic:\n\t            aux_samples = dist.mean.unsqueeze(0)\n\t            one_args = (1,) * dist.mean.ndim\n\t            aux_samples = aux_samples.repeat(num_samples, *one_args)\n\t        else:\n\t            aux_samples = dist.rsample((num_samples,))\n\t        aux_samples = aux_samples * mask\n\t        if sporadic:\n\t            aux_entropy = (dist.base_dist.entropy() * mask).sum(dim=-1)\n", "            aux_log_prob = (dist.base_dist.log_prob(aux_samples) * mask).sum(dim=-1)\n\t        else:\n\t            aux_entropy = dist.entropy()\n\t            aux_log_prob = dist.log_prob(aux_samples)\n\t            aux_entropy = aux_entropy * mask.squeeze(-1)\n\t            aux_log_prob = aux_log_prob * mask.squeeze(-1)\n\t        aux_entropy = aux_entropy[None].repeat(num_samples, 1, 1)\n\t        return (\n\t            aux_samples,  # .shape = N, B, T, aux_dim\n\t            aux_entropy,  # .shape = N, B, T\n", "            aux_log_prob,  # .shape = N, B, T\n\t        )\n"]}
{"filename": "src/ncdssm/models/__init__.py", "chunked_list": ["from .base import BaseLTI, BaseLL, BaseNL\n\tfrom .ncdssm import NCDSSMLTI, NCDSSMLL, NCDSSMNL\n\t__all__ = [\n\t    \"BaseLTI\",\n\t    \"NCDSSMLTI\",\n\t    \"BaseLL\",\n\t    \"NCDSSMLL\",\n\t    \"BaseNL\",\n\t    \"NCDSSMNL\",\n\t]\n"]}
{"filename": "src/ncdssm/models/ncdssm.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\timport numpy as np\n\tfrom .components import AuxInferenceModel\n\tfrom .base import BaseNL, BaseLTI, BaseLL\n\tfrom ..torch_utils import merge_leading_dims\n\tfrom ..type import Tensor, Optional, List\n\tclass NCDSSM(nn.Module):\n\t    \"\"\"Base class for NCDSSM models.\n\t    Parameters\n", "    ----------\n\t    aux_inference_net\n\t        The auxiliary inference model parameterized by a neural network\n\t    y_emission_net\n\t        The emission model parameterized by a neural network\n\t    aux_dim\n\t        The dimension of the auxiliary variables\n\t    z_dim\n\t        The dimension of the latent states\n\t    y_dim\n", "        The dimension of the observations\n\t    u_dim\n\t        The dimension of the control inputs\n\t    integration_method, optional\n\t        The integration method, can be one of \"euler\" or \"rk4\",\n\t        by default \"rk4\"\n\t    integration_step_size, optional\n\t        The integration step size, by default 0.1\n\t    sporadic, optional\n\t        A flag to indicate whether the dataset is sporadic,\n", "        i.e., with values missing in both time and feature dimensions,\n\t        by default False\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        aux_inference_net: nn.Module,\n\t        y_emission_net: nn.Module,\n\t        aux_dim: int,\n\t        z_dim: int,\n\t        y_dim: int,\n", "        u_dim: int,\n\t        integration_method: str = \"rk4\",\n\t        integration_step_size: float = 0.1,\n\t        sporadic: bool = False,\n\t        **kwargs,\n\t    ):\n\t        super().__init__()\n\t        assert u_dim == 0, \"Support for control inputs is not implemented yet\"\n\t        self.aux_inference_net = aux_inference_net\n\t        self.y_emission_net = y_emission_net\n", "        self.aux_dim = aux_dim\n\t        self.z_dim = z_dim\n\t        self.y_dim = y_dim\n\t        self.u_dim = u_dim\n\t        self.integration_method = integration_method\n\t        self.integration_step_size = integration_step_size\n\t        self.sporadic = sporadic\n\t    def forward(\n\t        self,\n\t        y: Tensor,\n", "        mask: Tensor,\n\t        times: Tensor,\n\t        num_samples: int = 1,\n\t        deterministic: bool = False,\n\t    ):\n\t        assert (\n\t            y.size() == mask.size() or y.size()[:-1] == mask.size()\n\t        ), \"Shapes of y and mask should match!\"\n\t        # Currently assumes that t = 0 is in times\n\t        assert times[0] == 0.0, \"First timestep should be 0!\"\n", "        batch_size = y.size(0)\n\t        aux_samples, aux_entropy, aux_post_log_prob = self.aux_inference_net(\n\t            y,\n\t            mask,\n\t            num_samples=num_samples,\n\t            deterministic=deterministic,\n\t        )\n\t        aux_samples = merge_leading_dims(aux_samples, ndims=2)\n\t        aux_entropy = merge_leading_dims(aux_entropy, ndims=2)\n\t        aux_post_log_prob = merge_leading_dims(aux_post_log_prob, ndims=2)\n", "        # Compute likelihoods\n\t        if mask.ndim < y.ndim:\n\t            mask = mask.unsqueeze(-1)\n\t        repeated_mask = mask.repeat(num_samples, 1, 1)\n\t        emission_dist = self.y_emission_net(aux_samples)\n\t        y_log_likelihood = emission_dist.log_prob(y.repeat(num_samples, 1, 1))\n\t        y_log_likelihood = y_log_likelihood * repeated_mask\n\t        y_log_likelihood = y_log_likelihood.sum(-1).sum(-1)\n\t        filter_result = self.base_ssm.filter(\n\t            aux_samples,\n", "            repeated_mask if self.sporadic else (repeated_mask.sum(-1) > 0).float(),\n\t            times,\n\t        )\n\t        aux_log_likelihood = filter_result[\"log_prob\"]\n\t        aux_entropy = aux_entropy.sum(dim=-1)\n\t        # Compute ELBO\n\t        regularizer = aux_log_likelihood + aux_entropy\n\t        elbo = y_log_likelihood + regularizer\n\t        # Compute IWELBO\n\t        iwelbo = torch.logsumexp(\n", "            y_log_likelihood.view(num_samples, batch_size)\n\t            + aux_log_likelihood.view(num_samples, batch_size)\n\t            - aux_post_log_prob.sum(dim=-1).view(num_samples, batch_size),\n\t            dim=0,\n\t        ) - np.log(num_samples)\n\t        return dict(\n\t            elbo=elbo,\n\t            iwelbo=iwelbo,\n\t            likelihood=y_log_likelihood,\n\t            regularizer=regularizer,\n", "        )\n\t    @torch.no_grad()\n\t    def forecast(\n\t        self,\n\t        y: Tensor,\n\t        mask: Tensor,\n\t        past_times: Tensor,\n\t        future_times: Tensor,\n\t        num_samples: int = 80,\n\t        deterministic: bool = False,\n", "        no_state_sampling: bool = False,\n\t        use_smooth: bool = False,\n\t    ):\n\t        \"\"\"Make predictions (imputation and forecast) using the observed data.\n\t        Parameters\n\t        ----------\n\t        y\n\t            The tensor of observations, of shape (batch_size, num_timesteps, y_dim)\n\t        mask\n\t            The mask of missing values (1: observed, 0: missing),\n", "            of shape (batch_size, num_timesteps, y_dim), if sporadic,\n\t            else (batch_size, num_timesteps)\n\t        past_times\n\t            The times of the past observations, of shape (num_past_steps,)\n\t        future_times\n\t            The times of the forecast, of shape (num_forecast_steps,)\n\t        num_samples, optional\n\t            The number of sample paths to draw, by default 80\n\t        deterministic, optional\n\t            Whether to peform deterministic sampling from auxiliary model,\n", "            by default False (not really used)\n\t        no_state_sampling, optional\n\t            Whether to sample from the predicted state distributions,\n\t            by default False and only uses the means of the distributions\n\t        use_smooth, optional\n\t            Whether to perform smoothing after filtering (useful for imputation),\n\t            by default False\n\t        Returns\n\t        -------\n\t            The reconstructed context (imputing values, if required) and the forecast\n", "        \"\"\"\n\t        B, T, _ = y.shape\n\t        aux_samples, _, _ = self.aux_inference_net(\n\t            y,\n\t            mask,\n\t            num_samples=1,\n\t            deterministic=deterministic,\n\t        )\n\t        # aux_samples.shape = num_samples x B x time x aux_dim\n\t        aux_samples = merge_leading_dims(aux_samples, ndims=2)\n", "        if mask.ndim < y.ndim:\n\t            mask = mask.unsqueeze(-1)\n\t        # Generate predictions from the base CDKF\n\t        base_predictions = self.base_ssm.forecast(\n\t            aux_samples,\n\t            mask if self.sporadic else (mask.sum(-1) > 0).float(),\n\t            past_times,\n\t            future_times,\n\t            num_samples=num_samples,\n\t            no_state_sampling=no_state_sampling,\n", "            use_smooth=use_smooth,\n\t        )\n\t        aux_reconstruction = base_predictions[\"reconstruction\"]\n\t        aux_forecast = base_predictions[\"forecast\"]\n\t        z_reconstruction = base_predictions[\"z_reconstruction\"]\n\t        z_forecast = base_predictions[\"z_forecast\"]\n\t        # Decode aux --> y\n\t        reconstruction_emit_dist = self.y_emission_net(\n\t            merge_leading_dims(aux_reconstruction, ndims=2)\n\t        )\n", "        y_reconstruction = reconstruction_emit_dist.sample()\n\t        y_reconstruction = y_reconstruction.view(\n\t            num_samples, B, aux_reconstruction.shape[-2], self.y_dim\n\t        )\n\t        forecast_emit_dist = self.y_emission_net(\n\t            merge_leading_dims(aux_forecast, ndims=2)\n\t        )\n\t        y_forecast = forecast_emit_dist.sample()\n\t        y_forecast = y_forecast.view(num_samples, B, aux_forecast.shape[-2], self.y_dim)\n\t        return dict(\n", "            reconstruction=y_reconstruction,\n\t            forecast=y_forecast,\n\t            z_reconstruction=z_reconstruction,\n\t            z_forecast=z_forecast,\n\t            aux_reconstruction=aux_reconstruction,\n\t            aux_forecast=aux_forecast,\n\t        )\n\tclass NCDSSMLTI(NCDSSM):\n\t    \"\"\"The NCDSSM model with linear time-invariant dynamics.\n\t    Parameters\n", "    ----------\n\t    aux_inference_net\n\t        The auxiliary inference model parameterized by a neural network\n\t    y_emission_net\n\t        The emission model parameterized by a neural network\n\t    aux_dim\n\t        The dimension of the auxiliary variables\n\t    z_dim\n\t        The dimension of the latent states\n\t    y_dim\n", "        The dimension of the observations\n\t    u_dim\n\t        The dimension of the control inputs\n\t    integration_method, optional\n\t        The integration method, can be one of \"euler\" or \"rk4\",\n\t        by default \"rk4\"\n\t    integration_step_size, optional\n\t        The integration step size, by default 0.1\n\t    sporadic, optional\n\t        A flag to indicate whether the dataset is sporadic,\n", "        i.e., with values missing in both time and feature dimensions,\n\t        by default False\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        aux_inference_net: nn.Module,\n\t        y_emission_net: nn.Module,\n\t        aux_dim: int,\n\t        z_dim: int,\n\t        y_dim: int,\n", "        u_dim: int,\n\t        integration_method: str = \"rk4\",\n\t        integration_step_size: float = 0.1,\n\t        sporadic: bool = False,\n\t        **kwargs,\n\t    ):\n\t        super().__init__(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim,\n", "            z_dim,\n\t            y_dim,\n\t            u_dim,\n\t            integration_method,\n\t            integration_step_size,\n\t            sporadic,\n\t            **kwargs,\n\t        )\n\t        self.base_ssm = BaseLTI(\n\t            z_dim=z_dim,\n", "            y_dim=aux_dim,\n\t            u_dim=u_dim,\n\t            integration_method=integration_method,\n\t            integration_step_size=integration_step_size,\n\t            sporadic=sporadic,\n\t            **kwargs,\n\t        )\n\tclass NCDSSMLL(NCDSSM):\n\t    \"\"\"The NCDSSM model with locally-linear dynamics.\n\t    Parameters\n", "    ----------\n\t    aux_inference_net\n\t        The auxiliary inference model parameterized by a neural network\n\t    y_emission_net\n\t        The emission model parameterized by a neural network\n\t    aux_dim\n\t        The dimension of the auxiliary variables\n\t    K\n\t        The number of base matrices (i.e., dynamics)\n\t    z_dim\n", "        The dimension of the latent states\n\t    y_dim\n\t        The dimension of the observations\n\t    u_dim\n\t        The dimension of the control inputs\n\t    alpha_net\n\t        A mixing network that takes the state `z` as input\n\t        and outputs the mixing coefficients for the base dynamics\n\t    integration_method, optional\n\t        The integration method, can be one of \"euler\" or \"rk4\",\n", "        by default \"rk4\"\n\t    integration_step_size, optional\n\t        The integration step size, by default 0.1\n\t    sporadic, optional\n\t        A flag to indicate whether the dataset is sporadic,\n\t        i.e., with values missing in both time and feature dimensions,\n\t        by default False\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n", "        aux_inference_net: AuxInferenceModel,\n\t        y_emission_net: nn.Module,\n\t        aux_dim: int,\n\t        K: int,\n\t        z_dim: int,\n\t        y_dim: int,\n\t        u_dim: int,\n\t        alpha_net: nn.Module,\n\t        integration_method: str = \"rk4\",\n\t        integration_step_size: float = 0.1,\n", "        sporadic: bool = False,\n\t        **kwargs,\n\t    ):\n\t        super().__init__(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim,\n\t            z_dim,\n\t            y_dim,\n\t            u_dim,\n", "            integration_method,\n\t            integration_step_size,\n\t            sporadic,\n\t            **kwargs,\n\t        )\n\t        self.base_ssm = BaseLL(\n\t            K=K,\n\t            z_dim=z_dim,\n\t            y_dim=aux_dim,\n\t            u_dim=u_dim,\n", "            alpha_net=alpha_net,\n\t            integration_method=integration_method,\n\t            integration_step_size=integration_step_size,\n\t            sporadic=sporadic,\n\t            **kwargs,\n\t        )\n\t    @torch.no_grad()\n\t    def forecast(\n\t        self,\n\t        y: Tensor,\n", "        mask: Tensor,\n\t        past_times: Tensor,\n\t        future_times: Tensor,\n\t        num_samples: int = 80,\n\t        deterministic: bool = False,\n\t        no_state_sampling: bool = False,\n\t        use_smooth: bool = False,\n\t    ):\n\t        B, T, _ = y.shape\n\t        aux_samples, _, _ = self.aux_inference_net(\n", "            y,\n\t            mask,\n\t            num_samples=1,\n\t            deterministic=deterministic,\n\t        )\n\t        # aux_samples.shape = num_samples x B x time x aux_dim\n\t        aux_samples = merge_leading_dims(aux_samples, ndims=2)\n\t        if mask.ndim < y.ndim:\n\t            mask = mask.unsqueeze(-1)\n\t        # Generate predictions from the base CDKF\n", "        base_predictions = self.base_ssm.forecast(\n\t            aux_samples,\n\t            mask if self.sporadic else (mask.sum(-1) > 0).float(),\n\t            past_times,\n\t            future_times,\n\t            num_samples=num_samples,\n\t            no_state_sampling=no_state_sampling,\n\t            use_smooth=use_smooth,\n\t        )\n\t        aux_reconstruction = base_predictions[\"reconstruction\"]\n", "        aux_forecast = base_predictions[\"forecast\"]\n\t        z_reconstruction = base_predictions[\"z_reconstruction\"]\n\t        z_forecast = base_predictions[\"z_forecast\"]\n\t        alpha_reconstruction = base_predictions[\"alpha_reconstruction\"]\n\t        alpha_forecast = base_predictions[\"alpha_forecast\"]\n\t        # Decode aux --> y\n\t        reconstruction_emit_dist = self.y_emission_net(\n\t            merge_leading_dims(aux_reconstruction, ndims=2)\n\t        )\n\t        y_reconstruction = reconstruction_emit_dist.sample()\n", "        y_reconstruction = y_reconstruction.view(\n\t            num_samples, B, aux_reconstruction.shape[-2], self.y_dim\n\t        )\n\t        forecast_emit_dist = self.y_emission_net(\n\t            merge_leading_dims(aux_forecast, ndims=2)\n\t        )\n\t        y_forecast = forecast_emit_dist.sample()\n\t        y_forecast = y_forecast.view(num_samples, B, aux_forecast.shape[-2], self.y_dim)\n\t        return dict(\n\t            reconstruction=y_reconstruction,\n", "            forecast=y_forecast,\n\t            z_reconstruction=z_reconstruction,\n\t            z_forecast=z_forecast,\n\t            alpha_reconstruction=alpha_reconstruction,\n\t            alpha_forecast=alpha_forecast,\n\t            aux_reconstruction=aux_reconstruction,\n\t            aux_forecast=aux_forecast,\n\t        )\n\tclass NCDSSMNL(NCDSSM):\n\t    \"\"\"The NCDSSM model with non-linear dynamics.\n", "    Parameters\n\t    ----------\n\t    aux_inference_net\n\t        The auxiliary inference model parameterized by a neural network\n\t    y_emission_net\n\t        The emission model parameterized by a neural network\n\t    aux_dim\n\t        The dimension of the auxiliary variables\n\t    z_dim\n\t        The dimension of the latent states\n", "    y_dim\n\t        The dimension of the observations\n\t    u_dim\n\t        The dimension of the control inputs\n\t    f, optional\n\t        The dynamics/drift function f(z), by default None\n\t    gs, optional\n\t        The list of diffusion functions g(z), one for each z_dim, by default None\n\t    integration_method, optional\n\t        The integration method, can be one of \"euler\" or \"rk4\",\n", "        by default \"rk4\"\n\t    integration_step_size, optional\n\t        The integration step size, by default 0.1\n\t    sporadic, optional\n\t        A flag to indicate whether the dataset is sporadic,\n\t        i.e., with values missing in both time and feature dimensions,\n\t        by default False\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n", "        aux_inference_net: AuxInferenceModel,\n\t        y_emission_net: nn.Module,\n\t        aux_dim: int,\n\t        z_dim: int,\n\t        y_dim: int,\n\t        u_dim: int,\n\t        f: nn.Module,\n\t        gs: Optional[List[nn.Module]] = None,\n\t        integration_method: str = \"rk4\",\n\t        integration_step_size: float = 0.1,\n", "        sporadic: bool = False,\n\t        **kwargs,\n\t    ):\n\t        super().__init__(\n\t            aux_inference_net,\n\t            y_emission_net,\n\t            aux_dim,\n\t            z_dim,\n\t            y_dim,\n\t            u_dim,\n", "            integration_method,\n\t            integration_step_size,\n\t            sporadic,\n\t            **kwargs,\n\t        )\n\t        self.base_ssm = BaseNL(\n\t            z_dim=z_dim,\n\t            y_dim=aux_dim,\n\t            u_dim=u_dim,\n\t            f=f,\n", "            gs=gs,\n\t            integration_method=integration_method,\n\t            integration_step_size=integration_step_size,\n\t            sporadic=sporadic,\n\t            **kwargs,\n\t        )\n"]}
{"filename": "src/ncdssm/datasets/mocap.py", "chunked_list": ["import torch\n\timport numpy as np\n\tfrom scipy.io import loadmat\n\tfrom ..utils import listofdict2dictoflist\n\tclass MocapDataset(torch.utils.data.Dataset):\n\t    def __init__(\n\t        self,\n\t        file_path: str,\n\t        mode: str = \"train\",\n\t        dt: float = 0.1,\n", "        ctx_len: int = 200,\n\t        pred_len: int = 100,\n\t        missing_p: float = 0.0,\n\t    ):\n\t        data = loadmat(file_path)\n\t        if mode == \"train\":\n\t            self._data = data[\"Xtr\"]\n\t        elif mode == \"val\":\n\t            self._data = data[\"Xval\"]\n\t        else:\n", "            self._data = data[\"Xtest\"]\n\t        self.dt = dt\n\t        self.ctx_len = ctx_len\n\t        self.pred_len = pred_len\n\t        self.missing_p = missing_p\n\t        self._set_mask()\n\t    def _set_mask(self):\n\t        self.observed_mask = np.random.choice(\n\t            [True, False],\n\t            p=[1 - self.missing_p, self.missing_p],\n", "            size=(self._data.shape[0], self.ctx_len),\n\t        )\n\t        self.observed_mask[:, :3] = True\n\t    def __len__(self):\n\t        return self._data.shape[0]\n\t    def __getitem__(self, idx):\n\t        target = self._data[idx]\n\t        past_target = target[: self.ctx_len]\n\t        past_times = np.arange(self.ctx_len) * self.dt\n\t        past_mask = self.observed_mask[idx]\n", "        # past_target = past_target * past_mask[:, None]\n\t        future_target = target[self.ctx_len :]\n\t        future_times = np.arange(target.shape[0]) * self.dt\n\t        future_times = future_times[self.ctx_len :]\n\t        return dict(\n\t            past_target=torch.as_tensor(past_target.astype(np.float32)),\n\t            future_target=torch.as_tensor(future_target.astype(np.float32)),\n\t            past_times=torch.as_tensor(past_times),\n\t            future_times=torch.as_tensor(future_times),\n\t            past_mask=torch.as_tensor(past_mask.astype(np.float32)),\n", "        )\n\t    def collate_fn(self, list_of_samples):\n\t        dict_of_samples = listofdict2dictoflist(list_of_samples)\n\t        comb_past_target = torch.stack(dict_of_samples[\"past_target\"])\n\t        comb_past_times = dict_of_samples[\"past_times\"][0]\n\t        comb_past_mask = torch.stack(dict_of_samples[\"past_mask\"])\n\t        comb_future_target = None\n\t        comb_future_times = None\n\t        if dict_of_samples[\"future_target\"][0] is not None:\n\t            comb_future_target = torch.stack(dict_of_samples[\"future_target\"])\n", "            comb_future_times = dict_of_samples[\"future_times\"][0]\n\t        return dict(\n\t            past_target=comb_past_target,\n\t            past_times=comb_past_times,\n\t            past_mask=comb_past_mask,\n\t            future_target=comb_future_target,\n\t            future_times=comb_future_times,\n\t        )\n"]}
{"filename": "src/ncdssm/datasets/__init__.py", "chunked_list": ["from .pymunk import PymunkDataset\n\tfrom .synthetic import BouncingBallDataset, DampedPendulumDataset\n\tfrom .mocap import MocapDataset\n\tfrom .climate import ClimateDataset\n\t__all__ = [\n\t    \"PymunkDataset\",\n\t    \"BouncingBallDataset\",\n\t    \"MocapDataset\",\n\t    \"DampedPendulumDataset\",\n\t    \"ClimateDataset\",\n", "]\n"]}
{"filename": "src/ncdssm/datasets/pymunk.py", "chunked_list": ["import torch\n\timport numpy as np\n\tfrom ..utils import listofdict2dictoflist\n\tclass PymunkDataset(torch.utils.data.Dataset):\n\t    def __init__(\n\t        self,\n\t        file_path: str,\n\t        missing_p=0.0,\n\t        train=True,\n\t        dt=0.1,\n", "        ctx_len=20,\n\t        pred_len=40,\n\t    ):\n\t        self._data, self._ground_truth = self._load_dataset(\n\t            file_path, num_timesteps=ctx_len + pred_len\n\t        )\n\t        self.missing_p = missing_p\n\t        self.train = train\n\t        self.dt = dt\n\t        self.ctx_len = ctx_len\n", "        self.observed_mask = np.random.choice(\n\t            [True, False],\n\t            p=[1 - missing_p, missing_p],\n\t            size=(self._data[\"y\"].shape[0], ctx_len),\n\t        )\n\t        self.observed_mask[:, 0] = True\n\t    def __len__(self):\n\t        idx_batch = 0\n\t        sizes = [val.shape[idx_batch] for val in self._data.values()]\n\t        assert all(size == sizes[0] for size in sizes)\n", "        size = sizes[0]\n\t        return size\n\t    def __getitem__(self, idx):\n\t        target = self._data[\"y\"][idx]\n\t        past_target = target[: self.ctx_len]\n\t        past_times = np.arange(self.ctx_len) * self.dt\n\t        past_mask = self.observed_mask[idx].astype(np.float32)\n\t        # past_target = past_target * past_mask[:, None]\n\t        if not self.train:\n\t            future_target = target[self.ctx_len :]\n", "            future_times = np.arange(target.shape[0]) * self.dt\n\t            future_times = future_times[self.ctx_len :]\n\t        return dict(\n\t            past_target=torch.as_tensor(past_target),\n\t            future_target=None if self.train else torch.as_tensor(future_target),\n\t            past_times=torch.as_tensor(past_times),\n\t            future_times=None if self.train else torch.as_tensor(future_times),\n\t            past_mask=torch.as_tensor(past_mask),\n\t        )\n\t    def collate_fn(self, list_of_samples):\n", "        dict_of_samples = listofdict2dictoflist(list_of_samples)\n\t        comb_past_target = torch.stack(dict_of_samples[\"past_target\"])\n\t        comb_past_times = dict_of_samples[\"past_times\"][0]\n\t        comb_past_mask = torch.stack(dict_of_samples[\"past_mask\"])\n\t        comb_future_target = None\n\t        comb_future_times = None\n\t        if dict_of_samples[\"future_target\"][0] is not None:\n\t            comb_future_target = torch.stack(dict_of_samples[\"future_target\"])\n\t            comb_future_times = dict_of_samples[\"future_times\"][0]\n\t        return dict(\n", "            past_target=comb_past_target,\n\t            past_times=comb_past_times,\n\t            past_mask=comb_past_mask,\n\t            future_target=comb_future_target,\n\t            future_times=comb_future_times,\n\t        )\n\t    def _load_dataset(self, file_path, num_timesteps=100):\n\t        npzfile = np.load(file_path)\n\t        images = npzfile[\"images\"].astype(np.float32)\n\t        # The datasets in KVAE are binarized images\n", "        images = (images > 0).astype(np.float32)\n\t        assert images.ndim == 4\n\t        images = images.reshape(\n\t            images.shape[0], images.shape[1], images.shape[2] * images.shape[3]\n\t        )\n\t        data = {\"y\": images[:, :num_timesteps]}\n\t        if \"state\" in npzfile:  # all except Pong have state.\n\t            position = npzfile[\"state\"].astype(np.float32)[:, :, :2]\n\t            velocity = npzfile[\"state\"].astype(np.float32)[:, :, 2:]\n\t            ground_truth_state = {\"position\": position, \"velocity\": velocity}\n", "        else:\n\t            ground_truth_state = None\n\t        return data, ground_truth_state\n"]}
{"filename": "src/ncdssm/datasets/synthetic.py", "chunked_list": ["import torch\n\timport numpy as np\n\tfrom torch.utils.data import Dataset\n\tfrom ..utils import listofdict2dictoflist\n\tclass BouncingBallDataset(Dataset):\n\t    def __init__(\n\t        self,\n\t        path: str = \"./data/bouncing_ball.npz\",\n\t        dt: float = 0.1,\n\t        ctx_len: int = 200,\n", "        pred_len: int = 100,\n\t        missing_p: float = 0.0,\n\t        num_always_obs: float = 0,\n\t    ):\n\t        self._data = np.load(path)[\"target\"]\n\t        self.dt = dt\n\t        self.ctx_len = ctx_len\n\t        self.pred_len = pred_len\n\t        self.missing_p = missing_p\n\t        self.num_always_obs = num_always_obs\n", "        self._set_mask()\n\t    def _set_mask(self):\n\t        self.observed_mask = np.random.choice(\n\t            [True, False],\n\t            p=[1 - self.missing_p, self.missing_p],\n\t            size=(self._data.shape[0], self.ctx_len),\n\t        )\n\t        self.observed_mask[:, : self.num_always_obs] = True\n\t    def __len__(self):\n\t        return self._data.shape[0]\n", "    def __getitem__(self, idx):\n\t        target = self._data[idx]\n\t        past_target = target[: self.ctx_len]\n\t        past_times = np.arange(self.ctx_len) * self.dt\n\t        past_mask = self.observed_mask[idx]\n\t        # past_target = past_target * past_mask[:, None]\n\t        future_target = target[self.ctx_len :]\n\t        future_times = np.arange(target.shape[0]) * self.dt\n\t        future_times = future_times[self.ctx_len :]\n\t        return dict(\n", "            past_target=torch.as_tensor(past_target.astype(np.float32)),\n\t            future_target=torch.as_tensor(future_target.astype(np.float32)),\n\t            past_times=torch.as_tensor(past_times),\n\t            future_times=torch.as_tensor(future_times),\n\t            past_mask=torch.as_tensor(past_mask.astype(np.float32)),\n\t        )\n\t    def collate_fn(self, list_of_samples):\n\t        dict_of_samples = listofdict2dictoflist(list_of_samples)\n\t        comb_past_target = torch.stack(dict_of_samples[\"past_target\"])\n\t        comb_past_times = dict_of_samples[\"past_times\"][0]\n", "        comb_past_mask = torch.stack(dict_of_samples[\"past_mask\"])\n\t        comb_future_target = None\n\t        comb_future_times = None\n\t        if dict_of_samples[\"future_target\"][0] is not None:\n\t            comb_future_target = torch.stack(dict_of_samples[\"future_target\"])\n\t            comb_future_times = dict_of_samples[\"future_times\"][0]\n\t        return dict(\n\t            past_target=comb_past_target,\n\t            past_times=comb_past_times,\n\t            past_mask=comb_past_mask,\n", "            future_target=comb_future_target,\n\t            future_times=comb_future_times,\n\t        )\n\tclass DampedPendulumDataset(BouncingBallDataset):\n\t    def __init__(\n\t        self,\n\t        path: str = \"./data/damped_pendulum/train.npz\",\n\t        dt: float = 0.1,\n\t        ctx_len: int = 50,\n\t        pred_len: int = 100,\n", "        missing_p: float = 0,\n\t        num_always_obs: float = 0,\n\t    ):\n\t        self._data = np.load(path)[\"obs\"]\n\t        self.dt = dt\n\t        self.ctx_len = ctx_len\n\t        self.pred_len = pred_len\n\t        self.missing_p = missing_p\n\t        self.num_always_obs = num_always_obs\n\t        self._set_mask()\n"]}
{"filename": "src/ncdssm/datasets/climate.py", "chunked_list": ["import torch\n\timport numpy as np\n\timport pandas as pd\n\tfrom ..type import Dict, NumpyArray\n\tfrom ..utils import listofdict2dictoflist\n\tclass ClimateDataset(torch.utils.data.Dataset):\n\t    def __init__(\n\t        self,\n\t        csv_path: str,\n\t        time_scale: float = 1.0,\n", "        train: bool = True,\n\t        ids: NumpyArray = None,\n\t        val_options: Dict = None,\n\t    ) -> None:\n\t        super().__init__()\n\t        self.train = train\n\t        self.df = pd.read_csv(csv_path)\n\t        assert self.df.columns[0] == \"ID\"\n\t        if not train:\n\t            assert val_options is not None\n", "            ids_before_tval = self.df.loc[\n\t                self.df[\"Time\"] <= val_options[\"T_val\"], \"ID\"\n\t            ].unique()\n\t            ids_after_tval = self.df.loc[\n\t                self.df[\"Time\"] > val_options[\"T_val\"], \"ID\"\n\t            ].unique()\n\t            filtered_ids = np.intersect1d(ids_before_tval, ids_after_tval)\n\t            self.df = self.df.loc[self.df[\"ID\"].isin(filtered_ids)]\n\t        if ids is not None:\n\t            self.df = self.df.loc[self.df[\"ID\"].isin(ids)].copy()\n", "            map_dict = dict(\n\t                zip(self.df[\"ID\"].unique(), np.arange(self.df[\"ID\"].nunique()))\n\t            )\n\t            self.df[\"ID\"] = self.df[\"ID\"].map(map_dict)\n\t        self.df.Time = self.df.Time * time_scale\n\t        if not train:\n\t            self.df_before_tval = self.df.loc[\n\t                self.df[\"Time\"] <= val_options[\"T_val\"]\n\t            ].copy()\n\t            self.df_after_tval = (\n", "                self.df.loc[self.df[\"Time\"] > val_options[\"T_val\"]]\n\t                .sort_values(\"Time\")\n\t                .copy()\n\t            )\n\t            self.df_after_tval = (\n\t                self.df_after_tval.groupby(\"ID\")\n\t                .head(val_options[\"forecast_steps\"])\n\t                .copy()\n\t            )\n\t            self.df = self.df_before_tval\n", "            self.df_after_tval = self.df_after_tval.astype(np.float32)\n\t            self.df_after_tval.ID = self.df_after_tval.ID.astype(int)\n\t            self.df_after_tval.sort_values(\"Time\", inplace=True)\n\t        self.df = self.df.astype(np.float32)\n\t        self.df.ID = self.df.ID.astype(int)\n\t        self.size = self.df[\"ID\"].nunique()\n\t        # self.df.set_index(\"ID\", inplace=True)\n\t        self.df.sort_values(\"Time\", inplace=True)\n\t        self.data_columns = list(\n\t            filter(lambda c: c.startswith(\"Value\"), self.df.columns)\n", "        )\n\t        self.mask_columns = list(\n\t            filter(lambda c: c.startswith(\"Mask\"), self.df.columns)\n\t        )\n\t        self.data = []\n\t        for id, sub_df in self.df.groupby(\"ID\"):\n\t            sub_df = sub_df.reset_index(drop=True).sort_values(\"Time\")\n\t            item = {\n\t                \"Time\": sub_df[\"Time\"].to_numpy(),\n\t                \"Value\": sub_df[self.data_columns].to_numpy(),\n", "                \"Mask\": sub_df[self.mask_columns].to_numpy(),\n\t            }\n\t            if not self.train:\n\t                val_sub_df = self.df_after_tval.loc[self.df_after_tval[\"ID\"] == id]\n\t                item[\"Future_Time\"] = val_sub_df[\"Time\"].to_numpy()\n\t                item[\"Future_Value\"] = val_sub_df[self.data_columns].to_numpy()\n\t                item[\"Future_Mask\"] = val_sub_df[self.mask_columns].to_numpy()\n\t            self.data.append(item)\n\t    def __len__(self):\n\t        return self.size\n", "    def __getitem__(self, idx):\n\t        subset = self.data[idx]\n\t        past_target = subset[\"Value\"]\n\t        past_mask = subset[\"Mask\"]\n\t        past_times = subset[\"Time\"]\n\t        if not self.train:\n\t            future_target = subset[\"Future_Value\"]\n\t            future_mask = subset[\"Future_Mask\"]\n\t            future_times = subset[\"Future_Time\"]\n\t        return dict(\n", "            past_target=torch.as_tensor(past_target),\n\t            past_mask=torch.as_tensor(past_mask),\n\t            past_times=torch.as_tensor(past_times),\n\t            future_target=None if self.train else torch.as_tensor(future_target),\n\t            future_mask=None if self.train else torch.as_tensor(future_mask),\n\t            future_times=None if self.train else torch.as_tensor(future_times),\n\t        )\n\t    def collate_fn(self, list_of_samples):\n\t        dict_of_samples = listofdict2dictoflist(list_of_samples)\n\t        batch_size = len(list_of_samples)\n", "        target_dim = dict_of_samples[\"past_target\"][0].shape[-1]\n\t        # Collate past\n\t        comb_past_times, past_inverse_indices = torch.unique(\n\t            torch.cat(dict_of_samples[\"past_times\"]), sorted=True, return_inverse=True\n\t        )\n\t        comb_past_target = torch.zeros(\n\t            [batch_size, comb_past_times.shape[0], target_dim]\n\t        )\n\t        comb_past_mask = torch.zeros_like(comb_past_target)\n\t        past_offset = 0\n", "        for i, (tgt, mask, time) in enumerate(\n\t            zip(\n\t                dict_of_samples[\"past_target\"],\n\t                dict_of_samples[\"past_mask\"],\n\t                dict_of_samples[\"past_times\"],\n\t            )\n\t        ):\n\t            past_indices = past_inverse_indices[\n\t                past_offset : past_offset + time.shape[0]\n\t            ]\n", "            past_offset += time.shape[0]\n\t            comb_past_target[i, past_indices] = tgt\n\t            comb_past_mask[i, past_indices] = mask\n\t        # Collate future\n\t        comb_future_target = None\n\t        comb_future_times = None\n\t        comb_future_mask = None\n\t        if dict_of_samples[\"future_target\"][0] is not None:\n\t            comb_future_times, future_inverse_indices = torch.unique(\n\t                torch.cat(dict_of_samples[\"future_times\"]),\n", "                sorted=True,\n\t                return_inverse=True,\n\t            )\n\t            comb_future_target = torch.zeros(\n\t                [batch_size, comb_future_times.shape[0], target_dim]\n\t            )\n\t            comb_future_mask = torch.zeros_like(comb_future_target)\n\t            future_offset = 0\n\t            for i, (tgt, mask, time) in enumerate(\n\t                zip(\n", "                    dict_of_samples[\"future_target\"],\n\t                    dict_of_samples[\"future_mask\"],\n\t                    dict_of_samples[\"future_times\"],\n\t                )\n\t            ):\n\t                future_indices = future_inverse_indices[\n\t                    future_offset : future_offset + time.shape[0]\n\t                ]\n\t                future_offset += time.shape[0]\n\t                comb_future_target[i, future_indices] = tgt\n", "                comb_future_mask[i, future_indices] = mask\n\t        return dict(\n\t            past_target=comb_past_target,\n\t            past_times=comb_past_times,\n\t            past_mask=comb_past_mask,\n\t            future_target=comb_future_target,\n\t            future_times=comb_future_times,\n\t            future_mask=comb_future_mask,\n\t        )\n"]}
