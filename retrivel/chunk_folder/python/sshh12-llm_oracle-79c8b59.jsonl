{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\twith open(\"requirements.txt\") as f:\n\t    required = f.read().splitlines()\n\tsetup(\n\t    name=\"llm_oracle\",\n\t    version=\"0.0.6\",\n\t    description=\"\",\n\t    url=\"https://github.com/sshh12/llm_oracle\",\n\t    author=\"Shrivu Shankar\",\n\t    license=\"MIT\",\n", "    packages=find_packages(),\n\t    include_package_data=True,\n\t    install_requires=required,\n\t)\n"]}
{"filename": "llm_oracle/text_utils.py", "chunked_list": ["import datetime\n\tTIME_UNITS = {\"year\": 365, \"month\": 31, \"week\": 7, \"day\": 1}\n\tdef future_date_to_string(raw_date: datetime.datetime) -> str:\n\t    date = raw_date.replace(tzinfo=None)\n\t    s = date.isoformat()[:10]\n\t    days_from_now = (date - datetime.datetime.now()).days\n\t    rel = None\n\t    for unit, unit_days in TIME_UNITS.items():\n\t        if days_from_now > unit_days:\n\t            rel = f\"~ {days_from_now/unit_days:.1f} {unit}s\"\n", "            break\n\t    return f\"{s} (in {rel})\"\n\tdef world_state_to_string() -> str:\n\t    state = {\"current_date\": datetime.datetime.now().isoformat()[:10]}\n\t    return \"\\n\".join([f\"{k}: {v}\" for k, v in state.items()])\n"]}
{"filename": "llm_oracle/llm.py", "chunked_list": ["from langchain.chat_models import ChatOpenAI\n\tfrom langchain.chat_models.base import BaseChatModel\n\tLLMModel = BaseChatModel\n\tdefault_fast_llm_options = dict(model_name=\"gpt-3.5-turbo\", request_timeout=120, max_retries=10, temperature=0.5)\n\tdefault_llm_options = dict(model_name=\"gpt-4\", request_timeout=120, max_retries=10, temperature=0.5)\n\tdef get_default_fast_llm() -> LLMModel:\n\t    chat = ChatOpenAI(**default_fast_llm_options)\n\t    return chat\n\tdef get_default_llm() -> LLMModel:\n\t    chat = ChatOpenAI(**default_llm_options)\n", "    return chat\n"]}
{"filename": "llm_oracle/__init__.py", "chunked_list": []}
{"filename": "llm_oracle/processing_utils.py", "chunked_list": ["from typing import Callable, Any, Optional\n\timport datetime\n\timport hashlib\n\timport pickle\n\timport re\n\timport os\n\tMAX_CACHE_VAL_LEN = 20\n\tcache_options = dict(cache=True, cache_dir=\"cache\")\n\tdef hash_str(val: str) -> str:\n\t    return str(int(hashlib.md5(val.encode(\"utf-8\")).hexdigest(), 16))\n", "def cache_func(func: Callable) -> Callable:\n\t    \"\"\"\n\t    Basic cache to save $$$ on API calls.\n\t    Caches based on `str` and `int` args only. Cache is done only for a single calendar day.\n\t    \"\"\"\n\t    def wrap(*args, **kwargs):\n\t        os.makedirs(cache_options[\"cache_dir\"], exist_ok=True)\n\t        args = [*args] + list(kwargs.values())\n\t        cache_val = re.sub(\"[^\\w\\d]\", \"\", repr([arg for arg in args if isinstance(arg, str) or isinstance(arg, int)]))\n\t        if len(cache_val) > MAX_CACHE_VAL_LEN:\n", "            cache_val = hash_str(cache_val)\n\t        date_key = datetime.datetime.now().isoformat()[:10].replace(\"-\", \"_\")\n\t        cache_key = f\"{func.__name__}_{date_key}_{cache_val}\"\n\t        cache_fn = os.path.join(cache_options[\"cache_dir\"], cache_key)\n\t        if os.path.exists(cache_fn) and cache_options[\"cache\"]:\n\t            with open(cache_fn, \"rb\") as f:\n\t                return pickle.load(f)\n\t        else:\n\t            result = func(*args, **kwargs)\n\t            with open(cache_fn, \"wb\") as f:\n", "                pickle.dump(result, f)\n\t            return result\n\t    return wrap\n\tdef run_with_retries(func: Callable, default_val: Optional[Any] = None, retries: Optional[int] = 3) -> Any:\n\t    attempts = 0\n\t    while True:\n\t        try:\n\t            attempts += 1\n\t            return func()\n\t        except Exception as e:\n", "            print(\"run_with_retries\", func, e)\n\t            if attempts > retries:\n\t                break\n\t    return default_val\n"]}
{"filename": "llm_oracle/link_scraping.py", "chunked_list": ["from typing import List, Optional\n\timport requests\n\timport os\n\tfrom bs4 import BeautifulSoup\n\tfrom llm_oracle import processing_utils\n\tMAX_LINK_LEN = 120\n\t@processing_utils.cache_func\n\tdef scrape_text(url: str, retries: Optional[int] = 2, use_proxy: bool = True) -> str:\n\t    try:\n\t        if use_proxy:\n", "            resp = requests.get(\n\t                url=\"https://app.scrapingbee.com/api/v1/\",\n\t                params={\n\t                    \"api_key\": os.environ[\"SCRAPINGBEE_API_KEY\"],\n\t                    \"url\": url,\n\t                    \"premium_proxy\": \"true\",\n\t                    \"country_code\": \"us\",\n\t                },\n\t            )\n\t        else:\n", "            resp = requests.get(\n\t                url,\n\t                headers={\n\t                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\"\n\t                },\n\t            )\n\t    except RuntimeError as e:\n\t        if retries > 0:\n\t            return scrape_text(url, retries=retries - 1)\n\t        else:\n", "            raise e\n\t    return resp.text\n\tdef _element_to_text(element) -> str:\n\t    elem_text = element.get_text()\n\t    lines = (line.strip() for line in elem_text.splitlines())\n\t    parts = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n\t    text = \"\\n\".join(c for c in parts if c)\n\t    links = []\n\t    for link in element.find_all(\"a\", href=True):\n\t        if len(link[\"href\"]) <= MAX_LINK_LEN:\n", "            links.append(link[\"href\"])\n\t    return text + \"\\n\\nLinks: \" + \" \".join(list(set(links)))\n\tdef _chunk_element(element, max_size: int) -> List[str]:\n\t    text = _element_to_text(element)\n\t    if len(text) == 0:\n\t        return []\n\t    if len(text) <= max_size:\n\t        return [text]\n\t    else:\n\t        chunks = []\n", "        for child in element.findChildren(recursive=False):\n\t            chunks.extend(_chunk_element(child, max_size))\n\t        return chunks\n\tdef _merge_text_chunks(vals: List[str], max_size: int) -> List[str]:\n\t    combined_strings = []\n\t    current_string = \"\"\n\t    for s in vals:\n\t        if len(current_string) + len(s) <= max_size:\n\t            current_string += s\n\t        else:\n", "            combined_strings.append(current_string)\n\t            current_string = s\n\t    if current_string:\n\t        combined_strings.append(current_string)\n\t    return combined_strings\n\tdef chunk_and_strip_html(raw_html: str, max_size: int) -> List[str]:\n\t    soup = BeautifulSoup(raw_html, features=\"html.parser\")\n\t    for script in soup([\"script\", \"style\"]):\n\t        script.extract()\n\t    chunks = _chunk_element(soup, max_size)\n", "    chunks = _merge_text_chunks(chunks, max_size)\n\t    return chunks\n"]}
{"filename": "llm_oracle/tools/__init__.py", "chunked_list": []}
{"filename": "llm_oracle/tools/read_link.py", "chunked_list": ["from typing import Optional, List\n\tfrom langchain.agents import Tool\n\tfrom llm_oracle.link_scraping import scrape_text, chunk_and_strip_html\n\tfrom llm_oracle import llm, processing_utils\n\tCHUNK_SIZE = 4000\n\tSUMMARIZE_PROMPT = \"\"\"\n\t```\n\t{chunk}\n\t```\n\tUsing the above text from scraping a website, create a very detailed summary of the information.\n", "Include key statistics, dates, numbers, and other details.\n\tNote: This will be used to answer \"{ask}\"\n\t\"\"\"\n\tSUMMARIZE_CHUNKS_PROMPT = \"\"\"\n\t```\n\t{chunks}\n\t```\n\tUsing the above text from scraping a website, create a very detailed summary of the information and provide information about \"{ask}\".\n\tInclude key statistics, dates, numbers, and other details.\n\t\"\"\"\n", "@processing_utils.cache_func\n\tdef _summarize_chunk(model: llm.LLMModel, chunk: str, ask: str) -> str:\n\t    return model.call_as_llm(SUMMARIZE_PROMPT.format(chunk=chunk, ask=ask))\n\tdef _summarize_chunks(model: llm.LLMModel, chunks: List[str], ask: str) -> str:\n\t    return model.call_as_llm(SUMMARIZE_CHUNKS_PROMPT.format(chunks=\"\\n\\n\".join(chunks), ask=ask))\n\tdef summarize_chunks(model: llm.LLMModel, chunks: List[str], ask: str) -> str:\n\t    summary_chunks = []\n\t    for chunk in chunks:\n\t        summary_chunks.append(_summarize_chunk(model, chunk, ask))\n\t    return _summarize_chunks(model, summary_chunks, ask)\n", "class ReadLinkWrapper:\n\t    def __init__(self, summary_model: Optional[llm.LLMModel] = None, use_proxy: bool = True):\n\t        if summary_model is None:\n\t            self.summary_model = llm.get_default_fast_llm()\n\t        else:\n\t            self.summary_model = summary_model\n\t        self.use_proxy = use_proxy\n\t    def run(self, query: str) -> str:\n\t        if query.endswith(\".pdf\"):\n\t            return \"Cannot read links that end in pdf\"\n", "        try:\n\t            url, ask = query.split(\", \")\n\t        except ValueError:\n\t            return 'input was in the wrong format, it should be \"url, question\"'\n\t        chunks = chunk_and_strip_html(scrape_text(url, use_proxy=self.use_proxy), CHUNK_SIZE)\n\t        return summarize_chunks(self.summary_model, chunks, ask)\n\tdef get_read_link_tool(**kwargs) -> Tool:\n\t    read_link = ReadLinkWrapper(**kwargs)\n\t    return Tool(\n\t        name=\"Read Link\",\n", "        func=read_link.run,\n\t        description='useful to read and extract the contents of any link. the input should be \"url, question\", e.g. \"https://en.wikipedia.org/wiki/2023_in_the_United_States, list of events in april 2023\"',\n\t    )\n"]}
{"filename": "llm_oracle/tools/search.py", "chunked_list": ["from langchain.utilities import GoogleSerperAPIWrapper\n\tfrom langchain.agents import Tool\n\tfrom llm_oracle import processing_utils\n\tclass GoogleSerperSearchWrapper(GoogleSerperAPIWrapper):\n\t    @processing_utils.cache_func\n\t    def run(self, query: str) -> str:\n\t        return super().run(query)\n\t    def _parse_results(self, results: dict) -> str:\n\t        snippets = []\n\t        if results.get(\"answerBox\"):\n", "            answer_box = results.get(\"answerBox\", {})\n\t            if answer_box.get(\"answer\"):\n\t                return answer_box.get(\"answer\")\n\t            elif answer_box.get(\"snippet\"):\n\t                return answer_box.get(\"snippet\").replace(\"\\n\", \" \")\n\t            elif answer_box.get(\"snippetHighlighted\"):\n\t                return \", \".join(answer_box.get(\"snippetHighlighted\"))\n\t        if results.get(\"knowledgeGraph\"):\n\t            kg = results.get(\"knowledgeGraph\", {})\n\t            title = kg.get(\"title\")\n", "            entity_type = kg.get(\"type\")\n\t            if entity_type:\n\t                snippets.append(f\"{title}: {entity_type}.\")\n\t            description = kg.get(\"description\")\n\t            if description:\n\t                snippets.append(description)\n\t            for attribute, value in kg.get(\"attributes\", {}).items():\n\t                snippets.append(f\"{title} {attribute}: {value}.\")\n\t        for result in results[\"organic\"][: self.k]:\n\t            if \"snippet\" in result:\n", "                snippets.append(f'{result[\"title\"]}: {result[\"snippet\"]} (link {result[\"link\"]})')\n\t            for attribute, value in result.get(\"attributes\", {}).items():\n\t                snippets.append(f'{result[\"title\"]}: {attribute} = {value}.')\n\t        if len(snippets) == 0:\n\t            return \"No good results found\"\n\t        return \"\\n\\n\".join(snippets)\n\tdef get_search_tool(**kwargs) -> Tool:\n\t    search = GoogleSerperSearchWrapper(**kwargs)\n\t    return Tool(\n\t        name=\"Search Term\",\n", "        func=search.run,\n\t        description=\"useful for when you need to find information about general things, names, usernames, places, etc. the input should be a search term\",\n\t    )\n"]}
{"filename": "llm_oracle/agents/base.py", "chunked_list": ["from typing import List, Dict\n\tfrom abc import ABC, abstractmethod\n\tfrom llm_oracle.markets.base import MarketEvent\n\tclass OracleAgent(ABC):\n\t    @abstractmethod\n\t    def predict_event_probability(self, event: MarketEvent) -> float:\n\t        return\n"]}
{"filename": "llm_oracle/agents/agent_tools.py", "chunked_list": ["from typing import Optional, List, Dict\n\tfrom langchain.memory import ConversationBufferMemory\n\tfrom langchain.agents import AgentType, initialize_agent, load_tools\n\tfrom langchain.input import print_text\n\tfrom langchain.callbacks.base import CallbackManager\n\tfrom llm_oracle import llm\n\tfrom llm_oracle.tools.search import get_search_tool\n\tfrom llm_oracle.tools.read_link import get_read_link_tool\n\tfrom llm_oracle.agents.base import OracleAgent\n\tfrom llm_oracle.agents.output import OUTPUT_PROMPT_P10, parse_p10_output, OUTPUT_PROMPT_LIKELY, parse_likely_output\n", "from llm_oracle.markets.base import MarketEvent\n\tTOOL_V1_QUESTION = f\"\"\"\n\tPredict the outcome of the following event.\n\t{{event_text}}\n\tRespond with:\n\t* What you learned might know about this.\n\t* Arguments for the event\n\t* Arguments against the event\n\t{OUTPUT_PROMPT_P10}\n\t\"\"\"\n", "TOOL_V1_PREFIX = \"\"\"\n\tYou are an expert forecasting analyst with tons knowledge and skill in making calibrated conclusions. \n\tYou never say \"I don't know\" and you are very thorough at using tools to perform the need research and investigation.\n\tYou always investigate both sides of an argument.\n\tYou always keep in mind that old sources might be outdated and no longer accurate.\n\tGiven the users prediction question, answer to the best of your ability and follow their instructions. \n\tYou have access to the following tools:\n\t\"\"\"\n\tTOOL_V1_FORMAT_INSTRUCTIONS = \"\"\"The way you use the tools is by specifying a json blob.\n\tSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n", "The only values that should be in the \"action\" field are: {tool_names}\n\tThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n\t```\n\t{{{{\n\t  \"action\": $TOOL_NAME,\n\t  \"action_input\": $INPUT\n\t}}}}\n\t```\n\tALWAYS use the following format:\n\tQuestion: the input question you must answer\n", "Thought: you should always think about what to do\n\tAction:\n\t```\n\t$JSON_BLOB\n\t```\n\tObservation: the result of the action\n\t... (this Thought/Action/Observation can repeat N times)\n\tThought: I now know the final answer\n\tFinal Answer: the final answer to the original input question\"\"\"\n\tTOOL_V1_SUFFIX = \"\"\"\n", "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n\t\"\"\"\n\tclass ToolAgentv1(OracleAgent):\n\t    def __init__(\n\t        self,\n\t        verbose: Optional[bool] = True,\n\t        model: Optional[llm.BaseChatModel] = None,\n\t        tool_model: Optional[llm.BaseChatModel] = None,\n\t        callback_manager: Optional[CallbackManager] = None,\n\t        use_proxy: Optional[bool] = True,\n", "    ):\n\t        self.model = model or llm.get_default_llm()\n\t        self.tool_model = tool_model or llm.get_default_fast_llm()\n\t        self.verbose = verbose\n\t        self.callback_manager = callback_manager\n\t        self.use_proxy = use_proxy\n\t    def get_tools(self) -> List:\n\t        return [\n\t            get_search_tool(),\n\t            get_read_link_tool(summary_model=self.tool_model, use_proxy=self.use_proxy),\n", "        ] + load_tools([\"wolfram-alpha\", \"llm-math\"], llm=self.model)\n\t    def get_agent_kwargs(self) -> Dict:\n\t        return {\n\t            \"prefix\": TOOL_V1_PREFIX,\n\t            \"suffix\": TOOL_V1_SUFFIX,\n\t            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n\t        }\n\t    def get_chain_prompt(self) -> str:\n\t        return TOOL_V1_QUESTION\n\t    def parse_output(self, result: str) -> float:\n", "        return parse_p10_output(result)\n\t    def predict_event_probability(self, event: MarketEvent) -> float:\n\t        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n\t        agent_chain = initialize_agent(\n\t            self.get_tools(),\n\t            self.model,\n\t            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n\t            verbose=True,\n\t            memory=memory,\n\t            agent_kwargs=self.get_agent_kwargs(),\n", "            callback_manager=self.callback_manager,\n\t        )\n\t        event_text = event.to_text()\n\t        if self.verbose:\n\t            print_text(event_text + \"\\n\", \"green\")\n\t        result = agent_chain.run(input=self.get_chain_prompt().format(event_text=event_text))\n\t        if self.verbose:\n\t            print_text(result + \"\\n\", \"yellow\")\n\t        return self.parse_output(result)\n\tTOOL_V2_QUESTION = f\"\"\"\n", "Predict the outcome of the following event.\n\t{{event_text}}\n\tRespond with:\n\t* What you learned about this\n\t* Arguments for the event\n\t* Rebuttal to your arguments for the event\n\t* Arguments against the event\n\t* Rebuttal to your arguments against the event\n\t{OUTPUT_PROMPT_P10}\n\t\"\"\"\n", "TOOL_V2_PREFIX = \"\"\"\n\tYou are an expert forecasting analyst with the ability to make well calibrated predictions about the future. \n\tYou never say \"I don't know\" and you are very thorough at using tools to perform the need research and investigation.\n\tYou always investigate both sides of an argument and weights the facts by validity of your sources.\n\tYou always keep in mind that old sources might be outdated and no longer accurate.\n\tGiven the users prediction question, answer to the best of your ability and follow their instructions. \n\tYou have access to the following tools:\n\t\"\"\"\n\tclass ToolAgentv2(ToolAgentv1):\n\t    def get_agent_kwargs(self) -> Dict:\n", "        return {\n\t            \"prefix\": TOOL_V2_PREFIX,\n\t            \"suffix\": TOOL_V1_SUFFIX,\n\t            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n\t        }\n\t    def get_chain_prompt(self) -> str:\n\t        return TOOL_V2_QUESTION\n\tTOOL_V3_QUESTION = f\"\"\"\n\tPredict the outcome of the following event.\n\t{{event_text}}\n", "Respond with:\n\t* What you learned about this\n\t* Arguments for the event\n\t* Rebuttal to your arguments for the event\n\t* Arguments against the event\n\t* Rebuttal to your arguments against the event\n\t{OUTPUT_PROMPT_LIKELY}\n\t\"\"\"\n\tclass ToolAgentv3(ToolAgentv1):\n\t    def get_agent_kwargs(self) -> Dict:\n", "        return {\n\t            \"prefix\": TOOL_V2_PREFIX,\n\t            \"suffix\": TOOL_V1_SUFFIX,\n\t            \"format_instructions\": TOOL_V1_FORMAT_INSTRUCTIONS,\n\t        }\n\t    def get_chain_prompt(self) -> str:\n\t        return TOOL_V3_QUESTION\n\t    def parse_output(self, result: str) -> float:\n\t        return parse_likely_output(result)\n"]}
{"filename": "llm_oracle/agents/agent_basic.py", "chunked_list": ["from typing import Optional, Callable\n\tfrom langchain.schema import HumanMessage, SystemMessage\n\tfrom langchain.input import print_text\n\tfrom llm_oracle import llm\n\tfrom llm_oracle.agents.base import OracleAgent\n\tfrom llm_oracle.agents.output import OUTPUT_PROMPT_P10, parse_p10_output, OUTPUT_PROMPT_LIKELY, parse_likely_output\n\tfrom llm_oracle.markets.base import MarketEvent\n\tPROMPT_SYSTEM_BASIC_AGENT_V1 = \"\"\"\n\tYou are an expert analyst with tons of already knowledge. You already know everything and you never say \"I don't know\".\n\tGiven the users prediction question, answer to the best of your ability and follow their instructions.\n", "\"\"\"\n\tPROMPT_HUMAN_BASIC_AGENT_V1 = f\"\"\"\n\tPredict the outcome of the following event.\n\t{{event_text}}\n\tRespond with what you already might know about this.\n\t{OUTPUT_PROMPT_P10}\n\t\"\"\"\n\tclass BasicAgentv1(OracleAgent):\n\t    def __init__(\n\t        self,\n", "        verbose: Optional[bool] = True,\n\t        model: Optional[llm.BaseChatModel] = None,\n\t        output_callback: Optional[Callable[[str], None]] = None,\n\t    ):\n\t        self.model = model or llm.get_default_llm()\n\t        self.verbose = verbose\n\t        self.output_callback = output_callback\n\t    def get_system_prompt(self) -> str:\n\t        return PROMPT_SYSTEM_BASIC_AGENT_V1\n\t    def get_human_prompt(self) -> str:\n", "        return PROMPT_HUMAN_BASIC_AGENT_V1\n\t    def parse_output(self, result: str) -> float:\n\t        return parse_p10_output(result)\n\t    def predict_event_probability(self, event: MarketEvent) -> float:\n\t        event_text = event.to_text()\n\t        if self.verbose:\n\t            print_text(event_text + \"\\n\", \"green\")\n\t        human_message = self.get_human_prompt().format(event_text=event_text)\n\t        result = self.model([SystemMessage(content=self.get_system_prompt()), HumanMessage(content=human_message)])\n\t        if self.output_callback:\n", "            self.output_callback(result.content)\n\t        if self.verbose:\n\t            print_text(result.content + \"\\n\", \"yellow\")\n\t        return self.parse_output(result.content)\n\tPROMPT_HUMAN_BASIC_AGENT_V2 = f\"\"\"\n\tPredict the outcome of the following event.\n\t{{event_text}}\n\tRespond with:\n\t* What you learned might know about this.\n\t* Arguments for the event\n", "* Arguments against the event\n\t{OUTPUT_PROMPT_P10}\n\t\"\"\"\n\tclass BasicAgentv2(BasicAgentv1):\n\t    def get_system_prompt(self) -> str:\n\t        return PROMPT_SYSTEM_BASIC_AGENT_V1\n\t    def get_human_prompt(self) -> str:\n\t        return PROMPT_HUMAN_BASIC_AGENT_V2\n\tPROMPT_HUMAN_BASIC_AGENT_V3 = f\"\"\"\n\tPredict the outcome of the following event.\n", "{{event_text}}\n\tRespond with:\n\t* What you learned might know about this.\n\t* Arguments for the event\n\t* Arguments against the event\n\t{OUTPUT_PROMPT_LIKELY}\n\t\"\"\"\n\tclass BasicAgentv3(BasicAgentv1):\n\t    def get_system_prompt(self) -> str:\n\t        return PROMPT_SYSTEM_BASIC_AGENT_V1\n", "    def get_human_prompt(self) -> str:\n\t        return PROMPT_HUMAN_BASIC_AGENT_V3\n\t    def parse_output(self, result: str) -> float:\n\t        return parse_likely_output(result)\n"]}
{"filename": "llm_oracle/agents/__init__.py", "chunked_list": []}
{"filename": "llm_oracle/agents/output.py", "chunked_list": ["import re\n\tOUTPUT_PROMPT_P10 = \"\"\"\n\tFinally, output a score between 0 and 10 (0 = high confident no or P(event) = 0%, 5 = unsure, 10 = high confident yes or P(event) = 100%).\n\tYou must use the format \"score=...\", e.g. score=3 or score=7. Use whole numbers. If you have a probability p [0.0, 1.0], then score = int(p*10).\n\t\"\"\"\n\tOUTPUT_PROMPT_P10_SCORE_REGEXES = [r\"[Ss]core\\s*=\\s*(\\d+)\", r\"[Ss]core\\s*of\\s*(\\d+)\"]\n\tdef parse_p10_output(output: str) -> float:\n\t    for regex in OUTPUT_PROMPT_P10_SCORE_REGEXES:\n\t        score_match = re.search(regex, output)\n\t        if score_match:\n", "            return int(score_match.group(1)) / 10\n\t    raise ValueError(output)\n\tOUTPUT_PROMPT_LIKELY = \"\"\"\n\tFinally, output a prediction from VERY_UNLIKELY to VERY_LIKELY.\n\tHere are the probabilities of each token:\n\t- VERY_UNLIKELY: 0% - 10%\n\t- UNLIKELY: 10% - 30%\n\t- SOMEWHAT_UNLIKELY: 30% - 45%\n\t- EVEN: 45% - 55%\n\t- SOMEWHAT_LIKELY: 55% - 70%\n", "- LIKELY: 70% - 90%\n\t- VERY_UNLIKELY: 90% - 100%\n\tYou must respond with exactly one of the tokens above like `prediction=SOMEWHAT_UNLIKELY` or `prediction=SOMEWHAT_LIKELY`.\n\t\"\"\"\n\tLIKELY_MAPPINGS = {\n\t    \"VERY_UNLIKELY\": 0.05,\n\t    \"VERY_LIKELY\": 0.95,\n\t    \"SOMEWHAT_UNLIKELY\": 0.37,\n\t    \"SOMEWHAT_LIKELY\": 0.62,\n\t    \"UNLIKELY\": 0.2,\n", "    \"LIKELY\": 0.8,\n\t    \"EVEN\": 0.5,\n\t}\n\tdef parse_likely_output(output: str) -> float:\n\t    for k, p in LIKELY_MAPPINGS.items():\n\t        if k in output:\n\t            return p\n\t    for k, p in LIKELY_MAPPINGS.items():\n\t        if k.lower().replace(\"_\", \"\") in output.lower().replace(\" \", \"\"):\n\t            return p\n", "    raise ValueError(output)\n"]}
{"filename": "llm_oracle/markets/custom.py", "chunked_list": ["from typing import List, Dict, Optional\n\timport datetime\n\tfrom llm_oracle.markets.base import Market, MarketEvent\n\tfrom llm_oracle import text_utils, processing_utils\n\tclass CustomEvent(MarketEvent):\n\t    def __init__(self, question: str, close_date: datetime.datetime, prior: Optional[float] = 0.5):\n\t        self.question = question\n\t        self.close_date = close_date\n\t        self.prior = prior\n\t    def to_text(self, *args, **kwargs) -> str:\n", "        text = [\"Prediction Market\"]\n\t        text.append(f'Will the following statement resolve to yes by the close date: \"{self.question}\"')\n\t        end_date = self.get_end_date()\n\t        if end_date is not None:\n\t            text.append(f\"close_date: {text_utils.future_date_to_string(self.get_end_date())}\")\n\t        text.append(text_utils.world_state_to_string())\n\t        return \"\\n\".join(text)\n\t    def get_title(self) -> str:\n\t        return self.question\n\t    def get_end_date(self) -> datetime.datetime:\n", "        return self.close_date\n\t    def get_market_probability(self) -> float:\n\t        return self.prior\n\t    def get_universal_id(self) -> str:\n\t        return \"custom:\" + processing_utils.hash_str(repr([self.question, self.close_date]))\n\t    def to_dict(self) -> Dict:\n\t        return {\"question\": self.question, \"close_date\": self.close_date}\n\t    def is_active(self) -> bool:\n\t        return True\n\t    def get_market_result(self) -> Optional[float]:\n", "        raise NotImplementedError()\n\tclass CustomMarket(Market):\n\t    def __init__(self, events: List[MarketEvent]):\n\t        self.events = events\n\t    def search(self, *args, **kwargs) -> List[Dict]:\n\t        return [event.to_dict() for event in self.events]\n\t    def get_event(self, event_id: str) -> CustomEvent:\n\t        return self.events[int(event_id)]\n"]}
{"filename": "llm_oracle/markets/base.py", "chunked_list": ["from typing import List, Dict, Optional\n\timport datetime\n\tfrom abc import ABC, abstractmethod\n\tclass MarketEvent(ABC):\n\t    @abstractmethod\n\t    def to_text(self, *args, **kwargs) -> str:\n\t        return\n\t    @abstractmethod\n\t    def get_end_date(self) -> datetime.datetime:\n\t        return\n", "    @abstractmethod\n\t    def get_market_probability(self) -> float:\n\t        return\n\t    @abstractmethod\n\t    def get_market_result(self) -> Optional[float]:\n\t        return\n\t    @abstractmethod\n\t    def get_title(self) -> str:\n\t        return\n\t    @abstractmethod\n", "    def get_universal_id(self) -> str:\n\t        return\n\t    @abstractmethod\n\t    def is_active(self) -> bool:\n\t        return\n\tclass Market(ABC):\n\t    @abstractmethod\n\t    def search(self, *args, **kwargs) -> List[Dict]:\n\t        return\n\t    @abstractmethod\n", "    def get_event(self, event_id: str) -> MarketEvent:\n\t        return\n"]}
{"filename": "llm_oracle/markets/kalshi.py", "chunked_list": ["from typing import List, Dict, Optional\n\timport requests\n\timport datetime\n\timport dateparser\n\timport kalshi_python\n\tfrom llm_oracle.markets.base import Market, MarketEvent\n\tfrom llm_oracle import text_utils\n\tconfig = kalshi_python.Configuration()\n\tclass KalshiEvent(MarketEvent):\n\t    def __init__(self, resp_json: Dict):\n", "        self.resp_json = resp_json\n\t    def to_text(self, *args, **kwargs) -> str:\n\t        text = [\"Kalshi Market\"]\n\t        for key in [\"title\", \"category\", \"subtitle\", \"can_close_early\"]:\n\t            text.append(f\"{key}: {self.resp_json[key]}\")\n\t        text.append(f\"close_date: {text_utils.future_date_to_string(self.get_end_date())}\")\n\t        text.append(text_utils.world_state_to_string())\n\t        return \"\\n\".join(text)\n\t    def get_title(self) -> str:\n\t        return self.resp_json[\"title\"]\n", "    def get_end_date(self) -> datetime.datetime:\n\t        return dateparser.parse(self.resp_json[\"close_time\"])\n\t    def get_market_probability(self) -> float:\n\t        return self.resp_json[\"last_price\"] / 100\n\t    def get_universal_id(self) -> str:\n\t        return \"kalshi2:\" + self.resp_json[\"ticker\"]\n\t    def is_active(self) -> bool:\n\t        return self.resp_json[\"status\"] == \"active\"\n\t    def get_market_result(self) -> Optional[float]:\n\t        result = self.resp_json.get(\"result\")\n", "        if result is None or result not in {\"yes\", \"no\"}:\n\t            return None\n\t        else:\n\t            return 1.0 if result == \"yes\" else 0.0\n\tclass KalshiMarket(Market):\n\t    def __init__(self, email: str, password: str):\n\t        self.session = kalshi_python.ApiInstance(\n\t            email=email,\n\t            password=password,\n\t            configuration=config,\n", "        )\n\t    def search(self, *args, **kwargs) -> List[Dict]:\n\t        return self.session.get_markets(*args, **kwargs).to_dict()[\"markets\"]\n\t    def get_event(self, event_id: str) -> KalshiEvent:\n\t        return KalshiEvent(self.session.get_market(event_id).to_dict()[\"market\"])\n"]}
{"filename": "llm_oracle/markets/manifold.py", "chunked_list": ["from typing import List, Dict, Optional\n\timport datetime\n\tfrom pymanifold import ManifoldClient, LiteMarket\n\tfrom llm_oracle.markets.base import Market, MarketEvent\n\tfrom llm_oracle import text_utils\n\tdef _content_to_text(node: Dict) -> str:\n\t    text = []\n\t    if \"content\" in node:\n\t        for content in node[\"content\"]:\n\t            text.append(_content_to_text(content))\n", "    if \"text\" in node:\n\t        text.append(node[\"text\"])\n\t    return \"\\n\".join(text)\n\tclass ManifoldEvent(MarketEvent):\n\t    def __init__(self, event_market: LiteMarket):\n\t        self.event_market = event_market\n\t    def to_text(self, *args, **kwargs) -> str:\n\t        text = [\"Manifold Market\"]\n\t        text.append(f\"question: {self.event_market.question}\")\n\t        text.append(f\"close_date: {text_utils.future_date_to_string(self.get_end_date())}\")\n", "        text.append(text_utils.world_state_to_string())\n\t        text.append(f\"description: \\n```\\n{self.get_description().strip()[:2000]}\\n```\")\n\t        return \"\\n\".join(text)\n\t    def get_description(self) -> str:\n\t        if self.event_market.description is None:\n\t            return \"\"\n\t        return _content_to_text(self.event_market.description)\n\t    def get_title(self) -> str:\n\t        return self.event_market.question\n\t    def get_end_date(self) -> datetime.datetime:\n", "        return datetime.datetime.fromtimestamp(self.event_market.closeTime / 1000)\n\t    def get_market_probability(self) -> float:\n\t        return self.event_market.probability\n\t    def get_universal_id(self) -> str:\n\t        return \"manifold2:\" + self.event_market.id\n\t    def is_active(self) -> bool:\n\t        return not self.event_market.isResolved\n\t    def get_market_result(self) -> Optional[float]:\n\t        res_p = self.event_market.resolutionProbability\n\t        return None if res_p is None else float(res_p)\n", "class ManifoldMarket(Market):\n\t    def __init__(self, **kwargs):\n\t        self.client = ManifoldClient(**kwargs)\n\t    def search(self, *args, **kwargs) -> List[Dict]:\n\t        return [dict(m.__dict__) for m in self.client.list_markets(*args, **kwargs)]\n\t    def get_event(self, event_id: str) -> ManifoldEvent:\n\t        if \"-\" in event_id:\n\t            me = self.client.get_market_by_slug(event_id)\n\t        else:\n\t            me = self.client.get_market_by_id(event_id)\n", "        return ManifoldEvent(me)\n"]}
{"filename": "llm_oracle/markets/__init__.py", "chunked_list": []}
{"filename": "examples/predict_markets.py", "chunked_list": ["from llm_oracle.markets.kalshi import KalshiMarket\n\tfrom llm_oracle.markets.custom import CustomMarket, CustomEvent\n\tfrom llm_oracle.markets.manifold import ManifoldMarket\n\tfrom llm_oracle.agents.agent_basic import BasicAgentv1, BasicAgentv2, BasicAgentv3\n\tfrom llm_oracle.agents.agent_tools import ToolAgentv1, ToolAgentv2, ToolAgentv3\n\timport datetime\n\timport os\n\tmanifold_market = ManifoldMarket()\n\tkalshi_market = KalshiMarket(email=os.environ[\"KALSHI_EMAIL\"], password=os.environ[\"KALSHI_PASSWORD\"])\n\tkalshi_event_ids = [\n", "    \"GTEMP-23-P1.02\",\n\t    \"NPPC-24DEC31\",\n\t    \"BIDENVNEBRASKA-24DEC31\",\n\t    \"TIKTOKBAN-23DEC31\",\n\t    \"SFFA-COMPLETE\",\n\t    \"COIN-23DEC31\",\n\t    \"HURCTOTMAJ-23DEC01-T3\",\n\t    \"SCOTUSN-23\",\n\t    \"MOON-25\",\n\t]\n", "manifold_event_ids = [\n\t    \"will-lex-fridman-interview-ai-by-20\",\n\t    \"will-biden-be-the-2024-democratic-n\",\n\t    \"will-a-nuclear-weapon-be-detonated-b71e74f6a8e4\",\n\t]\n\tcustom_market = CustomMarket(\n\t    [\n\t        CustomEvent(\n\t            \"Will a humanity be replaced by AI by 2050?\",\n\t            datetime.datetime(2050, 1, 1),\n", "        ),\n\t        CustomEvent(\n\t            \"Will a random number that I pull from a uniform distribution [0, 100] be greater or equal to 99?\",\n\t            datetime.datetime(2025, 1, 1),\n\t        ),\n\t    ]\n\t)\n\tEVENTS = (\n\t    [kalshi_market.get_event(kid) for kid in kalshi_event_ids]\n\t    + [manifold_market.get_event(mid) for mid in manifold_event_ids]\n", "    + custom_market.events\n\t)\n\tAGENTS = {\n\t    \"basic_v1\": BasicAgentv1(),\n\t    \"basic_v2\": BasicAgentv2(),\n\t    \"basic_v3\": BasicAgentv3(),\n\t    \"tool_v1\": ToolAgentv1(),\n\t    \"tool_v2\": ToolAgentv2(),\n\t    \"tool_v3\": ToolAgentv3(),\n\t}\n", "for event in EVENTS:\n\t    if not event.is_active():\n\t        continue\n\t    title = event.get_title()\n\t    event_uid = event.get_universal_id()\n\t    market_p = event.get_market_probability()\n\t    for agent_name, agent in AGENTS.items():\n\t        p = agent.predict_event_probability(event)\n\t        with open(\"predictions.tsv\", \"a\") as f:\n\t            f.write(f\"{event_uid}\\t{title}\\t{market_p}\\t{agent_name}\\t{p}\\n\")\n"]}
