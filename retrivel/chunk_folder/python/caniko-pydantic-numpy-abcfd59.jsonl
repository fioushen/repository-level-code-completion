{"filename": "tests/test_np_model.py", "chunked_list": ["import tempfile\n\tfrom pathlib import Path\n\timport numpy as np\n\timport pytest\n\tfrom hypothesis.extra.numpy import arrays\n\tfrom pydantic_numpy.model import NumpyModel\n\tfrom pydantic_numpy.model.np_model import model_agnostic_load\n\tfrom pydantic_numpy.typing import NpNDArray\n\tTEST_MODEL_OBJECT_ID = \"test\"\n\tOTHER_TEST_MODEL_OBJECT_ID = \"other_test\"\n", "NON_ARRAY_VALUE = 5\n\tclass NumpyModelForTest(NumpyModel):\n\t    array: NpNDArray\n\t    non_array: int\n\tclass TestWithArbitraryForTest(NumpyModelForTest, arbitrary_types_allowed=True):\n\t    my_arbitrary_slice: slice\n\tdef _create_example_array():\n\t    return arrays(np.float64, (1,)).example()\n\tdef _numpy_model():\n\t    return NumpyModelForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n", "@pytest.fixture\n\tdef numpy_model():\n\t    return _numpy_model()\n\t@pytest.fixture(\n\t    params=[\n\t        _numpy_model(),\n\t        TestWithArbitraryForTest(\n\t            array=_create_example_array(), non_array=NON_ARRAY_VALUE, my_arbitrary_slice=slice(0, 10)\n\t        ),\n\t    ]\n", ")\n\tdef numpy_model_with_arbitrary(request):\n\t    return request.param\n\tdef test_io_yaml(numpy_model: NumpyModel) -> None:\n\t    with tempfile.TemporaryDirectory() as tmp_dirname:\n\t        numpy_model.dump(tmp_dirname, TEST_MODEL_OBJECT_ID)\n\t        assert numpy_model.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model\n\tdef test_io_compressed_pickle(numpy_model_with_arbitrary: NumpyModel) -> None:\n\t    with tempfile.TemporaryDirectory() as tmp_dirname:\n\t        numpy_model_with_arbitrary.dump(tmp_dirname, TEST_MODEL_OBJECT_ID, pickle=True)\n", "        assert numpy_model_with_arbitrary.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model_with_arbitrary\n\tdef test_io_pickle(numpy_model_with_arbitrary: NumpyModel) -> None:\n\t    with tempfile.TemporaryDirectory() as tmp_dirname:\n\t        numpy_model_with_arbitrary.dump(tmp_dirname, TEST_MODEL_OBJECT_ID, pickle=True, compress=False)\n\t        assert numpy_model_with_arbitrary.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model_with_arbitrary\n\tdef test_typing_json_dump(numpy_model: NumpyModel):\n\t    assert numpy_model.model_dump_json() == '{\"array\":\"%s\",\"non_array\":%s}' % (\n\t        np.array2string(numpy_model.array),\n\t        NON_ARRAY_VALUE,\n\t    ), \"\"\n", "def test_model_agnostic_load():\n\t    class NumpyModelAForTest(NumpyModel):\n\t        array: NpNDArray\n\t        non_array: int\n\t    class NumpyModelBForTest(NumpyModel):\n\t        array: NpNDArray\n\t        non_array: int\n\t    model_a = NumpyModelAForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n\t    model_b = NumpyModelBForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n\t    with tempfile.TemporaryDirectory() as tmp_dirname:\n", "        tmp_dir_path = Path(tmp_dirname)\n\t        model_a.dump(tmp_dir_path, TEST_MODEL_OBJECT_ID)\n\t        model_b.dump(tmp_dir_path, OTHER_TEST_MODEL_OBJECT_ID)\n\t        models = [model_a, model_b]\n\t        assert model_a == model_agnostic_load(tmp_dir_path, TEST_MODEL_OBJECT_ID, models=models)\n\t        assert model_b == model_agnostic_load(tmp_dir_path, OTHER_TEST_MODEL_OBJECT_ID, models=models)\n"]}
{"filename": "tests/test_typing.py", "chunked_list": ["import tempfile\n\tfrom pathlib import Path\n\tfrom typing import Optional\n\timport numpy as np\n\timport numpy.typing as npt\n\timport pytest\n\tfrom hypothesis.extra.numpy import arrays\n\tfrom pydantic import ValidationError\n\tfrom pydantic_numpy.helper.validation import PydanticNumpyMultiArrayNumpyFileOnFilePath\n\tfrom pydantic_numpy.model import MultiArrayNumpyFile\n", "from pydantic_numpy.util import np_general_all_close\n\tfrom tests.helper.cache import cached_calculation\n\tfrom tests.helper.groups import (\n\t    data_type_array_typing_dimensions,\n\t    dimension_testing_group,\n\t    strict_data_type_nd_array_typing_dimensions,\n\t    supported_data_types,\n\t)\n\tAXIS_LENGTH = 1\n\t@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\n", "def test_correct_type(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n\t    assert cached_calculation(pydantic_typing)(\n\t        array_field=arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n\t    )\n\t@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", strict_data_type_nd_array_typing_dimensions)\n\t@pytest.mark.parametrize(\"wrong_numpy_type\", supported_data_types)\n\tdef test_wrong_dtype_type(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int], wrong_numpy_type):\n\t    if wrong_numpy_type == numpy_dtype:\n\t        return True\n\t    bad_array = arrays(wrong_numpy_type, tuple(AXIS_LENGTH for _ in range(dimensions or 5))).example()\n", "    with pytest.raises(ValidationError):\n\t        cached_calculation(pydantic_typing)(array_field=bad_array)\n\t@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", dimension_testing_group)\n\tdef test_wrong_dimension(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n\t    wrong_dimension = dimensions + 1\n\t    bad_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(wrong_dimension or 5))).example()\n\t    with pytest.raises(ValueError):\n\t        cached_calculation(pydantic_typing)(array_field=bad_array)\n\t@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\n\tdef test_file_path_passing_validation(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n", "    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n\t    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npz\") as tf:\n\t        np.savez_compressed(tf.name, my_array=hyp_array)\n\t        numpy_model = cached_calculation(pydantic_typing)(array_field=Path(tf.name))\n\t        assert np_general_all_close(numpy_model.array_field, hyp_array)\n\t@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\n\tdef test_file_path_error_on_reading_single_array_file(\n\t    numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]\n\t):\n\t    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n", "    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npz\") as tf:\n\t        np.savez_compressed(tf.name, my_array=hyp_array, my_identical_array=hyp_array)\n\t        model = cached_calculation(pydantic_typing)\n\t        with pytest.raises(PydanticNumpyMultiArrayNumpyFileOnFilePath):\n\t            model(array_field=Path(tf.name))\n\t@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\n\tdef test_multi_array_numpy_passing_validation(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n\t    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n\t    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npz\") as tf:\n\t        np.savez_compressed(tf.name, my_array=hyp_array)\n", "        numpy_model = cached_calculation(pydantic_typing)(\n\t            array_field=MultiArrayNumpyFile(path=Path(tf.name), key=\"my_array\")\n\t        )\n\t        assert np_general_all_close(numpy_model.array_field, hyp_array)\n\t@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\n\tdef test_multi_array_numpy_error_on_reading_single_array_file(\n\t    numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]\n\t):\n\t    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n\t    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npy\") as tf:\n", "        np.save(tf.name, hyp_array)\n\t        model = cached_calculation(pydantic_typing)\n\t        with pytest.raises(AttributeError):\n\t            model(array_field=MultiArrayNumpyFile(path=Path(tf.name), key=\"my_array\"))\n"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/helper/cache.py", "chunked_list": ["from functools import cache\n\tfrom pydantic import BaseModel\n\t@cache\n\tdef cached_calculation(array_type_hint) -> type[BaseModel]:\n\t    class ModelForTesting(BaseModel):\n\t        array_field: array_type_hint\n\t    return ModelForTesting\n"]}
{"filename": "tests/helper/__init__.py", "chunked_list": []}
{"filename": "tests/helper/groups.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.typing import *\n\tsupported_data_types = (\n\t    np.int64,\n\t    np.int32,\n\t    np.int16,\n\t    np.int8,\n\t    np.uint64,\n\t    np.uint32,\n\t    np.uint16,\n", "    np.uint8,\n\t    np.float128,\n\t    np.float64,\n\t    np.float32,\n\t    np.float16,\n\t    np.complex256,\n\t    np.complex128,\n\t    np.complex64,\n\t    np.datetime64,\n\t    np.timedelta64,\n", ")\n\tdata_type_1d_array_typing_dimensions = [\n\t    (np.int64, Np1DArrayInt64, 1),\n\t    (np.int32, Np1DArrayInt32, 1),\n\t    (np.int16, Np1DArrayInt16, 1),\n\t    (np.int8, Np1DArrayInt8, 1),\n\t    (np.uint64, Np1DArrayUint64, 1),\n\t    (np.uint32, Np1DArrayUint32, 1),\n\t    (np.uint16, Np1DArrayUint16, 1),\n\t    (np.uint8, Np1DArrayUint8, 1),\n", "    (np.float128, Np1DArrayFp128, 1),\n\t    (np.float64, Np1DArrayFp64, 1),\n\t    (np.float32, Np1DArrayFp32, 1),\n\t    (np.float16, Np1DArrayFp16, 1),\n\t    (np.complex256, Np1DArrayComplex256, 1),\n\t    (np.complex128, Np1DArrayComplex128, 1),\n\t    (np.complex64, Np1DArrayComplex64, 1),\n\t    (bool, Np1DArrayBool, 1),\n\t    (np.datetime64, Np1DArrayDatetime64, 1),\n\t    (np.timedelta64, Np1DArrayTimedelta64, 1),\n", "]\n\tdata_type_2d_array_typing_dimensions = [\n\t    (np.int64, Np2DArrayInt64, 2),\n\t    (np.int32, Np2DArrayInt32, 2),\n\t    (np.int16, Np2DArrayInt16, 2),\n\t    (np.int8, Np2DArrayInt8, 2),\n\t    (np.uint64, Np2DArrayUint64, 2),\n\t    (np.uint32, Np2DArrayUint32, 2),\n\t    (np.uint16, Np2DArrayUint16, 2),\n\t    (np.uint8, Np2DArrayUint8, 2),\n", "    (np.float128, Np2DArrayFp128, 2),\n\t    (np.float64, Np2DArrayFp64, 2),\n\t    (np.float32, Np2DArrayFp32, 2),\n\t    (np.float16, Np2DArrayFp16, 2),\n\t    (np.complex256, Np2DArrayComplex256, 2),\n\t    (np.complex128, Np2DArrayComplex128, 2),\n\t    (np.complex64, Np2DArrayComplex64, 2),\n\t    (bool, Np2DArrayBool, 2),\n\t    (np.datetime64, Np2DArrayDatetime64, 2),\n\t    (np.timedelta64, Np2DArrayTimedelta64, 2),\n", "]\n\tdata_type_3d_array_typing_dimensions = [\n\t    (np.int64, Np3DArrayInt64, 3),\n\t    (np.int32, Np3DArrayInt32, 3),\n\t    (np.int16, Np3DArrayInt16, 3),\n\t    (np.int8, Np3DArrayInt8, 3),\n\t    (np.uint64, Np3DArrayUint64, 3),\n\t    (np.uint32, Np3DArrayUint32, 3),\n\t    (np.uint16, Np3DArrayUint16, 3),\n\t    (np.uint8, Np3DArrayUint8, 3),\n", "    (np.float128, Np3DArrayFp128, 3),\n\t    (np.float64, Np3DArrayFp64, 3),\n\t    (np.float32, Np3DArrayFp32, 3),\n\t    (np.float16, Np3DArrayFp16, 3),\n\t    (np.complex256, Np3DArrayComplex256, 3),\n\t    (np.complex128, Np3DArrayComplex128, 3),\n\t    (np.complex64, Np3DArrayComplex64, 3),\n\t    (bool, Np3DArrayBool, 3),\n\t    (np.datetime64, Np3DArrayDatetime64, 3),\n\t    (np.timedelta64, Np3DArrayTimedelta64, 3),\n", "]\n\tdata_type_nd_array_typing_dimensions = [\n\t    (np.int64, NpNDArrayInt64, None),\n\t    (np.int32, NpNDArrayInt32, None),\n\t    (np.int16, NpNDArrayInt16, None),\n\t    (np.int8, NpNDArrayInt8, None),\n\t    (np.uint64, NpNDArrayUint64, None),\n\t    (np.uint32, NpNDArrayUint32, None),\n\t    (np.uint16, NpNDArrayUint16, None),\n\t    (np.uint8, NpNDArrayUint8, None),\n", "    (np.float128, NpNDArrayFp128, None),\n\t    (np.float64, NpNDArrayFp64, None),\n\t    (np.float32, NpNDArrayFp32, None),\n\t    (np.float16, NpNDArrayFp16, None),\n\t    (np.complex256, NpNDArrayComplex256, None),\n\t    (np.complex128, NpNDArrayComplex128, None),\n\t    (np.complex64, NpNDArrayComplex64, None),\n\t    (bool, NpNDArrayBool, None),\n\t    (np.datetime64, NpNDArrayDatetime64, None),\n\t    (np.timedelta64, NpNDArrayTimedelta64, None),\n", "]\n\tdata_type_array_typing_dimensions = [\n\t    *data_type_1d_array_typing_dimensions,\n\t    *data_type_2d_array_typing_dimensions,\n\t    *data_type_3d_array_typing_dimensions,\n\t    *data_type_nd_array_typing_dimensions,\n\t]\n\t# Data type strict\n\tstrict_data_type_1d_array_typing_dimensions = [\n\t    (np.int64, NpStrict1DArrayInt64, 1),\n", "    (np.int32, NpStrict1DArrayInt32, 1),\n\t    (np.int16, NpStrict1DArrayInt16, 1),\n\t    (np.int8, NpStrict1DArrayInt8, 1),\n\t    (np.uint64, NpStrict1DArrayUint64, 1),\n\t    (np.uint32, NpStrict1DArrayUint32, 1),\n\t    (np.uint16, NpStrict1DArrayUint16, 1),\n\t    (np.uint8, NpStrict1DArrayUint8, 1),\n\t    (np.float128, NpStrict1DArrayFp128, 1),\n\t    (np.float64, NpStrict1DArrayFp64, 1),\n\t    (np.float32, NpStrict1DArrayFp32, 1),\n", "    (np.float16, NpStrict1DArrayFp16, 1),\n\t    (np.complex256, NpStrict1DArrayComplex256, 1),\n\t    (np.complex128, NpStrict1DArrayComplex128, 1),\n\t    (np.complex64, NpStrict1DArrayComplex64, 1),\n\t    (bool, NpStrict1DArrayBool, 1),\n\t    (np.datetime64, NpStrict1DArrayDatetime64, 1),\n\t    (np.timedelta64, NpStrict1DArrayTimedelta64, 1),\n\t]\n\tstrict_data_type_2d_array_typing_dimensions = [\n\t    (np.int64, NpStrict2DArrayInt64, 2),\n", "    (np.int32, NpStrict2DArrayInt32, 2),\n\t    (np.int16, NpStrict2DArrayInt16, 2),\n\t    (np.int8, NpStrict2DArrayInt8, 2),\n\t    (np.uint64, NpStrict2DArrayUint64, 2),\n\t    (np.uint32, NpStrict2DArrayUint32, 2),\n\t    (np.uint16, NpStrict2DArrayUint16, 2),\n\t    (np.uint8, NpStrict2DArrayUint8, 2),\n\t    (np.float128, NpStrict2DArrayFp128, 2),\n\t    (np.float64, NpStrict2DArrayFp64, 2),\n\t    (np.float32, NpStrict2DArrayFp32, 2),\n", "    (np.float16, NpStrict2DArrayFp16, 2),\n\t    (np.complex256, NpStrict2DArrayComplex256, 2),\n\t    (np.complex128, NpStrict2DArrayComplex128, 2),\n\t    (np.complex64, NpStrict2DArrayComplex64, 2),\n\t    (bool, NpStrict2DArrayBool, 2),\n\t    (np.datetime64, NpStrict2DArrayDatetime64, 2),\n\t    (np.timedelta64, NpStrict2DArrayTimedelta64, 2),\n\t]\n\tstrict_data_type_3d_array_typing_dimensions = [\n\t    (np.int64, NpStrict3DArrayInt64, 3),\n", "    (np.int32, NpStrict3DArrayInt32, 3),\n\t    (np.int16, NpStrict3DArrayInt16, 3),\n\t    (np.int8, NpStrict3DArrayInt8, 3),\n\t    (np.uint64, NpStrict3DArrayUint64, 3),\n\t    (np.uint32, NpStrict3DArrayUint32, 3),\n\t    (np.uint16, NpStrict3DArrayUint16, 3),\n\t    (np.uint8, NpStrict3DArrayUint8, 3),\n\t    (np.float128, NpStrict3DArrayFp128, 3),\n\t    (np.float64, NpStrict3DArrayFp64, 3),\n\t    (np.float32, NpStrict3DArrayFp32, 3),\n", "    (np.float16, NpStrict3DArrayFp16, 3),\n\t    (np.complex256, NpStrict3DArrayComplex256, 3),\n\t    (np.complex128, NpStrict3DArrayComplex128, 3),\n\t    (np.complex64, NpStrict3DArrayComplex64, 3),\n\t    (bool, NpStrict3DArrayBool, 3),\n\t    (np.datetime64, NpStrict3DArrayDatetime64, 3),\n\t    (np.timedelta64, NpStrict3DArrayTimedelta64, 3),\n\t]\n\tstrict_data_type_nd_array_typing_dimensions = [\n\t    (np.int64, NpStrictNDArrayInt64, None),\n", "    (np.int32, NpStrictNDArrayInt32, None),\n\t    (np.int16, NpStrictNDArrayInt16, None),\n\t    (np.int8, NpStrictNDArrayInt8, None),\n\t    (np.uint64, NpStrictNDArrayUint64, None),\n\t    (np.uint32, NpStrictNDArrayUint32, None),\n\t    (np.uint16, NpStrictNDArrayUint16, None),\n\t    (np.uint8, NpStrictNDArrayUint8, None),\n\t    (np.float128, NpStrictNDArrayFp128, None),\n\t    (np.float64, NpStrictNDArrayFp64, None),\n\t    (np.float32, NpStrictNDArrayFp32, None),\n", "    (np.float16, NpStrictNDArrayFp16, None),\n\t    (np.complex256, NpStrictNDArrayComplex256, None),\n\t    (np.complex128, NpStrictNDArrayComplex128, None),\n\t    (np.complex64, NpStrictNDArrayComplex64, None),\n\t    (bool, NpStrictNDArrayBool, None),\n\t    (np.datetime64, NpStrictNDArrayDatetime64, None),\n\t    (np.timedelta64, NpStrictNDArrayTimedelta64, None),\n\t]\n\tstrict_data_type_array_typing_dimensions = [\n\t    *strict_data_type_1d_array_typing_dimensions,\n", "    *strict_data_type_2d_array_typing_dimensions,\n\t    *strict_data_type_3d_array_typing_dimensions,\n\t    *strict_data_type_nd_array_typing_dimensions,\n\t]\n\tdimension_testing_group = [\n\t    (np.int64, Np1DArrayInt64, 1),\n\t    (np.int64, Np2DArrayInt64, 2),\n\t    (np.int64, Np3DArrayInt64, 3),\n\t]\n"]}
{"filename": "pydantic_numpy/__init__.py", "chunked_list": ["from pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tfrom pydantic_numpy.typing.n_dimensional import *\n"]}
{"filename": "pydantic_numpy/util.py", "chunked_list": ["import numpy as np\n\timport numpy.typing as npt\n\tfrom numpy.core._exceptions import UFuncTypeError\n\tfrom semver import Version\n\tdef np_general_all_close(arr_a: npt.NDArray, arr_b: npt.NDArray, rtol: float = 1e-05, atol: float = 1e-08) -> bool:\n\t    \"\"\"\n\t    Data type agnostic function to define if two numpy array have elements that are close\n\t    Parameters\n\t    ----------\n\t    arr_a: npt.NDArray\n", "    arr_b: npt.NDArray\n\t    rtol: float\n\t        See np.allclose\n\t    atol: float\n\t        See np.allclose\n\t    Returns\n\t    -------\n\t    Bool\n\t    \"\"\"\n\t    return _np_general_all_close(arr_a, arr_b, rtol, atol)\n", "if Version.parse(np.version.version) < Version.parse(\"1.25.0\"):\n\t    def _np_general_all_close(arr_a: npt.NDArray, arr_b: npt.NDArray, rtol: float = 1e-05, atol: float = 1e-08) -> bool:\n\t        try:\n\t            return np.allclose(arr_a, arr_b, rtol=rtol, atol=atol, equal_nan=True)\n\t        except UFuncTypeError:\n\t            return np.allclose(arr_a.astype(np.float64), arr_b.astype(np.float64), rtol=rtol, atol=atol, equal_nan=True)\n\t        except TypeError:\n\t            return bool(np.all(arr_a == arr_b))\n\telse:\n\t    from numpy.exceptions import DTypePromotionError\n", "    def _np_general_all_close(arr_a: npt.NDArray, arr_b: npt.NDArray, rtol: float = 1e-05, atol: float = 1e-08) -> bool:\n\t        try:\n\t            return np.allclose(arr_a, arr_b, rtol=rtol, atol=atol, equal_nan=True)\n\t        except UFuncTypeError:\n\t            return np.allclose(arr_a.astype(np.float64), arr_b.astype(np.float64), rtol=rtol, atol=atol, equal_nan=True)\n\t        except DTypePromotionError:\n\t            return bool(np.all(arr_a == arr_b))\n"]}
{"filename": "pydantic_numpy/model/__init__.py", "chunked_list": ["from pydantic_numpy.model.multi_array import MultiArrayNumpyFile\n\tfrom pydantic_numpy.model.np_model import NumpyModel\n"]}
{"filename": "pydantic_numpy/model/np_model.py", "chunked_list": ["import pickle as pickle_pkg\n\tfrom pathlib import Path\n\tfrom typing import Any, Callable, ClassVar, Iterable, Optional\n\timport compress_pickle\n\timport numpy as np\n\timport numpy.typing as npt\n\tfrom pydantic import BaseModel, DirectoryPath, FilePath, computed_field, validate_call\n\tfrom ruamel.yaml import YAML\n\tfrom pydantic_numpy.util import np_general_all_close\n\tyaml = YAML()\n", "class NumpyModel(BaseModel):\n\t    _dump_compression: ClassVar[str] = \"lz4\"\n\t    _dump_numpy_savez_file_name: ClassVar[str] = \"arrays.npz\"\n\t    _dump_non_array_file_stem: ClassVar[str] = \"object_info\"\n\t    _directory_suffix: ClassVar[str] = \".pdnp\"\n\t    def __eq__(self, other: Any) -> bool:\n\t        if isinstance(other, NumpyModel):\n\t            self_type = self.__pydantic_generic_metadata__[\"origin\"] or self.__class__\n\t            other_type = other.__pydantic_generic_metadata__[\"origin\"] or other.__class__\n\t            self_ndarray_field_to_array, self_other_field_to_value = self._dump_numpy_split_dict()\n", "            other_ndarray_field_to_array, other_other_field_to_value = other._dump_numpy_split_dict()\n\t            return (\n\t                self_type == other_type\n\t                and self_other_field_to_value == other_other_field_to_value\n\t                and self.__pydantic_private__ == other.__pydantic_private__\n\t                and self.__pydantic_extra__ == other.__pydantic_extra__\n\t                and _compare_np_array_dicts(self_ndarray_field_to_array, other_ndarray_field_to_array)\n\t            )\n\t        elif isinstance(other, BaseModel):\n\t            return super().__eq__(other)\n", "        else:\n\t            return NotImplemented  # delegate to the other item in the comparison\n\t    @classmethod\n\t    @validate_call\n\t    def model_directory_path(cls, output_directory: DirectoryPath, object_id: str) -> DirectoryPath:\n\t        return output_directory / f\"{object_id}.{cls.__name__}{cls._directory_suffix}\"\n\t    @classmethod\n\t    @validate_call\n\t    def load(\n\t        cls,\n", "        output_directory: DirectoryPath,\n\t        object_id: str,\n\t        *,\n\t        pre_load_modifier: Optional[Callable[[dict[str, Any]], dict[str, Any]]] = None,\n\t    ):\n\t        \"\"\"\n\t        Load NumpyModel instance\n\t        Parameters\n\t        ----------\n\t        output_directory: DirectoryPath\n", "            The root directory where all model instances of interest are stored\n\t        object_id: String\n\t            The ID of the model instance\n\t        pre_load_modifier: Callable[[dict[str, Any]], dict[str, Any]] | None\n\t            Optional function that modifies the loaded arrays\n\t        Returns\n\t        -------\n\t        NumpyModel instance\n\t        \"\"\"\n\t        object_directory_path = cls.model_directory_path(output_directory, object_id)\n", "        npz_file = np.load(object_directory_path / cls._dump_numpy_savez_file_name)\n\t        other_path: FilePath\n\t        if (other_path := object_directory_path / cls._dump_compressed_pickle_file_name).exists():\n\t            other_field_to_value = compress_pickle.load(other_path)\n\t        elif (other_path := object_directory_path / cls._dump_pickle_file_name).exists():\n\t            with open(other_path, \"rb\") as in_pickle:\n\t                other_field_to_value = pickle_pkg.load(in_pickle)\n\t        elif (other_path := object_directory_path / cls._dump_non_array_yaml_name).exists():\n\t            with open(other_path, \"r\") as in_yaml:\n\t                other_field_to_value = yaml.load(in_yaml)\n", "        else:\n\t            other_field_to_value = {}\n\t        field_to_value = {**npz_file, **other_field_to_value}\n\t        if pre_load_modifier:\n\t            field_to_value = pre_load_modifier(field_to_value)\n\t        return cls(**field_to_value)\n\t    @validate_call\n\t    def dump(\n\t        self, output_directory: Path, object_id: str, *, compress: bool = True, pickle: bool = False\n\t    ) -> DirectoryPath:\n", "        assert \"arbitrary_types_allowed\" not in self.model_config or (\n\t            self.model_config[\"arbitrary_types_allowed\"] and pickle\n\t        ), \"Arbitrary types are only supported in pickle mode\"\n\t        dump_directory_path = self.model_directory_path(output_directory, object_id)\n\t        dump_directory_path.mkdir(parents=True, exist_ok=True)\n\t        ndarray_field_to_array, other_field_to_value = self._dump_numpy_split_dict()\n\t        if ndarray_field_to_array:\n\t            (np.savez_compressed if compress else np.savez)(\n\t                dump_directory_path / self._dump_numpy_savez_file_name, **ndarray_field_to_array\n\t            )\n", "        if other_field_to_value:\n\t            if pickle:\n\t                if compress:\n\t                    compress_pickle.dump(\n\t                        other_field_to_value,\n\t                        dump_directory_path / self._dump_compressed_pickle_file_name,\n\t                        compression=self._dump_compression,\n\t                    )\n\t                else:\n\t                    with open(dump_directory_path / self._dump_pickle_file_name, \"wb\") as out_pickle:\n", "                        pickle_pkg.dump(other_field_to_value, out_pickle)\n\t            else:\n\t                with open(dump_directory_path / self._dump_non_array_yaml_name, \"w\") as out_yaml:\n\t                    yaml.dump(other_field_to_value, out_yaml)\n\t        return dump_directory_path\n\t    def _dump_numpy_split_dict(self) -> tuple[dict, dict]:\n\t        ndarray_field_to_array = {}\n\t        other_field_to_value = {}\n\t        for k, v in self.model_dump(exclude_unset=True).items():\n\t            if isinstance(v, np.ndarray):\n", "                ndarray_field_to_array[k] = v\n\t            else:\n\t                other_field_to_value[k] = v\n\t        return ndarray_field_to_array, other_field_to_value\n\t    @classmethod  # type: ignore[misc]\n\t    @computed_field(return_type=str)\n\t    @property\n\t    def _dump_compressed_pickle_file_name(cls) -> str:\n\t        return f\"{cls._dump_non_array_file_stem}.pickle.{cls._dump_compression}\"\n\t    @classmethod  # type: ignore[misc]\n", "    @computed_field(return_type=str)\n\t    @property\n\t    def _dump_pickle_file_name(cls) -> str:\n\t        return f\"{cls._dump_non_array_file_stem}.pickle\"\n\t    @classmethod  # type: ignore[misc]\n\t    @computed_field(return_type=str)\n\t    @property\n\t    def _dump_non_array_yaml_name(cls) -> str:\n\t        return f\"{cls._dump_non_array_file_stem}.yaml\"\n\tdef model_agnostic_load(\n", "    output_directory: DirectoryPath,\n\t    object_id: str,\n\t    models: Iterable[type[NumpyModel]],\n\t    not_found_error: bool = False,\n\t    **load_kwargs,\n\t) -> Optional[NumpyModel]:\n\t    \"\"\"\n\t    Provided an Iterable containing possible models, and the directory where they have been dumped. Load the first\n\t    instance of model that matches the provided object ID.\n\t    Parameters\n", "    ----------\n\t    output_directory: DirectoryPath\n\t        The root directory where all model instances of interest are stored\n\t    object_id: String\n\t        The ID of the model instance\n\t    models: Iterable[type[NumpyModel]]\n\t        All NumpyModel instances of interest, note that they should have differing names\n\t    not_found_error: bool\n\t        If True, throw error when the respective model instance was not found\n\t    load_kwargs\n", "        Key-word arguments to pass to the load function\n\t    Returns\n\t    -------\n\t    NumpyModel instance if found\n\t    \"\"\"\n\t    for model in models:\n\t        if model.model_directory_path(output_directory, object_id).exists():\n\t            return model.load(output_directory, object_id, **load_kwargs)\n\t    if not_found_error:\n\t        raise FileNotFoundError(\n", "            f\"Could not find NumpyModel with {object_id} in {output_directory}.\"\n\t            f\"Tried from following classes:\\n{', '.join(model.__name__ for model in models)}\"\n\t        )\n\t    return None\n\tdef _compare_np_array_dicts(\n\t    dict_a: dict[str, npt.NDArray], dict_b: dict[str, npt.NDArray], rtol: float = 1e-05, atol: float = 1e-08\n\t) -> bool:\n\t    \"\"\"\n\t    Compare two dictionaries containing numpy arrays as values.\n\t    Parameters:\n", "    dict_a, dict_b: dictionaries to compare. They should have same keys.\n\t    rtol, atol: relative and absolute tolerances for np.isclose()\n\t    Returns:\n\t    Boolean value for each key, True if corresponding arrays are close, else False.\n\t    \"\"\"\n\t    keys1 = frozenset(dict_a.keys())\n\t    keys2 = frozenset(dict_b.keys())\n\t    if keys1 != keys2:\n\t        raise ValueError(\"Dictionaries have different keys\")\n\t    for key in keys1:\n", "        arr_a = dict_a[key]\n\t        arr_b = dict_b[key]\n\t        if arr_a.shape != arr_b.shape:\n\t            raise ValueError(f\"Arrays for key '{key}' have different shapes\")\n\t        if not np_general_all_close(arr_a, arr_b, rtol, atol):\n\t            return False\n\t    return True\n\t__all__ = [\"NumpyModel\", \"model_agnostic_load\"]\n"]}
{"filename": "pydantic_numpy/model/multi_array.py", "chunked_list": ["from functools import lru_cache\n\timport numpy as np\n\timport numpy.typing as npt\n\tfrom pydantic import FilePath\n\tfrom pydantic.dataclasses import dataclass\n\t@dataclass(frozen=True)\n\tclass MultiArrayNumpyFile:\n\t    path: FilePath\n\t    key: str\n\t    cached_load: bool = False\n", "    def load(self) -> npt.NDArray:\n\t        \"\"\"\n\t        Load the NDArray stored in the given path within the given key\n\t        Returns\n\t        -------\n\t        NDArray\n\t        \"\"\"\n\t        loaded = _cached_np_array_load(self.path) if self.cached_load else np.load(self.path)\n\t        try:\n\t            return loaded[self.key]\n", "        except IndexError:\n\t            msg = f\"The given path points to an uncompressed numpy file, which only has one array in it: {self.path}\"\n\t            raise AttributeError(msg)\n\t@lru_cache\n\tdef _cached_np_array_load(path: FilePath):\n\t    \"\"\"\n\t    Store the loaded numpy object within LRU cache in case we need it several times\n\t    Parameters\n\t    ----------\n\t    path: FilePath\n", "        Path to the numpy file\n\t    Returns\n\t    -------\n\t    Same as np.load\n\t    \"\"\"\n\t    return np.load(path)\n\t__all__ = [\"MultiArrayNumpyFile\"]\n"]}
{"filename": "pydantic_numpy/typing/ii_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNp2DArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=2, strict_data_typing=False)\n\tNp2DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=2)\n\tNp2DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=2)\n\tNp2DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=2)\n\tNp2DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=2)\n\tNp2DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=2)\n\tNp2DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=2)\n\tNp2DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=2)\n", "Np2DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=2)\n\tNp2DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=2)\n\tNp2DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=2)\n\tNp2DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=2)\n\tNp2DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=2)\n\tNp2DArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, dimensions=2)\n\tNp2DArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, dimensions=2)\n\tNp2DArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, dimensions=2)\n\tNp2DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=2)\n\t# Non-number types\n", "Np2DArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, dimensions=2)\n\tNp2DArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, dimensions=2)\n\t__all__ = [\n\t    \"Np2DArray\",\n\t    \"Np2DArrayInt64\",\n\t    \"Np2DArrayInt32\",\n\t    \"Np2DArrayInt16\",\n\t    \"Np2DArrayInt8\",\n\t    \"Np2DArrayUint64\",\n\t    \"Np2DArrayUint32\",\n", "    \"Np2DArrayUint16\",\n\t    \"Np2DArrayUint8\",\n\t    \"Np2DArrayFp128\",\n\t    \"Np2DArrayFp64\",\n\t    \"Np2DArrayFp32\",\n\t    \"Np2DArrayFp16\",\n\t    \"Np2DArrayComplex256\",\n\t    \"Np2DArrayComplex128\",\n\t    \"Np2DArrayComplex64\",\n\t    \"Np2DArrayBool\",\n", "    \"Np2DArrayDatetime64\",\n\t    \"Np2DArrayTimedelta64\",\n\t]\n"]}
{"filename": "pydantic_numpy/typing/i_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNp1DArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=1, strict_data_typing=False)\n\tNp1DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=1)\n\tNp1DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=1)\n\tNp1DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=1)\n\tNp1DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=1)\n\tNp1DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=1)\n\tNp1DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=1)\n\tNp1DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=1)\n", "Np1DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=1)\n\tNp1DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=1)\n\tNp1DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=1)\n\tNp1DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=1)\n\tNp1DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=1)\n\tNp1DArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, dimensions=1)\n\tNp1DArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, dimensions=1)\n\tNp1DArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, dimensions=1)\n\tNp1DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=1)\n\t# Non-number types\n", "Np1DArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, dimensions=1)\n\tNp1DArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, dimensions=1)\n\t__all__ = [\n\t    \"Np1DArray\",\n\t    \"Np1DArrayInt64\",\n\t    \"Np1DArrayInt32\",\n\t    \"Np1DArrayInt16\",\n\t    \"Np1DArrayInt8\",\n\t    \"Np1DArrayUint64\",\n\t    \"Np1DArrayUint32\",\n", "    \"Np1DArrayUint16\",\n\t    \"Np1DArrayUint8\",\n\t    \"Np1DArrayFp128\",\n\t    \"Np1DArrayFp64\",\n\t    \"Np1DArrayFp32\",\n\t    \"Np1DArrayFp16\",\n\t    \"Np1DArrayComplex256\",\n\t    \"Np1DArrayComplex128\",\n\t    \"Np1DArrayComplex64\",\n\t    \"Np1DArrayBool\",\n", "    \"Np1DArrayDatetime64\",\n\t    \"Np1DArrayTimedelta64\",\n\t]\n"]}
{"filename": "pydantic_numpy/typing/n_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNpNDArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=None, strict_data_typing=False)\n\tNpNDArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64)\n\tNpNDArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32)\n\tNpNDArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16)\n\tNpNDArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8)\n\tNpNDArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64)\n\tNpNDArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32)\n\tNpNDArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16)\n", "NpNDArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8)\n\tNpNDArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128)\n\tNpNDArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64)\n\tNpNDArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32)\n\tNpNDArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16)\n\tNpNDArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256)\n\tNpNDArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128)\n\tNpNDArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64)\n\tNpNDArrayBool = np_array_pydantic_annotated_typing(data_type=bool)\n\t# Non-number types\n", "NpNDArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64)\n\tNpNDArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64)\n\t__all__ = [\n\t    \"NpNDArray\",\n\t    \"NpNDArrayInt64\",\n\t    \"NpNDArrayInt32\",\n\t    \"NpNDArrayInt16\",\n\t    \"NpNDArrayInt8\",\n\t    \"NpNDArrayUint64\",\n\t    \"NpNDArrayUint32\",\n", "    \"NpNDArrayUint16\",\n\t    \"NpNDArrayUint8\",\n\t    \"NpNDArrayFp128\",\n\t    \"NpNDArrayFp64\",\n\t    \"NpNDArrayFp32\",\n\t    \"NpNDArrayFp16\",\n\t    \"NpNDArrayComplex256\",\n\t    \"NpNDArrayComplex128\",\n\t    \"NpNDArrayComplex64\",\n\t    \"NpNDArrayBool\",\n", "    \"NpNDArrayDatetime64\",\n\t    \"NpNDArrayTimedelta64\",\n\t]\n"]}
{"filename": "pydantic_numpy/typing/iii_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNp3DArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=3, strict_data_typing=False)\n\tNp3DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=3)\n\tNp3DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=3)\n\tNp3DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=3)\n\tNp3DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=3)\n\tNp3DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=3)\n\tNp3DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=3)\n\tNp3DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=3)\n", "Np3DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=3)\n\tNp3DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=3)\n\tNp3DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=3)\n\tNp3DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=3)\n\tNp3DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=3)\n\tNp3DArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, dimensions=3)\n\tNp3DArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, dimensions=3)\n\tNp3DArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, dimensions=3)\n\tNp3DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=3)\n\t# Non-number types\n", "Np3DArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, dimensions=3)\n\tNp3DArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, dimensions=3)\n\t__all__ = [\n\t    \"Np3DArray\",\n\t    \"Np3DArrayInt64\",\n\t    \"Np3DArrayInt32\",\n\t    \"Np3DArrayInt16\",\n\t    \"Np3DArrayInt8\",\n\t    \"Np3DArrayUint64\",\n\t    \"Np3DArrayUint32\",\n", "    \"Np3DArrayUint16\",\n\t    \"Np3DArrayUint8\",\n\t    \"Np3DArrayFp128\",\n\t    \"Np3DArrayFp64\",\n\t    \"Np3DArrayFp32\",\n\t    \"Np3DArrayFp16\",\n\t    \"Np3DArrayComplex256\",\n\t    \"Np3DArrayComplex128\",\n\t    \"Np3DArrayComplex64\",\n\t    \"Np3DArrayBool\",\n", "    \"Np3DArrayDatetime64\",\n\t    \"Np3DArrayTimedelta64\",\n\t]\n"]}
{"filename": "pydantic_numpy/typing/__init__.py", "chunked_list": ["from pydantic_numpy.typing.i_dimensional import *\n\tfrom pydantic_numpy.typing.ii_dimensional import *\n\tfrom pydantic_numpy.typing.iii_dimensional import *\n\tfrom pydantic_numpy.typing.n_dimensional import *\n\tfrom pydantic_numpy.typing.strict_data_type.i_dimensional import *\n\tfrom pydantic_numpy.typing.strict_data_type.ii_dimensional import *\n\tfrom pydantic_numpy.typing.strict_data_type.iii_dimensional import *\n\tfrom pydantic_numpy.typing.strict_data_type.n_dimensional import *\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/ii_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNpStrict2DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=2, strict_data_typing=True)\n", "NpStrict2DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=2, strict_data_typing=True)\n\tNpStrict2DArrayComplex256 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex256, dimensions=2, strict_data_typing=True\n\t)\n\tNpStrict2DArrayComplex128 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex128, dimensions=2, strict_data_typing=True\n\t)\n", "NpStrict2DArrayComplex64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex64, dimensions=2, strict_data_typing=True\n\t)\n\tNpStrict2DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=2, strict_data_typing=True)\n\t# Non-number types\n\tNpStrict2DArrayDatetime64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.datetime64, dimensions=2, strict_data_typing=True\n\t)\n\tNpStrict2DArrayTimedelta64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.timedelta64, dimensions=2, strict_data_typing=True\n", ")\n\t__all__ = [\n\t    \"NpStrict2DArrayInt64\",\n\t    \"NpStrict2DArrayInt32\",\n\t    \"NpStrict2DArrayInt16\",\n\t    \"NpStrict2DArrayInt8\",\n\t    \"NpStrict2DArrayUint64\",\n\t    \"NpStrict2DArrayUint32\",\n\t    \"NpStrict2DArrayUint16\",\n\t    \"NpStrict2DArrayUint8\",\n", "    \"NpStrict2DArrayFp128\",\n\t    \"NpStrict2DArrayFp64\",\n\t    \"NpStrict2DArrayFp32\",\n\t    \"NpStrict2DArrayFp16\",\n\t    \"NpStrict2DArrayComplex256\",\n\t    \"NpStrict2DArrayComplex128\",\n\t    \"NpStrict2DArrayComplex64\",\n\t    \"NpStrict2DArrayBool\",\n\t    \"NpStrict2DArrayDatetime64\",\n\t    \"NpStrict2DArrayTimedelta64\",\n", "]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/i_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNpStrict1DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=1, strict_data_typing=True)\n", "NpStrict1DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=1, strict_data_typing=True)\n\tNpStrict1DArrayComplex256 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex256, dimensions=1, strict_data_typing=True\n\t)\n\tNpStrict1DArrayComplex128 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex128, dimensions=1, strict_data_typing=True\n\t)\n", "NpStrict1DArrayComplex64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex64, dimensions=1, strict_data_typing=True\n\t)\n\tNpStrict1DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=1, strict_data_typing=True)\n\t# Non-number types\n\tNpStrict1DArrayDatetime64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.datetime64, dimensions=1, strict_data_typing=True\n\t)\n\tNpStrict1DArrayTimedelta64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.timedelta64, dimensions=1, strict_data_typing=True\n", ")\n\t__all__ = [\n\t    \"NpStrict1DArrayInt64\",\n\t    \"NpStrict1DArrayInt32\",\n\t    \"NpStrict1DArrayInt16\",\n\t    \"NpStrict1DArrayInt8\",\n\t    \"NpStrict1DArrayUint64\",\n\t    \"NpStrict1DArrayUint32\",\n\t    \"NpStrict1DArrayUint16\",\n\t    \"NpStrict1DArrayUint8\",\n", "    \"NpStrict1DArrayFp128\",\n\t    \"NpStrict1DArrayFp64\",\n\t    \"NpStrict1DArrayFp32\",\n\t    \"NpStrict1DArrayFp16\",\n\t    \"NpStrict1DArrayComplex256\",\n\t    \"NpStrict1DArrayComplex128\",\n\t    \"NpStrict1DArrayComplex64\",\n\t    \"NpStrict1DArrayBool\",\n\t    \"NpStrict1DArrayDatetime64\",\n\t    \"NpStrict1DArrayTimedelta64\",\n", "]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/n_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNpStrictNDArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, strict_data_typing=True)\n\tNpStrictNDArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, strict_data_typing=True)\n\tNpStrictNDArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, strict_data_typing=True)\n\tNpStrictNDArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, strict_data_typing=True)\n\tNpStrictNDArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, strict_data_typing=True)\n\tNpStrictNDArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, strict_data_typing=True)\n\tNpStrictNDArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, strict_data_typing=True)\n\tNpStrictNDArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, strict_data_typing=True)\n", "NpStrictNDArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, strict_data_typing=True)\n\tNpStrictNDArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, strict_data_typing=True)\n\tNpStrictNDArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, strict_data_typing=True)\n\tNpStrictNDArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, strict_data_typing=True)\n\tNpStrictNDArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, strict_data_typing=True)\n\tNpStrictNDArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, strict_data_typing=True)\n\tNpStrictNDArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, strict_data_typing=True)\n\tNpStrictNDArrayBool = np_array_pydantic_annotated_typing(data_type=bool, strict_data_typing=True)\n\t# Non-number types\n\tNpStrictNDArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, strict_data_typing=True)\n", "NpStrictNDArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, strict_data_typing=True)\n\t__all__ = [\n\t    \"NpStrictNDArrayInt64\",\n\t    \"NpStrictNDArrayInt32\",\n\t    \"NpStrictNDArrayInt16\",\n\t    \"NpStrictNDArrayInt8\",\n\t    \"NpStrictNDArrayUint64\",\n\t    \"NpStrictNDArrayUint32\",\n\t    \"NpStrictNDArrayUint16\",\n\t    \"NpStrictNDArrayUint8\",\n", "    \"NpStrictNDArrayFp128\",\n\t    \"NpStrictNDArrayFp64\",\n\t    \"NpStrictNDArrayFp32\",\n\t    \"NpStrictNDArrayFp16\",\n\t    \"NpStrictNDArrayComplex256\",\n\t    \"NpStrictNDArrayComplex128\",\n\t    \"NpStrictNDArrayComplex64\",\n\t    \"NpStrictNDArrayBool\",\n\t    \"NpStrictNDArrayDatetime64\",\n\t    \"NpStrictNDArrayTimedelta64\",\n", "]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/iii_dimensional.py", "chunked_list": ["import numpy as np\n\tfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\tNpStrict3DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=3, strict_data_typing=True)\n", "NpStrict3DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=3, strict_data_typing=True)\n\tNpStrict3DArrayComplex256 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex256, dimensions=3, strict_data_typing=True\n\t)\n\tNpStrict3DArrayComplex128 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex128, dimensions=3, strict_data_typing=True\n\t)\n", "NpStrict3DArrayComplex64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.complex64, dimensions=3, strict_data_typing=True\n\t)\n\tNpStrict3DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=3, strict_data_typing=True)\n\t# Non-number types\n\tNpStrict3DArrayDatetime64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.datetime64, dimensions=3, strict_data_typing=True\n\t)\n\tNpStrict3DArrayTimedelta64 = np_array_pydantic_annotated_typing(\n\t    data_type=np.timedelta64, dimensions=3, strict_data_typing=True\n", ")\n\t__all__ = [\n\t    \"NpStrict3DArrayInt64\",\n\t    \"NpStrict3DArrayInt32\",\n\t    \"NpStrict3DArrayInt16\",\n\t    \"NpStrict3DArrayInt8\",\n\t    \"NpStrict3DArrayUint64\",\n\t    \"NpStrict3DArrayUint32\",\n\t    \"NpStrict3DArrayUint16\",\n\t    \"NpStrict3DArrayUint8\",\n", "    \"NpStrict3DArrayFp128\",\n\t    \"NpStrict3DArrayFp64\",\n\t    \"NpStrict3DArrayFp32\",\n\t    \"NpStrict3DArrayFp16\",\n\t    \"NpStrict3DArrayComplex256\",\n\t    \"NpStrict3DArrayComplex128\",\n\t    \"NpStrict3DArrayComplex64\",\n\t    \"NpStrict3DArrayBool\",\n\t    \"NpStrict3DArrayDatetime64\",\n\t    \"NpStrict3DArrayTimedelta64\",\n", "]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/__init__.py", "chunked_list": []}
{"filename": "pydantic_numpy/helper/annotation.py", "chunked_list": ["from collections.abc import Sequence\n\tfrom pathlib import Path\n\tfrom typing import Any, Callable, ClassVar, Optional, Union\n\timport numpy as np\n\tfrom numpy.typing import DTypeLike\n\tfrom pydantic import FilePath, GetJsonSchemaHandler, PositiveInt\n\tfrom pydantic.json_schema import JsonSchemaValue\n\tfrom pydantic_core import core_schema\n\tfrom typing_extensions import Annotated\n\tfrom pydantic_numpy.helper.validation import (\n", "    create_array_validator,\n\t    validate_multi_array_numpy_file,\n\t    validate_numpy_array_file,\n\t)\n\tfrom pydantic_numpy.model.multi_array import MultiArrayNumpyFile\n\tclass NpArrayPydanticAnnotation:\n\t    dimensions: ClassVar[Optional[PositiveInt]]\n\t    data_type: ClassVar[DTypeLike]\n\t    strict_data_typing: ClassVar[bool]\n\t    @classmethod\n", "    def factory(\n\t        cls, *, data_type: DTypeLike, dimensions: Optional[int] = None, strict_data_typing: bool = False\n\t    ) -> type:\n\t        \"\"\"\n\t        Create an instance NpArrayPydanticAnnotation that is configured for a specific dimension and dtype.\n\t        The signature of the function is data_type, dimension and not dimension, data_type to reduce amount of\n\t        code for all the types.\n\t        Parameters\n\t        ----------\n\t        data_type: DTypeLike\n", "        dimensions: Optional[int]\n\t            Number of dimensions determine the depth of the numpy array.\n\t        strict_data_typing: bool\n\t            If True, the dtype of the numpy array must be identical to the data_type. No conversion attempts.\n\t        Returns\n\t        -------\n\t        NpArrayPydanticAnnotation\n\t        \"\"\"\n\t        if strict_data_typing and not data_type:\n\t            msg = \"Strict data typing requires data_type (DTypeLike) definition\"\n", "            raise ValueError(msg)\n\t        return type(\n\t            (\n\t                f\"Np{'Strict' if strict_data_typing else ''}{dimensions or 'N'}DArray\"\n\t                f\"{data_type.__name__.capitalize() if data_type else ''}PydanticAnnotation\"\n\t            ),\n\t            (cls,),\n\t            {\"dimensions\": dimensions, \"data_type\": data_type, \"strict_data_typing\": strict_data_typing},\n\t        )\n\t    @classmethod\n", "    def __get_pydantic_core_schema__(\n\t        cls,\n\t        _source_type: Any,\n\t        _handler: Callable[[Any], core_schema.CoreSchema],\n\t    ) -> core_schema.CoreSchema:\n\t        np_array_validator = create_array_validator(cls.dimensions, cls.data_type, cls.strict_data_typing)\n\t        np_array_schema = core_schema.no_info_plain_validator_function(np_array_validator)\n\t        return core_schema.json_or_python_schema(\n\t            python_schema=core_schema.chain_schema([_common_numpy_array_validator, np_array_schema]),\n\t            json_schema=np_array_schema,\n", "            serialization=core_schema.plain_serializer_function_ser_schema(\n\t                lambda arr: np.array2string(arr), when_used=\"json\"\n\t            ),\n\t        )\n\t    @classmethod\n\t    def __get_pydantic_json_schema__(\n\t        cls, _core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n\t    ) -> JsonSchemaValue:\n\t        return handler(\n\t            dict(\n", "                type=(\n\t                    f\"np.ndarray[{_int_to_dim_type[cls.dimensions] if cls.dimensions else 'Any'}, \"\n\t                    f\"{np.dtype[cls.data_type.__name__] if _data_type_resolver(cls.data_type) else cls.data_type}]\"  # type: ignore[name-defined]\n\t                ),\n\t                strict_data_typing=cls.strict_data_typing,\n\t            )\n\t        )\n\tdef np_array_pydantic_annotated_typing(\n\t    data_type: DTypeLike = None, dimensions: Optional[int] = None, strict_data_typing: bool = False\n\t):\n", "    \"\"\"\n\t    Generates typing and pydantic annotation of a np.ndarray parametrized with given constraints\n\t    Parameters\n\t    ----------\n\t    data_type: DTypeLike\n\t    dimensions: Optional[int]\n\t        Number of dimensions determine the depth of the numpy array.\n\t    strict_data_typing: bool\n\t        If True, the dtype of the numpy array must be identical to the data_type. No conversion attempts.\n\t    Returns\n", "    -------\n\t    type-hint for np.ndarray with Pydantic support\n\t    \"\"\"\n\t    return Annotated[\n\t        Union[\n\t            FilePath,\n\t            MultiArrayNumpyFile,\n\t            np.ndarray[  # type: ignore[misc]\n\t                _int_to_dim_type[dimensions] if dimensions else Any,\n\t                np.dtype[data_type] if _data_type_resolver(data_type) else data_type,\n", "            ],\n\t        ],\n\t        NpArrayPydanticAnnotation.factory(\n\t            data_type=data_type, dimensions=dimensions, strict_data_typing=strict_data_typing\n\t        ),\n\t    ]\n\tdef _data_type_resolver(data_type: DTypeLike):\n\t    return data_type is not None and issubclass(data_type, np.generic)\n\t_int_to_dim_type = {1: tuple[int], 2: tuple[int, int], 3: tuple[int, int, int]}\n\t_common_numpy_array_validator = core_schema.union_schema(\n", "    [\n\t        core_schema.chain_schema(\n\t            [\n\t                core_schema.is_instance_schema(Path),\n\t                core_schema.no_info_plain_validator_function(validate_numpy_array_file),\n\t            ]\n\t        ),\n\t        core_schema.chain_schema(\n\t            [\n\t                core_schema.is_instance_schema(MultiArrayNumpyFile),\n", "                core_schema.no_info_plain_validator_function(validate_multi_array_numpy_file),\n\t            ]\n\t        ),\n\t        core_schema.is_instance_schema(np.ndarray),\n\t        core_schema.chain_schema(\n\t            [\n\t                core_schema.is_instance_schema(Sequence),\n\t                core_schema.no_info_plain_validator_function(lambda v: np.asarray(v)),\n\t            ]\n\t        ),\n", "    ]\n\t)\n"]}
{"filename": "pydantic_numpy/helper/__init__.py", "chunked_list": []}
{"filename": "pydantic_numpy/helper/validation.py", "chunked_list": ["from typing import Callable, Optional\n\timport numpy as np\n\timport numpy.typing as npt\n\tfrom numpy import floating, integer\n\tfrom numpy.lib.npyio import NpzFile\n\tfrom pydantic import FilePath\n\tfrom pydantic_numpy.model.multi_array import MultiArrayNumpyFile\n\tclass PydanticNumpyMultiArrayNumpyFileOnFilePath(Exception):\n\t    pass\n\tdef create_array_validator(\n", "    dimensions: Optional[int], target_data_type: npt.DTypeLike, strict_data_typing: bool\n\t) -> Callable[[npt.NDArray], npt.NDArray]:\n\t    \"\"\"\n\t    Creates a validator that ensures the numpy array has the defined dimensions and dtype (data_type).\n\t    Parameters\n\t    ----------\n\t    dimensions: int | None\n\t        Default to None; if set to an integer, enforce the dimension of the numpy array to that integer\n\t    target_data_type: DTypeLike\n\t        The data type the array must have after validation, arrays with different data types will be converted\n", "        during validation. Float to integer is rounded (np.round) followed by an astype with target data type.\n\t    strict_data_typing: bool\n\t        Default False; if True, the incoming array must its dtype match the target_data_type. Strict mode.\n\t    Returns\n\t    -------\n\t    Callable[[npt.NDArray], npt.NDArray]\n\t    Validator for numpy array\n\t    \"\"\"\n\t    def array_validator(array: npt.NDArray) -> npt.NDArray:\n\t        if dimensions and (array_dimensions := len(array.shape)) != dimensions:\n", "            msg = f\"Array {array_dimensions}-dimensional; the target dimensions is {dimensions}\"\n\t            raise ValueError(msg)\n\t        if target_data_type and array.dtype.type != target_data_type:\n\t            if strict_data_typing:\n\t                msg = f\"The data_type {array.dtype.type} does not coincide with type hint; {target_data_type}\"\n\t                raise ValueError(msg)\n\t            if issubclass(_resolve_type_of_array_dtype(target_data_type), integer) and issubclass(\n\t                _resolve_type_of_array_dtype(array.dtype), floating\n\t            ):\n\t                array = np.round(array).astype(target_data_type, copy=False)\n", "            else:\n\t                array = array.astype(target_data_type, copy=True)\n\t        return array\n\t    return array_validator\n\tdef validate_numpy_array_file(v: FilePath) -> npt.NDArray:\n\t    \"\"\"\n\t    Validate file path to numpy file by loading and return the respective numpy array\n\t    Parameters\n\t    ----------\n\t    v: FilePath\n", "        Path to the numpy file\n\t    Returns\n\t    -------\n\t    NDArray\n\t    \"\"\"\n\t    result = np.load(v)\n\t    if isinstance(result, NpzFile):\n\t        files = result.files\n\t        if len(files) > 1:\n\t            msg = (\n", "                f\"The provided file path is a multi array NpzFile, which is not supported; \"\n\t                f\"convert to single array NpzFiles.\\n\"\n\t                f\"Path to multi array file: {result}\\n\"\n\t                f\"Array keys: {', '.join(result.files)}\\n\"\n\t                f\"Use pydantic_numpy.{MultiArrayNumpyFile.__class__.__name__} instead of a PathLike alone\"\n\t            )\n\t            raise PydanticNumpyMultiArrayNumpyFileOnFilePath(msg)\n\t        result = result[files[0]]\n\t    return result\n\tdef validate_multi_array_numpy_file(v: MultiArrayNumpyFile) -> npt.NDArray:\n", "    \"\"\"\n\t    Validation function for loading numpy array from a name mapping numpy file\n\t    Parameters\n\t    ----------\n\t    v: MultiArrayNumpyFile\n\t        MultiArrayNumpyFile to load\n\t    Returns\n\t    -------\n\t    NDArray from MultiArrayNumpyFile\n\t    \"\"\"\n", "    return v.load()\n\tdef _resolve_type_of_array_dtype(array_dtype: npt.DTypeLike) -> type:\n\t    \"\"\"\n\t    np.dtype have the type stored in the type attribute, function to extract that type.\n\t    If the DTypelike isn't np.dtype we just return what is already a type.\n\t    Parameters\n\t    ----------\n\t    array_dtype: DTypeLike\n\t    Returns\n\t    -------\n", "    type\n\t    \"\"\"\n\t    if hasattr(array_dtype, \"type\"):\n\t        return array_dtype.type\n\t    else:\n\t        return array_dtype\n"]}
