{"filename": "tests/test_basic.py", "chunked_list": ["import pytest\n\t# TODO: The method of a nonlocal counter is not great\n\t#       There should be a way to setup a fixture or a mock\n\t#       to check how many times the underlying function is called\n\tdef test_no_params(patched_decorator):\n\t    counter = 0\n\t    def no_params_func():\n\t        nonlocal counter\n\t        counter += 1\n\t        return counter\n", "    cached_func = patched_decorator()(no_params_func)\n\t    assert cached_func() == 1\n\t    assert cached_func() == 1\n\t    assert counter == 1\n\tdef test_method(patched_decorator):\n\t    counter = 0\n\t    class A:\n\t        def f(self):\n\t            nonlocal counter\n\t            counter += 1\n", "            return 1\n\t    a = A()\n\t    cached_func = patched_decorator()(a.f)\n\t    assert cached_func() == 1\n\t    assert cached_func() == 1\n\t    assert counter == 1\n\tdef test_one_arg(patched_decorator):\n\t    counter = 0\n\t    def one_arg_func(a):\n\t        nonlocal counter\n", "        counter += 1\n\t        return a + a\n\t    cached_func = patched_decorator()(one_arg_func)\n\t    assert cached_func(1) == 2\n\t    assert counter == 1\n\t    assert cached_func(1) == 2\n\t    assert cached_func(a=1) == 2\n\t    assert counter == 1\n\t    assert cached_func(2) == 4\n\t    assert counter == 2\n", "    assert cached_func(2) == 4\n\t    assert cached_func(a=2) == 4\n\t    assert counter == 2\n\t    assert cached_func(\"1\") == \"11\"\n\t    assert counter == 3\n\t    assert cached_func(\"1\") == \"11\"\n\t    assert cached_func(a=\"1\") == \"11\"\n\t    assert counter == 3\n\tdef test_multiple_args(patched_decorator):\n\t    counter = 0\n", "    def multiple_args_func(a, b):\n\t        nonlocal counter\n\t        counter += 1\n\t        return a + b\n\t    cached_func = patched_decorator()(multiple_args_func)\n\t    assert cached_func(1, 1) == 2\n\t    assert counter == 1\n\t    assert cached_func(1, 1) == 2\n\t    assert cached_func(1, b=1) == 2\n\t    assert cached_func(a=1, b=1) == 2\n", "    assert counter == 1\n\t    assert cached_func(1, 2) == 3\n\t    assert counter == 2\n\t    assert cached_func(1, 2) == 3\n\t    assert cached_func(1, b=2) == 3\n\t    assert cached_func(a=1, b=2) == 3\n\t    assert counter == 2\n\tdef test_keyword_only_args(patched_decorator):\n\t    counter = 0\n\t    def keyword_only_args_func(a, *, b):\n", "        nonlocal counter\n\t        counter += 1\n\t        return a + b\n\t    cached_func = patched_decorator()(keyword_only_args_func)\n\t    #\n\t    # Test that the cached function raises the same exception\n\t    # as the non-cached function\n\t    #\n\t    try:\n\t        keyword_only_args_func(1, 1)\n", "    except Exception as e:\n\t        expected_exception = e.__class__\n\t    with pytest.raises(expected_exception):\n\t        cached_func(1, 1)\n\t    assert cached_func(1, b=1) == 2\n\t    assert counter == 1\n\t    assert cached_func(1, b=1) == 2\n\t    assert cached_func(a=1, b=1) == 2\n\t    assert counter == 1\n\t    assert cached_func(1, b=2) == 3\n", "    assert counter == 2\n\t    assert cached_func(1, b=2) == 3\n\t    assert cached_func(a=1, b=2) == 3\n\t    assert counter == 2\n\tdef test_var_args(patched_decorator):\n\t    counter = 0\n\t    def var_args_func(*args, **kwargs):\n\t        nonlocal counter\n\t        counter += 1\n\t        return sum(args) + sum(kwargs.values())\n", "    cached_func = patched_decorator()(var_args_func)\n\t    assert cached_func(1, b=1) == 2\n\t    assert counter == 1\n\t    assert cached_func(1, b=1) == 2\n\t    assert counter == 1\n\t    assert cached_func(1, b=2) == 3\n\t    assert counter == 2\n\t    assert cached_func(1, b=2) == 3\n\t    assert counter == 2\n\t    # for these types of function scrat can't know if\n", "    # f(1, 2) is the same as f(1, b=2) so it's run again\n\t    assert cached_func(1, 2) == 3\n\t    assert counter == 3\n\t    assert cached_func(1, 2) == 3\n\t    assert counter == 3\n\t    assert cached_func(a=1, b=2) == 3\n\t    assert counter == 4\n\t    assert cached_func(a=1, b=2) == 3\n\t    assert counter == 4\n\tdef test_code_changes(patched_decorator):\n", "    counter = 0\n\t    def code_changes_func():\n\t        nonlocal counter\n\t        counter += 1\n\t        return 1\n\t    cached_func = patched_decorator()(code_changes_func)\n\t    assert cached_func() == 1\n\t    assert cached_func() == 1\n\t    assert counter == 1\n\t    # a new function with the same name and code should re-use the nut\n", "    def code_changes_func():\n\t        nonlocal counter\n\t        counter += 1\n\t        return 1\n\t    cached_func = patched_decorator()(code_changes_func)\n\t    assert cached_func() == 1\n\t    assert cached_func() == 1\n\t    assert counter == 1\n\t    # a new function with the same name but different code should create a new nut\n\t    def code_changes_func():\n", "        nonlocal counter\n\t        counter += 1\n\t        return 2  # <- difference\n\t    cached_func = patched_decorator()(code_changes_func)\n\t    assert cached_func() == 2\n\t    assert cached_func() == 2\n\t    assert counter == 2\n\tdef test_multiple_func(patched_decorator):\n\t    counter_1 = 0\n\t    def multi_func_1():\n", "        nonlocal counter_1\n\t        counter_1 += 1\n\t        return 1\n\t    cached_func_1 = patched_decorator()(multi_func_1)\n\t    counter_2 = 0\n\t    def multi_func_2():\n\t        nonlocal counter_2\n\t        counter_2 += 1\n\t        return 1\n\t    cached_func_2 = patched_decorator()(multi_func_2)\n", "    assert cached_func_1() == 1\n\t    assert cached_func_2() == 1\n\t    assert counter_1 == 1\n\t    assert counter_2 == 1\n\t    assert cached_func_1() == 1\n\t    assert cached_func_2() == 1\n\t    assert counter_1 == 1\n\t    assert counter_2 == 1\n"]}
{"filename": "tests/test_watch.py", "chunked_list": ["def test_watch_functions(patched_decorator):\n\t    counter = 0\n\t    def aux_func():\n\t        return 1\n\t    @patched_decorator(watch_functions=[aux_func])\n\t    def watch_test_func():\n\t        nonlocal counter\n\t        counter += 1\n\t        return aux_func()\n\t    assert watch_test_func() == 1\n", "    assert watch_test_func() == 1\n\t    assert counter == 1\n\t    #\n\t    # Simulate a code change in aux_func\n\t    #\n\t    def aux_func():\n\t        return 2\n\t    @patched_decorator(watch_functions=[aux_func])\n\t    def watch_test_func():\n\t        nonlocal counter\n", "        counter += 1\n\t        return aux_func()\n\t    assert watch_test_func() == 2\n\t    assert watch_test_func() == 2\n\t    assert counter == 2\n\tdef test_watch_globals(patched_decorator):\n\t    g1 = 1\n\t    counter = 0\n\t    @patched_decorator(watch_globals=[\"g1\"])\n\t    def test_global_func():\n", "        nonlocal counter\n\t        counter += 1\n\t        return g1\n\t    assert test_global_func() == 1\n\t    assert test_global_func() == 1\n\t    assert counter == 1\n\t    #\n\t    # Change global var\n\t    #\n\t    g1 = 2\n", "    assert test_global_func() == 2\n\t    assert test_global_func() == 2\n\t    assert counter == 2\n"]}
{"filename": "tests/test_limits.py", "chunked_list": ["def test_size_limit(patched_decorator):\n\t    import os\n\t    # Function returns a random string so the only\n\t    # we get the same result is that the result was cached\n\t    @patched_decorator(max_size=29)\n\t    def size_limit_test_func(a):\n\t        return os.urandom(10)\n\t    # Add 3 entries\n\t    r1 = size_limit_test_func(1)  # resulting stash: 1\n\t    r2 = size_limit_test_func(2)  # resulting stash: 1, 2\n", "    # The size should not be enough to hold 3 results so the last call\n\t    # should have removed the result for 1 (oldest)\n\t    r3 = size_limit_test_func(3)  # resulting stash: 2, 3\n\t    assert size_limit_test_func(2) == r2  # resulting stash: 3, 2\n\t    assert size_limit_test_func(3) == r3  # resulting stash: 2, 3\n\t    # Notice this last call should remove result for 2\n\t    r12 = size_limit_test_func(1)  # resulting stash: 3, 1\n\t    assert r12 != r1\n\t    # result 3 should be the next in line to be removed,\n\t    # but let's test what happens if we use it\n", "    assert size_limit_test_func(3) == r3  # resulting stash: 1, 3\n\t    # add a new entry should remove the result for 1 and leave the rest\n\t    r4 = size_limit_test_func(4)  # resulting stash: 3, 4\n\t    assert size_limit_test_func(4) == r4  # resulting stash: 3, 4\n\t    assert size_limit_test_func(3) == r3  # resulting stash: 4, 3\n\t    assert size_limit_test_func(1) != r1  # resulting stash: 3, 1\n\t    # finally test that result 2 was removed before\n\t    assert size_limit_test_func(2) != r2  # resulting stash: 1, 2\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["import logging\n\timport os\n\tfrom pathlib import Path\n\tfrom tempfile import gettempdir\n\timport pytest\n\tfrom sqlalchemy import create_engine\n\tfrom scrat import stash\n\tfrom scrat.config import Config\n\tfrom scrat.db import DBConnector\n\tlogging.basicConfig(\n", "    level=logging.DEBUG,\n\t    format=\" %(name)s :: %(levelname)-8s :: %(message)s\",\n\t    force=True,\n\t)\n\t@pytest.fixture\n\tdef in_memory_engine():\n\t    return create_engine(\"sqlite://\")\n\t@pytest.fixture\n\tdef patched_decorator(mocker, in_memory_engine):\n\t    mocker.patch(\"scrat.db.connector.create_engine\", lambda _: in_memory_engine)\n", "    tmp_folder = gettempdir()\n\t    mocker.patch(\n\t        \"scrat.config.Config.load\", lambda *_: Config(base_path=Path(tmp_folder))\n\t    )\n\t    config = Config.load()\n\t    os.makedirs(config.cache_path, exist_ok=True)\n\t    DBConnector.create_db(\"\")\n\t    return stash\n"]}
{"filename": "examples/many_entries/run.py", "chunked_list": ["import random\n\timport scrat as sc\n\t@sc.stash()\n\tdef func(i):\n\t    return random.randbytes(random.randint(1000, 5000))\n\tif __name__ == \"__main__\":\n\t    for i in range(20):\n\t        func(i)\n"]}
{"filename": "examples/pandas/run.py", "chunked_list": ["import logging\n\timport time\n\timport numpy as np\n\timport pandas as pd\n\timport scrat as sc\n\tlogging.basicConfig(level=logging.DEBUG)\n\t@sc.stash()\n\tdef slow_func(df):\n\t    sum = 0\n\t    for _, row in df.iterrows():\n", "        sum += row.sum()\n\t    return sum / (len(df) * len(df.columns))\n\tif __name__ == \"__main__\":\n\t    np.random.seed(0)\n\t    df = pd.DataFrame(np.random.rand(500_000, 10))\n\t    t0 = time.time()\n\t    result = slow_func(df)\n\t    print(f\"slow_func took: {time.time() - t0:.10f} seconds\")\n\t    print(f\"result: {result: .3f}\")\n"]}
{"filename": "scrat/decorator.py", "chunked_list": ["import functools\n\timport logging\n\timport typing as T\n\tfrom .hasher import Hasher\n\tfrom .serializer import Serializer, get_default_serializer\n\tfrom .squirrel import Squirrel\n\tfrom .utils import Timer\n\tlogger = logging.getLogger(__name__)\n\tdef stash(\n\t    serializer: T.Optional[Serializer] = None,\n", "    name: T.Optional[str] = None,\n\t    hashers: T.Optional[T.Dict[str, Hasher]] = None,\n\t    hash_code: T.Optional[bool] = True,\n\t    ignore_args: T.Optional[T.List[str]] = None,\n\t    watch_functions: T.Optional[T.List[T.Any]] = None,\n\t    watch_globals: T.Optional[T.List[str]] = None,\n\t    force: T.Optional[bool] = None,\n\t    disable: T.Optional[bool] = None,\n\t    max_size: T.Optional[int] = None,\n\t):\n", "    \"\"\"Wrap a function to stash the results\n\t    Parameters\n\t    ----------\n\t    serializer\n\t        Select a serializer for the function's result, by default a good\n\t        serializer is inferred from the typehint, using `PickleSerializer` as\n\t        the fallback.\n\t    name\n\t        Name that identifies this function, by default the function name is used.\n\t    hashers\n", "        Dictionary specifying hashers used for the arguments, by default hashers\n\t        are selected according to the type of the argument, using `ToStringHasher`\n\t        as the fallback.\n\t    hash_code\n\t        Control if the function's code should be used in the hash, by default True.\n\t    ignore_args\n\t        List of arguments to ignore from the hash, by default None\n\t    watch_functions\n\t        List of functions which code should be included in the hash, by default None\n\t    watch_globals\n", "        List of global variables to include in the hash, by default None\n\t    force\n\t        If set to True the stash is ignored, the function is called and the result\n\t        is saved to the stash, by default the global setting `scrat.Setting.force` is\n\t        used\n\t    disable\n\t        If set to True the stash is ignored, the function called and the result\n\t        is **not** saved, by default the global setting `scrat.Setting.disable` is used\n\t    Notes\n\t    -----\n", "    If possible, avoid using the default `PickleSerializer`. This serializer is used by\n\t    default because it works with most objects but pickle is not a good format to store\n\t    the results long-term. We encourage users to select one the other serializers\n\t    provided or writing a custom one.\n\t    Examples\n\t    --------\n\t    Simple example\n\t    >>> import scrat as sc\n\t    >>> @sc.stash()\n\t    >>> def funcion():\n", "    >>>     return 1\n\t    Custom serializer\n\t    >>> @sc.stash(serializer=sc.JsonSerializer())\n\t    >>> def funcion():\n\t    >>>     return {\"json\": True}\n\t    \"\"\"\n\t    def deco(func):\n\t        squirrel = Squirrel(\n\t            hashers=hashers,\n\t            name=name if name is not None else func.__name__,\n", "            ignore_args=ignore_args,\n\t            hash_code=hash_code,\n\t            watch_functions=watch_functions,\n\t            watch_globals=watch_globals,\n\t            serializer=serializer\n\t            if serializer is not None\n\t            else get_default_serializer(func),\n\t            force=force,\n\t            disable=disable,\n\t            max_size=max_size,\n", "        )\n\t        timer = Timer()\n\t        @functools.wraps(func)\n\t        def wrapper(*args, **kwargs):\n\t            hash_key = squirrel.hash(args, kwargs, func)\n\t            if squirrel.exists(hash_key):\n\t                logger.info(\"Cache hit %s\", hash_key)\n\t                return squirrel.fetch(hash_key)\n\t            logger.info(\"Cache miss %s\", hash_key)\n\t            timer.start()\n", "            result = func(*args, **kwargs)\n\t            func_time = timer.end()\n\t            squirrel.stash(hash_key=hash_key, time_s=func_time, result=result)\n\t            return result\n\t        return wrapper\n\t    return deco\n"]}
{"filename": "scrat/config.py", "chunked_list": ["import os\n\timport typing as T\n\tfrom dataclasses import dataclass\n\tfrom enum import Enum\n\tfrom pathlib import Path\n\timport yaml\n\tclass DeletionMethod(Enum):\n\t    lru = \"lru\"\n\t    lfu = \"lfu\"\n\t@dataclass(frozen=True)\n", "class Config:\n\t    base_path: Path\n\t    \"path to `.scrat` forlder\"\n\t    # TODO: global max_size is not enforced yet\n\t    max_size: T.Optional[int] = None\n\t    \"size limit of the stash\"\n\t    # TODO: global ttl is not enforced yet\n\t    ttl: T.Optional[int] = None\n\t    \"Time-to-live of objects\"\n\t    deletion_method: DeletionMethod = DeletionMethod.lru\n", "    \"Cache policy used to remove entries\"\n\t    force: bool = False\n\t    \"Forcefully re-run all functions\"\n\t    disable: bool = False\n\t    \"Forcefully re-run all functions but not store the results\"\n\t    db_file: str = \"stash.db\"\n\t    stash_dir: str = \"stash\"\n\t    config_file: str = \"config.yaml\"\n\t    @property\n\t    def stash_path(self) -> Path:\n", "        return self.base_path / self.stash_dir\n\t    @property\n\t    def db_path(self) -> Path:\n\t        return self.base_path / self.db_file\n\t    @property\n\t    def cache_path(self) -> Path:\n\t        return self.base_path / self.stash_dir\n\t    @property\n\t    def config_path(self) -> Path:\n\t        return self.base_path / self.config_file\n", "    # TODO: find a way to automatically save and load to/from yaml\n\t    @classmethod\n\t    def load(cls, base_path: T.Optional[Path] = None) -> \"Config\":\n\t        \"Load the config from a yaml\"\n\t        if base_path is None:\n\t            # Search '.scrat' folder starting from the CWD and walking up\n\t            cwd = Path(os.getcwd())\n\t            while not os.path.isdir(cwd / \".scrat\") and cwd.parent != cwd:\n\t                cwd = cwd.parent\n\t            if not os.path.isdir(cwd / \".scrat\"):\n", "                raise ValueError(\"Scrat is not initialized, did you run `scrat init`\")\n\t            base_path = cwd / \".scrat\"\n\t        with open(base_path / cls.config_file) as f:\n\t            config_dict = yaml.load(f, Loader=yaml.Loader)\n\t        return cls(\n\t            base_path=Path(config_dict[\"base_path\"]),\n\t            max_size=config_dict[\"max_size\"],\n\t            ttl=config_dict[\"ttl\"],\n\t            deletion_method=DeletionMethod(config_dict[\"deletion_method\"]),\n\t            force=(os.getenv(\"SCRAT_FORCE\", \"False\").lower() in (\"true\", 1)),\n", "            disable=(os.getenv(\"SCRAT_DISABLE\", \"False\").lower() in (\"true\", 1)),\n\t        )\n\t    @classmethod\n\t    def create_config_file(cls, base_path: Path):\n\t        \"Initialize the yaml with the default settings\"\n\t        config = cls(base_path=base_path)\n\t        with open(base_path / cls.config_file, \"w\") as f:\n\t            yaml.dump(\n\t                {\n\t                    \"base_path\": str(config.base_path.absolute()),\n", "                    \"max_size\": config.max_size,\n\t                    \"ttl\": config.ttl,\n\t                    \"deletion_method\": config.deletion_method.value,\n\t                },\n\t                f,\n\t            )\n\t        return config\n"]}
{"filename": "scrat/squirrel.py", "chunked_list": ["import logging\n\timport os\n\timport typing as T\n\tfrom datetime import datetime\n\tfrom pathlib import Path\n\tfrom sqlalchemy.sql import exists, func, select\n\tfrom scrat.db import DBConnector, Nut\n\tfrom .config import Config, DeletionMethod\n\tfrom .hasher import Hasher, HashManager\n\tfrom .serializer import Serializer\n", "logger = logging.getLogger(__name__)\n\tclass Squirrel:\n\t    \"\"\"\n\t    Stash manager, in charge of fetching and storing the Nuts.\n\t    Parameters\n\t    ----------\n\t    serializer\n\t        Select a serializer for the function's result, by default a good\n\t        serializer is inferred from the typehint, using `PickleSerializer` as\n\t        the fallback.\n", "    name\n\t        Name that identifies this function, by default the function name is used.\n\t    hashers\n\t        Dictionary specifying hashers used for the arguments, by default hashers\n\t        are selected according to the type of the argument, using `ToStringHasher`\n\t        as the fallback.\n\t    hash_code\n\t        Control if the function's code should be used in the hash, by default True.\n\t    ignore_args\n\t        List of arguments to ignore from the hash, by default None\n", "    watch_functions\n\t        List of functions which code should be included in the hash, by default None\n\t    watch_globals\n\t        List of global variables to include in the hash, by default None\n\t    force\n\t        If set to True the stash is ignored, the function is called and the result\n\t        is saved to the stash, by default the global setting `scrat.Setting.force` is\n\t        used\n\t    disable\n\t        If set to True the stash is ignored, the function called and the result\n", "        is **not** saved, by default the global setting `scrat.Setting.disable` is used\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        name: str,\n\t        serializer: Serializer,\n\t        hashers: T.Optional[T.Dict[str, Hasher]] = None,\n\t        hash_code: T.Optional[bool] = True,\n\t        ignore_args: T.Optional[T.List[str]] = None,\n\t        watch_functions: T.Optional[T.List[T.Any]] = None,\n", "        watch_globals: T.Optional[T.List[str]] = None,\n\t        force: T.Optional[bool] = None,\n\t        disable: T.Optional[bool] = None,\n\t        max_size: T.Optional[int] = None,\n\t    ) -> None:\n\t        self.config = Config.load()\n\t        self.name = name\n\t        self.force = force if force is not None else self.config.force\n\t        self.disable = disable if disable is not None else self.config.disable\n\t        self.max_size = max_size\n", "        self.db_connector = DBConnector(self.config.db_path)\n\t        self.hash_manager = HashManager(\n\t            hashers=hashers,\n\t            ignore_args=ignore_args,\n\t            hash_code=hash_code,\n\t            watch_functions=watch_functions,\n\t            watch_globals=watch_globals,\n\t        )\n\t        self.serializer = serializer\n\t    def hash(\n", "        self, args: T.List[T.Any], kwargs: T.Dict[str, T.Any], func: T.Callable\n\t    ) -> str:\n\t        \"\"\"\n\t        Calculate the hash for a function call.\n\t        Parameters\n\t        ----------\n\t        args\n\t            positional arguments.\n\t        kwargs\n\t            keyword arguments.\n", "        func\n\t            the function to be called.\n\t        Returns\n\t        -------\n\t            the hash-string resulting of combining all argument and code hashes.\n\t        \"\"\"\n\t        hash_key = self.hash_manager.hash(args=args, kwargs=kwargs, func=func)\n\t        logger.debug(\"Hash key for %s is '%s'\", self.name, hash_key)\n\t        return hash_key\n\t    def exists(self, hash_key: str) -> bool:\n", "        \"\"\"\n\t        Check if the hash exists\n\t        Parameters\n\t        ----------\n\t        hash_key\n\t            The hash-string calculated in `Squirrel.hash`.\n\t        Returns\n\t        -------\n\t            Whether the hash exists or not.\n\t        \"\"\"\n", "        if self.force or self.disable:\n\t            logger.debug(\n\t                \"Forcing the result or scrat is disable, not reusing the result\"\n\t            )\n\t            return False\n\t        with self.db_connector.session() as session:\n\t            return session.query(exists().where(Nut.hash == hash_key)).scalar()\n\t    def fetch(self, hash_key: str) -> T.Any:\n\t        \"\"\"\n\t        Fetch and recover a result from the stash.\n", "        Parameters\n\t        ----------\n\t        hash_key\n\t            The hash-string calculated in `Squirrel.hash`.\n\t        Returns\n\t        -------\n\t            The result loaded into memory.\n\t        \"\"\"\n\t        logger.debug(\"Fetching '%s' for %s\", hash_key, self.name)\n\t        with self.db_connector.session() as session:\n", "            nut = session.scalar(select(Nut).where(Nut.hash == hash_key))\n\t            result = self.serializer.load(Path(nut.path))\n\t            nut.use_count = nut.use_count + 1\n\t            nut.used_at = datetime.now()\n\t            session.commit()\n\t        return result\n\t    def stash(self, hash_key: str, time_s: int, result: T.Any):\n\t        \"\"\"\n\t        Stores a result.\n\t        Parameters\n", "        ----------\n\t        hash_key\n\t            The hash-string calculated in `Squirrel.hash`.\n\t        time_s\n\t            Execution time of the underlying function.\n\t        result\n\t            the result of the underlying function.\n\t        \"\"\"\n\t        if self.disable:\n\t            logger.debug(\"Scrat is disable, not saving\")\n", "            return\n\t        with self.db_connector.session() as session:\n\t            if self.max_size is not None:\n\t                current_size, count = (\n\t                    session.query(func.sum(Nut.size), func.count(Nut.hash))\n\t                    .filter(Nut.name == self.name)\n\t                    .first()\n\t                )\n\t                if count == 0:\n\t                    current_size = 0\n", "                while current_size >= self.max_size:\n\t                    logger.debug(\"Size limit hit, freeing space\")\n\t                    if self.config.deletion_method == DeletionMethod.lru:\n\t                        to_delete = (\n\t                            session.query(Nut)\n\t                            .filter(Nut.name == self.name)\n\t                            .order_by(func.ifnull(Nut.used_at, Nut.created_at))\n\t                            .first()\n\t                        )\n\t                        logger.info(\"Removing %s\", to_delete)\n", "                    elif self.config.deletion_method == DeletionMethod.lru:\n\t                        to_delete = (\n\t                            session.query(Nut)\n\t                            .filter(Nut.name == self.name)\n\t                            .order_by(Nut.use_count)\n\t                            .first()\n\t                        )\n\t                        logger.info(\"Removing %s\", to_delete)\n\t                    else:\n\t                        logger.error(\n", "                            \"Incorrect DeletionMethod %s\", self.config.deletion_method\n\t                        )\n\t                        break\n\t                    os.remove(to_delete.path)\n\t                    session.delete(to_delete)\n\t                    session.commit()\n\t                    current_size -= to_delete.size\n\t            logger.debug(\"Storing '%s' for %s\", hash_key, self.name)\n\t            path = self.config.cache_path / f\"{self.name}_{hash_key}\"\n\t            self.serializer.dump(result, path)\n", "            file_size = round(os.stat(path).st_size)\n\t            nut = Nut(\n\t                hash=hash_key,\n\t                name=self.name,\n\t                path=str(path),\n\t                created_at=datetime.now(),\n\t                used_at=None,\n\t                size=file_size,\n\t                use_count=0,\n\t                time_s=time_s,\n", "            )\n\t            session.add(nut)\n\t            session.commit()\n"]}
{"filename": "scrat/__init__.py", "chunked_list": ["\"Scrat Library\"\n\tfrom .config import Config  # noqa: F401\n\tfrom .decorator import stash  # noqa: F401\n\tfrom .hasher import *  # noqa: F401, F403\n\tfrom .serializer import *  # noqa: F401, F403\n\tfrom .squirrel import Squirrel  # noqa: F401\n\t__all__ = [\"stash\"]\n"]}
{"filename": "scrat/serializer/base.py", "chunked_list": ["import typing as T\n\tfrom abc import ABC, abstractmethod\n\tfrom pathlib import Path\n\tclass Serializer(ABC):\n\t    \"\"\"\n\t    Abstract class from which all Serializer inherit from.\n\t    \"\"\"\n\t    @abstractmethod\n\t    def dump(self, obj: T.Any, path: Path):\n\t        \"\"\"\n", "        Save an object to disk.\n\t        Parameters\n\t        ----------\n\t        obj\n\t            The result to save.\n\t        path\n\t            The target location in the filesystem.\n\t        \"\"\"\n\t        return NotImplemented\n\t    @abstractmethod\n", "    def load(self, path: Path) -> T.Any:\n\t        \"\"\"\n\t        Load a saved object from disk.\n\t        Parameters\n\t        ----------\n\t        path\n\t            Location of the stored result.\n\t        Returns\n\t        -------\n\t            The object loaded into memory.\n", "        \"\"\"\n\t        return NotImplemented\n"]}
{"filename": "scrat/serializer/dill.py", "chunked_list": ["import typing as T\n\tfrom pathlib import Path\n\tclass DillSerializer:\n\t    \"\"\"\n\t    Serializer using dill.\n\t    In order to use this Serializer dill needs to be installed.\n\t    Parameters\n\t    ----------\n\t    dump_kwargs\n\t        extra arguments for dill.dump, by default None\n", "    load_kwargs\n\t        extra arguments for dill.load, by default None\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        dump_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t    ) -> None:\n\t        # test that dill is installed\n\t        import dill  # noqa: F401\n", "        self.dump_kwargs = dump_kwargs if dump_kwargs is not None else {}\n\t        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n\t    def dump(self, obj: T.Any, path: Path):\n\t        import dill\n\t        with open(path, \"wb\") as f:\n\t            dill.dump(obj, f, **self.dump_kwargs)\n\t    def load(self, path: Path) -> T.Any:\n\t        import dill\n\t        with open(path, \"rb\") as f:\n\t            return dill.load(f, **self.load_kwargs)\n"]}
{"filename": "scrat/serializer/pickle.py", "chunked_list": ["import pickle\n\timport typing as T\n\tfrom pathlib import Path\n\tclass PickleSerializer:\n\t    \"\"\"\n\t    Pickle serializer.\n\t    Parameters\n\t    ----------\n\t    dump_kwargs\n\t        Extra arguments for pickle.dump, by default None\n", "    load_kwargs\n\t        Extra arguments for pickle.load, by default None\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        dump_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t    ) -> None:\n\t        self.dump_kwargs = dump_kwargs if dump_kwargs is not None else {}\n\t        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n", "    def dump(self, obj: T.Any, path: Path):\n\t        with open(path, \"wb\") as f:\n\t            pickle.dump(obj, f, **self.dump_kwargs)\n\t    def load(self, path: Path) -> T.Any:\n\t        with open(path, \"rb\") as f:\n\t            return pickle.load(f, **self.load_kwargs)\n"]}
{"filename": "scrat/serializer/pandas.py", "chunked_list": ["import typing as T\n\tfrom enum import Enum\n\tfrom pathlib import Path\n\tif T.TYPE_CHECKING:\n\t    import pandas as pd\n\tclass Format(Enum):\n\t    parquet = \"parquet\"\n\t    hdf5 = \"hdf5\"\n\t    feather = \"feather\"\n\t    orc = \"orc\"\n", "    excel = \"excel\"\n\t    csv = \"csv\"\n\t    pickle = \"pickle\"\n\t    json = \"json\"\n\t    stata = \"stata\"\n\tclass PandasSerializer:\n\t    \"\"\"\n\t    Serializer for Pandas Series and DataFrames.\n\t    In order to use this Serializer pandas needs to be installed,\n\t    some formats might need aditional libraries.\n", "    Parameters\n\t    ----------\n\t    format\n\t        Serialization method from the ones supported by pandas,\n\t        by default Format.parquet\n\t    to_kwargs\n\t        Extra arguments for the corresponding pandas.read_<format> function,\n\t        by default None\n\t    read_kwargs\n\t        Extra arguments for the corresponding pandas.to_<format> function,\n", "        by default None\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        format: T.Union[str, Format] = Format.parquet,\n\t        to_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t        read_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t    ) -> None:\n\t        # test that pandas is installed\n\t        import pandas  # noqa: F401\n", "        self.format = format if isinstance(format, Format) else Format(format)\n\t        self.to_kwargs = to_kwargs if to_kwargs is not None else {}\n\t        self.read_kwargs = read_kwargs if read_kwargs is not None else {}\n\t    def dump(self, obj: \"pd.DataFrame\", path: Path):\n\t        to_method = getattr(obj, f\"to_{self.format.value}\")\n\t        to_method(path, **self.to_kwargs)\n\t    def load(self, path: Path) -> \"pd.DataFrame\":\n\t        import pandas\n\t        read_method = getattr(pandas, f\"read_{self.format.value}\")\n\t        return read_method(path, **self.read_kwargs)\n"]}
{"filename": "scrat/serializer/__init__.py", "chunked_list": ["\"Module containing all Serializers\"\n\timport typing as T\n\tfrom .base import Serializer\n\tfrom .dill import DillSerializer  # noqa: F401\n\tfrom .json import JsonSerializer  # noqa: F401\n\tfrom .numpy import NumpySerializer\n\tfrom .pandas import PandasSerializer\n\tfrom .pickle import PickleSerializer\n\tDEFAULT_SERIALIZERS = {\n\t    \"DataFrame\": PandasSerializer,\n", "    \"Series\": PandasSerializer,\n\t    \"ndarray\": NumpySerializer,\n\t}\n\tdef get_default_serializer(func: T.Callable) -> Serializer:\n\t    \"\"\"\n\t    Try to find a sane serializer using the function's typehint.\n\t    Defaults to `PickleSerializer`\n\t    Parameters\n\t    ----------\n\t    func\n", "        The user function to be called\n\t    Returns\n\t    -------\n\t        An instance of the chosen Serializer\n\t    \"\"\"\n\t    import inspect\n\t    sign = inspect.signature(func)\n\t    if hasattr(sign, \"return_annotations\"):\n\t        return DEFAULT_SERIALIZERS.get(\n\t            sign.return_annotation.__name__, PickleSerializer\n", "        )()\n\t    return PickleSerializer()\n\t__all__ = [\n\t    \"Serializer\",\n\t    \"PickleSerializer\",\n\t    \"DillSerializer\",\n\t    \"JsonSerializer\",\n\t    \"NumpySerializer\",\n\t    \"PandasSerializer\",\n\t]\n"]}
{"filename": "scrat/serializer/numpy.py", "chunked_list": ["import typing as T\n\tfrom pathlib import Path\n\tif T.TYPE_CHECKING:\n\t    import numpy as np\n\tclass NumpySerializer:\n\t    \"\"\"\n\t    Serializer for numpy arrays.\n\t    In order to use this Serializer numpy needs to be installed.\n\t    Parameters\n\t    ----------\n", "    save_kwargs\n\t        Extra arguments for numpy.save, by default None\n\t    load_kwargs\n\t        Extra arguments for numpy.load, by default None\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        save_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t    ) -> None:\n", "        # test that numpy is installed\n\t        import numpy  # noqa: F401\n\t        self.save_kwargs = save_kwargs if save_kwargs is not None else {}\n\t        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n\t    def dump(self, obj: \"np.ndarray\", path: Path):\n\t        import numpy\n\t        numpy.save(path, obj, **self.save_kwargs)\n\t        obj.save(path)\n\t    def load(self, path: Path) -> \"np.ndarray\":\n\t        import numpy\n", "        return numpy.load(path, **self.load_kwargs)\n"]}
{"filename": "scrat/serializer/json.py", "chunked_list": ["import json\n\timport typing as T\n\tfrom pathlib import Path\n\tclass JsonSerializer:\n\t    \"\"\"\n\t    Serializer that uses json from the python standard library.\n\t    Parameters\n\t    ----------\n\t    dump_kwargs\n\t        Extra arguments for json.dump, by default None\n", "    load_kwargs\n\t        Extra arguments for json.load, by default None\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        dump_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t        load_kwargs: T.Optional[T.Dict[str, T.Any]] = None,\n\t    ) -> None:\n\t        self.dump_kwargs = dump_kwargs if dump_kwargs is not None else {}\n\t        self.load_kwargs = load_kwargs if load_kwargs is not None else {}\n", "    def dump(self, obj: T.Any, path: Path):\n\t        with open(path, \"w\") as f:\n\t            json.dump(obj, f, **self.dump_kwargs)\n\t    def load(self, path: Path) -> T.Any:\n\t        with open(path, \"r\") as f:\n\t            return json.load(f, **self.load_kwargs)\n"]}
{"filename": "scrat/cli/setup.py", "chunked_list": ["import os\n\tfrom pathlib import Path\n\timport click\n\tfrom scrat import Config\n\tfrom scrat.db import DBConnector\n\tdef _make_config(path) -> Config:\n\t    return Config.create_config_file(base_path=path)\n\tdef _make_db(path):\n\t    DBConnector.create_db(path=path)\n\t@click.command()\n", "def init():\n\t    \"\"\"Initialize Scrat's stash\"\"\"\n\t    cwd = Path(os.getcwd())\n\t    folder = cwd / \".scrat\"\n\t    if os.path.exists(folder):\n\t        click.secho(\"already initialized\", fg=\"red\")\n\t        exit(-1)\n\t    os.mkdir(folder)\n\t    config = _make_config(folder)\n\t    _make_db(config.db_path)\n", "    os.mkdir(config.stash_path)\n\t    if os.path.exists(cwd / \".git\"):\n\t        with open(folder / \".gitignore\", \"w\") as f:\n\t            f.write(f\"{config.stash_dir}\\n{config.db_file}\\n{config.config_file}\\n\")\n\t@click.command()\n\tdef deinit():\n\t    \"\"\"Remove Scrat's stash\"\"\"\n\t    import shutil\n\t    cwd = Path(os.getcwd())\n\t    folder = cwd / \".scrat\"\n", "    if not os.path.exists(folder):\n\t        click.secho(\"not initialized\", fg=\"red\")\n\t        exit(-1)\n\t    click.confirm(\n\t        \"This will remove everything from the stash are you sure?\", abort=True\n\t    )\n\t    shutil.rmtree(folder)\n\t    click.secho(\"Scrat was deinitialized correctly\")\n\tif __name__ == \"__main__\":\n\t    init()\n"]}
{"filename": "scrat/cli/stash.py", "chunked_list": ["import os\n\tfrom datetime import timedelta\n\timport click\n\tfrom sqlalchemy.sql import exists, select\n\tfrom scrat.config import Config\n\tfrom scrat.db import DBConnector, Nut\n\tfrom scrat.utils import humanize_size\n\t@click.group()\n\tdef stash():\n\t    pass\n", "COLUMNS = [\n\t    \"hash\",\n\t    \"name\",\n\t    \"path\",\n\t    \"created_at\",\n\t    \"used_at\",\n\t    \"size_mb\",\n\t    \"use_count\",\n\t    \"time_s\",\n\t]\n", "def format_datetime(datetime):\n\t    if datetime is not None:\n\t        return datetime.isoformat(timespec=\"minutes\", sep=\" \")\n\t    return \"\"\n\t@stash.command()\n\t@click.option(\n\t    \"-s\",\n\t    \"--sort-by\",\n\t    type=click.Choice(COLUMNS),\n\t    default=\"created_at\",\n", "    help=\"Column to sort by\",\n\t)\n\t@click.option(\n\t    \"-d\", \"--desc\", default=False, is_flag=True, help=\"Use to sort descending\"\n\t)\n\tdef list(sort_by, desc):\n\t    \"\"\"List content of stash\"\"\"\n\t    config = Config.load()\n\t    db_connector = DBConnector(config.db_path)\n\t    with db_connector.session() as session:\n", "        sorting = getattr(Nut, sort_by)\n\t        if desc:\n\t            sorting = sorting.desc()\n\t        click.secho(f\"{'name':<15} {'hash':<32} {'created_at':<16} {'size':5}\")\n\t        for nut in session.query(Nut).order_by(sorting).all():\n\t            click.secho(\n\t                (\n\t                    f\"{nut.name if len(nut.name) <= 15 else nut.name[:13] + '..' :<15} \"\n\t                    f\"{nut.hash} \"\n\t                    f\"{format_datetime(nut.created_at)} \"\n", "                    f\"{humanize_size(nut.size)}\"\n\t                )\n\t            )\n\t@stash.command()\n\t@click.argument(\"hash_key\")\n\tdef delete(hash_key):\n\t    \"\"\"Removes one nut from the stash\"\"\"\n\t    config = Config.load()\n\t    db_connector = DBConnector(config.db_path)\n\t    with db_connector.session() as session:\n", "        nut = session.scalar(select(Nut).where(Nut.hash == hash_key))\n\t        if nut is None:\n\t            click.secho(\"Nut does not exists\", fg=\"red\")\n\t            exit(-1)\n\t        try:\n\t            os.remove(nut.path)\n\t        except FileNotFoundError:\n\t            pass\n\t        session.query(Nut).filter_by(hash=hash_key).delete()\n\t        session.commit()\n", "@stash.command()\n\tdef clear():\n\t    \"\"\"Empty the stash\"\"\"\n\t    config = Config.load()\n\t    click.confirm(\n\t        \"This will remove everything from the stash are you sure?\", abort=True\n\t    )\n\t    try:\n\t        os.remove(config.db_path)\n\t    except FileNotFoundError:\n", "        click.secho(\"DB not found\")\n\t    for file in os.listdir(config.cache_path):\n\t        os.remove(config.cache_path / file)\n\t@stash.command()\n\tdef stats():\n\t    \"\"\"Print stash stats\"\"\"\n\t    config = Config.load()\n\t    db_connector = DBConnector(config.db_path)\n\t    seconds_saved = 0\n\t    size = 0\n", "    entries = 0\n\t    with db_connector.session() as session:\n\t        for nut in session.query(Nut).all():\n\t            seconds_saved += nut.use_count * nut.time_s\n\t            size += nut.size\n\t            entries += 1\n\t    click.secho(f\"Total entries: {entries}\")\n\t    if entries == 0:\n\t        return\n\t    click.secho(f\"Total size: {humanize_size(size)}\")\n", "    if seconds_saved > 0:\n\t        click.secho(f\"time saved: {timedelta(seconds=seconds_saved)}\")\n\t@stash.command()\n\tdef check():\n\t    \"\"\"Check the integrity of the stash\"\"\"\n\t    config = Config.load()\n\t    db_connector = DBConnector(config.db_path)\n\t    with db_connector.session() as session:\n\t        for nut in session.query(Nut).all():\n\t            if not os.path.exists(nut.path):\n", "                click.secho(f\"Missing file '{nut.hash}'\")\n\t        for file in os.listdir(config.cache_path):\n\t            if not session.query(exists().where(Nut.hash == file)).scalar():\n\t                click.secho(f\"File not indexed: '{file}'\")\n\tif __name__ == \"__main__\":\n\t    stash()\n"]}
{"filename": "scrat/cli/__init__.py", "chunked_list": ["\"Scrat CLI\"\n\timport click\n\tfrom .setup import deinit, init\n\tfrom .stash import stash\n\t@click.group()\n\tdef scrat():\n\t    pass\n\tscrat.add_command(init)\n\tscrat.add_command(deinit)\n\tscrat.add_command(stash)\n", "if __name__ == \"__main__\":\n\t    scrat()\n"]}
{"filename": "scrat/utils/__init__.py", "chunked_list": ["import typing as T\n\tfrom pathlib import Path\n\tfrom .timer import Timer  # noqa\n\tPathLike = T.Union[str, Path]\n\t_SUFFIXES = list(reversed(list(enumerate([\"B\", \"KB\", \"MB\", \"GB\"]))))\n\tdef humanize_size(size: int) -> str:\n\t    \"Format file size in bytes into a human-readable string\"\n\t    base = 1024\n\t    for exp, suffix in _SUFFIXES:\n\t        if size >= base**exp:\n", "            return f\"{size/base**exp:.1f}{suffix}\"\n\t    raise ValueError(\"could not format int %s\", int)\n"]}
{"filename": "scrat/utils/timer.py", "chunked_list": ["import time\n\tclass Timer:\n\t    \"Simple timer.\"\n\t    def __init__(self) -> None:\n\t        self._start_time = None\n\t    def start(self):\n\t        self._start_time = time.time()\n\t    def end(self) -> float:\n\t        try:\n\t            delta = time.time() - self._start_time\n", "        except TypeError:\n\t            raise RuntimeError(\"Trying to stop a timer that has not been started\")\n\t        self._start_time = None\n\t        return delta\n"]}
{"filename": "scrat/db/models.py", "chunked_list": ["import typing as T\n\tfrom datetime import datetime\n\tfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n\tclass Base(DeclarativeBase):\n\t    pass\n\tclass Nut(Base):\n\t    \"\"\"Represents an entry to the stash database\"\"\"\n\t    __tablename__ = \"nut\"\n\t    # TODO: hash should not be the PK because it could be repeated with a different name\n\t    hash: Mapped[str] = mapped_column(primary_key=True)\n", "    \"Resulting hash for this result\"\n\t    name: Mapped[str]\n\t    \"Name of the function that produced this result\"\n\t    path: Mapped[str]\n\t    \"Path where the result is stored\"\n\t    created_at: Mapped[datetime]\n\t    \"DateTime when the result was produced\"\n\t    used_at: Mapped[T.Optional[datetime]]\n\t    \"DateTime when the result was last used\"\n\t    size: Mapped[int]\n", "    \"Size of the store file, in bytes\"\n\t    use_count: Mapped[int]\n\t    \"Count of how many times the result was used\"\n\t    time_s: Mapped[int]\n\t    \"Execution time of the function, in seconds\"\n\t    def __repr__(self) -> str:\n\t        return f\"Nut(name={self.name!r}, hash={self.hash!r})\"\n"]}
{"filename": "scrat/db/__init__.py", "chunked_list": ["\"Module that contains the SQLAlchemy models and the connection to the database\"\n\tfrom .connector import DBConnector  # noqa\n\tfrom .models import Nut  # noqa\n"]}
{"filename": "scrat/db/connector.py", "chunked_list": ["from sqlalchemy import create_engine\n\tfrom sqlalchemy.orm import Session, sessionmaker\n\tfrom scrat.utils import PathLike\n\tfrom .models import Base\n\tclass DBConnector:\n\t    \"\"\"\n\t    Wrapper to handle the connection to sqlite.\n\t    Parameters\n\t    ----------\n\t    path\n", "        Path to the sqlite file.\n\t    \"\"\"\n\t    def __init__(self, path: PathLike) -> None:\n\t        self.engine = create_engine(\"sqlite:///\" + str(path))\n\t        Base.metadata.create_all(self.engine)\n\t        self.session_maker = sessionmaker(self.engine)\n\t    @classmethod\n\t    def create_db(cls, path: PathLike):\n\t        \"\"\"\n\t        Initialize the database.\n", "        Parameters\n\t        ----------\n\t        path\n\t            Path to the sqlite file.\n\t        \"\"\"\n\t        engine = create_engine(\"sqlite:///\" + str(path))\n\t        Base.metadata.create_all(engine)\n\t    def session(self) -> Session:\n\t        \"\"\"\n\t        Create a session\n", "        Returns\n\t        -------\n\t            SQLAlchemy's session\n\t        \"\"\"\n\t        return self.session_maker()\n"]}
{"filename": "scrat/hasher/manager.py", "chunked_list": ["import inspect\n\timport logging\n\timport typing as T\n\tfrom collections import OrderedDict\n\tfrom .base import Hasher\n\tfrom .iterable import IterableHasher\n\tfrom .numpy import NumpyHasher\n\tfrom .pandas import PandasHasher\n\tfrom .to_string import ToStringHasher\n\tlogger = logging.getLogger(__name__)\n", "FALLBACK = ToStringHasher()\n\tDEFAULTS: T.Dict[T.Any, Hasher] = OrderedDict()\n\ttry:\n\t    import numpy as np\n\t    DEFAULTS[np.ndarray] = NumpyHasher()\n\texcept ImportError:\n\t    logger.debug(\"numpy not installed, NumpyHasher disabled\")\n\ttry:\n\t    import pandas as pd\n\t    DEFAULTS[pd.DataFrame] = PandasHasher()\n", "    DEFAULTS[pd.Series] = PandasHasher()\n\texcept ImportError:\n\t    logger.debug(\"pandas not installed, NumpyHasher disabled\")\n\tDEFAULTS[list] = IterableHasher(FALLBACK)\n\tDEFAULTS[tuple] = IterableHasher(FALLBACK)\n\tclass HashManager:\n\t    \"\"\"\n\t    Coordinate the hashing of the arguments, code, etc\n\t    Parameters\n\t    ----------\n", "    hashers\n\t        Dictionary to override the Hasher used for certain arguments,\n\t        by default None\n\t    hash_code\n\t        If True the function's code is included in the hash, by default True\n\t    ignore_args\n\t        List of argument names to be ignored, by default None\n\t    watch_functions\n\t        Extra functions to include in the hash, by default None\n\t    watch_globals\n", "        Global variables to include in the hash, by default None\n\t    \"\"\"\n\t    def __init__(\n\t        self,\n\t        hashers: T.Optional[T.Dict[str, Hasher]] = None,\n\t        hash_code: T.Optional[bool] = True,\n\t        ignore_args: T.Optional[T.List[str]] = None,\n\t        watch_functions: T.Optional[T.List[T.Any]] = None,\n\t        watch_globals: T.Optional[T.List[str]] = None,\n\t    ) -> None:\n", "        # TODO: enforce unique names?\n\t        self.hash_code = hash_code\n\t        self.hashers = hashers if hashers is not None else {}\n\t        self.ignore_args = set(ignore_args if ignore_args is not None else [])\n\t        self.watch_functions = watch_functions if watch_functions is not None else []\n\t        self.watch_globals = watch_globals if watch_globals is not None else []\n\t    def hash(\n\t        self, args: T.List[T.Any], kwargs: T.Dict[str, T.Any], func: T.Callable\n\t    ) -> str:\n\t        \"\"\"\n", "        Calculate the hash for a function call.\n\t        Parameters\n\t        ----------\n\t        args\n\t            positional arguments.\n\t        kwargs\n\t            keyword arguments.\n\t        func\n\t            the function to be called.\n\t        Returns\n", "        -------\n\t            the hash-string resulting of combining all argument and code hashes.\n\t        \"\"\"\n\t        #\n\t        # hash arguments\n\t        #\n\t        hashed_args = []\n\t        for arg_name, arg_value in self._normalize_args(args, kwargs, func).items():\n\t            hashed_args.append(self.hash_argument(arg_name, arg_value))\n\t        hash_result = Hasher.md5_hash(*hashed_args)\n", "        #\n\t        # hash funcion's code if necessary\n\t        #\n\t        if self.hash_code:\n\t            hashed_code = self._hash_code(func)\n\t            hash_result = Hasher.md5_hash(hash_result, hashed_code)\n\t        #\n\t        # hash the code of any other watched function\n\t        #\n\t        if len(self.watch_functions):\n", "            hash_result = Hasher.md5_hash(\n\t                hash_result, *[self._hash_code(f) for f in self.watch_functions]\n\t            )\n\t        #\n\t        # hash any other watched global variable\n\t        #\n\t        if len(self.watch_globals):\n\t            closure = inspect.getclosurevars(func)\n\t            global_vars = closure.globals.copy()\n\t            global_vars.update(closure.nonlocals)\n", "            globals_hash = []\n\t            for global_name in self.watch_globals:\n\t                gloval_value = global_vars[global_name]\n\t                globals_hash.append(self.hash_argument(global_name, gloval_value))\n\t            hash_result = Hasher.md5_hash(hash_result, *globals_hash)\n\t        return hash_result\n\t    def hash_argument(self, name: str, value: T.Any) -> str:\n\t        \"\"\"\n\t        Generate the hash for a single argument.\n\t        Parameters\n", "        ----------\n\t        name\n\t            argument name normalized.\n\t        value\n\t            argument value.\n\t        Returns\n\t        -------\n\t            the hash-string corresponding to this argument.\n\t        \"\"\"\n\t        hasher = self._get_hasher(name, value)\n", "        logger.debug(\"using '%s' for argument '%s'\", hasher.__class__.__name__, name)\n\t        hashed_value = hasher.hash(value)\n\t        return Hasher.md5_hash(name, hashed_value, type(value).__name__)\n\t    def _get_hasher(self, arg_name: str, arg: T.Any) -> Hasher:\n\t        if arg_name in self.hashers:\n\t            return self.hashers[arg_name]\n\t        for cls, hasher in DEFAULTS.items():\n\t            if isinstance(arg, cls):\n\t                return hasher\n\t        return FALLBACK\n", "    def _hash_code(self, func) -> str:\n\t        return Hasher.md5_hash(inspect.getsource(func).encode())\n\t    def _normalize_args(\n\t        self, args: T.List[T.Any], kwargs: T.Dict[str, T.Any], func: T.Callable\n\t    ) -> T.Dict[str, T.Any]:\n\t        \"\"\"\n\t        Normalize args and kwargs.\n\t        The same function can be called with the same arguments but changing which\n\t        are passed by position (args) and which are passed by name (kwargs),\n\t        this function aims to normalize all those different forms of calling into a\n", "        single form that corresponds to call the function passing all arguments by name,\n\t        in the order they appear in the function's signature.\n\t        Parameters\n\t        ----------\n\t        args\n\t            positional arguments\n\t        kwargs\n\t            named or keyword arguments\n\t        func\n\t            function to be called\n", "        Returns\n\t        -------\n\t            keyword mapping\n\t        Examples\n\t        --------\n\t        >>> from scrat.hasher import HashManager\n\t        >>> manager = HashManager()\n\t        >>> def f(a, b):\n\t        >>>     pass\n\t        >>> manager._normalize_args(args=[1, 2], kwargs={}, func=f)\n", "        OrderedDict([('a', 1), ('b', 2)])\n\t        >>> manager._normalize_args(args=[1], kwargs={\"b\":2}, func=f)\n\t        OrderedDict([('a', 1), ('b', 2)])\n\t        >>> manager._normalize_args(args=[], kwargs={\"b\":2, \"a\":1}, func=f)\n\t        OrderedDict([('a', 1), ('b', 2)])\n\t        \"\"\"\n\t        args = list(args)\n\t        normalized_args = OrderedDict()\n\t        sign = inspect.signature(func)\n\t        for arg_name, param in sign.parameters.items():\n", "            if param.kind == param.POSITIONAL_ONLY:\n\t                # NOTE: Value must be supplied as a positional argument.\n\t                #       Python has no explicit syntax for defining positional-only\n\t                #       parameters, but many built-in and extension module functions\n\t                #       (especially those that accept only one or two parameters)\n\t                #       accept them.\n\t                normalized_args[arg_name] = args.pop(0)\n\t            elif param.kind == param.POSITIONAL_OR_KEYWORD:\n\t                # NOTE: Value may be supplied as either a keyword or positional\n\t                #       argument. This is the standard binding behaviour for functions\n", "                #       implemented in Python.\n\t                if arg_name in kwargs:\n\t                    normalized_args[arg_name] = kwargs[arg_name]\n\t                elif len(args) > 0:\n\t                    normalized_args[arg_name] = args.pop(0)\n\t                else:\n\t                    normalized_args[arg_name] = param.default\n\t            elif param.kind == param.VAR_POSITIONAL:\n\t                # NOTE: A tuple of positional arguments that aren’t bound to any other\n\t                #       parameter. This corresponds to a *args parameter in a Python\n", "                #       function definition.\n\t                # consume all remainder args\n\t                for i, arg in enumerate(args):\n\t                    normalized_args[f\"*{i}\"] = arg\n\t                args = []\n\t            elif param.kind == param.KEYWORD_ONLY:\n\t                # NOTE: Value must be supplied as a keyword argument.\n\t                #       Keyword only parameters are those which appear after a * or\n\t                #       *args nut in a Python function definition.\n\t                # If the param is keyword only then it must be passed as a kwarg,\n", "                # however we are not enforncing it here so that we don't fail and\n\t                # instead the user gets the normal python error\n\t                normalized_args[arg_name] = kwargs.get(arg_name)\n\t            if param.kind == param.VAR_KEYWORD:\n\t                # NOTE: A dict of keyword arguments that aren’t bound to any other\n\t                #       parameter.  This corresponds to a **kwargs parameter in a\n\t                #       Python function definition.\n\t                # consume all remainder kwargs\n\t                for arg_name, arg in kwargs.items():\n\t                    normalized_args[f\"**{arg_name}\"] = arg\n", "                kwargs = {}\n\t        return normalized_args\n"]}
{"filename": "scrat/hasher/base.py", "chunked_list": ["import hashlib\n\timport typing as T\n\tfrom abc import ABC, abstractmethod\n\tclass Hasher(ABC):\n\t    \"Abstract class from which all Hashers inherit from\"\n\t    @abstractmethod\n\t    def hash(self, value: T.Any) -> str:\n\t        \"\"\"Calculate the hash-string corresponding to a value\n\t        Parameters\n\t        ----------\n", "        value\n\t            The argument value\n\t        Returns\n\t        -------\n\t            The hash-string\n\t        \"\"\"\n\t        return NotImplemented\n\t    @classmethod\n\t    def md5_hash(cls, *args) -> str:\n\t        \"\"\"\n", "        Generate the hash for strings and bytes using md5\n\t        Returns\n\t        -------\n\t            the resulting hexdigest\n\t        \"\"\"\n\t        h = hashlib.md5()\n\t        for value in args:\n\t            if isinstance(value, str):\n\t                value = value.encode()\n\t            h.update(value)\n", "        return h.hexdigest()\n"]}
{"filename": "scrat/hasher/iterable.py", "chunked_list": ["import logging\n\timport typing as T\n\tfrom .base import Hasher\n\tlogger = logging.getLogger(__name__)\n\tclass IterableHasher(Hasher):\n\t    \"\"\"\n\t    Apply one Hasher to each element of a iterable\n\t    Parameters\n\t    ----------\n\t    item_hasher\n", "        A Hasher to hash each value in the iterable\n\t    Examples\n\t    --------\n\t    >>> import scrat as sc\n\t    >>> import numpy as np\n\t    >>> hasher = sc.IterableHasher(sc.NumpyHasher())\n\t    >>> hasher.hash([np.zeros(5), np.ones(3)])\n\t    'f86f4d4c12a426ce5d54d715723584be'\n\t    \"\"\"\n\t    def __init__(self, item_hasher: Hasher) -> None:\n", "        super().__init__()\n\t        self.item_hasher = item_hasher\n\t    def hash(self, value: T.Iterable) -> str:\n\t        return self.md5_hash(*[self.item_hasher.hash(x) for x in value])\n"]}
{"filename": "scrat/hasher/pandas.py", "chunked_list": ["import typing as T\n\tfrom .base import Hasher\n\tclass PandasHasher(Hasher):\n\t    \"\"\"\n\t    Hasher for Pandas Series and DataFrames\n\t    Parameters\n\t    ----------\n\t    use_values\n\t        If False, only the index of the dataframe is included in the hash\n\t        This can help with the speed of the hasher on big dataframes where\n", "        you only care what rows are included but you know the values\n\t        don't change, by default True\n\t    \"\"\"\n\t    def __init__(self, use_values: bool = True) -> None:\n\t        super().__init__()\n\t        self.use_values = use_values\n\t    def hash(self, value: T.Any) -> str:\n\t        if self.use_values:\n\t            return self.md5_hash(value.index.values, value.values)\n\t        return self.md5_hash(value.index.values)\n"]}
{"filename": "scrat/hasher/__init__.py", "chunked_list": ["\"Module containing all Hashers\"\n\tfrom .base import Hasher  # noqa: F401\n\tfrom .iterable import IterableHasher  # noqa: F401\n\tfrom .manager import HashManager  # noqa: F401\n\tfrom .numpy import NumpyHasher  # noqa: F401\n\tfrom .pandas import PandasHasher  # noqa: F401\n\tfrom .to_string import ToStringHasher  # noqa: F401\n\t__all__ = [\"NumpyHasher\", \"PandasHasher\", \"ToStringHasher\", \"IterableHasher\", \"Hasher\"]\n"]}
{"filename": "scrat/hasher/numpy.py", "chunked_list": ["import typing as T\n\tfrom .base import Hasher\n\tclass NumpyHasher(Hasher):\n\t    \"Hasher for numpy arrays\"\n\t    def hash(self, value: T.Any) -> str:\n\t        return self.md5_hash(value)\n"]}
{"filename": "scrat/hasher/to_string.py", "chunked_list": ["import typing as T\n\tfrom .base import Hasher\n\tclass ToStringHasher(Hasher):\n\t    \"Naive hasher that tries to conver the value to str and then hash it\"\n\t    def hash(self, value: T.Any) -> str:\n\t        return self.md5_hash(str(value))\n"]}
