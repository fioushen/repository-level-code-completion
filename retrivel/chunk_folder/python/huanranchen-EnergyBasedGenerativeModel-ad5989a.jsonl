{"filename": "main.py", "chunked_list": ["from Solver import MCMCSolver\n\tfrom sampler import EnergyBasedLangevinDynamicSampler\n\tfrom data import get_CIFAR10_train, get_CIFAR10_test\n\tfrom models import UnconditionalResNet32\n\timport torch\n\tfrom torchvision import transforms\n\tto_img = transforms.ToPILImage()\n\tloader = get_CIFAR10_train(batch_size=256)\n\tmodel = UnconditionalResNet32().cuda().eval()\n\t# model.load_state_dict(torch.load('model.pth'))\n", "sampler = EnergyBasedLangevinDynamicSampler(model)\n\tsolver = MCMCSolver(model, sampler)\n\tsolver.train(loader)\n\tmodel.eval()\n\t#\n\tx, _ = next(iter(loader))\n\tx = x[:1].cuda()\n\tprint(model(x.cuda()).sum())\n\tx = sampler.sample(x, step=600)\n\tprint(model(x.cuda()).sum(), x.shape)\n", "#\n\tx = torch.rand(1, 3, 32, 32).cuda()\n\tprint(model(x.cuda()).sum())\n\tx = sampler.sample(x, step=600)\n\tprint(model(x.cuda()).sum(), x.shape)\n\tx = to_img(x[0].squeeze())\n\tx.save('test.png')\n"]}
{"filename": "Solver/MCMCSolver.py", "chunked_list": ["import torch\n\tfrom torch import nn, Tensor\n\tfrom torch.utils.data import DataLoader\n\tfrom typing import Callable\n\tfrom tqdm import tqdm\n\timport random\n\tclass MCMCSolver():\n\t    def __init__(self,\n\t                 model: nn.Module,\n\t                 sampler: Callable):\n", "        self.device = torch.device('cuda')\n\t        self.model = model.to(self.device)\n\t        self.sampler = sampler\n\t    def train(self,\n\t              loader: DataLoader,\n\t              total_epoch=2000,\n\t              lr=1e-4,\n\t              uncondition_prob=1,\n\t              buffer_size=10000,\n\t              ):\n", "        self.buffer = torch.rand(64, *self.sampler.img_size, device=self.device)\n\t        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n\t        for epoch in range(1, total_epoch + 1):\n\t            pbar = tqdm(loader)\n\t            epoch_loss = 0\n\t            for step, (x, y) in enumerate(pbar, 1):\n\t                x, y = x.cuda(), y.cuda()\n\t                # small trick\n\t                x = x + torch.randn_like(x) * 0.0025\n\t                #\n", "                selected = torch.randint(low=0, high=self.buffer.shape[0] - 1,\n\t                                         size=(round(x.shape[0] * 0.95),))\n\t                unselected = set(list(range(self.buffer.shape[0]))) - set(selected.numpy().tolist())\n\t                unselected = torch.tensor(list(unselected), device=self.device)\n\t                negative_buffer = self.buffer[selected]\n\t                rand_buffer = self.initial_distribution_sample(round(x.shape[0] * 0.05))\n\t                self.buffer = self.buffer[unselected]\n\t                negative = torch.cat([negative_buffer, rand_buffer], dim=0)\n\t                self.model.eval().requires_grad_(False)\n\t                negative = self.sampler(negative)\n", "                self.buffer = torch.cat([self.buffer, negative], dim=0)\n\t                self.model.train().requires_grad_(True)\n\t                # self.model.eval()\n\t                input = torch.cat([x, negative], dim=0)\n\t                output = self.model(input)\n\t                positive, negative = output[:x.shape[0]], output[x.shape[0]:]\n\t                # positive = self.model(x)\n\t                # negative = self.model(negative)\n\t                # print(torch.mean(positive), torch.mean(negative), negative[-1])\n\t                if random.random() < uncondition_prob:  # uncondition\n", "                    regulation_term = torch.mean(positive ** 2) + torch.mean(negative ** 2)\n\t                    loss = torch.mean(negative - positive)\n\t                    epoch_loss += loss.item()\n\t                    loss = loss + regulation_term\n\t                else:\n\t                    pass  # condition\n\t                optimizer.zero_grad()\n\t                loss.backward()\n\t                optimizer.step()\n\t                if step % 10 == 0:\n", "                    pbar.set_postfix_str(f'step {step}, loss {epoch_loss / step}')\n\t            torch.save(self.model.state_dict(), 'model.pth')\n\t            if self.buffer.shape[0] > buffer_size:\n\t                self.buffer = self.buffer[torch.randperm(self.buffer.shape[0])]\n\t                self.buffer = self.buffer[:buffer_size]\n\t    def initial_distribution_sample(self, batch_size):\n\t        # x0 = torch.randn(batch_size, *self.img_size, device=self.device)\n\t        # x0 = x0 * torch.tensor([0.2470, 0.2435, 0.2616], device=self.device).view(1, 3, 1, 1) + \\\n\t        #      torch.tensor([0.4914, 0.4822, 0.4465], device=self.device).view(1, 3, 1, 1)\n\t        x0 = torch.rand(batch_size, *self.sampler.img_size, device=self.device)\n", "        return x0\n"]}
{"filename": "Solver/__init__.py", "chunked_list": ["from .MCMCSolver import MCMCSolver"]}
{"filename": "sampler/LangevinDynamic.py", "chunked_list": ["import torch\n\tfrom torch import nn\n\tfrom torch import Tensor\n\timport math\n\tclass EnergyBasedLangevinDynamicSampler():\n\t    def __init__(self, model: nn.Module, img_size=(3, 32, 32)):\n\t        self.model = model\n\t        self.img_size = img_size\n\t        self.device = torch.device('cuda')\n\t    @torch.enable_grad()\n", "    def get_grad(self, x: Tensor) -> Tensor:\n\t        x.requires_grad = True\n\t        x.grad = None\n\t        target = self.model(x)\n\t        target = target.sum()\n\t        # print(target)\n\t        target.backward()\n\t        grad = x.grad.clone()\n\t        x.grad = None\n\t        x.requires_grad = False\n", "        return grad\n\t    @torch.no_grad()\n\t    def sample(self, x: Tensor, step=60, lam=0.0025, step_size=10):\n\t        for t in range(1, step + 1):\n\t            grad = self.get_grad(x)\n\t            grad = self.clamp(grad, min=-0.03, max=0.03)\n\t            # x = x + step_size * grad + torch.randn_like(x) * lam\n\t            x = x + 10 * grad + torch.randn_like(x) * lam\n\t            # x = x - 1 / 255 * grad.sign() + 1e-4 * torch.randn_like(x)\n\t            # print(grad)\n", "            # print(torch.mean(torch.randn_like(x) * math.sqrt(lam)), torch.mean(lam / 2 * grad))\n\t            x = self.clamp(x)\n\t        return x.detach()\n\t    def __call__(self, *args, **kwargs):\n\t        return self.sample(*args, **kwargs)\n\t    @staticmethod\n\t    def clamp(x: Tensor, min=0., max=1.) -> Tensor:\n\t        x = torch.clamp(x, min=min, max=max)\n\t        return x\n"]}
{"filename": "sampler/__init__.py", "chunked_list": ["from .LangevinDynamic import EnergyBasedLangevinDynamicSampler"]}
{"filename": "data/someset.py", "chunked_list": ["'''\n\tthis file aims to read any dataset satisfied that:\n\t    1.all the images are in one folder\n\t    2.only a dict to store ground truth. Keys are image names, values are ground truth labels.\n\t'''\n\timport os\n\timport torch\n\tfrom torch.utils.data import DataLoader, Dataset\n\tfrom torchvision import transforms\n\tfrom PIL import Image\n", "import numpy as np\n\tclass SomeDataSet(Dataset):\n\t    def __init__(self, img_path, gt_path):\n\t        self.transform = transforms.Compose([\n\t            # transforms.RandomResizedCrop(size=(224, 224), scale=(0.7, 1)),\n\t            # transforms.AutoAugment(),\n\t            transforms.ToTensor(),\n\t            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n\t        ])\n\t        self.images = [img for img in os.listdir(img_path) if img.endswith('.jpg')]\n", "        self.gt = np.load(gt_path, allow_pickle=True).item()\n\t        self.img_path = img_path\n\t    def __len__(self):\n\t        return len(self.images)\n\t    def __getitem__(self, item):\n\t        now = self.images[item]\n\t        now_img = Image.open(os.path.join(self.img_path, now))  # numpy\n\t        return self.transform(now_img), self.gt[now]\n\tdef get_someset_loader(img_path,\n\t                       gt_path,\n", "                       batch_size=128,\n\t                       num_workers=8,\n\t                       pin_memory=False, ):\n\t    set = SomeDataSet(img_path=img_path, gt_path=gt_path)\n\t    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=pin_memory)\n\t    return loader\n"]}
{"filename": "data/__init__.py", "chunked_list": ["from .cifar import get_CIFAR100_test, get_CIFAR100_train, get_CIFAR10_train, get_CIFAR10_test\n\tfrom .someset import SomeDataSet, get_someset_loader"]}
{"filename": "data/cifar.py", "chunked_list": ["import torch\n\tfrom torch.utils.data import DataLoader\n\tfrom torchvision import transforms\n\timport os.path\n\timport pickle\n\tfrom typing import Any, Callable, Optional, Tuple\n\timport numpy as np\n\tfrom PIL import Image\n\tfrom torchvision.datasets.utils import check_integrity, download_and_extract_archive\n\tfrom torchvision.datasets.vision import VisionDataset\n", "class CIFAR10(VisionDataset):\n\t    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n\t    Args:\n\t        root (string): Root directory of dataset where directory\n\t            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n\t        train (bool, optional): If True, creates dataset from training set, otherwise\n\t            creates from test set.\n\t        transform (callable, optional): A function/transform that takes in an PIL image\n\t            and returns a transformed version. E.g, ``transforms.RandomCrop``\n\t        target_transform (callable, optional): A function/transform that takes in the\n", "            target and transforms it.\n\t        download (bool, optional): If true, downloads the dataset from the internet and\n\t            puts it in root directory. If dataset is already downloaded, it is not\n\t            downloaded again.\n\t    \"\"\"\n\t    base_folder = \"cifar-10-batches-py\"\n\t    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n\t    filename = \"cifar-10-python.tar.gz\"\n\t    tgz_md5 = \"c58f30108f718f92721af3b95e74349a\"\n\t    train_list = [\n", "        [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n\t        [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n\t        [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n\t        [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n\t        [\"data_batch_5\", \"482c414d41f54cd18b22e5b47cb7c3cb\"],\n\t    ]\n\t    test_list = [\n\t        [\"test_batch\", \"40351d587109b95175f43aff81a1287e\"],\n\t    ]\n\t    meta = {\n", "        \"filename\": \"batches.meta\",\n\t        \"key\": \"label_names\",\n\t        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n\t    }\n\t    def __init__(\n\t            self,\n\t            root: str,\n\t            train: bool = True,\n\t            transform: Optional[Callable] = None,\n\t            target_transform: Optional[Callable] = None,\n", "            download: bool = False,\n\t    ) -> None:\n\t        super().__init__(root, transform=transform, target_transform=target_transform)\n\t        self.train = train  # training set or test set\n\t        if download:\n\t            self.download()\n\t        if not self._check_integrity():\n\t            raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n\t        if self.train:\n\t            downloaded_list = self.train_list\n", "        else:\n\t            downloaded_list = self.test_list\n\t        self.data: Any = []\n\t        self.targets = []\n\t        # now load the picked numpy arrays\n\t        for file_name, checksum in downloaded_list:\n\t            file_path = os.path.join(self.root, self.base_folder, file_name)\n\t            with open(file_path, \"rb\") as f:\n\t                entry = pickle.load(f, encoding=\"latin1\")\n\t                self.data.append(entry[\"data\"])\n", "                if \"labels\" in entry:\n\t                    self.targets.extend(entry[\"labels\"])\n\t                else:\n\t                    self.targets.extend(entry[\"fine_labels\"])\n\t        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n\t        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n\t        self._load_meta()\n\t    def _load_meta(self) -> None:\n\t        path = os.path.join(self.root, self.base_folder, self.meta[\"filename\"])\n\t        if not check_integrity(path, self.meta[\"md5\"]):\n", "            raise RuntimeError(\"Dataset metadata file not found or corrupted. You can use download=True to download it\")\n\t        with open(path, \"rb\") as infile:\n\t            data = pickle.load(infile, encoding=\"latin1\")\n\t            self.classes = data[self.meta[\"key\"]]\n\t        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n\t    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n\t        \"\"\"\n\t        Args:\n\t            index (int): Index\n\t        Returns:\n", "            tuple: (image, target) where target is index of the target class.\n\t        \"\"\"\n\t        img, target = self.data[index], self.targets[index]\n\t        # doing this so that it is consistent with all other datasets\n\t        # to return a PIL Image\n\t        img = Image.fromarray(img)\n\t        if self.transform is not None:\n\t            img = self.transform(img)\n\t        if self.target_transform is not None:\n\t            target = self.target_transform(target)\n", "        return img, target\n\t    def __len__(self) -> int:\n\t        return len(self.data)\n\t    def _check_integrity(self) -> bool:\n\t        root = self.root\n\t        for fentry in self.train_list + self.test_list:\n\t            filename, md5 = fentry[0], fentry[1]\n\t            fpath = os.path.join(root, self.base_folder, filename)\n\t            if not check_integrity(fpath, md5):\n\t                return False\n", "        return True\n\t    def download(self) -> None:\n\t        if self._check_integrity():\n\t            print(\"Files already downloaded and verified\")\n\t            return\n\t        download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n\t    def extra_repr(self) -> str:\n\t        split = \"Train\" if self.train is True else \"Test\"\n\t        return f\"Split: {split}\"\n\tclass CIFAR100(CIFAR10):\n", "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n\t    This is a subclass of the `CIFAR10` Dataset.\n\t    \"\"\"\n\t    base_folder = \"cifar-100-python\"\n\t    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n\t    filename = \"cifar-100-python.tar.gz\"\n\t    tgz_md5 = \"eb9058c3a382ffc7106e4002c42a8d85\"\n\t    train_list = [\n\t        [\"train\", \"16019d7e3df5f24257cddd939b257f8d\"],\n\t    ]\n", "    test_list = [\n\t        [\"test\", \"f0ef6b0ae62326f3e7ffdfab6717acfc\"],\n\t    ]\n\t    meta = {\n\t        \"filename\": \"meta\",\n\t        \"key\": \"fine_label_names\",\n\t        \"md5\": \"7973b15100ade9c7d40fb424638fde48\",\n\t    }\n\tdef get_CIFAR100_train(batch_size=256,\n\t                       num_workers=8,\n", "                       pin_memory=True,\n\t                       augment=False,\n\t                       ):\n\t    if not augment:\n\t        transform = transforms.Compose([\n\t            transforms.ToTensor(),\n\t            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n\t        ])\n\t    else:\n\t        transform = transforms.Compose([\n", "            transforms.RandomHorizontalFlip(),\n\t            transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n\t            transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n\t            transforms.RandomRotation(5),\n\t            transforms.ToTensor(),\n\t            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n\t        ])\n\t    set = CIFAR100('./resources/CIFAR100', train=True, download=True, transform=transform)\n\t    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory,\n\t                        shuffle=True)\n", "    return loader\n\tdef get_CIFAR100_test(batch_size=256,\n\t                      num_workers=8,\n\t                      pin_memory=False, ):\n\t    transform = transforms.Compose([\n\t        transforms.ToTensor(),\n\t        transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n\t    ])\n\t    set = CIFAR100('./resources/CIFAR100', train=False, download=True, transform=transform)\n\t    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n", "    return loader\n\tdef get_CIFAR10_train(batch_size=256,\n\t                      num_workers=8,\n\t                      pin_memory=True,\n\t                      augment=False,\n\t                      ):\n\t    if not augment:\n\t        transform = transforms.Compose([\n\t            transforms.ToTensor(),\n\t            # transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n", "        ])\n\t    else:\n\t        transform = transforms.Compose([\n\t            # transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n\t            transforms.ToTensor(),\n\t            # transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n\t        ])\n\t    set = CIFAR10('./resources/CIFAR10', train=True, download=True, transform=transform)\n\t    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory,\n\t                        shuffle=True)\n", "    return loader\n\tdef get_CIFAR10_test(batch_size=256,\n\t                     num_workers=8,\n\t                     pin_memory=True, ):\n\t    transform = transforms.Compose([\n\t        transforms.ToTensor(),\n\t        # transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n\t    ])\n\t    set = CIFAR10('./resources/CIFAR10', train=False, download=True, transform=transform)\n\t    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n", "    return loader\n"]}
{"filename": "models/PreTransform.py", "chunked_list": ["import torch\n\tfrom torchvision import transforms\n\tdef cifar10_normalize():\n\t    return transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n"]}
{"filename": "models/__init__.py", "chunked_list": ["from .UnconditionalResNets import UnconditionalResNet32"]}
{"filename": "models/UnconditionalResNets.py", "chunked_list": ["from .SmallResolutionModel.resnet import resnet32\n\tfrom .SmallResolutionModel import Wide_ResNet, IGEBM\n\timport torch\n\tfrom torch import nn\n\tfrom .PreTransform import cifar10_normalize\n\tfrom torch import Tensor\n\tclass UnconditionalResNet32(nn.Module):\n\t    def __init__(self):\n\t        super(UnconditionalResNet32, self).__init__()\n\t        # self.transform = cifar10_normalize()\n", "        # self.cnn = Wide_ResNet(num_classes=1)\n\t        # self.cnn = resnet32(num_classes=1)\n\t        self.cnn = IGEBM()\n\t    def forward(self, x: Tensor) -> Tensor:\n\t        # x = self.transform(x)\n\t        x = (x - 0.5) * 2\n\t        x = self.cnn(x)\n\t        return x\n"]}
{"filename": "models/SmallResolutionModel/cifar10_resnet.py", "chunked_list": ["# ---------------------------------------------------------------\n\t# Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.\n\t#\n\t# This work is licensed under the NVIDIA Source Code License\n\t# for DiffPure. To view a copy of this license, see the LICENSE file.\n\t# ---------------------------------------------------------------\n\timport math\n\timport torch\n\timport torch.nn.functional as F\n\timport torch.nn as nn\n", "# ---------------------------- ResNet ----------------------------\n\tclass Bottleneck(nn.Module):\n\t    expansion = 4\n\t    def __init__(self, in_planes, planes, stride=1):\n\t        super(Bottleneck, self).__init__()\n\t        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(planes)\n\t        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\t        self.bn2 = nn.BatchNorm2d(planes)\n\t        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n", "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n\t        self.shortcut = nn.Sequential()\n\t        if stride != 1 or in_planes != self.expansion * planes:\n\t            self.shortcut = nn.Sequential(\n\t                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n\t                nn.BatchNorm2d(self.expansion * planes)\n\t            )\n\t    def forward(self, x):\n\t        out = F.relu(self.bn1(self.conv1(x)))\n\t        out = F.relu(self.bn2(self.conv2(out)))\n", "        out = self.bn3(self.conv3(out))\n\t        out += self.shortcut(x)\n\t        out = F.relu(out)\n\t        return out\n\tclass ResNet(nn.Module):\n\t    def __init__(self, block, num_blocks, num_classes=10):\n\t        super(ResNet, self).__init__()\n\t        self.in_planes = 64\n\t        num_input_channels = 3\n\t        mean = (0.4914, 0.4822, 0.4465)\n", "        std = (0.2471, 0.2435, 0.2616)\n\t        self.mean = torch.tensor(mean).view(num_input_channels, 1, 1)\n\t        self.std = torch.tensor(std).view(num_input_channels, 1, 1)\n\t        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(64)\n\t        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n\t        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n\t        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n\t        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n\t        self.linear = nn.Linear(512 * block.expansion, num_classes)\n", "    def _make_layer(self, block, planes, num_blocks, stride):\n\t        strides = [stride] + [1] * (num_blocks - 1)\n\t        layers = []\n\t        for stride in strides:\n\t            layers.append(block(self.in_planes, planes, stride))\n\t            self.in_planes = planes * block.expansion\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        out = (x - self.mean.to(x.device)) / self.std.to(x.device)\n\t        out = F.relu(self.bn1(self.conv1(out)))\n", "        out = self.layer1(out)\n\t        out = self.layer2(out)\n\t        out = self.layer3(out)\n\t        out = self.layer4(out)\n\t        out = F.avg_pool2d(out, 4)\n\t        out = out.view(out.size(0), -1)\n\t        out = self.linear(out)\n\t        return out\n\tdef ResNet50():\n\t    return ResNet(Bottleneck, [3, 4, 6, 3])\n", "# ---------------------------- ResNet ----------------------------\n\t# ---------------------------- WideResNet ----------------------------\n\tclass BasicBlock(nn.Module):\n\t    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n\t        super(BasicBlock, self).__init__()\n\t        self.bn1 = nn.BatchNorm2d(in_planes)\n\t        self.relu1 = nn.ReLU(inplace=True)\n\t        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n\t                               padding=1, bias=False)\n\t        self.bn2 = nn.BatchNorm2d(out_planes)\n", "        self.relu2 = nn.ReLU(inplace=True)\n\t        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n\t                               padding=1, bias=False)\n\t        self.droprate = dropRate\n\t        self.equalInOut = (in_planes == out_planes)\n\t        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n\t                                                                padding=0, bias=False) or None\n\t    def forward(self, x):\n\t        if not self.equalInOut:\n\t            x = self.relu1(self.bn1(x))\n", "        else:\n\t            out = self.relu1(self.bn1(x))\n\t        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n\t        if self.droprate > 0:\n\t            out = F.dropout(out, p=self.droprate, training=self.training)\n\t        out = self.conv2(out)\n\t        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\tclass NetworkBlock(nn.Module):\n\t    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n\t        super(NetworkBlock, self).__init__()\n", "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n\t    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n\t        layers = []\n\t        for i in range(int(nb_layers)):\n\t            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        return self.layer(x)\n\tclass WideResNet(nn.Module):\n\t    \"\"\" Based on code from https://github.com/yaodongyu/TRADES \"\"\"\n", "    def __init__(self, depth=28, num_classes=10, widen_factor=10, sub_block1=False, dropRate=0.0, bias_last=True):\n\t        super(WideResNet, self).__init__()\n\t        num_input_channels = 3\n\t        mean = (0.4914, 0.4822, 0.4465)\n\t        std = (0.2471, 0.2435, 0.2616)\n\t        self.mean = torch.tensor(mean).view(num_input_channels, 1, 1)\n\t        self.std = torch.tensor(std).view(num_input_channels, 1, 1)\n\t        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n\t        assert ((depth - 4) % 6 == 0)\n\t        n = (depth - 4) / 6\n", "        block = BasicBlock\n\t        # 1st conv before any network block\n\t        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n\t                               padding=1, bias=False)\n\t        # 1st block\n\t        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n\t        if sub_block1:\n\t            # 1st sub-block\n\t            self.sub_block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n\t        # 2nd block\n", "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n\t        # 3rd block\n\t        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n\t        # global average pooling and classifier\n\t        self.bn1 = nn.BatchNorm2d(nChannels[3])\n\t        self.relu = nn.ReLU(inplace=True)\n\t        self.fc = nn.Linear(nChannels[3], num_classes, bias=bias_last)\n\t        self.nChannels = nChannels[3]\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n", "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2. / n))\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear) and not m.bias is None:\n\t                m.bias.data.zero_()\n\t    def forward(self, x):\n\t        out = (x - self.mean.to(x.device)) / self.std.to(x.device)\n\t        out = self.conv1(out)\n", "        out = self.block1(out)\n\t        out = self.block2(out)\n\t        out = self.block3(out)\n\t        out = self.relu(self.bn1(out))\n\t        out = F.avg_pool2d(out, 8)\n\t        out = out.view(-1, self.nChannels)\n\t        return self.fc(out)\n\tdef WideResNet_70_16():\n\t    return WideResNet(depth=70, widen_factor=16, dropRate=0.0)\n\tdef WideResNet_70_16_dropout():\n", "    model = WideResNet(depth=70, widen_factor=16, dropRate=0.3)\n\t    state = torch.load('./resources/checkpoints/models/WideResNet_70_16_dropout.pt')\n\t    r = {}\n\t    for k, v in list(state.items()):\n\t        k = k.split('module.', 1)[1]\n\t        r[k] = v\n\t    model.load_state_dict(r)\n\t    return model\n\t# ---------------------------- WideResNet ----------------------------\n"]}
{"filename": "models/SmallResolutionModel/wrn.py", "chunked_list": ["import math\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\t\"\"\"\n\tOriginal Author: Wei Yang\n\tadding hyperparameter norm_layer: Huanran Chen\n\t\"\"\"\n\t__all__ = [\n\t    \"wrn\",\n", "    \"wrn_40_2_aux\",\n\t    \"wrn_16_2_aux\",\n\t    \"wrn_16_1\",\n\t    \"wrn_16_2\",\n\t    \"wrn_40_1\",\n\t    \"wrn_40_2\",\n\t    \"wrn_40_1_aux\",\n\t    \"wrn_16_2_spkd\",\n\t    \"wrn_40_1_spkd\",\n\t    \"wrn_40_2_spkd\",\n", "    \"wrn_40_1_crd\",\n\t    \"wrn_16_2_crd\",\n\t    \"wrn_40_2_crd\",\n\t    \"wrn_16_2_sskd\",\n\t    \"wrn_40_1_sskd\",\n\t    \"wrn_40_2_sskd\",\n\t]\n\tclass Normalizer4CRD(nn.Module):\n\t    def __init__(self, linear, power=2):\n\t        super().__init__()\n", "        self.linear = linear\n\t        self.power = power\n\t    def forward(self, x):\n\t        x = x.flatten(1)\n\t        z = self.linear(x)\n\t        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n\t        out = z.div(norm)\n\t        return out\n\tclass BasicBlock(nn.Module):\n\t    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, norm_layer=nn.BatchNorm2d):\n", "        super(BasicBlock, self).__init__()\n\t        self.bn1 = norm_layer(in_planes)\n\t        self.relu1 = nn.ReLU(inplace=True)\n\t        self.conv1 = nn.Conv2d(\n\t            in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False\n\t        )\n\t        self.bn2 = norm_layer(out_planes)\n\t        self.relu2 = nn.ReLU(inplace=True)\n\t        self.conv2 = nn.Conv2d(\n\t            out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False\n", "        )\n\t        self.droprate = dropRate\n\t        self.equalInOut = in_planes == out_planes\n\t        self.convShortcut = (\n\t                (not self.equalInOut)\n\t                and nn.Conv2d(\n\t            in_planes, out_planes, kernel_size=1, stride=stride, padding=0, bias=False\n\t        )\n\t                or None\n\t        )\n", "    def forward(self, x):\n\t        if not self.equalInOut:\n\t            x = self.relu1(self.bn1(x))\n\t        else:\n\t            out = self.relu1(self.bn1(x))\n\t        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n\t        if self.droprate > 0:\n\t            out = F.dropout(out, p=self.droprate, training=self.training)\n\t        out = self.conv2(out)\n\t        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n", "class NetworkBlock(nn.Module):\n\t    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0,\n\t                 norm_layer=nn.BatchNorm2d):\n\t        super(NetworkBlock, self).__init__()\n\t        self.layer = self._make_layer(block, in_planes, out_planes,\n\t                                      nb_layers, stride, dropRate, norm_layer)\n\t    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, norm_layer):\n\t        layers = []\n\t        for i in range(nb_layers):\n\t            layers.append(\n", "                block(\n\t                    i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate,\n\t                    norm_layer=norm_layer\n\t                )\n\t            )\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        return self.layer(x)\n\tclass WideResNet(nn.Module):\n\t    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0,\n", "                 norm_layer=nn.BatchNorm2d):\n\t        super(WideResNet, self).__init__()\n\t        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n\t        assert (depth - 4) % 6 == 0, \"depth should be 6n+4\"\n\t        n = (depth - 4) // 6\n\t        block = BasicBlock\n\t        # 1st conv before any network block\n\t        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)\n\t        # 1st block\n\t        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, norm_layer)\n", "        # 2nd block\n\t        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate, norm_layer)\n\t        # 3rd block\n\t        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate, norm_layer)\n\t        # global average pooling and classifier\n\t        self.bn1 = nn.BatchNorm2d(nChannels[3])\n\t        self.relu = nn.ReLU(inplace=True)\n\t        self.last_channel = nChannels[3]\n\t        self.fc = nn.Linear(nChannels[3], num_classes)\n\t        self.nChannels = nChannels[3]\n", "        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                m.bias.data.zero_()\n\t    def get_feat_modules(self):\n", "        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.block1)\n\t        feat_m.append(self.block2)\n\t        feat_m.append(self.block3)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        bn1 = self.block2.layer[0].bn1\n\t        bn2 = self.block3.layer[0].bn1\n\t        bn3 = self.bn1\n", "        return [bn1, bn2, bn3]\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        out = self.conv1(x)\n\t        out = self.block1(out)\n\t        f1 = out\n\t        out = self.block2(out)\n\t        f2 = out\n\t        out = self.block3(out)\n\t        f3 = out\n\t        out = self.relu(self.bn1(out))\n", "        f4 = out\n\t        out = F.avg_pool2d(out, 8)\n\t        out = out.view(-1, self.nChannels)\n\t        out = self.fc(out)\n\t        if is_feat:\n\t            return [f1, f2, f3, f4], out\n\t        else:\n\t            return out\n\tclass Auxiliary_Classifier(nn.Module):\n\t    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n", "        super(Auxiliary_Classifier, self).__init__()\n\t        self.nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n\t        block = BasicBlock\n\t        n = (depth - 4) // 6\n\t        self.block_extractor1 = nn.Sequential(\n\t            *[\n\t                NetworkBlock(n, self.nChannels[1], self.nChannels[2], block, 2),\n\t                NetworkBlock(n, self.nChannels[2], self.nChannels[3], block, 2),\n\t            ]\n\t        )\n", "        self.block_extractor2 = nn.Sequential(\n\t            *[NetworkBlock(n, self.nChannels[2], self.nChannels[3], block, 2)]\n\t        )\n\t        self.block_extractor3 = nn.Sequential(\n\t            *[NetworkBlock(n, self.nChannels[3], self.nChannels[3], block, 1)]\n\t        )\n\t        self.bn1 = nn.BatchNorm2d(self.nChannels[3])\n\t        self.bn2 = nn.BatchNorm2d(self.nChannels[3])\n\t        self.bn3 = nn.BatchNorm2d(self.nChannels[3])\n\t        self.relu = nn.ReLU(inplace=True)\n", "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc1 = nn.Linear(self.nChannels[3], num_classes)\n\t        self.fc2 = nn.Linear(self.nChannels[3], num_classes)\n\t        self.fc3 = nn.Linear(self.nChannels[3], num_classes)\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n", "                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                m.bias.data.zero_()\n\t    def forward(self, x):\n\t        ss_logits = []\n\t        ss_feats = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n\t            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = self.relu(getattr(self, \"bn\" + str(idx))(out))\n", "            out = self.avg_pool(out)\n\t            out = out.view(-1, self.nChannels[3])\n\t            ss_feats.append(out)\n\t            out = getattr(self, \"fc\" + str(idx))(out)\n\t            ss_logits.append(out)\n\t        return ss_logits\n\tclass WideResNet_Auxiliary(nn.Module):\n\t    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n\t        super(WideResNet_Auxiliary, self).__init__()\n\t        self.backbone = WideResNet(depth, num_classes, widen_factor=widen_factor)\n", "        self.auxiliary_classifier = Auxiliary_Classifier(\n\t            depth=depth, num_classes=num_classes * 4, widen_factor=widen_factor\n\t        )\n\t    def forward(self, x, grad=False):\n\t        feats, logit = self.backbone(x, is_feat=True)\n\t        if grad is False:\n\t            for i in range(len(feats)):\n\t                feats[i] = feats[i].detach()\n\t        ss_logits = self.auxiliary_classifier(feats)\n\t        return logit, ss_logits\n", "class WideResNet_SPKD(WideResNet):\n\t    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n\t        super(WideResNet_SPKD, self).__init__(depth, num_classes, widen_factor, dropRate)\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        out = self.conv1(x)\n\t        out = self.block1(out)\n\t        out = self.block2(out)\n\t        out = self.block3(out)\n\t        out = self.relu(self.bn1(out))\n\t        out = F.avg_pool2d(out, 8)\n", "        out = out.view(-1, self.nChannels)\n\t        f4 = out\n\t        out = self.fc(out)\n\t        return f4, out\n\tclass WideResNet_SSKD(WideResNet):\n\t    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n\t        super(WideResNet_SSKD, self).__init__(depth, num_classes, widen_factor, dropRate)\n\t        self.ss_module = nn.Sequential(\n\t            nn.Linear(self.nChannels, self.nChannels),\n\t            nn.ReLU(inplace=True),\n", "            nn.Linear(self.nChannels, self.nChannels),\n\t        )\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        out = self.conv1(x)\n\t        out = self.block1(out)\n\t        out = self.block2(out)\n\t        out = self.block3(out)\n\t        out = self.relu(self.bn1(out))\n\t        out = F.avg_pool2d(out, 8)\n\t        out = out.view(-1, self.nChannels)\n", "        f4 = self.ss_module(out)\n\t        out = self.fc(out)\n\t        return f4, out\n\tclass WideResNet_CRD(nn.Module):\n\t    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0,\n\t                 norm_layer=nn.BatchNorm2d):\n\t        super(WideResNet_CRD, self).__init__()\n\t        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n\t        assert (depth - 4) % 6 == 0, \"depth should be 6n+4\"\n\t        n = (depth - 4) // 6\n", "        block = BasicBlock\n\t        # 1st conv before any network block\n\t        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)\n\t        # 1st block\n\t        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n\t        # 2nd block\n\t        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n\t        # 3rd block\n\t        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n\t        # global average pooling and classifier\n", "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n\t        self.relu = nn.ReLU(inplace=True)\n\t        self.fc = nn.Linear(nChannels[3], num_classes)\n\t        linear = nn.Linear(nChannels[3], 128, bias=True)\n\t        self.normalizer = Normalizer4CRD(linear, power=2)\n\t        self.nChannels = nChannels[3]\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n", "            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                m.bias.data.zero_()\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.block1)\n\t        feat_m.append(self.block2)\n", "        feat_m.append(self.block3)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        bn1 = self.block2.layer[0].bn1\n\t        bn2 = self.block3.layer[0].bn1\n\t        bn3 = self.bn1\n\t        return [bn1, bn2, bn3]\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        out = self.conv1(x)\n\t        out = self.block1(out)\n", "        out = self.block2(out)\n\t        out = self.block3(out)\n\t        out = self.relu(self.bn1(out))\n\t        out = F.avg_pool2d(out, 8)\n\t        crdout = out\n\t        out = out.view(-1, self.nChannels)\n\t        out = self.fc(out)\n\t        crdout = self.normalizer(crdout)\n\t        return crdout, out\n\tdef wrn(**kwargs):\n", "    \"\"\"\n\t    Constructs a Wide Residual Networks.\n\t    \"\"\"\n\t    model = WideResNet(**kwargs)\n\t    return model\n\tdef wrn_40_2(**kwargs):\n\t    model = WideResNet(depth=40, widen_factor=2, **kwargs)\n\t    return model\n\tdef wrn_40_2_aux(**kwargs):\n\t    model = WideResNet_Auxiliary(depth=40, widen_factor=2, **kwargs)\n", "    return model\n\tdef wrn_40_2_spkd(**kwargs):\n\t    model = WideResNet_SPKD(depth=40, widen_factor=2, **kwargs)\n\t    return model\n\tdef wrn_40_2_sskd(**kwargs):\n\t    model = WideResNet_SSKD(depth=40, widen_factor=2, **kwargs)\n\t    return model\n\tdef wrn_40_2_crd(**kwargs):\n\t    model = WideResNet_CRD(depth=40, widen_factor=2, **kwargs)\n\t    return model\n", "def wrn_40_1(**kwargs):\n\t    model = WideResNet(depth=40, widen_factor=1, **kwargs)\n\t    return model\n\tdef wrn_40_1_aux(**kwargs):\n\t    model = WideResNet_Auxiliary(depth=40, widen_factor=1, **kwargs)\n\t    return model\n\tdef wrn_40_1_spkd(**kwargs):\n\t    model = WideResNet_SPKD(depth=40, widen_factor=1, **kwargs)\n\t    return model\n\tdef wrn_40_1_crd(**kwargs):\n", "    model = WideResNet_CRD(depth=40, widen_factor=1, **kwargs)\n\t    return model\n\tdef wrn_40_1_sskd(**kwargs):\n\t    model = WideResNet_SSKD(depth=40, widen_factor=1, **kwargs)\n\t    return model\n\tdef wrn_16_2(**kwargs):\n\t    model = WideResNet(depth=16, widen_factor=2, **kwargs)\n\t    return model\n\tdef wrn_16_2_aux(**kwargs):\n\t    model = WideResNet_Auxiliary(depth=16, widen_factor=2, **kwargs)\n", "    return model\n\tdef wrn_16_2_spkd(**kwargs):\n\t    model = WideResNet_SPKD(depth=16, widen_factor=2, **kwargs)\n\t    return model\n\tdef wrn_16_2_crd(**kwargs):\n\t    model = WideResNet_CRD(depth=16, widen_factor=2, **kwargs)\n\t    return model\n\tdef wrn_16_2_sskd(**kwargs):\n\t    model = WideResNet_SSKD(depth=16, widen_factor=2, **kwargs)\n\t    return model\n", "def wrn_16_1(**kwargs):\n\t    model = WideResNet(depth=16, widen_factor=1, **kwargs)\n\t    return model\n"]}
{"filename": "models/SmallResolutionModel/mobilenetv2.py", "chunked_list": ["\"\"\"\n\tMobileNetV2 implementation used in\n\t<Knowledge Distillation via Route Constrained Optimization>\n\tadding hyperparameter norm_layer: Huanran Chen\n\t\"\"\"\n\timport math\n\timport torch\n\timport torch.nn as nn\n\t__all__ = [\n\t    \"mobilenetv2_T_w\",\n", "    \"mobilenetV2\",\n\t    \"mobilenetV2_aux\",\n\t    \"mobilenetV2_spkd\",\n\t    \"mobilenetV2_crd\",\n\t]\n\tBN = None\n\tclass Normalizer4CRD(nn.Module):\n\t    def __init__(self, linear, power=2):\n\t        super().__init__()\n\t        self.linear = linear\n", "        self.power = power\n\t    def forward(self, x):\n\t        x = x.flatten(1)\n\t        z = self.linear(x)\n\t        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n\t        out = z.div(norm)\n\t        return out\n\tdef conv_bn(inp, oup, stride):\n\t    return nn.Sequential(\n\t        nn.Conv2d(inp, oup, 3, stride, 1, bias=False), nn.BatchNorm2d(oup), nn.ReLU(inplace=True)\n", "    )\n\tdef conv_1x1_bn(inp, oup):\n\t    return nn.Sequential(\n\t        nn.Conv2d(inp, oup, 1, 1, 0, bias=False), nn.BatchNorm2d(oup), nn.ReLU(inplace=True)\n\t    )\n\tclass InvertedResidual(nn.Module):\n\t    def __init__(self, inp, oup, stride, expand_ratio, norm_layer=nn.BatchNorm2d):\n\t        super(InvertedResidual, self).__init__()\n\t        self.blockname = None\n\t        self.stride = stride\n", "        assert stride in [1, 2]\n\t        self.use_res_connect = self.stride == 1 and inp == oup\n\t        self.conv = nn.Sequential(\n\t            # pw\n\t            nn.Conv2d(inp, inp * expand_ratio, 1, 1, 0, bias=False),\n\t            norm_layer(inp * expand_ratio),\n\t            nn.ReLU(inplace=True),\n\t            # dw\n\t            nn.Conv2d(\n\t                inp * expand_ratio,\n", "                inp * expand_ratio,\n\t                3,\n\t                stride,\n\t                1,\n\t                groups=inp * expand_ratio,\n\t                bias=False,\n\t            ),\n\t            norm_layer(inp * expand_ratio),\n\t            nn.ReLU(inplace=True),\n\t            # pw-linear\n", "            nn.Conv2d(inp * expand_ratio, oup, 1, 1, 0, bias=False),\n\t            norm_layer(oup),\n\t        )\n\t        self.names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n\t    def forward(self, x):\n\t        t = x\n\t        if self.use_res_connect:\n\t            return t + self.conv(x)\n\t        else:\n\t            return self.conv(x)\n", "class MobileNetV2(nn.Module):\n\t    \"\"\"mobilenetV2\"\"\"\n\t    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False,\n\t                 norm_layer=nn.BatchNorm2d):\n\t        super(MobileNetV2, self).__init__()\n\t        self.remove_avg = remove_avg\n\t        # setting of inverted residual blocks\n\t        self.interverted_residual_setting = [\n\t            # t, c, n, s\n\t            [1, 16, 1, 1],\n", "            [T, 24, 2, 1],\n\t            [T, 32, 3, 2],\n\t            [T, 64, 4, 2],\n\t            [T, 96, 3, 1],\n\t            [T, 160, 3, 2],\n\t            [T, 320, 1, 1],\n\t        ]\n\t        # building first layer\n\t        assert input_size % 32 == 0\n\t        input_channel = int(32 * width_mult)\n", "        self.conv1 = conv_bn(3, input_channel, 2)\n\t        # building inverted residual blocks\n\t        self.blocks = nn.ModuleList([])\n\t        for t, c, n, s in self.interverted_residual_setting:\n\t            output_channel = int(c * width_mult)\n\t            layers = []\n\t            strides = [s] + [1] * (n - 1)\n\t            for stride in strides:\n\t                layers.append(InvertedResidual(input_channel, output_channel, stride, t,\n\t                                               norm_layer=norm_layer))\n", "                input_channel = output_channel\n\t            self.blocks.append(nn.Sequential(*layers))\n\t        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n\t        self.conv2 = conv_1x1_bn(input_channel, self.last_channel)\n\t        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\t        # building classifier\n\t        # self.classifier = nn.Sequential(\n\t        #    # nn.Dropout(0.5),\n\t        #    nn.Linear(self.last_channel, feature_dim),\n\t        # )\n", "        self.classifier = nn.Linear(self.last_channel, feature_dim)\n\t        self._initialize_weights()\n\t    def get_bn_before_relu(self):\n\t        bn1 = self.blocks[1][-1].conv[-1]\n\t        bn2 = self.blocks[2][-1].conv[-1]\n\t        bn3 = self.blocks[4][-1].conv[-1]\n\t        bn4 = self.blocks[6][-1].conv[-1]\n\t        return [bn1, bn2, bn3, bn4]\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n", "        feat_m.append(self.conv1)\n\t        feat_m.append(self.blocks)\n\t        return feat_m\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        out = self.conv1(x)\n\t        out = self.blocks[0](out)\n\t        out = self.blocks[1](out)\n\t        f1 = out\n\t        out = self.blocks[2](out)\n\t        f2 = out\n", "        out = self.blocks[3](out)\n\t        out = self.blocks[4](out)\n\t        f3 = out\n\t        out = self.blocks[5](out)\n\t        out = self.blocks[6](out)\n\t        out = self.conv2(out)\n\t        f4 = out\n\t        if not self.remove_avg:\n\t            out = self.avgpool(out)\n\t        out = out.view(out.size(0), -1)\n", "        out = self.classifier(out)\n\t        if is_feat:\n\t            return [f1, f2, f3, f4], out\n\t        else:\n\t            return out\n\t    def _initialize_weights(self):\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n", "                if m.bias is not None:\n\t                    m.bias.data.zero_()\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                n = m.weight.size(1)\n\t                m.weight.data.normal_(0, 0.01)\n\t                m.bias.data.zero_()\n\tclass Auxiliary_Classifier(nn.Module):\n", "    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False):\n\t        super(Auxiliary_Classifier, self).__init__()\n\t        self.remove_avg = remove_avg\n\t        self.width_mult = width_mult\n\t        # setting of inverted residual blocks\n\t        interverted_residual_setting1 = [\n\t            [T, 32, 3, 2],\n\t            [T, 64, 4, 2],\n\t            [T, 96, 3, 1],\n\t            [T, 160, 3, 2],\n", "            [T, 320, 1, 1],\n\t        ]\n\t        self.block_extractor1 = self._make_layer(\n\t            input_channel=12, interverted_residual_setting=interverted_residual_setting1\n\t        )\n\t        interverted_residual_setting2 = [\n\t            [T, 64, 4, 2],\n\t            [T, 96, 3, 1],\n\t            [T, 160, 3, 2],\n\t            [T, 320, 1, 1],\n", "        ]\n\t        self.block_extractor2 = self._make_layer(\n\t            input_channel=16, interverted_residual_setting=interverted_residual_setting2\n\t        )\n\t        interverted_residual_setting3 = [\n\t            [T, 160, 3, 2],\n\t            [T, 320, 1, 1],\n\t        ]\n\t        self.block_extractor3 = self._make_layer(\n\t            input_channel=48, interverted_residual_setting=interverted_residual_setting3\n", "        )\n\t        interverted_residual_setting4 = [\n\t            [T, 160, 3, 1],\n\t            [T, 320, 1, 1],\n\t        ]\n\t        self.block_extractor4 = self._make_layer(\n\t            input_channel=160, interverted_residual_setting=interverted_residual_setting4\n\t        )\n\t        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n", "        self.conv2_1 = conv_1x1_bn(160, self.last_channel)\n\t        self.conv2_2 = conv_1x1_bn(160, self.last_channel)\n\t        self.conv2_3 = conv_1x1_bn(160, self.last_channel)\n\t        self.conv2_4 = conv_1x1_bn(160, self.last_channel)\n\t        self.fc1 = nn.Linear(self.last_channel, feature_dim)\n\t        self.fc2 = nn.Linear(self.last_channel, feature_dim)\n\t        self.fc3 = nn.Linear(self.last_channel, feature_dim)\n\t        self.fc4 = nn.Linear(self.last_channel, feature_dim)\n\t        self._initialize_weights()\n\t    def _make_layer(self, input_channel, interverted_residual_setting):\n", "        # building inverted residual blocks\n\t        blocks = []\n\t        for t, c, n, s in interverted_residual_setting:\n\t            output_channel = int(c * self.width_mult)\n\t            layers = []\n\t            strides = [s] + [1] * (n - 1)\n\t            for stride in strides:\n\t                layers.append(InvertedResidual(input_channel, output_channel, stride, t))\n\t                input_channel = output_channel\n\t            blocks.append(nn.Sequential(*layers))\n", "        return nn.Sequential(*blocks)\n\t    def _initialize_weights(self):\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t                if m.bias is not None:\n\t                    m.bias.data.zero_()\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n", "                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                n = m.weight.size(1)\n\t                m.weight.data.normal_(0, 0.01)\n\t                m.bias.data.zero_()\n\t    def forward(self, x):\n\t        ss_logits = []\n\t        ss_feats = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n", "            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = getattr(self, \"conv2_\" + str(idx))(out)\n\t            out = self.avg_pool(out)\n\t            out = out.view(out.size(0), -1)\n\t            ss_feats.append(out)\n\t            out = getattr(self, \"fc\" + str(idx))(out)\n\t            ss_logits.append(out)\n\t        return ss_feats, ss_logits\n\tclass MobileNetv2_Auxiliary(nn.Module):\n\t    def __init__(self, T, W, feature_dim=100):\n", "        super(MobileNetv2_Auxiliary, self).__init__()\n\t        self.backbone = MobileNetV2(T=T, feature_dim=feature_dim, width_mult=W)\n\t        self.auxiliary_classifier = Auxiliary_Classifier(\n\t            T=T, feature_dim=4 * feature_dim, width_mult=W\n\t        )\n\t    def forward(self, x, grad=False, att=False):\n\t        feats, logit = self.backbone(x, is_feat=True)\n\t        if grad is False:\n\t            for i in range(len(feats)):\n\t                feats[i] = feats[i].detach()\n", "        ss_feats, ss_logits = self.auxiliary_classifier(feats)\n\t        if att is False:\n\t            return logit, ss_logits\n\t        else:\n\t            return logit, ss_logits, feats\n\tclass MobileNetV2_SPKD(MobileNetV2):\n\t    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False):\n\t        super(MobileNetV2_SPKD, self).__init__(T, feature_dim, input_size, width_mult, remove_avg)\n\t    def forward(self, x):\n\t        out = self.conv1(x)\n", "        out = self.blocks[0](out)\n\t        out = self.blocks[1](out)\n\t        out = self.blocks[2](out)\n\t        out = self.blocks[3](out)\n\t        out = self.blocks[4](out)\n\t        out = self.blocks[5](out)\n\t        out = self.blocks[6](out)\n\t        f4 = out\n\t        out = self.conv2(out)\n\t        if not self.remove_avg:\n", "            out = self.avgpool(out)\n\t        out = out.view(out.size(0), -1)\n\t        out = self.classifier(out)\n\t        return f4, out\n\tclass MobileNetV2_CRD(nn.Module):\n\t    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False):\n\t        super(MobileNetV2_CRD, self).__init__()\n\t        self.remove_avg = remove_avg\n\t        # setting of inverted residual blocks\n\t        self.interverted_residual_setting = [\n", "            # t, c, n, s\n\t            [1, 16, 1, 1],\n\t            [T, 24, 2, 1],\n\t            [T, 32, 3, 2],\n\t            [T, 64, 4, 2],\n\t            [T, 96, 3, 1],\n\t            [T, 160, 3, 2],\n\t            [T, 320, 1, 1],\n\t        ]\n\t        # building first layer\n", "        assert input_size % 32 == 0\n\t        input_channel = int(32 * width_mult)\n\t        self.conv1 = conv_bn(3, input_channel, 1)\n\t        # building inverted residual blocks\n\t        self.blocks = nn.ModuleList([])\n\t        for t, c, n, s in self.interverted_residual_setting:\n\t            output_channel = int(c * width_mult)\n\t            layers = []\n\t            strides = [s] + [1] * (n - 1)\n\t            for stride in strides:\n", "                layers.append(InvertedResidual(input_channel, output_channel, stride, t))\n\t                input_channel = output_channel\n\t            self.blocks.append(nn.Sequential(*layers))\n\t        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n\t        self.conv2 = conv_1x1_bn(input_channel, self.last_channel)\n\t        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.classifier = nn.Linear(self.last_channel, feature_dim)\n\t        linear = nn.Linear(self.last_channel, 128, bias=True)\n\t        self.normalizer = Normalizer4CRD(linear, power=2)\n\t        self._initialize_weights()\n", "    def get_bn_before_relu(self):\n\t        bn1 = self.blocks[1][-1].conv[-1]\n\t        bn2 = self.blocks[2][-1].conv[-1]\n\t        bn3 = self.blocks[4][-1].conv[-1]\n\t        bn4 = self.blocks[6][-1].conv[-1]\n\t        return [bn1, bn2, bn3, bn4]\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.blocks)\n", "        return feat_m\n\t    def forward(self, x):\n\t        out = self.conv1(x)\n\t        out = self.blocks[0](out)\n\t        out = self.blocks[1](out)\n\t        out = self.blocks[2](out)\n\t        out = self.blocks[3](out)\n\t        out = self.blocks[4](out)\n\t        out = self.blocks[5](out)\n\t        out = self.blocks[6](out)\n", "        out = self.conv2(out)\n\t        out = self.avgpool(out)\n\t        f = out\n\t        out = out.view(out.size(0), -1)\n\t        out = self.classifier(out)\n\t        crdout = self.normalizer(f)\n\t        return crdout, out\n\t    def _initialize_weights(self):\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n", "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t                if m.bias is not None:\n\t                    m.bias.data.zero_()\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                n = m.weight.size(1)\n\t                m.weight.data.normal_(0, 0.01)\n", "                m.bias.data.zero_()\n\tdef mobilenetv2_T_w(T, W, feature_dim=100):\n\t    model = MobileNetV2(T=T, feature_dim=feature_dim, width_mult=W)\n\t    return model\n\tdef mobilenetV2(num_classes):\n\t    return mobilenetv2_T_w(6, 0.5, num_classes)\n\tdef mobilenetV2_aux(num_classes):\n\t    return MobileNetv2_Auxiliary(6, 0.5, num_classes)\n\tdef mobilenetV2_spkd(num_classes):\n\t    return MobileNetV2_SPKD(T=6, width_mult=0.5, feature_dim=num_classes)\n", "def mobilenetV2_crd(num_classes):\n\t    return MobileNetV2_CRD(T=6, width_mult=0.5, feature_dim=num_classes)\n"]}
{"filename": "models/SmallResolutionModel/resnet_imagenet.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\t__all__ = [\n\t    \"resnet18_imagenet\",\n\t    \"resnet18_imagenet_aux\",\n\t    \"resnet34_imagenet\",\n\t    \"resnet34_imagenet_aux\",\n\t    \"resnet50_imagenet\",\n\t    \"resnet50_imagenet_aux\",\n\t]\n", "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n\t    \"\"\"3x3 convolution with padding\"\"\"\n\t    return nn.Conv2d(\n\t        in_planes,\n\t        out_planes,\n\t        kernel_size=3,\n\t        stride=stride,\n\t        padding=dilation,\n\t        groups=groups,\n\t        bias=False,\n", "        dilation=dilation,\n\t    )\n\tdef conv1x1(in_planes, out_planes, stride=1):\n\t    \"\"\"1x1 convolution\"\"\"\n\t    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\tclass BasicBlock(nn.Module):\n\t    expansion = 1\n\t    def __init__(\n\t        self,\n\t        inplanes,\n", "        planes,\n\t        stride=1,\n\t        downsample=None,\n\t        groups=1,\n\t        base_width=64,\n\t        dilation=1,\n\t        norm_layer=None,\n\t    ):\n\t        super(BasicBlock, self).__init__()\n\t        if norm_layer is None:\n", "            norm_layer = nn.BatchNorm2d\n\t        if groups != 1 or base_width != 64:\n\t            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n\t        if dilation > 1:\n\t            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n\t        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n\t        self.conv1 = conv3x3(inplanes, planes, stride)\n\t        self.bn1 = norm_layer(planes)\n\t        self.relu = nn.ReLU(inplace=True)\n\t        self.conv2 = conv3x3(planes, planes)\n", "        self.bn2 = norm_layer(planes)\n\t        self.downsample = downsample\n\t        self.stride = stride\n\t    def forward(self, x):\n\t        identity = x\n\t        out = self.conv1(x)\n\t        out = self.bn1(out)\n\t        out = self.relu(out)\n\t        out = self.conv2(out)\n\t        out = self.bn2(out)\n", "        if self.downsample is not None:\n\t            identity = self.downsample(x)\n\t        out += identity\n\t        out = self.relu(out)\n\t        return out\n\tclass Bottleneck(nn.Module):\n\t    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n\t    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n\t    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n\t    # This variant is also known as ResNet V1.5 and improves accuracy according to\n", "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n\t    expansion = 4\n\t    def __init__(\n\t        self,\n\t        inplanes,\n\t        planes,\n\t        stride=1,\n\t        downsample=None,\n\t        groups=1,\n\t        base_width=64,\n", "        dilation=1,\n\t        norm_layer=None,\n\t    ):\n\t        super(Bottleneck, self).__init__()\n\t        if norm_layer is None:\n\t            norm_layer = nn.BatchNorm2d\n\t        width = int(planes * (base_width / 64.0)) * groups\n\t        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n\t        self.conv1 = conv1x1(inplanes, width)\n\t        self.bn1 = norm_layer(width)\n", "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n\t        self.bn2 = norm_layer(width)\n\t        self.conv3 = conv1x1(width, planes * self.expansion)\n\t        self.bn3 = norm_layer(planes * self.expansion)\n\t        self.relu = nn.ReLU(inplace=True)\n\t        self.downsample = downsample\n\t        self.stride = stride\n\t    def forward(self, x):\n\t        identity = x\n\t        out = self.conv1(x)\n", "        out = self.bn1(out)\n\t        out = self.relu(out)\n\t        out = self.conv2(out)\n\t        out = self.bn2(out)\n\t        out = self.relu(out)\n\t        out = self.conv3(out)\n\t        out = self.bn3(out)\n\t        if self.downsample is not None:\n\t            identity = self.downsample(x)\n\t        out += identity\n", "        out = self.relu(out)\n\t        return out\n\tclass ResNet(nn.Module):\n\t    def __init__(\n\t        self,\n\t        block,\n\t        layers,\n\t        num_classes=1000,\n\t        zero_init_residual=False,\n\t        groups=1,\n", "        width_per_group=64,\n\t        replace_stride_with_dilation=None,\n\t        norm_layer=None,\n\t    ):\n\t        super(ResNet, self).__init__()\n\t        if norm_layer is None:\n\t            norm_layer = nn.BatchNorm2d\n\t        self._norm_layer = norm_layer\n\t        self.inplanes = 64\n\t        self.dilation = 1\n", "        if replace_stride_with_dilation is None:\n\t            # each element in the tuple indicates if we should replace\n\t            # the 2x2 stride with a dilated convolution instead\n\t            replace_stride_with_dilation = [False, False, False]\n\t        if len(replace_stride_with_dilation) != 3:\n\t            raise ValueError(\n\t                \"replace_stride_with_dilation should be None \"\n\t                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n\t            )\n\t        self.groups = groups\n", "        self.base_width = width_per_group\n\t        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n\t        self.bn1 = norm_layer(self.inplanes)\n\t        self.relu = nn.ReLU(inplace=True)\n\t        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\t        self.layer1 = self._make_layer(block, 64, layers[0])\n\t        self.layer2 = self._make_layer(\n\t            block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]\n\t        )\n\t        self.layer3 = self._make_layer(\n", "            block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]\n\t        )\n\t        self.layer4 = self._make_layer(\n\t            block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]\n\t        )\n\t        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\t        self.last_channel = 512 * block.expansion\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n", "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n\t            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n\t                nn.init.constant_(m.weight, 1)\n\t                nn.init.constant_(m.bias, 0)\n\t        # Zero-initialize the last BN in each residual branch,\n\t        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n\t        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n\t        if zero_init_residual:\n\t            for m in self.modules():\n\t                if isinstance(m, Bottleneck):\n", "                    nn.init.constant_(m.bn3.weight, 0)\n\t                elif isinstance(m, BasicBlock):\n\t                    nn.init.constant_(m.bn2.weight, 0)\n\t    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n\t        norm_layer = self._norm_layer\n\t        downsample = None\n\t        previous_dilation = self.dilation\n\t        if dilate:\n\t            self.dilation *= stride\n\t            stride = 1\n", "        if stride != 1 or self.inplanes != planes * block.expansion:\n\t            downsample = nn.Sequential(\n\t                conv1x1(self.inplanes, planes * block.expansion, stride),\n\t                norm_layer(planes * block.expansion),\n\t            )\n\t        layers = []\n\t        layers.append(\n\t            block(\n\t                self.inplanes,\n\t                planes,\n", "                stride,\n\t                downsample,\n\t                self.groups,\n\t                self.base_width,\n\t                previous_dilation,\n\t                norm_layer,\n\t            )\n\t        )\n\t        self.inplanes = planes * block.expansion\n\t        for _ in range(1, blocks):\n", "            layers.append(\n\t                block(\n\t                    self.inplanes,\n\t                    planes,\n\t                    groups=self.groups,\n\t                    base_width=self.base_width,\n\t                    dilation=self.dilation,\n\t                    norm_layer=norm_layer,\n\t                )\n\t            )\n", "        return nn.Sequential(*layers)\n\t    def forward(self, x, is_feat=False):\n\t        # See note [TorchScript super()]\n\t        x = self.conv1(x)\n\t        x = self.bn1(x)\n\t        x = self.relu(x)\n\t        x = self.maxpool(x)\n\t        x = self.layer1(x)\n\t        f1 = x\n\t        x = self.layer2(x)\n", "        f2 = x\n\t        x = self.layer3(x)\n\t        f3 = x\n\t        x = self.layer4(x)\n\t        f4 = x\n\t        x = self.avgpool(x)\n\t        x = torch.flatten(x, 1)\n\t        x = self.fc(x)\n\t        if is_feat:\n\t            return [f1, f2, f3, f4], x\n", "        else:\n\t            return x\n\tclass Auxiliary_Classifier(nn.Module):\n\t    def __init__(\n\t        self,\n\t        block,\n\t        layers,\n\t        num_classes=1000,\n\t        zero_init_residual=False,\n\t        groups=1,\n", "        width_per_group=64,\n\t        replace_stride_with_dilation=None,\n\t        norm_layer=None,\n\t    ):\n\t        super(Auxiliary_Classifier, self).__init__()\n\t        self.dilation = 1\n\t        self.groups = groups\n\t        self.base_width = width_per_group\n\t        self.inplanes = 64 * block.expansion\n\t        self.block_extractor1 = nn.Sequential(\n", "            *[\n\t                self._make_layer(block, 128, layers[1], stride=2),\n\t                self._make_layer(block, 256, layers[2], stride=2),\n\t                self._make_layer(block, 512, layers[3], stride=2),\n\t            ]\n\t        )\n\t        self.inplanes = 128 * block.expansion\n\t        self.block_extractor2 = nn.Sequential(\n\t            *[\n\t                self._make_layer(block, 256, layers[2], stride=2),\n", "                self._make_layer(block, 512, layers[3], stride=2),\n\t            ]\n\t        )\n\t        self.inplanes = 256 * block.expansion\n\t        self.block_extractor3 = nn.Sequential(*[self._make_layer(block, 512, layers[3], stride=2)])\n\t        self.inplanes = 512 * block.expansion\n\t        self.block_extractor4 = nn.Sequential(*[self._make_layer(block, 512, layers[3], stride=1)])\n\t        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc1 = nn.Linear(512 * block.expansion, num_classes)\n\t        self.fc2 = nn.Linear(512 * block.expansion, num_classes)\n", "        self.fc3 = nn.Linear(512 * block.expansion, num_classes)\n\t        self.fc4 = nn.Linear(512 * block.expansion, num_classes)\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n\t            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n\t                nn.init.constant_(m.weight, 1)\n\t                nn.init.constant_(m.bias, 0)\n\t    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n\t        norm_layer = nn.BatchNorm2d\n", "        downsample = None\n\t        previous_dilation = self.dilation\n\t        if dilate:\n\t            self.dilation *= stride\n\t            stride = 1\n\t        if stride != 1 or self.inplanes != planes * block.expansion:\n\t            downsample = nn.Sequential(\n\t                conv1x1(self.inplanes, planes * block.expansion, stride),\n\t                norm_layer(planes * block.expansion),\n\t            )\n", "        layers = []\n\t        layers.append(\n\t            block(\n\t                self.inplanes,\n\t                planes,\n\t                stride,\n\t                downsample,\n\t                self.groups,\n\t                self.base_width,\n\t                previous_dilation,\n", "                norm_layer,\n\t            )\n\t        )\n\t        self.inplanes = planes * block.expansion\n\t        for _ in range(1, blocks):\n\t            layers.append(\n\t                block(\n\t                    self.inplanes,\n\t                    planes,\n\t                    groups=self.groups,\n", "                    base_width=self.base_width,\n\t                    dilation=self.dilation,\n\t                    norm_layer=norm_layer,\n\t                )\n\t            )\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        ss_logits = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n", "            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = self.avg_pool(out)\n\t            out = out.view(out.size(0), -1)\n\t            out = getattr(self, \"fc\" + str(idx))(out)\n\t            ss_logits.append(out)\n\t        return ss_logits\n\tclass ResNet_Auxiliary(nn.Module):\n\t    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n\t        super(ResNet_Auxiliary, self).__init__()\n\t        self.backbone = ResNet(\n", "            block, layers, num_classes=num_classes, zero_init_residual=zero_init_residual\n\t        )\n\t        self.auxiliary_classifier = Auxiliary_Classifier(\n\t            block, layers, num_classes=num_classes * 4, zero_init_residual=zero_init_residual\n\t        )\n\t    def forward(self, x, grad=False):\n\t        if grad is False:\n\t            feats, logit = self.backbone(x, is_feat=True)\n\t            for i in range(len(feats)):\n\t                feats[i] = feats[i].detach()\n", "        else:\n\t            feats, logit = self.backbone(x, is_feat=True)\n\t        ss_logits = self.auxiliary_classifier(feats)\n\t        return logit, ss_logits\n\tdef resnet18_imagenet(**kwargs):\n\t    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n\tdef resnet18_imagenet_aux(**kwargs):\n\t    return ResNet_Auxiliary(BasicBlock, [2, 2, 2, 2], **kwargs)\n\tdef resnet34_imagenet(**kwargs):\n\t    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n", "def resnet34_imagenet_aux(**kwargs):\n\t    return ResNet_Auxiliary(BasicBlock, [3, 4, 6, 3], **kwargs)\n\tdef resnet50_imagenet(**kwargs):\n\t    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n\tdef resnet50_imagenet_aux(**kwargs):\n\t    return ResNet_Auxiliary(Bottleneck, [3, 4, 6, 3], **kwargs)\n"]}
{"filename": "models/SmallResolutionModel/ShuffleNetv2.py", "chunked_list": ["\"\"\"ShuffleNetV2 in PyTorch.\n\tSee the paper \"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\" for more details.\n\tadding hyperparameter norm_layer: Huanran Chen\n\t\"\"\"\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\t__all__ = [\"ShuffleV2_aux\", \"ShuffleV2\"]\n\tclass ShuffleBlock(nn.Module):\n\t    def __init__(self, groups=2):\n", "        super(ShuffleBlock, self).__init__()\n\t        self.groups = groups\n\t    def forward(self, x):\n\t        \"\"\"Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]\"\"\"\n\t        N, C, H, W = x.size()\n\t        g = self.groups\n\t        return x.view(N, g, C // g, H, W).permute(0, 2, 1, 3, 4).reshape(N, C, H, W)\n\tclass SplitBlock(nn.Module):\n\t    def __init__(self, ratio):\n\t        super(SplitBlock, self).__init__()\n", "        self.ratio = ratio\n\t    def forward(self, x):\n\t        c = int(x.size(1) * self.ratio)\n\t        return x[:, :c, :, :], x[:, c:, :, :]\n\tclass BasicBlock(nn.Module):\n\t    def __init__(self, in_channels, split_ratio=0.5, is_last=False, norm_layer=nn.BatchNorm2d):\n\t        super(BasicBlock, self).__init__()\n\t        self.is_last = is_last\n\t        self.split = SplitBlock(split_ratio)\n\t        in_channels = int(in_channels * split_ratio)\n", "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n\t        self.bn1 = norm_layer(in_channels)\n\t        self.conv2 = nn.Conv2d(\n\t            in_channels,\n\t            in_channels,\n\t            kernel_size=3,\n\t            stride=1,\n\t            padding=1,\n\t            groups=in_channels,\n\t            bias=False,\n", "        )\n\t        self.bn2 = norm_layer(in_channels)\n\t        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n\t        self.bn3 = norm_layer(in_channels)\n\t        self.shuffle = ShuffleBlock()\n\t    def forward(self, x):\n\t        x1, x2 = self.split(x)\n\t        out = F.relu(self.bn1(self.conv1(x2)))\n\t        out = self.bn2(self.conv2(out))\n\t        preact = self.bn3(self.conv3(out))\n", "        out = F.relu(preact)\n\t        # out = F.relu(self.bn3(self.conv3(out)))\n\t        preact = torch.cat([x1, preact], 1)\n\t        out = torch.cat([x1, out], 1)\n\t        out = self.shuffle(out)\n\t        return out\n\tclass DownBlock(nn.Module):\n\t    def __init__(self, in_channels, out_channels, stride=2):\n\t        super(DownBlock, self).__init__()\n\t        mid_channels = out_channels // 2\n", "        # left\n\t        self.conv1 = nn.Conv2d(\n\t            in_channels,\n\t            in_channels,\n\t            kernel_size=3,\n\t            stride=stride,\n\t            padding=1,\n\t            groups=in_channels,\n\t            bias=False,\n\t        )\n", "        self.bn1 = nn.BatchNorm2d(in_channels)\n\t        self.conv2 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n\t        self.bn2 = nn.BatchNorm2d(mid_channels)\n\t        # right\n\t        self.conv3 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n\t        self.bn3 = nn.BatchNorm2d(mid_channels)\n\t        self.conv4 = nn.Conv2d(\n\t            mid_channels,\n\t            mid_channels,\n\t            kernel_size=3,\n", "            stride=stride,\n\t            padding=1,\n\t            groups=mid_channels,\n\t            bias=False,\n\t        )\n\t        self.bn4 = nn.BatchNorm2d(mid_channels)\n\t        self.conv5 = nn.Conv2d(mid_channels, mid_channels, kernel_size=1, bias=False)\n\t        self.bn5 = nn.BatchNorm2d(mid_channels)\n\t        self.shuffle = ShuffleBlock()\n\t    def forward(self, x):\n", "        # left\n\t        out1 = self.bn1(self.conv1(x))\n\t        out1 = F.relu(self.bn2(self.conv2(out1)))\n\t        # right\n\t        out2 = F.relu(self.bn3(self.conv3(x)))\n\t        out2 = self.bn4(self.conv4(out2))\n\t        out2 = F.relu(self.bn5(self.conv5(out2)))\n\t        # concat\n\t        out = torch.cat([out1, out2], 1)\n\t        out = self.shuffle(out)\n", "        return out\n\tclass ShuffleNetV2(nn.Module):\n\t    def __init__(self, net_size, num_classes=100, norm_layer=nn.BatchNorm2d):\n\t        super(ShuffleNetV2, self).__init__()\n\t        out_channels = configs[net_size][\"out_channels\"]\n\t        num_blocks = configs[net_size][\"num_blocks\"]\n\t        # self.conv1 = nn.Conv2d(3, 24, kernel_size=3,\n\t        #                        stride=1, padding=1, bias=False)\n\t        self.conv1 = nn.Conv2d(3, 24, kernel_size=1, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(24)\n", "        self.in_channels = 24\n\t        self.layer1 = self._make_layer(out_channels[0], num_blocks[0], norm_layer)\n\t        self.layer2 = self._make_layer(out_channels[1], num_blocks[1], norm_layer)\n\t        self.layer3 = self._make_layer(out_channels[2], num_blocks[2], norm_layer)\n\t        self.conv2 = nn.Conv2d(\n\t            out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n\t        )\n\t        self.bn2 = nn.BatchNorm2d(out_channels[3])\n\t        self.linear = nn.Linear(out_channels[3], num_classes)\n\t        self.last_channel = out_channels[3]\n", "    def _make_layer(self, out_channels, num_blocks, norm_layer=nn.BatchNorm2d):\n\t        layers = [DownBlock(self.in_channels, out_channels)]\n\t        for i in range(num_blocks):\n\t            layers.append(BasicBlock(out_channels, is_last=(i == num_blocks - 1), norm_layer=norm_layer))\n\t            self.in_channels = out_channels\n\t        return nn.Sequential(*layers)\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.bn1)\n", "        feat_m.append(self.layer1)\n\t        feat_m.append(self.layer2)\n\t        feat_m.append(self.layer3)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        raise NotImplementedError('ShuffleNetV2 currently is not supported for \"Overhaul\" teacher2')\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        out = F.relu(self.bn1(self.conv1(x)))\n\t        # out = F.max_pool2d(out, 3, stride=2, padding=1)\n\t        out = self.layer1(out)\n", "        f1 = out\n\t        out = self.layer2(out)\n\t        f2 = out\n\t        out = self.layer3(out)\n\t        f3 = out\n\t        out = F.relu(self.bn2(self.conv2(out)))\n\t        f4 = out\n\t        out = F.avg_pool2d(out, 4)\n\t        out = out.view(out.size(0), -1)\n\t        out = self.linear(out)\n", "        if is_feat:\n\t            return [f1, f2, f3, f4], out\n\t        else:\n\t            return out\n\tclass Auxiliary_Classifier(nn.Module):\n\t    def __init__(self, net_size, num_classes=100, norm_layer=nn.BatchNorm2d):\n\t        super(Auxiliary_Classifier, self).__init__()\n\t        out_channels = configs[net_size][\"out_channels\"]\n\t        num_blocks = configs[net_size][\"num_blocks\"]\n\t        self.in_channels = out_channels[0]\n", "        self.block_extractor1 = nn.Sequential(\n\t            *[\n\t                self._make_layer(out_channels[1], num_blocks[1]),\n\t                self._make_layer(out_channels[2], num_blocks[2]),\n\t                nn.Conv2d(\n\t                    out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n\t                ),\n\t                nn.BatchNorm2d(out_channels[3]),\n\t                nn.ReLU(inplace=True),\n\t            ]\n", "        )\n\t        self.in_channels = out_channels[1]\n\t        self.block_extractor2 = nn.Sequential(\n\t            *[\n\t                self._make_layer(out_channels[2], num_blocks[2]),\n\t                nn.Conv2d(\n\t                    out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n\t                ),\n\t                nn.BatchNorm2d(out_channels[3]),\n\t                nn.ReLU(inplace=True),\n", "            ]\n\t        )\n\t        self.in_channels = out_channels[2]\n\t        self.block_extractor3 = nn.Sequential(\n\t            *[\n\t                self._make_layer(out_channels[2], num_blocks[2], stride=1),\n\t                nn.Conv2d(\n\t                    out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n\t                ),\n\t                nn.BatchNorm2d(out_channels[3]),\n", "                nn.ReLU(inplace=True),\n\t            ]\n\t        )\n\t        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc1 = nn.Linear(out_channels[3], num_classes)\n\t        self.fc2 = nn.Linear(out_channels[3], num_classes)\n\t        self.fc3 = nn.Linear(out_channels[3], num_classes)\n\t    def _make_layer(self, out_channels, num_blocks, stride=2):\n\t        layers = [DownBlock(self.in_channels, out_channels, stride=stride)]\n\t        for i in range(num_blocks):\n", "            layers.append(BasicBlock(out_channels, is_last=(i == num_blocks - 1)))\n\t            self.in_channels = out_channels\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        ss_logits = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n\t            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = self.avg_pool(out)\n\t            out = out.view(out.size(0), -1)\n", "            out = getattr(self, \"fc\" + str(idx))(out)\n\t            ss_logits.append(out)\n\t        return ss_logits\n\tclass ShuffleNetV2_Auxiliary(nn.Module):\n\t    def __init__(self, net_size, num_classes=100):\n\t        super(ShuffleNetV2_Auxiliary, self).__init__()\n\t        self.backbone = ShuffleNetV2(net_size, num_classes=num_classes)\n\t        self.auxiliary_classifier = Auxiliary_Classifier(net_size, num_classes=num_classes * 4)\n\t    def forward(self, x, grad=False):\n\t        feats, logit = self.backbone(x, is_feat=True)\n", "        if grad is False:\n\t            for i in range(len(feats)):\n\t                feats[i] = feats[i].detach()\n\t        ss_logits = self.auxiliary_classifier(feats)\n\t        return logit, ss_logits\n\tconfigs = {\n\t    0.2: {\"out_channels\": (40, 80, 160, 512), \"num_blocks\": (3, 3, 3)},\n\t    0.3: {\"out_channels\": (40, 80, 160, 512), \"num_blocks\": (3, 7, 3)},\n\t    0.5: {\"out_channels\": (48, 96, 192, 1024), \"num_blocks\": (3, 7, 3)},\n\t    1: {\"out_channels\": (116, 232, 464, 1024), \"num_blocks\": (3, 7, 3)},\n", "    1.5: {\"out_channels\": (176, 352, 704, 1024), \"num_blocks\": (3, 7, 3)},\n\t    2: {\"out_channels\": (224, 488, 976, 2048), \"num_blocks\": (3, 7, 3)},\n\t}\n\tdef ShuffleV2(**kwargs):\n\t    model = ShuffleNetV2(net_size=1, **kwargs)\n\t    return model\n\tdef ShuffleV2_aux(**kwargs):\n\t    model = ShuffleNetV2_Auxiliary(net_size=1, **kwargs)\n\t    return model\n"]}
{"filename": "models/SmallResolutionModel/__init__.py", "chunked_list": ["from .mobilenetv2 import *\n\tfrom .resnet import *\n\tfrom .resnet_imagenet import *\n\tfrom .resnetv2 import *\n\tfrom .ShuffleNetv1 import *\n\tfrom .ShuffleNetv2 import *\n\tfrom .vgg import *\n\tfrom .wrn import *\n\tfrom .cifar10_resnet import WideResNet_70_16, WideResNet_70_16_dropout\n\tfrom .jem_wideresnet import Wide_ResNet\n", "from .igebm import IGEBM"]}
{"filename": "models/SmallResolutionModel/resnetv2.py", "chunked_list": ["\"\"\"ResNet in PyTorch.\n\tFor Pre-activation ResNet, see 'preact_resnet.py'.\n\tReference:\n\t[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n\t    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n\t\"\"\"\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\t__all__ = [\"ResNet50_aux\"]\n", "class BasicBlock(nn.Module):\n\t    expansion = 1\n\t    def __init__(self, in_planes, planes, stride=1, is_last=False):\n\t        super(BasicBlock, self).__init__()\n\t        self.is_last = is_last\n\t        self.conv1 = nn.Conv2d(\n\t            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n\t        )\n\t        self.bn1 = nn.BatchNorm2d(planes)\n\t        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n", "        self.bn2 = nn.BatchNorm2d(planes)\n\t        self.shortcut = nn.Sequential()\n\t        if stride != 1 or in_planes != self.expansion * planes:\n\t            self.shortcut = nn.Sequential(\n\t                nn.Conv2d(\n\t                    in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False\n\t                ),\n\t                nn.BatchNorm2d(self.expansion * planes),\n\t            )\n\t    def forward(self, x):\n", "        out = F.relu(self.bn1(self.conv1(x)))\n\t        out = self.bn2(self.conv2(out))\n\t        out += self.shortcut(x)\n\t        preact = out\n\t        out = F.relu(out)\n\t        if self.is_last:\n\t            return out, preact\n\t        else:\n\t            return out\n\tclass Bottleneck(nn.Module):\n", "    expansion = 4\n\t    def __init__(self, in_planes, planes, stride=1, is_last=False):\n\t        super(Bottleneck, self).__init__()\n\t        self.is_last = is_last\n\t        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(planes)\n\t        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\t        self.bn2 = nn.BatchNorm2d(planes)\n\t        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n\t        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n", "        self.shortcut = nn.Sequential()\n\t        if stride != 1 or in_planes != self.expansion * planes:\n\t            self.shortcut = nn.Sequential(\n\t                nn.Conv2d(\n\t                    in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False\n\t                ),\n\t                nn.BatchNorm2d(self.expansion * planes),\n\t            )\n\t    def forward(self, x):\n\t        out = F.relu(self.bn1(self.conv1(x)))\n", "        out = F.relu(self.bn2(self.conv2(out)))\n\t        out = self.bn3(self.conv3(out))\n\t        out += self.shortcut(x)\n\t        out = F.relu(out)\n\t        return out\n\tclass ResNet(nn.Module):\n\t    def __init__(self, block, num_blocks, num_classes=10, zero_init_residual=False):\n\t        super(ResNet, self).__init__()\n\t        self.in_planes = 64\n\t        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n", "        self.bn1 = nn.BatchNorm2d(64)\n\t        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n\t        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n\t        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n\t        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n\t        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.linear = nn.Linear(512 * block.expansion, num_classes)\n\t        self.last_channel = 512 * block.expansion\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n", "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n\t            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n\t                nn.init.constant_(m.weight, 1)\n\t                nn.init.constant_(m.bias, 0)\n\t        # Zero-initialize the last BN in each residual branch,\n\t        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n\t        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n\t        if zero_init_residual:\n\t            for m in self.modules():\n\t                if isinstance(m, Bottleneck):\n", "                    nn.init.constant_(m.bn3.weight, 0)\n\t                elif isinstance(m, BasicBlock):\n\t                    nn.init.constant_(m.bn2.weight, 0)\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.bn1)\n\t        feat_m.append(self.layer1)\n\t        feat_m.append(self.layer2)\n\t        feat_m.append(self.layer3)\n", "        feat_m.append(self.layer4)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        if isinstance(self.layer1[0], Bottleneck):\n\t            bn1 = self.layer1[-1].bn3\n\t            bn2 = self.layer2[-1].bn3\n\t            bn3 = self.layer3[-1].bn3\n\t            bn4 = self.layer4[-1].bn3\n\t        elif isinstance(self.layer1[0], BasicBlock):\n\t            bn1 = self.layer1[-1].bn2\n", "            bn2 = self.layer2[-1].bn2\n\t            bn3 = self.layer3[-1].bn2\n\t            bn4 = self.layer4[-1].bn2\n\t        else:\n\t            raise NotImplementedError(\"ResNet unknown block error !!!\")\n\t        return [bn1, bn2, bn3, bn4]\n\t    def _make_layer(self, block, planes, num_blocks, stride):\n\t        strides = [stride] + [1] * (num_blocks - 1)\n\t        layers = []\n\t        for i in range(num_blocks):\n", "            stride = strides[i]\n\t            layers.append(block(self.in_planes, planes, stride, i == num_blocks - 1))\n\t            self.in_planes = planes * block.expansion\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        out = F.relu(self.bn1(self.conv1(x)))\n\t        out = self.layer1(out)\n\t        f1 = out\n\t        out = self.layer2(out)\n\t        f2 = out\n", "        out = self.layer3(out)\n\t        f3 = out\n\t        out = self.layer4(out)\n\t        f4 = out\n\t        out = self.avgpool(out)\n\t        out = out.view(out.size(0), -1)\n\t        out = self.linear(out)\n\t        if is_feat:\n\t            return [f1, f2, f3, f4], out\n\t        else:\n", "            return out\n\tclass Auxiliary_Classifier(nn.Module):\n\t    def __init__(self, block, num_blocks, num_classes=10, zero_init_residual=False):\n\t        super(Auxiliary_Classifier, self).__init__()\n\t        self.in_planes = 64 * block.expansion\n\t        self.block_extractor1 = nn.Sequential(\n\t            *[\n\t                self._make_layer(block, 128, num_blocks[1], stride=2),\n\t                self._make_layer(block, 256, num_blocks[2], stride=2),\n\t                self._make_layer(block, 512, num_blocks[3], stride=2),\n", "            ]\n\t        )\n\t        self.in_planes = 128 * block.expansion\n\t        self.block_extractor2 = nn.Sequential(\n\t            *[\n\t                self._make_layer(block, 256, num_blocks[2], stride=2),\n\t                self._make_layer(block, 512, num_blocks[3], stride=2),\n\t            ]\n\t        )\n\t        self.in_planes = 256 * block.expansion\n", "        self.block_extractor3 = nn.Sequential(\n\t            *[self._make_layer(block, 512, num_blocks[3], stride=2)]\n\t        )\n\t        self.in_planes = 512 * block.expansion\n\t        self.block_extractor4 = nn.Sequential(\n\t            *[self._make_layer(block, 512, num_blocks[3], stride=1)]\n\t        )\n\t        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc1 = nn.Linear(512 * block.expansion, num_classes)\n\t        self.fc2 = nn.Linear(512 * block.expansion, num_classes)\n", "        self.fc3 = nn.Linear(512 * block.expansion, num_classes)\n\t        self.fc4 = nn.Linear(512 * block.expansion, num_classes)\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n\t            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n\t                nn.init.constant_(m.weight, 1)\n\t                nn.init.constant_(m.bias, 0)\n\t    def _make_layer(self, block, planes, num_blocks, stride):\n\t        strides = [stride] + [1] * (num_blocks - 1)\n", "        layers = []\n\t        for i in range(num_blocks):\n\t            stride = strides[i]\n\t            layers.append(block(self.in_planes, planes, stride, i == num_blocks - 1))\n\t            self.in_planes = planes * block.expansion\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        ss_logits = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n", "            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = self.avg_pool(out)\n\t            out = out.view(out.size(0), -1)\n\t            out = getattr(self, \"fc\" + str(idx))(out)\n\t            ss_logits.append(out)\n\t        return ss_logits\n\tclass ResNet_Auxiliary(nn.Module):\n\t    def __init__(self, block, num_blocks, num_classes=10, zero_init_residual=False):\n\t        super(ResNet_Auxiliary, self).__init__()\n\t        self.backbone = ResNet(\n", "            block, num_blocks, num_classes=num_classes, zero_init_residual=zero_init_residual\n\t        )\n\t        self.auxiliary_classifier = Auxiliary_Classifier(\n\t            block, num_blocks, num_classes=num_classes * 4, zero_init_residual=zero_init_residual\n\t        )\n\t    def forward(self, x, grad=False):\n\t        if grad is False:\n\t            feats, logit = self.backbone(x, is_feat=True)\n\t            for i in range(len(feats)):\n\t                feats[i] = feats[i].detach()\n", "        else:\n\t            feats, logit = self.backbone(x, is_feat=True)\n\t        ss_logits = self.auxiliary_classifier(feats)\n\t        return logit, ss_logits\n\tdef ResNet18(**kwargs):\n\t    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n\tdef ResNet34(**kwargs):\n\t    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n\tdef ResNet50(**kwargs):\n\t    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n", "def ResNet50_aux(**kwargs):\n\t    return ResNet_Auxiliary(Bottleneck, [3, 4, 6, 3], **kwargs)\n\tdef ResNet101(**kwargs):\n\t    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n\tdef ResNet152(**kwargs):\n\t    return ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n"]}
{"filename": "models/SmallResolutionModel/utils.py", "chunked_list": ["from __future__ import print_function\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.init as init\n\tdef cal_param_size(model):\n\t    return sum([i.numel() for i in model.parameters()])\n\tcount_ops = 0\n\tdef measure_layer(layer, x, multi_add=1):\n\t    delta_ops = 0\n\t    type_name = str(layer)[: str(layer).find(\"(\")].strip()\n", "    if type_name in [\"Conv2d\"]:\n\t        out_h = int(\n\t            (x.size()[2] + 2 * layer.padding[0] - layer.kernel_size[0]) // layer.stride[0] + 1\n\t        )\n\t        out_w = int(\n\t            (x.size()[3] + 2 * layer.padding[1] - layer.kernel_size[1]) // layer.stride[1] + 1\n\t        )\n\t        delta_ops = (\n\t            layer.in_channels\n\t            * layer.out_channels\n", "            * layer.kernel_size[0]\n\t            * layer.kernel_size[1]\n\t            * out_h\n\t            * out_w\n\t            // layer.groups\n\t            * multi_add\n\t        )\n\t    ### ops_linear\n\t    elif type_name in [\"Linear\"]:\n\t        weight_ops = layer.weight.numel() * multi_add\n", "        bias_ops = 0\n\t        delta_ops = weight_ops + bias_ops\n\t    global count_ops\n\t    count_ops += delta_ops\n\t    return\n\tdef is_leaf(module):\n\t    return sum(1 for x in module.children()) == 0\n\tdef should_measure(module):\n\t    if str(module).startswith(\"Sequential\"):\n\t        return False\n", "    if is_leaf(module):\n\t        return True\n\t    return False\n\tdef cal_multi_adds(model, shape=(2, 3, 32, 32)):\n\t    global count_ops\n\t    count_ops = 0\n\t    data = torch.zeros(shape)\n\t    def new_forward(m):\n\t        def lambda_forward(x):\n\t            measure_layer(m, x)\n", "            return m.old_forward(x)\n\t        return lambda_forward\n\t    def modify_forward(model):\n\t        for child in model.children():\n\t            if should_measure(child):\n\t                child.old_forward = child.forward\n\t                child.forward = new_forward(child)\n\t            else:\n\t                modify_forward(child)\n\t    def restore_forward(model):\n", "        for child in model.children():\n\t            if is_leaf(child) and hasattr(child, \"old_forward\"):\n\t                child.forward = child.old_forward\n\t                child.old_forward = None\n\t            else:\n\t                restore_forward(child)\n\t    modify_forward(model)\n\t    model.forward(data)\n\t    restore_forward(model)\n\t    return count_ops\n"]}
{"filename": "models/SmallResolutionModel/vgg.py", "chunked_list": ["\"\"\"VGG for CIFAR10. FC layers are removed.\n\t(c) YANG, Wei\n\tadding hyperparameter norm_layer: Huanran Chen\n\t\"\"\"\n\timport math\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\t__all__ = [\"vgg13_bn_aux\", \"vgg13_bn\", \"vgg13_bn_spkd\", \"vgg13_bn_crd\", \"vgg8_bn\"]\n\tmodel_urls = {\n\t    \"vgg11\": \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\",\n", "    \"vgg13\": \"https://download.pytorch.org/models/vgg13-c768596a.pth\",\n\t    \"vgg16\": \"https://download.pytorch.org/models/vgg16-397923af.pth\",\n\t    \"vgg19\": \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\",\n\t}\n\tclass Normalizer4CRD(nn.Module):\n\t    def __init__(self, linear, power=2):\n\t        super().__init__()\n\t        self.linear = linear\n\t        self.power = power\n\t    def forward(self, x):\n", "        x = x.flatten(1)\n\t        z = self.linear(x)\n\t        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n\t        out = z.div(norm)\n\t        return out\n\tclass VGG(nn.Module):\n\t    def __init__(self, cfg, batch_norm=False, num_classes=1000,\n\t                 norm_layer=nn.BatchNorm2d):\n\t        super(VGG, self).__init__()\n\t        self.block0 = self._make_layers(cfg[0], batch_norm, 3, norm_layer)\n", "        self.block1 = self._make_layers(cfg[1], batch_norm, cfg[0][-1], norm_layer)\n\t        self.block2 = self._make_layers(cfg[2], batch_norm, cfg[1][-1], norm_layer)\n\t        self.block3 = self._make_layers(cfg[3], batch_norm, cfg[2][-1], norm_layer)\n\t        self.block4 = self._make_layers(cfg[4], batch_norm, cfg[3][-1], norm_layer)\n\t        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))\n\t        # self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n", "        self.last_channel = 512\n\t        self.classifier = nn.Linear(512, num_classes)\n\t        self._initialize_weights()\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.block0)\n\t        feat_m.append(self.pool0)\n\t        feat_m.append(self.block1)\n\t        feat_m.append(self.pool1)\n\t        feat_m.append(self.block2)\n", "        feat_m.append(self.pool2)\n\t        feat_m.append(self.block3)\n\t        feat_m.append(self.pool3)\n\t        feat_m.append(self.block4)\n\t        feat_m.append(self.pool4)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        bn1 = self.block1[-1]\n\t        bn2 = self.block2[-1]\n\t        bn3 = self.block3[-1]\n", "        bn4 = self.block4[-1]\n\t        return [bn1, bn2, bn3, bn4]\n\t    def forward(self, x, is_feat=False, preact=False):\n\t        h = x.shape[2]\n\t        x = F.relu(self.block0(x))\n\t        f0 = x\n\t        x = self.pool0(x)\n\t        x = self.block1(x)\n\t        x = F.relu(x)\n\t        f1 = x\n", "        x = self.pool1(x)\n\t        x = self.block2(x)\n\t        x = F.relu(x)\n\t        f2 = x\n\t        x = self.pool2(x)\n\t        x = self.block3(x)\n\t        x = F.relu(x)\n\t        if h == 64:\n\t            x = self.pool3(x)\n\t        x = self.block4(x)\n", "        x = F.relu(x)\n\t        f3 = x\n\t        x = self.pool4(x)\n\t        x = x.view(x.size(0), -1)\n\t        x = self.classifier(x)\n\t        if is_feat:\n\t            return [f0, f1, f2, f3], x\n\t        else:\n\t            return x\n\t    @staticmethod\n", "    def _make_layers(cfg, batch_norm=False, in_channels=3, norm_layer=nn.BatchNorm2d):\n\t        layers = []\n\t        for v in cfg:\n\t            if v == \"M\":\n\t                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n\t            else:\n\t                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n\t                if batch_norm:\n\t                    layers += [conv2d, norm_layer(v), nn.ReLU(inplace=True)]\n\t                else:\n", "                    layers += [conv2d, nn.ReLU(inplace=True)]\n\t                in_channels = v\n\t        layers = layers[:-1]\n\t        return nn.Sequential(*layers)\n\t    def _initialize_weights(self):\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t                if m.bias is not None:\n", "                    m.bias.data.zero_()\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                n = m.weight.size(1)\n\t                m.weight.data.normal_(0, 0.01)\n\t                m.bias.data.zero_()\n\tclass Auxiliary_Classifier(nn.Module):\n\t    def __init__(self, cfg, batch_norm=False, num_classes=100):\n", "        super(Auxiliary_Classifier, self).__init__()\n\t        self.block_extractor1 = nn.Sequential(\n\t            *[\n\t                nn.MaxPool2d(kernel_size=2, stride=2),\n\t                self._make_layers(cfg[1], batch_norm, cfg[0][-1]),\n\t                nn.ReLU(inplace=True),\n\t                nn.MaxPool2d(kernel_size=2, stride=2),\n\t                self._make_layers(cfg[2], batch_norm, cfg[1][-1]),\n\t                nn.ReLU(inplace=True),\n\t                nn.MaxPool2d(kernel_size=2, stride=2),\n", "                self._make_layers(cfg[3], batch_norm, cfg[2][-1]),\n\t                nn.ReLU(inplace=True),\n\t                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n\t                nn.ReLU(inplace=True),\n\t                nn.AdaptiveAvgPool2d((1, 1)),\n\t            ]\n\t        )\n\t        self.block_extractor2 = nn.Sequential(\n\t            *[\n\t                nn.MaxPool2d(kernel_size=2, stride=2),\n", "                self._make_layers(cfg[2], batch_norm, cfg[1][-1]),\n\t                nn.ReLU(inplace=True),\n\t                nn.MaxPool2d(kernel_size=2, stride=2),\n\t                self._make_layers(cfg[3], batch_norm, cfg[2][-1]),\n\t                nn.ReLU(inplace=True),\n\t                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n\t                nn.ReLU(inplace=True),\n\t                nn.AdaptiveAvgPool2d((1, 1)),\n\t            ]\n\t        )\n", "        self.block_extractor3 = nn.Sequential(\n\t            *[\n\t                nn.MaxPool2d(kernel_size=2, stride=2),\n\t                self._make_layers(cfg[3], batch_norm, cfg[2][-1]),\n\t                nn.ReLU(inplace=True),\n\t                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n\t                nn.ReLU(inplace=True),\n\t                nn.AdaptiveAvgPool2d((1, 1)),\n\t            ]\n\t        )\n", "        self.block_extractor4 = nn.Sequential(\n\t            *[\n\t                self._make_layers(cfg[3], batch_norm, cfg[4][-1]),\n\t                nn.ReLU(inplace=True),\n\t                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n\t                nn.ReLU(inplace=True),\n\t                nn.AdaptiveAvgPool2d((1, 1)),\n\t            ]\n\t        )\n\t        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n", "        self.fc1 = nn.Linear(512, num_classes)\n\t        self.fc2 = nn.Linear(512, num_classes)\n\t        self.fc3 = nn.Linear(512, num_classes)\n\t        self.fc4 = nn.Linear(512, num_classes)\n\t        def _initialize_weights(self):\n\t            for m in self.modules():\n\t                if isinstance(m, nn.Conv2d):\n\t                    n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                    m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t                    if m.bias is not None:\n", "                        m.bias.data.zero_()\n\t                elif isinstance(m, nn.BatchNorm2d):\n\t                    m.weight.data.fill_(1)\n\t                    m.bias.data.zero_()\n\t                elif isinstance(m, nn.Linear):\n\t                    n = m.weight.size(1)\n\t                    m.weight.data.normal_(0, 0.01)\n\t                    m.bias.data.zero_()\n\t    @staticmethod\n\t    def _make_layers(cfg, batch_norm=False, in_channels=3):\n", "        layers = []\n\t        for v in cfg:\n\t            if v == \"M\":\n\t                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n\t            else:\n\t                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n\t                if batch_norm:\n\t                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n\t                else:\n\t                    layers += [conv2d, nn.ReLU(inplace=True)]\n", "                in_channels = v\n\t        layers = layers[:-1]\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        ss_logits = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n\t            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = out.view(-1, 512)\n\t            out = getattr(self, \"fc\" + str(idx))(out)\n", "            ss_logits.append(out)\n\t        return ss_logits\n\tclass VGG_Auxiliary(nn.Module):\n\t    def __init__(self, cfg, batch_norm=False, num_classes=100):\n\t        super(VGG_Auxiliary, self).__init__()\n\t        self.backbone = VGG(cfg, batch_norm=batch_norm, num_classes=num_classes)\n\t        self.auxiliary_classifier = Auxiliary_Classifier(\n\t            cfg, batch_norm=batch_norm, num_classes=num_classes * 4\n\t        )\n\t    def forward(self, x, grad=False):\n", "        feats, logit = self.backbone(x, is_feat=True)\n\t        if grad is False:\n\t            for i in range(len(feats)):\n\t                feats[i] = feats[i].detach()\n\t        ss_logits = self.auxiliary_classifier(feats)\n\t        return logit, ss_logits\n\tclass VGG_SPKD(VGG):\n\t    def __init__(self, cfg, batch_norm=False, num_classes=1000):\n\t        super(VGG_SPKD, self).__init__(cfg, batch_norm, num_classes)\n\t    def forward(self, x):\n", "        h = x.shape[2]\n\t        x = F.relu(self.block0(x))\n\t        x = self.pool0(x)\n\t        x = self.block1(x)\n\t        x = F.relu(x)\n\t        x = self.pool1(x)\n\t        x = self.block2(x)\n\t        x = F.relu(x)\n\t        x = self.pool2(x)\n\t        x = self.block3(x)\n", "        x = F.relu(x)\n\t        if h == 64:\n\t            x = self.pool3(x)\n\t        x = self.block4(x)\n\t        x = F.relu(x)\n\t        f3 = x\n\t        x = self.pool4(x)\n\t        x = x.view(x.size(0), -1)\n\t        x = self.classifier(x)\n\t        return f3, x\n", "cfg = {\n\t    \"A\": [[64], [128], [256, 256], [512, 512], [512, 512]],\n\t    \"B\": [[64, 64], [128, 128], [256, 256], [512, 512], [512, 512]],\n\t    \"D\": [[64, 64], [128, 128], [256, 256, 256], [512, 512, 512], [512, 512, 512]],\n\t    \"E\": [[64, 64], [128, 128], [256, 256, 256, 256], [512, 512, 512, 512], [512, 512, 512, 512]],\n\t    \"S\": [[64], [128], [256], [512], [512]],\n\t}\n\tclass VGG_CRD(nn.Module):\n\t    def __init__(self, cfg, batch_norm=False, num_classes=1000):\n\t        super(VGG_CRD, self).__init__()\n", "        self.block0 = self._make_layers(cfg[0], batch_norm, 3)\n\t        self.block1 = self._make_layers(cfg[1], batch_norm, cfg[0][-1])\n\t        self.block2 = self._make_layers(cfg[2], batch_norm, cfg[1][-1])\n\t        self.block3 = self._make_layers(cfg[3], batch_norm, cfg[2][-1])\n\t        self.block4 = self._make_layers(cfg[4], batch_norm, cfg[3][-1])\n\t        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))\n", "        # self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\t        self.classifier = nn.Linear(512, num_classes)\n\t        linear = nn.Linear(512, 128, bias=True)\n\t        self.normalizer = Normalizer4CRD(linear, power=2)\n\t        self._initialize_weights()\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.block0)\n\t        feat_m.append(self.pool0)\n\t        feat_m.append(self.block1)\n", "        feat_m.append(self.pool1)\n\t        feat_m.append(self.block2)\n\t        feat_m.append(self.pool2)\n\t        feat_m.append(self.block3)\n\t        feat_m.append(self.pool3)\n\t        feat_m.append(self.block4)\n\t        feat_m.append(self.pool4)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        bn1 = self.block1[-1]\n", "        bn2 = self.block2[-1]\n\t        bn3 = self.block3[-1]\n\t        bn4 = self.block4[-1]\n\t        return [bn1, bn2, bn3, bn4]\n\t    def forward(self, x):\n\t        h = x.shape[2]\n\t        x = F.relu(self.block0(x))\n\t        x = self.pool0(x)\n\t        x = self.block1(x)\n\t        x = F.relu(x)\n", "        x = self.pool1(x)\n\t        x = self.block2(x)\n\t        x = F.relu(x)\n\t        x = self.pool2(x)\n\t        x = self.block3(x)\n\t        x = F.relu(x)\n\t        if h == 64:\n\t            x = self.pool3(x)\n\t        x = self.block4(x)\n\t        x = F.relu(x)\n", "        x = self.pool4(x)\n\t        crdout = x\n\t        x = x.view(x.size(0), -1)\n\t        x = self.classifier(x)\n\t        crdout = self.normalizer(crdout)\n\t        return crdout, x\n\t    @staticmethod\n\t    def _make_layers(cfg, batch_norm=False, in_channels=3):\n\t        layers = []\n\t        for v in cfg:\n", "            if v == \"M\":\n\t                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n\t            else:\n\t                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n\t                if batch_norm:\n\t                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n\t                else:\n\t                    layers += [conv2d, nn.ReLU(inplace=True)]\n\t                in_channels = v\n\t        layers = layers[:-1]\n", "        return nn.Sequential(*layers)\n\t    def _initialize_weights(self):\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t                if m.bias is not None:\n\t                    m.bias.data.zero_()\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n", "                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                n = m.weight.size(1)\n\t                m.weight.data.normal_(0, 0.01)\n\t                m.bias.data.zero_()\n\tdef vgg8(**kwargs):\n\t    \"\"\"VGG 8-layer model (configuration \"S\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n", "    model = VGG(cfg[\"S\"], **kwargs)\n\t    return model\n\tdef vgg8_bn(**kwargs):\n\t    \"\"\"VGG 8-layer model (configuration \"S\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n\t    model = VGG(cfg[\"S\"], batch_norm=True, **kwargs)\n\t    return model\n\tdef vgg8_bn_aux(**kwargs):\n", "    \"\"\"VGG 8-layer model (configuration \"S\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n\t    model = VGG_Auxiliary(cfg[\"S\"], batch_norm=True, **kwargs)\n\t    return model\n\tdef vgg8_bn_spkd(**kwargs):\n\t    \"\"\"VGG 8-layer model (configuration \"S\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n", "    \"\"\"\n\t    model = VGG_SPKD(cfg[\"S\"], batch_norm=True, **kwargs)\n\t    return model\n\tdef vgg8_bn_crd(**kwargs):\n\t    \"\"\"VGG 8-layer model (configuration \"S\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n\t    model = VGG_CRD(cfg[\"S\"], batch_norm=True, **kwargs)\n\t    return model\n", "def vgg11(**kwargs):\n\t    \"\"\"VGG 11-layer model (configuration \"A\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n\t    model = VGG(cfg[\"A\"], **kwargs)\n\t    return model\n\tdef vgg11_bn(**kwargs):\n\t    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n\t    model = VGG(cfg[\"A\"], batch_norm=True, **kwargs)\n", "    return model\n\tdef vgg13(**kwargs):\n\t    \"\"\"VGG 13-layer model (configuration \"B\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n\t    model = VGG(cfg[\"B\"], **kwargs)\n\t    return model\n\tdef vgg13_bn(**kwargs):\n\t    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n", "    model = VGG(cfg[\"B\"], batch_norm=True, **kwargs)\n\t    return model\n\tdef vgg13_bn_aux(**kwargs):\n\t    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n\t    model = VGG_Auxiliary(cfg[\"B\"], batch_norm=True, **kwargs)\n\t    return model\n\tdef vgg13_bn_spkd(**kwargs):\n\t    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n\t    model = VGG_SPKD(cfg[\"B\"], batch_norm=True, **kwargs)\n\t    return model\n", "def vgg13_bn_crd(**kwargs):\n\t    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n\t    model = VGG_CRD(cfg[\"B\"], batch_norm=True, **kwargs)\n\t    return model\n\tdef vgg16(**kwargs):\n\t    \"\"\"VGG 16-layer model (configuration \"D\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n\t    model = VGG(cfg[\"D\"], **kwargs)\n", "    return model\n\tdef vgg16_bn(**kwargs):\n\t    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n\t    model = VGG(cfg[\"D\"], batch_norm=True, **kwargs)\n\t    return model\n\tdef vgg19(**kwargs):\n\t    \"\"\"VGG 19-layer model (configuration \"E\")\n\t    Args:\n\t        pretrained (bool): If True, returns a model pre-trained on ImageNet\n\t    \"\"\"\n", "    model = VGG(cfg[\"E\"], **kwargs)\n\t    return model\n\tdef vgg19_bn(**kwargs):\n\t    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n\t    model = VGG(cfg[\"E\"], batch_norm=True, **kwargs)\n\t    return model\n"]}
{"filename": "models/SmallResolutionModel/resnet.py", "chunked_list": ["from __future__ import absolute_import\n\t\"\"\"Resnet for cifar dataset.\n\tPorted form\n\thttps://github.com/facebook/fb.resnet.torch\n\tand\n\thttps://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n\t(c) YANG, Wei\n\tadding hyperparameter norm_layers\n\tHuanran Chen\n\t\"\"\"\n", "import math\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\t__all__ = [\n\t    \"resnet56_aux\",\n\t    \"resnet20_aux\",\n\t    \"resnet32x4_aux\",\n\t    \"resnet8x4_aux\",\n\t    \"resnet8\",\n", "    \"resnet8x4\",\n\t    \"resnet20\",\n\t    \"resnet32\",\n\t    \"resnet56\",\n\t    \"resnet110\",\n\t    \"resnet8_spkd\",\n\t    \"resnet20_spkd\",\n\t    \"resnet56_spkd\",\n\t    \"resnet8x4_spkd\",\n\t    \"resnet32x4_spkd\",\n", "    \"resnet32x4\",\n\t    \"resnet8_crd\",\n\t    \"resnet20_crd\",\n\t    \"resnet56_crd\",\n\t    \"resnet8x4_crd\",\n\t    \"resnet32x4_crd\",\n\t]\n\tclass Swish(nn.Module):\n\t    def __init__(self, **kwargs):\n\t        super(Swish, self).__init__()\n", "    def forward(self, x):\n\t        return x * torch.sigmoid(x)\n\tclass Normalizer4CRD(nn.Module):\n\t    def __init__(self, linear, power=2):\n\t        super().__init__()\n\t        self.linear = linear\n\t        self.power = power\n\t    def forward(self, x):\n\t        x = x.flatten(1)\n\t        z = self.linear(x)\n", "        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n\t        out = z.div(norm)\n\t        return out\n\tdef conv3x3(in_planes, out_planes, stride=1):\n\t    \"\"\"3x3 convolution with padding\"\"\"\n\t    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\tclass BasicBlock(nn.Module):\n\t    expansion = 1\n\t    def __init__(self, inplanes, planes, stride=1, downsample=None, is_last=False,\n\t                 norm_layer=nn.BatchNorm2d):\n", "        super(BasicBlock, self).__init__()\n\t        self.is_last = is_last\n\t        self.conv1 = conv3x3(inplanes, planes, stride)\n\t        self.bn1 = norm_layer(planes)\n\t        self.relu = Swish(inplace=True)\n\t        self.conv2 = conv3x3(planes, planes)\n\t        self.bn2 = norm_layer(planes)\n\t        self.downsample = downsample\n\t        self.stride = stride\n\t    def forward(self, x):\n", "        residual = x\n\t        out = self.conv1(x)\n\t        out = self.bn1(out)\n\t        out = self.relu(out)\n\t        out = self.conv2(out)\n\t        out = self.bn2(out)\n\t        if self.downsample is not None:\n\t            residual = self.downsample(x)\n\t        out += residual\n\t        out = F.relu(out)\n", "        return out\n\tclass Bottleneck(nn.Module):\n\t    expansion = 4\n\t    def __init__(self, inplanes, planes, stride=1, downsample=None, is_last=False,\n\t                 norm_layer=nn.BatchNorm2d):\n\t        super(Bottleneck, self).__init__()\n\t        self.is_last = is_last\n\t        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n\t        self.bn1 = norm_layer(planes)\n\t        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n", "        self.bn2 = norm_layer(planes)\n\t        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n\t        self.bn3 = norm_layer(planes * 4)\n\t        self.relu = Swish(inplace=True)\n\t        self.downsample = downsample\n\t        self.stride = stride\n\t    def forward(self, x):\n\t        residual = x\n\t        out = self.conv1(x)\n\t        out = self.bn1(out)\n", "        out = self.relu(out)\n\t        out = self.conv2(out)\n\t        out = self.bn2(out)\n\t        out = self.relu(out)\n\t        out = self.conv3(out)\n\t        out = self.bn3(out)\n\t        if self.downsample is not None:\n\t            residual = self.downsample(x)\n\t        out += residual\n\t        out = F.relu(out)\n", "        return out\n\tclass ResNet(nn.Module):\n\t    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10,\n\t                 norm_layer=nn.BatchNorm2d):\n\t        super(ResNet, self).__init__()\n\t        # Model type specifies number of layers for CIFAR-10 model\n\t        if block_name.lower() == \"basicblock\":\n\t            assert (\n\t                           depth - 2\n\t                   ) % 6 == 0, \"When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\"\n", "            n = (depth - 2) // 6\n\t            block = BasicBlock\n\t        elif block_name.lower() == \"bottleneck\":\n\t            assert (\n\t                           depth - 2\n\t                   ) % 9 == 0, \"When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\"\n\t            n = (depth - 2) // 9\n\t            block = Bottleneck\n\t        else:\n\t            raise ValueError(\"block_name shoule be Basicblock or Bottleneck\")\n", "        self.inplanes = num_filters[0]\n\t        self.conv1 = nn.Conv2d(3, num_filters[0], kernel_size=3, padding=1, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(num_filters[0])\n\t        self.relu = Swish(inplace=True)\n\t        self.layer1 = self._make_layer(block, num_filters[1], n, norm_layer)\n\t        self.layer2 = self._make_layer(block, num_filters[2], n, norm_layer, stride=2)\n\t        self.layer3 = self._make_layer(block, num_filters[3], n, norm_layer, stride=2)\n\t        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc = nn.Linear(num_filters[3] * block.expansion, num_classes)\n\t        self.last_channel = num_filters[3] * block.expansion\n", "        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n\t            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n\t                nn.init.constant_(m.weight, 1)\n\t                nn.init.constant_(m.bias, 0)\n\t    def _make_layer(self, block, planes, blocks, norm_layer, stride=1):\n\t        downsample = None\n\t        if stride != 1 or self.inplanes != planes * block.expansion:\n\t            downsample = nn.Sequential(\n", "                nn.Conv2d(\n\t                    self.inplanes,\n\t                    planes * block.expansion,\n\t                    kernel_size=1,\n\t                    stride=stride,\n\t                    bias=False,\n\t                ),\n\t                nn.BatchNorm2d(planes * block.expansion),\n\t            )\n\t        layers = list([])\n", "        layers.append(block(self.inplanes, planes, stride, downsample))\n\t        self.inplanes = planes * block.expansion\n\t        for i in range(1, blocks):\n\t            layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n\t        return nn.Sequential(*layers)\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.bn1)\n\t        feat_m.append(self.relu)\n", "        feat_m.append(self.layer1)\n\t        feat_m.append(self.layer2)\n\t        feat_m.append(self.layer3)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        if isinstance(self.layer1[0], Bottleneck):\n\t            bn1 = self.layer1[-1].bn3\n\t            bn2 = self.layer2[-1].bn3\n\t            bn3 = self.layer3[-1].bn3\n\t        elif isinstance(self.layer1[0], BasicBlock):\n", "            bn1 = self.layer1[-1].bn2\n\t            bn2 = self.layer2[-1].bn2\n\t            bn3 = self.layer3[-1].bn2\n\t        else:\n\t            raise NotImplementedError(\"ResNet unknown block error !!!\")\n\t        return [bn1, bn2, bn3]\n\t    def forward(self, x, is_feat=False):\n\t        x = self.conv1(x)\n\t        x = self.bn1(x)\n\t        x = self.relu(x)  # 32x32\n", "        x = self.layer1(x)  # 32x32\n\t        f1 = x\n\t        x = self.layer2(x)  # 16x16\n\t        f2 = x\n\t        x = self.layer3(x)  # 8x8\n\t        f3 = x\n\t        x = self.avgpool(x)\n\t        x = x.view(x.size(0), -1)\n\t        x = x.sum(1)\n\t        # x = self.fc(x)\n", "        if is_feat:\n\t            return [f1, f2, f3, f3], x\n\t        else:\n\t            return x\n\tclass Auxiliary_Classifier(nn.Module):\n\t    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=100):\n\t        super(Auxiliary_Classifier, self).__init__()\n\t        if block_name.lower() == \"basicblock\":\n\t            assert (\n\t                           depth - 2\n", "                   ) % 6 == 0, \"When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\"\n\t            n = (depth - 2) // 6\n\t            block = BasicBlock\n\t        elif block_name.lower() == \"bottleneck\":\n\t            assert (\n\t                           depth - 2\n\t                   ) % 9 == 0, \"When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\"\n\t            n = (depth - 2) // 9\n\t            block = Bottleneck\n\t        else:\n", "            raise ValueError(\"block_name shoule be Basicblock or Bottleneck\")\n\t        self.inplanes = num_filters[1] * block.expansion\n\t        self.block_extractor1 = nn.Sequential(\n\t            *[\n\t                self._make_layer(block, num_filters[2], n, stride=2),\n\t                self._make_layer(block, num_filters[3], n, stride=2),\n\t            ]\n\t        )\n\t        self.inplanes = num_filters[2] * block.expansion\n\t        self.block_extractor2 = nn.Sequential(\n", "            *[self._make_layer(block, num_filters[3], n, stride=2)]\n\t        )\n\t        self.inplanes = num_filters[3] * block.expansion\n\t        self.block_extractor3 = nn.Sequential(\n\t            *[self._make_layer(block, num_filters[3], n, stride=1)]\n\t        )\n\t        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc1 = nn.Linear(num_filters[3] * block.expansion, num_classes)\n\t        self.fc2 = nn.Linear(num_filters[3] * block.expansion, num_classes)\n\t        self.fc3 = nn.Linear(num_filters[3] * block.expansion, num_classes)\n", "        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n\t            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                m.bias.data.zero_()\n\t    def _make_layer(self, block, planes, blocks, stride=1):\n", "        downsample = None\n\t        if stride != 1 or self.inplanes != planes * block.expansion:\n\t            downsample = nn.Sequential(\n\t                nn.Conv2d(\n\t                    self.inplanes,\n\t                    planes * block.expansion,\n\t                    kernel_size=1,\n\t                    stride=stride,\n\t                    bias=False,\n\t                ),\n", "                nn.BatchNorm2d(planes * block.expansion),\n\t            )\n\t        layers = list([])\n\t        layers.append(block(self.inplanes, planes, stride, downsample, is_last=(blocks == 1)))\n\t        self.inplanes = planes * block.expansion\n\t        for i in range(1, blocks):\n\t            layers.append(block(self.inplanes, planes, is_last=(i == blocks - 1)))\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        ss_logits = []\n", "        ss_feats = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n\t            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = self.avg_pool(out)\n\t            out = out.view(out.size(0), -1)\n\t            ss_feats.append(out)\n\t            out = getattr(self, \"fc\" + str(idx))(out)\n\t            ss_logits.append(out)\n\t        return ss_feats, ss_logits\n", "class ResNet_Auxiliary(nn.Module):\n\t    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10):\n\t        super(ResNet_Auxiliary, self).__init__()\n\t        self.backbone = ResNet(depth, num_filters, block_name, num_classes)\n\t        self.auxiliary_classifier = Auxiliary_Classifier(\n\t            depth, num_filters, block_name, num_classes=num_classes * 4\n\t        )\n\t    def forward(self, x, grad=False, att=False):\n\t        feats, logit = self.backbone(x, is_feat=True)\n\t        if grad is False:\n", "            for i in range(len(feats)):\n\t                feats[i] = feats[i].detach()\n\t        ss_feats, ss_logits = self.auxiliary_classifier(feats)\n\t        if att is False:\n\t            return logit, ss_logits\n\t        else:\n\t            return logit, ss_logits, feats\n\tclass ResNet_SPKD(ResNet):\n\t    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10):\n\t        super(ResNet_SPKD, self).__init__(depth, num_filters, block_name, num_classes)\n", "    def forward(self, x):\n\t        x = self.conv1(x)\n\t        x = self.bn1(x)\n\t        x = self.relu(x)  # 32x32\n\t        x = self.layer1(x)  # 32x32\n\t        x = self.layer2(x)  # 16x16\n\t        x = self.layer3(x)  # 8x8\n\t        f3 = x\n\t        x = self.avgpool(x)\n\t        x = x.view(x.size(0), -1)\n", "        x = self.fc(x)\n\t        return f3, x\n\tclass ResNet_CRD(nn.Module):\n\t    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10):\n\t        super(ResNet_CRD, self).__init__()\n\t        # Model type specifies number of layers for CIFAR-10 model\n\t        if block_name.lower() == \"basicblock\":\n\t            assert (\n\t                           depth - 2\n\t                   ) % 6 == 0, \"When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\"\n", "            n = (depth - 2) // 6\n\t            block = BasicBlock\n\t        elif block_name.lower() == \"bottleneck\":\n\t            assert (\n\t                           depth - 2\n\t                   ) % 9 == 0, \"When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\"\n\t            n = (depth - 2) // 9\n\t            block = Bottleneck\n\t        else:\n\t            raise ValueError(\"block_name shoule be Basicblock or Bottleneck\")\n", "        self.inplanes = num_filters[0]\n\t        self.conv1 = nn.Conv2d(3, num_filters[0], kernel_size=3, padding=1, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(num_filters[0])\n\t        self.relu = Swish(inplace=True)\n\t        self.layer1 = self._make_layer(block, num_filters[1], n)\n\t        self.layer2 = self._make_layer(block, num_filters[2], n, stride=2)\n\t        self.layer3 = self._make_layer(block, num_filters[3], n, stride=2)\n\t        # self.avgpool = nn.Pool((1, 1))\n\t        self.fc = nn.Linear(num_filters[3] * block.expansion, num_classes)\n\t        linear = nn.Linear(num_filters[3] * block.expansion, 128, bias=True)\n", "        self.normalizer = Normalizer4CRD(linear, power=2)\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n\t            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n\t                nn.init.constant_(m.weight, 1)\n\t                nn.init.constant_(m.bias, 0)\n\t    def _make_layer(self, block, planes, blocks, stride=1):\n\t        downsample = None\n\t        if stride != 1 or self.inplanes != planes * block.expansion:\n", "            downsample = nn.Sequential(\n\t                nn.Conv2d(\n\t                    self.inplanes,\n\t                    planes * block.expansion,\n\t                    kernel_size=1,\n\t                    stride=stride,\n\t                    bias=False,\n\t                ),\n\t                nn.BatchNorm2d(planes * block.expansion),\n\t            )\n", "        layers = list([])\n\t        layers.append(block(self.inplanes, planes, stride, downsample))\n\t        self.inplanes = planes * block.expansion\n\t        for i in range(1, blocks):\n\t            layers.append(block(self.inplanes, planes))\n\t        return nn.Sequential(*layers)\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.bn1)\n", "        feat_m.append(self.relu)\n\t        feat_m.append(self.layer1)\n\t        feat_m.append(self.layer2)\n\t        feat_m.append(self.layer3)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        if isinstance(self.layer1[0], Bottleneck):\n\t            bn1 = self.layer1[-1].bn3\n\t            bn2 = self.layer2[-1].bn3\n\t            bn3 = self.layer3[-1].bn3\n", "        elif isinstance(self.layer1[0], BasicBlock):\n\t            bn1 = self.layer1[-1].bn2\n\t            bn2 = self.layer2[-1].bn2\n\t            bn3 = self.layer3[-1].bn2\n\t        else:\n\t            raise NotImplementedError(\"ResNet unknown block error !!!\")\n\t        return [bn1, bn2, bn3]\n\t    def forward(self, x):\n\t        x = self.conv1(x)\n\t        x = self.bn1(x)\n", "        x = self.relu(x)  # 32x32\n\t        x = self.layer1(x)  # 32x32\n\t        x = self.layer2(x)  # 16x16\n\t        x = self.layer3(x)  # 8x8\n\t        # x = self.avgpool(x)\n\t        print(x.shape)\n\t        assert False\n\t        crdout = x\n\t        x = x.view(x.size(0), -1)\n\t        x = self.fc(x)\n", "        crdout = self.normalizer(crdout)\n\t        return crdout, x\n\tdef resnet8(**kwargs):\n\t    return ResNet(8, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet14(**kwargs):\n\t    return ResNet(14, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet20(**kwargs):\n\t    return ResNet(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet8_spkd(**kwargs):\n\t    return ResNet_SPKD(8, [16, 16, 32, 64], \"basicblock\", **kwargs)\n", "def resnet14_spkd(**kwargs):\n\t    return ResNet_SPKD(14, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet20_spkd(**kwargs):\n\t    return ResNet_SPKD(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet8_crd(**kwargs):\n\t    return ResNet_CRD(8, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet14_crd(**kwargs):\n\t    return ResNet_CRD(14, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet20_crd(**kwargs):\n\t    return ResNet_CRD(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n", "def resnet20_aux(**kwargs):\n\t    return ResNet_Auxiliary(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet14x05(**kwargs):\n\t    return ResNet(14, [8, 8, 16, 32], \"basicblock\", **kwargs)\n\tdef resnet20x05(**kwargs):\n\t    return ResNet(20, [8, 8, 16, 32], \"basicblock\", **kwargs)\n\tdef resnet20x0375(**kwargs):\n\t    return ResNet(20, [6, 6, 12, 24], \"basicblock\", **kwargs)\n\tdef resnet32(**kwargs):\n\t    return ResNet(32, [16, 16, 32, 64], \"basicblock\", **kwargs)\n", "def resnet44(**kwargs):\n\t    return ResNet(44, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet56(**kwargs):\n\t    return ResNet(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet56_aux(**kwargs):\n\t    return ResNet_Auxiliary(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet56_spkd(**kwargs):\n\t    return ResNet_SPKD(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet56_crd(**kwargs):\n\t    return ResNet_CRD(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n", "def resnet110(**kwargs):\n\t    return ResNet(110, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\tdef resnet8x4(**kwargs):\n\t    return ResNet(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\tdef resnet8x4_aux(**kwargs):\n\t    return ResNet_Auxiliary(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\tdef resnet8x4_spkd(**kwargs):\n\t    return ResNet_SPKD(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\tdef resnet8x4_crd(**kwargs):\n\t    return ResNet_CRD(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n", "def resnet32x4(**kwargs):\n\t    return ResNet(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\tdef resnet32x4_aux(**kwargs):\n\t    return ResNet_Auxiliary(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\tdef resnet32x4_spkd(**kwargs):\n\t    return ResNet_SPKD(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\tdef resnet32x4_crd(**kwargs):\n\t    return ResNet_CRD(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n"]}
{"filename": "models/SmallResolutionModel/jem_wideresnet.py", "chunked_list": ["# coding=utf-8\n\t# Copyright 2019 The Google Research Authors.\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n", "# distributed under the License is distributed on an \"AS IS\" BASIS,\n\t# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport torch.nn as nn\n\timport torch.nn.init as init\n\timport torch.nn.functional as F\n\t# coding=utf-8\n\t# Copyright 2019 The Google Research Authors.\n\t#\n", "# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#     http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n\t# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n", "# limitations under the License.\n\timport torch\n\timport torch.nn as nn\n\tclass ConditionalInstanceNorm2dPlus(nn.Module):\n\t    def __init__(self, num_features, num_classes, bias=True):\n\t        super().__init__()\n\t        self.num_features = num_features\n\t        self.bias = bias\n\t        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n\t        if bias:\n", "            self.embed = nn.Embedding(num_classes, num_features * 3)\n\t            self.embed.weight.data[:, :2 * num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n\t            self.embed.weight.data[:, 2 * num_features:].zero_()  # Initialise bias at 0\n\t        else:\n\t            self.embed = nn.Embedding(num_classes, 2 * num_features)\n\t            self.embed.weight.data.normal_(1, 0.02)\n\t    def forward(self, x, y):\n\t        means = torch.mean(x, dim=(2, 3))\n\t        m = torch.mean(means, dim=-1, keepdim=True)\n\t        v = torch.var(means, dim=-1, keepdim=True)\n", "        means = (means - m) / (torch.sqrt(v + 1e-5))\n\t        h = self.instance_norm(x)\n\t        if self.bias:\n\t            gamma, alpha, beta = self.embed(y).chunk(3, dim=-1)\n\t            h = h + means[..., None, None] * alpha[..., None, None]\n\t            out = gamma.view(-1, self.num_features, 1, 1) * h + beta.view(-1, self.num_features, 1, 1)\n\t        else:\n\t            gamma, alpha = self.embed(y).chunk(2, dim=-1)\n\t            h = h + means[..., None, None] * alpha[..., None, None]\n\t            out = gamma.view(-1, self.num_features, 1, 1) * h\n", "        return out\n\tclass ConditionalActNorm(nn.Module):\n\t    def __init__(self, num_features, num_classes):\n\t        super().__init__()\n\t        self.num_features = num_features\n\t        self.num_classes = num_classes\n\t        self.embed = nn.Embedding(num_classes, num_features * 2)\n\t        self.embed.weight.data.zero_()\n\t        self.init = False\n\t    def forward(self, x, y):\n", "        if self.init:\n\t            scale, bias = self.embed(y).chunk(2, dim=-1)\n\t            return x * scale[:, :, None, None] + bias[:, :, None, None]\n\t        else:\n\t            m, v = torch.mean(x, dim=(0, 2, 3)), torch.var(x, dim=(0, 2, 3))\n\t            std = torch.sqrt(v + 1e-5)\n\t            scale_init = 1. / std\n\t            bias_init = -1. * m / std\n\t            self.embed.weight.data[:, :self.num_features] = scale_init[None].repeat(self.num_classes, 1)\n\t            self.embed.weight.data[:, self.num_features:] = bias_init[None].repeat(self.num_classes, 1)\n", "            self.init = True\n\t            return self(x, y)\n\tlogabs = lambda x: torch.log(torch.abs(x))\n\tclass ActNorm(nn.Module):\n\t    def __init__(self, in_channel, logdet=True):\n\t        super().__init__()\n\t        self.loc = nn.Parameter(torch.zeros(1, in_channel, 1, 1))\n\t        self.scale = nn.Parameter(torch.ones(1, in_channel, 1, 1))\n\t        self.register_buffer('initialized', torch.tensor(0, dtype=torch.uint8))\n\t        self.logdet = logdet\n", "    def initialize(self, input):\n\t        with torch.no_grad():\n\t            flatten = input.permute(1, 0, 2, 3).contiguous().view(input.shape[1], -1)\n\t            mean = (\n\t                flatten.mean(1)\n\t                    .unsqueeze(1)\n\t                    .unsqueeze(2)\n\t                    .unsqueeze(3)\n\t                    .permute(1, 0, 2, 3)\n\t            )\n", "            std = (\n\t                flatten.std(1)\n\t                    .unsqueeze(1)\n\t                    .unsqueeze(2)\n\t                    .unsqueeze(3)\n\t                    .permute(1, 0, 2, 3)\n\t            )\n\t            self.loc.data.copy_(-mean)\n\t            self.scale.data.copy_(1 / (std + 1e-6))\n\t    def forward(self, input):\n", "        _, _, height, width = input.shape\n\t        if self.initialized.item() == 0:\n\t            self.initialize(input)\n\t            self.initialized.fill_(1)\n\t        log_abs = logabs(self.scale)\n\t        logdet = height * width * torch.sum(log_abs)\n\t        if self.logdet:\n\t            return self.scale * (input + self.loc), logdet\n\t        else:\n\t            return self.scale * (input + self.loc)\n", "    def reverse(self, output):\n\t        return output / self.scale - self.loc\n\tclass ContinuousConditionalActNorm(nn.Module):\n\t    def __init__(self, num_features, num_classes):\n\t        super().__init__()\n\t        del num_classes\n\t        self.num_features = num_features\n\t        self.embed = nn.Sequential(nn.Linear(1, 256),\n\t                                   nn.ELU(inplace=True),\n\t                                   nn.Linear(256, 256),\n", "                                   nn.ELU(inplace=True),\n\t                                   nn.Linear(256, self.num_features * 2),\n\t                                   )\n\t    def forward(self, x, y):\n\t        scale, bias = self.embed(y.unsqueeze(-1)).chunk(2, dim=-1)\n\t        return x * scale[:, :, None, None] + bias[:, :, None, None]\n\t# class Identity(nn.Module):\n\t#     def __init__(self):\n\t#         super(Identity, self).__init__()\n\t#\n", "#     def forward(self, *args, **kwargs):\n\t#         return\n\timport numpy as np\n\tdef conv3x3(in_planes, out_planes, stride=1):\n\t    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\tdef conv_init(m):\n\t    classname = m.__class__.__name__\n\t    if classname.find('Conv') != -1:\n\t        init.xavier_uniform(m.weight, gain=np.sqrt(2))\n\t        init.constant(m.bias, 0)\n", "    elif classname.find('BatchNorm') != -1:\n\t        init.constant(m.weight, 1)\n\t        init.constant(m.bias, 0)\n\tclass Identity(nn.Module):\n\t    def __init__(self, *args, **kwargs):\n\t        super().__init__()\n\t    def forward(self, x):\n\t        return x\n\tclass wide_basic(nn.Module):\n\t    def __init__(self, in_planes, planes, dropout_rate, stride=1, norm=None, leak=.2):\n", "        super(wide_basic, self).__init__()\n\t        self.lrelu = nn.LeakyReLU(leak)\n\t        self.bn1 = get_norm(in_planes, norm)\n\t        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n\t        self.dropout = Identity() if dropout_rate == 0.0 else nn.Dropout(p=dropout_rate)\n\t        self.bn2 = get_norm(planes, norm)\n\t        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\t        self.shortcut = nn.Sequential()\n\t        if stride != 1 or in_planes != planes:\n\t            self.shortcut = nn.Sequential(\n", "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n\t            )\n\t    def forward(self, x):\n\t        out = self.dropout(self.conv1(self.lrelu(self.bn1(x))))\n\t        out = self.conv2(self.lrelu(self.bn2(out)))\n\t        out += self.shortcut(x)\n\t        return out\n\tdef get_norm(n_filters, norm):\n\t    if norm is None:\n\t        return Identity()\n", "    elif norm == \"batch\":\n\t        return nn.BatchNorm2d(n_filters, momentum=0.9)\n\t    elif norm == \"instance\":\n\t        return nn.InstanceNorm2d(n_filters, affine=True)\n\t    elif norm == \"layer\":\n\t        return nn.GroupNorm(1, n_filters)\n\t    elif norm == \"act\":\n\t        return ActNorm(n_filters, False)\n\tclass Wide_ResNet(nn.Module):\n\t    def __init__(self, depth=28, widen_factor=2, num_classes=1, input_channels=3,\n", "                 sum_pool=False, norm=None, leak=.2, dropout_rate=0.0):\n\t        super(Wide_ResNet, self).__init__()\n\t        self.leak = leak\n\t        self.in_planes = 16\n\t        self.sum_pool = sum_pool\n\t        self.norm = norm\n\t        self.lrelu = nn.LeakyReLU(leak)\n\t        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n\t        n = (depth - 4) // 6\n\t        k = widen_factor\n", "        print('| Wide-Resnet %dx%d' % (depth, k))\n\t        nStages = [16, 16 * k, 32 * k, 64 * k]\n\t        self.conv1 = conv3x3(input_channels, nStages[0])\n\t        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n\t        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n\t        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n\t        self.bn1 = get_norm(nStages[3], self.norm)\n\t        self.last_dim = nStages[3]\n\t        self.linear = nn.Linear(nStages[3], num_classes)\n\t    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n", "        strides = [stride] + [1] * (num_blocks - 1)\n\t        layers = []\n\t        for stride in strides:\n\t            layers.append(block(self.in_planes, planes, dropout_rate, stride, norm=self.norm))\n\t            self.in_planes = planes\n\t        return nn.Sequential(*layers)\n\t    def forward(self, x, vx=None):\n\t        out = self.conv1(x)\n\t        out = self.layer1(out)\n\t        out = self.layer2(out)\n", "        out = self.layer3(out)\n\t        out = self.lrelu(self.bn1(out))\n\t        if self.sum_pool:\n\t            out = out.view(out.size(0), out.size(1), -1).sum(2)\n\t        else:\n\t            out = F.avg_pool2d(out, 8)\n\t        out = out.view(out.size(0), -1)\n\t        return out\n"]}
{"filename": "models/SmallResolutionModel/ShuffleNetv1.py", "chunked_list": ["\"\"\"ShuffleNet in PyTorch.\n\tSee the paper \"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\" for more details.\n\t\"\"\"\n\timport math\n\timport torch\n\timport torch.nn as nn\n\timport torch.nn.functional as F\n\t__all__ = [\"ShuffleV1_aux\", \"ShuffleV1\"]\n\tclass ShuffleBlock(nn.Module):\n\t    def __init__(self, groups):\n", "        super(ShuffleBlock, self).__init__()\n\t        self.groups = groups\n\t    def forward(self, x):\n\t        \"\"\"Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]\"\"\"\n\t        N, C, H, W = x.size()\n\t        g = self.groups\n\t        return x.reshape(N, g, C // g, H, W).permute(0, 2, 1, 3, 4).reshape(N, C, H, W)\n\tclass Bottleneck(nn.Module):\n\t    def __init__(self, in_planes, out_planes, stride, groups, is_last=False):\n\t        super(Bottleneck, self).__init__()\n", "        self.is_last = is_last\n\t        self.stride = stride\n\t        mid_planes = int(out_planes / 4)\n\t        g = 1 if in_planes == 24 else groups\n\t        self.conv1 = nn.Conv2d(in_planes, mid_planes, kernel_size=1, groups=g, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(mid_planes)\n\t        self.shuffle1 = ShuffleBlock(groups=g)\n\t        self.conv2 = nn.Conv2d(\n\t            mid_planes,\n\t            mid_planes,\n", "            kernel_size=3,\n\t            stride=stride,\n\t            padding=1,\n\t            groups=mid_planes,\n\t            bias=False,\n\t        )\n\t        self.bn2 = nn.BatchNorm2d(mid_planes)\n\t        self.conv3 = nn.Conv2d(mid_planes, out_planes, kernel_size=1, groups=groups, bias=False)\n\t        self.bn3 = nn.BatchNorm2d(out_planes)\n\t        self.shortcut = nn.Sequential()\n", "        if stride == 2:\n\t            self.shortcut = nn.Sequential(nn.AvgPool2d(3, stride=2, padding=1))\n\t    def forward(self, x):\n\t        out = F.relu(self.bn1(self.conv1(x)))\n\t        out = self.shuffle1(out)\n\t        out = F.relu(self.bn2(self.conv2(out)))\n\t        out = self.bn3(self.conv3(out))\n\t        res = self.shortcut(x)\n\t        preact = torch.cat([out, res], 1) if self.stride == 2 else out + res\n\t        out = F.relu(preact)\n", "        # out = F.relu(torch.cat([out, res], 1)) if self.stride == 2 else F.relu(out+res)\n\t        if self.is_last:\n\t            return out, preact\n\t        else:\n\t            return out\n\tclass ShuffleNet(nn.Module):\n\t    def __init__(self, cfg, num_classes=10):\n\t        super(ShuffleNet, self).__init__()\n\t        out_planes = cfg[\"out_planes\"]\n\t        num_blocks = cfg[\"num_blocks\"]\n", "        groups = cfg[\"groups\"]\n\t        self.conv1 = nn.Conv2d(3, 24, kernel_size=1, bias=False)\n\t        self.bn1 = nn.BatchNorm2d(24)\n\t        self.in_planes = 24\n\t        self.layer1 = self._make_layer(out_planes[0], num_blocks[0], groups)\n\t        self.layer2 = self._make_layer(out_planes[1], num_blocks[1], groups)\n\t        self.layer3 = self._make_layer(out_planes[2], num_blocks[2], groups)\n\t        self.linear = nn.Linear(out_planes[2], num_classes)\n\t        self.last_channel = out_planes[2]\n\t    def _make_layer(self, out_planes, num_blocks, groups):\n", "        layers = []\n\t        for i in range(num_blocks):\n\t            stride = 2 if i == 0 else 1\n\t            cat_planes = self.in_planes if i == 0 else 0\n\t            layers.append(\n\t                Bottleneck(\n\t                    self.in_planes,\n\t                    out_planes - cat_planes,\n\t                    stride=stride,\n\t                    groups=groups,\n", "                    is_last=(i == num_blocks - 1),\n\t                )\n\t            )\n\t            self.in_planes = out_planes\n\t        return nn.Sequential(*layers)\n\t    def get_feat_modules(self):\n\t        feat_m = nn.ModuleList([])\n\t        feat_m.append(self.conv1)\n\t        feat_m.append(self.bn1)\n\t        feat_m.append(self.layer1)\n", "        feat_m.append(self.layer2)\n\t        feat_m.append(self.layer3)\n\t        return feat_m\n\t    def get_bn_before_relu(self):\n\t        raise NotImplementedError('ShuffleNet currently is not supported for \"Overhaul\" teacher')\n\t    def forward(self, x, is_feat=False):\n\t        out = F.relu(self.bn1(self.conv1(x)))\n\t        f0 = out\n\t        out, f1_pre = self.layer1(out)\n\t        f1 = out\n", "        out, f2_pre = self.layer2(out)\n\t        f2 = out\n\t        out, f3_pre = self.layer3(out)\n\t        f3 = out\n\t        out = F.avg_pool2d(out, 4)\n\t        out = out.reshape(out.size(0), -1)\n\t        out = self.linear(out)\n\t        if is_feat:\n\t            return [f0, f1, f2, f3], out\n\t        else:\n", "            return out\n\tclass Auxiliary_Classifier(nn.Module):\n\t    def __init__(self, cfg, num_classes=10):\n\t        super(Auxiliary_Classifier, self).__init__()\n\t        out_planes = cfg[\"out_planes\"]\n\t        num_blocks = cfg[\"num_blocks\"]\n\t        groups = cfg[\"groups\"]\n\t        self.in_planes = out_planes[0]\n\t        self.block_extractor1 = nn.Sequential(\n\t            *[\n", "                self._make_layer(out_planes[1], num_blocks[1], groups),\n\t                self._make_layer(out_planes[2], num_blocks[2], groups),\n\t            ]\n\t        )\n\t        self.in_planes = out_planes[1]\n\t        self.block_extractor2 = nn.Sequential(\n\t            *[self._make_layer(out_planes[2], num_blocks[2], groups)]\n\t        )\n\t        self.inplanes = out_planes[2]\n\t        self.block_extractor3 = nn.Sequential(\n", "            *[self._make_layer(out_planes[2], num_blocks[2], groups, downsample=False)]\n\t        )\n\t        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n\t        self.fc1 = nn.Linear(out_planes[2], num_classes)\n\t        self.fc2 = nn.Linear(out_planes[2], num_classes)\n\t        self.fc3 = nn.Linear(out_planes[2], num_classes)\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv2d):\n\t                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n\t                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n", "            elif isinstance(m, nn.BatchNorm2d):\n\t                m.weight.data.fill_(1)\n\t                m.bias.data.zero_()\n\t            elif isinstance(m, nn.Linear):\n\t                m.bias.data.zero_()\n\t    def _make_layer(self, out_planes, num_blocks, groups, downsample=True):\n\t        layers = []\n\t        for i in range(num_blocks):\n\t            stride = 2 if i == 0 and downsample is True else 1\n\t            cat_planes = self.in_planes if i == 0 and downsample is True else 0\n", "            layers.append(\n\t                Bottleneck(\n\t                    self.in_planes,\n\t                    out_planes - cat_planes,\n\t                    stride=stride,\n\t                    groups=groups,\n\t                    is_last=(i == num_blocks - 1),\n\t                )\n\t            )\n\t            self.in_planes = out_planes\n", "        return nn.Sequential(*layers)\n\t    def forward(self, x):\n\t        ss_logits = []\n\t        for i in range(len(x)):\n\t            idx = i + 1\n\t            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n\t            out = self.avg_pool(out)\n\t            out = out.view(out.size(0), -1)\n\t            out = getattr(self, \"fc\" + str(idx))(out)\n\t            ss_logits.append(out)\n", "        return ss_logits\n\tclass ShuffleNet_Auxiliary(nn.Module):\n\t    def __init__(self, cfg, num_classes=100):\n\t        super(ShuffleNet_Auxiliary, self).__init__()\n\t        self.backbone = ShuffleNet(cfg, num_classes=num_classes)\n\t        self.auxiliary_classifier = Auxiliary_Classifier(cfg, num_classes=num_classes * 4)\n\t    def forward(self, x, grad=False):\n\t        feats, logit = self.backbone(x, is_feat=True)\n\t        if grad is False:\n\t            for i in range(len(feats)):\n", "                feats[i] = feats[i].detach()\n\t        ss_logits = self.auxiliary_classifier(feats)\n\t        return logit, ss_logits\n\tdef ShuffleV1(**kwargs):\n\t    cfg = {\"out_planes\": [240, 480, 960], \"num_blocks\": [4, 8, 4], \"groups\": 3}\n\t    return ShuffleNet(cfg, **kwargs)\n\tdef ShuffleV1_aux(**kwargs):\n\t    cfg = {\"out_planes\": [240, 480, 960], \"num_blocks\": [4, 8, 4], \"groups\": 3}\n\t    return ShuffleNet_Auxiliary(cfg, **kwargs)\n"]}
{"filename": "models/SmallResolutionModel/igebm.py", "chunked_list": ["import torch\n\tfrom torch import nn\n\tfrom torch.nn import functional as F\n\tfrom torch.nn import utils\n\tclass SpectralNorm:\n\t    def __init__(self, name, bound=False):\n\t        self.name = name\n\t        self.bound = bound\n\t    def compute_weight(self, module):\n\t        weight = getattr(module, self.name + '_orig')\n", "        u = getattr(module, self.name + '_u')\n\t        size = weight.size()\n\t        weight_mat = weight.contiguous().view(size[0], -1)\n\t        with torch.no_grad():\n\t            v = weight_mat.t() @ u\n\t            v = v / v.norm()\n\t            u = weight_mat @ v\n\t            u = u / u.norm()\n\t        sigma = u @ weight_mat @ v\n\t        if self.bound:\n", "            weight_sn = weight / (sigma + 1e-6) * torch.clamp(sigma, max=1)\n\t        else:\n\t            weight_sn = weight / sigma\n\t        return weight_sn, u\n\t    @staticmethod\n\t    def apply(module, name, bound):\n\t        fn = SpectralNorm(name, bound)\n\t        weight = getattr(module, name)\n\t        del module._parameters[name]\n\t        module.register_parameter(name + '_orig', weight)\n", "        input_size = weight.size(0)\n\t        u = weight.new_empty(input_size).normal_()\n\t        module.register_buffer(name, weight)\n\t        module.register_buffer(name + '_u', u)\n\t        module.register_forward_pre_hook(fn)\n\t        return fn\n\t    def __call__(self, module, input):\n\t        weight_sn, u = self.compute_weight(module)\n\t        setattr(module, self.name, weight_sn)\n\t        setattr(module, self.name + '_u', u)\n", "def spectral_norm(module, init=True, std=1, bound=False):\n\t    if init:\n\t        nn.init.normal_(module.weight, 0, std)\n\t    if hasattr(module, 'bias') and module.bias is not None:\n\t        module.bias.data.zero_()\n\t    SpectralNorm.apply(module, 'weight', bound=bound)\n\t    return module\n\tclass ResBlock(nn.Module):\n\t    def __init__(self, in_channel, out_channel, n_class=None, downsample=False):\n\t        super().__init__()\n", "        self.conv1 = spectral_norm(\n\t            nn.Conv2d(\n\t                in_channel,\n\t                out_channel,\n\t                3,\n\t                padding=1,\n\t                bias=False if n_class is not None else True,\n\t            )\n\t        )\n\t        self.conv2 = spectral_norm(\n", "            nn.Conv2d(\n\t                out_channel,\n\t                out_channel,\n\t                3,\n\t                padding=1,\n\t                bias=False if n_class is not None else True,\n\t            ), std=1e-10, bound=True\n\t        )\n\t        self.class_embed = None\n\t        if n_class is not None:\n", "            class_embed = nn.Embedding(n_class, out_channel * 2 * 2)\n\t            class_embed.weight.data[:, : out_channel * 2] = 1\n\t            class_embed.weight.data[:, out_channel * 2 :] = 0\n\t            self.class_embed = class_embed\n\t        self.skip = None\n\t        if in_channel != out_channel or downsample:\n\t            self.skip = nn.Sequential(\n\t                spectral_norm(nn.Conv2d(in_channel, out_channel, 1, bias=False))\n\t            )\n\t        self.downsample = downsample\n", "    def forward(self, input, class_id=None):\n\t        out = input\n\t        out = self.conv1(out)\n\t        if self.class_embed is not None:\n\t            embed = self.class_embed(class_id).view(input.shape[0], -1, 1, 1)\n\t            weight1, weight2, bias1, bias2 = embed.chunk(4, 1)\n\t            out = weight1 * out + bias1\n\t        out = F.leaky_relu(out, negative_slope=0.2)\n\t        out = self.conv2(out)\n\t        if self.class_embed is not None:\n", "            out = weight2 * out + bias2\n\t        if self.skip is not None:\n\t            skip = self.skip(input)\n\t        else:\n\t            skip = input\n\t        out = out + skip\n\t        if self.downsample:\n\t            out = F.avg_pool2d(out, 2)\n\t        out = F.leaky_relu(out, negative_slope=0.2)\n\t        return out\n", "class IGEBM(nn.Module):\n\t    def __init__(self, n_class=None):\n\t        super().__init__()\n\t        self.conv1 = spectral_norm(nn.Conv2d(3, 128, 3, padding=1), std=1)\n\t        self.blocks = nn.ModuleList(\n\t            [\n\t                ResBlock(128, 128, n_class, downsample=True),\n\t                ResBlock(128, 128, n_class),\n\t                ResBlock(128, 256, n_class, downsample=True),\n\t                ResBlock(256, 256, n_class),\n", "                ResBlock(256, 256, n_class, downsample=True),\n\t                ResBlock(256, 256, n_class),\n\t            ]\n\t        )\n\t        self.linear = nn.Linear(256, 1)\n\t    def forward(self, input, class_id=None):\n\t        out = self.conv1(input)\n\t        out = F.leaky_relu(out, negative_slope=0.2)\n\t        for block in self.blocks:\n\t            out = block(out, class_id)\n", "        out = F.relu(out)\n\t        out = out.view(out.shape[0], out.shape[1], -1).sum(2)\n\t        out = self.linear(out)\n\t        return out\n"]}
{"filename": "optimizer/ALRS.py", "chunked_list": ["import torch\n\tclass ALRS():\n\t    '''\n\t    proposer: Huanran Chen\n\t    theory: landscape\n\t    Bootstrap Generalization Ability from Loss Landscape Perspective\n\t    '''\n\t    def __init__(self, optimizer, loss_threshold=0.01, loss_ratio_threshold=0.01, decay_rate=0.99):\n\t        self.optimizer = optimizer\n\t        self.loss_threshold = loss_threshold\n", "        self.decay_rate = decay_rate\n\t        self.loss_ratio_threshold = loss_ratio_threshold\n\t        self.last_loss = 999\n\t    def step(self, loss):\n\t        delta = self.last_loss - loss\n\t        if delta < self.loss_threshold and delta / self.last_loss < self.loss_ratio_threshold:\n\t            for group in self.optimizer.param_groups:\n\t                group['lr'] *= self.decay_rate\n\t                now_lr = group['lr']\n\t                print(f'now lr = {now_lr}')\n", "        self.last_loss = loss"]}
{"filename": "optimizer/FGSM.py", "chunked_list": ["import torch\n\tfrom torch.optim import Optimizer\n\tclass FGSM(Optimizer):\n\t    def __init__(self, params, lr, ):\n\t        dampening = 0\n\t        weight_decay = 0\n\t        nesterov = False\n\t        maximize = False\n\t        momentum = 0\n\t        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n", "                        weight_decay=weight_decay, nesterov=nesterov, maximize=maximize)\n\t        super(FGSM, self).__init__(params, defaults)\n\t        self.lr = lr\n\t    @torch.no_grad()\n\t    def step(self, closure=None):\n\t        for group in self.param_groups:\n\t            for p in group['params']:\n\t                if p.grad is not None:\n\t                    p.add_(-self.lr * p.grad.sign())\n"]}
{"filename": "optimizer/__init__.py", "chunked_list": ["from .FGSM import FGSM\n\tfrom torch.optim import Adam, AdamW, SGD\n\tfrom .default import default_optimizer, default_lr_scheduler\n\t__all__ = ['FGSM', 'AdamW', 'SGD', 'Adam', 'default_lr_scheduler', 'default_optimizer']\n"]}
{"filename": "optimizer/default.py", "chunked_list": ["import torch\n\tfrom torch import nn\n\tdef default_optimizer(model: nn.Module, lr=1e-1, ) -> torch.optim.Optimizer:\n\t    # return torch.optim.Adam(model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n\t    return torch.optim.SGD(model.parameters(), lr=lr)\n\tdef default_lr_scheduler(optimizer):\n\t    from .ALRS import ALRS\n\t    return ALRS(optimizer)"]}
{"filename": "tester/MembershipInference.py", "chunked_list": ["import torch\n\tfrom torch.utils.data import DataLoader\n\tfrom torch import Tensor\n\tdef most_similar(x: Tensor, loader: DataLoader) -> Tensor:\n\t    xs = []\n\t    for now_x, _ in loader:\n\t        xs.append(now_x.cuda())\n\t    xs = torch.cat(xs, dim=0)\n\t    N, C, H, D = xs.shape\n\t    d = ((x.squeeze() - xs) ** 2).view(N, C * H * D).sum(1)\n", "    min_index = torch.min(d, dim=0)[1]\n\t    target = xs[min_index]\n\t    return target.unsqueeze(0)\n"]}
{"filename": "tester/TransferAttackAcc.py", "chunked_list": ["import torch\n\tfrom torch import nn\n\tfrom torchvision import transforms\n\tfrom torch.utils.data import DataLoader\n\tfrom typing import List, Callable, Tuple\n\tfrom tqdm import tqdm\n\tfrom attacks import AdversarialInputAttacker\n\tfrom copy import deepcopy\n\tfrom torch import multiprocessing\n\tdef test_transfer_attack_acc(attacker: Callable, loader: DataLoader,\n", "                             target_models: List[nn.Module],\n\t                             device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> List[float]:\n\t    transfer_accs = [0] * len(target_models)\n\t    denominator = 0\n\t    # count = 0\n\t    # to_img = transforms.ToPILImage()\n\t    for x, y in tqdm(loader):\n\t        x = x.to(device)\n\t        y = y.to(device)\n\t        # ori_x = x.clone()\n", "        x = attacker(x, y)\n\t        # temp = to_img(x[0])\n\t        # temp.save(f'./what/mi/4/adv_{count}.png')\n\t        # temp = to_img(ori_x[0])\n\t        # temp.save(f'./what/mi/4/ori_{count}.png')\n\t        # temp = to_img(x[0]-ori_x[0])\n\t        # temp.save(f'./what/mi/4/perturb_{count}.png')\n\t        # count += 1\n\t        with torch.no_grad():\n\t            denominator += x.shape[0]\n", "            for i, model in enumerate(target_models):\n\t                pre = model(x)  # N, D\n\t                pre = torch.max(pre, dim=1)[1]  # N\n\t                transfer_accs[i] += torch.sum(pre == y).item()\n\t    transfer_accs = [1 - i / denominator for i in transfer_accs]\n\t    # print\n\t    for i, model in enumerate(target_models):\n\t        print('-' * 100)\n\t        print(model.__class__,  model.model.__class__, transfer_accs[i])\n\t        print('-' * 100)\n", "    return transfer_accs\n\tdef test_autoattack_acc(model: nn.Module, loader: DataLoader):\n\t    from autoattack import AutoAttack\n\t    adversary = AutoAttack(model, eps=8 / 255)\n\t    xs, ys = [], []\n\t    for x, y in tqdm(loader):\n\t        xs.append(x)\n\t        ys.append(y)\n\t    x = torch.concat(xs, dim=0)\n\t    y = torch.concat(ys, dim=0)\n", "    adversary.run_standard_evaluation(x, y)\n\tdef test_transfer_attack_acc_with_batch(get_attacker: Callable,\n\t                                        batch_x: torch.tensor,\n\t                                        batch_y: torch.tensor,\n\t                                        get_target_models: Callable,\n\t                                        batch_size: int = 1,\n\t                                        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> List[\n\t    float]:\n\t    attacker = get_attacker()\n\t    target_models = get_target_models()\n", "    transfer_accs = [0] * len(target_models)\n\t    denominator = 0\n\t    batch_x = batch_x.to(device)\n\t    batch_y = batch_y.to(device)\n\t    xs = list(torch.split(batch_x, batch_size, dim=0))\n\t    ys = list(torch.split(batch_y, batch_size, dim=0))\n\t    attacker.to(device)\n\t    for model in target_models:\n\t        model.to(device)\n\t    for x, y in tqdm(zip(xs, ys)):\n", "        x = attacker(x, y)\n\t        with torch.no_grad():\n\t            denominator += x.shape[0]\n\t            for i, model in enumerate(target_models):\n\t                pre = model(x)  # N, D\n\t                pre = torch.max(pre, dim=1)[1]  # N\n\t                transfer_accs[i] += torch.sum(pre == y).item()\n\t    transfer_accs = [1 - i / denominator for i in transfer_accs]\n\t    # print\n\t    for i, model in enumerate(target_models):\n", "        print('-' * 100)\n\t        print(model.__class__, transfer_accs[i])\n\t        print('-' * 100)\n\t    return transfer_accs\n\tdef test_transfer_attack_acc_distributed(get_attacker: Callable,\n\t                                         loader: DataLoader,\n\t                                         get_target_models: Callable,\n\t                                         batch_size: int = 1,\n\t                                         num_gpu: int = torch.cuda.device_count()):\n\t    def list_mean(x: list) -> float:\n", "        return sum(x) / len(x)\n\t    print(f'available gpu num {num_gpu}')\n\t    xs, ys = [], []\n\t    for x, y in loader:\n\t        xs.append(x)\n\t        ys.append(y)\n\t    xs, ys = torch.cat(xs, dim=0), torch.cat(ys, dim=0)\n\t    xs, ys = list(torch.split(xs, xs.shape[0] // num_gpu, dim=0)), list(torch.split(ys, ys.shape[0] // num_gpu, dim=0))\n\t    pool = multiprocessing.Pool(processes=num_gpu)\n\t    results = [pool.apply_async(func=test_transfer_attack_acc_with_batch,\n", "                                args=(\n\t                                    get_attacker,\n\t                                    xs[i], ys[i],\n\t                                    get_target_models\n\t                                ),\n\t                                kwds=(\n\t                                    {'batch_size': batch_size,\n\t                                     'device': torch.device(f'cuda:{num_gpu - i - 1}')\n\t                                     }\n\t                                )\n", "                                ) for i in range(num_gpu)\n\t               ]\n\t    pool.close()\n\t    pool.join()\n\t    # print(results)\n\t    # results = [list_mean([results[target_model_id][j] for j in range(len(results))])\n\t    #            for target_model_id in range(len(results[0]))]\n\t    # for i, model in enumerate(target_models):\n\t    #     print('-' * 100)\n\t    # print(model.__class__, model.model.__class__, results[i])\n", "    # print('-' * 100)\n\t    return results\n"]}
{"filename": "tester/__init__.py", "chunked_list": ["from .TestAcc import test_acc, test_autoattack_acc\n\tfrom .MembershipInference import most_similar"]}
{"filename": "tester/TestAcc.py", "chunked_list": ["import torch\n\tfrom torch.utils.data import DataLoader\n\tfrom torch import nn\n\tfrom tqdm import tqdm\n\t@torch.no_grad()\n\tdef test_acc(model: nn.Module, loader: DataLoader,\n\t             device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n\t    total_loss = 0\n\t    total_acc = 0\n\t    criterion = nn.CrossEntropyLoss().to(device)\n", "    model.to(device)\n\t    denominator = 0\n\t    for x, y in loader:\n\t        x, y = x.to(device), y.to(device)\n\t        pre = model(x)\n\t        total_loss += criterion(pre, y).item() * y.shape[0]\n\t        _, pre = torch.max(pre, dim=1)\n\t        total_acc += torch.sum((pre == y)).item()\n\t        denominator += y.shape[0]\n\t    test_loss = total_loss / denominator\n", "    test_accuracy = total_acc / denominator\n\t    print(f'loss = {test_loss}, acc = {test_accuracy}')\n\t    return test_loss, test_accuracy\n\tdef test_autoattack_acc(model: nn.Module, loader: DataLoader):\n\t    from autoattack import AutoAttack\n\t    adversary = AutoAttack(model, eps=8 / 255)\n\t    # adversary = AutoAttack(model, eps=0.01)\n\t    xs, ys = [], []\n\t    for x, y in tqdm(loader):\n\t        xs.append(x.cuda())\n", "        ys.append(y.cuda())\n\t    x = torch.concat(xs, dim=0)[:10]\n\t    y = torch.concat(ys, dim=0)[:10]\n\t    adversary.run_standard_evaluation(x, y, bs=1)\n"]}
