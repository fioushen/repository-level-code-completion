{"filename": "_metatune.py", "chunked_list": ["import inspect, copy\n\tfrom .baseline import BaseTuner, TrialCheckMixin\n\tfrom optuna.trial import Trial, FrozenTrial\n\tfrom .tune_regressor import regressor_search_space, regressor_tuner_model_class_map\n\tfrom .tune_classifier import classifier_search_space, classifier_tuner_model_class_map\n\tfrom .utils import make_default_tuner_type_mutable\n\tfrom typing import Iterable, Tuple, Dict, Union, Optional, Any, Callable\n\tclass MetaTune(TrialCheckMixin):\n\t    r\"\"\"\n\t        This class implements a sample utility for model and hyperparameter \n", "        sampling from customizable space\n\t        Parameters\n\t        ----------\n\t        task : str\n\t            Specifies the data modeling task 'regression' or 'classification'\n\t        custom_tuners: Optional[Iterable[BaseTuner]], default=None\n\t            Iterable of user defined tuners. The tuners in this list can either \n\t            be custom made by the user or one of the already existing tuners \n\t            available in this framework. This argument is especially useful if \n\t            you wish to change the default hyperparameter space of a given tuner,\n", "            you can import the tuner class from the designated module and overwite\n\t            the default hyperparameter space, this way, during hyperparameter \n\t            sampling, the sampler searchings through the custom space instead of \n\t            the default space::\n\t                from metatune.tune_classifier import NuSVCTuner\n\t                nusvc_tuner = NuSVCTuner(nu_space={\"low\":0.2, \"high\":1.0, \"step\":None, \"log\":False})\n\t                MetaTune(task=\"regression\", custom_tuners=[nusvc_tuner])\n\t        excluded : Optional[Iterable[Union[str, Callable]]], default=None\n\t            An iterable of str or callable type that specifies the list of tuners \n\t            of a given task to be exempted. This is especially useful if you have \n", "            identified beforehand that some models are not compatible with your \n\t            dataset.\n\t        custom_only : bool, default=False\n\t            Specifies if only custom tuners should be used for model and \n\t            hyperparameter sampling. This argument only applies if `custom_tuners`\n\t            is specified.\n\t        single_tuner: Optional[BaseTuner], default=None\n\t            If specified, only one tuner is used through out the sampling process, \n\t            inotherwords the sampling algorithm will only be sampling hyperparameters\n\t            for the specific tuner and no other.\n", "    \"\"\"\n\t    def __init__(\n\t            self, \n\t            task: str,\n\t            custom_tuners: Optional[Iterable[BaseTuner]]=None, \n\t            excluded: Optional[Iterable[Union[str, Callable]]]=None,\n\t            custom_only: bool=False, \n\t            single_tuner: Optional[BaseTuner]=None):\n\t        valid_tasks: Iterable[str] = [\"classification\", \"regression\"]\n\t        if task not in valid_tasks:\n", "            raise ValueError(\n\t                f\"Invalid task {task}, expects tasks to be 'regression' or 'classification', got {task}\")\n\t        self.task = task\n\t        self.custom_tuners = custom_tuners\n\t        self.excluded = excluded\n\t        self.custom_only = custom_only\n\t        self.single_tuner = single_tuner\n\t        if self.task == \"regression\":\n\t            self.search_space: Dict[str, BaseTuner] = copy.deepcopy(regressor_search_space)\n\t            self.tuner_model_class_map: Dict[str, Callable] = copy.deepcopy(regressor_tuner_model_class_map)\n", "        else:\n\t            self.search_space:  Dict[str, BaseTuner] = copy.deepcopy(classifier_search_space)\n\t            self.tuner_model_class_map: Dict[str, Callable] = copy.deepcopy(classifier_tuner_model_class_map)\n\t        self._exclude_tuners()\n\t        self._prepare_custom_tuners()\n\t        if self.single_tuner is not None:\n\t            self.search_space, self.tuner_model_class_map = self._get_single_tuner(self.single_tuner)\n\t    def _exclude_tuners(self):\n\t        if self.excluded is None: \n\t            return \n", "        for tuner_class in self.excluded:\n\t            if isinstance(tuner_class, Callable):\n\t                key = tuner_class.__name__\n\t            elif isinstance(tuner_class, str):\n\t                key = tuner_class\n\t            else:\n\t                raise ValueError(\n\t                    \"items of 'excluded' must either be of type str or Callable,\"\n\t                    \" corresponding to the class name or class of defined tuner to be excluded,\"\n\t                    f\" got {type(tuner_class)} instead\")\n", "            if key in self.search_space.keys():\n\t                self.search_space.pop(key)\n\t            if key in self.tuner_model_class_map.keys():\n\t                self.tuner_model_class_map.pop(key)\n\t    def _prepare_custom_tuners(self):\n\t        if not self.custom_tuners:\n\t            return\n\t        _search_space: Dict[str, BaseTuner] = {}\n\t        _tuner_model_class_map: Dict[str, Callable] = {}\n\t        for tuner in self.custom_tuners:\n", "            space, map_dict = self._get_single_tuner(tuner)\n\t            _search_space.update(space)\n\t            _tuner_model_class_map.update(map_dict)\n\t        if self.custom_only:\n\t            self.search_space: Dict[str, BaseTuner] = _search_space\n\t            self.tuner_model_class_map: Dict[str, Callable] = _tuner_model_class_map\n\t        else:\n\t            self.search_space.update(_search_space)\n\t            self.tuner_model_class_map.update(_tuner_model_class_map)\n\t    def _get_single_tuner(self, tuner: BaseTuner) -> Tuple[Dict[str, BaseTuner], Dict[str, Callable]]:\n", "        if tuner is None:\n\t            return\n\t        # by default some tuner attributes are of MappingProxyType objects. This wrapper was essential\n\t        # for sustaining the immutable nature of default class attributes of dataclasses, however we\n\t        # want to make these types mutable once more to avoid implementation issues.\n\t        tuner = make_default_tuner_type_mutable(tuner)\n\t        if not isinstance(tuner, BaseTuner):\n\t            raise ValueError(f\"{tuner} most be of type or extend from {BaseTuner}\")\n\t        _search_space: Dict[str, BaseTuner] = {tuner.__class__.__name__: tuner}\n\t        # check if tuner object name exists in the default self.tuner_model_class_map, \n", "        # if it does, it is a good indication that the custom tuner (BaseTuner type) is\n\t        # on that already exists in the system, whose default space parameters were \n\t        # probably edited by the user.\n\t        if tuner.__class__.__name__ in self.tuner_model_class_map.keys():\n\t            _tuner_model_class_map = {\n\t                tuner.__class__.__name__ : self.tuner_model_class_map[tuner.__class__.__name__]\n\t            }\n\t        # if tuner object name does not exist in the self.tuner_model_class_map, it indicates\n\t        # that the tuner (baseTuner type) is a custom tuner that is not part of the library of\n\t        # tuners in this framework. This tuner is expected to have a 'model_class' (Callable type) \n", "        # attribute which corresponds to the class of the model being tuned.\n\t        else:\n\t            if not hasattr(tuner, \"model_class\"):\n\t                raise AttributeError(\n\t                    F\"{tuner.__class__.__name__}() has no attribute 'model_class', which corresponds\"\n\t                    \" to the class implementation of the tuned model\")\n\t            if not isinstance(getattr(tuner, \"model_class\"), Callable):\n\t                    raise TypeError(\n\t                        f\"'model_class' attribute of {tuner.__class__.__name__}() is expected to be of type\"\n\t                        f\" Callable, got {type(getattr(tuner, 'model_class'))}\")\n", "            _tuner_model_class_map = {tuner.__class__.__name__: getattr(tuner, \"model_class\")}\n\t        return _search_space, _tuner_model_class_map\n\t    def only_compatible_with_data(self, X: Iterable, y: Iterable, probability_score: bool=False) -> Iterable[str]:\n\t        r\"\"\"\n\t        This method checks the tuners in the search space that are incompatible \n\t        with the given data, and automatically exludes them from the search space\n\t        and tuner model map. This way, during optuna sampling, less trials are \n\t        pruned\n\t        Note: \n\t            Calling this method is compulsory, as it may filter out tuners whose\n", "            corresponding models are compatible with your data, but have default\n\t            parameters that may lead to exceptions.\n\t        Parameters\n\t        ----------\n\t        X : Iterable | Array like of shape (n_samples, n_features)\n\t            Feature vectors or other representations of training data,\n\t            (preferably preprocessed)\n\t        y : Iterable | Array like of shape (n_samples, ) or (n_samples, labels)\n\t            Target values to predict, (preferably preprocessed)\n\t        probability_score : bool, default=True\n", "            use the `predict_proba(...)` method of the tuner `model_class` to\n\t            verify if `model_class` can output probability scores. Only useful\n\t            if `self.task=\"classification\"`\n\t        Return\n\t        ------\n\t        tuners: Iterable[str]\n\t            name of tuners that have been excluded due to incompatibility with data\n\t        \"\"\"\n\t        excluded = []\n\t        _tuner_names = list(self.tuner_model_class_map.keys())\n", "        for tuner_name in _tuner_names:\n\t            _model = self.tuner_model_class_map[tuner_name]()\n\t            if not hasattr(_model, \"fit\"):\n\t                raise AttributeError(\n\t                    f\"{_model} does not have method 'fit(...)'. This method is crucial and must be implemented\"\n\t                    \" in the model_class of your custom tuner\")\n\t            if not hasattr(_model, \"predict\"):\n\t                raise AttributeError(\n\t                    f\"{_model} does not have method 'predict(...)'. This method is crucial and must be implemented\"\n\t                    \" in the model_class of your custom tuner\")\n", "            try:\n\t                _model.fit(X, y)\n\t                _model.predict(X)\n\t                if probability_score:\n\t                    if self.task == \"classification\" and not hasattr(_model, \"predict_proba\"):\n\t                        raise AttributeError()\n\t            except Exception as e:\n\t                if tuner_name in self.search_space.keys():\n\t                    self.search_space.pop(tuner_name)\n\t                if tuner_name in self.tuner_model_class_map.keys():\n", "                    self.tuner_model_class_map.pop(tuner_name)\n\t                excluded.append(tuner_name)\n\t        if len(_tuner_names) == len(excluded):\n\t            raise Exception(\n\t                \"No tuner seems to be compatible with your data, ensure that your datatypes and format\"\n\t                \" are correct, no NaN values are present and all column vectors are numerical\")\n\t        return excluded\n\t    def sample_models_with_params(self, trial: Trial) -> Any:\n\t        r\"\"\"\n\t            This method samples a tuner corresponding to a model and samples the \n", "            corresponding hyperparameters from the search space defined in the tuner\n\t            that best optimizes an objective.\n\t            Parameters\n\t            ----------\n\t            trial : optuna.trial.Trial\n\t                optuna trial\n\t            Return\n\t            ------\n\t            model: Any\n\t                sampled model object initialised with sampled hyperparameters. \n", "                Note: model must implement `fit(...)` method.\n\t        \"\"\"\n\t        super().in_trial(trial)\n\t        tuner_name: str = trial.suggest_categorical(\"model_tuner\", list(self.search_space.keys()))\n\t        tuner: BaseTuner = self.search_space[tuner_name]\n\t        model = tuner.sample_model(trial)\n\t        return model\n\t    def build_sampled_model(self, best_trial: FrozenTrial, **kwargs) -> Any:\n\t        r\"\"\"\n\t            This method initialises a model corresponding to the sampled\n", "            tuner from the corresponding sampled parameters of the best \n\t            trial in the optuna study.\n\t            Parameters\n\t            ----------\n\t            best_trial : optuna.trial.FrozenTrial\n\t                best trial of the optuna study\n\t            kwargs (optional):\n\t                arguments corresponding model class of selected tuner\n\t            Return\n\t            ------\n", "            model: Any\n\t                sampled model object initialised with sampled hyperparameters. \n\t                Note: model must implement `fit(...)` method.\n\t        \"\"\"\n\t        tuner_name: str = best_trial.params[\"model_tuner\"]\n\t        model_class = self.tuner_model_class_map[tuner_name]\n\t        model_params_names = list(inspect.signature(model_class.__dict__[\"__init__\"]).parameters.keys())\n\t        best_params_dict = {\n\t            k.replace(f\"{tuner_name}_\", \"\") : v \n\t            for k, v in best_trial.params.items() \n", "            if k.replace(f\"{tuner_name}_\", \"\") in model_params_names\n\t            }\n\t        params = {**kwargs, **best_params_dict}\n\t        return model_class(**params)"]}
{"filename": "__init__.py", "chunked_list": ["from .tune_classifier import *\n\tfrom .tune_regressor import *\n\tfrom .baseline import *\n\tfrom ._metatune import *\n\tfrom typing import Iterable\n\t__all__: Iterable[str] = [\n\t    \"base\",\n\t    \"tests.test_tuners\",\n\t    \"tests.utils\",\n\t    \"ensemble_classifier\",\n", "    \"linear_model_classifier\",\n\t    \"mlp_classifier\",\n\t    \"naive_bayes_classifier\",\n\t    \"neighbor_classifier\",\n\t    \"svc\",\n\t    \"tree_classifier\"\n\t    \"ensemble_regressor\",\n\t    \"linear_model_regressor\",\n\t    \"mlp_regressor\",\n\t    \"neighbor_regressor\",\n", "    \"svr\",\n\t    \"tree_regressor\",\n\t    \"MetaTune\",\n\t    \"utils.module_utils\",\n\t]"]}
{"filename": "tune_regressor/tree_regressor.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Union, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n\t@dataclass\n\tclass DecisionTreeRegressorTuner(BaseTuner):\n\t    criterion_space: Iterable[str] = (\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\")\n\t    splitter_space: Iterable[str] = (\"best\", \"random\")\n", "    max_depth_space: Iterable[int] = MappingProxyType({\"low\":2, \"high\":1000, \"step\":1, \"log\":True})\n\t    min_samples_split_space: Dict[str, Any] = MappingProxyType({\"low\":1e-4, \"high\":1.0, \"step\":None, \"log\":True})\n\t    min_samples_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":1e-4, \"high\":1.0, \"step\":None, \"log\":True})\n\t    min_weight_fraction_leaf_space: Iterable[float] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    max_features_space: Iterable[Optional[str]] = (\"sqrt\", \"log2\", None)\n\t    random_state_space: Iterable[int] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    max_leaf_nodes_space: Iterable[int] = MappingProxyType({\"low\":2, \"high\":1000, \"step\":1, \"log\":True})\n\t    min_impurity_decrease_space: Iterable[float] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    ccp_alpha_space: Iterable[float] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n", "        super().sample_params(trial)\n\t        params = {}\n\t        params[\"criterion\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_criterion\", self.criterion_space)\n\t        params[\"splitter\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_splitter\", self.splitter_space)\n\t        params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n\t        if self.is_space_type(self.min_samples_split_space, float):\n\t            params[\"min_samples_split\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        else:\n\t            params[\"min_samples_split\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        if self.is_space_type(self.min_samples_leaf_space, float):\n", "            params[\"min_samples_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        else:\n\t            params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        params[\"min_weight_fraction_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_weight_fraction_leaf\", **dict(self.min_weight_fraction_leaf_space))\n\t        params[\"max_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_max_features\", self.max_features_space)\n\t        if params[\"splitter\"] == \"random\":\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        params[\"min_impurity_decrease\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_impurity_decrease\", **dict(self.min_impurity_decrease_space))\n\t        params[\"ccp_alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_ccp_alpha\", **dict(self.ccp_alpha_space))\n", "        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", DecisionTreeRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass ExtraTreeRegressorTuner(DecisionTreeRegressorTuner):\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n", "        return super(ExtraTreeRegressorTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super(DecisionTreeRegressorTuner, self).sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super(DecisionTreeRegressorTuner, self).evaluate_sampled_model(\"regression\", ExtraTreeRegressor, params)\n\t        self.model = model\n\t        return model"]}
{"filename": "tune_regressor/svr.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.svm import SVR, LinearSVR, NuSVR\n\t@dataclass\n\tclass SVRTuner(BaseTuner):\n\t    kernel_space: Iterable[str] = (\"linear\", \"poly\", \"rbf\", \"sigmoid\")\n\t    degree_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":5, \"step\":1, \"log\":False})\n", "    gamma_space: Iterable[str] = (\"scale\", \"auto\")\n\t    coef0_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    shrinking_space: Iterable[bool] = (True, )\n\t    epsilon_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"kernel\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_kernel\", self.kernel_space)\n", "        params[\"degree\"] = trial.suggest_int(f\"{self.__class__.__name__}_degree\", **dict(self.degree_space))\n\t        params[\"gamma\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_gamma\", self.gamma_space)\n\t        params[\"coef0\"] = trial.suggest_float(f\"{self.__class__.__name__}_coef0\", **dict(self.coef0_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"shrinking\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shrinking\", self.shrinking_space)\n\t        params[\"epsilon\"] = trial.suggest_float(f\"{self.__class__.__name__}_epsilon\", **dict(self.tol_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n", "        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", SVR, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass LinearSVRTuner(BaseTuner):\n\t    epsilon_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    loss_space: Iterable[str] = (\"epsilon_insensitive\", \"squared_epsilon_insensitive\")\n", "    fit_intercept_space: Iterable[bool] = (True, False)\n\t    intercept_scaling_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    dual_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":500, \"high\":2000, \"step\":1, \"log\":True})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"epsilon\"] = trial.suggest_float(f\"{self.__class__.__name__}_epsilon\", **dict(self.epsilon_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n", "        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"intercept_scaling\"] = trial.suggest_float(f\"{self.__class__.__name__}_intercept_scaling\", **dict(self.intercept_scaling_space))\n\t        params[\"dual\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_dual\", self.dual_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n", "        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", LinearSVR, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass NuSVRTuner(BaseTuner):\n\t    nu_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    kernel_space: Iterable[str] = (\"linear\", \"poly\", \"rbf\", \"sigmoid\")\n\t    degree_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":5, \"step\":1, \"log\":False})\n", "    gamma_space: Iterable[str] = (\"scale\", \"auto\")\n\t    coef0_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    shrinking_space: Iterable[bool] = (True, )\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"nu\"] = trial.suggest_float(f\"{self.__class__.__name__}_nu\", **dict(self.nu_space))\n\t        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"kernel\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_kernel\", self.kernel_space)\n", "        params[\"degree\"] = trial.suggest_int(f\"{self.__class__.__name__}_degree\", **dict(self.degree_space))\n\t        params[\"gamma\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_gamma\", self.gamma_space)\n\t        params[\"coef0\"] = trial.suggest_float(f\"{self.__class__.__name__}_coef0\", **dict(self.coef0_space))\n\t        params[\"shrinking\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shrinking\", self.shrinking_space)\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", NuSVR, params)\n", "        return model\n"]}
{"filename": "tune_regressor/ensemble_regressor.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Union, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.ensemble import (\n\t    RandomForestRegressor, \n\t    ExtraTreesRegressor, \n\t    AdaBoostRegressor, \n\t    GradientBoostingRegressor, \n", "    BaggingRegressor, \n\t    HistGradientBoostingRegressor,\n\t)\n\tfrom ..tune_classifier import BaggingClassifierTuner\n\t@dataclass\n\tclass RandomForestRegressorTuner(BaseTuner):\n\t    n_estimators_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":200, \"step\":1, \"log\":True})\n\t    criterion_space: Iterable[str] = (\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\")\n\t    set_max_depth_space: Iterable[bool] = (True, False)\n\t    max_depth_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":2000, \"step\":1, \"log\":True})\n", "    min_samples_split_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    min_samples_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    min_weight_fraction_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    max_features_space: Iterable[str] = (\"sqrt\", \"log2\", None)\n\t    set_max_leaf_nodes_space: Iterable[bool] = (True, False)\n\t    max_leaf_nodes_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":10000, \"step\":1, \"log\":True})\n\t    min_impurity_decrease_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    bootstrap_space: Iterable[bool] = (True, False)\n\t    oob_score_space: Iterable[bool] = (True, False)\n\t    set_random_state_space: Iterable[bool] = (False, )\n", "    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    ccp_alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    set_max_samples_space: Iterable[bool] = (True, False)\n\t    max_samples_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"n_estimators\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_estimators\", **dict(self.n_estimators_space))\n\t        params[\"criterion\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_criterion\", self.criterion_space)\n\t        set_max_depth = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_depth\", self.set_max_depth_space)\n", "        if set_max_depth:\n\t            params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n\t        if self.is_space_type(self.min_samples_split_space, float):\n\t            params[\"min_samples_split\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        else:\n\t            params[\"min_samples_split\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        if self.is_space_type(self.min_samples_leaf_space, float):\n\t            params[\"min_samples_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        else:\n\t            params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n", "        params[\"min_weight_fraction_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_weight_fraction_leaf\", **dict(self.min_weight_fraction_leaf_space))\n\t        if self.is_valid_categorical_space(self.max_features_space):\n\t            params[\"max_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_max_features\", self.max_features_space)\n\t        else:\n\t            if self.is_valid_float_space(self.max_features_space):\n\t                params[\"max_features\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t            else:\n\t                params[\"max_features\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t        set_max_leaf_node = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_leaf_nodes\", self.set_max_leaf_nodes_space)\n\t        if set_max_leaf_node:\n", "            params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        params[\"min_impurity_decrease\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_impurity_decrease\", **dict(self.min_impurity_decrease_space))\n\t        params[\"bootstrap\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_bootstrap\", self.bootstrap_space)\n\t        params[\"oob_score\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_oob_score\", self.oob_score_space)\n\t        set_random_state = trial.suggest_categorical(f\"{self.__class__.__name__}_set_random_state\", self.set_random_state_space)\n\t        if set_random_state:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"ccp_alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_ccp_alpha\", **dict(self.ccp_alpha_space))\n\t        set_max_samples = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_samples\", self.set_max_samples_space)\n\t        if set_max_samples:\n", "            if self.is_space_type(self.max_samples_space, float):\n\t                params[\"max_samples\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_samples\", **dict(self.max_samples_space))\n\t            else:\n\t                params[\"max_samples\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_samples\", **dict(self.max_samples_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", RandomForestRegressor, params)\n\t        self.model = model\n", "        return model\n\t@dataclass\n\tclass ExtraTreesRegressorTuner(RandomForestRegressorTuner):\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        return super(ExtraTreesRegressorTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super(RandomForestRegressorTuner, self).sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super(RandomForestRegressorTuner, self).evaluate_sampled_model(\"regression\", ExtraTreesRegressor, params)\n\t        self.model = model\n", "        return model\n\t@dataclass\n\tclass AdaBoostRegressorTuner(BaseTuner):\n\t    estimator_space: Iterable[Optional[object]] = (None, )\n\t    n_estimators_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":200, \"step\":1, \"log\":True})\n\t    learning_rate_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1, \"step\":None, \"log\":True})\n\t    loss_space: Iterable[str] = (\"linear\", \"square\", \"exponential\")\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n", "        params = {}\n\t        params[\"estimator\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_estimator\", self.estimator_space)\n\t        params[\"n_estimators\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_estimators\", **dict(self.n_estimators_space))\n\t        params[\"learning_rate\"] = trial.suggest_float(f\"{self.__class__.__name__}_learning_rate\", **dict(self.learning_rate_space))\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = super().evaluate_sampled_model(\"regression\", AdaBoostRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass GradientBoostingRegressorTuner(BaseTuner):\n\t    loss_space: Iterable[str] = (\"squared_error\", \"absolute_error\", \"huber\", \"quantile\")\n\t    learning_rate_space: Dict[str, Any] = MappingProxyType({\"low\":0.001, \"high\":1.0, \"step\":None, \"log\":True})\n\t    n_estimators_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    subsample_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    criterion_space: Iterable[str] = (\"friedman_mse\", \"squared_error\")\n", "    min_samples_split_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    min_samples_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    min_weight_fraction_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    set_max_depth_space: Iterable[bool] = (True, False)\n\t    max_depth_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":2000, \"step\":1, \"log\":True})\n\t    min_impurity_decrease_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    init_space: Iterable[Optional[object]] = (None, )\n\t    max_features_space: Iterable[str] = (\"sqrt\", \"log2\")\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1, \"step\":None, \"log\":True})\n\t    set_max_leaf_nodes_space: Iterable[bool] = (True, False)\n", "    max_leaf_nodes_space: Iterable[Optional[int]] = MappingProxyType({\"low\":2, \"high\":10000, \"step\":1, \"log\":True})\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    set_n_iter_no_change_space: Iterable[bool] = (True, False)\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    ccp_alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n", "        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"learning_rate\"] = trial.suggest_float(f\"{self.__class__.__name__}_learning_rate\", **dict(self.learning_rate_space))\n\t        params[\"n_estimators\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_estimators\", **dict(self.n_estimators_space))\n\t        params[\"subsample\"] = trial.suggest_float(f\"{self.__class__.__name__}_subsample\", **dict(self.subsample_space))\n\t        params[\"criterion\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_criterion\", self.criterion_space)\n\t        if self.is_space_type(self.min_samples_split_space, float):\n\t            params[\"min_samples_split\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        else:\n\t            params[\"min_samples_split\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        if self.is_space_type(self.min_samples_leaf_space, float):\n", "            params[\"min_samples_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        else:\n\t            params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        params[\"min_weight_fraction_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_weight_fraction_leaf\", **dict(self.min_weight_fraction_leaf_space))\n\t        set_max_depth = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_depth\", self.set_max_depth_space)\n\t        if set_max_depth:\n\t            params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n\t        params[\"min_impurity_decrease\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_impurity_decrease\", **dict(self.min_impurity_decrease_space))\n\t        params[\"init\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_init\", self.init_space)\n\t        if self.is_valid_categorical_space(self.max_features_space):\n", "            params[\"max_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_max_features\", self.max_features_space)\n\t        else:\n\t            if self.is_valid_float_space(self.max_features_space):\n\t                params[\"max_features\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t            else:\n\t                params[\"max_features\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t        set_max_leaf_nodes = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_leaf_nodes\", self.set_max_leaf_nodes_space)\n\t        if set_max_leaf_nodes:\n\t            params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n", "        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n\t        set_n_iter_no_change = trial.suggest_categorical(f\"{self.__class__.__name__}_set_n_iter_no_change\", self.set_n_iter_no_change_space)\n\t        if set_n_iter_no_change:\n\t            params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"ccp_alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_ccp_alpha\", **dict(self.ccp_alpha_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n", "        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", GradientBoostingRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass BaggingRegressorTuner(BaggingClassifierTuner):\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        return super(BaggingRegressorTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super(BaggingClassifierTuner, self).sample_model(trial)\n", "        params = self.sample_params(trial)\n\t        model = super(BaggingClassifierTuner, self).evaluate_sampled_model(\"regression\", BaggingRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass HistGradientBoostingRegressorTuner(BaseTuner):\n\t    loss_space: Iterable[str] = (\"squared_error\", \"absolute_error\", \"poisson\", \"quantile\")\n\t    quantile_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    learning_rate_space: Dict[str, Any] = MappingProxyType({\"low\":0.001, \"high\":1.0, \"step\":None, \"log\":True})\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":1000, \"step\":1, \"log\":True})\n", "    set_max_leaf_nodes_space: Iterable[bool] = (True, False)\n\t    max_leaf_nodes_space: Iterable[Optional[int]] = MappingProxyType({\"low\":2, \"high\":10000, \"step\":1, \"log\":True})\n\t    set_max_depth_space: Iterable[bool] = (True, False)\n\t    max_depth_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":2000, \"step\":1, \"log\":True})\n\t    min_samples_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":200, \"step\":1, \"log\":True})\n\t    l2_regularization_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    max_bins_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":255, \"step\":1, \"log\":True})\n\t    categorical_features_space: Iterable[Any] = (None, )\n\t    monotonic_cst_space: Iterable[Any] = (None, )\n\t    interaction_cst_space: Iterable[Any] = (None, )\n", "    early_stopping_space: Iterable[bool] = (\"auto\", True, False)\n\t    scoring_space: Iterable[Optional[Union[str, Callable]]] = (\"loss\", None)\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n", "        if params[\"loss\"] == \"quantile\":\n\t            params[\"quantile\"] = trial.suggest_float(f\"{self.__class__.__name__}_quantile\", **dict(self.quantile_space))\n\t        params[\"learning_rate\"] = trial.suggest_float(f\"{self.__class__.__name__}_learning_rate\", **dict(self.learning_rate_space))\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        set_max_leaf_nodes = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_leaf_nodes\", self.set_max_leaf_nodes_space)\n\t        if set_max_leaf_nodes:\n\t            params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        set_max_depth = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_depth\", self.set_max_depth_space)\n\t        if set_max_depth:\n\t            params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n", "        params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        params[\"l2_regularization\"] = trial.suggest_float(f\"{self.__class__.__name__}_l2_regularization\", **dict(self.l2_regularization_space))\n\t        params[\"max_bins\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_bins\", **dict(self.max_bins_space))\n\t        params[\"categorical_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_categorical_features\", self.categorical_features_space)\n\t        params[\"monotonic_cst\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_monotonic_cst\", self.monotonic_cst_space)\n\t        params[\"interaction_cst\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_interaction_cst\", self.interaction_cst_space)\n\t        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n\t        params[\"scoring\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_scoring\", self.scoring_space)\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n\t        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n", "        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", HistGradientBoostingRegressor, params)\n\t        self.model = model\n\t        return model\n"]}
{"filename": "tune_regressor/__init__.py", "chunked_list": ["from ..utils import make_default_tuner_type_mutable\n\tfrom .svr import *\n\tfrom .tree_regressor import *\n\tfrom .linear_model_regressor import *\n\tfrom .ensemble_regressor import *\n\tfrom .neighbor_regressor import *\n\tfrom .mlp_regressor import *\n\tfrom typing import Iterable, Dict, Callable\n\tregressor_tuner_model_class_map: Dict[str, Callable] = {\n\t    SVRTuner.__name__: SVR,\n", "    LinearSVRTuner.__name__: LinearSVR,\n\t    NuSVRTuner.__name__: NuSVR,\n\t    DecisionTreeRegressorTuner.__name__: DecisionTreeRegressor,\n\t    ExtraTreeRegressorTuner.__name__: ExtraTreeRegressor,\n\t    LinearRegressionTuner.__name__: LinearRegression,\n\t    LassoTuner.__name__: Lasso,\n\t    RidgeTuner.__name__: Ridge,\n\t    ElasticNetTuner.__name__: ElasticNet,\n\t    MultiTaskLassoTuner.__name__: MultiTaskLasso,\n\t    MultiTaskElasticNetTuner.__name__: MultiTaskElasticNet,\n", "    LarsTuner.__name__: Lars,\n\t    LassoLarsTuner.__name__: LassoLars,\n\t    LassoLarsICTuner.__name__: LassoLarsIC,\n\t    PassiveAggressiveRegressorTuner.__name__: PassiveAggressiveRegressor,\n\t    QuantileRegressorTuner.__name__: QuantileRegressor,\n\t    SGDRegressorTuner.__name__: SGDRegressor,\n\t    BayesianRidgeTuner.__name__: BayesianRidge,\n\t    OrthogonalMatchingPursuitTuner.__name__: OrthogonalMatchingPursuit,\n\t    PoissonRegressorTuner.__name__: PoissonRegressor,\n\t    GammaRegressorTuner.__name__: GammaRegressor,\n", "    TweedieRegressorTuner.__name__: TweedieRegressor,\n\t    HuberRegressorTuner.__name__: HuberRegressor,\n\t    TheilSenRegressorTuner.__name__: TheilSenRegressor,\n\t    ARDRegressionTuner.__name__: ARDRegression,\n\t    RANSACRegressorTuner.__name__: RANSACRegressor,\n\t    RandomForestRegressorTuner.__name__: RandomForestRegressor,\n\t    ExtraTreesRegressorTuner.__name__: ExtraTreesRegressor,\n\t    AdaBoostRegressorTuner.__name__: AdaBoostRegressor,\n\t    GradientBoostingRegressorTuner.__name__: GradientBoostingRegressor,\n\t    BaggingRegressorTuner.__name__: BaggingRegressor,\n", "    HistGradientBoostingRegressorTuner.__name__: HistGradientBoostingRegressor,\n\t    KNeighborsRegressorTuner.__name__: KNeighborsRegressor,\n\t    RadiusNeighborsRegressorTuner.__name__: RadiusNeighborsRegressor,\n\t    MLPRegressorTuner.__name__: MLPRegressor,\n\t}\n\tregressor_search_space: Dict[str, BaseTuner] = {\n\t    SVRTuner.__name__: SVRTuner(),\n\t    LinearSVRTuner.__name__: LinearSVRTuner(),\n\t    NuSVRTuner.__name__: NuSVRTuner(),\n\t    DecisionTreeRegressorTuner.__name__: DecisionTreeRegressorTuner(),\n", "    ExtraTreeRegressorTuner.__name__: ExtraTreeRegressorTuner(),\n\t    LinearRegressionTuner.__name__: LinearRegressionTuner(),\n\t    LassoTuner.__name__: LassoTuner(),\n\t    RidgeTuner.__name__: RidgeTuner(),\n\t    ElasticNetTuner.__name__: ElasticNetTuner(),\n\t    MultiTaskLassoTuner.__name__: MultiTaskLassoTuner(),\n\t    MultiTaskElasticNetTuner.__name__: MultiTaskElasticNetTuner(),\n\t    LarsTuner.__name__: LarsTuner(),\n\t    LassoLarsTuner.__name__: LassoLarsTuner(),\n\t    LassoLarsICTuner.__name__: LassoLarsICTuner(),\n", "    PassiveAggressiveRegressorTuner.__name__: PassiveAggressiveRegressorTuner(),\n\t    QuantileRegressorTuner.__name__: QuantileRegressorTuner(),\n\t    SGDRegressorTuner.__name__: SGDRegressorTuner(),\n\t    BayesianRidgeTuner.__name__: BayesianRidgeTuner(),\n\t    OrthogonalMatchingPursuitTuner.__name__: OrthogonalMatchingPursuitTuner(),\n\t    PoissonRegressorTuner.__name__: PoissonRegressorTuner(),\n\t    GammaRegressorTuner.__name__: GammaRegressorTuner(),\n\t    TweedieRegressorTuner.__name__: TweedieRegressorTuner(),\n\t    HuberRegressorTuner.__name__: HuberRegressorTuner(),\n\t    TheilSenRegressorTuner.__name__: TheilSenRegressorTuner(),\n", "    ARDRegressionTuner.__name__: ARDRegressionTuner(),\n\t    RANSACRegressorTuner.__name__: RANSACRegressorTuner(),\n\t    RandomForestRegressorTuner.__name__: RandomForestRegressorTuner(),\n\t    ExtraTreesRegressorTuner.__name__: ExtraTreesRegressorTuner(),\n\t    AdaBoostRegressorTuner.__name__: AdaBoostRegressorTuner(),\n\t    GradientBoostingRegressorTuner.__name__: GradientBoostingRegressorTuner(),\n\t    BaggingRegressorTuner.__name__: BaggingRegressorTuner(),\n\t    HistGradientBoostingRegressorTuner.__name__: HistGradientBoostingRegressorTuner(),\n\t    KNeighborsRegressorTuner.__name__: KNeighborsRegressorTuner(),\n\t    RadiusNeighborsRegressorTuner.__name__: RadiusNeighborsRegressorTuner(),\n", "    MLPRegressorTuner.__name__: MLPRegressorTuner(),\n\t}\n\tregressor_search_space: Dict[str, BaseTuner] = dict(\n\t    map(lambda pair : (pair[0], make_default_tuner_type_mutable(pair[1])), regressor_search_space.items())\n\t)\n\t__all__: Iterable[str] = [\n\t    \"regressor_tuner_model_class_map\",\n\t    \"regressor_search_space\",\n\t    \"SVRTuner\", \n\t    \"LinearSVRTuner\", \n", "    \"NuSVRTuner\", \n\t    \"DecisionTreeRegressorTuner\", \n\t    \"ExtraTreeRegressorTuner\", \n\t    \"LinearRegressionTuner\", \n\t    \"LassoTuner\", \n\t    \"RidgeTuner\", \n\t    \"ElasticNetTuner\", \n\t    \"MultiTaskLassoTuner\", \n\t    \"MultiTaskElasticNetTuner\", \n\t    \"LarsTuner\", \n", "    \"LassoLarsTuner\", \n\t    \"LassoLarsICTuner\", \n\t    \"PassiveAggressiveRegressorTuner\", \n\t    \"QuantileRegressorTuner\", \n\t    \"SGDRegressorTuner\", \n\t    \"BayesianRidgeTuner\", \n\t    \"OrthogonalMatchingPursuitTuner\", \n\t    \"PoissonRegressorTuner\", \n\t    \"GammaRegressorTuner\", \n\t    \"TweedieRegressorTuner\", \n", "    \"RandomForestRegressorTuner\", \n\t    \"ExtraTreesRegressorTuner\", \n\t    \"AdaBoostRegressorTuner\", \n\t    \"GradientBoostingRegressorTuner\", \n\t    \"BaggingRegressorTuner\", \n\t    \"HistGradientBoostingRegressorTuner\", \n\t    \"KNeighborsRegressorTuner\", \n\t    \"MLPRegressorTuner\",\n\t    \"RadiusNeighborsRegressorTuner\"\n\t]"]}
{"filename": "tune_regressor/neighbor_regressor.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n\tfrom ..tune_classifier import KNeighborsClassifierTuner\n\t@dataclass\n\tclass KNeighborsRegressorTuner(KNeighborsClassifierTuner):\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n", "        return super(KNeighborsRegressorTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super(KNeighborsClassifierTuner, self).sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super(KNeighborsClassifierTuner, self).evaluate_sampled_model(\"regression\", KNeighborsRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass RadiusNeighborsRegressorTuner(BaseTuner):\n\t    radius_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":20, \"step\":1, \"log\":False})\n", "    weight_space: Iterable[str] = (\"uniform\", \"distance\")\n\t    algorithm_space: Iterable[str] = (\"ball_tree\", \"kd_tree\", \"brute\")\n\t    leaf_size_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":100, \"step\":1, \"log\":True})\n\t    p_space: Dict[str, Any] = MappingProxyType({\"low\":3, \"high\":10, \"step\":1, \"log\":False})\n\t    metric_space: Iterable[str] = (\"cityblock\", \"cosine\", \"euclidean\", \"manhattan\", \"minkowski\")\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"radius\"] = trial.suggest_int(f\"{self.__class__.__name__}_radius\", **dict(self.radius_space))\n\t        params[\"weights\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_weight\", self.weight_space)\n", "        params[\"algorithm\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_algorithm\", self.algorithm_space)\n\t        params[\"leaf_size\"] = trial.suggest_int(f\"{self.__class__.__name__}_leaf_size\", **dict(self.leaf_size_space))\n\t        params[\"p\"] = trial.suggest_int(f\"{self.__class__.__name__}_p\", **dict(self.p_space))\n\t        params[\"metric\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_metric\", self.metric_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", RadiusNeighborsRegressor, params)\n\t        self.model = model\n", "        return model"]}
{"filename": "tune_regressor/linear_model_regressor.py", "chunked_list": ["import numpy as np\n\tfrom ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass, field\n\tfrom typing import Iterable, Optional, Dict, Any, Union, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.linear_model import (\n\t    LinearRegression,\n\t    Lasso, \n\t    Ridge, \n", "    ElasticNet, \n\t    MultiTaskLasso, \n\t    MultiTaskElasticNet, \n\t    Lars,\n\t    LassoLars,\n\t    LassoLarsIC,\n\t    HuberRegressor, \n\t    TheilSenRegressor,\n\t    BayesianRidge,\n\t    OrthogonalMatchingPursuit,\n", "    ARDRegression,\n\t    PassiveAggressiveRegressor,\n\t    QuantileRegressor,\n\t    SGDRegressor, \n\t    RANSACRegressor, \n\t    PoissonRegressor, \n\t    GammaRegressor, \n\t    TweedieRegressor)\n\tfrom sklearn.base import RegressorMixin, BaseEstimator \n\t@dataclass\n", "class LinearRegressionTuner(BaseTuner):\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    positive_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"positive\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_positive\", self.positive_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n", "        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", LinearRegression, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass LassoTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1.0, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n", "    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    positive_space: Iterable[bool] = (True, False)\n\t    selection_space: Iterable[str] = (\"cyclic\", \"random\")\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n", "        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"positive\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_positive\", self.positive_space)\n\t        params[\"selection\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_selection\", self.selection_space)\n\t        if params[\"selection\"] == \"random\":\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", Lasso, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass RidgeTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1.0, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    solver_space: Iterable[str] = (\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\", \"lbfgs\")\n\t    positive_space: Iterable[bool] = (True, False)\n", "    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"positive\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_positive\", self.positive_space)\n\t        params[\"solver\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver\", self.solver_space)\n", "        if params[\"solver\"] in [\"sag\", \"saga\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))  \n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", Ridge, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n", "class ElasticNetTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1.0, \"step\":None, \"log\":True})\n\t    l1_ratio_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    precompute_space: Iterable[Union[bool, Iterable]] = (True, False, )\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    positive_space: Iterable[bool] = (True, False)\n\t    selection_space: Iterable[str] = (\"cyclic\", \"random\")\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n", "    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"l1_ratio\"] = trial.suggest_float(f\"{self.__class__.__name__}_l1_ratio\", **dict(self.l1_ratio_space))\n\t        params[\"precompute\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_precompute\", self.precompute_space)\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"positive\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_positive\", self.positive_space)\n", "        params[\"selection\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_selection\", self.selection_space)\n\t        if params[\"selection\"] == \"random\":\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", ElasticNet, params)\n\t        self.model = model\n\t        return model\n", "@dataclass\n\tclass MultiTaskLassoTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1.0, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    selection_space: Iterable[str] = (\"cyclic\", \"random\")\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    is_multitask: str = field(init=False, default=True)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n", "        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"selection\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_selection\", self.selection_space)\n\t        if params[\"selection\"] == \"random\":\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n", "    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", MultiTaskLasso, params, is_multitask=self.is_multitask)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass MultiTaskElasticNetTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1.0, \"step\":None, \"log\":True})\n\t    l1_ratio_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n", "    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    selection_space: Iterable[str] = (\"cyclic\", \"random\")\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    is_multitask: str = field(init=False, default=True)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n", "        params[\"l1_ratio\"] = trial.suggest_float(f\"{self.__class__.__name__}_l1_ratio\", **dict(self.l1_ratio_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"selection\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_selection\", self.selection_space)\n\t        if params[\"selection\"] == \"random\":\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n", "        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\n\t            \"regression\", MultiTaskElasticNet, params, is_multitask=self.is_multitask)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass LarsTuner(BaseTuner):\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    precompute_space: Iterable[bool] = (True, False)\n\t    n_nonzero_coefs_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":500, \"step\":1, \"log\":True})\n", "    eps_space: Dict[str, Any] = MappingProxyType({\"low\":np.finfo(float).eps, \"high\":1e-10, \"step\":None, \"log\":True})\n\t    set_jitter_space: Iterable[bool] = (True, False)\n\t    jitter_space: Dict[str, Any] = MappingProxyType({\"low\":1e-8, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"precompute\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_precompute\", self.precompute_space)\n\t        params[\"n_nonzero_coefs\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_nonzero_coefs\", **dict(self.n_nonzero_coefs_space))\n", "        params[\"eps\"] = trial.suggest_float(f\"{self.__class__.__name__}_eps\", **dict(self.eps_space))\n\t        set_jitter = trial.suggest_categorical(f\"{self.__class__.__name__}_set_jitter\", self.set_jitter_space)\n\t        if set_jitter:\n\t            params[\"jitter\"] = trial.suggest_float(f\"{self.__class__.__name__}_jitter\", **dict(self.jitter_space))\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", Lars, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass LassoLarsTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    precompute_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n\t    eps_space: Dict[str, Any] = MappingProxyType({\"low\":np.finfo(float).eps, \"high\":1e-10, \"step\":None, \"log\":True})\n\t    positive_space: Iterable[bool] = (True, False)\n", "    set_jitter_space: Iterable[bool] = (True, False)\n\t    jitter_space: Dict[str, Any] = MappingProxyType({\"low\":1e-8, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"precompute\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_precompute\", self.precompute_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n", "        params[\"eps\"] = trial.suggest_float(f\"{self.__class__.__name__}_eps\", **dict(self.eps_space))\n\t        params[\"positive\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_positive\", self.positive_space)\n\t        set_jitter = trial.suggest_categorical(f\"{self.__class__.__name__}_set_jitter\", self.set_jitter_space)\n\t        if set_jitter:\n\t            params[\"jitter\"] = trial.suggest_float(f\"{self.__class__.__name__}_jitter\", **dict(self.jitter_space))\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = super().evaluate_sampled_model(\"regression\", LassoLars, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass LassoLarsICTuner(BaseTuner):\n\t    criterion_sapce: Iterable[str] = (\"aic\", \"bic\")\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    precompute_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n\t    eps_space: Dict[str, Any] = MappingProxyType({\"low\":np.finfo(float).eps, \"high\":1e-10, \"step\":None, \"log\":True})\n", "    positive_space: Iterable[bool] = (True, False)\n\t    set_noise_variance_space: Iterable[bool] = (True, False)\n\t    noise_variance_space: Dict[str, Any] = MappingProxyType({\"low\":1e-8, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"criterion\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_criterion\", self.criterion_sapce)\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"precompute\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_precompute\", self.precompute_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n", "        params[\"eps\"] = trial.suggest_float(f\"{self.__class__.__name__}_eps\", **dict(self.eps_space))\n\t        params[\"positive\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_positive\", self.positive_space)\n\t        set_noise_variance = trial.suggest_categorical(f\"{self.__class__.__name__}_set_noise_variance\", self.set_noise_variance_space)\n\t        if set_noise_variance:\n\t            params[\"noise_variance\"] = trial.suggest_float(f\"{self.__class__.__name__}_noise_variance\", **dict(self.noise_variance_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", LassoLarsIC, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass BayesianRidgeTuner(BaseTuner):\n\t    n_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    alpha_1_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    alpha_2_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    lambda_1_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    lambda_2_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n", "    set_alpha_init_space: Iterable[bool] = (True, False)\n\t    alpha_init_space: Iterable[bool] = MappingProxyType({\"low\":1e-8, \"high\":1.0, \"step\":None, \"log\":True})\n\t    lambda_init_space: Dict[str, Any] = MappingProxyType({\"low\":1e-8, \"high\":1.0, \"step\":None, \"log\":True})\n\t    compute_score_space: Iterable[bool] = (True, False)\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"n_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter\", **dict(self.n_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n", "        params[\"alpha_1\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha_1\", **dict(self.alpha_1_space))\n\t        params[\"alpha_2\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha_2\", **dict(self.alpha_2_space))\n\t        params[\"lambda_1\"] = trial.suggest_float(f\"{self.__class__.__name__}_lambda_1\", **dict(self.lambda_1_space))\n\t        params[\"lambda_2\"] = trial.suggest_float(f\"{self.__class__.__name__}_lambda_2\", **dict(self.lambda_2_space))\n\t        set_alpha_init = trial.suggest_categorical(f\"{self.__class__.__name__}_set_alpha_init\", self.set_alpha_init_space)\n\t        if set_alpha_init:\n\t            params[\"alpha_init\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha_init\", **dict(self.alpha_init_space))\n\t        params[\"lambda_init\"] = trial.suggest_float(f\"{self.__class__.__name__}_lambda_init\", **dict(self.lambda_init_space))\n\t        params[\"compute_score\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_compute_score\", self.compute_score_space)\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n", "        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", BayesianRidge, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass ARDRegressionTuner(BaseTuner):\n\t    n_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n", "    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    alpha_1_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    alpha_2_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    lambda_1_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    lambda_2_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    threshold_lambda_space: Dict[str, Any] = MappingProxyType({\"low\":1e3, \"high\":1e5, \"step\":None, \"log\":True})\n\t    compute_score_space: Iterable[bool] = (True, False)\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n", "        params = {}\n\t        params[\"n_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter\", **dict(self.n_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"alpha_1\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha_1\", **dict(self.alpha_1_space))\n\t        params[\"alpha_2\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha_2\", **dict(self.alpha_2_space))\n\t        params[\"lambda_1\"] = trial.suggest_float(f\"{self.__class__.__name__}_lambda_1\", **dict(self.lambda_1_space))\n\t        params[\"lambda_2\"] = trial.suggest_float(f\"{self.__class__.__name__}_lambda_2\", **dict(self.lambda_2_space))        \n\t        params[\"threshold_lambda\"] = trial.suggest_float(f\"{self.__class__.__name__}_threshold_lambda\", **dict(self.threshold_lambda_space))\n\t        params[\"compute_score\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_compute_score\", self.compute_score_space)\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n", "        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", ARDRegression, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass OrthogonalMatchingPursuitTuner(BaseTuner):\n\t    set_nonzero_coefs_space: Iterable[bool] = (True, False)\n", "    n_nonzero_coefs_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":500, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    precompute_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        set_nonzero_coefs = trial.suggest_categorical(f\"{self.__class__.__name__}_set_nonzero_coefs\", self.set_nonzero_coefs_space)\n\t        if set_nonzero_coefs:\n\t            params[\"n_nonzero_coefs\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_nonzero_coefs\", **dict(self.n_nonzero_coefs_space))\n", "        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"precompute\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_precompute\", self.precompute_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", OrthogonalMatchingPursuit, params)\n\t        self.model = model\n\t        return model\n", "@dataclass\n\tclass PassiveAggressiveRegressorTuner(BaseTuner):\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.9, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    early_stopping_space: Iterable[bool] = (True, False)\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":False})\n\t    shuffle_space: Iterable[bool] = (True, False)\n", "    loss_space: Iterable[str] = (\"epsilon_insensitive\", )\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    epsilon_space: Dict[str, Any] = MappingProxyType({\"low\":0.05, \"high\":0.5, \"step\":None, \"log\":True})\n\t    average_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n", "        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n\t        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t        params[\"shuffle\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shuffle\", self.shuffle_space)\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        if params[\"shuffle\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"epsilon\"] = trial.suggest_float(f\"{self.__class__.__name__}_epsilon\", **dict(self.epsilon_space))\n\t        params[\"average\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_average\", self.average_space)\n", "        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", PassiveAggressiveRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass QuantileRegressorTuner(BaseTuner):\n\t    quantile_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n", "    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1.0, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    solver_space: Iterable[str] = (\"highs-ds\", \"highs-ipm\", \"highs\", \"revised simplex\")\n\t    solver_options_space: Iterable[Optional[Dict[str, Any]]] = (None, )\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"quantile\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.quantile_space))\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n", "        params[\"solver\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver\", self.solver_space)\n\t        params[\"solver_options\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver_options\", self.solver_options_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", QuantileRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n", "class SGDRegressorTuner(BaseTuner):\n\t    loss_space: Iterable[str] = (\n\t        \"squared_error\", \n\t        \"huber\", \n\t        \"epsilon_insensitive\", \n\t        \"squared_epsilon_insensitive\")\n\t    penalty_space: Iterable[str] = (\"l1\", \"l2\", \"elasticnet\", None)\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":1.0, \"step\":None, \"log\":True})\n\t    l1_ratio_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n", "    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    shuffle_space: Iterable[bool] = (True, False)\n\t    epsilon_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    learning_rate_space: Iterable[str] = (\"constant\", \"optimal\", \"invscaling\", \"adaptive\")\n\t    eta0_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    power_t_space: Dict[str, Any] = MappingProxyType({\"low\":-1.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    early_stopping_space: Iterable[bool] = (True, False)\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n", "    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":False})\n\t    average_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"penalty\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_penalty\", self.penalty_space)\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"l1_ratio\"] = trial.suggest_float(f\"{self.__class__.__name__}_l1_ratio\", **dict(self.l1_ratio_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n", "        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"shuffle\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shuffle\", self.shuffle_space)\n\t        params[\"epsilon\"] = trial.suggest_float(f\"{self.__class__.__name__}_epsilon\", **dict(self.epsilon_space))\n\t        if params[\"shuffle\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"learning_rate\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_learning_rate\", self.learning_rate_space)\n\t        params[\"eta0\"] = trial.suggest_float(f\"{self.__class__.__name__}_eta0\", **dict(self.eta0_space))\n\t        params[\"power_t\"] = trial.suggest_float(f\"{self.__class__.__name__}_power_t\", **dict(self.power_t_space))\n\t        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n", "        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n\t        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t        params[\"average\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_average\", self.average_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", SGDRegressor, params)\n\t        self.model = model\n\t        return model\n", "@dataclass\n\tclass PoissonRegressorTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":1.0, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    solver_space: Iterable[str] = (\"lbfgs\", \"newton-cholesky\")\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n", "        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"solver\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver\", self.solver_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", PoissonRegressor, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass GammaRegressorTuner(PoissonRegressorTuner):\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        return super(GammaRegressorTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super(PoissonRegressorTuner, self).sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super(PoissonRegressorTuner, self).evaluate_sampled_model(\"regression\", GammaRegressor, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass TweedieRegressorTuner(BaseTuner):\n\t    power_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":3.0, \"step\":None, \"log\":True})\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":1.0, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    link_space: Iterable[str] = (\"auto\", \"identity\", \"log\")\n\t    solver_space: Iterable[str] = (\"lbfgs\", \"newton-cholesky\")\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n", "    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    model: Any = None\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"power\"] = trial.suggest_float(f\"{self.__class__.__name__}_power\", **dict(self.power_space))\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"link\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_link\", self.link_space)\n\t        params[\"solver\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver\", self.solver_space)\n", "        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", TweedieRegressor, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n", "class HuberRegressorTuner(BaseTuner):\n\t    epsilon_space: Dict[str, Any] = MappingProxyType({\"low\":1.0, \"high\":10.0, \"step\":None, \"log\":True})\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":1.0, \"step\":None, \"log\":True})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    model: Any = None\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n", "        params[\"epsilon\"] = trial.suggest_float(f\"{self.__class__.__name__}_epsilon\", **dict(self.epsilon_space))\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", HuberRegressor, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass TheilSenRegressorTuner(BaseTuner):\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_subpopulation_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1e5, \"step\":1, \"log\":True})\n\t    set_n_subsamples_space: Iterable[bool] = (False, )\n\t    n_subsamples_space: Optional[Dict[str, Any]] = MappingProxyType({\"low\":1, \"high\":40, \"step\":1, \"log\":True})\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":300, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n", "    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    model: Any = None\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_subpopulation\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_subpopulation\", **dict(self.max_subpopulation_space))\n\t        set_n_subsamples = trial.suggest_categorical(\"set_n_subsamples\", self.set_n_subsamples_space)\n\t        if set_n_subsamples:\n\t            params[\"n_subsamples\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_subsamples\", **dict(self.n_subsamples_space))\n", "        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", TheilSenRegressor, params)\n\t        self.model = model\n\t        return model    \n", "@dataclass\n\tclass RANSACRegressorTuner(BaseTuner):\n\t    estimator: Optional[Union[RegressorMixin, BaseEstimator]] = None\n\t    min_samples_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    residual_threshold_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    max_trials_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n\t    max_skips_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":1e5, \"step\":1, \"log\":True})\n\t    stop_n_inliers_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":1e5, \"step\":1, \"log\":True})\n\t    stop_score_space: Dict[str, Any] = MappingProxyType({\"low\":1.0, \"high\":1e5, \"step\":None, \"log\":True})\n\t    stop_probability_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":0.99, \"step\":None, \"log\":False})\n", "    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    model: Any = None\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"estimator\"] = self.estimator\n\t        params[\"min_samples\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples\", **dict(self.min_samples_space))\n\t        params[\"residual_threshold\"] = trial.suggest_float(f\"{self.__class__.__name__}_residual_threshold\", **dict(self.residual_threshold_space))\n\t        params[\"max_trials\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_trials\", **dict(self.max_trials_space))\n\t        params[\"max_skips\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_skips\", **dict(self.max_skips_space))\n", "        params[\"stop_n_inliers\"] = trial.suggest_int(f\"{self.__class__.__name__}_stop_n_inliers\", **dict(self.stop_n_inliers_space))\n\t        params[\"stop_score\"] = trial.suggest_float(f\"{self.__class__.__name__}_stop_score\", **dict(self.stop_score_space))\n\t        params[\"stop_probability\"] = trial.suggest_float(f\"{self.__class__.__name__}_stop_probability\", **dict(self.stop_probability_space))\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"regression\", RANSACRegressor, params)\n\t        self.model = model\n", "        return model    "]}
{"filename": "tune_regressor/mlp_regressor.py", "chunked_list": ["from optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Optional, Dict, Any, Callable\n\tfrom sklearn.neural_network import MLPRegressor\n\tfrom ..tune_classifier import MLPClassifierTuner\n\t@dataclass\n\tclass MLPRegressorTuner(MLPClassifierTuner):\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        return super(MLPRegressorTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n", "        super(MLPClassifierTuner, self).sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super(MLPClassifierTuner, self).evaluate_sampled_model(\"regression\", MLPRegressor, params)\n\t        self.model = model\n\t        return model\n"]}
{"filename": "utils/__init__.py", "chunked_list": ["from .tuner_object_utils import *\n\tfrom typing import Iterable\n\t__all__: Iterable[str] = [\n\t    \"make_default_tuner_type_mutable\"\n\t]"]}
{"filename": "utils/tuner_object_utils.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom types import MappingProxyType\n\tdef make_default_tuner_type_mutable(tuner: BaseTuner) -> BaseTuner:\n\t    for i in tuner.__dict__.keys():\n\t        if isinstance(tuner.__dict__[i], MappingProxyType):\n\t            setattr(tuner, i, dict(tuner.__dict__[i]))\n\t    return tuner"]}
{"filename": "baseline/base.py", "chunked_list": ["import inspect, optuna\n\timport numpy as np\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Optional, Dict, Any, Union, Tuple, Iterable, Callable\n\tfrom types import MappingProxyType\n\tclass SpaceTypeValidationMixin:\n\t    def is_space_type(self, space: Union[Dict, Iterable], type: Callable) -> bool:\n\t        if type not in [float, int]:\n\t            raise ValueError(\n", "                f\"is_space_type method expects type being checked to be 'int' or 'float', got {type}.\"\n\t                f\" To check for categorical types, try using the `is_valid_categorical_space(...)` method\"\n\t            )\n\t        if (isinstance(space, dict) or isinstance(space, MappingProxyType)):\n\t            valid_keys = [\"low\", \"high\"]\n\t            for key in valid_keys:\n\t                if key not in space.keys():\n\t                    raise ValueError(f\"defined non-categorical space is missing key-value '{key}'\")\n\t            if space[\"low\"] > space[\"high\"]:\n\t                raise ValueError(f\"low cannot be greater than high in space: {space}\")\n", "            if \"log\" in space.keys():\n\t                if not isinstance(space[\"log\"], bool):\n\t                    raise TypeError(f\"log is expected to be bool type, got {type(space['log'])} instead\")\n\t            if \"step\" in space.keys():\n\t                if space[\"step\"] is not None:\n\t                    if not isinstance(space[\"step\"], float) or not isinstance(space[\"step\"], int):\n\t                        raise TypeError(f\"step is expected to be numerical type, got {type(space['step'])} instead\")\n\t            return all(list(map(lambda x: isinstance(x, type), [space[\"low\"], space[\"high\"]])))\n\t        return False\n\t    def is_valid_int_space(self, space: Iterable) -> bool:\n", "        return self.is_space_type(space, int)\n\t    def is_valid_float_space(self, space: Iterable) -> bool:\n\t        return self.is_space_type(space, float)\n\t    def is_valid_categorical_space(self, space: Iterable) -> bool:\n\t        return (not self.is_valid_float_space(space)) and (not self.is_valid_float_space(space))\n\tclass TrialCheckMixin:\n\t    def in_trial(self, trial: Optional[Trial]=None) -> Dict[str, Any]: \n\t        if trial is None: raise ValueError(\"Method should be called in an optuna trial study\")\n\tclass SampledModelEvaluationMixin:\n\t    def _evaluate_params(self, model_class: Callable, params: Dict[str, Any]):\n", "        assert isinstance(model_class, Callable), f\"Invalid model_class, {model_class} is not Callable\"\n\t        param_names = list(params.keys())\n\t        valid_param_names = list(inspect.signature(model_class.__dict__[\"__init__\"]).parameters.keys())\n\t        for param_name in param_names:\n\t            if param_name not in valid_param_names:\n\t                raise ValueError(f\"invalid argument {param_name} for {model_class.__name__}\")\n\t    def _random_classification_set(self, is_multitask: bool=False) -> Tuple[Iterable]:\n\t        if not is_multitask:\n\t            return np.abs(np.random.randn(25, 5)), np.random.randint(0, 2, size=(25))\n\t        else:\n", "            return np.abs(np.random.randn(25, 5)), np.random.randint(0, 2, size=(25, 2))\n\t    def _random_regression_set(self, is_multitask: bool=False) -> Tuple[Iterable]:\n\t        if not is_multitask:\n\t            return np.abs(np.random.randn(25, 5)), np.abs(np.random.randn(25)) + 1e-4\n\t        else:\n\t            return np.abs(np.random.randn(25, 5)), np.abs(np.random.randn(25, 2)) + 1e-4\n\t    def evaluate_sampled_model(\n\t            self, \n\t            task: str, \n\t            model_class: Callable, \n", "            params: Dict[str, Any], \n\t            is_multitask: bool=False) -> Any:\n\t        valid_tasks: Iterable[str] = [\"regression\", \"classification\"]\n\t        assert task in valid_tasks, (\n\t            f\"Invalid task for self._evaluate_sampled_model, expected task to be one of {valid_tasks}, got {task}\"\n\t        )\n\t        self._evaluate_params(model_class, params)\n\t        if task == \"regression\":\n\t            X, y = self._random_regression_set(is_multitask)\n\t        else:\n", "            X, y = self._random_classification_set(is_multitask)\n\t        try:\n\t            model_class(**params).fit(X, y)\n\t        except (ValueError, NotImplementedError) as e:\n\t            raise optuna.exceptions.TrialPruned(e)\n\t        model = model_class(**params)\n\t        return model\n\t@dataclass\n\tclass BaseTuner(SpaceTypeValidationMixin, TrialCheckMixin, SampledModelEvaluationMixin):\n\t    r\"\"\"\n", "    BaseTuner class that everyother tuner extends from\n\t    If you wish to implement a custom tuner class with some default parameters, \n\t    you must first extend from the BaseTuner class. The custom tuner must \n\t    have the class attribute 'model_class' of type (Callable), which indicates\n\t    the class of the model being tuned::\n\t        @dataclass\n\t        class CustomTuner(BaseTuner):\n\t            model_class: Callable = GaussianProcessRegressor\n\t            #int space\n\t            param1_space: Dict[str, Any] = MappingProxyType({\n", "                \"low\":2, \n\t                \"high\":1000, \n\t                \"step\":1, \n\t                \"log\":True,\n\t            })\n\t            #float space\n\t            param2_space: Dict[str, Any] = MappingProxyType({\n\t                \"low\":0.1, \n\t                \"high\":1.0, \n\t                \"step\":None, \n", "                \"log\":False,\n\t            })\n\t            #categorical space\n\t            param3_space: Iterable[str] = (\"cat1\", \"cat2\", \"cat3\", \"cat4\")\n\t            def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t                super().sample_params(trial)\n\t                params = {}\n\t                params[\"param1\"] = trial.suggest_int(\n\t                    f\"{self.__class__.__name__}_param1\", **dict(self.param1_space))\n\t                params[\"param2\"] = trial.suggest_float(\n", "                    f\"{self.__class__.__name__}_param2\", **dict(self.param2_space))\n\t                params[\"param3\"] = trial.suggest_categorical(\n\t                    f\"{self.__class__.__name__}_param3\", self.param3_space)\n\t                return params\n\t            def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t                super().sample_model(trial)\n\t                params = self.sample_params(trial)\n\t                model = super().evaluate_sampled_model(\n\t                    \"regression\", self.model_class, params)\n\t                self.model = model\n", "                return model\n\t    \"\"\"\n\t    model: Any = None\n\t    def sample_params(self, trial: Trial) -> Dict[str, Any]:\n\t        r\"\"\"\n\t        Parameter\n\t        ---------\n\t        trial: optuna.trial.Trial\n\t            optuna trial\n\t        Return\n", "        ------\n\t        params: Dict[str, Any]\n\t            collected parameters sampled from the defined search space\n\t        \"\"\"\n\t        super().in_trial(trial)\n\t    def sample_model(self, trial: Trial) -> Any:\n\t        r\"\"\"\n\t        Parameter\n\t        ---------\n\t        trial: optuna.trial.Trial\n", "            optuna trial\n\t        Return\n\t        ------\n\t        params: Any\n\t            model initialised with sampled parameters\n\t        \"\"\"\n\t        super().in_trial(trial)"]}
{"filename": "baseline/__init__.py", "chunked_list": ["from .base import *\n\tfrom typing import Iterable\n\t__all__: Iterable[str] = [\n\t    \"SpaceTypeValidationMixin\",\n\t    \"TrialCheckMixin\", \n\t    \"SampledModelEvaluationMixin\",\n\t    \"BaseTuner\"\n\t]"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/utils.py", "chunked_list": ["import optuna, sklearn\n\timport numpy as np\n\tfrom sklearn import datasets\n\tfrom sklearn.preprocessing import MinMaxScaler\n\tfrom optuna.trial import Trial\n\tfrom ..baseline.base import BaseTuner\n\tfrom ..tune_classifier import classifier_tuner_model_class_map\n\tfrom ..tune_regressor import regressor_tuner_model_class_map\n\t# load sample datasets\n\t# regression\n", "REG_X, REG_y = datasets.load_diabetes(return_X_y=True)\n\tREG_X = MinMaxScaler().fit_transform(REG_X)\n\tREG_y = ((REG_y - REG_y.min()) / (REG_y.max() - REG_y.min())) + 1e-4\n\tREG_DATA = sklearn.model_selection.train_test_split(REG_X, REG_y, random_state=0)\n\t# classification\n\tCLS_X, CLS_y = datasets.load_iris(return_X_y=True)\n\tCLS_X = MinMaxScaler().fit_transform(CLS_X)\n\tCLS_DATA = sklearn.model_selection.train_test_split(CLS_X, CLS_y, random_state=0)\n\t#multi-task regression\n\tMULTITASK_REG_X, MULTITASK_REG_y = np.random.randn(200, 20), np.random.randn(200, 5)\n", "MULTITASK_REG_X = MinMaxScaler().fit_transform(MULTITASK_REG_X)\n\tMULTITASK_REG_y = MinMaxScaler().fit_transform(MULTITASK_REG_y)\n\tMULTITASK_DATA = sklearn.model_selection.train_test_split(MULTITASK_REG_X, MULTITASK_REG_y, random_state=0)\n\t# Define an objective function to be minimized.\n\tdef objective_factory(model: BaseTuner, task: str=\"regression\"):\n\t    \"\"\" generate objective function for given model \"\"\"\n\t    # unpack data\n\t    if task == \"regression\":\n\t        data = REG_DATA\n\t        metric = sklearn.metrics.mean_squared_error\n", "    else:\n\t        data = CLS_DATA\n\t        metric = sklearn.metrics.accuracy_score\n\t    if hasattr(model, \"is_multitask\"):\n\t        data = MULTITASK_DATA\n\t        metric = sklearn.metrics.mean_squared_error\n\t    X_train, X_val, y_train, y_val = data\n\t    def objective(trial: Trial):\n\t        sampled_model = model.sample_model(trial)\n\t        sampled_model.fit(X_train, y_train)\n", "        y_pred = sampled_model.predict(X_val)\n\t        error = metric(y_val, y_pred)\n\t        return error\n\t    return objective\n\tclass BaseTest:\n\t    model: BaseTuner = None\n\t    task: str = None\n\t    n_trials: int = 20\n\t    def test_dict_mapping(self):\n\t        if self.task == \"classification\":\n", "            assert self.model.__class__.__name__ in classifier_tuner_model_class_map.keys()\n\t        elif self.task == \"regression\":\n\t            assert self.model.__class__.__name__ in regressor_tuner_model_class_map.keys()\n\t        else: assert False\n\t    def test_methods_and_attrs(self):\n\t        assert hasattr(self.model, \"sample_params\")\n\t        assert hasattr(self.model, \"sample_model\")\n\t        assert hasattr(self.model, \"model\") and self.model.model is None\n\t    def test_study(self):\n\t        try:\n", "            study = optuna.create_study()  # Create a new study.\n\t            study.optimize(objective_factory(self.model, task=self.task), n_trials=self.n_trials)\n\t            best = study.best_params\n\t        except:\n\t            best = None\n\t        assert best is not None\n"]}
{"filename": "tests/test_tuners.py", "chunked_list": ["from ..baseline.base import BaseTuner\n\tfrom .. import tune_classifier\n\tfrom .. import tune_regressor\n\tfrom .utils import BaseTest\n\t# run python -m pytest -v\n\tclass TestSVR(BaseTest):\n\t    model: BaseTuner = tune_regressor.SVRTuner()\n\t    task: str = \"regression\"\n\tclass TestDecisionTreeRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.DecisionTreeRegressorTuner()\n", "    task: str = \"regression\"\n\tclass TestSVC(BaseTest):\n\t    model: BaseTuner = tune_classifier.SVCTuner()\n\t    task: str = \"classification\"\n\tclass TestDecisionTreeClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.DecisionTreeClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestLinearRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.LinearRegressionTuner()\n\t    task: str = \"regression\"\n", "class TestLassoRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.LassoTuner()\n\t    task: str = \"regression\"\n\tclass TestRidgeRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.RidgeTuner()\n\t    task: str = \"regression\"\n\tclass TestLogisticRegressor(BaseTest):\n\t    model: BaseTuner = tune_classifier.LogisticRegressionTuner()\n\t    task: str = \"classification\"\n\tclass TestLinearSVC(BaseTest):\n", "    model: BaseTuner = tune_classifier.LinearSVCTuner()\n\t    task: str = \"classification\"\n\tclass TestLinearSVR(BaseTest):\n\t    model: BaseTuner = tune_regressor.LinearSVRTuner()\n\t    task: str = \"regression\"\n\tclass TestExtraTreeRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.ExtraTreeRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestRandomForestClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.RandomForestClassifierTuner()\n", "    task: str = \"classification\"\n\tclass TestRandomForestRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.RandomForestRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestExtraTreesClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.ExtraTreesClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestExtraTreesRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.ExtraTreesRegressorTuner()\n\t    task: str = \"regression\"\n", "class TestExtraTreeClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.ExtraTreeClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestAdaBoostClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.AdaBoostClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestAdaBoostRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.AdaBoostRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestKNNClassifier(BaseTest):\n", "    model: BaseTuner = tune_classifier.KNeighborsClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestKNNRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.KNeighborsRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestNearestCentroidClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.NearestCentroidClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestElasticNetRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.ElasticNetTuner()\n", "    task: str = \"regression\"\n\tclass TestMultiTaskLassoRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.MultiTaskLassoTuner()\n\t    task: str = \"regression\"\n\tclass TestMultiTaskElasticNetRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.MultiTaskElasticNetTuner()\n\t    task: str = \"regression\"\n\tclass TestBaggingClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.BaggingClassifierTuner()\n\t    task: str = \"classification\"\n", "class TestBaggingRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.BaggingRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestGradientBoostingClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.GradientBoostingClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestGradientBoostingRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.GradientBoostingRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestRadiusNeighborClassifier(BaseTest):\n", "    model: BaseTuner = tune_classifier.RadiusNeighborsClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestRadiusNeighborRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.RadiusNeighborsRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestNuSVC(BaseTest):\n\t    model: BaseTuner = tune_classifier.NuSVCTuner()\n\t    task: str = \"classification\"\n\tclass TestNuSVR(BaseTest):\n\t    model: BaseTuner = tune_regressor.NuSVRTuner()\n", "    task: str = \"regression\"\n\tclass TestPerceptron(BaseTest):\n\t    model: BaseTuner = tune_classifier.PerceptronTuner()\n\t    task: str = \"classification\"\n\tclass TestPassiveAggressiveClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.PassiveAggressiveClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestPassiveAggressiveRegressorTuner(BaseTest):\n\t    model: BaseTuner = tune_regressor.PassiveAggressiveRegressorTuner()\n\t    task: str = \"regression\"\n", "class TestSGDClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.SGDClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestSGDRegressorTuner(BaseTest):\n\t    model: BaseTuner = tune_regressor.SGDRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestMLPClassifierTuner(BaseTest):\n\t    model: BaseTuner = tune_classifier.MLPClassifierTuner()\n\t    task: str = \"classification\"\n\t    n_trials: int = 10\n", "class TestMLPRegressorTuner(BaseTest):\n\t    model: BaseTuner = tune_regressor.MLPRegressorTuner()\n\t    task: str = \"regression\"\n\t    n_trials: int = 10\n\tclass TestHistGradientBoostingClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.HistGradientBoostingClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestHistGradientBoostingRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.HistGradientBoostingRegressorTuner()\n\t    task: str = \"regression\"\n", "class TestLars(BaseTest):\n\t    model: BaseTuner = tune_regressor.LarsTuner()\n\t    task: str = \"regression\"\n\tclass TestLassoLars(BaseTest):\n\t    model: BaseTuner = tune_regressor.LassoLarsTuner()\n\t    task: str = \"regression\"\n\tclass TestLassoLarsIC(BaseTest):\n\t    model: BaseTuner = tune_regressor.LassoLarsICTuner()\n\t    task: str = \"regression\"\n\tclass TestBayesianRidge(BaseTest):\n", "    model: BaseTuner = tune_regressor.BayesianRidgeTuner()\n\t    task: str = \"regression\"\n\tclass TestGaussianNBClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.GaussianNBTuner()\n\t    task: str = \"classification\"\n\tclass TestBernoulliNBClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.BernoulliNBTuner()\n\t    task: str = \"classification\"\n\tclass TestMultinomialNBClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.MultinomialNBTuner()\n", "    task: str = \"classification\"\n\tclass TestComplementNBClassifier(BaseTest):\n\t    model: BaseTuner = tune_classifier.ComplementNBTuner()\n\t    task: str = \"classification\"\n\tclass TestCategoricalNBTuner(BaseTest):\n\t    model: BaseTuner = tune_classifier.CategoricalNBTuner()\n\t    task: str = \"classification\"\n\tclass TestTweedieRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.TweedieRegressorTuner()\n\t    task: str = \"regression\"\n", "class TestOrthogonalMatchingPursuit(BaseTest):\n\t    model: BaseTuner = tune_regressor.OrthogonalMatchingPursuitTuner()\n\t    task: str = \"regression\"\n\tclass TestPoissonRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.PoissonRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestGammaRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.GammaRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestQuantileRegressor(BaseTest):\n", "    model: BaseTuner = tune_regressor.QuantileRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestHuberRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.HuberRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestTheilSenRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.TheilSenRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestARDRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.ARDRegressionTuner()\n", "    task: str = \"regression\"\n\tclass TestRANSACRegressor(BaseTest):\n\t    model: BaseTuner = tune_regressor.RANSACRegressorTuner()\n\t    task: str = \"regression\"\n\tclass TestLinearDiscriminantAnalysis(BaseTest):\n\t    model: BaseTuner = tune_classifier.LDAClassifierTuner()\n\t    task: str = \"classification\"\n\tclass TestQuadraticDiscriminantAnalysis(BaseTest):\n\t    model: BaseTuner = tune_classifier.QDAClassifierTuner()\n\t    task: str = \"classification\"\n"]}
{"filename": "tune_classifier/svc.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Callable\n\tfrom sklearn.svm import SVC, LinearSVC, NuSVC\n\tfrom types import MappingProxyType\n\t@dataclass\n\tclass SVCTuner(BaseTuner):\n\t    kernel_space: Iterable[str] = (\"linear\", \"poly\", \"rbf\", \"sigmoid\")\n\t    degree_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":5, \"step\":1, \"log\":False})\n", "    gamma_space: Iterable[str] = (\"scale\", \"auto\")\n\t    coef0_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n\t    shrinking_space: Iterable[bool] = (True, )\n\t    probability_space: Iterable[bool] = (True, )\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n", "        params = {}\n\t        params[\"kernel\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_kernel\", self.kernel_space)\n\t        params[\"degree\"] = trial.suggest_int(f\"{self.__class__.__name__}_degree\", **dict(self.degree_space))\n\t        params[\"gamma\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_gamma\", self.gamma_space)\n\t        params[\"coef0\"] = trial.suggest_float(f\"{self.__class__.__name__}_coef0\", **dict(self.coef0_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        params[\"shrinking\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shrinking\", self.shrinking_space)\n\t        params[\"probability\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_probability\", self.probability_space)\n", "        if params[\"probability\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", SVC, params)\n\t        return model\n\t@dataclass\n\tclass LinearSVCTuner(BaseTuner):\n", "    penalty_space: Iterable[str] = (\"l1\", \"l2\")\n\t    loss_space: Iterable[str] = (\"hinge\", \"squared_hinge\")\n\t    dual_space: Iterable[bool] = (True, False)\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    multi_class_space: Iterable[str] = (\"ovr\", \"crammer_singer\")\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    intercept_scaling_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":500, \"high\":2000, \"step\":1, \"log\":True})\n", "    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"penalty\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_penalty\", self.penalty_space)\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"dual\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_dual\", self.dual_space)\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"multi_class\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_multi_class\", self.multi_class_space)\n", "        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"intercept_scaling\"] = trial.suggest_float(f\"{self.__class__.__name__}_intercept_scaling\", **dict(self.intercept_scaling_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        if params[\"dual\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = super().evaluate_sampled_model(\"classification\", LinearSVC, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass NuSVCTuner(BaseTuner):\n\t    nu_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    kernel_space: Iterable[str] = (\"linear\", \"poly\", \"rbf\", \"sigmoid\")\n\t    degree_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":5, \"step\":1, \"log\":False})\n\t    gamma_space: Iterable[str] = (\"scale\", \"auto\")\n\t    coef0_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n", "    shrinking_space: Iterable[bool] = (True, )\n\t    probability_space: Iterable[bool] = (True, )\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n\t    decision_function_shape_space: Iterable[str] = (\"ovo\", \"ovr\")\n\t    break_ties_space: Iterable[bool] = (False, )\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n", "        params[\"nu\"] = trial.suggest_float(f\"{self.__class__.__name__}_nu\", **dict(self.nu_space))\n\t        params[\"kernel\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_kernel\", self.kernel_space)\n\t        params[\"degree\"] = trial.suggest_int(f\"{self.__class__.__name__}_degree\", **dict(self.degree_space))\n\t        params[\"gamma\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_gamma\", self.gamma_space)\n\t        params[\"coef0\"] = trial.suggest_float(f\"{self.__class__.__name__}_coef0\", **dict(self.coef0_space))\n\t        params[\"shrinking\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shrinking\", self.shrinking_space)\n\t        params[\"probability\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_probability\", self.probability_space)\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        params[\"decision_function_shape\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_decision_function_shape\", self.decision_function_shape_space)\n", "        params[\"break_ties\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_break_ties\", self.break_ties_space)\n\t        if params[\"probability\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", NuSVC, params)\n\t        return model\n"]}
{"filename": "tune_classifier/ensemble_classifier.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Union, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.ensemble import (\n\t    RandomForestClassifier, \n\t    ExtraTreesClassifier, \n\t    AdaBoostClassifier, \n\t    GradientBoostingClassifier, \n", "    BaggingClassifier, \n\t    HistGradientBoostingClassifier,\n\t)\n\t@dataclass\n\tclass RandomForestClassifierTuner(BaseTuner):\n\t    n_estimators_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":200, \"step\":1, \"log\":True})\n\t    criterion_space: Iterable[str] = (\"gini\", \"entropy\", \"log_loss\")\n\t    set_max_depth_space: Iterable[bool] = (True, False)\n\t    max_depth_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":2000, \"step\":1, \"log\":True})\n\t    min_samples_split_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n", "    min_samples_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    min_weight_fraction_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    max_features_space: Iterable[str] = (\"sqrt\", \"log2\", None)\n\t    set_max_leaf_nodes_space: Iterable[bool] = (True, False)\n\t    max_leaf_nodes_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":10000, \"step\":1, \"log\":True})\n\t    min_impurity_decrease_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    bootstrap_space: Iterable[bool] = (True, False)\n\t    oob_score_space: Iterable[bool] = (True, False)\n\t    class_weight_space: Iterable[str] = (\"balanced\", \"balanced_subsample\")\n\t    set_random_state_space: Iterable[bool] = (False, )\n", "    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    ccp_alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    set_max_samples_space: Iterable[bool] = (True, False)\n\t    max_samples_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"n_estimators\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_estimators\", **dict(self.n_estimators_space))\n\t        params[\"criterion\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_criterion\", self.criterion_space)\n\t        set_max_depth = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_depth\", self.set_max_depth_space)\n", "        if set_max_depth:\n\t            params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n\t        if self.is_space_type(self.min_samples_split_space, float):\n\t            params[\"min_samples_split\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        else:\n\t            params[\"min_samples_split\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        if self.is_space_type(self.min_samples_leaf_space, float):\n\t            params[\"min_samples_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        else:\n\t            params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n", "        params[\"min_weight_fraction_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_weight_fraction_leaf\", **dict(self.min_weight_fraction_leaf_space))\n\t        if self.is_valid_categorical_space(self.max_features_space):\n\t            params[\"max_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_max_features\", self.max_features_space)\n\t        else:\n\t            if self.is_valid_float_space(self.max_features_space):\n\t                params[\"max_features\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t            else:\n\t                params[\"max_features\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t        set_max_leaf_node = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_leaf_nodes\", self.set_max_leaf_nodes_space)\n\t        if set_max_leaf_node:\n", "            params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        params[\"min_impurity_decrease\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_impurity_decrease\", **dict(self.min_impurity_decrease_space))\n\t        params[\"bootstrap\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_bootstrap\", self.bootstrap_space)\n\t        params[\"oob_score\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_oob_score\", self.oob_score_space)\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        set_random_state = trial.suggest_categorical(f\"{self.__class__.__name__}_set_random_state\", self.set_random_state_space)\n\t        if set_random_state:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"ccp_alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_ccp_alpha\", **dict(self.ccp_alpha_space))\n\t        set_max_samples = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_samples\", self.set_max_samples_space)\n", "        if set_max_samples:\n\t            if self.is_space_type(self.max_samples_space, float):\n\t                params[\"max_samples\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_samples\", **dict(self.max_samples_space))\n\t            else:\n\t                params[\"max_samples\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_samples\", **dict(self.max_samples_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", RandomForestClassifier, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass ExtraTreesClassifierTuner(RandomForestClassifierTuner):\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        return super(ExtraTreesClassifierTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super(RandomForestClassifierTuner, self).sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super(RandomForestClassifierTuner, self).evaluate_sampled_model(\"classification\", ExtraTreesClassifier, params)\n", "        self.model = model\n\t        return model\n\t@dataclass\n\tclass AdaBoostClassifierTuner(BaseTuner):\n\t    estimator_space: Iterable[Optional[object]] = (None, )\n\t    n_estimators_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":200, \"step\":1, \"log\":True})\n\t    learning_rate_space: Dict[str, Any] = MappingProxyType({\"low\":0.01, \"high\":1, \"step\":None, \"log\":True})\n\t    algorithm_space: Iterable[str] = (\"SAMME\", \"SAMME.R\")\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n", "        super().sample_params(trial)\n\t        params = {}\n\t        params[\"estimator\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_estimator\", self.estimator_space)\n\t        params[\"n_estimators\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_estimators\", **dict(self.n_estimators_space))\n\t        params[\"learning_rate\"] = trial.suggest_float(f\"{self.__class__.__name__}_learning_rate\", **dict(self.learning_rate_space))\n\t        params[\"algorithm\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_algorithm\", self.algorithm_space)\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n", "        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", AdaBoostClassifier, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass GradientBoostingClassifierTuner(BaseTuner):\n\t    loss_space: Iterable[str] = (\"log_loss\", )\n\t    learning_rate_space: Dict[str, Any] = MappingProxyType({\"low\":0.001, \"high\":1.0, \"step\":None, \"log\":True})\n\t    n_estimators_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    subsample_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n", "    criterion_space: Iterable[str] = (\"friedman_mse\", \"squared_error\")\n\t    min_samples_split_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    min_samples_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    min_weight_fraction_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    set_max_depth_space: Iterable[bool] = (True, False)\n\t    max_depth_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":2000, \"step\":1, \"log\":True})\n\t    min_impurity_decrease_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    init_space: Iterable[Optional[object]] = (None, )\n\t    max_features_space: Iterable[str] = (\"sqrt\", \"log2\")\n\t    set_max_leaf_nodes_space: Iterable[bool] = (True, False)\n", "    max_leaf_nodes_space: Iterable[Optional[int]] = MappingProxyType({\"low\":2, \"high\":10000, \"step\":1, \"log\":True})\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    set_n_iter_no_change_space:Iterable[bool] = (True, False)\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    ccp_alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)        \n\t        params = {}\n", "        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"learning_rate\"] = trial.suggest_float(f\"{self.__class__.__name__}_learning_rate\", **dict(self.learning_rate_space))\n\t        params[\"n_estimators\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_estimators\", **dict(self.n_estimators_space))\n\t        params[\"subsample\"] = trial.suggest_float(f\"{self.__class__.__name__}_subsample\", **dict(self.subsample_space))\n\t        params[\"criterion\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_criterion\", self.criterion_space)\n\t        if self.is_space_type(self.min_samples_split_space, float):\n\t            params[\"min_samples_split\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        else:\n\t            params[\"min_samples_split\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        if self.is_space_type(self.min_samples_leaf_space, float):\n", "            params[\"min_samples_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        else:\n\t            params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        params[\"min_weight_fraction_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_weight_fraction_leaf\", **dict(self.min_weight_fraction_leaf_space))\n\t        set_max_depth = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_depth\", self.set_max_depth_space)\n\t        if set_max_depth:\n\t            params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n\t        params[\"min_impurity_decrease\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_impurity_decrease\", **dict(self.min_impurity_decrease_space))\n\t        params[\"init\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_init\", self.init_space)\n\t        if self.is_valid_categorical_space(self.max_features_space):\n", "            params[\"max_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_max_features\", self.max_features_space)\n\t        else:\n\t            if self.is_valid_float_space(self.max_features_space):\n\t                params[\"max_features\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t            else:\n\t                params[\"max_features\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t        set_max_leaf_nodes = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_leaf_nodes\", self.set_max_leaf_nodes_space)\n\t        if set_max_leaf_nodes:\n\t            params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n", "        set_n_iter_no_change = trial.suggest_categorical(f\"{self.__class__.__name__}_set_n_iter_no_change\", self.set_n_iter_no_change_space)\n\t        if set_n_iter_no_change:\n\t            params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"ccp_alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_ccp_alpha\", **dict(self.ccp_alpha_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = super().evaluate_sampled_model(\"classification\", GradientBoostingClassifier, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass BaggingClassifierTuner(BaseTuner):\n\t    estimator_space: Iterable[Optional[object]] = (None, )\n\t    n_estimators_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    max_samples_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    max_features_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    bootstrap_space: Iterable[bool] = (True, False)\n", "    bootstrap_features_space: Iterable[bool] = (True, False)\n\t    oob_score_space: Iterable[bool] = (True, False)\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"estimator\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_estimator\", self.estimator_space)\n\t        params[\"n_estimators\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_estimators\", **dict(self.n_estimators_space))\n\t        if self.is_space_type(self.max_samples_space, float):\n\t            params[\"max_samples\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_samples\", **dict(self.max_samples_space))\n", "        else:\n\t            params[\"max_samples\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_samples\", **dict(self.max_samples_space))\n\t        if self.is_space_type(self.max_features_space, float):\n\t            params[\"max_features\"] = trial.suggest_float(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t        else:\n\t            params[\"max_features\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_features\", **dict(self.max_features_space))\n\t        params[\"bootstrap\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_bootstrap\", self.bootstrap_space)\n\t        params[\"bootstrap_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_bootstrap_features\", self.bootstrap_features_space)\n\t        params[\"oob_score\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_oob_score\", self.oob_score_space)\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n", "        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", BaggingClassifier, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass HistGradientBoostingClassifierTuner(BaseTuner):\n\t    loss_space: Iterable[str] = (\"log_loss\", )\n", "    learning_rate_space: Dict[str, Any] = MappingProxyType({\"low\":0.001, \"high\":1.0, \"step\":None, \"log\":True})\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":1000, \"step\":1, \"log\":True})\n\t    set_max_leaf_nodes_space: Iterable[bool] = (True, False)\n\t    max_leaf_nodes_space: Iterable[Optional[int]] = MappingProxyType({\"low\":2, \"high\":10000, \"step\":1, \"log\":True})\n\t    set_max_depth_space: Iterable[bool] = (True, False)\n\t    max_depth_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":2000, \"step\":1, \"log\":True})\n\t    min_samples_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":200, \"step\":1, \"log\":True})\n\t    l2_regularization_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    max_bins_space: Dict[str, Any] = MappingProxyType({\"low\":10, \"high\":255, \"step\":1, \"log\":True})\n\t    categorical_features_space: Iterable[Any] = (None, )\n", "    monotonic_cst_space: Iterable[Any] = (None, )\n\t    interaction_cst_space: Iterable[Any] = (None, )\n\t    early_stopping_space: Iterable[bool] = (\"auto\", True, False)\n\t    scoring_space: Iterable[Optional[Union[str, Callable]]] = (\"loss\", None)\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":True})\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n", "        super().sample_params(trial)\n\t        params = {}\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"learning_rate\"] = trial.suggest_float(f\"{self.__class__.__name__}_learning_rate\", **dict(self.learning_rate_space))\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        set_max_leaf_nodes = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_leaf_nodes\", self.set_max_leaf_nodes_space)\n\t        if set_max_leaf_nodes:\n\t            params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        set_max_depth = trial.suggest_categorical(f\"{self.__class__.__name__}_set_max_depth\", self.set_max_depth_space)\n\t        if set_max_depth:\n", "            params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n\t        params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        params[\"l2_regularization\"] = trial.suggest_float(f\"{self.__class__.__name__}_l2_regularization\", **dict(self.l2_regularization_space))\n\t        params[\"max_bins\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_bins\", **dict(self.max_bins_space))\n\t        params[\"categorical_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_categorical_features\", self.categorical_features_space)\n\t        params[\"monotonic_cst\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_monotonic_cst\", self.monotonic_cst_space)\n\t        params[\"interaction_cst\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_interaction_cst\", self.interaction_cst_space)\n\t        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n\t        params[\"scoring\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_scoring\", self.scoring_space)\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n", "        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", HistGradientBoostingClassifier, params)\n\t        self.model = model\n", "        return model"]}
{"filename": "tune_classifier/neighbor_classifier.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n\t@dataclass\n\tclass KNeighborsClassifierTuner(BaseTuner):\n\t    n_neighbors_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10, \"step\":2, \"log\":False})\n\t    weights_space: Iterable[str] = (\"uniform\", \"distance\")\n", "    algorithm_space: Iterable[str] = (\"ball_tree\", \"kd_tree\", \"brute\")\n\t    leaf_size_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":100, \"step\":1, \"log\":True})\n\t    p_space: Dict[str, Any] = MappingProxyType({\"low\":3, \"high\":8, \"step\":1, \"log\":False})\n\t    metric_space: Iterable[str] = (\"cityblock\", \"cosine\", \"euclidean\", \"manhattan\", \"minkowski\")\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"n_neighbors\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_neighbors\", **dict(self.n_neighbors_space))\n\t        params[\"weights\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_weight\", self.weights_space)\n\t        params[\"algorithm\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_algorithm\", self.algorithm_space)\n", "        params[\"leaf_size\"] = trial.suggest_int(f\"{self.__class__.__name__}_leaf_size\", **dict(self.leaf_size_space))\n\t        params[\"p\"] = trial.suggest_int(f\"{self.__class__.__name__}_p\", **dict(self.p_space))\n\t        params[\"metric\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_metric\", self.metric_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", KNeighborsClassifier, params)\n\t        self.model = model\n\t        return model\n", "@dataclass\n\tclass RadiusNeighborsClassifierTuner(BaseTuner):\n\t    radius_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":20, \"step\":1, \"log\":False})\n\t    weight_space: Iterable[str] = (\"uniform\", \"distance\")\n\t    algorithm_space: Iterable[str] = (\"ball_tree\", \"kd_tree\", \"brute\")\n\t    leaf_size_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":100, \"step\":1, \"log\":True})\n\t    p_space: Dict[str, Any] = MappingProxyType({\"low\":3, \"high\":10, \"step\":1, \"log\":False})\n\t    metric_space: Iterable[str] = (\"cityblock\", \"cosine\", \"euclidean\", \"manhattan\", \"minkowski\")\n\t    outlier_label_space: Iterable[str] = (None, \"most_frequent\")\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n", "        super().sample_params(trial)\n\t        params = {}\n\t        params[\"radius\"] = trial.suggest_int(f\"{self.__class__.__name__}_radius\", **dict(self.radius_space))\n\t        params[\"weights\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_weight\", self.weight_space)\n\t        params[\"algorithm\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_algorithm\", self.algorithm_space)\n\t        params[\"leaf_size\"] = trial.suggest_int(f\"{self.__class__.__name__}_leaf_size\", **dict(self.leaf_size_space))\n\t        params[\"p\"] = trial.suggest_int(f\"{self.__class__.__name__}_p\", **dict(self.p_space))\n\t        params[\"metric\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_metric\", self.metric_space)\n\t        params[\"outlier_label\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_outlier_label\", self.outlier_label_space)\n\t        return params\n", "    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", RadiusNeighborsClassifier, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass NearestCentroidClassifierTuner(BaseTuner):\n\t    metric_space: Iterable[str] = (\"cityblock\", \"cosine\", \"euclidean\", \"manhattan\")\n\t    shrink_threshold_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.9, \"step\":None, \"log\":False})\n", "    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"metric\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_metric\", self.metric_space)\n\t        params[\"shrink_threshold\"] = trial.suggest_float(f\"{self.__class__.__name__}_shrink_threshold\", **dict(self.shrink_threshold_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", NearestCentroid, params)\n", "        self.model = model\n\t        return model"]}
{"filename": "tune_classifier/tree_classifier.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Union, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n\t@dataclass\n\tclass DecisionTreeClassifierTuner(BaseTuner):\n\t    criterion_space: Iterable[str] = (\"gini\", \"entropy\", \"log_loss\")\n\t    splitter_space: Iterable[str] = (\"best\", \"random\")\n", "    max_depth_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":1000, \"step\":1, \"log\":True})\n\t    min_samples_split_space: Iterable[Union[int, float]] = MappingProxyType({\"low\":1e-4, \"high\":1.0, \"step\":None, \"log\":True})\n\t    min_samples_leaf_space: Iterable[Union[int, float]] = MappingProxyType({\"low\":1e-4, \"high\":1.0, \"step\":None, \"log\":True})\n\t    min_weight_fraction_leaf_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":0.5, \"step\":None, \"log\":False})\n\t    max_features_space: Iterable[Optional[str]] = (\"sqrt\", \"log2\", None)\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    max_leaf_nodes_space: Dict[str, Any] = MappingProxyType({\"low\":2, \"high\":1000, \"step\":1, \"log\":True})\n\t    min_impurity_decrease_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    ccp_alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    class_weight_space: Iterable[Optional[str]] = (\"balanced\", None)\n", "    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"criterion\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_criterion\", self.criterion_space)\n\t        params[\"splitter\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_splitter\", self.splitter_space)\n\t        params[\"max_depth\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_depth\", **dict(self.max_depth_space))\n\t        if self.is_space_type(self.min_samples_split_space, float):\n\t            params[\"min_samples_split\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n\t        else:\n\t            params[\"min_samples_split\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_split\", **dict(self.min_samples_split_space))\n", "        if self.is_space_type(self.min_samples_leaf_space, float):\n\t            params[\"min_samples_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        else:\n\t            params[\"min_samples_leaf\"] = trial.suggest_int(f\"{self.__class__.__name__}_min_samples_leaf\", **dict(self.min_samples_leaf_space))\n\t        params[\"min_weight_fraction_leaf\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_weight_fraction_leaf\", **dict(self.min_weight_fraction_leaf_space))\n\t        params[\"max_features\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_max_features\", self.max_features_space)\n\t        if params[\"splitter\"] == \"random\":\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"max_leaf_nodes\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_leaf_nodes\", **dict(self.max_leaf_nodes_space))\n\t        params[\"min_impurity_decrease\"] = trial.suggest_float(f\"{self.__class__.__name__}_min_impurity_decrease\", **dict(self.min_impurity_decrease_space))\n", "        params[\"ccp_alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_ccp_alpha\", **dict(self.ccp_alpha_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", DecisionTreeClassifier, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n", "class ExtraTreeClassifierTuner(DecisionTreeClassifierTuner):\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        return super(ExtraTreeClassifierTuner, self).sample_params(trial)\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super(DecisionTreeClassifierTuner, self).sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super(DecisionTreeClassifierTuner, self).evaluate_sampled_model(\"classification\", ExtraTreeClassifier, params)\n\t        self.model = model\n\t        return model"]}
{"filename": "tune_classifier/discriminant_analysis_classifier.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom types import MappingProxyType\n\tfrom typing import Iterable, Optional, Dict, Any, Callable\n\tfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n\t@dataclass\n\tclass LDAClassifierTuner(BaseTuner):\n\t    solver_space: Iterable[str] = (\"svd\", \"lsqr\", \"eigen\")\n\t    shrinkage_space: Iterable[str] = (None, \"auto\")\n", "    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    priors_space: Iterable[Optional[Iterable[float]]] = (None, )\n\t    store_covariance: Iterable[bool] = (False, )\n\t    covariance_estimator_space: Iterable[Optional[object]] = (None, )\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"solver\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver\", self.solver_space)\n\t        if self.is_valid_categorical_space(self.shrinkage_space):\n\t            params[\"shrinkage\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shrinkage\", self.shrinkage_space)\n", "        else:\n\t            params[\"shrinkage\"] = trial.suggest_float(f\"{self.__class__.__name__}_shrinkage\", **dict(self.shrinkage_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"priors\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_prior\", self.priors_space)\n\t        params[\"store_covariance\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_store_covariance\", self.store_covariance)\n\t        params[\"covariance_estimator\"] = trial.suggest_categorical(\"covariance_estimator\", self.covariance_estimator_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = super().evaluate_sampled_model(\"classification\", LinearDiscriminantAnalysis, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass QDAClassifierTuner(BaseTuner):\n\t    reg_param_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    priors_space: Iterable[Optional[Iterable[float]]] = (None,)\n\t    store_covariance: Iterable[bool] = (False,)\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n", "        super().sample_params(trial)\n\t        params = {}\n\t        params[\"reg_param\"] = trial.suggest_float(f\"{self.__class__.__name__}_reg_param\", **dict(self.reg_param_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"priors\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_prior\", self.priors_space)\n\t        params[\"store_covariance\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_store_covariance\",  self.store_covariance)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = self.evaluate_sampled_model(\"classification\", QuadraticDiscriminantAnalysis, params)\n\t        self.model = model\n\t        return model"]}
{"filename": "tune_classifier/__init__.py", "chunked_list": ["from ..utils import make_default_tuner_type_mutable\n\tfrom .svc import *\n\tfrom .tree_classifier import *\n\tfrom .linear_model_classifier import *\n\tfrom .ensemble_classifier import *\n\tfrom .naive_bayes_classifier import *\n\tfrom .neighbor_classifier import *\n\tfrom .mlp_classifier import *\n\tfrom .discriminant_analysis_classifier import *\n\tfrom typing import Iterable, Dict, Callable\n", "classifier_tuner_model_class_map: Dict[str, Callable] = {\n\t    SVCTuner.__name__: SVC,\n\t    LinearSVCTuner.__name__: LinearSVC,\n\t    NuSVCTuner.__name__: NuSVC,\n\t    DecisionTreeClassifierTuner.__name__: DecisionTreeClassifier,\n\t    ExtraTreeClassifierTuner.__name__: ExtraTreeClassifier,\n\t    LogisticRegressionTuner.__name__: LogisticRegression,\n\t    PerceptronTuner.__name__: Perceptron,\n\t    PassiveAggressiveClassifierTuner.__name__: PassiveAggressiveClassifier,\n\t    SGDClassifierTuner.__name__: SGDClassifier,\n", "    RandomForestClassifierTuner.__name__: RandomForestClassifier,\n\t    ExtraTreesClassifierTuner.__name__: ExtraTreesClassifier,\n\t    AdaBoostClassifierTuner.__name__: AdaBoostClassifier,\n\t    GradientBoostingClassifierTuner.__name__: GradientBoostingClassifier,\n\t    BaggingClassifierTuner.__name__: BaggingClassifier,\n\t    HistGradientBoostingClassifierTuner.__name__: HistGradientBoostingClassifier,\n\t    GaussianNBTuner.__name__: GaussianNB,\n\t    BernoulliNBTuner.__name__: BernoulliNB,\n\t    MultinomialNBTuner.__name__: MultinomialNB,\n\t    ComplementNBTuner.__name__: ComplementNB,\n", "    CategoricalNBTuner.__name__: CategoricalNB,\n\t    KNeighborsClassifierTuner.__name__: KNeighborsClassifier,\n\t    RadiusNeighborsClassifierTuner.__name__: RadiusNeighborsClassifier,\n\t    NearestCentroidClassifierTuner.__name__: NearestCentroid,\n\t    MLPClassifierTuner.__name__: MLPClassifier,\n\t    LDAClassifierTuner.__name__: LinearDiscriminantAnalysis,\n\t    QDAClassifierTuner.__name__: QuadraticDiscriminantAnalysis,\n\t}\n\tclassifier_search_space: Dict[str, BaseTuner] = {\n\t    SVCTuner.__name__: SVCTuner(),\n", "    LinearSVCTuner.__name__: LinearSVCTuner(),\n\t    NuSVCTuner.__name__: NuSVCTuner(),\n\t    DecisionTreeClassifierTuner.__name__: DecisionTreeClassifierTuner(),\n\t    ExtraTreeClassifierTuner.__name__: ExtraTreeClassifierTuner(),\n\t    LogisticRegressionTuner.__name__: LogisticRegressionTuner(),\n\t    PerceptronTuner.__name__: PerceptronTuner(),\n\t    PassiveAggressiveClassifierTuner.__name__: PassiveAggressiveClassifierTuner(),\n\t    SGDClassifierTuner.__name__: SGDClassifierTuner(),\n\t    RandomForestClassifierTuner.__name__: RandomForestClassifierTuner(),\n\t    ExtraTreesClassifierTuner.__name__: ExtraTreesClassifierTuner(),\n", "    AdaBoostClassifierTuner.__name__: AdaBoostClassifierTuner(),\n\t    GradientBoostingClassifierTuner.__name__: GradientBoostingClassifierTuner(),\n\t    BaggingClassifierTuner.__name__: BaggingClassifierTuner(),\n\t    HistGradientBoostingClassifierTuner.__name__: HistGradientBoostingClassifierTuner(),\n\t    GaussianNBTuner.__name__: GaussianNBTuner(),\n\t    BernoulliNBTuner.__name__: BernoulliNBTuner(),\n\t    MultinomialNBTuner.__name__: MultinomialNBTuner(),\n\t    ComplementNBTuner.__name__: ComplementNBTuner(),\n\t    CategoricalNBTuner.__name__: CategoricalNBTuner(),\n\t    KNeighborsClassifierTuner.__name__: KNeighborsClassifierTuner(),\n", "    RadiusNeighborsClassifierTuner.__name__: RadiusNeighborsClassifierTuner(),\n\t    NearestCentroidClassifierTuner.__name__: NearestCentroidClassifierTuner(),\n\t    MLPClassifierTuner.__name__: MLPClassifierTuner(),\n\t    LDAClassifierTuner.__name__: LDAClassifierTuner(),\n\t    QDAClassifierTuner.__name__: QDAClassifierTuner(),\n\t}\n\tclassifier_search_space: Dict[str, BaseTuner] = dict(\n\t    map(lambda pair : (pair[0], make_default_tuner_type_mutable(pair[1])), classifier_search_space.items())\n\t)\n\t__all__: Iterable[str] = [\n", "    \"classifier_tuner_model_class_map\",\n\t    \"classifier_search_space\",\n\t    \"SVCTuner\", \n\t    \"LinearSVCTuner\", \n\t    \"NuSVCTuner\", \n\t    \"DecisionTreeClassifierTuner\", \n\t    \"ExtraTreeClassifierTuner\", \n\t    \"LogisticRegressionTuner\", \n\t    \"PerceptronTuner\", \n\t    \"PassiveAggressiveClassifierTuner\", \n", "    \"SGDClassifierTuner\", \n\t    \"RandomForestClassifierTuner\", \n\t    \"ExtraTreesClassifierTuner\", \n\t    \"AdaBoostClassifierTuner\", \n\t    \"GradientBoostingClassifierTuner\", \n\t    \"BaggingClassifierTuner\", \n\t    \"HistGradientBoostingClassifierTuner\", \n\t    \"GaussianNBTuner\", \n\t    \"BernoulliNBTuner\", \n\t    \"MultinomialNBTuner\", \n", "    \"ComplementNBTuner\", \n\t    \"CategoricalNBTuner\", \n\t    \"KNeighborsClassifierTuner\", \n\t    \"MLPClassifierTuner\",\n\t    \"RadiusNeighborsClassifierTuner\",\n\t    \"NearestCentroidClassifierTuner\",\n\t    \"LDAClassifierTuner\",\n\t    \"QDAClassifierTuner\"\n\t]\n"]}
{"filename": "tune_classifier/mlp_classifier.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.neural_network import MLPClassifier\n\t@dataclass\n\tclass MLPClassifierTuner(BaseTuner):\n\t    n_hidden_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":5, \"step\":1, \"log\":False})\n\t    hidden_layer_sizes_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":200, \"step\":1, \"log\":True})\n", "    activation_space: Iterable[str] = (\"identity\", \"logistic\", \"tanh\", \"relu\")\n\t    solver_space: Iterable[str] = (\"lbfgs\", \"sgd\", \"adam\")\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":1e-4, \"high\":1.0, \"step\":None, \"log\":True})\n\t    batch_size_space: Dict[str, Any] = MappingProxyType({\"low\":8, \"high\":256, \"step\":1, \"log\":True})\n\t    learning_rate_space: Iterable[str] = (\"constant\", \"invscaling\", \"adaptive\")\n\t    learning_rate_init_space: Dict[str, Any] = MappingProxyType({\"low\":1e-4, \"high\":1e-2, \"step\":None, \"log\":True})\n\t    power_t_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":200, \"high\":1000, \"step\":1, \"log\":True})\n\t    shuffle_space: Iterable[bool] = (True, False)\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n", "    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":1e-2, \"step\":None, \"log\":True})\n\t    momentum_space: Dict[str, Any] = MappingProxyType({\"low\":0.9, \"high\":1.0, \"step\":None, \"log\":False})\n\t    nesterovs_momentum_space: Iterable[bool] = (True, False)\n\t    early_stopping_space: Iterable[bool] = (True, False)\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    beta_1_space: Dict[str, Any] = MappingProxyType({\"low\":0.9, \"high\":1.0, \"step\":None, \"log\":False})\n\t    beta_2_space: Dict[str, Any] = MappingProxyType({\"low\":0.9, \"high\":1.0, \"step\":None, \"log\":False})\n\t    epsilon_space: Dict[str, Any] = MappingProxyType({\"low\":1e-8, \"high\":1e-5, \"step\":None, \"log\":True})\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":3, \"high\":50, \"step\":1, \"log\":True})\n\t    max_fun_space: Dict[str, Any] = MappingProxyType({\"low\":10000, \"high\":20000, \"step\":1, \"log\":True})\n", "    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        n_hidden = trial.suggest_int(f\"{self.__class__.__name__}_n_hidden\", **dict(self.n_hidden_space))\n\t        params[\"hidden_layer_sizes\"] = tuple(trial.suggest_int(f\"hidden_layer_sizes_{i}\", \n\t                                                          **dict(self.hidden_layer_sizes_space)) \n\t                                                          for i in range(n_hidden))\n\t        params[\"activation\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_activation\", self.activation_space)\n\t        params[\"solver\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver\", self.solver_space)\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n", "        params[\"batch_size\"] = trial.suggest_int(f\"{self.__class__.__name__}_batch_size\", **dict(self.batch_size_space))\n\t        params[\"learning_rate\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_learning_rate\", self.learning_rate_space)\n\t        params[\"learning_rate_init\"] = trial.suggest_float(f\"{self.__class__.__name__}_learning_rate_init\", **dict(self.learning_rate_init_space))\n\t        if params[\"learning_rate\"] == \"invscaling\" and params[\"solver\"] == \"sgd\":\n\t            params[\"power_t\"] = trial.suggest_float(f\"{self.__class__.__name__}_power_t\", **dict(self.power_t_space))\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"shuffle\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shuffle\", self.shuffle_space)\n\t        params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        if params[\"solver\"] == \"sgd\":\n", "            params[\"momentum\"] = trial.suggest_float(f\"{self.__class__.__name__}_momentum\", **dict(self.momentum_space))\n\t            params[\"nesterovs_momentum\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_nesterovs_momentum\", self.nesterovs_momentum_space)\n\t        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n\t        params[\"beta_1\"] = trial.suggest_float(f\"{self.__class__.__name__}_beta_1\", **dict(self.beta_1_space))\n\t        params[\"beta_2\"] = trial.suggest_float(f\"{self.__class__.__name__}_beta_2\", **dict(self.beta_2_space))\n\t        params[\"epsilon\"] = trial.suggest_float(f\"{self.__class__.__name__}_epsilon\", **dict(self.epsilon_space))\n\t        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t        params[\"max_fun\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_fun\", **dict(self.max_fun_space))\n\t        return params\n", "    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", MLPClassifier, params)\n\t        self.model = model\n\t        return model"]}
{"filename": "tune_classifier/naive_bayes_classifier.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Callable,Iterable, Optional, Dict, Any, Union\n\tfrom types import MappingProxyType\n\tfrom sklearn.naive_bayes import (\n\t    BernoulliNB, \n\t    GaussianNB, \n\t    MultinomialNB, \n\t    ComplementNB, \n", "    CategoricalNB\n\t    )\n\t@dataclass\n\tclass GaussianNBTuner(BaseTuner):\n\t    priors_space: Iterable[Optional[Iterable[float]]] = (None,) \n\t    var_smoothing_space: Dict[str, Any] = MappingProxyType({\"low\":1e-10, \"high\":1e-6, \"step\":None, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"priors\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_priors\", self.priors_space)\n", "        params[\"var_smoothing\"] = trial.suggest_float(f\"{self.__class__.__name__}_var_smoothing\", **dict(self.var_smoothing_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", GaussianNB, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass BernoulliNBTuner(BaseTuner):\n", "    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    force_alpha_space: Iterable[bool] = (True, False)\n\t    set_binarize_space: Iterable[bool] = (True, False)\n\t    binarize_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_prior_space: Iterable[bool] = (True, False)\n\t    class_prior_space: Iterable[Optional[Iterable[float]]] = (None, )    #TODO: Implement array selections\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))        \n", "        params[\"force_alpha\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_force_alpha\", self.force_alpha_space)\n\t        use_binarize = trial.suggest_categorical(f\"{self.__class__.__name__}_set_binarize\", self.set_binarize_space)\n\t        if use_binarize:\n\t            params[\"binarize\"] = trial.suggest_float(f\"{self.__class__.__name__}_binarize\", **dict(self.binarize_space))\n\t        params[\"fit_prior\"] = trial.suggest_categorical(\"fit_prior\", self.fit_prior_space)\n\t        params[\"class_prior\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_prior\", self.class_prior_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = super().evaluate_sampled_model(\"classification\", BernoulliNB, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass MultinomialNBTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})   \n\t    force_alpha_space: Iterable[bool] = (True, False)\n\t    fit_prior_space: Iterable[bool] = (True, False)\n\t    class_prior_space: Iterable[Optional[Iterable[float]]] = (None, )\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n", "        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))        \n\t        params[\"force_alpha\"]  = trial.suggest_categorical(\"force_alpha\", self.force_alpha_space)\n\t        params[\"fit_prior\"] = trial.suggest_categorical(\"fit_prior\", self.fit_prior_space)\n\t        params[\"class_prior\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_prior\", self.class_prior_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n", "        model = super().evaluate_sampled_model(\"classification\", MultinomialNB, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass ComplementNBTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    force_alpha_space: Iterable[bool] = (True, False)\n\t    fit_prior_space: Iterable[bool] = (True, False)\n\t    class_prior_space: Iterable[Optional[Iterable[float]]] = (None, )\n\t    norm_space: Iterable[bool] = (True, False)\n", "    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"force_alpha\"]  = trial.suggest_categorical(\"force_alpha\", self.force_alpha_space)\n\t        params[\"fit_prior\"] = trial.suggest_categorical(\"fit_prior\", self.fit_prior_space)\n\t        params[\"class_prior\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_prior\", self.class_prior_space)        \n\t        params[\"norm\"] = trial.suggest_categorical(\"norm\", self.norm_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n", "        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", ComplementNB, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass CategoricalNBTuner(BaseTuner):\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    force_alpha_space: Iterable[bool] = (True, False)\n\t    fit_prior_space: Iterable[bool] = (True, False)\n", "    class_prior_space: Iterable[Optional[Iterable[float]]] = (None,)\n\t    min_categories_space: Iterable[Optional[Union[int, Iterable[int]]]] = (None,)\n\t    def sample_params(self, trial: Optional[Trial] = None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"force_alpha\"]  = trial.suggest_categorical(\"force_alpha\", self.force_alpha_space)\n\t        params[\"fit_prior\"] = trial.suggest_categorical(\"fit_prior\", self.fit_prior_space)\n\t        params[\"class_prior\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_prior\", self.class_prior_space)        \n\t        params[\"min_categories\"] = trial.suggest_categorical(\"min_categories\", self.min_categories_space)    \n", "        return params\n\t    def sample_model(self, trial: Optional[Trial] = None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", CategoricalNB, params)\n\t        self.model = model\n\t        return model"]}
{"filename": "tune_classifier/linear_model_classifier.py", "chunked_list": ["from ..baseline import BaseTuner\n\tfrom optuna.trial import Trial\n\tfrom dataclasses import dataclass\n\tfrom typing import Iterable, Optional, Dict, Any, Callable\n\tfrom types import MappingProxyType\n\tfrom sklearn.linear_model import (\n\t    LogisticRegression, \n\t    Perceptron, \n\t    PassiveAggressiveClassifier,\n\t    SGDClassifier)\n", "@dataclass\n\tclass LogisticRegressionTuner(BaseTuner):\n\t    penalty_space: Iterable[Optional[str]] = (\"l1\", \"l2\", \"elasticnet\", None)\n\t    dual_space: Iterable[bool] = (True, False)\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.9, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    intercept_scaling_space: Dict[str, Any] = MappingProxyType({\"low\":0.5, \"high\":1.0, \"step\":None, \"log\":False})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n\t    solver_space: Iterable[str] = (\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\")\n", "    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":1000, \"step\":1, \"log\":True})\n\t    multi_class_space: Iterable[str] = (\"auto\", )\n\t    l1_ratio_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"penalty\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_penalty\", self.penalty_space)\n\t        params[\"dual\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_dual\", self.dual_space)\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n", "        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"intercept_scaling\"] = trial.suggest_float(f\"{self.__class__.__name__}_intercept_scaling\", **dict(self.intercept_scaling_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        params[\"solver\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_solver\", self.solver_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"multi_class\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_multi_class\", self.multi_class_space)\n\t        if params[\"penalty\"] == \"elasticnet\":\n\t            params[\"l1_ratio\"] = trial.suggest_float(f\"{self.__class__.__name__}_l1_ratio\", **dict(self.l1_ratio_space))\n\t        if params[\"solver\"] in [\"sag\", \"saga\", \"liblinear\"]:\n", "            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", LogisticRegression, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass PerceptronTuner(BaseTuner):\n", "    penalty_space: Iterable[Optional[str]] = (\"l1\", \"l2\", \"elasticnet\", None)\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":1.0, \"step\":None, \"log\":True})\n\t    l1_ratio_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    shuffle_space: Iterable[bool] = (True, False)\n\t    eta0_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    early_stopping_space: Iterable[bool] = (True, False)\n", "    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"penalty\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_penalty\", self.penalty_space)\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"l1_ratio\"] = trial.suggest_float(f\"{self.__class__.__name__}_l1_ratio\", **dict(self.l1_ratio_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n", "        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"shuffle\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shuffle\", self.shuffle_space)\n\t        if params[\"shuffle\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"eta0\"] = trial.suggest_float(f\"{self.__class__.__name__}_eta0\", **dict(self.eta0_space))\n\t        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n\t        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n", "        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", Perceptron, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass PassiveAggressiveClassifierTuner(BaseTuner):\n\t    C_space: Dict[str, Any] = MappingProxyType({\"low\":0.9, \"high\":1.0, \"step\":None, \"log\":False})\n", "    fit_intercept_space: Iterable[bool] = (True, False)\n\t    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    early_stopping_space: Iterable[bool] = (True, False)\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n\t    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    shuffle_space: Iterable[bool] = (True, False)\n\t    loss_space: Iterable[str] = (\"hinge\", )\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n", "    average_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"C\"] = trial.suggest_float(f\"{self.__class__.__name__}_C\", **dict(self.C_space))\n\t        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n", "        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t        params[\"shuffle\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shuffle\", self.shuffle_space)\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        if params[\"shuffle\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        params[\"average\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_average\", self.average_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n", "        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", PassiveAggressiveClassifier, params)\n\t        self.model = model\n\t        return model\n\t@dataclass\n\tclass SGDClassifierTuner(BaseTuner):\n\t    loss_space: Iterable[str] = (\n\t        \"hinge\", \n\t        \"log_loss\", \n\t        \"modified_huber\", \n", "        \"squared_hinge\", \n\t        \"perceptron\", \n\t        \"squared_error\",\n\t        \"huber\", \n\t        \"epsilon_insensitive\", \n\t        \"squared_epsilon_insensitive\")\n\t    penalty_space: Iterable[str] = (\"l1\", \"l2\", \"elasticnet\", None)\n\t    alpha_space: Dict[str, Any] = MappingProxyType({\"low\":1e-5, \"high\":1.0, \"step\":None, \"log\":True})\n\t    l1_ratio_space: Dict[str, Any] = MappingProxyType({\"low\":0.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    fit_intercept_space: Iterable[bool] = (True, False)\n", "    max_iter_space: Dict[str, Any] = MappingProxyType({\"low\":100, \"high\":2000, \"step\":1, \"log\":True})\n\t    tol_space: Dict[str, Any] = MappingProxyType({\"low\":1e-6, \"high\":1e-3, \"step\":None, \"log\":True})\n\t    shuffle_space: Iterable[bool] = (True, False)\n\t    epsilon_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    random_state_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":10000, \"step\":1, \"log\":True})\n\t    learning_rate_space: Iterable[str] = (\"constant\", \"optimal\", \"invscaling\", \"adaptive\")\n\t    eta0_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":1.0, \"step\":None, \"log\":False})\n\t    power_t_space: Dict[str, Any] = MappingProxyType({\"low\":-1.0, \"high\":1.0, \"step\":None, \"log\":False})\n\t    early_stopping_space: Iterable[bool] = (True, False)\n\t    validation_fraction_space: Dict[str, Any] = MappingProxyType({\"low\":0.1, \"high\":0.5, \"step\":None, \"log\":False})\n", "    n_iter_no_change_space: Dict[str, Any] = MappingProxyType({\"low\":1, \"high\":100, \"step\":1, \"log\":True})\n\t    class_weight_space: Iterable[str] = (\"balanced\", )\n\t    average_space: Iterable[bool] = (True, False)\n\t    def sample_params(self, trial: Optional[Trial]=None) -> Dict[str, Any]:\n\t        super().sample_params(trial)\n\t        params = {}\n\t        params[\"loss\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_loss\", self.loss_space)\n\t        params[\"penalty\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_penalty\", self.penalty_space)\n\t        params[\"alpha\"] = trial.suggest_float(f\"{self.__class__.__name__}_alpha\", **dict(self.alpha_space))\n\t        params[\"l1_ratio\"] = trial.suggest_float(f\"{self.__class__.__name__}_l1_ratio\", **dict(self.l1_ratio_space))\n", "        params[\"fit_intercept\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_fit_intercept\", self.fit_intercept_space)\n\t        params[\"max_iter\"] = trial.suggest_int(f\"{self.__class__.__name__}_max_iter\", **dict(self.max_iter_space))\n\t        params[\"tol\"] = trial.suggest_float(f\"{self.__class__.__name__}_tol\", **dict(self.tol_space))\n\t        params[\"shuffle\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_shuffle\", self.shuffle_space)\n\t        params[\"epsilon\"] = trial.suggest_float(f\"{self.__class__.__name__}_epsilon\", **dict(self.epsilon_space))\n\t        if params[\"shuffle\"]:\n\t            params[\"random_state\"] = trial.suggest_int(f\"{self.__class__.__name__}_random_state\", **dict(self.random_state_space))\n\t        params[\"learning_rate\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_learning_rate\", self.learning_rate_space)\n\t        params[\"eta0\"] = trial.suggest_float(f\"{self.__class__.__name__}_eta0\", **dict(self.eta0_space))\n\t        params[\"power_t\"] = trial.suggest_float(f\"{self.__class__.__name__}_power_t\", **dict(self.power_t_space))\n", "        params[\"early_stopping\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_early_stopping\", self.early_stopping_space)\n\t        params[\"validation_fraction\"] = trial.suggest_float(f\"{self.__class__.__name__}_validation_fraction\", **dict(self.validation_fraction_space))\n\t        params[\"n_iter_no_change\"] = trial.suggest_int(f\"{self.__class__.__name__}_n_iter_no_change\", **dict(self.n_iter_no_change_space))\n\t        params[\"class_weight\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_class_weight\", self.class_weight_space)\n\t        params[\"average\"] = trial.suggest_categorical(f\"{self.__class__.__name__}_average\", self.average_space)\n\t        return params\n\t    def sample_model(self, trial: Optional[Trial]=None) -> Any:\n\t        super().sample_model(trial)\n\t        params = self.sample_params(trial)\n\t        model = super().evaluate_sampled_model(\"classification\", SGDClassifier, params)\n", "        self.model = model\n\t        return model"]}
