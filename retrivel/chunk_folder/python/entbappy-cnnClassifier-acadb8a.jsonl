{"filename": "setup.py", "chunked_list": ["import setuptools\n\twith open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n\t    long_description = f.read()\n\t__version__ = \"0.0.0\"\n\tREPO_NAME = \"cnnClassifier\"\n\tAUTHOR_USER_NAME = \"entbappy\"\n\tSRC_REPO = \"cnnClassifier\"\n\tAUTHOR_EMAIL = \"entbappy73@gmail.com\"\n\tsetuptools.setup(\n\t    name=SRC_REPO,\n", "    version=__version__,\n\t    author=AUTHOR_USER_NAME,\n\t    author_email=AUTHOR_EMAIL,\n\t    description=\"A small python package for CNN app\",\n\t    long_description=long_description,\n\t    long_description_content=\"text/markdown\",\n\t    url=f\"https://github.com/{AUTHOR_USER_NAME}/{REPO_NAME}\",\n\t    project_urls={\n\t        \"Bug Tracker\": f\"https://github.com/{AUTHOR_USER_NAME}/{REPO_NAME}/issues\",\n\t    },\n", "    package_dir={\"\": \"src\"},\n\t    packages=setuptools.find_packages(where=\"src\")\n\t)"]}
{"filename": "main.py", "chunked_list": ["from cnnClassifier.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline\n\tfrom cnnClassifier.pipeline.stage_02_prepare_base_model import PrepareBaseModelTrainingPipeline\n\tfrom cnnClassifier.pipeline.stage_03_training import ModelTrainingPipeline\n\tfrom cnnClassifier.pipeline.stage_04_evaluation import EvaluationPipeline\n\tfrom cnnClassifier import logger\n\tSTAGE_NAME = \"Data Ingestion stage\"\n\ttry:\n\t   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\") \n\t   data_ingestion = DataIngestionTrainingPipeline()\n\t   data_ingestion.main()\n", "   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n\texcept Exception as e:\n\t        logger.exception(e)\n\t        raise e\n\tSTAGE_NAME = \"Prepare base model\"\n\ttry: \n\t   logger.info(f\"*******************\")\n\t   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n\t   prepare_base_model = PrepareBaseModelTrainingPipeline()\n\t   prepare_base_model.main()\n", "   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n\texcept Exception as e:\n\t        logger.exception(e)\n\t        raise e\n\tSTAGE_NAME = \"Training\"\n\ttry: \n\t   logger.info(f\"*******************\")\n\t   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n\t   model_trainer = ModelTrainingPipeline()\n\t   model_trainer.main()\n", "   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n\texcept Exception as e:\n\t        logger.exception(e)\n\t        raise e\n\tSTAGE_NAME = \"Evaluation stage\"\n\ttry:\n\t   logger.info(f\"*******************\")\n\t   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n\t   model_evalution = EvaluationPipeline()\n\t   model_evalution.main()\n", "   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n\texcept Exception as e:\n\t        logger.exception(e)\n\t        raise e\n"]}
{"filename": "app.py", "chunked_list": ["from flask import Flask, request, jsonify, render_template\n\timport os\n\tfrom flask_cors import CORS, cross_origin\n\tfrom cnnClassifier.utils import decodeImage\n\tfrom cnnClassifier.pipeline.predict import DogCat\n\tos.putenv('LANG', 'en_US.UTF-8')\n\tos.putenv('LC_ALL', 'en_US.UTF-8')\n\tapp = Flask(__name__)\n\tCORS(app)\n\tclass ClientApp:\n", "    def __init__(self):\n\t        self.filename = \"inputImage.jpg\"\n\t        self.classifier = DogCat(self.filename)\n\t@app.route(\"/\", methods=['GET'])\n\t@cross_origin()\n\tdef home():\n\t    return render_template('index.html')\n\t@app.route(\"/train\", methods=['GET','POST'])\n\t@cross_origin()\n\tdef trainRoute():\n", "    os.system(\"python main.py\")\n\t    return \"Training done successfully!\"\n\t@app.route(\"/predict\", methods=['POST'])\n\t@cross_origin()\n\tdef predictRoute():\n\t    image = request.json['image']\n\t    decodeImage(image, clApp.filename)\n\t    result = clApp.classifier.predictiondogcat()\n\t    return jsonify(result)\n\tif __name__ == \"__main__\":\n", "    clApp = ClientApp()\n\t    app.run(host='0.0.0.0', port=8080)\n"]}
{"filename": "template.py", "chunked_list": ["import os\n\tfrom pathlib import Path\n\timport logging\n\tlogging.basicConfig(level=logging.INFO, format='[%(asctime)s]: %(message)s:')\n\tproject_name = \"cnnClassifier\"\n\tlist_of_files = [\n\t    \".github/workflows/.gitkeep\",\n\t    f\"src/{project_name}/__init__.py\",\n\t    f\"src/{project_name}/components/__init__.py\",\n\t    f\"src/{project_name}/utils/__init__.py\",\n", "    f\"src/{project_name}/config/__init__.py\",\n\t    f\"src/{project_name}/pipeline/__init__.py\",\n\t    f\"src/{project_name}/entity/__init__.py\",\n\t    f\"src/{project_name}/constants/__init__.py\",\n\t    \"config/config.yaml\",\n\t    \"params.yaml\",\n\t    \"requirements.txt\",\n\t    \"setup.py\",\n\t    \"research/trials.ipynb\"\n\t]\n", "for filepath in list_of_files:\n\t    filepath = Path(filepath)\n\t    filedir, filename = os.path.split(filepath)\n\t    if filedir != \"\":\n\t        os.makedirs(filedir, exist_ok=True)\n\t        logging.info(f\"Creating directory: {filedir} for file: {filename}\")\n\t    if (not os.path.exists(filepath)) or (os.path.getsize(filepath) == 0):\n\t        with open(filepath, 'w') as f:\n\t            pass #creating an empty file only\n\t            logging.info(f\"Creating empty file: {filepath}\")\n", "    else:\n\t        logging.info(f\"{filename} is already exists\")\n"]}
{"filename": "test.py", "chunked_list": ["from cnnClassifier import logging\n\tlogging.info(\"Welcome to our custom Log\")"]}
{"filename": "src/cnnClassifier/__init__.py", "chunked_list": ["import os\n\timport sys\n\timport logging\n\tlogging_str = \"[%(asctime)s: %(levelname)s: %(module)s: %(message)s]\"\n\tlog_dir = \"logs\"\n\tlog_filepath = os.path.join(log_dir,\"running_logs.log\")\n\tos.makedirs(log_dir, exist_ok=True)\n\tlogging.basicConfig(\n\t    level= logging.INFO,\n\t    format= logging_str,\n", "    handlers=[\n\t        logging.FileHandler(log_filepath),\n\t        logging.StreamHandler(sys.stdout)\n\t    ]\n\t)\n\tlogger = logging.getLogger(\"cnnClassifierLogger\")"]}
{"filename": "src/cnnClassifier/components/evaluation.py", "chunked_list": ["import tensorflow as tf\n\tfrom pathlib import Path\n\tfrom cnnClassifier.entity import EvaluationConfig\n\tfrom cnnClassifier.utils import save_json\n\tclass Evaluation:\n\t    def __init__(self, config: EvaluationConfig):\n\t        self.config = config\n\t    def _valid_generator(self):\n\t        datagenerator_kwargs = dict(\n\t            rescale = 1./255,\n", "            validation_split=0.30\n\t        )\n\t        dataflow_kwargs = dict(\n\t            target_size=self.config.params_image_size[:-1],\n\t            batch_size=self.config.params_batch_size,\n\t            interpolation=\"bilinear\"\n\t        )\n\t        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n\t            **datagenerator_kwargs\n\t        )\n", "        self.valid_generator = valid_datagenerator.flow_from_directory(\n\t            directory=self.config.training_data,\n\t            subset=\"validation\",\n\t            shuffle=False,\n\t            **dataflow_kwargs\n\t        )\n\t    @staticmethod\n\t    def load_model(path: Path) -> tf.keras.Model:\n\t        return tf.keras.models.load_model(path)\n\t    def evaluation(self):\n", "        model = self.load_model(self.config.path_of_model)\n\t        self._valid_generator()\n\t        self.score = model.evaluate(self.valid_generator)\n\t    def save_score(self):\n\t        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n\t        save_json(path=Path(\"scores.json\"), data=scores)\n"]}
{"filename": "src/cnnClassifier/components/__init__.py", "chunked_list": ["from cnnClassifier.components.data_ingestion import DataIngestion\n\tfrom cnnClassifier.components.prepare_base_model import PrepareBaseModel\n\tfrom cnnClassifier.components.prepare_callback import PrepareCallback\n\tfrom cnnClassifier.components.training import Training\n\tfrom cnnClassifier.components.evaluation import Evaluation\n"]}
{"filename": "src/cnnClassifier/components/prepare_base_model.py", "chunked_list": ["from pathlib import Path\n\timport tensorflow as tf\n\tfrom cnnClassifier.entity import PrepareBaseModelConfig\n\tclass PrepareBaseModel:\n\t    def __init__(self, config: PrepareBaseModelConfig):\n\t        self.config = config\n\t    def get_base_model(self):\n\t        self.model = tf.keras.applications.vgg16.VGG16(\n\t            input_shape=self.config.params_image_size,\n\t            weights=self.config.params_weights,\n", "            include_top=self.config.params_include_top\n\t        )\n\t        self.save_model(path=self.config.base_model_path, model=self.model)\n\t    @staticmethod\n\t    def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n\t        if freeze_all:\n\t            for layer in model.layers:\n\t                model.trainable = False\n\t        elif (freeze_till is not None) and (freeze_till > 0):\n\t            for layer in model.layers[:-freeze_till]:\n", "                model.trainable = False\n\t        flatten_in = tf.keras.layers.Flatten()(model.output)\n\t        prediction = tf.keras.layers.Dense(\n\t            units=classes,\n\t            activation=\"softmax\"\n\t        )(flatten_in)\n\t        full_model = tf.keras.models.Model(\n\t            inputs=model.input,\n\t            outputs=prediction\n\t        )\n", "        full_model.compile(\n\t            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n\t            loss=tf.keras.losses.CategoricalCrossentropy(),\n\t            metrics=[\"accuracy\"]\n\t        )\n\t        full_model.summary()\n\t        return full_model\n\t    def update_base_model(self):\n\t        self.full_model = self._prepare_full_model(\n\t            model=self.model,\n", "            classes=self.config.params_classes,\n\t            freeze_all=True,\n\t            freeze_till=None,\n\t            learning_rate=self.config.params_learning_rate\n\t        )\n\t        self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n\t    @staticmethod\n\t    def save_model(path: Path, model: tf.keras.Model):\n\t        model.save(path)\n"]}
{"filename": "src/cnnClassifier/components/training.py", "chunked_list": ["from cnnClassifier.entity import TrainingConfig\n\timport tensorflow as tf\n\tfrom pathlib import Path\n\tclass Training:\n\t    def __init__(self, config: TrainingConfig):\n\t        self.config = config\n\t    def get_base_model(self):\n\t        self.model = tf.keras.models.load_model(\n\t            self.config.updated_base_model_path\n\t        )\n", "    def train_valid_generator(self):\n\t        datagenerator_kwargs = dict(\n\t            rescale = 1./255,\n\t            validation_split=0.20\n\t        )\n\t        dataflow_kwargs = dict(\n\t            target_size=self.config.params_image_size[:-1],\n\t            batch_size=self.config.params_batch_size,\n\t            interpolation=\"bilinear\"\n\t        )\n", "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n\t            **datagenerator_kwargs\n\t        )\n\t        self.valid_generator = valid_datagenerator.flow_from_directory(\n\t            directory=self.config.training_data,\n\t            subset=\"validation\",\n\t            shuffle=False,\n\t            **dataflow_kwargs\n\t        )\n\t        if self.config.params_is_augmentation:\n", "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n\t                rotation_range=40,\n\t                horizontal_flip=True,\n\t                width_shift_range=0.2,\n\t                height_shift_range=0.2,\n\t                shear_range=0.2,\n\t                zoom_range=0.2,\n\t                **datagenerator_kwargs\n\t            )\n\t        else:\n", "            train_datagenerator = valid_datagenerator\n\t        self.train_generator = train_datagenerator.flow_from_directory(\n\t            directory=self.config.training_data,\n\t            subset=\"training\",\n\t            shuffle=True,\n\t            **dataflow_kwargs\n\t        )\n\t    @staticmethod\n\t    def save_model(path: Path, model: tf.keras.Model):\n\t        model.save(path)\n", "    def train(self, callback_list: list):\n\t        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n\t        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n\t        self.model.fit(\n\t            self.train_generator,\n\t            epochs=self.config.params_epochs,\n\t            steps_per_epoch=self.steps_per_epoch,\n\t            validation_steps=self.validation_steps,\n\t            validation_data=self.valid_generator,\n\t            callbacks=callback_list\n", "        )\n\t        self.save_model(\n\t            path=self.config.trained_model_path,\n\t            model=self.model\n\t        )\n"]}
{"filename": "src/cnnClassifier/components/prepare_callback.py", "chunked_list": ["import tensorflow as tf\n\timport time\n\timport os\n\tfrom cnnClassifier.entity import PrepareCallbacksConfig\n\tclass PrepareCallback:\n\t    def __init__(self, config: PrepareCallbacksConfig):\n\t        self.config = config\n\t    @property\n\t    def _create_tb_callbacks(self):\n\t        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n", "        tb_running_log_dir = os.path.join(\n\t            self.config.tensorboard_root_log_dir,\n\t            f\"tb_logs_at_{timestamp}\",\n\t        )\n\t        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n\t    @property\n\t    def _create_ckpt_callbacks(self):\n\t        return tf.keras.callbacks.ModelCheckpoint(\n\t            filepath=self.config.checkpoint_model_filepath,\n\t            save_best_only=True\n", "        )\n\t    def get_tb_ckpt_callbacks(self):\n\t        return [\n\t            self._create_tb_callbacks,\n\t            self._create_ckpt_callbacks\n\t        ]\n"]}
{"filename": "src/cnnClassifier/components/data_ingestion.py", "chunked_list": ["import os\n\timport urllib.request as request\n\tfrom zipfile import ZipFile\n\tfrom tqdm import tqdm\n\tfrom pathlib import Path\n\tfrom cnnClassifier.entity import DataIngestionConfig\n\tfrom cnnClassifier import logger\n\tfrom cnnClassifier.utils import get_size\n\tclass DataIngestion:\n\t    def __init__(self, config: DataIngestionConfig):\n", "        self.config = config\n\t    def download_file(self):\n\t        logger.info(\"Trying to download file...\")\n\t        if not os.path.exists(self.config.local_data_file):\n\t            logger.info(\"Download started...\")\n\t            filename, headers = request.urlretrieve(\n\t                url=self.config.source_URL,\n\t                filename=self.config.local_data_file\n\t            )\n\t            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n", "        else:\n\t            logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")        \n\t    def _get_updated_list_of_files(self, list_of_files):\n\t        return [f for f in list_of_files if f.endswith(\".jpg\") and (\"Cat\" in f or \"Dog\" in f)]\n\t    def _preprocess(self, zf: ZipFile, f: str, working_dir: str):\n\t        target_filepath = os.path.join(working_dir, f)\n\t        if not os.path.exists(target_filepath):\n\t            zf.extract(f, working_dir)\n\t        if os.path.getsize(target_filepath) == 0:\n\t            logger.info(f\"removing file:{target_filepath} of size: {get_size(Path(target_filepath))}\")\n", "            os.remove(target_filepath)\n\t    def unzip_and_clean(self):\n\t        logger.info(f\"unzipping file and removing unawanted files\")\n\t        with ZipFile(file=self.config.local_data_file, mode=\"r\") as zf:\n\t            list_of_files = zf.namelist()\n\t            updated_list_of_files = self._get_updated_list_of_files(list_of_files)\n\t            for f in tqdm(updated_list_of_files):\n\t                self._preprocess(zf, f, self.config.unzip_dir)"]}
{"filename": "src/cnnClassifier/entity/config_entity.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom pathlib import Path\n\t@dataclass(frozen=True)\n\tclass DataIngestionConfig:\n\t    root_dir: Path\n\t    source_URL: str\n\t    local_data_file: Path\n\t    unzip_dir: Path\n\t@dataclass(frozen=True)\n\tclass PrepareBaseModelConfig:\n", "    root_dir: Path\n\t    base_model_path: Path\n\t    updated_base_model_path: Path\n\t    params_image_size: list\n\t    params_learning_rate: float\n\t    params_include_top: bool\n\t    params_weights: str\n\t    params_classes: int\n\t@dataclass(frozen=True)\n\tclass PrepareCallbacksConfig:\n", "    root_dir: Path\n\t    tensorboard_root_log_dir: Path\n\t    checkpoint_model_filepath: Path\n\t@dataclass(frozen=True)\n\tclass TrainingConfig:\n\t    root_dir: Path\n\t    trained_model_path: Path\n\t    updated_base_model_path: Path\n\t    training_data: Path\n\t    params_epochs: int\n", "    params_batch_size: int\n\t    params_is_augmentation: bool\n\t    params_image_size: list\n\t@dataclass(frozen=True)\n\tclass EvaluationConfig:\n\t    path_of_model: Path\n\t    training_data: Path\n\t    params_image_size: list\n\t    params_batch_size: int"]}
{"filename": "src/cnnClassifier/entity/__init__.py", "chunked_list": ["from cnnClassifier.entity.config_entity import (DataIngestionConfig,\n\t                                                PrepareBaseModelConfig,\n\t                                                PrepareCallbacksConfig,\n\t                                                TrainingConfig,\n\t                                                EvaluationConfig)"]}
{"filename": "src/cnnClassifier/utils/__init__.py", "chunked_list": ["from cnnClassifier.utils.common import *"]}
{"filename": "src/cnnClassifier/utils/common.py", "chunked_list": ["import os\n\tfrom box.exceptions import BoxValueError\n\timport yaml\n\tfrom cnnClassifier import logger\n\timport json\n\timport joblib\n\tfrom ensure import ensure_annotations\n\tfrom box import ConfigBox\n\tfrom pathlib import Path\n\tfrom typing import Any\n", "import base64\n\t@ensure_annotations\n\tdef read_yaml(path_to_yaml: Path) -> ConfigBox:\n\t    \"\"\"reads yaml file and returns\n\t    Args:\n\t        path_to_yaml (str): path like input\n\t    Raises:\n\t        ValueError: if yaml file is empty\n\t        e: empty file\n\t    Returns:\n", "        ConfigBox: ConfigBox type\n\t    \"\"\"\n\t    try:\n\t        with open(path_to_yaml) as yaml_file:\n\t            content = yaml.safe_load(yaml_file)\n\t            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n\t            return ConfigBox(content)\n\t    except BoxValueError:\n\t        raise ValueError(\"yaml file is empty\")\n\t    except Exception as e:\n", "        raise e\n\t@ensure_annotations\n\tdef create_directories(path_to_directories: list, verbose=True):\n\t    \"\"\"create list of directories\n\t    Args:\n\t        path_to_directories (list): list of path of directories\n\t        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n\t    \"\"\"\n\t    for path in path_to_directories:\n\t        os.makedirs(path, exist_ok=True)\n", "        if verbose:\n\t            logger.info(f\"created directory at: {path}\")\n\t@ensure_annotations\n\tdef save_json(path: Path, data: dict):\n\t    \"\"\"save json data\n\t    Args:\n\t        path (Path): path to json file\n\t        data (dict): data to be saved in json file\n\t    \"\"\"\n\t    with open(path, \"w\") as f:\n", "        json.dump(data, f, indent=4)\n\t    logger.info(f\"json file saved at: {path}\")\n\t@ensure_annotations\n\tdef load_json(path: Path) -> ConfigBox:\n\t    \"\"\"load json files data\n\t    Args:\n\t        path (Path): path to json file\n\t    Returns:\n\t        ConfigBox: data as class attributes instead of dict\n\t    \"\"\"\n", "    with open(path) as f:\n\t        content = json.load(f)\n\t    logger.info(f\"json file loaded succesfully from: {path}\")\n\t    return ConfigBox(content)\n\t@ensure_annotations\n\tdef save_bin(data: Any, path: Path):\n\t    \"\"\"save binary file\n\t    Args:\n\t        data (Any): data to be saved as binary\n\t        path (Path): path to binary file\n", "    \"\"\"\n\t    joblib.dump(value=data, filename=path)\n\t    logger.info(f\"binary file saved at: {path}\")\n\t@ensure_annotations\n\tdef load_bin(path: Path) -> Any:\n\t    \"\"\"load binary data\n\t    Args:\n\t        path (Path): path to binary file\n\t    Returns:\n\t        Any: object stored in the file\n", "    \"\"\"\n\t    data = joblib.load(path)\n\t    logger.info(f\"binary file loaded from: {path}\")\n\t    return data\n\t@ensure_annotations\n\tdef get_size(path: Path) -> str:\n\t    \"\"\"get size in KB\n\t    Args:\n\t        path (Path): path of the file\n\t    Returns:\n", "        str: size in KB\n\t    \"\"\"\n\t    size_in_kb = round(os.path.getsize(path)/1024)\n\t    return f\"~ {size_in_kb} KB\"\n\tdef decodeImage(imgstring, fileName):\n\t    imgdata = base64.b64decode(imgstring)\n\t    with open(fileName, 'wb') as f:\n\t        f.write(imgdata)\n\t        f.close()\n\tdef encodeImageIntoBase64(croppedImagePath):\n", "    with open(croppedImagePath, \"rb\") as f:\n\t        return base64.b64encode(f.read())"]}
{"filename": "src/cnnClassifier/config/__init__.py", "chunked_list": ["from cnnClassifier.config.configuration import ConfigurationManager"]}
{"filename": "src/cnnClassifier/config/configuration.py", "chunked_list": ["from cnnClassifier.utils import read_yaml, create_directories\n\tfrom cnnClassifier.constants import *\n\tfrom pathlib import Path\n\timport os\n\tfrom cnnClassifier.entity import (DataIngestionConfig,\n\t                                  PrepareBaseModelConfig,\n\t                                  PrepareCallbacksConfig,\n\t                                  TrainingConfig,\n\t                                  EvaluationConfig)\n\tclass ConfigurationManager:\n", "    def __init__(\n\t        self, \n\t        config_filepath = CONFIG_FILE_PATH,\n\t        params_filepath = PARAMS_FILE_PATH):\n\t        self.config = read_yaml(config_filepath)\n\t        self.params = read_yaml(params_filepath)\n\t        create_directories([self.config.artifacts_root])\n\t    def get_data_ingestion_config(self) -> DataIngestionConfig:\n\t        config = self.config.data_ingestion\n\t        create_directories([config.root_dir])\n", "        data_ingestion_config = DataIngestionConfig(\n\t            root_dir=config.root_dir,\n\t            source_URL=config.source_URL,\n\t            local_data_file=config.local_data_file,\n\t            unzip_dir=config.unzip_dir \n\t        )\n\t        return data_ingestion_config\n\t    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n\t        config = self.config.prepare_base_model\n\t        create_directories([config.root_dir])\n", "        prepare_base_model_config = PrepareBaseModelConfig(\n\t            root_dir=Path(config.root_dir),\n\t            base_model_path=Path(config.base_model_path),\n\t            updated_base_model_path=Path(config.updated_base_model_path),\n\t            params_image_size=self.params.IMAGE_SIZE,\n\t            params_learning_rate=self.params.LEARNING_RATE,\n\t            params_include_top=self.params.INCLUDE_TOP,\n\t            params_weights=self.params.WEIGHTS,\n\t            params_classes=self.params.CLASSES\n\t        )\n", "        return prepare_base_model_config\n\t    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n\t        config = self.config.prepare_callbacks\n\t        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n\t        create_directories([\n\t            Path(model_ckpt_dir),\n\t            Path(config.tensorboard_root_log_dir)\n\t        ])\n\t        prepare_callback_config = PrepareCallbacksConfig(\n\t            root_dir=Path(config.root_dir),\n", "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n\t            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n\t        )\n\t        return prepare_callback_config\n\t    def get_training_config(self) -> TrainingConfig:\n\t        training = self.config.training\n\t        prepare_base_model = self.config.prepare_base_model\n\t        params = self.params\n\t        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"PetImages\")\n\t        create_directories([\n", "            Path(training.root_dir)\n\t        ])\n\t        training_config = TrainingConfig(\n\t            root_dir=Path(training.root_dir),\n\t            trained_model_path=Path(training.trained_model_path),\n\t            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n\t            training_data=Path(training_data),\n\t            params_epochs=params.EPOCHS,\n\t            params_batch_size=params.BATCH_SIZE,\n\t            params_is_augmentation=params.AUGMENTATION,\n", "            params_image_size=params.IMAGE_SIZE\n\t        )\n\t        return training_config\n\t    def get_validation_config(self) -> EvaluationConfig:\n\t        eval_config = EvaluationConfig(\n\t            path_of_model=self.config.training.trained_model_path,\n\t            training_data=self.config.data_ingestion.unzip_dir,\n\t            params_image_size=self.params.IMAGE_SIZE,\n\t            params_batch_size=self.params.BATCH_SIZE\n\t        )\n", "        return eval_config\n"]}
{"filename": "src/cnnClassifier/pipeline/predict.py", "chunked_list": ["import numpy as np\n\tfrom tensorflow.keras.models import load_model\n\tfrom tensorflow.keras.preprocessing import image\n\timport os\n\tclass DogCat:\n\t    def __init__(self,filename):\n\t        self.filename =filename\n\t    def predictiondogcat(self):\n\t        # load model\n\t        model = load_model(os.path.join(\"artifacts\",\"training\", \"model.h5\"))\n", "        imagename = self.filename\n\t        test_image = image.load_img(imagename, target_size = (224,224))\n\t        test_image = image.img_to_array(test_image)\n\t        test_image = np.expand_dims(test_image, axis = 0)\n\t        result = np.argmax(model.predict(test_image), axis=1)\n\t        print(result)\n\t        if result[0] == 1:\n\t            prediction = 'dog'\n\t            return [{ \"image\" : prediction}]\n\t        else:\n", "            prediction = 'cat'\n\t            return [{ \"image\" : prediction}]\n"]}
{"filename": "src/cnnClassifier/pipeline/stage_02_prepare_base_model.py", "chunked_list": ["from cnnClassifier.config import ConfigurationManager\n\tfrom cnnClassifier.components import PrepareBaseModel\n\tfrom cnnClassifier import logger\n\tclass PrepareBaseModelTrainingPipeline:\n\t    def __init__(self):\n\t        pass\n\t    def main(self):\n\t        config = ConfigurationManager()\n\t        prepare_base_model_config = config.get_prepare_base_model_config()\n\t        prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n", "        prepare_base_model.get_base_model()\n\t        prepare_base_model.update_base_model()"]}
{"filename": "src/cnnClassifier/pipeline/__init__.py", "chunked_list": []}
{"filename": "src/cnnClassifier/pipeline/stage_01_data_ingestion.py", "chunked_list": ["from cnnClassifier.config import ConfigurationManager\n\tfrom cnnClassifier.components import DataIngestion\n\tfrom cnnClassifier import logger\n\tclass DataIngestionTrainingPipeline:\n\t    def __init__(self):\n\t        pass\n\t    def main(self):\n\t        config = ConfigurationManager()\n\t        data_ingestion_config = config.get_data_ingestion_config()\n\t        data_ingestion = DataIngestion(config=data_ingestion_config)\n", "        data_ingestion.download_file()\n\t        data_ingestion.unzip_and_clean()"]}
{"filename": "src/cnnClassifier/pipeline/stage_03_training.py", "chunked_list": ["from cnnClassifier.config import ConfigurationManager\n\tfrom cnnClassifier.components import PrepareCallback, Training\n\tfrom cnnClassifier import logger\n\tclass ModelTrainingPipeline:\n\t    def __init__(self):\n\t        pass\n\t    def main(self):\n\t        config = ConfigurationManager()\n\t        prepare_callbacks_config = config.get_prepare_callback_config()\n\t        prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n", "        callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n\t        training_config = config.get_training_config()\n\t        training = Training(config=training_config)\n\t        training.get_base_model()\n\t        training.train_valid_generator()\n\t        training.train(\n\t            callback_list=callback_list\n\t        )\n"]}
{"filename": "src/cnnClassifier/pipeline/stage_04_evaluation.py", "chunked_list": ["from cnnClassifier.config import ConfigurationManager\n\tfrom cnnClassifier.components import Evaluation\n\tfrom cnnClassifier import logger\n\tclass EvaluationPipeline:\n\t    def __init__(self):\n\t        pass\n\t    def main(self):\n\t        config = ConfigurationManager()\n\t        val_config = config.get_validation_config()\n\t        evaluation = Evaluation(val_config)\n", "        evaluation.evaluation()\n\t        evaluation.save_score()\n"]}
{"filename": "src/cnnClassifier/constants/__init__.py", "chunked_list": ["from pathlib import Path\n\tCONFIG_FILE_PATH = Path(\"config/config.yaml\")\n\tPARAMS_FILE_PATH = Path(\"params.yaml\")"]}
