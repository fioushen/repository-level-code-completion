{"filename": "Step2-Modality-Specific-Information-Disentanglement/main.py", "chunked_list": ["import torch\n\timport numpy as np\n\timport torch.optim as optim\n\tfrom options.Options import Options_x\n\tfrom dataset.dataset_lits_train import Lits_DataSet\n\tfrom dataset.dataset_lits_val import Val_DataSet\n\tfrom Model.networks import RUnet\n\tfrom torch.utils.data import DataLoader\n\tfrom setting.common import adjust_learning_rate\n\tfrom setting import logger, util\n", "from setting.metrics import LossAverage, DiceLoss\n\timport os\n\timport time\n\tfrom test import test_all\n\tfrom collections import OrderedDict\n\tdef val(val_dataloader, epoch):\n\t    since = time.time()\n\t    Loss = LossAverage()\n\t    DICE_Loss = LossAverage()\n\t    BCE_Loss = LossAverage()\n", "    for i, (DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt) in enumerate(val_dataloader):  # inner loop within one epoch\n\t        b, c, l, w, e = DCE0.shape[0], DCE0.shape[1], DCE0.shape[2], DCE0.shape[3], DCE0.shape[4]\n\t        DCE0 = DCE0.view(-1, 1, l, w, e).to(device)\n\t        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\t        sub = sub.view(-1, 1, l, w, e).to(device)\n\t        ADC = ADC.view(-1, 1, l, w, e).to(device)\n\t        T2W = T2W.view(-1, 1, l, w, e).to(device)\n\t        ADC_syn = ADC_syn.view(-1, 1, l, w, e).to(device)\n\t        T2W_syn = T2W_syn.view(-1, 1, l, w, e).to(device)\n\t        gt = gt.view(-1, 1, l, w, e).to(device)\n", "        pred = model(torch.cat((DCE, sub, ADC, T2W), dim=1))\n\t        Dice_loss = dice_loss(pred, gt)\n\t        Bce_loss = bce_loss(pred, gt)\n\t        loss = Bce_loss + 5 * Dice_loss\n\t        Loss.update(loss.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss.item(), DCE0.size(0))\n\t        BCE_Loss.update(Bce_loss.item(), DCE0.size(0))\n\t        pred_adc = model(torch.cat((DCE, sub, ADC_syn, T2W), dim=1))\n\t        Dice_loss1 = dice_loss(pred_adc, gt)\n\t        Bce_loss1 = bce_loss(pred_adc, gt)\n", "        loss1 = Bce_loss1 + 5 * Dice_loss1\n\t        Loss.update(loss1.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss1.item(), DCE0.size(0))\n\t        BCE_Loss.update(Bce_loss1.item(), DCE0.size(0))\n\t        pred_t2 = model(torch.cat((DCE, sub, ADC, T2W_syn), dim=1))\n\t        Dice_loss2 = dice_loss(pred_t2, gt)\n\t        Bce_loss2 = bce_loss(pred_t2, gt)\n\t        loss2 = Bce_loss2 + 5 * Dice_loss2\n\t        Loss.update(loss2.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss2.item(), DCE0.size(0))\n", "        BCE_Loss.update(Bce_loss2.item(), DCE0.size(0))\n\t        pred_all = model(torch.cat((DCE, sub, ADC_syn, T2W_syn), dim=1))\n\t        Dice_loss3 = dice_loss(pred_all, gt)\n\t        Bce_loss3 = bce_loss(pred_all, gt)\n\t        loss3 = Bce_loss3 + 5 * Dice_loss3\n\t        Loss.update(loss3.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss3.item(), DCE0.size(0))\n\t        BCE_Loss.update(Bce_loss3.item(), DCE0.size(0))\n\t    time_elapsed = time.time() - since\n\t    print(\"=======Val Epoch:{}======Learning_rate:{}======Validate complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n", "    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})\n\tdef train(train_dataloader, epoch):\n\t    since = time.time()\n\t    Loss = LossAverage()\n\t    DICE_Loss = LossAverage()\n\t    BCE_Loss = LossAverage()\n\t    model.train()\n\t    for i, (DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt) in enumerate(train_dataloader):\n\t        b, c, l, w, e = DCE0.shape[0], DCE0.shape[1], DCE0.shape[2], DCE0.shape[3], DCE0.shape[4]\n\t        DCE0 = DCE0.view(-1, 1, l, w, e).to(device)\n", "        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\t        sub = sub.view(-1, 1, l, w, e).to(device)\n\t        ADC = ADC.view(-1, 1, l, w, e).to(device)\n\t        T2W = T2W.view(-1, 1, l, w, e).to(device)\n\t        ADC_syn = ADC_syn.view(-1, 1, l, w, e).to(device)\n\t        T2W_syn = T2W_syn.view(-1, 1, l, w, e).to(device)\n\t        gt = gt.view(-1, 1, l, w, e).to(device)\n\t        pred = model(torch.cat((DCE, sub, ADC, T2W), dim=1))\n\t        Dice_loss = dice_loss(pred, gt)\n\t        Bce_loss = bce_loss(pred, gt)\n", "        loss = Bce_loss + 5 * Dice_loss\n\t        optimizer.zero_grad()\n\t        loss.backward()\n\t        optimizer.step()\n\t        Loss.update(loss.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss.item(), DCE0.size(0))\n\t        BCE_Loss.update(Bce_loss.item(), DCE0.size(0))\n\t        pred_adc = model(torch.cat((DCE, sub, ADC_syn, T2W), dim=1))\n\t        Dice_loss1 = dice_loss(pred_adc, gt)\n\t        Bce_loss1 = bce_loss(pred_adc, gt)\n", "        loss1 = Bce_loss1 + 5 * Dice_loss1\n\t        optimizer.zero_grad()\n\t        loss1.backward()\n\t        optimizer.step()\n\t        Loss.update(loss1.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss1.item(), DCE0.size(0))\n\t        BCE_Loss.update(Bce_loss1.item(), DCE0.size(0))\n\t        pred_t2 = model(torch.cat((DCE, sub, ADC, T2W_syn), dim=1))\n\t        Dice_loss2 = dice_loss(pred_t2, gt)\n\t        Bce_loss2 = bce_loss(pred_t2, gt)\n", "        loss2 = Bce_loss2 + 5 * Dice_loss2\n\t        optimizer.zero_grad()\n\t        loss2.backward()\n\t        optimizer.step()\n\t        Loss.update(loss2.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss2.item(), DCE0.size(0))\n\t        BCE_Loss.update(Bce_loss2.item(), DCE0.size(0))\n\t        pred_all = model(torch.cat((DCE, sub, ADC_syn, T2W_syn), dim=1))\n\t        Dice_loss3 = dice_loss(pred_all, gt)\n\t        Bce_loss3 = bce_loss(pred_all, gt)\n", "        loss3 = Bce_loss3 + 5 * Dice_loss3\n\t        optimizer.zero_grad()\n\t        loss3.backward()\n\t        optimizer.step()\n\t        Loss.update(loss3.item(), DCE0.size(0))\n\t        DICE_Loss.update(Dice_loss3.item(), DCE0.size(0))\n\t        BCE_Loss.update(Bce_loss3.item(), DCE0.size(0))\n\t        adjust_learning_rate(optimizer, epoch, opt)\n\t    time_elapsed = time.time() - since\n\t    print(\"=======Train Epoch:{}======Learning_rate:{}======Train complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n", "    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})\n\tif __name__ == '__main__':\n\t    opt = Options_x().parse()\n\t    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n\t    print(\"using {} device.\".format(device))\n\t    model = RUnet(num_cls=1).to(device)\n\t    save_path = opt.checkpoints_dir\n\t    dice_loss = DiceLoss()\n\t    bce_loss = torch.nn.BCEWithLogitsLoss()\n\t    save_result_path = os.path.join(save_path, opt.task_name)\n", "    util.mkdir(save_result_path)\n\t    optimizer = optim.Adam(model.parameters(), lr=opt.lr, weight_decay=1e-5)\n\t    model_save_path = os.path.join(save_result_path, 'model')\n\t    util.mkdir(model_save_path)\n\t    logger_save_path = os.path.join(save_result_path, 'logger')\n\t    util.mkdir(logger_save_path)\n\t    log_train = logger.Train_Logger(logger_save_path, \"train_log\")\n\t    log_val = logger.Val_Logger(logger_save_path, \"val_log\")\n\t    train_dataset = Lits_DataSet(opt.datapath, opt.patch_size)\n\t    val_dataset = Val_DataSet(opt.datapath, opt.patch_size)\n", "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n\t    val_dataloader = DataLoader(dataset=val_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n\t    types = ['train', 'val']\n\t    val_dice_loss = 99\n\t    best_epoch = 0\n\t    for epoch in range(opt.epoch):\n\t        epoch = epoch + 1\n\t        for type in types:\n\t            if type == 'train':\n\t                train_log = train(train_dataloader, epoch)\n", "                log_train.update(epoch, train_log)\n\t            elif type == 'val':\n\t                val_log = val(val_dataloader, epoch)\n\t                log_val.update(epoch, val_log)\n\t                if val_log['DICE_Loss'] < val_dice_loss:\n\t                    best_epoch = epoch\n\t                    val_dice_loss = val_log['DICE_Loss']\n\t                    state = {'model': model.state_dict(), 'epoch': best_epoch}\n\t                    torch.save(state, os.path.join(model_save_path, 'best_model.pth'))\n\t        state = {'model': model.state_dict(), 'epoch': epoch}\n", "        torch.save(state, os.path.join(model_save_path, 'latest_model.pth'))\n\t        if epoch % opt.model_save_fre == 0:\n\t            torch.save(state, os.path.join(model_save_path, 'model_' + np.str(epoch) + '.pth'))\n\t        torch.cuda.empty_cache()\n\t    test_all('best_model.pth')\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/test.py", "chunked_list": ["import torch\n\timport gc\n\timport numpy as np\n\timport SimpleITK as sitk\n\tfrom options.Options import Options_x\n\tfrom tqdm import tqdm\n\tfrom Model.networks import RUnet\n\tfrom torch.utils.data import DataLoader\n\tfrom setting import logger, util\n\tfrom setting.metrics import seg_metric\n", "import os\n\tfrom dataset.dataset_lits_test import Test_all_Datasets, Recompone_tool\n\tfrom collections import OrderedDict\n\tdef load(file):\n\t    itkimage = sitk.ReadImage(file)\n\t    image = sitk.GetArrayFromImage(itkimage)\n\t    return image\n\tdef test_all(model_name, flag):\n\t    opt = Options_x().parse()  # get training options\n\t    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n", "    print(\"using {} device.\".format(device))\n\t    model = RUnet().to(device)\n\t    ckpt = torch.load(opt.checkpoints_dir + '/' + opt.task_name + '/model/' + model_name, map_location=device)\n\t    model.load_state_dict(ckpt['model'])\n\t    save_result_path = os.path.join(opt.checkpoints_dir, opt.task_name, 'test_all_result')\n\t    util.mkdir(save_result_path)\n\t    model.eval()\n\t    save_excel_path = os.path.join(save_result_path, flag)\n\t    util.mkdir(save_excel_path)\n\t    log_test = logger.Test_Logger(save_excel_path, \"results_train\")\n", "    cut_param = {'patch_s': opt.patch_size[0], 'patch_h': opt.patch_size[1], 'patch_w': opt.patch_size[2],\n\t                 'stride_s': opt.patch_stride[0], 'stride_h': opt.patch_stride[1], 'stride_w': opt.patch_stride[2]}\n\t    datasets = Test_all_Datasets(opt.datapath, cut_param, flag)\n\t    for img_dataset, original_shape, new_shape, mask, file_idx in datasets:\n\t        save_tool = Recompone_tool(original_shape, new_shape, cut_param)\n\t        save_prob_tool = Recompone_tool(original_shape, new_shape, cut_param)\n\t        dataloader = DataLoader(img_dataset, batch_size=opt.test_batch, num_workers=opt.num_threads, shuffle=False)\n\t        with torch.no_grad():\n\t            for pre, pos, sub, adc, t2w, gt in tqdm(dataloader):\n\t                pos, sub, adc, t2w, gt = pos.to(device), sub.to(device), adc.to(device), t2w.to(device), gt.to(device)\n", "                pos = pos.unsqueeze(1).type(torch.float32)\n\t                sub = sub.unsqueeze(1).type(torch.float32)\n\t                adc = adc.unsqueeze(1).type(torch.float32)\n\t                t2w = t2w.unsqueeze(1).type(torch.float32)\n\t                output = model(pos, sub, adc, t2w)\n\t                probility = output.type(torch.float32)\n\t                seg = (output >= 0.5).type(torch.float32)\n\t                save_prob_tool.add_result(probility.detach().cpu())\n\t                save_tool.add_result(seg.detach().cpu())\n\t        probility = save_prob_tool.recompone_overlap()\n", "        pred = save_tool.recompone_overlap()\n\t        recon = (pred.numpy() > 0.5).astype(np.uint16) * mask.astype(np.uint16)\n\t        gt = load(os.path.join(opt.datapath, file_idx, 'GT.nii.gz'))\n\t        DSC, PPV, SEN, ASD = seg_metric(recon, gt)\n\t        index_results = OrderedDict({'DSC': DSC, 'PPV': PPV, 'SEN': SEN, 'ASD': ASD})\n\t        log_test.update(file_idx, index_results)\n\t        Pred = sitk.GetImageFromArray(np.array(recon))\n\t        prob_img = sitk.GetImageFromArray(np.array(probility))\n\t        result_save_path = os.path.join(save_result_path, flag, file_idx)\n\t        util.mkdir(result_save_path)\n", "        sitk.WriteImage(Pred, os.path.join(result_save_path, 'pred.nii.gz'))\n\t        sitk.WriteImage(prob_img, os.path.join(result_save_path, 'probility.nii.gz'))\n\t        del pred, recon, Pred, save_tool, save_prob_tool, prob_img, probility, gt\n\t        gc.collect()\n\t        torch.cuda.empty_cache()\n\tif __name__ == '__main__':\n\t    for flag_in in ['all_true', 'fake_adc', 'fake_t2', 'all_fake']:\n\t        test_all('best_model.pth', flag_in)\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/weights_init.py", "chunked_list": ["from torch.nn import init\n\tdef weights_init_normal(m):\n\t    classname = m.__class__.__name__\n\t    # print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.normal(m.weight.data, 0.0, 0.02)\n\t    elif classname.find('Linear') != -1:\n\t        init.normal(m.weight.data, 0.0, 0.02)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef weights_init_xavier(m):\n\t    classname = m.__class__.__name__\n\t    # print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.xavier_normal(m.weight.data, gain=1)\n\t    elif classname.find('Linear') != -1:\n\t        init.xavier_normal(m.weight.data, gain=1)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef weights_init_kaiming(m):\n\t    classname = m.__class__.__name__\n\t    # print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n\t    elif classname.find('Linear') != -1:\n\t        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef weights_init_orthogonal(m):\n\t    classname = m.__class__.__name__\n\t    # print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.orthogonal(m.weight.data, gain=1)\n\t    elif classname.find('Linear') != -1:\n\t        init.orthogonal(m.weight.data, gain=1)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef init_weights(net, init_type='normal'):\n\t    # print('initialization method [%s]' % init_type)\n\t    if init_type == 'normal':\n\t        net.apply(weights_init_normal)\n\t    elif init_type == 'xavier':\n\t        net.apply(weights_init_xavier)\n\t    elif init_type == 'kaiming':\n\t        net.apply(weights_init_kaiming)\n\t    elif init_type == 'orthogonal':\n", "        net.apply(weights_init_orthogonal)\n\t    else:\n\t        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/metrics.py", "chunked_list": ["import torch.nn as nn\n\timport torch\n\timport numpy as np\n\timport sys\n\tfrom scipy.ndimage import morphology\n\tsys.dont_write_bytecode = True\n\tclass LossAverage(object):\n\t    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n\t    def __init__(self):\n\t        self.reset()\n", "    def reset(self):\n\t        self.val = 0\n\t        self.avg = 0\n\t        self.sum = 0\n\t        self.count = 0\n\t    def update(self, val, n):\n\t        self.val = val\n\t        self.sum += val * n\n\t        self.count += n\n\t        self.avg = round(self.sum / self.count, 4)\n", "class DiceLoss(nn.Module):\n\t    \"\"\"\n\t    define the dice loss\n\t    \"\"\"\n\t    def __init__(self):\n\t        super(DiceLoss, self).__init__()\n\t    def forward(self, input, target):\n\t        smooth = 1.\n\t        iflat = input.contiguous().view(-1)\n\t        tflat = target.contiguous().view(-1)\n", "        intersection = (iflat * tflat).sum()\n\t        A_sum = torch.sum(iflat * iflat)\n\t        B_sum = torch.sum(tflat * tflat)\n\t        return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth))\n\t\"\"\"dice coefficient\"\"\"\n\tdef dice(pre, gt, tid=1):\n\t    pre = pre == tid  # make it boolean\n\t    gt = gt == tid  # make it boolean\n\t    pre = np.asarray(pre).astype(np.bool)\n\t    gt = np.asarray(gt).astype(np.bool)\n", "    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    dsc = (2. * intersection.sum() + 1e-07) / (pre.sum() + gt.sum() + 1e-07)\n\t    return dsc\n\t\"\"\"positive predictive value\"\"\"\n\tdef pospreval(pre, gt, tid=1):\n\t    pre = pre == tid  # make it boolean\n\t    gt = gt == tid  # make it boolean\n\t    pre = np.asarray(pre).astype(np.bool)\n", "    gt = np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    ppv = (1.0 * intersection.sum() + 1e-07) / (pre.sum() + 1e-07)\n\t    return ppv\n\t\"\"\"sensitivity\"\"\"\n\tdef sensitivity(pre, gt, tid=1):\n\t    pre = pre == tid  # make it boolean\n\t    gt = gt == tid  # make it boolean\n", "    pre = np.asarray(pre).astype(np.bool)\n\t    gt = np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    sen = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\t    return sen\n\t\"\"\"specificity\"\"\"\n\tdef specificity(pre, gt):\n\t    pre = pre == 0  # make it boolean\n", "    gt = gt == 0  # make it boolean\n\t    pre = np.asarray(pre).astype(np.bool)\n\t    gt = np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    spe = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\t    return spe\n\t\"\"\"average surface distance\"\"\"\n\tdef surfd(pre, gt, tid=1, sampling=1, connectivity=1):\n", "    pre = pre == tid  # make it boolean\n\t    gt = gt == tid  # make it boolean\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    input_1 = np.atleast_1d(pre.astype(np.bool))\n\t    input_2 = np.atleast_1d(gt.astype(np.bool))\n\t    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n\t    S = np.logical_xor(input_1, morphology.binary_erosion(input_1, conn))\n\t    Sprime = np.logical_xor(input_2, morphology.binary_erosion(input_2, conn))\n\t    dta = morphology.distance_transform_edt(~S, sampling)\n", "    dtb = morphology.distance_transform_edt(~Sprime, sampling)\n\t    sds = np.concatenate([np.ravel(dta[Sprime != 0]), np.ravel(dtb[S != 0])])\n\t    return sds\n\tdef asd(pre, gt, tid=1, sampling=1, connectivity=1):\n\t    sds = surfd(pre, gt, tid=tid, sampling=sampling, connectivity=connectivity)\n\t    dis = sds.mean()\n\t    return dis\n\tdef seg_metric(pre, gt):\n\t    mask = (pre > 0.5)\n\t    gt = (gt > 0.5)\n", "    ASD = asd(mask, gt)\n\t    DSC = dice(mask, gt)\n\t    SEN = sensitivity(mask, gt)\n\t    PPV = pospreval(mask, gt)\n\t    return DSC, PPV, SEN, ASD\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/logger.py", "chunked_list": ["import pandas as pd\n\tfrom torch.utils.tensorboard import SummaryWriter\n\timport torch, random\n\timport numpy as np\n\tfrom collections import OrderedDict\n\tclass Train_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n\t        self.save_path = save_path\n", "        self.save_name = save_name\n\t    def update(self, epoch, train_log):\n\t        item = OrderedDict({'epoch': epoch})\n\t        item.update(train_log)\n\t        print(\"\\033[0;33mTrain:\\033[0m\", train_log)\n\t        self.update_csv(item)\n\t        self.update_tensorboard(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n\t        if self.log is not None:\n", "            self.log = self.log.append(tmp, ignore_index=True)\n\t        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\t    def update_tensorboard(self, item):\n\t        if self.summary is None:\n\t            self.summary = SummaryWriter('%s/' % self.save_path)\n\t        epoch = item['epoch']\n\t        for key, value in item.items():\n\t            if key != 'epoch': self.summary.add_scalar(key, value, epoch)\n", "class Val_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n\t        self.save_path = save_path\n\t        self.save_name = save_name\n\t    def update(self, epoch, val_log):\n\t        item = OrderedDict({'epoch': epoch})\n\t        item.update(val_log)\n\t        print(\"\\033[0;33mValidate:\\033[0m\", val_log)\n", "        self.update_csv(item)\n\t        self.update_tensorboard(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n\t        if self.log is not None:\n\t            self.log = self.log.append(tmp, ignore_index=True)\n\t        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\t    def update_tensorboard(self, item):\n", "        if self.summary is None:\n\t            self.summary = SummaryWriter('%s/' % self.save_path)\n\t        epoch = item['epoch']\n\t        for key, value in item.items():\n\t            if key != 'epoch': self.summary.add_scalar(key, value, epoch)\n\tclass Test_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n\t        self.save_path = save_path\n", "        self.save_name = save_name\n\t    def update(self, name, log):\n\t        item = OrderedDict({'img_name': name})\n\t        item.update(log)\n\t        print(\"\\033[0;33mTest:\\033[0m\", log)\n\t        self.update_csv(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n\t        if self.log is not None:\n\t            self.log = self.log.append(tmp, ignore_index=True)\n", "        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\tdef setpu_seed(seed):\n\t    torch.manual_seed(seed)\n\t    torch.cuda.manual_seed_all(seed)\n\t    np.random.seed(seed)\n\t    torch.backends.cudnn.deterministic = True\n\t    random.seed(seed)\n\tdef dict_round(dic, num):\n", "    for key, value in dic.items():\n\t        dic[key] = round(value, num)\n\t    return dic\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/util.py", "chunked_list": ["\"\"\"This module contains simple helper functions \"\"\"\n\tfrom __future__ import print_function\n\timport torch\n\timport numpy as np\n\tfrom PIL import Image\n\timport os\n\tdef tensor2im(input_image, imtype=np.uint8):\n\t    \"\"\"\"Converts a Tensor array into a numpy image array.\n\t    Parameters:\n\t        input_image (tensor) --  the input image tensor array\n", "        imtype (type)        --  the desired type of the converted numpy array\n\t    \"\"\"\n\t    if not isinstance(input_image, np.ndarray):\n\t        if isinstance(input_image, torch.Tensor):\n\t            image_tensor = input_image.data\n\t        else:\n\t            return input_image\n\t        image_numpy = image_tensor[0].cpu().float().numpy()\n\t        if image_numpy.shape[0] == 1:\n\t            image_numpy = np.tile(image_numpy, (3, 1, 1))\n", "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n\t    else:\n\t        image_numpy = input_image\n\t    return image_numpy.astype(imtype)\n\tdef diagnose_network(net, name='network'):\n\t    \"\"\"Calculate and print the mean of average absolute(gradients)\n\t    Parameters:\n\t        net (torch network) -- Torch network\n\t        name (str) -- the name of the network\n\t    \"\"\"\n", "    mean = 0.0\n\t    count = 0\n\t    for param in net.parameters():\n\t        if param.grad is not None:\n\t            mean += torch.mean(torch.abs(param.grad.data))\n\t            count += 1\n\t    if count > 0:\n\t        mean = mean / count\n\t    print(name)\n\t    print(mean)\n", "def save_image(image_numpy, image_path, aspect_ratio=1.0):\n\t    \"\"\"Save a numpy image to the disk\n\t    Parameters:\n\t        image_numpy (numpy array) -- input numpy array\n\t        image_path (str)          -- the path of the image\n\t    \"\"\"\n\t    image_pil = Image.fromarray(image_numpy)\n\t    h, w, _ = image_numpy.shape\n\t    if aspect_ratio > 1.0:\n\t        image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)\n", "    if aspect_ratio < 1.0:\n\t        image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)\n\t    image_pil.save(image_path)\n\tdef print_numpy(x, val=True, shp=False):\n\t    \"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\t    Parameters:\n\t        val (bool) -- if print the values of the numpy array\n\t        shp (bool) -- if print the shape of the numpy array\n\t    \"\"\"\n\t    x = x.astype(np.float64)\n", "    if shp:\n\t        print('shape,', x.shape)\n\t    if val:\n\t        x = x.flatten()\n\t        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n\t            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))\n\tdef mkdirs(paths):\n\t    \"\"\"create empty directories if they don't exist\n\t    Parameters:\n\t        paths (str list) -- a list of directory paths\n", "    \"\"\"\n\t    if isinstance(paths, list) and not isinstance(paths, str):\n\t        for path in paths:\n\t            mkdir(path)\n\t    else:\n\t        mkdir(paths)\n\tdef mkdir(path):\n\t    \"\"\"create a single empty directory if it didn't exist\n\t    Parameters:\n\t        path (str) -- a single directory path\n", "    \"\"\"\n\t    if not os.path.exists(path):\n\t        os.makedirs(path)\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/setting/common.py", "chunked_list": ["import SimpleITK as sitk\n\timport numpy as np\n\timport math\n\tdef normalization(img):\n\t    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n\t    return out\n\tdef normalization_test (img):\n\t    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n\t    return out, np.max(img), np.min(img)\n\tdef center_crop_3d(img, label, slice_num=16):\n", "    if img.shape[0] < slice_num:\n\t        return None\n\t    left_x = img.shape[0]//2 - slice_num//2\n\t    right_x = img.shape[0]//2 + slice_num//2\n\t    crop_img = img[left_x:right_x]\n\t    crop_label = label[left_x:right_x]\n\t    return crop_img, crop_label\n\tdef load_file_name_list(file_path):\n\t    file_name_list = []\n\t    with open(file_path, 'r') as file_to_read:\n", "        while True:\n\t            lines = file_to_read.readline().strip()\n\t            if not lines:\n\t                break\n\t                pass\n\t            file_name_list.append(lines)\n\t            pass\n\t    return file_name_list\n\tdef MaskContour(image, position='xy', line=1):\n\t    itkimage = sitk.GetImageFromArray(image)\n", "    if position == 'xy':\n\t        erode_m = [line, line, 0]\n\t    elif position == 'yz':\n\t        erode_m = [0, line, line]\n\t    elif position == 'zx':\n\t        erode_m = [line, 0, line]\n\t    else:\n\t        erode_m = [line, line, 0]\n\t    mask = sitk.GetArrayFromImage(sitk.BinaryErode(itkimage, erode_m))\n\t    boundary = image - mask\n", "    out = sitk.GetImageFromArray(boundary)\n\t    return out\n\tdef print_network(net):\n\t    num_params = 0\n\t    for param in net.parameters():\n\t        num_params += param.numel()\n\t    print(net)\n\t    print('Total number of parameters: %d' % num_params)\n\tdef adjust_learning_rate(optimizer, epoch, opt):\n\t    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n", "    lr = opt.lr * (0.5 ** (epoch // opt.step))\n\t    for param_group in optimizer.param_groups:\n\t        param_group['lr'] = lr\n\tdef adjust_learning_rate_V2(optimizer, lr):\n\t    \"\"\"Sets the learning rate to a fixed number\"\"\"\n\t    for param_group in optimizer.param_groups:\n\t        param_group['lr'] = lr\n\tdef get_mse(img1, img2):\n\t    mse = np.mean( (img1 - img2) ** 2 )\n\t    return mse\n", "def get_psnr(img1, img2):\n\t    mse = np.mean( (img1 - img2) ** 2 )\n\t    if mse == 0:\n\t        return 100\n\t    PIXEL_MAX = 1.0\n\t    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))\n\t'''\n\tdef get_ssim(img1,img2):\n\t    n=img1.shape[0]\n\t    out = 0\n", "    for i in range(n):\n\t        out+=structural_similarity(img1[i].squeeze(),img2[i].squeeze())\n\t    return out/n\n\t'''    \n\tdef save_result(low_dose, high_dose, output, i, epoch):\n\t    def save_img(img, name):\n\t        img = sitk.GetImageFromArray(img)\n\t        sitk.WriteImage(img, 'result/image/'+name+'.nii.gz')\n\t    save_img(low_dose, 'low_dose_epoch_'+str(epoch) + \"_\" + str(i))\n\t    save_img(high_dose, 'high_dose_epoch_'+str(epoch) + \"_\" + str(i))\n", "    save_img(output, 'output_epoch_'+str(epoch) + \"_\" + str(i))\n\tdef de_normalization(img,max_x,min_x):\n\t    return img*(max_x - min_x) + min_x"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/options/BasicOptions.py", "chunked_list": ["import argparse\n\timport os\n\tfrom setting import util\n\timport torch\n\tclass BaseOptions():\n\t    \"\"\"This class defines options used during both training and test time.\n\t    It also implements several helper functions such as parsing, printing, and saving the options.\n\t    It also gathers additional options defined in <modify_commandline_options> functions in both dataset class and model class.\n\t    \"\"\"\n\t    def __init__(self):\n", "        \"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"\n\t        self.initialized = False\n\t    def initialize(self, parser):\n\t        \"\"\"Define the common options that are used in both training and test.\"\"\"\n\t        # basic parameters\n\t        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n\t        parser.add_argument('--num_threads', default=1, type=int, help='# threads for loading data')\n\t        parser.add_argument('--batch_size', type=int, default=1, help='input train batch size')\n\t        parser.add_argument('--test_batch', type=int, default=1, help='input test batch size')\n\t        parser.add_argument('--epoch', type=int, default=400, help='number of epochs with the initial learning rate')\n", "        parser.add_argument('--step', type=int, default=50, help='number of epochs to adjust learning rate')\n\t        parser.add_argument('--datapath', default=r'/data', help='path of the raw data')\n\t        parser.add_argument('--lr', type=float, default=0.005, help='initial learning rate of net for adam')\n\t        parser.add_argument('--model_save_fre', type=int, default=50, help='frequency of saving model') \n\t        parser.add_argument('--test_fre', type=int, default=600, help='frequency of testing the model')\n\t        parser.add_argument('--patch_size', type=int, default=(32,128,128), help='the size of crop patch')\n\t        parser.add_argument('--patch_stride', type=int, default=(8,64,64), help='the stride of patch')\n\t        parser.add_argument('--task_name', type=str, default='MultiModal_Parametric', help='the current task name')\n\t        self.initialized = True\n\t        return parser\n", "    def gather_options(self):\n\t        \"\"\"Initialize our parser with basic options(only once).\n\t        Add additional model-specific and dataset-specific options.\n\t        These options are defined in the <modify_commandline_options> function\n\t        in model and dataset classes.\n\t        \"\"\"\n\t        if not self.initialized:  # check if it has been initialized\n\t            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t            parser = self.initialize(parser)\n\t        # get the basic options\n", "        opt, _ = parser.parse_known_args()\n\t        # save and return the parser\n\t        self.parser = parser\n\t        return parser.parse_args()\n\t    def print_options(self, opt):\n\t        \"\"\"Print and save options\n\t        It will print both current options and default values(if different).\n\t        It will save options into a text file / [checkpoints_dir] / opt.txt\n\t        \"\"\"\n\t        message = ''\n", "        message += '----------------- Options ---------------\\n'\n\t        for k, v in sorted(vars(opt).items()):\n\t            comment = ''\n\t            default = self.parser.get_default(k)\n\t            if v != default:\n\t                comment = '\\t[default: %s]' % str(default)\n\t            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n\t        message += '----------------- End -------------------'\n\t        print(message)\n\t        # save to the disk\n", "        expr_dir = os.path.join(opt.checkpoints_dir, 'model_parameter_list')\n\t        util.mkdirs(expr_dir)\n\t        file_name = os.path.join(expr_dir, '{train_opt.txt')\n\t        with open(file_name, 'wt') as opt_file:\n\t            opt_file.write(message)\n\t            opt_file.write('\\n')\n\t    def parse(self):\n\t        \"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"\n\t        opt = self.gather_options()\n\t        opt.isTrain = self.isTrain   # train or test\n", "        self.print_options(opt)\n\t        self.opt = opt\n\t        return self.opt\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/options/Options.py", "chunked_list": ["from options.BasicOptions import BaseOptions\n\tclass Options_x(BaseOptions):\n\t    \"\"\"This class includes training options.\n\t    It also includes shared options defined in BaseOptions.\n\t    \"\"\"\n\t    def initialize(self, parser):\n\t        parser = BaseOptions.initialize(self, parser)\n\t        parser.add_argument('--name', type=str, default='Tumor_seg', help='name_of_the_project')\n\t        self.isTrain = True\n\t        return parser\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/dataset/dataset_lits_test.py", "chunked_list": ["import numpy as np\n\timport torch, os\n\tfrom torch.utils.data import Dataset\n\timport random\n\timport SimpleITK as sitk\n\tdef min_max_normalization(img):\n\t    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t    return out\n\tdef normalization(img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t    newimg = img.copy()\n", "    newimg = newimg.astype(np.float32)\n\t    if quantile is not None:\n\t        maxval = round(np.percentile(newimg, 100 - quantile))\n\t        minval = round(np.percentile(newimg, quantile))\n\t        newimg[newimg >= maxval] = maxval\n\t        newimg[newimg <= minval] = minval\n\t    if lmin is not None:\n\t        newimg[newimg < lmin] = lmin\n\t    if rmax is not None:\n\t        newimg[newimg > rmax] = rmax\n", "    minval = np.min(newimg)\n\t    if dividend is None:\n\t        maxval = np.max(newimg)\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t    else:\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t    return newimg\n\tdef load(file):\n\t    itkimage = sitk.ReadImage(file)\n\t    image = sitk.GetArrayFromImage(itkimage)\n", "    return image\n\tdef maskcor_extract_3d(mask, padding=(5, 5, 5)):\n\t    p = np.where(mask > 0)\n\t    a = np.zeros([3, 2], dtype=np.int)\n\t    for i in range(3):\n\t        s = p[i].min()\n\t        e = p[i].max() + 1\n\t        ss = s - padding[i]\n\t        ee = e + padding[i]\n\t        if ss < 0:\n", "            ss = 0\n\t        if ee > mask.shape[i]:\n\t            ee = mask.shape[i]\n\t        a[i, 0] = ss\n\t        a[i, 1] = ee\n\t    return a\n\tclass Img_DataSet(Dataset):\n\t    def __init__(self, pre, pos, sub, adc, t2w, gt, cut_param):\n\t        self.pre = pre\n\t        self.pos = pos\n", "        self.sub = sub\n\t        self.adc = adc\n\t        self.t2w = t2w\n\t        self.gt = gt\n\t        self.ori_shape = self.pre.shape\n\t        self.cut_param = cut_param\n\t        self.pre = self.padding_img(self.pre, self.cut_param)\n\t        self.pre = self.extract_ordered_overlap(self.pre, self.cut_param)\n\t        self.pos = self.padding_img(self.pos, self.cut_param)\n\t        self.pos = self.extract_ordered_overlap(self.pos, self.cut_param)\n", "        self.sub = self.padding_img(self.sub, self.cut_param)\n\t        self.sub = self.extract_ordered_overlap(self.sub, self.cut_param)\n\t        self.adc = self.padding_img(self.adc, self.cut_param)\n\t        self.adc = self.extract_ordered_overlap(self.adc, self.cut_param)\n\t        self.t2w = self.padding_img(self.t2w, self.cut_param)\n\t        self.t2w = self.extract_ordered_overlap(self.t2w, self.cut_param)\n\t        self.gt = self.padding_img(self.gt, self.cut_param)\n\t        self.gt = self.extract_ordered_overlap(self.gt, self.cut_param)\n\t        self.new_shape = self.pre.shape\n\t    def __getitem__(self, index):\n", "        pre = self.pre[index]\n\t        pos = self.pos[index]\n\t        sub = self.sub[index]\n\t        adc = self.adc[index]\n\t        t2w = self.t2w[index]\n\t        gt = self.gt[index]\n\t        return torch.from_numpy(pre), torch.from_numpy(pos), torch.from_numpy(sub), torch.from_numpy(\n\t            adc), torch.from_numpy(t2w), torch.from_numpy(gt)\n\t    def __len__(self):\n\t        return len(self.pre)\n", "    def padding_img(self, img, C):\n\t        assert (len(img.shape) == 3)  # 3D array\n\t        img_s, img_h, img_w = img.shape\n\t        leftover_s = (img_s - C['patch_s']) % C['stride_s']\n\t        leftover_h = (img_h - C['patch_h']) % C['stride_h']\n\t        leftover_w = (img_w - C['patch_w']) % C['stride_w']\n\t        if (leftover_s != 0):\n\t            s = img_s + (C['stride_s'] - leftover_s)\n\t        else:\n\t            s = img_s\n", "        if (leftover_h != 0):\n\t            h = img_h + (C['stride_h'] - leftover_h)\n\t        else:\n\t            h = img_h\n\t        if (leftover_w != 0):\n\t            w = img_w + (C['stride_w'] - leftover_w)\n\t        else:\n\t            w = img_w\n\t        tmp_full_imgs = np.zeros((s, h, w))\n\t        tmp_full_imgs[:img_s, :img_h, 0:img_w] = img\n", "        return tmp_full_imgs\n\t    def extract_ordered_overlap(self, img, C):\n\t        assert (len(img.shape) == 3)  # 3D arrays\n\t        img_s, img_h, img_w = img.shape\n\t        assert ((img_h - C['patch_h']) % C['stride_h'] == 0\n\t                and (img_w - C['patch_w']) % C['stride_w'] == 0\n\t                and (img_s - C['patch_s']) % C['stride_s'] == 0)\n\t        N_patches_s = (img_s - C['patch_s']) // C['stride_s'] + 1\n\t        N_patches_h = (img_h - C['patch_h']) // C['stride_h'] + 1\n\t        N_patches_w = (img_w - C['patch_w']) // C['stride_w'] + 1\n", "        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n\t        patches = np.empty((N_patches_img, C['patch_s'], C['patch_h'], C['patch_w']))\n\t        iter_tot = 0\n\t        for s in range(N_patches_s):  # loop over the full images\n\t            for h in range(N_patches_h):\n\t                for w in range(N_patches_w):\n\t                    patch = img[s * C['stride_s']: s * C['stride_s'] + C['patch_s'],\n\t                            h * C['stride_h']: h * C['stride_h'] + C['patch_h'],\n\t                            w * C['stride_w']: w * C['stride_w'] + C['patch_w']]\n\t                    patches[iter_tot] = patch\n", "                    iter_tot += 1  # total\n\t        assert (iter_tot == N_patches_img)\n\t        return patches  # array with all the full_imgs divided in patches\n\tclass Recompone_tool():\n\t    def __init__(self, img_ori_shape, img_new_shape, Cut_para):\n\t        self.result = None\n\t        self.ori_shape = img_ori_shape\n\t        self.new_shape = img_new_shape\n\t        self.C = Cut_para\n\t    def add_result(self, tensor):\n", "        if self.result is not None:\n\t            self.result = torch.cat((self.result, tensor), dim=0)\n\t        else:\n\t            self.result = tensor\n\t    def recompone_overlap(self):\n\t        \"\"\"\n\t        :param preds: output of model  shapeï¼š[N_patchs_img,3,patch_s,patch_h,patch_w]\n\t        :return: result of recompone output shape: [3,img_s,img_h,img_w]\n\t        \"\"\"\n\t        patch_s = self.result.shape[2]\n", "        patch_h = self.result.shape[3]\n\t        patch_w = self.result.shape[4]\n\t        N_patches_s = (self.new_shape[0] - patch_s) // self.C['stride_s'] + 1\n\t        N_patches_h = (self.new_shape[1] - patch_h) // self.C['stride_h'] + 1\n\t        N_patches_w = (self.new_shape[2] - patch_w) // self.C['stride_w'] + 1\n\t        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n\t        assert (self.result.shape[0] == N_patches_img)\n\t        full_prob = torch.zeros((self.new_shape[0], self.new_shape[1],\n\t                                 self.new_shape[2]))\n\t        full_sum = torch.zeros((self.new_shape[0], self.new_shape[1], self.new_shape[2]))\n", "        k = 0\n\t        for s in range(N_patches_s):\n\t            for h in range(N_patches_h):\n\t                for w in range(N_patches_w):\n\t                    full_prob[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n\t                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n\t                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += self.result[k].squeeze()\n\t                    full_sum[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n\t                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n\t                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += 1\n", "                    k += 1\n\t        assert (k == self.result.size(0))\n\t        assert (torch.min(full_sum) >= 1.0)  # at least one\n\t        final_avg = full_prob / full_sum\n\t        img = final_avg[:self.ori_shape[0], :self.ori_shape[1], :self.ori_shape[2]]\n\t        return img\n\tdef cal_newshape(img, C):\n\t    assert (len(img.shape) == 3)  # 3D array\n\t    img_s, img_h, img_w = img.shape\n\t    leftover_s = (img_s - C['patch_s']) % C['stride_s']\n", "    leftover_h = (img_h - C['patch_h']) % C['stride_h']\n\t    leftover_w = (img_w - C['patch_w']) % C['stride_w']\n\t    if (leftover_s != 0):\n\t        s = img_s + (C['stride_s'] - leftover_s)\n\t    else:\n\t        s = img_s\n\t    if (leftover_h != 0):\n\t        h = img_h + (C['stride_h'] - leftover_h)\n\t    else:\n\t        h = img_h\n", "    if (leftover_w != 0):\n\t        w = img_w + (C['stride_w'] - leftover_w)\n\t    else:\n\t        w = img_w\n\t    return np.zeros((s, h, w)).shape\n\tdef Test_all_Datasets(dataset_path, size, flag):\n\t    f = open(os.path.join(dataset_path, 'train.txt'))\n\t    data_list = f.read().splitlines()\n\t    print(\"The number of test samples is: \", len(data_list))\n\t    for file in data_list:\n", "        print(\"\\nStart Evaluate: \", file)\n\t        pre = normalization(load(os.path.join(dataset_path, file, 'DCE0.nii.gz'))).astype(np.float32)\n\t        pos = normalization(load(os.path.join(dataset_path, file, 'DCE.nii.gz'))).astype(np.float32)\n\t        sub = pos - pre\n\t        if flag == 'all_true':\n\t            adc = normalization(load(os.path.join(dataset_path, file, 'ADC.nii.gz'))).astype(np.float32)\n\t            t2w = normalization(load(os.path.join(dataset_path, file, 'T2.nii.gz'))).astype(np.float32)\n\t        elif flag == 'fake_adc':\n\t            adc = load(os.path.join(dataset_path, file, 'ADC_syn.nii.gz')).astype(np.float32)\n\t            t2w = normalization(load(os.path.join(dataset_path, file, 'T2.nii.gz'))).astype(np.float32)\n", "        elif flag == 'fake_t2':\n\t            adc = normalization(load(os.path.join(dataset_path, file, 'ADC.nii.gz'))).astype(np.float32)\n\t            t2w = load(os.path.join(dataset_path, file, 'T2_syn.nii.gz')).astype(np.float32)\n\t        elif flag == 'all_fake':\n\t            adc = load(os.path.join(dataset_path, file, 'ADC_syn.nii.gz')).astype(np.float32)\n\t            t2w = load(os.path.join(dataset_path, file, 'T2_syn.nii.gz')).astype(np.float32)\n\t        gt = load(os.path.join(dataset_path, file, 'GT.nii.gz')).astype(np.int16)\n\t        breast_mask = load(os.path.join(dataset_path, file, 'Breast_mask.nii.gz')).astype(np.int16)\n\t        original_shape = gt.shape\n\t        new_shape = cal_newshape(gt, size)\n", "        yield Img_DataSet(pre, pos, sub, adc, t2w, gt, size), original_shape, new_shape, breast_mask, file\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/dataset/dataset_lits_val.py", "chunked_list": ["import random\n\timport numpy as np\n\timport SimpleITK as sitk\n\timport os\n\tfrom torch.utils.data import Dataset\n\tclass Val_DataSet(Dataset):\n\t    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n\t        self.root = root\n\t        self.size = size\n\t        self.sample_index = sample_index\n", "        f = open(os.path.join(self.root, 'val.txt'))\n\t        self.filename = f.read().splitlines()\n\t    def __getitem__(self, index):\n\t        file = self.filename[index]\n\t        DCE0 = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz'))).astype(np.float32)\n\t        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n\t        sub = DCE - DCE0\n\t        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n\t        T2W = self.normalization(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n\t        ADC_syn = self.load(os.path.join(self.root, file, 'ADC_syn.nii.gz')).astype(np.float32)\n", "        T2W_syn = self.load(os.path.join(self.root, file, 'T2_syn.nii.gz')).astype(np.float32)\n\t        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\t        DCE0_patch, DCE_patch, sub_patch, ADC_patch, T2W_patch, ADC_syn_patch, T2W_syn_patch, gt_patch = [], [], [], [], [], [], [], []\n\t        for i in range(3):\n\t            if i == 1:\n\t                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_contain(\n\t                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n\t            else:\n\t                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_partial(\n\t                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n", "            DCE0_patch.append(DCE0_patch1), DCE_patch.append(DCE_patch1), sub_patch.append(\n\t                sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(T2W_patch1), ADC_syn_patch.append(\n\t                ADC_syn_patch1), T2W_syn_patch.append(T2W_syn_patch1), gt_patch.append(gt_patch1)\n\t        return np.array(DCE0_patch), np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(\n\t            T2W_patch), np.array(ADC_syn_patch), np.array(T2W_syn_patch), np.array(gt_patch)\n\t    def __len__(self):\n\t        return len(self.filename)\n\t    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, crop_size):\n\t        cor_box = self.maskcor_extract_3d(gt)\n\t        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n", "        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n\t        if random_x_min > random_x_max:\n\t            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n\t        if random_y_min > random_y_max:\n\t            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n\t        if random_z_min > random_z_max:\n\t            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n", "        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n", "                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, crop_size):\n\t        cor_box = self.maskcor_extract_3d(gt)\n", "        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def min_max_normalization(self, img):\n\t        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t        return out\n\t    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n", "            maxval = round(np.percentile(newimg, 100 - quantile))\n\t            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n\t            newimg[newimg <= minval] = minval\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n", "            maxval = np.max(newimg)\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t        return newimg\n\t    def load(self, file):\n\t        itkimage = sitk.ReadImage(file)\n\t        image = sitk.GetArrayFromImage(itkimage)\n\t        return image\n\t    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n", "        # mask_s = mask.shape\n\t        if np.sum(mask) == 0:\n\t            mask[10:12, 100:102, 100:102] = 1\n\t        p = np.where(mask > 0)\n\t        a = np.zeros([3, 2], dtype=np.int)\n\t        for i in range(3):\n\t            s = p[i].min()\n\t            e = p[i].max() + 1\n\t            ss = s - padding[i]\n\t            ee = e + padding[i]\n", "            if ss < 0:\n\t                ss = 0\n\t            if ee > mask.shape[i]:\n\t                ee = mask.shape[i]\n\t            a[i, 0] = ss\n\t            a[i, 1] = ee\n\t        return a\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/dataset/dataset_lits_train.py", "chunked_list": ["import random\n\timport numpy as np\n\timport SimpleITK as sitk\n\timport os\n\tfrom torch.utils.data import Dataset\n\tclass Lits_DataSet(Dataset):\n\t    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n\t        self.root = root\n\t        self.size = size\n\t        self.sample_index = sample_index\n", "        f = open(os.path.join(self.root, 'train.txt'))\n\t        self.filename = f.read().splitlines()\n\t    def __getitem__(self, index):\n\t        file = self.filename[index]\n\t        DCE0 = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz'))).astype(np.float32)\n\t        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n\t        sub = DCE - DCE0\n\t        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n\t        T2W = self.normalization(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n\t        ADC_syn = self.load(os.path.join(self.root, file, 'ADC_syn.nii.gz')).astype(np.float32)\n", "        T2W_syn = self.load(os.path.join(self.root, file, 'T2_syn.nii.gz')).astype(np.float32)\n\t        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\t        DCE0_patch, DCE_patch, sub_patch, ADC_patch, T2W_patch, ADC_syn_patch, T2W_syn_patch, gt_patch = [], [], [], [], [], [], [], []\n\t        for i in range(3):\n\t            if i == 1:\n\t                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_contain(\n\t                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n\t            else:\n\t                DCE0_patch1, DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, ADC_syn_patch1, T2W_syn_patch1, gt_patch1 = self.random_crop_3d_partial(\n\t                    DCE0, DCE, sub, ADC, T2W, ADC_syn, T2W_syn, gt, self.size)\n", "            DCE0_patch.append(DCE0_patch1), DCE_patch.append(DCE_patch1), sub_patch.append(\n\t                sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(T2W_patch1), ADC_syn_patch.append(\n\t                ADC_syn_patch1), T2W_syn_patch.append(T2W_syn_patch1), gt_patch.append(gt_patch1)\n\t        return np.array(DCE0_patch), np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(\n\t            T2W_patch), np.array(ADC_syn_patch), np.array(T2W_syn_patch), np.array(gt_patch)\n\t    def __len__(self):\n\t        return len(self.filename)\n\t    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, crop_size):\n\t        cor_box = self.maskcor_extract_3d(gt)\n\t        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n", "        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n\t        if random_x_min > random_x_max:\n\t            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n\t        if random_y_min > random_y_max:\n\t            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n\t        if random_z_min > random_z_max:\n\t            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n", "        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n", "                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, crop_size):\n\t        cor_box = self.maskcor_extract_3d(gt)\n", "        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def min_max_normalization(self, img):\n\t        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t        return out\n\t    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n", "            maxval = round(np.percentile(newimg, 100 - quantile))\n\t            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n\t            newimg[newimg <= minval] = minval\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n", "            maxval = np.max(newimg)\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t        return newimg\n\t    def load(self, file):\n\t        itkimage = sitk.ReadImage(file)\n\t        image = sitk.GetArrayFromImage(itkimage)\n\t        return image\n\t    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n", "        # mask_s = mask.shape\n\t        if np.sum(mask) == 0:\n\t            mask[10:12, 100:102, 100:102] = 1\n\t        p = np.where(mask > 0)\n\t        a = np.zeros([3, 2], dtype=np.int)\n\t        for i in range(3):\n\t            s = p[i].min()\n\t            e = p[i].max() + 1\n\t            ss = s - padding[i]\n\t            ee = e + padding[i]\n", "            if ss < 0:\n\t                ss = 0\n\t            if ee > mask.shape[i]:\n\t                ee = mask.shape[i]\n\t            a[i, 0] = ss\n\t            a[i, 1] = ee\n\t        return a\n"]}
{"filename": "Step2-Modality-Specific-Information-Disentanglement/Model/networks.py", "chunked_list": ["# x: 128x128 resolution for 32 frames.\n\timport torch\n\timport torch.nn as nn\n\tbasic_dims = 8\n\ttransformer_basic_dims = 512\n\tmlp_dim = 4096\n\tnum_heads = 8\n\tdepth = 1\n\tnum_modals = 3\n\tpatch_size = [2, 8, 8]\n", "def normalization(planes, norm='bn'):\n\t    if norm == 'bn':\n\t        m = nn.BatchNorm3d(planes)\n\t    elif norm == 'gn':\n\t        m = nn.GroupNorm(4, planes)\n\t    elif norm == 'in':\n\t        m = nn.InstanceNorm3d(planes)\n\t    else:\n\t        raise ValueError('normalization type {} is not supported'.format(norm))\n\t    return m\n", "class general_conv3d_prenorm(nn.Module):\n\t    def __init__(self, in_ch, out_ch, k_size=3, stride=1, padding=1, pad_type='zeros', norm='in', is_training=True,\n\t                 act_type='lrelu', relufactor=0.2):\n\t        super(general_conv3d_prenorm, self).__init__()\n\t        self.conv = nn.Conv3d(in_channels=in_ch, out_channels=out_ch, kernel_size=k_size, stride=stride,\n\t                              padding=padding, padding_mode=pad_type, bias=True)\n\t        self.norm = normalization(out_ch, norm=norm)\n\t        if act_type == 'relu':\n\t            self.activation = nn.ReLU(inplace=True)\n\t        elif act_type == 'lrelu':\n", "            self.activation = nn.LeakyReLU(negative_slope=relufactor, inplace=True)\n\t    def forward(self, x):\n\t        x = self.norm(x)\n\t        x = self.activation(x)\n\t        x = self.conv(x)\n\t        return x\n\tclass fusion_prenorm(nn.Module):\n\t    def __init__(self, in_channel=64, num_cls=1):\n\t        super(fusion_prenorm, self).__init__()\n\t        self.fusion_layer = nn.Sequential(\n", "            general_conv3d_prenorm(in_channel * num_modals, in_channel, k_size=1, padding=0, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\t    def forward(self, x):\n\t        return self.fusion_layer(x)\n\tclass Encoder(nn.Module):\n\t    def __init__(self, flag=True):\n\t        super(Encoder, self).__init__()\n\t        if flag:\n\t            self.e1_c1 = nn.Conv3d(in_channels=1, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n", "                                   padding_mode='zeros', bias=True)\n\t        else:\n\t            self.e1_c1 = nn.Conv3d(in_channels=2, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n\t                                   padding_mode='zeros', bias=True)\n\t        self.e1_c2 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\t        self.e1_c3 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\t        self.e2_c1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n\t        self.e2_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\t        self.e2_c3 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\t        self.e3_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n", "        self.e3_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\t        self.e3_c3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\t        self.e4_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n\t        self.e4_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\t        self.e4_c3 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\t        self.e5_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n\t        self.e5_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\t        self.e5_c3 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\t    def forward(self, x):\n\t        x1 = self.e1_c1(x)\n", "        x1 = x1 + self.e1_c3(self.e1_c2(x1))\n\t        x2 = self.e2_c1(x1)\n\t        x2 = x2 + self.e2_c3(self.e2_c2(x2))\n\t        x3 = self.e3_c1(x2)\n\t        x3 = x3 + self.e3_c3(self.e3_c2(x3))\n\t        x4 = self.e4_c1(x3)\n\t        x4 = x4 + self.e4_c3(self.e4_c2(x4))\n\t        x5 = self.e5_c1(x4)\n\t        x5 = x5 + self.e5_c3(self.e5_c2(x5))\n\t        return x1, x2, x3, x4, x5\n", "class Decoder_fuse(nn.Module):\n\t    def __init__(self, num_cls=4):\n\t        super(Decoder_fuse, self).__init__()\n\t        self.d4_c1 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n\t        self.d4_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n\t        self.d4_out = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, k_size=1, padding=0, pad_type='zeros')\n\t        self.d3_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n\t        self.d3_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n\t        self.d3_out = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, k_size=1, padding=0, pad_type='zeros')\n\t        self.d2_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n", "        self.d2_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n\t        self.d2_out = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, k_size=1, padding=0, pad_type='zeros')\n\t        self.d1_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n\t        self.d1_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n\t        self.d1_out = general_conv3d_prenorm(basic_dims, basic_dims, k_size=1, padding=0, pad_type='zeros')\n\t        self.seg_d4 = nn.Conv3d(in_channels=basic_dims * 16, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                bias=True)\n\t        self.seg_d3 = nn.Conv3d(in_channels=basic_dims * 8, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                bias=True)\n\t        self.seg_d2 = nn.Conv3d(in_channels=basic_dims * 4, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n", "                                bias=True)\n\t        self.seg_d1 = nn.Conv3d(in_channels=basic_dims * 2, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                bias=True)\n\t        self.seg_layer = nn.Conv3d(in_channels=basic_dims, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                   bias=True)\n\t        self.softmax = nn.Softmax(dim=1)\n\t        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n\t        self.RFM5 = fusion_prenorm(in_channel=basic_dims * 16, num_cls=num_cls)\n\t        self.RFM4 = fusion_prenorm(in_channel=basic_dims * 8, num_cls=num_cls)\n\t        self.RFM3 = fusion_prenorm(in_channel=basic_dims * 4, num_cls=num_cls)\n", "        self.RFM2 = fusion_prenorm(in_channel=basic_dims * 2, num_cls=num_cls)\n\t        self.RFM1 = fusion_prenorm(in_channel=basic_dims * 1, num_cls=num_cls)\n\t    def forward(self, x1, x2, x3, x4, x5):\n\t        de_x5 = self.RFM5(x5)\n\t        de_x5 = self.d4_c1(self.up2(de_x5))\n\t        de_x4 = self.RFM4(x4)\n\t        de_x4 = torch.cat((de_x4, de_x5), dim=1)\n\t        de_x4 = self.d4_out(self.d4_c2(de_x4))\n\t        de_x4 = self.d3_c1(self.up2(de_x4))\n\t        de_x3 = self.RFM3(x3)\n", "        de_x3 = torch.cat((de_x3, de_x4), dim=1)\n\t        de_x3 = self.d3_out(self.d3_c2(de_x3))\n\t        de_x3 = self.d2_c1(self.up2(de_x3))\n\t        de_x2 = self.RFM2(x2)\n\t        de_x2 = torch.cat((de_x2, de_x3), dim=1)\n\t        de_x2 = self.d2_out(self.d2_c2(de_x2))\n\t        de_x2 = self.d1_c1(self.up2(de_x2))\n\t        de_x1 = self.RFM1(x1)\n\t        de_x1 = torch.cat((de_x1, de_x2), dim=1)\n\t        de_x1 = self.d1_out(self.d1_c2(de_x1))\n", "        logits = self.seg_layer(de_x1)\n\t        pred = torch.sigmoid(logits)\n\t        return pred\n\tclass RUnet(nn.Module):\n\t    def __init__(self, num_cls=1):\n\t        super(RUnet, self).__init__()\n\t        self.DCE_encoder = Encoder(flag=False)\n\t        self.ADC_encoder = Encoder(flag=True)\n\t        self.T2_encoder = Encoder(flag=True)\n\t        self.decoder_fuse = Decoder_fuse(num_cls=num_cls)\n", "        self.is_training = True\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv3d):\n\t                torch.nn.init.kaiming_normal_(m.weight)\n\t    def forward(self, x):\n\t        DCE_x1, DCE_x2, DCE_x3, DCE_x4, DCE_x5 = self.DCE_encoder(x[:, 0:2, :, :, :])\n\t        ADC_x1, ADC_x2, ADC_x3, ADC_x4, ADC_x5 = self.ADC_encoder(x[:, 2:3, :, :, :])\n\t        T2_x1, T2_x2, T2_x3, T2_x4, T2_x5 = self.T2_encoder(x[:, 3:4, :, :, :])\n\t        x1 = torch.cat((DCE_x1, ADC_x1, T2_x1), dim=1)\n\t        x2 = torch.cat((DCE_x2, ADC_x2, T2_x2), dim=1)\n", "        x3 = torch.cat((DCE_x3, ADC_x3, T2_x3), dim=1)\n\t        x4 = torch.cat((DCE_x4, ADC_x4, T2_x4), dim=1)\n\t        x5 = torch.cat((DCE_x5, ADC_x5, T2_x5), dim=1)\n\t        fuse_pred = self.decoder_fuse(x1, x2, x3, x4, x5)\n\t        return fuse_pred\n"]}
{"filename": "Step3-Tumor-Segmentation/train.py", "chunked_list": ["import torch\n\timport numpy as np\n\timport torch.optim as optim\n\tfrom options.Options import Options_x\n\tfrom dataset.dataset_lits_train import Lits_DataSet\n\tfrom dataset.dataset_lits_val import Val_DataSet\n\tfrom Model.networks import MoSID\n\tfrom torch.utils.data import DataLoader\n\tfrom utils.common import adjust_learning_rate\n\tfrom utils import logger, util\n", "from utils.metrics import LossAverage, DiceLoss\n\timport os\n\timport time\n\tfrom test import test_all\n\tfrom collections import OrderedDict\n\tdef val(val_dataloader, epoch):\n\t    since = time.time()\n\t    Loss = LossAverage()\n\t    DICE_Loss = LossAverage()\n\t    BCE_Loss = LossAverage()\n", "    for i, (DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt) in enumerate(val_dataloader):\n\t        b, c, l, w, e = DCE.shape[0], DCE.shape[1], DCE.shape[2], DCE.shape[3], DCE.shape[4]\n\t        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\t        sub = sub.view(-1, 1, l, w, e).to(device)\n\t        ADC = ADC.view(-1, 1, l, w, e).to(device)\n\t        T2W = T2W.view(-1, 1, l, w, e).to(device)\n\t        Infor_DCE = Infor_DCE.view(-1, 1, l, w, e).to(device)\n\t        Infor_ADC = Infor_ADC.view(-1, 1, l, w, e).to(device)\n\t        Infor_T2 = Infor_T2.view(-1, 1, l, w, e).to(device)\n\t        gt = gt.view(-1, 1, l, w, e).to(device)\n", "        pred = model(DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2)\n\t        Dice_loss = dice_loss(pred, gt)\n\t        Bce_loss = bce_loss(pred, gt)\n\t        loss = Bce_loss + 5 * Dice_loss\n\t        Loss.update(loss.item(), DCE.size(0))\n\t        DICE_Loss.update(Dice_loss.item(), DCE.size(0))\n\t        BCE_Loss.update(Bce_loss.item(), DCE.size(0))\n\t    time_elapsed = time.time() - since\n\t    print(\"=======Val Epoch:{}======Learning_rate:{}======Validate complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n\t    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})\n", "def train(train_dataloader, epoch):\n\t    since = time.time()\n\t    Loss = LossAverage()\n\t    DICE_Loss = LossAverage()\n\t    BCE_Loss = LossAverage()\n\t    model.train()\n\t    for i, (DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt) in enumerate(train_dataloader):  # inner loop within one epoch\n\t        b, c, l, w, e = DCE.shape[0], DCE.shape[1], DCE.shape[2], DCE.shape[3], DCE.shape[4]\n\t        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\t        sub = sub.view(-1, 1, l, w, e).to(device)\n", "        ADC = ADC.view(-1, 1, l, w, e).to(device)\n\t        T2W = T2W.view(-1, 1, l, w, e).to(device)\n\t        Infor_DCE = Infor_DCE.view(-1, 1, l, w, e).to(device)\n\t        Infor_ADC = Infor_ADC.view(-1, 1, l, w, e).to(device)\n\t        Infor_T2 = Infor_T2.view(-1, 1, l, w, e).to(device)\n\t        gt = gt.view(-1, 1, l, w, e).to(device)\n\t        pred = model(DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2)\n\t        Dice_loss = dice_loss(pred, gt)\n\t        Bce_loss = bce_loss(pred, gt)\n\t        loss = Bce_loss + 5 * Dice_loss\n", "        optimizer.zero_grad()\n\t        loss.backward()\n\t        optimizer.step()\n\t        adjust_learning_rate(optimizer, epoch, opt)\n\t        Loss.update(loss.item(), DCE.size(0))\n\t        DICE_Loss.update(Dice_loss.item(), DCE.size(0))\n\t        BCE_Loss.update(Bce_loss.item(), DCE.size(0))\n\t    time_elapsed = time.time() - since\n\t    print(\"=======Train Epoch:{}======Learning_rate:{}======Train complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n\t    return OrderedDict({'Loss': Loss.avg, 'DICE_Loss': DICE_Loss.avg, 'BCE_Loss': BCE_Loss.avg})\n", "if __name__ == '__main__':\n\t    opt = Options_x().parse()  # get training options\n\t    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n\t    print(\"using {} device.\".format(device))\n\t    model = MoSID().to(device)\n\t    save_path = opt.checkpoints_dir\n\t    dice_loss = DiceLoss()\n\t    bce_loss = torch.nn.BCEWithLogitsLoss()\n\t    save_result_path = os.path.join(save_path, opt.task_name)\n\t    util.mkdir(save_result_path)\n", "    optimizer = optim.Adam(model.parameters(), lr=opt.lr, weight_decay=1e-5)\n\t    model_save_path = os.path.join(save_result_path, 'model')\n\t    util.mkdir(model_save_path)\n\t    logger_save_path = os.path.join(save_result_path, 'logger')\n\t    util.mkdir(logger_save_path)\n\t    log_train = logger.Train_Logger(logger_save_path, \"train_log\")\n\t    log_val = logger.Val_Logger(logger_save_path, \"val_log\")\n\t    train_dataset = Lits_DataSet(opt.datapath, opt.patch_size)\n\t    val_dataset = Val_DataSet(opt.datapath, opt.patch_size)\n\t    train_dataloader = DataLoader(dataset=train_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads,\n", "                                  shuffle=True)\n\t    val_dataloader = DataLoader(dataset=val_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads,\n\t                                shuffle=True)\n\t    types = ['train', 'val']\n\t    val_dice_loss = 99\n\t    best_epoch = 0\n\t    for epoch in range(opt.epoch):\n\t        epoch = epoch + 1\n\t        for type in types:\n\t            if type == 'train':\n", "                train_log = train(train_dataloader, epoch)\n\t                log_train.update(epoch, train_log)\n\t            elif type == 'val':\n\t                val_log = val(val_dataloader, epoch)\n\t                log_val.update(epoch, val_log)\n\t                if val_log['DICE_Loss'] < val_dice_loss:\n\t                    best_epoch = epoch\n\t                    val_dice_loss = val_log['DICE_Loss']\n\t                    state = {'model': model.state_dict(), 'epoch': best_epoch}\n\t                    torch.save(state, os.path.join(model_save_path, 'best_model.pth'))\n", "        state = {'model': model.state_dict(), 'epoch': epoch}\n\t        torch.save(state, os.path.join(model_save_path, 'latest_model.pth'))\n\t        if epoch % opt.model_save_fre == 0:\n\t            torch.save(state, os.path.join(model_save_path, 'model_' + np.str(epoch) + '.pth'))\n\t        torch.cuda.empty_cache()\n\t    test_all('best_model.pth')\n"]}
{"filename": "Step3-Tumor-Segmentation/test.py", "chunked_list": ["import torch\n\timport gc\n\timport numpy as np\n\timport SimpleITK as sitk\n\tfrom options.Options import Options_x\n\tfrom tqdm import tqdm\n\tfrom Model.networks import MoSID\n\tfrom torch.utils.data import DataLoader\n\tfrom utils import logger, util\n\tfrom utils.metrics import seg_metric\n", "import os\n\tfrom dataset.dataset_lits_test import Test_all_Datasets, Recompone_tool\n\tfrom collections import OrderedDict\n\tdef load(file):\n\t    itkimage = sitk.ReadImage(file)\n\t    image = sitk.GetArrayFromImage(itkimage)\n\t    return image\n\tdef test_all(model_name='model_200.pth'):\n\t    opt = Options_x().parse()  # get training options\n\t    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n", "    print(\"using {} device.\".format(device))\n\t    model = MoSID().to(device)\n\t    ckpt = torch.load(opt.checkpoints_dir + '/' + opt.task_name + '/model/' + model_name, map_location=device)\n\t    model.load_state_dict(ckpt['model'])\n\t    save_result_path = os.path.join(opt.checkpoints_dir, opt.task_name, 'test_all_result')\n\t    util.mkdir(save_result_path)\n\t    model.eval()\n\t    log_test = logger.Test_Logger(save_result_path, \"results\")\n\t    cut_param = {'patch_s': opt.patch_size[0], 'patch_h': opt.patch_size[1], 'patch_w': opt.patch_size[2],\n\t                 'stride_s': opt.patch_stride[0], 'stride_h': opt.patch_stride[1], 'stride_w': opt.patch_stride[2]}\n", "    datasets = Test_all_Datasets(opt.datapath, cut_param)\n\t    for img_dataset, original_shape, new_shape, mask, file_idx, crop_box in datasets:\n\t        save_tool = Recompone_tool(original_shape, new_shape, cut_param)\n\t        dataloader = DataLoader(img_dataset, batch_size=opt.test_batch, num_workers=opt.num_threads, shuffle=False)\n\t        with torch.no_grad():\n\t            for pos, sub, adc, t2w, p_all_fake, p_fake_adc, p_fake_t2, gt in tqdm(dataloader):\n\t                pos, sub, adc, t2w, p_all_fake, p_fake_adc, p_fake_t2, gt = pos.to(device), sub.to(device), adc.to(\n\t                    device), t2w.to(device), p_all_fake.to(device), p_fake_adc.to(device), p_fake_t2.to(device), gt.to(\n\t                    device)\n\t                pos = pos.unsqueeze(1).type(torch.float32)\n", "                sub = sub.unsqueeze(1).type(torch.float32)\n\t                adc = adc.unsqueeze(1).type(torch.float32)\n\t                t2w = t2w.unsqueeze(1).type(torch.float32)\n\t                p_all_fake = p_all_fake.unsqueeze(1).type(torch.float32)\n\t                p_fake_adc = p_fake_adc.unsqueeze(1).type(torch.float32)\n\t                p_fake_t2 = p_fake_t2.unsqueeze(1).type(torch.float32)\n\t                output = model(pos, sub, adc, t2w, p_all_fake, p_fake_adc, p_fake_t2)\n\t                output = (output >= 0.5).type(torch.float32)\n\t                save_tool.add_result(output.detach().cpu())\n\t        pred = save_tool.recompone_overlap()\n", "        recon = (pred.numpy() > 0.5).astype(np.uint16)\n\t        pred_coarse = load(os.path.join(opt.datapath, file_idx, 'pred_coarse.nii.gz'))\n\t        pred_coarse[crop_box[0, 0]:crop_box[0, 1], crop_box[1, 0]:crop_box[1, 1], crop_box[2, 0]:crop_box[2, 1]] = recon\n\t        if np.sum(pred_coarse) < 15:\n\t            pred_coarse = load(os.path.join(opt.datapath, file_idx, 'pred_coarse.nii.gz'))\n\t        pred_coarse = pred_coarse * mask\n\t        gt = load(os.path.join(opt.datapath, file_idx, 'GT.nii.gz'))\n\t        DSC, PPV, SEN, ASD = seg_metric(pred_coarse, gt)\n\t        index_results = OrderedDict({'DSC': DSC, 'PPV': PPV, 'SEN': SEN, 'ASD': ASD})\n\t        log_test.update(file_idx, index_results)\n", "        Pred = sitk.GetImageFromArray(np.array(pred_coarse))\n\t        result_save_path = os.path.join(save_result_path, file_idx)\n\t        util.mkdir(result_save_path)\n\t        sitk.WriteImage(Pred, os.path.join(result_save_path, 'pred.nii.gz'))\n\t        del pred, recon, Pred, save_tool, pred_coarse, gt\n\t        gc.collect()\n\t        torch.cuda.empty_cache()\n\tif __name__ == '__main__':\n\t    test_all('best_model.pth')\n"]}
{"filename": "Step3-Tumor-Segmentation/options/BasicOptions.py", "chunked_list": ["import argparse\n\timport os\n\tfrom utils import util\n\timport torch\n\tclass BaseOptions():\n\t    \"\"\"This class defines options used during both training and test time.\n\t    It also implements several helper functions such as parsing, printing, and saving the options.\n\t    It also gathers additional options defined in <modify_commandline_options> functions in both dataset class and model class.\n\t    \"\"\"\n\t    def __init__(self):\n", "        \"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"\n\t        self.initialized = False\n\t    def initialize(self, parser):\n\t        \"\"\"Define the common options that are used in both training and test.\"\"\"\n\t        # basic parameters\n\t        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n\t        parser.add_argument('--num_threads', default=1, type=int, help='# threads for loading data')\n\t        parser.add_argument('--batch_size', type=int, default=1, help='input train batch size')\n\t        parser.add_argument('--test_batch', type=int, default=1, help='input test batch size')\n\t        parser.add_argument('--epoch', type=int, default=400, help='number of epochs with the initial learning rate')\n", "        parser.add_argument('--step', type=int, default=50, help='number of epochs to adjust learning rate')\n\t        parser.add_argument('--datapath', default=r'/data', help='path of the raw data')\n\t        parser.add_argument('--lr', type=float, default=0.005, help='initial learning rate of net for adam')\n\t        parser.add_argument('--model_save_fre', type=int, default=50, help='frequency of saving model') \n\t        parser.add_argument('--test_fre', type=int, default=600, help='frequency of testing the model')\n\t        parser.add_argument('--patch_size', type=int, default=(32, 128, 128), help='the size of crop patch')\n\t        parser.add_argument('--patch_stride', type=int, default=(8, 64, 64), help='the stride of patch')\n\t        parser.add_argument('--data_folder', type=int, default=4, help='the folder of datasets(1-3) 0 for debug')\n\t        parser.add_argument('--task_name', type=str, default='MultiModal_Parametric', help='the current task name')\n\t        self.initialized = True\n", "        return parser\n\t    def gather_options(self):\n\t        \"\"\"Initialize our parser with basic options(only once).\n\t        Add additional model-specific and dataset-specific options.\n\t        These options are defined in the <modify_commandline_options> function\n\t        in model and dataset classes.\n\t        \"\"\"\n\t        if not self.initialized:  # check if it has been initialized\n\t            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t            parser = self.initialize(parser)\n", "        # get the basic options\n\t        opt, _ = parser.parse_known_args()\n\t        # save and return the parser\n\t        self.parser = parser\n\t        return parser.parse_args()\n\t    def print_options(self, opt):\n\t        \"\"\"Print and save options\n\t        It will print both current options and default values(if different).\n\t        It will save options into a text file / [checkpoints_dir] / opt.txt\n\t        \"\"\"\n", "        message = ''\n\t        message += '----------------- Options ---------------\\n'\n\t        for k, v in sorted(vars(opt).items()):\n\t            comment = ''\n\t            default = self.parser.get_default(k)\n\t            if v != default:\n\t                comment = '\\t[default: %s]' % str(default)\n\t            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n\t        message += '----------------- End -------------------'\n\t        print(message)\n", "        # save to the disk\n\t        expr_dir = os.path.join(opt.checkpoints_dir, 'model_parameter_list')\n\t        util.mkdirs(expr_dir)\n\t        file_name = os.path.join(expr_dir, '{train_opt.txt')\n\t        with open(file_name, 'wt') as opt_file:\n\t            opt_file.write(message)\n\t            opt_file.write('\\n')\n\t    def parse(self):\n\t        \"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"\n\t        opt = self.gather_options()\n", "        opt.isTrain = self.isTrain   # train or test\n\t        self.print_options(opt)\n\t        self.opt = opt\n\t        return self.opt\n"]}
{"filename": "Step3-Tumor-Segmentation/options/Options.py", "chunked_list": ["from options.BasicOptions import BaseOptions\n\tclass Options_x(BaseOptions):\n\t    \"\"\"This class includes training options.\n\t    It also includes shared options defined in BaseOptions.\n\t    \"\"\"\n\t    def initialize(self, parser):\n\t        parser = BaseOptions.initialize(self, parser)\n\t        # visdom and HTML visualization parameters\n\t        parser.add_argument('--name', type=str, default='Tumor_seg', help='name_of_the_project')\n\t        self.isTrain = True\n", "        return parser\n"]}
{"filename": "Step3-Tumor-Segmentation/utils/weights_init.py", "chunked_list": ["from torch.nn import init\n\tdef weights_init_normal(m):\n\t    classname = m.__class__.__name__\n\t    if classname.find('Conv') != -1:\n\t        init.normal(m.weight.data, 0.0, 0.02)\n\t    elif classname.find('Linear') != -1:\n\t        init.normal(m.weight.data, 0.0, 0.02)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n\t        init.constant(m.bias.data, 0.0)\n", "def weights_init_xavier(m):\n\t    classname = m.__class__.__name__\n\t    if classname.find('Conv') != -1:\n\t        init.xavier_normal(m.weight.data, gain=1)\n\t    elif classname.find('Linear') != -1:\n\t        init.xavier_normal(m.weight.data, gain=1)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n\t        init.constant(m.bias.data, 0.0)\n\tdef weights_init_kaiming(m):\n", "    classname = m.__class__.__name__\n\t    if classname.find('Conv') != -1:\n\t        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n\t    elif classname.find('Linear') != -1:\n\t        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n\t        init.constant(m.bias.data, 0.0)\n\tdef weights_init_orthogonal(m):\n\t    classname = m.__class__.__name__\n", "    if classname.find('Conv') != -1:\n\t        init.orthogonal(m.weight.data, gain=1)\n\t    elif classname.find('Linear') != -1:\n\t        init.orthogonal(m.weight.data, gain=1)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n\t        init.constant(m.bias.data, 0.0)\n\tdef init_weights(net, init_type='normal'):\n\t    if init_type == 'normal':\n\t        net.apply(weights_init_normal)\n", "    elif init_type == 'xavier':\n\t        net.apply(weights_init_xavier)\n\t    elif init_type == 'kaiming':\n\t        net.apply(weights_init_kaiming)\n\t    elif init_type == 'orthogonal':\n\t        net.apply(weights_init_orthogonal)\n\t    else:\n\t        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n"]}
{"filename": "Step3-Tumor-Segmentation/utils/metrics.py", "chunked_list": ["import torch.nn as nn\n\timport torch\n\timport numpy as np\n\timport sys\n\tfrom scipy.ndimage import morphology\n\tsys.dont_write_bytecode = True  # don't generate the binray python file .pyc\n\tclass LossAverage(object):\n\t    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n\t    def __init__(self):\n\t        self.reset()\n", "    def reset(self):\n\t        self.val = 0\n\t        self.avg = 0\n\t        self.sum = 0\n\t        self.count = 0\n\t    def update(self, val, n):\n\t        self.val = val\n\t        self.sum += val * n\n\t        self.count += n\n\t        self.avg = round(self.sum / self.count, 4)\n", "        # print(self.val)\n\tclass DiceLoss(nn.Module):\n\t    \"\"\"\n\t    define the dice loss\n\t    \"\"\"\n\t    def __init__(self):\n\t        super(DiceLoss, self).__init__()\n\t    def forward(self, input, target):\n\t        smooth = 1.\n\t        iflat = input.contiguous().view(-1)\n", "        tflat = target.contiguous().view(-1)\n\t        intersection = (iflat * tflat).sum()\n\t        A_sum = torch.sum(iflat * iflat)\n\t        B_sum = torch.sum(tflat * tflat)\n\t        return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth))\n\t\"\"\"dice coefficient\"\"\"\n\tdef dice(pre, gt, tid=1):\n\t    pre = pre == tid  # make it boolean\n\t    gt = gt == tid  # make it boolean\n\t    pre = np.asarray(pre).astype(np.bool)\n", "    gt = np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    dsc = (2. * intersection.sum() + 1e-07) / (pre.sum() + gt.sum() + 1e-07)\n\t    return dsc\n\t\"\"\"positive predictive value\"\"\"\n\tdef pospreval(pre, gt, tid=1):\n\t    pre = pre == tid  # make it boolean\n\t    gt = gt == tid  # make it boolean\n", "    pre = np.asarray(pre).astype(np.bool)\n\t    gt = np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    ppv = (1.0 * intersection.sum() + 1e-07) / (pre.sum() + 1e-07)\n\t    return ppv\n\t\"\"\"sensitivity\"\"\"\n\tdef sensitivity(pre, gt, tid=1):\n\t    pre = pre == tid  # make it boolean\n", "    gt = gt == tid  # make it boolean\n\t    pre = np.asarray(pre).astype(np.bool)\n\t    gt = np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    sen = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\t    return sen\n\t\"\"\"specificity\"\"\"\n\tdef specificity(pre, gt):\n", "    pre = pre == 0  # make it boolean\n\t    gt = gt == 0  # make it boolean\n\t    pre = np.asarray(pre).astype(np.bool)\n\t    gt = np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    spe = (1.0 * intersection.sum() + 1e-07) / (gt.sum() + 1e-07)\n\t    return spe\n\t\"\"\"average surface distance\"\"\"\n", "def surfd(pre, gt, tid=1, sampling=1, connectivity=1):\n\t    pre = pre == tid  # make it boolean\n\t    gt = gt == tid  # make it boolean\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    input_1 = np.atleast_1d(pre.astype(np.bool))\n\t    input_2 = np.atleast_1d(gt.astype(np.bool))\n\t    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n\t    S = np.logical_xor(input_1, morphology.binary_erosion(input_1, conn))\n\t    Sprime = np.logical_xor(input_2, morphology.binary_erosion(input_2, conn))\n", "    dta = morphology.distance_transform_edt(~S, sampling)\n\t    dtb = morphology.distance_transform_edt(~Sprime, sampling)\n\t    sds = np.concatenate([np.ravel(dta[Sprime != 0]), np.ravel(dtb[S != 0])])\n\t    return sds\n\tdef asd(pre, gt, tid=1, sampling=1, connectivity=1):\n\t    sds = surfd(pre, gt, tid=tid, sampling=sampling, connectivity=connectivity)\n\t    dis = sds.mean()\n\t    return dis\n\tdef seg_metric(pre, gt):\n\t    mask = (pre > 0.5)\n", "    gt = (gt > 0.5)\n\t    ASD = asd(mask, gt)\n\t    DSC = dice(mask, gt)\n\t    SEN = sensitivity(mask, gt)\n\t    PPV = pospreval(mask, gt)\n\t    return DSC, PPV, SEN, ASD\n"]}
{"filename": "Step3-Tumor-Segmentation/utils/logger.py", "chunked_list": ["import pandas as pd\n\tfrom torch.utils.tensorboard import SummaryWriter\n\timport torch, random\n\timport numpy as np\n\tfrom collections import OrderedDict\n\tclass Train_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n\t        self.save_path = save_path\n", "        self.save_name = save_name\n\t    def update(self, epoch, train_log):\n\t        item = OrderedDict({'epoch': epoch})\n\t        item.update(train_log)\n\t        print(\"\\033[0;33mTrain:\\033[0m\", train_log)\n\t        self.update_csv(item)\n\t        self.update_tensorboard(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n\t        if self.log is not None:\n", "            self.log = self.log.append(tmp, ignore_index=True)\n\t        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\t    def update_tensorboard(self, item):\n\t        if self.summary is None:\n\t            self.summary = SummaryWriter('%s/' % self.save_path)\n\t        epoch = item['epoch']\n\t        for key, value in item.items():\n\t            if key != 'epoch': self.summary.add_scalar(key, value, epoch)\n", "class Val_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n\t        self.save_path = save_path\n\t        self.save_name = save_name\n\t    def update(self, epoch, val_log):\n\t        item = OrderedDict({'epoch': epoch})\n\t        item.update(val_log)\n\t        print(\"\\033[0;33mValidate:\\033[0m\", val_log)\n", "        self.update_csv(item)\n\t        self.update_tensorboard(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n\t        if self.log is not None:\n\t            self.log = self.log.append(tmp, ignore_index=True)\n\t        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\t    def update_tensorboard(self, item):\n", "        if self.summary is None:\n\t            self.summary = SummaryWriter('%s/' % self.save_path)\n\t        epoch = item['epoch']\n\t        for key, value in item.items():\n\t            if key != 'epoch': self.summary.add_scalar(key, value, epoch)\n\tclass Test_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n\t        self.save_path = save_path\n", "        self.save_name = save_name\n\t    def update(self, name, log):\n\t        item = OrderedDict({'img_name': name})\n\t        item.update(log)\n\t        print(\"\\033[0;33mTest:\\033[0m\", log)\n\t        self.update_csv(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n\t        if self.log is not None:\n\t            self.log = self.log.append(tmp, ignore_index=True)\n", "        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\tdef setpu_seed(seed):\n\t    torch.manual_seed(seed)\n\t    torch.cuda.manual_seed_all(seed)\n\t    np.random.seed(seed)\n\t    torch.backends.cudnn.deterministic = True\n\t    random.seed(seed)\n\tdef dict_round(dic, num):\n", "    for key, value in dic.items():\n\t        dic[key] = round(value, num)\n\t    return dic\n"]}
{"filename": "Step3-Tumor-Segmentation/utils/__init__.py", "chunked_list": []}
{"filename": "Step3-Tumor-Segmentation/utils/util.py", "chunked_list": ["\"\"\"This module contains simple helper functions \"\"\"\n\tfrom __future__ import print_function\n\timport torch\n\timport numpy as np\n\tfrom PIL import Image\n\timport os\n\tdef tensor2im(input_image, imtype=np.uint8):\n\t    \"\"\"\"Converts a Tensor array into a numpy image array.\n\t    Parameters:\n\t        input_image (tensor) --  the input image tensor array\n", "        imtype (type)        --  the desired type of the converted numpy array\n\t    \"\"\"\n\t    if not isinstance(input_image, np.ndarray):\n\t        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n\t            image_tensor = input_image.data\n\t        else:\n\t            return input_image\n\t        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n\t        if image_numpy.shape[0] == 1:  # grayscale to RGB\n\t            image_numpy = np.tile(image_numpy, (3, 1, 1))\n", "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n\t    else:  # if it is a numpy array, do nothing\n\t        image_numpy = input_image\n\t    return image_numpy.astype(imtype)\n\tdef diagnose_network(net, name='network'):\n\t    \"\"\"Calculate and print the mean of average absolute(gradients)\n\t    Parameters:\n\t        net (torch network) -- Torch network\n\t        name (str) -- the name of the network\n\t    \"\"\"\n", "    mean = 0.0\n\t    count = 0\n\t    for param in net.parameters():\n\t        if param.grad is not None:\n\t            mean += torch.mean(torch.abs(param.grad.data))\n\t            count += 1\n\t    if count > 0:\n\t        mean = mean / count\n\t    print(name)\n\t    print(mean)\n", "def save_image(image_numpy, image_path, aspect_ratio=1.0):\n\t    \"\"\"Save a numpy image to the disk\n\t    Parameters:\n\t        image_numpy (numpy array) -- input numpy array\n\t        image_path (str)          -- the path of the image\n\t    \"\"\"\n\t    image_pil = Image.fromarray(image_numpy)\n\t    h, w, _ = image_numpy.shape\n\t    if aspect_ratio > 1.0:\n\t        image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)\n", "    if aspect_ratio < 1.0:\n\t        image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)\n\t    image_pil.save(image_path)\n\tdef print_numpy(x, val=True, shp=False):\n\t    \"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\t    Parameters:\n\t        val (bool) -- if print the values of the numpy array\n\t        shp (bool) -- if print the shape of the numpy array\n\t    \"\"\"\n\t    x = x.astype(np.float64)\n", "    if shp:\n\t        print('shape,', x.shape)\n\t    if val:\n\t        x = x.flatten()\n\t        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n\t            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))\n\tdef mkdirs(paths):\n\t    \"\"\"create empty directories if they don't exist\n\t    Parameters:\n\t        paths (str list) -- a list of directory paths\n", "    \"\"\"\n\t    if isinstance(paths, list) and not isinstance(paths, str):\n\t        for path in paths:\n\t            mkdir(path)\n\t    else:\n\t        mkdir(paths)\n\tdef mkdir(path):\n\t    \"\"\"create a single empty directory if it didn't exist\n\t    Parameters:\n\t        path (str) -- a single directory path\n", "    \"\"\"\n\t    if not os.path.exists(path):\n\t        os.makedirs(path)\n"]}
{"filename": "Step3-Tumor-Segmentation/utils/common.py", "chunked_list": ["import SimpleITK as sitk\n\timport numpy as np\n\timport math\n\tdef normalization(img):\n\t    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t    return out\n\tdef normalization_test(img):\n\t    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t    return out, np.max(img), np.min(img)\n\tdef center_crop_3d(img, label, slice_num=16):\n", "    if img.shape[0] < slice_num:\n\t        return None\n\t    left_x = img.shape[0] // 2 - slice_num // 2\n\t    right_x = img.shape[0] // 2 + slice_num // 2\n\t    crop_img = img[left_x:right_x]\n\t    crop_label = label[left_x:right_x]\n\t    return crop_img, crop_label\n\tdef load_file_name_list(file_path):\n\t    file_name_list = []\n\t    with open(file_path, 'r') as file_to_read:\n", "        while True:\n\t            lines = file_to_read.readline().strip()\n\t            if not lines:\n\t                break\n\t                pass\n\t            file_name_list.append(lines)\n\t            pass\n\t    return file_name_list\n\tdef MaskContour(image, position='xy', line=1):\n\t    itkimage = sitk.GetImageFromArray(image)\n", "    if position == 'xy':\n\t        erode_m = [line, line, 0]\n\t    elif position == 'yz':\n\t        erode_m = [0, line, line]\n\t    elif position == 'zx':\n\t        erode_m = [line, 0, line]\n\t    else:\n\t        erode_m = [line, line, 0]\n\t    mask = sitk.GetArrayFromImage(sitk.BinaryErode(itkimage, erode_m))\n\t    boundary = image - mask\n", "    out = sitk.GetImageFromArray(boundary)\n\t    return out\n\tdef print_network(net):\n\t    num_params = 0\n\t    for param in net.parameters():\n\t        num_params += param.numel()\n\t    print(net)\n\t    print('Total number of parameters: %d' % num_params)\n\tdef adjust_learning_rate(optimizer, epoch, opt):\n\t    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n", "    lr = opt.lr * (0.5 ** (epoch // opt.step))\n\t    for param_group in optimizer.param_groups:\n\t        param_group['lr'] = lr\n\tdef adjust_learning_rate_V2(optimizer, lr):\n\t    \"\"\"Sets the learning rate to a fixed number\"\"\"\n\t    for param_group in optimizer.param_groups:\n\t        param_group['lr'] = lr\n\tdef get_mse(img1, img2):\n\t    mse = np.mean((img1 - img2) ** 2)\n\t    return mse\n", "def get_psnr(img1, img2):\n\t    mse = np.mean((img1 - img2) ** 2)\n\t    if mse == 0:\n\t        return 100\n\t    PIXEL_MAX = 1.0\n\t    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))\n\t'''\n\tdef get_ssim(img1,img2):\n\t    n=img1.shape[0]\n\t    out = 0\n", "    for i in range(n):\n\t        out+=structural_similarity(img1[i].squeeze(),img2[i].squeeze())\n\t    return out/n\n\t'''\n\tdef save_result(low_dose, high_dose, output, i, epoch):\n\t    def save_img(img, name):\n\t        img = sitk.GetImageFromArray(img)\n\t        sitk.WriteImage(img, 'result/image/' + name + '.nii.gz')\n\t    save_img(low_dose, 'low_dose_epoch_' + str(epoch) + \"_\" + str(i))\n\t    save_img(high_dose, 'high_dose_epoch_' + str(epoch) + \"_\" + str(i))\n", "    save_img(output, 'output_epoch_' + str(epoch) + \"_\" + str(i))\n\tdef de_normalization(img, max_x, min_x):\n\t    return img * (max_x - min_x) + min_x\n"]}
{"filename": "Step3-Tumor-Segmentation/dataset/dataset_lits_test.py", "chunked_list": ["import numpy as np\n\timport torch, os\n\tfrom torch.utils.data import Dataset, DataLoader\n\tfrom glob import glob\n\timport random\n\timport SimpleITK as sitk\n\tdef normalization(img, lmin=1, rmax=None, dividend=None, quantile=1):\n\t    newimg = img.copy()\n\t    newimg = newimg.astype(np.float32)\n\t    if quantile is not None:\n", "        maxval = round(np.percentile(newimg, 100 - quantile))\n\t        minval = round(np.percentile(newimg, quantile))\n\t        newimg[newimg >= maxval] = maxval\n\t        newimg[newimg <= minval] = minval\n\t    if lmin is not None:\n\t        newimg[newimg < lmin] = lmin\n\t    if rmax is not None:\n\t        newimg[newimg > rmax] = rmax\n\t    minval = np.min(newimg)\n\t    if dividend is None:\n", "        maxval = np.max(newimg)\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t    else:\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t    return newimg, minval, maxval\n\tdef normalization_fix(img, minval, maxval, lmin=1):\n\t    newimg = img.copy()\n\t    newimg = newimg.astype(np.float32)\n\t    if lmin is not None:\n\t        newimg[newimg < lmin] = lmin\n", "    newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t    return newimg\n\tdef normalization_org(img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t    newimg = img.copy()\n\t    newimg = newimg.astype(np.float32)\n\t    if quantile is not None:\n\t        maxval = round(np.percentile(newimg, 100 - quantile))\n\t        minval = round(np.percentile(newimg, quantile))\n\t        newimg[newimg >= maxval] = maxval\n\t        newimg[newimg <= minval] = minval\n", "    if lmin is not None:\n\t        newimg[newimg < lmin] = lmin\n\t    if rmax is not None:\n\t        newimg[newimg > rmax] = rmax\n\t    minval = np.min(newimg)\n\t    if dividend is None:\n\t        maxval = np.max(newimg)\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t    else:\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n", "    return newimg\n\tdef load(file):\n\t    itkimage = sitk.ReadImage(file)\n\t    image = sitk.GetArrayFromImage(itkimage)\n\t    return image\n\tdef maskcor_extract_3d(mask, padding=(5, 5, 5)):\n\t    # mask_s = mask.shape\n\t    p = np.where(mask > 0)\n\t    a = np.zeros([3, 2], dtype=np.int)\n\t    if len(p[0]) == 0:\n", "        a[0, 0] = 0\n\t        a[0, 1] = 32\n\t        a[1, 0] = 0\n\t        a[1, 1] = 128\n\t        a[2, 0] = 0\n\t        a[2, 1] = 128\n\t        return a\n\t    for i in range(3):\n\t        s = p[i].min()\n\t        e = p[i].max() + 1\n", "        ss = s - padding[i]\n\t        ee = e + padding[i]\n\t        if ss < 0:\n\t            ss = 0\n\t        if ee > mask.shape[i]:\n\t            ee = mask.shape[i]\n\t        a[i, 0] = ss\n\t        a[i, 1] = ee\n\t    return a\n\tclass Img_DataSet(Dataset):\n", "    def __init__(self, pos, sub, adc, t2w, Infor_DCE, Infor_ADC, Infor_T2, gt, cut_param):\n\t        self.pos = pos\n\t        self.sub = sub\n\t        self.adc = adc\n\t        self.t2w = t2w\n\t        self.Infor_DCE = Infor_DCE\n\t        self.Infor_ADC = Infor_ADC\n\t        self.Infor_T2 = Infor_T2\n\t        self.gt = gt\n\t        self.ori_shape = self.pos.shape\n", "        self.cut_param = cut_param\n\t        self.pos = self.padding_img(self.pos, self.cut_param)\n\t        self.pos = self.extract_ordered_overlap(self.pos, self.cut_param)\n\t        self.sub = self.padding_img(self.sub, self.cut_param)\n\t        self.sub = self.extract_ordered_overlap(self.sub, self.cut_param)\n\t        self.adc = self.padding_img(self.adc, self.cut_param)\n\t        self.adc = self.extract_ordered_overlap(self.adc, self.cut_param)\n\t        self.t2w = self.padding_img(self.t2w, self.cut_param)\n\t        self.t2w = self.extract_ordered_overlap(self.t2w, self.cut_param)\n\t        self.Infor_DCE = self.padding_img(self.Infor_DCE, self.cut_param)\n", "        self.Infor_DCE = self.extract_ordered_overlap(self.Infor_DCE, self.cut_param)\n\t        self.Infor_ADC = self.padding_img(self.Infor_ADC, self.cut_param)\n\t        self.Infor_ADC = self.extract_ordered_overlap(self.Infor_ADC, self.cut_param)\n\t        self.Infor_T2 = self.padding_img(self.Infor_T2, self.cut_param)\n\t        self.Infor_T2 = self.extract_ordered_overlap(self.Infor_T2, self.cut_param)\n\t        self.gt = self.padding_img(self.gt, self.cut_param)\n\t        self.gt = self.extract_ordered_overlap(self.gt, self.cut_param)\n\t        self.new_shape = self.pos.shape\n\t    def __getitem__(self, index):\n\t        pos = self.pos[index]\n", "        sub = self.sub[index]\n\t        adc = self.adc[index]\n\t        t2w = self.t2w[index]\n\t        Infor_DCE = self.Infor_DCE[index]\n\t        Infor_ADC = self.Infor_ADC[index]\n\t        Infor_T2 = self.Infor_T2[index]\n\t        gt = self.gt[index]\n\t        return torch.from_numpy(pos), torch.from_numpy(sub), torch.from_numpy(\n\t            adc), torch.from_numpy(t2w), torch.from_numpy(Infor_DCE), torch.from_numpy(Infor_ADC), torch.from_numpy(\n\t            Infor_T2), torch.from_numpy(gt)\n", "    def __len__(self):\n\t        return len(self.pos)\n\t    def padding_img(self, img, C):\n\t        assert (len(img.shape) == 3)  # 3D array\n\t        img_s, img_h, img_w = img.shape\n\t        leftover_s = (img_s - C['patch_s']) % C['stride_s']\n\t        leftover_h = (img_h - C['patch_h']) % C['stride_h']\n\t        leftover_w = (img_w - C['patch_w']) % C['stride_w']\n\t        if (leftover_s != 0):\n\t            s = img_s + (C['stride_s'] - leftover_s)\n", "        else:\n\t            s = img_s\n\t        if (leftover_h != 0):\n\t            h = img_h + (C['stride_h'] - leftover_h)\n\t        else:\n\t            h = img_h\n\t        if (leftover_w != 0):\n\t            w = img_w + (C['stride_w'] - leftover_w)\n\t        else:\n\t            w = img_w\n", "        tmp_full_imgs = np.zeros((s, h, w))\n\t        tmp_full_imgs[:img_s, :img_h, 0:img_w] = img\n\t        # print(\"Padded images shape: \" + str(tmp_full_imgs.shape))\n\t        return tmp_full_imgs\n\t    # Divide all the full_imgs in pacthes\n\t    def extract_ordered_overlap(self, img, C):\n\t        assert (len(img.shape) == 3)  # 3D arrays\n\t        img_s, img_h, img_w = img.shape\n\t        assert ((img_h - C['patch_h']) % C['stride_h'] == 0\n\t                and (img_w - C['patch_w']) % C['stride_w'] == 0\n", "                and (img_s - C['patch_s']) % C['stride_s'] == 0)\n\t        N_patches_s = (img_s - C['patch_s']) // C['stride_s'] + 1\n\t        N_patches_h = (img_h - C['patch_h']) // C['stride_h'] + 1\n\t        N_patches_w = (img_w - C['patch_w']) // C['stride_w'] + 1\n\t        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n\t        # print(\"Patches number of the image:{} [s={} | h={} | w={}]\"\\\n\t        #               .format(N_patches_img, N_patches_s, N_patches_h, N_patches_w))\n\t        patches = np.empty((N_patches_img, C['patch_s'], C['patch_h'], C['patch_w']))\n\t        iter_tot = 0  # iter over the total number of patches (N_patches)\n\t        for s in range(N_patches_s):  # loop over the full images\n", "            for h in range(N_patches_h):\n\t                for w in range(N_patches_w):\n\t                    patch = img[s * C['stride_s']: s * C['stride_s'] + C['patch_s'],\n\t                            h * C['stride_h']: h * C['stride_h'] + C['patch_h'],\n\t                            w * C['stride_w']: w * C['stride_w'] + C['patch_w']]\n\t                    patches[iter_tot] = patch\n\t                    iter_tot += 1  # total\n\t        assert (iter_tot == N_patches_img)\n\t        return patches  # array with all the full_imgs divided in patches\n\tclass Recompone_tool():\n", "    def __init__(self, img_ori_shape, img_new_shape, Cut_para):\n\t        self.result = None\n\t        self.ori_shape = img_ori_shape\n\t        self.new_shape = img_new_shape\n\t        self.C = Cut_para\n\t    def add_result(self, tensor):\n\t        # tensor = tensor.detach().cpu() # shape: [N,class,s,h,w]\n\t        # tensor_np = np.squeeze(tensor_np,axis=0)\n\t        if self.result is not None:\n\t            self.result = torch.cat((self.result, tensor), dim=0)\n", "        else:\n\t            self.result = tensor\n\t    def recompone_overlap(self):\n\t        \"\"\"\n\t        :param preds: output of model  shapeï¼š[N_patchs_img,3,patch_s,patch_h,patch_w]\n\t        :return: result of recompone output shape: [3,img_s,img_h,img_w]\n\t        \"\"\"\n\t        patch_s = self.result.shape[2]\n\t        patch_h = self.result.shape[3]\n\t        patch_w = self.result.shape[4]\n", "        N_patches_s = (self.new_shape[0] - patch_s) // self.C['stride_s'] + 1\n\t        N_patches_h = (self.new_shape[1] - patch_h) // self.C['stride_h'] + 1\n\t        N_patches_w = (self.new_shape[2] - patch_w) // self.C['stride_w'] + 1\n\t        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n\t        assert (self.result.shape[0] == N_patches_img)\n\t        full_prob = torch.zeros((self.new_shape[0], self.new_shape[1],\n\t                                 self.new_shape[2]))  # itialize to zero mega array with sum of Probabilities\n\t        full_sum = torch.zeros((self.new_shape[0], self.new_shape[1], self.new_shape[2]))\n\t        k = 0  # iterator over all the patches\n\t        for s in range(N_patches_s):\n", "            for h in range(N_patches_h):\n\t                for w in range(N_patches_w):\n\t                    # print(k,self.result[k].squeeze().sum())\n\t                    full_prob[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n\t                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n\t                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += self.result[k].squeeze()\n\t                    full_sum[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n\t                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n\t                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += 1\n\t                    k += 1\n", "        assert (k == self.result.size(0))\n\t        assert (torch.min(full_sum) >= 1.0)  # at least one\n\t        final_avg = full_prob / full_sum\n\t        # print(final_avg.size())\n\t        img = final_avg[:self.ori_shape[0], :self.ori_shape[1], :self.ori_shape[2]]\n\t        return img\n\tdef cal_newshape(img, C):\n\t    assert (len(img.shape) == 3)  # 3D array\n\t    img_s, img_h, img_w = img.shape\n\t    leftover_s = (img_s - C['patch_s']) % C['stride_s']\n", "    leftover_h = (img_h - C['patch_h']) % C['stride_h']\n\t    leftover_w = (img_w - C['patch_w']) % C['stride_w']\n\t    if (leftover_s != 0):\n\t        s = img_s + (C['stride_s'] - leftover_s)\n\t    else:\n\t        s = img_s\n\t    if (leftover_h != 0):\n\t        h = img_h + (C['stride_h'] - leftover_h)\n\t    else:\n\t        h = img_h\n", "    if (leftover_w != 0):\n\t        w = img_w + (C['stride_w'] - leftover_w)\n\t    else:\n\t        w = img_w\n\t    return np.zeros((s, h, w)).shape\n\tdef package_torch(pre_patch, pos_patch, sub_patch, gt_patch):\n\t    pre_patch = torch.from_numpy(pre_patch[np.newaxis, np.newaxis, :])\n\t    pos_patch = torch.from_numpy(pos_patch[np.newaxis, np.newaxis, :])\n\t    sub_patch = torch.from_numpy(sub_patch[np.newaxis, np.newaxis, :])\n\t    gt_patch = torch.from_numpy(gt_patch[np.newaxis, np.newaxis, :])\n", "    return pre_patch, pos_patch, sub_patch, gt_patch\n\tdef crop_patch(img, crop_box):\n\t    img_patch = img[crop_box[0, 0]:crop_box[0, 1], crop_box[1, 0]:crop_box[1, 1], crop_box[2, 0]:crop_box[2, 1]]\n\t    return img_patch\n\tdef fine_crop(pred, crop_size):\n\t    cor_box = maskcor_extract_3d(pred, (10, 10, 10))\n\t    box_shape = pred.shape\n\t    for i in range(3):\n\t        len_cor = cor_box[i, 1] - cor_box[i, 0]\n\t        if (len_cor <= crop_size[i]):\n", "            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] // 2)\n\t            cor_box[i, 1] = cor_box[i, 0] + crop_size[i]\n\t            if cor_box[i, 0] < 0:\n\t                cor_box[i, 0] = 0\n\t                cor_box[i, 1] = cor_box[i, 0] + crop_size[i]\n\t            if cor_box[i, 1] > box_shape[i]:\n\t                cor_box[i, 1] = box_shape[i]\n\t                cor_box[i, 0] = cor_box[i, 1] - crop_size[i]\n\t        elif len_cor <= crop_size[i] * 2:\n\t            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i])\n", "            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 2\n\t            if cor_box[i, 0] < 0:\n\t                cor_box[i, 0] = 0\n\t                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 2\n\t            if cor_box[i, 1] > box_shape[i]:\n\t                cor_box[i, 1] = box_shape[i]\n\t                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 2\n\t        elif len_cor <= crop_size[i] * 3:\n\t            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 1.5)\n\t            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 3\n", "            if cor_box[i, 0] < 0:\n\t                cor_box[i, 0] = 0\n\t                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 3\n\t            if cor_box[i, 1] > box_shape[i]:\n\t                cor_box[i, 1] = box_shape[i]\n\t                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 3\n\t        elif len_cor <= crop_size[i] * 4:\n\t            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 2)\n\t            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 4\n\t            if cor_box[i, 0] < 0:\n", "                cor_box[i, 0] = 0\n\t                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 4\n\t            if cor_box[i, 1] > box_shape[i]:\n\t                cor_box[i, 1] = box_shape[i]\n\t                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 4\n\t        elif len_cor <= crop_size[i] * 5:\n\t            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 2.5)\n\t            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 5\n\t            if cor_box[i, 0] < 0:\n\t                cor_box[i, 0] = 0\n", "                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 5\n\t            if cor_box[i, 1] > box_shape[i]:\n\t                cor_box[i, 1] = box_shape[i]\n\t                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 5\n\t        elif len_cor <= crop_size[i] * 6:\n\t            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 3)\n\t            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 6\n\t            if cor_box[i, 0] < 0:\n\t                cor_box[i, 0] = 0\n\t                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 6\n", "            if cor_box[i, 1] > box_shape[i]:\n\t                cor_box[i, 1] = box_shape[i]\n\t                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 6\n\t        elif len_cor <= crop_size[i] * 7:\n\t            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 3.5)\n\t            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 7\n\t            if cor_box[i, 0] < 0:\n\t                cor_box[i, 0] = 0\n\t                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 7\n\t            if cor_box[i, 1] > box_shape[i]:\n", "                cor_box[i, 1] = box_shape[i]\n\t                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 7\n\t        elif len_cor <= crop_size[i] * 8:\n\t            cor_box[i, 0] = np.int((cor_box[i, 1] + cor_box[i, 0]) // 2 - crop_size[i] * 4)\n\t            cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 8\n\t            if cor_box[i, 0] < 0:\n\t                cor_box[i, 0] = 0\n\t                cor_box[i, 1] = cor_box[i, 0] + crop_size[i] * 8\n\t            if cor_box[i, 1] > box_shape[i]:\n\t                cor_box[i, 1] = box_shape[i]\n", "                cor_box[i, 0] = cor_box[i, 1] - crop_size[i] * 8\n\t        else:\n\t            print('too large tumor')\n\t            cor_box[i, 0] = 0\n\t            cor_box[i, 1] = box_shape[i]\n\t        if (cor_box[i, 1] - cor_box[i, 0]) >= box_shape[i]:\n\t            cor_box[i, 1] = box_shape[i]\n\t            cor_box[i, 0] = 0\n\t        if (cor_box[i, 1] - cor_box[i, 0]) != box_shape[i]:\n\t            if (cor_box[i, 1] - cor_box[i, 0]) % crop_size[i] != 0:\n", "                print('Something goes wrong!')\n\t        if (cor_box[i, 1] - cor_box[i, 0]) == box_shape[i]:\n\t            cor_box[i, 1] = (len_cor // crop_size[i]) * crop_size[i] + cor_box[i, 0]\n\t    return cor_box\n\tdef Test_all_Datasets(dataset_path, size):\n\t    f = open(os.path.join(dataset_path, 'test.txt'))\n\t    data_list = f.read().splitlines()\n\t    print(\"The number of test samples is: \", len(data_list))\n\t    for file in data_list:\n\t        print(\"\\nStart Evaluate: \", file)\n", "        pre, pre_min, pre_max = normalization(load(os.path.join(dataset_path, file, 'DCE0.nii.gz')))\n\t        pos = normalization_fix(load(os.path.join(dataset_path, file, 'DCE.nii.gz')), pre_min, pre_max).astype(\n\t            np.float32)\n\t        sub = pos - pre\n\t        adc = normalization_org(load(os.path.join(dataset_path, file, 'ADC.nii.gz'))).astype(np.float32)\n\t        t2w = normalization_org(load(os.path.join(dataset_path, file, 'T2.nii.gz'))).astype(np.float32)\n\t        Infor_DCE = load(os.path.join(dataset_path, file, 'Infor_DCE.nii.gz')).astype(np.float32)\n\t        Infor_ADC = load(os.path.join(dataset_path, file, 'Infor_ADC.nii.gz')).astype(np.float32)\n\t        Infor_T2 = load(os.path.join(dataset_path, file, 'Infor_T2.nii.gz')).astype(np.float32)\n\t        gt = load(os.path.join(dataset_path, file, 'GT.nii.gz')).astype(np.int16)\n", "        breast_mask = load(os.path.join(dataset_path, file, 'Breast_mask.nii.gz')).astype(np.int16)\n\t        pred = load(os.path.join(dataset_path, file, 'pred_coarse.nii.gz')).astype(np.float32)\n\t        cor_box = fine_crop(pred, (32, 128, 128))\n\t        pos = crop_patch(pos, cor_box)\n\t        sub = crop_patch(sub, cor_box)\n\t        t2w = crop_patch(t2w, cor_box)\n\t        adc = crop_patch(adc, cor_box)\n\t        Infor_DCE = crop_patch(Infor_DCE, cor_box)\n\t        Infor_ADC = crop_patch(Infor_ADC, cor_box)\n\t        Infor_T2 = crop_patch(Infor_T2, cor_box)\n", "        gt = crop_patch(gt, cor_box)\n\t        original_shape = gt.shape\n\t        new_shape = cal_newshape(gt, size)\n\t        yield Img_DataSet(pos, sub, adc, t2w, Infor_DCE, Infor_ADC, Infor_T2, gt,\n\t                          size), original_shape, new_shape, breast_mask, file, cor_box\n"]}
{"filename": "Step3-Tumor-Segmentation/dataset/dataset_lits_val.py", "chunked_list": ["import random\n\timport numpy as np\n\timport SimpleITK as sitk\n\timport os\n\tfrom torch.utils.data import Dataset\n\tclass Val_DataSet(Dataset):\n\t    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n\t        self.root = root\n\t        self.size = size\n\t        self.sample_index = sample_index\n", "        f = open(os.path.join(self.root, 'val.txt'))\n\t        self.filename = f.read().splitlines()\n\t    def __getitem__(self, index):\n\t        file = self.filename[index]\n\t        DCE0, DCE0_Min, DCE0_Max = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz')))\n\t        DCE = self.normalization_fix(self.load(os.path.join(self.root, file, 'DCE.nii.gz')), DCE0_Min, DCE0_Max).astype(\n\t            np.float32)\n\t        sub = DCE - DCE0\n\t        Coarse = self.load(os.path.join(self.root, file, 'pred_coarse.nii.gz')).astype(np.float32)\n\t        ADC = self.normalization_org(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n", "        T2W = self.normalization_org(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n\t        Infor_DCE = self.load(os.path.join(self.root, file, 'Infor_DCE.nii.gz')).astype(np.float32)\n\t        Infor_ADC = self.load(os.path.join(self.root, file, 'Infor_ADC.nii.gz')).astype(np.float32)\n\t        Infor_T2 = self.load(os.path.join(self.root, file, 'Infor_T2.nii.gz')).astype(np.float32)\n\t        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\t        DCE_patch, sub_patch, ADC_patch, T2W_patch, Infor_DCE_patch, Infor_ADC_patch, Infor_T2_patch, gt_patch = [], [], [], [], [], [], [], []\n\t        for i in range(3):\n\t            if i == 1:\n\t                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_partial(\n\t                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'add')\n", "            else:\n\t                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_contain(\n\t                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'sub')\n\t            DCE_patch.append(DCE_patch1), sub_patch.append(sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(\n\t                T2W_patch1), Infor_DCE_patch.append(\n\t                Infor_DCE_patch1), Infor_ADC_patch.append(Infor_ADC_patch1), Infor_T2_patch.append(\n\t                Infor_T2_patch1), gt_patch.append(gt_patch1)\n\t        return np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(T2W_patch), np.array(\n\t            Infor_DCE_patch), np.array(Infor_ADC_patch), np.array(Infor_T2_patch), np.array(gt_patch)\n\t    def __len__(self):\n", "        return len(self.filename)\n\t    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n\t        if pattern == 'sub':\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n\t        else:\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n\t        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n\t        if random_x_min > random_x_max:\n", "            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n\t        if random_y_min > random_y_max:\n\t            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n\t        if random_z_min > random_z_max:\n\t            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n\t        if pattern == 'sub':\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n\t        else:\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n", "        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def min_max_normalization(self, img):\n\t        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t        return out\n\t    def normalization_org(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n", "            maxval = round(np.percentile(newimg, 100 - quantile))\n\t            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n\t            newimg[newimg <= minval] = minval\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n", "            maxval = np.max(newimg)\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t        return newimg\n\t    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=1):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n\t            maxval = round(np.percentile(newimg, 100 - quantile))\n", "            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n\t            newimg[newimg <= minval] = minval\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n\t            maxval = np.max(newimg)\n", "            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t        return newimg, minval, maxval\n\t    def normalization_fix(self, img, minval, maxval, lmin=1):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n", "        return newimg\n\t    def load(self, file):\n\t        itkimage = sitk.ReadImage(file)\n\t        image = sitk.GetArrayFromImage(itkimage)\n\t        return image\n\t    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n\t        # mask_s = mask.shape\n\t        if np.sum(mask) == 0:\n\t            mask[10:12, 100:102, 100:102] = 1\n\t        p = np.where(mask > 0)\n", "        a = np.zeros([3, 2], dtype=np.int)\n\t        for i in range(3):\n\t            s = p[i].min()\n\t            e = p[i].max() + 1\n\t            ss = s - padding[i]\n\t            ee = e + padding[i]\n\t            if ss < 0:\n\t                ss = 0\n\t            if ee > mask.shape[i]:\n\t                ee = mask.shape[i]\n", "            a[i, 0] = ss\n\t            a[i, 1] = ee\n\t        return a\n"]}
{"filename": "Step3-Tumor-Segmentation/dataset/dataset_lits_train.py", "chunked_list": ["import random\n\timport numpy as np\n\timport SimpleITK as sitk\n\timport os\n\tfrom torch.utils.data import Dataset\n\tclass Lits_DataSet(Dataset):\n\t    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n\t        self.root = root\n\t        self.size = size\n\t        self.sample_index = sample_index\n", "        f = open(os.path.join(self.root, 'train.txt'))\n\t        self.filename = f.read().splitlines()\n\t    def __getitem__(self, index):\n\t        file = self.filename[index]\n\t        DCE0, DCE0_Min, DCE0_Max = self.normalization(self.load(os.path.join(self.root, file, 'DCE0.nii.gz')))\n\t        DCE = self.normalization_fix(self.load(os.path.join(self.root, file, 'DCE.nii.gz')), DCE0_Min, DCE0_Max).astype(\n\t            np.float32)\n\t        sub = DCE - DCE0\n\t        Coarse = self.load(os.path.join(self.root, file, 'pred_coarse.nii.gz')).astype(np.float32)\n\t        ADC = self.normalization_org(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n", "        T2W = self.normalization_org(self.load(os.path.join(self.root, file, 'T2.nii.gz'))).astype(np.float32)\n\t        Infor_DCE = self.load(os.path.join(self.root, file, 'Infor_DCE.nii.gz')).astype(np.float32)\n\t        Infor_ADC = self.load(os.path.join(self.root, file, 'Infor_ADC.nii.gz')).astype(np.float32)\n\t        Infor_T2 = self.load(os.path.join(self.root, file, 'Infor_T2.nii.gz')).astype(np.float32)\n\t        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\t        DCE_patch, sub_patch, ADC_patch, T2W_patch, Infor_DCE_patch, Infor_ADC_patch, Infor_T2_patch, gt_patch = [], [], [], [], [], [], [], []\n\t        for i in range(3):\n\t            if i == 1:\n\t                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_partial(\n\t                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'add')\n", "            else:\n\t                DCE_patch1, sub_patch1, ADC_patch1, T2W_patch1, Infor_DCE_patch1, Infor_ADC_patch1, Infor_T2_patch1, gt_patch1 = self.random_crop_3d_contain(\n\t                    DCE, sub, ADC, T2W, Infor_DCE, Infor_ADC, Infor_T2, gt, Coarse, self.size, 'sub')\n\t            DCE_patch.append(DCE_patch1), sub_patch.append(sub_patch1), ADC_patch.append(ADC_patch1), T2W_patch.append(\n\t                T2W_patch1), Infor_DCE_patch.append(\n\t                Infor_DCE_patch1), Infor_ADC_patch.append(Infor_ADC_patch1), Infor_T2_patch.append(\n\t                Infor_T2_patch1), gt_patch.append(gt_patch1)\n\t        return np.array(DCE_patch), np.array(sub_patch), np.array(ADC_patch), np.array(T2W_patch), np.array(\n\t            Infor_DCE_patch), np.array(Infor_ADC_patch), np.array(Infor_T2_patch), np.array(gt_patch)\n\t    def __len__(self):\n", "        return len(self.filename)\n\t    def random_crop_3d_contain(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n\t        if pattern == 'sub':\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n\t        else:\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n\t        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n\t        if random_x_min > random_x_max:\n", "            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n\t        if random_y_min > random_y_max:\n\t            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n\t        if random_z_min > random_z_max:\n\t            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def random_crop_3d_partial(self, a, b, c, d, e, f, g, gt, coarse, crop_size, pattern='sub'):\n\t        if pattern == 'sub':\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt - coarse))\n\t        else:\n\t            cor_box = self.maskcor_extract_3d(np.abs(gt + coarse))\n", "        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        c_patch = c[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        d_patch = d[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        e_patch = e[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        f_patch = f[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        g_patch = g[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, gt_patch\n\t    def min_max_normalization(self, img):\n\t        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t        return out\n\t    def normalization_org(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n", "            maxval = round(np.percentile(newimg, 100 - quantile))\n\t            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n\t            newimg[newimg <= minval] = minval\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n", "            maxval = np.max(newimg)\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t        return newimg\n\t    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=1):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n\t            maxval = round(np.percentile(newimg, 100 - quantile))\n", "            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n\t            newimg[newimg <= minval] = minval\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n\t            maxval = np.max(newimg)\n", "            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t        return newimg, minval, maxval\n\t    def normalization_fix(self, img, minval, maxval, lmin=1):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n", "        return newimg\n\t    def load(self, file):\n\t        itkimage = sitk.ReadImage(file)\n\t        image = sitk.GetArrayFromImage(itkimage)\n\t        return image\n\t    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n\t        # mask_s = mask.shape\n\t        if np.sum(mask) == 0:\n\t            mask[10:12, 100:102, 100:102] = 1\n\t        p = np.where(mask > 0)\n", "        a = np.zeros([3, 2], dtype=np.int)\n\t        for i in range(3):\n\t            s = p[i].min()\n\t            e = p[i].max() + 1\n\t            ss = s - padding[i]\n\t            ee = e + padding[i]\n\t            if ss < 0:\n\t                ss = 0\n\t            if ee > mask.shape[i]:\n\t                ee = mask.shape[i]\n", "            a[i, 0] = ss\n\t            a[i, 1] = ee\n\t        return a\n"]}
{"filename": "Step3-Tumor-Segmentation/Model/networks.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tbasic_dims = 8\n\tnum_modals = 3\n\tpatch_size = [2, 8, 8]\n\tdef normalization(planes, norm='bn'):\n\t    if norm == 'bn':\n\t        m = nn.BatchNorm3d(planes)\n\t    elif norm == 'gn':\n\t        m = nn.GroupNorm(4, planes)\n", "    elif norm == 'in':\n\t        m = nn.InstanceNorm3d(planes)\n\t    else:\n\t        raise ValueError('normalization type {} is not supported'.format(norm))\n\t    return m\n\tclass general_conv3d_prenorm(nn.Module):\n\t    def __init__(self, in_ch, out_ch, k_size=3, stride=1, padding=1, pad_type='zeros', norm='in', is_training=True,\n\t                 act_type='lrelu', relufactor=0.2):\n\t        super(general_conv3d_prenorm, self).__init__()\n\t        self.conv = nn.Conv3d(in_channels=in_ch, out_channels=out_ch, kernel_size=k_size, stride=stride,\n", "                              padding=padding, padding_mode=pad_type, bias=True)\n\t        self.norm = normalization(out_ch, norm=norm)\n\t        if act_type == 'relu':\n\t            self.activation = nn.ReLU(inplace=True)\n\t        elif act_type == 'lrelu':\n\t            self.activation = nn.LeakyReLU(negative_slope=relufactor, inplace=True)\n\t    def forward(self, x):\n\t        x = self.norm(x)\n\t        x = self.activation(x)\n\t        x = self.conv(x)\n", "        return x\n\tclass fusion_prenorm(nn.Module):\n\t    def __init__(self, in_channel=64, num_cls=1):\n\t        super(fusion_prenorm, self).__init__()\n\t        self.fusion_layer = nn.Sequential(\n\t            general_conv3d_prenorm(in_channel * num_modals, in_channel, k_size=1, padding=0, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\t    def forward(self, x):\n\t        return self.fusion_layer(x)\n", "class fusion_layer(nn.Module):\n\t    def __init__(self, in_channel=64, num_cls=1):\n\t        super(fusion_layer, self).__init__()\n\t        self.fusion_layer = nn.Sequential(\n\t            general_conv3d_prenorm(in_channel * 2, in_channel, k_size=1, padding=0, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\t    def forward(self, x):\n\t        return self.fusion_layer(x)\n\tclass MSA(nn.Module):\n", "    def __init__(self, F_g, F_l, n_coefficients):\n\t        super(MSA, self).__init__()\n\t        self.W_gate = nn.Sequential(\n\t            nn.Conv3d(F_g, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n\t            nn.BatchNorm3d(n_coefficients)\n\t        )\n\t        self.W_x = nn.Sequential(\n\t            nn.Conv3d(F_l, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n\t            nn.BatchNorm3d(n_coefficients)\n\t        )\n", "        self.psi = nn.Sequential(\n\t            nn.Conv3d(n_coefficients, 1, kernel_size=1, stride=1, padding=0, bias=True),\n\t            nn.BatchNorm3d(1),\n\t            nn.Sigmoid()\n\t        )\n\t        self.relu = nn.ReLU(inplace=True)\n\t    def forward(self, gate, skip_connection):\n\t        g1 = self.W_gate(gate)\n\t        x1 = self.W_x(skip_connection)\n\t        psi = self.relu(g1 + x1)\n", "        psi = self.psi(psi)\n\t        out = skip_connection * psi\n\t        return out\n\tclass Encoder(nn.Module):\n\t    def __init__(self, flag=True):\n\t        super(Encoder, self).__init__()\n\t        if flag:\n\t            self.e1_c1 = nn.Conv3d(in_channels=1, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n\t                                   padding_mode='zeros', bias=True)\n\t        else:\n", "            self.e1_c1 = nn.Conv3d(in_channels=2, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n\t                                   padding_mode='zeros', bias=True)\n\t        self.e1_c2 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\t        self.e1_c3 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\t        self.e2_c1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n\t        self.e2_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\t        self.e2_c3 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\t        self.e3_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n\t        self.e3_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\t        self.e3_c3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n", "        self.e4_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n\t        self.e4_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\t        self.e4_c3 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\t        self.e5_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n\t        self.e5_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\t        self.e5_c3 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\t        self.attehtion_block1 = MSA(basic_dims * 1, basic_dims * 1, basic_dims * 1)\n\t        self.attehtion_block2 = MSA(basic_dims * 2, basic_dims * 2, basic_dims * 2)\n\t        self.attehtion_block3 = MSA(basic_dims * 4, basic_dims * 4, basic_dims * 4)\n\t        self.attehtion_block4 = MSA(basic_dims * 8, basic_dims * 8, basic_dims * 8)\n", "        self.attehtion_block5 = MSA(basic_dims * 16, basic_dims * 16, basic_dims * 16)\n\t        self.Downsample1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n\t        self.Downsample2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n\t        self.Downsample3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n\t        self.Downsample4 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n\t        self.inforconv = general_conv3d_prenorm(1, basic_dims, pad_type='zeros')\n\t    def forward(self, x, infor):\n\t        x1 = self.e1_c1(x)\n\t        x1 = x1 + self.e1_c3(self.e1_c2(x1))\n\t        infor1 = self.inforconv(infor)\n", "        x1 = self.attehtion_block1(infor1, x1)\n\t        x2 = self.e2_c1(x1)\n\t        x2 = x2 + self.e2_c3(self.e2_c2(x2))\n\t        infor2 = self.Downsample1(infor1)\n\t        x2 = self.attehtion_block2(infor2, x2)\n\t        x3 = self.e3_c1(x2)\n\t        x3 = x3 + self.e3_c3(self.e3_c2(x3))\n\t        infor3 = self.Downsample2(infor2)\n\t        x3 = self.attehtion_block3(infor3, x3)\n\t        x4 = self.e4_c1(x3)\n", "        x4 = x4 + self.e4_c3(self.e4_c2(x4))\n\t        infor4 = self.Downsample3(infor3)\n\t        x4 = self.attehtion_block4(infor4, x4)\n\t        x5 = self.e5_c1(x4)\n\t        x5 = x5 + self.e5_c3(self.e5_c2(x5))\n\t        infor5 = self.Downsample4(infor4)\n\t        x5 = self.attehtion_block5(infor5, x5)\n\t        return x1, x2, x3, x4, x5\n\tclass Decoder_sep(nn.Module):\n\t    def __init__(self, num_cls=1):\n", "        super(Decoder_sep, self).__init__()\n\t        self.d4 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n\t        self.d4_c1 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n\t        self.d4_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n\t        self.d4_out = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, k_size=1, padding=0, pad_type='zeros')\n\t        self.d3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n\t        self.d3_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n\t        self.d3_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n\t        self.d3_out = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, k_size=1, padding=0, pad_type='zeros')\n\t        self.d2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n", "        self.d2_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n\t        self.d2_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n\t        self.d2_out = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, k_size=1, padding=0, pad_type='zeros')\n\t        self.d1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n\t        self.d1_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n\t        self.d1_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n\t        self.d1_out = general_conv3d_prenorm(basic_dims, basic_dims, k_size=1, padding=0, pad_type='zeros')\n\t        self.seg_layer = nn.Conv3d(in_channels=basic_dims, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                   bias=True)\n\t        self.softmax = nn.Softmax(dim=1)\n", "    def forward(self, x1, x2, x3, x4, x5):\n\t        de_x5 = self.d4_c1(self.d4(x5))\n\t        cat_x4 = torch.cat((de_x5, x4), dim=1)\n\t        de_x4 = self.d4_out(self.d4_c2(cat_x4))\n\t        de_x4 = self.d3_c1(self.d3(de_x4))\n\t        cat_x3 = torch.cat((de_x4, x3), dim=1)\n\t        de_x3 = self.d3_out(self.d3_c2(cat_x3))\n\t        de_x3 = self.d2_c1(self.d2(de_x3))\n\t        cat_x2 = torch.cat((de_x3, x2), dim=1)\n\t        de_x2 = self.d2_out(self.d2_c2(cat_x2))\n", "        de_x2 = self.d1_c1(self.d1(de_x2))\n\t        cat_x1 = torch.cat((de_x2, x1), dim=1)\n\t        de_x1 = self.d1_out(self.d1_c2(cat_x1))\n\t        logits = self.seg_layer(de_x1)\n\t        # pred = self.softmax(logits)\n\t        return torch.sigmoid(logits)\n\tclass Downsample(nn.Module):\n\t    def __init__(self):\n\t        super(Downsample, self).__init__()\n\t        self.inforconv = general_conv3d_prenorm(1, basic_dims, pad_type='zeros')\n", "        self.Downsample1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n\t        self.Downsample2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n\t        self.Downsample3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n\t        self.Downsample4 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n\t    def forward(self, x):\n\t        x1 = self.inforconv(x)\n\t        x2 = self.Downsample1(x1)\n\t        x3 = self.Downsample2(x2)\n\t        x4 = self.Downsample3(x3)\n\t        x5 = self.Downsample4(x4)\n", "        return x1, x2, x3, x4, x5\n\tclass att(nn.Module):\n\t    def __init__(self, in_channel=8):\n\t        super(att, self).__init__()\n\t        self.weight_layer = nn.Sequential(\n\t                            nn.Conv3d(4*in_channel, 128, 1, padding=0, bias=True),\n\t                            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\t                            nn.Conv3d(128, 1, 1, padding=0, bias=True))\n\t        self.sigmoid = nn.Sigmoid()\n\t    def forward(self, infor, all):\n", "        B, C, H, W, Z = infor.size()\n\t        infor_avg = torch.mean(infor, dim=(2, 3, 4), keepdim=False)\n\t        all_avg = torch.mean(all, dim=(2, 3, 4), keepdim=False)\n\t        infor_avg = infor_avg.view(B, C, 1, 1, 1)\n\t        all_avg = all_avg.view(B, 3 * C, 1, 1, 1)\n\t        infor_avg = torch.cat((infor_avg, all_avg), dim=1)\n\t        weight = torch.reshape(self.weight_layer(infor_avg), (B, 1))\n\t        weight = self.sigmoid(weight).view(B, 1, 1, 1, 1)\n\t        region_feat = infor * weight\n\t        return region_feat\n", "class MTG(nn.Module):\n\t    def __init__(self, in_channel=8):\n\t        super(MTG, self).__init__()\n\t        self.att_adc = att(in_channel)\n\t        self.att_t2 = att(in_channel)\n\t        self.conv_layer = general_conv3d_prenorm(in_channel, in_channel, pad_type='zeros')\n\t        self.fusion_prenorm = fusion_prenorm(in_channel)\n\t    def forward(self, DCE, ADC, T2, InforDCE, InforADC, InforT2):\n\t        newDCE = DCE * InforDCE\n\t        newADC = ADC * InforADC\n", "        newT2 = T2 * InforT2\n\t        all = torch.cat((newDCE, newADC, newT2), dim=1)\n\t        trust_ADC = self.att_adc(newADC, all)\n\t        trust_T2 = self.att_t2(newT2, all)\n\t        weight = self.fusion_prenorm(all) + trust_ADC + trust_T2\n\t        x = self.conv_layer(weight)\n\t        return x\n\tclass MoSID(nn.Module):\n\t    def __init__(self, num_cls=1):\n\t        super(MoSID, self).__init__()\n", "        self.DCE_encoder = Encoder(flag=False)\n\t        self.ADC_encoder = Encoder(flag=True)\n\t        self.T2_encoder = Encoder(flag=True)\n\t        self.decoder_sep = Decoder_sep(num_cls=num_cls)\n\t        self.downsample1 = Downsample()\n\t        self.downsample2 = Downsample()\n\t        self.downsample3 = Downsample()\n\t        self.MTG1 = MTG(in_channel=basic_dims * 1)\n\t        self.MTG2 = MTG(in_channel=basic_dims * 2)\n\t        self.MTG3 = MTG(in_channel=basic_dims * 4)\n", "        self.MTG4 = MTG(in_channel=basic_dims * 8)\n\t        self.MTG5 = MTG(in_channel=basic_dims * 16)\n\t        self.is_training = True\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv3d):\n\t                torch.nn.init.kaiming_normal_(m.weight)\n\t    def forward(self, DCE, Sub, ADC, T2, InforDCE, InforADC, InforT2):\n\t        input1 = torch.cat((DCE, Sub), dim=1)\n\t        DCE_x1, DCE_x2, DCE_x3, DCE_x4, DCE_x5 = self.DCE_encoder(input1, InforDCE)\n\t        ADC_x1, ADC_x2, ADC_x3, ADC_x4, ADC_x5 = self.ADC_encoder(ADC, InforADC)\n", "        T2_x1, T2_x2, T2_x3, T2_x4, T2_x5 = self.T2_encoder(T2, InforT2)\n\t        InforDCE_x1, InforDCE_x2, InforDCE_x3, InforDCE_x4, InforDCE_x5 = self.downsample1(InforDCE)\n\t        InforADC_x1, InforADC_x2, InforADC_x3, InforADC_x4, InforADC_x5 = self.downsample2(InforADC)\n\t        InforT2_x1, InforT2_x2, InforT2_x3, InforT2_x4, InforT2_x5 = self.downsample3(InforT2)\n\t        x1 = self.MTG1(DCE_x1, ADC_x1, T2_x1, InforDCE_x1, InforADC_x1, InforT2_x1)\n\t        x2 = self.MTG2(DCE_x2, ADC_x2, T2_x2, InforDCE_x2, InforADC_x2, InforT2_x2)\n\t        x3 = self.MTG3(DCE_x3, ADC_x3, T2_x3, InforDCE_x3, InforADC_x3, InforT2_x3)\n\t        x4 = self.MTG4(DCE_x4, ADC_x4, T2_x4, InforDCE_x4, InforADC_x4, InforT2_x4)\n\t        x5 = self.MTG5(DCE_x5, ADC_x5, T2_x5, InforDCE_x5, InforADC_x5, InforT2_x5)\n\t        fuse_pred = self.decoder_sep(x1, x2, x3, x4, x5)\n", "        return fuse_pred\n\tif __name__ == '__main__':\n\t    a = torch.zeros([1, 1, 32, 128, 128])\n\t    b = torch.zeros([1, 1, 32, 128, 128])\n\t    c = torch.zeros([1, 1, 32, 128, 128])\n\t    d = torch.zeros([1, 1, 32, 128, 128])\n\t    e = torch.zeros([1, 1, 32, 128, 128])\n\t    f = torch.zeros([1, 1, 32, 128, 128])\n\t    g = torch.zeros([1, 1, 32, 128, 128])\n\t    x = torch.cat((a, b, c, d, e, f, g), dim=1)\n", "    model = MoSID(num_cls=1)\n\t    out = model(a, b, c, d, e, f, g)\n\t    print(out[1].shape)\n"]}
{"filename": "Step3-Tumor-Segmentation/Model/__init__.py", "chunked_list": []}
{"filename": "Step1-Image-Synthesis/train.py", "chunked_list": ["import torch\n\timport numpy as np\n\timport torch.optim as optim\n\tfrom options.Options import Options_x\n\tfrom dataset.dataset_lits_train import Lits_DataSet\n\tfrom dataset.dataset_lits_val import Val_DataSet\n\tfrom Model.runet import RUnet\n\tfrom torch.utils.data import DataLoader\n\tfrom setting.common import adjust_learning_rate\n\tfrom setting import logger,util\n", "import torch.nn as nn\n\tfrom setting.metrics import LossAverage\n\timport os\n\timport time\n\tfrom test import test_all\n\tfrom collections import OrderedDict\n\tdef train(train_dataloader, epoch):\n\t    since = time.time()\n\t    Loss = LossAverage()\n\t    model.train()\n", "    for i, (DCE,ADC, gt) in enumerate(train_dataloader):  # inner loop within one epoch\n\t        b, c, l, w, e = ADC.shape[0], ADC.shape[1], ADC.shape[2], ADC.shape[3], ADC.shape[4]\n\t        ADC = ADC.view(-1, 1, l, w, e).to(device)\n\t        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\t        pred = model(DCE)\n\t        loss = nn.L1Loss()(pred, ADC)\n\t        optimizer.zero_grad()\n\t        loss.backward()\n\t        optimizer.step()\n\t        adjust_learning_rate(optimizer, epoch, opt)\n", "        Loss.update(loss.item(), ADC.size(0))\n\t    time_elapsed = time.time() - since\n\t    print(\"=======Train Epoch:{}======Learning_rate:{}======Train complete in {:.0f}m {:.0f}s=======\".format(epoch, optimizer.param_groups[0]['lr'], time_elapsed // 60, time_elapsed % 60))\n\t    return OrderedDict({'Loss': Loss.avg})\n\tdef val(val_dataloader, epoch):\n\t    since = time.time()\n\t    Loss = LossAverage()\n\t    model.eval()\n\t    for i, (DCE,ADC, gt) in enumerate(val_dataloader):  # inner loop within one epoch\n\t        b, c, l, w, e = ADC.shape[0], ADC.shape[1], ADC.shape[2], ADC.shape[3], ADC.shape[4]\n", "        ADC = ADC.view(-1, 1, l, w, e).to(device)\n\t        DCE = DCE.view(-1, 1, l, w, e).to(device)\n\t        pred = model(DCE)\n\t        loss = nn.L1Loss()(pred, ADC)\n\t        Loss.update(loss.item(), ADC.size(0))\n\t    time_elapsed = time.time() - since\n\t    return OrderedDict({'Loss': Loss.avg})\n\tif __name__ == '__main__':\n\t    opt = Options_x().parse()   # get training options\n\t    device = torch.device('cuda:'+opt.gpu_ids if torch.cuda.is_available() else \"cpu\")\n", "    print(\"using {} device.\".format(device))\n\t    model = RUnet(num_cls=1).to(device)\n\t    save_path = opt.checkpoints_dir\n\t    save_result_path = os.path.join(save_path, opt.task_name)\n\t    util.mkdir(save_result_path)\n\t    optimizer = optim.Adam(model.parameters(), lr=opt.lr, weight_decay=1e-5)\n\t    model_save_path = os.path.join(save_result_path, 'model')\n\t    util.mkdir(model_save_path)\n\t    logger_save_path = os.path.join(save_result_path, 'logger')\n\t    util.mkdir(logger_save_path)\n", "    log_train = logger.Train_Logger(logger_save_path, \"train_log\")\n\t    log_val = logger.Val_Logger(logger_save_path, \"val_log\")\n\t    train_dataset = Lits_DataSet(opt.datapath, opt.patch_size)\n\t    val_dataset = Val_DataSet(opt.datapath, opt.patch_size)\n\t    train_dataloader = DataLoader(dataset=train_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n\t    val_dataloader = DataLoader(dataset=val_dataset, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n\t    types = ['train','val']\n\t    val_loss = 99\n\t    best_epoch = 0\n\t    for epoch in range(opt.epoch):\n", "        epoch = epoch + 1\n\t        for type in types:\n\t            if type == 'train':\n\t                train_log = train(train_dataloader, epoch)\n\t                log_train.update(epoch, train_log)\n\t            elif type == 'val':\n\t                val_log = val(val_dataloader, epoch)\n\t                log_val.update(epoch, val_log)\n\t                if val_log['DICE_Loss'] < val_loss:\n\t                    best_epoch = epoch\n", "                    val_loss = val_log['DICE_Loss']\n\t                    state = {'model': model.state_dict(), 'epoch': best_epoch}\n\t                    torch.save(state, os.path.join(model_save_path, 'best_model.pth'))\n\t        state = {'model': model.state_dict(), 'epoch': epoch}\n\t        torch.save(state, os.path.join(model_save_path, 'latest_model.pth'))\n\t        if epoch % opt.model_save_fre == 0:\n\t            torch.save(state, os.path.join(model_save_path, 'model_'+np.str(epoch)+'.pth'))\n\t        torch.cuda.empty_cache()\n\t    test_all('best_model.pth')\n"]}
{"filename": "Step1-Image-Synthesis/test.py", "chunked_list": ["import torch\n\timport gc\n\timport numpy as np\n\timport SimpleITK as sitk\n\tfrom options.Options import Options_x\n\tfrom tqdm import tqdm\n\tfrom Model.runet import RUnet\n\tfrom torch.utils.data import DataLoader\n\tfrom setting import logger,util\n\timport os\n", "from dataset.dataset_lits_test import Test_all_Datasets, Recompone_tool\n\tdef load(file):\n\t    itkimage = sitk.ReadImage(file)\n\t    image = sitk.GetArrayFromImage(itkimage)\n\t    return image\n\tdef test_all(model_name='model_200.pth'):\n\t    opt = Options_x().parse()  # get training options\n\t    device = torch.device('cuda:'+opt.gpu_ids if torch.cuda.is_available() else \"cpu\")\n\t    print(\"using {} device.\".format(device))\n\t    model = RUnet(num_cls=1).to(device)\n", "    ckpt = torch.load(opt.checkpoints_dir + '/' + opt.task_name + '/model/' + model_name, map_location=device)\n\t    model.load_state_dict(ckpt['model'])\n\t    save_result_path = os.path.join(opt.checkpoints_dir, opt.task_name, 'test_all_result')\n\t    util.mkdir(save_result_path)\n\t    model.eval()\n\t    log_test = logger.Test_Logger(save_result_path, \"results\")\n\t    cut_param = {'patch_s': 192, 'patch_h': 192, 'patch_w': 320,\n\t                 'stride_s': 192, 'stride_h': 192, 'stride_w': 192}\n\t    datasets = Test_all_Datasets(opt.datapath, cut_param)\n\t    for img_dataset, original_shape, new_shape,  file_idx in datasets:\n", "        save_tool = Recompone_tool(original_shape, new_shape, cut_param)\n\t        dataloader = DataLoader(img_dataset, batch_size=opt.test_batch, num_workers=opt.num_threads, shuffle=False)\n\t        with torch.no_grad():\n\t            for DCE in tqdm(dataloader):\n\t                DCE= DCE.to(device)\n\t                DCE = DCE.unsqueeze(1).type(torch.float32)\n\t                pred = model(DCE)\n\t                output = pred.type(torch.float32)\n\t                save_tool.add_result(output.detach().cpu())\n\t        recon = save_tool.recompone_overlap()\n", "        Pred = sitk.GetImageFromArray(np.array(recon))\n\t        aaaaaa = sitk.ReadImage(os.path.join(opt.datapath,file_idx,'ADC.nii.gz'))\n\t        Pred.SetSpacing(aaaaaa.GetSpacing())\n\t        Pred.SetDirection(aaaaaa.GetDirection())\n\t        Pred.SetOrigin(aaaaaa.GetOrigin())\n\t        sitk.WriteImage(Pred, os.path.join(save_result_path, file_idx+'.nii.gz'))\n\t        del pred, recon, Pred, save_tool\n\t        gc.collect()\n\t        torch.cuda.empty_cache()\n\tif __name__ == '__main__':\n", "    test_all('best_model.pth')\n"]}
{"filename": "Step1-Image-Synthesis/setting/weights_init.py", "chunked_list": ["from torch.nn import init\n\tdef weights_init_normal(m):\n\t    classname = m.__class__.__name__\n\t    #print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.normal(m.weight.data, 0.0, 0.02)\n\t    elif classname.find('Linear') != -1:\n\t        init.normal(m.weight.data, 0.0, 0.02)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef weights_init_xavier(m):\n\t    classname = m.__class__.__name__\n\t    #print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.xavier_normal(m.weight.data, gain=1)\n\t    elif classname.find('Linear') != -1:\n\t        init.xavier_normal(m.weight.data, gain=1)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef weights_init_kaiming(m):\n\t    classname = m.__class__.__name__\n\t    #print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n\t    elif classname.find('Linear') != -1:\n\t        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef weights_init_orthogonal(m):\n\t    classname = m.__class__.__name__\n\t    #print(classname)\n\t    if classname.find('Conv') != -1:\n\t        init.orthogonal(m.weight.data, gain=1)\n\t    elif classname.find('Linear') != -1:\n\t        init.orthogonal(m.weight.data, gain=1)\n\t    elif classname.find('BatchNorm') != -1:\n\t        init.normal(m.weight.data, 1.0, 0.02)\n", "        init.constant(m.bias.data, 0.0)\n\tdef init_weights(net, init_type='normal'):\n\t    #print('initialization method [%s]' % init_type)\n\t    if init_type == 'normal':\n\t        net.apply(weights_init_normal)\n\t    elif init_type == 'xavier':\n\t        net.apply(weights_init_xavier)\n\t    elif init_type == 'kaiming':\n\t        net.apply(weights_init_kaiming)\n\t    elif init_type == 'orthogonal':\n", "        net.apply(weights_init_orthogonal)\n\t    else:\n\t        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)"]}
{"filename": "Step1-Image-Synthesis/setting/metrics.py", "chunked_list": ["import torch.nn as nn\n\timport torch.nn.functional as F\n\timport torch\n\t#from medpy.metric.binary import dc,asd,hd,sensitivity, precision, ravd\n\timport numpy as np\n\timport sys\n\tfrom scipy.ndimage import morphology\n\tsys.dont_write_bytecode = True  # don't generate the binray python file .pyc\n\tclass LossAverage(object):\n\t    \"\"\"Computes and stores the average and current value for calculate average loss\"\"\"\n", "    def __init__(self):\n\t        self.reset()\n\t    def reset(self):\n\t        self.val = 0\n\t        self.avg = 0\n\t        self.sum = 0\n\t        self.count = 0\n\t    def update(self, val, n):\n\t        self.val = val\n\t        self.sum += val * n\n", "        self.count += n\n\t        self.avg = round(self.sum / self.count, 4)\n\t        # print(self.val)\n\tclass DiceLoss(nn.Module):\n\t    \"\"\"\n\t    define the dice loss\n\t    \"\"\"\n\t    def __init__(self):\n\t        super(DiceLoss, self).__init__()\n\t    def forward(self, input, target):\n", "        smooth = 1.\n\t        iflat = input.contiguous().view(-1)\n\t        tflat = target.contiguous().view(-1)\n\t        intersection = (iflat * tflat).sum()\n\t        A_sum = torch.sum(iflat * iflat)\n\t        B_sum = torch.sum(tflat * tflat)\n\t        return 1-((2. * intersection + smooth) / (A_sum + B_sum + smooth))\n\t\"\"\"dice coefficient\"\"\"\n\tdef dice(pre, gt, tid=1):\n\t    pre=pre==tid   #make it boolean\n", "    gt=gt==tid     #make it boolean\n\t    pre=np.asarray(pre).astype(np.bool)\n\t    gt=np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    dsc=(2. * intersection.sum() + 1e-07) / (pre.sum() + gt.sum() + 1e-07)\n\t    return dsc\n\t\"\"\"positive predictive value\"\"\"\n\tdef pospreval(pre,gt,tid=1):\n", "    pre=pre==tid #make it boolean\n\t    gt=gt==tid   #make it boolean\n\t    pre=np.asarray(pre).astype(np.bool)\n\t    gt=np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    ppv=(1.0*intersection.sum() + 1e-07) / (pre.sum()+1e-07)\n\t    return ppv\n\t\"\"\"sensitivity\"\"\"\n", "def sensitivity(pre,gt,tid=1):\n\t    pre=pre==tid #make it boolean\n\t    gt=gt==tid   #make it boolean\n\t    pre=np.asarray(pre).astype(np.bool)\n\t    gt=np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    sen=(1.0*intersection.sum()+1e-07) / (gt.sum()+1e-07)\n\t    return sen\n", "\"\"\"specificity\"\"\"\n\tdef specificity(pre,gt):\n\t    pre=pre==0 #make it boolean\n\t    gt=gt==0   #make it boolean\n\t    pre=np.asarray(pre).astype(np.bool)\n\t    gt=np.asarray(gt).astype(np.bool)\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    intersection = np.logical_and(pre, gt)\n\t    spe=(1.0*intersection.sum()+1e-07) / (gt.sum()+1e-07)\n", "    return spe\n\t\"\"\"average surface distance\"\"\"#å¦‚ä½•è®¡ç®—ASDç›¸å…³çš„æŒ‡æ ‡ã€‚\n\tdef surfd(pre, gt, tid=1, sampling=1, connectivity=1):\n\t    pre=pre==tid   #make it boolean\n\t    gt=gt==tid     #make it boolean\n\t    if pre.shape != gt.shape:\n\t        raise ValueError(\"Shape mismatch: prediction and ground truth must have the same shape.\")\n\t    input_1 = np.atleast_1d(pre.astype(np.bool))\n\t    input_2 = np.atleast_1d(gt.astype(np.bool))\n\t    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n", "    S = np.logical_xor(input_1,morphology.binary_erosion(input_1, conn))\n\t    Sprime = np.logical_xor(input_2,morphology.binary_erosion(input_2, conn))\n\t    dta = morphology.distance_transform_edt(~S,sampling)\n\t    dtb = morphology.distance_transform_edt(~Sprime,sampling)\n\t    sds = np.concatenate([np.ravel(dta[Sprime!=0]), np.ravel(dtb[S!=0])])\n\t    return sds\n\tdef asd(pre, gt, tid=1, sampling=1, connectivity=1):\n\t    sds = surfd(pre, gt, tid=tid, sampling=sampling, connectivity=connectivity)\n\t    dis = sds.mean()\n\t    return dis\n", "def seg_metric(pre,gt):\n\t    mask = (pre>0.5)\n\t    gt = (gt>0.5)\n\t    ASD = asd(mask, gt)\n\t    DSC = dice(mask, gt)\n\t    SEN = sensitivity(mask,gt)\n\t    PPV = pospreval(mask,gt)\n\t    return DSC,PPV,SEN,ASD\n"]}
{"filename": "Step1-Image-Synthesis/setting/logger.py", "chunked_list": ["import pandas as pd\n\tfrom torch.utils.tensorboard import SummaryWriter\n\timport matplotlib.pyplot as plt\n\timport torch, random\n\timport numpy as np\n\tfrom collections import OrderedDict\n\tclass Train_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n", "        self.save_path = save_path\n\t        self.save_name = save_name\n\t    def update(self, epoch, train_log):\n\t        item = OrderedDict({'epoch': epoch})\n\t        item.update(train_log)\n\t        print(\"\\033[0;33mTrain:\\033[0m\", train_log)\n\t        self.update_csv(item)\n\t        self.update_tensorboard(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n", "        if self.log is not None:\n\t            self.log = self.log.append(tmp, ignore_index=True)\n\t        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\t    def update_tensorboard(self, item):\n\t        if self.summary is None:\n\t            self.summary = SummaryWriter('%s/' % self.save_path)\n\t        epoch = item['epoch']\n\t        for key, value in item.items():\n", "            if key != 'epoch': self.summary.add_scalar(key, value, epoch)\n\tclass Val_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n\t        self.summary = None\n\t        self.save_path = save_path\n\t        self.save_name = save_name\n\t    def update(self, epoch, val_log):\n\t        item = OrderedDict({'epoch': epoch})\n\t        item.update(val_log)\n", "        # item = dict_round(item,4) # ä¿ç•™å°æ•°ç‚¹åŽå››ä½æœ‰æ•ˆæ•°å­—\n\t        print(\"\\033[0;33mValidate:\\033[0m\", val_log)\n\t        self.update_csv(item)\n\t        self.update_tensorboard(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n\t        if self.log is not None:\n\t            self.log = self.log.append(tmp, ignore_index=True)\n\t        else:\n\t            self.log = tmp\n", "        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\t    def update_tensorboard(self, item):\n\t        if self.summary is None:\n\t            self.summary = SummaryWriter('%s/' % self.save_path)\n\t        epoch = item['epoch']\n\t        for key, value in item.items():\n\t            if key != 'epoch': self.summary.add_scalar(key, value, epoch)\n\tclass Test_Logger():\n\t    def __init__(self, save_path, save_name):\n\t        self.log = None\n", "        self.summary = None\n\t        self.save_path = save_path\n\t        self.save_name = save_name\n\t    def update(self, name, log):\n\t        item = OrderedDict({'img_name': name})\n\t        item.update(log)\n\t        print(\"\\033[0;33mTest:\\033[0m\", log)\n\t        self.update_csv(item)\n\t    def update_csv(self, item):\n\t        tmp = pd.DataFrame(item, index=[0])\n", "        if self.log is not None:\n\t            self.log = self.log.append(tmp, ignore_index=True)\n\t        else:\n\t            self.log = tmp\n\t        self.log.to_csv('%s/%s.csv' % (self.save_path, self.save_name), index=False)\n\tdef setpu_seed(seed):\n\t    torch.manual_seed(seed)\n\t    torch.cuda.manual_seed_all(seed)\n\t    np.random.seed(seed)\n\t    torch.backends.cudnn.deterministic = True\n", "    random.seed(seed)\n\tdef dict_round(dic, num):\n\t    for key, value in dic.items():\n\t        dic[key] = round(value, num)\n\t    return dic\n"]}
{"filename": "Step1-Image-Synthesis/setting/util.py", "chunked_list": ["\"\"\"This module contains simple helper functions \"\"\"\n\tfrom __future__ import print_function\n\timport torch\n\timport numpy as np\n\tfrom PIL import Image\n\timport os\n\tdef tensor2im(input_image, imtype=np.uint8):\n\t    \"\"\"\"Converts a Tensor array into a numpy image array.\n\t    Parameters:\n\t        input_image (tensor) --  the input image tensor array\n", "        imtype (type)        --  the desired type of the converted numpy array\n\t    \"\"\"\n\t    if not isinstance(input_image, np.ndarray):\n\t        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n\t            image_tensor = input_image.data\n\t        else:\n\t            return input_image\n\t        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n\t        if image_numpy.shape[0] == 1:  # grayscale to RGB\n\t            image_numpy = np.tile(image_numpy, (3, 1, 1))\n", "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n\t    else:  # if it is a numpy array, do nothing\n\t        image_numpy = input_image\n\t    return image_numpy.astype(imtype)\n\tdef diagnose_network(net, name='network'):\n\t    \"\"\"Calculate and print the mean of average absolute(gradients)\n\t    Parameters:\n\t        net (torch network) -- Torch network\n\t        name (str) -- the name of the network\n\t    \"\"\"\n", "    mean = 0.0\n\t    count = 0\n\t    for param in net.parameters():\n\t        if param.grad is not None:\n\t            mean += torch.mean(torch.abs(param.grad.data))\n\t            count += 1\n\t    if count > 0:\n\t        mean = mean / count\n\t    print(name)\n\t    print(mean)\n", "def save_image(image_numpy, image_path, aspect_ratio=1.0):\n\t    \"\"\"Save a numpy image to the disk\n\t    Parameters:\n\t        image_numpy (numpy array) -- input numpy array\n\t        image_path (str)          -- the path of the image\n\t    \"\"\"\n\t    image_pil = Image.fromarray(image_numpy)\n\t    h, w, _ = image_numpy.shape\n\t    if aspect_ratio > 1.0:\n\t        image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)\n", "    if aspect_ratio < 1.0:\n\t        image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)\n\t    image_pil.save(image_path)\n\tdef print_numpy(x, val=True, shp=False):\n\t    \"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\t    Parameters:\n\t        val (bool) -- if print the values of the numpy array\n\t        shp (bool) -- if print the shape of the numpy array\n\t    \"\"\"\n\t    x = x.astype(np.float64)\n", "    if shp:\n\t        print('shape,', x.shape)\n\t    if val:\n\t        x = x.flatten()\n\t        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n\t            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))\n\tdef mkdirs(paths):\n\t    \"\"\"create empty directories if they don't exist\n\t    Parameters:\n\t        paths (str list) -- a list of directory paths\n", "    \"\"\"\n\t    if isinstance(paths, list) and not isinstance(paths, str):\n\t        for path in paths:\n\t            mkdir(path)\n\t    else:\n\t        mkdir(paths)\n\tdef mkdir(path):\n\t    \"\"\"create a single empty directory if it didn't exist\n\t    Parameters:\n\t        path (str) -- a single directory path\n", "    \"\"\"\n\t    if not os.path.exists(path):\n\t        os.makedirs(path)\n"]}
{"filename": "Step1-Image-Synthesis/setting/common.py", "chunked_list": ["import SimpleITK as sitk\n\timport numpy as np\n\t#import pytorch_ssim\n\t#from skimage.metrics import structural_similarity\n\timport math\n\tfrom torch.autograd import Variable\n\tfrom scipy import ndimage\n\timport torch, random\n\tdef normalization(img):\n\t    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n", "    return out\n\tdef normalization_test (img):\n\t    out=(img - np.min(img))/(np.max(img) - np.min(img) + 0.000001 )\n\t    return out, np.max(img), np.min(img)\n\tdef center_crop_3d(img, label, slice_num=16):\n\t    if img.shape[0] < slice_num:\n\t        return None\n\t    left_x = img.shape[0]//2 - slice_num//2\n\t    right_x = img.shape[0]//2 + slice_num//2\n\t    crop_img = img[left_x:right_x]\n", "    crop_label = label[left_x:right_x]\n\t    return crop_img, crop_label\n\tdef load_file_name_list(file_path):\n\t    file_name_list = []\n\t    with open(file_path, 'r') as file_to_read:\n\t        while True:\n\t            lines = file_to_read.readline().strip()\n\t            if not lines:\n\t                break\n\t                pass\n", "            file_name_list.append(lines)\n\t            pass\n\t    return file_name_list\n\tdef MaskContour(image, position='xy', line=1):\n\t    itkimage = sitk.GetImageFromArray(image)\n\t    if position == 'xy':\n\t        erode_m = [line, line, 0]\n\t    elif position == 'yz':\n\t        erode_m = [0, line, line]\n\t    elif position == 'zx':\n", "        erode_m = [line, 0, line]\n\t    else:\n\t        erode_m = [line, line, 0]\n\t    mask = sitk.GetArrayFromImage(sitk.BinaryErode(itkimage, erode_m))\n\t    boundary = image - mask\n\t    out = sitk.GetImageFromArray(boundary)\n\t    return out\n\tdef print_network(net):\n\t    num_params = 0\n\t    for param in net.parameters():\n", "        num_params += param.numel()\n\t    print(net)\n\t    print('Total number of parameters: %d' % num_params)\n\tdef adjust_learning_rate(optimizer, epoch, opt):\n\t    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n\t    lr = opt.lr * (0.5 ** (epoch // opt.step))\n\t    for param_group in optimizer.param_groups:\n\t        param_group['lr'] = lr\n\tdef adjust_learning_rate_V2(optimizer, lr):\n\t    \"\"\"Sets the learning rate to a fixed number\"\"\"\n", "    for param_group in optimizer.param_groups:\n\t        param_group['lr'] = lr\n\tdef get_mse(img1, img2):\n\t    mse = np.mean( (img1 - img2) ** 2 )\n\t    return mse\n\tdef get_psnr(img1, img2):\n\t    mse = np.mean( (img1 - img2) ** 2 )\n\t    if mse == 0:\n\t        return 100\n\t    PIXEL_MAX = 1.0\n", "    return 10 * math.log10(PIXEL_MAX / math.sqrt(mse))\n\t'''\n\tdef get_ssim(img1,img2):\n\t    n=img1.shape[0]\n\t    out = 0\n\t    for i in range(n):\n\t        out+=structural_similarity(img1[i].squeeze(),img2[i].squeeze())\n\t    return out/n\n\t'''    \n\tdef save_result(low_dose, high_dose, output, i, epoch):\n", "    def save_img(img, name):\n\t        # img = SimpleITK.GetImageFromArray(img[0,0].cpu().detach().numpy())\n\t        img = sitk.GetImageFromArray(img)\n\t        sitk.WriteImage(img, 'result/image/'+name+'.nii.gz')\n\t    save_img(low_dose, 'low_dose_epoch_'+str(epoch) + \"_\" + str(i))\n\t    save_img(high_dose, 'high_dose_epoch_'+str(epoch) + \"_\" + str(i))\n\t    save_img(output, 'output_epoch_'+str(epoch) + \"_\" + str(i))\n\tdef de_normalization(img,max_x,min_x):\n\t    return img*(max_x - min_x) + min_x"]}
{"filename": "Step1-Image-Synthesis/options/BasicOptions.py", "chunked_list": ["import argparse\n\timport os\n\tfrom setting import util\n\timport torch\n\tclass BaseOptions():\n\t    \"\"\"This class defines options used during both training and test time.\n\t    It also implements several helper functions such as parsing, printing, and saving the options.\n\t    It also gathers additional options defined in <modify_commandline_options> functions in both dataset class and model class.\n\t    \"\"\"\n\t    def __init__(self):\n", "        \"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"\n\t        self.initialized = False\n\t    def initialize(self, parser):\n\t        \"\"\"Define the common options that are used in both training and test.\"\"\"\n\t        # basic parameters\n\t        parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n\t        parser.add_argument('--num_threads', default=2, type=int, help='# threads for loading data')\n\t        parser.add_argument('--batch_size', type=int, default=6, help='input train batch size')\n\t        parser.add_argument('--test_batch', type=int, default=16, help='input test batch size')\n\t        parser.add_argument('--epoch', type=int, default=500, help='number of epochs with the initial learning rate')\n", "        parser.add_argument('--step', type=int, default=50, help='number of epochs to adjust learning rate')\n\t        parser.add_argument('--datapath', default = r'/data', help='path of the raw data')\n\t        parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate of net for adam')\n\t        parser.add_argument('--model_save_fre', type=int, default=50, help='frequency of saving model')\n\t        parser.add_argument('--patch_size', type=int, default=(128, 160, 320), help='the size of crop patch')\n\t        parser.add_argument('--patch_stride', type=int, default=(8, 64, 64), help='the stride of patch')\n\t        parser.add_argument('--gpu_ids', type=str, default='1', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n\t        parser.add_argument('--task_name', type=str, default='Multi-parametric_adc', help='the current task name')\n\t        self.initialized = True\n\t        return parser\n", "    def gather_options(self):\n\t        \"\"\"Initialize our parser with basic options(only once).\n\t        Add additional model-specific and dataset-specific options.\n\t        These options are defined in the <modify_commandline_options> function\n\t        in model and dataset classes.\n\t        \"\"\"\n\t        if not self.initialized:  # check if it has been initialized\n\t            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t            parser = self.initialize(parser)\n\t        # get the basic options\n", "        opt, _ = parser.parse_known_args()\n\t        # save and return the parser\n\t        self.parser = parser\n\t        return parser.parse_args()\n\t    def print_options(self, opt):\n\t        \"\"\"Print and save options\n\t        It will print both current options and default values(if different).\n\t        It will save options into a text file / [checkpoints_dir] / opt.txt\n\t        \"\"\"\n\t        message = ''\n", "        message += '----------------- Options ---------------\\n'\n\t        for k, v in sorted(vars(opt).items()):\n\t            comment = ''\n\t            default = self.parser.get_default(k)\n\t            if v != default:\n\t                comment = '\\t[default: %s]' % str(default)\n\t            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n\t        message += '----------------- End -------------------'\n\t        print(message)\n\t        # save to the disk\n", "        expr_dir = os.path.join(opt.checkpoints_dir, 'model_parameter_list')\n\t        util.mkdirs(expr_dir)\n\t        file_name = os.path.join(expr_dir, '{train_opt.txt')\n\t        with open(file_name, 'wt') as opt_file:\n\t            opt_file.write(message)\n\t            opt_file.write('\\n')\n\t    def parse(self):\n\t        \"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"\n\t        opt = self.gather_options()\n\t        opt.isTrain = self.isTrain   # train or test\n", "        self.print_options(opt)\n\t        self.opt = opt\n\t        return self.opt\n"]}
{"filename": "Step1-Image-Synthesis/options/Options.py", "chunked_list": ["from options.BasicOptions import BaseOptions\n\tclass Options_x(BaseOptions):\n\t    \"\"\"This class includes training options.\n\t    It also includes shared options defined in BaseOptions.\n\t    \"\"\"\n\t    def initialize(self, parser):\n\t        parser = BaseOptions.initialize(self, parser)\n\t        # visdom and HTML visualization parameters\n\t        parser.add_argument('--name', type=str, default='Tumor_seg', help='name_of_the_project')\n\t        self.isTrain = True\n", "        return parser\n"]}
{"filename": "Step1-Image-Synthesis/dataset/dataset_lits_test.py", "chunked_list": ["import numpy as np\n\timport torch, os\n\tfrom torch.utils.data import Dataset, DataLoader\n\tfrom glob import glob\n\timport random\n\timport SimpleITK as sitk\n\tdef min_max_normalization(img):\n\t    out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t    return out\n\tdef normalization(img, lmin=1, rmax=None, dividend=None, quantile=None):\n", "    newimg = img.copy()\n\t    newimg = newimg.astype(np.float32)\n\t    if quantile is not None:\n\t        maxval = round(np.percentile(newimg, 100 - quantile))\n\t        minval = round(np.percentile(newimg, quantile))\n\t        newimg[newimg >= maxval] = maxval\n\t        newimg[newimg <= minval] = minval\n\t    if lmin is not None:\n\t        newimg[newimg < lmin] = lmin\n\t    if rmax is not None:\n", "        newimg[newimg > rmax] = rmax\n\t    minval = np.min(newimg)\n\t    if dividend is None:\n\t        maxval = np.max(newimg)\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t    else:\n\t        newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t    return newimg\n\tdef load(file):\n\t    itkimage = sitk.ReadImage(file)\n", "    image = sitk.GetArrayFromImage(itkimage)\n\t    return image\n\tdef random_crop_3d(adc, pos, sub, gt, crop_size):\n\t    cor_box = maskcor_extract_3d(gt)\n\t    random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], adc.shape[0] - crop_size[0])\n\t    random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], adc.shape[1] - crop_size[1])\n\t    random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], adc.shape[2] - crop_size[2])\n\t    if random_x_min > random_x_max:\n\t        random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n\t    if random_y_min > random_y_max:\n", "        random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n\t    if random_z_min > random_z_max:\n\t        random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n\t    # print(cor_box[0, 0], cor_box[0, 1],cor_box[1, 0], cor_box[1, 1],cor_box[2, 0], cor_box[2, 1])\n\t    # print(random_x_min, random_x_max,random_y_min, random_y_max,random_z_min, random_z_max)\n\t    x_random = random.randint(random_x_min, random_x_max)\n\t    y_random = random.randint(random_y_min, random_y_max)\n\t    z_random = random.randint(random_z_min, random_z_max)\n\t    adc_patch = adc[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                z_random:z_random + crop_size[2]]\n", "    pos_patch = pos[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                z_random:z_random + crop_size[2]]\n\t    sub_patch = sub[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                z_random:z_random + crop_size[2]]\n\t    gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t               z_random:z_random + crop_size[2]]\n\t    return adc_patch, pos_patch, sub_patch, gt_patch\n\tdef maskcor_extract_3d(mask, padding=(5, 5, 5)):\n\t    # mask_s = mask.shape\n\t    p = np.where(mask > 0)\n", "    a = np.zeros([3, 2], dtype=np.int)\n\t    for i in range(3):\n\t        s = p[i].min()\n\t        e = p[i].max() + 1\n\t        ss = s - padding[i]\n\t        ee = e + padding[i]\n\t        if ss < 0:\n\t            ss = 0\n\t        if ee > mask.shape[i]:\n\t            ee = mask.shape[i]\n", "        a[i, 0] = ss\n\t        a[i, 1] = ee\n\t    return a\n\tclass Img_DataSet(Dataset):\n\t    def __init__(self, adc, cut_param):\n\t        self.adc = adc\n\t        self.ori_shape = self.adc.shape\n\t        self.cut_param = cut_param\n\t        self.adc = self.padding_img(self.adc, self.cut_param)\n\t        self.adc = self.extract_ordered_overlap(self.adc, self.cut_param)\n", "        self.new_shape = self.adc.shape\n\t    def __getitem__(self, index):\n\t        adc = self.adc[index]\n\t        return torch.from_numpy(adc)\n\t    def __len__(self):\n\t        return len(self.adc)\n\t    def padding_img(self, img, C):\n\t        assert (len(img.shape) == 3)  # 3D array\n\t        img_s, img_h, img_w = img.shape\n\t        leftover_s = (img_s - C['patch_s']) % C['stride_s']\n", "        leftover_h = (img_h - C['patch_h']) % C['stride_h']\n\t        leftover_w = (img_w - C['patch_w']) % C['stride_w']\n\t        if (leftover_s != 0):\n\t            s = img_s + (C['stride_s'] - leftover_s)\n\t        else:\n\t            s = img_s\n\t        if (leftover_h != 0):\n\t            h = img_h + (C['stride_h'] - leftover_h)\n\t        else:\n\t            h = img_h\n", "        if (leftover_w != 0):\n\t            w = img_w + (C['stride_w'] - leftover_w)\n\t        else:\n\t            w = img_w\n\t        tmp_full_imgs = np.zeros((s, h, w))\n\t        tmp_full_imgs[:img_s, :img_h, 0:img_w] = img\n\t        # print(\"Padded images shape: \" + str(tmp_full_imgs.shape))\n\t        return tmp_full_imgs\n\t    # Divide all the full_imgs in pacthes\n\t    def extract_ordered_overlap(self, img, C):\n", "        assert (len(img.shape) == 3)  # 3D arrays\n\t        img_s, img_h, img_w = img.shape\n\t        assert ((img_h - C['patch_h']) % C['stride_h'] == 0\n\t                and (img_w - C['patch_w']) % C['stride_w'] == 0\n\t                and (img_s - C['patch_s']) % C['stride_s'] == 0)\n\t        N_patches_s = (img_s - C['patch_s']) // C['stride_s'] + 1\n\t        N_patches_h = (img_h - C['patch_h']) // C['stride_h'] + 1\n\t        N_patches_w = (img_w - C['patch_w']) // C['stride_w'] + 1\n\t        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n\t        #        print(\"Patches number of the image:{} [s={} | h={} | w={}]\"\\\n", "        #               .format(N_patches_img, N_patches_s, N_patches_h, N_patches_w))\n\t        patches = np.empty((N_patches_img, C['patch_s'], C['patch_h'], C['patch_w']))\n\t        iter_tot = 0  # iter over the total number of patches (N_patches)\n\t        for s in range(N_patches_s):  # loop over the full images\n\t            for h in range(N_patches_h):\n\t                for w in range(N_patches_w):\n\t                    patch = img[s * C['stride_s']: s * C['stride_s'] + C['patch_s'],\n\t                            h * C['stride_h']: h * C['stride_h'] + C['patch_h'],\n\t                            w * C['stride_w']: w * C['stride_w'] + C['patch_w']]\n\t                    patches[iter_tot] = patch\n", "                    iter_tot += 1  # total\n\t        assert (iter_tot == N_patches_img)\n\t        return patches  # array with all the full_imgs divided in patches\n\tclass Recompone_tool():\n\t    def __init__(self, img_ori_shape, img_new_shape, Cut_para):\n\t        self.result = None\n\t        self.ori_shape = img_ori_shape\n\t        self.new_shape = img_new_shape\n\t        self.C = Cut_para\n\t    def add_result(self, tensor):\n", "        # tensor = tensor.detach().cpu() # shape: [N,class,s,h,w]\n\t        # tensor_np = np.squeeze(tensor_np,axis=0)\n\t        if self.result is not None:\n\t            self.result = torch.cat((self.result, tensor), dim=0)\n\t        else:\n\t            self.result = tensor\n\t    def recompone_overlap(self):\n\t        \"\"\"\n\t        :param adcds: output of model  shapeï¼š[N_patchs_img,3,patch_s,patch_h,patch_w]\n\t        :return: result of recompone output shape: [3,img_s,img_h,img_w]\n", "        \"\"\"\n\t        patch_s = self.result.shape[2]\n\t        patch_h = self.result.shape[3]\n\t        patch_w = self.result.shape[4]\n\t        N_patches_s = (self.new_shape[0] - patch_s) // self.C['stride_s'] + 1\n\t        N_patches_h = (self.new_shape[1] - patch_h) // self.C['stride_h'] + 1\n\t        N_patches_w = (self.new_shape[2] - patch_w) // self.C['stride_w'] + 1\n\t        N_patches_img = N_patches_s * N_patches_h * N_patches_w\n\t        # print(\"N_patches_s/h/w:\", N_patches_s, N_patches_h, N_patches_w)\n\t        # print(\"N_patches_img: \" + str(N_patches_img))\n", "        assert (self.result.shape[0] == N_patches_img)\n\t        full_prob = torch.zeros((self.new_shape[0], self.new_shape[1],\n\t                                 self.new_shape[2]))  # itialize to zero mega array with sum of Probabilities\n\t        full_sum = torch.zeros((self.new_shape[0], self.new_shape[1], self.new_shape[2]))\n\t        k = 0  # iterator over all the patches\n\t        for s in range(N_patches_s):\n\t            for h in range(N_patches_h):\n\t                for w in range(N_patches_w):\n\t                    # print(k,self.result[k].squeeze().sum())\n\t                    full_prob[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n", "                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n\t                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += self.result[k].squeeze()\n\t                    full_sum[s * self.C['stride_s']:s * self.C['stride_s'] + patch_s,\n\t                    h * self.C['stride_h']:h * self.C['stride_h'] + patch_h,\n\t                    w * self.C['stride_w']:w * self.C['stride_w'] + patch_w] += 1\n\t                    k += 1\n\t        assert (k == self.result.size(0))\n\t        assert (torch.min(full_sum) >= 1.0)  # at least one\n\t        final_avg = full_prob / full_sum\n\t        # print(final_avg.size())\n", "        img = final_avg[:self.ori_shape[0], :self.ori_shape[1], :self.ori_shape[2]]\n\t        return img\n\tdef cal_newshape(img, C):\n\t    assert (len(img.shape) == 3)  # 3D array\n\t    img_s, img_h, img_w = img.shape\n\t    leftover_s = (img_s - C['patch_s']) % C['stride_s']\n\t    leftover_h = (img_h - C['patch_h']) % C['stride_h']\n\t    leftover_w = (img_w - C['patch_w']) % C['stride_w']\n\t    if (leftover_s != 0):\n\t        s = img_s + (C['stride_s'] - leftover_s)\n", "    else:\n\t        s = img_s\n\t    if (leftover_h != 0):\n\t        h = img_h + (C['stride_h'] - leftover_h)\n\t    else:\n\t        h = img_h\n\t    if (leftover_w != 0):\n\t        w = img_w + (C['stride_w'] - leftover_w)\n\t    else:\n\t        w = img_w\n", "    return np.zeros((s, h, w)).shape\n\tdef package_torch(adc_patch, pos_patch, sub_patch, gt_patch):\n\t    adc_patch = torch.from_numpy(adc_patch[np.newaxis, np.newaxis, :])\n\t    pos_patch = torch.from_numpy(pos_patch[np.newaxis, np.newaxis, :])\n\t    sub_patch = torch.from_numpy(sub_patch[np.newaxis, np.newaxis, :])\n\t    gt_patch = torch.from_numpy(gt_patch[np.newaxis, np.newaxis, :])\n\t    return adc_patch, pos_patch, sub_patch, gt_patch\n\tdef Test_Datasets(dataset_path, size, test_folder=1):\n\t    f = open(os.path.join(dataset_path, 'data_folder', 'test' + str(test_folder) + '.txt'))\n\t    data_list = f.read().splitlines()\n", "    print(\"The number of test samples is: \", len(data_list))\n\t    for file in data_list:\n\t        # file = str(int(file))\n\t        # print(\"\\nStart Evaluate: \", file)\n\t        adc = load(os.path.join(dataset_path, file, 'adc_contrast.nii.gz')).astype(np.float32)\n\t        pos = load(os.path.join(dataset_path, file, 'Pos_contrast.nii.gz')).astype(np.float32)\n\t        sub = normalization(pos - adc)\n\t        print(sub.shape)\n\t        gt = load(os.path.join(dataset_path, file, 'GT.nii.gz')).astype(np.int16)\n\t        adc_patch, pos_patch, sub_patch, gt_patch = random_crop_3d(adc, pos, sub, gt, size)\n", "        yield package_torch(adc_patch, pos_patch, sub_patch, gt_patch), file\n\tdef Test_all_Datasets(dataset_path, size):\n\t    f = open(os.path.join(dataset_path, 'data.txt'))\n\t    data_list = f.read().splitlines()\n\t    print(\"The number of test samples is: \", len(data_list))\n\t    for file in data_list:\n\t        print(\"\\nStart Evaluate: \", file)\n\t        DCE = normalization(load(os.path.join(dataset_path, file, 'DCE.nii.gz'))).astype(np.float32)\n\t        original_shape = DCE.shape\n\t        new_shape = cal_newshape(DCE, size)\n", "        # adc_patch, pos_patch, sub_patch, gt_patch = random_crop_3d(adc,pos,sub,gt,size)\n\t        yield Img_DataSet(DCE, size), original_shape, new_shape, file\n"]}
{"filename": "Step1-Image-Synthesis/dataset/dataset_lits_val.py", "chunked_list": ["import random\n\timport numpy as np\n\timport SimpleITK as sitk\n\timport os\n\tfrom torch.utils.data import Dataset\n\tclass Val_DataSet(Dataset):\n\t    def __init__(self, root, sample_index='partial', size=(32, 128, 128)):\n\t        self.root = root\n\t        self.size = size\n\t        self.sample_index = sample_index\n", "        f = open(os.path.join(self.root, 'val.txt'))\n\t        self.filename = f.read().splitlines()\n\t    def __getitem__(self, index):\n\t        file = self.filename[index]\n\t        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n\t        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n\t        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\t        ADC_patch, DCE_patch, gt_patch = [], []\n\t        for i in range(5):\n\t            if i == 1:\n", "                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_contain(DCE, ADC, gt, self.size)\n\t            elif i == 2:\n\t                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_partial(DEC, ADC, gt, self.size)\n\t            else:\n\t                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d(DEC, ADC, gt, self.size)\n\t            DCE_patch.append(DCE_patch1), ADC_patch.append(ADC_patch1), gt_patch.append(gt_patch1)\n\t        return np.array(DCE_patch), np.array(ADC_patch), np.array(gt_patch)\n\t    def __len__(self):\n\t        return len(self.filename)\n\t    def random_crop_3d_contain(self, a, b, gt, crop_size):\n", "        cor_box = self.maskcor_extract_3d(gt)\n\t        random_x_min, random_x_max = max(cor_box[0, 1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2] - crop_size[2])\n\t        if random_x_min > random_x_max:\n\t            random_x_min, random_x_max = cor_box[0, 0], cor_box[0, 1] - crop_size[0]\n\t        if random_y_min > random_y_max:\n\t            random_y_min, random_y_max = cor_box[1, 0], cor_box[1, 1] - crop_size[1]\n\t        if random_z_min > random_z_max:\n\t            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n", "        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, gt_patch\n", "    def random_crop_3d_partial(self, a, b, gt, crop_size):\n\t        cor_box = self.maskcor_extract_3d(gt)\n\t        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n", "        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, gt_patch\n\t    def random_crop_3d(self, a, b, gt, crop_size):\n\t        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(0, a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(0, a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(0, a.shape[2] - crop_size[2])\n\t        x_random = random.randint(0, a.shape[0] - crop_size[0])\n", "        y_random = random.randint(0, a.shape[1] - crop_size[1])\n\t        z_random = random.randint(0, a.shape[2] - crop_size[2])\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                   z_random:z_random + crop_size[2]]\n\t        return a_patch, b_patch, gt_patch\n\t    def min_max_normalization(self, img):\n", "        out = (img - np.min(img)) / (np.max(img) - np.min(img) + 0.000001)\n\t        return out\n\t    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n\t            maxval = round(np.percentile(newimg, 100 - quantile))\n\t            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n\t            newimg[newimg <= minval] = minval\n", "        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n\t            maxval = np.max(newimg)\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n", "        return newimg\n\t    def load(self, file):\n\t        itkimage = sitk.ReadImage(file)\n\t        image = sitk.GetArrayFromImage(itkimage)\n\t        return image\n\t    def maskcor_extract_3d(self, mask, padding=(0, 0, 0)):\n\t        # mask_s = mask.shape\n\t        if np.sum(mask) == 0:\n\t            mask[10:12, 100:102, 100:102] = 1\n\t        p = np.where(mask > 0)\n", "        a = np.zeros([3, 2], dtype=np.int)\n\t        for i in range(3):\n\t            s = p[i].min()\n\t            e = p[i].max() + 1\n\t            ss = s - padding[i]\n\t            ee = e + padding[i]\n\t            if ss < 0:\n\t                ss = 0\n\t            if ee > mask.shape[i]:\n\t                ee = mask.shape[i]\n", "            a[i, 0] = ss\n\t            a[i, 1] = ee\n\t        return a\n"]}
{"filename": "Step1-Image-Synthesis/dataset/dataset_lits_train.py", "chunked_list": ["import random\n\timport numpy as np\n\timport SimpleITK as sitk\n\timport os\n\tfrom torch.utils.data import Dataset\n\tclass Lits_DataSet(Dataset):\n\t    def __init__(self,root, sample_index='partial', size=(32, 128, 128)):\n\t        self.root = root\n\t        self.size = size\n\t        self.sample_index = sample_index\n", "        f = open(os.path.join(self.root, 'data.txt'))\n\t        self.filename = f.read().splitlines()\n\t    def __getitem__(self, index):\n\t        file = self.filename[index]\n\t        DCE = self.normalization(self.load(os.path.join(self.root, file, 'DCE.nii.gz'))).astype(np.float32)\n\t        ADC = self.normalization(self.load(os.path.join(self.root, file, 'ADC.nii.gz'))).astype(np.float32)\n\t        gt = self.load(os.path.join(self.root, file, 'GT.nii.gz')).astype(np.float32)\n\t        ADC_patch,DCE_patch, gt_patch = [], [], []\n\t        for i in range(5):\n\t            if i == 1:\n", "                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_contain(DCE,ADC, gt, self.size)\n\t            elif i==2:\n\t                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d_partial(DCE, ADC, gt, self.size)\n\t            else:\n\t                DCE_patch1, ADC_patch1, gt_patch1 = self.random_crop_3d(DCE, ADC, gt, self.size)\n\t            DCE_patch.append(DCE_patch1),ADC_patch.append(ADC_patch1), gt_patch.append(gt_patch1)\n\t        return np.array(DCE_patch),np.array(ADC_patch), np.array(gt_patch)\n\t    def __len__(self):\n\t        return len(self.filename)\n\t    def random_crop_3d_contain(self, a,b, gt, crop_size):\n", "        cor_box = self.maskcor_extract_3d(gt)\n\t        random_x_min, random_x_max = max(cor_box[0,1] - crop_size[0], 0), min(cor_box[0, 0], a.shape[0]-crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1,1] - crop_size[1], 0), min(cor_box[1, 0], a.shape[1]-crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2,1] - crop_size[2], 0), min(cor_box[2, 0], a.shape[2]-crop_size[2])\n\t        if random_x_min >random_x_max:\n\t            random_x_min, random_x_max = cor_box[0,0], cor_box[0,1] - crop_size[0]\n\t        if random_y_min >random_y_max:\n\t            random_y_min, random_y_max = cor_box[1,0], cor_box[1,1] - crop_size[1]\n\t        if random_z_min > random_z_max:\n\t            random_z_min, random_z_max = cor_box[2, 0], cor_box[2, 1] - crop_size[2]\n", "        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\t        return a_patch,b_patch, gt_patch\n\t    def random_crop_3d_partial(self, a,b, gt, crop_size):\n\t        cor_box = self.maskcor_extract_3d(gt)\n", "        random_x_min, random_x_max = max(cor_box[0, 0] - crop_size[0], 0), min(cor_box[0, 1], a.shape[0] - crop_size[0])\n\t        random_y_min, random_y_max = max(cor_box[1, 0] - crop_size[1], 0), min(cor_box[1, 1], a.shape[1] - crop_size[1])\n\t        random_z_min, random_z_max = max(cor_box[2, 0] - crop_size[2], 0), min(cor_box[2, 1], a.shape[2] - crop_size[2])\n\t        x_random = random.randint(random_x_min, random_x_max)\n\t        y_random = random.randint(random_y_min, random_y_max)\n\t        z_random = random.randint(random_z_min, random_z_max)\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n", "        return a_patch,b_patch, gt_patch\n\t    def random_crop_3d(self, a,b, gt, crop_size):\n\t        x_random = random.randint(0, a.shape[0] - crop_size[0])\n\t        y_random = random.randint(0, a.shape[1] - crop_size[1])\n\t        z_random = random.randint(0, a.shape[2] - crop_size[2])\n\t        a_patch = a[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\t        b_patch = b[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1],\n\t                  z_random:z_random + crop_size[2]]\n\t        gt_patch = gt[x_random:x_random + crop_size[0], y_random:y_random + crop_size[1], z_random:z_random + crop_size[2]]\n\t        return a_patch,b_patch, gt_patch\n", "    def min_max_normalization(self, img):\n\t        out = (img - np.min(img))/(np.max(img) - np.min(img) + 0.000001)\n\t        return out\n\t    def normalization(self, img, lmin=1, rmax=None, dividend=None, quantile=None):\n\t        newimg = img.copy()\n\t        newimg = newimg.astype(np.float32)\n\t        if quantile is not None:\n\t            maxval = round(np.percentile(newimg, 100 - quantile))\n\t            minval = round(np.percentile(newimg, quantile))\n\t            newimg[newimg >= maxval] = maxval\n", "            newimg[newimg <= minval] = minval\n\t        if lmin is not None:\n\t            newimg[newimg < lmin] = lmin\n\t        if rmax is not None:\n\t            newimg[newimg > rmax] = rmax\n\t        minval = np.min(newimg)\n\t        if dividend is None:\n\t            maxval = np.max(newimg)\n\t            newimg = (np.asarray(newimg).astype(np.float32) - minval) / (maxval - minval)\n\t        else:\n", "            newimg = (np.asarray(newimg).astype(np.float32) - minval) / dividend\n\t        return newimg\n\t    def load(self,file):\n\t        itkimage = sitk.ReadImage(file)\n\t        image = sitk.GetArrayFromImage(itkimage)\n\t        return image\n\t    def maskcor_extract_3d(self,mask, padding=(0, 0, 0)):\n\t        # mask_s = mask.shape\n\t        if np.sum(mask)==0:\n\t            mask[10:12,100:102,100:102]=1\n", "        p = np.where(mask > 0)\n\t        a = np.zeros([3, 2], dtype=np.int)\n\t        for i in range(3):\n\t            s = p[i].min()\n\t            e = p[i].max() + 1\n\t            ss = s - padding[i]\n\t            ee = e + padding[i]\n\t            if ss < 0:\n\t                ss = 0\n\t            if ee > mask.shape[i]:\n", "                ee = mask.shape[i]\n\t            a[i, 0] = ss\n\t            a[i, 1] = ee\n\t        return a\n"]}
{"filename": "Step1-Image-Synthesis/Model/runet.py", "chunked_list": ["import torch\n\timport torch.nn as nn\n\tbasic_dims = 8\n\tnum_modals = 1\n\tpatch_size = [2, 8, 8]\n\tdef normalization(planes, norm='bn'):\n\t    if norm == 'bn':\n\t        m = nn.BatchNorm3d(planes)\n\t    elif norm == 'gn':\n\t        m = nn.GroupNorm(4, planes)\n", "    elif norm == 'in':\n\t        m = nn.InstanceNorm3d(planes)\n\t    else:\n\t        raise ValueError('normalization type {} is not supported'.format(norm))\n\t    return m\n\tclass general_conv3d_prenorm(nn.Module):\n\t    def __init__(self, in_ch, out_ch, k_size=3, stride=1, padding=1, pad_type='zeros', norm='in', is_training=True,\n\t                 act_type='lrelu', relufactor=0.2):\n\t        super(general_conv3d_prenorm, self).__init__()\n\t        self.conv = nn.Conv3d(in_channels=in_ch, out_channels=out_ch, kernel_size=k_size, stride=stride,\n", "                              padding=padding, padding_mode=pad_type, bias=True)\n\t        self.norm = normalization(out_ch, norm=norm)\n\t        if act_type == 'relu':\n\t            self.activation = nn.ReLU(inplace=True)\n\t        elif act_type == 'lrelu':\n\t            self.activation = nn.LeakyReLU(negative_slope=relufactor, inplace=True)\n\t    def forward(self, x):\n\t        x = self.norm(x)\n\t        x = self.activation(x)\n\t        x = self.conv(x)\n", "        return x\n\tclass fusion_prenorm(nn.Module):\n\t    def __init__(self, in_channel=64, num_cls=4):\n\t        super(fusion_prenorm, self).__init__()\n\t        self.fusion_layer = nn.Sequential(\n\t            general_conv3d_prenorm(in_channel * num_modals, in_channel, k_size=1, padding=0, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=3, padding=1, stride=1),\n\t            general_conv3d_prenorm(in_channel, in_channel, k_size=1, padding=0, stride=1))\n\t    def forward(self, x):\n\t        return self.fusion_layer(x)\n", "class Encoder(nn.Module):\n\t    def __init__(self, flag=True):\n\t        super(Encoder, self).__init__()\n\t        if flag:\n\t            self.e1_c1 = nn.Conv3d(in_channels=1, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n\t                                   padding_mode='zeros', bias=True)\n\t        else:\n\t            self.e1_c1 = nn.Conv3d(in_channels=2, out_channels=basic_dims, kernel_size=3, stride=1, padding=1,\n\t                                   padding_mode='zeros', bias=True)\n\t        self.e1_c2 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n", "        self.e1_c3 = general_conv3d_prenorm(basic_dims, basic_dims, pad_type='zeros')\n\t        self.e2_c1 = general_conv3d_prenorm(basic_dims, basic_dims * 2, stride=2, pad_type='zeros')\n\t        self.e2_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\t        self.e2_c3 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, pad_type='zeros')\n\t        self.e3_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims * 4, stride=2, pad_type='zeros')\n\t        self.e3_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\t        self.e3_c3 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, pad_type='zeros')\n\t        self.e4_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 8, stride=2, pad_type='zeros')\n\t        self.e4_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n\t        self.e4_c3 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, pad_type='zeros')\n", "        self.e5_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 16, stride=2, pad_type='zeros')\n\t        self.e5_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\t        self.e5_c3 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 16, pad_type='zeros')\n\t    def forward(self, x):\n\t        x1 = self.e1_c1(x)\n\t        x1 = x1 + self.e1_c3(self.e1_c2(x1))\n\t        x2 = self.e2_c1(x1)\n\t        x2 = x2 + self.e2_c3(self.e2_c2(x2))\n\t        x3 = self.e3_c1(x2)\n\t        x3 = x3 + self.e3_c3(self.e3_c2(x3))\n", "        x4 = self.e4_c1(x3)\n\t        x4 = x4 + self.e4_c3(self.e4_c2(x4))\n\t        x5 = self.e5_c1(x4)\n\t        x5 = x5 + self.e5_c3(self.e5_c2(x5))\n\t        return x1, x2, x3, x4, x5\n\tclass Decoder_fuse(nn.Module):\n\t    def __init__(self, num_cls=1):\n\t        super(Decoder_fuse, self).__init__()\n\t        self.d4_c1 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n\t        self.d4_c2 = general_conv3d_prenorm(basic_dims * 16, basic_dims * 8, pad_type='zeros')\n", "        self.d4_out = general_conv3d_prenorm(basic_dims * 8, basic_dims * 8, k_size=1, padding=0, pad_type='zeros')\n\t        self.d3_c1 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n\t        self.d3_c2 = general_conv3d_prenorm(basic_dims * 8, basic_dims * 4, pad_type='zeros')\n\t        self.d3_out = general_conv3d_prenorm(basic_dims * 4, basic_dims * 4, k_size=1, padding=0, pad_type='zeros')\n\t        self.d2_c1 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n\t        self.d2_c2 = general_conv3d_prenorm(basic_dims * 4, basic_dims * 2, pad_type='zeros')\n\t        self.d2_out = general_conv3d_prenorm(basic_dims * 2, basic_dims * 2, k_size=1, padding=0, pad_type='zeros')\n\t        self.d1_c1 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n\t        self.d1_c2 = general_conv3d_prenorm(basic_dims * 2, basic_dims, pad_type='zeros')\n\t        self.d1_out = general_conv3d_prenorm(basic_dims, basic_dims, k_size=1, padding=0, pad_type='zeros')\n", "        self.seg_d4 = nn.Conv3d(in_channels=basic_dims * 16, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                bias=True)\n\t        self.seg_d3 = nn.Conv3d(in_channels=basic_dims * 8, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                bias=True)\n\t        self.seg_d2 = nn.Conv3d(in_channels=basic_dims * 4, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                bias=True)\n\t        self.seg_d1 = nn.Conv3d(in_channels=basic_dims * 2, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                bias=True)\n\t        self.seg_layer = nn.Conv3d(in_channels=basic_dims, out_channels=num_cls, kernel_size=1, stride=1, padding=0,\n\t                                   bias=True)\n", "        self.softmax = nn.Softmax(dim=1)\n\t        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n\t        self.RFM5 = fusion_prenorm(in_channel=basic_dims * 16, num_cls=num_cls)\n\t        self.RFM4 = fusion_prenorm(in_channel=basic_dims * 8, num_cls=num_cls)\n\t        self.RFM3 = fusion_prenorm(in_channel=basic_dims * 4, num_cls=num_cls)\n\t        self.RFM2 = fusion_prenorm(in_channel=basic_dims * 2, num_cls=num_cls)\n\t        self.RFM1 = fusion_prenorm(in_channel=basic_dims * 1, num_cls=num_cls)\n\t    def forward(self, x1, x2, x3, x4, x5):\n\t        de_x5 = self.RFM5(x5)\n\t        de_x5 = self.d4_c1(self.up2(de_x5))\n", "        de_x4 = self.RFM4(x4)\n\t        de_x4 = torch.cat((de_x4, de_x5), dim=1)\n\t        de_x4 = self.d4_out(self.d4_c2(de_x4))\n\t        de_x4 = self.d3_c1(self.up2(de_x4))\n\t        de_x3 = self.RFM3(x3)\n\t        de_x3 = torch.cat((de_x3, de_x4), dim=1)\n\t        de_x3 = self.d3_out(self.d3_c2(de_x3))\n\t        de_x3 = self.d2_c1(self.up2(de_x3))\n\t        de_x2 = self.RFM2(x2)\n\t        de_x2 = torch.cat((de_x2, de_x3), dim=1)\n", "        de_x2 = self.d2_out(self.d2_c2(de_x2))\n\t        de_x2 = self.d1_c1(self.up2(de_x2))\n\t        de_x1 = self.RFM1(x1)\n\t        de_x1 = torch.cat((de_x1, de_x2), dim=1)\n\t        de_x1 = self.d1_out(self.d1_c2(de_x1))\n\t        logits = self.seg_layer(de_x1)\n\t        pred = torch.sigmoid(logits)\n\t        return pred\n\tclass RUnet(nn.Module):\n\t    def __init__(self, num_cls=3):\n", "        super(RUnet, self).__init__()\n\t        self.ADC_encoder = Encoder(flag=True)\n\t        self.decoder_fuse = Decoder_fuse(num_cls=num_cls)\n\t        self.is_training = True\n\t        for m in self.modules():\n\t            if isinstance(m, nn.Conv3d):\n\t                torch.nn.init.kaiming_normal_(m.weight)\n\t    def forward(self, x):\n\t        ADC_x1, ADC_x2, ADC_x3, ADC_x4, ADC_x5 = self.ADC_encoder(x[:, 0:1, :, :, :])\n\t        x1 = ADC_x1\n", "        x2 = ADC_x2\n\t        x3 = ADC_x3\n\t        x4 = ADC_x4\n\t        x5 = ADC_x5\n\t        fuse_pred = self.decoder_fuse(x1, x2, x3, x4, x5)\n\t        return fuse_pred\n\tif __name__ == '__main__':\n\t    a = torch.zeros([10, 1, 32, 128, 128])\n\t    model = RUnet(num_cls=1)\n\t    out = model(a)\n", "    print(out.shape)\n"]}
