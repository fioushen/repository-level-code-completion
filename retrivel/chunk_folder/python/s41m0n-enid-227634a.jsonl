{"filename": "setup.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport setuptools\n\twith open(\"README.md\", \"r\") as fh:\n\t    long_description = fh.read()\n\twith open(\"VERSION\", \"r\") as fh:\n\t    version = fh.read()\n\twith open('requirements.txt') as fh:\n\t    requirements = fh.read().splitlines()\n", "setuptools.setup(\n\t    name=\"ENID\",\n\t    author=\"Simone Magnani\",\n\t    author_email=\"simonemagnani.96@gmail.com\",\n\t    version=version,\n\t    description=\"Enhancing Network Intrusion Detection: An Online Methodology for Performance Analysis\",\n\t    long_description=long_description,\n\t    long_description_content_type=\"text/markdown\",\n\t    url=\"https://github.com/s41m0n/enid\",\n\t    packages=setuptools.find_packages(exclude=(\"tests\",)),\n", "    license=\"Apache-2.0\",\n\t    classifiers=[\n\t        \"Programming Language :: Python :: 3\",\n\t        \"License :: OSI Approved :: Apache-2.0 License\",\n\t        \"Operating System :: Linux\",\n\t    ],\n\t    install_requires=requirements,\n\t    include_package_data=True,\n\t    python_requires='>=3.8'\n\t)\n"]}
{"filename": "enid/offline.py", "chunked_list": ["import argparse\n\timport os\n\tfrom .datasetter import DatasetConfig\n\tfrom .lib.utility import dump_json_data, get_logger, load_json_data, set_seed\n\tfrom .trainer import ModelConfig, ResultTrain\n\t_logger = get_logger(__name__)\n\tdef main(args_list):\n\t    # registering cli parameters, which can be shown with the -h\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n", "    parser.add_argument(\n\t        'de_models_dir', help='path to the model directory containing the models to test')\n\t    parser.add_argument(\n\t        '-r', '--retest', help='overwrite previous result', action=\"store_true\")\n\t    args = parser.parse_args(args_list).__dict__\n\t    models_dir = os.path.join(\n\t        args[\"de_models_dir\"], 'models')\n\t    models_config = ModelConfig(\n\t        **load_json_data(os.path.join(models_dir, \"conf.json\")))\n\t    dataset_config = DatasetConfig(\n", "        **load_json_data(os.path.join(args[\"de_models_dir\"], os.pardir, \"conf.json\")))\n\t    for c in models_config.train_params.all_train_combs():\n\t        name = models_config.detection_engine.model_name(**c)\n\t        new_path = os.path.join(models_dir, name)\n\t        if not args[\"retest\"] and os.path.isfile(os.path.join(new_path, \"results.json\")):\n\t            _logger.info(\n\t                f\"Offline results for {name} already present, skipping\")\n\t            continue\n\t        params = load_json_data(os.path.join(new_path, \"params.json\"))\n\t        fholder, params, model = models_config.detection_engine.load_model(\n", "            params, os.path.join(args[\"de_models_dir\"], \"models\"))\n\t        set_seed()\n\t        (_, _, _), (_, _, _), (xts, yts, pt) = models_config.detection_engine._load_dataset(\n\t            os.path.join(args[\"de_models_dir\"], os.pardir), fholder, **params.__dict__)\n\t        _logger.info(f\"Testing {name}\")\n\t        y_pred = models_config.detection_engine.predict(\n\t            model, xts, **params.__dict__)\n\t        res = ResultTrain(\n\t            _threshold=models_config.train_params.malicious_threshold,\n\t            _ypred=y_pred, _ytrue=yts)\n", "        res.update(dataset_config.offline, pt)\n\t        dump_json_data(res, os.path.join(new_path, \"results.json\"))\n"]}
{"filename": "enid/datasetter.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tMain file for creating a Dataser from a series of preprocessed pcap files.\n\tPcap can belong to different datasets and categories. This program takes into\n\taccount the creation of a unified and balanced train, validation and test set\n\tfor the training and the offline testing of the generated models.\n\tIn addition, a PCAP file from the testing samples is created for the further\n\tonline testing methodology.\n", "The algorithm for the creation of the dataset aims at taking an equally number\n\tof benign and malicious samples. However, within the same type (e.g., malicious)\n\tit is possible to still have a different amount of samples (e.g., 1000 ddos,\n\t10 sqli, 1 botnet).\n\t\"\"\"\n\timport argparse\n\timport math\n\timport multiprocessing\n\timport os\n\timport pickle\n", "import random\n\timport time\n\tfrom copy import deepcopy\n\tfrom dataclasses import dataclass, field, fields\n\tfrom typing import Any, Dict, List, Type\n\tfrom pypacker.ppcap import Reader, Writer\n\tfrom .lib import ATTACK_LABELS\n\tfrom .lib.definitions import DetectionEngine\n\tfrom .lib.identifiers import BaseKey, str_to_key\n\tfrom .lib.utility import (UpdatableDataclass, all_subclasses, create_dir,\n", "                          dump_json_data, get_logger, load_json_data)\n\tfrom .preprocesser import CategoryConfig, PcapConfig, PreprocessedConfig\n\t_logger = get_logger(__name__)\n\t@dataclass\n\tclass SingleDatasetTestConfig(PcapConfig, UpdatableDataclass):\n\t    categories: Dict[str, CategoryConfig] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        for k, v in self.categories.items():\n\t            self.categories[k] = CategoryConfig(**v)\n\t@dataclass\n", "class DatasetTestConfig(PcapConfig, UpdatableDataclass):\n\t    duration: int = 0\n\t    datasets: Dict[str, SingleDatasetTestConfig] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        for k, v in self.datasets.items():\n\t            self.datasets[k] = SingleDatasetTestConfig(**v)\n\t@dataclass\n\tclass BaseConfig(UpdatableDataclass):\n\t    taken: int = field(default=0)\n\t    train_taken: int = field(default=0)\n", "    val_taken: int = field(default=0)\n\t    test_taken: int = field(default=0)\n\t@dataclass\n\tclass TrainBaseConfig:\n\t    benign: BaseConfig = field(default_factory=BaseConfig)\n\t    malicious: BaseConfig = field(default_factory=BaseConfig)\n\t    def __post_init__(self):\n\t        if isinstance(self.benign, dict):\n\t            self.benign = BaseConfig(**self.benign)\n\t        if isinstance(self.malicious, dict):\n", "            self.malicious = BaseConfig(**self.malicious)\n\t@dataclass\n\tclass TrainCategoryConfig(TrainBaseConfig):\n\t    captures: Dict[str, TrainBaseConfig] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        for k, v in self.captures.items():\n\t            if isinstance(v, dict):\n\t                self.captures[k] = TrainBaseConfig(**v)\n\t@dataclass\n\tclass TrainDatasetConfig(TrainBaseConfig):\n", "    categories: Dict[str, TrainCategoryConfig] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        for k, v in self.categories.items():\n\t            if isinstance(v, dict):\n\t                self.categories[k] = TrainCategoryConfig(**v)\n\t@dataclass\n\tclass DatasetTrainConfig(TrainBaseConfig):\n\t    validation_percentage: float = field(default=0.1)\n\t    test_percentage: float = field(default=0.1)\n\t    max_to_take: int = field(default=0)\n", "    datasets: Dict[str, TrainDatasetConfig] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        for k, v in self.datasets.items():\n\t            if isinstance(v, dict):\n\t                self.datasets[k] = TrainDatasetConfig(**v)\n\t@dataclass\n\tclass DatasetConfig:\n\t    name: str = field(default=\"\")\n\t    time_window: int = 0\n\t    additional_params: Dict[str, Any] = field(default_factory=dict)\n", "    key_cls: Type[BaseKey] = field(default=None)\n\t    offline: DatasetTrainConfig = field(default_factory=DatasetTrainConfig)\n\t    online: DatasetTestConfig = field(default_factory=DatasetTestConfig)\n\t    attackers: List[Type[BaseKey]] = field(default_factory=list)\n\t    preprocessed_configs: Dict[str, PreprocessedConfig] = field(\n\t        default_factory=dict)\n\t    paths: Dict[str, str] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        self.name = \"\"\n\t        des = set()\n", "        if isinstance(self.key_cls, str):\n\t            self.key_cls = str_to_key(self.key_cls)\n\t        for i, k in enumerate(sorted(self.preprocessed_configs.keys())):\n\t            if isinstance(self.preprocessed_configs[k], dict):\n\t                self.preprocessed_configs[k] = PreprocessedConfig(\n\t                    **self.preprocessed_configs[k])\n\t            self.name += self.preprocessed_configs[k].family + \"-\"\n\t            des.add(self.preprocessed_configs[k].detection_engine.__name__)\n\t            if not self.key_cls:\n\t                self.key_cls = self.preprocessed_configs[k].key_cls\n", "            if not self.key_cls == self.preprocessed_configs[k].key_cls:\n\t                raise Exception(\"Key cls does not match\", self.key_cls,\n\t                                self.preprocessed_configs[k].key_cls)\n\t            if not self.time_window:\n\t                self.time_window = self.preprocessed_configs[k].time_window\n\t            if not self.time_window == self.preprocessed_configs[k].time_window:\n\t                raise Exception(\"Time Windows does not match\")\n\t            if i + 1 == len(self.preprocessed_configs):\n\t                self.name += self.preprocessed_configs[k].detection_engine.__name__\n\t        if not DetectionEngine.intersect(des):\n", "            raise Exception(\"Do not intersect\")\n\t        if isinstance(self.online, dict):\n\t            self.online = DatasetTestConfig(**self.online)\n\t        if isinstance(self.offline, dict):\n\t            self.offline = DatasetTrainConfig(**self.offline)\n\t        conf_names = list(self.preprocessed_configs.keys())\n\t        if not all(\n\t                self.preprocessed_configs[x].time_window == self.preprocessed_configs[conf_names[0]].time_window\n\t                for x in conf_names):\n\t            raise ValueError(\"Non son compatibili TW\")\n", "        if not all(\n\t                self.preprocessed_configs[x].additional_params == self.preprocessed_configs[conf_names[0]].additional_params\n\t                for x in conf_names):\n\t            raise ValueError(\"Non son compatibili FL\")\n\t        for i, v in enumerate(self.attackers):\n\t            tmp = None\n\t            if isinstance(v, BaseKey):\n\t                break\n\t            if not tmp:\n\t                tmp = next(y for y in all_subclasses(BaseKey)\n", "                           if len(v) == len(fields(y)) and all(p.name in v for p in fields(y)))\n\t            self.attackers[i] = tmp.create(**v)\n\tdef load_packets(pcap, dataset, category, capture):\n\t    \"\"\"Method to load all raw packets from a pcap into a buffer\"\"\"\n\t    _logger.info(f\"Started Loading packets of {pcap}\")\n\t    init_ts = 0\n\t    all_pkts = []\n\t    for i, (ts, pkt) in enumerate(Reader(filename=pcap)):\n\t        if i == 0:\n\t            init_ts = ts\n", "        all_pkts.append((ts - init_ts, pkt, dataset, category, capture))\n\t    _logger.info(f\"Finished Loading packets of {pcap}\")\n\t    return all_pkts\n\tdef async_combined(unordered, target_dir):\n\t    \"\"\"Method to sort all packets belonging to the provided pcaps by arrival time and\n\t    creating a unified capture file\"\"\"\n\t    _logger.info(\"Start Combined Async load\")\n\t    pkts = []\n\t    [pkts.extend(x) for x in unordered]\n\t    pkts = sorted(pkts, key=lambda x: x[0])\n", "    tmp = []\n\t    with Writer(filename=os.path.join(target_dir, \"combined.pcap\")) as w:\n\t        new_ts = time.time_ns()\n\t        for i, x in enumerate(pkts):\n\t            w.write(x[1], ts=new_ts+x[0])\n\t            tmp.append((x[2], x[3], x[4]))\n\t            if i % 50000 == 0:\n\t                _logger.info(f\"Report Combined Async Load {100*i/len(pkts)}%\")\n\t    with open(os.path.join(target_dir, \"combined.pickle\"), \"wb\") as fp:\n\t        pickle.dump(tmp, fp)\n", "    _logger.info(\"Finished Combined Async load\")\n\tdef async_join(conf: DatasetTrainConfig, preprocessed: Dict[str, PreprocessedConfig],\n\t               paths: Dict[str, str], target_dir, de: DetectionEngine):\n\t    \"\"\"Method to joining all portions of train, validation and test processed data into the final one\"\"\"\n\t    _logger.info(\"Async Join Start\")\n\t    for dataset, v in conf.datasets.items():\n\t        for category, vv in v.categories.items():\n\t            for capture, vvv in vv.captures.items():\n\t                for label, ttype in enumerate([\"benign\", \"malicious\"]):\n\t                    t: BaseConfig = getattr(vvv, ttype)\n", "                    if not t.taken:\n\t                        continue\n\t                    spath = os.path.join(paths[dataset], category, capture)\n\t                    available = getattr(\n\t                        preprocessed[dataset].categories[category].captures[capture], ttype)\n\t                    indexes = random.sample(range(available), t.taken)\n\t                    de.append_to_dataset(spath, target_dir, ttype, label,\n\t                                         indexes[:t.train_taken],\n\t                                         indexes[t.train_taken:t.train_taken +\n\t                                                 t.val_taken],\n", "                                         indexes[t.train_taken+t.val_taken:])\n\t    _logger.info(\"Async Join End\")\n\tdef main(args_list):\n\t    # registering cli args\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument(\n\t        '-b', '--benign', help='preprocessed directories with benign flows', type=str, nargs=\"+\", required=True)\n\t    parser.add_argument(\n\t        '-m', '--malicious', help='preprocessed directories with malicious flows', type=str, nargs=\"+\", required=True)\n", "    parser.add_argument(\n\t        '-pc', '--per-category', help='per category creation of the dataset', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-no', '--no-online', help='no online test', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-tp', '--test-percentage', help='percentage of test in dataset', type=float, default=0.1)\n\t    parser.add_argument(\n\t        '-vp', '--validation-percentage', help='percentage of validation within the entire train set',\n\t        type=float, default=0.1)\n\t    parser.add_argument(\n", "        '-p', '--parallel', help='number of parallel executions', type=int, default=os.cpu_count())\n\t    args = parser.parse_args(args_list).__dict__\n\t    conf: DatasetConfig = DatasetConfig()\n\t    conf.offline.test_percentage = args[\"test_percentage\"]\n\t    conf.offline.validation_percentage = args[\"validation_percentage\"]\n\t    detection_engine: DetectionEngine = None\n\t    for c in set(args[\"benign\"] + args[\"malicious\"]):\n\t        tmp = PreprocessedConfig(\n\t            **load_json_data(os.path.join(c, \"conf.json\")))\n\t        conf.preprocessed_configs[tmp.family] = tmp\n", "        detection_engine = tmp.detection_engine\n\t        conf.paths[tmp.family] = c\n\t        conf.attackers += ATTACK_LABELS[tmp.family](\n\t            tmp.captures_config.path)\n\t        conf.additional_params = tmp.additional_params\n\t    conf.__post_init__()\n\t    target_dir = os.path.join(\n\t        \"datasets\", conf.name, \"{}-{}\".format(\"percategory\" if args[\"per_category\"] else \"combined\",\n\t                                              \"offline\" if args[\"no_online\"] else \"online\"))\n\t    create_dir(target_dir, overwrite=False)\n", "    # Chosing portions for the online simulation according to their maximum number\n\t    # of benign and malicious samples (which are maximised)\n\t    test_pcaps = []\n\t    cop = deepcopy(conf.preprocessed_configs)\n\t    if not args[\"no_online\"]:\n\t        for ttype in (\"benign\", \"malicious\"):\n\t            for dpath in args[ttype]:\n\t                dataset_name = next(\n\t                    k for k, v in conf.paths.items() if v == dpath)\n\t                conf.online.datasets[dataset_name] = SingleDatasetTestConfig()\n", "                for cat, vals in conf.preprocessed_configs[dataset_name].categories.items():\n\t                    conf.online.datasets[dataset_name].categories[cat] = CategoryConfig(\n\t                    )\n\t                    chosen = max(vals.captures, key=lambda x: getattr(\n\t                        vals.captures[x], ttype))\n\t                    tmp = cop[dataset_name].categories[cat].captures.pop(\n\t                        chosen)\n\t                    conf.online.datasets[dataset_name].categories[cat].captures[chosen] = tmp\n\t                    test_pcaps.append((os.path.join(\n\t                        conf.preprocessed_configs[dataset_name].captures_config.path, cat, chosen),\n", "                        cop[dataset_name].family, cat, chosen))\n\t                    conf.online.datasets[dataset_name].categories[cat].update(\n\t                        tmp)\n\t                    conf.online.datasets[dataset_name].update(tmp)\n\t                    conf.online.update(tmp)\n\t    with multiprocessing.Pool(maxtasksperchild=1, processes=args[\"parallel\"]) as pool:\n\t        pkts = None\n\t        tasks = []\n\t        if not args[\"no_online\"]:\n\t            pkts = pool.starmap_async(load_packets, test_pcaps)\n", "        if not args[\"per_category\"]:\n\t            # Creating balanced train, validation and test portion for training\n\t            tmp = [(vvv.benign, vvv.malicious) for v in cop.values() for vv in v.categories.values()\n\t                   for vvv in vv.captures.values()]\n\t            conf.offline.max_to_take = min(\n\t                sum([v[0] for v in tmp]), sum([v[1] for v in tmp]))\n\t            for ttype in (\"benign\", \"malicious\"):\n\t                asd = {}\n\t                for dpath in args[ttype]:\n\t                    dname = next(\n", "                        k for k, v in conf.paths.items() if v == dpath)\n\t                    asd.update({(dname, kk): sum([getattr(vvv, ttype) for vvv in vv.captures.values()])\n\t                                for kk, vv in cop[dname].categories.items()})\n\t                asd = {k: v for k, v in asd.items() if v}\n\t                asd = {k: asd[k] for k in sorted(asd, key=asd.get)}\n\t                macina(conf, asd, cop, ttype)\n\t            tasks.append(pool.apply_async(async_join, (conf.offline, conf.preprocessed_configs, conf.paths,\n\t                                                       target_dir, detection_engine)))\n\t            if not args[\"no_online\"]:\n\t                conf.online.duration = max(vvv.duration for v in conf.online.datasets.values(\n", "                ) for vv in v.categories.values() for vvv in vv.captures.values())\n\t            _logger.info(\"Dumping configuration with updated stats\")\n\t            dump_json_data(conf, os.path.join(target_dir, \"conf.json\"))\n\t            if not args[\"no_online\"]:\n\t                pkts = pkts.get()\n\t                tasks.append(pool.apply_async(\n\t                    async_combined, (pkts, target_dir)))\n\t        else:\n\t            asd = {}\n\t            for dpath in args[\"benign\"]:\n", "                dname = next(k for k, v in conf.paths.items() if v == dpath)\n\t                asd.update({(dname, kk): sum([vvv.benign for vvv in vv.captures.values()])\n\t                            for kk, vv in cop[dname].categories.items()})\n\t            for dpath in args[\"malicious\"]:\n\t                dname = dataset_name = next(\n\t                    k for k, v in conf.paths.items() if v == dpath)\n\t                for cat, v in conf.preprocessed_configs[dname].categories.items():\n\t                    confi: DatasetConfig = deepcopy(conf)\n\t                    confi.offline.max_to_take = min(\n\t                        v.malicious, sum(v for v in asd.values()))\n", "                    macina(confi, asd, cop, \"benign\")\n\t                    macina(confi, {(dname, cat): v.malicious},\n\t                           cop, \"malicious\")\n\t                    _logger.info(\"Dumping configuration with updated stats\")\n\t                    ts = os.path.join(target_dir, dname, cat)\n\t                    create_dir(ts)\n\t                    dump_json_data(confi, os.path.join(ts, \"conf.json\"))\n\t                    tasks.append(pool.apply_async(async_join, (confi.offline, conf.preprocessed_configs, conf.paths,\n\t                                                               ts, detection_engine)))\n\t        _logger.info(\"Waiting for last tasks ...\")\n", "        for t in tasks:\n\t            t.get()\n\tdef macina(conf: DatasetConfig, asd, cop, ttype):\n\t    take_for_each_cat = math.floor(conf.offline.max_to_take/len(asd))\n\t    so_so_far = 0\n\t    for ii, (dataset_name, cat) in enumerate(asd.keys()):\n\t        take_for_each_pcap = math.floor(\n\t            take_for_each_cat/len(cop[dataset_name].categories[cat].captures))\n\t        if dataset_name not in conf.offline.datasets:\n\t            conf.offline.datasets[dataset_name] = TrainDatasetConfig()\n", "        if cat not in conf.offline.datasets[dataset_name].categories:\n\t            conf.offline.datasets[dataset_name].categories[cat] = TrainCategoryConfig(\n\t            )\n\t        so_far = 0\n\t        for i, (name, vals) in enumerate(sorted(cop[dataset_name].categories[cat].captures.items(),\n\t                                                key=lambda x: getattr(x[1], ttype))):\n\t            if name not in conf.offline.datasets[dataset_name].categories[cat].captures:\n\t                conf.offline.datasets[dataset_name].categories[cat].captures[name] = TrainBaseConfig(\n\t                )\n\t            taken = min(getattr(vals, ttype), take_for_each_pcap)\n", "            so_far += taken\n\t            if taken != take_for_each_pcap and i+1 != len(conf.preprocessed_configs[dataset_name].categories[cat].captures):\n\t                take_for_each_pcap = math.floor((take_for_each_cat - so_far) / (len(\n\t                    conf.preprocessed_configs[dataset_name].categories[cat].captures) - i - 1))\n\t            test_start = math.floor(\n\t                taken * (1 - conf.offline.test_percentage))\n\t            val_start = math.floor(\n\t                test_start * (1 - conf.offline.validation_percentage))\n\t            tmp = BaseConfig(\n\t                taken, val_start, test_start - val_start, taken - test_start)\n", "            setattr(\n\t                conf.offline.datasets[dataset_name].categories[cat].captures[name], ttype, tmp)\n\t            getattr(\n\t                conf.offline.datasets[dataset_name].categories[cat], ttype).update(tmp)\n\t            getattr(\n\t                conf.offline.datasets[dataset_name], ttype).update(tmp)\n\t            getattr(conf.offline, ttype).update(tmp)\n\t        so_so_far += so_far\n\t        if so_far != take_for_each_cat and ii+1 != len(asd):\n\t            take_for_each_cat = math.floor(\n", "                (conf.offline.max_to_take - so_so_far) / (len(asd)-ii-1))\n"]}
{"filename": "enid/__main__.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\timport argparse\n\timport importlib\n\timport os\n\tfrom .lib.definitions import DetectionEngine\n\tfrom .lib.utility import camel_to_snake, silence, set_seed\n\tif __name__ == '__main__':\n\t    silence()\n", "    set_seed()\n\t    de_with_main_list = DetectionEngine.list_all(only_main=True)\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument(\"operation\", help=\"Select the operation to perform\", type=str,\n\t                        choices=de_with_main_list + [x.replace(\".py\", \"\") for x in os.listdir(os.path.dirname(__file__))\n\t                                                     if not x.startswith(\"_\") and x.endswith(\".py\")\n\t                                                     and os.path.isfile(os.path.join(os.path.dirname(__file__), x))])\n\t    parser.add_argument(\"rest\", nargs=argparse.REMAINDER)\n\t    args = parser.parse_args().__dict__\n", "    if args[\"operation\"] not in de_with_main_list:\n\t        mod = importlib.import_module(\".{}\".format(\n\t            args[\"operation\"]), package=__package__)\n\t        mod.main(args[\"rest\"])\n\t    else:\n\t        args[\"operation\"] = camel_to_snake(args[\"operation\"])\n\t        parser = argparse.ArgumentParser(\n\t            formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t        parser.add_argument(\"action\", help=\"Main action\", type=str,\n\t                            choices=[x.replace(\".py\", \"\") for x in os.listdir(\n", "                                os.path.join(os.path.dirname(__file__), \"lib\", \"engines\", args[\"operation\"], \"main\"))\n\t                                if not x.startswith(\"_\") and x.endswith(\".py\")\n\t                                and os.path.isfile(\n\t                                os.path.join(os.path.dirname(__file__), \"lib\", \"engines\", args[\"operation\"], \"main\", x))])\n\t        parser.add_argument(\"rest\", nargs=argparse.REMAINDER)\n\t        args_nested = parser.parse_args(args[\"rest\"]).__dict__\n\t        mod = importlib.import_module(\".lib.engines.{}.main.{}\".format(\n\t            args[\"operation\"], args_nested[\"action\"]), package=__package__)\n\t        mod.main(args_nested[\"rest\"])\n"]}
{"filename": "enid/comparator.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tMain program to debug the online test results produced with the\n\tDebugLevel.ENHANCED. Given a certain threshold of packets provided,\n\tthis program outputs all the benign flows that have been erroneously\n\tclassified and their n° of following packets blocked, and the malicious\n\tsessions not detected and their n° packets that reached the application\n\tin the following intervals.\n", "\"\"\"\n\timport argparse\n\timport os\n\tfrom .datasetter import DatasetConfig\n\tfrom .lib.identifiers import str_to_key\n\tfrom .lib.utility import load_json_data\n\tdef _load_history(path):\n\t    s = load_json_data(path)\n\t    for k in s:\n\t        key_cls = str_to_key(s[k][\"analysis_state\"][\"current_key\"])\n", "        s[k][\"session_map\"] = {key_cls.create(\n\t            **j[\"key\"]): j[\"value\"] for j in s[k][\"session_map\"]}\n\t        s[k][\"black_map\"] = {key_cls.create(\n\t            **j[\"key\"]): j[\"value\"] for j in s[k][\"black_map\"]}\n\t    return s\n\tdef main(args_list):\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument(\n\t        \"files\", help=\"test history files to compare\", nargs=\"2+\", type=str)\n", "    parser.add_argument(\"-t\", \"--threshold\", type=int, default=0)\n\t    args = parser.parse_args(args_list).__dict__\n\t    files = {os.path.basename(x): _load_history(x) for x in args[\"files\"]}\n\t    malicious = {}\n\t    [malicious.update(DatasetConfig(**load_json_data(os.path.join(x, os.pardir,\n\t                      os.pardir, os.pardir, \"conf.json\"))).attackers) for x in args[\"files\"]]\n\t    already_handled = {}\n\t    timewindows = list(range(0, max(len(x) for x in files.values())))\n\t    for i, k in enumerate(timewindows):\n\t        seen_sess = set()\n", "        [seen_sess.update(v[k][\"session_map\"].keys()) for v in files.values()]\n\t        for s in seen_sess:\n\t            if s not in already_handled and all(s in v[k][\"session_map\"] for v in files.values()) and\\\n\t                (not all(v[k][\"session_map\"][s][\"prediction\"] > 0.5 for v in files.values()) or\n\t                 not all(v[k][\"session_map\"][s][\"prediction\"] < 0.5 for v in files.values())):\n\t                already_handled[s] = True\n\t                if getattr(s, \"dataset\", None):\n\t                    is_malicious_key = s.cast(\n\t                        malicious[s.dataset][0].__class__) in malicious[s.dataset]\n\t                else:\n", "                    is_malicious_key = any(\n\t                        s.cast(p[0].__class__) in p for p in malicious.values())\n\t                print(\"---------------------\")\n\t                print(\"Detected difference in time interval\", k)\n\t                print(f\"Key (is_ddos={is_malicious_key}):\", s)\n\t                print()\n\t                for k, v in files.items():\n\t                    if v[k][\"session_map\"][s][\"prediction\"] <= 0.5:\n\t                        continue\n\t                    fut_handled = sum(\n", "                        v[tw][\"black_map\"][s] if s in v[tw][\"black_map\"] else 0 for tw in timewindows[i+1:])\n\t                    if fut_handled < args[\"threshold\"]:\n\t                        continue\n\t                    print(\"File:\", k)\n\t                    print(\"SessionValue:\", v[k][\"session_map\"][s])\n\t                    print(\"Features:\", [(k[\"key\"], k[\"value\"])\n\t                          for k in v[k][\"analysis_state\"][\"current_features\"][\"value\"]])\n\t                    print(\"Future Packets Mitigated:\", fut_handled, \"in the following\", len(\n\t                        timewindows[i+1:]), \"time intervals\")\n\t                    print()\n", "                print(\"---------------------\")\n\t                input()\n"]}
{"filename": "enid/__init__.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n"]}
{"filename": "enid/plotter.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tMain file for creating plots of the achieved results.\n\tThis program can create all kinds of plots, according to the\n\tparameters of the Detection Model used and the configuration of the NIDS.\n\tIn particular, the following results can be plotted:\n\t1. Models complexity\n\t2. Models training history (loss and accuracy)\n", "3. Models features relevances\n\t4. Models train results\n\t5. Models train results detailed for each type of granularity (dataset/category/pcap)\n\t6. Test results of the various configurations\n\t7. Test results of the various configuration for each type of granularity\n\tTrain and Test (both offline and online) results can be plotted by condensing parameters\n\tand creating boxplot, in case of multiple dimensions of the Engine (e.g., packets P and features F)\n\t\"\"\"\n\timport argparse\n\timport math\n", "import multiprocessing\n\timport os\n\tfrom dataclasses import dataclass\n\tfrom multiprocessing.pool import ThreadPool\n\tfrom typing import Type\n\timport matplotlib.pyplot as plt\n\timport numpy as np\n\tfrom cycler import cycler\n\tfrom matplotlib.figure import Figure\n\tfrom matplotlib.lines import Line2D\n", "from .lib.definitions import DetectionEngine, FeaturesHolder\n\tfrom .lib.metrics import TestMetric, TrainMetric\n\tfrom .lib.utility import (create_dir, get_logger, handler,\n\t                          load_json_data, snake_to_camel)\n\tfrom .trainer import ModelConfig, DatasetConfig\n\t_logger = get_logger(__name__)\n\t@dataclass\n\tclass PlotArgs:\n\t    \"\"\"PlotArgs dataclass to contain personalised arguments for adjusting plots\"\"\"\n\t    logx: bool = False\n", "    logy: bool = False\n\t    fit: bool = False\n\t    offlegend: bool = False\n\t    hlegend: bool = False\n\t    seplegend: bool = False\n\t    minx: float = None\n\t    maxx: float = None\n\t    miny: float = None\n\t    maxy: float = None\n\t    xgrid: bool = True\n", "    ygrid: bool = True\n\t    figsizex: float = 4\n\t    figsizey: float = 3\n\t    ylabelchars: int = 35\n\t    xlabelchars: int = 35\n\t    style: str = \"science\"\n\t    def __post_init__(self):\n\t        plt.style.use(self.style)\n\t    def adjust(self, fig: Figure = None, ax: plt.Axes = None, xlabel: str = None, ylabel: str = None,\n\t               path: str = None, suptitle: str = None, title: str = None):\n", "        if ax:\n\t            if self.xgrid:\n\t                ax.grid(True, axis='x')\n\t            if self.ygrid:\n\t                ax.grid(True, axis='y')\n\t            if self.logy:\n\t                ax.set_yscale(\"log\")\n\t            if self.maxy is not None or self.miny is not None:\n\t                ax.set_ylim(top=self.maxy, bottom=self.miny)\n\t            if self.maxx is not None or self.minx is not None:\n", "                ax.set_xlim(right=self.maxx, left=self.minx)\n\t            if self.logx:\n\t                ax.set_xscale(\"log\")\n\t            if xlabel:\n\t                ax.set_xlabel(xlabel)\n\t            if ylabel:\n\t                ax.set_ylabel(ylabel)\n\t            if title:\n\t                ax.set_title(title)\n\t            if self.offlegend:\n", "                leg = ax.get_legend()\n\t                if leg:\n\t                    leg.remove()\n\t            else:\n\t                params = {}\n\t                if self.hlegend:\n\t                    params = {\n\t                        \"loc\": \"upper center\",\n\t                        \"ncol\": math.ceil(math.sqrt(len(ax.lines))) if not self.seplegend else len(ax.lines),\n\t                        \"bbox_to_anchor\": (0.5, 1.25) if not self.seplegend else None\n", "                    }\n\t                else:\n\t                    params = {\"loc\": \"center left\",\n\t                              \"ncol\": 1, \"bbox_to_anchor\": (1, 0.5)}\n\t                if self.seplegend:\n\t                    params.pop(\"loc\")\n\t                    params.pop(\"bbox_to_anchor\")\n\t                ax.legend(**params)\n\t                if self.seplegend:\n\t                    label_params = ax.get_legend_handles_labels()\n", "                    figl = plt.figure(figsize=(3, 2))\n\t                    figl.legend(*label_params, loc=\"center\", ncol=params[\"ncol\"], bbox_to_anchor=(0.5, 0.5),\n\t                                fontsize=40, markerscale=4, handlelength=1.5)\n\t                    figl.savefig(f\"{path}_legend.pdf\",\n\t                                 bbox_inches='tight', pad_inches=0.0)\n\t                    plt.close(figl)\n\t                    ax.get_legend().remove()\n\t        if fig:\n\t            if self.figsizex:\n\t                fig.set_figwidth(self.figsizex)\n", "            if self.figsizey:\n\t                fig.set_figheight(self.figsizey)\n\t            if suptitle:\n\t                fig.suptitle(suptitle)\n\t            if path:\n\t                fig.savefig(f\"{path}.pdf\")\n\t                plt.close(fig)\n\tdef _labelify(params, exclude):\n\t    \"\"\"Function to transform Detection model parameters into symbols\n\t    E.g.: features -> f; packets_per_session -> p\n", "    \"\"\"\n\t    return '-'.join(f\"{v}\" + \"\\\\textit{\" + k[0] + \"}\" for k, v in params.items() if k != exclude)\n\tdef _plottify_metric_name(name: str, max_len):\n\t    \"\"\"Method to adjust metric name for plotting according to the length provided\"\"\"\n\t    name = name.replace(\"percentage\", \"_(\\\\%)_\")\n\t    name = name.replace(\"_per_\", \"_/_\")\n\t    name = snake_to_camel(name, join_char=' ')\n\t    for x in (\"Tpr\", \"Tnr\", \"Fpr\", \"Fnr\"):\n\t        name = name.replace(x, x.upper())\n\t    if len(name) > max_len:\n", "        try:\n\t            post = name.index(\" \", max_len, len(name))\n\t        except ValueError:\n\t            post = len(name)\n\t        name = name[:post] + \"\\n\" + name[post:]\n\t    return name\n\tdef _plot_features_relevance(c, de: Type[DetectionEngine], path: str, plot_args: PlotArgs):\n\t    name = de.model_name(**c)\n\t    _logger.info(f\"Starting plotting relevance of {name}\")\n\t    rel: FeaturesHolder = de.features_holder_cls(**load_json_data(os.path.join(\n", "        path, \"models\", name, \"relevance.json\")))\n\t    if not rel:\n\t        _logger.info(f\"No relevance for {name}\")\n\t        return\n\t    xx, names = [], []\n\t    for x in de.features_holder_cls.ALLOWED:\n\t        asd = rel.get_feature_value(x)\n\t        if asd is not None and not isinstance(asd, (list, tuple)):\n\t            xx.append(asd)\n\t            names.append(\"\\\\textbf{\" + x.__name__ + \"}\")\n", "        else:\n\t            xx.append(0)\n\t            names.append(x.__name__)\n\t    fig, ax = plt.subplots()\n\t    ax.barh(names, xx)\n\t    plot_args.adjust(fig=fig, ax=ax, xlabel=\"Activation Score\",\n\t                     path=os.path.join(path, \"charts\", \"models\", \"features_relevance\", name))\n\t    _logger.info(f\"Finished plotting relevance of {name}\")\n\tdef _plot_train_histories(c, de: DetectionEngine, path: str, plot_args: PlotArgs):\n\t    name = de.model_name(**c)\n", "    _logger.info(f\"Starting plotting histories of {name}\")\n\t    hs = load_json_data(os.path.join(path, \"models\", name, \"history.json\"))\n\t    if not hs:\n\t        _logger.info(f\"No history for {name}\")\n\t        return\n\t    fig, ax = plt.subplots(2, 1, sharex=True)\n\t    fig.subplots_adjust(hspace=.0)\n\t    plot_args.offlegend = True\n\t    ax[0].plot(hs['loss'], 'b', label=\"Train\")\n\t    ax[0].plot(hs[\"val_loss\"], 'r', label=\"Validation\")\n", "    plot_args.adjust(fig=fig, ax=ax[0], ylabel='Loss')\n\t    ax[1].plot(hs['accuracy'], 'b', label=\"Train\")\n\t    ax[1].plot(hs[\"val_accuracy\"], 'r', label=\"Validation\")\n\t    plot_args.adjust(fig=fig, ax=ax[1], xlabel=\"Epocs\", ylabel='Accuracy')\n\t    handles, labels = ax[0].get_legend_handles_labels()\n\t    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(\n\t        0.5, 1), ncol=len(labels), bbox_transform=fig.transFigure)\n\t    plot_args.adjust(fig=fig, path=os.path.join(\n\t        path, \"charts\", \"models\", \"histories\", name))\n\t    _logger.info(f\"Finished plotting histories of {name}\")\n", "def _plot_models_complexity(agg_by_name, models_conf: ModelConfig, path, plot_args: PlotArgs):\n\t    \"\"\"Function to plot the model complexity in terms of trainable parameters\"\"\"\n\t    _logger.info(\n\t        f\"Started plotting complexity using {agg_by_name} as x-axis\")\n\t    store_path = os.path.join(\n\t        os.path.dirname(os.path.normpath(path)),\n\t        \"charts\", \"models\", \"complexity\", f\"trainable_by_{agg_by_name}\")\n\t    fig, ax = plt.subplots()\n\t    values = sorted(getattr(models_conf.train_params, agg_by_name))\n\t    values_tick = list(range(len(values)))\n", "    all_combs = models_conf.train_params.all_train_combs(exclude=agg_by_name)\n\t    ax.set_prop_cycle(cycler(linestyle=[\":\"]*len(all_combs)) +\n\t                      cycler(color=[plt.cm.nipy_spectral(i) for i in np.linspace(0, 1, len(all_combs))]) +\n\t                      cycler(marker=sorted([x for x, v in Line2D.markers.items() if v != \"nothing\" and x not in (\"|\", \"_\")],\n\t                                           reverse=True, key=lambda x: str(x))[:len(all_combs)]))\n\t    def asd(*args):\n\t        name = models_conf.detection_engine.model_name(**{\n\t            agg_by_name: args[1],\n\t            **args[0]})\n\t        return args[0], args[1], models_conf.detection_engine.parameters(\n", "            **load_json_data(os.path.join(path, name, \"params.json\")))\n\t    with ThreadPool() as pool:\n\t        r = pool.starmap(asd, [(c, v) for c in all_combs for v in values])\n\t    for c in all_combs:\n\t        tmp = []\n\t        for v in values:\n\t            x = next(x for x in r if x[0] == c and x[1] == v)\n\t            tmp.append(x[2])\n\t        ax.plot(values_tick, tmp, label=_labelify(c, agg_by_name))\n\t    ax.set_xticks(values_tick)\n", "    ax.set_xticklabels(values)\n\t    ax.tick_params(axis='x', which='minor', bottom=False, top=False)\n\t    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\t    plot_args.adjust(fig=fig, ax=ax, xlabel=\"\\\\textit{\" + agg_by_name[0] + \"}\",\n\t                     ylabel=\"Trainable Parameters\", path=store_path)\n\t    _logger.info(\n\t        f\"Finished plotting complexity using {agg_by_name} as x-axis\")\n\tdef _plot_results_metrics(agg_by_name, models_conf: ModelConfig,\n\t                          path, metric, plot_args: PlotArgs, add_name=\"\", depth=tuple()):\n\t    \"\"\"Function used to print result metrics for both offline and online testing\"\"\"\n", "    _logger.info(\n\t        f\"Started plotting metric {metric} depth={depth} using {agg_by_name} as x-axis\")\n\t    store_name = os.path.join(os.path.dirname(os.path.normpath(\n\t        path)), \"charts\", os.path.basename(path), \"results\", add_name)\n\t    for x in depth:\n\t        store_name = os.path.join(store_name, x)\n\t    store_name = os.path.join(\n\t        store_name, f\"total_by_{agg_by_name}\" if agg_by_name else \"\", metric)\n\t    fig, ax = plt.subplots()\n\t    values = sorted(getattr(models_conf.train_params, agg_by_name))\n", "    m_name = _plottify_metric_name(metric, plot_args.ylabelchars)\n\t    values_tick = values if plot_args.logx else list(range(len(values)))\n\t    all_combs = models_conf.train_params.all_train_combs(exclude=agg_by_name)\n\t    ax.set_prop_cycle(cycler(linestyle=[\":\"]*len(all_combs)) +\n\t                      cycler(color=[plt.cm.nipy_spectral(i) for i in np.linspace(0, 1, len(all_combs))]) +\n\t                      cycler(marker=(sorted([x for x, v in Line2D.markers.items() if v != \"nothing\" and x != \"|\"],\n\t                                            reverse=True, key=lambda x: str(x))*len(all_combs))[:len(all_combs)]))\n\t    for c in all_combs:\n\t        tmp = []\n\t        for v in values:\n", "            name = models_conf.detection_engine.model_name(\n\t                **c, **{agg_by_name: v})\n\t            j = load_json_data(os.path.join(\n\t                path, name, add_name, \"results.json\"))\n\t            if not depth:\n\t                tmp.append(j[metric])\n\t            elif len(depth) == 1:\n\t                tmp.append(j[\"datasets\"][depth[0]][metric])\n\t            elif len(depth) == 2:\n\t                tmp.append(j[\"datasets\"][depth[0]]\n", "                           [\"categories\"][depth[1]][metric])\n\t            else:\n\t                tmp.append(j[\"datasets\"][depth[0]][\"categories\"]\n\t                           [depth[1]][\"captures\"][depth[2]][metric])\n\t        if plot_args.fit:\n\t            aasd = ax.scatter(values, tmp, label=_labelify(c, agg_by_name))\n\t            ax.plot(values, np.polyval(np.polyfit(values, tmp, 2),\n\t                    values), color=aasd.get_facecolor()[0])\n\t        else:\n\t            ax.plot(values_tick, tmp, label=_labelify(c, agg_by_name))\n", "    ax.set_xticks(values_tick)\n\t    ax.set_xticklabels(values)\n\t    ax.tick_params(axis='x', which='minor', bottom=False, top=False)\n\t    plot_args.adjust(\n\t        fig=fig, ax=ax, xlabel=\"\\\\textit{\" + agg_by_name[0] + \"}\", ylabel=m_name, path=store_name)\n\t    _logger.info(\n\t        f\"Finished plotting metric {metric} depth={depth} agg by {agg_by_name}\")\n\tdef _plot_results_metrics_boxplot(agg_by_name, models_conf: ModelConfig,\n\t                                  path, metric, test_name, plot_args: PlotArgs, depth=tuple()):\n\t    \"\"\"Function for plotting resulting metrics condensed \"\"\"\n", "    _logger.info(f\"Started Plotting boxplot of {metric}\")\n\t    fig, ax = plt.subplots()\n\t    vals = []\n\t    m_name = _plottify_metric_name(metric, plot_args.ylabelchars)\n\t    asd = sorted(getattr(models_conf.train_params, agg_by_name))\n\t    asd_tick = asd if plot_args.logx else list(range(len(asd)))\n\t    for v in sorted(getattr(models_conf.train_params, agg_by_name)):\n\t        tmp = []\n\t        for c in [x for x in models_conf.train_params.all_train_combs() if x[agg_by_name] == v]:\n\t            name = models_conf.detection_engine.model_name(**c)\n", "            j = load_json_data(os.path.join(\n\t                path, test_name, name, \"results.json\"))\n\t            if not depth:\n\t                tmp.append(j[metric])\n\t            elif len(depth) == 1:\n\t                tmp.append(j[\"datasets\"][depth[0]][metric])\n\t            elif len(depth) == 2:\n\t                tmp.append(j[\"datasets\"][depth[0]]\n\t                           [\"categories\"][depth[1]][metric])\n\t            else:\n", "                tmp.append(j[\"datasets\"][depth[0]][\"categories\"]\n\t                           [depth[1]][\"captures\"][depth[2]][metric])\n\t        vals.append(tmp)\n\t    ret = ax.boxplot(vals, positions=asd_tick)\n\t    if plot_args.fit:\n\t        xs = asd\n\t        ys = np.array([q.get_ydata()[0] for q in ret['medians']])\n\t        ys = ys[~np.isnan(ys)]\n\t        polyval = np.polyval(np.polyfit(xs, ys, 2), xs)\n\t        ax.plot(asd_tick, [polyval[q] for q in asd_tick])\n", "    for v, vv, fl in zip(asd, vals, ret['fliers']):\n\t        off = -0.5\n\t        for c, vvv in zip([x for x in models_conf.train_params.all_train_combs() if x[agg_by_name] == v], vv):\n\t            if vvv in fl.get_ydata():\n\t                ax.text(fl.get_xdata()[0]+off, vvv,\n\t                        _labelify(c, agg_by_name), va='center', ha='left')\n\t                off *= -1\n\t            off = -0.5 if off < 0 else 0.25\n\t    ax.minorticks_off()\n\t    ax.set_xticks(asd_tick)\n", "    ax.set_xticklabels([str(k) for k in asd])\n\t    path = os.path.join(path, \"charts\", test_name, \"results\")\n\t    for x in depth:\n\t        path = os.path.join(path, x)\n\t    path = os.path.join(path, f\"condensed_by_{agg_by_name}\", metric)\n\t    plot_args.adjust(\n\t        fig=fig, ax=ax, xlabel=\"\\\\textit{\" + agg_by_name[0] + \"}\", ylabel=m_name, path=path)\n\t    _logger.info(f\"Finished Plotting boxplot of {metric} agg by {agg_by_name}\")\n\tdef main(args_list):\n\t    # registering cli parameters\n", "    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\n\t        'de_models_dir', help='path to the directory containing results', type=str)\n\t    parser.add_argument(\n\t        '-mf', '--model-complexity', help='display features relevance', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-fr', '--features-relevance', help='display features relevance', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-th', '--train-histories', help='display train histories', action=\"store_true\")\n\t    parser.add_argument(\n", "        '-tr', '--train-results', help='display train results', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-trd', '--train-results-detailed', help='display chart per-capture', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-ts', '--test-results', help='display test results', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-tsd', '--test-results-detailed', help='display chart per-capture in test', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-tl', '--transfer-learning', help='transfer learning', action=\"store_true\")\n\t    parser.add_argument(\n", "        '-tld', '--transfer-learning-detailed', help='transfer learning detailed', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-b', '--boxplot', help='condense in boxplot', action=\"store_true\")\n\t    args = parser.parse_args(args_list).__dict__\n\t    dataset_conf: DatasetConfig = DatasetConfig(\n\t        **load_json_data(os.path.join(args[\"de_models_dir\"], os.pardir, \"conf.json\")))\n\t    models_conf: ModelConfig = ModelConfig(\n\t        **load_json_data(os.path.join(args[\"de_models_dir\"], \"models\", \"conf.json\")))\n\t    star_tasks = []\n\t    plot_args = PlotArgs()\n", "    if args[\"model_complexity\"]:\n\t        # print complexity of the model in terms of trainable parameters\n\t        tmp = os.path.join(args[\"de_models_dir\"], \"models\")\n\t        for k in models_conf.train_params.train_combs():\n\t            if len(getattr(models_conf.train_params, k)) <= 1:\n\t                continue\n\t            create_dir(os.path.join(\n\t                args[\"de_models_dir\"], \"charts\", \"models\", \"complexity\"))\n\t            star_tasks.append(\n\t                (_plot_models_complexity, (k, models_conf, tmp, plot_args)))\n", "    if args[\"train_histories\"] and models_conf:\n\t        # print train histories, showing loss and accuracy of the train vs validation set\n\t        create_dir(os.path.join(\n\t            args[\"de_models_dir\"], \"charts\", \"models\", \"histories\"))\n\t        [star_tasks.append((_plot_train_histories, (c, models_conf.detection_engine, args[\"de_models_dir\"], plot_args)))\n\t         for c in models_conf.train_params.all_train_combs()]\n\t    if args[\"features_relevance\"] and models_conf:\n\t        # print relevance of each feature in each configuration of the NIDS\n\t        create_dir(os.path.join(\n\t            args[\"de_models_dir\"], \"charts\", \"models\", \"features_relevance\"))\n", "        [star_tasks.append((_plot_features_relevance, (c, models_conf.detection_engine, args[\"de_models_dir\"], plot_args)))\n\t         for c in models_conf.train_params.all_train_combs()]\n\t    if args[\"train_results\"]:\n\t        # print train results for each parameter (e.g., feature F in the x-axes, packets P in the x-axes)\n\t        tmp = os.path.join(args[\"de_models_dir\"], \"models\")\n\t        for k in models_conf.train_params.train_combs():\n\t            if len(getattr(models_conf.train_params, k)) <= 1:\n\t                continue\n\t            create_dir(os.path.join(\n\t                args[\"de_models_dir\"], \"charts\", \"models\", \"results\", f\"total_by_{k}\"))\n", "            [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args)))\n\t                for m in TrainMetric.get_metrics()]\n\t            if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                       for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                # print train results condensing plots by the parameters of interest\n\t                # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                # but other different parameters, such as all packets P)\n\t                create_dir(os.path.join(\n\t                    args[\"de_models_dir\"], \"charts\", \"models\", \"results\", f\"condensed_by_{k}\"))\n\t                [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n", "                                                                    m, \"models\", plot_args)))\n\t                 for m in TrainMetric.get_metrics()]\n\t    if args[\"train_results_detailed\"]:\n\t        tmp = os.path.join(args[\"de_models_dir\"], \"models\")\n\t        for k in models_conf.train_params.train_combs():\n\t            if len(getattr(models_conf.train_params, k)) <= 1:\n\t                continue\n\t            # print train results detailed at the DATASET granularity for each parameter\n\t            # (e.g., feature F in the x-axes, packets P in the x-axes)\n\t            for dataset_name, v in dataset_conf.offline.datasets.items():\n", "                create_dir(os.path.join(\n\t                    args[\"de_models_dir\"], \"charts\", \"models\", \"results\", dataset_name, f\"total_by_{k}\"))\n\t                [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args, \"\", (dataset_name,))))\n\t                    for m in TrainMetric.get_metrics()]\n\t                # print train results detailed at the DATASET granularity condensing plots by the parameters of interest\n\t                # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                # but other different parameters, such as all packets P)\n\t                if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                           for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                    create_dir(os.path.join(\n", "                        args[\"de_models_dir\"], \"charts\", \"models\", \"results\", dataset_name, f\"condensed_by_{k}\"))\n\t                    [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n\t                                                                        m, \"models\", plot_args, (dataset_name,))))\n\t                     for m in TrainMetric.get_metrics()]\n\t                # print train results detailed at the CATEGORY granularity for each parameter\n\t                # (e.g., feature F in the x-axes, packets P in the x-axes)\n\t                for c, vv in v.categories.items():\n\t                    create_dir(os.path.join(\n\t                        args[\"de_models_dir\"], \"charts\", \"models\", \"results\", dataset_name, c, f\"total_by_{k}\"))\n\t                    [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args, \"\", (dataset_name, c))))\n", "                        for m in TrainMetric.get_metrics()]\n\t                    # print train results detailed at the CATEGORY granularity condensing plots by the parameters of interest\n\t                    # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                    # but other different parameters, such as all packets P)\n\t                    if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                               for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                        create_dir(os.path.join(\n\t                            args[\"de_models_dir\"], \"charts\", \"models\", \"results\", dataset_name, c, f\"condensed_by_{k}\"))\n\t                        [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n\t                                                                            m, \"models\", plot_args, (dataset_name, c))))\n", "                         for m in TrainMetric.get_metrics()]\n\t                    # print train results detailed at the PCAP granularity for each parameter\n\t                    # (e.g., feature F in the x-axes, packets P in the x-axes)\n\t                    for capture in vv.captures:\n\t                        create_dir(os.path.join(\n\t                            args[\"de_models_dir\"], \"charts\", \"models\", \"results\", dataset_name, c, capture, f\"total_by_{k}\"))\n\t                        [star_tasks.append((_plot_results_metrics,\n\t                                            (k, models_conf, tmp, m, plot_args, \"\", (dataset_name, c, capture))))\n\t                            for m in TrainMetric.get_metrics()]\n\t                        # print train results detailed at the PCAP granularity condensing plots by the parameters of interest\n", "                        # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                        # but other different parameters, such as all packets P)\n\t                        if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                                   for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                            create_dir(os.path.join(\n\t                                args[\"de_models_dir\"], \"charts\", \"models\", \"results\", dataset_name,\n\t                                c, capture, f\"condensed_by_{k}\"))\n\t                            [star_tasks.append((_plot_results_metrics_boxplot,\n\t                                                (k, models_conf, args[\"de_models_dir\"],\n\t                                                 m, \"models\", plot_args, (dataset_name, c, capture))))\n", "                             for m in TrainMetric.get_metrics()]\n\t    if args[\"test_results\"]:\n\t        # look for folder with results of either one of the two test types (NORMAL and THROUGHPUT)\n\t        for x in os.listdir(args[\"de_models_dir\"]):\n\t            tmp = os.path.join(args[\"de_models_dir\"], x)\n\t            if not os.path.isdir(tmp) or (x != \"normal_test\" and x != \"throughput_test\") or\\\n\t                    not os.path.isfile(os.path.join(tmp, \"conf.json\")):\n\t                continue\n\t            # print test results for each parameter (e.g., feature F in the x-axes, packets P in the x-axes)\n\t            for k in models_conf.train_params.train_combs():\n", "                if len(getattr(models_conf.train_params, k)) <= 1:\n\t                    continue\n\t                create_dir(os.path.join(\n\t                    args[\"de_models_dir\"], \"charts\", x, \"results\", f\"total_by_{k}\"))\n\t                [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args)))\n\t                    for m in TestMetric.get_metrics()]\n\t                # print test results condensing plots by the parameters of interest\n\t                # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                # but other different parameters, such as all packets P)\n\t                if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n", "                                           for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                    create_dir(os.path.join(\n\t                        args[\"de_models_dir\"], \"charts\", x, \"results\", f\"condensed_by_{k}\"))\n\t                    [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n\t                                                                        m, x, plot_args)))\n\t                     for m in TestMetric.get_metrics()]\n\t    if args[\"test_results_detailed\"]:\n\t        # look for folder with results of either one of the two test types (NORMAL and THROUGHPUT)\n\t        for x in os.listdir(args[\"de_models_dir\"]):\n\t            tmp = os.path.join(args[\"de_models_dir\"], x)\n", "            if not os.path.isdir(tmp) or (x != \"normal_test\" and x != \"throughput_test\") or\\\n\t                    not os.path.isfile(os.path.join(tmp, \"conf.json\")):\n\t                continue\n\t            # print test results for each parameter (e.g., feature F in the x-axes, packets P in the x-axes)\n\t            for k in models_conf.train_params.train_combs():\n\t                if len(getattr(models_conf.train_params, k)) <= 1:\n\t                    continue\n\t                for dataset_name, v in dataset_conf.online.datasets.items():\n\t                    create_dir(os.path.join(\n\t                        args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, f\"total_by_{k}\"))\n", "                    [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args, \"\", (dataset_name,))))\n\t                        for m in TestMetric.get_metrics()]\n\t                    # print test results detailed at the DATASET granularity condensing plots by the parameters of interest\n\t                    # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                    # but other different parameters, such as all packets P)\n\t                    if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                               for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                        create_dir(os.path.join(\n\t                            args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, f\"condensed_by_{k}\"))\n\t                        [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n", "                                                                            m, x, plot_args, (dataset_name,))))\n\t                         for m in TestMetric.get_metrics()]\n\t                    # print test results detailed at the CATEGORY granularity for each parameter\n\t                    # (e.g., feature F in the x-axes, packets P in the x-axes)\n\t                    for c, vv in v.categories.items():\n\t                        create_dir(os.path.join(\n\t                            args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, c, f\"total_by_{k}\"))\n\t                        [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args, \"\", (dataset_name, c))))\n\t                            for m in TestMetric.get_metrics()]\n\t                        # print test results detailed at the CATEGORY granularity condensing plots by the parameters\n", "                        # of interest (e.g., each box in the boxplot refers to a specific features F' and all models\n\t                        # with that F' but other different parameters, such as all packets P)\n\t                        if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                                   for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                            create_dir(os.path.join(\n\t                                args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, c, f\"condensed_by_{k}\"))\n\t                            [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n\t                                                                                m, x, plot_args, (dataset_name, c))))\n\t                             for m in TestMetric.get_metrics()]\n\t                        # print test results detailed at the PCAP granularity for each parameter\n", "                        # (e.g., feature F in the x-axes, packets P in the x-axes)\n\t                        for capture in vv.captures:\n\t                            create_dir(os.path.join(\n\t                                args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, c, capture, f\"total_by_{k}\"))\n\t                            [star_tasks.append((_plot_results_metrics,\n\t                                                (k, models_conf, tmp, m, plot_args, \"\", (dataset_name, c, capture))))\n\t                                for m in TestMetric.get_metrics()]\n\t                            # print test results detailed at the PCAP granularity condensing plots by the parameters\n\t                            # of interest (e.g., each box in the boxplot refers to a specific features F' and\n\t                            # all models with that F' but other different parameters, such as all packets P)\n", "                            if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                                       for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                                create_dir(os.path.join(\n\t                                    args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name,\n\t                                    c, capture, f\"condensed_by_{k}\"))\n\t                                [star_tasks.append((_plot_results_metrics_boxplot,\n\t                                                    (k, models_conf, args[\"de_models_dir\"],\n\t                                                     m, x, plot_args, (dataset_name, c, capture))))\n\t                                 for m in TestMetric.get_metrics()]\n\t    if args[\"transfer_learning\"]:\n", "        # look for folder with results of either a transfer learning\n\t        for x in os.listdir(args[\"de_models_dir\"]):\n\t            tmp = os.path.join(args[\"de_models_dir\"], x)\n\t            if not os.path.isdir(tmp) or not x.startswith(\"transfer\"):\n\t                continue\n\t            # print test results for each parameter (e.g., feature F in the x-axes, packets P in the x-axes)\n\t            for k in models_conf.train_params.train_combs():\n\t                if len(getattr(models_conf.train_params, k)) <= 1:\n\t                    continue\n\t                create_dir(os.path.join(\n", "                    args[\"de_models_dir\"], \"charts\", x, \"results\", f\"total_by_{k}\"))\n\t                [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args)))\n\t                    for m in TrainMetric.get_metrics()]\n\t                # print test results condensing plots by the parameters of interest\n\t                # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                # but other different parameters, such as all packets P)\n\t                if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                           for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                    create_dir(os.path.join(\n\t                        args[\"de_models_dir\"], \"charts\", x, \"results\", f\"condensed_by_{k}\"))\n", "                    [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n\t                                                                        m, x, plot_args)))\n\t                     for m in TrainMetric.get_metrics()]\n\t    if args[\"transfer_learning_detailed\"]:\n\t        # look for folder with results of either one of the two test types (NORMAL and THROUGHPUT)\n\t        for x in os.listdir(args[\"de_models_dir\"]):\n\t            tmp = os.path.join(args[\"de_models_dir\"], x)\n\t            if not os.path.isdir(tmp) or not x.startswith(\"transfer\"):\n\t                continue\n\t            other_conf = DatasetConfig(\n", "                **load_json_data(os.path.join(tmp, \"conf.json\")))\n\t            # print test results for each parameter (e.g., feature F in the x-axes, packets P in the x-axes)\n\t            for k in models_conf.train_params.train_combs():\n\t                if len(getattr(models_conf.train_params, k)) <= 1:\n\t                    continue\n\t                for dataset_name, v in other_conf.offline.datasets.items():\n\t                    create_dir(os.path.join(\n\t                        args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, f\"total_by_{k}\"))\n\t                    [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args, \"\", (dataset_name,))))\n\t                        for m in TrainMetric.get_metrics()]\n", "                    # print test results detailed at the DATASET granularity condensing plots by the parameters of interest\n\t                    # (e.g., each box in the boxplot refers to a specific features F' and all models with that F'\n\t                    # but other different parameters, such as all packets P)\n\t                    if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                               for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                        create_dir(os.path.join(\n\t                            args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, f\"condensed_by_{k}\"))\n\t                        [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n\t                                                                            m, x, plot_args, (dataset_name,))))\n\t                         for m in TrainMetric.get_metrics()]\n", "                    # print test results detailed at the CATEGORY granularity for each parameter\n\t                    # (e.g., feature F in the x-axes, packets P in the x-axes)\n\t                    for c, vv in v.categories.items():\n\t                        create_dir(os.path.join(\n\t                            args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, c, f\"total_by_{k}\"))\n\t                        [star_tasks.append((_plot_results_metrics, (k, models_conf, tmp, m, plot_args, \"\", (dataset_name, c))))\n\t                            for m in TrainMetric.get_metrics()]\n\t                        # print test results detailed at the CATEGORY granularity condensing plots by the parameters\n\t                        # of interest (e.g., each box in the boxplot refers to a specific features F' and all models\n\t                        # with that F' but other different parameters, such as all packets P)\n", "                        if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                                   for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n\t                            create_dir(os.path.join(\n\t                                args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, c, f\"condensed_by_{k}\"))\n\t                            [star_tasks.append((_plot_results_metrics_boxplot, (k, models_conf, args[\"de_models_dir\"],\n\t                                                                                m, x, plot_args, (dataset_name, c))))\n\t                             for m in TrainMetric.get_metrics()]\n\t                        # print test results detailed at the PCAP granularity for each parameter\n\t                        # (e.g., feature F in the x-axes, packets P in the x-axes)\n\t                        for capture in vv.captures:\n", "                            create_dir(os.path.join(\n\t                                args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name, c, capture, f\"total_by_{k}\"))\n\t                            [star_tasks.append((_plot_results_metrics,\n\t                                                (k, models_conf, tmp, m, plot_args, \"\", (dataset_name, c, capture))))\n\t                                for m in TrainMetric.get_metrics()]\n\t                            # print test results detailed at the PCAP granularity condensing plots by the parameters\n\t                            # of interest (e.g., each box in the boxplot refers to a specific features F' and\n\t                            # all models with that F' but other different parameters, such as all packets P)\n\t                            if args[\"boxplot\"] and sum(len(getattr(models_conf.train_params, kk))\n\t                                                       for kk in models_conf.train_params.train_combs() if kk != k) > 1:\n", "                                create_dir(os.path.join(\n\t                                    args[\"de_models_dir\"], \"charts\", x, \"results\", dataset_name,\n\t                                    c, capture, f\"condensed_by_{k}\"))\n\t                                [star_tasks.append((_plot_results_metrics_boxplot,\n\t                                                    (k, models_conf, args[\"de_models_dir\"],\n\t                                                     m, x, plot_args, (dataset_name, c, capture))))\n\t                                 for m in TrainMetric.get_metrics()]\n\t    with multiprocessing.Pool(maxtasksperchild=1) as pool:\n\t        pool.starmap(handler, star_tasks)\n"]}
{"filename": "enid/preprocesser.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tMain file for Processing input network captures into data according to the specified\n\tDetection Model and parameters. This creates the files ready to be used for the creation of the dataset.\n\tFor each capture/category/dataset, this program records the n° of benign and malicious samples and\n\tthe respective network packets, information used later during the dataset creation.\n\tA key for grouping sessions needs to be chosen, whether considering only L3 or also L4.\n\t\"\"\"\n", "import argparse\n\timport multiprocessing\n\timport os\n\tfrom dataclasses import dataclass, field\n\tfrom typing import Any, Dict, Type\n\tfrom .lib import ATTACK_LABELS\n\tfrom .lib.definitions import DetectionEngine, TestType, TrafficAnalyser\n\tfrom .lib.identifiers import BaseKey, str_to_key\n\tfrom .lib.utility import (UpdatableDataclass, add_param_to_parser,\n\t                          all_subclasses, create_dir, dump_json_data,\n", "                          get_logger, get_param_for_method, load_json_data)\n\tfrom .splitter import CaptureConfig\n\t_logger = get_logger(__name__)\n\t@dataclass\n\tclass PcapConfig:\n\t    benign: int = 0\n\t    malicious: int = 0\n\t    unique_benign: int = 0\n\t    unique_malicious: int = 0\n\t    benign_packets: int = 0\n", "    malicious_packets: int = 0\n\t    duration: int = 0\n\t@dataclass\n\tclass CategoryConfig(PcapConfig, UpdatableDataclass):\n\t    captures: Dict[str, PcapConfig] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        for k in list(self.captures.keys()):\n\t            self.captures[k] = PcapConfig(**self.captures[k])\n\t@dataclass\n\tclass PreprocessedConfig(PcapConfig, UpdatableDataclass):\n", "    family: str = \"\"\n\t    time_window: int = 0\n\t    key_cls: Type[BaseKey] = None\n\t    detection_engine: Type[DetectionEngine] = None\n\t    additional_params: Dict[str, Any] = field(default_factory=dict)\n\t    categories: Dict[str, CategoryConfig] = field(default_factory=dict)\n\t    captures_config: CaptureConfig = field(default_factory=CaptureConfig)\n\t    def __post_init__(self):\n\t        if isinstance(self.captures_config, dict):\n\t            self.captures_config = CaptureConfig(**self.captures_config)\n", "        for k in list(self.categories.keys()):\n\t            self.categories[k] = CategoryConfig(**self.categories[k])\n\t        if isinstance(self.detection_engine, str):\n\t            self.detection_engine = DetectionEngine.import_de(\n\t                self.detection_engine)\n\t        if isinstance(self.key_cls, str):\n\t            self.key_cls = str_to_key(self.key_cls)\n\tdef process_pcap(target_dir, cap, dataset, cat, pcap, time_window, additional_params,\n\t                 attackers, de: Type[DetectionEngine], key_cls: Type[BaseKey]):\n\t    \"\"\"Function for parsing a pcap\"\"\"\n", "    target_ds = os.path.join(target_dir, cat, pcap)\n\t    pcap_file = os.path.join(cap, cat, pcap)\n\t    if not os.path.isfile(pcap_file):\n\t        return None\n\t    t = de.traffic_analyser_cls(\n\t        de, attackers, time_window, key_cls, TestType.PROCESSING,\n\t        dump_path=target_ds,\n\t        **additional_params)\n\t    _logger.info(f\"Starting processing {pcap_file}\")\n\t    # Creating a fake traffic analysers with no Filtering and Classificator components.\n", "    tot_time = TrafficAnalyser.generate_packets(pcap_file, t, pcap_file, labels=(dataset, cat, pcap))\n\t    _logger.info(f\"Finished processing {pcap_file}\")\n\t    p = PcapConfig(t.processing_stats.tot_benign, t.processing_stats.tot_malicious,\n\t                   t.processing_stats.unique_benign, t.processing_stats.unique_malicious,\n\t                   t.processing_stats.tot_benign_packets, t.processing_stats.tot_malicious_packets,\n\t                   duration=tot_time)\n\t    return target_dir, cat, pcap, p\n\tdef main(args_list):\n\t    # registering cli args, shown with the -h flag\n\t    parser = argparse.ArgumentParser(\n", "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument('time_window',\n\t                        help='time window of interest in nanoseconds', type=int)\n\t    parser.add_argument('key',\n\t                        help='Session Key to use', choices=[x.__name__ for x in all_subclasses(BaseKey)], type=str)\n\t    parser.add_argument(\n\t        '-p', '--parallel', help='number of parallel executions', type=int, default=os.cpu_count())\n\t    parser.add_argument(\"detection_engine\", help=\"Select the detection engine to use\", type=str,\n\t                        choices=DetectionEngine.list_all())\n\t    parser.add_argument(\"rest\", nargs=argparse.REMAINDER)\n", "    args = parser.parse_args(args_list).__dict__\n\t    de: Type[DetectionEngine] = DetectionEngine.import_de(\n\t        args[\"detection_engine\"])\n\t    # registering Detection Model - specific arguments\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    params_for_method = get_param_for_method(\n\t        de.model_name, exclude_super_cls=DetectionEngine)\n\t    for pname, (ptype, pdef) in params_for_method.items():\n\t        add_param_to_parser(parser, pname, ptype, pdef, \"Parameter\")\n", "    parser.add_argument(\n\t        'captures', help='capture directories', type=str, nargs=\"+\")\n\t    args.update(parser.parse_args(args[\"rest\"]).__dict__)\n\t    additional_params = {k: args[k] for k in params_for_method}\n\t    key_cls = str_to_key(args[\"key\"])\n\t    star_tasks = []\n\t    prep_configs: Dict[str, PreprocessedConfig] = {}\n\t    for cap in args[\"captures\"]:\n\t        dataset = os.path.basename(os.path.normpath(cap))\n\t        output_name = \"{}-{}t-{}\".format(\n", "            de.model_name(**additional_params), args[\"time_window\"], dataset)\n\t        target_dir = os.path.join(\n\t            \"preprocessed\", args[\"detection_engine\"], output_name)\n\t        create_dir(target_dir, overwrite=False)\n\t        malicious = ATTACK_LABELS[dataset](cap)\n\t        capture_conf = load_json_data(\n\t            os.path.join(cap, \"conf.json\"), fail=False)\n\t        if not capture_conf:\n\t            capture_conf = CaptureConfig(path=cap)\n\t        prep_configs[target_dir] = PreprocessedConfig(\n", "            key_cls=key_cls,\n\t            family=dataset,\n\t            additional_params=additional_params, time_window=args[\"time_window\"],\n\t            detection_engine=args[\"detection_engine\"], categories={},\n\t            captures_config=capture_conf)\n\t        for cat in os.listdir(cap):\n\t            if not os.path.isdir(os.path.join(cap, cat)):\n\t                continue\n\t            create_dir(os.path.join(target_dir, cat), overwrite=False)\n\t            for pcap in os.listdir(os.path.join(cap, cat)):\n", "                if not pcap.endswith(\".pcap\"):\n\t                    continue\n\t                star_tasks.append((target_dir, cap, dataset, cat, pcap, args[\"time_window\"],\n\t                                   additional_params, malicious, de, key_cls))\n\t    with multiprocessing.Pool(maxtasksperchild=1, processes=args[\"parallel\"]) as pool:\n\t        # concatenate all results of all launched processes\n\t        for ret in pool.starmap(process_pcap, star_tasks):\n\t            if not ret:\n\t                continue\n\t            td, cat, pcap, p = ret\n", "            if cat not in prep_configs[td].categories:\n\t                prep_configs[td].categories[cat] = CategoryConfig()\n\t            prep_configs[td].categories[cat].captures[pcap] = p\n\t            prep_configs[td].categories[cat].update(p)\n\t            prep_configs[td].update(p)\n\t    for td, val in prep_configs.items():\n\t        _logger.info(f\"Dumping {td} configuration with updated pcaps stats\")\n\t        dump_json_data(val, os.path.join(td, \"conf.json\"))\n"]}
{"filename": "enid/online.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tMain file for Testing the generated models' configurations.\n\tThis file executes in parallel on different processes the online\n\ttesting methodology with the Traffic Filter, the Feature Extractor,\n\tand the Classifier all active. For each configuration, the entire pipeline\n\tis adjusted accordingly to the set of parameters involved.\n\t\"\"\"\n", "import argparse\n\timport multiprocessing\n\timport os\n\tfrom dataclasses import dataclass, field\n\tfrom .lib.definitions import TestType, TrafficAnalyser, DebugLevel\n\tfrom .lib.utility import create_dir, dump_json_data, load_json_data\n\tfrom .trainer import DatasetConfig, ModelConfig\n\t@dataclass\n\tclass TestConfig:\n\t    debug: DebugLevel = DebugLevel.NONE\n", "    enforce_timewindows_delay: int = field(default=1)\n\t    sessions: int = None\n\t    is_throughput: bool = False\n\t    is_adaptiveness_enabled: bool = field(default=False)\n\t    def __post_init__(self):\n\t        if isinstance(self.debug, int):\n\t            self.debug = DebugLevel(self.debug)\n\tdef _run_async_adaptiveness(models_conf: ModelConfig, dataset_conf: DatasetConfig, test_conf: TestConfig, basedir, c):\n\t    name = models_conf.detection_engine.model_name(**c)\n\t    create_dir(os.path.join(basedir, name))\n", "    t = models_conf.detection_engine.traffic_analyser_cls(\n\t        models_conf.detection_engine,\n\t        dataset_conf.attackers,\n\t        dataset_conf.time_window,\n\t        dataset_conf.key_cls,\n\t        TestType.THROUGHPUT if test_conf.is_throughput else TestType.NORMAL,\n\t        models_dir=os.path.join(basedir, os.pardir, \"models\"),\n\t        debug=test_conf.debug,\n\t        enforce_timewindows_delay=test_conf.enforce_timewindows_delay,\n\t        is_adaptiveness_enabled=test_conf.is_adaptiveness_enabled,\n", "        sessions_per_timewindow=test_conf.sessions,\n\t        **c)\n\t    TrafficAnalyser.generate_packets(os.path.join(\n\t        basedir, os.pardir, os.pardir, \"combined.pcap\"), t)\n\t    dump_json_data(t.results, os.path.join(basedir, name, \"results.json\"))\n\t    if test_conf.debug != DebugLevel.NONE:\n\t        dump_json_data(t.debug_data, os.path.join(\n\t            basedir, name, \"history.json\"))\n\tdef main(args_list):\n\t    # registering cli parameters, which can be shown with the -h\n", "    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument(\n\t        'de_models_dir', help='path to the model directory containing the models to test')\n\t    parser.add_argument(\n\t        '-d', '--debug', help='debug mode', type=int, default=0)\n\t    parser.add_argument(\n\t        '-dd', '--detection-delay', help='number of time windows to wait before performing detection+mitigation',\n\t        type=int, default=0)\n\t    parser.add_argument(\n", "        '-s', '--sessions', help='number of monitored sessions at once', type=int, default=None)\n\t    parser.add_argument(\n\t        '-t', '--throughput', help='test throughput', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-a', '--adaptiveness', help='enable adaptiveness to auto adjust', action=\"store_true\")\n\t    parser.add_argument(\n\t        '-p', '--parallel', help='number of parallel executions', type=int, default=os.cpu_count())\n\t    args = parser.parse_args(args_list).__dict__\n\t    # loading configurations\n\t    models_config = ModelConfig(\n", "        **load_json_data(os.path.join(args[\"de_models_dir\"], \"models\", \"conf.json\")))\n\t    dataset_config = DatasetConfig(\n\t        **load_json_data(os.path.join(args[\"de_models_dir\"], os.pardir, \"conf.json\")))\n\t    test_config = TestConfig(\n\t        args[\"debug\"], args[\"detection_delay\"], args[\"sessions\"], args[\"throughput\"], args[\"adaptiveness\"])\n\t    dir_basename = os.path.join(\n\t        args[\"de_models_dir\"], \"throughput_test\" if test_config.is_throughput else \"normal_test\")\n\t    create_dir(dir_basename, overwrite=False)\n\t    dump_json_data(test_config, os.path.join(dir_basename, \"conf.json\"))\n\t    # create an async process to test each configuration standalone\n", "    with multiprocessing.Pool(maxtasksperchild=1, processes=args[\"parallel\"]) as pool:\n\t        pool.starmap(_run_async_adaptiveness, [\n\t            (models_config, dataset_config, test_config, dir_basename, c)\n\t            for c in models_config.train_params.all_train_combs()])\n"]}
{"filename": "enid/splitter.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tMain file for Splitting the provided traffic captures in a smaller size.\n\tEach directory is considered a category containing certain type of traffic\n\t(e.g., benign-traffic, malicious-ddos, malicious-sqli).\n\tEach pcap is split in smaller pcaps of the provided size: is its dimension is not\n\tat least 3 times the provided size, then the pcap is split in 3 using its own dimension.\n\tThis is to prevent having unfair split of the pcap within the Train, Val, and Test set\n", "of the dataset.\n\t\"\"\"\n\timport argparse\n\timport math\n\timport multiprocessing\n\timport os\n\tfrom dataclasses import dataclass\n\tfrom pypacker.ppcap import Reader, Writer\n\tfrom .lib.utility import create_dir, dump_json_data, get_logger\n\t_logger = get_logger(__name__)\n", "@dataclass\n\tclass CaptureConfig:\n\t    path: str\n\t    size: int = 0\n\t# could have used tcpdump -r {} -w {} -C {}, but don't want external dependencies\n\tdef _splitter(src_pcap, dst_pcap, pcap_size):\n\t    i = curr_bytes = dump_bytes = 0\n\t    buf = []\n\t    w = Writer(f\"{dst_pcap}{i}.pcap\")\n\t    _logger.info(\"Splitting {} in {}\".format(src_pcap, pcap_size))\n", "    for ts, raw in Reader(src_pcap):\n\t        buf.append((ts, raw))\n\t        curr_bytes += len(raw) + 16  # 16 bytes of timestamp\n\t        dump_bytes += len(raw) + 16\n\t        if dump_bytes > 2 * 1024**2 or curr_bytes >= pcap_size:  # dump data every 1MB of buffer\n\t            for x, y in buf:\n\t                w.write(y, ts=x)\n\t            buf.clear()\n\t            dump_bytes = 0\n\t        if curr_bytes >= pcap_size:\n", "            w.close()\n\t            curr_bytes = 0\n\t            i += 1\n\t            w = Writer(f\"{dst_pcap}{i}.pcap\")\n\t    if buf:\n\t        for x, y in buf:\n\t            w.write(y, ts=x)\n\t    w.close()\n\t    _logger.info(\"Finished {}\".format(src_pcap))\n\tdef main(args_list):\n", "    # registering cli parameters, to be shown with the -h flag\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument(\n\t        'path', help='capture directory', type=str)\n\t    parser.add_argument(\n\t        '-s', '--size', help='size to truncate in bytes', type=int, default=300*1024**2)\n\t    args = parser.parse_args(args_list).__dict__\n\t    conf = CaptureConfig(path=args[\"path\"], size=args[\"size\"])\n\t    dump_json_data(conf, os.path.join(conf.path, \"conf.json\"))\n", "    pcaps = [x.replace(\".pcap\", \"\")\n\t             for x in os.listdir(conf.path) if x.endswith(\".pcap\")]\n\t    star_tasks = []\n\t    for cat in pcaps:\n\t        dst_dir = os.path.join(conf.path, cat)\n\t        create_dir(dst_dir, overwrite=True)\n\t        src_pcap = os.path.join(conf.path, \"{}.pcap\".format(cat))\n\t        dst_pcap = os.path.join(dst_dir, cat)\n\t        pcap_size = os.path.getsize(src_pcap)\n\t        # if pcap size is not at least 3 times the provided size, then\n", "        # split the pcap in 3 according to the pcap size/3\n\t        # otherwise, split pcaps using the provided size\n\t        if pcap_size / conf.size < 3:\n\t            pcap_size = math.ceil(pcap_size/3)\n\t        else:\n\t            pcap_size = conf.size\n\t        star_tasks.append((src_pcap, dst_pcap, pcap_size))\n\t    with multiprocessing.Pool(maxtasksperchild=1) as pool:\n\t        pool.starmap(_splitter, star_tasks)\n"]}
{"filename": "enid/trainer.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"_\n\tMain file for Training the desired Detection Models.\n\tGiven the combination of hyperparameters and iterable parameters\n\tfor generating models with less information (e.g., maximum number of packets P and\n\tfeatures extracted F), this file will invoke the train method of the\n\tDetection Models untill all models are created. Every generated model is tested\n\toffline against the test portion of the chosen dataset, registering results at different\n", "granularities (i.e., for the entire dataset, for the single category of captures,\n\tfor the single pcap).\n\t\"\"\"\n\timport argparse\n\timport os\n\tfrom dataclasses import dataclass, field\n\tfrom typing import Dict, Type\n\timport numpy as np\n\timport tensorflow as tf\n\tfrom .datasetter import DatasetConfig, DatasetTrainConfig\n", "from .lib.definitions import DeParams, DetectionEngine\n\tfrom .lib.metrics import TrainMetric\n\tfrom .lib.utility import (SplitType, add_param_to_parser, create_dir,\n\t                          dump_json_data, get_logger, get_param_for_method,\n\t                          load_json_data, splittable_int)\n\t_logger = get_logger(__name__)\n\t@dataclass\n\tclass ResultCategory(TrainMetric):\n\t    captures: Dict[str, TrainMetric] = field(default_factory=dict)\n\t    def __post_init__(self):\n", "        super().__post_init__()\n\t        for k in self.captures:\n\t            if not isinstance(self.captures[k], TrainMetric):\n\t                self.captures[k] = TrainMetric(**self.captures[k])\n\t@dataclass\n\tclass ResultDataset(TrainMetric):\n\t    categories: Dict[str, ResultCategory] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        super().__post_init__()\n\t        for k in self.categories:\n", "            if not isinstance(self.categories[k], ResultCategory):\n\t                self.categories[k] = ResultCategory(**self.categories[k])\n\t@dataclass\n\tclass ResultTrain(TrainMetric):\n\t    datasets: Dict[str, ResultDataset] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        super().__post_init__()\n\t        for k in self.datasets:\n\t            if not isinstance(self.datasets[k], ResultDataset):\n\t                self.datasets[k] = ResultDataset(**self.datasets[k])\n", "    def update(self, test_dict: DatasetTrainConfig, pt):\n\t        # registering results at each granularity\n\t        if len(pt) != len(self._ypred):\n\t            return\n\t        i = 0\n\t        for dataset_name, v in test_dict.datasets.items():\n\t            self.datasets[dataset_name] = ResultDataset()\n\t            for cat, val in v.categories.items():\n\t                self.datasets[dataset_name].categories[cat] = ResultCategory()\n\t                for pcap, target in val.captures.items():\n", "                    next_i = i + target.benign.test_taken + target.malicious.test_taken\n\t                    indexes = np.where(\n\t                        np.logical_and(pt >= i, pt < next_i))\n\t                    y_pred_slice = self._ypred[indexes]\n\t                    y_test_slice = self._ytrue[indexes]\n\t                    self.datasets[dataset_name].categories[cat].captures[pcap] = TrainMetric(\n\t                        _threshold=[\n\t                            (self._threshold[0][0], y_pred_slice.size)],\n\t                        _ypred=y_pred_slice,\n\t                        _ytrue=y_test_slice)\n", "                    self.datasets[dataset_name].categories[cat].update(\n\t                        self.datasets[dataset_name].categories[cat].captures[pcap])\n\t                    i = next_i\n\t                self.datasets[dataset_name].update(\n\t                    self.datasets[dataset_name].categories[cat])\n\t@dataclass\n\tclass ModelConfig:\n\t    detection_engine: Type[DetectionEngine]\n\t    train_params: Type[DeParams]\n\t    split_type: SplitType = field(default=SplitType.NONE)\n", "    def __post_init__(self):\n\t        if isinstance(self.detection_engine, str):\n\t            self.detection_engine = DetectionEngine.import_de(\n\t                self.detection_engine)\n\t        if isinstance(self.train_params, dict):\n\t            self.train_params = self.detection_engine.de_params(\n\t                **self.train_params)\n\t        if isinstance(self.split_type, int):\n\t            self.split_type = SplitType(self.split_type)\n\t    def join(self, other: \"ModelConfig\") -> bool:\n", "        if self.detection_engine != other.detection_engine or str(self.train_params) != str(other.train_params):\n\t            return False\n\t        return True\n\tdef train(dataset_path: str, de: Type[DetectionEngine],\n\t          models_dir, test_dict: DatasetTrainConfig, train_params: Type[DeParams], c,\n\t          split_type: SplitType, split_chunk):\n\t    \"\"\"Function for training a given configuration\"\"\"\n\t    tf.keras.backend.clear_session()\n\t    name = de.model_name(**c)\n\t    new_path = os.path.join(models_dir, name)\n", "    # check if configuration already trained\n\t    if os.path.isdir(new_path) and all(\n\t            os.path.isfile(os.path.join(new_path, x))\n\t            for x in (\"results.json\", \"relevance.json\", \"history.json\", \"params.json\")):\n\t        _logger.info(\n\t            f\"Model {name} already trained, skipping\")\n\t        return\n\t    create_dir(new_path, overwrite=True)\n\t    # calling the Detection Model specific train method\n\t    hs, hp, best_model, xts, yts, features_holder, pt = de.train(\n", "        dataset_path, new_path, train_params, split_type, split_chunk, **c)\n\t    _logger.info(f\"Testing {name}\")\n\t    y_pred = de.predict(best_model, xts, **hp.__dict__)\n\t    dump_json_data(features_holder, os.path.join(new_path, \"relevance.json\"))\n\t    dump_json_data(hs, os.path.join(new_path, \"history.json\"))\n\t    dump_json_data(hp, os.path.join(new_path, \"params.json\"))\n\t    res = ResultTrain(\n\t        _threshold=hp.malicious_threshold,\n\t        _ypred=y_pred, _ytrue=yts)\n\t    res.update(test_dict, pt)\n", "    dump_json_data(res, os.path.join(new_path, \"results.json\"))\n\tdef main(args_list):\n\t    # registering cli parameters to be shown with the -h flag\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument(\n\t        'dataset', help='path to the dataset directory', type=str)\n\t    parser.add_argument(\n\t        'output', help='output name', type=str)\n\t    parser.add_argument(\n", "        '-s', '--split-type', help='split type', type=splittable_int, default=SplitType.NONE)\n\t    parser.add_argument(\"detection_engine\", help=\"Select the detection engine to use\", type=str,\n\t                        choices=DetectionEngine.list_all())\n\t    parser.add_argument(\"rest\", nargs=argparse.REMAINDER)\n\t    args = parser.parse_args(args_list).__dict__\n\t    de: Type[DetectionEngine] = DetectionEngine.import_de(\n\t        args[\"detection_engine\"])\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    add_comb_params = get_param_for_method(\n", "        de.model_name, exclude_super_cls=DetectionEngine, ignore_default=True)\n\t    params_for_method = {k: v for k, v in get_param_for_method(\n\t        de.de_params).items() if k not in add_comb_params}\n\t    # registering nested cli parameters once chosen the detection model (i.e., LucidCnn)\n\t    # a nested -h flag is available for showing the help menu\n\t    for pname, (ptype, pdef) in add_comb_params.items():\n\t        parser.add_argument(\n\t            f\"--{pname}\", help=\"Parameter for creating models\", type=ptype, nargs=\"+\",\n\t            **{\"default\": tuple(range(len(de.features_holder_cls.ALLOWED), 0, -1))}\n\t            if pname == \"features\" else {\"required\": True})\n", "    for pname, (ptype, pdef) in params_for_method.items():\n\t        add_param_to_parser(parser, pname, ptype, pdef,\n\t                            \"Parameter for Training\")\n\t    args.update(parser.parse_args(args[\"rest\"]).__dict__)\n\t    dataset_config = DatasetConfig(\n\t        **load_json_data(os.path.join(args[\"dataset\"], \"conf.json\")))\n\t    # check if Detection Models are compatible\n\t    if not DetectionEngine.intersect([args[\"detection_engine\"]] +\n\t                                     [v.detection_engine.__name__ for v in dataset_config.preprocessed_configs.values()]):\n\t        raise ValueError(\"Error with the DE\")\n", "    models_config = ModelConfig(\n\t        de, de.de_params(\n\t            **{a: args[a] for a in params_for_method if a not in add_comb_params},\n\t            **{a: sorted(args[a], reverse=True) for a in add_comb_params}), args[\"split_type\"])\n\t    models_dir = os.path.join(\n\t        args[\"dataset\"], args[\"output\"], 'models')\n\t    create_dir(models_dir, overwrite=False)\n\t    dump_json_data(models_config, os.path.join(models_dir, \"conf.json\"))\n\t    combs = models_config.train_params.all_train_combs()\n\t    for i, c in enumerate(combs):\n", "        train(args[\"dataset\"], de, models_dir, dataset_config.offline,\n\t              models_config.train_params, c, models_config.split_type, split_chunk=(i, len(combs)))\n"]}
{"filename": "enid/register.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tMain file for registering new Detection Engine to a previous ENID installation\n\t\"\"\"\n\timport argparse\n\timport os\n\timport shutil\n\tfrom .lib.definitions import DetectionEngine\n", "from .lib.utility import get_logger, snake_to_camel\n\t_logger = get_logger(__name__)\n\tdef main(args_list):\n\t    parser = argparse.ArgumentParser(\n\t        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\t    parser.add_argument('path',\n\t                        help='path to the de to register', type=str)\n\t    args = parser.parse_args(args_list).__dict__\n\t    args[\"path\"] = os.path.normpath(args[\"path\"])\n\t    if os.path.isfile(args[\"path\"]) and args[\"path\"].endswith(\".py\"):\n", "        de_name = os.path.basename(args[\"path\"]).replace(\".py\", \"\")\n\t    elif os.path.isdir(args[\"path\"]) and os.path.isfile(os.path.join(args[\"path\"], \"__init__.py\")):\n\t        de_name = os.path.basename(args[\"path\"])\n\t    else:\n\t        raise RuntimeError(\"Unsupported format for registering plugin\")\n\t    de_name_camelised = snake_to_camel(de_name)\n\t    dest_path = os.path.join(os.path.dirname(\n\t        __file__), \"lib\", \"engines\", de_name)\n\t    _logger.info(\n\t        f\"Copying Detection Engine {de_name_camelised} to directory {dest_path}\")\n", "    shutil.copytree(args[\"path\"], dest_path, dirs_exist_ok=True)\n\t    try:\n\t        _logger.info(\"Checking validity...\")\n\t        DetectionEngine.import_de(de_name_camelised)\n\t        _logger.info(\"Engine successfully installed!\")\n\t    except Exception as e:\n\t        _logger.info(f\"Invalid Engine, removing. Why: {e}\")\n\t        shutil.rmtree(dest_path)\n"]}
{"filename": "enid/lib/utility.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"Utility file containing all the function used among all the programs and modules.\"\"\"\n\timport datetime\n\timport importlib\n\timport inspect\n\timport json\n\timport logging\n\timport math\n", "import os\n\timport pkgutil\n\timport re\n\timport shutil\n\timport sys\n\timport typing\n\tfrom ctypes import Array, Structure\n\tfrom ctypes import Union as CUnion\n\tfrom ctypes import _Pointer, _SimpleCData\n\tfrom dataclasses import dataclass, fields, is_dataclass\n", "from enum import Enum\n\tfrom json import JSONEncoder\n\tfrom typing import Any, Callable, Dict, List, Tuple\n\timport numpy as np\n\timport psutil\n\tfrom pypacker.layer12.ethernet import Ethernet\n\tdef set_seed():\n\t    \"Function for resetting the seed if \"\n\t    seed = os.environ.get(\"PYTHONHASHSEED\", None)\n\t    if seed is not None:\n", "        import tensorflow as tf\n\t        import random\n\t        seed = int(seed)\n\t        random.seed(seed)\n\t        np.random.seed(seed)\n\t        tf.keras.utils.set_random_seed(seed)\n\tdef silence():\n\t    import warnings\n\t    import tensorflow as tf\n\t    import tensorflow.python.util.deprecation as deprecation\n", "    from sklearn.exceptions import UndefinedMetricWarning\n\t    \"\"\"Function for silencing warning and tensorflow logging\"\"\"\n\t    warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n\t    warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n\t    warnings.filterwarnings(action='ignore', category=UserWarning)\n\t    np.seterr(all=\"ignore\")\n\t    deprecation._PRINT_DEPRECATION_WARNINGS = False\n\t    tf.get_logger().setLevel('ERROR')\n\t    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\tclass EthInPcap(Ethernet):\n", "    \"\"\"Personalised class to insert a reference to the dataset, category and pcap\"\"\"\n\t    def __init__(self, timestamp: int, dataset: str, category: str, pcap: str, *args, **kwargs):\n\t        super().__init__(*args, **kwargs)\n\t        self.timestamp = timestamp\n\t        self.dataset = dataset\n\t        self.category = category\n\t        self.pcap = pcap\n\tclass CDataJSONEncoder(JSONEncoder):\n\t    \"\"\"A JSON Encoder that puts small containers on single lines.\"\"\"\n\t    CONTAINER_TYPES = (list, tuple, dict)\n", "    \"\"\"Container datatypes include primitives or other containers.\"\"\"\n\t    MAX_WIDTH = 120\n\t    \"\"\"Maximum width of a container that might be put on a single line.\"\"\"\n\t    MAX_ITEMS = 15\n\t    \"\"\"Maximum number of items in container that might be put on single line.\"\"\"\n\t    def __init__(self, *args, **kwargs):\n\t        # using this class without indentation is pointless\n\t        if kwargs.get(\"indent\") is None:\n\t            kwargs.update({\"indent\": 1})\n\t        super().__init__(*args, **kwargs)\n", "        self.indentation_level = 0\n\t    def encode(self, o):\n\t        \"\"\"Encode JSON object *o* with respect to single line lists.\"\"\"\n\t        o = self.default(o)\n\t        if isinstance(o, (list, tuple)):\n\t            if self._put_on_single_line(o):\n\t                return \"[\" + \", \".join(self.encode(el) for el in o) + \"]\"\n\t            else:\n\t                self.indentation_level += 1\n\t                output = [self.indent_str + self.encode(el) for el in o]\n", "                self.indentation_level -= 1\n\t                return \"[\\n\" + \",\\n\".join(output) + \"\\n\" + self.indent_str + \"]\"\n\t        elif isinstance(o, dict):\n\t            if o:\n\t                if self._put_on_single_line(o):\n\t                    return \"{ \" + \", \".join(f\"{self.encode(k)}: {self.encode(el)}\" for k, el in o.items()) + \" }\"\n\t                else:\n\t                    self.indentation_level += 1\n\t                    output = [\n\t                        self.indent_str + f\"{json.dumps(k)}: {self.encode(v)}\" for k, v in o.items()]\n", "                    self.indentation_level -= 1\n\t                    return \"{\\n\" + \",\\n\".join(output) + \"\\n\" + self.indent_str + \"}\"\n\t            else:\n\t                return \"{}\"\n\t        elif isinstance(o, str):  # escape newlines\n\t            o = o.replace(\"\\n\", \"\\\\n\")\n\t            return f'\"{o}\"'\n\t        else:\n\t            return json.dumps(o)\n\t    def iterencode(self, o, **kwargs):\n", "        \"\"\"Required to also work with `json.dump`.\"\"\"\n\t        return self.encode(o)\n\t    def _put_on_single_line(self, o):\n\t        return self._primitives_only(o) and len(o) <= self.MAX_ITEMS and len(str(o)) - 2 <= self.MAX_WIDTH\n\t    def _primitives_only(self, o: typing.Union[list, tuple, dict]):\n\t        if isinstance(o, (list, tuple)):\n\t            return not any(isinstance(el, self.CONTAINER_TYPES) for el in o)\n\t        elif isinstance(o, dict):\n\t            return not any(isinstance(el, self.CONTAINER_TYPES) for el in o.values())\n\t    @property\n", "    def indent_str(self) -> str:\n\t        if isinstance(self.indent, int):\n\t            return \" \" * (self.indentation_level * self.indent)\n\t        elif isinstance(self.indent, str):\n\t            return self.indentation_level * self.indent\n\t        else:\n\t            raise ValueError(\n\t                f\"indent must either be of type int or str (is: {type(self.indent)})\")\n\t    def default(self, obj):\n\t        if inspect.isclass(obj):\n", "            return obj.__name__\n\t        if isinstance(obj, (Array, list)):\n\t            return [self.default(e) for e in obj]\n\t        if isinstance(obj, _Pointer):\n\t            return self.default(obj.contents) if obj else None\n\t        if isinstance(obj, _SimpleCData):\n\t            return self.default(obj.value)\n\t        if isinstance(obj, (bool, int, float, str)):\n\t            return obj\n\t        if obj is None:\n", "            return obj\n\t        if isinstance(obj, Enum):\n\t            return obj.value\n\t        if isinstance(obj, (Structure, CUnion)):\n\t            result = {}\n\t            anonymous = getattr(obj, '_anonymous_', [])\n\t            for key, *_ in getattr(obj, '_fields_', []):\n\t                value = getattr(obj, key)\n\t                # private fields don't encode\n\t                if key.startswith('_'):\n", "                    continue\n\t                if key in anonymous:\n\t                    result.update(self.default(value))\n\t                else:\n\t                    result[key] = self.default(value)\n\t            return result\n\t        if is_dataclass(obj):\n\t            if hasattr(obj, \"to_json\"):\n\t                return obj.to_json()\n\t            else:\n", "                return {k.name: self.default(getattr(obj, k.name)) for k in fields(obj)}\n\t        if isinstance(obj, dict):\n\t            if obj and not isinstance(next(iter(obj), None), (int, float, str, bool)):\n\t                return [{'key': self.default(k), 'value': self.default(v)} for k, v in obj.items()]\n\t            else:\n\t                return {k: self.default(v) for k, v in obj.items()}\n\t        if isinstance(obj, tuple):\n\t            if hasattr(obj, \"_asdict\"):\n\t                return self.default(obj._asdict())\n\t            else:\n", "                return [self.default(e) for e in obj]\n\t        if isinstance(obj, np.ndarray):\n\t            return obj.tolist()\n\t        if isinstance(obj, np.integer):\n\t            return int(obj)\n\t        if isinstance(obj, np.floating):\n\t            return float(obj)\n\t        return JSONEncoder.default(self, obj)\n\tdef get_best_comb(n_comb):\n\t    \"\"\"Function to get the best n° of combinations during a randomised\n", "    search of hyperparameters\"\"\"\n\t    return n_comb if n_comb < 50 else 50\n\tdef get_best_dispatch(size: int):\n\t    \"\"\"Function to get the best dispatch n° of workers while doing\n\t    a randomised search of hyperparameters\"\"\"\n\t    total = psutil.virtual_memory().total\n\t    n_times = 0\n\t    while True:\n\t        if size * n_times > total:\n\t            break\n", "        n_times += 1\n\t    return min(math.floor(math.sqrt(n_times)), os.cpu_count())*2 or 1\n\tdef handler(x, y):\n\t    \"\"\"Utility to call function x with all parameters inside the arg y\"\"\"\n\t    return x(*y)\n\tdef sort_keep_comb(x, y):\n\t    \"\"\"Sort array x and y while preserving their labels and returning\n\t    the permutations used\"\"\"\n\t    p = np.random.permutation(len(x))\n\t    return x[p], y[p], p\n", "def create_dir(name, overwrite=None):\n\t    \"\"\"Function to create a directory and, in case, overwrite or\n\t    backup the old one if already present\"\"\"\n\t    try:\n\t        os.makedirs(name)\n\t    except FileExistsError:\n\t        if overwrite is False:\n\t            shutil.move(\n\t                name, f\"{name}_{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}______backup\")\n\t            os.makedirs(name)\n", "        elif overwrite is True:\n\t            shutil.rmtree(name)\n\t            os.makedirs(name)\n\tdef load_json_data(path: str, fail=True):\n\t    \"\"\"Function to load json file into a dictionary\"\"\"\n\t    if os.path.isfile(path):\n\t        with open(path, \"r\") as fp:\n\t            return json.load(fp)\n\t    elif fail:\n\t        raise FileNotFoundError(\"File {} not found\".format(path))\n", "    else:\n\t        return {}\n\tdef dump_json_data(data, path: str = None):\n\t    \"\"\"Function to dump dictionary or dataclass into json file\n\t    with the custom encoder\"\"\"\n\t    if path is None:\n\t        return json.dumps(data, cls=CDataJSONEncoder)\n\t    with open(path, 'w') as fp:\n\t        json.dump(data, fp, indent=2, cls=CDataJSONEncoder)\n\tdef snake_to_camel(name, join_char=''):\n", "    \"\"\"Function to transform a string from snake to camel case\"\"\"\n\t    return join_char.join(word.title() for word in name.split('_'))\n\tdef camel_to_snake(name):\n\t    \"\"\"Function to transform a string from camel case to snake\"\"\"\n\t    return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower().replace(\" \", \"\")\n\tdef safe_division(a, b, default=None):\n\t    \"\"\"Function to perform a safe division, meaning no exceptions are thrown\n\t    in case of a division by 0 or infinite number\"\"\"\n\t    ret = np.divide(a, b)\n\t    if default is not None:\n", "        return np.nan_to_num(ret, copy=False, nan=default, posinf=default, neginf=default)\n\t    return ret\n\tdef get_logger(name: str, filepath: str = None, log_level: int = logging.INFO) -> logging.Logger:\n\t    \"\"\"Function to create a logger, or return the existing one\"\"\"\n\t    logger = logging.getLogger(name)\n\t    logger.setLevel(log_level)\n\t    formatter = logging.Formatter(\n\t        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\t    handlers = [logging.StreamHandler()]\n\t    if filepath:\n", "        handlers.append(logging.FileHandler(filepath, mode=\"w\"))\n\t    for h in handlers:\n\t        h.setLevel(log_level)\n\t        h.setFormatter(formatter)\n\t        logger.addHandler(h)\n\t    return logger\n\tdef nullable_int(val: str) -> int:\n\t    \"\"\"Utility int checker function to accept None as\n\t    cli argument instead of an int\"\"\"\n\t    ret = int(val)\n", "    if ret < 1:\n\t        return None\n\t    return ret\n\tclass SplitType(Enum):\n\t    EQUALLY = 0\n\t    PROPORTIONED = 1\n\t    NONE = 2\n\tdef splittable_int(val: str) -> int:\n\t    \"\"\"Utility function to convert int into SplitType Enum\"\"\"\n\t    return SplitType(int(val))\n", "def all_subclasses(cls, recursive=False):\n\t    \"\"\"Function to return all subclasses of a given class, optionally\n\t    searching for recursive ones.\"\"\"\n\t    if recursive:\n\t        recursive_import(sys.modules[cls.__module__])\n\t    return set(cls.__subclasses__()).union(\n\t        [s for c in cls.__subclasses__() for s in all_subclasses(c)])\n\t@dataclass\n\tclass UpdatableDataclass:\n\t    \"\"\"Base dataclass to support the update method, which updates the fields\n", "    of the current one by looking at all the fields of the provided one\"\"\"\n\t    def update(self, other):\n\t        for k in fields(other):\n\t            k = k.name\n\t            if not hasattr(self, k):\n\t                continue\n\t            if isinstance(getattr(other, k), dict):\n\t                for kk, vv in getattr(other, k).items():\n\t                    getattr(self, k).setdefault(kk, 0)\n\t                    getattr(self, k)[kk] += vv\n", "            elif isinstance(getattr(other, k), list):\n\t                setattr(self, k, getattr(self, k) + getattr(other, k))\n\t            elif isinstance(getattr(other, k), np.ndarray):\n\t                setattr(self, k, np.concatenate(\n\t                    (getattr(self, k), getattr(other, k)), axis=0, dtype=getattr(self, k).dtype))\n\t            elif is_dataclass(getattr(other, k)):\n\t                getattr(self, k).update(getattr(other, k))\n\t            else:\n\t                setattr(self, k, getattr(self, k) + getattr(other, k))\n\tdef recursive_import(base_module):\n", "    \"\"\"Function to recursively import all modules within a base module\"\"\"\n\t    if not hasattr(base_module, \"__path__\"):\n\t        return\n\t    for _, modname, ispkg in pkgutil.walk_packages(\n\t            path=base_module.__path__,\n\t            prefix=base_module.__name__ + \".\",\n\t            onerror=lambda x: None):\n\t        if modname in sys.modules:\n\t            continue\n\t        if ispkg:\n", "            recursive_import(modname)\n\t        else:\n\t            try:\n\t                sys.modules[modname] = importlib.import_module(modname)\n\t            except Exception as e:\n\t                print(\"Exception while importing\", modname, e)\n\tdef get_param_for_method(method: Callable, exclude_super_cls=None, ignore_default=False) -> Dict[str, Tuple[Any, Any]]:\n\t    \"\"\"Function to return all params and info for a specific method. Optionally, all the parameters shared with the\n\t    provided super class are ignored.\"\"\"\n\t    if not exclude_super_cls:\n", "        super_ones = []\n\t    elif inspect.isclass(method):\n\t        super_ones = inspect.signature(exclude_super_cls).parameters\n\t    else:\n\t        super_ones = inspect.signature(\n\t            getattr(exclude_super_cls, method.__name__)).parameters\n\t    return {v.name: (v.annotation if v.annotation != inspect._empty else Any, v.default)\n\t            for v in inspect.signature(method).parameters.values() if v.name != \"kwargs\" and (\n\t                v.name not in super_ones or ignore_default or (\n\t                    not ignore_default and v.default != super_ones[v.name].default))}\n", "def get_max_comb(tmp: Dict[str, Tuple[Any]]):\n\t    \"\"\"Return the maximum combination of key-values in a dictionary\"\"\"\n\t    if not tmp:\n\t        return {}\n\t    if isinstance(tmp, (list, tuple)):\n\t        max = tmp[0]\n\t        for x in tmp:\n\t            if all(x[k] >= max[k] for k in x):\n\t                max = x\n\t        return max\n", "    return {k: max(v) for k, v in tmp.items()}\n\tdef get_all_dict_comb(tmp: Dict[str, Tuple[Any]]):\n\t    \"\"\"Return all combination of key-values in a dictionary\"\"\"\n\t    import itertools\n\t    keys, values = [], []\n\t    for k, v in tmp.items():\n\t        keys.append(k)\n\t        values.append(v if isinstance(v, (tuple, list)) else [v])\n\t    return [dict(zip(keys, v)) for v in itertools.product(*values)]\n\tdef add_param_to_parser(parser, pname, ptype, pdef, help=\"\"):\n", "    \"\"\"Function to add a cli parameter\"\"\"\n\t    other = {\"help\": help}\n\t    if hasattr(ptype, \"__origin__\") and issubclass(ptype.__origin__, (Tuple, List)):\n\t        other[\"nargs\"] = \"+\"\n\t        ptype = ptype.__args__[0]\n\t    if ptype == int and pdef is None:\n\t        ptype = nullable_int\n\t    if ptype == bool:\n\t        parser.add_argument(f'--{pname}', **other, action=\"store_{}\".format(\n\t            str(not pdef).lower() if pdef != inspect._empty and pdef is not None else \"true\"))\n", "    elif pdef != inspect._empty:\n\t        parser.add_argument(f'--{pname}', **other,  type=ptype, default=pdef)\n\t    else:\n\t        parser.add_argument(pname, **other, type=ptype)\n"]}
{"filename": "enid/lib/definitions.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"File containing the most important definitions of classes and behaviours.\"\"\"\n\timport importlib\n\timport os\n\timport pickle\n\timport time\n\tfrom abc import ABC, abstractclassmethod, abstractmethod\n\tfrom dataclasses import dataclass, field, fields, replace\n", "from enum import Enum\n\tfrom itertools import cycle\n\tfrom typing import Dict, List, OrderedDict, Tuple, Type, Union\n\timport numpy as np\n\tfrom pypacker.layer3.ip import IP\n\tfrom pypacker.ppcap import Reader\n\tfrom .identifiers import BaseKey, TwoIPsProtoPortsKey, str_to_key\n\tfrom .metrics import (BaseStats, ComputationalRequirements, ResultTest,\n\t                      ResultTestCategory, ResultTestDataset, Stats, TestMetric)\n\tfrom .utility import (CDataJSONEncoder, EthInPcap, SplitType, camel_to_snake,\n", "                      get_all_dict_comb, get_logger, load_json_data,\n\t                      safe_division, snake_to_camel)\n\t@dataclass\n\tclass BaseFeature(ABC):\n\t    \"\"\"BaseFeature class. All instances must comply to this interface.\"\"\"\n\t    value: int = 0\n\t    @property\n\t    @abstractmethod\n\t    def computational_requirements(cls) -> Tuple[ComputationalRequirements]:\n\t        \"\"\"Method to return a list or tuple of computational requirements.\"\"\"\n", "        pass\n\t    @property\n\t    @abstractmethod\n\t    def memory_requirements(cls) -> int:\n\t        \"\"\"Method to return the memory bytes corresponding to the feature\"\"\"\n\t        pass\n\t    @classmethod\n\t    def create(cls, eth: EthInPcap):\n\t        \"\"\"Method to create a new instance of the feature from the packet\"\"\"\n\t        ret = cls()\n", "        ret.extract(eth)\n\t        return ret\n\t    @abstractmethod\n\t    def extract(self, eth: EthInPcap):\n\t        \"\"\"Method to extract/update the current instance of the feature from the packet\"\"\"\n\t        pass\n\t    def to_json(self):\n\t        \"\"\"Method to return the feature in a json-like format\"\"\"\n\t        return self.value\n\t@dataclass\n", "class AggBaseFeature(BaseFeature):\n\t    \"\"\"AggbaseFeature class that represents the base class for all features that are\n\t    statistics instead of single values, hence updated throughout the time.\"\"\"\n\t    @classmethod\n\t    def create(cls, eth: EthInPcap, is_fwd=False):\n\t        ret = cls()\n\t        ret.extract(eth, is_fwd)\n\t        return ret\n\t    @abstractmethod\n\t    def extract(self, eth: EthInPcap, is_fwd=False):\n", "        pass\n\t@dataclass\n\tclass SessionValue:\n\t    \"\"\"Class to hold the values monitored from a flow\"\"\"\n\t    prediction: float = 0\n\t    metered_packets: int = 0\n\t    unmetered_packets: int = 0\n\t    value: Union[Tuple[AggBaseFeature],\n\t                 List[Tuple[BaseFeature]]] = field(default_factory=list)\n\t    @property\n", "    def total_packets(self):\n\t        return self.metered_packets + self.unmetered_packets\n\tclass Ticker:\n\t    \"\"\"Class to represent a ticker that hold a list of tasks and everytime the tick method\n\t    is called their age is reduced until zero.\"\"\"\n\t    def __init__(self, missing_tw, to_blacklist) -> None:\n\t        self.missing_tw: int = missing_tw\n\t        self.to_blacklist: List[Type[BaseKey]] = to_blacklist\n\t    def tick(self):\n\t        self.missing_tw -= 1\n", "    @property\n\t    def ready(self):\n\t        return self.missing_tw < 0\n\t@dataclass\n\tclass FeaturesHolder(ABC):\n\t    \"\"\"Abstract class for holding a features and defining which ones are\n\t    allowed within a Detection Model.\"\"\"\n\t    value: OrderedDict[Type[BaseFeature], Union[float,\n\t                                                Tuple[float, float]]] = field(default=None)\n\t    def __iter__(self):\n", "        for x in range(len(self.ALLOWED), 0, -1):\n\t            yield x\n\t    @classmethod\n\t    @property\n\t    @abstractmethod\n\t    def ALLOWED(cls) -> Tuple[Type[BaseFeature]]:\n\t        \"\"\"All the allowed ones\"\"\"\n\t        pass\n\t    @property\n\t    def computational_requirements(self):\n", "        \"\"\"Method to return the cpu requirements of extracting the current ones\"\"\"\n\t        return tuple(k for x in self.value for k in x.computational_requirements)\n\t    def get_feature_value(self, y: BaseFeature):\n\t        return self.value[y] if y in self.value else None\n\t    @property\n\t    def memory_requirements(self):\n\t        \"\"\"Method to return the memory requirements of extracting the current ones\"\"\"\n\t        return sum(x.memory_requirements for x in self.value)\n\t    @abstractmethod\n\t    def pop_less_relevant(self, key_depth_class: Type[BaseKey] = None) -> Type[BaseFeature]:\n", "        \"\"\"Abstract method to remove the least important features from the\n\t        currently active ones\"\"\"\n\t        pass\n\t    @property\n\t    def n_total(self) -> int:\n\t        \"\"\"All the allowed ones\"\"\"\n\t        return len(self.ALLOWED)\n\t    @property\n\t    def n_current(self) -> int:\n\t        \"\"\"Only the current ones\"\"\"\n", "        return len(self.value)\n\t@dataclass\n\tclass DeParams:\n\t    \"\"\"Base class to hold the parameters of a Detection Model\"\"\"\n\t    packets_per_session: int = None\n\t    features: int = None\n\t    max_packets_per_session: int = None\n\t    max_features: int = None\n\t    malicious_threshold: int = 0\n\t    key_depth_class: Type[BaseKey] = TwoIPsProtoPortsKey\n", "    def to_json(self):\n\t        \"\"\"Method to dump the class in a json-style\"\"\"\n\t        e = CDataJSONEncoder()\n\t        return {k.name: e.default(getattr(self, k.name)) for k in fields(self) if k.repr}\n\t    def __post_init__(self):\n\t        if isinstance(self.key_depth_class, str):\n\t            self.key_depth_class = str_to_key(self.key_depth_class)\n\t    def all_train_combs(self, exclude=None):\n\t        \"\"\"Method to return all combination of trainable models\"\"\"\n\t        return get_all_dict_comb({k: getattr(self, k) for k in self.train_combs() if k != exclude})\n", "    def previous_one(self, pps, ftrs):\n\t        \"\"\"Method to return the previous model parameters and the 'distance'\n\t        with the current one\"\"\"\n\t        is_max_features = ftrs == max(self.features)\n\t        if pps is None:\n\t            if is_max_features:\n\t                return False\n\t            prev_features = self.features[self.features.index(ftrs)-1]\n\t            return pps, prev_features, prev_features - ftrs, 0\n\t        is_max_packets = pps == max(self.packets_per_session)\n", "        if is_max_features and is_max_packets:\n\t            return False\n\t        if is_max_packets:\n\t            prev_features = self.features[self.features.index(ftrs)-1]\n\t            return pps, prev_features, prev_features - ftrs, 0\n\t        return self.packets_per_session[self.packets_per_session.index(pps)-1], ftrs, 0\n\t    def train_combs(self):\n\t        \"\"\"Method for returning the combination of parameters for generating models\"\"\"\n\t        return tuple(x for x in (\"packets_per_session\", \"features\") if getattr(self, x) is not None)\n\t@dataclass\n", "class AnalysisState:\n\t    \"\"\"Base class to represent the state of an analysis\"\"\"\n\t    time_window: int = None\n\t    sessions_per_timewindow: int = None\n\t    enforce_timewindows_delay: int = 0\n\t    is_adaptiveness_enabled: bool = False\n\t    current_key: Type[BaseKey] = field(default=None)\n\t    current_features: Type[FeaturesHolder] = field(default=None)\n\t    params: DeParams = field(default=None)\n\t    def __post_init__(self):\n", "        if isinstance(self.current_key, str):\n\t            self.current_key = str_to_key(self.current_key)\n\t        if isinstance(self.current_features, dict):\n\t            self.current_features = self.__class__.current_features.__class__(\n\t                **self.current_features)\n\t        if isinstance(self.params, dict):\n\t            self.params = self.__class__.params.__class__(**self.params)\n\tclass TestType(Enum):\n\t    \"\"\"Enumeration to hold the type of the online test\"\"\"\n\t    PROCESSING = 0\n", "    THROUGHPUT = 1\n\t    NORMAL = 2\n\tclass DebugLevel(Enum):\n\t    \"\"\"Enumeration to hold the debug level of the online test\"\"\"\n\t    NONE = 0\n\t    BASE = 1\n\t    ENHANCED = 2\n\t@dataclass\n\tclass BaseProcessingData:\n\t    \"\"\"Base data that need to be generated from a processing method while parsing pcap\n", "    with the preprocesser.py program\"\"\"\n\t    tot_benign: int = 0\n\t    tot_malicious: int = 0\n\t    unique_benign: int = 0\n\t    unique_malicious: int = 0\n\t    tot_benign_packets: int = 0\n\t    tot_malicious_packets: int = 0\n\tclass TrafficAnalyser(ABC):\n\t    \"\"\"Traffic Analyser that includes the Filtering mechanism to drop packets matching\n\t    the blacklist and the Feature Extraction mechanisms. In addition to that, it contains a\n", "    reference to the Detection Model of interests and all the parameters used.\"\"\"\n\t    analysis_state_cls: Type[AnalysisState] = AnalysisState\n\t    session_value_cls: Type[SessionValue] = SessionValue\n\t    def __init__(self, detection_engine_cls: Type[\"DetectionEngine\"],\n\t                 attackers: Dict[str, Tuple[Type[BaseKey]]],\n\t                 time_window: int, current_key: Type[BaseKey], test_type: TestType,\n\t                 models_dir: str = None, dump_path: str = None,\n\t                 enforce_timewindows_delay: int = None,\n\t                 is_adaptiveness_enabled: bool = None, sessions_per_timewindow=None,\n\t                 debug: DebugLevel = DebugLevel.NONE, **kwargs):\n", "        if test_type == TestType.PROCESSING:\n\t            params = detection_engine_cls.de_params(\n\t                packets_per_session=kwargs.get(\"packets_per_session\", None),\n\t                features=len(detection_engine_cls.features_holder_cls.ALLOWED))\n\t            hold = detection_engine_cls.features_holder_cls()\n\t        else:\n\t            name = detection_engine_cls.model_name(**kwargs)\n\t            hold = detection_engine_cls.features_holder_cls(**load_json_data(\n\t                os.path.join(models_dir, name, \"relevance.json\")))\n\t            params = detection_engine_cls.de_params(**load_json_data(\n", "                os.path.join(models_dir, name, \"params.json\")))\n\t        self.analysis_state = self.analysis_state_cls(\n\t            time_window=time_window,\n\t            sessions_per_timewindow=sessions_per_timewindow,\n\t            enforce_timewindows_delay=enforce_timewindows_delay,\n\t            is_adaptiveness_enabled=is_adaptiveness_enabled,\n\t            current_key=current_key,\n\t            current_features=hold,\n\t            params=params)\n\t        self.test_type = test_type\n", "        self.dump_path = dump_path\n\t        self.start_time_window: int = None\n\t        self.blacklist_times = {}\n\t        self.extraction_times = {}\n\t        self.black_map: Dict[Type[BaseKey], bool] = {}\n\t        self.seen_sessions_previous_prediction: Dict[Type[BaseKey], str] = {}\n\t        self.current_untracked_map: Dict[Type[BaseKey], int] = {}\n\t        self.current_black_map: Dict[Type[BaseKey], int] = {}\n\t        self.current_session_map: Dict[Type[BaseKey], Type[SessionValue]] = {}\n\t        self.enforce_tasks: List[Ticker] = []\n", "        self.de: Type[DetectionEngine] = detection_engine_cls(\n\t            self.analysis_state, models_dir)\n\t        if test_type != TestType.PROCESSING:\n\t            a, b, c = self.de.load_model(params.__dict__, self.de.base_dir)\n\t            self.de.model = c\n\t            self.analysis_state.params = b\n\t            self.analysis_state.current_features = a\n\t            self.de._init_scale_method()\n\t        self.results = ResultTest()\n\t        self.attackers = {ds: (\n", "            next(x for x in attackers if x.dataset == ds).__class__,\n\t            {x: None for x in attackers if x.dataset == ds}) for ds in set([x.dataset for x in attackers])}\n\t        self.n_timewindow = 0\n\t        if test_type == TestType.PROCESSING:\n\t            self.processing_stats = detection_engine_cls.processing_data_cls()\n\t        self.debug = debug\n\t        if debug != DebugLevel.NONE:\n\t            self.debug_data = {}\n\t    @abstractmethod\n\t    def _extract(self, sess_id: Type[BaseKey], eth: EthInPcap):\n", "        \"\"\"Method defined by the TrafficAnalyser of each Detection Model for\n\t        the feature extraction of the sessions under monitoring.\"\"\"\n\t        pass\n\t    def _terminate_timewindow(self):\n\t        \"\"\"Method invoked at the end of each time window. Here the data is used\n\t        for the classification, and the malicious sessions are blacklisted accordingly.\n\t        In addition, the method to compute costs and statistics is called.\"\"\"\n\t        self.n_timewindow += 1\n\t        de_cpu, conversion_time, preprocessing_time, predict_time, de_mem, y_pred = 0, 0, 0, 0, 0, None\n\t        # check if at least 1 session is monitored.\n", "        if self.current_session_map:\n\t            data, conversion_time, preprocessing_time = self.de.preprocess_samples(\n\t                self)\n\t            predict_time = time.clock_gettime_ns(time.CLOCK_PROCESS_CPUTIME_ID)\n\t            y_pred = self.de.predict(\n\t                self.de.model, data, **self.analysis_state.params.__dict__)\n\t            predict_time = time.clock_gettime_ns(\n\t                time.CLOCK_PROCESS_CPUTIME_ID) - predict_time\n\t            de_mem = round(data.nbytes/len(y_pred))\n\t            de_cpu = self.de.parameters(model=self.de.model)\n", "            tmp = []\n\t            # assign the prediction to each flow and create the list of flows to be blacklisted\n\t            for p, (sess_id, v) in zip(y_pred, self.current_session_map.items()):\n\t                v.prediction = p.item()\n\t                if v.prediction > self.analysis_state.params.malicious_threshold and sess_id not in self.black_map:\n\t                    tmp.append(sess_id)\n\t            if tmp:\n\t                # insert the list as a Ticker task\n\t                self.enforce_tasks.append(\n\t                    Ticker(self.analysis_state.enforce_timewindows_delay, tmp))\n", "        if self.enforce_tasks:\n\t            # decrease all tasks by 1 and apply rules of all the ready ones\n\t            [x.tick() for x in self.enforce_tasks]\n\t            if self.enforce_tasks[0].ready:\n\t                t = self.enforce_tasks.pop(0)\n\t                for x in t.to_blacklist:\n\t                    if x not in self.black_map:\n\t                        self.black_map[x] = True\n\t        # compute costs and statistics for both the current time window and the global results\n\t        self._compute_cost(de_cpu, de_mem, self.blacklist_times, self.extraction_times,\n", "                           conversion_time, preprocessing_time, predict_time)\n\t        if self.analysis_state.is_adaptiveness_enabled:\n\t            raise NotImplementedError(\"To be implemented\")\n\t    @abstractmethod\n\t    def _terminate_timewindow_preprocessing(self):\n\t        \"\"\"Method defined by the TrafficAnalyser of each Detection Model to be\n\t        invoked at the end of a monitoring time window while preprocessing data.\"\"\"\n\t        raise NotImplementedError()\n\t    def _new_packet_preprocesser(self, ts, eth: EthInPcap = None):\n\t        \"\"\"Method used to handle a packet while preprocessing data\"\"\"\n", "        # set current start of the window if not already set\n\t        if not self.start_time_window:\n\t            self.start_time_window = ts\n\t        # check whether time window is finished\n\t        if self.analysis_state.time_window > 0 and ts - self.start_time_window > self.analysis_state.time_window:\n\t            # invoke method and clear all data structures (except global blacklist)\n\t            self._terminate_timewindow_preprocessing()\n\t            self.current_session_map.clear()\n\t            self.start_time_window = None\n\t        # check if IP packet or valid ethernet buffer\n", "        if eth is None or not eth[IP]:\n\t            return None\n\t        # compute the session identifier\n\t        sess_id = self.analysis_state.current_key.extract(eth)\n\t        # check if it is possible to monitor the session\n\t        if sess_id not in self.current_session_map:\n\t            self.current_session_map[sess_id] = self.session_value_cls()\n\t        # check if session already reached the max number of monitored packets\n\t        if self.analysis_state.params.packets_per_session and\\\n\t                self.current_session_map[sess_id].metered_packets == self.analysis_state.params.packets_per_session:\n", "            self.current_session_map[sess_id].unmetered_packets += 1\n\t            return\n\t        self.current_session_map[sess_id].metered_packets += 1\n\t        # compute and execute the feature extraction\n\t        self._extract(sess_id, eth)\n\t    def _new_packet(self, ts, eth: EthInPcap = None):\n\t        \"\"\"Method used to handle a new ethernet packet\"\"\"\n\t        # set current start of the window if not already set\n\t        if not self.start_time_window:\n\t            self.start_time_window = ts\n", "        # check whether time window is finished\n\t        if self.analysis_state.time_window > 0 and ts - self.start_time_window > self.analysis_state.time_window:\n\t            # invoke method and clear all data structures (except global blacklist)\n\t            self._terminate_timewindow()\n\t            self.current_session_map.clear()\n\t            self.current_black_map.clear()\n\t            self.current_untracked_map.clear()\n\t            self.extraction_times = {}\n\t            self.blacklist_times = {}\n\t            self.start_time_window = None\n", "        # check if IP packet or valid ethernet buffer\n\t        if eth is None or not eth[IP]:\n\t            return None\n\t        # compute the session identifier\n\t        sess_id = self.analysis_state.current_key.extract(eth)\n\t        # compute time for the blacklist lookup\n\t        t = time.clock_gettime_ns(time.CLOCK_PROCESS_CPUTIME_ID)\n\t        is_blacklisted = sess_id in self.black_map\n\t        t = time.clock_gettime_ns(time.CLOCK_PROCESS_CPUTIME_ID) - t\n\t        if (sess_id.dataset, sess_id.category, sess_id.pcap) not in self.blacklist_times:\n", "            self.blacklist_times[(\n\t                sess_id.dataset, sess_id.category, sess_id.pcap)] = 0\n\t        self.blacklist_times[(\n\t            sess_id.dataset, sess_id.category, sess_id.pcap)] += t\n\t        # block packet if blacklisted and NORMAL test\n\t        if not self.test_type == TestType.THROUGHPUT and is_blacklisted:\n\t            if sess_id not in self.current_black_map:\n\t                self.current_black_map[sess_id] = 0\n\t            self.current_black_map[sess_id] += 1\n\t            return\n", "        #  skip the analysis of the packet if the session is not monitored\n\t        if sess_id in self.current_untracked_map:\n\t            self.current_untracked_map[sess_id] += 1\n\t            return\n\t        # check if it is possible to monitor the session\n\t        if sess_id not in self.current_session_map:\n\t            # check if enough space\n\t            if self.analysis_state.sessions_per_timewindow and\\\n\t                    len(self.current_session_map) == self.analysis_state.sessions_per_timewindow:\n\t                self.current_untracked_map[sess_id] = 1\n", "                return\n\t            self.current_session_map[sess_id] = self.session_value_cls()\n\t        # check if session already reached the max number of monitored packets\n\t        if self.analysis_state.params.packets_per_session and\\\n\t                self.current_session_map[sess_id].metered_packets == self.analysis_state.params.packets_per_session:\n\t            self.current_session_map[sess_id].unmetered_packets += 1\n\t            return\n\t        self.current_session_map[sess_id].metered_packets += 1\n\t        # compute and execute the feature extraction\n\t        t = time.clock_gettime_ns(time.CLOCK_PROCESS_CPUTIME_ID)\n", "        self._extract(sess_id, eth)\n\t        t = time.clock_gettime_ns(time.CLOCK_PROCESS_CPUTIME_ID) - t\n\t        if (sess_id.dataset, sess_id.category, sess_id.pcap) not in self.extraction_times:\n\t            self.extraction_times[(\n\t                sess_id.dataset, sess_id.category, sess_id.pcap)] = 0\n\t        self.extraction_times[(\n\t            sess_id.dataset, sess_id.category, sess_id.pcap)] += t\n\t    @staticmethod\n\t    def generate_packets(pcap, analyser: \"TrafficAnalyser\", identifier=None, labels=None) -> int:\n\t        \"\"\"Method to generate packets  for the analyser provided from the pcap.\n", "        If present, this function tries to load the packets' labels, such as the\n\t        dataset category and pcap of belonging.\"\"\"\n\t        if identifier is None:\n\t            identifier = analyser.de.model_name(\n\t                **analyser.analysis_state.params.__dict__)\n\t        logger = get_logger(identifier)\n\t        if not labels:\n\t            with open(pcap.replace(\".pcap\", \".pickle\"), \"rb\") as fp:\n\t                labels = pickle.load(fp)\n\t            method = analyser._new_packet\n", "        else:\n\t            labels = cycle([labels])\n\t            method = analyser._new_packet_preprocesser\n\t        tot_bytes = os.path.getsize(pcap)\n\t        curr_bytes = 0\n\t        tot_time = 0\n\t        for curr_pkts, ((s_dataset, s_category, s_pcap), (ts, buf)) in enumerate(zip(labels, Reader(filename=pcap))):\n\t            if curr_pkts == 0:\n\t                tot_time = ts\n\t            curr_bytes += len(buf) + 16  # timestamp in nanoseconds\n", "            if curr_pkts % 50000 == 0:\n\t                logger.info(\"Read {}% bytes ({}/{}) and packet n°{}\".format(\n\t                    round(curr_bytes*100/tot_bytes, 2), curr_bytes, tot_bytes, curr_pkts))\n\t            try:\n\t                eth = EthInPcap(ts, s_dataset, s_category, s_pcap, buf)\n\t            except Exception:\n\t                eth = None\n\t            method(ts, eth=eth)\n\t        if analyser.test_type == TestType.PROCESSING:\n\t            analyser._terminate_timewindow_preprocessing()\n", "        else:\n\t            analyser._terminate_timewindow()\n\t            analyser.results.update()\n\t        logger.info(\"Finished\")\n\t        return ts - tot_time\n\t    def _get_sess_type(self, sess_id):\n\t        \"\"\"Method to return 0/1 whether the session identifier is malicious\"\"\"\n\t        return int(sess_id.cast(self.attackers[sess_id.dataset][0]) in self.attackers[sess_id.dataset][1])\n\t    def _compute_cost(self, de_cpu, de_mem, blacklist_times, extraction_times, conversion_time,\n\t                      preprocessing_time, predict_time, **kwargs):\n", "        \"\"\"Method for computing costs and statistics from the results of the current time\n\t        interval. Results are also propagated to the global results of the test accordingly.\"\"\"\n\t        tw_res = ResultTest()\n\t        # retrieve key and feature computational costs\n\t        key_comp_req = ComputationalRequirements.requirements_to_cost(\n\t            self.analysis_state.current_key.computational_requirements)\n\t        feat_comp_req = ComputationalRequirements.requirements_to_cost(\n\t            self.analysis_state.current_features.computational_requirements, ignore_depth=self.analysis_state.current_key)\n\t        if self.current_session_map:\n\t            pcap = {}\n", "            n_samples = len(self.current_session_map)\n\t            # adjust times to refer to a single flow\n\t            predict_time = safe_division(predict_time, n_samples, default=0.0)\n\t            preprocessing_time = safe_division(\n\t                preprocessing_time, n_samples, default=0.0)\n\t            conversion_time = safe_division(\n\t                conversion_time, n_samples, default=0.0)\n\t            for sess_id, v in self.current_session_map.items():\n\t                is_malicious = self._get_sess_type(sess_id)\n\t                prev_prediction = self.seen_sessions_previous_prediction.get(\n", "                    sess_id, None)\n\t                is_predicted_malicious = v.prediction > self.analysis_state.params.malicious_threshold\n\t                ttype = TestMetric.get_type_from_pred_true(\n\t                    is_predicted_malicious, is_malicious)\n\t                # check if dataset, category and pcap already present in results\n\t                if sess_id.dataset not in tw_res.datasets:\n\t                    tw_res.datasets[sess_id.dataset] = ResultTestDataset()\n\t                if sess_id.category not in tw_res.datasets[sess_id.dataset].categories:\n\t                    tw_res.datasets[sess_id.dataset].categories[sess_id.category] = ResultTestCategory(\n\t                    )\n", "                if sess_id.pcap not in tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures:\n\t                    tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures[sess_id.pcap] = TestMetric(\n\t                    )\n\t                if (sess_id.dataset, sess_id.category, sess_id.pcap) not in pcap:\n\t                    pcap[(sess_id.dataset, sess_id.category, sess_id.pcap)] = (\n\t                        [], [])\n\t                # appending ytrue and ypred\n\t                pcap[(sess_id.dataset, sess_id.category, sess_id.pcap)\n\t                     ][0].append(is_malicious)\n\t                pcap[(sess_id.dataset, sess_id.category, sess_id.pcap)\n", "                     ][1].append(v.prediction)\n\t                # update times\n\t                t = tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures[sess_id.pcap]\n\t                t.times.conversion_time += conversion_time\n\t                t.times.predict_time += predict_time\n\t                t.times.preprocessing_time += preprocessing_time\n\t                # depending by the nature of the session (TP, FN, etc.) update metrics accordingly\n\t                t1: BaseStats = getattr(\n\t                    getattr(\n\t                        tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures[sess_id.pcap],\n", "                        f\"{ttype}_stats\"),\n\t                    \"new\" if prev_prediction is None else\n\t                    \"from_same\" if prev_prediction == ttype else \"from_opposite\")\n\t                t1.traffic_analyser_memory += self.analysis_state.current_key.memory_requirements + \\\n\t                    self.analysis_state.current_features.memory_requirements * \\\n\t                    (1 if isinstance(v.value[0],\n\t                     AggBaseFeature) else v.metered_packets)\n\t                t1.detection_engine_memory += de_mem\n\t                t1.detection_engine_cpu += de_cpu\n\t                t1.traffic_analyser_cpu += key_comp_req * (v.metered_packets+v.unmetered_packets) +\\\n", "                    feat_comp_req * v.metered_packets\n\t                t1.sessions += 1\n\t                t1.metered_packets += v.metered_packets\n\t                t1.unmetered_packets += v.unmetered_packets\n\t                if v.unmetered_packets:\n\t                    t1.sessions_with_unmetered_packets += 1\n\t                if is_predicted_malicious and prev_prediction not in ('tp', 'fp'):\n\t                    t1.mitigated_sessions += 1\n\t                    t1.mitigator_memory += self.analysis_state.current_key.memory_requirements\n\t                self.seen_sessions_previous_prediction[sess_id] = ttype\n", "            # Update extraction times for the right pcap\n\t            for (d, c, p), v in extraction_times.items():\n\t                tw_res.datasets[d].categories[c].captures[p].times.extraction_time += v\n\t            # update ytrue, ypred and threshold accordingly\n\t            for (d, c, p), v in pcap.items():\n\t                tw_res.datasets[d].categories[c].captures[p]._ytrue = np.array(\n\t                    v[0], dtype=np.float64)\n\t                tw_res.datasets[d].categories[c].captures[p]._ypred = np.array(\n\t                    v[1], dtype=np.float64)\n\t                tw_res.datasets[d].categories[c].captures[p]._threshold = [\n", "                    (self.analysis_state.params.malicious_threshold, len(v[0]))]\n\t        # for each untracked session update stats\n\t        for sess_id, v in self.current_untracked_map.items():\n\t            if sess_id.dataset not in tw_res.datasets:\n\t                tw_res.datasets[sess_id.dataset] = ResultTestDataset()\n\t            if sess_id.category not in tw_res.datasets[sess_id.dataset].categories:\n\t                tw_res.datasets[sess_id.dataset].categories[sess_id.category] = ResultTestCategory(\n\t                )\n\t            if sess_id.pcap not in tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures:\n\t                tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures[sess_id.pcap] = TestMetric(\n", "                    _threshold=[(self.analysis_state.params.malicious_threshold, 0)])\n\t            t2: Stats = getattr(tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures[sess_id.pcap],\n\t                                'tp_stats' if self._get_sess_type(sess_id) else 'fp_stats')\n\t            t2.ignored_sessions += 1\n\t            t2.ignored_packets += v\n\t        # foreach session that appeared in the blacklist in the current time interval\n\t        # update stats accordingly\n\t        for sess_id, v in self.current_black_map.items():\n\t            if sess_id.dataset not in tw_res.datasets:\n\t                tw_res.datasets[sess_id.dataset] = ResultTestDataset()\n", "            if sess_id.category not in tw_res.datasets[sess_id.dataset].categories:\n\t                tw_res.datasets[sess_id.dataset].categories[sess_id.category] = ResultTestCategory(\n\t                )\n\t            if sess_id.pcap not in tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures:\n\t                tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures[sess_id.pcap] = TestMetric(\n\t                    _threshold=[(self.analysis_state.params.malicious_threshold, 0)])\n\t            t3: Stats = getattr(tw_res.datasets[sess_id.dataset].categories[sess_id.category].captures[sess_id.pcap],\n\t                                'tp_stats' if self._get_sess_type(sess_id) else 'fp_stats')\n\t            t3.mitigated_packets += v\n\t            t3.mitigated_sessions_reappeared += 1\n", "            t3.mitigator_cpu += key_comp_req * v\n\t        # update blacklist times of the pcap\n\t        for (d, c, p), v in blacklist_times.items():\n\t            tw_res.datasets[d].categories[c].captures[p].times.blacklist_time += v\n\t        # update global results without recomputing metrics (too expensive, done only at the end of the test)\n\t        self.results.update(tw_res)\n\t        # check the debug level and in case recompute metrics and update debug data structures\n\t        if self.debug == DebugLevel.BASE:\n\t            tw_res.update()\n\t            self.debug_data[self.n_timewindow] = replace(tw_res)\n", "        elif self.debug == DebugLevel.ENHANCED:\n\t            tw_res.update()\n\t            self.debug_data[self.n_timewindow] = {\n\t                \"result\": replace(tw_res),\n\t                \"analysis_state\": replace(self.analysis_state),\n\t                \"session_map\": self.current_session_map.copy(),\n\t                \"untracked_map\": self.current_untracked_map.copy(),\n\t                \"black_map\": self.current_black_map.copy()\n\t            }\n\tclass DetectionEngine(ABC):\n", "    \"\"\"Main Abstract class for representing a Detection Engine\"\"\"\n\t    # class to be used when processing data\n\t    processing_data_cls = BaseProcessingData\n\t    # class to be used for the parameters of the model\n\t    de_params = DeParams\n\t    def __init__(self, analysis_state: Type[AnalysisState], base_dir: str) -> None:\n\t        self.model = None\n\t        self.analysis_state = analysis_state\n\t        self.base_dir: str = base_dir\n\t    def __del__(self):\n", "        del self.model\n\t    @staticmethod\n\t    def list_all(only_main=False):\n\t        \"\"\" Method to list all Detection Models available in this framework\"\"\"\n\t        ret = []\n\t        basepath = os.path.join(os.path.dirname(__file__), \"engines\")\n\t        for x in os.listdir(basepath):\n\t            if (only_main and os.path.isdir(os.path.join(\n\t                basepath, x, \"main\"))) or (not only_main and not x.startswith(\"_\") and\n\t                                           (x.endswith(\".py\") or os.path.isdir(os.path.join(basepath, x)))):\n", "                ret.append(snake_to_camel(x.replace(\".py\", \"\")))\n\t        return ret\n\t    @abstractclassmethod\n\t    def load_model(cls, params: Union[DeParams, Dict], basedir: str):\n\t        \"\"\"Abstract method to be implemented, used for loading the model\"\"\"\n\t        raise NotImplementedError()\n\t    def _init_scale_method(self):\n\t        pass\n\t    @staticmethod\n\t    def _load_dataset(basename, features_holder: FeaturesHolder, packets_per_session=None,\n", "                      max_packets_per_session=None, max_features=None,\n\t                      split_type=SplitType.NONE, split_chunk: Tuple[int, int] = tuple(), **kwargs):\n\t        raise NotImplementedError()\n\t    @staticmethod\n\t    @abstractmethod\n\t    def _fed_adapt_layer(src_w, dst_w, global_f, local_f, pad=False):\n\t        raise NotImplementedError()\n\t    @abstractclassmethod\n\t    def parameters(cls, model=None, **kwargs) -> int:\n\t        \"\"\"Method to be implemented and return the complexity of the model in terms of\n", "        trainable parameters\"\"\"\n\t        raise NotImplementedError()\n\t    @classmethod\n\t    @property\n\t    @abstractmethod\n\t    def features_holder_cls(cls) -> Type[FeaturesHolder]:\n\t        \"\"\"Feature Holder class to be specified when implementing the Detection Model\"\"\"\n\t        pass\n\t    @classmethod\n\t    @property\n", "    @abstractmethod\n\t    def traffic_analyser_cls(cls) -> Type[TrafficAnalyser]:\n\t        \"\"\"The Traffic Analyser class to be specified when implementing the Detection Model\"\"\"\n\t        pass\n\t    @abstractclassmethod\n\t    def _get_arch(*args, **kwargs):\n\t        \"\"\"Method to get an instance of the model according to the provided arguments\"\"\"\n\t        pass\n\t    @abstractmethod\n\t    def preprocess_samples(self, ta: Type[TrafficAnalyser], skip: bool = False) -> Tuple[np.ndarray, int, int]:\n", "        \"\"\"Method to preprocess samples captured by the analyser\"\"\"\n\t        pass\n\t    @classmethod\n\t    def predict(cls, model, data, **kwargs) -> np.ndarray:\n\t        \"\"\"Method for classifying the data\"\"\"\n\t        pass\n\t    @abstractclassmethod\n\t    def model_name(cls, features: int = None, **kwargs) -> str:\n\t        \"\"\"Method for returning the name of a model given the parameters provided\"\"\"\n\t        pass\n", "    @staticmethod\n\t    def import_de(name: str) -> Type[\"DetectionEngine\"]:\n\t        \"\"\"Method for importing and returning the Detection Engine class provided as string\"\"\"\n\t        return getattr(importlib.import_module('.engines.{}'.format(camel_to_snake(name)), package=\"enid.lib\"), name)\n\t    @staticmethod\n\t    @abstractmethod\n\t    def append_to_dataset(source, dest, ttype, label, indexes_tr, indexes_val, indexes_ts, **kwargs):\n\t        \"\"\"Method for appending single processed data to the dataset\"\"\"\n\t        pass\n\t    @abstractclassmethod\n", "    def train(cls, dataset_path: str, models_dir: str, params: Type[DeParams], split_type: SplitType,\n\t              split_chunk: Tuple[int, int], **kwargs):\n\t        \"\"\"Method for training an instance of the model\"\"\"\n\t        pass\n\t    @staticmethod\n\t    def intersect(engines_list: List[Type[\"DetectionEngine\"]]) -> bool:\n\t        \"\"\"Method to check whether the provided Engines intersect, meaning\n\t        they can be used with the same preprocessed data\"\"\"\n\t        engines_list = [x if isinstance(\n\t            x, DetectionEngine) else DetectionEngine.import_de(x) for x in engines_list]\n", "        return all(set(engines_list[0].features_holder_cls.ALLOWED) == set(elem.features_holder_cls.ALLOWED)\n\t                   for elem in engines_list) and\\\n\t            all(engines_list[0].append_to_dataset.__code__ ==\n\t                elem.append_to_dataset.__code__ and\n\t                engines_list[0].traffic_analyser_cls._new_packet.__code__ == elem.traffic_analyser_cls._new_packet.__code__\n\t                for elem in engines_list)\n"]}
{"filename": "enid/lib/metrics.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"File for defining metrics used within the offline and online test\"\"\"\n\timport math\n\tfrom dataclasses import dataclass, field, fields\n\tfrom enum import Enum\n\tfrom typing import Dict, List, Tuple, Type, Union\n\timport numpy as np\n\tfrom sklearn.metrics import (accuracy_score, average_precision_score,\n", "                             balanced_accuracy_score, confusion_matrix,\n\t                             f1_score, log_loss, precision_recall_curve,\n\t                             precision_score, recall_score, roc_auc_score,\n\t                             roc_curve)\n\tfrom .utility import CDataJSONEncoder, UpdatableDataclass, safe_division\n\tclass ComputationalRequirements(Enum):\n\t    \"\"\"Enumeration for representing the computational requirements of features and key fields\"\"\"\n\t    REQUIRED_L2 = 3\n\t    REQUIRED_L3 = REQUIRED_L2 + 3\n\t    REQUIRED_L4 = REQUIRED_L3 + 5\n", "    HASH_COMPUTATION = 3\n\t    BASE_MATH_OP = 1\n\t    ENHANCED_MATH_OP = 2\n\t    TIMER = 5\n\t    @staticmethod\n\t    def requirements_to_cost(requirements_lists: Tuple[\"ComputationalRequirements\"], ignore_depth: bool = False):\n\t        cost = 0\n\t        if ignore_depth is not True:\n\t            if isinstance(ignore_depth, bool):\n\t                target = requirements_lists\n", "            else:\n\t                from .definitions import BaseKey\n\t                ignore_depth: BaseKey = ignore_depth\n\t                target = tuple(x for x in (ComputationalRequirements.REQUIRED_L4,\n\t                                           ComputationalRequirements.REQUIRED_L3,\n\t                                           ComputationalRequirements.REQUIRED_L2)\n\t                               if x not in ignore_depth.computational_requirements)\n\t            if ComputationalRequirements.REQUIRED_L4 in target:\n\t                cost += ComputationalRequirements.REQUIRED_L4.value\n\t            elif ComputationalRequirements.REQUIRED_L3 in target:\n", "                cost += ComputationalRequirements.REQUIRED_L3.value\n\t            elif ComputationalRequirements.REQUIRED_L2 in target:\n\t                cost += ComputationalRequirements.REQUIRED_L2.value\n\t        for y in (ComputationalRequirements.HASH_COMPUTATION, ComputationalRequirements.BASE_MATH_OP,\n\t                  ComputationalRequirements.ENHANCED_MATH_OP, ComputationalRequirements.TIMER):\n\t            cost += y.value*requirements_lists.count(y)\n\t        return cost\n\t@dataclass\n\tclass TrainMetric:\n\t    \"\"\"Class for holding the train metrics\"\"\"\n", "    tp: int = 0\n\t    fp: int = 0\n\t    tn: int = 0\n\t    fn: int = 0\n\t    tpr: float = 0\n\t    fpr: float = 0\n\t    tnr: float = 0\n\t    fnr: float = 0\n\t    log_loss: float = 0\n\t    mcc: float = 0\n", "    cohen_k: float = 0\n\t    gmean: float = 0\n\t    f1_score: float = 0\n\t    accuracy: float = 0\n\t    balanced_accuracy: float = 0\n\t    roc_auc: float = 0\n\t    recall: float = 0\n\t    precision: float = 0\n\t    average_precision: float = 0\n\t    best_roc_threshold: float = 0\n", "    best_roc_gmean: float = 0\n\t    best_precision_recall_threshold: float = 0\n\t    best_precision_recall_f1score: float = 0\n\t    _threshold: List[Tuple[float, int]] = field(\n\t        default_factory=list, repr=False)\n\t    _ypred: np.ndarray = field(default=np.array(\n\t        [], dtype=np.float64), repr=False)\n\t    _ytrue: np.ndarray = field(default=np.array(\n\t        [], dtype=np.float64), repr=False)\n\t    def to_json(self):\n", "        \"\"\"Method to dump the class in a json-style\"\"\"\n\t        e = CDataJSONEncoder()\n\t        return {k.name: e.default(getattr(self, k.name)) for k in fields(self) if k.repr}\n\t    @staticmethod\n\t    def get_best_threshold_roc(y_pred, y_true):\n\t        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n\t        # calculate the g-mean for each threshold\n\t        gmeans = np.sqrt(tpr * (1-fpr))\n\t        np.nan_to_num(gmeans, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n\t        # locate the index of the largest g-mean\n", "        ix = np.argmax(gmeans)\n\t        return thresholds[ix], gmeans[ix]\n\t    @staticmethod\n\t    def get_best_threshold_f1(y_pred, y_true):\n\t        precision, recall, thresholds = precision_recall_curve(\n\t            y_true, y_pred)\n\t        # convert to f score\n\t        fscore = (2 * precision * recall) / (precision + recall)\n\t        np.nan_to_num(fscore, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n\t        # locate the index of the largest f score\n", "        ix = np.argmax(fscore)\n\t        return thresholds[ix], fscore[ix]\n\t    def __post_init__(self):\n\t        \"\"\"Method called after initialisation. If the class is not empty,\n\t        this method computes all the metrics.\"\"\"\n\t        if not isinstance(self._threshold, list):\n\t            self._threshold = [(self._threshold, self._ytrue.size)]\n\t        if self._ypred.size == 0 or self._ytrue.size == 0:\n\t            return\n\t        self.best_roc_threshold, self.best_roc_gmean = self.get_best_threshold_roc(\n", "            self._ypred, self._ytrue)\n\t        self.best_precision_recall_threshold, self.best_precision_recall_f1score = self.get_best_threshold_f1(\n\t            self._ypred, self._ytrue)\n\t        self.log_loss = log_loss(self._ytrue, self._ypred, labels=[0, 1])\n\t        ypred = np.copy(self._ypred)\n\t        # Since it might be possible that the threshold changed during the time,\n\t        # here we make sure to use the right threshold for the various\n\t        # bunch of data\n\t        prev_index = 0\n\t        for (t, index) in self._threshold:\n", "            if prev_index - index != 0:\n\t                ypred[prev_index:index] = ypred[prev_index:index] > t\n\t                prev_index = index\n\t        self.tn, self.fp, self.fn, self.tp = confusion_matrix(\n\t            self._ytrue, ypred, labels=[0, 1]).ravel()\n\t        self.tpr = safe_division(self.tp, self.tp + self.fn, default=0.0)\n\t        self.tnr = safe_division(self.tn, self.tn + self.fp, default=0.0)\n\t        self.fpr = safe_division(self.fp, self.fp + self.tn, default=0.0)\n\t        self.fnr = safe_division(self.fn, self.fn + self.tp, default=0.0)\n\t        self.mcc = safe_division(self.tn*self.tp-self.fn*self.fp, math.sqrt(\n", "            (self.tp+self.fp) * (self.tp + self.fn) * (self.tn + self.fp) * (self.tn + self.fn)),\n\t            default=0.0)\n\t        self.cohen_k = safe_division(2*(self.tp*self.tn - self.fn * self.fp),\n\t                                     (self.tp + self.fp) * (self.fp + self.tn) *\n\t                                     (self.tp + self.fn) * (self.fn + self.tn), default=0.0)\n\t        self.gmean = np.sqrt(self.tpr * (1-self.fpr))\n\t        self.f1_score = f1_score(self._ytrue, ypred, labels=[0, 1])\n\t        self.accuracy = accuracy_score(self._ytrue, ypred)\n\t        self.balanced_accuracy = balanced_accuracy_score(self._ytrue, ypred)\n\t        try:\n", "            self.roc_auc = roc_auc_score(self._ytrue, ypred, labels=[0, 1])\n\t        except ValueError:\n\t            self.roc_auc = 0.0\n\t        self.recall = recall_score(self._ytrue, ypred, labels=[0, 1])\n\t        self.precision = precision_score(self._ytrue, ypred, labels=[0, 1])\n\t        self.average_precision = average_precision_score(self._ytrue, ypred)\n\t    def update(self, other: \"TrainMetric\"):\n\t        \"\"\"Method to update such a class with another given one\"\"\"\n\t        i = self._threshold[-1][1] if self._threshold else 0\n\t        for (t, j) in other._threshold:\n", "            self._threshold.append((t, i+j))\n\t        self._ypred = np.concatenate(\n\t            (self._ypred, other._ypred), axis=0, dtype=np.float64)\n\t        self._ytrue = np.concatenate(\n\t            (self._ytrue, other._ytrue), axis=0, dtype=np.float64)\n\t        self.__post_init__()\n\t    @classmethod\n\t    def get_metrics(cls):\n\t        \"\"\"Method to return all the metrics defined in this class\"\"\"\n\t        return [k.name for k in fields(cls) if k.repr and k.name not in (\"tp\", \"tn\", \"fp\", \"fn\")]\n", "@dataclass\n\tclass BaseStats(UpdatableDataclass):\n\t    \"\"\"Base statistic class holding stats concerning a certain type of flows (new, etc.)\"\"\"\n\t    sessions: int = 0\n\t    mitigated_sessions: int = 0\n\t    metered_packets: int = 0\n\t    unmetered_packets: int = 0\n\t    sessions_with_unmetered_packets: int = 0\n\t    mitigator_memory: int = 0\n\t    traffic_analyser_memory: int = 0\n", "    detection_engine_memory: int = 0\n\t    traffic_analyser_cpu: int = 0\n\t    detection_engine_cpu: int = 0\n\t@dataclass\n\tclass Stats(UpdatableDataclass):\n\t    \"\"\"Stats class to hold information about all kind of flows within a certain\n\t    type (TP, FP).\"\"\"\n\t    # newly monitored\n\t    new: BaseStats = field(default_factory=BaseStats)\n\t    # already monitored and with the same prediction\n", "    from_same: BaseStats = field(default_factory=BaseStats)\n\t    # already monitored but with the opposite prediction\n\t    from_opposite: BaseStats = field(default_factory=BaseStats)\n\t    ignored_sessions: int = 0\n\t    ignored_packets: int = 0\n\t    mitigated_packets: int = 0\n\t    mitigated_sessions_reappeared: int = 0\n\t    mitigator_cpu: int = 0\n\t    def __post_init__(self):\n\t        for k in (\"new\", \"from_same\", \"from_opposite\"):\n", "            if isinstance(getattr(self, k), dict):\n\t                setattr(self, k, BaseStats(**getattr(self, k)))\n\t@dataclass\n\tclass Times(UpdatableDataclass):\n\t    \"\"\"Class to hold times recorded during the online test\"\"\"\n\t    blacklist_time: float = 0\n\t    extraction_time: float = 0\n\t    preprocessing_time: float = 0\n\t    conversion_time: float = 0\n\t    predict_time: float = 0\n", "    @property\n\t    def no_conversion(self):\n\t        return self.blacklist_time + self.extraction_time + self.preprocessing_time + self.predict_time\n\t    @property\n\t    def total(self):\n\t        return self.no_conversion + self.conversion_time\n\t@dataclass\n\tclass TestMetric(TrainMetric):\n\t    \"\"\"Class to hold all metrics used within the online test. Additional information\n\t    concerning each nature of flows (TP, etc.) are mantained separetely.\"\"\"\n", "    flows_per_second: float = 0.0\n\t    packets_per_second: float = 0.0\n\t    packets_fnr_time_window: float = 0.0\n\t    packets_fnr_early_mitigation: float = 0.0\n\t    packets_tpr_time_window: float = 0.0\n\t    packets_tpr_early_mitigation: float = 0.0\n\t    packets_tnr_time_window: float = 0.0\n\t    packets_tnr_early_mitigation: float = 0.0\n\t    packets_fpr_time_window: float = 0.0\n\t    packets_fpr_early_mitigation: float = 0.0\n", "    benign_traffic_metered_percentage: float = 0.0\n\t    malicious_traffic_metered_percentage: float = 0.0\n\t    traffic_metered_percentage: float = 0.0\n\t    flows_with_unmetered_packets_percentage: float = 0.0\n\t    benign_flows_with_unmetered_packets_percentage: float = 0.0\n\t    malicious_flows_with_unmetered_packets_percentage: float = 0.0\n\t    estimated_traffic_analyser_memory_bytes: int = 0\n\t    estimated_traffic_analyser_cpu_instructions: int = 0\n\t    estimated_detection_engine_memory_bytes: int = 0\n\t    estimated_detection_engine_cpu_instructions: int = 0\n", "    estimated_mitigator_memory_bytes: int = 0\n\t    estimated_mitigator_cpu_instructions: int = 0\n\t    estimated_memory_bytes: int = 0\n\t    estimated_cpu_instructions: int = 0\n\t    times: Times = field(default_factory=Times)\n\t    tp_stats: Stats = field(default_factory=Stats)\n\t    fp_stats: Stats = field(default_factory=Stats)\n\t    tn_stats: Stats = field(default_factory=Stats)\n\t    fn_stats: Stats = field(default_factory=Stats)\n\t    def __post_init__(self):\n", "        \"\"\"If the class is not empty, then compute all the metrics\"\"\"\n\t        super().__post_init__()\n\t        for k in (\"tn_stats\", \"fn_stats\", \"tp_stats\", \"fp_stats\"):\n\t            if not isinstance(getattr(self, k), Stats):\n\t                setattr(self, k, Stats(**getattr(self, k)))\n\t        if not isinstance(self.times, Times):\n\t            self.times = Times(**self.times)\n\t        if self._ypred.size == 0:\n\t            return\n\t        self.flows_with_unmetered_packets_percentage = safe_division(self.get_stats_for(\n", "            \"sessions_with_unmetered_packets\"), self.tp + self.tn + self.fp + self.fn)\n\t        self.benign_flows_with_unmetered_packets_percentage = safe_division(self.get_stats_for(\n\t            \"sessions_with_unmetered_packets\", (\"tn_stats\", \"fp_stats\")), self.tn + self.fp)\n\t        self.malicious_flows_with_unmetered_packets_percentage = safe_division(self.get_stats_for(\n\t            \"sessions_with_unmetered_packets\", (\"tp_stats\", \"fn_stats\")), self.tp + self.fn)\n\t        self.estimated_traffic_analyser_memory_bytes = self.get_stats_for(\n\t            \"traffic_analyser_memory\")\n\t        self.estimated_detection_engine_memory_bytes = self.get_stats_for(\n\t            \"detection_engine_memory\")\n\t        self.estimated_mitigator_memory_bytes = self.get_stats_for(\n", "            \"mitigator_memory\")\n\t        self.estimated_memory_bytes = self.estimated_traffic_analyser_memory_bytes + \\\n\t            self.estimated_mitigator_memory_bytes + \\\n\t            self.estimated_detection_engine_memory_bytes\n\t        self.estimated_mitigator_cpu_instructions = self.get_stats_for(\n\t            \"mitigator_cpu\")\n\t        self.estimated_traffic_analyser_cpu_instructions = self.get_stats_for(\n\t            \"traffic_analyser_cpu\")\n\t        self.estimated_detection_engine_cpu_instructions = self.get_stats_for(\n\t            \"detection_engine_cpu\")\n", "        self.estimated_cpu_instructions = self.estimated_mitigator_cpu_instructions + \\\n\t            self.estimated_traffic_analyser_cpu_instructions + \\\n\t            self.estimated_detection_engine_cpu_instructions\n\t        self.flows_per_second = safe_division(\n\t            (self.tp + self.tn + self.fp + self.fn) * 10**9, self.times.no_conversion)\n\t        self.packets_per_second = safe_division(\n\t            self.total_packets * 10**9, self.times.no_conversion)\n\t        self.packets_fnr_time_window = safe_division(self.get_stats_for(\n\t            (\"metered_packets\", \"unmetered_packets\"), (\"tp_stats\", \"fn_stats\")), self.total_malicious_packets)\n\t        self.packets_fnr_early_mitigation = safe_division(self.get_stats_for(\n", "            \"metered_packets\", \"tp_stats\") + self.get_stats_for((\"metered_packets\", \"unmetered_packets\"), \"fn_stats\"),\n\t            self.total_malicious_packets)\n\t        self.packets_tpr_time_window = 1 - self.packets_fnr_time_window\n\t        self.packets_tpr_early_mitigation = 1 - self.packets_fnr_early_mitigation\n\t        self.packets_tnr_time_window = safe_division(self.get_stats_for(\n\t            (\"metered_packets\", \"unmetered_packets\"), (\"tn_stats\", \"fp_stats\")), self.total_benign_packets)\n\t        self.packets_tnr_early_mitigation = safe_division(self.get_stats_for(\n\t            \"metered_packets\", \"fp_stats\") + self.get_stats_for((\"metered_packets\", \"unmetered_packets\"), \"tn_stats\"),\n\t            self.total_benign_packets)\n\t        self.packets_fpr_time_window = 1 - self.packets_tnr_time_window\n", "        self.packets_fpr_early_mitigation = 1 - self.packets_tnr_early_mitigation\n\t        self.benign_traffic_metered_percentage = safe_division(self.get_stats_for(\n\t            \"metered_packets\", (\"tn_stats\", \"fp_stats\")), self.total_benign_packets)\n\t        self.malicious_traffic_metered_percentage = safe_division(self.get_stats_for(\n\t            \"metered_packets\", (\"tp_stats\", \"fn_stats\")), self.total_malicious_packets)\n\t        self.traffic_metered_percentage = safe_division(\n\t            self.get_stats_for(\"metered_packets\"), self.total_packets)\n\t    def get_stats_for(\n\t            self,\n\t            attrs: Union[str, Tuple[str]],\n", "            natures: Union[str, Tuple[str]] = (\n\t                \"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\"),\n\t            types: Union[str, Tuple[str]] = (\"new\", \"from_same\", \"from_opposite\")):\n\t        \"\"\"Methods to return the desired values from all attributes matching the provided ones\"\"\"\n\t        if not isinstance(attrs, (tuple, list)):\n\t            attrs = (attrs, )\n\t        if not isinstance(natures, (tuple, list)):\n\t            natures = (natures, )\n\t        if not isinstance(types, (tuple, list)):\n\t            types = (types, )\n", "        third_nested = tuple(\n\t            x for x in attrs if next((y for y in fields(BaseStats) if x == y.name), False))\n\t        second_nested = tuple(\n\t            x for x in attrs if next((y for y in fields(Stats) if x == y.name), False))\n\t        return sum(getattr(getattr(getattr(self, x), y), z) for x in natures for y in types for z in third_nested) +\\\n\t            sum(getattr(getattr(self, x), z)\n\t                for x in natures for z in second_nested)\n\t    @classmethod\n\t    def get_metrics(cls):\n\t        \"\"\"Method to return all the metrics defined by this class\"\"\"\n", "        return [k.name for k in fields(cls) if k.repr and k.name not in (\n\t            \"tp\", \"tn\", \"fp\", \"fn\", \"tp_stats\", \"tn_stats\", \"fp_stats\", \"fn_stats\", \"times\")]\n\t    @staticmethod\n\t    def get_type_from_pred_true(is_predicted_malicious: bool, is_malicious: bool) -> str:\n\t        \"\"\"Method to return the nature of a flow given its true value and the predicted one\"\"\"\n\t        if is_malicious and is_predicted_malicious:\n\t            return \"tp\"\n\t        elif is_predicted_malicious and is_malicious != is_predicted_malicious:\n\t            return \"fp\"\n\t        elif not is_predicted_malicious and not is_malicious:\n", "            return \"tn\"\n\t        elif not is_predicted_malicious and is_malicious != is_predicted_malicious:\n\t            return \"fn\"\n\t        else:\n\t            raise ValueError(\"Do not know how to infer\")\n\t    def update(self, other: \"TestMetric\"):\n\t        \"\"\"Method to update this instance with another one\"\"\"\n\t        [getattr(self, x).update(getattr(other, x))\n\t         for x in (\"times\", \"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t        super().update(other)\n", "    @property\n\t    def total_malicious_packets(self):\n\t        return self.get_stats_for((\"metered_packets\", \"unmetered_packets\", \"mitigated_packets\"),\n\t                                  (\"tp_stats\", \"fn_stats\"))\n\t    @property\n\t    def total_benign_packets(self):\n\t        return self.get_stats_for((\"metered_packets\", \"unmetered_packets\", \"mitigated_packets\", \"ignored_packets\"),\n\t                                  (\"tn_stats\", \"fp_stats\"))\n\t    @property\n\t    def total_packets(self):\n", "        return self.get_stats_for((\"metered_packets\", \"unmetered_packets\", \"mitigated_packets\", \"ignored_packets\"))\n\t@dataclass\n\tclass ResultTestCategory(TestMetric):\n\t    captures: Dict[str, TestMetric] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        super().__post_init__()\n\t        for k in self.captures:\n\t            if not isinstance(self.captures[k], TestMetric):\n\t                self.captures[k] = TestMetric(**self.captures[k])\n\t@dataclass\n", "class ResultTestDataset(TestMetric):\n\t    categories: Dict[str, ResultTestCategory] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        super().__post_init__()\n\t        for k in self.categories:\n\t            if not isinstance(self.categories[k], ResultTestCategory):\n\t                self.categories[k] = ResultTestCategory(**self.datasets[k])\n\t@dataclass\n\tclass ResultTest(TestMetric):\n\t    \"\"\"Class holding results of the online test divided by granularity.\"\"\"\n", "    datasets: Dict[str, ResultTestDataset] = field(default_factory=dict)\n\t    def __post_init__(self):\n\t        super().__post_init__()\n\t        for k in self.datasets:\n\t            if not isinstance(self.datasets[k], ResultTestDataset):\n\t                self.datasets[k] = ResultTestDataset(**self.datasets[k])\n\t    def update(self, other: Type[\"ResultTest\"] = None):\n\t        \"\"\"Method to update such a class with the provided one. If the other one is not provided, then\n\t        this method recomputes the data of this class by starting from the most inner ones (pcap granularity)\n\t        untill the more generic ones are created.\"\"\"\n", "        if other:\n\t            # for each pcap in other, update pcap of this class.\n\t            # note that we update only pcap, as the category/dataset/general data\n\t            # is updated by invoking this method with no argument\n\t            for k, v in other.datasets.items():\n\t                if k not in self.datasets:\n\t                    self.datasets[k] = ResultTestDataset()\n\t                for kk, vv in v.categories.items():\n\t                    if kk not in self.datasets[k].categories:\n\t                        self.datasets[k].categories[kk] = ResultTestCategory()\n", "                    for kkk, vvv in vv.captures.items():\n\t                        if kkk not in self.datasets[k].categories[kk].captures:\n\t                            self.datasets[k].categories[kk].captures[kkk] = TestMetric(\n\t                            )\n\t                        tresh = vvv._threshold[-1][0]\n\t                        self.datasets[k].categories[kk].captures[kkk]._ypred = np.concatenate(\n\t                            (self.datasets[k].categories[kk].captures[kkk]._ypred, vvv._ypred), axis=0, dtype=np.float64)\n\t                        self.datasets[k].categories[kk].captures[kkk]._ytrue = np.concatenate(\n\t                            (self.datasets[k].categories[kk].captures[kkk]._ytrue, vvv._ytrue), axis=0, dtype=np.float64)\n\t                        self.datasets[k].categories[kk].captures[kkk]._threshold.append(\n", "                            (tresh, len(self.datasets[k].categories[kk].captures[kkk]._ytrue)))\n\t                        [getattr(self.datasets[k].categories[kk].captures[kkk], x).update(getattr(\n\t                            vvv, x)) for x in (\"times\", \"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t            for k, v in self.datasets.items():\n\t                for kk, vv in v.categories.items():\n\t                    for kkk, vvv in vv.captures.items():\n\t                        if k not in other.datasets or kk not in other.datasets[k].categories or\\\n\t                                kkk not in other.datasets[k].categories[kk].captures:\n\t                            self.datasets[k].categories[kk].captures[kkk]._threshold.append(\n\t                                (tresh, len(self.datasets[k].categories[kk].captures[kkk]._ytrue)))\n", "        else:\n\t            # Recompute stats starting by the pcap granularity until the more generic one\n\t            self._ypred = np.array([], dtype=np.float64)\n\t            self._ytrue = np.array([], dtype=np.float64)\n\t            self.times = Times()\n\t            [setattr(self, x, Stats())\n\t             for x in (\"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t            for v in self.datasets.values():\n\t                v._ypred = np.array([], dtype=np.float64)\n\t                v._ytrue = np.array([], dtype=np.float64)\n", "                v.times = Times()\n\t                [setattr(v, x, Stats())\n\t                 for x in (\"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t                for vv in v.categories.values():\n\t                    vv._ypred = np.array([], dtype=np.float64)\n\t                    vv._ytrue = np.array([], dtype=np.float64)\n\t                    vv.times = Times()\n\t                    [setattr(vv, x, Stats()) for x in (\n\t                        \"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t                    for vvv in vv.captures.values():\n", "                        vvv.__post_init__()\n\t                        vv._ypred = np.concatenate(\n\t                            (vv._ypred, vvv._ypred), axis=0, dtype=np.float64)\n\t                        vv._ytrue = np.concatenate(\n\t                            (vv._ytrue, vvv._ytrue), axis=0, dtype=np.float64)\n\t                        [getattr(vv, x).update(getattr(vvv, x)) for x in (\n\t                            \"times\", \"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t                    it = next(vvv._threshold for vvv in vv.captures.values())\n\t                    vv._threshold = [(it[i][0], sum(\n\t                        vvv._threshold[i][1] for vvv in vv.captures.values())) for i in range(len(it))]\n", "                    vv.__post_init__()\n\t                    v._ypred = np.concatenate(\n\t                        (v._ypred, vv._ypred), axis=0, dtype=np.float64)\n\t                    v._ytrue = np.concatenate(\n\t                        (v._ytrue, vv._ytrue), axis=0, dtype=np.float64)\n\t                    [getattr(v, x).update(getattr(vv, x)) for x in (\n\t                        \"times\", \"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t                it = next(vv._threshold for vv in v.categories.values())\n\t                v._threshold = [(it[i][0], sum(vv._threshold[i][1]\n\t                                 for vv in v.categories.values())) for i in range(len(it))]\n", "                v.__post_init__()\n\t                self._ypred = np.concatenate(\n\t                    (self._ypred, v._ypred), axis=0, dtype=np.float64)\n\t                self._ytrue = np.concatenate(\n\t                    (self._ytrue, v._ytrue), axis=0, dtype=np.float64)\n\t                [getattr(self, x).update(getattr(v, x)) for x in (\n\t                    \"times\", \"tp_stats\", \"fp_stats\", \"tn_stats\", \"fn_stats\")]\n\t            it = next(v._threshold for v in self.datasets.values())\n\t            self._threshold = [(it[i][0], sum(v._threshold[i][1]\n\t                                for v in self.datasets.values())) for i in range(len(it))]\n", "            self.__post_init__()\n"]}
{"filename": "enid/lib/__init__.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tFile containing the definitions of the labels for the supported datasets\n\tand the function to load their respective malicious flows' IDs.\n\t\"\"\"\n\timport itertools\n\timport multiprocessing\n\timport os\n", "from lxml import etree\n\tfrom .identifiers import TwoIPsKey, TwoIPsProtoPortsKey\n\tdef __internal_2012(xml_file):\n\t    attackers = set()\n\t    for child in etree.parse(xml_file).getroot():\n\t        if child.find('Tag').text == \"Normal\":\n\t            continue\n\t        protocol_string = child.find('protocolName').text.upper()\n\t        if \"TCP\" in protocol_string:\n\t            proto = \"TCP\"\n", "        elif \"UDP\" in protocol_string:\n\t            proto = \"UDP\"\n\t        elif \"ICMP\" in protocol_string:\n\t            proto = \"ICMP\"\n\t        else:\n\t            continue\n\t        attackers.add(TwoIPsProtoPortsKey.create(\n\t            \"IDS2012\", \"\", \"\",\n\t            ip=child.find('source').text,\n\t            ip1=child.find('destination').text,\n", "            proto=proto,\n\t            port=int(child.find('sourcePort').text),\n\t            port1=int(child.find('destinationPort').text)))\n\t    return attackers\n\tdef parse_xml_label_file_IDS2012(dir_path):\n\t    ret = set()\n\t    with multiprocessing.Pool(maxtasksperchild=1) as pool:\n\t        for k in pool.map(__internal_2012, [os.path.join(dir_path, x) for x in os.listdir(dir_path) if \".xml\" in x]):\n\t            ret.update(k)\n\t    return list(ret)\n", "ATTACK_LABELS = {\n\t    'IDS2012': parse_xml_label_file_IDS2012,\n\t    'IDS2017': lambda _: tuple(\n\t        TwoIPsKey.create(\"IDS2017\", \"\", \"\", ip=x, ip1=y) for x, y in itertools.product(\n\t            ['172.16.0.1'], ['192.168.10.50'])),\n\t    'IDS2018': lambda _: tuple(\n\t        TwoIPsKey.create(\"IDS2018\", \"\", \"\", ip=x, ip1=y) for x, y in itertools.product(\n\t            ['18.218.115.60', '18.219.9.1', '18.219.32.43', '18.218.55.126', '52.14.136.135',\n\t                '18.219.5.43', '18.216.200.189', '18.218.229.235', '18.218.11.51', '18.216.24.42'],\n\t            ['18.218.83.150', '172.31.69.28'])),\n", "    'IDS2019': lambda _: tuple(\n\t        TwoIPsKey.create(\"IDS2019\", \"\", \"\", ip=x, ip1=y) for x, y in itertools.product(\n\t            ['172.16.0.5'], ['192.168.50.1', '192.168.50.4'])),\n\t    'BENIGN': lambda _: tuple(),\n\t}\n"]}
{"filename": "enid/lib/identifiers.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tFile containing the definitions of all the field and keys usable withing this framework.\n\t\"\"\"\n\timport ipaddress\n\timport socket\n\timport sys\n\tfrom abc import ABC, abstractclassmethod, abstractmethod\n", "from dataclasses import dataclass, fields, field\n\tfrom typing import ClassVar, Tuple, Type\n\tfrom pypacker.layer3.ip import IP\n\tfrom pypacker.layer4.tcp import TCP\n\tfrom pypacker.layer4.udp import UDP\n\tfrom pypacker.layer12.ethernet import Ethernet\n\tfrom .metrics import ComputationalRequirements\n\tclass SourceIP(int):\n\t    \"\"\"Type representing the Source IP address\"\"\"\n\t    def __new__(cls, x=0, *args, **kwargs):\n", "        if isinstance(x, (str, bytes)):\n\t            x = int(ipaddress.IPv4Address(x))\n\t        elif isinstance(x, Ethernet):\n\t            x = cls.extract(x)\n\t        return int.__new__(cls, x, *args, **kwargs)\n\t    @staticmethod\n\t    def extract(eth: Ethernet):\n\t        return SourceIP(eth[IP].src)\n\t    def __repr__(self):\n\t        return str(ipaddress.IPv4Address(self))\n", "class DestinationIP(SourceIP):\n\t    \"\"\"Type representing the Destination IP address\"\"\"\n\t    @staticmethod\n\t    def extract(eth: Ethernet):\n\t        return DestinationIP(eth[IP].dst)\n\tclass IPProtocol(int):\n\t    \"\"\"Type representing the L4 protocol\"\"\"\n\t    PROTOCOLS: ClassVar[dict] = {int(num): name[len(\"IPPROTO_\"):] for name, num in vars(\n\t        socket).items() if name.startswith(\"IPPROTO_\")}\n\t    def __new__(cls, x=0, *args, **kwargs):\n", "        if isinstance(x, str):\n\t            x = next(k for k, v in IPProtocol.PROTOCOLS.items()\n\t                     if v == x.upper())\n\t        elif isinstance(x, Ethernet):\n\t            x = cls.extract(x)\n\t        return int.__new__(cls, x, *args, **kwargs)\n\t    @staticmethod\n\t    def extract(eth: Ethernet):\n\t        return IPProtocol(eth[IP].p)\n\t    def __repr__(self):\n", "        return IPProtocol.PROTOCOLS[self]\n\tclass SourcePort(int):\n\t    \"\"\"Type representing the Source L4 port\"\"\"\n\t    def __new__(cls, x=0, *args, **kwargs):\n\t        if isinstance(x, str):\n\t            x = int(x)\n\t        elif isinstance(x, Ethernet):\n\t            x = cls.extract(x)\n\t        return int.__new__(cls, x, *args, **kwargs)\n\t    @staticmethod\n", "    def extract(eth: Ethernet):\n\t        if eth[TCP]:\n\t            return SourcePort(eth[TCP].sport)\n\t        elif eth[UDP]:\n\t            return SourcePort(eth[UDP].sport)\n\t        return SourcePort(0)\n\tclass DestinationPort(SourcePort):\n\t    \"\"\"Type representing the Destination L4 port\"\"\"\n\t    @staticmethod\n\t    def extract(eth: Ethernet):\n", "        if eth[TCP]:\n\t            return DestinationPort(eth[TCP].dport)\n\t        elif eth[UDP]:\n\t            return DestinationPort(eth[UDP].dport)\n\t        return DestinationPort(0)\n\tclass Dataset(str):\n\t    \"\"\"Type representing the Dataset. Note that this\n\t    field is important, especially when mixing datasets\n\t    in order to avoid conflicts of session identifiers within 2\n\t    different datasets, which may be of different natures.\"\"\"\n", "    def __new__(cls, x=\"\", *args, **kwargs):\n\t        if isinstance(x, Ethernet):\n\t            x = cls.extract(x)\n\t        return str.__new__(cls, x, *args, **kwargs)\n\t    @staticmethod\n\t    def extract(eth: Ethernet):\n\t        return Dataset(eth.dataset)\n\tclass Category(str):\n\t    \"\"\"Type representing the Category.\"\"\"\n\t    def __new__(cls, x=\"\", *args, **kwargs):\n", "        if isinstance(x, Ethernet):\n\t            x = cls.extract(x)\n\t        return str.__new__(cls, x, *args, **kwargs)\n\t    @staticmethod\n\t    def extract(eth: Ethernet):\n\t        return Category(eth.category)\n\tclass Pcap(str):\n\t    \"\"\"Type representing the Pcap.\"\"\"\n\t    def __new__(cls, x=\"\", *args, **kwargs):\n\t        if isinstance(x, Ethernet):\n", "            x = cls.extract(x)\n\t        return str.__new__(cls, x, *args, **kwargs)\n\t    @staticmethod\n\t    def extract(eth: Ethernet):\n\t        return Pcap(eth.pcap)\n\t@dataclass(frozen=True)\n\tclass BaseKey(ABC):\n\t    \"\"\"Base key class, containing at least the dataset, category and pcap fields.\n\t    Note that, unless the dataset, the pcap and category are not used for hashing and\n\t    comparison, as it is supposed that within the same dataset a sessions is always the\n", "    same and does not change in nature (e.g., from benign to malicious).\"\"\"\n\t    dataset: Dataset\n\t    category: Category = field(hash=False, compare=False)\n\t    pcap: Pcap = field(hash=False, compare=False)\n\t    @classmethod\n\t    def extract(cls, eth: Ethernet):\n\t        return cls.create(**{k.name: k.type.extract(eth) for k in fields(cls)})\n\t    @property\n\t    @abstractmethod\n\t    def computational_requirements(cls) -> Tuple[ComputationalRequirements]:\n", "        \"\"\"Method to return the memory requirements for extracting the current ones\"\"\"\n\t        raise NotImplementedError()\n\t    @property\n\t    @abstractmethod\n\t    def memory_requirements(self) -> int:\n\t        \"\"\"Method to return the memory requirements for extracting the current ones\"\"\"\n\t        pass\n\t    @abstractclassmethod\n\t    def create(cls, dataset: Dataset, category: Category, pcap: Pcap, **kwargs):\n\t        raise NotImplementedError()\n", "    def cast(self, other_cls):\n\t        if self.__class__ == other_cls:\n\t            return self\n\t        return other_cls.create(**{k.name: getattr(self, k.name, None) for k in fields(other_cls)})\n\t    def to_json(self):\n\t        return {x.name: str(getattr(self, x.name)) for x in fields(self)}\n\t@dataclass(frozen=True)\n\tclass NoKey(BaseKey):\n\t    \"\"\"Identifier that groups all the traffic into a unique stats\"\"\"\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = tuple(\n", "    )\n\t    memory_requirements: ClassVar[int] = 0\n\t    @classmethod\n\t    def create(cls, dataset, category, pcap, **kwargs):\n\t        return cls(Dataset(dataset), Category(category), Pcap(pcap))\n\t@dataclass(frozen=True)\n\tclass SingleIPKey(BaseKey):\n\t    \"\"\"Identifier that group the traffic by the source IP address\"\"\"\n\t    ip: SourceIP\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (ComputationalRequirements.REQUIRED_L3.value,\n", "                                                                              ComputationalRequirements.BASE_MATH_OP.value)\n\t    memory_requirements: ClassVar[int] = 4\n\t    @classmethod\n\t    def create(cls, dataset, category, pcap, ip, **kwargs):\n\t        return cls(Dataset(dataset), Category(category), Pcap(pcap), SourceIP(ip))\n\t@dataclass(frozen=True)\n\tclass TwoIPsKey(SingleIPKey):\n\t    \"\"\"Identifier that group the traffic by the source and destination IP addresses\"\"\"\n\t    ip1: DestinationIP\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = SingleIPKey.computational_requirements + \\\n", "        (ComputationalRequirements.BASE_MATH_OP.value,\n\t         ComputationalRequirements.HASH_COMPUTATION.value)\n\t    memory_requirements: ClassVar[int] = SingleIPKey.memory_requirements + 4\n\t    @classmethod\n\t    def create(cls, dataset, category, pcap, ip, ip1, **kwargs):\n\t        ip, ip1 = SourceIP(ip), DestinationIP(ip1)\n\t        if ip1 > ip:\n\t            ip, ip1 = ip1, ip\n\t        return cls(Dataset(dataset), Category(category), Pcap(pcap), ip, ip1)\n\t@dataclass(frozen=True)\n", "class TwoIPsProtoKey(TwoIPsKey):\n\t    \"\"\"Identifier that group the traffic by the source and destination IP addresses plus the L4 protocol\"\"\"\n\t    proto: IPProtocol\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = TwoIPsKey.computational_requirements + \\\n\t        (ComputationalRequirements.BASE_MATH_OP.value, )\n\t    memory_requirements: ClassVar[int] = TwoIPsKey.memory_requirements + 1\n\t    @classmethod\n\t    def create(cls, dataset, category, pcap, ip, ip1, proto, **kwargs):\n\t        ip, ip1 = SourceIP(ip), DestinationIP(ip1)\n\t        if ip1 > ip:\n", "            ip, ip1 = ip1, ip\n\t        return cls(Dataset(dataset), Category(category), Pcap(pcap), ip, ip1, IPProtocol(proto))\n\t@dataclass(frozen=True)\n\tclass TwoIPsProtoPortsKey(TwoIPsProtoKey):\n\t    \"\"\"Identifier that group the traffic by the source and destination IP addresses,\n\t    source and destination L4 ports and the L4 protocol\"\"\"\n\t    port: SourcePort\n\t    port1: DestinationPort\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = TwoIPsProtoKey.computational_requirements +\\\n\t        (ComputationalRequirements.BASE_MATH_OP.value,)\n", "    memory_requirements: ClassVar[int] = TwoIPsProtoKey.memory_requirements + 4\n\t    @classmethod\n\t    def create(cls, dataset, category, pcap, ip, ip1, port, port1, proto, **kwargs):\n\t        ip, ip1, port, port1 = SourceIP(ip), DestinationIP(\n\t            ip1), SourcePort(port), DestinationPort(port1)\n\t        if ip1 > ip:\n\t            ip, ip1, port, port1 = ip1, ip, port1, port\n\t        return cls(Dataset(dataset), Category(category), Pcap(pcap), ip, ip1, IPProtocol(proto), port, port1)\n\tdef str_to_key(name) -> Type[BaseKey]:\n\t    \"\"\"Function to return the Key class corresponding to the name provided\"\"\"\n", "    ret = getattr(sys.modules[__name__], name)\n\t    if not issubclass(ret, BaseKey):\n\t        raise ValueError(f\"{name} is not a BaseKey instance\")\n\t    return ret\n"]}
{"filename": "enid/lib/engines/lucid_rnn.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"File defining the LucidRnn Detection Engine\"\"\"\n\tfrom .lucid_mlp import LucidMlp, tf\n\tclass LucidRnn(LucidMlp):\n\t    \"\"\"Detection Engine composed of:\n\t    - Lucid traffic processing mechanism\n\t    - RNN (LSTM) as model architecture\n\t    - Same training parameters and combination defined in LucidCnn\n", "    \"\"\"\n\t    @classmethod\n\t    def _get_arch(\n\t            cls, packets_per_session: int = None, features: int = None,\n\t            max_packets_per_session: int = None, max_features: int = None,\n\t            kernels: int = 64, dropout: float = 0.2,\n\t            learning_rate: float = 0.001, **kwargs):\n\t        if max_packets_per_session:\n\t            packets_per_session = max_packets_per_session\n\t        if max_features:\n", "            features = max_features\n\t        model = tf.keras.models.Sequential([\n\t            tf.keras.layers.LSTM(kernels, input_shape=(\n\t                packets_per_session, features), name=\"TARGET\"),\n\t            tf.keras.layers.Dropout(dropout, name=\"Dropout\"),\n\t            tf.keras.layers.Activation(\n\t                tf.keras.activations.relu, name=\"ReLu\"),\n\t            tf.keras.layers.Dense(1, name='FinalDense'),\n\t            tf.keras.layers.Activation(\n\t                tf.keras.activations.sigmoid, name=\"Sigmoid\")\n", "        ], name=cls.model_name(packets_per_session=packets_per_session, features=features))\n\t        if learning_rate:\n\t            model.compile(loss=tf.keras.metrics.binary_crossentropy,\n\t                          optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n\t                          metrics=[\"accuracy\"])\n\t        return model\n"]}
{"filename": "enid/lib/engines/__init__.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n"]}
{"filename": "enid/lib/engines/lucid_mlp.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"File defining the LucidMlp Detection Engine\"\"\"\n\tfrom dataclasses import dataclass, field\n\timport numpy as np\n\tfrom .lucid_cnn import LucidCnn, LucidDeParams, tf\n\t@dataclass\n\tclass MlpDeParams(LucidDeParams):\n\t    \"\"\"Class defining parameters for the Detection Model\"\"\"\n", "    regularization: bool = field(default=None, init=False, repr=False)\n\tclass LucidMlp(LucidCnn):\n\t    \"\"\"Detection Engine composed of:\n\t    - Lucid traffic processing mechanism\n\t    - Mlp (Fully-Connected) as model architecture\n\t    - Same training parameters and combination defined in LucidCnn\n\t    \"\"\"\n\t    de_params = MlpDeParams\n\t    @staticmethod\n\t    def _fed_adapt_layer(src_w, dst_w, global_f, local_f, pad=False):\n", "        if src_w.shape == dst_w.shape:\n\t            return src_w\n\t        indexes = [i for i, f in enumerate(global_f) if f in local_f]\n\t        if pad:\n\t            ret = np.zeros(\n\t                dst_w.shape if dst_w.shape[0] > src_w.shape[0] else src_w)\n\t            ret[indexes, ...] = src_w[indexes, ...]\n\t            return ret\n\t        return src_w[indexes, ...]\n\t    @classmethod\n", "    def _get_arch(\n\t            cls, packets_per_session: int = None, features: int = None,\n\t            max_packets_per_session: int = None, max_features: int = None,\n\t            kernels: int = 64, dropout: float = 0.2,\n\t            learning_rate: float = 0.001, **kwargs):\n\t        if max_packets_per_session:\n\t            packets_per_session = max_packets_per_session\n\t        if max_features:\n\t            features = max_features\n\t        model = tf.keras.models.Sequential([\n", "            tf.keras.layers.InputLayer(\n\t                input_shape=(packets_per_session, features), name=\"Input\"),\n\t            tf.keras.layers.Flatten(name=\"Flatten\"),\n\t            tf.keras.layers.Dense(kernels, name='TARGET'),\n\t            tf.keras.layers.Dropout(dropout, name=\"Dropout\"),\n\t            tf.keras.layers.Activation(\n\t                tf.keras.activations.relu, name=\"ReLu\"),\n\t            tf.keras.layers.Dense(1, name='FinalDense'),\n\t            tf.keras.layers.Activation(\n\t                tf.keras.activations.sigmoid, name=\"Sigmoid\")\n", "        ], name=cls.model_name(packets_per_session=packets_per_session, features=features))\n\t        if learning_rate:\n\t            model.compile(loss=tf.keras.metrics.binary_crossentropy,\n\t                          optimizer=tf.keras.optimizers.Adam(\n\t                              learning_rate=learning_rate),\n\t                          metrics=[\"accuracy\"])\n\t        return model\n"]}
{"filename": "enid/lib/engines/lucid_cnn/__init__.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"File defining the LucidCnn Detection Engine, its TrafficAnalyser and all\n\tthe parameters used.\"\"\"\n\timport copy\n\timport math\n\timport os\n\timport time\n\tfrom dataclasses import dataclass, field, fields, replace\n", "from functools import lru_cache\n\tfrom typing import Dict, List, Tuple, Type, Union\n\timport h5py\n\timport numpy as np\n\timport tensorflow as tf\n\tfrom pypacker.layer12.ethernet import Ethernet\n\tfrom sklearn.model_selection import RandomizedSearchCV\n\tfrom ...definitions import (AnalysisState, BaseProcessingData, DeParams,\n\t                            DetectionEngine, TrafficAnalyser)\n\tfrom ...identifiers import BaseKey\n", "from ...metrics import TrainMetric\n\tfrom ...utility import (SplitType, get_all_dict_comb, get_best_comb,\n\t                        get_best_dispatch, get_logger, load_json_data,\n\t                        set_seed, sort_keep_comb)\n\tfrom .features import LucidFeaturesHolder, Time\n\t_logger = get_logger(__name__)\n\t@dataclass\n\tclass LucidDeParams(DeParams):\n\t    \"\"\"Class defining parameters for the Detection Model\"\"\"\n\t    rerank_at_feature: int = None\n", "    rerank_at_packet: int = None\n\t    train_with_less: bool = False\n\t    prune_zero_first: bool = False\n\t    learn_only_from_benign: bool = False\n\t    rank_metric: str = \"f1_score\"\n\t    max_loss: int = 20\n\t    epochs: int = 500\n\t    malicious_threshold: int = 0.5\n\t    learning_rate: List[float] = (0.1, 0.01, 0.001)\n\t    batch_size: List[int] = (512, 1024, 2048)\n", "    kernels: List[int] = (8, 16, 32, 64)\n\t    dropout: List[float] = (0.2, 0.5, 0.8)\n\t    regularization: List[str] = (\"l1\", \"l2\")  # used only for CNN\n\t    @property\n\t    def is_to_train(self):\n\t        \"\"\"Return true if the current model is to train according to the parameters\"\"\"\n\t        return self.train_with_less or (not self.max_packets_per_session and not self.max_features) or\\\n\t            (self.max_packets_per_session and self.max_features and self.packets_per_session == self.max_packets_per_session\n\t             and self.features == self.max_features) or\\\n\t            (self.max_packets_per_session and not self.max_features and\n", "                self.packets_per_session == self.max_packets_per_session) or\\\n\t            (self.max_features and not self.max_packets_per_session and\n\t                self.features == self.max_features)\n\t    @property\n\t    def is_to_rerank(self):\n\t        \"\"\"Return true if the features need to be reranked\"\"\"\n\t        return (not self.rerank_at_packet and not self.rerank_at_feature) or\\\n\t            (self.rerank_at_packet and self.rerank_at_feature and self.packets_per_session == self.rerank_at_packet and\n\t                self.features == self.rerank_at_feature) or\\\n\t            (not self.rerank_at_packet and self.rerank_at_feature and self.features == self.rerank_at_feature) or\\\n", "            (not self.rerank_at_feature and self.rerank_at_packet and self.packets_per_session ==\n\t             self.rerank_at_packet)\n\t    @property\n\t    def is_load_previous_rank(self):\n\t        \"\"\"Return true if needed to load the previous features\"\"\"\n\t        return self.rerank_at_feature == self.features and self.rerank_at_packet != self.packets_per_session\n\t@dataclass\n\tclass ProcessingData(BaseProcessingData):\n\t    indexes_benign: List = field(default_factory=list)\n\t    indexes_malicious: List = field(default_factory=list)\n", "@dataclass\n\tclass LucidAnalysisState(AnalysisState):\n\t    current_features: Type[LucidFeaturesHolder] = field(default=None)\n\t    params: LucidDeParams = field(default=None)\n\tclass LucidTrafficAnalyser(TrafficAnalyser):\n\t    \"\"\"Traffic Analyser class that implements the extraction mechanism and the\n\t    termination of a time window while processing data.\"\"\"\n\t    analysis_state_cls: Type[AnalysisState] = LucidAnalysisState\n\t    def _extract(self, sess_id: Type[BaseKey], eth: Ethernet):\n\t        self.current_session_map[sess_id].value.append(\n", "            tuple(y.create(eth) for y in self.analysis_state.current_features.value))\n\t    def _terminate_timewindow_preprocessing(self):\n\t        if not self.current_session_map:\n\t            return\n\t        asd = next((x for x in self.attackers.values()), None)\n\t        for i, k in enumerate(self.current_session_map):\n\t            target = \"benign\"\n\t            if asd and k.cast(asd[0]) in asd[1]:\n\t                target = \"malicious\"\n\t            setattr(self.processing_stats, f\"tot_{target}_packets\",\n", "                    getattr(self.processing_stats, f\"tot_{target}_packets\") + self.current_session_map[k].metered_packets +\n\t                    self.current_session_map[k].unmetered_packets)\n\t            if k not in self.seen_sessions_previous_prediction:\n\t                setattr(self.processing_stats, f\"unique_{target}\", getattr(\n\t                    self.processing_stats, f\"unique_{target}\") + 1)\n\t                self.seen_sessions_previous_prediction[k] = True\n\t            setattr(self.processing_stats, f\"tot_{target}\", getattr(\n\t                self.processing_stats, f\"tot_{target}\") + 1)\n\t            getattr(self.processing_stats, f\"indexes_{target}\").append(i)\n\t        preprocessed, _, _ = self.de.preprocess_samples(self)\n", "        with h5py.File(f\"{self.dump_path}.h5\", 'a') as hf:\n\t            for ttype in [\"benign\", \"malicious\"]:\n\t                if not len(getattr(self.processing_stats, f\"indexes_{ttype}\")):\n\t                    continue\n\t                vals = preprocessed[getattr(\n\t                    self.processing_stats, f\"indexes_{ttype}\")]\n\t                getattr(self.processing_stats, f\"indexes_{ttype}\").clear()\n\t                if ttype in hf:\n\t                    hf[ttype].resize(\n\t                        (hf[ttype].shape[0] + vals.shape[0]), axis=0)\n", "                    hf[ttype][-vals.shape[0]:] = vals\n\t                else:\n\t                    hf.create_dataset(ttype, data=vals,\n\t                                      maxshape=(None, *vals.shape[1:]))\n\tclass LucidCnn(DetectionEngine):\n\t    \"\"\"Detection Engine composed of:\n\t    - Lucid traffic processing mechanism\n\t    - CNN as detection model\n\t    - Custom ranking mechanism\n\t    \"\"\"\n", "    features_holder_cls = LucidFeaturesHolder\n\t    traffic_analyser_cls = LucidTrafficAnalyser\n\t    processing_data_cls = ProcessingData\n\t    de_params = LucidDeParams\n\t    def __init__(self, analysis_state: LucidAnalysisState, base_dir) -> None:\n\t        super().__init__(analysis_state, base_dir)\n\t        self.analysis_state: LucidAnalysisState\n\t        self.maxs: np.ndarray = None\n\t        self.indexes = None\n\t        self.adjust_timestamp: int = None\n", "        self._init_scale_method()\n\t    @classmethod\n\t    def predict(cls, model, data, batch_size: int = None, **kwargs) -> np.ndarray:\n\t        return np.squeeze(model.predict(data, batch_size=batch_size,\n\t                                        verbose=0).astype(np.float64), axis=1)\n\t    @classmethod\n\t    def model_name(cls, packets_per_session: int, features: int = None, **kwargs):\n\t        if not features:\n\t            features = len(cls.features_holder_cls.ALLOWED)\n\t        return \"{}p-{}f\".format(packets_per_session, features)\n", "    @staticmethod\n\t    @lru_cache\n\t    def _internal_load(basename):\n\t        \"\"\"Internal method to load the dataset asynchronously\"\"\"\n\t        ret = []\n\t        for name in (\"train\", \"validation\", \"test\"):\n\t            with h5py.File(os.path.join(basename, f\"{name}.h5\"), 'r') as dataset:\n\t                x = dataset[\"set_x\"][:].astype(np.float64)\n\t                y = dataset[\"set_y\"][:].astype(np.float64)\n\t            ret.append(list(sort_keep_comb(x, y)))\n", "        return ret\n\t    @staticmethod\n\t    def _fed_adapt_layer(src_w, dst_w, global_f, local_f, pad=False):\n\t        if src_w.shape == dst_w.shape:\n\t            return src_w\n\t        indexes = [i for i, f in enumerate(global_f) if f in local_f]\n\t        if pad:\n\t            ret = np.zeros(\n\t                (max(dst_w.shape[0], src_w.shape[0]),\n\t                 max(dst_w.shape[1], src_w.shape[1]),\n", "                 *dst_w.shape[2:]))\n\t            ret[:src_w.shape[0], indexes, ...] = src_w[:, :, ...]\n\t            return ret\n\t        return src_w[:min(src_w.shape[0], dst_w.shape[0]), indexes, ...]\n\t    @staticmethod\n\t    def _load_dataset(basename, features_holder: LucidFeaturesHolder, packets_per_session=None,\n\t                      max_packets_per_session=None, max_features=None,\n\t                      split_type=SplitType.NONE, split_chunk: Tuple[int, int] = tuple(), **kwargs):\n\t        \"\"\"Load dataset and format it according the current parameters features/packets\"\"\"\n\t        not_current_indexes = [i for i, k in enumerate(features_holder.ALLOWED)\n", "                               if k not in features_holder.value]\n\t        current_indexes = [i for i, k in enumerate(features_holder.ALLOWED)\n\t                           if k in features_holder.value]\n\t        ret = copy.deepcopy(LucidCnn._internal_load(basename))\n\t        # if max_packets or max_features then keep their position but with the\n\t        # value in that coord set to 0\n\t        for i in range(len(ret)):\n\t            if split_type == SplitType.EQUALLY:\n\t                n_samples_per_type = math.floor(\n\t                    len(ret[i][0])/2/split_chunk[1])\n", "                indexes = np.where(ret[i][1] == 1.0)[\n\t                    0][split_chunk[0]*n_samples_per_type:(split_chunk[0]+1)*n_samples_per_type]\n\t                indexes = np.concatenate((indexes, np.where(ret[i][1] == 0.0)[\n\t                                         0][split_chunk[0]*n_samples_per_type:(split_chunk[0]+1)*n_samples_per_type]))\n\t                ret[i][0] = ret[i][0][indexes, ...]\n\t                ret[i][1] = ret[i][1][indexes, ...]\n\t            elif split_type == SplitType.NONE:\n\t                pass\n\t            else:\n\t                raise NotImplementedError()\n", "            if not packets_per_session:  # Ho solo features aggregate, non pacchetti\n\t                if max_features:\n\t                    ret[i][0][:, not_current_indexes] = 0.0\n\t                else:\n\t                    ret[i][0] = ret[i][0][:, current_indexes]\n\t            else:  # Ho anche pacchetti come dimensione\n\t                if max_packets_per_session:\n\t                    ret[i][0] = ret[i][0][:, :max_packets_per_session, :]\n\t                    ret[i][0][:, packets_per_session:, :] = 0.0\n\t                else:\n", "                    ret[i][0] = ret[i][0][:, :packets_per_session, :]\n\t                if max_features:\n\t                    ret[i][0][:, :, not_current_indexes] = 0.0\n\t                else:\n\t                    ret[i][0] = ret[i][0][:, :, current_indexes]\n\t        return ret[0], ret[1], ret[2]\n\t    @classmethod\n\t    def load_model(cls, params: Union[Dict, LucidDeParams], base_dir: str):\n\t        if isinstance(params, LucidDeParams):\n\t            params = params.__dict\n", "        current_name = cls.model_name(**params)\n\t        current_features = cls.features_holder_cls(**load_json_data(\n\t            os.path.join(base_dir, current_name, \"relevance.json\")))\n\t        params = LucidDeParams(**load_json_data(os.path.join(\n\t            base_dir, current_name, \"params.json\")))\n\t        max_par = {\n\t            \"packets_per_session\": params.max_packets_per_session or params.packets_per_session,\n\t            \"features\": params.max_features or params.features}\n\t        model = cls._get_arch(\n\t            **max_par, **{k: v for k, v in params.__dict__.items() if k not in max_par})\n", "        model.load_weights(os.path.join(\n\t            base_dir, cls.model_name(**max_par), \"weights.h5\"))\n\t        return current_features, params, model\n\t    def preprocess_samples(self, ta: LucidTrafficAnalyser):\n\t        is_nested = isinstance(\n\t            next(x for x in ta.current_session_map.values()).value, list)\n\t        # convert data into input-compliant\n\t        conversion_time = time.clock_gettime_ns(time.CLOCK_PROCESS_CPUTIME_ID)\n\t        if is_nested:\n\t            data = np.zeros((\n", "                len(ta.current_session_map),\n\t                self.analysis_state.params.max_packets_per_session or self.analysis_state.params.packets_per_session,\n\t                self.analysis_state.params.max_features or self.analysis_state.params.features),\n\t                dtype=np.float64)\n\t            for i, v in enumerate(ta.current_session_map.values()):\n\t                for ii, vv in enumerate(v.value):\n\t                    for iii, vvv in zip(self.indexes, vv):\n\t                        data[i, ii, iii] = vvv.value\n\t        else:\n\t            data = np.zeros((len(ta.current_session_map),\n", "                             self.analysis_state.params.max_features or self.analysis_state.params.features),\n\t                            dtype=np.float64)\n\t            for i, v in enumerate(ta.current_session_map.values()):\n\t                for ii, vv in zip(self.indexes, v.value):\n\t                    data[i, ii] = vv.value\n\t        conversion_time = time.clock_gettime_ns(\n\t            time.CLOCK_PROCESS_CPUTIME_ID) - conversion_time\n\t        preprocessing_time = time.clock_gettime_ns(\n\t            time.CLOCK_PROCESS_CPUTIME_ID)\n\t        # adjust timestamp\n", "        if self.adjust_timestamp:\n\t            data[:, :, self.adjust_timestamp] -= data[:,\n\t                                                      [0], self.adjust_timestamp]\n\t        # set min to zero\n\t        data[data < 0] = 0.0\n\t        # scale between 0 and max value\n\t        data[..., :] /= self.maxs\n\t        # remove nan\n\t        np.nan_to_num(data, copy=False)\n\t        preprocessing_time = time.clock_gettime_ns(\n", "            time.CLOCK_PROCESS_CPUTIME_ID) - preprocessing_time\n\t        return data, conversion_time, preprocessing_time\n\t    @classmethod\n\t    def _compute_features_weights(\n\t            cls, features_holder: LucidFeaturesHolder, x: np.ndarray, y: np.ndarray,\n\t            model, malicious_threshold, batch_size, metric, only_active=True):\n\t        \"\"\"Method to rank the features. Given this metric, the method\n\t        computes the rank of each feature by:\n\t        1. Computing the baseline value of the metric with the entire input set as it is\n\t        2. For each feature, the algorithm sets that feature to zero and computes the new metric\n", "        3. The rank of each feature is given by the performance loss/gain given by the difference\n\t        between the new value and the baseline.\"\"\"\n\t        baseline = TrainMetric(\n\t            _threshold=malicious_threshold, _ytrue=y,\n\t            _ypred=cls.predict(model, x, batch_size=batch_size))\n\t        minimize = metric in (\"log_loss\", \"fp\", \"fpr\", \"fn\", \"fnr\")\n\t        if only_active:\n\t            indexes = list(range(features_holder.n_current))\n\t        else:\n\t            indexes = [i for i, k in enumerate(\n", "                features_holder.ALLOWED) if k in features_holder.value]\n\t        for i, k in zip(indexes, features_holder.value):\n\t            x_tmp = np.copy(x)\n\t            x_tmp[..., i] = 0.0\n\t            t = TrainMetric(\n\t                _threshold=malicious_threshold, _ytrue=y,\n\t                _ypred=np.squeeze(model.predict(\n\t                    x_tmp, batch_size=batch_size, verbose=0), axis=1).astype(np.float64))\n\t            v_base = getattr(baseline, metric)\n\t            v_current = getattr(t, metric)\n", "            if v_base == 0 or v_current == 0:\n\t                # fallback accuracy metric as not possible to compute\n\t                _logger.info(f\"Metric for feature {k} switched to fallback accuracy,\"\n\t                             f\" as baseline={v_base} and current={v_current}\")\n\t                features_holder.value[k] = baseline.accuracy - t.accuracy\n\t            elif minimize:\n\t                features_holder.value[k] = v_current - v_base\n\t            else:\n\t                features_holder.value[k] = v_base - v_current\n\t    @classmethod\n", "    def parameters(cls, model=None, features=None, packets_per_session=None,\n\t                   max_features=None, max_packets_per_session=None, **params):\n\t        \"\"\"Method to return the number of trainable parameters of the model.\"\"\"\n\t        if model is None:\n\t            model = cls._get_arch(packets_per_session=max_packets_per_session or packets_per_session,\n\t                                  features=max_features or features, **params)\n\t        return int(np.sum([tf.keras.backend.count_params(p) for p in model.trainable_weights]))\n\t    @classmethod\n\t    def _get_arch(\n\t            cls, packets_per_session: int = None, features: int = None,\n", "            max_packets_per_session: int = None, max_features: int = None,\n\t            kernels: int = 64, dropout: float = 0.2,\n\t            regularization: str = \"l2\", learning_rate: float = 0.001,  **kwargs):\n\t        \"\"\"Method that defines the architecture of the CNN model\"\"\"\n\t        if max_packets_per_session:\n\t            packets_per_session = max_packets_per_session\n\t        if max_features:\n\t            features = max_features\n\t        model = tf.keras.models.Sequential([\n\t            tf.keras.layers.Reshape((packets_per_session, features, 1),\n", "                                    input_shape=(packets_per_session, features)),\n\t            # kernel size = (minimo tra n° packets e 3, n° features) - input shape = (n°pacchetti, n°features, 1)\n\t            tf.keras.layers.Conv2D(kernels, (min(packets_per_session, 3), features),\n\t                                   kernel_regularizer=regularization, name='TARGET'),\n\t            tf.keras.layers.Dropout(dropout, name=\"Dropout\"),\n\t            tf.keras.layers.Activation(tf.keras.activations.relu, name=\"ReLu\"),\n\t            # pool size = (massimo tra 1 e n°pacchetti-2, 1)\n\t            tf.keras.layers.GlobalMaxPooling2D(name=\"MaxPooling\"),\n\t            tf.keras.layers.Flatten(name=\"Flatten\"),\n\t            tf.keras.layers.Dense(1, name='FinalDense'),\n", "            tf.keras.layers.Activation(\n\t                tf.keras.activations.sigmoid, name=\"Sigmoid\")\n\t        ], name=cls.model_name(packets_per_session=packets_per_session, features=features))\n\t        if learning_rate:\n\t            model.compile(loss=tf.keras.metrics.binary_crossentropy,\n\t                          optimizer=tf.keras.optimizers.Adam(\n\t                              learning_rate=learning_rate),\n\t                          metrics=[\"accuracy\"])\n\t        return model\n\t    def _init_scale_method(self):\n", "        \"\"\"Method to compute the max value of each feature for the scaling, and set the max value of the\n\t        Time feature to the time window\"\"\"\n\t        Time.limit = self.analysis_state.time_window if self.analysis_state.time_window > 0 else (\n\t            1 << 64)\n\t        # check if need to keep features indexes also for those inactive\n\t        if self.analysis_state.params.max_features is not None:\n\t            self.indexes = [i for i, f in enumerate(\n\t                self.features_holder_cls.ALLOWED) if f in self.analysis_state.current_features.value]\n\t            self.maxs = np.array(\n\t                [x.limit for x in self.analysis_state.current_features.ALLOWED], dtype=np.float64)\n", "            self.adjust_timestamp = next((i for i, k in enumerate(\n\t                self.analysis_state.current_features.ALLOWED) if k == Time), None)\n\t        else:\n\t            self.indexes = list(\n\t                range(self.analysis_state.params.features))\n\t            self.maxs = np.array(\n\t                [x.limit for x in self.analysis_state.current_features.value], dtype=np.float64)\n\t            self.adjust_timestamp = next((i for i, k in enumerate(\n\t                self.analysis_state.current_features.value) if k == Time), None)\n\t    @staticmethod\n", "    def append_to_dataset(source, dest, ttype, label, indexes_tr, indexes_val, indexes_ts, **kwargs):\n\t        source += \".h5\"\n\t        with h5py.File(source, 'r') as dataset:\n\t            t = dataset[ttype][:]\n\t        for f, iii in zip((\"train\", \"validation\", \"test\"), (indexes_tr, indexes_val, indexes_ts)):\n\t            with h5py.File(os.path.join(dest, f\"{f}.h5\"), 'a') as new_dataset:\n\t                t_tmp = t[iii, ...]\n\t                plus_shape = len(iii)\n\t                if 'set_x' in new_dataset:\n\t                    new_dataset['set_x'].resize(\n", "                        (new_dataset['set_x'].shape[0] + plus_shape), axis=0)\n\t                    new_dataset['set_x'][-plus_shape:] = t_tmp\n\t                    new_dataset['set_y'].resize(\n\t                        (new_dataset['set_y'].shape[0] + plus_shape), axis=0)\n\t                    new_dataset['set_y'][-plus_shape:\n\t                                         ] = np.array([label]*plus_shape, dtype=np.float64)\n\t                else:\n\t                    new_dataset.create_dataset(\n\t                        'set_x', data=t_tmp, maxshape=(None, *t_tmp.shape[1:]))\n\t                    new_dataset.create_dataset('set_y', data=np.array(\n", "                        [label]*plus_shape, dtype=np.float64), maxshape=(None,))\n\t    @classmethod\n\t    def train(cls, dataset_path: str, models_dir, train_param: LucidDeParams,\n\t              split_type: SplitType, split_chunk: Tuple[int, int],\n\t              packets_per_session: int, features: int,\n\t              autoencoder=False):\n\t        previous = train_param.previous_one(packets_per_session, features)\n\t        # start from a previous features holder and pop less relevant feature\n\t        # untill the current number of features is matched\n\t        if previous is False:\n", "            features_holder = cls.features_holder_cls()\n\t        else:\n\t            pname = cls.model_name(packets_per_session=previous[0],\n\t                                   features=previous[1])\n\t            features_holder = cls.features_holder_cls(**load_json_data(\n\t                os.path.join(models_dir, os.pardir, pname, \"relevance.json\")))\n\t            to_pop = previous[2]\n\t            while to_pop:\n\t                features_holder.pop_less_relevant(\n\t                    **train_param.__dict__)\n", "                to_pop -= 1\n\t        hyper = {k.name: getattr(train_param, k.name) for k in fields(\n\t            train_param) if isinstance(k.default, (tuple, list))}\n\t        # set current pair of trained values\n\t        train_param = replace(\n\t            train_param, **{\"packets_per_session\": packets_per_session, \"features\": features})\n\t        set_seed()\n\t        _logger.info(\"Loading dataset\")\n\t        # load the dataset according to the current parameters\n\t        (xt, yt, _), (xv, yv, _), (xts, yts, pt) = cls._load_dataset(\n", "            dataset_path, features_holder, packets_per_session=packets_per_session,\n\t            max_packets_per_session=train_param.max_packets_per_session,\n\t            max_features=train_param.max_features,\n\t            split_type=split_type, split_chunk=split_chunk)\n\t        set_seed()\n\t        if train_param.learn_only_from_benign:\n\t            xt = xt[np.where(yt == 0.0)[0], ...]\n\t            yt = yt[np.where(yt == 0.0)[0], ...]\n\t            xvv = xv\n\t            yvv = yv\n", "            xv = xv[np.where(yv == 0.0)[0], ...]\n\t            yv = yv[np.where(yv == 0.0)[0], ...]\n\t        if autoencoder:\n\t            yt = np.reshape(\n\t                xt, (xt.shape[0], np.prod([x for x in xt.shape[1:]])))\n\t            yv = np.reshape(\n\t                xv, (xv.shape[0], np.prod([x for x in xv.shape[1:]])))\n\t        name = cls.model_name(\n\t            packets_per_session=packets_per_session, features=features)\n\t        combs = get_all_dict_comb(hyper)\n", "        n_len = len(combs)\n\t        if train_param.is_to_train:\n\t            if n_len > 1:\n\t                n_comb = get_best_comb(n_len)\n\t                n_dispatch = get_best_dispatch(\n\t                    xt.nbytes+yt.nbytes+xv.nbytes+yv.nbytes)\n\t                _logger.info(\"RandomizedSearchCV model {} on {} combinations over {} and dispatching {} jobs\".\n\t                             format(name, n_comb, n_len, n_dispatch))\n\t                rnd_search_cv = RandomizedSearchCV(\n\t                    tf.keras.wrappers.scikit_learn.KerasClassifier(\n", "                        build_fn=cls._get_arch, packets_per_session=train_param.max_packets_per_session or packets_per_session,\n\t                        features=train_param.max_features or features, verbose=0),\n\t                    hyper, cv=[(slice(None), slice(None))],\n\t                    n_iter=n_comb, refit=False, verbose=0, n_jobs=-1, pre_dispatch=n_dispatch)\n\t                rnd_search_cv.fit(x=xt, y=yt, epochs=train_param.epochs, validation_data=(xv, yv),\n\t                                  callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n\t                                                                              mode=\"min\",\n\t                                                                              patience=train_param.max_loss)])\n\t                hyper = rnd_search_cv.best_params_\n\t            else:\n", "                hyper = combs[0]\n\t            [setattr(train_param, k, v) for k, v in hyper.items()]\n\t            _logger.info(\n\t                f\"Fitting Model {name} using best parameters\")\n\t            best_model = cls._get_arch(packets_per_session=train_param.max_packets_per_session or packets_per_session,\n\t                                       features=train_param.max_features or features, **hyper)\n\t            hs = best_model.fit(x=xt, y=yt,\n\t                                validation_data=(xv, yv),\n\t                                batch_size=train_param.batch_size,\n\t                                epochs=train_param.epochs, verbose=1,\n", "                                callbacks=[\n\t                                    tf.keras.callbacks.EarlyStopping(\n\t                                        monitor='val_loss', mode=\"min\", patience=train_param.max_loss, min_delta=0.01),\n\t                                    tf.keras.callbacks.ModelCheckpoint(\n\t                                        filepath=os.path.join(\n\t                                            models_dir, \"weights.h5\"),\n\t                                        monitor='val_loss', mode='min',\n\t                                        save_best_only=True, save_weights_only=True)]).history\n\t        else:\n\t            hyper = {k: v for k, v in load_json_data(os.path.join(models_dir, os.pardir, cls.model_name(\n", "                packets_per_session=train_param.max_packets_per_session or packets_per_session,\n\t                features=train_param.max_features or features), \"params.json\")).items() if k in hyper}\n\t            [setattr(train_param, k, v) for k, v in hyper.items()]\n\t            best_model = cls._get_arch(packets_per_session=train_param.max_packets_per_session or packets_per_session,\n\t                                       features=train_param.max_features or features, **hyper)\n\t            hs = []\n\t            models_dir = os.path.join(models_dir, os.pardir, cls.model_name(\n\t                packets_per_session=train_param.max_packets_per_session, features=train_param.max_features or features))\n\t        best_model.load_weights(os.path.join(models_dir, \"weights.h5\"))\n\t        if train_param.malicious_threshold < 0:\n", "            train_param.malicious_threshold = TrainMetric.get_best_threshold_roc(\n\t                cls.predict(best_model, xv, **hyper), yv)\n\t        if train_param.is_to_rerank:\n\t            _logger.info(f\"Computing features importances for {name}\")\n\t            cls._compute_features_weights(features_holder, xvv, yvv, best_model,\n\t                                          train_param.malicious_threshold, train_param.batch_size,\n\t                                          metric=train_param.rank_metric,\n\t                                          only_active=train_param.max_features is None)\n\t        if train_param.is_load_previous_rank:\n\t            previous = cls.model_name(packets_per_session=train_param.rerank_at_packet,\n", "                                      features=train_param.rerank_at_feature)\n\t            features_holder = features_holder.__class__(**load_json_data(\n\t                os.path.join(models_dir, os.pardir, previous, \"relevance.json\")))\n\t        return hs, train_param, best_model, xts, yts, features_holder, pt\n"]}
{"filename": "enid/lib/engines/lucid_cnn/features.py", "chunked_list": ["# Copyright 2023 ENID\n\t#\n\t# Licensed under the Apache License, Version 2.0 (the \"License\");\n\t# you may not use this file except in compliance with the License.\n\t# You may obtain a copy of the License at\n\t#\n\t#    http://www.apache.org/licenses/LICENSE-2.0\n\t#\n\t# Unless required by applicable law or agreed to in writing, software\n\t# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\t# See the License for the specific language governing permissions and\n\t# limitations under the License.\n\t\"\"\"\n\tFile that defines the features required by Lucid, their extraction mechanisms\n\tand parameters. Also, the FeatureHolder class with the method for popping the\n\tless relevant feature is defined.\n\t\"\"\"\n\timport sys\n\tfrom collections import OrderedDict\n", "from dataclasses import dataclass, field\n\tfrom typing import ClassVar\n\tfrom typing import OrderedDict as OrderedDictType\n\tfrom typing import Tuple, Type\n\tfrom pypacker.layer3.icmp import ICMP\n\tfrom pypacker.layer3.ip import IP\n\tfrom pypacker.layer4.ssl import SSL\n\tfrom pypacker.layer4.tcp import TCP\n\tfrom pypacker.layer4.udp import UDP\n\tfrom pypacker.layer12.arp import ARP\n", "from pypacker.layer12.ethernet import Ethernet\n\tfrom pypacker.layer567.dns import DNS\n\tfrom pypacker.layer567.http import HTTP\n\tfrom pypacker.layer567.telnet import Telnet\n\tfrom pypacker.pypacker import Packet\n\tfrom ...definitions import (BaseFeature, BaseKey, ComputationalRequirements,\n\t                            FeaturesHolder)\n\t# Lucid supported protocols used in previous work\n\t_SUPPORTED_PROTOCOLS: Tuple[Type[Packet]] = (\n\t    HTTP, Telnet, SSL, UDP, TCP, IP, ICMP, DNS, Ethernet, ARP)\n", "@dataclass\n\tclass HighestLayer(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L4, ComputationalRequirements.ENHANCED_MATH_OP,\n\t        ComputationalRequirements.HASH_COMPUTATION, ComputationalRequirements.ENHANCED_MATH_OP)\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 10\n\t    def extract(self, eth: Ethernet):\n\t        self.value = 1 << 10 - \\\n\t            next(i for i, x in enumerate(_SUPPORTED_PROTOCOLS) if x in eth)\n", "@dataclass\n\tclass Protocols(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L4, ComputationalRequirements.ENHANCED_MATH_OP,\n\t        ComputationalRequirements.HASH_COMPUTATION) +\\\n\t        tuple(ComputationalRequirements.BASE_MATH_OP for _ in range(\n\t            len(_SUPPORTED_PROTOCOLS)))\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 10\n\t    def extract(self, eth: Ethernet):\n", "        protocols = tuple(x.__class__ for x in eth)\n\t        self.value = int(\n\t            ''.join(\"1\" if p in protocols else \"0\" for p in _SUPPORTED_PROTOCOLS), 2)\n\t@dataclass\n\tclass Time(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.TIMER,)\n\t    memory_requirements: ClassVar[int] = 8\n\t    limit: ClassVar[int] = None\n\t    def extract(self, eth: Ethernet):\n", "        self.value = eth.timestamp\n\t@dataclass\n\tclass IcmpType(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L3, ComputationalRequirements.BASE_MATH_OP)\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 16\n\t    def extract(self, eth: Ethernet):\n\t        if eth[ICMP]:\n\t            self.value = eth[ICMP].type\n", "@dataclass\n\tclass UDPLength(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L4, ComputationalRequirements.BASE_MATH_OP)\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 16\n\t    def extract(self, eth: Ethernet):\n\t        if eth[UDP]:\n\t            self.value = eth[UDP].ulen - 8\n\t@dataclass\n", "class TCPWindow(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L4, ComputationalRequirements.BASE_MATH_OP)\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 16\n\t    def extract(self, eth: Ethernet):\n\t        if eth[TCP]:\n\t            self.value = eth[TCP].win\n\t@dataclass\n\tclass TCPFlags(BaseFeature):\n", "    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L4, ComputationalRequirements.BASE_MATH_OP)\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 16\n\t    def extract(self, eth: Ethernet):\n\t        if eth[TCP]:\n\t            self.value = eth[TCP].flags\n\t@dataclass\n\tclass TCPLength(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n", "        ComputationalRequirements.REQUIRED_L4, ComputationalRequirements.BASE_MATH_OP)\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 16\n\t    def extract(self, eth: Ethernet):\n\t        if eth[TCP]:\n\t            self.value = eth[IP].len - (eth[IP].hl << 2)\n\t@dataclass\n\tclass IPFlags(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L3, ComputationalRequirements.BASE_MATH_OP)\n", "    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 16\n\t    def extract(self, eth: Ethernet):\n\t        self.value = eth[IP].flags\n\t@dataclass\n\tclass IPLength(BaseFeature):\n\t    computational_requirements: ClassVar[Tuple[ComputationalRequirements]] = (\n\t        ComputationalRequirements.REQUIRED_L3, ComputationalRequirements.BASE_MATH_OP)\n\t    memory_requirements: ClassVar[int] = 2\n\t    limit: ClassVar[int] = 1 << 16\n", "    def extract(self, eth: Ethernet):\n\t        self.value = eth[IP].len\n\t@dataclass\n\tclass LucidFeaturesHolder(FeaturesHolder):\n\t    ALLOWED: ClassVar[Tuple[Type[BaseFeature]]] = (HighestLayer, Protocols, Time,\n\t                                                   IcmpType, UDPLength,\n\t                                                   TCPWindow, TCPFlags, TCPLength,\n\t                                                   IPFlags, IPLength)\n\t    value: OrderedDictType[Type[BaseFeature], float] = field(\n\t        default_factory=OrderedDict)\n", "    def __post_init__(self):\n\t        if not self.value:\n\t            self.value = OrderedDict.fromkeys(self.ALLOWED, None)\n\t        elif isinstance(self.value, (list, tuple)):\n\t            if isinstance(self.value[0], dict):\n\t                self.value = OrderedDict(\n\t                    [(getattr(sys.modules[self.__module__], k[\"key\"]), k[\"value\"]) for k in self.value])\n\t            else:\n\t                self.value = OrderedDict.fromkeys(self.value, None)\n\t    def pop_less_relevant(self, prune_zero_first=False, key_depth_class: Type[BaseKey] = None, **kwargs):\n", "        \"\"\"Method for popping the less relevant feature from the current ones.\n\t        The method looks iteratively at the following attributes, unless only 1\n\t        feature is remained and removed:\n\t        1. If prune zero first, then consider all those with relevance=0, else\n\t        take all current into account\n\t        2. Get all features with minimum importance\n\t        3. Get all features with max CPU instructions\n\t        4. Get all features with max memory\n\t        If still more than 1 feature remains, then pop the first one.\n\t        \"\"\"\n", "        def _internal_loop(rest, cond, is_backed):\n\t            tmpk = []\n\t            tmpv = sys.maxsize if cond == 0 else sys.maxsize*-1\n\t            for k in rest:\n\t                if cond == 0:\n\t                    if is_backed:\n\t                        v = self.value[k][1]\n\t                    elif isinstance(self.value[k], (list, tuple)):\n\t                        v = self.value[k][0]\n\t                    else:\n", "                        v = self.value[k]\n\t                elif cond == 1:\n\t                    if key_depth_class is None:\n\t                        v = ComputationalRequirements.requirements_to_cost(\n\t                            k.computational_requirements, ignore_depth=True)\n\t                    else:\n\t                        v = ComputationalRequirements.requirements_to_cost(\n\t                            k.computational_requirements, ignore_depth=key_depth_class)\n\t                elif cond == 2:\n\t                    v = k.memory_requirements\n", "                else:\n\t                    raise Exception()\n\t                if (cond == 0 and v < tmpv) or ((cond == 1 or cond == 2) and v > tmpv):\n\t                    tmpv = v\n\t                    tmpk = [k]\n\t                elif v == tmpv:\n\t                    tmpk.append(k)\n\t            return tmpk\n\t        # used only in case all features' relevances were 0, so a backup metric is used.\n\t        is_backed_up = sum(1 for v in self.value.values()\n", "                           if isinstance(v, (tuple, list))) == len(self.value)\n\t        # get all features with no importance (0)\n\t        if prune_zero_first:\n\t            mink = [k for k, v in self.value.items() if (is_backed_up and v[1] == 0) or\n\t                    (not is_backed_up and v == 0)] or list(self.value.keys())\n\t            if len(mink) == 1:\n\t                return self.value.pop(mink[0])\n\t        else:\n\t            mink = list(self.value.keys())\n\t        # get all features with minimum importance\n", "        mink = _internal_loop(mink, 0, is_backed_up)\n\t        if len(mink) == 1:\n\t            return self.value.pop(mink[0])\n\t        # get all features with max CPU\n\t        mink = _internal_loop(mink, 1, is_backed_up)\n\t        if len(mink) == 1:\n\t            return self.value.pop(mink[0])\n\t        # get all features with max memory\n\t        mink = _internal_loop(mink, 2, is_backed_up)\n\t        return self.value.pop(mink[0])\n"]}
