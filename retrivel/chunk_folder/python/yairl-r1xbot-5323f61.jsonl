{"filename": "tools/user_settings.py", "chunked_list": ["#!/usr/bin/python3\n\timport os\n\timport sys\n\timport json\n\timport psycopg2\n\tfrom dotenv import load_dotenv\n\tfrom datetime import datetime\n\tdef connect_to_db():\n\t    stage = os.environ['R1X_STAGE'] if 'R1X_STAGE' in os.environ else 'dev'\n\t    print('Connecting to %s environment...' % stage)\n", "    load_dotenv('.env.%s' % stage)\n\t    connection_string = os.getenv('DB_CONNECTION_STRING')\n\t    conn = psycopg2.connect(connection_string)\n\t    return conn\n\tdef get_settings(user_id):\n\t    conn = connect_to_db()\n\t    cursor = conn.cursor()\n\t    cursor.execute(\"SELECT * FROM user_settings WHERE user_id = %s ORDER BY id DESC\", (user_id,))\n\t    row = cursor.fetchone()\n\t    if row:\n", "        print(\"Settings for user_id {}: {}\".format(user_id, row))\n\t    else:\n\t        print(\"No settings found for user_id {}\".format(user_id))\n\t    cursor.close()\n\t    conn.close()\n\tdef set_setting(user_id, key_value_pairs):\n\t    conn = connect_to_db()\n\t    cursor = conn.cursor()\n\t    cursor.execute(\"SELECT settings FROM user_settings WHERE user_id = %s\", (user_id,))\n\t    row = cursor.fetchone()\n", "    settings = row[0] if row else {}\n\t    for pair in key_value_pairs:\n\t        key, value = pair.split(\"=\")\n\t        settings[key] = value\n\t    cursor.execute('INSERT INTO user_settings (user_id, settings, version, \"createdAt\", \"updatedAt\") VALUES (%s, %s, 1, %s, %s)',\n\t                   (user_id, json.dumps(settings), datetime.now(), datetime.now()))\n\t    conn.commit()\n\t    cursor.close()\n\t    conn.close()\n\tdef clear_setting(user_id, key):\n", "    conn = connect_to_db()\n\t    cursor = conn.cursor()\n\t    cursor.execute(\"SELECT settings FROM user_settings WHERE user_id = %s\", (user_id,))\n\t    row = cursor.fetchone()\n\t    if row:\n\t        settings = row[0]\n\t        if key in settings:\n\t            del settings[key]\n\t            cursor.execute(\"UPDATE user_settings SET settings = %s WHERE user_id = %s\", (json.dumps(settings), user_id))\n\t            conn.commit()\n", "        else:\n\t            print(\"Key not found in settings for user_id {}\".format(user_id))\n\t    else:\n\t        print(\"No settings found for user_id {}\".format(user_id))\n\t    cursor.close()\n\t    conn.close()\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) < 3:\n\t        print(\"Usage: python script.py [get|set|clear] user_id [key=value [key=value]...]\")\n\t        sys.exit(1)\n", "    action = sys.argv[1]\n\t    user_id = sys.argv[2]\n\t    if action == \"get\":\n\t        get_settings(user_id)\n\t    elif action == \"set\":\n\t        if len(sys.argv) < 4:\n\t            print(\"Usage: python script.py set user_id key=value [key=value]...\")\n\t            sys.exit(1)\n\t        key_value_pairs = sys.argv[3:]\n\t        set_setting(user_id, key_value_pairs)\n", "    elif action == \"clear\":\n\t        if len(sys.argv) < 4:\n\t            print(\"Usage: python script.py clear user_id key\")\n\t            sys.exit(1)\n\t        key = sys.argv[3]\n\t        clear_setting(user_id, key)\n\t    else:\n\t        print(\"Invalid action. Use get, set, or clear.\")\n\t        sys.exit(1)\n"]}
{"filename": "tools/__init__.py", "chunked_list": []}
{"filename": "tools/extract.py", "chunked_list": ["#!/usr/bin/python3\n\timport re\n\timport json\n\timport argparse\n\tdef extract_messages(log_file, output_file):\n\t    with open(log_file, 'r') as log, open(output_file, 'w') as out:\n\t        log_content = log.read()\n\t        pattern = r\"Starting getChatCompletionWithTools\\.([\\s\\S]*?)(parsedMessages: \\[[\\s\\S]*?\\])\"\n\t        matches = re.findall(pattern, log_content)\n\t        if matches:\n", "            last_instance = matches[-1][-1]\n\t            role_pattern = r\"role: (?:'([^']*)'|\\\"([^\\\"]*)\\\")\"\n\t            #content_pattern = r\"content: (?:'([^']*)'|\\\"([^\\\"]*)\\\")\"\n\t            content_pattern = r\"content:\\s*(?:'([^']+)'|\\\"([^\\\"]+)\\\")\"\n\t            roles = [role[0] or role[1] for role in re.findall(role_pattern, last_instance)]\n\t            contents = [content[0] + content[1] for content in re.findall(content_pattern, last_instance, re.MULTILINE | re.DOTALL )]\n\t            messages = { \"messages\" : [{\"role\": role, \"content\": content} for role, content in zip(roles, contents)] }\n\t            with open(output_file, 'w') as out:\n\t                json.dump(messages, out, indent=2)\n\t        else:\n", "            print(\"No matching instances found in the log file.\")\n\t# Replace 'input.log' and 'output.json' with your actual log and output file names\n\tif __name__ == '__main__':\n\t    parser = argparse.ArgumentParser(description='Extract messages from a log file and save them to an output JSON file.')\n\t    parser.add_argument('--input', required=True, help='Path to the input log file.')\n\t    parser.add_argument('--output', required=True, help='Path to the output JSON file.')\n\t    args = parser.parse_args()\n\t    extract_messages(args.input, args.output)\n"]}
{"filename": "tools/stats.py", "chunked_list": ["#!/usr/bin/python3\n\timport argparse\n\timport dotenv\n\timport numpy\n\timport os\n\timport psycopg2\n\timport psycopg2.extras\n\tdotenv.load_dotenv('.env.prod')\n\tps = psycopg2.connect(os.environ['DB_CONNECTION_STRING'])\n\tcur = ps.cursor(cursor_factory=psycopg2.extras.DictCursor)\n", "def get_message_count(start_date, end_date):\n\t    cur = ps.cursor(cursor_factory=psycopg2.extras.DictCursor)\n\t    cur.execute('''SELECT COUNT(id) FROM \"Messages\" WHERE DATE(\"createdAt\") >= '%s' AND DATE(\"createdAt\") <= '%s';''' % (start_date, end_date))\n\t    message_count = cur.fetchall()[0][0]\n\t    return message_count\n\tdef get_active_chats_count(start_date, end_date):\n\t    cur = ps.cursor(cursor_factory=psycopg2.extras.DictCursor)\n\t    cur.execute('''SELECT COUNT(DISTINCT (source, \"chatId\")) FROM \"Messages\" WHERE DATE(\"createdAt\") >= '%s' AND DATE(\"createdAt\") <= '%s';''' % (start_date, end_date))\n\t    active_chat_count = cur.fetchall()[0][0]\n\t    return active_chat_count\n", "def get_active_chat_histogram(start_date, end_date):\n\t    cur = ps.cursor(cursor_factory=psycopg2.extras.DictCursor)\n\t    # Select <source>:<chat>, so this data can be used later to send messages to specific users.\n\t    cur.execute('''SELECT source, \"chatId\", chat_id_count FROM (SELECT source, \"chatId\", COUNT(*) as chat_id_count FROM \"Messages\" WHERE DATE(\"createdAt\") >= '%s' AND DATE(\"createdAt\") <= '%s' GROUP BY source, \"chatId\") AS chat_count_table ORDER BY chat_id_count DESC;''' % (start_date, end_date))\n\t    chats = []\n\t    for member in cur.fetchall():\n\t        chats.append(member)\n\t    return chats\n\tparser = argparse.ArgumentParser(description='Fetch statistics from R1X database.')\n\tparser.add_argument('--start-date', type=str, dest='start_date', help='Start date.', required=True)\n", "parser.add_argument('--end-date', type=str, dest='end_date', help='End date.', required=True)\n\targs = parser.parse_args()\n\tnum_msgs = get_message_count(args.start_date, args.end_date)\n\tprint('Number of messages: ', num_msgs)\n\tchats = get_active_chat_histogram(args.start_date, args.end_date)\n\tprint('Active chats today: ', len(chats))\n\tmsg_arr = []\n\tnumbers = [] \n\tfor chat in chats:\n\t    (source, chat_id, msgs) = chat\n", "    msg_arr.append(msgs)\n\t    if source == 'wa':\n\t        numbers.append(f'{source}:{chat_id}')\n\t    if msgs < 8:\n\t        continue\n\t    print(source, chat_id, msgs)\n\tprint(','.join(numbers))\n\tprint(numpy.histogram(msg_arr, [0, 5, 10, 15, 20, 50, 100]))\n"]}
{"filename": "tools/multi_sender.py", "chunked_list": ["#!/usr/bin/python3\n\timport argparse\n\timport sys\n\timport os\n\tfrom typing import Dict, List\n\tsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src')))\n\tfrom infra import utils \n\tfrom infra.context import Context\n\tfrom services.messengers.messenger_factory import make_messenger\n\tutils.load_env()\n", "def multi_send(ctx:Context, full_chat_ids: List[str], attrs: Dict[str,str]):\n\t    for full_chat_id in full_chat_ids:\n\t        messenger = make_messenger(full_chat_id)\n\t        response = messenger.send_message(ctx, attrs)\n\t        print(response)\n\t        should_send_contact = attrs['contact_name'] and attrs['contact_handle']\n\t        if should_send_contact:\n\t            response = messenger.send_contact(ctx, attrs['contact_name'], attrs['contact_handle'])\n\t            print(response)\n\tif __name__ == '__main__':\n", "    parser = argparse.ArgumentParser(description='Send a message to multiple chat ids.')\n\t    parser.add_argument('--message', required=False, help='Message string.')\n\t    parser.add_argument('--file', required=False, help='Message string, in file.')\n\t    parser.add_argument('--chat_ids', required=True, help='a comma seperated list of <messenger wa/tg>:<chat ids> e.g wa:12346578,tg:456789654 ')\n\t    parser.add_argument('--contact-name', required=False, action='store', help='''Send contact. Name is the contact's name.''')\n\t    parser.add_argument('--contact-handle', required=False, action='store', help='''Send contact. Handle is contact's handle in WhatsApp/Telegram.''')\n\t    args = parser.parse_args()\n\t    if not args.message and not args.file:\n\t        print('No message provided. Use --message or --file')\n\t    if args.message:\n", "        msg = args.message\n\t    else:\n\t        msg = open(args.file, 'r').read()\n\t    full_chat_ids=args.chat_ids.split(',')\n\t    ctx = Context()\n\t    multi_send(ctx, full_chat_ids, {\n\t            \"kind\": \"text\",\n\t            \"body\": msg,\n\t            \"contact_name\" : args.contact_name,\n\t            \"contact_handle\" : args.contact_handle\n", "        })\n"]}
{"filename": "tools/delete_chat.py", "chunked_list": ["#!/usr/bin/python3\n\timport os\n\timport sys\n\timport json\n\timport psycopg2\n\tfrom dotenv import load_dotenv\n\tfrom datetime import datetime\n\tdef connect_to_db():\n\t    stage = os.environ['R1X_STAGE'] if 'R1X_STAGE' in os.environ else 'dev'\n\t    print('Connecting to %s environment...' % stage)\n", "    load_dotenv('.env.%s' % stage)\n\t    connection_string = os.getenv('DB_CONNECTION_STRING')\n\t    conn = psycopg2.connect(connection_string)\n\t    return conn\n\tdef delete_history(source, chat_id):\n\t    conn = connect_to_db()\n\t    cursor = conn.cursor()\n\t    cursor.execute(\"DELETE FROM \\\"Messages\\\" WHERE source = %s AND \\\"chatId\\\" = %s\", (source, chat_id,)) \n\t    conn.commit()\n\t    cursor.close()\n", "    conn.close()\n\tif __name__ == \"__main__\":\n\t    if len(sys.argv) < 3:\n\t        print(\"Usage: python script.py source chat_id\")\n\t        sys.exit(1)\n\t    source = sys.argv[1]\n\t    chat_id = sys.argv[2]\n\t    delete_history(source, chat_id)\n"]}
{"filename": "test/local-test.py", "chunked_list": ["#!/usr/bin/python3\n\timport os\n\timport sys\n\tsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src')))\n\tfrom infra.utils import load_env\n\tload_env()\n\timport sys\n\timport json\n\timport asyncio\n\tfrom pathlib import Path\n", "from infra.logger import logger, create_logging_context\n\tfrom services.open_ai.query_openai import get_chat_completion_with_tools\n\tdef run():\n\t    args = sys.argv[1:]\n\t    # Check if the user specified any command line arguments\n\t    if not args:\n\t        print(\"No arguments provided.\")\n\t        sys.exit(1)\n\t    json_input = args[0]\n\t    with open(json_input, 'r', encoding='utf-8') as file:\n", "        data = file.read()\n\t    history = json.loads(data)[\"messages\"]\n\t    ctx = create_logging_context(0)\n\t    ctx.user_channel = 'stable'\n\t    reply = get_chat_completion_with_tools(ctx, 'WhatsApp', history, True)\n\t    print({'reply': reply})\n\trun()\n"]}
{"filename": "test/__init__.py", "chunked_list": []}
{"filename": "alembic/env.py", "chunked_list": ["from logging.config import fileConfig\n\timport os\n\timport dotenv\n\tfrom sqlalchemy import engine_from_config\n\tfrom sqlalchemy import pool\n\tfrom alembic import context\n\t# this is the Alembic Config object, which provides\n\t# access to the values within the .ini file in use.\n\tconfig = context.config\n\tSTAGE = os.environ.get('R1X_STAGE', 'dev')\n", "dotenv.load_dotenv(f'.env.{STAGE}')\n\tconfig.set_main_option(\n\t    \"sqlalchemy.url\", os.environ[\"DB_CONNECTION_STRING\"]\n\t)\n\t# Interpret the config file for Python logging.\n\t# This line sets up loggers basically.\n\tif config.config_file_name is not None:\n\t    fileConfig(config.config_file_name)\n\t# add your model's MetaData object here\n\t# for 'autogenerate' support\n", "# from myapp import mymodel\n\t# target_metadata = mymodel.Base.metadata\n\tfrom sqlalchemy import MetaData\n\timport src.db_models\n\ttarget_metadata = src.db_models.Base.metadata\n\t#target_metadata = None\n\t# other values from the config, defined by the needs of env.py,\n\t# can be acquired:\n\t# my_important_option = config.get_main_option(\"my_important_option\")\n\t# ... etc.\n", "def run_migrations_offline() -> None:\n\t    \"\"\"Run migrations in 'offline' mode.\n\t    This configures the context with just a URL\n\t    and not an Engine, though an Engine is acceptable\n\t    here as well.  By skipping the Engine creation\n\t    we don't even need a DBAPI to be available.\n\t    Calls to context.execute() here emit the given string to the\n\t    script output.\n\t    \"\"\"\n\t    url = config.get_main_option(\"sqlalchemy.url\")\n", "    context.configure(\n\t        url=url,\n\t        target_metadata=target_metadata,\n\t        literal_binds=True,\n\t        dialect_opts={\"paramstyle\": \"named\"},\n\t    )\n\t    with context.begin_transaction():\n\t        context.run_migrations()\n\tdef run_migrations_online() -> None:\n\t    \"\"\"Run migrations in 'online' mode.\n", "    In this scenario we need to create an Engine\n\t    and associate a connection with the context.\n\t    \"\"\"\n\t    connectable = engine_from_config(\n\t        config.get_section(config.config_ini_section, {}),\n\t        prefix=\"sqlalchemy.\",\n\t        poolclass=pool.NullPool,\n\t    )\n\t    with connectable.connect() as connection:\n\t        context.configure(\n", "            connection=connection, target_metadata=target_metadata\n\t        )\n\t        with context.begin_transaction():\n\t            context.run_migrations()\n\tif context.is_offline_mode():\n\t    run_migrations_offline()\n\telse:\n\t    run_migrations_online()\n"]}
{"filename": "alembic/versions/8a6746b2ce16_add_timers_table.py", "chunked_list": ["\"\"\"add timers table\n\tRevision ID: 8a6746b2ce16\n\tRevises: 7a4408168dda\n\tCreate Date: 2023-05-20 01:05:43.449156\n\t\"\"\"\n\tfrom alembic import op\n\timport sqlalchemy as sa\n\tfrom sqlalchemy.dialects.postgresql import JSONB\n\t# revision identifiers, used by Alembic.\n\trevision = '8a6746b2ce16'\n", "down_revision = '7a4408168dda'\n\tbranch_labels = None\n\tdepends_on = None\n\tdef upgrade():\n\t    op.create_table(\n\t        'timers',\n\t        sa.Column('id', sa.Integer, primary_key=True),\n\t        sa.Column('chat_id', sa.String, index=True),\n\t        sa.Column('trigger_timestamp', sa.DateTime, index=True),\n\t        sa.Column('data', JSONB),\n", "        sa.Column('created_at', sa.DateTime),\n\t        sa.Column('updated_at', sa.DateTime)\n\t    )\n\tdef downgrade():\n\t    op.drop_table('timers')\n"]}
{"filename": "alembic/versions/05e95b22503f_initial_migration.py", "chunked_list": ["\"\"\"Initial migration.\n\tRevision ID: 05e95b22503f\n\tRevises: \n\tCreate Date: 2023-05-10 01:55:00.147864\n\t\"\"\"\n\tfrom alembic import op\n\timport sqlalchemy as sa\n\t# revision identifiers, used by Alembic.\n\trevision = '05e95b22503f'\n\tdown_revision = None\n", "branch_labels = None\n\tdepends_on = None\n\tdef upgrade() -> None:\n\t    # ### commands auto generated by Alembic - please adjust! ###\n\t    op.drop_index('user_settings_created_at', table_name='user_settings')\n\t    op.drop_index('user_settings_user_id', table_name='user_settings')\n\t    op.create_index(op.f('ix_user_settings_createdAt'), 'user_settings', ['createdAt'], unique=False)\n\t    op.create_index(op.f('ix_user_settings_user_id'), 'user_settings', ['user_id'], unique=False)\n\t    # ### end Alembic commands ###\n\tdef downgrade() -> None:\n", "    # ### commands auto generated by Alembic - please adjust! ###\n\t    op.drop_index(op.f('ix_user_settings_user_id'), table_name='user_settings')\n\t    op.drop_index(op.f('ix_user_settings_createdAt'), table_name='user_settings')\n\t    op.create_index('user_settings_user_id', 'user_settings', ['user_id'], unique=False)\n\t    op.create_index('user_settings_created_at', 'user_settings', ['createdAt'], unique=False)\n\t    # ### end Alembic commands ###\n"]}
{"filename": "alembic/versions/7a4408168dda_add_events_table.py", "chunked_list": ["\"\"\"Add events table.\n\tRevision ID: 7a4408168dda\n\tRevises: 05e95b22503f\n\tCreate Date: 2023-05-14 23:03:50.906104\n\t\"\"\"\n\tfrom alembic import op\n\timport sqlalchemy as sa\n\tfrom sqlalchemy.dialects.postgresql import JSONB\n\t# revision identifiers, used by Alembic.\n\trevision = '7a4408168dda'\n", "down_revision = '05e95b22503f'\n\tbranch_labels = None\n\tdepends_on = None\n\tdef upgrade():\n\t    op.create_table(\n\t        'events',\n\t        sa.Column('id', sa.Integer, primary_key=True),\n\t        sa.Column('type', sa.String),\n\t        sa.Column('ref_table', sa.String),\n\t        sa.Column('ref_id', sa.Integer),\n", "        sa.Column('body', JSONB),\n\t        sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, server_default=sa.text('NOW()')),\n\t    )\n\t    op.create_index('ix_events_type', 'events', ['type'])\n\t    op.create_index('ix_events_ref', 'events', ['ref_table', 'ref_id'])\n\tdef downgrade():\n\t    op.drop_index('ix_events_ref', table_name='events')\n\t    op.drop_index('ix_events_type', table_name='events')\n\t    op.drop_table('events')\n"]}
{"filename": "src/message_handler.py", "chunked_list": ["import time\n\timport json\n\timport os\n\timport pathlib\n\timport tempfile\n\tfrom posthog import Posthog\n\tfrom sqlalchemy import desc\n\tfrom typing import Any, Dict\n\tfrom services.messengers import messenger_factory\n\tfrom services.messengers.messenger import MessagingService\n", "from services.open_ai.query_openai import get_chat_completion, get_chat_completion_with_tools, create_transcription\n\timport db_models\n\tfrom services.message_db import insert_message, get_message_history\n\timport services.messengers as messengers\n\tfrom infra.context import Context\n\tposthog_client = None\n\tif os.environ.get('POSTHOG_API_KEY', '') != '':\n\t    posthog_client = Posthog(\n\t        os.environ['POSTHOG_API_KEY'],\n\t        host='https://app.posthog.com'\n", "    )\n\tdef posthog_capture(distinct_id, event, properties):\n\t    if posthog_client == None:\n\t        return\n\t    posthog_client.capture(distinct_id=distinct_id, event=event, properties=properties)\n\tdef get_user_settings(parsed_message) -> Dict[str, Any]: \n\t    user_id = f\"{parsed_message.source}:{parsed_message.chatId}\"\n\t    session = db_models.Session()\n\t    settings = session.query(db_models.UserSettings) \\\n\t                .filter(db_models.UserSettings.user_id == user_id) \\\n", "                .order_by(desc(db_models.UserSettings.createdAt)) \\\n\t                .limit(1) \\\n\t                .one_or_none()\n\t    session.close()\n\t    return getattr(settings, 'settings', {})\n\tdef handle_incoming_message(ctx: Context, event):\n\t    in_flight = {\"working\": True}\n\t    try:\n\t        handle_incoming_message_core(ctx, event, in_flight)\n\t    except Exception as error:\n", "        ctx.log(\"Message processing failed: \",error)\n\t        raise Exception(\"Message processing failed.\")\n\t    finally:\n\t        in_flight[\"working\"] = False\n\tdef handle_incoming_message_core(ctx:Context, event, in_flight):\n\t    start = time.time()\n\t    parsed_event = json.loads(event)\n\t    ctx.log(parsed_event)\n\t    messenger = messenger_factory.make_messenger_from_event(parsed_event)\n\t    if messenger is None:\n", "        return\n\t    parse_message_result = messenger.parse_message(parsed_event[\"event\"])\n\t    parsed_message, file_info = parse_message_result\n\t    messenger.set_status_read(ctx, parsed_message.messageId)\n\t    ctx.user_settings = get_user_settings(parsed_message)\n\t    ctx.user_channel = ctx.user_settings.get('channel', 'stable')\n\t    if not ctx.user_settings.get('enabled', False):\n\t        messenger.send_message(ctx, {\n\t            \"chat_id\": parsed_message[\"chatId\"],\n\t            \"kind\": \"text\",\n", "            \"body\": \"Robot 1-X is no longer accessible for free. If you require access, please send a WhatsApp message to +16692221028.\\n\\nIf you simply require ChatGPT on your smartphone, you can use https://play.google.com/store/apps/details?id=com.openai.chatgpt (Android) or https://apps.apple.com/us/app/chatgpt/id6448311069 (iPhone).\"\n\t        })\n\t        return\n\t    is_typing = False\n\t    if parsed_message.kind == \"voice\":\n\t        is_typing = True\n\t        handle_audio_message(ctx, messenger, parsed_message, file_info, in_flight)\n\t        if parsed_message.isForwarded:\n\t            return\n\t    message = insert_message(ctx, parsed_message)\n", "    if message.isSentByMe or message.body is None:\n\t        return\n\t    if not messenger.is_message_for_me(message):\n\t        return\n\t    if not is_typing:\n\t        messenger.set_typing(in_flight)\n\t        is_typing = True\n\t    message_history = get_message_history(ctx, message)\n\t    ctx.log(\"message history pulled.\")\n\t    if len(message_history) <= 1:\n", "        ctx.log(\"sending intro message.\")\n\t        send_intro_message(ctx, messenger, parsed_message)\n\t        return\n\t    ctx.log(\"calling get_chat_completion...\")\n\t    messenger_name = \"WhatsApp\" if parsed_event[\"source\"] == \"wa\" else \"Telegram\"\n\t    completion = get_chat_completion_with_tools(ctx, messenger_name, message_history, direct=False)\n\t    ctx.log({\"completion\": completion})\n\t    ctx.log(\"get_chat_completion done, result is \", completion.response)\n\t    send_and_store(ctx, messenger, {\n\t        'chat_id': parsed_message.chatId,\n", "        'kind': \"text\",\n\t        'body': completion.response\n\t    })\n\t    response_time_ms = int((time.time() - parsed_message.messageTimestamp) * 1000)\n\t    processing_time_ms = int((time.time() - start) * 1000)\n\t    completion_tokens_per_sec = completion.completionTokens / (processing_time_ms / 1000)\n\t    ctx.set_stat('channel', ctx.user_channel)\n\t    ctx.set_stat('prompt_tokens', completion.promptTokens)\n\t    ctx.set_stat('completion_tokens', completion.completionTokens)\n\t    ctx.set_stat('completion_tokens_per_sec', completion_tokens_per_sec)\n", "    ctx.set_stat('total_tokens', completion.promptTokens + completion.completionTokens)\n\t    ctx.set_stat('response_time_ms', response_time_ms)\n\t    ctx.set_stat('processing_time_ms', processing_time_ms)\n\t    ph_props = {\n\t            'senderId': parsed_message.senderId,\n\t    }\n\t    ph_props.update(ctx.stats)\n\t    posthog_capture(\n\t        distinct_id = f'{parsed_message.source}:{parsed_message.chatId}',\n\t        event = 'reply-sent',\n", "        properties = ph_props\n\t    )\n\tdef handle_audio_message(ctx, messenger, parsed_message, file_info, in_flight):\n\t    messenger.set_typing(in_flight)\n\t    transcript = get_transcript(ctx, messenger, parsed_message, file_info)\n\t    text = \"\\N{SPEAKING HEAD IN SILHOUETTE}\\N{MEMO}: \" + transcript\n\t    send_attrs = {\n\t        \"chat_id\": parsed_message.chatId,\n\t        \"kind\": \"text\",\n\t        \"body\": text,\n", "        \"quote_id\": parsed_message.messageId\n\t    }\n\t    # Designed behavior:\n\t    #\n\t    # Forwarded messages: transcribe and exit\n\t    # Original messages: transcribe and respond\n\t    if parsed_message.isForwarded:\n\t        parsed_message.body = \"Please transcribe: <audio.mp3 file>\"\n\t        insert_message(ctx, parsed_message)\n\t        send_and_store(ctx, messenger, send_attrs)\n", "    else:\n\t        parsed_message.body = transcript\n\t        # Use messenger.send_message directly, so transcribed reply is not stored in DB\n\t        messenger.send_message(ctx, send_attrs)\n\t    posthog_capture(\n\t        distinct_id = f\"{parsed_message.source}:{parsed_message.chatId}\",\n\t        event = \"message-transcribed\",\n\t        properties = {\n\t            'sender_id': parsed_message.senderId,\n\t            'channel': ctx.user_channel,\n", "            'length_in_seconds': -1\n\t        }\n\t    )\n\tdef send_intro_message(ctx:Context, messenger, parsed_message):\n\t    intro_message_legal = \"\"\"Robot 1-X at your service!\n\tFirst, be aware that while I always do my best to help, I am not a professional doctor, psychologist, banker or otherwise.\n\tSome of my replies may provide incorrect information about people, locations and events.\n\tAlways check my suggestions with a professional.\n\tIf you're under 18, you must have your parents' permission before you continue talking to me!\n\tChatting with me means you agree to my Terms of Use (https://r1x.ai/terms-of-use) and Privacy policy (https://r1x.ai/privacy).\n", "Make sure to read them before continuing this chat.\"\"\"\n\t    intro_message_overview = \"\"\"Here are some things you can ask me for:\n\t- Write a bedtime story about Abigail and Jonathan, two superheroes who live next to a river.\n\t- Plan a 14-day road trip from Milan to Minsk. Include detailed suggestions about where to spend each day.\n\t- Rewrite the following text with spell-checking and punctuation: pleez send me all the docooments that is need for tomorrow flight im waiting for dem.\n\t- Please summarize the following text: <copy some text/email here>.\n\tAnd, you can record a message instead of typing!\n\tHow can I help?\"\"\"\n\t    send_and_store(ctx, messenger, {\n\t        \"chat_id\": parsed_message[\"chatId\"],\n", "        \"kind\": \"text\",\n\t        \"body\": intro_message_legal\n\t    })\n\t    send_and_store(ctx, messenger, {\n\t        \"chat_id\": parsed_message[\"chatId\"],\n\t        \"kind\": \"text\",\n\t        \"body\": intro_message_overview\n\t    })\n\tdef get_transcript(ctx:Context, messenger, parsed_message, file_info):\n\t    mp3_file_path = None\n", "    audio_root = pathlib.Path(tempfile.gettempdir()) / 'r1x' / 'audio'\n\t    audio_root.mkdir(exist_ok=True)\n\t    with tempfile.TemporaryDirectory(dir=audio_root, ignore_cleanup_errors=True) as workdir:\n\t        mp3_file_path = messenger.get_voice_mp3_file(ctx, parsed_message, file_info, pathlib.Path(workdir))\n\t        transcription = create_transcription(ctx, mp3_file_path)\n\t        return transcription\n\tdef send_and_store(ctx: Context, messenger: MessagingService, message_attributes):\n\t    response = messenger.send_message(ctx, message_attributes)\n\t    if response:\n\t        insert_message(ctx, response)\n"]}
{"filename": "src/run.py", "chunked_list": ["#!/usr/bin/python3\n\timport json\n\timport os\n\timport boto3\n\tfrom services.timers import alert_users\n\tfrom infra import logger\n\tfrom infra.context import Context\n\timport message_handler\n\timport threading\n\timport traceback\n", "from telegram import ForceReply, Update\n\tfrom telegram.ext import Application, CommandHandler, ContextTypes, MessageHandler, filters\n\tNUM_CONSUMERS = 10\n\tQUEUE_URL = os.environ[\"SQS_QUEUE_URL\"]\n\tdef process_message(message):\n\t    ctx = Context()\n\t    result = message_handler.handle_incoming_message(ctx, message['Body'])\n\t    ctx.log(\"Finished handling message\")\n\tdef single_sqs_handler(queue):\n\t    while True:\n", "        try:\n\t            single_sqs_handler_core(queue)\n\t        except Exception as e:\n\t            logger.logger.error(f'Exception occurred; {e}; stack trace: ', traceback.format_exc())\n\tdef single_sqs_handler_core(queue):\n\t    response = queue.receive_message(QueueUrl=QUEUE_URL, MaxNumberOfMessages=1, WaitTimeSeconds=20)\n\t    if not 'Messages' in response:\n\t       return\n\t    # Single message each time\n\t    message = response['Messages'][0]\n", "    process_message(message)\n\t    queue.delete_message(QueueUrl=QUEUE_URL, ReceiptHandle=message['ReceiptHandle'])\n\tdef launch_sqs_threads():\n\t    logger.logger.info(f'Listening on {NUM_CONSUMERS} queues...')\n\t    threads = []\n\t    for i in range(NUM_CONSUMERS):\n\t        queue = boto3.client('sqs', region_name='eu-central-1')\n\t        thread = threading.Thread(target=single_sqs_handler, args=(queue,))\n\t        thread.start()\n\t        threads.append(thread)\n", "    return threads\n\tasync def handle_local_incoming_telegram_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n\t    message = { 'Body' : json.dumps({ 'source' : 'tg', 'event' : json.loads(update.to_json()) }) }\n\t    ctx = Context()\n\t    process_message(message)\n\tdef launch_local_telegram_listener():\n\t    # Create the Application and pass it your bot's token.\n\t    application = Application.builder().token(os.environ['TELEGRAM_BOT_TOKEN']).build()\n\t    # on non command i.e message - echo the message on Telegram\n\t    tg_filters = (filters.AUDIO | filters.TEXT | filters.VOICE) & ~filters.COMMAND\n", "    application.add_handler(MessageHandler(tg_filters, handle_local_incoming_telegram_message))\n\t    # Run the bot until the user presses Ctrl-C\n\t    application.run_polling()\n\t    # Threads to wait on; never reached\n\t    return []\n\tdef main():\n\t    threads = []\n\t    timer_thread = threading.Thread(target=alert_users)\n\t    timer_thread.start()\n\t    threads.append(timer_thread)\n", "    if os.environ['R1X_STAGE'] in ['dev', 'prod']:\n\t        threads = launch_sqs_threads()\n\t    else:\n\t        threads = launch_local_telegram_listener()\n\t    for thread in threads:\n\t        thread.join()\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "src/db_models.py", "chunked_list": ["# coding: utf-8\n\timport os\n\timport sqlalchemy\n\tfrom sqlalchemy import create_engine, func\n\tfrom sqlalchemy import Boolean, Column, DateTime, Index, Integer, JSON, String, Text, text, TypeDecorator\n\tfrom sqlalchemy.dialects.postgresql import JSONB\n\tfrom sqlalchemy.ext.declarative import declarative_base\n\tfrom sqlalchemy.orm import sessionmaker\n\tfrom sqlalchemy.engine.url import URL\n\t# JSONB is not supported by SQLite, but is supported by PostgreSQL.\n", "# DialectAdapter selects the right one is used per database type.\n\tclass DialectAdapter(TypeDecorator):\n\t    impl = JSON\n\t    def load_dialect_impl(self, dialect):\n\t        if dialect.name == 'postgresql':\n\t            return dialect.type_descriptor(JSONB())\n\t        else:\n\t            return dialect.type_descriptor(JSON())\n\t### Start of table definitions ###\n\tBase = declarative_base()\n", "metadata = Base.metadata\n\tclass Message(Base):\n\t    __tablename__ = 'Messages'\n\t    __table_args__ = (\n\t        Index('index_on_messages_chat_id_message_id', 'chatId', 'messageId', unique=True),\n\t        Index('index_on_messages_created_at_chat_id', 'createdAt', 'chatId')\n\t    )\n\t    id = Column(Integer, primary_key=True)\n\t    source = Column(String(255))\n\t    messageTimestamp = Column(DateTime(True))\n", "    chatType = Column(String(255))\n\t    chatId = Column(String(255))\n\t    senderId = Column(String(255))\n\t    isSentByMe = Column(Boolean)\n\t    messageId = Column(String(255))\n\t    replyToMessageId = Column(String(255))\n\t    kind = Column(String(255))\n\t    body = Column(Text)\n\t    rawSource = Column(JSON)\n\t    createdAt = Column(DateTime(True), nullable=False)\n", "    updatedAt = Column(DateTime(True), nullable=False)\n\tclass SequelizeMeta(Base):\n\t    __tablename__ = 'SequelizeMeta'\n\t    name = Column(String(255), primary_key=True)\n\tclass UserSettings(Base):\n\t    __tablename__ = 'user_settings'\n\t    id = Column(Integer, primary_key=True)\n\t    user_id = Column(String(255), nullable=False, index=True)\n\t    settings = Column(DialectAdapter, nullable=False)\n\t    version = Column(Integer, nullable=False)\n", "    createdAt = Column(DateTime(True), nullable=False, index=True)\n\t    updatedAt = Column(DateTime(True), nullable=False)\n\tclass Event(Base):\n\t    __tablename__ = 'events'\n\t    id = Column(Integer, primary_key=True)\n\t    type = Column(String)\n\t    ref_table = Column(String)\n\t    ref_id = Column(Integer)\n\t    body = Column(DialectAdapter)\n\t    created_at = Column(DateTime(timezone=True), default=func.now(), nullable=False)\n", "    __table_args__ = (\n\t        sqlalchemy.Index('ix_events_type', 'type'),\n\t        sqlalchemy.Index('ix_events_ref', 'ref_table', 'ref_id'),\n\t    )\n\tclass Timer(Base):\n\t    __tablename__ = 'timers'\n\t    id = Column(Integer, primary_key=True)\n\t    chat_id = Column(String, index=True)\n\t    trigger_timestamp = Column(DateTime, index=True)\n\t    data = Column(DialectAdapter)\n", "    created_at = Column(DateTime)\n\t    updated_at = Column(DateTime)\n\t### End of table definitions ###\n\t# Set up the database connection\n\tengine = create_engine(os.environ['DB_CONNECTION_STRING'])\n\t# Create a session factory\n\tSession = sessionmaker(bind=engine)\n\t# Register models\n\tBase.metadata.create_all(engine)\n"]}
{"filename": "src/__init__.py", "chunked_list": []}
{"filename": "src/infra/context.py", "chunked_list": ["import threading\n\tfrom typing import Any, Dict, Union\n\tfrom infra import logger\n\tclass ThreadSafeCounter:\n\t    def __init__(self):\n\t        self._counter = 0\n\t        self._lock = threading.Lock()\n\t    def get_and_increment(self):\n\t        with self._lock:\n\t            val = self._counter\n", "            self._counter += 1\n\t            return val\n\t# Usage\n\tcounter = ThreadSafeCounter()\n\tclass Context(object):  \n\t    def __init__(self):\n\t        self.user_channel = None    # type: str\n\t        self.user_settings = {}     # type: Dict[str, Any]\n\t        self.msg_count = counter.get_and_increment()\n\t        self.logger = logger.create_logging_context(self.msg_count)\n", "        self.stats = {}\n\t    def log(self, message:Any, *args:Any) -> None:\n\t        self.logger.log(message, args)\n\t    def set_stat(self, key: str, value: Union[int, bool, float, str]):\n\t        self.stats[key] = value\n"]}
{"filename": "src/infra/logger.py", "chunked_list": ["import os\n\timport logging\n\tfrom logging.handlers import TimedRotatingFileHandler\n\t# This code was migrated from node.js to Python using ChatGPT.\n\t# Rotation is not necessarily working well.\n\tmax_file_size = os.environ.get(\"MAX_LOG_FILE_SIZE\", 100 * 1024 * 1024)\n\tmax_log_files = int(os.environ.get(\"MAX_LOG_FILES\", 50))\n\tlog_formatter = logging.Formatter('%(asctime)s.%(msecs)03d %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n\tfile_handler = TimedRotatingFileHandler('./logs/r1x.log', when='D', interval=1, backupCount=max_log_files)\n\tfile_handler.setFormatter(log_formatter)\n", "file_handler.setLevel(logging.INFO)\n\tfile_handler.suffix = '%Y-%m-%d'\n\tfile_handler.extMatch = file_handler.extMatch\n\tconsole_handler = logging.StreamHandler()\n\tconsole_handler.setFormatter(log_formatter)\n\tconsole_handler.setLevel(logging.INFO)\n\tlogger = logging.getLogger()\n\tlogger.setLevel(logging.INFO)\n\tlogger.addHandler(file_handler)\n\tlogger.addHandler(console_handler)\n", "class log_context():\n\t    def __init__(self, context):\n\t        self.context = context;\n\t    def log(self, message, *args):\n\t        merged_message = f\"[{self.context}] {message} {' '.join(str(arg) for arg in args)}\"\n\t        logger.info(merged_message)\n\tdef create_logging_context(context):\n\t    return log_context(context)\n"]}
{"filename": "src/infra/__init__.py", "chunked_list": []}
{"filename": "src/infra/utils.py", "chunked_list": ["import os\n\timport requests\n\timport sys\n\tfrom pathlib import Path\n\tfrom dotenv import load_dotenv\n\tfrom pydub import AudioSegment\n\tfrom infra.context import Context\n\tfrom infra.logger import logger\n\tdef download_stream_file(ctx:Context, url, path, headers=None):\n\t    # Create the directory if it doesn't exist\n", "    dir_path = Path(path).parent\n\t    os.makedirs(dir_path, exist_ok=True)\n\t    is_successful = False  # Variable to track download status\n\t    response = requests.get(url, headers=headers, stream=True)\n\t    with open(path, 'wb') as file:\n\t        for chunk in response.iter_content(chunk_size=8192):\n\t            file.write(chunk)\n\t    if response.status_code == 200:\n\t        ctx.log(\"downloadFile succeeded\")\n\t        is_successful = True\n", "    return is_successful\n\tdef convert_audio_to_mp3(ctx:Context, orig_file_path:str, mp3_file_path:str) -> str:\n\t    audio = AudioSegment.from_file(orig_file_path)\n\t    audio.export(mp3_file_path, format=\"mp3\")\n\t    ctx.log(\"convertAudioToMp3 succeeded\")\n\t    return mp3_file_path\n\tdef load_env():\n\t    stage = os.environ.get(\"R1X_STAGE\", \"dev\")\n\t    logger.info(f\"Running R1X bot in {stage} mode...\")\n\t    load_dotenv(f\"./.env.{stage}\")\n", "    # If no database is provided, resort to a locally-hosted SQLite version.\n\t    # Typically used for testing.\n\t    if os.environ.get('DB_CONNECTION_STRING', '') == '':\n\t        os.environ['DB_CONNECTION_STRING'] = 'sqlite:///file::memory:?cache=shared'\n\t    local_dev_required_envs = ['OPENAI_API_KEY', 'TELEGRAM_BOT_TOKEN', 'TELEGRAM_BOT_NAME', 'SERPER_API_KEY']\n\t    all_required_envs = local_dev_required_envs + ['AZURE_OPENAI_KEY', 'FACEBOOK_GRAPH_VERSION', 'WHATSAPP_BOT_TOKEN', 'WHATSAPP_PHONE_NUMBER_ID', 'WHATSAPP_PHONE_NUMBER', 'DB_CONNECTION_STRING', 'SQS_QUEUE_URL', 'DREAMSTUDIO_API_KEY', 'POSTHOG_API_KEY']\n\t    required_envs = local_dev_required_envs if stage == 'dev-local' else all_required_envs\n\t    # Ensure all reuqired environment variables are set up\n\t    for v in required_envs:\n\t        if os.environ.get(v, \"\") == \"\":\n", "            print(f\"Environment variable {v} is undefined or an empty string. Pleas configure it via you .env.{stage} file.\")\n\t            sys.exit(1)\n"]}
{"filename": "src/services/message_db.py", "chunked_list": ["from sqlalchemy import and_, desc\n\timport db_models\n\timport datetime\n\tfrom infra.context import Context\n\tdef insert_message(ctx:Context, attributes):\n\t    source = attributes['source']\n\t    message_timestamp = datetime.datetime.fromtimestamp(attributes['messageTimestamp'], tz=datetime.timezone.utc)\n\t    chat_type = attributes['chatType']\n\t    chat_id = attributes['chatId']\n\t    sender_id = attributes['senderId']\n", "    is_sent_by_me = attributes['isSentByMe']\n\t    message_id = attributes['messageId']\n\t    reply_to_message_id = attributes['replyToMessageId']\n\t    kind = attributes['kind']\n\t    body = attributes['body']\n\t    raw_source = attributes['rawSource']\n\t    ctx.log('insertMessage attributes:', attributes)\n\t    with db_models.Session() as session:\n\t        existing_message = session.query(db_models.Message).filter(and_(db_models.Message.chatId == chat_id, db_models.Message.messageId == message_id)).one_or_none()\n\t        if existing_message:\n", "            return existing_message\n\t        now = datetime.datetime.now()\n\t        message = db_models.Message(\n\t            source=source,\n\t            messageTimestamp=message_timestamp,\n\t            chatType=chat_type,\n\t            chatId=chat_id,\n\t            senderId=sender_id,\n\t            isSentByMe=is_sent_by_me,\n\t            messageId=message_id,\n", "            replyToMessageId=reply_to_message_id,\n\t            kind=kind,\n\t            body=body,\n\t            rawSource=raw_source,\n\t            createdAt=now,\n\t            updatedAt=now\n\t        )\n\t        session.add(message)\n\t        session.commit()\n\t        session.refresh(message)\n", "        session.close()\n\t    return message\n\tdef get_message_history(ctx:Context, message, options=None):\n\t    if options is None:\n\t        options = {}\n\t    limit = options.get('limit', 20)\n\t    chat_id = message.chatId\n\t    message_timestamp = message.messageTimestamp\n\t    with db_models.Session() as session:\n\t        messages = session.query(db_models.Message) \\\n", "                   .filter(and_(db_models.Message.chatId == chat_id, db_models.Message.messageTimestamp <= message_timestamp)) \\\n\t                   .order_by(desc(db_models.Message.createdAt)).limit(limit).all()\n\t        session.close()\n\t    return list(reversed(messages))\n"]}
{"filename": "src/services/timers.py", "chunked_list": ["import datetime\n\timport time\n\timport traceback\n\tfrom typing import Tuple\n\tfrom infra import logger, utils \n\tfrom infra.context import Context\n\tutils.load_env()\n\timport db_models\n\tfrom services.messengers import messenger_factory\n\tdef invoke_alert_tool(ctx:Context, alert_args:Tuple[int, str], parsed_message):\n", "    messenger_chat_id = f\"{parsed_message.source}:{parsed_message.chatId}\"\n\t    timestamp = int(parsed_message.messageTimestamp.timestamp())\n\t    ref_id = parsed_message.messageId\n\t    with db_models.Session() as session:\n\t        now = datetime.datetime.now()\n\t        delta_ts, topic = alert_args\n\t        timer_extra_data = {\"topic\":topic, \"ref_id\":ref_id}\n\t        trigger_ts = datetime.datetime.fromtimestamp(timestamp+ int(delta_ts))\n\t        timer = db_models.Timer(\n\t            chat_id=messenger_chat_id,\n", "            trigger_timestamp=trigger_ts, \n\t            data=timer_extra_data,\n\t            created_at=now,\n\t            updated_at=now\n\t        )\n\t        session.add(timer)\n\t        session.commit()\n\t        session.refresh(timer)\n\t        session.close()\n\t    return timer\n", "def alert_users():\n\t    ctx = Context()\n\t    while True:\n\t        try:\n\t            now = datetime.datetime.utcnow()\n\t            with db_models.Session() as session:\n\t                alerts = session.query(db_models.Timer).filter(db_models.Timer.trigger_timestamp <= now).all()\n\t            if alerts:\n\t                ctx.log(f\"[TIMER] found {len(alerts)} alerts\")                \n\t                for alert in alerts:\n", "                    try:\n\t                        topic = alert.data.get(\"topic\", None)\n\t                        quote_id = alert.data.get(\"ref_id\", None)\n\t                        messenger = messenger_factory.make_messenger(alert.chat_id)\n\t                        ctx.log(f\"[TIMER] sending a timer message to chat id {alert.chat_id}\")\n\t                        messenger.send_message(ctx, { \n\t                            \"kind\": \"text\",\n\t                            \"body\": f\"You asked me to remind you about {topic}\" if topic else \"You asked me to remind you\",\n\t                            \"quote_id\":quote_id\n\t                        })\n", "                    except:\n\t                        ctx.log(f\"[TIMER] failed to send alert {alert.id} to chat id:{alert.chat_id} \")\n\t                delete_alerts(ctx, now)                        \n\t            time.sleep(5)\n\t        except Exception as e:\n\t            logger.logger.error(f'Exception occurred; {e}; stack trace: ', traceback.format_exc()) \n\tdef delete_alerts(ctx:Context, now:datetime.datetime) -> None:\n\t    with db_models.Session() as session:\n\t        session.query(db_models.Timer).filter(db_models.Timer.trigger_timestamp <= now).delete()\n\t        ctx.log(\"[TIMER] alerts deleted\")\n", "        session.commit()   "]}
{"filename": "src/services/open_ai/__init__.py", "chunked_list": []}
{"filename": "src/services/open_ai/query_openai.py", "chunked_list": ["import backoff\n\timport json\n\timport os\n\timport openai\n\timport time\n\timport re\n\timport requests\n\timport traceback\n\tfrom typing import Dict\n\tfrom box import Box\n", "from services.timers import invoke_alert_tool\n\tfrom services.token_prediction import token_predictor\n\tfrom infra.context import Context\n\tfrom langchain.utilities import google_serper\n\tOPENAI_SPEECH_TO_TEXT_MODEL = 'whisper-1'\n\topenai.api_key = os.environ['OPENAI_API_KEY']\n\tdef deep_clone(o):\n\t    return json.loads(json.dumps(o))\n\tdef convert_message_to_chat_format(message):\n\t    converted_message = {\n", "        \"role\": \"assistant\" if message.isSentByMe else \"user\",\n\t        \"content\": message.body,\n\t    }\n\t    return converted_message\n\tdef get_system_message(ctx:Context, messenger_name):\n\t    current_date = time.strftime(\"%B %d, %Y\", time.gmtime()) \n\t    system_message = {\n\t        \"role\": \"system\",\n\t        \"content\": f\"\"\"You are Robot 1-X (R1X), a helpful, cheerful assistant developed by the Planet Express team and integrated into a {messenger_name} chat.\n\tYou are based on GPT-3.5 technology. More information about R1X is available at https://r1x.ai.\n", "Today is {current_date}.\n\tIf Robot 1-X does not know, it truthfully says so.\n\tIf user asks for information that Robot 1-X does not have but can estimate, Robot 1-X will provide the estimate, while mentioning it is an estimate and not a fact.\"\"\"\n\t    }\n\t    return system_message\n\tdef db_messages2messages(messages):\n\t    parsed_messages = []\n\t    for message in messages:\n\t        if message.body is None:\n\t            continue\n", "        parsed_messages.append(convert_message_to_chat_format(message))\n\t    return parsed_messages\n\tdef get_limited_message_history(ctx, messages, prompt_template):\n\t    soft_token_limit = 2048\n\t    hard_token_limit = 4000\n\t    messages_upto_max_tokens = token_predictor.get_messages_upto_max_tokens(\n\t        ctx, prompt_template, messages, soft_token_limit, hard_token_limit\n\t    )\n\t    if len(messages_upto_max_tokens) == 0:\n\t        return []\n", "    if messages_upto_max_tokens[0][\"role\"] == \"assistant\":\n\t        messages_upto_max_tokens.pop(0)\n\t    merged_messages = []\n\t    prev_role = None\n\t    for message in messages_upto_max_tokens:\n\t        if message[\"role\"] == 'assistant':\n\t            message[\"content\"] = message[\"content\"].removeprefix(\"\\N{LEFT-POINTING MAGNIFYING GLASS}: \")\n\t        if message[\"role\"] == prev_role:\n\t            merged_messages[-1][\"content\"] += f\"\\n{message['content']}\"\n\t        else:\n", "            merged_messages.append(message)\n\t        prev_role = message[\"role\"]\n\t    return merged_messages\n\tdef get_chat_completion(ctx:Context, messenger_name, messages, direct):\n\t    parsed_messages = deep_clone(messages) if direct else db_messages2messages(messages)\n\t    system_message = get_system_message(ctx, messenger_name)\n\t    messages_upto_max_tokens = get_limited_message_history(\n\t        ctx, parsed_messages, system_message\n\t    )\n\t    return get_chat_completion_core(ctx, messenger_name, messages_upto_max_tokens)\n", "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_tries=3)\n\tdef get_chat_completion_core(ctx, messenger_name, messages, model=None):\n\t    if not model:\n\t        model = \"gpt-4\" if ctx.user_channel == \"canary\" else \"gpt-3.5-turbo\"\n\t    try:\n\t        ctx.log(\"Messages: \", messages);\n\t        ctx.log(\"invoking completion request.\")\n\t        completion = chat_completion_create_wrap(ctx, model, messages)\n\t        ctx.log(\"getChatCompletionCore response: \", completion['choices'][0]['message']['content'])\n\t        return Box({\n", "            \"response\": completion['choices'][0]['message']['content'],\n\t            \"promptTokens\": completion['usage']['prompt_tokens'],\n\t            \"completionTokens\": completion['usage']['completion_tokens']\n\t        })\n\t    except Exception as e:\n\t        if hasattr(e, \"response\"):\n\t            ctx.log(f\"error: e.response={e.response}\")\n\t        else:\n\t            ctx.log(\"error: e={e}\", e)\n\t        ctx.log(\"error generating completion from OpenAI.\")\n", "        raise e\n\tdef get_prep_message(ctx : Context, messenger, is_final : bool) -> Dict[str, str]:\n\t    current_date = time.strftime(\"%B %d, %Y\", time.gmtime())\n\t    is_debug_prompt = False\n\t    gpt_ver = 'GPT-4' if ctx.user_channel == 'canary' else 'GPT-3.5'\n\t    prep_message_stable = {\n\t        \"role\" : \"user\",\n\t        \"content\" : f\"\"\"You are Robot 1-X (R1X), a helpful, cheerful assistant developed by the Planet Express team and integrated into a {messenger} chat.\n\tYou are based on {gpt_ver} technology. More information about you is available at https://r1x.ai.\n\tI will provide a CHAT between R1X and a human, wrapped with tags: <yair1xigor>CHAT</yair1xigor>. Last speaker is the user.\n", "Your task is to provide R1X's answer.\n\tYou can invoke one of the following tools to augment your knowledge before replying:\n\tALERT: sets a reminder for the user. TOOL_INPUT=(seconds, text), where seconds is relative time in seconds from request to when alert should be provided. answer with an error message if the user provides an absolute time.\n\tSEARCH: performs a Google search and returns key results. Use this tool to fetch real-time, up-to-date information about world events. Its data is more reliable than your existing knowledge. TOOL_INPUT=search prompt.\n\tWEATHER: per-location 3-day weather forecast, at day granularity. It does not provide a finer-grained forecast. TOOL_INPUT=<City, Country>, both in English. TOOL_INPUT should always be a well-defined settlement and country/state. IMPORTANT: If you believe the right value for TOOL_INPUT is unknown/my location/similar, do not ask for the tool to be invoked and instead use the ANSWER format to ask the user for location information.\n\tFor invoking a tool, provide your reply wrapped in <yair1xigoresponse>REPLY</yair1xigoresponse> tags, where REPLY is in JSON format with the following fields: TOOL, TOOL_INPUT.\n\tExamples:\n\t<yair1xigoresponse>{{ \"TOOL\" : \"ALERT\", \"TOOL_INPUT\" : (240, \"Do the dishes\") }}</yair1xigoresponse>\n\t<yair1xigoresponse>{{ \"TOOL\" : \"SEARCH\", \"TOOL_INPUT\" : \"Who is the current UK PM?\" }}</yair1xigoresponse>\n\t<yair1xigoresponse>{{ \"TOOL\" : \"WEATHER\", \"TOOL_INPUT\" : \"Tel Aviv, Israel\" }}</yair1xigoresponse>\n", "Use these exact formats, and do not deviate.\n\tOtherwise, provide your final reply wrapped in <yair1xigoresponse>REPLY</yair1xigoresponse> tags in a JSON format, with the following fields: ANSWER.\n\tExample:\n\t<yair1xigoresponse>{{ \"ANSWER\" : \"Current UK PM is Rishi Sunak\" }}</yair1xigoresponse>\n\tWhen providing a final answer, use this exact format, and do not deviate.\n\tIMPORTANT: ALWAYS wrap your final answer with <yair1xigoresponse> tags, and in JSON format.\n\tToday's date is {current_date}.\n\tFor up-to-date information about people, stocks and world events, ALWAYS use one of the tools available to you and DO NOT provide an answer.\n\tFor fiction requests, use your knowledge and creativity to answer.\n\tIf human request has no context of time, assume he is referring to current time period.\n", "All tools provided have real-time access to the internet; do not reply that you have no access to the internet, unless you have attempted to invoke the SEARCH tool first. Additionally, do not invoke a tool if the required TOOL_INPUT is unknown, vague, or not provided. Always follow the IMPORTANT note in the tool description.\n\tIf you have missing data and ONLY if you cannot use the tools provided to fetch it, try to estimate; in these cases, let the user know your answer is an estimate.\n\tDon't provide your response until you made sure it is valid, and meets all prerequisites laid out for tool invocation.\n\tWHEN PROVIDING A FINAL ANSWER TO THE USER, NEVER MENTION THE SEARCH AND WEATHER TOOLS DIRECTLY, AND DO NOT SUGGEST THAT THE USER UTILIZES THEM.\n\tYour thought process should follow the next steps {'audibly stating the CONCLUSION for each step number without quoting it:' if is_debug_prompt else 'silently:'}\n\t1. Understand the human's request and formulate it as a self-contained question.\n\t2. Decide which tool should be invoked can provide the most information, and with what input. Decide all prerequisites for the tool and show how each is met.\n\t3. Formulate the tool invocation request, or answer, in JSON format as detailed above. IMPORTANT: THIS PART MUST BE DELIVERED IN A SINGLE LINE. DO NOT USE MULTILINE SYNTAX.\n\tIMPORTANT: Make sure to focus on the most recent request from the user, even if it is a repeated one.\"\"\" }\n\t    prep_message_final = {\n", "        \"role\" : \"user\",\n\t        \"content\" : f\"\"\"You are Robot 1-X (R1X), a helpful, cheerful assistant developed by the Planet Express team and integrated into a {messenger} chat.\n\tYou are based on {gpt_ver} technology. More information about you is available at https://r1x.ai.\n\tI will provide a CHAT between R1X and a human, wrapped with tags: <yair1xigor>CHAT</yair1xigor>. Last speaker is the user.\n\tI will also provide you with data generated by external tool invocations, which you can rely on for your answers; this data will be wrapped with tags, as such: <r1xdata>DATA</r1xdata>.\n\tDO NOT CONTRADICT OR DOUBT THAT DATA. IT SUPERSEDES ANY OTHER DATA YOU HAVE, AND IS UP TO DATE AS OF TODAY.\n\tDO NOT MENTION TO THE USER THIS DATA WAS PROVIDED TO YOU IN ANY WAY.\n\tNEVER MENTION TO THE USER THE REPLY IS ACCORDING TO A SEARCH.\n\tDO NOT START YOUR ANSWER WITH A MAGNIFYING GLASS EMOJI; THAT WILL BE PROVIDED TO THE USER SEPARATELY, AS NEEDED.\n\tYour task is to provide R1X's answer.\n", "Today's date is {current_date}.\n\tYou are trained with knowledge until September 2021.\n\tIf you have missing data, try to estimate, and let the user know your answer is an estimate.\n\tYour thought process should follow the next steps {'audibly stating the CONCLUSION for each step number without quoting it:' if is_debug_prompt else 'silently:'}\n\t1. Understand the human's request and formulate it as a self-contained question.\n\t2. Integrate all data provided to you with your current knowledge and formulate a response.\n\tIMPORTANT: Make sure to focus on the most recent request from the user, even if it is a repeated one.\"\"\" }\n\t    return prep_message_final if is_final else prep_message_stable\n\tprep_reply_message = {\"role\": \"assistant\", \"content\": \"Understood. Please provide me with the chat between R1X and the human.\"}\n\timport datetime\n", "def get_chat_completion_with_tools(ctx:Context, messenger_name, messages, direct):\n\t    try:\n\t        ctx.log(\"Starting getChatCompletionWithTools.\")\n\t        parsed_messages = deep_clone(messages) if direct else db_messages2messages(messages)\n\t        ctx.log({\"messages\": parsed_messages})\n\t        prev_responses = []\n\t        #system_message = get_system_message(ctx, messenger_name)\n\t        system_message = None\n\t        history = get_limited_message_history(ctx, parsed_messages, system_message)\n\t        prompt_tokens_total = 0\n", "        completion_tokens_total = 0\n\t        max_iterations = 2\n\t        successful_iterations = 0\n\t        ctx.set_stat('tools-flow:tool-invocations', successful_iterations)\n\t        for i in range(max_iterations):\n\t            ctx.log(f\"Invoking completionIterativeStep #{i}\")\n\t            ctx.set_stat('tools-flow:iterations', i + 1)\n\t            is_final = (i == (max_iterations - 1))\n\t            result = completion_iterative_step(ctx, messenger_name, deep_clone(history), prev_responses, is_final)\n\t            answer = result['answer']\n", "            tool = result['tool']\n\t            input_ = result['input']\n\t            prompt_tokens = result['prompt_tokens']\n\t            completion_tokens = result['completion_tokens']\n\t            ctx.log(f\"completionIterativeStep done, answer={answer} tool={tool} input={input_} prompt_tokens={prompt_tokens} completion_tokens={completion_tokens}\" )\n\t            if not answer and not tool:\n\t                break\n\t            prompt_tokens_total += prompt_tokens\n\t            completion_tokens_total += completion_tokens\n\t            if answer:\n", "                ctx.log(f\"Answer returned: {answer}\")\n\t                if successful_iterations > 0:\n\t                    answer = \"\\N{LEFT-POINTING MAGNIFYING GLASS}: \" + answer\n\t                ctx.set_stat('tools-flow:success', True)\n\t                return Box({\n\t                    \"response\": answer,\n\t                    \"promptTokens\": prompt_tokens_total,\n\t                    \"completionTokens\": completion_tokens_total\n\t                })\n\t            if tool and input_:\n", "                successful_iterations += 1\n\t                ctx.set_stat('tools-flow:tool-invocations', successful_iterations)\n\t                ctx.log(f\"Invoking TOOL {tool} with INPUT {input_}\")\n\t                response, brk = invoke_tool(ctx, tool, input_, message=messages[-1])\n\t                if brk:\n\t                    return Box({\n\t                    \"response\": response,\n\t                    \"promptTokens\": prompt_tokens_total,\n\t                    \"completionTokens\": completion_tokens_total\n\t                })\n", "                prev_responses.append(f\"INVOKED TOOL={tool}, TOOL_INPUT={input_}, ACCURACY=100%, INVOCATION DATE={datetime.datetime.now().date()} RESPONSE={response}\")\n\t    except Exception as e:\n\t        ctx.log({\"e\": e})\n\t        traceback.print_exc();\n\t    ctx.log(\"getChatCompletionWithTools: failed generating customized reply, falling back to getChatCompletion.\")\n\t    ctx.set_stat('tools-flows:success', False)\n\t    return get_chat_completion(ctx, messenger_name, messages, direct)\n\tdef completion_iterative_step(ctx, messenger_name, history, prev_responses, is_final : bool):\n\t    result = {'answer': None, 'tool': None, 'input': None, 'prompt_tokens': None, 'completion_tokens': None}\n\t    messages = []\n", "    new_request = {'role': 'user', 'content': ''}\n\t    new_request['content'] += 'Here is the chat so far:\\n<yair1xigor>'\n\t    for message in history:\n\t        speaker = 'R1X' if message['role'] == 'assistant' else 'Human'\n\t        new_request['content'] += f'\\n<{speaker}>: {message[\"content\"]}'\n\t    new_request['content'] += '\\n<R1X:></yair1xigor>'\n\t    if prev_responses:\n\t        prev_responses_flat = '\\n'.join(prev_responses)\n\t        new_request['content'] += f'\\nhere is the data so far:\\n\\n<r1xdata>{prev_responses_flat}</r1xdata>\\n'\n\t    prep_message = get_prep_message(ctx, messenger_name, is_final)\n", "    messages.append(prep_message)\n\t    messages.append(prep_reply_message)\n\t    messages.append(new_request)\n\t    reply = get_chat_completion_core(ctx, messenger_name, messages)\n\t    result['prompt_tokens'] = reply.promptTokens\n\t    result['completion_tokens'] = reply.completionTokens\n\t    if is_final:\n\t        result['answer'] = reply['response']\n\t        return result\n\t    regex = re.compile(r'<yair1xigoresponse>(.*?)<\\/yair1xigoresponse>', re.DOTALL)\n", "    matches = regex.search(reply['response'])\n\t    if not matches:\n\t        return result\n\t    json_reply = eval(matches.group(1))\n\t    ctx.log(f'completionIterativeStep: matched response: {json_reply}')\n\t    result['answer'] = json_reply.get('ANSWER')\n\t    if result['answer']:\n\t        return result\n\t    if json_reply.get('TOOL') and json_reply.get('TOOL_INPUT'):\n\t        result['tool'] = json_reply.get('TOOL')\n", "        result['input'] = json_reply.get('TOOL_INPUT')\n\t        return result\n\t    return result\n\tdef chat_completion_create_wrap(ctx: Context, model, messages):\n\t    if model == 'gpt-4':\n\t        response = openai.ChatCompletion().create(model=model, messages=messages, temperature=0.2)\n\t        return response\n\t    if model == 'gpt-3.5-turbo':\n\t        # TODO: cleanup per issue #55\n\t        if os.environ['AZURE_OPENAI_KEY'] == '':\n", "            return openai.ChatCompletion().create(model=model, messages=messages, temperature=0.2)\n\t        url = \"https://r1x.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15\"\n\t        headers = {\n\t            \"Content-Type\": \"application/json\",\n\t            \"api-key\": os.environ['AZURE_OPENAI_KEY']\n\t        }\n\t        data = {\n\t            \"messages\" : messages,\n\t            \"temperature\": 0.2\n\t        }\n", "        response = requests.post(url, headers=headers, data=json.dumps(data)).json()\n\t        ctx.log('Azure GPT 3.5 response:', response)\n\t        content_filter_active = response.get('error', {}).get('code') == 'content_filter' or \\\n\t                                response.get('choices', [{}])[0].get('finish_reason') == 'content_filter'\n\t        if content_filter_active:\n\t            ctx.log('Content filtering applied; falling back to OpenAI API.')\n\t            ctx.set_stat('completion:content-filter', True)\n\t            response = openai.ChatCompletion().create(model=model, messages=messages, temperature=0.2)\n\t        return response\n\t    ctx.log(f'chat_completion_create_wrap: unsupported completion model {model}.')\n", "    assert False\n\tdef invoke_tool(ctx:Context, tool, input, message):\n\t    tool_canon = tool.strip().upper()\n\t    if tool_canon.startswith('SEARCH'):\n\t        # Replace this with an appropriate call to the Serper module\n\t        ctx.log(f'Invoking Google search using SERPER, input={input}')\n\t        serper = google_serper.GoogleSerperAPIWrapper(serper_api_key=os.environ['SERPER_API_KEY'])\n\t        answer = serper.run(input)\n\t        ctx.log(f'SERPER search result: {answer}')\n\t        return answer, False\n", "    if tool_canon.startswith('WEATHER'):\n\t        answer = invoke_weather_search(ctx, input)\n\t        return answer, False\n\t    if tool_canon.startswith('ALERT'):\n\t        ctx.set_stat('tools-flow:tool-alert', 1)\n\t        invoke_alert_tool(ctx, input, message)\n\t        return \"alert added successfully.\", True\n\t    return None, False\n\tdef parse_geolocation(location_data):\n\t    regex = re.compile(r'^(\\d+\\.\\d+)\\° ([NSEW]),\\s*(\\d+\\.\\d+)\\° ([NSEW])$')\n", "    match = regex.match(location_data)\n\t    if not match:\n\t        return None\n\t    lat = float(match.group(1)) * (-1 if match.group(2) == 'S' else 1)\n\t    lon = float(match.group(3)) * (-1 if match.group(4) == 'W' else 1)\n\t    return Box({'lat': lat, 'lon': lon})\n\tdef invoke_weather_search(ctx:Context, input):\n\t    ctx.log(f'invokeWeatherSearch, input={input}')\n\t    # Replace this with an appropriate call to the Serper module\n\t    # serper = Serper()\n", "    geo_prompt = f'{input} long lat'\n\t    ctx.log(f'Invoking geolocation search using SERPER, input={geo_prompt}')\n\t    serper = google_serper.GoogleSerperAPIWrapper(serper_api_key=os.environ['SERPER_API_KEY'])\n\t    geo_res = serper.run(geo_prompt)\n\t    ctx.log(f'SERPER geolocation result: {geo_res}')\n\t    geo = parse_geolocation(geo_res)\n\t    if not geo:\n\t        return None\n\t    ctx.log(f'Geolocation: lat={geo.lat} lon={geo.lon}')\n\t    w_res = requests.get(f'https://api.open-meteo.com/v1/forecast?latitude={geo.lat}&longitude={geo.lon}&daily=temperature_2m_max,temperature_2m_min,precipitation_hours,precipitation_probability_max,windspeed_10m_max&forecast_days=3&timezone=auto')\n", "    w_res_json = w_res.json()\n\t    return json.dumps(w_res_json['daily'])\n\tdef create_transcription(ctx:Context, mp3_file_path):\n\t    language = ctx.user_settings.get('transcription.lang', None)\n\t    ctx.log(f'createTranscription: preferred user language is {language}')\n\t    t0 = time.time()\n\t    transcript = openai.Audio.transcribe(\n\t        file = open(mp3_file_path, \"rb\"),\n\t        model = OPENAI_SPEECH_TO_TEXT_MODEL,\n\t        language = language\n", "    )\n\t    transcription = transcript['text']\n\t    time_taken = int((time.time() - t0) * 1000)\n\t    ctx.log(f'createTranscription: timeTaken={time_taken}ms transcription={transcription}')\n\t    return transcription\n"]}
{"filename": "src/services/token_prediction/token_predictor.py", "chunked_list": ["import json\n\timport os\n\timport tiktoken\n\t# global variable to hold the encode objects between invocations\n\tencoder = tiktoken.get_encoding(\"cl100k_base\")\n\tdef _num_tokens_from_messages(messages):\n\t    num_tokens = 0\n\t    for message in messages:\n\t        num_tokens += 4\n\t        for key, value in message.items():\n", "            num_tokens += len(encoder.encode(value))\n\t            if key == \"name\":\n\t                num_tokens -= 1\n\t    num_tokens += 2\n\t    num_tokens += 1\n\t    return num_tokens\n\tdef _get_message_tokens(message):\n\t    if len(message) == 0:\n\t        raise ValueError(f\"message is malformed. It's {message} but doesn't have any keys\")\n\t    num_tokens = 0\n", "    num_tokens += 4\n\t    for key, value in message.items():\n\t        num_tokens += len(encoder.encode(value))\n\t        if key == \"name\":\n\t            num_tokens -= 1\n\t    return num_tokens\n\tdef _get_message_index_upto_max_tokens(system_message, chat_messages, soft_token_limit, hard_token_limit):\n\t    num_tokens = 0\n\t    num_tokens += 2\n\t    num_tokens += 1\n", "    include_system_message = False\n\t    start_index = len(chat_messages)\n\t    if system_message != None:\n\t        num_tokens += _get_message_tokens(system_message)\n\t    if num_tokens > hard_token_limit:\n\t        return [include_system_message, start_index]\n\t    include_system_message = (system_message != None)\n\t    num_messages = 0\n\t    for start_index in range(len(chat_messages), 0, -1):\n\t        message = chat_messages[start_index - 1]\n", "        num_tokens += _get_message_tokens(message)\n\t        if num_tokens <= soft_token_limit:\n\t            num_messages += 1\n\t            continue\n\t        if start_index == len(chat_messages) and num_tokens <= hard_token_limit:\n\t            num_messages += 1\n\t            continue\n\t        break\n\t    return [include_system_message, len(chat_messages) - num_messages]\n\tdef get_messages_upto_max_tokens(ctx, system_message, chat_messages, soft_token_limit, hard_token_limit):\n", "    ctx.log(f\"getMessagesUptoMaxTokens: chatMessages.length={len(chat_messages)}, softTokenLimit={soft_token_limit}, hardTokenLimit={hard_token_limit}\")\n\t    include_system_message, start_index = _get_message_index_upto_max_tokens(system_message, chat_messages, soft_token_limit, hard_token_limit)\n\t    result = [system_message] if include_system_message else []\n\t    if start_index == len(chat_messages):\n\t        return result\n\t    result += chat_messages[start_index:]\n\t    return result\n"]}
{"filename": "src/services/messengers/messenger.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom typing import Tuple\n\tfrom box import Box\n\tfrom infra.context import Context\n\tclass MessageKindE:\n\t    TEXT = 'text'\n\t    VOICE = 'voice'\n\t    AUDIO = 'audio'\n\tclass MessagingService(ABC):\n\t    def __init__(self, chat_id: str):\n", "        super().__init__()\n\t        self.chat_id = chat_id\n\t    @abstractmethod\n\t    def parse_message(self, message) -> Tuple[Box, Box]:\n\t        pass\n\t    @abstractmethod\n\t    def send_message(self, ctx:Context, attributes) -> Box:\n\t        pass\n\t    @abstractmethod\n\t    def send_contact(self, ctx:Context, name:str, handle:str):\n", "        pass\n\t    @abstractmethod\n\t    def is_message_for_me(self, message) -> bool:\n\t        pass\n\t    @abstractmethod\n\t    def set_typing(self, in_flight) ->None:\n\t        pass\n\t    @abstractmethod\n\t    def get_voice_mp3_file(self, ctx:Context, parsed_message, file_info, work_dir) -> str:\n\t        pass\n", "    @abstractmethod\n\t    def set_status_read(self, ctx:Context, message_id) -> None:\n\t        pass"]}
{"filename": "src/services/messengers/messenger_factory.py", "chunked_list": ["from typing import Dict, Tuple, Optional, Type, Callable\n\tfrom services.messengers.messenger import MessagingService\n\tfrom services.messengers.tg import TelegramMessenger\n\tfrom services.messengers.wa import WhatsappMessenger\n\tmessenger_by_type: Dict[str, Type[MessagingService]] = {'tg': TelegramMessenger, 'wa': WhatsappMessenger}\n\tdef make_messenger(messenger_chat_id: str) -> MessagingService:\n\t    messenger_str, chat_id = messenger_chat_id.split(\":\")\n\t    messenger = messenger_by_type[messenger_str](chat_id)\n\t    return messenger\n\tdef _make_wa_messenger_from_event(event: Dict) -> Optional[MessagingService]:\n", "    entry_changes0 = event['event']['entry'][0]['changes'][0]['value']\n\t    if 'messages' not in entry_changes0:\n\t        # not a message event.\n\t        return None\n\t    chat_id = entry_changes0['messages'][0]['from']\n\t    messenger = messenger_by_type[event['source']](chat_id)\n\t    return messenger\n\tdef _make_tg_messenger_from_event(event: Dict) -> MessagingService:\n\t    chat_id = str(event['event']['message']['chat']['id'])\n\t    messenger = messenger_by_type[event['source']](chat_id)\n", "    return messenger\n\tmessenger_factory_by_type: Dict[str, Callable] = {'tg': _make_tg_messenger_from_event, 'wa': _make_wa_messenger_from_event}\n\tdef make_messenger_from_event(event: Dict) -> Optional[MessagingService]:\n\t    messenger = messenger_factory_by_type[event['source']](event)\n\t    return messenger\n"]}
{"filename": "src/services/messengers/__init__.py", "chunked_list": []}
{"filename": "src/services/messengers/wa.py", "chunked_list": ["import os\n\tfrom typing import Dict\n\timport requests\n\tfrom services.messengers.messenger import MessageKindE, MessagingService\n\tfrom infra import utils\n\tfrom box import Box\n\timport time\n\tfrom infra.context import Context\n\tclass EventKindE:\n\t    STATUS_UPDATE = 'status_update'\n", "    MESSAGE = 'message'\n\tclass WhatsappMessenger(MessagingService):\n\t    def _get_event_kind(self, value):\n\t        if 'statuses' in value:\n\t            return EventKindE.STATUS_UPDATE\n\t        if 'messages' in value:\n\t            return EventKindE.MESSAGE\n\t        return None\n\t    def _get_message_kind(self, value) -> str:\n\t        if value['type'] == 'audio':\n", "            return MessageKindE.VOICE\n\t        return value['type']\n\t    def parse_message(self, message):\n\t        source = \"wa\"\n\t        event_kind = self._get_event_kind(message['entry'][0]['changes'][0]['value'])\n\t        if event_kind != EventKindE.MESSAGE:\n\t            return None\n\t        message0 = message['entry'][0]['changes'][0]['value']['messages'][0]\n\t        kind = self._get_message_kind(message0)\n\t        message_timestamp = float(message0['timestamp'])\n", "        sender_id = message0['from']\n\t        chat_type = \"private\"\n\t        is_sent_by_me = sender_id == os.environ['WHATSAPP_PHONE_NUMBER']\n\t        is_forwarded = (message0.get('context', {}).get('forwarded', None) != None)\n\t        message_id = message0['id']\n\t        reply_to_message_id = message0.get('context', {}).get('id')\n\t        if kind == MessageKindE.TEXT:\n\t            body = message0['text']['body']\n\t        else:\n\t            body = None\n", "        if kind == MessageKindE.VOICE:\n\t            file_id = message0['audio']['id']\n\t        else:\n\t            file_id = None\n\t        file_unique_id = None\n\t        return [Box({\n\t            \"source\": source,\n\t            \"messageTimestamp\": message_timestamp,\n\t            \"chatType\": chat_type,\n\t            \"chatId\": self.chat_id,\n", "            \"senderId\": sender_id,\n\t            \"isSentByMe\": is_sent_by_me,\n\t            \"isForwarded\" : is_forwarded,\n\t            \"messageId\": message_id,\n\t            \"replyToMessageId\": reply_to_message_id,\n\t            \"kind\": kind,\n\t            \"body\": body,\n\t            \"rawSource\": message\n\t        }), Box({\n\t            \"fileId\": file_id,\n", "            \"fileUniqueId\": file_unique_id\n\t        })]\n\t    def _get_bot_generated_message(self, ctx:Context, send_message_response, attributes):\n\t        quote_id = attributes.get('quote_id')\n\t        kind = attributes.get('kind')\n\t        body = attributes.get('body')\n\t        message = {\n\t            \"entry\": [\n\t                {\n\t                    \"changes\": [\n", "                        {\n\t                            \"value\": {\n\t                                \"messages\": [\n\t                                    {\n\t                                        \"timestamp\": (int(time.time() * 1000) / 1e3),\n\t                                        \"from\": os.environ['WHATSAPP_PHONE_NUMBER'],\n\t                                        \"id\": send_message_response['messages'][0]['id'],\n\t                                        \"type\": kind,\n\t                                        \"text\": {\n\t                                            \"body\": body\n", "                                        }\n\t                                    }\n\t                                ]\n\t                            }\n\t                        }\n\t                    ]\n\t                }\n\t            ]\n\t        }\n\t        return message\n", "    def send_message(self, ctx:Context, attributes):\n\t        quote_id = attributes.get('quote_id')\n\t        kind = attributes.get('kind')\n\t        body = attributes.get('body')\n\t        if kind != \"text\":\n\t            return\n\t        if len(body) > 4000:\n\t            ctx.log('send_message: message body too long, %d > 4000' % len(body))\n\t            body = body[0:3999]\n\t        headers = {\n", "            \"Authorization\": f\"Bearer {os.environ['WHATSAPP_BOT_TOKEN']}\",\n\t            \"Content-Type\": \"application/json\"\n\t        }\n\t        args = {\n\t            \"messaging_product\": \"whatsapp\",\n\t            \"recipient_type\": \"individual\",\n\t            \"to\": self.chat_id,\n\t            \"type\": \"text\",\n\t            \"text\": {\n\t                \"preview_url\": False,\n", "                \"body\": body\n\t            }\n\t        }\n\t        if quote_id:\n\t            args[\"context\"] = {\"message_id\": quote_id}\n\t        response = self._post_message_request(ctx, headers, args)\n\t        if response == None:\n\t            return None\n\t        message = self._get_bot_generated_message(ctx, response.json(), attributes)\n\t        parsed_message, _ = self.parse_message(message)\n", "        parsed_message.chatId = self.chat_id\n\t        return parsed_message\n\t    def _post_message_request(self, ctx:Context, headers:Dict[str,str], args):\n\t        try:\n\t            response = requests.post(\n\t                f\"https://graph.facebook.com/{os.environ['FACEBOOK_GRAPH_VERSION']}/{os.environ['WHATSAPP_PHONE_NUMBER_ID']}/messages\",\n\t                json=args,\n\t                headers=headers\n\t            )\n\t            response.raise_for_status()\n", "        except requests.exceptions.RequestException as error:\n\t            ctx.log(f\"post_message_request: exception. error={error}\")\n\t            raise error\n\t        return response\n\t    def send_contact(self, ctx: Context, name:str, handle:str):\n\t        headers = {\n\t            \"Authorization\": f\"Bearer {os.environ['WHATSAPP_BOT_TOKEN']}\",\n\t            \"Content-Type\": \"application/json\"\n\t        }\n\t        contact_args = {\n", "            \"messaging_product\": \"whatsapp\",\n\t            \"recipient_type\": \"individual\",\n\t            \"to\": self.chat_id,\n\t            \"type\": \"contacts\",\n\t            \"contacts\": [\n\t                {\n\t                    \"addresses\": [],\n\t                    \"emails\": [],\n\t                    \"name\": {\n\t                        \"first_name\": name,\n", "                        \"formatted_name\": name,\n\t                        \"last_name\": \"\"\n\t                    },\n\t                    \"org\": {},\n\t                    \"phones\": [\n\t                        {\n\t                            \"phone\": f\"+{handle}\",\n\t                            \"type\": \"HOME\",\n\t                            \"wa_id\": handle\n\t                        }\n", "                    ],\n\t                    \"urls\": []\n\t                }\n\t            ]\n\t        }\n\t        response = self._post_message_request(ctx,headers,contact_args)\n\t        return response.json()     \n\t    def is_message_for_me(self, msg) -> bool:\n\t        if msg.chatType == \"private\":\n\t            return True\n", "        return False\n\t    def get_voice_mp3_file(self, ctx:Context, parsed_message, file_info, work_dir) -> str:\n\t        ctx.log(f\"getVoiceMp3File: {parsed_message}, {file_info}, {work_dir}\")\n\t        url = self._get_download_url(ctx, file_info.fileId)\n\t        orig_file_path, mp3_file_path = self._get_audio_file_paths(ctx, parsed_message.chatId, file_info, work_dir)\n\t        headers = {\n\t            \"Authorization\": f\"Bearer {os.environ['WHATSAPP_BOT_TOKEN']}\",\n\t        }\n\t        utils.download_stream_file(ctx, url, orig_file_path, headers)\n\t        utils.convert_audio_to_mp3(ctx, orig_file_path, mp3_file_path)\n", "        return mp3_file_path\n\t    def _get_download_url(self, ctx:Context, file_id):\n\t        ctx.log(f\"getDownloadUrl: {file_id}\")\n\t        headers = {\n\t            \"Authorization\": f\"Bearer {os.environ['WHATSAPP_BOT_TOKEN']}\",\n\t        }\n\t        try:\n\t            response = requests.get(\n\t                f\"https://graph.facebook.com/{os.environ['FACEBOOK_GRAPH_VERSION']}/{file_id}?phone_number_id={os.environ['WHATSAPP_PHONE_NUMBER_ID']}\",\n\t                headers=headers\n", "            )\n\t            response.raise_for_status()\n\t        except requests.exceptions.RequestException as error:\n\t            ctx.log(f\"getDownloadUrl: exception. error={error}\")\n\t            raise error\n\t        download_url = response.json()['url']\n\t        ctx.log(f\"getDownloadUrl: downloadUrl={download_url}\")\n\t        return download_url\n\t    def _get_audio_file_paths(self, ctx:Context, chat_id, file_info, work_dir):\n\t        orig_file_path = work_dir / 'audio.orig'\n", "        mp3_file_path = work_dir / 'audio.mp3'\n\t        ctx.log(f\"getAudioFilePaths: orgFilePath={orig_file_path}, mp3FilePath={mp3_file_path}\")\n\t        return orig_file_path, mp3_file_path\n\t    def set_typing(self, in_flight):\n\t        # TODO: igors - can't find WA API for typing indication.\n\t        pass\n\t    def set_status_read(self, ctx:Context, message_id):\n\t        ctx.log(\"setStatusRead\")\n\t        headers = {\n\t            \"Authorization\": f\"Bearer {os.environ['WHATSAPP_BOT_TOKEN']}\",\n", "            \"Content-Type\": \"application/json\",\n\t        }\n\t        args = {\n\t            \"messaging_product\": \"whatsapp\",\n\t            \"status\": \"read\",\n\t            \"message_id\": message_id,\n\t        }\n\t        try:\n\t            response = requests.post(\n\t                f\"https://graph.facebook.com/{os.environ['FACEBOOK_GRAPH_VERSION']}/{os.environ['WHATSAPP_PHONE_NUMBER_ID']}/messages\",\n", "                json=args,\n\t                headers=headers\n\t            )\n\t            response.raise_for_status()\n\t        except requests.exceptions.RequestException as error:\n\t            ctx.log(f\"setStatusRead: exception. error={error}\")\n\t            return\n\t        if response.json().get('success') != True:\n\t            ctx.log(f\"setStatusRead: response is wrong. Compared field {response.json().get('success')}. Full response {response}\")\n"]}
{"filename": "src/services/messengers/tg.py", "chunked_list": ["import os\n\timport random\n\timport tempfile\n\tfrom typing import Optional\n\timport requests\n\tfrom infra.context import Context\n\tfrom services.messengers.messenger import MessageKindE, MessagingService\n\tfrom infra import utils\n\tfrom box import Box\n\timport threading\n", "TELEGRAM_SENDER_ID = os.environ['TELEGRAM_BOT_TOKEN'].split(':')[0]\n\tclass TelegramMessenger(MessagingService):\n\t    def _get_message_kind(self, message) -> Optional[str]:\n\t        if 'text' in message:\n\t            return MessageKindE.TEXT\n\t        elif 'voice' in message:\n\t            return MessageKindE.VOICE\n\t        elif 'audio' in message:\n\t            return MessageKindE.AUDIO\n\t        return None\n", "    def parse_message(self, message):\n\t        message = message['message']\n\t        source = \"tg\"\n\t        message_timestamp = message['date']\n\t        chat_type = message['chat']['type']\n\t        sender_id = str(message['from']['id'])\n\t        is_sent_by_me = message['from']['id'] == int(TELEGRAM_SENDER_ID)\n\t        is_forwarded = message.get('forward_from', None) != None\n\t        messageId = str(message['message_id'])\n\t        reply_to_message_id = message['reply_to_message']['message_id'] if 'reply_to_message' in message else None\n", "        kind = self._get_message_kind(message)\n\t        body = message['text'] if 'text' in message else None\n\t        fileId = message['voice']['file_id'] if kind == MessageKindE.VOICE else None\n\t        fileUniqueId = message['voice']['file_unique_id'] if kind == MessageKindE.VOICE else None\n\t        return (\n\t            Box({\n\t                'source': source,\n\t                'messageTimestamp': message_timestamp,\n\t                'chatType': chat_type,\n\t                'chatId': self.chat_id,\n", "                'senderId': sender_id,\n\t                'isSentByMe': is_sent_by_me,\n\t                'isForwarded': is_forwarded,\n\t                'messageId': messageId,\n\t                'replyToMessageId': reply_to_message_id,\n\t                'kind': kind,\n\t                'body': body,\n\t                'rawSource': message\n\t            }),\n\t            Box({\n", "                'fileId': fileId,\n\t                'fileUniqueId': fileUniqueId\n\t            })\n\t        )\n\t    def send_message(self, ctx:Context, attributes): \n\t        quote_id = attributes.get('quote_id')\n\t        kind = attributes.get('kind')\n\t        body = attributes.get('body')\n\t        if kind != \"text\":\n\t            return\n", "        args = {'chat_id': self.chat_id, 'text': body}\n\t        if quote_id:\n\t            args['reply_to_message_id'] = quote_id\n\t            args['allow_sending_without_reply'] = True\n\t        response = requests.post(\n\t            f'https://api.telegram.org/bot{os.environ[\"TELEGRAM_BOT_TOKEN\"]}/sendMessage',\n\t            json=args\n\t        ).json()\n\t        if not response['ok']:\n\t            return None\n", "        message = {'message': response['result']}\n\t        parsed_message, file_info = self.parse_message(message)\n\t        return parsed_message\n\t    def send_contact(self, ctx: Context, name:str, handle:str):\n\t        args = {'chat_id': self.chat_id, 'text': f'https://t.me/{handle}'}\n\t        response = requests.post(\n\t            f'https://api.telegram.org/bot{os.environ[\"TELEGRAM_BOT_TOKEN\"]}/sendMessage',\n\t            json=args\n\t        ).json()\n\t        return response\n", "    def is_message_for_me(self, msg) -> bool:\n\t        if msg.chatType == \"private\":\n\t            return True\n\t        if msg.body.startswith(f'@{os.environ[\"TELEGRAM_BOT_NAME\"]}'):\n\t            return True\n\t        if 'reply_to_message' in msg.rawSource and msg.rawSource['reply_to_message']['from']['id'] == int(TELEGRAM_SENDER_ID):\n\t            return True\n\t        return False\n\t    def get_voice_mp3_file(self, ctx:Context, parsed_message, file_info, work_dir) -> str:\n\t        ctx.log(f\"getVoiceMp3File: {parsed_message}, {file_info}, {work_dir}\")\n", "        url = self._get_download_url(ctx, file_info.fileId)\n\t        orig_file_path, mp3_file_path = self._get_audio_file_paths(ctx, parsed_message.chatId, file_info, work_dir)\n\t        utils.download_stream_file(ctx, url, orig_file_path)\n\t        utils.convert_audio_to_mp3(ctx, orig_file_path, mp3_file_path)\n\t        return mp3_file_path\n\t    def _get_download_url(self, ctx:Context, file_id):\n\t        args = {\"file_id\": file_id}\n\t        response = requests.post(\n\t            f\"https://api.telegram.org/bot{os.environ['TELEGRAM_BOT_TOKEN']}/getFile\",\n\t            json=args,\n", "        )\n\t        data = response.json()\n\t        if not data[\"ok\"]:\n\t            ctx.log(f\"getDownloadUrl failed. response={data}\")\n\t        remote_file_path = data[\"result\"][\"file_path\"]\n\t        download_url = f\"https://api.telegram.org/file/bot{os.environ['TELEGRAM_BOT_TOKEN']}/{remote_file_path}\"\n\t        ctx.log(f\"getDownloadUrl: downloadUrl={download_url}\")\n\t        return download_url\n\t    def _get_audio_file_paths(self, ctx:Context, chat_id, file_info, work_dir):\n\t        orig_file_path = work_dir / 'audio.orig'\n", "        mp3_file_path = work_dir / 'audio.mp3'\n\t        ctx.log(f\"getAudioFilePaths: origFilePath={orig_file_path}, mp3FilePath={mp3_file_path}\")\n\t        return orig_file_path, mp3_file_path\n\t    def set_typing(self, in_flight):\n\t        if not in_flight[\"working\"]:\n\t            return\n\t        requests.post(\n\t            f\"https://api.telegram.org/bot{os.environ['TELEGRAM_BOT_TOKEN']}/sendChatAction\",\n\t            json={\"chat_id\": self.chat_id, \"action\": \"typing\"},\n\t        )\n", "        base_timeout = 6\n\t        extra_timeout = random.randint(0, 1500)\n\t        timeout = base_timeout + (extra_timeout / 1000)\n\t        timer = threading.Timer(timeout, self.set_typing, args=(in_flight,))\n\t        timer.start()\n\t    def set_status_read(self, ctx: Context, message_id) -> None:\n\t        return\n"]}
