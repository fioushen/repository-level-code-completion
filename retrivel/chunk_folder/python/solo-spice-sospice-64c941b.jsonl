{"filename": "sospice/__init__.py", "chunked_list": ["from ._version import __version__, __version_tuple__\n\tfrom .catalog.catalog import Catalog\n\tfrom .catalog.release import Release\n\tfrom .catalog.file_metadata import FileMetadata\n\tfrom .calibrate.uncertainties import spice_error\n"]}
{"filename": "sospice/tests/__init__.py", "chunked_list": []}
{"filename": "sospice/data/__init__.py", "chunked_list": []}
{"filename": "sospice/data/tests/__init__.py", "chunked_list": []}
{"filename": "sospice/util/rss.py", "chunked_list": ["import numpy as np\n\tdef rss(a, axis=None):\n\t    \"\"\"\n\t    Root sum square of array elements\n\t    Parameters\n\t    ----------\n\t    a: numpy.array\n\t        Input values\n\t    axis: None or int or tuple of ints\n\t        Axis or axes along which the root-sum-square is performed.\n", "    Return\n\t    ------\n\t    float\n\t        Root sum square of input values over a given axis\n\t    \"\"\"\n\t    return np.linalg.norm(a, axis=axis)\n"]}
{"filename": "sospice/util/__init__.py", "chunked_list": ["from .rss import rss\n"]}
{"filename": "sospice/util/tests/test_rss.py", "chunked_list": ["import numpy as np\n\tfrom ..rss import rss\n\tdef test_rss():\n\t    a = np.array([3, 4])\n\t    assert np.isclose(rss(a), 5.0)\n\t    a = np.array([[3, 4, 5], [5, 4, 3]])\n\t    assert np.isclose(rss(a), 10.0)\n\t    assert np.allclose(rss(a, axis=0), np.sqrt([34, 32, 34]))\n\t    assert np.allclose(rss(a, axis=1), np.sqrt([50, 50]))\n"]}
{"filename": "sospice/util/tests/__init__.py", "chunked_list": []}
{"filename": "sospice/catalog/catalog.py", "chunked_list": ["from dataclasses import dataclass\n\timport pandas as pd\n\tfrom pathlib import Path\n\tfrom astropy.utils.data import download_file\n\tfrom .release import Release\n\tfrom .file_metadata import required_columns\n\t@dataclass\n\tclass Catalog(pd.DataFrame):\n\t    \"\"\"\n\t    A SPICE catalog, initialized (in that order) either from a filename, a release tag, or a pandas.DataFrame.\n", "    Parameters\n\t    ----------\n\t    filename: str\n\t        A file name (or URL) for the catalog\n\t    release_tag: str\n\t        A release tag. The catalog is fetched online and dowloaded to the astropy cache.\n\t    data_frame: pandas.DataFrame\n\t        A pandas DataFrame to be used as SPICE catalog. Some basic checks are made to ensure\n\t        that is can be used as a SPICE catalog.\n\t    update_cache: bool\n", "        Update cached catalog for the given release tag\n\t    \"\"\"\n\t    filename: str = None\n\t    release_tag: str = None\n\t    data_frame: pd.DataFrame = None\n\t    update_cache: bool = False\n\t    def __post_init__(self):\n\t        \"\"\"\n\t        Read catalog and update object\n\t        \"\"\"\n", "        self._normalize_arguments()\n\t        if self.release_tag is not None:\n\t            self._cache_release_catalog()\n\t        if self.filename is not None:\n\t            super().__init__(self.read_catalog())\n\t        else:\n\t            if self.data_frame is None:\n\t                self.data_frame = pd.DataFrame()\n\t            self._validate_data_frame()\n\t            super().__init__(self.data_frame)\n", "            del self.data_frame  # needed for memory usage?\n\t            self.data_frame = None\n\t    def _normalize_arguments(self):\n\t        \"\"\"\n\t        Prioritize filename then release tag then data frame\n\t        \"\"\"\n\t        if self.filename is not None:\n\t            self.release_tag = None\n\t            self.data_frame = None\n\t        elif self.release_tag is not None:\n", "            self.data_frame = None\n\t    def _cache_release_catalog(self):\n\t        \"\"\"\n\t        Used cached catalog or download release catalog to astropy cache\n\t        \"\"\"\n\t        if self.release_tag is None:\n\t            return\n\t        if self.release_tag == \"latest\":\n\t            self.release_tag = None\n\t        release = Release(self.release_tag)\n", "        assert release.exists\n\t        self.filename = download_file(release.catalog_url, cache=True)\n\t        self.release_tag = None\n\t    def _validate_data_frame(self):\n\t        \"\"\"\n\t        Check that the data_frame argument can be considered a valid SPICE catalog (or raise an exception)\n\t        \"\"\"\n\t        assert self.data_frame is not None\n\t        if self.data_frame.empty:\n\t            return True  # an empty data frame is valid\n", "        assert required_columns.issubset(self.data_frame.columns)\n\t    def read_catalog(self):\n\t        \"\"\"\n\t        Read SPICE FITS files catalog\n\t        Return\n\t        ------\n\t        pandas.DataFrame\n\t            Catalog\n\t        \"\"\"\n\t        if not Path(self.filename).exists():\n", "            raise RuntimeError(f\"File {self.filename} does not exist\")\n\t        df = pd.read_csv(\n\t            self.filename,\n\t            low_memory=False,\n\t        )\n\t        date_columns = [\"DATE-BEG\", \"DATE\", \"TIMAQUTC\"]\n\t        for date_column in date_columns:\n\t            df.loc[df[date_column] == \"MISSING\", date_column] = \"NaT\"\n\t            df[date_column] = pd.to_datetime(df[date_column], format=\"ISO8601\")\n\t        return df\n", "    @classmethod\n\t    def build_query_from_keywords(cls, **kwargs):\n\t        \"\"\"\n\t        Build a query from the provided parameters: exact keyword matches\n\t        Parameters\n\t        ----------\n\t        kwargs: dict\n\t            Parameters and their values\n\t        Return\n\t        ------\n", "        str\n\t            Query string for `pandas.DataFrame.query()`\n\t        Notes:\n\t        * does not work for dates\n\t        * keywords are converted to upper case (FITS keywords)\n\t        * ignores keywords with value None\n\t        \"\"\"\n\t        queries = list()\n\t        for key in kwargs:\n\t            value = kwargs[key]\n", "            if value is None:\n\t                continue\n\t            if isinstance(value, str):\n\t                query = f'{key.upper()} == \"{kwargs[key]}\"'\n\t            else:\n\t                query = f\"{key.upper()} == {kwargs[key]}\"\n\t            queries.append(query)\n\t        return \" and \".join(queries)\n\t    def find_files_by_keywords(self, **kwargs):\n\t        \"\"\"\n", "        Find files according to criteria on metadata: exact keyword matches\n\t        Parameters\n\t        ----------\n\t        kwargs: dict\n\t            Parameters and their values\n\t        Return\n\t        ------\n\t        Catalog\n\t            Matching files\n\t        \"\"\"\n", "        if self.empty or not kwargs:\n\t            return self\n\t        query = Catalog.build_query_from_keywords(**kwargs)\n\t        if query != \"\":\n\t            df = self.query(query)\n\t            return Catalog(data_frame=df)\n\t        else:\n\t            return self\n\t    def find_files_by_date_range(self, date_min=None, date_max=None):\n\t        \"\"\"\n", "        Find files in some date range.\n\t        Parameters\n\t        ----------\n\t        date_min:\n\t            Minimum date of a date range\n\t        date_max:\n\t            Maximum date of a date range\n\t        Return\n\t        ------\n\t        Catalog\n", "            Matching files\n\t        \"\"\"\n\t        if self.empty:\n\t            return self\n\t        df = self\n\t        if date_min is not None:\n\t            if type(date_min) is str:\n\t                date_min = pd.Timestamp(date_min)\n\t            df = df[df[\"DATE-BEG\"] >= date_min]\n\t        if date_max is not None:\n", "            if type(date_max) is str:\n\t                date_max = pd.Timestamp(date_max)\n\t            df = df[df[\"DATE-BEG\"] <= date_max]\n\t        return Catalog(data_frame=df)\n\t    def find_file_closest_to_date(self, date, level=\"L2\"):\n\t        \"\"\"\n\t        Find file closest to some given date\n\t        Parameters\n\t        ----------\n\t        date: datetime.datetime, pandas.Timestamp...\n", "            Date (compared to DATE-BEG)\n\t        level: str\n\t            Data level\n\t        Return\n\t        ------\n\t        pandas.Series\n\t            Matching file\n\t        \"\"\"\n\t        if date is None:\n\t            return pd.Series()\n", "        if type(date) is str:\n\t            date = pd.Timestamp(date)\n\t        df = self[self.LEVEL == level]\n\t        df.set_index(\"DATE-BEG\", inplace=True)\n\t        index = df.index.get_indexer([date], method=\"nearest\")\n\t        df.reset_index(inplace=True)\n\t        return df.iloc[index[0]]\n\t    def find_files(\n\t        self, query=None, date_min=None, date_max=None, closest_to_date=None, **kwargs\n\t    ):\n", "        \"\"\"\n\t        Find files according to different criteria on metadata.\n\t        Parameters\n\t        ----------\n\t        query: str\n\t            Generic pandas.DataFrame.query() string\n\t        date_min:\n\t            Minimum date of a date range\n\t        date_max:\n\t            Maximum date of a date range\n", "        closest_to_date: datetime.datetime, pandas.Timestamp...\n\t            Find the file closest to a date.\n\t        kwargs: dict\n\t            Other parameters and their values\n\t        Return\n\t        ------\n\t        pandas.DataFrame\n\t            Matching files\n\t        Notes:\n\t        * Filtering is done by keyword exact match (LEVEL, SOOPNAME, MISOSTDU...),\n", "          then using the generic query string, then by date range, then by closest date.\n\t        * Keywords are converted to upper case (FITS keywords), so they can be passed as lowercase arguments\n\t        * Selects LEVEL=\"L2\" by default; if you want all levels, please specify LEVEL=None\n\t        * Date arguments are compared to DATE-BEG.\n\t        \"\"\"\n\t        if self.empty:\n\t            return self\n\t        if \"LEVEL\" not in [k.upper() for k in kwargs.keys()]:\n\t            kwargs[\"LEVEL\"] = \"L2\"\n\t        df = self.find_files_by_keywords(**kwargs)\n", "        if query is not None:\n\t            df = Catalog(data_frame=df.query(query))\n\t        df = df.find_files_by_date_range(date_min, date_max)\n\t        if closest_to_date is not None:\n\t            df = (\n\t                df.find_file_closest_to_date(closest_to_date, level=kwargs[\"LEVEL\"])\n\t                .to_frame()\n\t                .T\n\t            )\n\t        return df\n"]}
{"filename": "sospice/catalog/file_metadata.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom pathlib import Path\n\timport pandas as pd\n\tfrom astropy.utils.data import download_file\n\tfrom parfive import Downloader\n\tfrom .release import Release\n\trequired_columns = {\n\t    \"NAXIS1\",\n\t    \"NAXIS2\",\n\t    \"NAXIS3\",\n", "    \"NAXIS4\",\n\t    \"OBT_BEG\",\n\t    \"LEVEL\",\n\t    \"FILENAME\",\n\t    \"DATE-BEG\",\n\t    \"SPIOBSID\",\n\t    \"RASTERNO\",\n\t    \"STUDYTYP\",\n\t    \"MISOSTUD\",\n\t    \"XPOSURE\",\n", "    \"CRVAL1\",\n\t    \"CDELT1\",\n\t    \"CRVAL2\",\n\t    \"CDELT2\",\n\t    \"STP\",\n\t    \"DSUN_AU\",\n\t    \"CROTA\",\n\t    \"OBS_ID\",\n\t    \"SOOPNAME\",\n\t    \"SOOPTYPE\",\n", "    \"NWIN\",\n\t    \"DARKMAP\",\n\t    \"COMPLETE\",\n\t    \"SLIT_WID\",\n\t    \"DATE\",\n\t    \"PARENT\",\n\t    \"HGLT_OBS\",\n\t    \"HGLN_OBS\",\n\t    \"PRSTEP1\",\n\t    \"PRPROC1\",\n", "    \"PRPVER1\",\n\t    \"PRPARA1\",\n\t}\n\t@dataclass\n\tclass FileMetadata:\n\t    \"\"\"\n\t    A SPICE file entry in the SPICE catalog\n\t    Parameters\n\t    ----------\n\t    metadata: pandas.Series\n", "        File metadata\n\t    skip_validation: bool\n\t        Do no validate data\n\t    \"\"\"\n\t    metadata: pd.Series = None\n\t    skip_validation: bool = False\n\t    def __post_init__(self):\n\t        \"\"\"\n\t        Update object\n\t        \"\"\"\n", "        if not self.skip_validation:\n\t            self.validate()\n\t    def validate(self):\n\t        \"\"\"\n\t        Check file metadata\n\t        \"\"\"\n\t        assert self.metadata is not None\n\t        assert not self.metadata.empty\n\t        assert required_columns.issubset(self.metadata.keys())\n\t    def _get_file_url_from_base_url(self, base_url):\n", "        \"\"\"\n\t        Get URL for a file located under some base URL\n\t        Parameters\n\t        ----------\n\t        base_url: str\n\t            Base URL\n\t        Return\n\t        ------\n\t        str\n\t            File URL\n", "        Notes:\n\t        * There is no guarantee that the URL corresponds to an existing location\n\t        * The base URL can be a path on disk, but paths are built using \"/\"\n\t        and this might not work on all operating systems.\n\t        \"\"\"\n\t        if not base_url.endswith(\"/\"):\n\t            base_url += \"/\"\n\t        return base_url + self.metadata.FILE_PATH + \"/\" + self.metadata.FILENAME\n\t    def get_file_url(self, base_url=None, release=None):\n\t        \"\"\"\n", "        Get file URL, from a release, from some other online file tree, or from SOAR if no parameter has been provided\n\t        Parameters\n\t        ----------\n\t        base_url: str\n\t            Base URL for file\n\t        release: Release or str\n\t            Release to download file from. This can be a Release object, or a string for the release tag.\n\t        Return\n\t        ------\n\t        str\n", "            File URL\n\t        \"\"\"\n\t        if release is not None:\n\t            if type(release) is str:\n\t                release = Release(release)\n\t            url = self._get_file_url_from_base_url(release.url)\n\t        elif base_url is not None:\n\t            url = self._get_file_url_from_base_url(base_url)\n\t        else:\n\t            url = \"http://soar.esac.esa.int/soar-sl-tap/data\"\n", "            url += \"?retrieval_type=ALL_PRODUCTS\"\n\t            url += \"&QUERY=SELECT+filepath,filename+FROM+soar.v_sc_repository_file\"\n\t            url += f\"+WHERE+filename='{self.metadata.FILENAME}'\"\n\t        return url\n\t    def cache_file(self, base_url=None, release=None, update=False):\n\t        \"\"\"\n\t        Put file in local disk cache, from a release, from some other online\n\t        file tree, or from SOAR if no parameter has been provided\n\t        Parameters\n\t        ----------\n", "        base_url: str\n\t            Base URL for file\n\t        release: Release or str\n\t            Release to download file from\n\t        update: bool\n\t            Whether to update the cached file\n\t        Return\n\t        ------\n\t        Path\n\t            Cache file location\n", "        The cache is managed by `astropy.utils.data`.\n\t        \"\"\"\n\t        url = self.get_file_url(base_url=base_url, release=release)\n\t        cache = \"update\" if update else True\n\t        filename = download_file(url, cache=cache)\n\t        return Path(filename)\n\t    def download_file(\n\t        self, base_dir, base_url=None, release=None, keep_tree=True, downloader=None\n\t    ):\n\t        \"\"\"\n", "        Download file, from a release, from some other online file tree,\n\t        or from SOAR if no parameter has been provided\n\t        Parameters\n\t        ----------\n\t        base_dir: Path or str\n\t            Base directory to download file to\n\t        base_url: str\n\t            Base URL for file\n\t        release: Release or str\n\t            Release to download file from\n", "        keep_tree: bool\n\t            Keep tree directory structure (by level and date)\n\t        downloader: parfive.Downloader\n\t            If provided, enqueue file for download instead of downloading it.\n\t            To download enqueued files, run `downloader.download()`\n\t        Return\n\t        ------\n\t        parfive.Result\n\t            Download result (or None if file has only been enqueued)\n\t        \"\"\"\n", "        url = self.get_file_url(base_url=base_url, release=release)\n\t        if keep_tree:\n\t            destination = Path(base_dir) / self.metadata.FILE_PATH\n\t            destination.mkdir(parents=True, exist_ok=True)\n\t        else:\n\t            destination = Path(base_dir)\n\t        do_download = False\n\t        if downloader is None:\n\t            downloader = Downloader(overwrite=False)\n\t            do_download = True\n", "        downloader.enqueue_file(url, destination, self.metadata.FILENAME)\n\t        if do_download:\n\t            result = downloader.download()\n\t            return result\n\t        return None\n"]}
{"filename": "sospice/catalog/__init__.py", "chunked_list": ["from .release import Release\n\tfrom .catalog import Catalog\n\tfrom .file_metadata import FileMetadata\n"]}
{"filename": "sospice/catalog/release.py", "chunked_list": ["from dataclasses import dataclass\n\timport requests\n\t@dataclass\n\tclass Release:\n\t    tag: str = None\n\t    base_url: str = \"https://spice.osups.universite-paris-saclay.fr/spice-data/\"\n\t    _latest_tag: str = None\n\t    def __post_init__(self):\n\t        \"\"\"\n\t        Initialize object to latest release if no release tag set\n", "        \"\"\"\n\t        if self.tag is None:\n\t            self.tag = self.latest_tag\n\t    @property\n\t    def url(self):\n\t        \"\"\"\n\t        Return\n\t        ------\n\t        str\n\t            Release URL\n", "        \"\"\"\n\t        return f\"{self.base_url}release-{self.tag}/\"\n\t    @property\n\t    def catalog_url(self):\n\t        \"\"\"\n\t        Return\n\t        ------\n\t        str\n\t            Catalog URL for release\n\t        \"\"\"\n", "        return self.url + \"catalog.csv\"\n\t    @property\n\t    def latest_tag(self):\n\t        \"\"\"\n\t        Return\n\t        ------\n\t        str\n\t            Tag of latest release\n\t        \"\"\"\n\t        if self._latest_tag is None:\n", "            url = f\"{self.base_url}metadata/latest-release.txt\"\n\t            result = requests.get(url)\n\t            if not result.ok:\n\t                raise RuntimeError(\n\t                    \"Could not access URL for file with latest release tag\"\n\t                )\n\t            self._latest_tag = result.text.split(\"\\n\")[0]\n\t        return self._latest_tag\n\t    @property\n\t    def is_latest(self):\n", "        \"\"\"\n\t        Return\n\t        ------\n\t        bool\n\t            True is object corresponds to latest release\n\t        \"\"\"\n\t        return self.tag == self.latest_tag\n\t    @property\n\t    def exists(self):\n\t        \"\"\"\n", "        Return\n\t        ------\n\t        bool\n\t            True if release exists (is accessible online)\n\t        \"\"\"\n\t        result = requests.get(self.url)\n\t        return result.ok\n\tdef get_latest_release_tag():\n\t    \"\"\"\n\t    Return\n", "    ------\n\t    str\n\t        Latest available release tag\n\t    \"\"\"\n\t    release = Release()\n\t    return release.latest_tag\n"]}
{"filename": "sospice/catalog/tests/test_file_metadata.py", "chunked_list": ["import pytest\n\tfrom pathlib import Path\n\timport pandas as pd\n\tfrom parfive import Downloader\n\timport shutil\n\tfrom ..file_metadata import FileMetadata\n\tfrom .test_catalog import catalog2  # noqa: F401\n\tfrom .test_release import release2  # noqa: F401\n\t@pytest.fixture\n\tdef filename():  # noqa: F811\n", "    return \"solo_L2_spice-n-exp_20220305T072522_V01_100663707-014.fits\"\n\t@pytest.fixture\n\tdef file_metadata(catalog2, filename):  # noqa: F811\n\t    metadata = catalog2[catalog2.FILENAME == filename].iloc[0]\n\t    return FileMetadata(metadata)\n\tclass TestFileMetadata:\n\t    def test_get_file_url(self, file_metadata, release2, filename):  # noqa: F811\n\t        expected = \"https://foobar/level2/2022/03/05/\" + filename\n\t        assert file_metadata.get_file_url(base_url=\"https://foobar/\") == expected\n\t        assert file_metadata.get_file_url(base_url=\"https://foobar\") == expected\n", "        expected = (\n\t            \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-2.0/level2/2022/03/05/\"\n\t            + filename  # noqa: W503\n\t        )\n\t        assert file_metadata.get_file_url(release=release2) == expected\n\t        assert file_metadata.get_file_url(release=\"2.0\") == expected\n\t        expected = \"http://soar.esac.esa.int/soar-sl-tap/data?retrieval_type=ALL_PRODUCTS&QUERY=\"\n\t        expected += f\"SELECT+filepath,filename+FROM+soar.v_sc_repository_file+WHERE+filename='{filename}'\"\n\t        assert file_metadata.get_file_url() == expected\n\t    def test_cache_file(self, file_metadata, release2):  # noqa: F811\n", "        file_path = file_metadata.cache_file(release=release2)\n\t        assert file_path.exists()\n\t        now = pd.Timestamp(\"now\", tz=\"UTC\")\n\t        file_path = file_metadata.cache_file(release=release2, update=True)\n\t        assert file_path.exists()\n\t        mtime = pd.Timestamp(file_path.stat().st_mtime, unit=\"s\", tz=\"UTC\")\n\t        assert pd.Timestamp(mtime) >= now\n\t    def test_download_file(self, file_metadata, release2, filename):  # noqa: F811\n\t        base_dir = Path(\"./local/test_download_file\")\n\t        if base_dir.exists():\n", "            shutil.rmtree(base_dir)\n\t        result = file_metadata.download_file(\n\t            base_dir, release=release2, keep_tree=False\n\t        )\n\t        assert len(result) == 1\n\t        assert result[0] == (base_dir / filename).as_posix()\n\t        result = file_metadata.download_file(base_dir, release=release2)\n\t        expected = (base_dir / file_metadata.metadata.FILE_PATH / filename).as_posix()\n\t        assert len(result) == 1\n\t        assert result[0] == expected\n", "        downloader = Downloader(overwrite=False)\n\t        result = file_metadata.download_file(  # noqa: F841\n\t            base_dir, release=release2, downloader=downloader\n\t        )\n\t        assert result is None\n\t        assert downloader.queued_downloads == 1\n"]}
{"filename": "sospice/catalog/tests/test_catalog.py", "chunked_list": ["import pytest\n\tfrom datetime import datetime\n\timport pandas as pd\n\tfrom ..catalog import Catalog\n\t@pytest.fixture\n\tdef catalog2():\n\t    return Catalog(release_tag=\"2.0\")\n\t@pytest.fixture\n\tdef catalog_latest():\n\t    return Catalog(release_tag=\"latest\")\n", "@pytest.fixture\n\tdef catalog_empty():\n\t    return Catalog()\n\t@pytest.fixture\n\tdef catalog_df():\n\t    df = pd.DataFrame(\n\t        {\n\t            \"NAXIS1\": [12, 15, 20],\n\t            \"NAXIS2\": [100, 101, 102],\n\t            \"NAXIS3\": [41, 44, 47],\n", "            \"NAXIS4\": [1, 1, 1],\n\t            \"OBT_BEG\": [0, 0, 0],\n\t            \"LEVEL\": [\"L2\", 0, 0],\n\t            \"FILENAME\": [0, 0, 0],\n\t            \"DATE-BEG\": [pd.Timestamp(\"2023-02-01T12:34\"), 0, 0],\n\t            \"SPIOBSID\": [0, 0, 0],\n\t            \"RASTERNO\": [0, 0, 0],\n\t            \"STUDYTYP\": [0, 0, 0],\n\t            \"MISOSTUD\": [0, 0, 0],\n\t            \"XPOSURE\": [0, 0, 0],\n", "            \"CRVAL1\": [0, 0, 0],\n\t            \"CDELT1\": [0, 0, 0],\n\t            \"CRVAL2\": [0, 0, 0],\n\t            \"CDELT2\": [0, 0, 0],\n\t            \"STP\": [0, 0, 0],\n\t            \"DSUN_AU\": [0, 0, 0],\n\t            \"CROTA\": [0, 0, 0],\n\t            \"OBS_ID\": [0, 0, 0],\n\t            \"SOOPNAME\": [0, 0, 0],\n\t            \"SOOPTYPE\": [0, 0, 0],\n", "            \"NWIN\": [0, 0, 0],\n\t            \"DARKMAP\": [0, 0, 0],\n\t            \"COMPLETE\": [0, 0, 0],\n\t            \"SLIT_WID\": [0, 0, 0],\n\t            \"DATE\": [0, 0, 0],\n\t            \"PARENT\": [0, 0, 0],\n\t            \"HGLT_OBS\": [0, 0, 0],\n\t            \"HGLN_OBS\": [0, 0, 0],\n\t            \"PRSTEP1\": [0, 0, 0],\n\t            \"PRPROC1\": [0, 0, 0],\n", "            \"PRPVER1\": [0, 0, 0],\n\t            \"PRPARA1\": [0, 0, 0],\n\t            \"proc_steps\": [\n\t                '[{\"PRPROC\": \"JPEG Compression (On-board)\"},'\n\t                ' {\"PRPROC\": \"spice_prep_dark_offset_correction.pro\",'\n\t                ' \"PRPVER\": \"1.3\", \"PRPARA\": \"dark_spiobsid=117440828\"}]',\n\t                0,\n\t                0,\n\t            ],\n\t        }\n", "    )\n\t    return Catalog(data_frame=df)\n\tclass TestCatalog:\n\t    def test_init_filename(self):\n\t        filename = \"wepocmwkx.fts\"\n\t        with pytest.raises(RuntimeError, match=\"does not exist\"):\n\t            catalog = Catalog(filename)  # noqa: F841\n\t    def test_init_release(self, catalog2, catalog_latest):\n\t        columns = {\n\t            \"NAXIS1\",\n", "            \"NAXIS2\",\n\t            \"NAXIS3\",\n\t            \"NAXIS4\",\n\t            \"OBT_BEG\",\n\t            \"LEVEL\",\n\t        }\n\t        assert columns.issubset(catalog2.columns)\n\t        assert len(catalog2) > 10000\n\t        assert columns.issubset(catalog_latest.columns)\n\t        assert len(catalog_latest) > 10000\n", "        assert catalog_latest._cache_release_catalog() is None\n\t    def test_init_empty(self, catalog_empty):\n\t        assert len(catalog_empty) == 0\n\t        assert len(catalog_empty.columns) == 0\n\t    def test_init_dataframe(self, catalog_df):\n\t        assert len(catalog_df) == 3\n\t        assert len(catalog_df.columns) == 36\n\t        assert catalog_df.iloc[1].NAXIS2 == 101\n\t    def test_find_files_by_keywords(self, catalog2):\n\t        result = catalog2.find_files_by_keywords()\n", "        assert len(result) == 15643\n\t        result = catalog2.find_files_by_keywords(level=None)\n\t        assert len(result) == 15643\n\t        result = catalog2.find_files_by_keywords(level=\"L2\")\n\t        assert len(result) == 7756\n\t        result = catalog2.find_files_by_keywords(level=\"L2\", nbin3=2)\n\t        assert len(result) == 201\n\t    def test_find_files_by_date_range(self, catalog2):\n\t        result = Catalog().find_files_by_date_range()\n\t        assert result.empty\n", "        result = catalog2.find_files_by_date_range()\n\t        assert len(result) == 15643\n\t        result = catalog2.find_files_by_date_range(date_min=\"2022-01-01\")\n\t        assert len(result) == 14039\n\t        assert result[\"DATE-BEG\"].min() > pd.Timestamp(\"2022-01-01\")\n\t        result = catalog2.find_files_by_date_range(\n\t            date_min=\"2022-01-01\", date_max=\"2022-03-01\"\n\t        )\n\t        assert len(result) == 1711\n\t        assert result[\"DATE-BEG\"].max() < pd.Timestamp(\"2022-03-01\")\n", "    def test_find_file_closest_to_date(self, catalog2):\n\t        expected_filename = \"solo_L2_spice-n-exp_20211204T120022_V02_83886365-000.fits\"\n\t        result = catalog2.find_file_closest_to_date(pd.Timestamp(\"2021-10-10\"))\n\t        assert result.FILENAME == expected_filename\n\t        result = catalog2.find_file_closest_to_date(datetime(2021, 10, 10))\n\t        assert result.FILENAME == expected_filename\n\t        result = catalog2.find_file_closest_to_date(\"2021-10-10\")\n\t        assert result.FILENAME == expected_filename\n\t        result = catalog2.find_file_closest_to_date(None)\n\t        assert result.empty\n", "    def test_find_files(self, catalog2):\n\t        result = Catalog().find_files()\n\t        assert result.empty\n\t        result = catalog2.find_files()\n\t        assert len(result) == 7756\n\t        result = catalog2.find_files(level=None)\n\t        assert len(result) == 15643\n\t        result = catalog2.find_files(query=\"NBIN3==2\")\n\t        assert len(result) == 201\n\t        expected_filename = \"solo_L2_spice-n-exp_20211204T120022_V02_83886365-000.fits\"\n", "        result = catalog2.find_files(closest_to_date=\"2021-10-10\")\n\t        assert len(result) == 1\n\t        assert result.iloc[0].FILENAME == expected_filename\n"]}
{"filename": "sospice/catalog/tests/__init__.py", "chunked_list": []}
{"filename": "sospice/catalog/tests/test_release.py", "chunked_list": ["import pytest\n\tfrom ..release import Release, get_latest_release_tag\n\t@pytest.fixture\n\tdef release2():\n\t    return Release(\"2.0\")\n\tclass TestRelease:\n\t    def test_init(self, release2):\n\t        assert release2.tag == \"2.0\"\n\t        assert release2.base_url.startswith(\n\t            \"https://spice.osups.universite-paris-saclay.fr\"\n", "        )\n\t        assert release2.url.endswith(\"2.0/\")\n\t        assert release2.catalog_url.endswith(\"/catalog.csv\")\n\t        assert release2.exists  # online access\n\t        assert not release2.is_latest  # online access\n\t    def test_latest(self):  # online access\n\t        release = Release()\n\t        assert release.tag != \"2.0\"\n\t        assert release.base_url.startswith(\n\t            \"https://spice.osups.universite-paris-saclay.fr\"\n", "        )\n\t        assert release.catalog_url.endswith(\"/catalog.csv\")\n\t        assert release.exists\n\t        assert release.is_latest\n\t    def test_get_latest(self):\n\t        assert get_latest_release_tag() != \"2.0\"\n"]}
{"filename": "sospice/instrument_modelling/study.py", "chunked_list": ["from dataclasses import dataclass\n\timport astropy.units as u\n\t@dataclass\n\tclass Study:\n\t    \"\"\"\n\t    Study parameters\n\t    \"\"\"\n\t    slit: u.arcsec = None\n\t    bin_x: int = None  # bin over x or wavelength axis\n\t    bin_y: int = None\n", "    window_width: u.pix = None\n\t    exp_time: u.s = None\n\t    av_wavelength: u.m = None\n\t    radcal: u.ct / (u.W / u.m**2 / u.sr / u.nm) = None\n\t    level: str = None\n\t    def init_from_header(self, header):\n\t        \"\"\"\n\t        Initialize study parameters from FITS header\n\t        Parameters\n\t        ----------\n", "        header: astropy.io.fits.Header\n\t            FITS header\n\t        \"\"\"\n\t        # TODO use real slit width, not nominal slit width\n\t        self.slit = header[\"SLIT_WID\"] * u.arcsec\n\t        self.bin_x = header[\"NBIN3\"]  # bin factor in dispersion direction\n\t        self.bin_y = header[\"NBIN2\"]  # bin factor in slit direction\n\t        self.exp_time = header[\"XPOSURE\"] * u.s\n\t        self.window_width = header[\"NAXIS3\"] * u.pix\n\t        self.av_wavelength = (\n", "            (header[\"WAVEMIN\"] + header[\"WAVEMAX\"]) / 2 * 10 ** header[\"WAVEUNIT\"] * u.m\n\t        )\n\t        self.level = header[\"LEVEL\"]\n\t        if self.level == \"L2\":\n\t            self.radcal = header[\"RADCAL\"] * u.ct / (u.W / u.m**2 / u.sr / u.nm)\n\t        else:\n\t            self.radcal = None  # TODO or need to have a value of 1?\n\t    def __str__(self):\n\t        if self.slit is None:\n\t            return \"Non-initialized study\"\n", "        else:\n\t            return f\"\"\"\n\tSlit: {self.slit}\n\tBin: ({self.bin_x}, {self.bin_y})\n\tExposure time: {self.exp_time}\n\tWindow width: {self.window_width}\n\tAverage wavelength: {self.av_wavelength.to(u.nm)}\n\tRADCAL: {self.radcal}\n\t            \"\"\"\n"]}
{"filename": "sospice/instrument_modelling/__init__.py", "chunked_list": ["from .spice import Spice\n\tfrom .study import Study\n\tfrom .observation import Observation\n"]}
{"filename": "sospice/instrument_modelling/observation.py", "chunked_list": ["from dataclasses import dataclass\n\timport numpy as np\n\timport astropy.units as u\n\tfrom .spice import Spice\n\tfrom .study import Study\n\tfrom ..util import rss\n\t@dataclass\n\tclass Observation:\n\t    instrument: Spice()\n\t    study: Study()\n", "    @classmethod\n\t    def observation_from_spice_hdu(cls, hdu, verbose=True):\n\t        \"\"\"\n\t        Generate an Observation object from a SPICE L2 file HDU\n\t        \"\"\"\n\t        study = Study()\n\t        study.init_from_header(hdu.header)\n\t        if verbose:\n\t            print(f\"Getting observation parameters from {hdu.name}\")\n\t            print(study)\n", "        instrument = Spice()\n\t        observation = Observation(instrument, study)\n\t        return observation\n\t    @u.quantity_input\n\t    def av_dark_current(self, wvl: u.Angstrom = None):\n\t        \"\"\"\n\t        Average dark current in DN per macro-pixel over exposure time\n\t        Parameters\n\t        ----------\n\t        wvl: Quantity\n", "            Wavelength (or array of wavelengths)\n\t        Return\n\t        ------\n\t        float\n\t            Average dark current\n\t        TODO:\n\t        * Should depend on detector temperature.\n\t        * Actually non-Poissonian (need to look at real darks).\n\t        * Would depend on position (dark or hot pixels) in L1\n\t        \"\"\"\n", "        if wvl is None:\n\t            wvl = self.study.av_wavelength\n\t        return (\n\t            self.instrument.dark_current(wvl)\n\t            * self.study.exp_time  # noqa: W503\n\t            * self.study.bin_x  # noqa: W503\n\t            * self.study.bin_y  # noqa: W503\n\t        ).to(u.ct / u.pix)\n\t    @u.quantity_input\n\t    def av_background(self, wvl: u.Angstrom = None):\n", "        \"\"\"\n\t        Average background signal in DN per macro-pixel over exposure time\n\t        Parameters\n\t        ----------\n\t        wvl: Quantity\n\t            Wavelength (or array of wavelengths)\n\t        Return\n\t        ------\n\t        float\n\t            Average background\n", "        \"\"\"\n\t        if wvl is None:\n\t            wvl = self.study.av_wavelength\n\t        return (\n\t            self.instrument.background\n\t            * self.instrument.quantum_efficiency(wvl)  # noqa: W503\n\t            * self.study.exp_time  # noqa: W503\n\t            * self.study.bin_x  # noqa: W503\n\t            * self.study.bin_y  # noqa: W503\n\t            * self.instrument.gain(wvl)  # noqa: W503\n", "        ).to(u.ct / u.pix)\n\t    @property\n\t    def read_noise_width(self):\n\t        \"\"\"\n\t        Read noise distribution width in DN per macro-pixel\n\t        TODO make sure that this is a standard deviation and not a FWHM\n\t        \"\"\"\n\t        return self.instrument.read_noise * np.sqrt(self.study.bin_x * self.study.bin_y)\n\t    @u.quantity_input\n\t    def noise_effects(self, signal_mean: u.ct / u.pix, wvl: u.Angstrom = None):\n", "        \"\"\"\n\t        Return total (measured) signal increase and standard deviation due to noises\n\t        Parameters\n\t        ----------\n\t        signal_mean: Quantity\n\t            Measured signal mean, in DN/pix, excluding expected signal increase\n\t            due to average dark current and background (so this is not exactly\n\t            the measured signal).\n\t        wvl: Quantity\n\t            Wavelength (or array of wavelengths)\n", "        Return\n\t        ------\n\t        float:\n\t            Average contribution of noise to measured signal\n\t        dict:\n\t            Noise standard deviations for the different components (and total\n\t            uncertainty resulting from them)\n\t        Negative values of the signal are considered to be 0 for the purpose of\n\t        computing the noise on the signal. However, the total uncertainty is\n\t        then set to |signal_mean| + RSS (other noises), to ensure that the\n", "        error bars are still compatible with expected fitted functions.\n\t        We suggest users to replace large negative values of the signal\n\t        (e.g. < -3 * RSS(other noises)) by NaNs.\n\t        \"\"\"\n\t        if wvl is None:\n\t            wvl = self.study.av_wavelength\n\t        av_dark_current = self.av_dark_current()\n\t        av_background = self.av_background()\n\t        av_constant_noise_level = av_dark_current + av_background\n\t        sigma = dict()\n", "        gain = self.instrument.gain(wvl)\n\t        sigma[\"Dark\"] = np.sqrt(av_dark_current.value) * u.ct / u.pix\n\t        sigma[\"Background\"] = np.sqrt(av_background * gain).value * u.ct / u.pix\n\t        sigma[\"Read\"] = self.read_noise_width\n\t        signal_mean_nonneg = np.maximum(signal_mean, 0)\n\t        sigma[\"Signal\"] = np.sqrt(signal_mean_nonneg * gain).value * u.ct / u.pix\n\t        sigma[\"Signal\"] *= self.instrument.noise_factor(wvl)\n\t        constant_noises = rss(\n\t            np.array(\n\t                [sigma[\"Dark\"].value, sigma[\"Background\"].value, sigma[\"Read\"].value]\n", "            )\n\t        )\n\t        sigma[\"Total\"] = (\n\t            rss(\n\t                np.array(\n\t                    [\n\t                        constant_noises * np.ones_like(signal_mean.value),\n\t                        sigma[\"Signal\"].value,\n\t                    ]\n\t                ),\n", "                axis=0,\n\t            )  # noqa: W503\n\t            * sigma[\"Signal\"].unit  # noqa: W503\n\t        )\n\t        where_neg = signal_mean < 0\n\t        sigma[\"Total\"][where_neg] = (\n\t            -signal_mean[where_neg] + constant_noises * signal_mean.unit\n\t        )\n\t        return av_constant_noise_level, sigma\n\t    @u.quantity_input\n", "    def noise_effects_from_l2(\n\t        self, data: u.W / u.m**2 / u.sr / u.nm, wvl: u.Angstrom\n\t    ):\n\t        \"\"\"\n\t        Return total (measured) signal increase and standard deviation due to noises\n\t        Parameters\n\t        ----------\n\t        data: Quantity\n\t            L2 data, in W / m2 / sr / nm\n\t        wvl: Quantity\n", "            Wavelength\n\t        Return\n\t        ------\n\t        float:\n\t            Average contribution of noise to measured signal\n\t        dict:\n\t            Noise standard deviations for the different components (and total)\n\t        \"\"\"\n\t        data_dn = data * self.study.radcal / u.pix\n\t        av_constant_noise_level, sigma = self.noise_effects(data_dn, wvl)\n", "        av_constant_noise_level /= self.study.radcal / u.pix\n\t        for component in sigma:\n\t            sigma[component] /= self.study.radcal / u.pix\n\t        return av_constant_noise_level, sigma\n"]}
{"filename": "sospice/instrument_modelling/spice.py", "chunked_list": ["from dataclasses import dataclass\n\tfrom pathlib import Path\n\timport numpy as np\n\tfrom scipy.io import readsav\n\timport astropy.units as u\n\t@dataclass\n\tclass Spice:\n\t    # These values (Huang et al. 2023, doi:10.1051/0004-6361/202345988)\n\t    # are supposed to be the latest values presented by RAL.\n\t    # `astropy.units.ct` (counts) is used for DNs\n", "    read_noise = 6.9 * u.ct / u.pix\n\t    background = 0.0 * u.ph / u.s / u.pix  # 1.0 in SPICE-RAL-RP-0002\n\t    pix_x = 1.0 * u.arcsec / u.pix  # not used\n\t    pix_y = 1.0 * u.arcsec / u.pix  # not used except for PSF\n\t    pix_w = 0.0095 * u.nm / u.pix  # not used except for PSF\n\t    aeff_data = None  # Will be read from file when needed\n\t    @u.quantity_input\n\t    def effective_area(self, wvl: u.nm):\n\t        \"\"\"\n\t        Get the SPICE effective area for some wavelength\n", "        Parameters\n\t        ----------\n\t        wvl: Quantity\n\t            Wavelength (or array of wavelengths)\n\t        Return\n\t        ------\n\t        Quantity:\n\t            Effective area(s)\n\t        \"\"\"\n\t        wvl = wvl.to(u.nm).value\n", "        if self.aeff_data is None:\n\t            code_path = (Path(__file__) / \"..\" / \"..\").resolve()\n\t            aeff_file = code_path / \"data\" / \"calibration\" / \"effective_area.sav\"\n\t            self.aeff_data = readsav(aeff_file.as_posix())\n\t        # try interpolating for both second (1) and first (2) order\n\t        left_right = {\"left\": np.nan, \"right\": np.nan}\n\t        aeff1 = np.interp(\n\t            wvl, self.aeff_data[\"lam_1\"], self.aeff_data[\"net_resp_1\"], **left_right\n\t        )\n\t        aeff2 = np.interp(\n", "            wvl, self.aeff_data[\"lam_2\"], self.aeff_data[\"net_resp_2\"], **left_right\n\t        )\n\t        # choose where interpolation was done for the correct order\n\t        return np.where(np.isfinite(aeff2), aeff2, aeff1) * u.mm**2\n\t    @u.quantity_input\n\t    def quantum_efficiency(self, wvl: u.Angstrom):\n\t        \"\"\"\n\t        Get the SPICE detector quantum efficiency for some wavelength\n\t        Parameters\n\t        ----------\n", "        wvl: Quantity\n\t            Wavelength (or array of wavelengths)\n\t        Return\n\t        ------\n\t        Quantity:\n\t            Quantum efficiency(ies): number of detected photons / number of\n\t            incident photons\n\t        Not sure about the values for LW 2nd order, and on what wavelength\n\t        ranges the output should be NaN.\n\t        \"\"\"\n", "        wvl = wvl.to(u.Angstrom).value\n\t        # Source: Table 8.25 of SPICE-RAL-RP-0002 v10.0\n\t        qe_sw = np.interp(\n\t            wvl,\n\t            [703, 706, 770, 790],  # angstrom\n\t            [0.12, 0.12, 0.1, 0.1],  # electron/photon\n\t            left=np.nan,\n\t            right=np.nan,\n\t        )\n\t        qe_lw = 0.25  # electron/photon\n", "        return np.where((wvl > 703) & (wvl < 791), qe_sw, qe_lw)\n\t    @u.quantity_input\n\t    def which_detector(self, wvl: u.Angstrom):\n\t        \"\"\"\n\t        Determine which detector corresponds to some wavelength\n\t        Parameters\n\t        ----------\n\t        wvl: Quantity\n\t            Wavelength\n\t        Return\n", "        ------\n\t        str\n\t            Detector name (None if not on a detector)\n\t        \"\"\"\n\t        wvl = wvl.to(u.Angstrom).value\n\t        if 703 < wvl < 791:\n\t            return \"SW\"\n\t        elif 970 < wvl < 1053:\n\t            return \"LW\"\n\t        else:\n", "            return None\n\t    @u.quantity_input\n\t    def gain(self, wvl: u.Angstrom):\n\t        \"\"\"\n\t        Detector gain as a function of wavelength\n\t        Parameters\n\t        ----------\n\t        wvl: Quantity\n\t            Wavelength\n\t        Return\n", "        ------\n\t        float\n\t            Detector gain\n\t        \"\"\"\n\t        detector = self.which_detector(wvl)\n\t        if detector is None:\n\t            return np.nan * u.ct / u.ph\n\t        else:\n\t            return {\"SW\": 3.58, \"LW\": 0.57}[detector] * u.ct / u.ph\n\t    @u.quantity_input\n", "    def dark_current(self, wvl: u.Angstrom):\n\t        \"\"\"\n\t        Detector dark current as a function of wavelength\n\t        Parameters\n\t        ----------\n\t        wvl: Quantity\n\t            Wavelength\n\t        Return\n\t        ------\n\t        float\n", "            Detector dark current\n\t        \"\"\"\n\t        detector = self.which_detector(wvl)\n\t        if detector is None:\n\t            return np.nan * u.ct / u.s / u.pix\n\t        else:\n\t            return {\"SW\": 0.89, \"LW\": 0.54}[detector] * u.ct / u.s / u.pix\n\t    @u.quantity_input\n\t    def noise_factor(self, wvl: u.Angstrom):\n\t        \"\"\"\n", "        Detector noise multiplication factor as a function of wavelength\n\t        Parameters\n\t        ----------\n\t        wvl: Quantity\n\t            Wavelength\n\t        Return\n\t        ------\n\t        float\n\t            Noise multiplication factor\n\t        \"\"\"\n", "        detector = self.which_detector(wvl)\n\t        if detector is None:\n\t            return np.nan\n\t        else:\n\t            return {\"SW\": 1.0, \"LW\": 1.6}[detector]\n"]}
{"filename": "sospice/instrument_modelling/tests/test_study.py", "chunked_list": ["import pytest\n\timport astropy.units as u\n\tfrom ..study import Study\n\t@pytest.fixture\n\tdef empty_study():\n\t    return Study()\n\t@pytest.fixture\n\tdef header():\n\t    return {\n\t        \"SLIT_WID\": 4.0,\n", "        \"NBIN3\": 1,\n\t        \"NBIN2\": 2,\n\t        \"XPOSURE\": 10.0,\n\t        \"NAXIS3\": 48,\n\t        \"WAVEMIN\": 769,\n\t        \"WAVEMAX\": 771,\n\t        \"WAVEUNIT\": -10,\n\t        \"LEVEL\": \"L2\",\n\t        \"RADCAL\": 1000.0,\n\t    }\n", "@pytest.fixture\n\tdef study(header):\n\t    s = Study()\n\t    s.init_from_header(header)\n\t    return s\n\tclass TestStudy:\n\t    def test_init(self, empty_study):\n\t        attributes = [\n\t            \"slit\",\n\t            \"bin_x\",\n", "            \"bin_y\",\n\t            \"window_width\",\n\t            \"exp_time\",\n\t            \"av_wavelength\",\n\t            \"radcal\",\n\t        ]\n\t        for attribute in attributes:\n\t            assert getattr(empty_study, attribute) is None\n\t    def test_init_from_header(self, study):\n\t        expected_values = {\n", "            \"slit\": 4 * u.arcsec,\n\t            \"bin_x\": 1,\n\t            \"bin_y\": 2,\n\t            \"window_width\": 48 * u.pix,\n\t            \"exp_time\": 10 * u.s,\n\t            \"av_wavelength\": 77 * u.nm,\n\t            \"radcal\": 1000 * u.ct * u.m**2 * u.nm * u.sr / u.W,\n\t        }\n\t        for attribute in expected_values:\n\t            assert u.isclose(getattr(study, attribute), expected_values[attribute])\n", "    def test___str__(self, empty_study, study):\n\t        assert str(empty_study) == \"Non-initialized study\"\n\t        assert type(str(study)) is str\n"]}
{"filename": "sospice/instrument_modelling/tests/test_observation.py", "chunked_list": ["import pytest\n\tfrom astropy.io import fits\n\timport astropy.units as u\n\tfrom ..spice import Spice\n\tfrom ..study import Study\n\tfrom ..observation import Observation\n\t@pytest.fixture\n\tdef header():\n\t    return {\n\t        \"SLIT_WID\": 4.0,\n", "        \"NBIN3\": 1,\n\t        \"NBIN2\": 2,\n\t        \"XPOSURE\": 10.0,\n\t        \"NAXIS3\": 48,\n\t        \"WAVEMIN\": 769,\n\t        \"WAVEMAX\": 771,\n\t        \"WAVEUNIT\": -10,\n\t        \"LEVEL\": \"L2\",\n\t        \"RADCAL\": 1000.0,\n\t    }\n", "@pytest.fixture\n\tdef hdu():\n\t    url = \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-3.0/level2/2022/04/02/solo_L2_spice-n-ras_20220402T111537_V06_100664002-000.fits\"\n\t    # with fits.open(url) as hdu_list:\n\t    hdu_list = fits.open(url)\n\t    hdu = hdu_list[2]  # Ne VIII window\n\t    yield hdu\n\t    hdu_list.close()\n\t@pytest.fixture\n\tdef observation(header):\n", "    instrument = Spice()\n\t    study = Study()\n\t    study.init_from_header(header)\n\t    return Observation(instrument, study)\n\tclass TestObservation:\n\t    def test_observation_from_spice_hdu(self, hdu):\n\t        observation = Observation.observation_from_spice_hdu(hdu)\n\t        assert type(observation.instrument) is Spice\n\t        assert type(observation.study) is Study\n\t    def test_av_dark_current(self, observation):\n", "        # Expected values in DN/ph for wavelengths in nm\n\t        expected = {\n\t            77: 17.8,\n\t            102.5: 10.8,\n\t        }\n\t        for wavelength in expected:\n\t            assert u.isclose(\n\t                observation.av_dark_current(wavelength * u.nm),\n\t                expected[wavelength] * u.ct / u.pix,\n\t            )\n", "    def test_av_background(self, observation):\n\t        # Expected values in DN/ph for wavelengths in nm\n\t        expected = {\n\t            77: 0,\n\t            102.5: 0,\n\t        }\n\t        for wavelength in expected:\n\t            assert u.isclose(\n\t                observation.av_background(wavelength * u.nm),\n\t                expected[wavelength] * u.ct / u.pix,\n", "            )\n\t    def test_read_noise_width(self, observation):\n\t        assert u.isclose(observation.read_noise_width, 9.75807358 * u.ct / u.pix)\n\t    def test_noise_effects_from_l2(self, observation):\n\t        specrad_unit = u.mW / u.m**2 / u.sr / u.nm\n\t        av_constant_noise_level, sigma = observation.noise_effects_from_l2(\n\t            0.1 * specrad_unit, 77 * u.nm\n\t        )\n\t        assert u.isclose(av_constant_noise_level, 17.8 * specrad_unit)\n\t        expected = {\n", "            \"Dark\": 4.219004621945797,\n\t            \"Background\": 0.0,\n\t            \"Read\": 9.758073580374356,\n\t            \"Signal\": 18.920887928424502,\n\t            \"Total\": 21.702995184996933,\n\t        }\n\t        for component in expected:\n\t            assert u.isclose(sigma[component], expected[component] * specrad_unit)\n"]}
{"filename": "sospice/instrument_modelling/tests/__init__.py", "chunked_list": []}
{"filename": "sospice/instrument_modelling/tests/test_spice.py", "chunked_list": ["import pytest\n\timport numpy as np\n\timport astropy.units as u\n\tfrom ..spice import Spice\n\t@pytest.fixture\n\tdef spice():\n\t    return Spice()\n\tclass TestSpice:\n\t    def test_init(self, spice):\n\t        assert spice.read_noise == 6.9 * u.ct / u.pix\n", "        assert spice.aeff_data is None\n\t    def test_effective_area(self, spice):\n\t        # Expected values in mm² for wavelengths in nm\n\t        expected = {\n\t            20: np.nan,\n\t            77: 4.33579493,  # Ne VIII (SW)\n\t            102.6: 9.57706423,  # H Lyβ (LW)\n\t            52.1: 0.43514445,  # Si XII (LW, 2nd order)\n\t            200: np.nan,\n\t        }\n", "        for wavelength in expected:\n\t            assert u.isclose(\n\t                spice.effective_area(wavelength * u.nm),\n\t                expected[wavelength] * u.mm**2,\n\t                equal_nan=True,\n\t            )\n\t        assert u.allclose(\n\t            spice.effective_area([50, 80, 100] * u.nm),\n\t            [0.28686351, 5.50425673, 9.21953583] * u.mm**2,\n\t        )\n", "        assert spice.aeff_data is not None\n\t    def test_quantum_efficiency(self, spice):\n\t        # Expected values for wavelengths in nm\n\t        # Not sure about the value for 2nd order LW\n\t        expected = {\n\t            77: 0.1,\n\t            102.6: 0.25,\n\t        }\n\t        for wavelength in expected:\n\t            assert u.isclose(\n", "                spice.quantum_efficiency(wavelength * u.nm), expected[wavelength]\n\t            )\n\t    def test_which_detector(self, spice):\n\t        # Expected values for wavelengths in nm\n\t        expected = {\n\t            77: \"SW\",\n\t            102.6: \"LW\",\n\t        }\n\t        for wavelength in expected:\n\t            assert spice.which_detector(wavelength * u.nm) == expected[wavelength]\n", "        # Expected None values\n\t        expected_none = [70, 85, 106]\n\t        for wavelength in expected_none:\n\t            assert spice.which_detector(wavelength * u.nm) is None\n\t    def test_gain(self, spice):\n\t        # Expected values in DN/ph for wavelengths in nm\n\t        expected = {\n\t            20: np.nan,\n\t            77: 3.58,\n\t            102.6: 0.57,\n", "            200: np.nan,\n\t        }\n\t        for wavelength in expected:\n\t            assert u.isclose(\n\t                spice.gain(wavelength * u.nm),\n\t                expected[wavelength] * u.ct / u.ph,\n\t                equal_nan=True,\n\t            )\n\t    def test_dark_current(self, spice):\n\t        # Expected values in DN/s/pix for wavelengths in nm\n", "        expected = {\n\t            20: np.nan,\n\t            77: 0.89,\n\t            102.6: 0.54,\n\t            200: np.nan,\n\t        }\n\t        for wavelength in expected:\n\t            assert u.isclose(\n\t                spice.dark_current(wavelength * u.nm),\n\t                expected[wavelength] * u.ct / u.s / u.pix,\n", "                equal_nan=True,\n\t            )\n\t    def test_noise_factor(self, spice):\n\t        # Expected values in DN/s/pix for wavelengths in nm\n\t        expected = {\n\t            20: np.nan,\n\t            77: 1.0,\n\t            102.6: 1.6,\n\t            200: np.nan,\n\t        }\n", "        for wavelength in expected:\n\t            assert u.isclose(\n\t                spice.noise_factor(wavelength * u.nm),\n\t                expected[wavelength],\n\t                equal_nan=True,\n\t            )\n"]}
{"filename": "sospice/psf/__init__.py", "chunked_list": []}
{"filename": "sospice/psf/tests/__init__.py", "chunked_list": []}
{"filename": "sospice/calibrate/__init__.py", "chunked_list": ["from .uncertainties import spice_error\n"]}
{"filename": "sospice/calibrate/uncertainties.py", "chunked_list": ["import astropy.units as u\n\tfrom ..instrument_modelling import Spice, Study, Observation\n\tdef spice_error(hdu=None, data=None, header=None, verbose=True):\n\t    \"\"\"\n\t    Return total (measured) signal increase and standard deviation due to noises\n\t    Parameters\n\t    ----------\n\t    hdu: astropy.io.fits.hdu.image.ImageHDU\n\t        SPICE L2 FITS HDU\n\t    data: numpy.ndarray\n", "        SPICE L2 FITS data, assumed to be in W / m2 / sr / nm\n\t    header: astropy.io.fits.header.Header\n\t        SPICE L2 FITS header\n\t    verbose: bool\n\t        If True, displays details\n\t    Return\n\t    ------\n\t    float:\n\t        Average contribution of noise to measured signal\n\t    dict:\n", "        Noise standard deviations for the different components (and total)\n\t    Either hdu, or data and header should be provided.\n\t    \"\"\"\n\t    if data is None or header is None:\n\t        if hdu is None:\n\t            raise RuntimeError(\"Either hdu, or data and header should be provided\")\n\t        header = hdu.header\n\t        data = hdu.data\n\t    if header[\"LEVEL\"] != \"L2\":\n\t        raise RuntimeError(\"Level should be L2\")\n", "    data *= u.Unit(header[\"BUNIT\"])\n\t    print(data.unit)\n\t    study = Study()\n\t    study.init_from_header(header)\n\t    if verbose:\n\t        print(f\"Getting observation parameters from {header['EXTNAME']}\")\n\t        print(study)\n\t    instrument = Spice()\n\t    observation = Observation(instrument, study)\n\t    av_constant_noise_level, sigma = observation.noise_effects_from_l2(\n", "        data, study.av_wavelength\n\t    )\n\t    return av_constant_noise_level, sigma\n"]}
{"filename": "sospice/calibrate/tests/test_uncertainties.py", "chunked_list": ["import pytest\n\tfrom astropy.io import fits\n\timport astropy.units as u\n\tfrom ..uncertainties import spice_error\n\tspecrad_unit = u.mW / u.m**2 / u.sr / u.nm\n\t@pytest.fixture\n\tdef hdus():\n\t    # all expected values in specrad_unit\n\t    hdus = [\n\t        {\n", "            \"url\": \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-3.0/level2/2022/04/02/solo_L2_spice-n-ras_20220402T111537_V06_100664002-000.fits\",\n\t            \"hdu_index\": 2,  # Ne VIII window\n\t            \"expected_constant\": 42.9513921,\n\t            \"pixel_index\": (0, 25, 415, 80),\n\t            \"expected\": {\n\t                \"Dark\": 20.36091256,\n\t                \"Background\": 0.0,\n\t                \"Read\": 66.59878776,\n\t                \"Signal\": 168.60160232,\n\t                \"Total\": 182.41837621,\n", "            },\n\t        },\n\t        {  # File used for comparison with MPS' IDL code\n\t            \"url\": \"https://spice.osups.universite-paris-saclay.fr/spice-data/release-3.0/level2/2021/02/23/solo_L2_spice-n-ras_20210223T154400_V10_50331754-000.fits\",\n\t            \"hdu_index\": 2,  # Lyγ - C III\n\t            \"expected_constant\": 87.80646,\n\t            \"pixel_index\": (0, 25, 415, 80),\n\t            \"expected\": {\n\t                \"Dark\": 26.718655,\n\t                \"Background\": 0.0,\n", "                \"Read\": 56.098571,\n\t                \"Signal\": 61.990004,\n\t                \"Total\": 87.7707,\n\t            },\n\t        },\n\t    ]\n\t    for item in hdus:\n\t        item[\"hdu_list\"] = fits.open(item[\"url\"])\n\t    yield hdus\n\t    for item in hdus:\n", "        item[\"hdu_list\"].close()\n\tclass TestUncertainties:\n\t    def test_spice_error(self, hdus):\n\t        for item in hdus:\n\t            av_constant_noise_level, sigma = spice_error(\n\t                item[\"hdu_list\"][item[\"hdu_index\"]]\n\t            )\n\t        assert u.isclose(\n\t            av_constant_noise_level, item[\"expected_constant\"] * specrad_unit\n\t        )\n", "        for component in item[\"expected\"]:\n\t            pixel_index = (\n\t                () if len(sigma[component].shape) == 0 else item[\"pixel_index\"]\n\t            )\n\t            print(f\"{sigma[component][pixel_index]=}\")\n\t            assert u.isclose(\n\t                sigma[component][pixel_index],\n\t                item[\"expected\"][component] * specrad_unit,\n\t            )\n"]}
{"filename": "sospice/calibrate/tests/__init__.py", "chunked_list": []}
{"filename": "docs/source/conf.py", "chunked_list": ["# Configuration file for the Sphinx documentation builder.\n\t#\n\t# This file only contains a selection of the most common options. For a full\n\t# list see the documentation:\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\t# -- Path setup --------------------------------------------------------------\n\t# If extensions (or modules to document with autodoc) are in another directory,\n\t# add these directories to sys.path here. If the directory is relative to the\n\t# documentation root, use os.path.abspath to make it absolute, like shown here.\n\t#\n", "# import os\n\t# import sys\n\t# sys.path.insert(0, os.path.abspath('.'))\n\tfrom datetime import datetime\n\t# from sospice import __version__\n\tfrom setuptools_scm import get_version\n\t# -- Project information -----------------------------------------------------\n\tproject = \"sospice\"\n\tcopyright = f\"{datetime.now().year}, SPICE consortium\"\n\tauthor = \"SPICE consortium\"\n", "# The full version, including alpha/beta/rc tags\n\trelease = get_version(root=\"../..\", relative_to=__file__)\n\t# -- General configuration ---------------------------------------------------\n\t# Add any Sphinx extension module names here, as strings. They can be\n\t# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n\t# ones.\n\textensions = [\n\t    \"matplotlib.sphinxext.plot_directive\",\n\t    \"numpydoc\",\n\t    # \"sphinx_automodapi.automodapi\",\n", "    # \"sphinx_automodapi.smart_resolver\",\n\t    # \"sphinx_changelog\",\n\t    # \"sphinx_gallery.gen_gallery\",\n\t    \"sphinx.ext.autodoc\",\n\t    \"sphinx.ext.autosummary\",\n\t    \"sphinx.ext.coverage\",\n\t    \"sphinx.ext.doctest\",\n\t    \"sphinx.ext.inheritance_diagram\",\n\t    \"sphinx.ext.intersphinx\",\n\t    \"sphinx.ext.mathjax\",\n", "    \"sphinx.ext.napoleon\",\n\t    \"sphinx.ext.todo\",\n\t    \"sphinx.ext.viewcode\",\n\t    # \"sphinxext.opengraph\",\n\t    # \"sphinx_design\",\n\t    # \"sphinx_copybutton\",\n\t    # \"hoverxref.extension\",\n\t]\n\tautosummary_generate = True  # Turn on sphinx.ext.autosummary\n\t# Add any paths that contain templates here, relative to this directory.\n", "templates_path = [\"_templates\"]\n\t# List of patterns, relative to source directory, that match files and\n\t# directories to ignore when looking for source files.\n\t# This pattern also affects html_static_path and html_extra_path.\n\texclude_patterns = [\"build\", \"htmlcov\", \"sospice.egg-info\", \"venv\", \"tests\"]\n\t# -- Options for intersphinx extension ---------------------------------------\n\tintersphinx_mapping = {\n\t    \"python\": (\n\t        \"https://docs.python.org/3/\",\n\t        (None, \"http://data.astropy.org/intersphinx/python3.inv\"),\n", "    ),\n\t    \"numpy\": (\n\t        \"https://docs.scipy.org/doc/numpy/\",\n\t        (None, \"http://data.astropy.org/intersphinx/numpy.inv\"),\n\t    ),\n\t    \"matplotlib\": (\n\t        \"https://matplotlib.org/\",\n\t        (None, \"http://data.astropy.org/intersphinx/matplotlib.inv\"),\n\t    ),\n\t    \"astropy\": (\"http://docs.astropy.org/en/stable/\", None),\n", "    \"sunpy\": (\"https://docs.sunpy.org/en/stable/\", None),\n\t    \"sunraster\": (\"https://docs.sunpy.org/projects/sunraster/en/stable/\", None),\n\t}\n\t# -- Options for HTML output -------------------------------------------------\n\t# The theme to use for HTML and HTML Help pages.  See the documentation for\n\t# a list of builtin themes.\n\t#\n\thtml_theme = \"sphinx_rtd_theme\"\n\t# Add any paths that contain custom static files (such as style sheets) here,\n\t# relative to this directory. They are copied after the builtin static files,\n", "# so a file named \"default.css\" will overwrite the builtin \"default.css\".\n\thtml_static_path = [\"_static\"]\n"]}
