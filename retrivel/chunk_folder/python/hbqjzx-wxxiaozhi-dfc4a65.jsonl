{"filename": "app.py", "chunked_list": ["# encoding:utf-8\n\timport argparse\n\timport config\n\tfrom channel import channel_factory\n\tfrom common import log, const\n\tfrom multiprocessing import Pool\n\tfrom plugins.plugin_manager import PluginManager\n\t# 启动通道\n\tdef start_process(channel_type, config_path):\n\t    try:\n", "        # 若为多进程启动,子进程无法直接访问主进程的内存空间,重新创建config类\n\t        config.load_config(config_path)\n\t        model_type = config.conf().get(\"model\").get(\"type\")\n\t        log.info(\"[MultiChannel] Start up {} on {}\", model_type, channel_type)\n\t        channel = channel_factory.create_channel(channel_type)\n\t        channel.startup()\n\t    except Exception as e:\n\t        log.error(\"[MultiChannel] Start up failed on {}: {}\", channel_type, str(e))\n\t        raise e\n\tdef main():\n", "    try:\n\t        # load config\n\t        config.load_config(args.config)\n\t        model_type = config.conf().get(\"model\").get(\"type\")\n\t        channel_type = config.conf().get(\"channel\").get(\"type\")\n\t        PluginManager()\n\t        # 1.单个字符串格式配置时，直接启动\n\t        if not isinstance(channel_type, list):\n\t            start_process(channel_type, args.config)\n\t            exit(0)\n", "        # 2.单通道列表配置时，直接启动\n\t        if len(channel_type) == 1:\n\t            start_process(channel_type[0], args.config)\n\t            exit(0)\n\t        # 3.多通道配置时，进程池启动\n\t        # 使用主进程启动终端通道\n\t        if const.TERMINAL in channel_type:\n\t            index = channel_type.index(const.TERMINAL)\n\t            terminal = channel_type.pop(index)\n\t        else:\n", "            terminal = None\n\t        # 使用进程池启动其他通道子进程\n\t        pool = Pool(len(channel_type))\n\t        for type_item in channel_type:\n\t            log.info(\"[INIT] Start up: {} on {}\", model_type, type_item)\n\t            pool.apply_async(start_process, args=[type_item, args.config])\n\t        if terminal:\n\t            start_process(terminal, args.config)\n\t        # 等待池中所有进程执行完毕\n\t        pool.close()\n", "        pool.join()\n\t    except Exception as e:\n\t        log.error(\"App startup failed!\")\n\t        log.exception(e)\n\tif __name__ == '__main__':\n\t    parser = argparse.ArgumentParser()\n\t    parser.add_argument(\"--config\", help=\"config.json path(e.g: ./config.json  or  /usr/local/bot-on-anything/config.json)\",type=str,default=\"./config.json\")\n\t    args = parser.parse_args()\n\t    main()\n"]}
{"filename": "config.py", "chunked_list": ["# encoding:utf-8\n\timport json\n\timport os\n\tconfig = {}\n\tdef load_config(config_path = \"./config.json\"):\n\t    global config\n\t    if not os.path.exists(config_path):\n\t        raise Exception('配置文件不存在，请根据config-template.json模板创建config.json文件')\n\t    config_str = read_file(config_path)\n\t    # 将json字符串反序列化为dict类型\n", "    config = json.loads(config_str)\n\t    print(\"Load config success\")\n\t    return config\n\tdef get_root():\n\t    return os.path.dirname(os.path.abspath( __file__ ))\n\tdef read_file(path):\n\t    with open(path, mode='r', encoding='utf-8') as f:\n\t        return f.read()\n\tdef conf():\n\t    return config\n", "def model_conf(model_type):\n\t    return config.get('model').get(model_type)\n\tdef model_conf_val(model_type, key):\n\t    val = config.get('model').get(model_type).get(key)\n\t    if not val:\n\t        # common default config\n\t        return config.get('model').get(key)\n\t    return val\n\tdef channel_conf(channel_type):\n\t    return config.get('channel').get(channel_type)\n", "def channel_conf_val(channel_type, key, default=None):\n\t    val = config.get('channel').get(channel_type).get(key)\n\t    if not val:\n\t        # common default config\n\t        return config.get('channel').get(key, default)\n\t    return val\n\tdef common_conf_val(key, default=None):\n\t    if not config.get('common'):\n\t        return default\n\t    return config.get('common').get(key, default)\n"]}
{"filename": "plugins/plugin.py", "chunked_list": ["# encoding:utf-8\n\tclass Plugin:\n\t    def __init__(self):\n\t        self.handlers = {}\n\t    def get_help_text(self, **kwargs):\n\t        return \"暂无帮助信息\""]}
{"filename": "plugins/plugin_registry.py", "chunked_list": ["# encoding:utf-8\n\timport inspect\n\tfrom plugins.plugin import Plugin\n\tfrom common.log import logger\n\tfrom common import functions\n\t@functions.singleton\n\tclass PluginRegistry:\n\t    def __init__(self):\n\t        self.plugins = []\n\t    def register(self, name: str, desire_priority: int = 0, **kwargs):\n", "        def wrapper(plugin_cls):\n\t            plugin_cls.name = name\n\t            plugin_cls.priority = desire_priority\n\t            plugin_cls.desc = kwargs.get('desc')\n\t            plugin_cls.author = kwargs.get('author')\n\t            plugin_cls.version = kwargs.get('version') or \"1.0\"\n\t            plugin_cls.namecn = kwargs.get('namecn') or name\n\t            plugin_cls.hidden = kwargs.get('hidden') or False\n\t            plugin_cls.enabled = kwargs.get('enabled') or True\n\t            logger.info(f\"Plugin {name}_v{plugin_cls.version} registered\")\n", "            return plugin_cls\n\t        return wrapper\n\t    def register_from_module(self, module):\n\t            plugins = []\n\t            for name, obj in inspect.getmembers(module):\n\t                if inspect.isclass(obj) and issubclass(obj, Plugin) and obj != Plugin:\n\t                    plugin_name = getattr(obj, \"name\", None)\n\t                    if plugin_name:\n\t                        plugin = obj()\n\t                        plugin.name = plugin_name\n", "                        plugin.priority = getattr(obj, \"priority\", 0)\n\t                        plugin.desc = getattr(obj, \"desc\", None)\n\t                        plugin.author = getattr(obj, \"author\", None)\n\t                        plugin.version = getattr(obj, \"version\", \"1.0\")\n\t                        plugin.namecn = getattr(obj, \"namecn\", plugin_name)\n\t                        plugin.hidden = getattr(obj, \"hidden\", False)\n\t                        plugin.enabled = getattr(obj, \"enabled\", True)\n\t            # Sort the list of plugins by priority\n\t            self.plugins.append(plugin)\n\t            self.plugins.sort(key=lambda x: x.priority, reverse=True)\n", "    def get_plugin(self, name):\n\t        plugin = next((p for p in self.plugins if p.name.upper() == name.upper()), None)\n\t        return plugin\n\t    def list_plugins(self):\n\t        return [plugin for plugin in self.plugins]"]}
{"filename": "plugins/__init__.py", "chunked_list": ["# encoding:utf-8\n\tfrom .event import *\n\tfrom .plugin import *\n\tfrom plugins.plugin_registry import PluginRegistry\n\tinstance = PluginRegistry()\n\tregister                    = instance.register\n\t# load_plugins                = instance.load_plugins\n\t# emit_event                  = instance.emit_event\n"]}
{"filename": "plugins/event.py", "chunked_list": ["# encoding:utf-8\n\tfrom enum import Enum\n\tclass Event(Enum):\n\t    # ON_RECEIVE_MESSAGE = 1  # 收到消息\n\t    ON_HANDLE_CONTEXT = 2   # 对应通道处理消息前\n\t    \"\"\"\n\t    e_context = {  \"channel\": 消息channel,  \"context\" : 本次消息的context, \"reply\" : 目前的回复，初始为空 , \"args\": 其他上下文参数 }\n\t    \"\"\"\n\t    ON_DECORATE_REPLY = 3   # 得到回复后准备装饰\n\t    \"\"\"\n", "    e_context = {  \"channel\": 消息channel,  \"context\" : 本次消息的context, \"reply\" : 目前的回复 , \"args\": 其他上下文参数 }\n\t    \"\"\"\n\t    ON_SEND_REPLY = 4       # 发送回复前\n\t    \"\"\"\n\t    bot-on-anything 不支持ON_SEND_REPLY事件,请使用ON_BRIDGE_HANDLE_CONTEXT或者ON_BRIDGE_HANDLE_STREAM_CONTEXT事件\n\t    \"\"\"\n\t    # AFTER_SEND_REPLY = 5    # 发送回复后\n\t    ON_BRIDGE_HANDLE_CONTEXT = 6   # 模型桥处理消息前\n\t    \"\"\"\n\t    e_context = { \"context\" : 本次消息的context, \"reply\" : 目前的回复，初始为空 , \"args\": 其他上下文参数 }\n", "    \"\"\"\n\t    ON_BRIDGE_HANDLE_STREAM_CONTEXT = 7   # 模型桥处理流式消息前,流式对话的消息处理仅支持一次性返回,请直接返回结果\n\t    \"\"\"\n\t    e_context = {  \"context\" : 本次消息的context, \"reply\" : 目前的回复，初始为空 , \"args\": 其他上下文参数 }\n\t    \"\"\"\n\tclass EventAction(Enum):\n\t    CONTINUE = 1            # 事件未结束，继续交给下个插件处理，如果没有下个插件，则交付给默认的事件处理逻辑\n\t    BREAK = 2               # 事件结束，不再给下个插件处理，交付给默认的事件处理逻辑\n\t    BREAK_PASS = 3          # 事件结束，不再给下个插件处理，不交付给默认的事件处理逻辑\n\tclass EventContext:\n", "    def __init__(self, event, econtext=dict()):\n\t        self.event = event\n\t        self.econtext = econtext\n\t        self.action = EventAction.CONTINUE\n\t    def __getitem__(self, key):\n\t        return self.econtext.get(key,\"\")\n\t    def __setitem__(self, key, value):\n\t        self.econtext[key] = value\n\t    def __delitem__(self, key):\n\t        del self.econtext[key]\n", "    def is_pass(self):\n\t        return self.action == EventAction.BREAK_PASS\n"]}
{"filename": "plugins/plugin_manager.py", "chunked_list": ["# encoding:utf-8\n\timport os\n\timport importlib.util\n\tfrom plugins.event import EventAction, EventContext,Event\n\tfrom plugins.plugin_registry import PluginRegistry\n\tfrom common import functions, log\n\t@functions.singleton\n\tclass PluginManager:\n\t    def __init__(self, plugins_dir=\"./plugins/\"):\n\t        self.plugins_dir = plugins_dir\n", "        self.plugin_registry = PluginRegistry()\n\t        self.load_plugins()\n\t    def load_plugins(self):\n\t        for plugin_name in self.find_plugin_names():\n\t            if os.path.exists(f\"./plugins/{plugin_name}/{plugin_name}.py\"):\n\t                try:\n\t                    plugin_module = self.load_plugin_module(plugin_name)\n\t                    self.plugin_registry.register_from_module(plugin_module)\n\t                except Exception as e:\n\t                    log.warn(\"Failed to import plugin %s\" % (plugin_name))\n", "    def find_plugin_names(self):\n\t        plugin_names = []\n\t        for entry in os.scandir(self.plugins_dir):\n\t            if entry.is_dir():\n\t                plugin_names.append(entry.name)\n\t        return plugin_names\n\t    def load_plugin_module(self, plugin_name):\n\t        spec = importlib.util.spec_from_file_location(\n\t            plugin_name, os.path.join(self.plugins_dir, plugin_name, f\"{plugin_name}.py\")\n\t        )\n", "        module = importlib.util.module_from_spec(spec)\n\t        spec.loader.exec_module(module)\n\t        return module\n\t    def emit_event(self, e_context: EventContext, *args, **kwargs):\n\t        for plugin in self.plugin_registry.list_plugins():\n\t            if plugin.enabled and e_context.action == EventAction.CONTINUE:\n\t                if(e_context.event in plugin.handlers):\n\t                    plugin.handlers[e_context.event](e_context, *args, **kwargs)\n\t        return e_context\n"]}
{"filename": "plugins/selector/selector.py", "chunked_list": ["# encoding:utf-8\n\timport os\n\timport plugins\n\tfrom plugins import *\n\tfrom common import log\n\tfrom common import functions\n\t@plugins.register(name=\"Selector\", desire_priority=99, hidden=True, desc=\"A model selector\", version=\"0.1\", author=\"RegimenArsenic\")\n\tclass Selector(Plugin):\n\t    def __init__(self):\n\t        super().__init__()\n", "        curdir = os.path.dirname(__file__)\n\t        try:\n\t            self.config = functions.load_json_file(curdir, \"selector.json\")\n\t        except Exception as e:\n\t            log.warn(\"[Selector] init failed\")\n\t            raise e\n\t        self.handlers[Event.ON_HANDLE_CONTEXT] = self.select_model\n\t        self.handlers[Event.ON_BRIDGE_HANDLE_STREAM_CONTEXT] = self.select_model\n\t        log.info(\"[Selector] inited\")\n\t    def get_events(self):\n", "        return self.handlers\n\t    def select_model(self, e_context: EventContext):\n\t        model=e_context['args'].get('model')\n\t        for selector in self.config.get(\"selector\", []):\n\t            prefix = selector.get('prefix', [])\n\t            check_prefix=functions.check_prefix(e_context[\"context\"], prefix)\n\t            if (check_prefix):\n\t                model=selector.get('model')\n\t                if isinstance(check_prefix, str):\n\t                    e_context[\"context\"] = e_context[\"context\"].split(check_prefix, 1)[1].strip()\n", "                break\n\t        log.debug(f\"[Selector] select model {model}\")\n\t        e_context.action = EventAction.CONTINUE  # 事件继续，交付给下个插件或默认逻辑\n\t        e_context['args']['model']=model\n\t        return e_context\n"]}
{"filename": "plugins/createimg/createimg.py", "chunked_list": ["# encoding:utf-8\n\tfrom channel.http.http_channel import HttpChannel\n\tfrom channel.wechat.wechat_channel import WechatChannel\n\timport plugins\n\tfrom plugins import *\n\tfrom common import functions\n\tfrom config import channel_conf\n\tfrom config import channel_conf_val\n\tfrom common import const\n\t@plugins.register(name=\"CreateImg\", desire_priority=90, hidden=True, desc=\"A simple plugin that create images from model\", version=\"0.1\", author=\"RegimenArseic\")\n", "class Createimg(Plugin):\n\t    def __init__(self):\n\t        super().__init__()\n\t        self.handles = {HttpChannel: self.handle_http}\n\t        self.channel_types = {HttpChannel: const.HTTP,\n\t                              WechatChannel: const.WECHAT}\n\t        self.handlers[Event.ON_HANDLE_CONTEXT] = self.handle_query\n\t        self.handlers[Event.ON_DECORATE_REPLY] = self.send_images\n\t    def get_events(self):\n\t        return self.handlers\n", "    def handle_query(self, e_context: EventContext):\n\t        channel = e_context['channel']\n\t        channel_type = self.channel_types.get(type(channel), None)\n\t        if (channel_type):\n\t            query = e_context['context']\n\t            if (query):\n\t                img_match_prefix = functions.check_prefix(\n\t                    query, channel_conf_val(channel_type, 'image_create_prefix'))\n\t                if img_match_prefix:\n\t                    if (channel_type == const.HTTP) and e_context['args'].get('stream', False):\n", "                        e_context['reply'] = channel.handle(\n\t                            {'msg': e_context['args']['origin'], 'id': e_context['args']['from_user_id']})\n\t                        e_context.action = EventAction.BREAK_PASS\n\t                    else:\n\t                        query = query.split(img_match_prefix, 1)[1].strip()\n\t                        e_context['args']['type'] = 'IMAGE_CREATE'\n\t                        if (channel_type == const.WECHAT):\n\t                            channel._do_send_img(\n\t                                query, e_context['args'])\n\t                            e_context.action = EventAction.BREAK_PASS\n", "                        else:\n\t                            e_context.action = EventAction.CONTINUE\n\t        return e_context\n\t    def handle_http(self, e_context: EventContext):\n\t        reply = e_context[\"reply\"]\n\t        if e_context['args'].get('type', '') == 'IMAGE_CREATE':\n\t            if isinstance(reply, list):\n\t                images = \"\"\n\t                for url in reply:\n\t                    images += f\"[!['IMAGE_CREATE']({url})]({url})\\n\\n\"\n", "            e_context[\"reply\"] = images\n\t        return e_context\n\t    def send_images(self, e_context: EventContext):\n\t        channel = e_context['channel']\n\t        method = self.handles.get(type(channel), None)\n\t        if (method):\n\t            e_context = method(e_context)\n\t        e_context.action = EventAction.BREAK_PASS  # 事件结束，不再给下个插件处理，不交付给默认的事件处理逻辑\n\t        return e_context\n"]}
{"filename": "common/functions.py", "chunked_list": ["import json\n\timport os\n\timport re\n\tfrom common import log\n\tdef singleton(cls):\n\t    instances = {}\n\t    def get_instance(*args, **kwargs):\n\t        if cls not in instances:\n\t            instances[cls] = cls(*args, **kwargs)\n\t        return instances[cls]\n", "    return get_instance\n\tdef load_json_file(curdir: str, file: str = 'config.json'):\n\t    config_path = os.path.join(curdir, file)\n\t    try:\n\t        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n\t            config = json.load(f)\n\t            return config\n\t    except Exception as e:\n\t        if isinstance(e, FileNotFoundError):\n\t            log.warn(\n", "                f\"[common]load json file failed, {config_path}\\{file} not found\")\n\t        else:\n\t            log.warn(\"[common]load json file failed\")\n\t        raise e\n\tdef contain_chinese(str):\n\t    \"\"\"\n\t    判断一个字符串中是否含有中文\n\t    \"\"\"\n\t    pattern = re.compile('[\\u4e00-\\u9fa5]')\n\t    match = pattern.search(str)\n", "    return match != None\n\tdef check_prefix(content, prefix_list):\n\t    if(len(prefix_list)==0):\n\t        return True\n\t    for prefix in prefix_list:\n\t        if content.startswith(prefix):\n\t            return prefix\n\t    return False\n"]}
{"filename": "common/log.py", "chunked_list": ["# encoding:utf-8\n\timport logging\n\timport sys\n\tSWITCH = True\n\tdef _get_logger():\n\t    log = logging.getLogger('log')\n\t    log.setLevel(logging.INFO)\n\t    console_handle = logging.StreamHandler(sys.stdout)\n\t    console_handle.setFormatter(logging.Formatter('[%(levelname)s][%(asctime)s][%(filename)s:%(lineno)d] - %(message)s',\n\t                                                  datefmt='%Y-%m-%d %H:%M:%S'))\n", "    log.addHandler(console_handle)\n\t    return log\n\tdef close_log():\n\t    global  SWITCH\n\t    SWITCH = False\n\tdef debug(arg, *args):\n\t    if SWITCH:\n\t        if len(args) == 0:\n\t            logger.debug(arg)\n\t        else:\n", "            logger.debug(arg.format(*args))\n\tdef info(arg, *args):\n\t    if SWITCH:\n\t        if len(args) == 0:\n\t            logger.info(arg)\n\t        else:\n\t            logger.info(arg.format(*args))\n\tdef warn(arg, *args):\n\t    if len(args) == 0:\n\t        logger.warning(arg)\n", "    else:\n\t        logger.warning(arg.format(*args))\n\tdef error(arg, *args):\n\t    if len(args) == 0:\n\t        logger.error(arg)\n\t    else:\n\t        logger.error(arg.format(*args))\n\tdef exception(e):\n\t    logger.exception(e)\n\t# 日志句柄\n", "logger = _get_logger()\n"]}
{"filename": "common/sensitive_word.py", "chunked_list": ["import requests\n\tfrom  config import conf\n\tclass SensitiveWord:\n\t    def __init__(self):\n\t        # 读取配置文件\n\t        try:\n\t            self.config = conf()  # 加载配置文件\n\t            #print(self.config) # 输出配置文件内容以进行调试\n\t        except Exception as e:\n\t            print(e)  # 打印错误信息\n", "        # 设置请求 URL\n\t        self.url = \"https://aip.baidubce.com/rest/2.0/antispam/v2/spam\"\n\t        # 获取 access token\n\t        self.access_token = self.get_access_token()\n\t    def get_access_token(self):\n\t        \"\"\"\n\t        获取百度云接口的 access token\n\t        :return: str access token\n\t        \"\"\"\n\t        #检测敏感词配置是否存在\n", "        if self.config is not None and \"common\" in self.config and \"type\" in self.config[\"common\"] and self.config[\"common\"][\"type\"]:\n\t            url = \"https://aip.baidubce.com/oauth/2.0/token\"\n\t            params = {\n\t                \"grant_type\": \"client_credentials\",\n\t                \"client_id\": self.config[\"common\"][\"client_id\"],\n\t                \"client_secret\": self.config[\"common\"][\"client_secret\"]\n\t            }\n\t            response = requests.post(url, params=params)\n\t            response_json = response.json()\n\t            access_token = response_json.get(\"access_token\")\n", "            if not access_token:\n\t                raise ValueError(f\"获取 access_token 失败: {response_json.get('error_description')}\")\n\t            print(f\"Access token: {access_token}\")  # 输出访问令牌以进行调试\n\t            return access_token\n\t    def process_text(self, text):\n\t        #检测敏感词配置是否存在\n\t        if self.config is not None and \"common\" in self.config and \"sensitive\" in self.config[\"common\"] and self.config[\"common\"][\"sensitive\"]:\n\t            #存在则执行正常检测流程\n\t            url = \"https://aip.baidubce.com/rest/2.0/solution/v1/text_censor/v2/user_defined\"  # API 请求地址\n\t            access_token = self.get_access_token()\n", "            headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n\t            params = {\n\t                \"text\": text.encode(\"utf-8\"),\n\t                \"access_token\": access_token\n\t            }\n\t            response = requests.post(url, data=params, headers=headers)\n\t            if response.status_code != 200:\n\t                raise ValueError(f\"无法连接到接口，请检查你的网络: {response.json().get('error_msg')}\")\n\t            conclusion_type = response.json().get(\"conclusionType\")\n\t            print(response.json())  # 输出完整的 API 响应结果\n", "            if conclusion_type in [1, None]:\n\t                return False\n\t            else:\n\t                return True\n\t        #不存在则直接返回无敏感词\n\t        else:\n\t            return False\n"]}
{"filename": "common/const.py", "chunked_list": ["# channel\n\tTERMINAL = \"terminal\"\n\tWECHAT = \"wechat\"\n\tWECHAT_MP = \"wechat_mp\"\n\tWECHAT_MP_SERVICE = \"wechat_mp_service\"\n\tWECHAT_COM = \"wechat_com\"\n\tQQ = \"qq\"\n\tGMAIL = \"gmail\"\n\tTELEGRAM = \"telegram\"\n\tSLACK = \"slack\"\n", "HTTP = \"http\"\n\tDINGTALK = \"dingtalk\"\n\tFEISHU = \"feishu\"\n\tDISCORD = \"discord\"\n\t# model\n\tOPEN_AI = \"openai\"\n\tCHATGPT = \"chatgpt\"\n\tZHISHUYUN = \"zhishuyun\"\n\tBAIDU = \"baidu\"\n\tBING = \"bing\"\n", "BARD = \"bard\""]}
{"filename": "model/model.py", "chunked_list": ["\"\"\"\n\tAuto-replay chat robot abstract class\n\t\"\"\"\n\tclass Model(object):\n\t    def reply(self, query, context=None):\n\t        \"\"\"\n\t        model auto-reply content\n\t        :param req: received message\n\t        :return: reply content\n\t        \"\"\"\n", "        raise NotImplementedError\n"]}
{"filename": "model/model_factory.py", "chunked_list": ["\"\"\"\n\tchannel factory\n\t\"\"\"\n\tfrom common import const\n\tdef create_bot(model_type):\n\t    \"\"\"\n\t    create a channel instance\n\t    :param channel_type: channel type code\n\t    :return: channel instance\n\t    \"\"\"\n", "    if model_type == const.OPEN_AI:\n\t        # OpenAI 官方对话模型API (gpt-3.0)\n\t        from model.openai.open_ai_model import OpenAIModel\n\t        return OpenAIModel()\n\t    elif model_type == const.CHATGPT:\n\t        # ChatGPT API (gpt-3.5-turbo)\n\t        from model.openai.chatgpt_model import ChatGPTModel\n\t        return ChatGPTModel()\n\t    elif model_type == const.ZHISHUYUN:\n\t        from model.openai.zhishuyun_model import ZhishuyunModel\n", "        return ZhishuyunModel()\n\t    elif model_type == const.BAIDU:\n\t        from model.baidu.yiyan_model import YiyanModel\n\t        return YiyanModel()\n\t    elif model_type == const.BING:\n\t        from model.bing.new_bing_model import BingModel\n\t        return BingModel()\n\t    elif model_type == const.BARD:\n\t        from model.google.bard_model import BardModel\n\t        return BardModel()\n", "    raise RuntimeError\n"]}
{"filename": "model/bing/new_bing_model.py", "chunked_list": ["# encoding:utf-8\n\timport asyncio\n\tfrom model.model import Model\n\tfrom config import model_conf_val, common_conf_val\n\tfrom common import log\n\tfrom EdgeGPT import Chatbot, ConversationStyle\n\tfrom ImageGen import ImageGen\n\tfrom common import functions\n\tfrom model.bing.jailbroken_sydney import SydneyBot\n\tuser_session = dict()\n", "suggestion_session = dict()\n\t# newBing对话模型逆向网页gitAPI\n\tclass BingModel(Model):\n\t    style = ConversationStyle.creative\n\t    bot: Chatbot = None\n\t    cookies: list = None\n\t    def __init__(self):\n\t        try:\n\t            self.cookies = model_conf_val(\"bing\", \"cookies\")\n\t            self.jailbreak = model_conf_val(\"bing\", \"jailbreak\")\n", "            self.bot = SydneyBot(cookies=self.cookies, options={}) if (\n\t                self.jailbreak) else Chatbot(cookies=self.cookies)\n\t        except Exception as e:\n\t            log.warn(e)\n\t    async def reply_text_stream(self, query: str, context=None) -> dict:\n\t        async def handle_answer(final, answer):\n\t            if final:\n\t                try:\n\t                    reply = self.build_source_attributions(answer, context)\n\t                    log.info(\"[NewBing] reply:{}\", reply)\n", "                    yield True, reply\n\t                except Exception as e:\n\t                    log.warn(answer)\n\t                    log.warn(e)\n\t                    await user_session.get(context['from_user_id'], None).reset()\n\t                    yield True, answer\n\t            else:\n\t                try:\n\t                    yield False, answer\n\t                except Exception as e:\n", "                    log.warn(answer)\n\t                    log.warn(e)\n\t                    await user_session.get(context['from_user_id'], None).reset()\n\t                    yield True, answer\n\t        if not context or not context.get('type') or context.get('type') == 'TEXT':\n\t            clear_memory_commands = common_conf_val(\n\t                'clear_memory_commands', ['#清除记忆'])\n\t            if query in clear_memory_commands:\n\t                user_session[context['from_user_id']] = None\n\t                yield True, '记忆已清除'\n", "            bot = user_session.get(context['from_user_id'], None)\n\t            if not bot:\n\t                bot = self.bot\n\t            else:\n\t                query = self.get_quick_ask_query(query, context)\n\t            user_session[context['from_user_id']] = bot\n\t            log.info(\"[NewBing] query={}\".format(query))\n\t            if self.jailbreak:\n\t                async for final, answer in bot.ask_stream(query, conversation_style=self.style, message_id=bot.user_message_id):\n\t                    async for result in handle_answer(final, answer):\n", "                        yield result\n\t            else:\n\t                async for final, answer in bot.ask_stream(query, conversation_style=self.style):\n\t                    async for result in handle_answer(final, answer):\n\t                        yield result\n\t    def reply(self, query: str, context=None) -> tuple[str, dict]:\n\t        if not context or not context.get('type') or context.get('type') == 'TEXT':\n\t            clear_memory_commands = common_conf_val(\n\t                'clear_memory_commands', ['#清除记忆'])\n\t            if query in clear_memory_commands:\n", "                user_session[context['from_user_id']] = None\n\t                return '记忆已清除'\n\t            bot = user_session.get(context['from_user_id'], None)\n\t            if (bot == None):\n\t                bot = self.bot\n\t            else:\n\t                query = self.get_quick_ask_query(query, context)\n\t            user_session[context['from_user_id']] = bot\n\t            log.info(\"[NewBing] query={}\".format(query))\n\t            if (self.jailbreak):\n", "                task = bot.ask(query, conversation_style=self.style,\n\t                               message_id=bot.user_message_id)\n\t            else:\n\t                task = bot.ask(query, conversation_style=self.style)\n\t            answer = asyncio.run(task)\n\t            if isinstance(answer, str):\n\t                return answer\n\t            try:\n\t                reply = answer[\"item\"][\"messages\"][-1]\n\t            except Exception as e:\n", "                user_session.get(context['from_user_id'], None).reset()\n\t                log.warn(answer)\n\t                return \"本轮对话已超时，已开启新的一轮对话,请重新提问。\"\n\t            return self.build_source_attributions(answer, context)\n\t        elif context.get('type', None) == 'IMAGE_CREATE':\n\t            if functions.contain_chinese(query):\n\t                return \"ImageGen目前仅支持使用英文关键词生成图片\"\n\t            return self.create_img(query)\n\t    def create_img(self, query):\n\t        try:\n", "            log.info(\"[NewBing] image_query={}\".format(query))\n\t            cookie_value = self.cookies[0][\"value\"]\n\t            image_generator = ImageGen(cookie_value)\n\t            img_list = image_generator.get_images(query)\n\t            log.info(\"[NewBing] image_list={}\".format(img_list))\n\t            return img_list\n\t        except Exception as e:\n\t            log.warn(e)\n\t            return \"输入的内容可能违反微软的图片生成内容策略。过多的策略冲突可能会导致你被暂停访问。\"\n\t    def get_quick_ask_query(self, query, context):\n", "        if (len(query) == 1 and query.isdigit() and query != \"0\"):\n\t            suggestion_dict = suggestion_session[context['from_user_id']]\n\t            if (suggestion_dict != None):\n\t                query = suggestion_dict[int(query)-1]\n\t                if (query == None):\n\t                    return \"输入的序号不在建议列表范围中\"\n\t                else:\n\t                    query = \"在上面的基础上，\"+query\n\t        return query\n\t    def build_source_attributions(self, answer, context):\n", "        reference = \"\"\n\t        reply = answer[\"item\"][\"messages\"][-1]\n\t        reply_text = reply[\"text\"]\n\t        if \"sourceAttributions\" in reply:\n\t            for i, attribution in enumerate(reply[\"sourceAttributions\"]):\n\t                display_name = attribution[\"providerDisplayName\"]\n\t                url = attribution[\"seeMoreUrl\"]\n\t                reference += f\"{i+1}、[{display_name}]({url})\\n\\n\"\n\t            if len(reference) > 0:\n\t                reference = \"***\\n\"+reference\n", "            suggestion = \"\"\n\t            if \"suggestedResponses\" in reply:\n\t                suggestion_dict = dict()\n\t                for i, attribution in enumerate(reply[\"suggestedResponses\"]):\n\t                    suggestion_dict[i] = attribution[\"text\"]\n\t                    suggestion += f\">{i+1}、{attribution['text']}\\n\\n\"\n\t                suggestion_session[context['from_user_id']\n\t                                   ] = suggestion_dict\n\t            if len(suggestion) > 0:\n\t                suggestion = \"***\\n你可以通过输入序号快速追问我以下建议问题：\\n\\n\"+suggestion\n", "            throttling = answer[\"item\"][\"throttling\"]\n\t            throttling_str = \"\"\n\t            if throttling[\"numUserMessagesInConversation\"] == throttling[\"maxNumUserMessagesInConversation\"]:\n\t                user_session.get(context['from_user_id'], None).reset()\n\t                throttling_str = \"(对话轮次已达上限，本次聊天已结束，将开启新的对话)\"\n\t            else:\n\t                throttling_str = f\"对话轮次: {throttling['numUserMessagesInConversation']}/{throttling['maxNumUserMessagesInConversation']}\\n\"\n\t            response = f\"{reply_text}\\n{reference}\\n{suggestion}\\n***\\n{throttling_str}\"\n\t            log.info(\"[NewBing] reply={}\", response)\n\t            return response\n", "        else:\n\t            user_session.get(context['from_user_id'], None).reset()\n\t            log.warn(\"[NewBing] reply={}\", answer)\n\t            return \"对话被接口拒绝，已开启新的一轮对话。\"\n"]}
{"filename": "model/bing/jailbroken_sydney.py", "chunked_list": ["# encoding:utf-8\n\timport asyncio\n\timport time\n\timport websockets\n\timport random\n\timport uuid\n\timport EdgeGPT\n\tfrom EdgeGPT import ChatHubRequest, Chatbot, Conversation, ChatHub\n\tfrom typing import Generator\n\tfrom config import model_conf_val\n", "class SydneyBot(Chatbot):\n\t    def __init__(\n\t        self,\n\t        cookiePath: str = \"\",\n\t        cookies: dict | None = None,\n\t        proxy: str | None = None,\n\t        options: dict | None = None,\n\t    ) -> None:\n\t        self.conversations_cache = {}\n\t        self.parent_message_id = 0\n", "        self.user_message_id = 0\n\t        self.conversation_key = uuid.uuid4()\n\t        self.cookiePath: str = cookiePath\n\t        self.cookies: dict | None = cookies\n\t        self.proxy: str | None = proxy\n\t        self.chat_hub: SydneyHub\n\t        cache_options = options.get('cache', {})\n\t        cache_options['namespace'] = cache_options.get('namespace', 'bing')\n\t        self.conversations_cache = cache_options\n\t    @staticmethod\n", "    def get_messages_for_conversation(messages, parent_message_id):\n\t        ordered_messages = []\n\t        current_message_id = parent_message_id\n\t        while current_message_id:\n\t            message = next(\n\t                (m for m in messages if m['id'] == current_message_id), None)\n\t            if not message:\n\t                break\n\t            ordered_messages.insert(0, message)\n\t            current_message_id = message.get('parentMessageId')\n", "        return ordered_messages\n\t    async def ask_stream(\n\t        self,\n\t        prompt: str,\n\t        conversation_style: EdgeGPT.CONVERSATION_STYLE_TYPE = None,\n\t        message_id: str = None\n\t    ) -> dict:\n\t        # 开启新对话\n\t        self.chat_hub = SydneyHub(Conversation(\n\t            self.cookiePath, self.cookies, self.proxy))\n", "        self.parent_message_id = message_id if message_id != None else uuid.uuid4()\n\t        # 构造历史对话字符串,更新SydneyHubRequest的历史对话\n\t        conversation = self.conversations_cache.get(self.conversation_key)\n\t        if conversation is None:\n\t            conversation = {\n\t                \"messages\": [],\n\t                \"createdAt\": int(time.time()*1000)\n\t            }\n\t        previous_cached_messages = \"\"\n\t        for conversation_message in self.get_messages_for_conversation(conversation[\"messages\"], self.parent_message_id):\n", "            previous_cached_messages += f\"{conversation_message['role'].replace('bot', 'AI')}:\\n{conversation_message['message']}\\n\\n\"\n\t        chars = list(model_conf_val(\"bing\", \"jailbreak_prompt\"))\n\t        chars = [('-' + c if random.random() < 0.5 else '_' + c)\n\t                 if i > 0 else c for i, c in enumerate(chars)]\n\t        previous_messages = ''.join(chars)\n\t        self.chat_hub.request.previous_messages = previous_messages + \\\n\t            \"\\n\\n\"+previous_cached_messages\n\t        # 将当前提问加入历史对话列表\n\t        self.user_message_id = uuid.uuid4()\n\t        user_message = {\n", "            \"id\": self.user_message_id,\n\t            \"parentMessageId\": self.parent_message_id,\n\t            \"role\": 'User',\n\t            \"message\": prompt,\n\t        }\n\t        conversation[\"messages\"].append(user_message)\n\t        self.conversations_cache[self.conversation_key] = conversation\n\t        async for final, response in self.chat_hub.ask_stream(\n\t            prompt=prompt,\n\t            conversation_style=conversation_style\n", "        ):\n\t            if final:\n\t                try:\n\t                    if self.chat_hub.wss and not self.chat_hub.wss.closed:\n\t                        await self.chat_hub.wss.close()\n\t                    self.update_reply_cache(response[\"item\"][\"messages\"][-1])\n\t                except Exception as e:\n\t                    self.conversations_cache[self.conversation_key][\"messages\"].pop()\n\t                    yield True, f\"AI生成内容被微软内容过滤器拦截,已删除最后一次提问的记忆,请尝试使用其他文字描述问题,若AI依然无法正常回复,请清除全部记忆后再次尝试\"\n\t            yield final, response\n", "    async def ask(\n\t        self,\n\t        prompt: str,\n\t        conversation_style: EdgeGPT.CONVERSATION_STYLE_TYPE = None,\n\t        message_id: str = None\n\t    ) -> dict:\n\t        async for final, response in self.ask_stream(\n\t            prompt=prompt,\n\t            conversation_style=conversation_style,\n\t            message_id=message_id\n", "        ):\n\t            if final:\n\t                self.update_reply_cache(response[\"item\"][\"messages\"][-1])\n\t                return response\n\t    def update_reply_cache(\n\t        self,\n\t        reply,\n\t    ) -> None:\n\t        # 将回复加入历史对话列表\n\t        replyMessage = {\n", "            \"id\": uuid.uuid4(),\n\t            \"parentMessageId\": self.user_message_id,\n\t            \"role\": 'Bing',\n\t            \"message\": reply[\"text\"],\n\t            \"details\": reply,\n\t        }\n\t        self.conversations_cache[self.conversation_key][\"messages\"].append(\n\t            replyMessage)\n\t        self.user_message_id = replyMessage[\"id\"]\n\tclass SydneyHub(ChatHub):\n", "    \"\"\"\n\t    Chat API\n\t    \"\"\"\n\t    def __init__(self, conversation: Conversation) -> None:\n\t        self.wss: websockets.WebSocketClientProtocol | None = None\n\t        self.request: SydneyHubRequest\n\t        self.loop: bool\n\t        self.task: asyncio.Task\n\t        self.request = SydneyHubRequest(\n\t            conversation_signature=conversation.struct[\"conversationSignature\"],\n", "            client_id=conversation.struct[\"clientId\"],\n\t            conversation_id=conversation.struct[\"conversationId\"],\n\t        )\n\t    async def ask_stream(\n\t        self,\n\t        prompt: str,\n\t        wss_link: str = \"wss://sydney.bing.com/sydney/ChatHub\",\n\t        conversation_style: EdgeGPT.CONVERSATION_STYLE_TYPE = None,\n\t    ) -> Generator[str, None, None]:\n\t        async for item in super().ask_stream(prompt=prompt, conversation_style=conversation_style, wss_link=wss_link):\n", "            yield item\n\tclass SydneyHubRequest(ChatHubRequest):\n\t    def __init__(\n\t        self,\n\t        conversation_signature: str,\n\t        client_id: str,\n\t        conversation_id: str,\n\t        invocation_id: int = 0,\n\t    ) -> None:\n\t        super().__init__(conversation_signature=conversation_signature, client_id=client_id,\n", "                         conversation_id=conversation_id, invocation_id=invocation_id)\n\t        self.previous_messages = \"\"\n\t    def update(\n\t        self,\n\t        prompt: str,\n\t        conversation_style: EdgeGPT.CONVERSATION_STYLE_TYPE,\n\t        options: list | None = None,\n\t    ) -> None:\n\t        self.invocation_id = 0\n\t        super().update(prompt=prompt, conversation_style=conversation_style, options=options)\n", "        self.struct[\"arguments\"][0][\"message\"][\"messageType\"] = \"SearchQuery\"\n\t        self.struct[\"arguments\"][0][\"previousMessages\"] = [\n\t            {\"text\":  \"N/A\\n\\n\"+self.previous_messages, \"author\": 'bot', }]\n"]}
{"filename": "model/baidu/yiyan_model.py", "chunked_list": ["# encoding:utf-8\n\tfrom model.model import Model\n\tfrom config import model_conf\n\tfrom common import const\n\tfrom common.log import logger\n\timport requests\n\timport time\n\tsessions = {}\n\tclass YiyanModel(Model):\n\t    def __init__(self):\n", "        self.acs_token = model_conf(const.BAIDU).get('acs_token')\n\t        self.cookie = model_conf(const.BAIDU).get('cookie')\n\t        self.base_url = 'https://yiyan.baidu.com/eb'\n\t    def reply(self, query, context=None):\n\t        logger.info(\"[BAIDU] query={}\".format(query))\n\t        user_id = context.get('session_id') or context.get('from_user_id')\n\t        context['query'] = query\n\t        # 1.create session\n\t        chat_session_id = sessions.get(user_id)\n\t        if not chat_session_id:\n", "            self.new_session(context)\n\t            sessions[user_id] = context['chat_session_id']\n\t        else:\n\t            context['chat_session_id'] = chat_session_id\n\t        # 2.create chat\n\t        flag = self.new_chat(context)\n\t        if not flag:\n\t            return \"创建会话失败，请稍后再试\"\n\t        # 3.query\n\t        context['reply'] = ''\n", "        self.query(context, 0, 0)\n\t        return context['reply']\n\t    def new_session(self, context):\n\t        data = {\n\t            \"sessionName\": context['query'],\n\t            \"timestamp\": int(time.time() * 1000),\n\t            \"deviceType\": \"pc\"\n\t        }\n\t        res = requests.post(url=self.base_url+'/session/new', headers=self._create_header(), json=data)\n\t        # print(res.headers)\n", "        context['chat_session_id'] = res.json()['data']['sessionId']\n\t        logger.info(\"[BAIDU] newSession: id={}\".format(context['chat_session_id']))\n\t    def new_chat(self, context):\n\t        headers = self._create_header()\n\t        headers['Acs-Token'] = self.acs_token\n\t        data = {\n\t            \"sessionId\": context.get('chat_session_id'),\n\t            \"text\": context['query'],\n\t            \"parentChatId\": 0,\n\t            \"type\": 10,\n", "            \"timestamp\": int(time.time() * 1000),\n\t            \"deviceType\": \"pc\",\n\t            \"code\": 0,\n\t            \"msg\": \"\"\n\t        }\n\t        res = requests.post(url=self.base_url+'/chat/new', headers=headers, json=data).json()\n\t        if res['code'] != 0:\n\t            logger.error(\"[BAIDU] New chat error, msg={}\", res['msg'])\n\t            return False\n\t        context['chat_id'] = res['data']['botChat']['id']\n", "        context['parent_chat_id'] = res['data']['botChat']['parent']\n\t        return True\n\t    def query(self, context, sentence_id, count):\n\t        headers = self._create_header()\n\t        headers['Acs-Token'] = self.acs_token\n\t        data = {\n\t            \"chatId\": context['chat_id'],\n\t            \"parentChatId\": context['parent_chat_id'],\n\t            \"sentenceId\": sentence_id,\n\t            \"stop\": 0,\n", "            \"timestamp\": 1679068791405,\n\t            \"deviceType\": \"pc\"\n\t        }\n\t        res = requests.post(url=self.base_url + '/chat/query', headers=headers, json=data)\n\t        logger.debug(\"[BAIDU] query: sent_id={}, count={}, res={}\".format(sentence_id, count, res.text))\n\t        res = res.json()\n\t        if res['data']['text'] != '':\n\t            context['reply'] += res['data']['text']\n\t            # logger.debug(\"[BAIDU] query: sent_id={}, reply={}\".format(sentence_id, res['data']['text']))\n\t        if res['data']['is_end'] == 1:\n", "            return\n\t        if count > 10:\n\t            return\n\t        time.sleep(1)\n\t        if not res['data']['text']:\n\t            return self.query(context, sentence_id, count+1)\n\t        else:\n\t            return self.query(context, sentence_id+1, count+1)\n\t    def _create_header(self):\n\t        headers = {\n", "            'Host': 'yiyan.baidu.com',\n\t            'Origin': 'https://yiyan.baidu.com',\n\t            'Referer': 'https://yiyan.baidu.com',\n\t            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36',\n\t            'Content-Type': 'application/json',\n\t            'Cookie': self.cookie\n\t        }\n\t        return headers\n"]}
{"filename": "model/openai/zhishuyun_model.py", "chunked_list": ["# encoding:utf-8\n\tfrom model.model import Model\n\tfrom config import model_conf, common_conf_val\n\tfrom common import const\n\tfrom common import log\n\timport openai\n\timport time\n\timport requests\n\tuser_session = dict()\n\tuser_conversation_id = {}\n", "# OpenAI对话模型API (可用)\n\tclass ZhishuyunModel(Model):\n\t    def __init__(self):\n\t        self.token = model_conf(const.OPEN_AI).get('token')\n\t    def reply(self, query, context=None):\n\t        # acquire reply content\n\t        if not context or not context.get('type') or context.get('type') == 'TEXT':\n\t            log.info(\"[CHATGPT] query={}\".format(query))\n\t            from_user_id = context['from_user_id']\n\t            clear_memory_commands = common_conf_val('clear_memory_commands', ['#清除记忆'])\n", "            if query in clear_memory_commands:\n\t                Session.clear_session(from_user_id)\n\t                return '记忆已清除'\n\t            new_query = Session.build_session_query(query, from_user_id)\n\t            log.debug(\"[CHATGPT] session query={}\".format(new_query))\n\t            # if context.get('stream'):\n\t            #     # reply in stream\n\t            #     return self.reply_text_stream(query, new_query, from_user_id)\n\t            reply_content = self.reply_text(new_query, from_user_id, 0)\n\t            #log.debug(\"[CHATGPT] new_query={}, user={}, reply_cont={}\".format(new_query, from_user_id, reply_content))\n", "            return reply_content\n\t        elif context.get('type', None) == 'IMAGE_CREATE':\n\t            return self.create_img(query, 0)\n\t    def reply_text(self, query, user_id, retry_count=0):\n\t        try:\n\t            url = f'https://api.zhishuyun.com/chatgpt?token={self.token}'\n\t            headers = {\n\t                'accept': 'application/json',\n\t                'content-type': 'application/json'\n\t            }\n", "            if user_id in user_conversation_id:\n\t                conversation_id = user_conversation_id[user_id]\n\t                payload = {\n\t                    'question': query[-1]['content'],\n\t                    \"stateful\": True,\n\t                    'conversation_id': conversation_id\n\t                }\n\t            else:\n\t                payload = {\n\t                    'question': query[-1]['content'],\n", "                    \"stateful\": True\n\t                }\n\t            response = requests.post(url, json=payload, headers=headers)\n\t            answer = response.json()['answer']\n\t            conversation_id = response.json()['conversation_id']\n\t            user_conversation_id[user_id] = conversation_id\n\t            used_token = 500\n\t            log.debug(response)\n\t            log.info(\"[CHATGPT] reply={}\", answer)\n\t            if answer:\n", "                # save conversation\n\t                Session.save_session(query, answer, user_id, used_token)\n\t            return answer\n\t        except openai.error.RateLimitError as e:\n\t            # rate limit exception\n\t            log.warn(e)\n\t            if retry_count < 1:\n\t                time.sleep(5)\n\t                log.warn(\"[CHATGPT] RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                return self.reply_text(query, user_id, retry_count+1)\n", "            else:\n\t                return \"提问太快啦，请休息一下再问我吧\"\n\t        except openai.error.APIConnectionError as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] APIConnection failed\")\n\t            return \"我连接不到网络，请稍后重试\"\n\t        except openai.error.Timeout as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] Timeout\")\n\t            return \"我没有收到消息，请稍后重试\"\n", "        except Exception as e:\n\t            # unknown exception\n\t            log.exception(e)\n\t            Session.clear_session(user_id)\n\t            return \"请再问我一次吧\"\n\t    async def reply_text_stream(self, query,  context, retry_count=0):\n\t        try:\n\t            user_id=context['from_user_id']\n\t            new_query = Session.build_session_query(query, user_id)\n\t            res = openai.ChatCompletion.create(\n", "                model= model_conf(const.OPEN_AI).get(\"model\") or \"gpt-3.5-turbo\",  # 对话模型的名称\n\t                messages=new_query,\n\t                temperature=model_conf(const.OPEN_AI).get(\"temperature\", 0.75),  # 熵值，在[0,1]之间，越大表示选取的候选词越随机，回复越具有不确定性，建议和top_p参数二选一使用，创意性任务越大越好，精确性任务越小越好\n\t                #max_tokens=4096,  # 回复最大的字符数，为输入和输出的总数\n\t                #top_p=model_conf(const.OPEN_AI).get(\"top_p\", 0.7),,  #候选词列表。0.7 意味着只考虑前70%候选词的标记，建议和temperature参数二选一使用\n\t                frequency_penalty=model_conf(const.OPEN_AI).get(\"frequency_penalty\", 0.0),  # [-2,2]之间，该值越大则越降低模型一行中的重复用词，更倾向于产生不同的内容\n\t                presence_penalty=model_conf(const.OPEN_AI).get(\"presence_penalty\", 1.0),  # [-2,2]之间，该值越大则越不受输入限制，将鼓励模型生成输入中不存在的新词，更倾向于产生不同的内容\n\t                stream=True\n\t            )\n\t            full_response = \"\"\n", "            for chunk in res:\n\t                log.debug(chunk)\n\t                if (chunk[\"choices\"][0][\"finish_reason\"]==\"stop\"):\n\t                    break\n\t                chunk_message = chunk['choices'][0]['delta'].get(\"content\")\n\t                if(chunk_message):\n\t                    full_response+=chunk_message\n\t                yield False,full_response\n\t            Session.save_session(query, full_response, user_id)\n\t            log.info(\"[chatgpt]: reply={}\", full_response)\n", "            yield True,full_response\n\t        except openai.error.RateLimitError as e:\n\t            # rate limit exception\n\t            log.warn(e)\n\t            if retry_count < 1:\n\t                time.sleep(5)\n\t                log.warn(\"[CHATGPT] RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                yield True, self.reply_text_stream(query, user_id, retry_count+1)\n\t            else:\n\t                yield True, \"提问太快啦，请休息一下再问我吧\"\n", "        except openai.error.APIConnectionError as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] APIConnection failed\")\n\t            yield True, \"我连接不到网络，请稍后重试\"\n\t        except openai.error.Timeout as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] Timeout\")\n\t            yield True, \"我没有收到消息，请稍后重试\"\n\t        except Exception as e:\n\t            # unknown exception\n", "            log.exception(e)\n\t            Session.clear_session(user_id)\n\t            yield True, \"请再问我一次吧\"\n\t    def create_img(self, query, retry_count=0):\n\t        try:\n\t            log.info(\"[OPEN_AI] image_query={}\".format(query))\n\t            response = openai.Image.create(\n\t                prompt=query,    #图片描述\n\t                n=1,             #每次生成图片的数量\n\t                size=\"256x256\"   #图片大小,可选有 256x256, 512x512, 1024x1024\n", "            )\n\t            image_url = response['data'][0]['url']\n\t            log.info(\"[OPEN_AI] image_url={}\".format(image_url))\n\t            return [image_url]\n\t        except openai.error.RateLimitError as e:\n\t            log.warn(e)\n\t            if retry_count < 1:\n\t                time.sleep(5)\n\t                log.warn(\"[OPEN_AI] ImgCreate RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                return self.reply_text(query, retry_count+1)\n", "            else:\n\t                return \"提问太快啦，请休息一下再问我吧\"\n\t        except Exception as e:\n\t            log.exception(e)\n\t            return None\n\tclass Session(object):\n\t    @staticmethod\n\t    def build_session_query(query, user_id):\n\t        '''\n\t        build query with conversation history\n", "        e.g.  [\n\t            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n\t            {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n\t            {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n\t            {\"role\": \"user\", \"content\": \"Where was it played?\"}\n\t        ]\n\t        :param query: query content\n\t        :param user_id: from user id\n\t        :return: query content with conversaction\n\t        '''\n", "        session = user_session.get(user_id, [])\n\t        if len(session) == 0:\n\t            system_prompt = model_conf(const.OPEN_AI).get(\"character_desc\", \"\")\n\t            system_item = {'role': 'system', 'content': system_prompt}\n\t            session.append(system_item)\n\t            user_session[user_id] = session\n\t        user_item = {'role': 'user', 'content': query}\n\t        session.append(user_item)\n\t        return session\n\t    @staticmethod\n", "    def save_session(query, answer, user_id, used_tokens=0):\n\t        max_tokens = model_conf(const.OPEN_AI).get('conversation_max_tokens')\n\t        max_history_num = model_conf(const.OPEN_AI).get('max_history_num', None)\n\t        if not max_tokens or max_tokens > 4000:\n\t            # default value\n\t            max_tokens = 1000\n\t        session = user_session.get(user_id)\n\t        if session:\n\t            # append conversation\n\t            gpt_item = {'role': 'assistant', 'content': answer}\n", "            session.append(gpt_item)\n\t        if used_tokens > max_tokens and len(session) >= 3:\n\t            # pop first conversation (TODO: more accurate calculation)\n\t            session.pop(1)\n\t            session.pop(1)\n\t        if max_history_num is not None:\n\t            while len(session) > max_history_num * 2 + 1:\n\t                session.pop(1)\n\t                session.pop(1)\n\t    @staticmethod\n", "    def clear_session(user_id):\n\t        user_session[user_id] = []\n"]}
{"filename": "model/openai/chatgpt_model.py", "chunked_list": ["# encoding:utf-8\n\tfrom model.model import Model\n\tfrom config import model_conf, common_conf_val\n\tfrom common import const\n\tfrom common import log\n\timport openai\n\timport time\n\tuser_session = dict()\n\t# OpenAI对话模型API (可用)\n\tclass ChatGPTModel(Model):\n", "    def __init__(self):\n\t        openai.api_key = model_conf(const.OPEN_AI).get('api_key')\n\t        api_base = model_conf(const.OPEN_AI).get('api_base')\n\t        if api_base:\n\t            openai.api_base = api_base\n\t        proxy = model_conf(const.OPEN_AI).get('proxy')\n\t        if proxy:\n\t            openai.proxy = proxy\n\t        log.info(\"[CHATGPT] api_base={} proxy={}\".format(\n\t            api_base, proxy))\n", "    def reply(self, query, context=None):\n\t        # acquire reply content\n\t        if not context or not context.get('type') or context.get('type') == 'TEXT':\n\t            log.info(\"[CHATGPT] query={}\".format(query))\n\t            from_user_id = context['from_user_id']\n\t            clear_memory_commands = common_conf_val('clear_memory_commands', ['#清除记忆'])\n\t            if query in clear_memory_commands:\n\t                Session.clear_session(from_user_id)\n\t                return '记忆已清除'\n\t            new_query = Session.build_session_query(query, from_user_id)\n", "            log.debug(\"[CHATGPT] session query={}\".format(new_query))\n\t            # if context.get('stream'):\n\t            #     # reply in stream\n\t            #     return self.reply_text_stream(query, new_query, from_user_id)\n\t            reply_content = self.reply_text(new_query, from_user_id, 0)\n\t            #log.debug(\"[CHATGPT] new_query={}, user={}, reply_cont={}\".format(new_query, from_user_id, reply_content))\n\t            return reply_content\n\t        elif context.get('type', None) == 'IMAGE_CREATE':\n\t            return self.create_img(query, 0)\n\t    def reply_text(self, query, user_id, retry_count=0):\n", "        try:\n\t            response = openai.ChatCompletion.create(\n\t                model= model_conf(const.OPEN_AI).get(\"model\") or \"gpt-3.5-turbo\",  # 对话模型的名称\n\t                messages=query,\n\t                temperature=model_conf(const.OPEN_AI).get(\"temperature\", 0.75),  # 熵值，在[0,1]之间，越大表示选取的候选词越随机，回复越具有不确定性，建议和top_p参数二选一使用，创意性任务越大越好，精确性任务越小越好\n\t                #max_tokens=4096,  # 回复最大的字符数，为输入和输出的总数\n\t                #top_p=model_conf(const.OPEN_AI).get(\"top_p\", 0.7),,  #候选词列表。0.7 意味着只考虑前70%候选词的标记，建议和temperature参数二选一使用\n\t                frequency_penalty=model_conf(const.OPEN_AI).get(\"frequency_penalty\", 0.0),  # [-2,2]之间，该值越大则越降低模型一行中的重复用词，更倾向于产生不同的内容\n\t                presence_penalty=model_conf(const.OPEN_AI).get(\"presence_penalty\", 1.0)  # [-2,2]之间，该值越大则越不受输入限制，将鼓励模型生成输入中不存在的新词，更倾向于产生不同的内容\n\t                )\n", "            reply_content = response.choices[0]['message']['content']\n\t            used_token = response['usage']['total_tokens']\n\t            log.debug(response)\n\t            log.info(\"[CHATGPT] reply={}\", reply_content)\n\t            if reply_content:\n\t                # save conversation\n\t                Session.save_session(query, reply_content, user_id, used_token)\n\t            return response.choices[0]['message']['content']\n\t        except openai.error.RateLimitError as e:\n\t            # rate limit exception\n", "            log.warn(e)\n\t            if retry_count < 1:\n\t                time.sleep(5)\n\t                log.warn(\"[CHATGPT] RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                return self.reply_text(query, user_id, retry_count+1)\n\t            else:\n\t                return \"提问太快啦，请休息一下再问我吧\"\n\t        except openai.error.APIConnectionError as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] APIConnection failed\")\n", "            return \"我连接不到网络，请稍后重试\"\n\t        except openai.error.Timeout as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] Timeout\")\n\t            return \"我没有收到消息，请稍后重试\"\n\t        except Exception as e:\n\t            # unknown exception\n\t            log.exception(e)\n\t            Session.clear_session(user_id)\n\t            return \"请再问我一次吧\"\n", "    async def reply_text_stream(self, query,  context, retry_count=0):\n\t        try:\n\t            user_id=context['from_user_id']\n\t            new_query = Session.build_session_query(query, user_id)\n\t            res = openai.ChatCompletion.create(\n\t                model= model_conf(const.OPEN_AI).get(\"model\") or \"gpt-3.5-turbo\",  # 对话模型的名称\n\t                messages=new_query,\n\t                temperature=model_conf(const.OPEN_AI).get(\"temperature\", 0.75),  # 熵值，在[0,1]之间，越大表示选取的候选词越随机，回复越具有不确定性，建议和top_p参数二选一使用，创意性任务越大越好，精确性任务越小越好\n\t                #max_tokens=4096,  # 回复最大的字符数，为输入和输出的总数\n\t                #top_p=model_conf(const.OPEN_AI).get(\"top_p\", 0.7),,  #候选词列表。0.7 意味着只考虑前70%候选词的标记，建议和temperature参数二选一使用\n", "                frequency_penalty=model_conf(const.OPEN_AI).get(\"frequency_penalty\", 0.0),  # [-2,2]之间，该值越大则越降低模型一行中的重复用词，更倾向于产生不同的内容\n\t                presence_penalty=model_conf(const.OPEN_AI).get(\"presence_penalty\", 1.0),  # [-2,2]之间，该值越大则越不受输入限制，将鼓励模型生成输入中不存在的新词，更倾向于产生不同的内容\n\t                stream=True\n\t            )\n\t            full_response = \"\"\n\t            for chunk in res:\n\t                log.debug(chunk)\n\t                if (chunk[\"choices\"][0][\"finish_reason\"]==\"stop\"):\n\t                    break\n\t                chunk_message = chunk['choices'][0]['delta'].get(\"content\")\n", "                if(chunk_message):\n\t                    full_response+=chunk_message\n\t                yield False,full_response\n\t            Session.save_session(query, full_response, user_id)\n\t            log.info(\"[chatgpt]: reply={}\", full_response)\n\t            yield True,full_response\n\t        except openai.error.RateLimitError as e:\n\t            # rate limit exception\n\t            log.warn(e)\n\t            if retry_count < 1:\n", "                time.sleep(5)\n\t                log.warn(\"[CHATGPT] RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                yield True, self.reply_text_stream(query, user_id, retry_count+1)\n\t            else:\n\t                yield True, \"提问太快啦，请休息一下再问我吧\"\n\t        except openai.error.APIConnectionError as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] APIConnection failed\")\n\t            yield True, \"我连接不到网络，请稍后重试\"\n\t        except openai.error.Timeout as e:\n", "            log.warn(e)\n\t            log.warn(\"[CHATGPT] Timeout\")\n\t            yield True, \"我没有收到消息，请稍后重试\"\n\t        except Exception as e:\n\t            # unknown exception\n\t            log.exception(e)\n\t            Session.clear_session(user_id)\n\t            yield True, \"请再问我一次吧\"\n\t    def create_img(self, query, retry_count=0):\n\t        try:\n", "            log.info(\"[OPEN_AI] image_query={}\".format(query))\n\t            response = openai.Image.create(\n\t                prompt=query,    #图片描述\n\t                n=1,             #每次生成图片的数量\n\t                size=\"256x256\"   #图片大小,可选有 256x256, 512x512, 1024x1024\n\t            )\n\t            image_url = response['data'][0]['url']\n\t            log.info(\"[OPEN_AI] image_url={}\".format(image_url))\n\t            return [image_url]\n\t        except openai.error.RateLimitError as e:\n", "            log.warn(e)\n\t            if retry_count < 1:\n\t                time.sleep(5)\n\t                log.warn(\"[OPEN_AI] ImgCreate RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                return self.reply_text(query, retry_count+1)\n\t            else:\n\t                return \"提问太快啦，请休息一下再问我吧\"\n\t        except Exception as e:\n\t            log.exception(e)\n\t            return None\n", "class Session(object):\n\t    @staticmethod\n\t    def build_session_query(query, user_id):\n\t        '''\n\t        build query with conversation history\n\t        e.g.  [\n\t            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n\t            {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n\t            {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n\t            {\"role\": \"user\", \"content\": \"Where was it played?\"}\n", "        ]\n\t        :param query: query content\n\t        :param user_id: from user id\n\t        :return: query content with conversaction\n\t        '''\n\t        session = user_session.get(user_id, [])\n\t        if len(session) == 0:\n\t            system_prompt = model_conf(const.OPEN_AI).get(\"character_desc\", \"\")\n\t            system_item = {'role': 'system', 'content': system_prompt}\n\t            session.append(system_item)\n", "            user_session[user_id] = session\n\t        user_item = {'role': 'user', 'content': query}\n\t        session.append(user_item)\n\t        return session\n\t    @staticmethod\n\t    def save_session(query, answer, user_id, used_tokens=0):\n\t        max_tokens = model_conf(const.OPEN_AI).get('conversation_max_tokens')\n\t        max_history_num = model_conf(const.OPEN_AI).get('max_history_num', None)\n\t        if not max_tokens or max_tokens > 4000:\n\t            # default value\n", "            max_tokens = 1000\n\t        session = user_session.get(user_id)\n\t        if session:\n\t            # append conversation\n\t            gpt_item = {'role': 'assistant', 'content': answer}\n\t            session.append(gpt_item)\n\t        if used_tokens > max_tokens and len(session) >= 3:\n\t            # pop first conversation (TODO: more accurate calculation)\n\t            session.pop(1)\n\t            session.pop(1)\n", "        if max_history_num is not None:\n\t            while len(session) > max_history_num * 2 + 1:\n\t                session.pop(1)\n\t                session.pop(1)\n\t    @staticmethod\n\t    def clear_session(user_id):\n\t        user_session[user_id] = []\n"]}
{"filename": "model/openai/open_ai_model.py", "chunked_list": ["# encoding:utf-8\n\tfrom model.model import Model\n\tfrom config import model_conf, common_conf_val\n\tfrom common import const\n\tfrom common import log\n\timport openai\n\timport time\n\tuser_session = dict()\n\t# OpenAI对话模型API (可用)\n\tclass OpenAIModel(Model):\n", "    def __init__(self):\n\t        openai.api_key = model_conf(const.OPEN_AI).get('api_key')\n\t        api_base = model_conf(const.OPEN_AI).get('api_base')\n\t        if api_base:\n\t            openai.api_base = api_base\n\t        log.info(\"[OPEN_AI] api_base={}\".format(openai.api_base))\n\t        self.model = model_conf(const.OPEN_AI).get('model', 'text-davinci-003')\n\t        proxy = model_conf(const.OPEN_AI).get('proxy')\n\t        if proxy:\n\t            openai.proxy = proxy\n", "    def reply(self, query, context=None):\n\t        # acquire reply content\n\t        if not context or not context.get('type') or context.get('type') == 'TEXT':\n\t            log.info(\"[OPEN_AI] query={}\".format(query))\n\t            from_user_id = context['from_user_id']\n\t            clear_memory_commands = common_conf_val('clear_memory_commands', ['#清除记忆'])\n\t            if query in clear_memory_commands:\n\t                Session.clear_session(from_user_id)\n\t                return '记忆已清除'\n\t            new_query = Session.build_session_query(query, from_user_id)\n", "            log.debug(\"[OPEN_AI] session query={}\".format(new_query))\n\t            if context.get('stream'):\n\t                # reply in stream\n\t                return self.reply_text_stream(query, new_query, from_user_id)\n\t            reply_content = self.reply_text(new_query, from_user_id, 0)\n\t            log.debug(\"[OPEN_AI] new_query={}, user={}, reply_cont={}\".format(new_query, from_user_id, reply_content))\n\t            if reply_content and query:\n\t                Session.save_session(query, reply_content, from_user_id)\n\t            return reply_content\n\t        elif context.get('type', None) == 'IMAGE_CREATE':\n", "            return self.create_img(query, 0)\n\t    def reply_text(self, query, user_id, retry_count=0):\n\t        try:\n\t            response = openai.Completion.create(\n\t                model=self.model,  # 对话模型的名称\n\t                prompt=query,\n\t                temperature=model_conf(const.OPEN_AI).get(\"temperature\", 0.75),  # 熵值，在[0,1]之间，越大表示选取的候选词越随机，回复越具有不确定性，建议和top_p参数二选一使用，创意性任务越大越好，精确性任务越小越好\n\t                #max_tokens=4096,  # 回复最大的字符数，为输入和输出的总数\n\t                #top_p=model_conf(const.OPEN_AI).get(\"top_p\", 0.7),,  #候选词列表。0.7 意味着只考虑前70%候选词的标记，建议和temperature参数二选一使用\n\t                frequency_penalty=model_conf(const.OPEN_AI).get(\"frequency_penalty\", 0.0),  # [-2,2]之间，该值越大则越降低模型一行中的重复用词，更倾向于产生不同的内容\n", "                presence_penalty=model_conf(const.OPEN_AI).get(\"presence_penalty\", 1.0),  # [-2,2]之间，该值越大则越不受输入限制，将鼓励模型生成输入中不存在的新词，更倾向于产生不同的内容\n\t                stop=[\"\\n\\n\\n\"]\n\t            )\n\t            res_content = response.choices[0]['text'].strip().replace('<|endoftext|>', '')\n\t            log.info(\"[OPEN_AI] reply={}\".format(res_content))\n\t            return res_content\n\t        except openai.error.RateLimitError as e:\n\t            # rate limit exception\n\t            log.warn(e)\n\t            if retry_count < 1:\n", "                time.sleep(5)\n\t                log.warn(\"[OPEN_AI] RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                return self.reply_text(query, user_id, retry_count+1)\n\t            else:\n\t                return \"提问太快啦，请休息一下再问我吧\"\n\t        except Exception as e:\n\t            # unknown exception\n\t            log.exception(e)\n\t            Session.clear_session(user_id)\n\t            return \"请再问我一次吧\"\n", "    async def reply_text_stream(self, query,  context, retry_count=0):\n\t        try:\n\t            user_id=context['from_user_id']\n\t            new_query = Session.build_session_query(query, user_id)\n\t            res = openai.Completion.create(\n\t                model= \"text-davinci-003\",  # 对话模型的名称\n\t                prompt=new_query,\n\t                temperature=model_conf(const.OPEN_AI).get(\"temperature\", 0.75),  # 熵值，在[0,1]之间，越大表示选取的候选词越随机，回复越具有不确定性，建议和top_p参数二选一使用，创意性任务越大越好，精确性任务越小越好\n\t                max_tokens=model_conf(const.OPEN_AI).get(\"conversation_max_tokens\", 3000),  # 回复最大的字符数，为输入和输出的总数,davinci的流式对话需要启用这属性，不然对话会断流\n\t                #top_p=model_conf(const.OPEN_AI).get(\"top_p\", 0.7),,  #候选词列表。0.7 意味着只考虑前70%候选词的标记，建议和temperature参数二选一使用\n", "                frequency_penalty=model_conf(const.OPEN_AI).get(\"frequency_penalty\", 0.0),  # [-2,2]之间，该值越大则越降低模型一行中的重复用词，更倾向于产生不同的内容\n\t                presence_penalty=model_conf(const.OPEN_AI).get(\"presence_penalty\", 1.0),  # [-2,2]之间，该值越大则越不受输入限制，将鼓励模型生成输入中不存在的新词，更倾向于产生不同的内容\n\t                stream=True\n\t            )\n\t            full_response = \"\"\n\t            for chunk in res:\n\t                log.debug(chunk)\n\t                if (chunk[\"choices\"][0][\"finish_reason\"]==\"stop\"):\n\t                    break\n\t                chunk_message = chunk['choices'][0].get(\"text\")\n", "                if(chunk_message):\n\t                    full_response+=chunk_message\n\t                yield False,full_response\n\t            Session.save_session(query, full_response, user_id)\n\t            log.info(\"[chatgpt]: reply={}\", full_response)\n\t            yield True,full_response\n\t        except openai.error.RateLimitError as e:\n\t            # rate limit exception\n\t            log.warn(e)\n\t            if retry_count < 1:\n", "                time.sleep(5)\n\t                log.warn(\"[CHATGPT] RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                yield True, self.reply_text_stream(query, user_id, retry_count+1)\n\t            else:\n\t                yield True, \"提问太快啦，请休息一下再问我吧\"\n\t        except openai.error.APIConnectionError as e:\n\t            log.warn(e)\n\t            log.warn(\"[CHATGPT] APIConnection failed\")\n\t            yield True, \"我连接不到网络，请稍后重试\"\n\t        except openai.error.Timeout as e:\n", "            log.warn(e)\n\t            log.warn(\"[CHATGPT] Timeout\")\n\t            yield True, \"我没有收到消息，请稍后重试\"\n\t        except Exception as e:\n\t            # unknown exception\n\t            log.exception(e)\n\t            Session.clear_session(user_id)\n\t            yield True, \"请再问我一次吧\"\n\t    def _process_reply_stream(\n\t            self,\n", "            query: str,\n\t            reply: dict,\n\t            user_id: str\n\t    ) -> str:\n\t        full_response = \"\"\n\t        for response in reply:\n\t            if response.get(\"choices\") is None or len(response[\"choices\"]) == 0:\n\t                raise Exception(\"OpenAI API returned no choices\")\n\t            if response[\"choices\"][0].get(\"finish_details\") is not None:\n\t                break\n", "            if response[\"choices\"][0].get(\"text\") is None:\n\t                raise Exception(\"OpenAI API returned no text\")\n\t            if response[\"choices\"][0][\"text\"] == \"<|endoftext|>\":\n\t                break\n\t            yield response[\"choices\"][0][\"text\"]\n\t            full_response += response[\"choices\"][0][\"text\"]\n\t        if query and full_response:\n\t            Session.save_session(query, full_response, user_id)\n\t    def create_img(self, query, retry_count=0):\n\t        try:\n", "            log.info(\"[OPEN_AI] image_query={}\".format(query))\n\t            response = openai.Image.create(\n\t                prompt=query,    #图片描述\n\t                n=1,             #每次生成图片的数量\n\t                size=\"256x256\"   #图片大小,可选有 256x256, 512x512, 1024x1024\n\t            )\n\t            image_url = response['data'][0]['url']\n\t            log.info(\"[OPEN_AI] image_url={}\".format(image_url))\n\t            return [image_url]\n\t        except openai.error.RateLimitError as e:\n", "            log.warn(e)\n\t            if retry_count < 1:\n\t                time.sleep(5)\n\t                log.warn(\"[OPEN_AI] ImgCreate RateLimit exceed, 第{}次重试\".format(retry_count+1))\n\t                return self.reply_text(query, retry_count+1)\n\t            else:\n\t                return \"提问太快啦，请休息一下再问我吧\"\n\t        except Exception as e:\n\t            log.exception(e)\n\t            return None\n", "class Session(object):\n\t    @staticmethod\n\t    def build_session_query(query, user_id):\n\t        '''\n\t        build query with conversation history\n\t        e.g.  Q: xxx\n\t              A: xxx\n\t              Q: xxx\n\t        :param query: query content\n\t        :param user_id: from user id\n", "        :return: query content with conversaction\n\t        '''\n\t        prompt = model_conf(const.OPEN_AI).get(\"character_desc\", \"\")\n\t        if prompt:\n\t            prompt += \"<|endoftext|>\\n\\n\\n\"\n\t        session = user_session.get(user_id, None)\n\t        if session:\n\t            for conversation in session:\n\t                prompt += \"Q: \" + conversation[\"question\"] + \"\\n\\n\\nA: \" + conversation[\"answer\"] + \"<|endoftext|>\\n\"\n\t            prompt += \"Q: \" + query + \"\\nA: \"\n", "            return prompt\n\t        else:\n\t            return prompt + \"Q: \" + query + \"\\nA: \"\n\t    @staticmethod\n\t    def save_session(query, answer, user_id):\n\t        max_tokens = model_conf(const.OPEN_AI).get(\"conversation_max_tokens\")\n\t        if not max_tokens:\n\t            # default 3000\n\t            max_tokens = 1000\n\t        conversation = dict()\n", "        conversation[\"question\"] = query\n\t        conversation[\"answer\"] = answer\n\t        session = user_session.get(user_id)\n\t        log.debug(conversation)\n\t        log.debug(session)\n\t        if session:\n\t            # append conversation\n\t            session.append(conversation)\n\t        else:\n\t            # create session\n", "            queue = list()\n\t            queue.append(conversation)\n\t            user_session[user_id] = queue\n\t        # discard exceed limit conversation\n\t        Session.discard_exceed_conversation(user_session[user_id], max_tokens)\n\t    @staticmethod\n\t    def discard_exceed_conversation(session, max_tokens):\n\t        count = 0\n\t        count_list = list()\n\t        for i in range(len(session)-1, -1, -1):\n", "            # count tokens of conversation list\n\t            history_conv = session[i]\n\t            count += len(history_conv[\"question\"]) + len(history_conv[\"answer\"])\n\t            count_list.append(count)\n\t        for c in count_list:\n\t            if c > max_tokens:\n\t                # pop first conversation\n\t                session.pop(0)\n\t    @staticmethod\n\t    def clear_session(user_id):\n", "        user_session[user_id] = []\n"]}
{"filename": "model/google/bard_bot.py", "chunked_list": ["import json\n\timport random\n\timport requests\n\timport re\n\tclass BardBot:\n\t    BARD_URL = \"https://bard.google.com/\"\n\t    BARD_CHAT_URL = (\n\t        \"https://bard.google.com/_/BardChatUi/data/assistant.lamda.BardFrontendService/StreamGenerate\"\n\t    )\n\t    HEADERS = {\n", "        \"Host\": \"bard.google.com\",\n\t        \"X-Same-Domain\": \"1\",\n\t        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\",\n\t        \"Content-Type\": \"application/x-www-form-urlencoded;charset=UTF-8\",\n\t        \"Origin\": \"https://bard.google.com\",\n\t        \"Referer\": \"https://bard.google.com/\",\n\t    }\n\t    def __init__(self, session_id: str):\n\t        self._reqid = random.randrange(10000,99999)\n\t        self.conversation_id = \"\"\n", "        self.response_id = \"\"\n\t        self.choice_id = \"\"\n\t        self.session = requests.Session()\n\t        self.session.headers = self.HEADERS\n\t        self.session.cookies.set(\"__Secure-1PSID\", session_id)\n\t        self.SNlM0e = self.__get_snlm0e()\n\t    def __get_snlm0e(self) -> str:\n\t        resp = self.session.get(url=self.BARD_URL, timeout=10)\n\t        if resp.status_code != 200:\n\t            raise Exception(\"Failed to connect Google Bard\")\n", "        try:\n\t            SNlM0e = re.search(r\"SNlM0e\\\":\\\"(.*?)\\\"\", resp.text).group(1)\n\t            return SNlM0e\n\t        except Exception as e:\n\t            raise Exception(f\"Cookies may be wrong:{e}\")\n\t    def ask(self, message: str) -> dict[str, str]:\n\t        params = {\n\t            \"bl\": \"boq_assistant-bard-web-server_20230326.21_p0\",\n\t            \"_reqid\": str(self._reqid),\n\t            \"rt\": \"c\",\n", "        }\n\t        message_struct = [[message], None, [self.conversation_id, self.response_id, self.choice_id]]\n\t        data = {\"f.req\": json.dumps([None, json.dumps(message_struct)]), \"at\": self.SNlM0e}\n\t        try:\n\t            resp = self.session.post(self.BARD_CHAT_URL, params=params, data=data)\n\t            content = json.loads(resp.content.splitlines()[3])[0][2]\n\t            if not (content := json.loads(resp.content.splitlines()[3])[0][2]):\n\t                return {\"content\": f\"Bard encountered an error: {resp.content}.\"} \n\t            json_data = json.loads(content)\n\t            results = {\n", "                \"content\": json_data[0][0],\n\t                \"conversation_id\": json_data[1][0],\n\t                \"response_id\": json_data[1][1],\n\t                \"reference\": json_data[3],\n\t                \"choices\": [{\"id\": i[0], \"content\": i[1]} for i in json_data[4]],\n\t            }\n\t            self.conversation_id = results['conversation_id']\n\t            self.response_id = results['response_id']\n\t            self.choice_id = results[\"choices\"][0][\"id\"]\n\t            self._reqid += 100000\n", "            return results\n\t        except Exception as e:\n\t            raise Exception(f\"Failed to ask Google Bard:{e}\")"]}
{"filename": "model/google/bard_model.py", "chunked_list": ["# encoding:utf-8\n\tfrom .bard_bot import BardBot\n\tfrom config import model_conf_val\n\tfrom model.model import Model\n\tfrom common import log\n\tuser_session = dict()\n\tclass BardModel(Model):\n\t    bot: BardBot = None\n\t    def __init__(self):\n\t        try:\n", "            self.cookies = model_conf_val(\"bard\", \"cookie\")\n\t            self.bot = BardBot(self.cookies)\n\t        except Exception as e:\n\t            log.warn(e)\n\t    def reply(self, query: str, context=None) -> dict[str, str]:\n\t        if not context or not context.get('type') or context.get('type') == 'TEXT':\n\t            bot = user_session.get(context['from_user_id'], None)\n\t            if bot is None:\n\t                bot = self.bot\n\t            user_session[context['from_user_id']] = bot\n", "            log.info(f\"[Bard] query={query}\")\n\t            answer = bot.ask(query)\n\t            # Bard最多返回3个生成结果,目前暂时选第一个返回\n\t            reply = answer['content']\n\t            if answer['reference']:\n\t                reference = [({'index': item[0], 'reference':item[2][0] if item[2][0] else item[2][1]}) for item in answer['reference'][0]]\n\t                reference.sort(key=lambda x: x['index'], reverse=True)\n\t                reply = self.insert_reference(reply, reference)\n\t            log.warn(f\"[Bard] answer={reply}\")\n\t            return reply\n", "    async def reply_text_stream(self, query: str, context=None) -> dict:\n\t        reply = self.reply(query, context)\n\t        yield True, reply\n\t    def insert_reference(self, reply: str, reference: list) -> str:\n\t        refer = '\\n***\\n\\n'\n\t        length = len(reference)\n\t        for i, item in enumerate(reference):\n\t            index = item[\"index\"] - 1\n\t            reply = reply[:index] + f'[^{length-i}]' + reply[index:]\n\t            refer += f'- ^{i+1}：{item[\"reference\"]}\\n\\n'\n", "        refer += '***'\n\t        return reply + refer\n"]}
{"filename": "bridge/bridge.py", "chunked_list": ["from model import model_factory\n\timport config\n\tfrom plugins.event import Event, EventContext\n\tfrom plugins.plugin_manager import PluginManager\n\tclass Bridge(object):\n\t    def __init__(self):\n\t        pass\n\t    def fetch_reply_content(self, query, context):\n\t        econtext = PluginManager().emit_event(EventContext(\n\t            Event.ON_BRIDGE_HANDLE_CONTEXT, {'context': query, 'args': context}))\n", "        type = econtext['args'].get('model') or config.conf().get(\"model\").get(\"type\")\n\t        query = econtext.econtext.get(\"context\", None)\n\t        reply = econtext.econtext.get(\"reply\", \"无回复\")\n\t        if not econtext.is_pass() and query:\n\t            return model_factory.create_bot(type).reply(query, context)\n\t        else:\n\t            return reply\n\t    async def fetch_reply_stream(self, query, context):\n\t        econtext = PluginManager().emit_event(EventContext(\n\t            Event.ON_BRIDGE_HANDLE_CONTEXT, {'context': query, 'args': context}))\n", "        type = econtext['args'].get('model') or config.conf().get(\"model\").get(\"type\")\n\t        query = econtext.econtext.get(\"context\", None)\n\t        reply = econtext.econtext.get(\"reply\", \"无回复\")\n\t        bot = model_factory.create_bot(type)\n\t        if not econtext.is_pass() and query:\n\t            async for final, response in bot.reply_text_stream(query, context):\n\t                yield final, response\n\t        else:\n\t            yield True, reply\n"]}
{"filename": "channel/channel.py", "chunked_list": ["\"\"\"\n\tMessage sending channel abstract class\n\t\"\"\"\n\tfrom bridge.bridge import Bridge\n\tclass Channel(object):\n\t    def startup(self):\n\t        \"\"\"\n\t        init channel\n\t        \"\"\"\n\t        raise NotImplementedError\n", "    def handle(self, msg):\n\t        \"\"\"\n\t        process received msg\n\t        :param msg: message object\n\t        \"\"\"\n\t        raise NotImplementedError\n\t    def send(self, msg, receiver):\n\t        \"\"\"\n\t        send message to user\n\t        :param msg: message content\n", "        :param receiver: receiver channel account\n\t        :return: \n\t        \"\"\"\n\t        raise NotImplementedError\n\t    def build_reply_content(self, query, context=None):\n\t        return Bridge().fetch_reply_content(query, context)\n\t    async def build_reply_stream(self, query, context=None):\n\t        async for final,response in Bridge().fetch_reply_stream(query, context):\n\t            yield final,response\n"]}
{"filename": "channel/channel_factory.py", "chunked_list": ["\"\"\"\n\tchannel factory\n\t\"\"\"\n\tfrom common import const\n\tdef create_channel(channel_type):\n\t    \"\"\"\n\t    create a channel instance\n\t    :param channel_type: channel type code\n\t    :return: channel instance\n\t    \"\"\"\n", "    if channel_type== const.TERMINAL:\n\t        from channel.terminal.terminal_channel import TerminalChannel\n\t        return TerminalChannel()\n\t    if channel_type == const.WECHAT:\n\t        from channel.wechat.wechat_channel import WechatChannel\n\t        return WechatChannel()\n\t    elif channel_type == const.WECHAT_MP:\n\t        from channel.wechat.wechat_mp_channel import WechatSubsribeAccount\n\t        return WechatSubsribeAccount()\n\t    elif channel_type == const.WECHAT_MP_SERVICE:\n", "        from channel.wechat.wechat_mp_service_channel import WechatServiceAccount\n\t        return WechatServiceAccount()\n\t    elif channel_type == const.WECHAT_COM:\n\t        from channel.wechat.wechat_com_channel import WechatEnterpriseChannel\n\t        return WechatEnterpriseChannel()\n\t    elif channel_type == const.QQ:\n\t        from channel.qq.qq_channel import QQChannel\n\t        return QQChannel()\n\t    elif channel_type == const.GMAIL:\n\t        from channel.gmail.gmail_channel import GmailChannel\n", "        return GmailChannel()\n\t    elif channel_type == const.TELEGRAM:\n\t        from channel.telegram.telegram_channel import TelegramChannel\n\t        return TelegramChannel()\n\t    elif channel_type == const.SLACK:\n\t        from channel.slack.slack_channel import SlackChannel\n\t        return SlackChannel()\n\t    elif channel_type == const.HTTP:\n\t        from channel.http.http_channel import HttpChannel\n\t        return HttpChannel()\n", "    elif channel_type == const.DINGTALK:\n\t        from channel.dingtalk.dingtalk_channel import DingTalkChannel\n\t        return DingTalkChannel()\n\t    elif channel_type == const.FEISHU:\n\t        from channel.feishu.feishu_channel import FeiShuChannel\n\t        return FeiShuChannel()\n\t    elif channel_type == const.DISCORD:\n\t        from channel.discord.discord_channel import DiscordChannel\n\t        return DiscordChannel()\n\t    else:\n", "        raise RuntimeError(\"unknown channel_type in config.json: \" + channel_type)\n"]}
{"filename": "channel/dingtalk/dingtalk_channel.py", "chunked_list": ["# encoding:utf-8\n\timport json\n\timport hmac\n\timport hashlib\n\timport base64\n\timport time\n\timport requests\n\tfrom urllib.parse import quote_plus\n\tfrom common import log\n\tfrom flask import Flask, request, render_template, make_response\n", "from common import const\n\tfrom common import functions\n\tfrom config import channel_conf\n\tfrom config import channel_conf_val\n\tfrom channel.channel import Channel\n\tclass DingTalkHandler():\n\t    def __init__(self, config):\n\t        self.dingtalk_key = config.get('dingtalk_key')\n\t        self.dingtalk_secret = config.get('dingtalk_secret')\n\t        self.dingtalk_token = config.get('dingtalk_token')\n", "        self.dingtalk_post_token = config.get('dingtalk_post_token')\n\t        self.access_token = None\n\t        log.info(\"[DingTalk] AppKey={}, AppSecret={} Token={} post Token={}\".format(self.dingtalk_key, self.dingtalk_secret, self.dingtalk_token, self.dingtalk_post_token))\n\t    def notify_dingtalk_webhook(self, data):\n\t        timestamp = round(time.time() * 1000)\n\t        secret_enc = bytes(self.dingtalk_secret, encoding='utf-8')\n\t        string_to_sign = '{}\\n{}'.format(timestamp, self.dingtalk_secret)\n\t        string_to_sign_enc = bytes(string_to_sign, encoding='utf-8')\n\t        hmac_code = hmac.new(secret_enc, string_to_sign_enc,\n\t                             digestmod=hashlib.sha256).digest()\n", "        sign = quote_plus(base64.b64encode(hmac_code))\n\t        notify_url = f\"https://oapi.dingtalk.com/robot/send?access_token={self.dingtalk_token}&timestamp={timestamp}&sign={sign}\"\n\t        try:\n\t            log.info(\"[DingTalk] url={}\".format(str(notify_url)))\n\t            r = requests.post(notify_url, json=data)\n\t            reply = r.json()\n\t            log.info(\"[DingTalk] reply={}\".format(str(reply)))\n\t        except Exception as e:\n\t            log.error(e)\n\t    def get_token_internal(self):\n", "        access_token_url = 'https://api.dingtalk.com/v1.0/oauth2/accessToken'\n\t        try:\n\t            r = requests.post(access_token_url, json={\"appKey\": self.dingtalk_key, \"appSecret\": self.dingtalk_secret})\n\t        except:\n\t            raise Exception(\"DingTalk token获取失败!!!\")\n\t        data = json.loads(r.content)\n\t        access_token = data['accessToken']\n\t        expire_in = data['expireIn']\n\t        self.access_token = access_token\n\t        self.expire_at = int(expire_in) + time.time()\n", "        return self.access_token\n\t    def get_token(self):\n\t        if self.access_token is None or self.expire_at <= time.time():\n\t            self.get_token_internal()\n\t        return self.access_token\n\t    def get_post_url(self, data):\n\t        type = data['conversationType']\n\t        if type == \"1\":\n\t            return f\"https://api.dingtalk.com/v1.0/robot/oToMessages/batchSend\"\n\t        else:\n", "            return f\"https://api.dingtalk.com/v1.0/robot/groupMessages/send\"\n\t    def build_response(self, reply, data):\n\t        type = data['conversationType']\n\t        if type == \"1\":\n\t            return self.build_oto_response(reply, data)\n\t        else:\n\t            return self.build_group_response(reply, data)\n\t    def build_oto_response(self, reply, data):\n\t        conversation_id = data['conversationId']\n\t        prompt = data['text']['content']\n", "        prompt = prompt.strip()\n\t        img_match_prefix = functions.check_prefix(\n\t            prompt, channel_conf_val(const.DINGTALK, 'image_create_prefix'))\n\t        nick = data['senderNick']\n\t        staffid = data['senderStaffId']\n\t        robotCode = data['robotCode']\n\t        if img_match_prefix and isinstance(reply, list):\n\t            images = \"\"\n\t            for url in reply:\n\t                images += f\"!['IMAGE_CREATE']({url})\\n\"\n", "            reply = images\n\t            resp = {\n\t                \"msgKey\": \"sampleMarkdown\",\n\t                \"msgParam\": json.dumps({\n\t                    \"title\": \"IMAGE @\" + nick + \" \", \n\t                    \"text\": images + \" \\n \" + \"@\" + nick\n\t                }),\n\t                \"robotCode\": robotCode,\n\t                \"userIds\": [staffid]\n\t            }\n", "        else:\n\t            resp = {\n\t                \"msgKey\": \"sampleText\",\n\t                \"msgParam\": json.dumps({\n\t                    \"content\": reply\n\t                }),\n\t                \"robotCode\": robotCode,\n\t                \"userIds\": [staffid]\n\t            }\n\t        return resp\n", "    def build_group_response(self, reply, data):\n\t        conversation_id = data['conversationId']\n\t        prompt = data['text']['content']\n\t        prompt = prompt.strip()\n\t        img_match_prefix = functions.check_prefix(\n\t            prompt, channel_conf_val(const.DINGTALK, 'image_create_prefix'))\n\t        nick = data['senderNick']\n\t        staffid = data['senderStaffId']\n\t        robot_code = data['robotCode']\n\t        if img_match_prefix and isinstance(reply, list):\n", "            images = \"\"\n\t            for url in reply:\n\t                images += f\"!['IMAGE_CREATE']({url})\\n\"\n\t            reply = images\n\t            resp = {\n\t                \"msgKey\": \"sampleMarkdown\",\n\t                \"msgParam\": json.dumps({\n\t                    \"title\": \"IMAGE @\" + nick + \" \", \n\t                    \"text\": images + \" \\n \" + \"@\" + nick\n\t                }),\n", "                \"robotCode\": robot_code,\n\t                \"openConversationId\": conversation_id,\n\t                \"at\": {\n\t                    \"atUserIds\": [\n\t                        staffid\n\t                    ],\n\t                    \"isAtAll\": False\n\t                }\n\t            }\n\t        else:\n", "            resp = {\n\t                \"msgKey\": \"sampleText\",\n\t                \"msgParam\": json.dumps({\n\t                    \"content\": reply + \" \\n \" + \"@\" + nick\n\t                }),\n\t                \"robotCode\": robot_code,\n\t                \"openConversationId\": conversation_id,\n\t                \"at\": {\n\t                    \"atUserIds\": [\n\t                       staffid \n", "                    ],\n\t                    \"isAtAll\": False\n\t                }\n\t            }\n\t        return resp\n\t    def build_webhook_response(self, reply, data):\n\t        conversation_id = data['conversationId']\n\t        prompt = data['text']['content']\n\t        prompt = prompt.strip()\n\t        img_match_prefix = functions.check_prefix(\n", "            prompt, channel_conf_val(const.DINGTALK, 'image_create_prefix'))\n\t        nick = data['senderNick']\n\t        staffid = data['senderStaffId']\n\t        robotCode = data['robotCode']\n\t        if img_match_prefix and isinstance(reply, list):\n\t            images = \"\"\n\t            for url in reply:\n\t                images += f\"!['IMAGE_CREATE']({url})\\n\"\n\t            reply = images\n\t            resp = {\n", "                \"msgtype\": \"markdown\",\n\t                \"markdown\": {\n\t                    \"title\": \"IMAGE @\" + nick + \" \", \n\t                    \"text\": images + \" \\n \" + \"@\" + nick\n\t                },\n\t                \"at\": {\n\t                    \"atUserIds\": [\n\t                        staffid\n\t                    ],\n\t                    \"isAtAll\": False\n", "                }\n\t            }\n\t        else:\n\t            resp = {\n\t                \"msgtype\": \"text\",\n\t                \"text\": {\n\t                    \"content\": reply\n\t                },\n\t                \"at\": {\n\t                    \"atUserIds\": [\n", "                       staffid \n\t                    ],\n\t                    \"isAtAll\": False\n\t                }\n\t            }\n\t        return resp\n\t    def chat(self, channel, data):\n\t        reply = channel.handle(data)\n\t        type = data['conversationType']\n\t        if type == \"1\":\n", "            reply_json = self.build_response(reply, data)\n\t            self.notify_dingtalk(data, reply_json)\n\t        else:\n\t            # group的不清楚怎么@，先用webhook调用\n\t            reply_json = self.build_webhook_response(reply, data)\n\t            self.notify_dingtalk_webhook(reply_json)\n\t    def notify_dingtalk(self, data, reply_json):\n\t        headers = {\n\t            'content-type': 'application/json', \n\t            'x-acs-dingtalk-access-token': self.get_token()\n", "        }\n\t        notify_url = self.get_post_url(data)\n\t        try:\n\t            r = requests.post(notify_url, json=reply_json, headers=headers)\n\t            resp = r.json()\n\t            log.info(\"[DingTalk] response={}\".format(str(resp)))\n\t        except Exception as e:\n\t            log.error(e)\n\tclass DingTalkChannel(Channel):\n\t    def __init__(self):\n", "        log.info(\"[DingTalk] started.\")\n\t    def startup(self):\n\t        http_app.run(host='0.0.0.0', port=channel_conf(const.DINGTALK).get('port'))\n\t    def handle(self, data):\n\t        reply = \"您好，有什么我可以帮助您解答的问题吗？\"\n\t        prompt = data['text']['content']\n\t        prompt = prompt.strip()\n\t        if str(prompt) != 0:\n\t            conversation_id = data['conversationId']\n\t            sender_id = data['senderId']\n", "            context = dict()\n\t            img_match_prefix = functions.check_prefix(\n\t                prompt, channel_conf_val(const.DINGTALK, 'image_create_prefix'))\n\t            if img_match_prefix:\n\t                prompt = prompt.split(img_match_prefix, 1)[1].strip()\n\t                context['type'] = 'IMAGE_CREATE'\n\t            id = sender_id\n\t            context['from_user_id'] = str(id)\n\t            reply = super().build_reply_content(prompt, context)\n\t        return reply\n", "dd = DingTalkChannel()\n\thandlers = dict()\n\trobots = channel_conf(const.DINGTALK).get('dingtalk_robots')\n\tif robots and len(robots) > 0:\n\t    for robot in robots:\n\t        robot_config = channel_conf(const.DINGTALK).get(robot)\n\t        robot_key = robot_config.get('dingtalk_key')\n\t        group_name = robot_config.get('dingtalk_group')\n\t        handlers[group_name or robot_key] = DingTalkHandler(robot_config)\n\telse:\n", "    handlers['DEFAULT'] = DingTalkHandler(channel_conf(const.DINGTALK))\n\thttp_app = Flask(__name__,)\n\t@http_app.route(\"/\", methods=['POST'])\n\tdef chat():\n\t    log.info(\"[DingTalk] chat_headers={}\".format(str(request.headers)))\n\t    log.info(\"[DingTalk] chat={}\".format(str(request.data)))\n\t    token = request.headers.get('token')\n\t    data = json.loads(request.data)\n\t    if data:\n\t        content = data['text']['content']\n", "        if not content:\n\t            return\n\t        code = data['robotCode']\n\t        group_name = None\n\t        if 'conversationTitle' in data:\n\t            group_name = data['conversationTitle']\n\t        handler = handlers.get(group_name, handlers.get(code, handlers.get('DEFAULT')))\n\t        if handler.dingtalk_post_token and token != handler.dingtalk_post_token:\n\t            return {'ret': 203}\n\t        handler.chat(dd, data)\n", "        return {'ret': 200}\n\t    return {'ret': 201}\n"]}
{"filename": "channel/terminal/terminal_channel.py", "chunked_list": ["from channel.channel import Channel\n\tfrom common import log\n\timport sys\n\tclass TerminalChannel(Channel):\n\t    def startup(self):\n\t        # close log\n\t        log.close_log()\n\t        context = {\"from_user_id\": \"User\", \"stream\": True}\n\t        print(\"\\nPlease input your question\")\n\t        while True:\n", "            try:\n\t                prompt = self.get_input(\"User:\\n\")\n\t            except KeyboardInterrupt:\n\t                print(\"\\nExiting...\")\n\t                sys.exit()\n\t            print(\"Bot:\")\n\t            sys.stdout.flush()\n\t            for res in super().build_reply_content(prompt, context):\n\t                print(res, end=\"\")\n\t                sys.stdout.flush()\n", "            print(\"\\n\")\n\t    def get_input(self, prompt):\n\t        \"\"\"\n\t        Multi-line input function\n\t        \"\"\"\n\t        print(prompt, end=\"\")\n\t        line = input()\n\t        return line\n"]}
{"filename": "channel/wechat/wechat_mp_channel.py", "chunked_list": ["import werobot\n\timport time\n\tfrom config import channel_conf\n\tfrom common import const\n\tfrom common.log import logger\n\tfrom channel.channel import Channel\n\tfrom concurrent.futures import ThreadPoolExecutor\n\timport os\n\trobot = werobot.WeRoBot(token=channel_conf(const.WECHAT_MP).get('token'))\n\tthread_pool = ThreadPoolExecutor(max_workers=8)\n", "cache = {}\n\t@robot.text\n\tdef hello_world(msg):\n\t    with open('sensitive_words.txt', 'r', encoding='utf-8') as f: #加入检测违规词\n\t        sensitive_words = [line.strip() for line in f.readlines()]\n\t        found = False\n\t        for word in sensitive_words:\n\t            if word != '' and word in msg.content:\n\t                found = True\n\t                break\n", "        if found:\n\t            return \"输入内容有敏感词汇\"\n\t        else:\n\t            logger.info('[WX_Public] receive public msg: {}, userId: {}'.format(msg.content, msg.source))\n\t            key = msg.content + '|' + msg.source\n\t            if cache.get(key):\n\t                # request time\n\t                cache.get(key)['req_times'] += 1\n\t            return WechatSubsribeAccount().handle(msg)\n\tclass WechatSubsribeAccount(Channel):\n", "    def startup(self):\n\t        logger.info('[WX_Public] Wechat Public account service start!')\n\t        robot.config['PORT'] = channel_conf(const.WECHAT_MP).get('port')\n\t        robot.config['HOST'] = '0.0.0.0'\n\t        robot.run()\n\t    def handle(self, msg, count=1):\n\t        if msg.content == \"继续\":\n\t            return self.get_un_send_content(msg.source)\n\t        context = dict()\n\t        context['from_user_id'] = msg.source\n", "        key = msg.content + '|' + msg.source\n\t        res = cache.get(key)\n\t        if not res:\n\t            cache[key] = {\"status\": \"waiting\", \"req_times\": 1}\n\t            thread_pool.submit(self._do_send, msg.content, context)\n\t        res = cache.get(key)\n\t        logger.info(\"count={}, res={}\".format(count, res))\n\t        if res.get('status') == 'success':\n\t            res['status'] = \"done\"\n\t            cache.pop(key)\n", "            return res.get(\"data\")\n\t        if cache.get(key)['req_times'] == 3 and count >= 4:\n\t            logger.info(\"微信超时3次\")\n\t            return \"已开始处理，请稍等片刻后输入\\\"继续\\\"查看回复\"\n\t        if count <= 5:\n\t            time.sleep(1)\n\t            if count == 5:\n\t                # 第5秒不做返回，防止消息发送出去了但是微信已经中断连接\n\t                return None\n\t            return self.handle(msg, count+1)\n", "    def _do_send(self, query, context):\n\t        key = query + '|' + context['from_user_id']\n\t        reply_text = super().build_reply_content(query, context)\n\t        logger.info('[WX_Public] reply content: {}'.format(reply_text))\n\t        cache[key]['status'] = \"success\"\n\t        cache[key]['data'] = reply_text\n\t    def get_un_send_content(self, from_user_id):\n\t        for key in cache:\n\t            if from_user_id in key:\n\t                value = cache[key]\n", "                if value.get('status') == \"success\":\n\t                    cache.pop(key)\n\t                    return value.get(\"data\")\n\t                return \"还在处理中，请稍后再试\"\n\t        return \"目前无等待回复信息，请输入对话\"\n"]}
{"filename": "channel/wechat/wechat_com_channel.py", "chunked_list": ["#!/usr/bin/env python\n\t# -*- coding=utf-8 -*-\n\t\"\"\"\n\t@time: 2023/4/10 22:24\n\t@Project ：bot-on-anything\n\t@file: wechat_com_channel.py\n\t\"\"\"\n\tfrom channel.channel import Channel\n\tfrom concurrent.futures import ThreadPoolExecutor\n\tfrom common.log import logger\n", "from config import conf\n\tfrom wechatpy.enterprise.crypto import WeChatCrypto\n\tfrom wechatpy.enterprise import WeChatClient\n\tfrom wechatpy.exceptions import InvalidSignatureException\n\tfrom wechatpy.enterprise.exceptions import InvalidCorpIdException\n\tfrom wechatpy.enterprise import parse_message\n\tfrom flask import Flask, request, abort\n\tthread_pool = ThreadPoolExecutor(max_workers=8)\n\tapp = Flask(__name__)\n\t@app.route('/wechat', methods=['GET', 'POST'])\n", "def handler_msg():\n\t    return WechatEnterpriseChannel().handle()\n\t_conf = conf().get(\"channel\").get(\"wechat_com\")\n\tclass WechatEnterpriseChannel(Channel):\n\t    def __init__(self):\n\t        self.CorpId = _conf.get('wechat_corp_id')\n\t        self.Secret = _conf.get('secret')\n\t        self.AppId = _conf.get('appid')\n\t        self.TOKEN = _conf.get('wechat_token')\n\t        self.EncodingAESKey = _conf.get('wechat_encoding_aes_key')\n", "        self.crypto = WeChatCrypto(self.TOKEN, self.EncodingAESKey, self.CorpId)\n\t        self.client = WeChatClient(self.CorpId, self.Secret, self.AppId)\n\t    def startup(self):\n\t        # start message listener\n\t        app.run(host='0.0.0.0', port=_conf.get('port'))\n\t    def send(self, msg, receiver):\n\t        logger.info('[WXCOM] sendMsg={}, receiver={}'.format(msg, receiver))\n\t        self.client.message.send_text(self.AppId, receiver, msg)\n\t    def _do_send(self, query, reply_user_id):\n\t        try:\n", "            if not query:\n\t                return\n\t            context = dict()\n\t            context['from_user_id'] = reply_user_id\n\t            reply_text = super().build_reply_content(query, context)\n\t            if reply_text:\n\t                self.send(reply_text, reply_user_id)\n\t        except Exception as e:\n\t            logger.exception(e)\n\t    def handle(self):\n", "        query_params = request.args\n\t        signature = query_params.get('msg_signature', '')\n\t        timestamp = query_params.get('timestamp', '')\n\t        nonce = query_params.get('nonce', '')\n\t        if request.method == 'GET':\n\t            # 处理验证请求\n\t            echostr = query_params.get('echostr', '')\n\t            try:\n\t                echostr = self.crypto.check_signature(signature, timestamp, nonce, echostr)\n\t            except InvalidSignatureException:\n", "                abort(403)\n\t            print(echostr)\n\t            return echostr\n\t        elif request.method == 'POST':\n\t            try:\n\t                message = self.crypto.decrypt_message(\n\t                    request.data,\n\t                    signature,\n\t                    timestamp,\n\t                    nonce\n", "                )\n\t            except (InvalidSignatureException, InvalidCorpIdException):\n\t                abort(403)\n\t            msg = parse_message(message)\n\t            if msg.type == 'text':\n\t                thread_pool.submit(self._do_send, msg.content, msg.source)\n\t            else:\n\t                reply = 'Can not handle this for now'\n\t                # 未能处理的消息或菜单事件暂不做响应优化用户体验\n\t                # self.client.message.send_text(self.AppId, msg.source, reply)\n", "            return 'success'\n"]}
{"filename": "channel/wechat/wechat_channel.py", "chunked_list": ["# encoding:utf-8\n\t\"\"\"\n\twechat channel\n\t\"\"\"\n\timport time\n\timport itchat\n\timport json\n\tfrom itchat.content import *\n\tfrom channel.channel import Channel\n\tfrom concurrent.futures import ThreadPoolExecutor\n", "from common.log import logger\n\tfrom common import const\n\tfrom config import channel_conf_val\n\timport requests\n\tfrom plugins.plugin_manager import *\n\tfrom common.sensitive_word import SensitiveWord\n\timport io\n\tthread_pool = ThreadPoolExecutor(max_workers=8)\n\tsw = SensitiveWord()\n\t@itchat.msg_register(TEXT)\n", "def handler_single_msg(msg):\n\t    WechatChannel().handle(msg)\n\t    return None\n\t@itchat.msg_register(TEXT, isGroupChat=True)\n\tdef handler_group_msg(msg):\n\t    WechatChannel().handle_group(msg)\n\t    return None\n\tclass WechatChannel(Channel):\n\t    def __init__(self):\n\t        pass\n", "    def startup(self):\n\t        # login by scan QRCode\n\t        hot_reload = channel_conf_val(const.WECHAT, 'hot_reload', True)\n\t        if channel_conf_val(const.WECHAT, 'receive_qrcode_api'):\n\t            itchat.auto_login(enableCmdQR=2, hot_reload=hot_reload, qrCallback=self.login)\n\t        else:\n\t            itchat.auto_login(enableCmdQR=2, hotReload=hot_reload)\n\t        # start message listener\n\t        itchat.run()\n\t    def login(self, uuid=None, status='0', qrcode=None):\n", "        print('uuid:', uuid)\n\t        print('status:', status)\n\t        # 请将链接转发到外部接口，并在外部自行通过二维码生成库将链接转换为二维码后展示，例如：将下方的 qrcode_link 通过草料二维码进行处理后，再通过手机端扫码登录微信小号\n\t        print('qrcode_link:', 'https://login.weixin.qq.com/l/'+uuid)\n\t    def handle(self, msg):\n\t        logger.debug(\"[WX]receive msg: \" + json.dumps(msg, ensure_ascii=False))\n\t        from_user_id = msg['FromUserName']\n\t        to_user_id = msg['ToUserName']              # 接收人id\n\t        other_user_id = msg['User']['UserName']     # 对手方id\n\t        create_time = msg['CreateTime']             # 消息时间\n", "        content = msg['Text']\n\t        hot_reload = channel_conf_val(const.WECHAT, 'hot_reload', True)\n\t        if hot_reload == True and int(create_time) < int(time.time()) - 60:  # 跳过1分钟前的历史消息\n\t            logger.debug(\"[WX]history message skipped\")\n\t            return\n\t        # 调用敏感词检测函数\n\t        if sw.process_text(content):\n\t            self.send('请检查您的输入是否有违规内容', from_user_id)\n\t            return\n\t        match_prefix = self.check_prefix(content, channel_conf_val(const.WECHAT, 'single_chat_prefix'))\n", "        if from_user_id == other_user_id and match_prefix is not None:\n\t            # 好友向自己发送消息\n\t            if match_prefix != '':\n\t                str_list = content.split(match_prefix, 1)\n\t                if len(str_list) == 2:\n\t                    content = str_list[1].strip()\n\t            thread_pool.submit(self._do_send, content, from_user_id)\n\t        elif to_user_id == other_user_id and match_prefix:\n\t            # 自己给好友发送消息\n\t            str_list = content.split(match_prefix, 1)\n", "            if len(str_list) == 2:\n\t                content = str_list[1].strip()\n\t            thread_pool.submit(self._do_send, content, to_user_id)\n\t    def handle_group(self, msg):\n\t        logger.debug(\"[WX]receive group msg: \" + json.dumps(msg, ensure_ascii=False))\n\t        group_name = msg['User'].get('NickName', None)\n\t        group_id = msg['User'].get('UserName', None)\n\t        create_time = msg['CreateTime']             # 消息时间\n\t        hot_reload = channel_conf_val(const.WECHAT, 'hot_reload', True)\n\t        if hot_reload == True and int(create_time) < int(time.time()) - 60:  # 跳过1分钟前的历史消息\n", "            logger.debug(\"[WX]history message skipped\")\n\t            return\n\t        if not group_name:\n\t            return None\n\t        origin_content = msg['Content']\n\t        content = msg['Content']\n\t        content_list = content.split(' ', 1)\n\t        context_special_list = content.split('\\u2005', 1)\n\t        if len(context_special_list) == 2:\n\t            content = context_special_list[1]\n", "        elif len(content_list) == 2:\n\t            content = content_list[1]\n\t        match_prefix = (msg['IsAt'] and not channel_conf_val(const.WECHAT, \"group_at_off\", False)) or self.check_prefix(origin_content, channel_conf_val(const.WECHAT, 'group_chat_prefix')) or self.check_contain(origin_content, channel_conf_val(const.WECHAT, 'group_chat_keyword'))\n\t        # 如果在群里被at了 或 触发机器人关键字，则调用敏感词检测函数\n\t        if match_prefix is True:\n\t            if sw.process_text(content):\n\t                self.send('请检查您的输入是否有违规内容', group_id)\n\t                return\n\t        group_white_list = channel_conf_val(const.WECHAT, 'group_name_white_list')\n\t        if ('ALL_GROUP' in group_white_list or group_name in group_white_list or self.check_contain(group_name, channel_conf_val(const.WECHAT, 'group_name_keyword_white_list'))) and match_prefix:\n", "            thread_pool.submit(self._do_send_group, content, msg)\n\t        return None\n\t    def send(self, msg, receiver):\n\t        logger.info('[WX] sendMsg={}, receiver={}'.format(msg, receiver))\n\t        itchat.send(msg, toUserName=receiver)\n\t    def _do_send(self, query, reply_user_id):\n\t        try:\n\t            if not query:\n\t                return\n\t            context = dict()\n", "            context['from_user_id'] = reply_user_id\n\t            e_context = PluginManager().emit_event(EventContext(Event.ON_HANDLE_CONTEXT, {\n\t                'channel': self, 'context': query,  \"args\": context}))\n\t            reply = e_context['reply']\n\t            if not e_context.is_pass():\n\t                reply = super().build_reply_content(e_context[\"context\"], e_context[\"args\"])\n\t                e_context = PluginManager().emit_event(EventContext(Event.ON_DECORATE_REPLY, {\n\t                    'channel': self, 'context': context, 'reply': reply, \"args\": e_context[\"args\"]}))\n\t                reply = e_context['reply']\n\t                if reply:\n", "                    self.send(channel_conf_val(const.WECHAT, \"single_chat_reply_prefix\") + reply, reply_user_id)\n\t        except Exception as e:\n\t            logger.exception(e)\n\t    def _do_send_img(self, query, context):\n\t        try:\n\t            if not query:\n\t                return\n\t            reply_user_id=context['from_user_id']\n\t            img_urls = super().build_reply_content(query, context)\n\t            if not img_urls:\n", "                return\n\t            if not isinstance(img_urls, list):\n\t                self.send(channel_conf_val(const.WECHAT, \"single_chat_reply_prefix\") + img_urls, reply_user_id)\n\t                return\n\t            for url in img_urls:\n\t            # 图片下载\n\t                pic_res = requests.get(url, stream=True)\n\t                image_storage = io.BytesIO()\n\t                for block in pic_res.iter_content(1024):\n\t                    image_storage.write(block)\n", "                image_storage.seek(0)\n\t                # 图片发送\n\t                logger.info('[WX] sendImage, receiver={}'.format(reply_user_id))\n\t                itchat.send_image(image_storage, reply_user_id)\n\t        except Exception as e:\n\t            logger.exception(e)\n\t    def _do_send_group(self, query, msg):\n\t        if not query:\n\t            return\n\t        context = dict()\n", "        context['from_user_id'] = msg['User']['UserName']\n\t        e_context = PluginManager().emit_event(EventContext(Event.ON_HANDLE_CONTEXT, {\n\t            'channel': self, 'context': query,  \"args\": context}))\n\t        reply = e_context['reply']\n\t        if not e_context.is_pass():\n\t            context['from_user_id'] = msg['ActualUserName']\n\t            reply = super().build_reply_content(e_context[\"context\"], e_context[\"args\"])\n\t            e_context = PluginManager().emit_event(EventContext(Event.ON_DECORATE_REPLY, {\n\t                'channel': self, 'context': context, 'reply': reply, \"args\": e_context[\"args\"]}))\n\t            reply = e_context['reply']\n", "            if reply:\n\t                reply = '@' + msg['ActualNickName'] + ' ' + reply.strip()\n\t                self.send(channel_conf_val(const.WECHAT, \"group_chat_reply_prefix\", \"\") + reply, msg['User']['UserName'])\n\t    def check_prefix(self, content, prefix_list):\n\t        for prefix in prefix_list:\n\t            if content.startswith(prefix):\n\t                return prefix\n\t        return None\n\t    def check_contain(self, content, keyword_list):\n\t        if not keyword_list:\n", "            return None\n\t        for ky in keyword_list:\n\t            if content.find(ky) != -1:\n\t                return True\n\t        return None\n"]}
{"filename": "channel/wechat/wechat_mp_service_channel.py", "chunked_list": ["import werobot\n\tfrom config import channel_conf\n\tfrom common import const\n\tfrom common.log import logger\n\tfrom channel.channel import Channel\n\tfrom concurrent.futures import ThreadPoolExecutor\n\trobot = werobot.WeRoBot(token=channel_conf(const.WECHAT_MP).get('token'))\n\tthread_pool = ThreadPoolExecutor(max_workers=8)\n\t@robot.text\n\tdef hello_world(msg):\n", "    logger.info('[WX_Public] receive public msg: {}, userId: {}'.format(msg.content, msg.source))\n\t    return WechatServiceAccount().handle(msg)\n\tclass WechatServiceAccount(Channel):\n\t    def startup(self):\n\t        logger.info('[WX_Public] Wechat Public account service start!')\n\t        robot.config['PORT'] = channel_conf(const.WECHAT_MP).get('port')\n\t        robot.config[\"APP_ID\"] = channel_conf(const.WECHAT_MP).get('app_id')\n\t        robot.config[\"APP_SECRET\"] = channel_conf(const.WECHAT_MP).get('app_secret')\n\t        robot.config['HOST'] = '0.0.0.0'\n\t        robot.run()\n", "    def handle(self, msg, count=0):\n\t        context = {}\n\t        context['from_user_id'] = msg.source\n\t        thread_pool.submit(self._do_send, msg.content, context)\n\t        return \"正在思考中...\"\n\t    def _do_send(self, query, context):\n\t        reply_text = super().build_reply_content(query, context)\n\t        logger.info('[WX_Public] reply content: {}'.format(reply_text))\n\t        client = robot.client\n\t        client.send_text_message(context['from_user_id'], reply_text)\n"]}
{"filename": "channel/qq/qq_channel.py", "chunked_list": ["from channel.channel import Channel\n\tfrom aiocqhttp import CQHttp, Event\n\tfrom common import log\n\tfrom concurrent.futures import ThreadPoolExecutor\n\tbot = CQHttp(api_root='http://127.0.0.1:5700')\n\tthread_pool = ThreadPoolExecutor(max_workers=8)\n\t@bot.on_message('private')\n\tdef handle_private_msg(event: Event):\n\t    log.info(\"event: {}\", event)\n\t    QQChannel().handle(event)\n", "@bot.on_message('group')\n\tdef handle_private_msg(event: Event):\n\t    log.info(\"event: {}\", event)\n\t    QQChannel().handle_group(event)\n\tclass QQChannel(Channel):\n\t    def startup(self):\n\t        bot.run(host='127.0.0.1', port=8080)\n\t    # private chat\n\t    def handle(self, msg):\n\t        thread_pool.submit(self._do_handle, msg)\n", "    def _do_handle(self, msg):\n\t        context = dict()\n\t        log.info(\"event: {}\", \"do_handle\")\n\t        context['from_user_id'] = msg.user_id\n\t        reply_text = super().build_reply_content(msg.message, context)\n\t        bot.sync.send_private_msg(user_id=msg.user_id, message=reply_text)\n\t    # group chat\n\t    def handle_group(self, msg):\n\t        thread_pool.submit(self._do_handle_group, msg)\n\t    def _do_handle_group(self, msg):\n", "        context = dict()\n\t        if msg.message and msg.message.find('CQ:at'):\n\t            receiver = msg.message.split('qq=')[1].split(']')[0]\n\t            if receiver == str(msg['self_id']):\n\t                text_list = msg.message.split(']', 2)\n\t                if len(text_list) == 2 and len(text_list[1]) > 0:\n\t                    query = text_list[1].strip()\n\t                    context['from_user_id'] = str(msg.user_id)\n\t                    reply_text = super().build_reply_content(query, context)\n\t                    reply_text = '[CQ:at,qq=' + str(msg.user_id) + '] ' + reply_text\n", "                    bot.sync.send_group_msg(group_id=msg['group_id'], message=reply_text)\n"]}
{"filename": "channel/discord/discord_channel.py", "chunked_list": ["# encoding:utf-8\n\t\"\"\"\n\tdiscord channel\n\tPython discord - https://github.com/Rapptz/discord.py.git\n\t\"\"\"\n\tfrom channel.channel import Channel\n\tfrom common.log import logger\n\tfrom config import conf, common_conf_val, channel_conf\n\timport ssl\n\timport discord\n", "from discord.ext import commands\n\tclass DiscordChannel(Channel):\n\t    def __init__(self):\n\t        config = conf()\n\t        self.token = channel_conf('discord').get('app_token')\n\t        self.discord_channel_name = channel_conf('discord').get('channel_name')\n\t        self.discord_channel_session = channel_conf('discord').get('channel_session', 'author')\n\t        self.voice_enabled = channel_conf('discord').get('voice_enabled', False)\n\t        self.cmd_clear_session = common_conf_val('clear_memory_commands', ['#清除记忆'])[0]\n\t        self.sessions = []\n", "        self.intents = discord.Intents.default()\n\t        self.intents.message_content = True\n\t        self.intents.guilds = True\n\t        self.intents.members = True\n\t        self.intents.messages = True\n\t        self.intents.voice_states = True\n\t        context = ssl.create_default_context()\n\t        context.load_verify_locations(common_conf_val('certificate_file'))\n\t        self.bot = commands.Bot(command_prefix='!', intents=self.intents, ssl=context)\n\t        self.bot.add_listener(self.on_ready)\n", "        logger.debug('cmd_clear_session %s', self.cmd_clear_session)\n\t    def startup(self):\n\t        self.bot.add_listener(self.on_message)\n\t        self.bot.add_listener(self.on_guild_channel_delete)\n\t        self.bot.add_listener(self.on_guild_channel_create)\n\t        self.bot.add_listener(self.on_private_channel_delete)\n\t        self.bot.add_listener(self.on_private_channel_create)\n\t        self.bot.add_listener(self.on_channel_delete)\n\t        self.bot.add_listener(self.on_channel_create)\n\t        self.bot.add_listener(self.on_thread_delete)\n", "        self.bot.add_listener(self.on_thread_create)\n\t        self.bot.run(self.token)\n\t    async def on_ready(self):\n\t        logger.info('Bot is online user:{}'.format(self.bot.user))\n\t        if self.voice_enabled == False: \n\t            logger.debug('disable music')\n\t            await self.bot.remove_cog(\"Music\")\n\t    async def join(self, ctx):\n\t        logger.debug('join %s', repr(ctx))\n\t        channel = ctx.author.voice.channel\n", "        await channel.connect()\n\t    async def _do_on_channel_delete(self, channel):\n\t        if not self.discord_channel_name or channel.name != self.discord_channel_name:\n\t            logger.debug('skip _do_on_channel_delete %s', channel.name)\n\t            return\n\t        for name in self.sessions:\n\t            try:\n\t                response = self.send_text(name, self.cmd_clear_session)\n\t                logger.debug('_do_on_channel_delete %s %s', channel.name, response)\n\t            except Exception as e:\n", "                logger.warn('clear session except, id:%s', name)\n\t        self.sessions.clear()\n\t    async def on_guild_channel_delete(self, channel):\n\t        logger.debug('on_guild_channel_delete %s', repr(channel))\n\t        await self._do_on_channel_delete(channel)\n\t    async def on_guild_channel_create(self, channel):\n\t        logger.debug('on_guild_channel_create %s', repr(channel))\n\t    async def on_private_channel_delete(self, channel):\n\t        logger.debug('on_channel_delete %s', repr(channel))\n\t        await self._do_on_channel_delete(channel)\n", "    async def on_private_channel_create(self, channel):\n\t        logger.debug('on_channel_create %s', repr(channel))\n\t    async def on_channel_delete(self, channel):\n\t        logger.debug('on_channel_delete %s', repr(channel))\n\t    async def on_channel_create(self, channel):\n\t        logger.debug('on_channel_create %s', repr(channel))\n\t    async def on_thread_delete(self, thread):\n\t        print('on_thread_delete', thread)\n\t        if self.discord_channel_session != 'thread' or thread.parent.name != self.discord_channel_name:\n\t            logger.debug('skip on_thread_delete %s', thread.id)\n", "            return\n\t        try:\n\t            response = self.send_text(thread.id, self.cmd_clear_session)\n\t            if thread.id in self.sessions:\n\t                self.sessions.remove(thread.id)\n\t            logger.debug('on_thread_delete %s %s', thread.id, response)\n\t        except Exception as e:\n\t            logger.warn('on_thread_delete except %s', thread.id)\n\t            raise e\n\t    async def on_thread_create(self, thread):\n", "        logger.debug('on_thread_create %s', thread.id) \n\t        if self.discord_channel_session != 'thread' or thread.parent.name != self.discord_channel_name:\n\t            logger.debug('skip on_channel_create %s', repr(thread))\n\t            return\n\t        self.sessions.append(thread.id)\n\t    async def on_message(self, message):\n\t        \"\"\"\n\t        listen for message event\n\t        \"\"\"\n\t        await self.bot.wait_until_ready()\n", "        if not self.check_message(message):\n\t            return\n\t        prompt = message.content.strip();\n\t        logger.debug('author: %s', message.author)\n\t        logger.debug('prompt: %s', prompt)\n\t        session_id = message.author\n\t        if self.discord_channel_session == 'thread' and isinstance(message.channel, discord.Thread):\n\t            logger.debug('on_message thread id %s', message.channel.id)\n\t            session_id = message.channel.id\n\t        await message.channel.send('...')\n", "        response = response = self.send_text(session_id, prompt)\n\t        await message.channel.send(response)\n\t    def check_message(self, message):\n\t        if message.author == self.bot.user:\n\t            return False\n\t        prompt = message.content.strip();\n\t        if not prompt:\n\t            logger.debug('no prompt author: %s', message.author)\n\t            return False\n\t        if self.discord_channel_name:\n", "            if isinstance(message.channel, discord.Thread) and message.channel.parent.name == self.discord_channel_name:\n\t                return True\n\t            if not isinstance(message.channel, discord.Thread) and self.discord_channel_session != 'thread' and message.channel.name == self.discord_channel_name:\n\t                return True\n\t            logger.debug(\"The accessed channel does not meet the discord channel configuration conditions.\")\n\t            return False\n\t        else:\n\t            return True\n\t    def send_text(self, id, content):\n\t        context = dict()\n", "        context['type'] = 'TEXT'\n\t        context['from_user_id'] = id\n\t        context['content'] = content\n\t        return super().build_reply_content(content, context)"]}
{"filename": "channel/http/auth.py", "chunked_list": ["# encoding:utf-8\n\timport jwt\n\timport datetime\n\timport time\n\tfrom flask import jsonify, request\n\tfrom common import const\n\tfrom config import channel_conf\n\tclass Auth():\n\t    def __init__(self, login):\n\t    # argument 'privilegeRequired' is to set up your method's privilege\n", "    # name\n\t        self.login = login\n\t        super(Auth, self).__init__()\n\t    @staticmethod\n\t    def encode_auth_token(user_id, login_time):\n\t        \"\"\"\n\t        生成认证Token\n\t        :param user_id: int\n\t        :param login_time: datetime\n\t        :return: string\n", "        \"\"\"\n\t        try:\n\t            payload = {\n\t                'iss': 'ken',  # 签名\n\t                'exp': datetime.datetime.utcnow() + datetime.timedelta(days=0, hours=10),  # 过期时间\n\t                'iat': datetime.datetime.utcnow(),  # 开始时间\n\t                'data': {\n\t                    'id': user_id,\n\t                    'login_time': login_time\n\t                }\n", "            }\n\t            return jwt.encode(\n\t                payload,\n\t                channel_conf(const.HTTP).get('http_auth_secret_key'),\n\t                algorithm='HS256'\n\t            )  # 加密生成字符串\n\t        except Exception as e:\n\t            return e\n\t    @staticmethod\n\t    def decode_auth_token(auth_token):\n", "        \"\"\"\n\t        验证Token\n\t        :param auth_token:\n\t        :return: integer|string\n\t        \"\"\"\n\t        try:\n\t            # 取消过期时间验证\n\t            payload = jwt.decode(auth_token, channel_conf(const.HTTP).get(\n\t                'http_auth_secret_key'), algorithms='HS256')  # options={'verify_exp': False} 加上后不验证token过期时间\n\t            if ('data' in payload and 'id' in payload['data']):\n", "                return payload\n\t            else:\n\t                raise jwt.InvalidTokenError\n\t        except jwt.ExpiredSignatureError:\n\t            return 'Token过期'\n\t        except jwt.InvalidTokenError:\n\t            return '无效Token'\n\tdef authenticate(password):\n\t    \"\"\"\n\t    用户登录，登录成功返回token\n", "    :param password:\n\t    :return: json\n\t    \"\"\"\n\t    authPassword = channel_conf(const.HTTP).get('http_auth_password')\n\t    if (authPassword != password):\n\t        return False\n\t    else:\n\t        login_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n\t        token = Auth.encode_auth_token(password, login_time)\n\t        return token\n", "def identify(request):\n\t    \"\"\"\n\t    用户鉴权\n\t    :return: list\n\t    \"\"\"\n\t    try:\n\t        authPassword = channel_conf(const.HTTP).get('http_auth_password')\n\t        if (not authPassword):\n\t            return True\n\t        if (request is None):\n", "            return False\n\t        authorization = request.cookies.get('Authorization')\n\t        if (authorization):\n\t            payload = Auth.decode_auth_token(authorization)\n\t            if not isinstance(payload, str):\n\t                authPassword = channel_conf(\n\t                    const.HTTP).get('http_auth_password')\n\t                password = payload['data']['id']\n\t                if (password != authPassword):\n\t                    return False\n", "                else:\n\t                    return True\n\t        return False\n\t    except jwt.ExpiredSignatureError:\n\t        #result = 'Token已更改，请重新登录获取'\n\t        return False\n\t    except jwt.InvalidTokenError:\n\t        #result = '没有提供认证token'\n\t        return False\n"]}
{"filename": "channel/http/http_channel.py", "chunked_list": ["# encoding:utf-8\n\timport asyncio\n\timport json\n\tfrom channel.http import auth\n\tfrom flask import Flask, request, render_template, make_response\n\tfrom datetime import timedelta\n\tfrom common import const\n\tfrom common import functions\n\tfrom config import channel_conf\n\tfrom config import channel_conf_val\n", "from channel.channel import Channel\n\tfrom flask_socketio import SocketIO\n\tfrom common import log\n\tfrom plugins.plugin_manager import *\n\thttp_app = Flask(__name__,)\n\tsocketio = SocketIO(http_app, close_timeout=5)\n\t# 自动重载模板文件\n\thttp_app.jinja_env.auto_reload = True\n\thttp_app.config['TEMPLATES_AUTO_RELOAD'] = True\n\t# 设置静态文件缓存过期时间\n", "http_app.config['SEND_FILE_MAX_AGE_DEFAULT'] = timedelta(seconds=1)\n\tasync def return_stream(data):\n\t    async for final, response in HttpChannel().handle_stream(data=data):\n\t        try:\n\t            if (final):\n\t                socketio.server.emit(\n\t                    'disconnect', {'result': response, 'final': final}, request.sid, namespace=\"/chat\")\n\t                disconnect()\n\t            else:\n\t                socketio.server.emit(\n", "                    'message', {'result': response, 'final': final}, request.sid, namespace=\"/chat\")\n\t        except Exception as e:\n\t            disconnect()\n\t            log.warn(\"[http]emit:{}\", e)\n\t            break\n\t@socketio.on('message', namespace='/chat')\n\tdef stream(data):\n\t    if (auth.identify(request) == False):\n\t        client_sid = request.sid\n\t        socketio.server.disconnect(client_sid)\n", "        return\n\t    data = json.loads(data[\"data\"])\n\t    if (data):\n\t        img_match_prefix = functions.check_prefix(\n\t            data[\"msg\"], channel_conf_val(const.HTTP, 'image_create_prefix'))\n\t        if img_match_prefix:\n\t            reply_text = HttpChannel().handle(data=data)\n\t            socketio.emit(\n\t                'disconnect', {'result': reply_text}, namespace='/chat')\n\t            disconnect()\n", "            return\n\t        asyncio.run(return_stream(data))\n\t@socketio.on('connect', namespace='/chat')\n\tdef connect():\n\t    log.info('connected')\n\t    socketio.emit('message', {'info': \"connected\"}, namespace='/chat')\n\t@socketio.on('disconnect', namespace='/chat')\n\tdef disconnect():\n\t    log.info('disconnect')\n\t    socketio.server.disconnect(request.sid, namespace=\"/chat\")\n", "@http_app.route(\"/chat\", methods=['POST'])\n\tdef chat():\n\t    if (auth.identify(request) == False):\n\t        return\n\t    data = json.loads(request.data)\n\t    if data:\n\t        msg = data['msg']\n\t        if not msg:\n\t            return\n\t        reply_text = HttpChannel().handle(data=data)\n", "        return {'result': reply_text}\n\t@http_app.route(\"/\", methods=['GET'])\n\tdef index():\n\t    if (auth.identify(request) == False):\n\t        return login()\n\t    return render_template('index.html')\n\t@http_app.route(\"/login\", methods=['POST', 'GET'])\n\tdef login():\n\t    response = make_response(\"<html></html>\", 301)\n\t    response.headers.add_header('content-type', 'text/plain')\n", "    response.headers.add_header('location', './')\n\t    if (auth.identify(request) == True):\n\t        return response\n\t    else:\n\t        if request.method == \"POST\":\n\t            token = auth.authenticate(request.form['password'])\n\t            if (token != False):\n\t                response.set_cookie(key='Authorization', value=token)\n\t                return response\n\t        else:\n", "            return render_template('login.html')\n\t    response.headers.set('location', './login?err=登录失败')\n\t    return response\n\tclass HttpChannel(Channel):\n\t    def startup(self):\n\t        http_app.run(host='0.0.0.0', port=channel_conf(const.HTTP).get('port'))\n\t    def handle(self, data):\n\t        context = dict()\n\t        query = data[\"msg\"]\n\t        id = data[\"id\"]\n", "        context['from_user_id'] = str(id)\n\t        e_context = PluginManager().emit_event(EventContext(Event.ON_HANDLE_CONTEXT, {\n\t            'channel': self, 'context': query,  \"args\": context}))\n\t        reply = e_context['reply']\n\t        if not e_context.is_pass():\n\t            reply = super().build_reply_content(e_context[\"context\"], e_context[\"args\"])\n\t            e_context = PluginManager().emit_event(EventContext(Event.ON_DECORATE_REPLY, {\n\t                'channel': self, 'context': context, 'reply': reply, \"args\": context}))\n\t            reply = e_context['reply']\n\t        return reply\n", "    async def handle_stream(self, data):\n\t        context = dict()\n\t        id = data[\"id\"]\n\t        context['from_user_id'] = str(id)\n\t        context['stream'] = True\n\t        context['origin'] = data[\"msg\"]\n\t        e_context = PluginManager().emit_event(EventContext(Event.ON_HANDLE_CONTEXT, {\n\t            'channel': self, 'context': data[\"msg\"], 'reply': data[\"msg\"], \"args\": context}))\n\t        reply = e_context['reply']\n\t        if not e_context.is_pass():\n", "            async for final, reply in super().build_reply_stream(data[\"msg\"], context):\n\t                yield final, reply\n\t        else:\n\t            yield True, reply\n"]}
{"filename": "channel/slack/slack_channel.py", "chunked_list": ["import re\n\tfrom slack_bolt import App\n\tfrom slack_bolt.adapter.socket_mode import SocketModeHandler\n\tfrom common import const\n\tfrom common.log import logger\n\tfrom channel.channel import Channel\n\tfrom config import channel_conf\n\t# 创建 Slack Bolt 实例\n\tapp = App(token=channel_conf(const.SLACK).get('slack_bot_token'))\n\t# 创建 SocketModeHandler 实例\n", "handler = SocketModeHandler(app=app,\n\t                            app_token=channel_conf(const.SLACK).get('slack_app_token'))\n\t# 监听 Slack app_mention 事件\n\t@app.event(\"app_mention\")\n\tdef handle_mention(event, say):\n\t    if 'thread_ts' in event:\n\t        ts = event[\"thread_ts\"]\n\t    else:\n\t        ts = event[\"ts\"]\n\t    reply_text = SlackChannel().handle(event)\n", "    say(text=f\"{reply_text}\", thread_ts=ts)\n\tclass SlackChannel(Channel):\n\t    def startup(self):\n\t        handler.start()\n\t    def handle(self, event):\n\t        context = dict()\n\t        if 'thread_ts' in event:\n\t            ts = event[\"thread_ts\"]\n\t        else:\n\t            ts = event[\"ts\"]\n", "        context['from_user_id'] = str(ts)\n\t        # 使用正则表达式去除 @xxxx\n\t        plain_text = re.sub(r\"<@\\w+>\", \"\", event[\"text\"])\n\t        return super().build_reply_content(plain_text, context)\n"]}
{"filename": "channel/gmail/gmail_channel.py", "chunked_list": ["import smtplib\n\timport imaplib\n\timport email\n\timport re\n\timport base64\n\timport time\n\tfrom random import randrange\n\tfrom email.mime.text import MIMEText\n\tfrom email.header import decode_header\n\tfrom channel.channel import Channel\n", "from concurrent.futures import ThreadPoolExecutor\n\tfrom common import const\n\tfrom config import channel_conf_val, channel_conf\n\tsmtp_ssl_host = 'smtp.gmail.com: 587'\n\timap_ssl_host = 'imap.gmail.com'\n\tMAX_DELAY = 30\n\tMIN_DELAY = 15\n\tSTEP_TIME = 2\n\tLATESTN = 5\n\twait_time = 0\n", "thread_pool = ThreadPoolExecutor(max_workers=8)\n\tdef checkEmail(email):\n\t    # regex = '^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$'\n\t    regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n\t    if re.search(regex, email):\n\t        return True\n\t    else:\n\t        return False\n\tdef process(max, speed):\n\t    global wait_time\n", "    i=0\n\t    while i<=max:\n\t        i=i+1\n\t        time.sleep(speed)\n\t        print(\"\\r\"+\"Waited: \"+str(i+wait_time)+\"s\", end='')\n\t        # print(\"\\r\"+\"===\"*int(i-1)+\":-)\"+\"===\"*int(max-i)+\"$\"+str(max)+'  waited:'+str(i)+\"%\", end='')\n\t    wait_time += max*speed\n\tclass GmailChannel(Channel):\n\t    def __init__(self):\n\t        self.host_email = channel_conf_val(const.GMAIL, 'host_email')\n", "        self.host_password = channel_conf_val(const.GMAIL, 'host_password')\n\t        # self.addrs_white_list = channel_conf_val(const.GMAIL, 'addrs_white_list')\n\t        self.subject_keyword = channel_conf_val(const.GMAIL, 'subject_keyword')\n\t    def startup(self):\n\t        global wait_time\n\t        ques_list = list()\n\t        lastques = {'from': None, 'subject': None, 'content': None}\n\t        print(\"INFO: let's go...\")\n\t        while(True):\n\t            ques_list = self.receiveEmail()\n", "            if ques_list:\n\t                for ques in ques_list:\n\t                    if ques['subject'] is None:\n\t                        print(\"WARN: question from:%s is empty \" % ques['from'])\n\t                    elif(lastques['subject'] == ques['subject'] and lastques['from'] == ques['from']):\n\t                        print(\"INFO: this question has already been answered. Q:%s\" % (ques['subject']))\n\t                    else:\n\t                        if ques['subject']:\n\t                            print(\"Nice: a new message coming...\", end='\\n')\n\t                            self.handle(ques) \n", "                            lastques = ques\n\t                            wait_time = 0\n\t                        else: \n\t                            print(\"WARN: the question in subject is empty\")\n\t            else: \n\t                process(randrange(MIN_DELAY, MAX_DELAY), STEP_TIME)\n\t    def handle(self, question):\n\t        message = dict()\n\t        context = dict()\n\t        print(\"INFO: From: %s Question: %s\" % (question['from'], question['subject']))\n", "        context['from_user_id'] = question['from']\n\t        answer = super().build_reply_content(question['subject'], context) #get answer from openai\n\t        message = MIMEText(answer)\n\t        message['subject'] = question['subject']\n\t        message['from'] = self.host_email\n\t        message['to'] = question['from']\n\t        thread_pool.submit(self.sendEmail, message)\n\t    def sendEmail(self, message: list) -> dict:\n\t        smtp_server = smtplib.SMTP(smtp_ssl_host)\n\t        smtp_server.starttls()\n", "        smtp_server.login(self.host_email, self.host_password)\n\t        output = {'success': 0, 'failed': 0, 'invalid': 0}\n\t        try:\n\t            smtp_server.sendmail(message['from'], message['to'], message.as_string())\n\t            print(\"sending to {}\".format(message['to']))\n\t            output['success'] += 1\n\t        except Exception as e:\n\t            print(\"Error: {}\".format(e))\n\t            output['failed'] += 1\n\t        print(\"successed:{}, failed:{}\".format(output['success'], output['failed']))\n", "        smtp_server.quit()\n\t        return output\n\t    def receiveEmail(self):\n\t        question_list = list()\n\t        question = {'from': None, 'subject': None, 'content': None}\n\t        imap_server = imaplib.IMAP4_SSL(imap_ssl_host)\n\t        imap_server.login(self.host_email, self.host_password)\n\t        imap_server.select('inbox')\n\t        status, data = imap_server.search(None, 'ALL')\n\t        mail_ids = []\n", "        for block in data:\n\t            mail_ids += block.split()\n\t        #only fetch the latest 5 messages\n\t        mail_ids = mail_ids[-LATESTN:]\n\t        for i in mail_ids:\n\t            status, data = imap_server.fetch(i, '(RFC822)')\n\t            for response in data:\n\t                if isinstance(response, tuple):\n\t                    message = email.message_from_bytes(response[1])\n\t                    mail_from = message['from'].split('<')[1].replace(\">\", \"\")\n", "                    # if mail_from not in self.addrs_white_list:\n\t                    #     continue\n\t                    #subject do not support chinese\n\t                    mail_subject = decode_header(message['subject'])[0][0]\n\t                    if isinstance(mail_subject, bytes):\n\t                        # UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc5\n\t                        try:\n\t                            mail_subject = mail_subject.decode()\n\t                        except UnicodeDecodeError:\n\t                            mail_subject = mail_subject.decode('latin-1')\n", "                    if not self.check_contain(mail_subject, self.subject_keyword):   #check subject here\n\t                        continue\n\t                    if message.is_multipart(): \n\t                        mail_content = ''\n\t                        for part in message.get_payload():\n\t                            flag=False\n\t                            if isinstance(part.get_payload(), list): \n\t                                    part = part.get_payload()[0]\n\t                                    flag = True\n\t                            if part.get_content_type()  in ['text/plain', 'multipart/alternative']: \n", "                                #TODO some string can't be decode\n\t                                if flag:\n\t                                    mail_content += str(part.get_payload())\n\t                                else: \n\t                                    try:\n\t                                        mail_content += base64.b64decode(str(part.get_payload())).decode(\"utf-8\")\n\t                                    except UnicodeDecodeError:\n\t                                        mail_content += base64.b64decode(str(part.get_payload())).decode('latin-1')\n\t                    else:\n\t                        mail_content = message.get_payload()\n", "                    question['from'] = mail_from\n\t                    question['subject'] = ' '.join(mail_subject.split(' ')[1:])\n\t                    question['content'] = mail_content\n\t                    # print(f'\\nFrom: {mail_from}')\n\t                    print(f'\\n\\nSubject: {mail_subject}')\n\t                    # print(f'Content: {mail_content.replace(\" \", \"\")}')\n\t                    question_list.append(question)\n\t                    question = {'from': None, 'subject': None, 'content': None}\n\t                    imap_server.store(i, \"+FLAGS\", \"\\\\Deleted\") #delete the mail i\n\t                    print(\"INFO: deleting mail: %s\" % mail_subject)\n", "        imap_server.expunge()\n\t        imap_server.close()\n\t        imap_server.logout()\n\t        return question_list\n\t    def check_contain(self, content, keyword_list):\n\t        if not keyword_list:\n\t            return None\n\t        for ky in keyword_list:\n\t            if content.find(ky) != -1:\n\t                return True\n", "        return None \n"]}
{"filename": "channel/telegram/telegram_channel.py", "chunked_list": ["from concurrent.futures import ThreadPoolExecutor\n\timport io\n\timport requests\n\timport telebot\n\tfrom common import const\n\tfrom common.log import logger\n\tfrom channel.channel import Channel\n\tfrom config import channel_conf_val, channel_conf\n\tbot = telebot.TeleBot(token=channel_conf(const.TELEGRAM).get('bot_token'))\n\tthread_pool = ThreadPoolExecutor(max_workers=8)\n", "@bot.message_handler(commands=['help'])\n\tdef send_welcome(message):\n\t    bot.send_message(message.chat.id, \"<a>我是chatGPT机器人，开始和我聊天吧!</a>\", parse_mode = \"HTML\")\n\t# 处理文本类型消息\n\t@bot.message_handler(content_types=['text'])\n\tdef send_welcome(msg):\n\t    # telegram消息处理\n\t    TelegramChannel().handle(msg)\n\tclass TelegramChannel(Channel):\n\t    def __init__(self):\n", "        pass\n\t    def startup(self):\n\t        logger.info(\"开始启动[telegram]机器人\")\n\t        bot.infinity_polling()\n\t    def handle(self, msg):\n\t        logger.debug(\"[Telegram] receive msg: \" + msg.text)\n\t        img_match_prefix = self.check_prefix(msg, channel_conf_val(const.TELEGRAM, 'image_create_prefix'))\n\t        # 如果是图片请求\n\t        if img_match_prefix:\n\t            thread_pool.submit(self._do_send_img, msg, str(msg.chat.id))\n", "        else:\n\t            thread_pool.submit(self._dosend,msg.text,msg)\n\t    def _dosend(self,query,msg):\n\t        context= dict()\n\t        context['from_user_id'] = str(msg.chat.id)\n\t        reply_text = super().build_reply_content(query, context)\n\t        logger.info('[Telegram] reply content: {}'.format(reply_text))\n\t        bot.reply_to(msg,reply_text)\n\t    def _do_send_img(self, msg, reply_user_id):\n\t        try:\n", "            if not msg:\n\t                return\n\t            context = dict()\n\t            context['type'] = 'IMAGE_CREATE'\n\t            img_urls = super().build_reply_content(msg.text, context)\n\t            if not img_urls:\n\t                return\n\t            if not isinstance(img_urls, list):\n\t                bot.reply_to(msg,img_urls)\n\t                return\n", "            for url in img_urls:\n\t            # 图片下载\n\t                pic_res = requests.get(url, stream=True)\n\t                image_storage = io.BytesIO()\n\t                for block in pic_res.iter_content(1024):\n\t                    image_storage.write(block)\n\t                image_storage.seek(0)\n\t                # 图片发送\n\t                logger.info('[Telegrame] sendImage, receiver={}'.format(reply_user_id))\n\t                bot.send_photo(msg.chat.id,image_storage)\n", "        except Exception as e:\n\t            logger.exception(e)\n\t    def check_prefix(self, msg, prefix_list):\n\t        if not prefix_list:\n\t            return None\n\t        for prefix in prefix_list:\n\t            if msg.text.startswith(prefix):\n\t                return prefix\n\t        return None\n"]}
{"filename": "channel/feishu/store.py", "chunked_list": ["# -*- coding: UTF-8 -*-\n\timport time\n\tfrom threading import Lock\n\tclass Store(object):\n\t    \"\"\"\n\t    This is an interface to storage (Key, Value) pairs for sdk.\n\t    \"\"\"\n\t    def get(self, key):  # type: (str) -> Tuple[bool, str]\n\t        return False, ''\n\t    def set(self, key, value, expire):  # type: (str, str, int) -> None\n", "        \"\"\"\n\t        storage key, value into the store, value has an expire time.(unit: second)\n\t        \"\"\"\n\t        pass\n\tclass ExpireValue(object):\n\t    def __init__(self, value, expireTime):  # type: (str, int) -> None\n\t        self.value = value\n\t        self.expireTime = expireTime\n\tclass MemoryStore(Store):\n\t    \"\"\"\n", "    This is an implement of `StoreInterface` which stores data in the memory\n\t    \"\"\"\n\t    def __init__(self):  # type: () -> None\n\t        self.data = {}  # type: Dict[str, ExpireValue]\n\t        self.mutex = Lock()  # type: Lock\n\t    def get(self, key):  # type: (str) -> Tuple[bool, str]\n\t        # print('get %s' % key)\n\t        self.mutex.acquire()\n\t        try:\n\t            val = self.data.get(key)\n", "            if val is None:\n\t                return False, \"\"\n\t            else:\n\t                if val.expireTime == -1:\n\t                    return True, val.value\n\t                elif val.expireTime < int(time.time()):\n\t                    self.data.pop(key)\n\t                    return False, \"\"\n\t                else:\n\t                    return True, val.value\n", "        finally:\n\t            self.mutex.release()\n\t    def set(self, key, value, expire=None):  # type: (str, str, int) -> None\n\t        # print('put %s=%s, expire=%s' % (key, value, expire))\n\t        \"\"\"\n\t        storage key, value into the store, value has an expire time.(unit: second)\n\t        \"\"\"\n\t        self.mutex.acquire()\n\t        try:\n\t            self.data[key] = ExpireValue(\n", "                value, expire == None and -1 or int(time.time()) + expire)\n\t        finally:\n\t            self.mutex.release()\n"]}
{"filename": "channel/feishu/feishu_channel.py", "chunked_list": ["# encoding:utf-8\n\timport json\n\timport hmac\n\timport hashlib\n\timport base64\n\timport time\n\timport requests\n\tfrom urllib.parse import quote_plus\n\tfrom common import log\n\tfrom flask import Flask, request, render_template, make_response\n", "from common import const\n\tfrom common import functions\n\tfrom config import channel_conf\n\tfrom config import channel_conf_val\n\tfrom channel.channel import Channel\n\tfrom urllib import request as url_request\n\tfrom channel.feishu.store import MemoryStore\n\tclass FeiShuChannel(Channel):\n\t    def __init__(self):\n\t        self.app_id = channel_conf(\n", "            const.FEISHU).get('app_id')\n\t        self.app_secret = channel_conf(\n\t            const.FEISHU).get('app_secret')\n\t        self.verification_token = channel_conf(\n\t            const.FEISHU).get('verification_token')\n\t        log.info(\"[FeiShu] app_id={}, app_secret={} verification_token={}\".format(\n\t            self.app_id, self.app_secret, self.verification_token))\n\t        self.memory_store = MemoryStore()\n\t    def startup(self):\n\t        http_app.run(host='0.0.0.0', port=channel_conf(\n", "            const.FEISHU).get('port'))\n\t    def get_tenant_access_token(self):\n\t        url = \"https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal/\"\n\t        headers = {\n\t            \"Content-Type\": \"application/json\"\n\t        }\n\t        req_body = {\n\t            \"app_id\": self.app_id,\n\t            \"app_secret\": self.app_secret\n\t        }\n", "        data = bytes(json.dumps(req_body), encoding='utf8')\n\t        req = url_request.Request(url=url, data=data,\n\t                              headers=headers, method='POST')\n\t        try:\n\t            response = url_request.urlopen(req)\n\t        except Exception as e:\n\t            print(e.read().decode())\n\t            return \"\"\n\t        rsp_body = response.read().decode('utf-8')\n\t        rsp_dict = json.loads(rsp_body)\n", "        code = rsp_dict.get(\"code\", -1)\n\t        if code != 0:\n\t            print(\"get tenant_access_token error, code =\", code)\n\t            return \"\"\n\t        return rsp_dict.get(\"tenant_access_token\", \"\")\n\t    def notify_feishu(self, token, receive_type, receive_id, at_id, answer):\n\t        log.info(\"notify_feishu.receive_type = {} receive_id={}\",\n\t                 receive_type, receive_id)\n\t        url = \"https://open.feishu.cn/open-apis/im/v1/messages\"\n\t        params = {\"receive_id_type\": receive_type}\n", "        # text = at_id and \"<at user_id=\\\"%s\\\">%s</at>\" % (\n\t        #     at_id, answer.lstrip()) or answer.lstrip()\n\t        text = answer.lstrip()\n\t        log.info(\"notify_feishu.text = {}\", text)\n\t        msgContent = {\n\t            \"text\": text,\n\t        }\n\t        req = {\n\t            \"receive_id\": receive_id,  # chat id\n\t            \"msg_type\": \"text\",\n", "            \"content\": json.dumps(msgContent),\n\t        }\n\t        payload = json.dumps(req)\n\t        headers = {\n\t            # your access token\n\t            \"Authorization\": \"Bearer \" + token,\n\t            \"Content-Type\": \"application/json\",\n\t        }\n\t        response = requests.request(\n\t            \"POST\", url, params=params, headers=headers, data=payload\n", "        )\n\t        log.info(\"notify_feishu.response.content = {}\", response.content)\n\t    def handle(self, message):\n\t        event = message[\"event\"]\n\t        msg = event[\"message\"]\n\t        messageId = msg[\"message_id\"]\n\t        chat_type = msg[\"chat_type\"]\n\t        sender_id = event[\"sender\"][\"sender_id\"][\"open_id\"]\n\t        prompt = json.loads(msg[\"content\"])[\"text\"]\n\t        prompt = prompt.replace(\"@_user_1\", \"\")\n", "        #重复\n\t        r, v = self.memory_store.get(messageId)\n\t        if v:\n\t            return {'ret': 200}\n\t        self.memory_store.set(messageId, True)\n\t        # 非文本不处理\n\t        message_type = msg[\"message_type\"]\n\t        if message_type != \"text\":\n\t            return {'ret': 200}\n\t        if chat_type == \"group\":\n", "            mentions = msg[\"mentions\"]\n\t            # 日常群沟通要@才生效\n\t            if not mentions:\n\t                return {'ret': 200}\n\t            receive_type = \"chat_id\"\n\t            receive_id = msg.get(\"chat_id\")\n\t            at_id = sender_id\n\t        elif chat_type == \"p2p\":\n\t            receive_type = \"open_id\"\n\t            receive_id = sender_id\n", "            at_id = None\n\t        # 调用发消息 API 之前，先要获取 API 调用凭证：tenant_access_token\n\t        access_token = self.get_tenant_access_token()\n\t        if access_token == \"\":\n\t            log.error(\"send message access_token is empty\")\n\t            return {'ret': 204}\n\t        context = dict()\n\t        img_match_prefix = functions.check_prefix(\n\t            prompt, channel_conf_val(const.DINGTALK, 'image_create_prefix'))\n\t        if img_match_prefix:\n", "            prompt = prompt.split(img_match_prefix, 1)[1].strip()\n\t            context['type'] = 'IMAGE_CREATE'\n\t        context['from_user_id'] = str(sender_id)\n\t        reply = super().build_reply_content(prompt, context)\n\t        if img_match_prefix:\n\t            if not isinstance(reply, list):\n\t                return {'ret': 204}\n\t            images = \"\"\n\t            for url in reply:\n\t                images += f\"[!['IMAGE_CREATE']({url})]({url})\\n\"\n", "            reply = images\n\t        # 机器人 echo 收到的消息\n\t        self.notify_feishu(access_token, receive_type,\n\t                           receive_id, at_id, reply)\n\t        return {'ret': 200}\n\t    def handle_request_url_verify(self, post_obj):\n\t        # 原样返回 challenge 字段内容\n\t        challenge = post_obj.get(\"challenge\", \"\")\n\t        return {'challenge': challenge}\n\tfeishu = FeiShuChannel()\n", "http_app = Flask(__name__,)\n\t@http_app.route(\"/\", methods=['POST'])\n\tdef chat():\n\t    # log.info(\"[FeiShu] chat_headers={}\".format(str(request.headers)))\n\t    log.info(\"[FeiShu] chat={}\".format(str(request.data)))\n\t    obj = json.loads(request.data)\n\t    if not obj:\n\t        return {'ret': 201}\n\t    # 校验 verification token 是否匹配，token 不匹配说明该回调并非来自开发平台\n\t    headers = obj.get(\"header\")\n", "    if not headers:\n\t        return {'ret': 201}\n\t    token = headers.get(\"token\", \"\")\n\t    if token != feishu.verification_token:\n\t        log.error(\"verification token not match, token = {}\", token)\n\t        return {'ret': 201}\n\t    # 根据 type 处理不同类型事件\n\t    t = obj.get(\"type\", \"\")\n\t    if \"url_verification\" == t:  # 验证请求 URL 是否有效\n\t        return feishu.handle_request_url_verify(obj)\n", "    elif headers.get(\"event_type\", None) == \"im.message.receive_v1\":  # 事件回调\n\t        return feishu.handle(obj)\n\t    return {'ret': 202}\n"]}
