{"filename": "tests/test_args.py", "chunked_list": ["import pytest\n\t@pytest.mark.asyncio\n\tasync def test_pos_args_implicit_index(client):\n\t    rs = await client.execute(\"SELECT ?, ?\", [\"one\", \"two\"])\n\t    assert tuple(rs.rows[0]) == (\"one\", \"two\")\n\t@pytest.mark.asyncio\n\tasync def test_pos_args_explicit_index(client):\n\t    rs = await client.execute(\"SELECT ?2, ?3, ?1\", [\"one\", \"two\", \"three\"])\n\t    assert tuple(rs.rows[0]) == (\"two\", \"three\", \"one\")\n\t@pytest.mark.asyncio\n", "async def test_pos_args_explicit_index_with_holes(client):\n\t    rs = await client.execute(\"SELECT ?3, ?1\", [\"one\", \"two\", \"three\"])\n\t    assert tuple(rs.rows[0]) == (\"three\", \"one\")\n\t@pytest.mark.asyncio\n\tasync def test_pos_args_implicit_and_explicit_index(client):\n\t    rs = await client.execute(\"SELECT ?2, ?, ?3\", [\"one\", \"two\", \"three\"])\n\t    assert tuple(rs.rows[0]) == (\"two\", \"three\", \"three\")\n\t@pytest.mark.asyncio\n\t@pytest.mark.parametrize(\"sign\", [\":\", \"@\", \"$\"])\n\tasync def test_named_args(client, sign):\n", "    rs = await client.execute(\n\t        f\"SELECT {sign}b, {sign}a\", {\"a\": \"one\", f\"{sign}b\": \"two\"}\n\t    )\n\t    assert tuple(rs.rows[0]) == (\"two\", \"one\")\n\t@pytest.mark.asyncio\n\t@pytest.mark.parametrize(\"sign\", [\":\", \"@\", \"$\"])\n\tasync def test_named_args_used_multiple_times(client, sign):\n\t    rs = await client.execute(\n\t        f\"SELECT {sign}b, {sign}a, {sign}b || {sign}a\", {\"a\": \"one\", f\"{sign}b\": \"two\"}\n\t    )\n", "    assert tuple(rs.rows[0]) == (\"two\", \"one\", \"twoone\")\n\t@pytest.mark.asyncio\n\t@pytest.mark.parametrize(\"sign\", [\":\", \"@\", \"$\"])\n\tasync def test_named_args_and_pos_args(client, sign):\n\t    rs = await client.execute(\n\t        f\"SELECT {sign}b, {sign}a, ?1\", {\"a\": \"one\", f\"{sign}b\": \"two\"}\n\t    )\n\t    assert tuple(rs.rows[0]) == (\"two\", \"one\", \"two\")\n"]}
{"filename": "tests/test_network_errors.py", "chunked_list": ["import pytest\n\timport libsql_client\n\t@pytest.fixture(params=[\".close_ws\", \".close_tcp\"])\n\tdef trigger_net_error(request):\n\t    return request.param\n\t@pytest.mark.asyncio\n\tasync def test_execute(ws_client, trigger_net_error):\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await ws_client.execute(trigger_net_error)\n\t    assert excinfo.value.code == \"HRANA_WEBSOCKET_ERROR\"\n", "    rs = await ws_client.execute(\"SELECT 42\")\n\t    assert rs[0].astuple() == (42,)\n\t@pytest.mark.asyncio\n\tasync def test_batch(ws_client, trigger_net_error):\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await ws_client.batch([\"SELECT 42\", trigger_net_error, \"SELECT 24\"])\n\t    assert excinfo.value.code == \"HRANA_WEBSOCKET_ERROR\"\n\t    rs = await ws_client.execute(\"SELECT 42\")\n\t    assert rs[0].astuple() == (42,)\n\t@pytest.mark.asyncio\n", "async def test_transaction(ws_client, trigger_net_error):\n\t    txn = ws_client.transaction()\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await txn.execute(trigger_net_error)\n\t    assert excinfo.value.code == \"HRANA_WEBSOCKET_ERROR\"\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await txn.commit()\n\t    assert excinfo.value.code == \"HRANA_WEBSOCKET_ERROR\"\n\t    rs = await ws_client.execute(\"SELECT 42\")\n\t    assert rs[0].astuple() == (42,)\n"]}
{"filename": "tests/test_execute.py", "chunked_list": ["import pytest\n\timport libsql_client\n\t@pytest.mark.asyncio\n\tasync def test_query_value(client):\n\t    rs = await client.execute(\"SELECT 42\")\n\t    assert len(rs.columns) == 1\n\t    assert len(rs.rows) == 1\n\t    row = rs.rows[0]\n\t    assert len(row) == 1\n\t    assert row[0] == 42\n", "@pytest.mark.asyncio\n\tasync def test_query_row(client):\n\t    rs = await client.execute(\"SELECT 1 AS one, 'two' AS two, 0.5 AS three\")\n\t    assert rs.columns == (\"one\", \"two\", \"three\")\n\t    assert len(rs.rows) == 1\n\t    row = rs.rows[0]\n\t    assert len(row) == 3\n\t    assert (row[0], row[1], row[2]) == (1, \"two\", 0.5)\n\t    assert (row[\"one\"], row[\"two\"], row[\"three\"]) == (1, \"two\", 0.5)\n\t@pytest.mark.asyncio\n", "async def test_query_multiple_rows(client):\n\t    rs = await client.execute(\"VALUES (1, 'one'), (2, 'two'), (3, 'three')\")\n\t    assert len(rs.columns) == 2\n\t    assert len(rs.rows) == 3\n\t    assert tuple(rs.rows[0]) == (1, \"one\")\n\t    assert tuple(rs.rows[1]) == (2, \"two\")\n\t    assert tuple(rs.rows[2]) == (3, \"three\")\n\t@pytest.mark.asyncio\n\tasync def test_statement_without_args(client):\n\t    rs = await client.execute(libsql_client.Statement(\"SELECT 42\"))\n", "    assert rs[0][0] == 42\n\t@pytest.mark.asyncio\n\tasync def test_statement_with_args(client):\n\t    rs = await client.execute(libsql_client.Statement(\"SELECT ?\", [10]))\n\t    assert rs[0][0] == 10\n\t@pytest.mark.asyncio\n\tasync def test_error_no_such_column(client):\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await client.execute(\"SELECT foo\")\n\t    assert \"no such column: foo\" in str(excinfo.value)\n", "@pytest.mark.asyncio\n\tasync def test_error_syntax(client):\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await client.execute(\"SELECT\")\n\t    assert \"unexpected end of input\" in str(excinfo.value) or \"incomplete input\" in str(\n\t        excinfo.value\n\t    )\n\t@pytest.mark.asyncio\n\tasync def test_error_multiple_statements(url, client):\n\t    if url.startswith(\"file:\"):\n", "        return pytest.skip(\n\t            \"sqlite3 library does not provide a robust way \"\n\t            \"to recognize that the user attempted to execute multiple statements\"\n\t        )\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await client.execute(\"SELECT 1; SELECT 2\")\n\t    assert \"one statement\" in str(excinfo.value)\n\t@pytest.mark.asyncio\n\tasync def test_rows_affected_insert(client):\n\t    await client.batch(\n", "        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t        ]\n\t    )\n\t    rs = await client.execute(\"INSERT INTO t VALUES (1), (2)\")\n\t    assert rs.rows_affected == 2\n\t@pytest.mark.asyncio\n\tasync def test_rows_affected_delete(client):\n\t    await client.batch(\n", "        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t            \"INSERT INTO t VALUES (1), (2), (3), (4), (5)\",\n\t        ]\n\t    )\n\t    rs = await client.execute(\"DELETE FROM t WHERE a >= 3\")\n\t    assert rs.rows_affected == 3\n\t@pytest.mark.asyncio\n\tasync def test_last_insert_rowid(client):\n", "    await client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t            \"INSERT INTO t VALUES ('one'), ('two')\",\n\t        ]\n\t    )\n\t    insert_rs = await client.execute(\"INSERT INTO t VALUES ('three')\")\n\t    assert insert_rs.last_insert_rowid is not None\n\t    select_rs = await client.execute(\n", "        \"SELECT a FROM t WHERE ROWID = ?\", [insert_rs.last_insert_rowid]\n\t    )\n\t    assert select_rs[0].astuple() == (\"three\",)\n"]}
{"filename": "tests/test_sync.py", "chunked_list": ["import pytest\n\timport libsql_client\n\t@pytest.fixture\n\tdef client_sync(url):\n\t    with libsql_client.create_client_sync(url) as client:\n\t        yield client\n\t@pytest.fixture\n\tdef transaction_client_sync(transaction_url):\n\t    with libsql_client.create_client_sync(transaction_url) as client:\n\t        yield client\n", "def test_execute(client_sync):\n\t    rs = client_sync.execute(\"SELECT 1 AS one, 'two' AS two\")\n\t    assert rs.columns == (\"one\", \"two\")\n\t    assert len(rs.rows) == 1\n\t    assert rs.rows[0].astuple() == (1, \"two\")\n\tdef test_execute_error(client_sync):\n\t    with pytest.raises(libsql_client.LibsqlError):\n\t        client_sync.execute(\"SELECT foo\")\n\tdef test_batch(client_sync):\n\t    rss = client_sync.batch(\n", "        [\n\t            \"SELECT 1+1\",\n\t            (\"SELECT ? AS one, ? AS two\", [10, \"two\"]),\n\t        ]\n\t    )\n\t    assert [len(rs) for rs in rss] == [1, 1]\n\t    assert rss[0][0].astuple() == (2,)\n\t    assert rss[1][0].astuple() == (10, \"two\")\n\tdef test_transaction_commit(transaction_client_sync):\n\t    transaction_client_sync.batch(\n", "        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t        ]\n\t    )\n\t    with transaction_client_sync.transaction() as transaction:\n\t        transaction.execute(\"INSERT INTO t VALUES ('one'), ('two')\")\n\t        rs = transaction.execute(\"SELECT COUNT(*) FROM t\")\n\t        assert rs[0][0] == 2\n\t        transaction.commit()\n", "    assert transaction.closed\n\t    rs = transaction_client_sync.execute(\"SELECT COUNT(*) FROM t\")\n\t    assert rs[0][0] == 2\n\tdef test_transaction_rollback(transaction_client_sync):\n\t    transaction_client_sync.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t        ]\n\t    )\n", "    with transaction_client_sync.transaction() as transaction:\n\t        transaction.execute(\"INSERT INTO t VALUES ('one'), ('two')\")\n\t        rs = transaction.execute(\"SELECT COUNT(*) FROM t\")\n\t        assert rs[0][0] == 2\n\t        transaction.rollback()\n\t    assert transaction.closed\n\t    rs = transaction_client_sync.execute(\"SELECT COUNT(*) FROM t\")\n\t    assert rs[0][0] == 0\n\tdef test_close_twice(client_sync):\n\t    client_sync.close()\n", "    client_sync.close()\n\tdef test_close_transaction_twice(transaction_client_sync):\n\t    with transaction_client_sync.transaction() as transaction:\n\t        transaction.close()\n\tdef test_close_transaction_after_client(transaction_client_sync):\n\t    transaction = transaction_client_sync.transaction()\n\t    transaction_client_sync.close()\n\t    transaction.close()\n"]}
{"filename": "tests/test_result.py", "chunked_list": ["import pytest\n\t@pytest.mark.asyncio\n\tasync def test_blob(client):\n\t    rs = await client.execute(\"SELECT X'deadbeef'\")\n\t    assert rs.rows[0][0] == b\"\\xde\\xad\\xbe\\xef\"\n\t@pytest.mark.asyncio\n\tasync def test_columns(client):\n\t    rs = await client.execute(\"SELECT 1 AS a, 2 AS b, 3 AS c\")\n\t    assert rs.columns == (\"a\", \"b\", \"c\")\n\t    row = rs.rows[0]\n", "    assert row[\"a\"] == 1\n\t    assert row[\"b\"] == 2\n\t    assert row[\"c\"] == 3\n\t@pytest.mark.asyncio\n\tasync def test_rows(client):\n\t    rs = await client.execute(\"VALUES (1, 'one'), (2, 'two'), (3, 'three')\")\n\t    assert len(rs.rows) == 3\n\t    assert len(rs) == 3\n\t    assert rs.rows[0][0] == 1\n\t    assert rs.rows[0][1] == \"one\"\n", "    assert rs.rows[1][0] == 2\n\t    assert rs.rows[1][1] == \"two\"\n\t    assert rs.rows[2][0] == 3\n\t    assert rs.rows[2][1] == \"three\"\n\t    for i in range(3):\n\t        assert rs[i] is rs.rows[i]\n\t    assert list(rs) == rs.rows\n\t@pytest.mark.asyncio\n\tasync def test_row_repr(client):\n\t    rs = await client.execute(\"SELECT 42, 0.5, 'brontosaurus', NULL\")\n", "    assert repr(rs.rows[0]) == \"(42, 0.5, 'brontosaurus', None)\"\n\t@pytest.mark.asyncio\n\tasync def test_row_slice(client):\n\t    rs = await client.execute(\"SELECT 'one', 'two', 'three', 'four', 'five'\")\n\t    assert rs.rows[0][1:3] == (\"two\", \"three\")\n\t@pytest.mark.asyncio\n\tasync def test_row_tuple(client):\n\t    rs = await client.execute(\"SELECT 'one', 'two', 'three'\")\n\t    assert tuple(rs.rows[0]) == (\"one\", \"two\", \"three\")\n\t@pytest.mark.asyncio\n", "async def test_row_astuple(client):\n\t    rs = await client.execute(\"SELECT 'one', 'two', 'three'\")\n\t    assert rs.rows[0].astuple() == (\"one\", \"two\", \"three\")\n\t@pytest.mark.asyncio\n\tasync def test_row_asdict(client):\n\t    rs = await client.execute(\"SELECT 1 AS one, 2 AS two, 3 AS three\")\n\t    assert rs.rows[0].asdict() == {\"one\": 1, \"two\": 2, \"three\": 3}\n\t    assert rs.rows[0].asdict() == rs.rows[0]._asdict()\n\ttry:\n\t    import pandas\n", "except ImportError:\n\t    pandas = None\n\tpandas_only = pytest.mark.skipif(pandas is None, reason=\"pandas not installed\")\n\t@pytest.mark.asyncio\n\t@pandas_only\n\tasync def test_pandas_from_records(client):\n\t    rs = await client.execute(\"SELECT 1, 'two', 3.0\")\n\t    data_frame = pandas.DataFrame.from_records(rs.rows)\n\t    assert data_frame.shape == (1, 3)\n\t@pytest.mark.asyncio\n", "@pandas_only\n\tasync def test_pandas_ctor(client):\n\t    rs = await client.execute(\"SELECT 1 AS one, 'two' AS two, 3.0 AS three\")\n\t    data_frame = pandas.DataFrame(rs)\n\t    assert data_frame.shape == (1, 3)\n\t    assert tuple(data_frame.columns) == (\"one\", \"two\", \"three\")\n"]}
{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/test_batch.py", "chunked_list": ["import asyncio\n\timport pytest\n\timport libsql_client\n\t@pytest.mark.asyncio\n\tasync def test_multiple_queries(client):\n\t    rss = await client.batch(\n\t        [\n\t            \"SELECT 1+1\",\n\t            (\"SELECT 1 AS one, 2 AS two\",),\n\t            libsql_client.Statement(\"SELECT ?\", [\"boomerang\"]),\n", "            (\"VALUES (?), (?)\", [\"big\", \"ben\"]),\n\t        ]\n\t    )\n\t    assert [len(rs) for rs in rss] == [1, 1, 1, 2]\n\t    assert rss[0][0].astuple() == (2,)\n\t    assert rss[1][0].asdict() == {\"one\": 1, \"two\": 2}\n\t    assert rss[2][0].astuple() == (\"boomerang\",)\n\t    assert rss[3][0].astuple() == (\"big\",)\n\t    assert rss[3][1].astuple() == (\"ben\",)\n\t@pytest.mark.asyncio\n", "async def test_statements_are_executed_sequentially(client):\n\t    rss = await client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",  # 0\n\t            \"CREATE TABLE t (a, b)\",  # 1\n\t            \"INSERT INTO t VALUES (1, 'one')\",  # 2\n\t            \"SELECT * FROM t ORDER BY a\",  # 3\n\t            \"INSERT INTO t VALUES (2, 'two')\",  # 4\n\t            \"SELECT * FROM t ORDER BY a\",  # 5\n\t            \"DROP TABLE t\",  # 6\n", "        ]\n\t    )\n\t    assert len(rss) == 7\n\t    assert [r.astuple() for r in rss[3].rows] == [(1, \"one\")]\n\t    assert [r.astuple() for r in rss[5].rows] == [(1, \"one\"), (2, \"two\")]\n\t@pytest.mark.asyncio\n\tasync def test_statements_are_executed_in_transaction(client):\n\t    await client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t1\",\n", "            \"DROP TABLE IF EXISTS t2\",\n\t            \"CREATE TABLE t1 (a)\",\n\t            \"CREATE TABLE t2 (a)\",\n\t        ]\n\t    )\n\t    async def step(i):\n\t        rss = await client.batch(\n\t            [\n\t                (\"INSERT INTO t1 VALUES (?)\", [i]),\n\t                (\"INSERT INTO t2 VALUES (?)\", [i * 10]),\n", "                \"SELECT SUM(a) FROM t1\",\n\t                \"SELECT SUM(a) FROM t2\",\n\t            ]\n\t        )\n\t        sum1 = int(rss[2][0][0])\n\t        sum2 = int(rss[3][0][0])\n\t        assert sum2 == sum1 * 10\n\t    n = 100\n\t    await asyncio.gather(*(asyncio.create_task(step(i)) for i in range(n)))\n\t    rs1 = await client.execute(\"SELECT SUM(a) FROM t1\")\n", "    assert rs1[0][0] == n * (n - 1) / 2\n\t    rs2 = await client.execute(\"SELECT SUM(a) FROM t2\")\n\t    assert rs2[0][0] == 10 * n * (n - 1) / 2\n\t@pytest.mark.asyncio\n\tasync def test_error(client):\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await client.batch(\n\t            [\n\t                \"SELECT 1+1\",\n\t                \"SELECT foobar\",\n", "            ]\n\t        )\n\t    assert \"no such column: foobar\" in str(excinfo.value)\n\t@pytest.mark.asyncio\n\tasync def test_error_rollback(client):\n\t    await client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t            \"INSERT INTO t VALUES ('one')\",\n", "        ]\n\t    )\n\t    with pytest.raises(libsql_client.LibsqlError):\n\t        await client.batch(\n\t            [\n\t                \"INSERT INTO t VALUES ('two')\",\n\t                \"SELECT foobar\",\n\t                \"INSERT INTO t VALUES ('three')\",\n\t            ]\n\t        )\n", "    rs = await client.execute(\"SELECT COUNT(*) FROM t\")\n\t    assert rs[0][0] == 1\n"]}
{"filename": "tests/test_transaction.py", "chunked_list": ["import pytest\n\timport libsql_client\n\tasync def _assert_closed(t):\n\t    assert t.closed\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        await t.execute(\"SELECT 1\")\n\t    assert excinfo.value.code == \"TRANSACTION_CLOSED\"\n\t@pytest.mark.asyncio\n\tasync def test_multiple_queries(transaction_client):\n\t    with transaction_client.transaction() as t:\n", "        rs = await t.execute(\"SELECT 1\")\n\t        assert rs[0][0] == 1\n\t        rs = await t.execute(\"SELECT 1 AS one, 2 AS two, 3 AS three\")\n\t        assert rs[0].asdict() == {\"one\": 1, \"two\": 2, \"three\": 3}\n\t@pytest.mark.asyncio\n\tasync def test_commit(transaction_client):\n\t    await transaction_client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n", "        ]\n\t    )\n\t    with transaction_client.transaction() as t:\n\t        await t.execute(\"INSERT INTO t VALUES ('one')\")\n\t        assert not t.closed\n\t        await t.commit()\n\t        await _assert_closed(t)\n\t    rs = await transaction_client.execute(\"SELECT COUNT(*) FROM t\")\n\t    assert rs[0][0] == 1\n\t@pytest.mark.asyncio\n", "async def test_rollback(transaction_client):\n\t    await transaction_client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t        ]\n\t    )\n\t    with transaction_client.transaction() as t:\n\t        await t.execute(\"INSERT INTO t VALUES ('one')\")\n\t        assert not t.closed\n", "        await t.rollback()\n\t        await _assert_closed(t)\n\t    rs = await transaction_client.execute(\"SELECT COUNT(*) FROM t\")\n\t    assert rs[0][0] == 0\n\t@pytest.mark.asyncio\n\tasync def test_close(transaction_client):\n\t    await transaction_client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n", "        ]\n\t    )\n\t    t = transaction_client.transaction()\n\t    await t.execute(\"INSERT INTO t VALUES ('one')\")\n\t    assert not t.closed\n\t    t.close()\n\t    await _assert_closed(t)\n\t    rs = await transaction_client.execute(\"SELECT COUNT(*) FROM t\")\n\t    assert rs[0][0] == 0\n\t@pytest.mark.asyncio\n", "async def test_context_manager(transaction_client):\n\t    with transaction_client.transaction() as t:\n\t        assert not t.closed\n\t    assert t.closed\n\t@pytest.mark.asyncio\n\tasync def test_close_twice(transaction_client):\n\t    t = transaction_client.transaction()\n\t    t.close()\n\t    t.close()\n\t    assert t.closed\n", "@pytest.mark.asyncio\n\tasync def test_error_does_not_rollback(transaction_client):\n\t    await transaction_client.batch(\n\t        [\n\t            \"DROP TABLE IF EXISTS t\",\n\t            \"CREATE TABLE t (a)\",\n\t        ]\n\t    )\n\t    with transaction_client.transaction() as t:\n\t        await t.execute(\"INSERT INTO t VALUES ('one')\")\n", "        with pytest.raises(libsql_client.LibsqlError):\n\t            await t.execute(\"SELECT foobar\")\n\t        await t.execute(\"INSERT INTO t VALUES ('two')\")\n\t        await t.commit()\n\t    rs = await transaction_client.execute(\"SELECT COUNT(*) FROM t\")\n\t    assert rs[0][0] == 2\n\t@pytest.mark.asyncio\n\tasync def test_transaction_not_supported(http_url):\n\t    async with libsql_client.create_client(http_url) as c:\n\t        with pytest.raises(libsql_client.LibsqlError) as excinfo:\n", "            c.transaction()\n\t        assert excinfo.value.code == \"TRANSACTIONS_NOT_SUPPORTED\"\n"]}
{"filename": "tests/test_values.py", "chunked_list": ["from datetime import datetime\n\timport math\n\timport pytest\n\tasync def _roundtrip(client, arg):\n\t    rs = await client.execute(\"SELECT ?\", [arg])\n\t    return rs[0][0]\n\t@pytest.mark.asyncio\n\tasync def test_string(client):\n\t    assert await _roundtrip(client, \"boomerang\") == \"boomerang\"\n\t@pytest.mark.asyncio\n", "async def test_string_with_weird_characters(client):\n\t    assert await _roundtrip(client, \"a\\n\\r\\t \") == \"a\\n\\r\\t \"\n\t@pytest.mark.asyncio\n\tasync def test_string_with_unicode(client):\n\t    s = \"žluťoučký kůň úpěl ďábelské ódy\"\n\t    assert await _roundtrip(client, s) == s\n\t@pytest.mark.asyncio\n\tasync def test_int_zero(client):\n\t    x = await _roundtrip(client, 0)\n\t    assert isinstance(x, int) and x == 0\n", "@pytest.mark.asyncio\n\tasync def test_float_zero(client):\n\t    x = await _roundtrip(client, 0.0)\n\t    assert isinstance(x, float) and x == 0\n\t@pytest.mark.asyncio\n\tasync def test_integer(client):\n\t    x = await _roundtrip(client, -2023)\n\t    assert isinstance(x, int) and x == -2023\n\t@pytest.mark.asyncio\n\tasync def test_big_integer(client):\n", "    with pytest.raises(OverflowError):\n\t        await _roundtrip(client, 2**100 + 42)\n\t@pytest.mark.asyncio\n\tasync def test_float(client):\n\t    assert await _roundtrip(client, 12.345) == 12.345\n\t@pytest.mark.asyncio\n\tasync def test_not_finite(client):\n\t    for x in [math.inf, -math.inf, math.nan]:\n\t        with pytest.raises(ValueError):\n\t            await _roundtrip(client, x)\n", "@pytest.mark.asyncio\n\tasync def test_bytes(client):\n\t    for l in [0, 1, 2, 3, 4, 100, 113, 256]:\n\t        b = bytes(range(l))\n\t        assert await _roundtrip(client, b) == b\n\t@pytest.mark.asyncio\n\tasync def test_bytearray(client):\n\t    assert await _roundtrip(client, bytearray(b\"foobar\")) == b\"foobar\"\n\t@pytest.mark.asyncio\n\tasync def test_none(client):\n", "    assert await _roundtrip(client, None) is None\n\t@pytest.mark.asyncio\n\tasync def test_bool(client):\n\t    assert await _roundtrip(client, True) == 1\n\t    assert await _roundtrip(client, False) == 0\n\t@pytest.mark.asyncio\n\tasync def test_datetime(client):\n\t    d = datetime.fromisoformat(\"2023-04-01T12:34:56+02:00\")\n\t    ts = 1680345296000\n\t    assert await _roundtrip(client, d) == ts\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["import os\n\timport pytest\n\timport pytest_asyncio\n\timport libsql_client\n\t@pytest.fixture\n\tdef http_url():\n\t    return os.getenv(\"HTTP_URL\", \"http://localhost:8080\")\n\t@pytest.fixture\n\tdef ws_url():\n\t    return os.getenv(\"WS_URL\", \"ws://localhost:8080\")\n", "@pytest.fixture\n\tdef file_url(tmp_path):\n\t    return f\"file://{tmp_path.absolute() / 'test.db'}\"\n\tdef _url(request):\n\t    if request.param == \"http\":\n\t        return request.getfixturevalue(\"http_url\")\n\t    elif request.param == \"ws\":\n\t        return request.getfixturevalue(\"ws_url\")\n\t    elif request.param == \"file\":\n\t        return request.getfixturevalue(\"file_url\")\n", "    else:\n\t        assert False, f\"Bad URL request.param: {request.param!r}\"\n\t@pytest.fixture(params=[\"http\", \"ws\", \"file\"])\n\tdef url(request):\n\t    return _url(request)\n\t@pytest.fixture(params=[\"ws\", \"file\"])\n\tdef transaction_url(request):\n\t    return _url(request)\n\t@pytest_asyncio.fixture\n\tasync def client(url):\n", "    async with libsql_client.create_client(url) as c:\n\t        yield c\n\t@pytest_asyncio.fixture\n\tasync def transaction_client(transaction_url):\n\t    async with libsql_client.create_client(transaction_url) as c:\n\t        yield c\n\t@pytest_asyncio.fixture\n\tasync def ws_client(ws_url):\n\t    async with libsql_client.create_client(ws_url) as c:\n\t        yield c\n"]}
{"filename": "tests/test_create_client.py", "chunked_list": ["import pytest\n\timport libsql_client\n\t@pytest.mark.asyncio\n\tasync def test_closed(url):\n\t    client = libsql_client.create_client(url)\n\t    assert not client.closed\n\t    await client.close()\n\t    assert client.closed\n\t@pytest.mark.asyncio\n\tasync def test_context_manager(url):\n", "    async with libsql_client.create_client(url) as client:\n\t        assert not client.closed\n\t    assert client.closed\n\t@pytest.mark.asyncio\n\tasync def test_close_twice(url):\n\t    client = libsql_client.create_client(url)\n\t    await client.close()\n\t    await client.close()\n\t    assert client.closed\n\tdef test_error_url_scheme_not_supported():\n", "    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        libsql_client.create_client(\"ftp://localhost\")\n\t    assert excinfo.value.code == \"URL_SCHEME_NOT_SUPPORTED\"\n\t    assert \"ftp\" in str(excinfo.value)\n\tdef test_error_url_param_not_supported():\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        libsql_client.create_client(\"ws://localhost?foo=bar\")\n\t    assert excinfo.value.code == \"URL_PARAM_NOT_SUPPORTED\"\n\t    assert \"foo\" in str(excinfo.value)\n\tdef test_error_url_scheme_incompatible_with_tls():\n", "    urls = [\n\t        \"ws://localhost?tls=1\",\n\t        \"wss://localhost?tls=0\",\n\t        \"http://localhost?tls=1\",\n\t        \"https://localhost?tls=0\",\n\t    ]\n\t    for url in urls:\n\t        with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t            libsql_client.create_client(url)\n\t        assert excinfo.value.code == \"URL_INVALID\"\n", "        assert \"tls\" in str(excinfo.value)\n\tdef test_error_invalid_value_of_tls():\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        libsql_client.create_client(\"libsql://localhost?tls=foo\")\n\t    assert excinfo.value.code == \"URL_INVALID\"\n\t    assert \"foo\" in str(excinfo.value)\n\tdef test_missing_port_in_libsql_url_without_tls():\n\t    with pytest.raises(libsql_client.LibsqlError) as excinfo:\n\t        libsql_client.create_client(\"libsql://localhost?tls=0\")\n\t    assert excinfo.value.code == \"URL_INVALID\"\n", "    assert \"port\" in str(excinfo.value)\n"]}
{"filename": "tests/dbapi2/test_factory.py", "chunked_list": ["# pysqlite2/test/factory.py: tests for the various factories in pysqlite\n\t#\n\t# Copyright (C) 2005-2007 Gerhard Häring <gh@ghaering.de>\n\t#\n\t# This file is part of pysqlite.\n\t#\n\t# This software is provided 'as-is', without any express or implied\n\t# warranty.  In no event will the authors be held liable for any damages\n\t# arising from the use of this software.\n\t#\n", "# Permission is granted to anyone to use this software for any purpose,\n\t# including commercial applications, and to alter it and redistribute it\n\t# freely, subject to the following restrictions:\n\t#\n\t# 1. The origin of this software must not be misrepresented; you must not\n\t#    claim that you wrote the original software. If you use this software\n\t#    in a product, an acknowledgment in the product documentation would be\n\t#    appreciated but is not required.\n\t# 2. Altered source versions must be plainly marked as such, and must not be\n\t#    misrepresented as being the original software.\n", "# 3. This notice may not be removed or altered from any source distribution.\n\timport unittest\n\tfrom . import libsql_client_helpers as sqlite\n\tfrom collections.abc import Sequence\n\tdef dict_factory(cursor, row):\n\t    d = {}\n\t    for idx, col in enumerate(cursor.description):\n\t        d[col[0]] = row[idx]\n\t    return d\n\tclass MyCursor(sqlite.Cursor):\n", "    def __init__(self, *args, **kwargs):\n\t        sqlite.Cursor.__init__(self, *args, **kwargs)\n\t        self.row_factory = dict_factory\n\tclass ConnectionFactoryTests(unittest.TestCase):\n\t    def test_connection_factories(self):\n\t        class DefectFactory(sqlite.Connection):\n\t            def __init__(self, *args, **kwargs):\n\t                return None\n\t        class OkFactory(sqlite.Connection):\n\t            def __init__(self, *args, **kwargs):\n", "                sqlite.Connection.__init__(self, *args, **kwargs)\n\t        for factory in DefectFactory, OkFactory:\n\t            with self.subTest(factory=factory):\n\t                con = sqlite.connect(\":memory:\", factory=factory)\n\t                self.assertIsInstance(con, factory)\n\t    def test_connection_factory_relayed_call(self):\n\t        # gh-95132: keyword args must not be passed as positional args\n\t        class Factory(sqlite.Connection):\n\t            def __init__(self, *args, **kwargs):\n\t                kwargs[\"isolation_level\"] = None\n", "                super(Factory, self).__init__(*args, **kwargs)\n\t        con = sqlite.connect(\":memory:\", factory=Factory)\n\t        self.assertIsNone(con.isolation_level)\n\t        self.assertIsInstance(con, Factory)\n\t    def test_connection_factory_as_positional_arg(self):\n\t        class Factory(sqlite.Connection):\n\t            def __init__(self, *args, **kwargs):\n\t                super(Factory, self).__init__(*args, **kwargs)\n\t        con = sqlite.connect(\":memory:\", 5.0, 0, None, True, Factory)\n\t        self.assertIsNone(con.isolation_level)\n", "        self.assertIsInstance(con, Factory)\n\tclass CursorFactoryTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t    def tearDown(self):\n\t        self.con.close()\n\t    def test_is_instance(self):\n\t        cur = self.con.cursor()\n\t        self.assertIsInstance(cur, sqlite.Cursor)\n\t        cur = self.con.cursor(MyCursor)\n", "        self.assertIsInstance(cur, MyCursor)\n\t        cur = self.con.cursor(factory=lambda con: MyCursor(con))\n\t        self.assertIsInstance(cur, MyCursor)\n\t    def test_invalid_factory(self):\n\t        # not a callable at all\n\t        self.assertRaises(TypeError, self.con.cursor, None)\n\t        # invalid callable with not exact one argument\n\t        self.assertRaises(TypeError, self.con.cursor, lambda: None)\n\t        # invalid callable returning non-cursor\n\t        self.assertRaises(TypeError, self.con.cursor, lambda con: None)\n", "class RowFactoryTestsBackwardsCompat(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t    def test_is_produced_by_factory(self):\n\t        cur = self.con.cursor(factory=MyCursor)\n\t        cur.execute(\"select 4+5 as foo\")\n\t        row = cur.fetchone()\n\t        self.assertIsInstance(row, dict)\n\t        cur.close()\n\t    def tearDown(self):\n", "        self.con.close()\n\tclass RowFactoryTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t    def test_custom_factory(self):\n\t        self.con.row_factory = lambda cur, row: list(row)\n\t        row = self.con.execute(\"select 1, 2\").fetchone()\n\t        self.assertIsInstance(row, list)\n\t    def test_sqlite_row_index(self):\n\t        self.con.row_factory = sqlite.Row\n", "        row = self.con.execute(\"select 1 as a_1, 2 as b\").fetchone()\n\t        self.assertIsInstance(row, sqlite.Row)\n\t        self.assertEqual(row[\"a_1\"], 1, \"by name: wrong result for column 'a_1'\")\n\t        self.assertEqual(row[\"b\"], 2, \"by name: wrong result for column 'b'\")\n\t        self.assertEqual(row[\"A_1\"], 1, \"by name: wrong result for column 'A_1'\")\n\t        self.assertEqual(row[\"B\"], 2, \"by name: wrong result for column 'B'\")\n\t        self.assertEqual(row[0], 1, \"by index: wrong result for column 0\")\n\t        self.assertEqual(row[1], 2, \"by index: wrong result for column 1\")\n\t        self.assertEqual(row[-1], 2, \"by index: wrong result for column -1\")\n\t        self.assertEqual(row[-2], 1, \"by index: wrong result for column -2\")\n", "        with self.assertRaises(IndexError):\n\t            row['c']\n\t        with self.assertRaises(IndexError):\n\t            row['a_\\x11']\n\t        with self.assertRaises(IndexError):\n\t            row['a\\x7f1']\n\t        with self.assertRaises(IndexError):\n\t            row[2]\n\t        with self.assertRaises(IndexError):\n\t            row[-3]\n", "        with self.assertRaises(IndexError):\n\t            row[2**1000]\n\t        with self.assertRaises(IndexError):\n\t            row[complex()]  # index must be int or string\n\t    def test_sqlite_row_index_unicode(self):\n\t        self.con.row_factory = sqlite.Row\n\t        row = self.con.execute(\"select 1 as \\xff\").fetchone()\n\t        self.assertEqual(row[\"\\xff\"], 1)\n\t        with self.assertRaises(IndexError):\n\t            row['\\u0178']\n", "        with self.assertRaises(IndexError):\n\t            row['\\xdf']\n\t    def test_sqlite_row_slice(self):\n\t        # A sqlite.Row can be sliced like a list.\n\t        self.con.row_factory = sqlite.Row\n\t        row = self.con.execute(\"select 1, 2, 3, 4\").fetchone()\n\t        self.assertEqual(row[0:0], ())\n\t        self.assertEqual(row[0:1], (1,))\n\t        self.assertEqual(row[1:3], (2, 3))\n\t        self.assertEqual(row[3:1], ())\n", "        # Explicit bounds are optional.\n\t        self.assertEqual(row[1:], (2, 3, 4))\n\t        self.assertEqual(row[:3], (1, 2, 3))\n\t        # Slices can use negative indices.\n\t        self.assertEqual(row[-2:-1], (3,))\n\t        self.assertEqual(row[-2:], (3, 4))\n\t        # Slicing supports steps.\n\t        self.assertEqual(row[0:4:2], (1, 3))\n\t        self.assertEqual(row[3:0:-2], (4, 2))\n\t    def test_sqlite_row_iter(self):\n", "        \"\"\"Checks if the row object is iterable\"\"\"\n\t        self.con.row_factory = sqlite.Row\n\t        row = self.con.execute(\"select 1 as a, 2 as b\").fetchone()\n\t        # Is iterable in correct order and produces valid results:\n\t        items = [col for col in row]\n\t        self.assertEqual(items, [1, 2])\n\t        # Is iterable the second time:\n\t        items = [col for col in row]\n\t        self.assertEqual(items, [1, 2])\n\t    def test_sqlite_row_as_tuple(self):\n", "        \"\"\"Checks if the row object can be converted to a tuple\"\"\"\n\t        self.con.row_factory = sqlite.Row\n\t        row = self.con.execute(\"select 1 as a, 2 as b\").fetchone()\n\t        t = tuple(row)\n\t        self.assertEqual(t, (row['a'], row['b']))\n\t    def test_sqlite_row_as_dict(self):\n\t        \"\"\"Checks if the row object can be correctly converted to a dictionary\"\"\"\n\t        self.con.row_factory = sqlite.Row\n\t        row = self.con.execute(\"select 1 as a, 2 as b\").fetchone()\n\t        d = dict(row)\n", "        self.assertEqual(d[\"a\"], row[\"a\"])\n\t        self.assertEqual(d[\"b\"], row[\"b\"])\n\t    def test_sqlite_row_hash_cmp(self):\n\t        \"\"\"Checks if the row object compares and hashes correctly\"\"\"\n\t        self.con.row_factory = sqlite.Row\n\t        row_1 = self.con.execute(\"select 1 as a, 2 as b\").fetchone()\n\t        row_2 = self.con.execute(\"select 1 as a, 2 as b\").fetchone()\n\t        row_3 = self.con.execute(\"select 1 as a, 3 as b\").fetchone()\n\t        row_4 = self.con.execute(\"select 1 as b, 2 as a\").fetchone()\n\t        row_5 = self.con.execute(\"select 2 as b, 1 as a\").fetchone()\n", "        self.assertTrue(row_1 == row_1)\n\t        self.assertTrue(row_1 == row_2)\n\t        self.assertFalse(row_1 == row_3)\n\t        self.assertFalse(row_1 == row_4)\n\t        self.assertFalse(row_1 == row_5)\n\t        self.assertFalse(row_1 == object())\n\t        self.assertFalse(row_1 != row_1)\n\t        self.assertFalse(row_1 != row_2)\n\t        self.assertTrue(row_1 != row_3)\n\t        self.assertTrue(row_1 != row_4)\n", "        self.assertTrue(row_1 != row_5)\n\t        self.assertTrue(row_1 != object())\n\t        with self.assertRaises(TypeError):\n\t            row_1 > row_2\n\t        with self.assertRaises(TypeError):\n\t            row_1 < row_2\n\t        with self.assertRaises(TypeError):\n\t            row_1 >= row_2\n\t        with self.assertRaises(TypeError):\n\t            row_1 <= row_2\n", "        self.assertEqual(hash(row_1), hash(row_2))\n\t    def test_sqlite_row_as_sequence(self):\n\t        \"\"\" Checks if the row object can act like a sequence \"\"\"\n\t        self.con.row_factory = sqlite.Row\n\t        row = self.con.execute(\"select 1 as a, 2 as b\").fetchone()\n\t        as_tuple = tuple(row)\n\t        self.assertEqual(list(reversed(row)), list(reversed(as_tuple)))\n\t        self.assertIsInstance(row, Sequence)\n\t    def test_fake_cursor_class(self):\n\t        # Issue #24257: Incorrect use of PyObject_IsInstance() caused\n", "        # segmentation fault.\n\t        # Issue #27861: Also applies for cursor factory.\n\t        class FakeCursor(str):\n\t            __class__ = sqlite.Cursor\n\t        self.con.row_factory = sqlite.Row\n\t        self.assertRaises(TypeError, self.con.cursor, FakeCursor)\n\t        self.assertRaises(TypeError, sqlite.Row, FakeCursor(), ())\n\t    def tearDown(self):\n\t        self.con.close()\n\tclass TextFactoryTests(unittest.TestCase):\n", "    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t    def test_unicode(self):\n\t        austria = \"Österreich\"\n\t        row = self.con.execute(\"select ?\", (austria,)).fetchone()\n\t        self.assertEqual(type(row[0]), str, \"type of row[0] must be unicode\")\n\t    def test_string(self):\n\t        self.con.text_factory = bytes\n\t        austria = \"Österreich\"\n\t        row = self.con.execute(\"select ?\", (austria,)).fetchone()\n", "        self.assertEqual(type(row[0]), bytes, \"type of row[0] must be bytes\")\n\t        self.assertEqual(row[0], austria.encode(\"utf-8\"), \"column must equal original data in UTF-8\")\n\t    def test_custom(self):\n\t        self.con.text_factory = lambda x: str(x, \"utf-8\", \"ignore\")\n\t        austria = \"Österreich\"\n\t        row = self.con.execute(\"select ?\", (austria,)).fetchone()\n\t        self.assertEqual(type(row[0]), str, \"type of row[0] must be unicode\")\n\t        self.assertTrue(row[0].endswith(\"reich\"), \"column must contain original data\")\n\t    @unittest.skip(\"not supported by libsql_client\")\n\t    def test_optimized_unicode(self):\n", "        # OptimizedUnicode is deprecated as of Python 3.10\n\t        with self.assertWarns(DeprecationWarning) as cm:\n\t            self.con.text_factory = sqlite.OptimizedUnicode\n\t        self.assertIn(\"factory.py\", cm.filename)\n\t        austria = \"Österreich\"\n\t        germany = \"Deutchland\"\n\t        a_row = self.con.execute(\"select ?\", (austria,)).fetchone()\n\t        d_row = self.con.execute(\"select ?\", (germany,)).fetchone()\n\t        self.assertEqual(type(a_row[0]), str, \"type of non-ASCII row must be str\")\n\t        self.assertEqual(type(d_row[0]), str, \"type of ASCII-only row must be str\")\n", "    def tearDown(self):\n\t        self.con.close()\n\tclass TextFactoryTestsWithEmbeddedZeroBytes(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        self.con.execute(\"create table test (value text)\")\n\t        self.con.execute(\"insert into test (value) values (?)\", (\"a\\x00b\",))\n\t    def test_string(self):\n\t        # text_factory defaults to str\n\t        row = self.con.execute(\"select value from test\").fetchone()\n", "        self.assertIs(type(row[0]), str)\n\t        self.assertEqual(row[0], \"a\\x00b\")\n\t    def test_bytes(self):\n\t        self.con.text_factory = bytes\n\t        row = self.con.execute(\"select value from test\").fetchone()\n\t        self.assertIs(type(row[0]), bytes)\n\t        self.assertEqual(row[0], b\"a\\x00b\")\n\t    def test_bytearray(self):\n\t        self.con.text_factory = bytearray\n\t        row = self.con.execute(\"select value from test\").fetchone()\n", "        self.assertIs(type(row[0]), bytearray)\n\t        self.assertEqual(row[0], b\"a\\x00b\")\n\t    def test_custom(self):\n\t        # A custom factory should receive a bytes argument\n\t        self.con.text_factory = lambda x: x\n\t        row = self.con.execute(\"select value from test\").fetchone()\n\t        self.assertIs(type(row[0]), bytes)\n\t        self.assertEqual(row[0], b\"a\\x00b\")\n\t    def tearDown(self):\n\t        self.con.close()\n", "if __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/test_regression.py", "chunked_list": ["# pysqlite2/test/regression.py: pysqlite regression tests\n\t#\n\t# Copyright (C) 2006-2010 Gerhard Häring <gh@ghaering.de>\n\t#\n\t# This file is part of pysqlite.\n\t#\n\t# This software is provided 'as-is', without any express or implied\n\t# warranty.  In no event will the authors be held liable for any damages\n\t# arising from the use of this software.\n\t#\n", "# Permission is granted to anyone to use this software for any purpose,\n\t# including commercial applications, and to alter it and redistribute it\n\t# freely, subject to the following restrictions:\n\t#\n\t# 1. The origin of this software must not be misrepresented; you must not\n\t#    claim that you wrote the original software. If you use this software\n\t#    in a product, an acknowledgment in the product documentation would be\n\t#    appreciated but is not required.\n\t# 2. Altered source versions must be plainly marked as such, and must not be\n\t#    misrepresented as being the original software.\n", "# 3. This notice may not be removed or altered from any source distribution.\n\timport datetime\n\timport unittest\n\tfrom . import libsql_client_helpers as sqlite\n\timport weakref\n\timport functools\n\tfrom test import support\n\tfrom unittest.mock import patch\n\tfrom .test_dbapi import memory_database, cx_limit\n\tclass RegressionTests(unittest.TestCase):\n", "    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t    def tearDown(self):\n\t        self.con.close()\n\t    def test_pragma_user_version(self):\n\t        # This used to crash pysqlite because this pragma command returns NULL for the column name\n\t        cur = self.con.cursor()\n\t        cur.execute(\"pragma user_version\")\n\t    def test_pragma_schema_version(self):\n\t        # This still crashed pysqlite <= 2.2.1\n", "        con = sqlite.connect(\":memory:\", detect_types=sqlite.PARSE_COLNAMES)\n\t        try:\n\t            cur = self.con.cursor()\n\t            cur.execute(\"pragma schema_version\")\n\t        finally:\n\t            cur.close()\n\t            con.close()\n\t    def test_statement_reset(self):\n\t        # pysqlite 2.1.0 to 2.2.0 have the problem that not all statements are\n\t        # reset before a rollback, but only those that are still in the\n", "        # statement cache. The others are not accessible from the connection object.\n\t        con = sqlite.connect(\":memory:\", cached_statements=5)\n\t        cursors = [con.cursor() for x in range(5)]\n\t        cursors[0].execute(\"create table test(x)\")\n\t        for i in range(10):\n\t            cursors[0].executemany(\"insert into test(x) values (?)\", [(x,) for x in range(10)])\n\t        for i in range(5):\n\t            cursors[i].execute(\" \" * i + \"select x from test\")\n\t        con.rollback()\n\t    def test_column_name_with_spaces(self):\n", "        cur = self.con.cursor()\n\t        cur.execute('select 1 as \"foo bar [datetime]\"')\n\t        self.assertEqual(cur.description[0][0], \"foo bar [datetime]\")\n\t        cur.execute('select 1 as \"foo baz\"')\n\t        self.assertEqual(cur.description[0][0], \"foo baz\")\n\t    def test_statement_finalization_on_close_db(self):\n\t        # pysqlite versions <= 2.3.3 only finalized statements in the statement\n\t        # cache when closing the database. statements that were still\n\t        # referenced in cursors weren't closed and could provoke \"\n\t        # \"OperationalError: Unable to close due to unfinalised statements\".\n", "        con = sqlite.connect(\":memory:\")\n\t        cursors = []\n\t        # default statement cache size is 100\n\t        for i in range(105):\n\t            cur = con.cursor()\n\t            cursors.append(cur)\n\t            cur.execute(\"select 1 x union select \" + str(i))\n\t        con.close()\n\t    @unittest.skip(\"libsql_client depends on server sending autocommit mode\")\n\t    def test_on_conflict_rollback(self):\n", "        con = sqlite.connect(\":memory:\")\n\t        con.execute(\"create table foo(x, unique(x) on conflict rollback)\")\n\t        con.execute(\"insert into foo(x) values (1)\")\n\t        try:\n\t            con.execute(\"insert into foo(x) values (1)\")\n\t        except sqlite.DatabaseError:\n\t            pass\n\t        con.execute(\"insert into foo(x) values (2)\")\n\t        try:\n\t            con.commit()\n", "        except sqlite.OperationalError:\n\t            self.fail(\"pysqlite knew nothing about the implicit ROLLBACK\")\n\t    def test_workaround_for_buggy_sqlite_transfer_bindings(self):\n\t        \"\"\"\n\t        pysqlite would crash with older SQLite versions unless\n\t        a workaround is implemented.\n\t        \"\"\"\n\t        self.con.execute(\"create table foo(bar)\")\n\t        self.con.execute(\"drop table foo\")\n\t        self.con.execute(\"create table foo(bar)\")\n", "    def test_empty_statement(self):\n\t        \"\"\"\n\t        pysqlite used to segfault with SQLite versions 3.5.x. These return NULL\n\t        for \"no-operation\" statements\n\t        \"\"\"\n\t        self.con.execute(\"\")\n\t    @unittest.skip(\"does not make sense with libsql_client-py\")\n\t    def test_type_map_usage(self):\n\t        \"\"\"\n\t        pysqlite until 2.4.1 did not rebuild the row_cast_map when recompiling\n", "        a statement. This test exhibits the problem.\n\t        \"\"\"\n\t        SELECT = \"select * from foo\"\n\t        con = sqlite.connect(\":memory:\",detect_types=sqlite.PARSE_DECLTYPES)\n\t        cur = con.cursor()\n\t        cur.execute(\"create table foo(bar timestamp)\")\n\t        cur.execute(\"insert into foo(bar) values (?)\", (datetime.datetime.now(),))\n\t        cur.execute(SELECT)\n\t        cur.execute(\"drop table foo\")\n\t        cur.execute(\"create table foo(bar integer)\")\n", "        cur.execute(\"insert into foo(bar) values (5)\")\n\t        cur.execute(SELECT)\n\t    def test_bind_mutating_list(self):\n\t        # Issue41662: Crash when mutate a list of parameters during iteration.\n\t        class X:\n\t            def __conform__(self, protocol):\n\t                parameters.clear()\n\t                return \"...\"\n\t        parameters = [X(), 0]\n\t        con = sqlite.connect(\":memory:\",detect_types=sqlite.PARSE_DECLTYPES)\n", "        con.execute(\"create table foo(bar X, baz integer)\")\n\t        # Should not crash\n\t        with self.assertRaises(IndexError):\n\t            con.execute(\"insert into foo(bar, baz) values (?, ?)\", parameters)\n\t    @unittest.skip(\"causes sqld to close the WebSocket connection\")\n\t    def test_error_msg_decode_error(self):\n\t        # When porting the module to Python 3.0, the error message about\n\t        # decoding errors disappeared. This verifies they're back again.\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            self.con.execute(\"select 'xxx' || ? || 'yyy' colname\",\n", "                             (bytes(bytearray([250])),)).fetchone()\n\t        msg = \"Could not decode to UTF-8 column 'colname' with text 'xxx\"\n\t        self.assertIn(msg, str(cm.exception))\n\t    def test_register_adapter(self):\n\t        \"\"\"\n\t        See issue 3312.\n\t        \"\"\"\n\t        self.assertRaises(TypeError, sqlite.register_adapter, {}, None)\n\t    def test_set_isolation_level(self):\n\t        # See issue 27881.\n", "        class CustomStr(str):\n\t            def upper(self):\n\t                return None\n\t            def __del__(self):\n\t                con.isolation_level = \"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        con.isolation_level = None\n\t        for level in \"\", \"DEFERRED\", \"IMMEDIATE\", \"EXCLUSIVE\":\n\t            with self.subTest(level=level):\n\t                con.isolation_level = level\n", "                con.isolation_level = level.lower()\n\t                con.isolation_level = level.capitalize()\n\t                con.isolation_level = CustomStr(level)\n\t        # setting isolation_level failure should not alter previous state\n\t        con.isolation_level = None\n\t        con.isolation_level = \"DEFERRED\"\n\t        pairs = [\n\t            (1, TypeError), (b'', TypeError), (\"abc\", ValueError),\n\t            (\"IMMEDIATE\\0EXCLUSIVE\", ValueError), (\"\\xe9\", ValueError),\n\t        ]\n", "        for value, exc in pairs:\n\t            with self.subTest(level=value):\n\t                with self.assertRaises(exc):\n\t                    con.isolation_level = value\n\t                self.assertEqual(con.isolation_level, \"DEFERRED\")\n\t    def test_cursor_constructor_call_check(self):\n\t        \"\"\"\n\t        Verifies that cursor methods check whether base class __init__ was\n\t        called.\n\t        \"\"\"\n", "        class Cursor(sqlite.Cursor):\n\t            def __init__(self, con):\n\t                pass\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = Cursor(con)\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            cur.execute(\"select 4+5\").fetchall()\n\t        with self.assertRaisesRegex(sqlite.ProgrammingError,\n\t                                    r'^Base Cursor\\.__init__ not called\\.$'):\n\t            cur.close()\n", "    def test_str_subclass(self):\n\t        \"\"\"\n\t        The Python 3.0 port of the module didn't cope with values of subclasses of str.\n\t        \"\"\"\n\t        class MyStr(str): pass\n\t        self.con.execute(\"select ?\", (MyStr(\"abc\"),))\n\t    def test_connection_constructor_call_check(self):\n\t        \"\"\"\n\t        Verifies that connection methods check whether base class __init__ was\n\t        called.\n", "        \"\"\"\n\t        class Connection(sqlite.Connection):\n\t            def __init__(self, name):\n\t                pass\n\t        con = Connection(\":memory:\")\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            cur = con.cursor()\n\t    def test_auto_commit(self):\n\t        \"\"\"\n\t        Verifies that creating a connection in autocommit mode works.\n", "        2.5.3 introduced a regression so that these could no longer\n\t        be created.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\", isolation_level=None)\n\t    def test_pragma_autocommit(self):\n\t        \"\"\"\n\t        Verifies that running a PRAGMA statement that does an autocommit does\n\t        work. This did not work in 2.5.3/2.5.4.\n\t        \"\"\"\n\t        cur = self.con.cursor()\n", "        cur.execute(\"create table foo(bar)\")\n\t        cur.execute(\"insert into foo(bar) values (5)\")\n\t        cur.execute(\"pragma page_size\")\n\t        row = cur.fetchone()\n\t    def test_connection_call(self):\n\t        \"\"\"\n\t        Call a connection with a non-string SQL request: check error handling\n\t        of the statement constructor.\n\t        \"\"\"\n\t        self.assertRaises(TypeError, self.con, b\"select 1\")\n", "    @unittest.skip(\"Not supported\")\n\t    def test_collation(self):\n\t        def collation_cb(a, b):\n\t            return 1\n\t        self.assertRaises(UnicodeEncodeError, self.con.create_collation,\n\t            # Lone surrogate cannot be encoded to the default encoding (utf8)\n\t            \"\\uDC80\", collation_cb)\n\t    @unittest.skip(\"does not make sense for libsql_client\")\n\t    def test_recursive_cursor_use(self):\n\t        \"\"\"\n", "        http://bugs.python.org/issue10811\n\t        Recursively using a cursor, such as when reusing it from a generator led to segfaults.\n\t        Now we catch recursive cursor usage and raise a ProgrammingError.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        cur.execute(\"create table a (bar)\")\n\t        cur.execute(\"create table b (baz)\")\n\t        def foo():\n\t            cur.execute(\"insert into a (bar) values (?)\", (1,))\n", "            yield 1\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            cur.executemany(\"insert into b (baz) values (?)\",\n\t                            ((i,) for i in foo()))\n\t    def test_convert_timestamp_microsecond_padding(self):\n\t        \"\"\"\n\t        http://bugs.python.org/issue14720\n\t        The microsecond parsing of convert_timestamp() should pad with zeros,\n\t        since the microsecond string \"456\" actually represents \"456000\".\n\t        \"\"\"\n", "        con = sqlite.connect(\":memory:\", detect_types=sqlite.PARSE_DECLTYPES)\n\t        cur = con.cursor()\n\t        cur.execute(\"CREATE TABLE t (x TIMESTAMP)\")\n\t        # Microseconds should be 456000\n\t        cur.execute(\"INSERT INTO t (x) VALUES ('2012-04-04 15:06:00.456')\")\n\t        # Microseconds should be truncated to 123456\n\t        cur.execute(\"INSERT INTO t (x) VALUES ('2012-04-04 15:06:00.123456789')\")\n\t        cur.execute(\"SELECT * FROM t\")\n\t        values = [x[0] for x in cur.fetchall()]\n\t        self.assertEqual(values, [\n", "            datetime.datetime(2012, 4, 4, 15, 6, 0, 456000),\n\t            datetime.datetime(2012, 4, 4, 15, 6, 0, 123456),\n\t        ])\n\t    def test_invalid_isolation_level_type(self):\n\t        # isolation level is a string, not an integer\n\t        self.assertRaises(TypeError,\n\t                          sqlite.connect, \":memory:\", isolation_level=123)\n\t    def test_null_character(self):\n\t        # Issue #21147\n\t        cur = self.con.cursor()\n", "        queries = [\"\\0select 1\", \"select 1\\0\"]\n\t        for query in queries:\n\t            with self.subTest(query=query):\n\t                self.assertRaisesRegex(sqlite.ProgrammingError, \"null char\",\n\t                                       self.con.execute, query)\n\t            with self.subTest(query=query):\n\t                self.assertRaisesRegex(sqlite.ProgrammingError, \"null char\",\n\t                                       cur.execute, query)\n\t    @unittest.skip(\"TODO: implement this check\")\n\t    def test_surrogates(self):\n", "        con = sqlite.connect(\":memory:\")\n\t        self.assertRaises(UnicodeEncodeError, con, \"select '\\ud8ff'\")\n\t        self.assertRaises(UnicodeEncodeError, con, \"select '\\udcff'\")\n\t        cur = con.cursor()\n\t        self.assertRaises(UnicodeEncodeError, cur.execute, \"select '\\ud8ff'\")\n\t        self.assertRaises(UnicodeEncodeError, cur.execute, \"select '\\udcff'\")\n\t    def test_large_sql(self):\n\t        msg = \"query string is too large\"\n\t        with memory_database() as cx, cx_limit(cx) as lim:\n\t            cu = cx.cursor()\n", "            cx(\"select 1\".ljust(lim))\n\t            # use a different SQL statement; don't reuse from the LRU cache\n\t            cu.execute(\"select 2\".ljust(lim))\n\t            sql = \"select 3\".ljust(lim+1)\n\t            self.assertRaisesRegex(sqlite.DataError, msg, cx, sql)\n\t            self.assertRaisesRegex(sqlite.DataError, msg, cu.execute, sql)\n\t    @unittest.skip(\"Not supported\")\n\t    def test_commit_cursor_reset(self):\n\t        \"\"\"\n\t        Connection.commit() did reset cursors, which made sqlite3\n", "        to return rows multiple times when fetched from cursors\n\t        after commit. See issues 10513 and 23129 for details.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        con.executescript(\"\"\"\n\t        create table t(c);\n\t        create table t2(c);\n\t        insert into t values(0);\n\t        insert into t values(1);\n\t        insert into t values(2);\n", "        \"\"\")\n\t        self.assertEqual(con.isolation_level, \"\")\n\t        counter = 0\n\t        for i, row in enumerate(con.execute(\"select c from t\")):\n\t            with self.subTest(i=i, row=row):\n\t                con.execute(\"insert into t2(c) values (?)\", (i,))\n\t                con.commit()\n\t                if counter == 0:\n\t                    self.assertEqual(row[0], 0)\n\t                elif counter == 1:\n", "                    self.assertEqual(row[0], 1)\n\t                elif counter == 2:\n\t                    self.assertEqual(row[0], 2)\n\t                counter += 1\n\t        self.assertEqual(counter, 3, \"should have returned exactly three rows\")\n\t    @unittest.skip(\"Not supported\")\n\t    def test_bpo31770(self):\n\t        \"\"\"\n\t        The interpreter shouldn't crash in case Cursor.__init__() is called\n\t        more than once.\n", "        \"\"\"\n\t        def callback(*args):\n\t            pass\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = sqlite.Cursor(con)\n\t        ref = weakref.ref(cur, callback)\n\t        cur.__init__(con)\n\t        del cur\n\t        # The interpreter shouldn't crash when ref is collected.\n\t        del ref\n", "        support.gc_collect()\n\t    def test_del_isolation_level_segfault(self):\n\t        with self.assertRaises(AttributeError):\n\t            del self.con.isolation_level\n\t    @unittest.skip(\"Not supported\")\n\t    def test_bpo37347(self):\n\t        class Printer:\n\t            def log(self, *args):\n\t                return sqlite.SQLITE_OK\n\t        for method in [self.con.set_trace_callback,\n", "                       functools.partial(self.con.set_progress_handler, n=1),\n\t                       self.con.set_authorizer]:\n\t            printer_instance = Printer()\n\t            method(printer_instance.log)\n\t            method(printer_instance.log)\n\t            self.con.execute(\"select 1\")  # trigger seg fault\n\t            method(None)\n\t    def test_return_empty_bytestring(self):\n\t        cur = self.con.execute(\"select X''\")\n\t        val = cur.fetchone()[0]\n", "        self.assertEqual(val, b'')\n\t    def test_table_lock_cursor_replace_stmt(self):\n\t        with memory_database() as con:\n\t            cur = con.cursor()\n\t            cur.execute(\"create table t(t)\")\n\t            cur.executemany(\"insert into t values(?)\",\n\t                            ((v,) for v in range(5)))\n\t            con.commit()\n\t            cur.execute(\"select t from t\")\n\t            cur.execute(\"drop table t\")\n", "            con.commit()\n\t    def test_table_lock_cursor_dealloc(self):\n\t        with memory_database() as con:\n\t            con.execute(\"create table t(t)\")\n\t            con.executemany(\"insert into t values(?)\",\n\t                            ((v,) for v in range(5)))\n\t            con.commit()\n\t            cur = con.execute(\"select t from t\")\n\t            del cur\n\t            con.execute(\"drop table t\")\n", "            con.commit()\n\t    @unittest.skip(\"Not supported\")\n\t    def test_table_lock_cursor_non_readonly_select(self):\n\t        with memory_database() as con:\n\t            con.execute(\"create table t(t)\")\n\t            con.executemany(\"insert into t values(?)\",\n\t                            ((v,) for v in range(5)))\n\t            con.commit()\n\t            def dup(v):\n\t                con.execute(\"insert into t values(?)\", (v,))\n", "                return\n\t            con.create_function(\"dup\", 1, dup)\n\t            cur = con.execute(\"select dup(t) from t\")\n\t            del cur\n\t            con.execute(\"drop table t\")\n\t            con.commit()\n\t    @unittest.skip(\"Not supported\")\n\t    def test_executescript_step_through_select(self):\n\t        with memory_database() as con:\n\t            values = [(v,) for v in range(5)]\n", "            with con:\n\t                con.execute(\"create table t(t)\")\n\t                con.executemany(\"insert into t values(?)\", values)\n\t            steps = []\n\t            con.create_function(\"step\", 1, lambda x: steps.append((x,)))\n\t            con.executescript(\"select step(t) from t\")\n\t            self.assertEqual(steps, values)\n\t    def test_custom_cursor_object_crash_gh_99886(self):\n\t        # This test segfaults on GH-99886\n\t        class MyCursor(sqlite.Cursor):\n", "            def __init__(self, *args, **kwargs):\n\t                super().__init__(*args, **kwargs)\n\t                # this can go before or after the super call; doesn't matter\n\t                self.some_attr = None\n\t        with memory_database() as con:\n\t            cur = con.cursor(MyCursor)\n\t            cur.close()\n\t            del cur\n\tclass RecursiveUseOfCursors(unittest.TestCase):\n\t    # GH-80254: sqlite3 should not segfault for recursive use of cursors.\n", "    msg = \"Recursive use of cursors not allowed\"\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\",\n\t                                  detect_types=sqlite.PARSE_COLNAMES)\n\t        self.cur = self.con.cursor()\n\t        self.cur.execute(\"create table test(x foo)\")\n\t        self.cur.executemany(\"insert into test(x) values (?)\",\n\t                             [(\"foo\",), (\"bar\",)])\n\t    def tearDown(self):\n\t        self.cur.close()\n", "        self.con.close()\n\t    @unittest.skip(\"does not make sense for libsql_client\")\n\t    def test_recursive_cursor_init(self):\n\t        conv = lambda x: self.cur.__init__(self.con)\n\t        with patch.dict(sqlite.converters, {\"INIT\": conv}):\n\t            self.cur.execute(f'select x as \"x [INIT]\", x from test')\n\t            self.assertRaisesRegex(sqlite.ProgrammingError, self.msg,\n\t                                   self.cur.fetchall)\n\t    def test_recursive_cursor_close(self):\n\t        conv = lambda x: self.cur.close()\n", "        with patch.dict(sqlite.converters, {\"CLOSE\": conv}):\n\t            self.cur.execute(f'select x as \"x [CLOSE]\", x from test')\n\t            self.assertRaisesRegex(sqlite.ProgrammingError, self.msg,\n\t                                   self.cur.fetchall)\n\t    def test_recursive_cursor_iter(self):\n\t        conv = lambda x, l=[]: self.cur.fetchone() if l else l.append(None)\n\t        with patch.dict(sqlite.converters, {\"ITER\": conv}):\n\t            self.cur.execute(f'select x as \"x [ITER]\", x from test')\n\t            self.assertRaisesRegex(sqlite.ProgrammingError, self.msg,\n\t                                   self.cur.fetchall)\n", "if __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/test_types.py", "chunked_list": ["# pysqlite2/test/types.py: tests for type conversion and detection\n\t#\n\t# Copyright (C) 2005 Gerhard Häring <gh@ghaering.de>\n\t#\n\t# This file is part of pysqlite.\n\t#\n\t# This software is provided 'as-is', without any express or implied\n\t# warranty.  In no event will the authors be held liable for any damages\n\t# arising from the use of this software.\n\t#\n", "# Permission is granted to anyone to use this software for any purpose,\n\t# including commercial applications, and to alter it and redistribute it\n\t# freely, subject to the following restrictions:\n\t#\n\t# 1. The origin of this software must not be misrepresented; you must not\n\t#    claim that you wrote the original software. If you use this software\n\t#    in a product, an acknowledgment in the product documentation would be\n\t#    appreciated but is not required.\n\t# 2. Altered source versions must be plainly marked as such, and must not be\n\t#    misrepresented as being the original software.\n", "# 3. This notice may not be removed or altered from any source distribution.\n\timport datetime\n\timport unittest\n\tfrom . import libsql_client_helpers as sqlite\n\timport sys\n\ttry:\n\t    import zlib\n\texcept ImportError:\n\t    zlib = None\n\tfrom test import support\n", "class SqliteTypeTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        self.cur = self.con.cursor()\n\t        self.cur.execute(\"create table test(i integer, s varchar, f number, b blob)\")\n\t    def tearDown(self):\n\t        self.cur.close()\n\t        self.con.close()\n\t    def test_string(self):\n\t        self.cur.execute(\"insert into test(s) values (?)\", (\"Österreich\",))\n", "        self.cur.execute(\"select s from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], \"Österreich\")\n\t    def test_string_with_null_character(self):\n\t        self.cur.execute(\"insert into test(s) values (?)\", (\"a\\0b\",))\n\t        self.cur.execute(\"select s from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], \"a\\0b\")\n\t    def test_small_int(self):\n\t        self.cur.execute(\"insert into test(i) values (?)\", (42,))\n", "        self.cur.execute(\"select i from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], 42)\n\t    def test_large_int(self):\n\t        num = 123456789123456789\n\t        self.cur.execute(\"insert into test(i) values (?)\", (num,))\n\t        self.cur.execute(\"select i from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], num)\n\t    def test_float(self):\n", "        val = 3.14\n\t        self.cur.execute(\"insert into test(f) values (?)\", (val,))\n\t        self.cur.execute(\"select f from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], val)\n\t    def test_blob(self):\n\t        sample = b\"Guglhupf\"\n\t        val = memoryview(sample)\n\t        self.cur.execute(\"insert into test(b) values (?)\", (val,))\n\t        self.cur.execute(\"select b from test\")\n", "        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], sample)\n\t    def test_unicode_execute(self):\n\t        self.cur.execute(\"select 'Österreich'\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], \"Österreich\")\n\t    def test_too_large_int(self):\n\t        for value in 2**63, -2**63-1, 2**64:\n\t            with self.assertRaises(OverflowError):\n\t                self.cur.execute(\"insert into test(i) values (?)\", (value,))\n", "        self.cur.execute(\"select i from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertIsNone(row)\n\t    @unittest.skip(\"TODO: implement this check\")\n\t    def test_string_with_surrogates(self):\n\t        for value in 0xd8ff, 0xdcff:\n\t            with self.assertRaises(UnicodeEncodeError):\n\t                self.cur.execute(\"insert into test(s) values (?)\", (chr(value),))\n\t        self.cur.execute(\"select s from test\")\n\t        row = self.cur.fetchone()\n", "        self.assertIsNone(row)\n\t    @unittest.skipUnless(sys.maxsize > 2**32, 'requires 64bit platform')\n\t    @support.bigmemtest(size=2**31, memuse=4, dry_run=False)\n\t    def test_too_large_string(self, maxsize):\n\t        with self.assertRaises(sqlite.DataError):\n\t            self.cur.execute(\"insert into test(s) values (?)\", ('x'*(2**31-1),))\n\t        with self.assertRaises(sqlite.DataError):\n\t            self.cur.execute(\"insert into test(s) values (?)\", ('x'*(2**31),))\n\t        self.cur.execute(\"select 1 from test\")\n\t        row = self.cur.fetchone()\n", "        self.assertIsNone(row)\n\t    @unittest.skipUnless(sys.maxsize > 2**32, 'requires 64bit platform')\n\t    @support.bigmemtest(size=2**31, memuse=3, dry_run=False)\n\t    def test_too_large_blob(self, maxsize):\n\t        with self.assertRaises(sqlite.DataError):\n\t            self.cur.execute(\"insert into test(s) values (?)\", (b'x'*(2**31-1),))\n\t        with self.assertRaises(sqlite.DataError):\n\t            self.cur.execute(\"insert into test(s) values (?)\", (b'x'*(2**31),))\n\t        self.cur.execute(\"select 1 from test\")\n\t        row = self.cur.fetchone()\n", "        self.assertIsNone(row)\n\tclass DeclTypesTests(unittest.TestCase):\n\t    class Foo:\n\t        def __init__(self, _val):\n\t            if isinstance(_val, bytes):\n\t                # sqlite3 always calls __init__ with a bytes created from a\n\t                # UTF-8 string when __conform__ was used to store the object.\n\t                _val = _val.decode('utf-8')\n\t            self.val = _val\n\t        def __eq__(self, other):\n", "            if not isinstance(other, DeclTypesTests.Foo):\n\t                return NotImplemented\n\t            return self.val == other.val\n\t        def __conform__(self, protocol):\n\t            if protocol is sqlite.PrepareProtocol:\n\t                return self.val\n\t            else:\n\t                return None\n\t        def __str__(self):\n\t            return \"<%s>\" % self.val\n", "    class BadConform:\n\t        def __init__(self, exc):\n\t            self.exc = exc\n\t        def __conform__(self, protocol):\n\t            raise self.exc\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\", detect_types=sqlite.PARSE_DECLTYPES)\n\t        self.cur = self.con.cursor()\n\t        self.cur.execute(\"\"\"\n\t            create table test(\n", "                i int,\n\t                s str,\n\t                f float,\n\t                b bool,\n\t                u unicode,\n\t                foo foo,\n\t                bin blob,\n\t                n1 number,\n\t                n2 number(5),\n\t                bad bad,\n", "                cbin cblob)\n\t        \"\"\")\n\t        # override float, make them always return the same number\n\t        sqlite.converters[\"FLOAT\"] = lambda x: 47.2\n\t        # and implement two custom ones\n\t        sqlite.converters[\"BOOL\"] = lambda x: bool(int(x))\n\t        sqlite.converters[\"FOO\"] = DeclTypesTests.Foo\n\t        sqlite.converters[\"BAD\"] = DeclTypesTests.BadConform\n\t        sqlite.converters[\"WRONG\"] = lambda x: \"WRONG\"\n\t        sqlite.converters[\"NUMBER\"] = float\n", "        sqlite.converters[\"CBLOB\"] = lambda x: b\"blobish\"\n\t    def tearDown(self):\n\t        del sqlite.converters[\"FLOAT\"]\n\t        del sqlite.converters[\"BOOL\"]\n\t        del sqlite.converters[\"FOO\"]\n\t        del sqlite.converters[\"BAD\"]\n\t        del sqlite.converters[\"WRONG\"]\n\t        del sqlite.converters[\"NUMBER\"]\n\t        del sqlite.converters[\"CBLOB\"]\n\t        self.cur.close()\n", "        self.con.close()\n\t    def test_string(self):\n\t        # default\n\t        self.cur.execute(\"insert into test(s) values (?)\", (\"foo\",))\n\t        self.cur.execute('select s as \"s [WRONG]\" from test')\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], \"foo\")\n\t    def test_small_int(self):\n\t        # default\n\t        self.cur.execute(\"insert into test(i) values (?)\", (42,))\n", "        self.cur.execute(\"select i from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], 42)\n\t    def test_large_int(self):\n\t        # default\n\t        num = 123456789123456789\n\t        self.cur.execute(\"insert into test(i) values (?)\", (num,))\n\t        self.cur.execute(\"select i from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], num)\n", "    def test_float(self):\n\t        # custom\n\t        val = 3.14\n\t        self.cur.execute(\"insert into test(f) values (?)\", (val,))\n\t        self.cur.execute(\"select f from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], 47.2)\n\t    def test_bool(self):\n\t        # custom\n\t        self.cur.execute(\"insert into test(b) values (?)\", (False,))\n", "        self.cur.execute(\"select b from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertIs(row[0], False)\n\t        self.cur.execute(\"delete from test\")\n\t        self.cur.execute(\"insert into test(b) values (?)\", (True,))\n\t        self.cur.execute(\"select b from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertIs(row[0], True)\n\t    def test_unicode(self):\n\t        # default\n", "        val = \"\\xd6sterreich\"\n\t        self.cur.execute(\"insert into test(u) values (?)\", (val,))\n\t        self.cur.execute(\"select u from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], val)\n\t    def test_foo(self):\n\t        val = DeclTypesTests.Foo(\"bla\")\n\t        self.cur.execute(\"insert into test(foo) values (?)\", (val,))\n\t        self.cur.execute(\"select foo from test\")\n\t        row = self.cur.fetchone()\n", "        self.assertEqual(row[0], val)\n\t    def test_error_in_conform(self):\n\t        val = DeclTypesTests.BadConform(TypeError)\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cur.execute(\"insert into test(bad) values (?)\", (val,))\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cur.execute(\"insert into test(bad) values (:val)\", {\"val\": val})\n\t        val = DeclTypesTests.BadConform(KeyboardInterrupt)\n\t        with self.assertRaises(KeyboardInterrupt):\n\t            self.cur.execute(\"insert into test(bad) values (?)\", (val,))\n", "        with self.assertRaises(KeyboardInterrupt):\n\t            self.cur.execute(\"insert into test(bad) values (:val)\", {\"val\": val})\n\t    def test_unsupported_seq(self):\n\t        class Bar: pass\n\t        val = Bar()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cur.execute(\"insert into test(f) values (?)\", (val,))\n\t    def test_unsupported_dict(self):\n\t        class Bar: pass\n\t        val = Bar()\n", "        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cur.execute(\"insert into test(f) values (:val)\", {\"val\": val})\n\t    def test_blob(self):\n\t        # default\n\t        sample = b\"Guglhupf\"\n\t        val = memoryview(sample)\n\t        self.cur.execute(\"insert into test(bin) values (?)\", (val,))\n\t        self.cur.execute(\"select bin from test\")\n\t        row = self.cur.fetchone()\n\t        self.assertEqual(row[0], sample)\n", "    def test_number1(self):\n\t        self.cur.execute(\"insert into test(n1) values (5)\")\n\t        value = self.cur.execute(\"select n1 from test\").fetchone()[0]\n\t        # if the converter is not used, it's an int instead of a float\n\t        self.assertEqual(type(value), float)\n\t    def test_number2(self):\n\t        \"\"\"Checks whether converter names are cut off at '(' characters\"\"\"\n\t        self.cur.execute(\"insert into test(n2) values (5)\")\n\t        value = self.cur.execute(\"select n2 from test\").fetchone()[0]\n\t        # if the converter is not used, it's an int instead of a float\n", "        self.assertEqual(type(value), float)\n\t    def test_convert_zero_sized_blob(self):\n\t        self.con.execute(\"insert into test(cbin) values (?)\", (b\"\",))\n\t        cur = self.con.execute(\"select cbin from test\")\n\t        # Zero-sized blobs with converters returns None.  This differs from\n\t        # blobs without a converter, where b\"\" is returned.\n\t        self.assertIsNone(cur.fetchone()[0])\n\tclass ColNamesTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\", detect_types=sqlite.PARSE_COLNAMES)\n", "        self.cur = self.con.cursor()\n\t        self.cur.execute(\"create table test(x foo)\")\n\t        sqlite.converters[\"FOO\"] = lambda x: \"[%s]\" % x.decode(\"ascii\")\n\t        sqlite.converters[\"BAR\"] = lambda x: \"<%s>\" % x.decode(\"ascii\")\n\t        sqlite.converters[\"EXC\"] = lambda x: 5/0\n\t        sqlite.converters[\"B1B1\"] = lambda x: \"MARKER\"\n\t    def tearDown(self):\n\t        del sqlite.converters[\"FOO\"]\n\t        del sqlite.converters[\"BAR\"]\n\t        del sqlite.converters[\"EXC\"]\n", "        del sqlite.converters[\"B1B1\"]\n\t        self.cur.close()\n\t        self.con.close()\n\t    def test_decl_type_not_used(self):\n\t        \"\"\"\n\t        Assures that the declared type is not used when PARSE_DECLTYPES\n\t        is not set.\n\t        \"\"\"\n\t        self.cur.execute(\"insert into test(x) values (?)\", (\"xxx\",))\n\t        self.cur.execute(\"select x from test\")\n", "        val = self.cur.fetchone()[0]\n\t        self.assertEqual(val, \"xxx\")\n\t    def test_none(self):\n\t        self.cur.execute(\"insert into test(x) values (?)\", (None,))\n\t        self.cur.execute(\"select x from test\")\n\t        val = self.cur.fetchone()[0]\n\t        self.assertEqual(val, None)\n\t    def test_col_name(self):\n\t        self.cur.execute(\"insert into test(x) values (?)\", (\"xxx\",))\n\t        self.cur.execute('select x as \"x y [bar]\" from test')\n", "        val = self.cur.fetchone()[0]\n\t        self.assertEqual(val, \"<xxx>\")\n\t        # Check if the stripping of colnames works. Everything after the first\n\t        # '[' (and the preceding space) should be stripped.\n\t        self.assertEqual(self.cur.description[0][0], \"x y\")\n\t    def test_case_in_converter_name(self):\n\t        self.cur.execute(\"select 'other' as \\\"x [b1b1]\\\"\")\n\t        val = self.cur.fetchone()[0]\n\t        self.assertEqual(val, \"MARKER\")\n\t    def test_cursor_description_no_row(self):\n", "        \"\"\"\n\t        cursor.description should at least provide the column name(s), even if\n\t        no row returned.\n\t        \"\"\"\n\t        self.cur.execute(\"select * from test where 0 = 1\")\n\t        self.assertEqual(self.cur.description[0][0], \"x\")\n\t    def test_cursor_description_insert(self):\n\t        self.cur.execute(\"insert into test values (1)\")\n\t        self.assertIsNone(self.cur.description)\n\t@unittest.skipIf(sqlite.sqlite_version_info < (3, 8, 3), \"CTEs not supported\")\n", "class CommonTableExpressionTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        self.cur = self.con.cursor()\n\t        self.cur.execute(\"create table test(x foo)\")\n\t    def tearDown(self):\n\t        self.cur.close()\n\t        self.con.close()\n\t    def test_cursor_description_cte_simple(self):\n\t        self.cur.execute(\"with one as (select 1) select * from one\")\n", "        self.assertIsNotNone(self.cur.description)\n\t        self.assertEqual(self.cur.description[0][0], \"1\")\n\t    def test_cursor_description_cte_multiple_columns(self):\n\t        self.cur.execute(\"insert into test values(1)\")\n\t        self.cur.execute(\"insert into test values(2)\")\n\t        self.cur.execute(\"with testCTE as (select * from test) select * from testCTE\")\n\t        self.assertIsNotNone(self.cur.description)\n\t        self.assertEqual(self.cur.description[0][0], \"x\")\n\t    def test_cursor_description_cte(self):\n\t        self.cur.execute(\"insert into test values (1)\")\n", "        self.cur.execute(\"with bar as (select * from test) select * from test where x = 1\")\n\t        self.assertIsNotNone(self.cur.description)\n\t        self.assertEqual(self.cur.description[0][0], \"x\")\n\t        self.cur.execute(\"with bar as (select * from test) select * from test where x = 2\")\n\t        self.assertIsNotNone(self.cur.description)\n\t        self.assertEqual(self.cur.description[0][0], \"x\")\n\tclass ObjectAdaptationTests(unittest.TestCase):\n\t    def cast(obj):\n\t        return float(obj)\n\t    cast = staticmethod(cast)\n", "    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        try:\n\t            del sqlite.adapters[int]\n\t        except:\n\t            pass\n\t        sqlite.register_adapter(int, ObjectAdaptationTests.cast)\n\t        self.cur = self.con.cursor()\n\t    def tearDown(self):\n\t        del sqlite.adapters[(int, sqlite.PrepareProtocol)]\n", "        self.cur.close()\n\t        self.con.close()\n\t    def test_caster_is_used(self):\n\t        self.cur.execute(\"select ?\", (4,))\n\t        val = self.cur.fetchone()[0]\n\t        self.assertEqual(type(val), float)\n\t    def test_missing_adapter(self):\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            sqlite.adapt(1.)  # No float adapter registered\n\t    def test_missing_protocol(self):\n", "        with self.assertRaises(sqlite.ProgrammingError):\n\t            sqlite.adapt(1, None)\n\t    def test_defect_proto(self):\n\t        class DefectProto():\n\t            def __adapt__(self):\n\t                return None\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            sqlite.adapt(1., DefectProto)\n\t    def test_defect_self_adapt(self):\n\t        class DefectSelfAdapt(float):\n", "            def __conform__(self, _):\n\t                return None\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            sqlite.adapt(DefectSelfAdapt(1.))\n\t    def test_custom_proto(self):\n\t        class CustomProto():\n\t            def __adapt__(self):\n\t                return \"adapted\"\n\t        self.assertEqual(sqlite.adapt(1., CustomProto), \"adapted\")\n\t    def test_adapt(self):\n", "        val = 42\n\t        self.assertEqual(float(val), sqlite.adapt(val))\n\t    def test_adapt_alt(self):\n\t        alt = \"other\"\n\t        self.assertEqual(alt, sqlite.adapt(1., None, alt))\n\t@unittest.skipUnless(zlib, \"requires zlib\")\n\tclass BinaryConverterTests(unittest.TestCase):\n\t    def convert(s):\n\t        return zlib.decompress(s)\n\t    convert = staticmethod(convert)\n", "    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\", detect_types=sqlite.PARSE_COLNAMES)\n\t        sqlite.register_converter(\"bin\", BinaryConverterTests.convert)\n\t    def tearDown(self):\n\t        self.con.close()\n\t    def test_binary_input_for_converter(self):\n\t        testdata = b\"abcdefg\" * 10\n\t        result = self.con.execute('select ? as \"x [bin]\"', (memoryview(zlib.compress(testdata)),)).fetchone()[0]\n\t        self.assertEqual(testdata, result)\n\tclass DateTimeTests(unittest.TestCase):\n", "    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\", detect_types=sqlite.PARSE_DECLTYPES)\n\t        self.cur = self.con.cursor()\n\t        self.cur.execute(\"create table test(d date, ts timestamp)\")\n\t    def tearDown(self):\n\t        self.cur.close()\n\t        self.con.close()\n\t    def test_sqlite_date(self):\n\t        d = sqlite.Date(2004, 2, 14)\n\t        self.cur.execute(\"insert into test(d) values (?)\", (d,))\n", "        self.cur.execute(\"select d from test\")\n\t        d2 = self.cur.fetchone()[0]\n\t        self.assertEqual(d, d2)\n\t    def test_sqlite_timestamp(self):\n\t        ts = sqlite.Timestamp(2004, 2, 14, 7, 15, 0)\n\t        self.cur.execute(\"insert into test(ts) values (?)\", (ts,))\n\t        self.cur.execute(\"select ts from test\")\n\t        ts2 = self.cur.fetchone()[0]\n\t        self.assertEqual(ts, ts2)\n\t    def test_sql_timestamp(self):\n", "        now = datetime.datetime.utcnow()\n\t        self.cur.execute(\"insert into test(ts) values (current_timestamp)\")\n\t        self.cur.execute(\"select ts from test\")\n\t        ts = self.cur.fetchone()[0]\n\t        self.assertEqual(type(ts), datetime.datetime)\n\t        self.assertEqual(ts.year, now.year)\n\t    def test_date_time_sub_seconds(self):\n\t        ts = sqlite.Timestamp(2004, 2, 14, 7, 15, 0, 500000)\n\t        self.cur.execute(\"insert into test(ts) values (?)\", (ts,))\n\t        self.cur.execute(\"select ts from test\")\n", "        ts2 = self.cur.fetchone()[0]\n\t        self.assertEqual(ts, ts2)\n\t    def test_date_time_sub_seconds_floating_point(self):\n\t        ts = sqlite.Timestamp(2004, 2, 14, 7, 15, 0, 510241)\n\t        self.cur.execute(\"insert into test(ts) values (?)\", (ts,))\n\t        self.cur.execute(\"select ts from test\")\n\t        ts2 = self.cur.fetchone()[0]\n\t        self.assertEqual(ts, ts2)\n\tif __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/test_dump.py", "chunked_list": ["# Author: Paul Kippes <kippesp@gmail.com>\n\timport unittest\n\tfrom . import libsql_client_helpers as sqlite\n\tfrom .test_dbapi import memory_database\n\tclass DumpTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.cx = sqlite.connect(\":memory:\")\n\t        self.cu = self.cx.cursor()\n\t    def tearDown(self):\n\t        self.cx.close()\n", "    @unittest.skip(\"sqld doesn't support triggers yet\")\n\t    def test_table_dump(self):\n\t        expected_sqls = [\n\t                \"\"\"CREATE TABLE \"index\"(\"index\" blob);\"\"\"\n\t                ,\n\t                \"\"\"INSERT INTO \"index\" VALUES(X'01');\"\"\"\n\t                ,\n\t                \"\"\"CREATE TABLE \"quoted\"\"table\"(\"quoted\"\"field\" text);\"\"\"\n\t                ,\n\t                \"\"\"INSERT INTO \"quoted\"\"table\" VALUES('quoted''value');\"\"\"\n", "                ,\n\t                \"CREATE TABLE t1(id integer primary key, s1 text, \" \\\n\t                \"t1_i1 integer not null, i2 integer, unique (s1), \" \\\n\t                \"constraint t1_idx1 unique (i2));\"\n\t                ,\n\t                \"INSERT INTO \\\"t1\\\" VALUES(1,'foo',10,20);\"\n\t                ,\n\t                \"INSERT INTO \\\"t1\\\" VALUES(2,'foo2',30,30);\"\n\t                ,\n\t                \"CREATE TABLE t2(id integer, t2_i1 integer, \" \\\n", "                \"t2_i2 integer, primary key (id),\" \\\n\t                \"foreign key(t2_i1) references t1(t1_i1));\"\n\t                ,\n\t                \"CREATE TRIGGER trigger_1 update of t1_i1 on t1 \" \\\n\t                \"begin \" \\\n\t                \"update t2 set t2_i1 = new.t1_i1 where t2_i1 = old.t1_i1; \" \\\n\t                \"end;\"\n\t                ,\n\t                \"CREATE VIEW v1 as select * from t1 left join t2 \" \\\n\t                \"using (id);\"\n", "                ]\n\t        [self.cu.execute(s) for s in expected_sqls]\n\t        i = self.cx.iterdump()\n\t        actual_sqls = [s for s in i]\n\t        expected_sqls = ['BEGIN TRANSACTION;'] + expected_sqls + \\\n\t            ['COMMIT;']\n\t        [self.assertEqual(expected_sqls[i], actual_sqls[i])\n\t            for i in range(len(expected_sqls))]\n\t    @unittest.skip(\"sqld adds more tables and this exact test fails\")\n\t    def test_dump_autoincrement(self):\n", "        expected = [\n\t            'CREATE TABLE \"t1\" (id integer primary key autoincrement);',\n\t            'INSERT INTO \"t1\" VALUES(NULL);',\n\t            'CREATE TABLE \"t2\" (id integer primary key autoincrement);',\n\t        ]\n\t        self.cu.executescript(\"\".join(expected))\n\t        # the NULL value should now be automatically be set to 1\n\t        expected[1] = expected[1].replace(\"NULL\", \"1\")\n\t        expected.insert(0, \"BEGIN TRANSACTION;\")\n\t        expected.extend([\n", "            'DELETE FROM \"sqlite_sequence\";',\n\t            'INSERT INTO \"sqlite_sequence\" VALUES(\\'t1\\',1);',\n\t            'COMMIT;',\n\t        ])\n\t        actual = [stmt for stmt in self.cx.iterdump()]\n\t        self.assertEqual(expected, actual)\n\t    @unittest.skip(\"sqld cannot create new db\")\n\t    def test_dump_autoincrement_create_new_db(self):\n\t        self.cu.execute(\"BEGIN TRANSACTION\")\n\t        self.cu.execute(\"CREATE TABLE t1 (id integer primary key autoincrement)\")\n", "        self.cu.execute(\"CREATE TABLE t2 (id integer primary key autoincrement)\")\n\t        self.cu.executemany(\"INSERT INTO t1 VALUES(?)\", ((None,) for _ in range(9)))\n\t        self.cu.executemany(\"INSERT INTO t2 VALUES(?)\", ((None,) for _ in range(4)))\n\t        self.cx.commit()\n\t        with memory_database() as cx2:\n\t            query = \"\".join(self.cx.iterdump())\n\t            cx2.executescript(query)\n\t            cu2 = cx2.cursor()\n\t            dataset = (\n\t                (\"t1\", 9),\n", "                (\"t2\", 4),\n\t            )\n\t            for table, seq in dataset:\n\t                with self.subTest(table=table, seq=seq):\n\t                    res = cu2.execute(\"\"\"\n\t                        SELECT \"seq\" FROM \"sqlite_sequence\" WHERE \"name\" == ?\n\t                    \"\"\", (table,))\n\t                    rows = res.fetchall()\n\t                    self.assertEqual(rows[0][0], seq)\n\t    @unittest.skip(\"sqld adds more tables and this exact test fails\")\n", "    def test_unorderable_row(self):\n\t        # iterdump() should be able to cope with unorderable row types (issue #15545)\n\t        class UnorderableRow:\n\t            def __init__(self, cursor, row):\n\t                self.row = row\n\t            def __getitem__(self, index):\n\t                return self.row[index]\n\t        self.cx.row_factory = UnorderableRow\n\t        CREATE_ALPHA = \"\"\"CREATE TABLE \"alpha\" (\"one\");\"\"\"\n\t        CREATE_BETA = \"\"\"CREATE TABLE \"beta\" (\"two\");\"\"\"\n", "        expected = [\n\t            \"BEGIN TRANSACTION;\",\n\t            CREATE_ALPHA,\n\t            CREATE_BETA,\n\t            \"COMMIT;\"\n\t            ]\n\t        self.cu.execute(CREATE_BETA)\n\t        self.cu.execute(CREATE_ALPHA)\n\t        got = list(self.cx.iterdump())\n\t        self.assertEqual(expected, got)\n", "if __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/__init__.py", "chunked_list": []}
{"filename": "tests/dbapi2/test_hooks.py", "chunked_list": ["# pysqlite2/test/hooks.py: tests for various SQLite-specific hooks\n\t#\n\t# Copyright (C) 2006-2007 Gerhard Häring <gh@ghaering.de>\n\t#\n\t# This file is part of pysqlite.\n\t#\n\t# This software is provided 'as-is', without any express or implied\n\t# warranty.  In no event will the authors be held liable for any damages\n\t# arising from the use of this software.\n\t#\n", "# Permission is granted to anyone to use this software for any purpose,\n\t# including commercial applications, and to alter it and redistribute it\n\t# freely, subject to the following restrictions:\n\t#\n\t# 1. The origin of this software must not be misrepresented; you must not\n\t#    claim that you wrote the original software. If you use this software\n\t#    in a product, an acknowledgment in the product documentation would be\n\t#    appreciated but is not required.\n\t# 2. Altered source versions must be plainly marked as such, and must not be\n\t#    misrepresented as being the original software.\n", "# 3. This notice may not be removed or altered from any source distribution.\n\timport contextlib\n\tfrom . import libsql_client_helpers as sqlite\n\timport unittest\n\tfrom test.support.os_helper import TESTFN, unlink\n\tfrom .test_dbapi import memory_database, cx_limit\n\tfrom .test_userfunctions import with_tracebacks\n\t@unittest.skip(\"Not supported\")\n\tclass CollationTests(unittest.TestCase):\n\t    def test_create_collation_not_string(self):\n", "        con = sqlite.connect(\":memory:\")\n\t        with self.assertRaises(TypeError):\n\t            con.create_collation(None, lambda x, y: (x > y) - (x < y))\n\t    def test_create_collation_not_callable(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        with self.assertRaises(TypeError) as cm:\n\t            con.create_collation(\"X\", 42)\n\t        self.assertEqual(str(cm.exception), 'parameter must be callable')\n\t    def test_create_collation_not_ascii(self):\n\t        con = sqlite.connect(\":memory:\")\n", "        con.create_collation(\"collä\", lambda x, y: (x > y) - (x < y))\n\t    def test_create_collation_bad_upper(self):\n\t        class BadUpperStr(str):\n\t            def upper(self):\n\t                return None\n\t        con = sqlite.connect(\":memory:\")\n\t        mycoll = lambda x, y: -((x > y) - (x < y))\n\t        con.create_collation(BadUpperStr(\"mycoll\"), mycoll)\n\t        result = con.execute(\"\"\"\n\t            select x from (\n", "            select 'a' as x\n\t            union\n\t            select 'b' as x\n\t            ) order by x collate mycoll\n\t            \"\"\").fetchall()\n\t        self.assertEqual(result[0][0], 'b')\n\t        self.assertEqual(result[1][0], 'a')\n\t    def test_collation_is_used(self):\n\t        def mycoll(x, y):\n\t            # reverse order\n", "            return -((x > y) - (x < y))\n\t        con = sqlite.connect(\":memory:\")\n\t        con.create_collation(\"mycoll\", mycoll)\n\t        sql = \"\"\"\n\t            select x from (\n\t            select 'a' as x\n\t            union\n\t            select 'b' as x\n\t            union\n\t            select 'c' as x\n", "            ) order by x collate mycoll\n\t            \"\"\"\n\t        result = con.execute(sql).fetchall()\n\t        self.assertEqual(result, [('c',), ('b',), ('a',)],\n\t                         msg='the expected order was not returned')\n\t        con.create_collation(\"mycoll\", None)\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            result = con.execute(sql).fetchall()\n\t        self.assertEqual(str(cm.exception), 'no such collation sequence: mycoll')\n\t    def test_collation_returns_large_integer(self):\n", "        def mycoll(x, y):\n\t            # reverse order\n\t            return -((x > y) - (x < y)) * 2**32\n\t        con = sqlite.connect(\":memory:\")\n\t        con.create_collation(\"mycoll\", mycoll)\n\t        sql = \"\"\"\n\t            select x from (\n\t            select 'a' as x\n\t            union\n\t            select 'b' as x\n", "            union\n\t            select 'c' as x\n\t            ) order by x collate mycoll\n\t            \"\"\"\n\t        result = con.execute(sql).fetchall()\n\t        self.assertEqual(result, [('c',), ('b',), ('a',)],\n\t                         msg=\"the expected order was not returned\")\n\t    def test_collation_register_twice(self):\n\t        \"\"\"\n\t        Register two different collation functions under the same name.\n", "        Verify that the last one is actually used.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        con.create_collation(\"mycoll\", lambda x, y: (x > y) - (x < y))\n\t        con.create_collation(\"mycoll\", lambda x, y: -((x > y) - (x < y)))\n\t        result = con.execute(\"\"\"\n\t            select x from (select 'a' as x union select 'b' as x) order by x collate mycoll\n\t            \"\"\").fetchall()\n\t        self.assertEqual(result[0][0], 'b')\n\t        self.assertEqual(result[1][0], 'a')\n", "    def test_deregister_collation(self):\n\t        \"\"\"\n\t        Register a collation, then deregister it. Make sure an error is raised if we try\n\t        to use it.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        con.create_collation(\"mycoll\", lambda x, y: (x > y) - (x < y))\n\t        con.create_collation(\"mycoll\", None)\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            con.execute(\"select 'a' as x union select 'b' as x order by x collate mycoll\")\n", "        self.assertEqual(str(cm.exception), 'no such collation sequence: mycoll')\n\t@unittest.skip(\"Not supported\")\n\tclass ProgressTests(unittest.TestCase):\n\t    def test_progress_handler_used(self):\n\t        \"\"\"\n\t        Test that the progress handler is invoked once it is set.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        progress_calls = []\n\t        def progress():\n", "            progress_calls.append(None)\n\t            return 0\n\t        con.set_progress_handler(progress, 1)\n\t        con.execute(\"\"\"\n\t            create table foo(a, b)\n\t            \"\"\")\n\t        self.assertTrue(progress_calls)\n\t    def test_opcode_count(self):\n\t        \"\"\"\n\t        Test that the opcode argument is respected.\n", "        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        progress_calls = []\n\t        def progress():\n\t            progress_calls.append(None)\n\t            return 0\n\t        con.set_progress_handler(progress, 1)\n\t        curs = con.cursor()\n\t        curs.execute(\"\"\"\n\t            create table foo (a, b)\n", "            \"\"\")\n\t        first_count = len(progress_calls)\n\t        progress_calls = []\n\t        con.set_progress_handler(progress, 2)\n\t        curs.execute(\"\"\"\n\t            create table bar (a, b)\n\t            \"\"\")\n\t        second_count = len(progress_calls)\n\t        self.assertGreaterEqual(first_count, second_count)\n\t    def test_cancel_operation(self):\n", "        \"\"\"\n\t        Test that returning a non-zero value stops the operation in progress.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        def progress():\n\t            return 1\n\t        con.set_progress_handler(progress, 1)\n\t        curs = con.cursor()\n\t        self.assertRaises(\n\t            sqlite.OperationalError,\n", "            curs.execute,\n\t            \"create table bar (a, b)\")\n\t    def test_clear_handler(self):\n\t        \"\"\"\n\t        Test that setting the progress handler to None clears the previously set handler.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        action = 0\n\t        def progress():\n\t            nonlocal action\n", "            action = 1\n\t            return 0\n\t        con.set_progress_handler(progress, 1)\n\t        con.set_progress_handler(None, 1)\n\t        con.execute(\"select 1 union select 2 union select 3\").fetchall()\n\t        self.assertEqual(action, 0, \"progress handler was not cleared\")\n\t    @with_tracebacks(ZeroDivisionError, name=\"bad_progress\")\n\t    def test_error_in_progress_handler(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        def bad_progress():\n", "            1 / 0\n\t        con.set_progress_handler(bad_progress, 1)\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            con.execute(\"\"\"\n\t                create table foo(a, b)\n\t                \"\"\")\n\t    @with_tracebacks(ZeroDivisionError, name=\"bad_progress\")\n\t    def test_error_in_progress_handler_result(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        class BadBool:\n", "            def __bool__(self):\n\t                1 / 0\n\t        def bad_progress():\n\t            return BadBool()\n\t        con.set_progress_handler(bad_progress, 1)\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            con.execute(\"\"\"\n\t                create table foo(a, b)\n\t                \"\"\")\n\tclass TraceCallbackTests(unittest.TestCase):\n", "    @contextlib.contextmanager\n\t    def check_stmt_trace(self, cx, expected):\n\t        try:\n\t            traced = []\n\t            cx.set_trace_callback(lambda stmt: traced.append(stmt))\n\t            yield\n\t        finally:\n\t            self.assertEqual(traced, expected)\n\t            cx.set_trace_callback(None)\n\t    def test_trace_callback_used(self):\n", "        \"\"\"\n\t        Test that the trace callback is invoked once it is set.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        traced_statements = []\n\t        def trace(statement):\n\t            traced_statements.append(statement)\n\t        con.set_trace_callback(trace)\n\t        con.execute(\"create table foo(a, b)\")\n\t        self.assertTrue(traced_statements)\n", "        self.assertTrue(any(\"create table foo\" in stmt for stmt in traced_statements))\n\t    def test_clear_trace_callback(self):\n\t        \"\"\"\n\t        Test that setting the trace callback to None clears the previously set callback.\n\t        \"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        traced_statements = []\n\t        def trace(statement):\n\t            traced_statements.append(statement)\n\t        con.set_trace_callback(trace)\n", "        con.set_trace_callback(None)\n\t        con.execute(\"create table foo(a, b)\")\n\t        self.assertFalse(traced_statements, \"trace callback was not cleared\")\n\t    def test_unicode_content(self):\n\t        \"\"\"\n\t        Test that the statement can contain unicode literals.\n\t        \"\"\"\n\t        unicode_value = '\\xf6\\xe4\\xfc\\xd6\\xc4\\xdc\\xdf\\u20ac'\n\t        con = sqlite.connect(\":memory:\")\n\t        traced_statements = []\n", "        def trace(statement):\n\t            traced_statements.append(statement)\n\t        con.set_trace_callback(trace)\n\t        con.execute(\"create table foo(x)\")\n\t        con.execute(\"insert into foo(x) values ('%s')\" % unicode_value)\n\t        con.commit()\n\t        self.assertTrue(any(unicode_value in stmt for stmt in traced_statements),\n\t                        \"Unicode data %s garbled in trace callback: %s\"\n\t                        % (ascii(unicode_value), ', '.join(map(ascii, traced_statements))))\n\t    def test_trace_callback_content(self):\n", "        # set_trace_callback() shouldn't produce duplicate content (bpo-26187)\n\t        traced_statements = []\n\t        def trace(statement):\n\t            traced_statements.append(statement)\n\t        queries = [\"create table foo(x)\",\n\t                   \"insert into foo(x) values(1)\"]\n\t        self.addCleanup(unlink, TESTFN)\n\t        con1 = sqlite.connect(TESTFN, isolation_level=None)\n\t        con2 = sqlite.connect(TESTFN)\n\t        try:\n", "            con1.set_trace_callback(trace)\n\t            cur = con1.cursor()\n\t            cur.execute(queries[0])\n\t            con2.execute(\"create table bar(x)\")\n\t            cur.execute(queries[1])\n\t        finally:\n\t            con1.close()\n\t            con2.close()\n\t        self.assertEqual(traced_statements, queries)\n\t    @unittest.skip(\"libsql_client doesn't support expanded sql\")\n", "    def test_trace_expanded_sql(self):\n\t        expected = [\n\t            \"create table t(t)\",\n\t            \"BEGIN \",\n\t            \"insert into t values(0)\",\n\t            \"insert into t values(1)\",\n\t            \"insert into t values(2)\",\n\t            \"COMMIT\",\n\t        ]\n\t        with memory_database() as cx, self.check_stmt_trace(cx, expected):\n", "            with cx:\n\t                cx.execute(\"create table t(t)\")\n\t                cx.executemany(\"insert into t values(?)\", ((v,) for v in range(3)))\n\t    @unittest.skip(\"libsql_client doesn't support expanded sql\")\n\t    @with_tracebacks(\n\t        sqlite.DataError,\n\t        regex=\"Expanded SQL string exceeds the maximum string length\"\n\t    )\n\t    def test_trace_too_much_expanded_sql(self):\n\t        # If the expanded string is too large, we'll fall back to the\n", "        # unexpanded SQL statement (for SQLite 3.14.0 and newer).\n\t        # The resulting string length is limited by the runtime limit\n\t        # SQLITE_LIMIT_LENGTH.\n\t        template = \"select 1 as a where a=\"\n\t        category = sqlite.SQLITE_LIMIT_LENGTH\n\t        with memory_database() as cx, cx_limit(cx, category=category) as lim:\n\t            ok_param = \"a\"\n\t            bad_param = \"a\" * lim\n\t            unexpanded_query = template + \"?\"\n\t            expected = [unexpanded_query]\n", "            if sqlite.sqlite_version_info < (3, 14, 0):\n\t                expected = []\n\t            with self.check_stmt_trace(cx, expected):\n\t                cx.execute(unexpanded_query, (bad_param,))\n\t            expanded_query = f\"{template}'{ok_param}'\"\n\t            with self.check_stmt_trace(cx, [expanded_query]):\n\t                cx.execute(unexpanded_query, (ok_param,))\n\t    @with_tracebacks(ZeroDivisionError, regex=\"division by zero\")\n\t    def test_trace_bad_handler(self):\n\t        with memory_database() as cx:\n", "            cx.set_trace_callback(lambda stmt: 5/0)\n\t            cx.execute(\"select 1\")\n\tif __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/test_dbapi.py", "chunked_list": ["# pysqlite2/test/dbapi.py: tests for DB-API compliance\n\t#\n\t# Copyright (C) 2004-2010 Gerhard Häring <gh@ghaering.de>\n\t#\n\t# This file is part of pysqlite.\n\t#\n\t# This software is provided 'as-is', without any express or implied\n\t# warranty.  In no event will the authors be held liable for any damages\n\t# arising from the use of this software.\n\t#\n", "# Permission is granted to anyone to use this software for any purpose,\n\t# including commercial applications, and to alter it and redistribute it\n\t# freely, subject to the following restrictions:\n\t#\n\t# 1. The origin of this software must not be misrepresented; you must not\n\t#    claim that you wrote the original software. If you use this software\n\t#    in a product, an acknowledgment in the product documentation would be\n\t#    appreciated but is not required.\n\t# 2. Altered source versions must be plainly marked as such, and must not be\n\t#    misrepresented as being the original software.\n", "# 3. This notice may not be removed or altered from any source distribution.\n\timport contextlib\n\timport os\n\tfrom . import libsql_client_helpers as sqlite\n\timport subprocess\n\timport sys\n\timport threading\n\timport unittest\n\timport urllib.parse\n\tfrom test.support import (\n", "    SHORT_TIMEOUT, bigmemtest, check_disallow_instantiation, requires_subprocess,\n\t    is_emscripten, is_wasi\n\t)\n\tfrom test.support import threading_helper\n\tfrom _testcapi import INT_MAX, ULLONG_MAX\n\tfrom os import SEEK_SET, SEEK_CUR, SEEK_END\n\tfrom test.support.os_helper import TESTFN, TESTFN_UNDECODABLE, unlink, temp_dir, FakePath\n\t# Helper for temporary memory databases\n\tdef memory_database(*args, **kwargs):\n\t    cx = sqlite.connect(\":memory:\", *args, **kwargs)\n", "    return contextlib.closing(cx)\n\t# Temporarily limit a database connection parameter\n\t@contextlib.contextmanager\n\tdef cx_limit(cx, category=sqlite.SQLITE_LIMIT_SQL_LENGTH, limit=128):\n\t    try:\n\t        _prev = cx.setlimit(category, limit)\n\t        yield limit\n\t    finally:\n\t        cx.setlimit(category, _prev)\n\tclass ModuleTests(unittest.TestCase):\n", "    def test_api_level(self):\n\t        self.assertEqual(sqlite.apilevel, \"2.0\",\n\t                         \"apilevel is %s, should be 2.0\" % sqlite.apilevel)\n\t    def test_thread_safety(self):\n\t        self.assertIn(sqlite.threadsafety, {0, 1, 3},\n\t                      \"threadsafety is %d, should be 0, 1 or 3\" %\n\t                      sqlite.threadsafety)\n\t    def test_param_style(self):\n\t        self.assertEqual(sqlite.paramstyle, \"qmark\",\n\t                         \"paramstyle is '%s', should be 'qmark'\" %\n", "                         sqlite.paramstyle)\n\t    def test_warning(self):\n\t        self.assertTrue(issubclass(sqlite.Warning, Exception),\n\t                     \"Warning is not a subclass of Exception\")\n\t    def test_error(self):\n\t        self.assertTrue(issubclass(sqlite.Error, Exception),\n\t                        \"Error is not a subclass of Exception\")\n\t    def test_interface_error(self):\n\t        self.assertTrue(issubclass(sqlite.InterfaceError, sqlite.Error),\n\t                        \"InterfaceError is not a subclass of Error\")\n", "    def test_database_error(self):\n\t        self.assertTrue(issubclass(sqlite.DatabaseError, sqlite.Error),\n\t                        \"DatabaseError is not a subclass of Error\")\n\t    def test_data_error(self):\n\t        self.assertTrue(issubclass(sqlite.DataError, sqlite.DatabaseError),\n\t                        \"DataError is not a subclass of DatabaseError\")\n\t    def test_operational_error(self):\n\t        self.assertTrue(issubclass(sqlite.OperationalError, sqlite.DatabaseError),\n\t                        \"OperationalError is not a subclass of DatabaseError\")\n\t    def test_integrity_error(self):\n", "        self.assertTrue(issubclass(sqlite.IntegrityError, sqlite.DatabaseError),\n\t                        \"IntegrityError is not a subclass of DatabaseError\")\n\t    def test_internal_error(self):\n\t        self.assertTrue(issubclass(sqlite.InternalError, sqlite.DatabaseError),\n\t                        \"InternalError is not a subclass of DatabaseError\")\n\t    def test_programming_error(self):\n\t        self.assertTrue(issubclass(sqlite.ProgrammingError, sqlite.DatabaseError),\n\t                        \"ProgrammingError is not a subclass of DatabaseError\")\n\t    def test_not_supported_error(self):\n\t        self.assertTrue(issubclass(sqlite.NotSupportedError,\n", "                                   sqlite.DatabaseError),\n\t                        \"NotSupportedError is not a subclass of DatabaseError\")\n\t    def test_module_constants(self):\n\t        consts = [\n\t            \"SQLITE_ABORT\",\n\t            \"SQLITE_ALTER_TABLE\",\n\t            \"SQLITE_ANALYZE\",\n\t            \"SQLITE_ATTACH\",\n\t            \"SQLITE_AUTH\",\n\t            \"SQLITE_BUSY\",\n", "            \"SQLITE_CANTOPEN\",\n\t            \"SQLITE_CONSTRAINT\",\n\t            \"SQLITE_CORRUPT\",\n\t            \"SQLITE_CREATE_INDEX\",\n\t            \"SQLITE_CREATE_TABLE\",\n\t            \"SQLITE_CREATE_TEMP_INDEX\",\n\t            \"SQLITE_CREATE_TEMP_TABLE\",\n\t            \"SQLITE_CREATE_TEMP_TRIGGER\",\n\t            \"SQLITE_CREATE_TEMP_VIEW\",\n\t            \"SQLITE_CREATE_TRIGGER\",\n", "            \"SQLITE_CREATE_VIEW\",\n\t            \"SQLITE_CREATE_VTABLE\",\n\t            \"SQLITE_DELETE\",\n\t            \"SQLITE_DENY\",\n\t            \"SQLITE_DETACH\",\n\t            \"SQLITE_DONE\",\n\t            \"SQLITE_DROP_INDEX\",\n\t            \"SQLITE_DROP_TABLE\",\n\t            \"SQLITE_DROP_TEMP_INDEX\",\n\t            \"SQLITE_DROP_TEMP_TABLE\",\n", "            \"SQLITE_DROP_TEMP_TRIGGER\",\n\t            \"SQLITE_DROP_TEMP_VIEW\",\n\t            \"SQLITE_DROP_TRIGGER\",\n\t            \"SQLITE_DROP_VIEW\",\n\t            \"SQLITE_DROP_VTABLE\",\n\t            \"SQLITE_EMPTY\",\n\t            \"SQLITE_ERROR\",\n\t            \"SQLITE_FORMAT\",\n\t            \"SQLITE_FULL\",\n\t            \"SQLITE_FUNCTION\",\n", "            \"SQLITE_IGNORE\",\n\t            \"SQLITE_INSERT\",\n\t            \"SQLITE_INTERNAL\",\n\t            \"SQLITE_INTERRUPT\",\n\t            \"SQLITE_IOERR\",\n\t            \"SQLITE_LOCKED\",\n\t            \"SQLITE_MISMATCH\",\n\t            \"SQLITE_MISUSE\",\n\t            \"SQLITE_NOLFS\",\n\t            \"SQLITE_NOMEM\",\n", "            \"SQLITE_NOTADB\",\n\t            \"SQLITE_NOTFOUND\",\n\t            \"SQLITE_OK\",\n\t            \"SQLITE_PERM\",\n\t            \"SQLITE_PRAGMA\",\n\t            \"SQLITE_PROTOCOL\",\n\t            \"SQLITE_RANGE\",\n\t            \"SQLITE_READ\",\n\t            \"SQLITE_READONLY\",\n\t            \"SQLITE_REINDEX\",\n", "            \"SQLITE_ROW\",\n\t            \"SQLITE_SAVEPOINT\",\n\t            \"SQLITE_SCHEMA\",\n\t            \"SQLITE_SELECT\",\n\t            \"SQLITE_TOOBIG\",\n\t            \"SQLITE_TRANSACTION\",\n\t            \"SQLITE_UPDATE\",\n\t            # Run-time limit categories\n\t            \"SQLITE_LIMIT_LENGTH\",\n\t            \"SQLITE_LIMIT_SQL_LENGTH\",\n", "            \"SQLITE_LIMIT_COLUMN\",\n\t            \"SQLITE_LIMIT_EXPR_DEPTH\",\n\t            \"SQLITE_LIMIT_COMPOUND_SELECT\",\n\t            \"SQLITE_LIMIT_VDBE_OP\",\n\t            \"SQLITE_LIMIT_FUNCTION_ARG\",\n\t            \"SQLITE_LIMIT_ATTACHED\",\n\t            \"SQLITE_LIMIT_LIKE_PATTERN_LENGTH\",\n\t            \"SQLITE_LIMIT_VARIABLE_NUMBER\",\n\t            \"SQLITE_LIMIT_TRIGGER_DEPTH\",\n\t        ]\n", "        if sqlite.sqlite_version_info >= (3, 7, 17):\n\t            consts += [\"SQLITE_NOTICE\", \"SQLITE_WARNING\"]\n\t        if sqlite.sqlite_version_info >= (3, 8, 3):\n\t            consts.append(\"SQLITE_RECURSIVE\")\n\t        if sqlite.sqlite_version_info >= (3, 8, 7):\n\t            consts.append(\"SQLITE_LIMIT_WORKER_THREADS\")\n\t        consts += [\"PARSE_DECLTYPES\", \"PARSE_COLNAMES\"]\n\t        # Extended result codes\n\t        consts += [\n\t            \"SQLITE_ABORT_ROLLBACK\",\n", "            \"SQLITE_BUSY_RECOVERY\",\n\t            \"SQLITE_CANTOPEN_FULLPATH\",\n\t            \"SQLITE_CANTOPEN_ISDIR\",\n\t            \"SQLITE_CANTOPEN_NOTEMPDIR\",\n\t            \"SQLITE_CORRUPT_VTAB\",\n\t            \"SQLITE_IOERR_ACCESS\",\n\t            \"SQLITE_IOERR_BLOCKED\",\n\t            \"SQLITE_IOERR_CHECKRESERVEDLOCK\",\n\t            \"SQLITE_IOERR_CLOSE\",\n\t            \"SQLITE_IOERR_DELETE\",\n", "            \"SQLITE_IOERR_DELETE_NOENT\",\n\t            \"SQLITE_IOERR_DIR_CLOSE\",\n\t            \"SQLITE_IOERR_DIR_FSYNC\",\n\t            \"SQLITE_IOERR_FSTAT\",\n\t            \"SQLITE_IOERR_FSYNC\",\n\t            \"SQLITE_IOERR_LOCK\",\n\t            \"SQLITE_IOERR_NOMEM\",\n\t            \"SQLITE_IOERR_RDLOCK\",\n\t            \"SQLITE_IOERR_READ\",\n\t            \"SQLITE_IOERR_SEEK\",\n", "            \"SQLITE_IOERR_SHMLOCK\",\n\t            \"SQLITE_IOERR_SHMMAP\",\n\t            \"SQLITE_IOERR_SHMOPEN\",\n\t            \"SQLITE_IOERR_SHMSIZE\",\n\t            \"SQLITE_IOERR_SHORT_READ\",\n\t            \"SQLITE_IOERR_TRUNCATE\",\n\t            \"SQLITE_IOERR_UNLOCK\",\n\t            \"SQLITE_IOERR_WRITE\",\n\t            \"SQLITE_LOCKED_SHAREDCACHE\",\n\t            \"SQLITE_READONLY_CANTLOCK\",\n", "            \"SQLITE_READONLY_RECOVERY\",\n\t        ]\n\t        if sqlite.sqlite_version_info >= (3, 7, 16):\n\t            consts += [\n\t                \"SQLITE_CONSTRAINT_CHECK\",\n\t                \"SQLITE_CONSTRAINT_COMMITHOOK\",\n\t                \"SQLITE_CONSTRAINT_FOREIGNKEY\",\n\t                \"SQLITE_CONSTRAINT_FUNCTION\",\n\t                \"SQLITE_CONSTRAINT_NOTNULL\",\n\t                \"SQLITE_CONSTRAINT_PRIMARYKEY\",\n", "                \"SQLITE_CONSTRAINT_TRIGGER\",\n\t                \"SQLITE_CONSTRAINT_UNIQUE\",\n\t                \"SQLITE_CONSTRAINT_VTAB\",\n\t                \"SQLITE_READONLY_ROLLBACK\",\n\t            ]\n\t        if sqlite.sqlite_version_info >= (3, 7, 17):\n\t            consts += [\n\t                \"SQLITE_IOERR_MMAP\",\n\t                \"SQLITE_NOTICE_RECOVER_ROLLBACK\",\n\t                \"SQLITE_NOTICE_RECOVER_WAL\",\n", "            ]\n\t        if sqlite.sqlite_version_info >= (3, 8, 0):\n\t            consts += [\n\t                \"SQLITE_BUSY_SNAPSHOT\",\n\t                \"SQLITE_IOERR_GETTEMPPATH\",\n\t                \"SQLITE_WARNING_AUTOINDEX\",\n\t            ]\n\t        if sqlite.sqlite_version_info >= (3, 8, 1):\n\t            consts += [\"SQLITE_CANTOPEN_CONVPATH\", \"SQLITE_IOERR_CONVPATH\"]\n\t        if sqlite.sqlite_version_info >= (3, 8, 2):\n", "            consts.append(\"SQLITE_CONSTRAINT_ROWID\")\n\t        if sqlite.sqlite_version_info >= (3, 8, 3):\n\t            consts.append(\"SQLITE_READONLY_DBMOVED\")\n\t        if sqlite.sqlite_version_info >= (3, 8, 7):\n\t            consts.append(\"SQLITE_AUTH_USER\")\n\t        if sqlite.sqlite_version_info >= (3, 9, 0):\n\t            consts.append(\"SQLITE_IOERR_VNODE\")\n\t        if sqlite.sqlite_version_info >= (3, 10, 0):\n\t            consts.append(\"SQLITE_IOERR_AUTH\")\n\t        if sqlite.sqlite_version_info >= (3, 14, 1):\n", "            consts.append(\"SQLITE_OK_LOAD_PERMANENTLY\")\n\t        if sqlite.sqlite_version_info >= (3, 21, 0):\n\t            consts += [\n\t                \"SQLITE_IOERR_BEGIN_ATOMIC\",\n\t                \"SQLITE_IOERR_COMMIT_ATOMIC\",\n\t                \"SQLITE_IOERR_ROLLBACK_ATOMIC\",\n\t            ]\n\t        if sqlite.sqlite_version_info >= (3, 22, 0):\n\t            consts += [\n\t                \"SQLITE_ERROR_MISSING_COLLSEQ\",\n", "                \"SQLITE_ERROR_RETRY\",\n\t                \"SQLITE_READONLY_CANTINIT\",\n\t                \"SQLITE_READONLY_DIRECTORY\",\n\t            ]\n\t        if sqlite.sqlite_version_info >= (3, 24, 0):\n\t            consts += [\"SQLITE_CORRUPT_SEQUENCE\", \"SQLITE_LOCKED_VTAB\"]\n\t        if sqlite.sqlite_version_info >= (3, 25, 0):\n\t            consts += [\"SQLITE_CANTOPEN_DIRTYWAL\", \"SQLITE_ERROR_SNAPSHOT\"]\n\t        if sqlite.sqlite_version_info >= (3, 31, 0):\n\t            consts += [\n", "                \"SQLITE_CANTOPEN_SYMLINK\",\n\t                \"SQLITE_CONSTRAINT_PINNED\",\n\t                \"SQLITE_OK_SYMLINK\",\n\t            ]\n\t        if sqlite.sqlite_version_info >= (3, 32, 0):\n\t            consts += [\n\t                \"SQLITE_BUSY_TIMEOUT\",\n\t                \"SQLITE_CORRUPT_INDEX\",\n\t                \"SQLITE_IOERR_DATA\",\n\t            ]\n", "        if sqlite.sqlite_version_info >= (3, 34, 0):\n\t            consts.append(\"SQLITE_IOERR_CORRUPTFS\")\n\t        for const in consts:\n\t            with self.subTest(const=const):\n\t                self.assertTrue(hasattr(sqlite, const))\n\t    def test_error_code_on_exception(self):\n\t        err_msg = \"Cannot connect to host\"\n\t        if sys.platform.startswith(\"win\"):\n\t            err_code = sqlite.SQLITE_CANTOPEN_ISDIR\n\t        else:\n", "            err_code = sqlite.SQLITE_CANTOPEN\n\t        with temp_dir() as db:\n\t            with self.assertRaisesRegex(sqlite.Error, err_msg) as cm:\n\t                sqlite.connect(db)\n\t            e = cm.exception\n\t            self.assertEqual(e.sqlite_errorcode, err_code)\n\t            self.assertTrue(e.sqlite_errorname.startswith(\"SQLITE_CANTOPEN\"))\n\t    @unittest.skip(\"sqld is not sending this error\")\n\t    @unittest.skipIf(sqlite.sqlite_version_info <= (3, 7, 16),\n\t                     \"Requires SQLite 3.7.16 or newer\")\n", "    def test_extended_error_code_on_exception(self):\n\t        with memory_database() as con:\n\t            with con:\n\t                con.execute(\"create table t(t integer check(t > 0))\")\n\t            errmsg = \"constraint failed\"\n\t            with self.assertRaisesRegex(sqlite.IntegrityError, errmsg) as cm:\n\t                con.execute(\"insert into t values(-1)\")\n\t            exc = cm.exception\n\t            self.assertEqual(exc.sqlite_errorcode,\n\t                             sqlite.SQLITE_CONSTRAINT_CHECK)\n", "            self.assertEqual(exc.sqlite_errorname, \"SQLITE_CONSTRAINT_CHECK\")\n\t    @unittest.skip(\"not supported by libsql_client\")\n\t    # sqlite3_enable_shared_cache() is deprecated on macOS and calling it may raise\n\t    # OperationalError on some buildbots.\n\t    @unittest.skipIf(sys.platform == \"darwin\", \"shared cache is deprecated on macOS\")\n\t    def test_shared_cache_deprecated(self):\n\t        for enable in (True, False):\n\t            with self.assertWarns(DeprecationWarning) as cm:\n\t                sqlite.enable_shared_cache(enable)\n\t            self.assertIn(\"dbapi.py\", cm.filename)\n", "    def test_disallow_instantiation(self):\n\t        cx = sqlite.connect(\":memory:\")\n\t        check_disallow_instantiation(self, type(cx(\"select 1\")))\n\t        check_disallow_instantiation(self, sqlite.Blob)\n\t    def test_complete_statement(self):\n\t        self.assertFalse(sqlite.complete_statement(\"select t\"))\n\t        self.assertTrue(sqlite.complete_statement(\"create table t(t);\"))\n\t@unittest.skip(\"Not supported\")\n\tclass ConnectionTests(unittest.TestCase):\n\t    def setUp(self):\n", "        self.cx = sqlite.connect(\":memory:\")\n\t        cu = self.cx.cursor()\n\t        cu.execute(\"create table test(id integer primary key, name text)\")\n\t        cu.execute(\"insert into test(name) values (?)\", (\"foo\",))\n\t    def tearDown(self):\n\t        self.cx.close()\n\t    def test_commit(self):\n\t        self.cx.commit()\n\t    def test_commit_after_no_changes(self):\n\t        \"\"\"\n", "        A commit should also work when no changes were made to the database.\n\t        \"\"\"\n\t        self.cx.commit()\n\t        self.cx.commit()\n\t    def test_rollback(self):\n\t        self.cx.rollback()\n\t    def test_rollback_after_no_changes(self):\n\t        \"\"\"\n\t        A rollback should also work when no changes were made to the database.\n\t        \"\"\"\n", "        self.cx.rollback()\n\t        self.cx.rollback()\n\t    def test_cursor(self):\n\t        cu = self.cx.cursor()\n\t    def test_failed_open(self):\n\t        YOU_CANNOT_OPEN_THIS = \"/foo/bar/bla/23534/mydb.db\"\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            sqlite.connect(YOU_CANNOT_OPEN_THIS)\n\t    def test_close(self):\n\t        self.cx.close()\n", "    def test_use_after_close(self):\n\t        sql = \"select 1\"\n\t        cu = self.cx.cursor()\n\t        res = cu.execute(sql)\n\t        self.cx.close()\n\t        self.assertRaises(sqlite.ProgrammingError, res.fetchall)\n\t        self.assertRaises(sqlite.ProgrammingError, cu.execute, sql)\n\t        self.assertRaises(sqlite.ProgrammingError, cu.executemany, sql, [])\n\t        self.assertRaises(sqlite.ProgrammingError, cu.executescript, sql)\n\t        self.assertRaises(sqlite.ProgrammingError, self.cx.execute, sql)\n", "        self.assertRaises(sqlite.ProgrammingError,\n\t                          self.cx.executemany, sql, [])\n\t        self.assertRaises(sqlite.ProgrammingError, self.cx.executescript, sql)\n\t        self.assertRaises(sqlite.ProgrammingError,\n\t                          self.cx.create_function, \"t\", 1, lambda x: x)\n\t        self.assertRaises(sqlite.ProgrammingError, self.cx.cursor)\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            with self.cx:\n\t                pass\n\t    def test_exceptions(self):\n", "        # Optional DB-API extension.\n\t        self.assertEqual(self.cx.Warning, sqlite.Warning)\n\t        self.assertEqual(self.cx.Error, sqlite.Error)\n\t        self.assertEqual(self.cx.InterfaceError, sqlite.InterfaceError)\n\t        self.assertEqual(self.cx.DatabaseError, sqlite.DatabaseError)\n\t        self.assertEqual(self.cx.DataError, sqlite.DataError)\n\t        self.assertEqual(self.cx.OperationalError, sqlite.OperationalError)\n\t        self.assertEqual(self.cx.IntegrityError, sqlite.IntegrityError)\n\t        self.assertEqual(self.cx.InternalError, sqlite.InternalError)\n\t        self.assertEqual(self.cx.ProgrammingError, sqlite.ProgrammingError)\n", "        self.assertEqual(self.cx.NotSupportedError, sqlite.NotSupportedError)\n\t    def test_in_transaction(self):\n\t        # Can't use db from setUp because we want to test initial state.\n\t        cx = sqlite.connect(\":memory:\")\n\t        cu = cx.cursor()\n\t        self.assertEqual(cx.in_transaction, False)\n\t        cu.execute(\"create table transactiontest(id integer primary key, name text)\")\n\t        self.assertEqual(cx.in_transaction, False)\n\t        cu.execute(\"insert into transactiontest(name) values (?)\", (\"foo\",))\n\t        self.assertEqual(cx.in_transaction, True)\n", "        cu.execute(\"select name from transactiontest where name=?\", [\"foo\"])\n\t        row = cu.fetchone()\n\t        self.assertEqual(cx.in_transaction, True)\n\t        cx.commit()\n\t        self.assertEqual(cx.in_transaction, False)\n\t        cu.execute(\"select name from transactiontest where name=?\", [\"foo\"])\n\t        row = cu.fetchone()\n\t        self.assertEqual(cx.in_transaction, False)\n\t    def test_in_transaction_ro(self):\n\t        with self.assertRaises(AttributeError):\n", "            self.cx.in_transaction = True\n\t    def test_connection_exceptions(self):\n\t        exceptions = [\n\t            \"DataError\",\n\t            \"DatabaseError\",\n\t            \"Error\",\n\t            \"IntegrityError\",\n\t            \"InterfaceError\",\n\t            \"NotSupportedError\",\n\t            \"OperationalError\",\n", "            \"ProgrammingError\",\n\t            \"Warning\",\n\t        ]\n\t        for exc in exceptions:\n\t            with self.subTest(exc=exc):\n\t                self.assertTrue(hasattr(self.cx, exc))\n\t                self.assertIs(getattr(sqlite, exc), getattr(self.cx, exc))\n\t    def test_interrupt_on_closed_db(self):\n\t        cx = sqlite.connect(\":memory:\")\n\t        cx.close()\n", "        with self.assertRaises(sqlite.ProgrammingError):\n\t            cx.interrupt()\n\t    def test_interrupt(self):\n\t        self.assertIsNone(self.cx.interrupt())\n\t    def test_drop_unused_refs(self):\n\t        for n in range(500):\n\t            cu = self.cx.execute(f\"select {n}\")\n\t            self.assertEqual(cu.fetchone()[0], n)\n\t    def test_connection_limits(self):\n\t        category = sqlite.SQLITE_LIMIT_SQL_LENGTH\n", "        saved_limit = self.cx.getlimit(category)\n\t        try:\n\t            new_limit = 10\n\t            prev_limit = self.cx.setlimit(category, new_limit)\n\t            self.assertEqual(saved_limit, prev_limit)\n\t            self.assertEqual(self.cx.getlimit(category), new_limit)\n\t            msg = \"query string is too large\"\n\t            self.assertRaisesRegex(sqlite.DataError, msg,\n\t                                   self.cx.execute, \"select 1 as '16'\")\n\t        finally:  # restore saved limit\n", "            self.cx.setlimit(category, saved_limit)\n\t    def test_connection_bad_limit_category(self):\n\t        msg = \"'category' is out of bounds\"\n\t        cat = 1111\n\t        self.assertRaisesRegex(sqlite.ProgrammingError, msg,\n\t                               self.cx.getlimit, cat)\n\t        self.assertRaisesRegex(sqlite.ProgrammingError, msg,\n\t                               self.cx.setlimit, cat, 0)\n\t    def test_connection_init_bad_isolation_level(self):\n\t        msg = (\n", "            \"isolation_level string must be '', 'DEFERRED', 'IMMEDIATE', or \"\n\t            \"'EXCLUSIVE'\"\n\t        )\n\t        levels = (\n\t            \"BOGUS\",\n\t            \" \",\n\t            \"DEFERRE\",\n\t            \"IMMEDIAT\",\n\t            \"EXCLUSIV\",\n\t            \"DEFERREDS\",\n", "            \"IMMEDIATES\",\n\t            \"EXCLUSIVES\",\n\t        )\n\t        for level in levels:\n\t            with self.subTest(level=level):\n\t                with self.assertRaisesRegex(ValueError, msg):\n\t                    memory_database(isolation_level=level)\n\t                with memory_database() as cx:\n\t                    with self.assertRaisesRegex(ValueError, msg):\n\t                        cx.isolation_level = level\n", "                    # Check that the default level is not changed\n\t                    self.assertEqual(cx.isolation_level, \"\")\n\t    def test_connection_init_good_isolation_levels(self):\n\t        for level in (\"\", \"DEFERRED\", \"IMMEDIATE\", \"EXCLUSIVE\", None):\n\t            with self.subTest(level=level):\n\t                with memory_database(isolation_level=level) as cx:\n\t                    self.assertEqual(cx.isolation_level, level)\n\t                with memory_database() as cx:\n\t                    self.assertEqual(cx.isolation_level, \"\")\n\t                    cx.isolation_level = level\n", "                    self.assertEqual(cx.isolation_level, level)\n\t    def test_connection_reinit(self):\n\t        db = \":memory:\"\n\t        cx = sqlite.connect(db)\n\t        cx.text_factory = bytes\n\t        cx.row_factory = sqlite.Row\n\t        cu = cx.cursor()\n\t        cu.execute(\"create table foo (bar)\")\n\t        cu.executemany(\"insert into foo (bar) values (?)\",\n\t                       ((str(v),) for v in range(4)))\n", "        cu.execute(\"select bar from foo\")\n\t        rows = [r for r in cu.fetchmany(2)]\n\t        self.assertTrue(all(isinstance(r, sqlite.Row) for r in rows))\n\t        self.assertEqual([r[0] for r in rows], [b\"0\", b\"1\"])\n\t        cx.__init__(db)\n\t        cx.execute(\"create table foo (bar)\")\n\t        cx.executemany(\"insert into foo (bar) values (?)\",\n\t                       ((v,) for v in (\"a\", \"b\", \"c\", \"d\")))\n\t        # This uses the old database, old row factory, but new text factory\n\t        rows = [r for r in cu.fetchall()]\n", "        self.assertTrue(all(isinstance(r, sqlite.Row) for r in rows))\n\t        self.assertEqual([r[0] for r in rows], [\"2\", \"3\"])\n\t    def test_connection_bad_reinit(self):\n\t        cx = sqlite.connect(\":memory:\")\n\t        with cx:\n\t            cx.execute(\"create table t(t)\")\n\t        with temp_dir() as db:\n\t            self.assertRaisesRegex(sqlite.OperationalError,\n\t                                   \"unable to open database file\",\n\t                                   cx.__init__, db)\n", "            self.assertRaisesRegex(sqlite.ProgrammingError,\n\t                                   \"Base Connection.__init__ not called\",\n\t                                   cx.executemany, \"insert into t values(?)\",\n\t                                   ((v,) for v in range(3)))\n\t@unittest.skip(\"does not make sense with libsql_client-py\")\n\tclass UninitialisedConnectionTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.cx = sqlite.Connection.__new__(sqlite.Connection)\n\t    def test_uninit_operations(self):\n\t        funcs = (\n", "            lambda: self.cx.isolation_level,\n\t            lambda: self.cx.total_changes,\n\t            lambda: self.cx.in_transaction,\n\t            lambda: self.cx.iterdump(),\n\t            lambda: self.cx.cursor(),\n\t            lambda: self.cx.close(),\n\t        )\n\t        for func in funcs:\n\t            with self.subTest(func=func):\n\t                self.assertRaisesRegex(sqlite.ProgrammingError,\n", "                                       \"Base Connection.__init__ not called\",\n\t                                       func)\n\t@unittest.skip(\"Not supported\")\n\t@unittest.skipUnless(hasattr(sqlite.Connection, \"serialize\"),\n\t                     \"Needs SQLite serialize API\")\n\tclass SerializeTests(unittest.TestCase):\n\t    def test_serialize_deserialize(self):\n\t        with memory_database() as cx:\n\t            with cx:\n\t                cx.execute(\"create table t(t)\")\n", "            data = cx.serialize()\n\t            # Remove test table, verify that it was removed.\n\t            with cx:\n\t                cx.execute(\"drop table t\")\n\t            regex = \"no such table\"\n\t            with self.assertRaisesRegex(sqlite.OperationalError, regex):\n\t                cx.execute(\"select t from t\")\n\t            # Deserialize and verify that test table is restored.\n\t            cx.deserialize(data)\n\t            cx.execute(\"select t from t\")\n", "    def test_deserialize_wrong_args(self):\n\t        dataset = (\n\t            (BufferError, memoryview(b\"blob\")[::2]),\n\t            (TypeError, []),\n\t            (TypeError, 1),\n\t            (TypeError, None),\n\t        )\n\t        for exc, arg in dataset:\n\t            with self.subTest(exc=exc, arg=arg):\n\t                with memory_database() as cx:\n", "                    self.assertRaises(exc, cx.deserialize, arg)\n\t    def test_deserialize_corrupt_database(self):\n\t        with memory_database() as cx:\n\t            regex = \"file is not a database\"\n\t            with self.assertRaisesRegex(sqlite.DatabaseError, regex):\n\t                cx.deserialize(b\"\\0\\1\\3\")\n\t                # SQLite does not generate an error until you try to query the\n\t                # deserialized database.\n\t                cx.execute(\"create table fail(f)\")\n\t    @unittest.skip(\"Not supported\")\n", "    @unittest.skipUnless(sys.maxsize > 2**32, 'requires 64bit platform')\n\t    @bigmemtest(size=2**63, memuse=3, dry_run=False)\n\t    def test_deserialize_too_much_data_64bit(self):\n\t        with memory_database() as cx:\n\t            with self.assertRaisesRegex(OverflowError, \"'data' is too large\"):\n\t                cx.deserialize(b\"b\" * size)\n\tclass OpenTests(unittest.TestCase):\n\t    _sql = \"create table test(id integer)\"\n\t    def test_open_with_path_like_object(self):\n\t        \"\"\" Checks that we can successfully connect to a database using an object that\n", "            is PathLike, i.e. has __fspath__(). \"\"\"\n\t        path = FakePath(TESTFN)\n\t        self.addCleanup(unlink, path)\n\t        self.assertFalse(os.path.exists(path))\n\t        with contextlib.closing(sqlite.connect(path)) as cx:\n\t            self.assertTrue(os.path.exists(path))\n\t            cx.execute(self._sql)\n\t    @unittest.skipIf(sys.platform == \"win32\", \"skipped on Windows\")\n\t    @unittest.skipIf(sys.platform == \"darwin\", \"skipped on macOS\")\n\t    @unittest.skipIf(is_emscripten or is_wasi, \"not supported on Emscripten/WASI\")\n", "    @unittest.skipUnless(TESTFN_UNDECODABLE, \"only works if there are undecodable paths\")\n\t    def test_open_with_undecodable_path(self):\n\t        path = TESTFN_UNDECODABLE\n\t        self.addCleanup(unlink, path)\n\t        self.assertFalse(os.path.exists(path))\n\t        with contextlib.closing(sqlite.connect(path)) as cx:\n\t            self.assertTrue(os.path.exists(path))\n\t            cx.execute(self._sql)\n\t    def test_open_uri(self):\n\t        path = TESTFN\n", "        self.addCleanup(unlink, path)\n\t        uri = \"file:\" + urllib.parse.quote(os.fsencode(path))\n\t        self.assertFalse(os.path.exists(path))\n\t        with contextlib.closing(sqlite.connect(uri, uri=True)) as cx:\n\t            self.assertTrue(os.path.exists(path))\n\t            cx.execute(self._sql)\n\t    def test_open_unquoted_uri(self):\n\t        path = TESTFN\n\t        self.addCleanup(unlink, path)\n\t        uri = \"file:\" + path\n", "        self.assertFalse(os.path.exists(path))\n\t        with contextlib.closing(sqlite.connect(uri, uri=True)) as cx:\n\t            self.assertTrue(os.path.exists(path))\n\t            cx.execute(self._sql)\n\t    def test_open_uri_readonly(self):\n\t        path = TESTFN\n\t        self.addCleanup(unlink, path)\n\t        uri = \"file:\" + urllib.parse.quote(os.fsencode(path)) + \"?mode=ro\"\n\t        self.assertFalse(os.path.exists(path))\n\t        # Cannot create new DB\n", "        with self.assertRaises(sqlite.OperationalError):\n\t            sqlite.connect(uri, uri=True)\n\t        self.assertFalse(os.path.exists(path))\n\t        sqlite.connect(path).close()\n\t        self.assertTrue(os.path.exists(path))\n\t        # Cannot modify new DB\n\t        with contextlib.closing(sqlite.connect(uri, uri=True)) as cx:\n\t            with self.assertRaises(sqlite.OperationalError):\n\t                cx.execute(self._sql)\n\t    @unittest.skipIf(sys.platform == \"win32\", \"skipped on Windows\")\n", "    @unittest.skipIf(sys.platform == \"darwin\", \"skipped on macOS\")\n\t    @unittest.skipIf(is_emscripten or is_wasi, \"not supported on Emscripten/WASI\")\n\t    @unittest.skipUnless(TESTFN_UNDECODABLE, \"only works if there are undecodable paths\")\n\t    def test_open_undecodable_uri(self):\n\t        path = TESTFN_UNDECODABLE\n\t        self.addCleanup(unlink, path)\n\t        uri = \"file:\" + urllib.parse.quote(path)\n\t        self.assertFalse(os.path.exists(path))\n\t        with contextlib.closing(sqlite.connect(uri, uri=True)) as cx:\n\t            self.assertTrue(os.path.exists(path))\n", "            cx.execute(self._sql)\n\t    @unittest.skip(\"connecting to memory with ConnectionHrana is unsupported\")\n\t    def test_factory_database_arg(self):\n\t        def factory(database, *args, **kwargs):\n\t            nonlocal database_arg\n\t            database_arg = database\n\t            return sqlite.Connection(\":memory:\", *args, **kwargs)\n\t        for database in (TESTFN, os.fsencode(TESTFN),\n\t                         FakePath(TESTFN), FakePath(os.fsencode(TESTFN))):\n\t            database_arg = None\n", "            sqlite.connect(database, factory=factory).close()\n\t            self.assertEqual(database_arg, database)\n\t    def test_database_keyword(self):\n\t        with contextlib.closing(sqlite.connect(database=\":memory:\")) as cx:\n\t            self.assertEqual(type(cx), sqlite.Connection)\n\tclass CursorTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.cx = sqlite.connect(\":memory:\")\n\t        self.cu = self.cx.cursor()\n\t        self.cu.execute(\n", "            \"create table test(id integer primary key, name text, \"\n\t            \"income number, unique_test text unique)\"\n\t        )\n\t        self.cu.execute(\"insert into test(name) values (?)\", (\"foo\",))\n\t    def tearDown(self):\n\t        self.cu.close()\n\t        self.cx.close()\n\t    def test_execute_no_args(self):\n\t        self.cu.execute(\"delete from test\")\n\t    def test_execute_illegal_sql(self):\n", "        with self.assertRaises(sqlite.OperationalError):\n\t            self.cu.execute(\"select asdf\")\n\t    def test_execute_multiple_statements(self):\n\t        msg = \"You can only execute one statement at a time\"\n\t        dataset = (\n\t            \"select 1; select 2\",\n\t            \"select 1; // c++ comments are not allowed\",\n\t            \"select 1; *not a comment\",\n\t            \"select 1; -*not a comment\",\n\t            \"select 1; /* */ a\",\n", "            \"select 1; /**/a\",\n\t            \"select 1; -\",\n\t            \"select 1; /\",\n\t            \"select 1; -\\n- select 2\",\n\t            \"\"\"select 1;\n\t               -- comment\n\t               select 2\n\t            \"\"\",\n\t        )\n\t        for query in dataset:\n", "            with self.subTest(query=query):\n\t                with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                    self.cu.execute(query)\n\t    @unittest.skip(\"not supported by sqld\")\n\t    def test_execute_with_appended_comments(self):\n\t        dataset = (\n\t            \"select 1; -- foo bar\",\n\t            \"select 1; --\",\n\t            \"select 1; /*\",  # Unclosed comments ending in \\0 are skipped.\n\t            \"\"\"\n", "            select 5+4;\n\t            /*\n\t            foo\n\t            */\n\t            \"\"\",\n\t        )\n\t        for query in dataset:\n\t            with self.subTest(query=query):\n\t                self.cu.execute(query)\n\t    def test_execute_wrong_sql_arg(self):\n", "        with self.assertRaises(TypeError):\n\t            self.cu.execute(42)\n\t    def test_execute_arg_int(self):\n\t        self.cu.execute(\"insert into test(id) values (?)\", (42,))\n\t    def test_execute_arg_float(self):\n\t        self.cu.execute(\"insert into test(income) values (?)\", (2500.32,))\n\t    def test_execute_arg_string(self):\n\t        self.cu.execute(\"insert into test(name) values (?)\", (\"Hugo\",))\n\t    def test_execute_arg_string_with_zero_byte(self):\n\t        self.cu.execute(\"insert into test(name) values (?)\", (\"Hu\\x00go\",))\n", "        self.cu.execute(\"select name from test where id=?\", (self.cu.lastrowid,))\n\t        row = self.cu.fetchone()\n\t        self.assertEqual(row[0], \"Hu\\x00go\")\n\t    def test_execute_non_iterable(self):\n\t        with self.assertRaises(sqlite.ProgrammingError) as cm:\n\t            self.cu.execute(\"insert into test(id) values (?)\", 42)\n\t        self.assertEqual(str(cm.exception), 'parameters are of unsupported type')\n\t    def test_execute_wrong_no_of_args1(self):\n\t        # too many parameters\n\t        with self.assertRaises(sqlite.ProgrammingError):\n", "            self.cu.execute(\"insert into test(id) values (?)\", (17, \"Egon\"))\n\t    def test_execute_wrong_no_of_args2(self):\n\t        # too little parameters\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cu.execute(\"insert into test(id) values (?)\")\n\t    def test_execute_wrong_no_of_args3(self):\n\t        # no parameters, parameters are needed\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cu.execute(\"insert into test(id) values (?)\")\n\t    def test_execute_param_list(self):\n", "        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.cu.execute(\"select name from test where name=?\", [\"foo\"])\n\t        row = self.cu.fetchone()\n\t        self.assertEqual(row[0], \"foo\")\n\t    def test_execute_param_sequence(self):\n\t        class L:\n\t            def __len__(self):\n\t                return 1\n\t            def __getitem__(self, x):\n\t                assert x == 0\n", "                return \"foo\"\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.cu.execute(\"select name from test where name=?\", L())\n\t        row = self.cu.fetchone()\n\t        self.assertEqual(row[0], \"foo\")\n\t    def test_execute_param_sequence_bad_len(self):\n\t        # Issue41662: Error in __len__() was overridden with ProgrammingError.\n\t        class L:\n\t            def __len__(self):\n\t                1/0\n", "            def __getitem__(slf, x):\n\t                raise AssertionError\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        with self.assertRaises(ZeroDivisionError):\n\t            self.cu.execute(\"select name from test where name=?\", L())\n\t    @unittest.skip(\"Not supported\")\n\t    def test_execute_too_many_params(self):\n\t        category = sqlite.SQLITE_LIMIT_VARIABLE_NUMBER\n\t        msg = \"too many SQL variables\"\n\t        with cx_limit(self.cx, category=category, limit=1):\n", "            self.cu.execute(\"select * from test where id=?\", (1,))\n\t            with self.assertRaisesRegex(sqlite.OperationalError, msg):\n\t                self.cu.execute(\"select * from test where id!=? and id!=?\",\n\t                                (1, 2))\n\t    def test_execute_dict_mapping(self):\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.cu.execute(\"select name from test where name=:name\", {\"name\": \"foo\"})\n\t        row = self.cu.fetchone()\n\t        self.assertEqual(row[0], \"foo\")\n\t    @unittest.skip(\"Not supported\")\n", "    def test_execute_dict_mapping_mapping(self):\n\t        class D(dict):\n\t            def __missing__(self, key):\n\t                return \"foo\"\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.cu.execute(\"select name from test where name=:name\", D())\n\t        row = self.cu.fetchone()\n\t        self.assertEqual(row[0], \"foo\")\n\t    def test_execute_dict_mapping_too_little_args(self):\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n", "        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cu.execute(\"select name from test where name=:name and id=:id\", {\"name\": \"foo\"})\n\t    def test_execute_dict_mapping_no_args(self):\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cu.execute(\"select name from test where name=:name\")\n\t    def test_execute_dict_mapping_unnamed(self):\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cu.execute(\"select name from test where name=?\", {\"name\": \"foo\"})\n", "    def test_close(self):\n\t        self.cu.close()\n\t    def test_rowcount_execute(self):\n\t        self.cu.execute(\"delete from test\")\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.cu.execute(\"update test set name='bar'\")\n\t        self.assertEqual(self.cu.rowcount, 2)\n\t    def test_rowcount_select(self):\n\t        \"\"\"\n", "        pysqlite does not know the rowcount of SELECT statements, because we\n\t        don't fetch all rows after executing the select statement. The rowcount\n\t        has thus to be -1.\n\t        \"\"\"\n\t        self.cu.execute(\"select 5 union select 6\")\n\t        self.assertEqual(self.cu.rowcount, -1)\n\t    def test_rowcount_executemany(self):\n\t        self.cu.execute(\"delete from test\")\n\t        self.cu.executemany(\"insert into test(name) values (?)\", [(1,), (2,), (3,)])\n\t        self.assertEqual(self.cu.rowcount, 3)\n", "    @unittest.skipIf(sqlite.sqlite_version_info < (3, 35, 0),\n\t                     \"Requires SQLite 3.35.0 or newer\")\n\t    def test_rowcount_update_returning(self):\n\t        # gh-93421: rowcount is updated correctly for UPDATE...RETURNING queries\n\t        self.cu.execute(\"update test set name='bar' where name='foo' returning 1\")\n\t        self.assertEqual(self.cu.fetchone()[0], 1)\n\t        self.assertEqual(self.cu.rowcount, 1)\n\t    def test_rowcount_prefixed_with_comment(self):\n\t        # gh-79579: rowcount is updated even if query is prefixed with comments\n\t        self.cu.execute(\"\"\"\n", "            -- foo\n\t            insert into test(name) values ('foo'), ('foo')\n\t        \"\"\")\n\t        self.assertEqual(self.cu.rowcount, 2)\n\t        self.cu.execute(\"\"\"\n\t            /* -- messy *r /* /* ** *- *--\n\t            */\n\t            /* one more */ insert into test(name) values ('messy')\n\t        \"\"\")\n\t        self.assertEqual(self.cu.rowcount, 1)\n", "        self.cu.execute(\"/* bar */ update test set name='bar' where name='foo'\")\n\t        self.assertEqual(self.cu.rowcount, 3)\n\t    @unittest.skip(\"sqld doesn't allow vaccum\")\n\t    def test_rowcount_vaccuum(self):\n\t        data = ((1,), (2,), (3,))\n\t        self.cu.executemany(\"insert into test(income) values(?)\", data)\n\t        self.assertEqual(self.cu.rowcount, 3)\n\t        self.cx.commit()\n\t        self.cu.execute(\"vacuum\")\n\t        self.assertEqual(self.cu.rowcount, -1)\n", "    @unittest.skip(\"sqld doesn't inform, libsql_client can't account properly\")\n\t    def test_total_changes(self):\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.cu.execute(\"insert into test(name) values ('foo')\")\n\t        self.assertLess(2, self.cx.total_changes, msg='total changes reported wrong value')\n\t    # Checks for executemany:\n\t    # Sequences are required by the DB-API, iterators\n\t    # enhancements in pysqlite.\n\t    def test_execute_many_sequence(self):\n\t        self.cu.executemany(\"insert into test(income) values (?)\", [(x,) for x in range(100, 110)])\n", "    def test_execute_many_iterator(self):\n\t        class MyIter:\n\t            def __init__(self):\n\t                self.value = 5\n\t            def __iter__(self):\n\t                return self\n\t            def __next__(self):\n\t                if self.value == 10:\n\t                    raise StopIteration\n\t                else:\n", "                    self.value += 1\n\t                    return (self.value,)\n\t        self.cu.executemany(\"insert into test(income) values (?)\", MyIter())\n\t    def test_execute_many_generator(self):\n\t        def mygen():\n\t            for i in range(5):\n\t                yield (i,)\n\t        self.cu.executemany(\"insert into test(income) values (?)\", mygen())\n\t    def test_execute_many_wrong_sql_arg(self):\n\t        with self.assertRaises(TypeError):\n", "            self.cu.executemany(42, [(3,)])\n\t    def test_execute_many_select(self):\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            self.cu.executemany(\"select ?\", [(3,)])\n\t    def test_execute_many_not_iterable(self):\n\t        with self.assertRaises(TypeError):\n\t            self.cu.executemany(\"insert into test(income) values (?)\", 42)\n\t    def test_fetch_iter(self):\n\t        # Optional DB-API extension.\n\t        self.cu.execute(\"delete from test\")\n", "        self.cu.execute(\"insert into test(id) values (?)\", (5,))\n\t        self.cu.execute(\"insert into test(id) values (?)\", (6,))\n\t        self.cu.execute(\"select id from test order by id\")\n\t        lst = []\n\t        for row in self.cu:\n\t            lst.append(row[0])\n\t        self.assertEqual(lst[0], 5)\n\t        self.assertEqual(lst[1], 6)\n\t    def test_fetchone(self):\n\t        self.cu.execute(\"select name from test\")\n", "        row = self.cu.fetchone()\n\t        self.assertEqual(row[0], \"foo\")\n\t        row = self.cu.fetchone()\n\t        self.assertEqual(row, None)\n\t    def test_fetchone_no_statement(self):\n\t        cur = self.cx.cursor()\n\t        row = cur.fetchone()\n\t        self.assertEqual(row, None)\n\t    def test_array_size(self):\n\t        # must default to 1\n", "        self.assertEqual(self.cu.arraysize, 1)\n\t        # now set to 2\n\t        self.cu.arraysize = 2\n\t        # now make the query return 3 rows\n\t        self.cu.execute(\"delete from test\")\n\t        self.cu.execute(\"insert into test(name) values ('A')\")\n\t        self.cu.execute(\"insert into test(name) values ('B')\")\n\t        self.cu.execute(\"insert into test(name) values ('C')\")\n\t        self.cu.execute(\"select name from test\")\n\t        res = self.cu.fetchmany()\n", "        self.assertEqual(len(res), 2)\n\t    def test_fetchmany(self):\n\t        self.cu.execute(\"select name from test\")\n\t        res = self.cu.fetchmany(100)\n\t        self.assertEqual(len(res), 1)\n\t        res = self.cu.fetchmany(100)\n\t        self.assertEqual(res, [])\n\t    def test_fetchmany_kw_arg(self):\n\t        \"\"\"Checks if fetchmany works with keyword arguments\"\"\"\n\t        self.cu.execute(\"select name from test\")\n", "        res = self.cu.fetchmany(size=100)\n\t        self.assertEqual(len(res), 1)\n\t    def test_fetchall(self):\n\t        self.cu.execute(\"select name from test\")\n\t        res = self.cu.fetchall()\n\t        self.assertEqual(len(res), 1)\n\t        res = self.cu.fetchall()\n\t        self.assertEqual(res, [])\n\t    def test_setinputsizes(self):\n\t        self.cu.setinputsizes([3, 4, 5])\n", "    def test_setoutputsize(self):\n\t        self.cu.setoutputsize(5, 0)\n\t    def test_setoutputsize_no_column(self):\n\t        self.cu.setoutputsize(42)\n\t    def test_cursor_connection(self):\n\t        # Optional DB-API extension.\n\t        self.assertEqual(self.cu.connection, self.cx)\n\t    def test_wrong_cursor_callable(self):\n\t        with self.assertRaises(TypeError):\n\t            def f(): pass\n", "            cur = self.cx.cursor(f)\n\t    def test_cursor_wrong_class(self):\n\t        class Foo: pass\n\t        foo = Foo()\n\t        with self.assertRaises(TypeError):\n\t            cur = sqlite.Cursor(foo)\n\t    def test_last_row_id_on_replace(self):\n\t        \"\"\"\n\t        INSERT OR REPLACE and REPLACE INTO should produce the same behavior.\n\t        \"\"\"\n", "        sql = '{} INTO test(id, unique_test) VALUES (?, ?)'\n\t        for statement in ('INSERT OR REPLACE', 'REPLACE'):\n\t            with self.subTest(statement=statement):\n\t                self.cu.execute(sql.format(statement), (1, 'foo'))\n\t                self.assertEqual(self.cu.lastrowid, 1)\n\t    def test_last_row_id_on_ignore(self):\n\t        self.cu.execute(\n\t            \"insert or ignore into test(unique_test) values (?)\",\n\t            ('test',))\n\t        self.assertEqual(self.cu.lastrowid, 2)\n", "        self.cu.execute(\n\t            \"insert or ignore into test(unique_test) values (?)\",\n\t            ('test',))\n\t        self.assertEqual(self.cu.lastrowid, 2)\n\t    def test_last_row_id_insert_o_r(self):\n\t        results = []\n\t        for statement in ('FAIL', 'ABORT', 'ROLLBACK'):\n\t            sql = 'INSERT OR {} INTO test(unique_test) VALUES (?)'\n\t            with self.subTest(statement='INSERT OR {}'.format(statement)):\n\t                self.cu.execute(sql.format(statement), (statement,))\n", "                results.append((statement, self.cu.lastrowid))\n\t                with self.assertRaises(sqlite.IntegrityError):\n\t                    self.cu.execute(sql.format(statement), (statement,))\n\t                results.append((statement, self.cu.lastrowid))\n\t        expected = [\n\t            ('FAIL', 2), ('FAIL', 2),\n\t            ('ABORT', 3), ('ABORT', 3),\n\t            ('ROLLBACK', 4), ('ROLLBACK', 4),\n\t        ]\n\t        self.assertEqual(results, expected)\n", "    def test_column_count(self):\n\t        # Check that column count is updated correctly for cached statements\n\t        select = \"select * from test\"\n\t        res = self.cu.execute(select)\n\t        old_count = len(res.description)\n\t        # Add a new column and execute the cached select query again\n\t        self.cu.execute(\"alter table test add newcol\")\n\t        res = self.cu.execute(select)\n\t        new_count = len(res.description)\n\t        self.assertEqual(new_count - old_count, 1)\n", "    def test_same_query_in_multiple_cursors(self):\n\t        cursors = [self.cx.execute(\"select 1\") for _ in range(3)]\n\t        for cu in cursors:\n\t            self.assertEqual(cu.fetchall(), [(1,)])\n\t@unittest.skip(\"Not supported\")\n\tclass BlobTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.cx = sqlite.connect(\":memory:\")\n\t        self.cx.execute(\"create table test(b blob)\")\n\t        self.data = b\"this blob data string is exactly fifty bytes long!\"\n", "        self.cx.execute(\"insert into test(b) values (?)\", (self.data,))\n\t        self.blob = self.cx.blobopen(\"test\", \"b\", 1)\n\t    def tearDown(self):\n\t        self.blob.close()\n\t        self.cx.close()\n\t    def test_blob_is_a_blob(self):\n\t        self.assertIsInstance(self.blob, sqlite.Blob)\n\t    def test_blob_seek_and_tell(self):\n\t        self.blob.seek(10)\n\t        self.assertEqual(self.blob.tell(), 10)\n", "        self.blob.seek(10, SEEK_SET)\n\t        self.assertEqual(self.blob.tell(), 10)\n\t        self.blob.seek(10, SEEK_CUR)\n\t        self.assertEqual(self.blob.tell(), 20)\n\t        self.blob.seek(-10, SEEK_END)\n\t        self.assertEqual(self.blob.tell(), 40)\n\t    def test_blob_seek_error(self):\n\t        msg_oor = \"offset out of blob range\"\n\t        msg_orig = \"'origin' should be os.SEEK_SET, os.SEEK_CUR, or os.SEEK_END\"\n\t        msg_of = \"seek offset results in overflow\"\n", "        dataset = (\n\t            (ValueError, msg_oor, lambda: self.blob.seek(1000)),\n\t            (ValueError, msg_oor, lambda: self.blob.seek(-10)),\n\t            (ValueError, msg_orig, lambda: self.blob.seek(10, -1)),\n\t            (ValueError, msg_orig, lambda: self.blob.seek(10, 3)),\n\t        )\n\t        for exc, msg, fn in dataset:\n\t            with self.subTest(exc=exc, msg=msg, fn=fn):\n\t                self.assertRaisesRegex(exc, msg, fn)\n\t        # Force overflow errors\n", "        self.blob.seek(1, SEEK_SET)\n\t        with self.assertRaisesRegex(OverflowError, msg_of):\n\t            self.blob.seek(INT_MAX, SEEK_CUR)\n\t        with self.assertRaisesRegex(OverflowError, msg_of):\n\t            self.blob.seek(INT_MAX, SEEK_END)\n\t    def test_blob_read(self):\n\t        buf = self.blob.read()\n\t        self.assertEqual(buf, self.data)\n\t    def test_blob_read_oversized(self):\n\t        buf = self.blob.read(len(self.data) * 2)\n", "        self.assertEqual(buf, self.data)\n\t    def test_blob_read_advance_offset(self):\n\t        n = 10\n\t        buf = self.blob.read(n)\n\t        self.assertEqual(buf, self.data[:n])\n\t        self.assertEqual(self.blob.tell(), n)\n\t    def test_blob_read_at_offset(self):\n\t        self.blob.seek(10)\n\t        self.assertEqual(self.blob.read(10), self.data[10:20])\n\t    def test_blob_read_error_row_changed(self):\n", "        self.cx.execute(\"update test set b='aaaa' where rowid=1\")\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.blob.read()\n\t    def test_blob_write(self):\n\t        new_data = b\"new data\".ljust(50)\n\t        self.blob.write(new_data)\n\t        row = self.cx.execute(\"select b from test\").fetchone()\n\t        self.assertEqual(row[0], new_data)\n\t    def test_blob_write_at_offset(self):\n\t        new_data = b\"c\" * 25\n", "        self.blob.seek(25)\n\t        self.blob.write(new_data)\n\t        row = self.cx.execute(\"select b from test\").fetchone()\n\t        self.assertEqual(row[0], self.data[:25] + new_data)\n\t    def test_blob_write_advance_offset(self):\n\t        self.blob.write(b\"d\"*10)\n\t        self.assertEqual(self.blob.tell(), 10)\n\t    def test_blob_write_error_length(self):\n\t        with self.assertRaisesRegex(ValueError, \"data longer than blob\"):\n\t            self.blob.write(b\"a\" * 1000)\n", "        self.blob.seek(0, SEEK_SET)\n\t        n = len(self.blob)\n\t        self.blob.write(b\"a\" * (n-1))\n\t        self.blob.write(b\"a\")\n\t        with self.assertRaisesRegex(ValueError, \"data longer than blob\"):\n\t            self.blob.write(b\"a\")\n\t    def test_blob_write_error_row_changed(self):\n\t        self.cx.execute(\"update test set b='aaaa' where rowid=1\")\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.blob.write(b\"aaa\")\n", "    def test_blob_write_error_readonly(self):\n\t        ro_blob = self.cx.blobopen(\"test\", \"b\", 1, readonly=True)\n\t        with self.assertRaisesRegex(sqlite.OperationalError, \"readonly\"):\n\t            ro_blob.write(b\"aaa\")\n\t        ro_blob.close()\n\t    def test_blob_open_error(self):\n\t        dataset = (\n\t            ((\"test\", \"b\", 1), {\"name\": \"notexisting\"}),\n\t            ((\"notexisting\", \"b\", 1), {}),\n\t            ((\"test\", \"notexisting\", 1), {}),\n", "            ((\"test\", \"b\", 2), {}),\n\t        )\n\t        regex = \"no such\"\n\t        for args, kwds in dataset:\n\t            with self.subTest(args=args, kwds=kwds):\n\t                with self.assertRaisesRegex(sqlite.OperationalError, regex):\n\t                    self.cx.blobopen(*args, **kwds)\n\t    def test_blob_length(self):\n\t        self.assertEqual(len(self.blob), 50)\n\t    def test_blob_get_item(self):\n", "        self.assertEqual(self.blob[5], ord(\"b\"))\n\t        self.assertEqual(self.blob[6], ord(\"l\"))\n\t        self.assertEqual(self.blob[7], ord(\"o\"))\n\t        self.assertEqual(self.blob[8], ord(\"b\"))\n\t        self.assertEqual(self.blob[-1], ord(\"!\"))\n\t    def test_blob_set_item(self):\n\t        self.blob[0] = ord(\"b\")\n\t        expected = b\"b\" + self.data[1:]\n\t        actual = self.cx.execute(\"select b from test\").fetchone()[0]\n\t        self.assertEqual(actual, expected)\n", "    def test_blob_set_item_with_offset(self):\n\t        self.blob.seek(0, SEEK_END)\n\t        self.assertEqual(self.blob.read(), b\"\")  # verify that we're at EOB\n\t        self.blob[0] = ord(\"T\")\n\t        self.blob[-1] = ord(\".\")\n\t        self.blob.seek(0, SEEK_SET)\n\t        expected = b\"This blob data string is exactly fifty bytes long.\"\n\t        self.assertEqual(self.blob.read(), expected)\n\t    def test_blob_set_slice_buffer_object(self):\n\t        from array import array\n", "        self.blob[0:5] = memoryview(b\"12345\")\n\t        self.assertEqual(self.blob[0:5], b\"12345\")\n\t        self.blob[0:5] = bytearray(b\"23456\")\n\t        self.assertEqual(self.blob[0:5], b\"23456\")\n\t        self.blob[0:5] = array(\"b\", [1, 2, 3, 4, 5])\n\t        self.assertEqual(self.blob[0:5], b\"\\x01\\x02\\x03\\x04\\x05\")\n\t    def test_blob_set_item_negative_index(self):\n\t        self.blob[-1] = 255\n\t        self.assertEqual(self.blob[-1], 255)\n\t    def test_blob_get_slice(self):\n", "        self.assertEqual(self.blob[5:14], b\"blob data\")\n\t    def test_blob_get_empty_slice(self):\n\t        self.assertEqual(self.blob[5:5], b\"\")\n\t    def test_blob_get_slice_negative_index(self):\n\t        self.assertEqual(self.blob[5:-5], self.data[5:-5])\n\t    def test_blob_get_slice_with_skip(self):\n\t        self.assertEqual(self.blob[0:10:2], b\"ti lb\")\n\t    def test_blob_set_slice(self):\n\t        self.blob[0:5] = b\"12345\"\n\t        expected = b\"12345\" + self.data[5:]\n", "        actual = self.cx.execute(\"select b from test\").fetchone()[0]\n\t        self.assertEqual(actual, expected)\n\t    def test_blob_set_empty_slice(self):\n\t        self.blob[0:0] = b\"\"\n\t        self.assertEqual(self.blob[:], self.data)\n\t    def test_blob_set_slice_with_skip(self):\n\t        self.blob[0:10:2] = b\"12345\"\n\t        actual = self.cx.execute(\"select b from test\").fetchone()[0]\n\t        expected = b\"1h2s3b4o5 \" + self.data[10:]\n\t        self.assertEqual(actual, expected)\n", "    def test_blob_mapping_invalid_index_type(self):\n\t        msg = \"indices must be integers\"\n\t        with self.assertRaisesRegex(TypeError, msg):\n\t            self.blob[5:5.5]\n\t        with self.assertRaisesRegex(TypeError, msg):\n\t            self.blob[1.5]\n\t        with self.assertRaisesRegex(TypeError, msg):\n\t            self.blob[\"a\"] = b\"b\"\n\t    def test_blob_get_item_error(self):\n\t        dataset = [len(self.blob), 105, -105]\n", "        for idx in dataset:\n\t            with self.subTest(idx=idx):\n\t                with self.assertRaisesRegex(IndexError, \"index out of range\"):\n\t                    self.blob[idx]\n\t        with self.assertRaisesRegex(IndexError, \"cannot fit 'int'\"):\n\t            self.blob[ULLONG_MAX]\n\t        # Provoke read error\n\t        self.cx.execute(\"update test set b='aaaa' where rowid=1\")\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.blob[0]\n", "    def test_blob_set_item_error(self):\n\t        with self.assertRaisesRegex(TypeError, \"cannot be interpreted\"):\n\t            self.blob[0] = b\"multiple\"\n\t        with self.assertRaisesRegex(TypeError, \"cannot be interpreted\"):\n\t            self.blob[0] = b\"1\"\n\t        with self.assertRaisesRegex(TypeError, \"cannot be interpreted\"):\n\t            self.blob[0] = bytearray(b\"1\")\n\t        with self.assertRaisesRegex(TypeError, \"doesn't support.*deletion\"):\n\t            del self.blob[0]\n\t        with self.assertRaisesRegex(IndexError, \"Blob index out of range\"):\n", "            self.blob[1000] = 0\n\t        with self.assertRaisesRegex(ValueError, \"must be in range\"):\n\t            self.blob[0] = -1\n\t        with self.assertRaisesRegex(ValueError, \"must be in range\"):\n\t            self.blob[0] = 256\n\t        # Overflow errors are overridden with ValueError\n\t        with self.assertRaisesRegex(ValueError, \"must be in range\"):\n\t            self.blob[0] = 2**65\n\t    def test_blob_set_slice_error(self):\n\t        with self.assertRaisesRegex(IndexError, \"wrong size\"):\n", "            self.blob[5:10] = b\"a\"\n\t        with self.assertRaisesRegex(IndexError, \"wrong size\"):\n\t            self.blob[5:10] = b\"a\" * 1000\n\t        with self.assertRaisesRegex(TypeError, \"doesn't support.*deletion\"):\n\t            del self.blob[5:10]\n\t        with self.assertRaisesRegex(ValueError, \"step cannot be zero\"):\n\t            self.blob[5:10:0] = b\"12345\"\n\t        with self.assertRaises(BufferError):\n\t            self.blob[5:10] = memoryview(b\"abcde\")[::2]\n\t    def test_blob_sequence_not_supported(self):\n", "        with self.assertRaisesRegex(TypeError, \"unsupported operand\"):\n\t            self.blob + self.blob\n\t        with self.assertRaisesRegex(TypeError, \"unsupported operand\"):\n\t            self.blob * 5\n\t        with self.assertRaisesRegex(TypeError, \"is not iterable\"):\n\t            b\"a\" in self.blob\n\t    def test_blob_context_manager(self):\n\t        data = b\"a\" * 50\n\t        with self.cx.blobopen(\"test\", \"b\", 1) as blob:\n\t            blob.write(data)\n", "        actual = self.cx.execute(\"select b from test\").fetchone()[0]\n\t        self.assertEqual(actual, data)\n\t        # Check that __exit__ closed the blob\n\t        with self.assertRaisesRegex(sqlite.ProgrammingError, \"closed blob\"):\n\t            blob.read()\n\t    def test_blob_context_manager_reraise_exceptions(self):\n\t        class DummyException(Exception):\n\t            pass\n\t        with self.assertRaisesRegex(DummyException, \"reraised\"):\n\t            with self.cx.blobopen(\"test\", \"b\", 1) as blob:\n", "                raise DummyException(\"reraised\")\n\t    def test_blob_closed(self):\n\t        with memory_database() as cx:\n\t            cx.execute(\"create table test(b blob)\")\n\t            cx.execute(\"insert into test values (zeroblob(100))\")\n\t            blob = cx.blobopen(\"test\", \"b\", 1)\n\t            blob.close()\n\t            msg = \"Cannot operate on a closed blob\"\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob.read()\n", "            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob.write(b\"\")\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob.seek(0)\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob.tell()\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob.__enter__()\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob.__exit__(None, None, None)\n", "            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                len(blob)\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob[0]\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob[0:1]\n\t            with self.assertRaisesRegex(sqlite.ProgrammingError, msg):\n\t                blob[0] = b\"\"\n\t    def test_blob_closed_db_read(self):\n\t        with memory_database() as cx:\n", "            cx.execute(\"create table test(b blob)\")\n\t            cx.execute(\"insert into test(b) values (zeroblob(100))\")\n\t            blob = cx.blobopen(\"test\", \"b\", 1)\n\t            cx.close()\n\t            self.assertRaisesRegex(sqlite.ProgrammingError,\n\t                                   \"Cannot operate on a closed database\",\n\t                                   blob.read)\n\t@threading_helper.requires_working_threading()\n\tclass ThreadTests(unittest.TestCase):\n\t    def setUp(self):\n", "        self.con = sqlite.connect(\":memory:\")\n\t        self.cur = self.con.cursor()\n\t        self.cur.execute(\"create table test(name text, b blob)\")\n\t        self.cur.execute(\"insert into test values('blob', zeroblob(1))\")\n\t    def tearDown(self):\n\t        self.cur.close()\n\t        self.con.close()\n\t    @threading_helper.reap_threads\n\t    def _run_test(self, fn, *args, **kwds):\n\t        def run(err):\n", "            try:\n\t                fn(*args, **kwds)\n\t                err.append(\"did not raise ProgrammingError\")\n\t            except sqlite.ProgrammingError:\n\t                pass\n\t            except:\n\t                err.append(\"raised wrong exception\")\n\t        err = []\n\t        t = threading.Thread(target=run, kwargs={\"err\": err})\n\t        t.start()\n", "        t.join()\n\t        if err:\n\t            self.fail(\"\\n\".join(err))\n\t    def test_check_connection_thread(self):\n\t        fns = [\n\t            lambda: self.con.cursor(),\n\t            lambda: self.con.commit(),\n\t            lambda: self.con.rollback(),\n\t            lambda: self.con.close(),\n\t            lambda: self.con.set_trace_callback(None),\n", "            # NOTE: not supported by libsql_client\n\t            # lambda: self.con.set_authorizer(None),\n\t            # lambda: self.con.create_collation(\"foo\", None),\n\t            # lambda: self.con.setlimit(sqlite.SQLITE_LIMIT_LENGTH, -1),\n\t            # lambda: self.con.getlimit(sqlite.SQLITE_LIMIT_LENGTH),\n\t            # lambda: self.con.blobopen(\"test\", \"b\", 1),\n\t        ]\n\t        # NOTE: not supported by libsql_client\n\t        # if hasattr(sqlite.Connection, \"serialize\"):\n\t        #     fns.append(lambda: self.con.serialize())\n", "        #     fns.append(lambda: self.con.deserialize(b\"\"))\n\t        # if sqlite.sqlite_version_info >= (3, 25, 0):\n\t        #     fns.append(lambda: self.con.create_window_function(\"foo\", 0, None))\n\t        for fn in fns:\n\t            with self.subTest(fn=fn):\n\t                self._run_test(fn)\n\t    def test_check_cursor_thread(self):\n\t        fns = [\n\t            lambda: self.cur.execute(\"insert into test(name) values('a')\"),\n\t            lambda: self.cur.close(),\n", "            lambda: self.cur.execute(\"select name from test\"),\n\t            lambda: self.cur.fetchone(),\n\t        ]\n\t        for fn in fns:\n\t            with self.subTest(fn=fn):\n\t                self._run_test(fn)\n\t    @threading_helper.reap_threads\n\t    def test_dont_check_same_thread(self):\n\t        def run(con, err):\n\t            try:\n", "                con.execute(\"select 1\")\n\t            except sqlite.Error:\n\t                err.append(\"multi-threading not allowed\")\n\t        con = sqlite.connect(\":memory:\", check_same_thread=False)\n\t        err = []\n\t        t = threading.Thread(target=run, kwargs={\"con\": con, \"err\": err})\n\t        t.start()\n\t        t.join()\n\t        self.assertEqual(len(err), 0, \"\\n\".join(err))\n\tclass ConstructorTests(unittest.TestCase):\n", "    def test_date(self):\n\t        d = sqlite.Date(2004, 10, 28)\n\t    def test_time(self):\n\t        t = sqlite.Time(12, 39, 35)\n\t    def test_timestamp(self):\n\t        ts = sqlite.Timestamp(2004, 10, 28, 12, 39, 35)\n\t    def test_date_from_ticks(self):\n\t        d = sqlite.DateFromTicks(42)\n\t    def test_time_from_ticks(self):\n\t        t = sqlite.TimeFromTicks(42)\n", "    def test_timestamp_from_ticks(self):\n\t        ts = sqlite.TimestampFromTicks(42)\n\t    def test_binary(self):\n\t        b = sqlite.Binary(b\"\\0'\")\n\t@unittest.skip(\"Not supported\")\n\tclass ExtensionTests(unittest.TestCase):\n\t    def test_script_string_sql(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        cur.executescript(\"\"\"\n", "            -- bla bla\n\t            /* a stupid comment */\n\t            create table a(i);\n\t            insert into a(i) values (5);\n\t            \"\"\")\n\t        cur.execute(\"select i from a\")\n\t        res = cur.fetchone()[0]\n\t        self.assertEqual(res, 5)\n\t    def test_script_syntax_error(self):\n\t        con = sqlite.connect(\":memory:\")\n", "        cur = con.cursor()\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            cur.executescript(\"create table test(x); asdf; create table test2(x)\")\n\t    def test_script_error_normal(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            cur.executescript(\"create table test(sadfsadfdsa); select foo from hurz;\")\n\t    def test_cursor_executescript_as_bytes(self):\n\t        con = sqlite.connect(\":memory:\")\n", "        cur = con.cursor()\n\t        with self.assertRaises(TypeError):\n\t            cur.executescript(b\"create table test(foo); insert into test(foo) values (5);\")\n\t    def test_cursor_executescript_with_null_characters(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        with self.assertRaises(ValueError):\n\t            cur.executescript(\"\"\"\n\t                create table a(i);\\0\n\t                insert into a(i) values (5);\n", "                \"\"\")\n\t    def test_cursor_executescript_with_surrogates(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        with self.assertRaises(UnicodeEncodeError):\n\t            cur.executescript(\"\"\"\n\t                create table a(s);\n\t                insert into a(s) values ('\\ud8ff');\n\t                \"\"\")\n\t    def test_cursor_executescript_too_large_script(self):\n", "        msg = \"query string is too large\"\n\t        with memory_database() as cx, cx_limit(cx) as lim:\n\t            cx.executescript(\"select 'almost too large'\".ljust(lim))\n\t            with self.assertRaisesRegex(sqlite.DataError, msg):\n\t                cx.executescript(\"select 'too large'\".ljust(lim+1))\n\t    def test_cursor_executescript_tx_control(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.execute(\"begin\")\n\t        self.assertTrue(con.in_transaction)\n\t        con.executescript(\"select 1\")\n", "        self.assertFalse(con.in_transaction)\n\t    def test_connection_execute(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        result = con.execute(\"select 5\").fetchone()[0]\n\t        self.assertEqual(result, 5, \"Basic test of Connection.execute\")\n\t    def test_connection_executemany(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.execute(\"create table test(foo)\")\n\t        con.executemany(\"insert into test(foo) values (?)\", [(3,), (4,)])\n\t        result = con.execute(\"select foo from test order by foo\").fetchall()\n", "        self.assertEqual(result[0][0], 3, \"Basic test of Connection.executemany\")\n\t        self.assertEqual(result[1][0], 4, \"Basic test of Connection.executemany\")\n\t    def test_connection_executescript(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.executescript(\"create table test(foo); insert into test(foo) values (5);\")\n\t        result = con.execute(\"select foo from test\").fetchone()[0]\n\t        self.assertEqual(result, 5, \"Basic test of Connection.executescript\")\n\tclass ClosedConTests(unittest.TestCase):\n\t    def test_closed_con_cursor(self):\n\t        con = sqlite.connect(\":memory:\")\n", "        con.close()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            cur = con.cursor()\n\t    def test_closed_con_commit(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.close()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            con.commit()\n\t    def test_closed_con_rollback(self):\n\t        con = sqlite.connect(\":memory:\")\n", "        con.close()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            con.rollback()\n\t    def test_closed_cur_execute(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        con.close()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            cur.execute(\"select 4\")\n\t    @unittest.skip(\"Not supported\")\n", "    def test_closed_create_function(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.close()\n\t        def f(x): return 17\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            con.create_function(\"foo\", 1, f)\n\t    @unittest.skip(\"Not supported\")\n\t    def test_closed_create_aggregate(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.close()\n", "        class Agg:\n\t            def __init__(self):\n\t                pass\n\t            def step(self, x):\n\t                pass\n\t            def finalize(self):\n\t                return 17\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            con.create_aggregate(\"foo\", 1, Agg)\n\t    @unittest.skip(\"Not supported\")\n", "    def test_closed_set_authorizer(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.close()\n\t        def authorizer(*args):\n\t            return sqlite.DENY\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            con.set_authorizer(authorizer)\n\t    @unittest.skip(\"Not supported\")\n\t    def test_closed_set_progress_callback(self):\n\t        con = sqlite.connect(\":memory:\")\n", "        con.close()\n\t        def progress(): pass\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            con.set_progress_handler(progress, 100)\n\t    def test_closed_call(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        con.close()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            con()\n\tclass ClosedCurTests(unittest.TestCase):\n", "    def test_closed(self):\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        cur.close()\n\t        for method_name in (\"execute\", \"executemany\", \"executescript\", \"fetchall\", \"fetchmany\", \"fetchone\"):\n\t            if method_name in (\"execute\", \"executescript\"):\n\t                params = (\"select 4 union select 5\",)\n\t            elif method_name == \"executemany\":\n\t                params = (\"insert into foo(bar) values (?)\", [(3,), (4,)])\n\t            else:\n", "                params = []\n\t            with self.assertRaises(sqlite.ProgrammingError):\n\t                method = getattr(cur, method_name)\n\t                method(*params)\n\tclass SqliteOnConflictTests(unittest.TestCase):\n\t    \"\"\"\n\t    Tests for SQLite's \"insert on conflict\" feature.\n\t    See https://www.sqlite.org/lang_conflict.html for details.\n\t    \"\"\"\n\t    def setUp(self):\n", "        self.cx = sqlite.connect(\":memory:\")\n\t        self.cu = self.cx.cursor()\n\t        self.cu.execute(\"\"\"\n\t          CREATE TABLE test(\n\t            id INTEGER PRIMARY KEY, name TEXT, unique_name TEXT UNIQUE\n\t          );\n\t        \"\"\")\n\t    def tearDown(self):\n\t        self.cu.close()\n\t        self.cx.close()\n", "    @unittest.skip(\"libsql_client depends on server sending autocommit mode\")\n\t    def test_on_conflict_rollback_with_explicit_transaction(self):\n\t        self.cx.isolation_level = None  # autocommit mode\n\t        self.cu = self.cx.cursor()\n\t        # Start an explicit transaction.\n\t        self.cu.execute(\"BEGIN\")\n\t        self.cu.execute(\"INSERT INTO test(name) VALUES ('abort_test')\")\n\t        self.cu.execute(\"INSERT OR ROLLBACK INTO test(unique_name) VALUES ('foo')\")\n\t        with self.assertRaises(sqlite.IntegrityError):\n\t            self.cu.execute(\"INSERT OR ROLLBACK INTO test(unique_name) VALUES ('foo')\")\n", "        # Use connection to commit.\n\t        self.cx.commit()\n\t        self.cu.execute(\"SELECT name, unique_name from test\")\n\t        # Transaction should have rolled back and nothing should be in table.\n\t        self.assertEqual(self.cu.fetchall(), [])\n\t    def test_on_conflict_abort_raises_with_explicit_transactions(self):\n\t        # Abort cancels the current sql statement but doesn't change anything\n\t        # about the current transaction.\n\t        self.cx.isolation_level = None  # autocommit mode\n\t        self.cu = self.cx.cursor()\n", "        # Start an explicit transaction.\n\t        self.cu.execute(\"BEGIN\")\n\t        self.cu.execute(\"INSERT INTO test(name) VALUES ('abort_test')\")\n\t        self.cu.execute(\"INSERT OR ABORT INTO test(unique_name) VALUES ('foo')\")\n\t        with self.assertRaises(sqlite.IntegrityError):\n\t            self.cu.execute(\"INSERT OR ABORT INTO test(unique_name) VALUES ('foo')\")\n\t        self.cx.commit()\n\t        self.cu.execute(\"SELECT name, unique_name FROM test\")\n\t        # Expect the first two inserts to work, third to do nothing.\n\t        self.assertEqual(self.cu.fetchall(), [('abort_test', None), (None, 'foo',)])\n", "    def test_on_conflict_rollback_without_transaction(self):\n\t        # Start of implicit transaction\n\t        self.cu.execute(\"INSERT INTO test(name) VALUES ('abort_test')\")\n\t        self.cu.execute(\"INSERT OR ROLLBACK INTO test(unique_name) VALUES ('foo')\")\n\t        with self.assertRaises(sqlite.IntegrityError):\n\t            self.cu.execute(\"INSERT OR ROLLBACK INTO test(unique_name) VALUES ('foo')\")\n\t        self.cu.execute(\"SELECT name, unique_name FROM test\")\n\t        # Implicit transaction is rolled back on error.\n\t        self.assertEqual(self.cu.fetchall(), [])\n\t    def test_on_conflict_abort_raises_without_transactions(self):\n", "        # Abort cancels the current sql statement but doesn't change anything\n\t        # about the current transaction.\n\t        self.cu.execute(\"INSERT INTO test(name) VALUES ('abort_test')\")\n\t        self.cu.execute(\"INSERT OR ABORT INTO test(unique_name) VALUES ('foo')\")\n\t        with self.assertRaises(sqlite.IntegrityError):\n\t            self.cu.execute(\"INSERT OR ABORT INTO test(unique_name) VALUES ('foo')\")\n\t        # Make sure all other values were inserted.\n\t        self.cu.execute(\"SELECT name, unique_name FROM test\")\n\t        self.assertEqual(self.cu.fetchall(), [('abort_test', None), (None, 'foo',)])\n\t    def test_on_conflict_fail(self):\n", "        self.cu.execute(\"INSERT OR FAIL INTO test(unique_name) VALUES ('foo')\")\n\t        with self.assertRaises(sqlite.IntegrityError):\n\t            self.cu.execute(\"INSERT OR FAIL INTO test(unique_name) VALUES ('foo')\")\n\t        self.assertEqual(self.cu.fetchall(), [])\n\t    def test_on_conflict_ignore(self):\n\t        self.cu.execute(\"INSERT OR IGNORE INTO test(unique_name) VALUES ('foo')\")\n\t        # Nothing should happen.\n\t        self.cu.execute(\"INSERT OR IGNORE INTO test(unique_name) VALUES ('foo')\")\n\t        self.cu.execute(\"SELECT unique_name FROM test\")\n\t        self.assertEqual(self.cu.fetchall(), [('foo',)])\n", "    def test_on_conflict_replace(self):\n\t        self.cu.execute(\"INSERT OR REPLACE INTO test(name, unique_name) VALUES ('Data!', 'foo')\")\n\t        # There shouldn't be an IntegrityError exception.\n\t        self.cu.execute(\"INSERT OR REPLACE INTO test(name, unique_name) VALUES ('Very different data!', 'foo')\")\n\t        self.cu.execute(\"SELECT name, unique_name FROM test\")\n\t        self.assertEqual(self.cu.fetchall(), [('Very different data!', 'foo')])\n\t@requires_subprocess()\n\tclass MultiprocessTests(unittest.TestCase):\n\t    CONNECTION_TIMEOUT = SHORT_TIMEOUT / 1000.  # Defaults to 30 ms\n\t    def tearDown(self):\n", "        unlink(TESTFN)\n\t    def test_ctx_mgr_rollback_if_commit_failed(self):\n\t        # bpo-27334: ctx manager does not rollback if commit fails\n\t        SCRIPT = f\"\"\"if 1:\n\t            import sqlite3\n\t            def wait():\n\t                print(\"started\")\n\t                assert \"database is locked\" in input()\n\t            cx = sqlite3.connect(\"{TESTFN}\", timeout={self.CONNECTION_TIMEOUT})\n\t            cx.create_function(\"wait\", 0, wait)\n", "            with cx:\n\t                cx.execute(\"create table t(t)\")\n\t            try:\n\t                # execute two transactions; both will try to lock the db\n\t                cx.executescript('''\n\t                    -- start a transaction and wait for parent\n\t                    begin transaction;\n\t                    select * from t;\n\t                    select wait();\n\t                    rollback;\n", "                    -- start a new transaction; would fail if parent holds lock\n\t                    begin transaction;\n\t                    select * from t;\n\t                    rollback;\n\t                ''')\n\t            finally:\n\t                cx.close()\n\t        \"\"\"\n\t        # spawn child process\n\t        proc = subprocess.Popen(\n", "            [sys.executable, \"-c\", SCRIPT],\n\t            encoding=\"utf-8\",\n\t            bufsize=0,\n\t            stdin=subprocess.PIPE,\n\t            stdout=subprocess.PIPE,\n\t        )\n\t        self.addCleanup(proc.communicate)\n\t        # wait for child process to start\n\t        self.assertEqual(\"started\", proc.stdout.readline().strip())\n\t        cx = sqlite.connect(TESTFN, timeout=self.CONNECTION_TIMEOUT)\n", "        try:  # context manager should correctly release the db lock\n\t            with cx:\n\t                cx.execute(\"insert into t values('test')\")\n\t        except sqlite.OperationalError as exc:\n\t            proc.stdin.write(str(exc))\n\t        else:\n\t            proc.stdin.write(\"no error\")\n\t        finally:\n\t            cx.close()\n\t        # terminate child process\n", "        self.assertIsNone(proc.returncode)\n\t        try:\n\t            proc.communicate(input=\"end\", timeout=SHORT_TIMEOUT)\n\t        except subprocess.TimeoutExpired:\n\t            proc.kill()\n\t            proc.communicate()\n\t            raise\n\t        self.assertEqual(proc.returncode, 0)\n\tif __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/libsql_client_helpers.py", "chunked_list": ["import os\n\timport re\n\tfrom libsql_client.dbapi2 import *\n\tdburi = os.getenv(\"URL\", \"ws://localhost:8080\")\n\t_orig_connect = connect\n\t_system_schema_re = re.compile(\"^(_|sqlite_|libsql_)\")\n\tdef drop_user_schemas(conn):\n\t    try:\n\t        cur = conn.execute(\"SELECT name, type FROM sqlite_schema\")\n\t    except Exception as e:\n", "        print(f\"WARNING: could not list sqlite_schema: {e}\")\n\t        return\n\t    for name, kind in cur.fetchall():\n\t        if _system_schema_re.match(name):\n\t            continue\n\t        try:\n\t            conn.execute(f\"drop {kind} '{name}'\")\n\t        except Exception as e:\n\t            print(f\"WARNING: could not drop {kind} {name}: {e}\")\n\tdef connect(database, *args, **kwargs):\n", "    drop_schema = False\n\t    if database == \":memory:\":\n\t        # most of the test suite uses :memory: for testing, so redirect\n\t        # those to our test server, but drop all user schema\n\t        database = dburi\n\t        kwargs[\"uri\"] = True\n\t        drop_schema = True\n\t    elif os.path.isdir(database):\n\t        # tests that open a folder expect to fail\n\t        database = \"wss://127.0.0.1:1\"\n", "        kwargs[\"uri\"] = True\n\t    else:\n\t        # keep intact, but they will be using sqlite3.connect and not\n\t        # our code, nevertheless this helps to test our compatibility\n\t        pass\n\t    conn = _orig_connect(database, *args, **kwargs)\n\t    if drop_schema:\n\t        drop_user_schemas(conn)\n\t    return conn\n"]}
{"filename": "tests/dbapi2/test_backup.py", "chunked_list": ["from . import libsql_client_helpers as sqlite\n\timport unittest\n\t@unittest.skip(\"Not supported\")\n\tclass BackupTests(unittest.TestCase):\n\t    def setUp(self):\n\t        cx = self.cx = sqlite.connect(\":memory:\")\n\t        cx.execute('CREATE TABLE foo (key INTEGER)')\n\t        cx.executemany('INSERT INTO foo (key) VALUES (?)', [(3,), (4,)])\n\t        cx.commit()\n\t    def tearDown(self):\n", "        self.cx.close()\n\t    def verify_backup(self, bckcx):\n\t        result = bckcx.execute(\"SELECT key FROM foo ORDER BY key\").fetchall()\n\t        self.assertEqual(result[0][0], 3)\n\t        self.assertEqual(result[1][0], 4)\n\t    def test_bad_target(self):\n\t        with self.assertRaises(TypeError):\n\t            self.cx.backup(None)\n\t        with self.assertRaises(TypeError):\n\t            self.cx.backup()\n", "    def test_bad_target_filename(self):\n\t        with self.assertRaises(TypeError):\n\t            self.cx.backup('some_file_name.db')\n\t    def test_bad_target_same_connection(self):\n\t        with self.assertRaises(ValueError):\n\t            self.cx.backup(self.cx)\n\t    def test_bad_target_closed_connection(self):\n\t        bck = sqlite.connect(':memory:')\n\t        bck.close()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n", "            self.cx.backup(bck)\n\t    def test_bad_source_closed_connection(self):\n\t        bck = sqlite.connect(':memory:')\n\t        source = sqlite.connect(\":memory:\")\n\t        source.close()\n\t        with self.assertRaises(sqlite.ProgrammingError):\n\t            source.backup(bck)\n\t    def test_bad_target_in_transaction(self):\n\t        bck = sqlite.connect(':memory:')\n\t        bck.execute('CREATE TABLE bar (key INTEGER)')\n", "        bck.executemany('INSERT INTO bar (key) VALUES (?)', [(3,), (4,)])\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            self.cx.backup(bck)\n\t        if sqlite.sqlite_version_info < (3, 8, 8):\n\t            self.assertEqual(str(cm.exception), 'target is in transaction')\n\t    def test_keyword_only_args(self):\n\t        with self.assertRaises(TypeError):\n\t            with sqlite.connect(':memory:') as bck:\n\t                self.cx.backup(bck, 1)\n\t    def test_simple(self):\n", "        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck)\n\t            self.verify_backup(bck)\n\t    def test_progress(self):\n\t        journal = []\n\t        def progress(status, remaining, total):\n\t            journal.append(status)\n\t        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck, pages=1, progress=progress)\n\t            self.verify_backup(bck)\n", "        self.assertEqual(len(journal), 2)\n\t        self.assertEqual(journal[0], sqlite.SQLITE_OK)\n\t        self.assertEqual(journal[1], sqlite.SQLITE_DONE)\n\t    def test_progress_all_pages_at_once_1(self):\n\t        journal = []\n\t        def progress(status, remaining, total):\n\t            journal.append(remaining)\n\t        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck, progress=progress)\n\t            self.verify_backup(bck)\n", "        self.assertEqual(len(journal), 1)\n\t        self.assertEqual(journal[0], 0)\n\t    def test_progress_all_pages_at_once_2(self):\n\t        journal = []\n\t        def progress(status, remaining, total):\n\t            journal.append(remaining)\n\t        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck, pages=-1, progress=progress)\n\t            self.verify_backup(bck)\n\t        self.assertEqual(len(journal), 1)\n", "        self.assertEqual(journal[0], 0)\n\t    def test_non_callable_progress(self):\n\t        with self.assertRaises(TypeError) as cm:\n\t            with sqlite.connect(':memory:') as bck:\n\t                self.cx.backup(bck, pages=1, progress='bar')\n\t        self.assertEqual(str(cm.exception), 'progress argument must be a callable')\n\t    def test_modifying_progress(self):\n\t        journal = []\n\t        def progress(status, remaining, total):\n\t            if not journal:\n", "                self.cx.execute('INSERT INTO foo (key) VALUES (?)', (remaining+1000,))\n\t                self.cx.commit()\n\t            journal.append(remaining)\n\t        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck, pages=1, progress=progress)\n\t            self.verify_backup(bck)\n\t            result = bck.execute(\"SELECT key FROM foo\"\n\t                                 \" WHERE key >= 1000\"\n\t                                 \" ORDER BY key\").fetchall()\n\t            self.assertEqual(result[0][0], 1001)\n", "        self.assertEqual(len(journal), 3)\n\t        self.assertEqual(journal[0], 1)\n\t        self.assertEqual(journal[1], 1)\n\t        self.assertEqual(journal[2], 0)\n\t    def test_failing_progress(self):\n\t        def progress(status, remaining, total):\n\t            raise SystemError('nearly out of space')\n\t        with self.assertRaises(SystemError) as err:\n\t            with sqlite.connect(':memory:') as bck:\n\t                self.cx.backup(bck, progress=progress)\n", "        self.assertEqual(str(err.exception), 'nearly out of space')\n\t    def test_database_source_name(self):\n\t        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck, name='main')\n\t        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck, name='temp')\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            with sqlite.connect(':memory:') as bck:\n\t                self.cx.backup(bck, name='non-existing')\n\t        self.assertIn(\"unknown database\", str(cm.exception))\n", "        self.cx.execute(\"ATTACH DATABASE ':memory:' AS attached_db\")\n\t        self.cx.execute('CREATE TABLE attached_db.foo (key INTEGER)')\n\t        self.cx.executemany('INSERT INTO attached_db.foo (key) VALUES (?)', [(3,), (4,)])\n\t        self.cx.commit()\n\t        with sqlite.connect(':memory:') as bck:\n\t            self.cx.backup(bck, name='attached_db')\n\t            self.verify_backup(bck)\n\tif __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/test_userfunctions.py", "chunked_list": ["# pysqlite2/test/userfunctions.py: tests for user-defined functions and\n\t#                                  aggregates.\n\t#\n\t# Copyright (C) 2005-2007 Gerhard Häring <gh@ghaering.de>\n\t#\n\t# This file is part of pysqlite.\n\t#\n\t# This software is provided 'as-is', without any express or implied\n\t# warranty.  In no event will the authors be held liable for any damages\n\t# arising from the use of this software.\n", "#\n\t# Permission is granted to anyone to use this software for any purpose,\n\t# including commercial applications, and to alter it and redistribute it\n\t# freely, subject to the following restrictions:\n\t#\n\t# 1. The origin of this software must not be misrepresented; you must not\n\t#    claim that you wrote the original software. If you use this software\n\t#    in a product, an acknowledgment in the product documentation would be\n\t#    appreciated but is not required.\n\t# 2. Altered source versions must be plainly marked as such, and must not be\n", "#    misrepresented as being the original software.\n\t# 3. This notice may not be removed or altered from any source distribution.\n\timport contextlib\n\timport functools\n\timport io\n\timport re\n\timport sys\n\timport unittest\n\tfrom . import libsql_client_helpers as sqlite\n\tfrom unittest.mock import Mock, patch\n", "from test.support import bigmemtest, catch_unraisable_exception, gc_collect\n\tfrom .test_dbapi import cx_limit\n\tdef with_tracebacks(exc, regex=\"\", name=\"\"):\n\t    \"\"\"Convenience decorator for testing callback tracebacks.\"\"\"\n\t    def decorator(func):\n\t        _regex = re.compile(regex) if regex else None\n\t        @functools.wraps(func)\n\t        def wrapper(self, *args, **kwargs):\n\t            with catch_unraisable_exception() as cm:\n\t                # First, run the test with traceback enabled.\n", "                with check_tracebacks(self, cm, exc, _regex, name):\n\t                    func(self, *args, **kwargs)\n\t            # Then run the test with traceback disabled.\n\t            func(self, *args, **kwargs)\n\t        return wrapper\n\t    return decorator\n\t@contextlib.contextmanager\n\tdef check_tracebacks(self, cm, exc, regex, obj_name):\n\t    \"\"\"Convenience context manager for testing callback tracebacks.\"\"\"\n\t    sqlite.enable_callback_tracebacks(True)\n", "    try:\n\t        buf = io.StringIO()\n\t        with contextlib.redirect_stderr(buf):\n\t            yield\n\t        self.assertEqual(cm.unraisable.exc_type, exc)\n\t        if regex:\n\t            msg = str(cm.unraisable.exc_value)\n\t            self.assertIsNotNone(regex.search(msg))\n\t        if obj_name:\n\t            self.assertEqual(cm.unraisable.object.__name__, obj_name)\n", "    finally:\n\t        sqlite.enable_callback_tracebacks(False)\n\tdef func_returntext():\n\t    return \"foo\"\n\tdef func_returntextwithnull():\n\t    return \"1\\x002\"\n\tdef func_returnunicode():\n\t    return \"bar\"\n\tdef func_returnint():\n\t    return 42\n", "def func_returnfloat():\n\t    return 3.14\n\tdef func_returnnull():\n\t    return None\n\tdef func_returnblob():\n\t    return b\"blob\"\n\tdef func_returnlonglong():\n\t    return 1<<31\n\tdef func_raiseexception():\n\t    5/0\n", "def func_memoryerror():\n\t    raise MemoryError\n\tdef func_overflowerror():\n\t    raise OverflowError\n\tclass AggrNoStep:\n\t    def __init__(self):\n\t        pass\n\t    def finalize(self):\n\t        return 1\n\tclass AggrNoFinalize:\n", "    def __init__(self):\n\t        pass\n\t    def step(self, x):\n\t        pass\n\tclass AggrExceptionInInit:\n\t    def __init__(self):\n\t        5/0\n\t    def step(self, x):\n\t        pass\n\t    def finalize(self):\n", "        pass\n\tclass AggrExceptionInStep:\n\t    def __init__(self):\n\t        pass\n\t    def step(self, x):\n\t        5/0\n\t    def finalize(self):\n\t        return 42\n\tclass AggrExceptionInFinalize:\n\t    def __init__(self):\n", "        pass\n\t    def step(self, x):\n\t        pass\n\t    def finalize(self):\n\t        5/0\n\tclass AggrCheckType:\n\t    def __init__(self):\n\t        self.val = None\n\t    def step(self, whichType, val):\n\t        theType = {\"str\": str, \"int\": int, \"float\": float, \"None\": type(None),\n", "                   \"blob\": bytes}\n\t        self.val = int(theType[whichType] is type(val))\n\t    def finalize(self):\n\t        return self.val\n\tclass AggrCheckTypes:\n\t    def __init__(self):\n\t        self.val = 0\n\t    def step(self, whichType, *vals):\n\t        theType = {\"str\": str, \"int\": int, \"float\": float, \"None\": type(None),\n\t                   \"blob\": bytes}\n", "        for val in vals:\n\t            self.val += int(theType[whichType] is type(val))\n\t    def finalize(self):\n\t        return self.val\n\tclass AggrSum:\n\t    def __init__(self):\n\t        self.val = 0.0\n\t    def step(self, val):\n\t        self.val += val\n\t    def finalize(self):\n", "        return self.val\n\tclass AggrText:\n\t    def __init__(self):\n\t        self.txt = \"\"\n\t    def step(self, txt):\n\t        self.txt = self.txt + txt\n\t    def finalize(self):\n\t        return self.txt\n\t@unittest.skip(\"Not supported\")\n\tclass FunctionTests(unittest.TestCase):\n", "    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        self.con.create_function(\"returntext\", 0, func_returntext)\n\t        self.con.create_function(\"returntextwithnull\", 0, func_returntextwithnull)\n\t        self.con.create_function(\"returnunicode\", 0, func_returnunicode)\n\t        self.con.create_function(\"returnint\", 0, func_returnint)\n\t        self.con.create_function(\"returnfloat\", 0, func_returnfloat)\n\t        self.con.create_function(\"returnnull\", 0, func_returnnull)\n\t        self.con.create_function(\"returnblob\", 0, func_returnblob)\n\t        self.con.create_function(\"returnlonglong\", 0, func_returnlonglong)\n", "        self.con.create_function(\"returnnan\", 0, lambda: float(\"nan\"))\n\t        self.con.create_function(\"returntoolargeint\", 0, lambda: 1 << 65)\n\t        self.con.create_function(\"return_noncont_blob\", 0,\n\t                                 lambda: memoryview(b\"blob\")[::2])\n\t        self.con.create_function(\"raiseexception\", 0, func_raiseexception)\n\t        self.con.create_function(\"memoryerror\", 0, func_memoryerror)\n\t        self.con.create_function(\"overflowerror\", 0, func_overflowerror)\n\t        self.con.create_function(\"isblob\", 1, lambda x: isinstance(x, bytes))\n\t        self.con.create_function(\"isnone\", 1, lambda x: x is None)\n\t        self.con.create_function(\"spam\", -1, lambda *x: len(x))\n", "        self.con.execute(\"create table test(t text)\")\n\t    def tearDown(self):\n\t        self.con.close()\n\t    def test_func_error_on_create(self):\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.con.create_function(\"bla\", -100, lambda x: 2*x)\n\t    def test_func_too_many_args(self):\n\t        category = sqlite.SQLITE_LIMIT_FUNCTION_ARG\n\t        msg = \"too many arguments on function\"\n\t        with cx_limit(self.con, category=category, limit=1):\n", "            self.con.execute(\"select abs(-1)\");\n\t            with self.assertRaisesRegex(sqlite.OperationalError, msg):\n\t                self.con.execute(\"select max(1, 2)\");\n\t    def test_func_ref_count(self):\n\t        def getfunc():\n\t            def f():\n\t                return 1\n\t            return f\n\t        f = getfunc()\n\t        globals()[\"foo\"] = f\n", "        # self.con.create_function(\"reftest\", 0, getfunc())\n\t        self.con.create_function(\"reftest\", 0, f)\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select reftest()\")\n\t    def test_func_return_text(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returntext()\")\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(type(val), str)\n\t        self.assertEqual(val, \"foo\")\n", "    def test_func_return_text_with_null_char(self):\n\t        cur = self.con.cursor()\n\t        res = cur.execute(\"select returntextwithnull()\").fetchone()[0]\n\t        self.assertEqual(type(res), str)\n\t        self.assertEqual(res, \"1\\x002\")\n\t    def test_func_return_unicode(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returnunicode()\")\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(type(val), str)\n", "        self.assertEqual(val, \"bar\")\n\t    def test_func_return_int(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returnint()\")\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(type(val), int)\n\t        self.assertEqual(val, 42)\n\t    def test_func_return_float(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returnfloat()\")\n", "        val = cur.fetchone()[0]\n\t        self.assertEqual(type(val), float)\n\t        if val < 3.139 or val > 3.141:\n\t            self.fail(\"wrong value\")\n\t    def test_func_return_null(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returnnull()\")\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(type(val), type(None))\n\t        self.assertEqual(val, None)\n", "    def test_func_return_blob(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returnblob()\")\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(type(val), bytes)\n\t        self.assertEqual(val, b\"blob\")\n\t    def test_func_return_long_long(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returnlonglong()\")\n\t        val = cur.fetchone()[0]\n", "        self.assertEqual(val, 1<<31)\n\t    def test_func_return_nan(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select returnnan()\")\n\t        self.assertIsNone(cur.fetchone()[0])\n\t    def test_func_return_too_large_int(self):\n\t        cur = self.con.cursor()\n\t        self.assertRaisesRegex(sqlite.DataError, \"string or blob too big\",\n\t                               self.con.execute, \"select returntoolargeint()\")\n\t    @with_tracebacks(ZeroDivisionError, name=\"func_raiseexception\")\n", "    def test_func_exception(self):\n\t        cur = self.con.cursor()\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            cur.execute(\"select raiseexception()\")\n\t            cur.fetchone()\n\t        self.assertEqual(str(cm.exception), 'user-defined function raised exception')\n\t    @with_tracebacks(MemoryError, name=\"func_memoryerror\")\n\t    def test_func_memory_error(self):\n\t        cur = self.con.cursor()\n\t        with self.assertRaises(MemoryError):\n", "            cur.execute(\"select memoryerror()\")\n\t            cur.fetchone()\n\t    @with_tracebacks(OverflowError, name=\"func_overflowerror\")\n\t    def test_func_overflow_error(self):\n\t        cur = self.con.cursor()\n\t        with self.assertRaises(sqlite.DataError):\n\t            cur.execute(\"select overflowerror()\")\n\t            cur.fetchone()\n\t    def test_any_arguments(self):\n\t        cur = self.con.cursor()\n", "        cur.execute(\"select spam(?, ?)\", (1, 2))\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(val, 2)\n\t    def test_empty_blob(self):\n\t        cur = self.con.execute(\"select isblob(x'')\")\n\t        self.assertTrue(cur.fetchone()[0])\n\t    def test_nan_float(self):\n\t        cur = self.con.execute(\"select isnone(?)\", (float(\"nan\"),))\n\t        # SQLite has no concept of nan; it is converted to NULL\n\t        self.assertTrue(cur.fetchone()[0])\n", "    def test_too_large_int(self):\n\t        err = \"Python int too large to convert to SQLite INTEGER\"\n\t        self.assertRaisesRegex(OverflowError, err, self.con.execute,\n\t                               \"select spam(?)\", (1 << 65,))\n\t    def test_non_contiguous_blob(self):\n\t        self.assertRaisesRegex(BufferError,\n\t                               \"underlying buffer is not C-contiguous\",\n\t                               self.con.execute, \"select spam(?)\",\n\t                               (memoryview(b\"blob\")[::2],))\n\t    @with_tracebacks(BufferError, regex=\"buffer.*contiguous\")\n", "    def test_return_non_contiguous_blob(self):\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            cur = self.con.execute(\"select return_noncont_blob()\")\n\t            cur.fetchone()\n\t    def test_param_surrogates(self):\n\t        self.assertRaisesRegex(UnicodeEncodeError, \"surrogates not allowed\",\n\t                               self.con.execute, \"select spam(?)\",\n\t                               (\"\\ud803\\ude6d\",))\n\t    def test_func_params(self):\n\t        results = []\n", "        def append_result(arg):\n\t            results.append((arg, type(arg)))\n\t        self.con.create_function(\"test_params\", 1, append_result)\n\t        dataset = [\n\t            (42, int),\n\t            (-1, int),\n\t            (1234567890123456789, int),\n\t            (4611686018427387905, int),  # 63-bit int with non-zero low bits\n\t            (3.14, float),\n\t            (float('inf'), float),\n", "            (\"text\", str),\n\t            (\"1\\x002\", str),\n\t            (\"\\u02e2q\\u02e1\\u2071\\u1d57\\u1d49\", str),\n\t            (b\"blob\", bytes),\n\t            (bytearray(range(2)), bytes),\n\t            (memoryview(b\"blob\"), bytes),\n\t            (None, type(None)),\n\t        ]\n\t        for val, _ in dataset:\n\t            cur = self.con.execute(\"select test_params(?)\", (val,))\n", "            cur.fetchone()\n\t        self.assertEqual(dataset, results)\n\t    # Regarding deterministic functions:\n\t    #\n\t    # Between 3.8.3 and 3.15.0, deterministic functions were only used to\n\t    # optimize inner loops, so for those versions we can only test if the\n\t    # sqlite machinery has factored out a call or not. From 3.15.0 and onward,\n\t    # deterministic functions were permitted in WHERE clauses of partial\n\t    # indices, which allows testing based on syntax, iso. the query optimizer.\n\t    @unittest.skipIf(sqlite.sqlite_version_info < (3, 8, 3), \"Requires SQLite 3.8.3 or higher\")\n", "    def test_func_non_deterministic(self):\n\t        mock = Mock(return_value=None)\n\t        self.con.create_function(\"nondeterministic\", 0, mock, deterministic=False)\n\t        if sqlite.sqlite_version_info < (3, 15, 0):\n\t            self.con.execute(\"select nondeterministic() = nondeterministic()\")\n\t            self.assertEqual(mock.call_count, 2)\n\t        else:\n\t            with self.assertRaises(sqlite.OperationalError):\n\t                self.con.execute(\"create index t on test(t) where nondeterministic() is not null\")\n\t    @unittest.skipIf(sqlite.sqlite_version_info < (3, 8, 3), \"Requires SQLite 3.8.3 or higher\")\n", "    def test_func_deterministic(self):\n\t        mock = Mock(return_value=None)\n\t        self.con.create_function(\"deterministic\", 0, mock, deterministic=True)\n\t        if sqlite.sqlite_version_info < (3, 15, 0):\n\t            self.con.execute(\"select deterministic() = deterministic()\")\n\t            self.assertEqual(mock.call_count, 1)\n\t        else:\n\t            try:\n\t                self.con.execute(\"create index t on test(t) where deterministic() is not null\")\n\t            except sqlite.OperationalError:\n", "                self.fail(\"Unexpected failure while creating partial index\")\n\t    @unittest.skipIf(sqlite.sqlite_version_info >= (3, 8, 3), \"SQLite < 3.8.3 needed\")\n\t    def test_func_deterministic_not_supported(self):\n\t        with self.assertRaises(sqlite.NotSupportedError):\n\t            self.con.create_function(\"deterministic\", 0, int, deterministic=True)\n\t    def test_func_deterministic_keyword_only(self):\n\t        with self.assertRaises(TypeError):\n\t            self.con.create_function(\"deterministic\", 0, int, True)\n\t    def test_function_destructor_via_gc(self):\n\t        # See bpo-44304: The destructor of the user function can\n", "        # crash if is called without the GIL from the gc functions\n\t        dest = sqlite.connect(':memory:')\n\t        def md5sum(t):\n\t            return\n\t        dest.create_function(\"md5\", 1, md5sum)\n\t        x = dest(\"create table lang (name, first_appeared)\")\n\t        del md5sum, dest\n\t        y = [x]\n\t        y.append(y)\n\t        del x,y\n", "        gc_collect()\n\t    @with_tracebacks(OverflowError)\n\t    def test_func_return_too_large_int(self):\n\t        cur = self.con.cursor()\n\t        for value in 2**63, -2**63-1, 2**64:\n\t            self.con.create_function(\"largeint\", 0, lambda value=value: value)\n\t            with self.assertRaises(sqlite.DataError):\n\t                cur.execute(\"select largeint()\")\n\t    @with_tracebacks(UnicodeEncodeError, \"surrogates not allowed\", \"chr\")\n\t    def test_func_return_text_with_surrogates(self):\n", "        cur = self.con.cursor()\n\t        self.con.create_function(\"pychr\", 1, chr)\n\t        for value in 0xd8ff, 0xdcff:\n\t            with self.assertRaises(sqlite.OperationalError):\n\t                cur.execute(\"select pychr(?)\", (value,))\n\t    @unittest.skipUnless(sys.maxsize > 2**32, 'requires 64bit platform')\n\t    @bigmemtest(size=2**31, memuse=3, dry_run=False)\n\t    def test_func_return_too_large_text(self, size):\n\t        cur = self.con.cursor()\n\t        for size in 2**31-1, 2**31:\n", "            self.con.create_function(\"largetext\", 0, lambda size=size: \"b\" * size)\n\t            with self.assertRaises(sqlite.DataError):\n\t                cur.execute(\"select largetext()\")\n\t    @unittest.skipUnless(sys.maxsize > 2**32, 'requires 64bit platform')\n\t    @bigmemtest(size=2**31, memuse=2, dry_run=False)\n\t    def test_func_return_too_large_blob(self, size):\n\t        cur = self.con.cursor()\n\t        for size in 2**31-1, 2**31:\n\t            self.con.create_function(\"largeblob\", 0, lambda size=size: b\"b\" * size)\n\t            with self.assertRaises(sqlite.DataError):\n", "                cur.execute(\"select largeblob()\")\n\t    def test_func_return_illegal_value(self):\n\t        self.con.create_function(\"badreturn\", 0, lambda: self)\n\t        msg = \"user-defined function raised exception\"\n\t        self.assertRaisesRegex(sqlite.OperationalError, msg,\n\t                               self.con.execute, \"select badreturn()\")\n\tclass WindowSumInt:\n\t    def __init__(self):\n\t        self.count = 0\n\t    def step(self, value):\n", "        self.count += value\n\t    def value(self):\n\t        return self.count\n\t    def inverse(self, value):\n\t        self.count -= value\n\t    def finalize(self):\n\t        return self.count\n\tclass BadWindow(Exception):\n\t    pass\n\t@unittest.skip(\"Not supported\")\n", "@unittest.skipIf(sqlite.sqlite_version_info < (3, 25, 0),\n\t                 \"Requires SQLite 3.25.0 or newer\")\n\tclass WindowFunctionTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        self.cur = self.con.cursor()\n\t        # Test case taken from https://www.sqlite.org/windowfunctions.html#udfwinfunc\n\t        values = [\n\t            (\"a\", 4),\n\t            (\"b\", 5),\n", "            (\"c\", 3),\n\t            (\"d\", 8),\n\t            (\"e\", 1),\n\t        ]\n\t        with self.con:\n\t            self.con.execute(\"create table test(x, y)\")\n\t            self.con.executemany(\"insert into test values(?, ?)\", values)\n\t        self.expected = [\n\t            (\"a\", 9),\n\t            (\"b\", 12),\n", "            (\"c\", 16),\n\t            (\"d\", 12),\n\t            (\"e\", 9),\n\t        ]\n\t        self.query = \"\"\"\n\t            select x, %s(y) over (\n\t                order by x rows between 1 preceding and 1 following\n\t            ) as sum_y\n\t            from test order by x\n\t        \"\"\"\n", "        self.con.create_window_function(\"sumint\", 1, WindowSumInt)\n\t    def test_win_sum_int(self):\n\t        self.cur.execute(self.query % \"sumint\")\n\t        self.assertEqual(self.cur.fetchall(), self.expected)\n\t    def test_win_error_on_create(self):\n\t        self.assertRaises(sqlite.ProgrammingError,\n\t                          self.con.create_window_function,\n\t                          \"shouldfail\", -100, WindowSumInt)\n\t    @with_tracebacks(BadWindow)\n\t    def test_win_exception_in_method(self):\n", "        for meth in \"__init__\", \"step\", \"value\", \"inverse\":\n\t            with self.subTest(meth=meth):\n\t                with patch.object(WindowSumInt, meth, side_effect=BadWindow):\n\t                    name = f\"exc_{meth}\"\n\t                    self.con.create_window_function(name, 1, WindowSumInt)\n\t                    msg = f\"'{meth}' method raised error\"\n\t                    with self.assertRaisesRegex(sqlite.OperationalError, msg):\n\t                        self.cur.execute(self.query % name)\n\t                        self.cur.fetchall()\n\t    @with_tracebacks(BadWindow)\n", "    def test_win_exception_in_finalize(self):\n\t        # Note: SQLite does not (as of version 3.38.0) propagate finalize\n\t        # callback errors to sqlite3_step(); this implies that OperationalError\n\t        # is _not_ raised.\n\t        with patch.object(WindowSumInt, \"finalize\", side_effect=BadWindow):\n\t            name = f\"exception_in_finalize\"\n\t            self.con.create_window_function(name, 1, WindowSumInt)\n\t            self.cur.execute(self.query % name)\n\t            self.cur.fetchall()\n\t    @with_tracebacks(AttributeError)\n", "    def test_win_missing_method(self):\n\t        class MissingValue:\n\t            def step(self, x): pass\n\t            def inverse(self, x): pass\n\t            def finalize(self): return 42\n\t        class MissingInverse:\n\t            def step(self, x): pass\n\t            def value(self): return 42\n\t            def finalize(self): return 42\n\t        class MissingStep:\n", "            def value(self): return 42\n\t            def inverse(self, x): pass\n\t            def finalize(self): return 42\n\t        dataset = (\n\t            (\"step\", MissingStep),\n\t            (\"value\", MissingValue),\n\t            (\"inverse\", MissingInverse),\n\t        )\n\t        for meth, cls in dataset:\n\t            with self.subTest(meth=meth, cls=cls):\n", "                name = f\"exc_{meth}\"\n\t                self.con.create_window_function(name, 1, cls)\n\t                with self.assertRaisesRegex(sqlite.OperationalError,\n\t                                            f\"'{meth}' method not defined\"):\n\t                    self.cur.execute(self.query % name)\n\t                    self.cur.fetchall()\n\t    @with_tracebacks(AttributeError)\n\t    def test_win_missing_finalize(self):\n\t        # Note: SQLite does not (as of version 3.38.0) propagate finalize\n\t        # callback errors to sqlite3_step(); this implies that OperationalError\n", "        # is _not_ raised.\n\t        class MissingFinalize:\n\t            def step(self, x): pass\n\t            def value(self): return 42\n\t            def inverse(self, x): pass\n\t        name = \"missing_finalize\"\n\t        self.con.create_window_function(name, 1, MissingFinalize)\n\t        self.cur.execute(self.query % name)\n\t        self.cur.fetchall()\n\t    def test_win_clear_function(self):\n", "        self.con.create_window_function(\"sumint\", 1, None)\n\t        self.assertRaises(sqlite.OperationalError, self.cur.execute,\n\t                          self.query % \"sumint\")\n\t    def test_win_redefine_function(self):\n\t        # Redefine WindowSumInt; adjust the expected results accordingly.\n\t        class Redefined(WindowSumInt):\n\t            def step(self, value): self.count += value * 2\n\t            def inverse(self, value): self.count -= value * 2\n\t        expected = [(v[0], v[1]*2) for v in self.expected]\n\t        self.con.create_window_function(\"sumint\", 1, Redefined)\n", "        self.cur.execute(self.query % \"sumint\")\n\t        self.assertEqual(self.cur.fetchall(), expected)\n\t    def test_win_error_value_return(self):\n\t        class ErrorValueReturn:\n\t            def __init__(self): pass\n\t            def step(self, x): pass\n\t            def value(self): return 1 << 65\n\t        self.con.create_window_function(\"err_val_ret\", 1, ErrorValueReturn)\n\t        self.assertRaisesRegex(sqlite.DataError, \"string or blob too big\",\n\t                               self.cur.execute, self.query % \"err_val_ret\")\n", "@unittest.skip(\"Not supported\")\n\tclass AggregateTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        cur = self.con.cursor()\n\t        cur.execute(\"\"\"\n\t            create table test(\n\t                t text,\n\t                i integer,\n\t                f float,\n", "                n,\n\t                b blob\n\t                )\n\t            \"\"\")\n\t        cur.execute(\"insert into test(t, i, f, n, b) values (?, ?, ?, ?, ?)\",\n\t            (\"foo\", 5, 3.14, None, memoryview(b\"blob\"),))\n\t        self.con.create_aggregate(\"nostep\", 1, AggrNoStep)\n\t        self.con.create_aggregate(\"nofinalize\", 1, AggrNoFinalize)\n\t        self.con.create_aggregate(\"excInit\", 1, AggrExceptionInInit)\n\t        self.con.create_aggregate(\"excStep\", 1, AggrExceptionInStep)\n", "        self.con.create_aggregate(\"excFinalize\", 1, AggrExceptionInFinalize)\n\t        self.con.create_aggregate(\"checkType\", 2, AggrCheckType)\n\t        self.con.create_aggregate(\"checkTypes\", -1, AggrCheckTypes)\n\t        self.con.create_aggregate(\"mysum\", 1, AggrSum)\n\t        self.con.create_aggregate(\"aggtxt\", 1, AggrText)\n\t    def tearDown(self):\n\t        #self.cur.close()\n\t        #self.con.close()\n\t        pass\n\t    def test_aggr_error_on_create(self):\n", "        with self.assertRaises(sqlite.OperationalError):\n\t            self.con.create_function(\"bla\", -100, AggrSum)\n\t    @with_tracebacks(AttributeError, name=\"AggrNoStep\")\n\t    def test_aggr_no_step(self):\n\t        cur = self.con.cursor()\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            cur.execute(\"select nostep(t) from test\")\n\t        self.assertEqual(str(cm.exception),\n\t                         \"user-defined aggregate's 'step' method not defined\")\n\t    def test_aggr_no_finalize(self):\n", "        cur = self.con.cursor()\n\t        msg = \"user-defined aggregate's 'finalize' method not defined\"\n\t        with self.assertRaisesRegex(sqlite.OperationalError, msg):\n\t            cur.execute(\"select nofinalize(t) from test\")\n\t            val = cur.fetchone()[0]\n\t    @with_tracebacks(ZeroDivisionError, name=\"AggrExceptionInInit\")\n\t    def test_aggr_exception_in_init(self):\n\t        cur = self.con.cursor()\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            cur.execute(\"select excInit(t) from test\")\n", "            val = cur.fetchone()[0]\n\t        self.assertEqual(str(cm.exception), \"user-defined aggregate's '__init__' method raised error\")\n\t    @with_tracebacks(ZeroDivisionError, name=\"AggrExceptionInStep\")\n\t    def test_aggr_exception_in_step(self):\n\t        cur = self.con.cursor()\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            cur.execute(\"select excStep(t) from test\")\n\t            val = cur.fetchone()[0]\n\t        self.assertEqual(str(cm.exception), \"user-defined aggregate's 'step' method raised error\")\n\t    @with_tracebacks(ZeroDivisionError, name=\"AggrExceptionInFinalize\")\n", "    def test_aggr_exception_in_finalize(self):\n\t        cur = self.con.cursor()\n\t        with self.assertRaises(sqlite.OperationalError) as cm:\n\t            cur.execute(\"select excFinalize(t) from test\")\n\t            val = cur.fetchone()[0]\n\t        self.assertEqual(str(cm.exception), \"user-defined aggregate's 'finalize' method raised error\")\n\t    def test_aggr_check_param_str(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select checkTypes('str', ?, ?)\", (\"foo\", str()))\n\t        val = cur.fetchone()[0]\n", "        self.assertEqual(val, 2)\n\t    def test_aggr_check_param_int(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select checkType('int', ?)\", (42,))\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(val, 1)\n\t    def test_aggr_check_params_int(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select checkTypes('int', ?, ?)\", (42, 24))\n\t        val = cur.fetchone()[0]\n", "        self.assertEqual(val, 2)\n\t    def test_aggr_check_param_float(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select checkType('float', ?)\", (3.14,))\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(val, 1)\n\t    def test_aggr_check_param_none(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select checkType('None', ?)\", (None,))\n\t        val = cur.fetchone()[0]\n", "        self.assertEqual(val, 1)\n\t    def test_aggr_check_param_blob(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"select checkType('blob', ?)\", (memoryview(b\"blob\"),))\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(val, 1)\n\t    def test_aggr_check_aggr_sum(self):\n\t        cur = self.con.cursor()\n\t        cur.execute(\"delete from test\")\n\t        cur.executemany(\"insert into test(i) values (?)\", [(10,), (20,), (30,)])\n", "        cur.execute(\"select mysum(i) from test\")\n\t        val = cur.fetchone()[0]\n\t        self.assertEqual(val, 60)\n\t    def test_aggr_no_match(self):\n\t        cur = self.con.execute(\"select mysum(i) from (select 1 as i) where i == 0\")\n\t        val = cur.fetchone()[0]\n\t        self.assertIsNone(val)\n\t    def test_aggr_text(self):\n\t        cur = self.con.cursor()\n\t        for txt in [\"foo\", \"1\\x002\"]:\n", "            with self.subTest(txt=txt):\n\t                cur.execute(\"select aggtxt(?) from test\", (txt,))\n\t                val = cur.fetchone()[0]\n\t                self.assertEqual(val, txt)\n\t@unittest.skip(\"Not supported\")\n\tclass AuthorizerTests(unittest.TestCase):\n\t    @staticmethod\n\t    def authorizer_cb(action, arg1, arg2, dbname, source):\n\t        if action != sqlite.SQLITE_SELECT:\n\t            return sqlite.SQLITE_DENY\n", "        if arg2 == 'c2' or arg1 == 't2':\n\t            return sqlite.SQLITE_DENY\n\t        return sqlite.SQLITE_OK\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        self.con.executescript(\"\"\"\n\t            create table t1 (c1, c2);\n\t            create table t2 (c1, c2);\n\t            insert into t1 (c1, c2) values (1, 2);\n\t            insert into t2 (c1, c2) values (4, 5);\n", "            \"\"\")\n\t        # For our security test:\n\t        self.con.execute(\"select c2 from t2\")\n\t        self.con.set_authorizer(self.authorizer_cb)\n\t    def tearDown(self):\n\t        pass\n\t    def test_table_access(self):\n\t        with self.assertRaises(sqlite.DatabaseError) as cm:\n\t            self.con.execute(\"select * from t2\")\n\t        self.assertIn('prohibited', str(cm.exception))\n", "    def test_column_access(self):\n\t        with self.assertRaises(sqlite.DatabaseError) as cm:\n\t            self.con.execute(\"select c2 from t1\")\n\t        self.assertIn('prohibited', str(cm.exception))\n\t    def test_clear_authorizer(self):\n\t        self.con.set_authorizer(None)\n\t        self.con.execute(\"select * from t2\")\n\t        self.con.execute(\"select c2 from t1\")\n\tclass AuthorizerRaiseExceptionTests(AuthorizerTests):\n\t    @staticmethod\n", "    def authorizer_cb(action, arg1, arg2, dbname, source):\n\t        if action != sqlite.SQLITE_SELECT:\n\t            raise ValueError\n\t        if arg2 == 'c2' or arg1 == 't2':\n\t            raise ValueError\n\t        return sqlite.SQLITE_OK\n\t    @with_tracebacks(ValueError, name=\"authorizer_cb\")\n\t    def test_table_access(self):\n\t        super().test_table_access()\n\t    @with_tracebacks(ValueError, name=\"authorizer_cb\")\n", "    def test_column_access(self):\n\t        super().test_table_access()\n\tclass AuthorizerIllegalTypeTests(AuthorizerTests):\n\t    @staticmethod\n\t    def authorizer_cb(action, arg1, arg2, dbname, source):\n\t        if action != sqlite.SQLITE_SELECT:\n\t            return 0.0\n\t        if arg2 == 'c2' or arg1 == 't2':\n\t            return 0.0\n\t        return sqlite.SQLITE_OK\n", "class AuthorizerLargeIntegerTests(AuthorizerTests):\n\t    @staticmethod\n\t    def authorizer_cb(action, arg1, arg2, dbname, source):\n\t        if action != sqlite.SQLITE_SELECT:\n\t            return 2**32\n\t        if arg2 == 'c2' or arg1 == 't2':\n\t            return 2**32\n\t        return sqlite.SQLITE_OK\n\tif __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "tests/dbapi2/test_transactions.py", "chunked_list": ["# pysqlite2/test/transactions.py: tests transactions\n\t#\n\t# Copyright (C) 2005-2007 Gerhard Häring <gh@ghaering.de>\n\t#\n\t# This file is part of pysqlite.\n\t#\n\t# This software is provided 'as-is', without any express or implied\n\t# warranty.  In no event will the authors be held liable for any damages\n\t# arising from the use of this software.\n\t#\n", "# Permission is granted to anyone to use this software for any purpose,\n\t# including commercial applications, and to alter it and redistribute it\n\t# freely, subject to the following restrictions:\n\t#\n\t# 1. The origin of this software must not be misrepresented; you must not\n\t#    claim that you wrote the original software. If you use this software\n\t#    in a product, an acknowledgment in the product documentation would be\n\t#    appreciated but is not required.\n\t# 2. Altered source versions must be plainly marked as such, and must not be\n\t#    misrepresented as being the original software.\n", "# 3. This notice may not be removed or altered from any source distribution.\n\timport os, unittest\n\tfrom . import libsql_client_helpers as sqlite\n\tfrom test.support import LOOPBACK_TIMEOUT\n\tfrom test.support.os_helper import TESTFN, unlink\n\tfrom .test_dbapi import memory_database\n\tTIMEOUT = LOOPBACK_TIMEOUT / 10\n\tclass TransactionTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con1 = sqlite.connect(TESTFN, timeout=TIMEOUT)\n", "        self.cur1 = self.con1.cursor()\n\t        self.con2 = sqlite.connect(TESTFN, timeout=TIMEOUT)\n\t        self.cur2 = self.con2.cursor()\n\t    def tearDown(self):\n\t        try:\n\t            self.cur1.close()\n\t            self.con1.close()\n\t            self.cur2.close()\n\t            self.con2.close()\n\t        finally:\n", "            unlink(TESTFN)\n\t    def test_dml_does_not_auto_commit_before(self):\n\t        self.cur1.execute(\"create table test(i)\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        self.cur1.execute(\"create table test2(j)\")\n\t        self.cur2.execute(\"select i from test\")\n\t        res = self.cur2.fetchall()\n\t        self.assertEqual(len(res), 0)\n\t    def test_insert_starts_transaction(self):\n\t        self.cur1.execute(\"create table test(i)\")\n", "        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        self.cur2.execute(\"select i from test\")\n\t        res = self.cur2.fetchall()\n\t        self.assertEqual(len(res), 0)\n\t    def test_update_starts_transaction(self):\n\t        self.cur1.execute(\"create table test(i)\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        self.con1.commit()\n\t        self.cur1.execute(\"update test set i=6\")\n\t        self.cur2.execute(\"select i from test\")\n", "        res = self.cur2.fetchone()[0]\n\t        self.assertEqual(res, 5)\n\t    def test_delete_starts_transaction(self):\n\t        self.cur1.execute(\"create table test(i)\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        self.con1.commit()\n\t        self.cur1.execute(\"delete from test\")\n\t        self.cur2.execute(\"select i from test\")\n\t        res = self.cur2.fetchall()\n\t        self.assertEqual(len(res), 1)\n", "    def test_replace_starts_transaction(self):\n\t        self.cur1.execute(\"create table test(i)\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        self.con1.commit()\n\t        self.cur1.execute(\"replace into test(i) values (6)\")\n\t        self.cur2.execute(\"select i from test\")\n\t        res = self.cur2.fetchall()\n\t        self.assertEqual(len(res), 1)\n\t        self.assertEqual(res[0][0], 5)\n\t    def test_toggle_auto_commit(self):\n", "        self.cur1.execute(\"create table test(i)\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        self.con1.isolation_level = None\n\t        self.assertEqual(self.con1.isolation_level, None)\n\t        self.cur2.execute(\"select i from test\")\n\t        res = self.cur2.fetchall()\n\t        self.assertEqual(len(res), 1)\n\t        self.con1.isolation_level = \"DEFERRED\"\n\t        self.assertEqual(self.con1.isolation_level , \"DEFERRED\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n", "        self.cur2.execute(\"select i from test\")\n\t        res = self.cur2.fetchall()\n\t        self.assertEqual(len(res), 1)\n\t    def test_raise_timeout(self):\n\t        self.cur1.execute(\"create table test(i)\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.cur2.execute(\"insert into test(i) values (5)\")\n\t    def test_locking(self):\n\t        \"\"\"\n", "        This tests the improved concurrency with pysqlite 2.3.4. You needed\n\t        to roll back con2 before you could commit con1.\n\t        \"\"\"\n\t        self.cur1.execute(\"create table test(i)\")\n\t        self.cur1.execute(\"insert into test(i) values (5)\")\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.cur2.execute(\"insert into test(i) values (5)\")\n\t        # NO self.con2.rollback() HERE!!!\n\t        self.con1.commit()\n\t    def test_rollback_cursor_consistency(self):\n", "        \"\"\"Check that cursors behave correctly after rollback.\"\"\"\n\t        con = sqlite.connect(\":memory:\")\n\t        cur = con.cursor()\n\t        cur.execute(\"create table test(x)\")\n\t        cur.execute(\"insert into test(x) values (5)\")\n\t        cur.execute(\"select 1 union select 2 union select 3\")\n\t        con.rollback()\n\t        self.assertEqual(cur.fetchall(), [(1,), (2,), (3,)])\n\t    def test_multiple_cursors_and_iternext(self):\n\t        # gh-94028: statements are cleared and reset in cursor iternext.\n", "        # Provoke the gh-94028 by using a cursor cache.\n\t        CURSORS = {}\n\t        def sql(cx, sql, *args):\n\t            cu = cx.cursor()\n\t            cu.execute(sql, args)\n\t            CURSORS[id(sql)] = cu\n\t            return cu\n\t        self.con1.execute(\"create table t(t)\")\n\t        sql(self.con1, \"insert into t values (?), (?), (?)\", \"u1\", \"u2\", \"u3\")\n\t        self.con1.commit()\n", "        # On second connection, verify rows are visible, then delete them.\n\t        count = sql(self.con2, \"select count(*) from t\").fetchone()[0]\n\t        self.assertEqual(count, 3)\n\t        changes = sql(self.con2, \"delete from t\").rowcount\n\t        self.assertEqual(changes, 3)\n\t        self.con2.commit()\n\t        # Back in original connection, create 2 new users.\n\t        sql(self.con1, \"insert into t values (?)\", \"u4\")\n\t        sql(self.con1, \"insert into t values (?)\", \"u5\")\n\t        # The second connection cannot see uncommitted changes.\n", "        count = sql(self.con2, \"select count(*) from t\").fetchone()[0]\n\t        self.assertEqual(count, 0)\n\t        # First connection can see its own changes.\n\t        count = sql(self.con1, \"select count(*) from t\").fetchone()[0]\n\t        self.assertEqual(count, 2)\n\t        # The second connection can now see the changes.\n\t        self.con1.commit()\n\t        count = sql(self.con2, \"select count(*) from t\").fetchone()[0]\n\t        self.assertEqual(count, 2)\n\tclass RollbackTests(unittest.TestCase):\n", "    \"\"\"bpo-44092: sqlite3 now leaves it to SQLite to resolve rollback issues\"\"\"\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t        self.cur1 = self.con.cursor()\n\t        self.cur2 = self.con.cursor()\n\t        with self.con:\n\t            self.con.execute(\"create table t(c)\");\n\t            self.con.executemany(\"insert into t values(?)\", [(0,), (1,), (2,)])\n\t        self.cur1.execute(\"begin transaction\")\n\t        select = \"select c from t\"\n", "        self.cur1.execute(select)\n\t        self.con.rollback()\n\t        self.res = self.cur2.execute(select)  # Reusing stmt from cache\n\t    def tearDown(self):\n\t        self.con.close()\n\t    def _check_rows(self):\n\t        for i, row in enumerate(self.res):\n\t            self.assertEqual(row[0], i)\n\t    def test_no_duplicate_rows_after_rollback_del_cursor(self):\n\t        del self.cur1\n", "        self._check_rows()\n\t    def test_no_duplicate_rows_after_rollback_close_cursor(self):\n\t        self.cur1.close()\n\t        self._check_rows()\n\t    def test_no_duplicate_rows_after_rollback_new_query(self):\n\t        self.cur1.execute(\"select c from t where c = 1\")\n\t        self._check_rows()\n\tclass SpecialCommandTests(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n", "        self.cur = self.con.cursor()\n\t    def test_drop_table(self):\n\t        self.cur.execute(\"create table test(i)\")\n\t        self.cur.execute(\"insert into test(i) values (5)\")\n\t        self.cur.execute(\"drop table test\")\n\t    def test_pragma(self):\n\t        self.cur.execute(\"create table test(i)\")\n\t        self.cur.execute(\"insert into test(i) values (5)\")\n\t        self.cur.execute(\"pragma foreign_keys = ON\")\n\t    def tearDown(self):\n", "        self.cur.close()\n\t        self.con.close()\n\tclass TransactionalDDL(unittest.TestCase):\n\t    def setUp(self):\n\t        self.con = sqlite.connect(\":memory:\")\n\t    def test_ddl_does_not_autostart_transaction(self):\n\t        # For backwards compatibility reasons, DDL statements should not\n\t        # implicitly start a transaction.\n\t        self.con.execute(\"create table test(i)\")\n\t        self.con.rollback()\n", "        result = self.con.execute(\"select * from test\").fetchall()\n\t        self.assertEqual(result, [])\n\t    def test_immediate_transactional_ddl(self):\n\t        # You can achieve transactional DDL by issuing a BEGIN\n\t        # statement manually.\n\t        self.con.execute(\"begin immediate\")\n\t        self.con.execute(\"create table test(i)\")\n\t        self.con.rollback()\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.con.execute(\"select * from test\")\n", "    def test_transactional_ddl(self):\n\t        # You can achieve transactional DDL by issuing a BEGIN\n\t        # statement manually.\n\t        self.con.execute(\"begin\")\n\t        self.con.execute(\"create table test(i)\")\n\t        self.con.rollback()\n\t        with self.assertRaises(sqlite.OperationalError):\n\t            self.con.execute(\"select * from test\")\n\t    def tearDown(self):\n\t        self.con.close()\n", "class IsolationLevelFromInit(unittest.TestCase):\n\t    CREATE = \"create table t(t)\"\n\t    INSERT = \"insert into t values(1)\"\n\t    def setUp(self):\n\t        self.traced = []\n\t    def _run_test(self, cx):\n\t        cx.execute(self.CREATE)\n\t        cx.set_trace_callback(lambda stmt: self.traced.append(stmt))\n\t        with cx:\n\t            cx.execute(self.INSERT)\n", "    def test_isolation_level_default(self):\n\t        with memory_database() as cx:\n\t            self._run_test(cx)\n\t            self.assertEqual(self.traced, [\"BEGIN \", self.INSERT, \"COMMIT\"])\n\t    def test_isolation_level_begin(self):\n\t        with memory_database(isolation_level=\"\") as cx:\n\t            self._run_test(cx)\n\t            self.assertEqual(self.traced, [\"BEGIN \", self.INSERT, \"COMMIT\"])\n\t    def test_isolation_level_deferred(self):\n\t        with memory_database(isolation_level=\"DEFERRED\") as cx:\n", "            self._run_test(cx)\n\t            self.assertEqual(self.traced, [\"BEGIN DEFERRED\", self.INSERT, \"COMMIT\"])\n\t    def test_isolation_level_immediate(self):\n\t        with memory_database(isolation_level=\"IMMEDIATE\") as cx:\n\t            self._run_test(cx)\n\t            self.assertEqual(self.traced,\n\t                             [\"BEGIN IMMEDIATE\", self.INSERT, \"COMMIT\"])\n\t    def test_isolation_level_exclusive(self):\n\t        with memory_database(isolation_level=\"EXCLUSIVE\") as cx:\n\t            self._run_test(cx)\n", "            self.assertEqual(self.traced,\n\t                             [\"BEGIN EXCLUSIVE\", self.INSERT, \"COMMIT\"])\n\t    def test_isolation_level_none(self):\n\t        with memory_database(isolation_level=None) as cx:\n\t            self._run_test(cx)\n\t            self.assertEqual(self.traced, [self.INSERT])\n\tclass IsolationLevelPostInit(unittest.TestCase):\n\t    QUERY = \"insert into t values(1)\"\n\t    def setUp(self):\n\t        self.cx = sqlite.connect(\":memory:\")\n", "        self.cx.execute(\"create table t(t)\")\n\t        self.traced = []\n\t        self.cx.set_trace_callback(lambda stmt: self.traced.append(stmt))\n\t    def tearDown(self):\n\t        self.cx.close()\n\t    def test_isolation_level_default(self):\n\t        with self.cx:\n\t            self.cx.execute(self.QUERY)\n\t        self.assertEqual(self.traced, [\"BEGIN \", self.QUERY, \"COMMIT\"])\n\t    def test_isolation_level_begin(self):\n", "        self.cx.isolation_level = \"\"\n\t        with self.cx:\n\t            self.cx.execute(self.QUERY)\n\t        self.assertEqual(self.traced, [\"BEGIN \", self.QUERY, \"COMMIT\"])\n\t    def test_isolation_level_deferrred(self):\n\t        self.cx.isolation_level = \"DEFERRED\"\n\t        with self.cx:\n\t            self.cx.execute(self.QUERY)\n\t        self.assertEqual(self.traced, [\"BEGIN DEFERRED\", self.QUERY, \"COMMIT\"])\n\t    def test_isolation_level_immediate(self):\n", "        self.cx.isolation_level = \"IMMEDIATE\"\n\t        with self.cx:\n\t            self.cx.execute(self.QUERY)\n\t        self.assertEqual(self.traced,\n\t                         [\"BEGIN IMMEDIATE\", self.QUERY, \"COMMIT\"])\n\t    def test_isolation_level_exclusive(self):\n\t        self.cx.isolation_level = \"EXCLUSIVE\"\n\t        with self.cx:\n\t            self.cx.execute(self.QUERY)\n\t        self.assertEqual(self.traced,\n", "                         [\"BEGIN EXCLUSIVE\", self.QUERY, \"COMMIT\"])\n\t    def test_isolation_level_none(self):\n\t        self.cx.isolation_level = None\n\t        with self.cx:\n\t            self.cx.execute(self.QUERY)\n\t        self.assertEqual(self.traced, [self.QUERY])\n\tif __name__ == \"__main__\":\n\t    unittest.main()\n"]}
{"filename": "examples/dbapi2.py", "chunked_list": ["import datetime\n\timport logging\n\timport os\n\tfrom libsql_client import dbapi2\n\tdef show_rows(cursor, pfx=\"|\"):\n\t    table = []\n\t    table.append([repr(col[0]) for col in cursor.description])\n\t    sizes = [len(c) for c in table[0]]\n\t    for row in cursor:\n\t        r = [repr(cell) for cell in row]\n", "        table.append(r)\n\t        sizes = [max(prev, len(c)) for prev, c in zip(sizes, r)]\n\t    fmts = [\"%%-%ds\" % size for size in sizes]\n\t    for i, row in enumerate(table):\n\t        print(pfx + \" | \".join(fmt % value for fmt, value in zip(fmts, row)))\n\t        if i == 0:\n\t            print(pfx + \"-+-\".join(\"-\" * size for size in sizes))\n\t    print()\n\tdef main():\n\t    logging.basicConfig(level=os.getenv(\"LOG_LEVEL\", \"WARNING\"))\n", "    url = os.getenv(\"URL\", \"file:local.db\")\n\t    conn = dbapi2.connect(\n\t        url,\n\t        uri=True,\n\t        detect_types=dbapi2.PARSE_COLNAMES | dbapi2.PARSE_DECLTYPES,\n\t    )\n\t    conn.execute(\n\t        \"\"\"\n\t        CREATE TABLE IF NOT EXISTS users (\n\t            id INTEGER PRIMARY KEY,\n", "            email TEXT NOT NULL UNIQUE\n\t        )\n\t        \"\"\"\n\t    )\n\t    print(\"\\n# iterdump\")\n\t    for stmt in conn.iterdump():\n\t        print(f\"   {stmt}\")\n\t    print(\"\\n# execute\")\n\t    print(\"\\n>>> execute: no arguments, multiple values (rowcount)\")\n\t    cursor = conn.execute(\n", "        \"\"\"\n\t        INSERT INTO users (email) VALUES\n\t            ('alice@libsql.org'),\n\t            ('bob@example.com')\n\t        \"\"\"\n\t    )\n\t    print(f\"inserted rowid: {cursor.lastrowid}, affected: {cursor.rowcount}\")\n\t    print(\"\\n>>> execute: with positional arguments\")\n\t    cursor = conn.execute(\"INSERT INTO users (email) VALUES (?)\", (\"rob@other.com\",))\n\t    print(f\"inserted rowid: {cursor.lastrowid}, affected: {cursor.rowcount}\")\n", "    print(\"\\n>>> execute: with named arguments\")\n\t    cursor = conn.execute(\n\t        \"INSERT INTO users (email) VALUES (@email)\",\n\t        {\"email\": \"sql@other.com\"},\n\t    )\n\t    print(f\"inserted rowid: {cursor.lastrowid}, affected: {cursor.rowcount}\")\n\t    print(\"\\n# executemany\")\n\t    print(\"\\n>>> executemany: with positional arguments\")\n\t    cursor = conn.executemany(\n\t        \"INSERT INTO users (email) VALUES (?)\",\n", "        (\n\t            (\"sql2@sql.com\",),\n\t            (\"sql3@sql.com\",),\n\t        ),\n\t    )\n\t    print(f\"inserted rowid: {cursor.lastrowid}, affected: {cursor.rowcount}\")\n\t    print(\"\\n# executescript\")\n\t    conn.executescript(\n\t        \"\"\"\n\t        INSERT INTO users (email) VALUES ('script1@server.com');\n", "        INSERT INTO users (email) VALUES ('script2@server.com');\n\t        INSERT INTO users (email) VALUES ('script3@server.com');\n\t        \"\"\",\n\t    )\n\t    print(\"\\n# transactions\")\n\t    try:\n\t        with conn as cursor:\n\t            cursor.execute(\"BEGIN\")\n\t            cursor.execute(\"INSERT INTO users (email) VALUES ('bug!')\")\n\t            cursor.execute(\"INSERT INTO users (email) VALUES ('bug!')\")\n", "    except dbapi2.IntegrityError as e:\n\t        print(\"Got expected exception, should rollback transaction:\", e)\n\t    print(\"\\n# fetching: rows and description\")\n\t    cursor = conn.execute(\"SELECT * from users\")\n\t    show_rows(cursor)\n\t    # example based on:\n\t    # https://docs.python.org/3/library/sqlite3.html#default-adapters-and-converters\n\t    print(\"\\n# Type converters:\")\n\t    cursor.execute(\"create table test(d date, ts timestamp)\")\n\t    today = datetime.date.today()\n", "    now = datetime.datetime.now()\n\t    print(\"\\n>>> based on column decltype:\")\n\t    cursor.execute(\"insert into test(d, ts) values (?, ?)\", (today, now))\n\t    cursor.execute(\"select d, ts from test\")\n\t    show_rows(cursor)\n\t    conn.execute(\"DROP TABLE test\")\n\t    print(\"\\n>>> based on column names: 'd [date]', 'ts [timestamp]'\")\n\t    cursor.execute(\n\t        \"\"\"\n\t        select current_date as \"d [date]\",\n", "        current_timestamp as \"ts [timestamp]\"\n\t    \"\"\"\n\t    )\n\t    show_rows(cursor)\n\t    # https://docs.python.org/3/library/sqlite3.html#how-to-convert-sqlite-values-to-custom-python-types\n\t    class Point:\n\t        def __init__(self, x, y):\n\t            self.x, self.y = x, y\n\t        def __repr__(self):\n\t            return f\"Point({self.x}, {self.y})\"\n", "    def adapt_point(point):\n\t        return f\"{point.x};{point.y}\"\n\t    def convert_point(s):\n\t        x, y = list(map(float, s.split(b\";\")))\n\t        return Point(x, y)\n\t    # Register the adapter and converter\n\t    dbapi2.register_adapter(Point, adapt_point)\n\t    dbapi2.register_converter(\"point\", convert_point)\n\t    p = Point(4.0, -3.2)\n\t    cur = conn.execute(\"CREATE TABLE test(p point)\")\n", "    print(\"\\n>>> inserting custom type: Point\")\n\t    cur.execute(\"INSERT INTO test(p) VALUES(?)\", (p,))\n\t    cur.execute(\"SELECT p FROM test\")\n\t    show_rows(cur)\n\t    conn.execute(\"DROP TABLE test\")\n\t    cur = conn.execute(\"CREATE TABLE test(p)\")\n\t    cur.execute(\"INSERT INTO test(p) VALUES(?)\", (p,))\n\t    cur.execute('SELECT p AS \"p [point]\" FROM test')\n\t    show_rows(cur)\n\t    conn.execute(\"DROP TABLE test\")\n", "    conn.close()\n\tmain()\n"]}
{"filename": "examples/books.py", "chunked_list": ["import asyncio\n\timport os\n\timport random\n\timport libsql_client\n\tasync def main():\n\t    url = os.getenv(\"URL\", \"file:local.db\")\n\t    async with libsql_client.create_client(url) as client:\n\t        await client.batch(\n\t            [\n\t                \"\"\"\n", "            CREATE TABLE IF NOT EXISTS book (\n\t                id INTEGER PRIMARY KEY,\n\t                title TEXT NOT NULL,\n\t                author_id INTEGER NOT NULL\n\t            )\n\t            \"\"\",\n\t                \"\"\"\n\t            CREATE TABLE IF NOT EXISTS author (\n\t                id INTEGER PRIMARY KEY,\n\t                name TEXT NOT NULL\n", "            )\n\t            \"\"\",\n\t            ]\n\t        )\n\t        author_res = await client.execute(\n\t            \"INSERT INTO author (name) VALUES (?) RETURNING id\",\n\t            [sample_name(AUTHOR_NAME_PARTS)],\n\t        )\n\t        author_id = author_res.rows[0][0]\n\t        book_count = random.randint(1, 3)\n", "        for _ in range(book_count):\n\t            await client.execute(\n\t                \"INSERT INTO book (title, author_id) VALUES (?, ?)\",\n\t                [sample_name(BOOK_TITLE_PARTS), author_id],\n\t            )\n\t        books_res = await client.execute(\n\t            \"\"\"\n\t            SELECT b.id, b.title, a.id, a.name\n\t            FROM book b JOIN author a ON b.author_id = a.id\n\t            ORDER BY b.id ASC\n", "            \"\"\"\n\t        )\n\t        for row in books_res.rows:\n\t            print(row)\n\tdef sample_name(name_parts):\n\t    return \" \".join([random.choice(parts) for parts in name_parts])\n\tAUTHOR_NAME_PARTS = [\n\t    [\"Daniel\", \"Jane\", \"Mark\", \"William\", \"Milan\", \"Kazuo\", \"Sally\", \"Mieko\", \"Kim\"],\n\t    [\n\t        \"Defoe\",\n", "        \"Austen\",\n\t        \"Twain\",\n\t        \"Golding\",\n\t        \"Kundera\",\n\t        \"Ishiguro\",\n\t        \"Rooney\",\n\t        \"Kawakami\",\n\t        \"Hye-Jin\",\n\t    ],\n\t]\n", "BOOK_TITLE_PARTS = [\n\t    [\n\t        \"Robinson\",\n\t        \"Pride\",\n\t        \"Sense\",\n\t        \"Huckleberry\",\n\t        \"Tom\",\n\t        \"Lord\",\n\t        \"Život\",\n\t        \"Klara\",\n", "        \"Normal\",\n\t        \"Breasts\",\n\t        \"Concerning\",\n\t    ],\n\t    [\n\t        \"Crusoe\",\n\t        \"and Prejudice\",\n\t        \"and Sensibility\",\n\t        \"Finn\",\n\t        \"Sawyer\",\n", "        \"of the Flies\",\n\t        \"je jinde\",\n\t        \"and The Sun\",\n\t        \"People\",\n\t        \"and Eggs\",\n\t        \"My Daughter\",\n\t    ],\n\t]\n\tasyncio.run(main())\n"]}
{"filename": "examples/readme.py", "chunked_list": ["import asyncio\n\timport os\n\timport libsql_client\n\tasync def main():\n\t    url = os.getenv(\"URL\", \"file:local.db\")\n\t    async with libsql_client.create_client(url) as client:\n\t        await client.batch(\n\t            [\n\t                \"\"\"\n\t            CREATE TABLE IF NOT EXISTS users (\n", "                id INTEGER PRIMARY KEY,\n\t                email TEXT NOT NULL\n\t            )\n\t            \"\"\",\n\t                \"\"\"\n\t            INSERT INTO users (email) VALUES\n\t                ('alice@libsql.org'),\n\t                ('bob@example.com')\n\t            \"\"\",\n\t            ]\n", "        )\n\t        result_set = await client.execute(\"SELECT * from users\")\n\t        print(len(result_set.rows), \"rows\")\n\t        for row in result_set.rows:\n\t            print(row)\n\tasyncio.run(main())\n"]}
{"filename": "libsql_client/config.py", "chunked_list": ["from __future__ import annotations\n\tfrom typing import NamedTuple\n\tfrom typing import Optional\n\timport urllib.parse\n\tfrom .client import LibsqlError\n\tclass _Config(NamedTuple):\n\t    scheme: str\n\t    authority: str\n\t    path: str\n\t    auth_token: Optional[str]\n", "    tls: bool\n\tdef _expand_config(\n\t    url: str, *, auth_token: Optional[str], tls: Optional[bool]\n\t) -> _Config:\n\t    url_parsed = urllib.parse.urlparse(url)\n\t    scheme = url_parsed.scheme\n\t    authority = url_parsed.netloc\n\t    path = url_parsed.path\n\t    qsl = urllib.parse.parse_qsl(url_parsed.query, keep_blank_values=True)\n\t    for key, value in qsl:\n", "        if key == \"authToken\":\n\t            auth_token = value or None\n\t        elif key == \"tls\":\n\t            if value == \"0\":\n\t                tls = False\n\t            elif value == \"1\":\n\t                tls = True\n\t            else:\n\t                raise LibsqlError(\n\t                    f\"Unknown value for the 'tls' query argument: {value!r}. \"\n", "                    \"Supported values are '0' and '1'\",\n\t                    \"URL_INVALID\",\n\t                )\n\t        else:\n\t            raise LibsqlError(\n\t                f\"Unknown URL query parameter {key!r}\", \"URL_PARAM_NOT_SUPPORTED\"\n\t            )\n\t    if scheme == \"libsql\":\n\t        if tls is False:\n\t            if url_parsed.port is None:\n", "                raise LibsqlError(\n\t                    \"A 'libsql:' URL with ?tls=0 must specify an explicit port\",\n\t                    \"URL_INVALID\",\n\t                )\n\t            scheme = \"ws\"\n\t        else:\n\t            scheme = \"wss\"\n\t    elif scheme in (\"http\", \"ws\") and tls is None:\n\t        tls = False\n\t    if tls is None:\n", "        tls = True\n\t    if url_parsed.params:\n\t        raise LibsqlError(\n\t            f\"Unsupported URL parameter: {url_parsed.params!r}\", \"URL_INVALID\"\n\t        )\n\t    if url_parsed.fragment:\n\t        raise LibsqlError(\n\t            f\"Unsupported URL fragment: {url_parsed.fragment!r}\", \"URL_INVALID\"\n\t        )\n\t    return _Config(scheme, authority, path, auth_token, tls)\n"]}
{"filename": "libsql_client/client.py", "chunked_list": ["from __future__ import annotations\n\tfrom abc import ABC\n\tfrom abc import abstractmethod\n\tfrom datetime import datetime\n\tfrom typing import Any\n\tfrom typing import Dict\n\tfrom typing import List\n\tfrom typing import Tuple\n\tfrom typing import TYPE_CHECKING\n\tfrom typing import TypeVar\n", "from typing import Union\n\tfrom .result import ResultSet\n\tfrom .result import Value\n\tif TYPE_CHECKING:\n\t    from _typeshed import ReadableBuffer\n\telse:\n\t    ReadableBuffer = bytes\n\tInValue = Union[Value, bool, datetime, ReadableBuffer]\n\tInArgs = Union[List[InValue], Tuple[InValue, ...], Dict[str, InValue], None]\n\tInStatement = Union[\"Statement\", str, Tuple[str], Tuple[str, InArgs]]\n", "class Statement:\n\t    sql: str\n\t    args: InArgs\n\t    def __init__(self, sql: str, args: InArgs = None):\n\t        self.sql = sql\n\t        self.args = args\n\t    @staticmethod\n\t    def convert(stmt: InStatement, args: InArgs = None) -> Statement:\n\t        if isinstance(stmt, tuple):\n\t            if len(stmt) == 1:\n", "                return Statement(stmt[0], args)\n\t            if len(stmt) > 2:\n\t                raise TypeError(\n\t                    \"Statement must be a 1-tuple or 2-tuple, \"\n\t                    f\"but got a {len(stmt)}-tuple\"\n\t                )\n\t            if args:\n\t                raise TypeError(\n\t                    \"Cannot pass additional args to a statement passed as tuple\"\n\t                )\n", "            return Statement(stmt[0], stmt[1])  # type: ignore[misc]\n\t        if isinstance(stmt, Statement):\n\t            if args:\n\t                raise TypeError(\"Cannot pass additional args to a Statement instance\")\n\t            return stmt\n\t        return Statement(stmt, args)\n\tclass LibsqlError(RuntimeError):\n\t    code: str\n\t    explanation: str\n\t    def __init__(self, message: str, code: str):\n", "        super(RuntimeError, self).__init__(f\"{code}: {message}\")\n\t        self.code = code\n\t        self.explanation = message\n\tTClient = TypeVar(\"TClient\", bound=\"Client\")\n\tclass Client(ABC):\n\t    @abstractmethod\n\t    async def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        pass\n\t    @abstractmethod\n\t    async def batch(self, stmts: List[InStatement]) -> List[ResultSet]:\n", "        pass\n\t    @abstractmethod\n\t    def transaction(self) -> Transaction:\n\t        pass\n\t    @abstractmethod\n\t    async def close(self) -> None:\n\t        pass\n\t    @property\n\t    @abstractmethod\n\t    def closed(self) -> bool:\n", "        pass\n\t    async def __aenter__(self: TClient) -> TClient:\n\t        return self\n\t    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:\n\t        await self.close()\n\tTTransaction = TypeVar(\"TTransaction\", bound=\"Transaction\")\n\tclass Transaction(ABC):\n\t    @abstractmethod\n\t    async def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        ...\n", "    @abstractmethod\n\t    async def rollback(self) -> None:\n\t        ...\n\t    @abstractmethod\n\t    async def commit(self) -> None:\n\t        ...\n\t    @abstractmethod\n\t    def close(self) -> None:\n\t        ...\n\t    @property\n", "    @abstractmethod\n\t    def closed(self) -> bool:\n\t        ...\n\t    def __enter__(self: TTransaction) -> TTransaction:\n\t        return self\n\t    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:\n\t        self.close()\n\tdef _normalize_value(in_value: InValue) -> Value:\n\t    if isinstance(in_value, datetime):\n\t        return int(in_value.timestamp() * 1000)\n", "    elif isinstance(in_value, bool):\n\t        return int(in_value)\n\t    elif isinstance(in_value, (str, int, float)) or in_value is None:\n\t        return in_value\n\t    return bytes(memoryview(in_value))\n"]}
{"filename": "libsql_client/__init__.py", "chunked_list": ["from .client import Client\n\tfrom .client import InArgs\n\tfrom .client import InStatement\n\tfrom .client import InValue\n\tfrom .client import LibsqlError\n\tfrom .client import Statement\n\tfrom .client import Transaction\n\tfrom .create_client import create_client\n\tfrom .result import ResultSet\n\tfrom .result import Row\n", "from .result import Value\n\tfrom .sync import ClientSync\n\tfrom .sync import create_client_sync\n\tfrom .sync import TransactionSync\n"]}
{"filename": "libsql_client/result.py", "chunked_list": ["from __future__ import annotations\n\tfrom collections.abc import Sequence\n\tfrom typing import Dict\n\tfrom typing import Iterator\n\tfrom typing import List\n\tfrom typing import Optional\n\tfrom typing import overload\n\tfrom typing import Tuple\n\tfrom typing import Union\n\tValue = Union[None, str, int, float, bytes]\n", "class ResultSet:\n\t    \"\"\"Result of an SQL statement.\n\t    The result is composed of columns and rows.\n\t    Every row is represented as a `Row` object and the length of\n\t    every row is equal to the number of columns.\n\t    \"\"\"\n\t    _columns: Tuple[str, ...]\n\t    _rows: List[Row]\n\t    _rows_affected: int\n\t    _last_insert_rowid: Optional[int]\n", "    __slots__ = [\"_columns\", \"_rows\", \"_rows_affected\", \"_last_insert_rowid\"]\n\t    def __init__(\n\t        self,\n\t        columns: Tuple[str, ...],\n\t        rows: List[\"Row\"],\n\t        rows_affected: int,\n\t        last_insert_rowid: Optional[int],\n\t    ):\n\t        self._columns = columns\n\t        self._rows = rows\n", "        self._rows_affected = rows_affected\n\t        self._last_insert_rowid = last_insert_rowid\n\t    def __iter__(self) -> Iterator[\"Row\"]:\n\t        return self._rows.__iter__()\n\t    def __len__(self) -> int:\n\t        return len(self._rows)\n\t    @overload\n\t    def __getitem__(self, key: int) -> Row:\n\t        pass\n\t    @overload\n", "    def __getitem__(self, key: slice) -> List[Row]:\n\t        pass\n\t    def __getitem__(self, key: Union[int, slice]) -> Union[Row, List[Row]]:\n\t        return self._rows[key]\n\t    @property\n\t    def columns(self) -> Tuple[str, ...]:\n\t        return self._columns\n\t    @property\n\t    def rows(self) -> List[Row]:\n\t        return self._rows\n", "    @property\n\t    def rows_affected(self) -> int:\n\t        return self._rows_affected\n\t    @property\n\t    def last_insert_rowid(self) -> Optional[int]:\n\t        return self._last_insert_rowid\n\tclass Row(Sequence):\n\t    \"\"\"A row returned by an SQL statement.\n\t    The row values can be accessed with an index or by name.\n\t    \"\"\"\n", "    _column_idxs: Dict[str, int]\n\t    _values: Tuple[Value, ...]\n\t    __slots__ = [\"_column_idxs\", \"_values\"]\n\t    def __init__(self, column_idxs: Dict[str, int], values: Tuple[Value, ...]) -> None:\n\t        self._column_idxs = column_idxs\n\t        self._values = values\n\t    @overload\n\t    def __getitem__(self, key: int) -> Value:\n\t        pass\n\t    @overload\n", "    def __getitem__(self, key: str) -> Value:\n\t        pass\n\t    @overload\n\t    def __getitem__(self, key: slice) -> Tuple[Value, ...]:\n\t        pass\n\t    def __getitem__(\n\t        self, key: Union[int, str, slice]\n\t    ) -> Union[Value, Tuple[Value, ...]]:\n\t        \"\"\"Access a value by index or by name.\"\"\"\n\t        tuple_key: Union[int, slice]\n", "        if isinstance(key, str):\n\t            tuple_key = self._column_idxs[key]\n\t        else:\n\t            tuple_key = key\n\t        return self._values[tuple_key]\n\t    def __len__(self) -> int:\n\t        return len(self._values)\n\t    def __repr__(self) -> str:\n\t        return repr(self._values)\n\t    def astuple(self) -> Tuple[Value, ...]:\n", "        return self._values\n\t    def asdict(self) -> Dict[str, Value]:\n\t        return {key: self._values[idx] for key, idx in self._column_idxs.items()}\n\t    _asdict = asdict\n\t    @property\n\t    def _fields(self) -> Tuple[str, ...]:\n\t        return tuple(self._column_idxs.keys())\n"]}
{"filename": "libsql_client/http.py", "chunked_list": ["from __future__ import annotations\n\tfrom typing import Any\n\tfrom typing import cast\n\tfrom typing import List\n\tfrom typing import Optional\n\timport urllib.parse\n\timport aiohttp\n\tfrom typing_extensions import TypedDict\n\tfrom .client import Client\n\tfrom .client import InArgs\n", "from .client import InStatement\n\tfrom .client import LibsqlError\n\tfrom .client import Transaction\n\tfrom .config import _Config\n\tfrom .hrana import proto\n\tfrom .hrana.convert import _batch_results_from_proto\n\tfrom .hrana.convert import _batch_to_proto\n\tfrom .hrana.convert import _result_set_from_proto\n\tfrom .hrana.convert import _stmt_to_proto\n\tfrom .result import ResultSet\n", "def _create_http_client(config: _Config) -> HttpClient:\n\t    assert config.scheme in (\"http\", \"https\")\n\t    if config.scheme == \"http\" and config.tls:\n\t        raise LibsqlError(\n\t            \"A 'http:' URL cannot opt into TLS by using ?tls=1\", \"URL_INVALID\"\n\t        )\n\t    elif config.scheme == \"https\" and not config.tls:\n\t        raise LibsqlError(\n\t            \"A 'https:' URL cannot opt out of TLS by using ?tls=0\", \"URL_INVALID\"\n\t        )\n", "    url = urllib.parse.urlunparse(\n\t        (\n\t            config.scheme,\n\t            config.authority,\n\t            config.path,\n\t            \"\",\n\t            \"\",\n\t            \"\",\n\t        )\n\t    )\n", "    return HttpClient(url, auth_token=config.auth_token)\n\tclass HttpClient(Client):\n\t    _session: aiohttp.ClientSession\n\t    _url: str\n\t    def __init__(self, url: str, *, auth_token: Optional[str] = None):\n\t        headers = {\"authorization\": f\"Bearer {auth_token}\"}\n\t        self._session = aiohttp.ClientSession(headers=headers)\n\t        self._url = url\n\t    async def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        request: _ExecuteReq = {\n", "            \"stmt\": _stmt_to_proto(stmt, args),\n\t        }\n\t        response = await self._send(\"POST\", \"v1/execute\", request)\n\t        proto_res = cast(_ExecuteResp, response)[\"result\"]\n\t        return _result_set_from_proto(proto_res)\n\t    async def sequence(self, stmt: str) -> None:\n\t        raise LibsqlError(\n\t            \"The HTTP client does not support sequence.\",\n\t            \"SEQUENCE_NOT_SUPPORTED\",\n\t        )\n", "    async def batch(self, stmts: List[InStatement]) -> List[ResultSet]:\n\t        request: _BatchReq = {\n\t            \"batch\": _batch_to_proto(stmts),\n\t        }\n\t        response = await self._send(\"POST\", \"v1/batch\", request)\n\t        proto_res = cast(_BatchResp, response)[\"result\"]\n\t        return _batch_results_from_proto(proto_res, len(stmts))\n\t    def transaction(self) -> Transaction:\n\t        raise LibsqlError(\n\t            \"The HTTP client does not support transactions. \"\n", "            \"Please use a libsql:, ws: or wss: URL, so that the client \"\n\t            \"connects using a WebSocket.\",\n\t            \"TRANSACTIONS_NOT_SUPPORTED\",\n\t        )\n\t    async def close(self) -> None:\n\t        await self._session.close()\n\t    @property\n\t    def closed(self) -> bool:\n\t        return self._session.closed\n\t    async def _send(self, method: str, path: str, request_body: Any) -> Any:\n", "        url = urllib.parse.urljoin(self._url, path)\n\t        async with self._session.request(method, url, json=request_body) as resp:\n\t            if not resp.ok:\n\t                if resp.content_type == \"application/json\":\n\t                    resp_json = await resp.json()\n\t                    if \"message\" in resp_json:\n\t                        message = resp_json[\"message\"]\n\t                        code = resp_json.get(\"code\") or \"UNKNOWN\"\n\t                        raise LibsqlError(message, code)\n\t                elif resp.content_type == \"text/plain\":\n", "                    resp_text = await resp.text()\n\t                    raise LibsqlError(\n\t                        \"Server returned HTTP status \"\n\t                        f\"{resp.status} and error: {resp_text!r}\",\n\t                        \"SERVER_ERROR\",\n\t                    )\n\t                raise LibsqlError(\n\t                    f\"Server returned HTTP status {resp.status}\", \"SERVER_ERROR\"\n\t                )\n\t            return await resp.json()\n", "_ExecuteReq = TypedDict(\n\t    \"_ExecuteReq\",\n\t    {\n\t        \"stmt\": proto.Stmt,\n\t    },\n\t)\n\t_ExecuteResp = TypedDict(\n\t    \"_ExecuteResp\",\n\t    {\n\t        \"result\": proto.StmtResult,\n", "    },\n\t)\n\t_BatchReq = TypedDict(\n\t    \"_BatchReq\",\n\t    {\n\t        \"batch\": proto.Batch,\n\t    },\n\t)\n\t_BatchResp = TypedDict(\n\t    \"_BatchResp\",\n", "    {\n\t        \"result\": proto.BatchResult,\n\t    },\n\t)\n"]}
{"filename": "libsql_client/create_client.py", "chunked_list": ["from __future__ import annotations\n\tfrom typing import Optional\n\tfrom .client import Client\n\tfrom .client import LibsqlError\n\tfrom .config import _expand_config\n\tfrom .hrana import _create_hrana_client\n\tfrom .http import _create_http_client\n\tfrom .sqlite3 import _create_sqlite3_client\n\tdef create_client(\n\t    url: str, *, auth_token: Optional[str] = None, tls: Optional[bool] = None\n", ") -> Client:\n\t    config = _expand_config(url, auth_token=auth_token, tls=tls)\n\t    if config.scheme == \"file\":\n\t        return _create_sqlite3_client(config)\n\t    elif config.scheme in (\"ws\", \"wss\"):\n\t        return _create_hrana_client(config)\n\t    elif config.scheme in (\"http\", \"https\"):\n\t        return _create_http_client(config)\n\t    else:\n\t        raise LibsqlError(\n", "            f\"Unsupported URL scheme {config.scheme!r}\", \"URL_SCHEME_NOT_SUPPORTED\"\n\t        )\n"]}
{"filename": "libsql_client/sqlite3.py", "chunked_list": ["from __future__ import annotations\n\timport math\n\timport sqlite3\n\tfrom typing import Any\n\tfrom typing import cast\n\tfrom typing import List\n\tfrom typing import Optional\n\tfrom .client import _normalize_value\n\tfrom .client import Client\n\tfrom .client import InArgs\n", "from .client import InStatement\n\tfrom .client import InValue\n\tfrom .client import LibsqlError\n\tfrom .client import Statement\n\tfrom .client import Transaction\n\tfrom .config import _Config\n\tfrom .result import ResultSet\n\tfrom .result import Row\n\tdef _create_sqlite3_client(config: _Config) -> Sqlite3Client:\n\t    assert config.scheme == \"file\"\n", "    if config.authority not in (\"\", \"localhost\"):\n\t        raise LibsqlError(\n\t            f\"Invalid authority in file URL: {config.authority!r}\", \"URL_INVALID\"\n\t        )\n\t    client = Sqlite3Client(config.path)\n\t    db = client._connect()\n\t    try:\n\t        _execute_stmt(db, \"SELECT 1 AS check_that_the_database_can_be_opened\")\n\t    finally:\n\t        db.close()\n", "    return client\n\tclass Sqlite3Client(Client):\n\t    _path: str\n\t    _closed: bool\n\t    def __init__(self, path: str):\n\t        self._path = path\n\t        self._closed = False\n\t    async def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        db = self._connect()\n\t        try:\n", "            return _execute_stmt(db, stmt, args)\n\t        finally:\n\t            db.close()\n\t    async def batch(self, stmts: List[InStatement]) -> List[ResultSet]:\n\t        db = self._connect()\n\t        try:\n\t            _execute_stmt(db, \"BEGIN\")\n\t            result_sets = []\n\t            for stmt in stmts:\n\t                result_set = _execute_stmt(db, stmt)\n", "                result_sets.append(result_set)\n\t            _execute_stmt(db, \"COMMIT\")\n\t            return result_sets\n\t        finally:\n\t            db.close()\n\t    def transaction(self) -> Sqlite3Transaction:\n\t        db = self._connect()\n\t        try:\n\t            _execute_stmt(db, \"BEGIN\")\n\t            return Sqlite3Transaction(db)\n", "        except Exception:\n\t            db.close()\n\t            raise\n\t    async def close(self) -> None:\n\t        self._closed = True\n\t    @property\n\t    def closed(self) -> bool:\n\t        return self._closed\n\t    def _connect(self) -> sqlite3.Connection:\n\t        if self._closed:\n", "            raise LibsqlError(\"The client was closed\", \"CLIENT_CLOSED\")\n\t        return sqlite3.connect(\n\t            self._path,\n\t            isolation_level=None,\n\t            check_same_thread=False,\n\t            timeout=0,\n\t        )\n\tclass Sqlite3Transaction(Transaction):\n\t    database: Optional[sqlite3.Connection]\n\t    def __init__(self, database: sqlite3.Connection):\n", "        self.database = database\n\t    async def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        db = self._connection()\n\t        return _execute_stmt(db, stmt, args)\n\t    async def rollback(self) -> None:\n\t        if self.database is None:\n\t            return\n\t        _execute_stmt(self.database, \"ROLLBACK\")\n\t        self.close()\n\t    async def commit(self) -> None:\n", "        db = self._connection()\n\t        _execute_stmt(db, \"COMMIT\")\n\t        self.close()\n\t    def close(self) -> None:\n\t        db, self.database = self.database, None\n\t        if db is not None:\n\t            db.close()\n\t    @property\n\t    def closed(self) -> bool:\n\t        return self.database is None\n", "    def _connection(self) -> sqlite3.Connection:\n\t        if self.database is None:\n\t            raise LibsqlError(\"The transaction was closed\", \"TRANSACTION_CLOSED\")\n\t        return self.database\n\tdef _execute_stmt(\n\t    db: sqlite3.Connection, in_stmt: InStatement, in_args: InArgs = None\n\t) -> ResultSet:\n\t    stmt = Statement.convert(in_stmt, in_args)\n\t    sql_args: Any\n\t    if stmt.args is None:\n", "        sql_args = ()\n\t    elif isinstance(stmt.args, dict):\n\t        sql_args = {\n\t            _strip_arg_name(key): _value_to_sql(value)\n\t            for key, value in stmt.args.items()\n\t        }\n\t    else:\n\t        sql_args = [_value_to_sql(value) for value in stmt.args]\n\t    cursor = None\n\t    try:\n", "        cursor = db.execute(stmt.sql, sql_args)\n\t        sql_rows = cursor.fetchall()\n\t    except sqlite3.Error as e:\n\t        if cursor is not None:\n\t            cursor.close()\n\t        if hasattr(e, \"sqlite_errorname\"):\n\t            code = e.sqlite_errorname\n\t        else:\n\t            code = \"SQLITE\"\n\t        raise LibsqlError(str(e), code) from e\n", "    try:\n\t        columns = tuple(cast(str, desc[0]) for desc in cursor.description or ())\n\t        column_idxs = {column: idx for idx, column in enumerate(columns)}\n\t        rows = [Row(column_idxs, sql_row) for sql_row in sql_rows]\n\t        rows_affected = cursor.rowcount\n\t        last_insert_rowid = cursor.lastrowid\n\t        return ResultSet(columns, rows, rows_affected, last_insert_rowid)\n\t    finally:\n\t        cursor.close()\n\tdef _strip_arg_name(name: str) -> str:\n", "    if len(name) >= 1 and name[0] in (\":\", \"$\", \"@\"):\n\t        return name[1:]\n\t    return name\n\tdef _value_to_sql(value: InValue) -> Any:\n\t    if isinstance(value, float) and not math.isfinite(value):\n\t        raise ValueError(\"Only finite floats (not Infinity or NaN) are supported\")\n\t    return _normalize_value(value)\n"]}
{"filename": "libsql_client/sync.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport collections\n\timport concurrent\n\tfrom dataclasses import dataclass\n\timport threading\n\tfrom typing import Any\n\tfrom typing import Callable\n\tfrom typing import Coroutine\n\tfrom typing import Deque\n", "from typing import List\n\tfrom typing import Optional\n\tfrom typing import TypeVar\n\tfrom .client import Client\n\tfrom .client import InArgs\n\tfrom .client import InStatement\n\tfrom .client import LibsqlError\n\tfrom .client import Transaction\n\tfrom .create_client import create_client\n\tfrom .result import ResultSet\n", "T = TypeVar(\"T\")\n\tdef create_client_sync(*args: Any, **kwargs: Any) -> ClientSync:\n\t    executor = _AsyncExecutor()\n\t    try:\n\t        client: Client = executor.submit_func(lambda: create_client(*args, **kwargs))\n\t        return ClientSync(executor, client)\n\t    except Exception:\n\t        executor.close()\n\t        raise\n\tclass ClientSync:\n", "    _executor: _AsyncExecutor\n\t    _client: Client\n\t    def __init__(self, executor: _AsyncExecutor, client: Client):\n\t        self._executor = executor\n\t        self._client = client\n\t    def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        return self._executor.submit_coro(self._client.execute(stmt, args))\n\t    def batch(self, stmts: List[InStatement]) -> List[ResultSet]:\n\t        return self._executor.submit_coro(self._client.batch(stmts))\n\t    def transaction(self) -> TransactionSync:\n", "        transaction: Transaction = self._executor.submit_func(self._client.transaction)\n\t        return TransactionSync(self._executor, transaction)\n\t    def close(self) -> None:\n\t        self._executor.close_with_coro(self._client.close)\n\t    @property\n\t    def closed(self) -> bool:\n\t        return self._executor.is_closed()\n\t    def __enter__(self) -> ClientSync:\n\t        return self\n\t    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:\n", "        self.close()\n\tclass TransactionSync:\n\t    _executor: _AsyncExecutor\n\t    _transaction: Transaction\n\t    def __init__(self, executor: _AsyncExecutor, transaction: Transaction):\n\t        self._executor = executor\n\t        self._transaction = transaction\n\t    def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        return self._executor.submit_coro(self._transaction.execute(stmt, args))\n\t    def rollback(self) -> None:\n", "        return self._executor.submit_coro(self._transaction.rollback())\n\t    def commit(self) -> None:\n\t        return self._executor.submit_coro(self._transaction.commit())\n\t    def close(self) -> None:\n\t        self._executor.submit_func_unless_closed(self._transaction.close, lambda: None)\n\t    @property\n\t    def closed(self) -> bool:\n\t        return self._executor.submit_func_unless_closed(\n\t            lambda: self._transaction.closed, lambda: True\n\t        )\n", "    def __enter__(self) -> TransactionSync:\n\t        return self\n\t    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:\n\t        self.close()\n\t@dataclass\n\tclass _QueueItem:\n\t    coroutine: Coroutine[Any, Any, Any]\n\t    future: concurrent.futures.Future\n\tclass _AsyncExecutor:\n\t    _thread: threading.Thread\n", "    _loop: asyncio.AbstractEventLoop\n\t    _lock: threading.Lock\n\t    _closed: bool\n\t    _queue: Deque[Optional[_QueueItem]]\n\t    _waker: Optional[asyncio.Future[None]]\n\t    def __init__(self) -> None:\n\t        self._thread = threading.Thread(target=self._run, name=\"libsql_client\")\n\t        self._loop = asyncio.new_event_loop()\n\t        self._lock = threading.Lock()\n\t        self._closed = False\n", "        self._queue = collections.deque()\n\t        self._waker = None\n\t        self._thread.start()\n\t    def _run(self) -> None:\n\t        asyncio.set_event_loop(self._loop)\n\t        self._loop.run_until_complete(self._run_on_loop())\n\t        _cancel_all_tasks(self._loop)\n\t        self._loop.run_until_complete(self._loop.shutdown_asyncgens())\n\t        self._loop.close()\n\t    async def _run_on_loop(self) -> None:\n", "        while True:\n\t            item = await self._dequeue_item()\n\t            if item is None:\n\t                break\n\t            try:\n\t                item.future.set_result(await item.coroutine)\n\t            except Exception as e:\n\t                item.future.set_exception(e)\n\t        with self._lock:\n\t            self._closed = True\n", "            for item in self._queue:\n\t                if item is not None:\n\t                    item.future.set_exception(\n\t                        LibsqlError(\"Client is closed\", \"CLIENT_CLOSED\")\n\t                    )\n\t            self._queue.clear()\n\t    async def _dequeue_item(self) -> Optional[_QueueItem]:\n\t        while True:\n\t            with self._lock:\n\t                if len(self._queue) > 0:\n", "                    return self._queue.popleft()\n\t                assert self._waker is None\n\t                waker = self._loop.create_future()\n\t                self._waker = waker\n\t            await waker\n\t    def _enqueue_item_with_lock(self, item: Optional[_QueueItem]) -> None:\n\t        self._queue.append(item)\n\t        waker, self._waker = self._waker, None\n\t        if waker is not None:\n\t            waker_: asyncio.Future[None] = waker\n", "            def resolve_waker() -> None:\n\t                waker_.set_result(None)\n\t            self._loop.call_soon_threadsafe(resolve_waker)\n\t    def submit_coro(self, coro: Coroutine[Any, Any, T]) -> T:\n\t        with self._lock:\n\t            if self._closed:\n\t                raise LibsqlError(\"Client is closed\", \"CLIENT_CLOSED\")\n\t            fut: concurrent.futures.Future = concurrent.futures.Future()\n\t            self._enqueue_item_with_lock(_QueueItem(coro, fut))\n\t        return fut.result()\n", "    def submit_func(self, func: Callable[[], T]) -> T:\n\t        async def coro() -> T:\n\t            return func()\n\t        return self.submit_coro(coro())\n\t    def submit_func_unless_closed(\n\t        self, on_open: Callable[[], T], on_closed: Callable[[], T]\n\t    ) -> T:\n\t        async def on_open_coro() -> T:\n\t            return on_open()\n\t        with self._lock:\n", "            if self._closed:\n\t                return on_closed()\n\t            fut: concurrent.futures.Future = concurrent.futures.Future()\n\t            self._enqueue_item_with_lock(_QueueItem(on_open_coro(), fut))\n\t        return fut.result()\n\t    def close_with_coro(\n\t        self, coro_func: Callable[[], Coroutine[Any, Any, None]]\n\t    ) -> None:\n\t        with self._lock:\n\t            if self._closed:\n", "                return\n\t            fut: concurrent.futures.Future = concurrent.futures.Future()\n\t            self._enqueue_item_with_lock(_QueueItem(coro_func(), fut))\n\t            self._enqueue_item_with_lock(None)\n\t        self._thread.join()\n\t        fut.result()\n\t    def close(self) -> None:\n\t        async def noop() -> None:\n\t            return None\n\t        self.close_with_coro(noop)\n", "    def is_closed(self) -> bool:\n\t        with self._lock:\n\t            return self._closed\n\t# this is copied from CPython's Lib/asyncio/runners.py\n\tdef _cancel_all_tasks(loop: asyncio.AbstractEventLoop) -> None:\n\t    to_cancel = asyncio.all_tasks(loop)\n\t    if not to_cancel:\n\t        return\n\t    for task in to_cancel:\n\t        task.cancel()\n", "    loop.run_until_complete(asyncio.gather(*to_cancel, return_exceptions=True))\n\t    for task in to_cancel:\n\t        if task.cancelled():\n\t            continue\n\t        if task.exception() is not None:\n\t            loop.call_exception_handler(\n\t                {\n\t                    \"message\": \"unhandled exception during _AsyncExecutor shutdown\",\n\t                    \"exception\": task.exception(),\n\t                    \"task\": task,\n", "                }\n\t            )\n"]}
{"filename": "libsql_client/hrana/id_alloc.py", "chunked_list": ["from __future__ import annotations\n\tfrom typing import Set\n\t# An allocator of non-negative integer ids.\n\t#\n\t# This clever data structure has these \"ideal\" properties:\n\t# - It consumes memory proportional to the number of used ids (which is optimal).\n\t# - All operations are O(1) time.\n\t# - The allocated ids are small (with a slight modification, we could always\n\t#   provide the smallest possible\n\t# id).\n", "class IdAlloc:\n\t    # Set of all allocated ids\n\t    _used_ids: Set[int]\n\t    # Set of all free ids lower than `len(_used_ids)`\n\t    _free_ids: Set[int]\n\t    def __init__(self) -> None:\n\t        self._used_ids = set()\n\t        self._free_ids = set()\n\t    # Returns an id that was free, and marks it as used.\n\t    def alloc(self) -> int:\n", "        if len(self._free_ids) > 0:\n\t            free_id = self._free_ids.pop()\n\t            self._used_ids.add(free_id)\n\t            # maintain the invariant of `_free_ids`\n\t            if (len(self._used_ids) - 1) not in self._used_ids:\n\t                self._free_ids.add(len(self._used_ids) - 1)\n\t            return free_id\n\t        # the `_free_ids` set is empty, so there are no free ids lower than\n\t        # `len(_used_ids)` this means that `_used_ids` is a set that contains all\n\t        # numbers from 0 to `len(_used_ids) - 1`, so `len(_used_ids)` is free\n", "        free_id = len(self._used_ids)\n\t        self._used_ids.add(free_id)\n\t        return free_id\n\t    def free(self, used_id: int) -> None:\n\t        self._used_ids.remove(used_id)\n\t        # maintain the invariant of `_free_ids`\n\t        self._free_ids.discard(len(self._used_ids))\n\t        if used_id < len(self._used_ids):\n\t            self._free_ids.add(used_id)\n"]}
{"filename": "libsql_client/hrana/conn.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\tfrom dataclasses import dataclass\n\timport json\n\tfrom typing import Any\n\tfrom typing import Callable\n\tfrom typing import cast\n\tfrom typing import Dict\n\tfrom typing import Optional\n\tfrom typing import TypeVar\n", "from typing import Union\n\timport aiohttp\n\tfrom . import proto\n\tfrom .convert import _error_from_proto\n\tfrom .id_alloc import IdAlloc\n\tfrom ..client import LibsqlError\n\t@dataclass\n\tclass _ResponseState:\n\t    type: str\n\t    future: asyncio.Future[proto.Response]\n", "@dataclass\n\tclass _StreamState:\n\t    stream_id: int\n\t    closed: Optional[BaseException]\n\tclass HranaConn:\n\t    _connect_task: asyncio.Task[aiohttp.ClientWebSocketResponse]\n\t    _receive_task: Optional[asyncio.Task[None]]\n\t    _send_task: Optional[asyncio.Task[None]]\n\t    _socket: Optional[aiohttp.ClientWebSocketResponse]\n\t    _send_msg_queue: asyncio.Queue[str]\n", "    _recvd_hello: bool\n\t    _finished_handshake: asyncio.Event\n\t    _response_map: Dict[int, _ResponseState]\n\t    _request_id_alloc: IdAlloc\n\t    _stream_id_alloc: IdAlloc\n\t    _sql_id_alloc: IdAlloc\n\t    exception: Optional[BaseException]\n\t    def __init__(\n\t        self, session: aiohttp.ClientSession, url: str, auth_token: Optional[str] = None\n\t    ):\n", "        self._connect_task = asyncio.create_task(self._do_connect(session, url))\n\t        self._connect_task.add_done_callback(self._done_connect)\n\t        self._receive_task = None\n\t        self._send_task = None\n\t        self._socket = None\n\t        self._send_msg_queue = asyncio.Queue()\n\t        self._recvd_hello = False\n\t        self._finished_handshake = asyncio.Event()\n\t        self._response_map = {}\n\t        self._request_id_alloc = IdAlloc()\n", "        self._stream_id_alloc = IdAlloc()\n\t        self._sql_id_alloc = IdAlloc()\n\t        self.exception = None\n\t        self._send({\"type\": \"hello\", \"jwt\": auth_token})\n\t    async def wait_connected(self) -> None:\n\t        await self._finished_handshake.wait()\n\t        if self.exception:\n\t            raise self.exception\n\t    async def _do_connect(\n\t        self, session: aiohttp.ClientSession, url: str\n", "    ) -> aiohttp.ClientWebSocketResponse:\n\t        return await session.ws_connect(\n\t            url,\n\t            protocols=[\"hrana2\"],\n\t            autoclose=False,\n\t            autoping=True,\n\t        )\n\t    def _done_connect(\n\t        self, task: asyncio.Task[aiohttp.ClientWebSocketResponse]\n\t    ) -> None:\n", "        e: Optional[BaseException]\n\t        if task.cancelled():\n\t            e = LibsqlError(\"The connect task was cancelled\", \"CLIENT_CLOSED\")\n\t        else:\n\t            e = task.exception()\n\t        if e is not None:\n\t            self._set_exception(e)\n\t        if self.exception is not None:\n\t            return\n\t        socket = task.result()\n", "        receive_task = asyncio.create_task(self._do_receive(socket))\n\t        send_task = asyncio.create_task(self._do_send(socket))\n\t        receive_task.add_done_callback(self._done_receive)\n\t        send_task.add_done_callback(self._done_send)\n\t        self._socket = socket\n\t        self._receive_task = receive_task\n\t        self._send_task = send_task\n\t    async def _do_receive(self, socket: aiohttp.ClientWebSocketResponse) -> None:\n\t        while True:\n\t            msg = await socket.receive()\n", "            if msg.type == aiohttp.WSMsgType.TEXT:\n\t                try:\n\t                    self._receive(msg.data)\n\t                except Exception:\n\t                    await socket.close(\n\t                        code=3007, message=\"Could not handle message\".encode()\n\t                    )\n\t                    raise\n\t            elif msg.type == aiohttp.WSMsgType.BINARY:\n\t                await socket.close(\n", "                    code=3003, message=\"Only text messages are accepted\".encode()\n\t                )\n\t                raise LibsqlError(\n\t                    \"Received a binary WebSocket message\", \"HRANA_PROTO_ERROR\"\n\t                )\n\t            elif msg.type == aiohttp.WSMsgType.PING:\n\t                await socket.pong(msg.data)\n\t            elif msg.type == aiohttp.WSMsgType.PONG:\n\t                pass\n\t            elif msg.type == aiohttp.WSMsgType.CLOSE:\n", "                code = cast(aiohttp.WSCloseCode, msg.data)\n\t                reason = cast(str, msg.extra)\n\t                raise LibsqlError(\n\t                    f\"WebSocket was closed with code {code}: {reason!r}\",\n\t                    \"HRANA_WEBSOCKET_ERROR\",\n\t                )\n\t            elif msg.type == aiohttp.WSMsgType.CLOSING:\n\t                pass\n\t            elif msg.type == aiohttp.WSMsgType.CLOSED:\n\t                raise LibsqlError(\"WebSocket was closed\", \"HRANA_WEBSOCKET_ERROR\")\n", "            elif msg.type == aiohttp.WSMsgType.ERROR:\n\t                raise msg.data\n\t            else:\n\t                raise LibsqlError(\n\t                    f\"Received unexpected WebSocket message {msg.type!r}\",\n\t                    \"HRANA_PROTO_ERROR\",\n\t                )\n\t    async def _do_send(self, socket: aiohttp.ClientWebSocketResponse) -> None:\n\t        while True:\n\t            msg_str = await self._send_msg_queue.get()\n", "            await socket.send_str(msg_str)\n\t    def _done_receive(self, task: asyncio.Task[None]) -> None:\n\t        e: Optional[BaseException]\n\t        if task.cancelled():\n\t            e = LibsqlError(\"The receive task was cancelled\", \"CLIENT_CLOSED\")\n\t        else:\n\t            e = task.exception()\n\t        if e is not None:\n\t            if self._send_task is not None:\n\t                self._send_task.cancel()\n", "            self._set_exception(e)\n\t    def _done_send(self, task: asyncio.Task[None]) -> None:\n\t        e: Optional[BaseException]\n\t        if task.cancelled():\n\t            e = LibsqlError(\"The send task was cancelled\", \"CLIENT_CLOSED\")\n\t        else:\n\t            e = task.exception()\n\t        if e is not None:\n\t            self._set_exception(e)\n\t        if self._receive_task is not None:\n", "            self._receive_task.cancel()\n\t    def _send(self, msg: proto.ClientMsg) -> None:\n\t        assert self.exception is None\n\t        self._send_msg_queue.put_nowait(json.dumps(msg))\n\t    def _set_exception(self, e: BaseException) -> None:\n\t        if self.exception is not None:\n\t            return\n\t        self.exception = e\n\t        self._finished_handshake.set()\n\t        for task in (self._connect_task, self._receive_task, self._send_task):\n", "            if task is not None:\n\t                task.cancel()\n\t        for request_id, response_state in self._response_map.items():\n\t            response_state.future.set_exception(e)\n\t            self._request_id_alloc.free(request_id)\n\t        self._response_map.clear()\n\t    def send_request(self, request: proto.Request) -> asyncio.Future[proto.Response]:\n\t        future = asyncio.get_running_loop().create_future()\n\t        if self.exception is not None:\n\t            future.set_exception(self.exception)\n", "            return future\n\t        request_id = self._request_id_alloc.alloc()\n\t        self._response_map[request_id] = _ResponseState(request[\"type\"], future)\n\t        self._send({\"type\": \"request\", \"request_id\": request_id, \"request\": request})\n\t        return future\n\t    def _receive(self, text: str) -> None:\n\t        if self.exception is not None:\n\t            return\n\t        try:\n\t            msg = json.loads(text)\n", "        except ValueError as e:\n\t            raise LibsqlError(\n\t                \"Server message is not valid JSON\", \"HRANA_PROTO_ERROR\"\n\t            ) from e\n\t        if msg[\"type\"] in (\"hello_ok\", \"hello_error\"):\n\t            if self._recvd_hello:\n\t                raise LibsqlError(\n\t                    \"Received a duplicated error response\", \"HRANA_PROTO_ERROR\"\n\t                )\n\t            self._recvd_hello = True\n", "            self._finished_handshake.set()\n\t            if msg[\"type\"] == \"hello_error\":\n\t                raise _error_from_proto(msg[\"error\"])\n\t            return\n\t        elif not self._recvd_hello:\n\t            raise LibsqlError(\n\t                \"Received a non-hello message before hello response\",\n\t                \"HRANA_PROTO_ERROR\",\n\t            )\n\t        if msg[\"type\"] == \"response_ok\":\n", "            request_id = int(msg[\"request_id\"])\n\t            response_state = self._response_map.pop(request_id, None)\n\t            if response_state is None:\n\t                raise LibsqlError(\n\t                    \"Received unexpected OK response\", \"HRANA_PROTO_ERROR\"\n\t                )\n\t            self._request_id_alloc.free(request_id)\n\t            try:\n\t                if response_state.type != msg[\"response\"][\"type\"]:\n\t                    raise LibsqlError(\n", "                        \"Received unexpected type of response\", \"HRANA_PROTO_ERROR\"\n\t                    )\n\t                response_state.future.set_result(msg[\"response\"])\n\t            except Exception as e:\n\t                response_state.future.set_exception(e)\n\t                raise\n\t        elif msg[\"type\"] == \"response_error\":\n\t            request_id = int(msg[\"request_id\"])\n\t            response_state = self._response_map.pop(request_id, None)\n\t            if response_state is None:\n", "                raise LibsqlError(\n\t                    \"Received unexpected error response\", \"HRANA_PROTO_ERROR\"\n\t                )\n\t            self._request_id_alloc.free(request_id)\n\t            response_state.future.set_exception(_error_from_proto(msg[\"error\"]))\n\t        else:\n\t            raise LibsqlError(\"Received unexpected message type\", \"HRANA_PROTO_ERROR\")\n\t    def open_stream(self) -> HranaStream:\n\t        stream_id = self._stream_id_alloc.alloc()\n\t        stream_state = _StreamState(stream_id, None)\n", "        def open_done(fut: asyncio.Future[proto.Response]) -> None:\n\t            e: Optional[BaseException]\n\t            if fut.cancelled():\n\t                e = asyncio.CancelledError(\"Stream opening was cancelled\")\n\t            else:\n\t                e = fut.exception()\n\t            if e is not None:\n\t                self._close_stream(stream_state, e)\n\t        open_fut = self.send_request(\n\t            {\n", "                \"type\": \"open_stream\",\n\t                \"stream_id\": stream_id,\n\t            }\n\t        )\n\t        open_fut.add_done_callback(open_done)\n\t        return HranaStream(self, stream_state)\n\t    def _close_stream(self, stream_state: _StreamState, e: BaseException) -> None:\n\t        if stream_state.closed is not None or self.exception is not None:\n\t            return\n\t        stream_state.closed = e\n", "        def close_done(fut: asyncio.Future[proto.Response]) -> None:\n\t            self._stream_id_alloc.free(stream_state.stream_id)\n\t            if not fut.cancelled():\n\t                fut.exception()\n\t        close_fut = self.send_request(\n\t            {\n\t                \"type\": \"close_stream\",\n\t                \"stream_id\": stream_state.stream_id,\n\t            }\n\t        )\n", "        close_fut.add_done_callback(close_done)\n\t    async def close(self) -> None:\n\t        self._set_exception(LibsqlError(\"Client was manually closed\", \"CLIENT_CLOSED\"))\n\t        if self._socket is not None:\n\t            await self._socket.close()\n\t    def store_sql(self, sql: str) -> int:\n\t        sql_id = self._sql_id_alloc.alloc()\n\t        def store_sql_done(fut: asyncio.Future[proto.Response]) -> None:\n\t            e: Optional[BaseException]\n\t            if fut.cancelled():\n", "                e = asyncio.CancelledError(\"store_sql was cancelled\")\n\t            else:\n\t                e = fut.exception()\n\t            if e is not None:\n\t                self._sql_id_alloc.free(sql_id)\n\t        store_sql_fut = self.send_request(\n\t            {\n\t                \"type\": \"store_sql\",\n\t                \"sql_id\": sql_id,\n\t                \"sql\": sql,\n", "            }\n\t        )\n\t        store_sql_fut.add_done_callback(store_sql_done)\n\t        return sql_id\n\t    def close_sql(self, sql_id: int) -> None:\n\t        if self.exception is not None:\n\t            return\n\t        def close_sql_done(fut: asyncio.Future[proto.Response]) -> None:\n\t            self._sql_id_alloc.free(sql_id)\n\t            if not fut.cancelled():\n", "                fut.exception()\n\t        close_sql_fut = self.send_request(\n\t            {\n\t                \"type\": \"close_sql\",\n\t                \"sql_id\": sql_id,\n\t            }\n\t        )\n\t        close_sql_fut.add_done_callback(close_sql_done)\n\tclass HranaStream:\n\t    _conn: HranaConn\n", "    _state: _StreamState\n\t    def __init__(self, conn: HranaConn, state: _StreamState):\n\t        self._conn = conn\n\t        self._state = state\n\t    def execute(self, stmt: proto.Stmt) -> asyncio.Future[proto.StmtResult]:\n\t        if self._state.closed is not None:\n\t            raise LibsqlError(\n\t                \"Stream was closed\", \"STREAM_CLOSED\"\n\t            ) from self._state.closed\n\t        request: proto.ExecuteReq = {\n", "            \"type\": \"execute\",\n\t            \"stream_id\": self._state.stream_id,\n\t            \"stmt\": stmt,\n\t        }\n\t        response_fut = self._conn.send_request(request)\n\t        def get_result(response: proto.Response) -> proto.StmtResult:\n\t            return cast(proto.ExecuteResp, response)[\"result\"]\n\t        return _map_future(response_fut, get_result)\n\t    def sequence(self, stmt: Union[str, int]) -> asyncio.Future[None]:\n\t        if self._state.closed is not None:\n", "            raise LibsqlError(\n\t                \"Stream was closed\", \"STREAM_CLOSED\"\n\t            ) from self._state.closed\n\t        request: proto.SequenceReq\n\t        if isinstance(stmt, str):\n\t            request = {\n\t                \"type\": \"sequence\",\n\t                \"stream_id\": self._state.stream_id,\n\t                \"sql\": stmt,\n\t            }\n", "        else:\n\t            request = {\n\t                \"type\": \"sequence\",\n\t                \"stream_id\": self._state.stream_id,\n\t                \"sql_id\": stmt,\n\t            }\n\t        response_fut = self._conn.send_request(request)\n\t        def get_result(response: proto.Response) -> None:\n\t            return None\n\t        return _map_future(response_fut, get_result)\n", "    def batch(self, batch: proto.Batch) -> asyncio.Future[proto.BatchResult]:\n\t        if self._state.closed is not None:\n\t            raise LibsqlError(\n\t                \"Stream was closed\", \"STREAM_CLOSED\"\n\t            ) from self._state.closed\n\t        request: proto.BatchReq = {\n\t            \"type\": \"batch\",\n\t            \"stream_id\": self._state.stream_id,\n\t            \"batch\": batch,\n\t        }\n", "        response_fut = self._conn.send_request(request)\n\t        def get_result(response: proto.Response) -> proto.BatchResult:\n\t            return cast(proto.BatchResp, response)[\"result\"]\n\t        return _map_future(response_fut, get_result)\n\t    def close(self) -> None:\n\t        e = LibsqlError(\"Stream was manually closed\", \"STREAM_CLOSED\")\n\t        self._conn._close_stream(self._state, e)\n\t    @property\n\t    def closed(self) -> bool:\n\t        return self._state.closed is not None\n", "    def __enter__(self) -> HranaStream:\n\t        return self\n\t    def __exit__(self, _exc_type: Any, _exc_value: Any, _traceback: Any) -> None:\n\t        self.close()\n\tT = TypeVar(\"T\")\n\tR = TypeVar(\"R\")\n\tdef _map_future(fut: asyncio.Future[T], f: Callable[[T], R]) -> asyncio.Future[R]:\n\t    ret: asyncio.Future[R] = asyncio.get_running_loop().create_future()\n\t    def done(fut: asyncio.Future[T]) -> None:\n\t        if fut.cancelled():\n", "            ret.cancel()\n\t            return\n\t        e = fut.exception()\n\t        if e is None:\n\t            ret.set_result(f(fut.result()))\n\t        else:\n\t            ret.set_exception(e)\n\t    fut.add_done_callback(done)\n\t    return ret\n"]}
{"filename": "libsql_client/hrana/proto.py", "chunked_list": ["from __future__ import annotations\n\tfrom typing import List\n\tfrom typing import Optional\n\tfrom typing import Union\n\tfrom typing_extensions import Literal\n\tfrom typing_extensions import NotRequired\n\tfrom typing_extensions import TypedDict\n\t### Errors\n\tError = TypedDict(\n\t    \"Error\",\n", "    {\n\t        \"message\": str,\n\t        \"code\": NotRequired[Optional[str]],\n\t    },\n\t)\n\t### Values\n\tValueNull = TypedDict(\"ValueNull\", {\"type\": Literal[\"null\"]})\n\tValueInteger = TypedDict(\"ValueInteger\", {\"type\": Literal[\"integer\"], \"value\": str})\n\tValueFloat = TypedDict(\n\t    \"ValueFloat\", {\"type\": Literal[\"float\"], \"value\": Union[float, int]}\n", ")\n\tValueText = TypedDict(\"ValueText\", {\"type\": Literal[\"text\"], \"value\": str})\n\tValueBlob = TypedDict(\"ValueBlob\", {\"type\": Literal[\"blob\"], \"base64\": str})\n\tValue = Union[ValueNull, ValueInteger, ValueFloat, ValueText, ValueBlob]\n\t### Execute a statement\n\tNamedArg = TypedDict(\n\t    \"NamedArg\",\n\t    {\n\t        \"name\": str,\n\t        \"value\": Value,\n", "    },\n\t)\n\tStmt = TypedDict(\n\t    \"Stmt\",\n\t    {\n\t        # NOTE: must provide one of sql or sql_id\n\t        \"sql\": NotRequired[str],\n\t        \"sql_id\": NotRequired[int],\n\t        \"args\": NotRequired[List[Value]],\n\t        \"named_args\": NotRequired[List[NamedArg]],\n", "        \"want_rows\": bool,\n\t    },\n\t)\n\tCol = TypedDict(\n\t    \"Col\",\n\t    {\n\t        \"name\": Optional[str],\n\t        \"decltype\": NotRequired[Optional[str]],\n\t    },\n\t)\n", "StmtResult = TypedDict(\n\t    \"StmtResult\",\n\t    {\n\t        \"cols\": List[Col],\n\t        \"rows\": List[List[Value]],\n\t        \"affected_row_count\": int,\n\t        \"last_insert_rowid\": NotRequired[Optional[str]],\n\t    },\n\t)\n\tExecuteReq = TypedDict(\n", "    \"ExecuteReq\",\n\t    {\n\t        \"type\": Literal[\"execute\"],\n\t        \"stream_id\": int,\n\t        \"stmt\": Stmt,\n\t    },\n\t)\n\tExecuteResp = TypedDict(\n\t    \"ExecuteResp\",\n\t    {\n", "        \"type\": Literal[\"execute\"],\n\t        \"result\": StmtResult,\n\t    },\n\t)\n\t### Execute a sequence of SQL statements\n\tSequenceReq = TypedDict(\n\t    \"SequenceReq\",\n\t    {\n\t        \"type\": Literal[\"sequence\"],\n\t        \"stream_id\": int,\n", "        # NOTE: must provide one of sql or sql_id\n\t        \"sql\": NotRequired[str],\n\t        \"sql_id\": NotRequired[int],\n\t    },\n\t)\n\tSequenceResp = TypedDict(\n\t    \"SequenceResp\",\n\t    {\n\t        \"type\": Literal[\"sequence\"],\n\t    },\n", ")\n\t### Execute a batch\n\tBatchCondOk = TypedDict(\"BatchCondOk\", {\"type\": Literal[\"ok\"], \"step\": int})\n\tBatchCondError = TypedDict(\"BatchCondError\", {\"type\": Literal[\"error\"], \"step\": int})\n\tBatchCondNot = TypedDict(\"BatchCondNot\", {\"type\": Literal[\"not\"], \"cond\": \"BatchCond\"})\n\tBatchCondAnd = TypedDict(\n\t    \"BatchCondAnd\", {\"type\": Literal[\"and\"], \"conds\": List[\"BatchCond\"]}\n\t)\n\tBatchCondOr = TypedDict(\n\t    \"BatchCondOr\", {\"type\": Literal[\"or\"], \"conds\": List[\"BatchCond\"]}\n", ")\n\tBatchCond = Union[BatchCondOk, BatchCondError, BatchCondNot, BatchCondAnd, BatchCondOr]\n\tBatchStep = TypedDict(\n\t    \"BatchStep\",\n\t    {\n\t        \"condition\": NotRequired[Optional[BatchCond]],\n\t        \"stmt\": Stmt,\n\t    },\n\t)\n\tBatch = TypedDict(\n", "    \"Batch\",\n\t    {\n\t        \"steps\": List[BatchStep],\n\t    },\n\t)\n\tBatchReq = TypedDict(\n\t    \"BatchReq\",\n\t    {\n\t        \"type\": Literal[\"batch\"],\n\t        \"stream_id\": int,\n", "        \"batch\": Batch,\n\t    },\n\t)\n\tBatchResult = TypedDict(\n\t    \"BatchResult\",\n\t    {\n\t        \"step_results\": List[Optional[StmtResult]],\n\t        \"step_errors\": List[Optional[Error]],\n\t    },\n\t)\n", "BatchResp = TypedDict(\n\t    \"BatchResp\",\n\t    {\n\t        \"type\": Literal[\"batch\"],\n\t        \"result\": BatchResult,\n\t    },\n\t)\n\t### Open stream\n\tOpenStreamReq = TypedDict(\n\t    \"OpenStreamReq\",\n", "    {\n\t        \"type\": Literal[\"open_stream\"],\n\t        \"stream_id\": int,\n\t    },\n\t)\n\tOpenStreamResp = TypedDict(\n\t    \"OpenStreamResp\",\n\t    {\n\t        \"type\": Literal[\"open_stream\"],\n\t    },\n", ")\n\t### Close stream\n\tCloseStreamReq = TypedDict(\n\t    \"CloseStreamReq\",\n\t    {\n\t        \"type\": Literal[\"close_stream\"],\n\t        \"stream_id\": int,\n\t    },\n\t)\n\tCloseStreamResp = TypedDict(\n", "    \"CloseStreamResp\",\n\t    {\n\t        \"type\": Literal[\"close_stream\"],\n\t    },\n\t)\n\t### Hello\n\tHelloMsg = TypedDict(\n\t    \"HelloMsg\",\n\t    {\n\t        \"type\": Literal[\"hello\"],\n", "        \"jwt\": Optional[str],\n\t    },\n\t)\n\tHelloOkMsg = TypedDict(\n\t    \"HelloOkMsg\",\n\t    {\n\t        \"type\": Literal[\"hello_ok\"],\n\t    },\n\t)\n\tHelloErrorMsg = TypedDict(\n", "    \"HelloErrorMsg\",\n\t    {\n\t        \"type\": Literal[\"hello_error\"],\n\t        \"error\": Error,\n\t    },\n\t)\n\t### Store an SQL text on the server\n\tStoreSqlReq = TypedDict(\n\t    \"StoreSqlReq\",\n\t    {\n", "        \"type\": Literal[\"store_sql\"],\n\t        \"sql_id\": int,\n\t        \"sql\": str,\n\t    },\n\t)\n\tStoreSqlResp = TypedDict(\n\t    \"StoreSqlResp\",\n\t    {\n\t        \"type\": Literal[\"store_sql\"],\n\t    },\n", ")\n\t### Close a stored SQL text\n\tCloseSqlReq = TypedDict(\n\t    \"CloseSqlReq\",\n\t    {\n\t        \"type\": Literal[\"close_sql\"],\n\t        \"sql_id\": int,\n\t    },\n\t)\n\tCloseSqlResp = TypedDict(\n", "    \"CloseSqlResp\",\n\t    {\n\t        \"type\": Literal[\"close_sql\"],\n\t    },\n\t)\n\t### Request/response\n\tRequest = Union[\n\t    OpenStreamReq,\n\t    CloseStreamReq,\n\t    ExecuteReq,\n", "    BatchReq,\n\t    StoreSqlReq,\n\t    CloseSqlReq,\n\t    SequenceReq,\n\t]\n\tRequestMsg = TypedDict(\n\t    \"RequestMsg\",\n\t    {\n\t        \"type\": Literal[\"request\"],\n\t        \"request_id\": int,\n", "        \"request\": Request,\n\t    },\n\t)\n\tResponse = Union[\n\t    OpenStreamResp,\n\t    CloseStreamResp,\n\t    ExecuteResp,\n\t    BatchResp,\n\t    StoreSqlResp,\n\t    CloseSqlResp,\n", "    SequenceResp,\n\t]\n\tResponseOkMsg = TypedDict(\n\t    \"ResponseOkMsg\",\n\t    {\n\t        \"type\": Literal[\"response_ok\"],\n\t        \"request_id\": int,\n\t        \"response\": Response,\n\t    },\n\t)\n", "ResponseErrorMsg = TypedDict(\n\t    \"ResponseErrorMsg\",\n\t    {\n\t        \"type\": Literal[\"response_error\"],\n\t        \"request_id\": int,\n\t        \"error\": Error,\n\t    },\n\t)\n\t## Messages\n\tClientMsg = Union[\n", "    HelloMsg,\n\t    RequestMsg,\n\t]\n\tServerMsg = Union[\n\t    HelloOkMsg,\n\t    HelloErrorMsg,\n\t    ResponseOkMsg,\n\t    ResponseErrorMsg,\n\t]\n"]}
{"filename": "libsql_client/hrana/client.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\tfrom typing import List\n\tfrom typing import Optional\n\tfrom typing import Set\n\timport urllib.parse\n\timport aiohttp\n\tfrom . import proto\n\tfrom .conn import HranaConn\n\tfrom .conn import HranaStream\n", "from .convert import _batch_results_from_proto\n\tfrom .convert import _batch_to_proto\n\tfrom .convert import _result_set_from_proto\n\tfrom .convert import _stmt_to_proto\n\tfrom ..client import Client\n\tfrom ..client import InArgs\n\tfrom ..client import InStatement\n\tfrom ..client import LibsqlError\n\tfrom ..client import Transaction\n\tfrom ..config import _Config\n", "from ..result import ResultSet\n\tdef _create_hrana_client(config: _Config) -> HranaClient:\n\t    assert config.scheme in (\"ws\", \"wss\")\n\t    url = _config_to_url(config)\n\t    return HranaClient(url, config.auth_token)\n\tdef _config_to_url(config: _Config) -> str:\n\t    if config.scheme == \"ws\" and config.tls:\n\t        raise LibsqlError(\n\t            \"A 'ws:' URL cannot opt into TLS by using ?tls=1\", \"URL_INVALID\"\n\t        )\n", "    elif config.scheme == \"wss\" and not config.tls:\n\t        raise LibsqlError(\n\t            \"A 'wss:' URL cannot opt out of TLS by using ?tls=0\", \"URL_INVALID\"\n\t        )\n\t    return urllib.parse.urlunparse(\n\t        (\n\t            config.scheme,\n\t            config.authority,\n\t            config.path,\n\t            \"\",\n", "            \"\",\n\t            \"\",\n\t        )\n\t    )\n\tclass HranaClient(Client):\n\t    _session: aiohttp.ClientSession\n\t    _conn: HranaConn\n\t    _close_tasks: Set[asyncio.Task[None]]\n\t    _url: str\n\t    _auth_token: Optional[str]\n", "    _closed: bool\n\t    def __init__(self, url: str, auth_token: Optional[str]):\n\t        self._session = aiohttp.ClientSession()\n\t        self._close_tasks = set()\n\t        self._url = url\n\t        self._auth_token = auth_token\n\t        self._conn = self._open_conn()\n\t        self._closed = False\n\t    async def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        with self._open_stream() as stream:\n", "            proto_stmt = _stmt_to_proto(stmt, args)\n\t            proto_result_fut = stream.execute(proto_stmt)\n\t        return _result_set_from_proto(await proto_result_fut)\n\t    async def batch(self, stmts: List[InStatement]) -> List[ResultSet]:\n\t        with self._open_stream() as stream:\n\t            proto_batch = _batch_to_proto(stmts)\n\t            proto_result_fut = stream.batch(proto_batch)\n\t        return _batch_results_from_proto(await proto_result_fut, len(stmts))\n\t    def transaction(self) -> HranaTransaction:\n\t        stream = self._open_stream()\n", "        return HranaTransaction(stream)\n\t    def _open_stream(self) -> HranaStream:\n\t        if self._closed:\n\t            raise LibsqlError(\"The client is closed\", \"CLIENT_CLOSED\")\n\t        if self._conn.exception is not None:\n\t            close_task = asyncio.create_task(self._conn.close())\n\t            self._close_tasks.add(close_task)\n\t            close_task.add_done_callback(self._close_tasks.discard)\n\t            self._conn = self._open_conn()\n\t        return self._conn.open_stream()\n", "    def _open_conn(self) -> HranaConn:\n\t        return HranaConn(self._session, self._url, self._auth_token)\n\t    async def close(self) -> None:\n\t        await self._conn.close()\n\t        if len(self._close_tasks) > 0:\n\t            await asyncio.wait(\n\t                list(self._close_tasks), return_when=asyncio.ALL_COMPLETED\n\t            )\n\t        await self._session.close()\n\t        self._closed = True\n", "    @property\n\t    def closed(self) -> bool:\n\t        return self._closed\n\tclass HranaTransaction(Transaction):\n\t    _stream: HranaStream\n\t    _begin_fut: asyncio.Future[proto.StmtResult]\n\t    def __init__(self, stream: HranaStream):\n\t        self._stream = stream\n\t        self._begin_fut = stream.execute(\n\t            {\n", "                \"sql\": \"BEGIN\",\n\t                \"want_rows\": False,\n\t            }\n\t        )\n\t    async def execute(self, stmt: InStatement, args: InArgs = None) -> ResultSet:\n\t        await self._begin_fut\n\t        if self._stream.closed:\n\t            raise LibsqlError(\"The transaction is closed\", \"TRANSACTION_CLOSED\")\n\t        proto_stmt = _stmt_to_proto(stmt, args)\n\t        proto_result = await self._stream.execute(proto_stmt)\n", "        return _result_set_from_proto(proto_result)\n\t    async def rollback(self) -> None:\n\t        await self._begin_fut\n\t        if self._stream.closed:\n\t            return\n\t        fut = self._stream.execute(\n\t            {\n\t                \"sql\": \"ROLLBACK\",\n\t                \"want_rows\": False,\n\t            }\n", "        )\n\t        self._stream.close()\n\t        await fut\n\t    async def commit(self) -> None:\n\t        await self._begin_fut\n\t        if self._stream.closed:\n\t            raise LibsqlError(\"The transaction is closed\", \"TRANSACTION_CLOSED\")\n\t        fut = self._stream.execute(\n\t            {\n\t                \"sql\": \"COMMIT\",\n", "                \"want_rows\": False,\n\t            }\n\t        )\n\t        self._stream.close()\n\t        await fut\n\t    def close(self) -> None:\n\t        self._stream.close()\n\t    @property\n\t    def closed(self) -> bool:\n\t        return self._stream.closed\n"]}
{"filename": "libsql_client/hrana/convert.py", "chunked_list": ["from __future__ import annotations\n\timport base64\n\timport math\n\tfrom typing import List\n\tfrom . import proto\n\tfrom ..client import _normalize_value\n\tfrom ..client import InArgs\n\tfrom ..client import InStatement\n\tfrom ..client import InValue\n\tfrom ..client import LibsqlError\n", "from ..client import Statement\n\tfrom ..result import ResultSet\n\tfrom ..result import Row\n\tfrom ..result import Value\n\tdef _stmt_to_proto(in_stmt: InStatement, in_args: InArgs = None) -> proto.Stmt:\n\t    stmt = Statement.convert(in_stmt, in_args)\n\t    args: List[proto.Value] = []\n\t    named_args: List[proto.NamedArg] = []\n\t    if stmt.args is None:\n\t        pass\n", "    elif isinstance(stmt.args, dict):\n\t        named_args = [\n\t            {\"name\": key, \"value\": _value_to_proto(value)}\n\t            for key, value in stmt.args.items()\n\t        ]\n\t    else:\n\t        args = [_value_to_proto(value) for value in stmt.args]\n\t    return {\"sql\": stmt.sql, \"args\": args, \"named_args\": named_args, \"want_rows\": True}\n\tdef _result_set_from_proto(proto_res: proto.StmtResult) -> ResultSet:\n\t    columns = tuple(proto_col[\"name\"] or \"\" for proto_col in proto_res[\"cols\"])\n", "    column_idxs = {column: idx for idx, column in enumerate(columns)}\n\t    rows = []\n\t    for proto_row in proto_res[\"rows\"]:\n\t        values = tuple(_value_from_proto(proto_val) for proto_val in proto_row)\n\t        rows.append(Row(column_idxs, values))\n\t    rows_affected = proto_res[\"affected_row_count\"]\n\t    last_insert_rowid_str = proto_res.get(\"last_insert_rowid\")\n\t    last_insert_rowid = (\n\t        int(last_insert_rowid_str) if last_insert_rowid_str is not None else None\n\t    )\n", "    return ResultSet(columns, rows, rows_affected, last_insert_rowid)\n\tdef _batch_to_proto(in_stmts: List[InStatement]) -> proto.Batch:\n\t    steps: List[proto.BatchStep] = []\n\t    steps.append(\n\t        {\n\t            \"stmt\": {\"sql\": \"BEGIN\", \"want_rows\": False},\n\t        }\n\t    )\n\t    for in_stmt in in_stmts:\n\t        steps.append(\n", "            {\n\t                \"condition\": {\n\t                    \"type\": \"ok\",\n\t                    \"step\": len(steps) - 1,\n\t                },\n\t                \"stmt\": _stmt_to_proto(in_stmt),\n\t            }\n\t        )\n\t    steps.append(\n\t        {\n", "            \"condition\": {\n\t                \"type\": \"ok\",\n\t                \"step\": len(steps) - 1,\n\t            },\n\t            \"stmt\": {\"sql\": \"COMMIT\", \"want_rows\": False},\n\t        }\n\t    )\n\t    steps.append(\n\t        {\n\t            \"condition\": {\n", "                \"type\": \"not\",\n\t                \"cond\": {\n\t                    \"type\": \"ok\",\n\t                    \"step\": len(steps) - 1,\n\t                },\n\t            },\n\t            \"stmt\": {\"sql\": \"ROLLBACK\", \"want_rows\": False},\n\t        }\n\t    )\n\t    return {\"steps\": steps}\n", "def _batch_results_from_proto(\n\t    proto_res: proto.BatchResult, stmt_count: int\n\t) -> List[ResultSet]:\n\t    if len(proto_res[\"step_results\"]) != stmt_count + 3:\n\t        raise LibsqlError(\n\t            \"Server did not return the expected number of batch results\",\n\t            \"HRANA_PROTO_ERROR\",\n\t        )\n\t    if len(proto_res[\"step_errors\"]) != stmt_count + 3:\n\t        raise LibsqlError(\n", "            \"Server did not return the expected number of batch errors\",\n\t            \"HRANA_PROTO_ERROR\",\n\t        )\n\t    for proto_err in proto_res[\"step_errors\"]:\n\t        if proto_err is not None:\n\t            raise _error_from_proto(proto_err)\n\t    result_sets = []\n\t    for stmt_res in proto_res[\"step_results\"][1:-2]:\n\t        if stmt_res is None:\n\t            raise LibsqlError(\n", "                \"Server did not return a result in batch\", \"HRANA_PROTO_ERROR\"\n\t            )\n\t        result_sets.append(_result_set_from_proto(stmt_res))\n\t    return result_sets\n\tdef _error_from_proto(proto_err: proto.Error) -> LibsqlError:\n\t    message = proto_err[\"message\"]\n\t    code = proto_err.get(\"code\") or \"UNKNOWN\"\n\t    return LibsqlError(message, code)\n\tdef _value_to_proto(in_value: InValue) -> proto.Value:\n\t    value = _normalize_value(in_value)\n", "    if value is None:\n\t        return {\"type\": \"null\"}\n\t    elif isinstance(value, str):\n\t        return {\"type\": \"text\", \"value\": value}\n\t    elif isinstance(value, int):\n\t        if value < _MIN_INTEGER or value > _MAX_INTEGER:\n\t            raise OverflowError(\n\t                \"Integer exceeds the range of SQLite integers (64 bits, signed)\"\n\t            )\n\t        return {\"type\": \"integer\", \"value\": str(value)}\n", "    elif isinstance(value, float):\n\t        if not math.isfinite(value):\n\t            raise ValueError(\"Only finite floats (not Infinity or NaN) are supported\")\n\t        return {\"type\": \"float\", \"value\": value}\n\t    else:\n\t        try:\n\t            data = base64.b64encode(value).decode()\n\t            return {\"type\": \"blob\", \"base64\": data}\n\t        except TypeError:\n\t            raise TypeError(f\"Unsupported value of type {type(value)}\")\n", "_MIN_INTEGER = -(2**63)\n\t_MAX_INTEGER = 2**63 - 1\n\tdef _value_from_proto(value: proto.Value) -> Value:\n\t    if value[\"type\"] == \"null\":\n\t        return None\n\t    elif value[\"type\"] == \"text\":\n\t        return str(value[\"value\"])\n\t    elif value[\"type\"] == \"integer\":\n\t        return int(value[\"value\"])\n\t    elif value[\"type\"] == \"float\":\n", "        return float(value[\"value\"])\n\t    elif value[\"type\"] == \"blob\":\n\t        return base64.b64decode(value[\"base64\"] + \"====\")\n\t    else:\n\t        raise LibsqlError(f\"Unknown value type {value['type']!r}\", \"HRANA_PROTO_ERROR\")\n"]}
{"filename": "libsql_client/hrana/__init__.py", "chunked_list": ["from .client import _create_hrana_client\n\tfrom .client import HranaClient\n\tfrom .client import HranaStream\n\tfrom .client import HranaTransaction\n"]}
{"filename": "libsql_client/dbapi2/__main__.py", "chunked_list": ["import os\n\timport os.path\n\timport sys\n\targs = sys.argv[1:]\n\tenv = os.environ\n\tbootstrap_path = os.path.join(\n\t    os.path.dirname(__file__),\n\t    \"_replace_modules_pythonpath\",\n\t)\n\tif not args or args[0].lower() in (\"-h\", \"--help\", \"-?\"):\n", "    sys.stderr.write(\n\t        \"Usage:\\n\"\n\t        \"\\t<program> [program-args...]\\n\"\n\t        \"\\n\"\n\t        \"This will execute the python program transparently \"\n\t        \"replacing 'sqlite3' and 'sqlite3.dbapi2' imports with \"\n\t        \"'libsql_client.dbapi2' by adding \"\n\t        f\"'{bootstrap_path}' to $PYTHONPATH\"\n\t        \"\\n\"\n\t    )\n", "    sys.exit(0)\n\tpy_path = env.get(\"PYTHONPATH\", \"\")\n\tif not py_path:\n\t    py_path = bootstrap_path\n\telse:\n\t    py_path = os.pathsep.join([bootstrap_path, py_path])\n\tenv[\"LIBSQL_PYTHONPATH_BOOTSTRAP\"] = bootstrap_path\n\tenv[\"PYTHONPATH\"] = py_path\n\tos.execvpe(args[0], args, env)\n"]}
{"filename": "libsql_client/dbapi2/types.py", "chunked_list": ["from __future__ import annotations\n\tfrom abc import ABCMeta\n\tfrom abc import abstractmethod\n\timport collections\n\timport collections.abc\n\timport functools\n\timport logging\n\timport os\n\timport re\n\timport sqlite3.dbapi2\n", "from sqlite3.dump import _iterdump as sqlite3_iterdump\n\timport sys\n\timport threading\n\tfrom typing import Any\n\tfrom typing import Callable\n\tfrom typing import cast\n\tfrom typing import ClassVar\n\tfrom typing import Dict\n\tfrom typing import Iterable\n\tfrom typing import Iterator\n", "from typing import List\n\tfrom typing import NoReturn\n\tfrom typing import Optional\n\tfrom typing import overload\n\tfrom typing import Sequence\n\tfrom typing import Set\n\tfrom typing import Tuple\n\tfrom typing import TYPE_CHECKING\n\tfrom typing import TypeVar\n\tfrom typing import Union\n", "from weakref import WeakSet\n\tfrom typing_extensions import Literal\n\tfrom typing_extensions import ParamSpec\n\tfrom typing_extensions import Self\n\tfrom . import _reexports\n\tfrom ._reexports import DatabaseError\n\tfrom ._reexports import DataError\n\tfrom ._reexports import IntegrityError\n\tfrom ._reexports import InterfaceError\n\tfrom ._reexports import InternalError\n", "from ._reexports import NotSupportedError\n\tfrom ._reexports import OperationalError\n\tfrom ._reexports import ProgrammingError\n\tfrom ._reexports import SQLITE_LIMIT_SQL_LENGTH\n\tfrom ._utils import iter_sql_statements\n\tfrom ._utils import log_obj\n\tfrom ..client import LibsqlError\n\tfrom ..hrana import proto\n\tfrom ..hrana.convert import _value_from_proto\n\tif sys.version_info[:2] >= (3, 11):\n", "    from ._reexports import Blob\n\t_logger = logging.getLogger(__name__)\n\t_log_obj = functools.partial(log_obj, _logger)\n\tP = ParamSpec(\"P\")\n\tT = TypeVar(\"T\")\n\tif TYPE_CHECKING:\n\t    from sqlite3.dbapi2 import _Parameters as SqlParameters\n\t    from sqlite3.dbapi2 import _SqliteData as SqlData\n\telse:\n\t    SqlParameters = Any\n", "    SqlData = Any\n\tPathLike = Union[str, bytes, os.PathLike]\n\tIsolationLevel = Literal[\"\", \"DEFERRED\", \"EXCLUSIVE\", \"IMMEDIATE\"]\n\tisolation_level_set: Set[IsolationLevel] = {\n\t    \"\",\n\t    \"DEFERRED\",\n\t    \"EXCLUSIVE\",\n\t    \"IMMEDIATE\",\n\t}\n\tSqlNativeType = Union[None, int, float, str, bytes]\n", "ConnectionTypes = Union[sqlite3.dbapi2.Connection, \"Connection\"]\n\tConnectFactory = Callable[..., ConnectionTypes]\n\tCursorFactory = Callable[[\"Connection\"], \"Cursor\"]\n\tRowFactory = Callable[[\"Cursor\", Iterable[Any]], Any]\n\tTextFactory = Callable[[bytes], Any]\n\tConverterCallback = Callable[[Any], Any]\n\tAuthorizerCallback = Callable[..., int]  # SQLITE_OK, SQLITE_DENY, or SQLITE_IGNORE\n\tProgressHandler = Callable[[], int]\n\tTraceCallback = Callable[[str], None]\n\tBackupProgressCallback = Callable[[int, int, int], None]\n", "RawResults = proto.StmtResult\n\tRawColumn = proto.Col\n\tRawRow = List[proto.Value]\n\tLEGACY_TRANSACTION_CONTROL: Literal[-1] = -1\n\tAutocommit = Union[bool, Literal[-1]]\n\tdef _get_local_default_limits() -> Dict[int, int]:\n\t    if sys.version_info[:2] < (3, 11):\n\t        return {}\n\t    # while this doesn't make much sense, let's keep it compatible and\n\t    # allows tests to pass, such as checking if SQLITE_LIMIT_SQL_LENGTH\n", "    # is being enforced\n\t    with sqlite3.dbapi2.Connection(\":memory:\") as con:\n\t        categories = (\n\t            \"SQLITE_LIMIT_LENGTH\",\n\t            \"SQLITE_LIMIT_SQL_LENGTH\",\n\t            \"SQLITE_LIMIT_COLUMN\",\n\t            \"SQLITE_LIMIT_EXPR_DEPTH\",\n\t            \"SQLITE_LIMIT_COMPOUND_SELECT\",\n\t            \"SQLITE_LIMIT_VDBE_OP\",\n\t            \"SQLITE_LIMIT_FUNCTION_ARG\",\n", "            \"SQLITE_LIMIT_ATTACHED\",\n\t            \"SQLITE_LIMIT_LIKE_PATTERN_LENGTH\",\n\t            \"SQLITE_LIMIT_VARIABLE_NUMBER\",\n\t            \"SQLITE_LIMIT_TRIGGER_DEPTH\",\n\t            \"SQLITE_LIMIT_WORKER_THREADS\",\n\t        )\n\t        defaults = {}\n\t        for category in categories:\n\t            cat_id = getattr(_reexports, category)\n\t            defaults[cat_id] = con.getlimit(cat_id)\n", "        return defaults\n\t_default_limits = _get_local_default_limits()\n\tdef check_valid_autocommit(value: Any) -> Autocommit:\n\t    \":meta private:\"\n\t    if value is LEGACY_TRANSACTION_CONTROL or isinstance(value, bool):\n\t        return value\n\t    raise ValueError(\n\t        \"autocommit must be True, False, or \" \"sqlite3.LEGACY_TRANSACTION_CONTROL\"\n\t    )\n\t_callback_tracebacks: bool = False\n", "def enable_callback_tracebacks(flag: bool) -> None:\n\t    \"\"\"See :py:func:`sqlite3.enable_callback_tracebacks`\"\"\"\n\t    global _callback_tracebacks\n\t    _callback_tracebacks = flag\n\tclass RawExecuteResult:\n\t    \"\"\"Iterable over pairs of ``result, error``.\n\t    :meta private:\n\t    \"\"\"\n\t    results: List[Optional[RawResults]]\n\t    errors: List[Optional[BaseException]]\n", "    _idx: int\n\t    __slots__ = (\"results\", \"errors\", \"_idx\")\n\t    def __init__(\n\t        self,\n\t        results: List[Optional[RawResults]],\n\t        errors: List[Optional[BaseException]],\n\t    ) -> None:\n\t        assert len(results) == len(errors)\n\t        self.results = results\n\t        self.errors = errors\n", "        self._idx = 0\n\t    def __iter__(self) -> Self:\n\t        return self\n\t    def __next__(self) -> Tuple[Optional[RawResults], Optional[BaseException]]:\n\t        idx = self._idx\n\t        self._idx += 1\n\t        try:\n\t            return (self.results[idx], self.errors[idx])\n\t        except IndexError:\n\t            raise StopIteration\n", "class Statement:\n\t    \":meta private:\"\n\t    sql: str\n\t    tokens: Sequence[str]\n\t    is_dml: bool\n\t    is_ddl: bool\n\t    __slots__ = (\"sql\", \"tokens\", \"is_dml\", \"is_ddl\")\n\t    _dml_statements: ClassVar[Set[str]] = {\n\t        \"INSERT\",\n\t        \"UPDATE\",\n", "        \"DELETE\",\n\t        \"REPLACE\",\n\t    }\n\t    _ddl_statements: ClassVar[Set[str]] = {\n\t        \"CREATE\",\n\t        \"ALTER\",\n\t        \"DROP\",\n\t    }\n\t    @overload\n\t    def __init__(self, sql: str) -> None:\n", "        ...\n\t    @overload\n\t    def __init__(self, sql: str, _allow_instantiation: \"Connection\") -> None:\n\t        ...\n\t    def __init__(self, *args: object, **kwargs: object) -> None:\n\t        # NOTE do this to enable test_dbapi.py\n\t        # ModuleTests.test_disallow_instantiation(), it will call\n\t        # the connection to get a Statement, but the statement itself\n\t        # must not be instantiated directly.\n\t        # Test instantiates the result of: type(cx(\"select 1\"))\n", "        con = kwargs.get(\"_allow_instantiation\")\n\t        if not isinstance(con, Connection):\n\t            # matches check_disallow_instantiation() body\n\t            tp = self.__class__\n\t            mod = tp.__module__\n\t            name = tp.__name__\n\t            qualname = f\"{mod}.{name}\"\n\t            msg = f\"cannot create '{qualname}' instances\"\n\t            raise TypeError(msg)\n\t        assert len(args) == 1\n", "        sql = args[0]\n\t        if not isinstance(sql, str):\n\t            raise TypeError(\"sql must be a str\")\n\t        if \"\\0\" in sql:\n\t            raise ProgrammingError(\"the query contains a null character\")\n\t        if sys.version_info[:2] >= (3, 11):\n\t            if len(sql) > con.getlimit(SQLITE_LIMIT_SQL_LENGTH):\n\t                raise DataError(\"query string is too large\")\n\t        self.sql = sql\n\t        # see pysqlite_statement_create()\n", "        # https://github.com/python/cpython/blob/main/Modules/_sqlite/statement.c#L32\n\t        # however we need to parse the statement with iter_sql_statements()\n\t        # as we can't use sqlite3_prepare_v2()\n\t        itr = iter(iter_sql_statements(sql))\n\t        self.tokens = next(itr)\n\t        assert self.tokens\n\t        next_stmt = next(itr, None)\n\t        if next_stmt and next_stmt[0].upper() != \"END\":\n\t            msg = \"You can only execute one statement at a time.\"\n\t            raise ProgrammingError(msg)\n", "        self.is_dml = self._check_is_dml(self.tokens)\n\t        self.is_ddl = self._check_is_ddl(self.tokens)\n\t    @classmethod\n\t    def _check_is_dml(cls, tokens: Sequence[str]) -> bool:\n\t        # NOTE: this matches C pysqlite_statement_create()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/statement.c#L75-L82\n\t        # but it's not fully correct as the language allows: WITH ...\n\t        # See https://www.sqlite.org/lang_insert.html\n\t        # https://www.sqlite.org/lang_update.html\n\t        # https://www.sqlite.org/lang_delete.html\n", "        # Syntax:\n\t        #    WITH RECURSIVE table_name ( col_name, other_col)\n\t        #    AS NOT MATERIALIZED ( SELECT ... )\n\t        return tokens[0].upper() in cls._dml_statements\n\t    @classmethod\n\t    def _check_is_ddl(cls, tokens: Sequence[str]) -> bool:\n\t        return tokens[0].upper() in cls._ddl_statements\n\t    @property\n\t    def is_readonly(self) -> bool:\n\t        # mimics sqlite3_stmt_readonly()\n", "        return not self.is_dml and not self.is_ddl\n\tdef check_thread(fn: Callable[P, T]) -> Callable[P, T]:\n\t    \"\"\"Decorator that checks :py:class:`Connection` thread usage.\n\t    Otherwise raises ``ProgrammingError``.\n\t    :meta private:\n\t    \"\"\"\n\t    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n\t        self = args[0]\n\t        assert len(args) > 0 and isinstance(self, Connection)\n\t        self._do_check_thread()\n", "        return fn(*args, **kwargs)\n\t    return wrapper\n\tdef check_connection(fn: Callable[P, T]) -> Callable[P, T]:\n\t    \"\"\"Decorator that checks :py:class:`Connection` being valid.\n\t        Otherwise raises ``ProgrammingError``.\n\t    :meta private:\n\t    \"\"\"\n\t    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n\t        self = args[0]\n\t        assert len(args) > 0 and isinstance(self, Connection)\n", "        self._do_check_connection()\n\t        return fn(*args, **kwargs)\n\t    return wrapper\n\tclass Connection(metaclass=ABCMeta):\n\t    \"\"\"Implement :py:class:`sqlite3.Connection` for remote servers.\n\t    :meta private:\n\t    \"\"\"\n\t    _closed: bool\n\t    _thread: Optional[int]\n\t    _database: str\n", "    _timeout: float\n\t    _detect_types: int\n\t    _isolation_level: Optional[IsolationLevel]\n\t    _check_same_thread: bool\n\t    _cached_statement_getter: Callable[[str], Statement]\n\t    _in_transaction: bool\n\t    _cursors: WeakSet\n\t    _autocommit: Autocommit\n\t    _trace_callback: Optional[TraceCallback]\n\t    _limits: Dict[int, int]\n", "    row_factory: Optional[RowFactory]\n\t    text_factory: Optional[TextFactory]\n\t    cursor_factory: CursorFactory\n\t    def __init__(\n\t        self,\n\t        database: str,\n\t        timeout: float,\n\t        detect_types: int,\n\t        isolation_level: Optional[IsolationLevel],\n\t        check_same_thread: bool,\n", "        cached_statements: int,\n\t        autocommit: Autocommit,\n\t    ) -> None:\n\t        check_valid_autocommit(autocommit)  # required by test\n\t        self._closed = False\n\t        self._thread = threading.current_thread().ident\n\t        self._database = database\n\t        self._timeout = timeout\n\t        self._detect_types = detect_types\n\t        self._check_same_thread = check_same_thread\n", "        self._cached_statement_getter = functools.lru_cache(cached_statements)(\n\t            self.__call__\n\t        )\n\t        self._in_transaction = False\n\t        self._cursors = WeakSet()\n\t        self.row_factory = None\n\t        self.text_factory = None\n\t        self.cursor_factory = Cursor\n\t        self._autocommit = autocommit\n\t        self._trace_callback = None\n", "        self._limits = _default_limits.copy()\n\t        self.isolation_level = isolation_level\n\t        self._raw_init()  # after this point we can call the DB\n\t        if autocommit is False:\n\t            self.cursor()._query_execute(\"BEGIN\", want_rows=False)\n\t    @abstractmethod\n\t    def _raw_init(self) -> None:\n\t        raise NotImplementedError()\n\t    def __del__(self) -> None:\n\t        self._dbg(\"destroying\")\n", "        if getattr(self, \"_closed\", False):  # __init__() may have failed\n\t            try:\n\t                # do not check threads as the main thread reference may be\n\t                # gone before the executor executor thread\n\t                self._check_same_thread = False\n\t                self.close()\n\t            except Exception as e:\n\t                self._err(\"failed to close connection: %s\", e, exc_info=e)\n\t        self._inf(\"destroyed\")\n\t    def _do_check_thread(self) -> None:\n", "        # class may not be properly initialized, as in some unit tests\n\t        check = getattr(self, \"_check_same_thread\", None)\n\t        if check:\n\t            current_ident = threading.current_thread().ident\n\t            if self._thread != current_ident:\n\t                msg = (\n\t                    \"SQLite objects created in a thread can only be used \"\n\t                    \"in that same thread. \"\n\t                    \"The object was created in thread id \"\n\t                    \"%s and this is thread id %s.\" % (self._thread, current_ident)\n", "                )\n\t                raise ProgrammingError(msg)\n\t        elif check is None:\n\t            raise ProgrammingError(\"Base Connection.__init__ not called\")\n\t    def _do_check_connection(self) -> None:\n\t        # class may not be properly initialized, as in some unit tests\n\t        closed = getattr(self, \"_closed\", None)\n\t        if closed:\n\t            raise ProgrammingError(\"Cannot operate on a closed database.\")\n\t        elif closed is None:\n", "            raise ProgrammingError(\"Base Connection.__init__ not called\")\n\t    @check_connection\n\t    def __enter__(self) -> Self:\n\t        return self\n\t    def __exit__(\n\t        self,\n\t        exc_type: Any,\n\t        exc_value: Any,\n\t        traceback: Any,\n\t    ) -> Literal[False]:\n", "        # https://docs.python.org/3/library/sqlite3.html#how-to-use-the-connection-context-manager\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/connection.c#L2262\n\t        if exc_type is None:\n\t            self.commit()\n\t        else:\n\t            try:\n\t                self.rollback()\n\t            except Exception as e:  # TODO: is this explicitly needed?\n\t                raise e from exc_value\n\t        return False\n", "    @check_thread\n\t    @check_connection\n\t    def __call__(self, sql: str) -> Statement:\n\t        return Statement(sql, _allow_instantiation=self)\n\t    def __repr__(self) -> str:\n\t        return \"%s<%s>\" % (self.__class__.__name__, id(self))\n\t    @property\n\t    def _log_prefix(self) -> str:\n\t        idx = self._database.find(\"?\")\n\t        db = self._database if idx < 1 else self._database[:idx]\n", "        return \"%r: database=%r \" % (self, db)\n\t    _log = functools.partial(_log_obj)\n\t    _dbg = functools.partialmethod(_log, logging.DEBUG)\n\t    _inf = functools.partialmethod(_log, logging.INFO)\n\t    _err = functools.partialmethod(_log, logging.ERROR)\n\t    @property\n\t    def autocommit(self) -> Autocommit:\n\t        return self._autocommit\n\t    @autocommit.setter\n\t    def autocommit(self, value: Autocommit) -> None:\n", "        check_valid_autocommit(value)\n\t        if value is True:\n\t            if self._in_transaction:\n\t                self.cursor()._query_execute(\"COMMIT\", want_rows=False)\n\t        elif value is False:\n\t            if not self._in_transaction:\n\t                self.cursor()._query_execute(\"BEGIN\", want_rows=False)\n\t        self._autocommit = value\n\t    @property\n\t    @check_connection\n", "    def total_changes(self) -> int:\n\t        # I don't think we have a way to reliably implement it,\n\t        # but maybe incrementing based on cursors's rowcount will do\n\t        raise NotSupportedError()\n\t    @property\n\t    @check_connection\n\t    def in_transaction(self) -> bool:\n\t        # In C this is is retrieved from sqlite3_get_autocommit()\n\t        # here we try to emulate this behavior, see Cursor.execute()\n\t        # see pysqlite_connection_get_in_transaction()\n", "        # https://github.com/python/cpython/blob/main/Modules/_sqlite/connection.c#L1691\n\t        # see Connection._update_in_transaction()\n\t        return self._in_transaction\n\t    def _sqlite3_get_autocommit(self) -> bool:\n\t        # We don't have this, so we emulate based in in_transaction,\n\t        # which in C is implemented on top of sqlite3_get_autocommit(),\n\t        # here we reverse that logic.\n\t        # see pysqlite_connection_get_in_transaction()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/connection.c#L1691\n\t        return not self._in_transaction\n", "    @property\n\t    @check_connection\n\t    def isolation_level(self) -> Optional[IsolationLevel]:\n\t        return self._isolation_level\n\t    @isolation_level.setter\n\t    @check_connection\n\t    def isolation_level(self, level: Optional[IsolationLevel]) -> None:\n\t        if level is not None:\n\t            # required by RegressionTests.test_set_isolation_level()\n\t            if not isinstance(level, str):\n", "                raise TypeError(\"level must be a str\")\n\t            normalized_level = str(level).upper()\n\t            if normalized_level not in isolation_level_set:\n\t                raise ValueError(f\"unknown level: {normalized_level!r}\")\n\t            level = cast(Optional[IsolationLevel], normalized_level)\n\t        self._isolation_level = level\n\t        if level is None:\n\t            # Execute a COMMIT to re-enable autocommit mode\n\t            self.commit()\n\t    @overload\n", "    def cursor(self, factory: CursorFactory) -> \"Cursor\":\n\t        ...\n\t    @overload\n\t    def cursor(self) -> \"Cursor\":\n\t        ...\n\t    @check_thread\n\t    @check_connection\n\t    def cursor(\n\t        self,\n\t        *args: CursorFactory,\n", "        **kwargs: CursorFactory,\n\t    ) -> \"Cursor\":\n\t        if args:\n\t            factory = args[0]\n\t        elif \"factory\" in kwargs:\n\t            factory = kwargs[\"factory\"]\n\t        else:\n\t            factory = self.cursor_factory\n\t        if not callable(factory):\n\t            raise TypeError(\"factory must be callable\")\n", "        cursor = factory(self)\n\t        # While isinstance() should do,\n\t        # RowFactoryTests.test_fake_cursor_class() tests for a hack\n\t        # messing up with __class__\n\t        cur_tp = type(cursor)\n\t        if not issubclass(cur_tp, Cursor):\n\t            raise TypeError(\"factory must return a cursor\")\n\t        return cursor\n\t    def _add_cursor(self, cursor: \"Cursor\") -> None:\n\t        self._cursors.add(cursor)\n", "    def _remove_cursor(self, cursor: \"Cursor\") -> None:\n\t        self._cursors.discard(cursor)\n\t    def _get_statement(self, sql: str) -> Statement:\n\t        return self._cached_statement_getter(sql)\n\t    def _begin_transaction(self) -> None:\n\t        # see begin_transaction()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c#L476\n\t        assert self.isolation_level is not None\n\t        self.cursor()._query_execute(\n\t            f\"BEGIN {self.isolation_level}\",\n", "            want_rows=False,\n\t        )\n\t    def _begin_transaction_if_needed(self, statement: Statement) -> None:\n\t        # _pysqlite_query_execute()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c#L867-L877\n\t        if (\n\t            self._autocommit is LEGACY_TRANSACTION_CONTROL\n\t            and self.isolation_level is not None\n\t            and statement.is_dml\n\t            and self._sqlite3_get_autocommit()\n", "        ):\n\t            self._begin_transaction()\n\t    _begin_transaction_tokens: ClassVar[Set[str]] = {\"BEGIN\"}\n\t    _end_transaction_tokens: ClassVar[Set[str]] = {\"END\", \"COMMIT\", \"ROLLBACK\"}\n\t    def _update_in_transaction(self, statement: Statement) -> None:\n\t        # we cannot query sqlite3_get_autocommit(), then emulate\n\t        t = statement.tokens[0].upper()\n\t        if t in self._begin_transaction_tokens:\n\t            self._in_transaction = True\n\t        elif t in self._end_transaction_tokens:\n", "            self._in_transaction = False\n\t    @check_thread\n\t    @check_connection\n\t    def commit(self) -> None:\n\t        \"See :py:meth:`sqlite3.Connection.commit`\"\n\t        # See pysqlite_connection_commit_impl()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/connection.c#L634\n\t        if self._autocommit is LEGACY_TRANSACTION_CONTROL:\n\t            if not self._sqlite3_get_autocommit():\n\t                self.cursor()._query_execute(\"COMMIT\", want_rows=False)\n", "        elif self._autocommit is False:\n\t            c = self.cursor()\n\t            c._query_execute(\"COMMIT\", want_rows=False)\n\t            c._query_execute(\"BEGIN\", want_rows=False)\n\t    @check_thread\n\t    @check_connection\n\t    def rollback(self) -> None:\n\t        \"See :py:meth:`sqlite3.Connection.rollback`\"\n\t        # See pysqlite_connection_rollback_impl()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/connection.c#L668\n", "        if self._autocommit is LEGACY_TRANSACTION_CONTROL:\n\t            if not self._sqlite3_get_autocommit():\n\t                self.cursor()._query_execute(\"ROLLBACK\", want_rows=False)\n\t        elif self._autocommit is False:\n\t            c = self.cursor()\n\t            c._query_execute(\"ROLLBACK\", want_rows=False)\n\t            c._query_execute(\"BEGIN\", want_rows=False)\n\t    @abstractmethod\n\t    def _raw_close(self) -> None:\n\t        raise NotImplementedError()\n", "    @check_thread\n\t    def close(self) -> None:\n\t        \"See :py:meth:`sqlite3.Connection.close`\"\n\t        if self._closed:\n\t            return\n\t        if self._autocommit is False and not self._sqlite3_get_autocommit():\n\t            self.cursor()._query_execute(\"ROLLBACK\", want_rows=False)\n\t        self._dbg(\"closing %d cursors\", len(self._cursors))\n\t        for cursor in tuple(self._cursors):  # force a copy\n\t            cursor.close()\n", "        self._dbg(\"doing low level raw-close\")\n\t        self._raw_close()\n\t        self._dbg(\"finished low level raw-close\")\n\t        self._closed = True\n\t    def interrupt(self) -> None:\n\t        \"Does nothing\"\n\t        pass\n\t    def execute(\n\t        self,\n\t        sql: str,\n", "        parameters: SqlParameters = (),\n\t    ) -> \"Cursor\":\n\t        \"See :py:meth:`sqlite3.Connection.execute`\"\n\t        return self.cursor().execute(sql, parameters)\n\t    def executemany(\n\t        self,\n\t        sql: str,\n\t        parameters: Iterable[SqlParameters],\n\t    ) -> \"Cursor\":\n\t        \"See :py:meth:`sqlite3.Connection.executemany`\"\n", "        return self.cursor().executemany(sql, parameters)\n\t    def executescript(self, sql_script: str) -> \"Cursor\":\n\t        \"See :py:meth:`sqlite3.Connection.executescript`\"\n\t        return self.cursor().executescript(sql_script)\n\t    @check_connection\n\t    def iterdump(self) -> Iterator[str]:\n\t        \"See :py:meth:`sqlite3.Connection.iterdump`\"\n\t        return sqlite3_iterdump(self)\n\t    def _get_converter(self, key: str) -> Optional[ConverterCallback]:\n\t        # See _pysqlite_get_converter()\n", "        # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c#L186-L207\n\t        upcase_key = key.upper()\n\t        return sqlite3.converters.get(upcase_key)\n\t    @check_thread\n\t    @check_connection\n\t    def set_trace_callback(\n\t        self,\n\t        trace_callback: Optional[TraceCallback],\n\t    ) -> None:\n\t        \"See :py:meth:`sqlite3.Connection.set_trace_callback`\"\n", "        self._trace_callback = trace_callback\n\t    def _trace(self, sql: str) -> None:\n\t        if self._trace_callback is None:\n\t            return\n\t        try:\n\t            self._trace_callback(sql)\n\t        except Exception as e:\n\t            if _callback_tracebacks is False:\n\t                return\n\t            if sys.version_info[:2] >= (3, 8):\n", "                # this class is in sys.pyi but doesn't exist in runtime\n\t                class UnraisableHookArgs:\n\t                    exc_type = type(e)\n\t                    exc_value = e\n\t                    exc_traceback = e.__traceback__\n\t                    err_msg = f\"trace callback failed: {sql}\"\n\t                    object = self._trace_callback  # noqa: A003\n\t                sys.unraisablehook(UnraisableHookArgs())  # type: ignore\n\t            else:\n\t                self._dbg(\"trace callback failed: %r\", sql, exc_info=e)\n", "    # BEGIN: methods that are not supported when operating as RPC\n\t    if sys.version_info[:2] >= (3, 11):\n\t        def blobopen(\n\t            self,\n\t            table: str,\n\t            column: str,\n\t            row: str,\n\t            *,\n\t            readonly: bool = False,\n\t            name: str = \"main\",\n", "        ) -> Blob:\n\t            \"Unsupported by libsql_client.dbapi2\"\n\t            raise NotSupportedError()\n\t    def create_function(\n\t        self,\n\t        name: str,\n\t        narg: int,\n\t        func: Optional[Callable[..., SqlNativeType]],\n\t        *,\n\t        deterministic: bool = False,\n", "    ) -> None:\n\t        \"Unsupported by libsql_client.dbapi2\"\n\t        # maybe one day support with WASM\n\t        raise NotSupportedError()\n\t    def create_aggregate(\n\t        self,\n\t        name: str,\n\t        n_arg: int,\n\t        aggregate_class: Optional[Callable[..., Any]],\n\t    ) -> None:\n", "        \"Unsupported by libsql_client.dbapi2\"\n\t        # maybe one day support with WASM\n\t        raise NotSupportedError()\n\t    if sys.version_info[:2] >= (3, 11):\n\t        def create_window_function(\n\t            self,\n\t            name: str,\n\t            num_params: int,\n\t            aggregate_class: Optional[Callable[..., Any]],\n\t        ) -> None:\n", "            \"Unsupported by libsql_client.dbapi2\"\n\t            # maybe one day support with WASM\n\t            raise NotSupportedError()\n\t    def create_collation(\n\t        self,\n\t        name: str,\n\t        _callable: Optional[Callable[[str, str], int]],\n\t    ) -> None:\n\t        \"Unsupported by libsql_client.dbapi2\"\n\t        # maybe one day support with WASM\n", "        raise NotSupportedError()\n\t    def set_authorizer(\n\t        self,\n\t        authorizer_callback: Optional[AuthorizerCallback],\n\t    ) -> None:\n\t        \"Unsupported by libsql_client.dbapi2\"\n\t        # maybe one day support with WASM\n\t        raise NotSupportedError()\n\t    def set_progress_handler(\n\t        self,\n", "        progress_handler: Optional[ProgressHandler],\n\t        n: int,\n\t    ) -> None:\n\t        \"Unsupported by libsql_client.dbapi2\"\n\t        # not likely to be supported\n\t        raise NotSupportedError()\n\t    def enable_load_extension(self, enabled: bool) -> None:\n\t        \"Unsupported by libsql_client.dbapi2\"\n\t        # not likely to be supported\n\t        raise NotSupportedError()\n", "    def load_extension(self, path: str) -> None:\n\t        \"Unsupported by libsql_client.dbapi2\"\n\t        # not likely to be supported\n\t        raise NotSupportedError()\n\t    def backup(\n\t        self,\n\t        target: \"Connection\",\n\t        *,\n\t        pages: int = -1,\n\t        progress: Optional[BackupProgressCallback] = None,\n", "        name: str = \"main\",\n\t        sleep: float = 0.250,\n\t    ) -> None:\n\t        \"Unsupported by libsql_client.dbapi2\"\n\t        # not likely to be supported\n\t        raise NotSupportedError()\n\t    if sys.version_info[:2] >= (3, 11):\n\t        def getlimit(self, category: int) -> int:\n\t            \"Unsupported by libsql_client.dbapi2\"\n\t            try:\n", "                return self._limits[category]\n\t            except KeyError:\n\t                raise ProgrammingError(f\"unknown category: {category}\")\n\t        def setlimit(self, category: int, limit: int) -> int:\n\t            \"Unsupported by libsql_client.dbapi2\"\n\t            old = self.getlimit(category)\n\t            if limit >= 0:\n\t                self._limits[category] = limit\n\t            return old\n\t        def serialize(self, *, name: str = \"main\") -> bytes:\n", "            # not likely to be supported\n\t            \"Unsupported by libsql_client.dbapi2\"\n\t            raise NotSupportedError()\n\t        def deserialize(self, data: bytes, *, name: str = \"main\") -> None:\n\t            # not likely to be supported\n\t            # maybe use DatabaseError since it's declared in the original doc\n\t            \"Unsupported by libsql_client.dbapi2\"\n\t            raise NotSupportedError()\n\t    # END: methods that are not supported when operating as RPC\n\tCursorColumnDescription = Tuple[\n", "    str,  # name\n\t    None,  # type_code: sqlite also uses None in here\n\t    None,  # display_size\n\t    None,  # internal_size\n\t    None,  # precision\n\t    None,  # scale\n\t    None,  # null_ok\n\t]\n\tCursorDescription = Tuple[CursorColumnDescription, ...]\n\tRowCastMap = Tuple[Optional[ConverterCallback], ...]\n", "def tuple_row_factory(\n\t    cursor: \"Cursor\",\n\t    cells: Iterable[Any],\n\t) -> Tuple[Any, ...]:\n\t    \":meta private:\"\n\t    return tuple(cells)\n\tclass Row(collections.abc.Sequence):\n\t    \"\"\"Implement :py:class:`sqlite3.Row`\"\"\"\n\t    _description: CursorDescription\n\t    _data: Tuple[Any, ...]\n", "    __slots__ = (\"_description\", \"_data\")\n\t    def __init__(self, cursor: \"Cursor\", data: Iterable[Any]) -> None:\n\t        # While isinstance() should do,\n\t        # RowFactoryTests.test_fake_cursor_class() tests for a hack\n\t        # messing up with __class__\n\t        cur_tp = type(cursor)\n\t        if not issubclass(cur_tp, Cursor):\n\t            cls_name = self.__class__.__name__\n\t            cur_name = Cursor.__name__\n\t            got_name = type(cursor).__name__\n", "            msg = f\"{cls_name} argument 1 must be {cur_name}, not {got_name}\"\n\t            raise TypeError(msg)\n\t        description = getattr(cursor, \"description\", None)\n\t        if not description:\n\t            raise TypeError(\"cursor lacks description\")\n\t        self._description = description\n\t        self._data = tuple(data)\n\t    def __hash__(self) -> int:\n\t        return hash(self._description) ^ hash(self._data)\n\t    def __iter__(self) -> Iterator[Any]:\n", "        return iter(self._data)\n\t    def __len__(self) -> int:\n\t        return len(self._data)\n\t    def __eq__(self, other: object) -> bool:\n\t        if not isinstance(other, Row):\n\t            return False\n\t        if self._description != other._description:\n\t            return False\n\t        return self._data == other._data\n\t    def __getitem__(self, idx: Union[int, str, slice]) -> Any:\n", "        if isinstance(idx, (int, slice)):\n\t            return self._data[idx]\n\t        elif isinstance(idx, str):\n\t            idx_lower = idx.lower() if idx.isascii() else None\n\t            # similar to equal_ignore_case() in row.c,\n\t            # RowFactoryTests.test_sqlite_row_index_unicode checks this\n\t            for i, d in enumerate(self._description):\n\t                d_name = d[0]\n\t                if d_name == idx:\n\t                    return self._data[i]\n", "                if not isinstance(d_name, str):\n\t                    continue\n\t                if idx_lower is None or not d_name.isascii():\n\t                    continue\n\t                if idx_lower == d_name.lower():\n\t                    return self._data[i]\n\t            raise IndexError(\"No item with that key\")\n\t        else:\n\t            raise IndexError(\"Index must be int or string\")\n\t    def keys(self) -> List[str]:\n", "        return [d[0] for d in self._description]\n\tdef check_cursor(fn: Callable[P, T]) -> Callable[P, T]:\n\t    \"\"\"Decorator that checks :py:class:`Cursor` being valid\n\t    Otherwise raises ``ProgrammingError``.\n\t    :meta private:\n\t    \"\"\"\n\t    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n\t        self = args[0]\n\t        assert len(args) > 0 and isinstance(self, Cursor)\n\t        self._do_check_cursor()\n", "        return fn(*args, **kwargs)\n\t    return wrapper\n\t# https://github.com/python/cpython/blob/main/Modules/_sqlite/util.c#L28-L67C2\n\t_exc_code_map = {\n\t    \"SQLITE_INTERNAL\": InternalError,\n\t    \"SQL_INPUT_ERROR\": OperationalError,\n\t    \"SQLITE_NOTFOUND\": InternalError,\n\t    \"SQLITE_NOMEM\": MemoryError,\n\t    \"SQLITE_ERROR\": OperationalError,\n\t    \"SQLITE_PERM\": OperationalError,\n", "    \"SQLITE_ABORT\": OperationalError,\n\t    \"SQLITE_BUSY\": OperationalError,\n\t    \"SQLITE_LOCKED\": OperationalError,\n\t    \"SQLITE_READONLY\": OperationalError,\n\t    \"SQLITE_INTERRUPT\": OperationalError,\n\t    \"SQLITE_IOERR\": OperationalError,\n\t    \"SQLITE_FULL\": OperationalError,\n\t    \"SQLITE_CANTOPEN\": OperationalError,\n\t    \"SQLITE_PROTOCOL\": OperationalError,\n\t    \"SQLITE_EMPTY\": OperationalError,\n", "    \"SQLITE_SCHEMA\": OperationalError,\n\t    \"SQLITE_CORRUPT\": DatabaseError,\n\t    \"SQLITE_TOOBIG\": DataError,\n\t    \"SQLITE_CONSTRAINT\": IntegrityError,\n\t    \"SQLITE_MISMATCH\": IntegrityError,\n\t    \"SQLITE_MISUSE\": InterfaceError,\n\t    \"SQLITE_RANGE\": InterfaceError,\n\t    \"SQLITE_UNKNOWN\": OperationalError,\n\t    \"PROGRAMMING_ERROR\": ProgrammingError,\n\t    \"ARGS_INVALID\": ProgrammingError,\n", "    \"UNICODE_ERROR\": OperationalError,\n\t    \"VALUE_ERROR\": OperationalError,\n\t    \"UNKNOWN\": OperationalError,\n\t}\n\tdef _raise_converted_exception(exc: BaseException) -> NoReturn:\n\t    if not isinstance(exc, LibsqlError):\n\t        raise exc\n\t    code = exc.code\n\t    cls = None\n\t    while code and cls is None:\n", "        cls = _exc_code_map.get(code)\n\t        if cls is None and code.startswith(\"SQLITE_\"):\n\t            # fallback to mapped error, example:\n\t            # SQLITE_CONSTRAINT_UNIQUE -> SQLITE_CONSTRAINT\n\t            code = code.rsplit(\"_\", 1)[0]\n\t            if code == \"SQLITE\":\n\t                break\n\t        else:\n\t            break\n\t    if cls is None:\n", "        cls = DatabaseError\n\t    dbapi2_exc = cls(str(exc))\n\t    sqlite_errorcode = getattr(_reexports, exc.code, None)\n\t    dbapi2_exc.sqlite_errorname = exc.code  # type: ignore\n\t    dbapi2_exc.sqlite_errorcode = sqlite_errorcode  # type: ignore\n\t    raise dbapi2_exc from exc\n\tdef _get_value_bytes(value: proto.Value) -> Optional[bytes]:\n\t    # mimics https://www.sqlite.org/c3ref/column_blob.html\n\t    # usage in _pysqlite_fetch_one_row(), converter != Py_None branch at\n\t    # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c\n", "    v = _value_from_proto(value)\n\t    if v is None:\n\t        return None  # blob == NULL in their code\n\t    if isinstance(v, bytes):\n\t        return v\n\t    if isinstance(v, str):\n\t        return v.encode()\n\t    if isinstance(v, int):\n\t        return str(v).encode()  # ASCII rendering of the integer\n\t    if isinstance(v, float):\n", "        # https://www.sqlite.org/lang_expr.html#castexpr\n\t        return str(v).encode()  # converts to text\n\t    raise NotImplementedError(f\"cannot handle value type {type(v)}\")\n\tdef _get_value_converted(\n\t    value: proto.Value,\n\t    text_factory: Optional[TextFactory],\n\t) -> Any:\n\t    v = _value_from_proto(value)\n\t    if not isinstance(v, str) or text_factory is None or text_factory is str:\n\t        return v\n", "    b = v.encode()\n\t    if text_factory is bytes:\n\t        return b\n\t    return text_factory(b)\n\tclass Cursor(metaclass=ABCMeta):\n\t    \":meta private:\"\n\t    _connection: Connection\n\t    _description: Optional[CursorDescription]\n\t    _row_cast_map: Optional[RowCastMap]\n\t    arraysize: int\n", "    _lastrowid: Optional[int]\n\t    _rowcount: int\n\t    row_factory: Optional[RowFactory]\n\t    _rows: Optional[List[RawRow]]\n\t    _rows_iter_idx: int\n\t    _raw_results: Optional[RawExecuteResult]\n\t    _closed: bool\n\t    _locked: bool\n\t    __slots__ = (\n\t        \"_connection\",\n", "        \"_description\",\n\t        \"_row_cast_map\",\n\t        \"arraysize\",\n\t        \"_lastrowid\",\n\t        \"_rowcount\",\n\t        \"row_factory\",\n\t        \"_rows\",\n\t        \"_rows_iter_idx\",\n\t        \"_raw_results\",\n\t        \"_closed\",\n", "        \"_locked\",\n\t    )\n\t    def __init__(self, connection: Connection) -> None:\n\t        if not isinstance(connection, Connection):\n\t            # be safe, pass CursorTests.test_cursor_wrong_class\n\t            raise TypeError(\"connection must be instance of 'Connection'\")\n\t        self._connection = connection\n\t        self._connection._add_cursor(self)\n\t        self.arraysize = 1\n\t        self.row_factory = None\n", "        self._lastrowid = None  # not reset by _reset_result()\n\t        self._closed = False\n\t        self._locked = False\n\t        self._reset_result()\n\t    def __del__(self) -> None:\n\t        self._dbg(\"destroying\")\n\t        if getattr(self, \"_closed\", False):  # __init__() may have failed\n\t            try:\n\t                self.close()\n\t            except Exception as e:\n", "                self._err(\"failed to close cursor: %s\", e, exc_info=e)\n\t        self._dbg(\"destroyed\")\n\t    def __repr__(self) -> str:\n\t        return \"%s<%s>\" % (self.__class__.__name__, id(self))\n\t    @property\n\t    def _log_prefix(self) -> str:\n\t        return \"%r: connection=%r \" % (self, self._connection)\n\t    _log = functools.partial(_log_obj)\n\t    _dbg = functools.partialmethod(_log, logging.DEBUG)\n\t    _inf = functools.partialmethod(_log, logging.INFO)\n", "    _err = functools.partialmethod(_log, logging.ERROR)\n\t    def _do_check_cursor(self) -> None:\n\t        # class may not be properly initialized, as in some unit tests\n\t        closed = getattr(self, \"_closed\", None)\n\t        if closed:\n\t            raise ProgrammingError(\"Cannot operate on a closed cursor.\")\n\t        elif closed is None:\n\t            raise ProgrammingError(\"Base Cursor.__init__ not called.\")\n\t        self._connection._do_check_thread()\n\t        self._connection._do_check_connection()\n", "        self._do_check_locked()\n\t    def _do_check_locked(self) -> None:\n\t        # class may not be properly initialized, as in some unit tests\n\t        locked = getattr(self, \"_locked\", None)\n\t        if locked:\n\t            raise ProgrammingError(\"Recursive use of cursors not allowed\")\n\t        elif locked is None:\n\t            raise ProgrammingError(\"Base Cursor.__init__ not called.\")\n\t    def _reset_result(self, statement: Optional[Statement] = None) -> None:\n\t        is_dml = statement.is_dml if statement else False\n", "        self._description = None\n\t        self._row_cast_map = None\n\t        self._rowcount = 0 if is_dml else -1\n\t        self._rows = None\n\t        self._rows_iter_idx = 0\n\t        self._raw_results = None\n\t    @property\n\t    def connection(self) -> Connection:\n\t        \"Returns :py:class:`Connection`\"\n\t        return self._connection\n", "    @property\n\t    def description(self) -> Optional[CursorDescription]:\n\t        \"See :py:attr:`sqlite3.Cursor.description`\"\n\t        return self._description\n\t    @property\n\t    def lastrowid(self) -> Optional[int]:\n\t        \"See :py:attr:`sqlite3.Cursor.lastrowid`\"\n\t        return self._lastrowid\n\t    @property\n\t    def rowcount(self) -> int:\n", "        \"See :py:attr:`sqlite3.Cursor.rowcount`\"\n\t        return self._rowcount\n\t    @abstractmethod\n\t    def _raw_execute(\n\t        self,\n\t        sql: str,\n\t        parameters: Iterable[SqlParameters],\n\t        *,\n\t        want_rows: bool = True,\n\t    ) -> RawExecuteResult:\n", "        # each system should implement this one\n\t        raise NotImplementedError()\n\t    def _apply_raw_results(self, raw_results: RawResults) -> None:\n\t        row_id = raw_results[\"last_insert_rowid\"]\n\t        self._lastrowid = int(row_id) if row_id else None\n\t        if self._rowcount >= 0:  # -1 if not is_dml\n\t            self._rowcount += raw_results[\"affected_row_count\"]\n\t        self._apply_raw_results_description(raw_results)\n\t        self._apply_raw_results_rows(raw_results)\n\t    def _apply_raw_results_description(self, raw_results: RawResults) -> None:\n", "        columns = raw_results[\"cols\"]\n\t        if self._description is not None or len(columns) == 0:\n\t            return\n\t        description: List[CursorColumnDescription] = []\n\t        row_cast_map: List[Optional[ConverterCallback]] = []\n\t        for column in columns:\n\t            desc, cast_cb = self._get_column_description_and_cast(column)\n\t            description.append(desc)\n\t            row_cast_map.append(cast_cb)\n\t        self._description = tuple(description)\n", "        if row_cast_map.count(None) == len(row_cast_map):\n\t            self._row_cast_map = None\n\t        else:\n\t            self._row_cast_map = tuple(row_cast_map)\n\t    def _apply_raw_results_rows(self, raw_results: RawResults) -> None:\n\t        self._rows = raw_results[\"rows\"]\n\t        self._rows_iter_idx = 0\n\t    def _convert_row(self, row: RawRow) -> Any:\n\t        row_factory = (\n\t            self.row_factory or self.connection.row_factory or tuple_row_factory\n", "        )\n\t        return row_factory(self, self._get_cells(row))\n\t    def _get_cells(self, row: RawRow) -> Iterable[Any]:\n\t        # See _pysqlite_fetch_one_row()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c#L319\n\t        # https://docs.python.org/3/library/sqlite3.html#how-to-convert-sqlite-values-to-custom-python-types\n\t        cells = []\n\t        _row_cast_map = self._row_cast_map\n\t        text_factory = self.connection.text_factory\n\t        for i, v in enumerate(row):\n", "            if _row_cast_map is not None:\n\t                converter = _row_cast_map[i]\n\t            else:\n\t                converter = None\n\t            if converter is not None:\n\t                item = _get_value_bytes(v)\n\t                if item:\n\t                    converted = converter(item)\n\t                else:\n\t                    converted = None\n", "            else:\n\t                converted = _get_value_converted(v, text_factory)\n\t            cells.append(converted)\n\t        return cells\n\t    _row_colname_parser_re = re.compile(\n\t        r\"^(?P<name>[^[]+)\\s*\\[(?P<type_name>[^]]+)\\]\",\n\t    )\n\t    _row_decltype_parser_re = re.compile(r\"^(?P<type_name>[^ (]+)\")\n\t    def _get_column_description_and_cast(\n\t        self,\n", "        col: RawColumn,\n\t    ) -> Tuple[CursorColumnDescription, Optional[ConverterCallback]]:\n\t        name = col.get(\"name\") or \"\"\n\t        converter: Optional[ConverterCallback] = None\n\t        detect_types = self.connection._detect_types\n\t        get_converter = self.connection._get_converter\n\t        if detect_types & sqlite3.PARSE_COLNAMES:\n\t            m = self._row_colname_parser_re.match(name)\n\t            if m is not None:\n\t                name = m.group(\"name\").strip()\n", "                type_name = m.group(\"type_name\")\n\t                converter = get_converter(type_name)\n\t        if not converter and detect_types & sqlite3.PARSE_DECLTYPES:\n\t            decltype = col.get(\"decltype\") or \"\"\n\t            m = self._row_decltype_parser_re.match(decltype)\n\t            if m is not None:\n\t                type_name = m.group(\"type_name\")\n\t                converter = get_converter(type_name)\n\t        return ((name, None, None, None, None, None, None), converter)\n\t    _no_adapt_types = (int, float, str, bytes, bytearray, memoryview)\n", "    def _adapt_param_value(self, obj: Any) -> SqlData:\n\t        # see need_adapt(), but we can't optimize on BaseTypeAdapted\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c#L614-L627\n\t        try:\n\t            t = type(obj)\n\t            # See pysqlite_microprotocols_adapt()\n\t            # https://github.com/python/cpython/blob/main/Modules/_sqlite/microprotocols.c\n\t            # https://peps.python.org/pep-0246/\n\t            proto = sqlite3.PrepareProtocol\n\t            key = (t, proto)\n", "            adapter = sqlite3.adapters.get(key)\n\t            if adapter is not None:\n\t                return adapter(obj)\n\t            # try to have the protocol adapt this object\n\t            adapter = getattr(proto, \"___adapt__\", None)\n\t            if adapter is not None:\n\t                adapted = adapter(obj)\n\t                if adapted is not None:\n\t                    return adapted\n\t            # and finally try to have the object adapt itself\n", "            adapter = getattr(obj, \"__conform__\", None)\n\t            if adapter is not None:\n\t                adapted = adapter(proto)\n\t                if adapted is not None:\n\t                    return adapted\n\t            if obj is None:\n\t                return obj\n\t            if not isinstance(obj, self._no_adapt_types):\n\t                memoryview(obj)  # TypeError if not bytes-like\n\t                return obj\n", "            return obj\n\t        except TypeError:\n\t            raise ProgrammingError(\"can't adapt\")\n\t    def _adapt_params(self, parameters: SqlParameters) -> SqlParameters:\n\t        if isinstance(parameters, collections.abc.Mapping):\n\t            return {k: self._adapt_param_value(v) for k, v in parameters.items()}\n\t        elif parameters:\n\t            # SupportsLenAndGetItem is only __len__ + __getitem__, no __iter__\n\t            # so create the list manually :-(\n\t            return [\n", "                self._adapt_param_value(parameters[i]) for i in range(len(parameters))\n\t            ]\n\t        return parameters\n\t    @check_cursor\n\t    def _query_execute(\n\t        self,\n\t        sql: str,\n\t        parameters: Iterable[SqlParameters] = ((),),\n\t        *,\n\t        multiple: bool = False,\n", "        want_rows: bool = True,\n\t    ) -> Self:\n\t        if not isinstance(sql, str):\n\t            # required by test CursorTests.test_execute_many_wrong_sql_arg()\n\t            raise TypeError(\"sql must be a str\")\n\t        if not sql:\n\t            return self\n\t        params = tuple(self._adapt_params(p) for p in parameters)\n\t        # See _pysqlite_query_execute()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c#L781\n", "        try:\n\t            self._dbg(\"execute: %r, %r\", sql, params)\n\t            statement = self._connection._get_statement(sql)\n\t            if multiple and statement.is_readonly:\n\t                msg = \"executemany() can only execute DML statements.\"\n\t                raise ProgrammingError(msg)\n\t            self._reset_result(statement)\n\t            self._connection._begin_transaction_if_needed(statement)\n\t            # Locking is not that meaningful with libsql_client since\n\t            # we don't callback to python during execution as done by\n", "            # create_function() and the likes. Nevertheless keep it here\n\t            # NOTE: _begin_transaction_if_needed() will call this function\n\t            # so do not lock before this point!\n\t            self._locked = True\n\t            self._raw_results = self._raw_execute(\n\t                sql,\n\t                params,\n\t                want_rows=want_rows,\n\t            )\n\t            for result, error in self._raw_results:\n", "                if error is not None:\n\t                    self._rowcount = -1  # as per cursor.c\n\t                    _raise_converted_exception(error)\n\t                assert result is not None\n\t                self._apply_raw_results(result)\n\t            self._connection._update_in_transaction(statement)\n\t            return self\n\t        finally:\n\t            self._locked = False\n\t    def execute(\n", "        self,\n\t        sql: str,\n\t        parameters: SqlParameters = (),\n\t    ) -> Self:\n\t        \"See :py:meth:`sqlite3.Cursor.execute`\"\n\t        if not isinstance(parameters, collections.abc.Mapping) and not (\n\t            hasattr(parameters, \"__len__\") and hasattr(parameters, \"__getitem__\")\n\t        ):\n\t            raise ProgrammingError(\"parameters are of unsupported type\")\n\t        self._query_execute(sql, (parameters,), multiple=False, want_rows=True)\n", "        return self\n\t    def executemany(\n\t        self,\n\t        sql: str,\n\t        parameters: Iterable[SqlParameters],\n\t    ) -> Self:\n\t        \"See :py:meth:`sqlite3.Cursor.executemany`\"\n\t        self._query_execute(sql, parameters, multiple=True, want_rows=False)\n\t        return self\n\t    @abstractmethod\n", "    def _raw_execute_script(self, sql_script: str) -> None:\n\t        raise NotImplementedError()\n\t    @check_cursor\n\t    def executescript(self, sql_script: str) -> Self:\n\t        \"See :py:meth:`sqlite3.Cursor.executescript`\"\n\t        # See pysqlite_cursor_executescript_impl()\n\t        # https://github.com/python/cpython/blob/main/Modules/_sqlite/cursor.c#L1046-L1060\n\t        if self._connection._autocommit is LEGACY_TRANSACTION_CONTROL:\n\t            if not self._connection._sqlite3_get_autocommit():\n\t                self._query_execute(\"COMMIT\", want_rows=False)\n", "        self._raw_execute_script(sql_script)\n\t        return self\n\t    def __iter__(self) -> Self:\n\t        return self\n\t    @check_cursor\n\t    def __next__(self) -> Any:\n\t        # TODO: we're just doing a single raw_results in a batch,\n\t        # seems to match the behavior when calling executemany() (\"multiple\")\n\t        if self._rows is None:\n\t            raise StopIteration\n", "        idx = self._rows_iter_idx\n\t        self._rows_iter_idx += 1\n\t        try:\n\t            row = self._rows[idx]\n\t        except IndexError:\n\t            raise StopIteration\n\t        try:\n\t            self._locked = True\n\t            return self._convert_row(row)\n\t        finally:\n", "            self._locked = False\n\t    def fetchone(self) -> Any:\n\t        \"See :py:meth:`sqlite3.Cursor.fetchone`\"\n\t        return next(self, None)\n\t    def fetchmany(self, size: Optional[int] = None) -> List[Any]:\n\t        \"See :py:meth:`sqlite3.Cursor.fetchmany`\"\n\t        if size is None or size < 1:\n\t            assert self.arraysize > 0\n\t            size = self.arraysize\n\t        result = []\n", "        for i, row in enumerate(self):\n\t            if i == size:\n\t                break\n\t            result.append(row)\n\t        return result\n\t    def fetchall(self) -> List[Any]:\n\t        \"See :py:meth:`sqlite3.Cursor.fetchall`\"\n\t        return list(self)\n\t    @abstractmethod\n\t    def _raw_close(self) -> None:\n", "        raise NotImplementedError()\n\t    def close(self) -> None:\n\t        \"See :py:meth:`sqlite3.Cursor.close`\"\n\t        # class may not be properly initialized, as in some unit tests\n\t        closed = getattr(self, \"_closed\", None)\n\t        if closed:\n\t            return\n\t        self._do_check_locked()\n\t        self._connection._do_check_thread()\n\t        self._connection._do_check_connection()\n", "        self.connection._remove_cursor(self)\n\t        self._closed = True\n\t        self._reset_result()\n\t        self._raw_close()\n\t    def setinputsizes(self, sizes: Any) -> None:\n\t        \"Does nothing\"\n\t        # Required by the DB-API. Does nothing in sqlite3.\n\t        pass\n\t    def setoutputsize(self, size: int, column: Any = None) -> None:\n\t        \"Does nothing\"\n", "        # Required by the DB-API. Does nothing in sqlite3.\n\t        pass\n"]}
{"filename": "libsql_client/dbapi2/hrana.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport collections.abc\n\timport sqlite3.dbapi2\n\timport sys\n\tfrom typing import Awaitable\n\tfrom typing import Callable\n\tfrom typing import Iterable\n\tfrom typing import List\n\tfrom typing import Optional\n", "from typing import overload\n\tfrom typing import Tuple\n\tfrom typing import Type\n\tfrom typing import TYPE_CHECKING\n\tfrom typing import TypeVar\n\timport aiohttp\n\tfrom typing_extensions import ParamSpec\n\tfrom ._async_executor import AsyncExecutor\n\tfrom .types import Autocommit\n\tfrom .types import Connection\n", "from .types import Cursor\n\tfrom .types import IsolationLevel\n\tfrom .types import LEGACY_TRANSACTION_CONTROL\n\tfrom .types import OperationalError\n\tfrom .types import RawExecuteResult\n\tfrom .types import SqlParameters\n\tfrom ..client import LibsqlError\n\tfrom ..config import _expand_config\n\tfrom ..hrana.client import _config_to_url\n\tfrom ..hrana.conn import HranaConn\n", "from ..hrana.conn import HranaStream\n\tfrom ..hrana.convert import _error_from_proto\n\tfrom ..hrana.convert import _value_to_proto\n\tfrom ..hrana.proto import Batch\n\tfrom ..hrana.proto import BatchResult\n\tfrom ..hrana.proto import BatchStep\n\tfrom ..hrana.proto import Error as ErrorResult\n\tfrom ..hrana.proto import Stmt\n\tfrom ..hrana.proto import StmtResult\n\t# TODO: we're creating a whole sync client for each connection, but we\n", "# could create a single thread for all connections of the same URL,\n\t# with a single HranaClient/HranaConn, and just get a HranaStream.\n\t# But this requires us to change ClientSync and other stuff, will\n\t# do it later.\n\tP = ParamSpec(\"P\")\n\tT = TypeVar(\"T\")\n\tdef _create_hrana_connection(\n\t    session: aiohttp.ClientSession,\n\t    url: str,\n\t) -> HranaConn:\n", "    config = _expand_config(url, auth_token=None, tls=None)\n\t    try:\n\t        if config.scheme not in (\"ws\", \"wss\"):\n\t            raise LibsqlError(\n\t                \"Only 'libsql', 'ws' and 'wss' URLs are supported,\"\n\t                f\" got {config.scheme!r}\",\n\t                \"URL_INVALID\",\n\t            )\n\t        url = _config_to_url(config)\n\t    except LibsqlError as e:\n", "        if e.code == \"URL_INVALID\":\n\t            sqlite_err = OperationalError(str(e))\n\t            sqlite_err.sqlite_errorcode = 14  # type: ignore\n\t            sqlite_err.sqlite_errorname = \"SQLITE_CANTOPEN\"  # type: ignore\n\t            raise sqlite_err\n\t        raise\n\t    return HranaConn(session, url, config.auth_token)\n\tdef _conv_stmt_plain_to_stored(stmt: Stmt, sql_id: int) -> Stmt:\n\t    del stmt[\"sql\"]\n\t    stmt[\"sql_id\"] = sql_id\n", "    return stmt\n\tdef _conv_stmt(\n\t    sql: str,\n\t    parameters: SqlParameters,\n\t    want_rows: bool,\n\t) -> Stmt:\n\t    stmt: Stmt = {\n\t        \"sql\": sql,\n\t        \"want_rows\": want_rows,\n\t    }\n", "    if isinstance(parameters, collections.abc.Mapping):\n\t        stmt[\"named_args\"] = [\n\t            {\"name\": k, \"value\": _value_to_proto(v)} for k, v in parameters.items()\n\t        ]\n\t    elif parameters:\n\t        # SupportsLenAndGetItem is only __len__ + __getitem__, no __iter__\n\t        # so create the list manually :-(\n\t        args = []\n\t        for i in range(len(parameters)):\n\t            args.append(_value_to_proto(parameters[i]))\n", "        stmt[\"args\"] = args\n\t    return stmt\n\tdef _conv_stmts(\n\t    sql: str,\n\t    parameters: Iterable[SqlParameters],\n\t    want_rows: bool,\n\t) -> List[Stmt]:\n\t    return [_conv_stmt(sql, p, want_rows) for p in parameters]\n\t_aiohttp_error_map = (\n\t    (aiohttp.InvalidURL, \"SQLITE_CANTOPEN\"),\n", "    (aiohttp.ClientConnectionError, \"SQLITE_CANTOPEN\"),\n\t    (aiohttp.ClientResponseError, \"SQLITE_CANTOPEN\"),\n\t    (aiohttp.ClientPayloadError, \"SQLITE_IOERR\"),\n\t)\n\tdef _get_aiohttp_client_error_code(\n\t    error: aiohttp.ClientError,\n\t) -> Tuple[int, str]:\n\t    for error_cls, error_name in _aiohttp_error_map:\n\t        if isinstance(error, error_cls):\n\t            error_code = getattr(sqlite3.dbapi2, error_name)\n", "            return error_code, error_name\n\t    return 0, \"\"\n\tdef _conv_stmt_result(\n\t    result: Optional[StmtResult],\n\t    error: Optional[BaseException],\n\t) -> RawExecuteResult:\n\t    if isinstance(error, aiohttp.ClientError):\n\t        code, name = _get_aiohttp_client_error_code(error)\n\t        error = OperationalError(str(error))\n\t        if code:\n", "            error.sqlite_errorcode = code  # type: ignore\n\t            error.sqlite_errorname = name  # type: ignore\n\t    return RawExecuteResult([result], [error])\n\tdef _conv_batch(stmts: List[Stmt]) -> Batch:\n\t    steps: List[BatchStep] = []\n\t    for i, stmt in enumerate(stmts):\n\t        if i == 0:\n\t            steps.append({\"stmt\": stmt})\n\t        else:\n\t            steps.append(\n", "                {\n\t                    \"condition\": {\"type\": \"ok\", \"step\": i - 1},\n\t                    \"stmt\": stmt,\n\t                }\n\t            )\n\t    return {\"steps\": steps}\n\tdef _conv_batch_result(resp: BatchResult) -> RawExecuteResult:\n\t    def conv_err(e: Optional[ErrorResult]) -> Optional[BaseException]:\n\t        if e is None:\n\t            return None\n", "        return _error_from_proto(e)\n\t    errors = [conv_err(e) for e in resp[\"step_errors\"]]\n\t    return RawExecuteResult(resp[\"step_results\"], errors)\n\tif TYPE_CHECKING:\n\t    if sys.version_info[:2] >= (3, 9):\n\t        @overload\n\t        def run_in_executor(\n\t            fn: Callable[P, Awaitable[asyncio.Future[T]]],\n\t        ) -> Callable[P, T]:\n\t            ...\n", "    @overload\n\t    def run_in_executor(fn: Callable[P, Awaitable[T]]) -> Callable[P, T]:\n\t        ...\n\t    @overload\n\t    def run_in_executor(fn: Callable[P, T]) -> Callable[P, T]:\n\t        ...\n\tdef run_in_executor(fn: Callable[P, T]) -> Callable[P, T]:\n\t    \"\"\"ConnectionHrana method decorator that runs code in the executor thread.\n\t    This will execute the decorated method body inside the\n\t    :py:class:`AsyncExecutor` thread by doing a ``AsyncExecutor.submit()``\n", "    and then ``future.result(timeout)``.\n\t    The method itself will block until the executor runs.\n\t    :meta private:\n\t    \"\"\"\n\t    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n\t        self = args[0]\n\t        assert isinstance(self, ConnectionHrana)\n\t        assert self._executor is not None\n\t        future = self._executor.submit(fn, *args, **kwargs)\n\t        return future.result(timeout=self._timeout)\n", "    return wrapper\n\tclass ConnectionHrana(Connection):\n\t    \"\"\"Implement :py:class:`sqlite3.Connection` for remote servers\n\t    using the `Hrana Protocol\n\t    <https://github.com/libsql/sqld/blob/main/docs/HRANA_2_SPEC.md>`_.\n\t    \"\"\"\n\t    _executor: Optional[AsyncExecutor]  # TODO: share\n\t    _session: Optional[aiohttp.ClientSession]  # TODO: share (per url)\n\t    _conn: Optional[HranaConn]  # TODO: share (per url)\n\t    _stream: Optional[HranaStream]\n", "    cursor_factory: Type[\"CursorHrana\"]\n\t    def __init__(\n\t        self,\n\t        database: str,\n\t        timeout: float = 5.0,\n\t        detect_types: int = 0,\n\t        isolation_level: Optional[IsolationLevel] = \"\",\n\t        check_same_thread: bool = True,\n\t        cached_statements: int = 128,\n\t        uri: bool = False,\n", "        autocommit: Autocommit = LEGACY_TRANSACTION_CONTROL,\n\t    ) -> None:\n\t        assert uri\n\t        super().__init__(\n\t            database=database,\n\t            timeout=timeout,\n\t            detect_types=detect_types,\n\t            isolation_level=isolation_level,\n\t            check_same_thread=check_same_thread,\n\t            cached_statements=cached_statements,\n", "            autocommit=autocommit,\n\t        )\n\t    def _raw_init(self) -> None:\n\t        self.cursor_factory = CursorHrana\n\t        try:\n\t            self._executor = self._acquire_executor()\n\t            self._session = self._acquire_session()\n\t            self._conn = self._acquire_connection(self._database)\n\t            self._stream = self._create_stream()\n\t        except Exception:\n", "            self._raw_close()\n\t            raise\n\t    def _acquire_executor(self) -> AsyncExecutor:\n\t        return AsyncExecutor()  # TODO: share\n\t    def _dispose_executor(self, executor: AsyncExecutor) -> None:\n\t        executor.shutdown()  # TODO: share\n\t    @run_in_executor\n\t    def _acquire_session(self) -> aiohttp.ClientSession:\n\t        return aiohttp.ClientSession()  # TODO: share\n\t    @run_in_executor\n", "    async def _dispose_session(self, session: aiohttp.ClientSession) -> None:\n\t        await session.close()  # TODO: share\n\t    @run_in_executor\n\t    async def _acquire_connection(self, url: str) -> HranaConn:\n\t        assert self._session is not None\n\t        # TODO: share (per url)\n\t        conn = _create_hrana_connection(self._session, url)\n\t        try:\n\t            await conn.wait_connected()\n\t            return conn\n", "        except Exception as error:\n\t            await conn.close()\n\t            exc = _conv_stmt_result(None, error).errors[0]\n\t            assert exc is not None  # make mypy happy\n\t            raise exc\n\t    @run_in_executor\n\t    async def _dispose_connection(self, conn: HranaConn) -> None:\n\t        await conn.close()  # TODO: share (per url)\n\t    @run_in_executor\n\t    def _create_stream(self) -> HranaStream:\n", "        assert self._conn is not None\n\t        stream = self._conn.open_stream()\n\t        self._inf(\"created stream: %s\", stream)\n\t        return stream\n\t    @run_in_executor\n\t    def _destroy_stream(self, stream: HranaStream) -> None:\n\t        self._inf(\"closing stream: %s\", stream)\n\t        stream.close()\n\t    @run_in_executor\n\t    def _raw_execute(self, stmt: Stmt) -> asyncio.Future[StmtResult]:\n", "        assert self._stream is not None\n\t        return self._stream.execute(stmt)\n\t    @run_in_executor\n\t    def _raw_store_sql(self, sql: str) -> int:\n\t        assert self._conn is not None\n\t        return self._conn.store_sql(sql)\n\t    @run_in_executor\n\t    def _raw_close_sql(self, sql_id: int) -> None:\n\t        assert self._conn is not None\n\t        return self._conn.close_sql(sql_id)\n", "    @run_in_executor\n\t    def _raw_execute_script(self, sql_script: str) -> asyncio.Future[None]:\n\t        assert self._stream is not None\n\t        return self._stream.sequence(sql_script)\n\t    @run_in_executor\n\t    def _raw_batch(self, batch: Batch) -> asyncio.Future[BatchResult]:\n\t        assert self._stream is not None\n\t        return self._stream.batch(batch)\n\t    def _raw_close(self) -> None:\n\t        # use of getattr as the object may fail init\n", "        stream = getattr(self, \"_stream\", None)\n\t        if stream is not None:\n\t            self._destroy_stream(stream)\n\t            self._stream = None\n\t        conn = getattr(self, \"_conn\", None)\n\t        if conn is not None:\n\t            self._dispose_connection(conn)\n\t            self._conn = None\n\t        session = getattr(self, \"_session\", None)\n\t        if session is not None:\n", "            self._dispose_session(session)\n\t            self._session = None\n\t        executor = getattr(self, \"_executor\", None)\n\t        if executor is not None:\n\t            self._dispose_executor(executor)\n\t            self._executor = None\n\tclass CursorHrana(Cursor):\n\t    \"\"\"Implement :py:class:`sqlite3.Cursor` for remote servers\n\t    using the `Hrana Protocol\n\t    <https://github.com/libsql/sqld/blob/main/docs/HRANA_2_SPEC.md>`_.\n", "    \"\"\"\n\t    connection: ConnectionHrana\n\t    def _raw_execute_one(self, stmt: Stmt) -> RawExecuteResult:\n\t        try:\n\t            if self.connection._trace_callback is not None:\n\t                self.connection._trace(stmt[\"sql\"])\n\t            result = self.connection._raw_execute(stmt)\n\t            return _conv_stmt_result(result, None)\n\t        except Exception as error:\n\t            return _conv_stmt_result(None, error)\n", "    def _raw_execute_multiple(self, stmts: List[Stmt]) -> RawExecuteResult:\n\t        sql_id = None\n\t        try:\n\t            sql = stmts[0][\"sql\"]\n\t            sql_id = self.connection._raw_store_sql(sql)\n\t            assert sql_id is not None  # keep mypy happy\n\t            stored_stmts: List[Stmt] = [\n\t                _conv_stmt_plain_to_stored(stmt, sql_id) for stmt in stmts\n\t            ]\n\t            result = self.connection._raw_batch(_conv_batch(stored_stmts))\n", "            if self.connection._trace_callback is not None:\n\t                for stmt in stmts:\n\t                    self.connection._trace(sql)\n\t            return _conv_batch_result(result)\n\t        except Exception as error:\n\t            return _conv_stmt_result(None, error)\n\t        finally:\n\t            if sql_id is not None:\n\t                try:\n\t                    self.connection._raw_close_sql(sql_id)\n", "                except Exception:\n\t                    pass\n\t    def _raw_execute(\n\t        self,\n\t        sql: str,\n\t        parameters: Iterable[SqlParameters],\n\t        *,\n\t        want_rows: bool = True,\n\t    ) -> RawExecuteResult:\n\t        stmts = _conv_stmts(sql, parameters, want_rows)\n", "        if len(stmts) == 1:\n\t            return self._raw_execute_one(stmts[0])\n\t        elif len(stmts) > 1:\n\t            return self._raw_execute_multiple(stmts)\n\t        else:\n\t            return RawExecuteResult([], [])\n\t    def _raw_execute_script(self, sql_script: str) -> None:\n\t        self.connection._raw_execute_script(sql_script)\n\t    def _raw_close(self) -> None:\n\t        pass  # TODO: should we do anything specific?\n"]}
{"filename": "libsql_client/dbapi2/_reexports.py", "chunked_list": ["from sqlite3.dbapi2 import adapt\n\tfrom sqlite3.dbapi2 import adapters\n\tfrom sqlite3.dbapi2 import apilevel\n\tfrom sqlite3.dbapi2 import Binary\n\tfrom sqlite3.dbapi2 import complete_statement\n\tfrom sqlite3.dbapi2 import converters\n\tfrom sqlite3.dbapi2 import DatabaseError\n\tfrom sqlite3.dbapi2 import DataError\n\tfrom sqlite3.dbapi2 import Date\n\tfrom sqlite3.dbapi2 import DateFromTicks\n", "from sqlite3.dbapi2 import Error\n\tfrom sqlite3.dbapi2 import IntegrityError\n\tfrom sqlite3.dbapi2 import InterfaceError\n\tfrom sqlite3.dbapi2 import InternalError\n\tfrom sqlite3.dbapi2 import NotSupportedError\n\tfrom sqlite3.dbapi2 import OperationalError\n\tfrom sqlite3.dbapi2 import paramstyle\n\tfrom sqlite3.dbapi2 import PARSE_COLNAMES\n\tfrom sqlite3.dbapi2 import PARSE_DECLTYPES\n\tfrom sqlite3.dbapi2 import PrepareProtocol\n", "from sqlite3.dbapi2 import ProgrammingError\n\tfrom sqlite3.dbapi2 import register_adapter\n\tfrom sqlite3.dbapi2 import register_converter\n\tfrom sqlite3.dbapi2 import SQLITE_ALTER_TABLE\n\tfrom sqlite3.dbapi2 import SQLITE_ANALYZE\n\tfrom sqlite3.dbapi2 import SQLITE_ATTACH\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_INDEX\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_TABLE\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_TEMP_INDEX\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_TEMP_TABLE\n", "from sqlite3.dbapi2 import SQLITE_CREATE_TEMP_TRIGGER\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_TEMP_VIEW\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_TRIGGER\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_VIEW\n\tfrom sqlite3.dbapi2 import SQLITE_CREATE_VTABLE\n\tfrom sqlite3.dbapi2 import SQLITE_DELETE\n\tfrom sqlite3.dbapi2 import SQLITE_DENY\n\tfrom sqlite3.dbapi2 import SQLITE_DETACH\n\tfrom sqlite3.dbapi2 import SQLITE_DONE\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_INDEX\n", "from sqlite3.dbapi2 import SQLITE_DROP_TABLE\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_TEMP_INDEX\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_TEMP_TABLE\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_TEMP_TRIGGER\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_TEMP_VIEW\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_TRIGGER\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_VIEW\n\tfrom sqlite3.dbapi2 import SQLITE_DROP_VTABLE\n\tfrom sqlite3.dbapi2 import SQLITE_FUNCTION\n\tfrom sqlite3.dbapi2 import SQLITE_IGNORE\n", "from sqlite3.dbapi2 import SQLITE_INSERT\n\tfrom sqlite3.dbapi2 import SQLITE_OK\n\tfrom sqlite3.dbapi2 import SQLITE_PRAGMA\n\tfrom sqlite3.dbapi2 import SQLITE_READ\n\tfrom sqlite3.dbapi2 import SQLITE_RECURSIVE\n\tfrom sqlite3.dbapi2 import SQLITE_REINDEX\n\tfrom sqlite3.dbapi2 import SQLITE_SAVEPOINT\n\tfrom sqlite3.dbapi2 import SQLITE_SELECT\n\tfrom sqlite3.dbapi2 import SQLITE_TRANSACTION\n\tfrom sqlite3.dbapi2 import SQLITE_UPDATE\n", "from sqlite3.dbapi2 import sqlite_version\n\tfrom sqlite3.dbapi2 import sqlite_version_info\n\tfrom sqlite3.dbapi2 import threadsafety\n\tfrom sqlite3.dbapi2 import Time\n\tfrom sqlite3.dbapi2 import TimeFromTicks\n\tfrom sqlite3.dbapi2 import Timestamp\n\tfrom sqlite3.dbapi2 import TimestampFromTicks\n\tfrom sqlite3.dbapi2 import version\n\tfrom sqlite3.dbapi2 import Warning\n\timport sys\n", "if sys.version_info[:2] >= (3, 11):\n\t    from sqlite3.dbapi2 import Blob\n\t    from sqlite3.dbapi2 import SQLITE_ABORT\n\t    from sqlite3.dbapi2 import SQLITE_ABORT_ROLLBACK\n\t    from sqlite3.dbapi2 import SQLITE_AUTH_USER\n\t    from sqlite3.dbapi2 import SQLITE_AUTH\n\t    from sqlite3.dbapi2 import SQLITE_BUSY_RECOVERY\n\t    from sqlite3.dbapi2 import SQLITE_BUSY_SNAPSHOT\n\t    from sqlite3.dbapi2 import SQLITE_BUSY_TIMEOUT\n\t    from sqlite3.dbapi2 import SQLITE_BUSY\n", "    from sqlite3.dbapi2 import SQLITE_CANTOPEN_CONVPATH\n\t    from sqlite3.dbapi2 import SQLITE_CANTOPEN_DIRTYWAL\n\t    from sqlite3.dbapi2 import SQLITE_CANTOPEN_FULLPATH\n\t    from sqlite3.dbapi2 import SQLITE_CANTOPEN_ISDIR\n\t    from sqlite3.dbapi2 import SQLITE_CANTOPEN_NOTEMPDIR\n\t    from sqlite3.dbapi2 import SQLITE_CANTOPEN_SYMLINK\n\t    from sqlite3.dbapi2 import SQLITE_CANTOPEN\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_CHECK\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_COMMITHOOK\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_FOREIGNKEY\n", "    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_FUNCTION\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_NOTNULL\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_PINNED\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_PRIMARYKEY\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_ROWID\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_TRIGGER\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_UNIQUE\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT_VTAB\n\t    from sqlite3.dbapi2 import SQLITE_CONSTRAINT\n\t    from sqlite3.dbapi2 import SQLITE_CORRUPT_INDEX\n", "    from sqlite3.dbapi2 import SQLITE_CORRUPT_SEQUENCE\n\t    from sqlite3.dbapi2 import SQLITE_CORRUPT_VTAB\n\t    from sqlite3.dbapi2 import SQLITE_CORRUPT\n\t    from sqlite3.dbapi2 import SQLITE_EMPTY\n\t    from sqlite3.dbapi2 import SQLITE_ERROR_MISSING_COLLSEQ\n\t    from sqlite3.dbapi2 import SQLITE_ERROR_RETRY\n\t    from sqlite3.dbapi2 import SQLITE_ERROR_SNAPSHOT\n\t    from sqlite3.dbapi2 import SQLITE_ERROR\n\t    from sqlite3.dbapi2 import SQLITE_FORMAT\n\t    from sqlite3.dbapi2 import SQLITE_FULL\n", "    from sqlite3.dbapi2 import SQLITE_INTERNAL\n\t    from sqlite3.dbapi2 import SQLITE_INTERRUPT\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_ACCESS\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_AUTH\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_BEGIN_ATOMIC\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_BLOCKED\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_CHECKRESERVEDLOCK\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_CLOSE\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_COMMIT_ATOMIC\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_CONVPATH\n", "    from sqlite3.dbapi2 import SQLITE_IOERR_CORRUPTFS\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_DATA\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_DELETE_NOENT\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_DELETE\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_DIR_CLOSE\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_DIR_FSYNC\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_FSTAT\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_FSYNC\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_GETTEMPPATH\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_LOCK\n", "    from sqlite3.dbapi2 import SQLITE_IOERR_MMAP\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_NOMEM\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_RDLOCK\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_READ\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_ROLLBACK_ATOMIC\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_SEEK\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_SHMLOCK\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_SHMMAP\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_SHMOPEN\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_SHMSIZE\n", "    from sqlite3.dbapi2 import SQLITE_IOERR_SHORT_READ\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_TRUNCATE\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_UNLOCK\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_VNODE\n\t    from sqlite3.dbapi2 import SQLITE_IOERR_WRITE\n\t    from sqlite3.dbapi2 import SQLITE_IOERR\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_ATTACHED\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_COLUMN\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_COMPOUND_SELECT\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_EXPR_DEPTH\n", "    from sqlite3.dbapi2 import SQLITE_LIMIT_FUNCTION_ARG\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_LENGTH\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_LIKE_PATTERN_LENGTH\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_SQL_LENGTH\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_TRIGGER_DEPTH\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_VARIABLE_NUMBER\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_VDBE_OP\n\t    from sqlite3.dbapi2 import SQLITE_LIMIT_WORKER_THREADS\n\t    from sqlite3.dbapi2 import SQLITE_LOCKED_SHAREDCACHE\n\t    from sqlite3.dbapi2 import SQLITE_LOCKED_VTAB\n", "    from sqlite3.dbapi2 import SQLITE_LOCKED\n\t    from sqlite3.dbapi2 import SQLITE_MISMATCH\n\t    from sqlite3.dbapi2 import SQLITE_MISUSE\n\t    from sqlite3.dbapi2 import SQLITE_NOLFS\n\t    from sqlite3.dbapi2 import SQLITE_NOMEM\n\t    from sqlite3.dbapi2 import SQLITE_NOTADB\n\t    from sqlite3.dbapi2 import SQLITE_NOTFOUND\n\t    from sqlite3.dbapi2 import SQLITE_NOTICE_RECOVER_ROLLBACK\n\t    from sqlite3.dbapi2 import SQLITE_NOTICE_RECOVER_WAL\n\t    from sqlite3.dbapi2 import SQLITE_NOTICE\n", "    from sqlite3.dbapi2 import SQLITE_OK_LOAD_PERMANENTLY\n\t    from sqlite3.dbapi2 import SQLITE_OK_SYMLINK\n\t    from sqlite3.dbapi2 import SQLITE_PERM\n\t    from sqlite3.dbapi2 import SQLITE_PROTOCOL\n\t    from sqlite3.dbapi2 import SQLITE_RANGE\n\t    from sqlite3.dbapi2 import SQLITE_READONLY_CANTINIT\n\t    from sqlite3.dbapi2 import SQLITE_READONLY_CANTLOCK\n\t    from sqlite3.dbapi2 import SQLITE_READONLY_DBMOVED\n\t    from sqlite3.dbapi2 import SQLITE_READONLY_DIRECTORY\n\t    from sqlite3.dbapi2 import SQLITE_READONLY_RECOVERY\n", "    from sqlite3.dbapi2 import SQLITE_READONLY_ROLLBACK\n\t    from sqlite3.dbapi2 import SQLITE_READONLY\n\t    from sqlite3.dbapi2 import SQLITE_ROW\n\t    from sqlite3.dbapi2 import SQLITE_SCHEMA\n\t    from sqlite3.dbapi2 import SQLITE_TOOBIG\n\t    from sqlite3.dbapi2 import SQLITE_WARNING_AUTOINDEX\n\t    from sqlite3.dbapi2 import SQLITE_WARNING\n\telse:\n\t    class Blob:\n\t        pass\n", "    # Most constants were only defined in 3.11\n\t    #\n\t    # you can generate them by using getattr(sqlite3.dbapi2, name)\n\t    # in a newer python version\n\t    SQLITE_ABORT = 4\n\t    SQLITE_ABORT_ROLLBACK = 516\n\t    SQLITE_AUTH_USER = 279\n\t    SQLITE_AUTH = 23\n\t    SQLITE_BUSY_RECOVERY = 261\n\t    SQLITE_BUSY_SNAPSHOT = 517\n", "    SQLITE_BUSY_TIMEOUT = 773\n\t    SQLITE_BUSY = 5\n\t    SQLITE_CANTOPEN_CONVPATH = 1038\n\t    SQLITE_CANTOPEN_DIRTYWAL = 1294\n\t    SQLITE_CANTOPEN_FULLPATH = 782\n\t    SQLITE_CANTOPEN_ISDIR = 526\n\t    SQLITE_CANTOPEN_NOTEMPDIR = 270\n\t    SQLITE_CANTOPEN_SYMLINK = 1550\n\t    SQLITE_CANTOPEN = 14\n\t    SQLITE_CONSTRAINT_CHECK = 275\n", "    SQLITE_CONSTRAINT_COMMITHOOK = 531\n\t    SQLITE_CONSTRAINT_FOREIGNKEY = 787\n\t    SQLITE_CONSTRAINT_FUNCTION = 1043\n\t    SQLITE_CONSTRAINT_NOTNULL = 1299\n\t    SQLITE_CONSTRAINT_PINNED = 2835\n\t    SQLITE_CONSTRAINT_PRIMARYKEY = 1555\n\t    SQLITE_CONSTRAINT_ROWID = 2579\n\t    SQLITE_CONSTRAINT_TRIGGER = 1811\n\t    SQLITE_CONSTRAINT_UNIQUE = 2067\n\t    SQLITE_CONSTRAINT_VTAB = 2323\n", "    SQLITE_CONSTRAINT = 19\n\t    SQLITE_CORRUPT_INDEX = 779\n\t    SQLITE_CORRUPT_SEQUENCE = 523\n\t    SQLITE_CORRUPT_VTAB = 267\n\t    SQLITE_CORRUPT = 11\n\t    SQLITE_EMPTY = 16\n\t    SQLITE_ERROR_MISSING_COLLSEQ = 257\n\t    SQLITE_ERROR_RETRY = 513\n\t    SQLITE_ERROR_SNAPSHOT = 769\n\t    SQLITE_ERROR = 1\n", "    SQLITE_FORMAT = 24\n\t    SQLITE_FULL = 13\n\t    SQLITE_INTERNAL = 2\n\t    SQLITE_INTERRUPT = 9\n\t    SQLITE_IOERR_ACCESS = 3338\n\t    SQLITE_IOERR_AUTH = 7178\n\t    SQLITE_IOERR_BEGIN_ATOMIC = 7434\n\t    SQLITE_IOERR_BLOCKED = 2826\n\t    SQLITE_IOERR_CHECKRESERVEDLOCK = 3594\n\t    SQLITE_IOERR_CLOSE = 4106\n", "    SQLITE_IOERR_COMMIT_ATOMIC = 7690\n\t    SQLITE_IOERR_CONVPATH = 6666\n\t    SQLITE_IOERR_CORRUPTFS = 8458\n\t    SQLITE_IOERR_DATA = 8202\n\t    SQLITE_IOERR_DELETE_NOENT = 5898\n\t    SQLITE_IOERR_DELETE = 2570\n\t    SQLITE_IOERR_DIR_CLOSE = 4362\n\t    SQLITE_IOERR_DIR_FSYNC = 1290\n\t    SQLITE_IOERR_FSTAT = 1802\n\t    SQLITE_IOERR_FSYNC = 1034\n", "    SQLITE_IOERR_GETTEMPPATH = 6410\n\t    SQLITE_IOERR_LOCK = 3850\n\t    SQLITE_IOERR_MMAP = 6154\n\t    SQLITE_IOERR_NOMEM = 3082\n\t    SQLITE_IOERR_RDLOCK = 2314\n\t    SQLITE_IOERR_READ = 266\n\t    SQLITE_IOERR_ROLLBACK_ATOMIC = 7946\n\t    SQLITE_IOERR_SEEK = 5642\n\t    SQLITE_IOERR_SHMLOCK = 5130\n\t    SQLITE_IOERR_SHMMAP = 5386\n", "    SQLITE_IOERR_SHMOPEN = 4618\n\t    SQLITE_IOERR_SHMSIZE = 4874\n\t    SQLITE_IOERR_SHORT_READ = 522\n\t    SQLITE_IOERR_TRUNCATE = 1546\n\t    SQLITE_IOERR_UNLOCK = 2058\n\t    SQLITE_IOERR_VNODE = 6922\n\t    SQLITE_IOERR_WRITE = 778\n\t    SQLITE_IOERR = 10\n\t    SQLITE_LIMIT_ATTACHED = 7\n\t    SQLITE_LIMIT_COLUMN = 2\n", "    SQLITE_LIMIT_COMPOUND_SELECT = 4\n\t    SQLITE_LIMIT_EXPR_DEPTH = 3\n\t    SQLITE_LIMIT_FUNCTION_ARG = 6\n\t    SQLITE_LIMIT_LENGTH = 0\n\t    SQLITE_LIMIT_LIKE_PATTERN_LENGTH = 8\n\t    SQLITE_LIMIT_SQL_LENGTH = 1\n\t    SQLITE_LIMIT_TRIGGER_DEPTH = 10\n\t    SQLITE_LIMIT_VARIABLE_NUMBER = 9\n\t    SQLITE_LIMIT_VDBE_OP = 5\n\t    SQLITE_LIMIT_WORKER_THREADS = 11\n", "    SQLITE_LOCKED_SHAREDCACHE = 262\n\t    SQLITE_LOCKED_VTAB = 518\n\t    SQLITE_LOCKED = 6\n\t    SQLITE_MISMATCH = 20\n\t    SQLITE_MISUSE = 21\n\t    SQLITE_NOLFS = 22\n\t    SQLITE_NOMEM = 7\n\t    SQLITE_NOTADB = 26\n\t    SQLITE_NOTFOUND = 12\n\t    SQLITE_NOTICE_RECOVER_ROLLBACK = 539\n", "    SQLITE_NOTICE_RECOVER_WAL = 283\n\t    SQLITE_NOTICE = 27\n\t    SQLITE_OK_LOAD_PERMANENTLY = 256\n\t    SQLITE_OK_SYMLINK = 512\n\t    SQLITE_PERM = 3\n\t    SQLITE_PROTOCOL = 15\n\t    SQLITE_RANGE = 25\n\t    SQLITE_READONLY_CANTINIT = 1288\n\t    SQLITE_READONLY_CANTLOCK = 520\n\t    SQLITE_READONLY_DBMOVED = 1032\n", "    SQLITE_READONLY_DIRECTORY = 1544\n\t    SQLITE_READONLY_RECOVERY = 264\n\t    SQLITE_READONLY_ROLLBACK = 776\n\t    SQLITE_READONLY = 8\n\t    SQLITE_ROW = 100\n\t    SQLITE_SCHEMA = 17\n\t    SQLITE_TOOBIG = 18\n\t    SQLITE_WARNING_AUTOINDEX = 284\n\t    SQLITE_WARNING = 28\n\t__all__ = (\n", "    \"adapt\",\n\t    \"adapters\",\n\t    \"apilevel\",\n\t    \"Binary\",\n\t    \"Blob\",\n\t    \"complete_statement\",\n\t    \"converters\",\n\t    \"DatabaseError\",\n\t    \"DataError\",\n\t    \"Date\",\n", "    \"DateFromTicks\",\n\t    \"Error\",\n\t    \"IntegrityError\",\n\t    \"InterfaceError\",\n\t    \"InternalError\",\n\t    \"NotSupportedError\",\n\t    \"OperationalError\",\n\t    \"paramstyle\",\n\t    \"PARSE_COLNAMES\",\n\t    \"PARSE_DECLTYPES\",\n", "    \"PrepareProtocol\",\n\t    \"ProgrammingError\",\n\t    \"register_adapter\",\n\t    \"register_converter\",\n\t    \"SQLITE_ABORT_ROLLBACK\",\n\t    \"SQLITE_ABORT\",\n\t    \"SQLITE_ALTER_TABLE\",\n\t    \"SQLITE_ANALYZE\",\n\t    \"SQLITE_ATTACH\",\n\t    \"SQLITE_AUTH_USER\",\n", "    \"SQLITE_AUTH\",\n\t    \"SQLITE_BUSY_RECOVERY\",\n\t    \"SQLITE_BUSY_SNAPSHOT\",\n\t    \"SQLITE_BUSY_TIMEOUT\",\n\t    \"SQLITE_BUSY\",\n\t    \"SQLITE_CANTOPEN_CONVPATH\",\n\t    \"SQLITE_CANTOPEN_DIRTYWAL\",\n\t    \"SQLITE_CANTOPEN_FULLPATH\",\n\t    \"SQLITE_CANTOPEN_ISDIR\",\n\t    \"SQLITE_CANTOPEN_NOTEMPDIR\",\n", "    \"SQLITE_CANTOPEN_SYMLINK\",\n\t    \"SQLITE_CANTOPEN\",\n\t    \"SQLITE_CONSTRAINT_CHECK\",\n\t    \"SQLITE_CONSTRAINT_COMMITHOOK\",\n\t    \"SQLITE_CONSTRAINT_FOREIGNKEY\",\n\t    \"SQLITE_CONSTRAINT_FUNCTION\",\n\t    \"SQLITE_CONSTRAINT_NOTNULL\",\n\t    \"SQLITE_CONSTRAINT_PINNED\",\n\t    \"SQLITE_CONSTRAINT_PRIMARYKEY\",\n\t    \"SQLITE_CONSTRAINT_ROWID\",\n", "    \"SQLITE_CONSTRAINT_TRIGGER\",\n\t    \"SQLITE_CONSTRAINT_UNIQUE\",\n\t    \"SQLITE_CONSTRAINT_VTAB\",\n\t    \"SQLITE_CONSTRAINT\",\n\t    \"SQLITE_CORRUPT_INDEX\",\n\t    \"SQLITE_CORRUPT_SEQUENCE\",\n\t    \"SQLITE_CORRUPT_VTAB\",\n\t    \"SQLITE_CORRUPT\",\n\t    \"SQLITE_CREATE_INDEX\",\n\t    \"SQLITE_CREATE_TABLE\",\n", "    \"SQLITE_CREATE_TEMP_INDEX\",\n\t    \"SQLITE_CREATE_TEMP_TABLE\",\n\t    \"SQLITE_CREATE_TEMP_TRIGGER\",\n\t    \"SQLITE_CREATE_TEMP_VIEW\",\n\t    \"SQLITE_CREATE_TRIGGER\",\n\t    \"SQLITE_CREATE_VIEW\",\n\t    \"SQLITE_CREATE_VTABLE\",\n\t    \"SQLITE_DELETE\",\n\t    \"SQLITE_DENY\",\n\t    \"SQLITE_DETACH\",\n", "    \"SQLITE_DONE\",\n\t    \"SQLITE_DROP_INDEX\",\n\t    \"SQLITE_DROP_TABLE\",\n\t    \"SQLITE_DROP_TEMP_INDEX\",\n\t    \"SQLITE_DROP_TEMP_TABLE\",\n\t    \"SQLITE_DROP_TEMP_TRIGGER\",\n\t    \"SQLITE_DROP_TEMP_VIEW\",\n\t    \"SQLITE_DROP_TRIGGER\",\n\t    \"SQLITE_DROP_VIEW\",\n\t    \"SQLITE_DROP_VTABLE\",\n", "    \"SQLITE_EMPTY\",\n\t    \"SQLITE_ERROR_MISSING_COLLSEQ\",\n\t    \"SQLITE_ERROR_RETRY\",\n\t    \"SQLITE_ERROR_SNAPSHOT\",\n\t    \"SQLITE_ERROR\",\n\t    \"SQLITE_FORMAT\",\n\t    \"SQLITE_FULL\",\n\t    \"SQLITE_FUNCTION\",\n\t    \"SQLITE_IGNORE\",\n\t    \"SQLITE_INSERT\",\n", "    \"SQLITE_INTERNAL\",\n\t    \"SQLITE_INTERRUPT\",\n\t    \"SQLITE_IOERR_ACCESS\",\n\t    \"SQLITE_IOERR_AUTH\",\n\t    \"SQLITE_IOERR_BEGIN_ATOMIC\",\n\t    \"SQLITE_IOERR_BLOCKED\",\n\t    \"SQLITE_IOERR_CHECKRESERVEDLOCK\",\n\t    \"SQLITE_IOERR_CLOSE\",\n\t    \"SQLITE_IOERR_COMMIT_ATOMIC\",\n\t    \"SQLITE_IOERR_CONVPATH\",\n", "    \"SQLITE_IOERR_CORRUPTFS\",\n\t    \"SQLITE_IOERR_DATA\",\n\t    \"SQLITE_IOERR_DELETE_NOENT\",\n\t    \"SQLITE_IOERR_DELETE\",\n\t    \"SQLITE_IOERR_DIR_CLOSE\",\n\t    \"SQLITE_IOERR_DIR_FSYNC\",\n\t    \"SQLITE_IOERR_FSTAT\",\n\t    \"SQLITE_IOERR_FSYNC\",\n\t    \"SQLITE_IOERR_GETTEMPPATH\",\n\t    \"SQLITE_IOERR_LOCK\",\n", "    \"SQLITE_IOERR_MMAP\",\n\t    \"SQLITE_IOERR_NOMEM\",\n\t    \"SQLITE_IOERR_RDLOCK\",\n\t    \"SQLITE_IOERR_READ\",\n\t    \"SQLITE_IOERR_ROLLBACK_ATOMIC\",\n\t    \"SQLITE_IOERR_SEEK\",\n\t    \"SQLITE_IOERR_SHMLOCK\",\n\t    \"SQLITE_IOERR_SHMMAP\",\n\t    \"SQLITE_IOERR_SHMOPEN\",\n\t    \"SQLITE_IOERR_SHMSIZE\",\n", "    \"SQLITE_IOERR_SHORT_READ\",\n\t    \"SQLITE_IOERR_TRUNCATE\",\n\t    \"SQLITE_IOERR_UNLOCK\",\n\t    \"SQLITE_IOERR_VNODE\",\n\t    \"SQLITE_IOERR_WRITE\",\n\t    \"SQLITE_IOERR\",\n\t    \"SQLITE_LIMIT_ATTACHED\",\n\t    \"SQLITE_LIMIT_COLUMN\",\n\t    \"SQLITE_LIMIT_COMPOUND_SELECT\",\n\t    \"SQLITE_LIMIT_EXPR_DEPTH\",\n", "    \"SQLITE_LIMIT_FUNCTION_ARG\",\n\t    \"SQLITE_LIMIT_LENGTH\",\n\t    \"SQLITE_LIMIT_LIKE_PATTERN_LENGTH\",\n\t    \"SQLITE_LIMIT_SQL_LENGTH\",\n\t    \"SQLITE_LIMIT_TRIGGER_DEPTH\",\n\t    \"SQLITE_LIMIT_VARIABLE_NUMBER\",\n\t    \"SQLITE_LIMIT_VDBE_OP\",\n\t    \"SQLITE_LIMIT_WORKER_THREADS\",\n\t    \"SQLITE_LOCKED_SHAREDCACHE\",\n\t    \"SQLITE_LOCKED_VTAB\",\n", "    \"SQLITE_LOCKED\",\n\t    \"SQLITE_MISMATCH\",\n\t    \"SQLITE_MISUSE\",\n\t    \"SQLITE_NOLFS\",\n\t    \"SQLITE_NOMEM\",\n\t    \"SQLITE_NOTADB\",\n\t    \"SQLITE_NOTFOUND\",\n\t    \"SQLITE_NOTICE_RECOVER_ROLLBACK\",\n\t    \"SQLITE_NOTICE_RECOVER_WAL\",\n\t    \"SQLITE_NOTICE\",\n", "    \"SQLITE_OK_LOAD_PERMANENTLY\",\n\t    \"SQLITE_OK_SYMLINK\",\n\t    \"SQLITE_OK\",\n\t    \"SQLITE_PERM\",\n\t    \"SQLITE_PRAGMA\",\n\t    \"SQLITE_PROTOCOL\",\n\t    \"SQLITE_RANGE\",\n\t    \"SQLITE_READ\",\n\t    \"SQLITE_READONLY_CANTINIT\",\n\t    \"SQLITE_READONLY_CANTLOCK\",\n", "    \"SQLITE_READONLY_DBMOVED\",\n\t    \"SQLITE_READONLY_DIRECTORY\",\n\t    \"SQLITE_READONLY_RECOVERY\",\n\t    \"SQLITE_READONLY_ROLLBACK\",\n\t    \"SQLITE_READONLY\",\n\t    \"SQLITE_RECURSIVE\",\n\t    \"SQLITE_REINDEX\",\n\t    \"SQLITE_ROW\",\n\t    \"SQLITE_SAVEPOINT\",\n\t    \"SQLITE_SCHEMA\",\n", "    \"SQLITE_SELECT\",\n\t    \"SQLITE_TOOBIG\",\n\t    \"SQLITE_TRANSACTION\",\n\t    \"SQLITE_UPDATE\",\n\t    \"sqlite_version_info\",\n\t    \"sqlite_version\",\n\t    \"SQLITE_WARNING_AUTOINDEX\",\n\t    \"SQLITE_WARNING\",\n\t    \"threadsafety\",\n\t    \"Time\",\n", "    \"TimeFromTicks\",\n\t    \"Timestamp\",\n\t    \"TimestampFromTicks\",\n\t    \"version\",\n\t    \"Warning\",\n\t)\n"]}
{"filename": "libsql_client/dbapi2/_utils.py", "chunked_list": ["from __future__ import annotations\n\timport logging\n\tfrom typing import Iterable\n\tfrom typing import List\n\tfrom typing import Optional\n\tfrom typing import Sequence\n\tdef log_prefix(\n\t    logger: logging.Logger,\n\t    prefix: str,\n\t    level: int,\n", "    msg: str,\n\t    *args: object,\n\t    exc_info: Optional[BaseException] = None,\n\t) -> None:\n\t    logger.log(level, prefix + msg, *args, exc_info=exc_info)\n\tdef log_obj(\n\t    logger: logging.Logger,\n\t    obj: object,\n\t    level: int,\n\t    msg: str,\n", "    *args: object,\n\t    exc_info: Optional[BaseException] = None,\n\t) -> None:\n\t    prefix = getattr(obj, \"_log_prefix\", None)\n\t    if prefix is None:\n\t        prefix = f\"{obj!r}: \"\n\t    log_prefix(logger, prefix, level, msg, *args, exc_info=exc_info)\n\t_lstrip_sql_whitespace_chars = {\" \", \"\\t\", \"\\f\", \"\\n\", \"\\r\"}\n\tdef lstrip_sql(sql: str) -> Optional[str]:  # noqa: C901\n\t    # See statement.c, lstrip_sql() function at:\n", "    # https://github.com/python/cpython/blob/main/Modules/_sqlite/statement.c#L134\n\t    # using the same names here, however in C pos is both the index (offset)\n\t    # and the value (ch = *pos)\n\t    pos = 0\n\t    end_pos = len(sql)\n\t    while pos < end_pos:\n\t        ch = sql[pos]\n\t        if ch in _lstrip_sql_whitespace_chars:\n\t            pos += 1  # C uses for() with trailing ++\n\t            continue\n", "        if ch == \"-\":\n\t            # Skip line comments.\n\t            # NOTE: in C pos[end_pos] == 0, so \"pos[1] == '-'\" is enough,\n\t            # Here we must compare pos + 1 < end_pos\n\t            if pos + 1 < end_pos and sql[pos + 1] == \"-\":\n\t                pos += 2\n\t                # NOTE: in C pos[end_pos] == 0, so they do \"pos[0]\".\n\t                # Here we compare pos + 1 < end_pos\n\t                while pos < end_pos and sql[pos] != \"\\n\":\n\t                    pos += 1\n", "                if pos >= end_pos:\n\t                    return None\n\t                pos += 1  # C uses for() with trailing ++\n\t                continue\n\t            return sql[pos:]  # not a line comment\n\t        if ch == \"/\":\n\t            # Skip C style comments.\n\t            # NOTE: in C pos[end_pos] == 0, so \"pos[1] == '*'\" is enough,\n\t            # Here we must compare pos + 1 < end_pos\n\t            if pos + 1 < end_pos and sql[pos + 1] == \"*\":\n", "                pos += 2\n\t                # NOTE: in C pos[end_pos] == 0, so they do \"pos[0]\".\n\t                # Here we compare pos + 1 < end_pos. To avoid a messy\n\t                # long line, the condition is moved into an explicit \"if\"\n\t                # that \"break\"s.\n\t                while pos < end_pos:\n\t                    if sql[pos] == \"*\":\n\t                        if pos + 1 < end_pos and sql[pos + 1] == \"/\":\n\t                            break\n\t                    pos += 1\n", "                if pos >= end_pos:\n\t                    return None\n\t                pos += 2  # C uses for() with trailing ++\n\t                continue\n\t            return sql[pos:]  # not a C style comment\n\t        return sql[pos:]\n\t    return None\n\t_iter_sql_delim_chars = {\";\", \",\", \"(\", \")\", \"[\", \"]\"}\n\t_iter_sql_stop_chars = _lstrip_sql_whitespace_chars.union(\n\t    _iter_sql_delim_chars,\n", ")\n\t_iter_sql_quote_chars = {'\"', \"'\"}\n\tdef _iter_sql_get_quoted_end(sql: str, pos: int, end_pos: int) -> int:\n\t    \"\"\"Find the end of the quoted string starting at ``pos``.\n\t    The returned position includes the position of the quote character,\n\t    that matches the one at ``pos``.\n\t    >>> def test_quote(ts):\n\t    ...     end = _iter_sql_get_quoted_end(ts, 0, len(ts))\n\t    ...     return (end, ts[:end])\n\t    >>> test_quote(\"'abc'\")\n", "    (5, \"'abc'\")\n\t    >>> test_quote('\"abc \"')\n\t    (6, '\"abc \"')\n\t    >>> test_quote(\"'abc' def\")\n\t    (5, \"'abc'\")\n\t    >>> test_quote('\"abc \"def')\n\t    (6, '\"abc \"')\n\t    It also handles escaping by double quotes, see\n\t    https://www.sqlite.org/faq.html#q14\n\t    >>> test_quote('\"abc\"\"def\" ghi')\n", "    (10, '\"abc\"\"def\"')\n\t    >>> test_quote('\"abc \"def\" ghi')\n\t    (6, '\"abc \"')\n\t    \"\"\"\n\t    if pos + 1 >= end_pos:\n\t        return pos\n\t    ch = sql[pos]\n\t    while pos + 1 < end_pos:\n\t        pos += 1\n\t        if sql[pos] == ch:\n", "            pos += 1\n\t            if pos == end_pos or sql[pos] != ch:\n\t                break\n\t            # escaped by double quoting: https://www.sqlite.org/faq.html#q14\n\t            pos += 1\n\t    return pos\n\tdef iter_sql_tokens(sql: str) -> Iterable[str]:\n\t    \"\"\"Calls lstrip_sql() to get the start of the next token and yield it.\n\t    It will handle stop chars (;,[]()) as their own tokens, as well as handle\n\t    double and single quotes, as well as quote escaping with \\\\\n", "    >>> list(iter_sql_tokens(\"--COMMENT\\\\nBEGIN X\"))\n\t    ['BEGIN', 'X']\n\t    >>> list(iter_sql_tokens(\n\t    ... \"CREATE TABLE x (id INTEGER /* COMMENT */, name TEXT)\"))\n\t    ['CREATE', 'TABLE', 'x', '(', 'id', 'INTEGER', ',', 'name', 'TEXT', ')']\n\t    >>> list(iter_sql_tokens(\"SELECT; INSERT; DELETE\"))\n\t    ['SELECT', ';', 'INSERT', ';', 'DELETE']\n\t    >>> print(\"\\\\n\".join(iter_sql_tokens(\n\t    ... 'INSERT INTO t (a,b) VALUES(\"s -- c /* c */\", \\\\'x\\\\')'\n\t    ... )))\n", "    INSERT\n\t    INTO\n\t    t\n\t    (\n\t    a\n\t    ,\n\t    b\n\t    )\n\t    VALUES\n\t    (\n", "    \"s -- c /* c */\"\n\t    ,\n\t    'x'\n\t    )\n\t    >>> list(iter_sql_tokens('SELECT\"abc\"'))\n\t    ['SELECT', '\"abc\"']\n\t    \"\"\"\n\t    while sql:\n\t        sql = lstrip_sql(sql) or \"\"\n\t        if not sql:\n", "            break\n\t        pos = 0\n\t        end_pos = len(sql)\n\t        while pos < end_pos:\n\t            ch = sql[pos]\n\t            if ch in _iter_sql_quote_chars:\n\t                if pos > 0:\n\t                    break\n\t                pos = _iter_sql_get_quoted_end(sql, pos, end_pos)\n\t                break\n", "            elif ch in _iter_sql_stop_chars:\n\t                break\n\t            else:\n\t                pos += 1\n\t        if pos > 0:\n\t            yield sql[:pos]\n\t            sql = sql[pos:]\n\t        else:\n\t            yield sql[0]\n\t            sql = sql[1:]\n", "def iter_sql_statements(sql: str) -> Iterable[Sequence[str]]:\n\t    \"\"\"Yields sql statements based on \";\" tokens.\n\t    >>> list(iter_sql_statements(\"BEGIN\"))\n\t    [['BEGIN']]\n\t    >>> list(iter_sql_statements(\"BEGIN;INSERT INTO x;COMMIT\"))\n\t    [['BEGIN', ';'], ['INSERT', 'INTO', 'x', ';'], ['COMMIT']]\n\t    \"\"\"\n\t    stmt: List[str] = []\n\t    for token in iter_sql_tokens(sql):\n\t        stmt.append(token)\n", "        if token == \";\":\n\t            yield stmt\n\t            stmt = []\n\t    if stmt:\n\t        yield stmt\n"]}
{"filename": "libsql_client/dbapi2/__init__.py", "chunked_list": ["from __future__ import annotations\n\timport sqlite3.dbapi2\n\tfrom typing import Any\n\tfrom typing import Mapping\n\tfrom typing import Optional\n\tfrom urllib.parse import urlparse\n\tfrom ._reexports import *\n\tfrom .hrana import ConnectionHrana as Connection\n\tfrom .hrana import CursorHrana as Cursor\n\tfrom .types import ConnectFactory\n", "from .types import Connection as BaseConnection\n\tfrom .types import ConnectionTypes\n\tfrom .types import Cursor as BaseCursor\n\tfrom .types import enable_callback_tracebacks\n\tfrom .types import IsolationLevel\n\tfrom .types import LEGACY_TRANSACTION_CONTROL\n\tfrom .types import PathLike\n\tfrom .types import Row\n\t\"\"\"\n\tThis module implements `Python Database API Specification v2.0\n", "<https://peps.python.org/pep-0249/>`_\n\tmimicking as much as possible :py:mod:`sqlite3` in order to provide a\n\tdrop-in replacement. Whenever explicitly undocumented, please refer its\n\tdocumentation.\n\t\"\"\"\n\t__docformat__ = \"reStructuredText en\"\n\t_connection_handlers: Mapping[str, ConnectFactory] = {\n\t    \"file\": sqlite3.dbapi2.connect,\n\t    \"libsql\": Connection,\n\t    \"ws\": Connection,\n", "    \"wss\": Connection,\n\t}\n\t_uri_forced_databases_prefixes = (\"libsql://\", \"ws://\", \"wss://\")\n\tdef connect(\n\t    database: PathLike,\n\t    timeout: float = 5.0,\n\t    detect_types: int = 0,\n\t    isolation_level: Optional[IsolationLevel] = \"\",\n\t    check_same_thread: bool = True,\n\t    factory: Optional[ConnectFactory] = None,\n", "    cached_statements: int = 128,\n\t    uri: bool = False,\n\t    **kwargs: Any,\n\t) -> ConnectionTypes:\n\t    \"\"\"\n\t    Open a connection to an SQLite (local) or sqld (remote) database.\n\t    In addition to :py:func:`sqlite3.connect`, this function allows\n\t    connecting to remote servers using the following protocols:\n\t    - ``libsql://`` alias for ``wss://``\n\t    - ``ws://`` insecure web socket\n", "    - ``wss://`` secure web socket\n\t    If local files or ``:memory:`` is used, then the standard\n\t    :py:class:`sqlite3.Connection` is returned.\n\t    For remote URL, :py:class:`libsql_client.dbapi2.hrana.ConnectionHrana` is\n\t    returned, it should match the behavior of\n\t    :py:class:`sqlite3.Connection` whenever possible.\n\t    \"\"\"\n\t    if not uri and isinstance(database, str):\n\t        for prefix in _uri_forced_databases_prefixes:\n\t            if database.startswith(prefix):\n", "                uri = True\n\t                break\n\t    handler: ConnectFactory\n\t    if not uri:\n\t        handler = sqlite3.dbapi2.connect\n\t        if factory is not None:\n\t            kwargs[\"factory\"] = factory\n\t    else:\n\t        if factory is not None:\n\t            handler = factory\n", "        else:\n\t            assert isinstance(database, str)\n\t            u = urlparse(database)\n\t            try:\n\t                handler = _connection_handlers[u.scheme]\n\t            except KeyError as e:\n\t                raise ValueError(f\"unsupported uri scheme: {u.scheme}\") from e\n\t    return handler(\n\t        database,\n\t        timeout=timeout,\n", "        detect_types=detect_types,\n\t        isolation_level=isolation_level,\n\t        check_same_thread=check_same_thread,\n\t        cached_statements=cached_statements,\n\t        uri=uri,\n\t        **kwargs,\n\t    )\n"]}
{"filename": "libsql_client/dbapi2/_async_executor.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport concurrent.futures\n\timport functools\n\timport logging\n\timport queue\n\timport sys\n\timport threading\n\tfrom typing import Any\n\tfrom typing import Awaitable\n", "from typing import Callable\n\tfrom typing import NamedTuple\n\tfrom typing import Optional\n\tfrom typing import overload\n\tfrom typing import TypeVar\n\tfrom typing_extensions import ParamSpec\n\tfrom ._utils import log_obj\n\tfrom ._utils import log_prefix\n\t_logger = logging.getLogger(__name__)\n\t_log_obj = functools.partial(log_obj, _logger)\n", "_log_prefix = functools.partial(log_prefix, _logger)\n\tP = ParamSpec(\"P\")\n\tT = TypeVar(\"T\")\n\tclass LoopControl(NamedTuple):\n\t    loop: asyncio.AbstractEventLoop\n\t    stop_event: asyncio.Event\n\t# NOTE: keep outside of class, do not touch self, not even keep a reference\n\tdef _thread_main(log_prefix: str, q: queue.Queue[LoopControl]) -> None:\n\t    loop: Optional[asyncio.AbstractEventLoop] = None\n\t    def dbg(\n", "        msg: str,\n\t        *args: object,\n\t        exc_info: Optional[BaseException] = None,\n\t    ) -> None:\n\t        nonlocal loop\n\t        loop_str = f\" {loop!r}\" if loop else \"\"\n\t        prefix = f\"{log_prefix}{loop_str}: \"\n\t        _log_prefix(prefix, logging.DEBUG, msg, *args, exc_info=exc_info)\n\t    async def main() -> None:\n\t        nonlocal loop\n", "        stop_event = asyncio.Event()\n\t        loop = asyncio.get_running_loop()\n\t        try:\n\t            dbg(\"started main()\")\n\t            q.put_nowait(LoopControl(loop, stop_event))\n\t            await stop_event.wait()\n\t            dbg(\"finished main()\")\n\t        except Exception as e:\n\t            dbg(\"failed main(): %s\", e, exc_info=e)\n\t        finally:\n", "            loop = None\n\t    dbg(\"started thread\")\n\t    asyncio.run(main())\n\t    dbg(\"finished thread\")\n\tclass AsyncExecutor(threading.Thread):\n\t    _lock: threading.Lock\n\t    _control: Optional[LoopControl]\n\t    __slots__ = (\"_control\", \"_lock\")\n\t    def __init__(self) -> None:\n\t        self._control = None\n", "        q: queue.Queue[LoopControl] = queue.Queue(1)\n\t        log_prefix = f\"<{self.__class__.__name__} at {id(self):x}>\"\n\t        super().__init__(daemon=True, target=_thread_main, args=(log_prefix, q))\n\t        self._inf(\"created\")\n\t        self.start()\n\t        self._lock = threading.Lock()\n\t        self._control = q.get()\n\t        self._inf(\"thread ready\")\n\t    def __del__(self) -> None:\n\t        self._inf(\"destroyed\")\n", "        # This is really unlikely, since run() will be in the thread,\n\t        # and thus will hold a reference in there, but let's check it anyway\n\t        assert self._control is None, \"Thread is still running\"\n\t    def __repr__(self) -> str:\n\t        addr = hex(id(self))\n\t        s = \"started\" if self.is_alive() else \"stopped\"\n\t        if self._control is not None:\n\t            s += f\" loop={self._control.loop}\"\n\t        return f\"<{self.__class__.__name__} at {addr} name={self.name!r} {s}>\"\n\t    _log = functools.partial(_log_obj)\n", "    _dbg = functools.partialmethod(_log, logging.DEBUG)\n\t    _inf = functools.partialmethod(_log, logging.INFO)\n\t    _err = functools.partialmethod(_log, logging.ERROR)\n\t    def shutdown(self) -> None:\n\t        self._dbg(\"shuting down thread...\")\n\t        with self._lock:\n\t            if self._control is None:\n\t                raise RuntimeError(\"thread already down\")\n\t            loop, stop_event = self._control\n\t            self._control = None\n", "        async def run_in_main_loop() -> None:\n\t            self._dbg(\"notifying _stop_event\")\n\t            stop_event.set()\n\t        self._dbg(\"thread will stop\")\n\t        coro = run_in_main_loop()\n\t        future = asyncio.run_coroutine_threadsafe(coro, loop)\n\t        future.result()\n\t        self.join()\n\t        self._inf(\"thread did stop\")\n\t    if sys.version_info[:2] >= (3, 9):\n", "        @overload\n\t        def submit(\n\t            self,\n\t            fn: Callable[P, Awaitable[asyncio.Future[T]]],\n\t            *args: P.args,\n\t            **kwargs: P.kwargs,\n\t        ) -> concurrent.futures.Future[T]:\n\t            ...\n\t        @overload\n\t        def submit(\n", "            self,\n\t            fn: Callable[P, Awaitable[T]],\n\t            *args: P.args,\n\t            **kwargs: P.kwargs,\n\t        ) -> concurrent.futures.Future[T]:\n\t            ...\n\t        @overload\n\t        def submit(\n\t            self,\n\t            fn: Callable[P, T],\n", "            *args: P.args,\n\t            **kwargs: P.kwargs,\n\t        ) -> concurrent.futures.Future[T]:\n\t            ...\n\t    else:\n\t        @overload\n\t        def submit(\n\t            self,\n\t            fn: Callable[P, Awaitable[asyncio.Future]],\n\t            *args: P.args,\n", "            **kwargs: P.kwargs,\n\t        ) -> concurrent.futures.Future:\n\t            ...\n\t        @overload\n\t        def submit(\n\t            self,\n\t            fn: Callable[P, Awaitable[T]],\n\t            *args: P.args,\n\t            **kwargs: P.kwargs,\n\t        ) -> concurrent.futures.Future:\n", "            ...\n\t        @overload\n\t        def submit(\n\t            self,\n\t            fn: Callable[P, T],\n\t            *args: P.args,\n\t            **kwargs: P.kwargs,\n\t        ) -> concurrent.futures.Future:\n\t            ...\n\t    def submit(\n", "        self,\n\t        fn: Callable[P, T],\n\t        *args: P.args,\n\t        **kwargs: P.kwargs,\n\t    ) -> Any:  # variants are covered by overloads\n\t        with self._lock:\n\t            return self._unlocked_submit(fn, *args, **kwargs)\n\t    def _unlocked_submit(\n\t        self,\n\t        fn: Callable[P, T],\n", "        *args: P.args,\n\t        **kwargs: P.kwargs,\n\t    ) -> Any:  # variants are covered by overloads\n\t        if self._control is None:\n\t            raise RuntimeError(\"already down\")\n\t        async def run_in_main_loop() -> Any:\n\t            try:\n\t                self._dbg(\"calling: %s, args=%s, kwargs=%s\", fn, args, kwargs)\n\t                r = fn(*args, **kwargs)\n\t                while asyncio.iscoroutine(r) or asyncio.isfuture(r):\n", "                    r = await r\n\t                self._dbg(\n\t                    \"finished: %s, args=%s, kwargs=%s, result=%s\",\n\t                    fn,\n\t                    args,\n\t                    kwargs,\n\t                    r,\n\t                )\n\t                return r\n\t            except Exception as e:\n", "                self._dbg(\n\t                    \"failed: %s, args=%s, kwargs=%s, exc=%s\",\n\t                    fn,\n\t                    args,\n\t                    kwargs,\n\t                    e,\n\t                    exc_info=e,\n\t                )\n\t                raise\n\t        coro = run_in_main_loop()\n", "        return asyncio.run_coroutine_threadsafe(coro, self._control.loop)\n"]}
{"filename": "libsql_client/dbapi2/_replace_modules_pythonpath/sqlite3/dbapi2.py", "chunked_list": ["import os.path\n\timport sys\n\t# $LIBSQL_PYTHONPATH_BOOTSTRAP is set by libsql_client.dbapi2.__main__\n\tbootstrap_path = os.environ[\"LIBSQL_PYTHONPATH_BOOTSTRAP\"]\n\tsqlite3_dbapi2_modname = __name__\n\tsqlite3_modname = sqlite3_dbapi2_modname.split(\".\")[0]\n\t# Remove itself from sys.path/$PYTHONPATH\n\t#\n\t# This MUST be done before libsql_client.dbapi2 is imported\n\t# since it will use the stdlib sqlite3\n", "sys.path.remove(bootstrap_path)\n\tdel sys.modules[sqlite3_modname]\n\tdel sys.modules[sqlite3_dbapi2_modname]\n\timport libsql_client.dbapi2 as wrapper_dbapi2  # noqa: I900,E402\n\tsys.modules[sqlite3_modname] = wrapper_dbapi2\n\tsys.modules[sqlite3_dbapi2_modname] = wrapper_dbapi2\n"]}
{"filename": "libsql_client/dbapi2/_replace_modules_pythonpath/sqlite3/__init__.py", "chunked_list": ["from .dbapi2 import *  # noqa: F401,F403\n"]}
{"filename": "docs/conf.py", "chunked_list": ["# Configuration file for the Sphinx documentation builder.\n\t#\n\t# For the full list of built-in configuration values, see the documentation:\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\t# -- Project information -----------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n\tproject = \"Python SDK for libSQL\"\n\tcopyright = \"2023, Chiselstrike\"\n\tauthor = \"Chiselstrike\"\n\t# -- General configuration ---------------------------------------------------\n", "# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\textensions = [\"sphinx.ext.intersphinx\", \"sphinx.ext.autodoc\"]\n\ttemplates_path = [\"_templates\"]\n\texclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\t# -- Options for HTML output -------------------------------------------------\n\t# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n\thtml_theme = \"sphinxdoc\"\n\thtml_static_path = [\"_static\"]\n\tintersphinx_mapping = {\n\t    \"https://docs.python.org/3/\": None,\n", "}\n"]}
