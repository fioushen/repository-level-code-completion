{"filename": "tests/__init__.py", "chunked_list": []}
{"filename": "tests/test_registry.py", "chunked_list": ["import pickle\n\timport pytest\n\tfrom patio import Registry\n\tdef test_registry_properties(subtests):\n\t    r: Registry = Registry(project=\"foo\", strict=False, auto_naming=False)\n\t    assert r.project == \"foo\"\n\t    assert not r.strict\n\t    assert not r.auto_naming\n\t    r = Registry(project=\"bar\", strict=True, auto_naming=True)\n\t    assert r.project == \"bar\"\n", "    assert r.strict\n\t    assert r.auto_naming\n\tdef test_registry_as_mapping(subtests):\n\t    r: Registry = Registry()\n\t    with subtests.test(\"contains\"):\n\t        r[\"foo\"] = lambda x: None\n\t        assert \"foo\" in r\n\t        assert len(r) == 1\n\t    with subtests.test(\"del\"):\n\t        del r[\"foo\"]\n", "        assert \"foo\" not in r\n\t        assert len(r) == 0\n\t    with subtests.test(\"add twice\"):\n\t        r[\"foo\"] = lambda x: None\n\t        with pytest.raises(RuntimeError):\n\t            r[\"foo\"] = lambda x: None\n\t        del r[\"foo\"]\n\t    with subtests.test(\"locked\"):\n\t        assert not r.is_locked\n\t        r.lock()\n", "        assert r.is_locked\n\t        # Should be ok\n\t        r.lock()\n\t        with pytest.raises(RuntimeError):\n\t            r[\"foo\"] = lambda x: None\n\t        with pytest.raises(RuntimeError):\n\t            del r[\"foo\"]\n\tdef test_registry_decorator(subtests):\n\t    r: Registry = Registry(auto_naming=True)\n\t    @r(\"foo\")\n", "    def foo():\n\t        pass\n\t    with subtests.test(\"contains\"):\n\t        assert \"foo\" in r\n\t    with subtests.test(\"iter\"):\n\t        assert list(r) == [\"foo\"]\n\t    with subtests.test(\"items\"):\n\t        assert dict(r.items()) == {\"foo\": foo}\n\t    with subtests.test(\"keys\"):\n\t        assert list(r.keys()) == [\"foo\"]\n", "    with subtests.test(\"values\"):\n\t        assert list(r.values()) == [foo]\n\t    with subtests.test(\"del\"):\n\t        del r[\"foo\"]\n\t        assert \"foo\" not in r\n\tdef test_auto_naming(subtests):\n\t    with subtests.test(\"enabled\"):\n\t        r: Registry = Registry(project=\"test\", auto_naming=True)\n\t        with pytest.raises(KeyError):\n\t            print(r[\"bar\"])\n", "        @r\n\t        def foo():\n\t            pass\n\t        auto_name = r.get_name(foo)\n\t        assert auto_name in r\n\t        assert auto_name == (\n\t            \"test.tests.test_registry.test_auto_naming.<locals>.foo\"\n\t        )\n\t        assert r.resolve(auto_name) == r.resolve(foo)\n\t    with subtests.test(\"disabled\"):\n", "        r = Registry(project=\"test\", auto_naming=False)\n\t        with pytest.raises(ValueError):\n\t            @r\n\t            def foo():\n\t                pass\n\t        @r(\"spam\")\n\t        def spam():\n\t            pass\n\t        assert r.resolve(\"spam\") == spam\n\t        with pytest.raises(ValueError):\n", "            assert r.resolve(spam) is not None\n\t    with subtests.test(\"strict\"):\n\t        r = Registry(project=\"test\", auto_naming=True, strict=True)\n\t        @r\n\t        def bar():\n\t            pass\n\t        def baz():\n\t            pass\n\t        auto_name = r.get_name(bar)\n\t        assert auto_name in r\n", "        assert auto_name == (\n\t            \"test.tests.test_registry.test_auto_naming.<locals>.bar.\"\n\t            \"R+2IfaUD/3mHEJQ+XeqUstkXG1ZBRtFA74WWe05ex+w\"\n\t        )\n\t        assert r.resolve(auto_name) == r.resolve(bar)\n\t        with pytest.raises(KeyError):\n\t            r.get_name(baz)\n\t        r(baz)\n\t        assert r.get_name(baz) == (\n\t            \"test.tests.test_registry.test_auto_naming.<locals>.baz.\"\n", "            \"mYEWlo2vwOi3I/Z2rb5wayVONVncmvJ83EX07QsVOq8\"\n\t        )\n\tdef pickling_foo():\n\t    return\n\tdef pickling_bar():\n\t    return 1\n\tdef test_pickling():\n\t    r1: Registry = Registry()\n\t    r1(pickling_foo)\n\t    r1(pickling_bar)\n", "    r1[\"spam\"] = pickling_bar\n\t    dumped = pickle.dumps(r1)\n\t    r2: Registry = pickle.loads(dumped)\n\t    assert len(r2)\n\t    assert list(r1) == list(r2)\n\t    assert list(sorted(r1.items())) == list(sorted(r2.items()))\n"]}
{"filename": "tests/test_memory_broker.py", "chunked_list": ["from functools import reduce\n\tfrom operator import mul\n\tfrom typing import Any, AsyncGenerator\n\timport pytest\n\tfrom patio import Registry\n\tfrom patio.broker import MemoryBroker\n\tfrom patio.executor import ThreadPoolExecutor\n\t@pytest.fixture\n\tdef registry():\n\t    r: Registry = Registry()\n", "    @r(\"mul\")\n\t    def multiply(*args: int) -> int:\n\t        return reduce(mul, args)\n\t    return r\n\t@pytest.fixture\n\tasync def broker(\n\t    thread_executor: ThreadPoolExecutor,\n\t) -> AsyncGenerator[Any, MemoryBroker]:\n\t    async with MemoryBroker(thread_executor) as broker:\n\t        yield broker\n", "async def test_mul(broker: MemoryBroker):\n\t    assert await broker.call(\"mul\", 1, 2, 3) == 6\n"]}
{"filename": "tests/test_executor.py", "chunked_list": ["import asyncio\n\tfrom functools import reduce\n\tfrom operator import mul\n\tfrom typing import Any, AsyncGenerator\n\timport pytest\n\tfrom patio import Registry\n\tfrom patio.executor import (\n\t    AbstractExecutor, AsyncExecutor, NullExecutor, ProcessPoolExecutor,\n\t    ThreadPoolExecutor,\n\t)\n", "class AsyncExecutorBaseCase:\n\t    @staticmethod\n\t    def multiply(*args: int) -> Any:\n\t        raise NotImplementedError\n\t    @pytest.fixture\n\t    def registry(self) -> Registry:\n\t        rpc: Registry = Registry()\n\t        rpc[\"mul\"] = self.multiply\n\t        return rpc\n\t    async def test_multiply(self, executor: AbstractExecutor):\n", "        assert await executor.submit(self.multiply, 1, 2, 3) == 6\n\t    async def test_multiply_gather(self, executor: AbstractExecutor):\n\t        tasks = []\n\t        for _ in range(100):\n\t            tasks.append(executor.submit(self.multiply, 1, 2, 3))\n\t        assert await asyncio.gather(*tasks) == [6] * 100\n\tclass TestAsyncExecutor(AsyncExecutorBaseCase):\n\t    @pytest.fixture\n\t    async def executor(\n\t        self, registry: Registry,\n", "    ) -> AsyncGenerator[Any, AbstractExecutor]:\n\t        async with AsyncExecutor(registry) as executor:\n\t            yield executor\n\t    @staticmethod\n\t    async def multiply(*args: int) -> int:\n\t        return reduce(mul, args)\n\tclass TestThreadPoolExecutor(AsyncExecutorBaseCase):\n\t    @pytest.fixture\n\t    async def executor(\n\t        self, registry: Registry,\n", "    ) -> AsyncGenerator[Any, AbstractExecutor]:\n\t        async with ThreadPoolExecutor(registry) as executor:\n\t            yield executor\n\t    @staticmethod\n\t    def multiply(*args: int) -> int:\n\t        return reduce(mul, args)\n\tclass TestProcessPoolExecutor(AsyncExecutorBaseCase):\n\t    @pytest.fixture\n\t    async def executor(\n\t        self, registry: Registry,\n", "    ) -> AsyncGenerator[Any, AbstractExecutor]:\n\t        async with ProcessPoolExecutor(registry) as executor:\n\t            yield executor\n\t    @staticmethod\n\t    def multiply(*args: int) -> int:\n\t        return reduce(mul, args)\n\tclass TestNullExecutor:\n\t    @pytest.fixture\n\t    def registry(self) -> Registry:\n\t        rpc: Registry = Registry()\n", "        return rpc\n\t    @pytest.fixture\n\t    async def executor(\n\t        self, registry: Registry,\n\t    ) -> AsyncGenerator[Any, NullExecutor]:\n\t        async with NullExecutor(registry) as executor:\n\t            yield executor\n\t    async def test_simple(self, executor: AbstractExecutor):\n\t        with pytest.raises(RuntimeError):\n\t            await executor.submit(print)\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["from typing import Any, AsyncGenerator\n\timport pytest\n\tfrom patio import Registry\n\tfrom patio.executor import ThreadPoolExecutor\n\t@pytest.fixture\n\tdef registry():\n\t    return Registry()\n\t@pytest.fixture()\n\tasync def thread_executor(\n\t    registry: Registry,\n", ") -> AsyncGenerator[Any, ThreadPoolExecutor]:\n\t    async with ThreadPoolExecutor(registry) as executor:\n\t        yield executor\n"]}
{"filename": "tests/tcp_broker/test_tcp_broker.py", "chunked_list": ["import asyncio\n\timport time\n\tfrom functools import reduce\n\tfrom operator import mul, truediv\n\timport pytest\n\tfrom patio import Registry, TCPClientBroker, TCPServerBroker\n\tfrom patio.broker import TimeoutType\n\tfrom patio.broker.tcp.protocol import Protocol\n\t@pytest.fixture\n\tdef registry():\n", "    rpc: Registry = Registry()\n\t    @rpc(\"mul\")\n\t    def multiply(*args: int) -> int:\n\t        return reduce(mul, args)\n\t    @rpc(\"div\")\n\t    def division(*args: int) -> int:\n\t        return reduce(truediv, args)\n\t    @rpc(\"sleep\")\n\t    def sleep(delay: TimeoutType) -> None:\n\t        time.sleep(delay)\n", "    return rpc\n\tasync def test_mul(\n\t    server_broker: TCPServerBroker,\n\t    client_broker: TCPClientBroker,\n\t    subtests,\n\t):\n\t    with subtests.test(\"call from server\"):\n\t        assert await server_broker.call(\"mul\", 1, 2, 3) == 6\n\t    with subtests.test(\"call from client\"):\n\t        assert await client_broker.call(\"mul\", 1, 2, 3) == 6\n", "    with subtests.test(\"max serial reached\"):\n\t        client_broker.protocol.serial = Protocol.MAX_SERIAL - 1\n\t        assert await client_broker.call(\"mul\", 2, 2) == 4\n\t        assert client_broker.protocol.serial == 1\n\t    with subtests.test(\"error\"):\n\t        with pytest.raises(ZeroDivisionError):\n\t            assert await server_broker.call(\"div\", 2, 0)\n\tasync def test_timeout(\n\t    server_broker: TCPServerBroker,\n\t    client_broker: TCPClientBroker,\n", "    subtests,\n\t):\n\t    with pytest.raises(asyncio.TimeoutError):\n\t        await server_broker.call(\"sleep\", 0.5, timeout=0.1)\n\t    # waiting for response\n\t    await asyncio.sleep(1)\n\tasync def test_no_route(\n\t    server_broker: TCPServerBroker,\n\t    client_broker: TCPClientBroker,\n\t    subtests,\n", "):\n\t    with pytest.raises(asyncio.TimeoutError):\n\t        await server_broker.call(\"not-found\", timeout=0.5)\n"]}
{"filename": "tests/tcp_broker/__init__.py", "chunked_list": []}
{"filename": "tests/tcp_broker/test_restricted.py", "chunked_list": ["import os\n\timport pickle\n\timport pytest\n\tfrom patio import Registry, TCPClientBroker, TCPServerBroker\n\tfrom patio.broker.serializer import (\n\t    AbstractSerializer, RestrictedPickleSerializer,\n\t)\n\t@pytest.fixture(params=[RestrictedPickleSerializer()], ids=[\"restricted\"])\n\tdef serializer(request) -> AbstractSerializer:\n\t    return request.param\n", "@pytest.fixture\n\tdef registry():\n\t    rpc: Registry = Registry()\n\t    @rpc(\"call_any\")\n\t    def call_any(func, *args):\n\t        return func(*args)\n\t    return rpc\n\tasync def test_restricted(\n\t    server_broker: TCPServerBroker,\n\t    client_broker: TCPClientBroker,\n", "    subtests,\n\t):\n\t    with pytest.raises(pickle.UnpicklingError):\n\t        assert await client_broker.call(\n\t            \"call_any\", os.execv, \"ls\", [\"ls\", \"-1\"],\n\t        )\n"]}
{"filename": "tests/tcp_broker/conftest.py", "chunked_list": ["import ssl\n\tfrom pathlib import Path\n\tfrom typing import Any, AsyncGenerator, Optional, Tuple\n\timport pytest\n\tfrom patio import TCPClientBroker, TCPServerBroker\n\tfrom patio.broker.serializer import (\n\t    AbstractSerializer, PickleSerializer, RestrictedPickleSerializer,\n\t)\n\tfrom patio.executor import ThreadPoolExecutor\n\tSSL_PATH = Path(__file__).parent / \"ssl\"\n", "SSL_CA_FILE = SSL_PATH / \"CA.pem\"\n\tSSL_SERVER_CERT_FILE = SSL_PATH / \"server.pem\"\n\tSSL_CLIENT_CERT_FILE = SSL_PATH / \"client.pem\"\n\tSSL_SERVER_KEY_FILE = SSL_PATH / \"server.key\"\n\tSSL_CLIENT_KEY_FILE = SSL_PATH / \"client.key\"\n\tdef ssl_server_context(\n\t    mode=ssl.VerifyMode.CERT_OPTIONAL,\n\t) -> ssl.SSLContext:\n\t    ctx = ssl.SSLContext()\n\t    ctx.verify_mode = mode\n", "    ctx.load_verify_locations(SSL_CA_FILE)\n\t    ctx.load_cert_chain(SSL_SERVER_CERT_FILE, SSL_SERVER_KEY_FILE)\n\t    return ctx\n\tdef ssl_client_context() -> ssl.SSLContext:\n\t    ctx = ssl.SSLContext()\n\t    ctx.load_cert_chain(SSL_CLIENT_CERT_FILE, SSL_CLIENT_KEY_FILE)\n\t    return ctx\n\t@pytest.fixture()\n\tdef server_port(aiomisc_unused_port_factory) -> int:\n\t    return aiomisc_unused_port_factory()\n", "@pytest.fixture(\n\t    params=[\n\t        [\n\t            ssl_server_context(ssl.VerifyMode.CERT_OPTIONAL),\n\t            ssl.create_default_context(cafile=SSL_CA_FILE),\n\t        ],\n\t        [\n\t            ssl_server_context(ssl.VerifyMode.CERT_REQUIRED),\n\t            ssl_client_context(),\n\t        ],\n", "        [None, None],\n\t    ],\n\t    ids=[\"ssl\", \"ssl-client\", \"no-ssl\"],\n\t)\n\tdef ssl_context_pair(request) -> Tuple[\n\t    Optional[ssl.SSLContext],\n\t    Optional[ssl.SSLContext],\n\t]:\n\t    return request.param\n\t@pytest.fixture(\n", "    params=[\n\t        PickleSerializer(),\n\t        RestrictedPickleSerializer(),\n\t    ],\n\t    ids=[\"pickle\", \"restricted-pickle\"],\n\t)\n\tdef serializer(request) -> AbstractSerializer:\n\t    return request.param\n\t@pytest.fixture()\n\tasync def server_broker(\n", "    server_port: int, thread_executor: ThreadPoolExecutor,\n\t    localhost: str, ssl_context_pair, serializer: AbstractSerializer,\n\t) -> AsyncGenerator[Any, TCPServerBroker]:\n\t    ctx, _ = ssl_context_pair\n\t    async with TCPServerBroker(\n\t        thread_executor, ssl_context=ctx, serializer=serializer,\n\t    ) as broker:\n\t        await broker.listen(localhost, server_port)\n\t        yield broker\n\t@pytest.fixture()\n", "async def client_broker(\n\t    server_port: int, thread_executor: ThreadPoolExecutor,\n\t    server_broker: TCPServerBroker, localhost: str, ssl_context_pair,\n\t    serializer: AbstractSerializer,\n\t) -> AsyncGenerator[Any, TCPClientBroker]:\n\t    _, ctx = ssl_context_pair\n\t    async with TCPClientBroker(\n\t        thread_executor, ssl_context=ctx, serializer=serializer,\n\t    ) as broker:\n\t        await broker.connect(localhost, server_port)\n", "        yield broker\n"]}
{"filename": "patio/registry.py", "chunked_list": ["import hashlib\n\timport inspect\n\tfrom base64 import b64encode\n\tfrom collections import defaultdict\n\tfrom types import MappingProxyType\n\tfrom typing import (\n\t    Any, Awaitable, Callable, DefaultDict, Dict, Generic, ItemsView, Iterator,\n\t    KeysView, MutableMapping, Optional, Set, Tuple, TypeVar, Union, ValuesView,\n\t    overload,\n\t)\n", "from patio.compat import Self\n\tT = TypeVar(\"T\")\n\tAsyncTaskFunctionType = Callable[..., Awaitable[T]]\n\tSyncTaskFunctionType = Callable[..., T]\n\tTaskFunctionType = Union[AsyncTaskFunctionType, SyncTaskFunctionType]\n\tStoreType = Union[Dict[str, TaskFunctionType], MappingProxyType]\n\tReverseStoreType = Union[\n\t    DefaultDict[TaskFunctionType, Set[str]],\n\t    MappingProxyType,\n\t]\n", "class Registry(MutableMapping, Generic[T]):\n\t    \"\"\"\n\t    This is a container of functions for their subsequent execution.\n\t    You can register a function by specific name or without it,\n\t    in which case the function is assigned a unique name that depends on\n\t    the source code of the function.\n\t    This registry does not necessarily have to match on the calling and called\n\t    sides, but for functions that you register without a name it is must be,\n\t    and then you should not need to pass the function name but the function\n\t    itself when you will call it.\n", "    An instance of the registry must be transferred to the broker,\n\t    the first broker in the process of setting up will block the registry\n\t    to write, that is, registering new functions will be impossible.\n\t    An optional ``project`` parameter, this is essentially like a namespace\n\t    that will help avoid clash functions in different projects with the same\n\t    name. It is recommended to specify it and the broker should also use this\n\t    parameter, so it should be the same value within the same project.\n\t    You can either manually register elements or use a\n\t    registry instance as a decorator:\n\t    .. code-block:: python\n", "        from patio import Registry\n\t        rpc = Registry(project=\"example\")\n\t        # Will be registered with auto generated name\n\t        @rpc\n\t        def mul(a, b):\n\t            return a * b\n\t        @rpc('div')\n\t        def div(a, b):\n\t            return a / b\n\t        def pow(a, b):\n", "            return a ** b\n\t        def sub(a, b):\n\t            return a - b\n\t        # Register with auto generated name\n\t        rpc.register(pow)\n\t        rpc.register(sub, \"sub\")\n\t    Alternatively using ``register`` method:\n\t    .. code-block:: python\n\t        from patio import Registry\n\t        rpc = Registry(project=\"example\")\n", "        def pow(a, b):\n\t            return a ** b\n\t        def sub(a, b):\n\t            return a - b\n\t        # Register with auto generated name\n\t        rpc.register(pow)\n\t        rpc.register(sub, \"sub\")\n\t    Finally, you can register functions explicitly, as if it were\n\t    just a dictionary:\n\t    .. code-block:: python\n", "        from patio import Registry\n\t        rpc = Registry(project=\"example\")\n\t        def mul(a, b):\n\t            return a * b\n\t        rpc['mul'] = mul\n\t    \"\"\"\n\t    __slots__ = (\n\t        \"__project\", \"__strict\", \"__store\", \"__reverse_store\", \"__locked\",\n\t        \"__auto_naming\",\n\t    )\n", "    def __init__(\n\t        self, project: Optional[str] = None, strict: bool = False,\n\t        auto_naming: bool = True,\n\t    ):\n\t        self.__auto_naming: bool = auto_naming\n\t        self.__project = project\n\t        self.__strict = strict\n\t        self.__store: StoreType = {}\n\t        self.__reverse_store: ReverseStoreType = defaultdict(set)\n\t        self.__locked = False\n", "    @property\n\t    def is_locked(self) -> bool:\n\t        return self.__locked\n\t    @property\n\t    def project(self) -> Optional[str]:\n\t        return self.__project\n\t    @property\n\t    def strict(self) -> bool:\n\t        return self.__strict\n\t    @property\n", "    def auto_naming(self) -> bool:\n\t        return self.__auto_naming\n\t    def _make_function_name(self, func: TaskFunctionType) -> str:\n\t        parts = []\n\t        if self.project is not None:\n\t            parts.append(self.project)\n\t        if hasattr(func, \"__module__\"):\n\t            parts.append(func.__module__)\n\t        if hasattr(func, \"__qualname__\"):\n\t            parts.append(func.__qualname__)\n", "        if self.strict:\n\t            sources = inspect.getsource(func)\n\t            parts.append(\n\t                b64encode(\n\t                    hashlib.blake2s(sources.encode()).digest(),\n\t                ).strip(b\"=\").decode(),\n\t            )\n\t        return \".\".join(parts)\n\t    def lock(self) -> None:\n\t        if self.is_locked:\n", "            return\n\t        self.__store = MappingProxyType(self.__store)\n\t        self.__reverse_store = MappingProxyType({\n\t            k: frozenset(v) for k, v in self.__reverse_store.items()\n\t        })\n\t        self.__locked = True\n\t    def register(\n\t        self, func: TaskFunctionType, name: Optional[str] = None,\n\t    ) -> str:\n\t        if name is None:\n", "            if not self.__auto_naming:\n\t                raise ValueError(\n\t                    \"auto_naming is disabled, \"\n\t                    \"name parameter is required\",\n\t                )\n\t            name = self._make_function_name(func)\n\t        self[name] = func\n\t        return name\n\t    @overload\n\t    def __call__(self, name: TaskFunctionType) -> TaskFunctionType:\n", "        ...\n\t    @overload\n\t    def __call__(\n\t        self, name: Optional[str] = None,\n\t    ) -> Callable[..., TaskFunctionType]:\n\t        ...\n\t    def __call__(\n\t        self, name: Union[Optional[str], TaskFunctionType] = None,\n\t    ) -> Union[Callable[..., TaskFunctionType], TaskFunctionType]:\n\t        if callable(name):\n", "            return self.__call__(None)(name)\n\t        function_name: Optional[str] = name\n\t        def decorator(func: TaskFunctionType) -> TaskFunctionType:\n\t            self.register(func, function_name)\n\t            return func\n\t        return decorator\n\t    def __setitem__(self, name: str, func: TaskFunctionType) -> None:\n\t        if name in self.__store:\n\t            raise RuntimeError(\n\t                f\"Task with name {name!r} already \"\n", "                f\"registered for {self.__store[name]!r}\",\n\t            )\n\t        if (\n\t            isinstance(self.__store, MappingProxyType) or\n\t            isinstance(self.__reverse_store, MappingProxyType)\n\t        ):\n\t            raise RuntimeError(\"Registry locked\")\n\t        self.__store[name] = func\n\t        self.__reverse_store[func].add(name)\n\t    def __delitem__(self, name: str) -> None:\n", "        if (\n\t            isinstance(self.__store, MappingProxyType) or\n\t            isinstance(self.__reverse_store, MappingProxyType)\n\t        ):\n\t            raise RuntimeError(\"Registry locked\")\n\t        func = self.__store.pop(name)\n\t        del self.__reverse_store[func]\n\t    def __getitem__(self, name: str) -> TaskFunctionType:\n\t        return self.__store[name]\n\t    def __len__(self) -> int:\n", "        return len(self.__store)\n\t    def __iter__(self) -> Iterator[str]:\n\t        return iter(self.__store)\n\t    def items(self) -> ItemsView[str, TaskFunctionType]:\n\t        return self.__store.items()\n\t    def keys(self) -> KeysView[str]:\n\t        return self.__store.keys()\n\t    def values(self) -> ValuesView[TaskFunctionType]:\n\t        return self.__store.values()\n\t    def get_names(self, func: TaskFunctionType) -> Tuple[str, ...]:\n", "        return tuple(self.__reverse_store[func])\n\t    def get_name(self, func: TaskFunctionType) -> str:\n\t        candidates = self.get_names(func)\n\t        if not candidates:\n\t            raise KeyError(f\"{func!r} has not been registered\")\n\t        return candidates[0]\n\t    @overload\n\t    def resolve(self, func: str) -> Callable[..., T]:\n\t        ...\n\t    @overload\n", "    def resolve(self, func: Callable[..., T]) -> Callable[..., T]:\n\t        ...\n\t    def resolve(\n\t        self, func: Union[str, Callable[..., T]],\n\t    ) -> Callable[..., Any]:\n\t        if not isinstance(func, str):\n\t            if not self.__auto_naming:\n\t                raise ValueError(\n\t                    \"auto_naming is disabled, \"\n\t                    \"name parameter is required\",\n", "                )\n\t            func = self.get_name(func)\n\t        return self[func]\n\t    def __getstate__(self) -> Dict[str, Any]:\n\t        return dict(\n\t            auto_naming=self.__auto_naming,\n\t            project=self.__project,\n\t            strict=self.__strict,\n\t            store=self.__store,\n\t            locked=self.__locked,\n", "        )\n\t    def __setstate__(self, state: Dict[str, Any]) -> None:\n\t        self.__auto_naming = state[\"auto_naming\"]\n\t        self.__project = state[\"project\"]\n\t        self.__strict = state[\"strict\"]\n\t        self.__locked = state[\"locked\"]\n\t        self.__store = {}\n\t        self.__reverse_store = defaultdict(set)\n\t        for name, func in state[\"store\"].items():\n\t            self[name] = func\n", "    def __copy__(self) -> Self:\n\t        clone = self.__class__()\n\t        clone.__setstate__(self.__getstate__())\n\t        return clone\n\t__all__ = (\n\t    \"AsyncTaskFunctionType\",\n\t    \"Registry\",\n\t    \"SyncTaskFunctionType\",\n\t    \"T\",\n\t    \"TaskFunctionType\",\n", ")\n"]}
{"filename": "patio/compat.py", "chunked_list": ["import asyncio\n\timport sys\n\tfrom typing import Generic, TypeVar\n\ttry:\n\t    from typing import Self  # type: ignore\n\texcept ImportError:\n\t    from typing_extensions import Self\n\tT = TypeVar(\"T\")\n\tif sys.version_info >= (3, 9):\n\t    from asyncio import Queue\n", "else:\n\t    class Queue(asyncio.Queue, Generic[T]):\n\t        async def get(self) -> T:\n\t            return await super().get()\n\t        async def put(self, element: T) -> T:\n\t            return await super().put(element)\n\t        def get_nowait(self) -> T:\n\t            return super().get_nowait()\n\t        def put_nowait(self, element: T) -> None:\n\t            return super().put_nowait(element)\n", "__all__ = (\"Queue\", \"Self\")\n"]}
{"filename": "patio/__init__.py", "chunked_list": ["from patio.broker import (\n\t    AbstractBroker, MemoryBroker, TCPBrokerBase, TCPClientBroker,\n\t    TCPServerBroker,\n\t)\n\tfrom patio.executor import (\n\t    AbstractExecutor, AsyncExecutor, NullExecutor, ProcessPoolExecutor,\n\t    ThreadPoolExecutor,\n\t)\n\tfrom patio.registry import Registry, TaskFunctionType\n\t__all__ = (\n", "    \"AbstractBroker\",\n\t    \"AbstractExecutor\",\n\t    \"AsyncExecutor\",\n\t    \"MemoryBroker\",\n\t    \"NullExecutor\",\n\t    \"ProcessPoolExecutor\",\n\t    \"Registry\",\n\t    \"TCPBrokerBase\",\n\t    \"TCPClientBroker\",\n\t    \"TCPServerBroker\",\n", "    \"TaskFunctionType\",\n\t    \"ThreadPoolExecutor\",\n\t)\n"]}
{"filename": "patio/executor/base.py", "chunked_list": ["from __future__ import annotations\n\tfrom abc import abstractmethod\n\tfrom typing import Any, AsyncContextManager, Awaitable, Generic, Union\n\tfrom patio.registry import Registry, T, TaskFunctionType\n\tclass AbstractExecutor(Generic[T], AsyncContextManager):\n\t    \"\"\"\n\t    An Executor is an entity that executes local functions on the local side.\n\t    The following executors are implemented in the package:\n\t    * :class:`AsyncExecutor`\n\t    * :class:`ThreadPoolExecutor`\n", "    * :class:`ProcessPoolExecutor`\n\t    * :class:`NullExecutor`\n\t    Its role is to reliably execute jobs without taking too much so as not to\n\t    cause a denial of service, or excessive memory consumption.\n\t    The executor instance is passing to the broker, it's usually applies\n\t    it to the whole registry. Therefore, you should understand what functions\n\t    the registry must contain to choose kind of an executor.\n\t    \"\"\"\n\t    DEFAULT_MAX_WORKERS: int = 4\n\t    def __init__(\n", "        self, registry: Registry, max_workers: int = DEFAULT_MAX_WORKERS,\n\t    ):\n\t        self.registry = registry\n\t        self.max_workers = max_workers\n\t    @abstractmethod\n\t    async def setup(self) -> None:\n\t        \"\"\"\n\t        Configures the executor, can be called several times, with the\n\t        assumption that it will be configured exactly once.\n\t        \"\"\"\n", "        raise NotImplementedError(\n\t            f\"Not implemented method setup \"\n\t            f\"in {self.__class__.__name__!r} \",\n\t        )\n\t    @abstractmethod\n\t    def submit(\n\t        self, func: TaskFunctionType, *args: Any, **kwargs: Any\n\t    ) -> Awaitable[T]:\n\t        \"\"\"\n\t        Passes the function to execute, and waits for the result, returns it.\n", "        :param func: Function to be executed\n\t        :param args: positional arguments of the Function\n\t        :param kwargs: keyword arguments of the function\n\t        :return: the result that the function will return\n\t        \"\"\"\n\t        raise NotImplementedError(\n\t            f\"Not implemented method submit in {self.__class__.__name__!r} \"\n\t            f\"Call {func!r} with args={args!r}, kwargs={kwargs!r} skipped\",\n\t        )\n\t    @abstractmethod\n", "    async def shutdown(self) -> None:\n\t        \"\"\"\n\t        Performs an executor stop. All related and unperformed tasks\n\t        must be completed.\n\t        \"\"\"\n\t    async def __aenter__(self) -> AbstractExecutor:\n\t        await self.setup()\n\t        return self\n\t    async def __aexit__(self, *args: Any) -> None:\n\t        await self.shutdown()\n", "    async def execute(\n\t        self, func: Union[str, TaskFunctionType], *args: Any, **kwargs: Any\n\t    ) -> T:\n\t        func = self.registry.resolve(func)\n\t        return await self.submit(func, *args, ** kwargs)\n"]}
{"filename": "patio/executor/thread_pool.py", "chunked_list": ["import asyncio\n\timport concurrent.futures\n\tfrom functools import cached_property, partial\n\tfrom typing import Any, Awaitable\n\tfrom patio.executor.base import AbstractExecutor\n\tfrom patio.registry import SyncTaskFunctionType, T\n\tclass ThreadPoolExecutor(AbstractExecutor[T]):\n\t    \"\"\"\n\t    Execute jobs in a thread pool. Jobs cannot be asynchronous functions.\n\t    This means that the whole registry must not contain functions other than\n", "    specified kind.\n\t    \"\"\"\n\t    __slots__ = \"max_workers\", \"executor\"\n\t    DEFAULT_MAX_WORKERS: int = 4\n\t    executor: concurrent.futures.ThreadPoolExecutor\n\t    @cached_property\n\t    def loop(self) -> asyncio.AbstractEventLoop:\n\t        return asyncio.get_running_loop()\n\t    async def setup(self) -> None:\n\t        if hasattr(self, \"executor\"):\n", "            return\n\t        self.executor = await self.loop.run_in_executor(\n\t            None, concurrent.futures.ThreadPoolExecutor, self.max_workers,\n\t        )\n\t    def submit(\n\t        self, func: SyncTaskFunctionType, *args: Any, **kwargs: Any\n\t    ) -> Awaitable[T]:\n\t        return self.loop.run_in_executor(\n\t            self.executor, partial(func, *args, **kwargs),\n\t        )\n", "    async def shutdown(self) -> None:\n\t        await self.loop.run_in_executor(\n\t            None, partial(self.executor.shutdown, wait=True),\n\t        )\n"]}
{"filename": "patio/executor/null.py", "chunked_list": ["import copy\n\tfrom typing import Any, Awaitable, Callable\n\tfrom patio.executor.base import AbstractExecutor\n\tfrom patio.registry import T\n\tclass NullExecutor(AbstractExecutor):\n\t    \"\"\"\n\t    Doesn't execute anything, serves as a stub to explicitly forbid calls\n\t    to this registry.\n\t    \"\"\"\n\t    async def setup(self) -> None:\n", "        self.registry = copy.copy(self.registry)\n\t        self.registry.clear()\n\t    def submit(\n\t        self, func: Callable[..., T], *args: Any, **kwargs: Any\n\t    ) -> Awaitable[T]:\n\t        raise RuntimeError(\"Null executor can't execute anything\")\n\t    async def shutdown(self) -> None:\n\t        pass\n"]}
{"filename": "patio/executor/__init__.py", "chunked_list": ["from .asyncronous import AsyncExecutor\n\tfrom .base import AbstractExecutor\n\tfrom .null import NullExecutor\n\tfrom .process_pool import ProcessPoolExecutor\n\tfrom .thread_pool import ThreadPoolExecutor\n\t__all__ = (\n\t    \"AbstractExecutor\",\n\t    \"AsyncExecutor\",\n\t    \"NullExecutor\",\n\t    \"ProcessPoolExecutor\",\n", "    \"ThreadPoolExecutor\",\n\t)\n"]}
{"filename": "patio/executor/process_pool.py", "chunked_list": ["import asyncio\n\timport concurrent.futures\n\tfrom functools import cached_property, partial\n\tfrom typing import Any, Awaitable\n\tfrom patio.executor.base import AbstractExecutor\n\tfrom patio.registry import SyncTaskFunctionType, T\n\tclass ProcessPoolExecutor(AbstractExecutor[T]):\n\t    \"\"\"\n\t    Execute jobs in the process pool. Jobs cannot be asynchronous functions.\n\t    This means that the whole registry must not contain functions other than\n", "    specified kind.\n\t    \"\"\"\n\t    __slots__ = \"max_workers\", \"executor\"\n\t    DEFAULT_MAX_WORKERS: int = 4\n\t    executor: concurrent.futures.ProcessPoolExecutor\n\t    @cached_property\n\t    def loop(self) -> asyncio.AbstractEventLoop:\n\t        return asyncio.get_running_loop()\n\t    async def setup(self) -> None:\n\t        if hasattr(self, \"executor\"):\n", "            return\n\t        self.executor = await self.loop.run_in_executor(\n\t            None, concurrent.futures.ProcessPoolExecutor, self.max_workers,\n\t        )\n\t    def submit(\n\t        self, func: SyncTaskFunctionType, *args: Any, **kwargs: Any\n\t    ) -> Awaitable[T]:\n\t        return self.loop.run_in_executor(\n\t            self.executor, partial(func, *args, **kwargs),\n\t        )\n", "    async def shutdown(self) -> None:\n\t        await self.loop.run_in_executor(None, self.executor.shutdown, True)\n"]}
{"filename": "patio/executor/asyncronous.py", "chunked_list": ["import asyncio\n\tfrom functools import cached_property\n\tfrom typing import Any, Callable, Set, Tuple\n\tfrom patio.compat import Queue\n\tfrom patio.executor.base import AbstractExecutor\n\tfrom patio.registry import AsyncTaskFunctionType, T\n\tQueueType = Queue[Tuple[Callable[..., T], Any, Any, asyncio.Future]]\n\tclass AsyncExecutor(AbstractExecutor[T]):\n\t    \"\"\"\n\t    Executes the incoming tasks in the pool of the several concurrent tasks.\n", "    Tasks must be asynchronous functions, or functions that return an\n\t    awaitable object.\n\t    This means that the whole registry must not contain functions other than\n\t    specified kind.\n\t    \"\"\"\n\t    __slots__ = \"max_workers\", \"queue\", \"tasks\"\n\t    def __init__(self, *args: Any, **kwargs: Any):\n\t        super().__init__(*args, **kwargs)\n\t        self.queue: QueueType = Queue(maxsize=self.max_workers)\n\t        self.tasks: Set[asyncio.Task] = set()\n", "        self.started: bool = False\n\t    @cached_property\n\t    def loop(self) -> asyncio.AbstractEventLoop:\n\t        return asyncio.get_running_loop()\n\t    async def _executor(self) -> None:\n\t        while True:\n\t            func, args, kwargs, future = await self.queue.get()\n\t            if future.done():\n\t                continue\n\t            try:\n", "                future.set_result(await func(*args, **kwargs))\n\t            except Exception as e:\n\t                if future.done():\n\t                    continue\n\t                future.set_exception(e)\n\t    async def setup(self) -> None:\n\t        if self.started:\n\t            return\n\t        for _ in range(self.max_workers):\n\t            self.tasks.add(asyncio.create_task(self._executor()))\n", "        self.started = True\n\t    async def submit(\n\t        self, func: AsyncTaskFunctionType, *args: Any, **kwargs: Any\n\t    ) -> T:\n\t        future = self.loop.create_future()\n\t        await self.queue.put((func, args, kwargs, future))\n\t        return await future\n\t    async def shutdown(self) -> None:\n\t        cancelled = []\n\t        for task in self.tasks:\n", "            if task.done():\n\t                continue\n\t            task.cancel()\n\t            cancelled.append(task)\n\t        if cancelled:\n\t            await asyncio.gather(*cancelled, return_exceptions=True)\n"]}
{"filename": "patio/broker/abc.py", "chunked_list": ["import asyncio\n\tfrom abc import ABC, abstractmethod\n\tfrom functools import cached_property\n\tfrom typing import Any, Awaitable, Coroutine, List, Optional, Set, Union\n\tfrom patio.compat import Self\n\tfrom patio.executor import AbstractExecutor\n\tfrom patio.registry import TaskFunctionType\n\tTimeoutType = Union[int, float]\n\tclass AbstractBroker(ABC):\n\t    def __init__(self, executor: AbstractExecutor):\n", "        self.executor = executor\n\t        self.__tasks: Set[asyncio.Task] = set()\n\t    @cached_property\n\t    def loop(self) -> asyncio.AbstractEventLoop:\n\t        return asyncio.get_running_loop()\n\t    def create_task(self, coro: Coroutine[Any, Any, Any]) -> asyncio.Task:\n\t        task = self.loop.create_task(coro)\n\t        self.__tasks.add(task)\n\t        task.add_done_callback(self.__tasks.discard)\n\t        return task\n", "    async def setup(self) -> None:\n\t        await self.executor.setup()\n\t    async def close(self) -> None:\n\t        tasks: List[Awaitable[Any]] = [self.executor.shutdown()]\n\t        for task in tuple(self.__tasks):\n\t            if task.done():\n\t                continue\n\t            task.cancel()\n\t            tasks.append(task)\n\t        await asyncio.gather(*tasks, return_exceptions=True)\n", "    @abstractmethod\n\t    async def call(\n\t        self,\n\t        func: Union[str, TaskFunctionType],\n\t        *args: Any,\n\t        timeout: Optional[TimeoutType] = None,\n\t        **kwargs: Any,\n\t    ) -> Any:\n\t        ...\n\t    async def __aenter__(self) -> Self:\n", "        await self.setup()\n\t        return self\n\t    async def __aexit__(\n\t        self, exc_type: Any, exc_val: Any, exc_tb: Any,\n\t    ) -> None:\n\t        await self.close()\n\t    async def join(self) -> None:\n\t        async def waiter() -> None:\n\t            await self.loop.create_future()\n\t        await self.create_task(waiter())\n", "__all__ = \"AbstractBroker\", \"TimeoutType\", \"TaskFunctionType\"\n"]}
{"filename": "patio/broker/__init__.py", "chunked_list": ["from .abc import AbstractBroker, TimeoutType\n\tfrom .memory import MemoryBroker\n\tfrom .tcp.broker import TCPBrokerBase, TCPClientBroker, TCPServerBroker\n\t__all__ = (\n\t    \"AbstractBroker\",\n\t    \"MemoryBroker\",\n\t    \"TCPBrokerBase\",\n\t    \"TCPClientBroker\",\n\t    \"TCPServerBroker\",\n\t    \"TimeoutType\",\n", ")\n"]}
{"filename": "patio/broker/serializer.py", "chunked_list": ["from __future__ import annotations\n\timport builtins\n\timport inspect\n\timport pickle\n\tfrom abc import ABC, abstractmethod\n\tfrom io import BytesIO\n\tfrom typing import Any, Iterator\n\tclass AbstractSerializer(ABC):\n\t    @abstractmethod\n\t    def pack(self, payload: Any) -> bytes:\n", "        ...\n\t    @abstractmethod\n\t    def unpack(self, payload: bytes) -> Any:\n\t        ...\n\tclass PickleSerializer(AbstractSerializer):\n\t    def pack(self, payload: Any) -> bytes:\n\t        return pickle.dumps(payload, protocol=pickle.HIGHEST_PROTOCOL)\n\t    def unpack(self, payload: bytes) -> Any:\n\t        return pickle.loads(payload)\n\tdef _builtins_exceptions() -> Iterator[str]:\n", "    for item in dir(builtins):\n\t        obj = getattr(builtins, item)\n\t        if not inspect.isclass(obj):\n\t            continue\n\t        if issubclass(obj, BaseException):\n\t            yield f\"builtins.{obj.__name__}\"\n\tclass RestrictedUnpickler(pickle.Unpickler):\n\t    SAFE_EXCLUDES = frozenset({\n\t        \"builtins.complex\",\n\t        \"builtins.set\",\n", "        \"builtins.frozenset\",\n\t        *_builtins_exceptions(),\n\t    })\n\t    UNSAFE_MODULES = frozenset(\n\t        {\"builtins\", \"os\", \"sys\", \"posix\", \"_winapi\"},\n\t    )\n\t    def find_class(self, module: str, name: str) -> Any:\n\t        if module not in self.UNSAFE_MODULES:\n\t            return super().find_class(module, name)\n\t        if f\"{module}.{name}\" in self.SAFE_EXCLUDES:\n", "            return super().find_class(module, name)\n\t        raise pickle.UnpicklingError(f\"The '{module}.{name}' is forbidden\")\n\tclass RestrictedPickleSerializer(PickleSerializer):\n\t    def unpack(self, payload: bytes) -> Any:\n\t        with BytesIO(payload) as fp:\n\t            return RestrictedUnpickler(fp).load()\n"]}
{"filename": "patio/broker/memory.py", "chunked_list": ["import asyncio\n\tfrom typing import Any, Optional, Union\n\tfrom patio.broker.abc import AbstractBroker, TimeoutType\n\tfrom patio.registry import TaskFunctionType\n\tclass MemoryBroker(AbstractBroker):\n\t    async def call(\n\t        self,\n\t        func: Union[str, TaskFunctionType],\n\t        *args: Any,\n\t        timeout: Optional[TimeoutType] = 86400,\n", "        **kwargs: Any,\n\t    ) -> Any:\n\t        return await asyncio.wait_for(\n\t            self.executor.execute(func, *args, **kwargs),\n\t            timeout=timeout,\n\t        )\n\t__all__ = \"MemoryBroker\",\n"]}
{"filename": "patio/broker/tcp/protocol.py", "chunked_list": ["from __future__ import annotations\n\timport hashlib\n\timport threading\n\tfrom dataclasses import dataclass\n\tfrom enum import IntEnum, unique\n\tfrom io import BytesIO\n\tfrom random import getrandbits\n\tfrom struct import Struct\n\tfrom typing import Any, Optional, Tuple\n\tfrom patio.broker.serializer import AbstractSerializer\n", "@unique\n\tclass PacketTypes(IntEnum):\n\t    AUTH_DIGEST = 0\n\t    AUTH_REQUEST = 1\n\t    AUTH_RESPONSE = 2\n\t    AUTH_OK = 3\n\t    DISCOVER_REQUEST = 5\n\t    DISCOVER_RESPONSE = 6\n\t    REQUEST = 10\n\t    RESPONSE = 20\n", "    ERROR = 30\n\t@dataclass\n\tclass Header:\n\t    STRUCT = Struct(\"!bII\")\n\t    SIZE = STRUCT.size\n\t    type: PacketTypes\n\t    size: int\n\t    serial: int\n\t    def pack(self) -> bytes:\n\t        return self.STRUCT.pack(self.type.value, self.size, self.serial)\n", "    @classmethod\n\t    def unpack(cls, data: bytes) -> Header:\n\t        kind, size, serial = cls.STRUCT.unpack(data)\n\t        return cls(type=PacketTypes(kind), size=size, serial=serial)\n\tclass Protocol:\n\t    HEADER_STRUCT = Struct(\"!bII\")\n\t    MAX_SERIAL = 4294967295\n\t    __slots__ = \"__key\", \"serial\", \"lock\", \"serializer\"\n\t    def __init__(self, *, serializer: AbstractSerializer, key: bytes = b\"\"):\n\t        self.__key = key\n", "        self.serial = 0\n\t        self.lock = threading.Lock()\n\t        self.serializer = serializer\n\t    def get_serial(self) -> int:\n\t        with self.lock:\n\t            self.serial += 1\n\t            if self.serial >= self.MAX_SERIAL:\n\t                self.serial = 1\n\t            return self.serial\n\t    def digest(\n", "        self, data: bytes, *, salt: Optional[bytes] = None\n\t    ) -> Tuple[bytes, bytes]:\n\t        if salt is None:\n\t            salt = getrandbits(32).to_bytes(4, \"big\")\n\t        return salt, hashlib.blake2s(data, key=self.__key, salt=salt).digest()\n\t    def pack(\n\t        self, payload: Any, packet_type: PacketTypes,\n\t        *, serial: Optional[int] = None\n\t    ) -> bytes:\n\t        with BytesIO() as fp:\n", "            fp.seek(Header.SIZE)\n\t            fp.write(self.serializer.pack(payload))\n\t            header = Header(\n\t                type=packet_type,\n\t                size=fp.tell() - self.HEADER_STRUCT.size,\n\t                serial=serial or self.get_serial(),\n\t            )\n\t            fp.seek(0)\n\t            fp.write(header.pack())\n\t            return fp.getvalue()\n", "    def authorize_request(self, token: bytes) -> bytes:\n\t        salt, digest = self.digest(token)\n\t        return self.pack((salt, digest, token), PacketTypes.AUTH_REQUEST)\n\t    def authorize_check(self, payload: bytes) -> bool:\n\t        salt, digest, token = self.serializer.unpack(payload)\n\t        return self.digest(token, salt=salt) == (salt, digest)\n\t    def pack_error(self, exception: Exception, serial: int) -> bytes:\n\t        return self.pack(exception, PacketTypes.ERROR, serial=serial)\n\t__all__ = (\"PacketTypes\", \"Header\", \"Protocol\")\n"]}
{"filename": "patio/broker/tcp/broker.py", "chunked_list": ["from __future__ import annotations\n\timport asyncio\n\timport logging\n\timport pickle\n\timport ssl\n\timport uuid\n\tfrom abc import ABC, abstractmethod\n\tfrom collections import defaultdict, deque\n\tfrom dataclasses import dataclass\n\tfrom functools import cached_property\n", "from types import MappingProxyType\n\tfrom typing import (\n\t    Any, Callable, Coroutine, DefaultDict, Deque, Dict, Iterable, List, Mapping,\n\t    Optional, Set, Tuple, TypeVar, Union, final,\n\t)\n\tfrom patio.broker import AbstractBroker, TimeoutType\n\tfrom patio.broker.serializer import (\n\t    AbstractSerializer, RestrictedPickleSerializer,\n\t)\n\tfrom patio.broker.tcp.protocol import Header, PacketTypes, Protocol\n", "from patio.compat import Queue\n\tfrom patio.executor import AbstractExecutor\n\tfrom patio.registry import Registry, TaskFunctionType\n\tT = TypeVar(\"T\")\n\tlog = logging.getLogger(__name__)\n\t@dataclass(frozen=True)\n\tclass RPCEvent:\n\t    header: Header\n\t    payload: bytes\n\t@dataclass\n", "class CallRequest:\n\t    func: str\n\t    args: Tuple[Any, ...]\n\t    kwargs: Dict[str, Any]\n\t    timeout: Optional[TimeoutType]\n\tclass PacketHandler(ABC):\n\t    reader: asyncio.StreamReader\n\t    writer: asyncio.StreamWriter\n\t    protocol: Protocol\n\t    executor: AbstractExecutor\n", "    def __init__(\n\t        self,\n\t        reader: asyncio.StreamReader,\n\t        writer: asyncio.StreamWriter,\n\t        executor: AbstractExecutor,\n\t        protocol: Protocol,\n\t    ):\n\t        self.reader = reader\n\t        self.writer = writer\n\t        self.protocol = protocol\n", "        self.executor = executor\n\t        self.__client_info = self.writer.get_extra_info(\"peername\")\n\t        self.__events: Queue[RPCEvent] = Queue(self.executor.max_workers)\n\t        self.__results: Dict[int, asyncio.Future] = {}\n\t        self.__method_map: Mapping[\n\t            PacketTypes, Callable[[RPCEvent], Coroutine[Any, Any, Any]],\n\t        ] = MappingProxyType({\n\t            PacketTypes.REQUEST: self.handle_request,\n\t            PacketTypes.RESPONSE: self.handle_response,\n\t            PacketTypes.ERROR: self.handle_error,\n", "            PacketTypes.DISCOVER_REQUEST: self.handle_discover_request,\n\t        })\n\t    @cached_property\n\t    def loop(self) -> asyncio.AbstractEventLoop:\n\t        return asyncio.get_running_loop()\n\t    async def get_event(self) -> RPCEvent:\n\t        header = Header.unpack(await self.reader.readexactly(Header.SIZE))\n\t        payload = await self.reader.readexactly(header.size)\n\t        return RPCEvent(header=header, payload=payload)\n\t    async def handle_request(self, event: RPCEvent) -> None:\n", "        try:\n\t            request: CallRequest = self.protocol.serializer.unpack(\n\t                event.payload,\n\t            )\n\t            result = await asyncio.wait_for(\n\t                self.executor.execute(\n\t                    request.func, *request.args, **request.kwargs\n\t                ),\n\t                timeout=request.timeout,\n\t            )\n", "            self.writer.write(\n\t                self.protocol.pack(\n\t                    result, PacketTypes.RESPONSE, serial=event.header.serial,\n\t                ),\n\t            )\n\t        except Exception as e:\n\t            self.writer.write(\n\t                self.protocol.pack(\n\t                    e, PacketTypes.ERROR, serial=event.header.serial,\n\t                ),\n", "            )\n\t    async def handle_response(self, event: RPCEvent) -> None:\n\t        future = self.__results.pop(event.header.serial)\n\t        if future.done():\n\t            return\n\t        try:\n\t            payload = self.protocol.serializer.unpack(event.payload)\n\t        except (ValueError, pickle.UnpicklingError) as e:\n\t            future.set_exception(e)\n\t            return\n", "        future.set_result(payload)\n\t    async def handle_error(self, event: RPCEvent) -> None:\n\t        future = self.__results.pop(event.header.serial)\n\t        if future.done():\n\t            return\n\t        try:\n\t            payload = self.protocol.serializer.unpack(event.payload)\n\t        except (ValueError, pickle.UnpicklingError) as e:\n\t            future.set_exception(e)\n\t            return\n", "        future.set_exception(payload)\n\t    async def handle_discover_request(self, event: RPCEvent) -> None:\n\t        self.writer.write(\n\t            self.protocol.pack(\n\t                list(self.executor.registry),\n\t                PacketTypes.DISCOVER_RESPONSE,\n\t                serial=event.header.serial,\n\t            ),\n\t        )\n\t    async def step(self) -> None:\n", "        event = await self.get_event()\n\t        method = self.__method_map[event.header.type]\n\t        await method(event)\n\t    async def make_request(self, request: CallRequest) -> Any:\n\t        serial = self.protocol.get_serial()\n\t        future = self.loop.create_future()\n\t        self.__results[serial] = future\n\t        self.writer.write(\n\t            self.protocol.pack(request, PacketTypes.REQUEST, serial=serial),\n\t        )\n", "        return await future\n\t    async def discover(self) -> List[str]:\n\t        self.writer.write(\n\t            self.protocol.pack(None, PacketTypes.DISCOVER_REQUEST),\n\t        )\n\t        while True:\n\t            event: RPCEvent = await self.get_event()\n\t            if event.header.type == PacketTypes.DISCOVER_REQUEST:\n\t                await self.handle_discover_request(event)\n\t                continue\n", "            return self.protocol.serializer.unpack(event.payload)\n\t    @abstractmethod\n\t    async def authorize(self) -> bool:\n\t        raise NotImplementedError\n\t    async def close(self) -> None:\n\t        if not self.writer.can_write_eof():\n\t            return\n\t        self.writer.close()\n\t        await self.writer.wait_closed()\n\t    async def process_events(self) -> None:\n", "        while True:\n\t            event = await self.__events.get()\n\t            method = self.__method_map[event.header.type]\n\t            await method(event)\n\t            self.__events.task_done()\n\t    async def start_processing(self) -> None:\n\t        workers = []\n\t        for _ in range(self.executor.max_workers):\n\t            workers.append(self.loop.create_task(self.process_events()))\n\t        try:\n", "            while True:\n\t                try:\n\t                    await self.__events.put(await self.get_event())\n\t                except (ConnectionError, asyncio.IncompleteReadError):\n\t                    address, port = self.__client_info[:2]\n\t                    if \":\" in address:\n\t                        address = f\"[{address}]\"\n\t                    log.info(\n\t                        \"Client connection tcp://%s:%d had been closed\",\n\t                        address, port,\n", "                    )\n\t                    return\n\t        finally:\n\t            del self.__events\n\t            cancelling = []\n\t            for worker in workers:\n\t                if worker.done():\n\t                    continue\n\t                worker.cancel()\n\t                cancelling.append(worker)\n", "            if cancelling:\n\t                await asyncio.gather(*cancelling, return_exceptions=True)\n\tclass ServerPacketHandler(PacketHandler):\n\t    async def authorize(self) -> bool:\n\t        token = uuid.uuid4().bytes\n\t        self.writer.write(self.protocol.pack(token, PacketTypes.AUTH_DIGEST))\n\t        event = await self.get_event()\n\t        if event.header.type != PacketTypes.AUTH_REQUEST:\n\t            return False\n\t        if not self.protocol.authorize_check(event.payload):\n", "            return False\n\t        self.writer.write(self.protocol.pack(None, PacketTypes.AUTH_OK))\n\t        return True\n\tclass ClientPacketHandler(PacketHandler):\n\t    async def authorize(self) -> bool:\n\t        event = await self.get_event()\n\t        if event.header.type != PacketTypes.AUTH_DIGEST:\n\t            return False\n\t        token = event.payload\n\t        self.writer.write(self.protocol.authorize_request(token))\n", "        event = await self.get_event()\n\t        return event.header.type == PacketTypes.AUTH_OK\n\tclass TCPBrokerBase(AbstractBroker, ABC):\n\t    protocol: Protocol\n\t    registry: Registry\n\t    def __init__(\n\t        self,\n\t        executor: AbstractExecutor,\n\t        key: bytes = b\"\", *,\n\t        ssl_context: Optional[ssl.SSLContext] = None,\n", "        reconnect_timeout: TimeoutType = 1,\n\t        serializer: AbstractSerializer = RestrictedPickleSerializer()\n\t    ):\n\t        self.protocol = Protocol(key=key, serializer=serializer)\n\t        self.reconnect_timeout = reconnect_timeout\n\t        self._ssl_context: Optional[ssl.SSLContext] = ssl_context\n\t        self.__handlers: DefaultDict[str, Deque[PacketHandler]] = (\n\t            defaultdict(deque)\n\t        )\n\t        self.__rotate_lock = asyncio.Lock()\n", "        super().__init__(executor=executor)\n\t    async def _get_handler(self, method: str) -> PacketHandler:\n\t        handler: PacketHandler\n\t        async with self.__rotate_lock:\n\t            while method not in self.__handlers:\n\t                log.warning(\n\t                    \"No active connections, retrying after %.3f seconds.\",\n\t                    self.reconnect_timeout,\n\t                )\n\t                await asyncio.sleep(self.reconnect_timeout)\n", "            handler = self.__handlers[method].popleft()\n\t            self.__handlers[method].append(handler)\n\t        return handler\n\t    async def _add_handler(\n\t        self, handler: PacketHandler, methods: Iterable[str],\n\t    ) -> None:\n\t        for method in methods:\n\t            self.__handlers[method].append(handler)\n\t    async def _remove_handler(self, handler: PacketHandler) -> None:\n\t        async with self.__rotate_lock:\n", "            for handlers in self.__handlers.values():\n\t                handlers.remove(handler)\n\t    async def call(\n\t        self,\n\t        func: Union[str, TaskFunctionType],\n\t        *args: Any,\n\t        timeout: Optional[TimeoutType] = None,\n\t        **kwargs: Any,\n\t    ) -> Any:\n\t        if not isinstance(func, str):\n", "            raise TypeError(\"Only strings supports\")\n\t        request = CallRequest(\n\t            func=func, args=args, kwargs=kwargs, timeout=timeout,\n\t        )\n\t        async def go(name: str) -> Any:\n\t            handler = await self._get_handler(name)\n\t            return await handler.make_request(request)\n\t        return await asyncio.wait_for(go(func), timeout=timeout)\n\tDEFAULT_PORT = 15383\n\t@final\n", "class TCPServerBroker(TCPBrokerBase):\n\t    def __init__(\n\t        self,\n\t        executor: AbstractExecutor,\n\t        key: bytes = b\"\", *,\n\t        ssl_context: Optional[ssl.SSLContext] = None,\n\t        reconnect_timeout: TimeoutType = 1,\n\t        serializer: AbstractSerializer = RestrictedPickleSerializer()\n\t    ):\n\t        super().__init__(\n", "            executor=executor, key=key, ssl_context=ssl_context,\n\t            reconnect_timeout=reconnect_timeout, serializer=serializer,\n\t        )\n\t        self.servers: Set[asyncio.AbstractServer] = set()\n\t    async def _on_client_connected(\n\t        self, reader: asyncio.StreamReader, writer: asyncio.StreamWriter,\n\t    ) -> None:\n\t        handler = ServerPacketHandler(\n\t            reader=reader, writer=writer,\n\t            executor=self.executor, protocol=self.protocol,\n", "        )\n\t        async def handle() -> None:\n\t            if not await handler.authorize():\n\t                raise RuntimeError(\"Unauthorized\")\n\t            methods = await handler.discover()\n\t            await self._add_handler(handler, methods or ())\n\t            try:\n\t                await handler.start_processing()\n\t            finally:\n\t                await self._remove_handler(handler)\n", "        await self.create_task(handle())\n\t    async def listen(\n\t        self, address: str, port: int = DEFAULT_PORT, **kwargs: Any\n\t    ) -> None:\n\t        if \"ssl\" not in kwargs:\n\t            kwargs[\"ssl\"] = self._ssl_context\n\t        self.servers.add(\n\t            await asyncio.start_server(\n\t                self._on_client_connected,\n\t                host=address,\n", "                port=port,\n\t                **kwargs\n\t            ),\n\t        )\n\t    async def close(self) -> None:\n\t        tasks = [super().close()]\n\t        for server in self.servers:\n\t            server.close()\n\t            tasks.append(server.wait_closed())\n\t        await asyncio.gather(*tasks, return_exceptions=True)\n", "@final\n\tclass TCPClientBroker(TCPBrokerBase):\n\t    async def connection_fabric(\n\t        self, address: str, port: int,\n\t        on_connected: asyncio.Event,\n\t        **kwargs: Any\n\t    ) -> None:\n\t        if \"ssl\" not in kwargs:\n\t            kwargs[\"ssl\"] = self._ssl_context\n\t        while True:\n", "            try:\n\t                reader, writer = await asyncio.open_connection(\n\t                    host=address, port=port, **kwargs\n\t                )\n\t                try:\n\t                    handler = ClientPacketHandler(\n\t                        reader=reader, writer=writer,\n\t                        executor=self.executor, protocol=self.protocol,\n\t                    )\n\t                    if not await handler.authorize():\n", "                        raise RuntimeError(\"Unauthorized\")\n\t                    methods = await handler.discover()\n\t                    on_connected.set()\n\t                    await self._add_handler(handler, methods or ())\n\t                    await handler.start_processing()\n\t                except asyncio.CancelledError:\n\t                    if not writer.is_closing():\n\t                        writer.close()\n\t                        await writer.wait_closed()\n\t                    raise\n", "                if not writer.is_closing():\n\t                    writer.close()\n\t                    await writer.wait_closed()\n\t                on_connected.clear()\n\t                await self._remove_handler(handler)\n\t                log.error(\n\t                    \"Connection to tcp://%s:%d closed. \"\n\t                    \"Reconnecting after %.3f seconds...\",\n\t                    address, port, self.reconnect_timeout,\n\t                )\n", "            except (ConnectionError, asyncio.TimeoutError):\n\t                log.error(\n\t                    \"Failed to establish connection to tcp://%s:%d closed. \"\n\t                    \"Reconnecting after %.3f seconds.\",\n\t                    address, port, self.reconnect_timeout,\n\t                )\n\t            finally:\n\t                await asyncio.sleep(self.reconnect_timeout)\n\t            log.info(\n\t                \"Connection attempts to tcp://%s:%d has been stopped.\",\n", "                address, port,\n\t            )\n\t    async def connect(\n\t        self, address: str, port: int = DEFAULT_PORT, **kwargs: Any\n\t    ) -> None:\n\t        event = asyncio.Event()\n\t        self.create_task(\n\t            self.connection_fabric(address, port, event, **kwargs),\n\t        )\n\t        await event.wait()\n", "__all__ = (\"TCPBrokerBase\", \"TCPClientBroker\", \"TCPServerBroker\")\n"]}
{"filename": "patio/broker/tcp/__init__.py", "chunked_list": ["from .broker import TCPBrokerBase, TCPClientBroker, TCPServerBroker\n\t__all__ = (\n\t    \"TCPBrokerBase\",\n\t    \"TCPClientBroker\",\n\t    \"TCPServerBroker\",\n\t)\n"]}
{"filename": "examples/tcp/client-is-caller/client.py", "chunked_list": ["import asyncio\n\tfrom patio import Registry\n\tfrom patio.broker.tcp import TCPClientBroker\n\tfrom patio.executor import ThreadPoolExecutor\n\trpc = Registry(project=\"test\", strict=True)\n\tasync def main():\n\t    async with ThreadPoolExecutor(rpc) as executor:\n\t        async with TCPClientBroker(executor) as broker:\n\t            await broker.connect(address=\"127.0.0.1\")\n\t            await broker.connect(address=\"::1\")\n", "            print(\n\t                await asyncio.gather(\n\t                    *[\n\t                        broker.call(\"mul\", i, i) for i in range(10)\n\t                    ]\n\t                ),\n\t            )\n\tif __name__ == \"__main__\":\n\t    asyncio.run(main())\n"]}
{"filename": "examples/tcp/client-is-caller/server.py", "chunked_list": ["import asyncio\n\tfrom functools import reduce\n\tfrom patio import Registry\n\tfrom patio.broker.tcp import TCPServerBroker\n\tfrom patio.executor import ThreadPoolExecutor\n\trpc = Registry(project=\"test\", strict=True)\n\tdef mul(*args):\n\t    return reduce(lambda x, y: x * y, args)\n\tasync def main():\n\t    rpc.register(mul, \"mul\")\n", "    async with ThreadPoolExecutor(rpc) as executor:\n\t        async with TCPServerBroker(executor) as broker:\n\t            await broker.listen(address=\"127.0.0.1\")\n\t            await broker.listen(address=\"::1\")\n\t            await broker.join()\n\tif __name__ == \"__main__\":\n\t    asyncio.run(main())\n"]}
{"filename": "examples/tcp/server-is-caller/client.py", "chunked_list": ["import asyncio\n\tfrom functools import reduce\n\tfrom patio import Registry\n\tfrom patio.broker.tcp import TCPClientBroker\n\tfrom patio.executor import ThreadPoolExecutor\n\trpc = Registry(project=\"test\", strict=True)\n\tdef mul(*args):\n\t    return reduce(lambda x, y: x * y, args)\n\tasync def main():\n\t    rpc.register(mul, \"mul\")\n", "    async with ThreadPoolExecutor(rpc) as executor:\n\t        async with TCPClientBroker(executor) as broker:\n\t            await broker.connect(address=\"127.0.0.1\")\n\t            await broker.join()\n\tif __name__ == \"__main__\":\n\t    asyncio.run(main())\n"]}
{"filename": "examples/tcp/server-is-caller/server.py", "chunked_list": ["import asyncio\n\tfrom patio import Registry\n\tfrom patio.broker.tcp import TCPServerBroker\n\tfrom patio.executor import ThreadPoolExecutor\n\trpc = Registry(project=\"test\", strict=True)\n\tasync def main():\n\t    async with ThreadPoolExecutor(rpc) as executor:\n\t        async with TCPServerBroker(executor) as broker:\n\t            await broker.listen(address=\"127.0.0.1\")\n\t            while True:\n", "                print(\n\t                    await asyncio.gather(\n\t                        *[\n\t                            broker.call(\"mul\", i, i) for i in range(10)\n\t                        ], return_exceptions=True\n\t                    ),\n\t                )\n\t                await asyncio.sleep(1)\n\tif __name__ == \"__main__\":\n\t    asyncio.run(main())\n"]}
{"filename": "examples/memory/multiplication-decorator.py", "chunked_list": ["import asyncio\n\tfrom functools import reduce\n\tfrom patio import AsyncExecutor, MemoryBroker, Registry\n\trpc = Registry(project=\"test\", strict=True)\n\t@rpc\n\tasync def mul(*args):\n\t    loop = asyncio.get_running_loop()\n\t    return await loop.run_in_executor(None, reduce, lambda x, y: x * y, args)\n\tasync def main():\n\t    async with AsyncExecutor(max_workers=50) as executor:\n", "        async with MemoryBroker(executor) as broker:\n\t            await broker.setup(registry=rpc)\n\t            print(\n\t                await asyncio.gather(\n\t                    *[\n\t                        broker.call(mul, i, i) for i in range(10)\n\t                    ]\n\t                ),\n\t            )\n\tif __name__ == \"__main__\":\n", "    asyncio.run(main())\n"]}
{"filename": "examples/memory/multiplication.py", "chunked_list": ["import asyncio\n\tfrom functools import reduce\n\tfrom patio import MemoryBroker, Registry\n\tfrom patio.executor import ThreadPoolExecutor\n\trpc = Registry(project=\"test\", strict=True)\n\tdef mul(*args):\n\t    return reduce(lambda x, y: x * y, args)\n\tasync def main():\n\t    rpc.register(mul, \"mul\")\n\t    async with ThreadPoolExecutor(rpc) as executor:\n", "        async with MemoryBroker(executor) as broker:\n\t            print(\n\t                await asyncio.gather(\n\t                    *[\n\t                        broker.call(mul, i, i) for i in range(10)\n\t                    ]\n\t                ),\n\t            )\n\tif __name__ == \"__main__\":\n\t    asyncio.run(main())\n"]}
