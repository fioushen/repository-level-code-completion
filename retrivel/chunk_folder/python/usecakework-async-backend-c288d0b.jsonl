{"filename": "cli/newprojfiles/assets/bake.py", "chunked_list": ["from cakework import Client\n\timport time\n\tfrom pathlib import Path\n\tif __name__ == \"__main__\":\n\t    p = Path(__file__).with_name('.env')\n\t    with p.open('r') as f:\n\t        CAKEWORK_CLIENT_TOKEN = f.readline().strip('\\n')\n\t        client = Client(\"REPLACE_APPNAME\", CAKEWORK_CLIENT_TOKEN)\n\t        run_id = client.run(\"say_hello\", {\"name\":\"from Cakework\"}, compute={})\n\t        print(\"Your run id is \" + run_id)\n", "        status = client.get_run_status(run_id)\n\t        while status == \"PENDING\" or status == \"IN_PROGRESS\":\n\t            print(\"Still baking...!\")\n\t            time.sleep(1)\n\t            status = client.get_run_status(run_id)\n\t        if status == \"SUCCEEDED\":\n\t            result = client.get_run_result(run_id)\n\t            print(result)\n\t        else:\n\t            print(\"Task stopped  with status: \" + status)\n"]}
{"filename": "cli/newprojfiles/assets/main.py", "chunked_list": ["from cakework import Cakework\n\timport time\n\tdef say_hello(params):\n\t    time.sleep(5)\n\t    return \"Hello \" + params['name'] + \"!\"\n\tif __name__ == \"__main__\":\n\t    cakework = Cakework(\"REPLACE_APPNAME\")\n\t    cakework.add_task(say_hello)"]}
{"filename": "sdk/python/__init__.py", "chunked_list": []}
{"filename": "sdk/python/src/cakework/client.py", "chunked_list": ["from __future__ import print_function\n\t# import logging\n\timport json\n\timport sys\n\timport uuid\n\tfrom random import randrange # TODO remove this\n\timport requests\n\timport logging\n\tfrom cakework import exceptions\n\tfrom urllib3.exceptions import NewConnectionError\n", "import os\n\t# TODO: need to re-enable TLS for the handlers in the fly.toml file. Try these settings: https://community.fly.io/t/urgent-grpc-server-unreachable-via-grpcurl/2694/12 for alpn\n\t# TODO figure out how to configure the settings for fly.toml for grpc!\n\t# TODO also need to make sure different runs don't interfere with each other\n\t# TODO add a parameter for an entry point into the system (currently, assume that using cakework_app.py)\n\tlogging.basicConfig(level=logging.INFO)\n\tclass Client:\n\t    def __init__(self, project, client_token, local=False): # TODO: infer user id // TODO revert local back to False\n\t        self.project = project\n\t        self.client_token = client_token\n", "        if local:\n\t            self.frontend_url = \"http://localhost:8080\"\n\t        else:\n\t            self.frontend_url = \"https://cakework-frontend.fly.dev\"\n\t        self.local = local\n\t    def get_run_status(self, run_id):\n\t        response = None\n\t        try:\n\t            # Q: status 200 vs 201??? what's the diff?\n\t            # TODO strip app from everywhere\n", "            response = requests.get(f\"{self.frontend_url}/client/runs/{run_id}/status\", params={\"token\": self.client_token})                \n\t            response.raise_for_status()\n\t            # TODO: handle http error, or request id not found error\n\t        except requests.exceptions.HTTPError as err:\n\t            raise exceptions.CakeworkError(\"Http error while connecting to Cakework frontend\") from err\n\t        except requests.exceptions.Timeout as err:\n\t            raise exceptions.CakeworkError(\"Timed out connecting to Cakework frontend\") from err\n\t        except requests.exceptions.RequestException as err:\n\t            raise exceptions.CakeworkError(\"Request exception connecting Cakework frontend\") from err\n\t        except (ConnectionRefusedError, ConnectionResetError) as err:\n", "            raise exceptions.CakeworkError(\"Failed to connect to Cakework frontend service\") from err\n\t        except Exception as err:\n\t            # TODO catch and raise specific errors? \n\t            raise exceptions.CakeworkError(\"Error happened while getting status\") from err\n\t        if response is not None:\n\t            if response.status_code == 200:\n\t                status = response.text\n\t                return json.loads(status)\n\t            elif response.status_code == 404:\n\t                return None\n", "            else:\n\t                raise exceptions.CakeworkError(\"Internal server exception\")\n\t        else:\n\t            raise exceptions.CakeworkError(\"Internal server exception\") \n\t    # TODO figure out how to refactor get_result and get_status  \n\t    def get_run_result(self, run_id):\n\t        response = None\n\t        try:\n\t            # Q: status 200 vs 201??? what's the diff?\n\t            response = requests.get(f\"{self.frontend_url}/client/runs/{run_id}/result\", params={\"token\": self.client_token})                \n", "            response.raise_for_status() # TODO delete this?\n\t            # TODO: handle http error, or request id not found error\n\t        except requests.exceptions.HTTPError as errh:\n\t            raise exceptions.CakeworkError(\"Http error while connecting to Cakework frontend\")\n\t        except requests.exceptions.Timeout as errt:\n\t            raise exceptions.CakeworkError(\"Timed out connecting to Cakework frontend\")\n\t        except requests.exceptions.RequestException as err:\n\t            raise exceptions.CakeworkError(\"Request exception connecting Cakework frontend\")\n\t        except (ConnectionRefusedError, ConnectionResetError) as e:\n\t            raise exceptions.CakeworkError(\"Failed to connect to Cakework frontend service\")\n", "        except Exception as e:\n\t            # TODO catch and raise specific errors? \n\t            raise exceptions.CakeworkError(\"Something unexpected happened\")\n\t        if response is not None:\n\t            if response.status_code == 200:\n\t                result = json.loads(response.json())\n\t                return result\n\t            elif response.status_code == 404:\n\t                return None\n\t            else:\n", "                raise exceptions.CakeworkError(\"Internal server exception\")\n\t        else:\n\t            raise exceptions.CakeworkError(\"Internal server exception\") \n\t    def run(self, task, params, compute ={\"cpu\":1, \"memory\": 256}):\n\t        request = {\n\t            \"parameters\": params,\n\t            \"compute\": {}\n\t        }\n\t        cpu = compute.get(\"cpu\")\n\t        if cpu is not None:\n", "            if cpu < 1 or cpu > 8:\n\t                raise exceptions.CakeworkError(\"Number of cpus must be between 1 and 8\")\n\t            else:\n\t                request[\"compute\"][\"cpu\"] = cpu\n\t        else:\n\t            request[\"compute\"]['cpu'] = 1\n\t        memory = compute.get(\"memory\")\n\t        if memory is not None:\n\t            if memory < 256 or memory > 16384:\n\t                raise exceptions.CakeworkError(\"Amount of memory must be between 256 and 16384 mb\")\n", "            else:\n\t                request[\"compute\"][\"memory\"] = memory\n\t        else:\n\t            request[\"compute\"]['memory'] = 256\n\t        request[\"token\"] = self.client_token\n\t        response = requests.post(f\"{self.frontend_url}/client/projects/{self.project}/tasks/{task}/runs\", json=request, params={\"token\": self.client_token})\n\t        response_json = response.json()\n\t        if response is None:\n\t            raise exceptions.CakeworkError(\"Did not get a response from the frontend\")  \n\t        if response.status_code == 201:\n", "            run_id = response_json[\"runId\"]\n\t            return run_id\n\t        elif response.status_code == 404:\n\t            raise exceptions.CakeworkError(\"Task \" + task + \" for project \" + self.project + \" not found. Have you tried running `cakework deploy` first?\")  \n\t        else:\n\t            print(response) # TODO delete? \n\t            raise exceptions.CakeworkError(\"Internal server exception\")  "]}
{"filename": "sdk/python/src/cakework/__init__.py", "chunked_list": ["from .cakework import Cakework\n\tfrom .client import Client\n\tfrom .exceptions import CakeworkError"]}
{"filename": "sdk/python/src/cakework/cakework_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: cakework.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x0e\\x63\\x61kework.proto\\x12\\x08\\x63\\x61kework\\\"M\\n\\x07Request\\x12\\x12\\n\\nparameters\\x18\\x01 \\x01(\\t\\x12\\x0e\\n\\x06userId\\x18\\x02 \\x01(\\t\\x12\\x0f\\n\\x07project\\x18\\x03 \\x01(\\t\\x12\\r\\n\\x05runId\\x18\\x04 \\x01(\\t\\\"\\x17\\n\\x05Reply\\x12\\x0e\\n\\x06result\\x18\\x01 \\x01(\\t27\\n\\x08\\x43\\x61kework\\x12+\\n\\x03Run\\x12\\x11.cakework.Request\\x1a\\x0f.cakework.Reply\\\"\\x00\\x62\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'cakework_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  _REQUEST._serialized_start=28\n\t  _REQUEST._serialized_end=105\n\t  _REPLY._serialized_start=107\n\t  _REPLY._serialized_end=130\n\t  _CAKEWORK._serialized_start=132\n", "  _CAKEWORK._serialized_end=187\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "sdk/python/src/cakework/cakework_pb2_grpc.py", "chunked_list": ["# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!\n\t\"\"\"Client and server classes corresponding to protobuf-defined services.\"\"\"\n\timport grpc\n\t# import cakework_pb2 as cakework__pb2\n\t# TODO programatically fix this\n\tfrom cakework import cakework_pb2 as cakework__pb2\n\tclass CakeworkStub(object):\n\t    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\t    def __init__(self, channel):\n\t        \"\"\"Constructor.\n", "        Args:\n\t            channel: A grpc.Channel.\n\t        \"\"\"\n\t        self.Run = channel.unary_unary(\n\t                '/cakework.Cakework/Run',\n\t                request_serializer=cakework__pb2.Request.SerializeToString,\n\t                response_deserializer=cakework__pb2.Reply.FromString,\n\t                )\n\tclass CakeworkServicer(object):\n\t    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n", "    def Run(self, request, context):\n\t        \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\t        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n\t        context.set_details('Method not implemented!')\n\t        raise NotImplementedError('Method not implemented!')\n\tdef add_CakeworkServicer_to_server(servicer, server):\n\t    rpc_method_handlers = {\n\t            'Run': grpc.unary_unary_rpc_method_handler(\n\t                    servicer.Run,\n\t                    request_deserializer=cakework__pb2.Request.FromString,\n", "                    response_serializer=cakework__pb2.Reply.SerializeToString,\n\t            ),\n\t    }\n\t    generic_handler = grpc.method_handlers_generic_handler(\n\t            'cakework.Cakework', rpc_method_handlers)\n\t    server.add_generic_rpc_handlers((generic_handler,))\n\t # This class is part of an EXPERIMENTAL API.\n\tclass Cakework(object):\n\t    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\t    @staticmethod\n", "    def Run(request,\n\t            target,\n\t            options=(),\n\t            channel_credentials=None,\n\t            call_credentials=None,\n\t            insecure=False,\n\t            compression=None,\n\t            wait_for_ready=None,\n\t            timeout=None,\n\t            metadata=None):\n", "        return grpc.experimental.unary_unary(request, target, '/cakework.Cakework/Run',\n\t            cakework__pb2.Request.SerializeToString,\n\t            cakework__pb2.Reply.FromString,\n\t            options, channel_credentials,\n\t            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n"]}
{"filename": "sdk/python/src/cakework/task_server.py", "chunked_list": ["from concurrent import futures\n\timport logging\n\timport grpc\n\tfrom cakework import cakework_pb2\n\tfrom cakework import cakework_pb2_grpc\n\timport json\n\timport threading\n\timport requests\n\timport os\n\timport logging\n", "logging.basicConfig(level=logging.INFO)\n\tdef get_token(context):\n\t    metadict = dict(context.invocation_metadata())\n\t    authorization = metadict['authorization']\n\t    split = authorization.split(' ')\n\t    return split[1]\n\tclass Cakework(cakework_pb2_grpc.CakeworkServicer):\n\t    def __init__(self, user_task, local=False):\n\t        self.user_task = user_task\n\t        self.local = local\n", "        if self.local:\n\t            self.frontend_url = \"http://localhost:8080\"\n\t        else:\n\t            self.frontend_url = \"https://cakework-frontend.fly.dev\"\n\t    def Run(self, request, context):\n\t        token = get_token(context)\n\t        headers = {'content-type': 'application/json', 'authorization': 'Bearer ' + token, 'project': request.project}\n\t        response = requests.post(f\"{self.frontend_url}/runs/{request.runId}/status\", json={\"runId\": request.runId, \"status\": \"IN_PROGRESS\"}, headers=headers)\n\t        # TODO check the response\n\t        parameters = json.loads(request.parameters)\n", "        # parameters = json.loads(request.parameters) # instead of passing a dict (parameters), pass a variable number of parameters \n\t        task = threading.Thread(target=self.background, args=[request.userId, request.project, request.runId, parameters, token])\n\t        task.daemon = True # Q: does returning kill the task?\n\t        task.start()\n\t        # what should we return? now, the client is no longer hitting the grpc server\n\t        return cakework_pb2.Reply(result=json.dumps(\"worker started task\")) # TODO this should return the request id\n\t    # note: we need to get the request id in here as well\n\t    def background(self, user_id, project, run_id, parameters, token):\n\t        res = \"\"\n\t        # logging.info(\"starting background task with parameters: \" + str(parameters))\n", "        headers = {'content-type': 'application/json', 'authorization': 'Bearer ' + token, 'project': project}\n\t        try:\n\t            logging.info(\"Starting run with id:\" + run_id)\n\t            res = self.user_task(parameters)\n\t            # TODO call the frontend api to update the status and result\n\t            logging.info(\"Finished request \" + run_id)\n\t            response = requests.post(f\"{self.frontend_url}/runs/{run_id}/result\", json={\"runId\": run_id, \"result\": json.dumps(res)}, headers=headers)\n\t            if response.status_code != 200:\n\t                logging.error(\"Failed to update run status\")\n\t                response.raise_for_status()\n", "            logging.info(\"Got successful response to update status\")\n\t            # TODO check the response\n\t            response = requests.post(f\"{self.frontend_url}/runs/{run_id}/status\", json={\"runId\": run_id, \"status\": \"SUCCEEDED\"}, headers=headers)\n\t            if response.status_code != 200:\n\t                logging.error(\"Failed to update run status\")\n\t                response.raise_for_status()\n\t            logging.info(\"Got successful response to update result\")\n\t        except Exception as e:\n\t            logging.exception(\"Error occurred while running task\", exc_info=True)\n\t            # logging.info(e)\n", "            response = requests.post(f\"{self.frontend_url}/runs/{run_id}/status\", json={\"runId\": run_id, \"status\": \"FAILED\"}, headers=headers)\n\t            # TODO: handle case if updating the status in the db failed; then user may keep polling forever\n\t            return cakework_pb2.Reply(result=None)\n\t        finally:\n\t            logging.info(\"Request complete, exiting\")\n\t            os._exit(1)\n\t        # Q: who are we returning to here? instead of returning, we can just write this to the database. or emit a message and have the poller be in charge of writing to db\n\t        return cakework_pb2.Reply(result=json.dumps(res))\n\tdef serve():\n\t    port = '50051'\n", "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=1)) # what should the default be?\n\t    cakework_pb2_grpc.add_CakeworkServicer_to_server(Cakework(), server)\n\t    server.add_insecure_port('[::]:' + port)\n\t    server.start()\n\t    logging.info(\"Server started, listening on \" + port)\n\t    server.wait_for_termination()\n\tif __name__ == '__main__':\n\t    logging.basicConfig()\n\t    serve()\n\tclass TaskServer:\n", "    def __init__(self, user_task, local=False):\n\t        self.user_task = user_task\n\t        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=1)) # what should the default be?\n\t        self.local = local\n\t    def start(self):        \n\t        port = '50051'\n\t        cakework_pb2_grpc.add_CakeworkServicer_to_server(Cakework(self.user_task, self.local), self.server)\n\t        self.server.add_insecure_port('[::]:' + port)\n\t        self.server.start()\n\t        logging.info(\"Server started, listening on \" + port)\n", "        self.server.wait_for_termination()"]}
{"filename": "sdk/python/src/cakework/cakework.py", "chunked_list": ["import subprocess\n\timport os\n\timport shutil\n\timport sys\n\timport inspect\n\timport json\n\tfrom concurrent import futures\n\tfrom cakework import cakework_pb2\n\tfrom cakework import cakework_pb2_grpc\n\tfrom .task_server import TaskServer\n", "import importlib\n\timport logging\n\tlogging.basicConfig(level=logging.INFO)\n\tclass Cakework:\n\t\tdef __init__(self, name, local=False): # TODO remove local when release as open source\n\t\t\tself.name = name\n\t\t\tself.local = local\n\t\t\tlogging.info(\"Created project with name: \" + self.name)\n\t\tdef add_task(self, task):\n\t\t\tactivity_server = TaskServer(task, self.local)\n", "\t\tactivity_server.start()\n\tdef serve():\n\t    port = '50051'\n\t    server = grpc.server(futures.ThreadPoolExecutor(max_workers=1)) # what should the default be?\n\t    cakework_pb2_grpc.add_CakeworkServicer_to_server(cakework_pb2_grpc.Cakework(), server)\n\t    server.add_insecure_port('[::]:' + port)\n\t    server.start()\n\t    logging.info(\"Server started, listening on \" + port)\n\t    server.wait_for_termination()"]}
{"filename": "sdk/python/src/cakework/frontend_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\t# Generated by the protocol buffer compiler.  DO NOT EDIT!\n\t# source: proto/frontend.proto\n\t\"\"\"Generated protocol buffer code.\"\"\"\n\tfrom google.protobuf.internal import builder as _builder\n\tfrom google.protobuf import descriptor as _descriptor\n\tfrom google.protobuf import descriptor_pool as _descriptor_pool\n\tfrom google.protobuf import symbol_database as _symbol_database\n\t# @@protoc_insertion_point(imports)\n\t_sym_db = _symbol_database.Default()\n", "DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x14proto/frontend.proto\\x12\\x08\\x66rontend\\\"P\\n\\x0f\\x43\\x61llTaskRequest\\x12\\x0e\\n\\x06userId\\x18\\x01 \\x01(\\t\\x12\\x0b\\n\\x03\\x61pp\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04task\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nparameters\\x18\\x04 \\x01(\\t\\\"1\\n\\rCallTaskReply\\x12\\x11\\n\\trequestId\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05\\x65rror\\x18\\x02 \\x01(\\t2L\\n\\x08\\x46rontend\\x12@\\n\\x08\\x43\\x61llTask\\x12\\x19.frontend.CallTaskRequest\\x1a\\x17.frontend.CallTaskReply\\\"\\x00\\x42\\x0cZ\\n.;frontendb\\x06proto3')\n\t_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n\t_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'proto.frontend_pb2', globals())\n\tif _descriptor._USE_C_DESCRIPTORS == False:\n\t  DESCRIPTOR._options = None\n\t  DESCRIPTOR._serialized_options = b'Z\\n.;frontend'\n\t  _CALLTASKREQUEST._serialized_start=34\n\t  _CALLTASKREQUEST._serialized_end=114\n\t  _CALLTASKREPLY._serialized_start=116\n\t  _CALLTASKREPLY._serialized_end=165\n", "  _FRONTEND._serialized_start=167\n\t  _FRONTEND._serialized_end=243\n\t# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "sdk/python/src/cakework/exceptions.py", "chunked_list": ["__all__ = (\n\t    # TODO add more specific errors and warnings\n\t    # Core errors\n\t    'CakeworkError'\n\t)\n\tclass CakeworkError(Exception):\n\t    \"\"\"Base class for all Cakework errors.\"\"\"\n"]}
{"filename": "sdk/python/src/cakework/frontend_pb2_grpc.py", "chunked_list": ["# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!\n\t\"\"\"Client and server classes corresponding to protobuf-defined services.\"\"\"\n\timport grpc\n\tfrom cakework import frontend_pb2 as proto_dot_frontend__pb2\n\tclass FrontendStub(object):\n\t    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\t    def __init__(self, channel):\n\t        \"\"\"Constructor.\n\t        Args:\n\t            channel: A grpc.Channel.\n", "        \"\"\"\n\t        self.CallTask = channel.unary_unary(\n\t                '/frontend.Frontend/CallTask',\n\t                request_serializer=proto_dot_frontend__pb2.CallTaskRequest.SerializeToString,\n\t                response_deserializer=proto_dot_frontend__pb2.CallTaskReply.FromString,\n\t                )\n\tclass FrontendServicer(object):\n\t    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\t    def CallTask(self, request, context):\n\t        \"\"\"Sends a greeting\n", "        \"\"\"\n\t        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n\t        context.set_details('Method not implemented!')\n\t        raise NotImplementedError('Method not implemented!')\n\tdef add_FrontendServicer_to_server(servicer, server):\n\t    rpc_method_handlers = {\n\t            'CallTask': grpc.unary_unary_rpc_method_handler(\n\t                    servicer.CallTask,\n\t                    request_deserializer=proto_dot_frontend__pb2.CallTaskRequest.FromString,\n\t                    response_serializer=proto_dot_frontend__pb2.CallTaskReply.SerializeToString,\n", "            ),\n\t    }\n\t    generic_handler = grpc.method_handlers_generic_handler(\n\t            'frontend.Frontend', rpc_method_handlers)\n\t    server.add_generic_rpc_handlers((generic_handler,))\n\t # This class is part of an EXPERIMENTAL API.\n\tclass Frontend(object):\n\t    \"\"\"Missing associated documentation comment in .proto file.\"\"\"\n\t    @staticmethod\n\t    def CallTask(request,\n", "            target,\n\t            options=(),\n\t            channel_credentials=None,\n\t            call_credentials=None,\n\t            insecure=False,\n\t            compression=None,\n\t            wait_for_ready=None,\n\t            timeout=None,\n\t            metadata=None):\n\t        return grpc.experimental.unary_unary(request, target, '/frontend.Frontend/CallTask',\n", "            proto_dot_frontend__pb2.CallTaskRequest.SerializeToString,\n\t            proto_dot_frontend__pb2.CallTaskReply.FromString,\n\t            options, channel_credentials,\n\t            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n"]}
{"filename": "examples/react-example/react-example-backend/react_example_backend/main.py", "chunked_list": ["from cakework import Cakework\n\timport time\n\tdef say_hello(params):\n\t    time.sleep(5)\n\t    return \"Hello \" + params['name'] + \"!\"\n\tif __name__ == \"__main__\":\n\t    cakework = Cakework(\"react-example-backend\")\n\t    cakework.add_task(say_hello)"]}
{"filename": "examples/react-example/react-example-backend/react_example_backend/__init__.py", "chunked_list": []}
{"filename": "examples/react-example/react-example-backend/tests/bake.py", "chunked_list": ["from cakework import Client\n\timport time\n\tfrom pathlib import Path\n\tif __name__ == \"__main__\":\n\t    p = Path(__file__).with_name('.env')\n\t    with p.open('r') as f:\n\t        CAKEWORK_CLIENT_TOKEN = f.readline().strip('\\n')\n\t        client = Client(\"REPLACE_APPNAME\", CAKEWORK_CLIENT_TOKEN, local=False)\n\t        run_id = client.run(\"say_hello\", {\"name\":\"from Cakework\"}, compute={})\n\t        print(\"Your run id is \" + run_id)\n", "        status = client.get_run_status(run_id)\n\t        while status == \"PENDING\" or status == \"IN_PROGRESS\":\n\t            print(\"Still baking...!\")\n\t            time.sleep(1)\n\t            status = client.get_run_status(run_id)\n\t        if status == \"SUCCEEDED\":\n\t            result = client.get_run_result(run_id)\n\t            print(result)\n\t        else:\n\t            print(\"Task stopped  with status: \" + status)\n"]}
{"filename": "examples/react-example/react-example-backend/tests/__init__.py", "chunked_list": []}
{"filename": "examples/image_generation/backend/backend/main.py", "chunked_list": ["from cakework import Cakework\n\timport banana_dev as banana\n\timport base64\n\tfrom io import BytesIO\n\tfrom PIL import Image\n\timport boto3\n\tfrom nanoid import generate\n\tAWS_ACCESS_KEY_ID = \"YOUR_ACCESS_KEY_ID\"\n\tAWS_SECRET_ACCESS_KEY = \"YOUR_SECRET_KEY\"\n\tAWS_BUCKET = \"YOUR_AWS_BUCKET\"\n", "BANANA_API_KEY = \"YOUR_API_KEY\"\n\tBANANA_MODEL_KEY = \"YOUR_MODEL_KEY\"\n\t# Run image generation model, returning the image as bytes.\n\t# We are running stable diffusion hosted on banana.\n\tdef run_image_generation_model(prompt):\n\t    model_inputs = {\n\t        \"prompt\": prompt,\n\t        \"num_inference_steps\": 50,\n\t        \"guidance_scale\": 9,\n\t        \"height\": 512,\n", "        \"width\": 512,\n\t        \"seed\": 3242\n\t    }\n\t    output = banana.run(BANANA_API_KEY, BANANA_MODEL_KEY, model_inputs)\n\t    image_byte_string = output[\"modelOutputs\"][0][\"image_base64\"]\n\t    image_encoded = image_byte_string.encode('utf-8')\n\t    image_bytes = BytesIO(base64.b64decode(image_encoded))\n\t    return Image.open(image_bytes)\n\t# Converts the image to a .jpg and uploads it to S3\n\tdef upload_image(image):\n", "    s3 = boto3.client(\n\t    's3',\n\t    aws_access_key_id=AWS_ACCESS_KEY_ID,\n\t    aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n\t    id = generate(size=10)\n\t    filename = id + \".png\"\n\t    file = BytesIO()\n\t    image.save(file, \"png\")\n\t    file.seek(0)\n\t    s3.upload_fileobj(file, AWS_BUCKET, filename)\n", "    return filename\n\t# Generates a stable diffusion prompt from input\n\tdef generate_prompt(object, style):\n\t    return object + \" in \" + style + \" style \"\n\t# Run the image generation process and save to S3\n\tdef generate_image(object, style):\n\t    prompt = generate_prompt(object, style)\n\t    image = run_image_generation_model(prompt)\n\t    s3_location = upload_image(image)\n\t    return {\n", "        \"s3Location\": s3_location\n\t    }\n\tif __name__ == \"__main__\":\n\t    app = Cakework(\"backend\")\n\t    app.add_task(generate_image)"]}
{"filename": "examples/image_generation/backend/backend/__init__.py", "chunked_list": []}
{"filename": "examples/image_generation/backend/tests/bake.py", "chunked_list": ["from cakework import Client\n\timport time\n\tfrom pathlib import Path\n\tif __name__ == \"__main__\":\n\t    p = Path(__file__).with_name('.env')\n\t    with p.open('r') as f:\n\t        CAKEWORK_CLIENT_TOKEN = f.readline().strip('\\n')\n\t        client = Client(\"backend\", CAKEWORK_CLIENT_TOKEN)\n\t        # You can persist this run ID to get status of the job later\n\t        run_id = client.say_hello(\"from Cakework\")\n", "        print(\"Your run id is \" + run_id)\n\t        status = client.get_status(run_id)\n\t        while (status == \"PENDING\" or status == \"IN_PROGRESS\"):\n\t            print(\"Still baking...!\")\n\t            status = client.get_status(run_id)\n\t            time.sleep(1)\n\t        if (client.get_status(run_id) == \"SUCCEEDED\"):\n\t            result = client.get_result(run_id)\n\t            print(result)"]}
{"filename": "examples/image_generation/backend/tests/__init__.py", "chunked_list": []}
{"filename": "examples/image_generation/client/tests/__init__.py", "chunked_list": []}
{"filename": "examples/image_generation/client/client/main.py", "chunked_list": ["from cakework import Client\n\timport time\n\timport json\n\tS3_BUCKET_URL = \"YOUR_S3_BUCKET_URL\"\n\tCAKEWORK_CLIENT_TOKEN = \"YOUR_CAKEWORK_CLIENT_TOKEN\"\n\tif __name__ == \"__main__\":\n\t    client = Client(\"image_generation\", CAKEWORK_CLIENT_TOKEN)\n\t    # You can persist this run ID to get status of the job later\n\t    run_id = client.generate_image(\"cute piece of cake\", \"cartoon\")\n\t    print(run_id)\n", "    status = client.get_status(run_id)\n\t    while (status == \"PENDING\" or status == \"IN_PROGRESS\"):\n\t        print(\"Still baking that cake!\")\n\t        status = client.get_status(run_id)\n\t        time.sleep(1)\n\t    if (client.get_status(run_id) == \"SUCCEEDED\"):\n\t        result = json.loads(client.get_result(run_id))\n\t        url = S3_BUCKET_URL + result[\"s3Location\"]\n\t        print(url)\n"]}
{"filename": "examples/image_generation/client/client/__init__.py", "chunked_list": []}
