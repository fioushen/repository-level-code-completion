{"filename": "tests/test_prompts.py", "chunked_list": ["from doccano_mini.prompts import make_classification_prompt, make_task_free_prompt\n\tdef test_make_classification_prompt():\n\t    examples = [\n\t        {\"text\": \"That would be awesome!\", \"label\": \"positive\"},\n\t        {\"text\": \"This is awful!\", \"label\": \"negative\"},\n\t    ]\n\t    expected = \"\"\"\\\n\tClassify the text into one of the following labels:\n\t- negative\n\t- positive\n", "text: That would be awesome!\n\tlabel: positive\n\ttext: This is awful!\n\tlabel: negative\n\ttext: It's very hot.\"\"\"\n\t    input_text = \"It's very hot.\"\n\t    prompt = make_classification_prompt(examples)\n\t    assert prompt.format(input=input_text) == expected\n\tdef test_make_task_free_prompt():\n\t    examples = [\n", "        {\"English\": \"I like sushi.\", \"Japanese\": \"寿司が好きです。\"},\n\t        {\"English\": \"I live in Japan.\", \"Japanese\": \"日本に住んでいます。\"},\n\t    ]\n\t    expected = \"\"\"\\\n\tPredict Japanese based on English.\n\tEnglish: I like sushi.\n\tJapanese: 寿司が好きです。\n\tEnglish: I live in Japan.\n\tJapanese: 日本に住んでいます。\n\tEnglish: I'm developing doccano-mini.\"\"\"\n", "    english_text = \"I'm developing doccano-mini.\"\n\t    prompt = make_task_free_prompt(examples)\n\t    assert prompt.format(English=english_text) == expected\n"]}
{"filename": "doccano_mini/components.py", "chunked_list": ["import os\n\tfrom pathlib import Path\n\tfrom typing import Optional\n\timport streamlit as st\n\tfrom langchain.llms import OpenAI\n\tfrom langchain.prompts.few_shot import FewShotPromptTemplate\n\tfrom langchain.schema import BaseLanguageModel\n\tdef display_download_button():\n\t    st.header(\"Download a config file\")\n\t    with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as f:\n", "        st.download_button(\n\t            label=\"Download\",\n\t            data=f,\n\t            file_name=\"config.yaml\",\n\t        )\n\tdef usage():\n\t    st.header(\"Usage\")\n\t    filepath = Path(__file__).parent.resolve() / \"docs\" / \"usage.md\"\n\t    with filepath.open(\"r\", encoding=\"utf-8\") as f:\n\t        st.markdown(f.read())\n", "def task_instruction_editor(prompt: FewShotPromptTemplate) -> FewShotPromptTemplate:\n\t    st.header(\"Edit instruction\")\n\t    with st.expander(\"See instruction\"):\n\t        prompt.prefix = st.text_area(label=\"Enter task instruction\", value=prompt.prefix, height=200)\n\t    return prompt\n\tdef openai_model_form() -> Optional[BaseLanguageModel]:\n\t    # https://platform.openai.com/docs/models/gpt-3-5\n\t    AVAILABLE_MODELS = (\n\t        \"gpt-3.5-turbo\",\n\t        \"gpt-3.5-turbo-0301\",\n", "        \"text-davinci-003\",\n\t        \"text-davinci-002\",\n\t        \"code-davinci-002\",\n\t    )\n\t    api_key = st.text_input(\"API key\", value=os.environ.get(\"OPENAI_API_KEY\", \"\"), type=\"password\")\n\t    model_name = st.selectbox(\"Model\", AVAILABLE_MODELS, index=2)\n\t    temperature = st.slider(\"Temperature\", min_value=0.0, max_value=1.0, value=0.7, step=0.01)\n\t    top_p = st.slider(\"Top-p\", min_value=0.0, max_value=1.0, value=1.0, step=0.01)\n\t    if not api_key:\n\t        return None\n", "    return OpenAI(model_name=model_name, temperature=temperature, top_p=top_p, openai_api_key=api_key)  # type:ignore\n"]}
{"filename": "doccano_mini/home.py", "chunked_list": ["from pathlib import Path\n\timport streamlit as st\n\tdef main():\n\t    st.set_page_config(page_title=\"doccano-mini\", page_icon=\":memo:\")\n\t    filepath = Path(__file__).parent.resolve() / \"docs\" / \"README.md\"\n\t    # Development\n\t    if not filepath.exists():\n\t        filepath = Path(__file__).parent.parent.resolve() / \"README.md\"\n\t    with filepath.open(\"r\", encoding=\"utf-8\") as f:\n\t        st.markdown(f.read(), unsafe_allow_html=True)\n", "if __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "doccano_mini/__init__.py", "chunked_list": []}
{"filename": "doccano_mini/utils.py", "chunked_list": ["import re\n\tdef escape_markdown(text: str) -> str:\n\t    # Brought from https://github.com/python-telegram-bot/python-telegram-bot/blob/v20.2/telegram/helpers.py#L66\n\t    escape_chars = r\"\\_*[]()~`>#+-=|{}.!$\"\n\t    return re.sub(f\"([{re.escape(escape_chars)}])\", r\"\\\\\\1\", text)\n"]}
{"filename": "doccano_mini/prompts.py", "chunked_list": ["import json\n\tfrom typing import List\n\tfrom langchain.prompts.few_shot import FewShotPromptTemplate\n\tfrom langchain.prompts.prompt import PromptTemplate\n\tdef make_classification_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n\t    unique_labels = set([example[\"label\"] for example in examples])\n\t    task_instruction = \"Classify the text into one of the following labels:\\n\"\n\t    # Sorting to make label order deterministic\n\t    for label in sorted(unique_labels):\n\t        task_instruction += f\"- {label}\\n\"\n", "    example_prompt = PromptTemplate(input_variables=[\"text\", \"label\"], template=\"text: {text}\\nlabel: {label}\")\n\t    prompt = FewShotPromptTemplate(\n\t        examples=examples,\n\t        example_prompt=example_prompt,\n\t        prefix=task_instruction,\n\t        suffix=\"text: {input}\",\n\t        input_variables=[\"input\"],\n\t    )\n\t    return prompt\n\tdef make_question_answering_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n", "    task_instruction = (\n\t        \"You are a highly intelligent question answering bot. \"\n\t        \"You take context and question as input and return the answer from the context. \"\n\t        \"Retain as much information as needed to answer the question at a later time. \"\n\t        \"If you don't know the answer, you should return N/A.\"\n\t    )\n\t    example_prompt = PromptTemplate(\n\t        input_variables=[\"context\", \"question\", \"answer\"],\n\t        template=\"context: {context}\\nquestion: {question}\\nanswer: {answer}\",\n\t    )\n", "    prompt = FewShotPromptTemplate(\n\t        examples=examples,\n\t        example_prompt=example_prompt,\n\t        prefix=task_instruction,\n\t        suffix=\"context: {context}\\nquestion: {question}\",\n\t        input_variables=[\"context\", \"question\"],\n\t    )\n\t    return prompt\n\tdef make_summarization_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n\t    task_instruction = (\n", "        \"You are a highly intelligent Summarization system. \"\n\t        \"You take Passage as input and summarize the passage as an expert.\"\n\t    )\n\t    example_prompt = PromptTemplate(\n\t        input_variables=[\"passage\", \"summary\"], template=\"passage: {passage}\\nsummary: {summary}\"\n\t    )\n\t    prompt = FewShotPromptTemplate(\n\t        examples=examples,\n\t        example_prompt=example_prompt,\n\t        prefix=task_instruction,\n", "        suffix=\"passage: {passage}\",\n\t        input_variables=[\"passage\"],\n\t    )\n\t    return prompt\n\tdef make_paraphrase_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n\t    task_instruction = (\n\t        \"You are a highly intelligent paraphrasing system. You take text as input and paraphrase it as an expert.\"\n\t    )\n\t    example_prompt = PromptTemplate(\n\t        input_variables=[\"text\", \"paraphrase\"], template=\"text: {text}\\nparaphrase: {paraphrase}\"\n", "    )\n\t    prompt = FewShotPromptTemplate(\n\t        examples=examples,\n\t        example_prompt=example_prompt,\n\t        prefix=task_instruction,\n\t        suffix=\"text: {text}\",\n\t        input_variables=[\"text\"],\n\t    )\n\t    return prompt\n\tdef make_task_free_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n", "    columns = list(examples[0])\n\t    task_instruction = f\"Predict {columns[-1]} based on {', '.join(columns[:-1])}.\"\n\t    example_prompt = PromptTemplate(\n\t        input_variables=columns, template=\"\\n\".join([f\"{column}: {{{column}}}\" for column in columns])\n\t    )\n\t    prompt = FewShotPromptTemplate(\n\t        examples=examples,\n\t        example_prompt=example_prompt,\n\t        prefix=task_instruction,\n\t        suffix=\"\\n\".join([f\"{column}: {{{column}}}\" for column in columns[:-1]]),\n", "        input_variables=columns[:-1],\n\t    )\n\t    return prompt\n\tdef make_named_entity_recognition_prompt(examples: List[dict], **kwargs) -> FewShotPromptTemplate:\n\t    task_instruction = (\n\t        \"You are a highly intelligent and accurate Named-entity recognition(NER) system. \"\n\t        \"You take Passage as input and your task is to recognize and extract specific types of \"\n\t        \"named entities in that given passage and classify into a set of entity types.\\n\"\n\t    )\n\t    types = kwargs.get(\"types\", [])\n", "    task_instruction += \"The following entity types are allowed:\\n\"\n\t    for type in types:\n\t        task_instruction += f\"- {type}\\n\"\n\t    for example in examples:\n\t        entities = [\n\t            {\"mention\": example[\"text\"][entity[\"start\"] : entity[\"end\"]], \"type\": entity[\"label\"]}\n\t            for entity in example[\"entities\"]\n\t        ]\n\t        example[\"entities\"] = json.dumps(entities)\n\t    example_prompt = PromptTemplate(\n", "        input_variables=[\"text\", \"entities\"],\n\t        template=\"text: {text}\\nentities: {entities}\",\n\t    )\n\t    prompt = FewShotPromptTemplate(\n\t        examples=examples,\n\t        example_prompt=example_prompt,\n\t        prefix=task_instruction,\n\t        suffix=\"text: {{text}}\",\n\t        input_variables=[\"text\"],\n\t        template_format=\"jinja2\",\n", "    )\n\t    return prompt\n"]}
{"filename": "doccano_mini/layout.py", "chunked_list": ["from abc import ABC, abstractmethod\n\tfrom pathlib import Path\n\tfrom typing import Dict, List\n\timport pandas as pd\n\timport streamlit as st\n\tfrom langchain.chains import LLMChain\n\tfrom langchain.prompts.few_shot import FewShotPromptTemplate\n\tfrom doccano_mini.components import (\n\t    display_download_button,\n\t    openai_model_form,\n", "    task_instruction_editor,\n\t    usage,\n\t)\n\tfrom doccano_mini.utils import escape_markdown\n\tclass BasePage(ABC):\n\t    example_path: str = \"\"\n\t    def __init__(self, title: str) -> None:\n\t        self.title = title\n\t    @property\n\t    def columns(self) -> List[str]:\n", "        return []\n\t    def load_examples(self, filename: str) -> pd.DataFrame:\n\t        filepath = Path(__file__).parent.resolve().joinpath(\"examples\", filename)\n\t        return pd.read_json(filepath)\n\t    def make_examples(self, columns: List[str]) -> List[Dict]:\n\t        df = self.load_examples(self.example_path)\n\t        edited_df = st.experimental_data_editor(df, num_rows=\"dynamic\", width=1000)\n\t        examples = edited_df.to_dict(orient=\"records\")\n\t        return examples\n\t    @abstractmethod\n", "    def make_prompt(self, examples: List[Dict]) -> FewShotPromptTemplate:\n\t        raise NotImplementedError()\n\t    @abstractmethod\n\t    def prepare_inputs(self, columns: List[str]) -> Dict:\n\t        raise NotImplementedError()\n\t    def annotate(self, examples: List[Dict]) -> List[Dict]:\n\t        return examples\n\t    def render(self) -> None:\n\t        st.title(self.title)\n\t        st.header(\"Annotate your data\")\n", "        columns = self.columns\n\t        examples = self.make_examples(columns)\n\t        examples = self.annotate(examples)\n\t        prompt = self.make_prompt(examples)\n\t        prompt = task_instruction_editor(prompt)\n\t        st.header(\"Test\")\n\t        col1, col2 = st.columns([3, 1])\n\t        with col1:\n\t            inputs = self.prepare_inputs(columns)\n\t        with col2:\n", "            llm = openai_model_form()\n\t        with st.expander(\"See your prompt\"):\n\t            st.markdown(f\"```\\n{prompt.format(**inputs)}\\n```\")\n\t        if llm is None:\n\t            st.error(\"Enter your API key.\")\n\t        if st.button(\"Predict\", disabled=llm is None):\n\t            chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n\t            response = chain.run(**inputs)\n\t            st.markdown(escape_markdown(response).replace(\"\\n\", \"  \\n\"))\n\t            chain.save(\"config.yaml\")\n", "            display_download_button()\n\t        usage()\n"]}
{"filename": "doccano_mini/cli.py", "chunked_list": ["import sys\n\tfrom pathlib import Path\n\timport streamlit.web.cli as stcli\n\tdef main():\n\t    filepath = str(Path(__file__).parent.resolve() / \"home.py\")\n\t    sys.argv = [\"streamlit\", \"run\", filepath, \"--global.developmentMode=false\"]\n\t    sys.exit(stcli.main())\n\tif __name__ == \"__main__\":\n\t    main()\n"]}
{"filename": "doccano_mini/pages/04_Paraphrase.py", "chunked_list": ["from typing import Dict, List\n\timport streamlit as st\n\tfrom doccano_mini.layout import BasePage\n\tfrom doccano_mini.prompts import make_paraphrase_prompt\n\tclass ParaphrasePage(BasePage):\n\t    example_path = \"paraphrase.json\"\n\t    def make_prompt(self, examples: List[Dict]):\n\t        return make_paraphrase_prompt(examples)\n\t    def prepare_inputs(self, columns: List[str]):\n\t        return {\n", "            \"text\": st.text_area(label=\"Text.\", value=\"\", height=300),\n\t        }\n\tpage = ParaphrasePage(title=\"Paraphrase\")\n\tpage.render()\n"]}
{"filename": "doccano_mini/pages/02_Question_Answering.py", "chunked_list": ["from typing import Dict, List\n\timport streamlit as st\n\tfrom doccano_mini.layout import BasePage\n\tfrom doccano_mini.prompts import make_question_answering_prompt\n\tclass QuestionAnsweringPage(BasePage):\n\t    example_path = \"question_answering.json\"\n\t    def make_prompt(self, examples: List[Dict]):\n\t        return make_question_answering_prompt(examples)\n\t    def prepare_inputs(self, columns: List[str]):\n\t        return {\n", "            \"context\": st.text_area(label=\"Context.\", value=\"\", height=300),\n\t            \"question\": st.text_input(label=\"Question.\", value=\"\"),\n\t        }\n\tpage = QuestionAnsweringPage(title=\"Question Answering\")\n\tpage.render()\n"]}
{"filename": "doccano_mini/pages/01_Text_Classification.py", "chunked_list": ["from typing import Dict, List\n\timport streamlit as st\n\tfrom doccano_mini.layout import BasePage\n\tfrom doccano_mini.prompts import make_classification_prompt\n\tclass TextClassificationPage(BasePage):\n\t    example_path = \"text_classification.json\"\n\t    def make_prompt(self, examples: List[Dict]):\n\t        return make_classification_prompt(examples)\n\t    def prepare_inputs(self, columns: List[str]):\n\t        return {\"input\": st.text_area(label=\"Please enter your text.\", value=\"\", height=300)}\n", "page = TextClassificationPage(title=\"Text Classification\")\n\tpage.render()\n"]}
{"filename": "doccano_mini/pages/09_Task_Free.py", "chunked_list": ["from typing import Dict, List\n\timport streamlit as st\n\tfrom doccano_mini.layout import BasePage\n\tfrom doccano_mini.prompts import make_task_free_prompt\n\tclass TaskFreePage(BasePage):\n\t    @property\n\t    def columns(self) -> List[str]:\n\t        num_cols = st.number_input(\"Set the number of columns\", min_value=2, max_value=10)\n\t        columns = [st.text_input(f\"Column {i + 1}:\", value=f\"column {i + 1}\") for i in range(int(num_cols))]\n\t        return columns\n", "    def make_examples(self, columns: List[str]):\n\t        df = self.load_examples(\"task_free.json\")\n\t        df = df.reindex(columns, axis=\"columns\", fill_value=\"\")\n\t        edited_df = st.experimental_data_editor(df, num_rows=\"dynamic\", width=1000)\n\t        examples = edited_df.to_dict(orient=\"records\")\n\t        return examples\n\t    def make_prompt(self, examples: List[Dict]):\n\t        return make_task_free_prompt(examples)\n\t    def prepare_inputs(self, columns: List[str]):\n\t        return {column: st.text_area(label=f\"Input for {column}:\", value=\"\", height=300) for column in columns[:-1]}\n", "page = TaskFreePage(title=\"Task Free\")\n\tpage.render()\n"]}
{"filename": "doccano_mini/pages/06_(Beta)_Evaluation.py", "chunked_list": ["from collections import defaultdict\n\timport pandas as pd\n\timport streamlit as st\n\tfrom datasets import load_dataset\n\tfrom langchain.chains import LLMChain\n\tfrom more_itertools import interleave_longest\n\tfrom sklearn.metrics import classification_report\n\tfrom doccano_mini.components import openai_model_form, task_instruction_editor\n\tfrom doccano_mini.prompts import make_classification_prompt\n\tfrom doccano_mini.utils import escape_markdown\n", "AVAILABLE_DATASETS = (\"imdb\", \"ag_news\", \"rotten_tomatoes\")\n\t@st.cache_resource\n\tdef prepare_dataset(dataset_id):\n\t    # Loading dataset\n\t    dataset = load_dataset(dataset_id, split=\"train\")\n\t    # Splitting dataset\n\t    dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", shuffle=True)\n\t    # Preparing indices\n\t    indices_by_label = defaultdict(list)\n\t    for i, x in enumerate(dataset[\"train\"]):\n", "        indices_by_label[x[\"label\"]].append(i)\n\t    return dataset, list(interleave_longest(*indices_by_label.values()))\n\tst.title(\"Text Classification Evaluation on 🤗 datasets\")\n\tst.header(\"Setup your data\")\n\tdataset_id = st.selectbox(\"Select a dataset\", options=AVAILABLE_DATASETS)\n\tdataset, train_indices = prepare_dataset(dataset_id)\n\ttrain_dataset = dataset[\"train\"]\n\tvalidation_dataset = dataset[\"test\"]\n\tlabel_info = train_dataset.features[\"label\"]\n\tnum_classes = label_info.num_classes\n", "few_shot_example_size = int(\n\t    st.number_input(\"Number of examples\", min_value=num_classes, max_value=num_classes * 5, value=num_classes)\n\t)\n\tsubset = []\n\tfor i in range(few_shot_example_size):\n\t    example = train_dataset[train_indices[i]]\n\t    subset.append({\"text\": example[\"text\"], \"label\": label_info.int2str(example[\"label\"])})\n\tdf = pd.DataFrame(subset)\n\tst.write(df)\n\tprompt = make_classification_prompt(df.to_dict(\"records\"))\n", "prompt = task_instruction_editor(prompt)\n\tst.header(\"Test\")\n\tcol1, col2 = st.columns([3, 1])\n\twith col1:\n\t    inputs = {\"input\": st.text_area(label=\"Please enter your text.\", value=\"\", height=300)}\n\twith col2:\n\t    llm = openai_model_form()\n\twith st.expander(\"See your prompt\"):\n\t    st.markdown(f\"```\\n{prompt.format(**inputs)}\\n```\")\n\tif llm is None:\n", "    st.error(\"Enter your API key.\")\n\tif st.button(\"Predict\", disabled=llm is None):\n\t    chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n\t    response = chain.run(**inputs)\n\t    st.markdown(escape_markdown(response).replace(\"\\n\", \"  \\n\"))\n\tst.subheader(\"Evaluation\")\n\tevaluation_size = int(st.number_input(\"Number of examples\", min_value=5, max_value=validation_dataset.dataset_size))\n\tif llm is None:\n\t    st.error(\"Enter your API key.\")\n\tif st.button(\"Evaluate\", disabled=llm is None):\n", "    chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n\t    y_true = []\n\t    y_pred = []\n\t    for i in range(evaluation_size):\n\t        example = validation_dataset[i]\n\t        response = chain.run(input=example[\"text\"])\n\t        y_true.append(label_info.int2str(example[\"label\"]))\n\t        y_pred.append(response.split(\":\")[-1].strip())\n\t    st.text(classification_report(y_true, y_pred, digits=3))\n"]}
{"filename": "doccano_mini/pages/03_Summarization.py", "chunked_list": ["from typing import Dict, List\n\timport streamlit as st\n\tfrom doccano_mini.layout import BasePage\n\tfrom doccano_mini.prompts import make_summarization_prompt\n\tclass SummarizationPage(BasePage):\n\t    example_path = \"summarization.json\"\n\t    def make_prompt(self, examples: List[Dict]):\n\t        return make_summarization_prompt(examples)\n\t    def prepare_inputs(self, columns: List[str]):\n\t        return {\n", "            \"passage\": st.text_area(label=\"Passage.\", value=\"\", height=300),\n\t        }\n\tpage = SummarizationPage(title=\"Summarization\")\n\tpage.render()\n"]}
{"filename": "doccano_mini/pages/05_Named_Entity_Recognition.py", "chunked_list": ["from typing import Dict, List\n\timport pandas as pd\n\timport streamlit as st\n\tfrom st_ner_annotate import st_ner_annotate\n\tfrom doccano_mini.layout import BasePage\n\tfrom doccano_mini.prompts import make_named_entity_recognition_prompt\n\tfrom doccano_mini.storages.entity import EntitySessionStorage\n\tfrom doccano_mini.storages.stepper import StepperSessionStorage\n\tclass NamedEntityRecognitionPage(BasePage):\n\t    example_path = \"named_entity_recognition.json\"\n", "    def __init__(self, title: str) -> None:\n\t        super().__init__(title)\n\t        self.types: List[str] = []\n\t        self.entity_repository = EntitySessionStorage()\n\t        self.stepper_repository = StepperSessionStorage()\n\t    def define_entity_types(self):\n\t        st.subheader(\"Define entity types\")\n\t        default_types = pd.DataFrame([{\"type\": entity_type} for entity_type in [\"ORG\", \"LOC\", \"PER\"]])\n\t        edited_df = st.experimental_data_editor(default_types, num_rows=\"dynamic\", width=1000)\n\t        types = edited_df[\"type\"].values\n", "        self.types = types\n\t        return types\n\t    def annotate(self, examples: List[Dict]) -> List[Dict]:\n\t        if len(examples) == 0:\n\t            return []\n\t        types = self.define_entity_types()\n\t        selected_type = st.selectbox(\"Select an entity type\", types)\n\t        col1, col2, _ = st.columns([1, 1, 8])\n\t        col1.button(\"Prev\", on_click=self.stepper_repository.decrement, args=(len(examples),))\n\t        col2.button(\"Next\", on_click=self.stepper_repository.increment, args=(len(examples),))\n", "        self.stepper_repository.fit(len(examples))\n\t        step = self.stepper_repository.get_step()\n\t        text = examples[step][\"text\"]\n\t        entities = self.entity_repository.find_by_text(text)\n\t        entities = st_ner_annotate(selected_type, text, entities, key=text)\n\t        self.entity_repository.store_by_text(text, entities)\n\t        return examples\n\t    def make_prompt(self, examples: List[Dict]):\n\t        examples = [\n\t            {**example, \"entities\": self.entity_repository.find_by_text(example[\"text\"])} for example in examples\n", "        ]\n\t        return make_named_entity_recognition_prompt(examples, types=self.types)\n\t    def prepare_inputs(self, columns: List[str]):\n\t        return {\"text\": st.text_area(label=\"Please enter your text.\", value=\"\", height=300)}\n\tpage = NamedEntityRecognitionPage(title=\"Named Entity Recognition\")\n\tpage.render()\n"]}
{"filename": "doccano_mini/storages/session_storage.py", "chunked_list": ["from typing import Any\n\tfrom streamlit.runtime.state import SessionStateProxy\n\tclass SessionStorage:\n\t    def __init__(self, state: SessionStateProxy) -> None:\n\t        self.state = state\n\t    def init_state(self, key: str, value: Any) -> None:\n\t        if key not in self.state:\n\t            self.state[key] = value\n\t    def set_state(self, key: str, value: Any, *, do_init: bool = False) -> None:\n\t        if do_init:\n", "            self.init_state(key, value)\n\t        self.state[key] = value\n\t    def get_state(self, key: str) -> Any:\n\t        return self.state.get(key, None)\n"]}
{"filename": "doccano_mini/storages/entity.py", "chunked_list": ["from collections import defaultdict\n\tfrom typing import List\n\timport streamlit as st\n\tfrom doccano_mini.models.entity import Entity\n\tfrom doccano_mini.storages.session_storage import SessionStorage\n\tclass EntitySessionStorage:\n\t    def __init__(self) -> None:\n\t        self.storage = SessionStorage(state=st.session_state)\n\t        self.storage.init_state(\"entities\", defaultdict(list))\n\t    def find_by_text(self, text: str) -> List[Entity]:\n", "        entities = self.storage.get_state(\"entities\")\n\t        return entities.get(text, [])\n\t    def store_by_text(self, text: str, entities: List[Entity]) -> None:\n\t        current_entities = self.storage.get_state(\"entities\")\n\t        current_entities[text] = entities\n\t        self.storage.set_state(\"entities\", current_entities)\n"]}
{"filename": "doccano_mini/storages/stepper.py", "chunked_list": ["import streamlit as st\n\tfrom doccano_mini.models.stepper import Stepper\n\tfrom doccano_mini.storages.session_storage import SessionStorage\n\tclass StepperSessionStorage:\n\t    def __init__(self) -> None:\n\t        self.storage = SessionStorage(state=st.session_state)\n\t        self.storage.init_state(\"step\", 0)\n\t    def get_step(self) -> int:\n\t        return self.storage.get_state(\"step\")\n\t    def fit(self, total: int) -> None:\n", "        step = self.storage.get_state(\"step\")\n\t        stepper = Stepper(step)\n\t        stepper.fit(total)\n\t        self.storage.set_state(\"step\", stepper.step)\n\t    def increment(self, total: int) -> None:\n\t        step = self.storage.get_state(\"step\")\n\t        stepper = Stepper(step)\n\t        stepper.increment(total)\n\t        self.storage.set_state(\"step\", stepper.step)\n\t    def decrement(self, total: int) -> None:\n", "        step = self.storage.get_state(\"step\")\n\t        stepper = Stepper(step)\n\t        stepper.decrement(total)\n\t        self.storage.set_state(\"step\", stepper.step)\n"]}
{"filename": "doccano_mini/models/entity.py", "chunked_list": ["from typing import TypedDict\n\tclass Entity(TypedDict):\n\t    start: int\n\t    end: int\n\t    label: str\n"]}
{"filename": "doccano_mini/models/stepper.py", "chunked_list": ["class Stepper:\n\t    def __init__(self, step=0):\n\t        self._step = step\n\t    @property\n\t    def step(self) -> int:\n\t        return self._step\n\t    def fit(self, total: int):\n\t        if self._step >= total:\n\t            self._step = total - 1\n\t    def at(self, step: int, total: int):\n", "        if step >= total:\n\t            raise ValueError(f\"step must be less than {total}\")\n\t        if step < 0:\n\t            raise ValueError(\"step must be greater than 0\")\n\t        self._step = step\n\t    def increment(self, total: int):\n\t        self._step += 1\n\t        if self._step >= total:\n\t            self._step = 0\n\t    def decrement(self, total: int):\n", "        self._step -= 1\n\t        if self._step < 0:\n\t            self._step = total - 1\n"]}
