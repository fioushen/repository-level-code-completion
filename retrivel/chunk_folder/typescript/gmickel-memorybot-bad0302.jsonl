{"filename": "src/global.d.ts", "chunked_list": ["type Command = {\n\t  name: string;\n\t  aliases: string[];\n\t  description: string;\n\t  execute: (args: string[], output: NodeJS.WriteStream, commandHandler: CommandHandler) => Promise<void>;\n\t};\n\ttype CommandHandler = {\n\t  getCommands: () => Command[];\n\t  execute: (commandName: string, args: string[], output: NodeJS.WriteStream) => Promise<void>;\n\t};\n", "type Page = {\n\t  url: string;\n\t  text: string;\n\t  title: string;\n\t};\n\tinterface Config {\n\t  currentVectorStoreDatabasePath: string;\n\t  numContextDocumentsToRetrieve: number;\n\t  numMemoryDocumentsToRetrieve: number;\n\t  useWindowMemory: boolean;\n", "}\n\tinterface FileInfo {\n\t  name: string;\n\t  size: number;\n\t}\n\tinterface DirectoryContent {\n\t  [directory: string]: FileInfo[];\n\t}\n"]}
{"filename": "src/commands.ts", "chunked_list": ["import chalk from 'chalk';\n\timport changeContextStoreCommand from './commands/switchContextStoreCommand.js';\n\timport helpCommand from './commands/helpCommand.js';\n\timport quitCommand from './commands/quitCommand.js';\n\timport resetChatCommand from './commands/resetChatCommand.js';\n\timport addDocumentCommand from './commands/addDocumentCommand.js';\n\timport addURLCommand from './commands/addURLCommand.js';\n\timport addYouTubeCommand from './commands/addYouTubeCommand.js';\n\timport setContextConfigCommand from './commands/setContextConfigCommand.js';\n\timport setMemoryConfigCommand from './commands/setMemoryConfigCommand.js';\n", "import toggleWindowBufferMemoryCommand from './commands/toggleWindowBufferMemoryCommand.js';\n\timport listContextStoresCommand from './commands/listContextStoresCommand.js';\n\tfunction createCommandHandler(): CommandHandler {\n\t  const commands: Command[] = [\n\t    helpCommand,\n\t    quitCommand,\n\t    resetChatCommand,\n\t    addDocumentCommand,\n\t    addURLCommand,\n\t    addYouTubeCommand,\n", "    setContextConfigCommand,\n\t    setMemoryConfigCommand,\n\t    toggleWindowBufferMemoryCommand,\n\t    listContextStoresCommand,\n\t    changeContextStoreCommand,\n\t  ];\n\t  function getCommands() {\n\t    return commands;\n\t  }\n\t  const commandHandler: CommandHandler = {\n", "    getCommands,\n\t    async execute(commandName: string, args: string[], output: NodeJS.WriteStream) {\n\t      const command = commands.find((cmd) => cmd.name === commandName || cmd.aliases.includes(commandName));\n\t      if (command) {\n\t        await command.execute(args, output, commandHandler);\n\t      } else {\n\t        output.write(chalk.red('Unknown command. Type /help to see the list of available commands.\\n'));\n\t      }\n\t    },\n\t  };\n", "  return commandHandler;\n\t}\n\texport default createCommandHandler;\n"]}
{"filename": "src/updateReadme.ts", "chunked_list": ["import fs from 'fs';\n\timport path from 'path';\n\timport { getProjectRoot } from './config/index.js';\n\tconst projectRootDir = getProjectRoot();\n\tconst commandsDir = path.join(projectRootDir, 'src', 'commands');\n\tconst readmePath = path.join(projectRootDir, 'README.md');\n\tconst commandFiles = fs.readdirSync(commandsDir).filter((file) => file !== 'command.ts');\n\tasync function getCommandsMarkdown() {\n\t  const commandsPromises = commandFiles.map(async (file) => {\n\t    const commandModule = await import(path.join(commandsDir, file));\n", "    const command = commandModule.default;\n\t    const aliases =\n\t      command.aliases.length > 0 ? ` (${command.aliases.map((alias: string) => `/${alias}`).join(', ')})` : '';\n\t    return `- \\`/${command.name}\\`${aliases} - ${command.description}`;\n\t  });\n\t  const commands = await Promise.all(commandsPromises);\n\t  return commands.join('\\n');\n\t}\n\t(async () => {\n\t  const commandsMarkdown = await getCommandsMarkdown();\n", "  const readmeContent = fs.readFileSync(readmePath, 'utf8');\n\t  const updatedReadmeContent = readmeContent.replace(\n\t    /<!-- COMMANDS_START -->([\\s\\S]*?)<!-- COMMANDS_END -->/,\n\t    `<!-- COMMANDS_START -->\\n${commandsMarkdown}\\n<!-- COMMANDS_END -->`\n\t  );\n\t  fs.writeFileSync(readmePath, updatedReadmeContent, 'utf8');\n\t})();\n"]}
{"filename": "src/index.ts", "chunked_list": ["/* eslint-disable no-await-in-loop */\n\timport dotenv from 'dotenv';\n\timport { OpenAIChat } from 'langchain/llms/openai';\n\t// eslint-disable-next-line import/no-unresolved\n\timport * as readline from 'node:readline/promises';\n\timport path from 'path';\n\timport fs from 'fs';\n\t/* This line of code is importing the `stdin` and `stdout` streams from the `process` module in\n\tNode.js. These streams are used for reading input from the user and writing output to the console,\n\trespectively. */\n", "import { stdin as input, stdout as output } from 'node:process';\n\timport { CallbackManager } from 'langchain/callbacks';\n\timport { ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate } from 'langchain/prompts';\n\timport { LLMChain } from 'langchain/chains';\n\timport { oneLine } from 'common-tags';\n\timport chalk from 'chalk';\n\timport logChat from './chatLogger.js';\n\timport createCommandHandler from './commands.js';\n\timport { getMemoryVectorStore, addDocumentsToMemoryVectorStore, getBufferWindowMemory } from './lib/memoryManager.js';\n\timport { getContextVectorStore } from './lib/contextManager.js';\n", "import { getRelevantContext } from './lib/vectorStoreUtils.js';\n\timport sanitizeInput from './utils/sanitizeInput.js';\n\timport { getConfig, getProjectRoot } from './config/index.js';\n\tconst projectRootDir = getProjectRoot();\n\tdotenv.config();\n\t// Set up the chat log directory\n\tconst chatLogDirectory = path.join(projectRootDir, 'chat_logs');\n\t// Get the prompt template\n\tconst systemPromptTemplate = fs.readFileSync(path.join(projectRootDir, 'src/prompt.txt'), 'utf8');\n\t// Set up the readline interface to read input from the user and write output to the console\n", "const rl = readline.createInterface({ input, output });\n\t// Set up CLI commands\n\tconst commandHandler: CommandHandler = createCommandHandler();\n\tconst callbackManager = CallbackManager.fromHandlers({\n\t  // This function is called when the LLM generates a new token (i.e., a prediction for the next word)\n\t  async handleLLMNewToken(token: string) {\n\t    // Write the token to the output stream (i.e., the console)\n\t    output.write(token);\n\t  },\n\t});\n", "const llm = new OpenAIChat({\n\t  streaming: true,\n\t  callbackManager,\n\t  modelName: process.env.MODEL || 'gpt-3.5-turbo',\n\t});\n\tconst systemPrompt = SystemMessagePromptTemplate.fromTemplate(oneLine`\n\t  ${systemPromptTemplate}\n\t`);\n\tconst chatPrompt = ChatPromptTemplate.fromPromptMessages([\n\t  systemPrompt,\n", "  HumanMessagePromptTemplate.fromTemplate('QUESTION: \"\"\"{input}\"\"\"'),\n\t]);\n\tconst windowMemory = getBufferWindowMemory();\n\tconst chain = new LLMChain({\n\t  prompt: chatPrompt,\n\t  memory: windowMemory,\n\t  llm,\n\t});\n\t// eslint-disable-next-line no-constant-condition\n\twhile (true) {\n", "  output.write(chalk.green('\\nStart chatting or type /help for a list of commands\\n'));\n\t  const userInput = await rl.question('> ');\n\t  let response;\n\t  if (userInput.startsWith('/')) {\n\t    const [command, ...args] = userInput.slice(1).split(' ');\n\t    await commandHandler.execute(command, args, output);\n\t  } else {\n\t    const memoryVectorStore = await getMemoryVectorStore();\n\t    const contextVectorStore = await getContextVectorStore();\n\t    const question = sanitizeInput(userInput);\n", "    const config = getConfig();\n\t    const context = await getRelevantContext(contextVectorStore, question, config.numContextDocumentsToRetrieve);\n\t    const history = await getRelevantContext(memoryVectorStore, question, config.numMemoryDocumentsToRetrieve);\n\t    try {\n\t      response = await chain.call({\n\t        input: question,\n\t        context,\n\t        history,\n\t        immediate_history: config.useWindowMemory ? windowMemory : '',\n\t      });\n", "      if (response) {\n\t        await addDocumentsToMemoryVectorStore([\n\t          { content: question, metadataType: 'question' },\n\t          { content: response.text, metadataType: 'answer' },\n\t        ]);\n\t        await logChat(chatLogDirectory, question, response.response);\n\t      }\n\t    } catch (error) {\n\t      if (error instanceof Error && error.message.includes('Cancel:')) {\n\t        // TODO: Handle cancel\n", "      } else if (error instanceof Error) {\n\t        output.write(chalk.red(error.message));\n\t      } else {\n\t        output.write(chalk.red(error));\n\t      }\n\t    }\n\t  }\n\t  output.write('\\n');\n\t}\n"]}
{"filename": "src/chatLogger.ts", "chunked_list": ["import fs from 'fs-extra';\n\timport path from 'path';\n\tinterface ChatHistory {\n\t  timestamp: string;\n\t  question: string;\n\t  answer: string;\n\t}\n\tconst ensureLogDirectory = (logDirectory: string): void => {\n\t  fs.ensureDirSync(logDirectory);\n\t};\n", "const getLogFilename = (): string => {\n\t  const currentDate = new Date();\n\t  const year = currentDate.getFullYear();\n\t  const month = String(currentDate.getMonth() + 1).padStart(2, '0');\n\t  const day = String(currentDate.getDate()).padStart(2, '0');\n\t  return `${year}-${month}-${day}.json`;\n\t};\n\tconst logChat = async (logDirectory: string, question: string, answer: string): Promise<void> => {\n\t  const timestamp = new Date().toISOString();\n\t  const chatHistory: ChatHistory = { timestamp, question, answer };\n", "  const logFilename = getLogFilename();\n\t  const logFilePath = path.join(logDirectory, logFilename);\n\t  ensureLogDirectory(logDirectory);\n\t  if (!fs.existsSync(logFilePath)) {\n\t    await fs.writeJson(logFilePath, [chatHistory]);\n\t  } else {\n\t    const chatHistoryArray = await fs.readJson(logFilePath);\n\t    chatHistoryArray.push(chatHistory);\n\t    await fs.writeJson(logFilePath, chatHistoryArray);\n\t  }\n", "};\n\texport default logChat;\n"]}
{"filename": "src/commands/toggleWindowBufferMemoryCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { setUseWindowMemory, getConfig } from '../config/index.js';\n\tconst toggleWindowBufferMemoryCommand = createCommand(\n\t  'toggle-window-memory',\n\t  ['wm'],\n\t  `Toggles the window buffer memory (MemoryBot's short-term transient memory) on or off.`,\n\t  async (_args, output) => {\n\t    setUseWindowMemory(!getConfig().useWindowMemory);\n\t    const config = getConfig();\n", "    output.write(chalk.blue(`Use Window Buffer Memory set to ${config.useWindowMemory}`));\n\t  }\n\t);\n\texport default toggleWindowBufferMemoryCommand;\n"]}
{"filename": "src/commands/switchContextStoreCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { loadOrCreateEmptyVectorStore } from '../lib/contextManager.js';\n\tconst changeContextStoreCommand = createCommand(\n\t  'change-context-store',\n\t  ['ccs'],\n\t  `Loads an existing or creates a new empty context vector store as a subdirectory of the db directory.\\n\n\t    Arguments: \\`subdirectory\\`\\n\n\t    Example: /change-context-store newcontext`,\n\t  async (args, output) => {\n", "    if (!args || args.length !== 1) {\n\t      output.write(chalk.red('Invalid number of arguments. Usage: /change-context-store `subdirectory`\\n'));\n\t      return;\n\t    }\n\t    const subDirectory = args[0];\n\t    await loadOrCreateEmptyVectorStore(subDirectory);\n\t  }\n\t);\n\texport default changeContextStoreCommand;\n"]}
{"filename": "src/commands/addYouTubeCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { addYouTube } from '../lib/contextManager.js';\n\tconst addYouTubeCommand = createCommand(\n\t  'add-youtube',\n\t  ['yt'],\n\t  `Adds the transcript from a youtube video and adds it to the context vector store.\\n\n\t    Arguments: \\`youtube url\\` or \\`youtube videoid\\`\\n\n\t    Example: /add-url https://www.youtube.com/watch?v=VMj-3S1tku0`,\n\t  async (args, output) => {\n", "    if (!args || args.length !== 1) {\n\t      output.write(chalk.red('Invalid number of arguments. Usage: /add-url `youtube url` or `youtube videoid`\\n'));\n\t      return;\n\t    }\n\t    const URLOrVideoID = args[0];\n\t    await addYouTube(URLOrVideoID);\n\t  }\n\t);\n\texport default addYouTubeCommand;\n"]}
{"filename": "src/commands/addURLCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { addURL } from '../lib/contextManager.js';\n\tconst addURLCommand = createCommand(\n\t  'add-url',\n\t  ['url'],\n\t  `Scrapes the content from a url and adds it to the context vector store.\\n\n\t    Arguments: \\`url\\`, \\`selector to extract\\` (Default: body), \\`Maximum number of links to follow\\` (Default: 20), \\`Ignore pages with less than n characters\\` (Default: 200)\\n\n\t    Example: /add-url https://dociq.io main 10 500\\n\n\t    This operation may try to generate a large number of embeddings depending on the structure of the web pages and may lead to rate-limiting.\\n\n", "    To avoid this, you can try to target a specific selector such as \\`.main\\``,\n\t  async (args, output) => {\n\t    if (!args || args.length > 4) {\n\t      output.write(\n\t        chalk.red(\n\t          'Invalid number of arguments. Usage: /add-url `url` `selector to extract` `Maximum number of links to follow` `Ignore pages with less than n characters`\\n'\n\t        )\n\t      );\n\t      return;\n\t    }\n", "    const url = args[0];\n\t    const selector = args[1];\n\t    const maxLinks = parseInt(args[2], 10) || 20;\n\t    const minChars = parseInt(args[3], 10) || 200;\n\t    await addURL(url, selector, maxLinks, minChars);\n\t  }\n\t);\n\texport default addURLCommand;\n"]}
{"filename": "src/commands/addDocumentCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { addDocument } from '../lib/contextManager.js';\n\tconst addDocumentCommand = createCommand(\n\t  'add-docs',\n\t  ['docs'],\n\t  `Adds new documents from your configured docs directory to the context vector store.\\n\n\t    Usage: /add-docs example.txt example.md\\n\n\t    Supports the following file types: .txt, .md, .pdf, .docx, .csv, .epub`,\n\t  async (args: string[], output: NodeJS.WriteStream) => {\n", "    if (!args) {\n\t      output.write(chalk.red('Invalid number of arguments. Usage: /add-docs example.txt example.md\\n'));\n\t      return;\n\t    }\n\t    await addDocument(args);\n\t  }\n\t);\n\texport default addDocumentCommand;\n"]}
{"filename": "src/commands/listContextStoresCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { listContextStores } from '../lib/contextManager.js';\n\tconst listContextStoresCommand = createCommand(\n\t  'list-context-stores',\n\t  ['lcs'],\n\t  `Lists all available context vector stores and their details.\\n`,\n\t  async (args, output) => {\n\t    if (!args || args.length > 0) {\n\t      output.write(chalk.red('Invalid number of arguments. Usage: /list-context-stores\\n'));\n", "      return;\n\t    }\n\t    await listContextStores();\n\t  }\n\t);\n\texport default listContextStoresCommand;\n"]}
{"filename": "src/commands/setMemoryConfigCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { setNumMemoryDocumentsToRetrieve, getConfig } from '../config/index.js';\n\tconst setMemoryConfigCommand = createCommand(\n\t  'memory-config',\n\t  ['mc'],\n\t  `Sets the number of relevant documents to return from the memory vector store.\\n\n\t    Arguments: \\`number of documents\\` (Default: 4)\\n\n\t    Example: /memory-config 10`,\n\t  async (args, output) => {\n", "    if (!args || args.length !== 1) {\n\t      output.write(chalk.red('Invalid number of arguments. Usage: /memory-config `number of documents`\\n'));\n\t      return;\n\t    }\n\t    const numMemoryDocumentsToRetrieve = parseInt(args[0], 10);\n\t    setNumMemoryDocumentsToRetrieve(numMemoryDocumentsToRetrieve);\n\t    const config = getConfig();\n\t    output.write(chalk.blue(`Number of memory documents to retrieve set to ${config.numMemoryDocumentsToRetrieve}`));\n\t  }\n\t);\n", "export default setMemoryConfigCommand;\n"]}
{"filename": "src/commands/quitCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\tconst exitCommand = createCommand('quit', ['q'], 'Terminates the script', (_args, output) => {\n\t  output.write(chalk.yellow('\\nThanks for talking, bye!\\n'));\n\t  process.exit(0);\n\t});\n\texport default exitCommand;\n"]}
{"filename": "src/commands/setContextConfigCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { setNumContextDocumentsToRetrieve, getConfig } from '../config/index.js';\n\tconst setContextConfigCommand = createCommand(\n\t  'context-config',\n\t  ['cc'],\n\t  `Sets the number of relevant documents to return from the context vector store.\\n\n\t    Arguments: \\`number of documents\\` (Default: 6)\\n\n\t    Example: \\`/context-config 10\\``,\n\t  async (args, output) => {\n", "    if (!args || args.length !== 1) {\n\t      output.write(chalk.red('Invalid number of arguments. Usage: /context-config `number of documents`\\n'));\n\t      return;\n\t    }\n\t    const numContextDocumentsToRetrieve = parseInt(args[0], 10);\n\t    setNumContextDocumentsToRetrieve(numContextDocumentsToRetrieve);\n\t    const config = getConfig();\n\t    output.write(chalk.blue(`Number of context documents to retrieve set to ${config.numContextDocumentsToRetrieve}`));\n\t  }\n\t);\n", "export default setContextConfigCommand;\n"]}
{"filename": "src/commands/resetChatCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\timport { resetBufferWindowMemory, resetMemoryVectorStore, setMemoryVectorStore } from '../lib/memoryManager.js';\n\tconst resetChatCommand = createCommand(\n\t  'reset',\n\t  [],\n\t  'Resets the chat and starts a new conversation - This clears the memory vector store and the buffer window memory.',\n\t  async (_args, output) => {\n\t    output.write(chalk.yellow('\\nResetting the chat!\\n'));\n\t    await resetMemoryVectorStore((newMemoryVectorStore) => {\n", "      setMemoryVectorStore(newMemoryVectorStore);\n\t    });\n\t    resetBufferWindowMemory();\n\t  }\n\t);\n\texport default resetChatCommand;\n"]}
{"filename": "src/commands/helpCommand.ts", "chunked_list": ["import chalk from 'chalk';\n\timport createCommand from './command.js';\n\tconst helpCommand = createCommand(\n\t  'help',\n\t  ['h', '?'],\n\t  'Show the list of available commands',\n\t  (_args, output, commandHandler) =>\n\t    new Promise<void>((resolve) => {\n\t      output.write(chalk.blue('Usage:\\n'));\n\t      output.write('Ask memorybot to write some marketing materials and press enter.\\n');\n", "      output.write(chalk.blue('\\nAvailable commands:\\n'));\n\t      commandHandler.getCommands().forEach((command) => {\n\t        const aliases = command.aliases.length > 0 ? ` (/${command.aliases.join(', /')})` : '';\n\t        output.write(chalk.yellow(`/${command.name}${aliases}`));\n\t        output.write(` - ${command.description}`);\n\t        output.write('\\n');\n\t      });\n\t      resolve();\n\t    })\n\t);\n", "export default helpCommand;\n"]}
{"filename": "src/commands/command.ts", "chunked_list": ["/**\n\t * The function creates a command object with a name, aliases, description, and an execute function\n\t * that returns a Promise.\n\t * @param {string} name - A string representing the name of the command.\n\t * @param {string[]} aliases - An array of alternative names that can be used to call the command. For\n\t * example, if the command is named \"help\", aliases could include \"h\" or \"info\".\n\t * @param {string} description - A brief description of what the command does.\n\t * @param execute - The `execute` parameter is a function that takes in three arguments:\n\t * @returns A `Command` object is being returned.\n\t */\n", "function createCommand(\n\t  name: string,\n\t  aliases: string[],\n\t  description: string,\n\t  execute: (args: string[], output: NodeJS.WriteStream, commandHandler: CommandHandler) => Promise<void>\n\t): Command {\n\t  return { name, aliases, description, execute };\n\t}\n\texport default createCommand;\n"]}
{"filename": "src/utils/getDirectoryFiles.ts", "chunked_list": ["import path from 'path';\n\timport fs from 'node:fs/promises';\n\texport default async function getDirectoryFiles(directoryPath: string): Promise<string[]> {\n\t  const fileNames = await fs.readdir(directoryPath);\n\t  const filePathsPromises = fileNames.map(async (fileName) => {\n\t    const filePath = path.join(directoryPath, fileName);\n\t    const stat = await fs.stat(filePath);\n\t    if (stat.isDirectory()) {\n\t      const subDirectoryFiles = await getDirectoryFiles(filePath);\n\t      return subDirectoryFiles;\n", "    }\n\t    return filePath;\n\t  });\n\t  const filePathsArray = await Promise.all(filePathsPromises);\n\t  const filePaths = filePathsArray.flat();\n\t  return filePaths;\n\t}\n"]}
{"filename": "src/utils/createDirectory.ts", "chunked_list": ["import fs from 'node:fs/promises';\n\texport default async function createDirectory(directoryPath: string): Promise<void> {\n\t  if (await fs.stat(directoryPath).catch(() => false)) {\n\t    return;\n\t  }\n\t  await fs.mkdir(directoryPath, { recursive: true });\n\t}\n"]}
{"filename": "src/utils/getDirectoryListWithDetails.ts", "chunked_list": ["import fs from 'node:fs/promises';\n\timport path from 'path';\n\texport default async function getDirectoryListWithDetails(\n\t  directory: string,\n\t  contents: DirectoryContent = {}\n\t): Promise<DirectoryContent> {\n\t  const dirents = await fs.readdir(directory, { withFileTypes: true });\n\t  const newContents: DirectoryContent = { ...contents };\n\t  const files: FileInfo[] = [];\n\t  const actions = dirents.map(async (dirent) => {\n", "    const res = path.resolve(directory, dirent.name);\n\t    if (dirent.isDirectory()) {\n\t      const subdirContents = await getDirectoryListWithDetails(res, newContents);\n\t      Object.assign(newContents, subdirContents);\n\t    } else if (dirent.isFile() && dirent.name !== '.gitignore') {\n\t      const stats = await fs.stat(res);\n\t      files.push({ name: dirent.name, size: Math.ceil(stats.size / 1024) });\n\t    }\n\t  });\n\t  await Promise.all(actions);\n", "  if (files.length) {\n\t    newContents[directory] = files;\n\t  }\n\t  return newContents;\n\t}\n"]}
{"filename": "src/utils/resolveURL.ts", "chunked_list": ["/**\n\t * The function resolves a URL from a given base URL and returns the resolved URL as a string.\n\t * @param {string} from - The `from` parameter is a string representing the base URL that the `to`\n\t * parameter will be resolved against. It can be an absolute or relative URL.\n\t * @param {string} to - The `to` parameter is a string representing the URL that needs to be resolved.\n\t * It can be an absolute URL or a relative URL.\n\t * @returns The function `resolve` returns a string that represents the resolved URL. If the `to`\n\t * parameter is a relative URL, the function returns a string that represents the resolved URL relative\n\t * to the `from` parameter. If the `to` parameter is an absolute URL, the function returns a string\n\t * that represents the resolved URL.\n", " */\n\texport default function resolve(from: string, to: string) {\n\t  const resolvedUrl = new URL(to, new URL(from, 'resolve://'));\n\t  if (resolvedUrl.protocol === 'resolve:') {\n\t    // `from` is a relative URL.\n\t    const { pathname, search, hash } = resolvedUrl;\n\t    return pathname + search + hash;\n\t  }\n\t  return resolvedUrl.toString();\n\t}\n"]}
{"filename": "src/utils/sanitizeInput.ts", "chunked_list": ["/**\n\t * The function sanitizes a string input by removing leading/trailing white spaces and replacing new\n\t * lines with spaces.\n\t * @param {string} input - The input parameter is a string that needs to be sanitized.\n\t * @returns The function `sanitizeInput` is returning a string. The string is the input string with\n\t * leading and trailing whitespace removed, and all newline characters replaced with a space character.\n\t */\n\texport default function sanitizeInput(input: string): string {\n\t  return input.trim().replaceAll('\\n', ' ');\n\t}\n"]}
{"filename": "src/config/index.ts", "chunked_list": ["import type { Options } from 'ora';\n\timport type { Writable } from 'stream';\n\timport { fileURLToPath } from 'url';\n\timport path from 'path';\n\texport function getProjectRoot() {\n\t  const currentModulePath = fileURLToPath(import.meta.url);\n\t  const projectRoot = path.resolve(path.dirname(currentModulePath), '..', '..');\n\t  return projectRoot;\n\t}\n\texport function getDefaultOraOptions(output: Writable): Options {\n", "  return {\n\t    text: 'Loading',\n\t    stream: output,\n\t    discardStdin: false,\n\t  };\n\t}\n\tconst defaultConfig: Config = {\n\t  currentVectorStoreDatabasePath: path.join(getProjectRoot(), process.env.VECTOR_STORE_DIR || 'db/default'),\n\t  numContextDocumentsToRetrieve: 6,\n\t  numMemoryDocumentsToRetrieve: 4,\n", "  useWindowMemory: true,\n\t};\n\tlet config: Config = { ...defaultConfig };\n\texport function getConfig(): Config {\n\t  return config;\n\t}\n\texport function setCurrentVectorStoreDatabasePath(currentVectorStoreDatabasePath: string) {\n\t  config = { ...config, currentVectorStoreDatabasePath };\n\t}\n\texport function setNumContextDocumentsToRetrieve(numContextDocumentsToRetrieve: number) {\n", "  config = { ...config, numContextDocumentsToRetrieve };\n\t}\n\texport function setNumMemoryDocumentsToRetrieve(numMemoryDocumentsToRetrieve: number) {\n\t  config = { ...config, numMemoryDocumentsToRetrieve };\n\t}\n\texport function setUseWindowMemory(useWindowMemory: boolean) {\n\t  config = { ...config, useWindowMemory };\n\t}\n"]}
{"filename": "src/lib/vectorStoreUtils.ts", "chunked_list": ["import { HNSWLib } from 'langchain/vectorstores/hnswlib';\n\t/**\n\t * Retrieves relevant context for the given question by performing a similarity search on the provided vector store.\n\t * @param {HNSWLib} vectorStore - HNSWLib is a library for approximate nearest neighbor search, used to\n\t * search for similar vectors in a high-dimensional space.\n\t * @param {string} sanitizedQuestion - The sanitized version of the question that needs to be answered.\n\t * It is a string input.\n\t * @param {number} numDocuments - The `numDocuments` parameter is the number of documents that the\n\t * `getRelevantContext` function should retrieve from the `vectorStore` based on their similarity to\n\t * the `sanitizedQuestion`.\n", " * @returns The function `getRelevantContext` is returning a Promise that resolves to a string. The\n\t * string is the concatenation of the `pageContent` property of the top `numDocuments` documents\n\t * returned by a similarity search performed on a `vectorStore` using the `sanitizedQuestion` as the\n\t * query. The resulting string is trimmed and all newline characters are replaced with spaces.\n\t */\n\tasync function getRelevantContext(\n\t  vectorStore: HNSWLib,\n\t  sanitizedQuestion: string,\n\t  numDocuments: number\n\t): Promise<string> {\n", "  const documents = await vectorStore.similaritySearch(sanitizedQuestion, numDocuments);\n\t  return documents\n\t    .map((doc) => doc.pageContent)\n\t    .join(', ')\n\t    .trim()\n\t    .replaceAll('\\n', ' ');\n\t}\n\t// eslint-disable-next-line import/prefer-default-export\n\texport { getRelevantContext };\n"]}
{"filename": "src/lib/contextManager.ts", "chunked_list": ["import chalk from 'chalk';\n\timport { stdout as output } from 'node:process';\n\timport { OpenAIEmbeddings } from 'langchain/embeddings/openai';\n\timport { HNSWLib } from 'langchain/vectorstores/hnswlib';\n\timport { JSONLoader } from 'langchain/document_loaders/fs/json';\n\timport { TextLoader } from 'langchain/document_loaders/fs/text';\n\timport { PDFLoader } from 'langchain/document_loaders/fs/pdf';\n\timport { DocxLoader } from 'langchain/document_loaders/fs/docx';\n\timport { EPubLoader } from 'langchain/document_loaders/fs/epub';\n\timport { CSVLoader } from 'langchain/document_loaders/fs/csv';\n", "import ora from 'ora';\n\timport { MarkdownTextSplitter, RecursiveCharacterTextSplitter } from 'langchain/text_splitter';\n\timport { Document } from 'langchain/document';\n\timport path from 'path';\n\timport { YoutubeTranscript } from 'youtube-transcript';\n\timport getDirectoryListWithDetails from '../utils/getDirectoryListWithDetails.js';\n\timport createDirectory from '../utils/createDirectory.js';\n\timport { getConfig, getDefaultOraOptions, getProjectRoot, setCurrentVectorStoreDatabasePath } from '../config/index.js';\n\timport getDirectoryFiles from '../utils/getDirectoryFiles.js';\n\timport WebCrawler from './crawler.js';\n", "const projectRootDir = getProjectRoot();\n\tconst defaultOraOptions = getDefaultOraOptions(output);\n\t/**\n\t * This function loads and splits a file based on its extension using different loaders and text\n\t * splitters.\n\t * @param {string} filePath - A string representing the path to the file that needs to be loaded and\n\t * split into documents.\n\t * @returns The function `loadAndSplitFile` returns a Promise that resolves to an array of `Document`\n\t * objects, where each `Document` represents a split portion of the input file. The type of the\n\t * `Document` object is `Document<Record<string, unknown>>`, which means it has a generic type\n", " * parameter that is an object with string keys and unknown values.\n\t */\n\tasync function loadAndSplitFile(filePath: string): Promise<Document<Record<string, unknown>>[]> {\n\t  const fileExtension = path.extname(filePath);\n\t  let loader;\n\t  let documents: Document<Record<string, unknown>>[];\n\t  switch (fileExtension) {\n\t    case '.json':\n\t      loader = new JSONLoader(filePath);\n\t      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n", "      break;\n\t    case '.txt':\n\t      loader = new TextLoader(filePath);\n\t      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n\t      break;\n\t    case '.md':\n\t      loader = new TextLoader(filePath);\n\t      documents = await loader.loadAndSplit(new MarkdownTextSplitter());\n\t      break;\n\t    case '.pdf':\n", "      loader = new PDFLoader(filePath, { splitPages: false });\n\t      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n\t      break;\n\t    case '.docx':\n\t      loader = new DocxLoader(filePath);\n\t      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n\t      break;\n\t    case '.csv':\n\t      loader = new CSVLoader(filePath);\n\t      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n", "      break;\n\t    case '.epub':\n\t      loader = new EPubLoader(filePath, { splitChapters: false });\n\t      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n\t      break;\n\t    default:\n\t      throw new Error(`Unsupported file extension: ${fileExtension}`);\n\t  }\n\t  return documents;\n\t}\n", "/**\n\t * This function loads or creates a vector store using HNSWLib and OpenAIEmbeddings.\n\t * @returns The function `loadOrCreateVectorStore` returns a Promise that resolves to an instance of\n\t * the `HNSWLib` class, which is a vector store used for storing and searching high-dimensional\n\t * vectors.\n\t */\n\tasync function loadOrCreateVectorStore(): Promise<HNSWLib> {\n\t  let vectorStore: HNSWLib;\n\t  let spinner;\n\t  await createDirectory(getConfig().currentVectorStoreDatabasePath);\n", "  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n\t  try {\n\t    vectorStore = await HNSWLib.load(dbDirectory, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n\t  } catch {\n\t    spinner = ora({\n\t      ...defaultOraOptions,\n\t      text: chalk.blue(`Creating new Context Vector Store in the ${dbDirectory} directory`),\n\t    }).start();\n\t    const docsDirectory = path.join(projectRootDir, process.env.DOCS_DIR || 'docs');\n\t    const filesToAdd = await getDirectoryFiles(docsDirectory);\n", "    const documents = await Promise.all(filesToAdd.map((filePath) => loadAndSplitFile(filePath)));\n\t    const flattenedDocuments = documents.reduce((acc, val) => acc.concat(val), []);\n\t    vectorStore = await HNSWLib.fromDocuments(flattenedDocuments, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n\t    await vectorStore.save(dbDirectory);\n\t    spinner.succeed();\n\t  }\n\t  return vectorStore;\n\t}\n\tconst contextVectorStore = await loadOrCreateVectorStore();\n\tconst contextWrapper = {\n", "  contextInstance: contextVectorStore,\n\t};\n\t/**\n\t * This function loads or creates a new empty Context Vector Store using HNSWLib and OpenAIEmbeddings.\n\t * @returns a Promise that resolves to an instance of the HNSWLib class, which represents a\n\t * hierarchical navigable small world graph used for nearest neighbor search. The instance is either\n\t * loaded from an existing directory or created as a new empty Context Vector Store with specified\n\t * parameters.\n\t */\n\tasync function loadOrCreateEmptyVectorStore(subDirectory: string): Promise<HNSWLib> {\n", "  let vectorStore: HNSWLib;\n\t  let spinner;\n\t  const newContextVectorStorePath = path.join(projectRootDir, process.env.VECTOR_STORE_BASE_DIR || 'db', subDirectory);\n\t  await createDirectory(newContextVectorStorePath);\n\t  setCurrentVectorStoreDatabasePath(newContextVectorStorePath);\n\t  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n\t  try {\n\t    vectorStore = await HNSWLib.load(dbDirectory, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n\t    output.write(chalk.blue(`Using Context Vector Store in the ${dbDirectory} directory\\n`));\n\t  } catch {\n", "    spinner = ora({\n\t      ...defaultOraOptions,\n\t      text: chalk.blue(`Creating new empty Context Vector Store in the ${dbDirectory} directory`),\n\t    }).start();\n\t    vectorStore = new HNSWLib(new OpenAIEmbeddings({ maxConcurrency: 5 }), {\n\t      space: 'cosine',\n\t      numDimensions: 1536,\n\t    });\n\t    spinner.succeed();\n\t    output.write(\n", "      chalk.red.bold(\n\t        `\\nThe Context Vector Store is currently empty and unsaved, add context to is using \\`/add-docs\\`, \\`/add-url\\` or \\`/add-youtube\\``\n\t      )\n\t    );\n\t  }\n\t  contextWrapper.contextInstance = vectorStore;\n\t  return vectorStore;\n\t}\n\tasync function getContextVectorStore() {\n\t  return contextWrapper.contextInstance;\n", "}\n\t/**\n\t * This function adds documents to a context vector store and saves them.\n\t * @param {string[]} filePaths - The `filePaths` parameter is an array of strings representing the file\n\t * paths of the documents that need to be added to the Context Vector Store.\n\t * @returns nothing (`undefined`).\n\t */\n\tasync function addDocument(filePaths: string[]) {\n\t  let spinner;\n\t  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n", "  try {\n\t    spinner = ora({ ...defaultOraOptions, text: `Adding files to the Context Vector Store` }).start();\n\t    const docsDirectory = path.join(projectRootDir, process.env.DOCS_DIR || 'docs');\n\t    const documents = await Promise.all(\n\t      filePaths.map((filePath) => loadAndSplitFile(path.join(docsDirectory, filePath)))\n\t    );\n\t    const flattenedDocuments = documents.reduce((acc, val) => acc.concat(val), []);\n\t    const vectorStore = await getContextVectorStore();\n\t    await vectorStore.addDocuments(flattenedDocuments);\n\t    await vectorStore.save(dbDirectory);\n", "    spinner.succeed();\n\t    return;\n\t  } catch (error) {\n\t    if (spinner) {\n\t      spinner.fail(chalk.red(error));\n\t    } else {\n\t      output.write(chalk.red(error));\n\t    }\n\t  }\n\t}\n", "/**\n\t * The function adds a YouTube video transcript to a Context Vector Store.\n\t * @param {string} URLOrVideoID - The URLOrVideoID parameter is a string that represents either the URL\n\t * or the video ID of a YouTube video.\n\t * @returns Nothing is being returned explicitly in the code, but the function is expected to return\n\t * undefined after completing its execution.\n\t */\n\tasync function addYouTube(URLOrVideoID: string) {\n\t  let spinner;\n\t  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n", "  try {\n\t    spinner = ora({\n\t      ...defaultOraOptions,\n\t      text: `Adding Video transcript from ${URLOrVideoID} to the Context Vector Store`,\n\t    }).start();\n\t    const transcript = await YoutubeTranscript.fetchTranscript(URLOrVideoID);\n\t    const text = transcript.map((part) => part.text).join(' ');\n\t    const splitter = new RecursiveCharacterTextSplitter();\n\t    const videoDocs = await splitter.splitDocuments([\n\t      new Document({\n", "        pageContent: text,\n\t      }),\n\t    ]);\n\t    const vectorStore = await getContextVectorStore();\n\t    await vectorStore.addDocuments(videoDocs);\n\t    await vectorStore.save(dbDirectory);\n\t    spinner.succeed();\n\t    return;\n\t  } catch (error) {\n\t    if (spinner) {\n", "      spinner.fail(chalk.red(error));\n\t    } else {\n\t      output.write(chalk.red(error));\n\t    }\n\t  }\n\t}\n\t/**\n\t * The function crawls a given URL, extracts text from the pages, splits the text into documents,\n\t * generates embeddings for the documents, and saves them to a vector store.\n\t * @param {string} URL - The URL of the website to crawl and extract text from.\n", " * @param {string} selector - The selector parameter is a string that represents a CSS selector used to\n\t * identify the HTML elements to be crawled on the web page. The WebCrawler will only crawl the\n\t * elements that match the selector.\n\t * @param {number} maxPages - The maximum number of pages to crawl for the given URL.\n\t * @param {number} numberOfCharactersRequired - `numberOfCharactersRequired` is a number that specifies\n\t * the minimum number of characters required for a document to be considered valid and used for\n\t * generating embeddings. Any document with less than this number of characters will be discarded.\n\t * @returns Nothing is being returned explicitly in the function, but it is implied that the function\n\t * will return undefined if there are no errors.\n\t */\n", "async function addURL(URL: string, selector: string, maxPages: number, numberOfCharactersRequired: number) {\n\t  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n\t  const addUrlSpinner = ora({ ...defaultOraOptions, text: `Crawling ${URL}` });\n\t  let documents;\n\t  try {\n\t    addUrlSpinner.start();\n\t    const progressCallback = (linksFound: number, linksCrawled: number, currentUrl: string) => {\n\t      addUrlSpinner.text = `Links found: ${linksFound} - Links crawled: ${linksCrawled} - Crawling ${currentUrl}`;\n\t    };\n\t    const crawler = new WebCrawler([URL], progressCallback, selector, maxPages, numberOfCharactersRequired);\n", "    const pages = (await crawler.start()) as Page[];\n\t    documents = await Promise.all(\n\t      pages.map((row) => {\n\t        const splitter = new RecursiveCharacterTextSplitter();\n\t        const webDocs = splitter.splitDocuments([\n\t          new Document({\n\t            pageContent: row.text,\n\t          }),\n\t        ]);\n\t        return webDocs;\n", "      })\n\t    );\n\t    addUrlSpinner.succeed();\n\t  } catch (error) {\n\t    addUrlSpinner.fail(chalk.red(error));\n\t  }\n\t  if (documents) {\n\t    const generateEmbeddingsSpinner = ora({ ...defaultOraOptions, text: `Generating Embeddings` });\n\t    try {\n\t      const flattenedDocuments = documents.flat();\n", "      generateEmbeddingsSpinner.text = `Generating Embeddings for ${flattenedDocuments.length} documents`;\n\t      generateEmbeddingsSpinner.start();\n\t      const vectorStore = await getContextVectorStore();\n\t      await vectorStore.addDocuments(flattenedDocuments);\n\t      await vectorStore.save(dbDirectory);\n\t      generateEmbeddingsSpinner.succeed();\n\t      return;\n\t    } catch (error) {\n\t      generateEmbeddingsSpinner.fail(chalk.red(error));\n\t    }\n", "  }\n\t}\n\tasync function listContextStores() {\n\t  const projectRoot = getProjectRoot(); // Please replace this with your actual function to get the project root\n\t  const vectorStoreDir = process.env.VECTOR_STORE_BASE_DIR || 'db';\n\t  const targetDir = path.join(projectRoot, vectorStoreDir);\n\t  const contextVectorStoresList = await getDirectoryListWithDetails(targetDir);\n\t  output.write(chalk.blue(`Context Vector Stores in ${targetDir}:\\n\\n`));\n\t  Object.entries(contextVectorStoresList).forEach(([dir, files]) => {\n\t    output.write(chalk.yellow(`Directory: ${dir}`));\n", "    if (dir === getConfig().currentVectorStoreDatabasePath) {\n\t      output.write(chalk.green(` (Currently selected)`));\n\t    }\n\t    output.write('\\n');\n\t    files.forEach((file) => {\n\t      output.write(chalk.yellow(`  File: ${file.name}, Size: ${file.size} KB\\n`));\n\t    });\n\t  });\n\t}\n\texport { getContextVectorStore, addDocument, addURL, addYouTube, listContextStores, loadOrCreateEmptyVectorStore };\n"]}
{"filename": "src/lib/crawler.ts", "chunked_list": ["import * as cheerio from 'cheerio';\n\timport Crawler, { CrawlerRequestResponse } from 'crawler';\n\timport { stderr } from 'node:process';\n\timport resolveURL from '../utils/resolveURL.js';\n\t// import TurndownService from 'turndown';\n\t// const turndownService = new TurndownService();\n\ttype ProgressCallback = (linksFound: number, linksCrawled: number, currentUrl: string) => void;\n\tinterface Page {\n\t  url: string;\n\t  text: string;\n", "  title: string;\n\t}\n\t/* The WebCrawler class is a TypeScript implementation of a web crawler that can extract text from web\n\tpages and follow links to crawl more pages. */\n\tclass WebCrawler {\n\t  pages: Page[];\n\t  limit: number;\n\t  urls: string[];\n\t  count: number;\n\t  textLengthMinimum: number;\n", "  selector: string;\n\t  progressCallback: ProgressCallback;\n\t  crawler: Crawler;\n\t  constructor(\n\t    urls: string[],\n\t    progressCallback: ProgressCallback,\n\t    selector = 'body',\n\t    limit = 20,\n\t    textLengthMinimum = 200\n\t  ) {\n", "    this.urls = urls;\n\t    this.selector = selector;\n\t    this.limit = limit;\n\t    this.textLengthMinimum = textLengthMinimum;\n\t    this.progressCallback = progressCallback;\n\t    this.count = 0;\n\t    this.pages = [];\n\t    this.crawler = new Crawler({\n\t      maxConnections: 10,\n\t      callback: this.handleRequest,\n", "      userAgent: 'node-crawler',\n\t    });\n\t  }\n\t  /* `handleRequest` is a method that handles the response of a web page request made by the `crawler`\n\tobject. It takes in three parameters: `error`, `res`, and `done`. */\n\t  handleRequest = (error: Error | null, res: CrawlerRequestResponse, done: () => void) => {\n\t    if (error) {\n\t      stderr.write(error.message);\n\t      done();\n\t      return;\n", "    }\n\t    const $ = cheerio.load(res.body);\n\t    // Remove obviously superfluous elements\n\t    $('script').remove();\n\t    $('header').remove();\n\t    $('nav').remove();\n\t    $('style').remove();\n\t    $('img').remove();\n\t    $('svg').remove();\n\t    const title = $('title').text() || '';\n", "    const text = $(this.selector).text();\n\t    // const text = turndownService.turndown(html || '');\n\t    const page: Page = {\n\t      url: res.request.uri.href,\n\t      text,\n\t      title,\n\t    };\n\t    if (text.length > this.textLengthMinimum) {\n\t      this.pages.push(page);\n\t      this.progressCallback(this.count + 1, this.pages.length, res.request.uri.href);\n", "    }\n\t    $('a').each((_i: number, elem: cheerio.Element) => {\n\t      if (this.count >= this.limit) {\n\t        return false; // Stop iterating once the limit is reached\n\t      }\n\t      const href = $(elem).attr('href')?.split('#')[0];\n\t      const uri = res.request.uri.href;\n\t      const url = href && resolveURL(uri, href);\n\t      // crawl more\n\t      if (url && this.urls.some((u) => url.includes(u))) {\n", "        this.crawler.queue(url);\n\t        this.count += 1;\n\t      }\n\t      return true; // Continue iterating when the limit is not reached\n\t    });\n\t    done();\n\t  };\n\t  start = async () => {\n\t    this.pages = [];\n\t    return new Promise((resolve) => {\n", "      this.crawler.on('drain', () => {\n\t        resolve(this.pages);\n\t      });\n\t      this.urls.forEach((url) => {\n\t        this.crawler.queue(url);\n\t      });\n\t    });\n\t  };\n\t}\n\texport default WebCrawler;\n"]}
{"filename": "src/lib/memoryManager.ts", "chunked_list": ["import chalk from 'chalk';\n\timport { HNSWLib } from 'langchain/vectorstores/hnswlib';\n\timport fs from 'fs/promises';\n\timport path from 'path';\n\timport { stdout as output } from 'node:process';\n\timport { OpenAIEmbeddings } from 'langchain/embeddings/openai';\n\timport { Document } from 'langchain/document';\n\timport { BufferWindowMemory } from 'langchain/memory';\n\timport { getProjectRoot } from '../config/index.js';\n\tconst projectRootDir = getProjectRoot();\n", "const memoryDirectory = path.join(projectRootDir, process.env.MEMORY_VECTOR_STORE_DIR || 'memory');\n\tlet memoryVectorStore: HNSWLib;\n\ttry {\n\t  memoryVectorStore = await HNSWLib.load(memoryDirectory, new OpenAIEmbeddings());\n\t} catch {\n\t  output.write(`${chalk.blue(`Creating a new memory vector store index in the ${memoryDirectory} directory`)}\\n`);\n\t  memoryVectorStore = new HNSWLib(new OpenAIEmbeddings(), {\n\t    space: 'cosine',\n\t    numDimensions: 1536,\n\t  });\n", "}\n\tconst bufferWindowMemory = new BufferWindowMemory({\n\t  returnMessages: false,\n\t  memoryKey: 'immediate_history',\n\t  inputKey: 'input',\n\t  k: 2,\n\t});\n\tconst memoryWrapper = {\n\t  vectorStoreInstance: memoryVectorStore,\n\t};\n", "async function getMemoryVectorStore() {\n\t  return memoryWrapper.vectorStoreInstance;\n\t}\n\tfunction getBufferWindowMemory() {\n\t  return bufferWindowMemory;\n\t}\n\tasync function saveMemoryVectorStore() {\n\t  await memoryWrapper.vectorStoreInstance.save(memoryDirectory);\n\t}\n\tasync function addDocumentsToMemoryVectorStore(\n", "  documents: Array<{ content: string; metadataType: string }>\n\t): Promise<void> {\n\t  const formattedDocuments = documents.map(\n\t    (doc) => new Document({ pageContent: doc.content, metadata: { type: doc.metadataType } })\n\t  );\n\t  await memoryWrapper.vectorStoreInstance.addDocuments(formattedDocuments);\n\t  await saveMemoryVectorStore();\n\t}\n\tfunction resetBufferWindowMemory() {\n\t  bufferWindowMemory.clear();\n", "}\n\tasync function deleteMemoryDirectory() {\n\t  try {\n\t    const files = await fs.readdir(memoryDirectory);\n\t    const deletePromises = files.map((file) => fs.unlink(path.join(memoryDirectory, file)));\n\t    await Promise.all(deletePromises);\n\t    return `All files in the memory directory have been deleted.`;\n\t  } catch (error) {\n\t    if (error instanceof Error) {\n\t      return chalk.red(`All files in the memory directory have been deleted: ${error.message}`);\n", "    }\n\t    return chalk.red(`All files in the memory directory have been deleted: ${error}`);\n\t  }\n\t}\n\tasync function resetMemoryVectorStore(onReset: (newMemoryVectorStore: HNSWLib) => void) {\n\t  const newMemoryVectorStore = new HNSWLib(new OpenAIEmbeddings(), {\n\t    space: 'cosine',\n\t    numDimensions: 1536,\n\t  });\n\t  await deleteMemoryDirectory();\n", "  onReset(newMemoryVectorStore);\n\t}\n\tfunction setMemoryVectorStore(newMemoryVectorStore: HNSWLib) {\n\t  memoryWrapper.vectorStoreInstance = newMemoryVectorStore;\n\t}\n\texport {\n\t  getMemoryVectorStore,\n\t  setMemoryVectorStore,\n\t  addDocumentsToMemoryVectorStore,\n\t  resetMemoryVectorStore,\n", "  getBufferWindowMemory,\n\t  resetBufferWindowMemory,\n\t};\n"]}
