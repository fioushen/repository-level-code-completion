{"filename": "vitest.config.ts", "chunked_list": ["import path from \"node:path\";\n\timport { configDefaults, defineConfig } from \"vitest/config\";\n\texport default defineConfig({\n\t  test: {\n\t    exclude: [...configDefaults.exclude],\n\t  },\n\t  resolve: {\n\t    alias: {\n\t      \"~\": path.resolve(__dirname, \"./src\"),\n\t    },\n", "  },\n\t});\n"]}
{"filename": "tsup.config.ts", "chunked_list": ["import { defineConfig } from \"tsup\";\n\texport default defineConfig({\n\t  entry: [\"src/index.ts\"],\n\t  format: [\"esm\"],\n\t  /**\n\t   * The `isolate` binary is an ES module. It is required to have the `.mjs`\n\t   * file extension, otherwise a non-ESM workspace will try to load it as\n\t   * commonJS. For details on this read [this article from Alex\n\t   * Rauschmayer](https://exploringjs.com/nodejs-shell-scripting/ch_creating-shell-scripts.html#node.*\n\t   * js-esm-modules-as-standalone-shell-scripts-on-unix)\n", "   */\n\t  outExtension() {\n\t    return {\n\t      js: `.mjs`,\n\t    };\n\t  },\n\t  target: \"esnext\",\n\t  sourcemap: true,\n\t  dts: true,\n\t  clean: true,\n", "});\n"]}
{"filename": "src/index.ts", "chunked_list": ["#!/usr/bin/env node\n\t/**\n\t * For PNPM the hashbang at the top of the script was not required, but Yarn 3\n\t * did not seem to execute without it.\n\t */\n\t/**\n\t * A word about used terminology:\n\t *\n\t * The various package managers, while being very similar, seem to use a\n\t * different definition for the term \"workspace\". If you want to read the code\n", " * it might be good to know that I consider the workspace to be the monorepo\n\t * itself, in other words, the overall structure that holds all the packages.\n\t */\n\timport fs from \"fs-extra\";\n\timport assert from \"node:assert\";\n\timport path from \"node:path\";\n\timport sourceMaps from \"source-map-support\";\n\timport {\n\t  PackageManifest,\n\t  adaptManifestFiles,\n", "  adaptTargetPackageManifest,\n\t  createPackagesRegistry,\n\t  detectPackageManager,\n\t  getBuildOutputDir,\n\t  getConfig,\n\t  listLocalDependencies,\n\t  packDependencies,\n\t  processBuildOutputFiles,\n\t  processLockfile,\n\t  unpackDependencies,\n", "} from \"~/helpers\";\n\timport {\n\t  createLogger,\n\t  getDirname,\n\t  getRootRelativePath,\n\t  readTypedJson,\n\t} from \"~/utils\";\n\tconst config = getConfig();\n\tconst log = createLogger(config.logLevel);\n\tsourceMaps.install();\n", "async function start() {\n\t  const __dirname = getDirname(import.meta.url);\n\t  const thisPackageManifest = await readTypedJson<PackageManifest>(\n\t    path.join(path.join(__dirname, \"..\", \"package.json\"))\n\t  );\n\t  log.debug(\"Running isolate-package version\", thisPackageManifest.version);\n\t  /**\n\t   * If a targetPackagePath is set, we assume the configuration lives in the\n\t   * root of the workspace. If targetPackagePath is undefined (the default), we\n\t   * assume that the configuration lives in the target package directory.\n", "   */\n\t  const targetPackageDir = config.targetPackagePath\n\t    ? path.join(process.cwd(), config.targetPackagePath)\n\t    : process.cwd();\n\t  /**\n\t   * We want a trailing slash here. Functionally it doesn't matter, but it makes\n\t   * the relative paths more correct in the debug output.\n\t   */\n\t  const workspaceRootDir = config.targetPackagePath\n\t    ? process.cwd()\n", "    : path.join(targetPackageDir, config.workspaceRoot);\n\t  const buildOutputDir = await getBuildOutputDir(targetPackageDir);\n\t  assert(\n\t    fs.existsSync(buildOutputDir),\n\t    `Failed to find build output path at ${buildOutputDir}. Please make sure you build the source before isolating it.`\n\t  );\n\t  log.debug(\"Workspace root resolved to\", workspaceRootDir);\n\t  log.debug(\n\t    \"Isolate target package\",\n\t    getRootRelativePath(targetPackageDir, workspaceRootDir)\n", "  );\n\t  const isolateDir = path.join(targetPackageDir, config.isolateDirName);\n\t  log.debug(\n\t    \"Isolate output directory\",\n\t    getRootRelativePath(isolateDir, workspaceRootDir)\n\t  );\n\t  if (fs.existsSync(isolateDir)) {\n\t    await fs.remove(isolateDir);\n\t    log.debug(\"Cleaned the existing isolate output directory\");\n\t  }\n", "  await fs.ensureDir(isolateDir);\n\t  const tmpDir = path.join(isolateDir, \"__tmp\");\n\t  await fs.ensureDir(tmpDir);\n\t  const targetPackageManifest = await readTypedJson<PackageManifest>(\n\t    path.join(targetPackageDir, \"package.json\")\n\t  );\n\t  const packageManager = detectPackageManager(workspaceRootDir);\n\t  log.debug(\n\t    \"Detected package manager\",\n\t    packageManager.name,\n", "    packageManager.version\n\t  );\n\t  /**\n\t   * Disable lock files for PNPM because they are not yet supported.\n\t   */\n\t  if (packageManager.name === \"pnpm\") {\n\t    config.excludeLockfile = true;\n\t  }\n\t  /**\n\t   * Build a packages registry so we can find the workspace packages by name and\n", "   * have access to their manifest files and relative paths.\n\t   */\n\t  const packagesRegistry = await createPackagesRegistry(\n\t    workspaceRootDir,\n\t    config.workspacePackages\n\t  );\n\t  const localDependencies = listLocalDependencies(\n\t    targetPackageManifest,\n\t    packagesRegistry,\n\t    {\n", "      includeDevDependencies: config.includeDevDependencies,\n\t    }\n\t  );\n\t  const packedFilesByName = await packDependencies({\n\t    localDependencies,\n\t    packagesRegistry,\n\t    packDestinationDir: tmpDir,\n\t  });\n\t  await unpackDependencies(\n\t    packedFilesByName,\n", "    packagesRegistry,\n\t    tmpDir,\n\t    isolateDir\n\t  );\n\t  /**\n\t   * Adapt the manifest files for all the unpacked local dependencies\n\t   */\n\t  await adaptManifestFiles(localDependencies, packagesRegistry, isolateDir);\n\t  /**\n\t   * Pack the target package directory, and unpack it in the isolate location\n", "   */\n\t  await processBuildOutputFiles({\n\t    targetPackageDir,\n\t    tmpDir,\n\t    isolateDir,\n\t  });\n\t  /**\n\t   * Copy the target manifest file to the isolate location and adapt its\n\t   * workspace dependencies to point to the isolated packages.\n\t   */\n", "  await adaptTargetPackageManifest(\n\t    targetPackageManifest,\n\t    packagesRegistry,\n\t    isolateDir\n\t  );\n\t  if (config.excludeLockfile) {\n\t    log.warn(\"Excluding the lockfile from the isolate output\");\n\t  } else {\n\t    /**\n\t     * Copy and adapt the lockfile\n", "     */\n\t    await processLockfile({\n\t      workspaceRootDir,\n\t      targetPackageName: targetPackageManifest.name,\n\t      isolateDir,\n\t      packagesRegistry,\n\t    });\n\t  }\n\t  /**\n\t   * If there is an .npmrc file in the workspace root, copy it to the\n", "   * isolate because the settings there could affect how the lockfile is\n\t   * resolved. Note that .npmrc is used by both NPM and PNPM for configuration.\n\t   *\n\t   * See also: https://pnpm.io/npmrc\n\t   */\n\t  const npmrcPath = path.join(workspaceRootDir, \".npmrc\");\n\t  if (fs.existsSync(npmrcPath)) {\n\t    fs.copyFileSync(npmrcPath, path.join(isolateDir, \".npmrc\"));\n\t    log.debug(\"Copied .npmrc file to the isolate output\");\n\t  }\n", "  /**\n\t   * Clean up. Only so this in the happy path, so we can look at the temp folder\n\t   * when thing go wrong.\n\t   */\n\t  log.debug(\n\t    \"Deleting temp directory\",\n\t    getRootRelativePath(tmpDir, workspaceRootDir)\n\t  );\n\t  await fs.remove(tmpDir);\n\t  log.info(\"Isolate completed at\", isolateDir);\n", "}\n\tstart().catch((err) => {\n\t  if (err instanceof Error) {\n\t    log.error(err.stack);\n\t    process.exit(1);\n\t  } else {\n\t    console.error(err);\n\t  }\n\t});\n\tprocess.on(\"unhandledRejection\", log.error);\n"]}
{"filename": "src/utils/inspect-value.ts", "chunked_list": ["import { inspect } from \"node:util\";\n\timport { JsonValue } from \"type-fest\";\n\texport function inspectValue(value: JsonValue) {\n\t  return inspect(value, false, 4, true);\n\t}\n"]}
{"filename": "src/utils/yaml.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport yaml from \"yaml\";\n\timport { getErrorMessage } from \"./get-error-message\";\n\texport function readTypedYamlSync<T>(filePath: string) {\n\t  try {\n\t    const rawContent = fs.readFileSync(filePath, \"utf-8\");\n\t    const data = yaml.parse(rawContent);\n\t    /**\n\t     * @TODO add some zod validation maybe\n\t     */\n", "    return data as T;\n\t  } catch (err) {\n\t    throw new Error(\n\t      `Failed to read YAML from ${filePath}: ${getErrorMessage(err)}`\n\t    );\n\t  }\n\t}\n\texport function writeTypedYamlSync<T>(filePath: string, content: T) {\n\t  /**\n\t   * @TODO add some zod validation maybe\n", "   */\n\t  fs.writeFileSync(filePath, yaml.stringify(content), \"utf-8\");\n\t}\n"]}
{"filename": "src/utils/get-error-message.ts", "chunked_list": ["type ErrorWithMessage = {\n\t  message: string;\n\t};\n\texport function getErrorMessage(error: unknown) {\n\t  return toErrorWithMessage(error).message;\n\t}\n\tfunction isErrorWithMessage(error: unknown): error is ErrorWithMessage {\n\t  return typeof error === \"object\" && error !== null && \"message\" in error;\n\t}\n\tfunction toErrorWithMessage(maybeError: unknown): ErrorWithMessage {\n", "  if (isErrorWithMessage(maybeError)) return maybeError;\n\t  try {\n\t    return new Error(JSON.stringify(maybeError));\n\t  } catch {\n\t    /**\n\t     * Fallback in case thereâ€™s an error stringifying the maybeError\n\t     * like with circular references.\n\t     */\n\t    return new Error(String(maybeError));\n\t  }\n", "}\n"]}
{"filename": "src/utils/pack.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport { exec } from \"node:child_process\";\n\timport path from \"node:path\";\n\timport { getConfig } from \"~/helpers\";\n\timport { createLogger } from \"./logger\";\n\texport async function pack(\n\t  srcDir: string,\n\t  dstDir: string,\n\t  usePnpmPack = false\n\t) {\n", "  const execOptions = {\n\t    maxBuffer: 10 * 1024 * 1024,\n\t  };\n\t  const log = createLogger(getConfig().logLevel);\n\t  const previousCwd = process.cwd();\n\t  process.chdir(srcDir);\n\t  /**\n\t   * PNPM pack seems to be a lot faster than NPM pack, so when PNPM is detected\n\t   * we use that instead.\n\t   */\n", "  const stdout = usePnpmPack\n\t    ? await new Promise<string>((resolve, reject) => {\n\t        exec(\n\t          `pnpm pack --pack-destination ${dstDir}`,\n\t          execOptions,\n\t          (err, stdout, stderr) => {\n\t            if (err) {\n\t              log.error(stderr);\n\t              return reject(err);\n\t            }\n", "            resolve(stdout);\n\t          }\n\t        );\n\t      })\n\t    : await new Promise<string>((resolve, reject) => {\n\t        exec(\n\t          `npm pack --pack-destination ${dstDir}`,\n\t          execOptions,\n\t          (err, stdout) => {\n\t            if (err) {\n", "              return reject(err);\n\t            }\n\t            resolve(stdout);\n\t          }\n\t        );\n\t      });\n\t  const fileName = path.basename(stdout.trim());\n\t  const filePath = path.join(dstDir, fileName);\n\t  if (!fs.existsSync(filePath)) {\n\t    log.error(\n", "      `The response from pack could not be resolved to an existing file: ${filePath}`\n\t    );\n\t  } else {\n\t    log.debug(`Packed (temp)/${fileName}`);\n\t  }\n\t  process.chdir(previousCwd);\n\t  /**\n\t   * Return the path anyway even if it doesn't validate. A later stage will wait\n\t   * for the file to occur still. Not sure if this makes sense. Maybe we should\n\t   * stop at the validation error...\n", "   */\n\t  return filePath;\n\t}\n"]}
{"filename": "src/utils/logger.ts", "chunked_list": ["import chalk from \"chalk\";\n\timport { IsolateConfigResolved } from \"~/helpers\";\n\texport type Logger = {\n\t  debug(...args: any[]): void;\n\t  info(...args: any[]): void;\n\t  warn(...args: any[]): void;\n\t  error(...args: any[]): void;\n\t};\n\texport function createLogger(\n\t  logLevel: IsolateConfigResolved[\"logLevel\"]\n", "): Logger {\n\t  return {\n\t    debug(...args: any[]) {\n\t      if (logLevel === \"debug\") {\n\t        console.log(chalk.blue(\"debug\"), ...args);\n\t      }\n\t    },\n\t    info(...args: any[]) {\n\t      if (logLevel === \"debug\" || logLevel === \"info\") {\n\t        console.log(chalk.green(\"info\"), ...args);\n", "      }\n\t    },\n\t    warn(...args: any[]) {\n\t      if (logLevel === \"debug\" || logLevel === \"info\" || logLevel === \"warn\") {\n\t        console.log(chalk.yellow(\"warning\"), ...args);\n\t      }\n\t    },\n\t    error(...args: any[]) {\n\t      console.log(chalk.red(\"error\"), ...args);\n\t    },\n", "  };\n\t}\n"]}
{"filename": "src/utils/index.ts", "chunked_list": ["export * from \"./filter-object-undefined\";\n\texport * from \"./get-dirname\";\n\texport * from \"./get-error-message\";\n\texport * from \"./get-relative-path\";\n\texport * from \"./inspect-value\";\n\texport * from \"./json\";\n\texport * from \"./logger\";\n\texport * from \"./pack\";\n\texport * from \"./unpack\";\n\texport * from \"./yaml\";\n"]}
{"filename": "src/utils/json.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport stripJsonComments from \"strip-json-comments\";\n\timport { getErrorMessage } from \"./get-error-message\";\n\t/**\n\t * @TODO pass in zod schema and validate\n\t */\n\texport function readTypedJsonSync<T>(filePath: string) {\n\t  try {\n\t    const rawContent = fs.readFileSync(filePath, \"utf-8\");\n\t    const data = JSON.parse(stripJsonComments(rawContent)) as T;\n", "    return data;\n\t  } catch (err) {\n\t    throw new Error(\n\t      `Failed to read JSON from ${filePath}: ${getErrorMessage(err)}`\n\t    );\n\t  }\n\t}\n\texport async function readTypedJson<T>(filePath: string) {\n\t  try {\n\t    const rawContent = await fs.readFile(filePath, \"utf-8\");\n", "    const data = JSON.parse(rawContent) as T;\n\t    return data;\n\t  } catch (err) {\n\t    throw new Error(\n\t      `Failed to read JSON from ${filePath}: ${getErrorMessage(err)}`\n\t    );\n\t  }\n\t}\n"]}
{"filename": "src/utils/filter-object-undefined.test.ts", "chunked_list": ["import { describe, expect, it } from \"vitest\";\n\timport { filterObjectUndefined } from \"./filter-object-undefined\";\n\tdescribe(\"filterObjectUndefined\", () => {\n\t  it(\"should filter out undefined values\", () => {\n\t    expect(\n\t      filterObjectUndefined({\n\t        a: \"a\",\n\t        b: undefined,\n\t        c: \"c\",\n\t      })\n", "    ).toEqual({\n\t      a: \"a\",\n\t      c: \"c\",\n\t    });\n\t  });\n\t});\n"]}
{"filename": "src/utils/get-dirname.ts", "chunked_list": ["import { fileURLToPath } from \"url\";\n\t/**\n\t * Calling context should pass in import.meta.url and the function will return\n\t * the equivalent of __dirname in Node/CommonJs.\n\t */\n\texport function getDirname(importMetaUrl: string) {\n\t  return fileURLToPath(new URL(\".\", importMetaUrl));\n\t}\n"]}
{"filename": "src/utils/unpack.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport tar from \"tar-fs\";\n\timport { createGunzip } from \"zlib\";\n\texport async function unpack(filePath: string, unpackDir: string) {\n\t  await new Promise<void>((resolve, reject) => {\n\t    fs.createReadStream(filePath)\n\t      .pipe(createGunzip())\n\t      .pipe(tar.extract(unpackDir))\n\t      .on(\"finish\", () => resolve())\n\t      .on(\"error\", (err) => reject(err));\n", "  });\n\t}\n"]}
{"filename": "src/utils/get-relative-path.ts", "chunked_list": ["export function getRootRelativePath(path: string, rootPath: string) {\n\t  const strippedPath = path.replace(rootPath, \"\");\n\t  return strippedPath.startsWith(\"/\")\n\t    ? `(root)${strippedPath}`\n\t    : `(root)/${strippedPath}`;\n\t}\n\texport function getIsolateRelativePath(path: string, isolatePath: string) {\n\t  const strippedPath = path.replace(isolatePath, \"\");\n\t  return strippedPath.startsWith(\"/\")\n\t    ? `(isolate)${strippedPath}`\n", "    : `(isolate)/${strippedPath}`;\n\t}\n"]}
{"filename": "src/utils/filter-object-undefined.ts", "chunked_list": ["export function filterObjectUndefined(object: Record<string, unknown>) {\n\t  return Object.fromEntries(\n\t    Object.entries(object).filter(([_, value]) => value !== undefined)\n\t  );\n\t}\n"]}
{"filename": "src/helpers/config.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport { isEmpty } from \"lodash-es\";\n\timport path from \"node:path\";\n\timport { createLogger, inspectValue, readTypedJsonSync } from \"~/utils\";\n\texport type IsolateConfigResolved = {\n\t  buildDirName?: string;\n\t  includeDevDependencies: boolean;\n\t  isolateDirName: string;\n\t  logLevel: \"info\" | \"debug\" | \"warn\" | \"error\";\n\t  targetPackagePath?: string;\n", "  tsconfigPath: string;\n\t  workspacePackages?: string[];\n\t  workspaceRoot: string;\n\t  excludeLockfile: boolean;\n\t  avoidPnpmPack: boolean;\n\t};\n\texport type IsolateConfig = Partial<IsolateConfigResolved>;\n\tconst configDefaults: IsolateConfigResolved = {\n\t  buildDirName: undefined,\n\t  includeDevDependencies: false,\n", "  isolateDirName: \"isolate\",\n\t  logLevel: \"info\",\n\t  targetPackagePath: undefined,\n\t  tsconfigPath: \"./tsconfig.json\",\n\t  workspacePackages: undefined,\n\t  workspaceRoot: \"../..\",\n\t  excludeLockfile: false,\n\t  avoidPnpmPack: false,\n\t};\n\t/**\n", " * Only initialize the configuration once, and keeping it here for subsequent\n\t * calls to getConfig.\n\t */\n\tlet __config: IsolateConfigResolved | undefined;\n\tconst validConfigKeys = Object.keys(configDefaults);\n\tconst CONFIG_FILE_NAME = \"isolate.config.json\";\n\ttype LogLevel = IsolateConfigResolved[\"logLevel\"];\n\texport function getConfig(): IsolateConfigResolved {\n\t  if (__config) {\n\t    return __config;\n", "  }\n\t  /**\n\t   * Since the logLevel is set via config we can't use it to determine if we\n\t   * should output verbose logging as part of the config loading process. Using\n\t   * the env var ISOLATE_CONFIG_LOG_LEVEL you have the option to log debug\n\t   * output.\n\t   */\n\t  const log = createLogger(\n\t    (process.env.ISOLATE_CONFIG_LOG_LEVEL as LogLevel) ?? \"warn\"\n\t  );\n", "  const configFilePath = path.join(process.cwd(), CONFIG_FILE_NAME);\n\t  log.debug(`Attempting to load config from ${configFilePath}`);\n\t  const configFromFile = fs.existsSync(configFilePath)\n\t    ? readTypedJsonSync<IsolateConfig>(configFilePath)\n\t    : {};\n\t  const foreignKeys = Object.keys(configFromFile).filter(\n\t    (key) => !validConfigKeys.includes(key)\n\t  );\n\t  if (!isEmpty(foreignKeys)) {\n\t    log.warn(`Found invalid config settings:`, foreignKeys.join(\", \"));\n", "  }\n\t  const config = Object.assign(\n\t    {},\n\t    configDefaults,\n\t    configFromFile\n\t  ) satisfies IsolateConfigResolved;\n\t  log.debug(\"Using configuration:\", inspectValue(config));\n\t  __config = config;\n\t  return config;\n\t}\n"]}
{"filename": "src/helpers/adapt-manifest-workspace-deps.ts", "chunked_list": ["import { omit } from \"lodash-es\";\n\timport { filterObjectUndefined } from \"~/utils\";\n\timport { PackageManifest, PackagesRegistry, patchWorkspaceEntries } from \".\";\n\texport function adaptManifestWorkspaceDeps(\n\t  {\n\t    manifest,\n\t    packagesRegistry,\n\t    parentRootRelativeDir,\n\t  }: {\n\t    manifest: PackageManifest;\n", "    packagesRegistry: PackagesRegistry;\n\t    parentRootRelativeDir?: string;\n\t  },\n\t  opts: { includeDevDependencies?: boolean } = {}\n\t): PackageManifest {\n\t  return Object.assign(\n\t    omit(manifest, [\"devDependencies\"]),\n\t    filterObjectUndefined({\n\t      dependencies: manifest.dependencies\n\t        ? patchWorkspaceEntries(\n", "            manifest.dependencies,\n\t            packagesRegistry,\n\t            parentRootRelativeDir\n\t          )\n\t        : undefined,\n\t      devDependencies:\n\t        opts.includeDevDependencies && manifest.devDependencies\n\t          ? patchWorkspaceEntries(\n\t              manifest.devDependencies,\n\t              packagesRegistry,\n", "              parentRootRelativeDir\n\t            )\n\t          : undefined,\n\t    })\n\t  );\n\t}\n"]}
{"filename": "src/helpers/unpack-dependencies.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport path, { join } from \"node:path\";\n\timport { getIsolateRelativePath } from \"~/utils\";\n\timport { createLogger } from \"~/utils/logger\";\n\timport { PackagesRegistry, getConfig } from \".\";\n\timport { unpack } from \"../utils/unpack\";\n\texport async function unpackDependencies(\n\t  packedFilesByName: Record<string, string>,\n\t  packagesRegistry: PackagesRegistry,\n\t  tmpDir: string,\n", "  isolateDir: string\n\t) {\n\t  const log = createLogger(getConfig().logLevel);\n\t  await Promise.all(\n\t    Object.entries(packedFilesByName).map(async ([packageName, filePath]) => {\n\t      const dir = packagesRegistry[packageName].rootRelativeDir;\n\t      const unpackDir = join(tmpDir, dir);\n\t      log.debug(\"Unpacking\", `(temp)/${path.basename(filePath)}`);\n\t      await unpack(filePath, unpackDir);\n\t      const destinationDir = join(isolateDir, dir);\n", "      await fs.ensureDir(destinationDir);\n\t      await fs.move(join(unpackDir, \"package\"), destinationDir, {\n\t        overwrite: true,\n\t      });\n\t      log.debug(\n\t        `Moved package files to ${getIsolateRelativePath(\n\t          destinationDir,\n\t          isolateDir\n\t        )}`\n\t      );\n", "    })\n\t  );\n\t}\n"]}
{"filename": "src/helpers/detect-package-manager.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport assert from \"node:assert\";\n\timport { execSync } from \"node:child_process\";\n\timport path from \"node:path\";\n\timport { createLogger, readTypedJsonSync } from \"~/utils\";\n\timport { getConfig } from \"./config\";\n\timport { PackageManifest } from \"./create-packages-registry\";\n\timport { getLockfileFileName } from \"./process-lockfile\";\n\tconst supportedPackageManagerNames = [\"pnpm\", \"yarn\", \"npm\"] as const;\n\texport type PackageManagerName = (typeof supportedPackageManagerNames)[number];\n", "export type PackageManager = {\n\t  name: PackageManagerName;\n\t  version: string;\n\t};\n\tlet packageManager: PackageManager | undefined;\n\t/**\n\t * First we check if the package manager is declared in the manifest. If it is,\n\t * we get the name and version from there. Otherwise we'll search for the\n\t * different lockfiles and ask the OS to report the installed version.\n\t */\n", "export function detectPackageManager(workspaceRoot: string): PackageManager {\n\t  /**\n\t   * Disable infer from manifest for now. I doubt it is useful after all but\n\t   * I'll keep the code as a reminder.\n\t   */\n\t  // packageManager =\n\t  //   inferFromManifest(workspaceRoot) ?? inferFromFiles(workspaceRoot);\n\t  packageManager = inferFromFiles(workspaceRoot);\n\t  return packageManager;\n\t}\n", "function inferFromManifest(workspaceRoot: string) {\n\t  const log = createLogger(getConfig().logLevel);\n\t  const rootManifest = readTypedJsonSync<PackageManifest>(\n\t    path.join(workspaceRoot, \"package.json\")\n\t  );\n\t  if (!rootManifest.packageManager) {\n\t    log.debug(\"No packageManager field found in root manifest\");\n\t    return;\n\t  }\n\t  const [name, version = \"*\"] = rootManifest.packageManager.split(\"@\") as [\n", "    PackageManagerName,\n\t    string,\n\t  ];\n\t  assert(\n\t    supportedPackageManagerNames.includes(name),\n\t    `Package manager \"${name}\" is not currently supported`\n\t  );\n\t  const lockfileName = getLockfileFileName(name);\n\t  assert(\n\t    fs.existsSync(path.join(workspaceRoot, lockfileName)),\n", "    `Manifest declares ${name} to be the packageManager, but failed to find ${lockfileName} in workspace root`\n\t  );\n\t  return { name, version };\n\t}\n\tfunction inferFromFiles(workspaceRoot: string): PackageManager {\n\t  for (const name of supportedPackageManagerNames) {\n\t    const lockfileName = getLockfileFileName(name);\n\t    if (fs.existsSync(path.join(workspaceRoot, lockfileName))) {\n\t      return { name, version: getVersion(name) };\n\t    }\n", "  }\n\t  /**\n\t   * If no lockfile was found, it could be that there is an npm shrinkwrap file.\n\t   */\n\t  if (fs.existsSync(path.join(workspaceRoot, \"npm-shrinkwrap.json\"))) {\n\t    return { name: \"npm\", version: getVersion(\"npm\") };\n\t  }\n\t  throw new Error(`Failed to detect package manager`);\n\t}\n\tfunction getVersion(packageManagerName: PackageManagerName): string {\n", "  const buffer = execSync(`${packageManagerName} --version`);\n\t  return buffer.toString().trim();\n\t}\n\texport function usePackageManager() {\n\t  if (!packageManager) {\n\t    throw Error(\n\t      \"No package manager detected. Make sure to call detectPackageManager() before usePackageManager()\"\n\t    );\n\t  }\n\t  return packageManager;\n", "}\n"]}
{"filename": "src/helpers/patch-workspace-entries.ts", "chunked_list": ["import path from \"node:path\";\n\timport { createLogger } from \"~/utils\";\n\timport { getConfig } from \"./config\";\n\timport { PackagesRegistry } from \"./create-packages-registry\";\n\texport function patchWorkspaceEntries(\n\t  dependencies: Record<string, string>,\n\t  packagesRegistry: PackagesRegistry,\n\t  parentRootRelativeDir?: string\n\t) {\n\t  const log = createLogger(getConfig().logLevel);\n", "  const allWorkspacePackageNames = Object.keys(packagesRegistry);\n\t  return Object.fromEntries(\n\t    Object.entries(dependencies).map(([key, value]) => {\n\t      if (allWorkspacePackageNames.includes(key)) {\n\t        const def = packagesRegistry[key];\n\t        /**\n\t         * When nested shared dependencies are used (local deps linking to other\n\t         * local deps), the parentRootRelativeDir will be passed in, and we\n\t         * store the relative path to the isolate/packages directory, as is\n\t         * required by some package managers.\n", "         *\n\t         * For consistency we also write the other file paths starting with\n\t         * ./, but it doesn't seem to be necessary for any package manager.\n\t         */\n\t        const relativePath = parentRootRelativeDir\n\t          ? path.relative(parentRootRelativeDir, `./${def.rootRelativeDir}`)\n\t          : `./${def.rootRelativeDir}`;\n\t        const linkPath = `file:${relativePath}`;\n\t        log.debug(`Linking dependency ${key} to ${linkPath}`);\n\t        return [key, linkPath];\n", "      } else {\n\t        return [key, value];\n\t      }\n\t    })\n\t  );\n\t}\n"]}
{"filename": "src/helpers/adapt-target-package-manifest.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport path from \"node:path\";\n\timport {\n\t  PackageManifest,\n\t  PackagesRegistry,\n\t  adaptManifestWorkspaceDeps,\n\t  getConfig,\n\t} from \"~/helpers\";\n\texport async function adaptTargetPackageManifest(\n\t  manifest: PackageManifest,\n", "  packagesRegistry: PackagesRegistry,\n\t  isolateDir: string\n\t) {\n\t  const outputManifest = adaptManifestWorkspaceDeps(\n\t    {\n\t      manifest,\n\t      packagesRegistry,\n\t    },\n\t    { includeDevDependencies: getConfig().includeDevDependencies }\n\t  );\n", "  await fs.writeFile(\n\t    path.join(isolateDir, \"package.json\"),\n\t    JSON.stringify(outputManifest, null, 2)\n\t  );\n\t}\n"]}
{"filename": "src/helpers/process-lockfile.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport assert from \"node:assert\";\n\timport path from \"node:path\";\n\timport { createLogger, readTypedYamlSync, writeTypedYamlSync } from \"~/utils\";\n\timport { getConfig } from \"./config\";\n\timport { PackagesRegistry } from \"./create-packages-registry\";\n\timport {\n\t  PackageManagerName,\n\t  usePackageManager,\n\t} from \"./detect-package-manager\";\n", "type PackagePath = string;\n\ttype PnpmLockfile = {\n\t  lockfileVersion: string;\n\t  importers: Record<\n\t    PackagePath,\n\t    {\n\t      dependencies?: Record<string, unknown>;\n\t      devDependencies?: Record<string, unknown>;\n\t    }\n\t  >;\n", "};\n\texport function getLockfileFileName(name: PackageManagerName) {\n\t  switch (name) {\n\t    case \"pnpm\":\n\t      return \"pnpm-lock.yaml\";\n\t    case \"yarn\":\n\t      return \"yarn.lock\";\n\t    case \"npm\":\n\t      return \"package-lock.json\";\n\t  }\n", "}\n\t/**\n\t * Adapt the lockfile and write it to the isolate directory. Because we keep the\n\t * structure of packages in the isolate directory the same as they were in the\n\t * monorepo, the lockfile is largely still correct. The only things that need to\n\t * be done is to remove the root dependencies and devDependencies, and rename\n\t * the path to the target package to act as the new root.\n\t */\n\texport function processLockfile({\n\t  workspaceRootDir,\n", "  targetPackageName,\n\t  packagesRegistry,\n\t  isolateDir,\n\t}: {\n\t  workspaceRootDir: string;\n\t  targetPackageName: string;\n\t  packagesRegistry: PackagesRegistry;\n\t  isolateDir: string;\n\t}) {\n\t  const log = createLogger(getConfig().logLevel);\n", "  const targetPackageRelativeDir =\n\t    packagesRegistry[targetPackageName].rootRelativeDir;\n\t  const { name } = usePackageManager();\n\t  const fileName = getLockfileFileName(name);\n\t  const lockfileSrcPath = path.join(workspaceRootDir, fileName);\n\t  const lockfileDstPath = path.join(isolateDir, fileName);\n\t  switch (name) {\n\t    case \"npm\": {\n\t      /**\n\t       * If there is a shrinkwrap file we copy that instead of the lockfile\n", "       */\n\t      const shrinkwrapSrcPath = path.join(\n\t        workspaceRootDir,\n\t        \"npm-shrinkwrap.json\"\n\t      );\n\t      const shrinkwrapDstPath = path.join(isolateDir, \"npm-shrinkwrap.json\");\n\t      if (fs.existsSync(shrinkwrapSrcPath)) {\n\t        fs.copyFileSync(shrinkwrapSrcPath, shrinkwrapDstPath);\n\t        log.debug(\"Copied shrinkwrap to\", shrinkwrapDstPath);\n\t      } else {\n", "        fs.copyFileSync(lockfileSrcPath, lockfileDstPath);\n\t        log.debug(\"Copied lockfile to\", lockfileDstPath);\n\t      }\n\t      return;\n\t    }\n\t    case \"yarn\": {\n\t      fs.copyFileSync(lockfileSrcPath, lockfileDstPath);\n\t      log.debug(\"Copied lockfile to\", lockfileDstPath);\n\t      return;\n\t    }\n", "    case \"pnpm\": {\n\t      const origLockfile = readTypedYamlSync<PnpmLockfile>(lockfileSrcPath);\n\t      log.debug(\"Read PNPM lockfile, version:\", origLockfile.lockfileVersion);\n\t      const adaptedLockfile = structuredClone(origLockfile);\n\t      const targetPackageDef =\n\t        adaptedLockfile.importers[targetPackageRelativeDir];\n\t      assert(\n\t        targetPackageDef,\n\t        `Failed to find target package in lockfile at importers[${targetPackageRelativeDir}]`\n\t      );\n", "      /**\n\t       * Overwrite the root importer with the target package importer contents\n\t       */\n\t      adaptedLockfile.importers[\".\"] = targetPackageDef;\n\t      /**\n\t       * Delete the target package original importer. Not really necessary.\n\t       */\n\t      delete adaptedLockfile.importers[targetPackageRelativeDir];\n\t      writeTypedYamlSync(lockfileDstPath, adaptedLockfile);\n\t      log.debug(\"Stored adapted lockfile at\", lockfileDstPath);\n", "      return;\n\t    }\n\t  }\n\t}\n"]}
{"filename": "src/helpers/process-build-output-files.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport path from \"node:path\";\n\timport { createLogger, pack, unpack } from \"~/utils\";\n\timport { getConfig } from \"./config\";\n\tconst TIMEOUT_MS = 5000;\n\texport async function processBuildOutputFiles({\n\t  targetPackageDir,\n\t  tmpDir,\n\t  isolateDir,\n\t}: {\n", "  targetPackageDir: string;\n\t  tmpDir: string;\n\t  isolateDir: string;\n\t}) {\n\t  const log = createLogger(getConfig().logLevel);\n\t  const packedFilePath = await pack(targetPackageDir, tmpDir);\n\t  const unpackDir = path.join(tmpDir, \"target\");\n\t  const now = Date.now();\n\t  let isWaitingYet = false;\n\t  while (!fs.existsSync(packedFilePath) && Date.now() - now < TIMEOUT_MS) {\n", "    if (!isWaitingYet) {\n\t      log.debug(`Waiting for ${packedFilePath} to become available...`);\n\t    }\n\t    isWaitingYet = true;\n\t    await new Promise((resolve) => setTimeout(resolve, 100));\n\t  }\n\t  await unpack(packedFilePath, unpackDir);\n\t  await fs.copy(path.join(unpackDir, \"package\"), isolateDir);\n\t}\n"]}
{"filename": "src/helpers/get-build-output-dir.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport path from \"node:path\";\n\timport outdent from \"outdent\";\n\timport { getConfig } from \"~/helpers\";\n\timport { createLogger, readTypedJson } from \"~/utils\";\n\texport async function getBuildOutputDir(targetPackageDir: string) {\n\t  const config = getConfig();\n\t  const log = createLogger(getConfig().logLevel);\n\t  if (config.buildDirName) {\n\t    log.debug(\"Using buildDirName from config:\", config.buildDirName);\n", "    return path.join(targetPackageDir, config.buildDirName);\n\t  }\n\t  const tsconfigPath = path.join(targetPackageDir, config.tsconfigPath);\n\t  if (fs.existsSync(tsconfigPath)) {\n\t    log.debug(\"Found tsconfig at:\", config.tsconfigPath);\n\t    const tsconfig = await readTypedJson<{\n\t      compilerOptions?: { outDir?: string };\n\t    }>(tsconfigPath);\n\t    const outDir = tsconfig.compilerOptions?.outDir;\n\t    if (outDir) {\n", "      return path.join(targetPackageDir, outDir);\n\t    } else {\n\t      throw new Error(outdent`\n\t        Failed to find outDir in tsconfig. If you are executing isolate from the root of a monorepo you should specify the buildDirName in isolate.config.json.\n\t      `);\n\t    }\n\t  } else {\n\t    log.warn(\"Failed to find tsconfig at:\", tsconfigPath);\n\t    throw new Error(outdent`\n\t      Failed to infer the build output directory from either the isolate config buildDirName or a Typescript config file. See the documentation on how to configure one of these options.\n", "    `);\n\t  }\n\t}\n"]}
{"filename": "src/helpers/find-packages-globs.ts", "chunked_list": ["import assert from \"node:assert\";\n\timport path from \"node:path\";\n\timport {\n\t  createLogger,\n\t  inspectValue,\n\t  readTypedJsonSync,\n\t  readTypedYamlSync,\n\t} from \"~/utils\";\n\timport { getConfig } from \"./config\";\n\timport { usePackageManager } from \"./detect-package-manager\";\n", "/**\n\t * Find the globs that define where the packages are located within the\n\t * monorepo. This configuration is dependent on the package manager used, and I\n\t * don't know if we're covering all cases yet...\n\t */\n\texport function findPackagesGlobs(workspaceRootDir: string) {\n\t  const log = createLogger(getConfig().logLevel);\n\t  const packageManager = usePackageManager();\n\t  switch (packageManager.name) {\n\t    case \"pnpm\": {\n", "      const { packages: globs } = readTypedYamlSync<{ packages: string[] }>(\n\t        path.join(workspaceRootDir, \"pnpm-workspace.yaml\")\n\t      );\n\t      log.debug(\"Detected pnpm packages globs:\", inspectValue(globs));\n\t      return globs;\n\t    }\n\t    case \"yarn\":\n\t    case \"npm\": {\n\t      const workspaceRootManifestPath = path.join(\n\t        workspaceRootDir,\n", "        \"package.json\"\n\t      );\n\t      const { workspaces } = readTypedJsonSync<{ workspaces: string[] }>(\n\t        workspaceRootManifestPath\n\t      );\n\t      if (!workspaces) {\n\t        throw new Error(\n\t          `No workspaces field found in ${workspaceRootManifestPath}`\n\t        );\n\t      }\n", "      if (Array.isArray(workspaces)) {\n\t        return workspaces;\n\t      } else {\n\t        /**\n\t         * For Yarn, workspaces could be defined as an object with { packages: [],\n\t         * nohoist: [] }. See https://classic.yarnpkg.com/blog/2018/02/15/nohoist/\n\t         */\n\t        const workspacesObject = workspaces as { packages?: string[] };\n\t        assert(\n\t          workspacesObject.packages,\n", "          \"workspaces.packages must be an array\"\n\t        );\n\t        return workspacesObject.packages;\n\t      }\n\t    }\n\t  }\n\t}\n"]}
{"filename": "src/helpers/list-local-dependencies.ts", "chunked_list": ["import { PackageManifest, PackagesRegistry } from \"./create-packages-registry\";\n\t/**\n\t * Recursively list the packages from dependencies (and optionally\n\t * devDependencies) that are found in the workspace.\n\t *\n\t * Here we do not need to rely on packages being declared as \"workspace:\" in the\n\t * manifest. We can simply compare the package names with the list of packages\n\t * that were found via the workspace glob patterns and added to the registry.\n\t */\n\texport function listLocalDependencies(\n", "  manifest: PackageManifest,\n\t  packagesRegistry: PackagesRegistry,\n\t  { includeDevDependencies = false } = {}\n\t): string[] {\n\t  const allWorkspacePackageNames = Object.keys(packagesRegistry);\n\t  const localDependencyPackageNames = (\n\t    includeDevDependencies\n\t      ? [\n\t          ...Object.keys(manifest.dependencies ?? {}),\n\t          ...Object.keys(manifest.devDependencies ?? {}),\n", "        ]\n\t      : Object.keys(manifest.dependencies ?? {})\n\t  ).filter((name) => allWorkspacePackageNames.includes(name));\n\t  const nestedLocalDependencies = localDependencyPackageNames.flatMap(\n\t    (packageName) =>\n\t      listLocalDependencies(\n\t        packagesRegistry[packageName].manifest,\n\t        packagesRegistry,\n\t        { includeDevDependencies }\n\t      )\n", "  );\n\t  return localDependencyPackageNames.concat(nestedLocalDependencies);\n\t}\n"]}
{"filename": "src/helpers/manifest.ts", "chunked_list": ["import path from \"node:path\";\n\timport { readTypedJson } from \"~/utils\";\n\timport { PackageManifest } from \"./create-packages-registry\";\n\texport async function importManifest(packageDir: string) {\n\t  return readTypedJson<PackageManifest>(path.join(packageDir, \"package.json\"));\n\t}\n"]}
{"filename": "src/helpers/adapt-manifest-files.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport path from \"node:path\";\n\timport {\n\t  PackagesRegistry,\n\t  adaptManifestWorkspaceDeps,\n\t  getConfig,\n\t} from \"~/helpers\";\n\timport { createLogger } from \"~/utils\";\n\texport async function adaptManifestFiles(\n\t  localDependencies: string[],\n", "  packagesRegistry: PackagesRegistry,\n\t  isolateDir: string\n\t) {\n\t  await Promise.all(\n\t    localDependencies.map(async (packageName) => {\n\t      const { manifest, rootRelativeDir } = packagesRegistry[packageName];\n\t      const outputManifest = adaptManifestWorkspaceDeps(\n\t        { manifest, packagesRegistry, parentRootRelativeDir: rootRelativeDir },\n\t        { includeDevDependencies: getConfig().includeDevDependencies }\n\t      );\n", "      await fs.writeFile(\n\t        path.join(isolateDir, rootRelativeDir, \"package.json\"),\n\t        JSON.stringify(outputManifest, null, 2)\n\t      );\n\t    })\n\t  );\n\t}\n"]}
{"filename": "src/helpers/index.ts", "chunked_list": ["export * from \"./adapt-manifest-files\";\n\texport * from \"./adapt-manifest-workspace-deps\";\n\texport * from \"./adapt-target-package-manifest\";\n\texport * from \"./config\";\n\texport * from \"./create-packages-registry\";\n\texport * from \"./detect-package-manager\";\n\texport * from \"./find-packages-globs\";\n\texport * from \"./get-build-output-dir\";\n\texport * from \"./list-local-dependencies\";\n\texport * from \"./manifest\";\n", "export * from \"./pack-dependencies\";\n\texport * from \"./patch-workspace-entries\";\n\texport * from \"./process-build-output-files\";\n\texport * from \"./process-lockfile\";\n\texport * from \"./unpack-dependencies\";\n"]}
{"filename": "src/helpers/create-packages-registry.ts", "chunked_list": ["import fs from \"fs-extra\";\n\timport { globSync } from \"glob\";\n\timport path from \"node:path\";\n\timport { createLogger, readTypedJson } from \"~/utils\";\n\timport { getConfig } from \"./config\";\n\timport { findPackagesGlobs } from \"./find-packages-globs\";\n\texport type PackageManifest = {\n\t  name: string;\n\t  packageManager?: string;\n\t  dependencies?: Record<string, string>;\n", "  devDependencies?: Record<string, string>;\n\t  main: string;\n\t  module?: string;\n\t  exports?: Record<string, { require: string; import: string }>;\n\t  files: string[];\n\t  version?: string;\n\t  typings?: string;\n\t  scripts?: Record<string, string>;\n\t};\n\texport type WorkspacePackageInfo = {\n", "  absoluteDir: string;\n\t  /**\n\t   * The path of the package relative to the workspace root. This is the path\n\t   * referenced in the lock file.\n\t   */\n\t  rootRelativeDir: string;\n\t  /**\n\t   * The package.json file contents\n\t   */\n\t  manifest: PackageManifest;\n", "};\n\texport type PackagesRegistry = Record<string, WorkspacePackageInfo>;\n\t/**\n\t * Build a list of all packages in the workspace, depending on the package\n\t * manager used, with a possible override from the config file. The list contains\n\t * the manifest with some directory info mapped by module name.\n\t */\n\texport async function createPackagesRegistry(\n\t  workspaceRootDir: string,\n\t  workspacePackagesOverride: string[] | undefined\n", "): Promise<PackagesRegistry> {\n\t  const log = createLogger(getConfig().logLevel);\n\t  if (workspacePackagesOverride) {\n\t    log.debug(\n\t      `Override workspace packages via config: ${workspacePackagesOverride}`\n\t    );\n\t  }\n\t  const packagesGlobs =\n\t    workspacePackagesOverride ?? findPackagesGlobs(workspaceRootDir);\n\t  const cwd = process.cwd();\n", "  process.chdir(workspaceRootDir);\n\t  const allPackages = packagesGlobs\n\t    .flatMap((glob) => globSync(glob))\n\t    /**\n\t     * Make sure to filter any loose files that might hang around.\n\t     */\n\t    .filter((dir) => fs.lstatSync(dir).isDirectory());\n\t  const registry: PackagesRegistry = (\n\t    await Promise.all(\n\t      allPackages.map(async (rootRelativeDir) => {\n", "        const manifestPath = path.join(rootRelativeDir, \"package.json\");\n\t        if (!fs.existsSync(manifestPath)) {\n\t          log.warn(\n\t            `Ignoring directory ./${rootRelativeDir} because it does not contain a package.json file`\n\t          );\n\t          return;\n\t        } else {\n\t          log.debug(`Registering package ./${rootRelativeDir}`);\n\t          const manifest = await readTypedJson<PackageManifest>(\n\t            path.join(rootRelativeDir, \"package.json\")\n", "          );\n\t          return {\n\t            manifest,\n\t            rootRelativeDir,\n\t            absoluteDir: path.join(workspaceRootDir, rootRelativeDir),\n\t          };\n\t        }\n\t      })\n\t    )\n\t  ).reduce<PackagesRegistry>((acc, info) => {\n", "    if (info) {\n\t      acc[info.manifest.name] = info;\n\t    }\n\t    return acc;\n\t  }, {});\n\t  process.chdir(cwd);\n\t  return registry;\n\t}\n"]}
{"filename": "src/helpers/pack-dependencies.ts", "chunked_list": ["import assert from \"node:assert\";\n\timport { createLogger, pack } from \"~/utils\";\n\timport { getConfig } from \"./config\";\n\timport { PackagesRegistry } from \"./create-packages-registry\";\n\timport { usePackageManager } from \"./detect-package-manager\";\n\t/**\n\t * Pack dependencies so that we extract only the files that are supposed to be\n\t * published by the packages.\n\t *\n\t * @returns A map of package names to the path of the packed file\n", " */\n\texport async function packDependencies({\n\t  /**\n\t   * All packages found in the monorepo by workspaces declaration\n\t   */\n\t  packagesRegistry,\n\t  /**\n\t   * The package names that appear to be local dependencies\n\t   */\n\t  localDependencies,\n", "  /**\n\t   * The directory where the isolated package and all its dependencies will end\n\t   * up. This is also the directory from where the package will be deployed. By\n\t   * default it is a subfolder in targetPackageDir called \"isolate\" but you can\n\t   * configure it.\n\t   */\n\t  packDestinationDir,\n\t}: {\n\t  packagesRegistry: PackagesRegistry;\n\t  localDependencies: string[];\n", "  packDestinationDir: string;\n\t}) {\n\t  const config = getConfig();\n\t  const log = createLogger(config.logLevel);\n\t  const packedFileByName: Record<string, string> = {};\n\t  const { name, version } = usePackageManager();\n\t  const versionMajor = parseInt(version.split(\".\")[0], 10);\n\t  const usePnpmPack =\n\t    !config.avoidPnpmPack && name === \"pnpm\" && versionMajor >= 8;\n\t  if (usePnpmPack) {\n", "    log.debug(\"Using PNPM pack instead of NPM pack\");\n\t  }\n\t  for (const dependency of localDependencies) {\n\t    const def = packagesRegistry[dependency];\n\t    assert(dependency, `Failed to find package definition for ${dependency}`);\n\t    const { name } = def.manifest;\n\t    /**\n\t     * If this dependency has already been packed, we skip it. It could happen\n\t     * because we are packing workspace dependencies recursively.\n\t     */\n", "    if (packedFileByName[name]) {\n\t      log.debug(`Skipping ${name} because it has already been packed`);\n\t      continue;\n\t    }\n\t    packedFileByName[name] = await pack(\n\t      def.absoluteDir,\n\t      packDestinationDir,\n\t      usePnpmPack\n\t    );\n\t  }\n", "  return packedFileByName;\n\t}\n"]}
