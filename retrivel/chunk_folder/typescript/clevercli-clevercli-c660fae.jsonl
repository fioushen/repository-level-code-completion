{"filename": "src/loadPromptConfig.ts", "chunked_list": ["import { Config } from \"./types.js\";\n\timport { join as pathJoin } from \"node:path\";\n\timport { AppError } from \"./errors.js\";\n\timport { fileURLToPath } from \"node:url\";\n\timport { dirname, parse } from \"node:path\";\n\timport { readdir } from \"node:fs/promises\";\n\tasync function readFilesInDirectory(path: string) {\n\t  try {\n\t    const files = await readdir(path);\n\t    return files\n", "      .filter((f) => f.endsWith(\".js\") || f.endsWith(\".mjs\"))\n\t      .map((filename) => pathJoin(path, filename));\n\t  } catch (err) {\n\t    if (err instanceof Error && \"code\" in err) {\n\t      if (err.code == \"ENOENT\") {\n\t        // ignore error: ENOENT: no such file or directory\n\t        return [];\n\t      }\n\t    }\n\t    throw err;\n", "  }\n\t}\n\t// Returns a path relative to import.meta.filename\n\texport function sourceRelativePath(\n\t  meta: { url: string },\n\t  ...relPaths: string[]\n\t) {\n\t  const __dirname = dirname(fileURLToPath(meta.url));\n\t  return pathJoin(__dirname, ...relPaths);\n\t}\n", "export async function loadFromPath(path: string) {\n\t  const promptConfig = await import(path);\n\t  // TODO: validate promptConfig?\n\t  return promptConfig.default;\n\t}\n\texport async function loadPromptConfig(promptId: string, config: Config) {\n\t  try {\n\t    const promptConfig = await Promise.any([\n\t      loadFromPath(sourceRelativePath(import.meta, `./prompts/${promptId}.js`)),\n\t      loadFromPath(pathJoin(config.paths.data, `${promptId}.mjs`)),\n", "    ]);\n\t    return promptConfig;\n\t  } catch (err) {\n\t    throw new AppError({\n\t      message: `Could not find prompt ${promptId}. Are you sure it is a builtin prompt or that ${config.paths.data}/${promptId}.mjs exists?`,\n\t    });\n\t  }\n\t}\n\texport async function listPrompts(config: Config) {\n\t  const [localFiles, builtinFiles] = await Promise.all(\n", "    [\n\t      sourceRelativePath(import.meta, `./prompts`),\n\t      pathJoin(config.paths.data),\n\t    ].map(readFilesInDirectory)\n\t  );\n\t  const allFiles = [...localFiles, ...builtinFiles];\n\t  const allPromptConfigs = await Promise.all(allFiles.map(loadFromPath));\n\t  return allPromptConfigs.map((config, i) => {\n\t    const name = parse(allFiles[i]).name;\n\t    return {\n", "      name,\n\t      description: config.description,\n\t    };\n\t  });\n\t}\n"]}
{"filename": "src/config.ts", "chunked_list": ["import { ConfigError } from \"./errors.js\";\n\timport { APPNAME, Config } from \"./types.js\";\n\timport envPaths from \"env-paths\";\n\timport { homedir } from \"node:os\";\n\timport { join as pathJoin } from \"node:path\";\n\timport createDebug from \"debug\";\n\tconst debug = createDebug(`${APPNAME}:config`);\n\tfunction getEnvOrThrow(key: string) {\n\t  const val = process.env[key];\n\t  if (typeof val === \"undefined\") {\n", "    throw new ConfigError({\n\t      message: `Please set the ${key} environment variable.`,\n\t    });\n\t  }\n\t  return val;\n\t}\n\tconst paths = envPaths(APPNAME, { suffix: \"\" });\n\texport function loadConfig(): Config {\n\t  const config = {\n\t    openai: {\n", "      apiKey: getEnvOrThrow(\"OPENAI_API_KEY\"),\n\t    },\n\t    paths: {\n\t      data: pathJoin(homedir(), `.${APPNAME}`),\n\t      cache: paths.cache,\n\t    },\n\t    useCache: true,\n\t  };\n\t  debug(config);\n\t  return config;\n", "}\n"]}
{"filename": "src/openaiModels.ts", "chunked_list": ["import { Model, ModelType } from \"./types.js\";\n\texport const GPT_3_5Turbo: Model = {\n\t  id: \"gpt-3.5-turbo\",\n\t  type: ModelType.Chat,\n\t  maxTokens: 4096,\n\t};\n\tconst allModels = [GPT_3_5Turbo];\n\tconst modelsById: Map<string, Model> = new Map(\n\t  allModels.reduce((acc: [string, Model][], ele: Model): [string, Model][] => {\n\t    return [...acc, [ele.id, ele]];\n", "  }, [])\n\t);\n\texport const defaultModel = GPT_3_5Turbo;\n\texport default modelsById;\n"]}
{"filename": "src/types.ts", "chunked_list": ["export const APPNAME = \"clevercli\";\n\texport interface ParsedResponse {\n\t  message: string;\n\t  meta?: object;\n\t}\n\texport enum ModelType {\n\t  Chat,\n\t  Completion,\n\t}\n\texport interface Model {\n", "  id: string;\n\t  type: ModelType;\n\t  maxTokens: number;\n\t}\n\texport interface PromptConfiguration {\n\t  createPrompt(input: string): string;\n\t  parseResponse?(response: string, input: string): ParsedResponse;\n\t  model?: string;\n\t  description?: string;\n\t}\n", "export interface Config {\n\t  openai: {\n\t    apiKey: string;\n\t  };\n\t  useCache: boolean;\n\t  paths: {\n\t    data: string;\n\t    cache: string;\n\t  };\n\t}\n"]}
{"filename": "src/executePrompt.ts", "chunked_list": ["import {\n\t  ChatCompletionRequestMessageRoleEnum,\n\t  Configuration as OpenAIConfiguration,\n\t  OpenAIApi,\n\t} from \"openai\";\n\timport models, { defaultModel } from \"./openaiModels.js\";\n\timport { ApiError, AppError } from \"./errors.js\";\n\timport { Config, Model, ParsedResponse, PromptConfiguration } from \"./types.js\";\n\timport KeyValueStore from \"./kvs/abstract.js\";\n\timport { openAIQuery } from \"./openai.js\";\n", "import { asyncIterableToArray } from \"./utils.js\";\n\tfunction defaultParseResponse(content: string, _input: string): ParsedResponse {\n\t  return { message: content };\n\t}\n\tfunction toModel(promptConfig: PromptConfiguration): Model {\n\t  const model = promptConfig.model\n\t    ? models.get(promptConfig.model)\n\t    : defaultModel;\n\t  if (!model) {\n\t    throw new AppError({\n", "      message: `Could not find model \"${promptConfig.model}\"`,\n\t    });\n\t  }\n\t  return model;\n\t}\n\texport async function* executePromptStream(\n\t  promptConfig: PromptConfiguration,\n\t  input: string,\n\t  config: Config,\n\t  cache?: KeyValueStore<string, string>\n", "): AsyncGenerator<string> {\n\t  const model = toModel(promptConfig);\n\t  const formattedPrompt = promptConfig.createPrompt(input);\n\t  const cacheKey = `${model.id}-${formattedPrompt}`;\n\t  if (cache) {\n\t    const cachedResponse = await cache.get(cacheKey);\n\t    if (cachedResponse) {\n\t      yield cachedResponse;\n\t      return;\n\t    }\n", "  }\n\t  const stream = openAIQuery(model, formattedPrompt, config);\n\t  const chunks = [];\n\t  for await (const chunk of stream) {\n\t    chunks.push(chunk);\n\t    yield chunk;\n\t  }\n\t  if (cache) {\n\t    const response = chunks.join(\"\");\n\t    await cache.set(cacheKey, response);\n", "  }\n\t}\n\texport async function executePrompt(\n\t  promptConfig: PromptConfiguration,\n\t  input: string,\n\t  config: Config,\n\t  cache?: KeyValueStore<string, string>\n\t): Promise<ParsedResponse> {\n\t  const model = toModel(promptConfig);\n\t  const parseResponse = promptConfig.parseResponse ?? defaultParseResponse;\n", "  const response = (\n\t    await asyncIterableToArray(\n\t      executePromptStream(promptConfig, input, config, cache)\n\t    )\n\t  ).join(\"\");\n\t  return parseResponse(response, input);\n\t}\n\texport default executePrompt;\n"]}
{"filename": "src/openai.ts", "chunked_list": ["import { Config, Model } from \"./types.js\";\n\timport {\n\t  ChatCompletionRequestMessageRoleEnum,\n\t  Configuration,\n\t  OpenAIApi,\n\t} from \"openai\";\n\timport { ApiError } from \"./errors.js\";\n\timport { asyncIterableToArray } from \"./utils.js\";\n\t// https://2ality.com/2018/04/async-iter-nodejs.html#generator-%231%3A-from-chunks-to-lines\n\tasync function* chunksToLines(chunksAsync: AsyncGenerator<string>) {\n", "  let previous = \"\";\n\t  for await (const chunk of chunksAsync) {\n\t    const bufferChunk = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk);\n\t    previous += bufferChunk;\n\t    let eolIndex;\n\t    while ((eolIndex = previous.indexOf(\"\\n\")) >= 0) {\n\t      // line includes the EOL\n\t      const line = previous.slice(0, eolIndex + 1).trimEnd();\n\t      if (line === \"data: [DONE]\") break;\n\t      if (line.startsWith(\"data: \")) {\n", "        yield line.slice(\"data: \".length);\n\t      }\n\t      previous = previous.slice(eolIndex + 1);\n\t    }\n\t  }\n\t}\n\t// Wraps openai and provides streaming API + auto selection of api function based on model\n\texport async function* openAIQuery(\n\t  model: Model,\n\t  prompt: string,\n", "  config: Config\n\t): AsyncGenerator<string> {\n\t  const openai = new OpenAIApi(\n\t    new Configuration({\n\t      apiKey: config.openai.apiKey,\n\t    })\n\t  );\n\t  // TODO: select right api route/function based on model\n\t  const opts = {\n\t    stream: true,\n", "    model: model.id,\n\t    messages: [\n\t      {\n\t        role: ChatCompletionRequestMessageRoleEnum.System,\n\t        content: prompt,\n\t      },\n\t    ],\n\t  };\n\t  const res = await (async () => {\n\t    try {\n", "      return await openai.createChatCompletion(opts, {\n\t        responseType: \"stream\",\n\t      });\n\t    } catch (err) {\n\t      if (err instanceof Error) {\n\t        if (\"isAxiosError\" in err) {\n\t          /* @ts-ignore */\n\t          const data = await asyncIterableToArray(err.response.data);\n\t          const error = JSON.parse(data.toString()).error;\n\t          throw new ApiError(error);\n", "        }\n\t      }\n\t      throw err;\n\t    }\n\t  })();\n\t  /* @ts-ignore */\n\t  const stream = res.data as IncomingMessage;\n\t  for await (const chunk of chunksToLines(stream)) {\n\t    const data = JSON.parse(chunk);\n\t    const content = data.choices[0].delta.content;\n", "    // console.log({ json });\n\t    if (content) {\n\t      yield content;\n\t    }\n\t  }\n\t}\n"]}
{"filename": "src/errors.ts", "chunked_list": ["const PROGRAMMING_ERROR_CLASSES: Array<typeof Error> = [\n\t  TypeError,\n\t  ReferenceError,\n\t  RangeError,\n\t  SyntaxError,\n\t];\n\tfunction isProgrammingError(err: unknown) {\n\t  return PROGRAMMING_ERROR_CLASSES.some((ErrorClass: ErrorConstructor) => {\n\t    return err instanceof ErrorClass;\n\t  });\n", "}\n\texport class AppError extends Error {\n\t  cause?: Error;\n\t  exitCode = 1;\n\t  private static wrap(err: unknown) {\n\t    // We don't wrap errors that indicate unexpected/programming errors\n\t    if (isProgrammingError(err)) {\n\t      return err;\n\t    }\n\t    const cause = err instanceof Error ? err : undefined;\n", "    return new this({ cause });\n\t  }\n\t  get name(): string {\n\t    return this.constructor.name;\n\t  }\n\t  toJSON() {\n\t    return {\n\t      name: this.name,\n\t      message: this.message,\n\t      cause: this.cause,\n", "    };\n\t  }\n\t  toString(): string | this {\n\t    const printCause = this.cause\n\t      ? () => {\n\t          return `(cause: ${this.cause})`;\n\t        }\n\t      : () => \"\";\n\t    return `${this.name}: ${this.message}${printCause()}`;\n\t  }\n", "  constructor(opts?: { message?: string; cause?: Error }) {\n\t    super(opts?.message);\n\t    this.cause = opts?.cause;\n\t  }\n\t}\n\texport class ApiError extends AppError {\n\t  type: string;\n\t  param: string;\n\t  code: string;\n\t  constructor(data: {\n", "    message: string;\n\t    type: string;\n\t    param: string;\n\t    code: string;\n\t  }) {\n\t    super({ message: data.message });\n\t    this.message = data.message;\n\t    this.type = data.type;\n\t    this.param = data.param;\n\t    this.code = data.code;\n", "  }\n\t  toString(): string {\n\t    return `${this.name}: ${this.message} (type = ${this.type}, param = ${this.param}, code = ${this.code})`;\n\t  }\n\t}\n\texport class ConfigError extends AppError {}\n"]}
{"filename": "src/utils.ts", "chunked_list": ["export async function asyncIterableToArray<T>(\n\t  asyncIterator: AsyncIterable<T>\n\t): Promise<T[]> {\n\t  const arr = [];\n\t  for await (const ele of asyncIterator) {\n\t    arr.push(ele);\n\t  }\n\t  return arr;\n\t}\n"]}
{"filename": "src/index.ts", "chunked_list": ["import { executePrompt, executePromptStream } from \"./executePrompt.js\";\n\timport { loadConfig } from \"./config.js\";\n\timport { loadPromptConfig, listPrompts } from \"./loadPromptConfig.js\";\n\timport { APPNAME } from \"./types.js\";\n\timport FileSystemKVS from \"./kvs/kvs-filesystem.js\";\n\timport { AppError } from \"./errors.js\";\n\timport { readFileSync } from \"node:fs\";\n\tfunction parseArgs(argv: string[]) {\n\t  const [_nodeBin, _jsFile, promptId, ...rest] = argv;\n\t  const input = rest.join(\" \");\n", "  return { promptId, input };\n\t}\n\tfunction printUsageAndExit() {\n\t  console.log(\"Usage:\");\n\t  console.log(`$ ${APPNAME} <promptType> <input>`);\n\t  console.log(`$ ${APPNAME} --list`);\n\t  console.log(\"\");\n\t  console.log(\"Example: \");\n\t  console.log(\"\");\n\t  console.log(`$ ${APPNAME} eli5 \"what are large language models?\"`);\n", "  process.exit(1);\n\t}\n\tfunction getInput(argvInput: string) {\n\t  try {\n\t    const stdinInput = readFileSync(process.stdin.fd, \"utf-8\");\n\t    // console.log({ stdinInput });\n\t    return `${argvInput} ${stdinInput}`;\n\t  } catch (err) {\n\t    return argvInput;\n\t  }\n", "}\n\texport async function cli() {\n\t  try {\n\t    const config = loadConfig();\n\t    const { promptId, input: argvInput } = parseArgs(process.argv);\n\t    if (promptId === \"--list\") {\n\t      const prompts = await listPrompts(config);\n\t      console.log(\n\t        prompts\n\t          .map((p) => {\n", "            const description = p.description ? `: ${p.description}` : \"\";\n\t            return `${p.name}${description}`;\n\t          })\n\t          .join(\"\\n\")\n\t      );\n\t      return;\n\t    } else if (promptId && promptId.startsWith(\"--\")) {\n\t      printUsageAndExit();\n\t    }\n\t    const input = getInput(argvInput);\n", "    if (!promptId || !input) {\n\t      printUsageAndExit();\n\t    }\n\t    const promptConfig = await loadPromptConfig(promptId, config);\n\t    const cache = config.useCache\n\t      ? new FileSystemKVS({ baseDir: config.paths.cache })\n\t      : undefined;\n\t    const stream = executePromptStream(promptConfig, input, config, cache);\n\t    for await (const chunk of stream) {\n\t      process.stdout.write(chunk);\n", "    }\n\t    process.stdout.write(\"\\n\");\n\t  } catch (err) {\n\t    if (err instanceof AppError) {\n\t      console.error(err.toString());\n\t      process.exit(err.exitCode);\n\t    }\n\t    console.error(err);\n\t    process.exit(1);\n\t  }\n", "}\n\texport default cli;\n"]}
{"filename": "src/kvs/kvs-memory.ts", "chunked_list": ["import KeyValueStore from \"./abstract.js\";\n\texport default class MemoryKVS<K, V> extends KeyValueStore<K, V> {\n\t  map: Map<K, string>;\n\t  constructor() {\n\t    super();\n\t    this.map = new Map<K, string>();\n\t  }\n\t  async set(key: K, value: V) {\n\t    this.map.set(key, `${value}`);\n\t  }\n", "  async get(key: K): Promise<string | undefined> {\n\t    return this.map.get(key);\n\t  }\n\t  async delete(key: K) {\n\t    this.map.delete(key);\n\t  }\n\t}\n"]}
{"filename": "src/kvs/index.test.ts", "chunked_list": ["import { test } from \"vitest\";\n\timport { KeyValueStore, FileSystemKVS, MemoryKVS } from \"./index.js\";\n\tfunction runTestForKvs(\n\t  KvsClass: new (opts: any) => KeyValueStore<string, string>\n\t) {\n\t  const testData = [\n\t    [\"somekey\", \"somevalue\"],\n\t    ['some/  crazy/\"key !!😂', \"somevalue\"],\n\t    [\"well\", 'some crazy/\"value !!😂'],\n\t    [\"somekeythatgetsoverwritten\", \"initial value\"],\n", "    [\"somekeythatgetsoverwritten\", \"final value\"],\n\t  ];\n\t  const prefix = `kvs: ${KvsClass.name}:`;\n\t  test(`${prefix} integration test`, async ({ expect }) => {\n\t    const kvs = new KvsClass({});\n\t    for (const [k, v] of testData) {\n\t      await kvs.set(k, v);\n\t      let retrievedVal = await kvs.get(k);\n\t      expect(retrievedVal).toBe(v);\n\t    }\n", "    const map = new Map();\n\t    testData.forEach(([k, v]) => map.set(k, v));\n\t    for (const [k, _] of testData) {\n\t      const retrievedVal = await kvs.get(k);\n\t      expect(retrievedVal).toBe(map.get(k));\n\t    }\n\t    expect(await kvs.get(\"key does not exist\")).toBeUndefined();\n\t    await kvs.delete(\"somekey\");\n\t    expect(await kvs.get(\"somekey\")).toBeUndefined();\n\t  });\n", "}\n\trunTestForKvs(MemoryKVS);\n\trunTestForKvs(FileSystemKVS);\n"]}
{"filename": "src/kvs/kvs-filesystem.ts", "chunked_list": ["import { mkdtemp, unlink, readFile, writeFile } from \"node:fs/promises\";\n\timport mkdirp from \"mkdirp\";\n\timport { join as pathJoin } from \"path\";\n\timport { createHash } from \"node:crypto\";\n\timport KeyValueStore from \"./abstract.js\";\n\timport { tmpdir } from \"node:os\";\n\texport default class FileSystemKVS<K, V> extends KeyValueStore<K, V> {\n\t  baseDir: string;\n\t  // tmpPath: string | undefined;\n\t  waitInit: Promise<void>;\n", "  constructor(opts: { baseDir?: string }) {\n\t    super();\n\t    this.baseDir = opts.baseDir ?? \"\";\n\t    this.waitInit = this._init();\n\t  }\n\t  private async _init() {\n\t    if (this.baseDir) {\n\t      // ensure base dir exists\n\t      await mkdirp(this.baseDir);\n\t      return;\n", "    }\n\t    // create temporary dir\n\t    const tmpPath = await mkdtemp(pathJoin(tmpdir(), \"filesystem-kvs-\"));\n\t    this.baseDir = tmpPath;\n\t  }\n\t  private _keyToFilename(key: K): string {\n\t    return createHash(\"sha1\").update(`${key}`).digest().toString(\"hex\");\n\t  }\n\t  private _keyToFilePath(key: K): string {\n\t    // if (!this.baseDir) throw new TypeError('_keyToFilePath');\n", "    const baseDir = this.baseDir;\n\t    const filePath = pathJoin(baseDir, this._keyToFilename(key));\n\t    // console.log({ filePath });\n\t    return filePath;\n\t  }\n\t  async set(key: K, value: V) {\n\t    await this.waitInit;\n\t    await writeFile(this._keyToFilePath(key), `${value}`);\n\t  }\n\t  async get(key: K): Promise<string | undefined> {\n", "    await this.waitInit;\n\t    const filePath = this._keyToFilePath(key);\n\t    try {\n\t      const val = await readFile(filePath, \"utf8\");\n\t      return val;\n\t    } catch (err) {\n\t      return;\n\t    }\n\t  }\n\t  async delete(key: K) {\n", "    await this.waitInit;\n\t    try {\n\t      await unlink(this._keyToFilePath(key));\n\t    } catch {}\n\t  }\n\t}\n"]}
{"filename": "src/kvs/index.ts", "chunked_list": ["export { default as FileSystemKVS } from \"./kvs-filesystem.js\";\n\texport { default as MemoryKVS } from \"./kvs-memory.js\";\n\texport { default as KeyValueStore } from \"./abstract.js\";\n"]}
{"filename": "src/kvs/abstract.ts", "chunked_list": ["export default abstract class KeyValueStore<K, V> {\n\t  // constructor(opts?: {}) {}\n\t  abstract set(key: K, value: V): Promise<void>;\n\t  abstract get(key: K): Promise<string | undefined>;\n\t  abstract delete(key: K): Promise<void>;\n\t}\n"]}
{"filename": "src/bin/cli.ts", "chunked_list": ["#!/usr/bin/env node\n\timport { cli } from \"../index.js\";\n\tawait cli();\n"]}
{"filename": "src/prompts/convert-to-rust.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description: \"Converts source file to Rust\",\n\t  createPrompt(input: string) {\n\t    return `Rewrite this file in Rust. Only output valid code, no comments. ${input}\\n\\n`;\n\t  },\n\t};\n\texport default promptConfiguration;\n"]}
{"filename": "src/prompts/unix-command.ts", "chunked_list": ["export default {\n\t  description: \"Outputs Unix commands\",\n\t  createPrompt(input: string) {\n\t    return `Reply only with commands that can be run in a UNIX Bash shell. DO NOT give an explanation of what the command does. Reply as if your answer is piped directly to a bash. Here's what the command should do: ${input}`;\n\t  },\n\t};\n"]}
{"filename": "src/prompts/jsdoc.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description: \"Adds JSDoc comments to exported functions.\",\n\t  createPrompt(input: string) {\n\t    return `Add JSDoc comments to exported functions. Don't include types if they are already specified in TypeScript.\\n\\n${input}`;\n\t  },\n\t};\n\texport default promptConfiguration;\n"]}
{"filename": "src/prompts/refactor.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description: \"Asks ChatGPT to refactor code in a file.\",\n\t  createPrompt(input: string) {\n\t    return `Help me refactor this code (only output code and comments): ${input}.\\n###\\n`;\n\t  },\n\t};\n\texport default promptConfiguration;\n"]}
{"filename": "src/prompts/synonyms.ts", "chunked_list": ["export default {\n\t  description: \"List synonyms for the input words\",\n\t  createPrompt(input: string) {\n\t    return `Ouput a comma separated list of synonyms for: ${input}.\\n###\\n`;\n\t  },\n\t};\n"]}
{"filename": "src/prompts/joke.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description: \"Tells a joke about the topic.\",\n\t  createPrompt(input: string) {\n\t    return `Tell me a funny joke on this topic: ${input}.\\n###\\n`;\n\t  },\n\t};\n\texport default promptConfiguration;\n"]}
{"filename": "src/prompts/poem.ts", "chunked_list": ["export default {\n\t  description: \"Asks ChatGPT to write a small poem on the topic.\",\n\t  createPrompt(input: string) {\n\t    return `Write a small poem about: ${input}.\\n###\\n`;\n\t  },\n\t};\n"]}
{"filename": "src/prompts/recipe.ts", "chunked_list": ["export default {\n\t  description:\n\t    \"Outputs recipe suggestions given a list of available ingredients.\",\n\t  createPrompt(input: string) {\n\t    return `Give me some recipe suggestions knowing that I have the following ingredients available: ${input}.\\n###\\n`;\n\t  },\n\t};\n"]}
{"filename": "src/prompts/summarize.ts", "chunked_list": ["export default {\n\t  description: \"Outputs a short summary of the text.\",\n\t  createPrompt(input: string) {\n\t    return `Give me a short summary of this text: ${input}.\\n###\\n`;\n\t  },\n\t};\n"]}
{"filename": "src/prompts/convert-to-typescript.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description: \"Converts source file to TypeScript\",\n\t  createPrompt(input: string) {\n\t    return `Rewrite this file in TypeScript. Only output valid code, no comments. ${input}\\n\\n`;\n\t  },\n\t};\n\texport default promptConfiguration;\n"]}
{"filename": "src/prompts/regex.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description:\n\t    \"Gives a JavaScript compatible RegEx that matches the input examples.\",\n\t  createPrompt(input: string) {\n\t    return `Output a JavaScript regex that matches the following examples: ${input}.\\n###\\n`;\n\t  },\n\t};\n\texport default promptConfiguration;\n"]}
{"filename": "src/prompts/eli5.ts", "chunked_list": ["import { ParsedResponse, PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description: \"Explain Me Like I'm 5\",\n\t  createPrompt(input: string) {\n\t    return `Provide a very detailed explanation but like I am 5 years old (ELI5) on this topic: ${input}.\\n###\\n`;\n\t  },\n\t  parseResponse(response: string, _input: string): ParsedResponse {\n\t    return { message: response };\n\t  },\n\t};\n", "export default promptConfiguration;\n"]}
{"filename": "src/prompts/ask.ts", "chunked_list": ["import { ParsedResponse, PromptConfiguration } from \"../types.js\";\n\tconst promptConfiguration: PromptConfiguration = {\n\t  description: \"Just passes through the input directly to ChatGPT.\",\n\t  createPrompt(input: string) {\n\t    return input;\n\t  },\n\t  parseResponse(response: string, _input: string): ParsedResponse {\n\t    return { message: response };\n\t  },\n\t};\n", "export default promptConfiguration;\n"]}
