{"filename": "vite.config.ts", "chunked_list": ["// vite.config.ts\nimport react from '@vitejs/plugin-react';\nimport { defineConfig } from 'vite';\n\nexport default defineConfig({\n  plugins: [react()],\n  server: {\n    port: 8082,\n    host: '0.0.0.0',\n  },", "    host: '0.0.0.0',\n  },\n  build: {\n    minify: true,\n  },\n  base: '',\n});\n"]}
{"filename": "src/webgpu/webgpubindgroup.ts", "chunked_list": ["import { WebGPUResourceOptions } from './types';\nimport { WebGPUBindGroupLayout } from './webgpubindgrouplayout';\n\ntype WebGPUBindGroupOptions = WebGPUResourceOptions & {\n  bindGroupLayout: WebGPUBindGroupLayout;\n  entries: GPUBindGroupEntry[];\n};\n\nexport class WebGPUBindGroup {\n  private group: GPUBindGroup;\n\n  public get bindGroup() {\n    return this.group;\n  }\n\n  public create(options: WebGPUBindGroupOptions) {\n    this.group = options.device.createBindGroup({\n      label: options.label,\n      layout: options.bindGroupLayout.layout,\n      entries: options.entries,\n    });\n  }\n}\n", "export class WebGPUBindGroup {\n  private group: GPUBindGroup;\n\n  public get bindGroup() {\n    return this.group;\n  }\n\n  public create(options: WebGPUBindGroupOptions) {\n    this.group = options.device.createBindGroup({\n      label: options.label,\n      layout: options.bindGroupLayout.layout,\n      entries: options.entries,\n    });\n  }\n}\n"]}
{"filename": "src/webgpu/types.ts", "chunked_list": ["export type WebGPUResourceOptions = {\n  label?: string;\n  device: GPUDevice;\n};\n"]}
{"filename": "src/webgpu/webgpucontext.ts", "chunked_list": ["export class WebGPURenderContext {\n  private _canvas: HTMLCanvasElement;\n  private _device: GPUDevice;\n  private _queue: GPUQueue;\n  private _gpuCanvasContext: GPUCanvasContext;\n  private _presentationFormat: GPUTextureFormat;\n  private _adapterLimits: GPUSupportedLimits;\n  private _adapterInfo: GPUAdapterInfo;\n\n  public async initialize(canvas: HTMLCanvasElement) {\n    this._canvas = canvas;\n\n    const gpu: GPU = navigator.gpu;\n\n    const adapter = await gpu.requestAdapter();\n    this._adapterLimits = adapter.limits;\n    this._adapterInfo = await adapter.requestAdapterInfo();\n    this._device = await adapter.requestDevice();\n    this._queue = this._device.queue;\n\n    this._gpuCanvasContext = this._canvas.getContext('webgpu');\n    this._presentationFormat = gpu.getPreferredCanvasFormat();\n  }\n\n  public get device() {\n    return this._device;\n  }\n\n  public get queue() {\n    return this._queue;\n  }\n\n  public get presentationContext() {\n    return this._gpuCanvasContext;\n  }\n\n  public get presentationFormat() {\n    return this._presentationFormat;\n  }\n}\n"]}
{"filename": "src/webgpu/webgpurenderpipeline.ts", "chunked_list": ["import { WebGPUResourceOptions } from './types';\nimport { WebGPUPipelineLayout } from './webgpupipelinelayout';\nimport { createShaderModuleFromPath } from './webgpushader';\n\ntype WebGPURenderPipelineOptions = WebGPUResourceOptions & {\n  sampleCount: number;\n  vertexShaderFile: string;\n  fragmentShaderFile: string;\n  fragmentTargets: GPUColorTargetState[];\n  pipelineLayout?: WebGPUPipelineLayout;\n};\n", "export class WebGPURenderPipeline {\n  private renderPipeline: GPURenderPipeline;\n\n  public get pipeline() {\n    return this.renderPipeline;\n  }\n\n  public async create(options: WebGPURenderPipelineOptions) {\n    this.renderPipeline = options.device.createRenderPipeline({\n      label: options.label,\n      layout: options.pipelineLayout?.layout ?? 'auto',\n      vertex: {\n        module: await createShaderModuleFromPath(options.vertexShaderFile, options.device),\n        entryPoint: 'main',\n      },\n      fragment: {\n        module: await createShaderModuleFromPath(options.fragmentShaderFile, options.device),\n        entryPoint: 'main',\n        targets: options.fragmentTargets,\n      },\n      primitive: {\n        topology: 'triangle-list',\n      },\n      multisample: {\n        count: options.sampleCount,\n      },\n    });\n  }\n}\n"]}
{"filename": "src/webgpu/helpers.ts", "chunked_list": ["export function supportsWebGPU(): boolean {\n  if (navigator.gpu) {\n    return true;\n  }\n  return false;\n}\n\nexport function createBuffer(array: ArrayBuffer, usage: GPUBufferUsageFlags, device: GPUDevice): GPUBuffer {\n  try {\n    const buffer = device.createBuffer({\n      size: array.byteLength,\n      usage,\n    });\n\n    device.queue.writeBuffer(buffer, 0, array);\n\n    return buffer;", "  try {\n    const buffer = device.createBuffer({\n      size: array.byteLength,\n      usage,\n    });\n\n    device.queue.writeBuffer(buffer, 0, array);\n\n    return buffer;\n  } catch (e) {\n    console.error(e);\n  }\n}\n", "  } catch (e) {\n    console.error(e);\n  }\n}\n"]}
{"filename": "src/webgpu/index.ts", "chunked_list": ["export * from './helpers';\nexport * from './webgpucontext';\nexport * from './webgpurenderer';\n"]}
{"filename": "src/webgpu/webgpubindgrouplayout.ts", "chunked_list": ["import { WebGPUResourceOptions } from './types';\n\ntype WebGPUBindGroupLayoutOptions = WebGPUResourceOptions & {\n  entries: GPUBindGroupLayoutEntry[];\n};\n\nexport class WebGPUBindGroupLayout {\n  private bindGroupLayout: GPUBindGroupLayout;\n\n  public get layout() {\n    return this.bindGroupLayout;\n  }\n\n  public create(options: WebGPUBindGroupLayoutOptions) {\n    this.bindGroupLayout = options.device.createBindGroupLayout({\n      label: options.label,\n      entries: options.entries,\n    });\n  }\n}\n"]}
{"filename": "src/webgpu/webgpurenderer.ts", "chunked_list": ["import { Vec2, Vec3, vec2 } from 'wgpu-matrix';\nimport { Camera } from './camera';\nimport { createBuffer } from './helpers';\nimport { WebGPUBindGroup } from './webgpubindgroup';\nimport { WebGPUBindGroupLayout } from './webgpubindgrouplayout';\nimport { WebGPURenderContext } from './webgpucontext';\nimport { WebGPUPipelineLayout } from './webgpupipelinelayout';\nimport { WebGPURenderPipeline } from './webgpurenderpipeline';\n\ntype UniformParams = {\n  resolution: Vec2;\n  cameraPosition: Vec3;\n};", "\ntype UniformParams = {\n  resolution: Vec2;\n  cameraPosition: Vec3;\n};\nexport class WebGPURenderer {\n  private readonly canvas: HTMLCanvasElement;\n  private readonly context = new WebGPURenderContext();\n  private presentationSize: GPUExtent3DDict;\n  private readonly depthOrArrayLayers = 1;\n  private readonly sampleCount = 4;\n\n  private renderTarget: GPUTexture;\n  private renderTargetView: GPUTextureView;\n\n  private depthTarget: GPUTexture;\n  private depthTargetView: GPUTextureView;\n  private currentTime = 0;\n  private renderPipeline: WebGPURenderPipeline;\n  // private computePipeline: GPUComputePipeline;\n\n  private uniformParams: UniformParams;\n  private uniformParamsBuffer: GPUBuffer;\n  private uniformParamsGroup: WebGPUBindGroup;\n  private camera: Camera;\n\n  constructor(canvas: HTMLCanvasElement) {\n    this.canvas = canvas;\n    this.camera = new Camera(canvas, [0, 0, 5], [0, 0, 0]);\n    this.uniformParams = {\n      resolution: [0, 0],\n      cameraPosition: this.camera.position,\n    };\n  }\n\n  private async initialize() {\n    await this.context.initialize(this.canvas);\n\n    this.uniformParams.resolution = [this.canvas.clientWidth, this.canvas.clientHeight];\n\n    const width = this.uniformParams.resolution[0] * window.devicePixelRatio;\n    const height = this.uniformParams.resolution[1] * window.devicePixelRatio;\n\n    this.presentationSize = {\n      width,\n      height,\n      depthOrArrayLayers: this.depthOrArrayLayers,\n    };\n\n    this.canvas.width = width;\n    this.canvas.height = height;\n\n    this.context.presentationContext.configure({\n      device: this.context.device,\n      format: this.context.presentationFormat,\n      alphaMode: 'opaque',\n    });\n\n    const resizeObserver = new ResizeObserver(entries => {", "      if (!Array.isArray(entries)) {\n        return;\n      }\n\n      this.resize([entries[0].contentRect.width, entries[0].contentRect.height]);\n    });\n    resizeObserver.observe(this.canvas);\n  }\n\n  private resize(newResolution: Vec2) {\n    if (!vec2.equals(this.uniformParams.resolution, newResolution)) {\n      this.uniformParams.resolution = newResolution;\n\n      const width = this.uniformParams.resolution[0] * window.devicePixelRatio;\n      const height = this.uniformParams.resolution[1] * window.devicePixelRatio;\n\n      this.canvas.width = width;\n      this.canvas.height = height;\n      this.presentationSize = {\n        width,\n        height,\n        depthOrArrayLayers: this.depthOrArrayLayers,\n      };\n      this.reCreateRenderTargets();\n    }\n  }\n\n  private reCreateRenderTargets() {", "    if (!vec2.equals(this.uniformParams.resolution, newResolution)) {\n      this.uniformParams.resolution = newResolution;\n\n      const width = this.uniformParams.resolution[0] * window.devicePixelRatio;\n      const height = this.uniformParams.resolution[1] * window.devicePixelRatio;\n\n      this.canvas.width = width;\n      this.canvas.height = height;\n      this.presentationSize = {\n        width,\n        height,\n        depthOrArrayLayers: this.depthOrArrayLayers,\n      };\n      this.reCreateRenderTargets();\n    }\n  }\n\n  private reCreateRenderTargets() {", "    if (this.renderTarget) {\n      this.renderTarget.destroy();\n    }\n    if (this.depthTarget) {\n      this.depthTarget.destroy();\n    }\n\n    /* render target */\n    this.renderTarget = this.context.device.createTexture({\n      size: this.presentationSize,\n      sampleCount: this.sampleCount,\n      format: this.context.presentationFormat,\n      usage: GPUTextureUsage.RENDER_ATTACHMENT,\n    });\n    this.renderTargetView = this.renderTarget.createView();\n\n    /* depth target */\n    this.depthTarget = this.context.device.createTexture({\n      size: this.presentationSize,\n      sampleCount: this.sampleCount,\n      format: 'depth24plus-stencil8',\n      usage: GPUTextureUsage.RENDER_ATTACHMENT,\n    });\n    this.depthTargetView = this.depthTarget.createView();\n  }\n\n  private getUniformParamsArray(): ArrayBuffer {\n    const uniformParamsArray = new ArrayBuffer(32);\n    new Uint32Array(uniformParamsArray, 0, 2).set(this.uniformParams.resolution);\n    new Float32Array(uniformParamsArray, 16, 3).set(this.uniformParams.cameraPosition);\n    return uniformParamsArray;\n  }\n\n  private async initializeResources() {\n    this.uniformParamsBuffer = createBuffer(\n      this.getUniformParamsArray(),\n      GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n      this.context.device,\n    );\n\n    const bindGroupLayout = new WebGPUBindGroupLayout();\n    bindGroupLayout.create({\n      device: this.context.device,\n      entries: [\n        {\n          binding: 0,\n          visibility: GPUShaderStage.FRAGMENT,\n          buffer: {\n            type: 'uniform',\n          },\n        },\n      ],\n    });\n\n    this.uniformParamsGroup = new WebGPUBindGroup();\n    this.uniformParamsGroup.create({\n      device: this.context.device,\n      bindGroupLayout,\n      entries: [\n        {\n          binding: 0,\n          resource: {\n            buffer: this.uniformParamsBuffer,\n          },\n        },\n      ],\n    });\n\n    const pipelineLayout = new WebGPUPipelineLayout();\n    pipelineLayout.create({\n      device: this.context.device,\n      bindGroupLayouts: [bindGroupLayout],\n    });\n\n    this.renderPipeline = new WebGPURenderPipeline();\n    await this.renderPipeline.create({\n      device: this.context.device,\n      vertexShaderFile: './shaders/basic.vert.wgsl',\n      fragmentShaderFile: './shaders/basic.frag.wgsl',\n      fragmentTargets: [{ format: this.context.presentationFormat }],\n      sampleCount: this.sampleCount,\n      pipelineLayout,\n    });\n  }\n\n  private updateUniformBuffer() {\n    this.context.queue.writeBuffer(this.uniformParamsBuffer, 0, this.getUniformParamsArray());\n  }\n\n  public async start() {\n    await this.initialize();\n    this.reCreateRenderTargets();\n    await this.initializeResources();\n    this.currentTime = performance.now();\n    this.update();\n  }\n\n  private update = () => {\n    const beginFrameTime = performance.now();\n    const duration = beginFrameTime - this.currentTime;\n    this.currentTime = beginFrameTime;\n\n    this.uniformParams.cameraPosition = this.camera.position;\n\n    this.render(duration);\n    window.requestAnimationFrame(this.update);\n    const endFrameTime = performance.now();\n    const frameDuration = endFrameTime - beginFrameTime;\n  };\n\n  private render(deltaTime: number) {\n    // this.computePass(deltaTime);\n    this.renderPass();\n  }\n\n  private renderPass() {\n    this.updateUniformBuffer();\n    const renderPassDesc: GPURenderPassDescriptor = {\n      colorAttachments: [\n        {\n          view: this.sampleCount > 1 ? this.renderTargetView : this.context.presentationContext.getCurrentTexture().createView(),\n          resolveTarget: this.sampleCount > 1 ? this.context.presentationContext.getCurrentTexture().createView() : undefined,\n          clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n          loadOp: 'clear',\n          storeOp: 'discard',\n        },\n      ],\n      // depthStencilAttachment: {\n      //   view: this.depthTargetView,\n\n      //   depthLoadOp: 'clear',\n      //   depthClearValue: 1.0,\n      //   depthStoreOp: 'store',\n\n      //   stencilLoadOp: 'clear',\n      //   stencilClearValue: 0,\n      //   stencilStoreOp: 'store',\n      // },\n    };\n\n    const commandEncoder = this.context.device.createCommandEncoder();\n    const passEncoder = commandEncoder.beginRenderPass(renderPassDesc);\n    passEncoder.setPipeline(this.renderPipeline.pipeline);\n    passEncoder.setBindGroup(0, this.uniformParamsGroup.bindGroup);\n    passEncoder.draw(3, 1, 0, 0); // only 1 triangle\n    passEncoder.end();\n\n    this.context.queue.submit([commandEncoder.finish()]);\n  }\n\n  // private computePass(deltaTime: number) {\n  //   const commandEncoder = this.context.device.createCommandEncoder();\n  //   const passEncoder = commandEncoder.beginComputePass();\n  //   passEncoder.setPipeline(this.computePipeline);\n\n  //   passEncoder.end();\n  //   this.context.queue.submit([commandEncoder.finish()]);\n  // }\n}\n"]}
{"filename": "src/webgpu/webgpushader.ts", "chunked_list": ["export function createShaderModuleFromString(code: string, device: GPUDevice) {\n  return device.createShaderModule({ code });\n}\n\nexport async function createShaderModuleFromPath(path: string, device: GPUDevice) {\n  const res = await fetch(path);\n  const code = await res.text();\n  return createShaderModuleFromString(code, device);\n}\n"]}
{"filename": "src/webgpu/webgpupipelinelayout.ts", "chunked_list": ["import { WebGPUResourceOptions } from './types';\nimport { WebGPUBindGroupLayout } from './webgpubindgrouplayout';\n\nexport type WebGPUPipelineLayoutOptions = WebGPUResourceOptions & {\n  bindGroupLayouts: WebGPUBindGroupLayout[];\n};\n\nexport class WebGPUPipelineLayout {\n  private pipelineLayout: GPUPipelineLayout;\n\n  public get layout() {\n    return this.pipelineLayout;\n  }\n\n  public create(options: WebGPUPipelineLayoutOptions) {\n    this.pipelineLayout = options.device.createPipelineLayout({\n      label: options.label,\n      bindGroupLayouts: options.bindGroupLayouts.map(bgl => bgl.layout),\n    });\n  }\n}\n"]}
{"filename": "src/webgpu/camera.ts", "chunked_list": ["import { Vec2, Vec3, vec2 } from 'wgpu-matrix';\n\nexport class Camera {\n  private currentMousePosition: Vec2 = vec2.create();\n\n  constructor(canvas: HTMLCanvasElement, private cameraPosition: Vec3, private cameraTarget: Vec3) {\n    canvas.addEventListener('wheel', this.onMouseWheel);\n    canvas.addEventListener('mousemove', this.onMouseMove);\n    document.addEventListener('keydown', this.onKeyDown);\n    document.addEventListener('keyup', this.onKeyup);\n  }\n\n  private onMouseWheel = (event: WheelEvent) => {\n    this.cameraPosition[2] = this.cameraPosition[2] + event.deltaY * 0.01;\n  };\n\n  private onMouseMove = (event: MouseEvent) => {\n    // const currentPos: Vec2 = [event.clientX, event.clientY];", "    // if (event.buttons === 1) {\n    //   const offset = vec2.subtract(currentPos, this.currentMousePosition);\n    //   vec2.scale(offset, 0.0025, offset);\n    //   vec2.add(this.cameraPosition, [offset[0], offset[1], 0], this.cameraPosition);\n    //   //console.log(cameraPosition);\n    // }\n    // this.currentMousePosition = currentPos;\n  };\n\n  private onKeyDown = (event: KeyboardEvent) => {\n    const movementSpeed = 0.25;\n\n    let x = this.cameraPosition[0];\n    let y = this.cameraPosition[1];\n\n    switch (event.key) {\n      case 'w':\n        y += movementSpeed;\n        break;\n      case 's':\n        y -= movementSpeed;\n        break;\n      case 'a':\n        x -= movementSpeed;\n        break;\n      case 'd':\n        x += movementSpeed;\n        break;\n    }\n\n    this.cameraPosition[0] = x;\n    this.cameraPosition[1] = y;\n  };\n\n  private onKeyup = (event: KeyboardEvent) => {\n    //\n  };\n\n  public get position(): Vec3 {\n    return this.cameraPosition;\n  }\n\n  public get target(): Vec3 {\n    return this.cameraTarget;\n  }\n}\n"]}
