{"filename": "src/loadPromptConfig.ts", "chunked_list": ["import { Config } from \"./types.js\";\nimport { join as pathJoin } from \"node:path\";\nimport { AppError } from \"./errors.js\";\nimport { fileURLToPath } from \"node:url\";\nimport { dirname, parse } from \"node:path\";\nimport { readdir } from \"node:fs/promises\";\n\nasync function readFilesInDirectory(path: string) {\n  try {\n    const files = await readdir(path);\n    return files\n      .filter((f) => f.endsWith(\".js\") || f.endsWith(\".mjs\"))\n      .map((filename) => pathJoin(path, filename));", "  try {\n    const files = await readdir(path);\n    return files\n      .filter((f) => f.endsWith(\".js\") || f.endsWith(\".mjs\"))\n      .map((filename) => pathJoin(path, filename));\n  } catch (err) {\n    if (err instanceof Error && \"code\" in err) {\n      if (err.code == \"ENOENT\") {\n        // ignore error: ENOENT: no such file or directory\n        return [];\n      }\n    }\n    throw err;\n  }\n}\n\n// Returns a path relative to import.meta.filename", "export function sourceRelativePath(\n  meta: { url: string },\n  ...relPaths: string[]\n) {\n  const __dirname = dirname(fileURLToPath(meta.url));\n  return pathJoin(__dirname, ...relPaths);\n}\n\nexport async function loadFromPath(path: string) {\n  const promptConfig = await import(path);\n  // TODO: validate promptConfig?\n  return promptConfig.default;\n}\n", "export async function loadFromPath(path: string) {\n  const promptConfig = await import(path);\n  // TODO: validate promptConfig?\n  return promptConfig.default;\n}\n\nexport async function loadPromptConfig(promptId: string, config: Config) {\n  try {\n    const promptConfig = await Promise.any([\n      loadFromPath(sourceRelativePath(import.meta, `./prompts/${promptId}.js`)),\n      loadFromPath(pathJoin(config.paths.data, `${promptId}.mjs`)),\n    ]);\n    return promptConfig;", "  } catch (err) {\n    throw new AppError({\n      message: `Could not find prompt ${promptId}. Are you sure it is a builtin prompt or that ${config.paths.data}/${promptId}.mjs exists?`,\n    });\n  }\n}\n\nexport async function listPrompts(config: Config) {\n  const [localFiles, builtinFiles] = await Promise.all(\n    [\n      sourceRelativePath(import.meta, `./prompts`),\n      pathJoin(config.paths.data),\n    ].map(readFilesInDirectory)\n  );\n  const allFiles = [...localFiles, ...builtinFiles];\n  const allPromptConfigs = await Promise.all(allFiles.map(loadFromPath));\n\n  return allPromptConfigs.map((config, i) => {\n    const name = parse(allFiles[i]).name;\n    return {\n      name,\n      description: config.description,\n    };\n  });\n}\n"]}
{"filename": "src/config.ts", "chunked_list": ["import { ConfigError } from \"./errors.js\";\nimport { APPNAME, Config } from \"./types.js\";\nimport envPaths from \"env-paths\";\nimport { homedir } from \"node:os\";\nimport { join as pathJoin } from \"node:path\";\nimport createDebug from \"debug\";\n\nconst debug = createDebug(`${APPNAME}:config`);\n\nfunction getEnvOrThrow(key: string) {\n  const val = process.env[key];", "\nfunction getEnvOrThrow(key: string) {\n  const val = process.env[key];\n  if (typeof val === \"undefined\") {\n    throw new ConfigError({\n      message: `Please set the ${key} environment variable.`,\n    });\n  }\n  return val;\n}\n\nconst paths = envPaths(APPNAME, { suffix: \"\" });\n", "export function loadConfig(): Config {\n  const config = {\n    openai: {\n      apiKey: getEnvOrThrow(\"OPENAI_API_KEY\"),\n    },\n    paths: {\n      data: pathJoin(homedir(), `.${APPNAME}`),\n      cache: paths.cache,\n    },\n    useCache: true,\n  };\n  debug(config);\n  return config;\n}\n"]}
{"filename": "src/openaiModels.ts", "chunked_list": ["import { Model, ModelType } from \"./types.js\";\n\nexport const GPT_3_5Turbo: Model = {\n  id: \"gpt-3.5-turbo\",\n  type: ModelType.Chat,\n  maxTokens: 4096,\n};\n\nconst allModels = [GPT_3_5Turbo];\n", "const allModels = [GPT_3_5Turbo];\n\nconst modelsById: Map<string, Model> = new Map(\n  allModels.reduce((acc: [string, Model][], ele: Model): [string, Model][] => {\n    return [...acc, [ele.id, ele]];\n  }, [])\n);\n\nexport const defaultModel = GPT_3_5Turbo;\n", "export const defaultModel = GPT_3_5Turbo;\n\nexport default modelsById;\n"]}
{"filename": "src/types.ts", "chunked_list": ["export const APPNAME = \"clevercli\";\n\nexport interface ParsedResponse {\n  message: string;\n  meta?: object;\n}\n\nexport enum ModelType {\n  Chat,\n  Completion,\n}\n", "export interface Model {\n  id: string;\n  type: ModelType;\n  maxTokens: number;\n}\n\nexport interface PromptConfiguration {\n  createPrompt(input: string): string;\n  parseResponse?(response: string, input: string): ParsedResponse;\n  model?: string;\n  description?: string;\n}\n", "export interface Config {\n  openai: {\n    apiKey: string;\n  };\n  useCache: boolean;\n  paths: {\n    data: string;\n    cache: string;\n  };\n}\n"]}
{"filename": "src/executePrompt.ts", "chunked_list": ["import {\n  ChatCompletionRequestMessageRoleEnum,\n  Configuration as OpenAIConfiguration,\n  OpenAIApi,\n} from \"openai\";\nimport models, { defaultModel } from \"./openaiModels.js\";\nimport { ApiError, AppError } from \"./errors.js\";\nimport { Config, Model, ParsedResponse, PromptConfiguration } from \"./types.js\";\nimport KeyValueStore from \"./kvs/abstract.js\";\nimport { openAIQuery } from \"./openai.js\";", "import KeyValueStore from \"./kvs/abstract.js\";\nimport { openAIQuery } from \"./openai.js\";\nimport { asyncIterableToArray } from \"./utils.js\";\n\nfunction defaultParseResponse(content: string, _input: string): ParsedResponse {\n  return { message: content };\n}\n\nfunction toModel(promptConfig: PromptConfiguration): Model {\n  const model = promptConfig.model\n    ? models.get(promptConfig.model)\n    : defaultModel;", "function toModel(promptConfig: PromptConfiguration): Model {\n  const model = promptConfig.model\n    ? models.get(promptConfig.model)\n    : defaultModel;\n  if (!model) {\n    throw new AppError({\n      message: `Could not find model \"${promptConfig.model}\"`,\n    });\n  }\n  return model;\n}\n\nexport async function* executePromptStream(\n  promptConfig: PromptConfiguration,\n  input: string,\n  config: Config,\n  cache?: KeyValueStore<string, string>\n): AsyncGenerator<string> {\n  const model = toModel(promptConfig);\n  const formattedPrompt = promptConfig.createPrompt(input);\n  const cacheKey = `${model.id}-${formattedPrompt}`;\n", "  if (cache) {\n    const cachedResponse = await cache.get(cacheKey);\n    if (cachedResponse) {\n      yield cachedResponse;\n      return;\n    }\n  }\n  const stream = openAIQuery(model, formattedPrompt, config);\n  const chunks = [];\n  for await (const chunk of stream) {\n    chunks.push(chunk);\n    yield chunk;\n  }", "  if (cache) {\n    const response = chunks.join(\"\");\n    await cache.set(cacheKey, response);\n  }\n}\n\nexport async function executePrompt(\n  promptConfig: PromptConfiguration,\n  input: string,\n  config: Config,\n  cache?: KeyValueStore<string, string>\n): Promise<ParsedResponse> {\n  const model = toModel(promptConfig);\n  const parseResponse = promptConfig.parseResponse ?? defaultParseResponse;\n  const response = (\n    await asyncIterableToArray(\n      executePromptStream(promptConfig, input, config, cache)\n    )\n  ).join(\"\");\n  return parseResponse(response, input);\n}\n\nexport default executePrompt;\n"]}
{"filename": "src/openai.ts", "chunked_list": ["import { Config, Model } from \"./types.js\";\nimport {\n  ChatCompletionRequestMessageRoleEnum,\n  Configuration,\n  OpenAIApi,\n} from \"openai\";\nimport { ApiError } from \"./errors.js\";\nimport { asyncIterableToArray } from \"./utils.js\";\n\n// https://2ality.com/2018/04/async-iter-nodejs.html#generator-%231%3A-from-chunks-to-lines", "\n// https://2ality.com/2018/04/async-iter-nodejs.html#generator-%231%3A-from-chunks-to-lines\nasync function* chunksToLines(chunksAsync: AsyncGenerator<string>) {\n  let previous = \"\";\n  for await (const chunk of chunksAsync) {\n    const bufferChunk = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk);\n    previous += bufferChunk;\n    let eolIndex;\n    while ((eolIndex = previous.indexOf(\"\\n\")) >= 0) {\n      // line includes the EOL\n      const line = previous.slice(0, eolIndex + 1).trimEnd();", "    while ((eolIndex = previous.indexOf(\"\\n\")) >= 0) {\n      // line includes the EOL\n      const line = previous.slice(0, eolIndex + 1).trimEnd();\n      if (line === \"data: [DONE]\") break;\n      if (line.startsWith(\"data: \")) {\n        yield line.slice(\"data: \".length);\n      }\n      previous = previous.slice(eolIndex + 1);\n    }\n  }\n}\n", "// Wraps openai and provides streaming API + auto selection of api function based on model\nexport async function* openAIQuery(\n  model: Model,\n  prompt: string,\n  config: Config\n): AsyncGenerator<string> {\n  const openai = new OpenAIApi(\n    new Configuration({\n      apiKey: config.openai.apiKey,\n    })\n  );", "  // TODO: select right api route/function based on model\n  const opts = {\n    stream: true,\n    model: model.id,\n    messages: [\n      {\n        role: ChatCompletionRequestMessageRoleEnum.System,\n        content: prompt,\n      },\n    ],\n  };\n  const res = await (async () => {", "    try {\n      return await openai.createChatCompletion(opts, {\n        responseType: \"stream\",\n      });\n    } catch (err) {\n      if (err instanceof Error) {\n        if (\"isAxiosError\" in err) {\n          /* @ts-ignore */\n          const data = await asyncIterableToArray(err.response.data);\n          const error = JSON.parse(data.toString()).error;\n          throw new ApiError(error);\n        }\n      }\n      throw err;\n    }\n  })();\n  /* @ts-ignore */\n  const stream = res.data as IncomingMessage;\n  for await (const chunk of chunksToLines(stream)) {\n    const data = JSON.parse(chunk);\n    const content = data.choices[0].delta.content;\n    // console.log({ json });", "    if (content) {\n      yield content;\n    }\n  }\n}\n"]}
{"filename": "src/errors.ts", "chunked_list": ["const PROGRAMMING_ERROR_CLASSES: Array<typeof Error> = [\n  TypeError,\n  ReferenceError,\n  RangeError,\n  SyntaxError,\n];\n\nfunction isProgrammingError(err: unknown) {\n  return PROGRAMMING_ERROR_CLASSES.some((ErrorClass: ErrorConstructor) => {\n    return err instanceof ErrorClass;\n  });\n}\n", "export class AppError extends Error {\n  cause?: Error;\n  exitCode = 1;\n\n  private static wrap(err: unknown) {\n    // We don't wrap errors that indicate unexpected/programming errors\n    if (isProgrammingError(err)) {\n      return err;\n    }\n    const cause = err instanceof Error ? err : undefined;\n    return new this({ cause });\n  }\n\n  get name(): string {\n    return this.constructor.name;\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      cause: this.cause,\n    };\n  }\n\n  toString(): string | this {\n    const printCause = this.cause\n      ? () => {\n          return `(cause: ${this.cause})`;\n        }\n      : () => \"\";\n    return `${this.name}: ${this.message}${printCause()}`;\n  }\n\n  constructor(opts?: { message?: string; cause?: Error }) {\n    super(opts?.message);\n    this.cause = opts?.cause;\n  }\n}\n", "export class ApiError extends AppError {\n  type: string;\n  param: string;\n  code: string;\n  constructor(data: {\n    message: string;\n    type: string;\n    param: string;\n    code: string;\n  }) {\n    super({ message: data.message });\n    this.message = data.message;\n    this.type = data.type;\n    this.param = data.param;\n    this.code = data.code;\n  }\n  toString(): string {\n    return `${this.name}: ${this.message} (type = ${this.type}, param = ${this.param}, code = ${this.code})`;\n  }\n}", "export class ConfigError extends AppError {}\n"]}
{"filename": "src/utils.ts", "chunked_list": ["export async function asyncIterableToArray<T>(\n  asyncIterator: AsyncIterable<T>\n): Promise<T[]> {\n  const arr = [];\n  for await (const ele of asyncIterator) {\n    arr.push(ele);\n  }\n  return arr;\n}\n"]}
{"filename": "src/index.ts", "chunked_list": ["import { executePrompt, executePromptStream } from \"./executePrompt.js\";\nimport { loadConfig } from \"./config.js\";\nimport { loadPromptConfig, listPrompts } from \"./loadPromptConfig.js\";\nimport { APPNAME } from \"./types.js\";\nimport FileSystemKVS from \"./kvs/kvs-filesystem.js\";\nimport { AppError } from \"./errors.js\";\nimport { readFileSync } from \"node:fs\";\n\nfunction parseArgs(argv: string[]) {\n  const [_nodeBin, _jsFile, promptId, ...rest] = argv;\n  const input = rest.join(\" \");\n  return { promptId, input };\n}\n", "function parseArgs(argv: string[]) {\n  const [_nodeBin, _jsFile, promptId, ...rest] = argv;\n  const input = rest.join(\" \");\n  return { promptId, input };\n}\n\nfunction printUsageAndExit() {\n  console.log(\"Usage:\");\n  console.log(`$ ${APPNAME} <promptType> <input>`);\n  console.log(`$ ${APPNAME} --list`);\n  console.log(\"\");\n  console.log(\"Example: \");\n  console.log(\"\");\n  console.log(`$ ${APPNAME} eli5 \"what are large language models?\"`);\n  process.exit(1);\n}\n", "function getInput(argvInput: string) {\n  try {\n    const stdinInput = readFileSync(process.stdin.fd, \"utf-8\");\n    // console.log({ stdinInput });\n    return `${argvInput} ${stdinInput}`;\n  } catch (err) {\n    return argvInput;\n  }\n}\n\nexport async function cli() {", "export async function cli() {\n  try {\n    const config = loadConfig();\n    const { promptId, input: argvInput } = parseArgs(process.argv);\n    if (promptId === \"--list\") {\n      const prompts = await listPrompts(config);\n      console.log(\n        prompts\n          .map((p) => {\n            const description = p.description ? `: ${p.description}` : \"\";\n            return `${p.name}${description}`;\n          })\n          .join(\"\\n\")\n      );\n      return;", "    } else if (promptId && promptId.startsWith(\"--\")) {\n      printUsageAndExit();\n    }\n    const input = getInput(argvInput);\n    if (!promptId || !input) {\n      printUsageAndExit();\n    }\n    const promptConfig = await loadPromptConfig(promptId, config);\n    const cache = config.useCache\n      ? new FileSystemKVS({ baseDir: config.paths.cache })\n      : undefined;\n    const stream = executePromptStream(promptConfig, input, config, cache);\n    for await (const chunk of stream) {\n      process.stdout.write(chunk);\n    }\n    process.stdout.write(\"\\n\");", "  } catch (err) {\n    if (err instanceof AppError) {\n      console.error(err.toString());\n      process.exit(err.exitCode);\n    }\n    console.error(err);\n    process.exit(1);\n  }\n}\n\nexport default cli;\n"]}
{"filename": "src/kvs/kvs-memory.ts", "chunked_list": ["import KeyValueStore from \"./abstract.js\";\n\nexport default class MemoryKVS<K, V> extends KeyValueStore<K, V> {\n  map: Map<K, string>;\n\n  constructor() {\n    super();\n    this.map = new Map<K, string>();\n  }\n  async set(key: K, value: V) {\n    this.map.set(key, `${value}`);\n  }\n  async get(key: K): Promise<string | undefined> {\n    return this.map.get(key);\n  }\n  async delete(key: K) {\n    this.map.delete(key);\n  }\n}\n"]}
{"filename": "src/kvs/index.test.ts", "chunked_list": ["import { test } from \"vitest\";\nimport { KeyValueStore, FileSystemKVS, MemoryKVS } from \"./index.js\";\n\nfunction runTestForKvs(\n  KvsClass: new (opts: any) => KeyValueStore<string, string>\n) {\n  const testData = [\n    [\"somekey\", \"somevalue\"],\n    ['some/  crazy/\"key !!\ud83d\ude02', \"somevalue\"],\n    [\"well\", 'some crazy/\"value !!\ud83d\ude02'],\n    [\"somekeythatgetsoverwritten\", \"initial value\"],\n    [\"somekeythatgetsoverwritten\", \"final value\"],\n  ];\n  const prefix = `kvs: ${KvsClass.name}:`;\n  test(`${prefix} integration test`, async ({ expect }) => {\n    const kvs = new KvsClass({});", "    for (const [k, v] of testData) {\n      await kvs.set(k, v);\n      let retrievedVal = await kvs.get(k);\n      expect(retrievedVal).toBe(v);\n    }\n\n    const map = new Map();\n    testData.forEach(([k, v]) => map.set(k, v));\n    for (const [k, _] of testData) {\n      const retrievedVal = await kvs.get(k);\n      expect(retrievedVal).toBe(map.get(k));\n    }\n\n    expect(await kvs.get(\"key does not exist\")).toBeUndefined();\n    await kvs.delete(\"somekey\");\n    expect(await kvs.get(\"somekey\")).toBeUndefined();\n  });\n}\n\nrunTestForKvs(MemoryKVS);\nrunTestForKvs(FileSystemKVS);\n", "    for (const [k, _] of testData) {\n      const retrievedVal = await kvs.get(k);\n      expect(retrievedVal).toBe(map.get(k));\n    }\n\n    expect(await kvs.get(\"key does not exist\")).toBeUndefined();\n    await kvs.delete(\"somekey\");\n    expect(await kvs.get(\"somekey\")).toBeUndefined();\n  });\n}\n\nrunTestForKvs(MemoryKVS);\nrunTestForKvs(FileSystemKVS);\n"]}
{"filename": "src/kvs/kvs-filesystem.ts", "chunked_list": ["import { mkdtemp, unlink, readFile, writeFile } from \"node:fs/promises\";\nimport mkdirp from \"mkdirp\";\nimport { join as pathJoin } from \"path\";\nimport { createHash } from \"node:crypto\";\nimport KeyValueStore from \"./abstract.js\";\nimport { tmpdir } from \"node:os\";\n\nexport default class FileSystemKVS<K, V> extends KeyValueStore<K, V> {\n  baseDir: string;\n  // tmpPath: string | undefined;\n  waitInit: Promise<void>;\n\n  constructor(opts: { baseDir?: string }) {\n    super();\n    this.baseDir = opts.baseDir ?? \"\";\n    this.waitInit = this._init();\n  }\n\n  private async _init() {", "    if (this.baseDir) {\n      // ensure base dir exists\n      await mkdirp(this.baseDir);\n      return;\n    }\n    // create temporary dir\n    const tmpPath = await mkdtemp(pathJoin(tmpdir(), \"filesystem-kvs-\"));\n    this.baseDir = tmpPath;\n  }\n\n  private _keyToFilename(key: K): string {\n    return createHash(\"sha1\").update(`${key}`).digest().toString(\"hex\");\n  }\n\n  private _keyToFilePath(key: K): string {", "    // if (!this.baseDir) throw new TypeError('_keyToFilePath');\n    const baseDir = this.baseDir;\n    const filePath = pathJoin(baseDir, this._keyToFilename(key));\n    // console.log({ filePath });\n    return filePath;\n  }\n\n  async set(key: K, value: V) {\n    await this.waitInit;\n    await writeFile(this._keyToFilePath(key), `${value}`);\n  }\n\n  async get(key: K): Promise<string | undefined> {\n    await this.waitInit;\n    const filePath = this._keyToFilePath(key);", "    try {\n      const val = await readFile(filePath, \"utf8\");\n      return val;\n    } catch (err) {\n      return;\n    }\n  }\n\n  async delete(key: K) {\n    await this.waitInit;\n    try {\n      await unlink(this._keyToFilePath(key));\n    } catch {}\n  }\n}\n", "    try {\n      await unlink(this._keyToFilePath(key));\n    } catch {}\n  }\n}\n"]}
{"filename": "src/kvs/index.ts", "chunked_list": ["export { default as FileSystemKVS } from \"./kvs-filesystem.js\";\nexport { default as MemoryKVS } from \"./kvs-memory.js\";\nexport { default as KeyValueStore } from \"./abstract.js\";\n"]}
{"filename": "src/kvs/abstract.ts", "chunked_list": ["export default abstract class KeyValueStore<K, V> {\n  // constructor(opts?: {}) {}\n  abstract set(key: K, value: V): Promise<void>;\n  abstract get(key: K): Promise<string | undefined>;\n  abstract delete(key: K): Promise<void>;\n}\n"]}
{"filename": "src/bin/cli.ts", "chunked_list": ["#!/usr/bin/env node\nimport { cli } from \"../index.js\";\n\nawait cli();\n"]}
{"filename": "src/prompts/convert-to-rust.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description: \"Converts source file to Rust\",\n  createPrompt(input: string) {\n    return `Rewrite this file in Rust. Only output valid code, no comments. ${input}\\n\\n`;\n  },\n};\n\nexport default promptConfiguration;", "\nexport default promptConfiguration;\n"]}
{"filename": "src/prompts/unix-command.ts", "chunked_list": ["export default {\n  description: \"Outputs Unix commands\",\n  createPrompt(input: string) {\n    return `Reply only with commands that can be run in a UNIX Bash shell. DO NOT give an explanation of what the command does. Reply as if your answer is piped directly to a bash. Here's what the command should do: ${input}`;\n  },\n};\n"]}
{"filename": "src/prompts/jsdoc.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description: \"Adds JSDoc comments to exported functions.\",\n  createPrompt(input: string) {\n    return `Add JSDoc comments to exported functions. Don't include types if they are already specified in TypeScript.\\n\\n${input}`;\n  },\n};\n\nexport default promptConfiguration;", "\nexport default promptConfiguration;\n"]}
{"filename": "src/prompts/refactor.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description: \"Asks ChatGPT to refactor code in a file.\",\n  createPrompt(input: string) {\n    return `Help me refactor this code (only output code and comments): ${input}.\\n###\\n`;\n  },\n};\n\nexport default promptConfiguration;", "\nexport default promptConfiguration;\n"]}
{"filename": "src/prompts/synonyms.ts", "chunked_list": ["export default {\n  description: \"List synonyms for the input words\",\n  createPrompt(input: string) {\n    return `Ouput a comma separated list of synonyms for: ${input}.\\n###\\n`;\n  },\n};\n"]}
{"filename": "src/prompts/joke.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description: \"Tells a joke about the topic.\",\n  createPrompt(input: string) {\n    return `Tell me a funny joke on this topic: ${input}.\\n###\\n`;\n  },\n};\n\nexport default promptConfiguration;", "\nexport default promptConfiguration;\n"]}
{"filename": "src/prompts/poem.ts", "chunked_list": ["export default {\n  description: \"Asks ChatGPT to write a small poem on the topic.\",\n  createPrompt(input: string) {\n    return `Write a small poem about: ${input}.\\n###\\n`;\n  },\n};\n"]}
{"filename": "src/prompts/recipe.ts", "chunked_list": ["export default {\n  description:\n    \"Outputs recipe suggestions given a list of available ingredients.\",\n  createPrompt(input: string) {\n    return `Give me some recipe suggestions knowing that I have the following ingredients available: ${input}.\\n###\\n`;\n  },\n};\n"]}
{"filename": "src/prompts/summarize.ts", "chunked_list": ["export default {\n  description: \"Outputs a short summary of the text.\",\n  createPrompt(input: string) {\n    return `Give me a short summary of this text: ${input}.\\n###\\n`;\n  },\n};\n"]}
{"filename": "src/prompts/convert-to-typescript.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description: \"Converts source file to TypeScript\",\n  createPrompt(input: string) {\n    return `Rewrite this file in TypeScript. Only output valid code, no comments. ${input}\\n\\n`;\n  },\n};\n\nexport default promptConfiguration;", "\nexport default promptConfiguration;\n"]}
{"filename": "src/prompts/regex.ts", "chunked_list": ["import { PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description:\n    \"Gives a JavaScript compatible RegEx that matches the input examples.\",\n  createPrompt(input: string) {\n    return `Output a JavaScript regex that matches the following examples: ${input}.\\n###\\n`;\n  },\n};\n", "};\n\nexport default promptConfiguration;\n"]}
{"filename": "src/prompts/eli5.ts", "chunked_list": ["import { ParsedResponse, PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description: \"Explain Me Like I'm 5\",\n  createPrompt(input: string) {\n    return `Provide a very detailed explanation but like I am 5 years old (ELI5) on this topic: ${input}.\\n###\\n`;\n  },\n  parseResponse(response: string, _input: string): ParsedResponse {\n    return { message: response };\n  },", "    return { message: response };\n  },\n};\n\nexport default promptConfiguration;\n"]}
{"filename": "src/prompts/ask.ts", "chunked_list": ["import { ParsedResponse, PromptConfiguration } from \"../types.js\";\n\nconst promptConfiguration: PromptConfiguration = {\n  description: \"Just passes through the input directly to ChatGPT.\",\n  createPrompt(input: string) {\n    return input;\n  },\n  parseResponse(response: string, _input: string): ParsedResponse {\n    return { message: response };\n  },", "    return { message: response };\n  },\n};\n\nexport default promptConfiguration;\n"]}
