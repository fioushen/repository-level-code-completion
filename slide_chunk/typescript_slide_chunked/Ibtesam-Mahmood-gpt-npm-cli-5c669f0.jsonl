{"filename": "src/index.ts", "chunked_list": ["#! /usr/bin/env node\n\nimport { Command } from \"commander\";\nimport SummaryProgram from \"./programs/summary-program.js\";\nimport figlet from \"figlet\";\nimport ConfigureProgram from \"./programs/configure/configure-program.js\";\nimport TranslateProgram from \"./programs/translate-program.js\";\nimport UnderstandProgram from \"./programs/understand-program.js\";\nimport ChatProgram from \"./programs/chat-program.js\";\nimport PromptProgram from \"./programs/prompt-program.js\";", "import ChatProgram from \"./programs/chat-program.js\";\nimport PromptProgram from \"./programs/prompt-program.js\";\n\nconst version = \"0.1.5\";\nconst description =\n  \"A super charged CLI for interfacing with GPT-3 and other AI services\";\n\nasync function main(): Promise<void> {\n  console.log(figlet.textSync(\"GPT CLI\"));\n\n  // Create a new command instance for the program and configure it with root commands\n  const cliApp = new Command()\n    .version(version)\n    .description(description)\n    .option(\"-d, --debug\", \"toggles verbose logging\", false);\n\n  // Configure the help command\n  cliApp.configureHelp({\n    sortSubcommands: true,\n    sortOptions: true,\n    showGlobalOptions: true,\n    subcommandDescription(cmd) {\n      return cmd.description();\n    },\n    subcommandTerm: (cmd: Command): string => {\n      let term = cmd.name();", "      if (cmd.aliases().length > 0) {\n        term += `, ${cmd.aliases().join(\", \")}`;\n      }\n      return term;\n    },\n  });\n\n  // Confifgure the programs\n  new SummaryProgram().configure(cliApp);\n  new ConfigureProgram().configure(cliApp);\n  new TranslateProgram().configure(cliApp);\n  new UnderstandProgram().configure(cliApp);\n  new ChatProgram().configure(cliApp);\n  new PromptProgram().configure(cliApp);\n\n  // Parse the args for the program\n  await cliApp.parseAsync(process.argv);\n}\n\nmain();\n"]}
{"filename": "src/langchain/open-ai-chat-helper.ts", "chunked_list": ["import { initializeAgentExecutor, Tool } from \"langchain/agents\";\nimport { LLMChain, ChatVectorDBQAChain } from \"langchain/chains\";\nimport { LLM } from \"langchain/llms\";\nimport { BufferMemory } from \"langchain/memory\";\nimport {\n  ChatPromptTemplate,\n  HumanMessagePromptTemplate,\n  SystemMessagePromptTemplate,\n} from \"langchain/prompts\";\nimport { Calculator, SerpAPI } from \"langchain/tools\";", "} from \"langchain/prompts\";\nimport { Calculator, SerpAPI } from \"langchain/tools\";\nimport { VectorStore } from \"langchain/vectorstores\";\nimport * as cliChat from \"./helpers/cli-chat-helper.js\";\nimport CurrencyConversionTool from \"./tools/currency-conversion-tool.js\";\nconst { Document: LangDocument } = await import(\"langchain/document\");\nconst { loadSummarizationChain } = await import(\"langchain/chains\");\nconst { OpenAIChat } = await import(\"langchain/llms\");\nconst { CallbackManager } = await import(\"langchain/callbacks\");\n\ninterface OpenAiChatHelperInput {\n  model?: string;\n  temperature?: number;\n  verbose?: boolean;\n}\n", "const { CallbackManager } = await import(\"langchain/callbacks\");\n\ninterface OpenAiChatHelperInput {\n  model?: string;\n  temperature?: number;\n  verbose?: boolean;\n}\n\ninterface SummarizationOptions {\n  type: \"map_reduce\" | \"stuff\";\n  split: number;\n}\n", "interface SummarizationOptions {\n  type: \"map_reduce\" | \"stuff\";\n  split: number;\n}\n\ninterface TranslationOptions {\n  source: string;\n  output: string;\n}\n\ninterface AgentToolOptions {\n  tools?: { [name: string]: Tool };\n}\n", "interface AgentToolOptions {\n  tools?: { [name: string]: Tool };\n}\n\nfunction getToolsList(input?: AgentToolOptions) {\n  return Object.values(input?.tools ?? {});\n}\n\nclass OpenAiChatHelper {\n  public model: LLM;\n\n  constructor(input: OpenAiChatHelperInput) {\n    let params = {\n      temperature: input.temperature ?? 0.7,\n      modelName: input.model ?? \"gpt-3.5-turbo\",\n      verbose: input.verbose ?? false,\n      callbackManager: null as any,\n    };\n", "class OpenAiChatHelper {\n  public model: LLM;\n\n  constructor(input: OpenAiChatHelperInput) {\n    let params = {\n      temperature: input.temperature ?? 0.7,\n      modelName: input.model ?? \"gpt-3.5-turbo\",\n      verbose: input.verbose ?? false,\n      callbackManager: null as any,\n    };\n", "    if (params.verbose) {\n      params.callbackManager = OpenAiChatHelper.defaultCallBackManager;\n    }\n\n    this.model = new OpenAIChat(params);\n  }\n\n  public static get defaultCallBackManager() {\n    return CallbackManager.fromHandlers({\n      handleLLMStart: async (llm: { name: string }, prompts: string[]) => {\n        console.log(JSON.stringify(llm, null, 2));\n        console.log(JSON.stringify(prompts, null, 2));\n      },\n      handleLLMEnd: async (output: any) => {\n        console.log(JSON.stringify(output, null, 2));\n      },\n      handleLLMError: async (err: Error) => {\n        console.error(err);\n      },\n    });\n  }\n\n  public static get noCallBackManager() {\n    return CallbackManager.fromHandlers({});\n  }\n\n  /*\n \n     ____                                             \n    / ___| _   _ _ __ ___  _ __ ___   __ _ _ __ _   _ \n    \\___ \\| | | | '_ ` _ \\| '_ ` _ \\ / _` | '__| | | |\n     ___) | |_| | | | | | | | | | | | (_| | |  | |_| |\n    |____/ \\__,_|_| |_| |_|_| |_| |_|\\__,_|_|   \\__, |\n                                                |___/ \n \n*/\n\n  public async summarize(\n    text: string,\n    options: SummarizationOptions = {\n      type: \"map_reduce\",\n      split: 3000,\n    }\n  ): Promise<string> {\n    // Loads in the chain\n    const chain = loadSummarizationChain(this.model, { type: options.type });\n\n    // Create the documents\n    let docs = [];", "    if (options.type === \"map_reduce\") {\n      const { RecursiveCharacterTextSplitter } = await import(\n        \"langchain/text_splitter\"\n      );\n      const textSplitter = new RecursiveCharacterTextSplitter({\n        chunkSize: options.split,\n      });\n      docs = await textSplitter.createDocuments([text]);\n    } else {\n      docs = [new LangDocument({ pageContent: text })];\n    }\n\n    // Summarize\n    const res = await chain.call({\n      input_documents: docs,\n    });\n\n    // Output the result\n    return res.text;\n  }\n\n  /*\n \n     _____                    _       _       \n    |_   _| __ __ _ _ __  ___| | __ _| |_ ___ \n      | || '__/ _` | '_ \\/ __| |/ _` | __/ _ \\\n      | || | | (_| | | | \\__ \\ | (_| | ||  __/\n      |_||_|  \\__,_|_| |_|___/_|\\__,_|\\__\\___|\n                                              \n \n*/\n\n  public async translate(\n    text: string,\n    options: TranslationOptions = {\n      source: \"auto\",\n      output: \"english\",\n    }\n  ): Promise<string> {\n    const template =\n      \"You are a helpful assistant that takes text in {input_language} and only responds with its translation in {output_language}.\";\n    const autoTemplate =\n      \"You are a helpful assistant that detects the language of the input and only responds with its translation in {output_language}.\";\n\n    let promptTemplate = template;", "    if (options.source === \"auto\") {\n      promptTemplate = autoTemplate;\n    }\n\n    const chatPrompt = ChatPromptTemplate.fromPromptMessages([\n      SystemMessagePromptTemplate.fromTemplate(promptTemplate),\n      HumanMessagePromptTemplate.fromTemplate(\"{text}\"),\n    ]);\n\n    const chain = new LLMChain({ llm: this.model, prompt: chatPrompt });\n\n    const response = await chain.call({\n      input_language: options.source,\n      output_language: options.output,\n      text: text,\n    });\n\n    return response.text;\n  }\n\n  /*\n \n     _   _           _               _                  _ \n    | | | |_ __   __| | ___ _ __ ___| |_ __ _ _ __   __| |\n    | | | | '_ \\ / _` |/ _ \\ '__/ __| __/ _` | '_ \\ / _` |\n    | |_| | | | | (_| |  __/ |  \\__ \\ || (_| | | | | (_| |\n     \\___/|_| |_|\\__,_|\\___|_|  |___/\\__\\__,_|_| |_|\\__,_|\n                                                          \n \n*/\n\n  // Runs a chat on the vector store\n  public async understand(info: VectorStore): Promise<void> {\n    const qaTemplate = `Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\n    {context}\n\n    Chat History:\n    {chat_history}\n    Question: {question}\n    Helpful Answer:`;\n\n    // define chat vars\n    const chain = ChatVectorDBQAChain.fromLLM(this.model, info, {\n      k: 2,\n      qaTemplate: qaTemplate,\n    });\n\n    // Options for the chat\n    const runner = async (\n      input: string,\n      history: string[]\n    ): Promise<cliChat.ChatRunnerOutput> => {\n      const result = await chain.call({\n        question: input,\n        chat_history: history,\n      });\n\n      return { output: result.text };\n    };\n\n    // Run the chat\n    await cliChat.run({ runner, inputTitle: \"Question\" });\n  }\n\n  /*\n \n      ____ _           _   \n     / ___| |__   __ _| |_ \n    | |   | '_ \\ / _` | __|\n    | |___| | | | (_| | |_ \n     \\____|_| |_|\\__,_|\\__|\n                           \n \n*/\n\n  public async chat(input?: AgentToolOptions): Promise<void> {\n    // Create the chat agent\n    const executor = await initializeAgentExecutor(\n      getToolsList(input), // input any tools\n      this.model,\n      \"chat-conversational-react-description\",\n      this.model.verbose\n    );\n\n    // Add memory to the agent\n    executor.memory = new BufferMemory({\n      returnMessages: true,\n      memoryKey: \"chat_history\",\n      inputKey: \"input\",\n    });\n\n    // Options for the chat helper\n    const runner = async (\n      input: string,\n      _: string[]\n    ): Promise<cliChat.ChatRunnerOutput> => {\n      const result = await executor.call({ input });\n\n      return { output: result.output };\n    };\n\n    // Run the chat\n    await cliChat.run({ runner, historyUpdate: cliChat.noHistoryUpdate });\n  }\n\n  /*\n \n     _____             ____  _           _     ____                 _   \n    |__  /___ _ __ ___/ ___|| |__   ___ | |_  |  _ \\ ___  __ _  ___| |_ \n      / // _ \\ '__/ _ \\___ \\| '_ \\ / _ \\| __| | |_) / _ \\/ _` |/ __| __|\n     / /|  __/ | | (_) |__) | | | | (_) | |_  |  _ <  __/ (_| | (__| |_ \n    /____\\___|_|  \\___/____/|_| |_|\\___/ \\__| |_| \\_\\___|\\__,_|\\___|\\__|\n                                                                        \n \n*/\n\n  public async zeroShot(input?: AgentToolOptions): Promise<void> {\n    // Create the chat zero shot agent\n    const executor = await initializeAgentExecutor(\n      getToolsList(input), // input any tools\n      this.model,\n      \"chat-zero-shot-react-description\",\n      this.model.verbose\n    );\n\n    this.model.callbackManager = OpenAiChatHelper.noCallBackManager; // Leave logging to the executor\n\n    // Options for the chat helper\n    const runner = async (\n      input: string,\n      _: string[]\n    ): Promise<cliChat.ChatRunnerOutput> => {\n      const result = await executor.call({ input });\n\n      return { output: result.output, stop: true };\n    };\n\n    // Run the chat\n    await cliChat.run({ runner, historyUpdate: cliChat.noHistoryUpdate });\n  }\n}\n\nexport default OpenAiChatHelper;\n"]}
{"filename": "src/langchain/tools/finnhub-stock-price-tool.ts", "chunked_list": ["import { Quote } from \"@stoqey/finnhub\";\nimport { SymbolData } from \"@stoqey/finnhub/dist/api/fundamentals/interface.js\";\nimport { Tool } from \"langchain/tools\";\nconst { FinnhubAPI } = await import(\"@stoqey/finnhub\");\n\ninterface RawQuoteData extends SymbolData {\n  quote: Quote | null;\n}\n\ninterface QuoteData extends SymbolData {\n  quote: Quote;\n}\n", "interface QuoteData extends SymbolData {\n  quote: Quote;\n}\n\nclass FinnhubStockPriceTool extends Tool {\n  name: string;\n  description: string;\n  apiKey: string;\n\n  constructor(apiKey: string | undefined) {\n    super();\n", "    if (!apiKey) {\n      throw new Error(\"No apiKey provided\");\n    }\n\n    this.apiKey = apiKey as string;\n    this.name = \"stockPrice\";\n    this.description =\n      \"a stock value checker. useful for when you need to find the out up to date price of a stock in USD, however, does not work for products. input only should be the stock symbol or stock name and nothing else.\";\n  }\n\n  protected async _call(input: string, verbose?: boolean): Promise<string> {\n    const api = new FinnhubAPI(this.apiKey);\n", "    try {\n      // search for the stock symbol\n      const lookup = await api.symbolLookup(input);\n\n      if ((lookup?.count ?? 0) === 0) {\n        return `No stocks found for ${input}`;\n      }\n\n      // filter the lookup to 10 results\n      const symbols = lookup!.result.slice(0, Math.min(10, lookup!.count));\n      if (verbose) console.log(symbols.map((s) => s.symbol).join(\", \"));\n\n      // map the symbols to parallel quote requests\n      const requests = symbols.map(\n        async (symbol: SymbolData): Promise<RawQuoteData> => {", "      if (verbose) console.log(symbols.map((s) => s.symbol).join(\", \"));\n\n      // map the symbols to parallel quote requests\n      const requests = symbols.map(\n        async (symbol: SymbolData): Promise<RawQuoteData> => {\n          const quote = await api.getQuote(symbol.symbol).catch(() => null);\n          return {\n            ...symbol,\n            quote: quote,\n          };\n        }\n      );\n\n      // wait for all the requests to complete\n      const quotes: QuoteData[] = (await Promise.all(requests))\n        .filter((q) => q.quote && q.quote.close > 0)\n        .map((q) => {\n          return q as QuoteData;\n        });", "      if (quotes.length === 0) {\n        return `No stocks found for ${input}`;\n      }\n      if (verbose) console.log(quotes);\n\n      // collect the stock prices into a bullet list\n      const stockPrices = quotes\n        .map((q) => {\n          return `- The current price of ${q.description} (${q.displaySymbol}) is $${q.quote.close} USD as of ${q.quote.date}`;\n        })\n        .join(\"\\n\");\n\n      // return the stock prices\n      return `Stock Prices: \\n${stockPrices}`;", "    } catch (e) {\n      throw new Error(`Got error from finnhub API: ${e}`);\n    }\n  }\n}\n\nexport default FinnhubStockPriceTool;\n"]}
{"filename": "src/langchain/tools/value-serp-tool.ts", "chunked_list": ["import axios from \"axios\";\nimport { Tool } from \"langchain/tools\";\n\nconst value_serp_url = \"https://api.valueserp.com/search\";\n\nclass ValueSerpAPI extends Tool {\n  name: string;\n  description: string;\n  apiKey: string;\n\n  constructor(apiKey: string | undefined) {\n    super();\n", "    if (!apiKey) {\n      throw new Error(\"No apiKey provided\");\n    }\n\n    this.apiKey = apiKey as string;\n    this.name = \"search\";\n    this.description =\n      \"a search engine. useful for when you need to answer questions about current events. input should be a search query.\";\n  }\n\n  protected async _call(input: string): Promise<string> {\n    const params = this.getParams(input);\n", "    try {\n      const response = await axios.get(value_serp_url, { params });\n\n      const data = response.data;\n      return this.extractData(data);\n    } catch (e) {\n      throw new Error(`Got error from valueSerpAPI: ${e}`);\n    }\n  }\n\n  private getParams(input: string): any {\n    return {\n      api_key: this.apiKey,\n      q: input,\n      hl: \"en\",\n      google_domain: \"google.com\",\n      gl: \"us\",\n    };\n  }\n\n  private extractData(data: any): string {\n    let response: string = \"\";\n\n    // answer box", "    if (data?.answer_box?.answers) {\n      const answers = (data.answer_box.answers as any[])\n        .map((e) => `- ${e.answer}`)\n        .join(\"\\n\");\n\n      response += \"Possible Answers: \\n\" + answers + \"\\n\\n\";\n    }\n\n    // knowledge graph\n    if (data?.knowledge_graph?.description) {\n      response +=\n        \"Additional Information: \\n- \" +\n        data.knowledge_graph.description +\n        \"\\n\\n\";\n    }\n\n    // QA results", "    if (data?.knowledge_graph?.description) {\n      response +=\n        \"Additional Information: \\n- \" +\n        data.knowledge_graph.description +\n        \"\\n\\n\";\n    }\n\n    // QA results\n    if (data?.related_questions) {\n      const questions = data.related_questions.slice(\n        0,\n        Math.min(3, data.related_questions.length)\n      );\n\n      const results = questions\n        .map((e: any) => `[Q]: ${e.question}\\n[A]: ${e.answer}`)\n        .join(\"\\n---\\n\");\n\n      response += \"Related Question Responses: \\n\" + results + \"\\n\\n\";\n    }\n\n    // organic web results, only run if there is no response", "    if (data?.related_questions) {\n      const questions = data.related_questions.slice(\n        0,\n        Math.min(3, data.related_questions.length)\n      );\n\n      const results = questions\n        .map((e: any) => `[Q]: ${e.question}\\n[A]: ${e.answer}`)\n        .join(\"\\n---\\n\");\n\n      response += \"Related Question Responses: \\n\" + results + \"\\n\\n\";\n    }\n\n    // organic web results, only run if there is no response", "    if (data?.organic_results) {\n      const organgicResults = data.organic_results.slice(\n        0,\n        Math.min(3, data.organic_results.length)\n      );\n      const results = organgicResults\n        .map((e: any) => `- [${e.title}]: ${e.snippet}`)\n        .join(\"\\n\");\n      response += \"Top Web Results: \\n\" + results + \"\\n\\n\";\n    }\n\n    // defualt response", "    if (response.length === 0) {\n      return \"No good search result found\";\n    }\n\n    return response;\n  }\n}\n\nexport default ValueSerpAPI;\n"]}
{"filename": "src/langchain/tools/currency-conversion-tool.ts", "chunked_list": ["import axios from \"axios\";\nimport { Tool } from \"langchain/tools\";\n\nconst conversion_url =\n  \"https://cdn.jsdelivr.net/gh/fawazahmed0/currency-api@1/latest/currencies\";\n\nclass CurrencyConversionTool extends Tool {\n  name: string;\n  description: string;\n\n  constructor() {\n    super();\n\n    this.name = \"currency-convert\";\n    this.description =\n      'a currency exchange tool. useful for when you need to convert currency values. input should comma seperated text containin the 2 ISO codes for the currencies. Example Input:\"usd,cad\"';\n  }\n\n  protected async _call(input: string): Promise<string> {\n    const { from, to } = this.extractParams(input);\n", "    try {\n      const response = await this.getConversion(from, to);\n\n      return `1 ${from.toUpperCase()} = ${response} ${to.toUpperCase()}`;\n    } catch (e) {}\n\n    return \"Could not find a conversion rate for that currency pair.\";\n  }\n\n  private extractParams(input: string): { from: string; to: string } {\n    const [from, to] = input.toLowerCase().split(\",\");\n\n    return { from, to };\n  }\n\n  private async getConversion(from: string, to: string): Promise<number> {\n    const response = await axios.get(`${conversion_url}/${from}/${to}.json`);\n    const data = response.data;\n\n    return data[to];\n  }\n}\n\nexport default CurrencyConversionTool;\n"]}
{"filename": "src/langchain/helpers/cli-chat-helper.ts", "chunked_list": ["import * as readline from \"readline\";\n\ninterface ChatRunnerOutput {\n  output: string;\n  stop?: boolean;\n}\n\ninterface ChatOptions {\n  runner: (input: string, history: string[]) => Promise<ChatRunnerOutput>;\n  historyUpdate?: (\n    input: string,\n    output: string,\n    history: string[]\n  ) => string[];\n  inputTitle?: string;\n}\n", "function noHistoryUpdate(_: string, __: string, history: string[]): string[] {\n  return history;\n}\n\nfunction defaultHistoryUpdate(\n  input: string,\n  output: string,\n  history: string[]\n): string[] {\n  return [...history, `User: ${input}`, `Chat: ${output}`];\n}\n", "async function run(options: ChatOptions): Promise<string[]> {\n  const userInputString = `----------\\n${\n    options.inputTitle ?? \"Input\"\n  }:\\n----------`;\n  const chatInputString = `----------\\nResponse:\\n----------`;\n  const rl = readline.createInterface({\n    input: process.stdin,\n    output: process.stdout,\n  });\n  function closeChat(print: boolean = true): void {\n    if (print) {\n      console.log();\n      console.log(\"Exiting chat\");\n    }\n    rl.close();\n  }\n\n  // State\n  let chatHistory: string[] = [];\n\n  // start the chat\n  console.log();\n  console.log('Type \"..\" to exit');\n  console.log();\n  console.log(userInputString);\n  rl.on(\"line\", async (input) => {\n    // Exit the chat", "  function closeChat(print: boolean = true): void {\n    if (print) {\n      console.log();\n      console.log(\"Exiting chat\");\n    }\n    rl.close();\n  }\n\n  // State\n  let chatHistory: string[] = [];\n\n  // start the chat\n  console.log();\n  console.log('Type \"..\" to exit');\n  console.log();\n  console.log(userInputString);\n  rl.on(\"line\", async (input) => {\n    // Exit the chat", "    if (input === \"..\") {\n      return closeChat();\n    }\n\n    // Run the query\n    console.log();\n    const { output: result, stop } = await options.runner(input, chatHistory);\n\n    // Print resopnse and next question prompt\n    console.log();\n    console.log(chatInputString);\n    console.log(result);\n\n    // Exit the chat", "    if (stop) {\n      return closeChat(false);\n    }\n    console.log();\n    console.log(userInputString);\n\n    // Update the chat history\n    chatHistory =\n      options.historyUpdate?.(input, result, chatHistory) ??\n      defaultHistoryUpdate(input, result, chatHistory);\n  });\n\n  return chatHistory;\n}\n\nexport {\n  ChatOptions,\n  ChatRunnerOutput,\n  run,\n  defaultHistoryUpdate,\n  noHistoryUpdate,\n};\n"]}
{"filename": "src/langchain/services/embedding-service.ts", "chunked_list": ["const __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.join(path.dirname(__filename), \"vectors\", \"hsnw\");\n\nimport path from \"path\";\nimport { fileURLToPath } from \"url\";\nimport { HNSWLib, VectorStore } from \"langchain/vectorstores\";\nimport { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\nimport { Embeddings, OpenAIEmbeddings } from \"langchain/embeddings\";\n\ninterface EmbeddingInputBase {\n  embedding?: Embeddings;\n  debug?: boolean;\n}\n", "\ninterface EmbeddingInputBase {\n  embedding?: Embeddings;\n  debug?: boolean;\n}\n\ninterface EmbeddingLoadInput extends EmbeddingInputBase {\n  path: string;\n}\n\ninterface EmbeddingInput extends EmbeddingInputBase {\n  documents: string[];\n  path?: string;\n  chunkSize?: number;\n}\n", "interface EmbeddingInput extends EmbeddingInputBase {\n  documents: string[];\n  path?: string;\n  chunkSize?: number;\n}\n\n// Singleton class named EmbeddingDirectory\nclass EmbeddingDirectory {\n  private static instance: EmbeddingDirectory;\n\n  private constructor() {}\n\n  public static getInstance(): EmbeddingDirectory {", "    if (!EmbeddingDirectory.instance) {\n      EmbeddingDirectory.instance = new EmbeddingDirectory();\n    }\n\n    return EmbeddingDirectory.instance;\n  }\n\n  public url(url: string): string {\n    // extract hostname and path from url\n    const urlObj = new URL(url);\n    const hostname = urlObj.hostname.replace(/\\./g, \"-\");\n    const urlPath = urlObj.pathname.substring(1);\n\n    return path.resolve(__dirname, \"urls\", hostname, urlPath);\n  }\n}\n", "class EmbeddingService {\n  public static get embeddingDirectory(): EmbeddingDirectory {\n    return EmbeddingDirectory.getInstance();\n  }\n\n  public static async load(\n    input: EmbeddingLoadInput\n  ): Promise<VectorStore | null> {\n    const debug = input.debug ?? false;\n    const embeddingModel: Embeddings =\n      input.embedding ?? new OpenAIEmbeddings();\n    let vectorStore: HNSWLib;\n\n    // Attempt to load in the vector store", "    if (input.path) {\n      try {\n        if (debug) {\n          console.log(`Loading vector store from path: [${input.path}]`);\n        }\n        // Load in the vector store\n        vectorStore = await HNSWLib.load(input.path, embeddingModel);\n\n        // Return the vector store if it was loaded\n        if (vectorStore) {\n          return vectorStore;\n        }", "        if (vectorStore) {\n          return vectorStore;\n        }\n      } catch (e) {\n        if (debug) {\n          console.log(`Failed to load vector store from path: [${input.path}]`);\n        }\n      }\n    }\n\n    return null;\n  }\n\n  public static async embed(input: EmbeddingInput): Promise<VectorStore> {\n    const debug = input.debug ?? false;\n    const embeddingModel: Embeddings =\n      input.embedding ?? new OpenAIEmbeddings();\n    let vectorStore: HNSWLib;\n\n    // Create new vector store\n    /* Split the text into chunks */\n    const textSplitter = new RecursiveCharacterTextSplitter({\n      chunkSize: input.chunkSize ?? 1000,\n    });\n    const docs = await textSplitter.createDocuments(input.documents);\n\n    /* Create the vectorstore */\n    vectorStore = await HNSWLib.fromDocuments(docs, embeddingModel);\n\n    // If the path is provided, save the vector store", "    if (input.path) {\n      if (debug) {\n        console.log(`Saving vector store to path: [${input.path}]`);\n      }\n      await vectorStore.save(input.path);\n    }\n\n    return vectorStore;\n  }\n}\n\nexport default EmbeddingService;\n"]}
{"filename": "src/programs/summary-program.ts", "chunked_list": ["import { ProgramInterface, ProgramInput } from \"./program-interface.js\";\nimport EnvironmentService from \"../services/environment-service.js\";\nimport { Argument, Option } from \"commander\";\nimport WebExtractionService from \"../services/web-extraction-service.js\";\nimport OpenAiChatHelper from \"../langchain/open-ai-chat-helper.js\";\n\ninterface SummarizationInput {\n  text: string; //url or text\n  mode: \"map_reduce\" | \"stuff\";\n  split: number;\n  debug: boolean;\n  url?: string;\n}\n", "class SummaryProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"summary\";\n  }\n  protected get description(): string {\n    return `Allows for the sumarization of text and urls. By defualt runs the map reduce mode which does not have a limit on its input.`;\n  }\n  protected get requiredEnvironmentVariables(): string[] {\n    return [EnvironmentService.names.OPENAI_API_KEY];\n  }\n  protected get arguments(): Argument[] {\n    return [new Argument(\"[input...]\", \"The text or url to summarize.\")];\n  }\n  protected get options(): Option[] {\n    return [\n      new Option(\n        \"-m, --mode <mode>\",\n        \"The summarization mode to run on:\" +\n          \"\\n\\tmap-reduce: Runs the map reduce mode which does not have a limit on its input.\" +\n          \"\\n\\tstuff: Sends the input directly to summarization, you may encounter max rate limits.\"\n      )\n        .choices([\"map_reduce\", \"stuff\"])\n        .default(\"map_reduce\"),\n      new Option(\n        \"--split <split>\",\n        \"Defines the split length for large input texts when running with map reduce mode.\"\n      ).default(3000),\n    ];\n  }\n\n  public async run(input: ProgramInput): Promise<void> {", "    if (input.args.length > 0) {\n      // Extract the text\n      const inputArg = input.args[0].join(\" \");\n\n      if (inputArg.length > 0) {\n        // Summarize\n        return SummaryProgram.runSummary({\n          text: inputArg,\n          mode: input.input.mode,\n          split: input.input.split,\n          debug: input.globals.debug,\n        });\n      }\n    }\n\n    // Default show help\n    input.command.help();\n  }\n\n  private static async runSummary(input: SummarizationInput): Promise<void> {\n    // Determine if the text is a url\n    const isUrl = WebExtractionService.isUrl(input.text);", "    if (isUrl) {\n      // Extract the webpage content\n      try {\n        input.url = input.text;\n        input.text = (\n          await WebExtractionService.extract(input.text)\n        ).toString();\n      } catch (e) {\n        console.error(`Could not extract webpage content from url: ${input}`);\n        return;\n      }\n    }\n\n    // Summarize the text\n    await SummaryProgram.summarizeText(input);\n  }\n\n  private static async summarizeText(input: SummarizationInput): Promise<void> {", "    if (input.debug) {\n      console.log(\"Input:\");\n      console.log(input);\n      console.log();\n    }\n\n    // Model\n    const chat = new OpenAiChatHelper({\n      model: \"gpt-3.5-turbo\",\n      temperature: 0.7,\n      verbose: input.debug,\n    });\n\n    // Run summary\n    const summary = await chat.summarize(input.text, {\n      type: input.mode,\n      split: input.split,\n    });\n\n    // Output the result\n    console.log();\n    console.log(summary);\n  }\n}\n\nexport default SummaryProgram;\n"]}
{"filename": "src/programs/translate-program.ts", "chunked_list": ["import { ProgramInterface, ProgramInput } from \"./program-interface.js\";\nimport EnvironmentService from \"../services/environment-service.js\";\nimport { Argument, Option } from \"commander\";\nimport OpenAiChatHelper from \"../langchain/open-ai-chat-helper.js\";\n\ninterface TranslationInput {\n  text: string; //text\n  source: string; // source language\n  output: string; // output language\n  debug: boolean;\n}\n", "class TranslateProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"translate\";\n  }\n  protected get description(): string {\n    return `Allows for the translatation of text from one langauge to the other. By defualt the program detects the input language and translates to english.`;\n  }\n  protected get requiredEnvironmentVariables(): string[] {\n    return [EnvironmentService.names.OPENAI_API_KEY];\n  }\n  protected get arguments(): Argument[] {\n    return [new Argument(\"[input...]\", \"The text tranlsate.\")];\n  }\n  protected get options(): Option[] {\n    return [\n      new Option(\n        \"-s, --source <source>\",\n        \"The expected langauge for the input.\"\n      ).default(\"Auto\"),\n      new Option(\n        \"-o, --output <output>\",\n        \"The langauge to translate the input to.\"\n      ).default(\"English\"),\n    ];\n  }\n\n  public async run(input: ProgramInput): Promise<void> {", "    if (input.args.length > 0) {\n      // Extract the text\n      const inputArg = input.args[0].join(\" \");\n\n      if (inputArg.length > 0) {\n        // Summarize\n        TranslateProgram.translate({\n          text: inputArg,\n          source: (input.input.source as string).toLowerCase(),\n          output: (input.input.output as string).toLowerCase(),\n          debug: input.globals.debug,\n        });\n        return;\n      }\n    }\n\n    // Default show help\n    input.command.help();\n  }\n\n  private static async translate(input: TranslationInput): Promise<void> {", "    if (input.debug) {\n      console.log(\"Input:\");\n      console.log(input);\n      console.log();\n    }\n\n    // Model\n    const chat = new OpenAiChatHelper({\n      model: \"gpt-3.5-turbo\",\n      temperature: 0, // Enforces deterministic behavior\n      verbose: input.debug,\n    });\n\n    // Run summary\n    const translation = await chat.translate(input.text, {\n      source: input.source,\n      output: input.output,\n    });\n\n    // Output the result\n    console.log();\n    console.log(translation);\n  }\n}\n\nexport default TranslateProgram;\n"]}
{"filename": "src/programs/prompt-program.ts", "chunked_list": ["import { ProgramInput, ProgramInterface } from \"./program-interface.js\";\nimport EnvironmentService from \"../services/environment-service.js\";\nimport OpenAiChatHelper from \"../langchain/open-ai-chat-helper.js\";\nimport * as toolHelper from \"../helpers/agent-tool-helper.js\";\n\nclass PromptProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"prompt\";\n  }\n  protected get aliases(): string[] {\n    return [\"p\"];\n  }\n  protected get description(): string {\n    return `Runs a ReAct agent to resolve the users prompt, limited to a single input.`;\n  }\n  protected get requiredEnvironmentVariables(): string[] {\n    return [EnvironmentService.names.OPENAI_API_KEY];\n  }\n\n  protected formatDescription(): string {\n    let description =\n      super.formatDescription() + toolHelper.getToolOptionDescription();\n\n    return description;\n  }\n\n  public async run(input: ProgramInput): Promise<void> {\n    // Create model\n    const model = new OpenAiChatHelper({\n      model: \"gpt-3.5-turbo\",\n      temperature: 0.7,\n      verbose: input.globals.debug,\n    });\n\n    // Get the tools\n    const tools = toolHelper.getEnabledTools();\n\n    // Log the tools\n    console.log(`Running with Tools: [${Object.keys(tools).join(\", \")}]`);\n\n    // Start chat with the tools\n    return model.zeroShot({ tools });\n  }\n}\n\nexport default PromptProgram;\n"]}
{"filename": "src/programs/chat-program.ts", "chunked_list": ["import { ProgramInput, ProgramInterface } from \"./program-interface.js\";\nimport EnvironmentService from \"../services/environment-service.js\";\nimport OpenAiChatHelper from \"../langchain/open-ai-chat-helper.js\";\nimport * as toolHelper from \"../helpers/agent-tool-helper.js\";\n\nclass ChatProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"chat\";\n  }\n  protected get aliases(): string[] {\n    return [\"c\"];\n  }\n  protected get description(): string {", "    return `Runs a chat interface with ChatGPT. various api keys can be set in the environment variables to enable additional features.`;\n  }\n  protected get requiredEnvironmentVariables(): string[] {\n    return [EnvironmentService.names.OPENAI_API_KEY];\n  }\n\n  protected formatDescription(): string {\n    let description =\n      super.formatDescription() + toolHelper.getToolOptionDescription();\n\n    return description;\n  }\n\n  public async run(input: ProgramInput): Promise<void> {\n    // Create model\n    const model = new OpenAiChatHelper({\n      model: \"gpt-3.5-turbo\",\n      temperature: 0.7,\n      verbose: input.globals.debug,\n    });\n\n    // Get the tools\n    const tools = toolHelper.getEnabledTools();\n\n    // Log the tools\n    console.log(`Running with Tools: [${Object.keys(tools).join(\", \")}]`);\n\n    // Start chat with the tools\n    return model.chat({ tools });\n  }\n}\n\nexport default ChatProgram;\n"]}
{"filename": "src/programs/understand-program.ts", "chunked_list": ["import { VectorStore } from \"langchain/vectorstores\";\nimport { ProgramInput, ProgramInterface } from \"./program-interface.js\";\nimport EnvironmentService from \"../services/environment-service.js\";\nimport { Argument, Option } from \"commander\";\nimport WebExtractionService from \"../services/web-extraction-service.js\";\nimport OpenAiChatHelper from \"../langchain/open-ai-chat-helper.js\";\nimport EmbeddingService from \"../langchain/services/embedding-service.js\";\n\ninterface UnderstandInput {\n  url: string; //text\n  clear: boolean;\n  debug: boolean;\n}\n", "interface UnderstandInput {\n  url: string; //text\n  clear: boolean;\n  debug: boolean;\n}\n\nclass UnderstandProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"understand\";\n  }\n  protected get description(): string {\n    return `Allows for the AI Model to understand a Website. Ask it questions about the website.`;\n  }\n  protected get requiredEnvironmentVariables(): string[] {\n    return [EnvironmentService.names.OPENAI_API_KEY];\n  }\n  protected get arguments(): Argument[] {\n    return [new Argument(\"[input...]\", \"The text tranlsate.\")];\n  }\n  protected get options(): Option[] {\n    return [\n      new Option(\n        \"-c, --clear\",\n        \"Clears any cached vector stores for the input, and creates a new one.\"\n      ).default(false),\n    ];\n  }\n\n  public async run(input: ProgramInput): Promise<void> {\n    // Extract the text\n    const inputArg = input.args[0].join(\" \");\n", "    if (inputArg.length > 0) {\n      return UnderstandProgram.understandWebpage({\n        url: inputArg,\n        clear: input.input.clear,\n        debug: input.globals.debug,\n      });\n    }\n\n    // Default show help\n    input.command.help();\n  }\n\n  public static async understandWebpage(input: UnderstandInput): Promise<void> {", "    if (input.debug) {\n      console.log(\"Input:\");\n      console.log(input);\n      console.log();\n    }\n\n    // Embed the webpage\n    const vectorStore = await this.embedWebpage(input);\n\n    // Model\n    // Create Model (Randonmess level 0.7)\n    const chat = new OpenAiChatHelper({\n      model: \"gpt-3.5-turbo\",\n      temperature: 0.7,\n      verbose: input.debug,\n    });\n\n    await chat.understand(vectorStore);\n  }\n\n  // Embedds the contents of a webpage into a vector store\n  public static async embedWebpage(\n    input: UnderstandInput\n  ): Promise<VectorStore> {\n    const { url, debug, clear } = input;\n\n    // Error checking", "    if (WebExtractionService.isUrl(url) == false) {\n      throw new Error(\"Invalid URL\");\n    }\n\n    let vectorStore: VectorStore | null = null;\n    const urlDirectory = EmbeddingService.embeddingDirectory.url(url);\n\n    if (!clear) {\n      // Loads the vector store if it exists\n      vectorStore = await EmbeddingService.load({\n        path: urlDirectory,\n        debug: debug,\n      });\n    }\n", "    if (!vectorStore) {\n      // Vector store does not exist, create it\n      if (debug) {\n        console.log(\"Starting webpage embedding\");\n      }\n\n      // Extract the text\n      const text = await WebExtractionService.extract(url);\n\n      if (debug) {\n        console.log(\"Text abstraction complete\");\n      }\n\n      vectorStore = await EmbeddingService.embed({\n        documents: [text.toString()],\n        path: urlDirectory,\n        debug: debug,\n      });\n    }\n", "      if (debug) {\n        console.log(\"Text abstraction complete\");\n      }\n\n      vectorStore = await EmbeddingService.embed({\n        documents: [text.toString()],\n        path: urlDirectory,\n        debug: debug,\n      });\n    }\n", "    if (debug) {\n      console.log(\"Created vector store\");\n    }\n\n    return vectorStore;\n  }\n}\n\nexport default UnderstandProgram;\n"]}
{"filename": "src/programs/program-interface.ts", "chunked_list": ["import { Command, Option, Argument } from \"commander\";\nimport EnvironmentService from \"../services/environment-service.js\";\n\ninterface ProgramInput {\n  args: any[]; // A list of the input arguments\n  input: { [key: string]: any }; // A dictionary of the input options\n  globals: { [key: string]: any }; // A dictionary of the global options\n  objects: { [key: string]: any }; // A dictionary of the additional objects\n  root: Command; // The root command\n  command: Command; // The current command\n}\n", "abstract class ProgramInterface {\n  public command?: Command;\n  protected abstract get name(): string;\n  protected abstract get description(): string;\n\n  // Optional\n  protected get aliases(): string[] {\n    return [];\n  }\n  protected get arguments(): Argument[] {\n    return [];\n  }\n  protected get options(): Option[] {\n    return [];\n  }\n  protected get requiredEnvironmentVariables(): string[] {\n    return [];\n  }\n  protected get inputObjects(): { [key: string]: any } {\n    return {};\n  }\n\n  // Configure the program with the commander instance\n  // Sets the command at each step\n  public configure(root: Command): Command {\n    let command: Command = root\n      .command(this.name)\n      .description(this.formatDescription() + \"\\n\\n\");\n\n    // Add the aliases if they exists", "    if (this.aliases) {\n      command = command.aliases(this.aliases);\n    }\n\n    // Add any arguments\n    this.arguments.forEach((argument) => {\n      command = command.addArgument(argument);\n    });\n\n    // Add any options\n    this.options.forEach((option) => {\n      command = command.addOption(option);\n    });\n", "    // Add the run function to the command\n    command = command.action((...args) =>\n      this.runWrapper(this.run, root, ...args)\n    );\n\n    this.command = command;\n\n    return command;\n  }\n\n  protected abstract run(input: ProgramInput): Promise<void>;\n\n  // Formats the description, adding the required environment variables\n  protected formatDescription(): string {\n    let description = this.description;", "    if (this.requiredEnvironmentVariables.length > 0) {\n      const envList = this.requiredEnvironmentVariables.join(\", \");\n      description += `\\n<Required: [${envList}]>`;\n    }\n    return description;\n  }\n\n  // formats the input for the runner\n  private async runWrapper(\n    run: (input: ProgramInput) => Promise<void>,\n    root: Command,\n    ...args: any[]\n  ): Promise<void> {\n    // Format the input\n    const finalArgs = [];", "    for (let i = 0; i < args.length; i++) {\n      if (args[i] instanceof Command) {\n        break;\n      } else if (args[i] != undefined && args[i] != null) {\n        finalArgs.push(args[i]);\n      }\n    }\n\n    let finalInput = {};\n    if (typeof finalArgs[finalArgs.length - 1] === typeof {}) {\n      finalInput = finalArgs.pop();\n    }\n\n    let input: ProgramInput = {\n      args: finalArgs,\n      input: finalInput,\n      globals: root.optsWithGlobals(),\n      objects: this.inputObjects,\n      root: root,\n      command: this.command!,\n    };\n\n    const isInit = EnvironmentService.isEnvironmentInitialized(\n      this.requiredEnvironmentVariables\n    );\n\n    // Run the command and validate it", "    if (typeof finalArgs[finalArgs.length - 1] === typeof {}) {\n      finalInput = finalArgs.pop();\n    }\n\n    let input: ProgramInput = {\n      args: finalArgs,\n      input: finalInput,\n      globals: root.optsWithGlobals(),\n      objects: this.inputObjects,\n      root: root,\n      command: this.command!,\n    };\n\n    const isInit = EnvironmentService.isEnvironmentInitialized(\n      this.requiredEnvironmentVariables\n    );\n\n    // Run the command and validate it", "    try {\n      if (!isInit) {\n        throw new Error(\n          `All required environment variables are not set. required: ${this.requiredEnvironmentVariables.join(\n            \", \"\n          )}`\n        );\n      }\n\n      if (input.globals.debug) {\n        console.log(\"Running with debug mode [enabled]\");\n      } else {\n        process.removeAllListeners(\"warning\");\n        console.warn = () => {};\n      }\n\n      // Run the program\n      await this.run(input);", "      if (input.globals.debug) {\n        console.log(\"Running with debug mode [enabled]\");\n      } else {\n        process.removeAllListeners(\"warning\");\n        console.warn = () => {};\n      }\n\n      // Run the program\n      await this.run(input);\n    } catch (e) {\n      // Catch any errors and print them", "    } catch (e) {\n      // Catch any errors and print them\n      if (input.globals.debug) {\n        // Check if the verbose flag is set and print the stack trace\n        console.error(e);\n      } else {\n        // Print just the message\n        let message = e;\n        if (e instanceof Error) {\n          message = e.message;\n        }\n        console.error(message);\n      }\n    }\n  }\n}\n\nexport { ProgramInterface, ProgramInput };\n", "        if (e instanceof Error) {\n          message = e.message;\n        }\n        console.error(message);\n      }\n    }\n  }\n}\n\nexport { ProgramInterface, ProgramInput };\n"]}
{"filename": "src/programs/configure/configure-key-program.ts", "chunked_list": ["import { Argument, Option } from \"commander\";\nimport { ProgramInterface, ProgramInput } from \"../program-interface.js\";\nimport EnvironmentService from \"../../services/environment-service.js\";\n\ninterface ConfigureKeyInput {\n  command: string;\n  name: string;\n  env: string;\n}\n\nclass ConfigureKeyProgram extends ProgramInterface {\n  protected get name(): string {\n    return this.config.command;\n  }\n  protected get description(): string {\n    return `Sets the ${this.config.name} key within the CLI environment variable. Overrides the exsisting value at the [${this.config.env}] index.`;\n  }\n  protected get arguments(): Argument[] {\n    return [new Argument(\"[key]\", `The key for the ${this.config.name}`)];\n  }\n  protected get options(): Option[] {\n    return [\n      new Option(\"-p, --print\", \"Prints the current key to the console\"),\n      new Option(\"-c, --clear\", \"Clears the current key\"),\n    ];\n  }\n  protected get inputObjects(): { [key: string]: any } {\n    return {\n      config: this.config,\n    };\n  }\n\n  private config: ConfigureKeyInput;\n  constructor(input: ConfigureKeyInput) {\n    super();\n    this.config = input;\n  }\n\n  public async run(input: ProgramInput): Promise<void> {", "class ConfigureKeyProgram extends ProgramInterface {\n  protected get name(): string {\n    return this.config.command;\n  }\n  protected get description(): string {\n    return `Sets the ${this.config.name} key within the CLI environment variable. Overrides the exsisting value at the [${this.config.env}] index.`;\n  }\n  protected get arguments(): Argument[] {\n    return [new Argument(\"[key]\", `The key for the ${this.config.name}`)];\n  }\n  protected get options(): Option[] {\n    return [\n      new Option(\"-p, --print\", \"Prints the current key to the console\"),\n      new Option(\"-c, --clear\", \"Clears the current key\"),\n    ];\n  }\n  protected get inputObjects(): { [key: string]: any } {\n    return {\n      config: this.config,\n    };\n  }\n\n  private config: ConfigureKeyInput;\n  constructor(input: ConfigureKeyInput) {\n    super();\n    this.config = input;\n  }\n\n  public async run(input: ProgramInput): Promise<void> {", "    if (input.args.length === 1) {\n      // Write key\n      EnvironmentService.writeToEnvironmentFile(\n        input.objects.config.env,\n        input.args[0]\n      );\n      console.log(\n        `Wrote ${input.objects.config.name} key to environment file.`\n      );\n    } else if (input.input.print) {\n      // Print current key\n      const key = EnvironmentService.getEnvironmentVariable(\n        input.objects.config.env\n      );\n      console.log(`Current ${input.objects.config.name} key: ${key}`);", "    } else if (input.input.print) {\n      // Print current key\n      const key = EnvironmentService.getEnvironmentVariable(\n        input.objects.config.env\n      );\n      console.log(`Current ${input.objects.config.name} key: ${key}`);\n    } else if (input.input.clear) {\n      // Clear current key\n      EnvironmentService.clearFromEnvironmentFile([input.objects.config.env]);\n      console.log(`${input.objects.config.name} key cleared.`);\n    } else {\n      // Show help\n      input.command.help();\n    }\n  }\n}\n\nexport { ConfigureKeyProgram, ConfigureKeyInput };\n"]}
{"filename": "src/programs/configure/clear-configuration-program.ts", "chunked_list": ["import { ProgramInterface, ProgramInput } from \"../program-interface.js\";\nimport EnvironmentService from \"../../services/environment-service.js\";\n\nclass ClearConfigurationProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"clear\";\n  }\n  protected get description(): string {\n    return \"Clears all environment variables for the application\";\n  }\n\n  public async run(input: ProgramInput): Promise<void> {\n    EnvironmentService.setEnvironemntFile(\"\");\n    console.log(\"Cleared environment file\");\n  }\n}\n\nexport default ClearConfigurationProgram;\n"]}
{"filename": "src/programs/configure/configure-program.ts", "chunked_list": ["import { Command } from \"commander\";\nimport { ProgramInterface, ProgramInput } from \"../program-interface.js\";\nimport EnvironmentService from \"../../services/environment-service.js\";\nimport {\n  ConfigureKeyProgram,\n  ConfigureKeyInput,\n} from \"./configure-key-program.js\";\nimport ClearConfigurationProgram from \"./clear-configuration-program.js\";\n\nclass ConfigureProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"config\";\n  }\n  protected get description(): string {\n    return \"Configures environment variables for the application. An alternative to setting environment variables manually.\";\n  }\n\n  // Configure the program with the commander instance\n  public configure(root: Command): Command {\n    this.command = super.configure(root);\n\n    // clear sub command\n    new ClearConfigurationProgram().configure(this.command);\n\n    // key sub commands\n    this.configureKeyPrograms(this.keyPrograms);\n\n    return this.command!;\n  }\n\n  private configureKeyPrograms(inputs: ConfigureKeyInput[]): void {", "\nclass ConfigureProgram extends ProgramInterface {\n  protected get name(): string {\n    return \"config\";\n  }\n  protected get description(): string {\n    return \"Configures environment variables for the application. An alternative to setting environment variables manually.\";\n  }\n\n  // Configure the program with the commander instance\n  public configure(root: Command): Command {\n    this.command = super.configure(root);\n\n    // clear sub command\n    new ClearConfigurationProgram().configure(this.command);\n\n    // key sub commands\n    this.configureKeyPrograms(this.keyPrograms);\n\n    return this.command!;\n  }\n\n  private configureKeyPrograms(inputs: ConfigureKeyInput[]): void {", "    for (const input of inputs) {\n      new ConfigureKeyProgram(input).configure(this.command!);\n    }\n  }\n\n  public async run(input: ProgramInput): Promise<void> {\n    // Runs the help command\n    input.command.help();\n  }\n\n  private get keyPrograms(): ConfigureKeyInput[] {\n    return [\n      // open ai key\n      {\n        command: \"openai\",\n        name: \"Open AI API\",\n        env: EnvironmentService.names.OPENAI_API_KEY,\n      },\n\n      // serp api key\n      {\n        command: \"serpapi\",\n        name: \"SERP API Key\",\n        env: EnvironmentService.names.SERPAPI_API_KEY,\n      },\n\n      // value serp api key\n      {\n        command: \"valueserp\",\n        name: \"Value SERP API Key\",\n        env: EnvironmentService.names.VALUESERP_API_KEY,\n      },\n\n      // finnhub api key\n      {\n        command: \"finnhub\",\n        name: \"Finnhub API Key\",\n        env: EnvironmentService.names.FINNHUB_API_KEY,\n      },\n    ];\n  }\n}\n\nexport default ConfigureProgram;\n"]}
{"filename": "src/helpers/agent-tool-helper.ts", "chunked_list": ["import { Calculator, SerpAPI, Tool } from \"langchain/tools\";\nimport EnvironmentService from \"../services/environment-service.js\";\nimport ValueSerpAPI from \"../langchain/tools/value-serp-tool.js\";\nimport FinnhubStockPriceTool from \"../langchain/tools/finnhub-stock-price-tool.js\";\nimport CurrencyConversionTool from \"../langchain/tools/currency-conversion-tool.js\";\n\nfunction getToolOptionDescription(): string {\n  let description = \"\\n<Optional>:\";\n  description += `\\n[${EnvironmentService.names.SERPAPI_API_KEY}]: Enables the use of the SerpAPI to enable search functionality.`;\n  description += `\\n[${EnvironmentService.names.VALUESERP_API_KEY}]: Preffered over SerpAPI, enabled search functionality.`;\n  description += `\\n[${EnvironmentService.names.FINNHUB_API_KEY}]: Enables real-time stock price knowledge for the agent.`;\n  return description;\n}\n", "function getEnabledTools(): { [name: string]: Tool } {\n  const tools: { [name: string]: Tool } = {\n    // Default tools\n    Calulator: new Calculator(),\n    CurrencyConvertor: new CurrencyConversionTool(),\n  };\n\n  // Environment Tools\n\n  // search tools\n  if (process.env[EnvironmentService.names.VALUESERP_API_KEY]) {\n    tools[\"ValueSerp\"] = new ValueSerpAPI(\n      process.env[EnvironmentService.names.VALUESERP_API_KEY]\n    );", "  if (process.env[EnvironmentService.names.VALUESERP_API_KEY]) {\n    tools[\"ValueSerp\"] = new ValueSerpAPI(\n      process.env[EnvironmentService.names.VALUESERP_API_KEY]\n    );\n  } else if (process.env[EnvironmentService.names.SERPAPI_API_KEY]) {\n    tools[\"SerpAPI\"] = new SerpAPI(\n      process.env[EnvironmentService.names.SERPAPI_API_KEY]\n    );\n  }\n\n  // finnhub tool", "  if (process.env[EnvironmentService.names.FINNHUB_API_KEY]) {\n    tools[\"FinnhubStockPrice\"] = new FinnhubStockPriceTool(\n      process.env[EnvironmentService.names.FINNHUB_API_KEY]\n    );\n  }\n\n  return tools;\n}\n\nexport { getToolOptionDescription, getEnabledTools };\n"]}
{"filename": "src/helpers/commander-helper.ts", "chunked_list": ["import commander from \"commander\";\n\nfunction parseIntArgument(value: string, _: any): number {\n  const parsedValue = parseInt(value, 10);\n  if (isNaN(parsedValue)) {\n    throw new commander.InvalidArgumentError(\"Not a valid number.\");\n  }\n  return parsedValue;\n}\n\nexport { parseIntArgument };\n"]}
{"filename": "src/services/environment-service.ts", "chunked_list": ["import dotenv from \"dotenv\";\nimport path from \"path\";\nimport fs from \"fs\";\nimport { fileURLToPath } from \"url\";\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\n\nclass EnvironmentNames {\n  OPENAI_API_KEY: string = \"OPENAI_API_KEY\";\n  SERPAPI_API_KEY: string = \"SERPAPI_API_KEY\";\n  VALUESERP_API_KEY: string = \"VALUESERP_API_KEY\";\n  FINNHUB_API_KEY: string = \"FINNHUB_API_KEY\";\n}\n", "class EnvironmentNames {\n  OPENAI_API_KEY: string = \"OPENAI_API_KEY\";\n  SERPAPI_API_KEY: string = \"SERPAPI_API_KEY\";\n  VALUESERP_API_KEY: string = \"VALUESERP_API_KEY\";\n  FINNHUB_API_KEY: string = \"FINNHUB_API_KEY\";\n}\n\nclass EnvironmentService {\n  public static readonly names: EnvironmentNames = new EnvironmentNames();\n\n  private static readonly ENV_PATH: string = path.resolve(__dirname, \".env\");\n\n  public static initializeEnvironment(): void {\n    dotenv.config({\n      path: EnvironmentService.ENV_PATH,\n    });\n  }\n\n  public static isEnvironmentInitialized(vars: string[]): boolean {\n    EnvironmentService.initializeEnvironment();\n    return vars.every((v) => !!process.env[v]);\n  }\n\n  public static getEnvironmentVariable(key: string): string {\n    EnvironmentService.initializeEnvironment();\n    return process.env[key] || \"\";\n  }\n\n  public static setEnvironemntFile(value: string): void {\n    fs.writeFileSync(EnvironmentService.ENV_PATH, value);\n  }\n\n  public static clearEnvironment(): void {\n    EnvironmentService.setEnvironemntFile(\"\");\n  }\n\n  public static clearFromEnvironmentFile(keys: string[]): void {\n    // Check if the environment file exists\n    let contentsList: string[] = [];", "    if (fs.existsSync(EnvironmentService.ENV_PATH)) {\n      // Pull the file contents and set the contents list\n\n      const fileContents = fs\n        .readFileSync(EnvironmentService.ENV_PATH)\n        .toString();\n      contentsList = fileContents.split(\"\\n\");\n    }\n\n    // Split the keys into a map\n    let keysMap: { [key: string]: string } = {};\n\n    contentsList.forEach((c) => {\n      const [envKey, value] = c.split(\"=\");\n      keysMap[envKey] = value;\n    });\n\n    // Remove the keys\n    keys.forEach((k) => {\n      delete keysMap[k];\n    });\n\n    // Convert the map back into a string\n    const newContents = Object.keys(keysMap).reduce((acc, key) => {", "      if (!key) return acc;\n      return `${acc}${key}=${keysMap[key]}\\n`;\n    }, \"\");\n\n    // Write the new contents to the file\n    EnvironmentService.setEnvironemntFile(newContents);\n  }\n\n  public static writeToEnvironmentFile(key: string, value: string): void {\n    // Check if the environment file exists\n    let contentsList: string[] = [];", "    if (fs.existsSync(EnvironmentService.ENV_PATH)) {\n      // Pull the file contents and set the contents list\n      const fileContents = fs\n        .readFileSync(EnvironmentService.ENV_PATH)\n        .toString();\n      contentsList = fileContents.split(\"\\n\");\n    }\n\n    // Split the keys into a map\n    let keysMap: { [key: string]: string } = {};\n    contentsList.forEach((c) => {\n      const [envKey, value] = c.split(\"=\");\n      keysMap[envKey] = value;\n    });\n\n    // Replace the value at the key\n    keysMap[key] = value;\n\n    // Convert the map back into a string\n    const newContents = Object.keys(keysMap).reduce((acc, key) => {", "      if (!key) return acc;\n      return `${acc}${key}=${keysMap[key]}\\n`;\n    }, \"\");\n\n    // Write the new contents to the file\n    EnvironmentService.setEnvironemntFile(newContents);\n  }\n}\n\nexport default EnvironmentService;\n"]}
{"filename": "src/services/web-extraction-service.ts", "chunked_list": ["import axios from \"axios\";\nimport cheerio from \"cheerio\";\n\ninterface ExtractedPageData {\n  type: \"text\" | \"header\" | \"list\" | \"table\";\n  content: string;\n}\n\nclass WebPageData {\n  public data: ExtractedPageData[];\n  constructor(data: ExtractedPageData[]) {\n    this.data = data;\n  }\n\n  public toString(): string {\n    return this.data.map((data) => data.content).join(\"\\n\");\n  }\n}\n", "class WebPageData {\n  public data: ExtractedPageData[];\n  constructor(data: ExtractedPageData[]) {\n    this.data = data;\n  }\n\n  public toString(): string {\n    return this.data.map((data) => data.content).join(\"\\n\");\n  }\n}\n", "class WebExtractionService {\n  public static get urlPattern(): RegExp {\n    return /^(https?:\\/\\/)?([\\da-z.-]+)\\.([a-z.]{2,6})([/\\w .-]*)*\\/?$/i;\n  }\n\n  /*\n \n     ___       _             __                \n    |_ _|_ __ | |_ ___ _ __ / _| __ _  ___ ___ \n     | || '_ \\| __/ _ \\ '__| |_ / _` |/ __/ _ \\\n     | || | | | ||  __/ |  |  _| (_| | (_|  __/\n    |___|_| |_|\\__\\___|_|  |_|  \\__,_|\\___\\___|\n                                               \n \n*/\n  public static isUrl(url: string): boolean {\n    return WebExtractionService.urlPattern.test(url);\n  }\n\n  public static async extract(url: string): Promise<WebPageData> {", "    if (!WebExtractionService.isUrl(url))\n      throw new Error(\"Invalid url provided.\");\n    const html = await WebExtractionService.fetchWebPage(url);\n    return WebExtractionService.extractHtmlData(html);\n  }\n\n  public static async fetchWebPage(url: string): Promise<string> {\n    const response = await axios.get(url);\n    return response.data;\n  }\n\n  public static extractHtmlData(html: string): WebPageData {\n    const $ = cheerio.load(html);\n    const data: ExtractedPageData[] = [];\n\n    $(\"body\")\n      .find(\"*\")\n      .each((_, e: cheerio.Element) => {\n        const extractedData = WebExtractionService._dataFromElement($, e);", "        if (extractedData) {\n          if (Array.isArray(extractedData)) {\n            data.push(...extractedData);\n          } else {\n            data.push(extractedData);\n          }\n        }\n      });\n\n    return new WebPageData(data);\n  }\n\n  /*\n \n     _   _      _                     \n    | | | | ___| |_ __   ___ _ __ ___ \n    | |_| |/ _ \\ | '_ \\ / _ \\ '__/ __|\n    |  _  |  __/ | |_) |  __/ |  \\__ \\\n    |_| |_|\\___|_| .__/ \\___|_|  |___/\n                 |_|                  \n \n*/\n\n  private static _extractText(\n    $: cheerio.Root,\n    element: cheerio.Cheerio\n  ): ExtractedPageData[] {\n    return element\n      .map((_, el) => ({\n        type: \"text\",\n        content: $(el).text().trim(),\n      }))\n      .get();\n  }\n\n  private static _dataFromElement(\n    $: cheerio.Root,\n    element: cheerio.Element\n  ): ExtractedPageData[] | ExtractedPageData | null {", "    if (element.type === \"text\") {\n      // Parse text element\n      return {\n        type: \"text\",\n        content: element.data ?? \"\",\n      };\n    } else if (element.type === \"tag\") {\n      // Parse tagged element\n      const tagName = element.tagName.toLowerCase();\n\n      if (\n        tagName.startsWith(\"h\") &&\n        tagName.length === 2 &&\n        !isNaN(Number(tagName[1]))\n      ) {\n        // H1-H6\n        return {\n          type: \"header\",\n          content: $(element).text().trim(),\n        };", "      if (\n        tagName.startsWith(\"h\") &&\n        tagName.length === 2 &&\n        !isNaN(Number(tagName[1]))\n      ) {\n        // H1-H6\n        return {\n          type: \"header\",\n          content: $(element).text().trim(),\n        };\n      } else if (tagName === \"p\") {\n        // Paragraph\n        return WebExtractionService._extractText($, $(element));", "      } else if (tagName === \"p\") {\n        // Paragraph\n        return WebExtractionService._extractText($, $(element));\n      } else if (tagName === \"ul\" || tagName === \"ol\") {\n        // List\n        const isOrdered = tagName === \"ol\";\n        return {\n          type: \"list\",\n          content: $(element)\n            .find(\"li\")\n            .map(\n              (i, li) =>\n                `${isOrdered ? `${i + 1}. ` : \"\"}${$(li).text().trim()}`\n            )\n            .get()\n            .join(\", \"),\n        };", "      } else if (tagName === \"table\") {\n        // Table\n        return {\n          type: \"table\",\n          content: $(element)\n            .find(\"tr\")\n            .map((_, tr) =>\n              $(tr)\n                .find(\"td, th\")\n                .map((_, cell) => $(cell).text().trim())\n                .get()\n                .join(\" | \")\n            )\n            .get()\n            .join(\"\\n\"),\n        };\n      }\n    }\n\n    return null;\n  }\n}\n\nexport default WebExtractionService;\n"]}
