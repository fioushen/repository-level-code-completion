{"filename": "src/pages/api/trpc/[trpc].ts", "chunked_list": ["import { createNextApiHandler } from \"@trpc/server/adapters/next\";\n\nimport { env } from \"~/env.mjs\";\nimport { createTRPCContext } from \"~/server/api/trpc\";\nimport { appRouter } from \"~/server/api/root\";\n\n// export API handler\nexport default createNextApiHandler({\n  router: appRouter,\n  createContext: createTRPCContext,", "  router: appRouter,\n  createContext: createTRPCContext,\n  onError:\n    env.NODE_ENV === \"development\"\n      ? ({ path, error }) => {\n          console.error(\n            `\u274c tRPC failed on ${path ?? \"<no-path>\"}: ${error.message}`,\n          );\n        }\n      : undefined,", "        }\n      : undefined,\n});\n"]}
{"filename": "src/pages/api/auth/[...nextauth].ts", "chunked_list": ["import NextAuth from \"next-auth\";\nimport { authOptions } from \"~/server/auth\";\n\nexport default NextAuth(authOptions);\n"]}
{"filename": "src/store/store.ts", "chunked_list": ["import { create } from \"zustand\";\nimport type { Model, Profile, Thread } from \"~/types/appstate\";\n\nconst models = [\n  {\n    name: \"GPT-3.5-TURBO\",\n    id: \"gpt-3.5-turbo\",\n    description:\n      \"Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003. Will be updated with our latest model iteration.\",\n    maxTokens: 4096,", "      \"Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003. Will be updated with our latest model iteration.\",\n    maxTokens: 4096,\n    usageCost: 0.002,\n    trainingData: \"Up to Sep 2021\",\n  },\n  {\n    name: \"GPT-3.5-TURBO-0301\",\n    id: \"gpt-3.5-turbo-0301\",\n    description:\n      \"Snapshot of gpt-3.5-turbo from March 1st 2023. Unlike gpt-3.5-turbo, this model will not receive updates, and will only be supported for a three month period ending on June 1st 2023.\",", "    description:\n      \"Snapshot of gpt-3.5-turbo from March 1st 2023. Unlike gpt-3.5-turbo, this model will not receive updates, and will only be supported for a three month period ending on June 1st 2023.\",\n    maxTokens: 4096,\n    usageCost: 0.002,\n    trainingData: \"Up to Sep 2021\",\n  },\n  {\n    name: \"GPT-4 (Limited Beta)\",\n    id: \"gpt-4\",\n    description:", "    id: \"gpt-4\",\n    description:\n      \"More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Will be updated with our latest model iteration.\",\n    maxTokens: 8192,\n    promptCost: 0.03,\n    completionCost: 0.06,\n    trainingData: \"Up to Sep 2021\",\n    note: \"you need API Access to GPT-4 to use this model. If you haven't already, join the waitlist here: https://openai.com/waitlist/gpt-4-api\",\n  },\n  {", "  },\n  {\n    name: \"GPT-4-0314 (Limited Beta)\",\n    id: \"gpt-4-0314\",\n    description:\n      \"Snapshot of gpt-4 from March 14th 2023. Unlike gpt-4, this model will not receive updates, and will only be supported for a three month period ending on June 14th 2023.\",\n    maxTokens: 8192,\n    promptCost: 0.03,\n    completionCost: 0.06,\n    trainingData: \"Up to Sep 2021\",", "    completionCost: 0.06,\n    trainingData: \"Up to Sep 2021\",\n    note: \"you need API Access to GPT-4 to use this model. If you haven't already, join the waitlist here: https://openai.com/waitlist/gpt-4-api\",\n  },\n  {\n    name: \"GPT-4-32K (Limited Beta)\",\n    id: \"gpt-4-32k\",\n    description:\n      \"Same capabilities as GPT-4, but with 4x the context length. Will be updated with our latest model iteration.\",\n    trainingData: \"Up to Sep 2021\",", "      \"Same capabilities as GPT-4, but with 4x the context length. Will be updated with our latest model iteration.\",\n    trainingData: \"Up to Sep 2021\",\n    promptCost: 0.06,\n    completionCost: 0.12,\n    maxTokens: 32768,\n    note: \"you need API Access to GPT-4 to use this model. If you haven't already, join the waitlist here: https://openai.com/waitlist/gpt-4-api\",\n  },\n  {\n    name: \"GPT-4-32K-0314 (Limited Beta)\",\n    id: \"gpt-4-32k-0314\",", "    name: \"GPT-4-32K-0314 (Limited Beta)\",\n    id: \"gpt-4-32k-0314\",\n    description:\n      \"Snapshot of gpt-4-32k from March 14th 2023. Unlike gpt-4-32k, this model will not receive updates, and will only be supported for a three month period ending on June 14th 2023.\",\n    trainingData: \"Up to Sep 2021\",\n    promptCost: 0.06,\n    completionCost: 0.12,\n    maxTokens: 32768,\n    note: \"you need API Access to GPT-4 to use this model. If you haven't already, join the waitlist here: https://openai.com/waitlist/gpt-4-api\",\n  },", "    note: \"you need API Access to GPT-4 to use this model. If you haven't already, join the waitlist here: https://openai.com/waitlist/gpt-4-api\",\n  },\n] as Model[];\n\nconst initialThread = {\n  id: \"\",\n  name: \"\",\n  profileId: \"\",\n  budget: 0,\n  cost: 0,", "  budget: 0,\n  cost: 0,\n  description: \"\",\n  initialSystemInstruction: \"\",\n  messages: [],\n  model: models[0] as Model,\n  starred: false,\n  title: \"\",\n} as Thread;\n", "} as Thread;\n\nexport const initialValues = {\n  profile: {\n    id: \"\",\n    name: \"\",\n    model: models[0] as Model,\n    budget: 0,\n    cost: 0,\n    usage: {", "    cost: 0,\n    usage: {\n      completion_tokens: 0,\n      prompt_tokens: 0,\n      total_tokens: 0,\n    },\n    key: \"\",\n    threadIds: [],\n    organization: \"\",\n  } as Profile,", "    organization: \"\",\n  } as Profile,\n  profiles: [] as Profile[],\n  selectedProfile: \"\",\n  thread: initialThread,\n  threads: [] as Thread[],\n  selectedApiKey: 0,\n  apiKeyModal: false,\n  apiKeyError: false,\n  modelModal: false,", "  apiKeyError: false,\n  modelModal: false,\n  models,\n  width: 0,\n};\n\nconst getLocalProfileList = () => {\n  const raw = localStorage.getItem(\"Profiles\");\n  if (!raw) {\n    return null;\n  }\n  return JSON.parse(raw) as string[];\n};\nconst getSelectedProfile = () => {\n  const raw = localStorage.getItem(\"SelectedProfile\");", "  if (!raw) {\n    return null;\n  }\n  return JSON.parse(raw) as string[];\n};\nconst getSelectedProfile = () => {\n  const raw = localStorage.getItem(\"SelectedProfile\");\n  if (!raw) {\n    return null;\n  }\n  return JSON.parse(raw) as string;\n};\nexport const getProfile = (id: string) => {\n  const raw = localStorage.getItem(\"Profile_\" + id);", "  if (!raw) {\n    return;\n  }\n  return JSON.parse(raw) as Profile;\n};\nconst loadProfiles = () => {\n  const profileList = getLocalProfileList();\n  if (!profileList) {\n    return null;\n  }\n  const selectedProfile = getSelectedProfile();", "  if (!selectedProfile) {\n    return null;\n  }\n  const profiles: Profile[] = [];\n  for (const id of profileList) {\n    const profile = getProfile(id);\n    if (!profile) {\n      continue;\n    }\n    profiles.push(profile);\n  }", "  if (profiles.length === 0) {\n    return null;\n  }\n  const profile = profiles.find((p) => p.id === selectedProfile);\n  if (!profile) {\n    const profile = profiles[0] as Profile;\n    return { profiles, profile, selectedProfile: profile.id };\n  }\n  return { profiles, profile, selectedProfile };\n};\nexport const getThread = (id: string) => {\n  const raw = localStorage.getItem(\"Thread_\" + id);", "  if (raw) {\n    return JSON.parse(raw) as Thread;\n  }\n};\nexport const loadData = () => {\n  const profileData = loadProfiles();\n  if (!profileData) {\n    return null;\n  }\n  const { profiles, profile, selectedProfile } = profileData;\n  const threads = profile.threadIds\n    .map((id) => getThread(id))\n    .filter((t) => t !== undefined) as Thread[];\n  return { profiles, profile, selectedProfile, threads };\n};\n", "interface Store {\n  profile: Profile;\n  setProfile: (value: Profile) => void;\n  addProfile: (value: Profile) => void;\n  deleteProfile: (value: Profile) => void;\n  selectedProfile: string;\n  setSelectedProfile: (value: string) => void;\n  profiles: Profile[];\n  setProfiles: (value: Profile[]) => void;\n  thread: Thread;\n  setThread: (value: Thread) => void;\n  addThread: (value: Thread) => void;\n  deleteThread: (value: Thread) => void;\n  threads: Thread[];\n  setThreads: (value: Thread[]) => void;\n  apiKeyModal: boolean;\n  setApiKeyModal: (value: boolean) => void;\n  apiKeyError: boolean;\n  setApiKeyError: (value: boolean) => void;\n  models: Model[];\n  setModels: (value: Model[]) => void;\n  modelModal: boolean;\n  setModelModal: (value: boolean) => void;\n  selectedApiKey: number;\n  setSelectedApiKey: (value: number) => void;\n  width: number;\n  setWidth: (value: number) => void;\n  resetValues: () => void;\n  resetThread: () => void;\n  load: () => void;\n}\n\nconst updateSelectedProfile = (id: string) => {\n  localStorage.setItem(\"SelectedProfile\", JSON.stringify(id));\n};\nconst updateProfile = (profile: Profile) => {\n  localStorage.setItem(\"Profile_\" + profile.id, JSON.stringify(profile));\n};\nconst addProfile = (profile: Profile) => {\n  localStorage.setItem(\"Profile_\" + profile.id, JSON.stringify(profile));\n  const profileList = getLocalProfileList();", "  if (profileList) {\n    localStorage.setItem(\n      \"Profiles\",\n      JSON.stringify([...profileList, profile.id])\n    );\n  } else {\n    localStorage.setItem(\"Profiles\", JSON.stringify([profile.id]));\n  }\n};\nconst deleteProfile = (profile: Profile) => {\n  profile.threadIds.forEach((id) => deleteThread(id));\n  localStorage.removeItem(\"Profile_\" + profile.id);\n  const profileList = getLocalProfileList();", "  if (profileList) {\n    const newProfileList = profileList.filter((p) => p !== profile.id);\n    localStorage.setItem(\"Profiles\", JSON.stringify(newProfileList));\n    const selectedProfile = getSelectedProfile();\n    if (selectedProfile === profile.id) {\n      localStorage.removeItem(\"SelectedProfile\");\n    }\n    if (newProfileList.length === 0) {\n      localStorage.removeItem(\"Profiles\");\n    } else {\n      const newSelectedProfile = newProfileList[0];\n      localStorage.setItem(\n        \"SelectedProfile\",\n        JSON.stringify(newSelectedProfile)\n      );\n    }\n  }\n};\nconst updateThread = (thread: Thread) => {\n  localStorage.setItem(\"Thread_\" + thread.id, JSON.stringify(thread));\n};\nconst deleteThread = (id: string) => {\n  localStorage.removeItem(\"Thread_\" + id);\n};\nconst useStore = create<Store>((set) => ({\n  ...initialValues,\n  setProfiles: (value: Profile[]) => set({ profiles: value }),\n  setProfile: (value: Profile) => {\n    updateProfile(value);\n    set({ profile: value });\n  },\n  addProfile: (value: Profile) => {\n    addProfile(value);\n    set((state) => ({ profiles: [...state.profiles, value] }));\n  },\n  deleteProfile: (value: Profile) => {\n    deleteProfile(value);\n    set((state) => ({\n      profiles: state.profiles.filter((p) => p.id !== value.id),\n    }));\n  },\n  addThread: (value: Thread) => {\n    updateThread(value);\n    set((state) => ({\n      threads: [...state.threads, value],\n    }));\n  },\n  deleteThread: (value: Thread) => {\n    deleteThread(value.id);\n    set((state) => ({\n      threads: state.threads.filter((t) => t.id !== value.id),\n    }));\n  },\n  setSelectedProfile: (value: string) => {\n    updateSelectedProfile(value);\n    set({ selectedProfile: value });\n  },\n  setThread: (value: Thread) => {\n    updateThread(value);\n    set((state) => ({ thread: value, threads: [...state.threads, value] }));\n  },\n  setThreads: (value: Thread[]) => {\n    set({ threads: value });\n  },\n  setApiKeyModal: (value: boolean) => set({ apiKeyModal: value }),\n  setApiKeyError: (value: boolean) => set({ apiKeyError: value }),\n  setModels: (value: Model[]) => set({ models: value }),\n  setModelModal: (value: boolean) => set({ modelModal: value }),\n  setWidth: (value: number) => set({ width: value }),\n  setSelectedApiKey: (value: number) => set({ selectedApiKey: value }),\n  load: () => set({ ...initialValues, ...loadData() }),\n  resetThread: () => set({ thread: initialValues.thread }),\n  resetValues: () => set(initialValues),\n}));\n\nexport default useStore;\n"]}
{"filename": "src/utils/api.ts", "chunked_list": ["/**\n * This is the client-side entrypoint for your tRPC API. It is used to create the `api` object which\n * contains the Next.js App-wrapper, as well as your type-safe React Query hooks.\n *\n * We also create a few inference helpers for input and output types.\n */\nimport { httpBatchLink, loggerLink } from \"@trpc/client\";\nimport { createTRPCNext } from \"@trpc/next\";\nimport { type inferRouterInputs, type inferRouterOutputs } from \"@trpc/server\";\nimport superjson from \"superjson\";\n", "import { type inferRouterInputs, type inferRouterOutputs } from \"@trpc/server\";\nimport superjson from \"superjson\";\n\nimport { type AppRouter } from \"~/server/api/root\";\n\nconst getBaseUrl = () => {\n  if (typeof window !== \"undefined\") return \"\"; // browser should use relative url\n  if (process.env.VERCEL_URL) return `https://${process.env.VERCEL_URL}`; // SSR should use vercel url\n  return `http://localhost:${process.env.PORT ?? 3000}`; // dev SSR should use localhost\n};\n\n/** A set of type-safe react-query hooks for your tRPC API. */\nexport const api = createTRPCNext<AppRouter>({\n  config() {\n    return {\n      /**\n       * Transformer used for data de-serialization from the server.\n       *\n       * @see https://trpc.io/docs/data-transformers\n       */\n      transformer: superjson,\n\n      /**\n       * Links used to determine request flow from client to server.\n       *\n       * @see https://trpc.io/docs/links\n       */\n      links: [\n        loggerLink({\n          enabled: (opts) =>\n            process.env.NODE_ENV === \"development\" ||\n            (opts.direction === \"down\" && opts.result instanceof Error),\n        }),\n        httpBatchLink({\n          url: `${getBaseUrl()}/api/trpc`,\n        }),\n      ],\n    };\n  },\n  /**\n   * Whether tRPC should await queries when server rendering pages.\n   *\n   * @see https://trpc.io/docs/nextjs#ssr-boolean-default-false\n   */\n  ssr: false,\n});\n\n/**\n * Inference helper for inputs.\n *", " * @example type HelloInput = RouterInputs['example']['hello']\n */\nexport type RouterInputs = inferRouterInputs<AppRouter>;\n\n/**\n * Inference helper for outputs.\n *\n * @example type HelloOutput = RouterOutputs['example']['hello']\n */\nexport type RouterOutputs = inferRouterOutputs<AppRouter>;\n", "export type RouterOutputs = inferRouterOutputs<AppRouter>;\n"]}
{"filename": "src/server/auth.ts", "chunked_list": ["import { type GetServerSidePropsContext } from \"next\";\nimport {\n  getServerSession,\n  type NextAuthOptions,\n  type DefaultSession,\n} from \"next-auth\";\nimport AzureADProvider from \"next-auth/providers/azure-ad\";\nimport { PrismaAdapter } from \"@next-auth/prisma-adapter\";\nimport { env } from \"~/env.mjs\";\nimport { prisma } from \"~/server/db\";\n\n/**\n * Module augmentation for `next-auth` types. Allows us to add custom properties to the `session`", " * object and keep type safety.\n *\n * @see https://next-auth.js.org/getting-started/typescript#module-augmentation\n */\ndeclare module \"next-auth\" {\n  interface Session extends DefaultSession {\n    user: {\n      id: string;\n      // ...other properties\n      // role: UserRole;\n    } & DefaultSession[\"user\"];\n  }\n", "  // interface User {\n  //   // ...other properties\n  //   // role: UserRole;\n  // }\n}\n\n/**\n * Options for NextAuth.js used to configure adapters, providers, callbacks, etc.\n *\n * @see https://next-auth.js.org/configuration/options\n */\nexport const authOptions: NextAuthOptions = {\n  callbacks: {\n    session({ session, user }) {", "      if (session.user) {\n        session.user.id = user.id;\n        // session.user.role = user.role; <-- put other properties on the session here\n      }\n      return session;\n    },\n  },\n  adapter: PrismaAdapter(prisma),\n  providers: [\n    AzureADProvider({\n      clientId: env.AZURE_CLIENT_ID,\n      clientSecret: env.AZURE_CLIENT_SECRET,\n    }),\n    /**\n     * ...add more providers here.\n     *\n     * Most other providers require a bit more work than the Discord provider. For example, the\n     * GitHub provider requires you to add the `refresh_token_expires_in` field to the Account\n     * model. Refer to the NextAuth.js docs for the provider you want to use. Example:\n     *\n     * @see https://next-auth.js.org/providers/github\n     */\n  ],\n};\n\n/**\n * Wrapper for `getServerSession` so that you don't need to import the `authOptions` in every file.\n *\n * @see https://next-auth.js.org/configuration/nextjs\n */\nexport const getServerAuthSession = (ctx: {\n  req: GetServerSidePropsContext[\"req\"];\n  res: GetServerSidePropsContext[\"res\"];\n}) => {\n  return getServerSession(ctx.req, ctx.res, authOptions);\n};\n"]}
{"filename": "src/server/db.ts", "chunked_list": ["import { PrismaClient } from \"@prisma/client\";\n\nimport { env } from \"~/env.mjs\";\n\nconst globalForPrisma = globalThis as unknown as { prisma: PrismaClient };\n\nexport const prisma =\n  globalForPrisma.prisma ||\n  new PrismaClient({\n    log:", "  new PrismaClient({\n    log:\n      env.NODE_ENV === \"development\" ? [\"query\", \"error\", \"warn\"] : [\"error\"],\n  });\n\nif (env.NODE_ENV !== \"production\") globalForPrisma.prisma = prisma;\n"]}
{"filename": "src/server/api/trpc.ts", "chunked_list": ["/**\n * YOU PROBABLY DON'T NEED TO EDIT THIS FILE, UNLESS:\n * 1. You want to modify request context (see Part 1).\n * 2. You want to create a new middleware or type of procedure (see Part 3).\n *\n * TL;DR - This is where all the tRPC server stuff is created and plugged in. The pieces you will\n * need to use are documented accordingly near the end.\n */\n\n/**\n * 1. CONTEXT\n *\n * This section defines the \"contexts\" that are available in the backend API.\n *\n * These allow you to access things when processing a request, like the database, the session, etc.\n */", "import { type CreateNextContextOptions } from \"@trpc/server/adapters/next\";\nimport { type Session } from \"next-auth\";\n\nimport { getServerAuthSession } from \"~/server/auth\";\nimport { prisma } from \"~/server/db\";\n\ntype CreateContextOptions = {\n  session: Session | null;\n};\n\n/**\n * This helper generates the \"internals\" for a tRPC context. If you need to use it, you can export\n * it from here.\n *\n * Examples of things you may need it for:\n * - testing, so we don't have to mock Next.js' req/res\n * - tRPC's `createSSGHelpers`, where we don't have req/res\n *\n * @see https://create.t3.gg/en/usage/trpc#-servertrpccontextts\n */\nconst createInnerTRPCContext = (opts: CreateContextOptions) => {\n  return {\n    session: opts.session,\n    prisma,\n  };\n};\n\n/**\n * This is the actual context you will use in your router. It will be used to process every request\n * that goes through your tRPC endpoint.\n *\n * @see https://trpc.io/docs/context\n */\nexport const createTRPCContext = async (opts: CreateNextContextOptions) => {\n  const { req, res } = opts;\n\n  // Get the session from the server using the getServerSession wrapper function\n  const session = await getServerAuthSession({ req, res });\n\n  return createInnerTRPCContext({\n    session,\n  });\n};\n\n/**\n * 2. INITIALIZATION\n *\n * This is where the tRPC API is initialized, connecting the context and transformer. We also parse\n * ZodErrors so that you get typesafety on the frontend if your procedure fails due to validation\n * errors on the backend.\n */\nimport { initTRPC, TRPCError } from \"@trpc/server\";\nimport superjson from \"superjson\";\nimport { ZodError } from \"zod\";\n\nconst t = initTRPC.context<typeof createTRPCContext>().create({\n  transformer: superjson,\n  errorFormatter({ shape, error }) {\n    return {\n      ...shape,\n      data: {\n        ...shape.data,\n        zodError:\n          error.cause instanceof ZodError ? error.cause.flatten() : null,\n      },\n    };\n  },\n});\n\n/**\n * 3. ROUTER & PROCEDURE (THE IMPORTANT BIT)\n *\n * These are the pieces you use to build your tRPC API. You should import these a lot in the\n * \"/src/server/api/routers\" directory.\n */\n\n/**\n * This is how you create new routers and sub-routers in your tRPC API.\n *\n * @see https://trpc.io/docs/router\n */\nexport const createTRPCRouter = t.router;\n\n/**\n * Public (unauthenticated) procedure\n *\n * This is the base piece you use to build new queries and mutations on your tRPC API. It does not\n * guarantee that a user querying is authorized, but you can still access user session data if they\n * are logged in.\n */\nexport const publicProcedure = t.procedure;\n\n/** Reusable middleware that enforces users are logged in before running the procedure. */\nconst enforceUserIsAuthed = t.middleware(({ ctx, next }) => {", "  if (!ctx.session || !ctx.session.user) {\n    throw new TRPCError({ code: \"UNAUTHORIZED\" });\n  }\n  return next({\n    ctx: {\n      // infers the `session` as non-nullable\n      session: { ...ctx.session, user: ctx.session.user },\n    },\n  });\n});\n\n/**\n * Protected (authenticated) procedure\n *\n * If you want a query or mutation to ONLY be accessible to logged in users, use this. It verifies\n * the session is valid and guarantees `ctx.session.user` is not null.\n *\n * @see https://trpc.io/docs/procedures\n */\nexport const protectedProcedure = t.procedure.use(enforceUserIsAuthed);\n"]}
{"filename": "src/server/api/root.ts", "chunked_list": ["import { createTRPCRouter } from \"~/server/api/trpc\";\nimport { exampleRouter } from \"~/server/api/routers/example\";\nimport { gptRouter } from \"./routers/gpt\";\n\n/**\n * This is the primary router for your server.\n *\n * All routers added in /api/routers should be manually added here.\n */\nexport const appRouter = createTRPCRouter({", " */\nexport const appRouter = createTRPCRouter({\n  example: exampleRouter,\n  gpt: gptRouter,\n});\n\n// export type definition of API\nexport type AppRouter = typeof appRouter;\n"]}
{"filename": "src/server/api/routers/gpt.ts", "chunked_list": ["import { TRPCError } from \"@trpc/server\";\nimport { Configuration, OpenAIApi } from \"openai\";\nimport { type AxiosError } from \"axios\";\nimport { z } from \"zod\";\nimport {\n  createTRPCRouter,\n  publicProcedure,\n  protectedProcedure,\n} from \"~/server/api/trpc\";\nimport type { Message } from \"~/types/appstate\";\n", "export type ChatResponse = {\n  id: string;\n  created: number;\n  model: string;\n  choices: [\n    {\n      finish_reason: string;\n      index: number;\n      message: Message;\n    }\n  ];\n  object: string;\n  usage: {\n    completion_tokens: number;\n    prompt_tokens: number;\n    total_tokens: number;\n  };\n};\n\nexport const gptRouter = createTRPCRouter({\n  post: publicProcedure\n    .input(\n      z.object({\n        apiKey: z.string(),\n        model: z.string(),\n        messages: z.array(\n          z.object({\n            role: z.enum([\"user\", \"system\", \"assistant\"]),\n            content: z.string(),\n          })\n        ),\n      })\n    )\n    .mutation(async ({ input }) => {\n      const configuration = new Configuration({\n        apiKey: input.apiKey,\n      });\n      const openai = new OpenAIApi(configuration);\n      const response = await openai\n        .createChatCompletion({\n          model: input.model,\n          messages: input.messages,\n        })", "        .catch((error: AxiosError) => {\n          console.error(error);\n          if (error.response) {\n            console.log(error.response.status);\n            console.log(error.response.data);\n            throw new TRPCError({\n              code: \"INTERNAL_SERVER_ERROR\",\n              cause: error.response.data,\n              message: error.message,\n            });\n          } else {\n            console.log(error.message);\n            throw new TRPCError({\n              code: \"INTERNAL_SERVER_ERROR\",\n              message: error.message,\n            });\n          }\n        });\n      return response.data as ChatResponse;\n    }),\n});\n"]}
{"filename": "src/server/api/routers/example.ts", "chunked_list": ["import { z } from \"zod\";\n\nimport {\n  createTRPCRouter,\n  publicProcedure,\n  protectedProcedure,\n} from \"~/server/api/trpc\";\n\nexport const exampleRouter = createTRPCRouter({\n  hello: publicProcedure", "export const exampleRouter = createTRPCRouter({\n  hello: publicProcedure\n    .input(z.object({ text: z.string() }))\n    .query(({ input }) => {\n      return {\n        greeting: `Hello ${input.text}`,\n      };\n    }),\n\n  getAll: publicProcedure.query(({ ctx }) => {", "\n  getAll: publicProcedure.query(({ ctx }) => {\n    return ctx.prisma.example.findMany();\n  }),\n\n  getSecretMessage: protectedProcedure.query(() => {\n    return \"you can now see this secret message!\";\n  }),\n});\n", "});\n"]}
{"filename": "src/types/appstate.ts", "chunked_list": ["// appstate.ts\n\nexport type Message = {\n  role: \"user\" | \"system\" | \"assistant\";\n  content: string;\n};\n\nexport type Usage = {\n  total_tokens: number;\n  completion_tokens: number;\n  prompt_tokens: number;\n};\n", "export type Profile = {\n  id: string;\n  key: string;\n  name: string;\n  organization?: string;\n  usage: {\n    total_tokens: number;\n    completion_tokens: number;\n    prompt_tokens: number;\n  };\n  cost: number;\n  budget: number;\n  threadIds: string[];\n};\n", "export interface Model {\n  id: string;\n  maxTokens: number;\n  name: string;\n  description: string;\n  trainingData: string;\n  promptCost?: number;\n  completionCost?: number;\n  usageCost?: number;\n  note?: string;\n}\n", "export type Thread = {\n  id: string;\n  profileId: string;\n  messages: Message[];\n  model: Model;\n  initialSystemInstruction: string;\n  title: string;\n  description: string;\n  starred: boolean;\n  cost: number;\n  budget: number;\n};\n"]}
