{"filename": "src/global.d.ts", "chunked_list": ["type Command = {\n  name: string;\n  aliases: string[];\n  description: string;\n  execute: (args: string[], output: NodeJS.WriteStream, commandHandler: CommandHandler) => Promise<void>;\n};\n\ntype CommandHandler = {\n  getCommands: () => Command[];\n  execute: (commandName: string, args: string[], output: NodeJS.WriteStream) => Promise<void>;\n};\n", "type Page = {\n  url: string;\n  text: string;\n  title: string;\n};\n\ninterface Config {\n  currentVectorStoreDatabasePath: string;\n  numContextDocumentsToRetrieve: number;\n  numMemoryDocumentsToRetrieve: number;\n  useWindowMemory: boolean;\n}\n", "interface FileInfo {\n  name: string;\n  size: number;\n}\n\ninterface DirectoryContent {\n  [directory: string]: FileInfo[];\n}\n"]}
{"filename": "src/commands.ts", "chunked_list": ["import chalk from 'chalk';\nimport changeContextStoreCommand from './commands/switchContextStoreCommand.js';\nimport helpCommand from './commands/helpCommand.js';\nimport quitCommand from './commands/quitCommand.js';\nimport resetChatCommand from './commands/resetChatCommand.js';\nimport addDocumentCommand from './commands/addDocumentCommand.js';\nimport addURLCommand from './commands/addURLCommand.js';\nimport addYouTubeCommand from './commands/addYouTubeCommand.js';\nimport setContextConfigCommand from './commands/setContextConfigCommand.js';\nimport setMemoryConfigCommand from './commands/setMemoryConfigCommand.js';", "import setContextConfigCommand from './commands/setContextConfigCommand.js';\nimport setMemoryConfigCommand from './commands/setMemoryConfigCommand.js';\nimport toggleWindowBufferMemoryCommand from './commands/toggleWindowBufferMemoryCommand.js';\nimport listContextStoresCommand from './commands/listContextStoresCommand.js';\n\nfunction createCommandHandler(): CommandHandler {\n  const commands: Command[] = [\n    helpCommand,\n    quitCommand,\n    resetChatCommand,\n    addDocumentCommand,\n    addURLCommand,\n    addYouTubeCommand,\n    setContextConfigCommand,\n    setMemoryConfigCommand,\n    toggleWindowBufferMemoryCommand,\n    listContextStoresCommand,\n    changeContextStoreCommand,\n  ];\n", "  function getCommands() {\n    return commands;\n  }\n\n  const commandHandler: CommandHandler = {\n    getCommands,\n    async execute(commandName: string, args: string[], output: NodeJS.WriteStream) {\n      const command = commands.find((cmd) => cmd.name === commandName || cmd.aliases.includes(commandName));\n      if (command) {\n        await command.execute(args, output, commandHandler);\n      } else {\n        output.write(chalk.red('Unknown command. Type /help to see the list of available commands.\\n'));\n      }\n    },\n  };\n  return commandHandler;\n}\n\nexport default createCommandHandler;\n", "      if (command) {\n        await command.execute(args, output, commandHandler);\n      } else {\n        output.write(chalk.red('Unknown command. Type /help to see the list of available commands.\\n'));\n      }\n    },\n  };\n  return commandHandler;\n}\n\nexport default createCommandHandler;\n"]}
{"filename": "src/updateReadme.ts", "chunked_list": ["import fs from 'fs';\nimport path from 'path';\nimport { getProjectRoot } from './config/index.js';\n\nconst projectRootDir = getProjectRoot();\n\nconst commandsDir = path.join(projectRootDir, 'src', 'commands');\nconst readmePath = path.join(projectRootDir, 'README.md');\n\nconst commandFiles = fs.readdirSync(commandsDir).filter((file) => file !== 'command.ts');", "\nconst commandFiles = fs.readdirSync(commandsDir).filter((file) => file !== 'command.ts');\n\nasync function getCommandsMarkdown() {\n  const commandsPromises = commandFiles.map(async (file) => {\n    const commandModule = await import(path.join(commandsDir, file));\n    const command = commandModule.default;\n    const aliases =\n      command.aliases.length > 0 ? ` (${command.aliases.map((alias: string) => `/${alias}`).join(', ')})` : '';\n    return `- \\`/${command.name}\\`${aliases} - ${command.description}`;\n  });\n\n  const commands = await Promise.all(commandsPromises);\n  return commands.join('\\n');\n}\n\n(async () => {\n  const commandsMarkdown = await getCommandsMarkdown();\n  const readmeContent = fs.readFileSync(readmePath, 'utf8');\n  const updatedReadmeContent = readmeContent.replace(\n    /<!-- COMMANDS_START -->([\\s\\S]*?)<!-- COMMANDS_END -->/,\n    `<!-- COMMANDS_START -->\\n${commandsMarkdown}\\n<!-- COMMANDS_END -->`\n  );\n\n  fs.writeFileSync(readmePath, updatedReadmeContent, 'utf8');\n})();\n"]}
{"filename": "src/index.ts", "chunked_list": ["/* eslint-disable no-await-in-loop */\nimport dotenv from 'dotenv';\nimport { OpenAIChat } from 'langchain/llms/openai';\n// eslint-disable-next-line import/no-unresolved\nimport * as readline from 'node:readline/promises';\nimport path from 'path';\nimport fs from 'fs';\n/* This line of code is importing the `stdin` and `stdout` streams from the `process` module in\nNode.js. These streams are used for reading input from the user and writing output to the console,\nrespectively. */\nimport { stdin as input, stdout as output } from 'node:process';\nimport { CallbackManager } from 'langchain/callbacks';\nimport { ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate } from 'langchain/prompts';\nimport { LLMChain } from 'langchain/chains';\nimport { oneLine } from 'common-tags';\nimport chalk from 'chalk';\nimport logChat from './chatLogger.js';\nimport createCommandHandler from './commands.js';\nimport { getMemoryVectorStore, addDocumentsToMemoryVectorStore, getBufferWindowMemory } from './lib/memoryManager.js';\nimport { getContextVectorStore } from './lib/contextManager.js';\nimport { getRelevantContext } from './lib/vectorStoreUtils.js';\nimport sanitizeInput from './utils/sanitizeInput.js';\nimport { getConfig, getProjectRoot } from './config/index.js';\n\nconst projectRootDir = getProjectRoot();\n\ndotenv.config();\n\n// Set up the chat log directory\nconst chatLogDirectory = path.join(projectRootDir, 'chat_logs');\n\n// Get the prompt template\nconst systemPromptTemplate = fs.readFileSync(path.join(projectRootDir, 'src/prompt.txt'), 'utf8');\n", "// Set up the readline interface to read input from the user and write output to the console\nconst rl = readline.createInterface({ input, output });\n\n// Set up CLI commands\nconst commandHandler: CommandHandler = createCommandHandler();\n\nconst callbackManager = CallbackManager.fromHandlers({\n  // This function is called when the LLM generates a new token (i.e., a prediction for the next word)\n  async handleLLMNewToken(token: string) {\n    // Write the token to the output stream (i.e., the console)\n    output.write(token);\n  },\n});\n\nconst llm = new OpenAIChat({\n  streaming: true,\n  callbackManager,\n  modelName: process.env.MODEL || 'gpt-3.5-turbo',\n});\n\nconst systemPrompt = SystemMessagePromptTemplate.fromTemplate(oneLine`\n  ${systemPromptTemplate}\n`);\n\nconst chatPrompt = ChatPromptTemplate.fromPromptMessages([\n  systemPrompt,\n  HumanMessagePromptTemplate.fromTemplate('QUESTION: \"\"\"{input}\"\"\"'),\n]);\n\nconst windowMemory = getBufferWindowMemory();\n\nconst chain = new LLMChain({\n  prompt: chatPrompt,\n  memory: windowMemory,\n  llm,\n});\n\n// eslint-disable-next-line no-constant-condition", "while (true) {\n  output.write(chalk.green('\\nStart chatting or type /help for a list of commands\\n'));\n  const userInput = await rl.question('> ');\n  let response;\n  if (userInput.startsWith('/')) {\n    const [command, ...args] = userInput.slice(1).split(' ');\n    await commandHandler.execute(command, args, output);\n  } else {\n    const memoryVectorStore = await getMemoryVectorStore();\n    const contextVectorStore = await getContextVectorStore();\n    const question = sanitizeInput(userInput);\n    const config = getConfig();\n    const context = await getRelevantContext(contextVectorStore, question, config.numContextDocumentsToRetrieve);\n    const history = await getRelevantContext(memoryVectorStore, question, config.numMemoryDocumentsToRetrieve);", "    try {\n      response = await chain.call({\n        input: question,\n        context,\n        history,\n        immediate_history: config.useWindowMemory ? windowMemory : '',\n      });\n      if (response) {\n        await addDocumentsToMemoryVectorStore([\n          { content: question, metadataType: 'question' },\n          { content: response.text, metadataType: 'answer' },\n        ]);\n        await logChat(chatLogDirectory, question, response.response);\n      }", "    } catch (error) {\n      if (error instanceof Error && error.message.includes('Cancel:')) {\n        // TODO: Handle cancel\n      } else if (error instanceof Error) {\n        output.write(chalk.red(error.message));\n      } else {\n        output.write(chalk.red(error));\n      }\n    }\n  }\n  output.write('\\n');\n}\n"]}
{"filename": "src/chatLogger.ts", "chunked_list": ["import fs from 'fs-extra';\nimport path from 'path';\n\ninterface ChatHistory {\n  timestamp: string;\n  question: string;\n  answer: string;\n}\n\nconst ensureLogDirectory = (logDirectory: string): void => {\n  fs.ensureDirSync(logDirectory);\n};\n\nconst getLogFilename = (): string => {\n  const currentDate = new Date();\n  const year = currentDate.getFullYear();\n  const month = String(currentDate.getMonth() + 1).padStart(2, '0');\n  const day = String(currentDate.getDate()).padStart(2, '0');\n\n  return `${year}-${month}-${day}.json`;\n};\n\nconst logChat = async (logDirectory: string, question: string, answer: string): Promise<void> => {\n  const timestamp = new Date().toISOString();\n  const chatHistory: ChatHistory = { timestamp, question, answer };\n  const logFilename = getLogFilename();\n  const logFilePath = path.join(logDirectory, logFilename);\n\n  ensureLogDirectory(logDirectory);\n", "  if (!fs.existsSync(logFilePath)) {\n    await fs.writeJson(logFilePath, [chatHistory]);\n  } else {\n    const chatHistoryArray = await fs.readJson(logFilePath);\n    chatHistoryArray.push(chatHistory);\n    await fs.writeJson(logFilePath, chatHistoryArray);\n  }\n};\n\nexport default logChat;\n"]}
{"filename": "src/commands/toggleWindowBufferMemoryCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { setUseWindowMemory, getConfig } from '../config/index.js';\n\nconst toggleWindowBufferMemoryCommand = createCommand(\n  'toggle-window-memory',\n  ['wm'],\n  `Toggles the window buffer memory (MemoryBot's short-term transient memory) on or off.`,\n  async (_args, output) => {\n    setUseWindowMemory(!getConfig().useWindowMemory);", "  async (_args, output) => {\n    setUseWindowMemory(!getConfig().useWindowMemory);\n    const config = getConfig();\n    output.write(chalk.blue(`Use Window Buffer Memory set to ${config.useWindowMemory}`));\n  }\n);\nexport default toggleWindowBufferMemoryCommand;\n"]}
{"filename": "src/commands/switchContextStoreCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { loadOrCreateEmptyVectorStore } from '../lib/contextManager.js';\n\nconst changeContextStoreCommand = createCommand(\n  'change-context-store',\n  ['ccs'],\n  `Loads an existing or creates a new empty context vector store as a subdirectory of the db directory.\\n\n    Arguments: \\`subdirectory\\`\\n\n    Example: /change-context-store newcontext`,", "    Arguments: \\`subdirectory\\`\\n\n    Example: /change-context-store newcontext`,\n  async (args, output) => {\n    if (!args || args.length !== 1) {\n      output.write(chalk.red('Invalid number of arguments. Usage: /change-context-store `subdirectory`\\n'));\n      return;\n    }\n    const subDirectory = args[0];\n    await loadOrCreateEmptyVectorStore(subDirectory);\n  }\n);\nexport default changeContextStoreCommand;\n"]}
{"filename": "src/commands/addYouTubeCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { addYouTube } from '../lib/contextManager.js';\n\nconst addYouTubeCommand = createCommand(\n  'add-youtube',\n  ['yt'],\n  `Adds the transcript from a youtube video and adds it to the context vector store.\\n\n    Arguments: \\`youtube url\\` or \\`youtube videoid\\`\\n\n    Example: /add-url https://www.youtube.com/watch?v=VMj-3S1tku0`,", "    Arguments: \\`youtube url\\` or \\`youtube videoid\\`\\n\n    Example: /add-url https://www.youtube.com/watch?v=VMj-3S1tku0`,\n  async (args, output) => {\n    if (!args || args.length !== 1) {\n      output.write(chalk.red('Invalid number of arguments. Usage: /add-url `youtube url` or `youtube videoid`\\n'));\n      return;\n    }\n    const URLOrVideoID = args[0];\n    await addYouTube(URLOrVideoID);\n  }\n);\nexport default addYouTubeCommand;\n"]}
{"filename": "src/commands/addURLCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { addURL } from '../lib/contextManager.js';\n\nconst addURLCommand = createCommand(\n  'add-url',\n  ['url'],\n  `Scrapes the content from a url and adds it to the context vector store.\\n\n    Arguments: \\`url\\`, \\`selector to extract\\` (Default: body), \\`Maximum number of links to follow\\` (Default: 20), \\`Ignore pages with less than n characters\\` (Default: 200)\\n\n    Example: /add-url https://dociq.io main 10 500\\n", "    Arguments: \\`url\\`, \\`selector to extract\\` (Default: body), \\`Maximum number of links to follow\\` (Default: 20), \\`Ignore pages with less than n characters\\` (Default: 200)\\n\n    Example: /add-url https://dociq.io main 10 500\\n\n    This operation may try to generate a large number of embeddings depending on the structure of the web pages and may lead to rate-limiting.\\n\n    To avoid this, you can try to target a specific selector such as \\`.main\\``,\n  async (args, output) => {\n    if (!args || args.length > 4) {\n      output.write(\n        chalk.red(\n          'Invalid number of arguments. Usage: /add-url `url` `selector to extract` `Maximum number of links to follow` `Ignore pages with less than n characters`\\n'\n        )\n      );\n      return;\n    }\n    const url = args[0];\n    const selector = args[1];\n    const maxLinks = parseInt(args[2], 10) || 20;\n    const minChars = parseInt(args[3], 10) || 200;\n    await addURL(url, selector, maxLinks, minChars);\n  }\n);\nexport default addURLCommand;\n"]}
{"filename": "src/commands/addDocumentCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { addDocument } from '../lib/contextManager.js';\n\nconst addDocumentCommand = createCommand(\n  'add-docs',\n  ['docs'],\n  `Adds new documents from your configured docs directory to the context vector store.\\n\n    Usage: /add-docs example.txt example.md\\n\n    Supports the following file types: .txt, .md, .pdf, .docx, .csv, .epub`,", "    Usage: /add-docs example.txt example.md\\n\n    Supports the following file types: .txt, .md, .pdf, .docx, .csv, .epub`,\n  async (args: string[], output: NodeJS.WriteStream) => {\n    if (!args) {\n      output.write(chalk.red('Invalid number of arguments. Usage: /add-docs example.txt example.md\\n'));\n      return;\n    }\n    await addDocument(args);\n  }\n);\nexport default addDocumentCommand;\n"]}
{"filename": "src/commands/listContextStoresCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { listContextStores } from '../lib/contextManager.js';\n\nconst listContextStoresCommand = createCommand(\n  'list-context-stores',\n  ['lcs'],\n  `Lists all available context vector stores and their details.\\n`,\n  async (args, output) => {\n    if (!args || args.length > 0) {\n      output.write(chalk.red('Invalid number of arguments. Usage: /list-context-stores\\n'));\n      return;\n    }\n    await listContextStores();\n  }\n);\nexport default listContextStoresCommand;\n", "  async (args, output) => {\n    if (!args || args.length > 0) {\n      output.write(chalk.red('Invalid number of arguments. Usage: /list-context-stores\\n'));\n      return;\n    }\n    await listContextStores();\n  }\n);\nexport default listContextStoresCommand;\n"]}
{"filename": "src/commands/setMemoryConfigCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { setNumMemoryDocumentsToRetrieve, getConfig } from '../config/index.js';\n\nconst setMemoryConfigCommand = createCommand(\n  'memory-config',\n  ['mc'],\n  `Sets the number of relevant documents to return from the memory vector store.\\n\n    Arguments: \\`number of documents\\` (Default: 4)\\n\n    Example: /memory-config 10`,", "    Arguments: \\`number of documents\\` (Default: 4)\\n\n    Example: /memory-config 10`,\n  async (args, output) => {\n    if (!args || args.length !== 1) {\n      output.write(chalk.red('Invalid number of arguments. Usage: /memory-config `number of documents`\\n'));\n      return;\n    }\n    const numMemoryDocumentsToRetrieve = parseInt(args[0], 10);\n    setNumMemoryDocumentsToRetrieve(numMemoryDocumentsToRetrieve);\n    const config = getConfig();\n    output.write(chalk.blue(`Number of memory documents to retrieve set to ${config.numMemoryDocumentsToRetrieve}`));\n  }\n);\nexport default setMemoryConfigCommand;\n"]}
{"filename": "src/commands/quitCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\n\nconst exitCommand = createCommand('quit', ['q'], 'Terminates the script', (_args, output) => {\n  output.write(chalk.yellow('\\nThanks for talking, bye!\\n'));\n  process.exit(0);\n});\n\nexport default exitCommand;\n", "export default exitCommand;\n"]}
{"filename": "src/commands/setContextConfigCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { setNumContextDocumentsToRetrieve, getConfig } from '../config/index.js';\n\nconst setContextConfigCommand = createCommand(\n  'context-config',\n  ['cc'],\n  `Sets the number of relevant documents to return from the context vector store.\\n\n    Arguments: \\`number of documents\\` (Default: 6)\\n\n    Example: \\`/context-config 10\\``,", "    Arguments: \\`number of documents\\` (Default: 6)\\n\n    Example: \\`/context-config 10\\``,\n  async (args, output) => {\n    if (!args || args.length !== 1) {\n      output.write(chalk.red('Invalid number of arguments. Usage: /context-config `number of documents`\\n'));\n      return;\n    }\n    const numContextDocumentsToRetrieve = parseInt(args[0], 10);\n    setNumContextDocumentsToRetrieve(numContextDocumentsToRetrieve);\n    const config = getConfig();\n    output.write(chalk.blue(`Number of context documents to retrieve set to ${config.numContextDocumentsToRetrieve}`));\n  }\n);\nexport default setContextConfigCommand;\n"]}
{"filename": "src/commands/resetChatCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\nimport { resetBufferWindowMemory, resetMemoryVectorStore, setMemoryVectorStore } from '../lib/memoryManager.js';\n\nconst resetChatCommand = createCommand(\n  'reset',\n  [],\n  'Resets the chat and starts a new conversation - This clears the memory vector store and the buffer window memory.',\n  async (_args, output) => {\n    output.write(chalk.yellow('\\nResetting the chat!\\n'));", "  async (_args, output) => {\n    output.write(chalk.yellow('\\nResetting the chat!\\n'));\n    await resetMemoryVectorStore((newMemoryVectorStore) => {\n      setMemoryVectorStore(newMemoryVectorStore);\n    });\n    resetBufferWindowMemory();\n  }\n);\nexport default resetChatCommand;\n", "export default resetChatCommand;\n"]}
{"filename": "src/commands/helpCommand.ts", "chunked_list": ["import chalk from 'chalk';\nimport createCommand from './command.js';\n\nconst helpCommand = createCommand(\n  'help',\n  ['h', '?'],\n  'Show the list of available commands',\n  (_args, output, commandHandler) =>\n    new Promise<void>((resolve) => {\n      output.write(chalk.blue('Usage:\\n'));", "    new Promise<void>((resolve) => {\n      output.write(chalk.blue('Usage:\\n'));\n      output.write('Ask memorybot to write some marketing materials and press enter.\\n');\n      output.write(chalk.blue('\\nAvailable commands:\\n'));\n      commandHandler.getCommands().forEach((command) => {\n        const aliases = command.aliases.length > 0 ? ` (/${command.aliases.join(', /')})` : '';\n        output.write(chalk.yellow(`/${command.name}${aliases}`));\n        output.write(` - ${command.description}`);\n        output.write('\\n');\n      });", "        output.write('\\n');\n      });\n      resolve();\n    })\n);\n\nexport default helpCommand;\n"]}
{"filename": "src/commands/command.ts", "chunked_list": ["/**\n * The function creates a command object with a name, aliases, description, and an execute function\n * that returns a Promise.\n * @param {string} name - A string representing the name of the command.\n * @param {string[]} aliases - An array of alternative names that can be used to call the command. For\n * example, if the command is named \"help\", aliases could include \"h\" or \"info\".\n * @param {string} description - A brief description of what the command does.\n * @param execute - The `execute` parameter is a function that takes in three arguments:\n * @returns A `Command` object is being returned.\n */\nfunction createCommand(\n  name: string,\n  aliases: string[],\n  description: string,\n  execute: (args: string[], output: NodeJS.WriteStream, commandHandler: CommandHandler) => Promise<void>\n): Command {\n  return { name, aliases, description, execute };\n}\nexport default createCommand;\n", "function createCommand(\n  name: string,\n  aliases: string[],\n  description: string,\n  execute: (args: string[], output: NodeJS.WriteStream, commandHandler: CommandHandler) => Promise<void>\n): Command {\n  return { name, aliases, description, execute };\n}\nexport default createCommand;\n"]}
{"filename": "src/utils/getDirectoryFiles.ts", "chunked_list": ["import path from 'path';\nimport fs from 'node:fs/promises';\n\nexport default async function getDirectoryFiles(directoryPath: string): Promise<string[]> {\n  const fileNames = await fs.readdir(directoryPath);\n\n  const filePathsPromises = fileNames.map(async (fileName) => {\n    const filePath = path.join(directoryPath, fileName);\n    const stat = await fs.stat(filePath);\n\n    if (stat.isDirectory()) {\n      const subDirectoryFiles = await getDirectoryFiles(filePath);\n      return subDirectoryFiles;\n    }\n    return filePath;\n  });\n\n  const filePathsArray = await Promise.all(filePathsPromises);\n  const filePaths = filePathsArray.flat();\n  return filePaths;\n}\n", "    if (stat.isDirectory()) {\n      const subDirectoryFiles = await getDirectoryFiles(filePath);\n      return subDirectoryFiles;\n    }\n    return filePath;\n  });\n\n  const filePathsArray = await Promise.all(filePathsPromises);\n  const filePaths = filePathsArray.flat();\n  return filePaths;\n}\n"]}
{"filename": "src/utils/createDirectory.ts", "chunked_list": ["import fs from 'node:fs/promises';\n\nexport default async function createDirectory(directoryPath: string): Promise<void> {\n  if (await fs.stat(directoryPath).catch(() => false)) {\n    return;\n  }\n  await fs.mkdir(directoryPath, { recursive: true });\n}\n"]}
{"filename": "src/utils/getDirectoryListWithDetails.ts", "chunked_list": ["import fs from 'node:fs/promises';\nimport path from 'path';\n\nexport default async function getDirectoryListWithDetails(\n  directory: string,\n  contents: DirectoryContent = {}\n): Promise<DirectoryContent> {\n  const dirents = await fs.readdir(directory, { withFileTypes: true });\n  const newContents: DirectoryContent = { ...contents };\n  const files: FileInfo[] = [];\n\n  const actions = dirents.map(async (dirent) => {\n    const res = path.resolve(directory, dirent.name);", "    if (dirent.isDirectory()) {\n      const subdirContents = await getDirectoryListWithDetails(res, newContents);\n      Object.assign(newContents, subdirContents);\n    } else if (dirent.isFile() && dirent.name !== '.gitignore') {\n      const stats = await fs.stat(res);\n      files.push({ name: dirent.name, size: Math.ceil(stats.size / 1024) });\n    }\n  });\n\n  await Promise.all(actions);\n", "  if (files.length) {\n    newContents[directory] = files;\n  }\n\n  return newContents;\n}\n"]}
{"filename": "src/utils/resolveURL.ts", "chunked_list": ["/**\n * The function resolves a URL from a given base URL and returns the resolved URL as a string.\n * @param {string} from - The `from` parameter is a string representing the base URL that the `to`\n * parameter will be resolved against. It can be an absolute or relative URL.\n * @param {string} to - The `to` parameter is a string representing the URL that needs to be resolved.\n * It can be an absolute URL or a relative URL.\n * @returns The function `resolve` returns a string that represents the resolved URL. If the `to`\n * parameter is a relative URL, the function returns a string that represents the resolved URL relative\n * to the `from` parameter. If the `to` parameter is an absolute URL, the function returns a string\n * that represents the resolved URL.\n */", " * to the `from` parameter. If the `to` parameter is an absolute URL, the function returns a string\n * that represents the resolved URL.\n */\nexport default function resolve(from: string, to: string) {\n  const resolvedUrl = new URL(to, new URL(from, 'resolve://'));\n  if (resolvedUrl.protocol === 'resolve:') {\n    // `from` is a relative URL.\n    const { pathname, search, hash } = resolvedUrl;\n    return pathname + search + hash;\n  }\n  return resolvedUrl.toString();\n}\n"]}
{"filename": "src/utils/sanitizeInput.ts", "chunked_list": ["/**\n * The function sanitizes a string input by removing leading/trailing white spaces and replacing new\n * lines with spaces.\n * @param {string} input - The input parameter is a string that needs to be sanitized.\n * @returns The function `sanitizeInput` is returning a string. The string is the input string with\n * leading and trailing whitespace removed, and all newline characters replaced with a space character.\n */\nexport default function sanitizeInput(input: string): string {\n  return input.trim().replaceAll('\\n', ' ');\n}\n"]}
{"filename": "src/config/index.ts", "chunked_list": ["import type { Options } from 'ora';\nimport type { Writable } from 'stream';\nimport { fileURLToPath } from 'url';\nimport path from 'path';\n\nexport function getProjectRoot() {\n  const currentModulePath = fileURLToPath(import.meta.url);\n  const projectRoot = path.resolve(path.dirname(currentModulePath), '..', '..');\n  return projectRoot;\n}\n", "export function getDefaultOraOptions(output: Writable): Options {\n  return {\n    text: 'Loading',\n    stream: output,\n    discardStdin: false,\n  };\n}\n\nconst defaultConfig: Config = {\n  currentVectorStoreDatabasePath: path.join(getProjectRoot(), process.env.VECTOR_STORE_DIR || 'db/default'),\n  numContextDocumentsToRetrieve: 6,\n  numMemoryDocumentsToRetrieve: 4,\n  useWindowMemory: true,\n};\n\nlet config: Config = { ...defaultConfig };\n", "export function getConfig(): Config {\n  return config;\n}\n\nexport function setCurrentVectorStoreDatabasePath(currentVectorStoreDatabasePath: string) {\n  config = { ...config, currentVectorStoreDatabasePath };\n}\n\nexport function setNumContextDocumentsToRetrieve(numContextDocumentsToRetrieve: number) {\n  config = { ...config, numContextDocumentsToRetrieve };\n}\n", "export function setNumContextDocumentsToRetrieve(numContextDocumentsToRetrieve: number) {\n  config = { ...config, numContextDocumentsToRetrieve };\n}\n\nexport function setNumMemoryDocumentsToRetrieve(numMemoryDocumentsToRetrieve: number) {\n  config = { ...config, numMemoryDocumentsToRetrieve };\n}\n\nexport function setUseWindowMemory(useWindowMemory: boolean) {\n  config = { ...config, useWindowMemory };\n}\n", "export function setUseWindowMemory(useWindowMemory: boolean) {\n  config = { ...config, useWindowMemory };\n}\n"]}
{"filename": "src/lib/vectorStoreUtils.ts", "chunked_list": ["import { HNSWLib } from 'langchain/vectorstores/hnswlib';\n\n/**\n * Retrieves relevant context for the given question by performing a similarity search on the provided vector store.\n * @param {HNSWLib} vectorStore - HNSWLib is a library for approximate nearest neighbor search, used to\n * search for similar vectors in a high-dimensional space.\n * @param {string} sanitizedQuestion - The sanitized version of the question that needs to be answered.\n * It is a string input.\n * @param {number} numDocuments - The `numDocuments` parameter is the number of documents that the\n * `getRelevantContext` function should retrieve from the `vectorStore` based on their similarity to\n * the `sanitizedQuestion`.\n * @returns The function `getRelevantContext` is returning a Promise that resolves to a string. The\n * string is the concatenation of the `pageContent` property of the top `numDocuments` documents\n * returned by a similarity search performed on a `vectorStore` using the `sanitizedQuestion` as the\n * query. The resulting string is trimmed and all newline characters are replaced with spaces.\n */", " * @param {number} numDocuments - The `numDocuments` parameter is the number of documents that the\n * `getRelevantContext` function should retrieve from the `vectorStore` based on their similarity to\n * the `sanitizedQuestion`.\n * @returns The function `getRelevantContext` is returning a Promise that resolves to a string. The\n * string is the concatenation of the `pageContent` property of the top `numDocuments` documents\n * returned by a similarity search performed on a `vectorStore` using the `sanitizedQuestion` as the\n * query. The resulting string is trimmed and all newline characters are replaced with spaces.\n */\nasync function getRelevantContext(\n  vectorStore: HNSWLib,\n  sanitizedQuestion: string,\n  numDocuments: number\n): Promise<string> {\n  const documents = await vectorStore.similaritySearch(sanitizedQuestion, numDocuments);\n  return documents\n    .map((doc) => doc.pageContent)\n    .join(', ')\n    .trim()\n    .replaceAll('\\n', ' ');\n}\n\n// eslint-disable-next-line import/prefer-default-export\nexport { getRelevantContext };\n", "async function getRelevantContext(\n  vectorStore: HNSWLib,\n  sanitizedQuestion: string,\n  numDocuments: number\n): Promise<string> {\n  const documents = await vectorStore.similaritySearch(sanitizedQuestion, numDocuments);\n  return documents\n    .map((doc) => doc.pageContent)\n    .join(', ')\n    .trim()\n    .replaceAll('\\n', ' ');\n}\n\n// eslint-disable-next-line import/prefer-default-export\nexport { getRelevantContext };\n"]}
{"filename": "src/lib/contextManager.ts", "chunked_list": ["import chalk from 'chalk';\nimport { stdout as output } from 'node:process';\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai';\nimport { HNSWLib } from 'langchain/vectorstores/hnswlib';\nimport { JSONLoader } from 'langchain/document_loaders/fs/json';\nimport { TextLoader } from 'langchain/document_loaders/fs/text';\nimport { PDFLoader } from 'langchain/document_loaders/fs/pdf';\nimport { DocxLoader } from 'langchain/document_loaders/fs/docx';\nimport { EPubLoader } from 'langchain/document_loaders/fs/epub';\nimport { CSVLoader } from 'langchain/document_loaders/fs/csv';", "import { EPubLoader } from 'langchain/document_loaders/fs/epub';\nimport { CSVLoader } from 'langchain/document_loaders/fs/csv';\nimport ora from 'ora';\nimport { MarkdownTextSplitter, RecursiveCharacterTextSplitter } from 'langchain/text_splitter';\nimport { Document } from 'langchain/document';\nimport path from 'path';\nimport { YoutubeTranscript } from 'youtube-transcript';\nimport getDirectoryListWithDetails from '../utils/getDirectoryListWithDetails.js';\nimport createDirectory from '../utils/createDirectory.js';\nimport { getConfig, getDefaultOraOptions, getProjectRoot, setCurrentVectorStoreDatabasePath } from '../config/index.js';", "import createDirectory from '../utils/createDirectory.js';\nimport { getConfig, getDefaultOraOptions, getProjectRoot, setCurrentVectorStoreDatabasePath } from '../config/index.js';\nimport getDirectoryFiles from '../utils/getDirectoryFiles.js';\nimport WebCrawler from './crawler.js';\n\nconst projectRootDir = getProjectRoot();\n\nconst defaultOraOptions = getDefaultOraOptions(output);\n\n/**\n * This function loads and splits a file based on its extension using different loaders and text\n * splitters.\n * @param {string} filePath - A string representing the path to the file that needs to be loaded and\n * split into documents.\n * @returns The function `loadAndSplitFile` returns a Promise that resolves to an array of `Document`", "\n/**\n * This function loads and splits a file based on its extension using different loaders and text\n * splitters.\n * @param {string} filePath - A string representing the path to the file that needs to be loaded and\n * split into documents.\n * @returns The function `loadAndSplitFile` returns a Promise that resolves to an array of `Document`\n * objects, where each `Document` represents a split portion of the input file. The type of the\n * `Document` object is `Document<Record<string, unknown>>`, which means it has a generic type\n * parameter that is an object with string keys and unknown values.\n */", "async function loadAndSplitFile(filePath: string): Promise<Document<Record<string, unknown>>[]> {\n  const fileExtension = path.extname(filePath);\n  let loader;\n  let documents: Document<Record<string, unknown>>[];\n  switch (fileExtension) {\n    case '.json':\n      loader = new JSONLoader(filePath);\n      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n      break;\n    case '.txt':\n      loader = new TextLoader(filePath);\n      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n      break;\n    case '.md':\n      loader = new TextLoader(filePath);\n      documents = await loader.loadAndSplit(new MarkdownTextSplitter());\n      break;\n    case '.pdf':\n      loader = new PDFLoader(filePath, { splitPages: false });\n      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n      break;\n    case '.docx':\n      loader = new DocxLoader(filePath);\n      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n      break;\n    case '.csv':\n      loader = new CSVLoader(filePath);\n      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n      break;\n    case '.epub':\n      loader = new EPubLoader(filePath, { splitChapters: false });\n      documents = await loader.loadAndSplit(new RecursiveCharacterTextSplitter());\n      break;\n    default:\n      throw new Error(`Unsupported file extension: ${fileExtension}`);\n  }\n  return documents;\n}\n\n/**", " * This function loads or creates a vector store using HNSWLib and OpenAIEmbeddings.\n * @returns The function `loadOrCreateVectorStore` returns a Promise that resolves to an instance of\n * the `HNSWLib` class, which is a vector store used for storing and searching high-dimensional\n * vectors.\n */\nasync function loadOrCreateVectorStore(): Promise<HNSWLib> {\n  let vectorStore: HNSWLib;\n  let spinner;\n  await createDirectory(getConfig().currentVectorStoreDatabasePath);\n  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n  try {\n    vectorStore = await HNSWLib.load(dbDirectory, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n  } catch {\n    spinner = ora({\n      ...defaultOraOptions,\n      text: chalk.blue(`Creating new Context Vector Store in the ${dbDirectory} directory`),\n    }).start();\n    const docsDirectory = path.join(projectRootDir, process.env.DOCS_DIR || 'docs');\n    const filesToAdd = await getDirectoryFiles(docsDirectory);\n    const documents = await Promise.all(filesToAdd.map((filePath) => loadAndSplitFile(filePath)));\n    const flattenedDocuments = documents.reduce((acc, val) => acc.concat(val), []);\n    vectorStore = await HNSWLib.fromDocuments(flattenedDocuments, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n    await vectorStore.save(dbDirectory);\n    spinner.succeed();\n  }\n  return vectorStore;\n}\n\nconst contextVectorStore = await loadOrCreateVectorStore();\n\nconst contextWrapper = {\n  contextInstance: contextVectorStore,\n};\n\n/**", "  try {\n    vectorStore = await HNSWLib.load(dbDirectory, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n  } catch {\n    spinner = ora({\n      ...defaultOraOptions,\n      text: chalk.blue(`Creating new Context Vector Store in the ${dbDirectory} directory`),\n    }).start();\n    const docsDirectory = path.join(projectRootDir, process.env.DOCS_DIR || 'docs');\n    const filesToAdd = await getDirectoryFiles(docsDirectory);\n    const documents = await Promise.all(filesToAdd.map((filePath) => loadAndSplitFile(filePath)));\n    const flattenedDocuments = documents.reduce((acc, val) => acc.concat(val), []);\n    vectorStore = await HNSWLib.fromDocuments(flattenedDocuments, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n    await vectorStore.save(dbDirectory);\n    spinner.succeed();\n  }\n  return vectorStore;\n}\n\nconst contextVectorStore = await loadOrCreateVectorStore();\n\nconst contextWrapper = {\n  contextInstance: contextVectorStore,\n};\n\n/**", " * This function loads or creates a new empty Context Vector Store using HNSWLib and OpenAIEmbeddings.\n * @returns a Promise that resolves to an instance of the HNSWLib class, which represents a\n * hierarchical navigable small world graph used for nearest neighbor search. The instance is either\n * loaded from an existing directory or created as a new empty Context Vector Store with specified\n * parameters.\n */\nasync function loadOrCreateEmptyVectorStore(subDirectory: string): Promise<HNSWLib> {\n  let vectorStore: HNSWLib;\n  let spinner;\n  const newContextVectorStorePath = path.join(projectRootDir, process.env.VECTOR_STORE_BASE_DIR || 'db', subDirectory);\n  await createDirectory(newContextVectorStorePath);\n  setCurrentVectorStoreDatabasePath(newContextVectorStorePath);\n  const dbDirectory = getConfig().currentVectorStoreDatabasePath;", "  try {\n    vectorStore = await HNSWLib.load(dbDirectory, new OpenAIEmbeddings({ maxConcurrency: 5 }));\n    output.write(chalk.blue(`Using Context Vector Store in the ${dbDirectory} directory\\n`));\n  } catch {\n    spinner = ora({\n      ...defaultOraOptions,\n      text: chalk.blue(`Creating new empty Context Vector Store in the ${dbDirectory} directory`),\n    }).start();\n    vectorStore = new HNSWLib(new OpenAIEmbeddings({ maxConcurrency: 5 }), {\n      space: 'cosine',\n      numDimensions: 1536,\n    });\n    spinner.succeed();\n    output.write(\n      chalk.red.bold(\n        `\\nThe Context Vector Store is currently empty and unsaved, add context to is using \\`/add-docs\\`, \\`/add-url\\` or \\`/add-youtube\\``\n      )\n    );\n  }\n  contextWrapper.contextInstance = vectorStore;\n  return vectorStore;\n}\n", "async function getContextVectorStore() {\n  return contextWrapper.contextInstance;\n}\n\n/**\n * This function adds documents to a context vector store and saves them.\n * @param {string[]} filePaths - The `filePaths` parameter is an array of strings representing the file\n * paths of the documents that need to be added to the Context Vector Store.\n * @returns nothing (`undefined`).\n */\nasync function addDocument(filePaths: string[]) {\n  let spinner;\n  const dbDirectory = getConfig().currentVectorStoreDatabasePath;", "async function addDocument(filePaths: string[]) {\n  let spinner;\n  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n  try {\n    spinner = ora({ ...defaultOraOptions, text: `Adding files to the Context Vector Store` }).start();\n    const docsDirectory = path.join(projectRootDir, process.env.DOCS_DIR || 'docs');\n    const documents = await Promise.all(\n      filePaths.map((filePath) => loadAndSplitFile(path.join(docsDirectory, filePath)))\n    );\n    const flattenedDocuments = documents.reduce((acc, val) => acc.concat(val), []);\n    const vectorStore = await getContextVectorStore();\n    await vectorStore.addDocuments(flattenedDocuments);\n    await vectorStore.save(dbDirectory);\n    spinner.succeed();\n    return;", "  } catch (error) {\n    if (spinner) {\n      spinner.fail(chalk.red(error));\n    } else {\n      output.write(chalk.red(error));\n    }\n  }\n}\n\n/**\n * The function adds a YouTube video transcript to a Context Vector Store.\n * @param {string} URLOrVideoID - The URLOrVideoID parameter is a string that represents either the URL\n * or the video ID of a YouTube video.", " * The function adds a YouTube video transcript to a Context Vector Store.\n * @param {string} URLOrVideoID - The URLOrVideoID parameter is a string that represents either the URL\n * or the video ID of a YouTube video.\n * @returns Nothing is being returned explicitly in the code, but the function is expected to return\n * undefined after completing its execution.\n */\nasync function addYouTube(URLOrVideoID: string) {\n  let spinner;\n  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n  try {\n    spinner = ora({\n      ...defaultOraOptions,\n      text: `Adding Video transcript from ${URLOrVideoID} to the Context Vector Store`,\n    }).start();\n    const transcript = await YoutubeTranscript.fetchTranscript(URLOrVideoID);\n    const text = transcript.map((part) => part.text).join(' ');\n    const splitter = new RecursiveCharacterTextSplitter();\n    const videoDocs = await splitter.splitDocuments([\n      new Document({\n        pageContent: text,\n      }),\n    ]);\n    const vectorStore = await getContextVectorStore();\n    await vectorStore.addDocuments(videoDocs);\n    await vectorStore.save(dbDirectory);\n    spinner.succeed();\n    return;", "  try {\n    spinner = ora({\n      ...defaultOraOptions,\n      text: `Adding Video transcript from ${URLOrVideoID} to the Context Vector Store`,\n    }).start();\n    const transcript = await YoutubeTranscript.fetchTranscript(URLOrVideoID);\n    const text = transcript.map((part) => part.text).join(' ');\n    const splitter = new RecursiveCharacterTextSplitter();\n    const videoDocs = await splitter.splitDocuments([\n      new Document({\n        pageContent: text,\n      }),\n    ]);\n    const vectorStore = await getContextVectorStore();\n    await vectorStore.addDocuments(videoDocs);\n    await vectorStore.save(dbDirectory);\n    spinner.succeed();\n    return;", "  } catch (error) {\n    if (spinner) {\n      spinner.fail(chalk.red(error));\n    } else {\n      output.write(chalk.red(error));\n    }\n  }\n}\n\n/**\n * The function crawls a given URL, extracts text from the pages, splits the text into documents,\n * generates embeddings for the documents, and saves them to a vector store.\n * @param {string} URL - The URL of the website to crawl and extract text from.\n * @param {string} selector - The selector parameter is a string that represents a CSS selector used to\n * identify the HTML elements to be crawled on the web page. The WebCrawler will only crawl the\n * elements that match the selector.\n * @param {number} maxPages - The maximum number of pages to crawl for the given URL.\n * @param {number} numberOfCharactersRequired - `numberOfCharactersRequired` is a number that specifies\n * the minimum number of characters required for a document to be considered valid and used for\n * generating embeddings. Any document with less than this number of characters will be discarded.\n * @returns Nothing is being returned explicitly in the function, but it is implied that the function\n * will return undefined if there are no errors.\n */", " * The function crawls a given URL, extracts text from the pages, splits the text into documents,\n * generates embeddings for the documents, and saves them to a vector store.\n * @param {string} URL - The URL of the website to crawl and extract text from.\n * @param {string} selector - The selector parameter is a string that represents a CSS selector used to\n * identify the HTML elements to be crawled on the web page. The WebCrawler will only crawl the\n * elements that match the selector.\n * @param {number} maxPages - The maximum number of pages to crawl for the given URL.\n * @param {number} numberOfCharactersRequired - `numberOfCharactersRequired` is a number that specifies\n * the minimum number of characters required for a document to be considered valid and used for\n * generating embeddings. Any document with less than this number of characters will be discarded.\n * @returns Nothing is being returned explicitly in the function, but it is implied that the function\n * will return undefined if there are no errors.\n */", "async function addURL(URL: string, selector: string, maxPages: number, numberOfCharactersRequired: number) {\n  const dbDirectory = getConfig().currentVectorStoreDatabasePath;\n  const addUrlSpinner = ora({ ...defaultOraOptions, text: `Crawling ${URL}` });\n  let documents;\n  try {\n    addUrlSpinner.start();\n    const progressCallback = (linksFound: number, linksCrawled: number, currentUrl: string) => {\n      addUrlSpinner.text = `Links found: ${linksFound} - Links crawled: ${linksCrawled} - Crawling ${currentUrl}`;\n    };\n\n    const crawler = new WebCrawler([URL], progressCallback, selector, maxPages, numberOfCharactersRequired);\n    const pages = (await crawler.start()) as Page[];\n\n    documents = await Promise.all(\n      pages.map((row) => {\n        const splitter = new RecursiveCharacterTextSplitter();\n\n        const webDocs = splitter.splitDocuments([\n          new Document({\n            pageContent: row.text,\n          }),\n        ]);\n        return webDocs;\n      })\n    );\n    addUrlSpinner.succeed();", "  } catch (error) {\n    addUrlSpinner.fail(chalk.red(error));\n  }\n  if (documents) {\n    const generateEmbeddingsSpinner = ora({ ...defaultOraOptions, text: `Generating Embeddings` });\n    try {\n      const flattenedDocuments = documents.flat();\n      generateEmbeddingsSpinner.text = `Generating Embeddings for ${flattenedDocuments.length} documents`;\n      generateEmbeddingsSpinner.start();\n      const vectorStore = await getContextVectorStore();\n      await vectorStore.addDocuments(flattenedDocuments);\n      await vectorStore.save(dbDirectory);\n      generateEmbeddingsSpinner.succeed();\n      return;", "    } catch (error) {\n      generateEmbeddingsSpinner.fail(chalk.red(error));\n    }\n  }\n}\n\nasync function listContextStores() {\n  const projectRoot = getProjectRoot(); // Please replace this with your actual function to get the project root\n  const vectorStoreDir = process.env.VECTOR_STORE_BASE_DIR || 'db';\n  const targetDir = path.join(projectRoot, vectorStoreDir);\n  const contextVectorStoresList = await getDirectoryListWithDetails(targetDir);\n  output.write(chalk.blue(`Context Vector Stores in ${targetDir}:\\n\\n`));\n  Object.entries(contextVectorStoresList).forEach(([dir, files]) => {\n    output.write(chalk.yellow(`Directory: ${dir}`));", "    if (dir === getConfig().currentVectorStoreDatabasePath) {\n      output.write(chalk.green(` (Currently selected)`));\n    }\n    output.write('\\n');\n    files.forEach((file) => {\n      output.write(chalk.yellow(`  File: ${file.name}, Size: ${file.size} KB\\n`));\n    });\n  });\n}\n\nexport { getContextVectorStore, addDocument, addURL, addYouTube, listContextStores, loadOrCreateEmptyVectorStore };\n"]}
{"filename": "src/lib/crawler.ts", "chunked_list": ["import * as cheerio from 'cheerio';\nimport Crawler, { CrawlerRequestResponse } from 'crawler';\nimport { stderr } from 'node:process';\nimport resolveURL from '../utils/resolveURL.js';\n\n// import TurndownService from 'turndown';\n\n// const turndownService = new TurndownService();\n\ntype ProgressCallback = (linksFound: number, linksCrawled: number, currentUrl: string) => void;\n", "\ntype ProgressCallback = (linksFound: number, linksCrawled: number, currentUrl: string) => void;\n\ninterface Page {\n  url: string;\n  text: string;\n  title: string;\n}\n\n/* The WebCrawler class is a TypeScript implementation of a web crawler that can extract text from web\npages and follow links to crawl more pages. */", "/* The WebCrawler class is a TypeScript implementation of a web crawler that can extract text from web\npages and follow links to crawl more pages. */\nclass WebCrawler {\n  pages: Page[];\n\n  limit: number;\n\n  urls: string[];\n\n  count: number;\n\n  textLengthMinimum: number;\n\n  selector: string;\n\n  progressCallback: ProgressCallback;\n\n  crawler: Crawler;\n\n  constructor(\n    urls: string[],\n    progressCallback: ProgressCallback,\n    selector = 'body',\n    limit = 20,\n    textLengthMinimum = 200\n  ) {\n    this.urls = urls;\n    this.selector = selector;\n    this.limit = limit;\n    this.textLengthMinimum = textLengthMinimum;\n    this.progressCallback = progressCallback;\n    this.count = 0;\n    this.pages = [];\n    this.crawler = new Crawler({\n      maxConnections: 10,\n      callback: this.handleRequest,\n      userAgent: 'node-crawler',\n    });\n  }\n\n  /* `handleRequest` is a method that handles the response of a web page request made by the `crawler`\nobject. It takes in three parameters: `error`, `res`, and `done`. */\n  handleRequest = (error: Error | null, res: CrawlerRequestResponse, done: () => void) => {", "    if (error) {\n      stderr.write(error.message);\n      done();\n      return;\n    }\n\n    const $ = cheerio.load(res.body);\n    // Remove obviously superfluous elements\n    $('script').remove();\n    $('header').remove();\n    $('nav').remove();\n    $('style').remove();\n    $('img').remove();\n    $('svg').remove();\n    const title = $('title').text() || '';\n    const text = $(this.selector).text();\n    // const text = turndownService.turndown(html || '');\n\n    const page: Page = {\n      url: res.request.uri.href,\n      text,\n      title,\n    };", "    if (text.length > this.textLengthMinimum) {\n      this.pages.push(page);\n      this.progressCallback(this.count + 1, this.pages.length, res.request.uri.href);\n    }\n\n    $('a').each((_i: number, elem: cheerio.Element) => {\n      if (this.count >= this.limit) {\n        return false; // Stop iterating once the limit is reached\n      }\n\n      const href = $(elem).attr('href')?.split('#')[0];\n      const uri = res.request.uri.href;\n      const url = href && resolveURL(uri, href);\n      // crawl more", "      if (url && this.urls.some((u) => url.includes(u))) {\n        this.crawler.queue(url);\n        this.count += 1;\n      }\n      return true; // Continue iterating when the limit is not reached\n    });\n\n    done();\n  };\n\n  start = async () => {\n    this.pages = [];\n    return new Promise((resolve) => {\n      this.crawler.on('drain', () => {\n        resolve(this.pages);\n      });\n      this.urls.forEach((url) => {\n        this.crawler.queue(url);\n      });\n    });\n  };\n}\n\nexport default WebCrawler;\n"]}
{"filename": "src/lib/memoryManager.ts", "chunked_list": ["import chalk from 'chalk';\nimport { HNSWLib } from 'langchain/vectorstores/hnswlib';\nimport fs from 'fs/promises';\nimport path from 'path';\nimport { stdout as output } from 'node:process';\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai';\nimport { Document } from 'langchain/document';\nimport { BufferWindowMemory } from 'langchain/memory';\nimport { getProjectRoot } from '../config/index.js';\n", "import { getProjectRoot } from '../config/index.js';\n\nconst projectRootDir = getProjectRoot();\n\nconst memoryDirectory = path.join(projectRootDir, process.env.MEMORY_VECTOR_STORE_DIR || 'memory');\n\nlet memoryVectorStore: HNSWLib;\ntry {\n  memoryVectorStore = await HNSWLib.load(memoryDirectory, new OpenAIEmbeddings());\n} catch {\n  output.write(`${chalk.blue(`Creating a new memory vector store index in the ${memoryDirectory} directory`)}\\n`);\n  memoryVectorStore = new HNSWLib(new OpenAIEmbeddings(), {\n    space: 'cosine',\n    numDimensions: 1536,\n  });\n}\n\nconst bufferWindowMemory = new BufferWindowMemory({\n  returnMessages: false,\n  memoryKey: 'immediate_history',\n  inputKey: 'input',\n  k: 2,\n});\n\nconst memoryWrapper = {\n  vectorStoreInstance: memoryVectorStore,\n};\n", "async function getMemoryVectorStore() {\n  return memoryWrapper.vectorStoreInstance;\n}\n\nfunction getBufferWindowMemory() {\n  return bufferWindowMemory;\n}\n\nasync function saveMemoryVectorStore() {\n  await memoryWrapper.vectorStoreInstance.save(memoryDirectory);\n}\n", "async function saveMemoryVectorStore() {\n  await memoryWrapper.vectorStoreInstance.save(memoryDirectory);\n}\n\nasync function addDocumentsToMemoryVectorStore(\n  documents: Array<{ content: string; metadataType: string }>\n): Promise<void> {\n  const formattedDocuments = documents.map(\n    (doc) => new Document({ pageContent: doc.content, metadata: { type: doc.metadataType } })\n  );\n  await memoryWrapper.vectorStoreInstance.addDocuments(formattedDocuments);\n  await saveMemoryVectorStore();\n}\n", "function resetBufferWindowMemory() {\n  bufferWindowMemory.clear();\n}\n\nasync function deleteMemoryDirectory() {\n  try {\n    const files = await fs.readdir(memoryDirectory);\n    const deletePromises = files.map((file) => fs.unlink(path.join(memoryDirectory, file)));\n    await Promise.all(deletePromises);\n    return `All files in the memory directory have been deleted.`;\n  } catch (error) {", "  } catch (error) {\n    if (error instanceof Error) {\n      return chalk.red(`All files in the memory directory have been deleted: ${error.message}`);\n    }\n    return chalk.red(`All files in the memory directory have been deleted: ${error}`);\n  }\n}\n\nasync function resetMemoryVectorStore(onReset: (newMemoryVectorStore: HNSWLib) => void) {\n  const newMemoryVectorStore = new HNSWLib(new OpenAIEmbeddings(), {\n    space: 'cosine',\n    numDimensions: 1536,\n  });\n  await deleteMemoryDirectory();\n  onReset(newMemoryVectorStore);\n}\n", "async function resetMemoryVectorStore(onReset: (newMemoryVectorStore: HNSWLib) => void) {\n  const newMemoryVectorStore = new HNSWLib(new OpenAIEmbeddings(), {\n    space: 'cosine',\n    numDimensions: 1536,\n  });\n  await deleteMemoryDirectory();\n  onReset(newMemoryVectorStore);\n}\n\nfunction setMemoryVectorStore(newMemoryVectorStore: HNSWLib) {\n  memoryWrapper.vectorStoreInstance = newMemoryVectorStore;\n}\n\nexport {\n  getMemoryVectorStore,\n  setMemoryVectorStore,\n  addDocumentsToMemoryVectorStore,\n  resetMemoryVectorStore,\n  getBufferWindowMemory,\n  resetBufferWindowMemory,\n};\n", "function setMemoryVectorStore(newMemoryVectorStore: HNSWLib) {\n  memoryWrapper.vectorStoreInstance = newMemoryVectorStore;\n}\n\nexport {\n  getMemoryVectorStore,\n  setMemoryVectorStore,\n  addDocumentsToMemoryVectorStore,\n  resetMemoryVectorStore,\n  getBufferWindowMemory,\n  resetBufferWindowMemory,\n};\n"]}
