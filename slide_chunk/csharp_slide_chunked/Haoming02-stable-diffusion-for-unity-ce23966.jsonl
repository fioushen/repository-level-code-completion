{"filename": "Assets/Scripts/Manual1111.cs", "chunked_list": ["using UnityEngine;\nusing UnityEngine.UI;\n\npublic class Manual1111 : MonoBehaviour\n{\n    [SerializeField]\n    private InputField promptField;\n\n    [SerializeField]\n    private Text stepsLabel;\n    [SerializeField]", "    private Text stepsLabel;\n    [SerializeField]\n    private Text cfgLabel;\n    [SerializeField]\n    private Text schedulerLabel;\n\n    private int steps = 20;\n    private float cfg = 7;\n    private bool useLMS = false;\n\n    private const int resolution = 512;\n\n    [SerializeField]", "    private bool useLMS = false;\n\n    private const int resolution = 512;\n\n    [SerializeField]\n    private RawImage result;\n    private Texture2D output;\n\n    void Awake()\n    {\n        Application.targetFrameRate = 60;\n\n        StableDiffusion.Main.Init(\n            Application.streamingAssetsPath + \"/unet/\" + \"model\" + \".onnx\",\n            Application.streamingAssetsPath + \"/text_encoder/\" + \"model\" + \".onnx\",\n            Application.streamingAssetsPath + \"/tokenizer/\" + \"cliptokenizer\" + \".onnx\",\n            Application.streamingAssetsPath + \"/tokenizer/\" + \"ortextensions\" + \".dll\",\n            Application.streamingAssetsPath + \"/vae_decoder/\" + \"model\" + \".onnx\"\n        );\n\n        output = new Texture2D(resolution, resolution, TextureFormat.RGBA32, false);\n    }\n", "    public void SetSteps(float s)\n    {\n        steps = (int)s;\n        stepsLabel.text = $\"{steps}\";\n    }\n\n    public void SetGuidance(float g)\n    {\n        cfg = g;\n        cfgLabel.text = $\"{cfg}\";\n    }\n", "    public void ToggleSampler()\n    {\n        useLMS = !useLMS;\n        schedulerLabel.text = useLMS ? \"LMS\" : \"Euler A\";\n    }\n\n    public void Run()\n    {\n        StableDiffusion.Main.Run(promptField.text, steps, cfg, Random.Range(0, int.MaxValue), ref output, useLMS);\n        result.texture = output;\n    }\n\n    void OnDisable()\n    {\n        StableDiffusion.Main.Free();\n    }\n}"]}
{"filename": "Assets/Scripts/DemoScene.cs", "chunked_list": ["using UnityEngine;\nusing System.Collections;\n\npublic class DemoScene : MonoBehaviour\n{\n    private const int steps = 6;\n    private const float cfg = 4;\n    private const bool useLMS = false;\n\n    private const int resolution = 512;\n", "    private const int resolution = 512;\n\n    private Texture2D paintingTexture;\n    private Texture2D skyboxTexture;\n\n    [SerializeField]\n    private Canvas loading;\n    [SerializeField]\n    private Canvas generating;\n\n    [SerializeField]", "    private Canvas generating;\n\n    [SerializeField]\n    private Renderer skybox;\n    [SerializeField]\n    private Renderer painting;\n\n    private float xRotation = 0.0f;\n\n    void Awake()\n    {\n        Application.targetFrameRate = 60;\n        Cursor.lockState = CursorLockMode.Locked;\n        Cursor.visible = false;\n    }\n\n    void Start()\n    {\n        loading.enabled = true;\n        generating.enabled = false;\n\n        StableDiffusion.Main.onReady += OnReady;\n\n        StableDiffusion.Main.Init(\n            Application.streamingAssetsPath + \"/unet/\" + \"model\" + \".onnx\",\n            Application.streamingAssetsPath + \"/text_encoder/\" + \"model\" + \".onnx\",\n            Application.streamingAssetsPath + \"/tokenizer/\" + \"cliptokenizer\" + \".onnx\",\n            Application.streamingAssetsPath + \"/tokenizer/\" + \"ortextensions\" + \".dll\",\n            Application.streamingAssetsPath + \"/vae_decoder/\" + \"model\" + \".onnx\"\n        );\n\n        paintingTexture = new Texture2D(resolution, resolution, TextureFormat.RGBA32, false);\n        skyboxTexture = new Texture2D(resolution, resolution, TextureFormat.RGBA32, false);\n    }\n", "    private void OnReady()\n    {\n        loading.enabled = false;\n        StartCoroutine(MainLoop());\n    }\n\n    private IEnumerator MainLoop()\n    {\n        while (true)\n        {\n            float x = Input.GetAxis(\"Mouse X\");\n            float y = Input.GetAxis(\"Mouse Y\");\n\n            xRotation = Mathf.Clamp(xRotation - y, -60.0f, 60.0f);\n\n            Vector3 camRotation = transform.rotation.eulerAngles;\n            camRotation.x = xRotation;\n            camRotation.y += x;\n\n            transform.rotation = Quaternion.Euler(camRotation);\n", "        while (true)\n        {\n            float x = Input.GetAxis(\"Mouse X\");\n            float y = Input.GetAxis(\"Mouse Y\");\n\n            xRotation = Mathf.Clamp(xRotation - y, -60.0f, 60.0f);\n\n            Vector3 camRotation = transform.rotation.eulerAngles;\n            camRotation.x = xRotation;\n            camRotation.y += x;\n\n            transform.rotation = Quaternion.Euler(camRotation);\n", "            if (Input.GetKeyDown(KeyCode.Alpha1))\n            {\n                generating.enabled = true;\n\n                yield return null;\n\n                GenSkybox();\n\n                yield return null;\n\n                generating.enabled = false;\n            }\n", "            if (Input.GetKeyDown(KeyCode.Alpha2))\n            {\n                generating.enabled = true;\n\n                yield return null;\n\n                GenPainting();\n\n                yield return null;\n\n                generating.enabled = false;\n            }\n\n            yield return null;\n        }\n    }\n", "    private const string promptPainting = \"high quality, best quality, masterpiece, a painting of a flower, by davinci\";\n    private const string promptSkybox = \"high quality, best quality, a dslr photo of blue sky with cloud and sun, hdr\";\n\n    private void GenPainting()\n    {\n        StableDiffusion.Main.Run(promptPainting, steps, cfg, Random.Range(0, int.MaxValue), ref paintingTexture, useLMS);\n        painting.material.mainTexture = paintingTexture;\n    }\n\n    private void GenSkybox()\n    {\n        StableDiffusion.Main.Run(promptSkybox, steps, cfg, Random.Range(0, int.MaxValue), ref skyboxTexture, useLMS);\n        skybox.material.mainTexture = skyboxTexture;\n    }\n\n    void OnDisable()\n    {\n        StableDiffusion.Main.Free();\n    }\n}", "    private void GenSkybox()\n    {\n        StableDiffusion.Main.Run(promptSkybox, steps, cfg, Random.Range(0, int.MaxValue), ref skyboxTexture, useLMS);\n        skybox.material.mainTexture = skyboxTexture;\n    }\n\n    void OnDisable()\n    {\n        StableDiffusion.Main.Free();\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/LMSDiscreteScheduler.cs", "chunked_list": ["\ufeffusing MathNet.Numerics;\nusing Microsoft.ML.OnnxRuntime.Tensors;\nusing NumSharp;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\n\nnamespace StableDiffusion\n{\n    public class LMSDiscreteScheduler : SchedulerBase\n    {", "{\n    public class LMSDiscreteScheduler : SchedulerBase\n    {\n        private string _predictionType;\n\n        public override Tensor<float> Sigmas { get; set; }\n        public override List<int> Timesteps { get; set; }\n        public List<Tensor<float>> Derivatives;\n        public override float InitNoiseSigma { get; set; }\n\n        public LMSDiscreteScheduler(int num_train_timesteps = 1000, float beta_start = 0.00085f, float beta_end = 0.012f, string beta_schedule = \"scaled_linear\", string prediction_type = \"epsilon\", List<float> trained_betas = null)\n        {\n            _predictionType = prediction_type;\n            Derivatives = new List<Tensor<float>>();\n            Timesteps = new List<int>();\n\n            var alphas = new List<float>();\n            var betas = new List<float>();\n", "        public override float InitNoiseSigma { get; set; }\n\n        public LMSDiscreteScheduler(int num_train_timesteps = 1000, float beta_start = 0.00085f, float beta_end = 0.012f, string beta_schedule = \"scaled_linear\", string prediction_type = \"epsilon\", List<float> trained_betas = null)\n        {\n            _predictionType = prediction_type;\n            Derivatives = new List<Tensor<float>>();\n            Timesteps = new List<int>();\n\n            var alphas = new List<float>();\n            var betas = new List<float>();\n", "            if (trained_betas != null)\n            {\n                betas = trained_betas;\n            }\n            else if (beta_schedule == \"linear\")\n            {\n                betas = Enumerable.Range(0, num_train_timesteps).Select(i => beta_start + (beta_end - beta_start) * i / (num_train_timesteps - 1)).ToList();\n            }\n            else if (beta_schedule == \"scaled_linear\")\n            {\n                var start = (float)Math.Sqrt(beta_start);\n                var end = (float)Math.Sqrt(beta_end);\n                betas = np.linspace(start, end, num_train_timesteps).ToArray<float>().Select(x => x * x).ToList();\n            }\n            else\n            {\n                throw new Exception(\"beta_schedule must be one of 'linear' or 'scaled_linear'\");\n            }\n\n            alphas = betas.Select(beta => 1 - beta).ToList();\n\n            this._alphasCumulativeProducts = alphas.Select((alpha, i) => alphas.Take(i + 1).Aggregate((a, b) => a * b)).ToList();\n            // Create sigmas as a list and reverse it\n            var sigmas = _alphasCumulativeProducts.Select(alpha_prod => Math.Sqrt((1 - alpha_prod) / alpha_prod)).Reverse().ToList();\n\n            // standard deviation of the initial noise distrubution\n            this.InitNoiseSigma = (float)sigmas.Max();\n        }\n\n        //python line 135 of scheduling_lms_discrete.py", "            else if (beta_schedule == \"scaled_linear\")\n            {\n                var start = (float)Math.Sqrt(beta_start);\n                var end = (float)Math.Sqrt(beta_end);\n                betas = np.linspace(start, end, num_train_timesteps).ToArray<float>().Select(x => x * x).ToList();\n            }\n            else\n            {\n                throw new Exception(\"beta_schedule must be one of 'linear' or 'scaled_linear'\");\n            }\n\n            alphas = betas.Select(beta => 1 - beta).ToList();\n\n            this._alphasCumulativeProducts = alphas.Select((alpha, i) => alphas.Take(i + 1).Aggregate((a, b) => a * b)).ToList();\n            // Create sigmas as a list and reverse it\n            var sigmas = _alphasCumulativeProducts.Select(alpha_prod => Math.Sqrt((1 - alpha_prod) / alpha_prod)).Reverse().ToList();\n\n            // standard deviation of the initial noise distrubution\n            this.InitNoiseSigma = (float)sigmas.Max();\n        }\n\n        //python line 135 of scheduling_lms_discrete.py", "        public double GetLmsCoefficient(int order, int t, int currentOrder)\n        {\n            // Compute a linear multistep coefficient.\n\n            double LmsDerivative(double tau)\n            {\n                double prod = 1.0;\n                for (int k = 0; k < order; k++)\n                {\n                    if (currentOrder == k)\n                    {\n                        continue;\n                    }\n                    prod *= (tau - this.Sigmas[t - k]) / (this.Sigmas[t - currentOrder] - this.Sigmas[t - k]);\n                }\n                return prod;\n            }\n\n            double integratedCoeff = Integrate.OnClosedInterval(LmsDerivative, this.Sigmas[t], this.Sigmas[t + 1], 1e-4);\n\n            return integratedCoeff;\n        }\n\n        // Line 157 of scheduling_lms_discrete.py from HuggingFace diffusers", "                    if (currentOrder == k)\n                    {\n                        continue;\n                    }\n                    prod *= (tau - this.Sigmas[t - k]) / (this.Sigmas[t - currentOrder] - this.Sigmas[t - k]);\n                }\n                return prod;\n            }\n\n            double integratedCoeff = Integrate.OnClosedInterval(LmsDerivative, this.Sigmas[t], this.Sigmas[t + 1], 1e-4);\n\n            return integratedCoeff;\n        }\n\n        // Line 157 of scheduling_lms_discrete.py from HuggingFace diffusers", "        public override int[] SetTimesteps(int num_inference_steps)\n        {\n            double start = 0;\n            double stop = _numTrainTimesteps - 1;\n            double[] timesteps = np.linspace(start, stop, num_inference_steps).ToArray<double>();\n\n            this.Timesteps = timesteps.Select(x => (int)x).Reverse().ToList();\n\n            var sigmas = _alphasCumulativeProducts.Select(alpha_prod => Math.Sqrt((1 - alpha_prod) / alpha_prod)).Reverse().ToList();\n            var range = np.arange((double)0, (double)(sigmas.Count)).ToArray<double>();\n            sigmas = Interpolate(timesteps, range, sigmas).ToList();\n            this.Sigmas = new DenseTensor<float>(sigmas.Count());", "            for (int i = 0; i < sigmas.Count(); i++)\n            {\n                this.Sigmas[i] = (float)sigmas[i];\n            }\n\n            return this.Timesteps.ToArray();\n        }\n\n        public override DenseTensor<float> Step(\n               Tensor<float> modelOutput,\n               int timestep,\n               Tensor<float> sample,\n               int order = 4\n            )\n        {\n            int stepIndex = this.Timesteps.IndexOf(timestep);\n            var sigma = this.Sigmas[stepIndex];\n\n            // 1. compute predicted original sample (x_0) from sigma-scaled predicted noise\n            Tensor<float> predOriginalSample;\n\n            // Create array of type float length modelOutput.length\n            float[] predOriginalSampleArray = new float[modelOutput.Length];\n            var modelOutPutArray = modelOutput.ToArray();\n            var sampleArray = sample.ToArray();\n", "        public override DenseTensor<float> Step(\n               Tensor<float> modelOutput,\n               int timestep,\n               Tensor<float> sample,\n               int order = 4\n            )\n        {\n            int stepIndex = this.Timesteps.IndexOf(timestep);\n            var sigma = this.Sigmas[stepIndex];\n\n            // 1. compute predicted original sample (x_0) from sigma-scaled predicted noise\n            Tensor<float> predOriginalSample;\n\n            // Create array of type float length modelOutput.length\n            float[] predOriginalSampleArray = new float[modelOutput.Length];\n            var modelOutPutArray = modelOutput.ToArray();\n            var sampleArray = sample.ToArray();\n", "            if (this._predictionType == \"epsilon\")\n            {\n                for (int i = 0; i < modelOutPutArray.Length; i++)\n                {\n                    predOriginalSampleArray[i] = sampleArray[i] - sigma * modelOutPutArray[i];\n                }\n                predOriginalSample = TensorHelper.CreateTensor(predOriginalSampleArray, modelOutput.Dimensions.ToArray());\n            }\n            else if (this._predictionType == \"v_prediction\")\n            {\n                //predOriginalSample = modelOutput * ((-sigma / Math.Sqrt((Math.Pow(sigma,2) + 1))) + (sample / (Math.Pow(sigma,2) + 1)));\n                throw new Exception($\"prediction_type given as {this._predictionType} not implemented yet.\");\n            }\n            else\n            {\n                throw new Exception($\"prediction_type given as {this._predictionType} must be one of `epsilon`, or `v_prediction`\");\n            }\n\n            // 2. Convert to an ODE derivative\n            var derivativeItems = new DenseTensor<float>(sample.Dimensions.ToArray());\n\n            var derivativeItemsArray = new float[derivativeItems.Length];\n", "            else if (this._predictionType == \"v_prediction\")\n            {\n                //predOriginalSample = modelOutput * ((-sigma / Math.Sqrt((Math.Pow(sigma,2) + 1))) + (sample / (Math.Pow(sigma,2) + 1)));\n                throw new Exception($\"prediction_type given as {this._predictionType} not implemented yet.\");\n            }\n            else\n            {\n                throw new Exception($\"prediction_type given as {this._predictionType} must be one of `epsilon`, or `v_prediction`\");\n            }\n\n            // 2. Convert to an ODE derivative\n            var derivativeItems = new DenseTensor<float>(sample.Dimensions.ToArray());\n\n            var derivativeItemsArray = new float[derivativeItems.Length];\n", "            for (int i = 0; i < modelOutPutArray.Length; i++)\n            {\n                //predOriginalSample = (sample - predOriginalSample) / sigma;\n                derivativeItemsArray[i] = (sampleArray[i] - predOriginalSampleArray[i]) / sigma;\n            }\n            derivativeItems = TensorHelper.CreateTensor(derivativeItemsArray, derivativeItems.Dimensions.ToArray());\n\n            this.Derivatives?.Add(derivativeItems);\n\n            if (this.Derivatives?.Count() > order)\n            {\n                // remove first element\n                this.Derivatives?.RemoveAt(0);\n            }\n\n            // 3. compute linear multistep coefficients\n            order = Math.Min(stepIndex + 1, order);\n            var lmsCoeffs = Enumerable.Range(0, order).Select(currOrder => GetLmsCoefficient(order, stepIndex, currOrder)).ToArray();\n\n            // 4. compute previous sample based on the derivative path\n            // Reverse list of tensors this.derivatives\n            var revDerivatives = Enumerable.Reverse(this.Derivatives).ToList();\n\n            // Create list of tuples from the lmsCoeffs and reversed derivatives\n            var lmsCoeffsAndDerivatives = lmsCoeffs.Zip(revDerivatives, (lmsCoeff, derivative) => (lmsCoeff, derivative));\n\n            // Create tensor for product of lmscoeffs and derivatives\n            var lmsDerProduct = new Tensor<float>[this.Derivatives.Count()];\n", "            if (this.Derivatives?.Count() > order)\n            {\n                // remove first element\n                this.Derivatives?.RemoveAt(0);\n            }\n\n            // 3. compute linear multistep coefficients\n            order = Math.Min(stepIndex + 1, order);\n            var lmsCoeffs = Enumerable.Range(0, order).Select(currOrder => GetLmsCoefficient(order, stepIndex, currOrder)).ToArray();\n\n            // 4. compute previous sample based on the derivative path\n            // Reverse list of tensors this.derivatives\n            var revDerivatives = Enumerable.Reverse(this.Derivatives).ToList();\n\n            // Create list of tuples from the lmsCoeffs and reversed derivatives\n            var lmsCoeffsAndDerivatives = lmsCoeffs.Zip(revDerivatives, (lmsCoeff, derivative) => (lmsCoeff, derivative));\n\n            // Create tensor for product of lmscoeffs and derivatives\n            var lmsDerProduct = new Tensor<float>[this.Derivatives.Count()];\n", "            for (int m = 0; m < lmsCoeffsAndDerivatives.Count(); m++)\n            {\n                var item = lmsCoeffsAndDerivatives.ElementAt(m);\n                // Multiply to coeff by each derivatives to create the new tensors\n                lmsDerProduct[m] = TensorHelper.MultipleTensorByFloat(item.derivative.ToArray(), (float)item.lmsCoeff, item.derivative.Dimensions.ToArray());\n            }\n            // Sum the tensors\n            var sumTensor = TensorHelper.SumTensors(lmsDerProduct, new[] { 1, 4, 64, 64 });\n\n            // Add the sumed tensor to the sample\n            var prevSample = TensorHelper.AddTensors(sample.ToArray(), sumTensor.ToArray(), sample.Dimensions.ToArray());\n\n            return prevSample;\n        }\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/TensorHelper.cs", "chunked_list": ["\ufeffusing Microsoft.ML.OnnxRuntime.Tensors;\nusing System;\nusing System.Linq;\n\nnamespace StableDiffusion\n{\n    public class TensorHelper\n    {\n        public static DenseTensor<T> CreateTensor<T>(T[] data, int[] dimensions)\n        {\n            return new DenseTensor<T>(data, dimensions); ;\n        }\n", "        public static DenseTensor<T> CreateTensor<T>(T[] data, int[] dimensions)\n        {\n            return new DenseTensor<T>(data, dimensions); ;\n        }\n\n        public static DenseTensor<float> DivideTensorByFloat(float[] data, float value, int[] dimensions)\n        {\n            for (int i = 0; i < data.Length; i++)\n            {\n                data[i] = data[i] / value;\n            }\n\n            return CreateTensor(data, dimensions);\n        }\n", "        public static DenseTensor<float> MultipleTensorByFloat(float[] data, float value, int[] dimensions)\n        {\n            for (int i = 0; i < data.Length; i++)\n            {\n                data[i] = data[i] * value;\n            }\n\n            return CreateTensor(data, dimensions);\n        }\n\n        public static DenseTensor<float> MultipleTensorByFloat(Tensor<float> data, float value)\n        {\n            return MultipleTensorByFloat(data.ToArray(), value, data.Dimensions.ToArray());\n        }\n", "        public static DenseTensor<float> MultipleTensorByFloat(Tensor<float> data, float value)\n        {\n            return MultipleTensorByFloat(data.ToArray(), value, data.Dimensions.ToArray());\n        }\n\n        public static DenseTensor<float> AddTensors(float[] sample, float[] sumTensor, int[] dimensions)\n        {\n            for (var i = 0; i < sample.Length; i++)\n            {\n                sample[i] = sample[i] + sumTensor[i];\n            }\n            return CreateTensor(sample, dimensions); ;\n        }\n", "        public static DenseTensor<float> AddTensors(Tensor<float> sample, Tensor<float> sumTensor)\n        {\n            return AddTensors(sample.ToArray(), sumTensor.ToArray(), sample.Dimensions.ToArray());\n        }\n\n        public static Tuple<Tensor<float>, Tensor<float>> SplitTensor(Tensor<float> tensorToSplit, int[] dimensions)\n        {\n            var tensor1 = new DenseTensor<float>(dimensions);\n            var tensor2 = new DenseTensor<float>(dimensions);\n\n            for (int i = 0; i < 1; i++)\n            {", "            for (int i = 0; i < 1; i++)\n            {\n                for (int j = 0; j < 4; j++)\n                {\n                    for (int k = 0; k < 512 / 8; k++)\n                    {\n                        for (int l = 0; l < 512 / 8; l++)\n                        {\n                            tensor1[i, j, k, l] = tensorToSplit[i, j, k, l];\n                            tensor2[i, j, k, l] = tensorToSplit[i, j + 4, k, l];\n                        }\n                    }\n                }\n            }\n\n            return new Tuple<Tensor<float>, Tensor<float>>(tensor1, tensor2);\n        }\n", "        public static DenseTensor<float> SumTensors(Tensor<float>[] tensorArray, int[] dimensions)\n        {\n            var sumTensor = new DenseTensor<float>(dimensions);\n            var sumArray = new float[sumTensor.Length];\n\n            for (int m = 0; m < tensorArray.Count(); m++)\n            {\n                var tensorToSum = tensorArray[m].ToArray();\n                for (var i = 0; i < tensorToSum.Length; i++)\n                {\n                    sumArray[i] += (float)tensorToSum[i];\n                }\n            }\n\n            return CreateTensor(sumArray, dimensions);\n        }\n", "                for (var i = 0; i < tensorToSum.Length; i++)\n                {\n                    sumArray[i] += (float)tensorToSum[i];\n                }\n            }\n\n            return CreateTensor(sumArray, dimensions);\n        }\n\n        public static DenseTensor<float> Duplicate(float[] data, int[] dimensions)\n        {\n            data = data.Concat(data).ToArray();\n            return CreateTensor(data, dimensions);\n        }\n", "        public static DenseTensor<float> Duplicate(float[] data, int[] dimensions)\n        {\n            data = data.Concat(data).ToArray();\n            return CreateTensor(data, dimensions);\n        }\n\n        public static DenseTensor<float> SubtractTensors(float[] sample, float[] subTensor, int[] dimensions)\n        {\n            for (var i = 0; i < sample.Length; i++)\n            {\n                sample[i] = sample[i] - subTensor[i];\n            }\n            return CreateTensor(sample, dimensions);\n        }\n", "            for (var i = 0; i < sample.Length; i++)\n            {\n                sample[i] = sample[i] - subTensor[i];\n            }\n            return CreateTensor(sample, dimensions);\n        }\n\n        public static DenseTensor<float> SubtractTensors(Tensor<float> sample, Tensor<float> subTensor)\n        {\n            return SubtractTensors(sample.ToArray(), subTensor.ToArray(), sample.Dimensions.ToArray());\n        }\n", "        public static Tensor<float> GetRandomTensor(ReadOnlySpan<int> dimensions)\n        {\n            var latents = new DenseTensor<float>(dimensions);\n            var latentsArray = latents.ToArray();\n\n            for (int i = 0; i < latentsArray.Length; i++)\n            {\n                // Generate a random number from a normal distribution with mean 0 and variance 1\n                var u1 = UnityEngine.Random.Range(0.0f, 1.0f); // Uniform(0,1) random number\n                var u2 = UnityEngine.Random.Range(0.0f, 1.0f); // Uniform(0,1) random number\n                var radius = Math.Sqrt(-2.0 * Math.Log(u1)); // Radius of polar coordinates\n                var theta = 2.0 * Math.PI * u2; // Angle of polar coordinates\n                var standardNormalRand = radius * Math.Cos(theta); // Standard normal random number\n                latentsArray[i] = (float)standardNormalRand;\n            }\n\n            latents = CreateTensor(latentsArray, latents.Dimensions.ToArray());\n\n            return latents;\n        }\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/VAE.cs", "chunked_list": ["using Microsoft.ML.OnnxRuntime;\nusing Microsoft.ML.OnnxRuntime.Tensors;\nusing System.Collections.Generic;\nusing System.Linq;\nusing UnityEngine;\n\nnamespace StableDiffusion\n{\n    public class VAE\n    {\n        private static InferenceSession vaeDecoderModel;\n", "    public class VAE\n    {\n        private static InferenceSession vaeDecoderModel;\n\n        public static void LoadModel(string path)\n        {\n            vaeDecoderModel = new InferenceSession(path);\n        }\n\n        public static void Free() { vaeDecoderModel.Dispose(); }\n", "        public static void Free() { vaeDecoderModel.Dispose(); }\n\n        public static Tensor<float> Decoder(List<NamedOnnxValue> input)\n        {\n            var output = vaeDecoderModel.Run(input);\n            return (output.ToList().First().Value as Tensor<float>);\n        }\n\n        public static void ConvertToImage(ref Texture2D result, Tensor<float> output, int width, int height)\n        {\n            for (int y = 0; y < height; y++)", "        public static void ConvertToImage(ref Texture2D result, Tensor<float> output, int width, int height)\n        {\n            for (int y = 0; y < height; y++)\n                for (int x = 0; x < width; x++)\n                    result.SetPixel(x, y, new Color(output[0, 0, y, x] / 2 + 0.5f, output[0, 1, y, x] / 2 + 0.5f, output[0, 2, y, x] / 2 + 0.5f, 1.0f));\n\n            result.Apply();\n        }\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/EulerAncestralDiscreteScheduler.cs", "chunked_list": ["\ufeffusing Microsoft.ML.OnnxRuntime.Tensors;\nusing NumSharp;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\n\nnamespace StableDiffusion\n{\n    public class EulerAncestralDiscreteScheduler : SchedulerBase\n    {\n        private readonly string _predictionType;", "    public class EulerAncestralDiscreteScheduler : SchedulerBase\n    {\n        private readonly string _predictionType;\n        public override float InitNoiseSigma { get; set; }\n        public int num_inference_steps;\n        public override List<int> Timesteps { get; set; }\n        public override Tensor<float> Sigmas { get; set; }\n\n        public EulerAncestralDiscreteScheduler(\n            int num_train_timesteps = 1000,\n            float beta_start = 0.00085f,\n            float beta_end = 0.012f,\n            string beta_schedule = \"scaled_linear\",\n            List<float> trained_betas = null,\n            string prediction_type = \"epsilon\"\n        ) : base(num_train_timesteps)\n        {\n            var alphas = new List<float>();\n            var betas = new List<float>();\n            _predictionType = prediction_type;\n", "            if (trained_betas != null)\n            {\n                betas = trained_betas;\n            }\n            else if (beta_schedule == \"linear\")\n            {\n                betas = Enumerable.Range(0, num_train_timesteps).Select(i => beta_start + (beta_end - beta_start) * i / (num_train_timesteps - 1)).ToList();\n            }\n            else if (beta_schedule == \"scaled_linear\")\n            {\n                var start = (float)Math.Sqrt(beta_start);\n                var end = (float)Math.Sqrt(beta_end);\n                betas = np.linspace(start, end, num_train_timesteps).ToArray<float>().Select(x => x * x).ToList();\n            }\n            else\n            {\n                throw new Exception(\"beta_schedule must be one of 'linear' or 'scaled_linear'\");\n            }\n\n            alphas = betas.Select(beta => 1 - beta).ToList();\n\n            this._alphasCumulativeProducts = alphas.Select((alpha, i) => alphas.Take(i + 1).Aggregate((a, b) => a * b)).ToList();\n            // Create sigmas as a list and reverse it\n            var sigmas = _alphasCumulativeProducts.Select(alpha_prod => Math.Sqrt((1 - alpha_prod) / alpha_prod)).Reverse().ToList();\n\n            // standard deviation of the initial noise distrubution\n            this.InitNoiseSigma = (float)sigmas.Max();\n        }\n", "            else if (beta_schedule == \"scaled_linear\")\n            {\n                var start = (float)Math.Sqrt(beta_start);\n                var end = (float)Math.Sqrt(beta_end);\n                betas = np.linspace(start, end, num_train_timesteps).ToArray<float>().Select(x => x * x).ToList();\n            }\n            else\n            {\n                throw new Exception(\"beta_schedule must be one of 'linear' or 'scaled_linear'\");\n            }\n\n            alphas = betas.Select(beta => 1 - beta).ToList();\n\n            this._alphasCumulativeProducts = alphas.Select((alpha, i) => alphas.Take(i + 1).Aggregate((a, b) => a * b)).ToList();\n            // Create sigmas as a list and reverse it\n            var sigmas = _alphasCumulativeProducts.Select(alpha_prod => Math.Sqrt((1 - alpha_prod) / alpha_prod)).Reverse().ToList();\n\n            // standard deviation of the initial noise distrubution\n            this.InitNoiseSigma = (float)sigmas.Max();\n        }\n", "        public override int[] SetTimesteps(int num_inference_steps)\n        {\n            double start = 0;\n            double stop = _numTrainTimesteps - 1;\n            double[] timesteps = np.linspace(start, stop, num_inference_steps).ToArray<double>();\n\n            this.Timesteps = timesteps.Select(x => (int)x).Reverse().ToList();\n\n            var sigmas = _alphasCumulativeProducts.Select(alpha_prod => Math.Sqrt((1 - alpha_prod) / alpha_prod)).Reverse().ToList();\n            var range = np.arange((double)0, (double)(sigmas.Count)).ToArray<double>();\n            sigmas = Interpolate(timesteps, range, sigmas).ToList();\n            this.InitNoiseSigma = (float)sigmas.Max();\n            this.Sigmas = new DenseTensor<float>(sigmas.Count());", "            for (int i = 0; i < sigmas.Count(); i++)\n            {\n                this.Sigmas[i] = (float)sigmas[i];\n            }\n\n            return this.Timesteps.ToArray();\n        }\n\n        public override DenseTensor<float> Step(Tensor<float> modelOutput,\n               int timestep,\n               Tensor<float> sample,\n               int order = 4\n            )\n        {\n", "        public override DenseTensor<float> Step(Tensor<float> modelOutput,\n               int timestep,\n               Tensor<float> sample,\n               int order = 4\n            )\n        {\n\n            if (!this.is_scale_input_called)\n            {\n                UnityEngine.Debug.Log(\n                    \"The `scale_model_input` function should be called before `step` to ensure correct denoising. \" +\n                    \"See `StableDiffusionPipeline` for a usage example.\"\n                );\n            }\n\n            int stepIndex = this.Timesteps.IndexOf((int)timestep);\n            var sigma = this.Sigmas[stepIndex];\n\n            // 1. compute predicted original sample (x_0) from sigma-scaled predicted noise\n            Tensor<float> predOriginalSample = null;", "            if (this._predictionType == \"epsilon\")\n            {\n                //  pred_original_sample = sample - sigma * model_output\n                predOriginalSample = TensorHelper.SubtractTensors(sample,\n                                                                  TensorHelper.MultipleTensorByFloat(modelOutput, sigma));\n            }\n            else if (this._predictionType == \"v_prediction\")\n            {\n                // * c_out + input * c_skip\n                //predOriginalSample = modelOutput * (-sigma / Math.Pow(sigma * sigma + 1, 0.5)) + (sample / (sigma * sigma + 1));\n                throw new NotImplementedException($\"prediction_type not implemented yet: {_predictionType}\");\n            }", "            else if (this._predictionType == \"sample\")\n            {\n                throw new NotImplementedException($\"prediction_type not implemented yet: {_predictionType}\");\n            }\n            else\n            {\n                throw new ArgumentException(\n                    $\"prediction_type given as {this._predictionType} must be one of `epsilon`, or `v_prediction`\"\n                );\n            }\n\n            float sigmaFrom = this.Sigmas[stepIndex];\n            float sigmaTo = this.Sigmas[stepIndex + 1];\n\n            var sigmaFromLessSigmaTo = (MathF.Pow(sigmaFrom, 2) - MathF.Pow(sigmaTo, 2));\n            var sigmaUpResult = (MathF.Pow(sigmaTo, 2) * sigmaFromLessSigmaTo) / MathF.Pow(sigmaFrom, 2);\n            var sigmaUp = sigmaUpResult < 0 ? -MathF.Pow(MathF.Abs(sigmaUpResult), 0.5f) : MathF.Pow(sigmaUpResult, 0.5f);\n\n            var sigmaDownResult = (MathF.Pow(sigmaTo, 2) - MathF.Pow(sigmaUp, 2));\n            var sigmaDown = sigmaDownResult < 0 ? -MathF.Pow(MathF.Abs(sigmaDownResult), 0.5f) : MathF.Pow(sigmaDownResult, 0.5f);\n\n            // 2. Convert to an ODE derivative\n            var sampleMinusPredOriginalSample = TensorHelper.SubtractTensors(sample, predOriginalSample);\n            DenseTensor<float> derivative = TensorHelper.DivideTensorByFloat(sampleMinusPredOriginalSample.ToArray(), sigma, predOriginalSample.Dimensions.ToArray());// (sample - predOriginalSample) / sigma;\n\n            float dt = sigmaDown - sigma;\n\n            DenseTensor<float> prevSample = TensorHelper.AddTensors(sample, TensorHelper.MultipleTensorByFloat(derivative, dt));// sample + derivative * dt;\n\n            //var noise = generator == null ? np.random.randn(modelOutput.shape) : np.random.RandomState(generator).randn(modelOutput.shape);\n            var noise = TensorHelper.GetRandomTensor(prevSample.Dimensions);\n\n            var noiseSigmaUpProduct = TensorHelper.MultipleTensorByFloat(noise, sigmaUp);\n            prevSample = TensorHelper.AddTensors(prevSample, noiseSigmaUpProduct);// prevSample + noise * sigmaUp;\n\n            return prevSample;\n        }\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/TextTokenizer.cs", "chunked_list": ["using Microsoft.ML.OnnxRuntime;\nusing Microsoft.ML.OnnxRuntime.Tensors;\nusing System.Collections.Generic;\nusing System.Linq;\n\nnamespace StableDiffusion\n{\n    public class TextTokenizer\n    {\n        private static InferenceSession textTokenizerModel;\n        private const int modelMaxLength = 77;", "        private static InferenceSession textTokenizerModel;\n        private const int modelMaxLength = 77;\n        private const int blankTokenValue = 49407;\n\n        public static void LoadModel(string path, string extension)\n        {\n            var sessionOptions = new SessionOptions();\n            sessionOptions.RegisterCustomOpLibraryV2(extension, out _);\n            textTokenizerModel = new InferenceSession(path, sessionOptions);\n        }\n", "        public static void Free() { textTokenizerModel.Dispose(); }\n\n        public static int[] TokenizeText(string text)\n        {\n            var inputTensor = new DenseTensor<string>(new string[] { text }, new int[] { 1 });\n            var inputString = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor<string>(\"string_input\", inputTensor) };\n            var tokens = textTokenizerModel.Run(inputString);\n\n            var inputIds = (tokens.ToList().First().Value as IEnumerable<long>).ToArray();\n\n            var InputIdsInt = inputIds.Select(x => (int)x).ToArray();\n", "            if (InputIdsInt.Length < modelMaxLength)\n            {\n                var pad = Enumerable.Repeat(blankTokenValue, 77 - InputIdsInt.Length).ToArray();\n                InputIdsInt = InputIdsInt.Concat(pad).ToArray();\n            }\n\n            return InputIdsInt;\n        }\n\n        public static int[] CreateUncondInput()\n        {\n            var inputIds = new List<int>() { 49406 };\n\n            var pad = Enumerable.Repeat(blankTokenValue, modelMaxLength - inputIds.Count()).ToArray();\n            inputIds.AddRange(pad);\n\n            return inputIds.ToArray();\n        }\n    }\n}", "        public static int[] CreateUncondInput()\n        {\n            var inputIds = new List<int>() { 49406 };\n\n            var pad = Enumerable.Repeat(blankTokenValue, modelMaxLength - inputIds.Count()).ToArray();\n            inputIds.AddRange(pad);\n\n            return inputIds.ToArray();\n        }\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/SchedulerBase.cs", "chunked_list": ["\ufeffusing Microsoft.ML.OnnxRuntime.Tensors;\nusing NumSharp;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\n\nnamespace StableDiffusion\n{\n    public abstract class SchedulerBase\n    {\n        protected readonly int _numTrainTimesteps;\n        protected List<float> _alphasCumulativeProducts;", "    public abstract class SchedulerBase\n    {\n        protected readonly int _numTrainTimesteps;\n        protected List<float> _alphasCumulativeProducts;\n        public bool is_scale_input_called;\n\n        public abstract List<int> Timesteps { get; set; }\n        public abstract Tensor<float> Sigmas { get; set; }\n        public abstract float InitNoiseSigma { get; set; }\n\n        public SchedulerBase(int _numTrainTimesteps = 1000)\n        {\n            this._numTrainTimesteps = _numTrainTimesteps;\n        }\n", "        public abstract float InitNoiseSigma { get; set; }\n\n        public SchedulerBase(int _numTrainTimesteps = 1000)\n        {\n            this._numTrainTimesteps = _numTrainTimesteps;\n        }\n\n        public static double[] Interpolate(double[] timesteps, double[] range, List<double> sigmas)\n        {\n            // Create an output array with the same shape as timesteps\n            var result = np.zeros(timesteps.Length + 1);\n\n            // Loop over each element of timesteps", "            for (int i = 0; i < timesteps.Length; i++)\n            {\n                // Find the index of the first element in range that is greater than or equal to timesteps[i]\n                int index = Array.BinarySearch(range, timesteps[i]);\n\n                // If timesteps[i] is exactly equal to an element in range, use the corresponding value in sigma\n                if (index >= 0)\n                {\n                    result[i] = sigmas[index];\n                }\n\n                // If timesteps[i] is less than the first element in range, use the first value in sigmas", "                else if (index == -1)\n                {\n                    result[i] = sigmas[0];\n                }\n\n                // If timesteps[i] is greater than the last element in range, use the last value in sigmas\n                else if (index == -range.Length - 1)\n                {\n                    result[i] = sigmas[-1];\n                }\n\n                // Otherwise, interpolate linearly between two adjacent values in sigmas\n                else\n                {\n                    index = ~index; // bitwise complement of j gives the insertion point of x[i]\n                    double t = (timesteps[i] - range[index - 1]) / (range[index] - range[index - 1]); // fractional distance between two points\n                    result[i] = sigmas[index - 1] + t * (sigmas[index] - sigmas[index - 1]); // linear interpolation formula\n                }\n            }\n\n            //  add 0.000 to the end of the result\n            result = np.add(result, 0.000f);\n            return result.ToArray<double>();\n        }\n\n        public DenseTensor<float> ScaleInput(DenseTensor<float> sample, int timestep)\n        {\n            // Get step index of timestep from TimeSteps\n            int stepIndex = this.Timesteps.IndexOf(timestep);\n            // Get sigma at stepIndex\n            var sigma = this.Sigmas[stepIndex];\n            sigma = (float)Math.Sqrt((Math.Pow(sigma, 2) + 1));\n\n            // Divide sample tensor shape {2,4,64,64} by sigma\n            sample = TensorHelper.DivideTensorByFloat(sample.ToArray(), sigma, sample.Dimensions.ToArray());\n            is_scale_input_called = true;\n            return sample;\n        }\n", "        public abstract int[] SetTimesteps(int num_inference_steps);\n\n        public abstract DenseTensor<float> Step(\n               Tensor<float> modelOutput,\n               int timestep,\n               Tensor<float> sample,\n               int order = 4\n            );\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/Unet.cs", "chunked_list": ["using Microsoft.ML.OnnxRuntime;\nusing Microsoft.ML.OnnxRuntime.Tensors;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing Unity.Mathematics;\nusing UnityEngine;\nusing MathRandom = Unity.Mathematics.Random;\n\nnamespace StableDiffusion", "\nnamespace StableDiffusion\n{\n    public class Unet\n    {\n        private static InferenceSession unetEncoderModel;\n        private static SchedulerBase scheduler;\n\n        private const int batch_size = 1;\n        private const int height = 512;\n        private const int width = 512;", "        private const int batch_size = 1;\n        private const int height = 512;\n        private const int width = 512;\n        private const int channels = 4;\n\n        private const float scale = 1.0f / 0.18215f;\n\n        public static void LoadModel(string path)\n        {\n            unetEncoderModel = new InferenceSession(path, Options());\n        }\n", "        public static void Free() { unetEncoderModel.Dispose(); }\n\n        public static void Inference(int steps, DenseTensor<float> textEmbeddings, float cfg, int seed, ref Texture2D result, bool useLMS)\n        {\n            scheduler = useLMS ? new LMSDiscreteScheduler() : new EulerAncestralDiscreteScheduler();\n            var timesteps = scheduler.SetTimesteps(steps);\n\n            var latents = GenerateLatentSample(batch_size, seed, scheduler.InitNoiseSigma);\n            var input = new List<NamedOnnxValue>();\n\n            for (int t = 0; t < steps; t++)\n            {\n                var latentModelInput = TensorHelper.Duplicate(latents.ToArray(), new[] { 2, 4, height / 8, width / 8 });\n\n                latentModelInput = scheduler.ScaleInput(latentModelInput, timesteps[t]);\n\n                input = CreateUnetModelInput(textEmbeddings, latentModelInput, timesteps[t]);\n\n                // Run Inference\n                var output = unetEncoderModel.Run(input);\n                var outputTensor = (output.ToList().First().Value as DenseTensor<float>);\n\n                var splitTensors = TensorHelper.SplitTensor(outputTensor, new[] { 1, 4, height / 8, width / 8 });\n                var noisePred = splitTensors.Item1;\n                var noisePredText = splitTensors.Item2;\n\n                noisePred = performGuidance(noisePred, noisePredText, cfg);\n\n                latents = scheduler.Step(noisePred, timesteps[t], latents);\n            }\n\n            latents = TensorHelper.MultipleTensorByFloat(latents.ToArray(), scale, latents.Dimensions.ToArray());\n            var decoderInput = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor(\"latent_sample\", latents) };\n\n            VAE.ConvertToImage(ref result, VAE.Decoder(decoderInput), width, height);\n        }\n", "            for (int t = 0; t < steps; t++)\n            {\n                var latentModelInput = TensorHelper.Duplicate(latents.ToArray(), new[] { 2, 4, height / 8, width / 8 });\n\n                latentModelInput = scheduler.ScaleInput(latentModelInput, timesteps[t]);\n\n                input = CreateUnetModelInput(textEmbeddings, latentModelInput, timesteps[t]);\n\n                // Run Inference\n                var output = unetEncoderModel.Run(input);\n                var outputTensor = (output.ToList().First().Value as DenseTensor<float>);\n\n                var splitTensors = TensorHelper.SplitTensor(outputTensor, new[] { 1, 4, height / 8, width / 8 });\n                var noisePred = splitTensors.Item1;\n                var noisePredText = splitTensors.Item2;\n\n                noisePred = performGuidance(noisePred, noisePredText, cfg);\n\n                latents = scheduler.Step(noisePred, timesteps[t], latents);\n            }\n\n            latents = TensorHelper.MultipleTensorByFloat(latents.ToArray(), scale, latents.Dimensions.ToArray());\n            var decoderInput = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor(\"latent_sample\", latents) };\n\n            VAE.ConvertToImage(ref result, VAE.Decoder(decoderInput), width, height);\n        }\n", "        public static Tensor<float> GenerateLatentSample(int batchSize, int seed, float initNoiseSigma)\n        {\n            var latents = new DenseTensor<float>(new[] { batchSize, channels, height / 8, width / 8 });\n            float[] latentsArray = latents.ToArray();\n            MathRandom random = new MathRandom((uint)seed);\n\n            Parallel.For(0, latentsArray.Length, i =>\n            {\n                // Generate a random number from a normal distribution with mean 0 and variance 1\n                float u1 = random.NextFloat(); // Uniform(0,1) random number\n                float u2 = random.NextFloat(); // Uniform(0,1) random number\n                float radius = math.sqrt(-2.0f * math.log(u1)); // Radius of polar coordinates\n                float theta = 2.0f * math.PI * u2; // Angle of polar coordinates\n                float standardNormalRand = radius * math.cos(theta); // Standard normal random number\n\n                // add noise to latents with * scheduler.init_noise_sigma\n                // generate randoms that are negative and positive\n                latentsArray[i] = standardNormalRand * initNoiseSigma;\n            });\n\n            latents = TensorHelper.CreateTensor(latentsArray, latents.Dimensions.ToArray());\n\n            return latents;\n        }\n", "        public static List<NamedOnnxValue> CreateUnetModelInput(Tensor<float> encoderHiddenStates, Tensor<float> sample, long timeStep)\n        {\n            var input = new List<NamedOnnxValue> {\n                NamedOnnxValue.CreateFromTensor(\"encoder_hidden_states\", encoderHiddenStates),\n                NamedOnnxValue.CreateFromTensor(\"sample\", sample),\n                NamedOnnxValue.CreateFromTensor(\"timestep\", new DenseTensor<float>(new float[] { timeStep }, new int[] { 1 }))\n                // NamedOnnxValue.CreateFromTensor(\"timestep\", new DenseTensor<long>(new long[] { timeStep }, new int[] { 1 }))\n            };\n\n            return input;\n        }\n", "        private static Tensor<float> performGuidance(Tensor<float> noisePred, Tensor<float> noisePredText, double guidanceScale)\n        {\n            Parallel.For(0, noisePred.Dimensions[0], i =>\n            {\n                for (int j = 0; j < noisePred.Dimensions[1]; j++)\n                    for (int k = 0; k < noisePred.Dimensions[2]; k++)\n                        for (int l = 0; l < noisePred.Dimensions[3]; l++)\n                            noisePred[i, j, k, l] = noisePred[i, j, k, l] + (float)guidanceScale * (noisePredText[i, j, k, l] - noisePred[i, j, k, l]);\n            });\n\n            return noisePred;\n        }\n", "        private static SessionOptions Options()\n        {\n            var sessionOptions = new SessionOptions();\n\n            try\n            {\n                sessionOptions.GraphOptimizationLevel = GraphOptimizationLevel.ORT_ENABLE_ALL;\n                sessionOptions.AppendExecutionProvider_CUDA();\n            }\n            //catch\n            //{\n            //    sessionOptions.EnableMemoryPattern = false;\n            //    sessionOptions.AppendExecutionProvider_DML();\n            //}\n            finally\n            {\n                sessionOptions.AppendExecutionProvider_CPU();\n            }\n\n            return sessionOptions;\n        }\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/TextEncoder.cs", "chunked_list": ["using Microsoft.ML.OnnxRuntime;\nusing Microsoft.ML.OnnxRuntime.Tensors;\nusing System.Collections.Generic;\nusing System.Linq;\n\nnamespace StableDiffusion\n{\n    public class TextEncoder\n    {\n        private static InferenceSession textEncoderModel;\n", "        private static InferenceSession textEncoderModel;\n\n        public static void LoadModel(string path)\n        {\n            textEncoderModel = new InferenceSession(path);\n        }\n\n        public static void Free() { textEncoderModel.Dispose(); }\n\n        public static DenseTensor<float> Encode(int[] tokenizedInput)\n        {\n            var input_ids = TensorHelper.CreateTensor(tokenizedInput, new[] { 1, tokenizedInput.Count() });\n\n            var input = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor<int>(\"input_ids\", input_ids) };\n\n            var encoded = textEncoderModel.Run(input);\n\n            var lastHiddenState = (encoded.ToList().First().Value as IEnumerable<float>).ToArray();\n            var lastHiddenStateTensor = TensorHelper.CreateTensor(lastHiddenState.ToArray(), new[] { 1, 77, 768 });\n\n            return lastHiddenStateTensor;\n        }\n    }\n}", "        public static DenseTensor<float> Encode(int[] tokenizedInput)\n        {\n            var input_ids = TensorHelper.CreateTensor(tokenizedInput, new[] { 1, tokenizedInput.Count() });\n\n            var input = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor<int>(\"input_ids\", input_ids) };\n\n            var encoded = textEncoderModel.Run(input);\n\n            var lastHiddenState = (encoded.ToList().First().Value as IEnumerable<float>).ToArray();\n            var lastHiddenStateTensor = TensorHelper.CreateTensor(lastHiddenState.ToArray(), new[] { 1, 77, 768 });\n\n            return lastHiddenStateTensor;\n        }\n    }\n}"]}
{"filename": "Assets/Scripts/StableDiffusion/Main.cs", "chunked_list": ["using Microsoft.ML.OnnxRuntime.Tensors;\nusing System.Linq;\nusing UnityEngine;\n\nnamespace StableDiffusion\n{\n    public class Main\n    {\n        private const int EmbeddingSize = 59136;    // 77 x 768\n\n        private static DenseTensor<float> textEmbeddings;\n", "        private const int EmbeddingSize = 59136;    // 77 x 768\n\n        private static DenseTensor<float> textEmbeddings;\n\n        public delegate void pipelineLoaded();\n        public static pipelineLoaded onReady;\n\n        public static void Init(string unet, string textEncoder, string clipTokenizer, string extension, string vaeDecoder)\n        {\n            Unet.LoadModel(unet);\n            TextEncoder.LoadModel(textEncoder);\n            TextTokenizer.LoadModel(clipTokenizer, extension);\n            VAE.LoadModel(vaeDecoder);\n\n            int[] uncondInputTokens = TextTokenizer.CreateUncondInput();\n            float[] uncondEmbedding = TextEncoder.Encode(uncondInputTokens).ToArray();\n\n            textEmbeddings = new DenseTensor<float>(new[] { 2, 77, 768 });", "            for (int i = 0; i < EmbeddingSize; i++)\n                textEmbeddings[0, i / 768, i % 768] = uncondEmbedding[i];\n\n            onReady?.Invoke();\n        }\n\n        public static void Run(string prompt, int steps, float cfg, int seed, ref Texture2D output, bool useLMS)\n        {\n            var textTokenized = TextTokenizer.TokenizeText(prompt);\n            float[] textPromptEmbeddings = TextEncoder.Encode(textTokenized).ToArray();\n", "            for (int i = 0; i < EmbeddingSize; i++)\n                textEmbeddings[1, i / 768, i % 768] = textPromptEmbeddings[i];\n\n            Unet.Inference(steps, textEmbeddings, cfg, seed, ref output, useLMS);\n        }\n\n        public static void Free()\n        {\n            Unet.Free();\n            TextEncoder.Free();\n            TextTokenizer.Free();\n            VAE.Free();\n        }\n    }\n}"]}
