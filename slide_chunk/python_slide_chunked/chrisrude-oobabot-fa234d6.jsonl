{"filename": "tests/test_decide_to_respond.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\ntests for unsolicited response logic\n\"\"\"\n\n\nfrom oobabot import decide_to_respond\n\n\ndef test_last_reply_times():\n    # a unit test which stores 10 timestamps, then purges the oldest 5\n    # and checks that the remaining 5 are the newest 5\n    lrt = decide_to_respond.LastReplyTimes(10, 5)\n    for i in range(10):\n        lrt[i] = i\n    lrt.purge_outdated(10)\n    assert len(lrt) == 5\n    assert sorted(lrt.values()) == [5, 6, 7, 8, 9]", "\ndef test_last_reply_times():\n    # a unit test which stores 10 timestamps, then purges the oldest 5\n    # and checks that the remaining 5 are the newest 5\n    lrt = decide_to_respond.LastReplyTimes(10, 5)\n    for i in range(10):\n        lrt[i] = i\n    lrt.purge_outdated(10)\n    assert len(lrt) == 5\n    assert sorted(lrt.values()) == [5, 6, 7, 8, 9]", "\n\ndef test_values_purged_when_cache_timeout_happens():\n    # a unit test which stores 10 timestamps, but with a timeout\n    # of 4 seconds.  Checks that after 5 seconds, there are 9\n    # timestamps left, and that the oldest one is 1 second old.\n    lrt = decide_to_respond.LastReplyTimes(4, 0)\n    for i in range(10):\n        lrt[i] = i\n    lrt.purge_outdated(5)\n    assert len(lrt) == 9\n    assert sorted(lrt.values())[0] == 1\n\n    lrt.purge_outdated(13)\n    assert len(lrt) == 1\n    assert sorted(lrt.values())[0] == 9\n\n    lrt.purge_outdated(14)\n    assert len(lrt) == 0", "\n\ndef test_when_not_full():\n    # a unit test which stores 5 timestamps with an unsolicited\n    # channel cap of 10, and checks that they're all there\n    lrt = decide_to_respond.LastReplyTimes(10, 10)\n    for i in range(5):\n        lrt[i] = i\n    lrt.purge_outdated(5)\n    assert len(lrt) == 5\n    assert sorted(lrt.values()) == [0, 1, 2, 3, 4]", "\n\ndef test_unlimited_channels():\n    # a unit test which stores 5 timestamps with an unsolicited\n    # channel cap of 0, and checks that they're all there\n    lrt = decide_to_respond.LastReplyTimes(5, 0)\n    for i in range(5):\n        lrt[i] = i\n    lrt.purge_outdated(5)\n    assert len(lrt) == 5\n    assert sorted(lrt.values()) == [0, 1, 2, 3, 4]", "\n\ndef test_when_empty():\n    # test that when the cache is empty, we don't crash\n    lrt = decide_to_respond.LastReplyTimes(10, 10)\n    lrt.purge_outdated(5)\n    assert len(lrt) == 0\n"]}
{"filename": "tests/test_transcript.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nwould include tests for Oobabot if we had any good ones\n\"\"\"\n\nimport asyncio\nimport json\nimport typing\n\nimport pytest", "\nimport pytest\n\nfrom oobabot import discrivener_message\nfrom oobabot import transcript\nfrom oobabot import types\n\nTEST_FILE = \"tests/test_data/discrivener-json.data\"\n\n\ndef load_messages() -> typing.List[\"types.DiscrivenerMessage\"]:\n    messages = []\n    with open(TEST_FILE, \"r\", encoding=\"utf-8\") as file:\n        for line in file.readlines():\n            try:\n                message = json.loads(\n                    line,\n                    object_pairs_hook=discrivener_message.object_pairs_hook,\n                )\n                messages.append(message)\n            except json.JSONDecodeError:\n                pytest.fail(f\"could not parse {line}\")\n    assert len(messages) == 71\n    return messages", "\n\ndef load_messages() -> typing.List[\"types.DiscrivenerMessage\"]:\n    messages = []\n    with open(TEST_FILE, \"r\", encoding=\"utf-8\") as file:\n        for line in file.readlines():\n            try:\n                message = json.loads(\n                    line,\n                    object_pairs_hook=discrivener_message.object_pairs_hook,\n                )\n                messages.append(message)\n            except json.JSONDecodeError:\n                pytest.fail(f\"could not parse {line}\")\n    assert len(messages) == 71\n    return messages", "\n\ndef test_can_make_transcript():\n    messages = load_messages()\n\n    # on python3.9 and earlier, we need to manually create\n    # an event loop for the transcript to run in\n    try:\n        asyncio.get_event_loop()\n    except RuntimeError:\n        print(\"creating new event loop\")\n        asyncio.set_event_loop(asyncio.new_event_loop())\n\n    script = transcript.Transcript(1, [])\n    for message in messages:\n        if isinstance(message, discrivener_message.UserVoiceMessage):\n            script.on_transcription(message)\n\n    assert 16 == script.message_buffer.size()", ""]}
{"filename": "tests/test_sentence_splitter.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# import pytest\n\"\"\"\nTests whether the sentence splitter works as expected\n\"\"\"\nfrom oobabot.ooba_client import SentenceSplitter\n\n\ndef test_split_text_to_sentences():\n    text = \"This is a sentence. This is another sentence.\"\n    tokens = list(text)\n    tokens.append(SentenceSplitter.END_OF_INPUT)\n\n    sentence_1 = \"This is a sentence. \"\n    sentence_2 = \"This is another sentence.\"\n    expected = []\n    expected.extend([[]] * (len(sentence_1)))\n    expected.append([sentence_1])\n    expected.extend([[]] * (len(sentence_2) - 1))\n    expected.append([sentence_2])\n\n    sentence_1 = SentenceSplitter()\n    for token in tokens:\n        for sent in sentence_1.next(token):\n            print(f\"^{sent}$\")\n\n    splitter = SentenceSplitter()\n    actual = [list(splitter.next(token)) for token in tokens]\n\n    assert expected == actual", "def test_split_text_to_sentences():\n    text = \"This is a sentence. This is another sentence.\"\n    tokens = list(text)\n    tokens.append(SentenceSplitter.END_OF_INPUT)\n\n    sentence_1 = \"This is a sentence. \"\n    sentence_2 = \"This is another sentence.\"\n    expected = []\n    expected.extend([[]] * (len(sentence_1)))\n    expected.append([sentence_1])\n    expected.extend([[]] * (len(sentence_2) - 1))\n    expected.append([sentence_2])\n\n    sentence_1 = SentenceSplitter()\n    for token in tokens:\n        for sent in sentence_1.next(token):\n            print(f\"^{sent}$\")\n\n    splitter = SentenceSplitter()\n    actual = [list(splitter.next(token)) for token in tokens]\n\n    assert expected == actual", ""]}
{"filename": "tests/test_persona.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# import pytest\n\"\"\"\nTests loading persona files in different formats\n\"\"\"\nimport pytest\n\nimport oobabot.persona\n\nBASE_SETTINGS = {", "\nBASE_SETTINGS = {\n    \"ai_name\": \"oobabot\",\n    \"persona\": \"\",\n    \"wakewords\": [],\n}\n\n\n@pytest.fixture(autouse=True)\ndef change_test_dir(request, monkeypatch):\n    monkeypatch.chdir(request.fspath.dirname)", "@pytest.fixture(autouse=True)\ndef change_test_dir(request, monkeypatch):\n    monkeypatch.chdir(request.fspath.dirname)\n\n\ndef test_persona_loading_base():\n    test_char_1_json = BASE_SETTINGS.copy()\n    persona = oobabot.persona.Persona(test_char_1_json)\n    assert persona.ai_name == BASE_SETTINGS[\"ai_name\"]\n    assert persona.persona == BASE_SETTINGS[\"persona\"]\n    assert persona.wakewords == BASE_SETTINGS[\"wakewords\"]", "\n\ndef test_persona_loading_json_1():\n    test_char_1_json = BASE_SETTINGS.copy()\n    test_char_1_json[\"persona_file\"] = \"./test_data/test-char-1.json\"\n    persona = oobabot.persona.Persona(test_char_1_json)\n    assert persona.ai_name == \"...name...\"\n    assert persona.persona == \"...name... ...description...\"\n    assert persona.wakewords == [\"...name...\"]\n", "\n\ndef test_persona_loading_json_2():\n    test_char_2_json = BASE_SETTINGS.copy()\n    test_char_2_json[\"persona_file\"] = \"./test_data/test-char-2.json\"\n    persona = oobabot.persona.Persona(test_char_2_json)\n    assert persona.ai_name == \"...name...\"\n    assert persona.persona == \"...persona...\"\n    assert persona.wakewords == [\"...name...\"]\n", "\n\ndef test_persona_loading_json_3():\n    test_char_3_json = BASE_SETTINGS.copy()\n    test_char_3_json[\"persona_file\"] = \"./test_data/test-char-3.json\"\n    persona = oobabot.persona.Persona(test_char_3_json)\n    assert persona.ai_name == \"...char_name...\"\n    assert persona.persona == \"...char_persona...\"\n    print(persona.wakewords)\n    assert persona.wakewords == [\"...char_name...\"]", "\n\ndef test_persona_loading_yaml():\n    test_char_1_yaml = BASE_SETTINGS.copy()\n    test_char_1_yaml[\"persona_file\"] = \"./test_data/test-char-1.yaml\"\n    persona = oobabot.persona.Persona(test_char_1_yaml)\n    assert persona.ai_name == \"...name...\"\n    assert persona.persona == \"...context...\"\n    # assert persona.wakewords == [\"...name...\"]\n", "    # assert persona.wakewords == [\"...name...\"]\n\n\ndef test_persona_loading_txt():\n    test_char_1_txt = BASE_SETTINGS.copy()\n    test_char_1_txt[\"persona_file\"] = \"./test_data/test-char-1.txt\"\n    persona = oobabot.persona.Persona(test_char_1_txt)\n    assert persona.ai_name == BASE_SETTINGS[\"ai_name\"]\n    assert persona.persona == \"...persona...\\n\"\n    # assert persona.wakewords == BASE_SETTINGS[\"wakewords\"]", "    # assert persona.wakewords == BASE_SETTINGS[\"wakewords\"]\n"]}
{"filename": "tests/test_oobabot.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nwould include tests for Oobabot if we had any good ones\n\"\"\"\nimport asyncio\nimport os\n\nimport aiohttp\n\nfrom oobabot import oobabot", "\nfrom oobabot import oobabot\n\nDISCORD_TOKEN_INVALID_INTENTS_ENV_VAR = \"DISCORD_TOKEN_INVALID_INTENTS\"\n\n\ndef test_things_can_be_created_at_least():\n    args = [\"--discord-token\", \"1234\"]\n    oobabot.Oobabot(args)\n", "\n\ndef test_user_id_extraction():\n    assert 1111111111111111111 == oobabot.discord_utils.get_user_id_from_token(\n        \"MTExMTExMTExMTExMTExMTExMQ.000000.00000000000000000000000000000000000000\"\n    )\n\n    assert 1234567891101101011 == oobabot.discord_utils.get_user_id_from_token(\n        \"MTIzNDU2Nzg5MTEwMTEwMTAxMQ.000000.00000000000000000000000000000000000000\"\n    )", "\n\ndef test_discord_token():\n    bot = oobabot.Oobabot([])\n    connected = bot.test_discord_token(\"1234\")\n    assert connected is False\n\n    # if token is set in the environment, expect it to be valid\n    token = os.environ.get(oobabot.settings.Settings.DISCORD_TOKEN_ENV_VAR, \"\")\n    if token:\n        connected = bot.test_discord_token(token)\n        assert connected is True\n\n    invalid_intents_token = os.environ.get(DISCORD_TOKEN_INVALID_INTENTS_ENV_VAR, \"\")\n    if invalid_intents_token:\n        connected = bot.test_discord_token(invalid_intents_token)\n        assert connected is False", "\n\ndef test_invite_url():\n    bot = oobabot.Oobabot([])\n    token = os.environ.get(oobabot.settings.Settings.DISCORD_TOKEN_ENV_VAR, \"\")\n    if not token:\n        return\n    url = bot.generate_invite_url(token)\n\n    async def test_url(url: str) -> bool:\n        print(url)\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url) as resp:\n                print(resp.status)\n                return resp.status == 200\n\n    result = asyncio.run(test_url(url))\n    assert result is True", ""]}
{"filename": "src/oobabot/templates.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nTemplates for text generated by the bot.  There are two types:\n - templates used to generate prompts for the AI\n - templates used to generate UI messages for the user\n\"\"\"\n\nimport enum\nimport functools\nimport textwrap", "import functools\nimport textwrap\nimport typing\n\n\n@functools.total_ordering\nclass Templates(enum.Enum):\n    \"\"\"\n    Enumeration of all different templates.\n    \"\"\"\n\n    COMMAND_LOBOTOMIZE_RESPONSE = \"command_lobotomize_response\"\n\n    IMAGE_DETACH = \"image_detach\"\n    IMAGE_CONFIRMATION = \"image_confirmation\"\n    IMAGE_GENERATION_ERROR = \"image_generation_error\"\n    IMAGE_UNAUTHORIZED = \"image_unauthorized\"\n\n    # prompts to the AI to generate text responses\n    PROMPT = \"prompt\"\n    PROMPT_HISTORY_LINE = \"prompt_history_line\"\n    PROMPT_IMAGE_COMING = \"prompt_image_coming\"\n\n    def __str__(self) -> str:\n        return self.value\n\n    def __lt__(self, other: \"Templates\") -> bool:\n        return str(self.value) < str(other.value)", "\n\nclass TemplateToken(str, enum.Enum):\n    \"\"\"\n    Enumeration of all tokens used in templates.\n    Tokens are variable substitutions into the templates.\n    \"\"\"\n\n    AI_NAME = \"AI_NAME\"\n    PERSONA = \"PERSONA\"\n    IMAGE_COMING = \"IMAGE_COMING\"\n    IMAGE_PROMPT = \"IMAGE_PROMPT\"\n    MESSAGE_HISTORY = \"MESSAGE_HISTORY\"\n    USER_MESSAGE = \"USER_MESSAGE\"\n    USER_NAME = \"USER_NAME\"\n\n    def __str__(self):\n        return \"{\" + self.value + \"}\"", "\n\nclass TemplateStore:\n    \"\"\"\n    Data object storing all template definitions and default values.\n    \"\"\"\n\n    # mapping of template names to tokens allowed in that template\n    #  key: template name\n    #  value: tuple of (list of tokens, description, is_an_ai_prompt)\n    TEMPLATES: typing.Dict[\n        Templates, typing.Tuple[typing.List[TemplateToken], str, bool]\n    ] = {\n        Templates.COMMAND_LOBOTOMIZE_RESPONSE: (\n            [\n                TemplateToken.AI_NAME,\n                TemplateToken.USER_NAME,\n            ],\n            \"Displayed in Discord after a successful /lobotomize command.  \"\n            + \"Both the discord users and the bot AI will see this message.\",\n            True,\n        ),\n        Templates.PROMPT: (\n            [\n                TemplateToken.AI_NAME,\n                TemplateToken.IMAGE_COMING,\n                TemplateToken.MESSAGE_HISTORY,\n                TemplateToken.PERSONA,\n            ],\n            \"The main prompt sent to Oobabooga to generate a response from \"\n            + \"the bot AI.  The AI's reply to this prompt will be sent to \"\n            + \"discord as the bot's response.\",\n            True,\n        ),\n        Templates.PROMPT_HISTORY_LINE: (\n            [\n                TemplateToken.USER_MESSAGE,\n                TemplateToken.USER_NAME,\n            ],\n            \"Part of the AI response-generation prompt, this is used to \"\n            + \"render a single line of chat history.  A list of these, \"\n            + \"one for each past chat message, will become {MESSAGE_HISTORY} \"\n            + \"and inserted into the main prompt\",\n            True,\n        ),\n        Templates.PROMPT_IMAGE_COMING: (\n            [\n                TemplateToken.AI_NAME,\n            ],\n            \"Part of the AI response-generation prompt, this is used to \"\n            + \"inform the AI that it is in the process of generating an \"\n            + \"image.\",\n            True,\n        ),\n        Templates.IMAGE_DETACH: (\n            [\n                TemplateToken.IMAGE_PROMPT,\n                TemplateToken.USER_NAME,\n            ],\n            \"Shown in Discord when the user selects to discard an image \"\n            + \"that Stable Diffusion had generated.\",\n            False,\n        ),\n        Templates.IMAGE_CONFIRMATION: (\n            [\n                TemplateToken.IMAGE_PROMPT,\n                TemplateToken.USER_NAME,\n            ],\n            \"Shown in Discord when an image is first generated from \"\n            + \"Stable Diffusion.  This should prompt the user to either \"\n            + \"save or discard the image.\",\n            False,\n        ),\n        Templates.IMAGE_GENERATION_ERROR: (\n            [\n                TemplateToken.IMAGE_PROMPT,\n                TemplateToken.USER_NAME,\n            ],\n            \"Shown in Discord when the we could not contact Stable Diffusion \"\n            + \"to generate an image.\",\n            False,\n        ),\n        Templates.IMAGE_UNAUTHORIZED: (\n            [TemplateToken.USER_NAME],\n            \"Shown in Discord privately to a user if they try to regenerate \"\n            \"an image that was requested by someone else.\",\n            False,\n        ),\n    }\n\n    DEFAULT_TEMPLATES: typing.Dict[Templates, str] = {\n        Templates.PROMPT: textwrap.dedent(\n            \"\"\"\n            You are in a chat room with multiple participants.\n            Below is a transcript of recent messages in the conversation.\n            Write the next one to three messages that you would send in this\n            conversation, from the point of view of the participant named\n            {AI_NAME}.\n\n            {PERSONA}\n\n            All responses you write must be from the point of view of\n            {AI_NAME}.\n            ### Transcript:\n            {MESSAGE_HISTORY}\n            {IMAGE_COMING}\n            \"\"\"\n        ),\n        Templates.PROMPT_HISTORY_LINE: textwrap.dedent(\n            \"\"\"\n            {USER_NAME} says:\n            {USER_MESSAGE}\n\n            \"\"\"\n        ),\n        Templates.PROMPT_IMAGE_COMING: textwrap.dedent(\n            \"\"\"\n            {AI_NAME}: is currently generating an image, as requested.\n            \"\"\"\n        ),\n        Templates.IMAGE_DETACH: textwrap.dedent(\n            \"\"\"\n            {USER_NAME} asked for an image with the prompt:\n                '{IMAGE_PROMPT}'\n            ...but couldn't find a suitable one.\n            \"\"\"\n        ),\n        Templates.IMAGE_CONFIRMATION: textwrap.dedent(\n            \"\"\"\n            {USER_NAME}, is this what you wanted?\n            If no choice is made, this message will \ud83d\udca3 self-destruct \ud83d\udca3 in 3 minutes.\n            \"\"\"\n        ),\n        Templates.IMAGE_GENERATION_ERROR: textwrap.dedent(\n            \"\"\"\n            Something went wrong generating your image.  Sorry about that!\n            \"\"\"\n        ),\n        Templates.IMAGE_UNAUTHORIZED: textwrap.dedent(\n            \"\"\"\n            Sorry, only {USER_NAME} can press the buttons.\n            \"\"\"\n        ),\n        Templates.COMMAND_LOBOTOMIZE_RESPONSE: textwrap.dedent(\n            \"\"\"\n            Ummmm... what were we talking about?\n            \"\"\"\n        ),\n    }\n\n    def __init__(self, settings: dict):\n        self.templates: typing.Dict[Templates, TemplateMessageFormatter] = {}\n        for template, (tokens, purpose, is_ai_prompt) in self.TEMPLATES.items():\n            template_name = str(template)\n            template_fmt = settings[template_name]\n            if template_fmt is None:\n                raise ValueError(f\"Template {template_name} has no default format\")\n            self.add_template(template, template_fmt, tokens, purpose, is_ai_prompt)\n\n    def add_template(\n        self,\n        template_name: Templates,\n        format_str: str,\n        allowed_tokens: typing.List[TemplateToken],\n        purpose: str,\n        is_ai_prompt: bool,\n    ):\n        self.templates[template_name] = TemplateMessageFormatter(\n            template_name,\n            format_str,\n            allowed_tokens,\n            purpose,\n            is_ai_prompt,\n        )\n\n    def format(\n        self, template_name: Templates, format_args: typing.Dict[TemplateToken, str]\n    ) -> str:\n        return self.templates[template_name].format(format_args)", "\n\nclass TemplateMessageFormatter:\n    \"\"\"\n    Validates that templates are safe to run string.format() on, and\n    runs string.format()\n    \"\"\"\n\n    def __init__(\n        self,\n        template_name: Templates,\n        template: str,\n        allowed_tokens: typing.List[TemplateToken],\n        purpose: str,\n        is_ai_prompt: bool,\n    ):\n        self._validate_format_string(template_name, template, allowed_tokens)\n        self.template_name = template_name\n        self.template = template\n        self.allowed_tokens = allowed_tokens\n        self.purpose = purpose\n        self.is_ai_prompt = is_ai_prompt\n\n    def __str__(self):\n        return self.template\n\n    def format(self, format_args: typing.Dict[TemplateToken, str]) -> str:\n        return self.template.format(**format_args)\n\n    @staticmethod\n    def _validate_format_string(\n        template_name: Templates,\n        format_str: str,\n        allowed_args: typing.List[TemplateToken],\n    ):\n        def find_all_ch(string: str, char: str) -> typing.Generator[int, None, None]:\n            # find all indices of ch in s\n            for i, letter in enumerate(string):\n                if letter == char:\n                    yield i\n\n        # raises if fmt_string contains any args not in allowed_args\n        allowed_close_brace_indices: typing.Set[int] = set()\n\n        for open_brace_idx in find_all_ch(format_str, \"{\"):\n            for allowed_arg in allowed_args:\n                idx_end = open_brace_idx + len(allowed_arg) + 1\n                next_substr = format_str[open_brace_idx : idx_end + 1]\n                if next_substr == \"{\" + allowed_arg + \"}\":\n                    allowed_close_brace_indices.add(idx_end)\n                    break\n            else:\n                raise ValueError(\n                    f\"invalid template: {template_name} contains \"\n                    + f\"an argument not in {allowed_args}\"\n                )\n        for close_brace_idx in find_all_ch(format_str, \"}\"):\n            if close_brace_idx not in allowed_close_brace_indices:\n                raise ValueError(\n                    f\"invalid template: {template_name} contains \"\n                    + f\"an argument not in {allowed_args}\"\n                )", ""]}
{"filename": "src/oobabot/oobabot.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n\"\"\"\nBot entrypoint.\n\"\"\"\n\nimport asyncio\nimport signal\nimport sys", "import signal\nimport sys\nimport threading\nimport typing\n\nimport oobabot\nfrom oobabot import discord_utils\nfrom oobabot import fancy_logger\nfrom oobabot import runtime\nfrom oobabot import settings", "from oobabot import runtime\nfrom oobabot import settings\nfrom oobabot import types\nfrom oobabot import voice_client\n\n\nclass Oobabot:\n    \"\"\"\n    Main bot class.  Load settings, creates helper objects,\n    and invokes the bot loop.\n\n    Methods:\n        constructor: Loads settings from the command line, environment\n            variables, and config file.  This config may be changed\n            before calling start().\n        start: Start the bot.  Blocks until the bot exits.\n        stop: Stop the bot.  Blocks until the bot exits.\n        is_voice_enabled: Returns True if the bot is configured to\n            participate in voice channels.\n        current_voice_transcript (property): Returns the current\n            voice transcript, or an empty list if the bot is not\n            in a voice channel.\n        fancy_author_info: Given a Discord user_id, returns a struct\n            describing a user's display name, accent color, and icon.\n            Bot must be running for this to work.\n\n    Class Methods:\n        test_discord_token: Test a discord token to see if it's valid.\n            Requires Internet access.\n        generate_invite_url: Generate a URL that can be used to invite\n            the bot to a server.\n    \"\"\"\n\n    def __init__(\n        self,\n        cli_args: typing.List[str],\n        running_from_cli: bool = False,\n    ):\n        \"\"\"\n        Initialize the bot, and load settings from the command line,\n        environment variables, and config file.  These will be\n        available in self.settings.\n\n        self.settings is an :py:class:`oobabot.settings.Settings` object.\n        \"\"\"\n\n        self.runtime: typing.Optional[runtime.Runtime] = None\n        # guards access to runtime from multiple threads\n        self.runtime_lock = threading.Lock()\n        self.settings = settings.Settings()\n\n        try:\n            self.settings.load(cli_args, running_from_cli=running_from_cli)\n        except settings.SettingsError as err:\n            print(\"\\n\".join([str(arg) for arg in list(err.args)]), file=sys.stderr)\n            raise\n\n        fancy_logger.init_logging(\n            level=self.settings.discord_settings.get_str(\"log_level\"),\n            running_from_cli=running_from_cli,\n        )\n\n    def start(self):\n        \"\"\"\n        Start the bot.  Blocks until the bot exits.\n\n        When running inside another process, the bot will exit\n        when another thread calls stop().  Otherwise it will\n        exit when the user presses Ctrl-C, or the process receives\n        a SIGTERM or SIGINT signal.\n        \"\"\"\n        fancy_logger.get().info(\n            \"Starting oobabot, core version %s\", oobabot.__version__\n        )\n\n        with self.runtime_lock:\n            self.runtime = runtime.Runtime(self.settings)\n            test_passed = self.runtime.test_connections()\n            if not test_passed:\n                # test_connections will have logged the error\n                self.runtime = None\n                return\n\n        asyncio.run(self.runtime.run())\n\n    # pylint: disable=R1732\n    def stop(self) -> bool:\n        \"\"\"\n        Stop the bot.  Blocks until the bot exits.\n        \"\"\"\n        result = self.runtime_lock.acquire(timeout=5)\n        if result:\n            try:\n                if self.runtime is not None:\n                    self.runtime.stop()\n            finally:\n                self.runtime_lock.release()\n        else:\n            fancy_logger.get().error(\n                \"Failed to acquire runtime lock, could not shutdown gracefully\"\n            )\n        self.runtime = None\n        return result\n\n    # pylint: enable=R1732\n\n    @classmethod\n    def test_discord_token(cls, discord_token: str) -> bool:\n        \"\"\"\n        Tests a discord token to see if it's valid.  Can be called from any thread.\n\n        Requires Internet connectivity.\n\n        Returns True if it was able to connect with the token, False if it isn't.\n        \"\"\"\n        return asyncio.run(discord_utils.test_discord_token(discord_token))\n\n    @classmethod\n    def generate_invite_url(cls, discord_token: str) -> str:\n        \"\"\"\n        Generates an invite URL for the bot with the given token.\n\n        Can be called from any thread.  Does not require Internet connectivity.\n        \"\"\"\n        ai_user_id = discord_utils.get_user_id_from_token(discord_token)\n        return discord_utils.generate_invite_url(ai_user_id)\n\n    def is_voice_enabled(self) -> bool:\n        \"\"\"\n        Returns True if the bot is configured to participate in voice channels.\n\n        This checks that both:\n         a. discrivener is configured\n         b. discrivener is installed\n        \"\"\"\n        exe_location, model_location = discord_utils.validate_discrivener_locations(\n            self.settings.discord_settings.get_str(\"discrivener_location\"),\n            self.settings.discord_settings.get_str(\"discrivener_model_location\"),\n        )\n        return exe_location is not None and model_location is not None\n\n    @property\n    def current_voice_transcript(\n        self,\n    ) -> typing.List[\"types.VoiceMessage\"]:\n        \"\"\"\n        If the bot is currently in a voice channel, returns the transcript\n        of what's being said.  Otherwise, returns an empty list.\n        \"\"\"\n        client = voice_client.VoiceClient.current_instance\n        if client is None:\n            return []\n        transcript = client.current_transcript()\n        if transcript is None:\n            return []\n        return transcript.message_buffer.get()\n\n    def fancy_author_info(self, user_id: int) -> typing.Optional[\"types.FancyAuthor\"]:\n        \"\"\"\n        Returns a FancyAuthor object for the given user_id.\n\n        This will only work if the bot is running and connected\n        to a voice channel, and then only for users who are\n        in that discord server.\n\n        We do this instead of a more general lookup because\n        this is what lets us get more information, including\n        the server-specific nickname, color, and icon.\n        \"\"\"\n        client = voice_client.VoiceClient.current_instance\n        if client is None:\n            return None\n        return discord_utils.author_from_user_id(user_id, client.guild)\n\n    def log_count(self) -> int:\n        \"\"\"\n        Returns the current number of times the log has been\n        appended to.\n        \"\"\"\n        return fancy_logger.recent_logs.changes\n\n    def logs(self) -> typing.List[str]:\n        \"\"\"\n        Returns a list of the most recent log messages.\n        \"\"\"\n        return fancy_logger.recent_logs.get_all()", "\n\ndef run_cli():\n    \"\"\"\n    Run the bot from the command line.  Blocks until the bot exits.\n\n    This is the main entrypoint for the CLI.\n\n    In addition to running the bot, this function also handles\n    other CLI commands, such as:\n    - help: Print help and exit\n    - generate_config: Print a the config file and exit\n    - invite_url: Print a URL that can be used to invite the bot\n    \"\"\"\n\n    # create the object and load our settings\n    try:\n        oobabot = Oobabot(sys.argv[1:], running_from_cli=True)\n    except settings.SettingsError:\n        sys.exit(1)\n\n    # if we're running as a worker thread in another process,\n    # we can't (and shouldn't) register\n    def exit_handler(signum, _frame):\n        sig_name = signal.Signals(signum).name\n        fancy_logger.get().info(\"Received signal %s, exiting...\", sig_name)\n        result = oobabot.stop()\n        sys.exit(not result)\n\n    signal.signal(signal.SIGINT, exit_handler)\n    signal.signal(signal.SIGTERM, exit_handler)\n\n    if oobabot.settings.general_settings.get(\"help\"):\n        oobabot.settings.print_help()\n        return\n\n    if oobabot.settings.general_settings.get(\"generate_config\"):\n        oobabot.settings.write_to_stream(out_stream=sys.stdout)\n        if sys.stdout.isatty():\n            print(oobabot.settings.META_INSTRUCTION, file=sys.stderr)\n        else:\n            print(\"# oobabot: config.yml output successfully\", file=sys.stderr)\n        return\n\n    if not oobabot.settings.discord_settings.get(\"discord_token\"):\n        msg = (\n            f\"Please set the '{oobabot.settings.DISCORD_TOKEN_ENV_VAR}' \"\n            + \"environment variable to your bot's discord token.\"\n        )\n        print(msg, file=sys.stderr)\n        sys.exit(1)\n\n    if oobabot.settings.general_settings.get(\"invite_url\"):\n        url = oobabot.generate_invite_url(\n            oobabot.settings.discord_settings.get_str(\"discord_token\")\n        )\n        print(url)\n        return\n\n    sys.excepthook = fancy_logger.excepthook\n\n    oobabot.start()", "\n\ndef main():\n    run_cli()\n"]}
{"filename": "src/oobabot/prompt_generator.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nGenerate a prompt for the AI to respond to, given the\nmessage history and persona.\n\"\"\"\nimport typing\n\nfrom oobabot import fancy_logger\nfrom oobabot import persona\nfrom oobabot import templates", "from oobabot import persona\nfrom oobabot import templates\nfrom oobabot import types\n\n\nclass PromptGenerator:\n    \"\"\"\n    Purpose: generate a prompt for the AI to use, given\n    the message history and persona.\n    \"\"\"\n\n    # this is set by the AI, and is the maximum length\n    # it will understand before it starts to ignore\n    # the rest of the prompt_prefix\n    # note: we don't currently measure tokens, we just\n    # count characters. This is a rough estimate.\n    EST_CHARACTERS_PER_TOKEN = 3\n\n    # the estimated number of characters in a line of message history\n    # this is used to roughly calculate whether we'll have enough space\n    # to supply the requested number of lines of history.\n    #\n    # in practice, we will look at the actual number of characters to\n    # see what we can fit.\n    #\n    # note that we're doing calculations in characters, not in tokens,\n    # so even counting characters exactly is still an estimate.\n    EST_CHARACTERS_PER_HISTORY_LINE = 30\n\n    # when we're not splitting responses, each history line is\n    # much larger, and it's easier to run out of token space,\n    # so we use a different estimate\n    EST_CHARACTERS_PER_HISTORY_LINE_NOT_SPLITTING_RESPONSES = 180\n\n    def __init__(\n        self,\n        discord_settings: dict,\n        oobabooga_settings: dict,\n        persona: persona.Persona,\n        template_store: templates.TemplateStore,\n    ):\n        self.dont_split_responses = discord_settings[\"dont_split_responses\"]\n        self.history_lines = discord_settings[\"history_lines\"]\n        self.token_space = oobabooga_settings[\"request_params\"][\"truncation_length\"]\n\n        self.persona = persona\n        self.template_store = template_store\n\n        # this will be also used when sending message\n        # to suppress sending the prompt text to the user\n        self.bot_prompt_line = self.template_store.format(\n            templates.Templates.PROMPT_HISTORY_LINE,\n            {\n                templates.TemplateToken.USER_NAME: self.persona.ai_name,\n                templates.TemplateToken.USER_MESSAGE: \"\",\n            },\n        ).strip()\n\n        self.image_request_made = self.template_store.format(\n            templates.Templates.PROMPT_IMAGE_COMING,\n            {\n                templates.TemplateToken.AI_NAME: self.persona.ai_name,\n            },\n        )\n\n        self._init_history_available_chars()\n\n    def _init_history_available_chars(self) -> None:\n        \"\"\"\n        Calculate the number of characters we have available\n        for history, and raise an exception if we don't have\n        enough.\n\n        Raises:\n            ValueError: if we don't estimate to have enough space\n                for the requested number of lines of history\n        \"\"\"\n        # the number of chars we have available for history\n        # is:\n        #   number of chars in token space (estimated)\n        #   minus the number of chars in the prompt\n        #     - without any history\n        #     - but with the photo request\n        #\n        est_chars_in_token_space = self.token_space * self.EST_CHARACTERS_PER_TOKEN\n        prompt_without_history = self._generate(\"\", self.image_request_made)\n\n        # how many chars might we have available for history?\n        available_chars_for_history = est_chars_in_token_space - len(\n            prompt_without_history\n        )\n        # how many chars do we need for the requested number of\n        # lines of history?\n        chars_per_history_line = self.EST_CHARACTERS_PER_HISTORY_LINE\n        if self.dont_split_responses:\n            chars_per_history_line = (\n                self.EST_CHARACTERS_PER_HISTORY_LINE_NOT_SPLITTING_RESPONSES\n            )\n\n        required_history_size_chars = self.history_lines * chars_per_history_line\n\n        if available_chars_for_history < required_history_size_chars:\n            fancy_logger.get().warning(\n                \"AI token space is too small for prompt_prefix and history \"\n                + \"by an estimated %d\"\n                + \" characters.  You may lose history context.  You can save space\"\n                + \" by shortening the persona or reducing the requested number of\"\n                + \" lines of history.\",\n                required_history_size_chars - available_chars_for_history,\n            )\n        self.max_history_chars = available_chars_for_history\n\n    async def _render_history(\n        self,\n        message_history: typing.AsyncIterator[types.GenericMessage],\n    ) -> str:\n        # add on more history, but only if we have room\n        # if we don't have room, we'll just truncate the history\n        # by discarding the oldest messages first\n        # this is s\n        # it will understand before ignore\n        #\n        prompt_len_remaining = self.max_history_chars\n\n        # history_lines is newest first, so figure out\n        # how many we can take, then append them in\n        # reverse order\n        history_lines = []\n\n        async for message in message_history:\n            if not message.body_text:\n                continue\n\n            line = self.template_store.format(\n                templates.Templates.PROMPT_HISTORY_LINE,\n                {\n                    templates.TemplateToken.USER_NAME: message.author_name,\n                    templates.TemplateToken.USER_MESSAGE: message.body_text,\n                },\n            )\n\n            if len(line) > prompt_len_remaining:\n                num_discarded_lines = self.history_lines - len(history_lines)\n                fancy_logger.get().warning(\n                    \"ran out of prompt space, discarding {%d} lines of chat history\",\n                    num_discarded_lines,\n                )\n                break\n\n            prompt_len_remaining -= len(line)\n            history_lines.append(line)\n\n        history_lines.reverse()\n        return \"\".join(history_lines)\n\n    def _generate(\n        self,\n        message_history_txt: str,\n        image_coming: str,\n    ) -> str:\n        prompt = self.template_store.format(\n            templates.Templates.PROMPT,\n            {\n                templates.TemplateToken.AI_NAME: self.persona.ai_name,\n                templates.TemplateToken.PERSONA: self.persona.persona,\n                templates.TemplateToken.MESSAGE_HISTORY: message_history_txt,\n                templates.TemplateToken.IMAGE_COMING: image_coming,\n            },\n        )\n        prompt += self.bot_prompt_line + \"\\n\"\n        return prompt\n\n    async def generate(\n        self,\n        message_history: typing.Optional[typing.AsyncIterator[types.GenericMessage]],\n        image_requested: bool,\n    ) -> str:\n        \"\"\"\n        Generate a prompt for the AI to respond to.\n        \"\"\"\n        message_history_txt = \"\"\n        if message_history is not None:\n            message_history_txt = await self._render_history(\n                message_history,\n            )\n        image_coming = self.image_request_made if image_requested else \"\"\n        return self._generate(message_history_txt, image_coming)", ""]}
{"filename": "src/oobabot/settings.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nDocuments all the settings for the bot.  Allows for settings\nto be loaded from the environment, command line and config file.\n\nMethods:\n    - load:\n        loads settings from the environment, command line and config file\n\n    - write_to_stream:", "\n    - write_to_stream:\n        writes the current config file to the given stream\n\n    - write_to_file:\n        writes the current config file to the given file path\n\nAttributes:\n    - setting_groups:\n        a list of all the setting groups", "    - setting_groups:\n        a list of all the setting groups\n\n    - discord_settings:\n        a setting group for settings related to Discord\n\n    - oobabooga_settings:\n        a setting group for settings related to the oobabooga API\n\n    - stable_diffusion_settings:", "\n    - stable_diffusion_settings:\n        a setting group for settings related to the stable diffusion API\n\n    - general_settings:\n        a setting group for settings that are not included in the config file\n\"\"\"\nimport os\nimport shutil\nimport textwrap", "import shutil\nimport textwrap\nimport typing\n\nfrom oobabot import templates\nimport oobabot.overengineered_settings_parser as oesp\n\n\nclass SettingsError(Exception):\n    \"\"\"\n    Base class for exceptions in this module.\n    \"\"\"\n\n    def __init__(self, message: str, cause: Exception):\n        self.message = message\n        super().__init__(message, cause)", "class SettingsError(Exception):\n    \"\"\"\n    Base class for exceptions in this module.\n    \"\"\"\n\n    def __init__(self, message: str, cause: Exception):\n        self.message = message\n        super().__init__(message, cause)\n\n\ndef _console_wrapped(message):\n    width = shutil.get_terminal_size().columns\n    return \"\\n\".join(textwrap.wrap(message, width))", "\n\ndef _console_wrapped(message):\n    width = shutil.get_terminal_size().columns\n    return \"\\n\".join(textwrap.wrap(message, width))\n\n\ndef _make_template_comment(\n    tokens_desc_tuple: typing.Tuple[typing.List[templates.TemplateToken], str, bool],\n) -> typing.List[str]:\n    return [\n        tokens_desc_tuple[1],\n        \".\",\n        f\"Allowed tokens: {', '.join([str(t) for t in tokens_desc_tuple[0]])}\",\n        \".\",\n    ]", "\n\nclass Settings:\n    \"\"\"\n    User=customizable settings for the bot.  Reads from\n    environment variables and command line arguments.\n    \"\"\"\n\n    ############################################################\n    # This section is for constants which are not yet\n    # customizable by the user.\n\n    # This is a table of the probability that the bot will respond\n    # in an unsolicited manner (i.e. it isn't specifically pinged)\n    # to a message, based on how long ago it was pinged in that\n    # same channel.\n    TIME_VS_RESPONSE_CHANCE: typing.List[typing.Tuple[float, float]] = [\n        # (seconds, base % chance of an unsolicited response)\n        (60.0, 0.90),\n        (120.0, 0.70),\n        (60.0 * 5, 0.50),\n    ]\n\n    # increased chance of responding to a message if it ends with\n    # a question mark or exclamation point\n    DECIDE_TO_RESPOND_INTERROBANG_BONUS = 0.3\n\n    # number of times in a row that the bot will repeat itself\n    # before the repetition tracker will take action\n    REPETITION_TRACKER_THRESHOLD = 1\n\n    OOBABOOGA_DEFAULT_REQUEST_PARAMS: oesp.SettingDictType = {\n        \"max_new_tokens\": 250,\n        \"do_sample\": True,\n        \"temperature\": 1.3,\n        \"top_p\": 0.1,\n        \"typical_p\": 1,\n        \"epsilon_cutoff\": 0,  # In units of 1e-4\n        \"eta_cutoff\": 0,  # In units of 1e-4\n        \"tfs\": 1,\n        \"top_a\": 0,\n        \"repetition_penalty\": 1.18,\n        \"top_k\": 40,\n        \"min_length\": 0,\n        \"no_repeat_ngram_size\": 0,\n        \"num_beams\": 1,\n        \"penalty_alpha\": 0,\n        \"length_penalty\": 1,\n        \"early_stopping\": False,\n        \"mirostat_mode\": 0,\n        \"mirostat_tau\": 5,\n        \"mirostat_eta\": 0.1,\n        \"seed\": -1,\n        \"add_bos_token\": True,\n        \"truncation_length\": 2048,\n        \"ban_eos_token\": False,\n        \"skip_special_tokens\": True,\n        \"stopping_strings\": [],\n    }\n\n    # set default negative prompts to make it more difficult\n    # to create content against the discord TOS\n    # https://discord.com/guidelines\n\n    # use this prompt for \"age_restricted\" Discord channels\n    #  i.e. channel.nsfw is true\n    DEFAULT_SD_NEGATIVE_PROMPT_NSFW: str = \"animal harm, suicide, loli\"\n\n    # use this prompt for non-age-restricted channels\n    DEFAULT_SD_NEGATIVE_PROMPT: str = DEFAULT_SD_NEGATIVE_PROMPT_NSFW + \", nsfw\"\n\n    SD_CLIENT_MAGIC_MODEL_KEY = \"model\"\n\n    DEFAULT_SD_REQUEST_PARAMS: oesp.SettingDictType = {\n        \"cfg_scale\": 7,\n        #    This is a privacy concern for the users of the service.\n        #    We don't want to save the generated images anyway, since they\n        #    are going to be on Discord.  Also, we don't want to use the\n        #    disk space.\n        \"do_not_save_samples\": True,\n        \"do_not_save_grid\": True,\n        \"enable_hr\": False,\n        # this is a fake setting, SD calls it \"sd_model_checkpoint\",\n        # and it needs to appear under \"override_params\".  But put it here\n        # for convenience, the SD client will do the right thing with it.\n        SD_CLIENT_MAGIC_MODEL_KEY: \"\",\n        \"negative_prompt\": DEFAULT_SD_NEGATIVE_PROMPT,\n        \"negative_prompt_nsfw\": DEFAULT_SD_NEGATIVE_PROMPT_NSFW,\n        \"sampler_name\": \"\",\n        \"seed\": -1,\n        \"steps\": 30,\n        \"width\": 512,\n        \"height\": 512,\n    }\n\n    DEFAULT_SD_USER_OVERRIDE_PARAMS = [\n        \"cfg_scale\",\n        \"enable_hr\",\n        SD_CLIENT_MAGIC_MODEL_KEY,\n        \"negative_prompt\",\n        \"sampler_name\",\n        \"seed\",\n        \"height\",\n        \"width\",\n    ]\n\n    # words to look for in the prompt to indicate that the user\n    # wants to generate an image\n    DEFAULT_IMAGE_WORDS: typing.List[str] = [\n        \"draw me\",\n        \"drawing\",\n        \"photo\",\n        \"pic\",\n        \"picture\",\n        \"image\",\n        \"sketch\",\n    ]\n\n    # ENVIRONMENT VARIABLES ####\n    DISCORD_TOKEN_ENV_VAR: str = \"DISCORD_TOKEN\"\n    OOBABOT_PERSONA_ENV_VAR: str = \"OOBABOT_PERSONA\"\n\n    def __init__(self):\n        self._settings = None\n\n        self.arg_parser = None\n        self.setting_groups: typing.List[oesp.ConfigSettingGroup] = []\n\n        ###########################################################\n        # General Settings\n        #  won't be included in the config.yaml\n\n        self.general_settings = oesp.ConfigSettingGroup(\n            \"General Settings\", include_in_yaml=False\n        )\n        self.setting_groups.append(self.general_settings)\n\n        self.general_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"help\",\n                default=False,\n                description_lines=[],\n                cli_args=[\"-h\", \"--help\"],\n            )\n        )\n        # read a path to a config file from the command line\n        self.general_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"config\",\n                default=\"config.yml\",\n                description_lines=[\n                    \"Path to a config file to read settings from.\",\n                    \"Command line settings will override settings in this file.\",\n                ],\n                cli_args=[\"-c\", \"--config\"],\n            )\n        )\n        self.general_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"generate_config\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        If set, oobabot will print its configuration as a .yml file,\n                        then exit.  Any command-line settings also passed will be\n                        reflected in this file.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.general_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"invite_url\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        Print a URL which can be used to invite the\n                        bot to a Discord server.  Requires that\n                        the Discord token is set.\n                        \"\"\"\n                    ),\n                ],\n                cli_args=[\"--invite-url\"],\n            )\n        )\n\n        ###########################################################\n        # Persona Settings\n\n        self.persona_settings = oesp.ConfigSettingGroup(\"Persona\")\n        self.setting_groups.append(self.persona_settings)\n\n        self.persona_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"ai_name\",\n                default=\"oobabot\",\n                description_lines=[\n                    \"Name the AI will use to refer to itself\",\n                ],\n            )\n        )\n        self.persona_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"persona\",\n                default=os.environ.get(self.OOBABOT_PERSONA_ENV_VAR, \"\"),\n                description_lines=[\n                    textwrap.dedent(\n                        f\"\"\"\n                        This prefix will be added in front of every user-supplied\n                        request.  This is useful for setting up a 'character' for the\n                        bot to play.  Alternatively, this can be set with the\n                        {self.OOBABOT_PERSONA_ENV_VAR} environment variable.\n                        \"\"\"\n                    )\n                ],\n                show_default_in_yaml=False,\n            )\n        )\n        # path to a json or txt file containing persona\n        self.persona_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"persona_file\",\n                default=\"\",\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        Path to a file containing a persona.  This can be just a\n                        single string, a json file in the common \"tavern\" formats,\n                        or a yaml file in the Oobabooga format.\n\n                        With a single string, the persona will be set to that string.\n\n                        Otherwise, the ai_name and persona will be overwritten with\n                        the values in the file.  Also, the wakewords will be\n                        extended to include the character's own name.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n        self.persona_settings.add_setting(\n            oesp.ConfigSetting[typing.List[str]](\n                name=\"wakewords\",\n                default=[\"oobabot\"],\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        One or more words that the bot will listen for.\n                        The bot will listen in all discord channels it can\n                        access for one of these words to be mentioned, then reply\n                        to any messages it sees with a matching word.\n                        The bot will always reply to @-mentions and\n                        direct messages, even if no wakewords are supplied.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n\n        ###########################################################\n        # Discord Settings\n\n        self.discord_settings = oesp.ConfigSettingGroup(\"Discord\")\n        self.setting_groups.append(self.discord_settings)\n\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"discord_token\",\n                default=os.environ.get(self.DISCORD_TOKEN_ENV_VAR, \"\"),\n                description_lines=[\n                    textwrap.dedent(\n                        f\"\"\"\n                        Token to log into Discord with.  For security purposes\n                        it's strongly recommended that you set this via the\n                        {self.DISCORD_TOKEN_ENV_VAR} environment variable\n                        instead, if possible.\n                        \"\"\"\n                    )\n                ],\n                cli_args=[\"--discord-token\"],\n                show_default_in_yaml=False,\n                place_default_in_yaml=True,\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"dont_split_responses\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        Post the entire response as a single message, rather than\n                        splitting it into separate messages by sentence.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[int](\n                name=\"history_lines\",\n                default=7,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        Number of lines of chat history the AI will see\n                        when generating a response.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"ignore_dms\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        If set, the bot will not respond to direct messages.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        # log level\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"log_level\",\n                default=\"DEBUG\",\n                description_lines=[\n                    \"Set the log level.  Valid values are: \",\n                    \"CRITICAL, ERROR, WARNING, INFO, DEBUG\",\n                ],\n                include_in_argparse=False,\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"reply_in_thread\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        If set, the bot will generate a thread to respond in\n                        if it is not already in one.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[typing.List[str]](\n                name=\"stop_markers\",\n                default=[\n                    \"### End of Transcript ###<|endoftext|>\",\n                    \"<|endoftext|>\",\n                ],\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        A list of strings that will cause the bot to stop\n                        generating a response when encountered.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[int](\n                name=\"stream_responses\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        FEATURE PREVIEW: Stream responses into a single message\n                        as they are generated.\n                        Note: may be janky\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[float](\n                name=\"stream_responses_speed_limit\",\n                default=0.7,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        FEATURE PREVIEW: When streaming responses, cap the\n                        rate at which we send updates to Discord to be no\n                        more than once per this many seconds.\n\n                        This does not guarantee that updates will be sent\n                        this fast.  Only that they will not be sent any\n                        faster than this rate.\n\n                        This is useful because Discord has a rate limit on\n                        how often you can send messages, and if you exceed\n                        it, the updates will suddenly become slow.\n\n                        Example: 0.2 means we will send updates no faster\n                        than 5 times per second.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[int](\n                name=\"unsolicited_channel_cap\",\n                default=3,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        Adds a limit to the number of channels the bot will post\n                        unsolicited messages in at the same time.  This is to\n                        prevent the bot from being too noisy in large servers.\n\n                        When set, only the most recent N channels the bot has\n                        been summoned in will have a chance of receiving an\n                        unsolicited message.  The bot will still respond to\n                        @-mentions and wake words in any channel it can access.\n\n                        Set to 0 to disable this feature.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"disable_unsolicited_replies\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        If set, the bot will not reply to any messages that\n                        do not @-mention it or include a wakeword.\n\n                        If unsolicited replies are disabled, the unsolicited_channel_cap\n                        setting will have no effect.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"discrivener_location\",\n                default=\"\",\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        FEATURE PREVIEW: Path to the Discrivener executable.\n                        Will enable prototype voice integration.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n\n        self.discord_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"discrivener_model_location\",\n                default=\"\",\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        FEATURE PREVIEW: Path to the Discrivener model to\n                        load.  Required if discrivener_location is set.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n        ###########################################################\n        # Oobabooga Settings\n\n        self.oobabooga_settings = oesp.ConfigSettingGroup(\"Oobabooga\")\n        self.setting_groups.append(self.oobabooga_settings)\n\n        self.oobabooga_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"base_url\",\n                default=\"ws://localhost:5005\",\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        Base URL for the oobabooga instance.  This should be\n                        ws://hostname[:port] for plain websocket connections,\n                        or wss://hostname[:port] for websocket connections over TLS.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.oobabooga_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"log_all_the_things\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        Print all AI input and output to STDOUT.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        # get a regex for filtering a message\n        self.oobabooga_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"message_regex\",\n                default=\"\",\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        A regex that will be used to extract message lines\n                        from the AI's output.  The first capture group will\n                        be used as the message.  If this is not set, the\n                        entire output will be used as the message.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.oobabooga_settings.add_setting(\n            oesp.ConfigSetting[oesp.SettingDictType](\n                name=\"request_params\",\n                default=self.OOBABOOGA_DEFAULT_REQUEST_PARAMS,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        A dictionary which will be passed straight through to\n                        Oobabooga on every request.  Feel free to add additional\n                        simple parameters here as Oobabooga's API evolves.\n                        See Oobabooga's documentation for what these parameters\n                        mean.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n                show_default_in_yaml=False,\n                place_default_in_yaml=True,\n            )\n        )\n        self.oobabooga_settings.add_setting(\n            oesp.ConfigSetting[bool](\n                name=\"plugin_auto_start\",\n                default=False,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        When running inside the Oobabooga plugin, automatically\n                        connect to Discord when Oobabooga starts.  This has no effect\n                        when running from the command line.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n            )\n        )\n\n        ###########################################################\n        # Stable Diffusion Settings\n\n        self.stable_diffusion_settings = oesp.ConfigSettingGroup(\"Stable Diffusion\")\n        self.setting_groups.append(self.stable_diffusion_settings)\n\n        self.stable_diffusion_settings.add_setting(\n            oesp.ConfigSetting[typing.List[str]](\n                name=\"image_words\",\n                default=self.DEFAULT_IMAGE_WORDS,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        When one of these words is used in a message, the bot will\n                        generate an image.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.stable_diffusion_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"stable_diffusion_url\",\n                default=\"\",\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        URL for an AUTOMATIC1111 Stable Diffusion server.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.stable_diffusion_settings.add_setting(\n            oesp.ConfigSetting[str](\n                name=\"extra_prompt_text\",\n                default=\"\",\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        This will be appended to every image generation prompt\n                        sent to Stable Diffusion.\n                        \"\"\"\n                    )\n                ],\n            )\n        )\n        self.stable_diffusion_settings.add_setting(\n            oesp.ConfigSetting[oesp.SettingDictType](\n                name=\"request_params\",\n                default=self.DEFAULT_SD_REQUEST_PARAMS,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        A dictionary which will be passed straight through to\n                        Stable Diffusion on every request.  Feel free to add additional\n                        simple parameters here as Stable Diffusion's API evolves.\n                        See Stable Diffusion's documentation for what these parameters\n                        mean.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n                show_default_in_yaml=False,\n                place_default_in_yaml=True,\n            )\n        )\n        self.stable_diffusion_settings.add_setting(\n            oesp.ConfigSetting[list](\n                name=\"user_override_params\",\n                default=self.DEFAULT_SD_USER_OVERRIDE_PARAMS,\n                description_lines=[\n                    textwrap.dedent(\n                        \"\"\"\n                        These parameters can be overridden by the Discord user\n                        by including them in their image generation request.\n\n                        The format for this is: param_name=value\n\n                        This is a whitelist of parameters that can be overridden.\n                        They must be simple parameters (strings, numbers, booleans),\n                        and they must be in the request_params dictionary.\n\n                        The value the user inputs will be checked against the type\n                        from the request_params dictionary, and if it doesn't match,\n                        the default value will be used instead.\n\n                        Otherwise, this value will be passed through to Stable\n                        Diffusion without any changes, so be mindful of what you allow\n                        here.  It could potentially be used to inject malicious\n                        values into your SD server.\n\n                        For example, steps=1000000 could be bad for your server.\n                        \"\"\"\n                    )\n                ],\n                include_in_argparse=False,\n                show_default_in_yaml=False,\n                place_default_in_yaml=True,\n            )\n        )\n\n        ###########################################################\n        # Template Settings\n\n        self.template_settings = oesp.ConfigSettingGroup(\n            \"Template\",\n            description=\"UI and AI request templates\",\n            include_in_argparse=False,\n        )\n        self.setting_groups.append(self.template_settings)\n\n        for template, tokens_desc_tuple in templates.TemplateStore.TEMPLATES.items():\n            _, _, is_ai_prompt = tokens_desc_tuple\n\n            self.template_settings.add_setting(\n                oesp.ConfigSetting[str](\n                    name=str(template),\n                    default=templates.TemplateStore.DEFAULT_TEMPLATES[template],\n                    description_lines=_make_template_comment(tokens_desc_tuple),\n                    include_in_yaml=is_ai_prompt,\n                )\n            )\n\n    META_INSTRUCTION = (\n        \"\\n\\n\"\n        + \"# \" * 30\n        + textwrap.dedent(\n            \"\"\"\n            # Please save this output into ./config.yml\n            # edit it to your liking, then run the bot again.\n            #\n            #  e.g. oobabot --generate-config > config.yml\n            #       oobabot\n            \"\"\"\n        )\n    )\n\n    def write_to_stream(self, out_stream) -> None:\n        oesp.write_to_stream(self.setting_groups, out_stream)\n\n    def write_to_file(self, filename: str) -> None:\n        oesp.write_to_file(self.setting_groups, filename)\n\n    def _filename_from_args(self, args: typing.List[str]) -> typing.Tuple[str, bool]:\n        \"\"\"\n        Get the configuration filename from the command line arguments.\n        If none is supplied, return the default.\n\n        Returns a tuple with the file to open, and True if it came\n        from the default, rather than a CLI argument.\n        \"\"\"\n\n        # we need to hack this in here because we want to know the filename\n        # before we parse the args, so that we can load the config file\n        # first and then have the arguments overwrite the config file.\n        config_setting = self.general_settings.get_setting(\"config\")\n        if args is not None:\n            for config_flag in config_setting.cli_args:\n                # find the element after config_flag in args\n                try:\n                    return (args[args.index(config_flag) + 1], False)\n                except (ValueError, IndexError):\n                    continue\n        return (config_setting.default, True)\n\n    def load_from_yaml_stream(self, stream: typing.TextIO) -> typing.Optional[str]:\n        \"\"\"\n        Load the config from a YAML stream.\n\n        params:\n            stream: stream to load the config from\n\n        returns:\n            None if the config was loaded successfully, otherwise a string\n            containing an error message.\n        \"\"\"\n        return oesp.load_from_yaml_stream(stream, setting_groups=self.setting_groups)\n\n    def load(\n        self,\n        cli_args: typing.List[str],\n        config_file: typing.Optional[str] = None,\n        running_from_cli: bool = False,\n    ) -> None:\n        \"\"\"\n        Load the config from the command line arguments and config file.\n\n        params:\n            cli_args: list of command line arguments to parse\n            config_file: path to the config file to load\n\n        cli_args is intended to be used when running from a standalone\n        application, while config_file is intended to be used when\n        running from inside another process.\n\n        raises SettingsError if a specific configuration file\n        was requested (either by the config_file argument or the CLI),\n        but it could not be found.\n        \"\"\"\n\n        is_default = False\n        if config_file is None:\n            config_file, is_default = self._filename_from_args(cli_args)\n        raise_if_file_missing = not is_default and running_from_cli\n\n        try:\n            self.arg_parser = oesp.load(\n                cli_args=cli_args,\n                setting_groups=self.setting_groups,\n                config_file=config_file,\n                raise_if_file_missing=raise_if_file_missing,\n            )\n        except oesp.ConfigFileMissingError as err:\n            # get full path to config_file\n            config_file = os.path.abspath(config_file)\n            msg = f\"Could not load config file at: {config_file}\"\n            raise SettingsError(msg, err) from err\n\n    def print_help(self):\n        \"\"\"\n        Prints CLI usage information to STDOUT.\n        \"\"\"\n        if self.arg_parser is None:\n            raise ValueError(\"display_help called before load\")\n\n        help_str = self.arg_parser.format_help()\n        print(help_str)\n\n        print(\n            \"\\n\"\n            + _console_wrapped(\n                (\n                    \"Additional settings can be set in config.yml.  \"\n                    \"Use the --generate-config option to print a new \"\n                    \"copy of this file to STDOUT.\"\n                )\n            )\n        )\n\n        if \"\" == self.discord_settings.get(\"discord_token\"):\n            print(\n                \"\\n\"\n                + _console_wrapped(\n                    (\n                        f\"Please set the '{self.DISCORD_TOKEN_ENV_VAR}' \"\n                        \"environment variable to your bot's discord token.\"\n                    )\n                )\n            )", ""]}
{"filename": "src/oobabot/__main__.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nPackage entrypoint\n\"\"\"\n\nfrom . import oobabot\n\nif __name__ == \"__main__\":\n    oobabot.main()\n", ""]}
{"filename": "src/oobabot/types.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nGeneric types for messages, used to abstract away\nDiscord-specific types from the rest of the code.\n\"\"\"\nimport abc\nimport datetime\nimport enum\nimport typing\n", "import typing\n\n\nclass GenericMessage:\n    \"\"\"\n    Represents a message from a user.\n    \"\"\"\n\n    def __init__(\n        self,\n        author_id: int,\n        author_name: str,\n        channel_id: int,\n        channel_name: str,\n        message_id: int,\n        reference_message_id,\n        body_text: str,\n        author_is_bot: bool,\n        send_timestamp: float,\n    ):\n        self.author_id = author_id\n        self.author_name = author_name\n        self.message_id = message_id\n        self.body_text = body_text\n        self.author_is_bot = author_is_bot\n        self.reference_message_id = reference_message_id\n        self.send_timestamp = send_timestamp\n        self.channel_id = channel_id\n        self.channel_name = channel_name\n\n    def is_empty(self) -> bool:\n        return not self.body_text.strip()", "\n\nclass DirectMessage(GenericMessage):\n    \"\"\"\n    Represents a message sent directly to the bot.\n    \"\"\"\n\n\nclass ChannelMessage(GenericMessage):\n    \"\"\"\n    Represents a message sent in a channel, including\n    a private group chat or thread.\n    \"\"\"\n\n    def __init__(\n        self,\n        /,\n        mentions: typing.List[int],\n        **kwargs,\n    ):\n        super().__init__(**kwargs)  # type: ignore\n        self.mentions = mentions\n\n    def is_mentioned(self, user_id: int) -> bool:\n        return user_id in self.mentions", "class ChannelMessage(GenericMessage):\n    \"\"\"\n    Represents a message sent in a channel, including\n    a private group chat or thread.\n    \"\"\"\n\n    def __init__(\n        self,\n        /,\n        mentions: typing.List[int],\n        **kwargs,\n    ):\n        super().__init__(**kwargs)  # type: ignore\n        self.mentions = mentions\n\n    def is_mentioned(self, user_id: int) -> bool:\n        return user_id in self.mentions", "\n\nclass FancyAuthor:\n    \"\"\"\n    Display information about the author of a message.\n    \"\"\"\n\n    def __init__(\n        self,\n        user_id: int,\n        author_is_bot: bool,\n        author_name: str,\n        author_accent_color: typing.Tuple[int, int, int],\n        author_avatar_url: typing.Optional[str],\n    ):\n        self._user_id = user_id\n        self._author_is_bot = author_is_bot\n        self._author_name = author_name\n        self._author_accent_color = author_accent_color\n        self._author_avatar_url = author_avatar_url\n\n    @property\n    def user_id(self) -> int:\n        \"\"\"\n        Returns the ID of the user who sent the message.\n        \"\"\"\n        return self._user_id\n\n    @property\n    def author_is_bot(self) -> bool:\n        \"\"\"\n        Returns whether the user who sent the message is a bot.\n        \"\"\"\n        return self._author_is_bot\n\n    @property\n    def author_name(self) -> str:\n        \"\"\"\n        Returns the name of the user who sent the message.\n        \"\"\"\n        return self._author_name\n\n    @property\n    def author_accent_color(self) -> typing.Tuple[int, int, int]:\n        \"\"\"\n        Returns the accent color of the user who sent the message.\n        \"\"\"\n        return self._author_accent_color\n\n    @property\n    def author_avatar_url(self) -> typing.Optional[str]:\n        \"\"\"\n        Returns the avatar URL of the user who sent the message,\n        if the user has chosen one.\n\n        Will be null if the user has not set an avatar.\n        \"\"\"\n        return self._author_avatar_url", "\n\nclass DiscrivenerMessageType(str, enum.Enum):\n    \"\"\"\n    Enumerates the different types of Discrivener messages.\n    \"\"\"\n\n    CHANNEL_SILENT = \"ChannelSilent\"\n    CONNECT = \"Connect\"\n    DISCONNECT = \"Disconnect\"\n    RECONNECT = \"Reconnect\"\n    TRANSCRIPTION = \"Transcription\"\n    USER_JOIN = \"UserJoin\"\n    USER_LEAVE = \"UserLeave\"", "\n\nclass DiscrivenerMessage(abc.ABC):\n    \"\"\"\n    Base class for all Discrivener messages.\n    \"\"\"\n\n    @abc.abstractmethod\n    def __init__(self, message: dict):\n        ...\n\n    type: DiscrivenerMessageType", "\n\n# not an actual GenericMessage, but still a message\nclass VoiceMessage(DiscrivenerMessage):\n    \"\"\"\n    Represents a message that we have transcribed\n    from a voice channel, attributed to a user.\n    \"\"\"\n\n    def __init__(\n        self,\n        user_id: int,\n        start_time: datetime.datetime,\n        duration: datetime.timedelta,\n    ):\n        self._user_id = user_id\n        self._start_time = start_time\n        self._audio_duration = duration\n\n    @property\n    def user_id(self) -> int:\n        \"\"\"\n        Returns the user ID of the user who sent the message.\n        \"\"\"\n        return self._user_id\n\n    @property\n    def start_time(self) -> datetime.datetime:\n        \"\"\"\n        Returns the start time of the transcription.\n        \"\"\"\n        return self._start_time\n\n    @property\n    def duration(self) -> datetime.timedelta:\n        \"\"\"\n        Returns the duration of the transcription.\n        \"\"\"\n        return self._audio_duration\n\n    @property\n    @abc.abstractmethod\n    def text(self) -> str:\n        \"\"\"\n        Returns the text of the transcription.\n        \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def is_bot(self) -> bool:\n        \"\"\"\n        Returns whether the user who sent the message is a bot.\n        \"\"\"", "\n\nclass VoiceMessageWithTokens(VoiceMessage):\n    \"\"\"\n    A voice message that can be broken down into tokens.\n    \"\"\"\n\n    @property\n    @abc.abstractmethod\n    def tokens_with_confidence(self) -> typing.List[typing.Tuple[str, int]]:\n        \"\"\"\n        Returns the tokens of the transcription, with confidence scores.\n        \"\"\"", ""]}
{"filename": "src/oobabot/http_client.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nPurpose: Provides a base class for HTTP clients that limits the number\nof connections to a single host to one, so that we don't overwhelm the\nserver.\n\nThis is a workaround for the fact that Oobabooga, at the time of writing,\ncould not support multiple pending requests at the same time without failing.\n\"\"\"\n", "\"\"\"\n\nimport abc\nimport asyncio\nimport socket\n\nimport aiohttp\n\n\nclass OobaHttpClientError(Exception):\n    \"\"\"\n    Purpose: Exception class for OobaHttpClient\n    \"\"\"", "\nclass OobaHttpClientError(Exception):\n    \"\"\"\n    Purpose: Exception class for OobaHttpClient\n    \"\"\"\n\n\nclass SerializedHttpClient(abc.ABC):\n    \"\"\"\n    Purpose: Limits the number of connections to a single host\n    to one, so that we don't overwhelm the server.\n    \"\"\"\n\n    HTTP_CLIENT_TIMEOUT_SECONDS: aiohttp.ClientTimeout = aiohttp.ClientTimeout(\n        total=None,\n        connect=None,\n        sock_connect=5.0,\n        sock_read=None,\n    )\n\n    @abc.abstractmethod\n    async def _setup(self):\n        # it's ok to raise an exception here, it will be caught\n        ...\n\n    async def setup(self):\n        \"\"\"\n        Attempt to connect to the server.\n\n        Returns:\n            nothing, if the connection test was successful\n\n        Raises:\n            OobaHttpClientError, if the connection fails\n        \"\"\"\n        try:\n            await self._setup()\n        except (\n            aiohttp.ClientConnectionError,\n            aiohttp.ClientError,\n            ConnectionRefusedError,\n            socket.gaierror,\n            asyncio.exceptions.TimeoutError,\n        ) as err:\n            raise OobaHttpClientError(\n                f\"Could not connect to {self.service_name} server: [{self.base_url}]\"\n            ) from err\n\n    def __init__(self, service_name: str, base_url: str):\n        self.service_name = service_name\n        self.base_url = base_url\n        self._session = None\n\n    def _get_session(self) -> aiohttp.ClientSession:\n        \"\"\"\n        Returns: the session, if it exists\n        Raises: OobaHttpClientError if the session does not exist.\n        \"\"\"\n        if not self._session:\n            raise OobaHttpClientError(\"Session not initialized\")\n        return self._session\n\n    async def __aenter__(self):\n        connector = aiohttp.TCPConnector(limit_per_host=1)\n        self._session = aiohttp.ClientSession(\n            base_url=self.base_url,\n            connector=connector,\n            timeout=self.HTTP_CLIENT_TIMEOUT_SECONDS,\n        )\n        return self\n\n    async def __aexit__(self, *_err):\n        if self._session:\n            await self._session.close()\n        self._session = None\n\n    def test_connection(self) -> None:\n        async def try_setup():\n            async with self:\n                await self.setup()\n\n        try:\n            asyncio.run(try_setup())\n        except AssertionError as err:\n            # asyncio will throw an AssertionError if we try to run\n            # with a base_url that has a path.  This is a user-supplied\n            # value, so catching this is grody but necessary.\n            raise OobaHttpClientError(\n                f\"Could not connect to {self.service_name} server: [{self.base_url}]\"\n            ) from err", ""]}
{"filename": "src/oobabot/discrivener.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nDiscrivener process launcher and handler.  Receives and\nparses messages from the Discrivener process and passes\nthem to the handler.\n\"\"\"\n\nimport asyncio\nimport json\nimport pathlib", "import json\nimport pathlib\nimport signal\nimport typing\n\nfrom oobabot import discrivener_message\nfrom oobabot import fancy_logger\nfrom oobabot import types\n\n\nclass Discrivener:\n    \"\"\"\n    Launches and handles the Discrivener process.\n    \"\"\"\n\n    KILL_TIMEOUT: float = 2.0\n\n    # pylint: disable=R1732\n    def __init__(\n        self,\n        discrivener_location: str,\n        discrivener_model_location: str,\n        handler: typing.Callable[[\"types.DiscrivenerMessage\"], None],\n        log_file: typing.Optional[str] = None,\n    ):\n        self._discrivener_location = pathlib.Path(discrivener_location).expanduser()\n        self._discrivener_model_location = pathlib.Path(\n            discrivener_model_location\n        ).expanduser()\n        self._handler: typing.Callable[[\"types.DiscrivenerMessage\"], None] = handler\n        self._process: typing.Optional[\"asyncio.subprocess.Process\"] = None\n        self._stderr_reading_task: typing.Optional[asyncio.Task] = None\n        self._stdout_reading_task: typing.Optional[asyncio.Task] = None\n        if log_file is not None:\n            self._log_file = open(log_file, \"a\", encoding=\"utf-8\")\n        else:\n            self._log_file = None\n\n    # pylint: enable=R1732\n\n    async def run(\n        self,\n        channel_id: int,\n        endpoint: str,\n        guild_id: int,\n        session_id: str,\n        user_id: int,\n        voice_token: str,\n    ):\n        if self.is_running():\n            raise RuntimeError(\"Already running\")\n\n        args = (\n            \"--channel-id\",\n            str(channel_id),\n            \"--endpoint\",\n            endpoint,\n            \"--guild-id\",\n            str(guild_id),\n            \"--session-id\",\n            session_id,\n            \"--user-id\",\n            str(user_id),\n            \"--voice-token\",\n            voice_token,\n            str(self._discrivener_model_location),\n        )\n        await self._launch_process(args)\n\n    async def stop(self):\n        if self.is_running():\n            await self._kill_process()\n\n    def is_running(self):\n        return self._process is not None\n\n    async def _launch_process(self, args: typing.Tuple[str, ...]):\n        fancy_logger.get().info(\n            \"Launching Discrivener process: %s\", self._discrivener_location\n        )\n        fancy_logger.get().debug(\n            \"Using Discrivener model file: %s\", self._discrivener_model_location\n        )\n\n        self._process = await asyncio.create_subprocess_exec(\n            self._discrivener_location,\n            *args,\n            stdin=asyncio.subprocess.PIPE,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n        )\n        fancy_logger.get().info(\n            \"Discrivener process started, PID: %d\", self._process.pid\n        )\n\n        self._stderr_reading_task = asyncio.create_task(self._read_stderr())\n        self._stdout_reading_task = asyncio.create_task(self._read_stdout())\n\n    async def _kill_process(self):\n        if self._process is None:\n            return\n        self._process.send_signal(signal.SIGINT)\n        try:\n            await asyncio.wait_for(self._process.wait(), timeout=self.KILL_TIMEOUT)\n            fancy_logger.get().info(\n                \"Discrivener process (PID %d) stopped gracefully\", self._process.pid\n            )\n\n        except asyncio.TimeoutError:\n            fancy_logger.get().warning(\n                \"Discrivener process (PID %d) did not exit after %d seconds, killing\",\n                self._process.pid,\n                self.KILL_TIMEOUT,\n            )\n            self._process.kill()\n            await asyncio.wait_for(self._process.wait(), timeout=self.KILL_TIMEOUT)\n            fancy_logger.get().warning(\n                \"Discrivener process (PID %d) force-killed\", self._process.pid\n            )\n        finally:\n            self._process = None\n            if self._stderr_reading_task is not None:\n                self._stderr_reading_task.cancel()\n            if self._stdout_reading_task is not None:\n                self._stdout_reading_task.cancel()\n\n        # terminate stdout and stderr reading tasks\n        if self._stderr_reading_task is not None:\n            await asyncio.wait_for(self._stderr_reading_task, timeout=self.KILL_TIMEOUT)\n            self._stderr_reading_task = None\n\n        if self._stdout_reading_task is not None:\n            await asyncio.wait_for(self._stdout_reading_task, timeout=self.KILL_TIMEOUT)\n            self._stdout_reading_task = None\n\n    # @fancy_logger.log_async_task\n    async def _read_stdout(self):\n        while True:\n            try:\n                if self._process is None or self._process.stdout is None:\n                    fancy_logger.get().debug(\n                        \"Discrivener stdout reader: _process went away, exiting\"\n                    )\n                    break\n                line_bytes = await self._process.stdout.readuntil()\n            except asyncio.IncompleteReadError:\n                break\n            line = line_bytes.decode(\"utf-8\").strip()\n\n            if self._log_file is not None:\n                try:\n                    self._log_file.write(line + \"\\n\")\n                except (IOError, OSError) as err:\n                    fancy_logger.get().warning(\n                        \"transcript: failed to log to file: %s\", err\n                    )\n            try:\n                message = json.loads(\n                    line,\n                    object_pairs_hook=discrivener_message.object_pairs_hook,\n                )\n                self._handler(message)\n            except json.JSONDecodeError:\n                fancy_logger.get().error(\"Discrivener: could not parse %s\", line)\n\n        fancy_logger.get().info(\"Discrivener stdout reader exited\")\n\n    # @fancy_logger.log_async_task\n    async def _read_stderr(self):\n        print(\"reading stderr\")\n        # loop until EOF, printing everything to stderr\n        while True:\n            try:\n                if self._process is None or self._process.stderr is None:\n                    fancy_logger.get().debug(\n                        \"Discrivener stderr reader: _process went away, exiting\"\n                    )\n                    break\n                line_bytes = await self._process.stderr.readuntil()\n            except asyncio.IncompleteReadError:\n                break\n            line = line_bytes.decode(\"utf-8\").strip()\n            if (\n                \"whisper_init_state: \" in line\n                or \"whisper_init_from_file_no_state: \" in line\n                or \"whisper_model_load: \" in line\n            ):\n                # workaround nonsense noise in whisper.cpp\n                continue\n            fancy_logger.get().error(\"Discrivener: %s\", line)\n\n        fancy_logger.get().info(\"Discrivener stderr reader exited\")\n\n    def speak(self, text: str):\n        if self._process is None or self._process.stdin is None:\n            fancy_logger.get().error(\"Discrivener: _process is not running\")\n            return\n\n        self._process.stdin.write(text.encode(\"utf-8\") + b\"\\n\")", "\n\nclass Discrivener:\n    \"\"\"\n    Launches and handles the Discrivener process.\n    \"\"\"\n\n    KILL_TIMEOUT: float = 2.0\n\n    # pylint: disable=R1732\n    def __init__(\n        self,\n        discrivener_location: str,\n        discrivener_model_location: str,\n        handler: typing.Callable[[\"types.DiscrivenerMessage\"], None],\n        log_file: typing.Optional[str] = None,\n    ):\n        self._discrivener_location = pathlib.Path(discrivener_location).expanduser()\n        self._discrivener_model_location = pathlib.Path(\n            discrivener_model_location\n        ).expanduser()\n        self._handler: typing.Callable[[\"types.DiscrivenerMessage\"], None] = handler\n        self._process: typing.Optional[\"asyncio.subprocess.Process\"] = None\n        self._stderr_reading_task: typing.Optional[asyncio.Task] = None\n        self._stdout_reading_task: typing.Optional[asyncio.Task] = None\n        if log_file is not None:\n            self._log_file = open(log_file, \"a\", encoding=\"utf-8\")\n        else:\n            self._log_file = None\n\n    # pylint: enable=R1732\n\n    async def run(\n        self,\n        channel_id: int,\n        endpoint: str,\n        guild_id: int,\n        session_id: str,\n        user_id: int,\n        voice_token: str,\n    ):\n        if self.is_running():\n            raise RuntimeError(\"Already running\")\n\n        args = (\n            \"--channel-id\",\n            str(channel_id),\n            \"--endpoint\",\n            endpoint,\n            \"--guild-id\",\n            str(guild_id),\n            \"--session-id\",\n            session_id,\n            \"--user-id\",\n            str(user_id),\n            \"--voice-token\",\n            voice_token,\n            str(self._discrivener_model_location),\n        )\n        await self._launch_process(args)\n\n    async def stop(self):\n        if self.is_running():\n            await self._kill_process()\n\n    def is_running(self):\n        return self._process is not None\n\n    async def _launch_process(self, args: typing.Tuple[str, ...]):\n        fancy_logger.get().info(\n            \"Launching Discrivener process: %s\", self._discrivener_location\n        )\n        fancy_logger.get().debug(\n            \"Using Discrivener model file: %s\", self._discrivener_model_location\n        )\n\n        self._process = await asyncio.create_subprocess_exec(\n            self._discrivener_location,\n            *args,\n            stdin=asyncio.subprocess.PIPE,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n        )\n        fancy_logger.get().info(\n            \"Discrivener process started, PID: %d\", self._process.pid\n        )\n\n        self._stderr_reading_task = asyncio.create_task(self._read_stderr())\n        self._stdout_reading_task = asyncio.create_task(self._read_stdout())\n\n    async def _kill_process(self):\n        if self._process is None:\n            return\n        self._process.send_signal(signal.SIGINT)\n        try:\n            await asyncio.wait_for(self._process.wait(), timeout=self.KILL_TIMEOUT)\n            fancy_logger.get().info(\n                \"Discrivener process (PID %d) stopped gracefully\", self._process.pid\n            )\n\n        except asyncio.TimeoutError:\n            fancy_logger.get().warning(\n                \"Discrivener process (PID %d) did not exit after %d seconds, killing\",\n                self._process.pid,\n                self.KILL_TIMEOUT,\n            )\n            self._process.kill()\n            await asyncio.wait_for(self._process.wait(), timeout=self.KILL_TIMEOUT)\n            fancy_logger.get().warning(\n                \"Discrivener process (PID %d) force-killed\", self._process.pid\n            )\n        finally:\n            self._process = None\n            if self._stderr_reading_task is not None:\n                self._stderr_reading_task.cancel()\n            if self._stdout_reading_task is not None:\n                self._stdout_reading_task.cancel()\n\n        # terminate stdout and stderr reading tasks\n        if self._stderr_reading_task is not None:\n            await asyncio.wait_for(self._stderr_reading_task, timeout=self.KILL_TIMEOUT)\n            self._stderr_reading_task = None\n\n        if self._stdout_reading_task is not None:\n            await asyncio.wait_for(self._stdout_reading_task, timeout=self.KILL_TIMEOUT)\n            self._stdout_reading_task = None\n\n    # @fancy_logger.log_async_task\n    async def _read_stdout(self):\n        while True:\n            try:\n                if self._process is None or self._process.stdout is None:\n                    fancy_logger.get().debug(\n                        \"Discrivener stdout reader: _process went away, exiting\"\n                    )\n                    break\n                line_bytes = await self._process.stdout.readuntil()\n            except asyncio.IncompleteReadError:\n                break\n            line = line_bytes.decode(\"utf-8\").strip()\n\n            if self._log_file is not None:\n                try:\n                    self._log_file.write(line + \"\\n\")\n                except (IOError, OSError) as err:\n                    fancy_logger.get().warning(\n                        \"transcript: failed to log to file: %s\", err\n                    )\n            try:\n                message = json.loads(\n                    line,\n                    object_pairs_hook=discrivener_message.object_pairs_hook,\n                )\n                self._handler(message)\n            except json.JSONDecodeError:\n                fancy_logger.get().error(\"Discrivener: could not parse %s\", line)\n\n        fancy_logger.get().info(\"Discrivener stdout reader exited\")\n\n    # @fancy_logger.log_async_task\n    async def _read_stderr(self):\n        print(\"reading stderr\")\n        # loop until EOF, printing everything to stderr\n        while True:\n            try:\n                if self._process is None or self._process.stderr is None:\n                    fancy_logger.get().debug(\n                        \"Discrivener stderr reader: _process went away, exiting\"\n                    )\n                    break\n                line_bytes = await self._process.stderr.readuntil()\n            except asyncio.IncompleteReadError:\n                break\n            line = line_bytes.decode(\"utf-8\").strip()\n            if (\n                \"whisper_init_state: \" in line\n                or \"whisper_init_from_file_no_state: \" in line\n                or \"whisper_model_load: \" in line\n            ):\n                # workaround nonsense noise in whisper.cpp\n                continue\n            fancy_logger.get().error(\"Discrivener: %s\", line)\n\n        fancy_logger.get().info(\"Discrivener stderr reader exited\")\n\n    def speak(self, text: str):\n        if self._process is None or self._process.stdin is None:\n            fancy_logger.get().error(\"Discrivener: _process is not running\")\n            return\n\n        self._process.stdin.write(text.encode(\"utf-8\") + b\"\\n\")", ""]}
{"filename": "src/oobabot/response_stats.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nPurpose: collects timing and rate statistics for the bot's responses\n\"\"\"\n\nimport time\nimport typing\n\nfrom oobabot import fancy_logger\n", "from oobabot import fancy_logger\n\n\nclass ResponseStats:\n    \"\"\"\n    Purpose: collects timing and rate statistics for a single response\n    \"\"\"\n\n    def __init__(self, fn_get_total_tokens: typing.Callable[[], int], prompt: str):\n        self.fn_get_total_tokens = fn_get_total_tokens\n        self.start_time = time.time()\n        self.start_tokens = fn_get_total_tokens()\n        self.duration = 0\n        self.latency = 0\n        self.tokens = 0\n        self.prompt_len = len(prompt)\n\n    def log_response_part(self) -> None:\n        \"\"\"\n        Call this each time the response is updated by the AI.\n        \"\"\"\n\n        now = time.time()\n        if not self.latency:\n            self.latency = now - self.start_time\n        self.duration = now - self.start_time\n        self.tokens = self.fn_get_total_tokens() - self.start_tokens\n\n    def tokens_per_second(self) -> float:\n        \"\"\"\n        Returns the rate at which tokens were generated, in tokens per second.\n        \"\"\"\n        if not self.duration:\n            return 0\n        return self.tokens / self.duration\n\n    def write_to_log(self, log_prefix: str) -> None:\n        \"\"\"\n        This writes the statistics for this specific\n        request to the log.\n        \"\"\"\n        fancy_logger.get().debug(\n            log_prefix\n            + f\"tokens: {self.tokens}, \"\n            + f\"time: {self.duration:.2f}s, \"\n            + f\"latency: {self.latency:.2f}s, \"\n            + f\"rate: {self.tokens_per_second():.2f} tok/s\"\n        )", "\n\nclass AggregateResponseStats:\n    \"\"\"\n    Purpose: collects timing and rate statistics for all AggregateResponseStats\n    \"\"\"\n\n    def __init__(self, fn_get_total_tokens: typing.Callable[[], int]):\n        self.total_requests_received = 0\n        self.total_successful_responses = 0\n        self.total_failed_responses = 0\n        self.total_response_time_seconds = 0\n        self.total_response_latency_seconds = 0\n        self.prompt_max_chars = 0\n        self.prompt_min_chars = 0\n        self.prompt_total_chars = 0\n        self.fn_get_total_tokens = fn_get_total_tokens\n\n    def log_request_arrived(self, prompt) -> ResponseStats:\n        \"\"\"\n        Call this when a request has arrived.\n        This must be followed by zero or more calls\n        to log_response_part(), and then exactly one call to\n        either log_response_failure() or log_response_success().\n        \"\"\"\n        result = ResponseStats(self.fn_get_total_tokens, prompt)\n\n        self.total_requests_received += 1\n        # update the prompt stats now\n        if self.prompt_max_chars < result.prompt_len:\n            self.prompt_max_chars = result.prompt_len\n        if self.prompt_min_chars > result.prompt_len:\n            self.prompt_min_chars = result.prompt_len\n        self.prompt_total_chars += result.prompt_len\n\n        return result\n\n    def log_response_failure(self) -> None:\n        \"\"\"\n        Track the statistics for a failed response.\n        \"\"\"\n        self.total_failed_responses += 1\n\n    def log_response_success(self, response: ResponseStats) -> None:\n        \"\"\"\n        Track the statistics for a successful response, and\n        averages them into the overall statistics.\n\n        Parameters:\n         - response: the Response object returned\n              by log_request_arrived()\n        \"\"\"\n        self.total_successful_responses += 1\n        self.total_response_time_seconds += response.duration\n        self.total_response_latency_seconds += response.latency\n\n    def error_rate(self) -> float:\n        \"\"\"\n        Returns the percentage of requests that failed.\n        \"\"\"\n        if 0 == self.total_requests_received:\n            return 0.0\n        return 100 * self.total_failed_responses / self.total_requests_received\n\n    def average_response_time(self) -> float:\n        \"\"\"\n        Returns the average response time in seconds.\n        \"\"\"\n        if 0 == self.total_successful_responses:\n            return 0.0\n        return self.total_response_time_seconds / self.total_successful_responses\n\n    def average_response_latency(self) -> float:\n        \"\"\"\n        Returns the average response latency in seconds.\n        \"\"\"\n        if 0 == self.total_successful_responses:\n            return 0.0\n        return self.total_response_latency_seconds / self.total_successful_responses\n\n    def average_tokens_per_second(self) -> float:\n        \"\"\"\n        Returns the average rate at which tokens were generated,\n        in tokens per second.\n        \"\"\"\n        if 0 == self.total_successful_responses:\n            return 0.0\n        if 0.0 == self.total_response_time_seconds:\n            return 0.0\n        return self.fn_get_total_tokens() / self.total_response_time_seconds\n\n    def average_prompt_length(self) -> float:\n        \"\"\"\n        Returns the average prompt length in characters.\n        \"\"\"\n        if 0 == self.total_requests_received:\n            return 0.0\n        return self.prompt_total_chars / self.total_requests_received\n\n    def write_stat_summary_to_log(self) -> None:\n        \"\"\"\n        This writes a summary of the statistics to the log.\n        Call this after all AggregateResponseStats have been handled.\n        \"\"\"\n        if 0 == self.total_requests_received:\n            fancy_logger.get().info(\"No requests handled\")\n            return\n\n        fancy_logger.get().info(\n            f\"Received {self.total_requests_received} request(s), \"\n            + f\"sent {self.total_successful_responses} successful responses \"\n            + f\"and failed to send one {self.total_failed_responses} times(s)\"\n        )\n\n        if self.total_failed_responses > 0:\n            fancy_logger.get().error(\n                \"Error rate:                  %0.2f%%\", self.error_rate()\n            )\n\n        if self.total_successful_responses > 0:\n            fancy_logger.get().debug(\n                \"Average response time:       %6.2fs\", self.average_response_time()\n            )\n            fancy_logger.get().debug(\n                \"Average response latency:    %6.2fs\", self.average_response_latency()\n            )\n            fancy_logger.get().debug(\n                \"Average tokens per response: %6.2f\", self.average_tokens_per_second()\n            )\n\n        if self.total_response_time_seconds > 0:\n            fancy_logger.get().debug(\n                \"Average tokens per second:   %6.2f\", self.average_tokens_per_second()\n            )\n\n        fancy_logger.get().debug(\n            \"Prompt length: \"\n            + f\"max: {self.prompt_max_chars}, \"\n            + f\"min: {self.prompt_min_chars}, \"\n            + f\"avg: {self.average_prompt_length():.2f}\"\n        )", ""]}
{"filename": "src/oobabot/transcript.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nStores a transcript of a voice channel.\n\"\"\"\nimport asyncio\nimport datetime\nimport random\nimport re\nimport typing\n", "import typing\n\nfrom oobabot import discord_utils\nfrom oobabot import discrivener_message\nfrom oobabot import fancy_logger\nfrom oobabot import types\n\n\nclass Transcript:\n    \"\"\"\n    Stores a transcript of a voice channel.\n    \"\"\"\n\n    NUM_LINES = 300\n\n    def __init__(\n        self,\n        bot_user_id: int,\n        wakewords: typing.List[str],\n    ):\n        self._bot_user_id = bot_user_id\n        self._wakewords: typing.Set[str] = set(word.lower() for word in wakewords)\n\n        self.message_buffer = discord_utils.RingBuffer[types.VoiceMessage](\n            self.NUM_LINES\n        )\n        self.silence_event = asyncio.Event()\n        self.wakeword_event = asyncio.Event()\n        self.last_mention = datetime.datetime.min\n\n    def on_bot_response(self, text: str):\n        \"\"\"\n        Adds a bot response to the transcript.\n        \"\"\"\n        self.message_buffer.append(BotVoiceMessage(self._bot_user_id, text))\n\n    def on_transcription(\n        self,\n        message: discrivener_message.UserVoiceMessage,\n    ) -> None:\n        self.message_buffer.append(message)\n\n        # todo: what about wakewords which span segments?\n        wakeword_found = False\n        for word in re.split(r\"[ .,!?\\\"']\", message.text):\n            if word.lower() in self._wakewords:\n                wakeword_found = True\n                break\n\n        now = datetime.datetime.now()\n        if wakeword_found:\n            fancy_logger.get().info(\"transcript: wakeword detected! %s\", message.text)\n            self.last_mention = now\n            self.wakeword_event.set()\n        else:\n            # chance of replying within 5 minutes of last reply\n            seconds_since_mention = (now - self.last_mention).seconds\n            if seconds_since_mention > 2 * 60:\n                chance = 0.05\n            else:\n                chance = 0.95 ** (1 - (seconds_since_mention / 60))\n            # also, divide chance by number of human speakers\n            # in the message history\n            humans = set()\n            for msg in self.message_buffer.get():\n                if not msg.is_bot:\n                    humans.add(msg.user_id)\n            if 1 == len(humans):\n                chance = 1.0\n            else:\n                chance /= 3 * len(humans)\n            fancy_logger.get().debug(\n                \"transcript: chance of replying: %f (+seconds: %d, humans: %d)\",\n                chance,\n                seconds_since_mention,\n                len(humans),\n            )\n            if chance > 0.0 and chance > random.random():\n                self.wakeword_event.set()\n\n    def on_channel_silent(\n        self, activity: discrivener_message.ChannelSilentData\n    ) -> None:\n        if activity.silent:\n            self.silence_event.set()\n        else:\n            self.silence_event.clear()", "class Transcript:\n    \"\"\"\n    Stores a transcript of a voice channel.\n    \"\"\"\n\n    NUM_LINES = 300\n\n    def __init__(\n        self,\n        bot_user_id: int,\n        wakewords: typing.List[str],\n    ):\n        self._bot_user_id = bot_user_id\n        self._wakewords: typing.Set[str] = set(word.lower() for word in wakewords)\n\n        self.message_buffer = discord_utils.RingBuffer[types.VoiceMessage](\n            self.NUM_LINES\n        )\n        self.silence_event = asyncio.Event()\n        self.wakeword_event = asyncio.Event()\n        self.last_mention = datetime.datetime.min\n\n    def on_bot_response(self, text: str):\n        \"\"\"\n        Adds a bot response to the transcript.\n        \"\"\"\n        self.message_buffer.append(BotVoiceMessage(self._bot_user_id, text))\n\n    def on_transcription(\n        self,\n        message: discrivener_message.UserVoiceMessage,\n    ) -> None:\n        self.message_buffer.append(message)\n\n        # todo: what about wakewords which span segments?\n        wakeword_found = False\n        for word in re.split(r\"[ .,!?\\\"']\", message.text):\n            if word.lower() in self._wakewords:\n                wakeword_found = True\n                break\n\n        now = datetime.datetime.now()\n        if wakeword_found:\n            fancy_logger.get().info(\"transcript: wakeword detected! %s\", message.text)\n            self.last_mention = now\n            self.wakeword_event.set()\n        else:\n            # chance of replying within 5 minutes of last reply\n            seconds_since_mention = (now - self.last_mention).seconds\n            if seconds_since_mention > 2 * 60:\n                chance = 0.05\n            else:\n                chance = 0.95 ** (1 - (seconds_since_mention / 60))\n            # also, divide chance by number of human speakers\n            # in the message history\n            humans = set()\n            for msg in self.message_buffer.get():\n                if not msg.is_bot:\n                    humans.add(msg.user_id)\n            if 1 == len(humans):\n                chance = 1.0\n            else:\n                chance /= 3 * len(humans)\n            fancy_logger.get().debug(\n                \"transcript: chance of replying: %f (+seconds: %d, humans: %d)\",\n                chance,\n                seconds_since_mention,\n                len(humans),\n            )\n            if chance > 0.0 and chance > random.random():\n                self.wakeword_event.set()\n\n    def on_channel_silent(\n        self, activity: discrivener_message.ChannelSilentData\n    ) -> None:\n        if activity.silent:\n            self.silence_event.set()\n        else:\n            self.silence_event.clear()", "\n\nclass BotVoiceMessage(types.VoiceMessage):\n    \"\"\"\n    Represents a fake \"transcribed\" message generated by\n    the bot.  This isn't a real transcription, because we got\n    it from the bot, not from Discrivener.  But we're creating\n    a similar object to store it in, so that we can use similar\n    code to store and display it.\n    \"\"\"\n\n    def __init__(\n        self,\n        bot_user_id: int,\n        text: str,\n    ):\n        self._text = text\n        super().__init__(\n            user_id=bot_user_id,\n            start_time=datetime.datetime.now(),\n            duration=datetime.timedelta(seconds=1),\n        )\n\n    @property\n    def text(self) -> str:\n        return self._text\n\n    @property\n    def is_bot(self) -> bool:\n        \"\"\"\n        Returns whether the user is a bot.\n        \"\"\"\n        return True", ""]}
{"filename": "src/oobabot/bot_commands.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nImplementation of the bot's slash commands.\n\"\"\"\nimport typing\n\nimport discord\n\nfrom oobabot import audio_commands\nfrom oobabot import decide_to_respond", "from oobabot import audio_commands\nfrom oobabot import decide_to_respond\nfrom oobabot import discord_utils\nfrom oobabot import fancy_logger\nfrom oobabot import ooba_client\nfrom oobabot import persona\nfrom oobabot import prompt_generator\nfrom oobabot import repetition_tracker\nfrom oobabot import templates\n", "from oobabot import templates\n\n\nclass BotCommands:\n    \"\"\"\n    Implementation of the bot's slash commands.\n    \"\"\"\n\n    def __init__(\n        self,\n        decide_to_respond: decide_to_respond.DecideToRespond,\n        repetition_tracker: repetition_tracker.RepetitionTracker,\n        persona: persona.Persona,\n        discord_settings: dict,\n        template_store: templates.TemplateStore,\n        ooba_client: ooba_client.OobaClient,\n        prompt_generator: prompt_generator.PromptGenerator,\n    ):\n        self.decide_to_respond = decide_to_respond\n        self.repetition_tracker = repetition_tracker\n        self.persona = persona\n        self.reply_in_thread = discord_settings[\"reply_in_thread\"]\n        self.template_store = template_store\n\n        (\n            self.discrivener_location,\n            self.discrivener_model_location,\n        ) = discord_utils.validate_discrivener_locations(\n            discord_settings[\"discrivener_location\"],\n            discord_settings[\"discrivener_model_location\"],\n        )\n\n        if (\n            discord_settings[\"discrivener_location\"]\n            and self.discrivener_location is None\n        ):\n            fancy_logger.get().warning(\n                \"Audio disabled because executable at discrivener_location \"\n                + \"could not be found: %s\",\n                discord_settings[\"discrivener_location\"],\n            )\n\n        if (\n            discord_settings[\"discrivener_model_location\"]\n            and self.discrivener_model_location is None\n        ):\n            fancy_logger.get().warning(\n                \"Audio disable because the discrivener_model_location \"\n                + \"could not be found: %s\",\n                discord_settings[\"discrivener_model_location\"],\n            )\n\n        if self.discrivener_location is None or self.discrivener_model_location is None:\n            self.audio_commands = None\n        else:\n            self.audio_commands = audio_commands.AudioCommands(\n                persona,\n                ooba_client,\n                prompt_generator,\n                self.discrivener_location,\n                self.discrivener_model_location,\n            )\n\n    async def on_ready(self, client: discord.Client):\n        \"\"\"\n        Register commands with Discord.\n        \"\"\"\n\n        async def get_messageable(\n            interaction: discord.Interaction,\n        ) -> (\n            typing.Optional[\n                typing.Union[\n                    discord.TextChannel,\n                    discord.Thread,\n                    discord.DMChannel,\n                    discord.GroupChannel,\n                ]\n            ]\n        ):\n            if interaction.channel_id is not None:\n                # find the current message in this channel\n                # tell the Repetition Tracker to hide messages\n                # before this message\n                channel = await interaction.client.fetch_channel(interaction.channel_id)\n                if channel is not None:\n                    if isinstance(channel, discord.TextChannel):\n                        return channel\n                    if isinstance(channel, discord.Thread):\n                        return channel\n                    if isinstance(channel, discord.DMChannel):\n                        return channel\n                    if isinstance(channel, discord.GroupChannel):\n                        return channel\n            return None\n\n        @discord.app_commands.command(\n            name=\"say\",\n            description=f\"Force {self.persona.ai_name} to say the provided message.\",\n        )\n        @discord.app_commands.rename(text_to_send=\"message\")\n        @discord.app_commands.describe(\n            text_to_send=f\"Message to force {self.persona.ai_name} to say.\"\n        )\n        async def say(interaction: discord.Interaction, text_to_send: str):\n            if interaction.channel_id is None:\n                await discord_utils.fail_interaction(interaction)\n                return\n\n            # if reply_in_thread is True, we don't want our bot to\n            # speak in guild channels, only threads and private messages\n            if self.reply_in_thread:\n                channel = await get_messageable(interaction)\n                if channel is None or isinstance(channel, discord.TextChannel):\n                    await discord_utils.fail_interaction(\n                        interaction, f\"{self.persona.ai_name} may only speak in threads\"\n                    )\n                    return\n\n            fancy_logger.get().debug(\n                \"/say called by user '%s' in channel #%d\",\n                interaction.user.name,\n                interaction.channel_id,\n            )\n            # this will cause the bot to monitor the channel\n            # and consider unsolicited responses\n            self.decide_to_respond.log_mention(\n                channel_id=interaction.channel_id,\n                send_timestamp=interaction.created_at.timestamp(),\n            )\n            await interaction.response.send_message(\n                text_to_send,\n                suppress_embeds=True,\n            )\n\n        @discord.app_commands.command(\n            name=\"lobotomize\",\n            description=f\"Erase {self.persona.ai_name}'s memory of any message \"\n            + \"before now in this channel.\",\n        )\n        async def lobotomize(interaction: discord.Interaction):\n            channel = await get_messageable(interaction)\n            if channel is None:\n                await discord_utils.fail_interaction(interaction)\n                return\n\n            # find the current message in this channel\n            # tell the Repetition Tracker to hide messages\n            # before this message\n            async for message in channel.history(limit=1):\n                channel_name = discord_utils.get_channel_name(channel)\n                fancy_logger.get().info(\n                    \"/lobotomize called by user '%s' in #%s\",\n                    interaction.user.name,\n                    channel_name,\n                )\n                self.repetition_tracker.hide_messages_before(\n                    channel_id=channel.id,\n                    message_id=message.id,\n                )\n\n            response = self.template_store.format(\n                template_name=templates.Templates.COMMAND_LOBOTOMIZE_RESPONSE,\n                format_args={\n                    templates.TemplateToken.AI_NAME: self.persona.ai_name,\n                    templates.TemplateToken.USER_NAME: interaction.user.name,\n                },\n            )\n            await interaction.response.send_message(\n                response,\n                silent=True,\n                suppress_embeds=True,\n            )\n\n        fancy_logger.get().debug(\n            \"Registering commands, sometimes this takes a while...\"\n        )\n\n        tree = discord.app_commands.CommandTree(client)\n        tree.add_command(lobotomize)\n        tree.add_command(say)\n\n        if self.audio_commands is not None:\n            self.audio_commands.add_commands(tree)\n\n        commands = await tree.sync(guild=None)\n        for command in commands:\n            fancy_logger.get().info(\n                \"Registered command: %s: %s\", command.name, command.description\n            )", ""]}
{"filename": "src/oobabot/__init__.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nPackage definition\n\"\"\"\n\n# todo: sync this up automatically\n__version__ = \"0.2.3\"\n"]}
{"filename": "src/oobabot/discord_bot.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nMain bot class.  Contains Discord-specific code that can't\nbe easily extracted into a cross-platform library.\n\"\"\"\n\nimport asyncio\nimport typing\n\nimport discord", "\nimport discord\n\nfrom oobabot import bot_commands\nfrom oobabot import decide_to_respond\nfrom oobabot import discord_utils\nfrom oobabot import fancy_logger\nfrom oobabot import image_generator\nfrom oobabot import ooba_client\nfrom oobabot import persona", "from oobabot import ooba_client\nfrom oobabot import persona\nfrom oobabot import prompt_generator\nfrom oobabot import repetition_tracker\nfrom oobabot import response_stats\nfrom oobabot import types\n\n\nclass DiscordBot(discord.Client):\n    \"\"\"\n    Main bot class.  Connects to Discord, monitors for messages,\n    and dispatches responses.\n    \"\"\"\n\n    def __init__(\n        self,\n        bot_commands: bot_commands.BotCommands,\n        decide_to_respond: decide_to_respond.DecideToRespond,\n        discord_settings: dict,\n        image_generator: typing.Optional[image_generator.ImageGenerator],\n        ooba_client: ooba_client.OobaClient,\n        persona: persona.Persona,\n        prompt_generator: prompt_generator.PromptGenerator,\n        repetition_tracker: repetition_tracker.RepetitionTracker,\n        response_stats: response_stats.AggregateResponseStats,\n    ):\n        self.bot_commands = bot_commands\n        self.decide_to_respond = decide_to_respond\n        self.image_generator = image_generator\n        self.ooba_client = ooba_client\n        self.persona = persona\n        self.prompt_generator = prompt_generator\n        self.repetition_tracker = repetition_tracker\n        self.response_stats = response_stats\n\n        self.ai_user_id = -1\n\n        self.dont_split_responses = discord_settings[\"dont_split_responses\"]\n        self.ignore_dms = discord_settings[\"ignore_dms\"]\n        self.reply_in_thread = discord_settings[\"reply_in_thread\"]\n        self.stop_markers = discord_settings[\"stop_markers\"]\n        self.stream_responses = discord_settings[\"stream_responses\"]\n        self.stream_responses_speed_limit = discord_settings[\n            \"stream_responses_speed_limit\"\n        ]\n\n        # add stopping_strings to stop_markers\n        self.stop_markers.extend(self.ooba_client.get_stopping_strings())\n\n        super().__init__(intents=discord_utils.get_intents())\n\n    async def on_ready(self) -> None:\n        guilds = self.guilds\n        num_guilds = len(guilds)\n        num_channels = sum(len(guild.channels) for guild in guilds)\n\n        if self.user:\n            self.ai_user_id = self.user.id\n            user_id_str = self.user.name\n        else:\n            user_id_str = \"<unknown>\"\n\n        fancy_logger.get().info(\n            \"Connected to discord as %s (ID: %d)\", user_id_str, self.ai_user_id\n        )\n        fancy_logger.get().debug(\n            \"monitoring %d channels across %d server(s)\", num_channels, num_guilds\n        )\n        if self.ignore_dms:\n            fancy_logger.get().debug(\"Ignoring DMs\")\n        else:\n            fancy_logger.get().debug(\"listening to DMs\")\n\n        if self.stream_responses:\n            fancy_logger.get().debug(\n                \"Response Grouping: streamed live into a single message\"\n            )\n        elif self.dont_split_responses:\n            fancy_logger.get().debug(\"Response Grouping: returned as single messages\")\n        else:\n            fancy_logger.get().debug(\n                \"Response Grouping: split into messages by sentence\"\n            )\n\n        fancy_logger.get().debug(\"AI name: %s\", self.persona.ai_name)\n        fancy_logger.get().debug(\"AI persona: %s\", self.persona.persona)\n\n        fancy_logger.get().debug(\n            \"History: %d lines \", self.prompt_generator.history_lines\n        )\n\n        fancy_logger.get().debug(\n            \"Stop markers: %s\", \", \".join(self.stop_markers) or \"<none>\"\n        )\n\n        # log unsolicited_channel_cap\n        cap = self.decide_to_respond.get_unsolicited_channel_cap()\n        cap = str(cap) if cap > 0 else \"<unlimited>\"\n        fancy_logger.get().debug(\n            \"Unsolicited channel cap: %s\",\n            cap,\n        )\n\n        str_wakewords = (\n            \", \".join(self.persona.wakewords) if self.persona.wakewords else \"<none>\"\n        )\n        fancy_logger.get().debug(\"Wakewords: %s\", str_wakewords)\n\n        self.ooba_client.on_ready()\n\n        if self.image_generator is None:\n            fancy_logger.get().debug(\"Stable Diffusion: disabled\")\n        else:\n            self.image_generator.on_ready()\n\n        # we do this at the very end because when you restart\n        # the bot, it can take a while for the commands to\n        # register\n        try:\n            # register the commands\n            await self.bot_commands.on_ready(self)\n        except discord.DiscordException as err:\n            fancy_logger.get().warning(\n                \"Failed to register commands: %s (continuing without commands)\", err\n            )\n\n        # show a warning if the bot is connected to zero guilds,\n        # with a helpful link on how to fix it\n        if num_guilds == 0:\n            fancy_logger.get().warning(\n                \"The bot is not connected to any servers.  \"\n                + \"Please add the bot to a server here:\",\n            )\n            fancy_logger.get().warning(\n                discord_utils.generate_invite_url(self.ai_user_id)\n            )\n\n    async def on_message(self, raw_message: discord.Message) -> None:\n        \"\"\"\n        Called when a message is received from Discord.\n\n        This method is called for every message that the bot can see.\n        It decides whether to respond to the message, and if so,\n        calls _handle_response() to generate a response.\n\n        :param raw_message: The raw message from Discord.\n        \"\"\"\n        try:\n            message = discord_utils.discord_message_to_generic_message(raw_message)\n            should_respond, is_summon = self.decide_to_respond.should_reply_to_message(\n                self.ai_user_id, message\n            )\n            if not should_respond:\n                return\n\n            is_summon_in_public_channel = is_summon and isinstance(\n                message,\n                types.ChannelMessage,\n            )\n\n            async with raw_message.channel.typing():\n                await self._handle_response(\n                    message, raw_message, is_summon_in_public_channel\n                )\n\n        except discord.DiscordException as err:\n            fancy_logger.get().error(\n                \"Exception while processing message: %s\", err, exc_info=True\n            )\n\n    async def _handle_response(\n        self,\n        message: types.GenericMessage,\n        raw_message: discord.Message,\n        is_summon_in_public_channel: bool,\n    ) -> None:\n        \"\"\"\n        Called when we've decided to respond to a message.\n\n        It decides if we're sending a text response, an image response,\n        or both, and then sends the response(s).\n        \"\"\"\n        image_prompt = None\n        if self.image_generator is not None:\n            # are we creating an image?\n            image_prompt = self.image_generator.maybe_get_image_prompt(raw_message)\n\n        result = await self._send_text_response(\n            message=message,\n            raw_message=raw_message,\n            image_requested=image_prompt is not None,\n            is_summon_in_public_channel=is_summon_in_public_channel,\n        )\n        if result is None:\n            # we failed to create a thread that the user could\n            # read our response in, so we're done here.  Abort!\n            return\n        message_task, response_channel = result\n\n        # log the mention, now that we know the channel we\n        # want to monitor later to continue to conversation\n        if isinstance(response_channel, (discord.Thread, discord.abc.GuildChannel)):\n            if is_summon_in_public_channel:\n                self.decide_to_respond.log_mention(\n                    response_channel.id,\n                    message.send_timestamp,\n                )\n\n        image_task = None\n        if self.image_generator is not None and image_prompt is not None:\n            image_task = await self.image_generator.generate_image(\n                image_prompt,\n                raw_message,\n                response_channel=response_channel,\n            )\n\n        response_tasks = [\n            task for task in [message_task, image_task] if task is not None\n        ]\n        await asyncio.wait(response_tasks)\n\n        # there may be more than one exception, so be sure to log\n        # them all before raising either of them\n        raise_later = None\n        for task in response_tasks:\n            if task.exception() is not None:\n                fancy_logger.get().error(\n                    f\"Exception while running {task.get_coro()} \"\n                    + f\"response: {task.exception()}\",\n                    stack_info=True,\n                )\n                raise_later = task.exception()\n        if raise_later is not None:\n            raise raise_later\n\n    async def _send_text_response(\n        self,\n        message: types.GenericMessage,\n        raw_message: discord.Message,\n        image_requested: bool,\n        is_summon_in_public_channel: bool,\n    ) -> typing.Optional[typing.Tuple[asyncio.Task, discord.abc.Messageable]]:\n        \"\"\"\n        Send a text response to a message.\n\n        This method determines what channel or thread to post the message\n        in, creating a thread if necessary.  It then posts the message\n        by calling _send_text_response_to_channel().\n\n        Returns a tuple of the task that was created to send the message,\n        and the channel that the message was sent to.\n\n        If no message was sent, the task and channel will be None.\n        \"\"\"\n        response_channel = raw_message.channel\n        if (\n            self.reply_in_thread\n            and isinstance(raw_message.channel, discord.TextChannel)\n            and isinstance(raw_message.author, discord.Member)\n        ):\n            # we want to create a response thread, if possible\n            # but we have to see if the user has permission to do so\n            # if the user can't we wont respond at all.\n            perms = raw_message.channel.permissions_for(raw_message.author)\n            if perms.create_public_threads:\n                response_channel = await raw_message.create_thread(\n                    name=f\"{self.persona.ai_name}, replying to \"\n                    + f\"{raw_message.author.display_name}\",\n                )\n                fancy_logger.get().debug(\n                    f\"Created response thread {response_channel.name} \"\n                    + f\"({response_channel.id}) \"\n                    + f\"in {raw_message.channel.name}\"\n                )\n            else:\n                # This user can't create threads, so we won't respond.\n                # The reason we don't respond in the channel is that\n                # it can create confusion later if a second user who\n                # DOES have thread-create permission replies to that\n                # message.  We'd end up creating a thread for that\n                # second user's response, and again for a third user,\n                # etc.\n                fancy_logger.get().debug(\"User can't create threads, not responding.\")\n                return None\n\n        response_coro = self._send_text_response_in_channel(\n            message=message,\n            raw_message=raw_message,\n            image_requested=image_requested,\n            is_summon_in_public_channel=is_summon_in_public_channel,\n            response_channel=response_channel,\n            response_channel_id=response_channel.id,\n        )\n        response_task = asyncio.create_task(response_coro)\n        return (response_task, response_channel)\n\n    async def _send_text_response_in_channel(\n        self,\n        message: types.GenericMessage,\n        raw_message: discord.Message,\n        image_requested: bool,\n        is_summon_in_public_channel: bool,\n        response_channel: discord.abc.Messageable,\n        response_channel_id: int,\n    ) -> None:\n        \"\"\"\n        Getting closer now!  This method is what actually gathers message\n        history, queries the AI for a text response, breaks the response\n        into individual messages, and then and then calls\n        __send_response_message() to send sech message.\n        \"\"\"\n        fancy_logger.get().debug(\n            \"Request from %s in %s\", message.author_name, message.channel_name\n        )\n\n        repeated_id = self.repetition_tracker.get_throttle_message_id(\n            response_channel_id\n        )\n\n        # determine if we're responding to a specific message that\n        # summoned us.  If so, find out what message ID that was, so\n        # that we can ignore all messages sent after it (as not to\n        # confuse the AI about what to reply to)\n        reference = None\n        ignore_all_until_message_id = None\n        if is_summon_in_public_channel:\n            # we can't use the message reference if we're starting a new thread\n            if message.channel_id == response_channel_id:\n                reference = raw_message.to_reference()\n            ignore_all_until_message_id = raw_message.id\n\n        recent_messages = await self._recent_messages_following_thread(\n            channel=response_channel,\n            num_history_lines=self.prompt_generator.history_lines,\n            stop_before_message_id=repeated_id,\n            ignore_all_until_message_id=ignore_all_until_message_id,\n        )\n\n        prompt_prefix = await self.prompt_generator.generate(\n            message_history=recent_messages,\n            image_requested=image_requested,\n        )\n\n        this_response_stat = self.response_stats.log_request_arrived(prompt_prefix)\n\n        # restrict the @mentions the AI is allowed to use in its response.\n        # this is to prevent another user from being able to trick the AI\n        # into @-pinging a large group and annoying them.\n        # Only the author of the original message may be @-pinged.\n        allowed_mentions = discord.AllowedMentions(\n            everyone=False,\n            users=[raw_message.author],\n            roles=False,\n        )\n\n        # will be set to true when we abort the response because:\n        #  it was empty\n        #  it repeated a previous response and we're throttling it\n        aborted_by_us = False\n        sent_message_count = 0\n        try:\n            if self.stream_responses:\n                generator = self.ooba_client.request_as_grouped_tokens(\n                    prompt_prefix, interval=self.stream_responses_speed_limit\n                )\n                last_sent_message = await self._render_streaming_response(\n                    generator,\n                    this_response_stat,\n                    response_channel,\n                    response_channel_id,\n                    allowed_mentions,\n                    reference,\n                )\n                if last_sent_message is not None:\n                    sent_message_count = 1\n            else:\n                if self.dont_split_responses:\n                    response = await self.ooba_client.request_as_string(prompt_prefix)\n                    (\n                        last_sent_message,\n                        aborted_by_us,\n                    ) = await self._send_response_message(\n                        response,\n                        this_response_stat,\n                        response_channel,\n                        response_channel_id,\n                        allowed_mentions,\n                        reference,\n                    )\n                    if last_sent_message is not None:\n                        sent_message_count = 1\n                else:\n                    sent_message_count = 0\n                    last_sent_message = None\n                    async for sentence in self.ooba_client.request_by_message(\n                        prompt_prefix\n                    ):\n                        (\n                            sent_message,\n                            abort_response,\n                        ) = await self._send_response_message(\n                            sentence,\n                            this_response_stat,\n                            response_channel,\n                            response_channel_id,\n                            allowed_mentions=allowed_mentions,\n                            reference=reference,\n                        )\n                        if sent_message is not None:\n                            last_sent_message = sent_message\n                            sent_message_count += 1\n                            # only use the reference for the first\n                            # message in a multi-message chain\n                            reference = None\n                        if abort_response:\n                            aborted_by_us = True\n                            break\n\n        except discord.DiscordException as err:\n            fancy_logger.get().error(\"Error: %s\", err, exc_info=True)\n            self.response_stats.log_response_failure()\n            return\n\n        if 0 == sent_message_count:\n            if aborted_by_us:\n                fancy_logger.get().warning(\n                    \"No response sent.  The AI has generated a message that we have \"\n                    + \"chosen not to send, probably because it was empty or repeated.\"\n                )\n            else:\n                fancy_logger.get().warning(\n                    \"An empty response was received from Oobabooga.  Please check that \"\n                    + \"the AI is running properly on the Oobabooga server at %s.\",\n                    self.ooba_client.base_url,\n                )\n            self.response_stats.log_response_failure()\n            return\n\n        this_response_stat.write_to_log(f\"Response to {message.author_name} done!  \")\n        self.response_stats.log_response_success(this_response_stat)\n\n    async def _send_response_message(\n        self,\n        response: str,\n        this_response_stat: response_stats.ResponseStats,\n        response_channel: discord.abc.Messageable,\n        response_channel_id: int,\n        allowed_mentions: discord.AllowedMentions,\n        reference: typing.Optional[discord.MessageReference],\n    ) -> typing.Tuple[typing.Optional[discord.Message], bool]:\n        \"\"\"\n        Given a string that represents an individual response message,\n        post it in the given channel.\n\n        It also looks to see if a message contains a termination string,\n        and if so it will return False to indicate that we should stop\n        the response.\n\n        Also does some bookkeeping to make sure we don't repeat ourselves,\n        and to track how many messages we've sent.\n\n        Returns a tuple with:\n        - the sent discord message, if any\n        - a boolean indicating if we need to abort the response entirely\n        \"\"\"\n        (sentence, abort_response) = self._filter_immersion_breaking_lines(response)\n        if abort_response:\n            return (None, True)\n        if not sentence:\n            # we can't send an empty message\n            return (None, False)\n\n        response_message = await response_channel.send(\n            sentence,\n            allowed_mentions=allowed_mentions,\n            suppress_embeds=True,\n            reference=reference,  # type: ignore\n        )\n        self.repetition_tracker.log_message(\n            response_channel_id,\n            discord_utils.discord_message_to_generic_message(response_message),\n        )\n\n        this_response_stat.log_response_part()\n        return (response_message, False)\n\n    async def _render_streaming_response(\n        self,\n        response_iterator: typing.AsyncIterator[str],\n        this_response_stat: response_stats.ResponseStats,\n        response_channel: discord.abc.Messageable,\n        response_channel_id: int,\n        allowed_mentions: discord.AllowedMentions,\n        reference: typing.Optional[discord.MessageReference],\n    ) -> typing.Optional[discord.Message]:\n        response = \"\"\n        last_message = None\n        async for token in response_iterator:\n            if \"\" == token:\n                continue\n\n            response += token\n            (response, abort_response) = self._filter_immersion_breaking_lines(response)\n\n            # if we are aborting a response, we want to at least post\n            # the valid parts, so don't abort quite yet.\n\n            if last_message is None:\n                if not response:\n                    # we don't want to send an empty message\n                    continue\n\n                # when we send the first message, we don't want to send a notification,\n                # as it will only include the first token of the response.  This will\n                # not be very useful to anyone.\n                last_message = await response_channel.send(\n                    response,\n                    allowed_mentions=allowed_mentions,\n                    silent=True,\n                    suppress_embeds=True,\n                    reference=reference,  # type: ignore\n                )\n            else:\n                await last_message.edit(\n                    content=response,\n                    allowed_mentions=allowed_mentions,\n                    suppress=True,\n                )\n                last_message.content = response\n\n            # we want to abort the response only after we've sent any valid\n            # messages, and potentially removed any partial immersion-breaking\n            # lines that we posted when they were in the process of being received.\n            if abort_response:\n                break\n\n            this_response_stat.log_response_part()\n\n        if last_message is not None:\n            self.repetition_tracker.log_message(\n                response_channel_id,\n                discord_utils.discord_message_to_generic_message(last_message),\n            )\n\n        return last_message\n\n    def _filter_immersion_breaking_lines(\n        self, sentence: str\n    ) -> typing.Tuple[str, bool]:\n        \"\"\"\n        Given a string that represents an individual response message,\n        filter out any lines that would break immersion.\n\n        These include lines that include a termination symbol, lines\n        that attempt to carry on the conversation as a different user,\n        and lines that include text which is part of the AI prompt.\n\n        Returns the subset of the input string that should be sent,\n        and a boolean indicating if we should abort the response entirely,\n        ignoring any further lines.\n        \"\"\"\n        lines = sentence.split(\"\\n\")\n        good_lines = []\n        previous_line = \"\"\n        abort_response = False\n        for line in lines:\n            # if the AI gives itself a second line, just ignore\n            # the line instruction and continue\n            if self.prompt_generator.bot_prompt_line == line:\n                fancy_logger.get().warning(\n                    \"Filtered out %s from response, continuing\", line\n                )\n                continue\n\n            # hack: abort response if it looks like the AI is\n            # continuing the conversation as someone else\n            if line.endswith(\" says:\"):\n                fancy_logger.get().warning(\n                    'Filtered out \"%s\" from response, aborting', line\n                )\n                abort_response = True\n                break\n\n            # look for partial stop markers within a line\n            for marker in self.stop_markers:\n                if marker in line:\n                    (keep_part, removed) = line.split(marker, 1)\n                    fancy_logger.get().warning(\n                        'Filtered out \"%s\" from response, aborting',\n                        removed,\n                    )\n                    if keep_part:\n                        good_lines.append(keep_part)\n                    abort_response = True\n                    break\n\n            if not line and not previous_line:\n                # filter out multiple blank lines in a row\n                continue\n\n            if not line.strip():\n                # filter out lines that are entirely made of whitespace\n                continue\n\n            good_lines.append(line)\n        return (\"\\n\".join(good_lines), abort_response)\n\n    ########\n    async def _filter_history_message(\n        self,\n        message: discord.Message,\n        stop_before_message_id: typing.Optional[int],\n    ) -> typing.Tuple[typing.Optional[types.GenericMessage], bool]:\n        \"\"\"\n        Filter out any messages that we don't want to include in the\n        AI's history.\n\n        These include:\n         - messages generated by our image generator\n         - messages at or before the stop_before_message_id\n\n        Also, modify the message in the following ways:\n         - if the message is from the AI, set the author name to\n           the AI's persona name, not its Discord account name\n         - remove <@_0000000_> user-id based message mention text,\n           replacing them with @username mentions\n        \"\"\"\n        # if we've hit the throttle message, stop and don't add any\n        # more history\n        if stop_before_message_id and message.id == stop_before_message_id:\n            return (None, False)\n\n        generic_message = discord_utils.discord_message_to_generic_message(message)\n\n        if generic_message.author_id == self.ai_user_id:\n            # make sure the AI always sees its persona name\n            # in the transcript, even if the chat program\n            # has it under a different account name\n            generic_message.author_name = self.persona.ai_name\n\n            # hack: use the suppress_embeds=True flag to indicate\n            # that this message is one we generated as part of a text\n            # response, as opposed to an image or application message\n            if not message.flags.suppress_embeds:\n                # this is a message generated by our image generator\n                return (None, True)\n\n        if message.channel.guild is None:\n            fn_user_id_to_name = discord_utils.dm_user_id_to_name(\n                self.ai_user_id,\n                self.persona.ai_name,\n            )\n        else:\n            fn_user_id_to_name = discord_utils.guild_user_id_to_name(\n                message.channel.guild,\n            )\n\n        discord_utils.replace_mention_ids_with_names(\n            generic_message,\n            fn_user_id_to_name=fn_user_id_to_name,\n        )\n        return (generic_message, True)\n\n    async def _filtered_history_iterator(\n        self,\n        async_iter_history: typing.AsyncIterator[discord.Message],\n        stop_before_message_id: typing.Optional[int],\n        ignore_all_until_message_id: typing.Optional[int],\n        limit: int,\n    ) -> typing.AsyncIterator[types.GenericMessage]:\n        \"\"\"\n        When returning the history of a thread, Discord\n        does not include the message that kicked off the thread.\n\n        It will show it in the UI as if it were, but it's not\n        one of the messages returned by the history iterator.\n\n        This method attempts to return that message as well,\n        if we need it.\n        \"\"\"\n        items = 0\n        last_returned = None\n        ignoring_all = ignore_all_until_message_id is not None\n        async for item in async_iter_history:\n            if items >= limit:\n                return\n\n            if ignoring_all:\n                if item.id == ignore_all_until_message_id:\n                    ignoring_all = False\n                else:\n                    # this message was sent after the message we're\n                    # responding to.  So filter out it as to not confuse\n                    # the AI into responding to content from that message\n                    # instead\n                    continue\n\n            last_returned = item\n            (sanitized_message, allow_more) = await self._filter_history_message(\n                item,\n                stop_before_message_id=stop_before_message_id,\n            )\n            if not allow_more:\n                # we've hit a message which requires us to stop\n                # and look at more history\n                return\n            if sanitized_message is not None:\n                yield sanitized_message\n                items += 1\n\n        if last_returned is not None and items < limit:\n            # we've reached the beginning of the history, but\n            # still have space.  If this message was a reply\n            # to another message, return that message as well.\n            if last_returned.reference is None:\n                return\n\n            ref = last_returned.reference.resolved\n\n            # the resolved message may be None if the message\n            # was deleted\n            if ref is not None and isinstance(ref, discord.Message):\n                (sanitized_message, _) = await self._filter_history_message(\n                    ref,\n                    stop_before_message_id,\n                )\n                if sanitized_message is not None:\n                    yield sanitized_message\n\n    # when looking through the history of a channel, we'll have a goal\n    # of retrieving a certain number of lines of history.  However,\n    # there are some messages in the history that we'll want to filter\n    # out.  These include messages that were generated by our image\n    # generator, as well as certain messages that will be ignored\n    # in order to generate a response for a specific user who\n    # @-mentions the bot.\n    #\n    # This is the maximum number of \"extra\" messages to retrieve\n    # from the history, in an attempt to find enough messages\n    # that we can filter out the ones we don't want and still\n    # have enough left over to satisfy the request.\n    #\n    # Note that since the history is returned in reverse order,\n    # and each is pulled in only as needed, there's not much of a\n    # penalty to making this somewhat large.  But still, we want\n    # to keep it reasonable.\n    MESSAGE_HISTORY_LOOKBACK_BONUS = 20\n\n    async def _recent_messages_following_thread(\n        self,\n        channel: discord.abc.Messageable,\n        stop_before_message_id: typing.Optional[int],\n        ignore_all_until_message_id: typing.Optional[int],\n        num_history_lines: int,\n    ) -> typing.AsyncIterator[types.GenericMessage]:\n        max_messages_to_check = num_history_lines + self.MESSAGE_HISTORY_LOOKBACK_BONUS\n        history = channel.history(limit=max_messages_to_check)\n        result = self._filtered_history_iterator(\n            history,\n            limit=num_history_lines,\n            stop_before_message_id=stop_before_message_id,\n            ignore_all_until_message_id=ignore_all_until_message_id,\n        )\n        return result", "class DiscordBot(discord.Client):\n    \"\"\"\n    Main bot class.  Connects to Discord, monitors for messages,\n    and dispatches responses.\n    \"\"\"\n\n    def __init__(\n        self,\n        bot_commands: bot_commands.BotCommands,\n        decide_to_respond: decide_to_respond.DecideToRespond,\n        discord_settings: dict,\n        image_generator: typing.Optional[image_generator.ImageGenerator],\n        ooba_client: ooba_client.OobaClient,\n        persona: persona.Persona,\n        prompt_generator: prompt_generator.PromptGenerator,\n        repetition_tracker: repetition_tracker.RepetitionTracker,\n        response_stats: response_stats.AggregateResponseStats,\n    ):\n        self.bot_commands = bot_commands\n        self.decide_to_respond = decide_to_respond\n        self.image_generator = image_generator\n        self.ooba_client = ooba_client\n        self.persona = persona\n        self.prompt_generator = prompt_generator\n        self.repetition_tracker = repetition_tracker\n        self.response_stats = response_stats\n\n        self.ai_user_id = -1\n\n        self.dont_split_responses = discord_settings[\"dont_split_responses\"]\n        self.ignore_dms = discord_settings[\"ignore_dms\"]\n        self.reply_in_thread = discord_settings[\"reply_in_thread\"]\n        self.stop_markers = discord_settings[\"stop_markers\"]\n        self.stream_responses = discord_settings[\"stream_responses\"]\n        self.stream_responses_speed_limit = discord_settings[\n            \"stream_responses_speed_limit\"\n        ]\n\n        # add stopping_strings to stop_markers\n        self.stop_markers.extend(self.ooba_client.get_stopping_strings())\n\n        super().__init__(intents=discord_utils.get_intents())\n\n    async def on_ready(self) -> None:\n        guilds = self.guilds\n        num_guilds = len(guilds)\n        num_channels = sum(len(guild.channels) for guild in guilds)\n\n        if self.user:\n            self.ai_user_id = self.user.id\n            user_id_str = self.user.name\n        else:\n            user_id_str = \"<unknown>\"\n\n        fancy_logger.get().info(\n            \"Connected to discord as %s (ID: %d)\", user_id_str, self.ai_user_id\n        )\n        fancy_logger.get().debug(\n            \"monitoring %d channels across %d server(s)\", num_channels, num_guilds\n        )\n        if self.ignore_dms:\n            fancy_logger.get().debug(\"Ignoring DMs\")\n        else:\n            fancy_logger.get().debug(\"listening to DMs\")\n\n        if self.stream_responses:\n            fancy_logger.get().debug(\n                \"Response Grouping: streamed live into a single message\"\n            )\n        elif self.dont_split_responses:\n            fancy_logger.get().debug(\"Response Grouping: returned as single messages\")\n        else:\n            fancy_logger.get().debug(\n                \"Response Grouping: split into messages by sentence\"\n            )\n\n        fancy_logger.get().debug(\"AI name: %s\", self.persona.ai_name)\n        fancy_logger.get().debug(\"AI persona: %s\", self.persona.persona)\n\n        fancy_logger.get().debug(\n            \"History: %d lines \", self.prompt_generator.history_lines\n        )\n\n        fancy_logger.get().debug(\n            \"Stop markers: %s\", \", \".join(self.stop_markers) or \"<none>\"\n        )\n\n        # log unsolicited_channel_cap\n        cap = self.decide_to_respond.get_unsolicited_channel_cap()\n        cap = str(cap) if cap > 0 else \"<unlimited>\"\n        fancy_logger.get().debug(\n            \"Unsolicited channel cap: %s\",\n            cap,\n        )\n\n        str_wakewords = (\n            \", \".join(self.persona.wakewords) if self.persona.wakewords else \"<none>\"\n        )\n        fancy_logger.get().debug(\"Wakewords: %s\", str_wakewords)\n\n        self.ooba_client.on_ready()\n\n        if self.image_generator is None:\n            fancy_logger.get().debug(\"Stable Diffusion: disabled\")\n        else:\n            self.image_generator.on_ready()\n\n        # we do this at the very end because when you restart\n        # the bot, it can take a while for the commands to\n        # register\n        try:\n            # register the commands\n            await self.bot_commands.on_ready(self)\n        except discord.DiscordException as err:\n            fancy_logger.get().warning(\n                \"Failed to register commands: %s (continuing without commands)\", err\n            )\n\n        # show a warning if the bot is connected to zero guilds,\n        # with a helpful link on how to fix it\n        if num_guilds == 0:\n            fancy_logger.get().warning(\n                \"The bot is not connected to any servers.  \"\n                + \"Please add the bot to a server here:\",\n            )\n            fancy_logger.get().warning(\n                discord_utils.generate_invite_url(self.ai_user_id)\n            )\n\n    async def on_message(self, raw_message: discord.Message) -> None:\n        \"\"\"\n        Called when a message is received from Discord.\n\n        This method is called for every message that the bot can see.\n        It decides whether to respond to the message, and if so,\n        calls _handle_response() to generate a response.\n\n        :param raw_message: The raw message from Discord.\n        \"\"\"\n        try:\n            message = discord_utils.discord_message_to_generic_message(raw_message)\n            should_respond, is_summon = self.decide_to_respond.should_reply_to_message(\n                self.ai_user_id, message\n            )\n            if not should_respond:\n                return\n\n            is_summon_in_public_channel = is_summon and isinstance(\n                message,\n                types.ChannelMessage,\n            )\n\n            async with raw_message.channel.typing():\n                await self._handle_response(\n                    message, raw_message, is_summon_in_public_channel\n                )\n\n        except discord.DiscordException as err:\n            fancy_logger.get().error(\n                \"Exception while processing message: %s\", err, exc_info=True\n            )\n\n    async def _handle_response(\n        self,\n        message: types.GenericMessage,\n        raw_message: discord.Message,\n        is_summon_in_public_channel: bool,\n    ) -> None:\n        \"\"\"\n        Called when we've decided to respond to a message.\n\n        It decides if we're sending a text response, an image response,\n        or both, and then sends the response(s).\n        \"\"\"\n        image_prompt = None\n        if self.image_generator is not None:\n            # are we creating an image?\n            image_prompt = self.image_generator.maybe_get_image_prompt(raw_message)\n\n        result = await self._send_text_response(\n            message=message,\n            raw_message=raw_message,\n            image_requested=image_prompt is not None,\n            is_summon_in_public_channel=is_summon_in_public_channel,\n        )\n        if result is None:\n            # we failed to create a thread that the user could\n            # read our response in, so we're done here.  Abort!\n            return\n        message_task, response_channel = result\n\n        # log the mention, now that we know the channel we\n        # want to monitor later to continue to conversation\n        if isinstance(response_channel, (discord.Thread, discord.abc.GuildChannel)):\n            if is_summon_in_public_channel:\n                self.decide_to_respond.log_mention(\n                    response_channel.id,\n                    message.send_timestamp,\n                )\n\n        image_task = None\n        if self.image_generator is not None and image_prompt is not None:\n            image_task = await self.image_generator.generate_image(\n                image_prompt,\n                raw_message,\n                response_channel=response_channel,\n            )\n\n        response_tasks = [\n            task for task in [message_task, image_task] if task is not None\n        ]\n        await asyncio.wait(response_tasks)\n\n        # there may be more than one exception, so be sure to log\n        # them all before raising either of them\n        raise_later = None\n        for task in response_tasks:\n            if task.exception() is not None:\n                fancy_logger.get().error(\n                    f\"Exception while running {task.get_coro()} \"\n                    + f\"response: {task.exception()}\",\n                    stack_info=True,\n                )\n                raise_later = task.exception()\n        if raise_later is not None:\n            raise raise_later\n\n    async def _send_text_response(\n        self,\n        message: types.GenericMessage,\n        raw_message: discord.Message,\n        image_requested: bool,\n        is_summon_in_public_channel: bool,\n    ) -> typing.Optional[typing.Tuple[asyncio.Task, discord.abc.Messageable]]:\n        \"\"\"\n        Send a text response to a message.\n\n        This method determines what channel or thread to post the message\n        in, creating a thread if necessary.  It then posts the message\n        by calling _send_text_response_to_channel().\n\n        Returns a tuple of the task that was created to send the message,\n        and the channel that the message was sent to.\n\n        If no message was sent, the task and channel will be None.\n        \"\"\"\n        response_channel = raw_message.channel\n        if (\n            self.reply_in_thread\n            and isinstance(raw_message.channel, discord.TextChannel)\n            and isinstance(raw_message.author, discord.Member)\n        ):\n            # we want to create a response thread, if possible\n            # but we have to see if the user has permission to do so\n            # if the user can't we wont respond at all.\n            perms = raw_message.channel.permissions_for(raw_message.author)\n            if perms.create_public_threads:\n                response_channel = await raw_message.create_thread(\n                    name=f\"{self.persona.ai_name}, replying to \"\n                    + f\"{raw_message.author.display_name}\",\n                )\n                fancy_logger.get().debug(\n                    f\"Created response thread {response_channel.name} \"\n                    + f\"({response_channel.id}) \"\n                    + f\"in {raw_message.channel.name}\"\n                )\n            else:\n                # This user can't create threads, so we won't respond.\n                # The reason we don't respond in the channel is that\n                # it can create confusion later if a second user who\n                # DOES have thread-create permission replies to that\n                # message.  We'd end up creating a thread for that\n                # second user's response, and again for a third user,\n                # etc.\n                fancy_logger.get().debug(\"User can't create threads, not responding.\")\n                return None\n\n        response_coro = self._send_text_response_in_channel(\n            message=message,\n            raw_message=raw_message,\n            image_requested=image_requested,\n            is_summon_in_public_channel=is_summon_in_public_channel,\n            response_channel=response_channel,\n            response_channel_id=response_channel.id,\n        )\n        response_task = asyncio.create_task(response_coro)\n        return (response_task, response_channel)\n\n    async def _send_text_response_in_channel(\n        self,\n        message: types.GenericMessage,\n        raw_message: discord.Message,\n        image_requested: bool,\n        is_summon_in_public_channel: bool,\n        response_channel: discord.abc.Messageable,\n        response_channel_id: int,\n    ) -> None:\n        \"\"\"\n        Getting closer now!  This method is what actually gathers message\n        history, queries the AI for a text response, breaks the response\n        into individual messages, and then and then calls\n        __send_response_message() to send sech message.\n        \"\"\"\n        fancy_logger.get().debug(\n            \"Request from %s in %s\", message.author_name, message.channel_name\n        )\n\n        repeated_id = self.repetition_tracker.get_throttle_message_id(\n            response_channel_id\n        )\n\n        # determine if we're responding to a specific message that\n        # summoned us.  If so, find out what message ID that was, so\n        # that we can ignore all messages sent after it (as not to\n        # confuse the AI about what to reply to)\n        reference = None\n        ignore_all_until_message_id = None\n        if is_summon_in_public_channel:\n            # we can't use the message reference if we're starting a new thread\n            if message.channel_id == response_channel_id:\n                reference = raw_message.to_reference()\n            ignore_all_until_message_id = raw_message.id\n\n        recent_messages = await self._recent_messages_following_thread(\n            channel=response_channel,\n            num_history_lines=self.prompt_generator.history_lines,\n            stop_before_message_id=repeated_id,\n            ignore_all_until_message_id=ignore_all_until_message_id,\n        )\n\n        prompt_prefix = await self.prompt_generator.generate(\n            message_history=recent_messages,\n            image_requested=image_requested,\n        )\n\n        this_response_stat = self.response_stats.log_request_arrived(prompt_prefix)\n\n        # restrict the @mentions the AI is allowed to use in its response.\n        # this is to prevent another user from being able to trick the AI\n        # into @-pinging a large group and annoying them.\n        # Only the author of the original message may be @-pinged.\n        allowed_mentions = discord.AllowedMentions(\n            everyone=False,\n            users=[raw_message.author],\n            roles=False,\n        )\n\n        # will be set to true when we abort the response because:\n        #  it was empty\n        #  it repeated a previous response and we're throttling it\n        aborted_by_us = False\n        sent_message_count = 0\n        try:\n            if self.stream_responses:\n                generator = self.ooba_client.request_as_grouped_tokens(\n                    prompt_prefix, interval=self.stream_responses_speed_limit\n                )\n                last_sent_message = await self._render_streaming_response(\n                    generator,\n                    this_response_stat,\n                    response_channel,\n                    response_channel_id,\n                    allowed_mentions,\n                    reference,\n                )\n                if last_sent_message is not None:\n                    sent_message_count = 1\n            else:\n                if self.dont_split_responses:\n                    response = await self.ooba_client.request_as_string(prompt_prefix)\n                    (\n                        last_sent_message,\n                        aborted_by_us,\n                    ) = await self._send_response_message(\n                        response,\n                        this_response_stat,\n                        response_channel,\n                        response_channel_id,\n                        allowed_mentions,\n                        reference,\n                    )\n                    if last_sent_message is not None:\n                        sent_message_count = 1\n                else:\n                    sent_message_count = 0\n                    last_sent_message = None\n                    async for sentence in self.ooba_client.request_by_message(\n                        prompt_prefix\n                    ):\n                        (\n                            sent_message,\n                            abort_response,\n                        ) = await self._send_response_message(\n                            sentence,\n                            this_response_stat,\n                            response_channel,\n                            response_channel_id,\n                            allowed_mentions=allowed_mentions,\n                            reference=reference,\n                        )\n                        if sent_message is not None:\n                            last_sent_message = sent_message\n                            sent_message_count += 1\n                            # only use the reference for the first\n                            # message in a multi-message chain\n                            reference = None\n                        if abort_response:\n                            aborted_by_us = True\n                            break\n\n        except discord.DiscordException as err:\n            fancy_logger.get().error(\"Error: %s\", err, exc_info=True)\n            self.response_stats.log_response_failure()\n            return\n\n        if 0 == sent_message_count:\n            if aborted_by_us:\n                fancy_logger.get().warning(\n                    \"No response sent.  The AI has generated a message that we have \"\n                    + \"chosen not to send, probably because it was empty or repeated.\"\n                )\n            else:\n                fancy_logger.get().warning(\n                    \"An empty response was received from Oobabooga.  Please check that \"\n                    + \"the AI is running properly on the Oobabooga server at %s.\",\n                    self.ooba_client.base_url,\n                )\n            self.response_stats.log_response_failure()\n            return\n\n        this_response_stat.write_to_log(f\"Response to {message.author_name} done!  \")\n        self.response_stats.log_response_success(this_response_stat)\n\n    async def _send_response_message(\n        self,\n        response: str,\n        this_response_stat: response_stats.ResponseStats,\n        response_channel: discord.abc.Messageable,\n        response_channel_id: int,\n        allowed_mentions: discord.AllowedMentions,\n        reference: typing.Optional[discord.MessageReference],\n    ) -> typing.Tuple[typing.Optional[discord.Message], bool]:\n        \"\"\"\n        Given a string that represents an individual response message,\n        post it in the given channel.\n\n        It also looks to see if a message contains a termination string,\n        and if so it will return False to indicate that we should stop\n        the response.\n\n        Also does some bookkeeping to make sure we don't repeat ourselves,\n        and to track how many messages we've sent.\n\n        Returns a tuple with:\n        - the sent discord message, if any\n        - a boolean indicating if we need to abort the response entirely\n        \"\"\"\n        (sentence, abort_response) = self._filter_immersion_breaking_lines(response)\n        if abort_response:\n            return (None, True)\n        if not sentence:\n            # we can't send an empty message\n            return (None, False)\n\n        response_message = await response_channel.send(\n            sentence,\n            allowed_mentions=allowed_mentions,\n            suppress_embeds=True,\n            reference=reference,  # type: ignore\n        )\n        self.repetition_tracker.log_message(\n            response_channel_id,\n            discord_utils.discord_message_to_generic_message(response_message),\n        )\n\n        this_response_stat.log_response_part()\n        return (response_message, False)\n\n    async def _render_streaming_response(\n        self,\n        response_iterator: typing.AsyncIterator[str],\n        this_response_stat: response_stats.ResponseStats,\n        response_channel: discord.abc.Messageable,\n        response_channel_id: int,\n        allowed_mentions: discord.AllowedMentions,\n        reference: typing.Optional[discord.MessageReference],\n    ) -> typing.Optional[discord.Message]:\n        response = \"\"\n        last_message = None\n        async for token in response_iterator:\n            if \"\" == token:\n                continue\n\n            response += token\n            (response, abort_response) = self._filter_immersion_breaking_lines(response)\n\n            # if we are aborting a response, we want to at least post\n            # the valid parts, so don't abort quite yet.\n\n            if last_message is None:\n                if not response:\n                    # we don't want to send an empty message\n                    continue\n\n                # when we send the first message, we don't want to send a notification,\n                # as it will only include the first token of the response.  This will\n                # not be very useful to anyone.\n                last_message = await response_channel.send(\n                    response,\n                    allowed_mentions=allowed_mentions,\n                    silent=True,\n                    suppress_embeds=True,\n                    reference=reference,  # type: ignore\n                )\n            else:\n                await last_message.edit(\n                    content=response,\n                    allowed_mentions=allowed_mentions,\n                    suppress=True,\n                )\n                last_message.content = response\n\n            # we want to abort the response only after we've sent any valid\n            # messages, and potentially removed any partial immersion-breaking\n            # lines that we posted when they were in the process of being received.\n            if abort_response:\n                break\n\n            this_response_stat.log_response_part()\n\n        if last_message is not None:\n            self.repetition_tracker.log_message(\n                response_channel_id,\n                discord_utils.discord_message_to_generic_message(last_message),\n            )\n\n        return last_message\n\n    def _filter_immersion_breaking_lines(\n        self, sentence: str\n    ) -> typing.Tuple[str, bool]:\n        \"\"\"\n        Given a string that represents an individual response message,\n        filter out any lines that would break immersion.\n\n        These include lines that include a termination symbol, lines\n        that attempt to carry on the conversation as a different user,\n        and lines that include text which is part of the AI prompt.\n\n        Returns the subset of the input string that should be sent,\n        and a boolean indicating if we should abort the response entirely,\n        ignoring any further lines.\n        \"\"\"\n        lines = sentence.split(\"\\n\")\n        good_lines = []\n        previous_line = \"\"\n        abort_response = False\n        for line in lines:\n            # if the AI gives itself a second line, just ignore\n            # the line instruction and continue\n            if self.prompt_generator.bot_prompt_line == line:\n                fancy_logger.get().warning(\n                    \"Filtered out %s from response, continuing\", line\n                )\n                continue\n\n            # hack: abort response if it looks like the AI is\n            # continuing the conversation as someone else\n            if line.endswith(\" says:\"):\n                fancy_logger.get().warning(\n                    'Filtered out \"%s\" from response, aborting', line\n                )\n                abort_response = True\n                break\n\n            # look for partial stop markers within a line\n            for marker in self.stop_markers:\n                if marker in line:\n                    (keep_part, removed) = line.split(marker, 1)\n                    fancy_logger.get().warning(\n                        'Filtered out \"%s\" from response, aborting',\n                        removed,\n                    )\n                    if keep_part:\n                        good_lines.append(keep_part)\n                    abort_response = True\n                    break\n\n            if not line and not previous_line:\n                # filter out multiple blank lines in a row\n                continue\n\n            if not line.strip():\n                # filter out lines that are entirely made of whitespace\n                continue\n\n            good_lines.append(line)\n        return (\"\\n\".join(good_lines), abort_response)\n\n    ########\n    async def _filter_history_message(\n        self,\n        message: discord.Message,\n        stop_before_message_id: typing.Optional[int],\n    ) -> typing.Tuple[typing.Optional[types.GenericMessage], bool]:\n        \"\"\"\n        Filter out any messages that we don't want to include in the\n        AI's history.\n\n        These include:\n         - messages generated by our image generator\n         - messages at or before the stop_before_message_id\n\n        Also, modify the message in the following ways:\n         - if the message is from the AI, set the author name to\n           the AI's persona name, not its Discord account name\n         - remove <@_0000000_> user-id based message mention text,\n           replacing them with @username mentions\n        \"\"\"\n        # if we've hit the throttle message, stop and don't add any\n        # more history\n        if stop_before_message_id and message.id == stop_before_message_id:\n            return (None, False)\n\n        generic_message = discord_utils.discord_message_to_generic_message(message)\n\n        if generic_message.author_id == self.ai_user_id:\n            # make sure the AI always sees its persona name\n            # in the transcript, even if the chat program\n            # has it under a different account name\n            generic_message.author_name = self.persona.ai_name\n\n            # hack: use the suppress_embeds=True flag to indicate\n            # that this message is one we generated as part of a text\n            # response, as opposed to an image or application message\n            if not message.flags.suppress_embeds:\n                # this is a message generated by our image generator\n                return (None, True)\n\n        if message.channel.guild is None:\n            fn_user_id_to_name = discord_utils.dm_user_id_to_name(\n                self.ai_user_id,\n                self.persona.ai_name,\n            )\n        else:\n            fn_user_id_to_name = discord_utils.guild_user_id_to_name(\n                message.channel.guild,\n            )\n\n        discord_utils.replace_mention_ids_with_names(\n            generic_message,\n            fn_user_id_to_name=fn_user_id_to_name,\n        )\n        return (generic_message, True)\n\n    async def _filtered_history_iterator(\n        self,\n        async_iter_history: typing.AsyncIterator[discord.Message],\n        stop_before_message_id: typing.Optional[int],\n        ignore_all_until_message_id: typing.Optional[int],\n        limit: int,\n    ) -> typing.AsyncIterator[types.GenericMessage]:\n        \"\"\"\n        When returning the history of a thread, Discord\n        does not include the message that kicked off the thread.\n\n        It will show it in the UI as if it were, but it's not\n        one of the messages returned by the history iterator.\n\n        This method attempts to return that message as well,\n        if we need it.\n        \"\"\"\n        items = 0\n        last_returned = None\n        ignoring_all = ignore_all_until_message_id is not None\n        async for item in async_iter_history:\n            if items >= limit:\n                return\n\n            if ignoring_all:\n                if item.id == ignore_all_until_message_id:\n                    ignoring_all = False\n                else:\n                    # this message was sent after the message we're\n                    # responding to.  So filter out it as to not confuse\n                    # the AI into responding to content from that message\n                    # instead\n                    continue\n\n            last_returned = item\n            (sanitized_message, allow_more) = await self._filter_history_message(\n                item,\n                stop_before_message_id=stop_before_message_id,\n            )\n            if not allow_more:\n                # we've hit a message which requires us to stop\n                # and look at more history\n                return\n            if sanitized_message is not None:\n                yield sanitized_message\n                items += 1\n\n        if last_returned is not None and items < limit:\n            # we've reached the beginning of the history, but\n            # still have space.  If this message was a reply\n            # to another message, return that message as well.\n            if last_returned.reference is None:\n                return\n\n            ref = last_returned.reference.resolved\n\n            # the resolved message may be None if the message\n            # was deleted\n            if ref is not None and isinstance(ref, discord.Message):\n                (sanitized_message, _) = await self._filter_history_message(\n                    ref,\n                    stop_before_message_id,\n                )\n                if sanitized_message is not None:\n                    yield sanitized_message\n\n    # when looking through the history of a channel, we'll have a goal\n    # of retrieving a certain number of lines of history.  However,\n    # there are some messages in the history that we'll want to filter\n    # out.  These include messages that were generated by our image\n    # generator, as well as certain messages that will be ignored\n    # in order to generate a response for a specific user who\n    # @-mentions the bot.\n    #\n    # This is the maximum number of \"extra\" messages to retrieve\n    # from the history, in an attempt to find enough messages\n    # that we can filter out the ones we don't want and still\n    # have enough left over to satisfy the request.\n    #\n    # Note that since the history is returned in reverse order,\n    # and each is pulled in only as needed, there's not much of a\n    # penalty to making this somewhat large.  But still, we want\n    # to keep it reasonable.\n    MESSAGE_HISTORY_LOOKBACK_BONUS = 20\n\n    async def _recent_messages_following_thread(\n        self,\n        channel: discord.abc.Messageable,\n        stop_before_message_id: typing.Optional[int],\n        ignore_all_until_message_id: typing.Optional[int],\n        num_history_lines: int,\n    ) -> typing.AsyncIterator[types.GenericMessage]:\n        max_messages_to_check = num_history_lines + self.MESSAGE_HISTORY_LOOKBACK_BONUS\n        history = channel.history(limit=max_messages_to_check)\n        result = self._filtered_history_iterator(\n            history,\n            limit=num_history_lines,\n            stop_before_message_id=stop_before_message_id,\n            ignore_all_until_message_id=ignore_all_until_message_id,\n        )\n        return result", ""]}
{"filename": "src/oobabot/persona.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nRetrieves persona data from a variety of formats.\n\"\"\"\n\nimport json\nimport re\nimport typing\n\nimport ruamel.yaml as ryaml", "\nimport ruamel.yaml as ryaml\n\nfrom oobabot import fancy_logger\n\n\nclass Persona:\n    \"\"\"\n    Handles retrieving persona data from a variety of formats\n    \"\"\"\n\n    # list of keys that, depending on the json/yaml schema, might\n    # contain the AI's name.  Take the first one found, in order.\n    NAME_KEYS = [\"char_name\", \"name\"]\n\n    # list of keys that, depending on the json/yaml schema, might\n    # contain the AI's persona.  Take the first one found, in order.\n    PERSONA_KEYS = [\"char_persona\", \"description\", \"context\", \"personality\"]\n\n    def __init__(self, persona_settings: dict) -> None:\n        self.ai_name: str = persona_settings[\"ai_name\"]\n        self.persona: str = persona_settings[\"persona\"]\n        self.wakewords: typing.List[str] = persona_settings[\"wakewords\"].copy()\n\n        # if a json file is specified, load it and have\n        # that overwrite everything else\n        if \"persona_file\" in persona_settings:\n            filename = persona_settings[\"persona_file\"]\n            try:\n                self.load_from_file(filename)\n            except FileNotFoundError:\n                fancy_logger.get().warning(\n                    \"Could not find persona file: %s\",\n                    filename,\n                )\n                return\n\n        # match messages that include any `wakeword`, but not as part of\n        # another word\n        self.wakeword_patterns = [\n            re.compile(rf\"\\b{wakeword}\\b\", re.IGNORECASE) for wakeword in self.wakewords\n        ]\n\n    def contains_wakeword(self, message: str) -> bool:\n        for wakeword_pattern in self.wakeword_patterns:\n            if wakeword_pattern.search(message):\n                return True\n        return False\n\n    def substitute(self, text: str) -> str:\n        return text.replace(\"{{char}}\", self.ai_name)\n\n    def load_from_file(self, filename: str):\n        if not filename:\n            return\n\n        if filename.endswith(\".json\"):\n            self.load_from_json_file(filename)\n            return\n\n        if filename.endswith(\".yaml\"):\n            self.load_from_yaml_file(filename)\n            return\n\n        if filename.endswith(\".txt\"):\n            self.load_from_text_file(filename)\n            return\n\n        fancy_logger.get().warning(\n            \"Unknown persona file extension (expected .json, or .txt): %s\",\n            filename,\n        )\n\n    def load_from_text_file(self, filename: str):\n        with open(filename, \"r\", encoding=\"utf-8\") as file:\n            persona = file.read()\n        self.persona = persona\n\n    def load_from_json_file(self, filename: str):\n        try:\n            with open(filename, \"r\", encoding=\"utf-8\") as file:\n                json_data = json.load(file)\n\n        except json.JSONDecodeError as err:\n            fancy_logger.get().warning(\n                \"Could not parse persona file: %s.  Cause: %s\",\n                filename,\n                err,\n            )\n            return\n        self.load_from_dict(json_data)\n\n    def load_from_yaml_file(self, filename):\n        with open(filename, \"r\", encoding=\"utf-8\") as file:\n            yaml = ryaml.YAML(typ=\"safe\")\n            try:\n                yaml_settings = yaml.load(file)\n            except ryaml.YAMLError as err:\n                fancy_logger.get().warning(\n                    \"Could not parse persona file: %s.  Cause: %s\",\n                    filename,\n                    err,\n                )\n                return\n        self.load_from_dict(yaml_settings)\n\n    def load_from_dict(self, json_data: dict):\n        for name_key in Persona.NAME_KEYS:\n            if name_key in json_data and json_data[name_key]:\n                self.ai_name = json_data[name_key]\n                break\n        for persona_key in Persona.PERSONA_KEYS:\n            if persona_key in json_data and json_data[persona_key]:\n                self.persona = self.substitute(json_data[persona_key])\n                break\n        if self.ai_name not in self.wakewords and self.ai_name:\n            self.wakewords.append(self.ai_name)", ""]}
{"filename": "src/oobabot/discord_utils.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nConverts Discord library objects into generic objects that can be used by the AI\n\nThis is done to make it easier to swap out the Discord library for something else\nin the future, and to make it easier to test the AI without having to mock the\nDiscord library.\n\"\"\"\n\n", "\n\nimport base64\nimport functools\nimport os\nimport pathlib\nimport re\nimport typing\n\nimport discord", "\nimport discord\n\nfrom oobabot import fancy_logger\nfrom oobabot import types\n\nFORBIDDEN_CHARACTERS = r\"[\\n\\r\\t]\"\nFORBIDDEN_CHARACTERS_PATTERN = re.compile(FORBIDDEN_CHARACTERS)\n\n\ndef get_channel_name(channel: discord.abc.Messageable) -> str:\n    if isinstance(channel, discord.Thread):\n        return \"thread #\" + channel.name\n    if isinstance(channel, discord.abc.GuildChannel):\n        return \"channel #\" + channel.name\n    if isinstance(channel, discord.DMChannel):\n        return \"-DM-\"\n    if isinstance(channel, discord.GroupChannel):\n        return \"-GROUP-DM-\"\n    return \"-Unknown-\"", "\n\ndef get_channel_name(channel: discord.abc.Messageable) -> str:\n    if isinstance(channel, discord.Thread):\n        return \"thread #\" + channel.name\n    if isinstance(channel, discord.abc.GuildChannel):\n        return \"channel #\" + channel.name\n    if isinstance(channel, discord.DMChannel):\n        return \"-DM-\"\n    if isinstance(channel, discord.GroupChannel):\n        return \"-GROUP-DM-\"\n    return \"-Unknown-\"", "\n\ndef sanitize_string(raw_string: str) -> str:\n    \"\"\"\n    Filter out any characters that would confuse the AI\n    \"\"\"\n    return FORBIDDEN_CHARACTERS_PATTERN.sub(\" \", raw_string)\n\n\ndef discord_message_to_generic_message(\n    raw_message: discord.Message,\n) -> typing.Union[types.GenericMessage, types.ChannelMessage, types.DirectMessage]:\n    \"\"\"\n    Convert a discord message to a GenericMessage or subclass thereof\n    \"\"\"\n    if raw_message.author.bot:\n        # address issue https://github.com/chrisrude/oobabot/issues/76\n        # If the bot is creating a formatted message, keep that formatting\n        # intact.\n        # Ideally, this would be nice to do for user messages as well,\n        # but if we allowed that then it would let a malicious user\n        # impersonate both the bot and other users.  So trust bots only.\n        body_text = raw_message.content\n    else:\n        body_text = sanitize_string(raw_message.content)\n\n    generic_args = {\n        \"author_id\": raw_message.author.id,\n        \"author_name\": sanitize_string(raw_message.author.display_name),\n        \"channel_id\": raw_message.channel.id,\n        \"channel_name\": get_channel_name(raw_message.channel),\n        \"message_id\": raw_message.id,\n        \"body_text\": body_text,\n        \"author_is_bot\": raw_message.author.bot,\n        \"send_timestamp\": raw_message.created_at.timestamp(),\n        \"reference_message_id\": raw_message.reference.message_id\n        if raw_message.reference\n        else \"\",\n    }\n    if isinstance(raw_message.channel, discord.DMChannel):\n        return types.DirectMessage(**generic_args)\n    if isinstance(\n        raw_message.channel,\n        (\n            discord.TextChannel,\n            discord.GroupChannel,\n            discord.Thread,\n            discord.VoiceChannel,\n        ),\n    ):\n        return types.ChannelMessage(\n            mentions=[mention.id for mention in raw_message.mentions],\n            **generic_args,\n        )\n    fancy_logger.get().warning(\n        f\"Unknown channel type {type(raw_message.channel)}, \"\n        + f\"unsolicited replies disabled.: {raw_message.channel}\"\n    )\n    return types.GenericMessage(**generic_args)", "\ndef discord_message_to_generic_message(\n    raw_message: discord.Message,\n) -> typing.Union[types.GenericMessage, types.ChannelMessage, types.DirectMessage]:\n    \"\"\"\n    Convert a discord message to a GenericMessage or subclass thereof\n    \"\"\"\n    if raw_message.author.bot:\n        # address issue https://github.com/chrisrude/oobabot/issues/76\n        # If the bot is creating a formatted message, keep that formatting\n        # intact.\n        # Ideally, this would be nice to do for user messages as well,\n        # but if we allowed that then it would let a malicious user\n        # impersonate both the bot and other users.  So trust bots only.\n        body_text = raw_message.content\n    else:\n        body_text = sanitize_string(raw_message.content)\n\n    generic_args = {\n        \"author_id\": raw_message.author.id,\n        \"author_name\": sanitize_string(raw_message.author.display_name),\n        \"channel_id\": raw_message.channel.id,\n        \"channel_name\": get_channel_name(raw_message.channel),\n        \"message_id\": raw_message.id,\n        \"body_text\": body_text,\n        \"author_is_bot\": raw_message.author.bot,\n        \"send_timestamp\": raw_message.created_at.timestamp(),\n        \"reference_message_id\": raw_message.reference.message_id\n        if raw_message.reference\n        else \"\",\n    }\n    if isinstance(raw_message.channel, discord.DMChannel):\n        return types.DirectMessage(**generic_args)\n    if isinstance(\n        raw_message.channel,\n        (\n            discord.TextChannel,\n            discord.GroupChannel,\n            discord.Thread,\n            discord.VoiceChannel,\n        ),\n    ):\n        return types.ChannelMessage(\n            mentions=[mention.id for mention in raw_message.mentions],\n            **generic_args,\n        )\n    fancy_logger.get().warning(\n        f\"Unknown channel type {type(raw_message.channel)}, \"\n        + f\"unsolicited replies disabled.: {raw_message.channel}\"\n    )\n    return types.GenericMessage(**generic_args)", "\n\ndef replace_mention_ids_with_names(\n    generic_message: types.GenericMessage,\n    fn_user_id_to_name: typing.Callable[[\"re.Match[str]\"], str],\n):\n    \"\"\"\n    Replace user ID mentions with the user's chosen display\n    name in the given guild (aka server)\n    \"\"\"\n    # it looks like normal IDs are 18 digits.  But give it some\n    # wiggle room in case things change in the future.\n    # e.g.: <@009999999999999999>\n    at_mention_pattern = r\"<@(\\d{16,20})>\"\n    while True:\n        match = re.search(at_mention_pattern, generic_message.body_text)\n        if not match:\n            break\n        generic_message.body_text = (\n            generic_message.body_text[: match.start()]\n            + fn_user_id_to_name(match)\n            + generic_message.body_text[match.end() :]\n        )", "\n\ndef dm_user_id_to_name(\n    bot_user_id: int,\n    bot_name: str,\n) -> typing.Callable[[\"re.Match[str]\"], str]:\n    \"\"\"\n    Replace user ID mentions with the bot's name.  Used when\n    we are in a DM with the bot.\n    \"\"\"\n    if \" \" in bot_name:\n        bot_name = f'\"{bot_name}\"'\n\n    def _replace_user_id_mention(match: typing.Match[str]) -> str:\n        user_id = int(match.group(1))\n        print(f\"bot_user_id={bot_user_id}, user_id={user_id}\")\n        if user_id == bot_user_id:\n            return f\"@{bot_name}\"\n        return match.group(0)\n\n    return _replace_user_id_mention", "\n\ndef guild_user_id_to_name(\n    guild: discord.Guild,\n) -> typing.Callable[[\"re.Match[str]\"], str]:\n    def _replace_user_id_mention(match: typing.Match[str]) -> str:\n        user_id = int(match.group(1))\n        member = guild.get_member(user_id)\n        if member is None:\n            return match.group(0)\n        display_name = member.display_name\n        if \" \" in display_name:\n            display_name = f'\"{display_name}\"'\n        return f\"@{display_name}\"\n\n    return _replace_user_id_mention", "\n\ndef get_intents() -> discord.Intents:\n    intents = discord.Intents.default()\n    intents.message_content = True\n    intents.members = True\n    return intents\n\n\nasync def test_discord_token(discord_token: str) -> bool:\n    class _SimplestBot(discord.Client):\n        async def on_ready(self):\n            self.has_connected = True\n            await self.close()\n\n        def __init__(self):\n            super().__init__(intents=get_intents())\n            self.has_connected = False", "\nasync def test_discord_token(discord_token: str) -> bool:\n    class _SimplestBot(discord.Client):\n        async def on_ready(self):\n            self.has_connected = True\n            await self.close()\n\n        def __init__(self):\n            super().__init__(intents=get_intents())\n            self.has_connected = False", "\n    simplest_bot = _SimplestBot()\n    try:\n        await simplest_bot.start(discord_token, reconnect=False)\n    except discord.errors.ConnectionClosed as err:\n        # in theory, discord.errors.PrivilegedIntentsRequired\n        # should get fired in this case, but it doesn't\n        if err.code != 4014:\n            raise\n        fancy_logger.get().warning(\n            \"The bot token you provided does not have the required \"\n            + \"gateway intents.  Did you remember to enable both \"\n            + \"'SERVER MEMBERS INTENT' and 'MESSAGE CONTENT INTENT' \"\n            + \"in the bot's settings on Discord?\",\n        )\n        return False\n\n    except discord.LoginFailure:\n        return False\n    finally:\n        await simplest_bot.close()", "    return simplest_bot.has_connected\n\n\ndef get_user_id_from_token(discord_token: str) -> int:\n    \"\"\"\n    Extract the bot's user ID from the discord token.\n    \"\"\"\n\n    # turns out, the discord_token includes our client ID, so we can just\n    # extract it from there.\n    #\n    # the discord token has this format:\n    # AAAAAAAAAAAAAAAAAAAAAAAAAA.BBBBBB.CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n    #\n    # where each section, A, B, and C, is independently a base64-encoded string.\n    #\n    # Section A encodes the bot's client ID, which is the decimal encoding of\n    # a 64-bit number in the range [21154535154122752, 18446744073709551615]\n    # (17 to 20 digits long).\n    #\n    # The other sections aren't important here.\n    token_parts = discord_token.split(\".\")\n    token_part_a = token_parts[0]\n\n    # the base64 decoder requires the string to be a multiple of 4 characters\n    # long, so we need to add padding\n    if len(token_part_a) % 4 != 0:\n        token_part_a += \"=\" * (4 - len(token_part_a) % 4)\n\n    return int(base64.b64decode(token_part_a).decode(\"utf-8\"))", "\n\ndef generate_invite_url(ai_user_id: int) -> str:\n    # we want to generate a URL like this:\n    # https://discord.com/api/oauth2/authorize?client_id={client_id}&permissions={permissions}}&scope=bot\n    #\n    # where {client_id} is the bot's client ID, and {permissions} is the\n    # permissions bit array with our desired permissions set.\n\n    # for the permissions bit array, we can generate it with the library\n    permissions = discord.Permissions(\n        change_nickname=True,\n        send_messages=True,\n        create_public_threads=True,\n        send_messages_in_threads=True,\n        attach_files=True,\n        read_message_history=True,\n        read_messages=True,\n        add_reactions=True,\n    ).value\n\n    return (\n        \"https://discord.com/api/oauth2/authorize?client_id=\"\n        + f\"{ai_user_id}&permissions={permissions}&scope=bot\"\n    )", "\n\ndef setup_logging(**kwargs: typing.Any):\n    discord.utils.setup_logging(**kwargs)\n\n\nasync def fail_interaction(\n    interaction: discord.Interaction, reason: typing.Optional[str] = None\n):\n    command = \"unknown command\"\n    if interaction.command is not None:\n        command = interaction.command.name", "):\n    command = \"unknown command\"\n    if interaction.command is not None:\n        command = interaction.command.name\n\n    if reason is None:\n        reason = f\"{command} failed\"\n\n    fancy_logger.get().warning(\n        \"interaction failed: command='%s', user='%s', channel='%s', reason='%s'\",", "    fancy_logger.get().warning(\n        \"interaction failed: command='%s', user='%s', channel='%s', reason='%s'\",\n        command,\n        interaction.user,\n        interaction.channel,\n        reason,\n    )\n\n    await interaction.response.send_message(reason, ephemeral=True, silent=True)\n", "    await interaction.response.send_message(reason, ephemeral=True, silent=True)\n\n\ndef _file_exists_and_is_file(filepath: typing.Optional[str]) -> typing.Optional[str]:\n    if filepath is None:\n        return None\n\n    path = pathlib.Path(filepath).expanduser()\n    if not path.is_file():\n        return None\n\n    if not os.access(path, os.R_OK):\n        return None\n\n    return str(path.resolve())", "\n\ndef validate_discrivener_locations(\n    discrivener_location: str,\n    discrivener_model_location: str,\n) -> typing.Tuple[typing.Optional[str], typing.Optional[str]]:\n    \"\"\"\n    Verify that the file discrivener_location exists\n    and is a file.\n\n    If that passes, also checks that discrivener_model_location\n    exists and is a file.\n\n    Returns the expanded paths to each files if it exists,\n    or None if it doesn't.\n\n    Returns the tuple of these checks for the two passed files.\n    \"\"\"\n    actual_discrivener_location = _file_exists_and_is_file(discrivener_location)\n    # check that the discrivener binary is executable as well\n    if actual_discrivener_location is not None:\n        if not os.access(actual_discrivener_location, os.X_OK):\n            fancy_logger.get().warning(\n                \"discrivener binary is not executable: %s\",\n                actual_discrivener_location,\n            )\n            actual_discrivener_location = None\n\n    actual_model_location = _file_exists_and_is_file(discrivener_model_location)\n    return (actual_discrivener_location, actual_model_location)", "\n\n# the following class was modified from O'Reilly's Python Cookbook,\n# chapter 5, section 19.  Its use is allowed under this license:\n# Copyright (c) 2001, S\u00e9bastien Keim\n# All rights reserved.\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#    * Redistributions of source code must retain the above copyright", "# are met:\n#    * Redistributions of source code must retain the above copyright\n#      notice, this list of conditions and the following disclaimer.\n#    * Redistributions in binary form must reproduce the above\n#      copyright notice, this list of conditions and the following\n#      disclaimer in the documentation and/or other materials provided\n#      with the distribution.\n#    * Neither the name of the <ORGANIZATION> nor the names of its\n#      contributors may be used to endorse or promote products derived\n#      from this software without specific prior written permission.", "#      contributors may be used to endorse or promote products derived\n#      from this software without specific prior written permission.\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS\n# OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,", "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR\n# OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nT = typing.TypeVar(\"T\")\nS = typing.TypeVar(\"S\")\n\n\nclass RingBuffer(typing.Generic[T]):\n    \"\"\"\n    A generic ring buffer.\n    \"\"\"\n\n    def __init__(self, size_max: int):\n        self.cur = 0\n        self.max = size_max\n        self.data: typing.List[T] = []\n\n    class _FullRingBuffer(typing.Generic[S]):\n        \"\"\"\n        Class implementing the RingBuffer when it's full.\n        With python class magic, this class is swapped in when the\n        buffer becomes full.\n        \"\"\"\n\n        cur: int\n        max: int\n        data: typing.List[S]\n\n        def append(self, val: S) -> None:\n            \"\"\"\n            Append an element overwriting the oldest one.\n            \"\"\"\n            self.data[self.cur] = val\n            self.cur = (self.cur + 1) % self.max\n\n        def get(self) -> typing.List[S]:\n            \"\"\"\n            Return a list of elements from the oldest to the newest.\n            \"\"\"\n            return self.data[self.cur :] + self.data[: self.cur]\n\n        def size(self) -> int:\n            \"\"\"\n            Return the size of the buffer.\n            \"\"\"\n            return self.max\n\n    def append(self, val: T) -> None:\n        \"\"\"\n        Append an element at the end of the buffer.\n        \"\"\"\n        self.data.append(val)\n        if len(self.data) == self.max:\n            self.cur = 0\n            # Permanently change self's class from non-full to full\n            self.__class__ = self._FullRingBuffer\n\n    def get(self) -> typing.List[T]:\n        \"\"\"\n        Return a list of elements from the oldest to the newest.\n        \"\"\"\n        return self.data\n\n    def size(self) -> int:\n        \"\"\"\n        Return the number of elements currently in the buffer.\n        \"\"\"\n        return len(self.data)", "\n\nclass RingBuffer(typing.Generic[T]):\n    \"\"\"\n    A generic ring buffer.\n    \"\"\"\n\n    def __init__(self, size_max: int):\n        self.cur = 0\n        self.max = size_max\n        self.data: typing.List[T] = []\n\n    class _FullRingBuffer(typing.Generic[S]):\n        \"\"\"\n        Class implementing the RingBuffer when it's full.\n        With python class magic, this class is swapped in when the\n        buffer becomes full.\n        \"\"\"\n\n        cur: int\n        max: int\n        data: typing.List[S]\n\n        def append(self, val: S) -> None:\n            \"\"\"\n            Append an element overwriting the oldest one.\n            \"\"\"\n            self.data[self.cur] = val\n            self.cur = (self.cur + 1) % self.max\n\n        def get(self) -> typing.List[S]:\n            \"\"\"\n            Return a list of elements from the oldest to the newest.\n            \"\"\"\n            return self.data[self.cur :] + self.data[: self.cur]\n\n        def size(self) -> int:\n            \"\"\"\n            Return the size of the buffer.\n            \"\"\"\n            return self.max\n\n    def append(self, val: T) -> None:\n        \"\"\"\n        Append an element at the end of the buffer.\n        \"\"\"\n        self.data.append(val)\n        if len(self.data) == self.max:\n            self.cur = 0\n            # Permanently change self's class from non-full to full\n            self.__class__ = self._FullRingBuffer\n\n    def get(self) -> typing.List[T]:\n        \"\"\"\n        Return a list of elements from the oldest to the newest.\n        \"\"\"\n        return self.data\n\n    def size(self) -> int:\n        \"\"\"\n        Return the number of elements currently in the buffer.\n        \"\"\"\n        return len(self.data)", "\n\n# end of O'Reilly code\n\n\n@functools.lru_cache\ndef author_from_user_id(\n    user_id: int,\n    guild: discord.Guild,\n) -> typing.Optional[\"types.FancyAuthor\"]:\n    member = guild.get_member(user_id)\n    if member is None:\n        return None\n    if member.avatar:\n        avatar_url = member.avatar.url\n    else:\n        avatar_url = None\n    if member.accent_color:\n        accent_color = member.accent_color.to_rgb()\n    else:\n        accent_color = (0, 0, 0)\n    return types.FancyAuthor(\n        user_id=user_id,\n        author_is_bot=member.bot,\n        author_name=member.display_name,\n        author_accent_color=accent_color,\n        author_avatar_url=avatar_url,\n    )", ""]}
{"filename": "src/oobabot/repetition_tracker.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nDetects when the bot is repeating previous messages, and attempts\nto fix this by hiding the messages that it's repeating from its view\nof the chat history.\n\nIs also used to implement the /lobotomize command, which is the same\nthing except it's triggered by a command instead of automatically.\n\"\"\"\nimport typing", "\"\"\"\nimport typing\n\nfrom oobabot import fancy_logger\nfrom oobabot import types\n\n\nclass RepetitionTracker:\n    \"\"\"\n    Tracks the last message the bot posted in each channel, and\n    the number of times in a row it has been repeated.\n    \"\"\"\n\n    def __init__(self, repetition_threshold: int) -> None:\n        self.repetition_threshold = repetition_threshold\n\n        # stores a map of channel_id ->\n        #   (last_message, throttle_message_id, repetition_count)\n\n        self.repetition_count: typing.Dict[int, typing.Tuple[str, int, int]] = {}\n\n    def get_throttle_message_id(self, channel_id: int) -> int:\n        \"\"\"\n        Returns the message ID of the last message that should be throttled, or 0\n        if no throttling is needed\n        \"\"\"\n        _, throttle_message_id, _ = self.repetition_count.get(\n            channel_id, (None, 0, None)\n        )\n        return throttle_message_id\n\n    def log_message(\n        self, channel_id: int, response_message: types.GenericMessage\n    ) -> None:\n        \"\"\"\n        Logs a message sent by the bot, to be used for repetition tracking\n        \"\"\"\n        # make string into canonical form\n        sentence = self.make_canonical(response_message.body_text)\n\n        last_message, throttle_message_id, repetition_count = self.repetition_count.get(\n            channel_id, (\"\", 0, 0)\n        )\n        if last_message == sentence:\n            repetition_count += 1\n        else:\n            repetition_count = 0\n\n        if repetition_count > 0:\n            fancy_logger.get().debug(\n                \"Repetition count for channel %d is %d\", channel_id, repetition_count\n            )\n\n        if self.should_throttle(repetition_count):\n            fancy_logger.get().warning(\n                \"Repetition found, will throttle history for channel #%d \"\n                + \"in next request\",\n                channel_id,\n            )\n            throttle_message_id = response_message.message_id\n\n        self.repetition_count[channel_id] = (\n            sentence,\n            throttle_message_id,\n            repetition_count,\n        )\n\n    def hide_messages_before(self, channel_id: int, message_id: int) -> None:\n        \"\"\"\n        Hides all messages before the given message ID in the given channel\n        \"\"\"\n        sentence, _, repetition_count = self.repetition_count.get(\n            channel_id, (\"\", 0, 0)\n        )\n        fancy_logger.get().info(\n            \"Hiding messages before message ID %d in channel %d\", message_id, channel_id\n        )\n        self.repetition_count[channel_id] = (sentence, message_id, repetition_count)\n\n    def should_throttle(self, repetition_count: int) -> bool:\n        \"\"\"\n        Returns whether the bot should throttle history for a given repetition count\n        \"\"\"\n        return repetition_count >= self.repetition_threshold\n\n    def make_canonical(self, content: str) -> str:\n        return content.strip().lower()", ""]}
{"filename": "src/oobabot/audio_commands.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nImplementation of commands to join and leave voice channels.\n\"\"\"\nimport typing\n\nimport discord\n\nfrom oobabot import discord_utils\nfrom oobabot import fancy_logger", "from oobabot import discord_utils\nfrom oobabot import fancy_logger\nfrom oobabot import ooba_client\nfrom oobabot import persona\nfrom oobabot import prompt_generator\nfrom oobabot import voice_client\n\n\nclass AudioCommands:\n    \"\"\"\n    Implementation of commands to join and leave voice channels.\n    \"\"\"\n\n    def __init__(\n        self,\n        persona: persona.Persona,\n        ooba_client: ooba_client.OobaClient,\n        prompt_generator: prompt_generator.PromptGenerator,\n        discrivener_location: str,\n        discrivener_model_location: str,\n    ):\n        voice_client.VoiceClient.wakewords = persona.wakewords\n\n        self.discrivener_location = discrivener_location\n        self.persona = persona\n        self.voice_client: typing.Optional[voice_client.VoiceClient] = None\n\n        voice_client.VoiceClient.discrivener_location = discrivener_location\n        voice_client.VoiceClient.discrivener_model_location = discrivener_model_location\n        voice_client.VoiceClient.ooba_client = ooba_client\n        voice_client.VoiceClient.prompt_generator = prompt_generator\n\n    def _discover_voice_channel(\n        self, interaction: discord.Interaction\n    ) -> typing.Optional[discord.VoiceChannel]:\n        if isinstance(interaction.user, discord.Member):\n            # if invoked from a guild channel, join the voice channel\n            # the invoker is in, within that guild\n            if (\n                interaction.user.voice is not None\n                and interaction.user.voice.channel is not None\n                and isinstance(interaction.user.voice.channel, discord.VoiceChannel)\n            ):\n                return interaction.user.voice.channel\n\n        # if invoked from a private message, look at all guilds\n        # which have both the bot and the invoking user as a member,\n        # find find the first such guild where the user is in a voice\n        # channel.\n        for guild in interaction.user.mutual_guilds:\n            # get member of guild\n            member = guild.get_member(interaction.user.id)\n            if (\n                member is not None\n                and member.voice is not None\n                and member.voice.channel is not None\n                and isinstance(member.voice.channel, discord.VoiceChannel)\n            ):\n                return member.voice.channel\n        return None\n\n    def add_commands(self, tree):\n        @discord.app_commands.command(\n            name=\"join_voice\",\n            description=f\"Have {self.persona.ai_name} join the voice \"\n            + \"channel you are in right now.\",\n        )\n        async def join_voice(interaction: discord.Interaction):\n            if interaction.user is None:\n                await discord_utils.fail_interaction(interaction)\n\n            fancy_logger.get().debug(\n                \"/join_voice called by user '%s'\", interaction.user.name\n            )\n\n            voice_channel = self._discover_voice_channel(interaction)\n            if voice_channel is None:\n                await discord_utils.fail_interaction(\n                    interaction, \"You must be in a voice channel to use this command\"\n                )\n                return\n\n            # are we already connected to a voice channel?  If so, disconnect\n            if self.voice_client is not None:\n                fancy_logger.get().debug(\n                    \"disconnecting from voice channel #%s\", self.voice_client.channel\n                )\n                await self.voice_client.disconnect()\n                self.voice_client = None\n\n            await interaction.response.defer(\n                ephemeral=True,\n                thinking=True,\n            )\n\n            try:\n                self.voice_client = await voice_channel.connect(\n                    cls=voice_client.VoiceClient,\n                )\n                message = f\"Joined voice channel #{voice_channel.name}\"\n            except discord.DiscordException as err:\n                fancy_logger.get().error(\n                    \"Failed to connect to voice channel #%d: %s\", voice_channel.id, err\n                )\n                message = (\n                    f\"Failed to connect to voice channel #{voice_channel.name}: {err}\"\n                )\n                return\n\n            await interaction.followup.send(message)\n\n        @discord.app_commands.command(\n            name=\"leave_voice\",\n            description=f\"Have {self.persona.ai_name} leave the \"\n            + \"voice channel it is in.\",\n        )\n        async def leave_voice(interaction: discord.Interaction):\n            if interaction.user is None:\n                await discord_utils.fail_interaction(interaction)\n\n            fancy_logger.get().debug(\n                \"/leave_voice called by user: '%s'\", interaction.user.name\n            )\n\n            # are we already connected to a voice channel?  If so, disconnect\n            if self.voice_client is None:\n                await discord_utils.fail_interaction(\n                    interaction, \"Not connected to a voice channel\"\n                )\n                return\n\n            channel = self.voice_client.channel\n\n            fancy_logger.get().debug(\"leaving voice channel #%s\", channel)\n\n            await self.voice_client.disconnect()\n            self.voice_client = None\n\n            await interaction.response.send_message(\n                \"Left voice channel\",\n                ephemeral=True,\n                silent=True,\n            )\n\n        fancy_logger.get().debug(\"Registering audio commands\")\n        tree.add_command(join_voice)\n        tree.add_command(leave_voice)", "class AudioCommands:\n    \"\"\"\n    Implementation of commands to join and leave voice channels.\n    \"\"\"\n\n    def __init__(\n        self,\n        persona: persona.Persona,\n        ooba_client: ooba_client.OobaClient,\n        prompt_generator: prompt_generator.PromptGenerator,\n        discrivener_location: str,\n        discrivener_model_location: str,\n    ):\n        voice_client.VoiceClient.wakewords = persona.wakewords\n\n        self.discrivener_location = discrivener_location\n        self.persona = persona\n        self.voice_client: typing.Optional[voice_client.VoiceClient] = None\n\n        voice_client.VoiceClient.discrivener_location = discrivener_location\n        voice_client.VoiceClient.discrivener_model_location = discrivener_model_location\n        voice_client.VoiceClient.ooba_client = ooba_client\n        voice_client.VoiceClient.prompt_generator = prompt_generator\n\n    def _discover_voice_channel(\n        self, interaction: discord.Interaction\n    ) -> typing.Optional[discord.VoiceChannel]:\n        if isinstance(interaction.user, discord.Member):\n            # if invoked from a guild channel, join the voice channel\n            # the invoker is in, within that guild\n            if (\n                interaction.user.voice is not None\n                and interaction.user.voice.channel is not None\n                and isinstance(interaction.user.voice.channel, discord.VoiceChannel)\n            ):\n                return interaction.user.voice.channel\n\n        # if invoked from a private message, look at all guilds\n        # which have both the bot and the invoking user as a member,\n        # find find the first such guild where the user is in a voice\n        # channel.\n        for guild in interaction.user.mutual_guilds:\n            # get member of guild\n            member = guild.get_member(interaction.user.id)\n            if (\n                member is not None\n                and member.voice is not None\n                and member.voice.channel is not None\n                and isinstance(member.voice.channel, discord.VoiceChannel)\n            ):\n                return member.voice.channel\n        return None\n\n    def add_commands(self, tree):\n        @discord.app_commands.command(\n            name=\"join_voice\",\n            description=f\"Have {self.persona.ai_name} join the voice \"\n            + \"channel you are in right now.\",\n        )\n        async def join_voice(interaction: discord.Interaction):\n            if interaction.user is None:\n                await discord_utils.fail_interaction(interaction)\n\n            fancy_logger.get().debug(\n                \"/join_voice called by user '%s'\", interaction.user.name\n            )\n\n            voice_channel = self._discover_voice_channel(interaction)\n            if voice_channel is None:\n                await discord_utils.fail_interaction(\n                    interaction, \"You must be in a voice channel to use this command\"\n                )\n                return\n\n            # are we already connected to a voice channel?  If so, disconnect\n            if self.voice_client is not None:\n                fancy_logger.get().debug(\n                    \"disconnecting from voice channel #%s\", self.voice_client.channel\n                )\n                await self.voice_client.disconnect()\n                self.voice_client = None\n\n            await interaction.response.defer(\n                ephemeral=True,\n                thinking=True,\n            )\n\n            try:\n                self.voice_client = await voice_channel.connect(\n                    cls=voice_client.VoiceClient,\n                )\n                message = f\"Joined voice channel #{voice_channel.name}\"\n            except discord.DiscordException as err:\n                fancy_logger.get().error(\n                    \"Failed to connect to voice channel #%d: %s\", voice_channel.id, err\n                )\n                message = (\n                    f\"Failed to connect to voice channel #{voice_channel.name}: {err}\"\n                )\n                return\n\n            await interaction.followup.send(message)\n\n        @discord.app_commands.command(\n            name=\"leave_voice\",\n            description=f\"Have {self.persona.ai_name} leave the \"\n            + \"voice channel it is in.\",\n        )\n        async def leave_voice(interaction: discord.Interaction):\n            if interaction.user is None:\n                await discord_utils.fail_interaction(interaction)\n\n            fancy_logger.get().debug(\n                \"/leave_voice called by user: '%s'\", interaction.user.name\n            )\n\n            # are we already connected to a voice channel?  If so, disconnect\n            if self.voice_client is None:\n                await discord_utils.fail_interaction(\n                    interaction, \"Not connected to a voice channel\"\n                )\n                return\n\n            channel = self.voice_client.channel\n\n            fancy_logger.get().debug(\"leaving voice channel #%s\", channel)\n\n            await self.voice_client.disconnect()\n            self.voice_client = None\n\n            await interaction.response.send_message(\n                \"Left voice channel\",\n                ephemeral=True,\n                silent=True,\n            )\n\n        fancy_logger.get().debug(\"Registering audio commands\")\n        tree.add_command(join_voice)\n        tree.add_command(leave_voice)", ""]}
{"filename": "src/oobabot/ooba_client.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nClient for the Ooba API.\nCan provide the response by token or by sentence.\n\"\"\"\nimport abc\nimport json\nimport re\nimport time\nimport typing", "import time\nimport typing\n\nimport aiohttp\nimport pysbd\nimport pysbd.utils\n\nfrom oobabot import fancy_logger\nfrom oobabot import http_client\n", "from oobabot import http_client\n\n\nclass MessageSplitter(abc.ABC):\n    \"\"\"\n    Split a response into separate messages.\n    \"\"\"\n\n    # anything that can't be in a real response\n    END_OF_INPUT = \"\"\n\n    def __init__(self):\n        self.printed_idx = 0\n        self.full_response = \"\"\n\n    def next(self, new_token: str) -> typing.Generator[str, None, None]:\n        \"\"\"\n        Collects tokens into a single string, splits into messages\n        by the subclass's logic, then yields each message as soon\n        as it's found.\n\n        Parameters:\n            new_token: str, the next token to add to the string\n\n        Returns:\n            Generator[str, None, None], yields each sentence\n\n        Note:\n        When there is no longer any input, the caller must pass\n        MessageSplitter.END_OF_INPUT to this function.  This\n        function will then yield any remaining text, even if it\n        doesn't look like a full sentence.\n        \"\"\"\n\n        self.full_response += new_token\n        unseen = self.full_response[self.printed_idx :]\n\n        # if we've reached the end of input, yield it all,\n        # even if we don't think it's a full sentence.\n        if self.END_OF_INPUT == new_token:\n            to_print = unseen.strip()\n            if to_print:\n                yield unseen\n            self.printed_idx += len(unseen)\n            return\n\n        yield from self.partition(unseen)\n\n    @abc.abstractmethod\n    def partition(self, unseen: str) -> typing.Generator[str, None, None]:\n        pass", "\n\nclass RegexSplitter(MessageSplitter):\n    \"\"\"\n    Split a response into separate messages using a regex.\n    \"\"\"\n\n    def __init__(self, regex: str):\n        super().__init__()\n        self.pattern = re.compile(regex)\n\n    def partition(self, unseen: str) -> typing.Generator[str, None, None]:\n        while True:\n            match = self.pattern.match(unseen)\n            if not match:\n                break\n            to_print = match.group(1)\n            yield to_print\n            self.printed_idx += match.end()\n            unseen = self.full_response[self.printed_idx :]", "\n\nclass SentenceSplitter(MessageSplitter):\n    \"\"\"\n    Split a response into separate messages using English\n    sentence word breaks.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.segmenter = pysbd.Segmenter(language=\"en\", clean=False, char_span=True)\n\n    def partition(self, unseen: str) -> typing.Generator[str, None, None]:\n        segments: typing.List[pysbd.utils.TextSpan] = self.segmenter.segment(\n            unseen\n        )  # type: ignore -- type is determined by char_span=True above\n\n        # any remaining non-sentence things will be in the last element\n        # of the list.  Don't print that yet.  At the very worst, we'll\n        # print it when the END_OF_INPUT signal is reached.\n        for sentence_w_char_spans in segments[:-1]:\n            # sentence_w_char_spans is a class with the following fields:\n            #  - sent: str, sentence text\n            #  - start: start idx of 'sent', relative to original string\n            #  - end: end idx of 'sent', relative to original string\n            #\n            # we want to remove the last '\\n' if there is one.\n            # we do want to include any other whitespace, though.\n\n            to_print = sentence_w_char_spans.sent  # type: ignore\n            if to_print.endswith(\"\\n\"):\n                to_print = to_print[:-1]\n\n            yield to_print\n\n        # since we've printed all the previous segments,\n        # the start of the last segment becomes the starting\n        # point for the next round.\n        if len(segments) > 0:\n            self.printed_idx += segments[-1].start  # type: ignore", "\n\nclass OobaClient(http_client.SerializedHttpClient):\n    \"\"\"\n    Client for the Ooba API.  Can provide the response by token or by sentence.\n    \"\"\"\n\n    SERVICE_NAME = \"Oobabooga\"\n\n    OOBABOOGA_STREAMING_URI_PATH: str = \"/api/v1/stream\"\n\n    def __init__(\n        self,\n        settings: typing.Dict[str, typing.Any],\n    ):\n        super().__init__(self.SERVICE_NAME, settings[\"base_url\"])\n        self.total_response_tokens = 0\n        self.message_regex = settings[\"message_regex\"]\n        self.request_params = settings[\"request_params\"]\n        self.log_all_the_things = settings[\"log_all_the_things\"]\n\n        if self.message_regex:\n            self.fn_new_splitter = lambda: RegexSplitter(self.message_regex)\n        else:\n            self.fn_new_splitter = SentenceSplitter\n\n    def on_ready(self):\n        \"\"\"\n        Called when the client is ready to start.\n        Used to log our configuration.\n        \"\"\"\n        if self.message_regex:\n            fancy_logger.get().debug(\n                \"Ooba Client: Splitting responses into messages \" + \"with: %s\",\n                self.message_regex,\n            )\n        else:\n            fancy_logger.get().debug(\n                \"Ooba Client: Splitting responses into messages \"\n                + \"by English sentence.\",\n            )\n\n    async def _setup(self):\n        async with self._get_session().ws_connect(self.OOBABOOGA_STREAMING_URI_PATH):\n            return\n\n    def get_stopping_strings(self) -> typing.List[str]:\n        \"\"\"\n        Returns a list of strings that indicate the end of a response.\n        Taken from the yaml `stopping_strings` within our\n        response_params.\n        \"\"\"\n        return self.request_params.get(\"stopping_strings\", [])\n\n    async def request_by_message(self, prompt: str) -> typing.AsyncIterator[str]:\n        \"\"\"\n        Yields individual messages from the response as it arrives.\n        These can be split by a regex or by sentence.\n        \"\"\"\n        splitter = self.fn_new_splitter()\n        async for new_token in self.request_by_token(prompt):\n            for sentence in splitter.next(new_token):\n                # remove \"### Assistant: \" from strings\n                if sentence.startswith(\"### Assistant: \"):\n                    sentence = sentence[len(\"### Assistant: \") :]\n                yield sentence\n\n    async def request_as_string(self, prompt: str) -> str:\n        \"\"\"\n        Yields the entire response as a single string.\n        \"\"\"\n        return \"\".join([token async for token in self.request_by_token(prompt)])\n\n    async def request_as_grouped_tokens(\n        self,\n        prompt: str,\n        interval: float = 0.2,\n    ) -> typing.AsyncIterator[str]:\n        \"\"\"\n        Yields the response as a series of tokens, grouped by time.\n        \"\"\"\n\n        last_response = time.perf_counter()\n        tokens = \"\"\n        async for token in self.request_by_token(prompt):\n            if token == SentenceSplitter.END_OF_INPUT:\n                if tokens:\n                    yield tokens\n                break\n            tokens += token\n            now = time.perf_counter()\n            if now < (last_response + interval):\n                continue\n            yield tokens\n            tokens = \"\"\n            last_response = time.perf_counter()\n\n    async def request_by_token(self, prompt: str) -> typing.AsyncIterator[str]:\n        \"\"\"\n        Yields each token of the response as it arrives.\n        \"\"\"\n\n        request: dict[\n            str, typing.Union[bool, float, int, str, typing.List[typing.Any]]\n        ] = {\n            \"prompt\": prompt,\n        }\n        request.update(self.request_params)\n\n        async with self._get_session().ws_connect(\n            self.OOBABOOGA_STREAMING_URI_PATH\n        ) as websocket:\n            await websocket.send_json(request)\n            if self.log_all_the_things:\n                try:\n                    print(f\"Sent request:\\n{json.dumps(request, indent=1)}\")\n                    print(f\"Prompt:\\n{str(request['prompt'])}\")\n                except UnicodeEncodeError:\n                    print(\n                        \"Sent request:\\n\"\n                        + f\"{json.dumps(request, indent=1).encode('utf-8')}\"\n                    )\n                    print(f\"Prompt:\\n{str(request['prompt']).encode('utf-8')}\")\n\n            async for msg in websocket:\n                # we expect a series of text messages in JSON encoding,\n                # like this:\n                #\n                # {\"event\": \"text_stream\", \"message_num\": 0, \"text\": \"\"}\n                # {\"event\": \"text_stream\", \"message_num\": 1, \"text\": \"Oh\"}\n                # {\"event\": \"text_stream\", \"message_num\": 2, \"text\": \",\"}\n                # {\"event\": \"text_stream\", \"message_num\": 3, \"text\": \" okay\"}\n                # {\"event\": \"text_stream\", \"message_num\": 4, \"text\": \".\"}\n                # {\"event\": \"stream_end\", \"message_num\": 5}\n                if msg.type == aiohttp.WSMsgType.TEXT:\n                    # bdata = typing.cast(bytes, msg.data)\n                    # get_logger().debug(f\"Received data: {bdata}\")\n\n                    incoming_data = msg.json()\n                    if \"text_stream\" == incoming_data[\"event\"]:\n                        self.total_response_tokens += 1\n                        text = incoming_data[\"text\"]\n                        if text != SentenceSplitter.END_OF_INPUT:\n                            if self.log_all_the_things:\n                                try:\n                                    print(text, end=\"\", flush=True)\n                                except UnicodeEncodeError:\n                                    print(text.encode(\"utf-8\"), end=\"\", flush=True)\n\n                            yield text\n\n                    elif \"stream_end\" == incoming_data[\"event\"]:\n                        # Make sure any unprinted text is flushed.\n                        if self.log_all_the_things:\n                            print(\"\", flush=True)\n                        yield SentenceSplitter.END_OF_INPUT\n                        return\n\n                    else:\n                        fancy_logger.get().warning(\n                            \"Unexpected event: %s\", incoming_data\n                        )\n\n                elif msg.type == aiohttp.WSMsgType.ERROR:\n                    fancy_logger.get().error(\n                        \"WebSocket connection closed with error: %s\", msg\n                    )\n                    raise http_client.OobaHttpClientError(\n                        f\"WebSocket connection closed with error {msg}\"\n                    )\n                elif msg.type == aiohttp.WSMsgType.CLOSED:\n                    fancy_logger.get().info(\n                        \"WebSocket connection closed normally: %s\", msg\n                    )\n                    return", ""]}
{"filename": "src/oobabot/image_generator.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nGenerates images from Stable Diffusion\n\"\"\"\n\nimport asyncio\nimport io\nimport re\nimport typing\n", "import typing\n\nimport discord\n\nfrom oobabot import fancy_logger\nfrom oobabot import http_client\nfrom oobabot import ooba_client\nfrom oobabot import prompt_generator\nfrom oobabot import sd_client\nfrom oobabot import templates", "from oobabot import sd_client\nfrom oobabot import templates\n\n\nasync def image_task_to_file(image_task: \"asyncio.Task[bytes]\", image_request: str):\n    await image_task\n    img_bytes = image_task.result()\n    file_of_bytes = io.BytesIO(img_bytes)\n    file = discord.File(file_of_bytes)\n    file.filename = \"photo.png\"", "    file = discord.File(file_of_bytes)\n    file.filename = \"photo.png\"\n    file.description = f\"image generated from '{image_request}'\"\n    return file\n\n\nclass StableDiffusionImageView(discord.ui.View):\n    \"\"\"\n    A View that displays buttons to regenerate an image\n    from Stable Diffusion with a new seed, or to lock\n    in the current image.\n    \"\"\"\n\n    LABEL_ACCEPT = \"Accept\"\n    LABEL_DELETE = \"Delete\"\n\n    # these two phrases (along with exactly two periods)\n    # in \"Drawing..\" were chosen because they render at\n    # the exact same width as each other.  If they don't,\n    # the buttons will shift to the left and right as the\n    # labels are swapped.\n    LABEL_TRY_AGAIN = \"Try Again\"\n    LABEL_DRAWING = \"Drawing..\"\n\n    def __init__(\n        self,\n        stable_diffusion_client: sd_client.StableDiffusionClient,\n        is_channel_nsfw: bool,\n        image_prompt: str,\n        requesting_user_id: int,\n        requesting_user_name: str,\n        template_store: templates.TemplateStore,\n    ):\n        super().__init__(timeout=120.0)\n\n        self.template_store = template_store\n\n        # only the user who requested generation of the image\n        # can have it replaced\n        self.requesting_user_id = requesting_user_id\n        self.requesting_user_name = requesting_user_name\n        self.image_prompt = image_prompt\n        self.photo_accepted = False\n\n        #####################################################\n        # \"Try Again\" button\n        #\n        btn_try_again = discord.ui.Button(\n            label=self.LABEL_TRY_AGAIN,\n            style=discord.ButtonStyle.blurple,\n            row=1,\n        )\n        self.image_message = None\n\n        async def on_try_again(interaction: discord.Interaction):\n            result = await self.diy_interaction_check(interaction)\n            if not result:\n                # unauthorized user\n                return\n\n            try:\n                btn_try_again.label = self.LABEL_DRAWING\n\n                # we disable all three buttons because otherwise\n                # the lock_in and delete buttons will flicker\n                # when we disable the try_again button.  And it\n                # doesn't make much sense for them to work anyway\n                # when the button is being regenerated.\n                btn_try_again.disabled = True\n                btn_lock_in.disabled = True\n                btn_delete.disabled = True\n\n                await interaction.response.defer()\n                await self.get_image_message().edit(view=self)\n\n                # generate a new image\n                regen_task = stable_diffusion_client.generate_image(\n                    image_prompt, is_channel_nsfw\n                )\n                regen_file = await image_task_to_file(regen_task, image_prompt)\n\n                btn_try_again.label = self.LABEL_TRY_AGAIN\n                btn_try_again.disabled = False\n                btn_lock_in.disabled = False\n                btn_delete.disabled = False\n\n                await self.get_image_message().edit(attachments=[regen_file], view=self)\n            except (http_client.OobaHttpClientError, discord.DiscordException) as err:\n                fancy_logger.get().error(\n                    \"Could not regenerate image: %s\", err, exc_info=True\n                )\n\n        btn_try_again.callback = on_try_again\n\n        #####################################################\n        # \"Accept\" button\n        #\n        btn_lock_in = discord.ui.Button(\n            label=self.LABEL_ACCEPT,\n            style=discord.ButtonStyle.success,\n            row=1,\n        )\n\n        async def on_lock_in(interaction: discord.Interaction):\n            result = await self.diy_interaction_check(interaction)\n            if not result:\n                # unauthorized user\n                return\n            await interaction.response.defer()\n            await self.detach_view_keep_img()\n\n        btn_lock_in.callback = on_lock_in\n\n        #####################################################\n        # \"Delete\" button\n        #\n        btn_delete = discord.ui.Button(\n            label=self.LABEL_DELETE,\n            style=discord.ButtonStyle.danger,\n            row=1,\n        )\n\n        async def on_delete(interaction: discord.Interaction):\n            result = await self.diy_interaction_check(interaction)\n            if not result:\n                # unauthorized user\n                return\n            await interaction.response.defer()\n            await self.delete_image()\n\n        btn_delete.callback = on_delete\n\n        super().add_item(btn_try_again).add_item(btn_lock_in).add_item(btn_delete)\n\n    def set_image_message(self, image_message: discord.Message):\n        self.image_message = image_message\n\n    def get_image_message(self) -> discord.Message:\n        if self.image_message is None:\n            raise ValueError(\"image_message is None\")\n        return self.image_message\n\n    async def delete_image(self):\n        await self.detach_view_delete_img(self.get_detach_message())\n\n    async def detach_view_delete_img(self, detach_msg: str):\n        await self.get_image_message().edit(\n            content=detach_msg,\n            view=None,\n            attachments=[],\n        )\n\n    async def detach_view_keep_img(self):\n        self.photo_accepted = True\n        await self.get_image_message().edit(\n            content=None,\n            view=None,\n        )\n\n    async def on_timeout(self):\n        if not self.photo_accepted:\n            await self.delete_image()\n\n    async def diy_interaction_check(self, interaction: discord.Interaction) -> bool:\n        \"\"\"\n        Only allow the requesting user to interact with this view.\n        \"\"\"\n        if interaction.user.id == self.requesting_user_id:\n            return True\n        error_message = self._get_message(templates.Templates.IMAGE_UNAUTHORIZED)\n        await interaction.response.send_message(\n            content=error_message,\n            ephemeral=True,\n        )\n        return False\n\n    def get_image_message_text(self) -> str:\n        return self._get_message(templates.Templates.IMAGE_CONFIRMATION)\n\n    def get_detach_message(self) -> str:\n        return self._get_message(templates.Templates.IMAGE_DETACH)\n\n    def _get_message(self, message_type: templates.Templates) -> str:\n        return self.template_store.format(\n            message_type,\n            {\n                templates.TemplateToken.USER_NAME: self.requesting_user_name,\n                templates.TemplateToken.IMAGE_PROMPT: self.image_prompt,\n            },\n        )", "\n\nclass ImageGenerator:\n    \"\"\"\n    Generates images from a given prompt, and posts that image as a\n    message to a given channel.\n    \"\"\"\n\n    # if a potential image prompt is shorter than this, we will\n    # conclude that it is not an image prompt.\n    MIN_IMAGE_PROMPT_LENGTH = 3\n\n    def __init__(\n        self,\n        ooba_client: ooba_client.OobaClient,\n        persona_settings: typing.Dict[str, typing.Any],\n        prompt_generator: prompt_generator.PromptGenerator,\n        sd_settings: typing.Dict[str, typing.Any],\n        stable_diffusion_client: sd_client.StableDiffusionClient,\n        template_store: templates.TemplateStore,\n    ):\n        self.ai_name = persona_settings.get(\"ai_name\", \"\")\n        self.ooba_client = ooba_client\n        self.image_words = sd_settings.get(\"image_words\", [])\n        self.prompt_generator = prompt_generator\n        self.stable_diffusion_client = stable_diffusion_client\n        self.template_store = template_store\n\n        self.image_patterns = [\n            re.compile(\n                r\"^.*\\b\" + image_word + r\"\\b[\\s]*(of|with)?[\\s]*[:]?(.*)$\",\n                re.IGNORECASE,\n            )\n            for image_word in self.image_words\n        ]\n\n    def on_ready(self):\n        \"\"\"\n        Called when the bot is connected to Discord.\n        \"\"\"\n        fancy_logger.get().debug(\n            \"Stable Diffusion: image keywords: %s\",\n            \", \".join(self.image_words),\n        )\n\n    # @fancy_logger.log_async_task\n    async def _generate_image(\n        self,\n        image_prompt: str,\n        raw_message: discord.Message,\n        response_channel: discord.abc.Messageable,\n    ) -> discord.Message:\n        is_channel_nsfw = False\n\n        # note: public threads in NSFW channels are not considered here\n        if isinstance(raw_message.channel, discord.TextChannel):\n            is_channel_nsfw = raw_message.channel.is_nsfw()\n\n        image_task = self.stable_diffusion_client.generate_image(\n            image_prompt, is_channel_nsfw=is_channel_nsfw\n        )\n        try:\n            file = await image_task_to_file(image_task, image_prompt)\n        except (http_client.OobaHttpClientError, discord.DiscordException) as err:\n            fancy_logger.get().error(\"Could not generate image: %s\", err, exc_info=True)\n            error_message = self.template_store.format(\n                templates.Templates.IMAGE_GENERATION_ERROR,\n                {\n                    templates.TemplateToken.USER_NAME: raw_message.author.display_name,\n                    templates.TemplateToken.IMAGE_PROMPT: image_prompt,\n                },\n            )\n            return await response_channel.send(error_message, reference=raw_message)\n\n        regen_view = StableDiffusionImageView(\n            self.stable_diffusion_client,\n            is_channel_nsfw=is_channel_nsfw,\n            image_prompt=image_prompt,\n            requesting_user_id=raw_message.author.id,\n            requesting_user_name=raw_message.author.display_name,\n            template_store=self.template_store,\n        )\n\n        kwargs = {}\n        # we can only pass a reference if the message is in the same channel\n        # as the original request.  Also, send() won't take None of this\n        # argument, so we need to conditionally add it.\n        if raw_message.channel == response_channel:\n            kwargs[\"reference\"] = raw_message\n\n        image_message = await response_channel.send(\n            content=regen_view.get_image_message_text(),\n            file=file,\n            view=regen_view,\n            **kwargs,\n        )\n        regen_view.image_message = image_message\n        return image_message\n\n    def maybe_get_image_prompt(\n        self, raw_message: discord.Message\n    ) -> typing.Optional[str]:\n        for image_pattern in self.image_patterns:\n            match = image_pattern.search(raw_message.content)\n            if match:\n                image_prompt = match.group(2)\n                if len(image_prompt) < self.MIN_IMAGE_PROMPT_LENGTH:\n                    continue\n                fancy_logger.get().debug(\"Found image prompt: %s\", image_prompt)\n                return image_prompt\n        return None\n\n    async def generate_image(\n        self,\n        user_image_keywords: str,\n        raw_message: discord.Message,\n        response_channel: discord.abc.Messageable,\n    ) -> \"asyncio.Task[discord.Message]\":\n        \"\"\"\n        Kick off a task to generate an image, post it to the channel,\n        and return message the image is posted in.\n        \"\"\"\n        return asyncio.create_task(\n            self._generate_image(user_image_keywords, raw_message, response_channel)\n        )", ""]}
{"filename": "src/oobabot/sd_client.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nClient for generating images using the AUTOMATIC1111\nAPI.  Takes a prompt and returns image binary data in PNG format.\n\"\"\"\n\nimport asyncio\nimport base64\nimport re\nimport time", "import re\nimport time\nimport typing\n\nimport aiohttp\n\nfrom oobabot import fancy_logger\nfrom oobabot import http_client\n\n# todo: response stats for SD client", "\n# todo: response stats for SD client\n\n\ndef _find_substring_in_dict(\n    desired_val: str, search_list: typing.List\n) -> typing.Optional[str]:\n    desired_val = desired_val.lower()\n    for value in search_list:\n        if value.lower() in desired_val:\n            return value\n    return None", "\n\nclass StableDiffusionClient(http_client.SerializedHttpClient):\n    \"\"\"\n    Purpose: Client for generating images using the AUTOMATIC1111\n    API.  Takes a prompt and returns image binary data in PNG format.\n    \"\"\"\n\n    SERVICE_NAME = \"Stable Diffusion\"\n    STABLE_DIFFUSION_API_URI_PATH: str = \"/sdapi/v1/\"\n\n    SAMPLER_KEY = \"sampler_name\"\n    SAMPLER_KEY_ALIAS = \"sampler\"\n\n    API_COMMAND_URLS = {\n        \"get_samplers\": STABLE_DIFFUSION_API_URI_PATH + \"samplers\",\n        # get_samplers: GET only\n        #   returns a list of samplers which we can use\n        #   in text2img\n        \"options\": STABLE_DIFFUSION_API_URI_PATH + \"options\",\n        # options: GET and POST\n        #   retrieves (GET) and sets (POST) global options\n        #   for the server.  This is how we set the checkpoint\n        #   and also a few privacy-related fields.\n        \"progress\": STABLE_DIFFUSION_API_URI_PATH + \"progress\",\n        # progress: GET only\n        #   returns the progress of the current image generation\n        \"txt2img\": STABLE_DIFFUSION_API_URI_PATH + \"txt2img\",\n        # txt2img: POST only\n        #   takes a prompt, generates an image and returns it\n        \"sd-models\": STABLE_DIFFUSION_API_URI_PATH + \"sd-models\",\n        # sd-models: GET only\n        # [\n        #   {\n        #     \"title\": \"Anything-V3.0.ckpt [812cd9f9d9]\",\n        #     \"model_name\": \"Anything-V3.0\",\n        #     \"hash\": \"812cd9f9d9\",\n        #     \"sha256\": \"812cd9f9d9a0cb62aaad605173fd64dea1....\",\n        #     \"filename\": \"...long..path.../models/Stable-diffusion/Anything-V3.0.ckpt\",\n        #     \"config\": null\n        #   },\n        # ...\n        # ]\n    }\n\n    def __init__(\n        self,\n        settings: typing.Dict[str, typing.Any],\n        magic_model_key: str,\n    ):\n        super().__init__(self.SERVICE_NAME, settings[\"stable_diffusion_url\"])\n\n        self.extra_prompt_text = settings[\"extra_prompt_text\"]\n        self.request_params = settings[\"request_params\"]\n\n        # lower-case all keys in request_params\n        self.request_params = {k.lower(): v for k, v in self.request_params.items()}\n        self.sd_models = []\n        self.sd_samplers = []\n\n        self.user_override_params = {}\n        # ensure that each customizable param is in the request_params\n        for param in settings[\"user_override_params\"]:\n            param = param.lower()\n            if param not in self.request_params:\n                fancy_logger.get().warning(\n                    \"Stable Diffusion:  customizable param '%s' not in request_params.\"\n                    + \"  Ignoring setting.\",\n                    param,\n                )\n                continue\n            # store the type of the param, so we can validate user input later\n            self.user_override_params[param] = type(self.request_params[param])\n\n        self.magic_model_key = magic_model_key.lower()\n\n        # when we're in a \"age restricted\" channel, we'll swap\n        # the \"negative_prompt\" in the request_params with this\n        # value.  Otherwise we'll use the one already in\n        # request_params[\"negative_prompt\"]\n        self.negative_prompt_nsfw = self.request_params.pop(\"negative_prompt_nsfw\", \"\")\n\n    DEFAULT_OPTIONS = {\n        #\n        # - \"enable_pnginfo\"\n        #   by default, this will store the parameters used to generate the image.\n        #   For instance:\n        #         Parameters: zombie taylor swift pinup movie posterSteps: 30,\n        #           Sampler: DPM++ 2M Karras, CFG scale: 7, Seed: 1317257172,\n        #           Size: 768x768, Model hash: 9aba26abdf, Model: Deliberate-2.0-15236\n        #   We want to disable this, for a few reasons:\n        #   - it's a privacy concern, since it's not clear to the user what\n        #     is happening\n        #   - it will include our negative prompts, which are actually bad\n        #     phrases that represent content we DON'T want to generate.  If\n        #     we upload these same strings to Discord, they might mistakenly\n        #     flag the content as violating their TOS.  Even though the only\n        #     reason those strings are used is to prevent that content.\n        \"enable_pnginfo\": False,\n        #\n        # - \"do_not_add_watermark\"\n        #    Similar to the above, we don't want to add a watermark to the\n        #    generated image, just since it looks bad.  Also, it can leak\n        #    the version of the SD software we are using, which isn't a good\n        #    idea for security reasons.\n        \"do_not_add_watermark\": True,\n        #\n        # - \"samples_format\"\n        #   this is the format used for all image generation.\n        \"samples_format\": \"png\",\n    }\n\n    async def set_options(self):\n        url = self.API_COMMAND_URLS[\"options\"]\n\n        # first, get the current options.  We do this for two\n        # reasons;\n        #  - show the user exactly what we changed, if anything\n        #  - some versions of the API don't support the\n        #    \"do_not_add_watermark\" option, so we need to\n        #    check if it's there before we try to set it\n        #\n        current_options = None\n        async with self._get_session().get(url) as response:\n            if response.status != 200:\n                raise http_client.OobaHttpClientError(response)\n            current_options = await response.json()\n\n        options_to_set = {}\n        for option_name, option_value in self.DEFAULT_OPTIONS.items():\n            if option_name not in current_options:\n                continue\n            if option_value == current_options[option_name]:\n                continue\n            options_to_set[option_name] = option_value\n            fancy_logger.get().info(\n                \"Stable Diffusion:  changing option '%s' from to '%s' to '%s'\",\n                option_name,\n                current_options[option_name],\n                option_value,\n            )\n\n        if not options_to_set:\n            fancy_logger.get().debug(\n                \"Stable Diffusion: Options are already set correctly, no changes made.\"\n            )\n            return\n\n        async with self._get_session().post(url, json=options_to_set) as response:\n            if response.status != 200:\n                raise http_client.OobaHttpClientError(response)\n            await response.json()\n\n    async def _call_and_extract_field(\n        self, command: str, field: str\n    ) -> typing.List[str]:\n        url = self.API_COMMAND_URLS[command]\n        async with self._get_session().get(url) as response:\n            if response.status != 200:\n                raise http_client.OobaHttpClientError(response)\n            response = await response.json()\n            values = [str(value[field]) for value in response]\n            return values\n\n    async def get_samplers(self) -> typing.List[str]:\n        return await self._call_and_extract_field(\"get_samplers\", \"name\")\n\n    async def get_models(self) -> typing.List[str]:\n        return await self._call_and_extract_field(\"sd-models\", \"model_name\")\n\n    SD_DELIMITER = \"=\"\n\n    def _find_model(self, desired_model: str) -> typing.Optional[str]:\n        return _find_substring_in_dict(desired_model, self.sd_models)\n\n    def _find_sampler(self, desired_sampler: str) -> typing.Optional[str]:\n        return _find_substring_in_dict(desired_sampler, self.sd_samplers)\n\n    def _to_key_value_pair(\n        self, word: str\n    ) -> typing.Optional[typing.Tuple[str, typing.Any]]:\n        if self.SD_DELIMITER not in word:\n            return None\n\n        keyword_pair = word.split(self.SD_DELIMITER, 1)\n        if len(keyword_pair) < 2:\n            return None\n        key, val = keyword_pair\n\n        # lowercase the key, so we can match it against the\n        # user_override_params dict\n        key = key.lower()\n\n        # magical alias for \"negative_prompt\"\n        if key == \"np\":\n            key = \"negative_prompt\"\n\n        if key == self.SAMPLER_KEY_ALIAS:\n            key = self.SAMPLER_KEY\n\n        if key not in self.user_override_params:\n            return None\n\n        # try to remove any quotes around the value\n        if val.startswith('\"') and val.endswith('\"'):\n            val = val[1:-1]\n\n        try:\n            val_type = self.user_override_params[key]\n            if val_type == bool:\n                if val.lower in (\"true\", \"yes\", \"y\"):\n                    val = True\n                elif val.lower in (\"false\", \"no\", \"n\"):\n                    val = False\n            elif val_type == int:\n                val = int(val)\n            elif val_type == float:\n                val = float(val)\n        except ValueError:\n            return None\n\n        return (key, val)\n\n    def update_model_and_sampler(self, params: typing.Dict[str, typing.Any]):\n        \"\"\"\n        Model and Sampler are special since we have a list of known acceptable\n        values.  If the user specifies a value that is not in the list, we\n        ignore it.  If the user specifies a value that is in the list, we\n        override the default.\n\n        Also, \"sampler\" is an alias for \"sampler_name\", and \"model\" is an\n        alias for what should appear in \"override_settings.sd_model_checkpoint\".\n\n        Finally, we allow the user to specify a substring of the model or\n        sampler name, and we will match the first one we find.  This is\n        useful for when the user doesn't know the exact name of the model\n        or sampler, but knows a substring of it.\n        \"\"\"\n        desired_model = params.pop(self.magic_model_key, None)\n        if desired_model is not None:\n            model = self._find_model(desired_model)\n            if model is not None:\n                if \"override_settings\" not in params:\n                    params[\"override_settings\"] = {}\n                params[\"override_settings\"][\"sd_model_checkpoint\"] = model\n                fancy_logger.get().debug(\n                    \"Stable Diffusion: per user request, setting model to '%s'\", model\n                )\n            else:\n                fancy_logger.get().debug(\n                    \"Stable Diffusion: unavailable model requested.  \"\n                    + \"If newly added, restart oobabot: '%s'\",\n                    desired_model,\n                )\n\n        # the proper key is \"sampler_name\", but we also allow\n        # \"sampler\" for convenience.  Move the value, if any, over now.\n        desired_sampler = params.pop(self.SAMPLER_KEY_ALIAS, None)\n        if desired_sampler is not None:\n            params[self.SAMPLER_KEY] = desired_sampler\n\n        desired_sampler = params.pop(self.SAMPLER_KEY, None)\n        if desired_sampler is not None:\n            sampler = self._find_sampler(desired_sampler)\n            if sampler is not None:\n                params[self.SAMPLER_KEY] = sampler\n            else:\n                fancy_logger.get().debug(\n                    \"Stable Diffusion: unavailable sampler requested.  \"\n                    + \"If newly added, restart oobabot: '%s'\",\n                    desired_sampler,\n                )\n\n    # this is intended to split the prompt into words, but\n    # also to handle quoted strings.  For instance, if the\n    # prompt is:\n    #   \"zombie taylor swift\" pinup movie poster\n    # then we want to split it into:\n    #   [\"zombie taylor swift\", \"pinup\", \"movie\", \"poster\"]\n    #\n    SD_PARAM_SPLIT_REGEX = re.compile(r'(?:\".*?\"|\\S)+')\n\n    def update_params(self, prompt: str, params: typing.Dict[str, typing.Any]) -> str:\n        \"\"\"\n        Updates the request parameters included in the given prompt,\n        and then returns the remaining prompt.\n        \"\"\"\n        remaining_prompt = \"\"\n        for word in self.SD_PARAM_SPLIT_REGEX.findall(prompt):\n            key_val_pair = self._to_key_value_pair(word)\n            if key_val_pair is None:\n                remaining_prompt += word + \" \"\n                continue\n            key, val = key_val_pair\n\n            fancy_logger.get().debug(\n                \"Stable Diffusion: per user request, setting '%s' to '%s'\", key, val\n            )\n            params[key] = val\n\n        self.update_model_and_sampler(params)\n\n        return remaining_prompt.strip()\n\n    def generate_image(\n        self,\n        prompt: str,\n        is_channel_nsfw: bool = False,\n    ) -> \"asyncio.Task[bytes]\":\n        \"\"\"\n        Generate an image from a prompt.\n        Args:\n            prompt: The prompt to generate an image from.\n            is_channel_nsfw: Whether the channel is NSFW.\n            this will change the negative prompt.\n        Returns:\n            The image as bytes.\n        Raises:\n            OobaHttpClientError, if the request fails.\n        \"\"\"\n        request = self.request_params.copy()\n\n        if is_channel_nsfw:\n            request[\"negative_prompt\"] = self.negative_prompt_nsfw\n\n        # extract any allowed user overrides from the prompt\n        # and add them to the request dict.  The remaining\n        # prompt is returned.\n        request[\"prompt\"] = self.update_params(prompt, request)\n\n        if self.extra_prompt_text:\n            request[\"prompt\"] += \", \" + self.extra_prompt_text\n\n        async def do_post() -> bytes:\n            fancy_logger.get().debug(\n                \"Stable Diffusion: Image request (nsfw: %r): %s\",\n                is_channel_nsfw,\n                request,\n            )\n            start_time = time.time()\n\n            async with self._get_session().post(\n                self.API_COMMAND_URLS[\"txt2img\"],\n                json=request,\n            ) as response:\n                if response.status != 200:\n                    raise http_client.OobaHttpClientError(response)\n                duration = time.time() - start_time\n                json_body = await response.json()\n                image_bytes = base64.b64decode(json_body[\"images\"][0])\n                fancy_logger.get().debug(\n                    \"Stable Diffusion: Image generated, %d bytes in %.2f seconds\",\n                    len(image_bytes),\n                    duration,\n                )\n                return image_bytes\n\n        # works around aiohttp being bad\n        async def do_post_with_retry() -> bytes:\n            tries = 0\n            while True:\n                try:\n                    return await do_post()\n                except (aiohttp.ClientError, aiohttp.ClientOSError) as err:\n                    retry = False\n                    if err.__cause__ is ConnectionResetError:\n                        retry = True\n                    if isinstance(err, aiohttp.ClientOSError) and 104 == err.errno:\n                        retry = True\n                    if tries > 2:\n                        retry = False\n                    if not retry:\n                        raise\n\n                    fancy_logger.get().warning(\n                        \"Stable Diffusion: Connection reset error: %s, \"\n                        + \"retrying in 1 second\",\n                        err,\n                    )\n                    await asyncio.sleep(1)\n                    tries += 1\n\n        return asyncio.create_task(do_post_with_retry())\n\n    async def _setup(self):\n        await self.set_options()\n        self.sd_models = await self.get_models()\n        self.sd_samplers = await self.get_samplers()\n        fancy_logger.get().info(\n            \"Stable Diffusion: Available models: %s\", \", \".join(self.sd_models)\n        )\n        # log a warning if the default model is not available\n        desired_model = self.request_params.get(self.magic_model_key, None)\n        if desired_model:\n            model = self._find_model(desired_model)\n            if model is None:\n                fancy_logger.get().warning(\n                    \"Stable Diffusion: Desired default model '%s' not available.\",\n                    desired_model,\n                )\n            else:\n                fancy_logger.get().debug(\n                    \"Stable Diffusion: Using default model '%s'\", desired_model\n                )\n\n        fancy_logger.get().info(\n            \"Stable Diffusion: Available samplers: %s\", \", \".join(self.sd_samplers)\n        )\n        # log a warning if the default sampler is not available\n        desired_sampler = self.request_params.get(\n            self.SAMPLER_KEY_ALIAS, self.request_params.get(self.SAMPLER_KEY, None)\n        )\n        if desired_sampler:\n            sampler = self._find_sampler(desired_sampler)\n            if sampler is None:\n                fancy_logger.get().warning(\n                    \"Stable Diffusion: Desired default sampler '%s' not available.\",\n                    desired_sampler,\n                )\n            else:\n                fancy_logger.get().debug(\n                    \"Stable Diffusion: Using default sampler '%s'\", desired_sampler\n                )\n\n        fancy_logger.get().debug(\n            \"Stable Diffusion: Using negative prompt: %s...\",\n            str(self.request_params.get(\"negative_prompt\", \"\"))[:20],\n        )\n        if self.extra_prompt_text:\n            fancy_logger.get().debug(\n                \"Stable Diffusion: Bot will append to every prompt: '%s'\",\n                self.extra_prompt_text,\n            )\n        if 0 == len(self.user_override_params):\n            fancy_logger.get().debug(\n                \"Stable Diffusion: Users cannot override any SD params\"\n            )\n        else:\n            fancy_logger.get().debug(\n                \"Stable Diffusion: Users may override: %s\",\n                \", \".join(self.user_override_params.keys()),\n            )", ""]}
{"filename": "src/oobabot/voice_client.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nA replacement voice client for discord.py, using the Discrivener audio transcriber.\n\"\"\"\n\nimport asyncio\nimport typing\n\nimport discord\nimport discord.backoff", "import discord\nimport discord.backoff\nimport discord.gateway\nimport discord.guild\nimport discord.opus\nimport discord.state\nimport discord.types\nfrom discord.types import voice  # this is so pylint doesn't complain\n\nfrom oobabot import audio_responder", "\nfrom oobabot import audio_responder\nfrom oobabot import discrivener\nfrom oobabot import discrivener_message\nfrom oobabot import fancy_logger\nfrom oobabot import ooba_client  # pylint: disable=unused-import\nfrom oobabot import prompt_generator  # pylint: disable=unused-import\nfrom oobabot import transcript\nfrom oobabot import types\n", "from oobabot import types\n\n\nclass VoiceClientError(Exception):\n    \"\"\"\n    Base exception class for voice client errors.\n    \"\"\"\n\n\nclass VoiceClient(discord.VoiceProtocol):\n    \"\"\"\n    A replacement voice client for discord.py, using the Discrivener audio transcriber.\n\n\n    You do not create these, you typically get them from\n    e.g. :meth:`VoiceChannel.connect`, by passing in\n    cls=voice_client.VoiceClient\n    \"\"\"\n\n    discrivener_location: str\n    discrivener_model_location: str\n    current_instance: typing.Optional[\"VoiceClient\"] = None\n    ooba_client: ooba_client.OobaClient\n    prompt_generator: prompt_generator.PromptGenerator\n    wakewords: typing.List[str] = []\n\n    supported_modes: typing.Tuple[voice.SupportedModes, ...] = (\n        \"xsalsa20_poly1305\",\n        \"xsalsa20_poly1305_suffix\",\n        \"xsalsa20_poly1305_lite\",\n    )\n\n    def __init__(\n        self,\n        client: discord.client.Client,\n        channel: discord.abc.Connectable,\n    ) -> None:\n        super().__init__(client, channel)\n\n        if not isinstance(channel, discord.VoiceChannel):\n            raise ValueError(\"Channel is not a voice channel.\")\n\n        if channel.guild is None:\n            raise ValueError(\"Channel does not have a guild.\")\n\n        if client.user is None:\n            raise ValueError(\"Client does not have a user.\")\n\n        self._discrivener = discrivener.Discrivener(\n            self.discrivener_location,\n            self.discrivener_model_location,\n            self._handle_discrivener_output,\n        )\n        self._discrivener_connected = False\n        self._handshaking = False\n        self._oobabot_voice_connected = False\n        self._potentially_reconnecting = False\n        self._voice_state_complete = asyncio.Event()\n        self._voice_server_complete = asyncio.Event()\n        self._state: discord.state.ConnectionState = client._connection\n        self._session_id = discord.utils.MISSING\n        self._server_id = discord.utils.MISSING\n        self._transcript = transcript.Transcript(client.user.id, self.wakewords)\n        self._guild_channel = channel\n        self._user = client.user\n\n        self._audio_responder = audio_responder.AudioResponder(\n            channel,\n            self._discrivener,\n            self.ooba_client,\n            self.prompt_generator,\n            self._transcript,\n        )\n\n    @property\n    def guild(self) -> discord.guild.Guild:\n        \"\"\"\n        :class:`Guild`: The guild we're connected to.\n        \"\"\"\n        return self._guild_channel.guild\n\n    @property\n    def user(self) -> discord.user.ClientUser:\n        \"\"\"\n        :class:`ClientUser`: The user connected to voice (i.e. ourselves).\n        \"\"\"\n        return self._user\n\n    @property\n    def session_id(self) -> str:\n        \"\"\"\n        :class:`str`: The session ID for this voice connection.\n        \"\"\"\n        return self._session_id\n\n    async def on_voice_state_update(\n        self,\n        data: voice.GuildVoiceState,\n        /,\n    ) -> None:\n        self._session_id = data[\"session_id\"]\n        channel_id = data[\"channel_id\"]\n\n        if not self._handshaking or self._potentially_reconnecting:\n            fancy_logger.get().debug(\n                \"Server-initiated voice state update for Channel ID %s (Guild ID %s)\",\n                channel_id,\n                self.guild.id,\n            )\n\n            # If we're done handshaking then we just need to update ourselves\n            # If we're potentially reconnecting due to a 4014, then we need to\n            # differentiate\n            # a channel move and an actual force disconnect\n            if channel_id is None:\n                # We're being disconnected so cleanup\n                await self.disconnect()\n            else:\n                channel = self.guild.get_channel(int(channel_id))\n                if channel is None:\n                    fancy_logger.get().warning(\n                        \"Channel ID %s not found in Guild ID %s\",\n                        channel_id,\n                        self.guild.id,\n                    )\n                    return\n                if not isinstance(channel, discord.VoiceChannel):\n                    fancy_logger.get().warning(\n                        \"Channel ID %s not a VoiceChannel.\", channel_id\n                    )\n                    return\n                self.channel = channel\n        else:\n            fancy_logger.get().debug(\n                \"Voice state complete for Channel ID %s (Guild ID %s) during handshake\",\n                channel_id,\n                self.guild.id,\n            )\n            self._voice_state_complete.set()\n\n    async def on_voice_server_update(\n        self,\n        data: voice.VoiceServerUpdate,\n        /,\n    ) -> None:\n        if self._voice_server_complete.is_set():\n            fancy_logger.get().warning(\"Ignoring extraneous voice server update.\")\n            return\n\n        token = data[\"token\"]\n        guild_id = int(data[\"guild_id\"])\n        endpoint = data.get(\"endpoint\")\n\n        if endpoint is None or token is None:\n            fancy_logger.get().warning(\n                \"Awaiting endpoint... This requires waiting. \"\n                \"If timeout occurred considering raising the timeout and reconnecting.\"\n            )\n            return\n\n        endpoint, _, _ = endpoint.rpartition(\":\")\n        if endpoint.startswith(\"wss://\"):\n            # Just in case, strip it off since we're going to add it later\n            endpoint = endpoint[6:]\n\n        # this will start the process, we'll get a callback when the connection\n        # is made\n        await self._discrivener.run(\n            self._guild_channel.id,\n            endpoint,\n            guild_id,\n            self.session_id,\n            self.user.id,\n            token,\n        )\n        await self._audio_responder.start()\n        self._voice_server_complete.set()\n\n    async def voice_connect(\n        self, self_deaf: bool = False, self_mute: bool = False\n    ) -> None:\n        await self._guild_channel.guild.change_voice_state(\n            channel=self._guild_channel, self_deaf=self_deaf, self_mute=self_mute\n        )\n\n    async def voice_disconnect(self) -> None:\n        fancy_logger.get().info(\n            \"The voice handshake is being terminated for Channel ID %s (Guild ID %s)\",\n            self._guild_channel.id,\n            self.guild.id,\n        )\n        self._oobabot_voice_connected = False\n        await self._guild_channel.guild.change_voice_state(channel=None)\n        await self._discrivener.stop()\n        await self._audio_responder.stop()\n        VoiceClient.current_instance = None\n\n    async def connect(\n        self,\n        *,\n        reconnect: bool,\n        timeout: float,\n        self_deaf: bool = False,\n        self_mute: bool = False,\n    ) -> None:\n        fancy_logger.get().info(\"Connecting to voice...\")\n\n        if self.is_connected():\n            raise VoiceClientError(\"Already connected to a voice channel.\")\n\n        self._voice_state_complete.clear()\n        self._voice_server_complete.clear()\n\n        futures = [\n            self._voice_state_complete.wait(),\n            self._voice_server_complete.wait(),\n        ]\n\n        self._handshaking = True\n\n        fancy_logger.get().info(\"Starting voice handshake...\")\n\n        await self.voice_connect(self_deaf, self_mute)\n\n        try:\n            await discord.utils.sane_wait_for(futures, timeout=timeout)\n        except asyncio.TimeoutError as err:\n            await self.disconnect(force=True)\n            raise VoiceClientError(\n                f\"Couldn't connect to voice channel within {timeout:.2f}s\"\n            ) from err\n\n        self._oobabot_voice_connected = True\n\n        self._voice_state_complete.clear()\n        self._voice_server_complete.clear()\n\n        fancy_logger.get().info(\"Voice handshake complete.\")\n        self._handshaking = False\n        VoiceClient.current_instance = self\n\n    async def potential_reconnect(self) -> bool:\n        # Attempt to stop the player thread from playing early\n        # self._potentially_reconnecting = True\n        fancy_logger.get().warning(\"voice_client::potential_reconnect: not implemented\")\n        return False\n\n    async def disconnect(self, *, force: bool = False) -> None:\n        \"\"\"|coro|\n\n        Disconnects this voice client from voice.\n        \"\"\"\n        if not force and not self.is_connected():\n            return\n\n        try:\n            await self.voice_disconnect()\n        finally:\n            self.cleanup()\n\n    async def move_to(self, channel: typing.Optional[discord.abc.Snowflake]) -> None:\n        \"\"\"|coro|\n\n        Moves you to a different voice channel.\n\n        Parameters\n        -----------\n        channel: Optional[:class:`abc.Snowflake`]\n            The channel to move to. Must be a voice channel.\n        \"\"\"\n        # todo: tell songbird to move channels\n        fancy_logger.get().warning(\"voice_client::move_to: not implemented\")\n        await self._guild_channel.guild.change_voice_state(channel=channel)\n\n    def is_connected(self) -> bool:\n        \"\"\"Indicates if the voice client is connected to voice.\"\"\"\n        if not self._oobabot_voice_connected:\n            return False\n        if self._discrivener is None:\n            return False\n        if not self._discrivener.is_running():\n            return False\n        return self._discrivener_connected\n\n    def _handle_discrivener_output(self, message: \"types.DiscrivenerMessage\"):\n        if message.type in (\n            types.DiscrivenerMessageType.CONNECT,\n            types.DiscrivenerMessageType.RECONNECT,\n        ):\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n            self._voice_state_complete.set()\n            self._discrivener_connected = True\n\n        elif types.DiscrivenerMessageType.DISCONNECT == message.type:\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n            self._voice_state_complete.set()\n            self._discrivener_connected = False\n\n            # we're disconnected, so have the voice_client disconnect\n            # too... however we can't call disconnect() here because\n            # we would create a deadlock.  The disconnect() method\n            # will terminate the process, then wait for its notification\n            # threads to exit... and we're on the notification thread\n            # right now.  So to break the loop, use asyncio to schedule\n            # the disconnect() call to happen later.\n            loop = asyncio.get_event_loop()\n            if loop is None:\n                fancy_logger.get().warning(\n                    \"No event loop to schedule voice_client.disconnect() call\"\n                )\n                return\n            # todo: how to wait for a result here?\n            loop.call_soon_threadsafe(self.disconnect)\n\n        elif types.DiscrivenerMessageType.USER_JOIN == message.type:\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n\n        elif types.DiscrivenerMessageType.USER_LEAVE == message.type:\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n\n        elif types.DiscrivenerMessageType.TRANSCRIPTION == message.type:\n            if isinstance(message, discrivener_message.UserVoiceMessage):\n                self._transcript.on_transcription(message)\n            else:\n                fancy_logger.get().warning(\n                    \"Unexpected message value %s\", type(message).__name__\n                )\n\n        elif types.DiscrivenerMessageType.CHANNEL_SILENT == message.type:\n            if isinstance(message, discrivener_message.ChannelSilentData):\n                self._transcript.on_channel_silent(message)\n            else:\n                fancy_logger.get().warning(\n                    \"Unexpected message value %s\", type(message).__name__\n                )\n\n        else:\n            fancy_logger.get().warning(\n                \"Unknown discrivener message type: %s\", message.type\n            )\n\n    def current_transcript(self) -> typing.Optional[transcript.Transcript]:\n        return self._transcript", "\nclass VoiceClient(discord.VoiceProtocol):\n    \"\"\"\n    A replacement voice client for discord.py, using the Discrivener audio transcriber.\n\n\n    You do not create these, you typically get them from\n    e.g. :meth:`VoiceChannel.connect`, by passing in\n    cls=voice_client.VoiceClient\n    \"\"\"\n\n    discrivener_location: str\n    discrivener_model_location: str\n    current_instance: typing.Optional[\"VoiceClient\"] = None\n    ooba_client: ooba_client.OobaClient\n    prompt_generator: prompt_generator.PromptGenerator\n    wakewords: typing.List[str] = []\n\n    supported_modes: typing.Tuple[voice.SupportedModes, ...] = (\n        \"xsalsa20_poly1305\",\n        \"xsalsa20_poly1305_suffix\",\n        \"xsalsa20_poly1305_lite\",\n    )\n\n    def __init__(\n        self,\n        client: discord.client.Client,\n        channel: discord.abc.Connectable,\n    ) -> None:\n        super().__init__(client, channel)\n\n        if not isinstance(channel, discord.VoiceChannel):\n            raise ValueError(\"Channel is not a voice channel.\")\n\n        if channel.guild is None:\n            raise ValueError(\"Channel does not have a guild.\")\n\n        if client.user is None:\n            raise ValueError(\"Client does not have a user.\")\n\n        self._discrivener = discrivener.Discrivener(\n            self.discrivener_location,\n            self.discrivener_model_location,\n            self._handle_discrivener_output,\n        )\n        self._discrivener_connected = False\n        self._handshaking = False\n        self._oobabot_voice_connected = False\n        self._potentially_reconnecting = False\n        self._voice_state_complete = asyncio.Event()\n        self._voice_server_complete = asyncio.Event()\n        self._state: discord.state.ConnectionState = client._connection\n        self._session_id = discord.utils.MISSING\n        self._server_id = discord.utils.MISSING\n        self._transcript = transcript.Transcript(client.user.id, self.wakewords)\n        self._guild_channel = channel\n        self._user = client.user\n\n        self._audio_responder = audio_responder.AudioResponder(\n            channel,\n            self._discrivener,\n            self.ooba_client,\n            self.prompt_generator,\n            self._transcript,\n        )\n\n    @property\n    def guild(self) -> discord.guild.Guild:\n        \"\"\"\n        :class:`Guild`: The guild we're connected to.\n        \"\"\"\n        return self._guild_channel.guild\n\n    @property\n    def user(self) -> discord.user.ClientUser:\n        \"\"\"\n        :class:`ClientUser`: The user connected to voice (i.e. ourselves).\n        \"\"\"\n        return self._user\n\n    @property\n    def session_id(self) -> str:\n        \"\"\"\n        :class:`str`: The session ID for this voice connection.\n        \"\"\"\n        return self._session_id\n\n    async def on_voice_state_update(\n        self,\n        data: voice.GuildVoiceState,\n        /,\n    ) -> None:\n        self._session_id = data[\"session_id\"]\n        channel_id = data[\"channel_id\"]\n\n        if not self._handshaking or self._potentially_reconnecting:\n            fancy_logger.get().debug(\n                \"Server-initiated voice state update for Channel ID %s (Guild ID %s)\",\n                channel_id,\n                self.guild.id,\n            )\n\n            # If we're done handshaking then we just need to update ourselves\n            # If we're potentially reconnecting due to a 4014, then we need to\n            # differentiate\n            # a channel move and an actual force disconnect\n            if channel_id is None:\n                # We're being disconnected so cleanup\n                await self.disconnect()\n            else:\n                channel = self.guild.get_channel(int(channel_id))\n                if channel is None:\n                    fancy_logger.get().warning(\n                        \"Channel ID %s not found in Guild ID %s\",\n                        channel_id,\n                        self.guild.id,\n                    )\n                    return\n                if not isinstance(channel, discord.VoiceChannel):\n                    fancy_logger.get().warning(\n                        \"Channel ID %s not a VoiceChannel.\", channel_id\n                    )\n                    return\n                self.channel = channel\n        else:\n            fancy_logger.get().debug(\n                \"Voice state complete for Channel ID %s (Guild ID %s) during handshake\",\n                channel_id,\n                self.guild.id,\n            )\n            self._voice_state_complete.set()\n\n    async def on_voice_server_update(\n        self,\n        data: voice.VoiceServerUpdate,\n        /,\n    ) -> None:\n        if self._voice_server_complete.is_set():\n            fancy_logger.get().warning(\"Ignoring extraneous voice server update.\")\n            return\n\n        token = data[\"token\"]\n        guild_id = int(data[\"guild_id\"])\n        endpoint = data.get(\"endpoint\")\n\n        if endpoint is None or token is None:\n            fancy_logger.get().warning(\n                \"Awaiting endpoint... This requires waiting. \"\n                \"If timeout occurred considering raising the timeout and reconnecting.\"\n            )\n            return\n\n        endpoint, _, _ = endpoint.rpartition(\":\")\n        if endpoint.startswith(\"wss://\"):\n            # Just in case, strip it off since we're going to add it later\n            endpoint = endpoint[6:]\n\n        # this will start the process, we'll get a callback when the connection\n        # is made\n        await self._discrivener.run(\n            self._guild_channel.id,\n            endpoint,\n            guild_id,\n            self.session_id,\n            self.user.id,\n            token,\n        )\n        await self._audio_responder.start()\n        self._voice_server_complete.set()\n\n    async def voice_connect(\n        self, self_deaf: bool = False, self_mute: bool = False\n    ) -> None:\n        await self._guild_channel.guild.change_voice_state(\n            channel=self._guild_channel, self_deaf=self_deaf, self_mute=self_mute\n        )\n\n    async def voice_disconnect(self) -> None:\n        fancy_logger.get().info(\n            \"The voice handshake is being terminated for Channel ID %s (Guild ID %s)\",\n            self._guild_channel.id,\n            self.guild.id,\n        )\n        self._oobabot_voice_connected = False\n        await self._guild_channel.guild.change_voice_state(channel=None)\n        await self._discrivener.stop()\n        await self._audio_responder.stop()\n        VoiceClient.current_instance = None\n\n    async def connect(\n        self,\n        *,\n        reconnect: bool,\n        timeout: float,\n        self_deaf: bool = False,\n        self_mute: bool = False,\n    ) -> None:\n        fancy_logger.get().info(\"Connecting to voice...\")\n\n        if self.is_connected():\n            raise VoiceClientError(\"Already connected to a voice channel.\")\n\n        self._voice_state_complete.clear()\n        self._voice_server_complete.clear()\n\n        futures = [\n            self._voice_state_complete.wait(),\n            self._voice_server_complete.wait(),\n        ]\n\n        self._handshaking = True\n\n        fancy_logger.get().info(\"Starting voice handshake...\")\n\n        await self.voice_connect(self_deaf, self_mute)\n\n        try:\n            await discord.utils.sane_wait_for(futures, timeout=timeout)\n        except asyncio.TimeoutError as err:\n            await self.disconnect(force=True)\n            raise VoiceClientError(\n                f\"Couldn't connect to voice channel within {timeout:.2f}s\"\n            ) from err\n\n        self._oobabot_voice_connected = True\n\n        self._voice_state_complete.clear()\n        self._voice_server_complete.clear()\n\n        fancy_logger.get().info(\"Voice handshake complete.\")\n        self._handshaking = False\n        VoiceClient.current_instance = self\n\n    async def potential_reconnect(self) -> bool:\n        # Attempt to stop the player thread from playing early\n        # self._potentially_reconnecting = True\n        fancy_logger.get().warning(\"voice_client::potential_reconnect: not implemented\")\n        return False\n\n    async def disconnect(self, *, force: bool = False) -> None:\n        \"\"\"|coro|\n\n        Disconnects this voice client from voice.\n        \"\"\"\n        if not force and not self.is_connected():\n            return\n\n        try:\n            await self.voice_disconnect()\n        finally:\n            self.cleanup()\n\n    async def move_to(self, channel: typing.Optional[discord.abc.Snowflake]) -> None:\n        \"\"\"|coro|\n\n        Moves you to a different voice channel.\n\n        Parameters\n        -----------\n        channel: Optional[:class:`abc.Snowflake`]\n            The channel to move to. Must be a voice channel.\n        \"\"\"\n        # todo: tell songbird to move channels\n        fancy_logger.get().warning(\"voice_client::move_to: not implemented\")\n        await self._guild_channel.guild.change_voice_state(channel=channel)\n\n    def is_connected(self) -> bool:\n        \"\"\"Indicates if the voice client is connected to voice.\"\"\"\n        if not self._oobabot_voice_connected:\n            return False\n        if self._discrivener is None:\n            return False\n        if not self._discrivener.is_running():\n            return False\n        return self._discrivener_connected\n\n    def _handle_discrivener_output(self, message: \"types.DiscrivenerMessage\"):\n        if message.type in (\n            types.DiscrivenerMessageType.CONNECT,\n            types.DiscrivenerMessageType.RECONNECT,\n        ):\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n            self._voice_state_complete.set()\n            self._discrivener_connected = True\n\n        elif types.DiscrivenerMessageType.DISCONNECT == message.type:\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n            self._voice_state_complete.set()\n            self._discrivener_connected = False\n\n            # we're disconnected, so have the voice_client disconnect\n            # too... however we can't call disconnect() here because\n            # we would create a deadlock.  The disconnect() method\n            # will terminate the process, then wait for its notification\n            # threads to exit... and we're on the notification thread\n            # right now.  So to break the loop, use asyncio to schedule\n            # the disconnect() call to happen later.\n            loop = asyncio.get_event_loop()\n            if loop is None:\n                fancy_logger.get().warning(\n                    \"No event loop to schedule voice_client.disconnect() call\"\n                )\n                return\n            # todo: how to wait for a result here?\n            loop.call_soon_threadsafe(self.disconnect)\n\n        elif types.DiscrivenerMessageType.USER_JOIN == message.type:\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n\n        elif types.DiscrivenerMessageType.USER_LEAVE == message.type:\n            fancy_logger.get().debug(\"discrivener message: %s\", message)\n\n        elif types.DiscrivenerMessageType.TRANSCRIPTION == message.type:\n            if isinstance(message, discrivener_message.UserVoiceMessage):\n                self._transcript.on_transcription(message)\n            else:\n                fancy_logger.get().warning(\n                    \"Unexpected message value %s\", type(message).__name__\n                )\n\n        elif types.DiscrivenerMessageType.CHANNEL_SILENT == message.type:\n            if isinstance(message, discrivener_message.ChannelSilentData):\n                self._transcript.on_channel_silent(message)\n            else:\n                fancy_logger.get().warning(\n                    \"Unexpected message value %s\", type(message).__name__\n                )\n\n        else:\n            fancy_logger.get().warning(\n                \"Unknown discrivener message type: %s\", message.type\n            )\n\n    def current_transcript(self) -> typing.Optional[transcript.Transcript]:\n        return self._transcript", ""]}
{"filename": "src/oobabot/audio_responder.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nWatches the transcript, when a wakeword is detected,\nit builds a prompt for the AI, queries it, and\nthen queues a response.\n\"\"\"\n\nimport asyncio\nimport typing\n", "import typing\n\nimport discord\n\nfrom oobabot import discord_utils\nfrom oobabot import discrivener\nfrom oobabot import fancy_logger\nfrom oobabot import ooba_client\nfrom oobabot import prompt_generator\nfrom oobabot import transcript", "from oobabot import prompt_generator\nfrom oobabot import transcript\nfrom oobabot import types\n\n\nclass AudioResponder:\n    \"\"\"\n    Watches the transcript, when a wakeword is detected,\n    it builds a prompt for the AI, queries it, and\n    then queues a response.\n    \"\"\"\n\n    TASK_TIMEOUT_SECONDS = 5.0\n\n    def __init__(\n        self,\n        channel: discord.VoiceChannel,\n        discrivener: discrivener.Discrivener,\n        ooba_client: ooba_client.OobaClient,\n        prompt_generator: prompt_generator.PromptGenerator,\n        transcript: transcript.Transcript,\n    ):\n        self._abort = False\n        self._channel = channel\n        self._discrivener = discrivener\n        self._ooba_client = ooba_client\n        self._prompt_generator = prompt_generator\n        self._transcript = transcript\n        self._task: typing.Optional[asyncio.Task] = None\n\n    async def start(self):\n        await self.stop()\n        self._task = asyncio.create_task(self._transcript_reply_task())\n\n    async def stop(self):\n        if self._task is None:\n            return\n\n        self._abort = True\n        self._task.cancel()\n        try:\n            await asyncio.wait_for(self._task, timeout=self.TASK_TIMEOUT_SECONDS)\n        except asyncio.TimeoutError:\n            fancy_logger.get().warning(\"audio_responder: task did not quit in time\")\n        except asyncio.CancelledError:\n            fancy_logger.get().info(\"audio_responder: task stopped\")\n        self._task = None\n        self._abort = False\n\n    # @fancy_logger.log_async_task\n    async def _transcript_reply_task(self):\n        fancy_logger.get().info(\"audio_responder: started\")\n        while not self._abort:\n            await self._transcript.wakeword_event.wait()\n            self._transcript.wakeword_event.clear()\n            await self._respond()\n\n        fancy_logger.get().info(\"audio_responder: exiting\")\n\n    async def _respond(self):\n        transcript_history = self._transcript_history_iterator()\n        prompt_prefix = await self._prompt_generator.generate(\n            message_history=transcript_history,\n            image_requested=False,\n        )\n\n        response = await self._ooba_client.request_as_string(prompt_prefix)\n        fancy_logger.get().debug(\"received response: '%s'\", response)\n\n        # wait for silence before responding\n        await self._transcript.silence_event.wait()\n\n        # shove response into history\n        self._transcript.on_bot_response(response)\n\n        self._discrivener.speak(response)\n        # todo: make this a setting?\n        # await self._channel.send(response)\n\n    def _transcript_history_iterator(\n        self,\n    ) -> typing.AsyncIterator[types.GenericMessage]:\n        voice_messages = self._transcript.message_buffer.get()\n        voice_messages.sort(key=lambda message: message.start_time, reverse=True)\n\n        # create an async generator which iterates over the lines\n        # in the transcript\n        async def _gen():\n            for message in voice_messages:\n                author = discord_utils.author_from_user_id(\n                    message.user_id,\n                    self._channel.guild,\n                )\n                if author is None:\n                    author_name = f\"user #{message.user_id}\"\n                    author_is_bot = message.is_bot\n                else:\n                    author_name = author.author_name\n                    author_is_bot = author.author_is_bot\n                yield types.GenericMessage(\n                    author_id=message.user_id,\n                    author_name=author_name,\n                    channel_id=0,\n                    channel_name=\"\",\n                    message_id=0,\n                    reference_message_id=0,\n                    body_text=message.text,\n                    author_is_bot=author_is_bot,\n                    send_timestamp=message.start_time.timestamp(),\n                )\n\n        return _gen()", ""]}
{"filename": "src/oobabot/decide_to_respond.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nDecides whether the bot responds to a message.\n\"\"\"\n\nimport random\nimport typing\n\nfrom oobabot import fancy_logger\nfrom oobabot import persona", "from oobabot import fancy_logger\nfrom oobabot import persona\nfrom oobabot import types\n\n\nclass LastReplyTimes(dict):\n    \"\"\"\n    A dictionary that keeps track of the last time we were mentioned\n    in a channel.\n\n    This uses the timestamp on the message, not the local system's\n    RTC.  The advantage of this is that if messages are delayed,\n    we'll only respond to ones that were actually sent within the\n    appropriate time window.  It also makes it easier to test.\n    \"\"\"\n\n    def __init__(self, cache_timeout: float, unsolicited_channel_cap: int):\n        self.cache_timeout = cache_timeout\n        self.unsolicited_channel_cap = unsolicited_channel_cap\n\n    def purge_outdated(self, latest_timestamp: float) -> None:\n        oldest_time_to_keep = latest_timestamp - self.cache_timeout\n\n        if self.unsolicited_channel_cap > 0:\n            # find the n-th largest timestamp\n            if self.unsolicited_channel_cap < len(self):\n                nth_largest_timestamp = sorted(self.values())[\n                    -self.unsolicited_channel_cap\n                ]\n                oldest_time_to_keep = max(oldest_time_to_keep, nth_largest_timestamp)\n        purged = {\n            channel_id: response_time\n            for channel_id, response_time in self.items()\n            if response_time >= oldest_time_to_keep\n        }\n        self.clear()\n        self.update(purged)\n\n    def log_mention(self, channel_id: int, send_timestamp: float) -> None:\n        self[channel_id] = send_timestamp\n\n    def time_since_last_mention(self, message: types.ChannelMessage) -> float:\n        self.purge_outdated(message.send_timestamp)\n        return message.send_timestamp - self.get(message.channel_id, 0)", "\n\nclass DecideToRespond:\n    \"\"\"\n    Decide whether to respond to a message.\n    \"\"\"\n\n    def __init__(\n        self,\n        discord_settings: dict,\n        persona: persona.Persona,\n        interrobang_bonus: float,\n        time_vs_response_chance: typing.List[typing.Tuple[float, float]],\n    ):\n        self.disable_unsolicited_replies = discord_settings[\n            \"disable_unsolicited_replies\"\n        ]\n        self.ignore_dms = discord_settings[\"ignore_dms\"]\n        self.interrobang_bonus = interrobang_bonus\n        self.persona = persona\n        self.time_vs_response_chance = time_vs_response_chance\n\n        last_reply_cache_timeout = max(time for time, _ in time_vs_response_chance)\n        unsolicited_channel_cap = discord_settings[\"unsolicited_channel_cap\"]\n        self.last_reply_times = LastReplyTimes(\n            last_reply_cache_timeout,\n            unsolicited_channel_cap,\n        )\n\n    def is_directly_mentioned(\n        self, our_user_id: int, message: types.GenericMessage\n    ) -> bool:\n        \"\"\"\n        Returns True if the message is a direct message to us, or if it\n        mentions us by @name or wakeword.\n        \"\"\"\n\n        # reply to all private messages\n        if isinstance(message, types.DirectMessage):\n            if self.ignore_dms:\n                return False\n            return True\n\n        # reply to all messages in which we're @-mentioned\n        if isinstance(message, types.ChannelMessage):\n            if message.is_mentioned(our_user_id):\n                return True\n\n        # reply to all messages that include a wakeword\n        if self.persona.contains_wakeword(message.body_text):\n            return True\n\n        return False\n\n    def calc_base_chance_of_unsolicited_reply(\n        self, message: types.ChannelMessage\n    ) -> float:\n        \"\"\"\n        Calculate base chance of unsolicited reply using the\n        TIME_VS_RESPONSE_CHANCE table.\n        \"\"\"\n        # return a base chance that we'll respond to a message that wasn't\n        # addressed to us, based on the table in TIME_VS_RESPONSE_CHANCE.\n        # other factors might increase this chance.\n        time_since_last_send = self.last_reply_times.time_since_last_mention(message)\n        response_chance = 0.0\n        for duration, chance in self.time_vs_response_chance:\n            if time_since_last_send < duration:\n                response_chance = chance\n                break\n        return response_chance\n\n    def provide_unsolicited_reply_in_channel(\n        self, our_user_id: int, message: types.ChannelMessage\n    ) -> bool:\n        \"\"\"\n        Returns True if we should respond to the message, even\n        though we weren't directly mentioned.\n        \"\"\"\n\n        # if we're not at-mentioned but others are, don't reply\n        if message.mentions and not message.is_mentioned(our_user_id):\n            return False\n\n        # if message is empty, don't reply.  This can happen if someone\n        # posts an image or an attachment without a comment.\n        if message.is_empty():\n            return False\n\n        # if we've posted recently in this channel, there are a few\n        # other reasons we may respond.  But if we haven't, just\n        # ignore the message.\n\n        # if the admin has disabled unsolicited replies, don't reply\n        if self.disable_unsolicited_replies:\n            return False\n\n        # if we haven't posted to this channel recently, don't reply\n        response_chance = self.calc_base_chance_of_unsolicited_reply(message)\n        if response_chance == 0.0:\n            return False\n\n        # if the new message ends with a question mark, we'll respond\n        if message.body_text.endswith(\"?\"):\n            response_chance += self.interrobang_bonus\n\n        # if the new message ends with an exclamation point, we'll respond\n        if message.body_text.endswith(\"!\"):\n            response_chance += self.interrobang_bonus\n\n        time_since_last_mention = self.last_reply_times.time_since_last_mention(message)\n        fancy_logger.get().debug(\n            \"Considering unsolicited response in channel %s after %2.0f seconds.  \"\n            + \"chance: %2.0f%%.\",\n            message.channel_name,\n            time_since_last_mention,\n            response_chance * 100.0,\n        )\n\n        if random.random() < response_chance:\n            return True\n\n        return False\n\n    def should_reply_to_message(\n        self, our_user_id: int, message: types.GenericMessage\n    ) -> typing.Tuple[bool, bool]:\n        \"\"\"\n        Returns a tuple of (should_reply, is_direct_mention).\n\n        Direct mentions are always replied to, but also, the\n        caller should log the mention later by calling log_mention().\n\n        The only reason this method doesn't to so itself is that\n        in the case of us generating a thread to reply on, the\n        channel ID we want to track will be that of the thread\n        we create, not the channel the message was posted in.\n        \"\"\"\n\n        # ignore messages from other bots, out of fear of infinite loops,\n        # as well as world domination\n        if message.author_is_bot:\n            return (False, False)\n\n        # we do not want the bot to reply to itself.  This is redundant\n        # with the previous check, except it won't be if someone decides\n        # to run this under their own user token, rather than a proper\n        # bot token.\n        if message.author_id == our_user_id:\n            return (False, False)\n\n        if self.is_directly_mentioned(our_user_id, message):\n            return (True, True)\n\n        if isinstance(message, types.ChannelMessage):\n            if self.provide_unsolicited_reply_in_channel(our_user_id, message):\n                return (True, False)\n\n        # ignore anything else\n        return (False, False)\n\n    def log_mention(self, channel_id: int, send_timestamp: float) -> None:\n        self.last_reply_times.log_mention(channel_id, send_timestamp)\n\n    def get_unsolicited_channel_cap(self) -> int:\n        return self.last_reply_times.unsolicited_channel_cap", ""]}
{"filename": "src/oobabot/discrivener_message.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nData classes for all Discrivener messages, plus code\nto deserialize them from JSON.\n\"\"\"\n\n\nimport collections\nimport datetime\nimport typing", "import datetime\nimport typing\n\nfrom oobabot import types\n\n\ndef object_pairs_hook(\n    pairs: typing.List[typing.Tuple[str, typing.Any]]\n) -> typing.Union[\"types.DiscrivenerMessage\", dict]:\n    cls = MESSAGE_TYPE_TO_CLASS.get(pairs[0][0])\n    if cls is not None and len(pairs) == 1:\n        return cls(pairs[0][1])\n    return collections.OrderedDict(pairs)", "\n\nclass ChannelSilentData(types.DiscrivenerMessage):\n    \"\"\"\n    Represents whether any user is speaking in the channel.\n    \"\"\"\n\n    def __init__(self, data: dict):\n        self.type = types.DiscrivenerMessageType.CHANNEL_SILENT\n        self.silent = bool(data)\n\n    def __repr__(self):\n        return f\"ChannelSilent(silent={self.silent})\"", "\n\nclass ConnectData(types.DiscrivenerMessage):\n    \"\"\"\n    Represents us connecting or reconnecting to the voice channel.\n    \"\"\"\n\n    def __init__(self, data: dict):\n        self.type = types.DiscrivenerMessageType.CONNECT\n        self.channel_id = data.get(\"channel_id\")\n        self.guild_id = data.get(\"guild_id\")\n        self.session_id = data.get(\"session_id\")\n        self.server = data.get(\"server\")\n        self.ssrc = data.get(\"ssrc\")\n\n    def __repr__(self):\n        return (\n            f\"ConnectData(channel_id={self.channel_id}, \"\n            + f\"guild_id={self.guild_id}, \"\n            + f\"session_id={self.session_id}, \"\n            + f\"server={self.server}, \"\n            + f\"ssrc={self.ssrc})\"\n        )", "\n\nclass DisconnectData(types.DiscrivenerMessage):\n    \"\"\"\n    Represents a disconnect from the voice channel.\n    \"\"\"\n\n    def __init__(self, data: dict):\n        self.type = types.DiscrivenerMessageType.DISCONNECT\n        self.kind: str = data.get(\"kind\", \"unknown\")\n        self.reason: str = data.get(\"reason\", \"unknown\")\n        self.channel_id: int = data.get(\"channel_id\", 0)\n        self.guild_id: int = data.get(\"guild_id\", 0)\n        self.session_id: int = data.get(\"session_id\", 0)\n\n    def __repr__(self):\n        return (\n            f\"DisconnectData(kind={self.kind}, \"\n            + f\"reason={self.reason}, \"\n            + f\"channel_id={self.channel_id}, \"\n            + f\"guild_id={self.guild_id}, \"\n            + f\"session_id={self.session_id})\"\n        )", "\n\nclass UserJoinData(types.DiscrivenerMessage):\n    \"\"\"\n    Represents a user joining a voice channel.\n    \"\"\"\n\n    def __init__(self, data: int):\n        print(f\"UserJoinData data is {data}\")\n        self.type = types.DiscrivenerMessageType.USER_JOIN\n        self.user_id: int = data\n\n    def __str__(self):\n        return f\"User #{self.user_id} joined voice channel\"", "\n\nclass UserLeaveData(types.DiscrivenerMessage):\n    \"\"\"\n    Represents a user leaving a voice channel.\n    \"\"\"\n\n    def __init__(self, data: int):\n        print(f\"UserLeaveData data is {data}\")\n        self.type = types.DiscrivenerMessageType.USER_LEAVE\n        self.user_id: int = data\n\n    def __str__(self):\n        return f\"User #{self.user_id} left voice channel\"", "\n\nclass TokenWithProbability:\n    \"\"\"\n    Represents a token with a probability.\n    \"\"\"\n\n    def __init__(self, data: dict):\n        self.probability: int = data.get(\"p\", 0)\n        self.token_id: int = data.get(\"token_id\", 0)\n        self.token_text: str = str(data.get(\"token_text\"))\n\n    def __repr__(self):\n        return (\n            \"TokenWithProbability(\"\n            + f\"probability={self.probability}, \"\n            + f\"token_id={self.token_id}, \"\n            + f\"token_text={self.token_text})\"\n        )", "\n\ndef to_datetime(message: dict) -> datetime.datetime:\n    \"\"\"\n    Converts a message into a datetime object.\n    \"\"\"\n    seconds: int = message.get(\"secs_since_epoch\", 0)\n    nanos: int = message.get(\"nanos_since_epoch\", 0)\n    return datetime.datetime.fromtimestamp(seconds + nanos / 1e9)\n", "\n\ndef to_duration(message: dict) -> datetime.timedelta:\n    \"\"\"\n    Converts a message into a timedelta object.\n    \"\"\"\n    seconds: int = message.get(\"secs\", 0)\n    nanos: int = message.get(\"nanos\", 0)\n    return datetime.timedelta(seconds=seconds, microseconds=nanos / 1e3)\n", "\n\nclass TextSegment:\n    \"\"\"\n    Represents a single text segment of a transcribed message.\n    \"\"\"\n\n    def __init__(self, message: dict):\n        self.tokens_with_probability = [\n            TokenWithProbability(data)\n            for data in message.get(\"tokens_with_probability\", [])\n        ]\n        self.start_offset_ms: int = message.get(\"start_offset_ms\", 0)\n        self.end_offset_ms: int = message.get(\"end_offset_ms\", self.start_offset_ms + 1)\n\n    def __repr__(self):\n        return (\n            f\"TextSegment(tokens_with_probability={self.tokens_with_probability}, \"\n            + f\"start_offset_ms={self.start_offset_ms}, \"\n            + f\"end_offset_ms={self.end_offset_ms})\"\n        )\n\n    def __str__(self) -> str:\n        return \"\".join([t.token_text for t in self.tokens_with_probability])", "\n\nclass UserVoiceMessage(types.VoiceMessageWithTokens):\n    \"\"\"\n    Represents a transcribed message.\n    \"\"\"\n\n    def __init__(self, message: dict):\n        self.type = types.DiscrivenerMessageType.TRANSCRIPTION\n        self._processing_time: datetime.timedelta = to_duration(\n            message.get(\"processing_time\", datetime.timedelta(milliseconds=1.0))\n        )\n        self._segments: typing.List[TextSegment] = [\n            TextSegment(s) for s in message.get(\"segments\", [])\n        ]\n        super().__init__(\n            message.get(\"user_id\", 0),\n            to_datetime(message.get(\"start_timestamp\", datetime.datetime.now)),\n            to_duration(\n                message.get(\"audio_duration\", datetime.timedelta(milliseconds=1.0))\n            ),\n        )\n        self._latency: datetime.timedelta = (\n            datetime.datetime.now() - self._start_time - self._audio_duration\n        )\n\n    @property\n    def processing_time(self):\n        \"\"\"\n        Returns the processing time of the transcription.\n        \"\"\"\n        return self._processing_time\n\n    @property\n    def latency(self):\n        \"\"\"\n        Returns the latency of the transcription.\n        \"\"\"\n        return self._latency\n\n    @property\n    def text(self) -> str:\n        \"\"\"\n        Returns the text of the transcription.\n        \"\"\"\n        return \"\".join([str(s) for s in self._segments])\n\n    @property\n    def is_bot(self) -> bool:\n        \"\"\"\n        Returns whether the user is a bot.\n        \"\"\"\n        return False\n\n    @property\n    def tokens_with_confidence(self) -> typing.List[typing.Tuple[str, int]]:\n        \"\"\"\n        Returns the tokens with their confidence.\n        \"\"\"\n        return [\n            (t.token_text, t.probability)\n            for s in self._segments\n            for t in s.tokens_with_probability\n        ]\n\n    def __repr__(self) -> str:\n        return (\n            \"UserVoiceMessage(\"\n            + f\"start_time={self._start_time}, \"\n            + f\"user_id={self._user_id}, \"\n            + f\"audio_duration={self._audio_duration}, \"\n            + f\"processing_time={self._processing_time}, \"\n            + f\"segments={self._segments}, \"\n            + f\"latency={self._latency})\"\n        )", "\n\nMESSAGE_TYPE_TO_CLASS: typing.Dict[str, typing.Type[types.DiscrivenerMessage]] = {\n    types.DiscrivenerMessageType.CHANNEL_SILENT: ChannelSilentData,\n    types.DiscrivenerMessageType.CONNECT: ConnectData,\n    types.DiscrivenerMessageType.DISCONNECT: DisconnectData,\n    types.DiscrivenerMessageType.RECONNECT: ConnectData,\n    types.DiscrivenerMessageType.TRANSCRIPTION: UserVoiceMessage,\n    types.DiscrivenerMessageType.USER_JOIN: UserJoinData,\n    types.DiscrivenerMessageType.USER_LEAVE: UserLeaveData,", "    types.DiscrivenerMessageType.USER_JOIN: UserJoinData,\n    types.DiscrivenerMessageType.USER_LEAVE: UserLeaveData,\n}\n"]}
{"filename": "src/oobabot/overengineered_settings_parser.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nSettings library which supports both CLI and YAML settings files.\nAllows for settings to be exposed through one or both of these interfaces.\n\nload - sets defaults, then loads from YAML, then loads from CLI.\nload_from_cli - sets defaults, then loads from CLI only.\nload_from_dict - sets defaults, then loads from a dictionary only.\nload_from_yaml - sets defaults, then loads from YAML only.\nwrite_to_file - writes the given config as YAML to the given file.", "load_from_yaml - sets defaults, then loads from YAML only.\nwrite_to_file - writes the given config as YAML to the given file.\nwrite_to_stream - writes the given config as YAML to the given stream.\n\"\"\"\n\nimport argparse\nimport pathlib\nimport textwrap\nimport typing\n", "import typing\n\nimport ruamel.yaml as ryaml\nimport ruamel.yaml.error as ryaml_error\n\nimport oobabot\n\nYAML_WIDTH = 88\nDIVIDER = \"# \" * (YAML_WIDTH >> 1)\nINDENT_UNIT = 2", "DIVIDER = \"# \" * (YAML_WIDTH >> 1)\nINDENT_UNIT = 2\n\n\nclass ConfigFileMissingError(Exception):\n    \"\"\"\n    Raised when the config file is missing.\n    \"\"\"\n\n", "\n\nSettingDictType = typing.Dict[\n    str, typing.Union[bool, int, float, str, typing.List[str]]\n]\n\nSettingValueType = typing.Union[\n    bool, int, float, str, typing.List[str], SettingDictType\n]\n", "]\n\n\ndef format_yaml_comment(comment_lines: typing.List[str]) -> str:\n    out = []\n    for line in comment_lines:\n        out.append(\"\\n\".join(textwrap.wrap(line, width=YAML_WIDTH)))\n    return \"\\n\" + \"\\n\".join(out)\n\n\ndef add_to_group(\n    group: ryaml.CommentedMap,\n    key: str,\n    value: typing.Any,\n    comment_lines: typing.List[str],\n    indent: int,\n) -> None:\n    group[key] = value\n    group.yaml_set_comment_before_after_key(\n        key,\n        before=format_yaml_comment(comment_lines),\n        indent=indent,\n    )", "\n\ndef add_to_group(\n    group: ryaml.CommentedMap,\n    key: str,\n    value: typing.Any,\n    comment_lines: typing.List[str],\n    indent: int,\n) -> None:\n    group[key] = value\n    group.yaml_set_comment_before_after_key(\n        key,\n        before=format_yaml_comment(comment_lines),\n        indent=indent,\n    )", "\n\nT = typing.TypeVar(\"T\", bound=\"SettingValueType\")\n\n\nclass ConfigSetting(typing.Generic[T]):\n    \"\"\"\n    An individual setting that can be exposed through CLI and/or YAML\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        default: T,\n        description_lines: typing.List[str],\n        cli_args: typing.Optional[typing.List[str]] = None,\n        place_default_in_yaml: bool = False,\n        include_in_argparse: bool = True,\n        include_in_yaml: bool = True,\n        show_default_in_yaml: bool = True,\n        fn_on_set: typing.Callable[[T], None] = lambda x: None,\n    ):\n        self.name = name\n        self.default = default\n        self.description_lines = [x.strip() for x in description_lines]\n        if cli_args is None:\n            cli_args = [\"--\" + name.replace(\"_\", \"-\")]\n        self.cli_args = cli_args\n        self.value = default\n        self.include_in_argparse = include_in_argparse\n        self.include_in_yaml = include_in_yaml\n        self.place_default_in_yaml = place_default_in_yaml\n        self.show_default_in_yaml = show_default_in_yaml\n        self.fn_on_set = fn_on_set\n\n    def add_to_argparse(self, parser: argparse._ArgumentGroup):\n        if not self.include_in_argparse:\n            return\n\n        kwargs = {\n            \"default\": self.value,\n            \"help\": \" \".join(self.description_lines),\n        }\n\n        # note: the other way to do this is with\n        #   typing.get_args(self.__orig_class__)[0]\n        # but that isn't officially supported, so\n        # let's do it the jankier way\n        if isinstance(self.default, str):\n            kwargs[\"type\"] = str\n        elif isinstance(self.default, bool):\n            kwargs[\"action\"] = \"store_true\"\n            if self.default:\n                kwargs[\"action\"] = \"store_false\"\n        elif isinstance(self.default, int):\n            kwargs[\"type\"] = int\n        elif isinstance(self.default, float):\n            kwargs[\"type\"] = float\n        elif isinstance(self.default, list):\n            kwargs[\"type\"] = str\n            kwargs[\"nargs\"] = \"*\"\n\n        parser.add_argument(*self.cli_args, **kwargs)\n\n    def set_value_from_argparse(self, args: argparse.Namespace) -> None:\n        if not self.include_in_argparse:\n            return\n        if not hasattr(args, self.name):\n            raise ValueError(f\"Namespace does not have attribute {self.name}\")\n        self.set_value(getattr(args, self.name))\n\n    def add_to_yaml_group(self, group: ryaml.CommentedMap):\n        if not self.include_in_yaml:\n            return\n        value = None\n        if self.place_default_in_yaml or (self.value != self.default):\n            value = self.value\n        add_to_group(\n            group,\n            key=self.name,\n            value=value,\n            comment_lines=self.make_yaml_comment(),\n            indent=INDENT_UNIT,\n        )\n\n    def make_yaml_comment(self) -> typing.List[str]:\n        comment_lines = self.description_lines.copy()\n\n        if self.show_default_in_yaml:\n            if self.default is not None:\n                comment_lines.append(f\"  default: {self.default}\")\n            else:\n                comment_lines.append(\"  default: None\")\n        return comment_lines\n\n    def set_value_from_yaml(self, yaml: ryaml.CommentedMap) -> None:\n        if not self.include_in_yaml:\n            return\n        if self.name not in yaml:\n            return\n        if (not self.place_default_in_yaml) and (yaml[self.name] is None):\n            # if we didn't place the default in the yaml, and the setting\n            # is now blank, that's no surprise.  Keep the default\n            # rather than overwriting it with None\n            return\n        value = yaml[self.name]\n        # if value is a dict, it's possible that it only contains\n        # some, but not all of the keys that we need.  So we want to\n        # merge it with the default dict, overwriting the default\n        # values with the values from the yaml\n        if isinstance(value, dict):\n            if isinstance(self.default, dict):\n                value = {**self.default, **value}\n            else:\n                raise ValueError(\n                    f\"Setting {self.name} is a dict, but the default value is not\"\n                )\n        # note: keeping the type checker happy across python versions\n        # here is actually kinda hard.  It's worried about what the\n        # values in the combined dict might be.  But really it's fine,\n        # so just tell it to chill.\n        self.set_value(value)  # type: ignore\n\n    def set_value(self, value: T) -> None:\n        if isinstance(self.default, bool) and isinstance(value, str):\n            if value.lower() in [\"true\", \"yes\", \"1\"]:\n                value = True  # type: ignore\n            elif value.lower() in [\"false\", \"no\", \"0\"]:\n                value = False  # type: ignore\n            else:\n                value = bool(value)  # type: ignore\n\n        self.value = value\n        self.fn_on_set(value)\n\n    def get(self) -> T:\n        if isinstance(self.value, dict):\n            return self.value.copy()\n        return self.value", "\n\nclass ConfigSettingGroup:\n    \"\"\"\n    A group of related settings that can be exposed through CLI and/or YAML\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        description: str = \"\",\n        include_in_argparse: bool = True,\n        include_in_yaml: bool = True,\n    ):\n        self.name = name\n        self.description = description\n        self.settings = {}\n        self.include_in_argparse = include_in_argparse\n        self.include_in_yaml = include_in_yaml\n\n    def add_setting(self, setting: \"ConfigSetting\") -> None:\n        self.settings[setting.name] = setting\n\n    def add_to_argparse(self, parser: argparse.ArgumentParser):\n        if not self.include_in_argparse:\n            return\n        arg_group = parser.add_argument_group(self.name, self.description)\n        for setting in self.settings.values():\n            setting.add_to_argparse(arg_group)\n\n    def set_values_from_argparse(self, args: argparse.Namespace) -> None:\n        if not self.include_in_argparse:\n            return\n        for setting in self.settings.values():\n            setting.set_value_from_argparse(args)\n\n    def add_to_yaml(self, yaml: ryaml.CommentedMap):\n        if not self.include_in_yaml:\n            return\n        group_key = self.name.lower().replace(\" \", \"_\")\n\n        group = ryaml.CommentedMap()\n        for setting in self.settings.values():\n            setting.add_to_yaml_group(group)\n\n        add_to_group(\n            group=yaml,\n            key=group_key,\n            value=group,\n            comment_lines=[DIVIDER, group_key, \".\"],\n            indent=0,\n        )\n\n    def set_values_from_yaml(self, yaml: dict):\n        if not self.include_in_yaml:\n            return\n        if yaml is None:\n            return\n        group_key = self.name.lower().replace(\" \", \"_\")\n        if group_key not in yaml:\n            return\n        group = yaml[group_key]\n        for setting in self.settings.values():\n            setting.set_value_from_yaml(group)\n\n    def set_values_from_dict(self, main_dict: dict):\n        group_dict = main_dict.get(self.name.lower().replace(\" \", \"_\"), {})\n        for setting in self.settings.values():\n            if setting.name in group_dict:\n                val = group_dict[setting.name]\n                setting.set_value(val)\n\n    def set(self, name: str, value: SettingValueType) -> None:\n        self.settings[name].set_value(value)\n\n    def get_setting(self, name: str) -> ConfigSetting:\n        return self.settings[name]\n\n    def get(self, name: str) -> SettingValueType:\n        return self.settings[name].value\n\n    def get_str(self, name: str) -> str:\n        return self.settings[name].value\n\n    def get_list(self, name: str) -> typing.List[SettingValueType]:\n        return self.settings[name].value\n\n    def get_all(self) -> typing.Dict[str, SettingValueType]:\n        return {name: setting.get() for (name, setting) in self.settings.items()}.copy()", "\n\ndef load_from_yaml(\n    filename: str,\n    setting_groups: typing.List[\"ConfigSettingGroup\"],\n) -> typing.Optional[str]:\n    \"\"\"\n    Load settings from a YAML file only\n\n    Returns None if successful, or an error message if not\n    \"\"\"\n    try:\n        with open(filename, \"r\", encoding=\"utf-8\") as file:\n            return load_from_yaml_stream(file, setting_groups)\n\n    except (FileNotFoundError, IsADirectoryError):\n        return \"File not found\"", "\n\ndef load_from_yaml_stream(\n    stream: typing.Union[pathlib.Path, ryaml.StreamTextType],\n    setting_groups: typing.List[\"ConfigSettingGroup\"],\n) -> typing.Optional[str]:\n    \"\"\"\n    Load settings from a YAML string only\n\n    Returns None if successful, or an error message if not\n    \"\"\"\n    try:\n        yaml = ryaml.YAML(typ=\"safe\")\n        yaml_settings = yaml.load(stream)\n    except ryaml_error.MarkedYAMLError as err:\n        return str(err)\n\n    for group in setting_groups:\n        group.set_values_from_yaml(yaml_settings)\n    return None", "\n\ndef load_from_cli(\n    args,\n    setting_groups: typing.List[\"ConfigSettingGroup\"],\n) -> argparse.ArgumentParser:\n    \"\"\"\n    Load settings from the command line only\n    \"\"\"\n    cli_parser = argparse.ArgumentParser(\n        description=f\"oobabot v{oobabot.__version__}: Discord bot for \"\n        + \"oobabooga's text-generation-webui\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n        add_help=False,\n    )\n\n    # we need to initialize argparse AFTER we read from\n    # the yaml file, so that the argparse defaults are\n    # set to the yaml-read values.\n    for group in setting_groups:\n        group.add_to_argparse(cli_parser)\n\n    cli_settings = cli_parser.parse_args(args=args)\n    for group in setting_groups:\n        group.set_values_from_argparse(cli_settings)\n\n    return cli_parser", "\n\ndef load_from_dict(\n    setting_groups: typing.List[\"ConfigSettingGroup\"],\n    settings_dict: dict,\n) -> None:\n    \"\"\"\n    Load settings from a dictionary\n    \"\"\"\n    for group in setting_groups:\n        group.set_values_from_dict(settings_dict)", "\n\ndef load(\n    cli_args: typing.List[str],\n    setting_groups: typing.List[\"ConfigSettingGroup\"],\n    config_file: str,\n    raise_if_file_missing: bool,\n) -> argparse.ArgumentParser:\n    \"\"\"\n    Load settings from defaults, config.yml, and command line arguments\n    in that order.  Later sources will overwrite earlier ones.\n\n    Returns the argparse parser, which can be used to print out the help\n    message.\n    \"\"\"\n    load_error_message = load_from_yaml(config_file, setting_groups)\n    if load_error_message and raise_if_file_missing:\n        raise ConfigFileMissingError(load_error_message)\n\n    namespace = load_from_cli(cli_args, setting_groups)\n\n    # returning this since it can print out the help message\n    return namespace", "\n\nSTART_COMMENT = textwrap.dedent(\n    \"\"\"\n    # Welcome to Oobabot!\n    #\n    # This is the configuration file for Oobabot.  It is a YAML file, and\n    # comments are allowed.  Oobabot attempts to load a file named\n    # \"config.yml\" from the current directory when it is run.\n    #", "    # \"config.yml\" from the current directory when it is run.\n    #\n    \"\"\"\n)\n\n\ndef write_to_stream(\n    setting_groups: typing.List[\"ConfigSettingGroup\"],\n    out_stream: typing.TextIO,\n) -> None:\n    yaml_map = ryaml.CommentedMap()\n    yaml_map.yaml_set_start_comment(START_COMMENT)\n\n    add_to_group(\n        group=yaml_map,\n        key=\"version\",\n        value=oobabot.__version__,\n        comment_lines=[],\n        indent=0,\n    )\n\n    for group in setting_groups:\n        group.add_to_yaml(yaml_map)\n\n    yaml = ryaml.YAML()\n    yaml.default_flow_style = False\n    yaml.allow_unicode = True\n    yaml.indent(mapping=INDENT_UNIT, sequence=2 * INDENT_UNIT, offset=INDENT_UNIT)\n\n    yaml.dump(yaml_map, out_stream)", "\n\ndef write_to_file(\n    setting_groups: typing.List[\"ConfigSettingGroup\"], filename: str\n) -> None:\n    \"\"\"\n    Write the current values in the setting groups to a YAML file\n    \"\"\"\n    with open(filename, \"w\", encoding=\"utf-8\") as file:\n        write_to_stream(setting_groups, file)", ""]}
{"filename": "src/oobabot/runtime.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nContains all runtime state of the bot.\n\"\"\"\n\nimport asyncio\nfrom concurrent import futures\nimport contextlib\nimport threading\nimport typing", "import threading\nimport typing\n\nimport discord\n\nfrom oobabot import bot_commands\nfrom oobabot import decide_to_respond\nfrom oobabot import discord_bot\nfrom oobabot import fancy_logger\nfrom oobabot import http_client", "from oobabot import fancy_logger\nfrom oobabot import http_client\nfrom oobabot import image_generator\nfrom oobabot import ooba_client\nfrom oobabot import persona\nfrom oobabot import prompt_generator\nfrom oobabot import repetition_tracker\nfrom oobabot import response_stats\nfrom oobabot import sd_client\nfrom oobabot import settings", "from oobabot import sd_client\nfrom oobabot import settings\nfrom oobabot import templates\n\n\nclass OobabotRuntimeError(Exception):\n    \"\"\"\n    Raised when the bot encounters an error that it can't recover from.\n    \"\"\"\n", "\n\nclass Runtime:\n    \"\"\"\n    Contains all the runtime state of the bot.  It should be\n    created once the configuration is known.\n    \"\"\"\n\n    def __init__(self, settings: settings.Settings):\n        # templates used to generate prompts to send to the AI\n        # as well as for some UI elements\n        self.template_store = templates.TemplateStore(\n            settings=settings.template_settings.get_all()\n        )\n\n        ########################################################\n        # Connect to Oobabooga\n\n        self.ooba_client = ooba_client.OobaClient(\n            settings=settings.oobabooga_settings.get_all(),\n        )\n\n        ########################################################\n        # Connect to Stable Diffusion, if configured\n\n        self.stable_diffusion_client: typing.Optional[\n            sd_client.StableDiffusionClient\n        ] = None\n        sd_settings = settings.stable_diffusion_settings.get_all()\n        if sd_settings[\"stable_diffusion_url\"]:\n            self.stable_diffusion_client = sd_client.StableDiffusionClient(\n                settings=sd_settings,\n                magic_model_key=settings.SD_CLIENT_MAGIC_MODEL_KEY,\n            )\n\n        ########################################################\n        # Bot logic\n\n        self.persona = persona.Persona(\n            persona_settings=settings.persona_settings.get_all()\n        )\n\n        # decides which messages the bot will respond to\n        self.decide_to_respond = decide_to_respond.DecideToRespond(\n            discord_settings=settings.discord_settings.get_all(),\n            persona=self.persona,\n            interrobang_bonus=settings.DECIDE_TO_RESPOND_INTERROBANG_BONUS,\n            time_vs_response_chance=settings.TIME_VS_RESPONSE_CHANCE,\n        )\n\n        # once we decide to respond, this generates a prompt\n        # to send to the AI, given a message history\n        self.prompt_generator = prompt_generator.PromptGenerator(\n            discord_settings=settings.discord_settings.get_all(),\n            oobabooga_settings=settings.oobabooga_settings.get_all(),\n            persona=self.persona,\n            template_store=self.template_store,\n        )\n\n        # tracks of the time spent on responding, success rate, etc.\n        self.response_stats = response_stats.AggregateResponseStats(\n            fn_get_total_tokens=lambda: self.ooba_client.total_response_tokens\n        )\n\n        # generates images, if stable diffusion is configured\n        # also includes a UI to regenerate images on demand\n        self.image_generator = None\n        if self.stable_diffusion_client is not None:\n            self.image_generator = image_generator.ImageGenerator(\n                ooba_client=self.ooba_client,\n                persona_settings=settings.persona_settings.get_all(),\n                prompt_generator=self.prompt_generator,\n                sd_settings=settings.stable_diffusion_settings.get_all(),\n                stable_diffusion_client=self.stable_diffusion_client,\n                template_store=self.template_store,\n            )\n\n        # if a bot sees itself repeating a message over and over,\n        # it will keep doing so forever.  This attempts to fix that.\n        # by looking for repeated responses, and deciding how far\n        # back in history the bot can see.\n        self.repetition_tracker = repetition_tracker.RepetitionTracker(\n            repetition_threshold=settings.REPETITION_TRACKER_THRESHOLD\n        )\n\n        self.bot_commands = bot_commands.BotCommands(\n            decide_to_respond=self.decide_to_respond,\n            repetition_tracker=self.repetition_tracker,\n            persona=self.persona,\n            discord_settings=settings.discord_settings.get_all(),\n            template_store=self.template_store,\n            ooba_client=self.ooba_client,\n            prompt_generator=self.prompt_generator,\n        )\n\n        ########################################################\n        # Connect to Discord\n\n        self.discord_bot = discord_bot.DiscordBot(\n            bot_commands=self.bot_commands,\n            decide_to_respond=self.decide_to_respond,\n            discord_settings=settings.discord_settings.get_all(),\n            ooba_client=self.ooba_client,\n            image_generator=self.image_generator,\n            persona=self.persona,\n            prompt_generator=self.prompt_generator,\n            repetition_tracker=self.repetition_tracker,\n            response_stats=self.response_stats,\n        )\n\n        self.discord_token = settings.discord_settings.get_str(\"discord_token\")\n\n    def test_connections(self) -> bool:\n        \"\"\"\n        Tests that we can connect to all services we depend on.\n        Does not test Discord connectivity.\n\n        Returns True if all configured connections succeeded,\n        False otherwise.\n        \"\"\"\n\n        for client in [self.ooba_client, self.stable_diffusion_client]:\n            if client is None:\n                continue\n\n            fancy_logger.get().info(\"%s is at %s\", client.service_name, client.base_url)\n            try:\n                client.test_connection()\n                fancy_logger.get().info(\"Connected to %s!\", client.service_name)\n            except (ValueError, http_client.OobaHttpClientError) as err:\n                fancy_logger.get().warning(\n                    \"Could not connect to %s server: [%s]\",\n                    client.service_name,\n                    client.base_url,\n                )\n                fancy_logger.get().warning(\"Please check the URL and try again.\")\n                if err.__cause__ is not None:\n                    fancy_logger.get().error(\"Reason: %s\", err.__cause__)\n                return False\n        return True\n\n    async def run(self):\n        \"\"\"\n        Opens HTTP connections to oobabooga and stable diffusion,\n        then connects to Discord.  Blocks until the bot is stopped.\n\n        Raises OobabotRuntimeError if the bot cannot connect to Discord.\n        \"\"\"\n\n        async with contextlib.AsyncExitStack() as stack:\n            for context_manager in [\n                self.ooba_client,\n                self.stable_diffusion_client,\n            ]:\n                if context_manager is not None:\n                    await stack.enter_async_context(context_manager)\n\n            try:\n                fancy_logger.get().info(\"Connecting to Discord... \")\n                await self.discord_bot.start(self.discord_token)\n                fancy_logger.get().info(\"Discord bot exited.\")\n\n            except discord.errors.PrivilegedIntentsRequired as err:\n                fancy_logger.get().warning(\"Could not log in to Discord: %s\", err)\n                fancy_logger.get().warning(\n                    \"The bot token you provided does not have the required \"\n                    + \"gateway intents.  Did you remember to enable both \"\n                    + \"'SERVER MEMBERS INTENT' and 'MESSAGE CONTENT INTENT' \"\n                    + \"in the bot's settings on Discord?\"\n                )\n                raise OobabotRuntimeError(\n                    \"Could not log in to Discord: intents not set\"\n                ) from err\n\n            except discord.LoginFailure as err:\n                fancy_logger.get().warning(\"Could not log in to Discord: %s\", err)\n                fancy_logger.get().warning(\"Please check the token and try again.\")\n                raise OobabotRuntimeError(\n                    \"Could not log in to Discord: invalid token\"\n                ) from err\n\n            finally:\n                await self.discord_bot.close()\n        fancy_logger.get().info(\"Disconnected from Discord.\")\n\n    def stop(self, wait_timeout: float = 5.0) -> None:\n        \"\"\"\n        Stops the bot, if it's running.  Safe to be called\n        from a separate thread from the one that called run().\n\n        Blocks until the bot is gracefully stopped, or until\n        wait_timeout seconds have passed, whichever comes first.\n        \"\"\"\n\n        self.response_stats.write_stat_summary_to_log()\n\n        # if we're on our main thread, then we can just terminate\n        # the bot loop directly.  But if we're on a separate thread,\n        # then we need to call it from the  discord bot's event loop.\n        if threading.current_thread() == threading.main_thread():\n            self.discord_bot.loop.stop()\n            return\n\n        try:\n            # if discord is already stopped, then their .loop is set\n            # _MissingSentinel.  So instead check if it's still connected.\n            if self.discord_bot.is_closed():\n                fancy_logger.get().info(\"Discord bot already stopped.\")\n                return\n\n            future = asyncio.run_coroutine_threadsafe(\n                self.discord_bot.close(),\n                self.discord_bot.loop,\n            )\n            future.result(timeout=wait_timeout)\n        except RuntimeError as err:\n            # this can happen if the main application is shutting down\n            fancy_logger.get().error(\"Could not stop Discord bot: %s\", err)\n            raise OobabotRuntimeError(\"Discord bot is already stopped.\") from err\n        except futures.TimeoutError:\n            fancy_logger.get().warning(\n                \"Discord bot did not stop in time, it might be busted.\"\n            )", ""]}
{"filename": "src/oobabot/fancy_logger.py", "chunked_list": ["# -*- coding: utf-8 -*-\n\"\"\"\nLogging with colors\n\"\"\"\n\nimport html\nimport logging\nimport sys\nimport textwrap\nimport typing", "import textwrap\nimport typing\n\nfrom oobabot import discord_utils\n\nFOREGROUND_COLORS = {\n    \"black\": 30,\n    \"red\": 31,\n    \"green\": 32,\n    \"yellow\": 33,", "    \"green\": 32,\n    \"yellow\": 33,\n    \"blue\": 34,\n    \"magenta\": 35,\n    \"cyan\": 36,\n    \"white\": 37,\n}\n\nBACKGROUND_COLORS = {k: v + 10 for k, v in FOREGROUND_COLORS.items()}\n", "BACKGROUND_COLORS = {k: v + 10 for k, v in FOREGROUND_COLORS.items()}\n\nHTML_HEADER = textwrap.dedent(\n    \"\"\"\n    <!DOCTYPE html>\n    <html lang=\"en\">\n    <head>\n    <meta charset=\"utf-8\">\n    <title>oobabot logs</title>\n    <style>", "    <title>oobabot logs</title>\n    <style>\n    body {\n        background-color: #0C0C0C;\n        color: #CCCCCC;\n        font-family: Consolas, Lucida Console, monospace;\n    }\n    .oobabot-red {\n        color: #C50F1F;\n    }", "        color: #C50F1F;\n    }\n    .oobabot-yellow {\n        color: #C19C00;\n    }\n    .oobabot-cyan {\n        color: #3A96DD;\n    }\n    .oobabot-white {\n        color: #CCCCCC;", "    .oobabot-white {\n        color: #CCCCCC;\n    }\n    </style>\n    </head>\n    <body><div class=\"oobabot-log\">\n    \"\"\"\n)\nHTML_RECORD_SEPARATOR = \"\\n<br>\"\nHTML_FOOTER = \"</div></body></html>\"", "HTML_RECORD_SEPARATOR = \"\\n<br>\"\nHTML_FOOTER = \"</div></body></html>\"\n\n\ndef apply_color_console(color: str, text: str, bg_color: str = \"black\") -> str:\n    return (\n        f\"\\033[{FOREGROUND_COLORS[color]};{BACKGROUND_COLORS[bg_color]}m{text}\\033[0m\"\n    )\n\n\ndef apply_color_html(color: str, text: str) -> str:\n    return f\"<span class='oobabot-{color}'>{text}</span>\"", "\n\ndef apply_color_html(color: str, text: str) -> str:\n    return f\"<span class='oobabot-{color}'>{text}</span>\"\n\n\ndef make_coloring_book(\n    fn_apply_color: typing.Callable[[str, str], str]\n) -> typing.Dict[int, str]:\n    prefix = (\n        f'{fn_apply_color(\"yellow\", \"%(asctime)s\")}'\n        + f'{fn_apply_color(\"white\", \" %(levelname)5s \")}'\n    )\n    msg = \"%(message)s\"\n    return {\n        logging.DEBUG: prefix + fn_apply_color(\"cyan\", msg),\n        logging.INFO: prefix + fn_apply_color(\"white\", msg),\n        logging.WARNING: prefix + fn_apply_color(\"yellow\", msg),\n        logging.ERROR: prefix + fn_apply_color(\"red\", msg),\n        logging.CRITICAL: prefix + fn_apply_color(\"red\", msg),\n    }", "\n\nclass ColorfulLoggingFormatter(logging.Formatter):\n    \"\"\"\n    Logging formatter that adds colors to the log levels.\n    \"\"\"\n\n    def __init__(\n        self,\n        coloring_book: typing.Dict[int, str],\n        fn_format_message: typing.Optional[\n            typing.Callable[[typing.Optional[typing.Any]], typing.Optional[typing.Any]]\n        ] = None,\n    ) -> None:\n        super().__init__()\n        self.formatters = {}\n        for logging_level, fmt_color in coloring_book.items():\n            self.formatters[logging_level] = logging.Formatter(fmt_color)\n        self.fn_format_message = fn_format_message\n\n    def format(self, record: logging.LogRecord) -> str:\n        if self.fn_format_message:\n            record = logging.makeLogRecord(record.__dict__)\n            record.msg = self.fn_format_message(record.msg)\n            # record.args is a tuple.  Call self.fn_format_message for each\n            # element of the tuple, and then reassemble the tuple.\n            if record.args:\n                record.args = tuple(self.fn_format_message(arg) for arg in record.args)\n\n        formatter = self.formatters.get(record.levelno)\n        if formatter:\n            result = formatter.format(record)\n\n            # From the Python docs for logging.Formatter():\n            # ...you should be careful if you have more than one Formatter\n            # subclass which customizes the formatting of exception information.\n            # In this case, you will have to clear the cached value (by setting\n            # the exc_text attribute to None) after a formatter has done its\n            # formatting, so that the next formatter to handle the event doesn\u2019t\n            # use the cached value, but recalculates it afresh.\n            record.exc_text = None\n            return result\n        return record.getMessage()", "\n\ndef get(name: str = \"oobabot\") -> logging.Logger:\n    return logging.getLogger(name)\n\n\ndef do_escape(msg: typing.Optional[typing.Any]) -> typing.Optional[typing.Any]:\n    if msg is None:\n        return None\n    if not isinstance(msg, str):\n        return msg\n    result = html.escape(msg)\n    return result", "\n\ndef init_logging(\n    level: typing.Union[int, str],\n    running_from_cli: bool = True,\n) -> None:\n    logger = get()\n    logger.setLevel(level)\n\n    if running_from_cli:\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(level)\n        console_handler.setFormatter(\n            ColorfulLoggingFormatter(\n                coloring_book=make_coloring_book(apply_color_console),\n            )\n        )\n        logger.addHandler(console_handler)\n\n        discord_utils.setup_logging(\n            handler=logging.StreamHandler(),\n            level=logging.INFO,\n            formatter=ColorfulLoggingFormatter(\n                coloring_book=make_coloring_book(\n                    lambda a, b: apply_color_console(a, b, \"magenta\")\n                ),\n            ),\n            root=False,\n        )\n\n    recent_logs.setLevel(level)\n    recent_logs.setFormatter(\n        ColorfulLoggingFormatter(\n            coloring_book=make_coloring_book(apply_color_html),\n            fn_format_message=do_escape,\n        )\n    )\n    logger.addHandler(recent_logs)", "\n\n# the following class was modified from O'Reilly's Python Cookbook,\n# chapter 5, section 19.  Its use is allowed under this license:\n# Copyright (c) 2001, S\u00e9bastien Keim\n# All rights reserved.\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#    * Redistributions of source code must retain the above copyright", "# are met:\n#    * Redistributions of source code must retain the above copyright\n#      notice, this list of conditions and the following disclaimer.\n#    * Redistributions in binary form must reproduce the above\n#      copyright notice, this list of conditions and the following\n#      disclaimer in the documentation and/or other materials provided\n#      with the distribution.\n#    * Neither the name of the <ORGANIZATION> nor the names of its\n#      contributors may be used to endorse or promote products derived\n#      from this software without specific prior written permission.", "#      contributors may be used to endorse or promote products derived\n#      from this software without specific prior written permission.\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS\n# OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,", "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\n# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR\n# OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n# ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nclass RingBuffer:\n    \"\"\"\n    A generic ring buffer.\n    \"\"\"\n\n    def __init__(self, size_max: int):\n        self.cur = 0\n        self.max = size_max\n        self.data: typing.List[str] = []\n\n    class _FullRingBuffer:\n        \"\"\"\n        Class implementing the RingBuffer when it's full.\n        With python class magic, this class is swapped in when the\n        buffer becomes full.\n        \"\"\"\n\n        cur: int\n        max: int\n        data: typing.List[str]\n\n        def append(self, val: str) -> None:\n            \"\"\"\n            Append an element overwriting the oldest one.\n            \"\"\"\n            self.data[self.cur] = val\n            self.cur = (self.cur + 1) % self.max\n\n        def get(self) -> typing.List[str]:\n            \"\"\"\n            Return a list of elements from the oldest to the newest.\n            \"\"\"\n            return self.data[self.cur :] + self.data[: self.cur]\n\n        def size(self) -> int:\n            \"\"\"\n            Return the size of the buffer.\n            \"\"\"\n            return self.max\n\n    def append(self, val: str) -> None:\n        \"\"\"\n        Append an element at the end of the buffer.\n        \"\"\"\n        self.data.append(val)\n        if len(self.data) == self.max:\n            self.cur = 0\n            # Permanently change self's class from non-full to full\n            self.__class__ = self._FullRingBuffer\n\n    def get(self) -> typing.List[str]:\n        \"\"\"\n        Return a list of elements from the oldest to the newest.\n        \"\"\"\n        return self.data\n\n    def size(self) -> int:\n        \"\"\"\n        Return the number of elements currently in the buffer.\n        \"\"\"\n        return len(self.data)", "\n\n# end of O'Reilly code\n\n\nclass RingBufferedHandler(logging.Handler):\n    \"\"\"\n    A singleton logging handler that stores the last N log messages in a ring buffer.\n    \"\"\"\n\n    def __init__(self, buffer_size: int = 45) -> None:\n        super().__init__()\n        self.change_count = 0\n        self.buffer = RingBuffer(buffer_size)\n\n    def emit(self, record: logging.LogRecord) -> None:\n        self.change_count += 1\n        self.buffer.append(self.format(record))\n\n    @property\n    def changes(self) -> int:\n        \"\"\"\n        Return the number of times the buffer has been\n        updated.\n        \"\"\"\n        return self.change_count\n\n    def get_all(self) -> typing.List[str]:\n        return self.buffer.get()", "\n\nrecent_logs = RingBufferedHandler()\n\n\n# def log_async_task(fn_inner):\n#     \"\"\"\n#     Decorator for async tasks that logs unhandled exceptions.\n#     This is useful for tasks that won't be awaited until the\n#     program exits.  With this, the error will be logged as it", "#     This is useful for tasks that won't be awaited until the\n#     program exits.  With this, the error will be logged as it\n#     happens, rather than when the task is awaited.\n#     \"\"\"\n\n#     @functools.wraps(fn_inner)\n#     async def wrapper(*args, **kwargs):\n#         try:\n#             return await fn_inner(*args, **kwargs)\n#         except (KeyboardInterrupt, SystemExit):", "#             return await fn_inner(*args, **kwargs)\n#         except (KeyboardInterrupt, SystemExit):\n#             get().info(\"Exiting async task due to interrupt\")\n#             raise\n#         except Exception as err:\n#             get().error(\"Unhandled exception from async task\", exc_info=err)\n#             raise\n\n#     return wrapper\n", "#     return wrapper\n\n\ndef excepthook(exc_type, exc_value, exc_traceback):\n    if issubclass(exc_type, (KeyboardInterrupt, SystemExit)):\n        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n    get().error(\"Unhandled exception\", exc_info=(exc_type, exc_value, exc_traceback))\n"]}
