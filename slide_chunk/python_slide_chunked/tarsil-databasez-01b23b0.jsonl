{"filename": "tests/test_connection_options.py", "chunked_list": ["\"\"\"\nUnit tests for the backend connection arguments.\n\"\"\"\nimport sys\n\nimport pytest\nfrom tests.test_databases import DATABASE_URLS, async_adapter\n\nfrom databasez.backends.aiopg import AiopgBackend\nfrom databasez.backends.asyncmy import AsyncMyBackend", "from databasez.backends.aiopg import AiopgBackend\nfrom databasez.backends.asyncmy import AsyncMyBackend\nfrom databasez.backends.mysql import MySQLBackend\nfrom databasez.backends.postgres import PostgresBackend\nfrom databasez.core import DatabaseURL\n\n\ndef test_postgres_pool_size():\n    backend = PostgresBackend(\"postgres://localhost/database?min_size=1&max_size=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"min_size\": 1, \"max_size\": 20}", "\n\n@async_adapter\nasync def test_postgres_pool_size_connect():\n    for url in DATABASE_URLS:\n        if DatabaseURL(url).dialect != \"postgresql\":\n            continue\n        backend = PostgresBackend(url + \"?min_size=1&max_size=20\")\n        await backend.connect()\n        await backend.disconnect()", "\n\ndef test_postgres_explicit_pool_size():\n    backend = PostgresBackend(\"postgres://localhost/database\", min_size=1, max_size=20)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"min_size\": 1, \"max_size\": 20}\n\n\ndef test_postgres_ssl():\n    backend = PostgresBackend(\"postgres://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "def test_postgres_ssl():\n    backend = PostgresBackend(\"postgres://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\ndef test_postgres_explicit_ssl():\n    backend = PostgresBackend(\"postgres://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "\n\ndef test_postgres_no_extra_options():\n    backend = PostgresBackend(\"postgres://localhost/database\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {}\n\n\ndef test_postgres_password_as_callable():\n    def gen_password():\n        return \"Foo\"\n\n    backend = PostgresBackend(\"postgres://:password@localhost/database\", password=gen_password)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"password\": gen_password}\n    assert kwargs[\"password\"]() == \"Foo\"", "def test_postgres_password_as_callable():\n    def gen_password():\n        return \"Foo\"\n\n    backend = PostgresBackend(\"postgres://:password@localhost/database\", password=gen_password)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"password\": gen_password}\n    assert kwargs[\"password\"]() == \"Foo\"\n\n", "\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_pool_size():\n    backend = MySQLBackend(\"mysql://localhost/database?min_size=1&max_size=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_unix_socket():\n    backend = MySQLBackend(\n        \"mysql+aiomysql://username:password@/testsuite?unix_socket=/tmp/mysqld/mysqld.sock\"\n    )\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"unix_socket\": \"/tmp/mysqld/mysqld.sock\"}", "\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_unix_socket():\n    backend = MySQLBackend(\n        \"mysql+aiomysql://username:password@/testsuite?unix_socket=/tmp/mysqld/mysqld.sock\"\n    )\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"unix_socket\": \"/tmp/mysqld/mysqld.sock\"}\n\n", "\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_explicit_pool_size():\n    backend = MySQLBackend(\"mysql://localhost/database\", min_size=1, max_size=20)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_ssl():\n    backend = MySQLBackend(\"mysql://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_ssl():\n    backend = MySQLBackend(\"mysql://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_explicit_ssl():\n    backend = MySQLBackend(\"mysql://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_explicit_ssl():\n    backend = MySQLBackend(\"mysql://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mysql_pool_recycle():\n    backend = MySQLBackend(\"mysql://localhost/database?pool_recycle=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"pool_recycle\": 20}", "def test_mysql_pool_recycle():\n    backend = MySQLBackend(\"mysql://localhost/database?pool_recycle=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"pool_recycle\": 20}\n\n\n@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_pool_size():\n    backend = AsyncMyBackend(\"mysql+asyncmy://localhost/database?min_size=1&max_size=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}", "\n\n@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_unix_socket():\n    backend = AsyncMyBackend(\n        \"mysql+asyncmy://username:password@/testsuite?unix_socket=/tmp/mysqld/mysqld.sock\"\n    )\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"unix_socket\": \"/tmp/mysqld/mysqld.sock\"}\n", "\n\n@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_explicit_pool_size():\n    backend = AsyncMyBackend(\"mysql://localhost/database\", min_size=1, max_size=20)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}\n\n\n@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_ssl():\n    backend = AsyncMyBackend(\"mysql+asyncmy://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "\n@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_ssl():\n    backend = AsyncMyBackend(\"mysql+asyncmy://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\n@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_explicit_ssl():\n    backend = AsyncMyBackend(\"mysql+asyncmy://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_explicit_ssl():\n    backend = AsyncMyBackend(\"mysql+asyncmy://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\n@pytest.mark.skipif(sys.version_info < (3, 7), reason=\"requires python3.7 or higher\")\ndef test_asyncmy_pool_recycle():\n    backend = AsyncMyBackend(\"mysql+asyncmy://localhost/database?pool_recycle=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"pool_recycle\": 20}", "def test_asyncmy_pool_recycle():\n    backend = AsyncMyBackend(\"mysql+asyncmy://localhost/database?pool_recycle=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"pool_recycle\": 20}\n\n\ndef test_aiopg_pool_size():\n    backend = AiopgBackend(\"postgresql+aiopg://localhost/database?min_size=1&max_size=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}", "\n\ndef test_aiopg_explicit_pool_size():\n    backend = AiopgBackend(\"postgresql+aiopg://localhost/database\", min_size=1, max_size=20)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}\n\n\ndef test_aiopg_ssl():\n    backend = AiopgBackend(\"postgresql+aiopg://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "def test_aiopg_ssl():\n    backend = AiopgBackend(\"postgresql+aiopg://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\ndef test_aiopg_explicit_ssl():\n    backend = AiopgBackend(\"postgresql+aiopg://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mssql_pool_size():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database?min_size=1&max_size=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mssql_explicit_pool_size():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database\", min_size=1, max_size=20)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}", "\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mssql_explicit_pool_size():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database\", min_size=1, max_size=20)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"minsize\": 1, \"maxsize\": 20}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mssql_ssl():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mssql_ssl():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database?ssl=true\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mssql_explicit_ssl():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}", "def test_mssql_explicit_ssl():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database\", ssl=True)\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"ssl\": True}\n\n\n@pytest.mark.skipif(sys.version_info >= (3, 10), reason=\"requires python3.9 or lower\")\ndef test_mssql_pool_recycle():\n    backend = MySQLBackend(\"mssql+pyodbc://localhost/database?pool_recycle=20\")\n    kwargs = backend._get_connection_kwargs()\n    assert kwargs == {\"pool_recycle\": 20}", ""]}
{"filename": "tests/test_importer.py", "chunked_list": ["import pytest\n\nfrom databasez.importer import ImportFromStringError, import_from_string\n\n\ndef test_invalid_format():\n    with pytest.raises(ImportFromStringError) as exc_info:\n        import_from_string(\"example:\")\n    expected = 'Import string \"example:\" must be in format \"<module>:<attribute>\".'\n    assert exc_info.match(expected)", "\n\ndef test_invalid_module():\n    with pytest.raises(ImportFromStringError) as exc_info:\n        import_from_string(\"module_does_not_exist:myattr\")\n    expected = 'Could not import module \"module_does_not_exist\".'\n    assert exc_info.match(expected)\n\n\ndef test_invalid_attr():\n    with pytest.raises(ImportFromStringError) as exc_info:\n        import_from_string(\"tempfile:attr_does_not_exist\")\n    expected = 'Attribute \"attr_does_not_exist\" not found in module \"tempfile\".'\n    assert exc_info.match(expected)", "\ndef test_invalid_attr():\n    with pytest.raises(ImportFromStringError) as exc_info:\n        import_from_string(\"tempfile:attr_does_not_exist\")\n    expected = 'Attribute \"attr_does_not_exist\" not found in module \"tempfile\".'\n    assert exc_info.match(expected)\n\n\ndef test_internal_import_error():\n    with pytest.raises(ImportError):\n        import_from_string(\"tests.importer.raise_import_error:myattr\")", "def test_internal_import_error():\n    with pytest.raises(ImportError):\n        import_from_string(\"tests.importer.raise_import_error:myattr\")\n\n\ndef test_valid_import():\n    instance = import_from_string(\"tempfile:TemporaryFile\")\n    from tempfile import TemporaryFile\n\n    assert instance == TemporaryFile", ""]}
{"filename": "tests/test_integration.py", "chunked_list": ["import pytest\nimport sqlalchemy\nfrom esmerald import Gateway\nfrom esmerald import JSONResponse as EsmeraldJSONResponse\nfrom esmerald import Request, route\nfrom esmerald.applications import Esmerald\nfrom esmerald.testclient import EsmeraldTestClient\nfrom starlette.applications import Starlette\nfrom starlette.responses import JSONResponse\nfrom starlette.testclient import TestClient", "from starlette.responses import JSONResponse\nfrom starlette.testclient import TestClient\nfrom tests.test_databases import DATABASE_URLS\n\nfrom databasez import Database, DatabaseURL\n\nmetadata = sqlalchemy.MetaData()\n\nnotes = sqlalchemy.Table(\n    \"notes\",", "notes = sqlalchemy.Table(\n    \"notes\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"text\", sqlalchemy.String(length=100)),\n    sqlalchemy.Column(\"completed\", sqlalchemy.Boolean),\n)\n\n\n@pytest.fixture(autouse=True, scope=\"module\")\ndef create_test_database():\n    # Create test databases\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        elif database_url.scheme in [\n            \"mssql\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n            \"mssql+pymssql\",\n        ]:\n            url = str(database_url.replace(driver=\"pyodbc\"))\n        engine = sqlalchemy.create_engine(url)\n        metadata.create_all(engine)\n\n    # Run the test suite\n    yield\n\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        elif database_url.scheme in [\n            \"mssql\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n            \"mssql+pymssql\",\n        ]:\n            url = str(database_url.replace(driver=\"pyodbc\"))\n        engine = sqlalchemy.create_engine(url)\n        metadata.drop_all(engine)", "\n@pytest.fixture(autouse=True, scope=\"module\")\ndef create_test_database():\n    # Create test databases\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        elif database_url.scheme in [\n            \"mssql\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n            \"mssql+pymssql\",\n        ]:\n            url = str(database_url.replace(driver=\"pyodbc\"))\n        engine = sqlalchemy.create_engine(url)\n        metadata.create_all(engine)\n\n    # Run the test suite\n    yield\n\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        elif database_url.scheme in [\n            \"mssql\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n            \"mssql+pymssql\",\n        ]:\n            url = str(database_url.replace(driver=\"pyodbc\"))\n        engine = sqlalchemy.create_engine(url)\n        metadata.drop_all(engine)", "\n\ndef get_app(database_url):\n    database = Database(database_url, force_rollback=True)\n    app = Starlette()\n\n    @app.on_event(\"startup\")\n    async def startup():\n        await database.connect()\n\n    @app.on_event(\"shutdown\")\n    async def shutdown():\n        await database.disconnect()\n\n    @app.route(\"/notes\", methods=[\"GET\"])\n    async def list_notes(request):\n        query = notes.select()\n        results = await database.fetch_all(query)\n        content = [\n            {\"text\": result[\"text\"], \"completed\": result[\"completed\"]} for result in results\n        ]\n        return JSONResponse(content)\n\n    @app.route(\"/notes\", methods=[\"POST\"])\n    async def add_note(request):\n        data = await request.json()\n        query = notes.insert().values(text=data[\"text\"], completed=data[\"completed\"])\n        await database.execute(query)\n        return JSONResponse({\"text\": data[\"text\"], \"completed\": data[\"completed\"]})\n\n    return app", "\n\ndef get_esmerald_app(database_url):\n    database = Database(database_url, force_rollback=True)\n\n    @route(\"/notes\", methods=[\"GET\"])\n    async def list_notes(request: Request) -> EsmeraldJSONResponse:\n        query = notes.select()\n        results = await database.fetch_all(query)\n        content = [\n            {\"text\": result[\"text\"], \"completed\": result[\"completed\"]} for result in results\n        ]\n        return EsmeraldJSONResponse(content)\n\n    @route(\"/notes\", methods=[\"POST\"])\n    async def add_notes(request: Request) -> EsmeraldJSONResponse:\n        data = await request.json()\n        query = notes.insert().values(text=data[\"text\"], completed=data[\"completed\"])\n        await database.execute(query)\n        return EsmeraldJSONResponse({\"text\": data[\"text\"], \"completed\": data[\"completed\"]})\n\n    app = Esmerald(routes=[Gateway(handler=list_notes), Gateway(handler=add_notes)])\n\n    @app.on_event(\"startup\")\n    async def startup():\n        await database.connect()\n\n    @app.on_event(\"shutdown\")\n    async def shutdown():\n        await database.disconnect()\n\n    return app", "\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\ndef test_integration(database_url):\n    app = get_app(database_url)\n\n    with TestClient(app) as client:\n        response = client.post(\"/notes\", json={\"text\": \"example\", \"completed\": True})\n        assert response.status_code == 200\n        assert response.json() == {\"text\": \"example\", \"completed\": True}\n\n        response = client.get(\"/notes\")\n        assert response.status_code == 200\n        assert response.json() == [{\"text\": \"example\", \"completed\": True}]\n\n    with TestClient(app) as client:\n        # Ensure sessions are isolated\n        response = client.get(\"/notes\")\n        assert response.status_code == 200\n        assert response.json() == []", "\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\ndef test_integration_esmerald(database_url):\n    app = get_esmerald_app(database_url)\n\n    with EsmeraldTestClient(app) as client:\n        response = client.post(\"/notes\", json={\"text\": \"example\", \"completed\": True})\n        assert response.status_code == 200\n        assert response.json() == {\"text\": \"example\", \"completed\": True}\n\n        response = client.get(\"/notes\")\n        assert response.status_code == 200\n        assert response.json() == [{\"text\": \"example\", \"completed\": True}]\n\n    with EsmeraldTestClient(app) as client:\n        # Ensure sessions are isolated\n        response = client.get(\"/notes\")\n        assert response.status_code == 200\n        assert response.json() == []", ""]}
{"filename": "tests/test_databases.py", "chunked_list": ["import asyncio\nimport datetime\nimport decimal\nimport functools\nimport gc\nimport os\nfrom typing import MutableMapping\nfrom unittest.mock import MagicMock, patch\nfrom urllib.parse import parse_qsl, urlsplit\n", "from urllib.parse import parse_qsl, urlsplit\n\nimport pytest\nimport sqlalchemy\n\nfrom databasez import Database, DatabaseURL\n\nassert \"TEST_DATABASE_URLS\" in os.environ, \"TEST_DATABASE_URLS is not set.\"\n\nDATABASE_URLS = [url.strip() for url in os.environ[\"TEST_DATABASE_URLS\"].split(\",\")]", "\nDATABASE_URLS = [url.strip() for url in os.environ[\"TEST_DATABASE_URLS\"].split(\",\")]\n\nDATABASE_CONFIG_URLS = []\nfor value in DATABASE_URLS:\n    spliter = urlsplit(value)\n    DATABASE_CONFIG_URLS.append(\n        {\n            \"connection\": {\n                \"credentials\": {\n                    \"scheme\": spliter.scheme.split(\"+\")[0],\n                    \"host\": spliter.hostname,\n                    \"port\": spliter.port,\n                    \"user\": spliter.username,\n                    \"password\": spliter.password,\n                    \"database\": spliter.path[1:],\n                    \"options\": dict(parse_qsl(spliter.query)),\n                }\n            }\n        }\n    )", "\n\nclass AsyncMock(MagicMock):\n    async def __call__(self, *args, **kwargs):\n        return super(AsyncMock, self).__call__(*args, **kwargs)\n\n\nclass MyEpochType(sqlalchemy.types.TypeDecorator):\n    impl = sqlalchemy.Integer\n\n    epoch = datetime.date(1970, 1, 1)\n\n    def process_bind_param(self, value, dialect):\n        return (value - self.epoch).days\n\n    def process_result_value(self, value, dialect):\n        return self.epoch + datetime.timedelta(days=value)", "\n\nmetadata = sqlalchemy.MetaData()\n\nnotes = sqlalchemy.Table(\n    \"notes\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"text\", sqlalchemy.String(length=100)),\n    sqlalchemy.Column(\"completed\", sqlalchemy.Boolean),", "    sqlalchemy.Column(\"text\", sqlalchemy.String(length=100)),\n    sqlalchemy.Column(\"completed\", sqlalchemy.Boolean),\n)\n\n# Used to test DateTime\narticles = sqlalchemy.Table(\n    \"articles\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"title\", sqlalchemy.String(length=100)),", "    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"title\", sqlalchemy.String(length=100)),\n    sqlalchemy.Column(\"published\", sqlalchemy.DateTime),\n)\n\n# Used to test JSON\nsession = sqlalchemy.Table(\n    \"session\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),", "    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"data\", sqlalchemy.JSON),\n)\n\n# Used to test custom column types\ncustom_date = sqlalchemy.Table(\n    \"custom_date\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),", "    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"title\", sqlalchemy.String(length=100)),\n    sqlalchemy.Column(\"published\", MyEpochType),\n)\n\n# Used to test Numeric\nprices = sqlalchemy.Table(\n    \"prices\",\n    metadata,", "    \"prices\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"price\", sqlalchemy.Numeric(precision=30, scale=20)),\n)\n\n\n@pytest.fixture(autouse=True, scope=\"function\")\ndef create_test_database():\n    # Create test databases with tables creation\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        engine = sqlalchemy.create_engine(url)\n        metadata.create_all(engine)\n\n    # Run the test suite\n    yield\n\n    # Drop test databases\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        engine = sqlalchemy.create_engine(url)\n        metadata.drop_all(engine)", "def create_test_database():\n    # Create test databases with tables creation\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        engine = sqlalchemy.create_engine(url)\n        metadata.create_all(engine)\n\n    # Run the test suite\n    yield\n\n    # Drop test databases\n    for url in DATABASE_URLS:\n        database_url = DatabaseURL(url)\n        if database_url.scheme in [\"mysql\", \"mysql+aiomysql\", \"mysql+asyncmy\"]:\n            url = str(database_url.replace(driver=\"pymysql\"))\n        elif database_url.scheme in [\n            \"postgresql+aiopg\",\n            \"sqlite+aiosqlite\",\n            \"postgresql+asyncpg\",\n            \"mssql+pyodbc\",\n            \"mssql+aioodbc\",\n        ]:\n            url = str(database_url.replace(driver=None))\n        engine = sqlalchemy.create_engine(url)\n        metadata.drop_all(engine)", "\n\ndef async_adapter(wrapped_func):\n    \"\"\"\n    Decorator used to run async test cases.\n    \"\"\"\n\n    @functools.wraps(wrapped_func)\n    def run_sync(*args, **kwargs):\n        loop = asyncio.new_event_loop()\n        task = wrapped_func(*args, **kwargs)\n        return loop.run_until_complete(task)\n\n    return run_sync", "\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_queries(database_url):\n    \"\"\"\n    Test that the basic `execute()`, `execute_many()`, `fetch_all()``, and\n    `fetch_one()` interfaces are all supported (using SQLAlchemy core).\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            # execute()", "        async with database.transaction(force_rollback=True):\n            # execute()\n            query = notes.insert()\n            values = {\"text\": \"example1\", \"completed\": True}\n            await database.execute(query, values)\n\n            # execute_many()\n            query = notes.insert()\n            values = [\n                {\"text\": \"example2\", \"completed\": False},", "            values = [\n                {\"text\": \"example2\", \"completed\": False},\n                {\"text\": \"example3\", \"completed\": True},\n            ]\n            await database.execute_many(query, values)\n\n            # fetch_all()\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n", "            results = await database.fetch_all(query=query)\n\n            assert len(results) == 3\n            assert results[0][\"text\"] == \"example1\"\n            assert results[0][\"completed\"] is True\n            assert results[1][\"text\"] == \"example2\"\n            assert results[1][\"completed\"] is False\n            assert results[2][\"text\"] == \"example3\"\n            assert results[2][\"completed\"] is True\n", "            assert results[2][\"completed\"] is True\n\n            # fetch_one()\n            query = notes.select()\n            result = await database.fetch_one(query=query)\n            assert result[\"text\"] == \"example1\"\n            assert result[\"completed\"] is True\n\n            # fetch_val()\n            query = sqlalchemy.sql.select(*[notes.c.text])", "            # fetch_val()\n            query = sqlalchemy.sql.select(*[notes.c.text])\n            result = await database.fetch_val(query=query)\n            assert result == \"example1\"\n\n            # fetch_val() with no rows\n            query = sqlalchemy.sql.select(*[notes.c.text]).where(notes.c.text == \"impossible\")\n            result = await database.fetch_val(query=query)\n            assert result is None\n", "            assert result is None\n\n            # fetch_val() with a different column\n            query = sqlalchemy.sql.select(*[notes.c.id, notes.c.text])\n            result = await database.fetch_val(query=query, column=1)\n            assert result == \"example1\"\n\n            # row access (needed to maintain test coverage for Record.__getitem__ in postgres backend)\n            query = sqlalchemy.sql.select(*[notes.c.text])\n            result = await database.fetch_one(query=query)", "            query = sqlalchemy.sql.select(*[notes.c.text])\n            result = await database.fetch_one(query=query)\n            assert result[\"text\"] == \"example1\"\n            assert result[0] == \"example1\"\n\n            # iterate()\n            query = notes.select()\n            iterate_results = []\n            async for result in database.iterate(query=query):\n                iterate_results.append(result)", "            async for result in database.iterate(query=query):\n                iterate_results.append(result)\n            assert len(iterate_results) == 3\n            assert iterate_results[0][\"text\"] == \"example1\"\n            assert iterate_results[0][\"completed\"] is True\n            assert iterate_results[1][\"text\"] == \"example2\"\n            assert iterate_results[1][\"completed\"] is False\n            assert iterate_results[2][\"text\"] == \"example3\"\n            assert iterate_results[2][\"completed\"] is True\n", "            assert iterate_results[2][\"completed\"] is True\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_queries_raw(database_url):\n    \"\"\"\n    Test that the basic `execute()`, `execute_many()`, `fetch_all()``, and\n    `fetch_one()` interfaces are all supported (raw queries).\n    \"\"\"", "    `fetch_one()` interfaces are all supported (raw queries).\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):", "    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            # execute()\n            query = \"INSERT INTO notes(text, completed) VALUES (:text, :completed)\"\n            values = {\"text\": \"example1\", \"completed\": True}\n            await database.execute(query, values)\n\n            # execute_many()\n            query = \"INSERT INTO notes(text, completed) VALUES (:text, :completed)\"\n            values = [", "            query = \"INSERT INTO notes(text, completed) VALUES (:text, :completed)\"\n            values = [\n                {\"text\": \"example2\", \"completed\": False},\n                {\"text\": \"example3\", \"completed\": True},\n            ]\n            await database.execute_many(query, values)\n\n            # fetch_all()\n            query = \"SELECT * FROM notes WHERE completed = :completed\"\n            results = await database.fetch_all(query=query, values={\"completed\": True})", "            query = \"SELECT * FROM notes WHERE completed = :completed\"\n            results = await database.fetch_all(query=query, values={\"completed\": True})\n            assert len(results) == 2\n            assert results[0][\"text\"] == \"example1\"\n            assert results[0][\"completed\"] == True\n            assert results[1][\"text\"] == \"example3\"\n            assert results[1][\"completed\"] == True\n\n            # fetch_one()\n            query = \"SELECT * FROM notes WHERE completed = :completed\"", "            # fetch_one()\n            query = \"SELECT * FROM notes WHERE completed = :completed\"\n            result = await database.fetch_one(query=query, values={\"completed\": False})\n            assert result[\"text\"] == \"example2\"\n            assert result[\"completed\"] == False\n\n            # fetch_val()\n            query = \"SELECT completed FROM notes WHERE text = :text\"\n            result = await database.fetch_val(query=query, values={\"text\": \"example1\"})\n            assert result == True", "            result = await database.fetch_val(query=query, values={\"text\": \"example1\"})\n            assert result == True\n\n            query = \"SELECT * FROM notes WHERE text = :text\"\n            result = await database.fetch_val(\n                query=query, values={\"text\": \"example1\"}, column=\"completed\"\n            )\n            assert result == True\n\n            # iterate()", "\n            # iterate()\n            query = \"SELECT * FROM notes\"\n            iterate_results = []\n            async for result in database.iterate(query=query):\n                iterate_results.append(result)\n            assert len(iterate_results) == 3\n            assert iterate_results[0][\"text\"] == \"example1\"\n            assert iterate_results[0][\"completed\"] == True\n            assert iterate_results[1][\"text\"] == \"example2\"", "            assert iterate_results[0][\"completed\"] == True\n            assert iterate_results[1][\"text\"] == \"example2\"\n            assert iterate_results[1][\"completed\"] == False\n            assert iterate_results[2][\"text\"] == \"example3\"\n            assert iterate_results[2][\"completed\"] == True\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_ddl_queries(database_url):", "@async_adapter\nasync def test_ddl_queries(database_url):\n    \"\"\"\n    Test that the built-in DDL elements such as `DropTable()`,\n    `CreateTable()` are supported (using SQLAlchemy core).\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            # DropTable()\n            query = sqlalchemy.schema.DropTable(notes)\n            await database.execute(query)\n\n            # CreateTable()\n            query = sqlalchemy.schema.CreateTable(notes)\n            await database.execute(query)", "            query = sqlalchemy.schema.CreateTable(notes)\n            await database.execute(query)\n\n\n@pytest.mark.parametrize(\"exception\", [Exception, asyncio.CancelledError])\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_queries_after_error(database_url, exception):\n    \"\"\"\n    Test that the basic `execute()` works after a previous error.", "    \"\"\"\n    Test that the basic `execute()` works after a previous error.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        with patch.object(\n            database.connection()._connection,\n            \"acquire\",\n            new=AsyncMock(side_effect=exception),\n        ):\n            with pytest.raises(exception):\n                query = notes.select()\n                await database.fetch_all(query)", "\n    async with Database(**data) as database:\n        with patch.object(\n            database.connection()._connection,\n            \"acquire\",\n            new=AsyncMock(side_effect=exception),\n        ):\n            with pytest.raises(exception):\n                query = notes.select()\n                await database.fetch_all(query)", "\n        query = notes.select()\n        await database.fetch_all(query)\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_results_support_mapping_interface(database_url):\n    \"\"\"\n    Casting results to a dict should work, since the interface defines them", "    \"\"\"\n    Casting results to a dict should work, since the interface defines them\n    as supporting the mapping interface.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            # execute()\n            query = notes.insert()\n            values = {\"text\": \"example1\", \"completed\": True}\n            await database.execute(query, values)\n\n            # fetch_all()\n            query = notes.select()", "            # fetch_all()\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            results_as_dicts = [dict(item) for item in results]\n\n            assert len(results[0]) == 3\n            assert len(results_as_dicts[0]) == 3\n\n            assert isinstance(results_as_dicts[0][\"id\"], int)\n            assert results_as_dicts[0][\"text\"] == \"example1\"", "            assert isinstance(results_as_dicts[0][\"id\"], int)\n            assert results_as_dicts[0][\"text\"] == \"example1\"\n            assert results_as_dicts[0][\"completed\"] is True\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_results_support_column_reference(database_url):\n    \"\"\"\n    Casting results to a dict should work, since the interface defines them", "    \"\"\"\n    Casting results to a dict should work, since the interface defines them\n    as supporting the mapping interface.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            now = datetime.datetime.now().replace(microsecond=0)\n            today = datetime.date.today()\n\n            # execute()\n            query = articles.insert()\n            values = {\"title\": \"Hello, world Article\", \"published\": now}\n            await database.execute(query, values)", "            values = {\"title\": \"Hello, world Article\", \"published\": now}\n            await database.execute(query, values)\n\n            query = custom_date.insert()\n            values = {\"title\": \"Hello, world Custom\", \"published\": today}\n            await database.execute(query, values)\n\n            # fetch_all()\n            query = sqlalchemy.select(*[articles, custom_date])\n            results = await database.fetch_all(query=query)", "            query = sqlalchemy.select(*[articles, custom_date])\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n            assert results[0][articles.c.title] == \"Hello, world Article\"\n            assert results[0][articles.c.published] == now\n            assert results[0][custom_date.c.title] == \"Hello, world Custom\"\n            assert results[0][custom_date.c.published] == today\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])", "\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_result_values_allow_duplicate_names(database_url):\n    \"\"\"\n    The values of a result should respect when two columns are selected\n    with the same name.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            query = \"SELECT 1 AS id, 2 AS id\"\n            row = await database.fetch_one(query=query)", "            query = \"SELECT 1 AS id, 2 AS id\"\n            row = await database.fetch_one(query=query)\n\n            assert list(row._mapping.keys()) == [\"id\", \"id\"]\n            assert list(row._mapping.values()) == [1, 2]\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_fetch_one_returning_no_results(database_url):", "@async_adapter\nasync def test_fetch_one_returning_no_results(database_url):\n    \"\"\"\n    fetch_one should return `None` when no results match.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            # fetch_all()\n            query = notes.select()\n            result = await database.fetch_one(query=query)\n            assert result is None\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])", "\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_execute_return_val(database_url):\n    \"\"\"\n    Test using return value from `execute()` to get an inserted primary key.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            query = notes.insert()\n            values = {\"text\": \"example1\", \"completed\": True}\n            pk = await database.execute(query, values)", "            values = {\"text\": \"example1\", \"completed\": True}\n            pk = await database.execute(query, values)\n            assert isinstance(pk, int)\n\n            # Apparently for `aiopg` it's OID that will always 0 in this case\n            # As it's only one action within this cursor life cycle\n            # It's recommended to use the `RETURNING` clause\n            # For obtaining the record id\n            if database.url.scheme == \"postgresql+aiopg\":\n                assert pk == 0\n            else:\n                query = notes.select().where(notes.c.id == pk)\n                result = await database.fetch_one(query)\n                assert result[\"text\"] == \"example1\"\n                assert result[\"completed\"] is True", "            if database.url.scheme == \"postgresql+aiopg\":\n                assert pk == 0\n            else:\n                query = notes.select().where(notes.c.id == pk)\n                result = await database.fetch_one(query)\n                assert result[\"text\"] == \"example1\"\n                assert result[\"completed\"] is True\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])", "\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_rollback_isolation(database_url):\n    \"\"\"\n    Ensure that `database.transaction(force_rollback=True)` provides strict isolation.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        # Perform some INSERT operations on the database.\n        async with database.transaction(force_rollback=True):\n            query = notes.insert().values(text=\"example1\", completed=True)\n            await database.execute(query)", "            query = notes.insert().values(text=\"example1\", completed=True)\n            await database.execute(query)\n\n        # Ensure INSERT operations have been rolled back.\n        query = notes.select()\n        results = await database.fetch_all(query=query)\n        assert len(results) == 0\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])", "\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_rollback_isolation_with_contextmanager(database_url):\n    \"\"\"\n    Ensure that `database.force_rollback()` provides strict isolation.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    database = Database(**data)\n\n    with database.force_rollback():\n        async with database:\n            # Perform some INSERT operations on the database.\n            query = notes.insert().values(text=\"example1\", completed=True)\n            await database.execute(query)\n\n        async with database:\n            # Ensure INSERT operations have been rolled back.\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 0", "\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_transaction_commit(database_url):\n    \"\"\"\n    Ensure that transaction commit is supported.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            async with database.transaction():\n                query = notes.insert().values(text=\"example1\", completed=True)", "            async with database.transaction():\n                query = notes.insert().values(text=\"example1\", completed=True)\n                await database.execute(query)\n\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)", "\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_transaction_commit_serializable(database_url):\n    \"\"\"\n    Ensure that serializable transaction commit via extra parameters is supported.\n    \"\"\"\n    database_url = DatabaseURL(database_url)\n\n    if database_url.scheme not in [\"postgresql\", \"postgresql+asyncpg\"]:\n        pytest.skip(\"Test (currently) only supports asyncpg\")", "\n    if database_url.scheme not in [\"postgresql\", \"postgresql+asyncpg\"]:\n        pytest.skip(\"Test (currently) only supports asyncpg\")\n\n    if database_url.scheme == \"postgresql+asyncpg\":\n        database_url = database_url.replace(driver=None)\n\n    def insert_independently():\n        engine = sqlalchemy.create_engine(str(database_url))\n        conn = engine.connect()\n\n        query = notes.insert().values(text=\"example1\", completed=True)\n        conn.execute(query)\n        conn.close()", "\n    def delete_independently():\n        engine = sqlalchemy.create_engine(str(database_url))\n        conn = engine.connect()\n\n        query = notes.delete()\n        conn.execute(query)\n        conn.close()\n\n    async with Database(database_url) as database:", "\n    async with Database(database_url) as database:\n        async with database.transaction(force_rollback=True, isolation=\"serializable\"):\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 0\n\n            insert_independently()\n\n            query = notes.select()", "\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 0\n\n            delete_independently()\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter", "@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_transaction_rollback(database_url):\n    \"\"\"\n    Ensure that transaction rollback is supported.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            try:\n                async with database.transaction():\n                    query = notes.insert().values(text=\"example1\", completed=True)\n                    await database.execute(query)\n                    raise RuntimeError()\n            except RuntimeError:\n                pass", "\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 0\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_transaction_commit_low_level(database_url):\n    \"\"\"", "async def test_transaction_commit_low_level(database_url):\n    \"\"\"\n    Ensure that an explicit `await transaction.commit()` is supported.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            transaction = await database.transaction()\n            try:\n                query = notes.insert().values(text=\"example1\", completed=True)\n                await database.execute(query)\n            except Exception:\n                await transaction.rollback()\n            else:\n                await transaction.commit()", "\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_transaction_rollback_low_level(database_url):\n    \"\"\"", "async def test_transaction_rollback_low_level(database_url):\n    \"\"\"\n    Ensure that an explicit `await transaction.rollback()` is supported.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            transaction = await database.transaction()\n            try:\n                query = notes.insert().values(text=\"example1\", completed=True)\n                await database.execute(query)\n                raise RuntimeError()\n            except Exception:\n                await transaction.rollback()\n            else:  # pragma: no cover\n                await transaction.commit()", "\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 0\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_transaction_decorator(database_url):\n    \"\"\"", "async def test_transaction_decorator(database_url):\n    \"\"\"\n    Ensure that @database.transaction() is supported.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n", "\n    database = Database(force_rollback=True, **data)\n\n    @database.transaction()\n    async def insert_data(raise_exception):\n        query = notes.insert().values(text=\"example\", completed=True)\n        await database.execute(query)\n        if raise_exception:\n            raise RuntimeError()\n", "\n    async with database:\n        with pytest.raises(RuntimeError):\n            await insert_data(raise_exception=True)\n\n        query = notes.select()\n        results = await database.fetch_all(query=query)\n        assert len(results) == 0\n\n        await insert_data(raise_exception=False)", "\n        await insert_data(raise_exception=False)\n\n        query = notes.select()\n        results = await database.fetch_all(query=query)\n        assert len(results) == 1\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter", "@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_datetime_field(database_url):\n    \"\"\"\n    Test DataTime columns, to ensure records are coerced to/from proper Python types.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            now = datetime.datetime.now().replace(microsecond=0)\n\n            # execute()\n            query = articles.insert()\n            values = {\"title\": \"Hello, world\", \"published\": now}\n            await database.execute(query, values)\n", "            await database.execute(query, values)\n\n            # fetch_all()\n            query = articles.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n            assert results[0][\"title\"] == \"Hello, world\"\n            assert results[0][\"published\"] == now\n\n", "\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_decimal_field(database_url):\n    \"\"\"\n    Test Decimal (NUMERIC) columns, to ensure records are coerced to/from proper Python types.\n    \"\"\"\n\n    async with Database(database_url) as database:", "\n    async with Database(database_url) as database:\n        async with database.transaction(force_rollback=True):\n            price = decimal.Decimal(\"0.700000000000001\")\n\n            # execute()\n            query = prices.insert()\n            values = {\"price\": price}\n            await database.execute(query, values)\n", "            await database.execute(query, values)\n\n            # fetch_all()\n            query = prices.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n            if database_url.startswith(\"sqlite\"):\n                # aiosqlite does not support native decimals --> a roud-off error is expected\n                assert results[0][\"price\"] == pytest.approx(price)\n            else:\n                assert results[0][\"price\"] == price", "\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_json_field(database_url):\n    \"\"\"\n    Test JSON columns, to ensure correct cross-database support.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            # execute()\n            data = {\"text\": \"hello\", \"boolean\": True, \"int\": 1}", "            # execute()\n            data = {\"text\": \"hello\", \"boolean\": True, \"int\": 1}\n            values = {\"data\": data}\n            query = session.insert()\n            await database.execute(query, values)\n\n            # fetch_all()\n            query = session.select()\n            results = await database.fetch_all(query=query)\n", "            results = await database.fetch_all(query=query)\n\n            assert len(results) == 1\n            assert results[0][\"data\"] == {\"text\": \"hello\", \"boolean\": True, \"int\": 1}\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_custom_field(database_url):\n    \"\"\"", "async def test_custom_field(database_url):\n    \"\"\"\n    Test custom column types.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n", "\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            today = datetime.date.today()\n\n            # execute()\n            query = custom_date.insert()\n            values = {\"title\": \"Hello, world\", \"published\": today}\n\n            await database.execute(query, values)", "\n            await database.execute(query, values)\n\n            # fetch_all()\n            query = custom_date.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n            assert results[0][\"title\"] == \"Hello, world\"\n            assert results[0][\"published\"] == today\n", "            assert results[0][\"published\"] == today\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_connections_isolation(database_url):\n    \"\"\"\n    Ensure that changes are visible between different connections.\n    To check this we have to not create a transaction, so that\n    each query ends up on a different connection from the pool.", "    To check this we have to not create a transaction, so that\n    each query ends up on a different connection from the pool.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        try:\n            query = notes.insert().values(text=\"example1\", completed=True)\n            await database.execute(query)\n\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n        finally:\n            query = notes.delete()\n            await database.execute(query)", "\n    async with Database(**data) as database:\n        try:\n            query = notes.insert().values(text=\"example1\", completed=True)\n            await database.execute(query)\n\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n        finally:\n            query = notes.delete()\n            await database.execute(query)", "\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_commit_on_root_transaction(database_url):\n    \"\"\"\n    Because our tests are generally wrapped in rollback-islation, they\n    don't have coverage for commiting the root transaction.\n\n    Deal with this here, and delete the records rather than rolling back.", "\n    Deal with this here, and delete the records rather than rolling back.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        try:\n            async with database.transaction():\n                query = notes.insert().values(text=\"example1\", completed=True)\n                await database.execute(query)\n\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n        finally:\n            query = notes.delete()\n            await database.execute(query)", "\n    async with Database(**data) as database:\n        try:\n            async with database.transaction():\n                query = notes.insert().values(text=\"example1\", completed=True)\n                await database.execute(query)\n\n            query = notes.select()\n            results = await database.fetch_all(query=query)\n            assert len(results) == 1\n        finally:\n            query = notes.delete()\n            await database.execute(query)", "\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_connect_and_disconnect(database_url):\n    \"\"\"\n    Test explicit connect() and disconnect().\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    database = Database(**data)\n\n    assert not database.is_connected\n    await database.connect()", "    assert not database.is_connected\n    await database.connect()\n    assert database.is_connected\n    await database.disconnect()\n    assert not database.is_connected\n\n    # connect and disconnect idempotence\n    await database.connect()\n    await database.connect()\n    assert database.is_connected", "    await database.connect()\n    assert database.is_connected\n    await database.disconnect()\n    await database.disconnect()\n    assert not database.is_connected\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_connection_context(database_url):", "@async_adapter\nasync def test_connection_context(database_url):\n    \"\"\"\n    Test connection contexts are task-local.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "\n    async with Database(**data) as database:\n        async with database.connection() as connection_1:\n            async with database.connection() as connection_2:\n                assert connection_1 is connection_2\n\n    async with Database(**data) as database:\n        connection_1 = None\n        connection_2 = None\n        test_complete = asyncio.Event()", "        connection_2 = None\n        test_complete = asyncio.Event()\n\n        async def get_connection_1():\n            nonlocal connection_1\n\n            async with database.connection() as connection:\n                connection_1 = connection\n                await test_complete.wait()\n", "                await test_complete.wait()\n\n        async def get_connection_2():\n            nonlocal connection_2\n\n            async with database.connection() as connection:\n                connection_2 = connection\n                await test_complete.wait()\n\n        loop = asyncio.get_event_loop()", "\n        loop = asyncio.get_event_loop()\n        task_1 = loop.create_task(get_connection_1())\n        task_2 = loop.create_task(get_connection_2())\n        while connection_1 is None or connection_2 is None:\n            await asyncio.sleep(0.000001)\n        assert connection_1 is not connection_2\n        test_complete.set()\n        await task_1\n        await task_2", "        await task_1\n        await task_2\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_connection_context_with_raw_connection(database_url):\n    \"\"\"\n    Test connection contexts with respect to the raw connection.\n    \"\"\"", "    Test connection contexts with respect to the raw connection.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.connection() as connection_1:", "    async with Database(**data) as database:\n        async with database.connection() as connection_1:\n            async with database.connection() as connection_2:\n                assert connection_1 is connection_2\n                assert connection_1.raw_connection is connection_2.raw_connection\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_queries_with_expose_backend_connection(database_url):", "@async_adapter\nasync def test_queries_with_expose_backend_connection(database_url):\n    \"\"\"\n    Replication of `execute()`, `execute_many()`, `fetch_all()``, and\n    `fetch_one()` using the raw driver interface.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "\n    async with Database(**data) as database:\n        async with database.connection() as connection:\n            async with connection.transaction(force_rollback=True):\n                # Get the raw connection\n                raw_connection = connection.raw_connection\n                # Insert query\n                if database.url.scheme in [\n                    \"mysql\",\n                    \"mysql+asyncmy\",\n                    \"mysql+aiomysql\",\n                    \"postgresql+aiopg\",\n                ]:\n                    insert_query = \"INSERT INTO notes (text, completed) VALUES (%s, %s)\"\n                elif database.url.scheme in [\n                    \"mssql\",\n                    \"mssql+pyodbc\",\n                    \"mssql+aioodbc\",\n                ]:\n                    insert_query = \"INSERT INTO notes (text, completed) VALUES (?, ?)\"\n                else:\n                    insert_query = \"INSERT INTO notes (text, completed) VALUES ($1, $2)\"", "\n                # execute()\n                values = (\"example1\", True)\n\n                if database.url.scheme in [\n                    \"mysql\",\n                    \"mysql+aiomysql\",\n                    \"postgresql+aiopg\",\n                    \"mssql\",\n                    \"mssql+pyodbc\",\n                    \"mssql+aioodbc\",\n                ]:\n                    cursor = await raw_connection.cursor()\n                    await cursor.execute(insert_query, values)\n                elif database.url.scheme == \"mysql+asyncmy\":\n                    async with raw_connection.cursor() as cursor:\n                        await cursor.execute(insert_query, values)\n                elif database.url.scheme in [\"postgresql\", \"postgresql+asyncpg\"]:\n                    await raw_connection.execute(insert_query, *values)\n                elif database.url.scheme in [\"sqlite\", \"sqlite+aiosqlite\"]:\n                    await raw_connection.execute(insert_query, values)", "\n                # execute_many()\n                values = [(\"example2\", False), (\"example3\", True)]\n\n                if database.url.scheme in [\"mysql\", \"mysql+aiomysql\"]:\n                    cursor = await raw_connection.cursor()\n                    await cursor.executemany(insert_query, values)\n                elif database.url.scheme == \"mysql+asyncmy\":\n                    async with raw_connection.cursor() as cursor:\n                        await cursor.executemany(insert_query, values)\n                elif database.url.scheme == \"postgresql+aiopg\":\n                    cursor = await raw_connection.cursor()\n                    # No async support for `executemany`\n                    for value in values:\n                        await cursor.execute(insert_query, value)\n                elif database.url.scheme in [\"mssql\", \"mssql+aioodbc\", \"mssql+pyodbc\"]:\n                    cursor = await raw_connection.cursor()\n                    for value in values:\n                        await cursor.execute(insert_query, value)\n                else:\n                    await raw_connection.executemany(insert_query, values)", "\n                # Select query\n                select_query = \"SELECT notes.id, notes.text, notes.completed FROM notes\"\n\n                # fetch_all()\n                if database.url.scheme in [\n                    \"mysql\",\n                    \"mysql+aiomysql\",\n                    \"postgresql+aiopg\",\n                    \"mssql\",\n                    \"mssql+pyodbc\",\n                    \"mssql+aioodbc\",\n                ]:\n                    cursor = await raw_connection.cursor()\n                    await cursor.execute(select_query)\n                    results = await cursor.fetchall()\n                elif database.url.scheme == \"mysql+asyncmy\":\n                    async with raw_connection.cursor() as cursor:\n                        await cursor.execute(select_query)\n                        results = await cursor.fetchall()\n                elif database.url.scheme in [\"postgresql\", \"postgresql+asyncpg\"]:\n                    results = await raw_connection.fetch(select_query)\n                elif database.url.scheme in [\"sqlite\", \"sqlite+aiosqlite\"]:\n                    results = await raw_connection.execute_fetchall(select_query)", "\n                assert len(results) == 3\n                # Raw output for the raw request\n                assert results[0][1] == \"example1\"\n                assert results[0][2] == True\n                assert results[1][1] == \"example2\"\n                assert results[1][2] == False\n                assert results[2][1] == \"example3\"\n                assert results[2][2] == True\n", "                assert results[2][2] == True\n\n                # fetch_one()\n                if database.url.scheme in [\"postgresql\", \"postgresql+asyncpg\"]:\n                    result = await raw_connection.fetchrow(select_query)\n                elif database.url.scheme == \"mysql+asyncmy\":\n                    async with raw_connection.cursor() as cursor:\n                        await cursor.execute(select_query)\n                        result = await cursor.fetchone()\n                elif database.url.scheme in [\"mssql\", \"mssql+pyodbc\", \"mssql+aioodbc\"]:\n                    cursor = await raw_connection.cursor()\n                    try:\n                        await cursor.execute(select_query)\n                        result = await cursor.fetchone()\n                    finally:\n                        await cursor.close()\n                else:\n                    cursor = await raw_connection.cursor()\n                    await cursor.execute(select_query)\n                    result = await cursor.fetchone()", "\n                # Raw output for the raw request\n                assert result[1] == \"example1\"\n                assert result[2] == True\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_database_url_interface(database_url):\n    \"\"\"", "async def test_database_url_interface(database_url):\n    \"\"\"\n    Test that Database instances expose a `.url` attribute.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n", "\n    async with Database(**data) as database:\n        assert isinstance(database.url, DatabaseURL)\n        if isinstance(database_url, str):\n            assert database.url == database_url\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_concurrent_access_on_single_connection(database_url):", "@async_adapter\nasync def test_concurrent_access_on_single_connection(database_url):\n    database_url = DatabaseURL(database_url)\n    if database_url.dialect != \"postgresql\":\n        pytest.skip(\"Test requires `pg_sleep()`\")\n\n    async with Database(database_url, force_rollback=True) as database:\n\n        async def db_lookup():\n            await database.fetch_one(\"SELECT pg_sleep(1)\")", "        async def db_lookup():\n            await database.fetch_one(\"SELECT pg_sleep(1)\")\n\n        await asyncio.gather(db_lookup(), db_lookup())\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\ndef test_global_connection_is_initialized_lazily(database_url):\n    \"\"\"\n    Ensure that global connection is initialized at latest possible time\n    so it's _query_lock will belong to same event loop that async_adapter has\n    initialized.\n\n    See https://github.com/dymmond/databasez/issues/157 for more context.\n    \"\"\"\n\n    database_url = DatabaseURL(database_url)\n    if database_url.dialect != \"postgresql\":\n        pytest.skip(\"Test requires `pg_sleep()`\")\n\n    database = Database(database_url, force_rollback=True)\n\n    @async_adapter\n    async def run_database_queries():\n        async with database:\n\n            async def db_lookup():\n                await database.fetch_one(\"SELECT pg_sleep(1)\")\n\n            await asyncio.gather(db_lookup(), db_lookup())\n\n    run_database_queries()", "\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_iterate_outside_transaction_with_values(database_url):\n    \"\"\"\n    Ensure `iterate()` works even without a transaction on all drivers.\n    The asyncpg driver relies on server-side cursors without hold\n    for iteration, which requires a transaction to be created.\n    This is mentionned in both their documentation and their test suite.", "    for iteration, which requires a transaction to be created.\n    This is mentionned in both their documentation and their test suite.\n    \"\"\"\n\n    database_url = DatabaseURL(database_url)\n    if database_url.dialect == \"mysql\":\n        pytest.skip(\"MySQL does not support `FROM (VALUES ...)` (F641)\")\n\n    async with Database(database_url) as database:\n        if database_url.dialect == \"mssql\":\n            query = \"SELECT * FROM (VALUES (1), (2), (3), (4), (5)) as X(t)\"\n        else:\n            query = \"SELECT * FROM (VALUES (1), (2), (3), (4), (5)) as t\"", "    async with Database(database_url) as database:\n        if database_url.dialect == \"mssql\":\n            query = \"SELECT * FROM (VALUES (1), (2), (3), (4), (5)) as X(t)\"\n        else:\n            query = \"SELECT * FROM (VALUES (1), (2), (3), (4), (5)) as t\"\n        iterate_results = []\n\n        async for result in database.iterate(query=query):\n            iterate_results.append(result)\n", "            iterate_results.append(result)\n\n        assert len(iterate_results) == 5\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_iterate_outside_transaction_with_temp_table(database_url):\n    \"\"\"\n    Same as test_iterate_outside_transaction_with_values but uses a", "    \"\"\"\n    Same as test_iterate_outside_transaction_with_values but uses a\n    temporary table instead of a list of values.\n    \"\"\"\n    database_url = DatabaseURL(database_url)\n    if database_url.dialect == \"sqlite\":\n        pytest.skip(\"SQLite interface does not work with temporary tables.\")\n\n    async with Database(database_url) as database:\n        if database_url.dialect == \"mssql\":\n            query = \"CREATE TABLE ##no_transac(num INTEGER)\"\n            await database.execute(query)\n\n            query = \"INSERT INTO ##no_transac VALUES (1), (2), (3), (4), (5)\"\n            await database.execute(query)\n\n            query = \"SELECT * FROM ##no_transac\"\n\n        else:\n            query = \"CREATE TEMPORARY TABLE no_transac(num INTEGER)\"\n            await database.execute(query)\n\n            query = \"INSERT INTO no_transac(num) VALUES (1), (2), (3), (4), (5)\"\n            await database.execute(query)\n\n            query = \"SELECT * FROM no_transac\"", "    async with Database(database_url) as database:\n        if database_url.dialect == \"mssql\":\n            query = \"CREATE TABLE ##no_transac(num INTEGER)\"\n            await database.execute(query)\n\n            query = \"INSERT INTO ##no_transac VALUES (1), (2), (3), (4), (5)\"\n            await database.execute(query)\n\n            query = \"SELECT * FROM ##no_transac\"\n\n        else:\n            query = \"CREATE TEMPORARY TABLE no_transac(num INTEGER)\"\n            await database.execute(query)\n\n            query = \"INSERT INTO no_transac(num) VALUES (1), (2), (3), (4), (5)\"\n            await database.execute(query)\n\n            query = \"SELECT * FROM no_transac\"", "\n        iterate_results = []\n\n        async for result in database.iterate(query=query):\n            iterate_results.append(result)\n\n        assert len(iterate_results) == 5\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])", "\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@pytest.mark.parametrize(\"select_query\", [notes.select(), \"SELECT * FROM notes\"])\n@async_adapter\nasync def test_column_names(database_url, select_query):\n    \"\"\"\n    Test that column names are exposed correctly through `._mapping.keys()` on each row.\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        async with database.transaction(force_rollback=True):\n            # insert values\n            query = notes.insert()", "            # insert values\n            query = notes.insert()\n            values = {\"text\": \"example1\", \"completed\": True}\n            await database.execute(query, values)\n            # fetch results\n            results = await database.fetch_all(query=select_query)\n            assert len(results) == 1\n\n            assert sorted(results[0]._mapping.keys()) == [\"completed\", \"id\", \"text\"]\n            assert results[0][\"text\"] == \"example1\"", "            assert sorted(results[0]._mapping.keys()) == [\"completed\", \"id\", \"text\"]\n            assert results[0][\"text\"] == \"example1\"\n            assert results[0][\"completed\"] == True\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_postcompile_queries(database_url):\n    \"\"\"\n    Since SQLAlchemy 1.4, IN operators needs to do render_postcompile", "    \"\"\"\n    Since SQLAlchemy 1.4, IN operators needs to do render_postcompile\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:", "\n    async with Database(**data) as database:\n        query = notes.insert()\n        values = {\"text\": \"example1\", \"completed\": True}\n        await database.execute(query, values)\n\n        query = notes.select().where(notes.c.id.in_([2, 3]))\n        results = await database.fetch_all(query=query)\n\n        assert len(results) == 0", "\n        assert len(results) == 0\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_result_named_access(database_url):\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        query = notes.insert()\n        values = {\"text\": \"example1\", \"completed\": True}\n        await database.execute(query, values)\n", "        await database.execute(query, values)\n\n        query = notes.select().where(notes.c.text == \"example1\")\n        result = await database.fetch_one(query=query)\n\n        assert result.text == \"example1\"\n        assert result.completed is True\n\n\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])", "\n@pytest.mark.parametrize(\"database_url\", [DATABASE_URLS, DATABASE_CONFIG_URLS])\n@async_adapter\nasync def test_mapping_property_interface(database_url):\n    \"\"\"\n    Test that all connections implement interface with `_mapping` property\n    \"\"\"\n    database_url = database_url[0]\n    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}", "    if isinstance(database_url, str):\n        data = {\"url\": database_url}\n    else:\n        data = {\"config\": database_url}\n\n    async with Database(**data) as database:\n        query = notes.insert()\n        values = {\"text\": \"example1\", \"completed\": True}\n        await database.execute(query, values)\n", "        await database.execute(query, values)\n\n        query = notes.select()\n        single_result = await database.fetch_one(query=query)\n        assert single_result._mapping[\"text\"] == \"example1\"\n        assert single_result._mapping[\"completed\"] is True\n\n        list_result = await database.fetch_all(query=query)\n        assert list_result[0]._mapping[\"text\"] == \"example1\"\n        assert list_result[0]._mapping[\"completed\"] is True", "        assert list_result[0]._mapping[\"text\"] == \"example1\"\n        assert list_result[0]._mapping[\"completed\"] is True\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_transaction_context_child_task_inheritance(database_url):\n    \"\"\"\n    Ensure that transactions are inherited by child tasks.\n    \"\"\"", "    Ensure that transactions are inherited by child tasks.\n    \"\"\"\n    async with Database(database_url) as database:\n\n        async def check_transaction(transaction, active_transaction):\n            # Should have inherited the same transaction backend from the parent task\n            assert transaction._transaction is active_transaction\n\n        async with database.transaction() as transaction:\n            await asyncio.create_task(check_transaction(transaction, transaction._transaction))", "        async with database.transaction() as transaction:\n            await asyncio.create_task(check_transaction(transaction, transaction._transaction))\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_transaction_context_child_task_inheritance_example(database_url):\n    \"\"\"\n    Ensure that child tasks may influence inherited transactions.\n    \"\"\"", "    Ensure that child tasks may influence inherited transactions.\n    \"\"\"\n    # This is an practical example of the above test.\n    db = Database(database_url)\n    if db.url.dialect == \"mssql\":\n        return\n\n    async with Database(database_url) as database:\n        async with database.transaction():\n            # Create a note", "        async with database.transaction():\n            # Create a note\n            await database.execute(notes.insert().values(id=1, text=\"setup\", completed=True))\n\n            # Change the note from the same task\n            await database.execute(notes.update().where(notes.c.id == 1).values(text=\"prior\"))\n\n            # Confirm the change\n            result = await database.fetch_one(notes.select().where(notes.c.id == 1))\n            assert result.text == \"prior\"", "            result = await database.fetch_one(notes.select().where(notes.c.id == 1))\n            assert result.text == \"prior\"\n\n            async def run_update_from_child_task(connection):\n                # Change the note from a child task\n                await connection.execute(notes.update().where(notes.c.id == 1).values(text=\"test\"))\n\n            await asyncio.create_task(run_update_from_child_task(database.connection()))\n\n            # Confirm the child's change", "\n            # Confirm the child's change\n            result = await database.fetch_one(notes.select().where(notes.c.id == 1))\n            assert result.text == \"test\"\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_transaction_context_sibling_task_isolation(database_url):\n    \"\"\"", "async def test_transaction_context_sibling_task_isolation(database_url):\n    \"\"\"\n    Ensure that transactions are isolated between sibling tasks.\n    \"\"\"\n    start = asyncio.Event()\n    end = asyncio.Event()\n\n    async with Database(database_url) as database:\n\n        async def check_transaction(transaction):", "\n        async def check_transaction(transaction):\n            await start.wait()\n            # Parent task is now in a transaction, we should not\n            # see its transaction backend since this task was\n            # _started_ in a context where no transaction was active.\n            assert transaction._transaction is None\n            end.set()\n\n        transaction = database.transaction()", "\n        transaction = database.transaction()\n        assert transaction._transaction is None\n        task = asyncio.create_task(check_transaction(transaction))\n\n        async with transaction:\n            start.set()\n            assert transaction._transaction is not None\n            await end.wait()\n", "            await end.wait()\n\n        # Cleanup for \"Task not awaited\" warning\n        await task\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_transaction_context_sibling_task_isolation_example(database_url):\n    \"\"\"", "async def test_transaction_context_sibling_task_isolation_example(database_url):\n    \"\"\"\n    Ensure that transactions are running in sibling tasks are isolated from eachother.\n    \"\"\"\n    # This is an practical example of the above test.\n    db = Database(database_url)\n    if db.url.dialect == \"mssql\":\n        return\n    setup = asyncio.Event()\n    done = asyncio.Event()", "    setup = asyncio.Event()\n    done = asyncio.Event()\n\n    async def tx1(connection):\n        async with connection.transaction():\n            await db.execute(notes.insert(), values={\"id\": 1, \"text\": \"tx1\", \"completed\": False})\n            setup.set()\n            await done.wait()\n\n    async def tx2(connection):", "\n    async def tx2(connection):\n        async with connection.transaction():\n            await setup.wait()\n            result = await db.fetch_all(notes.select())\n            assert result == [], result\n            done.set()\n\n    async with Database(database_url) as db:\n        await asyncio.gather(tx1(db), tx2(db))", "    async with Database(database_url) as db:\n        await asyncio.gather(tx1(db), tx2(db))\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_connection_cleanup_contextmanager(database_url):\n    \"\"\"\n    Ensure that task connections are not persisted unecessarily.\n    \"\"\"", "    Ensure that task connections are not persisted unecessarily.\n    \"\"\"\n\n    ready = asyncio.Event()\n    done = asyncio.Event()\n\n    async def check_child_connection(database: Database):\n        async with database.connection():\n            ready.set()\n            await done.wait()", "            ready.set()\n            await done.wait()\n\n    async with Database(database_url) as database:\n        # Should have a connection in this task\n        # .connect is lazy, it doesn't create a Connection, but .connection does\n        connection = database.connection()\n        assert isinstance(database._connection_map, MutableMapping)\n        assert database._connection_map.get(asyncio.current_task()) is connection\n", "        assert database._connection_map.get(asyncio.current_task()) is connection\n\n        # Create a child task and see if it registers a connection\n        task = asyncio.create_task(check_child_connection(database))\n        await ready.wait()\n        assert database._connection_map.get(task) is not None\n        assert database._connection_map.get(task) is not connection\n\n        # Let the child task finish, and see if it cleaned up\n        done.set()", "        # Let the child task finish, and see if it cleaned up\n        done.set()\n        await task\n        # This is normal exit logic cleanup, the WeakKeyDictionary\n        # shouldn't have cleaned up yet since the task is still referenced\n        assert task not in database._connection_map\n\n    # Context manager closes, all open connections are removed\n    assert isinstance(database._connection_map, MutableMapping)\n    assert len(database._connection_map) == 0", "    assert isinstance(database._connection_map, MutableMapping)\n    assert len(database._connection_map) == 0\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_connection_cleanup_garbagecollector(database_url):\n    \"\"\"\n    Ensure that connections for tasks are not persisted unecessarily, even\n    if exit handlers are not called.", "    Ensure that connections for tasks are not persisted unecessarily, even\n    if exit handlers are not called.\n    \"\"\"\n    database = Database(database_url)\n    await database.connect()\n\n    created = asyncio.Event()\n\n    async def check_child_connection(database: Database):\n        # neither .disconnect nor .__aexit__ are called before deleting this task", "    async def check_child_connection(database: Database):\n        # neither .disconnect nor .__aexit__ are called before deleting this task\n        database.connection()\n        created.set()\n\n    task = asyncio.create_task(check_child_connection(database))\n    await created.wait()\n    assert task in database._connection_map\n    await task\n    del task", "    await task\n    del task\n    gc.collect()\n\n    # Should not have a connection for the task anymore\n    assert len(database._connection_map) == 0\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter", "@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_transaction_context_cleanup_contextmanager(database_url):\n    \"\"\"\n    Ensure that contextvar transactions are not persisted unecessarily.\n    \"\"\"\n    from databasez.core import ACTIVE_TRANSACTIONS\n\n    assert ACTIVE_TRANSACTIONS.get() is None\n", "    assert ACTIVE_TRANSACTIONS.get() is None\n\n    async with Database(database_url) as database:\n        async with database.transaction() as transaction:\n            open_transactions = ACTIVE_TRANSACTIONS.get()\n            assert isinstance(open_transactions, MutableMapping)\n            assert open_transactions.get(transaction) is transaction._transaction\n\n        # Context manager closes, open_transactions is cleaned up\n        open_transactions = ACTIVE_TRANSACTIONS.get()", "        # Context manager closes, open_transactions is cleaned up\n        open_transactions = ACTIVE_TRANSACTIONS.get()\n        assert isinstance(open_transactions, MutableMapping)\n        assert open_transactions.get(transaction, None) is None\n\n\n@pytest.mark.parametrize(\"database_url\", DATABASE_URLS)\n@async_adapter\nasync def test_transaction_context_cleanup_garbagecollector(database_url):\n    \"\"\"", "async def test_transaction_context_cleanup_garbagecollector(database_url):\n    \"\"\"\n    Ensure that contextvar transactions are not persisted unecessarily, even\n    if exit handlers are not called.\n    This test should be an XFAIL, but cannot be due to the way that is hangs\n    during teardown.\n    \"\"\"\n    from databasez.core import ACTIVE_TRANSACTIONS\n\n    assert ACTIVE_TRANSACTIONS.get() is None", "\n    assert ACTIVE_TRANSACTIONS.get() is None\n\n    async with Database(database_url) as database:\n        transaction = database.transaction()\n        await transaction.start()\n\n        # Should be tracking the transaction\n        open_transactions = ACTIVE_TRANSACTIONS.get()\n        assert isinstance(open_transactions, MutableMapping)", "        open_transactions = ACTIVE_TRANSACTIONS.get()\n        assert isinstance(open_transactions, MutableMapping)\n        assert open_transactions.get(transaction) is transaction._transaction\n\n        # neither .commit, .rollback, nor .__aexit__ are called\n        del transaction\n        gc.collect()\n\n        # A strong reference to the transaction is kept alive by the connection's\n        # ._transaction_stack, so it is still be tracked at this point.", "        # A strong reference to the transaction is kept alive by the connection's\n        # ._transaction_stack, so it is still be tracked at this point.\n        assert len(open_transactions) == 1\n\n        # If that were magically cleared, the transaction would be cleaned up,\n        # but as it stands this always causes a hang during teardown at\n        # `Database(...).disconnect()` if the transaction is not closed.\n        transaction = database.connection()._transaction_stack[-1]\n        await transaction.rollback()\n        del transaction", "        await transaction.rollback()\n        del transaction\n\n        # Now with the transaction rolled-back, it should be cleaned up.\n        assert len(open_transactions) == 0\n"]}
{"filename": "tests/test_database_url.py", "chunked_list": ["from urllib.parse import quote\n\nimport pytest\n\nfrom databasez import DatabaseURL\n\n\ndef test_database_url_repr():\n    u = DatabaseURL(\"postgresql://localhost/name\")\n    assert repr(u) == \"DatabaseURL('postgresql://localhost/name')\"\n\n    u = DatabaseURL(\"postgresql://username@localhost/name\")\n    assert repr(u) == \"DatabaseURL('postgresql://username@localhost/name')\"\n\n    u = DatabaseURL(\"postgresql://username:password@localhost/name\")\n    assert repr(u) == \"DatabaseURL('postgresql://username:********@localhost/name')\"\n\n    u = DatabaseURL(f\"postgresql://username:{quote('[password')}@localhost/name\")\n    assert repr(u) == \"DatabaseURL('postgresql://username:********@localhost/name')\"", "\n\ndef test_database_url_properties():\n    u = DatabaseURL(\"postgresql+asyncpg://username:password@localhost:123/mydatabase\")\n    assert u.dialect == \"postgresql\"\n    assert u.driver == \"asyncpg\"\n    assert u.username == \"username\"\n    assert u.password == \"password\"\n    assert u.hostname == \"localhost\"\n    assert u.port == 123\n    assert u.database == \"mydatabase\"\n\n    u = DatabaseURL(\n        \"postgresql://username:password@/mydatabase?host=/var/run/postgresql/.s.PGSQL.5432\"\n    )\n    assert u.dialect == \"postgresql\"\n    assert u.username == \"username\"\n    assert u.password == \"password\"\n    assert u.hostname == \"/var/run/postgresql/.s.PGSQL.5432\"\n    assert u.database == \"mydatabase\"\n\n    u = DatabaseURL(\n        \"postgresql://username:password@/mydatabase?unix_sock=/var/run/postgresql/.s.PGSQL.5432\"\n    )\n    assert u.hostname == \"/var/run/postgresql/.s.PGSQL.5432\"", "\n\ndef test_database_url_escape():\n    u = DatabaseURL(f\"postgresql://username:{quote('[password')}@localhost/mydatabase\")\n    assert u.username == \"username\"\n    assert u.password == \"[password\"\n    assert u.userinfo == f\"username:{quote('[password')}\".encode(\"utf-8\")\n\n    u2 = DatabaseURL(u)\n    assert u2.password == \"[password\"\n\n    u3 = DatabaseURL(str(u))\n    assert u3.password == \"[password\"", "\n\ndef test_database_url_constructor():\n    with pytest.raises(TypeError):\n        DatabaseURL((\"postgresql\", \"username\", \"password\", \"localhost\", \"mydatabase\"))\n\n    u = DatabaseURL(\"postgresql+asyncpg://username:password@localhost:123/mydatabase\")\n    assert DatabaseURL(u) == u\n\n\ndef test_database_url_options():\n    u = DatabaseURL(\"postgresql://localhost/mydatabase?pool_size=20&ssl=true\")\n    assert u.options == {\"pool_size\": \"20\", \"ssl\": \"true\"}\n\n    u = DatabaseURL(\"mysql+asyncmy://username/testsuite?unix_socket=/tmp/mysqld/mysqld.sock\")\n    assert u.options == {\"unix_socket\": \"/tmp/mysqld/mysqld.sock\"}", "\n\ndef test_database_url_options():\n    u = DatabaseURL(\"postgresql://localhost/mydatabase?pool_size=20&ssl=true\")\n    assert u.options == {\"pool_size\": \"20\", \"ssl\": \"true\"}\n\n    u = DatabaseURL(\"mysql+asyncmy://username/testsuite?unix_socket=/tmp/mysqld/mysqld.sock\")\n    assert u.options == {\"unix_socket\": \"/tmp/mysqld/mysqld.sock\"}\n\n\ndef test_replace_database_url_components():\n    u = DatabaseURL(\"postgresql://localhost/mydatabase\")\n\n    assert u.database == \"mydatabase\"\n    new = u.replace(database=\"test_\" + u.database)\n    assert new.database == \"test_mydatabase\"\n    assert str(new) == \"postgresql://localhost/test_mydatabase\"\n\n    assert u.driver == \"\"\n    new = u.replace(driver=\"asyncpg\")\n    assert new.driver == \"asyncpg\"\n    assert str(new) == \"postgresql+asyncpg://localhost/mydatabase\"\n\n    assert u.port is None\n    new = u.replace(port=123)\n    assert new.port == 123\n    assert str(new) == \"postgresql://localhost:123/mydatabase\"\n\n    assert u.username is None\n    assert u.userinfo is None\n\n    u = DatabaseURL(\"sqlite:///mydatabase\")\n    assert u.database == \"mydatabase\"\n    new = u.replace(database=\"test_\" + u.database)\n    assert new.database == \"test_mydatabase\"\n    assert str(new) == \"sqlite:///test_mydatabase\"\n\n    u = DatabaseURL(\"sqlite:////absolute/path\")\n    assert u.database == \"/absolute/path\"\n    new = u.replace(database=u.database + \"_test\")\n    assert new.database == \"/absolute/path_test\"\n    assert str(new) == \"sqlite:////absolute/path_test\"", "\n\ndef test_replace_database_url_components():\n    u = DatabaseURL(\"postgresql://localhost/mydatabase\")\n\n    assert u.database == \"mydatabase\"\n    new = u.replace(database=\"test_\" + u.database)\n    assert new.database == \"test_mydatabase\"\n    assert str(new) == \"postgresql://localhost/test_mydatabase\"\n\n    assert u.driver == \"\"\n    new = u.replace(driver=\"asyncpg\")\n    assert new.driver == \"asyncpg\"\n    assert str(new) == \"postgresql+asyncpg://localhost/mydatabase\"\n\n    assert u.port is None\n    new = u.replace(port=123)\n    assert new.port == 123\n    assert str(new) == \"postgresql://localhost:123/mydatabase\"\n\n    assert u.username is None\n    assert u.userinfo is None\n\n    u = DatabaseURL(\"sqlite:///mydatabase\")\n    assert u.database == \"mydatabase\"\n    new = u.replace(database=\"test_\" + u.database)\n    assert new.database == \"test_mydatabase\"\n    assert str(new) == \"sqlite:///test_mydatabase\"\n\n    u = DatabaseURL(\"sqlite:////absolute/path\")\n    assert u.database == \"/absolute/path\"\n    new = u.replace(database=u.database + \"_test\")\n    assert new.database == \"/absolute/path_test\"\n    assert str(new) == \"sqlite:////absolute/path_test\"", ""]}
{"filename": "tests/importer/__init__.py", "chunked_list": [""]}
{"filename": "tests/importer/raise_import_error.py", "chunked_list": ["# Used by test_importer.py\n\nmyattr = 123\n\nimport does_not_exist as does_not_exist  # noqa: E402\n"]}
{"filename": "docs_src/quickstart/quickstart.py", "chunked_list": ["# Create a database instance, and connect to it.\nfrom databasez import Database\n\ndatabase = Database(\"sqlite+aiosqlite:///example.db\")\nawait database.connect()\n\n# Create a table.\nquery = \"\"\"CREATE TABLE HighScores (id INTEGER PRIMARY KEY, name VARCHAR(100), score INTEGER)\"\"\"\nawait database.execute(query=query)\n", "await database.execute(query=query)\n\n# Insert some data.\nquery = \"INSERT INTO HighScores(name, score) VALUES (:name, :score)\"\nvalues = [\n    {\"name\": \"Daisy\", \"score\": 92},\n    {\"name\": \"Neil\", \"score\": 87},\n    {\"name\": \"Carol\", \"score\": 43},\n]\nawait database.execute_many(query=query, values=values)", "]\nawait database.execute_many(query=query, values=values)\n\n# Run a database query.\nquery = \"SELECT * FROM HighScores\"\nrows = await database.fetch_all(query=query)\n\nprint(\"High Scores:\", rows)\n", ""]}
{"filename": "docs_src/connections/mssql.py", "chunked_list": ["from databasez import Database\n\nCONFIG = {\n    \"connection\": {\n        \"credentials\": {\n            \"scheme\": \"mssql+aioodbc\",\n            \"host\": \"localhost\",\n            \"port\": 1433,\n            \"user\": \"sa\",\n            \"password\": \"Mssql123mssql\",", "            \"user\": \"sa\",\n            \"password\": \"Mssql123mssql\",\n            \"database\": \"master\",\n            \"options\": {\"driver\": \"ODBC Driver 17 for SQL Server\"},\n        }\n    }\n}\n\ndatabase = Database(config=CONFIG)\n", "database = Database(config=CONFIG)\n"]}
{"filename": "docs_src/connections/as_dict.py", "chunked_list": ["from databasez import Database\n\nCONFIG = {\n    \"connection\": {\n        \"credentials\": {\n            \"scheme\": \"postgres+asyncpg\",\n            \"host\": \"localhost\",\n            \"port\": 5432,\n            \"user\": \"postgres\",\n            \"password\": \"password\",", "            \"user\": \"postgres\",\n            \"password\": \"password\",\n            \"database\": \"my_db\",\n        }\n    }\n}\n\ndatabase = Database(config=CONFIG)\n", ""]}
{"filename": "docs_src/testclient/tests.py", "chunked_list": ["import datetime\nimport decimal\nimport ipaddress\nimport uuid\nfrom enum import Enum\n\nimport pytest\nimport saffier\nfrom databasez.testclient import DatabaseTestClient\nfrom saffier.db.models import fields", "from databasez.testclient import DatabaseTestClient\nfrom saffier.db.models import fields\n\nfrom tests.settings import DATABASE_URL\n\ndatabase = DatabaseTestClient(DATABASE_URL, drop_database=True)\nmodels = saffier.Registry(database=database)\n\npytestmark = pytest.mark.anyio\n", "pytestmark = pytest.mark.anyio\n\n\ndef time():\n    return datetime.datetime.now().time()\n\n\nclass StatusEnum(Enum):\n    DRAFT = \"Draft\"\n    RELEASED = \"Released\"", "\n\nclass Product(saffier.Model):\n    id = fields.IntegerField(primary_key=True)\n    uuid = fields.UUIDField(null=True)\n    created = fields.DateTimeField(default=datetime.datetime.now)\n    created_day = fields.DateField(default=datetime.date.today)\n    created_time = fields.TimeField(default=time)\n    created_date = fields.DateField(auto_now_add=True)\n    created_datetime = fields.DateTimeField(auto_now_add=True)\n    updated_datetime = fields.DateTimeField(auto_now=True)\n    updated_date = fields.DateField(auto_now=True)\n    data = fields.JSONField(default={})\n    description = fields.CharField(blank=True, max_length=255)\n    huge_number = fields.BigIntegerField(default=0)\n    price = fields.DecimalField(max_digits=5, decimal_places=2, null=True)\n    status = fields.ChoiceField(StatusEnum, default=StatusEnum.DRAFT)\n    value = fields.FloatField(null=True)\n\n    class Meta:\n        registry = models", "\n\nclass User(saffier.Model):\n    id = fields.UUIDField(primary_key=True, default=uuid.uuid4)\n    name = fields.CharField(null=True, max_length=16)\n    email = fields.EmailField(null=True, max_length=256)\n    ipaddress = fields.IPAddressField(null=True)\n    url = fields.URLField(null=True, max_length=2048)\n    password = fields.PasswordField(null=True, max_length=255)\n\n    class Meta:\n        registry = models", "\n\nclass Customer(saffier.Model):\n    name = fields.CharField(null=True, max_length=16)\n\n    class Meta:\n        registry = models\n\n\n@pytest.fixture(autouse=True, scope=\"module\")", "\n@pytest.fixture(autouse=True, scope=\"module\")\nasync def create_test_database():\n    await models.create_all()\n    yield\n    await models.drop_all()\n\n\n@pytest.fixture(autouse=True)\nasync def rollback_transactions():\n    with database.force_rollback():\n        async with database:\n            yield", "@pytest.fixture(autouse=True)\nasync def rollback_transactions():\n    with database.force_rollback():\n        async with database:\n            yield\n\n\nasync def test_model_crud():\n    product = await Product.query.create()\n    product = await Product.query.get(pk=product.pk)", "    product = await Product.query.create()\n    product = await Product.query.get(pk=product.pk)\n    assert product.created.year == datetime.datetime.now().year\n    assert product.created_day == datetime.date.today()\n    assert product.created_date == datetime.date.today()\n    assert product.created_datetime.date() == datetime.datetime.now().date()\n    assert product.updated_date == datetime.date.today()\n    assert product.updated_datetime.date() == datetime.datetime.now().date()\n    assert product.data == {}\n    assert product.description == \"\"", "    assert product.data == {}\n    assert product.description == \"\"\n    assert product.huge_number == 0\n    assert product.price is None\n    assert product.status == StatusEnum.DRAFT\n    assert product.value is None\n    assert product.uuid is None\n\n    await product.update(\n        data={\"foo\": 123},", "    await product.update(\n        data={\"foo\": 123},\n        value=123.456,\n        status=StatusEnum.RELEASED,\n        price=decimal.Decimal(\"999.99\"),\n        uuid=uuid.UUID(\"f4e87646-bafa-431e-a0cb-e84f2fcf6b55\"),\n    )\n\n    product = await Product.query.get()\n    assert product.value == 123.456", "    product = await Product.query.get()\n    assert product.value == 123.456\n    assert product.data == {\"foo\": 123}\n    assert product.status == StatusEnum.RELEASED\n    assert product.price == decimal.Decimal(\"999.99\")\n    assert product.uuid == uuid.UUID(\"f4e87646-bafa-431e-a0cb-e84f2fcf6b55\")\n\n    last_updated_datetime = product.updated_datetime\n    last_updated_date = product.updated_date\n    user = await User.query.create()", "    last_updated_date = product.updated_date\n    user = await User.query.create()\n    assert isinstance(user.pk, uuid.UUID)\n\n    user = await User.query.get()\n    assert user.email is None\n    assert user.ipaddress is None\n    assert user.url is None\n\n    await user.update(", "\n    await user.update(\n        ipaddress=\"192.168.1.1\",\n        name=\"Test\",\n        email=\"test@saffier.com\",\n        url=\"https://saffier.com\",\n        password=\"12345\",\n    )\n\n    user = await User.query.get()", "\n    user = await User.query.get()\n    assert isinstance(user.ipaddress, (ipaddress.IPv4Address, ipaddress.IPv6Address))\n    assert user.password == \"12345\"\n\n    assert user.url == \"https://saffier.com\"\n    await product.update(data={\"foo\": 1234})\n    assert product.updated_datetime != last_updated_datetime\n    assert product.updated_date == last_updated_date\n", "    assert product.updated_date == last_updated_date\n"]}
{"filename": "docs_src/queries/declarations2.py", "chunked_list": ["import sqlalchemy\n\nmetadata = sqlalchemy.MetaData()\n\nuser = sqlalchemy.Table(\n    \"users\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"name\", sqlalchemy.String(length=150)),\n    sqlalchemy.Column(\"address\", sqlalchemy.String(length=500)),", "    sqlalchemy.Column(\"name\", sqlalchemy.String(length=150)),\n    sqlalchemy.Column(\"address\", sqlalchemy.String(length=500)),\n    sqlalchemy.Column(\"config\", sqlalchemy.JSON(none_as_null=True)),\n)\n"]}
{"filename": "docs_src/queries/create_tables.py", "chunked_list": ["import sqlalchemy\nfrom databasez import Database\n\ndatabase = Database(\"postgresql+asyncpg://localhost/example\")\n\n# Establish the connection pool\nawait database.connect()\n\nmetadata = sqlalchemy.MetaData()\ndialect = sqlalchemy.dialects.postgresql.dialect()", "metadata = sqlalchemy.MetaData()\ndialect = sqlalchemy.dialects.postgresql.dialect()\n\n# Define your table(s)\nusers = sqlalchemy.Table(\n    \"users\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"name\", sqlalchemy.String(length=150)),\n    sqlalchemy.Column(\"address\", sqlalchemy.String(length=500)),", "    sqlalchemy.Column(\"name\", sqlalchemy.String(length=150)),\n    sqlalchemy.Column(\"address\", sqlalchemy.String(length=500)),\n)\n\n# Create tables\nfor table in metadata.tables.values():\n    # Set `if_not_exists=False` if you want the query to throw an\n    # exception when the table already exists\n    schema = sqlalchemy.schema.CreateTable(table, if_not_exists=True)\n    query = str(schema.compile(dialect=dialect))\n    await database.execute(query=query)", "\n# Close all connections in the connection pool\nawait database.disconnect()\n"]}
{"filename": "docs_src/queries/raw_queries.py", "chunked_list": ["from databasez import Database\n\ndatabase = Database(\"postgresql+asyncpg://localhost/example\")\n\n\n# Establish the connection pool\nawait database.connect()\n\n# Execute\nquery = \"INSERT INTO users(name, address) VALUES (:name, :address)\"", "# Execute\nquery = \"INSERT INTO users(name, address) VALUES (:name, :address)\"\nvalues = {\"text\": \"databasez\", \"address\": \"London, United Kingdom\"}\nawait database.execute(query=query, values=values)\n\n# Execute many\nquery = \"INSERT INTO users(name, address) VALUES (:name, :address)\"\nvalues = [\n    {\"name\": \"databasez\", \"address\": \"London, United Kingdom\"},\n    {\"name\": \"another name\", \"address\": \"The Hague, Netherlands\"},", "    {\"name\": \"databasez\", \"address\": \"London, United Kingdom\"},\n    {\"name\": \"another name\", \"address\": \"The Hague, Netherlands\"},\n]\nawait database.execute_many(query=query, values=values)\n\n# Fetch multiple rows\nquery = \"SELECT * FROM users WHERE address = :address\"\nrows = await database.fetch_all(query=query, values={\"address\": \"London, United Kingdom\"})\n\n# Fetch single row", "\n# Fetch single row\nquery = \"SELECT * FROM users WHERE id = :id\"\nresult = await database.fetch_one(query=query, values={\"id\": 1})\n"]}
{"filename": "docs_src/queries/declarations.py", "chunked_list": ["import sqlalchemy\n\nmetadata = sqlalchemy.MetaData()\n\nuser = sqlalchemy.Table(\n    \"users\",\n    metadata,\n    sqlalchemy.Column(\"id\", sqlalchemy.Integer, primary_key=True),\n    sqlalchemy.Column(\"name\", sqlalchemy.String(length=150)),\n    sqlalchemy.Column(\"address\", sqlalchemy.String(length=500)),", "    sqlalchemy.Column(\"name\", sqlalchemy.String(length=150)),\n    sqlalchemy.Column(\"address\", sqlalchemy.String(length=500)),\n)\n"]}
{"filename": "docs_src/queries/queries.py", "chunked_list": ["from databasez import Database\n\ndatabase = Database(\"postgresql+asyncpg://localhost/example\")\n\n\n# Establish the connection pool\nawait database.connect()\n\n# Execute\nquery = users.insert()", "# Execute\nquery = users.insert()\nvalues = {\"name\": \"databasez\", \"address\": \"London, United Kingdom\"}\nawait database.execute(query=query, values=values)\n\n# Execute many\nquery = users.insert()\nvalues = [\n    {\"name\": \"databasez\", \"address\": \"London, United Kingdom\"},\n    {\"name\": \"another name\", \"address\": \"The Hague, Netherlands\"},", "    {\"name\": \"databasez\", \"address\": \"London, United Kingdom\"},\n    {\"name\": \"another name\", \"address\": \"The Hague, Netherlands\"},\n]\nawait database.execute_many(query=query, values=values)\n\n# Fetch multiple rows\nquery = users.select()\nrows = await database.fetch_all(query=query)\n\n# Fetch single row", "\n# Fetch single row\nquery = users.select()\nrow = await database.fetch_one(query=query)\n\n# Fetch single value, defaults to `column=0`.\nquery = users.select()\nvalue = await database.fetch_val(query=query)\n\n# Fetch multiple rows without loading them all into memory at once", "\n# Fetch multiple rows without loading them all into memory at once\nquery = users.select()\nasync for row in database.iterate(query=query):\n    ...\n\n# Close all connections in the connection pool\nawait database.disconnect()\n", ""]}
{"filename": "databasez/types.py", "chunked_list": ["from typing import Any, Dict\n\nDictAny = Dict[str, Any]\n"]}
{"filename": "databasez/importer.py", "chunked_list": ["import importlib\nimport typing\n\n\nclass ImportFromStringError(Exception):\n    pass\n\n\ndef import_from_string(import_str: str) -> typing.Any:\n    module_str, _, attrs_str = import_str.partition(\":\")\n    if not module_str or not attrs_str:\n        message = 'Import string \"{import_str}\" must be in format \"<module>:<attribute>\".'\n        raise ImportFromStringError(message.format(import_str=import_str))\n\n    try:\n        module = importlib.import_module(module_str)\n    except ImportError as exc:\n        if exc.name != module_str:\n            raise exc from None\n        message = 'Could not import module \"{module_str}\".'\n        raise ImportFromStringError(message.format(module_str=module_str)) from exc\n\n    instance = module\n    try:\n        for attr_str in attrs_str.split(\".\"):\n            instance = getattr(instance, attr_str)\n    except AttributeError as e:\n        message = 'Attribute \"{attrs_str}\" not found in module \"{module_str}\".'\n        raise ImportFromStringError(\n            message.format(attrs_str=attrs_str, module_str=module_str)\n        ) from e\n\n    return instance", "def import_from_string(import_str: str) -> typing.Any:\n    module_str, _, attrs_str = import_str.partition(\":\")\n    if not module_str or not attrs_str:\n        message = 'Import string \"{import_str}\" must be in format \"<module>:<attribute>\".'\n        raise ImportFromStringError(message.format(import_str=import_str))\n\n    try:\n        module = importlib.import_module(module_str)\n    except ImportError as exc:\n        if exc.name != module_str:\n            raise exc from None\n        message = 'Could not import module \"{module_str}\".'\n        raise ImportFromStringError(message.format(module_str=module_str)) from exc\n\n    instance = module\n    try:\n        for attr_str in attrs_str.split(\".\"):\n            instance = getattr(instance, attr_str)\n    except AttributeError as e:\n        message = 'Attribute \"{attrs_str}\" not found in module \"{module_str}\".'\n        raise ImportFromStringError(\n            message.format(attrs_str=attrs_str, module_str=module_str)\n        ) from e\n\n    return instance", ""]}
{"filename": "databasez/__init__.py", "chunked_list": ["from databasez.core import Database, DatabaseURL\n\n__version__ = \"0.5.0\"\n\n__all__ = [\"Database\", \"DatabaseURL\"]\n"]}
{"filename": "databasez/core.py", "chunked_list": ["import asyncio\nimport contextlib\nimport functools\nimport logging\nimport typing\nimport weakref\nfrom contextvars import ContextVar\nfrom types import TracebackType\nfrom urllib.parse import SplitResult, parse_qsl, unquote, urlencode, urlsplit\n", "from urllib.parse import SplitResult, parse_qsl, unquote, urlencode, urlsplit\n\nfrom sqlalchemy import text\nfrom sqlalchemy.sql import ClauseElement\n\nfrom databasez.importer import import_from_string\nfrom databasez.interfaces import DatabaseBackend, Record, TransactionBackend\n\nif typing.TYPE_CHECKING:\n    from databasez.types import DictAny", "if typing.TYPE_CHECKING:\n    from databasez.types import DictAny\n\ntry:  # pragma: no cover\n    import click\n\n    # Extra log info for optional coloured terminal outputs.\n    LOG_EXTRA = {\"color_message\": \"Query: \" + click.style(\"%s\", bold=True) + \" Args: %s\"}\n    CONNECT_EXTRA = {\"color_message\": \"Connected to database \" + click.style(\"%s\", bold=True)}\n    DISCONNECT_EXTRA = {\n        \"color_message\": \"Disconnected from database \" + click.style(\"%s\", bold=True)\n    }\nexcept ImportError:  # pragma: no cover\n    LOG_EXTRA = {}\n    CONNECT_EXTRA = {}\n    DISCONNECT_EXTRA = {}", "\n\nlogger = logging.getLogger(\"databasez\")\n\n\nACTIVE_TRANSACTIONS: ContextVar[\n    typing.Optional[\"weakref.WeakKeyDictionary['Transaction', 'TransactionBackend']\"]\n] = ContextVar(\"databasez:active_transactions\", default=None)\n\n\nclass Database:\n    \"\"\"\n    An abstraction on the top of the EncodeORM databases.Database object.\n\n    This object allows to pass also a configuration dictionary in the format of\n\n    DATABASEZ_CONFIG = {\n        \"connection\": {\n            \"credentials\": {\n                \"scheme\": 'sqlite', \"postgres\"...\n                \"host\": ...,\n                \"port\": ...,\n                \"user\": ...,\n                \"password\": ...,\n                \"database\": ...,\n                \"options\": {\n                    \"driver\": ...\n                    \"ssl\": ...\n                }\n            }\n        }\n    }\n    \"\"\"\n\n    SUPPORTED_BACKENDS = {\n        \"postgresql\": \"databasez.backends.postgres:PostgresBackend\",\n        \"postgresql+aiopg\": \"databasez.backends.aiopg:AiopgBackend\",\n        \"postgres\": \"databasez.backends.postgres:PostgresBackend\",\n        \"mysql\": \"databasez.backends.mysql:MySQLBackend\",\n        \"mysql+asyncmy\": \"databasez.backends.asyncmy:AsyncMyBackend\",\n        \"mssql\": \"databasez.backends.mssql:MSSQLBackend\",\n        \"mssql+pyodbc\": \"databasez.backends.mssql:MSSQLBackend\",\n        \"mssql+aioodbc\": \"databasez.backends.mssql:MSSQLBackend\",\n        \"sqlite\": \"databasez.backends.sqlite:SQLiteBackend\",\n    }\n    DIRECT_URL_SCHEME = {\"sqlite\"}\n    MANDATORY_FIELDS = [\"host\", \"port\", \"user\", \"database\"]\n    _connection_map: \"weakref.WeakKeyDictionary[asyncio.Task, 'Connection']\"\n\n    def __init__(\n        self,\n        url: typing.Optional[typing.Union[str, \"DatabaseURL\"]] = None,\n        *,\n        force_rollback: bool = False,\n        config: typing.Optional[\"DictAny\"] = None,\n        **options: typing.Any,\n    ):\n        assert config is None or url is None, \"Use either 'url' or 'config', not both.\"\n\n        _url: typing.Optional[typing.Union[str, \"DatabaseURL\"]] = None\n        if not config:\n            _url = url\n        else:\n            _url = self._build_url(config)\n\n        self.url = DatabaseURL(_url)  # type: ignore\n        self.options = options\n        self.is_connected = False\n        self._connection_map = weakref.WeakKeyDictionary()\n\n        self._force_rollback = force_rollback\n\n        backend_str = self._get_backend()\n        backend_cls = import_from_string(backend_str)\n        assert issubclass(backend_cls, DatabaseBackend)\n        self._backend = backend_cls(self.url, **self.options)\n\n        # When `force_rollback=True` is used, we use a single global\n        # connection, within a transaction that always rolls back.\n        self._global_connection: typing.Optional[Connection] = None\n        self._global_transaction: typing.Optional[Transaction] = None\n\n    @property\n    def allowed_url_schemes(self) -> typing.Set[str]:\n        schemes = {\n            value\n            for value in self.SUPPORTED_BACKENDS.keys()\n            if value not in self.DIRECT_URL_SCHEME\n        }\n        return schemes\n\n    def _build_url(self, config: \"DictAny\") -> str:\n        assert \"connection\" in config, \"connection not found in the database configuration\"\n        connection = config[\"connection\"]\n\n        assert \"credentials\" in connection, \"credetials not found in connection\"\n        credentials = connection[\"credentials\"]\n\n        assert (\n            \"scheme\" in credentials\n        ), \"scheme is missing from credentials. Use postgres or mysql instead\"\n\n        scheme = credentials[\"scheme\"]\n        if not scheme or scheme is None:\n            raise ValueError(\"scheme cannot be None\")\n\n        database = credentials[\"database\"]\n\n        scheme = scheme.lower()\n        if scheme.lower() in self.DIRECT_URL_SCHEME:\n            return self._build_url_for_direct_url_scheme(scheme, database)\n\n        for value in self.MANDATORY_FIELDS:\n            if not value or value is None:\n                raise ValueError(f\"{value} is required in the credentials\")\n\n        user = credentials[\"user\"]\n        password = credentials.get(\"password\", None)\n        host = credentials[\"host\"]\n        port = credentials[\"port\"]\n\n        if \"password\" not in credentials:\n            connection_string = f\"{scheme}://{user}@{host}:{port}/{database}\"\n        else:\n            connection_string = f\"{scheme}://{user}:{password}@{host}:{port}/{database}\"\n\n        options = credentials.get(\"options\", None)\n\n        if options is None or not options:\n            return connection_string\n        return f\"{connection_string}?{urlencode(options)}\"\n\n    def _build_url_for_direct_url_scheme(self, scheme: str, database: str) -> str:\n        \"\"\"Builds the URL for direct url schemes that do not support user, password and other\n        parameters. Example: SQLite.\n        \"\"\"\n        return f\"{scheme}:///{database}\"\n\n    @property\n    def _current_task(self) -> asyncio.Task:\n        task = asyncio.current_task()\n        if not task:\n            raise RuntimeError(\"No currently active asyncio.Task found\")\n        return task\n\n    @property\n    def _connection(self) -> typing.Optional[\"Connection\"]:\n        return self._connection_map.get(self._current_task)\n\n    @_connection.setter\n    def _connection(\n        self, connection: typing.Optional[\"Connection\"]\n    ) -> typing.Optional[\"Connection\"]:\n        task = self._current_task\n\n        if connection is None:\n            self._connection_map.pop(task, None)\n        else:\n            self._connection_map[task] = connection\n\n        return self._connection\n\n    async def connect(self) -> None:\n        \"\"\"\n        Establish the connection pool.\n        \"\"\"\n        if self.is_connected:\n            logger.debug(\"Already connected, skipping connection\")\n            return None\n\n        await self._backend.connect()\n        logger.info(\"Connected to database %s\", self.url.obscure_password, extra=CONNECT_EXTRA)\n        self.is_connected = True\n\n        if self._force_rollback:\n            assert self._global_connection is None\n            assert self._global_transaction is None\n\n            self._global_connection = Connection(self, self._backend)\n            self._global_transaction = self._global_connection.transaction(force_rollback=True)\n\n            await self._global_transaction.__aenter__()\n\n    async def disconnect(self) -> None:\n        \"\"\"\n        Close all connections in the connection pool.\n        \"\"\"\n        if not self.is_connected:\n            logger.debug(\"Already disconnected, skipping disconnection\")\n            return None\n\n        if self._force_rollback:\n            assert self._global_connection is not None\n            assert self._global_transaction is not None\n\n            await self._global_transaction.__aexit__()\n\n            self._global_transaction = None\n            self._global_connection = None\n        else:\n            self._connection = None\n\n        await self._backend.disconnect()\n        logger.info(\n            \"Disconnected from database %s\",\n            self.url.obscure_password,\n            extra=DISCONNECT_EXTRA,\n        )\n        self.is_connected = False\n\n    async def __aenter__(self) -> \"Database\":\n        await self.connect()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: typing.Optional[typing.Type[BaseException]] = None,\n        exc_value: typing.Optional[BaseException] = None,\n        traceback: typing.Optional[TracebackType] = None,\n    ) -> None:\n        await self.disconnect()\n\n    async def fetch_all(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.List[Record]:\n        async with self.connection() as connection:\n            return await connection.fetch_all(query, values)\n\n    async def fetch_one(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.Optional[Record]:\n        async with self.connection() as connection:\n            return await connection.fetch_one(query, values)\n\n    async def fetch_val(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n        column: typing.Any = 0,\n    ) -> typing.Any:\n        async with self.connection() as connection:\n            return await connection.fetch_val(query, values, column=column)\n\n    async def execute(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.Any:\n        async with self.connection() as connection:\n            return await connection.execute(query, values)\n\n    async def execute_many(self, query: typing.Union[ClauseElement, str], values: list) -> None:\n        async with self.connection() as connection:\n            return await connection.execute_many(query, values)\n\n    async def iterate(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.AsyncGenerator[typing.Mapping, None]:\n        async with self.connection() as connection:\n            async for record in connection.iterate(query, values):\n                yield record\n\n    def connection(self) -> \"Connection\":\n        if self._global_connection is not None:\n            return self._global_connection\n\n        if not self._connection:\n            self._connection = Connection(self, self._backend)\n        return self._connection\n\n    def transaction(self, *, force_rollback: bool = False, **kwargs: typing.Any) -> \"Transaction\":\n        return Transaction(self.connection, force_rollback=force_rollback, **kwargs)\n\n    @contextlib.contextmanager\n    def force_rollback(self) -> typing.Iterator[None]:\n        initial = self._force_rollback\n        self._force_rollback = True\n        try:\n            yield\n        finally:\n            self._force_rollback = initial\n\n    def _get_backend(self) -> str:\n        return self.SUPPORTED_BACKENDS.get(\n            self.url.scheme, self.SUPPORTED_BACKENDS[self.url.dialect]\n        )", "\n\nclass Database:\n    \"\"\"\n    An abstraction on the top of the EncodeORM databases.Database object.\n\n    This object allows to pass also a configuration dictionary in the format of\n\n    DATABASEZ_CONFIG = {\n        \"connection\": {\n            \"credentials\": {\n                \"scheme\": 'sqlite', \"postgres\"...\n                \"host\": ...,\n                \"port\": ...,\n                \"user\": ...,\n                \"password\": ...,\n                \"database\": ...,\n                \"options\": {\n                    \"driver\": ...\n                    \"ssl\": ...\n                }\n            }\n        }\n    }\n    \"\"\"\n\n    SUPPORTED_BACKENDS = {\n        \"postgresql\": \"databasez.backends.postgres:PostgresBackend\",\n        \"postgresql+aiopg\": \"databasez.backends.aiopg:AiopgBackend\",\n        \"postgres\": \"databasez.backends.postgres:PostgresBackend\",\n        \"mysql\": \"databasez.backends.mysql:MySQLBackend\",\n        \"mysql+asyncmy\": \"databasez.backends.asyncmy:AsyncMyBackend\",\n        \"mssql\": \"databasez.backends.mssql:MSSQLBackend\",\n        \"mssql+pyodbc\": \"databasez.backends.mssql:MSSQLBackend\",\n        \"mssql+aioodbc\": \"databasez.backends.mssql:MSSQLBackend\",\n        \"sqlite\": \"databasez.backends.sqlite:SQLiteBackend\",\n    }\n    DIRECT_URL_SCHEME = {\"sqlite\"}\n    MANDATORY_FIELDS = [\"host\", \"port\", \"user\", \"database\"]\n    _connection_map: \"weakref.WeakKeyDictionary[asyncio.Task, 'Connection']\"\n\n    def __init__(\n        self,\n        url: typing.Optional[typing.Union[str, \"DatabaseURL\"]] = None,\n        *,\n        force_rollback: bool = False,\n        config: typing.Optional[\"DictAny\"] = None,\n        **options: typing.Any,\n    ):\n        assert config is None or url is None, \"Use either 'url' or 'config', not both.\"\n\n        _url: typing.Optional[typing.Union[str, \"DatabaseURL\"]] = None\n        if not config:\n            _url = url\n        else:\n            _url = self._build_url(config)\n\n        self.url = DatabaseURL(_url)  # type: ignore\n        self.options = options\n        self.is_connected = False\n        self._connection_map = weakref.WeakKeyDictionary()\n\n        self._force_rollback = force_rollback\n\n        backend_str = self._get_backend()\n        backend_cls = import_from_string(backend_str)\n        assert issubclass(backend_cls, DatabaseBackend)\n        self._backend = backend_cls(self.url, **self.options)\n\n        # When `force_rollback=True` is used, we use a single global\n        # connection, within a transaction that always rolls back.\n        self._global_connection: typing.Optional[Connection] = None\n        self._global_transaction: typing.Optional[Transaction] = None\n\n    @property\n    def allowed_url_schemes(self) -> typing.Set[str]:\n        schemes = {\n            value\n            for value in self.SUPPORTED_BACKENDS.keys()\n            if value not in self.DIRECT_URL_SCHEME\n        }\n        return schemes\n\n    def _build_url(self, config: \"DictAny\") -> str:\n        assert \"connection\" in config, \"connection not found in the database configuration\"\n        connection = config[\"connection\"]\n\n        assert \"credentials\" in connection, \"credetials not found in connection\"\n        credentials = connection[\"credentials\"]\n\n        assert (\n            \"scheme\" in credentials\n        ), \"scheme is missing from credentials. Use postgres or mysql instead\"\n\n        scheme = credentials[\"scheme\"]\n        if not scheme or scheme is None:\n            raise ValueError(\"scheme cannot be None\")\n\n        database = credentials[\"database\"]\n\n        scheme = scheme.lower()\n        if scheme.lower() in self.DIRECT_URL_SCHEME:\n            return self._build_url_for_direct_url_scheme(scheme, database)\n\n        for value in self.MANDATORY_FIELDS:\n            if not value or value is None:\n                raise ValueError(f\"{value} is required in the credentials\")\n\n        user = credentials[\"user\"]\n        password = credentials.get(\"password\", None)\n        host = credentials[\"host\"]\n        port = credentials[\"port\"]\n\n        if \"password\" not in credentials:\n            connection_string = f\"{scheme}://{user}@{host}:{port}/{database}\"\n        else:\n            connection_string = f\"{scheme}://{user}:{password}@{host}:{port}/{database}\"\n\n        options = credentials.get(\"options\", None)\n\n        if options is None or not options:\n            return connection_string\n        return f\"{connection_string}?{urlencode(options)}\"\n\n    def _build_url_for_direct_url_scheme(self, scheme: str, database: str) -> str:\n        \"\"\"Builds the URL for direct url schemes that do not support user, password and other\n        parameters. Example: SQLite.\n        \"\"\"\n        return f\"{scheme}:///{database}\"\n\n    @property\n    def _current_task(self) -> asyncio.Task:\n        task = asyncio.current_task()\n        if not task:\n            raise RuntimeError(\"No currently active asyncio.Task found\")\n        return task\n\n    @property\n    def _connection(self) -> typing.Optional[\"Connection\"]:\n        return self._connection_map.get(self._current_task)\n\n    @_connection.setter\n    def _connection(\n        self, connection: typing.Optional[\"Connection\"]\n    ) -> typing.Optional[\"Connection\"]:\n        task = self._current_task\n\n        if connection is None:\n            self._connection_map.pop(task, None)\n        else:\n            self._connection_map[task] = connection\n\n        return self._connection\n\n    async def connect(self) -> None:\n        \"\"\"\n        Establish the connection pool.\n        \"\"\"\n        if self.is_connected:\n            logger.debug(\"Already connected, skipping connection\")\n            return None\n\n        await self._backend.connect()\n        logger.info(\"Connected to database %s\", self.url.obscure_password, extra=CONNECT_EXTRA)\n        self.is_connected = True\n\n        if self._force_rollback:\n            assert self._global_connection is None\n            assert self._global_transaction is None\n\n            self._global_connection = Connection(self, self._backend)\n            self._global_transaction = self._global_connection.transaction(force_rollback=True)\n\n            await self._global_transaction.__aenter__()\n\n    async def disconnect(self) -> None:\n        \"\"\"\n        Close all connections in the connection pool.\n        \"\"\"\n        if not self.is_connected:\n            logger.debug(\"Already disconnected, skipping disconnection\")\n            return None\n\n        if self._force_rollback:\n            assert self._global_connection is not None\n            assert self._global_transaction is not None\n\n            await self._global_transaction.__aexit__()\n\n            self._global_transaction = None\n            self._global_connection = None\n        else:\n            self._connection = None\n\n        await self._backend.disconnect()\n        logger.info(\n            \"Disconnected from database %s\",\n            self.url.obscure_password,\n            extra=DISCONNECT_EXTRA,\n        )\n        self.is_connected = False\n\n    async def __aenter__(self) -> \"Database\":\n        await self.connect()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: typing.Optional[typing.Type[BaseException]] = None,\n        exc_value: typing.Optional[BaseException] = None,\n        traceback: typing.Optional[TracebackType] = None,\n    ) -> None:\n        await self.disconnect()\n\n    async def fetch_all(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.List[Record]:\n        async with self.connection() as connection:\n            return await connection.fetch_all(query, values)\n\n    async def fetch_one(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.Optional[Record]:\n        async with self.connection() as connection:\n            return await connection.fetch_one(query, values)\n\n    async def fetch_val(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n        column: typing.Any = 0,\n    ) -> typing.Any:\n        async with self.connection() as connection:\n            return await connection.fetch_val(query, values, column=column)\n\n    async def execute(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.Any:\n        async with self.connection() as connection:\n            return await connection.execute(query, values)\n\n    async def execute_many(self, query: typing.Union[ClauseElement, str], values: list) -> None:\n        async with self.connection() as connection:\n            return await connection.execute_many(query, values)\n\n    async def iterate(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.AsyncGenerator[typing.Mapping, None]:\n        async with self.connection() as connection:\n            async for record in connection.iterate(query, values):\n                yield record\n\n    def connection(self) -> \"Connection\":\n        if self._global_connection is not None:\n            return self._global_connection\n\n        if not self._connection:\n            self._connection = Connection(self, self._backend)\n        return self._connection\n\n    def transaction(self, *, force_rollback: bool = False, **kwargs: typing.Any) -> \"Transaction\":\n        return Transaction(self.connection, force_rollback=force_rollback, **kwargs)\n\n    @contextlib.contextmanager\n    def force_rollback(self) -> typing.Iterator[None]:\n        initial = self._force_rollback\n        self._force_rollback = True\n        try:\n            yield\n        finally:\n            self._force_rollback = initial\n\n    def _get_backend(self) -> str:\n        return self.SUPPORTED_BACKENDS.get(\n            self.url.scheme, self.SUPPORTED_BACKENDS[self.url.dialect]\n        )", "\n\nclass Connection:\n    def __init__(self, database: Database, backend: DatabaseBackend) -> None:\n        self._database = database\n        self._backend = backend\n\n        self._connection_lock = asyncio.Lock()\n        self._connection = self._backend.connection()\n        self._connection_counter = 0\n\n        self._transaction_lock = asyncio.Lock()\n        self._transaction_stack: typing.List[Transaction] = []\n\n        self._query_lock = asyncio.Lock()\n\n    async def __aenter__(self) -> \"Connection\":\n        async with self._connection_lock:\n            self._connection_counter += 1\n            try:\n                if self._connection_counter == 1:\n                    await self._connection.acquire()\n            except BaseException as e:\n                self._connection_counter -= 1\n                raise e\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: typing.Optional[typing.Type[BaseException]] = None,\n        exc_value: typing.Optional[BaseException] = None,\n        traceback: typing.Optional[TracebackType] = None,\n    ) -> None:\n        async with self._connection_lock:\n            assert self._connection is not None\n            self._connection_counter -= 1\n            if self._connection_counter == 0:\n                await self._connection.release()\n                self._database._connection = None\n\n    async def fetch_all(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.List[Record]:\n        built_query = self._build_query(query, values)\n        async with self._query_lock:\n            return await self._connection.fetch_all(built_query)\n\n    async def fetch_one(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.Optional[Record]:\n        built_query = self._build_query(query, values)\n        async with self._query_lock:\n            return await self._connection.fetch_one(built_query)\n\n    async def fetch_val(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n        column: typing.Any = 0,\n    ) -> typing.Any:\n        built_query = self._build_query(query, values)\n        async with self._query_lock:\n            return await self._connection.fetch_val(built_query, column)\n\n    async def execute(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.Any:\n        built_query = self._build_query(query, values)\n        async with self._query_lock:\n            return await self._connection.execute(built_query)\n\n    async def execute_many(self, query: typing.Union[ClauseElement, str], values: list) -> None:\n        queries = [self._build_query(query, values_set) for values_set in values]\n        async with self._query_lock:\n            await self._connection.execute_many(queries)\n\n    async def iterate(\n        self,\n        query: typing.Union[ClauseElement, str],\n        values: typing.Optional[dict] = None,\n    ) -> typing.AsyncGenerator[typing.Any, None]:\n        built_query = self._build_query(query, values)\n        async with self.transaction():\n            async with self._query_lock:\n                async for record in self._connection.iterate(built_query):\n                    yield record\n\n    def transaction(self, *, force_rollback: bool = False, **kwargs: typing.Any) -> \"Transaction\":\n        def connection_callable() -> Connection:\n            return self\n\n        return Transaction(connection_callable, force_rollback, **kwargs)\n\n    @property\n    def raw_connection(self) -> typing.Any:\n        return self._connection.raw_connection\n\n    @staticmethod\n    def _build_query(\n        query: typing.Union[ClauseElement, str], values: typing.Optional[dict] = None\n    ) -> ClauseElement:\n        if isinstance(query, str):\n            query = text(query)\n\n            return query.bindparams(**values) if values is not None else query\n        elif values:\n            return query.values(**values)  # type: ignore\n\n        return query", "\n\n_CallableType = typing.TypeVar(\"_CallableType\", bound=typing.Callable)\n\n\nclass Transaction:\n    def __init__(\n        self,\n        connection_callable: typing.Callable[[], Connection],\n        force_rollback: bool,\n        **kwargs: typing.Any,\n    ) -> None:\n        self._connection_callable = connection_callable\n        self._force_rollback = force_rollback\n        self._extra_options = kwargs\n\n    @property\n    def _connection(self) -> \"Connection\":\n        # Returns the same connection if called multiple times\n        return self._connection_callable()\n\n    @property\n    def _transaction(self) -> typing.Optional[\"TransactionBackend\"]:\n        transactions = ACTIVE_TRANSACTIONS.get()\n        if transactions is None:\n            return None\n\n        return transactions.get(self, None)\n\n    @_transaction.setter\n    def _transaction(\n        self, transaction: typing.Optional[\"TransactionBackend\"]\n    ) -> typing.Optional[\"TransactionBackend\"]:\n        transactions = ACTIVE_TRANSACTIONS.get()\n        if transactions is None:\n            transactions = weakref.WeakKeyDictionary()\n        else:\n            transactions = transactions.copy()\n\n        if transaction is None:\n            transactions.pop(self, None)\n        else:\n            transactions[self] = transaction\n\n        ACTIVE_TRANSACTIONS.set(transactions)\n        return transactions.get(self, None)\n\n    async def __aenter__(self) -> \"Transaction\":\n        \"\"\"\n        Called when entering `async with database.transaction()`\n        \"\"\"\n        await self.start()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: typing.Optional[typing.Type[BaseException]] = None,\n        exc_value: typing.Optional[BaseException] = None,\n        traceback: typing.Optional[TracebackType] = None,\n    ) -> None:\n        \"\"\"\n        Called when exiting `async with database.transaction()`\n        \"\"\"\n        if exc_type is not None or self._force_rollback:\n            await self.rollback()\n        else:\n            await self.commit()\n\n    def __await__(self) -> typing.Generator[None, None, \"Transaction\"]:\n        \"\"\"\n        Called if using the low-level `transaction = await database.transaction()`\n        \"\"\"\n        return self.start().__await__()\n\n    def __call__(self, func: _CallableType) -> _CallableType:\n        \"\"\"\n        Called if using `@database.transaction()` as a decorator.\n        \"\"\"\n\n        @functools.wraps(func)\n        async def wrapper(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n            async with self:\n                return await func(*args, **kwargs)\n\n        return wrapper  # type: ignore\n\n    async def start(self) -> \"Transaction\":\n        self._transaction = self._connection._connection.transaction()\n\n        async with self._connection._transaction_lock:\n            is_root = not self._connection._transaction_stack\n            await self._connection.__aenter__()\n            await self._transaction.start(is_root=is_root, extra_options=self._extra_options)\n            self._connection._transaction_stack.append(self)\n        return self\n\n    async def commit(self) -> None:\n        async with self._connection._transaction_lock:\n            assert self._connection._transaction_stack[-1] is self\n            self._connection._transaction_stack.pop()\n            assert self._transaction is not None\n            await self._transaction.commit()\n            await self._connection.__aexit__()\n            self._transaction = None\n\n    async def rollback(self) -> None:\n        async with self._connection._transaction_lock:\n            assert self._connection._transaction_stack[-1] is self\n            self._connection._transaction_stack.pop()\n            assert self._transaction is not None\n            await self._transaction.rollback()\n            await self._connection.__aexit__()\n            self._transaction = None", "\n\nclass _EmptyNetloc(str):\n    def __bool__(self) -> bool:\n        return True\n\n\nclass DatabaseURL:\n    def __init__(self, url: typing.Union[str, \"DatabaseURL\"]):\n        if isinstance(url, DatabaseURL):\n            self._url: str = url._url\n        elif isinstance(url, str):\n            self._url = url\n        else:\n            raise TypeError(\n                f\"Invalid type for DatabaseURL. Expected str or DatabaseURL, got {type(url)}\"\n            )\n\n    @property\n    def components(self) -> SplitResult:\n        if not hasattr(self, \"_components\"):\n            self._components = urlsplit(self._url)\n        return self._components\n\n    @property\n    def scheme(self) -> str:\n        return self.components.scheme\n\n    @property\n    def dialect(self) -> str:\n        return self.components.scheme.split(\"+\")[0]\n\n    @property\n    def driver(self) -> str:\n        if \"+\" not in self.components.scheme:\n            return \"\"\n        return self.components.scheme.split(\"+\", 1)[1]\n\n    @property\n    def userinfo(self) -> typing.Optional[bytes]:\n        if self.components.username:\n            info = self.components.username\n            if self.components.password:\n                info += \":\" + self.components.password\n            return info.encode(\"utf-8\")\n        return None\n\n    @property\n    def username(self) -> typing.Optional[str]:\n        if self.components.username is None:\n            return None\n        return unquote(self.components.username)\n\n    @property\n    def password(self) -> typing.Optional[str]:\n        if self.components.password is None:\n            return None\n        return unquote(self.components.password)\n\n    @property\n    def hostname(self) -> typing.Optional[str]:\n        return (\n            self.components.hostname or self.options.get(\"host\") or self.options.get(\"unix_sock\")\n        )\n\n    @property\n    def port(self) -> typing.Optional[int]:\n        return self.components.port\n\n    @property\n    def netloc(self) -> typing.Optional[str]:\n        return self.components.netloc\n\n    @property\n    def database(self) -> str:\n        path = self.components.path\n        if path.startswith(\"/\"):\n            path = path[1:]\n        return unquote(path)\n\n    @property\n    def options(self) -> dict:\n        if not hasattr(self, \"_options\"):\n            self._options = dict(parse_qsl(self.components.query))\n        return self._options\n\n    def replace(self, **kwargs: typing.Any) -> \"DatabaseURL\":\n        if (\n            \"username\" in kwargs\n            or \"password\" in kwargs\n            or \"hostname\" in kwargs\n            or \"port\" in kwargs\n        ):\n            hostname = kwargs.pop(\"hostname\", self.hostname)\n            port = kwargs.pop(\"port\", self.port)\n            username = kwargs.pop(\"username\", self.components.username)\n            password = kwargs.pop(\"password\", self.components.password)\n\n            netloc = hostname\n            if port is not None:\n                netloc += f\":{port}\"\n            if username is not None:\n                userpass = username\n                if password is not None:\n                    userpass += f\":{password}\"\n                netloc = f\"{userpass}@{netloc}\"\n\n            kwargs[\"netloc\"] = netloc\n\n        if \"database\" in kwargs:\n            kwargs[\"path\"] = \"/\" + kwargs.pop(\"database\")\n\n        if \"dialect\" in kwargs or \"driver\" in kwargs:\n            dialect = kwargs.pop(\"dialect\", self.dialect)\n            driver = kwargs.pop(\"driver\", self.driver)\n            kwargs[\"scheme\"] = f\"{dialect}+{driver}\" if driver else dialect\n\n        if not kwargs.get(\"netloc\", self.netloc):\n            # Using an empty string that evaluates as True means we end up\n            # with URLs like `sqlite:///database` instead of `sqlite:/database`\n            kwargs[\"netloc\"] = _EmptyNetloc()\n\n        components = self.components._replace(**kwargs)\n        return self.__class__(components.geturl())\n\n    @property\n    def obscure_password(self) -> str:\n        if self.password:\n            return self.replace(password=\"********\")._url\n        return self._url\n\n    def __str__(self) -> str:\n        return self._url\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({repr(self.obscure_password)})\"\n\n    def __eq__(self, other: typing.Any) -> bool:\n        return str(self) == str(other)", ""]}
{"filename": "databasez/testclient.py", "chunked_list": ["import asyncio\nimport os\nimport typing\nfrom typing import Any\n\nimport nest_asyncio\nimport sqlalchemy as sa\nfrom sqlalchemy.exc import OperationalError, ProgrammingError\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy_utils.functions.database import _set_url_database, _sqlite_file_exists, make_url", "from sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy_utils.functions.database import _set_url_database, _sqlite_file_exists, make_url\nfrom sqlalchemy_utils.functions.orm import quote\n\nfrom databasez import Database, DatabaseURL\n\nnest_asyncio.apply()\n\n\nasync def _get_scalar_result(engine: typing.Any, sql: typing.Any) -> Any:\n    try:\n        async with engine.connect() as conn:\n            return await conn.scalar(sql)\n    except Exception:\n        return False", "\nasync def _get_scalar_result(engine: typing.Any, sql: typing.Any) -> Any:\n    try:\n        async with engine.connect() as conn:\n            return await conn.scalar(sql)\n    except Exception:\n        return False\n\n\nclass DatabaseTestClient(Database):\n    \"\"\"\n    Client used only or unit testing.\n\n    This client simply creates a \"test_\" from the database provided in the\n    connection.\n    \"\"\"\n\n    def __init__(\n        self,\n        url: typing.Union[str, \"DatabaseURL\"],\n        *,\n        force_rollback: bool = False,\n        use_existing: bool = False,\n        drop_database: bool = False,\n        **options: typing.Any,\n    ):\n        url = DatabaseURL(url) if isinstance(url, str) else url\n        test_database_url = url.replace(database=\"test_\" + url.database)\n        self.test_db_url = test_database_url._url\n        self.use_existing = use_existing\n\n        asyncio.get_event_loop().run_until_complete(self.setup())\n\n        super().__init__(test_database_url, force_rollback=force_rollback, **options)\n        self.drop = drop_database\n\n    async def setup(self) -> None:\n        \"\"\"\n        Makes sure the database is created if does not exist or use existing\n        if needed.\n        \"\"\"\n        if not self.use_existing:\n            if await self.is_database_exist():\n                await self.drop_database(self.test_db_url)\n            await self.create_database(self.test_db_url)\n        else:\n            if not self.is_database_exist():\n                await self.create_database(self.test_db_url)\n\n    async def is_database_exist(self) -> Any:\n        \"\"\"\n        Checks if a database exists.\n        \"\"\"\n        return await self.database_exists(self.test_db_url)\n\n    async def database_exists(self, url: str) -> Any:\n        url = make_url(url)\n        database = url.database\n        dialect_name = url.get_dialect().name\n        engine = None\n        try:\n            if dialect_name == \"postgresql\":\n                text = \"SELECT 1 FROM pg_database WHERE datname='%s'\" % database\n                for db in (database, \"postgres\", \"template1\", \"template0\", None):\n                    url = _set_url_database(url, database=db)\n                    engine = create_async_engine(url)\n                    try:\n                        return bool(await _get_scalar_result(engine, sa.text(text)))\n                    except (ProgrammingError, OperationalError):\n                        pass\n                return False\n\n            elif dialect_name == \"mysql\":\n                url = _set_url_database(url, database=None)\n                engine = create_async_engine(url)\n                text = (\n                    \"SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA \"\n                    \"WHERE SCHEMA_NAME = '%s'\" % database\n                )\n                return bool(await _get_scalar_result(engine, sa.text(text)))\n\n            elif dialect_name == \"sqlite\":\n                url = _set_url_database(url, database=None)\n                engine = create_async_engine(url)\n                if database:\n                    return database == \":memory:\" or _sqlite_file_exists(database)\n                else:\n                    # The default SQLAlchemy database is in memory, and :memory: is\n                    # not required, thus we should support that use case.\n                    return True\n            else:\n                text = \"SELECT 1\"\n                try:\n                    engine = create_async_engine(url)\n                    return bool(await _get_scalar_result(engine, sa.text(text)))\n                except (ProgrammingError, OperationalError):\n                    return False\n        finally:\n            if engine:\n                await engine.dispose()\n\n    async def create_database(\n        self, url: str, encoding: str = \"utf8\", template: typing.Any = None\n    ) -> Any:\n        url = make_url(url)\n        database = url.database\n        dialect_name = url.get_dialect().name\n        dialect_driver = url.get_dialect().driver\n\n        if dialect_name == \"postgresql\":\n            url = _set_url_database(url, database=\"postgres\")\n        elif dialect_name == \"mssql\":\n            url = _set_url_database(url, database=\"master\")\n        elif dialect_name == \"cockroachdb\":\n            url = _set_url_database(url, database=\"defaultdb\")\n        elif not dialect_name == \"sqlite\":\n            url = _set_url_database(url, database=None)\n\n        if (dialect_name == \"mssql\" and dialect_driver in {\"pymssql\", \"pyodbc\"}) or (\n            dialect_name == \"postgresql\"\n            and dialect_driver in {\"asyncpg\", \"pg8000\", \"psycopg2\", \"psycopg2cffi\"}\n        ):\n            engine = create_async_engine(url, isolation_level=\"AUTOCOMMIT\")\n        else:\n            engine = create_async_engine(url)\n\n        if dialect_name == \"postgresql\":\n            if not template:\n                template = \"template1\"\n\n            async with engine.begin() as conn:\n                text = \"CREATE DATABASE {} ENCODING '{}' TEMPLATE {}\".format(\n                    quote(conn, database), encoding, quote(conn, template)\n                )\n                await conn.execute(sa.text(text))\n\n        elif dialect_name == \"mysql\":\n            async with engine.begin() as conn:\n                text = \"CREATE DATABASE {} CHARACTER SET = '{}'\".format(\n                    quote(conn, database), encoding\n                )\n                await conn.execute(sa.text(text))\n\n        elif dialect_name == \"sqlite\" and database != \":memory:\":\n            if database:\n                async with engine.begin() as conn:\n                    await conn.execute(sa.text(\"CREATE TABLE DB(id int)\"))\n                    await conn.execute(sa.text(\"DROP TABLE DB\"))\n\n        else:\n            async with engine.begin() as conn:\n                text = f\"CREATE DATABASE {quote(conn, database)}\"\n                await conn.execute(sa.text(text))\n\n        await engine.dispose()\n\n    async def drop_database(self, url: str) -> Any:\n        url = make_url(url)\n        database = url.database\n        dialect_name = url.get_dialect().name\n        dialect_driver = url.get_dialect().driver\n\n        if dialect_name == \"postgresql\":\n            url = _set_url_database(url, database=\"postgres\")\n        elif dialect_name == \"mssql\":\n            url = _set_url_database(url, database=\"master\")\n        elif dialect_name == \"cockroachdb\":\n            url = _set_url_database(url, database=\"defaultdb\")\n        elif not dialect_name == \"sqlite\":\n            url = _set_url_database(url, database=None)\n\n        if dialect_name == \"mssql\" and dialect_driver in {\"pymssql\", \"pyodbc\"}:\n            engine = create_async_engine(url, connect_args={\"autocommit\": True})\n        elif dialect_name == \"postgresql\" and dialect_driver in {\n            \"asyncpg\",\n            \"pg8000\",\n            \"psycopg2\",\n            \"psycopg2cffi\",\n        }:\n            engine = create_async_engine(url, isolation_level=\"AUTOCOMMIT\")\n        else:\n            engine = create_async_engine(url)\n\n        if dialect_name == \"sqlite\" and database != \":memory:\":\n            if database:\n                os.remove(database)\n        elif dialect_name == \"postgresql\":\n            async with engine.begin() as conn:\n                # Disconnect all users from the database we are dropping.\n                version = conn.dialect.server_version_info\n                pid_column = \"pid\" if (version >= (9, 2)) else \"procpid\"\n                text = \"\"\"\n                SELECT pg_terminate_backend(pg_stat_activity.{pid_column})\n                FROM pg_stat_activity\n                WHERE pg_stat_activity.datname = '{database}'\n                AND {pid_column} <> pg_backend_pid();\n                \"\"\".format(\n                    pid_column=pid_column, database=database\n                )\n                await conn.execute(sa.text(text))\n\n                # Drop the database.\n                text = f\"DROP DATABASE {quote(conn, database)}\"\n                await conn.execute(sa.text(text))\n        else:\n            async with engine.begin() as conn:\n                text = f\"DROP DATABASE {quote(conn, database)}\"\n                await conn.execute(sa.text(text))\n\n        await engine.dispose()\n\n    async def disconnect(self) -> None:\n        if self.drop:\n            await self.drop_database(self.test_db_url)\n        await super().disconnect()", "\nclass DatabaseTestClient(Database):\n    \"\"\"\n    Client used only or unit testing.\n\n    This client simply creates a \"test_\" from the database provided in the\n    connection.\n    \"\"\"\n\n    def __init__(\n        self,\n        url: typing.Union[str, \"DatabaseURL\"],\n        *,\n        force_rollback: bool = False,\n        use_existing: bool = False,\n        drop_database: bool = False,\n        **options: typing.Any,\n    ):\n        url = DatabaseURL(url) if isinstance(url, str) else url\n        test_database_url = url.replace(database=\"test_\" + url.database)\n        self.test_db_url = test_database_url._url\n        self.use_existing = use_existing\n\n        asyncio.get_event_loop().run_until_complete(self.setup())\n\n        super().__init__(test_database_url, force_rollback=force_rollback, **options)\n        self.drop = drop_database\n\n    async def setup(self) -> None:\n        \"\"\"\n        Makes sure the database is created if does not exist or use existing\n        if needed.\n        \"\"\"\n        if not self.use_existing:\n            if await self.is_database_exist():\n                await self.drop_database(self.test_db_url)\n            await self.create_database(self.test_db_url)\n        else:\n            if not self.is_database_exist():\n                await self.create_database(self.test_db_url)\n\n    async def is_database_exist(self) -> Any:\n        \"\"\"\n        Checks if a database exists.\n        \"\"\"\n        return await self.database_exists(self.test_db_url)\n\n    async def database_exists(self, url: str) -> Any:\n        url = make_url(url)\n        database = url.database\n        dialect_name = url.get_dialect().name\n        engine = None\n        try:\n            if dialect_name == \"postgresql\":\n                text = \"SELECT 1 FROM pg_database WHERE datname='%s'\" % database\n                for db in (database, \"postgres\", \"template1\", \"template0\", None):\n                    url = _set_url_database(url, database=db)\n                    engine = create_async_engine(url)\n                    try:\n                        return bool(await _get_scalar_result(engine, sa.text(text)))\n                    except (ProgrammingError, OperationalError):\n                        pass\n                return False\n\n            elif dialect_name == \"mysql\":\n                url = _set_url_database(url, database=None)\n                engine = create_async_engine(url)\n                text = (\n                    \"SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA \"\n                    \"WHERE SCHEMA_NAME = '%s'\" % database\n                )\n                return bool(await _get_scalar_result(engine, sa.text(text)))\n\n            elif dialect_name == \"sqlite\":\n                url = _set_url_database(url, database=None)\n                engine = create_async_engine(url)\n                if database:\n                    return database == \":memory:\" or _sqlite_file_exists(database)\n                else:\n                    # The default SQLAlchemy database is in memory, and :memory: is\n                    # not required, thus we should support that use case.\n                    return True\n            else:\n                text = \"SELECT 1\"\n                try:\n                    engine = create_async_engine(url)\n                    return bool(await _get_scalar_result(engine, sa.text(text)))\n                except (ProgrammingError, OperationalError):\n                    return False\n        finally:\n            if engine:\n                await engine.dispose()\n\n    async def create_database(\n        self, url: str, encoding: str = \"utf8\", template: typing.Any = None\n    ) -> Any:\n        url = make_url(url)\n        database = url.database\n        dialect_name = url.get_dialect().name\n        dialect_driver = url.get_dialect().driver\n\n        if dialect_name == \"postgresql\":\n            url = _set_url_database(url, database=\"postgres\")\n        elif dialect_name == \"mssql\":\n            url = _set_url_database(url, database=\"master\")\n        elif dialect_name == \"cockroachdb\":\n            url = _set_url_database(url, database=\"defaultdb\")\n        elif not dialect_name == \"sqlite\":\n            url = _set_url_database(url, database=None)\n\n        if (dialect_name == \"mssql\" and dialect_driver in {\"pymssql\", \"pyodbc\"}) or (\n            dialect_name == \"postgresql\"\n            and dialect_driver in {\"asyncpg\", \"pg8000\", \"psycopg2\", \"psycopg2cffi\"}\n        ):\n            engine = create_async_engine(url, isolation_level=\"AUTOCOMMIT\")\n        else:\n            engine = create_async_engine(url)\n\n        if dialect_name == \"postgresql\":\n            if not template:\n                template = \"template1\"\n\n            async with engine.begin() as conn:\n                text = \"CREATE DATABASE {} ENCODING '{}' TEMPLATE {}\".format(\n                    quote(conn, database), encoding, quote(conn, template)\n                )\n                await conn.execute(sa.text(text))\n\n        elif dialect_name == \"mysql\":\n            async with engine.begin() as conn:\n                text = \"CREATE DATABASE {} CHARACTER SET = '{}'\".format(\n                    quote(conn, database), encoding\n                )\n                await conn.execute(sa.text(text))\n\n        elif dialect_name == \"sqlite\" and database != \":memory:\":\n            if database:\n                async with engine.begin() as conn:\n                    await conn.execute(sa.text(\"CREATE TABLE DB(id int)\"))\n                    await conn.execute(sa.text(\"DROP TABLE DB\"))\n\n        else:\n            async with engine.begin() as conn:\n                text = f\"CREATE DATABASE {quote(conn, database)}\"\n                await conn.execute(sa.text(text))\n\n        await engine.dispose()\n\n    async def drop_database(self, url: str) -> Any:\n        url = make_url(url)\n        database = url.database\n        dialect_name = url.get_dialect().name\n        dialect_driver = url.get_dialect().driver\n\n        if dialect_name == \"postgresql\":\n            url = _set_url_database(url, database=\"postgres\")\n        elif dialect_name == \"mssql\":\n            url = _set_url_database(url, database=\"master\")\n        elif dialect_name == \"cockroachdb\":\n            url = _set_url_database(url, database=\"defaultdb\")\n        elif not dialect_name == \"sqlite\":\n            url = _set_url_database(url, database=None)\n\n        if dialect_name == \"mssql\" and dialect_driver in {\"pymssql\", \"pyodbc\"}:\n            engine = create_async_engine(url, connect_args={\"autocommit\": True})\n        elif dialect_name == \"postgresql\" and dialect_driver in {\n            \"asyncpg\",\n            \"pg8000\",\n            \"psycopg2\",\n            \"psycopg2cffi\",\n        }:\n            engine = create_async_engine(url, isolation_level=\"AUTOCOMMIT\")\n        else:\n            engine = create_async_engine(url)\n\n        if dialect_name == \"sqlite\" and database != \":memory:\":\n            if database:\n                os.remove(database)\n        elif dialect_name == \"postgresql\":\n            async with engine.begin() as conn:\n                # Disconnect all users from the database we are dropping.\n                version = conn.dialect.server_version_info\n                pid_column = \"pid\" if (version >= (9, 2)) else \"procpid\"\n                text = \"\"\"\n                SELECT pg_terminate_backend(pg_stat_activity.{pid_column})\n                FROM pg_stat_activity\n                WHERE pg_stat_activity.datname = '{database}'\n                AND {pid_column} <> pg_backend_pid();\n                \"\"\".format(\n                    pid_column=pid_column, database=database\n                )\n                await conn.execute(sa.text(text))\n\n                # Drop the database.\n                text = f\"DROP DATABASE {quote(conn, database)}\"\n                await conn.execute(sa.text(text))\n        else:\n            async with engine.begin() as conn:\n                text = f\"DROP DATABASE {quote(conn, database)}\"\n                await conn.execute(sa.text(text))\n\n        await engine.dispose()\n\n    async def disconnect(self) -> None:\n        if self.drop:\n            await self.drop_database(self.test_db_url)\n        await super().disconnect()", ""]}
{"filename": "databasez/interfaces.py", "chunked_list": ["import typing\nfrom collections.abc import Sequence\n\nfrom sqlalchemy.sql import ClauseElement\n\n\nclass DatabaseBackend:\n    async def connect(self) -> None:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def disconnect(self) -> None:\n        raise NotImplementedError()  # pragma: no cover\n\n    def connection(self) -> \"ConnectionBackend\":\n        raise NotImplementedError()  # pragma: no cover", "\n\nclass ConnectionBackend:\n    async def acquire(self) -> None:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def release(self) -> None:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def fetch_all(self, query: ClauseElement) -> typing.List[\"Record\"]:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def fetch_one(self, query: ClauseElement) -> typing.Optional[\"Record\"]:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def fetch_val(self, query: ClauseElement, column: typing.Any = 0) -> typing.Any:\n        row = await self.fetch_one(query)\n        return None if row is None else row[column]\n\n    async def execute(self, query: ClauseElement) -> typing.Any:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def execute_many(self, queries: typing.List[ClauseElement]) -> None:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def iterate(self, query: ClauseElement) -> typing.AsyncGenerator[typing.Mapping, None]:\n        raise NotImplementedError()  # pragma: no cover\n        # mypy needs async iterators to contain a `yield`\n        # https://github.com/python/mypy/issues/5385#issuecomment-407281656\n        yield True  # pragma: no cover\n\n    def transaction(self) -> \"TransactionBackend\":\n        raise NotImplementedError()  # pragma: no cover\n\n    @property\n    def raw_connection(self) -> typing.Any:\n        raise NotImplementedError()  # pragma: no cover", "\n\nclass TransactionBackend:\n    async def start(\n        self, is_root: bool, extra_options: typing.Dict[typing.Any, typing.Any]\n    ) -> None:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def commit(self) -> None:\n        raise NotImplementedError()  # pragma: no cover\n\n    async def rollback(self) -> None:\n        raise NotImplementedError()  # pragma: no cover", "\n\nclass Record(Sequence):\n    @property\n    def _mapping(self) -> typing.Mapping:\n        raise NotImplementedError()  # pragma: no cover\n\n    def __getitem__(self, key: typing.Any) -> typing.Any:\n        raise NotImplementedError()  # pragma: no cover\n", ""]}
{"filename": "databasez/backends/sqlite.py", "chunked_list": ["import logging\nimport typing\nimport uuid\n\nimport aiosqlite\nfrom sqlalchemy.dialects.sqlite import pysqlite\nfrom sqlalchemy.engine.cursor import CursorResultMetaData\nfrom sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement\nfrom sqlalchemy.sql.ddl import DDLElement", "from sqlalchemy.sql import ClauseElement\nfrom sqlalchemy.sql.ddl import DDLElement\n\nfrom databasez.backends.common.records import Record, Row, create_column_maps\nfrom databasez.core import LOG_EXTRA, DatabaseURL\nfrom databasez.interfaces import ConnectionBackend, DatabaseBackend, TransactionBackend\n\nlogger = logging.getLogger(\"databasez\")\n\n\nclass SQLiteBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = pysqlite.dialect(paramstyle=\"qmark\")\n        # aiosqlite does not support decimals\n        self._dialect.supports_native_decimal = False\n        self._pool = SQLitePool(self._database_url, **self._options)\n\n    async def connect(self) -> None:\n        ...\n\n    async def disconnect(self) -> None:\n        ...\n\n    def connection(self) -> \"SQLiteConnection\":\n        return SQLiteConnection(self._pool, self._dialect)", "\n\nclass SQLiteBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = pysqlite.dialect(paramstyle=\"qmark\")\n        # aiosqlite does not support decimals\n        self._dialect.supports_native_decimal = False\n        self._pool = SQLitePool(self._database_url, **self._options)\n\n    async def connect(self) -> None:\n        ...\n\n    async def disconnect(self) -> None:\n        ...\n\n    def connection(self) -> \"SQLiteConnection\":\n        return SQLiteConnection(self._pool, self._dialect)", "\n\nclass SQLitePool:\n    def __init__(self, url: DatabaseURL, **options: typing.Any) -> None:\n        self._url = url\n        self._options = options\n\n    async def acquire(self) -> aiosqlite.Connection:\n        connection = aiosqlite.connect(\n            database=self._url.database, isolation_level=None, **self._options\n        )\n        await connection.__aenter__()\n        return connection\n\n    async def release(self, connection: aiosqlite.Connection) -> None:\n        await connection.__aexit__(None, None, None)", "\n\nclass CompilationContext:\n    def __init__(self, context: ExecutionContext):\n        self.context = context\n\n\nclass SQLiteConnection(ConnectionBackend):\n    def __init__(self, pool: SQLitePool, dialect: Dialect):\n        self._pool = pool\n        self._dialect = dialect\n        self._connection: typing.Optional[aiosqlite.Connection] = None\n\n    async def acquire(self) -> None:\n        assert self._connection is None, \"Connection is already acquired\"\n        self._connection = await self._pool.acquire()\n\n    async def release(self) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        connection, self._connection = self._connection, None\n        await self._pool.release(connection)\n\n    async def fetch_all(self, query: ClauseElement) -> typing.List[Record]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n\n        async with self._connection.execute(query_str, args) as cursor:\n            rows = await cursor.fetchall()\n            metadata = CursorResultMetaData(context, cursor.description)\n            rows = [\n                Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                for row in rows\n            ]\n            return [Record(row, result_columns, dialect, column_maps) for row in rows]\n\n    async def fetch_one(self, query: ClauseElement) -> typing.Optional[Record]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n\n        async with self._connection.execute(query_str, args) as cursor:\n            row = await cursor.fetchone()\n            if row is None:\n                return None\n            metadata = CursorResultMetaData(context, cursor.description)\n            row = Row(\n                metadata,\n                metadata._effective_processors,\n                metadata._key_to_index,\n                row,\n            )\n            return Record(row, result_columns, dialect, column_maps)\n\n    async def execute(self, query: ClauseElement) -> typing.Any:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        async with self._connection.cursor() as cursor:\n            await cursor.execute(query_str, args)\n            if cursor.lastrowid == 0:\n                return cursor.rowcount\n            return cursor.lastrowid\n\n    async def execute_many(self, queries: typing.List[ClauseElement]) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        for single_query in queries:\n            await self.execute(single_query)\n\n    async def iterate(self, query: ClauseElement) -> typing.AsyncGenerator[typing.Any, None]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n\n        async with self._connection.execute(query_str, args) as cursor:\n            metadata = CursorResultMetaData(context, cursor.description)\n            async for row in cursor:\n                record = Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                yield Record(record, result_columns, dialect, column_maps)\n\n    def transaction(self) -> TransactionBackend:\n        return SQLiteTransaction(self)\n\n    def _compile(self, query: ClauseElement) -> typing.Tuple[str, list, tuple]:\n        compiled = query.compile(\n            dialect=self._dialect, compile_kwargs={\"render_postcompile\": True}\n        )\n        execution_context = self._dialect.execution_ctx_cls()\n        execution_context.dialect = self._dialect\n\n        args = []\n        result_map = None\n\n        if not isinstance(query, DDLElement):\n            compiled_params = sorted(compiled.params.items())\n\n            params = compiled.construct_params()\n            for key in compiled.positiontup:\n                raw_val = params[key]\n                if key in compiled._bind_processors:\n                    val = compiled._bind_processors[key](raw_val)\n                else:\n                    val = raw_val\n                args.append(val)\n\n            execution_context.result_column_struct = (\n                compiled._result_columns,\n                compiled._ordered_columns,\n                compiled._textual_ordered_columns,\n                compiled._ad_hoc_textual,\n                compiled._loose_column_name_matching,\n            )\n\n            mapping = {key: \"$\" + str(i) for i, (key, _) in enumerate(compiled_params, start=1)}\n            compiled_query = compiled.string % mapping\n            result_map = compiled._result_columns\n\n        else:\n            compiled_query = compiled.string\n\n        query_message = compiled_query.replace(\" \\n\", \" \").replace(\"\\n\", \" \")\n        logger.debug(\"Query: %s Args: %s\", query_message, repr(tuple(args)), extra=LOG_EXTRA)\n        return compiled.string, args, result_map, CompilationContext(execution_context)\n\n    @property\n    def raw_connection(self) -> aiosqlite.core.Connection:\n        assert self._connection is not None, \"Connection is not acquired\"\n        return self._connection", "\n\nclass SQLiteTransaction(TransactionBackend):\n    def __init__(self, connection: SQLiteConnection):\n        self._connection = connection\n        self._is_root = False\n        self._savepoint_name = \"\"\n\n    async def start(\n        self, is_root: bool, extra_options: typing.Dict[typing.Any, typing.Any]\n    ) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        self._is_root = is_root\n        if self._is_root:\n            async with self._connection._connection.execute(\"BEGIN\") as cursor:\n                await cursor.close()\n        else:\n            id = str(uuid.uuid4()).replace(\"-\", \"_\")\n            self._savepoint_name = f\"STARLETTE_SAVEPOINT_{id}\"\n            async with self._connection._connection.execute(\n                f\"SAVEPOINT {self._savepoint_name}\"\n            ) as cursor:\n                await cursor.close()\n\n    async def commit(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        if self._is_root:\n            async with self._connection._connection.execute(\"COMMIT\") as cursor:\n                await cursor.close()\n        else:\n            async with self._connection._connection.execute(\n                f\"RELEASE SAVEPOINT {self._savepoint_name}\"\n            ) as cursor:\n                await cursor.close()\n\n    async def rollback(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        if self._is_root:\n            async with self._connection._connection.execute(\"ROLLBACK\") as cursor:\n                await cursor.close()\n        else:\n            async with self._connection._connection.execute(\n                f\"ROLLBACK TO SAVEPOINT {self._savepoint_name}\"\n            ) as cursor:\n                await cursor.close()", ""]}
{"filename": "databasez/backends/postgres.py", "chunked_list": ["import logging\nimport typing\n\nimport asyncpg\nfrom sqlalchemy.engine.interfaces import Dialect\nfrom sqlalchemy.sql import ClauseElement\nfrom sqlalchemy.sql.ddl import DDLElement\n\nfrom databasez.backends.common.records import Record, create_column_maps\nfrom databasez.backends.dialects.psycopg import dialect as psycopg_dialect", "from databasez.backends.common.records import Record, create_column_maps\nfrom databasez.backends.dialects.psycopg import dialect as psycopg_dialect\nfrom databasez.core import LOG_EXTRA, DatabaseURL\nfrom databasez.interfaces import ConnectionBackend, DatabaseBackend\nfrom databasez.interfaces import Record as RecordInterface\nfrom databasez.interfaces import TransactionBackend\n\nlogger = logging.getLogger(\"databasez\")\n\n\nclass PostgresBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = self._get_dialect()\n        self._pool = None\n\n    def _get_dialect(self) -> Dialect:\n        dialect = psycopg_dialect(paramstyle=\"pyformat\")\n\n        dialect.implicit_returning = True\n        dialect.supports_native_enum = True\n        dialect.supports_smallserial = True  # 9.2+\n        dialect._backslash_escapes = False\n        dialect.supports_sane_multi_rowcount = True  # psycopg 2.0.9+\n        dialect._has_native_hstore = True\n        dialect.supports_native_decimal = True\n\n        return dialect\n\n    def _get_connection_kwargs(self) -> dict:\n        url_options = self._database_url.options\n\n        kwargs: typing.Dict[str, typing.Any] = {}\n        min_size = url_options.get(\"min_size\")\n        max_size = url_options.get(\"max_size\")\n        ssl = url_options.get(\"ssl\")\n\n        if min_size is not None:\n            kwargs[\"min_size\"] = int(min_size)\n        if max_size is not None:\n            kwargs[\"max_size\"] = int(max_size)\n        if ssl is not None:\n            kwargs[\"ssl\"] = {\"true\": True, \"false\": False}[ssl.lower()]\n\n        kwargs.update(self._options)\n\n        return kwargs\n\n    async def connect(self) -> None:\n        assert self._pool is None, \"DatabaseBackend is already running\"\n        kwargs = {\n            \"host\": self._database_url.hostname,\n            \"port\": self._database_url.port,\n            \"user\": self._database_url.username,\n            \"password\": self._database_url.password,\n            \"database\": self._database_url.database,\n        }\n        kwargs.update(self._get_connection_kwargs())\n        self._pool = await asyncpg.create_pool(**kwargs)\n\n    async def disconnect(self) -> None:\n        assert self._pool is not None, \"DatabaseBackend is not running\"\n        await self._pool.close()\n        self._pool = None\n\n    def connection(self) -> \"PostgresConnection\":\n        return PostgresConnection(self, self._dialect)", "\n\nclass PostgresBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = self._get_dialect()\n        self._pool = None\n\n    def _get_dialect(self) -> Dialect:\n        dialect = psycopg_dialect(paramstyle=\"pyformat\")\n\n        dialect.implicit_returning = True\n        dialect.supports_native_enum = True\n        dialect.supports_smallserial = True  # 9.2+\n        dialect._backslash_escapes = False\n        dialect.supports_sane_multi_rowcount = True  # psycopg 2.0.9+\n        dialect._has_native_hstore = True\n        dialect.supports_native_decimal = True\n\n        return dialect\n\n    def _get_connection_kwargs(self) -> dict:\n        url_options = self._database_url.options\n\n        kwargs: typing.Dict[str, typing.Any] = {}\n        min_size = url_options.get(\"min_size\")\n        max_size = url_options.get(\"max_size\")\n        ssl = url_options.get(\"ssl\")\n\n        if min_size is not None:\n            kwargs[\"min_size\"] = int(min_size)\n        if max_size is not None:\n            kwargs[\"max_size\"] = int(max_size)\n        if ssl is not None:\n            kwargs[\"ssl\"] = {\"true\": True, \"false\": False}[ssl.lower()]\n\n        kwargs.update(self._options)\n\n        return kwargs\n\n    async def connect(self) -> None:\n        assert self._pool is None, \"DatabaseBackend is already running\"\n        kwargs = {\n            \"host\": self._database_url.hostname,\n            \"port\": self._database_url.port,\n            \"user\": self._database_url.username,\n            \"password\": self._database_url.password,\n            \"database\": self._database_url.database,\n        }\n        kwargs.update(self._get_connection_kwargs())\n        self._pool = await asyncpg.create_pool(**kwargs)\n\n    async def disconnect(self) -> None:\n        assert self._pool is not None, \"DatabaseBackend is not running\"\n        await self._pool.close()\n        self._pool = None\n\n    def connection(self) -> \"PostgresConnection\":\n        return PostgresConnection(self, self._dialect)", "\n\nclass PostgresConnection(ConnectionBackend):\n    def __init__(self, database: PostgresBackend, dialect: Dialect):\n        self._database = database\n        self._dialect = dialect\n        self._connection: typing.Optional[asyncpg.connection.Connection] = None\n\n    async def acquire(self) -> None:\n        assert self._connection is None, \"Connection is already acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        self._connection = await self._database._pool.acquire()\n\n    async def release(self) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        connection, self._connection = self._connection, None\n        self._connection = await self._database._pool.release(connection)\n\n    async def fetch_all(self, query: ClauseElement) -> typing.List[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns = self._compile(query)\n        rows = await self._connection.fetch(query_str, *args)\n        dialect = self._dialect\n        column_maps = create_column_maps(result_columns)\n        return [Record(row, result_columns, dialect, column_maps) for row in rows]\n\n    async def fetch_one(self, query: ClauseElement) -> typing.Optional[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns = self._compile(query)\n        row = await self._connection.fetchrow(query_str, *args)\n        if row is None:\n            return None\n        return Record(\n            row,\n            result_columns,\n            self._dialect,\n            create_column_maps(result_columns),\n        )\n\n    async def fetch_val(self, query: ClauseElement, column: typing.Any = 0) -> typing.Any:\n        # we are not calling self._connection.fetchval here because\n        # it does not convert all the types, e.g. JSON stays string\n        # instead of an object\n        # see also:\n        # https://github.com/dymmond/databasez/pull/131\n        # https://github.com/dymmond/databasez/pull/132\n        # https://github.com/dymmond/databasez/pull/246\n        row = await self.fetch_one(query)\n        if row is None:\n            return None\n        return row[column]\n\n    async def execute(self, query: ClauseElement) -> typing.Any:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, _ = self._compile(query)\n        return await self._connection.fetchval(query_str, *args)\n\n    async def execute_many(self, queries: typing.List[ClauseElement]) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        # asyncpg uses prepared statements under the hood, so we just\n        # loop through multiple executes here, which should all end up\n        # using the same prepared statement.\n        for single_query in queries:\n            single_query, args, _ = self._compile(single_query)\n            await self._connection.execute(single_query, *args)\n\n    async def iterate(self, query: ClauseElement) -> typing.AsyncGenerator[typing.Any, None]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        async for row in self._connection.cursor(query_str, *args):\n            yield Record(row, result_columns, self._dialect, column_maps)\n\n    def transaction(self) -> TransactionBackend:\n        return PostgresTransaction(connection=self)\n\n    def _compile(self, query: ClauseElement) -> typing.Tuple[str, list, tuple]:\n        compiled = query.compile(\n            dialect=self._dialect, compile_kwargs={\"render_postcompile\": True}\n        )\n\n        if not isinstance(query, DDLElement):\n            compiled_params = sorted(compiled.params.items())\n\n            mapping = {key: \"$\" + str(i) for i, (key, _) in enumerate(compiled_params, start=1)}\n            compiled_query = compiled.string % mapping\n\n            processors = compiled._bind_processors\n            args = [\n                processors[key](val) if key in processors else val for key, val in compiled_params\n            ]\n            result_map = compiled._result_columns\n        else:\n            compiled_query = compiled.string\n            args = []\n            result_map = None\n\n        query_message = compiled_query.replace(\" \\n\", \" \").replace(\"\\n\", \" \")\n        logger.debug(\"Query: %s Args: %s\", query_message, repr(tuple(args)), extra=LOG_EXTRA)\n        return compiled_query, args, result_map\n\n    @property\n    def raw_connection(self) -> asyncpg.connection.Connection:\n        assert self._connection is not None, \"Connection is not acquired\"\n        return self._connection", "\n\nclass PostgresTransaction(TransactionBackend):\n    def __init__(self, connection: PostgresConnection):\n        self._connection = connection\n        self._transaction: typing.Optional[asyncpg.transaction.Transaction] = None\n\n    async def start(\n        self, is_root: bool, extra_options: typing.Dict[typing.Any, typing.Any]\n    ) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        self._transaction = self._connection._connection.transaction(**extra_options)\n        await self._transaction.start()\n\n    async def commit(self) -> None:\n        assert self._transaction is not None\n        await self._transaction.commit()\n\n    async def rollback(self) -> None:\n        assert self._transaction is not None\n        await self._transaction.rollback()", ""]}
{"filename": "databasez/backends/mysql.py", "chunked_list": ["import getpass\nimport logging\nimport typing\nimport uuid\n\nimport aiomysql\nfrom sqlalchemy.dialects.mysql import pymysql\nfrom sqlalchemy.engine.cursor import CursorResultMetaData\nfrom sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement", "from sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement\nfrom sqlalchemy.sql.ddl import DDLElement\n\nfrom databasez.backends.common.records import Record, Row, create_column_maps\nfrom databasez.core import LOG_EXTRA, DatabaseURL\nfrom databasez.interfaces import ConnectionBackend, DatabaseBackend\nfrom databasez.interfaces import Record as RecordInterface\nfrom databasez.interfaces import TransactionBackend\n", "from databasez.interfaces import TransactionBackend\n\nlogger = logging.getLogger(\"databasez\")\n\n\nclass MySQLBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = pymysql.dialect(paramstyle=\"pyformat\")\n        self._dialect.supports_native_decimal = True\n        self._pool = None\n\n    def _get_connection_kwargs(self) -> dict:\n        url_options = self._database_url.options\n\n        kwargs = {}\n        min_size = url_options.get(\"min_size\")\n        max_size = url_options.get(\"max_size\")\n        pool_recycle = url_options.get(\"pool_recycle\")\n        unix_socket = url_options.get(\"unix_socket\")\n        ssl = url_options.get(\"ssl\")\n\n        if min_size is not None:\n            kwargs[\"minsize\"] = int(min_size)\n        if max_size is not None:\n            kwargs[\"maxsize\"] = int(max_size)\n        if unix_socket is not None:\n            kwargs[\"unix_socket\"] = unix_socket\n        if pool_recycle is not None:\n            kwargs[\"pool_recycle\"] = int(pool_recycle)\n        if ssl is not None:\n            kwargs[\"ssl\"] = {\"true\": True, \"false\": False}[ssl.lower()]\n\n        for key, value in self._options.items():\n            # Coerce 'min_size' and 'max_size' for consistency.\n            if key == \"min_size\":\n                key = \"minsize\"\n            elif key == \"max_size\":\n                key = \"maxsize\"\n            kwargs[key] = value\n\n        return kwargs\n\n    async def connect(self) -> None:\n        assert self._pool is None, \"DatabaseBackend is already running\"\n        kwargs = self._get_connection_kwargs()\n        self._pool = await aiomysql.create_pool(\n            host=self._database_url.hostname,\n            port=self._database_url.port or 3306,\n            user=self._database_url.username or getpass.getuser(),\n            password=self._database_url.password,\n            db=self._database_url.database,\n            autocommit=True,\n            **kwargs,\n        )\n\n    async def disconnect(self) -> None:\n        assert self._pool is not None, \"DatabaseBackend is not running\"\n        self._pool.close()\n        pool, self._pool = self._pool, None\n        await pool.wait_closed()\n\n    def connection(self) -> \"MySQLConnection\":\n        return MySQLConnection(self, self._dialect)", "\n\nclass CompilationContext:\n    def __init__(self, context: ExecutionContext):\n        self.context = context\n\n\nclass MySQLConnection(ConnectionBackend):\n    def __init__(self, database: MySQLBackend, dialect: Dialect):\n        self._database = database\n        self._dialect = dialect\n        self._connection: typing.Optional[aiomysql.Connection] = None\n\n    async def acquire(self) -> None:\n        assert self._connection is None, \"Connection is already acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        self._connection = await self._database._pool.acquire()\n\n    async def release(self) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        await self._database._pool.release(self._connection)\n        self._connection = None\n\n    async def fetch_all(self, query: ClauseElement) -> typing.List[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            rows = await cursor.fetchall()\n            metadata = CursorResultMetaData(context, cursor.description)\n            rows = [\n                Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                for row in rows\n            ]\n            return [Record(row, result_columns, dialect, column_maps) for row in rows]\n        finally:\n            await cursor.close()\n\n    async def fetch_one(self, query: ClauseElement) -> typing.Optional[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            row = await cursor.fetchone()\n            if row is None:\n                return None\n            metadata = CursorResultMetaData(context, cursor.description)\n            row = Row(\n                metadata,\n                metadata._effective_processors,\n                metadata._key_to_index,\n                row,\n            )\n            return Record(row, result_columns, dialect, column_maps)\n        finally:\n            await cursor.close()\n\n    async def execute(self, query: ClauseElement) -> typing.Any:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, _, _ = self._compile(query)\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            if cursor.lastrowid == 0:\n                return cursor.rowcount\n            return cursor.lastrowid\n        finally:\n            await cursor.close()\n\n    async def execute_many(self, queries: typing.List[ClauseElement]) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        cursor = await self._connection.cursor()\n        try:\n            for single_query in queries:\n                single_query, args, _, _ = self._compile(single_query)\n                await cursor.execute(single_query, args)\n        finally:\n            await cursor.close()\n\n    async def iterate(self, query: ClauseElement) -> typing.AsyncGenerator[typing.Any, None]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            metadata = CursorResultMetaData(context, cursor.description)\n            async for row in cursor:\n                record = Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                yield Record(record, result_columns, dialect, column_maps)\n        finally:\n            await cursor.close()\n\n    def transaction(self) -> TransactionBackend:\n        return MySQLTransaction(self)\n\n    def _compile(self, query: ClauseElement) -> typing.Tuple[str, list, tuple]:\n        compiled = query.compile(\n            dialect=self._dialect, compile_kwargs={\"render_postcompile\": True}\n        )\n        execution_context = self._dialect.execution_ctx_cls()\n        execution_context.dialect = self._dialect\n\n        if not isinstance(query, DDLElement):\n            compiled_params = sorted(compiled.params.items())\n\n            args = compiled.construct_params()\n            for key, val in args.items():\n                if key in compiled._bind_processors:\n                    args[key] = compiled._bind_processors[key](val)\n\n            execution_context.result_column_struct = (\n                compiled._result_columns,\n                compiled._ordered_columns,\n                compiled._textual_ordered_columns,\n                compiled._ad_hoc_textual,\n                compiled._loose_column_name_matching,\n            )\n\n            mapping = {key: \"$\" + str(i) for i, (key, _) in enumerate(compiled_params, start=1)}\n            compiled_query = compiled.string % mapping\n            result_map = compiled._result_columns\n\n        else:\n            args = {}\n            result_map = None\n            compiled_query = compiled.string\n\n        query_message = compiled_query.replace(\" \\n\", \" \").replace(\"\\n\", \" \")\n        logger.debug(\"Query: %s Args: %s\", query_message, repr(tuple(args)), extra=LOG_EXTRA)\n        return compiled.string, args, result_map, CompilationContext(execution_context)\n\n    @property\n    def raw_connection(self) -> aiomysql.connection.Connection:\n        assert self._connection is not None, \"Connection is not acquired\"\n        return self._connection", "\n\nclass MySQLTransaction(TransactionBackend):\n    def __init__(self, connection: MySQLConnection):\n        self._connection = connection\n        self._is_root = False\n        self._savepoint_name = \"\"\n\n    async def start(\n        self, is_root: bool, extra_options: typing.Dict[typing.Any, typing.Any]\n    ) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        self._is_root = is_root\n        if self._is_root:\n            await self._connection._connection.begin()\n        else:\n            id = str(uuid.uuid4()).replace(\"-\", \"_\")\n            self._savepoint_name = f\"STARLETTE_SAVEPOINT_{id}\"\n            cursor = await self._connection._connection.cursor()\n            try:\n                await cursor.execute(f\"SAVEPOINT {self._savepoint_name}\")\n            finally:\n                await cursor.close()\n\n    async def commit(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        if self._is_root:\n            await self._connection._connection.commit()\n        else:\n            cursor = await self._connection._connection.cursor()\n            try:\n                await cursor.execute(f\"RELEASE SAVEPOINT {self._savepoint_name}\")\n            finally:\n                await cursor.close()\n\n    async def rollback(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        if self._is_root:\n            await self._connection._connection.rollback()\n        else:\n            cursor = await self._connection._connection.cursor()\n            try:\n                await cursor.execute(f\"ROLLBACK TO SAVEPOINT {self._savepoint_name}\")\n            finally:\n                await cursor.close()", ""]}
{"filename": "databasez/backends/asyncmy.py", "chunked_list": ["import getpass\nimport logging\nimport typing\nimport uuid\n\nimport asyncmy\nfrom sqlalchemy.dialects.mysql import pymysql\nfrom sqlalchemy.engine.cursor import CursorResultMetaData\nfrom sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement", "from sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement\nfrom sqlalchemy.sql.ddl import DDLElement\n\nfrom databasez.backends.common.records import Record, Row, create_column_maps\nfrom databasez.core import LOG_EXTRA, DatabaseURL\nfrom databasez.interfaces import ConnectionBackend, DatabaseBackend\nfrom databasez.interfaces import Record as RecordInterface\nfrom databasez.interfaces import TransactionBackend\n", "from databasez.interfaces import TransactionBackend\n\nlogger = logging.getLogger(\"databasez\")\n\n\nclass AsyncMyBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = pymysql.dialect(paramstyle=\"pyformat\")\n        self._dialect.supports_native_decimal = True\n        self._pool = None\n\n    def _get_connection_kwargs(self) -> dict:\n        url_options = self._database_url.options\n\n        kwargs = {}\n        min_size = url_options.get(\"min_size\")\n        max_size = url_options.get(\"max_size\")\n        pool_recycle = url_options.get(\"pool_recycle\")\n        unix_socket = url_options.get(\"unix_socket\")\n        ssl = url_options.get(\"ssl\")\n\n        if min_size is not None:\n            kwargs[\"minsize\"] = int(min_size)\n        if max_size is not None:\n            kwargs[\"maxsize\"] = int(max_size)\n        if unix_socket is not None:\n            kwargs[\"unix_socket\"] = unix_socket\n        if pool_recycle is not None:\n            kwargs[\"pool_recycle\"] = int(pool_recycle)\n        if ssl is not None:\n            kwargs[\"ssl\"] = {\"true\": True, \"false\": False}[ssl.lower()]\n\n        for key, value in self._options.items():\n            # Coerce 'min_size' and 'max_size' for consistency.\n            if key == \"min_size\":\n                key = \"minsize\"\n            elif key == \"max_size\":\n                key = \"maxsize\"\n            kwargs[key] = value\n\n        return kwargs\n\n    async def connect(self) -> None:\n        assert self._pool is None, \"DatabaseBackend is already running\"\n        kwargs = self._get_connection_kwargs()\n        self._pool = await asyncmy.create_pool(\n            host=self._database_url.hostname,\n            port=self._database_url.port or 3306,\n            user=self._database_url.username or getpass.getuser(),\n            password=self._database_url.password,\n            db=self._database_url.database,\n            autocommit=True,\n            **kwargs,\n        )\n\n    async def disconnect(self) -> None:\n        assert self._pool is not None, \"DatabaseBackend is not running\"\n        self._pool.close()\n        pool, self._pool = self._pool, None\n        await pool.wait_closed()\n\n    def connection(self) -> \"AsyncMyConnection\":\n        return AsyncMyConnection(self, self._dialect)", "\n\nclass CompilationContext:\n    def __init__(self, context: ExecutionContext):\n        self.context = context\n\n\nclass AsyncMyConnection(ConnectionBackend):\n    def __init__(self, database: AsyncMyBackend, dialect: Dialect):\n        self._database = database\n        self._dialect = dialect\n        self._connection: typing.Optional[asyncmy.Connection] = None\n\n    async def acquire(self) -> None:\n        assert self._connection is None, \"Connection is already acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        self._connection = await self._database._pool.acquire()\n\n    async def release(self) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        await self._database._pool.release(self._connection)\n        self._connection = None\n\n    async def fetch_all(self, query: ClauseElement) -> typing.List[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n\n        async with self._connection.cursor() as cursor:\n            try:\n                await cursor.execute(query_str, args)\n                rows = await cursor.fetchall()\n                metadata = CursorResultMetaData(context, cursor.description)\n                rows = [\n                    Row(\n                        metadata,\n                        metadata._effective_processors,\n                        metadata._key_to_index,\n                        row,\n                    )\n                    for row in rows\n                ]\n                return [Record(row, result_columns, dialect, column_maps) for row in rows]\n            finally:\n                await cursor.close()\n\n    async def fetch_one(self, query: ClauseElement) -> typing.Optional[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        async with self._connection.cursor() as cursor:\n            try:\n                await cursor.execute(query_str, args)\n                row = await cursor.fetchone()\n                if row is None:\n                    return None\n                metadata = CursorResultMetaData(context, cursor.description)\n                row = Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                return Record(row, result_columns, dialect, column_maps)\n            finally:\n                await cursor.close()\n\n    async def execute(self, query: ClauseElement) -> typing.Any:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, _, _ = self._compile(query)\n        async with self._connection.cursor() as cursor:\n            try:\n                await cursor.execute(query_str, args)\n                if cursor.lastrowid == 0:\n                    return cursor.rowcount\n                return cursor.lastrowid\n            finally:\n                await cursor.close()\n\n    async def execute_many(self, queries: typing.List[ClauseElement]) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        async with self._connection.cursor() as cursor:\n            try:\n                for single_query in queries:\n                    single_query, args, _, _ = self._compile(single_query)\n                    await cursor.execute(single_query, args)\n            finally:\n                await cursor.close()\n\n    async def iterate(self, query: ClauseElement) -> typing.AsyncGenerator[typing.Any, None]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        async with self._connection.cursor() as cursor:\n            try:\n                await cursor.execute(query_str, args)\n                metadata = CursorResultMetaData(context, cursor.description)\n                async for row in cursor:\n                    record = Row(\n                        metadata,\n                        metadata._effective_processors,\n                        metadata._key_to_index,\n                        row,\n                    )\n                    yield Record(record, result_columns, dialect, column_maps)\n            finally:\n                await cursor.close()\n\n    def transaction(self) -> TransactionBackend:\n        return AsyncMyTransaction(self)\n\n    def _compile(self, query: ClauseElement) -> typing.Tuple[str, list, tuple]:\n        compiled = query.compile(\n            dialect=self._dialect, compile_kwargs={\"render_postcompile\": True}\n        )\n        execution_context = self._dialect.execution_ctx_cls()\n        execution_context.dialect = self._dialect\n\n        if not isinstance(query, DDLElement):\n            compiled_params = sorted(compiled.params.items())\n\n            args = compiled.construct_params()\n            for key, val in args.items():\n                if key in compiled._bind_processors:\n                    args[key] = compiled._bind_processors[key](val)\n\n            execution_context.result_column_struct = (\n                compiled._result_columns,\n                compiled._ordered_columns,\n                compiled._textual_ordered_columns,\n                compiled._ad_hoc_textual,\n                compiled._loose_column_name_matching,\n            )\n\n            mapping = {key: \"$\" + str(i) for i, (key, _) in enumerate(compiled_params, start=1)}\n            compiled_query = compiled.string % mapping\n            result_map = compiled._result_columns\n\n        else:\n            args = {}\n            result_map = None\n            compiled_query = compiled.string\n\n        query_message = compiled_query.replace(\" \\n\", \" \").replace(\"\\n\", \" \")\n        logger.debug(\"Query: %s Args: %s\", query_message, repr(tuple(args)), extra=LOG_EXTRA)\n        return compiled.string, args, result_map, CompilationContext(execution_context)\n\n    @property\n    def raw_connection(self) -> asyncmy.connection.Connection:\n        assert self._connection is not None, \"Connection is not acquired\"\n        return self._connection", "\n\nclass AsyncMyTransaction(TransactionBackend):\n    def __init__(self, connection: AsyncMyConnection):\n        self._connection = connection\n        self._is_root = False\n        self._savepoint_name = \"\"\n\n    async def start(\n        self, is_root: bool, extra_options: typing.Dict[typing.Any, typing.Any]\n    ) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        self._is_root = is_root\n        if self._is_root:\n            await self._connection._connection.begin()\n        else:\n            id = str(uuid.uuid4()).replace(\"-\", \"_\")\n            self._savepoint_name = f\"STARLETTE_SAVEPOINT_{id}\"\n            async with self._connection._connection.cursor() as cursor:\n                try:\n                    await cursor.execute(f\"SAVEPOINT {self._savepoint_name}\")\n                finally:\n                    await cursor.close()\n\n    async def commit(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        if self._is_root:\n            await self._connection._connection.commit()\n        else:\n            async with self._connection._connection.cursor() as cursor:\n                try:\n                    await cursor.execute(f\"RELEASE SAVEPOINT {self._savepoint_name}\")\n                finally:\n                    await cursor.close()\n\n    async def rollback(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        if self._is_root:\n            await self._connection._connection.rollback()\n        else:\n            async with self._connection._connection.cursor() as cursor:\n                try:\n                    await cursor.execute(f\"ROLLBACK TO SAVEPOINT {self._savepoint_name}\")\n                finally:\n                    await cursor.close()", ""]}
{"filename": "databasez/backends/mssql.py", "chunked_list": ["import getpass\nimport logging\nimport typing\nimport uuid\n\nimport aioodbc\nimport pyodbc as ext_pyodbc\nfrom sqlalchemy.dialects.mssql import pyodbc\nfrom sqlalchemy.engine.cursor import CursorResultMetaData\nfrom sqlalchemy.engine.interfaces import Dialect, ExecutionContext", "from sqlalchemy.engine.cursor import CursorResultMetaData\nfrom sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement\nfrom sqlalchemy.sql.ddl import DDLElement\n\nfrom databasez.backends.common.records import Record, Row, create_column_maps\nfrom databasez.core import LOG_EXTRA, DatabaseURL\nfrom databasez.interfaces import ConnectionBackend, DatabaseBackend\nfrom databasez.interfaces import Record as RecordInterface\nfrom databasez.interfaces import TransactionBackend", "from databasez.interfaces import Record as RecordInterface\nfrom databasez.interfaces import TransactionBackend\n\nlogger = logging.getLogger(\"databasez\")\n\n\nclass MSSQLBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = pyodbc.dialect(paramstyle=\"pyformat\")\n        self._dialect.supports_native_decimal = True\n        self._pool: aioodbc.Pool = None\n\n    def _get_connection_kwargs(self) -> dict:\n        url_options = self._database_url.options\n\n        kwargs = {}\n        min_size = url_options.get(\"min_size\")\n        max_size = url_options.get(\"max_size\")\n        pool_recycle = url_options.get(\"pool_recycle\")\n        ssl = url_options.get(\"ssl\")\n        driver = url_options.get(\"driver\")\n        timeout = url_options.get(\"connection_timeout\", 30)\n        trusted_connection = url_options.get(\"trusted_connection\", \"no\")\n\n        assert driver is not None, \"The driver must be specified\"\n\n        if min_size is not None:\n            kwargs[\"minsize\"] = int(min_size)\n        if max_size is not None:\n            kwargs[\"maxsize\"] = int(max_size)\n        if pool_recycle is not None:\n            kwargs[\"pool_recycle\"] = int(pool_recycle)\n        if ssl is not None:\n            kwargs[\"ssl\"] = {\"true\": True, \"false\": False}[ssl.lower()]\n\n        kwargs.update(\n            {\n                \"ignore_no_transaction_on_rollback\": True,\n                \"trusted_connection\": trusted_connection.lower(),\n                \"timeout\": timeout,\n                \"autocommit\": True,\n                \"driver\": driver,\n            }\n        )\n\n        for key, value in self._options.items():\n            # Coerce 'min_size' and 'max_size' for consistency.\n            if key == \"min_size\":\n                key = \"minsize\"\n            elif key == \"max_size\":\n                key = \"maxsize\"\n            kwargs[key] = value\n\n        return kwargs\n\n    async def connect(self) -> None:\n        assert self._pool is None, \"DatabaseBackend is already running\"\n        kwargs = self._get_connection_kwargs()\n\n        driver = kwargs[\"driver\"]\n        database = self._database_url.database\n        hostname = self._database_url.hostname\n        port = self._database_url.port or 1433\n        user = self._database_url.username or getpass.getuser()\n        password = self._database_url.password\n        timeout = kwargs.pop(\"timeout\")\n\n        if port:\n            dsn = f\"Driver={driver};Database={database};Server={hostname},{port};UID={user};PWD={password};Connection+Timeout={timeout}\"\n        else:\n            dsn = f\"Driver={driver};Database={database};Server={hostname},{port};UID={user};PWD={password};Connection+Timeout={timeout}\"\n\n        self._pool = await aioodbc.create_pool(\n            dsn=dsn,\n            **kwargs,\n        )\n\n    async def disconnect(self) -> None:\n        assert self._pool is not None, \"DatabaseBackend is not running\"\n        self._pool.close()\n        pool, self._pool = self._pool, None\n        await pool.wait_closed()\n\n    def connection(self) -> \"MSSQLConnection\":\n        return MSSQLConnection(self, self._dialect)", "\n\nclass CompilationContext:\n    def __init__(self, context: ExecutionContext):\n        self.context = context\n\n\nclass MSSQLConnection(ConnectionBackend):\n    def __init__(self, database: MSSQLBackend, dialect: Dialect) -> None:\n        self._database = database\n        self._dialect = dialect\n        self._connection: typing.Optional[aioodbc.Connection] = None\n\n    async def acquire(self) -> None:\n        assert self._connection is None, \"Connection is already acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        self._connection = await self._database._pool.acquire()\n\n    async def release(self) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        await self._database._pool.release(self._connection)\n        self._connection = None\n\n    async def fetch_all(self, query: ClauseElement) -> typing.List[\"RecordInterface\"]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            rows = await cursor.fetchall()\n            metadata = CursorResultMetaData(context, cursor.description)\n            rows = [\n                Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                for row in rows\n            ]\n            return [Record(row, result_columns, dialect, column_maps) for row in rows]\n        finally:\n            await cursor.close()\n\n    async def fetch_one(self, query: ClauseElement) -> typing.Optional[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            row = await cursor.fetchone()\n            if row is None:\n                return None\n            metadata = CursorResultMetaData(context, cursor.description)\n            row = Row(\n                metadata,\n                metadata._effective_processors,\n                metadata._key_to_index,\n                row,\n            )\n            return Record(row, result_columns, dialect, column_maps)\n        finally:\n            await cursor.close()\n\n    async def execute(self, query: ClauseElement) -> typing.Any:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, _, _ = self._compile(query)\n        cursor = await self._connection.cursor()\n        try:\n            values = await cursor.execute(query_str, args)\n            try:\n                values = await values.fetchone()\n                return values[0]\n            except Exception:\n                ...\n        finally:\n            await cursor.close()\n\n    async def execute_many(self, queries: typing.List[ClauseElement]) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        cursor = await self._connection.cursor()\n        try:\n            for single_query in queries:\n                single_query, args, _, _ = self._compile(single_query)\n                await cursor.execute(single_query, args)\n        finally:\n            await cursor.close()\n\n    async def iterate(self, query: ClauseElement) -> typing.AsyncGenerator[typing.Any, None]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            metadata = CursorResultMetaData(context, cursor.description)\n            async for row in cursor:\n                record = Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                yield Record(record, result_columns, dialect, column_maps)\n        finally:\n            await cursor.close()\n\n    def transaction(self) -> TransactionBackend:\n        return MSSQLTransaction(self)\n\n    def _compile(self, query: ClauseElement) -> typing.Tuple[str, list, tuple]:\n        compiled = query.compile(\n            dialect=self._dialect, compile_kwargs={\"render_postcompile\": True}\n        )\n\n        execution_context = self._dialect.execution_ctx_cls()\n        execution_context.dialect = self._dialect\n\n        if not isinstance(query, DDLElement):\n            compiled_params = compiled.params.items()\n\n            mapping = {key: \"?\" for _, (key, _) in enumerate(compiled_params, start=1)}\n            compiled_query = compiled.string % mapping\n\n            processors = compiled._bind_processors\n            args = [\n                processors[key](val) if key in processors else val for key, val in compiled_params\n            ]\n\n            execution_context.result_column_struct = (\n                compiled._result_columns,\n                compiled._ordered_columns,\n                compiled._textual_ordered_columns,\n                compiled._ad_hoc_textual,\n                compiled._loose_column_name_matching,\n            )\n\n            result_map = compiled._result_columns\n        else:\n            compiled_query = compiled.string\n            args = []\n            result_map = None\n\n        query_message = compiled_query.replace(\" \\n\", \" \").replace(\"\\n\", \" \")\n        logger.debug(\"Query: %s Args: %s\", query_message, repr(tuple(args)), extra=LOG_EXTRA)\n        return compiled_query, args, result_map, CompilationContext(execution_context)\n\n    @property\n    def raw_connection(self) -> aioodbc.connection.Connection:\n        assert self._connection is not None, \"Connection is not acquired\"\n        return self._connection", "\n\nclass MSSQLTransaction(TransactionBackend):\n    def __init__(self, connection: MSSQLConnection):\n        self._connection = connection\n        self._is_root = False\n        self._savepoint_name = \"\"\n\n    async def start(\n        self, is_root: bool, extra_options: typing.Dict[typing.Any, typing.Any]\n    ) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        self._is_root = is_root\n        cursor = await self._connection._connection.cursor()\n        if self._is_root:\n            await cursor.execute(\"BEGIN TRANSACTION\")\n        else:\n            id = str(uuid.uuid4()).replace(\"-\", \"_\")[:12]\n            self._savepoint_name = f\"STARLETTE_SAVEPOINT_{id}\"\n            try:\n                await cursor.execute(f\"SAVE TRANSACTION {self._savepoint_name}\")\n            finally:\n                cursor.close()\n\n    async def commit(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        cursor = await self._connection._connection.cursor()\n        if self._is_root:\n            await cursor.execute(\"COMMIT TRANSACTION\")\n        else:\n            try:\n                await cursor.execute(f\"COMMIT TRANSACTION {self._savepoint_name}\")\n            finally:\n                cursor.close()\n\n    async def rollback(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        cursor = await self._connection._connection.cursor()\n        if self._is_root:\n            try:\n                await cursor.execute(\"ROLLBACK TRANSACTION\")\n            except ext_pyodbc.ProgrammingError:\n                logger.error(\"There is no transaction to rollback\")\n        else:\n            try:\n                await cursor.execute(f\"ROLLBACK TRANSACTION {self._savepoint_name}\")\n            finally:\n                cursor.close()", ""]}
{"filename": "databasez/backends/__init__.py", "chunked_list": [""]}
{"filename": "databasez/backends/aiopg.py", "chunked_list": ["import getpass\nimport json\nimport logging\nimport typing\nimport uuid\n\nimport aiopg\nfrom sqlalchemy.engine.cursor import CursorResultMetaData\nfrom sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement", "from sqlalchemy.engine.interfaces import Dialect, ExecutionContext\nfrom sqlalchemy.sql import ClauseElement\nfrom sqlalchemy.sql.ddl import DDLElement\n\nfrom databasez.backends.common.records import Record, Row, create_column_maps\nfrom databasez.backends.compilers.psycopg import PGCompiler_psycopg\nfrom databasez.backends.dialects.psycopg import PGDialect_psycopg\nfrom databasez.core import LOG_EXTRA, DatabaseURL\nfrom databasez.interfaces import ConnectionBackend, DatabaseBackend\nfrom databasez.interfaces import Record as RecordInterface", "from databasez.interfaces import ConnectionBackend, DatabaseBackend\nfrom databasez.interfaces import Record as RecordInterface\nfrom databasez.interfaces import TransactionBackend\n\nlogger = logging.getLogger(\"databasez\")\n\n\nclass AiopgBackend(DatabaseBackend):\n    def __init__(\n        self, database_url: typing.Union[DatabaseURL, str], **options: typing.Any\n    ) -> None:\n        self._database_url = DatabaseURL(database_url)\n        self._options = options\n        self._dialect = self._get_dialect()\n        self._pool: typing.Union[aiopg.Pool, None] = None\n\n    def _get_dialect(self) -> Dialect:\n        dialect = PGDialect_psycopg(json_serializer=json.dumps, json_deserializer=lambda x: x)\n        dialect.statement_compiler = PGCompiler_psycopg\n        dialect.implicit_returning = True\n        dialect.supports_native_enum = True\n        dialect.supports_smallserial = True  # 9.2+\n        dialect._backslash_escapes = False\n        dialect.supports_sane_multi_rowcount = True  # psycopg 2.0.9+\n        dialect._has_native_hstore = True\n        dialect.supports_native_decimal = True\n\n        return dialect\n\n    def _get_connection_kwargs(self) -> dict:\n        url_options = self._database_url.options\n\n        kwargs = {}\n        min_size = url_options.get(\"min_size\")\n        max_size = url_options.get(\"max_size\")\n        ssl = url_options.get(\"ssl\")\n\n        if min_size is not None:\n            kwargs[\"minsize\"] = int(min_size)\n        if max_size is not None:\n            kwargs[\"maxsize\"] = int(max_size)\n        if ssl is not None:\n            kwargs[\"ssl\"] = {\"true\": True, \"false\": False}[ssl.lower()]\n\n        for key, value in self._options.items():\n            # Coerce 'min_size' and 'max_size' for consistency.\n            if key == \"min_size\":\n                key = \"minsize\"\n            elif key == \"max_size\":\n                key = \"maxsize\"\n            kwargs[key] = value\n\n        return kwargs\n\n    async def connect(self) -> None:\n        assert self._pool is None, \"DatabaseBackend is already running\"\n        kwargs = self._get_connection_kwargs()\n        self._pool = await aiopg.create_pool(\n            host=self._database_url.hostname,\n            port=self._database_url.port,\n            user=self._database_url.username or getpass.getuser(),\n            password=self._database_url.password,\n            database=self._database_url.database,\n            **kwargs,\n        )\n\n    async def disconnect(self) -> None:\n        assert self._pool is not None, \"DatabaseBackend is not running\"\n        self._pool.close()\n        await self._pool.wait_closed()\n        self._pool = None\n\n    def connection(self) -> \"AiopgConnection\":\n        return AiopgConnection(self, self._dialect)", "\n\nclass CompilationContext:\n    def __init__(self, context: ExecutionContext):\n        self.context = context\n\n\nclass AiopgConnection(ConnectionBackend):\n    def __init__(self, database: AiopgBackend, dialect: Dialect):\n        self._database = database\n        self._dialect = dialect\n        self._connection: typing.Optional[aiopg.Connection] = None\n\n    async def acquire(self) -> None:\n        assert self._connection is None, \"Connection is already acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        self._connection = await self._database._pool.acquire()\n\n    async def release(self) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        assert self._database._pool is not None, \"DatabaseBackend is not running\"\n        connection, self._connection = self._connection, None\n        await self._database._pool.release(connection)\n\n    async def fetch_all(self, query: ClauseElement) -> typing.List[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            rows = await cursor.fetchall()\n            metadata = CursorResultMetaData(context, cursor.description)\n            rows = [\n                Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                for row in rows\n            ]\n            return [Record(row, result_columns, dialect, column_maps) for row in rows]\n        finally:\n            cursor.close()\n\n    async def fetch_one(self, query: ClauseElement) -> typing.Optional[RecordInterface]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            row = await cursor.fetchone()\n            if row is None:\n                return None\n            metadata = CursorResultMetaData(context, cursor.description)\n            row = Row(\n                metadata,\n                metadata._effective_processors,\n                metadata._key_to_index,\n                row,\n            )\n            return Record(row, result_columns, dialect, column_maps)\n        finally:\n            cursor.close()\n\n    async def execute(self, query: ClauseElement) -> typing.Any:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, _, _ = self._compile(query)\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            return cursor.lastrowid\n        finally:\n            cursor.close()\n\n    async def execute_many(self, queries: typing.List[ClauseElement]) -> None:\n        assert self._connection is not None, \"Connection is not acquired\"\n        cursor = await self._connection.cursor()\n        try:\n            for single_query in queries:\n                single_query, args, _, _ = self._compile(single_query)\n                await cursor.execute(single_query, args)\n        finally:\n            cursor.close()\n\n    async def iterate(self, query: ClauseElement) -> typing.AsyncGenerator[typing.Any, None]:\n        assert self._connection is not None, \"Connection is not acquired\"\n        query_str, args, result_columns, context = self._compile(query)\n        column_maps = create_column_maps(result_columns)\n        dialect = self._dialect\n        cursor = await self._connection.cursor()\n        try:\n            await cursor.execute(query_str, args)\n            metadata = CursorResultMetaData(context, cursor.description)\n            async for row in cursor:\n                record = Row(\n                    metadata,\n                    metadata._effective_processors,\n                    metadata._key_to_index,\n                    row,\n                )\n                yield Record(record, result_columns, dialect, column_maps)\n        finally:\n            cursor.close()\n\n    def transaction(self) -> TransactionBackend:\n        return AiopgTransaction(self)\n\n    def _compile(self, query: ClauseElement) -> typing.Tuple[str, list, tuple]:\n        compiled = query.compile(\n            dialect=self._dialect, compile_kwargs={\"render_postcompile\": True}\n        )\n        execution_context = self._dialect.execution_ctx_cls()\n        execution_context.dialect = self._dialect\n\n        if not isinstance(query, DDLElement):\n            compiled_params = sorted(compiled.params.items())\n\n            args = compiled.construct_params()\n            for key, val in args.items():\n                if key in compiled._bind_processors:\n                    args[key] = compiled._bind_processors[key](val)\n\n            execution_context.result_column_struct = (\n                compiled._result_columns,\n                compiled._ordered_columns,\n                compiled._textual_ordered_columns,\n                compiled._ad_hoc_textual,\n                compiled._loose_column_name_matching,\n            )\n\n            mapping = {key: \"$\" + str(i) for i, (key, _) in enumerate(compiled_params, start=1)}\n            compiled_query = compiled.string % mapping\n            result_map = compiled._result_columns\n\n        else:\n            args = {}\n            result_map = None\n            compiled_query = compiled.string\n\n        query_message = compiled_query.replace(\" \\n\", \" \").replace(\"\\n\", \" \")\n        logger.debug(\"Query: %s Args: %s\", query_message, repr(tuple(args)), extra=LOG_EXTRA)\n        return compiled.string, args, result_map, CompilationContext(execution_context)\n\n    @property\n    def raw_connection(self) -> aiopg.connection.Connection:\n        assert self._connection is not None, \"Connection is not acquired\"\n        return self._connection", "\n\nclass AiopgTransaction(TransactionBackend):\n    def __init__(self, connection: AiopgConnection):\n        self._connection = connection\n        self._is_root = False\n        self._savepoint_name = \"\"\n\n    async def start(\n        self, is_root: bool, extra_options: typing.Dict[typing.Any, typing.Any]\n    ) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        self._is_root = is_root\n        cursor = await self._connection._connection.cursor()\n        if self._is_root:\n            await cursor.execute(\"BEGIN\")\n        else:\n            id = str(uuid.uuid4()).replace(\"-\", \"_\")\n            self._savepoint_name = f\"STARLETTE_SAVEPOINT_{id}\"\n            try:\n                await cursor.execute(f\"SAVEPOINT {self._savepoint_name}\")\n            finally:\n                cursor.close()\n\n    async def commit(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        cursor = await self._connection._connection.cursor()\n        if self._is_root:\n            await cursor.execute(\"COMMIT\")\n        else:\n            try:\n                await cursor.execute(f\"RELEASE SAVEPOINT {self._savepoint_name}\")\n            finally:\n                cursor.close()\n\n    async def rollback(self) -> None:\n        assert self._connection._connection is not None, \"Connection is not acquired\"\n        cursor = await self._connection._connection.cursor()\n        if self._is_root:\n            await cursor.execute(\"ROLLBACK\")\n        else:\n            try:\n                await cursor.execute(f\"ROLLBACK TO SAVEPOINT {self._savepoint_name}\")\n            finally:\n                cursor.close()", ""]}
{"filename": "databasez/backends/compilers/psycopg.py", "chunked_list": ["from sqlalchemy.dialects.postgresql.psycopg import PGCompiler_psycopg\n\n\nclass APGCompiler_psycopg2(PGCompiler_psycopg):\n    def construct_params(self, *args, **kwargs):\n        pd = super().construct_params(*args, **kwargs)\n\n        for column in self.prefetch:\n            pd[column.key] = self._exec_default(column.default)\n\n        return pd\n\n    def _exec_default(self, default):\n        if default.is_callable:\n            return default.arg(self.dialect)\n        else:\n            return default.arg", ""]}
{"filename": "databasez/backends/compilers/__init__.py", "chunked_list": [""]}
{"filename": "databasez/backends/common/records.py", "chunked_list": ["import json\nimport typing\nfrom datetime import date, datetime\n\nfrom sqlalchemy.engine.interfaces import Dialect\nfrom sqlalchemy.engine.row import Row as SQLRow\nfrom sqlalchemy.sql.compiler import _CompileLabel\nfrom sqlalchemy.sql.schema import Column\nfrom sqlalchemy.types import TypeEngine\n", "from sqlalchemy.types import TypeEngine\n\nfrom databasez.interfaces import Record as RecordInterface\n\nDIALECT_EXCLUDE = {\"postgresql\"}\n\n\nclass Record(RecordInterface):\n    __slots__ = (\n        \"_row\",\n        \"_result_columns\",\n        \"_dialect\",\n        \"_column_map\",\n        \"_column_map_int\",\n        \"_column_map_full\",\n    )\n\n    def __init__(\n        self,\n        row: typing.Any,\n        result_columns: tuple,\n        dialect: Dialect,\n        column_maps: typing.Tuple[\n            typing.Mapping[typing.Any, typing.Tuple[int, TypeEngine]],\n            typing.Mapping[int, typing.Tuple[int, TypeEngine]],\n            typing.Mapping[str, typing.Tuple[int, TypeEngine]],\n        ],\n    ) -> None:\n        self._row = row\n        self._result_columns = result_columns\n        self._dialect = dialect\n        self._column_map, self._column_map_int, self._column_map_full = column_maps\n\n    @property\n    def _mapping(self) -> typing.Mapping:\n        return self._row\n\n    def keys(self) -> typing.KeysView:\n        return self._mapping.keys()\n\n    def values(self) -> typing.ValuesView:\n        return self._mapping.values()\n\n    def __getitem__(self, key: typing.Any) -> typing.Any:\n        if len(self._column_map) == 0:\n            return self._row[key]\n        elif isinstance(key, Column):\n            idx, datatype = self._column_map_full[str(key)]\n        elif isinstance(key, int):\n            idx, datatype = self._column_map_int[key]\n        else:\n            idx, datatype = self._column_map[key]\n\n        raw = self._row[idx]\n        processor = datatype._cached_result_processor(self._dialect, None)\n\n        if self._dialect.name not in DIALECT_EXCLUDE:\n            if isinstance(raw, dict):\n                raw = json.dumps(raw)\n\n        if processor is not None and (not isinstance(raw, (datetime, date))):\n            return processor(raw)\n        return raw\n\n    def __iter__(self) -> typing.Iterator:\n        return iter(self._row.keys())\n\n    def __len__(self) -> int:\n        return len(self._row)\n\n    def __getattr__(self, name: str) -> typing.Any:\n        try:\n            return self.__getitem__(name)\n        except KeyError as e:\n            raise AttributeError(e.args[0]) from e\n\n    def __str__(self) -> str:\n        return f\"Record{str(self._row)}\"\n\n    def __repr__(self) -> str:\n        return str(self)", "\n\nclass Row(SQLRow):\n    def __getitem__(self, key: typing.Any) -> typing.Any:\n        \"\"\"\n        An instance of a Row in SQLAlchemy allows the access\n        to the Row._fields as tuple and the Row._mapping for\n        the values.\n\n        return RowMapping(\n            self._parent,\n            None,\n            self._keymap,\n            RowMapping._default_key_style,\n            self._data,\n            return RowMapping(self._parent, None, self._key_to_index, self._data)\n        )\n        \"\"\"\n        if isinstance(key, int):\n            field = self._fields[key]\n            return self._mapping[field]\n        return self._mapping[key]\n\n    def keys(self):\n        return self._mapping.keys()\n\n    def values(self):\n        return self._mapping.values()\n\n    def __getattr__(self, name: str) -> typing.Any:\n        try:\n            return self.__getitem__(name)\n        except KeyError as e:\n            raise AttributeError(e.args[0]) from e", "\n\ndef create_column_maps(\n    result_columns: typing.Any,\n) -> typing.Tuple[\n    typing.Mapping[typing.Any, typing.Tuple[int, TypeEngine]],\n    typing.Mapping[int, typing.Tuple[int, TypeEngine]],\n    typing.Mapping[str, typing.Tuple[int, TypeEngine]],\n]:\n    \"\"\"\n    Generate column -> datatype mappings from the column definitions.\n\n    These mappings are used throughout PostgresConnection methods\n    to initialize Record-s. The underlying DB driver does not do type\n    conversion for us so we have wrap the returned asyncpg.Record-s.\n\n    :return: Three mappings from different ways to address a column to \\\n                corresponding column indexes and datatypes: \\\n                1. by column identifier; \\\n                2. by column index; \\\n                3. by column name in Column sqlalchemy objects.\n    \"\"\"\n    column_map, column_map_int, column_map_full = {}, {}, {}\n    for idx, (column_name, _, column, datatype) in enumerate(result_columns):\n        column_map[column_name] = (idx, datatype)\n        column_map_int[idx] = (idx, datatype)\n\n        if not column:\n            continue\n\n        # Added in SQLA 2.0 and _CompileLabels do not have _annotations\n        # When this happens, the mapping is on the second position\n        if isinstance(column[0], _CompileLabel):\n            column_map_full[str(column[2])] = (idx, datatype)\n        else:\n            column_map_full[str(column[0])] = (idx, datatype)\n    return column_map, column_map_int, column_map_full", ""]}
{"filename": "databasez/backends/common/__init__.py", "chunked_list": [""]}
{"filename": "databasez/backends/dialects/psycopg.py", "chunked_list": ["\"\"\"\nAll the unique changes for the databases package\nwith the custom Numeric as the deprecated pypostgresql\nfor backwards compatibility and to make sure the\npackage can go to SQLAlchemy 2.0+.\n\"\"\"\n\nimport typing\n\nfrom sqlalchemy import types, util", "\nfrom sqlalchemy import types, util\nfrom sqlalchemy.dialects.postgresql.base import PGDialect, PGExecutionContext\nfrom sqlalchemy.engine import processors\nfrom sqlalchemy.types import Float, Numeric\n\n\nclass PGExecutionContext_psycopg(PGExecutionContext):\n    ...\n", "\n\nclass PGNumeric(Numeric):\n    def bind_processor(self, dialect: typing.Any) -> typing.Union[str, None]:  # pragma: no cover\n        return processors.to_str\n\n    def result_processor(\n        self, dialect: typing.Any, coltype: typing.Any\n    ) -> typing.Union[float, None]:  # pragma: no cover\n        if self.asdecimal:\n            return None\n        else:\n            return processors.to_float", "\n\nclass PGDialect_psycopg(PGDialect):\n    colspecs = util.update_copy(\n        PGDialect.colspecs,\n        {\n            types.Numeric: PGNumeric,\n            types.Float: Float,\n        },\n    )\n    execution_ctx_cls = PGExecutionContext_psycopg", "\n\ndialect = PGDialect_psycopg\n"]}
{"filename": "databasez/backends/dialects/__init__.py", "chunked_list": [""]}
