{"filename": "src/inn_service/settings.py", "chunked_list": ["from typing import Optional\n\nfrom pydantic import BaseSettings\n\n\nclass Settings(BaseSettings):\n    app_name: str = 'INN service'\n    app_request_retry_times: int  # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u043f\u044b\u0442\u043e\u043a \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0432\u043d\u0435\u0448\u043d\u0435\u0433\u043e \u0437\u0430\u043f\u0440\u043e\u0441\u0430\n    app_request_retry_sec: int  # \u0412\u0440\u0435\u043c\u044f \u0437\u0430\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0441\u0435\u043a\u0443\u043d\u0434\u0430\u0445 \u043f\u0435\u0440\u0435\u0434 \u043f\u043e\u0432\u0442\u043e\u0440\u043d\u043e\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u043e\u0439 \u0437\u0430\u043f\u0440\u043e\u0441\u0430\n\n    http_host: str\n    http_port: int\n    http_handler: str = 'asyncio'\n\n    mongo_host: str\n    mongo_port: str\n    mongo_user: str\n    mongo_pass: str\n    mongo_name: str\n    mongo_rs: Optional[str] = None\n    mongo_auth: str\n    mongo_timeout_server_select: int = 5000\n\n    rabbitmq_host: str\n    rabbitmq_port: int\n    rabbitmq_user: str\n    rabbitmq_pass: str\n    rabbitmq_vhost: str\n    rabbitmq_exchange_type: str\n    rabbitmq_prefetch_count: int\n    rabbitmq_source_queue_name: str\n\n    client_nalog_url: str  # \u0410\u0434\u0440\u0435\u0441 \u0432\u043d\u0435\u0448\u043d\u0435\u0433\u043e \u0441\u0435\u0440\u0432\u0438\u0441\u0430 \u0434\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0418\u041d\u041d\n    client_nalog_timeout_sec: int  # \u0422\u0430\u0439\u043c\u0430\u0443\u0442 \u043e\u0436\u0438\u0434\u0430\u043d\u0438\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043e\u0442 \u0441\u0435\u0440\u0432\u0438\u0441\u0430\n    client_nalog_retries: int  # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u043f\u044b\u0442\u043e\u043a \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432 \u043a \u0432\u043d\u0435\u0448\u043d\u0435\u043c\u0443 \u0441\u0435\u0440\u0432\u0438\u0441\u0443\n    client_nalog_wait_sec: int  # \u0412\u0440\u0435\u043c\u044f \u043e\u0436\u0438\u0434\u0430\u043d\u0438\u044f \u043c\u0435\u0436\u0434\u0443 \u043f\u043e\u043f\u044b\u0442\u043a\u0430\u043c\u0438 client_nalog_retries\n\n    @property\n    def mongo_dsn(self) -> str:\n        mongo_dsn = 'mongodb://{}:{}@{}:{}/{}'.format(\n            self.mongo_user,\n            self.mongo_pass,\n            self.mongo_host,\n            self.mongo_port,\n            self.mongo_auth\n        )\n\n        if self.mongo_rs:\n            mongo_dsn += f'?replicaSet={self.mongo_rs}'\n\n        return mongo_dsn\n\n    @property\n    def rabbitmq_dsn(self) -> str:\n        return 'amqp://{}:{}@{}:{}/{}'.format(\n            self.rabbitmq_user,\n            self.rabbitmq_pass,\n            self.rabbitmq_host,\n            self.rabbitmq_port,\n            self.rabbitmq_vhost\n        )", ""]}
{"filename": "src/inn_service/main.py", "chunked_list": ["import typer\nfrom core.application import Application\nfrom app_container import ApplicationContainer\n\n\ndef main():\n    try:\n        application = Application(ApplicationContainer)\n        application.run()\n    except BaseException as exc:\n        typer.echo(f'Error starting application. Details: {str(exc)}')", "\n\nif __name__ == \"__main__\":\n    typer.run(main)\n"]}
{"filename": "src/inn_service/logger.py", "chunked_list": ["import datetime\nimport json\nimport logging\nimport traceback\n\nfrom collections import OrderedDict\n\n\nclass AppLogger:\n\n    def __init__(self, logger: logging.Logger) -> None:\n        self._logger = logger\n\n    def _is_jsonible(self, object_type) -> bool:\n        return isinstance(object_type, (list, tuple, str, int, float, bool, type(None)))\n\n    def _format_kwargs(self, kwargs):\n        _kwargs = {}\n        for k, v in kwargs.items():\n            if self._is_jsonible(v):\n                _kwargs[k] = v\n            elif isinstance(v, (set, frozenset)):\n                _kwargs[k] = list(v)\n            elif isinstance(v, (dict, OrderedDict)):\n                _kwargs[k] = self._format_kwargs(v)\n            elif isinstance(v, (datetime.datetime, datetime.date)):\n                _kwargs[k] = v.isoformat()\n            else:\n                try:\n                    _kwargs[k] = str(v)\n                except Exception as e:\n                    _kwargs[k] = f'format_error: {e}'\n        return _kwargs\n\n    def _format(self, msg: str, level, **kwargs):\n        try:\n            extras = {\n                **self._format_kwargs(kwargs),\n            }\n            extras_json = json.dumps(extras, ensure_ascii=False, default=str)\n        except Exception as e:\n            extras_json = json.dumps({\"logger_error\": str(e)}, ensure_ascii=False)\n\n        return json.dumps(\n            {\n                \"app\": self._logger.name,\n                \"timestamp\": str(datetime.datetime.utcnow()),\n                \"event\": msg,\n                \"level\": level,\n                \"extra\": extras_json,\n            },\n            ensure_ascii=False,\n        )\n\n    def critical(self, msg: str, **kwargs):\n        self._logger.critical(self._format(msg, level=\"critical\", **kwargs))\n\n    def error(self, msg: str, **kwargs):\n        self._logger.error(self._format(msg, level=\"error\", **kwargs))\n\n    def warning(self, msg: str, **kwargs):\n        self._logger.warning(self._format(msg, level=\"warning\", **kwargs))\n\n    def info(self, msg: str, **kwargs):\n        self._logger.info(self._format(msg, level=\"info\", **kwargs))\n\n    def debug(self, msg: str, **kwargs):\n        self._logger.debug(self._format(msg, level=\"debug\", **kwargs))\n\n    def exception(self, msg: str, **kwargs):\n        self._logger.error(\n            self._format(\n                msg,\n                level=\"exception\",\n                traceback=traceback.format_exc(),\n                **kwargs,\n            )\n        )", "class AppLogger:\n\n    def __init__(self, logger: logging.Logger) -> None:\n        self._logger = logger\n\n    def _is_jsonible(self, object_type) -> bool:\n        return isinstance(object_type, (list, tuple, str, int, float, bool, type(None)))\n\n    def _format_kwargs(self, kwargs):\n        _kwargs = {}\n        for k, v in kwargs.items():\n            if self._is_jsonible(v):\n                _kwargs[k] = v\n            elif isinstance(v, (set, frozenset)):\n                _kwargs[k] = list(v)\n            elif isinstance(v, (dict, OrderedDict)):\n                _kwargs[k] = self._format_kwargs(v)\n            elif isinstance(v, (datetime.datetime, datetime.date)):\n                _kwargs[k] = v.isoformat()\n            else:\n                try:\n                    _kwargs[k] = str(v)\n                except Exception as e:\n                    _kwargs[k] = f'format_error: {e}'\n        return _kwargs\n\n    def _format(self, msg: str, level, **kwargs):\n        try:\n            extras = {\n                **self._format_kwargs(kwargs),\n            }\n            extras_json = json.dumps(extras, ensure_ascii=False, default=str)\n        except Exception as e:\n            extras_json = json.dumps({\"logger_error\": str(e)}, ensure_ascii=False)\n\n        return json.dumps(\n            {\n                \"app\": self._logger.name,\n                \"timestamp\": str(datetime.datetime.utcnow()),\n                \"event\": msg,\n                \"level\": level,\n                \"extra\": extras_json,\n            },\n            ensure_ascii=False,\n        )\n\n    def critical(self, msg: str, **kwargs):\n        self._logger.critical(self._format(msg, level=\"critical\", **kwargs))\n\n    def error(self, msg: str, **kwargs):\n        self._logger.error(self._format(msg, level=\"error\", **kwargs))\n\n    def warning(self, msg: str, **kwargs):\n        self._logger.warning(self._format(msg, level=\"warning\", **kwargs))\n\n    def info(self, msg: str, **kwargs):\n        self._logger.info(self._format(msg, level=\"info\", **kwargs))\n\n    def debug(self, msg: str, **kwargs):\n        self._logger.debug(self._format(msg, level=\"debug\", **kwargs))\n\n    def exception(self, msg: str, **kwargs):\n        self._logger.error(\n            self._format(\n                msg,\n                level=\"exception\",\n                traceback=traceback.format_exc(),\n                **kwargs,\n            )\n        )", ""]}
{"filename": "src/inn_service/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/app_container.py", "chunked_list": ["from injector import singleton, provider\nimport logging\n\nfrom core.container_manager import Container\nfrom settings import Settings\nfrom logger import AppLogger\nfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\nfrom connection_managers.mongo_connection_manager import MongoConnectionManager\nfrom services.inn_service import InnService\nfrom services.live_probe_service import LiveProbeService", "from services.inn_service import InnService\nfrom services.live_probe_service import LiveProbeService\nfrom infrastructure.queue_manager.queue_manager import QueueManager\nfrom infrastructure.handlers.request_handler import RequestHandler\nfrom clients.inn_nalog_client import NalogApiClient\nfrom repositories.request_mongo_repository import RequestRepository\n\n\nclass ApplicationContainer(Container):\n\n    @singleton\n    @provider\n    def provide_settings(self) -> Settings:\n        return Settings()\n\n    @singleton\n    @provider\n    def provide_logger(self, settings: Settings) -> AppLogger:\n        logger = logging.getLogger(settings.app_name)\n        logger.setLevel(logging.DEBUG)\n        sh = logging.StreamHandler()\n        sh.setLevel(logging.DEBUG)\n        logger.setLevel(logging.DEBUG)\n        logger.addHandler(sh)\n        return AppLogger(logger)\n\n    @singleton\n    @provider\n    def provide_mongodb_connection(self, settings: Settings, logger: AppLogger) -> MongoConnectionManager:\n        return MongoConnectionManager(settings, logger)\n\n    @singleton\n    @provider\n    def provide_rabbitmq_connection(self, settings: Settings, logger: AppLogger) -> RabbitConnectionManager:\n        return RabbitConnectionManager(settings, logger)\n\n    @singleton\n    @provider\n    def provide_nalog_api_client(self, settings: Settings, logger: AppLogger) -> NalogApiClient:\n        return NalogApiClient(settings, logger)\n\n    @singleton\n    @provider\n    def provide_request_repository(self, settings: Settings, mongo_connection: MongoConnectionManager) -> RequestRepository:\n        return RequestRepository(mongo_connection, settings)\n\n    @singleton\n    @provider\n    def provide_inn_service(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            nalog_api_client: NalogApiClient,\n            request_repository: RequestRepository\n    ) -> InnService:\n        return InnService(settings, logger, nalog_api_client, request_repository)\n\n    @singleton\n    @provider\n    def provide_queue_manager(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            rabbitmq: RabbitConnectionManager\n    ) -> QueueManager:\n        return QueueManager(settings, logger, rabbitmq)\n\n    @singleton\n    @provider\n    def provide_request_handler(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            inn_service: InnService,\n            rabbitmq_connection_manager: RabbitConnectionManager\n    ) -> RequestHandler:\n        return RequestHandler(settings, logger, rabbitmq_connection_manager, inn_service)\n\n    @singleton\n    @provider\n    def provide_live_probe_service(self, logger: AppLogger) -> LiveProbeService:\n        return LiveProbeService(logger)", "class ApplicationContainer(Container):\n\n    @singleton\n    @provider\n    def provide_settings(self) -> Settings:\n        return Settings()\n\n    @singleton\n    @provider\n    def provide_logger(self, settings: Settings) -> AppLogger:\n        logger = logging.getLogger(settings.app_name)\n        logger.setLevel(logging.DEBUG)\n        sh = logging.StreamHandler()\n        sh.setLevel(logging.DEBUG)\n        logger.setLevel(logging.DEBUG)\n        logger.addHandler(sh)\n        return AppLogger(logger)\n\n    @singleton\n    @provider\n    def provide_mongodb_connection(self, settings: Settings, logger: AppLogger) -> MongoConnectionManager:\n        return MongoConnectionManager(settings, logger)\n\n    @singleton\n    @provider\n    def provide_rabbitmq_connection(self, settings: Settings, logger: AppLogger) -> RabbitConnectionManager:\n        return RabbitConnectionManager(settings, logger)\n\n    @singleton\n    @provider\n    def provide_nalog_api_client(self, settings: Settings, logger: AppLogger) -> NalogApiClient:\n        return NalogApiClient(settings, logger)\n\n    @singleton\n    @provider\n    def provide_request_repository(self, settings: Settings, mongo_connection: MongoConnectionManager) -> RequestRepository:\n        return RequestRepository(mongo_connection, settings)\n\n    @singleton\n    @provider\n    def provide_inn_service(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            nalog_api_client: NalogApiClient,\n            request_repository: RequestRepository\n    ) -> InnService:\n        return InnService(settings, logger, nalog_api_client, request_repository)\n\n    @singleton\n    @provider\n    def provide_queue_manager(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            rabbitmq: RabbitConnectionManager\n    ) -> QueueManager:\n        return QueueManager(settings, logger, rabbitmq)\n\n    @singleton\n    @provider\n    def provide_request_handler(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            inn_service: InnService,\n            rabbitmq_connection_manager: RabbitConnectionManager\n    ) -> RequestHandler:\n        return RequestHandler(settings, logger, rabbitmq_connection_manager, inn_service)\n\n    @singleton\n    @provider\n    def provide_live_probe_service(self, logger: AppLogger) -> LiveProbeService:\n        return LiveProbeService(logger)", ""]}
{"filename": "src/inn_service/connection_managers/mongo_connection_manager.py", "chunked_list": ["from typing import List, Any, Coroutine\n\nfrom motor.motor_asyncio import AsyncIOMotorClient\nfrom pymongo.errors import ServerSelectionTimeoutError, OperationFailure\nfrom pymongo.mongo_client import MongoClient\n\nfrom core.event_mixins import EventLiveProbeMixin, LiveProbeStatus, StartupEventMixin, ShutdownEventMixin\nfrom core.exceptions import MongoConnectionError\nfrom settings import Settings\nfrom logger import AppLogger", "from settings import Settings\nfrom logger import AppLogger\n\n\nclass MongoConnectionManager(StartupEventMixin, ShutdownEventMixin, EventLiveProbeMixin):\n\n    def __init__(self, settings: Settings, logger: AppLogger):\n        self.logger = logger\n        self._mongodb_uri = settings.mongo_dsn\n        self._mongo_db = settings.mongo_name\n        self._timeout = settings.mongo_timeout_server_select\n        self._connection: AsyncIOMotorClient = AsyncIOMotorClient(\n            self._mongodb_uri,\n            serverSelectionTimeoutMS=self._timeout,\n            connect=False\n        )\n\n    def shutdown(self) -> Coroutine:\n        return self.close_connection()\n\n    def startup(self) -> Coroutine:\n        return self.create_connection()\n\n    async def get_connection(self) -> AsyncIOMotorClient:\n        is_connected = await self.is_connected()\n        if is_connected.status:\n            return self._connection\n        else:\n            await self.create_connection()\n            return self._connection\n\n    async def create_connection(self) -> None:\n        self.logger.info('Create connection MongoDB')\n        try:\n            db = self._connection.get_database(self._mongo_db)\n            await db.list_collection_names()\n        except (ServerSelectionTimeoutError, OperationFailure) as exc:\n            self.logger.error('Error connected to Mongo', details=str(exc))\n            raise MongoConnectionError(str(exc))\n\n    async def close_connection(self):\n        if self._connection is not None:\n            self._connection.close()\n\n    async def is_connected(self) -> LiveProbeStatus:\n        try:\n            db = self._connection.get_database(self._mongo_db)\n            await db.list_collection_names()\n            status = True\n        except ServerSelectionTimeoutError:\n            status = False\n\n        return LiveProbeStatus(service_name='MongoDb', status=status)", ""]}
{"filename": "src/inn_service/connection_managers/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/connection_managers/rabbitmq_connection_manager.py", "chunked_list": ["import json\nfrom typing import Optional, Coroutine, Callable\n\nfrom aio_pika import Exchange, connect_robust, Message, Channel\nfrom aio_pika.connection import Connection\nfrom aiormq.exceptions import ChannelPreconditionFailed\n\nfrom core.event_mixins import EventLiveProbeMixin, LiveProbeStatus, StartupEventMixin, ShutdownEventMixin\nfrom settings import Settings\nfrom logger import AppLogger", "from settings import Settings\nfrom logger import AppLogger\n\n\nclass RabbitConnectionManager(StartupEventMixin, ShutdownEventMixin, EventLiveProbeMixin):\n    def __init__(self, settings: Settings, logger: AppLogger) -> None:\n        self._dsn = settings.rabbitmq_dsn\n        self.prefetch_count = settings.rabbitmq_prefetch_count\n        self.exchange_type = settings.rabbitmq_exchange_type\n        self._connection = None\n        self._channel = None\n        self._exchange = None\n        self.connected: bool = False\n        self.logger = logger\n\n    def shutdown(self) -> Coroutine:\n        return self.close_connection()\n\n    def startup(self) -> Coroutine:\n        return self.create_connection()\n\n    async def is_connected(self) -> LiveProbeStatus:\n        return LiveProbeStatus(service_name='RabbitMQ', status=self.connected)\n\n    async def create_connection(self) -> None:\n        self.logger.info('Create connection RabbitMQ')\n        try:\n            self._connection = await connect_robust(self._dsn)\n            self._connection.reconnect_callbacks.add(self.on_connection_restore)\n            self._connection.close_callbacks.add(self.on_close_connection)\n            self.connected = True\n        except ConnectionError as exc:\n            err_message = f'Rabbit connection problem: {exc}'\n            self.logger.error(err_message)\n            raise ConnectionError(err_message)\n\n    async def close_connection(self) -> None:\n        if self._connection:\n            await self._connection.close()\n\n    async def get_connection(self) -> Connection:\n        return self._connection\n\n    async def get_channel(self) -> Channel:\n        if not self._channel:\n            connection = await self.get_connection()\n            self._channel = await connection.channel()\n            await self._channel.set_qos(prefetch_count=self.prefetch_count)\n        return self._channel\n\n    async def get_exchange(self) -> Exchange:\n        if not self._exchange:\n            channel = await self.get_channel()\n            self._exchange = await channel.declare_exchange(self.exchange_type, auto_delete=False, durable=True)\n        return self._exchange\n\n    async def delete_dl_queue_after_error(self, dl_queue_name: str) -> None:\n        connection = await self.get_connection()\n        self._channel = await connection.channel()\n        channel = await self.get_channel()\n        await channel.queue_delete(dl_queue_name)\n\n    async def create_dl_queue(self, queue_name: str, ttl: int):\n        channel = await self.get_channel()\n        exchange = await self.get_exchange()\n        dead_letter_queue_arguments = {\n            'x-dead-letter-exchange': exchange.name,\n            'x-dead-letter-routing-key': queue_name,\n            'x-message-ttl': ttl\n        }\n\n        dead_queue = await channel.declare_queue(\n            f'dl-{queue_name}',\n            auto_delete=False,\n            durable=True,\n            arguments=dead_letter_queue_arguments\n        )\n        await dead_queue.bind(exchange)\n\n    async def create_queue_listener(\n            self,\n            queue_name: str,\n            callback_worker: Callable,\n            use_retry: bool = False,\n            retry_ttl: int = 0,\n    ) -> None:\n        channel = await self.get_channel()\n        exchange = await self.get_exchange()\n\n        dl_queue_name = f'dl-{queue_name}'\n        queue_arguments = {}\n\n        if use_retry:\n            queue_arguments['x-dead-letter-exchange'] = exchange.name\n            queue_arguments['x-dead-letter-routing-key'] = dl_queue_name\n            try:\n                await self.create_dl_queue(queue_name=queue_name, ttl=retry_ttl)\n            except ChannelPreconditionFailed:\n                self.logger.warning('PRECONDITION_FAILED - trying to reset Dead Letter queue')\n                await self.delete_dl_queue_after_error(dl_queue_name=dl_queue_name)\n                await self.create_queue_listener(queue_name, callback_worker, use_retry, retry_ttl)\n                self.logger.info(f'Dead Letter queue <{dl_queue_name}> recreated')\n                return\n\n        queue = await channel.declare_queue(queue_name, auto_delete=False, durable=True, arguments=queue_arguments)\n        await queue.bind(exchange)\n        await queue.consume(callback_worker)\n\n    async def declare_queue(\n            self,\n            name: str,\n            dead_exchange: Optional[str] = None,\n            dead_queue_name: Optional[str] = None\n    ) -> None:\n        if dead_queue_name:\n            queue_arguments = {\n                'x-dead-letter-exchange': dead_exchange,\n                'x-dead-letter-routing-key': dead_queue_name\n            }\n        else:\n            queue_arguments = {}\n        connection = await self.get_connection()\n        channel = await connection.channel()\n        exchange = await self.get_exchange()\n        queue = await channel.declare_queue(name, auto_delete=False, durable=True, arguments=queue_arguments)\n        await queue.bind(exchange, name)\n\n    async def send_data_in_queue(self, data: dict, queue_name: str) -> None:\n        data_bytes = json.dumps(data).encode()\n        exchange = await self.get_exchange()\n        self.logger.debug(f'Send message in \"{queue_name}\". Message: {data}')\n        await exchange.publish(Message(data_bytes), routing_key=queue_name)\n\n    def on_close_connection(self, *args):\n        self.logger.error('Lost connection to RabbitMQ...')\n        self.connected = False\n\n    def on_connection_restore(self, *args):\n        self.logger.info('Connection to RabbitMQ has been restored...')\n        self._channel = None\n        self._exchange = None\n        self.connected = True", ""]}
{"filename": "src/inn_service/infrastructure/handlers/base_handler.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Optional\n\nfrom logger import AppLogger\n\n\nfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\nfrom settings import Settings\n\n\nclass BaseHandler(ABC):\n    \"\"\"\n    \u0411\u0430\u0437\u043e\u0432\u044b\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\n    \"\"\"\n    def __init__(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            rabbitmq_connection: RabbitConnectionManager\n    ) -> None:\n        self.settings = settings\n        self.logger = logger\n        self.rabbitmq_connection = rabbitmq_connection\n\n    def __repr__(self):\n        return self.handler_name()\n\n    def handler_name(self) -> str:\n        return 'BaseHandler'\n\n    @abstractmethod\n    def get_use_retry(self) -> bool:\n        raise NotImplementedError\n\n    def get_retry_ttl(self) -> int:\n        return 0\n\n    @abstractmethod\n    def get_source_queue(self) -> str:\n        raise NotImplementedError\n\n    def convert_seconds_to_mseconds(self, value: int) -> int:\n        return value * 1000\n\n    @abstractmethod\n    def get_error_response(self, request_id: str, error_message: str) -> dict:\n        raise NotImplementedError\n\n    @abstractmethod\n    async def run_handler(\n            self,\n            message: dict,\n            request_id: Optional[str],\n            result_queue: Optional[str],\n            count_retry: Optional[int] = 0\n    ) -> bool:\n        raise NotImplementedError", "\n\nclass BaseHandler(ABC):\n    \"\"\"\n    \u0411\u0430\u0437\u043e\u0432\u044b\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\n    \"\"\"\n    def __init__(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            rabbitmq_connection: RabbitConnectionManager\n    ) -> None:\n        self.settings = settings\n        self.logger = logger\n        self.rabbitmq_connection = rabbitmq_connection\n\n    def __repr__(self):\n        return self.handler_name()\n\n    def handler_name(self) -> str:\n        return 'BaseHandler'\n\n    @abstractmethod\n    def get_use_retry(self) -> bool:\n        raise NotImplementedError\n\n    def get_retry_ttl(self) -> int:\n        return 0\n\n    @abstractmethod\n    def get_source_queue(self) -> str:\n        raise NotImplementedError\n\n    def convert_seconds_to_mseconds(self, value: int) -> int:\n        return value * 1000\n\n    @abstractmethod\n    def get_error_response(self, request_id: str, error_message: str) -> dict:\n        raise NotImplementedError\n\n    @abstractmethod\n    async def run_handler(\n            self,\n            message: dict,\n            request_id: Optional[str],\n            result_queue: Optional[str],\n            count_retry: Optional[int] = 0\n    ) -> bool:\n        raise NotImplementedError", ""]}
{"filename": "src/inn_service/infrastructure/handlers/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/infrastructure/handlers/request_handler.py", "chunked_list": ["from typing import Optional\n\nfrom logger import AppLogger\n\nfrom infrastructure.handlers.base_handler import BaseHandler\nfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\nfrom settings import Settings\nfrom services.inn_service import InnService\nfrom models.model import ClientDataDTO\nfrom core.exceptions import HandlerNoRequestIdException", "from models.model import ClientDataDTO\nfrom core.exceptions import HandlerNoRequestIdException\nfrom serializers.request_serializer import RequestMqSerializer\n\n\nclass RequestHandler(BaseHandler):\n    def __init__(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            rabbitmq_connection: RabbitConnectionManager,\n            service: InnService\n    ) -> None:\n        super().__init__(settings, logger, rabbitmq_connection)\n        self.source_queue_name = self.settings.rabbitmq_source_queue_name\n        self.retry_times = self.settings.app_request_retry_times\n        self.retry_sec = self.settings.app_request_retry_sec\n        self.service = service\n\n    def handler_name(self) -> str:\n        return 'RequestHandler'\n\n    def get_source_queue(self) -> str:\n        return self.source_queue_name\n\n    def get_use_retry(self) -> bool:\n        return True\n\n    def get_retry_ttl(self) -> int:\n        return self.retry_sec\n\n    def get_error_response(self, request_id: str, error_message: str) -> dict:\n        response = ClientDataDTO(\n            request_id=request_id,\n            inn='',\n            details=error_message,\n            elapsed_time=0\n        )\n        return response.dict(by_alias=True)\n\n    async def run_handler(\n            self,\n            message: dict,\n            request_id: Optional[str],\n            result_queue: Optional[str],\n            count_retry: Optional[int] = 0\n    ) -> bool:\n        if count_retry > self.retry_times:\n            self.logger.warning(f'Request {request_id} was rejected by excess attempts {self.retry_times} times')\n            return True\n\n        if not request_id:\n            raise HandlerNoRequestIdException\n\n        self.logger.info(f'Get request {request_id} for response {result_queue}')\n\n        client_data = RequestMqSerializer.parse_obj(message)\n\n        response = await self.service.get_client_inn(client_data)\n\n        if result_queue:\n            json_message = response.dict()\n            await self.rabbitmq_connection.send_data_in_queue(json_message, result_queue)\n\n        return True", ""]}
{"filename": "src/inn_service/infrastructure/queue_manager/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/infrastructure/queue_manager/queue_manager.py", "chunked_list": ["import json\nfrom typing import List, Callable\n\nfrom aio_pika import IncomingMessage\nfrom logger import AppLogger\nfrom pydantic import ValidationError\n\nfrom connection_managers.rabbitmq_connection_manager import RabbitConnectionManager\nfrom infrastructure.handlers.base_handler import BaseHandler\nfrom settings import Settings", "from infrastructure.handlers.base_handler import BaseHandler\nfrom settings import Settings\n\n\nclass QueueManager:\n    \"\"\"\n    \u041c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 mq \u0434\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439\n    \"\"\"\n\n    def __init__(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            queue_connection_manager: RabbitConnectionManager\n    ) -> None:\n        self.settings = settings\n        self.logger = logger\n        self.connection_manager = queue_connection_manager\n        self._handlers: List[BaseHandler] = []\n        self._exchange = None\n\n    def add_handler(self, item: BaseHandler):\n        self._handlers.append(item)\n\n    async def run_handlers_async(self) -> None:\n        \"\"\"\n        \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u043e\u0432\n        \"\"\"\n        for handler in self._handlers:\n            await self._create_consumer(handler)\n\n    async def _create_consumer(self, item: BaseHandler) -> None:\n        self.logger.info(f'Create consumer for {item.get_source_queue()}')\n        await self.connection_manager.create_queue_listener(\n            item.get_source_queue(),\n            self.make_consumer_function(item),\n            item.get_use_retry(),\n            item.get_retry_ttl()\n        )\n\n    async def _send_error_response(self, response: dict, queue: str) -> None:\n        await self.connection_manager.send_data_in_queue(response, queue)\n\n    def _get_message_retry(self, message: IncomingMessage) -> int:\n        \"\"\"\n        \u041f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0432\u0442\u043e\u0440\u043e\u0432 \u043f\u0435\u0440\u0435\u0441\u044b\u043b\u043a\u0438 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f\n        \"\"\"\n        count_retry = 0\n        x_death = message.headers.get('x-death', [])\n        if len(x_death) > 0:\n            count_retry = x_death[0].get('count', 0)\n        return count_retry\n\n    def make_consumer_function(self, handler: BaseHandler) -> Callable:\n        \"\"\"\n        \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439 \u0438\u0437 mq\n        \"\"\"\n\n        async def _function(message: IncomingMessage) -> None:\n            message_content = message.body.decode('utf-8')\n            result_queue = message.reply_to\n            request_id = None\n\n            try:\n                data = json.loads(message_content)\n                request_id = data.get('requestId')\n                count_retry = self._get_message_retry(message)\n\n                is_processed = await handler.run_handler(data, request_id, result_queue, count_retry)\n\n                if is_processed:\n                    await message.ack()\n                else:\n                    await message.reject()\n\n            except json.JSONDecodeError as exc:\n                self.logger.error('Unable to parse message.', details=str(exc), message=message_content)\n                await message.ack()\n\n            except ValidationError as exc:\n                error_message = f'Request body content error. {str(exc.errors())}'\n                self.logger.error(error_message)\n                if result_queue:\n                    response = handler.get_error_response(request_id, error_message)\n                    await self._send_error_response(response, result_queue)\n                await message.ack()\n\n            except Exception as ex:\n                error_message = f'Handler {handler=} error. Type error: {type(ex)=}, message: {str(ex)}'\n                self.logger.error(error_message, reply_to=result_queue, request_id=request_id)\n                if result_queue:\n                    response = handler.get_error_response(request_id, error_message)\n                    await self._send_error_response(response, result_queue)\n                await message.ack()\n\n        return _function", ""]}
{"filename": "src/inn_service/infrastructure/controllers/base_controller.py", "chunked_list": ["from fastapi import Depends\nfrom injector import Injector\n\nfrom core.container_manager import get_container_injector\n\n\nclass BaseController:\n    injector: Injector = Depends(get_container_injector)\n", ""]}
{"filename": "src/inn_service/infrastructure/controllers/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/infrastructure/controllers/liveprobe_controller.py", "chunked_list": ["from fastapi.responses import Response\nfrom fastapi_utils.cbv import cbv\nfrom fastapi_utils.inferring_router import InferringRouter\n\nfrom infrastructure.controllers.base_controller import BaseController\nfrom services.live_probe_service import LiveProbeService\n\nrouter = InferringRouter()\n\n", "\n\n@cbv(router)\nclass CoreController(BaseController):\n\n    def __init__(self):\n        self.live_probe_service = self.injector.get(LiveProbeService)\n\n    @router.get('/livez')\n    async def check_health(self):\n        is_success = await self.live_probe_service.get_component_status()\n        status_code = 200 if is_success else 500\n        return Response(status_code=status_code)", ""]}
{"filename": "src/inn_service/infrastructure/http_server/http_server_manager.py", "chunked_list": ["from typing import Optional\n\nfrom fastapi import FastAPI\nfrom injector import Injector\nfrom uvicorn import Server, Config\n\nfrom services.live_probe_service import LiveProbeService\nfrom settings import Settings\nfrom infrastructure.controllers.liveprobe_controller import router as infrastructure_route\n", "from infrastructure.controllers.liveprobe_controller import router as infrastructure_route\n\n\nclass ServerApplication(FastAPI):\n\n    def __init__(self, container: Injector) -> None:\n        self.container = container\n        settings_ = self.container.get(Settings)\n        super(ServerApplication, self).__init__(title=settings_.app_name)\n        self.live_probe_service = self.container.get(LiveProbeService)\n        self._include_routes()\n\n    def _include_routes(self) -> None:\n        self.include_router(infrastructure_route, tags=['Core'])", "\n\nclass ServerAPIManager:\n\n    def __init__(self, container: Injector) -> None:\n        self.container = container\n        settings = self.container.get(Settings)\n        self.host = settings.http_host\n        self.port = settings.http_port\n        self.http_handler = settings.http_handler\n        self.api_server: Optional[Server] = None\n        self.api_application = None\n\n        self.init_api_server()\n\n    async def serve(self) -> None:\n        await self.api_server.serve()\n\n    async def shutdown_server(self):\n        if self.api_server and self.api_server.started:\n            await self.api_server.shutdown()\n\n    def init_api_server(self) -> None:\n        self.api_application = ServerApplication(self.container)\n        config = Config(\n            app=self.api_application,\n            loop=self.http_handler,\n            host=self.host,\n            port=self.port,\n            access_log=False,\n            log_config=None,\n        )\n        self.api_server = Server(config)", ""]}
{"filename": "src/inn_service/infrastructure/http_server/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/repositories/request_mongo_repository.py", "chunked_list": ["from typing import Iterable, Optional\n\nfrom pymongo import ASCENDING\n\nfrom repositories.base_mongo_repository import BaseRepository\nfrom connection_managers.mongo_connection_manager import MongoConnectionManager\nfrom repositories.base_mongo_repository import IndexDef\nfrom models.model import ClientDataModel\nfrom settings import Settings\n", "from settings import Settings\n\n\nclass RequestRepository(BaseRepository):\n\n    def __init__(self, connection_manager: MongoConnectionManager, settings: Settings):\n        super().__init__(connection_manager, settings)\n\n    @property\n    def collection_name(self) -> str:\n        return 'clients'\n\n    @property\n    def collection_indexes(self) -> Iterable[IndexDef]:\n        return [\n            IndexDef(name='passport_num', sort=ASCENDING),\n            IndexDef(name='request_id', sort=ASCENDING),\n        ]\n\n    async def save_client_data(self, request: ClientDataModel) -> str:\n        record_id = await self.save_document(request.dict())\n        return str(record_id)\n\n    async def find_client_data(self, passport_num: str, request_id: str) -> Optional[ClientDataModel]:\n        criteria = {\n            '$or': [\n                {'passport_num': passport_num},\n                {'request_id': request_id}\n            ]\n        }\n        result = await self.get_one_document(criteria)\n        if result:\n            return ClientDataModel(**result)\n\n    async def update_client_data(self, request_id: str, replacement_data: dict) -> None:\n        await self.update_document(\n            {\n                'request_id': request_id\n            },\n            replacement_data\n        )", ""]}
{"filename": "src/inn_service/repositories/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/repositories/base_mongo_repository.py", "chunked_list": ["import asyncio\nfrom dataclasses import dataclass\nfrom typing import Optional, List, Iterable, Coroutine\n\nfrom connection_managers.mongo_connection_manager import MongoConnectionManager\nfrom core.event_mixins import StartupEventMixin\nfrom settings import Settings\n\n\n@dataclass\nclass IndexDef:\n    name: str\n    sort: int", "\n@dataclass\nclass IndexDef:\n    name: str\n    sort: int\n\n\nclass BaseRepository(StartupEventMixin):\n\n    def __init__(self, mongodb_connection_manager: MongoConnectionManager, setting: Settings) -> None:\n        self.mongodb_connection_manager = mongodb_connection_manager\n        self.db_name = setting.mongo_name\n\n    @property\n    def collection_name(self) -> str:\n        raise NotImplementedError\n\n    @property\n    def collection_indexes(self) -> Iterable[IndexDef]:\n        raise NotImplementedError\n\n    def startup(self) -> Coroutine:\n        return self.create_indexes()\n\n    async def create_index(self, field_name: str, sort_id: int) -> None:\n        \"\"\"\n        \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438\u043d\u0434\u0435\u043a\u0441\u0430 \u0432 \u0444\u043e\u043d\u0435\n        \"\"\"\n        connection = await self.mongodb_connection_manager.get_connection()\n        collection = connection[self.db_name][self.collection_name]\n        await collection.create_index([(field_name, sort_id), ], background=True)\n\n    async def create_indexes(self) -> None:\n        \"\"\"\n        \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0432\u0441\u0435\u0445 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0445 \u0438\u043d\u0434\u0435\u043a\u0441\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u043e\u0440\u0438\u044f\n        \"\"\"\n        tasks = []\n        for index_item in self.collection_indexes:\n            tasks.append(self.create_index(index_item.name, index_item.sort))\n        asyncio.ensure_future(asyncio.gather(*tasks))\n\n    async def get_one_document(self, criteria: dict) -> Optional[dict]:\n        connection = await self.mongodb_connection_manager.get_connection()\n        collection = connection[self.db_name][self.collection_name]\n        return await collection.find_one(criteria)\n\n    async def get_list_document(\n            self,\n            criteria: dict,\n            sort_criteria: Optional[list] = None,\n            limit: Optional[int] = 0,\n            skip: Optional[int] = 0,\n    ) -> List[dict]:\n        if not sort_criteria:\n            sort_criteria = []\n        connection = await self.mongodb_connection_manager.get_connection()\n        cursor = connection[self.db_name][self.collection_name].find(\n            criteria,\n            limit=limit,\n            skip=skip,\n            sort=sort_criteria\n        )\n\n        result = list()\n        async for data in cursor:\n            result.append(data)\n        return result\n\n    async def save_document(self, data: dict) -> str:\n        connection = await self.mongodb_connection_manager.get_connection()\n        result = await connection[self.db_name][self.collection_name].insert_one(data)\n        return result.inserted_id\n\n    async def update_document(self, criteria: dict, data: dict) -> None:\n        connection = await self.mongodb_connection_manager.get_connection()\n        await connection[self.db_name][self.collection_name].update_one(criteria, {'$set': data})", ""]}
{"filename": "src/inn_service/serializers/request_serializer.py", "chunked_list": ["from datetime import date\nfrom pydantic import BaseModel, Field\n\n\nclass RequestMqSerializer(BaseModel):\n    request_id: str = Field(alias='requestId')\n    first_name: str = Field(alias='firstName')\n    last_name: str = Field(alias='lastName')\n    middle_name: str = Field(alias='middleName')\n    birth_date: date = Field(alias='birthDate')\n    document_serial: str = Field(alias='documentSerial')\n    document_number: str = Field(alias='documentNumber')\n    document_date: date = Field(alias='documentDate')", ""]}
{"filename": "src/inn_service/serializers/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/serializers/nalog_api_serializer.py", "chunked_list": ["from pydantic import BaseModel, Field\n\nfrom serializers.request_serializer import RequestMqSerializer\n\n\nclass NalogApiRequestSerializer(BaseModel):\n    last_name: str = Field(None, alias='fam')\n    first_name: str = Field(None, alias='nam')\n    middle_name: str = Field('\u043d\u0435\u0442', alias='otch')\n    birth_date: str = Field(None, alias='bdate')\n    birth_place: str = Field('', alias='bplace')\n    doc_type: int = Field(21, alias='doctype')\n    doc_number: str = Field(None, alias='docno')\n    doc_date: str = Field(None, alias='docdt')\n    type: str = Field('innMy', alias='c')\n    captcha: str = Field('', alias='captcha')\n    captchaToken: str = Field('', alias='captchaToken')\n\n    @property\n    def client_fullname(self):\n        return f'{self.last_name} {self.first_name} {self.middle_name}'\n\n    @classmethod\n    def create_from_request(cls, request: RequestMqSerializer) -> 'NalogApiRequestSerializer':\n        document_number = '{} {} {}'.format(\n            request.document_serial[0:2],\n            request.document_serial[2:4],\n            request.document_number\n        )\n        return NalogApiRequestSerializer(\n            last_name=request.last_name,\n            first_name=request.first_name,\n            middle_name=request.middle_name,\n            birth_date=request.birth_date.strftime('%d.%m.%Y'),\n            doc_number=document_number,\n            doc_date=request.document_date.strftime('%d.%m.%Y')\n        )\n\n    class Config:\n        allow_population_by_field_name = True", ""]}
{"filename": "src/inn_service/models/model.py", "chunked_list": ["from typing import Optional\nfrom pydantic import BaseModel, Field\nfrom datetime import date, datetime\n\nfrom serializers.request_serializer import RequestMqSerializer\n\n\nclass ClientDataModel(BaseModel):\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n    request_id: str\n    first_name: str\n    last_name: str\n    middle_name: str\n    birth_date: datetime\n    birth_place: str = Field(default='')\n    passport_num: str\n    document_date: datetime\n    executed_at: Optional[datetime]\n    inn: Optional[str]\n    error: Optional[str]\n\n    @classmethod\n    def create_from_request(cls, request: RequestMqSerializer) -> 'ClientDataModel':\n        return ClientDataModel(\n            request_id=request.request_id,\n            first_name=request.first_name,\n            last_name=request.last_name,\n            middle_name=request.middle_name,\n            birth_date=datetime.combine(request.birth_date, datetime.min.time()),\n            passport_num='{} {}'.format(request.document_serial, request.document_number),\n            document_date=datetime.combine(request.document_date, datetime.min.time()),\n        )\n\n    @property\n    def elapsed_time(self) -> float:\n        end = self.executed_at or datetime.utcnow()\n        return (end - self.created_at).total_seconds()", "\n\nclass ClientDataDTO(BaseModel):\n    request_id: Optional[str] = Field(alias='requestId')\n    inn: str = Field(alias='inn')\n    details: Optional[str] = Field('', alias='details')\n    cashed: bool = Field(False, alias='cached')\n    elapsed_time: float = Field(alias='elapsedTime')\n\n    class Config:\n        allow_population_by_field_name = True"]}
{"filename": "src/inn_service/models/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/clients/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/clients/utils.py", "chunked_list": ["from typing import Tuple\nfrom asyncio import sleep\n\nfrom logger import AppLogger\n\n\ndef retry(exceptions: Tuple, logger: AppLogger, attempts: int = 3, wait_sec: int = 1):\n    def decorator(func):\n        async def wrapper(*args, **kwargs):\n            exc = None\n            for attempt in range(1, attempts + 1):\n                try:\n                    return await func(*args, **kwargs)\n                except exceptions as error:\n                    logger.exception('Call http query error', func=func.__name__, attempt=attempt, retriable=True)\n                    await sleep(wait_sec)\n                    exc = error\n                except Exception:\n                    logger.exception('Call http query error', func=func.__name__, attempt=attempt, retriable=False)\n                    raise\n            raise exc\n\n        return wrapper\n\n    return decorator", ""]}
{"filename": "src/inn_service/clients/inn_nalog_client.py", "chunked_list": ["import http\nfrom logger import AppLogger\nfrom typing import Optional\n\nimport aiohttp\n\nfrom clients.utils import retry\nfrom core.exceptions import NalogApiClientException\nfrom serializers.nalog_api_serializer import NalogApiRequestSerializer\nfrom settings import Settings", "from serializers.nalog_api_serializer import NalogApiRequestSerializer\nfrom settings import Settings\n\n\nclass NalogApiClient:\n    CLIENT_EXCEPTIONS = (\n        NalogApiClientException,\n        aiohttp.ClientProxyConnectionError,\n        aiohttp.ServerTimeoutError,\n    )\n\n    def __init__(self, settings: Settings, logger: AppLogger) -> None:\n        self.nalog_api_service_url = settings.client_nalog_url\n        self.request_timeout = settings.client_nalog_timeout_sec\n        self.retries_times = settings.client_nalog_retries\n        self.retries_wait = settings.client_nalog_wait_sec\n        self.logger = logger\n        self.timeout = aiohttp.ClientTimeout(total=self.request_timeout)\n\n    @property\n    def _headers(self):\n        return {\n            \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n            \"Accept-Language\": \"ru-RU,ru\",\n            \"Connection\": \"keep-alive\",\n            \"Origin\": \"https://service.nalog.ru\",\n            \"Referer\": \"https://service.nalog.ru/inn.do\",\n            \"Sec-Fetch-Dest\": \"empty\",\n            \"Sec-Fetch-Mode\": \"cors\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-GPC\": \"1\",\n            \"X-Requested-With\": \"XMLHttpRequest\",\n        }\n\n    async def send_request_for_inn(self, nalog_api_request: NalogApiRequestSerializer) -> Optional[str]:\n        \"\"\"\n        \u041e\u0442\u043f\u0440\u0430\u0432\u043a\u0430 \u0437\u0430\u043f\u0440\u043e\u0441\u0430 \u0432 API service.nalog.ru\n        \"\"\"\n        self.logger.debug(f'Request to nalog api service for {nalog_api_request.client_fullname}')\n\n        form_data = nalog_api_request.dict(by_alias=True)\n\n        @retry(self.CLIENT_EXCEPTIONS, logger=self.logger, attempts=self.retries_times, wait_sec=self.retries_wait)\n        async def make_request(client_session: aiohttp.ClientSession):\n            async with client_session.post(url=self.nalog_api_service_url, data=form_data) as response:\n                if response.status not in [http.HTTPStatus.OK, http.HTTPStatus.NOT_FOUND]:\n                    response_text = await response.text()\n                    raise NalogApiClientException(response_text)\n                data = await response.json()\n                code = data.get('code')\n                captcha_required = data.get('captchaRequired')\n                if captcha_required:\n                    raise NalogApiClientException(f'Captcha required for request {nalog_api_request.client_fullname}')\n                if code == 0:\n                    return 'no inn'\n                elif code == 1:\n                    return data.get('inn')\n                else:\n                    raise NalogApiClientException(f'Unable to parse response! Details: {response}')\n\n        async with aiohttp.ClientSession(timeout=self.timeout, headers=self._headers) as session:\n            return await make_request(session)", ""]}
{"filename": "src/inn_service/core/event_mixins.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Coroutine\n\nfrom pydantic import BaseModel\n\n\nclass LiveProbeStatus(BaseModel):\n    service_name: str\n    status: bool\n", "\n\nclass EventLiveProbeMixin(ABC):\n\n    @abstractmethod\n    def is_connected(self) -> LiveProbeStatus:\n        raise NotImplementedError\n\n\nclass StartupEventMixin(ABC):\n\n    @abstractmethod\n    def startup(self) -> Coroutine:\n        raise NotImplementedError", "\nclass StartupEventMixin(ABC):\n\n    @abstractmethod\n    def startup(self) -> Coroutine:\n        raise NotImplementedError\n\n\nclass ShutdownEventMixin(ABC):\n\n    @abstractmethod\n    def shutdown(self) -> Coroutine:\n        raise NotImplementedError", "class ShutdownEventMixin(ABC):\n\n    @abstractmethod\n    def shutdown(self) -> Coroutine:\n        raise NotImplementedError\n"]}
{"filename": "src/inn_service/core/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/core/container_manager.py", "chunked_list": ["import asyncio\nfrom abc import ABC, abstractmethod\nfrom typing import Type, List, Callable\n\nfrom injector import singleton, provider, Injector, Module\nfrom starlette.requests import Request\n\nfrom core.event_mixins import EventLiveProbeMixin, StartupEventMixin, ShutdownEventMixin\nfrom settings import Settings\n", "from settings import Settings\n\n\nclass Container(ABC, Module):\n\n    @singleton\n    @provider\n    @abstractmethod\n    def provide_settings(self) -> Settings:\n        return Settings()", "\n\nclass ContainerManager:\n\n    def __init__(self, cls_container: Type[Container]) -> None:\n        self._container = Injector(cls_container())\n        self._bindings = self._container.binder._bindings\n\n    def get_container(self) -> Injector:\n        return self._container\n\n    def get_live_probe_handlers(self) -> List[Type[Callable]]:\n        \"\"\"\n        \u041f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0441\u043f\u0438\u0441\u043e\u043a \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u043e\u0432 \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u044e\u0449\u0438\u0445 \u043c\u0438\u043a\u0441\u0438\u043d\u0443 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 liveness probe EventLiveProbeMixin\n        \"\"\"\n        result = []\n        binding_collection = [binding for binding in self._bindings]\n        for binding in binding_collection:\n            if issubclass(binding, EventLiveProbeMixin):\n                binding_obj = self._container.get(binding)\n                result.append(binding_obj.is_connected)\n        return result\n\n    def get_startup_handlers(self):\n        handlers = []\n        binding_collection = [binding for binding in self._bindings]\n        for binding in binding_collection:\n            if issubclass(binding, StartupEventMixin):\n                binding_obj = self._container.get(binding)\n                handlers.append(binding_obj.startup())\n        return handlers\n\n    def get_shutdown_handlers(self):\n        handlers = []\n        binding_collection = [binding for binding in self._bindings]\n        for binding in binding_collection:\n            if issubclass(binding, ShutdownEventMixin):\n                binding_obj = self._container.get(binding)\n                handlers.append(binding_obj.shutdown())\n        return handlers\n\n    async def run_startup(self) -> None:\n        exception = None\n        for handler in self.get_startup_handlers():\n            if exception:\n                handler.close()\n            else:\n                try:\n                    await handler\n                except Exception as exc:\n                    exception = exc\n\n        if exception is not None:\n            raise exception\n\n    async def run_shutdown(self) -> None:\n        handlers = []\n        for handler in self.get_shutdown_handlers():\n            handlers.append(handler)\n        await asyncio.gather(*handlers)", "\n\nasync def get_container_injector(request: Request) -> Container:\n    return request.app.container\n"]}
{"filename": "src/inn_service/core/application.py", "chunked_list": ["import asyncio\nfrom typing import Type\n\nfrom core.container_manager import Container, ContainerManager\nfrom infrastructure.queue_manager.queue_manager import QueueManager\nfrom infrastructure.http_server.http_server_manager import ServerAPIManager\nfrom infrastructure.handlers.request_handler import RequestHandler\nfrom services.live_probe_service import LiveProbeService\nfrom settings import Settings\nfrom logger import AppLogger", "from settings import Settings\nfrom logger import AppLogger\n\n\nclass Application:\n\n    def __init__(self, cls_container: Type[Container]) -> None:\n        self.loop = asyncio.get_event_loop()\n        self.container_manager = ContainerManager(cls_container)\n        self.container = self.container_manager.get_container()\n        self.settings = self.container.get(Settings)\n        self.logger = self.container.get(AppLogger)\n        self.live_probe_service = self.container.get(LiveProbeService)\n        self.queue_manager = self.container.get(QueueManager)\n        self.app_name = self.settings.app_name\n        self.http_server = None\n\n    def init_application(self):\n        self.http_server = ServerAPIManager(self.container)\n\n        request_handler = self.container.get(RequestHandler)\n        self.queue_manager.add_handler(request_handler)\n\n        live_probe_handlers = self.container_manager.get_live_probe_handlers()\n        for handler in live_probe_handlers:\n            self.live_probe_service.add_component(handler)\n\n    def run(self) -> None:\n        self.logger.info(f'Starting application {self.app_name}')\n\n        self.init_application()\n\n        try:\n            self.loop.run_until_complete(self.container_manager.run_startup())\n\n            tasks = asyncio.gather(\n                self.http_server.serve(),\n                self.queue_manager.run_handlers_async(),\n            )\n            self.loop.run_until_complete(tasks)\n\n            self.loop.run_forever()\n        except BaseException as exception:\n            exit(1)\n        finally:\n            self.loop.run_until_complete(self.container_manager.run_shutdown())\n\n            self.loop.close()\n            self.logger.info('Application disabled')", ""]}
{"filename": "src/inn_service/core/exceptions.py", "chunked_list": ["class MongoConnectionError(Exception):\n    def __init__(self, message: str):\n        self.message = message\n\n    def __str__(self):\n        return f'Mongo connection problem: {self.message}'\n\n\nclass NalogApiClientException(Exception):\n    pass", "class NalogApiClientException(Exception):\n    pass\n\n\nclass HandlerNoRequestIdException(Exception):\n    def __str__(self):\n        return 'Need to specify requestId attribute.'\n"]}
{"filename": "src/inn_service/services/__init__.py", "chunked_list": [""]}
{"filename": "src/inn_service/services/inn_service.py", "chunked_list": ["from typing import Optional\nfrom datetime import datetime\n\nfrom core.exceptions import NalogApiClientException\nfrom settings import Settings\nfrom logger import AppLogger\n\nfrom serializers.request_serializer import RequestMqSerializer\nfrom serializers.nalog_api_serializer import NalogApiRequestSerializer\nfrom clients.inn_nalog_client import NalogApiClient", "from serializers.nalog_api_serializer import NalogApiRequestSerializer\nfrom clients.inn_nalog_client import NalogApiClient\nfrom models.model import ClientDataModel, ClientDataDTO\nfrom repositories.request_mongo_repository import RequestRepository\n\n\nclass InnService:\n    def __init__(\n            self,\n            settings: Settings,\n            logger: AppLogger,\n            client: NalogApiClient,\n            storage: RequestRepository\n    ) -> None:\n        self.settings = settings\n        self.logger = logger\n        self.client = client\n        self.storage_repository = storage\n\n    async def get_client_inn_from_storage(self, client_data: RequestMqSerializer) -> Optional[ClientDataModel]:\n        client_passport = f'{client_data.document_serial} {client_data.document_number}'\n        client_request = await self.storage_repository.find_client_data(client_passport, client_data.request_id)\n        return client_request\n\n    def update_status(self, model: ClientDataModel, inn: str, error: str) -> None:\n        model.inn = inn\n        model.error = error\n\n    async def get_client_inn(self, client_data: RequestMqSerializer) -> ClientDataDTO:\n        \"\"\"\u041f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u043a\u043b\u0438\u0435\u043d\u0442\u0441\u043a\u043e\u0433\u043e \u0418\u041d\u041d\"\"\"\n        start_process = datetime.utcnow()\n        model = ClientDataModel.create_from_request(client_data)\n\n        # \u041f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0438\u0437 \u0411\u0414\n        existing_data = await self.get_client_inn_from_storage(client_data)\n        if existing_data:\n            elapsed_time = (datetime.utcnow() - start_process).total_seconds()\n            return ClientDataDTO(\n                request_id=client_data.request_id,\n                inn=existing_data.inn,\n                elapsed_time=elapsed_time,\n                cashed=True\n            )\n\n        # \u0421\u0434\u0435\u043b\u0430\u0442\u044c \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0437\u0430\u043f\u0440\u043e\u0441 \u0432 Nalog API\n        request = NalogApiRequestSerializer.create_from_request(client_data)\n        error, result = None, ''\n        try:\n            result = await self.client.send_request_for_inn(request)\n        except NalogApiClientException as exception:\n            self.logger.error('Error request to Nalog api service', details=str(exception))\n            error = str(exception)\n\n        self.update_status(model, result, error)\n        await self.storage_repository.save_client_data(model)\n\n        return ClientDataDTO(\n            request_id=model.request_id,\n            inn=model.inn,\n            details=model.error,\n            elapsed_time=model.elapsed_time\n        )", ""]}
{"filename": "src/inn_service/services/live_probe_service.py", "chunked_list": ["import asyncio\nfrom typing import List, Callable\nfrom logger import AppLogger\n\n\nclass LiveProbeService:\n    def __init__(\n            self,\n            logger: AppLogger\n    ):\n        self.logger = logger\n        self.handlers: List[Callable] = []\n\n    def add_component(self, component: Callable) -> None:\n        self.handlers.append(component)\n\n    async def get_component_status(self) -> bool:\n        tasks = []\n        component_status = True\n        for handler in self.handlers:\n            tasks.append(handler())\n        probe_results = await asyncio.gather(*tasks)\n\n        for probe_result in probe_results:\n            component_status = component_status and probe_result.status\n            if not probe_result.status:\n                self.logger.error(f'Service {probe_result.service_name} is down')\n\n        return component_status", ""]}
