{"filename": "setup.py", "chunked_list": ["import os\n\nfrom setuptools import find_packages, setup\n\n\ndef read(fname):\n    return open(os.path.join(os.path.dirname(__file__), fname)).read()\n\n\nlong_description = read('README.md') if os.path.isfile(\"README.md\") else \"\"", "\nlong_description = read('README.md') if os.path.isfile(\"README.md\") else \"\"\n\nsetup(\n    name='cosmos-etl',\n    version='0.0.2',\n    author='Bisola Olasehinde',\n    author_email='horlasehinde@gmail.com',\n    description='Tools for exporting Cosmos blockchain data to CSV or JSON',\n    long_description=long_description,", "    description='Tools for exporting Cosmos blockchain data to CSV or JSON',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    url='https://github.com/bizzyvinci/cosmos-etl',\n    packages=find_packages(),\n    classifiers=[\n        'Development Status :: 4 - Beta',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python :: 3',", "        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9'\n    ],\n    keywords=['cosmos', 'tendermint'],\n    python_requires='>=3.7.2,<4',\n    install_requires=[\n        'blockchain-etl-common',", "    install_requires=[\n        'blockchain-etl-common',\n        'web3>=5.29,<6'\n    ],\n    entry_points={\n        'console_scripts': [\n            'cosmosetl=cosmosetl.cli:cli',\n        ],\n    },\n    project_urls={", "    },\n    project_urls={\n        'Bug Reports': 'https://github.com/bizzyvinci/cosmos-etl/issues',\n        'Source': 'https://github.com/bizzyvinci/cosmos-etl',\n    },\n)\n"]}
{"filename": "cosmosetl/json_rpc_requests.py", "chunked_list": ["from cosmosetl.utils import MAX_PER_PAGE\n\n\ndef generate_json_rpc(method, params, request_id=1):\n    return {\n        'jsonrpc': '2.0',\n        'method': method,\n        'params': params,\n        'id': request_id,\n    }", "\n\ndef generate_get_block_by_number_json_rpc(block_numbers):\n    for idx, block_number in enumerate(block_numbers):\n        yield generate_json_rpc(\n            method='block',\n            params=[str(block_number)],\n            request_id=idx\n        )\n", "\n\ndef generate_tx_search_by_height_json_rpc(heights, page=1, per_page=MAX_PER_PAGE):\n    for idx, height in enumerate(heights):\n        yield generate_json_rpc(\n            method='tx_search',\n            params=[\"tx.height=%d\" % height, True, str(page), str(per_page), \"asc\"],\n            request_id=idx\n        )\n", ""]}
{"filename": "cosmosetl/__main__.py", "chunked_list": ["from cosmosetl.cli import cli\n\ncli()\n"]}
{"filename": "cosmosetl/__init__.py", "chunked_list": [""]}
{"filename": "cosmosetl/utils.py", "chunked_list": ["import base64\nimport itertools\nimport re\nfrom datetime import datetime\n\n\nMAX_PER_PAGE = 100\n\ndef str_to_dec(num_string):\n    if num_string is None:\n        return None\n    try:\n        return int(num_string)\n    except ValueError:\n        print(\"Not a num string %s\" % num_string)\n        return num_string", "def str_to_dec(num_string):\n    if num_string is None:\n        return None\n    try:\n        return int(num_string)\n    except ValueError:\n        print(\"Not a num string %s\" % num_string)\n        return num_string\n\n\ndef block_time_to_timestamp(time):\n    \"\"\"Convert block time to timestamp\n    param time: str e.g block.time\n    \"\"\"\n    # Had to use re.match because\n    # 1. The precision is in nanoseconds so we pick 6 digits and leave 3 out\n    # 2. But the genesis block time precision is seconds\n    # Added timezone Z because all the sample network have seen are in Z timezone\n\n    time = re.match('\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.?\\d{0,6}', time)\n    time = time.group(0)\n    format = \"%Y-%m-%dT%H:%M:%S%z\" if len(time) == 19 else \"%Y-%m-%dT%H:%M:%S.%f%z\"\n    return str_to_timestamp(time+'Z', format)", "\n\ndef block_time_to_timestamp(time):\n    \"\"\"Convert block time to timestamp\n    param time: str e.g block.time\n    \"\"\"\n    # Had to use re.match because\n    # 1. The precision is in nanoseconds so we pick 6 digits and leave 3 out\n    # 2. But the genesis block time precision is seconds\n    # Added timezone Z because all the sample network have seen are in Z timezone\n\n    time = re.match('\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.?\\d{0,6}', time)\n    time = time.group(0)\n    format = \"%Y-%m-%dT%H:%M:%S%z\" if len(time) == 19 else \"%Y-%m-%dT%H:%M:%S.%f%z\"\n    return str_to_timestamp(time+'Z', format)", "\n\ndef str_to_timestamp(date_string, format=\"%Y-%m-%dT%H:%M:%S.%f%z\"):\n    if date_string is None:\n        return None\n    try:\n        return datetime.strptime(date_string, format).timestamp()\n    except ValueError:\n        print(\"Date string (%s) or format (%s) is incorrect\" % (date_string, format))\n        return date_string", "\n\ndef b64decode(input_string, encoding='utf-8'):\n    if input_string is None:\n        return None\n    try:\n        return base64.b64decode(input_string).decode(encoding)\n    except Exception:\n        print(\"b64 decoding failed %s\" % input_string)\n        return input_string", "\n\ndef validate_range(range_start_incl, range_end_incl):\n    if range_start_incl < 0 or range_end_incl < 0:\n        raise ValueError('range_start and range_end must be greater or equal to 0')\n\n    if range_end_incl < range_start_incl:\n        raise ValueError('range_end must be greater or equal to range_start')\n\n\ndef rpc_response_to_result(response):\n    result = response.get('result')\n    if result is None:\n        error_message = 'result is None in response {}.'.format(response)\n        # Make better error messages\n        raise ValueError(error_message)\n    return result", "\n\ndef rpc_response_to_result(response):\n    result = response.get('result')\n    if result is None:\n        error_message = 'result is None in response {}.'.format(response)\n        # Make better error messages\n        raise ValueError(error_message)\n    return result\n", "\n\ndef rpc_response_batch_to_results(response):\n    # Sometimes response is dict instead of list\n    if isinstance(response, dict):\n        yield rpc_response_to_result(response)\n    else:\n        for response_item in response:\n            yield rpc_response_to_result(response_item)\n", "\n\ndef pairwise(iterable):\n    \"\"\"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return zip(a, b)\n"]}
{"filename": "cosmosetl/get_block.py", "chunked_list": ["import re\nfrom cosmosetl.mappers.block_mapper import CosmBlockMapper\nfrom cosmosetl.utils import rpc_response_to_result\n\ndef get_block(web3, height=None):\n    # height==None would return latest block\n    if height is not None and not isinstance(height, str):\n        height = str(height)\n    response = web3.make_request('block', [height])\n    result = rpc_response_to_result(response)\n    return CosmBlockMapper().json_dict_to_block(result)", "\n\ndef get_genesis_block(web3):\n    response = web3.make_request('block', ['1'])\n    if 'error' in response:\n        search = re.search('lowest height is (\\d+)', response['error']['data'])\n        if search is not None:\n            genesis_height = search.group(1)\n            response = web3.make_request('block', [genesis_height])\n    \n    result = rpc_response_to_result(response)\n    return CosmBlockMapper().json_dict_to_block(result)", "\n\ndef get_latest_block(web3):\n    return get_block(web3, None)\n\n"]}
{"filename": "cosmosetl/thread_local_proxy.py", "chunked_list": ["import threading\n\n\nclass ThreadLocalProxy:\n    def __init__(self, delegate_factory):\n        self._thread_local = threading.local()\n        self._delegate_factory = delegate_factory\n\n    def __getattr__(self, name):\n        return getattr(self._get_thread_local_delegate(), name)\n\n    def _get_thread_local_delegate(self):\n        if getattr(self._thread_local, '_delegate', None) is None:\n            self._thread_local._delegate = self._delegate_factory()\n        return self._thread_local._delegate", ""]}
{"filename": "cosmosetl/cli/export_transactions_and_events.py", "chunked_list": ["import click\n\nfrom blockchainetl_common.logging_utils import logging_basic_config\nfrom cosmosetl.jobs.export_transactions_job import ExportTransactionsJob\nfrom cosmosetl.jobs.exporters.transactions_and_events_item_exporter import transactions_and_events_item_exporter\nfrom cosmosetl.providers.auto import get_provider_from_uri\nfrom cosmosetl.thread_local_proxy import ThreadLocalProxy\n\nlogging_basic_config()\n", "logging_basic_config()\n\n\n@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n@click.option('-s', '--start-block', default=0, show_default=True, type=int, help='Start block')\n@click.option('-e', '--end-block', required=True, type=int, help='End block')\n@click.option('-b', '--batch-size', default=100, show_default=True, type=int, help='The number of blocks to export at a time.')\n@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n@click.option('-w', '--max-workers', default=5, show_default=True, type=int, help='The maximum number of workers.')\n@click.option('-to', '--transactions-output', default=None, show_default=True, type=str, help='Output file for transactions (ending with .csv or .json)')", "@click.option('-w', '--max-workers', default=5, show_default=True, type=int, help='The maximum number of workers.')\n@click.option('-to', '--transactions-output', default=None, show_default=True, type=str, help='Output file for transactions (ending with .csv or .json)')\n@click.option('-eo', '--events-output', default=None, show_default=True, type=str, help='Output file for events (ending with .csv or .json)')\ndef export_transactions_and_events(start_block, end_block, batch_size, provider_uri, max_workers, transactions_output, events_output):\n    job = ExportTransactionsJob(\n        start_block=start_block,\n        end_block=end_block,\n        batch_size=batch_size,\n        batch_web3_provider=ThreadLocalProxy(lambda: get_provider_from_uri(provider_uri, batch=True)),\n        max_workers=max_workers,\n        item_exporter=transactions_and_events_item_exporter(transactions_output, events_output),\n        export_transactions=transactions_output is not None,\n        export_events=events_output is not None\n    )\n    job.run()", ""]}
{"filename": "cosmosetl/cli/get_block_range_for_date.py", "chunked_list": ["import click\nfrom datetime import datetime\n\nfrom blockchainetl_common.file_utils import smart_open\nfrom blockchainetl_common.logging_utils import logging_basic_config\nfrom cosmosetl.providers.auto import get_provider_from_uri\nfrom cosmosetl.service.cosm_service import CosmService\n\nlogging_basic_config()\n", "logging_basic_config()\n\n\n@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n@click.option('-d', '--date', required=True, type=lambda d: datetime.strptime(d, '%Y-%m-%d'),\n              help='The date YYYY-MM-DD e.g. 2022-02-22.')\n@click.option('-o', '--output', default='-', show_default=True, type=str, help='The output file. If not specified stdout is used.')\ndef get_block_range_for_date(provider_uri, date, output):\n    \"\"\"Outputs start and end blocks for given date.\"\"\"\n    provider = get_provider_from_uri(provider_uri)\n    cosm_service = CosmService(provider)\n\n    start_block, end_block = cosm_service.get_block_range_for_date(date)\n\n    with smart_open(output, 'w') as output_file:\n        output_file.write('{},{}\\n'.format(start_block, end_block))", "def get_block_range_for_date(provider_uri, date, output):\n    \"\"\"Outputs start and end blocks for given date.\"\"\"\n    provider = get_provider_from_uri(provider_uri)\n    cosm_service = CosmService(provider)\n\n    start_block, end_block = cosm_service.get_block_range_for_date(date)\n\n    with smart_open(output, 'w') as output_file:\n        output_file.write('{},{}\\n'.format(start_block, end_block))\n", ""]}
{"filename": "cosmosetl/cli/export_blocks.py", "chunked_list": ["from email.policy import default\nimport click\n\nfrom blockchainetl_common.logging_utils import logging_basic_config\nfrom cosmosetl.jobs.export_blocks_job import ExportBlocksJob\nfrom cosmosetl.jobs.exporters.blocks_item_exporter import blocks_item_exporter\nfrom cosmosetl.providers.auto import get_provider_from_uri\nfrom cosmosetl.thread_local_proxy import ThreadLocalProxy\n\nlogging_basic_config()", "\nlogging_basic_config()\n\n\n@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n@click.option('-s', '--start-block', default=0, show_default=True, type=int, help='Start block')\n@click.option('-e', '--end-block', required=True, type=int, help='End block')\n@click.option('-b', '--batch-size', default=100, show_default=True, type=int, help='The number of blocks to export at a time.')\n@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n@click.option('-w', '--max-workers', default=5, show_default=True, type=int, help='The maximum number of workers.')", "@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n@click.option('-w', '--max-workers', default=5, show_default=True, type=int, help='The maximum number of workers.')\n@click.option('-o', '--output', required=True, type=str, help='Output file for blocks (ending with .csv or .json)')\ndef export_blocks(start_block, end_block, batch_size, provider_uri, max_workers, output):\n    job = ExportBlocksJob(\n        start_block=start_block,\n        end_block=end_block,\n        batch_size=batch_size,\n        batch_web3_provider=ThreadLocalProxy(lambda: get_provider_from_uri(provider_uri, batch=True)),\n        max_workers=max_workers,\n        item_exporter=blocks_item_exporter(output)\n    )\n    job.run()", ""]}
{"filename": "cosmosetl/cli/__init__.py", "chunked_list": ["from blockchainetl_common.logging_utils import logging_basic_config\nlogging_basic_config()\n\nimport click\n\nfrom cosmosetl.cli.export_blocks import export_blocks\nfrom cosmosetl.cli.export_transactions_and_events import export_transactions_and_events\nfrom cosmosetl.cli.get_block_range_for_date import get_block_range_for_date\nfrom cosmosetl.cli.get_block_range_for_timestamps import get_block_range_for_timestamps\n", "from cosmosetl.cli.get_block_range_for_timestamps import get_block_range_for_timestamps\n\n@click.group()\n@click.version_option(version='0.0.2')\n@click.pass_context\ndef cli(ctx):\n    pass\n\n\n# export", "\n# export\ncli.add_command(export_blocks, \"export_blocks\")\ncli.add_command(export_transactions_and_events, \"export_transactions_and_events\")\ncli.add_command(get_block_range_for_date, \"get_block_range_for_date\")\ncli.add_command(get_block_range_for_timestamps, \"get_block_range_for_timestamps\")\n"]}
{"filename": "cosmosetl/cli/get_block_range_for_timestamps.py", "chunked_list": ["import click\nfrom datetime import datetime\n\nfrom blockchainetl_common.file_utils import smart_open\nfrom blockchainetl_common.logging_utils import logging_basic_config\nfrom cosmosetl.providers.auto import get_provider_from_uri\nfrom cosmosetl.service.cosm_service import CosmService\n\nlogging_basic_config()\n", "logging_basic_config()\n\n\n@click.command(context_settings=dict(help_option_names=['-h', '--help']))\n@click.option('-p', '--provider-uri', required=True, type=str, help='The URI of tendermint RPC')\n@click.option('-s', '--start-timestamp', required=True, type=int, help='Start unix timestamp, in seconds.')\n@click.option('-e', '--end-timestamp', required=True, type=int, help='End unix timestamp, in seconds.')\n@click.option('-o', '--output', default='-', show_default=True, type=str, help='The output file. If not specified stdout is used.')\ndef get_block_range_for_timestamps(provider_uri, start_timestamp, end_timestamp, output):\n    \"\"\"Outputs start and end blocks for given date.\"\"\"\n    provider = get_provider_from_uri(provider_uri)\n    cosm_service = CosmService(provider)\n\n    start_block, end_block = cosm_service.get_block_range_for_timestamps(start_timestamp, end_timestamp)\n\n    with smart_open(output, 'w') as output_file:\n        output_file.write('{},{}\\n'.format(start_block, end_block))", "def get_block_range_for_timestamps(provider_uri, start_timestamp, end_timestamp, output):\n    \"\"\"Outputs start and end blocks for given date.\"\"\"\n    provider = get_provider_from_uri(provider_uri)\n    cosm_service = CosmService(provider)\n\n    start_block, end_block = cosm_service.get_block_range_for_timestamps(start_timestamp, end_timestamp)\n\n    with smart_open(output, 'w') as output_file:\n        output_file.write('{},{}\\n'.format(start_block, end_block))\n", ""]}
{"filename": "cosmosetl/domain/block.py", "chunked_list": ["class CosmBlock:\n    def __init__(self):\n        self.height = None\n        self.hash = None\n        self.last_block_hash = None\n        self.data_hash = None\n        self.proposer = None\n        self.num_txs = None\n        self.time = None\n", ""]}
{"filename": "cosmosetl/domain/__init__.py", "chunked_list": [""]}
{"filename": "cosmosetl/domain/transaction.py", "chunked_list": ["class CosmTransaction:\n    def __init__(self):\n        self.hash = None\n        self.height = None\n        self.index = None\n        self.code = None\n        self.gas_used = None\n        self.gas_wanted = None\n        self.num_events = None\n        self.root_hash = None\n        self.tx = None\n        self.data = None\n        self.raw_data = None\n        self.raw_log = None\n        self.events = []", ""]}
{"filename": "cosmosetl/domain/event.py", "chunked_list": ["class CosmEvent:\n    def __init__(self):\n        self._type = None\n        self.attributes = None\n        self.tx_hash = None\n"]}
{"filename": "cosmosetl/providers/ipc.py", "chunked_list": ["import json\nimport socket\n\nfrom web3.providers.ipc import IPCProvider\nfrom web3._utils.threads import (\n    Timeout,\n)\n\ntry:\n    from json import JSONDecodeError\nexcept ImportError:\n    JSONDecodeError = ValueError", "try:\n    from json import JSONDecodeError\nexcept ImportError:\n    JSONDecodeError = ValueError\n\n\n# Mostly copied from web3.py/providers/ipc.py. Supports batch requests.\n# Will be removed once batch feature is added to web3.py https://github.com/ethereum/web3.py/issues/832\n# Also see this optimization https://github.com/ethereum/web3.py/pull/849\nclass BatchIPCProvider(IPCProvider):\n    _socket = None\n\n    def make_batch_request(self, text):\n        request = text.encode('utf-8')\n        with self._lock, self._socket as sock:\n            try:\n                sock.sendall(request)\n            except BrokenPipeError:\n                # one extra attempt, then give up\n                sock = self._socket.reset()\n                sock.sendall(request)\n\n            raw_response = b\"\"\n            with Timeout(self.timeout) as timeout:\n                while True:\n                    try:\n                        raw_response += sock.recv(4096)\n                    except socket.timeout:\n                        timeout.sleep(0)\n                        continue\n                    if raw_response == b\"\":\n                        timeout.sleep(0)\n                    elif has_valid_json_rpc_ending(raw_response):\n                        try:\n                            response = json.loads(raw_response.decode('utf-8'))\n                        except JSONDecodeError:\n                            timeout.sleep(0)\n                            continue\n                        else:\n                            return response\n                    else:\n                        timeout.sleep(0)\n                        continue", "# Also see this optimization https://github.com/ethereum/web3.py/pull/849\nclass BatchIPCProvider(IPCProvider):\n    _socket = None\n\n    def make_batch_request(self, text):\n        request = text.encode('utf-8')\n        with self._lock, self._socket as sock:\n            try:\n                sock.sendall(request)\n            except BrokenPipeError:\n                # one extra attempt, then give up\n                sock = self._socket.reset()\n                sock.sendall(request)\n\n            raw_response = b\"\"\n            with Timeout(self.timeout) as timeout:\n                while True:\n                    try:\n                        raw_response += sock.recv(4096)\n                    except socket.timeout:\n                        timeout.sleep(0)\n                        continue\n                    if raw_response == b\"\":\n                        timeout.sleep(0)\n                    elif has_valid_json_rpc_ending(raw_response):\n                        try:\n                            response = json.loads(raw_response.decode('utf-8'))\n                        except JSONDecodeError:\n                            timeout.sleep(0)\n                            continue\n                        else:\n                            return response\n                    else:\n                        timeout.sleep(0)\n                        continue", "\n\n# A valid JSON RPC response can only end in } or ] http://www.jsonrpc.org/specification\ndef has_valid_json_rpc_ending(raw_response):\n    for valid_ending in [b\"}\\n\", b\"]\\n\"]:\n        if raw_response.endswith(valid_ending):\n            return True\n    else:\n        return False\n", ""]}
{"filename": "cosmosetl/providers/auto.py", "chunked_list": ["from urllib.parse import urlparse\n\nfrom web3 import IPCProvider, HTTPProvider\n\nfrom cosmosetl.providers.ipc import BatchIPCProvider\nfrom cosmosetl.providers.rpc import BatchHTTPProvider\n\nDEFAULT_TIMEOUT = 60\n\n\ndef get_provider_from_uri(uri_string, timeout=DEFAULT_TIMEOUT, batch=False):\n    uri = urlparse(uri_string)\n    if uri.scheme == 'file':\n        if batch:\n            return BatchIPCProvider(uri.path, timeout=timeout)\n        else:\n            return IPCProvider(uri.path, timeout=timeout)\n    elif uri.scheme == 'http' or uri.scheme == 'https':\n        request_kwargs = {'timeout': timeout}\n        if batch:\n            return BatchHTTPProvider(uri_string, request_kwargs=request_kwargs)\n        else:\n            return HTTPProvider(uri_string, request_kwargs=request_kwargs)\n    else:\n        raise ValueError('Unknown uri scheme {}'.format(uri_string))", "\n\ndef get_provider_from_uri(uri_string, timeout=DEFAULT_TIMEOUT, batch=False):\n    uri = urlparse(uri_string)\n    if uri.scheme == 'file':\n        if batch:\n            return BatchIPCProvider(uri.path, timeout=timeout)\n        else:\n            return IPCProvider(uri.path, timeout=timeout)\n    elif uri.scheme == 'http' or uri.scheme == 'https':\n        request_kwargs = {'timeout': timeout}\n        if batch:\n            return BatchHTTPProvider(uri_string, request_kwargs=request_kwargs)\n        else:\n            return HTTPProvider(uri_string, request_kwargs=request_kwargs)\n    else:\n        raise ValueError('Unknown uri scheme {}'.format(uri_string))", "\n"]}
{"filename": "cosmosetl/providers/__init__.py", "chunked_list": [""]}
{"filename": "cosmosetl/providers/rpc.py", "chunked_list": ["from web3 import HTTPProvider\nfrom web3._utils.request import make_post_request\n\n\n# Mostly copied from web3.py/providers/rpc.py. Supports batch requests.\n# Will be removed once batch feature is added to web3.py https://github.com/ethereum/web3.py/issues/832\nclass BatchHTTPProvider(HTTPProvider):\n\n    def make_batch_request(self, text):\n        self.logger.debug(\"Making request HTTP. URI: %s, Request: %s\",\n                          self.endpoint_uri, text)\n        request_data = text.encode('utf-8')\n        raw_response = make_post_request(\n            self.endpoint_uri,\n            request_data,\n            **self.get_request_kwargs()\n        )\n        response = self.decode_rpc_response(raw_response)\n        self.logger.debug(\"Getting response HTTP. URI: %s, \"\n                          \"Request: %s, Response: %s\",\n                          self.endpoint_uri, text, response)\n        return response", ""]}
{"filename": "cosmosetl/mappers/__init__.py", "chunked_list": [""]}
{"filename": "cosmosetl/mappers/event_mapper.py", "chunked_list": ["import json\nfrom cosmosetl.domain.event import CosmEvent\nfrom cosmosetl.utils import b64decode\n\nclass CosmEventMapper:\n    def json_dict_to_event(self, json_dict, tx_hash=None):\n        event = CosmEvent()\n        event._type = json_dict.get(\"type\")\n        attributes = json.dumps([\n            {'key': b64decode(attr.get('key')), 'value': b64decode(attr.get('value'))}\n            for attr in json_dict.get(\"attributes\", [])\n        ])\n        event.attributes = attributes if attributes else None\n        event.tx_hash = tx_hash\n        return event\n        \n    def event_to_dict(self, event):\n        return {\n            \"type\": \"event\",\n            \"_type\": event._type,\n            \"attributes\": event.attributes,\n            \"tx_hash\": event.tx_hash\n        }", ""]}
{"filename": "cosmosetl/mappers/transaction_mapper.py", "chunked_list": ["from asyncio import events\nimport json\nfrom cosmosetl.domain.transaction import CosmTransaction\nfrom cosmosetl.mappers.event_mapper import CosmEventMapper\nfrom cosmosetl.utils import str_to_dec, b64decode\n\nclass CosmTransactionMapper:\n    def __init__(self):\n        self.event_mapper = CosmEventMapper()\n\n    def json_dict_to_transaction(self, json_dict):\n        transaction = CosmTransaction()\n        transaction.hash = json_dict.get(\"hash\")\n        transaction.height = str_to_dec(json_dict.get(\"height\"))\n        transaction.index = json_dict.get(\"index\")\n        transaction.code = json_dict.get(\"tx_result\", {}).get(\"code\")\n        transaction.gas_used = json_dict.get(\"tx_result\", {}).get(\"gas_used\")\n        transaction.gas_wanted = json_dict.get(\"tx_result\", {}).get(\"gas_wanted\")\n        transaction.num_events = len(json_dict.get(\"tx_result\", {}).get(\"events\", []))\n        transaction.root_hash = json_dict.get(\"proof\", {}).get(\"root_hash\")\n        transaction.tx = json_dict.get(\"tx\")\n        # simple b64decoding doesn't work for data\n        # transaction.data = b64decode(json_dict.get(\"tx_result\", {}).get(\"data\"))\n        transaction.raw_data = json_dict.get(\"tx_result\", {}).get(\"data\")\n        transaction.raw_log = json_dict.get(\"tx_result\", {}).get(\"log\")\n        transaction.events = [\n            self.event_mapper.json_dict_to_event(evt, tx_hash=transaction.hash)\n            for evt in json_dict.get('tx_result', {}).get('events', [])\n        ]\n        return transaction\n        \n    def transaction_to_dict(self, transaction):\n        return {\n            \"type\": \"transaction\",\n            \"hash\": transaction.hash,\n            \"height\": transaction.height,\n            \"index\": transaction.index,\n            \"code\": transaction.code,\n            \"gas_used\": transaction.gas_used,\n            \"gas_wanted\": transaction.gas_wanted,\n            \"num_events\": transaction.num_events,\n            \"root_hash\": transaction.root_hash,\n            \"tx\": transaction.tx,\n            \"data\": transaction.data,\n            \"raw_data\": transaction.raw_data,\n            \"raw_log\": transaction.raw_log,\n        }", ""]}
{"filename": "cosmosetl/mappers/block_mapper.py", "chunked_list": ["from cosmosetl.domain.block import CosmBlock\nfrom cosmosetl.utils import str_to_dec\n\nclass CosmBlockMapper:\n    def json_dict_to_block(self, json_dict):\n        block = CosmBlock()\n        block.height = str_to_dec(json_dict['block']['header'].get('height'))\n        block.hash = json_dict['block_id'].get('hash')\n        block.last_block_hash = json_dict['block']['header'].get('last_block_id', {}).get('hash')\n        block.data_hash = json_dict['block']['header'].get('data_hash')\n        block.proposer = json_dict['block']['header'].get('proposer_address')\n        block.num_txs = len(json_dict['block']['data'].get('txs', []))\n        block.time = json_dict['block']['header'].get('time')\n        return block\n    \n    def block_to_dict(self, block):\n        return {\n            'type': 'block',\n            'height': block.height,\n            'hash': block.hash,\n            'last_block_hash': block.last_block_hash,\n            'data_hash': block.data_hash,\n            'proposer': block.proposer,\n            'num_txs': block.num_txs,\n            'time': block.time,\n        }"]}
{"filename": "cosmosetl/jobs/export_blocks_job.py", "chunked_list": ["import json\nfrom blockchainetl_common.jobs.base_job import BaseJob\nfrom blockchainetl_common.executors.batch_work_executor import BatchWorkExecutor\nfrom cosmosetl.mappers.block_mapper import CosmBlockMapper\nfrom cosmosetl.json_rpc_requests import generate_get_block_by_number_json_rpc\nfrom cosmosetl.utils import validate_range, rpc_response_batch_to_results\n\nclass ExportBlocksJob(BaseJob):\n    def __init__(self, start_block, end_block, batch_size, batch_web3_provider,\n                max_workers, item_exporter):\n        validate_range(start_block, end_block)\n        self.start_block = start_block\n        self.end_block = end_block\n\n        self.batch_web3_provider = batch_web3_provider\n\n        self.batch_work_executor = BatchWorkExecutor(batch_size, max_workers)\n        self.item_exporter = item_exporter\n        self.block_mapper = CosmBlockMapper()\n        \n    def _start(self):\n        self.item_exporter.open()\n    \n    def _export(self):\n        self.batch_work_executor.execute(\n            range(self.start_block, self.end_block + 1),\n            self._export_batch,\n            total_items=self.end_block - self.start_block + 1\n        )\n    \n    def _export_batch(self, block_number_batch):\n        blocks_rpc = list(generate_get_block_by_number_json_rpc(block_number_batch))\n        response = self.batch_web3_provider.make_batch_request(json.dumps(blocks_rpc))\n        results = rpc_response_batch_to_results(response)\n        blocks = [self.block_mapper.json_dict_to_block(result) for result in results]\n\n        for block in blocks:\n            self._export_block(block)\n\n    def _export_block(self, block):\n        self.item_exporter.export_item(self.block_mapper.block_to_dict(block))\n\n    def _end(self):\n        self.batch_work_executor.shutdown()\n        self.item_exporter.close()", ""]}
{"filename": "cosmosetl/jobs/__init__.py", "chunked_list": [""]}
{"filename": "cosmosetl/jobs/export_transactions_job.py", "chunked_list": ["import json\nfrom blockchainetl_common.jobs.base_job import BaseJob\nfrom blockchainetl_common.executors.batch_work_executor import BatchWorkExecutor\nfrom cosmosetl.mappers.event_mapper import CosmEventMapper\nfrom cosmosetl.mappers.transaction_mapper import CosmTransactionMapper\nfrom cosmosetl.json_rpc_requests import generate_tx_search_by_height_json_rpc\nfrom cosmosetl.utils import MAX_PER_PAGE, validate_range, rpc_response_batch_to_results\n\nclass ExportTransactionsJob(BaseJob):\n    def __init__(self, start_block, end_block, batch_size, batch_web3_provider, max_workers, item_exporter,\n                export_transactions=True, export_events=True):\n        validate_range(start_block, end_block)\n        self.start_block = start_block\n        self.end_block = end_block\n        self.batch_web3_provider = batch_web3_provider\n        self.batch_work_executor = BatchWorkExecutor(batch_size, max_workers)\n        self.item_exporter = item_exporter\n        self.transaction_mapper = CosmTransactionMapper()\n        self.event_mapper = CosmEventMapper()\n        self.export_transactions = export_transactions\n        self.export_events = export_events\n\n    def _start(self):\n        self.item_exporter.open()\n    \n    def _export(self):\n        self.batch_work_executor.execute(\n            range(self.start_block, self.end_block + 1),\n            self._export_batch,\n            total_items=self.end_block - self.start_block + 1\n        )\n\n    def _export_batch(self, block_number_batch, page=1):\n        requests = list(generate_tx_search_by_height_json_rpc(block_number_batch, page))\n        response = self.batch_web3_provider.make_batch_request(json.dumps(requests))\n        results = rpc_response_batch_to_results(response)\n        next_block_number_batch = []\n\n        for block in results:\n            self._export_block(block)\n            if int(block.get('total_count', 0)) > page * MAX_PER_PAGE:\n                next_block_number_batch.append(block)\n        \n        if next_block_number_batch:\n            self._export_batch(next_block_number_batch, page+1)\n    \n    def _export_block(self, block):\n        for tx in block.get('txs', []):\n            transaction = self.transaction_mapper.json_dict_to_transaction(tx)\n            self._export_transaction(transaction)\n    \n    def _export_transaction(self, transaction):\n        if self.export_transactions:\n            self.item_exporter.export_item(self.transaction_mapper.transaction_to_dict(transaction))\n        if self.export_events:\n            for evt in transaction.events:\n                self.item_exporter.export_item(self.event_mapper.event_to_dict(evt))\n\n    def _end(self):\n        self.batch_work_executor.shutdown()\n        self.item_exporter.close()", "class ExportTransactionsJob(BaseJob):\n    def __init__(self, start_block, end_block, batch_size, batch_web3_provider, max_workers, item_exporter,\n                export_transactions=True, export_events=True):\n        validate_range(start_block, end_block)\n        self.start_block = start_block\n        self.end_block = end_block\n        self.batch_web3_provider = batch_web3_provider\n        self.batch_work_executor = BatchWorkExecutor(batch_size, max_workers)\n        self.item_exporter = item_exporter\n        self.transaction_mapper = CosmTransactionMapper()\n        self.event_mapper = CosmEventMapper()\n        self.export_transactions = export_transactions\n        self.export_events = export_events\n\n    def _start(self):\n        self.item_exporter.open()\n    \n    def _export(self):\n        self.batch_work_executor.execute(\n            range(self.start_block, self.end_block + 1),\n            self._export_batch,\n            total_items=self.end_block - self.start_block + 1\n        )\n\n    def _export_batch(self, block_number_batch, page=1):\n        requests = list(generate_tx_search_by_height_json_rpc(block_number_batch, page))\n        response = self.batch_web3_provider.make_batch_request(json.dumps(requests))\n        results = rpc_response_batch_to_results(response)\n        next_block_number_batch = []\n\n        for block in results:\n            self._export_block(block)\n            if int(block.get('total_count', 0)) > page * MAX_PER_PAGE:\n                next_block_number_batch.append(block)\n        \n        if next_block_number_batch:\n            self._export_batch(next_block_number_batch, page+1)\n    \n    def _export_block(self, block):\n        for tx in block.get('txs', []):\n            transaction = self.transaction_mapper.json_dict_to_transaction(tx)\n            self._export_transaction(transaction)\n    \n    def _export_transaction(self, transaction):\n        if self.export_transactions:\n            self.item_exporter.export_item(self.transaction_mapper.transaction_to_dict(transaction))\n        if self.export_events:\n            for evt in transaction.events:\n                self.item_exporter.export_item(self.event_mapper.event_to_dict(evt))\n\n    def _end(self):\n        self.batch_work_executor.shutdown()\n        self.item_exporter.close()", ""]}
{"filename": "cosmosetl/jobs/exporters/transactions_and_events_item_exporter.py", "chunked_list": ["from blockchainetl_common.jobs.exporters.composite_item_exporter import CompositeItemExporter\n\nTRANSACTION_FIELDS_TO_EXPORT = [\n    'hash',\n    'height',\n    'index',\n    'code',\n    'gas_used',\n    'gas_wanted',\n    'num_events',", "    'gas_wanted',\n    'num_events',\n    'root_hash',\n    'tx',\n    'data',\n    'raw_data',\n    'raw_log',\n]\n\nEVENT_FIELDS_TO_EXPORT = [", "\nEVENT_FIELDS_TO_EXPORT = [\n    '_type',\n    'attributes',\n    'tx_hash'\n]\n\n\ndef transactions_and_events_item_exporter(transactions_output=None, events_output=None):\n    return CompositeItemExporter(\n        filename_mapping={\n            'transaction': transactions_output,\n            'event': events_output\n        },\n        field_mapping={\n            'transaction': TRANSACTION_FIELDS_TO_EXPORT,\n            'event': EVENT_FIELDS_TO_EXPORT\n        }\n    )", "def transactions_and_events_item_exporter(transactions_output=None, events_output=None):\n    return CompositeItemExporter(\n        filename_mapping={\n            'transaction': transactions_output,\n            'event': events_output\n        },\n        field_mapping={\n            'transaction': TRANSACTION_FIELDS_TO_EXPORT,\n            'event': EVENT_FIELDS_TO_EXPORT\n        }\n    )"]}
{"filename": "cosmosetl/jobs/exporters/__init__.py", "chunked_list": [""]}
{"filename": "cosmosetl/jobs/exporters/blocks_item_exporter.py", "chunked_list": ["from blockchainetl_common.jobs.exporters.composite_item_exporter import CompositeItemExporter\n\nBLOCK_FIELDS_TO_EXPORT = [\n    'height',\n    'hash',\n    'last_block_hash',\n    'data_hash',\n    'proposer',\n    'num_txs',\n    'time'", "    'num_txs',\n    'time'\n]\n\n\ndef blocks_item_exporter(blocks_output):\n    return CompositeItemExporter(\n        filename_mapping={\n            'block': blocks_output\n        },\n        field_mapping={\n            'block': BLOCK_FIELDS_TO_EXPORT\n        }\n    )", ""]}
{"filename": "cosmosetl/service/__init__.py", "chunked_list": [""]}
{"filename": "cosmosetl/service/cosm_service.py", "chunked_list": ["from datetime import datetime, timezone\nfrom cosmosetl.service.graph_operations import GraphOperations, OutOfBoundsError, Point\nfrom cosmosetl.utils import  block_time_to_timestamp\nfrom cosmosetl.get_block import get_block, get_genesis_block, get_latest_block\n\n\nclass CosmService(object):\n    def __init__(self, web3):\n        graph = BlockTimestampGraph(web3)\n        self._graph_operations = GraphOperations(graph)\n\n    def get_block_range_for_date(self, date):\n        start_datetime = datetime.combine(date, datetime.min.time().replace(tzinfo=timezone.utc))\n        end_datetime = datetime.combine(date, datetime.max.time().replace(tzinfo=timezone.utc))\n        return self.get_block_range_for_timestamps(start_datetime.timestamp(), end_datetime.timestamp())\n\n    def get_block_range_for_timestamps(self, start_timestamp, end_timestamp):\n        start_timestamp = int(start_timestamp)\n        end_timestamp = int(end_timestamp)\n        if start_timestamp > end_timestamp:\n            raise ValueError('start_timestamp must be greater or equal to end_timestamp')\n\n        try:\n            start_block_bounds = self._graph_operations.get_bounds_for_y_coordinate(start_timestamp)\n        except OutOfBoundsError:\n            start_block_bounds = (0, 0)\n\n        try:\n            end_block_bounds = self._graph_operations.get_bounds_for_y_coordinate(end_timestamp)\n        except OutOfBoundsError as e:\n            raise OutOfBoundsError('The existing blocks do not completely cover the given time range') from e\n\n        if start_block_bounds == end_block_bounds and start_block_bounds[0] != start_block_bounds[1]:\n            raise ValueError('The given timestamp range does not cover any blocks')\n\n        start_block = start_block_bounds[1]\n        end_block = end_block_bounds[0]\n\n        # The genesis block has timestamp 0 but we include it with the 1st block.\n        if start_block == 1:\n            start_block = 0\n\n        return start_block, end_block", "\n\nclass BlockTimestampGraph(object):\n    def __init__(self, web3):\n        self._web3 = web3\n\n    def get_first_point(self):\n        return block_to_point(get_genesis_block(self._web3))\n\n    def get_last_point(self):\n        return block_to_point(get_latest_block(self._web3))\n\n    def get_point(self, x):\n        return block_to_point(get_block(self._web3, x))", "\n\ndef block_to_point(block):\n    return Point(block.height, block_time_to_timestamp(block.time))\n"]}
{"filename": "cosmosetl/service/graph_operations.py", "chunked_list": ["from cosmosetl.utils import pairwise\n\n\nclass GraphOperations(object):\n    def __init__(self, graph):\n        \"\"\"x axis on the graph must be integers, y value must increase strictly monotonically with increase of x\"\"\"\n        self._graph = graph\n        self._cached_points = []\n\n    def get_bounds_for_y_coordinate(self, y):\n        \"\"\"given the y coordinate, outputs a pair of x coordinates for closest points that bound the y coordinate.\n        Left and right bounds are equal in case given y is equal to one of the points y coordinate\"\"\"\n        initial_bounds = find_best_bounds(y, self._cached_points)\n        if initial_bounds is None:\n            initial_bounds = self._get_first_point(), self._get_last_point()\n\n        result = self._get_bounds_for_y_coordinate_recursive(y, *initial_bounds)\n        return result\n\n    def _get_bounds_for_y_coordinate_recursive(self, y, start, end):\n        if y < start.y or y > end.y:\n            raise OutOfBoundsError('y coordinate {} is out of bounds for points {}-{}'.format(y, start, end))\n\n        if y == start.y:\n            return start.x, start.x\n        elif y == end.y:\n            return end.x, end.x\n        elif (end.x - start.x) <= 1:\n            return start.x, end.x\n        else:\n            assert start.y < y < end.y\n            if start.y >= end.y:\n                raise ValueError('y must increase strictly monotonically')\n\n            # Interpolation Search https://en.wikipedia.org/wiki/Interpolation_search, O(log(log(n)) average case.\n            # Improvements for worst case:\n            # Find the 1st estimation by linear interpolation from start and end points.\n            # If the 1st estimation is below the needed y coordinate (graph is concave),\n            # drop the next estimation by interpolating with the start and 1st estimation point\n            # (likely will be above the needed y).\n            # If 1st estimation is above the needed y coordinate (graph is convex),\n            # drop the next estimation by interpolating with the 1st estimation and end point\n            # (likely will be below the needed y).\n\n            estimation1_x = interpolate(start, end, y)\n            estimation1_x = bound(estimation1_x, (start.x, end.x))\n            estimation1 = self._get_point(estimation1_x)\n\n            if estimation1.y < y:\n                points = (start, estimation1)\n            else:\n                points = (estimation1, end)\n\n            estimation2_x = interpolate(*points, y)\n            estimation2_x = bound(estimation2_x, (start.x, end.x))\n            estimation2 = self._get_point(estimation2_x)\n\n            all_points = [start, estimation1, estimation2, end]\n\n            bounds = find_best_bounds(y, all_points)\n            if bounds is None:\n                raise ValueError('Unable to find bounds for points {} and y coordinate {}'.format(points, y))\n\n            return self._get_bounds_for_y_coordinate_recursive(y, *bounds)\n\n    def _get_point(self, x):\n        point = self._graph.get_point(x)\n        self._cached_points.append(point)\n        return point\n\n    def _get_first_point(self):\n        point = self._graph.get_first_point()\n        self._cached_points.append(point)\n        return point\n\n    def _get_last_point(self):\n        point = self._graph.get_last_point()\n        self._cached_points.append(point)\n        return point", "\n\ndef find_best_bounds(y, points):\n    sorted_points = sorted(points, key=lambda point: point.y)\n    for point1, point2 in pairwise(sorted_points):\n        if point1.y <= y <= point2.y:\n            return point1, point2\n    return None\n\n\ndef interpolate(point1, point2, y):\n    x1, y1 = point1.x, point1.y\n    x2, y2 = point2.x, point2.y\n    if y1 == y2:\n        raise ValueError('The y coordinate for points is the same {}, {}'.format(point1, point2))\n    x = int((y - y1) * (x2 - x1) / (y2 - y1) + x1)\n    return x", "\n\ndef interpolate(point1, point2, y):\n    x1, y1 = point1.x, point1.y\n    x2, y2 = point2.x, point2.y\n    if y1 == y2:\n        raise ValueError('The y coordinate for points is the same {}, {}'.format(point1, point2))\n    x = int((y - y1) * (x2 - x1) / (y2 - y1) + x1)\n    return x\n", "\n\ndef bound(x, bounds):\n    x1, x2 = bounds\n    if x1 > x2:\n        x1, x2 = x2, x1\n    if x <= x1:\n        return x1 + 1\n    elif x >= x2:\n        return x2 - 1\n    else:\n        return x", "\n\nclass OutOfBoundsError(Exception):\n    pass\n\n\nclass Point(object):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __str__(self):\n        return '({},{})'.format(self.x, self.y)\n\n    def __repr__(self):\n        return 'Point({},{})'.format(self.x, self.y)", ""]}
