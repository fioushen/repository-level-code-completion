{"filename": "tests/test_permutations.py", "chunked_list": ["import numpy as np\nimport unittest\nfrom hypothesis import given\nfrom tests.strategies import objects, adapted_function, finite_functions, permutations, parallel_permutations, parallel_arrows\n\nfrom yarrow.numpy import FiniteFunction\nfrom yarrow.finite_function import argsort\n\nfrom tests.util import sorts\n", "from tests.util import sorts\n\n# Invert a permutation\ndef invert(p):\n    return argsort(p)\n\n# Ensure the invert function works(!)\n@given(p=permutations())\ndef test_invert(p):\n    assert invert(p) >> p == FiniteFunction.identity(p.source)\n    assert p >> invert(p) == FiniteFunction.identity(p.source)", "def test_invert(p):\n    assert invert(p) >> p == FiniteFunction.identity(p.source)\n    assert p >> invert(p) == FiniteFunction.identity(p.source)\n\n# Definition A.2 \"Sorting\"\n@given(f=finite_functions())\ndef test_argsort_matches_definition(f):\n    p = f.argsort()\n    y = p >> f\n\n    if len(y.table) <= 1:\n        return None\n\n    assert sorts(p, f)", "\n# Proposition A.3\n# we test something slightly weaker; instead of a general monomorphism we just\n# use a permutation.\n# TODO: generate a monomorphism by just `spreading out' values of the identity\n# function, then permuting?\n@given(p=permutations())\ndef test_argsort_monomorphism_strictly_increasing(p):\n    q = p.argsort()\n    y = q >> p\n\n    if len(y.table) <= 1:\n        return None\n\n    assert sorts(q, p, strict=True)", "\n# TODO: test uniqueness A.4 (?)\n\n# Proposition A.5\n@given(fpq=adapted_function(source=None, target=None))\ndef test_sort_by_permuted_key(fpq):\n    f, p, q = fpq\n    s = f.argsort()\n    assert sorts(s >> invert(p), p >> f)\n", "\n# Proposition A.6\n# Again using permutations instead of monomorphisms;\n# see test_argsort_monomorphism_strictly_increasing\n@given(fp=parallel_permutations())\ndef test_sort_pf_equals_sortf_p(fp):\n    f, p = fp\n    assert (p >> f).argsort() == (f.argsort() >> invert(p))\n\n# interleave and its inverse cancel on both sides", "\n# interleave and its inverse cancel on both sides\n@given(n=objects)\ndef test_interleave_inverse(n: int):\n    a = FiniteFunction.interleave(n)\n    b = FiniteFunction.cointerleave(n)\n    i = FiniteFunction.identity(2*n)\n\n    assert a >> b == i\n    assert b >> a == i", "\n# Cointerleaving is the opposite of interleaving, and has a more meaningful\n# interpretation which we can test easily.\n@given(fg=parallel_arrows())\ndef test_cointerleave(fg):\n    f, g = fg\n    N = f.source\n    assert N == g.source # should be true because parallel_arrows\n\n    h = (f @ g)\n    a = FiniteFunction.cointerleave(N)\n    r = a >> h\n\n    Array = type(f)._Array\n\n    assert Array.all(r.table[0::2] == h.table[0:N])\n    assert Array.all(r.table[1::2] == h.table[N:])", ""]}
{"filename": "tests/test_optic.py", "chunked_list": ["from hypothesis import given\nfrom dataclasses import dataclass\nimport hypothesis.strategies as st\nfrom tests.strategies import *\n\n# testing against the numpy backend\nfrom yarrow.numpy import *\n\nfrom yarrow.functor.functor import *\nfrom yarrow.functor.optic import *", "from yarrow.functor.functor import *\nfrom yarrow.functor.optic import *\n\n# Assume a finite signature \u03a3.\n#\n# For each operation \u03a3\u2081\n#\n#   f : Ai \u2192 Aj\n#\n# Define residuals", "#\n# Define residuals\n#\n#   M_f\n#\n# And two operations in \u03a9\u2081 = \u03a3\u2081*2:\n#\n#   fwd(f) : fwd(Ai) \u25cf M_f \u2192 fwd(Aj)\n#   rev(f) : M_f \u25cf rev(Ai) \u2192 rev(Aj)\n# ", "#   rev(f) : M_f \u25cf rev(Ai) \u2192 rev(Aj)\n# \n# with fwd(f) = 2*f\n#      rev(f) = 2*f+1\n# \n# The types are determined by the action of fwd/rev on *objects*.\n\n@dataclass\nclass FiniteOpticFunctor(FrobeniusOpticFunctor):\n    \"\"\" Optic Functor whose action on generating objects is given, and whose action on operations is ... \"\"\"\n    # Assume categories C presented by \u03a3 and D presented by \u03a9.\n    # objects in \u03a3\u2080 are mapped to lists \u03a9\u2080*\n    wn_fwd: IndexedCoproduct # \u03a3\u2080 \u2192 \u03a9\u2080*\n    wn_rev: IndexedCoproduct # \u03a3\u2080 \u2192 \u03a9\u2080*\n    # \u03a3\u2080 \u2192 \u03a9\u2081 where \u03a9\u2081 = 2 * \u03a3\u2080\n\n    # Residuals map generating operations into some choice of object in D\n    # residuals : \u03a3\u2081 \u2192 \u03a9\u2080*\n    #   sources : \u03a3\u2081 \u2192 Ks\n    #   targets : \u03a3\u2081 \u2192 Kt\n    #   values  : \u03a3\u2081 \u2192 \u03a9\u2080\n    _residuals: IndexedCoproduct\n\n    def __post_init__(self):\n        assert len(self.wn_fwd) == len(self.wn_rev)\n        assert self.wn_fwd.values.target == self._residuals.values.target\n        assert self.wn_rev.values.target == self._residuals.values.target\n\n    def map_fwd_objects(self, objects) -> IndexedCoproduct:\n        # wn_fwd.sources associates to each object i \u2208 \u03a3\u2080 a size k(i).\n        # Thus to get the sizes of the coproducts, we just compose objects >> self.wn_fwd.sources\n        assert objects.target == len(self.wn_fwd)\n        result = IndexedCoproduct(\n                sources=objects >> self.wn_fwd.sources,\n                values = FiniteFunction(self.wn_fwd.values.target, self.wn_fwd.coproduct(objects).table))\n        return result\n\n    def map_rev_objects(self, objects) -> IndexedCoproduct:\n        assert objects.target == len(self.wn_rev)\n        return IndexedCoproduct(\n                sources=objects >> self.wn_rev.sources,\n                values = FiniteFunction(self.wn_rev.values.target, self.wn_rev.coproduct(objects).table))\n\n    def residuals(self, ops: Operations) -> IndexedCoproduct:\n        assert ops.xn.target == len(self._residuals)\n        return IndexedCoproduct(\n                sources=FiniteFunction(None, (ops.xn >> self._residuals.sources).table),\n                values=FiniteFunction(self.wn_fwd.values.target, self._residuals.coproduct(ops.xn).table))\n\n    def map_fwd_operations(self, ops: Operations) -> Diagram:\n        # Each operation f maps to the singleton diagram \n        #\n        #   2*f : F(A) \u2192 F(B) \u25cf M_f\n        #\n        # We could parallelize this, but it's easier to just use a loop for testing!\n        omega = ops.xn.target * 2\n\n        diagrams = []\n        for (x, a, b), M in zip(ops, self.residuals(ops)):\n            FA = self.map_fwd_objects(a).values\n            FB = self.map_fwd_objects(b).values\n            xn = FiniteFunction.singleton(2*x, omega)\n            diagrams.append(Diagram.singleton(FA, FB + M, xn))\n\n        wn = None \n        xn = None\n        if len(diagrams) == 0:\n            wn = FiniteFunction(self.wn_fwd.values.target, [])\n            xn = FiniteFunction(ops.xn.target, [])\n\n        return Diagram.tensor_list(diagrams, wn=wn, xn=xn), FiniteFunction(None, [ len(d.type[1]) for d in diagrams ])\n\n    def map_rev_operations(self, ops: Operations) -> Diagram:\n        omega = ops.xn.target * 2\n\n        diagrams = []\n        for (x, a, b), M in zip(ops, self.residuals(ops)):\n            FA = self.map_rev_objects(a).values\n            FB = self.map_rev_objects(b).values\n            xn = FiniteFunction.singleton(2*x+1, omega)\n            diagrams.append(Diagram.singleton(M + FB, FA, xn))\n\n        wn = None \n        xn = None\n        if len(diagrams) == 0:\n            wn = FiniteFunction(self.wn_rev.values.target, [])\n            xn = FiniteFunction(ops.xn.target, [])\n\n        # return Diagram.tensor_list(diagrams, wn=wn, xn=xn)\n        return Diagram.tensor_list(diagrams, wn=wn, xn=xn), FiniteFunction(None, [ len(d.type[0]) for d in diagrams ])", "class FiniteOpticFunctor(FrobeniusOpticFunctor):\n    \"\"\" Optic Functor whose action on generating objects is given, and whose action on operations is ... \"\"\"\n    # Assume categories C presented by \u03a3 and D presented by \u03a9.\n    # objects in \u03a3\u2080 are mapped to lists \u03a9\u2080*\n    wn_fwd: IndexedCoproduct # \u03a3\u2080 \u2192 \u03a9\u2080*\n    wn_rev: IndexedCoproduct # \u03a3\u2080 \u2192 \u03a9\u2080*\n    # \u03a3\u2080 \u2192 \u03a9\u2081 where \u03a9\u2081 = 2 * \u03a3\u2080\n\n    # Residuals map generating operations into some choice of object in D\n    # residuals : \u03a3\u2081 \u2192 \u03a9\u2080*\n    #   sources : \u03a3\u2081 \u2192 Ks\n    #   targets : \u03a3\u2081 \u2192 Kt\n    #   values  : \u03a3\u2081 \u2192 \u03a9\u2080\n    _residuals: IndexedCoproduct\n\n    def __post_init__(self):\n        assert len(self.wn_fwd) == len(self.wn_rev)\n        assert self.wn_fwd.values.target == self._residuals.values.target\n        assert self.wn_rev.values.target == self._residuals.values.target\n\n    def map_fwd_objects(self, objects) -> IndexedCoproduct:\n        # wn_fwd.sources associates to each object i \u2208 \u03a3\u2080 a size k(i).\n        # Thus to get the sizes of the coproducts, we just compose objects >> self.wn_fwd.sources\n        assert objects.target == len(self.wn_fwd)\n        result = IndexedCoproduct(\n                sources=objects >> self.wn_fwd.sources,\n                values = FiniteFunction(self.wn_fwd.values.target, self.wn_fwd.coproduct(objects).table))\n        return result\n\n    def map_rev_objects(self, objects) -> IndexedCoproduct:\n        assert objects.target == len(self.wn_rev)\n        return IndexedCoproduct(\n                sources=objects >> self.wn_rev.sources,\n                values = FiniteFunction(self.wn_rev.values.target, self.wn_rev.coproduct(objects).table))\n\n    def residuals(self, ops: Operations) -> IndexedCoproduct:\n        assert ops.xn.target == len(self._residuals)\n        return IndexedCoproduct(\n                sources=FiniteFunction(None, (ops.xn >> self._residuals.sources).table),\n                values=FiniteFunction(self.wn_fwd.values.target, self._residuals.coproduct(ops.xn).table))\n\n    def map_fwd_operations(self, ops: Operations) -> Diagram:\n        # Each operation f maps to the singleton diagram \n        #\n        #   2*f : F(A) \u2192 F(B) \u25cf M_f\n        #\n        # We could parallelize this, but it's easier to just use a loop for testing!\n        omega = ops.xn.target * 2\n\n        diagrams = []\n        for (x, a, b), M in zip(ops, self.residuals(ops)):\n            FA = self.map_fwd_objects(a).values\n            FB = self.map_fwd_objects(b).values\n            xn = FiniteFunction.singleton(2*x, omega)\n            diagrams.append(Diagram.singleton(FA, FB + M, xn))\n\n        wn = None \n        xn = None\n        if len(diagrams) == 0:\n            wn = FiniteFunction(self.wn_fwd.values.target, [])\n            xn = FiniteFunction(ops.xn.target, [])\n\n        return Diagram.tensor_list(diagrams, wn=wn, xn=xn), FiniteFunction(None, [ len(d.type[1]) for d in diagrams ])\n\n    def map_rev_operations(self, ops: Operations) -> Diagram:\n        omega = ops.xn.target * 2\n\n        diagrams = []\n        for (x, a, b), M in zip(ops, self.residuals(ops)):\n            FA = self.map_rev_objects(a).values\n            FB = self.map_rev_objects(b).values\n            xn = FiniteFunction.singleton(2*x+1, omega)\n            diagrams.append(Diagram.singleton(M + FB, FA, xn))\n\n        wn = None \n        xn = None\n        if len(diagrams) == 0:\n            wn = FiniteFunction(self.wn_rev.values.target, [])\n            xn = FiniteFunction(ops.xn.target, [])\n\n        # return Diagram.tensor_list(diagrams, wn=wn, xn=xn)\n        return Diagram.tensor_list(diagrams, wn=wn, xn=xn), FiniteFunction(None, [ len(d.type[0]) for d in diagrams ])", "\n@st.composite\ndef finite_optic_functor(draw):\n    sigma_0, omega_0 = draw(arrow_type())\n\n    wn_fwd  = draw(indexed_coproducts(N=sigma_0, Obj=omega_0))\n    wn_fwd.sources.target = None # bit of a hack\n\n    wn_rev  = draw(indexed_coproducts(N=sigma_0, Obj=omega_0))\n    wn_rev.sources.target = None # bit of a hack\n\n    sigma_1, _ = draw(arrow_type(target=omega_0))\n    residuals = draw(segmented_finite_functions(N=sigma_1, Obj=omega_0))\n\n    return FiniteOpticFunctor(wn_fwd, wn_rev, residuals)", "\n@st.composite\ndef finite_optic_functor_and_diagram(draw):\n    # F : Free_\u03a3 \u2192 Free_\u03a9\n    #   wn_fwd    : \u03a3\u2080 \u2192 \u03a9\u2080*\n    #   wn_rev    : \u03a3\u2080 \u2192 \u03a9\u2080*\n    #   residuals : \u03a3\u2081 \u2192 \u03a9\u2080*\n\n    F = draw(finite_optic_functor())\n    sigma_0 = len(F.wn_fwd)\n    sigma_1 = len(F._residuals)\n    omega_0 = F.wn_fwd.values.target\n    assert omega_0 == F.wn_rev.values.target\n    assert omega_0 == F._residuals.values.target\n    d = draw(diagrams(Obj=sigma_0, Arr=sigma_1))\n    return F, d", "\n@given(finite_optic_functor_and_diagram())\ndef test_optic_functor(Fd):\n    F, d = Fd\n    F.map_arrow(d)\n"]}
{"filename": "tests/test_bipartite_multigraph.py", "chunked_list": ["import pytest\n\nimport numpy as np\nfrom yarrow.numpy import *\n\nfrom hypothesis import given\nimport hypothesis.strategies as st\nfrom tests.strategies import *\n\n################################################################################", "\n################################################################################\n# Applying coequalizers to bipartite multigraphs\n\n@given(fg=parallel_arrows())\ndef test_universal_identity(fg):\n    f, g = fg\n    q = f.coequalizer(g)\n    u = universal(q, q)\n    assert u == FiniteFunction.identity(q.target)", "\n# A custom strategy for the test_universal_permutation test.\n@st.composite\ndef coequalizer_and_permutation(draw, source=None, target=None):\n    f, g = draw(parallel_arrows(source, target))\n    q = f.coequalizer(g)\n    p = draw(permutations(n=q.target))\n    return f, g, q, p\n\n@given(fgqp=coequalizer_and_permutation())\ndef test_universal_permutation(fgqp):\n    f, g, q1, p = fgqp\n    q2 = q1 >> p # a permuted coequalizer still coequalizes!\n    u = universal(q1, q2)\n    assert q1 >> u == q2", "\n@given(fgqp=coequalizer_and_permutation())\ndef test_universal_permutation(fgqp):\n    f, g, q1, p = fgqp\n    q2 = q1 >> p # a permuted coequalizer still coequalizes!\n    u = universal(q1, q2)\n    assert q1 >> u == q2\n\n################################################################################\n# Discrete BPMGs", "################################################################################\n# Discrete BPMGs\n\n@given(wn=finite_functions(source=0), xn=finite_functions(source=0))\ndef test_empty(wn, xn):\n    # constructor should run with no errors.\n    BipartiteMultigraph.empty(wn, xn)\n\n@given(wn=finite_functions(), xn=finite_functions(source=0))\ndef test_discrete(wn, xn):\n    # constructor should run with no errors.\n    BipartiteMultigraph.discrete(wn, xn)", "@given(wn=finite_functions(), xn=finite_functions(source=0))\ndef test_discrete(wn, xn):\n    # constructor should run with no errors.\n    BipartiteMultigraph.discrete(wn, xn)\n\n# Custom strategy for test_discrete_coequalize_wires\n@st.composite\ndef coequalizer_and_permutation(draw, source=None, target=None, ob=None):\n    f, g = draw(parallel_arrows(source, target))\n    W = f.target\n    wn   = draw(finite_functions(source=W, target=ob))\n    print(f'target: {W}')\n    print(f'wn    : {wn}')\n    xn   = draw(finite_functions(source=0))\n    return f, g, wn, xn", "\n# Given:\n#   f, g : A \u2192 W\n#   wn : W \u2192 1\n#   xn : 0 \u2192 \u03a3\u2081\n#   D: discrete(wn, xn)\n#   q = FF.coequalizer(f, g) : wn.source \u2192 Q\n# Ensure that wires can be coequalized.\n# NOTE: This only handles the PROP case when \u03a3\u2080 = 1\n@given(cap=coequalizer_and_permutation(ob=1))\ndef test_discrete_coequalize_unityped_wires(cap):\n    f, g, wn, xn = cap\n    q = f.coequalizer(g)\n    D = BipartiteMultigraph.discrete(wn, xn)\n    E = D.coequalize_wires(q)\n    assert E.wn.source == q.target", "# NOTE: This only handles the PROP case when \u03a3\u2080 = 1\n@given(cap=coequalizer_and_permutation(ob=1))\ndef test_discrete_coequalize_unityped_wires(cap):\n    f, g, wn, xn = cap\n    q = f.coequalizer(g)\n    D = BipartiteMultigraph.discrete(wn, xn)\n    E = D.coequalize_wires(q)\n    assert E.wn.source == q.target\n\n# TODO: FIXME: Need to test coequalize_wires with genuine label-preserving maps!", "\n# TODO: FIXME: Need to test coequalize_wires with genuine label-preserving maps!\n"]}
{"filename": "tests/test_diagram.py", "chunked_list": ["import pytest\nimport unittest\n\nimport numpy as np\nfrom yarrow.numpy import *\n\nfrom hypothesis import given\nimport hypothesis.strategies as st\nfrom tests.strategies import *\n", "from tests.strategies import *\n\n################################################################################\n# Primitives\n\n@given(wn=finite_functions(source=0), xn=finite_functions(source=0))\ndef test_empty(wn, xn):\n    # Should run without errors\n    e = Diagram.empty(wn, xn)\n    (A, B) = e.type\n    assert A == FiniteFunction.initial(wn.target)\n    assert B == FiniteFunction.initial(wn.target)\n    assert e.s == FiniteFunction.initial(0)\n    assert e.t == FiniteFunction.initial(0)", "\n@given(wn=finite_functions(), xn=finite_functions(source=0))\ndef test_identity(wn: FiniteFunction, xn: FiniteFunction):\n    # Should run without errors\n    d = Diagram.identity(wn, xn)\n    (A, B) = d.type\n    assert A == wn\n    assert B == wn\n\n@given(ab=parallel_arrows(), xn=finite_functions(source=0))\ndef test_twist(ab, xn: FiniteFunction):\n    wn_A, wn_B = ab\n\n    d = Diagram.twist(wn_A, wn_B, xn)\n    (S, T) = d.type\n    assert S == wn_A + wn_B\n    assert T == wn_B + wn_A", "\n@given(ab=parallel_arrows(), xn=finite_functions(source=0))\ndef test_twist(ab, xn: FiniteFunction):\n    wn_A, wn_B = ab\n\n    d = Diagram.twist(wn_A, wn_B, xn)\n    (S, T) = d.type\n    assert S == wn_A + wn_B\n    assert T == wn_B + wn_A\n", "\n# TODO!\n# @unittest.skip\n# @given(ab=parallel_arrows(), xn=finite_functions(source=0))\n# def test_twist(ab, xn: FiniteFunction):\n    # wn_A, wn_B = ab\n\n    # d = Diagram.twist(wn, xn)\n    # # TODO: can't implement this as below; no guarantee we'll not get something like (p,\n    # # p^{-1}, G) instead!", "    # # TODO: can't implement this as below; no guarantee we'll not get something like (p,\n    # # p^{-1}, G) instead!\n    # d >> d == Diagram.identity(d.wires)\n    # (S, T) = d.type\n    # assert S == wn_A + wn_B\n    # assert T == wn_B + wn_A\n\n\n@given(stw=labeled_cospans(), x=finite_functions(source=0))\ndef test_spider(stw, x):\n    \"\"\" Given a random cospan\n          s   t\n        A \u2192 W \u2190 B\n    And a labeling\n        w : W \u2192 \u03a3\u2080\n    Generates a random spider.\n    \"\"\"\n    s, t, w = stw\n    Diagram.spider(s, t, w, x)", "@given(stw=labeled_cospans(), x=finite_functions(source=0))\ndef test_spider(stw, x):\n    \"\"\" Given a random cospan\n          s   t\n        A \u2192 W \u2190 B\n    And a labeling\n        w : W \u2192 \u03a3\u2080\n    Generates a random spider.\n    \"\"\"\n    s, t, w = stw\n    Diagram.spider(s, t, w, x)", "\n@given(d=spiders())\ndef test_dagger_spider(d: Diagram):\n    e = d.dagger()\n    assert e.s == d.t\n    assert e.t == d.s\n\n    X = e.type\n    Y = d.type\n    assert X[0] == Y[1]\n    assert X[1] == Y[0]\n\n    assert e.G == d.G", "\n@given(abx=generator_and_typing())\ndef test_singleton(abx):\n    a, b, xn = abx\n    # test constructor works\n    d = Diagram.singleton(a, b, xn)\n    (A, B) = d.type\n    # Type of the diagram should be the same as the chosen typing of the generator.\n    assert a == A\n    assert b == B\n    # The number of internal wires should be equal to the number of ports on the\n    # generator.\n    assert d.wires == a.source + b.source", "\n################################################################################\n# Tensor\n\n@given(ds=many_diagrams(n=2))\ndef test_tensor_type(ds):\n    \"\"\" Check that the tensor of two diagrams has the correct type and preserves\n    the number of wires and edges \"\"\"\n    d1, d2 = ds\n\n    d = d1.tensor(d2)\n    S, T = d.type\n\n    S1, T1 = d1.type\n    S2, T2 = d2.type\n\n    # NOTE: types are maps  N \u2192 \u03a3\u2080, so we take their COPRODUCT!\n    assert S == S1 + S2\n    assert T == T1 + T2\n    assert d.wires == d1.wires + d2.wires\n    assert d.G.Ei == d1.G.Ei + d2.G.Ei\n    assert d.G.Eo == d1.G.Eo + d2.G.Eo", "\n################################################################################\n# Composition\n\n@given(fg=composite_diagrams())\ndef test_compose_type(fg):\n    f, g = fg\n    h = f >> g\n\n    A, B = f.type\n    B2, C = g.type\n    assert B == B2\n    assert h.type == (A, C)", "\n@given(fg=composite_diagrams())\ndef test_compose_nonfinite_signature(fg):\n    # TODO: FIXME: this test should not exist. Instead, diagrams with non-finite\n    # signatures should be generated by the hypothesis strategies.\n    f, g = fg\n\n    def objectify(f: Diagram):\n        # modify the wn and xn arrays of a diagram f in place\n        # so they have the dtype object.\n        # It doesn't matter too much what the actual objects are.\n        wn = np.empty_like(f.G.wn.table, dtype='object')\n        wn[:] = [(x,x) for x in f.G.wn.table] # put tuples in.\n\n        xn = np.empty_like(f.G.xn.table, dtype='object')\n        xn[:] = [(x,x) for x in f.G.xn.table]\n\n        f.G.wn = FiniteFunction(None, wn)\n        f.G.xn = FiniteFunction(None, xn)\n\n    objectify(f)\n    objectify(g)\n\n    h = f >> g\n    A, B = f.type\n    B2, C = g.type\n    assert B == B2\n    assert h.type == (A, C)", "\n@given(fg=composite_diagrams())\ndef test_compose_wire_count(fg):\n    \"\"\" Check that the number of wires in a composite is within a certain range \"\"\"\n    f, g = fg\n    h = f >> g\n    # If f has M wires in the boundary, and g has N,\n    # we might quotient M+N \u2192 0.\n    # So wires in the composite f >> g is no more than the composite f @ g,\n    # but greater than or equal to f.W + g.W - (M + N)\n    M = f.t.target\n    N = g.s.target\n    assert h.wires <= (f.wires + g.wires) and \\\n           h.wires >= (f.wires + g.wires - (M + N))", "\n@given(f=diagrams())\ndef test_compose_dagger(f):\n    A, B = f.type\n    g = f.dagger()\n    h = f >> g\n\n\n    X, Y = h.type\n    assert X == A\n    assert Y == A", "\n@given(f=singletons())\ndef test_compose_singleton_dagger(f):\n    A, B = f.type\n    g = f.dagger()\n    h = f >> g\n\n    X, Y = h.type\n    assert X == A\n    assert Y == A\n\n    # Check that the total number of wires in the result is equal to those of f\n    # and g minus the shared boundary.\n    assert (f.wires + g.wires - (B.source)) == h.wires\n\n    # Since the result is a composition of singletons, we should also expect\n    # that the set of nodes appearing in the image of s is completely disjoint\n    # from t.\n    assert set(h.s.table).isdisjoint(set(h.t.table))", "\n@given(fg=many_singletons(n=2))\ndef test_tensor_singletons(fg):\n    f, g = fg\n    A0, B0 = f.type\n    A1, B1 = g.type\n\n    h = f @ g\n    assert h.type == (A0 + A1, B0 + B1)\n", "\n@given(fg=composite_singletons())\ndef test_compose_singletons(fg):\n    \"\"\" Explicitly test that singletons can be composed \"\"\"\n    f, g = fg\n\n    A, B = f.type\n    B_, C = g.type\n    assert B == B_\n\n    h = f >> g\n\n    A_, C_ = h.type\n    assert A == A_\n    assert C == C_", "\n################################################################################\n# N-fold tensor of a list of diagrams\n\n@given(d=diagrams())\ndef test_tensor_list_empty(d):\n    # generate a random diagram and use its signature, but not the actual\n    # diagram content.\n    wn = d._Fun.initial(d.G.wn.target)\n    xn = d._Fun.initial(d.G.xn.target)\n    assert Diagram.tensor_list([], wn, xn) == Diagram.empty(wn, xn)", "\n@given(ds=many_diagrams(min_n=1))\ndef test_tensor_list(ds):\n    \"\"\" Check that the tensor of two diagrams has the correct type and preserves\n    the number of wires and edges \"\"\"\n    assert len(ds) > 0\n\n    # slowly compute the tensor product in O(n\u00b2) time\n    expected = ds[0]\n    for d in ds[1:]:\n        expected = expected @ d\n\n    actual = Diagram.tensor_list(ds)\n    assert expected == actual", ""]}
{"filename": "tests/test_decompose.py", "chunked_list": ["import pytest\nfrom yarrow.decompose.frobenius import frobenius_decomposition\n\nfrom hypothesis import given\nimport hypothesis.strategies as st\n\nfrom tests.strategies import *\nfrom tests.util import monotonic, is_segmented_arange\n\n@given(c=diagrams())\ndef test_sort_x_p(c):\n    pass", "\n@given(c=diagrams())\ndef test_sort_x_p(c):\n    pass\n\n@given(c=diagrams())\ndef test_frobenius_decomposition(c):\n    # Check the function doesn't crash!\n    frobenius_decomposition(c)\n", "\n@given(c=diagrams())\ndef test_frobenius_decomposition_type(c):\n    # Check that a frobenius decomposition has the same type as the diagram being decomposed\n    d = frobenius_decomposition(c)\n    A1, B1 = c.type\n    A2, B2 = d.type\n    assert A1 == A2\n    assert B1 == B2\n", "\n@given(c=diagrams())\ndef test_frobenius_decomposition_monotonic(c):\n    # Check that components of a Frobenius decomposition are in\n    # (generator, port) order.\n    d = frobenius_decomposition(c)\n\n    # (generator, port) order means xi and xo should be arrays of the form\n    # 0 0 0 ... | 1 1 1 ... | 2 2 2 ... |\n    assert monotonic(d.G.xi.table)\n    assert monotonic(d.G.xo.table)\n\n    # similarly, ports should be increasing \"runs\" (i.e., segmented aranges) of\n    # the form\n    # 0 1 2 ... | 0 1 2 ... | ...\n    assert is_segmented_arange(d.G.pi.table)\n    assert is_segmented_arange(d.G.po.table)", ""]}
{"filename": "tests/test_strategies.py", "chunked_list": ["\"\"\" Tests for the test strategies! Test all the things! \"\"\"\nfrom hypothesis import given\nimport hypothesis.strategies as st\nfrom tests.strategies import *\n\n@given(f=finite_functions(source=2))\ndef test_healthcheck_finite_functions(f):\n    assert (f.target != 0 if f.source != 0 else True)\n\n@given(AB=arrow_type(target=0))\ndef test_arrow_type_target_zero(AB):\n    A, B = AB\n    assert B == 0\n    assert A == 0", "\n@given(AB=arrow_type(target=0))\ndef test_arrow_type_target_zero(AB):\n    A, B = AB\n    assert B == 0\n    assert A == 0\n\n@given(f=finite_functions(target=0))\ndef test_finite_functions_target_zero(f):\n    assert f.source == 0", "def test_finite_functions_target_zero(f):\n    assert f.source == 0\n\n@given(fg=composite_diagrams())\ndef test_composite_diagrams(fg):\n    f, g = fg\n    assert f.type[1] == g.type[0]\n\n@given(fg=composite_singletons())\ndef test_composite_singletons(fg):\n    f, g = fg\n    assert f.operations == 1\n    assert g.operations == 1\n    assert f.type[1] == g.type[0]", "@given(fg=composite_singletons())\ndef test_composite_singletons(fg):\n    f, g = fg\n    assert f.operations == 1\n    assert g.operations == 1\n    assert f.type[1] == g.type[0]\n\n@given(fg=many_singletons(n=2))\ndef test_many_singletons(fg):\n    f, g = fg\n    assert f.G.wn.target == g.G.wn.target\n    assert f.G.xn.target == g.G.xn.target", "def test_many_singletons(fg):\n    f, g = fg\n    assert f.G.wn.target == g.G.wn.target\n    assert f.G.xn.target == g.G.xn.target\n\n@given(sff=segmented_finite_functions())\ndef test_segmented_finite_function(sff):\n    assert sff.sources.source == sff.targets.source\n    assert np.sum(sff.sources.table) == sff.values.source\n    # values are in the range [0, N)\n    # targets are all exactly N, so targets has codomain N+1.\n    assert sff.targets.target == sff.values.target +1", "\n@given(ops=operations())\ndef test_operations(ops):\n    xn, s_type, t_type = ops.xn, ops.s_type, ops.t_type\n    N = xn.source\n    assert len(s_type.sources) == N\n    assert len(t_type.sources) == N\n\n    assert np.sum(s_type.sources.table) == s_type.values.source\n    assert np.sum(t_type.sources.table) == t_type.values.source", "\n@given(sff_f_wn=object_map_and_half_spider())\ndef test_object_map_and_half_spider(sff_f_wn):\n    sff, f, wn = sff_f_wn\n    assert sff.sources.source == wn.target\n    assert f.target == wn.source\n"]}
{"filename": "tests/test_segmented.py", "chunked_list": ["from hypothesis import given\nimport hypothesis.strategies as st\n\nfrom yarrow.numpy import FiniteFunction, SegmentedFiniteFunction\n\nfrom tests.strategies import *\n\n@given(fsx=common_targets())\ndef test_indexed_coproduct(fsx):\n    \"\"\" Test the sequential indexed coproduct against parallel/vectorised one \"\"\"\n    fs, x = fsx\n\n    target = 0 if len(fs) == 0 else fs[0].target\n    expected = \\\n        FiniteFunction.coproduct_list([ fs[x(i)] for i in range(0, x.source) ], target)\n    actual = SegmentedFiniteFunction.from_list(fs).coproduct(x)\n\n    assert actual == expected\n    assert actual.source == sum(fs[x(i)].source for i in range(0, x.source))\n    assert actual.target == target", "def test_indexed_coproduct(fsx):\n    \"\"\" Test the sequential indexed coproduct against parallel/vectorised one \"\"\"\n    fs, x = fsx\n\n    target = 0 if len(fs) == 0 else fs[0].target\n    expected = \\\n        FiniteFunction.coproduct_list([ fs[x(i)] for i in range(0, x.source) ], target)\n    actual = SegmentedFiniteFunction.from_list(fs).coproduct(x)\n\n    assert actual == expected\n    assert actual.source == sum(fs[x(i)].source for i in range(0, x.source))\n    assert actual.target == target", "\n@given(fsx=finite_function_lists())\ndef test_indexed_tensor(fsx):\n    \"\"\" Test the sequential indexed *tensor* against parallel/vectorised one \"\"\"\n    fs, x = fsx\n    expected = FiniteFunction.tensor_list([fs[x(i)] for i in range(0, x.source) ])\n    actual   = SegmentedFiniteFunction.from_list(fs).tensor(x)\n    assert actual == expected\n    assert actual.source == sum(fs[x(i)].source for i in range(0, x.source))\n    assert actual.target == sum(fs[x(i)].target for i in range(0, x.source))", "\n@given(segmented_finite_functions())\ndef test_segmented_finite_functions_roundtrip(sff):\n    # Given a list of functions, we can convert to a segmented finite function and back losslessly.\n    # NOTE: this is not true the other way, because there are multiple valid target values for the 'sources' and 'targets' fields.\n    fs = list(sff)\n    roundtrip = list(type(sff).from_list(fs))\n    assert fs == roundtrip\n\n@given(segmented_finite_functions())\ndef test_segmented_finite_functions_roundtrip_op(sff):\n    # Roundtrip from SFF \u2192 list \u2192 SFF\n    # NOTE: this is not lossless, since sff.sources.target and\n    # sff.targets.target values might be lost.\n    roundtrip = type(sff).from_list(list(sff))\n\n    # sources must match exactly, but we ignore the domains of finite functions\n    # because there are multiple valid choices.\n    assert np.all(sff.sources.table == roundtrip.sources.table)\n    assert np.all(sff.targets.table == roundtrip.targets.table)\n    assert np.all(sff.values.table  == roundtrip.values.table)", "\n@given(segmented_finite_functions())\ndef test_segmented_finite_functions_roundtrip_op(sff):\n    # Roundtrip from SFF \u2192 list \u2192 SFF\n    # NOTE: this is not lossless, since sff.sources.target and\n    # sff.targets.target values might be lost.\n    roundtrip = type(sff).from_list(list(sff))\n\n    # sources must match exactly, but we ignore the domains of finite functions\n    # because there are multiple valid choices.\n    assert np.all(sff.sources.table == roundtrip.sources.table)\n    assert np.all(sff.targets.table == roundtrip.targets.table)\n    assert np.all(sff.values.table  == roundtrip.values.table)", "\n################################################################################\n# Segmented operations\n\n@given(ops=operations())\ndef test_tensor_operations_type(ops):\n    d = Diagram.tensor_operations(ops)\n\n    A, B = d.type\n    assert A == ops.s_type.values\n    assert B == ops.t_type.values\n\n    # check number of edges and wires in the diagram.\n    # Ei should be equal to total input arity\n    # Eo equal to total output arity\n    # wires = Ei + Eo.\n    Ki = len(ops.s_type.values)\n    Ko = len(ops.t_type.values)\n\n    assert d.G.W  == Ki + Ko\n    assert d.G.Ei == Ki\n    assert d.G.Eo == Ko\n    assert d.G.X  == ops.xn.source", "\n@given(ops=operations())\ndef test_operations_iter(ops):\n    ops_list = list(ops)\n    assert len(ops_list) == len(ops)\n    assert np.all(np.array([ x[0] for x in ops_list ], dtype=ops.xn.table.dtype) == ops.xn.table)\n    # check types have correct codomain (i.e. \u03a3\u2080)\n    assert np.all(np.array([ x[1].target for x in ops_list ], dtype=int) == ops.s_type.values.target)\n    assert np.all(np.array([ x[2].target for x in ops_list ], dtype=int) == ops.t_type.values.target)\n", ""]}
{"filename": "tests/test_indexed_coproduct.py", "chunked_list": ["from yarrow import *\n\nfrom hypothesis import given\nimport hypothesis.strategies as st\nfrom tests.strategies import *\n\n@given(c=indexed_coproducts())\ndef test_indexed_coproduct_roundtrip(c):\n    assert c == IndexedCoproduct.from_list(c.target, list(c))\n", "\n@given(fsx=common_targets())\ndef test_indexed_coproduct_roundtrip_functions(fsx):\n    fs, x = fsx\n    target = 0 if len(fs) == 0 else fs[0].target\n    assert fs == list(IndexedCoproduct.from_list(target, fs))\n\n@given(fsx=common_targets())\ndef test_indexed_coproduct_map(fsx):\n    # a bunch of finite functions \"fs\" with common target.\n    fs, x = fsx\n    target = 0 if len(fs) == 0 else fs[0].target\n\n    expected_sources = FiniteFunction(None, [len(fs[x(i)]) for i in range(0, x.source) ])\n    expected_values = FiniteFunction.coproduct_list([ fs[x(i)] for i in range(0, x.source) ], target)\n\n    c = IndexedCoproduct.from_list(target, fs)\n    assert len(c) == len(fs)\n\n    d = c.map(x)\n    assert len(d) == x.source\n\n    assert d.sources == expected_sources\n    assert d.values == expected_values", "def test_indexed_coproduct_map(fsx):\n    # a bunch of finite functions \"fs\" with common target.\n    fs, x = fsx\n    target = 0 if len(fs) == 0 else fs[0].target\n\n    expected_sources = FiniteFunction(None, [len(fs[x(i)]) for i in range(0, x.source) ])\n    expected_values = FiniteFunction.coproduct_list([ fs[x(i)] for i in range(0, x.source) ], target)\n\n    c = IndexedCoproduct.from_list(target, fs)\n    assert len(c) == len(fs)\n\n    d = c.map(x)\n    assert len(d) == x.source\n\n    assert d.sources == expected_sources\n    assert d.values == expected_values", ""]}
{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/test_vector.py", "chunked_list": ["# Vector program tests\nimport numpy as np\nfrom yarrow.array import numpy\n\nfrom hypothesis import given\nimport hypothesis.strategies as st\nfrom tests.strategies import *\n\n# A \"run\" of length N being e.g. 0 1 2 3 4 ... N\n_MAX_RUN_LENGTH = 128", "# A \"run\" of length N being e.g. 0 1 2 3 4 ... N\n_MAX_RUN_LENGTH = 128\n_MAX_RUNS = 128\n\n# A non-vectorised implementation of segmented_arange\ndef _slow_segmented_arange(x):\n    x = np.array(x)\n\n    N = np.sum(x) # how many values to make?\n    r = np.zeros(N, dtype=x.dtype) # allocate\n\n    k = 0\n    # for each size s,\n    for i in range(0, len(x)):\n        size = x[i]\n        # fill result with a run 0, 1, ..., s\n        for j in range(0, size):\n            r[k] = j\n            k += 1\n\n    return r", "\n@given(\n    x=st.lists(st.integers(min_value=0, max_value=_MAX_RUN_LENGTH), min_size=0, max_size=_MAX_RUNS)\n)\ndef test_segmented_arange(x):\n    \"\"\" Ensure the 'segmented_arange' vector program outputs runs like 0, 1, 2, 0, 1, 2, 3, 4, ... \"\"\"\n    # We're returning an array of size MAX_VALUE * MAX_SIZE, so keep it smallish!\n    x = np.array(x, dtype=int)\n    N = np.sum(x)\n    a = numpy.segmented_arange(x)\n\n    # Check we got the expected number of elements\n    assert len(a) == N\n    assert np.all(_slow_segmented_arange(x) == a)", ""]}
{"filename": "tests/strategies.py", "chunked_list": ["\"\"\" Hypothesis strategies for FiniteFunctions \"\"\"\nimport numpy as np\nfrom yarrow.array import numpy\nfrom yarrow import FiniteFunction, BipartiteMultigraph, Diagram, SegmentedFiniteFunction, IndexedCoproduct\nfrom yarrow.segmented.operations import Operations\n\nimport hypothesis.strategies as st\n\n# these constants are completely arbitrary, I picked a smallish number I like.\n_MAX_SEGMENT_SIZE = 32", "# these constants are completely arbitrary, I picked a smallish number I like.\n_MAX_SEGMENT_SIZE = 32\n_MAX_SIGMA_1 = 32\n_MAX_OBJECTS = 32\n\n# generator for arity/coarity of operations\nsegment_sizes = st.integers(min_value=0, max_value=_MAX_SEGMENT_SIZE)\n\n# generator for finite sets \u03a3\u2081\nsigma_1 = st.integers(min_value=0, max_value=_MAX_SIGMA_1)", "# generator for finite sets \u03a3\u2081\nsigma_1 = st.integers(min_value=0, max_value=_MAX_SIGMA_1)\nnonzero_sigma_1 = st.integers(min_value=1, max_value=_MAX_SIGMA_1)\n\n# a generator for objects of FinFun\nobjects = st.integers(min_value=0, max_value=_MAX_OBJECTS)\nnonzero_objects = st.integers(min_value=1, max_value=32)\n\ndef _is_valid_arrow_type(s, t):\n    if t == 0:\n        return s == 0\n    return True", "def _is_valid_arrow_type(s, t):\n    if t == 0:\n        return s == 0\n    return True\n\n@st.composite\ndef arrow_type(draw, source=None, target=None):\n    \"\"\" Generate a random type of finite function.\n    For example, a type of n \u2192 0 is forbidden.\n    \"\"\"\n    # User specified both target and source\n    if target is not None and source is not None:\n        if target == 0 and source != 0:\n            raise ValueError(\"No arrows exist of type n \u2192 0 for n != 0.\")\n        return source, target\n\n    elif source is None:\n        # any target\n        target = draw(objects) if target is None else target\n\n        if target == 0:\n            source = 0\n        else:\n            source = draw(objects)\n\n        return source, target\n\n    # target is None, but source is not\n    target = draw(nonzero_objects) if source > 0 else draw(objects)\n    return source, target", "\n# generate a random FiniteFunction\n@st.composite\ndef finite_functions(draw, source=None, target=None):\n    source, target = draw(arrow_type(source=source, target=target))\n    assert _is_valid_arrow_type(source, target)\n\n    # generate a random array of elements in {0, ..., target - 1}\n    if target == 0:\n        # FIXME: remove np hardcoding for other backends.\n        table = np.zeros(0, dtype=int)\n    else:\n        table = np.random.randint(0, high=target, size=source)\n\n    return FiniteFunction(target, table)", "\n@st.composite\ndef finite_function_lists(draw, n=None, source=None, target=None):\n    \"\"\" Draw a small-ish list of N finite functions, and an indexer x : X \u2192 N\"\"\"\n    n = n if n is not None else draw(objects)\n    fs = [ draw(finite_functions(source=source, target=target)) ]\n    x = draw(finite_functions(target=len(fs)))\n    return fs, x\n\n# Generate exactly n composite functions.", "\n# Generate exactly n composite functions.\n@st.composite\ndef composite_functions(draw, n):\n    # NOTE: n is the number of *arrows*, so we need n+1 *objects*.\n    #\n    #    f\u2081   f\u2082 ... fn\n    # A\u2080 \u2192 A\u2081 \u2192  ... \u2192 An\n\n    if n == 0:\n        return []\n\n    # for each function f : A \u2192 B, if B = 0, then A = 0.\n    # This is because there can be no functions n \u2192 0 with n != 0\n    obj = draw(st.lists(objects, min_size=n+1, max_size=n+1))\n    for i in range(0, n+1):\n        if obj[-i] == 0:\n            obj[-i-1] = 0\n\n    fs = [ draw(finite_functions(source=a, target=b)) for a, b in zip(obj, obj[1:]) ]\n    return fs", "\n# generate h : X \u2192 B,\n# and from this generate f : A\u2081 \u2192 B, g : A\u2082 \u2192 B\n# such that A\u2081 + A\u2082 = X\n# and f + g = h\n@st.composite\ndef composite_coproduct(draw, source=None, target=None):\n    source, target = draw(arrow_type(source, target))\n    assert _is_valid_arrow_type(source, target)\n    a1 = draw(st.integers(min_value=0, max_value=source))\n    a2 = source - a1\n\n    f = draw(finite_functions(source=a1, target=target))\n    g = draw(finite_functions(source=a2, target=target))\n\n    return f, g", "\n@st.composite\ndef common_targets(draw, n=None, source=None, target=None):\n    \"\"\" Draw a list of random functions with the same target,\n\n        fs[i] : A_i \u2192 B\n\n    For i \u2208 N, and an indexing function\n\n        x : X \u2192 N\n    \"\"\"\n    n = draw(objects) if n is None else n\n\n    target = draw(objects) if target is None else target\n\n    fs = []\n    for i in range(0, n):\n        source, _ = draw(arrow_type(target=target))\n        fs.append(draw(finite_functions(source=source, target=target)))\n\n    x = draw(finite_functions(target=n))\n    return fs, x", "\n@st.composite\ndef parallel_arrows(draw, source=None, target=None):\n    source, target = draw(arrow_type(source, target))\n    assert _is_valid_arrow_type(source, target)\n\n    f = draw(finite_functions(source=source, target=target))\n    g = draw(finite_functions(source=source, target=target))\n    return f, g\n", "\n@st.composite\ndef parallel_permutations(draw, source=None, target=None):\n    n = draw(objects)\n    assert _is_valid_arrow_type(n, n)\n    p = draw(permutations(n))\n    q = draw(permutations(n))\n    return p, q\n\n@st.composite\ndef permutations(draw, n=None):\n    if n is None:\n        n = draw(objects)\n    x = np.arange(0, n, dtype=int)\n    np.random.shuffle(x)\n    return FiniteFunction(n, x)", "\n@st.composite\ndef permutations(draw, n=None):\n    if n is None:\n        n = draw(objects)\n    x = np.arange(0, n, dtype=int)\n    np.random.shuffle(x)\n    return FiniteFunction(n, x)\n\n@st.composite\ndef adapted_function(draw, source=None, target=None):\n    source, target = draw(arrow_type(source, target))\n    assert _is_valid_arrow_type(source, target)\n\n    f = draw(finite_functions(source=source, target=target))\n    p = draw(permutations(n=source))\n    q = draw(permutations(n=target))\n\n    return f, p, q", "\n@st.composite\ndef adapted_function(draw, source=None, target=None):\n    source, target = draw(arrow_type(source, target))\n    assert _is_valid_arrow_type(source, target)\n\n    f = draw(finite_functions(source=source, target=target))\n    p = draw(permutations(n=source))\n    q = draw(permutations(n=target))\n\n    return f, p, q", "\n################################################################################\n# Diagrams\n\n# Draw a cospan\n#   s : A \u2192 W\n#   t : B \u2192 W\n#   w : W \u2192 \u03a3\u2080\n@st.composite\ndef labeled_cospans(draw, W=None, Ob=None, A=None, B=None):\n    w = draw(finite_functions(source=W, target=Ob))\n    s = draw(finite_functions(source=A, target=w.source))\n    t = draw(finite_functions(source=B, target=w.source))\n    return (s, t, w)", "@st.composite\ndef labeled_cospans(draw, W=None, Ob=None, A=None, B=None):\n    w = draw(finite_functions(source=W, target=Ob))\n    s = draw(finite_functions(source=A, target=w.source))\n    t = draw(finite_functions(source=B, target=w.source))\n    return (s, t, w)\n\n@st.composite\ndef spiders(draw, W=None, Ob=None, A=None, B=None, Arr=None):\n    \"\"\" Given a random cospan\n          s   t\n        A \u2192 W \u2190 B\n    And a labeling\n        w : W \u2192 \u03a3\u2080\n    Generate a random spider.\n    \"\"\"\n    s, t, w = draw(labeled_cospans(W=W, Ob=Ob, A=A, B=B))\n\n    x = draw(finite_functions(source=0, target=Arr))\n    return Diagram.spider(s, t, w, x)", "def spiders(draw, W=None, Ob=None, A=None, B=None, Arr=None):\n    \"\"\" Given a random cospan\n          s   t\n        A \u2192 W \u2190 B\n    And a labeling\n        w : W \u2192 \u03a3\u2080\n    Generate a random spider.\n    \"\"\"\n    s, t, w = draw(labeled_cospans(W=W, Ob=Ob, A=A, B=B))\n\n    x = draw(finite_functions(source=0, target=Arr))\n    return Diagram.spider(s, t, w, x)", "\n@st.composite\ndef generator_and_typing(draw, Obj=None, Arr=None):\n    \"\"\" Generate a random generator\n        x : 1 \u2192 \u03a3\u2081\n    and its type\n        a : A \u2192 \u03a3\u2080\n        b : B \u2192 \u03a3\u2080\n    \"\"\"\n    # \u03a3\u2081 > 0, \u03a3\u2080 > 0\n    Arr = draw(nonzero_objects) if Arr is None else Arr\n    Obj = draw(nonzero_objects) if Obj is None else Obj\n\n    # xn : 1 \u2192 \u03a3\u2081\n    xn = draw(finite_functions(source=1, target=Arr))\n\n    # Typing\n    a = draw(finite_functions(target=Obj))\n    b = draw(finite_functions(target=Obj))\n\n    return a, b, xn", "\n@st.composite\ndef singletons(draw, Obj=None, Arr=None):\n    a, b, xn = draw(generator_and_typing(Obj=Obj, Arr=Arr))\n    return Diagram.singleton(a, b, xn)\n\n@st.composite\ndef diagrams(draw, Obj=None, Arr=None):\n    \"\"\" Generate a random diagram.\n    Since we're also generating a random signature,\n    we only need to ensure that ports are correct.\n    \"\"\"\n    Array = numpy\n\n    # \u03a3\u2080 > 0    \u03a3\u2081 \u2265 0\n    Obj = Obj if Obj is not None else draw(objects)\n    Arr = Arr if Arr is not None else draw(objects)\n\n    # max arity, coarity of generators.\n    # These get set to 0 if there are no wires in the diagram.\n    MAX_ARITY = None\n    MAX_COARITY = None\n\n    # Start with the number of wires in the diagram\n    # NOTE: This probably biases generation somehow.\n    wn = draw(finite_functions(target=Obj))\n\n    if wn.source == 0 or Arr == 0:\n        MAX_ARITY = 0\n        MAX_COARITY = 0\n        # return Diagram.empty(wn)\n\n    # 'arities' maps each generator xn(i) to its arity\n    arities   = draw(finite_functions(target=MAX_ARITY))\n    Ei = np.sum(arities.table)\n\n    coarities = draw(finite_functions(source=arities.source, target=MAX_COARITY))\n    Eo = np.sum(coarities.table)\n\n    # Now choose the number of generators and their arity/coarity.\n    xn = draw(finite_functions(source=arities.source, target=Arr))\n\n    # wi : Ei \u2192 W\n    # NOTE: Hypothesis builtin strategies really don't like numpy's int64s!\n    wi = draw(finite_functions(source=int(Ei), target=wn.source))\n    wo = draw(finite_functions(source=int(Eo), target=wn.source))\n\n    # pi and po are a 'segmented arange' of the arities and coarities\n    # e.g., [ 3 2 0 5 ] \u2192 [ 0 1 2 0 1 0 1 2 3 4 ]\n    pi = FiniteFunction(None, Array.segmented_arange(arities.table))\n    po = FiniteFunction(None, Array.segmented_arange(coarities.table))\n\n    # relatedly, xi and xo are just a repeat:\n    # (TODO: we could inline segmented_arange here and save recomputation of e.g., repeats)\n    # e.g., [ 3 2 0 5 ] \u2192 [ 0 0 0 1 1 2 2 2 2 2 ]\n    i = Array.arange(xn.source, dtype=int)\n    xi = FiniteFunction(xn.source, Array.repeat(i, arities.table))\n    xo = FiniteFunction(xn.source, Array.repeat(i, coarities.table))\n\n    G = BipartiteMultigraph(\n            wi=wi,\n            wo=wo,\n\n            xi=xi,\n            xo=xo,\n\n            wn=wn,\n            pi=pi,\n            po=po,\n            xn=xn)\n\n    s = draw(finite_functions(target=wn.source))\n    t = draw(finite_functions(target=wn.source))\n    return Diagram(s, t, G)", "\n@st.composite\ndef many_diagrams(draw, n=None, min_n=0, max_n=32):\n    \"\"\" Generate several diagrams from the same signature \"\"\"\n    # TODO: allow Obj = 0? Then we can only ever generate the empty diagram, or\n    # maybe only diagrams with generating morphisms of type 0 \u2192 0?\n    if n is None:\n        n = draw(st.integers(min_value=min_n, max_value=max_n))\n    Obj = draw(nonzero_objects)\n    Arr = draw(sigma_1)\n    return [ draw(diagrams(Obj=Obj, Arr=Arr)) for _ in range(0, n) ]", "\n@st.composite\ndef many_singletons(draw, n):\n    \"\"\" Generate several singleton diagrams from the same signature \"\"\"\n    Obj = draw(objects)\n    Arr = draw(nonzero_sigma_1)\n    return [ draw(singletons(Obj=Obj, Arr=Arr)) for _ in range(0, n) ]\n\n@st.composite\ndef composite_diagrams(draw, max_boundary_size=128):\n    \"\"\"\n    Generate a composite diagram with a random signature.\n          f ; g\n        A \u2192 B \u2192 C\n    \"\"\"\n    # Obj = draw(nonzero_objects)\n    Obj = 1 # Only handle the PROP case for now.\n    Arr = draw(sigma_1)\n\n    # Draw two diagrams with \u03a3\u2080 = 1, then change sources + targets to have a\n    # common boundary.\n    f = draw(diagrams(Obj=Obj, Arr=Arr))\n    g = draw(diagrams(Obj=Obj, Arr=Arr))\n\n    if f.wires == 0 or g.wires == 0:\n        B = 0\n    else:\n        B = draw(st.integers(min_value=0, max_value=max_boundary_size))\n\n    f.t = draw(finite_functions(source=B, target=f.wires))\n    g.s = draw(finite_functions(source=B, target=g.wires))\n\n    return f, g", "@st.composite\ndef composite_diagrams(draw, max_boundary_size=128):\n    \"\"\"\n    Generate a composite diagram with a random signature.\n          f ; g\n        A \u2192 B \u2192 C\n    \"\"\"\n    # Obj = draw(nonzero_objects)\n    Obj = 1 # Only handle the PROP case for now.\n    Arr = draw(sigma_1)\n\n    # Draw two diagrams with \u03a3\u2080 = 1, then change sources + targets to have a\n    # common boundary.\n    f = draw(diagrams(Obj=Obj, Arr=Arr))\n    g = draw(diagrams(Obj=Obj, Arr=Arr))\n\n    if f.wires == 0 or g.wires == 0:\n        B = 0\n    else:\n        B = draw(st.integers(min_value=0, max_value=max_boundary_size))\n\n    f.t = draw(finite_functions(source=B, target=f.wires))\n    g.s = draw(finite_functions(source=B, target=g.wires))\n\n    return f, g", "\n@st.composite\ndef composite_singletons(draw, max_boundary_size=128):\n    \"\"\"\n    Generate a composite diagram with a random signature.\n          f ; g\n        A \u2192 B \u2192 C\n    where f, g are singleton diagrams.\n    \"\"\"\n\n    \u03a3_0 = draw(objects)\n\n    # types of f, g\n    a = draw(finite_functions(target=\u03a3_0))\n    b = draw(finite_functions(target=\u03a3_0))\n    c = draw(finite_functions(target=\u03a3_0))\n\n    # generator labels\n    _, \u03a3_1 = draw(arrow_type(source=1))\n    xn_f = draw(finite_functions(source=1, target=\u03a3_1))\n    xn_g = draw(finite_functions(source=1, target=\u03a3_1))\n    f = Diagram.singleton(a, b, xn_f)\n    g = Diagram.singleton(b, c, xn_g)\n\n    return f, g", "\n################################################################################\n# Segmented finite functions\n\n\n# Generate a segmented finite function like the one below\n#   sff\n#       sources: N            \u2192 K\u2080\n#       values : sum(sources) \u2192 \u03a3\u2080      (= max(targets))\n#       targets: N            \u2192 \u03a3\u2080      (= const \u03a3\u2080+1)", "#       values : sum(sources) \u2192 \u03a3\u2080      (= max(targets))\n#       targets: N            \u2192 \u03a3\u2080      (= const \u03a3\u2080+1)\n@st.composite\ndef segmented_finite_functions(draw, N=None, Obj=None):\n    N, Obj = draw(arrow_type(source=N, target=Obj))\n\n    sources = draw(finite_functions(source=N))\n    values  = draw(finite_functions(source=np.sum(sources.table), target=Obj))\n\n    # make an array [\u03a3\u2080, \u03a3\u2080, ... ]\n    targets = FiniteFunction.terminal(N).inject1(Obj)\n\n    return SegmentedFiniteFunction(\n        sources=sources,\n        targets=targets,\n        values=values)", "\n# Generate a coproduct of finite functions like the one below\n#   sff\n#       sources: N            \u2192 K\u2080\n#       values : sum(sources) \u2192 \u03a3\u2080      (= max(targets))\n@st.composite\ndef indexed_coproducts(draw, N=None, Obj=None):\n    N, Obj = draw(arrow_type(source=N, target=Obj))\n    sources = FiniteFunction(None, draw(finite_functions(source=N)).table)\n    values  = draw(finite_functions(source=np.sum(sources.table), target=Obj))\n    return IndexedCoproduct(sources=sources, values=values)", "\n# Generate a tensoring of operations with the following types.\n#   xn         : N            \u2192 \u03a3\u2081\n#\n#   s_type\n#       sources: N            \u2192 K\u2080\n#       values : sum(sources) \u2192 \u03a3\u2080      (= max(targets))\n#       targets: N            \u2192 \u03a3\u2080      (= const \u03a3\u2080+1)\n#   t_type\n#       sources: N            \u2192 K\u2081", "#   t_type\n#       sources: N            \u2192 K\u2081\n#       values : sum(sources) \u2192 \u03a3\u2080      (= max(targets))\n#       targets: N            \u2192 \u03a3\u2080      (= const \u03a3\u2080+1)\n@st.composite\ndef operations(draw):\n    Obj = draw(objects)\n    s_type = draw(indexed_coproducts(Obj=Obj))\n    t_type = draw(indexed_coproducts(\n        N=len(s_type.sources),\n        Obj=s_type.values.target))\n\n    N = len(s_type.sources)\n    xn = draw(finite_functions(source=N))\n\n    return Operations(xn, s_type, t_type)", "\n################################################################################\n# Half spiders\n\n@st.composite\ndef half_spider(draw, Obj=None):\n    Obj = draw(objects) if Obj is None else Obj\n    wn = draw(finite_functions(target=Obj))\n    f  = draw(finite_functions(target=wn.source))\n    return f, wn", "\n# The functions\n#   f  : A \u2192 B\n#   wn : B \u2192 \u03a3\u2080\n# together give a half-spider, and\n#   F\u2080~ : \u03a3\u2080 \u2192 \u03a9\u2080*\n#   F\u2080  : sum(s) \u2192 \u03a9\u2080\n#   s   : \u03a3\u2080 \u2192 Nat\n# a segmented array encoding the object map of a (finite) functor.\n@st.composite\ndef object_map_and_half_spider(draw):\n    c = draw(indexed_coproducts())\n    f, wn = draw(half_spider(Obj=c.sources.source))\n    return c, f, wn", "# a segmented array encoding the object map of a (finite) functor.\n@st.composite\ndef object_map_and_half_spider(draw):\n    c = draw(indexed_coproducts())\n    f, wn = draw(half_spider(Obj=c.sources.source))\n    return c, f, wn\n\n\n################################################################################\n# Functions of Finite Domain", "################################################################################\n# Functions of Finite Domain\n# TODO: these generators are quite hacky and not nice. Refactor!\n\n# A FinFun target is either:\n#   (target: int, dtype=int64)\n#   (None,        dtype=[int64 | object])\n#\n\n@st.composite\ndef finite_function_target(draw, target=None, is_inf=None, inf_dtype=None):\n    if target is not None:\n        return False, None\n\n    is_inf = draw(st.booleans()) if is_inf == None else is_inf\n    inf_dtype = draw(st.sampled_from(['int', 'object'])) if inf_dtype is None else inf_dtype\n\n    return is_inf, inf_dtype", "\n@st.composite\ndef finite_function_target(draw, target=None, is_inf=None, inf_dtype=None):\n    if target is not None:\n        return False, None\n\n    is_inf = draw(st.booleans()) if is_inf == None else is_inf\n    inf_dtype = draw(st.sampled_from(['int', 'object'])) if inf_dtype is None else inf_dtype\n\n    return is_inf, inf_dtype", "\n@st.composite\ndef finite_domain_functions(draw, source=None, target=None, is_inf=None, inf_dtype=None):\n    \"\"\" Generate functions of finite domain (possibly infinite codomain!) \"\"\"\n    is_inf, inf_dtype = draw(finite_function_target(target, is_inf, inf_dtype))\n\n    if is_inf:\n        f = draw(finite_functions(source=source))\n        target = None\n        dtype = inf_dtype # if inf_dtype is not None else draw(st.sampled_from(['int', 'object']))\n        if dtype == 'int':\n            table = f.table\n        else:\n            # TODO: Generate more varied object data\n            table = np.empty(len(f.table), dtype='object')\n            table[:] = [(x,x) for x in f.table]\n    else:\n        f = draw(finite_functions(source=source, target=target))\n        target = f.target\n        table = f.table\n\n    return FiniteFunction(target, table, dtype=table.dtype)", "\n@st.composite\ndef composite_coproduct_finite_domain(draw, source=None, target=None):\n    source, target = draw(arrow_type(source, target))\n    assert _is_valid_arrow_type(source, target)\n\n    a1 = draw(st.integers(min_value=0, max_value=source))\n    a2 = source - a1\n\n    is_inf, inf_dtype = draw(finite_function_target(target=target))\n    f = draw(finite_domain_functions(source=a1, target=target, is_inf=is_inf, inf_dtype=inf_dtype))\n    g = draw(finite_domain_functions(source=a2, target=target, is_inf=is_inf, inf_dtype=inf_dtype))\n\n    return f, g", "\n@st.composite\ndef composite_nonfinite_codomain(draw, source=None, middle=None):\n    \"\"\" Draw a composite function with a possibly non-finite codomain \"\"\"\n    A, B = draw(arrow_type(source, middle))\n\n    f = draw(finite_functions(source=A, target=B))\n    g = draw(finite_domain_functions(source=B))\n    return f, g\n", ""]}
{"filename": "tests/util.py", "chunked_list": ["import numpy as np\n\ndef monotonic(x, strict=False):\n    if len(x) <= 1:\n        return True # arrays of length <= 1 are trivially sorted\n\n    if strict:\n        return np.all(x[:-1] < x[1:])\n    return np.all(x[:-1] <= x[1:])\n", "\n# return true if s sorts by f.\ndef sorts(s, f, strict=False):\n    y = s >> f\n    return monotonic(y.table)\n\n# check if an array is of the form\n#   [ 0, 1, 2, ..., N\u2080 | 0 1 2 ... N\u2081 | ... ]\ndef is_segmented_arange(x):\n    # empty array is trivially segmented\n    if len(x) == 0:\n        return True\n\n    # all differences should be exactly 1, except where x = 0.\n    d = x[1:] - x[:-1]\n    z = (x == 0)[1:]\n\n    # either difference is 1, or it's <= 0 at the start of a run.\n    return np.all((d == 1) | (z & (d <= 0)))", "def is_segmented_arange(x):\n    # empty array is trivially segmented\n    if len(x) == 0:\n        return True\n\n    # all differences should be exactly 1, except where x = 0.\n    d = x[1:] - x[:-1]\n    z = (x == 0)[1:]\n\n    # either difference is 1, or it's <= 0 at the start of a run.\n    return np.all((d == 1) | (z & (d <= 0)))", ""]}
{"filename": "tests/test_layering.py", "chunked_list": ["import scipy.sparse as sp\nimport numpy as np\n\n# SUT\nfrom yarrow.finite_function import bincount\nfrom yarrow.numpy import Diagram\nfrom yarrow.numpy.layer import layer, kahn, operation_adjacency\n\nfrom tests.strategies import diagrams\n", "from tests.strategies import diagrams\n\nfrom hypothesis import given\nimport hypothesis.strategies as st\n\n# TODO:\n# Generators:\n#   - monogamous acyclic diagrams \n# Tests:\n#   - Check that layer(ma_diagram) visits all operations", "# Tests:\n#   - Check that layer(ma_diagram) visits all operations\n#   - Check that for MA diagrams d\u2081 and d\u2082 and layer(d\u2081 ; d\u2082) ...\n#       - d\u2081 layerings should be unchanged\n#       - d\u2082 layerings should all be larger or equal to layer(d\u2082)\n#           - NOTE: relies on operations not being reordered after composition\n\n# Generate a random acyclic adjacency matrix\n_MAX_MATRIX_SIZE = 512\n@st.composite\ndef acyclic_adjacency_matrix(draw):\n    N = draw(st.integers(min_value=0, max_value=_MAX_MATRIX_SIZE))\n\n    # generate a random matrix, zero below diagonal\n    # Density set to 1/N, so memory usage is O(N).\n    density = 1 if N == 0 else 1/N\n\n    # NOTE: use LIL format so we can call setdiag efficiently below\n    M = sp.random(N, N, density=density, format='lil', dtype=bool)\n\n    # Set diagonal to zero otherwise we can get self-loops!\n    M.setdiag(0)\n\n    # convert to CSR for later.\n    M = sp.csr_array(M)\n\n    # Return a matrix which zeroes out the upper triangle\n    return sp.tril(M.astype(int))", "_MAX_MATRIX_SIZE = 512\n@st.composite\ndef acyclic_adjacency_matrix(draw):\n    N = draw(st.integers(min_value=0, max_value=_MAX_MATRIX_SIZE))\n\n    # generate a random matrix, zero below diagonal\n    # Density set to 1/N, so memory usage is O(N).\n    density = 1 if N == 0 else 1/N\n\n    # NOTE: use LIL format so we can call setdiag efficiently below\n    M = sp.random(N, N, density=density, format='lil', dtype=bool)\n\n    # Set diagonal to zero otherwise we can get self-loops!\n    M.setdiag(0)\n\n    # convert to CSR for later.\n    M = sp.csr_array(M)\n\n    # Return a matrix which zeroes out the upper triangle\n    return sp.tril(M.astype(int))", "\n# Test kahn layering visits all nodes in an acyclic matrix\n@given(acyclic_adjacency_matrix())\ndef test_kahn_acyclic_all_visited(M):\n    \"\"\" Verify that kahn layering correctly orders nodes and visits all nodes in\n    an acyclic graph \"\"\"\n    order, visited = kahn(M)\n\n    # All nodes should be visited (the graph is acyclic)\n    assert np.all(visited)\n\n    # TODO: check that the ordering reflects the acyclic structure.\n    pass", "\n# Test kahn layering *doesn't* visit all nodes in a *cyclic* matrix.\n@given(acyclic_adjacency_matrix())\ndef test_kahn_cyclic_not_all_visited(M):\n    # TODO: this test only checks a small subset of cyclic graphs. Extend the\n    # generator to a larger class.\n\n    # put a self-cycle on all nodes\n    M.setdiag(1)\n\n    # All nodes should be in layer 0 because there are self-cycles on all nodes\n    order, visited = kahn(M)\n\n    # all nodes should have order 0, and none should be visited.\n    assert np.all(order == 0)\n    assert not np.any(visited)", "\n# Test operation_adjacency function does not crash :)\n@given(d=diagrams())\ndef test_operation_adjacency(d: Diagram):\n    M = operation_adjacency(d)\n\n    # NOTE: the (commented) test code below is wrong:\n    # Given an operation, we don't know how many others it connects to just by its arity/coarity, because of the Frobenius structure. We might have for each port:\n    #   - No other operations connected to (\"discard\")\n    #   - Every other operation connected to (\"copy\")\n\n    # check number of incoming edges is less than or equal to arity\n    # arity = bincount(d.G.xi)\n    # indegree = M.sum(axis=1)\n    # assert np.all(arity.table >= indegree)\n\n    # check number of outgoing edges is less than or equal to coarity\n    # coarity = bincount(d.G.xo)\n    # outdegree = M.sum(axis=0)\n    # assert np.all(coarity.table >= outdegree)\n    pass", "\n# Test the layer function does not crash\n@given(d=diagrams())\ndef test_layer_call(d: Diagram):\n    layer(d)\n"]}
{"filename": "tests/test_finite_function.py", "chunked_list": ["import pytest\n\nimport numpy as np\nfrom yarrow import *\n\nfrom hypothesis import given\nimport hypothesis.strategies as st\n\nfrom tests.strategies import *\n", "from tests.strategies import *\n\n################################################################################\n# Equality\n\n@given(f=finite_functions())\ndef test_equality_reflexive(f):\n    assert f == f\n\n@given(fg=parallel_arrows())\ndef test_inequality_table(fg):\n    \"\"\" Ensure that if the function tables of two FiniteFunctions are different,\n    then == returns false.\"\"\"\n    f, g = fg\n    if np.any(f.table != g.table):\n        assert f != g", "\n@given(fg=parallel_arrows())\ndef test_inequality_table(fg):\n    \"\"\" Ensure that if the function tables of two FiniteFunctions are different,\n    then == returns false.\"\"\"\n    f, g = fg\n    if np.any(f.table != g.table):\n        assert f != g\n\n@given(f=finite_functions(), g=finite_functions())\ndef test_inequality_type(f, g):\n    \"\"\" Ensure that if the function tables of two FiniteFunctions are different,\n    then == returns false.\"\"\"\n    if f.source != g.source:\n        assert f != g\n    if f.target != g.target:\n        assert f != g", "\n@given(f=finite_functions(), g=finite_functions())\ndef test_inequality_type(f, g):\n    \"\"\" Ensure that if the function tables of two FiniteFunctions are different,\n    then == returns false.\"\"\"\n    if f.source != g.source:\n        assert f != g\n    if f.target != g.target:\n        assert f != g\n", "\n################################################################################\n# Basic tests\n\n# only test small arrays, we don't need to OOM thank you very much\n@given(objects)\ndef test_identity(n):\n    identity = FiniteFunction.identity(n)\n    assert np.all(identity.table == np.arange(0, n))\n    assert identity.table.shape == (n, )", "\n@given(st.integers(max_value=-1))\ndef test_identity_invalid_object(n):\n    with pytest.raises(AssertionError) as exc_info:\n        identity = FiniteFunction.identity(n)\n\n\n################################################################################\n# Category laws\n", "# Category laws\n\n# left identities       id ; f = f\n@given(f=finite_functions(source=0))\ndef test_identity_composition_left(f):\n    \"\"\" id ; f = f \"\"\"\n    identity = FiniteFunction.identity(f.source)\n    assert (identity >> f) == f\n\n# right identities      f ; id = f", "\n# right identities      f ; id = f\n@given(f=finite_functions())\ndef test_identity_composition_right(f):\n    \"\"\" f ; id = f \"\"\"\n    identity = FiniteFunction.identity(f.target)\n    assert (f >> identity) == f\n\n# Make sure composition doesn't crash\n@given(fns=composite_functions(n=2))\ndef test_composition(fns):\n    f, g = fns\n    x = f >> g", "# Make sure composition doesn't crash\n@given(fns=composite_functions(n=2))\ndef test_composition(fns):\n    f, g = fns\n    x = f >> g\n\n# Check associativity of composition    (f ; g) ; h = f ; (g ; h)\n@given(fgh=composite_functions(n=3))\ndef test_composition_assoc(fgh):\n    f, g, h = fgh\n    assert ((f >> g) >> h) == (f >> (g >> h))", "def test_composition_assoc(fgh):\n    f, g, h = fgh\n    assert ((f >> g) >> h) == (f >> (g >> h))\n\n################################################################################\n# Coproducts\n\n# Uniqueness of the initial map\n# any map f : 0 \u2192 B is equal to the initial map ? : 0 \u2192 B\n@given(f=finite_functions(source=0))\ndef test_initial_map_unique(f):\n    assert f == FiniteFunction.initial(f.target)", "# any map f : 0 \u2192 B is equal to the initial map ? : 0 \u2192 B\n@given(f=finite_functions(source=0))\ndef test_initial_map_unique(f):\n    assert f == FiniteFunction.initial(f.target)\n\n# Coproducts!\n# given f : A\u2081 \u2192 B and g : A\u2082 \u2192 B, ensure f + g commutes with injections.\n# i.e.,  \u03b9\u2080 ; (f + g) = f\n#        \u03b9\u2081 ; (f + g) = g\n@given(fg=composite_coproduct())\ndef test_coproduct_commutes(fg):\n    f, g = fg\n    i0 = FiniteFunction.inj0(f.source, g.source)\n    i1 = FiniteFunction.inj1(f.source, g.source)\n\n    assert (i0 >> (f + g)) == f\n    assert (i1 >> (f + g)) == g", "#        \u03b9\u2081 ; (f + g) = g\n@given(fg=composite_coproduct())\ndef test_coproduct_commutes(fg):\n    f, g = fg\n    i0 = FiniteFunction.inj0(f.source, g.source)\n    i1 = FiniteFunction.inj1(f.source, g.source)\n\n    assert (i0 >> (f + g)) == f\n    assert (i1 >> (f + g)) == g\n", "\n\n@given(f=finite_functions(), b=objects)\ndef test_f_cp_inj0_equals_inject0(f, b):\n    assert f >> FiniteFunction.inj0(f.target, b) == f.inject0(b)\n\n@given(f=finite_functions(), a=objects)\ndef test_f_cp_inj1_equals_inject0(f, a):\n    assert f >> FiniteFunction.inj1(a, f.target) == f.inject1(a)\n", "\n################################################################################\n# (Strict) symmetric monoidal tests\n\n@given(f=finite_functions(), g=finite_functions())\ndef test_tensor_vs_injections(f, g):\n    \"\"\" Verify that the tensor product corresponds to its definition in terms of\n    coproducts and injections \"\"\"\n    i0 = FiniteFunction.inj0(f.target, g.target)\n    i1 = FiniteFunction.inj1(f.target, g.target)\n\n    f @ g == (f >> i0) + (g >> i1)", "\n@given(a=objects, b=objects)\ndef test_twist_inverse(a, b):\n    \"\"\" Check the law \u03c3 ; \u03c3 = id \"\"\"\n    f = FiniteFunction.twist(a, b)\n    g = FiniteFunction.twist(b, a)\n    identity = FiniteFunction.identity(a + b)\n    assert f >> g == identity\n    assert g >> f == identity\n", "\n@given(f=finite_functions(), g=finite_functions())\ndef test_twist_naturality(f, g):\n    \"\"\" Check naturality of \u03c3, so that (f @ g) ; \u03c3 = \u03c3 ; (f @ g) \"\"\"\n    post_twist = FiniteFunction.twist(f.target, g.target)\n    pre_twist  = FiniteFunction.twist(f.source, g.source)\n    assert ((f @ g) >> post_twist) == (pre_twist >> (g @ f))\n\n################################################################################\n# Test coequalizers", "################################################################################\n# Test coequalizers\n@given(fg=parallel_arrows())\ndef test_coequalizer_commutes(fg):\n    f, g = fg\n    c = f.coequalizer(g)\n    assert (f >> c) == (g >> c)\n\n################################################################################\n# Finite coproducts", "################################################################################\n# Finite coproducts\n\n@given(s=finite_functions())\ndef test_injection_coproduct_identity(s: FiniteFunction):\n    \"\"\" Test that\n        \u03b9_0 + \u03b9_1 + ... + \u03b9_N = identity(sum_{i \u2208 N} s(i))\n    \"\"\"\n    i = FiniteFunction.identity(s.source)\n    assert s.injections(i) == FiniteFunction.identity(np.sum(s.table))", "\n@given(f=finite_functions())\ndef test_bincount(f: FiniteFunction):\n    b = bincount(f)\n    assert b.source == f.target\n    assert b.target == f.source+1\n    assert np.all(b.table < len(f)+1)\n    assert np.all(b.table >= 0)\n\n################################################################################", "\n################################################################################\n# Test functions with None target\n\n@given(fg=composite_coproduct_finite_domain())\ndef test_finite_domain_coproduct(fg):\n    f, g = fg\n    A0, B = f.type\n    A1, B_ = g.type\n    assert B == B_\n\n    h = f + g\n    X, Y = h.type\n\n    assert X == A0 + A1\n    assert Y == B\n    assert h.table.dtype == f.table.dtype\n    assert h.table.dtype == g.table.dtype", "\n@given(fg=composite_nonfinite_codomain())\ndef test_compose_finite_domain(fg):\n    \"\"\" Test composition with functions of non-finite codomain \"\"\"\n    f, g = fg\n\n    A, B = f.type\n    B_, C = g.type\n    assert B == B_\n\n    h = f >> g\n    assert h.type == (A, C)", "\n@given(f=finite_functions())\ndef test_cumsum(f):\n    g = cumsum(f)\n    assert len(g) == len(f)\n    assert g.target == np.sum(f.table) + 1\n"]}
{"filename": "tests/test_functor.py", "chunked_list": ["import unittest\nfrom hypothesis import given\nimport hypothesis.strategies as st\nfrom tests.strategies import *\n\nfrom yarrow.decompose.frobenius import frobenius_decomposition\n\n# SUT\nfrom yarrow.functor.functor import *\n", "from yarrow.functor.functor import *\n\n@given(d=diagrams())\ndef test_decomposition_to_operations(d):\n    d = frobenius_decomposition(d)\n    ops = decomposition_to_operations(d)\n\n# Given an object L(B)\n#   Bwn : B \u2192 \u03a3\u2080\n# ... a half-spider", "#   Bwn : B \u2192 \u03a3\u2080\n# ... a half-spider\n#   f  : A \u2192 B\n# ... and segmented finite function representing the object map of a functor\n#   c\n#       sources : \u03a3\u2080 \u2192 Nat\n#       values  : sum(sources) \u2192 \u03a9\u2080\n# verify that applying the functor does not raise errors.\n@given(c_f_wn=object_map_and_half_spider())\ndef test_apply_finite_object_map(c_f_wn):\n    c, f, Bwn = c_f_wn\n    FBwn = apply_finite_object_map(c, Bwn)", "@given(c_f_wn=object_map_and_half_spider())\ndef test_apply_finite_object_map(c_f_wn):\n    c, f, Bwn = c_f_wn\n    FBwn = apply_finite_object_map(c, Bwn)\n\n# Check that mapping half-spiders is natural\n#   f    :   A  \u2192   B\n#   F(f) : F(A) \u2192 F(B)\n# Proposition 9.6, paper v1\n@given(c_f_wn=object_map_and_half_spider())\ndef test_map_half_spider(c_f_wn):\n    c, f, Bwn = c_f_wn\n    Awn = f >> Bwn # A(wn) = f ; B(wn) by naturality\n\n    # the object map of the functor we're applying.\n    # For the purposes of this test, it's finite.\n    def object_map(wn):\n        return apply_finite_object_map(c, wn)\n\n    # Compute F(B)(wn) and F(f)\n    FBwn = object_map(Bwn)\n    Ff = map_half_spider(FBwn, f)\n\n    # F(A)(wn)\n    FAwn = Ff >> FBwn.values\n\n    # Holds by Proposition 9.6\n    assert object_map(Awn).values == FAwn", "# Proposition 9.6, paper v1\n@given(c_f_wn=object_map_and_half_spider())\ndef test_map_half_spider(c_f_wn):\n    c, f, Bwn = c_f_wn\n    Awn = f >> Bwn # A(wn) = f ; B(wn) by naturality\n\n    # the object map of the functor we're applying.\n    # For the purposes of this test, it's finite.\n    def object_map(wn):\n        return apply_finite_object_map(c, wn)\n\n    # Compute F(B)(wn) and F(f)\n    FBwn = object_map(Bwn)\n    Ff = map_half_spider(FBwn, f)\n\n    # F(A)(wn)\n    FAwn = Ff >> FBwn.values\n\n    # Holds by Proposition 9.6\n    assert object_map(Awn).values == FAwn", "\n# Ensure that applying the identity object map to an object\n# L(A) (represented by wn) gives the array wn.\n@given(c=diagrams())\ndef test_identity_object_map(c):\n    wn = c.G.wn\n    Fwn = identity_object_map(wn)\n    assert Fwn.values == wn\n    assert np.all(Fwn.sources.table == 1)\n", "\n# Check that the identity functor implemented as a 'Frobenius Functor' gives the\n# input diagram back.\n# TODO: test against the Identity functor!\n@given(c=diagrams())\ndef test_identity_frobenius_functor(c):\n    F = FrobeniusIdentity()\n    d = F.map_arrow(c)\n\n    A, B = c.type \n    C, D = d.type\n\n    assert A == C\n    assert B == D\n\n    # for this particular functor, we expect exact equality of diagrams.\n    assert c == d", "\nclass DaggerDaggerFunctor(FrobeniusFunctor):\n    \"\"\" The DaggerDagger functor maps each generating morphism\n\n        f : A \u2192 B\n\n    to the composition\n\n        f ; f\u2020 ; f : A \u2192 B\n\n    and so is identity-on-objects.\n    \"\"\"\n    def map_objects(self, objects: AbstractFiniteFunction):\n        return identity_object_map(objects)\n\n    def map_operations(self, ops: Operations) -> Diagram:\n        d = Diagram.tensor_operations(ops)\n        return (d >> d.dagger() >> d)", "\n# A more complicated test for the FrobeniusFunctor class:\n# make sure that even diagrams with internal wiring are mapped correctly.\n# This checks that the diagram has the expected type and number of operations.\n@given(c=diagrams())\ndef test_dagger_dagger_functor(c):\n    F = DaggerDaggerFunctor()\n    d = F.map_arrow(c)\n\n    A, B = c.type \n    C, D = d.type\n\n    assert A == C\n    assert B == D\n\n    # d has exactly 3x as many generating operations as c.\n    assert d.G.xn.source == c.G.xn.source * 3", "\n# TODO: replace this with FiniteFunction.interleave >> (x + y) ?\ndef interleave(x, y):\n    \"\"\" Return the finite function whose table is the interleaving of x and y \"\"\"\n    h = x + y\n    h.table[0::2] = x.table\n    h.table[1::2] = y.table\n    return h\n\nclass DoublingFunctor(FrobeniusFunctor):\n    \"\"\" The functor which maps each generating object A to the tensor (A \u25cf A),\n    and each generating operation f : A\u2080 \u25cf A\u2081 ... An \u2192 B\u2080 \u25cf B\u2081 ... Bn\n    to the operation f : A\u2080 A\u2080 \u25cf A\u2081 A\u2081 ... An An \u2192 B\u2080 B\u2080 \u25cf B\u2081 B\u2081 ... Bn Bn.\n    Note that we simply assume a signature in which this is well-typed.\n    \"\"\"\n    def map_objects(self, objects: AbstractFiniteFunction):\n        # TODO: generalise this to the application of two distinct functors interleaved (optics!)\n        N = len(objects.table) * 2\n        table = np.zeros_like(objects.table, shape=N)\n        table[0::2] = objects.table\n        table[1::2] = objects.table\n\n        sources = FiniteFunction(None, np.full(N//2, 2, dtype='int'))\n        values  = FiniteFunction(objects.target, table)\n        # return SegmentedFiniteFunction(sources, targets, values)\n        return IndexedCoproduct(sources, values)\n\n    def map_operations(self, ops: Operations) -> Diagram:\n        s_type = IndexedCoproduct(\n            sources = FiniteFunction(None, ops.s_type.sources.table * 2),\n            values  = interleave(ops.s_type.values, ops.s_type.values))\n\n        t_type = IndexedCoproduct(\n            sources = FiniteFunction(None, ops.t_type.sources.table * 2),\n            values  = interleave(ops.t_type.values, ops.t_type.values))\n\n        ops = Operations(ops.xn, s_type, t_type)\n        d = Diagram.tensor_operations(ops)\n        return d", "\nclass DoublingFunctor(FrobeniusFunctor):\n    \"\"\" The functor which maps each generating object A to the tensor (A \u25cf A),\n    and each generating operation f : A\u2080 \u25cf A\u2081 ... An \u2192 B\u2080 \u25cf B\u2081 ... Bn\n    to the operation f : A\u2080 A\u2080 \u25cf A\u2081 A\u2081 ... An An \u2192 B\u2080 B\u2080 \u25cf B\u2081 B\u2081 ... Bn Bn.\n    Note that we simply assume a signature in which this is well-typed.\n    \"\"\"\n    def map_objects(self, objects: AbstractFiniteFunction):\n        # TODO: generalise this to the application of two distinct functors interleaved (optics!)\n        N = len(objects.table) * 2\n        table = np.zeros_like(objects.table, shape=N)\n        table[0::2] = objects.table\n        table[1::2] = objects.table\n\n        sources = FiniteFunction(None, np.full(N//2, 2, dtype='int'))\n        values  = FiniteFunction(objects.target, table)\n        # return SegmentedFiniteFunction(sources, targets, values)\n        return IndexedCoproduct(sources, values)\n\n    def map_operations(self, ops: Operations) -> Diagram:\n        s_type = IndexedCoproduct(\n            sources = FiniteFunction(None, ops.s_type.sources.table * 2),\n            values  = interleave(ops.s_type.values, ops.s_type.values))\n\n        t_type = IndexedCoproduct(\n            sources = FiniteFunction(None, ops.t_type.sources.table * 2),\n            values  = interleave(ops.t_type.values, ops.t_type.values))\n\n        ops = Operations(ops.xn, s_type, t_type)\n        d = Diagram.tensor_operations(ops)\n        return d", "\n# We need to test the case of functors which are not identity-on-objects.\n@given(c=diagrams())\ndef test_doubling_functor(c):\n    F = DoublingFunctor()\n    d = F.map_arrow(c)\n\n    A, B = c.type\n    C, D = d.type\n\n    assert np.all(C.table == interleave(A, A).table)\n    assert np.all(D.table == interleave(B, B).table)\n\n    # Same number of operations (just with different types)\n    assert d.G.xn.source == c.G.xn.source", ""]}
{"filename": "yarrow/finite_function.py", "chunked_list": ["\"\"\"An implementation of finite functions as arrays.\nAll yarrow datastructures are ultimately built from finite functions.\nFor an overview, see :cite:t:`dpafsd`, Section 2.2.2.\n\nFinite functions can be thought of as a thin wrapper around integer arrays whose\nelements are within a specified range.\nHere's an example of contructing a finite function:\n\n>>> print(FiniteFunction(3, [0, 1, 2, 0]))\n[0 1 2 0] : 4 \u2192 3", ">>> print(FiniteFunction(3, [0, 1, 2, 0]))\n[0 1 2 0] : 4 \u2192 3\n\nMathematically, this represents a function from the set of 4 elements to the set\nof 3 elements, and so its \"type\" is ``4 \u2192 3``.\n\nThere are several constructors for finite functions corresponding to useful\nmorphisms in category theory.\nFor example, the ``identity`` map is like numpy's ``arange``:\n", "For example, the ``identity`` map is like numpy's ``arange``:\n\n>>> print(FiniteFunction.identity(5))\n[0 1 2 3 4] : 5 \u2192 5\n\nand the ``terminal`` map is an array of zeroes:\n\n>>> print(FiniteFunction.terminal(5))\n[0 0 0 0 0] : 5 \u2192 1\n", "[0 0 0 0 0] : 5 \u2192 1\n\nFinite functions form a *symmetric monoidal category*.\nThey can be composed sequentially:\n\n>>> print(FiniteFunction.identity(5) >> FiniteFunction.terminal(5))\n[0 0 0 0 0] : 5 \u2192 5\n\nAnd in parallel:\n", "And in parallel:\n\n>>> FiniteFunction.identity(5) @ FiniteFunction.terminal(5)\nFiniteFunction(6, [0 1 2 3 4 5 5 5 5 5])\n\"\"\"\n\nfrom typing import List\n# import yarrow.array.numpy as numpy\n\nDTYPE='int64'", "\nDTYPE='int64'\n\nclass AbstractFiniteFunction:\n    \"\"\"\n    Finite functions parametrised over the underlying array type (the \"backend\").\n    This implementation assumes there is a cls._Array member implementing various primitives.\n    For example, cls._Array.sum() should compute the sum of an array.\n    \"\"\"\n    def __init__(self, target, table, dtype=DTYPE):\n        # TODO: this constructor is too complicated; it should be simplified.\n        # _Array is the \"array functions module\"\n        # It lets us parametrise AbstractFiniteFunction by a module like \"numpy\".\n        Array = type(self)._Array\n        if type(table) == Array.Type:\n           self.table = table\n        else:\n            self.table = Array.array(table, dtype=dtype)\n\n        self.target = target\n\n        assert len(self.table.shape) == 1 # ensure 1D array\n        assert self.source >= 0\n        if self.source > 0 and self.target is not None:\n            assert self.target >= 0\n            assert self.target > Array.max(table)\n\n    @property\n    def source(self):\n        \"\"\"The source (aka \"domain\") of this finite function\"\"\"\n        return len(self.table)\n\n    def __len__(self):\n        \"\"\"Same as self.source.\n        Sometimes this is clearer when thinking of a finite function as an array.\n        \"\"\"\n        return len(self.table)\n\n    def __str__(self):\n        return f'{self.table} : {self.source} \u2192 {self.target}'\n\n    def __repr__(self):\n        return f'FiniteFunction({self.target}, {self.table})'\n\n    def __call__(self, i: int):\n        if i >= self.source:\n            raise ValueError(\"Calling {self} with {i} >= source {self.source}\")\n        return self.table[i]\n\n    @property\n    def type(f):\n        \"\"\"Get the source and target of this finite function.\n\n        Returns:\n            tuple: (f.source, f.target)\n        \"\"\"\n        return f.source, f.target\n\n    ################################################################################\n    # FiniteFunction forms a category\n\n    @classmethod\n    def identity(cls, n: int):\n        \"\"\"Return the identity finite function of type n \u2192 n.\n        Args:\n            n(int): The object of which to return the identity map\n\n        Returns:\n            AbstractFiniteFunction: Identity map at n\n        \"\"\"\n        assert n >= 0\n        return cls(n, cls._Array.arange(0, n, dtype=DTYPE))\n\n    # Compute (f ; g), i.e., the function x \u2192 g(f(x))\n    def compose(f: 'AbstractFiniteFunction', g: 'AbstractFiniteFunction'):\n        \"\"\"Compose this finite function with another\n\n        Args:\n            g: A FiniteFunction for which self.target == g.source\n\n        Returns:\n            The composition f ; g.\n\n        Raises:\n            ValueError: if self.target != g.source\n        \"\"\"\n        if f.target != g.source:\n            raise ValueError(f\"Can't compose FiniteFunction {f} with {g}: f.target != g.source\")\n\n        source = f.source\n        target = g.target\n        # Use array indexing to compute composition in parallel (if applicable\n        # cls._Array backend is used)\n        table = g.table[f.table]\n\n        return type(f)(target, table)\n\n    def __rshift__(f, g):\n        return f.compose(g)\n\n    # We can compare functions for equality in a reasonable way: by just\n    # comparing elements.\n    # This is basically because FinFun is skeletal, so we don't need to check\n    # \"up to isomorphism\".\n    def __eq__(f, g):\n        return f.source == g.source \\\n           and f.target == g.target \\\n           and f._Array.all(f.table == g.table)\n\n    ################################################################################\n    # FiniteFunction has initial objects and coproducts\n    @classmethod\n    def initial(cls, b, dtype=DTYPE):\n        \"\"\"Compute the initial map ``? : 0 \u2192 b``\"\"\"\n        return cls(b, cls._Array.zeros(0, dtype=dtype))\n\n    @classmethod\n    def inj0(cls, a, b):\n        \"\"\"Compute the injection ``\u03b9\u2080 : a \u2192 a + b``\"\"\"\n        table = cls._Array.arange(0, a, dtype=DTYPE)\n        return cls(a + b, table)\n\n    @classmethod\n    def inj1(cls, a, b):\n        \"\"\"Compute the injection ``\u03b9\u2081 : b \u2192 a + b``\"\"\"\n        table = cls._Array.arange(a, a + b, dtype=DTYPE)\n        return cls(a + b, table)\n\n    def inject0(f, b):\n        \"\"\"\n        Directly compute (f ; \u03b9\u2080) instead of by composition.\n\n        >>> f.inject0(b) == f >> \u03b9\u2080\n        \"\"\"\n        return type(f)(f.target + b, f.table)\n\n    def inject1(f, a):\n        \"\"\"\n        Directly compute (f ; \u03b9\u2081) instead of by composition.\n\n        >>> f.inject1(a) == f >> \u03b9\u2081\n        \"\"\"\n        return type(f)(a + f.target, a + f.table)\n\n    def coproduct(f, g):\n        \"\"\" Given maps ``f : A\u2080 \u2192 B`` and ``g : A\u2081 \u2192 B``\n        compute the coproduct ``f.coproduct(g) : A\u2080 + A\u2081 \u2192 B``\"\"\"\n        assert f.target == g.target\n        assert f.table.dtype == g.table.dtype\n        target = f.target\n        table = type(f)._Array.concatenate([f.table, g.table])\n        return type(f)(target, table)\n\n    def __add__(f, g):\n        \"\"\" Inline coproduct \"\"\"\n        return f.coproduct(g)\n\n    ################################################################################\n    # FiniteFunction as a strict symmetric monoidal category\n    @staticmethod\n    def unit():\n        \"\"\" return the unit object of the category \"\"\"\n        return 0\n\n    def tensor(f, g):\n        \"\"\" Given maps\n        ``f : A\u2080 \u2192 B\u2080`` and\n        ``g : A\u2081 \u2192 B\u2081``\n        compute the *tensor* product\n        ``f.tensor(g) : A\u2080 + A\u2081 \u2192 B\u2080 + B\u2081``\"\"\"\n        # The tensor (f @ g) is the same as (f;\u03b9\u2080) + (g;\u03b9\u2081)\n        # however, we compute it directly for the sake of efficiency\n        T = type(f)\n        table = T._Array.concatenate([f.table, g.table + f.target])\n        return T(f.target + g.target, table)\n\n    def __matmul__(f, g):\n        return f.tensor(g)\n\n    @classmethod\n    def twist(cls, a, b):\n        # Read a permutation as the array whose ith position denotes \"where to send\" value i.\n        # e.g., twist_{2, 3} = [3 4 0 1 2]\n        #       twist_{2, 1} = [1 2 0]\n        #       twist_{0, 2} = [0 1]\n        table = cls._Array.concatenate([b + cls._Array.arange(0, a), cls._Array.arange(0, b)])\n        return cls(a + b, table)\n\n    ################################################################################\n    # Coequalizers for FiniteFunction\n    def coequalizer(f, g):\n        \"\"\"\n        Given finite functions    ``f, g : A \u2192 B``,\n        return the *coequalizer*  ``q    : B \u2192 Q``\n        which is the unique arrow such that  ``f >> q = g >> q``\n        having a unique arrow to any other such map.\n        \"\"\"\n\n        if f.type != g.type:\n            raise ValueError(\n                f\"cannot coequalize arrows {f} and {g} of different types: {f.type} != {g.type}\")\n\n        # connected_components returns:\n        #   Q:        number of components\n        #   q: B \u2192 Q  map assigning vertices to their component\n        # For the latter we have that\n        #   * if f.table[i] == g.table[i]\n        #   * then q[f.table[i]] == q[g.table[i]]\n        # NOTE: we pass f.target so the size of the sparse adjacency matrix\n        # representing the graph can be computed efficiently; otherwise we'd\n        # have to take a max() of each table.\n        # Q: number of connected components\n        T = type(f)\n        Q, q = T._Array.connected_components(f.table, g.table, f.target)\n        return T(Q, q)\n\n    ################################################################################\n    # FiniteFunction also has cartesian structure which is useful\n    @classmethod\n    def terminal(cls, a, dtype=DTYPE):\n        \"\"\" Compute the terminal map ``! : a \u2192 1``. \"\"\"\n        return cls(1, cls._Array.zeros(a, dtype=DTYPE))\n\n    # TODO: rename this \"element\"?\n    @classmethod\n    def singleton(cls, x, b, dtype=DTYPE):\n        \"\"\" return the singleton array ``[x]`` whose domain is ``b``. \"\"\"\n        assert x < b\n        return cls(b, cls._Array.full(1, x, dtype=dtype))\n\n    ################################################################################\n    # Sorting morphisms\n    def argsort(f: 'AbstractFiniteFunction'):\n        \"\"\"\n        Given a finite function                     ``f : A \u2192 B``\n        Return the *stable* sorting permutation     ``p : A \u2192 A``\n        such that                                   ``p >> f``  is monotonic.\n        \"\"\"\n        return type(f)(f.source, f._Array.argsort(f.table))\n\n    ################################################################################\n    # Useful permutations\n\n    # Given generating objects A_i and B_i for i \u2208 ord{n},\n    #   interleave : (A\u2080 \u25cf A\u2081 \u25cf ... \u25cf An) \u25cf (B\u2080 \u25cf B\u2081 \u25cf ... \u25cf Bn) \u2192 (A\u2080 \u25cf B\u2080) \u25cf .. \u25cf (An \u25cf Bn)\n    @classmethod\n    def interleave(cls, N: int):\n        table = cls._Array.zeros(2*N, dtype=int)\n        table[0:N] = cls._Array.arange(N)*2\n        table[N:] = table[0:N] + 1\n        return cls(2*N, table)\n\n    # Given generating objects A_i and B_i for i \u2208 ord{n},\n    #   cointerleave : (A\u2080 \u25cf B\u2080) \u25cf .. \u25cf (An \u25cf Bn) \u2192 (A\u2080 \u25cf A\u2081 \u25cf ... \u25cf An) \u25cf (B\u2080 \u25cf B\u2081 \u25cf ... \u25cf Bn)\n    @classmethod\n    def cointerleave(cls, N):\n        table = cls._Array.zeros(2*N, dtype=int)\n        table[0::2] = cls._Array.arange(N)\n        table[1::2] = table[0::2] + N\n        return cls(2*N, table)\n\n\n    ################################################################################\n    # Sequential-only methods\n\n    @classmethod\n    def coproduct_list(cls, fs: List['AbstractFiniteFunction'], target=None):\n        \"\"\" Compute the coproduct of a list of finite functions. O(n) in size of the result.\n\n        .. warning::\n            Does not speed up to O(log n) in the parallel case.\n        \"\"\"\n        # NOTE: this function is not parallelized!\n        if len(fs) == 0:\n            return cls.initial(0 if target is None else target)\n\n        # all targets must be equal\n        assert all(f.target == g.target for f, g in zip(fs, fs[:1]))\n        return cls(fs[0].target, cls._Array.concatenate([f.table for f in fs]))\n\n    @classmethod\n    def tensor_list(cls, fs: List['AbstractFiniteFunction']):\n        \"\"\" Compute the tensor product of a list of finite functions. O(n) in size of the result.\n\n        .. warning::\n            Does not speed up to O(log n) in the parallel case.\n        \"\"\"\n        if len(fs) == 0:\n            return cls.initial(0)\n\n        targets = cls._Array.array([f.target for f in fs])\n        offsets = cls._Array.zeros(len(targets) + 1, dtype=type(fs[0].source))\n        offsets[1:] = cls._Array.cumsum(targets) # exclusive scan\n        table = cls._Array.concatenate([f.table + offset for f, offset in zip(fs, offsets[:-1])])\n        return cls(offsets[-1], table)\n\n\n    ################################################################################\n    # Finite coproducts\n    def injections(s: 'AbstractFiniteFunction', a: 'AbstractFiniteFunction'):\n        \"\"\"\n        Given a finite function ``s : N \u2192 K``\n        representing the objects of the coproduct\n        ``\u03a3_{n \u2208 N} s(n)``\n        whose injections have the type\n        ``\u03b9_x : s(x) \u2192 \u03a3_{n \u2208 N} s(n)``,\n        and given a finite map\n        ``a : A \u2192 N``,\n        compute the coproduct of injections\n\n        .. code-block:: text\n\n            injections(s, a) : \u03a3_{x \u2208 A} s(x) \u2192 \u03a3_{n \u2208 N} s(n)\n            injections(s, a) = \u03a3_{x \u2208 A} \u03b9_a(x)\n\n        So that ``injections(s, id) == id``\n\n        Note that when a is a permutation,\n        injections(s, a) is a \"blockwise\" version of that permutation with block\n        sizes equal to s.\n        \"\"\"\n        # segment pointers\n        Array = a._Array\n\n        # cumsum is inclusive, we need exclusive so we just allocate 1 more space.\n        p = Array.zeros(s.source + 1, dtype=Array.DEFAULT_DTYPE)\n        p[1:] = Array.cumsum(s.table)\n\n        k = a >> s # avoid recomputation\n        r = Array.segmented_arange(k.table)\n        # NOTE: p[-1] is sum(s).\n        cls = type(s)\n        return cls(p[-1], r + cls._Array.repeat(p[a.table], k.table))", "\n\ndef argsort(f: AbstractFiniteFunction):\n    \"\"\" Applies a stable 'argsort' to the underlying array of a finite function.\n    When that finite function is a permutation, this inverts it.\n    \"\"\"\n    return type(f)(f.source, f._Array.argsort(f.table))\n\ndef bincount(f: AbstractFiniteFunction):\n    \"\"\" bincount the underlying array of a finite function\n\n    Args:\n        f: A finite function of type ``A \u2192 B``\n\n    Returns:\n        AbstractFiniteFunction: A finite function of type ``B \u2192 A+1``\n\n    \"\"\"\n    # the bincount of an array\n    #   f : A \u2192 B\n    # is a finite function\n    #   g : B \u2192 A+1\n    # where\n    #   g(b) = |{b . \u2203a. f(a) = b}|\n    return type(f)(len(f)+1, f._Array.bincount(f.table, minlength=f.target))", "def bincount(f: AbstractFiniteFunction):\n    \"\"\" bincount the underlying array of a finite function\n\n    Args:\n        f: A finite function of type ``A \u2192 B``\n\n    Returns:\n        AbstractFiniteFunction: A finite function of type ``B \u2192 A+1``\n\n    \"\"\"\n    # the bincount of an array\n    #   f : A \u2192 B\n    # is a finite function\n    #   g : B \u2192 A+1\n    # where\n    #   g(b) = |{b . \u2203a. f(a) = b}|\n    return type(f)(len(f)+1, f._Array.bincount(f.table, minlength=f.target))", "\ndef cumsum(f: AbstractFiniteFunction) -> AbstractFiniteFunction:\n    Fun = type(f)\n    Array = Fun._Array\n    table = Array.zeros(len(f) + 1, dtype=f.table.dtype)\n    table[1:] = Array.cumsum(f.table)\n    return Fun(table[-1]+1, table[:-1])\n"]}
{"filename": "yarrow/cupy.py", "chunked_list": ["\"\"\" CuPy-backed finite functions, bipartite multigraphs, and diagrams.\n\n.. danger::\n   **Experimental Module**\n\n   This code is not thoroughly tested.\n   It's included here as a proof-of-concept for GPU acceleration.\n   The way backends are selected is also likely to change in the future.\n\"\"\"\n# Abstract implementations", "\"\"\"\n# Abstract implementations\nfrom yarrow.finite_function import *\nfrom yarrow.bipartite_multigraph import *\nfrom yarrow.diagram import *\nfrom yarrow.segmented.finite_function import AbstractIndexedCoproduct, AbstractSegmentedFiniteFunction\n\n# Array backend\nimport yarrow.array.cupy as cupy\n\nclass FiniteFunction(AbstractFiniteFunction):\n    \"\"\" CuPy-backed finite functions \"\"\"\n    _Array = cupy", "import yarrow.array.cupy as cupy\n\nclass FiniteFunction(AbstractFiniteFunction):\n    \"\"\" CuPy-backed finite functions \"\"\"\n    _Array = cupy\n\nclass IndexedCoproduct(AbstractIndexedCoproduct):\n    _Fun = FiniteFunction\n\nclass BipartiteMultigraph(AbstractBipartiteMultigraph):\n    \"\"\" CuPy-backed bipartite multigraphs \"\"\"\n    _Fun = FiniteFunction", "\nclass BipartiteMultigraph(AbstractBipartiteMultigraph):\n    \"\"\" CuPy-backed bipartite multigraphs \"\"\"\n    _Fun = FiniteFunction\n\nclass Diagram(AbstractDiagram):\n    \"\"\" CuPy-backed string diagrams \"\"\"\n    _Fun = FiniteFunction\n    _Graph = BipartiteMultigraph\n\nclass SegmentedFiniteFunction(AbstractSegmentedFiniteFunction):\n    _Array = cupy\n    _Fun = FiniteFunction", "\nclass SegmentedFiniteFunction(AbstractSegmentedFiniteFunction):\n    _Array = cupy\n    _Fun = FiniteFunction\n\n# If we had types, this would be 'type-level function' giving us the\n# implementation of each of these classes in terms of the base (Numpy-backed\n# FiniteFunction)\nFiniteFunction.IndexedCoproduct = IndexedCoproduct\nFiniteFunction.BipartiteMultigraph = BipartiteMultigraph", "FiniteFunction.IndexedCoproduct = IndexedCoproduct\nFiniteFunction.BipartiteMultigraph = BipartiteMultigraph\nFiniteFunction.Diagram = Diagram\n"]}
{"filename": "yarrow/diagram.py", "chunked_list": ["\"\"\"Diagrams are the main datastructure of yarrow, and represent string diagrams.\n\nThe :py:class:`AbstractDiagram` is the main datastructure of yarrow.\nIt represents a string diagram as a *cospan of bipartite multigraphs*.\nFor example, the diagram below left is represented internally below right:\n\n.. image:: /string-diagram-side-by-side.svg\n   :scale: 150%\n   :align: center\n   :alt: a string diagram and its representation as a cospan", "   :align: center\n   :alt: a string diagram and its representation as a cospan\n\nThis representation (the :py:class:`AbstractDiagram` class) consists of three\nthings:\n\n1. An :py:class:`AbstractBipartiteMultigraph` ``G`` (center grey box)\n2. The *source map* ``s``: the dotted arrows from the *left* blue box to the center box\n3. The *target map* ``t``: the dotted arrows from the *right* blue box to the center box\n", "3. The *target map* ``t``: the dotted arrows from the *right* blue box to the center box\n\nThe center box `G` encodes the internal wiring of the diagram, while ``s`` and\n``t`` encode the \"dangling wires\" on the left and right.\n\nThe :py:class:`AbstractDiagram` class is a backend-agnostic implementation.\nConcrete implementations choose a *backend*, which is an implementation of the classes\n:py:class:`AbstractFiniteFunction` and :py:class:`AbstractBipartiteMultigraph`.\n\nFor example, numpy-backed diagrams are implemented by the :py:class:`Diagram` class,", "\nFor example, numpy-backed diagrams are implemented by the :py:class:`Diagram` class,\nwhich inherits :py:class:`AbstractDiagram` and sets two class members:\n\n- `_Fun = yarrow.array.numpy`\n- `_Graph = yarrow.bipartite_multigraph.BipartiteMultigraph`\n\nFor more information on backends, see :ref:`backends`.\n\nSummary", "\nSummary\n-------\n\n.. autosummary::\n    :template: class.rst\n\n    AbstractDiagram\n\"\"\"\nfrom dataclasses import astuple", "\"\"\"\nfrom dataclasses import astuple\n\nfrom yarrow.finite_function import AbstractFiniteFunction\nfrom yarrow.bipartite_multigraph import AbstractBipartiteMultigraph\n\n# for tensor_operations\nfrom yarrow.segmented.operations import Operations\n\nclass AbstractDiagram:\n    \"\"\" Implements diagrams parametrised by an underlying choice of backend.\n    To use this class, inherit from it and set class members:\n\n    - ``_Fun`` (finite functions)\n    - ``_Graph`` (bipartite multigraphs)\n\n    See for example the :py:class:`Diagram` class, which uses numpy-backed arrays.\n    \"\"\"\n    def __init__(self,\n                 s: AbstractFiniteFunction,\n                 t: AbstractFiniteFunction,\n                 G: AbstractBipartiteMultigraph):\n        \"\"\"Construct a :py:class:`AbstractDiagram` from a triple ``(s, t, G)``.\n\n        Description\n\n        Args:\n            s: Finite function of type `A \u2192 G.W`\n            t: Finite function of type `B \u2192 G.W`\n            G: An :py:class:`AbstractBipartiteMultigraph`\n        \"\"\"\n        self.s = s\n        self.t = t\n        self.G = G\n\n        # the cospan (s, t) is a pair of arrows\n        #     s   t\n        #   A \u2192 G(W) \u2190 B\n        # so we need to verify types work out.\n        assert G.W == s.target\n        assert G.W == t.target\n\n        # Lastly, the underlying finite function type should be the same.\n        _Fun = type(self)._Fun\n        assert _Fun == type(s)\n        assert _Fun == type(t)\n        assert _Fun == G._Fun\n\n    @property\n    def wires(self):\n        \"\"\"\n        Return the number of 'wires' in the diagram.\n        A wire is a node in the graph corresponding to a wire of the string diagram.\n        \"\"\"\n        return self.G.W\n\n    @property\n    def operations(self):\n        \"\"\"Return the number of generating operations in the diagram.\"\"\"\n        return self.G.X\n\n    @property\n    def shape(self):\n        \"\"\" Return the arity and coarity of the diagram. \"\"\"\n        return self.s.source, self.t.source\n\n    @property\n    def type(self):\n        \"\"\" Return a pair of finite functions representing the type of the morphism.\n\n        Returns:\n            (tuple): tuple of:\n                source(AbstractFiniteFunction): typed `self.s.domain \u2192 \u03a3\u2080`\n                target(AbstractFiniteFunction): typed `self.t.domain \u2192 \u03a3\u2080`\n        \"\"\"\n        wire_labels = self.G.wn\n        return (self.s >> wire_labels, self.t >> wire_labels)\n\n    def __eq__(f, g):\n        return f.s == g.s and f.t == g.t and f.G == g.G\n\n    @classmethod\n    def empty(cls, wn : AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\"\n        Args:\n            wn: A FiniteFunction typed `0 \u2192 \u03a3\u2080`: giving the generating objects\n            xn: A FiniteFunction typed `0 \u2192 \u03a3\u2081`: giving the generating operations\n\n        Returns:\n            The empty diagram for the monoidal signature (\u03a3\u2080, \u03a3\u2081)\n\n        Note that for a non-finite signature, we allow the targets of ``wn`` and\n        ``xn`` to be ``None``.\n        \"\"\"\n        s = t = cls._Fun.initial(0)\n        return cls(s, t, cls._Graph.empty(wn, xn))\n\n    @classmethod\n    def identity(cls, wn: AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\"\n        Args:\n            wn: A FiniteFunction typed `W \u2192 \u03a3\u2080`: giving the generating objects\n            xn: A FiniteFunction typed `0 \u2192 \u03a3\u2081`: giving the generating operations\n\n        Returns:\n            AbstractDiagram: The identity diagram with `W` wires labeled `wn : W \u2192 \u03a3\u2080` whose empty set of generators is labeled in \u03a3\u2081\n        \"\"\"\n        assert xn.source == 0\n        s = cls._Fun.identity(wn.source)\n        t = cls._Fun.identity(wn.source)\n        G = cls._Graph.discrete(wn, xn)\n        return cls(s, t, G)\n\n    @classmethod\n    def twist(cls, wn_A: AbstractFiniteFunction, wn_B: AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\"\n        Args:\n            wn_A : typed `A \u2192 \u03a3\u2080`\n            wn_B : typed `B \u2192 \u03a3\u2080`\n            xn   : typed `0 \u2192 \u03a3\u2081`\n\n        Returns:\n            AbstractDiagram: The symmetry diagram `\u03c3 : A \u25cf B \u2192 B \u25cf A`.\n        \"\"\"\n        assert xn.source == 0\n        wn = wn_A + wn_B\n        s = cls._Fun.identity(wn.source)\n        t = cls._Fun.twist(wn_A.source, wn_B.source)\n        G = cls._Graph.discrete(wn, xn)\n        return cls(s, t, G)\n\n    @classmethod\n    def spider(cls,\n               s: AbstractFiniteFunction,\n               t: AbstractFiniteFunction,\n               w: AbstractFiniteFunction,\n               x: AbstractFiniteFunction):\n        \"\"\"Create a *Frobenius Spider* (see Definition 2.8, Proposition 4.7 of :cite:p:`dpafsd`).\n\n        Args:\n            s : source map typed `S \u2192 W`\n            t : target map typed `T \u2192 W`\n            w : wires typed `W \u2192 \u03a3\u2080`\n            x : empty set of operations `0 \u2192 \u03a3\u2081`\n\n        Returns:\n            AbstractDiagram: A frobenius spider with `S` inputs and `T` outputs.\n        \"\"\"\n        assert x.source == 0\n        assert w.source == s.target\n        assert w.source == t.target\n        G = cls._Graph.discrete(w, x)\n        return cls(s, t, G)\n\n    @classmethod\n    def half_spider(cls,\n                    s: AbstractFiniteFunction,\n                    w: AbstractFiniteFunction,\n                    x: AbstractFiniteFunction):\n        \"\"\" Create a *Frobenius Half-Spider*, which is a spider whose target map is the identity \"\"\"\n        # s : A \u2192 W\n        # w : W \u2192 \u03a3\u2080\n        assert s.target == w.source\n        t = cls._Fun.identity(w.source)\n        return cls.spider(s, t, w, x)\n\n    def dagger(self):\n        \"\"\"Swap the *source* and *target* maps of the diagram.\n\n        Returns:\n            AbstractDiagram: The dagger functor applied to this diagram.\n        \"\"\"\n        return type(self)(self.t, self.s, self.G)\n\n    @classmethod\n    def singleton(cls, a: AbstractFiniteFunction, b: AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\" Construct a diagram consisting of a single operation (Definition 4.9, :cite:p:`dpafsd`).\n\n        Args:\n            x: A single operation represented as an AbstractFiniteFunction of type `1 \u2192 \u03a3\u2081`\n            a: The input type of `x` as a finite function `A \u2192 \u03a3\u2080`\n            b: The output type of `x` as a finite function `B \u2192 \u03a3\u2080`\n\n        Returns:\n            AbstractDiagram: a diagram with a single generating operation.\n        \"\"\"\n        Array = cls._Fun._Array\n        F = cls._Fun\n        assert F == type(a)\n        assert F == type(b)\n        assert F == type(xn)\n\n        # x : 1 \u2192 \u03a3\u2081\n        assert xn.source == 1\n\n        # Must be able to take coproduct a + b because\n        #   wn : A + B \u2192 \u03a3\u2080\n        assert a.target == b.target\n\n        # wi : A \u2192 A + B     wo : B \u2192 A + B\n        wi = F.inj0(a.source, b.source)\n        wo = F.inj1(a.source, b.source)\n\n        G = cls._Graph(\n            wi=wi,\n            wo=wo,\n\n            # xi : A \u2192 1         xo : B \u2192 1\n            xi = F.terminal(a.source),\n            xo = F.terminal(b.source),\n\n            # wn : A + B \u2192 \u03a3\u2080\n            wn = a + b,\n\n            # pi' : A \u2192 Nat       po' : B \u2192 Nat\n            # pi = pi';\u03b9          po  = po';\u03b9\n            pi = F(None, Array.arange(a.source)),\n            po = F(None, Array.arange(b.source)),\n\n            xn = xn,\n        )\n\n        # Note: s=inj0, t=inj1, so we just reuse wi and wo.\n        return cls(s=wi, t=wo, G=G)\n\n    def tensor(f: 'AbstractDiagram', g: 'AbstractDiagram'):\n        \"\"\"Stack one diagram atop another, so `f.tensor(g)` is the diagram depicted by\n\n        .. image:: /tensor-f-g.svg\n           :scale: 150%\n           :align: center\n           :alt: a depiction of the tensor product of diagrams\n\n        Args:\n            g(AbstractDiagram): An arbitrary diagram\n\n        Returns:\n            AbstractDiagram: The tensor product of this diagram with `g`.\n        \"\"\"\n        return type(f)(\n            s = f.s @ g.s,\n            t = f.t @ g.t,\n            G = f.G @ g.G)\n\n    def __matmul__(f, g):\n        \"\"\" Shorthand for :py:meth:`yarrow.Diagram.tensor`.\n        f @ g == f.tensor(g)\n        \"\"\"\n        return f.tensor(g)\n\n    def compose(f: 'AbstractDiagram', g: 'AbstractDiagram'):\n        \"\"\"Compose this diagram with `g`, so `f.compose(g)` is the diagram\n\n        .. image:: /compose-f-g.svg\n           :scale: 150%\n           :align: center\n           :alt: a depiction of the tensor product of diagrams\n\n\n        Args:\n            g(AbstractDiagram): A diagram with `g.type[0] == self.type[1]`\n\n        Returns:\n            AbstractDiagram: The tensor product of this diagram with `g`.\n\n        Raises:\n            AssertionError: If `g.type[0] != f.type[1]`\n        \"\"\"\n\n        assert f.type[1] == g.type[0]\n        h = f @ g\n        q = f.t.inject0(g.G.W).coequalizer(g.s.inject1(f.G.W))\n        return type(f)(\n            s = f.s.inject0(g.G.W) >> q,\n            t = g.t.inject1(f.G.W) >> q,\n            G = h.G.coequalize_wires(q))\n\n    def __rshift__(f, g):\n        return f.compose(g)\n\n    @classmethod\n    def tensor_list(cls, ds: 'List[AbstractDiagram]', wn=None, xn=None):\n        \"\"\" Compute the tensor product of a list of diagrams. O(n) time in the size of the result.\n\n        .. warning::\n            Does not speed up to O(log n) in the parallel case\n        \"\"\"\n        if len(ds) == 0:\n            assert wn is not None\n            assert xn is not None\n            return cls.empty(wn, xn)\n\n        assert wn is None\n        assert xn is None\n        s = cls._Fun.tensor_list([d.s for d in ds])\n        t = cls._Fun.tensor_list([d.t for d in ds])\n        G = cls._Graph.coproduct_list([d.G for d in ds])\n        return cls(s, t, G)\n\n    @classmethod\n    def tensor_operations(cls, ops: Operations):\n        pass # hide the docstring for now\n        \"\"\" Compute the X-fold tensoring of operations\n\n        .. code-block:: text\n\n            xn : X \u2192 \u03a3\u2081\n\n        whose typings are given by the segmented finite functions\n\n        .. code-block:: text\n\n            s_type : sum_{i \u2208 X} arity(xn(i))   \u2192 \u03a3\u2080\n            t_type : sum_{i \u2208 X} coarity(xn(i)) \u2192 \u03a3\u2080\n\n        See Proposition 4.13 in :cite:t:`dpafsd`.\n        \"\"\"\n        Fun   = cls._Fun\n        Array = Fun._Array\n\n        xn, s_type, t_type = ops.xn, ops.s_type, ops.t_type\n\n        r = Array.arange(0, xn.source)\n        # TODO: FIXME: redundant computation.\n        # we do a sum of s_type/t_type sources, but we already do a cumsum in\n        # segmented_arange, so this is wasted effort!\n        Ki = Array.sum(s_type.sources.table)\n        Ko = Array.sum(t_type.sources.table)\n\n        i0 = Fun.inj0(Ki, Ko)\n        i1 = Fun.inj1(Ki, Ko)\n\n        return cls(\n            s = i0,\n            t = i1,\n            G = cls._Graph(\n                xn = xn,\n                # Tensor product of terminal maps\n                # e.g. 1 1 1 | 2 2 | 3 3 3 3 ...\n                xi = Fun(xn.source, Array.repeat(r, s_type.sources.table)),\n                xo = Fun(xn.source, Array.repeat(r, t_type.sources.table)),\n                # Coproduct of \u03b9\u2080 maps\n                # e.g. 0 1 2 | 0 1 | 0 1 2 3 ...\n                pi = Fun(None, Array.segmented_arange(s_type.sources.table)),\n                po = Fun(None, Array.segmented_arange(t_type.sources.table)),\n                # wires: sources first, then targets\n                wi = i0,\n                wo = i1,\n                wn = s_type.values + t_type.values))", "\nclass AbstractDiagram:\n    \"\"\" Implements diagrams parametrised by an underlying choice of backend.\n    To use this class, inherit from it and set class members:\n\n    - ``_Fun`` (finite functions)\n    - ``_Graph`` (bipartite multigraphs)\n\n    See for example the :py:class:`Diagram` class, which uses numpy-backed arrays.\n    \"\"\"\n    def __init__(self,\n                 s: AbstractFiniteFunction,\n                 t: AbstractFiniteFunction,\n                 G: AbstractBipartiteMultigraph):\n        \"\"\"Construct a :py:class:`AbstractDiagram` from a triple ``(s, t, G)``.\n\n        Description\n\n        Args:\n            s: Finite function of type `A \u2192 G.W`\n            t: Finite function of type `B \u2192 G.W`\n            G: An :py:class:`AbstractBipartiteMultigraph`\n        \"\"\"\n        self.s = s\n        self.t = t\n        self.G = G\n\n        # the cospan (s, t) is a pair of arrows\n        #     s   t\n        #   A \u2192 G(W) \u2190 B\n        # so we need to verify types work out.\n        assert G.W == s.target\n        assert G.W == t.target\n\n        # Lastly, the underlying finite function type should be the same.\n        _Fun = type(self)._Fun\n        assert _Fun == type(s)\n        assert _Fun == type(t)\n        assert _Fun == G._Fun\n\n    @property\n    def wires(self):\n        \"\"\"\n        Return the number of 'wires' in the diagram.\n        A wire is a node in the graph corresponding to a wire of the string diagram.\n        \"\"\"\n        return self.G.W\n\n    @property\n    def operations(self):\n        \"\"\"Return the number of generating operations in the diagram.\"\"\"\n        return self.G.X\n\n    @property\n    def shape(self):\n        \"\"\" Return the arity and coarity of the diagram. \"\"\"\n        return self.s.source, self.t.source\n\n    @property\n    def type(self):\n        \"\"\" Return a pair of finite functions representing the type of the morphism.\n\n        Returns:\n            (tuple): tuple of:\n                source(AbstractFiniteFunction): typed `self.s.domain \u2192 \u03a3\u2080`\n                target(AbstractFiniteFunction): typed `self.t.domain \u2192 \u03a3\u2080`\n        \"\"\"\n        wire_labels = self.G.wn\n        return (self.s >> wire_labels, self.t >> wire_labels)\n\n    def __eq__(f, g):\n        return f.s == g.s and f.t == g.t and f.G == g.G\n\n    @classmethod\n    def empty(cls, wn : AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\"\n        Args:\n            wn: A FiniteFunction typed `0 \u2192 \u03a3\u2080`: giving the generating objects\n            xn: A FiniteFunction typed `0 \u2192 \u03a3\u2081`: giving the generating operations\n\n        Returns:\n            The empty diagram for the monoidal signature (\u03a3\u2080, \u03a3\u2081)\n\n        Note that for a non-finite signature, we allow the targets of ``wn`` and\n        ``xn`` to be ``None``.\n        \"\"\"\n        s = t = cls._Fun.initial(0)\n        return cls(s, t, cls._Graph.empty(wn, xn))\n\n    @classmethod\n    def identity(cls, wn: AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\"\n        Args:\n            wn: A FiniteFunction typed `W \u2192 \u03a3\u2080`: giving the generating objects\n            xn: A FiniteFunction typed `0 \u2192 \u03a3\u2081`: giving the generating operations\n\n        Returns:\n            AbstractDiagram: The identity diagram with `W` wires labeled `wn : W \u2192 \u03a3\u2080` whose empty set of generators is labeled in \u03a3\u2081\n        \"\"\"\n        assert xn.source == 0\n        s = cls._Fun.identity(wn.source)\n        t = cls._Fun.identity(wn.source)\n        G = cls._Graph.discrete(wn, xn)\n        return cls(s, t, G)\n\n    @classmethod\n    def twist(cls, wn_A: AbstractFiniteFunction, wn_B: AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\"\n        Args:\n            wn_A : typed `A \u2192 \u03a3\u2080`\n            wn_B : typed `B \u2192 \u03a3\u2080`\n            xn   : typed `0 \u2192 \u03a3\u2081`\n\n        Returns:\n            AbstractDiagram: The symmetry diagram `\u03c3 : A \u25cf B \u2192 B \u25cf A`.\n        \"\"\"\n        assert xn.source == 0\n        wn = wn_A + wn_B\n        s = cls._Fun.identity(wn.source)\n        t = cls._Fun.twist(wn_A.source, wn_B.source)\n        G = cls._Graph.discrete(wn, xn)\n        return cls(s, t, G)\n\n    @classmethod\n    def spider(cls,\n               s: AbstractFiniteFunction,\n               t: AbstractFiniteFunction,\n               w: AbstractFiniteFunction,\n               x: AbstractFiniteFunction):\n        \"\"\"Create a *Frobenius Spider* (see Definition 2.8, Proposition 4.7 of :cite:p:`dpafsd`).\n\n        Args:\n            s : source map typed `S \u2192 W`\n            t : target map typed `T \u2192 W`\n            w : wires typed `W \u2192 \u03a3\u2080`\n            x : empty set of operations `0 \u2192 \u03a3\u2081`\n\n        Returns:\n            AbstractDiagram: A frobenius spider with `S` inputs and `T` outputs.\n        \"\"\"\n        assert x.source == 0\n        assert w.source == s.target\n        assert w.source == t.target\n        G = cls._Graph.discrete(w, x)\n        return cls(s, t, G)\n\n    @classmethod\n    def half_spider(cls,\n                    s: AbstractFiniteFunction,\n                    w: AbstractFiniteFunction,\n                    x: AbstractFiniteFunction):\n        \"\"\" Create a *Frobenius Half-Spider*, which is a spider whose target map is the identity \"\"\"\n        # s : A \u2192 W\n        # w : W \u2192 \u03a3\u2080\n        assert s.target == w.source\n        t = cls._Fun.identity(w.source)\n        return cls.spider(s, t, w, x)\n\n    def dagger(self):\n        \"\"\"Swap the *source* and *target* maps of the diagram.\n\n        Returns:\n            AbstractDiagram: The dagger functor applied to this diagram.\n        \"\"\"\n        return type(self)(self.t, self.s, self.G)\n\n    @classmethod\n    def singleton(cls, a: AbstractFiniteFunction, b: AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\" Construct a diagram consisting of a single operation (Definition 4.9, :cite:p:`dpafsd`).\n\n        Args:\n            x: A single operation represented as an AbstractFiniteFunction of type `1 \u2192 \u03a3\u2081`\n            a: The input type of `x` as a finite function `A \u2192 \u03a3\u2080`\n            b: The output type of `x` as a finite function `B \u2192 \u03a3\u2080`\n\n        Returns:\n            AbstractDiagram: a diagram with a single generating operation.\n        \"\"\"\n        Array = cls._Fun._Array\n        F = cls._Fun\n        assert F == type(a)\n        assert F == type(b)\n        assert F == type(xn)\n\n        # x : 1 \u2192 \u03a3\u2081\n        assert xn.source == 1\n\n        # Must be able to take coproduct a + b because\n        #   wn : A + B \u2192 \u03a3\u2080\n        assert a.target == b.target\n\n        # wi : A \u2192 A + B     wo : B \u2192 A + B\n        wi = F.inj0(a.source, b.source)\n        wo = F.inj1(a.source, b.source)\n\n        G = cls._Graph(\n            wi=wi,\n            wo=wo,\n\n            # xi : A \u2192 1         xo : B \u2192 1\n            xi = F.terminal(a.source),\n            xo = F.terminal(b.source),\n\n            # wn : A + B \u2192 \u03a3\u2080\n            wn = a + b,\n\n            # pi' : A \u2192 Nat       po' : B \u2192 Nat\n            # pi = pi';\u03b9          po  = po';\u03b9\n            pi = F(None, Array.arange(a.source)),\n            po = F(None, Array.arange(b.source)),\n\n            xn = xn,\n        )\n\n        # Note: s=inj0, t=inj1, so we just reuse wi and wo.\n        return cls(s=wi, t=wo, G=G)\n\n    def tensor(f: 'AbstractDiagram', g: 'AbstractDiagram'):\n        \"\"\"Stack one diagram atop another, so `f.tensor(g)` is the diagram depicted by\n\n        .. image:: /tensor-f-g.svg\n           :scale: 150%\n           :align: center\n           :alt: a depiction of the tensor product of diagrams\n\n        Args:\n            g(AbstractDiagram): An arbitrary diagram\n\n        Returns:\n            AbstractDiagram: The tensor product of this diagram with `g`.\n        \"\"\"\n        return type(f)(\n            s = f.s @ g.s,\n            t = f.t @ g.t,\n            G = f.G @ g.G)\n\n    def __matmul__(f, g):\n        \"\"\" Shorthand for :py:meth:`yarrow.Diagram.tensor`.\n        f @ g == f.tensor(g)\n        \"\"\"\n        return f.tensor(g)\n\n    def compose(f: 'AbstractDiagram', g: 'AbstractDiagram'):\n        \"\"\"Compose this diagram with `g`, so `f.compose(g)` is the diagram\n\n        .. image:: /compose-f-g.svg\n           :scale: 150%\n           :align: center\n           :alt: a depiction of the tensor product of diagrams\n\n\n        Args:\n            g(AbstractDiagram): A diagram with `g.type[0] == self.type[1]`\n\n        Returns:\n            AbstractDiagram: The tensor product of this diagram with `g`.\n\n        Raises:\n            AssertionError: If `g.type[0] != f.type[1]`\n        \"\"\"\n\n        assert f.type[1] == g.type[0]\n        h = f @ g\n        q = f.t.inject0(g.G.W).coequalizer(g.s.inject1(f.G.W))\n        return type(f)(\n            s = f.s.inject0(g.G.W) >> q,\n            t = g.t.inject1(f.G.W) >> q,\n            G = h.G.coequalize_wires(q))\n\n    def __rshift__(f, g):\n        return f.compose(g)\n\n    @classmethod\n    def tensor_list(cls, ds: 'List[AbstractDiagram]', wn=None, xn=None):\n        \"\"\" Compute the tensor product of a list of diagrams. O(n) time in the size of the result.\n\n        .. warning::\n            Does not speed up to O(log n) in the parallel case\n        \"\"\"\n        if len(ds) == 0:\n            assert wn is not None\n            assert xn is not None\n            return cls.empty(wn, xn)\n\n        assert wn is None\n        assert xn is None\n        s = cls._Fun.tensor_list([d.s for d in ds])\n        t = cls._Fun.tensor_list([d.t for d in ds])\n        G = cls._Graph.coproduct_list([d.G for d in ds])\n        return cls(s, t, G)\n\n    @classmethod\n    def tensor_operations(cls, ops: Operations):\n        pass # hide the docstring for now\n        \"\"\" Compute the X-fold tensoring of operations\n\n        .. code-block:: text\n\n            xn : X \u2192 \u03a3\u2081\n\n        whose typings are given by the segmented finite functions\n\n        .. code-block:: text\n\n            s_type : sum_{i \u2208 X} arity(xn(i))   \u2192 \u03a3\u2080\n            t_type : sum_{i \u2208 X} coarity(xn(i)) \u2192 \u03a3\u2080\n\n        See Proposition 4.13 in :cite:t:`dpafsd`.\n        \"\"\"\n        Fun   = cls._Fun\n        Array = Fun._Array\n\n        xn, s_type, t_type = ops.xn, ops.s_type, ops.t_type\n\n        r = Array.arange(0, xn.source)\n        # TODO: FIXME: redundant computation.\n        # we do a sum of s_type/t_type sources, but we already do a cumsum in\n        # segmented_arange, so this is wasted effort!\n        Ki = Array.sum(s_type.sources.table)\n        Ko = Array.sum(t_type.sources.table)\n\n        i0 = Fun.inj0(Ki, Ko)\n        i1 = Fun.inj1(Ki, Ko)\n\n        return cls(\n            s = i0,\n            t = i1,\n            G = cls._Graph(\n                xn = xn,\n                # Tensor product of terminal maps\n                # e.g. 1 1 1 | 2 2 | 3 3 3 3 ...\n                xi = Fun(xn.source, Array.repeat(r, s_type.sources.table)),\n                xo = Fun(xn.source, Array.repeat(r, t_type.sources.table)),\n                # Coproduct of \u03b9\u2080 maps\n                # e.g. 0 1 2 | 0 1 | 0 1 2 3 ...\n                pi = Fun(None, Array.segmented_arange(s_type.sources.table)),\n                po = Fun(None, Array.segmented_arange(t_type.sources.table)),\n                # wires: sources first, then targets\n                wi = i0,\n                wo = i1,\n                wn = s_type.values + t_type.values))", ""]}
{"filename": "yarrow/__init__.py", "chunked_list": ["# The default backend is numpy\nfrom yarrow.numpy import *\n"]}
{"filename": "yarrow/bipartite_multigraph.py", "chunked_list": ["\"\"\"A representation of the \"internal wiring\" of string diagrams.\nBipartite multigraphs have edge labels corresponding to the \"ports\" of\noperations, and node labels either generating objects or generating operations\nof a signature \u03a3.\n\nAs with other classes, these graphs are implemented with an abstract base class\n:py:class:`AbstractBipartiteMultigraph`,\nwhose concrete instantiations choose a backend.\nFor example, :py:class:`BipartiteMultigraph` are backed by numpy arrays.\n\"\"\"", "For example, :py:class:`BipartiteMultigraph` are backed by numpy arrays.\n\"\"\"\nfrom dataclasses import dataclass\nfrom yarrow.finite_function import AbstractFiniteFunction\n\nclass AbstractBipartiteMultigraph:\n    \"\"\" The type of bipartite multigraphs, parametrised by cls._Fun, the\n    underlying representation of finite functions \"\"\"\n    def __init__(self, wi, wo, xi, xo, wn, pi, po, xn):\n        \"\"\"Create a BipartiteMultigraph from its component finite functions.\n        For more details see :cite:p:`dpafsd`, Section 3.2.\n        \"\"\"\n        # Edge/Wire incidence\n        self.wi = wi\n        self.wo = wo\n\n        # Edge/Generator incidence\n        self.xi = xi\n        self.xo = xo\n\n        # Wire + generator labels\n        self.xn = xn\n        self.wn = wn\n\n        # Port labels\n        self.pi = pi\n        self.po = po\n\n        # Check schema of bipartite multigraphs is satisfied\n        if wi.target != wo.target:\n            raise ValueError(\"wi.target != wo.target\")\n        if xi.target != xo.target:\n            raise ValueError(\"xi.target != xo.target\")\n        if wi.source != xi.source:\n            raise ValueError(\"wi.source != xi.source\")\n        if wo.source != xo.source:\n            raise ValueError(\"wo.source != xo.source\")\n        if wn.source != wi.target:\n            raise ValueError(\"wn.source != wi.target\")\n        if wn.source != wi.target:\n            raise ValueError(\"wn.source != wi.target\")\n        if pi.source != xi.source:\n            raise ValueError(\"pi.source != xi.source\")\n        if po.source != xo.source:\n            raise ValueError(\"pi.source != xo.source\")\n        if xn.source != xi.target:\n            raise ValueError(\"xn.source != xi.target\")\n\n    @property\n    def W(self):\n        \"\"\"Test\n\n        Returns:\n            G(W)\n        \"\"\"\n        # wn : G(W) \u2192 \u03a3\u2080\n        return self.wn.source\n\n    @property\n    def Ei(self):\n        \"\"\"Test\n\n        Returns:\n            The number of *input edges* in the graph\n        \"\"\"\n        return self.wi.source\n\n    @property\n    def Eo(self):\n        \"\"\"\n        Returns:\n            The number of *output edges* in the graph\n        \"\"\"\n        return self.wo.source\n\n    @property\n    def X(self):\n        \"\"\"\n        Returns:\n            int: Corresponds to G(X), the number of generating operations in the diagram\"\"\"\n        # xn : G(X) \u2192 \u03a3\u2081\n        return self.xn.source\n\n    @classmethod\n    def empty(cls, wn, xn):\n        \"\"\"\n        Args:\n            wn: Finite function typed `0 \u2192 \u03a3\u2080`\n            xn: Finite function typed `0 \u2192 \u03a3\u2081`\n\n        Returns:\n            AbstractBipartiteMultigraph: The empty bipartite multigraph with no edges and no nodes.\n        \"\"\"\n        assert wn.source == 0\n        assert xn.source == 0\n        e = cls._Fun.initial(0)\n        pi = po = cls._Fun.initial(None)\n        return cls(e, e, e, e, wn, pi, po, xn)\n\n    @classmethod\n    def discrete(cls, wn: AbstractFiniteFunction, xn: AbstractFiniteFunction):\n        \"\"\"\n        Create the discrete graph of n wires for a given monoidal signature \u03a3\n        whose maps are all initial except for `wn`.\n\n        Args:\n            wn: An array of wire labels as a finite function typed `n \u2192 \u03a3\u2080`\n            xn: The type of operations as an empty finite function typed `0 \u2192 \u03a3\u2081`\n        \"\"\"\n        if xn.source != 0:\n            raise ValueError(\"xn.source != 0\")\n\n        return cls(\n            # There are no edges, so we make empty maps for all edge data\n            wi = cls._Fun.initial(wn.source),\n            wo = cls._Fun.initial(wn.source),\n            xi = cls._Fun.initial(0),\n            xo = cls._Fun.initial(0),\n\n            # TODO: dirty hack alert: None represents any \"non-finite\" codomain here.\n            # In this case, we need edge_data : E \u2192 Nat\n            # but this (obviously) cannot be represented by a finite function.\n            # This is justified because both these maps factor through some\n            # finite function: we just don't know what it is at this point in\n            # the code.\n            pi = cls._Fun.initial(None),\n            po = cls._Fun.initial(None),\n\n            wn = wn, # there are w_label.target wires\n            xn = xn, # and no operation nodes\n        )\n\n    def __eq__(a, b):\n        return \\\n            a.wi == b.wi and \\\n            a.wo == b.wo and \\\n            a.xi == b.xi and \\\n            a.xo == b.xo and \\\n            a.wn == b.wn and \\\n            a.pi == b.pi and \\\n            a.po == b.po and \\\n            a.xn == b.xn\n\n    def coproduct(f, g):\n        \"\"\"Compute the coproduct of bipartite multigraphs\n\n        Args:\n            g: an arbitrary AbstractBipartiteMultigraph over the same signature\n\n        Returns:\n            The coproduct ``self + g``.\n        \"\"\"\n        # check signatures match\n        assert f.wn.target == g.wn.target\n        assert f.xn.target == g.xn.target\n\n        return type(f)(\n            # Tensor product of data\n            wi=f.wi @ g.wi,\n            wo=f.wo @ g.wo,\n            xi=f.xi @ g.xi,\n            xo=f.xo @ g.xo,\n            # Coproduct of attributes\n            wn=f.wn + g.wn,\n            pi=f.pi + g.pi,\n            po=f.po + g.po,\n            xn=f.xn + g.xn,\n        )\n\n    def __matmul__(f, g):\n        return f.coproduct(g)\n\n    @classmethod\n    def coproduct_list(cls, Gs: 'List[AbstractBipartiteMultigraph]', wn=None, xn=None):\n        \"\"\" Compute the coproduct of a list of bipartite multigraphs. O(n) in the size of the result.\n\n        .. warning::\n            Does not speed up to O(log n) in the parallel case.\n        \"\"\"\n        if len(Gs) == 0:\n            assert wn is not None\n            assert xn is not None\n            return cls.empty(wn, xn)\n\n        # can't specify \u03a3 if Gs is non-empty\n        assert wn is None\n        assert xn is None\n        return cls(\n            wi=cls._Fun.tensor_list([g.wi for g in Gs]),\n            wo=cls._Fun.tensor_list([g.wo for g in Gs]),\n            xi=cls._Fun.tensor_list([g.xi for g in Gs]),\n            xo=cls._Fun.tensor_list([g.xo for g in Gs]),\n            wn=cls._Fun.coproduct_list([g.wn for g in Gs]),\n            pi=cls._Fun.coproduct_list([g.pi for g in Gs]),\n            po=cls._Fun.coproduct_list([g.po for g in Gs]),\n            xn=cls._Fun.coproduct_list([g.xn for g in Gs]))\n\n    # Apply a morphism \u03b1 of bipartite multigraphs whose only\n    # non-identity component is \u03b1_W = q.\n    def coequalize_wires(self, q : AbstractFiniteFunction):\n        \"\"\"\n        Apply a morphism \u03b1 of bipartite multigraphs\n        whose only non-identity component \u03b1_W = q\n        for some coequalizer q.\n\n        Args:\n            q: An AbstractFiniteFunction which is a coequalizer.\n\n        Returns:\n            AbstractBipartiteMultigraph: The bipartite multigraph equal to the target of \u03b1.\n        \"\"\"\n        assert self.wn.source == q.source\n        u = universal(q, self.wn)\n\n        # Check that resulting diagram commutes\n        # TODO: this is unnecessary extra computation when the user knows that q is a coequalizer.\n        # Make a flag?\n        Array = type(q)._Array\n        if not (q >> u) == self.wn:\n            raise ValueError(f\"Universal morphism doesn't make {q};{u}, {self.wn} commute. Is q really a coequalizer?\")\n\n        return type(self)(\n                wi=self.wi >> q,\n                wo=self.wo >> q,\n                wn=u,\n                xi=self.xi,\n                xo=self.xo,\n                pi=self.pi,\n                po=self.po,\n                xn=self.xn)", "\n# Let G be a bipartite multigraph.\n# Given a coequalizer q : G(W) \u2192 Q of finite functions,\n# Define the map\n#   \u03b1 : G \u2192 G'\n# with\n#   \u03b1_W = q\n#   \u03b1_Y = id_Y\n#\n# Then we need a map", "#\n# Then we need a map\n#   Q(W) \u2192 \u03a3\u2080\n# which we can get because\n#   G(wn) : G(W) \u2192 \u03a3\u2080\n# coequalizes, and so there exists some unique\n#   u : Q(W) \u2192 \u03a3\u2080\n# such that\n#   q ; u = G(wn)\n# And this can be computed as follows:", "#   q ; u = G(wn)\n# And this can be computed as follows:\n#   u[q[i]] = G(wn)\ndef universal(q: AbstractFiniteFunction, f: AbstractFiniteFunction):\n    \"\"\"\n    Given a coequalizer q : B \u2192 Q of morphisms a, b : A \u2192 B\n    and some f : B \u2192 B' such that f(a) = f(b),\n    Compute the universal map u : Q \u2192 B'\n    such that q ; u = f.\n    \"\"\"\n    target = f.target\n    u = q._Array.zeros(q.target, dtype=f.table.dtype)\n    # TODO: in the below we assume the PRAM CRCW model: multiple writes to the\n    # same memory location in the 'u' array can happen in parallel, with an\n    # arbitrary write succeeding.\n    # Note that this doesn't affect correctness because q and f are co-forks,\n    # and q is a coequalizer.\n    # However, this won't perform well on e.g., GPU hardware. FIXME!\n    u[q.table] = f.table\n    return type(f)(target, u)", ""]}
{"filename": "yarrow/numpy/layer.py", "chunked_list": ["\"\"\" Layered decomposition for numpy-backed diagrams.\nNote that this (currently) uses SciPy sparse arrays, so it can't be used for diagrams backed\nby other array libraries (e.g., CuPy).\n\nUse the ``layer`` function to assign a *layering* to operations in the diagram.\nThis is like a topological sort, except multiple operations can be assigned to\nthe same layering.\n\"\"\"\nimport numpy as np\nimport scipy.sparse as sp", "import numpy as np\nimport scipy.sparse as sp\n\nfrom yarrow.numpy import *\n\ndef make_sparse(s: FiniteFunction, t: FiniteFunction):\n    \"\"\"Given finite functions ``s : E \u2192 A`` and ``t : E \u2192 B``\n    representing a bipartite graph ``G : A \u2192 B``,\n    return the sparse ``B\u00d7A`` adjacency matrix representing ``G``.\n    \"\"\"\n    assert s.source == t.source\n    N = s.source\n    # (data, (row, col))\n    # rows are *outputs*, so row = t.table\n    # cols are *inputs* so col = s.table\n    return sp.csr_array((np.ones(N, dtype=bool), (t.table, s.table)), shape=(t.target, s.target))", "\ndef operation_adjacency(d: Diagram):\n    \"\"\" Construct the underlying graph of operation adjacency from a diagram.\n    An operation ``x`` is adjacent to an operation ``y`` if there is a directed\n    path from ``x`` to ``y`` going through a single \u25a0-node.\n    \"\"\"\n    # construct the adjacency matrix for generators\n    Mi = make_sparse(d.G.wi, d.G.xi)\n    Mo = make_sparse(d.G.wo, d.G.xo)\n    return Mi @ Mo.T", "\n# Kahn's Algorithm, but vectorised a bit.\n# https://en.wikipedia.org/wiki/Topological_sorting#Kahn's_algorithm\n# Attempts to 'parallelize' the layering where possible, e.g.:\n#\n#          \u25cb--\\\n#              \u25cb---\u25cb\n#          \u25cb--/\n#\n#       ---\u25cb--------", "#\n#       ---\u25cb--------\n#\n#  layer   0   1   2\n#\ndef kahn(adjacency: sp.csr_array):\n    \"\"\" A version of Kahn's algorithm which assigns a *layering* to each \u25cb-node,\n    but where multiple nodes can have the same layering.\n\n    Returns a pair of arrays ``(order, visited)``.\n    ``order[v]`` is a natural number indicating the computed ordering of node ``v``,\n    and ``visited[v]`` is 1 if and only if ``v`` was visited while traversing the graph.\n\n    If not all vertices were visited, the graph had a cycle.\n    \"\"\"\n    n, m = adjacency.shape\n    assert n == m\n    adjacency = adjacency.astype(int)\n\n    # NOTE: convert to numpy ndarray instead of matrix given by adjacency;\n    # this makes indexing behaviour a bit nicer!\n    # NOTE: we use reshape here because adjacency.sum() gives different dimensions when input is 0x0!\n    indegree = np.asarray(adjacency.sum(axis=1, dtype=int)).reshape((n,))\n\n    # return values\n    visited  = np.zeros(n, dtype=bool)\n    order    = np.zeros(n, dtype=int)\n\n    # start at nodes with no incoming edges\n    start = (indegree == 0).nonzero()[0]\n\n    # initialize the frontier at the requested start nodes\n    k = len(start)\n    frontier = sp.csr_array((np.ones(k, int), (start, np.zeros(k, int))), (n, 1))\n\n    # as long as the frontier contains some nodes, we'll keep going.\n    depth = 0\n    while frontier.nnz > 0:\n        # Mark nodes in the current frontier as visited,\n        # and set their layering value ('order') to the current depth.\n        frontier_ixs = frontier.nonzero()[0]\n        visited[frontier_ixs] = True\n        order[frontier_ixs] = depth\n\n        # Find \"reachable\", which is the set of nodes adjacent to the current frontier.\n        # Decrement the indegree of each adjacent node by the number of edges between it and the frontier.\n        # NOTE: nodes only remain in the frontier for ONE iteration, so this\n        # will only decrement once for each edge.\n        reachable = adjacency @ frontier\n        reachable_ix = reachable.nonzero()[0]\n        indegree[reachable_ix] -= reachable.data\n\n        # Compute the new frontier: the reachable nodes with indegree equal to zero (no more remaining edges!)\n        # NOTE: indegree is an (N,1) matrix, so we select out the first row.\n        new_frontier_ixs = reachable_ix[indegree[reachable_ix] == 0]\n        k = len(new_frontier_ixs)\n        frontier = sp.csr_array((np.ones(k, int), (new_frontier_ixs, np.zeros(k, int))), shape=(n, 1))\n\n        # increment depth so the new frontier will be layered correctly\n        depth += 1\n\n    # Return the layering (order) and whether each node was visited.\n    # Note that if not np.all(visited), then there must be a cycle.\n    return order, visited", "\ndef layer(d: Diagram):\n    \"\"\" Assign a *layering* to a diagram ``d``.\n        This computes a FiniteFunction ``f : G(X) \u2192 K``,\n        mapping \u25cb-nodes of ``d.G`` to a natural number in the ``range(0, K)``.\n        This mapping is 'dense' in the sense that for each ``i \u2208 {0..K}``,\n        there is always some \u25cb-node v for which ``f(v) = i``.\n    \"\"\"\n    # (Partially) topologically sort it using a kahn-ish algorithm\n    # NOTE: if completed is not all True, then some generators were not ordered.\n    # In this case, we leave their ordering as 0, since they contain cycles.\n    M = operation_adjacency(d)\n    ordering, completed = kahn(M)\n    return FiniteFunction(d.operations, ordering), completed", ""]}
{"filename": "yarrow/numpy/__init__.py", "chunked_list": ["\"\"\" NumPy-backed finite functions, bipartite multigraphs, and diagrams.\n\n**Additional NumPy-backend-only code:**\n\n.. autosummary::\n    :toctree: _autosummary\n    :recursive:\n\n    yarrow.numpy.layer\n", "    yarrow.numpy.layer\n\n**NumPy-backed datastructures**:\n\"\"\"\n# Abstract implementations\nfrom yarrow.finite_function import *\nfrom yarrow.bipartite_multigraph import *\nfrom yarrow.diagram import *\nfrom yarrow.segmented.finite_function import AbstractIndexedCoproduct, AbstractSegmentedFiniteFunction\n", "from yarrow.segmented.finite_function import AbstractIndexedCoproduct, AbstractSegmentedFiniteFunction\n\n# Array backend\nimport yarrow.array.numpy as numpy_backend\n\nclass FiniteFunction(AbstractFiniteFunction):\n    \"\"\" NumPy-backed finite functions \"\"\"\n    _Array = numpy_backend\n\nclass IndexedCoproduct(AbstractIndexedCoproduct):\n    _Fun = FiniteFunction", "\nclass IndexedCoproduct(AbstractIndexedCoproduct):\n    _Fun = FiniteFunction\n\nclass BipartiteMultigraph(AbstractBipartiteMultigraph):\n    \"\"\" NumPy-backed bipartite multigraphs \"\"\"\n    _Fun = FiniteFunction\n\nclass Diagram(AbstractDiagram):\n    \"\"\" NumPy-backed string diagrams \"\"\"\n    _Fun = FiniteFunction\n    _Graph = BipartiteMultigraph", "class Diagram(AbstractDiagram):\n    \"\"\" NumPy-backed string diagrams \"\"\"\n    _Fun = FiniteFunction\n    _Graph = BipartiteMultigraph\n\nclass SegmentedFiniteFunction(AbstractSegmentedFiniteFunction):\n    _Array = numpy_backend\n    _Fun = FiniteFunction\n\n# If we had types, this would be 'type-level function' giving us the", "\n# If we had types, this would be 'type-level function' giving us the\n# implementation of each of these classes in terms of the base (Numpy-backed\n# FiniteFunction)\nFiniteFunction.IndexedCoproduct = IndexedCoproduct\nFiniteFunction.BipartiteMultigraph = BipartiteMultigraph\nFiniteFunction.Diagram = Diagram\n"]}
{"filename": "yarrow/functor/optic.py", "chunked_list": ["\"\"\" Functors to diagrams of optics.\n\nThis module contains a class :py:class:`FrobeniusOpticFunctor`, which can be\nused to implement a functor from diagrams into a category of *optics*.\n\n\"\"\"\nfrom yarrow.diagram import AbstractDiagram\nfrom yarrow.functor.functor import *\n\n# A generic base class for optics\nclass FrobeniusOpticFunctor(FrobeniusFunctor):\n\n    @abstractmethod\n    def map_fwd_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        ...\n\n    @abstractmethod\n    def map_rev_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        ...\n\n    @abstractmethod\n    def residuals(self, ops: Operations) -> AbstractIndexedCoproduct:\n        ...\n\n    @abstractmethod\n    def map_fwd_operations(self, ops: Operations) -> AbstractDiagram:\n        ...\n\n    @abstractmethod\n    def map_rev_operations(self, ops: Operations) -> AbstractDiagram:\n        ...\n\n    ############################################################################\n    # Implementation\n\n    def map_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        \"\"\" Implements map_objects in terms of ``map_fwd_objects`` and ``map_rev_objects``. \"\"\"\n        # look up concrete impl. of IndexedCoproduct\n        IndexedCoproduct = type(objects).IndexedCoproduct\n\n        # interleave forward and reverse objects\n        fwd = self.map_fwd_objects(objects)\n        rev = self.map_rev_objects(objects)\n\n        # this must hold because len(fwd) == len(objects).\n        N = len(objects)\n        assert N == len(fwd)\n        assert N == len(rev)\n        Fun = type(objects)\n\n        # return the blockwise interleaving of fwd/rev\n        i = Fun.cointerleave(N)\n        sources = Fun(None, fwd.sources.table + rev.sources.table)\n\n        both = IndexedCoproduct(\n            sources = fwd.sources + rev.sources,\n            values  = fwd.values  + rev.values)\n\n        sigma_1 = fwd.values.target\n        result = IndexedCoproduct(\n            sources = sources,\n            values  = Fun(sigma_1, both.coproduct(i).table))\n        return result\n\n    def map_operations(self, ops: Operations) -> AbstractDiagram:\n        \"\"\" Implements ``map_operations`` using ``map_fwd_operations`` and ``map_rev_operations``. \"\"\"\n        # TODO: add diagram from notes 2023-06-12\n        fwds, fwd_coarity = self.map_fwd_operations(ops)\n        revs, rev_arity   = self.map_rev_operations(ops)\n\n        Diagram = type(fwds)\n        Fun = fwds._Fun\n        xn = Fun.initial(fwds.G.xn.source) >> fwds.G.xn\n\n        # We need the sizes of each of these types in order to compute\n        # both the internal and external interleavings.\n        Afwd = self.map_fwd_objects(ops.s_type.values)\n        Arev = self.map_rev_objects(ops.s_type.values)\n        Bfwd = self.map_fwd_objects(ops.t_type.values)\n        Brev = self.map_rev_objects(ops.t_type.values)\n        Na = len(Afwd.sources) # number of source wires before functor\n        Nb = len(Bfwd.sources) # number of target wires before functor\n\n        # Get the residuals for each operation\n        M = self.residuals(ops)\n\n        # 'Internal' interleaving maps which bundle together all the Bfwd / M values\n        # so we can pass all the M's to \"revs\".\n        wn1 = Bfwd.values + M.values\n        fwd_output_sizes = Fun(None, fwd_coarity.table - M.sources.table) + M.sources\n        i1 = fwd_output_sizes.injections(Fun.cointerleave(len(ops.xn)))\n        i1 = Diagram.half_spider(i1, wn1, xn)\n\n        wn2 = M.values + Brev.values\n        rev_input_sizes = M.sources + Fun(None, rev_arity.table - M.sources.table)\n        i2 = rev_input_sizes.injections(Fun.cointerleave(len(ops.xn)))\n        i2 = Diagram.half_spider(i2, wn2, xn).dagger()\n\n        id_Bfwd = Diagram.identity(Bfwd.values, xn)\n        id_Brev = Diagram.identity(Brev.values, xn)\n        x = (fwds >> i1) @ id_Brev\n        y = id_Bfwd @ (i2 >> revs)\n        c = x >> y\n\n        # Bend wires to make an optic.\n        # Sources: fwd sources and rev targets\n        # Targets: fwd targets and rev sources\n        s = (Fun.inj0(len(Afwd.values), len(Brev.values)) >> c.s) + (Fun.inj1(len(Bfwd.values), len(Arev.values)) >> c.t)\n        t = (Fun.inj0(len(Bfwd.values), len(Arev.values)) >> c.t) + (Fun.inj1(len(Afwd.values), len(Brev.values)) >> c.s)\n        d = Diagram(s, t, c.G)\n\n        # Finally, interleave Afwd/Arev and Bfwd/Brev so optics can be tensored.\n        lhs = (Afwd.sources + Arev.sources).injections(Fun.cointerleave(Na))\n        rhs = (Bfwd.sources + Brev.sources).injections(Fun.cointerleave(Nb))\n\n        lhs = Diagram.half_spider(lhs, d.type[0], xn)\n        rhs = Diagram.half_spider(rhs, d.type[1], xn).dagger()\n        return lhs >> d >> rhs", "\n# A generic base class for optics\nclass FrobeniusOpticFunctor(FrobeniusFunctor):\n\n    @abstractmethod\n    def map_fwd_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        ...\n\n    @abstractmethod\n    def map_rev_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        ...\n\n    @abstractmethod\n    def residuals(self, ops: Operations) -> AbstractIndexedCoproduct:\n        ...\n\n    @abstractmethod\n    def map_fwd_operations(self, ops: Operations) -> AbstractDiagram:\n        ...\n\n    @abstractmethod\n    def map_rev_operations(self, ops: Operations) -> AbstractDiagram:\n        ...\n\n    ############################################################################\n    # Implementation\n\n    def map_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        \"\"\" Implements map_objects in terms of ``map_fwd_objects`` and ``map_rev_objects``. \"\"\"\n        # look up concrete impl. of IndexedCoproduct\n        IndexedCoproduct = type(objects).IndexedCoproduct\n\n        # interleave forward and reverse objects\n        fwd = self.map_fwd_objects(objects)\n        rev = self.map_rev_objects(objects)\n\n        # this must hold because len(fwd) == len(objects).\n        N = len(objects)\n        assert N == len(fwd)\n        assert N == len(rev)\n        Fun = type(objects)\n\n        # return the blockwise interleaving of fwd/rev\n        i = Fun.cointerleave(N)\n        sources = Fun(None, fwd.sources.table + rev.sources.table)\n\n        both = IndexedCoproduct(\n            sources = fwd.sources + rev.sources,\n            values  = fwd.values  + rev.values)\n\n        sigma_1 = fwd.values.target\n        result = IndexedCoproduct(\n            sources = sources,\n            values  = Fun(sigma_1, both.coproduct(i).table))\n        return result\n\n    def map_operations(self, ops: Operations) -> AbstractDiagram:\n        \"\"\" Implements ``map_operations`` using ``map_fwd_operations`` and ``map_rev_operations``. \"\"\"\n        # TODO: add diagram from notes 2023-06-12\n        fwds, fwd_coarity = self.map_fwd_operations(ops)\n        revs, rev_arity   = self.map_rev_operations(ops)\n\n        Diagram = type(fwds)\n        Fun = fwds._Fun\n        xn = Fun.initial(fwds.G.xn.source) >> fwds.G.xn\n\n        # We need the sizes of each of these types in order to compute\n        # both the internal and external interleavings.\n        Afwd = self.map_fwd_objects(ops.s_type.values)\n        Arev = self.map_rev_objects(ops.s_type.values)\n        Bfwd = self.map_fwd_objects(ops.t_type.values)\n        Brev = self.map_rev_objects(ops.t_type.values)\n        Na = len(Afwd.sources) # number of source wires before functor\n        Nb = len(Bfwd.sources) # number of target wires before functor\n\n        # Get the residuals for each operation\n        M = self.residuals(ops)\n\n        # 'Internal' interleaving maps which bundle together all the Bfwd / M values\n        # so we can pass all the M's to \"revs\".\n        wn1 = Bfwd.values + M.values\n        fwd_output_sizes = Fun(None, fwd_coarity.table - M.sources.table) + M.sources\n        i1 = fwd_output_sizes.injections(Fun.cointerleave(len(ops.xn)))\n        i1 = Diagram.half_spider(i1, wn1, xn)\n\n        wn2 = M.values + Brev.values\n        rev_input_sizes = M.sources + Fun(None, rev_arity.table - M.sources.table)\n        i2 = rev_input_sizes.injections(Fun.cointerleave(len(ops.xn)))\n        i2 = Diagram.half_spider(i2, wn2, xn).dagger()\n\n        id_Bfwd = Diagram.identity(Bfwd.values, xn)\n        id_Brev = Diagram.identity(Brev.values, xn)\n        x = (fwds >> i1) @ id_Brev\n        y = id_Bfwd @ (i2 >> revs)\n        c = x >> y\n\n        # Bend wires to make an optic.\n        # Sources: fwd sources and rev targets\n        # Targets: fwd targets and rev sources\n        s = (Fun.inj0(len(Afwd.values), len(Brev.values)) >> c.s) + (Fun.inj1(len(Bfwd.values), len(Arev.values)) >> c.t)\n        t = (Fun.inj0(len(Bfwd.values), len(Arev.values)) >> c.t) + (Fun.inj1(len(Afwd.values), len(Brev.values)) >> c.s)\n        d = Diagram(s, t, c.G)\n\n        # Finally, interleave Afwd/Arev and Bfwd/Brev so optics can be tensored.\n        lhs = (Afwd.sources + Arev.sources).injections(Fun.cointerleave(Na))\n        rhs = (Bfwd.sources + Brev.sources).injections(Fun.cointerleave(Nb))\n\n        lhs = Diagram.half_spider(lhs, d.type[0], xn)\n        rhs = Diagram.half_spider(rhs, d.type[1], xn).dagger()\n        return lhs >> d >> rhs", "\ndef lens_fwd(ops: Operations, copy_label) -> AbstractDiagram:\n    \"\"\" :meta hide-value: \"\"\"\n    # Given a tensoring\n    #       f\u2080 \u25cf f\u2081 \u25cf ... \u25cf fn\n    # Return the diagram representing the forward part of a lens optic, i.e.,\n    #       \u0394 ; (f\u2080 \u25cf id)  \u25cf \u0394 ; (f\u2081 \u25cf id) ... \n    # This is given by \n    raise NotImplementedError(\"TODO\")\n\ndef adapt_optic(optic: AbstractDiagram, Afwd, Arev, Bfwd, Brev):\n    \"\"\" :meta hide-value: \"\"\"\n    raise NotImplementedError(\"TODO\")", "\ndef adapt_optic(optic: AbstractDiagram, Afwd, Arev, Bfwd, Brev):\n    \"\"\" :meta hide-value: \"\"\"\n    raise NotImplementedError(\"TODO\")\n"]}
{"filename": "yarrow/functor/functor.py", "chunked_list": ["\"\"\" Strict Symmetric Monoidal Hypergraph Functors of Diagrams.\n\nThis module consists of two classes.\n\n* :py:class:`Functor`\n* :py:class:`FrobeniusFunctor`\n\nThe former is the generic interface that all functors must implement.\nIf you wish to define a functor, it is strongly recommended to define\na class which inherits from :py:class:`FrobeniusFunctor`.", "If you wish to define a functor, it is strongly recommended to define\na class which inherits from :py:class:`FrobeniusFunctor`.\nThat way, instead of mapping arbitrary diagrams, you can define your functor in\nterms of mapping *generating operations*.\n\n\"\"\"\nfrom abc import abstractmethod\nfrom yarrow.finite_function import AbstractFiniteFunction, bincount\nfrom yarrow.diagram import AbstractDiagram\nfrom yarrow.segmented.finite_function import AbstractIndexedCoproduct", "from yarrow.diagram import AbstractDiagram\nfrom yarrow.segmented.finite_function import AbstractIndexedCoproduct\nfrom yarrow.segmented.operations import Operations\nfrom yarrow.decompose.frobenius import frobenius_decomposition\n\nclass Functor:\n    \"\"\" A base class for implementing strict symmetric monoidal hypergraph functors.\n\n    A Functor must implement two things:\n\n    * A mapping on *objects* :py:meth:`yarrow.functor.functor.Functor.map_objects`\n    * A mapping on *arrows* :py:meth:`yarrow.functor.functor.Functor.map_arrow`\n\n    The latter is hard to write from scratch!\n    Generally you will want to implement\n    :py:class:`yarrow.functor.functor.FrobeniusFunctor`.\n    Then you only have to implement a mapping on *generating operations*, and the\n    `map_arrow` function will be implemented for you.\n    \"\"\"\n    # In the paper we denote\n    # - map_objects as F\u2080\n    # - map_arrow   as F\u2081\n    @abstractmethod\n    def map_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        \"\"\" The object map ``F\u2080`` of a functor ``F : Diagram_\u03a3 \u2192 Diagram_\u03a9`` maps between\n        lists of generating objects `F\u2080 : \u03a3\u2080* \u2192 \u03a9\u2080*`.\n        Given an array of generating objects encoded as a FiniteFunction::\n\n            objects : W \u2192 \u03a3\u2080\n\n        This function must return an *indexed coproduct* representing the lists\n        to which each object was mapped::\n\n            sources : W            \u2192 Nat\n            values  : sum(sources) \u2192 \u03a9\u2080\n\n        (An \"indexed coproduct\" is basically a categorical name for a segmented array.)\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def map_arrow(self, d: AbstractDiagram) -> AbstractDiagram:\n        # \"\"\"The arrow map of a functor \"\"\"\n        \"\"\"F.map_arrow(d) should apply the functor F to diagram d.\"\"\"\n        ...", "\ndef apply_finite_object_map(\n        finite_object_map: AbstractIndexedCoproduct,\n        wn: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n    \"\"\"Given an AbstractIndexedCoproduct ``f`` representing a family of ``K`` functions::\n\n        f_i : N_i \u2192 \u03a9\u2080*, i \u2208 K\n\n    where ``f_i`` is the action of a functor ``F`` on generating object ``i``,\n    and an object ``wn = L(A)`` in the image of ``L``,\n    ``apply_finite_object_map(f, wn)`` computes the object ``F(wn)``\n    as a segmented array.\n    \"\"\"\n    assert isinstance(finite_object_map, AbstractIndexedCoproduct)\n    return type(finite_object_map)(\n        values  = finite_object_map.sources.injections(wn) >> finite_object_map.values,\n        sources = wn >> finite_object_map.sources)", "\ndef map_half_spider(swn: AbstractIndexedCoproduct, f: AbstractFiniteFunction) -> AbstractFiniteFunction:\n    \"\"\"Let ``swn = F.map_objects(f.type[1])`` for some functor ``F``,\n    and suppose ``S(f)`` is a half-spider.\n    Then ``S(map_half_spider(swn, f)) == F(S(f))``.\n    \"\"\"\n    # NOTE: swn should be the result of applying an object map to wn.\n    # swn = object_map(wn)\n    return swn.sources.injections(f)\n\ndef decomposition_to_operations(d: 'AbstractDiagram') -> Operations:\n    \"\"\" Get the array of operations (and their types) from a Frobenius\n    decomposition.  \"\"\"\n    # NOTE: it's *very* important that d is a frobenius decomposition, since we\n    # directly use the maps d.G.wi and d.G.wo in the result.\n    Fun = d._Fun\n    Array = Fun._Array\n\n    # A concrete Fun implementation knows what its IndexedCoproduct class is;\n    # see concrete modules yarrow.numpy and yarrow.cupy for details!\n    IndexedCoproduct = Fun.IndexedCoproduct\n\n    s_type = IndexedCoproduct(\n        sources = Fun(None, bincount(d.G.xi).table),\n        values  = d.G.wi >> d.G.wn)\n\n    t_type = IndexedCoproduct(\n        sources = Fun(None, bincount(d.G.xo).table),\n        values  = d.G.wo >> d.G.wn)\n\n    return Operations(d.G.xn, s_type, t_type)", "\ndef decomposition_to_operations(d: 'AbstractDiagram') -> Operations:\n    \"\"\" Get the array of operations (and their types) from a Frobenius\n    decomposition.  \"\"\"\n    # NOTE: it's *very* important that d is a frobenius decomposition, since we\n    # directly use the maps d.G.wi and d.G.wo in the result.\n    Fun = d._Fun\n    Array = Fun._Array\n\n    # A concrete Fun implementation knows what its IndexedCoproduct class is;\n    # see concrete modules yarrow.numpy and yarrow.cupy for details!\n    IndexedCoproduct = Fun.IndexedCoproduct\n\n    s_type = IndexedCoproduct(\n        sources = Fun(None, bincount(d.G.xi).table),\n        values  = d.G.wi >> d.G.wn)\n\n    t_type = IndexedCoproduct(\n        sources = Fun(None, bincount(d.G.xo).table),\n        values  = d.G.wo >> d.G.wn)\n\n    return Operations(d.G.xn, s_type, t_type)", "\nclass FrobeniusFunctor(Functor):\n    \"\"\" A functor defined in terms of Frobenius decompositions.\n    Instead of specifying `map_arrow`, the implementor can specify `map_operations`.\n    This should map a *tensoring* of generators to a :py:class:`AbstractDiagram`.\n    \"\"\"\n    @abstractmethod\n    def map_objects(self, objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n        ...\n\n    @abstractmethod\n    def map_operations(self, ops: Operations) -> AbstractDiagram:\n        \"\"\"Given an array of generating operations::\n\n            xn : X \u2192 \u03a3\u2081\n\n        and their types::\n\n            s_type : sum_{i \u2208 X} arity(xn(i))   \u2192 \u03a3\u2080\n            t_type : sum_{i \u2208 X} coarity(xn(i)) \u2192 \u03a3\u2080\n\n        You must return an :py:class:`yarrow.diagram.AbstractDiagram` representing the tensoring::\n\n            F\u2081(xn(0)) \u25cf F\u2081(xn(1)) ... F\u2081(xn(X - 1))\n        \"\"\"\n        ...\n\n    def map_arrow(self, d: AbstractDiagram) -> AbstractDiagram:\n        \"\"\" Apply a functor to a diagram. NOTE: You do not need to implement this method \"\"\"\n        Diagram = type(d)\n        d = frobenius_decomposition(d)\n        ops = decomposition_to_operations(d)\n\n        # swn = F(G(wn))\n        # ... is the IndexedCoproduct resulting from applying the functor to the\n        # wire labeling d.G.wn\n        swn = self.map_objects(d.G.wn)\n        h = self.map_operations(ops)\n\n        Fun   = h._Fun\n        Graph = h._Graph\n\n        xn = d._Fun.initial(h.G.xn.target, dtype=h.G.xn.table.dtype)\n\n        # build the morphisms (s ; x) ; (id \u25cf h) ; (y ; t) from Proposition B.1\n        i = Diagram.identity(swn.values, xn)\n        # note: we use the source/target maps of i in constructing those of sx, yt\n        # to avoid constructing another array with the same data.\n        sx = Diagram(map_half_spider(swn, d.s), i.t + map_half_spider(swn, d.G.wi), Graph.discrete(swn.values, xn))\n        yt = Diagram(i.s + map_half_spider(swn, d.G.wo), map_half_spider(swn, d.t), Graph.discrete(swn.values, xn))\n        return (sx >> (i @ h) >> yt)", "\n\n################################################################################\n# Built-in functors, supplied as examples.\n\ndef identity_object_map(objects: AbstractFiniteFunction) -> AbstractIndexedCoproduct:\n    \"\"\" The object map of the identity functor \"\"\"\n    Fun = type(objects)\n    Array = objects._Array\n\n    IndexedCoproduct = Fun.IndexedCoproduct\n\n    # TODO: write a test for this!\n    targets_codomain = None if objects.target is None else objects.target + 1\n    return IndexedCoproduct(\n        sources = Fun(None, Array.ones(len(objects))),\n        values  = objects)", "\nclass Identity(Functor):\n    \"\"\" The identity functor, whose ``map_arrow`` method is implemented by\n    actually just returning the same diagram \"\"\"\n    def map_objects(self, objects) -> AbstractIndexedCoproduct:\n        \"\"\" \"\"\"\n        return identity_object_map(objects)\n\n    def map_arrow(self, d: AbstractDiagram) -> AbstractDiagram:\n        \"\"\" \"\"\"\n        return d", "\nclass FrobeniusIdentity(FrobeniusFunctor):\n    \"\"\" The identity functor, implemented using Frobenius decompositions.\n    This is provided as a simple example of how to use the FrobeniusFunctor type:\n    instead of implementing ``map_arrow`` directly, one can instead write a mapping\n    on tensorings of operations.\n    This is typically much easier, since for a strict monoidal functor F we have\n    ``F(f\u2080 \u25cf f\u2081 \u25cf ... \u25cf fn) = F(f\u2080) \u25cf F(f\u2081) \u25cf ... \u25cf F(fn)``\n    \"\"\"\n    def map_objects(self, objects: AbstractFiniteFunction):\n        \"\"\" \"\"\"\n        return identity_object_map(objects)\n\n    def map_operations(self, ops: Operations) -> AbstractDiagram:\n        \"\"\" \"\"\"\n        # look up concrete Diagram type from the FiniteFunction\n        Diagram = type(ops.xn).Diagram\n        return Diagram.tensor_operations(ops)", ""]}
{"filename": "yarrow/functor/__init__.py", "chunked_list": ["\"\"\" (Strict Symmetric Monoidal Hypergraph) Functors of Diagrams, and diagrams of optics.\n\nThe \"functor\" module provides two things:\n\n* An API for defining functors of diagrams\n* An API for defining functors into *optics*.\n\n.. warning::\n   This API is not described in :cite:t:`dpafsd`.\n", "   This API is not described in :cite:t:`dpafsd`.\n\n.. autosummary::\n    :toctree: _autosummary\n    :recursive:\n\n    yarrow.functor.functor\n    yarrow.functor.optic\n\"\"\"\n", "\"\"\"\n"]}
{"filename": "yarrow/decompose/frobenius.py", "chunked_list": ["from yarrow.diagram import AbstractDiagram\n\ndef frobenius_decomposition(d: AbstractDiagram) -> AbstractDiagram:\n    \"\"\" Given a Diagram, permute its xi, xo, pi, and po maps to be in\n    (generator, port) order.\n    \"\"\"\n    # A Frobenius Decomposition is really just diagram whose edges are put in\n    # \"generator, port\" order.\n    # Obtaining the half spiders and tensorings from such a diagram is trivial:\n    # - s, t  are the source, targets of the diagram\n    # - everything else is just a component of the bipartite multigraph\n    p = sort_x_p(d.G.xi, d.G.pi)\n    q = sort_x_p(d.G.xo, d.G.po)\n\n    return type(d)(\n        s  = d.s,\n        t  = d.t,\n        G  = type(d.G)(\n            wi = p >> d.G.wi, # e_s\n            wo = q >> d.G.wo, # e_t\n            wn = d.G.wn,\n\n            xi = p >> d.G.xi,\n            xo = q >> d.G.xo,\n            pi = p >> d.G.pi,\n            po = q >> d.G.po,\n            xn = d.G.xn)\n    )", "\ndef sort_x_p(x, port):\n    # Sort by the compound key <x, port>.\n    # First argsorts port (\"p\")\n    # then stably argsorts by x\n    Array = x._Array\n    assert Array == port._Array\n    # x, port must be equal length arrays\n    assert x.source == port.source\n\n    p = Array.argsort(port.table)\n    table = Array.argsort(x.table[p])\n    return type(x)(x.source, table[p])", ""]}
{"filename": "yarrow/array/cupy.py", "chunked_list": ["\"\"\"A CuPy array backend.\n\n.. danger::\n   **Experimental Module**\n\n   This code is not thoroughly tested.\n   It's included here as a proof-of-concept for GPU acceleration.\n\"\"\"\nimport cupy as cp\nimport cupyx.scipy.sparse as sparse", "import cupy as cp\nimport cupyx.scipy.sparse as sparse\nfrom cupyx.scipy.sparse import csgraph\n\nDEFAULT_DTYPE='int64'\n\nType = cp.ndarray\n\ndef array(*args, **kwargs):\n    return cp.array(*args, **kwargs)", "def array(*args, **kwargs):\n    return cp.array(*args, **kwargs)\n\ndef max(*args, **kwargs):\n    return cp.max(*args, **kwargs)\n\ndef arange(*args, **kwargs):\n    return cp.arange(*args, **kwargs)\n\ndef all(*args, **kwargs):\n    return cp.all(*args, **kwargs)", "\ndef all(*args, **kwargs):\n    return cp.all(*args, **kwargs)\n\ndef zeros(*args, **kwargs):\n    return cp.zeros(*args, **kwargs)\n\ndef ones(*args, **kwargs):\n    return cp.ones(*args, **kwargs)\n\ndef cumsum(*args, **kwargs):\n    return cp.cumsum(*args, **kwargs)", "\ndef cumsum(*args, **kwargs):\n    return cp.cumsum(*args, **kwargs)\n\ndef sum(*args, **kwargs):\n    return cp.sum(*args, **kwargs)\n\ndef repeat(*args, **kwargs):\n    return cp.repeat(*args, **kwargs)\n\ndef concatenate(*args, **kwargs):\n    return cp.concatenate(*args, **kwargs)", "\ndef concatenate(*args, **kwargs):\n    return cp.concatenate(*args, **kwargs)\n\n# Compute the connected components of a graph.\n# connected components of a graph, encoded as a list of edges between points\n# so we have s, t arrays encoding edges (s[i], t[i]) of a square n\u00d7n matrix.\n# NOTE: we have to wrap libraries since we don't tend to get a consistent interface,\n# and don't want to expose e.g. sparse graphs in the main code.\ndef connected_components(source, target, n, dtype=DEFAULT_DTYPE):\n    \"\"\"Compute the connected components of a graph with ``N`` nodes,\n    whose edges are encoded as a pair of arrays ``(source, target)``\n    such that the edges of the graph are ``source[i] \u2192 target[i]``.\n\n    Args:\n        source(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n        target(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n\n    Returns:\n        (int, array):\n\n        A pair ``(c, cc_ix)`` of the number of connected components\n        ``c`` and a mapping from nodes to connected components ``cc_ix``.\n    \"\"\"\n    if len(source) != len(target):\n        raise ValueError(\"Expected a graph encoded as a pair of arrays (source, target) of the same length\")\n\n    assert len(source) == len(target)\n    # TODO: FIXME:\n    # Something seems broken with cupy's weakly connected components but I can't\n    # figure out what.\n    # The workaround is to make the graph symmetric and compute *strongly*\n    # connected components.\n    # This is obviously lame and needs to be fixed.\n\n    # make an n\u00d7n sparse matrix representing the graph with edges\n    # source[i] \u2192 target[i]\n    # NOTE: dtype of the values is float32 since integers aren't supported.\n    # This doesn't matter though, we actually don't care about this data.\n    ones = cp.ones(2*len(source), dtype='float32')\n\n    s = cp.concatenate([source, target])\n    t = cp.concatenate([target, source])\n    M = sparse.csr_matrix((ones, (s, t)), shape=(n, n))\n\n    # compute & return connected components\n    c, cc_ix = csgraph.connected_components(M, connection='strong')\n    return c, cc_ix", "# and don't want to expose e.g. sparse graphs in the main code.\ndef connected_components(source, target, n, dtype=DEFAULT_DTYPE):\n    \"\"\"Compute the connected components of a graph with ``N`` nodes,\n    whose edges are encoded as a pair of arrays ``(source, target)``\n    such that the edges of the graph are ``source[i] \u2192 target[i]``.\n\n    Args:\n        source(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n        target(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n\n    Returns:\n        (int, array):\n\n        A pair ``(c, cc_ix)`` of the number of connected components\n        ``c`` and a mapping from nodes to connected components ``cc_ix``.\n    \"\"\"\n    if len(source) != len(target):\n        raise ValueError(\"Expected a graph encoded as a pair of arrays (source, target) of the same length\")\n\n    assert len(source) == len(target)\n    # TODO: FIXME:\n    # Something seems broken with cupy's weakly connected components but I can't\n    # figure out what.\n    # The workaround is to make the graph symmetric and compute *strongly*\n    # connected components.\n    # This is obviously lame and needs to be fixed.\n\n    # make an n\u00d7n sparse matrix representing the graph with edges\n    # source[i] \u2192 target[i]\n    # NOTE: dtype of the values is float32 since integers aren't supported.\n    # This doesn't matter though, we actually don't care about this data.\n    ones = cp.ones(2*len(source), dtype='float32')\n\n    s = cp.concatenate([source, target])\n    t = cp.concatenate([target, source])\n    M = sparse.csr_matrix((ones, (s, t)), shape=(n, n))\n\n    # compute & return connected components\n    c, cc_ix = csgraph.connected_components(M, connection='strong')\n    return c, cc_ix", "\ndef argsort(x):\n    return cp.argsort(x, kind='stable')\n\n################################################################################\n# Non-primitive routines (i.e., vector routines built out of primitives)\n# TODO: implement an \"asbtract array library\" class, inherit faster impls for numpy etc.\n\n# e.g.,\n#   x       = [ 2 3 0 5 ]", "# e.g.,\n#   x       = [ 2 3 0 5 ]\n#   output  = [ 0 1 | 0 1 2 | | 0 1 2 3 4 ]\n# compute ptrs\n#   p       = [ 0 2 5 5 ]\n#   r       = [ 0 0 | 2 2 2 | | 5 5 5 5 5 ]\n#   i       = [ 0 1   2 3 4     5 6 7 8 9 ]\n#   i - r   = [ 0 1 | 0 1 2 | | 0 1 2 3 4 ]\n# Note: r is computed as repeat(p, n)\n#", "# Note: r is computed as repeat(p, n)\n#\n# Complexity\n#   O(n)     sequential\n#   O(log n) PRAM CREW (cumsum is log n)\ndef segmented_arange(x):\n    \"\"\"Given an array of *sizes*, ``[x\u2080, x\u2081, ...]``  output an array equal to the concatenation\n    ``concatenate([arange(x\u2080), arange(x\u2081), ...])``\n\n    >>> FiniteFunction._Array.segmented_arange([5, 2, 3, 1])\n    array([0, 1, 2, 3, 4, 0, 1, 0, 1, 2, 0])\n\n    Params:\n        x: An array of the sizes of each \"segment\" of the output\n\n    Returns:\n        array:\n\n        segmented array with segment ``i`` equal to ``arange(i)``.\n    \"\"\"\n    x = cp.array(x)\n\n    # create segment pointer array\n    ptr = cp.zeros(len(x) + 1, dtype=x.dtype) # O(1) PRAM\n    ptr[1:] = cp.cumsum(x)                    # O(log x) PRAM\n    N = ptr[-1] # total size\n\n    r = cp.repeat(ptr[:-1], x) # O(log x) PRAM\n    return cp.arange(0, N) - r # O(1)     PRAM", "\ndef bincount(x, *args, **kwargs):\n    return cp.bincount(x, *args, **kwargs)\n\ndef full(n, x, *args, **kwargs):\n    return cp.full(n, x, *args, **kwargs)\n"]}
{"filename": "yarrow/array/__init__.py", "chunked_list": ["\"\"\"Array backends for :ref:`yarrow.finite_function`.\n\nEach sub-module of :ref:`yarrow.array` is an \"array backend\".\nArray backends provide a small number of *primitive functions*\nlike :func:`yarrow.array.numpy.zeros` and :func:`yarrow.array.numpy.arange` .\nSee :ref:`yarrow.array.numpy` (the default backend) for a list.\n\n.. warning::\n   This part of the API is likely to change significantly in future releases.\n", "   This part of the API is likely to change significantly in future releases.\n\n.. autosummary::\n    :toctree: _autosummary\n    :recursive:\n\n    yarrow.array.numpy\n    yarrow.array.cupy\n\"\"\"\n", "\"\"\"\n"]}
{"filename": "yarrow/array/numpy.py", "chunked_list": ["\"\"\"numpy- and scipy-backed arrays and algorithms.\nAlmost all exposed functions are thin wrappers around numpy functions.\nThe only exceptions are:\n\n* :func:`connected_components` -- wraps `scipy.sparse.csgraph.connected_components`\n* :func:`segmented_arange` -- a subroutine implemented in terms of the other primitives\n\nThis module is the default array backend.\nIt's used by :py:class:`FiniteFunction`.\n\"\"\"", "It's used by :py:class:`FiniteFunction`.\n\"\"\"\nimport numpy as np\nimport scipy.sparse as sparse\n\nDEFAULT_DTYPE='int64'\n\nType = np.ndarray\n\"\"\" The underlying array type used by functions in the backend. For numpy this is ``np.ndarray``.\n", "\"\"\" The underlying array type used by functions in the backend. For numpy this is ``np.ndarray``.\n\n   :meta hide-value:\n\"\"\"\n# NOTE: we use :meta hide-value: above because numpy is mocked, so sphinx will\n# have the incorrect value in documentation.\n\ndef array(*args, **kwargs):\n    kwargs.setdefault('dtype', DEFAULT_DTYPE)\n    return np.fromiter(*args, **kwargs)", "\ndef max(*args, **kwargs):\n    return np.max(*args, **kwargs)\n\ndef arange(*args, **kwargs):\n    return np.arange(*args, **kwargs)\n\ndef all(*args, **kwargs):\n    return np.all(*args, **kwargs)\n\ndef zeros(*args, **kwargs):\n    kwargs.setdefault('dtype', DEFAULT_DTYPE)\n    return np.zeros(*args, **kwargs)", "\ndef zeros(*args, **kwargs):\n    kwargs.setdefault('dtype', DEFAULT_DTYPE)\n    return np.zeros(*args, **kwargs)\n\ndef ones(*args, **kwargs):\n    kwargs.setdefault('dtype', DEFAULT_DTYPE)\n    return np.ones(*args, **kwargs)\n\ndef cumsum(*args, **kwargs):\n    return np.cumsum(*args, **kwargs)", "\ndef cumsum(*args, **kwargs):\n    return np.cumsum(*args, **kwargs)\n\ndef sum(*args, **kwargs):\n    return np.sum(*args, **kwargs)\n\ndef repeat(*args, **kwargs):\n    return np.repeat(*args, **kwargs)\n\ndef concatenate(*args, **kwargs):\n    return np.concatenate(*args, **kwargs)", "\ndef concatenate(*args, **kwargs):\n    return np.concatenate(*args, **kwargs)\n\n# Compute the connected components of a graph.\n# connected components of a graph, encoded as a list of edges between points\n# so we have s, t arrays encoding edges (s[i], t[i]) of a square n\u00d7n matrix.\n# NOTE: we have to wrap libraries since we don't tend to get a consistent interface,\n# and don't want to expose e.g. sparse graphs in the main code.\ndef connected_components(source, target, n, dtype=DEFAULT_DTYPE):\n    \"\"\"Compute the connected components of a graph with ``N`` nodes,\n    whose edges are encoded as a pair of arrays ``(source, target)``\n    such that the edges of the graph are ``source[i] \u2192 target[i]``.\n\n    Args:\n        source(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n        target(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n\n    Returns:\n        (int, array):\n\n        A pair ``(c, cc_ix)`` of the number of connected components\n        ``c`` and a mapping from nodes to connected components ``cc_ix``.\n    \"\"\"\n    if len(source) != len(target):\n        raise ValueError(\"Expected a graph encoded as a pair of arrays (source, target) of the same length\")\n\n    assert len(source) == len(target)\n\n    # make an n\u00d7n sparse matrix representing the graph with edges\n    # source[i] \u2192 target[i]\n    ones = np.ones(len(source), dtype=DEFAULT_DTYPE)\n    M = sparse.csr_matrix((ones, (source, target)), shape=(n, n))\n\n    # compute & return connected components\n    c, cc_ix = sparse.csgraph.connected_components(M)\n    return c, cc_ix", "# and don't want to expose e.g. sparse graphs in the main code.\ndef connected_components(source, target, n, dtype=DEFAULT_DTYPE):\n    \"\"\"Compute the connected components of a graph with ``N`` nodes,\n    whose edges are encoded as a pair of arrays ``(source, target)``\n    such that the edges of the graph are ``source[i] \u2192 target[i]``.\n\n    Args:\n        source(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n        target(array): A length-N array with elements in the set ``{0 .. N - 1}``.\n\n    Returns:\n        (int, array):\n\n        A pair ``(c, cc_ix)`` of the number of connected components\n        ``c`` and a mapping from nodes to connected components ``cc_ix``.\n    \"\"\"\n    if len(source) != len(target):\n        raise ValueError(\"Expected a graph encoded as a pair of arrays (source, target) of the same length\")\n\n    assert len(source) == len(target)\n\n    # make an n\u00d7n sparse matrix representing the graph with edges\n    # source[i] \u2192 target[i]\n    ones = np.ones(len(source), dtype=DEFAULT_DTYPE)\n    M = sparse.csr_matrix((ones, (source, target)), shape=(n, n))\n\n    # compute & return connected components\n    c, cc_ix = sparse.csgraph.connected_components(M)\n    return c, cc_ix", "\ndef argsort(x):\n    return np.argsort(x, kind='stable')\n\n################################################################################\n# Non-primitive routines (i.e., vector routines built out of primitives)\n# TODO: implement an \"asbtract array library\" class, inherit faster impls for numpy etc.\n\n# e.g.,\n#   x       = [ 2 3 0 5 ]", "# e.g.,\n#   x       = [ 2 3 0 5 ]\n#   output  = [ 0 1 | 0 1 2 | | 0 1 2 3 4 ]\n# compute ptrs\n#   p       = [ 0 2 5 5 ]\n#   r       = [ 0 0 | 2 2 2 | | 5 5 5 5 5 ]\n#   i       = [ 0 1   2 3 4     5 6 7 8 9 ]\n#   i - r   = [ 0 1 | 0 1 2 | | 0 1 2 3 4 ]\n# Note: r is computed as repeat(p, n)\n#", "# Note: r is computed as repeat(p, n)\n#\n# Complexity\n#   O(n)     sequential\n#   O(log n) PRAM CREW (cumsum is log n)\ndef segmented_arange(x):\n    \"\"\"Given an array of *sizes*, ``[x\u2080, x\u2081, ...]``  output an array equal to the concatenation\n    ``concatenate([arange(x\u2080), arange(x\u2081), ...])``\n\n    >>> FiniteFunction._Array.segmented_arange([5, 2, 3, 1])\n    array([0, 1, 2, 3, 4, 0, 1, 0, 1, 2, 0])\n\n    Params:\n        x: An array of the sizes of each \"segment\" of the output\n\n    Returns:\n        array:\n\n        segmented array with segment ``i`` equal to ``arange(i)``.\n    \"\"\"\n    x = np.array(x, dtype=DEFAULT_DTYPE)\n\n    # create segment pointer array\n    ptr = np.zeros(len(x) + 1, dtype=x.dtype) # O(1) PRAM\n    ptr[1:] = np.cumsum(x)                    # O(log x) PRAM\n    N = ptr[-1] # total size\n\n    r = np.repeat(ptr[:-1], x) # O(log x) PRAM\n    return np.arange(0, N) - r # O(1)     PRAM", "\ndef bincount(x, *args, **kwargs):\n    return np.bincount(x, *args, **kwargs)\n\ndef full(n, x, *args, **kwargs):\n    kwargs.setdefault('dtype', DEFAULT_DTYPE)\n    return np.full(n, x, *args, **kwargs)\n"]}
{"filename": "yarrow/segmented/finite_function.py", "chunked_list": ["\"\"\" Finite coproducts for Finite Functions.\nThey're used to parallelize several operations like the\n:py:meth:`yarrow.functor.functor.Functor.map_objects` method.\n\"\"\"\nfrom yarrow.finite_function import *\nfrom dataclasses import dataclass\nimport yarrow.array.numpy as numpy\n\n@dataclass\nclass AbstractIndexedCoproduct:\n    \"\"\" A finite coproduct of finite functions.\n    You can think of it simply as a segmented array.\n    Categorically, it represents a finite coproduct::\n\n        \u03a3_{i \u2208 N} f_i : s(f_i) \u2192 Y\n\n    as a pair of maps::\n\n        sources: N            \u2192 Nat     (target is natural numbers)\n        values : sum(sources) \u2192 \u03a3\u2080\n    \"\"\"\n    # sources: an array of segment sizes (note: not ptrs)\n    sources: AbstractFiniteFunction\n\n    # values: the values of the coproduct\n    values: AbstractFiniteFunction\n\n    def __post_init__(self):\n        # TODO FIXME: make this type derivable from AbstractFiniteFunction so we\n        # don't need to have one version for each backend?\n        self._Fun = type(self.sources)\n        self._Array = self._Fun._Array\n\n        # we always ignore the target of sources; this ensures\n        # roundtrippability.\n        assert self.sources.target is None\n        assert type(self.values) == self._Fun\n        assert len(self.values) == self._Array.sum(self.sources.table)\n\n    @property\n    def target(self):\n        return self.values.target\n\n    def __len__(self):\n        \"\"\" return the number of finite functions in the coproduct \"\"\"\n        return len(self.sources)\n\n    @classmethod\n    def from_list(cls, target, fs: List['AbstractFiniteFunction']):\n        \"\"\" Create an `AbstractIndexedCoproduct` from a list of :py:class:`AbstractFiniteFunction` \"\"\"\n        assert all(target == f.target for f in fs)\n        return cls(\n            sources=cls._Fun(None, [len(f) for f in fs], dtype=int),\n            values=cls._Fun.coproduct_list(fs, target=target))\n\n    def __iter__(self):\n        \"\"\" Yield an iterator of the constituent finite functions\n\n        >>> list(AbstractIndexedCoproduct.from_list(fs)) == fs\n        True\n        \"\"\"\n        N     = len(self.sources)\n\n        # Compute source pointers\n        s_ptr = self._Array.zeros(N+1, dtype=self.sources.table.dtype)\n        s_ptr[1:] = self._Array.cumsum(self.sources.table)\n\n        for i in range(0, N):\n            yield self._Fun(self.target, self.values.table[s_ptr[i]:s_ptr[i+1]])\n\n    def map(self, x: AbstractFiniteFunction):\n        \"\"\" Given an :py:class:`AbstractIndexedCoproduct` of finite functions::\n\n            \u03a3_{i \u2208 X} f_i : \u03a3_{i \u2208 X} A_i \u2192 B\n\n        and a finite function::\n\n            x : W \u2192 X\n\n        return a new :py:class:`AbstractIndexedCoproduct` representing::\n\n            \u03a3_{i \u2208 X} f_{x(i)} : \u03a3_{i \u2208 W} A_{x(i)} \u2192 B\n        \"\"\"\n        return type(self)(\n            sources = x >> self.sources,\n            values = self.coproduct(x))\n\n    def coproduct(self, x: AbstractFiniteFunction) -> AbstractFiniteFunction:\n        \"\"\"Like ``map`` but only computes the ``values`` array of an AbstractIndexedCoproduct\"\"\"\n        assert x.target == len(self.sources)\n        return self.sources.injections(x) >> self.values", "@dataclass\nclass AbstractIndexedCoproduct:\n    \"\"\" A finite coproduct of finite functions.\n    You can think of it simply as a segmented array.\n    Categorically, it represents a finite coproduct::\n\n        \u03a3_{i \u2208 N} f_i : s(f_i) \u2192 Y\n\n    as a pair of maps::\n\n        sources: N            \u2192 Nat     (target is natural numbers)\n        values : sum(sources) \u2192 \u03a3\u2080\n    \"\"\"\n    # sources: an array of segment sizes (note: not ptrs)\n    sources: AbstractFiniteFunction\n\n    # values: the values of the coproduct\n    values: AbstractFiniteFunction\n\n    def __post_init__(self):\n        # TODO FIXME: make this type derivable from AbstractFiniteFunction so we\n        # don't need to have one version for each backend?\n        self._Fun = type(self.sources)\n        self._Array = self._Fun._Array\n\n        # we always ignore the target of sources; this ensures\n        # roundtrippability.\n        assert self.sources.target is None\n        assert type(self.values) == self._Fun\n        assert len(self.values) == self._Array.sum(self.sources.table)\n\n    @property\n    def target(self):\n        return self.values.target\n\n    def __len__(self):\n        \"\"\" return the number of finite functions in the coproduct \"\"\"\n        return len(self.sources)\n\n    @classmethod\n    def from_list(cls, target, fs: List['AbstractFiniteFunction']):\n        \"\"\" Create an `AbstractIndexedCoproduct` from a list of :py:class:`AbstractFiniteFunction` \"\"\"\n        assert all(target == f.target for f in fs)\n        return cls(\n            sources=cls._Fun(None, [len(f) for f in fs], dtype=int),\n            values=cls._Fun.coproduct_list(fs, target=target))\n\n    def __iter__(self):\n        \"\"\" Yield an iterator of the constituent finite functions\n\n        >>> list(AbstractIndexedCoproduct.from_list(fs)) == fs\n        True\n        \"\"\"\n        N     = len(self.sources)\n\n        # Compute source pointers\n        s_ptr = self._Array.zeros(N+1, dtype=self.sources.table.dtype)\n        s_ptr[1:] = self._Array.cumsum(self.sources.table)\n\n        for i in range(0, N):\n            yield self._Fun(self.target, self.values.table[s_ptr[i]:s_ptr[i+1]])\n\n    def map(self, x: AbstractFiniteFunction):\n        \"\"\" Given an :py:class:`AbstractIndexedCoproduct` of finite functions::\n\n            \u03a3_{i \u2208 X} f_i : \u03a3_{i \u2208 X} A_i \u2192 B\n\n        and a finite function::\n\n            x : W \u2192 X\n\n        return a new :py:class:`AbstractIndexedCoproduct` representing::\n\n            \u03a3_{i \u2208 X} f_{x(i)} : \u03a3_{i \u2208 W} A_{x(i)} \u2192 B\n        \"\"\"\n        return type(self)(\n            sources = x >> self.sources,\n            values = self.coproduct(x))\n\n    def coproduct(self, x: AbstractFiniteFunction) -> AbstractFiniteFunction:\n        \"\"\"Like ``map`` but only computes the ``values`` array of an AbstractIndexedCoproduct\"\"\"\n        assert x.target == len(self.sources)\n        return self.sources.injections(x) >> self.values", "\n\n\n@dataclass\nclass AbstractSegmentedFiniteFunction:\n    \"\"\" An AbstractSegmentedFiniteFunction encodes a *tensoring* of finite functions.\n    This means we have to include an array of *targets* as well.\n\n    ..warning::\n        Deprecated\n    \"\"\"\n    # sizes of each of the N segments\n    # sources : N \u2192 Nat\n    sources: AbstractFiniteFunction\n\n    # Targets of each finite function.\n    # This is required if we want to tensor\n    # targets : N \u2192 Nat\n    targets: AbstractFiniteFunction\n\n    # values of all segments, flattened\n    # value : \u03a3_{i \u2208 N} size(i) \u2192 Nat\n    values: AbstractFiniteFunction\n\n    def __post_init__(self):\n        cls = type(self)\n        assert self.sources._Array == cls._Array\n        assert self.targets._Array == cls._Array\n        assert self.values._Array == cls._Array\n\n        # Check that values : \u03a3_{i \u2208 N} n(i)\n        assert self._Array.sum(self.sources.table) == len(self.values)\n\n        # lengths of sources and targets arrays are the same\n        assert len(self.sources) == len(self.targets)\n\n        if len(self.targets) == 0:\n            self._is_coproduct = True\n        else:\n            self._is_coproduct = \\\n                    self._Array.all(self.targets.table[:-1] == self.targets.table[1:])\n\n    # return the number of segments\n    def __len__(self):\n        return len(self.sources)\n\n    @classmethod\n    def from_list(cls, fs: List['AbstractFiniteFunction']):\n        \"\"\" Create a SegmentedFiniteFunction from a list of morphisms \"\"\"\n        # TODO: tidy up. do 1 iteration instead of 3\n        sources = cls._Array.array([ f.source for f in fs ])\n        targets = cls._Array.array([ f.target for f in fs ])\n\n        if len(fs) == 0:\n            max_source = 0\n            max_target = 0\n            values = cls._Array.zeros(0)\n        else:\n            max_source = cls._Array.max(sources) + 1\n            max_target = cls._Array.max(targets) + 1\n            values  = cls._Array.concatenate([ f.table for f in fs])\n\n        return cls(\n            sources = cls._Fun(max_source, sources),\n            targets = cls._Fun(max_target, targets),\n            values  = cls._Fun(None, values))\n\n    def __iter__(self):\n        Fun   = type(self.sources)\n        Array = Fun._Array\n        N     = len(self.sources)\n\n        s_ptr = Array.zeros(N+1, dtype=self.sources.table.dtype)\n        s_ptr[1:] = Array.cumsum(self.sources.table)\n\n        for i in range(0, N):\n            yield Fun(self.targets(i), self.values.table[s_ptr[i]:s_ptr[i+1]])\n\n    @property\n    def N(self):\n        # number of segments in the array\n        return self.sources.source\n\n    def slice(self, x: AbstractFiniteFunction):\n        # check indexing function won't go out of bounds\n        assert x.target == self.N\n        return self.sources.injections(x) >> self.values\n\n    # Since values is the concatenation of\n    # finite functions F_i : size(i) \u2192 Nat,\n    # i.e.,\n    #   values = F_0 + F_1 + ... + F_{N-1}\n    # we have\n    #   \u03b9_x ; value = F_i\n    def coproduct(self, x: AbstractFiniteFunction):\n        \"\"\" sff.coproduct(x) computes an x-indexed coproduct of sff \"\"\"\n        # check all targets are the same\n        assert self._is_coproduct\n\n        # TODO FIXME: this is a hack, and is totally broken for \"empty\" coproducts, which MUST have target specified!\n        target = 0 if self.targets.source == 0 else self.targets(0)\n        return type(x)(target, self.slice(x).table)\n\n    def tensor(self, x: AbstractFiniteFunction):\n        \"\"\" sff.coproduct(x) computes an x-indexed *tensor* product of sff \"\"\"\n        table = self.slice(x).table\n        p = self._Array.zeros(x.source + 1, dtype='int64')\n        # p[1:] = self._Array.cumsum(self.targets.table[x.table])\n        p[1:] = self._Array.cumsum(self.targets.table[x.table])\n        z = self._Array.repeat(p[:-1], self.sources.table[x.table])\n        return type(x)(p[-1], table + z)", ""]}
{"filename": "yarrow/segmented/operations.py", "chunked_list": ["from dataclasses import dataclass\nfrom yarrow.finite_function import AbstractFiniteFunction\nfrom yarrow.segmented.finite_function import AbstractIndexedCoproduct\n\ndef _is_valid(ops: 'Operations'):\n    \"\"\" Check if a tensoring of operations has correct types \"\"\"\n    N = ops.xn.source\n    return len(ops.s_type) == N and \\\n           len(ops.t_type) == N\n", "\n@dataclass\nclass Operations:\n    \"\"\" A flat array representation of a sequence of (typed) operations.\n    Since polymorphic operations have variable types, in order to get a\n    completely flat representation, we need to store them in *segmented arrays*.\n    The Operations type is therefore a 3-tuple:\n\n    Operation labels::\n\n      xn         : N            \u2192 \u03a3\u2081\n\n    Source types (encoded as an :py:class:`AbstractIndexedCoproduct`)::\n\n      s_type\n          sources: N            \u2192 None\n          values : sum(sources) \u2192 \u03a3\u2080\n\n    Target types (encoded as an :py:class:`AbstractIndexedCoproduct`)::\n\n      t_type\n          sources: N            \u2192 None\n          values : sum(sources) \u2192 \u03a3\u2080\n    \"\"\"\n    xn: AbstractFiniteFunction\n    s_type: AbstractIndexedCoproduct\n    t_type: AbstractIndexedCoproduct\n\n    def __post_init__(self):\n        assert _is_valid(self)\n        # check types of finite functions, segmented finite functions are equal\n        assert self.s_type._Fun == type(self.xn)\n        assert type(self.s_type) == type(self.t_type)\n\n    # return the number of operations\n    def __len__(self):\n        return len(self.xn)\n\n    def __iter__(self):\n        yield from zip(self.xn.table, self.s_type, self.t_type, strict=True)", ""]}
{"filename": "yarrow/segmented/__init__.py", "chunked_list": ["\"\"\" Segmented arrays with a categorical flavour\n\n.. warning::\n   This API has diverged from its description in :cite:t:`dpafsd`.\n\n.. autosummary::\n    :toctree: _autosummary\n    :recursive:\n\n    yarrow.segmented.finite_function", "\n    yarrow.segmented.finite_function\n    yarrow.segmented.operations\n\"\"\"\n"]}
{"filename": "docs/source/conf.py", "chunked_list": ["# Configuration file for the Sphinx documentation builder.\n#\n# For the full list of built-in configuration values, see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Setup -----------------------------------------------------\n# Ensure the yarrow module is in the path so autosummary can load it.\nimport sys\nfrom pathlib import Path\nroot = Path(__file__).parent.parent.parent", "from pathlib import Path\nroot = Path(__file__).parent.parent.parent\nsys.path.insert(0, str(root))\n\n# Mock numpy, scipy, and cupy so sphinx can build docs without installing them\n# as dependencies.\n# See https://blog.rtwilson.com/how-to-make-your-sphinx-documentation-compile-with-readthedocs-when-youre-using-numpy-and-scipy/\nfrom unittest import mock\nMOCK_MODULES = ['numpy', 'scipy', 'scipy.sparse', 'cupy', 'cupyx', 'cupyx.scipy', 'cupyx.scipy.sparse']\nfor mod_name in MOCK_MODULES:\n    sys.modules[mod_name] = mock.MagicMock()", "MOCK_MODULES = ['numpy', 'scipy', 'scipy.sparse', 'cupy', 'cupyx', 'cupyx.scipy', 'cupyx.scipy.sparse']\nfor mod_name in MOCK_MODULES:\n    sys.modules[mod_name] = mock.MagicMock()\n\n# -- Project information -----------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n# Project name etc.\nproject = 'yarrow'\ncopyright = '2023, Paul Wilson'\nauthor = 'Paul Wilson'", "copyright = '2023, Paul Wilson'\nauthor = 'Paul Wilson'\n\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\nextensions = [\n    \"sphinx_rtd_theme\", # readthedocs theme\n    \"sphinx.ext.duration\",\n    \"sphinx.ext.doctest\",", "    \"sphinx.ext.duration\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosummary\",\n    \"sphinxcontrib.bibtex\",\n    \"sphinx.ext.napoleon\",\n]\n\n# Include both __init__ docstrings and class docstrings\n# autoclass_content = \"both\" # the non-napoleon version of this option", "# Include both __init__ docstrings and class docstrings\n# autoclass_content = \"both\" # the non-napoleon version of this option\nnapoleon_include_init_with_doc = True\n\n# Number figures\nnumfig = True\n\n# class members should be in the order they are written in the file\nautodoc_member_order = \"bysource\"\n", "autodoc_member_order = \"bysource\"\n\n# references\nbibtex_bibfiles = [\"refs.bib\"]\n\n# let autosummary recurse and generate all modules specified\n# https://stackoverflow.com/questions/2701998/\nautosummary_generate = True\n\ntemplates_path = ['_templates']", "\ntemplates_path = ['_templates']\nexclude_patterns = []\n\n\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n\n# html_theme = 'alabaster'\nhtml_theme = 'sphinx_rtd_theme'", "# html_theme = 'alabaster'\nhtml_theme = 'sphinx_rtd_theme'\nhtml_static_path = []\n# html_static_path = ['_static']\n"]}
