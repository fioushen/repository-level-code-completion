{"filename": "main.py", "chunked_list": ["from Solver import MCMCSolver\nfrom sampler import EnergyBasedLangevinDynamicSampler\nfrom data import get_CIFAR10_train, get_CIFAR10_test\nfrom models import UnconditionalResNet32\nimport torch\nfrom torchvision import transforms\n\nto_img = transforms.ToPILImage()\n\nloader = get_CIFAR10_train(batch_size=256)", "\nloader = get_CIFAR10_train(batch_size=256)\nmodel = UnconditionalResNet32().cuda().eval()\n# model.load_state_dict(torch.load('model.pth'))\n\nsampler = EnergyBasedLangevinDynamicSampler(model)\nsolver = MCMCSolver(model, sampler)\nsolver.train(loader)\n\n", "\n\nmodel.eval()\n\n\n#\nx, _ = next(iter(loader))\nx = x[:1].cuda()\nprint(model(x.cuda()).sum())\nx = sampler.sample(x, step=600)", "print(model(x.cuda()).sum())\nx = sampler.sample(x, step=600)\nprint(model(x.cuda()).sum(), x.shape)\n\n#\nx = torch.rand(1, 3, 32, 32).cuda()\nprint(model(x.cuda()).sum())\nx = sampler.sample(x, step=600)\nprint(model(x.cuda()).sum(), x.shape)\nx = to_img(x[0].squeeze())", "print(model(x.cuda()).sum(), x.shape)\nx = to_img(x[0].squeeze())\nx.save('test.png')\n"]}
{"filename": "Solver/MCMCSolver.py", "chunked_list": ["import torch\nfrom torch import nn, Tensor\nfrom torch.utils.data import DataLoader\nfrom typing import Callable\nfrom tqdm import tqdm\nimport random\n\n\nclass MCMCSolver():\n    def __init__(self,\n                 model: nn.Module,\n                 sampler: Callable):\n        self.device = torch.device('cuda')\n        self.model = model.to(self.device)\n        self.sampler = sampler\n\n    def train(self,\n              loader: DataLoader,\n              total_epoch=2000,\n              lr=1e-4,\n              uncondition_prob=1,\n              buffer_size=10000,\n              ):\n        self.buffer = torch.rand(64, *self.sampler.img_size, device=self.device)\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n        for epoch in range(1, total_epoch + 1):\n            pbar = tqdm(loader)\n            epoch_loss = 0\n            for step, (x, y) in enumerate(pbar, 1):\n                x, y = x.cuda(), y.cuda()\n                # small trick\n                x = x + torch.randn_like(x) * 0.0025\n                #\n                selected = torch.randint(low=0, high=self.buffer.shape[0] - 1,\n                                         size=(round(x.shape[0] * 0.95),))\n                unselected = set(list(range(self.buffer.shape[0]))) - set(selected.numpy().tolist())\n                unselected = torch.tensor(list(unselected), device=self.device)\n                negative_buffer = self.buffer[selected]\n                rand_buffer = self.initial_distribution_sample(round(x.shape[0] * 0.05))\n                self.buffer = self.buffer[unselected]\n                negative = torch.cat([negative_buffer, rand_buffer], dim=0)\n                self.model.eval().requires_grad_(False)\n                negative = self.sampler(negative)\n                self.buffer = torch.cat([self.buffer, negative], dim=0)\n                self.model.train().requires_grad_(True)\n                # self.model.eval()\n                input = torch.cat([x, negative], dim=0)\n                output = self.model(input)\n                positive, negative = output[:x.shape[0]], output[x.shape[0]:]\n                # positive = self.model(x)\n                # negative = self.model(negative)\n                # print(torch.mean(positive), torch.mean(negative), negative[-1])\n                if random.random() < uncondition_prob:  # uncondition\n                    regulation_term = torch.mean(positive ** 2) + torch.mean(negative ** 2)\n                    loss = torch.mean(negative - positive)\n                    epoch_loss += loss.item()\n                    loss = loss + regulation_term\n                else:\n                    pass  # condition\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                if step % 10 == 0:\n                    pbar.set_postfix_str(f'step {step}, loss {epoch_loss / step}')\n            torch.save(self.model.state_dict(), 'model.pth')\n            if self.buffer.shape[0] > buffer_size:\n                self.buffer = self.buffer[torch.randperm(self.buffer.shape[0])]\n                self.buffer = self.buffer[:buffer_size]\n\n    def initial_distribution_sample(self, batch_size):\n        # x0 = torch.randn(batch_size, *self.img_size, device=self.device)\n        # x0 = x0 * torch.tensor([0.2470, 0.2435, 0.2616], device=self.device).view(1, 3, 1, 1) + \\\n        #      torch.tensor([0.4914, 0.4822, 0.4465], device=self.device).view(1, 3, 1, 1)\n        x0 = torch.rand(batch_size, *self.sampler.img_size, device=self.device)\n        return x0", "class MCMCSolver():\n    def __init__(self,\n                 model: nn.Module,\n                 sampler: Callable):\n        self.device = torch.device('cuda')\n        self.model = model.to(self.device)\n        self.sampler = sampler\n\n    def train(self,\n              loader: DataLoader,\n              total_epoch=2000,\n              lr=1e-4,\n              uncondition_prob=1,\n              buffer_size=10000,\n              ):\n        self.buffer = torch.rand(64, *self.sampler.img_size, device=self.device)\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n        for epoch in range(1, total_epoch + 1):\n            pbar = tqdm(loader)\n            epoch_loss = 0\n            for step, (x, y) in enumerate(pbar, 1):\n                x, y = x.cuda(), y.cuda()\n                # small trick\n                x = x + torch.randn_like(x) * 0.0025\n                #\n                selected = torch.randint(low=0, high=self.buffer.shape[0] - 1,\n                                         size=(round(x.shape[0] * 0.95),))\n                unselected = set(list(range(self.buffer.shape[0]))) - set(selected.numpy().tolist())\n                unselected = torch.tensor(list(unselected), device=self.device)\n                negative_buffer = self.buffer[selected]\n                rand_buffer = self.initial_distribution_sample(round(x.shape[0] * 0.05))\n                self.buffer = self.buffer[unselected]\n                negative = torch.cat([negative_buffer, rand_buffer], dim=0)\n                self.model.eval().requires_grad_(False)\n                negative = self.sampler(negative)\n                self.buffer = torch.cat([self.buffer, negative], dim=0)\n                self.model.train().requires_grad_(True)\n                # self.model.eval()\n                input = torch.cat([x, negative], dim=0)\n                output = self.model(input)\n                positive, negative = output[:x.shape[0]], output[x.shape[0]:]\n                # positive = self.model(x)\n                # negative = self.model(negative)\n                # print(torch.mean(positive), torch.mean(negative), negative[-1])\n                if random.random() < uncondition_prob:  # uncondition\n                    regulation_term = torch.mean(positive ** 2) + torch.mean(negative ** 2)\n                    loss = torch.mean(negative - positive)\n                    epoch_loss += loss.item()\n                    loss = loss + regulation_term\n                else:\n                    pass  # condition\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                if step % 10 == 0:\n                    pbar.set_postfix_str(f'step {step}, loss {epoch_loss / step}')\n            torch.save(self.model.state_dict(), 'model.pth')\n            if self.buffer.shape[0] > buffer_size:\n                self.buffer = self.buffer[torch.randperm(self.buffer.shape[0])]\n                self.buffer = self.buffer[:buffer_size]\n\n    def initial_distribution_sample(self, batch_size):\n        # x0 = torch.randn(batch_size, *self.img_size, device=self.device)\n        # x0 = x0 * torch.tensor([0.2470, 0.2435, 0.2616], device=self.device).view(1, 3, 1, 1) + \\\n        #      torch.tensor([0.4914, 0.4822, 0.4465], device=self.device).view(1, 3, 1, 1)\n        x0 = torch.rand(batch_size, *self.sampler.img_size, device=self.device)\n        return x0", ""]}
{"filename": "Solver/__init__.py", "chunked_list": ["from .MCMCSolver import MCMCSolver"]}
{"filename": "sampler/LangevinDynamic.py", "chunked_list": ["import torch\nfrom torch import nn\nfrom torch import Tensor\nimport math\n\n\nclass EnergyBasedLangevinDynamicSampler():\n    def __init__(self, model: nn.Module, img_size=(3, 32, 32)):\n        self.model = model\n        self.img_size = img_size\n        self.device = torch.device('cuda')\n\n    @torch.enable_grad()\n    def get_grad(self, x: Tensor) -> Tensor:\n        x.requires_grad = True\n        x.grad = None\n        target = self.model(x)\n        target = target.sum()\n        # print(target)\n        target.backward()\n        grad = x.grad.clone()\n        x.grad = None\n        x.requires_grad = False\n        return grad\n\n    @torch.no_grad()\n    def sample(self, x: Tensor, step=60, lam=0.0025, step_size=10):\n        for t in range(1, step + 1):\n            grad = self.get_grad(x)\n            grad = self.clamp(grad, min=-0.03, max=0.03)\n            # x = x + step_size * grad + torch.randn_like(x) * lam\n            x = x + 10 * grad + torch.randn_like(x) * lam\n            # x = x - 1 / 255 * grad.sign() + 1e-4 * torch.randn_like(x)\n            # print(grad)\n            # print(torch.mean(torch.randn_like(x) * math.sqrt(lam)), torch.mean(lam / 2 * grad))\n            x = self.clamp(x)\n        return x.detach()\n\n    def __call__(self, *args, **kwargs):\n        return self.sample(*args, **kwargs)\n\n    @staticmethod\n    def clamp(x: Tensor, min=0., max=1.) -> Tensor:\n        x = torch.clamp(x, min=min, max=max)\n        return x", ""]}
{"filename": "sampler/__init__.py", "chunked_list": ["from .LangevinDynamic import EnergyBasedLangevinDynamicSampler"]}
{"filename": "data/someset.py", "chunked_list": ["'''\nthis file aims to read any dataset satisfied that:\n    1.all the images are in one folder\n    2.only a dict to store ground truth. Keys are image names, values are ground truth labels.\n'''\n\nimport os\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms", "from torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\n\n\nclass SomeDataSet(Dataset):\n    def __init__(self, img_path, gt_path):\n        self.transform = transforms.Compose([\n            # transforms.RandomResizedCrop(size=(224, 224), scale=(0.7, 1)),\n            # transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n        ])\n        self.images = [img for img in os.listdir(img_path) if img.endswith('.jpg')]\n        self.gt = np.load(gt_path, allow_pickle=True).item()\n        self.img_path = img_path\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, item):\n        now = self.images[item]\n        now_img = Image.open(os.path.join(self.img_path, now))  # numpy\n        return self.transform(now_img), self.gt[now]", "\n\ndef get_someset_loader(img_path,\n                       gt_path,\n                       batch_size=128,\n                       num_workers=8,\n                       pin_memory=False, ):\n    set = SomeDataSet(img_path=img_path, gt_path=gt_path)\n    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=pin_memory)\n    return loader", ""]}
{"filename": "data/__init__.py", "chunked_list": ["from .cifar import get_CIFAR100_test, get_CIFAR100_train, get_CIFAR10_train, get_CIFAR10_test\nfrom .someset import SomeDataSet, get_someset_loader"]}
{"filename": "data/cifar.py", "chunked_list": ["import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport os.path\nimport pickle\nfrom typing import Any, Callable, Optional, Tuple\n\nimport numpy as np\nfrom PIL import Image\n", "from PIL import Image\n\nfrom torchvision.datasets.utils import check_integrity, download_and_extract_archive\nfrom torchvision.datasets.vision import VisionDataset\n\n\nclass CIFAR10(VisionDataset):\n    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n\n    Args:\n        root (string): Root directory of dataset where directory\n            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n        train (bool, optional): If True, creates dataset from training set, otherwise\n            creates from test set.\n        transform (callable, optional): A function/transform that takes in an PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n    base_folder = \"cifar-10-batches-py\"\n    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n    filename = \"cifar-10-python.tar.gz\"\n    tgz_md5 = \"c58f30108f718f92721af3b95e74349a\"\n    train_list = [\n        [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n        [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n        [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n        [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n        [\"data_batch_5\", \"482c414d41f54cd18b22e5b47cb7c3cb\"],\n    ]\n\n    test_list = [\n        [\"test_batch\", \"40351d587109b95175f43aff81a1287e\"],\n    ]\n    meta = {\n        \"filename\": \"batches.meta\",\n        \"key\": \"label_names\",\n        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n    }\n\n    def __init__(\n            self,\n            root: str,\n            train: bool = True,\n            transform: Optional[Callable] = None,\n            target_transform: Optional[Callable] = None,\n            download: bool = False,\n    ) -> None:\n\n        super().__init__(root, transform=transform, target_transform=target_transform)\n\n        self.train = train  # training set or test set\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n\n        if self.train:\n            downloaded_list = self.train_list\n        else:\n            downloaded_list = self.test_list\n\n        self.data: Any = []\n        self.targets = []\n\n        # now load the picked numpy arrays\n        for file_name, checksum in downloaded_list:\n            file_path = os.path.join(self.root, self.base_folder, file_name)\n            with open(file_path, \"rb\") as f:\n                entry = pickle.load(f, encoding=\"latin1\")\n                self.data.append(entry[\"data\"])\n                if \"labels\" in entry:\n                    self.targets.extend(entry[\"labels\"])\n                else:\n                    self.targets.extend(entry[\"fine_labels\"])\n\n        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n\n        self._load_meta()\n\n    def _load_meta(self) -> None:\n        path = os.path.join(self.root, self.base_folder, self.meta[\"filename\"])\n        if not check_integrity(path, self.meta[\"md5\"]):\n            raise RuntimeError(\"Dataset metadata file not found or corrupted. You can use download=True to download it\")\n        with open(path, \"rb\") as infile:\n            data = pickle.load(infile, encoding=\"latin1\")\n            self.classes = data[self.meta[\"key\"]]\n        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n\n    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n        \"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"\n        img, target = self.data[index], self.targets[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img)\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target\n\n    def __len__(self) -> int:\n        return len(self.data)\n\n    def _check_integrity(self) -> bool:\n        root = self.root\n        for fentry in self.train_list + self.test_list:\n            filename, md5 = fentry[0], fentry[1]\n            fpath = os.path.join(root, self.base_folder, filename)\n            if not check_integrity(fpath, md5):\n                return False\n        return True\n\n    def download(self) -> None:\n        if self._check_integrity():\n            print(\"Files already downloaded and verified\")\n            return\n        download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n\n    def extra_repr(self) -> str:\n        split = \"Train\" if self.train is True else \"Test\"\n        return f\"Split: {split}\"", "\n\nclass CIFAR100(CIFAR10):\n    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n\n    This is a subclass of the `CIFAR10` Dataset.\n    \"\"\"\n\n    base_folder = \"cifar-100-python\"\n    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n    filename = \"cifar-100-python.tar.gz\"\n    tgz_md5 = \"eb9058c3a382ffc7106e4002c42a8d85\"\n    train_list = [\n        [\"train\", \"16019d7e3df5f24257cddd939b257f8d\"],\n    ]\n\n    test_list = [\n        [\"test\", \"f0ef6b0ae62326f3e7ffdfab6717acfc\"],\n    ]\n    meta = {\n        \"filename\": \"meta\",\n        \"key\": \"fine_label_names\",\n        \"md5\": \"7973b15100ade9c7d40fb424638fde48\",\n    }", "\n\ndef get_CIFAR100_train(batch_size=256,\n                       num_workers=8,\n                       pin_memory=True,\n                       augment=False,\n                       ):\n    if not augment:\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n        ])\n    else:\n        transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n            transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n            transforms.RandomRotation(5),\n            transforms.ToTensor(),\n            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n        ])\n\n    set = CIFAR100('./resources/CIFAR100', train=True, download=True, transform=transform)\n    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory,\n                        shuffle=True)\n    return loader", "\n\ndef get_CIFAR100_test(batch_size=256,\n                      num_workers=8,\n                      pin_memory=False, ):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761]),\n    ])\n    set = CIFAR100('./resources/CIFAR100', train=False, download=True, transform=transform)\n    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n    return loader", "\n\ndef get_CIFAR10_train(batch_size=256,\n                      num_workers=8,\n                      pin_memory=True,\n                      augment=False,\n                      ):\n    if not augment:\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            # transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n        ])\n    else:\n        transform = transforms.Compose([\n            # transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n            transforms.ToTensor(),\n            # transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n        ])\n    set = CIFAR10('./resources/CIFAR10', train=True, download=True, transform=transform)\n    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory,\n                        shuffle=True)\n    return loader", "\n\ndef get_CIFAR10_test(batch_size=256,\n                     num_workers=8,\n                     pin_memory=True, ):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        # transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n    ])\n    set = CIFAR10('./resources/CIFAR10', train=False, download=True, transform=transform)\n    loader = DataLoader(set, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n    return loader", ""]}
{"filename": "models/PreTransform.py", "chunked_list": ["import torch\nfrom torchvision import transforms\n\n\ndef cifar10_normalize():\n    return transforms.Normalize(((0.4914, 0.4822, 0.4465)), (0.2470, 0.2435, 0.2616))\n"]}
{"filename": "models/__init__.py", "chunked_list": ["from .UnconditionalResNets import UnconditionalResNet32"]}
{"filename": "models/UnconditionalResNets.py", "chunked_list": ["from .SmallResolutionModel.resnet import resnet32\nfrom .SmallResolutionModel import Wide_ResNet, IGEBM\nimport torch\nfrom torch import nn\nfrom .PreTransform import cifar10_normalize\nfrom torch import Tensor\n\n\nclass UnconditionalResNet32(nn.Module):\n    def __init__(self):\n        super(UnconditionalResNet32, self).__init__()\n        # self.transform = cifar10_normalize()\n        # self.cnn = Wide_ResNet(num_classes=1)\n        # self.cnn = resnet32(num_classes=1)\n        self.cnn = IGEBM()\n\n    def forward(self, x: Tensor) -> Tensor:\n        # x = self.transform(x)\n        x = (x - 0.5) * 2\n        x = self.cnn(x)\n        return x", "class UnconditionalResNet32(nn.Module):\n    def __init__(self):\n        super(UnconditionalResNet32, self).__init__()\n        # self.transform = cifar10_normalize()\n        # self.cnn = Wide_ResNet(num_classes=1)\n        # self.cnn = resnet32(num_classes=1)\n        self.cnn = IGEBM()\n\n    def forward(self, x: Tensor) -> Tensor:\n        # x = self.transform(x)\n        x = (x - 0.5) * 2\n        x = self.cnn(x)\n        return x", ""]}
{"filename": "models/SmallResolutionModel/cifar10_resnet.py", "chunked_list": ["# ---------------------------------------------------------------\n# Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.\n#\n# This work is licensed under the NVIDIA Source Code License\n# for DiffPure. To view a copy of this license, see the LICENSE file.\n# ---------------------------------------------------------------\n\nimport math\n\nimport torch", "\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\n\n\n# ---------------------------- ResNet ----------------------------\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out", "class Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out", "\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        num_input_channels = 3\n        mean = (0.4914, 0.4822, 0.4465)\n        std = (0.2471, 0.2435, 0.2616)\n        self.mean = torch.tensor(mean).view(num_input_channels, 1, 1)\n        self.std = torch.tensor(std).view(num_input_channels, 1, 1)\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = (x - self.mean.to(x.device)) / self.std.to(x.device)\n        out = F.relu(self.bn1(self.conv1(out)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out", "\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3, 4, 6, 3])\n\n\n# ---------------------------- ResNet ----------------------------\n\n\n# ---------------------------- WideResNet ----------------------------", "\n# ---------------------------- WideResNet ----------------------------\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                                                                padding=0, bias=False) or None\n\n    def forward(self, x):\n        if not self.equalInOut:\n            x = self.relu1(self.bn1(x))\n        else:\n            out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)", "\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(int(nb_layers)):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.layer(x)", "\n\nclass WideResNet(nn.Module):\n    \"\"\" Based on code from https://github.com/yaodongyu/TRADES \"\"\"\n\n    def __init__(self, depth=28, num_classes=10, widen_factor=10, sub_block1=False, dropRate=0.0, bias_last=True):\n        super(WideResNet, self).__init__()\n\n        num_input_channels = 3\n        mean = (0.4914, 0.4822, 0.4465)\n        std = (0.2471, 0.2435, 0.2616)\n        self.mean = torch.tensor(mean).view(num_input_channels, 1, 1)\n        self.std = torch.tensor(std).view(num_input_channels, 1, 1)\n\n        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n        assert ((depth - 4) % 6 == 0)\n        n = (depth - 4) / 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        if sub_block1:\n            # 1st sub-block\n            self.sub_block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes, bias=bias_last)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear) and not m.bias is None:\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        out = (x - self.mean.to(x.device)) / self.std.to(x.device)\n        out = self.conv1(out)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)", "\n\ndef WideResNet_70_16():\n    return WideResNet(depth=70, widen_factor=16, dropRate=0.0)\n\n\ndef WideResNet_70_16_dropout():\n    model = WideResNet(depth=70, widen_factor=16, dropRate=0.3)\n    state = torch.load('./resources/checkpoints/models/WideResNet_70_16_dropout.pt')\n    r = {}\n    for k, v in list(state.items()):\n        k = k.split('module.', 1)[1]\n        r[k] = v\n    model.load_state_dict(r)\n    return model", "# ---------------------------- WideResNet ----------------------------\n"]}
{"filename": "models/SmallResolutionModel/wrn.py", "chunked_list": ["import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\"\"\"\nOriginal Author: Wei Yang\n\n", "\n\nadding hyperparameter norm_layer: Huanran Chen\n\"\"\"\n\n__all__ = [\n    \"wrn\",\n    \"wrn_40_2_aux\",\n    \"wrn_16_2_aux\",\n    \"wrn_16_1\",", "    \"wrn_16_2_aux\",\n    \"wrn_16_1\",\n    \"wrn_16_2\",\n    \"wrn_40_1\",\n    \"wrn_40_2\",\n    \"wrn_40_1_aux\",\n    \"wrn_16_2_spkd\",\n    \"wrn_40_1_spkd\",\n    \"wrn_40_2_spkd\",\n    \"wrn_40_1_crd\",", "    \"wrn_40_2_spkd\",\n    \"wrn_40_1_crd\",\n    \"wrn_16_2_crd\",\n    \"wrn_40_2_crd\",\n    \"wrn_16_2_sskd\",\n    \"wrn_40_1_sskd\",\n    \"wrn_40_2_sskd\",\n]\n\n\nclass Normalizer4CRD(nn.Module):\n    def __init__(self, linear, power=2):\n        super().__init__()\n        self.linear = linear\n        self.power = power\n\n    def forward(self, x):\n        x = x.flatten(1)\n        z = self.linear(x)\n        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n        out = z.div(norm)\n        return out", "\n\nclass Normalizer4CRD(nn.Module):\n    def __init__(self, linear, power=2):\n        super().__init__()\n        self.linear = linear\n        self.power = power\n\n    def forward(self, x):\n        x = x.flatten(1)\n        z = self.linear(x)\n        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n        out = z.div(norm)\n        return out", "\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, norm_layer=nn.BatchNorm2d):\n        super(BasicBlock, self).__init__()\n        self.bn1 = norm_layer(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(\n            in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn2 = norm_layer(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(\n            out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.droprate = dropRate\n        self.equalInOut = in_planes == out_planes\n        self.convShortcut = (\n                (not self.equalInOut)\n                and nn.Conv2d(\n            in_planes, out_planes, kernel_size=1, stride=stride, padding=0, bias=False\n        )\n                or None\n        )\n\n    def forward(self, x):\n        if not self.equalInOut:\n            x = self.relu1(self.bn1(x))\n        else:\n            out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)", "\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0,\n                 norm_layer=nn.BatchNorm2d):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes,\n                                      nb_layers, stride, dropRate, norm_layer)\n\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, norm_layer):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(\n                block(\n                    i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate,\n                    norm_layer=norm_layer\n                )\n            )\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.layer(x)", "\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0,\n                 norm_layer=nn.BatchNorm2d):\n        super(WideResNet, self).__init__()\n        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n        assert (depth - 4) % 6 == 0, \"depth should be 6n+4\"\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, norm_layer)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate, norm_layer)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate, norm_layer)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.last_channel = nChannels[3]\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.block1)\n        feat_m.append(self.block2)\n        feat_m.append(self.block3)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        bn1 = self.block2.layer[0].bn1\n        bn2 = self.block3.layer[0].bn1\n        bn3 = self.bn1\n\n        return [bn1, bn2, bn3]\n\n    def forward(self, x, is_feat=False, preact=False):\n        out = self.conv1(x)\n        out = self.block1(out)\n        f1 = out\n        out = self.block2(out)\n        f2 = out\n        out = self.block3(out)\n        f3 = out\n        out = self.relu(self.bn1(out))\n        f4 = out\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        out = self.fc(out)\n        if is_feat:\n            return [f1, f2, f3, f4], out\n        else:\n            return out", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(Auxiliary_Classifier, self).__init__()\n        self.nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n        block = BasicBlock\n        n = (depth - 4) // 6\n        self.block_extractor1 = nn.Sequential(\n            *[\n                NetworkBlock(n, self.nChannels[1], self.nChannels[2], block, 2),\n                NetworkBlock(n, self.nChannels[2], self.nChannels[3], block, 2),\n            ]\n        )\n        self.block_extractor2 = nn.Sequential(\n            *[NetworkBlock(n, self.nChannels[2], self.nChannels[3], block, 2)]\n        )\n        self.block_extractor3 = nn.Sequential(\n            *[NetworkBlock(n, self.nChannels[3], self.nChannels[3], block, 1)]\n        )\n\n        self.bn1 = nn.BatchNorm2d(self.nChannels[3])\n        self.bn2 = nn.BatchNorm2d(self.nChannels[3])\n        self.bn3 = nn.BatchNorm2d(self.nChannels[3])\n\n        self.relu = nn.ReLU(inplace=True)\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc1 = nn.Linear(self.nChannels[3], num_classes)\n        self.fc2 = nn.Linear(self.nChannels[3], num_classes)\n        self.fc3 = nn.Linear(self.nChannels[3], num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        ss_logits = []\n        ss_feats = []\n        for i in range(len(x)):\n            idx = i + 1\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = self.relu(getattr(self, \"bn\" + str(idx))(out))\n            out = self.avg_pool(out)\n            out = out.view(-1, self.nChannels[3])\n            ss_feats.append(out)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n        return ss_logits", "\n\nclass WideResNet_Auxiliary(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet_Auxiliary, self).__init__()\n        self.backbone = WideResNet(depth, num_classes, widen_factor=widen_factor)\n        self.auxiliary_classifier = Auxiliary_Classifier(\n            depth=depth, num_classes=num_classes * 4, widen_factor=widen_factor\n        )\n\n    def forward(self, x, grad=False):\n        feats, logit = self.backbone(x, is_feat=True)\n        if grad is False:\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        ss_logits = self.auxiliary_classifier(feats)\n\n        return logit, ss_logits", "\n\nclass WideResNet_SPKD(WideResNet):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet_SPKD, self).__init__(depth, num_classes, widen_factor, dropRate)\n\n    def forward(self, x, is_feat=False, preact=False):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        f4 = out\n        out = self.fc(out)\n        return f4, out", "\n\nclass WideResNet_SSKD(WideResNet):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet_SSKD, self).__init__(depth, num_classes, widen_factor, dropRate)\n        self.ss_module = nn.Sequential(\n            nn.Linear(self.nChannels, self.nChannels),\n            nn.ReLU(inplace=True),\n            nn.Linear(self.nChannels, self.nChannels),\n        )\n\n    def forward(self, x, is_feat=False, preact=False):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        f4 = self.ss_module(out)\n        out = self.fc(out)\n        return f4, out", "\n\nclass WideResNet_CRD(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0,\n                 norm_layer=nn.BatchNorm2d):\n        super(WideResNet_CRD, self).__init__()\n        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n        assert (depth - 4) % 6 == 0, \"depth should be 6n+4\"\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        linear = nn.Linear(nChannels[3], 128, bias=True)\n        self.normalizer = Normalizer4CRD(linear, power=2)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.block1)\n        feat_m.append(self.block2)\n        feat_m.append(self.block3)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        bn1 = self.block2.layer[0].bn1\n        bn2 = self.block3.layer[0].bn1\n        bn3 = self.bn1\n\n        return [bn1, bn2, bn3]\n\n    def forward(self, x, is_feat=False, preact=False):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        crdout = out\n        out = out.view(-1, self.nChannels)\n        out = self.fc(out)\n        crdout = self.normalizer(crdout)\n        return crdout, out", "\n\ndef wrn(**kwargs):\n    \"\"\"\n    Constructs a Wide Residual Networks.\n    \"\"\"\n    model = WideResNet(**kwargs)\n    return model\n\n\ndef wrn_40_2(**kwargs):\n    model = WideResNet(depth=40, widen_factor=2, **kwargs)\n    return model", "\n\ndef wrn_40_2(**kwargs):\n    model = WideResNet(depth=40, widen_factor=2, **kwargs)\n    return model\n\n\ndef wrn_40_2_aux(**kwargs):\n    model = WideResNet_Auxiliary(depth=40, widen_factor=2, **kwargs)\n    return model", "\n\ndef wrn_40_2_spkd(**kwargs):\n    model = WideResNet_SPKD(depth=40, widen_factor=2, **kwargs)\n    return model\n\n\ndef wrn_40_2_sskd(**kwargs):\n    model = WideResNet_SSKD(depth=40, widen_factor=2, **kwargs)\n    return model", "\n\ndef wrn_40_2_crd(**kwargs):\n    model = WideResNet_CRD(depth=40, widen_factor=2, **kwargs)\n    return model\n\n\ndef wrn_40_1(**kwargs):\n    model = WideResNet(depth=40, widen_factor=1, **kwargs)\n    return model", "\n\ndef wrn_40_1_aux(**kwargs):\n    model = WideResNet_Auxiliary(depth=40, widen_factor=1, **kwargs)\n    return model\n\n\ndef wrn_40_1_spkd(**kwargs):\n    model = WideResNet_SPKD(depth=40, widen_factor=1, **kwargs)\n    return model", "\n\ndef wrn_40_1_crd(**kwargs):\n    model = WideResNet_CRD(depth=40, widen_factor=1, **kwargs)\n    return model\n\n\ndef wrn_40_1_sskd(**kwargs):\n    model = WideResNet_SSKD(depth=40, widen_factor=1, **kwargs)\n    return model", "\n\ndef wrn_16_2(**kwargs):\n    model = WideResNet(depth=16, widen_factor=2, **kwargs)\n    return model\n\n\ndef wrn_16_2_aux(**kwargs):\n    model = WideResNet_Auxiliary(depth=16, widen_factor=2, **kwargs)\n    return model", "\n\ndef wrn_16_2_spkd(**kwargs):\n    model = WideResNet_SPKD(depth=16, widen_factor=2, **kwargs)\n    return model\n\n\ndef wrn_16_2_crd(**kwargs):\n    model = WideResNet_CRD(depth=16, widen_factor=2, **kwargs)\n    return model", "\n\ndef wrn_16_2_sskd(**kwargs):\n    model = WideResNet_SSKD(depth=16, widen_factor=2, **kwargs)\n    return model\n\n\ndef wrn_16_1(**kwargs):\n    model = WideResNet(depth=16, widen_factor=1, **kwargs)\n    return model", ""]}
{"filename": "models/SmallResolutionModel/mobilenetv2.py", "chunked_list": ["\"\"\"\nMobileNetV2 implementation used in\n<Knowledge Distillation via Route Constrained Optimization>\n\nadding hyperparameter norm_layer: Huanran Chen\n\"\"\"\n\nimport math\n\nimport torch", "\nimport torch\nimport torch.nn as nn\n\n__all__ = [\n    \"mobilenetv2_T_w\",\n    \"mobilenetV2\",\n    \"mobilenetV2_aux\",\n    \"mobilenetV2_spkd\",\n    \"mobilenetV2_crd\",", "    \"mobilenetV2_spkd\",\n    \"mobilenetV2_crd\",\n]\n\nBN = None\n\n\nclass Normalizer4CRD(nn.Module):\n    def __init__(self, linear, power=2):\n        super().__init__()\n        self.linear = linear\n        self.power = power\n\n    def forward(self, x):\n        x = x.flatten(1)\n        z = self.linear(x)\n        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n        out = z.div(norm)\n        return out", "\n\ndef conv_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False), nn.BatchNorm2d(oup), nn.ReLU(inplace=True)\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False), nn.BatchNorm2d(oup), nn.ReLU(inplace=True)\n    )", "def conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False), nn.BatchNorm2d(oup), nn.ReLU(inplace=True)\n    )\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio, norm_layer=nn.BatchNorm2d):\n        super(InvertedResidual, self).__init__()\n        self.blockname = None\n\n        self.stride = stride\n        assert stride in [1, 2]\n\n        self.use_res_connect = self.stride == 1 and inp == oup\n\n        self.conv = nn.Sequential(\n            # pw\n            nn.Conv2d(inp, inp * expand_ratio, 1, 1, 0, bias=False),\n            norm_layer(inp * expand_ratio),\n            nn.ReLU(inplace=True),\n            # dw\n            nn.Conv2d(\n                inp * expand_ratio,\n                inp * expand_ratio,\n                3,\n                stride,\n                1,\n                groups=inp * expand_ratio,\n                bias=False,\n            ),\n            norm_layer(inp * expand_ratio),\n            nn.ReLU(inplace=True),\n            # pw-linear\n            nn.Conv2d(inp * expand_ratio, oup, 1, 1, 0, bias=False),\n            norm_layer(oup),\n        )\n        self.names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n\n    def forward(self, x):\n        t = x\n\n        if self.use_res_connect:\n            return t + self.conv(x)\n        else:\n            return self.conv(x)", "\n\nclass MobileNetV2(nn.Module):\n    \"\"\"mobilenetV2\"\"\"\n\n    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False,\n                 norm_layer=nn.BatchNorm2d):\n        super(MobileNetV2, self).__init__()\n        self.remove_avg = remove_avg\n\n        # setting of inverted residual blocks\n        self.interverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [T, 24, 2, 1],\n            [T, 32, 3, 2],\n            [T, 64, 4, 2],\n            [T, 96, 3, 1],\n            [T, 160, 3, 2],\n            [T, 320, 1, 1],\n        ]\n\n        # building first layer\n        assert input_size % 32 == 0\n        input_channel = int(32 * width_mult)\n        self.conv1 = conv_bn(3, input_channel, 2)\n\n        # building inverted residual blocks\n        self.blocks = nn.ModuleList([])\n        for t, c, n, s in self.interverted_residual_setting:\n            output_channel = int(c * width_mult)\n            layers = []\n            strides = [s] + [1] * (n - 1)\n            for stride in strides:\n                layers.append(InvertedResidual(input_channel, output_channel, stride, t,\n                                               norm_layer=norm_layer))\n                input_channel = output_channel\n            self.blocks.append(nn.Sequential(*layers))\n\n        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n        self.conv2 = conv_1x1_bn(input_channel, self.last_channel)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n        # building classifier\n        # self.classifier = nn.Sequential(\n        #    # nn.Dropout(0.5),\n        #    nn.Linear(self.last_channel, feature_dim),\n        # )\n        self.classifier = nn.Linear(self.last_channel, feature_dim)\n\n        self._initialize_weights()\n\n    def get_bn_before_relu(self):\n        bn1 = self.blocks[1][-1].conv[-1]\n        bn2 = self.blocks[2][-1].conv[-1]\n        bn3 = self.blocks[4][-1].conv[-1]\n        bn4 = self.blocks[6][-1].conv[-1]\n        return [bn1, bn2, bn3, bn4]\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.blocks)\n        return feat_m\n\n    def forward(self, x, is_feat=False, preact=False):\n\n        out = self.conv1(x)\n        out = self.blocks[0](out)\n        out = self.blocks[1](out)\n        f1 = out\n        out = self.blocks[2](out)\n        f2 = out\n        out = self.blocks[3](out)\n        out = self.blocks[4](out)\n        f3 = out\n        out = self.blocks[5](out)\n        out = self.blocks[6](out)\n        out = self.conv2(out)\n        f4 = out\n\n        if not self.remove_avg:\n            out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.classifier(out)\n\n        if is_feat:\n            return [f1, f2, f3, f4], out\n        else:\n            return out\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False):\n        super(Auxiliary_Classifier, self).__init__()\n\n        self.remove_avg = remove_avg\n        self.width_mult = width_mult\n        # setting of inverted residual blocks\n        interverted_residual_setting1 = [\n            [T, 32, 3, 2],\n            [T, 64, 4, 2],\n            [T, 96, 3, 1],\n            [T, 160, 3, 2],\n            [T, 320, 1, 1],\n        ]\n        self.block_extractor1 = self._make_layer(\n            input_channel=12, interverted_residual_setting=interverted_residual_setting1\n        )\n\n        interverted_residual_setting2 = [\n            [T, 64, 4, 2],\n            [T, 96, 3, 1],\n            [T, 160, 3, 2],\n            [T, 320, 1, 1],\n        ]\n        self.block_extractor2 = self._make_layer(\n            input_channel=16, interverted_residual_setting=interverted_residual_setting2\n        )\n\n        interverted_residual_setting3 = [\n            [T, 160, 3, 2],\n            [T, 320, 1, 1],\n        ]\n        self.block_extractor3 = self._make_layer(\n            input_channel=48, interverted_residual_setting=interverted_residual_setting3\n        )\n\n        interverted_residual_setting4 = [\n            [T, 160, 3, 1],\n            [T, 320, 1, 1],\n        ]\n        self.block_extractor4 = self._make_layer(\n            input_channel=160, interverted_residual_setting=interverted_residual_setting4\n        )\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n\n        self.conv2_1 = conv_1x1_bn(160, self.last_channel)\n        self.conv2_2 = conv_1x1_bn(160, self.last_channel)\n        self.conv2_3 = conv_1x1_bn(160, self.last_channel)\n        self.conv2_4 = conv_1x1_bn(160, self.last_channel)\n\n        self.fc1 = nn.Linear(self.last_channel, feature_dim)\n        self.fc2 = nn.Linear(self.last_channel, feature_dim)\n        self.fc3 = nn.Linear(self.last_channel, feature_dim)\n        self.fc4 = nn.Linear(self.last_channel, feature_dim)\n\n        self._initialize_weights()\n\n    def _make_layer(self, input_channel, interverted_residual_setting):\n        # building inverted residual blocks\n        blocks = []\n        for t, c, n, s in interverted_residual_setting:\n            output_channel = int(c * self.width_mult)\n            layers = []\n            strides = [s] + [1] * (n - 1)\n            for stride in strides:\n                layers.append(InvertedResidual(input_channel, output_channel, stride, t))\n                input_channel = output_channel\n            blocks.append(nn.Sequential(*layers))\n\n        return nn.Sequential(*blocks)\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        ss_logits = []\n        ss_feats = []\n\n        for i in range(len(x)):\n            idx = i + 1\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = getattr(self, \"conv2_\" + str(idx))(out)\n            out = self.avg_pool(out)\n            out = out.view(out.size(0), -1)\n            ss_feats.append(out)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n\n        return ss_feats, ss_logits", "\n\nclass MobileNetv2_Auxiliary(nn.Module):\n    def __init__(self, T, W, feature_dim=100):\n        super(MobileNetv2_Auxiliary, self).__init__()\n        self.backbone = MobileNetV2(T=T, feature_dim=feature_dim, width_mult=W)\n        self.auxiliary_classifier = Auxiliary_Classifier(\n            T=T, feature_dim=4 * feature_dim, width_mult=W\n        )\n\n    def forward(self, x, grad=False, att=False):\n        feats, logit = self.backbone(x, is_feat=True)\n        if grad is False:\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        ss_feats, ss_logits = self.auxiliary_classifier(feats)\n        if att is False:\n            return logit, ss_logits\n        else:\n            return logit, ss_logits, feats", "\n\nclass MobileNetV2_SPKD(MobileNetV2):\n    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False):\n        super(MobileNetV2_SPKD, self).__init__(T, feature_dim, input_size, width_mult, remove_avg)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.blocks[0](out)\n        out = self.blocks[1](out)\n        out = self.blocks[2](out)\n        out = self.blocks[3](out)\n        out = self.blocks[4](out)\n        out = self.blocks[5](out)\n        out = self.blocks[6](out)\n        f4 = out\n\n        out = self.conv2(out)\n\n        if not self.remove_avg:\n            out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.classifier(out)\n        return f4, out", "\n\nclass MobileNetV2_CRD(nn.Module):\n    def __init__(self, T, feature_dim, input_size=32, width_mult=1.0, remove_avg=False):\n        super(MobileNetV2_CRD, self).__init__()\n        self.remove_avg = remove_avg\n\n        # setting of inverted residual blocks\n        self.interverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [T, 24, 2, 1],\n            [T, 32, 3, 2],\n            [T, 64, 4, 2],\n            [T, 96, 3, 1],\n            [T, 160, 3, 2],\n            [T, 320, 1, 1],\n        ]\n\n        # building first layer\n        assert input_size % 32 == 0\n        input_channel = int(32 * width_mult)\n        self.conv1 = conv_bn(3, input_channel, 1)\n\n        # building inverted residual blocks\n        self.blocks = nn.ModuleList([])\n        for t, c, n, s in self.interverted_residual_setting:\n            output_channel = int(c * width_mult)\n            layers = []\n            strides = [s] + [1] * (n - 1)\n            for stride in strides:\n                layers.append(InvertedResidual(input_channel, output_channel, stride, t))\n                input_channel = output_channel\n            self.blocks.append(nn.Sequential(*layers))\n\n        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n        self.conv2 = conv_1x1_bn(input_channel, self.last_channel)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(self.last_channel, feature_dim)\n        linear = nn.Linear(self.last_channel, 128, bias=True)\n        self.normalizer = Normalizer4CRD(linear, power=2)\n        self._initialize_weights()\n\n    def get_bn_before_relu(self):\n        bn1 = self.blocks[1][-1].conv[-1]\n        bn2 = self.blocks[2][-1].conv[-1]\n        bn3 = self.blocks[4][-1].conv[-1]\n        bn4 = self.blocks[6][-1].conv[-1]\n        return [bn1, bn2, bn3, bn4]\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.blocks)\n        return feat_m\n\n    def forward(self, x):\n\n        out = self.conv1(x)\n        out = self.blocks[0](out)\n        out = self.blocks[1](out)\n        out = self.blocks[2](out)\n        out = self.blocks[3](out)\n        out = self.blocks[4](out)\n        out = self.blocks[5](out)\n        out = self.blocks[6](out)\n        out = self.conv2(out)\n        out = self.avgpool(out)\n        f = out\n        out = out.view(out.size(0), -1)\n        out = self.classifier(out)\n        crdout = self.normalizer(f)\n        return crdout, out\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()", "\n\ndef mobilenetv2_T_w(T, W, feature_dim=100):\n    model = MobileNetV2(T=T, feature_dim=feature_dim, width_mult=W)\n    return model\n\n\ndef mobilenetV2(num_classes):\n    return mobilenetv2_T_w(6, 0.5, num_classes)\n", "\n\ndef mobilenetV2_aux(num_classes):\n    return MobileNetv2_Auxiliary(6, 0.5, num_classes)\n\n\ndef mobilenetV2_spkd(num_classes):\n    return MobileNetV2_SPKD(T=6, width_mult=0.5, feature_dim=num_classes)\n\n\ndef mobilenetV2_crd(num_classes):\n    return MobileNetV2_CRD(T=6, width_mult=0.5, feature_dim=num_classes)", "\n\ndef mobilenetV2_crd(num_classes):\n    return MobileNetV2_CRD(T=6, width_mult=0.5, feature_dim=num_classes)\n"]}
{"filename": "models/SmallResolutionModel/resnet_imagenet.py", "chunked_list": ["import torch\nimport torch.nn as nn\n\n__all__ = [\n    \"resnet18_imagenet\",\n    \"resnet18_imagenet_aux\",\n    \"resnet34_imagenet\",\n    \"resnet34_imagenet_aux\",\n    \"resnet50_imagenet\",\n    \"resnet50_imagenet_aux\",", "    \"resnet50_imagenet\",\n    \"resnet50_imagenet_aux\",\n]\n\n\ndef conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(\n        in_planes,\n        out_planes,\n        kernel_size=3,\n        stride=stride,\n        padding=dilation,\n        groups=groups,\n        bias=False,\n        dilation=dilation,\n    )", "\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(\n        self,\n        inplanes,\n        planes,\n        stride=1,\n        downsample=None,\n        groups=1,\n        base_width=64,\n        dilation=1,\n        norm_layer=None,\n    ):\n        super(BasicBlock, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        if groups != 1 or base_width != 64:\n            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n        if dilation > 1:\n            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out", "\n\nclass Bottleneck(nn.Module):\n    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n    # This variant is also known as ResNet V1.5 and improves accuracy according to\n    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n\n    expansion = 4\n\n    def __init__(\n        self,\n        inplanes,\n        planes,\n        stride=1,\n        downsample=None,\n        groups=1,\n        base_width=64,\n        dilation=1,\n        norm_layer=None,\n    ):\n        super(Bottleneck, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        width = int(planes * (base_width / 64.0)) * groups\n        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv1x1(inplanes, width)\n        self.bn1 = norm_layer(width)\n        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n        self.bn2 = norm_layer(width)\n        self.conv3 = conv1x1(width, planes * self.expansion)\n        self.bn3 = norm_layer(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out", "\n\nclass ResNet(nn.Module):\n    def __init__(\n        self,\n        block,\n        layers,\n        num_classes=1000,\n        zero_init_residual=False,\n        groups=1,\n        width_per_group=64,\n        replace_stride_with_dilation=None,\n        norm_layer=None,\n    ):\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self._norm_layer = norm_layer\n\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            # each element in the tuple indicates if we should replace\n            # the 2x2 stride with a dilated convolution instead\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\n                \"replace_stride_with_dilation should be None \"\n                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n            )\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(\n            block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]\n        )\n        self.layer3 = self._make_layer(\n            block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]\n        )\n        self.layer4 = self._make_layer(\n            block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n        self.last_channel = 512 * block.expansion\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n        norm_layer = self._norm_layer\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(\n            block(\n                self.inplanes,\n                planes,\n                stride,\n                downsample,\n                self.groups,\n                self.base_width,\n                previous_dilation,\n                norm_layer,\n            )\n        )\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(\n                block(\n                    self.inplanes,\n                    planes,\n                    groups=self.groups,\n                    base_width=self.base_width,\n                    dilation=self.dilation,\n                    norm_layer=norm_layer,\n                )\n            )\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x, is_feat=False):\n        # See note [TorchScript super()]\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        f1 = x\n        x = self.layer2(x)\n        f2 = x\n        x = self.layer3(x)\n        f3 = x\n        x = self.layer4(x)\n        f4 = x\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        if is_feat:\n            return [f1, f2, f3, f4], x\n        else:\n            return x", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(\n        self,\n        block,\n        layers,\n        num_classes=1000,\n        zero_init_residual=False,\n        groups=1,\n        width_per_group=64,\n        replace_stride_with_dilation=None,\n        norm_layer=None,\n    ):\n        super(Auxiliary_Classifier, self).__init__()\n\n        self.dilation = 1\n        self.groups = groups\n        self.base_width = width_per_group\n        self.inplanes = 64 * block.expansion\n        self.block_extractor1 = nn.Sequential(\n            *[\n                self._make_layer(block, 128, layers[1], stride=2),\n                self._make_layer(block, 256, layers[2], stride=2),\n                self._make_layer(block, 512, layers[3], stride=2),\n            ]\n        )\n\n        self.inplanes = 128 * block.expansion\n        self.block_extractor2 = nn.Sequential(\n            *[\n                self._make_layer(block, 256, layers[2], stride=2),\n                self._make_layer(block, 512, layers[3], stride=2),\n            ]\n        )\n\n        self.inplanes = 256 * block.expansion\n        self.block_extractor3 = nn.Sequential(*[self._make_layer(block, 512, layers[3], stride=2)])\n\n        self.inplanes = 512 * block.expansion\n        self.block_extractor4 = nn.Sequential(*[self._make_layer(block, 512, layers[3], stride=1)])\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc1 = nn.Linear(512 * block.expansion, num_classes)\n        self.fc2 = nn.Linear(512 * block.expansion, num_classes)\n        self.fc3 = nn.Linear(512 * block.expansion, num_classes)\n        self.fc4 = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n        norm_layer = nn.BatchNorm2d\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(\n            block(\n                self.inplanes,\n                planes,\n                stride,\n                downsample,\n                self.groups,\n                self.base_width,\n                previous_dilation,\n                norm_layer,\n            )\n        )\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(\n                block(\n                    self.inplanes,\n                    planes,\n                    groups=self.groups,\n                    base_width=self.base_width,\n                    dilation=self.dilation,\n                    norm_layer=norm_layer,\n                )\n            )\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        ss_logits = []\n        for i in range(len(x)):\n            idx = i + 1\n\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = self.avg_pool(out)\n            out = out.view(out.size(0), -1)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n        return ss_logits", "\n\nclass ResNet_Auxiliary(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n        super(ResNet_Auxiliary, self).__init__()\n        self.backbone = ResNet(\n            block, layers, num_classes=num_classes, zero_init_residual=zero_init_residual\n        )\n        self.auxiliary_classifier = Auxiliary_Classifier(\n            block, layers, num_classes=num_classes * 4, zero_init_residual=zero_init_residual\n        )\n\n    def forward(self, x, grad=False):\n        if grad is False:\n            feats, logit = self.backbone(x, is_feat=True)\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        else:\n            feats, logit = self.backbone(x, is_feat=True)\n\n        ss_logits = self.auxiliary_classifier(feats)\n        return logit, ss_logits", "\n\ndef resnet18_imagenet(**kwargs):\n    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n\n\ndef resnet18_imagenet_aux(**kwargs):\n    return ResNet_Auxiliary(BasicBlock, [2, 2, 2, 2], **kwargs)\n\n\ndef resnet34_imagenet(**kwargs):\n    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)", "\n\ndef resnet34_imagenet(**kwargs):\n    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n\n\ndef resnet34_imagenet_aux(**kwargs):\n    return ResNet_Auxiliary(BasicBlock, [3, 4, 6, 3], **kwargs)\n\n\ndef resnet50_imagenet(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)", "\n\ndef resnet50_imagenet(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n\n\ndef resnet50_imagenet_aux(**kwargs):\n    return ResNet_Auxiliary(Bottleneck, [3, 4, 6, 3], **kwargs)\n", ""]}
{"filename": "models/SmallResolutionModel/ShuffleNetv2.py", "chunked_list": ["\"\"\"ShuffleNetV2 in PyTorch.\nSee the paper \"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\" for more details.\n\n\nadding hyperparameter norm_layer: Huanran Chen\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n", "import torch.nn.functional as F\n\n__all__ = [\"ShuffleV2_aux\", \"ShuffleV2\"]\n\n\nclass ShuffleBlock(nn.Module):\n    def __init__(self, groups=2):\n        super(ShuffleBlock, self).__init__()\n        self.groups = groups\n\n    def forward(self, x):\n        \"\"\"Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]\"\"\"\n        N, C, H, W = x.size()\n        g = self.groups\n        return x.view(N, g, C // g, H, W).permute(0, 2, 1, 3, 4).reshape(N, C, H, W)", "\n\nclass SplitBlock(nn.Module):\n    def __init__(self, ratio):\n        super(SplitBlock, self).__init__()\n        self.ratio = ratio\n\n    def forward(self, x):\n        c = int(x.size(1) * self.ratio)\n        return x[:, :c, :, :], x[:, c:, :, :]", "\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, split_ratio=0.5, is_last=False, norm_layer=nn.BatchNorm2d):\n        super(BasicBlock, self).__init__()\n        self.is_last = is_last\n        self.split = SplitBlock(split_ratio)\n        in_channels = int(in_channels * split_ratio)\n        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n        self.bn1 = norm_layer(in_channels)\n        self.conv2 = nn.Conv2d(\n            in_channels,\n            in_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1,\n            groups=in_channels,\n            bias=False,\n        )\n        self.bn2 = norm_layer(in_channels)\n        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n        self.bn3 = norm_layer(in_channels)\n        self.shuffle = ShuffleBlock()\n\n    def forward(self, x):\n        x1, x2 = self.split(x)\n        out = F.relu(self.bn1(self.conv1(x2)))\n        out = self.bn2(self.conv2(out))\n        preact = self.bn3(self.conv3(out))\n        out = F.relu(preact)\n        # out = F.relu(self.bn3(self.conv3(out)))\n        preact = torch.cat([x1, preact], 1)\n        out = torch.cat([x1, out], 1)\n        out = self.shuffle(out)\n        return out", "\n\nclass DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=2):\n        super(DownBlock, self).__init__()\n        mid_channels = out_channels // 2\n        # left\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            in_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            groups=in_channels,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(in_channels)\n        self.conv2 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(mid_channels)\n        # right\n        self.conv3 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(mid_channels)\n        self.conv4 = nn.Conv2d(\n            mid_channels,\n            mid_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            groups=mid_channels,\n            bias=False,\n        )\n        self.bn4 = nn.BatchNorm2d(mid_channels)\n        self.conv5 = nn.Conv2d(mid_channels, mid_channels, kernel_size=1, bias=False)\n        self.bn5 = nn.BatchNorm2d(mid_channels)\n\n        self.shuffle = ShuffleBlock()\n\n    def forward(self, x):\n        # left\n        out1 = self.bn1(self.conv1(x))\n        out1 = F.relu(self.bn2(self.conv2(out1)))\n        # right\n        out2 = F.relu(self.bn3(self.conv3(x)))\n        out2 = self.bn4(self.conv4(out2))\n        out2 = F.relu(self.bn5(self.conv5(out2)))\n        # concat\n        out = torch.cat([out1, out2], 1)\n        out = self.shuffle(out)\n        return out", "\n\nclass ShuffleNetV2(nn.Module):\n    def __init__(self, net_size, num_classes=100, norm_layer=nn.BatchNorm2d):\n        super(ShuffleNetV2, self).__init__()\n        out_channels = configs[net_size][\"out_channels\"]\n        num_blocks = configs[net_size][\"num_blocks\"]\n\n        # self.conv1 = nn.Conv2d(3, 24, kernel_size=3,\n        #                        stride=1, padding=1, bias=False)\n        self.conv1 = nn.Conv2d(3, 24, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(24)\n        self.in_channels = 24\n        self.layer1 = self._make_layer(out_channels[0], num_blocks[0], norm_layer)\n        self.layer2 = self._make_layer(out_channels[1], num_blocks[1], norm_layer)\n        self.layer3 = self._make_layer(out_channels[2], num_blocks[2], norm_layer)\n        self.conv2 = nn.Conv2d(\n            out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(out_channels[3])\n        self.linear = nn.Linear(out_channels[3], num_classes)\n        self.last_channel = out_channels[3]\n\n    def _make_layer(self, out_channels, num_blocks, norm_layer=nn.BatchNorm2d):\n        layers = [DownBlock(self.in_channels, out_channels)]\n        for i in range(num_blocks):\n            layers.append(BasicBlock(out_channels, is_last=(i == num_blocks - 1), norm_layer=norm_layer))\n            self.in_channels = out_channels\n        return nn.Sequential(*layers)\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.bn1)\n        feat_m.append(self.layer1)\n        feat_m.append(self.layer2)\n        feat_m.append(self.layer3)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        raise NotImplementedError('ShuffleNetV2 currently is not supported for \"Overhaul\" teacher2')\n\n    def forward(self, x, is_feat=False, preact=False):\n        out = F.relu(self.bn1(self.conv1(x)))\n        # out = F.max_pool2d(out, 3, stride=2, padding=1)\n        out = self.layer1(out)\n        f1 = out\n        out = self.layer2(out)\n        f2 = out\n        out = self.layer3(out)\n        f3 = out\n        out = F.relu(self.bn2(self.conv2(out)))\n        f4 = out\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        if is_feat:\n            return [f1, f2, f3, f4], out\n        else:\n            return out", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(self, net_size, num_classes=100, norm_layer=nn.BatchNorm2d):\n        super(Auxiliary_Classifier, self).__init__()\n        out_channels = configs[net_size][\"out_channels\"]\n        num_blocks = configs[net_size][\"num_blocks\"]\n\n        self.in_channels = out_channels[0]\n        self.block_extractor1 = nn.Sequential(\n            *[\n                self._make_layer(out_channels[1], num_blocks[1]),\n                self._make_layer(out_channels[2], num_blocks[2]),\n                nn.Conv2d(\n                    out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n                ),\n                nn.BatchNorm2d(out_channels[3]),\n                nn.ReLU(inplace=True),\n            ]\n        )\n\n        self.in_channels = out_channels[1]\n        self.block_extractor2 = nn.Sequential(\n            *[\n                self._make_layer(out_channels[2], num_blocks[2]),\n                nn.Conv2d(\n                    out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n                ),\n                nn.BatchNorm2d(out_channels[3]),\n                nn.ReLU(inplace=True),\n            ]\n        )\n\n        self.in_channels = out_channels[2]\n        self.block_extractor3 = nn.Sequential(\n            *[\n                self._make_layer(out_channels[2], num_blocks[2], stride=1),\n                nn.Conv2d(\n                    out_channels[2], out_channels[3], kernel_size=1, stride=1, padding=0, bias=False\n                ),\n                nn.BatchNorm2d(out_channels[3]),\n                nn.ReLU(inplace=True),\n            ]\n        )\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc1 = nn.Linear(out_channels[3], num_classes)\n        self.fc2 = nn.Linear(out_channels[3], num_classes)\n        self.fc3 = nn.Linear(out_channels[3], num_classes)\n\n    def _make_layer(self, out_channels, num_blocks, stride=2):\n        layers = [DownBlock(self.in_channels, out_channels, stride=stride)]\n        for i in range(num_blocks):\n            layers.append(BasicBlock(out_channels, is_last=(i == num_blocks - 1)))\n            self.in_channels = out_channels\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        ss_logits = []\n        for i in range(len(x)):\n            idx = i + 1\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = self.avg_pool(out)\n            out = out.view(out.size(0), -1)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n        return ss_logits", "\n\nclass ShuffleNetV2_Auxiliary(nn.Module):\n    def __init__(self, net_size, num_classes=100):\n        super(ShuffleNetV2_Auxiliary, self).__init__()\n        self.backbone = ShuffleNetV2(net_size, num_classes=num_classes)\n        self.auxiliary_classifier = Auxiliary_Classifier(net_size, num_classes=num_classes * 4)\n\n    def forward(self, x, grad=False):\n        feats, logit = self.backbone(x, is_feat=True)\n        if grad is False:\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        ss_logits = self.auxiliary_classifier(feats)\n        return logit, ss_logits", "\n\nconfigs = {\n    0.2: {\"out_channels\": (40, 80, 160, 512), \"num_blocks\": (3, 3, 3)},\n    0.3: {\"out_channels\": (40, 80, 160, 512), \"num_blocks\": (3, 7, 3)},\n    0.5: {\"out_channels\": (48, 96, 192, 1024), \"num_blocks\": (3, 7, 3)},\n    1: {\"out_channels\": (116, 232, 464, 1024), \"num_blocks\": (3, 7, 3)},\n    1.5: {\"out_channels\": (176, 352, 704, 1024), \"num_blocks\": (3, 7, 3)},\n    2: {\"out_channels\": (224, 488, 976, 2048), \"num_blocks\": (3, 7, 3)},\n}", "    2: {\"out_channels\": (224, 488, 976, 2048), \"num_blocks\": (3, 7, 3)},\n}\n\n\ndef ShuffleV2(**kwargs):\n    model = ShuffleNetV2(net_size=1, **kwargs)\n    return model\n\n\ndef ShuffleV2_aux(**kwargs):\n    model = ShuffleNetV2_Auxiliary(net_size=1, **kwargs)\n    return model", "\ndef ShuffleV2_aux(**kwargs):\n    model = ShuffleNetV2_Auxiliary(net_size=1, **kwargs)\n    return model\n"]}
{"filename": "models/SmallResolutionModel/__init__.py", "chunked_list": ["from .mobilenetv2 import *\nfrom .resnet import *\nfrom .resnet_imagenet import *\nfrom .resnetv2 import *\nfrom .ShuffleNetv1 import *\nfrom .ShuffleNetv2 import *\nfrom .vgg import *\nfrom .wrn import *\nfrom .cifar10_resnet import WideResNet_70_16, WideResNet_70_16_dropout\nfrom .jem_wideresnet import Wide_ResNet", "from .cifar10_resnet import WideResNet_70_16, WideResNet_70_16_dropout\nfrom .jem_wideresnet import Wide_ResNet\nfrom .igebm import IGEBM"]}
{"filename": "models/SmallResolutionModel/resnetv2.py", "chunked_list": ["\"\"\"ResNet in PyTorch.\nFor Pre-activation ResNet, see 'preact_resnet.py'.\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n", "import torch.nn.functional as F\n\n__all__ = [\"ResNet50_aux\"]\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, is_last=False):\n        super(BasicBlock, self).__init__()\n        self.is_last = is_last\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        preact = out\n        out = F.relu(out)\n        if self.is_last:\n            return out, preact\n        else:\n            return out", "\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1, is_last=False):\n        super(Bottleneck, self).__init__()\n        self.is_last = is_last\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False\n                ),\n                nn.BatchNorm2d(self.expansion * planes),\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out", "\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10, zero_init_residual=False):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n        self.last_channel = 512 * block.expansion\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.bn1)\n        feat_m.append(self.layer1)\n        feat_m.append(self.layer2)\n        feat_m.append(self.layer3)\n        feat_m.append(self.layer4)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        if isinstance(self.layer1[0], Bottleneck):\n            bn1 = self.layer1[-1].bn3\n            bn2 = self.layer2[-1].bn3\n            bn3 = self.layer3[-1].bn3\n            bn4 = self.layer4[-1].bn3\n        elif isinstance(self.layer1[0], BasicBlock):\n            bn1 = self.layer1[-1].bn2\n            bn2 = self.layer2[-1].bn2\n            bn3 = self.layer3[-1].bn2\n            bn4 = self.layer4[-1].bn2\n        else:\n            raise NotImplementedError(\"ResNet unknown block error !!!\")\n\n        return [bn1, bn2, bn3, bn4]\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for i in range(num_blocks):\n            stride = strides[i]\n            layers.append(block(self.in_planes, planes, stride, i == num_blocks - 1))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x, is_feat=False, preact=False):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        f1 = out\n        out = self.layer2(out)\n        f2 = out\n        out = self.layer3(out)\n        f3 = out\n        out = self.layer4(out)\n        f4 = out\n        out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        if is_feat:\n            return [f1, f2, f3, f4], out\n        else:\n            return out", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10, zero_init_residual=False):\n        super(Auxiliary_Classifier, self).__init__()\n\n        self.in_planes = 64 * block.expansion\n        self.block_extractor1 = nn.Sequential(\n            *[\n                self._make_layer(block, 128, num_blocks[1], stride=2),\n                self._make_layer(block, 256, num_blocks[2], stride=2),\n                self._make_layer(block, 512, num_blocks[3], stride=2),\n            ]\n        )\n\n        self.in_planes = 128 * block.expansion\n        self.block_extractor2 = nn.Sequential(\n            *[\n                self._make_layer(block, 256, num_blocks[2], stride=2),\n                self._make_layer(block, 512, num_blocks[3], stride=2),\n            ]\n        )\n\n        self.in_planes = 256 * block.expansion\n        self.block_extractor3 = nn.Sequential(\n            *[self._make_layer(block, 512, num_blocks[3], stride=2)]\n        )\n\n        self.in_planes = 512 * block.expansion\n        self.block_extractor4 = nn.Sequential(\n            *[self._make_layer(block, 512, num_blocks[3], stride=1)]\n        )\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc1 = nn.Linear(512 * block.expansion, num_classes)\n        self.fc2 = nn.Linear(512 * block.expansion, num_classes)\n        self.fc3 = nn.Linear(512 * block.expansion, num_classes)\n        self.fc4 = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for i in range(num_blocks):\n            stride = strides[i]\n            layers.append(block(self.in_planes, planes, stride, i == num_blocks - 1))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        ss_logits = []\n        for i in range(len(x)):\n            idx = i + 1\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = self.avg_pool(out)\n            out = out.view(out.size(0), -1)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n        return ss_logits", "\n\nclass ResNet_Auxiliary(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10, zero_init_residual=False):\n        super(ResNet_Auxiliary, self).__init__()\n        self.backbone = ResNet(\n            block, num_blocks, num_classes=num_classes, zero_init_residual=zero_init_residual\n        )\n        self.auxiliary_classifier = Auxiliary_Classifier(\n            block, num_blocks, num_classes=num_classes * 4, zero_init_residual=zero_init_residual\n        )\n\n    def forward(self, x, grad=False):\n        if grad is False:\n            feats, logit = self.backbone(x, is_feat=True)\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        else:\n            feats, logit = self.backbone(x, is_feat=True)\n\n        ss_logits = self.auxiliary_classifier(feats)\n        return logit, ss_logits", "\n\ndef ResNet18(**kwargs):\n    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n\n\ndef ResNet34(**kwargs):\n    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n\n\ndef ResNet50(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)", "\n\ndef ResNet50(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n\n\ndef ResNet50_aux(**kwargs):\n    return ResNet_Auxiliary(Bottleneck, [3, 4, 6, 3], **kwargs)\n\n\ndef ResNet101(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)", "\n\ndef ResNet101(**kwargs):\n    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n\n\ndef ResNet152(**kwargs):\n    return ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n", ""]}
{"filename": "models/SmallResolutionModel/utils.py", "chunked_list": ["from __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef cal_param_size(model):\n    return sum([i.numel() for i in model.parameters()])\n", "\n\ncount_ops = 0\n\n\ndef measure_layer(layer, x, multi_add=1):\n    delta_ops = 0\n    type_name = str(layer)[: str(layer).find(\"(\")].strip()\n\n    if type_name in [\"Conv2d\"]:\n        out_h = int(\n            (x.size()[2] + 2 * layer.padding[0] - layer.kernel_size[0]) // layer.stride[0] + 1\n        )\n        out_w = int(\n            (x.size()[3] + 2 * layer.padding[1] - layer.kernel_size[1]) // layer.stride[1] + 1\n        )\n        delta_ops = (\n            layer.in_channels\n            * layer.out_channels\n            * layer.kernel_size[0]\n            * layer.kernel_size[1]\n            * out_h\n            * out_w\n            // layer.groups\n            * multi_add\n        )\n\n    ### ops_linear\n    elif type_name in [\"Linear\"]:\n        weight_ops = layer.weight.numel() * multi_add\n        bias_ops = 0\n        delta_ops = weight_ops + bias_ops\n\n    global count_ops\n    count_ops += delta_ops\n    return", "\n\ndef is_leaf(module):\n    return sum(1 for x in module.children()) == 0\n\n\ndef should_measure(module):\n    if str(module).startswith(\"Sequential\"):\n        return False\n    if is_leaf(module):\n        return True\n    return False", "\n\ndef cal_multi_adds(model, shape=(2, 3, 32, 32)):\n    global count_ops\n    count_ops = 0\n    data = torch.zeros(shape)\n\n    def new_forward(m):\n        def lambda_forward(x):\n            measure_layer(m, x)\n            return m.old_forward(x)\n\n        return lambda_forward\n\n    def modify_forward(model):\n        for child in model.children():\n            if should_measure(child):\n                child.old_forward = child.forward\n                child.forward = new_forward(child)\n            else:\n                modify_forward(child)\n\n    def restore_forward(model):\n        for child in model.children():\n            if is_leaf(child) and hasattr(child, \"old_forward\"):\n                child.forward = child.old_forward\n                child.old_forward = None\n            else:\n                restore_forward(child)\n\n    modify_forward(model)\n    model.forward(data)\n    restore_forward(model)\n\n    return count_ops", ""]}
{"filename": "models/SmallResolutionModel/vgg.py", "chunked_list": ["\"\"\"VGG for CIFAR10. FC layers are removed.\n(c) YANG, Wei\n\n\nadding hyperparameter norm_layer: Huanran Chen\n\"\"\"\n\nimport math\n\nimport torch.nn as nn", "\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [\"vgg13_bn_aux\", \"vgg13_bn\", \"vgg13_bn_spkd\", \"vgg13_bn_crd\", \"vgg8_bn\"]\n\nmodel_urls = {\n    \"vgg11\": \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\",\n    \"vgg13\": \"https://download.pytorch.org/models/vgg13-c768596a.pth\",\n    \"vgg16\": \"https://download.pytorch.org/models/vgg16-397923af.pth\",", "    \"vgg13\": \"https://download.pytorch.org/models/vgg13-c768596a.pth\",\n    \"vgg16\": \"https://download.pytorch.org/models/vgg16-397923af.pth\",\n    \"vgg19\": \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\",\n}\n\n\nclass Normalizer4CRD(nn.Module):\n    def __init__(self, linear, power=2):\n        super().__init__()\n        self.linear = linear\n        self.power = power\n\n    def forward(self, x):\n        x = x.flatten(1)\n        z = self.linear(x)\n        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n        out = z.div(norm)\n        return out", "\n\nclass VGG(nn.Module):\n    def __init__(self, cfg, batch_norm=False, num_classes=1000,\n                 norm_layer=nn.BatchNorm2d):\n        super(VGG, self).__init__()\n        self.block0 = self._make_layers(cfg[0], batch_norm, 3, norm_layer)\n        self.block1 = self._make_layers(cfg[1], batch_norm, cfg[0][-1], norm_layer)\n        self.block2 = self._make_layers(cfg[2], batch_norm, cfg[1][-1], norm_layer)\n        self.block3 = self._make_layers(cfg[3], batch_norm, cfg[2][-1], norm_layer)\n        self.block4 = self._make_layers(cfg[4], batch_norm, cfg[3][-1], norm_layer)\n\n        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))\n        # self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.last_channel = 512\n        self.classifier = nn.Linear(512, num_classes)\n        self._initialize_weights()\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.block0)\n        feat_m.append(self.pool0)\n        feat_m.append(self.block1)\n        feat_m.append(self.pool1)\n        feat_m.append(self.block2)\n        feat_m.append(self.pool2)\n        feat_m.append(self.block3)\n        feat_m.append(self.pool3)\n        feat_m.append(self.block4)\n        feat_m.append(self.pool4)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        bn1 = self.block1[-1]\n        bn2 = self.block2[-1]\n        bn3 = self.block3[-1]\n        bn4 = self.block4[-1]\n        return [bn1, bn2, bn3, bn4]\n\n    def forward(self, x, is_feat=False, preact=False):\n        h = x.shape[2]\n        x = F.relu(self.block0(x))\n        f0 = x\n\n        x = self.pool0(x)\n        x = self.block1(x)\n        x = F.relu(x)\n        f1 = x\n\n        x = self.pool1(x)\n        x = self.block2(x)\n        x = F.relu(x)\n        f2 = x\n\n        x = self.pool2(x)\n        x = self.block3(x)\n        x = F.relu(x)\n        if h == 64:\n            x = self.pool3(x)\n        x = self.block4(x)\n        x = F.relu(x)\n        f3 = x\n\n        x = self.pool4(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n\n        if is_feat:\n            return [f0, f1, f2, f3], x\n        else:\n            return x\n\n    @staticmethod\n    def _make_layers(cfg, batch_norm=False, in_channels=3, norm_layer=nn.BatchNorm2d):\n        layers = []\n        for v in cfg:\n            if v == \"M\":\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n                if batch_norm:\n                    layers += [conv2d, norm_layer(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        layers = layers[:-1]\n        return nn.Sequential(*layers)\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(self, cfg, batch_norm=False, num_classes=100):\n        super(Auxiliary_Classifier, self).__init__()\n\n        self.block_extractor1 = nn.Sequential(\n            *[\n                nn.MaxPool2d(kernel_size=2, stride=2),\n                self._make_layers(cfg[1], batch_norm, cfg[0][-1]),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=2, stride=2),\n                self._make_layers(cfg[2], batch_norm, cfg[1][-1]),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=2, stride=2),\n                self._make_layers(cfg[3], batch_norm, cfg[2][-1]),\n                nn.ReLU(inplace=True),\n                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n                nn.ReLU(inplace=True),\n                nn.AdaptiveAvgPool2d((1, 1)),\n            ]\n        )\n\n        self.block_extractor2 = nn.Sequential(\n            *[\n                nn.MaxPool2d(kernel_size=2, stride=2),\n                self._make_layers(cfg[2], batch_norm, cfg[1][-1]),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=2, stride=2),\n                self._make_layers(cfg[3], batch_norm, cfg[2][-1]),\n                nn.ReLU(inplace=True),\n                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n                nn.ReLU(inplace=True),\n                nn.AdaptiveAvgPool2d((1, 1)),\n            ]\n        )\n\n        self.block_extractor3 = nn.Sequential(\n            *[\n                nn.MaxPool2d(kernel_size=2, stride=2),\n                self._make_layers(cfg[3], batch_norm, cfg[2][-1]),\n                nn.ReLU(inplace=True),\n                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n                nn.ReLU(inplace=True),\n                nn.AdaptiveAvgPool2d((1, 1)),\n            ]\n        )\n\n        self.block_extractor4 = nn.Sequential(\n            *[\n                self._make_layers(cfg[3], batch_norm, cfg[4][-1]),\n                nn.ReLU(inplace=True),\n                self._make_layers(cfg[4], batch_norm, cfg[3][-1]),\n                nn.ReLU(inplace=True),\n                nn.AdaptiveAvgPool2d((1, 1)),\n            ]\n        )\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc1 = nn.Linear(512, num_classes)\n        self.fc2 = nn.Linear(512, num_classes)\n        self.fc3 = nn.Linear(512, num_classes)\n        self.fc4 = nn.Linear(512, num_classes)\n\n        def _initialize_weights(self):\n            for m in self.modules():\n                if isinstance(m, nn.Conv2d):\n                    n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                    m.weight.data.normal_(0, math.sqrt(2.0 / n))\n                    if m.bias is not None:\n                        m.bias.data.zero_()\n                elif isinstance(m, nn.BatchNorm2d):\n                    m.weight.data.fill_(1)\n                    m.bias.data.zero_()\n                elif isinstance(m, nn.Linear):\n                    n = m.weight.size(1)\n                    m.weight.data.normal_(0, 0.01)\n                    m.bias.data.zero_()\n\n    @staticmethod\n    def _make_layers(cfg, batch_norm=False, in_channels=3):\n        layers = []\n        for v in cfg:\n            if v == \"M\":\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        layers = layers[:-1]\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        ss_logits = []\n        for i in range(len(x)):\n            idx = i + 1\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = out.view(-1, 512)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n        return ss_logits", "\n\nclass VGG_Auxiliary(nn.Module):\n    def __init__(self, cfg, batch_norm=False, num_classes=100):\n        super(VGG_Auxiliary, self).__init__()\n        self.backbone = VGG(cfg, batch_norm=batch_norm, num_classes=num_classes)\n        self.auxiliary_classifier = Auxiliary_Classifier(\n            cfg, batch_norm=batch_norm, num_classes=num_classes * 4\n        )\n\n    def forward(self, x, grad=False):\n        feats, logit = self.backbone(x, is_feat=True)\n        if grad is False:\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        ss_logits = self.auxiliary_classifier(feats)\n        return logit, ss_logits", "\n\nclass VGG_SPKD(VGG):\n    def __init__(self, cfg, batch_norm=False, num_classes=1000):\n        super(VGG_SPKD, self).__init__(cfg, batch_norm, num_classes)\n\n    def forward(self, x):\n        h = x.shape[2]\n        x = F.relu(self.block0(x))\n\n        x = self.pool0(x)\n        x = self.block1(x)\n        x = F.relu(x)\n\n        x = self.pool1(x)\n        x = self.block2(x)\n        x = F.relu(x)\n\n        x = self.pool2(x)\n        x = self.block3(x)\n        x = F.relu(x)\n        if h == 64:\n            x = self.pool3(x)\n        x = self.block4(x)\n        x = F.relu(x)\n        f3 = x\n\n        x = self.pool4(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return f3, x", "\n\ncfg = {\n    \"A\": [[64], [128], [256, 256], [512, 512], [512, 512]],\n    \"B\": [[64, 64], [128, 128], [256, 256], [512, 512], [512, 512]],\n    \"D\": [[64, 64], [128, 128], [256, 256, 256], [512, 512, 512], [512, 512, 512]],\n    \"E\": [[64, 64], [128, 128], [256, 256, 256, 256], [512, 512, 512, 512], [512, 512, 512, 512]],\n    \"S\": [[64], [128], [256], [512], [512]],\n}\n", "}\n\n\nclass VGG_CRD(nn.Module):\n    def __init__(self, cfg, batch_norm=False, num_classes=1000):\n        super(VGG_CRD, self).__init__()\n        self.block0 = self._make_layers(cfg[0], batch_norm, 3)\n        self.block1 = self._make_layers(cfg[1], batch_norm, cfg[0][-1])\n        self.block2 = self._make_layers(cfg[2], batch_norm, cfg[1][-1])\n        self.block3 = self._make_layers(cfg[3], batch_norm, cfg[2][-1])\n        self.block4 = self._make_layers(cfg[4], batch_norm, cfg[3][-1])\n\n        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))\n        # self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.classifier = nn.Linear(512, num_classes)\n        linear = nn.Linear(512, 128, bias=True)\n        self.normalizer = Normalizer4CRD(linear, power=2)\n        self._initialize_weights()\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.block0)\n        feat_m.append(self.pool0)\n        feat_m.append(self.block1)\n        feat_m.append(self.pool1)\n        feat_m.append(self.block2)\n        feat_m.append(self.pool2)\n        feat_m.append(self.block3)\n        feat_m.append(self.pool3)\n        feat_m.append(self.block4)\n        feat_m.append(self.pool4)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        bn1 = self.block1[-1]\n        bn2 = self.block2[-1]\n        bn3 = self.block3[-1]\n        bn4 = self.block4[-1]\n        return [bn1, bn2, bn3, bn4]\n\n    def forward(self, x):\n        h = x.shape[2]\n        x = F.relu(self.block0(x))\n\n        x = self.pool0(x)\n        x = self.block1(x)\n        x = F.relu(x)\n\n        x = self.pool1(x)\n        x = self.block2(x)\n        x = F.relu(x)\n\n        x = self.pool2(x)\n        x = self.block3(x)\n        x = F.relu(x)\n        if h == 64:\n            x = self.pool3(x)\n        x = self.block4(x)\n        x = F.relu(x)\n\n        x = self.pool4(x)\n        crdout = x\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        crdout = self.normalizer(crdout)\n        return crdout, x\n\n    @staticmethod\n    def _make_layers(cfg, batch_norm=False, in_channels=3):\n        layers = []\n        for v in cfg:\n            if v == \"M\":\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        layers = layers[:-1]\n        return nn.Sequential(*layers)\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()", "\n\ndef vgg8(**kwargs):\n    \"\"\"VGG 8-layer model (configuration \"S\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"S\"], **kwargs)\n    return model\n", "\n\ndef vgg8_bn(**kwargs):\n    \"\"\"VGG 8-layer model (configuration \"S\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"S\"], batch_norm=True, **kwargs)\n    return model\n", "\n\ndef vgg8_bn_aux(**kwargs):\n    \"\"\"VGG 8-layer model (configuration \"S\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG_Auxiliary(cfg[\"S\"], batch_norm=True, **kwargs)\n    return model\n", "\n\ndef vgg8_bn_spkd(**kwargs):\n    \"\"\"VGG 8-layer model (configuration \"S\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG_SPKD(cfg[\"S\"], batch_norm=True, **kwargs)\n    return model\n", "\n\ndef vgg8_bn_crd(**kwargs):\n    \"\"\"VGG 8-layer model (configuration \"S\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG_CRD(cfg[\"S\"], batch_norm=True, **kwargs)\n    return model\n", "\n\ndef vgg11(**kwargs):\n    \"\"\"VGG 11-layer model (configuration \"A\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"A\"], **kwargs)\n    return model\n", "\n\ndef vgg11_bn(**kwargs):\n    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n    model = VGG(cfg[\"A\"], batch_norm=True, **kwargs)\n    return model\n\n\ndef vgg13(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"B\"], **kwargs)\n    return model", "def vgg13(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"B\"], **kwargs)\n    return model\n\n\ndef vgg13_bn(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n    model = VGG(cfg[\"B\"], batch_norm=True, **kwargs)\n    return model", "\ndef vgg13_bn(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n    model = VGG(cfg[\"B\"], batch_norm=True, **kwargs)\n    return model\n\n\ndef vgg13_bn_aux(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n    model = VGG_Auxiliary(cfg[\"B\"], batch_norm=True, **kwargs)\n    return model", "\n\ndef vgg13_bn_spkd(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n    model = VGG_SPKD(cfg[\"B\"], batch_norm=True, **kwargs)\n    return model\n\n\ndef vgg13_bn_crd(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n    model = VGG_CRD(cfg[\"B\"], batch_norm=True, **kwargs)\n    return model", "def vgg13_bn_crd(**kwargs):\n    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n    model = VGG_CRD(cfg[\"B\"], batch_norm=True, **kwargs)\n    return model\n\n\ndef vgg16(**kwargs):\n    \"\"\"VGG 16-layer model (configuration \"D\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"D\"], **kwargs)\n    return model", "\n\ndef vgg16_bn(**kwargs):\n    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n    model = VGG(cfg[\"D\"], batch_norm=True, **kwargs)\n    return model\n\n\ndef vgg19(**kwargs):\n    \"\"\"VGG 19-layer model (configuration \"E\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"E\"], **kwargs)\n    return model", "def vgg19(**kwargs):\n    \"\"\"VGG 19-layer model (configuration \"E\")\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = VGG(cfg[\"E\"], **kwargs)\n    return model\n\n\ndef vgg19_bn(**kwargs):\n    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n    model = VGG(cfg[\"E\"], batch_norm=True, **kwargs)\n    return model", "\ndef vgg19_bn(**kwargs):\n    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n    model = VGG(cfg[\"E\"], batch_norm=True, **kwargs)\n    return model\n"]}
{"filename": "models/SmallResolutionModel/resnet.py", "chunked_list": ["from __future__ import absolute_import\n\n\"\"\"Resnet for cifar dataset.\nPorted form\nhttps://github.com/facebook/fb.resnet.torch\nand\nhttps://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n(c) YANG, Wei\n\n", "\n\nadding hyperparameter norm_layers\nHuanran Chen\n\"\"\"\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n", "import torch.nn.functional as F\n\n__all__ = [\n    \"resnet56_aux\",\n    \"resnet20_aux\",\n    \"resnet32x4_aux\",\n    \"resnet8x4_aux\",\n    \"resnet8\",\n    \"resnet8x4\",\n    \"resnet20\",", "    \"resnet8x4\",\n    \"resnet20\",\n    \"resnet32\",\n    \"resnet56\",\n    \"resnet110\",\n    \"resnet8_spkd\",\n    \"resnet20_spkd\",\n    \"resnet56_spkd\",\n    \"resnet8x4_spkd\",\n    \"resnet32x4_spkd\",", "    \"resnet8x4_spkd\",\n    \"resnet32x4_spkd\",\n    \"resnet32x4\",\n    \"resnet8_crd\",\n    \"resnet20_crd\",\n    \"resnet56_crd\",\n    \"resnet8x4_crd\",\n    \"resnet32x4_crd\",\n]\n", "]\n\n\nclass Swish(nn.Module):\n    def __init__(self, **kwargs):\n        super(Swish, self).__init__()\n\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n", "\n\nclass Normalizer4CRD(nn.Module):\n    def __init__(self, linear, power=2):\n        super().__init__()\n        self.linear = linear\n        self.power = power\n\n    def forward(self, x):\n        x = x.flatten(1)\n        z = self.linear(x)\n        norm = z.pow(self.power).sum(1, keepdim=True).pow(1.0 / self.power)\n        out = z.div(norm)\n        return out", "\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, is_last=False,\n                 norm_layer=nn.BatchNorm2d):\n        super(BasicBlock, self).__init__()\n        self.is_last = is_last\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = Swish(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = F.relu(out)\n        return out", "\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, is_last=False,\n                 norm_layer=nn.BatchNorm2d):\n        super(Bottleneck, self).__init__()\n        self.is_last = is_last\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = norm_layer(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = norm_layer(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = norm_layer(planes * 4)\n        self.relu = Swish(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = F.relu(out)\n        return out", "\n\nclass ResNet(nn.Module):\n    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10,\n                 norm_layer=nn.BatchNorm2d):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        if block_name.lower() == \"basicblock\":\n            assert (\n                           depth - 2\n                   ) % 6 == 0, \"When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\"\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name.lower() == \"bottleneck\":\n            assert (\n                           depth - 2\n                   ) % 9 == 0, \"When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\"\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError(\"block_name shoule be Basicblock or Bottleneck\")\n\n        self.inplanes = num_filters[0]\n        self.conv1 = nn.Conv2d(3, num_filters[0], kernel_size=3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(num_filters[0])\n        self.relu = Swish(inplace=True)\n        self.layer1 = self._make_layer(block, num_filters[1], n, norm_layer)\n        self.layer2 = self._make_layer(block, num_filters[2], n, norm_layer, stride=2)\n        self.layer3 = self._make_layer(block, num_filters[3], n, norm_layer, stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(num_filters[3] * block.expansion, num_classes)\n        self.last_channel = num_filters[3] * block.expansion\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, norm_layer, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = list([])\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.bn1)\n        feat_m.append(self.relu)\n        feat_m.append(self.layer1)\n        feat_m.append(self.layer2)\n        feat_m.append(self.layer3)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        if isinstance(self.layer1[0], Bottleneck):\n            bn1 = self.layer1[-1].bn3\n            bn2 = self.layer2[-1].bn3\n            bn3 = self.layer3[-1].bn3\n        elif isinstance(self.layer1[0], BasicBlock):\n            bn1 = self.layer1[-1].bn2\n            bn2 = self.layer2[-1].bn2\n            bn3 = self.layer3[-1].bn2\n        else:\n            raise NotImplementedError(\"ResNet unknown block error !!!\")\n\n        return [bn1, bn2, bn3]\n\n    def forward(self, x, is_feat=False):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)  # 32x32\n\n        x = self.layer1(x)  # 32x32\n        f1 = x\n        x = self.layer2(x)  # 16x16\n        f2 = x\n        x = self.layer3(x)  # 8x8\n        f3 = x\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = x.sum(1)\n        # x = self.fc(x)\n\n        if is_feat:\n            return [f1, f2, f3, f3], x\n        else:\n            return x", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=100):\n        super(Auxiliary_Classifier, self).__init__()\n        if block_name.lower() == \"basicblock\":\n            assert (\n                           depth - 2\n                   ) % 6 == 0, \"When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\"\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name.lower() == \"bottleneck\":\n            assert (\n                           depth - 2\n                   ) % 9 == 0, \"When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\"\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError(\"block_name shoule be Basicblock or Bottleneck\")\n\n        self.inplanes = num_filters[1] * block.expansion\n        self.block_extractor1 = nn.Sequential(\n            *[\n                self._make_layer(block, num_filters[2], n, stride=2),\n                self._make_layer(block, num_filters[3], n, stride=2),\n            ]\n        )\n        self.inplanes = num_filters[2] * block.expansion\n        self.block_extractor2 = nn.Sequential(\n            *[self._make_layer(block, num_filters[3], n, stride=2)]\n        )\n        self.inplanes = num_filters[3] * block.expansion\n        self.block_extractor3 = nn.Sequential(\n            *[self._make_layer(block, num_filters[3], n, stride=1)]\n        )\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc1 = nn.Linear(num_filters[3] * block.expansion, num_classes)\n        self.fc2 = nn.Linear(num_filters[3] * block.expansion, num_classes)\n        self.fc3 = nn.Linear(num_filters[3] * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = list([])\n        layers.append(block(self.inplanes, planes, stride, downsample, is_last=(blocks == 1)))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, is_last=(i == blocks - 1)))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        ss_logits = []\n        ss_feats = []\n        for i in range(len(x)):\n            idx = i + 1\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = self.avg_pool(out)\n            out = out.view(out.size(0), -1)\n            ss_feats.append(out)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n\n        return ss_feats, ss_logits", "\n\nclass ResNet_Auxiliary(nn.Module):\n    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10):\n        super(ResNet_Auxiliary, self).__init__()\n        self.backbone = ResNet(depth, num_filters, block_name, num_classes)\n        self.auxiliary_classifier = Auxiliary_Classifier(\n            depth, num_filters, block_name, num_classes=num_classes * 4\n        )\n\n    def forward(self, x, grad=False, att=False):\n        feats, logit = self.backbone(x, is_feat=True)\n        if grad is False:\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        ss_feats, ss_logits = self.auxiliary_classifier(feats)\n        if att is False:\n            return logit, ss_logits\n        else:\n            return logit, ss_logits, feats", "\n\nclass ResNet_SPKD(ResNet):\n    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10):\n        super(ResNet_SPKD, self).__init__(depth, num_filters, block_name, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)  # 32x32\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n        f3 = x\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return f3, x", "\n\nclass ResNet_CRD(nn.Module):\n    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=10):\n        super(ResNet_CRD, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        if block_name.lower() == \"basicblock\":\n            assert (\n                           depth - 2\n                   ) % 6 == 0, \"When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\"\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name.lower() == \"bottleneck\":\n            assert (\n                           depth - 2\n                   ) % 9 == 0, \"When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199\"\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError(\"block_name shoule be Basicblock or Bottleneck\")\n\n        self.inplanes = num_filters[0]\n        self.conv1 = nn.Conv2d(3, num_filters[0], kernel_size=3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(num_filters[0])\n        self.relu = Swish(inplace=True)\n        self.layer1 = self._make_layer(block, num_filters[1], n)\n        self.layer2 = self._make_layer(block, num_filters[2], n, stride=2)\n        self.layer3 = self._make_layer(block, num_filters[3], n, stride=2)\n        # self.avgpool = nn.Pool((1, 1))\n        self.fc = nn.Linear(num_filters[3] * block.expansion, num_classes)\n        linear = nn.Linear(num_filters[3] * block.expansion, 128, bias=True)\n        self.normalizer = Normalizer4CRD(linear, power=2)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = list([])\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.bn1)\n        feat_m.append(self.relu)\n        feat_m.append(self.layer1)\n        feat_m.append(self.layer2)\n        feat_m.append(self.layer3)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        if isinstance(self.layer1[0], Bottleneck):\n            bn1 = self.layer1[-1].bn3\n            bn2 = self.layer2[-1].bn3\n            bn3 = self.layer3[-1].bn3\n        elif isinstance(self.layer1[0], BasicBlock):\n            bn1 = self.layer1[-1].bn2\n            bn2 = self.layer2[-1].bn2\n            bn3 = self.layer3[-1].bn2\n        else:\n            raise NotImplementedError(\"ResNet unknown block error !!!\")\n\n        return [bn1, bn2, bn3]\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)  # 32x32\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n\n        # x = self.avgpool(x)\n        print(x.shape)\n        assert False\n        crdout = x\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        crdout = self.normalizer(crdout)\n        return crdout, x", "\n\ndef resnet8(**kwargs):\n    return ResNet(8, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet14(**kwargs):\n    return ResNet(14, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet20(**kwargs):\n    return ResNet(20, [16, 16, 32, 64], \"basicblock\", **kwargs)", "\n\ndef resnet20(**kwargs):\n    return ResNet(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet8_spkd(**kwargs):\n    return ResNet_SPKD(8, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet14_spkd(**kwargs):\n    return ResNet_SPKD(14, [16, 16, 32, 64], \"basicblock\", **kwargs)", "\n\ndef resnet14_spkd(**kwargs):\n    return ResNet_SPKD(14, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet20_spkd(**kwargs):\n    return ResNet_SPKD(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet8_crd(**kwargs):\n    return ResNet_CRD(8, [16, 16, 32, 64], \"basicblock\", **kwargs)", "\n\ndef resnet8_crd(**kwargs):\n    return ResNet_CRD(8, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet14_crd(**kwargs):\n    return ResNet_CRD(14, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet20_crd(**kwargs):\n    return ResNet_CRD(20, [16, 16, 32, 64], \"basicblock\", **kwargs)", "\n\ndef resnet20_crd(**kwargs):\n    return ResNet_CRD(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet20_aux(**kwargs):\n    return ResNet_Auxiliary(20, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet14x05(**kwargs):\n    return ResNet(14, [8, 8, 16, 32], \"basicblock\", **kwargs)", "\n\ndef resnet14x05(**kwargs):\n    return ResNet(14, [8, 8, 16, 32], \"basicblock\", **kwargs)\n\n\ndef resnet20x05(**kwargs):\n    return ResNet(20, [8, 8, 16, 32], \"basicblock\", **kwargs)\n\n\ndef resnet20x0375(**kwargs):\n    return ResNet(20, [6, 6, 12, 24], \"basicblock\", **kwargs)", "\n\ndef resnet20x0375(**kwargs):\n    return ResNet(20, [6, 6, 12, 24], \"basicblock\", **kwargs)\n\n\ndef resnet32(**kwargs):\n    return ResNet(32, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet44(**kwargs):\n    return ResNet(44, [16, 16, 32, 64], \"basicblock\", **kwargs)", "\n\ndef resnet44(**kwargs):\n    return ResNet(44, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet56(**kwargs):\n    return ResNet(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet56_aux(**kwargs):\n    return ResNet_Auxiliary(56, [16, 16, 32, 64], \"basicblock\", **kwargs)", "\n\ndef resnet56_aux(**kwargs):\n    return ResNet_Auxiliary(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet56_spkd(**kwargs):\n    return ResNet_SPKD(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet56_crd(**kwargs):\n    return ResNet_CRD(56, [16, 16, 32, 64], \"basicblock\", **kwargs)", "\n\ndef resnet56_crd(**kwargs):\n    return ResNet_CRD(56, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet110(**kwargs):\n    return ResNet(110, [16, 16, 32, 64], \"basicblock\", **kwargs)\n\n\ndef resnet8x4(**kwargs):\n    return ResNet(8, [32, 64, 128, 256], \"basicblock\", **kwargs)", "\n\ndef resnet8x4(**kwargs):\n    return ResNet(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\n\ndef resnet8x4_aux(**kwargs):\n    return ResNet_Auxiliary(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\n\ndef resnet8x4_spkd(**kwargs):\n    return ResNet_SPKD(8, [32, 64, 128, 256], \"basicblock\", **kwargs)", "\n\ndef resnet8x4_spkd(**kwargs):\n    return ResNet_SPKD(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\n\ndef resnet8x4_crd(**kwargs):\n    return ResNet_CRD(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\n\ndef resnet32x4(**kwargs):\n    return ResNet(32, [32, 64, 128, 256], \"basicblock\", **kwargs)", "\n\ndef resnet32x4(**kwargs):\n    return ResNet(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\n\ndef resnet32x4_aux(**kwargs):\n    return ResNet_Auxiliary(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\n\ndef resnet32x4_spkd(**kwargs):\n    return ResNet_SPKD(32, [32, 64, 128, 256], \"basicblock\", **kwargs)", "\n\ndef resnet32x4_spkd(**kwargs):\n    return ResNet_SPKD(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n\n\ndef resnet32x4_crd(**kwargs):\n    return ResNet_CRD(32, [32, 64, 128, 256], \"basicblock\", **kwargs)\n", ""]}
{"filename": "models/SmallResolutionModel/jem_wideresnet.py", "chunked_list": ["# coding=utf-8\n# Copyright 2019 The Google Research Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software", "#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F", "import torch.nn.init as init\nimport torch.nn.functional as F\n# coding=utf-8\n# Copyright 2019 The Google Research Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0", "#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport torch", "\nimport torch\nimport torch.nn as nn\n\n\nclass ConditionalInstanceNorm2dPlus(nn.Module):\n    def __init__(self, num_features, num_classes, bias=True):\n        super().__init__()\n        self.num_features = num_features\n        self.bias = bias\n        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n        if bias:\n            self.embed = nn.Embedding(num_classes, num_features * 3)\n            self.embed.weight.data[:, :2 * num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n            self.embed.weight.data[:, 2 * num_features:].zero_()  # Initialise bias at 0\n        else:\n            self.embed = nn.Embedding(num_classes, 2 * num_features)\n            self.embed.weight.data.normal_(1, 0.02)\n\n    def forward(self, x, y):\n        means = torch.mean(x, dim=(2, 3))\n        m = torch.mean(means, dim=-1, keepdim=True)\n        v = torch.var(means, dim=-1, keepdim=True)\n        means = (means - m) / (torch.sqrt(v + 1e-5))\n        h = self.instance_norm(x)\n\n        if self.bias:\n            gamma, alpha, beta = self.embed(y).chunk(3, dim=-1)\n            h = h + means[..., None, None] * alpha[..., None, None]\n            out = gamma.view(-1, self.num_features, 1, 1) * h + beta.view(-1, self.num_features, 1, 1)\n        else:\n            gamma, alpha = self.embed(y).chunk(2, dim=-1)\n            h = h + means[..., None, None] * alpha[..., None, None]\n            out = gamma.view(-1, self.num_features, 1, 1) * h\n        return out", "\n\nclass ConditionalActNorm(nn.Module):\n    def __init__(self, num_features, num_classes):\n        super().__init__()\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.embed = nn.Embedding(num_classes, num_features * 2)\n        self.embed.weight.data.zero_()\n        self.init = False\n\n    def forward(self, x, y):\n        if self.init:\n            scale, bias = self.embed(y).chunk(2, dim=-1)\n            return x * scale[:, :, None, None] + bias[:, :, None, None]\n        else:\n            m, v = torch.mean(x, dim=(0, 2, 3)), torch.var(x, dim=(0, 2, 3))\n            std = torch.sqrt(v + 1e-5)\n            scale_init = 1. / std\n            bias_init = -1. * m / std\n            self.embed.weight.data[:, :self.num_features] = scale_init[None].repeat(self.num_classes, 1)\n            self.embed.weight.data[:, self.num_features:] = bias_init[None].repeat(self.num_classes, 1)\n            self.init = True\n            return self(x, y)", "\n\nlogabs = lambda x: torch.log(torch.abs(x))\n\n\nclass ActNorm(nn.Module):\n    def __init__(self, in_channel, logdet=True):\n        super().__init__()\n\n        self.loc = nn.Parameter(torch.zeros(1, in_channel, 1, 1))\n        self.scale = nn.Parameter(torch.ones(1, in_channel, 1, 1))\n\n        self.register_buffer('initialized', torch.tensor(0, dtype=torch.uint8))\n        self.logdet = logdet\n\n    def initialize(self, input):\n        with torch.no_grad():\n            flatten = input.permute(1, 0, 2, 3).contiguous().view(input.shape[1], -1)\n            mean = (\n                flatten.mean(1)\n                    .unsqueeze(1)\n                    .unsqueeze(2)\n                    .unsqueeze(3)\n                    .permute(1, 0, 2, 3)\n            )\n            std = (\n                flatten.std(1)\n                    .unsqueeze(1)\n                    .unsqueeze(2)\n                    .unsqueeze(3)\n                    .permute(1, 0, 2, 3)\n            )\n\n            self.loc.data.copy_(-mean)\n            self.scale.data.copy_(1 / (std + 1e-6))\n\n    def forward(self, input):\n        _, _, height, width = input.shape\n\n        if self.initialized.item() == 0:\n            self.initialize(input)\n            self.initialized.fill_(1)\n\n        log_abs = logabs(self.scale)\n\n        logdet = height * width * torch.sum(log_abs)\n\n        if self.logdet:\n            return self.scale * (input + self.loc), logdet\n\n        else:\n            return self.scale * (input + self.loc)\n\n    def reverse(self, output):\n        return output / self.scale - self.loc", "\n\nclass ContinuousConditionalActNorm(nn.Module):\n    def __init__(self, num_features, num_classes):\n        super().__init__()\n        del num_classes\n        self.num_features = num_features\n        self.embed = nn.Sequential(nn.Linear(1, 256),\n                                   nn.ELU(inplace=True),\n                                   nn.Linear(256, 256),\n                                   nn.ELU(inplace=True),\n                                   nn.Linear(256, self.num_features * 2),\n                                   )\n\n    def forward(self, x, y):\n        scale, bias = self.embed(y.unsqueeze(-1)).chunk(2, dim=-1)\n        return x * scale[:, :, None, None] + bias[:, :, None, None]", "\n\n# class Identity(nn.Module):\n#     def __init__(self):\n#         super(Identity, self).__init__()\n#\n#     def forward(self, *args, **kwargs):\n#         return\n\n", "\n\nimport numpy as np\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\n\ndef conv_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.xavier_uniform(m.weight, gain=np.sqrt(2))\n        init.constant(m.bias, 0)\n    elif classname.find('BatchNorm') != -1:\n        init.constant(m.weight, 1)\n        init.constant(m.bias, 0)", "\ndef conv_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.xavier_uniform(m.weight, gain=np.sqrt(2))\n        init.constant(m.bias, 0)\n    elif classname.find('BatchNorm') != -1:\n        init.constant(m.weight, 1)\n        init.constant(m.bias, 0)\n", "\n\nclass Identity(nn.Module):\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n\n    def forward(self, x):\n        return x\n\n\nclass wide_basic(nn.Module):\n    def __init__(self, in_planes, planes, dropout_rate, stride=1, norm=None, leak=.2):\n        super(wide_basic, self).__init__()\n        self.lrelu = nn.LeakyReLU(leak)\n        self.bn1 = get_norm(in_planes, norm)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n        self.dropout = Identity() if dropout_rate == 0.0 else nn.Dropout(p=dropout_rate)\n        self.bn2 = get_norm(planes, norm)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n            )\n\n    def forward(self, x):\n        out = self.dropout(self.conv1(self.lrelu(self.bn1(x))))\n        out = self.conv2(self.lrelu(self.bn2(out)))\n        out += self.shortcut(x)\n\n        return out", "\n\nclass wide_basic(nn.Module):\n    def __init__(self, in_planes, planes, dropout_rate, stride=1, norm=None, leak=.2):\n        super(wide_basic, self).__init__()\n        self.lrelu = nn.LeakyReLU(leak)\n        self.bn1 = get_norm(in_planes, norm)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n        self.dropout = Identity() if dropout_rate == 0.0 else nn.Dropout(p=dropout_rate)\n        self.bn2 = get_norm(planes, norm)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n            )\n\n    def forward(self, x):\n        out = self.dropout(self.conv1(self.lrelu(self.bn1(x))))\n        out = self.conv2(self.lrelu(self.bn2(out)))\n        out += self.shortcut(x)\n\n        return out", "\n\ndef get_norm(n_filters, norm):\n    if norm is None:\n        return Identity()\n    elif norm == \"batch\":\n        return nn.BatchNorm2d(n_filters, momentum=0.9)\n    elif norm == \"instance\":\n        return nn.InstanceNorm2d(n_filters, affine=True)\n    elif norm == \"layer\":\n        return nn.GroupNorm(1, n_filters)\n    elif norm == \"act\":\n        return ActNorm(n_filters, False)", "\n\nclass Wide_ResNet(nn.Module):\n    def __init__(self, depth=28, widen_factor=2, num_classes=1, input_channels=3,\n                 sum_pool=False, norm=None, leak=.2, dropout_rate=0.0):\n        super(Wide_ResNet, self).__init__()\n        self.leak = leak\n        self.in_planes = 16\n        self.sum_pool = sum_pool\n        self.norm = norm\n        self.lrelu = nn.LeakyReLU(leak)\n\n        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n        n = (depth - 4) // 6\n        k = widen_factor\n\n        print('| Wide-Resnet %dx%d' % (depth, k))\n        nStages = [16, 16 * k, 32 * k, 64 * k]\n\n        self.conv1 = conv3x3(input_channels, nStages[0])\n        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n        self.bn1 = get_norm(nStages[3], self.norm)\n        self.last_dim = nStages[3]\n        self.linear = nn.Linear(nStages[3], num_classes)\n\n    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, dropout_rate, stride, norm=self.norm))\n            self.in_planes = planes\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x, vx=None):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.lrelu(self.bn1(out))\n        if self.sum_pool:\n            out = out.view(out.size(0), out.size(1), -1).sum(2)\n        else:\n            out = F.avg_pool2d(out, 8)\n        out = out.view(out.size(0), -1)\n        return out", ""]}
{"filename": "models/SmallResolutionModel/ShuffleNetv1.py", "chunked_list": ["\"\"\"ShuffleNet in PyTorch.\nSee the paper \"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\" for more details.\n\"\"\"\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [\"ShuffleV1_aux\", \"ShuffleV1\"]", "\n__all__ = [\"ShuffleV1_aux\", \"ShuffleV1\"]\n\n\nclass ShuffleBlock(nn.Module):\n    def __init__(self, groups):\n        super(ShuffleBlock, self).__init__()\n        self.groups = groups\n\n    def forward(self, x):\n        \"\"\"Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]\"\"\"\n        N, C, H, W = x.size()\n        g = self.groups\n        return x.reshape(N, g, C // g, H, W).permute(0, 2, 1, 3, 4).reshape(N, C, H, W)", "\n\nclass Bottleneck(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, groups, is_last=False):\n        super(Bottleneck, self).__init__()\n        self.is_last = is_last\n        self.stride = stride\n\n        mid_planes = int(out_planes / 4)\n        g = 1 if in_planes == 24 else groups\n        self.conv1 = nn.Conv2d(in_planes, mid_planes, kernel_size=1, groups=g, bias=False)\n        self.bn1 = nn.BatchNorm2d(mid_planes)\n        self.shuffle1 = ShuffleBlock(groups=g)\n        self.conv2 = nn.Conv2d(\n            mid_planes,\n            mid_planes,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            groups=mid_planes,\n            bias=False,\n        )\n        self.bn2 = nn.BatchNorm2d(mid_planes)\n        self.conv3 = nn.Conv2d(mid_planes, out_planes, kernel_size=1, groups=groups, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_planes)\n\n        self.shortcut = nn.Sequential()\n        if stride == 2:\n            self.shortcut = nn.Sequential(nn.AvgPool2d(3, stride=2, padding=1))\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.shuffle1(out)\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        res = self.shortcut(x)\n        preact = torch.cat([out, res], 1) if self.stride == 2 else out + res\n        out = F.relu(preact)\n        # out = F.relu(torch.cat([out, res], 1)) if self.stride == 2 else F.relu(out+res)\n        if self.is_last:\n            return out, preact\n        else:\n            return out", "\n\nclass ShuffleNet(nn.Module):\n    def __init__(self, cfg, num_classes=10):\n        super(ShuffleNet, self).__init__()\n        out_planes = cfg[\"out_planes\"]\n        num_blocks = cfg[\"num_blocks\"]\n        groups = cfg[\"groups\"]\n\n        self.conv1 = nn.Conv2d(3, 24, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(24)\n        self.in_planes = 24\n        self.layer1 = self._make_layer(out_planes[0], num_blocks[0], groups)\n        self.layer2 = self._make_layer(out_planes[1], num_blocks[1], groups)\n        self.layer3 = self._make_layer(out_planes[2], num_blocks[2], groups)\n        self.linear = nn.Linear(out_planes[2], num_classes)\n        self.last_channel = out_planes[2]\n\n    def _make_layer(self, out_planes, num_blocks, groups):\n        layers = []\n        for i in range(num_blocks):\n            stride = 2 if i == 0 else 1\n            cat_planes = self.in_planes if i == 0 else 0\n            layers.append(\n                Bottleneck(\n                    self.in_planes,\n                    out_planes - cat_planes,\n                    stride=stride,\n                    groups=groups,\n                    is_last=(i == num_blocks - 1),\n                )\n            )\n            self.in_planes = out_planes\n        return nn.Sequential(*layers)\n\n    def get_feat_modules(self):\n        feat_m = nn.ModuleList([])\n        feat_m.append(self.conv1)\n        feat_m.append(self.bn1)\n        feat_m.append(self.layer1)\n        feat_m.append(self.layer2)\n        feat_m.append(self.layer3)\n        return feat_m\n\n    def get_bn_before_relu(self):\n        raise NotImplementedError('ShuffleNet currently is not supported for \"Overhaul\" teacher')\n\n    def forward(self, x, is_feat=False):\n        out = F.relu(self.bn1(self.conv1(x)))\n        f0 = out\n        out, f1_pre = self.layer1(out)\n        f1 = out\n        out, f2_pre = self.layer2(out)\n        f2 = out\n        out, f3_pre = self.layer3(out)\n        f3 = out\n        out = F.avg_pool2d(out, 4)\n        out = out.reshape(out.size(0), -1)\n        out = self.linear(out)\n        if is_feat:\n            return [f0, f1, f2, f3], out\n        else:\n            return out", "\n\nclass Auxiliary_Classifier(nn.Module):\n    def __init__(self, cfg, num_classes=10):\n        super(Auxiliary_Classifier, self).__init__()\n        out_planes = cfg[\"out_planes\"]\n        num_blocks = cfg[\"num_blocks\"]\n        groups = cfg[\"groups\"]\n\n        self.in_planes = out_planes[0]\n        self.block_extractor1 = nn.Sequential(\n            *[\n                self._make_layer(out_planes[1], num_blocks[1], groups),\n                self._make_layer(out_planes[2], num_blocks[2], groups),\n            ]\n        )\n        self.in_planes = out_planes[1]\n        self.block_extractor2 = nn.Sequential(\n            *[self._make_layer(out_planes[2], num_blocks[2], groups)]\n        )\n\n        self.inplanes = out_planes[2]\n        self.block_extractor3 = nn.Sequential(\n            *[self._make_layer(out_planes[2], num_blocks[2], groups, downsample=False)]\n        )\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc1 = nn.Linear(out_planes[2], num_classes)\n        self.fc2 = nn.Linear(out_planes[2], num_classes)\n        self.fc3 = nn.Linear(out_planes[2], num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def _make_layer(self, out_planes, num_blocks, groups, downsample=True):\n        layers = []\n        for i in range(num_blocks):\n            stride = 2 if i == 0 and downsample is True else 1\n            cat_planes = self.in_planes if i == 0 and downsample is True else 0\n            layers.append(\n                Bottleneck(\n                    self.in_planes,\n                    out_planes - cat_planes,\n                    stride=stride,\n                    groups=groups,\n                    is_last=(i == num_blocks - 1),\n                )\n            )\n            self.in_planes = out_planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        ss_logits = []\n        for i in range(len(x)):\n            idx = i + 1\n            out = getattr(self, \"block_extractor\" + str(idx))(x[i])\n            out = self.avg_pool(out)\n            out = out.view(out.size(0), -1)\n            out = getattr(self, \"fc\" + str(idx))(out)\n            ss_logits.append(out)\n        return ss_logits", "\n\nclass ShuffleNet_Auxiliary(nn.Module):\n    def __init__(self, cfg, num_classes=100):\n        super(ShuffleNet_Auxiliary, self).__init__()\n        self.backbone = ShuffleNet(cfg, num_classes=num_classes)\n        self.auxiliary_classifier = Auxiliary_Classifier(cfg, num_classes=num_classes * 4)\n\n    def forward(self, x, grad=False):\n        feats, logit = self.backbone(x, is_feat=True)\n        if grad is False:\n            for i in range(len(feats)):\n                feats[i] = feats[i].detach()\n        ss_logits = self.auxiliary_classifier(feats)\n        return logit, ss_logits", "\n\ndef ShuffleV1(**kwargs):\n    cfg = {\"out_planes\": [240, 480, 960], \"num_blocks\": [4, 8, 4], \"groups\": 3}\n    return ShuffleNet(cfg, **kwargs)\n\n\ndef ShuffleV1_aux(**kwargs):\n    cfg = {\"out_planes\": [240, 480, 960], \"num_blocks\": [4, 8, 4], \"groups\": 3}\n    return ShuffleNet_Auxiliary(cfg, **kwargs)", ""]}
{"filename": "models/SmallResolutionModel/igebm.py", "chunked_list": ["import torch\n\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.nn import utils\n\n\nclass SpectralNorm:\n    def __init__(self, name, bound=False):\n        self.name = name\n        self.bound = bound\n\n    def compute_weight(self, module):\n        weight = getattr(module, self.name + '_orig')\n        u = getattr(module, self.name + '_u')\n        size = weight.size()\n        weight_mat = weight.contiguous().view(size[0], -1)\n\n        with torch.no_grad():\n            v = weight_mat.t() @ u\n            v = v / v.norm()\n            u = weight_mat @ v\n            u = u / u.norm()\n\n        sigma = u @ weight_mat @ v\n\n        if self.bound:\n            weight_sn = weight / (sigma + 1e-6) * torch.clamp(sigma, max=1)\n\n        else:\n            weight_sn = weight / sigma\n\n        return weight_sn, u\n\n    @staticmethod\n    def apply(module, name, bound):\n        fn = SpectralNorm(name, bound)\n\n        weight = getattr(module, name)\n        del module._parameters[name]\n        module.register_parameter(name + '_orig', weight)\n        input_size = weight.size(0)\n        u = weight.new_empty(input_size).normal_()\n        module.register_buffer(name, weight)\n        module.register_buffer(name + '_u', u)\n\n        module.register_forward_pre_hook(fn)\n\n        return fn\n\n    def __call__(self, module, input):\n        weight_sn, u = self.compute_weight(module)\n        setattr(module, self.name, weight_sn)\n        setattr(module, self.name + '_u', u)", "\n\ndef spectral_norm(module, init=True, std=1, bound=False):\n    if init:\n        nn.init.normal_(module.weight, 0, std)\n\n    if hasattr(module, 'bias') and module.bias is not None:\n        module.bias.data.zero_()\n\n    SpectralNorm.apply(module, 'weight', bound=bound)\n\n    return module", "\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_channel, out_channel, n_class=None, downsample=False):\n        super().__init__()\n\n        self.conv1 = spectral_norm(\n            nn.Conv2d(\n                in_channel,\n                out_channel,\n                3,\n                padding=1,\n                bias=False if n_class is not None else True,\n            )\n        )\n\n        self.conv2 = spectral_norm(\n            nn.Conv2d(\n                out_channel,\n                out_channel,\n                3,\n                padding=1,\n                bias=False if n_class is not None else True,\n            ), std=1e-10, bound=True\n        )\n\n        self.class_embed = None\n\n        if n_class is not None:\n            class_embed = nn.Embedding(n_class, out_channel * 2 * 2)\n            class_embed.weight.data[:, : out_channel * 2] = 1\n            class_embed.weight.data[:, out_channel * 2 :] = 0\n\n            self.class_embed = class_embed\n\n        self.skip = None\n\n        if in_channel != out_channel or downsample:\n            self.skip = nn.Sequential(\n                spectral_norm(nn.Conv2d(in_channel, out_channel, 1, bias=False))\n            )\n\n        self.downsample = downsample\n\n    def forward(self, input, class_id=None):\n        out = input\n\n        out = self.conv1(out)\n\n        if self.class_embed is not None:\n            embed = self.class_embed(class_id).view(input.shape[0], -1, 1, 1)\n            weight1, weight2, bias1, bias2 = embed.chunk(4, 1)\n            out = weight1 * out + bias1\n\n        out = F.leaky_relu(out, negative_slope=0.2)\n\n        out = self.conv2(out)\n\n        if self.class_embed is not None:\n            out = weight2 * out + bias2\n\n        if self.skip is not None:\n            skip = self.skip(input)\n\n        else:\n            skip = input\n\n        out = out + skip\n\n        if self.downsample:\n            out = F.avg_pool2d(out, 2)\n\n        out = F.leaky_relu(out, negative_slope=0.2)\n\n        return out", "\n\nclass IGEBM(nn.Module):\n    def __init__(self, n_class=None):\n        super().__init__()\n\n        self.conv1 = spectral_norm(nn.Conv2d(3, 128, 3, padding=1), std=1)\n\n        self.blocks = nn.ModuleList(\n            [\n                ResBlock(128, 128, n_class, downsample=True),\n                ResBlock(128, 128, n_class),\n                ResBlock(128, 256, n_class, downsample=True),\n                ResBlock(256, 256, n_class),\n                ResBlock(256, 256, n_class, downsample=True),\n                ResBlock(256, 256, n_class),\n            ]\n        )\n\n        self.linear = nn.Linear(256, 1)\n\n    def forward(self, input, class_id=None):\n        out = self.conv1(input)\n\n        out = F.leaky_relu(out, negative_slope=0.2)\n\n        for block in self.blocks:\n            out = block(out, class_id)\n\n        out = F.relu(out)\n        out = out.view(out.shape[0], out.shape[1], -1).sum(2)\n        out = self.linear(out)\n\n        return out", ""]}
{"filename": "optimizer/ALRS.py", "chunked_list": ["import torch\n\n\nclass ALRS():\n    '''\n    proposer: Huanran Chen\n    theory: landscape\n    Bootstrap Generalization Ability from Loss Landscape Perspective\n    '''\n\n    def __init__(self, optimizer, loss_threshold=0.01, loss_ratio_threshold=0.01, decay_rate=0.99):\n        self.optimizer = optimizer\n        self.loss_threshold = loss_threshold\n        self.decay_rate = decay_rate\n        self.loss_ratio_threshold = loss_ratio_threshold\n\n        self.last_loss = 999\n\n    def step(self, loss):\n        delta = self.last_loss - loss\n        if delta < self.loss_threshold and delta / self.last_loss < self.loss_ratio_threshold:\n            for group in self.optimizer.param_groups:\n                group['lr'] *= self.decay_rate\n                now_lr = group['lr']\n                print(f'now lr = {now_lr}')\n\n        self.last_loss = loss"]}
{"filename": "optimizer/FGSM.py", "chunked_list": ["import torch\nfrom torch.optim import Optimizer\n\n\nclass FGSM(Optimizer):\n    def __init__(self, params, lr, ):\n        dampening = 0\n        weight_decay = 0\n        nesterov = False\n        maximize = False\n        momentum = 0\n        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n                        weight_decay=weight_decay, nesterov=nesterov, maximize=maximize)\n        super(FGSM, self).__init__(params, defaults)\n        self.lr = lr\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is not None:\n                    p.add_(-self.lr * p.grad.sign())", ""]}
{"filename": "optimizer/__init__.py", "chunked_list": ["from .FGSM import FGSM\nfrom torch.optim import Adam, AdamW, SGD\nfrom .default import default_optimizer, default_lr_scheduler\n\n__all__ = ['FGSM', 'AdamW', 'SGD', 'Adam', 'default_lr_scheduler', 'default_optimizer']\n"]}
{"filename": "optimizer/default.py", "chunked_list": ["import torch\nfrom torch import nn\n\ndef default_optimizer(model: nn.Module, lr=1e-1, ) -> torch.optim.Optimizer:\n    # return torch.optim.Adam(model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n    return torch.optim.SGD(model.parameters(), lr=lr)\n\n\ndef default_lr_scheduler(optimizer):\n    from .ALRS import ALRS\n    return ALRS(optimizer)", "def default_lr_scheduler(optimizer):\n    from .ALRS import ALRS\n    return ALRS(optimizer)"]}
{"filename": "tester/MembershipInference.py", "chunked_list": ["import torch\nfrom torch.utils.data import DataLoader\nfrom torch import Tensor\n\n\ndef most_similar(x: Tensor, loader: DataLoader) -> Tensor:\n    xs = []\n    for now_x, _ in loader:\n        xs.append(now_x.cuda())\n    xs = torch.cat(xs, dim=0)\n    N, C, H, D = xs.shape\n    d = ((x.squeeze() - xs) ** 2).view(N, C * H * D).sum(1)\n    min_index = torch.min(d, dim=0)[1]\n    target = xs[min_index]\n    return target.unsqueeze(0)", ""]}
{"filename": "tester/TransferAttackAcc.py", "chunked_list": ["import torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom typing import List, Callable, Tuple\nfrom tqdm import tqdm\nfrom attacks import AdversarialInputAttacker\nfrom copy import deepcopy\nfrom torch import multiprocessing\n", "from torch import multiprocessing\n\n\ndef test_transfer_attack_acc(attacker: Callable, loader: DataLoader,\n                             target_models: List[nn.Module],\n                             device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> List[float]:\n    transfer_accs = [0] * len(target_models)\n    denominator = 0\n    # count = 0\n    # to_img = transforms.ToPILImage()\n    for x, y in tqdm(loader):\n        x = x.to(device)\n        y = y.to(device)\n        # ori_x = x.clone()\n        x = attacker(x, y)\n        # temp = to_img(x[0])\n        # temp.save(f'./what/mi/4/adv_{count}.png')\n        # temp = to_img(ori_x[0])\n        # temp.save(f'./what/mi/4/ori_{count}.png')\n        # temp = to_img(x[0]-ori_x[0])\n        # temp.save(f'./what/mi/4/perturb_{count}.png')\n        # count += 1\n        with torch.no_grad():\n            denominator += x.shape[0]\n            for i, model in enumerate(target_models):\n                pre = model(x)  # N, D\n                pre = torch.max(pre, dim=1)[1]  # N\n                transfer_accs[i] += torch.sum(pre == y).item()\n\n    transfer_accs = [1 - i / denominator for i in transfer_accs]\n    # print\n    for i, model in enumerate(target_models):\n        print('-' * 100)\n        print(model.__class__,  model.model.__class__, transfer_accs[i])\n        print('-' * 100)\n    return transfer_accs", "\n\ndef test_autoattack_acc(model: nn.Module, loader: DataLoader):\n    from autoattack import AutoAttack\n    adversary = AutoAttack(model, eps=8 / 255)\n    xs, ys = [], []\n    for x, y in tqdm(loader):\n        xs.append(x)\n        ys.append(y)\n    x = torch.concat(xs, dim=0)\n    y = torch.concat(ys, dim=0)\n    adversary.run_standard_evaluation(x, y)", "\n\ndef test_transfer_attack_acc_with_batch(get_attacker: Callable,\n                                        batch_x: torch.tensor,\n                                        batch_y: torch.tensor,\n                                        get_target_models: Callable,\n                                        batch_size: int = 1,\n                                        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> List[\n    float]:\n    attacker = get_attacker()\n    target_models = get_target_models()\n    transfer_accs = [0] * len(target_models)\n    denominator = 0\n    batch_x = batch_x.to(device)\n    batch_y = batch_y.to(device)\n    xs = list(torch.split(batch_x, batch_size, dim=0))\n    ys = list(torch.split(batch_y, batch_size, dim=0))\n    attacker.to(device)\n\n    for model in target_models:\n        model.to(device)\n    for x, y in tqdm(zip(xs, ys)):\n        x = attacker(x, y)\n        with torch.no_grad():\n            denominator += x.shape[0]\n            for i, model in enumerate(target_models):\n                pre = model(x)  # N, D\n                pre = torch.max(pre, dim=1)[1]  # N\n                transfer_accs[i] += torch.sum(pre == y).item()\n\n    transfer_accs = [1 - i / denominator for i in transfer_accs]\n    # print\n    for i, model in enumerate(target_models):\n        print('-' * 100)\n        print(model.__class__, transfer_accs[i])\n        print('-' * 100)\n    return transfer_accs", "\n\ndef test_transfer_attack_acc_distributed(get_attacker: Callable,\n                                         loader: DataLoader,\n                                         get_target_models: Callable,\n                                         batch_size: int = 1,\n                                         num_gpu: int = torch.cuda.device_count()):\n    def list_mean(x: list) -> float:\n        return sum(x) / len(x)\n\n    print(f'available gpu num {num_gpu}')\n    xs, ys = [], []\n    for x, y in loader:\n        xs.append(x)\n        ys.append(y)\n    xs, ys = torch.cat(xs, dim=0), torch.cat(ys, dim=0)\n    xs, ys = list(torch.split(xs, xs.shape[0] // num_gpu, dim=0)), list(torch.split(ys, ys.shape[0] // num_gpu, dim=0))\n    pool = multiprocessing.Pool(processes=num_gpu)\n    results = [pool.apply_async(func=test_transfer_attack_acc_with_batch,\n                                args=(\n                                    get_attacker,\n                                    xs[i], ys[i],\n                                    get_target_models\n                                ),\n                                kwds=(\n                                    {'batch_size': batch_size,\n                                     'device': torch.device(f'cuda:{num_gpu - i - 1}')\n                                     }\n                                )\n                                ) for i in range(num_gpu)\n               ]\n    pool.close()\n    pool.join()\n    # print(results)\n    # results = [list_mean([results[target_model_id][j] for j in range(len(results))])\n    #            for target_model_id in range(len(results[0]))]\n    # for i, model in enumerate(target_models):\n    #     print('-' * 100)\n    # print(model.__class__, model.model.__class__, results[i])\n    # print('-' * 100)\n    return results", ""]}
{"filename": "tester/__init__.py", "chunked_list": ["from .TestAcc import test_acc, test_autoattack_acc\nfrom .MembershipInference import most_similar"]}
{"filename": "tester/TestAcc.py", "chunked_list": ["import torch\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nfrom tqdm import tqdm\n\n\n@torch.no_grad()\ndef test_acc(model: nn.Module, loader: DataLoader,\n             device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n    total_loss = 0\n    total_acc = 0\n    criterion = nn.CrossEntropyLoss().to(device)\n    model.to(device)\n    denominator = 0\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        pre = model(x)\n        total_loss += criterion(pre, y).item() * y.shape[0]\n        _, pre = torch.max(pre, dim=1)\n        total_acc += torch.sum((pre == y)).item()\n        denominator += y.shape[0]\n\n    test_loss = total_loss / denominator\n    test_accuracy = total_acc / denominator\n    print(f'loss = {test_loss}, acc = {test_accuracy}')\n    return test_loss, test_accuracy", "\n\ndef test_autoattack_acc(model: nn.Module, loader: DataLoader):\n    from autoattack import AutoAttack\n    adversary = AutoAttack(model, eps=8 / 255)\n    # adversary = AutoAttack(model, eps=0.01)\n    xs, ys = [], []\n    for x, y in tqdm(loader):\n        xs.append(x.cuda())\n        ys.append(y.cuda())\n    x = torch.concat(xs, dim=0)[:10]\n    y = torch.concat(ys, dim=0)[:10]\n    adversary.run_standard_evaluation(x, y, bs=1)", ""]}
