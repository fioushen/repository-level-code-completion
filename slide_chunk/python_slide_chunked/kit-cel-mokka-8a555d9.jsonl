{"filename": "tests/__init__.py", "chunked_list": ["\"\"\"Test package for MOKKa.\"\"\"\n"]}
{"filename": "tests/mokka/test_equalizers.py", "chunked_list": ["import mokka.equalizers.torch as equalizers  # noqa\n"]}
{"filename": "tests/mokka/test_synchronizers.py", "chunked_list": ["import mokka.synchronizers.phase.torch as phase  # noqa\n"]}
{"filename": "tests/mokka/__init__.py", "chunked_list": ["\"\"\"Tests for Mokka module\"\"\"\n"]}
{"filename": "tests/mokka/test_normalization.py", "chunked_list": ["from mokka import normalization\nimport torch\n\n\ndef test_energy_simple():\n    test_values = torch.ones((1, 10))\n    expected_result = test_values\n    result = normalization.energy(test_values)\n    assert torch.allclose(result, expected_result)\n", "\n\ndef test_energy_complex():\n    test_values = torch.ones((2, 10)) + 1j * torch.ones((2, 10))\n    expected_result = torch.full(\n        (2, 10), (1 + 1j) / torch.sqrt(torch.tensor(2)), dtype=torch.complex64\n    )\n    result = normalization.energy(test_values)\n    assert torch.allclose(result, expected_result)\n", "\n\ndef test_energy_weighted():\n    test_values = torch.ones((2, 10)) + 1j * torch.ones((2, 10))\n    expected_result = torch.full(\n        (2, 10), (1 + 1j) / torch.sqrt(torch.tensor(2)), dtype=torch.complex64\n    )\n    p = torch.ones((10,)) / 10\n    result = normalization.energy(test_values, p)\n    assert torch.allclose(result, expected_result)", ""]}
{"filename": "tests/mokka/test_e2e.py", "chunked_list": ["import mokka.e2e.torch as e2e  # noqa\n"]}
{"filename": "tests/mokka/test_channels.py", "chunked_list": ["import mokka.channels.torch as channels\nimport mokka.utils as utils\nimport torch\n\nnum_samples = 1000\n\nsymbolrate = 30e9\noversampling = 16\ndt = 1 / (oversampling * symbolrate)\ndz = 1  # km", "dt = 1 / (oversampling * symbolrate)\ndz = 1  # km\nwavelength = 1550  # nm\nspan_length = length_span = 100  # km\nnum_span = 10\namp_gain = \"alpha_equalization\"\nalphadb = alphaa_db = alphab_db = 0.2  # db/km\nD = 16  # [ps/nm/km]\ngamma = torch.tensor(1.3)  # [1/W/km]\nbetaa2 = utils.beta2(D, wavelength)", "gamma = torch.tensor(1.3)  # [1/W/km]\nbetaa2 = utils.beta2(D, wavelength)\nbetapa = betap = torch.tensor([0, 0, betaa2])\nbetab2 = betaa2\nbetapb = torch.tensor([0, 0, betab2])\namp_noise = True\nnoise_figure = 5  # dB\noptical_carrier_frequency = wavelength / 0.3  # GHz\nbw = 2 * symbolrate\nP_input = 0  # dBm", "bw = 2 * symbolrate\nP_input = 0  # dBm\nP_input_lin = 10 ** ((P_input - 30) / 10)  # W\npadding = 1000\n\n\ndef test_awgn():\n    channel = channels.ComplexAWGN()\n    sigma = torch.tensor(0.1)\n    x = torch.zeros(num_samples, dtype=torch.complex64)\n    y = channel(x, sigma)\n    assert len(y) == num_samples", "\n\ndef test_phasenoise():\n    channel = channels.PhasenoiseWiener()\n    sigma_phi = torch.tensor(0.1)\n    sigma_n = torch.tensor(0.01)\n    x = torch.zeros(num_samples, dtype=torch.complex64)\n    y = channel(x, sigma_phi, sigma_n)\n    assert len(y) == num_samples\n", "\n\ndef test_residualphasenoise():\n    channel = channels.ResidualPhaseNoise()\n    sigma_phi = torch.tensor(0.1)\n    x = torch.zeros(num_samples, dtype=torch.complex64)\n    y = channel.forward(x, sigma_phi)\n    assert len(y) == num_samples\n\n\ndef test_opticalnoise():\n    wavelength_bw = 0.1  # nm\n    optical_snr = 25  # dB\n    channel = channels.OpticalNoise(dt, wavelength, wavelength_bw, optical_snr)\n    x = torch.zeros(num_samples, dtype=torch.complex64)\n    y = channel(x)\n    assert len(y) == num_samples", "\n\ndef test_opticalnoise():\n    wavelength_bw = 0.1  # nm\n    optical_snr = 25  # dB\n    channel = channels.OpticalNoise(dt, wavelength, wavelength_bw, optical_snr)\n    x = torch.zeros(num_samples, dtype=torch.complex64)\n    y = channel(x)\n    assert len(y) == num_samples\n", "\n\ndef test_edfa_singlepol():\n    amp = channels.EDFAAmpSinglePol(\n        span_length,\n        amp_gain,\n        alphadb,\n        amp_noise,\n        noise_figure,\n        optical_carrier_frequency,\n        bw,\n        P_input_lin,\n        padding,\n    )\n    x = torch.zeros(num_samples, dtype=torch.complex64)\n    y = amp(x, 0)\n    assert len(y) == num_samples\n    y = amp(x, 1)\n    assert len(y) == num_samples\n    y = amp(x, 2)\n    assert len(y) == num_samples", "\n\ndef test_SSFM_singlepol():\n    amp = channels.EDFAAmpSinglePol(\n        span_length,\n        amp_gain,\n        alphadb,\n        amp_noise,\n        noise_figure,\n        optical_carrier_frequency,\n        bw,\n        P_input_lin,\n        padding,\n    )\n    channel = channels.SSFMPropagationSinglePol(\n        dt, dz, alphadb, betap, gamma, length_span, num_span, amp=amp\n    )\n    x = torch.zeros(num_samples, dtype=torch.complex64)\n    y = channel(x)\n    assert len(y) == num_samples", "\n\ndef test_SSFM_dualpol():\n    amp = channels.EDFAAmpDualPol(  # noqa\n        span_length,\n        amp_gain,\n        alphaa_db,\n        alphab_db,\n        amp_noise,\n        noise_figure,\n        optical_carrier_frequency,\n        bw,\n        P_input_lin,\n        padding,\n    )\n    channel = channels.SSFMPropagationDualPol(\n        dt, dz, alphaa_db, alphab_db, betapa, betapb, gamma, length_span, num_span\n    )\n    x1 = torch.zeros(num_samples, dtype=torch.complex64)\n    x2 = torch.zeros(num_samples, dtype=torch.complex64)\n    y1, y2 = channel(x1, x2)\n    assert len(y1) == num_samples\n    assert len(y2) == num_samples", ""]}
{"filename": "tests/mokka/test_functional.py", "chunked_list": ["import numpy as np\nimport mokka\nimport torch\n\n\ndef test_convolve_pytorch_real():\n    a = np.arange(10)\n    b = np.arange(3)\n    reference = np.convolve(a, b)\n    result = (\n        mokka.functional.torch.convolve(torch.tensor(a), torch.tensor(b))\n        .detach()\n        .numpy()\n    )\n    assert np.allclose(reference, result)", "\n\ndef test_convolve_pytorch_complex():\n    a = np.arange(10) + 1j * np.arange(10)\n    b = np.arange(3) - 1j * np.arange(3)\n    reference = np.convolve(a, b)\n    result = (\n        mokka.functional.torch.convolve(torch.tensor(a), torch.tensor(b))\n        .detach()\n        .numpy()\n    )\n    assert np.allclose(reference, result)", "\n\ndef test_unwrap():\n    angle_diff = np.random.random(10000) * 2 * np.pi\n    angles = np.cumsum(angle_diff)\n    result = mokka.functional.torch.unwrap_torch(torch.tensor(angles))\n    expected_result = np.unwrap(angles)\n    assert np.allclose(result, expected_result)\n", ""]}
{"filename": "tests/mokka/test_mapping.py", "chunked_list": ["from mokka import mapping\nimport numpy as np\n\n# PyTorch tests\n\n\ndef test_simple_constellation_mapper_random():\n    m = 4\n    mapper = mapping.torch.SimpleConstellationMapper(m)\n    symbols = mapper.get_constellation()\n    assert symbols.shape[0] == 16", "\n\ndef test_simple_constellation_mapper_qaminit():\n    m = 4\n    mapper = mapping.torch.SimpleConstellationMapper(m, qam_init=True)\n    symbols = mapper.get_constellation().detach().numpy().flatten()\n    reference_symbols = mapping.numpy.QAM(m).get_constellation().flatten()\n    assert np.allclose(symbols, reference_symbols)\n\n\ndef test_regular_constellation_mapper_random():\n    m = 4\n    mapper = mapping.torch.ConstellationMapper(m)\n    symbols = mapper.get_constellation()\n    assert symbols.shape[0] == 16", "\n\ndef test_regular_constellation_mapper_random():\n    m = 4\n    mapper = mapping.torch.ConstellationMapper(m)\n    symbols = mapper.get_constellation()\n    assert symbols.shape[0] == 16\n\n\ndef test_regular_constellation_mapper_qaminit():\n    m = 4\n    mapper = mapping.torch.ConstellationMapper(m, qam_init=True)\n    symbols = mapper.get_constellation().detach().numpy().flatten()\n    reference_symbols = mapping.numpy.QAM(m).get_constellation().flatten()\n    assert np.allclose(symbols, reference_symbols)", "\ndef test_regular_constellation_mapper_qaminit():\n    m = 4\n    mapper = mapping.torch.ConstellationMapper(m, qam_init=True)\n    symbols = mapper.get_constellation().detach().numpy().flatten()\n    reference_symbols = mapping.numpy.QAM(m).get_constellation().flatten()\n    assert np.allclose(symbols, reference_symbols)\n\n\ndef test_qam_constellation_mapper():\n    m = 4\n    mapper = mapping.torch.QAMConstellationMapper(m)\n    symbols = mapper.get_constellation().detach().numpy().flatten()\n    reference_symbols = mapping.numpy.QAM(m).get_constellation().flatten()\n    assert np.allclose(symbols, reference_symbols)", "\ndef test_qam_constellation_mapper():\n    m = 4\n    mapper = mapping.torch.QAMConstellationMapper(m)\n    symbols = mapper.get_constellation().detach().numpy().flatten()\n    reference_symbols = mapping.numpy.QAM(m).get_constellation().flatten()\n    assert np.allclose(symbols, reference_symbols)\n"]}
{"filename": "tests/mokka/test_utils.py", "chunked_list": ["from mokka.utils import generators\nfrom mokka.utils import bitops\nimport torch\nimport numpy as np\n\n\ndef test_generatebits():\n    bits = generators.numpy.generate_bits((1, 10))\n    assert bits.shape == (1, 10)\n", "\n\ndef test_generate_all_bits():\n    m = 4\n    all_bits = generators.numpy.generate_all_bits(m)\n    assert all_bits.shape == (2**m, m)\n\n\ndef test_one_hot():\n    m = 4\n    all_bits = generators.numpy.generate_all_bits(m)\n    one_hot = bitops.torch.bits_to_onehot(torch.tensor(all_bits.copy()))\n    expected_result = torch.tensor(np.zeros((2**m, 2**m)))\n    for idx in range(2**m):\n        expected_result[idx][idx] = 1.0\n    assert torch.all(one_hot == expected_result)", "def test_one_hot():\n    m = 4\n    all_bits = generators.numpy.generate_all_bits(m)\n    one_hot = bitops.torch.bits_to_onehot(torch.tensor(all_bits.copy()))\n    expected_result = torch.tensor(np.zeros((2**m, 2**m)))\n    for idx in range(2**m):\n        expected_result[idx][idx] = 1.0\n    assert torch.all(one_hot == expected_result)\n", ""]}
{"filename": "tests/mokka/test_import.py", "chunked_list": ["def test_import():\n    import mokka  # noqa\n"]}
{"filename": "tests/mokka/test_pulseshaping.py", "chunked_list": ["import mokka.pulseshaping.torch as pulseshape  # noqa\n"]}
{"filename": "docs/conf.py", "chunked_list": ["# Configuration file for the Sphinx documentation builder.\n#\n# For the full list of built-in configuration values, see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Project information -----------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\nimport os\nfrom sphinx_pyproject import SphinxConfig\n", "from sphinx_pyproject import SphinxConfig\n\nmodule_dir = os.path.join(os.path.dirname(__file__), \"../src/mokka\")\n\nconfig = SphinxConfig(\"../pyproject.toml\", globalns=globals())\n\nauthor=config.author\nproject=config.name\n", ""]}
{"filename": "src/mokka/__init__.py", "chunked_list": ["\"\"\"\nPython package for machine learning in communication.\n\nThis package is broken up into several modules, each tasked with only a single\npart of the whole communication system. Each module shall work independently of\neach other, except modules like `utils` and `functional`. Processing blocks of the\ncommunication system shall be implemented as modular blocks and within\nsimulations it should be possible to chain output of a preceeding block\nto the input of the next block.\n", "to the input of the next block.\n\nThis package implements blocks either for PyTorch or TensorFlow, most\nfunctionality is implemented exclusively in one of the frameworks.\nIn the case of TensorFlow the functions are implemented in conjunction\nwith the framework sionna.\n\"\"\"\n\n__version__ = \"1.0.1\"\n", "__version__ = \"1.0.1\"\n\n\nfrom . import utils  # noqa\nfrom . import functional  # noqa\nfrom . import normalization  # noqa\n\nfrom . import channels  # noqa\nfrom . import inft  # noqa\nfrom . import equalizers  # noqa", "from . import inft  # noqa\nfrom . import equalizers  # noqa\nfrom . import synchronizers  # noqa\nfrom . import e2e  # noqa\nfrom . import mapping  # noqa\nfrom . import pulseshaping  # noqa\n"]}
{"filename": "src/mokka/synchronizers/__init__.py", "chunked_list": ["\"\"\"Module implementing synchrization.\"\"\"\n\nfrom . import phase  # noqa\n"]}
{"filename": "src/mokka/synchronizers/phase/__init__.py", "chunked_list": ["\"\"\"Module implementing phase synchronizers.\"\"\"\n\nfrom . import torch  # noqa\n"]}
{"filename": "src/mokka/synchronizers/phase/torch/__init__.py", "chunked_list": ["\"\"\"Module implementing phase synchronizers in PyTorch.\"\"\"\n\nfrom .bps import BPS  # noqa\n"]}
{"filename": "src/mokka/synchronizers/phase/torch/bps.py", "chunked_list": ["\"\"\"Submodule implementing methods for the blind phase search.\"\"\"\n\nimport torch\nimport numpy as np\nfrom ....functional.torch import unwrap_torch\n\n\nclass BPS(torch.nn.Module):\n    \"\"\"\n    The blind phase search algorithm (BPS).\n\n    This class implements the differentiable and non-differentiable versions of the BPS.\n    \"\"\"\n\n    def __init__(\n        self,\n        Mtestangles,\n        symbols,\n        N,\n        diff,\n        temperature_per_epoch,\n        no_sectors,\n        avg_filter_type=\"tri\",\n        trainable=False,\n    ):\n        \"\"\"Construct the BPS class.\"\"\"\n        super(BPS, self).__init__()\n        (\n            self.Mtestangles,\n            self.symbols,\n            self.N,\n            self.diff,\n            self._temperature,\n            self.no_sectors,\n            self.avg_filter_type,\n        ) = (\n            Mtestangles,\n            symbols,\n            N,\n            diff,\n            temperature_per_epoch,\n            no_sectors,\n            avg_filter_type,\n        )\n\n        if self.avg_filter_type == \"rect\":\n            avg_filter = torch.ones(\n                2 * self.N + 1, dtype=torch.float32, device=symbols.device\n            )\n        elif self.avg_filter_type == \"tri\":\n            avg_filter = torch.cat(\n                [\n                    torch.arange(\n                        1, self.N + 2, dtype=torch.float32, device=symbols.device\n                    ),\n                    torch.arange(\n                        self.N, 0, step=-1, dtype=torch.float32, device=symbols.device\n                    ),\n                ]\n            )\n        elif self.avg_filter_type == \"nonlinear\":\n            self.nonlin_filter = torch.nn.Sequential(\n                torch.nn.Linear(2 * self.N + 1, 1, device=symbols.device),\n                torch.nn.ELU(),\n                # torch.nn.Linear(2 * self.N + 1, 1, device=symbols.device),\n            )\n        else:\n            raise ValueError(\"Unknown averaging filter\")\n\n        self.trainable = trainable\n        if self.trainable:\n            self.sigmoid = torch.nn.Sigmoid()\n            self._temperature = torch.nn.Parameter(temperature_per_epoch)\n            if self.avg_filter_type != \"nonlinear\":\n                self.avg_filter = torch.nn.Parameter(avg_filter)\n\n            # self.avg_filter = avg_filter  # TODO\n        else:\n            self.register_buffer(\"avg_filter\", avg_filter)\n\n    @property\n    def temperature_per_epoch(self):\n        \"\"\"\n        Get temperature setting for differentiable BPS.\n\n        :returns: temperature value.\n\n        \"\"\"\n        if self.trainable:\n            return self.sigmoid(self._temperature)\n        return self._temperature\n\n    @property\n    def normalized_filter(self):\n        \"\"\"\n        Return normalized filter.\n\n        :returns: normalized filter taps\n\n        \"\"\"\n        return self.avg_filter / torch.sum(self.avg_filter)\n\n    @temperature_per_epoch.setter\n    def temperature_per_epoch(self, new_temperature_per_epoch):\n        if self.trainable:\n            raise AttributeError(\n                \"Temperature parameter in a trainable BPS cannot be updated manually\"\n            )\n        self._temperature = new_temperature_per_epoch\n\n    def forward(self, x, *args):\n        \"\"\"\n        Perform blind phase search.\n\n        :param x: received complex symbols\n        :returns:\n\n        \"\"\"\n        # Ignore other arguments given to other parts of the channel\n        bpsx = self.bps_torch(x)\n        return torch.squeeze(bpsx[0]), torch.squeeze(bpsx[1])\n\n    def set_constellation(self, constellation):\n        \"\"\"\n        Set constellation points in blind phase equalizer.\n\n        :param constellation: array of (complex) constellation points\n        \"\"\"\n        self.symbols = constellation\n        return self\n\n    def train(self, mode):\n        \"\"\"Enable training.\n\n        :param mode: if true enable training and differentiable mode.\n        :returns: the BPS in trainable mode\n\n        \"\"\"\n        self.diff = mode\n        return super(BPS, self).train(mode)\n\n    def bps_torch(\n        self,\n        x,\n    ):\n        \"\"\"\n        Perform a blind phase search according to [1].\n\n        Parameters\n        ----------\n        x           : array_like\n            input signal (single polarisation)\n        Returns\n        -------\n        Eout    : array_like\n            signal with compensated phase\n        ph      : array_like\n            unwrapped angle from phase recovery\n\n\n        References\n        ----------\n        [1] Timo Pfau et al, Hardware-Efficient Coherent Digital Receiver \\\n            Concept With Feedforward Carrier Recovery for M-QAM Constellations, \\\n            Journal of Lightwave Technology 27, pp 989-999 (2009)\n        \"\"\"\n        softmin = torch.nn.Softmin(dim=1)\n\n        # Use this line\n        if self.no_sectors == 4:\n            if self.Mtestangles == 2:\n                angles = torch.atleast_2d(\n                    torch.tensor(\n                        (-np.pi / 6, np.pi / 6),\n                        device=x.device,\n                    )\n                )\n            else:\n                angles = torch.atleast_2d(\n                    torch.linspace(\n                        -np.pi / 4,\n                        np.pi / 4 - (np.pi / 4 + np.pi / 4) / self.Mtestangles,\n                        self.Mtestangles,\n                        device=x.device,\n                    )\n                )\n        else:\n            angles = torch.atleast_2d(\n                torch.linspace(\n                    -np.pi,\n                    np.pi - (np.pi + np.pi) / self.Mtestangles,\n                    self.Mtestangles,\n                    device=x.device,\n                )\n            )\n\n        Ew = torch.atleast_2d(x)\n        if self.diff is True:\n            for i in range(Ew.shape[0]):\n                mvg = self._bps_idx_torch(Ew[i], angles)\n                if self.no_sectors == 4:\n                    smvg = softmin(mvg / self.temperature_per_epoch)\n                    sangles = 4 * torch.squeeze(angles)\n                    ph = (\n                        unwrap_torch(\n                            torch.angle(\n                                smvg @ torch.cos(sangles)\n                                + 1j * (smvg @ torch.sin(sangles))\n                            ),\n                            np.pi,\n                            -1,\n                            2 * np.pi,\n                        )\n                        / 4\n                    )\n                else:\n                    smvg = softmin(mvg / self.temperature_per_epoch)\n                    sangles = torch.squeeze(angles)\n                    ph = unwrap_torch(\n                        torch.angle(\n                            smvg @ torch.cos(sangles) + 1j * (smvg @ torch.sin(sangles))\n                        ),\n                        np.pi,\n                        -1,\n                        2 * np.pi,\n                    )\n            return torch.squeeze(Ew * torch.exp(1j * ph)), ph\n        else:\n            ph = torch.empty(Ew.shape[0], Ew.shape[1], device=x.device)\n            for i in range(Ew.shape[0]):\n                idx = self._bps_idx_torch(Ew[i], angles)\n                ph[i] = self.select_angles_torch(angles.clone(), idx.int())\n\n            if self.no_sectors == 4:\n                ph[0, :] = unwrap_torch(4 * ph[0, :], np.pi, -1, 2 * np.pi) / 4\n            else:\n                ph[0, :] = unwrap_torch(ph[0, :], np.pi, -1, 2 * np.pi)\n            return Ew * torch.exp(1j * ph), ph\n\n    def _bps_idx_torch(self, x, angles):\n        \"\"\"Blind phase search core algorithm using PyTorch.\"\"\"\n        EE = torch.unsqueeze(x, 1) * torch.exp(1j * angles)\n        idx = torch.zeros(x.shape[0], dtype=torch.int, device=x.device)\n        dist = torch.min(torch.abs(torch.unsqueeze(EE, 2) - self.symbols) ** 2, dim=2)[\n            0\n        ]\n        # print(\"dist shape\", dist.shape)\n        # unfold = torch.nn.Unfold(0, 2 * self.N + 1, 3)\n        dist_pad = torch.cat(\n            (\n                torch.zeros([self.N, dist.shape[1]], device=dist.device),\n                dist,\n                torch.zeros([self.N, dist.shape[1]], device=dist.device),\n            ),\n            0,\n        )\n        if self.avg_filter_type == \"nonlinear\":\n            unfolded_dist = dist_pad.unfold(0, 2 * self.N + 1, 1)\n            # print(\"unfolded dist shape\", unfolded_dist.shape)\n\n            mvg = self.nonlin_filter(unfolded_dist).squeeze()\n            # print(\"nonlin_mvg shape\", nonlin_mvg.shape)\n        else:\n            mvg = (\n                torch.conv1d(\n                    input=dist.transpose(0, 1).view(-1, 1, x.shape[0]),\n                    weight=self.normalized_filter.view(1, 1, -1),\n                    padding=\"same\",\n                )\n                .squeeze()\n                .transpose(0, 1)\n            )\n\n        # print(\"mvg shape\", mvg.shape)\n        # print(\"mvg shape\", torch.sum(mvg, 1).shape)\n        # input()\n        # normalize mvg values\n        mvg /= torch.unsqueeze(torch.sum(mvg, 1), 1)\n        if self.diff is True:\n            return mvg\n        else:\n            idx = torch.argmin(mvg, dim=1)\n            return idx\n\n    def select_angles_torch(self, angles, idx):\n        \"\"\"\n        Perform selection on angles.\n\n        :param angles: vector of angles\n        :param idx: vector of indices\n        :returns: selected angles\n        \"\"\"\n        L = angles.shape[0]\n        anglesn = torch.zeros(L, dtype=angles.dtype)\n        if angles.shape[0] > 1:\n            # omp parallel for\n            for i in range(L):\n                anglesn[i] = angles[i, idx[i]]\n            return anglesn\n        else:\n            L = idx.shape[0]\n            anglesn = torch.zeros(L, dtype=angles.dtype)\n            anglesn = angles[0, idx.long()]\n            return anglesn", ""]}
{"filename": "src/mokka/pulseshaping/torch.py", "chunked_list": ["\"\"\"Module implementing pulseshaping with PyTorch.\"\"\"\n\nimport torch\nimport attr\nimport math\n\nfrom .. import functional\n\ntorch.pi = math.pi\n", "torch.pi = math.pi\n\n\n@attr.define\nclass PulseShaping(torch.nn.Module):\n    \"\"\"\n    PulseShaping filter class.\n\n    Several classical shapes, a filter function \\\n    and a matched filter function are provided.\n    \"\"\"\n\n    _impulse_response: torch.tensor\n    learnable: bool = False\n    impulse_response_conj: torch.tensor = attr.field(init=False)\n\n    def __attrs_post_init__(self):\n        \"\"\"Perform construction of other parts.\"\"\"\n        super(PulseShaping, self).__init__()\n        if self.learnable:\n            self.impulse_response = torch.nn.Parameter(self._impulse_response)\n            self.impulse_response_conj = torch.nn.Parameter(\n                torch.resolve_conj(self._impulse_response.conj())\n            )\n        else:\n            self.register_buffer(\"impulse_response\", self._impulse_response)\n            self.register_buffer(\n                \"impulse_response_conj\",\n                torch.resolve_conj(self._impulse_response.conj()),\n            )\n        self.ir_norm = torch.linalg.norm(self.impulse_response)\n\n    def forward(self, y, n_up):\n        \"\"\"Perform pulse shaping.\n\n        :param y: transmit signal\n        :param n_up: upsampling factor\n        :returns: shaped and upsampled transmit signal at sample rate\n        \"\"\"\n        y_up = torch.zeros(y.shape[0] * n_up, dtype=torch.complex64, device=y.device)\n        y_up[::n_up] = y\n        y_shaped = functional.torch.convolve(y_up, self.impulse_response)\n        return y_shaped\n\n    def matched(self, r, n_down):\n        \"\"\"Perform matched filtering.\n\n        This function assumes perfect timing sync.\n\n        :param r: received complex signal\n        :param n_down: downsampling factor\n        :returns: filtered and downsampled signal at symbol rate\n        \"\"\"\n        y_filt = functional.torch.convolve(r, self.impulse_response_conj / n_down)\n        offset = self.impulse_response_conj.shape[0] - 1\n        y = y_filt[::n_down][int(offset / n_down) : -int(offset / n_down)]\n        return y\n\n    def normalize_filter(self):\n        \"\"\"Normalize filter taps saved in this object.\"\"\"\n        # print('saved ir_norm',self.ir_norm)\n        # print('current ir_norm',torch.linalg.norm(self.impulse_response))\n        self.impulse_response = torch.nn.Parameter(\n            self.ir_norm\n            * self.impulse_response\n            / torch.linalg.norm(self.impulse_response)\n        )\n        self.impulse_response_conj = torch.nn.Parameter(\n            self.ir_norm\n            * self.impulse_response_conj\n            / torch.linalg.norm(self.impulse_response_conj)\n        )\n        # print('current ir_norm',torch.linalg.norm(self.impulse_response))\n\n    @classmethod\n    def get_rc_ir(cls, syms, r, n_up, learnable=False):\n        \"\"\"Determine normed coefficients of an RC filter.\n\n        Formula out of: K.-D. Kammeyer, Nachrichten\u00fcbertragung\n        At poles, l'Hospital was used\n\n        :param syms: \"normed\" length of ir. ir-length will be 2*syms+1\n        :param r: roll-off factor [Float]\n        :param n_up: upsampling factor [Int]\n\n        :returns: tuple containing time-index-array and impulse response in an array\n\n        \"\"\"\n        with torch.no_grad():\n            # initialize output length and sample time\n            T_symbol = 1.0\n            T_sample = 1.0 / n_up\n            # length of one sample is the symbol-duration divided\n            # by the oversampling factor (=1/sampling rate)\n            T_ir = 2 * syms * T_symbol\n            # Duration of the impulse response is positive and negative\n            # normed symbols added multplied by Symbol Duration\n            ir = torch.zeros(int(T_ir / T_sample) + 1)\n            # samples of impulse response is definied by duration\n            # of the ir divided by the sample time plus one for the 0th sample\n\n            # time indices and sampled time\n            k_steps = torch.arange(\n                -T_ir / T_sample / 2, T_ir / T_sample / 2 + 1, dtype=int\n            )\n            t_steps = k_steps * T_sample\n\n            for k in k_steps:\n                if t_steps[k] == 0:\n                    ir[k] = 1.0 / T_symbol\n\n                elif r != 0 and torch.abs(t_steps[k]) == T_symbol / (2.0 * r):\n                    ir[k] = r / (2.0 * T_symbol) * torch.sin(torch.pi / (2.0 * r))\n\n                else:\n                    ir[k] = (\n                        torch.sin(torch.pi * t_steps[k] / T_symbol)\n                        / torch.pi\n                        / t_steps[k]\n                        * torch.cos(r * torch.pi * t_steps[k] / T_symbol)\n                        / (1.0 - (2.0 * r * t_steps[k] / T_symbol) ** 2)\n                    )\n\n            # Norming on Energy = 1\n            ir /= torch.linalg.norm(ir) * torch.sqrt(T_sample)\n\n        return cls(ir, learnable)\n\n    @classmethod\n    def get_rrc_ir(cls, syms, r, n_up, learnable=False):\n        \"\"\"Determine normed coefficients of an RRC filter.\n\n        This function is adapted from Sourcecode written by Dominik Rimpf and was\n        published under the MIT license [https://gitlab.com/domrim/bachelorarbeit-code]\n\n        Formula out of: K.-D. Kammeyer, Nachrichten\u00fcbertragung\n        At poles, l'Hospital was used\n\n        :param syms: \"normed\" length of ir. ir-length will be 2*syms+1\n        :param r: roll-off factor [Float]\n        :param n_up: upsampling factor [Int]\n\n        :returns: tuple containing time-index-array and impulse response in an array\n\n        \"\"\"\n        with torch.no_grad():\n            # initialize output length and sample time\n            T_symbol = 1.0\n            T_sample = 1 / n_up\n            T_ir = 2 * syms * T_symbol\n            # Duration of the impulse response is positive and negative\n            # normed symbols added multplied by Symbol Duration\n            ir = torch.zeros(int(T_ir / T_sample) + 1)\n            # samples of impulse response is definied by duration of\n            # the ir divided by the sample time plus one for the 0th sample\n\n            # time indices and sampled time\n            k_steps = torch.arange(\n                -T_ir / T_sample / 2, T_ir / T_sample / 2 + 1, dtype=int\n            )\n            t_steps = k_steps * T_sample\n\n            for k in k_steps.int():\n                if t_steps[k] == 0:\n                    ir[k] = (torch.pi + 4.0 * r - torch.pi * r) / (torch.pi * T_symbol)\n\n                elif r != 0 and torch.abs(t_steps[k]) == T_symbol / (4.0 * r):\n                    ir[k] = (\n                        r\n                        * (\n                            -2.0\n                            * torch.cos(\n                                torch.pi * torch.tensor(1.0 + r) / torch.tensor(4.0 * r)\n                            )\n                            + torch.pi\n                            * torch.sin(\n                                torch.pi * torch.tensor(1.0 + r) / torch.tensor(4.0 * r)\n                            )\n                        )\n                        / (torch.pi * T_symbol)\n                    )\n\n                else:\n                    ir[k] = (\n                        4.0\n                        * r\n                        * t_steps[k]\n                        / T_symbol\n                        * torch.cos(torch.pi * (1.0 + r) * t_steps[k] / T_symbol)\n                        + torch.sin(torch.pi * (1.0 - r) * t_steps[k] / T_symbol)\n                    ) / (\n                        (1.0 - (4.0 * r * t_steps[k] / T_symbol) ** 2)\n                        * torch.pi\n                        * t_steps[k]\n                    )\n\n            # Norming on Energy = 1\n            ir /= torch.linalg.norm(ir) * torch.sqrt(torch.tensor(T_sample))\n            ir = ir.type(torch.complex64)\n        return cls(ir, learnable)", "\n\nclass MidriseQuantizer(torch.nn.Module):\n    \"\"\"Implement a Quantizer which translates a continuos signal into 2**m levels.\"\"\"\n\n    def __init__(self, bit, max_amplitude=1.0):\n        \"\"\"Construct `MidriseQuuantizer`.\"\"\"\n        super(MidriseQuantizer, self).__init__()\n\n        self.delta = max_amplitude / (2 ** (bit - 1))\n        self.max_amplitude = max_amplitude\n\n    def forward(self, y):\n        \"\"\"Perform quantization.\"\"\"\n        y_quant = (\n            torch.sign(y)\n            * self.delta\n            * (\n                torch.floor(\n                    torch.clamp(torch.abs(y), 0, self.max_amplitude) / self.delta\n                )\n                + 0.5\n            )\n        )\n        y_quant = y_quant + y - y.detach()  # Retain the gradients\n        return y_quant", ""]}
{"filename": "src/mokka/pulseshaping/__init__.py", "chunked_list": ["\"\"\"Module implementing pulseshaping.\"\"\"\n\nfrom . import torch  # noqa\n"]}
{"filename": "src/mokka/utils/__init__.py", "chunked_list": ["\"\"\"\nUtilities sub-module for MOKKa.\n\nThis sub-module contains a lot of useful utiltiies used throughout\nthe MOKKa package.\n\"\"\"\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\n", "import matplotlib.pyplot as plt\n\nimport logging\n\n\n# Plotting utilities\n\n\ndef setup_plot(title):\n    \"\"\"\n    Create a figure and axes.\n\n    :params title: Title of the figure\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(title=title)\n    return fig, ax", "def setup_plot(title):\n    \"\"\"\n    Create a figure and axes.\n\n    :params title: Title of the figure\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(title=title)\n    return fig, ax\n", "\n\ndef plot_scatter(ax, samples, labels):\n    \"\"\"\n    Scatter plot a bunch of samples with labels.\n\n    :params ax: matplotlib axis\n    :params samples: complex samples to plot\n    :params labels: list of labels assigning a label per sample\n    \"\"\"\n    classes = np.unique(labels)\n    for c in classes:\n        c_idx = np.nonzero(labels == c)\n        ax.scatter(samples[c_idx].real, samples[c_idx].imag)", "\n\ndef plot_classifier(ax, class_fn, range_x, range_y, points_x, points_y):\n    \"\"\"\n    Plot classifier regions.\n\n    :params ax: matplotlib axis\n    \"\"\"\n    grid_x, grid_y = torch.meshgrid(\n        torch.linspace(range_x[0], range_x[1], points_x),\n        torch.linspace(range_y[0], range_y[1], points_y),\n    )\n    class_input = torch.cat(\n        (torch.reshape(grid_x, (-1, 1)), torch.reshape(grid_y, (-1, 1))), dim=1\n    )\n    class_output = class_fn(class_input)\n\n    plot_value = torch.reshape(class_output, (points_x, -1)).detach().numpy()\n    ax.contourf(grid_x.detach().numpy(), grid_y.detach().numpy(), plot_value, levels=10)", "\n\ndef plot_constellation(\n    ax,\n    constellation,\n    label=True,\n    keep=False,\n    color=None,\n    size=2,\n    probabilities=None,\n    label_type=\"hex\",\n):\n    \"\"\"Plot constellation points.\n\n    :param ax: matplotlib axis\n    :param constellation: Constellation points in the order of their bitlabels\n    :param label: Switch to plot labels\n    :param keep: Keep existing drawing on the axis\n    :param color: Color for the constellation points\n    :param size: Size of the constellation points\n    :param probabilities: scale the size of the constellation according\n                          to their probability.\n    :param label_type: Hexadecimal or bitstring labels\n    :returns: axis\n\n    \"\"\"\n    const_cpu = constellation.detach().cpu().numpy()\n\n    if label_type == \"hex\":\n        vhex = np.vectorize(hex)\n        labels = list(str(v)[2:].upper() for v in vhex(np.arange(len(const_cpu))))\n    else:\n        labels = list(\n            [\n                str(row)\n                for row in np.unpackbits(\n                    np.expand_dims(np.arange(len(const_cpu), dtype=np.uint8), 1),\n                    axis=1,\n                    count=int(np.log2(len(const_cpu))),\n                    bitorder=\"little\",\n                )\n            ]\n        )\n    if not keep:\n        ax.clear()\n    ax.set_facecolor(\"white\")\n    if probabilities is not None:\n        size = probabilities * 600\n    if color is not None:\n        ax.scatter(\n            const_cpu.real,\n            const_cpu.imag,\n            alpha=0.8,\n            edgecolor=None,\n            s=size,\n            color=color,\n        )\n    else:\n        ax.scatter(const_cpu.real, const_cpu.imag, alpha=0.8, edgecolor=None, s=size)\n    if label:\n        for point, label in zip(const_cpu, labels):\n            ax.annotate(\n                label,\n                (point.real, point.imag),\n                textcoords=\"offset points\",\n                xytext=(1, 4),\n                size=8,\n                color=\"black\",\n            )", "\n\ndef plot_bitwise_decision_regions(\n    axs,\n    demapper,\n    num_samples=10000,\n    meshgrid=False,\n    additional_args=None,\n    sample_radius=1.2,\n):\n    \"\"\"\n    Plot the bitwise decision regions of the demapper.\n\n    This is done by either sampling random points within a radius or using a meshgrid\n    to sample points along the real and imaginary axis with a fixed spacing.\n\n    :param axs: Matplotlib axis\n    :param demapper: demapper object\n    :param num_samples: number of samples in total or per axis is meshgrid is used\n    :param meshgrid: Use a meshgrid to sample the 2D area\n    :param additional_args: additional arguments to provide to the demapper\n    :param sample_radius: either the radius or the maximum amplitude for meshgrid\n\n    \"\"\"\n    if meshgrid:\n        pp_axis = num_samples\n        sample_real, sample_imag = torch.meshgrid(\n            (\n                torch.linspace(-sample_radius, sample_radius, pp_axis),\n                torch.linspace(-sample_radius, sample_radius, pp_axis),\n            )\n        )\n        sample_points = sample_real + 1j * sample_imag\n        sample_points = sample_points.flatten().to(next(demapper.parameters()).device)\n\n        if additional_args is not None:\n            args_expanded = tuple(\n                arg.expand(num_samples**2, 1) for arg in additional_args\n            )\n\n    else:\n        sample_points = (\n            sample_radius\n            * torch.rand((num_samples,))\n            * torch.exp(2j * np.pi * torch.rand((num_samples,)))\n        ).to(next(demapper.parameters()).device)\n        if additional_args is not None:\n            args_expanded = tuple(arg.expand(num_samples, 1) for arg in additional_args)\n\n    if additional_args is None:\n        sample_demapped_bits = demapper(sample_points)\n    else:\n        sample_demapped_bits = demapper(sample_points, *args_expanded)\n    for m in range(demapper.m.item()):\n        ax = axs[m]\n        axs[m].clear()\n        _ = ax.tricontourf(\n            sample_points.real.detach().cpu().numpy(),\n            sample_points.imag.detach().cpu().numpy(),\n            np.clip(sample_demapped_bits[:, m].detach().cpu().numpy(), -20, 19.9),\n            levels=np.linspace(-20, 20, 100),\n            cmap=\"RdBu\",\n        )\n        # plt.colorbar(tcf, ax=ax)\n    return sample_points, sample_demapped_bits", "\n\ndef setup_logging(level, component=\"\"):\n    \"\"\"\n    Configure the Python logging module to print logs for given component \\\n    and minimum level on stdout.\n\n    :param level: A level from the logging module as minimum level\n    :param component: The parent component for which all logs should be displayed.\n    \"\"\"\n    logger = logging.getLogger(component)\n    logger.setLevel(level)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(level)\n\n    # create formatter\n    formatter = logging.Formatter(\n        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    )\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)", "\n\ndef sigma_phi(linewidth, symbolrate):\n    r\"\"\"Calculate :math:`\\sigma_{\\phi}` given a laser linewidth and symbol rate.\n\n    :param linewidth: laser linewidth :math:`\\Delta f`  [Hz]\n    :param symbolrate: symbol rate :math:`R_{\\mathrm{sym}}` [Bd]\n    :returns: :math:`\\sqrt{2 \\pi \\Delta f / R_{\\mathrm{sym}}}`\n\n    \"\"\"\n    return np.sqrt(2 * np.pi * linewidth / symbolrate)", "\n\ndef N0(SNR):\n    r\"\"\"Calculate :math:`N_0` from SNR.\n\n    :param SNR: signal-to-noise ratio :math:`s` [dB]\n    :returns: :math:`10^{-\\frac{s}{10}}`\n\n    \"\"\"\n    return 10 ** (-SNR / 10)", "\n\ndef export_constellation(output_file, constellation):\n    \"\"\"Export a constellation to a csv file.\n\n    :param output_file: path to file\n    :param constellation: tensor of complex constellation points\n    :returns:\n\n    \"\"\"\n    vhex = np.vectorize(hex)\n    labels = list(str(v)[2:].upper() for v in vhex(np.arange(len(constellation))))\n    result = [\"real\\timag\\tlabel\\n\"]\n    for point, label in zip(constellation, labels):\n        result.append(f\"{point.real}\\t{point.imag}\\t{label}\\n\")\n    with open(output_file, \"w\") as result_file:\n        result_file.truncate()\n        result_file.writelines(result)", "\n\ndef beta2(D, wavelength):\n    r\"\"\"\n    Calculate :math:`\\beta_2` from the dispersion coefficient and wavelength.\n\n    :param D: Dispersion coefficient [ps/nm/km]\n    :param wavelength: wavelength of optical carrier [nm]\n    :returns: beta2 in [ps**2/km]\n    \"\"\"\n    return -D * wavelength**2 / (2 * np.pi * 3e8) * 1e3", "\n\ndef wavelength(D, beta2):\n    r\"\"\"\n    Calculate the wavelength from :math:`\\beta_2` and the dispersion coefficient.\n\n    :param D: Dispersion coefficient [ps/nm/km]\n    :param beta2: Group velocity dispersion [ps**2/km]\n    :param: returns wavelength of optical carrier [nm]\n    \"\"\"\n    return np.sqrt(-beta2 * 2 * np.pi * 3e8 / D / 1e3)", "\n\ndef estimate_SNR(x, y):\n    \"\"\"\n    Calculate the (non-linear) SNR from the sent and received symbols.\n\n    :params x: signal vector\n    :params y: signal + noise vector\n    \"\"\"\n    signal_power = torch.mean(torch.abs(x) ** 2)\n    noise_power = torch.mean(torch.abs(x - y) ** 2)\n    snr = signal_power / noise_power\n    return 10 * torch.log10(snr)", "\n\ndef pow2db(y):\n    \"\"\"Calculate the power in decibel.\n\n    :param y: power in linear units [W]\n    :returns: power in decibel [dBW]\n\n    \"\"\"\n    return 10 * torch.log10(y)", "\n\ndef pow2dbm(y):\n    \"\"\"Calculate the power in dBm.\n\n    :param y: power in linear units [W]\n    :returns: power in dBm [dBm]\n    \"\"\"\n    return 10 * torch.log10(y) + 30\n", "\n\ndef db2pow(ydb):\n    \"\"\"Calculate the power in linear units.\n\n    :param ydb: power in decibel [dB]\n    :returns: power in linear units [W]\n    \"\"\"\n    return 10 ** (ydb / 10)\n", "\n\ndef dbm2pow(ydbm):\n    \"\"\"Calculate the power in linear units.\n\n    :param ydbm: power in dBm [dBm]\n    :returns: power in linear units [W]\n    \"\"\"\n    return 10 ** ((ydbm - 30) / 10)\n", ""]}
{"filename": "src/mokka/utils/bitops/torch.py", "chunked_list": ["\"\"\"Operations for bit manipulation in PyTorch.\"\"\"\nimport torch\n\n\ndef bits2idx(bits):\n    \"\"\"\n    Convert bits to their integer representation.\n\n    :param bits: Vectors of bits with the last dimension representing the size of words\n    :returns: Vector of integers\n    \"\"\"\n    coeff = 2 ** torch.arange(bits.shape[-1], device=bits.device)\n    B = torch.sum(bits * torch.flip(coeff, dims=(0,)), -1)\n    return B", "\n\ndef bits_to_onehot(bits):\n    \"\"\"\n    Convert bits to one hot vectors.\n\n    :param bits: Vectors of bits with the last dimension representing the size of words\n    :returns: Vectors of one-hot vectors\n    \"\"\"\n    B = bits2idx(bits)\n    idx = torch.meshgrid(list(torch.arange(s) for s in B.size()))\n    B_hot = torch.zeros(\n        (*B.size(), 2 ** bits.shape[-1]), dtype=torch.float32, device=bits.device\n    )\n    idx = (*idx, B.long())\n    B_hot[idx] = 1.0\n    return B_hot", "\n\ndef idx2bits(idxs, num_bits_per_symbol):\n    \"\"\"\n    Convert integer representations of bit vectors back to bits.\n\n    :param idxs: Vector of indices\n    :param num_bits_per_symbol: size of the bit vectors\n    :returns: vector of bit vectors\n    \"\"\"\n    bits = torch.remainder(\n        torch.bitwise_right_shift(\n            torch.unsqueeze(idxs.long(), 1),\n            torch.arange(num_bits_per_symbol, device=idxs.device),\n        ),\n        2,\n    )\n    return bits", ""]}
{"filename": "src/mokka/utils/bitops/__init__.py", "chunked_list": ["\"\"\"Operations for bit manipulation.\"\"\"\nfrom . import numpy  # noqa\nfrom .numpy import gray  # noqa\n\ntry:\n    from . import torch  # noqa\nexcept ImportError:\n    pass\n", ""]}
{"filename": "src/mokka/utils/bitops/numpy.py", "chunked_list": ["\"\"\"Module to implement bit operations in NumPy.\"\"\"\n\nimport numpy as np\n\n\ndef idx2bits(idxs, num_bits_per_symbol):\n    \"\"\"\n    Convert integer representations of bit vectors to bits in LSB-first.\n\n    :param idxs: Vector of indices\n    :param num_bits_per_symbol: size of the bit vectors\n    :returns: vector of bit vectors\n    \"\"\"\n    bits = np.remainder(\n        np.right_shift(\n            idxs[:, np.newaxis],\n            np.arange(num_bits_per_symbol),\n        ),\n        2,\n    )\n    return bits", "\n\ndef bits2idx(bits):\n    \"\"\"\n    Convert bits in LSB-first to their integer representation.\n\n    :param bits: Vectors of bits with the last dimension representing the size of words\n    :returns: Vector of integers\n    \"\"\"\n    coeff = 2 ** np.arange(bits.shape[-1])\n    B = np.sum(bits * np.flip(coeff, dims=(0,)), -1)\n    return B", "\n\ndef generate_all_input_bits(m):\n    \"\"\"Generate all :math:`2^m` possible bitstrings.\n\n    :param m: Length of the bitstring\n    :returns: Array with all possible bitstrings in LSB\n\n    \"\"\"\n    nums = np.arange(2**m, dtype=np.uint8)\n    bits = idx2bits(nums, m)\n    return bits", "\n\ndef gray(m):\n    \"\"\"Generate a sequence of bit strings with binary-reflected Gray coding.\n\n    :param m: length of the bitstrings\n    :returns: Tuple of :math:`2^m` Gray-encoded bitstrings\n\n    \"\"\"\n    if m == 1:\n        return ((0,), (1,))\n    prev = gray(m - 1)\n    return tuple((0,) + p for p in prev) + tuple((1,) + p for p in reversed(prev))", ""]}
{"filename": "src/mokka/utils/generators/torch.py", "chunked_list": ["\"\"\"Module for data generators in PyTorch.\"\"\"\n\nimport torch  # noqa\n"]}
{"filename": "src/mokka/utils/generators/__init__.py", "chunked_list": ["\"\"\"Module with data generators.\"\"\"\n\nfrom . import numpy  # noqa\n\ntry:\n    from . import torch  # noqa\nexcept ImportError:\n    pass\n", ""]}
{"filename": "src/mokka/utils/generators/numpy.py", "chunked_list": ["\"\"\"Data generators implemented in NumPy.\"\"\"\nimport numpy as np\nimport os\nimport sys\n\nseed = int.from_bytes(os.urandom(4), byteorder=sys.byteorder)\ngen = np.random.default_rng(seed)\n\n\ndef generate_BPSK(N, P_in_dbm):\n    \"\"\"Generate BPSK symbols with a given power.\n\n    :param N: Number of BPSK symbols to generate\n    :param P_in_dbm: signal power [dBm]\n    :returns: (pseudo-)randomly generated array of BPSK symbols\n\n    \"\"\"\n    P_in = 10 ** (P_in_dbm / 10 - 3)\n    symbols = np.array([-1, 1]) * np.sqrt(P_in)\n    samples = gen.choice(symbols, (N,))\n    return samples", "\ndef generate_BPSK(N, P_in_dbm):\n    \"\"\"Generate BPSK symbols with a given power.\n\n    :param N: Number of BPSK symbols to generate\n    :param P_in_dbm: signal power [dBm]\n    :returns: (pseudo-)randomly generated array of BPSK symbols\n\n    \"\"\"\n    P_in = 10 ** (P_in_dbm / 10 - 3)\n    symbols = np.array([-1, 1]) * np.sqrt(P_in)\n    samples = gen.choice(symbols, (N,))\n    return samples", "\n\ndef generate_bits(shape):\n    \"\"\"Generate uniform random bits.\n\n    :param shape: tuple with resulting shape\n    :returns: array with uniform random bits in the requested shape\n\n    \"\"\"\n    bits = np.random.choice([0, 1], shape)\n    return bits", "\n\ndef generate_all_bits(m):\n    \"\"\"Generate all possible bitstrings of length m.\n\n    :param m: length of the bitstring\n    :returns: array with all possible bitstrings.\n\n    \"\"\"\n    all_bits = np.arange(2**m, dtype=np.uint8)\n    all_bits = np.expand_dims(all_bits, 1)\n    # Generate bits from 0 to 2**m\n    B = np.flip(np.unpackbits(all_bits, axis=1, count=m, bitorder=\"little\"), axis=1)\n    return B", ""]}
{"filename": "src/mokka/functional/torch.py", "chunked_list": ["\"\"\"Functions that do not fit anywhere else - in PyTorch.\"\"\"\n\nimport torch\nimport numpy as np\n\n\ndef convolve(signal, kernel, mode=\"full\"):\n    \"\"\"Calculate the 1-D convolution using the torch.conv1d function.\n\n    This function is a convenience to assist using the torch convolution function\n    within a signal processing context. The convolution function provided by\n    PyTorch has image processing in mind and therefore some parameters of this function\n    can be simplfied.\n\n    :param signal: signal in the time domain.\n    :param kernel: second signal in the time domain, must be shorter.\n    :param mode: either \"full\", \"same\" or \"valid\".\n    :returns: convolution between signal and kernel.\n\n    \"\"\"\n    if mode == \"full\":\n        padding = kernel.shape[0] - 1\n    elif mode == \"same\":\n        padding = \"same\"\n    elif mode == \"valid\":\n        padding = \"valid\"\n    return torch.squeeze(\n        torch.conv1d(\n            signal[None, :],\n            torch.flip(kernel[None, None, :], (2,)),\n            padding=padding,\n        )\n    )", "\n\ndef distribution_quantization(probs, n):\n    \"\"\"\n    Compute a quantized distribution for given probabilities.\n\n    This function uses an algorithm introduced for calculating\n    a discrete distribution minimizing the KL divergence for CCDM.\n\n    :param probs: probabilities of occurence for each element.\n    :param n: length of the full sequence.\n    :returns: number of ocurrences for each element in the sequence.\n\n    \"\"\"\n    c = torch.floor(probs * n)\n    k = c + 1\n    klogk = k * torch.log(k)\n    clogc = c * torch.log(c)\n    clogc[torch.isnan(clogc)] = 0\n    inc_cost = klogk - clogc - torch.log(probs)\n    for i in torch.arange(n - torch.sum(c).item()):\n        idx = torch.argmin(inc_cost)\n        c[idx] += 1\n        k = c[idx] + 1\n        tmp = k * torch.log(k)\n        inc_cost[idx] = inc_cost[idx] - klogk[idx] - klogk[idx] + tmp + clogc[idx]\n        clogc[idx] = klogk[idx]\n        klogk[idx] = tmp\n    return c", "\n\ndef distribution_quant_gumbel_softmax(probs, n, temp=0.1):\n    \"\"\"\n    Compute a quantized distribution for given probabilities with Gumbel-Softmax.\n\n    This uses the Gumbel-Softmax sampling method to provide a differentiable\n    way to embed the information about the distribution into the sequence.\n    We use the straight-through trick to retain the gradients of softmax but\n    actually use the values from a argmax for calculation.\n\n    :param probs: probabilities of occurence for each element\n    :param n: length of the sequence to sample\n    :param temp: temperature of Softmax.\n    :returns: sampled indices in as sequence of length n\n    \"\"\"\n    probs = torch.atleast_2d(probs)\n\n    oh_soft = torch.nn.functional.gumbel_softmax(\n        torch.tile(torch.log(probs), dims=(n, 1)), tau=temp, dim=1, hard=False\n    )\n    oh_hard = torch.nn.functional.one_hot(\n        torch.argmax(oh_soft, dim=1), oh_soft.shape[1]\n    )\n    oh = oh_hard - oh_soft.detach() + oh_soft\n    idx = (\n        torch.arange(0, probs.shape[1], dtype=torch.float, device=oh.device)[None, :]\n        @ oh.T\n    )\n    return idx", "\n\ndef unwrap_torch(p, discont=np.pi, dim=-1, period=2 * np.pi):\n    \"\"\"\n    Perform phase unwrapping in PyTorch.\n\n    This implementation follows the NumPy implementation closely.\n\n    :param p: tensor with angle values\n    :param discont: discontinuity to unwrap\n    :param dim: dimension to unwrap\n    :param period: which periodicity the signal has\n    \"\"\"\n    # NP unwrap implemented in Torch\n    nd = p.ndim\n    dd = torch.diff(p, dim=dim)\n    slice1 = [slice(None, None)] * nd  # full slices\n    slice1[dim] = slice(1, None)\n    slice1 = tuple(slice1)\n    ddmod = torch.remainder(dd + np.pi, 2 * np.pi) - np.pi\n    ph_correct = ddmod - dd\n    up = p.clone()\n    up[slice1] = p[slice1] + torch.cumsum(ph_correct, dim=dim)\n    return up", ""]}
{"filename": "src/mokka/functional/__init__.py", "chunked_list": ["\"\"\"Functions which do not fit anywhere else.\"\"\"\nfrom . import torch  # noqa\n"]}
{"filename": "src/mokka/mapping/torch.py", "chunked_list": ["\"\"\"PyTorch implementation of Mappers and Demappers.\"\"\"\n\nfrom .. import normalization, functional\nfrom .numpy import QAM\nfrom ..utils.bitops.torch import bits_to_onehot\nfrom ..utils.generators.numpy import generate_all_bits\nfrom . import numpy as classical\nimport torch\nimport logging\nimport numpy as np", "import logging\nimport numpy as np\nimport math\n\nlogger = logging.getLogger(__name__)\n\n\nclass QAMConstellationMapper(torch.nn.Module):\n    \"\"\"Non-trainable QAM constellation Mapper.\"\"\"\n\n    def __init__(self, m):\n        \"\"\"Construct QAMConstellationMapper.\"\"\"\n        super(QAMConstellationMapper, self).__init__()\n        self.register_buffer(\"m\", torch.tensor(m))\n        qam = QAM(m)\n        constellation_symbols = qam.get_constellation().flatten()\n        self.register_buffer(\n            \"symbols\", torch.tensor(constellation_symbols, dtype=torch.complex64)\n        )\n        self.register_buffer(\"p_symbols\", torch.full((2**m,), 1.0 / (2**m)))\n\n    def get_constellation(self, *args):\n        \"\"\"\n        Return all constellation symbols.\n\n        :returns: all constellation symbols\n        \"\"\"\n        b = torch.tensor(generate_all_bits(self.m.item()).copy()).to(\n            self.symbols.device\n        )\n        symbols = self.forward(b, *args)\n        return symbols\n\n    def forward(self, b, *args):\n        \"\"\"\n        Perform mapping of bitstrings.\n\n        :returns: complex symbol per bitstring of length `self.m`\n        \"\"\"\n        device = b.device\n        logger.debug(\"b size: %s\", b.size())\n        B_hot = bits_to_onehot(b)\n\n        c = torch.unsqueeze(self.symbols, 0).expand(*b.size()[:-1], -1).to(device)\n        c = normalization.energy(c, self.p_symbols)\n        x = torch.sum(B_hot * c, -1)\n        x = torch.unsqueeze(x, 1)\n        return x  # , idx[1]", "\n\nclass CustomConstellationMapper(torch.nn.Module):\n    \"\"\"Non-trainable custom constellation Mapper.\"\"\"\n\n    def __init__(self, m, constellation_symbols):\n        \"\"\"Construct CustomConstellationMapper.\"\"\"\n        super(CustomConstellationMapper, self).__init__()\n        assert len(constellation_symbols) == 2**m\n        self.register_buffer(\"m\", torch.tensor(m))\n        self.register_buffer(\n            \"symbols\",\n            constellation_symbols,\n        )\n\n    def get_constellation(self, *args):\n        \"\"\"\n        Return all constellation symbols.\n\n        :returns: all constellation symbols\n        \"\"\"\n        return self.symbols\n\n    def forward(self, b, *args):\n        \"\"\"\n        Perform mapping of bitstrings.\n\n        :returns: complex symbol per bitstring of length `self.m`\n        \"\"\"\n        device = b.device\n        logger.debug(\"b size: %s\", b.size())\n\n        B_hot = bits_to_onehot(b)\n\n        c = torch.unsqueeze(self.symbols, 0).expand(*b.size()[:-1], -1).to(device)\n        x = torch.sum(B_hot * c, -1)\n        x = torch.unsqueeze(x, 1)\n        return x  # , idx[1]", "\n\nclass SimpleConstellationMapper(torch.nn.Module):\n    \"\"\"\n    Mapper which  maps using a simple list of weights  and a one-hot vector.\n\n    :param m: bits per symbol\n    \"\"\"\n\n    def __init__(self, m, qam_init=False):\n        \"\"\"Construct SimpleConstellationMapper.\"\"\"\n        super(SimpleConstellationMapper, self).__init__()\n        self.register_buffer(\"m\", torch.tensor(m))\n\n        if qam_init:\n            symbols = QAM(m).get_constellation().flatten()\n            self.register_parameter(\n                \"weights\",\n                torch.nn.Parameter(\n                    torch.tensor(\n                        np.stack((symbols.real, symbols.imag), axis=-1),\n                        dtype=torch.float32,\n                    ),\n                ),\n            )\n        else:\n            self.weights = torch.nn.Parameter(\n                torch.nn.init.xavier_normal_(\n                    torch.zeros((2**m, 2), dtype=torch.float32)\n                )\n            )\n\n    def get_constellation(self, *args):\n        \"\"\"\n        Return constellation for all input bits.\n\n        :params args: same arguments as for forward() if constellation mapper is\n                      parametrized\n        :returns: tensor of constellation points\n        \"\"\"\n        # Test bits\n        B = generate_all_bits(self.m.item()).copy()\n        bits = torch.from_numpy(B).to(self.weights.device)\n        logger.debug(\"bits device: %s\", bits.device)\n        out = self.forward(bits)\n        return out\n\n    def forward(self, b, *args):\n        \"\"\"\n        Perform mapping of bits to symbols.\n\n        This mappper ignores all optional arguments as this Module\n        is not parametrizable on call\n\n        :params b: PyTorch tensor with bit vectors\n        :returns: mapped constellation points\n        \"\"\"\n        # Generate one-hot representatios for m bits\n        # in vectors of length 2**m\n        logger.debug(\"b size: %s\", b.size())\n        B_hot = bits_to_onehot(b)\n        c = torch.view_as_complex(\n            torch.unsqueeze(self.weights, 0).expand(b.size()[0], -1, -1),\n        )\n        c = normalization.energy(c)\n        x = torch.sum(B_hot * c, -1)\n        x = torch.unsqueeze(x, 1)\n        return x\n\n    @staticmethod\n    def load_model(model_dict):\n        \"\"\"\n        Load saved weights.\n\n        :param model_dict: dictionary loaded with `torch.load()`\n        \"\"\"\n        mapper_dict = {\n            k[len(\"mapper.\") :]: v\n            # k.removeprefix(\"mapper.\"): v #\n            # Reenable if terminal computers are Python 3.9+\n            for k, v in model_dict.items()\n            if k.startswith(\"mapper\")\n        }\n        m = mapper_dict[\"m\"].item()\n        model = SimpleConstellationMapper(m)\n        model.load_state_dict(mapper_dict)\n        return model", "\n\nclass ConstellationMapper(torch.nn.Module):\n    \"\"\"\n    Mapper which maps from bits in float 0,1 representation to \\\n    Symbols in the complex plane with average energy E_S = 1.\n\n    :param m: bits per symbol\n    :param mod_extra_params: index of extra parameters to feed the NN\n    :param center_constellation: Apply operation at the end to center constellation\n    :param qam_init: Initialize the weights to form a Gray mapped QAM constellation\n    \"\"\"\n\n    def __init__(\n        self, m, mod_extra_params=None, center_constellation=False, qam_init=False\n    ):\n        \"\"\"Construct ConstellationMapper.\"\"\"\n        super(ConstellationMapper, self).__init__()\n        self.ReLU = torch.nn.ReLU()\n        self.register_buffer(\"m\", torch.tensor(m))\n        self.register_buffer(\"mod_extra_params\", torch.tensor(mod_extra_params or []))\n        self.register_buffer(\"center_constellation\", torch.tensor(center_constellation))\n        # Mapper\n        self.map1 = torch.nn.Linear(max(len(mod_extra_params or []), 1), 2 ** (m + 1))\n        self.map2 = torch.nn.Linear(2 ** (m + 1), 2 ** (m + 1))\n        self.register_buffer(\"p_symbols\", torch.full((2**m,), 1.0 / (2**m)))\n        if qam_init:\n            with torch.no_grad():\n                symbols = QAM(m).get_constellation().flatten()\n                self.map1.weight.zero_()\n                self.map1.bias.fill_(1)\n                self.map2.weight = torch.nn.Parameter(\n                    torch.diag(\n                        torch.tensor(\n                            np.stack((symbols.real, symbols.imag), axis=-1).flatten(),\n                            dtype=torch.float32,\n                        ),\n                    )\n                )\n                self.map2.bias.zero_()\n        else:\n            torch.nn.init.xavier_normal_(self.map1.weight)\n            torch.nn.init.xavier_normal_(self.map2.weight)\n\n    def forward(self, b, *args):\n        \"\"\"\n        Perform mapping of bitstrings.\n\n        :returns: complex symbol per bitstring of length `self.m`\n        \"\"\"\n        # Generate one-hot representatios for m bits\n        # in vectors of length 2**m\n        device = b.device\n        logger.debug(\"b size: %s\", b.size())\n        B_hot = bits_to_onehot(b)\n        logger.debug(\"len args: %s\", len(args))\n        logger.debug(\"args: %s\", args)\n        if len(self.mod_extra_params):\n            # Concatenate arguments along batch_axis\n            mod_args = (\n                torch.stack(\n                    tuple(args[idx] for idx in self.mod_extra_params),\n                    dim=1,\n                )\n                .to(device)\n                .squeeze()\n            )\n            # Generate Constellation mapping c of size 2**m\n            # c = self.ReLU(self.map1(snr_dB))\n        else:\n            # Just feed the network with zeros which will zero\n            # influence of weights of first layer\n            # and only train bias\n            mod_args = torch.zeros((*b.size()[:-1], 1), device=device)\n            # c = self.ReLU(self.map1(torch.zeros((torch.numel(B),), device=device)))\n            # c = torch.unsqueeze(c, 0)\n        logger.debug(\"mod_args: %s\", mod_args)\n        logger.debug(\"mod_args dim: %s\", mod_args.size())\n        c = self.ReLU(self.map1(mod_args))\n        logger.debug(\"c size at creation: %s\", c.size())\n        c = self.map2(c)\n        c = torch.view_as_complex(\n            torch.reshape(c, (*b.size()[:-1], 2 ** self.m.item(), 2))\n        )\n        if self.center_constellation.item():\n            c = normalization.centered_energy(c, self.p_symbols)\n        else:\n            c = normalization.energy(c, self.p_symbols)\n        logger.debug(\"c device: %s\", c.device)\n        logger.debug(\"c size after scaling: %s\", c.size())\n        logger.debug(\"c energy for item 0: %s\", torch.abs(c[0, :]) ** 2)\n        # transmit (batchsize x symbols per training sample) symbols\n        x = torch.sum(B_hot * c, -1)\n        x = torch.unsqueeze(x, 1)\n        logger.debug(\"x device: %s\", x.device)\n        return x\n\n    def get_constellation(self, *args):\n        \"\"\"\n        Return constellation for all input bits.\n\n        :params args: same arguments as for forward() if constellation mapper is\n                      parametrized\n        :returns: tensor of constellation points\n        \"\"\"\n        # Test bits\n        mod_args = torch.tensor(args, dtype=torch.float32)\n        mod_args = mod_args.repeat(2 ** self.m.item(), 1).split(1, dim=-1)\n        B = generate_all_bits(self.m.item()).copy()\n        bits = torch.from_numpy(B).to(self.map1.weight.device)\n        logger.debug(\"bits device: %s\", bits.device)\n        out = self.forward(bits, *mod_args).flatten()\n        return out\n\n    @staticmethod\n    def load_model(model_dict):\n        \"\"\"\n        Load saved weights.\n\n        :param model_dict: dictionary loaded with `torch.load()`\n        \"\"\"\n        mapper_dict = {\n            (k[len(\"mapper.\") :] if k.startswith(\"mapper\") else k): v\n            # k.removeprefix(\"mapper.\"): v\n            # Renable if terminal computers have Python 3.9+\n            for k, v in model_dict.items()\n            if not (k.startswith(\"demapper\") or k.startswith(\"channel\"))\n        }\n        m = mapper_dict[\"m\"].item()\n        mod_extra_params = mapper_dict[\"mod_extra_params\"].tolist()\n        model = ConstellationMapper(m, mod_extra_params)\n        if \"p_symbols\" not in mapper_dict:\n            mapper_dict[\"p_symbols\"] = torch.full(\n                (2 ** mapper_dict[\"m\"],), 1.0 / (2 ** mapper_dict[\"m\"])\n            )\n        model.load_state_dict(mapper_dict)\n        return model", "\n\nclass SeparatedConstellationMapper(torch.nn.Module):\n    \"\"\"\n    Model to map complex and imaginary parts separately \\\n    in two PAM modulations and add them after modulation.\n\n    :param m: bits per symbol\n    :param mod_extra_params: index of extra parameters to feed the NN\n    :param center_constellation: Apply operation at the end to center constellation\n    :param qam_init: Initialize the weights to form a Gray mapped QAM constellation\n    \"\"\"\n\n    def __init__(self, m, m_real=None, m_imag=None, qam_init=False):\n        \"\"\"Construct SeparatedConstellationMapper.\"\"\"\n        super(SeparatedConstellationMapper, self).__init__()\n        if m % 2 > 0 and m_real is None and m_imag is None:\n            raise ValueError(\"m needs to be even or m_real/m_imag have to be specified\")\n        if m_real is not None and m_imag is not None:\n            if m != (m_real + m_imag):\n                raise ValueError(\"m_real and m_imag must add up to m\")\n        self.register_buffer(\"m\", torch.tensor(m))\n        if m_real is None and m_imag is None:\n            m_real = m // 2\n            m_imag = m // 2\n        elif m_imag is None:\n            m_imag = m - m_real\n        elif m_real is None:\n            m_real = m - m_imag\n\n        self.register_buffer(\"m_real\", torch.tensor(m_real))\n        self.register_buffer(\"m_imag\", torch.tensor(m_imag))\n\n        if qam_init:\n            real_gray_idx = (\n                torch.tensor(\n                    np.packbits(classical.gray(m_real), bitorder=\"big\", axis=-1)\n                )\n                .squeeze()\n                .to(torch.int64)\n            )\n            imag_gray_idx = (\n                torch.tensor(\n                    np.packbits(classical.gray(m_imag), bitorder=\"big\", axis=-1)\n                )\n                .squeeze()\n                .to(torch.int64)\n            )\n\n            real_pam = torch.linspace(\n                -(2**m_real - 1), 2**m_real - 1, 2**m_real\n            ) * np.sqrt(3 / (2 * (2**m - 1)))\n            imag_pam = torch.linspace(\n                -(2**m_imag - 1), 2**m_imag - 1, 2**m_imag\n            ) * np.sqrt(3 / (2 * (2**m - 1)))\n            real_sort_idx = torch.argsort(real_gray_idx)\n            imag_sort_idx = torch.argsort(imag_gray_idx)\n            self.real_weights = torch.nn.Parameter(real_pam[real_sort_idx].unsqueeze(1))\n            self.imag_weights = torch.nn.Parameter(imag_pam[imag_sort_idx].unsqueeze(1))\n\n        else:\n            self.real_weights = torch.nn.Parameter(\n                torch.nn.init.xavier_normal_(\n                    torch.zeros((2**m_real, 1), dtype=torch.float32)\n                )\n            )\n            self.imag_weights = torch.nn.Parameter(\n                torch.nn.init.xavier_normal_(\n                    torch.zeros((2**m_imag, 1), dtype=torch.float32)\n                )\n            )\n\n    def get_constellation(self, *args):\n        \"\"\"\n        Return constellation for all input bits.\n\n        :params args: same arguments as for forward() if constellation mapper is\n                      parametrized\n        :returns: tensor of constellation points\n        \"\"\"\n        # Test bits\n        all_bits = np.arange(2 ** self.m.item(), dtype=np.uint8)\n        all_bits = np.expand_dims(all_bits, 1)\n        B = np.unpackbits(all_bits, axis=1, count=self.m.item(), bitorder=\"little\")\n        bits = torch.from_numpy(B).to(self.real_weights.device)\n        logger.debug(\"bits device: %s\", bits.device)\n        out = self.forward(bits, *args)\n        return out\n\n    def forward(self, b, *args):\n        \"\"\"\n        Perform mapping of bitstrings.\n\n        :returns: complex symbol per bitstring of length `self.m`\n        \"\"\"\n        # Generate one-hot representatios for m bits\n        # in vectors of length 2**m\n        logger.debug(\"b size: %s\", b.size())\n        B_hot = bits_to_onehot(b)\n        c = (\n            self.real_weights.unsqueeze(1).repeat(1, self.imag_weights.size()[0], 1)\n            + 1j\n            * self.imag_weights.unsqueeze(0).repeat(self.real_weights.size()[0], 1, 1)\n        ).flatten()\n        c = torch.unsqueeze(c, 0).expand(b.size()[0], -1)\n        c = normalization.energy(c)\n        x = torch.sum(B_hot * c, -1)\n        x = torch.unsqueeze(x, 1)\n        return x\n\n    @staticmethod\n    def load_model(model_dict):\n        \"\"\"\n        Load saved weights.\n\n        :param model_dict: dictionary loaded with `torch.load()`\n        \"\"\"\n        mapper_dict = {\n            k[len(\"mapper.\") :]: v\n            # k.removeprefix(\"mapper.\"): v #\n            # Reenable if terminal computers are Python 3.9+\n            for k, v in model_dict.items()\n            if k.startswith(\"mapper\")\n        }\n        m = mapper_dict[\"m\"].item()\n        m_real = mapper_dict[\"m_real\"].item()\n        m_imag = mapper_dict[\"m_imag\"].item()\n        model = SeparatedConstellationMapper(m, m_real, m_imag)\n        model.load_state_dict(mapper_dict)\n        return model", "\n\nclass ConstellationDemapper(torch.nn.Module):\n    \"\"\"\n    Demap from a complex input with optional SNR to an output with \\\n    m-Levels with trainable neural networks.\n\n    :param m: Bits per symbol\n    :params depth: Number of hidden layers\n    :params width: Neurons per layer\n    \"\"\"\n\n    def __init__(self, m, depth=3, width=128, with_logit=True, demod_extra_params=None):\n        \"\"\"Construct ConstellationDemapper.\"\"\"\n        super(ConstellationDemapper, self).__init__()\n        self.with_logit = with_logit\n\n        self.register_buffer(\n            \"demod_extra_params\", torch.tensor(demod_extra_params or [])\n        )\n        self.register_buffer(\"m\", torch.tensor(m))\n        self.register_buffer(\"width\", torch.tensor(width))\n        self.register_buffer(\"depth\", torch.tensor(depth))\n\n        self.ReLU = torch.nn.LeakyReLU()\n        self.sigmoid = torch.nn.Sigmoid()\n\n        self.demaps = torch.nn.ModuleList()\n        input_width = 2 + len(demod_extra_params or [])\n        self.demaps.append(torch.nn.Linear(input_width, width))\n        for d in range(depth - 2):\n            self.demaps.append(torch.nn.Linear(width, width))\n        self.demaps.append(torch.nn.Linear(width, m))\n\n        for demap in self.demaps:\n            torch.nn.init.xavier_normal_(demap.weight)\n\n    def forward(self, y, *args):\n        \"\"\"\n        Perform bitwise demapping of complex symbols.\n\n        :returns: Approximated log likelihood ratio of dimension `self.m`\n        \"\"\"\n        y = torch.view_as_real(y)\n        y = torch.squeeze(y, 1)\n        # Feed received symbols into decoder network\n        if len(self.demod_extra_params):\n            # Input is y: (batchsize x symbols per snr), snr: (batchsize x 1)\n            y = torch.cat(\n                (y, torch.cat(args, 1)),\n                1,\n            )\n        for demap in self.demaps[:-1]:\n            y = demap(y)\n            y = self.ReLU(y)\n        # We need to define logit as p(b_j = 0 | y) = sigmoid(logit)\n        # to have logit correspond to LLRs for later decoding\n        # This changes the sign\n        logit = self.demaps[-1](y)\n        if not self.training:\n            # Change the sign for evaluation\n            logit = -1 * logit\n        if self.with_logit:\n            return logit\n        return self.sigmoid(logit)\n\n    @staticmethod\n    def load_model(model_dict, with_logit=True):\n        \"\"\"\n        Load saved weights.\n\n        :param model_dict: dictionary loaded with `torch.load()`\n        \"\"\"\n        demapper_dict = {\n            (k[len(\"demapper.\") :] if k.startswith(\"demapper\") else k): v\n            for k, v in model_dict.items()\n            if not (k.startswith(\"mapper\") or k.startswith(\"channel\"))\n        }\n        m = demapper_dict[\"m\"].item()\n        demod_extra_params = demapper_dict[\"demod_extra_params\"].tolist()\n        if len(demod_extra_params) == 0:\n            demod_extra_params = None\n        width = demapper_dict[\"width\"].item()\n        depth = demapper_dict[\"depth\"].item()\n        model = ConstellationDemapper(\n            m,\n            width=width,\n            depth=depth,\n            with_logit=with_logit,\n            demod_extra_params=demod_extra_params,\n        )\n        model.load_state_dict(demapper_dict)\n        return model", "\n\nclass ClassicalDemapper(torch.nn.Module):\n    r\"\"\"\n    Classical Bitwise Soft Demapper with Gaussian Noise assumption.\n\n    It takes the noise_sigma and constellation sorted from [0,2**m -1] and constructs\n    an more or less efficient demapper which outputs LLRS for all m bits for\n    each received symbol\n\n    :param noise_sigma: $\\\\sigma$ for the Gaussian assumption\n    :param constellation: PyTorch tensor of complex constellation symbols\n    :param optimize: Use $\\\\sigma$ as trainable paramater\n    \"\"\"\n\n    def __init__(self, noise_sigma, constellation, optimize=False):\n        \"\"\"Construct ClassicalDemapper.\"\"\"\n        super(ClassicalDemapper, self).__init__()\n        if optimize:\n            self.register_parameter(\n                \"noise_sigma\",\n                torch.nn.Parameter(torch.tensor(noise_sigma, dtype=torch.float32)),\n            )\n        else:\n            self.noise_sigma = noise_sigma\n        self.constellation = constellation\n\n        M = torch.numel(self.constellation)\n        m = int(math.log2(M))\n        self.register_buffer(\"m\", torch.tensor(m))\n\n        all_bits = np.arange(2**m, dtype=np.uint8)\n        all_bits = np.expand_dims(all_bits, 1)\n        B = np.unpackbits(all_bits, axis=1, count=m, bitorder=\"little\")\n        self.bits = torch.from_numpy(B).to(constellation.device)\n        with torch.no_grad():\n            self.one_idx = torch.nonzero(self.bits)\n            self.m_one_idx = [\n                self.one_idx[torch.nonzero(self.one_idx[:, 1] == m_i)][:, 0][:, 0]\n                for m_i in range(m)\n            ]\n            self.zero_idx = torch.nonzero(torch.abs(self.bits - 1))\n            self.m_zero_idx = [\n                self.zero_idx[torch.nonzero(self.zero_idx[:, 1] == m_i)][:, 0][:, 0]\n                for m_i in range(m)\n            ]\n\n    def update_constellation(self, constellation):\n        \"\"\"Update saved constellation.\"\"\"\n        self.constellation = constellation.clone()\n\n    def forward(self, y, *args):\n        \"\"\"\n        Perform bitwise demapping of complex symbols.\n\n        :params y: Received complex symbols of dimension batch_size x 1\n        :returns: log likelihood ratios\n        \"\"\"\n        if len(y.size()) < 2:\n            y = y[:, None]\n        dist = torch.exp(\n            (-1 * torch.abs(y - self.constellation) ** 2)\n            / (2 * torch.clip(self.noise_sigma, 0.001) ** 2)\n        )  # batch_size x 2**m x 1\n        llrs = torch.zeros((y.size()[0], self.m.item())).to(dist.device)\n        bias = 1e-8  # required to stop sum inside log2 from becoming zero\n        for bit in np.arange(self.m.item()):\n            one_llr = torch.log(\n                torch.sum(dist[:, self.m_one_idx[bit]] + bias, axis=1)\n            ).clone()\n            zero_llr = torch.log(\n                torch.sum(dist[:, self.m_zero_idx[bit]] + bias, axis=1)\n            ).clone()\n            llrs[:, bit] = torch.squeeze(zero_llr - one_llr)\n        if torch.allclose(llrs, torch.tensor(0.0)):\n            raise ValueError(\"LLRs all became zero, convergence problem\")\n        return llrs\n\n    def symbolwise(self, y, *args):\n        \"\"\"\n        Perform symbolwise hard demapping of complex symbols.\n\n        :params y: Received complex symbols\n        :returns: index of closest complex constellation symbol\n        \"\"\"\n        if len(y.size()) < 2:\n            y = y[:, None]\n        dist = torch.abs(y - self.constellation)\n        _, min_idx = torch.min(dist, dim=-1)\n        return min_idx", "\n\nclass GaussianDemapper(torch.nn.Module):\n    \"\"\"\n    Classical Bitwise Soft Demapper with Gaussian Noise assumption.\n\n    Learns bias and covariance matrix of noise for constellation sorted from [0,2**m -1]\n    and constructs a more or less efficient demapper which outputs LLRS for all m bits\n    for each received symbol\n    \"\"\"\n\n    def __init__(self, constellation):\n        \"\"\"Construct GaussianDemapper.\"\"\"\n        super(GaussianDemapper, self).__init__()\n        constellation = torch.squeeze(constellation).detach().clone()\n        if constellation.dtype == torch.complex64:\n            dim = 2\n            self.constellation = torch.stack(\n                (\n                    torch.real(constellation.detach().clone()),\n                    torch.imag(constellation.detach().clone()),\n                ),\n                1,\n            )\n        else:\n            dim = 1\n            self.constellation = constellation.detach().clone().unsqueeze(1)\n\n        noise_mean = self.constellation.detach().clone().unsqueeze(2)\n\n        M = torch.numel(constellation)\n        m = int(math.log2(M))\n        self.register_buffer(\"m\", torch.tensor(m))\n        self.register_buffer(\"M\", torch.tensor(M))\n        self.register_buffer(\"dim\", torch.tensor(dim))\n\n        self.register_parameter(\n            \"cov_gen_mat\",\n            torch.nn.Parameter(\n                torch.eye(dim, dtype=torch.float32, device=constellation.device)\n                .unsqueeze(0)\n                .repeat(M, 1, 1)\n            ),\n        )\n\n        self.register_parameter(\n            \"noise_mean\",\n            torch.nn.Parameter(noise_mean),\n        )\n\n        all_bits = np.arange(2**m, dtype=np.uint8)\n        all_bits = np.expand_dims(all_bits, 1)\n        B = np.unpackbits(all_bits, axis=1, count=m, bitorder=\"little\")\n        self.bits = torch.from_numpy(B).to(constellation.device)\n        with torch.no_grad():\n            self.one_idx = torch.nonzero(self.bits)\n            self.m_one_idx = [\n                self.one_idx[torch.nonzero(self.one_idx[:, 1] == m_i)][:, 0][:, 0]\n                for m_i in range(m)\n            ]\n            self.zero_idx = torch.nonzero(torch.abs(self.bits - 1))\n            self.m_zero_idx = [\n                self.zero_idx[torch.nonzero(self.zero_idx[:, 1] == m_i)][:, 0][:, 0]\n                for m_i in range(m)\n            ]\n\n    def update_constellation(self, constellation):\n        \"\"\"\n        Update saved constellation.\n\n        :params constellation: Complex constellation symbols\n        \"\"\"\n        if self.dim == 2:\n            self.constellation = torch.stack(\n                (\n                    torch.real(constellation.detach().clone()),\n                    torch.imag(constellation.detach().clone()),\n                ),\n                1,\n            )\n\n        else:\n            self.constellation = constellation.detach().clone().unsqueeze(1)\n\n    def warm_start(self, sym_idx, y, learning_fraction=0.3, single_circular=False):\n        \"\"\"\n        Train covariance matrix with known symbols.\n\n        :params sym_idx: Sent symbol index\n        :param y: Received complex symbols\n        :param learning_fraction: Learning rate\n        :param single_circular: Toggle if a a single sigma is learned for all symbols\n        \"\"\"\n        with torch.no_grad():\n            meanfree_vals = torch.empty(0).to(y.device)\n            for i in np.arange(self.M.item()):\n                idx = (sym_idx == i).nonzero()\n                idx = idx[\n                    torch.randperm(len(idx))[\n                        0 : int(np.ceil(learning_fraction * len(idx)))\n                    ]\n                ]\n                rx_sym = y[idx].squeeze()\n                if y.dtype == torch.complex64:\n                    rx_sym = torch.stack(\n                        (torch.real(rx_sym), torch.imag(rx_sym))\n                    ).squeeze()\n                else:\n                    rx_sym = torch.transpose(rx_sym.unsqueeze(1), 0, 1)\n\n                rx_mean = torch.mean(rx_sym, 1).unsqueeze(1)\n                self.noise_mean[i] = rx_mean\n\n                rx_meanfree = torch.sub(rx_sym, rx_mean)\n                if not single_circular:\n                    CovMatrix = torch.matmul(\n                        rx_meanfree, torch.transpose(rx_meanfree, 0, 1)\n                    ) / len(idx)\n                    self.cov_gen_mat[i] = torch.linalg.cholesky(CovMatrix)\n                else:\n                    meanfree_vals = torch.cat(\n                        [\n                            meanfree_vals,\n                            torch.flatten(rx_meanfree),\n                        ]\n                    )\n            if single_circular:\n                sigma = torch.sqrt(torch.sum(meanfree_vals**2) / len(meanfree_vals))\n                for i in np.arange(self.M.item()):\n                    self.cov_gen_mat[i] = sigma * torch.eye(self.dim, device=y.device)\n\n    def forward(self, y, *args):\n        \"\"\"\n        Perform bitwise demapping.\n\n        :params y: Received complex symbols of dimension batch_size x 1\n        \"\"\"\n        if self.dim == 2:\n            symbols = torch.squeeze(torch.stack((torch.real(y), torch.imag(y))))\n            noise_cov = torch.transpose(self.cov_gen_mat, 1, 2) * self.cov_gen_mat\n            cov_det = (\n                noise_cov[:, 0, 0] * noise_cov[:, 1, 1]\n                - noise_cov[:, 0, 1] * noise_cov[:, 1, 0]\n            )\n\n            noise_inv_cov = torch.zeros(\n                noise_cov.shape, dtype=torch.float32, device=y.device\n            )\n            noise_inv_cov[:, 0, 0] = noise_cov[:, 1, 1] / cov_det\n            noise_inv_cov[:, 0, 1] = -noise_cov[:, 0, 1] / cov_det\n            noise_inv_cov[:, 1, 0] = -noise_cov[:, 1, 0] / cov_det\n            noise_inv_cov[:, 1, 1] = noise_cov[:, 0, 0] / cov_det\n        else:\n            symbols = torch.transpose(y, 0, 1)\n            noise_cov = self.cov_gen_mat**2\n            cov_det = noise_cov\n            noise_inv_cov = 1 / noise_cov\n\n        Q_YX = torch.zeros(symbols.shape[1], self.M).to(y.device)\n        for i in np.arange(self.M.item()):\n            symbols_minus_mean = torch.sub(symbols, self.noise_mean[i])\n            Q_YX[:, i] = (\n                1 / (torch.sqrt(cov_det[i] * ((2 * torch.pi) ** self.dim)))\n            ) * torch.exp(\n                -0.5\n                * torch.sum(\n                    symbols_minus_mean * (noise_inv_cov[i] @ symbols_minus_mean),\n                    0,\n                )\n            )\n        bias = 1e-8  # required to stop sum inside log2 from becoming zero\n        llrs = torch.zeros((y.size()[0], self.m.item())).to(y.device)\n        for bit in np.arange(self.m.item()):\n            one_llr = torch.log(\n                torch.sum(Q_YX[:, self.m_one_idx[bit]] + bias, axis=1)\n            ).clone()\n            zero_llr = torch.log(\n                torch.sum(Q_YX[:, self.m_zero_idx[bit]] + bias, axis=1)\n            ).clone()\n            llrs[:, bit] = torch.squeeze(zero_llr - one_llr)\n\n        if torch.allclose(llrs, torch.tensor(0.0)):\n            raise ValueError(\"LLRs all became zero, convergence problem\")\n        return llrs, Q_YX", "\n    # def visualize(self, N=100, sigma_scale=1):\n    #     \"\"\"\n    #     :params N: Number of points on contour per constellation point\n\n    #     Uses idea from https://commons.wikimedia.org/wiki/File:MultivariateNormal.png\n    #     \"\"\"\n    #     with torch.no_grad():\n    #         # Get the sigma ellipses by transform a circle by the cholesky decomp\n    #         CovMatrix = np.zeros([2, 2])", "    #         # Get the sigma ellipses by transform a circle by the cholesky decomp\n    #         CovMatrix = np.zeros([2, 2])\n    #         t = np.linspace(0.0, 2 * np.pi, num=N)\n    #         circle_points = np.stack((np.cos(t), np.sin(t)))\n    #         E_points = []\n    #         for i in np.arange(self.M.item()):\n    #             inv_cov_det = (\n    #                 self.noise_inv_cov[i][0, 0] * self.noise_inv_cov[i][1, 1]\n    #                 - self.noise_inv_cov[i][0, 1] * self.noise_inv_cov[i][1, 0]\n    #             ).item()", "    #                 - self.noise_inv_cov[i][0, 1] * self.noise_inv_cov[i][1, 0]\n    #             ).item()\n    #             CovMatrix[0, 0] = (self.noise_inv_cov[i][1, 1] / inv_cov_det).item()\n    #             CovMatrix[0, 1] = (-self.noise_inv_cov[i][0, 1] / inv_cov_det).item()\n    #             CovMatrix[1, 0] = (-self.noise_inv_cov[i][1, 0] / inv_cov_det).item()\n    #             CovMatrix[1, 1] = (self.noise_inv_cov[i][0, 0] / inv_cov_det).item()\n    #             L = np.linalg.cholesky(CovMatrix)\n    #             E_points.append(\n    #                 (sigma_scale * L @ circle_points)\n    #                 + self.noise_mean[i].detach().cpu().numpy()", "    #                 (sigma_scale * L @ circle_points)\n    #                 + self.noise_mean[i].detach().cpu().numpy()\n    #             )\n\n    # return E_points\n\n\nclass SeparatedSimpleDemapper(torch.nn.Module):\n    \"\"\"\n    Simplified Demapper which approximates output LLRS of bits separated in real \\\n    and imaginary parts.\n\n    Do simple function approximation with in -> Linear -> ReLU -> Linear -> out\n    This should be easy to replicate in hardware with LUT\n    \"\"\"\n\n    def __init__(self, m, demapper_width, demod_extra_params=()):\n        \"\"\"Construct SeparatedSimpleDemapper.\"\"\"\n        super(SeparatedSimpleDemapper, self).__init__()\n        self.register_buffer(\"m\", torch.tensor(m))\n        self.register_buffer(\"width\", torch.tensor(demapper_width))\n        self.demod_extra_params = demod_extra_params\n        self.ReLU = torch.nn.ReLU()\n        self.real1 = torch.nn.Linear(1 + len(demod_extra_params), demapper_width)\n        self.real2 = torch.nn.Linear(demapper_width, m // 2)\n        self.imag1 = torch.nn.Linear(1 + len(demod_extra_params), demapper_width)\n        self.imag2 = torch.nn.Linear(demapper_width, m // 2)\n\n    def forward(self, y, *args):\n        \"\"\"\n        Perform bitwise demapping of complex symbols.\n\n        :returns: Approximated log likelihood ratio of dimension `self.m`\n        \"\"\"\n        y = torch.view_as_real(y)\n        y = torch.squeeze(y, 1)\n        if len(self.demod_extra_params):\n            y_real = torch.cat(\n                (torch.unsqueeze(y[:, 0], 1), torch.cat(args, 1)),\n                1,\n            )\n            y_imag = torch.cat(\n                (torch.unsqueeze(y[:, 1], 1), torch.cat(args, 1)),\n                1,\n            )\n        else:\n            y_real = torch.unsqueeze(y[:, 0], 1)\n            y_imag = torch.unsqueeze(y[:, 1], 1)\n        llr_real = self.real2(self.ReLU(self.real1(y_real)))\n        llr_imag = self.imag2(self.ReLU(self.imag1(y_imag)))\n        result = torch.cat((llr_imag, llr_real), 1)\n        if self.training:\n            return result\n        return -1 * result\n\n    @staticmethod\n    def load_model(model_dict, with_logit=True):\n        \"\"\"\n        Load saved weights.\n\n        :param model_dict: dictionary loaded with `torch.load()`\n        \"\"\"\n        demapper_dict = {\n            (k[len(\"demapper.\") :] if k.startswith(\"demapper\") else k): v\n            # k.removeprefix(\"demapper.\"): v\n            for k, v in model_dict.items()\n            if not (k.startswith(\"mapper\") or k.startswith(\"channel\"))\n        }\n        m = demapper_dict[\"m\"].item()\n        if \"demap_extra_params\" in demapper_dict:\n            demod_extra_params = demapper_dict[\"demod_extra_params\"].tolist()\n        else:\n            demod_extra_params = ()\n        width = demapper_dict[\"width\"].item()\n        if len(demod_extra_params) == 0:\n            demod_extra_params = ()\n        model = SeparatedSimpleDemapper(\n            m,\n            demapper_width=width,\n            demod_extra_params=demod_extra_params,\n        )\n\n        model.load_state_dict(demapper_dict)\n        return model", "\n\nclass PCSSampler(torch.nn.Module):\n    \"\"\"\n    Sample symbol indices from a learnable discrete probability distribution.\n\n    :params m: bits per symbol\n    :params l_init: Initial values for the per-symbol logits\n    :param symmetries: number of times the probabilty vector is repeated to\n                       obtain a probability distribution with uniform distribution\n                       for certain bits in the bitstring.\n    \"\"\"\n\n    def __init__(self, m, l_init=None, symmetries=0, pcs_extra_params=None):\n        \"\"\"Construct PCSSampler.\"\"\"\n        super(PCSSampler, self).__init__()\n        self.m = torch.tensor(m, dtype=torch.float32)\n        self.register_buffer(\"symmetries\", torch.tensor(symmetries))\n        self.register_buffer(\"pcs_extra_params\", torch.tensor(pcs_extra_params or []))\n        if pcs_extra_params:\n            self.map1 = torch.nn.Linear(\n                len(pcs_extra_params), 2**m // 2**symmetries\n            )\n            self.map2 = torch.nn.Linear(\n                2**m // 2**symmetries, 2**m // 2**symmetries\n            )\n            torch.nn.init.xavier_normal_(self.map1.weight)\n            torch.nn.init.xavier_normal_(self.map2.weight)\n        else:\n            if l_init is None:\n                self.logits = torch.nn.Parameter(\n                    torch.nn.init.xavier_normal_(\n                        torch.zeros((2**m // 2**symmetries, 1), dtype=torch.float32)\n                    )\n                )\n            else:\n                if l_init.shape[0] != 2**m // 2**symmetries:\n                    raise ValueError(\"l_init must be size of 2**m/2**symmetries\")\n                self.logits = torch.nn.Parameter(l_init)\n        self.relu = torch.nn.ReLU()\n        self.softmax = torch.nn.Softmax(dim=0)\n\n    def forward(self, batchsize, *args):\n        \"\"\"\n        Generate symbol indices.\n\n        :params batchsize: Number of indices to generate\n        \"\"\"\n        # num_symbols = torch.min(\n        #    (torch.round(self.p_symbols * batchsize)).type(torch.int32), 1\n        # ).values\n        idx = (\n            functional.torch.distribution_quant_gumbel_softmax(\n                self.p_symbols(*args), batchsize\n            )\n            .squeeze()\n            .long()\n        )\n        # idx = torch.repeat_interleave(\n        #     torch.arange(2 ** self.m.item(), device=num_symbols.device), num_symbols\n        # )\n        logger.debug(\"idx: %s\", idx)\n        return idx.squeeze()\n\n    def p_symbols(self, *args):\n        \"\"\"Return current probability distribution.\"\"\"\n        if len(self.pcs_extra_params):\n            pcs_args = (\n                torch.stack(\n                    tuple(args[idx][0, None] for idx in self.pcs_extra_params), dim=1\n                )\n                .to(self.map1.weight.device)\n                .squeeze()\n            )\n            logits = self.map2(self.relu(self.map1(pcs_args)))\n        else:\n            logits = self.logits\n        logger.debug(\"logits: %s\", logits)\n        return self.softmax(\n            torch.tile(logits, (1, self.symmetries.item() + 1)).reshape((-1, 1))\n        ).squeeze()", "\n\nclass MBPCSSampler(torch.nn.Module):\n    \"\"\"\n    This class is supposed to use NNs to find a lambda [0,1] for each given parameter \\\n    (if given parameters) and then return p_symbols for further simulation.\n\n    :params constellation_symbols: Complex constellation symbols\n    \"\"\"\n\n    def __init__(\n        self, constellation_symbols, pcs_extra_params, fixed_lambda=False, l_init=None\n    ):\n        \"\"\"Construct MBPCSSampler.\"\"\"\n        super(MBPCSSampler, self).__init__()\n\n        self.register_buffer(\"symbols\", constellation_symbols)\n        self.pcs_extra_params = pcs_extra_params\n        self.fixed_lambda = fixed_lambda\n\n        if self.fixed_lambda:\n            self.register_buffer(\"_lambda\", torch.tensor(0.5))\n        else:\n            if pcs_extra_params:\n                self.map1 = torch.nn.Linear(len(pcs_extra_params), 32)\n                self.map2 = torch.nn.Linear(32, 1)\n                torch.nn.init.xavier_normal_(self.map1.weight)\n                torch.nn.init.xavier_normal_(self.map2.weight)\n            else:\n                if l_init is None:\n                    self.logits = torch.nn.Parameter(\n                        torch.nn.init.xavier_normal_(\n                            torch.zeros((1,), dtype=torch.float32)\n                        )\n                    )\n                else:\n                    if l_init.shape[0] != 1:\n                        raise ValueError(\"l_init must be size of 1\")\n                    self.logits = torch.nn.Parameter(l_init)\n            self.relu = torch.nn.ReLU()\n            self.sigmoid = torch.nn.Sigmoid()\n\n    def forward(self, batchsize, *args):\n        \"\"\"\n        Generate symbol indices.\n\n        :params batchsize: Number of indices to generate\n        \"\"\"\n        num_symbols = (\n            functional.torch.distribution_quantization(self.p_symbols(*args), batchsize)\n            .squeeze()\n            .long()\n        )\n        idx = torch.repeat_interleave(\n            torch.arange(len(self.symbols), device=num_symbols.device), num_symbols\n        )\n        logger.debug(\"idx: %s\", idx)\n        return idx.squeeze()\n\n    def p_symbols(self, *args):\n        \"\"\"Return current probability distribution.\"\"\"\n        lambda_mb = self.lambda_mb(*args)\n        return MB_dist(lambda_mb, self.symbols)\n\n    def lambda_mb(self, *args):\n        \"\"\"Return currently trained lambda.\"\"\"\n        if self.fixed_lambda:\n            return self._lambda\n        if len(self.pcs_extra_params):\n            pcs_args = (\n                torch.stack(\n                    tuple(args[idx][0, None] for idx in self.pcs_extra_params), dim=1\n                )\n                .to(self.map1.weight.device)\n                .squeeze()\n            )\n            logit = self.map2(self.relu(self.map1(pcs_args)))\n        else:\n            logit = self.logits\n        return logit", "\n\ndef MB_dist(lmbd, symbols):\n    \"\"\"\n    Calculate the Maxwell-Boltzmann distribution for a given constellation.\n\n    :params lambda: Lambda parameter of the Maxwell-Boltzmann distribution\n    :params symbols: Complex constellation symbols\n    \"\"\"\n    mb_dist = torch.exp(-lmbd * torch.abs(symbols) ** 2)\n    mb_dist_norm = mb_dist / torch.sum(mb_dist)\n    return mb_dist_norm", ""]}
{"filename": "src/mokka/mapping/__init__.py", "chunked_list": ["\"\"\"Module implementing mapping and demapping.\"\"\"\n"]}
{"filename": "src/mokka/mapping/numpy.py", "chunked_list": ["\"\"\"NumPy implementation of Mappers and Demappers.\"\"\"\n\nimport numpy as np\nfrom ..utils.bitops import gray\nfrom scipy import interpolate as interp\nfrom ..utils.generators.numpy import generate_all_bits\nimport logging\n\nlogger = logging.getLogger(__name__)\n", "logger = logging.getLogger(__name__)\n\n\nclass QAM:\n    \"\"\"\n    Arbitrarily sized QAM constellation with gray mapping.\n\n    :param m: Information per symbol [bit/symbol]\n    \"\"\"\n\n    def __init__(self, m):\n        \"\"\"Construct QAM class.\"\"\"\n        if m % 2:\n            raise ValueError(\n                \"Only bits/per Symbol which are multiple of 2 are supported\"\n            )\n        self.m = m\n        self.bit_sequence = np.array(gray(m // 2))\n\n        self.one_idx = np.nonzero(self.bit_sequence)\n        self.zero_idx = np.nonzero(np.abs(self.bit_sequence - 1))\n\n        scaling = np.sqrt(3 / 2) * (np.sqrt(2**m) - 1) / (np.sqrt(2**m - 1))\n        self.symbol_amplitudes = np.linspace(-1, 1, 2 ** (m // 2)) * scaling\n        self.symbol_amplitudes_rep = self.symbol_amplitudes[:, np.newaxis].repeat(\n            m // 2, axis=1\n        )\n        self.demap_interp = interp.interp1d(\n            self.symbol_amplitudes,\n            np.arange(2 ** (m // 2)),\n            bounds_error=None,\n            fill_value=\"extrapolate\",\n        )\n\n    def get_constellation(self):\n        \"\"\"\n        Return all constellation symbols.\n\n        The index represents the integer representation of\n        the encoded bit-string (LSB first).\n\n        :returns: all constellation symbols\n        \"\"\"\n        bits = generate_all_bits(self.m)\n        symbols = self.map(bits)\n        return symbols\n\n    def map(self, bits):\n        \"\"\"\n        Perform mapping of bitstrings.\n\n        :returns: complex symbol per bitstring of length `self.m`\n        \"\"\"\n        output = []\n        for seq in bits.reshape(-1, self.m):\n            # Take first half for real and second half for imag\n            real = self.symbol_amplitudes[\n                (self.bit_sequence == seq[: self.m // 2]).all(axis=1).nonzero()\n            ]\n            imag = self.symbol_amplitudes[\n                (self.bit_sequence == seq[-(self.m // 2) :]).all(axis=1).nonzero()\n            ]\n            output.append(real + 1j * imag)\n        return np.array(output)", ""]}
{"filename": "src/mokka/normalization/torch.py", "chunked_list": ["\"\"\"Normalization for communication systems in PyTorch.\"\"\"\n\nimport torch\n\n\ndef energy(c, p=None):\n    \"\"\"\n    Perform normalization on average energy.\n\n    :param c: complex constellation points\n    :param p: probabilities, if None: uniform probability is assumed\n    :returns: constellation with average energy 1\n    \"\"\"\n    if p is not None:\n        scaling = torch.sqrt(1.0 / torch.sum(p * (torch.abs(c) ** 2), -1))\n    else:\n        scaling = torch.sqrt((c.size()[-1]) / torch.sum(torch.abs(c) ** 2, -1))\n    scaling = torch.unsqueeze(scaling, -1).repeat(*((1,) * len(c.size())), c.size()[-1])\n    scaling = torch.squeeze(scaling, 0)\n    c = torch.multiply(c, scaling)\n    return c", "\n\ndef centered_energy(c, p=None):\n    \"\"\"Perform centered (zero-mean) normalization of the complex constellation.\n\n    :param c: complex constellation points\n    :param p: probabilities, if None: uniform probability is assumed\n    :returns: centered constellation with average energy of 1\n\n    \"\"\"\n    if p is not None:\n        c = (c - (torch.sum(p * c, -1))) / (\n            torch.sqrt(\n                (\n                    (torch.sum(p * torch.abs(c) ** 2, -1))\n                    - torch.abs((torch.sum(p * c, -1))) ** 2\n                )\n            )\n        )\n    else:\n        c = (c - (torch.sum(c, -1) / (c.size()[-1]))) / (\n            torch.sqrt(\n                (\n                    (torch.sum(torch.abs(c) ** 2, -1) / c.size()[-1])\n                    - torch.abs((torch.sum(c, -1) / c.size()[-1])) ** 2\n                )\n            )\n        )\n    return c", ""]}
{"filename": "src/mokka/normalization/__init__.py", "chunked_list": ["\"\"\"Module containing normalization functions.\"\"\"\n\nfrom . import torch  # noqa\nfrom .torch import energy, centered_energy  # noqa\n"]}
{"filename": "src/mokka/channels/torch.py", "chunked_list": ["\"\"\"Channels sub-module implemented within the PyTorch framework.\"\"\"\nimport torch\nimport torchaudio\nimport math\nimport scipy.special\nimport numpy as np\nimport attr\nimport logging\nfrom .. import utils\n", "from .. import utils\n\nlogger = logging.getLogger(__name__)\n\n\nclass ComplexAWGN(torch.nn.Module):\n    \"\"\"\n    Complex AWGN channel defined with zero mean and variance N_0.\n\n    This converts to a setting of stddev sqrt(N_0/2) for real and imaginary parts of the\n    distribution.\n    \"\"\"\n\n    def __init__(self, N_0=None):\n        \"\"\"Construct ComplexAWGN.\"\"\"\n        super(ComplexAWGN, self).__init__()\n        self.N_0 = N_0\n\n    def forward(self, x, N_0=None):\n        \"\"\"Apply Gaussian noise to a signal.\n\n        :param x: input signal to apply noise to.\n        :param N_0: noise variance\n        :returns: input signal distorted with AWGN\n\n        \"\"\"\n        if N_0 is None:\n            if self.N_0 is None:\n                raise Exception(\"N_0 needs to be defined somewhere\")\n            N_0 = self.N_0\n        n = torch.zeros_like(x, device=x.device).normal_()\n        # If only one value is supplied for all given samples\n        if n.size() != N_0.size():\n            N_0 = torch.full_like(n, N_0, dtype=torch.float32)\n        n = torch.mul(n, torch.sqrt(N_0))\n        return x + n", "\n\nclass PhasenoiseWiener(torch.nn.Module):\n    \"\"\"\n    Wiener phase noise channel.\n\n    Forward call takes N0 for AWGN and sigma_phi for Wiener phase noise.\n\n    :param start_phase_width: upper bound for initialization\n                              with a uniform distribution.\n    :param start_phase_init: initial phase value at the start of the\n                             generation for each noise sequence.\n    \"\"\"\n\n    def __init__(self, start_phase_width=2 * np.pi, start_phase_init=0):\n        \"\"\"Construct PhasenoiseWiener.\"\"\"\n        super(PhasenoiseWiener, self).__init__()\n        self.awgn = ComplexAWGN()\n        self.start_phase_init = start_phase_init\n        self.start_phase_width = start_phase_width\n\n    def forward(self, x, N0=None, sigma_phi=None):\n        r\"\"\"Apply Wiener phase noise to a complex signal.\n\n        :param x: ipnut signal to apply noise to\n        :param N0: noise variance for Gaussian noise\n        :param sigma_phi: standard deviation of Wiener phase noise process\n        :returns: noise impaired signal\n        \"\"\"\n        if N0 is not None:\n            x = self.awgn(x, N0)\n        x = self.apply(x, sigma_phi)\n        logger.debug(\"x size: %s\", x.size())\n        return x\n\n    def apply(self, x, sigma_phi=None):\n        \"\"\"\n        Apply only Wiener phase noise.\n\n        Parameters\n        ----------\n        x: array_like\n           Input data\n        \"\"\"\n        x = torch.squeeze(x)\n        logger.debug(\"sigma_phi: %s\", sigma_phi.item())\n        sigma_phi_temp = sigma_phi\n\n        # \"Physical\" Channel\n        delta_phi = sigma_phi_temp * torch.randn(\n            len(x), device=x.device, dtype=torch.float32\n        )\n        phi = torch.cumsum(delta_phi, 0) + (\n            self.start_phase_init\n            + torch.rand(1, device=x.device, dtype=torch.float32)\n            * self.start_phase_width\n        )\n        x = x * torch.exp(1j * phi)\n        logger.debug(\"x size: %s\", x.size())\n        return x\n\n    def sample_noise(self, x, sigma_phi=None):\n        \"\"\"\n        Sample one realization of phase noise.\n\n        Parameters\n        ----------\n        x: array_like\n           Input data\n        \"\"\"\n        x = torch.squeeze(x)\n        logger.debug(\"sigma_phi: %s\", sigma_phi.item())\n        sigma_phi_temp = sigma_phi\n\n        # \"Physical\" Channel\n        delta_phi = sigma_phi_temp * torch.randn(\n            len(x), device=x.device, dtype=torch.float32\n        )\n        phi = torch.cumsum(delta_phi, 0) + (\n            self.start_phase_init\n            + torch.rand(1, device=x.device, dtype=torch.float32)\n            * self.start_phase_width\n        )\n        logger.debug(\"x size: %s\", x.size())\n        return phi", "\n\nclass ResidualPhaseNoise(torch.nn.Module):\n    \"\"\"\n    Residual phase noise implementation.\n\n    This implements residual phase noise modeled with a zero mean phase noise process.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Construct ResidualPhaseNoise.\"\"\"\n        super(ResidualPhaseNoise, self).__init__()\n\n    def forward(self, x, RPN):\n        \"\"\"\n        Apply residual phase noise to signal.\n\n        :param x: complex input signal\n        :param RPN: phase noise variance per input symbol\n        :returns: x with phase noise\n        \"\"\"\n        n_phi = torch.zeros(x.size(), dtype=torch.float32, device=x.device).normal_()\n        # If only one value is supplied for all given samples\n        if n_phi.size() != RPN.size():\n            RPN = torch.full_like(n_phi, RPN, dtype=float)\n        n_phi = torch.mul(n_phi, torch.sqrt(RPN))\n        return x * torch.exp(1j * n_phi)", "\n\n@attr.define\nclass OpticalNoise(torch.nn.Module):\n    \"\"\"\n    Zero mean additive Gaussian noise based on given OSNR defined over \\\n    certain wavelength.\n\n    :param dt: Time step\n    :param optical_carrier_wavelength: Wavelength of optical carrier in nm\n    :param wavelength_bandwidth: Bandwidth in nm for which OSNR is given\n    :param OSNR: Optical SNR in dB\n    \"\"\"\n\n    dt: float\n    optical_carrier_wavelength: float\n    wavelength_bandwidth: float\n    OSNR: float\n\n    def __attrs_pre_init__(self):\n        \"\"\"Actual init function for attr classes.\"\"\"\n        super(OpticalNoise, self).__init__()\n\n    def __attrs_post_init__(self):\n        \"\"\"Post-init function for attr classes.\"\"\"\n        # Conversion equation from https://www.rp-photonics.com/bandwidth.html\n        self.frequency_bandwidth = (\n            scipy.constants.c\n            * self.wavelength_bandwidth\n            / (self.optical_carrier_wavelength**2 * 1e-9)\n        )\n\n    def forward(self, signal):\n        \"\"\"Apply optical noise realization on signal.\n\n        :param signal: input signal\n        :returns: noise impaired signal\n        \"\"\"\n        n0 = torch.randn(len(signal)).to(signal.device) + 1j * torch.randn(\n            len(signal)\n        ).to(signal.device)\n        fvec = torch.fft.fftfreq(len(signal), self.dt)\n\n        stft = torchaudio.transforms.Spectrogram(\n            n_fft=len(signal), win_length=len(signal) // 8, power=2, onesided=False\n        ).to(signal.device)\n        stft_n0 = stft(n0)\n        stft_signal = stft(signal)\n        scl = (\n            torch.sum(stft_signal[torch.abs(fvec) <= self.frequency_bandwidth / 2])\n            / utils.db2pow(self.OSNR)\n        ) / torch.sum(stft_n0[torch.abs(fvec) <= self.frequency_bandwidth / 2])\n\n        n = n0 * torch.sqrt(scl)\n        return signal + n", "\n\n@attr.define\nclass EDFAAmpSinglePol(torch.nn.Module):\n    \"\"\"\n    Gaussian noise model of an EDFA for single polarization fiberoptics.\n\n    :param span_length: span_length [km]\n    :param amp_noise: Consider amplification noise [bool]\n    :param amp_gain: Which amplification gain model to use either 'alpha_equalization',\n                     'equal_power'\n    :param optical_carrier_frequency: Optical carrier frequency (for PSD) [GHz]\n    :param bw: Occupied bandwidth (for PSD) [Hz]\n    :param P_input_lin: Input power [W]\n    :param padding: Number of samples to ignore in the beginning and end\n    \"\"\"\n\n    span_length: int\n    amp_gain: str\n    alpha_db: torch.tensor\n    amp_noise: bool\n    noise_figure: torch.tensor\n    optical_carrier_frequency: float\n    bw: float\n    P_input_lin: float\n    padding: int\n    alpha_lin: torch.tensor = attr.field(init=False)\n\n    def __attrs_pre_init__(self):\n        \"\"\"Pre-init for attrs classes.\"\"\"\n        super(EDFAAmpSinglePol, self).__init__()\n\n    def __attrs_post_init__(self):\n        \"\"\"Post-init for attrs classes0.\"\"\"\n        self.alpha_lin = self.alpha_db * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n\n    def forward(self, signal, segment):\n        r\"\"\"\n        Amplify the signal according to the selected method after each span.\n\n        Attention: the noise depends on the amplification. if :math:`\\alpha = 0`,\n        no noise is added.\n\n        Parameters\n        ----------\n        signal : singal before the amplifier\n        segment: segment number\n        Returns\n        -------\n        signal : signal after the amplifier\n        \"\"\"\n        if self.alpha_lin != 0 and segment == 2:\n            if self.amp_gain == \"alpha_equalization\":\n                gain_signal = torch.sqrt(torch.exp(self.alpha_lin * self.span_length))\n            elif self.amp_gain == \"equal_power\":\n                if self.padding > 0:\n                    P_in = torch.mean(\n                        torch.abs(signal[self.padding : -self.padding]) ** 2\n                    )\n                else:\n                    P_in = torch.mean(torch.abs(signal) ** 2)\n                gain_signal = torch.sqrt(self.P_input_lin / P_in)\n            # calculate power spectrum density of the noise and add it to the\n            # signal according to On Signal Constellations and Coding for\n            # Long-Haul Fiber-Optical Systems (Christian H\u00e4ger)\n            signal *= gain_signal\n            if self.amp_noise:\n                gain_power = gain_signal**2\n                F_n = 10 ** (self.noise_figure / 10)\n                n_sp = F_n / 2 * ((1 / ((1 - 1 / gain_power))))\n                psd = (\n                    (gain_power - 1)\n                    * scipy.constants.h\n                    * self.optical_carrier_frequency\n                    * 1e9  # Convert back to Hz\n                    * n_sp\n                )\n                sigma = torch.sqrt(psd * self.bw / 2)\n                b = sigma * (\n                    torch.randn(len(signal)).to(signal.device)\n                    + 1j * torch.randn(len(signal)).to(signal.device)\n                )\n                signal += b\n        return signal\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Execute forward() on calling of this class.\"\"\"\n        return self.forward(*args, **kwargs)", "\n\n@attr.define\nclass EDFAAmpDualPol(torch.nn.Module):\n    \"\"\"\n    Implement Gaussian noise EDFA model for dual polarization fiberoptical simulation.\n\n    :param span_length: span_length\n    :param amp_gain: Which amplification gain model to use either 'alpha_equalization',\n                     'equal_power'\n    :param alphaa_db: power loss coeficient [dB/km] for eigenstate a\n    :param alphab_db: power loss coeficient [dB/km] for eigenstate b\n    :param amp_noise: Consider amplification noise\n    :param noise_figure: Amplifier noise figure in dB\n    :param optical_carrier_frequency: Optical carrier frequency (for PSD) [GHz]\n    :param bw: Bandwidth of baseband signal (for PSD)\n    :param P_input_lin: Input power\n    :param padding: Number of samples to ignore in the beginning and end\n    \"\"\"\n\n    span_length: int\n    amp_gain: str\n    alphaa_db: torch.tensor\n    alphab_db: torch.tensor\n    amp_noise: bool\n    noise_figure: torch.tensor\n    optical_carrier_frequency: float\n    bw: float\n    P_input_lin: float\n    padding: int\n    alphaa_lin: torch.tensor = attr.field(init=False)\n    alphab_lin: torch.tensor = attr.field(init=False)\n\n    def __attrs_pre_init__(self):\n        \"\"\"Pre-init for attrs classes.\"\"\"\n        super(EDFAAmpDualPol, self).__init__()\n\n    def __attrs_post_init__(self):\n        \"\"\"Post-init for attrs classes.\"\"\"\n        self.alphaa_lin = self.alphaa_db * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n        self.alphab_lin = self.alphab_db * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n        self.amp_type = \"EDFA\"\n\n    def forward(self, u1, u2, segment):\n        r\"\"\"\n        Amplify the signal according to the selected method after each span.\n\n        attention: the noise depends on the amplification. if :math:`\\alpha = 0`,\n        no noise is added.\n\n        Parameters\n        ----------\n        signal : singal before the amplifier\n        segment: segment number\n        Returns\n        -------\n        signal : signal after the amplifier\n        \"\"\"\n        if self.alphaa_lin != 0 and self.alphab_lin != 0 and segment == 2:\n            if self.amp_gain == \"alpha_equalization\":\n                gain_signal_1 = torch.exp(0.5 * self.alphaa_lin * self.span_length)\n                gain_signal_2 = torch.exp(0.5 * self.alphab_lin * self.span_length)\n\n            elif self.amp_gain == \"equal_power\":\n                if self.padding > 0:\n                    P_in = torch.mean(\n                        torch.abs(u1[self.padding : -self.padding]) ** 2\n                    ) + torch.mean(torch.abs(u2[self.padding : -self.padding]) ** 2)\n                else:\n                    P_in = torch.mean(torch.abs(u1) ** 2) + torch.mean(\n                        torch.abs(u2) ** 2\n                    )\n                gain_signal_1 = torch.sqrt(self.P_input_lin / P_in)\n                gain_signal_2 = gain_signal_1\n            # calculate power spectrum density of the noise and add it to the\n            # signal according to On Signal Constellations and Coding for\n            # Long-Haul Fiber-Optical Systems (Christian H\u00e4ger)\n            u1 *= gain_signal_1\n            u2 *= gain_signal_2\n            logger.debug(\n                \"Pre noise addition: power u1 %s dBm\",\n                10 * torch.log10(torch.mean(torch.abs(u1) ** 2)).item() + 30,\n            )\n            if self.amp_noise:\n                gain_power = gain_signal_1**2\n                F_n = 10 ** (self.noise_figure / 10)  # amplifier noise figure\n                hf = scipy.constants.h * self.optical_carrier_frequency * 1e9\n                nsp = F_n / 2 * gain_power / (gain_power - 1)\n\n                p_rho_ase = nsp * (gain_power - 1) * hf\n                P_n_ase = 2 * p_rho_ase * self.bw\n                logger.debug(\"bw: %s\", self.bw)\n                logger.debug(\"nsp: %s\", nsp)\n                logger.debug(\"P_n: %s\", P_n_ase)\n                logger.debug(\n                    \"hf: %s\", scipy.constants.h * self.optical_carrier_frequency * 1e9\n                )\n                sigma = torch.sqrt(P_n_ase / 2)\n\n                n1 = sigma * (\n                    torch.randn(len(u1)).to(u1.device)\n                    + 1j * torch.randn(len(u1)).to(u1.device)\n                )\n                n2 = sigma * (\n                    torch.randn(len(u2)).to(u2.device)\n                    + 1j * torch.randn(len(u2)).to(u2.device)\n                )\n                u1 += n1\n                u2 += n2\n                # print(\"Post noise addition: power u1\",torch.mean(torch.abs(u1) ** 2))\n                logger.debug(\n                    \"Noise power u1 %s dBm\",\n                    10 * torch.log10(torch.mean(torch.abs(n1) ** 2)).item() + 30,\n                )\n                logger.debug(\n                    \"Post noise addition: power u1 %s dBm\",\n                    10 * torch.log10(torch.mean(torch.abs(u1) ** 2)).item() + 30,\n                )\n        return u1, u2\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Call forward() on calling of this class.\"\"\"\n        return self.forward(*args, **kwargs)", "\n\n@attr.define\nclass RamanAmpDualPol(torch.nn.Module):\n    \"\"\"\n    Implement a Gaussian model of the Raman dual polarization amp.\n\n    :param amp_gain: Which amplification gain model to use either 'alpha_equalization',\n                     'equal_power'\n    :param alphaa_db: power loss coeficient [dB/km] for eigenstate a\n    :param alphab_db: power loss coeficient [dB/km] for eigenstate b\n    :param noise_figure: Amplifier noise figure in dB\n    :param optical_carrier_frequency: Optical carrier frequency (for PSD) [GHz]\n    :param bw: Bandwidth of baseband signal (for PSD)\n    :param P_input_lin: Input power\n    :param padding: Number of samples to ignore in the beginning and end\n    \"\"\"\n\n    amp_gain: str\n    alphaa_db: torch.tensor\n    alphab_db: torch.tensor\n    amp_noise: bool\n    noise_figure: torch.tensor\n    optical_carrier_frequency: float\n    bw: float\n    P_input_lin: float\n    padding: int\n    alphaa_lin: torch.tensor = attr.field(init=False)\n    alphab_lin: torch.tensor = attr.field(init=False)\n\n    def __attrs_pre_init__(self):\n        \"\"\"Pre-init of attrs classes.\"\"\"\n        super(RamanAmpDualPol, self).__init__()\n\n    def __attrs_post_init__(self):\n        \"\"\"Post-init of attrs classes.\"\"\"\n        self.alphaa_lin = self.alphaa_db * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n        self.alphab_lin = self.alphab_db * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n        self.amp_type = \"Raman\"\n\n    def forward(self, u1, u2, dz):\n        r\"\"\"\n        Amplify the signal according to the selected method after each span.\n\n        Attention: the noise depends on the amplification. if :math:`\\alpha = 0`,\n        no noise is added\n        Parameters\n        ----------\n        signal : signal before the amplifier\n        dz : step-size\n        Returns\n        -------\n        signal : signal after the amplifier\n        \"\"\"\n        if self.alphaa_lin != 0 and self.alphab_lin != 0:\n            if self.amp_gain == \"alpha_equalization\":\n                gain_signal_1 = torch.exp(0.5 * self.alphaa_lin * dz)\n                gain_signal_2 = torch.exp(0.5 * self.alphab_lin * dz)\n\n            elif self.amp_gain == \"equal_power\":\n                if self.padding > 0:\n                    P_in = torch.mean(\n                        torch.abs(u1[self.padding : -self.padding]) ** 2\n                    ) + torch.mean(torch.abs(u2[self.padding : -self.padding]) ** 2)\n                else:\n                    P_in = torch.mean(torch.abs(u1) ** 2) + torch.mean(\n                        torch.abs(u2) ** 2\n                    )\n                gain_signal_1 = torch.sqrt(self.P_input_lin / P_in)\n                gain_signal_2 = gain_signal_1\n            # calculate power spectrum density of the noise and add it to the\n            # signal according to On Signal Constellations and Coding for\n            # Long-Haul Fiber-Optical Systems (Christian H\u00e4ger)\n            u1 *= gain_signal_1\n            u2 *= gain_signal_2\n            logger.debug(\n                \"Pre noise addition: power u1 %s dBm\",\n                10 * torch.log10(torch.mean(torch.abs(u1) ** 2)).item() + 30,\n            )\n            if self.amp_noise:\n                gain_power = gain_signal_1**2\n                F_n = 10 ** (self.noise_figure / 10)  # amplifier noise figure\n                n_sp = F_n / 2 * ((1 / ((1 - 1 / gain_power))))\n                psd = (\n                    (gain_power - 1)\n                    * scipy.constants.h\n                    * self.optical_carrier_frequency\n                    * 1e9  # Convert back to Hz\n                    * n_sp\n                )\n                # print(\"bw\", self.bw)\n                # print(\"n_sp\", n_sp)\n                # print(\"psd\", psd)\n                sigma = torch.sqrt(psd * self.bw / 2)\n\n                n1 = sigma * (\n                    torch.randn(len(u1)).to(u1.device)\n                    + 1j * torch.randn(len(u1)).to(u1.device)\n                )\n                n2 = sigma * (\n                    torch.randn(len(u2)).to(u2.device)\n                    + 1j * torch.randn(len(u2)).to(u2.device)\n                )\n                u1 += n1\n                u2 += n2\n                # print(\"Post noise addition: power u1\",torch.mean(torch.abs(u1) ** 2))\n                logger.debug(\n                    \"Noise power u1 %s dBm\",\n                    10 * torch.log10(torch.mean(torch.abs(n1) ** 2)).item() + 30,\n                )\n                logger.debug(\n                    \"Post noise addition: power u1 %s dBm\",\n                    10 * torch.log10(torch.mean(torch.abs(u1) ** 2)).item() + 30,\n                )\n        return u1, u2\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Execute `forward()` on call.\"\"\"\n        return self.forward(*args, **kwargs)", "\n\n@attr.define\nclass SSFMPropagationSinglePol(torch.nn.Module):\n    \"\"\"Non-linear fibre propagation (with SSFM).\n\n    This class is adapted from Code written by Dominik Rimpf published under the MIT\n    license [https://gitlab.com/domrim/bachelorarbeit-code]\n\n    This class solves the nonlinear Schrodinger equation for pulse propagation in an\n    optical fiber using the split-step Fourier method.\n    The actual implementation is the local error method Sec II.E of Optimization of the\n    Split-Step Fourier Method in Modeling Optical-Fiber Communications Systems\n    https://doi.org/10.1109/JLT.2003.808628\n\n\n    :param dt: time step between samples (sample time)\n    :param dz: propagation stepsize (delta z) of SSFM (segment length)\n    :param alphadb: power loss coeficient [dB/km]\n    :param beta2: dispersion polynomial coefficient\n    :param gamma: nonlinearity coefficient\n    :param length_span: Length of span between amplifiers\n    :param num_span: Number of spans where num_span * length_span is full fiber channel\n                     length\n    :param delta_G: Goal local error\n    :param maxiter: Number of step-size iterations\n\n    \"\"\"\n\n    dt: torch.tensor\n    dz: torch.tensor\n    alphadb: torch.tensor\n    betap: torch.tensor\n    gamma: torch.tensor\n    length_span: torch.tensor\n    num_span: torch.tensor\n    delta_G: torch.tensor = 1e-3\n    maxiter: torch.tensor = 4\n    alphalin: torch.tensor = attr.field(init=False)\n    amp: object = None\n    solver_method: str = \"localerror\"\n\n    def __attrs_pre_init__(self):\n        \"\"\"Pre-init for attrs classes.\"\"\"\n        super(SSFMPropagationSinglePol, self).__init__()\n\n    def __attrs_post_init__(self):\n        \"\"\"Post-init for attrs classes.\"\"\"\n        self.alphalin = self.alphadb * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n\n    def get_operators(self, dz):\n        \"\"\"Calculate linear operators for given step length.\"\"\"\n        # Linear operator (frequency domain) (EDFA) for RAMAN just set alphadb to zero\n        h_dz = torch.exp(self.h_basis * dz)\n        h_dz_2 = torch.exp(self.h_basis * dz * 0.5)\n\n        # Nonlinear operator (time domain)\n        def nonlinear_operator(u):\n            return torch.exp(-1j * self.gamma * torch.square(torch.absolute(u)) * dz)\n\n        return (h_dz, h_dz_2, nonlinear_operator)\n\n    def forward(self, u):  # noqa: C901\n        \"\"\"\n        Compute the propagation through the configured fiber-optical channel.\n\n        :param u0: input signal (array)\n        :returns: array signal at the end of the fiber\n        \"\"\"\n        w = (2 * torch.pi * torch.fft.fftfreq(u.shape[0], self.dt * 1e12)).to(\n            self.gamma.device\n        )  # THz\n\n        self.h_basis = -self.alphalin / 2 - self.betap[0]\n        wc = w\n        for i in range(1, self.betap.shape[0]):\n            self.h_basis = (\n                self.h_basis - (1j * self.betap[i] / np.math.factorial(i)) * wc\n            )\n            wc = wc * w\n\n        uz = u\n        # For EDFA apply amplification at the end of each span\n        # For RAMAN apply amplification at the beginning of each segment plus at the end\n        # of the simulation\n        # logger.info(\"y0 norm %s\", torch.linalg.vector_norm(y).item())\n        dz = self.dz\n        for span in range(self.num_span):\n            # logger.info(\"SSFM Span %s/%s\", span + 1, self.num_span.item())\n            z = 0\n            iter = 0\n            (h_2dz, h_dz, NOP2dz) = self.get_operators(2 * dz)\n            (h_dz, h_dz_2, NOPdz) = self.get_operators(dz)\n            new_dz = dz\n            while z + 2 * new_dz <= self.length_span and new_dz != 0:\n                if new_dz != dz:\n                    dz = new_dz\n                    (h_2dz, h_dz, NOP2dz) = self.get_operators(2 * dz)\n                    (h_dz, h_dz_2, NOPdz) = self.get_operators(dz)\n\n                uf = symmetrical_SSFM_step(uz, h_dz_2, NOPdz)\n                uf = symmetrical_SSFM_step(uf, h_dz_2, NOPdz)\n                # logger.info(\"uc norm %s\", torch.linalg.vector_norm(uc).item())\n                # logger.info(\"uf norm %s\", torch.linalg.vector_norm(uf).item())\n                good_sol_flag = True\n                if self.solver_method == \"localerror\":\n                    uc = symmetrical_SSFM_step(uz, h_dz, NOP2dz)\n                    delta = torch.linalg.vector_norm(\n                        uf - uc\n                    ) / torch.linalg.vector_norm(uf)\n\n                    if delta > 2 * self.delta_G:\n                        new_dz = dz / 2\n                        good_sol_flag = False\n                        iter = iter + 1\n                    elif self.delta_G <= delta <= 2 * self.delta_G:\n                        new_dz = dz / 1.259921049894873\n                    elif delta < 0.5 * self.delta_G:\n                        new_dz = dz * 1.259921049894873\n\n                if good_sol_flag or iter >= self.maxiter:\n                    if self.solver_method == \"localerror\":\n                        uz = (4 * uf - uc) / 3\n                    elif self.solver_method == \"fixedstep\":\n                        uz = uf\n                    else:\n                        uz = uf\n                    z = z + 2 * dz\n                    if iter >= self.maxiter:\n                        logger.info(\n                            \"WARNING: Failed to converge to goal local error \\\n                            of %s in %s iterations\",\n                            self.delta_G,\n                            self.maxiter,\n                        )\n                        new_dz = self.dz\n\n                    iter = 0\n\n                    if z + 2 * new_dz > self.length_span:\n                        new_dz = (self.length_span - z) / 2\n\n            if self.amp is not None:\n                uz = self.amp(uz, 2)\n\n        return uz\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Execute `forward()` on call.\"\"\"\n        return self.forward(*args, **kwargs)", "\n\n@attr.define\nclass SSFMPropagationDualPol(torch.nn.Module):\n    \"\"\"Coupled NLS fibre propagation (with SSFM).\n\n    This class is adapted from Code written by Dominik Rimpf published under the MIT\n    license [https://gitlab.com/domrim/bachelorarbeit-code]\n\n    This class solves the coupled nonlinear Schrodinger equation for pulse propagation\n    in an optical fiber using the split-step Fourier method.\n    The implementation and name are based on\n    https://photonics.umd.edu/software/ssprop/vector-version/\n\n    :param dt: time step between samples (sample time)\n    :param dz: propagation stepsize (delta z) of SSFM (segment length)\n    :param alphaa_db: power loss coeficient [dB/km] for eigenstate a\n    :param alphab_db: power loss coeficient [dB/km] for eigenstate b\n    :param betapa: dispersion polynomial coefficient vector for eigenstate a\n    :param betapb: dispersion polynomial coefficient vector for eigenstate b\n    :param gamma: nonlinearity coefficient\n    :param length_span: Length of span between amplifiers\n    :param num_span: Number of spans where num_span * length_span is full fiber channel\n                     length\n    :param delta_G: Goal local error (optional) (default 1e-3)\n    :param maxiter: Number of step-size iterations (optional) (default 4)\n    :param psp: Principal eigenstate of the fiber specified as a 2-vector containing\n                the angles Psi and Chi (optional) (default [0,0])\n    :param solution_method: String that specifies which method to use when performing\n                            the split-step calculations. Supported methods elliptical\n                            and circular (optional) (default elliptical)\n\n    \"\"\"\n\n    dt: torch.tensor\n    dz: torch.tensor\n    alphaa_db: torch.tensor\n    alphab_db: torch.tensor\n    betapa: torch.tensor\n    betapb: torch.tensor\n    gamma: torch.tensor\n    length_span: torch.tensor\n    num_span: torch.tensor\n    delta_G: torch.tensor = 1e-3\n    maxiter: torch.tensor = 4\n    psp: torch.tensor = torch.tensor([0, 0])\n    solution_method = \"elliptical\"\n    alphaa_lin: torch.tensor = attr.field(init=False)\n    alphab_lin: torch.tensor = attr.field(init=False)\n    amp: object = None\n    solver_method: str = \"localerror\"\n\n    def __attrs_pre_init__(self):\n        \"\"\"Pre-init for attrs classes.\"\"\"\n        super(SSFMPropagationDualPol, self).__init__()\n\n    def __attrs_post_init__(self):\n        \"\"\"Post-init for attrs classes.\"\"\"\n        self.alphaa_lin = self.alphaa_db * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n        self.alphab_lin = self.alphab_db * (\n            torch.log(torch.tensor(10)) / 10\n        )  # dB/km -> 1/km\n        self.Psi = self.psp[0]\n        self.Chi = self.psp[1]\n\n        if self.solution_method == \"elliptical\":\n            self.TM11 = torch.cos(self.Psi) * torch.cos(self.Chi) + 1j * torch.sin(\n                self.Psi\n            ) * torch.sin(self.Chi)\n            self.TM12 = torch.sin(self.Psi) * torch.cos(self.Chi) - 1j * torch.cos(\n                self.Psi\n            ) * torch.sin(self.Chi)\n            self.TM21 = -torch.sin(self.Psi) * torch.cos(self.Chi) - 1j * torch.cos(\n                self.Psi\n            ) * torch.sin(self.Chi)\n            self.TM22 = torch.cos(self.Psi) * torch.cos(self.Chi) - 1j * torch.sin(\n                self.Psi\n            ) * torch.sin(self.Chi)\n\n            self.n1_basis = (\n                (1j / 3) * self.gamma * (2 + torch.square(torch.cos(2 * self.Chi)))\n            )\n            self.n2_basis = (\n                (1j / 3) * self.gamma * (2 + 2 * torch.square(torch.sin(2 * self.Chi)))\n            )\n\n        elif self.solution_method == \"circular\":\n            sqrt2 = torch.sqrt(2)\n            self.TM11 = 1 / sqrt2\n            self.TM12 = -1j / sqrt2\n            self.TM21 = self.TM12\n            self.TM22 = self.TM11\n\n            self.n1_basis = (2j / 3) * self.gamma\n            self.n2_basis = (4j / 3) * self.gamma\n        else:\n            raise ValueError(\"Unknown solution method.\")\n\n    def get_operators(self, dz):\n        \"\"\"Obtain linear operators for given step length.\"\"\"\n        \"\"\"\n        Create operators based on step-size\n        \"\"\"\n        if self.solution_method == \"elliptical\":\n            # Linear operator (frequency domain) (EDFA)\n            h11_dz = torch.exp(self.ha_basis * dz)\n            h11_dz_2 = torch.exp(self.ha_basis * dz / 2)\n            h22_dz = torch.exp(self.hb_basis * dz)\n            h22_dz_2 = torch.exp(self.hb_basis * dz / 2)\n            h12_dz = 0\n            h12_dz_2 = 0\n            h21_dz = 0\n            h21_dz_2 = 0\n\n        elif self.solution_method == \"circular\":\n            self.solution_method = \"elliptical\"\n            ha_dz, ha_dz_2, _, _, _, _, hb_dz, hb_dz_2 = self.get_operators(dz)\n            self.solution_method = \"circular\"\n\n            sp = 0.5 * (1 + torch.sin(2 * self.Chi))\n            sn = 0.5 * (1 - torch.sin(2 * self.Chi))\n            h11_dz = sp * ha_dz + sn * hb_dz\n            h11_dz_2 = sp * ha_dz_2 + sn * hb_dz_2\n\n            h12_dz = 0.5j * torch.exp(-2j * self.Psi) * torch.cos(2 * self.Chi)\n            h12_dz_2 = h12_dz * (ha_dz_2 - hb_dz_2)\n            h12_dz = h12_dz * (ha_dz - hb_dz)\n\n            h21_dz = -0.5j * torch.exp(2j * self.Psi) * torch.cos(2 * self.Chi)\n            h21_dz_2 = h21_dz * (ha_dz_2 - hb_dz_2)\n            h21_dz = h21_dz * (ha_dz - hb_dz)\n\n            h22_dz = sn * ha_dz + sp * hb_dz\n            h22_dz_2 = sn * ha_dz_2 + sp * hb_dz_2\n\n        else:\n            raise ValueError(\"Unknown solution method.\")\n\n        # Nonlinear operator (time domain)\n        def nonlinear_operator(u1, u2):\n            u1abssqre = torch.square(torch.absolute(u1))\n            u2abssqre = torch.square(torch.absolute(u2))\n            return torch.exp(\n                ((self.n1_basis * u1abssqre) + (self.n2_basis * u2abssqre)) * dz\n            ), torch.exp(\n                ((self.n1_basis * u2abssqre) + (self.n2_basis * u1abssqre)) * dz\n            )\n\n        return (\n            h11_dz,\n            h11_dz_2,\n            h12_dz,\n            h12_dz_2,\n            h21_dz,\n            h21_dz_2,\n            h22_dz,\n            h22_dz_2,\n            nonlinear_operator,\n        )\n\n    def forward(self, ux, uy):\n        \"\"\"\n        Compute the progpagation for the dual polarization signal through the \\\n        fiber optical channel.\n\n        :param ux: input signal in x-polarization.\n        :param uy: input signal in y-polarization.\n        :returns: signal at the end of the fiber\n        \"\"\"\n        w = (2 * torch.pi * torch.fft.fftfreq(ux.shape[0], self.dt * 1e12)).to(\n            self.betapa.device\n        )  # THz\n\n        self.ha_basis = -self.alphaa_lin / 2 - self.betapa[0]\n        self.hb_basis = -self.alphab_lin / 2 - self.betapb[0]\n        wc = w\n        for i in range(1, self.betapa.shape[0]):\n            self.ha_basis = (\n                self.ha_basis - (1j * self.betapa[i] / math.factorial(i)) * wc\n            )\n            self.hb_basis = (\n                self.hb_basis - (1j * self.betapb[i] / math.factorial(i)) * wc\n            )\n            wc = wc * w\n\n        u1 = self.TM11 * ux + self.TM12 * uy\n        u2 = self.TM21 * ux + self.TM22 * uy\n        # For EDFA apply amplification at the end of each span\n\n        # logger.info(\"y0 norm %s\", torch.linalg.vector_norm(y).item())\n        dz = self.dz\n        # logger.info(\"u1 norm %s\", torch.linalg.vector_norm(u1).item())\n        # logger.info(\"u2 norm %s\", torch.linalg.vector_norm(u2).item())\n        for span in range(self.num_span):\n            # logger.info(\"SSFM Span %s/%s\", span + 1, self.num_span.item())\n            z = 0\n            iter = 0\n            (\n                h11_2dz,\n                h11_dz,\n                h12_2dz,\n                h12_dz,\n                h21_2dz,\n                h21_dz,\n                h22_2dz,\n                h22_dz,\n                NOP2dz,\n            ) = self.get_operators(2 * dz)\n            (\n                h11_dz,\n                h11_dz_2,\n                h12_dz,\n                h12_dz_2,\n                h21_dz,\n                h21_dz_2,\n                h22_dz,\n                h22_dz_2,\n                NOPdz,\n            ) = self.get_operators(dz)\n            new_dz = dz\n            while z + 2 * new_dz <= self.length_span and new_dz != 0:\n                if new_dz != dz:\n                    dz = new_dz\n                    (\n                        h11_2dz,\n                        h11_dz,\n                        h12_2dz,\n                        h12_dz,\n                        h21_2dz,\n                        h21_dz,\n                        h22_2dz,\n                        h22_dz,\n                        NOP2dz,\n                    ) = self.get_operators(2 * dz)\n                    (\n                        h11_dz,\n                        h11_dz_2,\n                        h12_dz,\n                        h12_dz_2,\n                        h21_dz,\n                        h21_dz_2,\n                        h22_dz,\n                        h22_dz_2,\n                        NOPdz,\n                    ) = self.get_operators(dz)\n\n                u1f, u2f = symmetrical_SSPROPV_step(\n                    u1, u2, h11_dz_2, h12_dz_2, h21_dz_2, h22_dz_2, NOPdz\n                )\n                u1f, u2f = symmetrical_SSPROPV_step(\n                    u1f, u2f, h11_dz_2, h12_dz_2, h21_dz_2, h22_dz_2, NOPdz\n                )\n                good_sol_flag = True\n                # logger.info(\"u1c norm %s\", torch.linalg.vector_norm(u1c).item())\n                # logger.info(\"u2c norm %s\", torch.linalg.vector_norm(u2c).item())\n                # logger.info(\"u1f norm %s\", torch.linalg.vector_norm(u1f).item())\n                # logger.info(\"u2f norm %s\", torch.linalg.vector_norm(u2f).item())\n                if self.solution_method == \"localerror\":\n                    u1c, u2c = symmetrical_SSPROPV_step(\n                        u1, u2, h11_dz, h12_dz, h21_dz, h22_dz, NOP2dz\n                    )\n                    delta = (\n                        torch.linalg.vector_norm(u1f - u1c)\n                        + torch.linalg.vector_norm(u2f - u2c)\n                    ) / (torch.linalg.vector_norm(u1f) + torch.linalg.vector_norm(u2f))\n                    # logger.info(\"dz is %s, delta is %s\", dz.item(), delta.item())\n\n                    if delta > 2 * self.delta_G:\n                        new_dz = dz / 2\n                        good_sol_flag = False\n                        iter = iter + 1\n                    elif self.delta_G <= delta <= 2 * self.delta_G:\n                        new_dz = dz / 1.259921049894873\n                    elif delta < 0.5 * self.delta_G:\n                        new_dz = dz * 1.259921049894873\n\n                if good_sol_flag or iter >= self.maxiter:\n                    if self.solution_method == \"localerror\":\n                        u1 = (4 * u1f - u1c) / 3\n                        u2 = (4 * u2f - u2c) / 3\n                    elif self.solution_method == \"fixedstep\":\n                        u1 = u1f\n                        u2 = u2f\n                    else:\n                        u1 = u1f\n                        u2 = u2f\n\n                    z = z + 2 * dz\n\n                    if self.amp is not None and self.amp.amp_type == \"Raman\":\n                        u1, u2 = self.amp(u1, u2, 2 * dz)  # TODO Where to add noise?\n\n                    if iter >= self.maxiter:\n                        logger.info(\n                            \"WARNING: Failed to converge to goal local error \\\n                             of %s in %s iterations\",\n                            self.delta_G,\n                            self.maxiter,\n                        )\n                        new_dz = self.dz\n\n                    iter = 0\n\n                    if z + 2 * new_dz > self.length_span:\n                        new_dz = (self.length_span - z) / 2\n\n                    # logger.info(\"z is %s,new_dz is %s\", z.item(), new_dz.item())\n\n            if self.amp is not None and self.amp.amp_type == \"EDFA\":\n                u1, u2 = self.amp(u1, u2, 2)  # TODO Where to add noise?\n            # logger.info(\"yz norm %s\", torch.linalg.vector_norm(yz).item())\n        ux = self.TM22 * u1 - self.TM12 * u2\n        uy = -self.TM21 * u1 + self.TM11 * u2\n        return ux, uy\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Execute `forward()` on call.\"\"\"\n        return self.forward(*args, **kwargs)", "\n\ndef SSFM_step(signal, linear_op, nonlinear_op):\n    \"\"\"Calculate single polarization SSFM step.\"\"\"\n    f_signal = torch.fft.fft(signal) * linear_op\n    t_signal = torch.fft.ifft(f_signal)\n    t_signal = t_signal * nonlinear_op(t_signal)\n    return t_signal\n\n\ndef symmetrical_SSFM_step(signal, half_linear_op, nonlinear_op):\n    \"\"\"Calculate symmetrical single polarization SSFM step.\"\"\"\n    f_signal = torch.fft.fft(signal) * half_linear_op\n    t_signal = torch.fft.ifft(f_signal)\n    t_signal = t_signal * nonlinear_op(t_signal)\n    return torch.fft.ifft(torch.fft.fft(t_signal) * half_linear_op)", "\n\ndef symmetrical_SSFM_step(signal, half_linear_op, nonlinear_op):\n    \"\"\"Calculate symmetrical single polarization SSFM step.\"\"\"\n    f_signal = torch.fft.fft(signal) * half_linear_op\n    t_signal = torch.fft.ifft(f_signal)\n    t_signal = t_signal * nonlinear_op(t_signal)\n    return torch.fft.ifft(torch.fft.fft(t_signal) * half_linear_op)\n\n\ndef symmetrical_SSPROPV_step(u1, u2, h11, h12, h21, h22, NOP):\n    \"\"\"Calculate symmetrical dual polarization SSFM step.\"\"\"\n    u1f = torch.fft.fft(u1)\n    u2f = torch.fft.fft(u2)\n    u1 = torch.fft.ifft(h11 * u1f + h12 * u2f)\n    u2 = torch.fft.ifft(h21 * u1f + h22 * u2f)\n    nu1, nu2 = NOP(u1, u2)\n    u1 = nu1 * u1\n    u2 = nu2 * u2\n    u1f = torch.fft.fft(u1)\n    u2f = torch.fft.fft(u2)\n    u1 = torch.fft.ifft(h11 * u1f + h12 * u2f)\n    u2 = torch.fft.ifft(h21 * u1f + h22 * u2f)\n    return u1, u2", "\n\ndef symmetrical_SSPROPV_step(u1, u2, h11, h12, h21, h22, NOP):\n    \"\"\"Calculate symmetrical dual polarization SSFM step.\"\"\"\n    u1f = torch.fft.fft(u1)\n    u2f = torch.fft.fft(u2)\n    u1 = torch.fft.ifft(h11 * u1f + h12 * u2f)\n    u2 = torch.fft.ifft(h21 * u1f + h22 * u2f)\n    nu1, nu2 = NOP(u1, u2)\n    u1 = nu1 * u1\n    u2 = nu2 * u2\n    u1f = torch.fft.fft(u1)\n    u2f = torch.fft.fft(u2)\n    u1 = torch.fft.ifft(h11 * u1f + h12 * u2f)\n    u2 = torch.fft.ifft(h21 * u1f + h22 * u2f)\n    return u1, u2", "\n\ndef SSFM_halfstep_end(signal, linear_op):\n    \"\"\"Calculate the final halfstep of the single polarization SSFM.\"\"\"\n    return torch.fft.ifft(torch.fft.fft(signal) * linear_op)\n"]}
{"filename": "src/mokka/channels/__init__.py", "chunked_list": ["\"\"\"Module with channel model implementations.\"\"\"\n\nfrom . import torch  # noqa\n"]}
{"filename": "src/mokka/equalizers/torch.py", "chunked_list": ["\"\"\"Equalizer blocks after channel before decoder/demodulator - in PyTorch.\"\"\"\nimport torch\nimport numpy as np\n\n\nclass CD_compensation(torch.nn.Module):\n    \"\"\"\n    Class implementing chromatic dispersion compensation in the frequency domain.\n\n    :param dt: sample time [s]\n    :param beta2: dispersion coefficient of the optical fiber [ps^2/km]\n    :param channel_length: total length of the channel [km]\n    \"\"\"\n\n    def __init__(self, dt, beta2, channel_length):\n        \"\"\"Construct `CD_compensation`.\"\"\"\n        super(CD_compensation, self).__init__()\n        self.dt = dt\n        self.beta2 = beta2  # ps**2/km\n        self.channel_length = channel_length\n\n    def forward(self, y):\n        \"\"\"\n        Peform chromatic dispersion compensation in the frequency domain.\n\n        :param y: received complex single polarization signal y\n        :returns: equalized signal\n        \"\"\"\n        nt = y.size()[0]\n        dw = (2 * np.pi * torch.fft.fftfreq(nt, self.dt * 1e12)).to(y.device)  # *(1/4)\n\n        linear_operator = torch.exp(\n            -1j * self.beta2 / 2 * dw**2 * self.channel_length\n        )\n        Y = torch.fft.fft(y)\n        Y = Y / linear_operator\n        return torch.fft.ifft(Y)", ""]}
{"filename": "src/mokka/equalizers/__init__.py", "chunked_list": ["\"\"\"Module implementing equalizers.\"\"\"\n\nfrom . import torch  # noqa\n"]}
{"filename": "src/mokka/e2e/torch.py", "chunked_list": ["\"\"\"Module with blocks for end-to-end simulations in PyTorch.\"\"\"\n\nimport torch\nfrom .. import channels\nfrom ..mapping.torch import ConstellationMapper, ConstellationDemapper\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass BitwiseAutoEncoder(torch.nn.Module):\n    \"\"\"\n    Bitwise Auto-Encoder implementation.\n\n    :param m: bits per symbol and input and output width of the Autoencoder\n    :param demapper_width: Width of the hidden layers in the demapper\n    :param demapper_depth: Number of hidden layers in the demapper\n\n    \"\"\"\n\n    def __init__(\n        self,\n        m,\n        demapper_width=127,\n        demapper_depth=3,\n        channel=None,\n        mod_extra_params=(0,),\n        demod_extra_params=(0,),\n        mapper=None,\n        demapper=None,\n    ):\n        \"\"\"Construct BitwiseAutoEncoder.\"\"\"\n        super(BitwiseAutoEncoder, self).__init__()\n        # Attributes\n        self.m = m\n        # Layers\n        if mapper is None:\n            self.mapper = ConstellationMapper(m, mod_extra_params=mod_extra_params)\n        else:\n            self.mapper = mapper\n        if channel is not None:\n            self.channel = channel\n        else:\n            self.channel = channels.ComplexAWGN()\n        if demapper is None:\n            self.demapper = ConstellationDemapper(\n                m,\n                depth=demapper_depth,\n                width=demapper_width,\n                demod_extra_params=demod_extra_params,\n            )\n        else:\n            self.demapper = demapper\n\n    def forward(self, b, *args):\n        \"\"\"\n        Perform end-to-end simulation with the BitWiseAutoEncoder.\n\n        Take input-bits and output LLRs, then outside of the auto-encoder the loss\n        can be calculated.\n\n        :param b: tensor of bit-strings.\n        :returns: tensor of LLRs.\n        \"\"\"\n        logger.debug(\"args: %s\", args)\n        x = self.mapper(b, *args)\n\n        # Feed transmit symbols through channel with given parametrization\n\n        logger.debug(\"x size: %s\", x.size())\n        y = self.channel(x, *args)\n        logger.debug(\"y size: %s\", y.size())\n\n        # For symbols with E(|x|**2) = 1 N0 == 1/snr\n        # with sqrt(N0) for I and sqrt(N0) for Q\n        # to create circular Gaussian noise in the complex domain\n        # TODO seed RNG for controlled/reproducible simulations\n        x_hat = self.demapper(y, *args)\n        logger.debug(\"x_hat size: %s\", x_hat.size())\n        return x_hat\n\n    @staticmethod\n    def load_model(model_dict):\n        \"\"\"Load model weights from a dictionary.\n\n        :param model_dict: model weights from a file, opened with torch.load.\n        :returns: BitwiseAutoEncoder model initialized with saved weights.\n\n        \"\"\"\n        m = model_dict[\"demapper.m\"].item()\n        demod_extra_params = model_dict[\"demapper.demod_extra_params\"].tolist()\n        mod_extra_params = model_dict[\"mapper.mod_extra_params\"].tolist()\n        width = model_dict[\"demapper.width\"].item()\n        depth = model_dict[\"demapper.depth\"].item()\n        model = BitwiseAutoEncoder(\n            m,\n            demapper_width=width,\n            demapper_depth=depth,\n            demod_extra_params=demod_extra_params,\n            mod_extra_params=mod_extra_params,\n        )\n        model.load_state_dict(model_dict)\n        return model", "\n\nclass BitwiseAutoEncoder(torch.nn.Module):\n    \"\"\"\n    Bitwise Auto-Encoder implementation.\n\n    :param m: bits per symbol and input and output width of the Autoencoder\n    :param demapper_width: Width of the hidden layers in the demapper\n    :param demapper_depth: Number of hidden layers in the demapper\n\n    \"\"\"\n\n    def __init__(\n        self,\n        m,\n        demapper_width=127,\n        demapper_depth=3,\n        channel=None,\n        mod_extra_params=(0,),\n        demod_extra_params=(0,),\n        mapper=None,\n        demapper=None,\n    ):\n        \"\"\"Construct BitwiseAutoEncoder.\"\"\"\n        super(BitwiseAutoEncoder, self).__init__()\n        # Attributes\n        self.m = m\n        # Layers\n        if mapper is None:\n            self.mapper = ConstellationMapper(m, mod_extra_params=mod_extra_params)\n        else:\n            self.mapper = mapper\n        if channel is not None:\n            self.channel = channel\n        else:\n            self.channel = channels.ComplexAWGN()\n        if demapper is None:\n            self.demapper = ConstellationDemapper(\n                m,\n                depth=demapper_depth,\n                width=demapper_width,\n                demod_extra_params=demod_extra_params,\n            )\n        else:\n            self.demapper = demapper\n\n    def forward(self, b, *args):\n        \"\"\"\n        Perform end-to-end simulation with the BitWiseAutoEncoder.\n\n        Take input-bits and output LLRs, then outside of the auto-encoder the loss\n        can be calculated.\n\n        :param b: tensor of bit-strings.\n        :returns: tensor of LLRs.\n        \"\"\"\n        logger.debug(\"args: %s\", args)\n        x = self.mapper(b, *args)\n\n        # Feed transmit symbols through channel with given parametrization\n\n        logger.debug(\"x size: %s\", x.size())\n        y = self.channel(x, *args)\n        logger.debug(\"y size: %s\", y.size())\n\n        # For symbols with E(|x|**2) = 1 N0 == 1/snr\n        # with sqrt(N0) for I and sqrt(N0) for Q\n        # to create circular Gaussian noise in the complex domain\n        # TODO seed RNG for controlled/reproducible simulations\n        x_hat = self.demapper(y, *args)\n        logger.debug(\"x_hat size: %s\", x_hat.size())\n        return x_hat\n\n    @staticmethod\n    def load_model(model_dict):\n        \"\"\"Load model weights from a dictionary.\n\n        :param model_dict: model weights from a file, opened with torch.load.\n        :returns: BitwiseAutoEncoder model initialized with saved weights.\n\n        \"\"\"\n        m = model_dict[\"demapper.m\"].item()\n        demod_extra_params = model_dict[\"demapper.demod_extra_params\"].tolist()\n        mod_extra_params = model_dict[\"mapper.mod_extra_params\"].tolist()\n        width = model_dict[\"demapper.width\"].item()\n        depth = model_dict[\"demapper.depth\"].item()\n        model = BitwiseAutoEncoder(\n            m,\n            demapper_width=width,\n            demapper_depth=depth,\n            demod_extra_params=demod_extra_params,\n            mod_extra_params=mod_extra_params,\n        )\n        model.load_state_dict(model_dict)\n        return model", ""]}
{"filename": "src/mokka/e2e/__init__.py", "chunked_list": ["\"\"\"Module with blocks for end-to-end simulations.\"\"\"\n\nfrom . import torch  # noqa\n"]}
{"filename": "src/mokka/inft/torch.py", "chunked_list": ["\"\"\"Implementation of information theoretic functions in pyTorch for MOKKa.\"\"\"\n\nimport torch\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\ndef BMI(m, N, b_ij, L_ij, p=None):\n    \"\"\"\n    Calculate the bitwise mutual information.\n\n    Originally written by Benedikt Geiger\n\n    Parameters\n    ----------\n    m           : int\n        number of bits\n    N           : int\n        number of sent/received symbols\n    b_ij        : 2D-matrix_like\n        value of the i-th (Sent) modulation symbol\n        at the j-th position in the bit-string\n    L_ij        : 2D-matrix_like\n        LLRs\n\n    Returns\n    -------\n    BMI         : float\n        bitwise mutual information\n    \"\"\"\n    if p is not None:\n        entropy = torch.sum(-p * torch.log2(p))\n    else:\n        entropy = m\n    BMI = entropy - 1 / N * torch.sum(\n        torch.log2(\n            1\n            + torch.exp(\n                torch.clip(\n                    -1 * torch.pow(-1, b_ij) * L_ij,\n                    max=torch.tensor(88.0).to(b_ij.device),\n                )\n            )\n        )\n    )  # Positive L_ij corresponds to 0 bit\n    return BMI", "def BMI(m, N, b_ij, L_ij, p=None):\n    \"\"\"\n    Calculate the bitwise mutual information.\n\n    Originally written by Benedikt Geiger\n\n    Parameters\n    ----------\n    m           : int\n        number of bits\n    N           : int\n        number of sent/received symbols\n    b_ij        : 2D-matrix_like\n        value of the i-th (Sent) modulation symbol\n        at the j-th position in the bit-string\n    L_ij        : 2D-matrix_like\n        LLRs\n\n    Returns\n    -------\n    BMI         : float\n        bitwise mutual information\n    \"\"\"\n    if p is not None:\n        entropy = torch.sum(-p * torch.log2(p))\n    else:\n        entropy = m\n    BMI = entropy - 1 / N * torch.sum(\n        torch.log2(\n            1\n            + torch.exp(\n                torch.clip(\n                    -1 * torch.pow(-1, b_ij) * L_ij,\n                    max=torch.tensor(88.0).to(b_ij.device),\n                )\n            )\n        )\n    )  # Positive L_ij corresponds to 0 bit\n    return BMI", "\n\ndef MI(M, PX, N, symbol_idx, Q_YX):\n    \"\"\"\n    Calculate the mutual information.\n\n    Numerically Computing Achievable Rates of Memoryless Channels\n\n    Parameters\n    ----------\n    M           : int\n        number of symbols\n    N           : int\n        number of sent/received symbols\n    Q_YX        : 2D-matrix_like\n        N x M conditonal probabilities\n    PX        : 2D-matrix_like\n        1 x M\n\n    Returns\n    -------\n    MI         : float\n        mutual information\n    \"\"\"\n    MI = torch.mean(\n        torch.log2(\n            Q_YX[torch.arange(0, N, device=Q_YX.device), symbol_idx]\n            / torch.sum(Q_YX * PX, 1)\n        ),\n        0,\n    )\n    return MI", "\n\ndef hMI(m, N, symbol_idx, demapped_symbol_idx):\n    \"\"\"\n    Calculate the mutual information according to \\\n    \"Achievable Rates for Probabilistic Shaping\" (Eq. 87).\n\n    If probabilistic shaping is applied this has to be reflected\n    in the transmit symbols indices\n\n    Parameters\n    ----------\n    m           : int\n        number of bits per symbol\n    N           : int\n        number of sent/received symbols\n    b_ij        : 2D-matrix_like\n        value of the i-th (Sent) modulation symbol\n        at the j-th position in the bit-string\n    rb_ij        : 2D-matrix_like\n        received bits\n\n    Returns\n    -------\n    BMI         : float\n        bitwise mutual information\n\n    \"\"\"\n    epsilon = 1 - torch.count_nonzero(demapped_symbol_idx == symbol_idx) / N\n    epsilon = torch.clamp(epsilon, 1e-8, 1 - 1e-8)\n    logger.debug(\"epsilon: %s\", epsilon.item())\n    hard_mi = m - (\n        -(1 - epsilon) * torch.log2(1 - epsilon)\n        - epsilon * torch.log2(epsilon)\n        + epsilon * torch.log2(torch.tensor(2**m - 1))\n    )\n\n    return hard_mi", "\n\ndef SNR(M, sym_idx, rx_syms):\n    \"\"\"\n    Calculate the signal to noise ratio.\n\n    Parameters\n    ----------\n    M           : int\n        number of constellation points\n    sym_idx        : Vector\n        Transmitted symbol indices between 0 and M-1\n    rx_syms        : Vector\n        Complex received symbols\n\n    Returns\n    -------\n    SNR        : float\n        Signal to noise ratio in linear units\n    SNR_dB        :float\n        Signal to noise ratio in decibels\n\n    \"\"\"\n    assert sym_idx.shape == rx_syms.shape, \"Dimension mismatch\"\n    rx_vals_mean = torch.zeros(M, dtype=torch.complex64, device=rx_syms.device)\n    rx_vals_sigma2 = torch.zeros(M, dtype=torch.float64, device=rx_syms.device)\n    for i in torch.arange(M):\n        idx = (sym_idx == i).nonzero()\n        rx_vals_mean[i] = torch.mean(rx_syms[idx])\n        rx_vals_sigma2[i] = torch.mean(\n            torch.square(torch.abs(rx_syms[idx] - rx_vals_mean[i]))\n        )\n    SNR = torch.mean(torch.square(torch.abs(rx_vals_mean))) / torch.mean(rx_vals_sigma2)\n    SNR_dB = 10 * torch.log10(SNR)\n    return SNR, SNR_dB", ""]}
{"filename": "src/mokka/inft/__init__.py", "chunked_list": ["\"\"\"Module implementing functions in information theory for MOKKa.\"\"\"\n\nfrom . import torch  # noqa\n"]}
