{"filename": "src/lcd/__main__.py", "chunked_list": ["import importlib.util\nimport os\nfrom pathlib import Path\n\nimport typer\nfrom loguru import logger\n\nfrom lcd.utils.setup import abspath  # for monkeypatches\n\n# Define the directory path containing the Python modules to import", "\n# Define the directory path containing the Python modules to import\napps_dir = abspath() / \"apps\"\napp: typer.Typer = typer.Typer(name=\"lcd\", no_args_is_help=True, pretty_exceptions_show_locals=False)\n\n\ndef main():\n    \"\"\"The master entrypoint to lcd.\n    :param app: The app to run.\n    :type app: str\n    \"\"\"\n    command_kwargs = dict(\n        context_settings={\n            \"allow_extra_args\": True,\n            \"ignore_unknown_options\": True,\n        },\n        # no_args_is_help=True\n    )\n    # Iterate over all files in the directory\n    for filename in os.listdir(apps_dir):\n        # Check if the file is a Python module\n        if filename.endswith(\".py\"):\n            # Construct the module name from the filename\n            module_name = filename[:-3]\n            # Import the module using importlib\n            module_spec = importlib.util.spec_from_file_location(\n                module_name, os.path.join(apps_dir, filename)\n            )\n            module = importlib.util.module_from_spec(module_spec)\n            module_spec.loader.exec_module(module)\n            # Add the module to the dictionary\n            if hasattr(module, \"_app_\"):\n                module_app = module._app_\n                app.add_typer(\n                    module_app,\n                    name=module_name,\n                    **command_kwargs\n                    # add docs later by modulestring\n                )\n\n            else:\n                try:\n                    app.command(name=module_name, **command_kwargs)(module.main)\n                except AttributeError as e:\n                    logger.info(\n                        f\"{app} doesn't have a main function. Please check that {os.path.join(apps_dir, module_name)}.py defines main()\"\n                    )\n\n    app()", "\n\nif __name__ == \"__main__\":\n    main()\n"]}
{"filename": "src/lcd/__init__.py", "chunked_list": ["# type: ignore[attr-defined]\n\"\"\"Code for efficiently scaling through space, time, and tasks\"\"\"\n\n\"\"\"\nMonkey Patching\n\"\"\"\n# monkey patch loguru to default with colors\nimport loguru\n\nfrom lcd.utils.setup import abspath", "\nfrom lcd.utils.setup import abspath\n\nloguru.logger = loguru.logger.opt(colors=True)\n\n\ndef remove_shm_from_resource_tracker():\n    \"\"\"\n    Monkey patch multiprocessing.resource_tracker so SharedMemory won't be tracked\n    More details at: https://bugs.python.org/issue38119\n    \"\"\"\n    # pylint: disable=protected-access, import-outside-toplevel\n    # Ignore linting errors in this bug workaround hack\n    from multiprocessing import resource_tracker\n\n    def fix_register(name, rtype):\n        if rtype == \"shared_memory\":\n            return None\n        return resource_tracker._resource_tracker.register(name, rtype)\n\n    resource_tracker.register = fix_register\n\n    def fix_unregister(name, rtype):\n        if rtype == \"shared_memory\":\n            return None\n        return resource_tracker._resource_tracker.unregister(name, rtype)\n\n    resource_tracker.unregister = fix_unregister\n    if \"shared_memory\" in resource_tracker._CLEANUP_FUNCS:\n        del resource_tracker._CLEANUP_FUNCS[\"shared_memory\"]", "\n\n# More details at: https://bugs.python.org/issue38119\nremove_shm_from_resource_tracker()\n\nimport sys\nfrom importlib import metadata as importlib_metadata\n\n\"\"\"\nGlobal variables", "\"\"\"\nGlobal variables\n\"\"\"\nfrom pathlib import Path\n\n# * Feel free to change this path if your data is stored somewhere else\n# DATA_PATH = (abspath() / \"../../submodules/hulc-data\").resolve()\nDATA_PATH = (abspath() / \"../../submodules/hulc-data\").resolve()\nHULC_PATH = (abspath() / \"../../submodules/hulc-baseline\").resolve()\nREPO_PATH = (abspath() / \"../../\").resolve()", "HULC_PATH = (abspath() / \"../../submodules/hulc-baseline\").resolve()\nREPO_PATH = (abspath() / \"../../\").resolve()\n\n# Check these paths exist\nassert DATA_PATH.exists(), f\"{DATA_PATH=} does not exist\"\nassert HULC_PATH.exists(), f\"{HULC_PATH=} does not exist\"\nassert REPO_PATH.exists(), f\"{REPO_PATH=} does not exist\"\n\n\"\"\"\nVersioning", "\"\"\"\nVersioning\n\"\"\"\n\n\ndef get_version() -> str:\n    try:\n        return importlib_metadata.version(__name__)\n    except importlib_metadata.PackageNotFoundError:  # pragma: no cover\n        return \"unknown\"", "\n\nversion: str = get_version()\n"]}
{"filename": "src/lcd/utils/git_utils.py", "chunked_list": ["import os\nimport pdb\n\nimport git\n\nPROJECT_PATH = os.path.dirname(os.path.realpath(os.path.join(__file__, \"..\", \"..\")))\n\n\ndef get_repo(path=PROJECT_PATH, search_parent_directories=True):\n    repo = git.Repo(path, search_parent_directories=search_parent_directories)\n    return repo", "def get_repo(path=PROJECT_PATH, search_parent_directories=True):\n    repo = git.Repo(path, search_parent_directories=search_parent_directories)\n    return repo\n\n\ndef get_git_rev(*args, **kwargs):\n    try:\n        repo = get_repo(*args, **kwargs)\n        if repo.head.is_detached:\n            git_rev = repo.head.object.name_rev\n        else:\n            git_rev = repo.active_branch.commit.name_rev\n    except:\n        git_rev = None\n\n    return git_rev", "\n\ndef git_diff(*args, **kwargs):\n    repo = get_repo(*args, **kwargs)\n    diff = repo.git.diff()\n    return diff\n\n\ndef save_git_diff(savepath, *args, **kwargs):\n    diff = git_diff(*args, **kwargs)\n    with open(savepath, \"w\") as f:\n        f.write(diff)", "def save_git_diff(savepath, *args, **kwargs):\n    diff = git_diff(*args, **kwargs)\n    with open(savepath, \"w\") as f:\n        f.write(diff)\n\n\nif __name__ == \"__main__\":\n    git_rev = get_git_rev()\n    print(git_rev)\n\n    save_git_diff(\"diff_test.txt\")", ""]}
{"filename": "src/lcd/utils/setup.py", "chunked_list": ["import datetime\nimport importlib\nimport inspect\nimport os\nimport pdb\nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport torch", "import numpy as np\nimport torch\nfrom tap import Tap\n\nfrom .git_utils import get_git_rev, save_git_diff\nfrom .serialization import mkdir\n\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)", "def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n\ndef abspath():\n    # https://stackoverflow.com/questions/16771894/python-nameerror-global-name-file-is-not-defined\n    # https://docs.python.org/3/library/inspect.html#inspect.FrameInfo\n    # return os.path.dirname(inspect.stack()[1][1]) # type: ignore\n    # return os.path.dirname(getsourcefile(lambda:0)) # type: ignore\n    return Path(inspect.getsourcefile(inspect.stack()[1][0])).parent  # type: ignore", "\n\ndef watch(args_to_watch):\n    def _fn(args):\n        exp_name = []\n        for key, label in args_to_watch:\n            if not hasattr(args, key):\n                continue\n            val = getattr(args, key)\n            if type(val) == dict:\n                val = \"_\".join(f\"{k}-{v}\" for k, v in val.items())\n            exp_name.append(f\"{label}{val}\")\n        exp_name = \"_\".join(exp_name)\n        exp_name = exp_name.replace(\"/_\", \"/\")\n        exp_name = exp_name.replace(\"(\", \"\").replace(\")\", \"\")\n        exp_name = exp_name.replace(\", \", \"-\")\n        return exp_name\n\n    return _fn", "\n\ndef lazy_fstring(template, args):\n    ## https://stackoverflow.com/a/53671539\n    return eval(f\"f'{template}'\")\n\n\nclass Parser(Tap):\n    def save(self):\n        fullpath = os.path.join(self.savepath, \"args.json\")\n        print(f\"[ utils/setup ] Saved args to {fullpath}\")\n        super().save(fullpath, skip_unpicklable=True)\n\n    def parse_args(self, experiment=None):\n        args = super().parse_args(known_only=True)\n        ## if not loading from a config script, skip the result of the setup\n        if not hasattr(args, \"config\"):\n            return args\n        args = self.read_config(args, experiment)\n        self.add_extras(args)\n        self.eval_fstrings(args)\n        self.set_seed(args)\n        self.get_commit(args)\n        self.set_loadbase(args)\n        self.generate_exp_name(args)\n        self.mkdir(args)\n        self.save_diff(args)\n        return args\n\n    def read_config(self, args, experiment):\n        \"\"\"\n        Load parameters from config file\n        \"\"\"\n        print(f\"[ utils/setup ] Reading config: {args.config}\")\n        module = importlib.import_module(args.config)\n        params = getattr(module, \"base\")[experiment]\n\n        self._dict = {}\n        for key, val in params.items():\n            setattr(args, key, val)\n            self._dict[key] = val\n\n        return args\n\n    def add_extras(self, args):\n        \"\"\"\n        Override config parameters with command-line arguments\n        \"\"\"\n        extras = args.extra_args\n        if not len(extras):\n            return\n\n        print(f\"[ utils/setup ] Found extras: {extras}\")\n        assert (\n            len(extras) % 2 == 0\n        ), f\"Found odd number ({len(extras)}) of extras: {extras}\"\n        for i in range(0, len(extras), 2):\n            key = extras[i].replace(\"--\", \"\")\n            val = extras[i + 1]\n            assert hasattr(\n                args, key\n            ), f\"[ utils/setup ] {key} not found in config: {args.config}\"\n            old_val = getattr(args, key)\n            old_type = type(old_val)\n            print(f\"[ utils/setup ] Overriding config | {key} : {old_val} --> {val}\")\n            if val == \"None\":\n                val = None\n            elif val == \"latest\":\n                val = \"latest\"\n            elif old_type in [bool, type(None)]:\n                try:\n                    val = eval(val)\n                except:\n                    print(\n                        f\"[ utils/setup ] Warning: could not parse {val} (old: {old_val}, {old_type}), using str\"\n                    )\n            else:\n                val = old_type(val)\n            setattr(args, key, val)\n            self._dict[key] = val\n\n    def eval_fstrings(self, args):\n        for key, old in self._dict.items():\n            if type(old) is str and old[:2] == \"f:\":\n                val = old.replace(\"{\", \"{args.\").replace(\"f:\", \"\")\n                new = lazy_fstring(val, args)\n                print(f\"[ utils/setup ] Lazy fstring | {key} : {old} --> {new}\")\n                setattr(self, key, new)\n                self._dict[key] = new\n\n    def set_seed(self, args):\n        if not hasattr(args, \"seed\") or args.seed is None:\n            return\n        print(f\"[ utils/setup ] Setting seed: {args.seed}\")\n        set_seed(args.seed)\n\n    def set_loadbase(self, args):\n        if hasattr(args, \"loadbase\") and args.loadbase is None:\n            print(f\"[ utils/setup ] Setting loadbase: {args.logbase}\")\n            args.loadbase = args.logbase\n\n    def generate_exp_name(self, args):\n        if not \"exp_name\" in dir(args):\n            return\n        exp_name = getattr(args, \"exp_name\")\n        if callable(exp_name):\n            exp_name_string = exp_name(args)\n            print(f\"[ utils/setup ] Setting exp_name to: {exp_name_string}\")\n            setattr(args, \"exp_name\", exp_name_string)\n            self._dict[\"exp_name\"] = exp_name_string\n\n    def mkdir(self, args):\n        from lcd import REPO_PATH\n\n        if \"logbase\" in dir(args) and \"exp_name\" in dir(args):\n            datestr = datetime.datetime.now().strftime(\"%m-%d_%H:%M:%S\")\n            args.savepath = os.path.join(\n                str(REPO_PATH), args.logbase, args.exp_name, datestr\n            )\n            self._dict[\"savepath\"] = args.savepath\n            if \"suffix\" in dir(args):\n                args.savepath = os.path.join(args.savepath, args.suffix)\n            if mkdir(args.savepath):\n                print(f\"[ utils/setup ] Made savepath: {args.savepath}\")\n            self.savepath = args.savepath\n            self.save()\n\n    def get_commit(self, args):\n        args.commit = get_git_rev()\n\n    def save_diff(self, args):\n        try:\n            save_git_diff(os.path.join(args.savepath, \"diff.txt\"))\n        except:\n            print(\"[ utils/setup ] WARNING: did not save git diff\")", ""]}
{"filename": "src/lcd/utils/serialization.py", "chunked_list": ["import glob\nimport os\nimport pdb\nimport pickle\nfrom collections import namedtuple\n\nimport torch\n\nDiffusion = namedtuple(\n    \"Diffusion\", \"dataset renderer model diffusion ema trainer epoch\"", "Diffusion = namedtuple(\n    \"Diffusion\", \"dataset renderer model diffusion ema trainer epoch\"\n)\n\n\ndef mkdir(savepath):\n    \"\"\"\n    returns `True` iff `savepath` is created\n    \"\"\"\n    if not os.path.exists(savepath):\n        os.makedirs(savepath)\n        return True\n    else:\n        return False", "\n\ndef get_latest_epoch(loadpath):\n    states = glob.glob1(os.path.join(*loadpath), \"state_*\")\n    latest_epoch = -1\n    for state in states:\n        epoch = int(state.replace(\"state_\", \"\").replace(\".pt\", \"\"))\n        latest_epoch = max(epoch, latest_epoch)\n    return latest_epoch\n", "\n\ndef load_config(*loadpath):\n    loadpath: str = os.path.join(*loadpath)\n    config = pickle.load(open(loadpath, \"rb\"))\n    print(f\"[ utils/serialization ] Loaded config from {loadpath}\")\n    print(config)\n    return config\n\n\ndef load_diffusion(*loadpath, epoch=\"latest\", device=\"cuda:0\", seed=None):\n    dataset_config = load_config(*loadpath, \"dataset_config.pkl\")\n    render_config = load_config(*loadpath, \"render_config.pkl\")\n    model_config = load_config(*loadpath, \"model_config.pkl\")\n    diffusion_config = load_config(*loadpath, \"diffusion_config.pkl\")\n    trainer_config = load_config(*loadpath, \"trainer_config.pkl\")\n\n    trainer_config._dict[\"results_folder\"] = os.path.join(*loadpath)\n\n    dataset = dataset_config(seed=seed)\n    renderer = render_config()\n    model = model_config()\n    diffusion = diffusion_config(model)\n    trainer = trainer_config(diffusion, dataset, renderer)\n\n    if epoch == \"latest\":\n        epoch = get_latest_epoch(loadpath)\n\n    print(f\"\\n[ utils/serialization ] Loading model epoch: {epoch}\\n\")\n\n    trainer.load(epoch)\n\n    return Diffusion(\n        dataset, renderer, model, diffusion, trainer.ema_model, trainer, epoch\n    )", "\n\ndef load_diffusion(*loadpath, epoch=\"latest\", device=\"cuda:0\", seed=None):\n    dataset_config = load_config(*loadpath, \"dataset_config.pkl\")\n    render_config = load_config(*loadpath, \"render_config.pkl\")\n    model_config = load_config(*loadpath, \"model_config.pkl\")\n    diffusion_config = load_config(*loadpath, \"diffusion_config.pkl\")\n    trainer_config = load_config(*loadpath, \"trainer_config.pkl\")\n\n    trainer_config._dict[\"results_folder\"] = os.path.join(*loadpath)\n\n    dataset = dataset_config(seed=seed)\n    renderer = render_config()\n    model = model_config()\n    diffusion = diffusion_config(model)\n    trainer = trainer_config(diffusion, dataset, renderer)\n\n    if epoch == \"latest\":\n        epoch = get_latest_epoch(loadpath)\n\n    print(f\"\\n[ utils/serialization ] Loading model epoch: {epoch}\\n\")\n\n    trainer.load(epoch)\n\n    return Diffusion(\n        dataset, renderer, model, diffusion, trainer.ema_model, trainer, epoch\n    )", "\n\ndef check_compatibility(experiment_1, experiment_2):\n    \"\"\"\n    returns True if `experiment_1 and `experiment_2` have\n    the same normalizers and number of diffusion steps\n    \"\"\"\n    normalizers_1 = experiment_1.dataset.normalizer.get_field_normalizers()\n    normalizers_2 = experiment_2.dataset.normalizer.get_field_normalizers()\n    for key in normalizers_1:\n        norm_1 = type(normalizers_1[key])\n        norm_2 = type(normalizers_2[key])\n        assert (\n            norm_1 == norm_2\n        ), f\"Normalizers should be identical, found {norm_1} and {norm_2} for field {key}\"\n\n    n_steps_1 = experiment_1.diffusion.n_timesteps\n    n_steps_2 = experiment_2.diffusion.n_timesteps\n    assert n_steps_1 == n_steps_2, (\n        \"Number of timesteps should match between diffusion experiments, \"\n        f\"found {n_steps_1} and {n_steps_2}\"\n    )", ""]}
{"filename": "src/lcd/utils/config.py", "chunked_list": ["import collections\nimport importlib\nimport os\nimport pickle\n\n\ndef import_class(_class):\n    if type(_class) is not str:\n        return _class\n    ## 'diffusion' on standard installs\n    repo_name = __name__.split(\".\")[0]\n    ## eg, 'utils'\n    module_name = \".\".join(_class.split(\".\")[:-1])\n    ## eg, 'Renderer'\n    class_name = _class.split(\".\")[-1]\n    ## eg, 'diffusion.utils'\n    module = importlib.import_module(f\"{repo_name}.{module_name}\")\n    ## eg, diffusion.utils.Renderer\n    _class = getattr(module, class_name)\n    print(f\"[ utils/config ] Imported {repo_name}.{module_name}:{class_name}\")\n    return _class", "\n\nclass AttriDict(dict):\n    \"\"\"\n    A dict which is accessible via attribute dot notation\n    https://stackoverflow.com/a/41514848\n    https://stackoverflow.com/a/14620633\n    \"\"\"\n\n    DICT_RESERVED_KEYS = list(vars(dict).keys())\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        :param args: multiple dicts ({}, {}, ..)\n        :param kwargs: arbitrary keys='value'\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.__dict__ = self\n\n    def __getattr__(self, attr):\n        if attr not in AttriDict.DICT_RESERVED_KEYS:\n            return self.get(attr)\n        return getattr(self, attr)\n\n    def __setattr__(self, key, value):\n        if key == \"__dict__\":\n            super().__setattr__(key, value)\n            return\n        if key in AttriDict.DICT_RESERVED_KEYS:\n            raise AttributeError(\"You cannot set a reserved name as attribute\")\n        self.__setitem__(key, value)\n\n    def __copy__(self):\n        return self.__class__(self)\n\n    def copy(self):\n        return self.__copy__()", "\n\nclass Config(collections.abc.Mapping):  # type: ignore\n    def __init__(self, _class, verbose=True, savepath=None, device=None, **kwargs):\n        self._class = import_class(_class)\n        self._device = device\n        self._dict = {}\n\n        for key, val in kwargs.items():\n            self._dict[key] = val\n\n        if verbose:\n            print(self)\n\n        if savepath is not None:\n            savepath = os.path.join(*savepath) if type(savepath) is tuple else savepath\n            pickle.dump(self, open(savepath, \"wb\"))\n            print(f\"[ utils/config ] Saved config to: {savepath}\\n\")\n\n    def __repr__(self):\n        string = f\"\\n[utils/config ] Config: {self._class}\\n\"\n        for key in sorted(self._dict.keys()):\n            val = self._dict[key]\n            string += f\"    {key}: {val}\\n\"\n        return string\n\n    def __iter__(self):\n        return iter(self._dict)\n\n    def __getitem__(self, item):\n        return self._dict[item]\n\n    def __len__(self):\n        return len(self._dict)\n\n    def __getattr__(self, attr):\n        if attr == \"_dict\" and \"_dict\" not in vars(self):\n            self._dict = {}\n            return self._dict\n        try:\n            return self._dict[attr]\n        except KeyError:\n            raise AttributeError(attr)\n\n    def __call__(self, *args, **kwargs):\n        instance = self._class(*args, **kwargs, **self._dict)\n        if self._device:\n            instance = instance.to(self._device)\n        return instance", ""]}
{"filename": "src/lcd/utils/__init__.py", "chunked_list": ["from .arrays import *\nfrom .config import *\nfrom .serialization import *\nfrom .setup import *\nfrom .training import *\n"]}
{"filename": "src/lcd/utils/eval.py", "chunked_list": ["# originally taken from https://github.com/lukashermann/hulc/blob/fb14d5461ae54f919d52c0c30131b38f806ef8db/hulc/evaluation/evaluate_policy.py and adapted for hierarchical imitation learning and data collection\nimport gc\nimport json\nimport os\nimport sys\nimport time\nfrom collections import Counter\nfrom datetime import datetime\nfrom pathlib import Path\n", "from pathlib import Path\n\nimport hydra\nimport numpy as np\nimport torch\nfrom hulc.evaluation.utils import get_env_state_for_initial_condition, join_vis_lang\nfrom loguru import logger\nfrom omegaconf import OmegaConf\nfrom tqdm import tqdm\n", "from tqdm import tqdm\n\nimport lcd\nfrom lcd import DATA_PATH, HULC_PATH, REPO_PATH\nfrom lcd.utils.serialization import load_config\n\n\nclass DiffusionModelWrapper(torch.nn.Module):\n    def __init__(\n        self, device=\"cpu\", model_path__epoch=(None, None), model__args=(None, None)\n    ) -> None:\n        \"\"\"\n        Wrapper for the LCD diffusion model to use during evaluation.\n        Can either take in model directly through model__args or load from the filesystem with model_path__epoch\n        \"\"\"\n        super().__init__()\n        model_path, epoch, model, args = (*model_path__epoch, *model__args)\n\n        assert model_path or model, \"Need to specify either model_path or model\"\n\n        if model_path:\n            sys.modules[\"diffuser\"] = lcd\n            model_config = load_config(model_path, \"model_config.pkl\")\n            diffusion_config = load_config(model_path, \"diffusion_config.pkl\")\n            init_hulc_goal_state_dicts = torch.load(\n                os.path.join(model_path, f\"state_{epoch}.pt\"), map_location=\"cpu\"\n            )\n            model = model_config()\n            diffusion = diffusion_config(model)\n            diffusion.load_state_dict(init_hulc_goal_state_dicts[\"ema\"])\n            self.model = diffusion\n            self.args = json.load(open(f\"{model_path}/args.json\"))\n        else:\n            self.model = model\n            self.args = args\n\n        self.model.to(device)\n\n    def forward(self, cond, inpaint):\n        samples = self.model.conditional_sample(\n            cond, horizon=1, inpaint={0: inpaint}\n        ).trajectories\n        return samples[:, :, :32].squeeze(dim=1)", "\n\ndef get_sequences(args, regenerate=False):\n    if regenerate:\n        from hulc.evaluation.multistep_sequences import get_sequences\n\n        # this takes a few minutes\n        return get_sequences(args.num_sequences)\n    else:\n        return torch.load(DATA_PATH / \"default_1000_sequences.pt\")[: args.num_sequences]", "\n\ndef count_success(results):\n    count = Counter(results)\n    step_success = []\n    for i in range(1, 6):\n        n_success = sum(count[j] for j in reversed(range(i, 6)))\n        sr = n_success / len(results)\n        step_success.append(sr)\n    return step_success", "\n\ndef get_log_dir(log_dir):\n    log_dir = Path(log_dir) if log_dir is not None else REPO_PATH / \"results\"\n    if not log_dir.exists():\n        log_dir.mkdir()\n    print(f\"logging to {log_dir}\")\n    return log_dir\n\n\ndef print_and_save(results, args, histories, model_id):\n    def get_task_success_rate(results, sequences):\n        cnt_success = Counter()\n        cnt_fail = Counter()\n\n        for result, (_, sequence) in zip(results, sequences):\n            for successful_tasks in sequence[:result]:\n                cnt_success[successful_tasks] += 1\n            if result < len(sequence):\n                failed_task = sequence[result]\n                cnt_fail[failed_task] += 1\n\n        total = cnt_success + cnt_fail\n        task_info = {}\n        for task in total:\n            task_info[task] = {\"success\": cnt_success[task], \"total\": total[task]}\n            print(\n                f\"{task}: {cnt_success[task]} / {total[task]} |  SR: {cnt_success[task] / total[task] * 100:.1f}%\"\n            )\n        return task_info\n\n    log_dir = get_log_dir(args.log_dir)\n\n    sequences = get_sequences(args)\n    if args.generate:\n        Path(log_dir / \"rollouts\").mkdir(\n            exist_ok=True, parents=True\n        )  # create rollouts folder if it doesn't exist\n        torch.save(\n            histories,\n            log_dir\n            / f\"rollouts/{model_id}_gen_history_{datetime.now().strftime('%d-%m-%Y-%H:%M:%S')}.pt\",\n        )\n\n    current_data = {}\n    # epoch = checkpoint.stem\n    print(f\"Results for Model {model_id}:\")\n    avg_seq_len = np.mean(results)\n    chain_sr = {i + 1: sr for i, sr in enumerate(count_success(results))}\n    print(f\"Average successful sequence length: {avg_seq_len}\")\n    print(\"Success rates for i instructions in a row:\")\n    for i, sr in chain_sr.items():\n        print(f\"{i}: {sr * 100:.1f}%\")\n\n    data = {\n        \"avg_seq_len\": avg_seq_len,\n        \"chain_sr\": chain_sr,\n        \"task_info\": get_task_success_rate(results, sequences),\n    }\n\n    current_data[model_id] = data\n    previous_data = {}\n\n    try:\n        with open(log_dir / \"results.json\") as file:\n            previous_data = json.load(file)\n    except FileNotFoundError:\n        pass\n    json_data = {**previous_data, **current_data}\n    with open(log_dir / \"results.json\", \"w\") as file:\n        json.dump(json_data, file)\n    return data", "\n\ndef print_and_save(results, args, histories, model_id):\n    def get_task_success_rate(results, sequences):\n        cnt_success = Counter()\n        cnt_fail = Counter()\n\n        for result, (_, sequence) in zip(results, sequences):\n            for successful_tasks in sequence[:result]:\n                cnt_success[successful_tasks] += 1\n            if result < len(sequence):\n                failed_task = sequence[result]\n                cnt_fail[failed_task] += 1\n\n        total = cnt_success + cnt_fail\n        task_info = {}\n        for task in total:\n            task_info[task] = {\"success\": cnt_success[task], \"total\": total[task]}\n            print(\n                f\"{task}: {cnt_success[task]} / {total[task]} |  SR: {cnt_success[task] / total[task] * 100:.1f}%\"\n            )\n        return task_info\n\n    log_dir = get_log_dir(args.log_dir)\n\n    sequences = get_sequences(args)\n    if args.generate:\n        Path(log_dir / \"rollouts\").mkdir(\n            exist_ok=True, parents=True\n        )  # create rollouts folder if it doesn't exist\n        torch.save(\n            histories,\n            log_dir\n            / f\"rollouts/{model_id}_gen_history_{datetime.now().strftime('%d-%m-%Y-%H:%M:%S')}.pt\",\n        )\n\n    current_data = {}\n    # epoch = checkpoint.stem\n    print(f\"Results for Model {model_id}:\")\n    avg_seq_len = np.mean(results)\n    chain_sr = {i + 1: sr for i, sr in enumerate(count_success(results))}\n    print(f\"Average successful sequence length: {avg_seq_len}\")\n    print(\"Success rates for i instructions in a row:\")\n    for i, sr in chain_sr.items():\n        print(f\"{i}: {sr * 100:.1f}%\")\n\n    data = {\n        \"avg_seq_len\": avg_seq_len,\n        \"chain_sr\": chain_sr,\n        \"task_info\": get_task_success_rate(results, sequences),\n    }\n\n    current_data[model_id] = data\n    previous_data = {}\n\n    try:\n        with open(log_dir / \"results.json\") as file:\n            previous_data = json.load(file)\n    except FileNotFoundError:\n        pass\n    json_data = {**previous_data, **current_data}\n    with open(log_dir / \"results.json\", \"w\") as file:\n        json.dump(json_data, file)\n    return data", "\n\ndef evaluate_policy(state, args):\n    conf_dir = HULC_PATH / \"conf\"\n    task_cfg = OmegaConf.load(\n        conf_dir / \"callbacks/rollout/tasks/new_playtable_tasks.yaml\"\n    )\n    task_oracle = hydra.utils.instantiate(task_cfg)\n    val_annotations = OmegaConf.load(\n        conf_dir / \"annotations/new_playtable_validation.yaml\"\n    )\n\n    eval_sequences = get_sequences(args)\n    if not args.debug:\n        eval_sequences = tqdm(eval_sequences, position=0, leave=True)\n\n    results = []\n    histories = []\n    for initial_state, eval_sequence in eval_sequences:\n        robot_obs, scene_obs = get_env_state_for_initial_condition(initial_state)\n        state.env.reset(robot_obs=robot_obs, scene_obs=scene_obs)\n\n        success_counter = 0\n        history = []\n\n        if args.debug:\n            time.sleep(1)\n            print()\n            print()\n            print(f\"Evaluating sequence: {' -> '.join(eval_sequence)}\")\n            print(\"Subtask: \", end=\"\")\n        for subtask in eval_sequence:\n            success, info = rollout(\n                state.env,\n                state.model,\n                task_oracle,\n                args,\n                subtask,\n                state.lang_embeddings,\n                val_annotations,\n            )\n            if success:\n                success_counter += 1\n                history.append(info)\n            else:\n                break\n\n        histories.append(history)\n        results.append(success_counter)\n        if not args.debug:\n            eval_sequences.set_description(\n                \" \".join(\n                    [\n                        f\"{i + 1}/5 : {v * 100:.1f}% |\"\n                        for i, v in enumerate(count_success(results))\n                    ]\n                )\n                + \"|\"\n            )\n\n    return results, histories", "\n\ndef rollout(env, model, task_oracle, args, subtask, lang_embeddings, val_annotations):\n    if args.debug:\n        print(f\"{subtask} \", end=\"\")\n        time.sleep(0.5)\n    if args.generate:\n        states = []\n        actions = []\n        scene_info = []\n\n    obs = env.get_obs()\n    # get lang annotation for subtask\n    lang_annotation = val_annotations[subtask][0]\n\n    if args.dm is not None:\n        model.replan_freq = args.subgoal_interval\n        current_state = model.get_pp_plan_vision(obs, obs)[-1]\n        lang_goal = lang_embeddings[lang_annotation].to(args.device)\n        goal = {\"lang\": args.dm(lang_goal[None], current_state)}\n    else:\n        goal = lang_embeddings.get_lang_goal(lang_annotation)\n        plan, latent_goal = model.get_pp_plan_lang(obs, goal)\n\n    model.reset()\n    start_info = current_info = env.get_info()\n    success_step = 0\n    success = False\n\n    for step in range(args.ep_len):\n        if (\n            success_step and step == success_step + 4\n        ):  # record four states past the successful state\n            break\n        if args.dm is not None:\n            if not (step % args.subgoal_interval):\n                current_state = (\n                    model.visual_goal(\n                        model.perceptual_encoder(obs[\"rgb_obs\"], {}, None)\n                    )\n                    .squeeze()\n                    .cpu()\n                )\n                goal = {\"lang\": args.dm(lang_goal[None], current_state)}\n\n        action = model.step(obs, goal, direct=args.dm is not None)\n\n        if args.generate:\n            states.append(\n                model.visual_goal(model.perceptual_encoder(obs[\"rgb_obs\"], {}, None))\n                .squeeze()\n                .cpu()\n            )\n            scene_info.append(current_info)\n            actions.append(action.squeeze().cpu())\n\n        obs, _, _, current_info = env.step(action)\n\n        if args.debug:\n            img = env.render(mode=\"rgb_array\")\n            join_vis_lang(img, lang_annotation)\n            # time.sleep(0.1)\n        # check if current step solves a task\n        current_task_info = task_oracle.get_task_info_for_set(\n            start_info, current_info, {subtask}\n        )\n        if len(current_task_info) > 0 and not success:\n            if args.debug:\n                logger.info(\"<green>Success</green>\")\n            success = True\n            success_step = step\n\n    if args.debug and not success:\n        logger.info(\"<red>Fail</red>\")\n\n    if not args.generate:\n        return success, {}\n    else:\n        gc.collect()\n        torch.cuda.empty_cache()\n        return success, {\n            \"states\": torch.stack(states).cpu().detach(),\n            \"actions\": torch.stack(actions).cpu().detach(),\n            \"goal_lang\": goal[\"lang\"].cpu().detach().squeeze(),\n            \"goal_task\": subtask,\n            \"scene_info\": scene_info,\n        }", ""]}
{"filename": "src/lcd/utils/timer.py", "chunked_list": ["import time\n\n\nclass Timer:\n    def __init__(self):\n        self._start = time.time()\n\n    def __call__(self, reset=True):\n        now = time.time()\n        diff = now - self._start\n        if reset:\n            self._start = now\n        return diff", ""]}
{"filename": "src/lcd/utils/training.py", "chunked_list": ["import copy\nimport os\nimport pdb\n\nimport einops\nimport numpy as np\nimport torch\nimport tqdm\n\nimport wandb", "\nimport wandb\nfrom lcd.datasets.sequence import Batch\n\nfrom .arrays import batch_to_device\nfrom .timer import Timer\n\n\ndef cycle(dl):\n    while True:\n        yield from dl", "def cycle(dl):\n    while True:\n        yield from dl\n\n\ndef wlog(*args, **kwargs):\n    if wandb.run is not None:\n        wandb.log(*args, **kwargs)\n\n\nclass EMA:\n    \"\"\"\n    empirical moving average\n    \"\"\"\n\n    def __init__(self, beta):\n        super().__init__()\n        self.beta = beta\n\n    def update_model_average(self, ma_model, current_model):\n        for current_params, ma_params in zip(\n            current_model.parameters(), ma_model.parameters()\n        ):\n            old_weight, up_weight = ma_params.data, current_params.data\n            ma_params.data = self.update_average(old_weight, up_weight)\n\n    def update_average(self, old, new):\n        if old is None:\n            return new\n        return old * self.beta + (1 - self.beta) * new", "\n\nclass EMA:\n    \"\"\"\n    empirical moving average\n    \"\"\"\n\n    def __init__(self, beta):\n        super().__init__()\n        self.beta = beta\n\n    def update_model_average(self, ma_model, current_model):\n        for current_params, ma_params in zip(\n            current_model.parameters(), ma_model.parameters()\n        ):\n            old_weight, up_weight = ma_params.data, current_params.data\n            ma_params.data = self.update_average(old_weight, up_weight)\n\n    def update_average(self, old, new):\n        if old is None:\n            return new\n        return old * self.beta + (1 - self.beta) * new", "\n\nclass Trainer:\n    def __init__(\n        self,\n        diffusion_model,\n        dataset,\n        ema_decay=0.995,\n        train_batch_size=32,\n        train_lr=2e-5,\n        gradient_accumulate_every=2,\n        step_start_ema=2000,\n        update_ema_every=10,\n        log_freq=100,\n        sample_freq=1000,\n        save_freq=1000,\n        label_freq=100000,\n        save_parallel=False,\n        results_folder=\"./results\",\n        n_reference=8,\n        bucket=None,\n    ):\n        super().__init__()\n        self.model = diffusion_model\n        self.ema = EMA(ema_decay)\n        self.ema_model = copy.deepcopy(self.model)\n        self.update_ema_every = update_ema_every\n\n        self.step_start_ema = step_start_ema\n        self.log_freq = log_freq\n        self.sample_freq = sample_freq\n        self.save_freq = save_freq\n        self.label_freq = label_freq\n        self.save_parallel = save_parallel\n\n        self.batch_size = train_batch_size\n        self.gradient_accumulate_every = gradient_accumulate_every\n\n        self.dataset = dataset\n        self.dataloader = cycle(\n            torch.utils.data.DataLoader(\n                self.dataset,\n                batch_size=train_batch_size,\n                num_workers=1,\n                shuffle=True,\n                pin_memory=True,\n            )\n        )\n        self.dataloader_vis = cycle(\n            torch.utils.data.DataLoader(\n                self.dataset, batch_size=1, num_workers=0, shuffle=True, pin_memory=True\n            )\n        )\n        self.optimizer = torch.optim.Adam(diffusion_model.parameters(), lr=train_lr)\n\n        self.logdir = results_folder\n        self.bucket = bucket\n        self.n_reference = n_reference\n\n        self.reset_parameters()\n        self.step = 0\n\n    def reset_parameters(self):\n        self.ema_model.load_state_dict(self.model.state_dict())\n\n    def step_ema(self):\n        if self.step < self.step_start_ema:\n            self.reset_parameters()\n            return\n        self.ema.update_model_average(self.ema_model, self.model)\n\n    # -----------------------------------------------------------------------------#\n    # ------------------------------------ api ------------------------------------#\n    # -----------------------------------------------------------------------------#\n\n    def train(self, n_train_steps):\n        timer = Timer()\n        for step in tqdm.tqdm(range(n_train_steps)):\n            for i in range(self.gradient_accumulate_every):\n                batch = next(self.dataloader)\n                batch = batch_to_device(batch)\n\n                if isinstance(batch, Batch):\n                    loss, infos = self.model.loss(*batch)\n                else:\n                    loss, infos = self.model.loss(*batch[0], **batch[1])\n                loss = loss / self.gradient_accumulate_every\n                loss.backward()\n\n            wlog({\"loss\": loss, **infos})\n\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n\n            if self.step % self.update_ema_every == 0:\n                self.step_ema()\n\n            if self.step % self.save_freq == 0:\n                self.save(self.step)\n\n            if self.step % self.log_freq == 0:\n                infos_str = \" | \".join(\n                    [f\"{key}: {val:8.4f}\" for key, val in infos.items()]\n                )\n                print(\n                    f\"{self.step}: {loss:8.4f} | {infos_str} | t: {timer():8.4f}\",\n                    flush=True,\n                )\n\n            if self.sample_freq and self.step % self.sample_freq == 0:\n                samples = self.ema_model.conditional_sample(\n                    batch[0][1], horizon=1, **batch[1]\n                ).trajectories\n                l1 = (samples[:, :, :32] - batch[0][0][:, :, :32]).abs()\n                wlog({\"generation_mae_mean\": l1.mean(), \"generation_mae_std\": l1.std()})\n\n            self.step += 1\n\n    def save(self, epoch):\n        \"\"\"\n        saves model and ema to disk;\n        syncs to storage bucket if a bucket is specified\n        \"\"\"\n        data = {\n            \"step\": self.step,\n            \"model\": self.model.state_dict(),\n            \"ema\": self.ema_model.state_dict(),\n        }\n        savepath = os.path.join(self.logdir, f\"state_{epoch}.pt\")\n        torch.save(data, savepath)\n        torch.save(self.ema_model, os.path.join(self.logdir, f\"model_{epoch}.pt\"))\n        print(f\"[ utils/training ] Saved model to {savepath}\", flush=True)\n\n    def load(self, epoch):\n        \"\"\"\n        loads model and ema from disk\n        \"\"\"\n        loadpath = os.path.join(self.logdir, f\"state_{epoch}.pt\")\n        data = torch.load(loadpath)\n\n        self.step = data[\"step\"]\n        self.model.load_state_dict(data[\"model\"])\n        self.ema_model.load_state_dict(data[\"ema\"])", ""]}
{"filename": "src/lcd/utils/arrays.py", "chunked_list": ["import collections\nimport pdb\n\nimport numpy as np\nimport torch\n\nDTYPE = torch.float\nDEVICE = \"cuda:0\"\n\n# -----------------------------------------------------------------------------#", "\n# -----------------------------------------------------------------------------#\n# ------------------------------ numpy <--> torch -----------------------------#\n# -----------------------------------------------------------------------------#\n\n\ndef to_np(x):\n    if torch.is_tensor(x):\n        x = x.detach().cpu().numpy()\n    return x", "\n\ndef to_torch(x, dtype=None, device=None):\n    dtype = dtype or DTYPE\n    device = device or DEVICE\n    if type(x) is dict:\n        return {k: to_torch(v, dtype, device) for k, v in x.items()}\n    elif torch.is_tensor(x):\n        return x.to(device).type(dtype)\n    return torch.tensor(x, dtype=dtype, device=device)", "\n\ndef to_device(x, device=DEVICE):\n    if torch.is_tensor(x):\n        return x.to(device)\n    elif type(x) is dict:\n        return {k: to_device(v, device) for k, v in x.items()}\n    elif isinstance(x, tuple):\n        return tuple(to_device(v, device) for v in x)\n    elif isinstance(x, list):\n        return [to_device(v, device) for v in x]\n    else:\n        raise RuntimeError(f\"Unrecognized type in `to_device`: {type(x)}\")", "\n\ndef apply_dict(fn, d, *args, **kwargs):\n    return {k: fn(v, *args, **kwargs) for k, v in d.items()}\n\n\ndef set_device(device):\n    if \"cuda\" in device:\n        torch.set_default_tensor_type(torch.cuda.FloatTensor)  # type: ignore\n", "\n\ndef batch_to_device(batch, device=\"cuda:0\"):\n    vals = [to_device(getattr(batch, field), device) for field in batch._fields]\n    return type(batch)(*vals)\n\n\ndef _to_str(num):\n    if num >= 1e6:\n        return f\"{(num/1e6):.2f} M\"\n    else:\n        return f\"{(num/1e3):.2f} k\"", "\n\n# -----------------------------------------------------------------------------#\n# ----------------------------- parameter counting ----------------------------#\n# -----------------------------------------------------------------------------#\n\n\ndef param_to_module(param):\n    module_name = param[::-1].split(\".\", maxsplit=1)[-1][::-1]\n    return module_name", "\n\ndef report_parameters(model, topk=10):\n    counts = {k: p.numel() for k, p in model.named_parameters()}\n    n_parameters = sum(counts.values())\n    print(f\"[ utils/arrays ] Total parameters: {_to_str(n_parameters)}\")\n\n    modules = dict(model.named_modules())\n    sorted_keys = sorted(counts, key=lambda x: -counts[x])  # type: ignore\n    max_length = max([len(k) for k in sorted_keys])\n    for i in range(topk):\n        key = sorted_keys[i]\n        count = counts[key]\n        module = param_to_module(key)\n        print(\" \" * 8, f\"{key:10}: {_to_str(count)} | {modules[module]}\")\n\n    remaining_parameters = sum([counts[k] for k in sorted_keys[topk:]])\n    print(\n        \" \" * 8,\n        f\"... and {len(counts)-topk} others accounting for {_to_str(remaining_parameters)} parameters\",\n    )\n    return n_parameters", ""]}
{"filename": "src/lcd/scripts/diffuser.py", "chunked_list": ["import os\n\nimport torch\n\nimport lcd.utils as utils\nimport wandb\nfrom lcd import DATA_PATH\nfrom lcd.apps import rollout\nfrom lcd.datasets.sequence import Batch\nfrom lcd.utils.arrays import batch_to_device", "from lcd.datasets.sequence import Batch\nfrom lcd.utils.arrays import batch_to_device\nfrom lcd.utils.training import cycle\n\nscript_dir = os.path.dirname(os.path.realpath(__file__))\n# -----------------------------------------------------------------------------#\n# ----------------------------------- setup -----------------------------------#\n# -----------------------------------------------------------------------------#\n\n\nclass Parser(utils.Parser):\n    config: str = \"lcd.config.calvin\"", "\n\nclass Parser(utils.Parser):\n    config: str = \"lcd.config.calvin\"\n\n\nargs = Parser().parse_args(\"diffusion\")\nargs.dim_mults = tuple(int(i) for i in args.dim_mults)\n\n# -----------------------------------------------------------------------------#", "\n# -----------------------------------------------------------------------------#\n# ---------------------------------- dataset ----------------------------------#\n# -----------------------------------------------------------------------------#\n\ndataset_config = utils.Config(\n    args.loader,\n    savepath=(args.savepath, \"dataset_config.pkl\"),\n    horizon=args.horizon,\n    normalizer=args.normalizer,", "    horizon=args.horizon,\n    normalizer=args.normalizer,\n    preprocess_fns=args.preprocess_fns,\n    use_padding=args.use_padding,\n    max_path_length=args.max_path_length,\n    frame_offset=args.frame_offset,\n    lang_embeds=DATA_PATH / \"t5-v1_1-xxl_embeddings.pt\",\n    task_to_ann=DATA_PATH / \"annotations.json\",\n    buf=DATA_PATH / f\"hulc-trajectories/{args.seed}_all_trajectories.pt\",\n    observation_dim=args.observation_dim,", "    buf=DATA_PATH / f\"hulc-trajectories/{args.seed}_all_trajectories.pt\",\n    observation_dim=args.observation_dim,\n    action_dim=args.action_dim,\n)\n\ndataset = dataset_config()\n\nobservation_dim = dataset.observation_dim\naction_dim = dataset.action_dim\n", "action_dim = dataset.action_dim\n\n\n# -----------------------------------------------------------------------------#\n# ------------------------------ model & trainer ------------------------------#\n# -----------------------------------------------------------------------------#\n\nmodel_config = utils.Config(\n    args.model,\n    savepath=(args.savepath, \"model_config.pkl\"),", "    args.model,\n    savepath=(args.savepath, \"model_config.pkl\"),\n    horizon=args.horizon,\n    transition_dim=observation_dim + action_dim,\n    cond_dim=observation_dim,\n    dim_mults=args.dim_mults,\n    dim=args.model_dim,\n    attention=args.attention,\n    device=args.device,\n    downsample=args.downsample,", "    device=args.device,\n    downsample=args.downsample,\n)\n\ndiffusion_config = utils.Config(\n    args.diffusion,\n    savepath=(args.savepath, \"diffusion_config.pkl\"),\n    horizon=args.horizon,\n    observation_dim=observation_dim,\n    action_dim=action_dim,", "    observation_dim=observation_dim,\n    action_dim=action_dim,\n    n_timesteps=args.n_diffusion_steps,\n    loss_type=args.loss_type,\n    clip_denoised=args.clip_denoised,\n    predict_epsilon=args.predict_epsilon,\n    ## loss weighting\n    action_weight=args.action_weight,\n    loss_weights=args.loss_weights,\n    loss_discount=args.loss_discount,", "    loss_weights=args.loss_weights,\n    loss_discount=args.loss_discount,\n    device=args.device,\n)\n\ntrainer_config = utils.Config(\n    utils.Trainer,\n    savepath=(args.savepath, \"trainer_config.pkl\"),\n    train_batch_size=args.batch_size,\n    train_lr=args.learning_rate,", "    train_batch_size=args.batch_size,\n    train_lr=args.learning_rate,\n    gradient_accumulate_every=args.gradient_accumulate_every,\n    ema_decay=args.ema_decay,\n    sample_freq=args.sample_freq,\n    save_freq=args.save_freq,\n    label_freq=int(args.n_train_steps // args.n_saves),\n    save_parallel=args.save_parallel,\n    results_folder=args.savepath,\n    bucket=args.bucket,", "    results_folder=args.savepath,\n    bucket=args.bucket,\n    n_reference=args.n_reference,\n)\n\n# -----------------------------------------------------------------------------#\n# -------------------------------- instantiate --------------------------------#\n# -----------------------------------------------------------------------------#\n\nmodel = model_config()", "\nmodel = model_config()\n\ndiffusion = diffusion_config(model)\n\ntrainer = trainer_config(diffusion, dataset)\n\n\n# -----------------------------------------------------------------------------#\n# ------------------------ test forward & backward pass -----------------------#", "# -----------------------------------------------------------------------------#\n# ------------------------ test forward & backward pass -----------------------#\n# -----------------------------------------------------------------------------#\n\nutils.report_parameters(model)\nprint(\"Testing forward...\", end=\" \", flush=True)\ndataloader = cycle(torch.utils.data.DataLoader(dataset, batch_size=1, num_workers=0))\nbatch = batch_to_device(next(dataloader))\nif isinstance(batch, Batch):\n    loss, infos = diffusion.loss(*batch)\nelse:\n    loss, infos = diffusion.loss(*batch[0], **batch[1])", "if isinstance(batch, Batch):\n    loss, infos = diffusion.loss(*batch)\nelse:\n    loss, infos = diffusion.loss(*batch[0], **batch[1])\nloss.backward()\nprint(\"\u2713\")\n\n\n# -----------------------------------------------------------------------------#\n# --------------------------------- main loop ---------------------------------#", "# -----------------------------------------------------------------------------#\n# --------------------------------- main loop ---------------------------------#\n# -----------------------------------------------------------------------------#\n\nn_epochs = int(args.n_train_steps // args.n_steps_per_epoch)\n\nif args.wandb:\n    wandb.init(\n        project=\"vanilla-diffuser\",\n        entity=\"lang-diffusion\",\n        name=f\"hulc-{args.wandb_name}\",\n        config=vars(args),\n    )", "\n\ndef eval_model(num_evals, epoch=0):\n    rollout.main(seed=args.seed, num_sequences=num_evals)\n    dm_args = args.as_dict()\n    dm_args[\"epoch\"] = epoch\n    rollout.lcd(dm__args=(diffusion, dm_args))\n\n\nprint(\"Testing evaluation...\", end=\" \", flush=True)", "\nprint(\"Testing evaluation...\", end=\" \", flush=True)\neval_model(\n    num_evals=2,\n)\nprint(\"\u2713\")\n\n\nfor i in range(n_epochs):\n    print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n\n    trainer.train(n_train_steps=args.n_steps_per_epoch)\n    if not (i % args.eval_freq):\n        eval_model(\n            num_evals=args.n_evals_per_epoch,\n            epoch=args.n_steps_per_epoch * (i + 1),\n        )", "for i in range(n_epochs):\n    print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n\n    trainer.train(n_train_steps=args.n_steps_per_epoch)\n    if not (i % args.eval_freq):\n        eval_model(\n            num_evals=args.n_evals_per_epoch,\n            epoch=args.n_steps_per_epoch * (i + 1),\n        )\n", "\neval_model(\n    num_evals=1000,\n    epoch=args.n_steps_per_epoch * (i + 1),\n)\n"]}
{"filename": "src/lcd/scripts/generation/embeddings.py", "chunked_list": ["from typing import List\n\nimport json\n\nimport torch\nfrom einops import rearrange\nfrom transformers import T5EncoderModel, T5Tokenizer\n\nDEFAULT_T5_NAME = \"google/t5-v1_1-base\"\nT5_CONFIGS = {}", "DEFAULT_T5_NAME = \"google/t5-v1_1-base\"\nT5_CONFIGS = {}\nMAX_LENGTH = 256\n\n\n# taken from https://github.com/lucidrains/imagen-pytorch/blob/35f24ea102ab1d71da7df3c8a650c4fe712d2a9c/imagen_pytorch/t5.py#L107\ndef t5_encode_text(texts: List[str], name=DEFAULT_T5_NAME, return_attn_mask=False):\n    token_ids, attn_mask = t5_tokenize(texts, name=name)\n    encoded_text = t5_encode_tokenized_text(token_ids, attn_mask=attn_mask, name=name)\n\n    if return_attn_mask:\n        attn_mask = attn_mask.bool()\n        return encoded_text, attn_mask\n\n    return encoded_text", "\n\ndef exists(val):\n    return val is not None\n\n\ndef get_tokenizer(name):\n    tokenizer = T5Tokenizer.from_pretrained(name, model_max_length=MAX_LENGTH)\n    return tokenizer\n", "\n\ndef get_model(name):\n    model = T5EncoderModel.from_pretrained(name)\n    return model\n\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if callable(d) else d", "\n\ndef get_model_and_tokenizer(name):\n    global T5_CONFIGS\n\n    if name not in T5_CONFIGS:\n        T5_CONFIGS[name] = dict()\n    if \"model\" not in T5_CONFIGS[name]:\n        T5_CONFIGS[name][\"model\"] = get_model(name)\n    if \"tokenizer\" not in T5_CONFIGS[name]:\n        T5_CONFIGS[name][\"tokenizer\"] = get_tokenizer(name)\n\n    return T5_CONFIGS[name][\"model\"], T5_CONFIGS[name][\"tokenizer\"]", "\n\ndef t5_tokenize(texts: List[str], name=DEFAULT_T5_NAME):\n    t5, tokenizer = get_model_and_tokenizer(name)\n\n    if torch.cuda.is_available():\n        t5 = t5.cuda()\n\n    device = next(t5.parameters()).device\n\n    encoded = tokenizer.batch_encode_plus(\n        texts,\n        return_tensors=\"pt\",\n        padding=\"longest\",\n        max_length=MAX_LENGTH,\n        truncation=True,\n    )\n\n    input_ids = encoded.input_ids.to(device)\n    attn_mask = encoded.attention_mask.to(device)\n    return input_ids, attn_mask", "\n\ndef t5_encode_tokenized_text(\n    token_ids, attn_mask=None, pad_id=None, name=DEFAULT_T5_NAME\n):\n    assert exists(attn_mask) or exists(pad_id)\n    t5, _ = get_model_and_tokenizer(name)\n\n    attn_mask = default(attn_mask, lambda: (token_ids != pad_id).long())\n\n    t5.eval()\n\n    with torch.no_grad():\n        output = t5(input_ids=token_ids, attention_mask=attn_mask)\n        encoded_text = output.last_hidden_state.detach()\n\n    attn_mask = attn_mask.bool()\n\n    encoded_text = encoded_text.masked_fill(\n        ~rearrange(attn_mask, \"... -> ... 1\"), 0.0\n    )  # just force all embeddings that is padding to be equal to 0.\n    return encoded_text", "\n\nNAME = \"t5-v1_1-xxl\"\nanns = sum(json.load(open(\"/data2/eddie/calvin/annotations.json\")).values(), [])\nembeds = {}\nembeddings = t5_encode_text(anns, name=f\"google/{NAME}\")\nfor a, e in zip(anns, embeddings):\n    embeds[a] = e.cpu()\ntorch.save(embeds, f\"{NAME}_embeddings.pt\")\n", "torch.save(embeds, f\"{NAME}_embeddings.pt\")\n"]}
{"filename": "src/lcd/scripts/generation/dataset.py", "chunked_list": ["# %%\nimport os\nfrom os.path import join as j\n\nimport torch\n\np = \"/home/ubuntu/vanilla-hulc-larel-baseline/evaluation\"\nfiles = [j(p, f) for f in os.listdir(p) if f.startswith(\"gen\")]\nos.chdir(p)\n", "os.chdir(p)\n\n# %%\n\"\"\"\n{seq_length: [ traj... ]}\ntraj = [subtask, subtask...] # total of seq_length subtasks\n\nsubtask: dict_keys(['states', 'actions', 'goal_image', 'goal_lang', 'goal_task'])\n\nsubtask.states = [ { dict_keys(['rgb_obs', 'robot_obs', 'depth_obs', 'robot_obs_raw', 'scene_obs']) } ...] # rgb is normalized already. ", "\nsubtask.states = [ { dict_keys(['rgb_obs', 'robot_obs', 'depth_obs', 'robot_obs_raw', 'scene_obs']) } ...] # rgb is normalized already. \nepth_obs is empty\nsubtask.actions = tensor ([len(subtask), 1, 1, 7])\nsubtask.goal_image = { dict_keys(['rgb_obs', 'robot_obs', 'depth_obs', 'robot_obs_raw', 'scene_obs']) }\nsubtask.goal_task = 'rotate_pink_block_right'\nsubtask.goal_lang = ?\n\"\"\"\n# s = torch.load(j(p, 'gen_history_HULC_D_D_02-01-2023-09:17:46.pt'), map_location='cpu')\n# len(s[1][0][0])", "# s = torch.load(j(p, 'gen_history_HULC_D_D_02-01-2023-09:17:46.pt'), map_location='cpu')\n# len(s[1][0][0])\n\n\"\"\"\nYou can generate each key state with +- some random epsilon for each index\nYou can use this \"embeddings = np.load(Path(val_dataset_path) / lang_folder / \"embeddings.npy\", allow_pickle=True).item()\" for embedding\n\n\"\"\"\nfrom collections import defaultdict\nfrom pathlib import Path", "from collections import defaultdict\nfrom pathlib import Path\n\nimport numpy as np\nimport yaml\nfrom hulc.models.hulc import Hulc\n\n\ndef gen_annotations_embeddings():\n    n = np.load(\n        \"/home/ubuntu/vanilla-hulc-icml-baseline/data/task_D_D/training/lang_paraphrase-MiniLM-L3-v2/auto_lang_ann.npy\",\n        allow_pickle=True,\n    ).item()\n    ann, tasks, emb = n[\"language\"].values()\n    annotations = defaultdict(list)\n    embeddings = defaultdict(list)\n    for i in range(len(ann)):\n        if ann[i] not in annotations[tasks[i]]:\n            annotations[tasks[i]].append(ann[i])\n            embeddings[tasks[i]].append(emb[i])\n    return annotations, embeddings", "def gen_annotations_embeddings():\n    n = np.load(\n        \"/home/ubuntu/vanilla-hulc-icml-baseline/data/task_D_D/training/lang_paraphrase-MiniLM-L3-v2/auto_lang_ann.npy\",\n        allow_pickle=True,\n    ).item()\n    ann, tasks, emb = n[\"language\"].values()\n    annotations = defaultdict(list)\n    embeddings = defaultdict(list)\n    for i in range(len(ann)):\n        if ann[i] not in annotations[tasks[i]]:\n            annotations[tasks[i]].append(ann[i])\n            embeddings[tasks[i]].append(emb[i])\n    return annotations, embeddings", "\n\nannotations, embeddings = gen_annotations_embeddings()\n# model = Hulc.load_from_checkpoint(Path(\"/home/eddie/git/lad/vhulc/checkpoints/HULC_D_D/saved_models/HULC_D_D.ckpt\"))\n# model.freeze()\n\n\n# %%\nimport random\n", "import random\n\nimport tqdm\n\n\ndef sample(task):\n    anns = annotations[task]\n    idx = random.randint(0, len(anns) - 1)\n    return anns[idx], embeddings[task][idx][0]\n", "\n\n# def gen_goal(states):\n#     emb = model.perceptual_encoder(aggregate(states), {}, None)\n#     return model.visual_goal(emb.squeeze(dim=1))\n\n\ndef aggregate(states):\n    return {\n        \"rgb_static\": torch.concat([v[\"rgb_obs\"][\"rgb_static\"] for v in states]),\n        \"rgb_gripper\": torch.concat([v[\"rgb_obs\"][\"rgb_gripper\"] for v in states]),\n    }", "\n\n# %%\n\n# ret = defaultdict(list)\n# for f in tqdm.tqdm(files):\n#     f = torch.load(f, map_location=\"cpu\")\n#     for seq_length in f:\n#         for traj in f[seq_length]:\n#             for subtask in traj:", "#         for traj in f[seq_length]:\n#             for subtask in traj:\n#                 goal_space_states = gen_goal(subtask[\"states\"])\n#                 ret[\"states\"].append(goal_space_states)\n#                 ret[\"goal_task\"].append(subtask[\"goal_task\"])\n#                 ann, lang = sample(subtask[\"goal_task\"])\n#                 ret[\"goal_lang\"].append(lang)\n#                 ret[\"goal_ann\"].append(ann)\n\n#     inter = {}", "\n#     inter = {}\n#     inter[\"states\"] = np.array(ret[\"states\"], dtype=object)\n#     inter[\"goal_lang\"] = torch.tensor(np.array(ret[\"goal_lang\"]))\n#     inter[\"goal_task\"] = np.array(ret[\"goal_task\"])\n#     inter[\"goal_ann\"] = np.array(ret[\"goal_ann\"])\n\n#     torch.save(inter, \"all_trajectories_all_states.pt\")\n\n", "\n\n# ? AWS FROM SCRATCH\n# %%\nfrom collections import defaultdict\n\nimport tqdm\n\nfor seed in [12, 13, 42]:\n    seed = str(seed)\n    p = \"/home/ubuntu/vanilla-hulc-larel-baseline/evaluation\"\n    files = [j(p, f) for f in os.listdir(p) if f.startswith(f\"TG{seed}\")]\n    os.chdir(p)\n\n    ret = defaultdict(list)\n    for f in tqdm.tqdm(files):\n        try:\n            f = torch.load(f, map_location=\"cpu\")\n            for traj in f:\n                for subtask in traj:\n                    # goal_space_states = gen_goal(subtask[\"states\"])\n                    ret[\"states\"].append(subtask[\"states\"])\n                    ret[\"goal_task\"].append(subtask[\"goal_task\"])\n                    ann, lang = sample(subtask[\"goal_task\"])\n                    ret[\"goal_lang\"].append(lang)\n                    ret[\"goal_ann\"].append(ann)\n\n            inter = {}\n            inter[\"states\"] = np.array(ret[\"states\"], dtype=object)\n            inter[\"goal_lang\"] = torch.tensor(np.array(ret[\"goal_lang\"]))\n            inter[\"goal_task\"] = np.array(ret[\"goal_task\"])\n            inter[\"goal_ann\"] = np.array(ret[\"goal_ann\"])\n        except Exception as e:\n            print(\"*\" * 50)\n            print(f)\n            print(e)\n            print(\"*\" * 50)\n\n        torch.save(inter, f\"{seed}_all_trajectories.pt\")", "for seed in [12, 13, 42]:\n    seed = str(seed)\n    p = \"/home/ubuntu/vanilla-hulc-larel-baseline/evaluation\"\n    files = [j(p, f) for f in os.listdir(p) if f.startswith(f\"TG{seed}\")]\n    os.chdir(p)\n\n    ret = defaultdict(list)\n    for f in tqdm.tqdm(files):\n        try:\n            f = torch.load(f, map_location=\"cpu\")\n            for traj in f:\n                for subtask in traj:\n                    # goal_space_states = gen_goal(subtask[\"states\"])\n                    ret[\"states\"].append(subtask[\"states\"])\n                    ret[\"goal_task\"].append(subtask[\"goal_task\"])\n                    ann, lang = sample(subtask[\"goal_task\"])\n                    ret[\"goal_lang\"].append(lang)\n                    ret[\"goal_ann\"].append(ann)\n\n            inter = {}\n            inter[\"states\"] = np.array(ret[\"states\"], dtype=object)\n            inter[\"goal_lang\"] = torch.tensor(np.array(ret[\"goal_lang\"]))\n            inter[\"goal_task\"] = np.array(ret[\"goal_task\"])\n            inter[\"goal_ann\"] = np.array(ret[\"goal_ann\"])\n        except Exception as e:\n            print(\"*\" * 50)\n            print(f)\n            print(e)\n            print(\"*\" * 50)\n\n        torch.save(inter, f\"{seed}_all_trajectories.pt\")", ""]}
{"filename": "src/lcd/scripts/generation/task_orderings.py", "chunked_list": ["from collections import defaultdict\n\nimport torch\nfrom hulc.evaluation.multistep_sequences import get_sequences\n\nseq = get_sequences(num_sequences=10000, num_workers=64)\n\nfirst_task = [s[1][0] for s in seq]\nindices = defaultdict(list)\nfor i, s in enumerate(seq):\n    indices[s[1][0]].append(i)", "indices = defaultdict(list)\nfor i, s in enumerate(seq):\n    indices[s[1][0]].append(i)\n\nfirst_indices = list(indices.keys())\nfor i, s in enumerate(seq):\n    if s[1][1] not in first_indices:\n        indices[s[1][1]].append(i)\n    if s[1][2] == \"unstack_block\":\n        indices[s[1][2]].append(i)", "\ninfo = (indices, seq)\ntorch.save(info, \"(indices,seq).pt\")\n"]}
{"filename": "src/lcd/config/calvin.py", "chunked_list": ["from lcd.utils import watch\n\n# ------------------------ base ------------------------#\n\n## automatically make experiment names for planning\n## by labelling folders with these args\n\nargs_to_watch = [\n    (\"prefix\", \"\"),\n    # ('horizon', 'H'),", "    (\"prefix\", \"\"),\n    # ('horizon', 'H'),\n    (\"n_diffusion_steps\", \"T\"),\n    ## value kwargs\n    (\"seed\", \"S\"),\n]\n\nlogbase = \"logs\"\n\nbase = {", "\nbase = {\n    \"diffusion\": {\n        ## model\n        \"model\": \"models.TemporalUnet\",\n        \"diffusion\": \"models.GaussianDiffusion\",\n        \"horizon\": 4,  # 1,\n        \"n_diffusion_steps\": 20,\n        \"action_weight\": 100,\n        \"loss_weights\": None,", "        \"action_weight\": 100,\n        \"loss_weights\": None,\n        \"loss_discount\": 1,\n        \"predict_epsilon\": False,\n        \"dim_mults\": (1, 4, 8),  # (1, 2, 4, 8),\n        \"attention\": True,  # False\n        \"renderer\": \"utils.MuJoCoRenderer\",\n        \"downsample\": False,  # True\n        \"model_dim\": 64,  # 128,\n        ## dataset", "        \"model_dim\": 64,  # 128,\n        ## dataset\n        \"loader\": \"datasets.HulcDataset\",  # 'datasets.HulcDataset',\n        \"frame_offset\": 0,\n        \"normalizer\": \"GaussianNormalizer\",\n        \"preprocess_fns\": [],\n        \"clip_denoised\": False,\n        \"use_padding\": True,\n        \"max_path_length\": 1000,\n        \"observation_dim\": 32,", "        \"max_path_length\": 1000,\n        \"observation_dim\": 32,\n        \"action_dim\": 32,\n        ## serialization\n        \"logbase\": logbase,\n        \"prefix\": \"diffusion/defaults\",\n        \"exp_name\": watch(args_to_watch),\n        ## training\n        \"wandb\": False,  # true\n        \"wandb_name\": \"default\",", "        \"wandb\": False,  # true\n        \"wandb_name\": \"default\",\n        \"wandb_project\": \"language-control-diffusion\",\n        # \"wandb_entity\": \"<REPLACE WITH YOUR WANDB ORG>\",  #!! Change me\n        \"wandb_entity\": \"lang-diffusion\",  #!! Change me\n        \"n_steps_per_epoch\": 10000,\n        \"n_evals_per_epoch\": 10,\n        \"eval_freq\": 10,\n        \"loss_type\": \"l2\",\n        \"n_train_steps\": 3e5,", "        \"loss_type\": \"l2\",\n        \"n_train_steps\": 3e5,\n        \"batch_size\": 512,\n        \"learning_rate\": 2e-4,\n        \"gradient_accumulate_every\": 1,\n        \"ema_decay\": 0.995,\n        \"save_freq\": 10000,\n        \"sample_freq\": 1000,\n        \"n_saves\": 5,\n        \"save_parallel\": False,", "        \"n_saves\": 5,\n        \"save_parallel\": False,\n        \"n_reference\": 8,\n        \"bucket\": None,\n        \"device\": \"cuda\",\n        \"seed\": 0,\n    }\n}\n", ""]}
{"filename": "src/lcd/models/diffusion.py", "chunked_list": ["import pdb\nfrom collections import namedtuple\n\nimport numpy as np\nimport torch\nfrom torch import nn\n\nimport lcd.utils as utils\n\nfrom .helpers import Losses, apply_conditioning, cosine_beta_schedule, extract", "\nfrom .helpers import Losses, apply_conditioning, cosine_beta_schedule, extract\n\nSample = namedtuple(\"Sample\", \"trajectories values chains\")\n\n\n@torch.no_grad()\ndef default_sample_fn(model, x, cond, t, **kwargs):\n    model_mean, _, model_log_variance = model.p_mean_variance(\n        x=x, cond=cond, t=t, **kwargs\n    )\n    model_std = torch.exp(0.5 * model_log_variance)\n\n    # no noise when t == 0\n    noise = torch.randn_like(x)\n    noise[t == 0] = 0\n\n    values = torch.zeros(len(x), device=x.device)\n    return model_mean + model_std * noise, values", "\n\ndef make_timesteps(batch_size, i, device):\n    t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n    return t\n\n\nclass GaussianDiffusion(nn.Module):\n    def __init__(\n        self,\n        model,\n        horizon,\n        observation_dim,\n        action_dim,\n        n_timesteps=1000,\n        loss_type=\"l1\",\n        clip_denoised=False,\n        predict_epsilon=True,\n        action_weight=1.0,\n        loss_discount=1.0,\n        loss_weights=None,\n        classifier_drop_probability=-1.0,  # 0.1\n    ):\n        super().__init__()\n        self.horizon = horizon\n        self.observation_dim = observation_dim\n        self.action_dim = action_dim\n        self.transition_dim = observation_dim + action_dim\n        self.model = model\n\n        self.classifier_drop_probability = classifier_drop_probability\n        betas = cosine_beta_schedule(n_timesteps)\n        alphas: torch.Tensor = 1.0 - betas\n        alphas_cumprod = torch.cumprod(alphas, dim=0)\n        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])\n\n        self.n_timesteps = int(n_timesteps)\n        self.clip_denoised = clip_denoised\n        self.predict_epsilon = predict_epsilon\n\n        self.register_buffer(\"betas\", betas)\n        self.register_buffer(\"alphas_cumprod\", alphas_cumprod)\n        self.register_buffer(\"alphas_cumprod_prev\", alphas_cumprod_prev)\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer(\"sqrt_alphas_cumprod\", torch.sqrt(alphas_cumprod))\n        self.register_buffer(\n            \"sqrt_one_minus_alphas_cumprod\", torch.sqrt(1.0 - alphas_cumprod)\n        )\n        self.register_buffer(\n            \"log_one_minus_alphas_cumprod\", torch.log(1.0 - alphas_cumprod)\n        )\n        self.register_buffer(\n            \"sqrt_recip_alphas_cumprod\", torch.sqrt(1.0 / alphas_cumprod)\n        )\n        self.register_buffer(\n            \"sqrt_recipm1_alphas_cumprod\", torch.sqrt(1.0 / alphas_cumprod - 1)\n        )\n\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n        posterior_variance = (\n            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n        )\n        self.register_buffer(\"posterior_variance\", posterior_variance)\n\n        ## log calculation clipped because the posterior variance\n        ## is 0 at the beginning of the diffusion chain\n        self.register_buffer(\n            \"posterior_log_variance_clipped\",\n            torch.log(torch.clamp(posterior_variance, min=1e-20)),\n        )\n        self.register_buffer(\n            \"posterior_mean_coef1\",\n            betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),\n        )\n        self.register_buffer(\n            \"posterior_mean_coef2\",\n            (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),\n        )\n\n        ## get loss coefficients and initialize objective\n        loss_weights = self.get_loss_weights(action_weight, loss_discount, loss_weights)\n        self.loss_fn = Losses[loss_type](loss_weights, self.action_dim)\n\n    def get_loss_weights(self, action_weight, discount, weights_dict):\n        \"\"\"\n        sets loss coefficients for trajectory\n\n        action_weight   : float\n            coefficient on first action loss\n        discount   : float\n            multiplies t^th timestep of trajectory loss by discount**t\n        weights_dict    : dict\n            { i: c } multiplies dimension i of observation loss by c\n        \"\"\"\n        self.action_weight = action_weight\n\n        dim_weights = torch.ones(self.transition_dim, dtype=torch.float32)\n\n        ## set loss coefficients for dimensions of observation\n        if weights_dict is None:\n            weights_dict = {}\n        for ind, w in weights_dict.items():\n            dim_weights[self.action_dim + ind] *= w\n\n        ## decay loss with trajectory timestep: discount**t\n        discounts = discount ** torch.arange(self.horizon, dtype=torch.float)\n        discounts = discounts / discounts.mean()\n        loss_weights = torch.einsum(\"h,t->ht\", discounts, dim_weights)\n\n        ## manually set a0 weight\n        loss_weights[0, : self.action_dim] = action_weight\n        return loss_weights\n\n    # ------------------------------------------ sampling ------------------------------------------#\n    def predict_noise_from_start(self, x_t, t, x0):\n        \"\"\"\n        if self.predict_epsilon, model output is (scaled) noise;\n        otherwise, model predicts x0 directly\n        \"\"\"\n        if self.predict_epsilon:\n            return x0\n        else:\n            return (\n                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - x0\n            ) / extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n\n    def predict_start_from_noise(self, x_t, t, noise):\n        \"\"\"\n        if self.predict_epsilon, model output is (scaled) noise;\n        otherwise, model predicts x0 directly\n        \"\"\"\n        if self.predict_epsilon:\n            return (\n                extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t\n                - extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n            )\n        else:\n            return noise\n\n    def q_posterior(self, x_start, x_t, t):\n        posterior_mean = (\n            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start\n            + extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n        )\n        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n        posterior_log_variance_clipped = extract(\n            self.posterior_log_variance_clipped, t, x_t.shape\n        )\n        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n    def p_mean_variance(self, x, cond, t):\n        x_recon = self.predict_start_from_noise(x, t=t, noise=self.model(x, cond, t))\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n            x_start=x_recon, x_t=x, t=t\n        )\n        return model_mean, posterior_variance, posterior_log_variance\n\n    @torch.no_grad()\n    def p_sample_loop(\n        self,\n        shape,\n        cond,\n        prior=None,\n        inpaint=None,\n        verbose=False,\n        return_chain=False,\n        sample_fn=default_sample_fn,\n        **sample_kwargs,\n    ):\n        device = self.betas.device\n\n        batch_size = shape[0]\n        if prior is None:\n            x = torch.randn(shape, device=device)  # type: ignore\n        else:\n            x = prior\n\n        if inpaint is not None:\n            x = apply_conditioning(x, inpaint, self.action_dim)\n\n        chain = [x]\n\n        for i in reversed(range(0, self.n_timesteps)):\n            t = make_timesteps(batch_size, i, device)\n            x, values = sample_fn(self, x, cond, t, **sample_kwargs)\n            if inpaint is not None:\n                x = apply_conditioning(x, inpaint, self.action_dim)\n\n            if return_chain:\n                chain.append(x)\n\n        # x, values = sort_by_values(x, values)\n        if return_chain:\n            chain = torch.stack(chain, dim=1)  # type: ignore\n        return Sample(x, values, chain)\n\n    @torch.no_grad()\n    def ddim_sample(\n        self, shape, cond, prior=None, inpaint=None, return_chain=False, **sample_kwargs\n    ):\n        batch_size, device, total_timesteps, sampling_timesteps, eta = (\n            shape[0],\n            self.betas.device,\n            self.n_timesteps,\n            10,\n            0,\n        )\n\n        times = torch.linspace(\n            -1, total_timesteps - 1, steps=sampling_timesteps + 1\n        )  # [-1, 0, 1, 2, ..., T-1] when sampling_timesteps == total_timesteps\n        times = list(reversed(times.int().tolist()))\n        time_pairs = list(\n            zip(times[:-1], times[1:])\n        )  # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]\n\n        x = torch.randn(shape, device=device)  # type: ignore\n        if prior is not None:\n            x += 0.02 * prior\n\n        if inpaint is not None:\n            x = apply_conditioning(x, inpaint, self.action_dim)\n\n        x_start = None\n\n        chain = []\n\n        for time, time_next in time_pairs:\n            t = make_timesteps(batch_size, time, device)\n            t_next = make_timesteps(batch_size, time_next, device)\n\n            model_out = self.model(x, cond, t)\n            x_start = self.predict_start_from_noise(x, t=t, noise=model_out)\n            pred_noise = self.predict_noise_from_start(x, t=t, x0=model_out)\n\n            if time_next < 0:\n                x = x_start\n                continue\n\n            alpha = extract(self.alphas_cumprod, t, x.shape)\n            alpha_next = extract(self.alphas_cumprod, t_next, x.shape)\n\n            sigma = (\n                eta * ((1 - alpha / alpha_next) * (1 - alpha_next) / (1 - alpha)).sqrt()\n            )\n            c = (1 - alpha_next - sigma**2).sqrt()\n\n            noise = torch.randn_like(x)\n\n            x = x_start * alpha_next.sqrt() + c * pred_noise + sigma * noise\n\n            if inpaint is not None:\n                x = apply_conditioning(x, inpaint, self.action_dim)\n\n            if return_chain:\n                chain.append(x)\n\n        if return_chain:\n            chain = torch.stack(chain, dim=1)  # type: ignore\n\n        if inpaint is not None:\n            x = apply_conditioning(x, inpaint, self.action_dim)\n\n        return Sample(x, None, chain)\n\n    @torch.no_grad()\n    def conditional_sample(self, cond, horizon=None, **sample_kwargs):\n        \"\"\"\n        conditions : [ (time, state), ... ]\n        \"\"\"\n        batch_size = len(cond)\n        horizon = horizon or self.horizon\n        shape = (batch_size, horizon, self.transition_dim)\n        if sample_kwargs.get(\"ddim\"):\n            return self.ddim_sample(shape, cond, **sample_kwargs)\n\n        return self.p_sample_loop(shape, cond, **sample_kwargs)\n\n    # ------------------------------------------ training ------------------------------------------#\n\n    def q_sample(self, x_start, t, noise=None):\n        if noise is None:\n            noise = torch.randn_like(x_start)\n\n        sample = (\n            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n            + extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n        )\n\n        return sample\n\n    def p_losses(self, x_start, cond, t, inpaint=None, **model_kwargs):\n        noise = torch.randn_like(x_start)\n\n        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise).to(x_start)\n        if inpaint is not None:\n            x_noisy = apply_conditioning(x_noisy, inpaint, self.action_dim)\n\n        if np.random.uniform() < self.classifier_drop_probability:\n            cond = torch.zeros_like(cond)\n\n        x_recon = self.model(x_noisy, cond, t, **model_kwargs)\n        if inpaint is not None:\n            x_recon = apply_conditioning(x_recon, inpaint, self.action_dim)\n\n        assert noise.shape == x_recon.shape\n\n        if self.predict_epsilon:\n            loss, info = self.loss_fn(x_recon, noise)\n        else:\n            loss, info = self.loss_fn(x_recon, x_start)\n\n        return loss, info\n\n    def loss(self, x, cond, inpaint=None, **model_kwargs):\n        batch_size = len(x)\n        t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()\n        return self.p_losses(x, cond, t, inpaint=inpaint, **model_kwargs)\n\n    def forward(self, *args, **kwargs):\n        return self.conditional_sample(*args, **kwargs)", ""]}
{"filename": "src/lcd/models/temporal.py", "chunked_list": ["import pdb\n\nimport einops\nimport torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .helpers import (\n    Conv1dBlock,\n    CrossAttention,", "    Conv1dBlock,\n    CrossAttention,\n    Downsample1d,\n    PreNorm,\n    Residual,\n    SinusoidalPosEmb,\n    Upsample1d,\n)\n\n\nclass ResidualTemporalBlock(nn.Module):\n    def __init__(self, inp_channels, out_channels, embed_dim, horizon, kernel_size=5):\n        super().__init__()\n\n        self.blocks = nn.ModuleList(\n            [\n                Conv1dBlock(inp_channels, out_channels, kernel_size),\n                Conv1dBlock(out_channels, out_channels, kernel_size),\n            ]\n        )\n\n        self.time_mlp = nn.Sequential(\n            nn.Mish(),\n            nn.Linear(embed_dim, out_channels),\n            Rearrange(\"batch t -> batch t 1\"),\n        )\n\n        self.residual_conv = (\n            nn.Conv1d(inp_channels, out_channels, 1)\n            if inp_channels != out_channels\n            else nn.Identity()\n        )\n\n    def forward(self, x, t):\n        \"\"\"\n        x : [ batch_size x inp_channels x horizon ]\n        t : [ batch_size x embed_dim ]\n        returns:\n        out : [ batch_size x out_channels x horizon ]\n        \"\"\"\n        out = self.blocks[0](x) + self.time_mlp(t)\n        out = self.blocks[1](out)\n        return out + self.residual_conv(x)", "\n\nclass ResidualTemporalBlock(nn.Module):\n    def __init__(self, inp_channels, out_channels, embed_dim, horizon, kernel_size=5):\n        super().__init__()\n\n        self.blocks = nn.ModuleList(\n            [\n                Conv1dBlock(inp_channels, out_channels, kernel_size),\n                Conv1dBlock(out_channels, out_channels, kernel_size),\n            ]\n        )\n\n        self.time_mlp = nn.Sequential(\n            nn.Mish(),\n            nn.Linear(embed_dim, out_channels),\n            Rearrange(\"batch t -> batch t 1\"),\n        )\n\n        self.residual_conv = (\n            nn.Conv1d(inp_channels, out_channels, 1)\n            if inp_channels != out_channels\n            else nn.Identity()\n        )\n\n    def forward(self, x, t):\n        \"\"\"\n        x : [ batch_size x inp_channels x horizon ]\n        t : [ batch_size x embed_dim ]\n        returns:\n        out : [ batch_size x out_channels x horizon ]\n        \"\"\"\n        out = self.blocks[0](x) + self.time_mlp(t)\n        out = self.blocks[1](out)\n        return out + self.residual_conv(x)", "\n\nclass TemporalUnet(nn.Module):\n    def __init__(\n        self,\n        horizon,\n        transition_dim,\n        cond_dim,\n        dim=32,\n        dim_mults=(1, 2, 4, 8),\n        attention=False,\n        downsample=True,\n    ):\n        super().__init__()\n\n        dims = [transition_dim, *map(lambda m: dim * m, dim_mults)]  # type: ignore\n        in_out = list(zip(dims[:-1], dims[1:]))\n        print(f\"[ models/temporal ] Channel dimensions: {in_out}\")\n\n        time_dim = dim\n        self.time_mlp = nn.Sequential(\n            SinusoidalPosEmb(dim),\n            nn.Linear(dim, dim * 4),\n            nn.Mish(),\n            nn.Linear(dim * 4, dim),\n        )\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        print(in_out)\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.downs.append(\n                nn.ModuleList(\n                    [\n                        ResidualTemporalBlock(\n                            dim_in, dim_out, embed_dim=time_dim, horizon=horizon\n                        ),\n                        ResidualTemporalBlock(\n                            dim_out, dim_out, embed_dim=time_dim, horizon=horizon\n                        ),\n                        CrossAttention(dim_out, cross_attention_dim=4096)\n                        if attention\n                        else nn.Identity(),\n                        Downsample1d(dim_out)\n                        if not is_last and downsample\n                        else nn.Identity(),\n                    ]\n                )\n            )\n\n            if not is_last and downsample:\n                horizon = horizon // 2\n\n        mid_dim = dims[-1]\n        self.mid_block1 = ResidualTemporalBlock(\n            mid_dim, mid_dim, embed_dim=time_dim, horizon=horizon\n        )\n        self.mid_attn = (\n            CrossAttention(mid_dim, cross_attention_dim=4096)\n            if attention\n            else nn.Identity()\n        )\n        self.mid_block2 = ResidualTemporalBlock(\n            mid_dim, mid_dim, embed_dim=time_dim, horizon=horizon\n        )\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.ups.append(\n                nn.ModuleList(\n                    [\n                        ResidualTemporalBlock(\n                            dim_out * 2, dim_in, embed_dim=time_dim, horizon=horizon\n                        ),\n                        ResidualTemporalBlock(\n                            dim_in, dim_in, embed_dim=time_dim, horizon=horizon\n                        ),\n                        CrossAttention(dim_in, cross_attention_dim=4096)\n                        if attention\n                        else nn.Identity(),\n                        Upsample1d(dim_in)\n                        if not is_last and downsample\n                        else nn.Identity(),\n                    ]\n                )\n            )\n\n            if not is_last and downsample:\n                horizon = horizon * 2\n\n        self.final_conv = nn.Sequential(\n            Conv1dBlock(dim, dim, kernel_size=5), nn.Conv1d(dim, transition_dim, 1)\n        )\n\n    def forward(self, x, cond, time):\n        \"\"\"\n        x : [ batch x horizon x transition ]\n        \"\"\"\n\n        x = einops.rearrange(x, \"b h t -> b t h\")\n\n        t = self.time_mlp(time)\n        h = []\n\n        for resnet, resnet2, attn, downsample in self.downs:\n            x = resnet(x, t)\n            x = resnet2(x, t)\n            x = attn(x, cond)\n            h.append(x)\n            x = downsample(x)\n\n        x = self.mid_block1(x, t)\n        x = self.mid_attn(x, cond)\n        x = self.mid_block2(x, t)\n\n        for resnet, resnet2, attn, upsample in self.ups:\n            x = torch.cat((x, h.pop()), dim=1)\n            x = resnet(x, t)\n            x = resnet2(x, t)\n            x = attn(x, cond)\n            x = upsample(x)\n\n        x = self.final_conv(x)\n\n        x = einops.rearrange(x, \"b t h -> b h t\")\n        return x", ""]}
{"filename": "src/lcd/models/__init__.py", "chunked_list": ["from .diffusion import GaussianDiffusion\nfrom .temporal import TemporalUnet\n"]}
{"filename": "src/lcd/models/helpers.py", "chunked_list": ["import math\nimport pdb\n\nimport einops\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops.layers.torch import Rearrange\n", "from einops.layers.torch import Rearrange\n\nimport lcd.utils as utils\n\n# -----------------------------------------------------------------------------#\n# ---------------------------------- modules ----------------------------------#\n# -----------------------------------------------------------------------------#\n\n\nclass SinusoidalPosEmb(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        device = x.device\n        half_dim = self.dim // 2\n        emb = math.log(10000) / (half_dim - 1)\n        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n        emb = x[:, None] * emb[None, :]\n        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n        return emb", "\nclass SinusoidalPosEmb(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        device = x.device\n        half_dim = self.dim // 2\n        emb = math.log(10000) / (half_dim - 1)\n        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n        emb = x[:, None] * emb[None, :]\n        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n        return emb", "\n\nclass Downsample1d(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n\n    def forward(self, x):\n        return self.conv(x)\n", "\n\nclass Upsample1d(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n\n    def forward(self, x):\n        return self.conv(x)\n", "\n\nclass Conv1dBlock(nn.Module):\n    \"\"\"\n    Conv1d --> GroupNorm --> Mish\n    \"\"\"\n\n    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n        super().__init__()\n\n        self.block = nn.Sequential(\n            nn.Conv1d(\n                inp_channels, out_channels, kernel_size, padding=kernel_size // 2\n            ),\n            Rearrange(\"batch channels horizon -> batch channels 1 horizon\"),\n            nn.GroupNorm(n_groups, out_channels),\n            Rearrange(\"batch channels 1 horizon -> batch channels horizon\"),\n            nn.Mish(),\n        )\n\n    def forward(self, x):\n        return self.block(x)", "\n\n# -----------------------------------------------------------------------------#\n# --------------------------------- attention ---------------------------------#\n# -----------------------------------------------------------------------------#\n\n\nclass Residual(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n\n    def forward(self, x, *args, **kwargs):\n        return self.fn(x, *args, **kwargs) + x", "\n\nclass LayerNorm(nn.Module):\n    def __init__(self, dim, eps=1e-5):\n        super().__init__()\n        self.eps = eps\n        self.g = nn.Parameter(torch.ones(1, dim, 1))\n        self.b = nn.Parameter(torch.zeros(1, dim, 1))\n\n    def forward(self, x):\n        var = torch.var(x, dim=1, unbiased=False, keepdim=True)\n        mean = torch.mean(x, dim=1, keepdim=True)\n        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b", "\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.fn = fn\n        self.norm = LayerNorm(dim)\n\n    def forward(self, x):\n        x = self.norm(x)\n        return self.fn(x)", "\n\nclass CrossAttention(nn.Module):  # replace with regular cross attention\n    def __init__(\n        self,\n        query_dim,\n        cross_attention_dim=None,\n        heads=4,\n        dim_head=32,\n        bias=False,\n        dropout=0,\n    ):\n        super().__init__()\n        cross_attention_dim = (\n            cross_attention_dim if cross_attention_dim is not None else query_dim\n        )\n        self.scale = dim_head**-0.5\n        self.heads = heads\n        self.query_dim = query_dim\n\n        hidden_dim = dim_head * heads\n\n        self.norm = LayerNorm(query_dim)\n        self.to_q = nn.Linear(query_dim, hidden_dim, bias=bias)\n        self.to_k = nn.Linear(cross_attention_dim, hidden_dim, bias=bias)\n        self.to_v = nn.Linear(cross_attention_dim, hidden_dim, bias=bias)\n\n        self.to_out = nn.Conv1d(hidden_dim, query_dim, 1)\n        self.dropout = nn.Dropout(p=dropout) if dropout else nn.Identity()\n\n    def forward(self, x, context=None):\n        og_x = x\n        x = self.norm(x)\n        x = x.permute(0, 2, 1)\n        q = self.to_q(x)\n        context = context if context is not None else x\n        k = self.to_k(context)\n        v = self.to_v(context)\n\n        q, k, v = map(lambda t: einops.rearrange(t.permute(0, 2, 1), \"b (h c) d -> b h c d\", h=self.heads), (q, k, v))  # type: ignore\n\n        # b = batch\n        # h = heads\n        # c = channels\n        # d = number of queries\n        # e = number of key/values\n        qk = (torch.einsum(\"b h c d, b h c e -> b h d e\", q, k) * self.scale).softmax(\n            dim=-1\n        )\n\n        out = torch.einsum(\"b h d e, b h c e -> b h c d\", qk, v)\n        out = einops.rearrange(out, \"b h c d -> b (h c) d\")\n        return self.dropout(self.to_out(out) + og_x)", "\n\n# -----------------------------------------------------------------------------#\n# ---------------------------------- sampling ---------------------------------#\n# -----------------------------------------------------------------------------#\n\n\ndef extract(a, t, x_shape):\n    b, *_ = t.shape\n    out = a.gather(-1, t)\n    return out.reshape(b, *((1,) * (len(x_shape) - 1)))", "\n\ndef cosine_beta_schedule(timesteps, s=0.008, dtype=torch.float32):\n    \"\"\"\n    cosine schedule\n    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n    \"\"\"\n    steps = timesteps + 1\n    x = np.linspace(0, steps, steps)\n    alphas_cumprod = np.cos(((x / steps) + s) / (1 + s) * np.pi * 0.5) ** 2\n    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n    betas_clipped = np.clip(betas, a_min=0, a_max=0.999)\n    return torch.tensor(betas_clipped, dtype=dtype)", "\n\ndef apply_conditioning(x, conditions, action_dim):\n    for t, val in conditions.items():\n        x[:, t, action_dim:] = val.clone()\n    return x\n\n\n# -----------------------------------------------------------------------------#\n# ---------------------------------- losses -----------------------------------#", "# -----------------------------------------------------------------------------#\n# ---------------------------------- losses -----------------------------------#\n# -----------------------------------------------------------------------------#\n\n\nclass WeightedLoss(nn.Module):\n    def __init__(self, weights, action_dim):\n        super().__init__()\n        self.register_buffer(\"weights\", weights)\n        self.action_dim = action_dim\n\n    def forward(self, pred, targ):\n        \"\"\"\n        pred, targ : tensor\n            [ batch_size x horizon x transition_dim ]\n        \"\"\"\n        loss = self._loss(pred, targ)\n        weighted_loss = (loss * self.weights).mean()\n        a0_loss = (loss[:, 0, : self.action_dim] / self.weights[0, : self.action_dim]).mean()  # type: ignore\n        return weighted_loss / self.weights[0, 0].detach(), {\"a0_loss\": a0_loss}\n\n    def _loss(self, pred, targ):\n        return NotImplementedError", "\n\nclass WeightedL1(WeightedLoss):\n    def _loss(self, pred, targ):\n        return torch.abs(pred - targ)\n\n\nclass WeightedL2(WeightedLoss):\n    def _loss(self, pred, targ):\n        return F.mse_loss(pred, targ, reduction=\"none\")", "\n\nLosses = {\"l1\": WeightedL1, \"l2\": WeightedL2}\n"]}
{"filename": "src/lcd/datasets/sequence.py", "chunked_list": ["import json\nimport random\nfrom collections import namedtuple\n\nimport numpy as np\nimport torch\n\nBatch = namedtuple(\"Batch\", \"trajectories conditions\")\nKwargsBatch = namedtuple(\"KwargsBatch\", \"batch kwargs\")\nValueBatch = namedtuple(\"ValueBatch\", \"trajectories conditions values\")", "KwargsBatch = namedtuple(\"KwargsBatch\", \"batch kwargs\")\nValueBatch = namedtuple(\"ValueBatch\", \"trajectories conditions values\")\n\n\ndef cut_last(tensor):\n    return tensor[:-1, ...]\n\n\ndef cut_first(tensor):\n    return tensor[1:, ...]", "def cut_first(tensor):\n    return tensor[1:, ...]\n\n\ndef stack_next(tensor):\n    return torch.concat((cut_first(tensor), cut_last(tensor)), dim=1)\n\n\nclass HulcDataset(torch.utils.data.Dataset):\n    \"Characterizes a dataset for PyTorch\"\n\n    def __init__(\n        self,\n        *args,\n        buf,\n        task_to_ann,\n        lang_embeds,\n        frame_offset=0,\n        horizon=4,\n        clip_stride=16,\n        **kwargs,\n    ):\n        print(f\"{buf=}\")\n        self.clip_stride = clip_stride\n        self.frame_offset = frame_offset\n        self.horizon = horizon\n\n        print(\"loading dataset...\")\n        buf = torch.load(buf, map_location=\"cpu\")\n        print(\"done loading!\")\n\n        buf[\"states\"] = np.array([i[-100:] for i in buf[\"states\"]])\n        lens = np.array([len(f) for f in buf[\"states\"]])\n        valid_indices = np.argwhere(lens >= 17).squeeze()\n\n        self.buf = {\n            \"states\": buf[\"states\"][valid_indices],\n            \"goal_lang\": np.array(buf[\"goal_lang\"])[valid_indices],\n            \"goal_task\": np.array(buf[\"goal_task\"])[valid_indices],\n        }\n        self.task_to_ann = json.load(open(task_to_ann))\n        self.lang_embeds = torch.load(lang_embeds)\n\n        self.observation_dim = kwargs.get(\"observation_dim\")\n        self.action_dim = kwargs.get(\"action_dim\")\n\n    def __len__(self):\n        return len(self.buf[\"states\"])\n\n    def __getitem__(self, index):\n        obs_traj = self.buf[\"states\"][index]\n        idx = random.randint(0, len(obs_traj) - self.clip_stride - 1)\n        offset = random.randint(-self.frame_offset, self.frame_offset)\n\n        indices = (\n            idx + torch.arange(self.horizon + 1) * self.clip_stride + offset\n        ).clamp(max=len(obs_traj) - 1)\n\n        traj = stack_next(obs_traj[indices])\n        lang = self.lang_embeds[\n            random.choice(self.task_to_ann[self.buf[\"goal_task\"][index]])\n        ]\n        return KwargsBatch(\n            Batch(traj, lang), {\"inpaint\": {0: traj[0, self.action_dim :]}}\n        )", "class HulcDataset(torch.utils.data.Dataset):\n    \"Characterizes a dataset for PyTorch\"\n\n    def __init__(\n        self,\n        *args,\n        buf,\n        task_to_ann,\n        lang_embeds,\n        frame_offset=0,\n        horizon=4,\n        clip_stride=16,\n        **kwargs,\n    ):\n        print(f\"{buf=}\")\n        self.clip_stride = clip_stride\n        self.frame_offset = frame_offset\n        self.horizon = horizon\n\n        print(\"loading dataset...\")\n        buf = torch.load(buf, map_location=\"cpu\")\n        print(\"done loading!\")\n\n        buf[\"states\"] = np.array([i[-100:] for i in buf[\"states\"]])\n        lens = np.array([len(f) for f in buf[\"states\"]])\n        valid_indices = np.argwhere(lens >= 17).squeeze()\n\n        self.buf = {\n            \"states\": buf[\"states\"][valid_indices],\n            \"goal_lang\": np.array(buf[\"goal_lang\"])[valid_indices],\n            \"goal_task\": np.array(buf[\"goal_task\"])[valid_indices],\n        }\n        self.task_to_ann = json.load(open(task_to_ann))\n        self.lang_embeds = torch.load(lang_embeds)\n\n        self.observation_dim = kwargs.get(\"observation_dim\")\n        self.action_dim = kwargs.get(\"action_dim\")\n\n    def __len__(self):\n        return len(self.buf[\"states\"])\n\n    def __getitem__(self, index):\n        obs_traj = self.buf[\"states\"][index]\n        idx = random.randint(0, len(obs_traj) - self.clip_stride - 1)\n        offset = random.randint(-self.frame_offset, self.frame_offset)\n\n        indices = (\n            idx + torch.arange(self.horizon + 1) * self.clip_stride + offset\n        ).clamp(max=len(obs_traj) - 1)\n\n        traj = stack_next(obs_traj[indices])\n        lang = self.lang_embeds[\n            random.choice(self.task_to_ann[self.buf[\"goal_task\"][index]])\n        ]\n        return KwargsBatch(\n            Batch(traj, lang), {\"inpaint\": {0: traj[0, self.action_dim :]}}\n        )", ""]}
{"filename": "src/lcd/datasets/__init__.py", "chunked_list": ["from .sequence import HulcDataset\n"]}
{"filename": "src/lcd/apps/rollout.py", "chunked_list": ["from pathlib import Path\n\nimport torch\nimport typer\nfrom hulc.evaluation.utils import get_default_model_and_env\nfrom loguru import logger\n\nfrom lcd import DATA_PATH, HULC_PATH\nfrom lcd.utils.config import AttriDict\nfrom lcd.utils.eval import DiffusionModelWrapper, evaluate_policy, print_and_save", "from lcd.utils.config import AttriDict\nfrom lcd.utils.eval import DiffusionModelWrapper, evaluate_policy, print_and_save\n\n_app_ = app = typer.Typer(name=\"lcd\")\n\nargs = AttriDict()\nstate = AttriDict()\n\n\ndef eval_pipeline():\n    logger.debug(f\"{args=}\")\n    results, histories = evaluate_policy(state, args)\n    train_folder=args.train_folder.replace('/', '-').replace('\\\\','')\n    model_id = f\"train_folder={train_folder}_{args.seed=}\"\n    if args.diffusion_path is not None:\n        model_id += f\"_{args.diffusion_path=}_{args.diffusion_epoch=}\"\n    print_and_save(results, args, histories, model_id)", "\ndef eval_pipeline():\n    logger.debug(f\"{args=}\")\n    results, histories = evaluate_policy(state, args)\n    train_folder=args.train_folder.replace('/', '-').replace('\\\\','')\n    model_id = f\"train_folder={train_folder}_{args.seed=}\"\n    if args.diffusion_path is not None:\n        model_id += f\"_{args.diffusion_path=}_{args.diffusion_epoch=}\"\n    print_and_save(results, args, histories, model_id)\n", "\n\n@app.callback()\ndef main(\n    dataset_path: str = str(HULC_PATH / \"dataset/task_D_D\"),\n    train_folder: str = str(DATA_PATH / \"hulc-baselines-30\"),\n    seed: int = 12,\n    debug: bool = False,\n    log_dir: str = None,\n    device: int = 0,\n    num_sequences: int = 1000,\n):\n    \"\"\"\n    Rollout in the environment for evaluation or dataset collection\n    \"\"\"\n    ep_len = 360\n    args.update(locals())\n\n    # *******\n    (\n        state.model,\n        state.env,\n        _,\n        state.lang_embeddings,\n    ) = get_default_model_and_env(\n        args.train_folder,\n        args.dataset_path,\n        Path(args.train_folder) / f\"saved_models/seed={args.seed}.ckpt\",\n        env=None,\n        lang_embeddings=None,\n        device_id=args.device,\n    )", "\n\n@app.command()\ndef lcd(\n    diffusion_path: str = DATA_PATH / \"lcd-seeds/seed-12\",\n    diffusion_epoch: str = 250_000,\n    subgoal_interval: int = 16,\n    dm__args: str = None,\n):\n    \"\"\"\n    Rollout with LCD\n    \"\"\"\n    args.update(locals())\n\n    # *******\n    if dm__args:\n        args.dm = DiffusionModelWrapper(\n            device=f\"cuda:{args.device}\",\n            model__args=dm__args,\n        )\n        args.diffusion_path = dm__args[1][\"savepath\"]\n        args.diffusion_epoch = dm__args[1][\"epoch\"]\n    else:\n        args.dm = DiffusionModelWrapper(\n            device=f\"cuda:{args.device}\",\n            model_path__epoch=(args.diffusion_path, args.diffusion_epoch),\n        )\n\n    state.lang_embeddings = torch.load(DATA_PATH / \"t5-v1_1-xxl_embeddings.pt\")\n\n    eval_pipeline()", "\n\n@app.command()\ndef hulc():\n    \"\"\"\n    Rollout with HULC\n    \"\"\"\n    eval_pipeline()\n\n", "\n\n@app.command()\ndef generate():\n    \"\"\"\n    Generate an on-policy dataset for training a high level policy (e.g. LCD)\n    \"\"\"\n    args.generate = True\n    eval_pipeline()\n", ""]}
{"filename": "src/lcd/apps/train_lcd.py", "chunked_list": ["import os\nimport sys\nfrom pathlib import Path\n\nimport typer\nfrom loguru import logger\n\nfrom lcd import HULC_PATH, REPO_PATH\n\npy = sys.executable", "\npy = sys.executable\n\n\ndef main(\n    ctx: typer.Context,\n):\n    \"\"\"Train the original hulc model\"\"\"\n    if ctx.args:\n        args = \" \".join(ctx.args)\n    else:\n        args = f\" --seed 12 --wandb True\"\n\n    cmd = f\"{py} {REPO_PATH / 'src/lcd/scripts/diffuser.py'} {args}\"\n    logger.info(f\"Running: \\n{cmd}\")\n    os.system(cmd)", ""]}
{"filename": "src/lcd/apps/train_hulc.py", "chunked_list": ["import os\nimport sys\nfrom pathlib import Path\n\nimport typer\nfrom loguru import logger\n\nfrom lcd import HULC_PATH\n\npy = sys.executable", "\npy = sys.executable\n\n\ndef cache_shm_dataset(dataset):\n    if not os.system(f\"\"\"tmux new-session -d -s calvin_cache_dataset\"\"\"):\n        # only continue if the tmux session wasn't created before\n        os.system(f\"\"\"tmux send-keys -t calvin_cache_dataset 'cd {HULC_PATH}' Enter\"\"\")\n        os.system(\n            f\"\"\"tmux send-keys -t calvin_cache_dataset '{py} hulc/training.py datamodule.root_data_dir={dataset} model=dummy logger=tb_logger trainer.gpus=1' Enter\"\"\"\n        )\n        logger.info(\n            \"View dataset caching progress with: tmux a -t calvin_cache_dataset\"\n        )\n        logger.info(\n            \"Please wait until the dataset has completely finished loading, then run this command again. This tmux session should remain running indefinitely in the background, effectively as a daemon.\"\n        )\n        exit(0)", "\n\ndef main(\n    ctx: typer.Context,\n):\n    \"\"\"Train the original hulc model\"\"\"\n    if ctx.args:\n        args = \" \".join(ctx.args)\n    else:\n        args = f\" trainer.gpus=-1 datamodule.root_data_dir={HULC_PATH / 'dataset/task_D_D'} seed=12\"\n\n    # parse dataset\n    dataset = None\n    for arg in args.split(\" \"):\n        split_arg = arg.split(\"=\")\n        if len(split_arg) == 2 and split_arg[0] == \"datamodule.root_data_dir\":\n            dataset = split_arg[1]\n\n    if dataset is None:\n        logger.error(\n            \"Must specify the dataset directory in the args with datamodule.root_data_dir=/path/to/data\"\n        )\n        raise ValueError\n\n    # cache shm dataset\n    cache_shm_dataset(dataset)\n\n    cmd = f\"{py} {HULC_PATH / 'hulc/training.py'} {args}\"\n    logger.info(f\"Running: \\n{cmd}\")\n    os.system(cmd)", ""]}
