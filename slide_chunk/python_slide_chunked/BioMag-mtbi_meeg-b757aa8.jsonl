{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\nwith open('requirements.txt') as f:\n    requirements = f.read().splitlines()\n\nsetup(\n    name='mtbi_meeg',\n    version='0.0.1',\n    description='Pipeline to analyze EEG and MEG data and determine minor Trauma Brain Injuries',\n    author=['Verna Heikkinen', 'Estanislao Porta', 'Aino Kuusi'],", "    description='Pipeline to analyze EEG and MEG data and determine minor Trauma Brain Injuries',\n    author=['Verna Heikkinen', 'Estanislao Porta', 'Aino Kuusi'],\n    author_email=['verna.heikkinen@example.com', 'estanislao.porta@aalto.fi'],\n    install_requires=requirements,\n    url='githubURL',\n    package_dir = {'': 'src'},\n    packages = ['analysis', 'processing'],\n    classifiers=[\n\t'Programming Language :: Python :: 3',\n\t'License :: OSI Approved :: MIT License',", "\t'Programming Language :: Python :: 3',\n\t'License :: OSI Approved :: MIT License',\n\t'Operating System :: OS Independent',\n\t],\n)\n"]}
{"filename": "tests/test_02_plot_processed_data.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n#############################\n# test_02_plot_processed_data.py #\n#############################\n@author: Estanislao Porta \n\nTests the functions from module 02_plot_processed_data.py\nUse `python3 -m pytest test_02_plot_processed_data.py` to run it from terminal", "Tests the functions from module 02_plot_processed_data.py\nUse `python3 -m pytest test_02_plot_processed_data.py` to run it from terminal\n# TODO: Should this import wide_bands and thin_bands from config_eeg?\n\"\"\"\nimport pytest\nimport importlib\nimport os\nimport sys\nimport tempfile\nimport shutil", "import tempfile\nimport shutil\nimport numpy as np\nimport pandas as pd\n\nsrc_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src'))\nsys.path.append(src_dir)\nfrom config_eeg import channels\n\nanalysis_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src', 'analysis'))", "\nanalysis_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src', 'analysis'))\nsys.path.append(analysis_dir)\nmodule_name = \"02_plot_processed_data\" # Use importlib to import the module as a string to avoid conflicts with the numbers\nplot_processed_data = importlib.import_module(module_name)\n\ndef test_load_pickle_data():\n    #possibly moved to a class\n    pass\n\ndef test_define_freq_bands():\n    # I dont think there is anything really to be tested here. It should actually be moved to the config-eeg\n    pass", "\ndef test_define_freq_bands():\n    # I dont think there is anything really to be tested here. It should actually be moved to the config-eeg\n    pass\n\n\ndef test_global_averaging_with_sample_data():\n    # TODO: Test for wide freqs!\n    freqs = np.array([x for x in range(1, 43)])   \n    eeg_data = np.random.rand(3, len(freqs) * channels)\n    df = pd.DataFrame({'Group': [1, 0, 1], 'Subject': [\"26P\", \"01C\", \"02P\"]})\n    df = pd.concat([df, pd.DataFrame(eeg_data)], axis=1)\n    metadata = {\"roi\": 'All'}\n    \n    expected_output = []\n    for idx in df.index:\n        subj_arr = np.array(df.loc[idx])[2:]\n        subj_arr = 10*np.log10(subj_arr.astype(float))\n        subj_arr = np.reshape(subj_arr, (channels, freqs.size))\n   # TODO: Remove the ROI for the testing     \n        if metadata[\"roi\"] == 'Frontal': \n            subj_arr = subj_arr[0:22, :]\n        GA = np.mean(subj_arr, axis=0)\n        expected_output.append(GA)    \n\n    actual_output = plot_processed_data.global_averaging(df, metadata, freqs)\n    assert len(expected_output) == len(actual_output)\n    assert all(tuple(a) == tuple(b) for a, b in zip(actual_output, expected_output)), \"The actual output does not match the expected output.\"", "    \ndef test_global_averaging_with_empty_dataframe():\n    # The pickle data handler should already be considering these issues\n    metadata = {\"roi\": 'All'}\n    freqs = np.array([x for x in range(1, 43)])   \n    eeg_data = []\n    df = pd.DataFrame({'Group': [1, 0, 1], 'Subject': [\"26P\", \"01C\", \"02P\"]})\n    df = pd.concat([df, pd.DataFrame(eeg_data)], axis=1)\n    \n    with pytest.raises(ValueError) as e:\n        plot_processed_data.global_averaging(df, metadata, freqs)\n    assert str(e.value) == \"Error: Empty data array.\"", "\ndef test_global_averaging_with_nan_values():\n    # The pickle data handler should already be considering this\n    metadata = {\"roi\": 'All'}\n    freqs = np.array([x for x in range(1, 43)])   \n    eeg_data = np.full((3, len(freqs) * channels), np.nan)\n    df = pd.DataFrame({'Group': [1, 0, 1], 'Subject': [\"26P\", \"01C\", \"02P\"]})\n    df = pd.concat([df, pd.DataFrame(eeg_data)], axis=1)\n    \n    with pytest.raises(ValueError) as e:\n        plot_processed_data.global_averaging(df, metadata, freqs)\n    assert str(e.value) == \"Error: There is at least one NaN value.\"", "\ndef test_create_df_for_plotting():\n    metadata = {\"control_plot_segment\": 1, \"segments\": 2}\n    freqs = np.array([x for x in range(1, 43)])   \n    eeg_data = np.random.rand(3, len(freqs) * channels)\n    df = pd.DataFrame({'Group': [1, 0, 1], 'Subject': [\"26P\", \"01C\", \"02P\"]})\n    df = pd.concat([df, pd.DataFrame(eeg_data)], axis=1)\n    \n    global_averages = []\n    for idx in df.index:\n        subj_arr = np.array(df.loc[idx])[2:]\n        subj_arr = 10 * np.log10(subj_arr.astype(float))\n        subj_arr = np.reshape(subj_arr, (channels, freqs.size))\n\n        GA = np.mean(subj_arr, axis=0)\n        global_averages.append(GA)\n    \n    df_for_plotting = plot_processed_data.create_df_for_plotting(df, metadata, freqs, global_averages)\n    assert isinstance(df_for_plotting, pd.DataFrame)", "\ndef test_plot_control_figures():\n    pass\n\ndef test_save_fig():\n    pass\n\n\n", ""]}
{"filename": "tests/test_01_read_processed_data_unittest.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n#############################\n# test_01_read_processed_data.py #\n#############################\n@author: Estanislao Porta \n\nTests the functions from module 01_read_processed_data.py\n", "Tests the functions from module 01_read_processed_data.py\n\n\"\"\"\n\nimport unittest\nimport importlib\nimport os\nimport sys\nimport tempfile\nimport shutil", "import tempfile\nimport shutil\nimport numpy as np\n\nsrc_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src'))\nsys.path.append(src_dir)\nfrom config_eeg import channels\n\nanalysis_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src', 'analysis'))\nsys.path.append(analysis_dir)", "analysis_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src', 'analysis'))\nsys.path.append(analysis_dir)\nmodule_name = \"01_read_processed_data\" # Use importlib to import the module as a string to avoid conflicts with the numbers\nread_processed_data = importlib.import_module(module_name)\n\n\nclass TestCreateSubjectsAndTasks(unittest.TestCase):\n    def test_create_subjects_and_tasks(self):\n        chosen_tasks = ['ec_1', 'ec_2', 'ec_3']\n        subjects = ['01P', '02C']\n        subjects_and_tasks = read_processed_data.create_subjects_and_tasks(chosen_tasks, subjects)\n\n        # Check that the output is a list\n        self.assertIsInstance(subjects_and_tasks, list)\n    \n        # Check that the output has the correct length\n        self.assertEqual(len(subjects_and_tasks), len(chosen_tasks) * len(subjects))\n    \n        # Check that each element in the output is a tuple with two elements\n        for element in subjects_and_tasks:\n            self.assertIsInstance(element, tuple)\n            self.assertEqual(len(element), 2)", "\nclass TestReadData(unittest.TestCase):\n    def test_read_data(self):\n        # Create temporary directory and dummy data\n        tmp_dir = tempfile.mkdtemp()\n        subjects_and_tasks = [('01P', 'ec_1'), ('01P', 'ec_2'), ('01P', 'ec_3')]\n        freq_bands = 'thin'\n        normalization = False\n        \n        # Create dummy data files in the temporary directory\n        for subject, task in subjects_and_tasks:\n            subject_dir = os.path.join(tmp_dir, f'sub-{subject}', 'ses-01', 'eeg', 'bandpowers')\n            os.makedirs(subject_dir, exist_ok=True)\n            # Create random data for \n            data = np.random.rand(89, 64)\n            filename = f'{freq_bands}_{task}.csv'\n            filepath = os.path.join(subject_dir, filename)\n            np.savetxt(filepath, data, delimiter=',')\n    \n        # Call the method with the temporary directory and dummy data\n        processed_data_dir = tmp_dir\n        result = read_processed_data.read_data(subjects_and_tasks, freq_bands, normalization, processed_data_dir)\n    \n        # Check that the output has the expected shape\n        expected_shape = (len(subjects_and_tasks), channels*38)\n        assert np.shape(result) == expected_shape, f\"Output has shape {np.shape(result)}, but expected shape is {expected_shape}\"\n    \n        # Remove the temporary directory\n        shutil.rmtree(tmp_dir)", "\nclass TestCreateDataFrame(self):\n    create_data_frame\n\nif __name__ == '__main__':\n    unittest.main()\n\n"]}
{"filename": "tests/test_01_read_processed_data.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n#############################\n# test_01_read_processed_data.py #\n#############################\n@author: Estanislao Porta \n\nTests the functions from module 01_read_processed_data.py\nUse `python3 -m pytest test_01_read_processed_data.py` to run it from terminal", "Tests the functions from module 01_read_processed_data.py\nUse `python3 -m pytest test_01_read_processed_data.py` to run it from terminal\n\"\"\"\n\nimport pytest\nimport importlib\nimport os\nimport sys\nimport tempfile\nimport shutil", "import tempfile\nimport shutil\nimport numpy as np\nimport pandas as pd\n\nsrc_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src'))\nsys.path.append(src_dir)\nfrom config_eeg import channels\n\nanalysis_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src', 'analysis'))", "\nanalysis_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src', 'analysis'))\nsys.path.append(analysis_dir)\nmodule_name = \"01_read_processed_data\" # Use importlib to import the module as a string to avoid conflicts with the numbers\nread_processed_data = importlib.import_module(module_name)\n\n\ndef test_create_subjects_and_tasks():\n    chosen_tasks = ['ec_1', 'ec_2', 'ec_3']\n    subjects = ['01P', '02C']\n    subjects_and_tasks = read_processed_data.create_subjects_and_tasks(chosen_tasks, subjects)\n\n    # Check that the output is a list\n    assert isinstance(subjects_and_tasks, list)\n\n    # Check that the output has the correct length\n    assert len(subjects_and_tasks) == len(chosen_tasks) * len(subjects)\n\n    # Check that each element in the output is a tuple with two elements\n    for element in subjects_and_tasks:\n        assert isinstance(element, tuple)\n        assert len(element) == 2", "\ndef test_read_data():\n    # NOTE> This is only testing for 'thin' bands.\n    # NOTE: I should check if data is empty?\n    # Create temporary directory and dummy data\n    tmp_dir = tempfile.mkdtemp()\n    subjects_and_tasks = [('01P', 'ec_1'), ('01P', 'ec_2'), ('01P', 'ec_3')]\n    freq_bands = 'thin'\n    normalization = False\n    \n    # Create dummy data files in the temporary directory\n    for subject, task in subjects_and_tasks:\n        subject_dir = os.path.join(tmp_dir, f'sub-{subject}', 'ses-01', 'eeg', 'bandpowers')\n        os.makedirs(subject_dir, exist_ok=True)\n        # Create random data for \n        data = np.random.rand(89, 64)\n        filename = f'{freq_bands}_{task}.csv'\n        filepath = os.path.join(subject_dir, filename)\n        np.savetxt(filepath, data, delimiter=',')\n\n    # Call the method with the temporary directory and dummy data\n    processed_data_dir = tmp_dir\n    result = read_processed_data.read_data(subjects_and_tasks, freq_bands, normalization, processed_data_dir)\n\n    # Check that the output has the expected shape\n    expected_shape = (len(subjects_and_tasks), channels*38)\n    assert np.shape(result) == expected_shape, f\"Output has shape {np.shape(result)}, but expected shape is {expected_shape}\"\n\n    # Remove the temporary directory\n    shutil.rmtree(tmp_dir)", "\ndef test_create_data_frame():\n    # define subjects_and_tasks: list of 2-uples (same as above?)\n    subjects_and_tasks = [('01P', 'ec_1'), ('01P', 'ec_2'), ('01C', 'ec_1'), ('01C', 'ec_2'),]\n    # define all_bands_vectors\n    all_bands_vectors = np.random.rand(len(subjects_and_tasks), channels*38)\n    \n    dataframe = read_processed_data.create_data_frame(subjects_and_tasks, all_bands_vectors)\n    assert isinstance(dataframe, pd.DataFrame), \"Output is not a Pandas DataFrame\"\n    assert dataframe.shape == (len(subjects_and_tasks), channels*38 + 2), \"Dimensions of DataFrame are wrong\"\n    assert dataframe[\"Subject\"].dtype == 'object', \"Some subjects are not strings\"\n    assert dataframe[\"Group\"].dtype == 'int64', \"Some groups are not integers\"", "\ndef test_create_data_frame_empty_subjects_and_tasks():\n    all_bands_vectors = np.random.rand(4, channels*38)\n    subjects_and_tasks = []\n    with pytest.raises(ValueError) as e:\n       read_processed_data.create_data_frame(subjects_and_tasks, all_bands_vectors)\n    assert str(e.value) == \"The list of subject-task combinations cannot be empty.\"\n\ndef test_create_data_frame_empty_bands_vectors():\n    #all_bands_vectors = np.random.rand(len(subjects_and_tasks), channels*38)\n\n    subjects_and_tasks = [('01P', 'ec_1'), ('01P', 'ec_2'), ('01C', 'ec_1'), ('01C', 'ec_2'),]\n    all_bands_vectors = []\n    with pytest.raises(ValueError) as e:\n       read_processed_data.create_data_frame(subjects_and_tasks, all_bands_vectors)\n    assert str(e.value) == \"The list of PSD data cannot be empty.\"", "def test_create_data_frame_empty_bands_vectors():\n    #all_bands_vectors = np.random.rand(len(subjects_and_tasks), channels*38)\n\n    subjects_and_tasks = [('01P', 'ec_1'), ('01P', 'ec_2'), ('01C', 'ec_1'), ('01C', 'ec_2'),]\n    all_bands_vectors = []\n    with pytest.raises(ValueError) as e:\n       read_processed_data.create_data_frame(subjects_and_tasks, all_bands_vectors)\n    assert str(e.value) == \"The list of PSD data cannot be empty.\"\n    \n", "    \n\n\n\n\n"]}
{"filename": "src/config_common.py", "chunked_list": ["\"\"\"\n===========\nConfig file\n===========\n\nConfiguration parameters related to the users\n\n\"\"\"\n\nimport os", "\nimport os\nfrom getpass import getuser\nfrom socket import gethostname\n\n###############################################################################\n# Determine which user is running the scripts on which machine and set the path\n# where the data is stored and how many CPU cores to use.\n##############################################################################\n", "##############################################################################\n\nuser = getuser()  # Username of the user running the scripts\nhost = gethostname()  # Hostname of the machine running the scripts\n\n# You want to add your machine to this list\nif host == 'nbe-077' and user == 'heikkiv7':\n    # Verna's workstation in Aalto\n    raw_data_dir = '/m/nbe/scratch/tbi-meg/verna/BIDS'\n    processed_data_dir = '/m/nbe/scratch/tbi-meg/verna/k22_processed'\n    reports_dir = '/m/nbe/scratch/tbi-meg/verna/reports'\n    figures_dir = '/m/nbe/scratch/tbi-meg/verna/k22_processedfigures'\n    n_jobs = 4\n    matplotlib_backend = 'Qt5Agg'\nelif host.endswith('triton.aalto.fi'):\n    # Triton cluster\n    raw_data_dir = '/m/nbe/scratch/brrr_fingerprinting/biomagtbi_bids/bids'\n    processed_data_dir = '/m/nbe/scratch/brrr_fingerprinting/biomagtbi_bids/bids/derivatives/biomag-tbi'\n    reports_dir = '/home/vanvlm1/data/biomag-tbi/reports'\n    figures_dir = '/home/vanvlm1/data/biomag-tbi/figures'\n    n_jobs = 1\n    matplotlib_backend = 'Agg'  # No graphics on triton\nelif host == 'sirius' and user == 'heikkiv' : \n    # Verna's workstation in BioMag\n    raw_data_dir = '/net/theta/fishpool/projects/tbi_meg/BIDS'\n    processed_data_dir = '/net/theta/fishpool/projects/tbi_meg/k22_processed'\n    reports_dir = os.path.join('/net/tera2/home/heikkiv/work_s2022/mtbi_meeg/output/reports',user)\n    figures_dir = os.path.join('/net/tera2/home/heikkiv/work_s2022/mtbi_meeg/output/figures',user)\n    n_jobs = 4\n    matplotlib_backend = 'Qt5Agg'\nelif host == 'ypsilon.biomag.hus.fi' and user == 'heikkiv':\n    raw_data_dir = '/net/theta/fishpool/projects/tbi_meg/BIDS'\n    processed_data_dir = '/net/theta/fishpool/projects/tbi_meg/k22_processed'\n    reports_dir = os.path.join('/net/tera2/home/heikkiv/work_s2022/mtbi_meeg/output/reports',user)\n    figures_dir = os.path.join('/net/tera2/home/heikkiv/work_s2022/mtbi_meeg/output/reports',user)\n    n_jobs = 4\n    matplotlib_backend = 'Qt5Agg'\nelif host == 'psi' and user == 'aino' :\n    # Ainos's workstation in BioMag\n    raw_data_dir = '/net/theta/fishpool/projects/tbi_meg/BIDS'\n    processed_data_dir = '/net/theta/fishpool/projects/tbi_meg/k22_processed'\n    reports_dir = os.path.join('/net/tera2/home/aino/work/mtbi-eeg/src/reports', user)\n    figures_dir = os.path.join('/net/tera2/home/aino/work/mtbi-eeg/src/figures',user)\n    n_jobs = 4\n    matplotlib_backend = 'Qt5Agg'\nelif host == 'rho' and user == 'portae1' :\n    # Estanislao's workstation in BioMag\n    raw_data_dir = '/net/theta/fishpool/projects/tbi_meg/BIDS'\n    processed_data_dir = '/net/theta/fishpool/projects/tbi_meg/k22_processed'\n    reports_dir = os.path.join('/net/tera2/home/portae1/biomag/mtbi_meeg/output/reports', user)\n    figures_dir = os.path.join('/net/tera2/home/portae1/biomag/mtbi_meeg/output/figures', user)\n    n_jobs = 4\n    matplotlib_backend = 'Qt5Agg' \nelif 'vdiubuntu' in host and user == 'portae1' :\n    # Estanislao's workstation in VirtualMachine Aalto\n    raw_data_dir = '/m/home/home2/20/portae1/unix/biomag/k22_processed' #This is not in use actually\n    processed_data_dir = '/m/home/home2/20/portae1/unix/biomag/k22_processed'\n    reports_dir = '/m/home/home2/20/portae1/unix/biomag/mtbi_meeg/output/reports'\n    figures_dir = '/m/home/home2/20/portae1/unix/biomag/mtbi_meeg/output/figures'\n    n_jobs = 4\n    matplotlib_backend = 'Qt5Agg' \n## Add new users below\n# elif host == '<WORKSTATION>' and user == '<USER>' :\n#    # <USER>'s workstation in <WORKPLACE>\n#    raw_data_dir = ''\n#    processed_data_dir = ''\n#    reports_dir = ''\n#    figures_dir = ''\n#    n_jobs = 4\n#    matplotlib_backend = '' \n\nelse:\n    raise ValueError(f'User or host not recognized. \\nPlease enter the details of your system ({user}@{host}) in config_common.py')", "\n# For BLAS to use the right amount of cores\nos.environ['OMP_NUM_THREADS'] = str(n_jobs)\n\n# Configure the graphics backend\nimport matplotlib\nmatplotlib.use(matplotlib_backend)\n"]}
{"filename": "src/config_eeg.py", "chunked_list": ["\"\"\"\nThese are all the relevant parameters that are unique to the EEG analysis\npipeline.\n\"\"\"\n\nimport os \nfrom fnames import FileNames\nfrom config_common import (raw_data_dir, processed_data_dir, figures_dir,\n                           reports_dir)\n", "                           reports_dir)\n\n\ntasks = ['ec', 'eo', 'PASAT']\n\n\n###############################################################################\n# Parameters that should be mentioned in the paper\n\n# Seed to be used in the initialization of the classifiers and the CV", "\n# Seed to be used in the initialization of the classifiers and the CV\nseed =  8\n\n# Channels from the eeg measurment\nchannels = 64\n\n# Folds for cv\nfolds = 10\n", "folds = 10\n\n# Computation of the PSDs\nn_fft = 2048  # Higher number means more resolution at the lower frequencies\n#1024?4096?\n\n# Highpass filter above 1Hz. This is needed for the ICA to perform well\n# later on. Lowpass filter below 100Hz to get rid of the signal produced by\n# the cHPI coils. Notch filters at 50Hz and 100Hz to get rid of powerline.\nfreq_min = 1", "# the cHPI coils. Notch filters at 50Hz and 100Hz to get rid of powerline.\nfreq_min = 1\nfreq_max = 43\nfilt_freq_max = 90\nfnotch = [50, 100]\n\nthin_bands = [(x, x+1) for x in range(1, 43)] # thin_bands = (1,2),...., (42,43)\nwide_bands =  [(1,3), (3,5.2), (5.2,7.6), (7.6,10.2), (10.2,13), (13,16), (16,19.2), \n               (19.2,22.6), (22.6,26.2), (26.2,30), (30,34), (34,38.2), (38.2,42.6)]\n", "               (19.2,22.6), (22.6,26.2), (26.2,30), (30,34), (34,38.2), (38.2,42.6)]\n\n\n###############################################################################\n# Parameters pertaining to the subjects\n\n## All subjects for which there is some form of data available\nall_subjects = os.listdir(raw_data_dir)\n# Filter in directories-only\nall_subjects = [s for s in all_subjects if os.path.isdir(os.path.join(raw_data_dir, s))] # filter out non-directories", "# Filter in directories-only\nall_subjects = [s for s in all_subjects if os.path.isdir(os.path.join(raw_data_dir, s))] # filter out non-directories\n# Remove file 'participants.tsv' if it exists\nif 'participants.tsv' in all_subjects:\n    all_subjects.remove('participants.tsv')\n# Remove the 'sub-' prefix from the list\nall_subjects = [x.replace('sub-', '') for x in all_subjects]\n\n\nbad_subjects= []", "\nbad_subjects= []\n# Analysis is performed on these subjects\nsubjects = [subject for subject in all_subjects if subject not in bad_subjects]\n\necg_channel = 'ECG002'\neog_channel = 'EOG001'\nbads={}\n\n#Bad EEG channels for each subject and each task", "\n#Bad EEG channels for each subject and each task\nec_bads = {\n        '01C': ['EEG033', 'EEG025', 'EEG023'],\n        '02C': [],\n        '03C': ['EEG044'],\n        '04C': ['EEG026', 'EEG045', 'EEG027', 'EEG049'],\n        '05C': ['EEG003', 'EEG010', 'EEG057'],\n        '06C':['EEG001', 'EEG013', 'EEG020', 'EEG022', 'EEG027', 'EEG026', 'EEG023', 'EEG018', 'EEG019', 'EEG012', 'EEG011'],\n        '07C': [],", "        '06C':['EEG001', 'EEG013', 'EEG020', 'EEG022', 'EEG027', 'EEG026', 'EEG023', 'EEG018', 'EEG019', 'EEG012', 'EEG011'],\n        '07C': [],\n        '08C': ['EEG003', 'EEG007', 'EEG004', 'EEG008'],\n        '09C': ['EEG011', 'EEG018'],\n        '10C':['EEG019', 'EEG018', 'EEG011'],\n        '11C': ['EEG029'],\n        '12C':['EEG016', 'EEG033', 'EEG023'],\n        '13C': ['EEG019'],\n        '14C':['EEG003', 'EEG018', 'EEG007', 'EEG008', 'EEG004', 'EEG014', 'EEG015', 'EEG033', 'EEG023'],\n        '15C':['EEG018', 'EEG019', 'EEG011', 'EEG033', 'EEG023', 'EEG055', 'EEG063'],", "        '14C':['EEG003', 'EEG018', 'EEG007', 'EEG008', 'EEG004', 'EEG014', 'EEG015', 'EEG033', 'EEG023'],\n        '15C':['EEG018', 'EEG019', 'EEG011', 'EEG033', 'EEG023', 'EEG055', 'EEG063'],\n        '16C':['EEG043', 'EEG018', 'EEG019'],\n        '17C': ['EEG005', 'EEG020', 'EEG026', 'EEG028', 'EEG023', 'EEG027', 'EEG017'],\n        '18C':['EEG007', 'EEG008', 'EEG004', 'EEG034'],\n        '19C':['EEG004', 'EEG008', 'EEG007', 'EEG022', 'EEG043'],\n        '20C':['EEG044', 'EEG045', 'EEG052', 'EEG059'],\n        '21C':['EEG003', 'EEG010', 'EEG012', 'EEG019', 'EEG029', 'EEG030', 'EEG042', 'EEG046', 'EEG059', 'EEG062', 'EEG061'],\n        '22C': [],#really bad eeg\n        '23C':['EEG003', 'EEG018', 'EEG027', 'EEG025', 'EEG037'],", "        '22C': [],#really bad eeg\n        '23C':['EEG003', 'EEG018', 'EEG027', 'EEG025', 'EEG037'],\n        '24C':['EEG013', 'EEG020', 'EEG001', 'EEG022', 'EEG027', 'EEG029', 'EEG028', 'EEG047'],\n        '25C':['EEG001', 'EEG002', 'EEG013', 'EEG017', 'EEG022', 'EEG023', 'EEG026', 'EEG027', 'EEG028'],\n        '26C':['EEG034', 'EEG035', 'EEG037', 'EEG050', 'EEG048', 'EEG042', 'EEG043', 'EEG049', 'EEG047'],\n        '27C':['EEG033', 'EEG058'],\n        '28C':['EEG019', 'EEG056'],#first 30 s bad\n        '29C':['EEG023', 'EEG033'],\n        '30C':[],\n        '31C':['EEG001', 'EEG002', 'EEG013', 'EEG032', 'EEG028', 'EEG027', 'EEG026', 'EEG023', 'EEG022', 'EEG050', 'EEG003'],", "        '30C':[],\n        '31C':['EEG001', 'EEG002', 'EEG013', 'EEG032', 'EEG028', 'EEG027', 'EEG026', 'EEG023', 'EEG022', 'EEG050', 'EEG003'],\n        '32C':['EEG003', 'EEG060'],\n        '33C':['EEG001', 'EEG003', 'EEG020', 'EEG026', 'EEG028', 'EEG027', 'EEG056'],\n        '34C':[],\n        '35C':['EEG006', 'EEG003', 'EEG028'],\n        '36C':['EEG003', 'EEG006'],\n        '37C':['EEG003', 'EEG001', 'EEG017', 'EEG013', 'EEG005', 'EEG020', 'EEG014', 'EEG022', 'EEG023', 'EEG027', 'EEG028'],\n        '38C':['EEG019', 'EEG022', 'EEG023'],\n        '39C':['EEG018', 'EEG011', 'EEG010'],", "        '38C':['EEG019', 'EEG022', 'EEG023'],\n        '39C':['EEG018', 'EEG011', 'EEG010'],\n        '40C':[],\n        '41C':['EEG007', 'EEG063', 'EEG062', 'EEG064', 'EEG055'],#\"karvaisia kanavia\"\n        '01P':[],\n        '02P':['EEG013', 'EEG017', 'EEG022', 'EEG027'],\n        '03P':['EEG005', 'EEG022', 'EEG023', 'EEG027', 'EEG032', 'EEG028'],\n        '04P':['EEG018'],\n        '05P':[],\n        '06P':['EEG013', 'EEG012', 'EEG032', 'EEG026', 'EEG022', 'EEG023'],", "        '05P':[],\n        '06P':['EEG013', 'EEG012', 'EEG032', 'EEG026', 'EEG022', 'EEG023'],\n        '07P':[],\n        '08P':['EEG027', 'EEG042'],\n        '09P':['EEG009', 'EEG013', 'EEG035'],\n        '10P': [], #a lot of eye movement and heart artifacts\n        '11P':[],\n        '12P':[],\n        '13P':['EEG029', 'EEG038', 'EEG042'],\n        '14P':['EEG018', 'EEG007', 'EEG014', 'EEG027', 'EEG026', 'EEG043', 'EEG048'],", "        '13P':['EEG029', 'EEG038', 'EEG042'],\n        '14P':['EEG018', 'EEG007', 'EEG014', 'EEG027', 'EEG026', 'EEG043', 'EEG048'],\n        '15P':['EEG039', 'EEG044', 'EEG056', 'EEG059', 'EEG060', 'EEG046', 'EEG063'],\n        '16P':['EEG017', 'EEG016', 'EEG021', 'EEG028'],\n        '17P':['EEG017'],#001-007 \"karvaisia\"\n        '18P':['EEG017', 'EEG020', 'EEG009', 'EEG022', 'EEG023', 'EEG026', 'EEG028', 'EEG048', 'EEG047'],\n        '19P':['EEG007', 'EEG014', 'EEG008', 'EEG015'],\n        '20P':['EEG010', 'EEG014', 'EEG007', 'EEG008', 'EEG009'],\n        '21P':['EEG004', 'EEG030', 'EEG052', 'EEG061'],#a lot of eye movements\n        '22P':['EEG017', 'EEG020', 'EEG019', 'EEG013', 'EEG018', 'EEG022', 'EEG028', 'EEG026'],", "        '21P':['EEG004', 'EEG030', 'EEG052', 'EEG061'],#a lot of eye movements\n        '22P':['EEG017', 'EEG020', 'EEG019', 'EEG013', 'EEG018', 'EEG022', 'EEG028', 'EEG026'],\n        '23P':['EEG007', 'EEG004', 'EEG003', 'EEG014'],\n        '24P':['EEG023', 'EEG033', 'EEG035', 'EEG042'],\n        '25P':['EEG004', 'EEG007', 'EEG023', 'EEG033'],\n        '26P':['EEG007', 'EEG004', 'EEG029', 'EEG050'],\n        '27P':['EEG010', 'EEG027'],\n        '28P':['EEG003'],\n        '29P':['EEG001', 'EEG003', 'EEG020', 'EEG019', 'EEG013', 'EEG005', 'EEG027', 'EEG022'],\n        '30P':['EEG003', 'EEG004', 'EEG007', 'EEG008', 'EEG026', 'EEG029'],", "        '29P':['EEG001', 'EEG003', 'EEG020', 'EEG019', 'EEG013', 'EEG005', 'EEG027', 'EEG022'],\n        '30P':['EEG003', 'EEG004', 'EEG007', 'EEG008', 'EEG026', 'EEG029'],\n        '31P':['EEG003', 'EEG007', 'EEG011', 'EEG028', 'EEG027', 'EEG034'],\n        }#channels 11, 18, 19 were quite flat in general\n\neo_bads = {\n        \"01C\": ['EEG023', 'EEG025', 'EEG033'],\n        '02C': ['EEG040'],\n        '03C': ['EEG044'],\n        '04C':['EEG026', 'EEG036', 'EEG028', 'EEG027', 'EEG032', 'EEG045', 'EEG047', 'EEG043', 'EEG054', 'EEG049'],", "        '03C': ['EEG044'],\n        '04C':['EEG026', 'EEG036', 'EEG028', 'EEG027', 'EEG032', 'EEG045', 'EEG047', 'EEG043', 'EEG054', 'EEG049'],\n        '05C':['EEG003', 'EEG010', 'EEG057', 'EEG053', 'EEG062'],\n        '06C': ['EEG001', 'EEG013', 'EEG020', 'EEG022', 'EEG023', 'EEG026', 'EEG027'],\n        '07C':['EEG032', 'EEG041'],\n        '08C':['EEG003', 'EEG028'],#a lot of eye movements \n        '09C':['EEG020'],\n        '10C':['EEG014'],\n        '11C':['EEG007', 'EEG004', 'EEG003', 'EEG008', 'EEG015', 'EEG029', 'EEG032'],\n        '12C':['EEG016', 'EEG008', 'EEG023', 'EEG033'],", "        '11C':['EEG007', 'EEG004', 'EEG003', 'EEG008', 'EEG015', 'EEG029', 'EEG032'],\n        '12C':['EEG016', 'EEG008', 'EEG023', 'EEG033'],\n        '13C':['EEG042'],\n        '14C':['EEG003', 'EEG014', 'EEG023', 'EEG033'],\n        '15C':['EEG023', 'EEG033', 'EEG055'],\n        '16C':['EEG012', 'EEG043'],\n        '17C':['EEG003', 'EEG005', 'EEG017', 'EEG026', 'EEG023', 'EEG028', 'EEG027'],\n        '18C': ['EEG034'],\n        '19C':['EEG022', 'EEG043'],\n        '20C':['EEG012', 'EEG032', 'EEG044', 'EEG045', 'EEG059', 'EEG052', 'EEG058', 'EEG053', 'EEG054', 'EEG064'],", "        '19C':['EEG022', 'EEG043'],\n        '20C':['EEG012', 'EEG032', 'EEG044', 'EEG045', 'EEG059', 'EEG052', 'EEG058', 'EEG053', 'EEG054', 'EEG064'],\n        '21C':['EEG003', 'EEG010', 'EEG012', 'EEG019', 'EEG005', 'EEG007', 'EEG029', 'EEG030', 'EEG024', 'EEG042', 'EEG046', 'EEG059', 'EEG062', 'EEG053'],\n        '22C':[], #very bad eeg\n        '23C':['EEG018', 'EEG027', 'EEG025', 'EEG037', 'EEG034'],\n        '24C':['EEG017', 'EEG013', 'EEG020', 'EEG003', 'EEG001', 'EEG027', 'EEG022', 'EEG029', 'EEG028', 'EEG047'],\n        '25C':['EEG013', 'EEG001', 'EEG002', 'EEG022', 'EEG023', 'EEG026', 'EEG027', 'EEG028', 'EEG048', 'EEG049'],\n        '26C':['EEG035', 'EEG034', 'EEG037', 'EEG042', 'EEG043', 'EEG048', 'EEG050', 'EEG047', 'EEG049', 'EEG056'],\n        '27C':['EEG033', 'EEG058'],\n        '28C': ['EEG019', 'EEG013', 'EEG028', 'EEG058'],", "        '27C':['EEG033', 'EEG058'],\n        '28C': ['EEG019', 'EEG013', 'EEG028', 'EEG058'],\n        '29C':['EEG007', 'EEG018', 'EEG009', 'EEG023', 'EEG033', 'EEG032'],\n        '30C':[],\n        '31C':['EEG001', 'EEG002', 'EEG013', 'EEG003', 'EEG022', 'EEG023', 'EEG026', 'EEG027', 'EEG028', 'EEG032', 'EEG050'],\n        '32C':['EEG003', 'EEG060'],\n        '33C':['EEG001', 'EEG003', 'EEG020', 'EEG013', 'EEG026', 'EEG028', 'EEG027', 'EEG056'],\n        '34C':[],\n        '35C':['EEG013', 'EEG007', 'EEG008', 'EEG034', 'EEG032', 'EEG043', 'EEG047'],#ekg?\n        '36C':['EEG006', 'EEG003', 'EEG028'],", "        '35C':['EEG013', 'EEG007', 'EEG008', 'EEG034', 'EEG032', 'EEG043', 'EEG047'],#ekg?\n        '36C':['EEG006', 'EEG003', 'EEG028'],\n        '37C': ['EEG017', 'EEG013', 'EEG005', 'EEG020', 'EEG003', 'EEG001', 'EEG027', 'EEG023', 'EEG022'],\n        '38C':['EEG001', 'EEG008', 'EEG015', 'EEG035', 'EEG023'],\n        '39C':['EEG018', 'EEG015', 'EEG002', 'EEG010', 'EEG009', 'EEG011'],\n        '40C':[],\n        '41C':['EEG064', 'EEG063', 'EEG062'],\n        '01P':['EEG004', 'EEG017'],\n        '02P':['EEG017', 'EEG003', 'EEG013', 'EEG022', 'EEG027', 'EEG061', 'EEG056'],\n        '03P':['EEG005', 'EEG013', 'EEG022', 'EEG023', 'EEG027', 'EEG032', 'EEG038'],", "        '02P':['EEG017', 'EEG003', 'EEG013', 'EEG022', 'EEG027', 'EEG061', 'EEG056'],\n        '03P':['EEG005', 'EEG013', 'EEG022', 'EEG023', 'EEG027', 'EEG032', 'EEG038'],\n        '04P':['EEG018', 'EEG003', 'EEG024', 'EEG032', 'EEG044', 'EEG055', 'EEG062'],\n        '05P':['EEG014', 'EEG032'],\n        '06P':['EEG013', 'EEG012', 'EEG022', 'EEG023', 'EEG026', 'EEG032'],\n        '07P':['EEG008'],\n        '08P':['EEG027', 'EEG024', 'EEG042'],\n        '09P':['EEG009', 'EEG035'],\n        '10P':[], #heart artefact\n        '11P':[],", "        '10P':[], #heart artefact\n        '11P':[],\n        '12P':[],\n        '13P':['EEG013', 'EEG038'],\n        '14P':['EEG018', 'EEG027', 'EEG043', 'EEG048'],\n        '15P':['EEG015', 'EEG014', 'EEG044', 'EEG056', 'EEG059', 'EEG060', 'EEG046', 'EEG063'],\n        '16P':['EEG016', 'EEG017', 'EEG032'],\n        '17P':['EEG017'],#001-007 \"karvaisia\"\n        '18P':['EEG017', 'EEG020', 'EEG001', 'EEG003', 'EEG026', 'EEG023', 'EEG022', 'EEG028', 'EEG047', 'EEG048'],\n        '19P':[], #a lot of blinking", "        '18P':['EEG017', 'EEG020', 'EEG001', 'EEG003', 'EEG026', 'EEG023', 'EEG022', 'EEG028', 'EEG047', 'EEG048'],\n        '19P':[], #a lot of blinking\n        '20P':['EEG014', 'EEG027', 'EEG061'],\n        '21P':['EEG052'], #a lot of eye movements\n        '22P':['EEG017', 'EEG019', 'EEG020', 'EEG018', 'EEG013', 'EEG022', 'EEG028', 'EEG041'],\n        '23P':[],\n        '24P':['EEG023', 'EEG033', 'EEG035'],\n        '25P':['EEG023', 'EEG033'], #001-007 \"karvaisia\"\n        '26P':[],\n        '27P':['EEG027'],", "        '26P':[],\n        '27P':['EEG027'],\n        '28P':['EEG003'],\n        '29P':['EEG001', 'EEG003', 'EEG005', 'EEG019', 'EEG020', 'EEG026', 'EEG027', 'EEG022', 'EEG023', 'EEG048', 'EEG042'],\n        '30P':[], #\"karvaisia kanavia\"\n        '31P':['EEG003', 'EEG007', 'EEG027', 'EEG028', 'EEG045'] #a lot of blinking       \n        }\npasat1_bads = {#pasats are shorter\n        '01C': ['EEG033', 'EEG025', 'EEG023'],\n        '02C': ['EEG016', 'EEG053', 'EEG054'],", "        '01C': ['EEG033', 'EEG025', 'EEG023'],\n        '02C': ['EEG016', 'EEG053', 'EEG054'],\n        '03C': ['EEG044'],\n        '04C': ['EEG049', 'EEG045', 'EEG043', 'EEG038'], #a lot of bad data\n        '05C': [],\n        '06C':['EEG001', 'EEG020', 'EEG027', 'EEG023', 'EEG022', 'EEG026'],\n        '07C': [],\n        '08C': ['EEG003'],\n        '09C': ['EEG027'],\n        '10C':[],", "        '09C': ['EEG027'],\n        '10C':[],\n        '11C': ['EEG029', 'EEG032'],#karvaisia kanavia 1-7, bad eog, weird ecg\n        '12C':['EEG016', 'EEG033', 'EEG027', 'EEG023'],\n        '13C':  ['EEG003', 'EEG007'],\n        '14C':['EEG033', 'EEG023', 'EEG063'],\n        '15C':['EEG023', 'EEG033', 'EEG055'],\n        '16C':[],\n        '17C': ['EEG005', 'EEG017', 'EEG020', 'EEG027', 'EEG028', 'EEG026', 'EEG023'],\n        '18C':[],", "        '17C': ['EEG005', 'EEG017', 'EEG020', 'EEG027', 'EEG028', 'EEG026', 'EEG023'],\n        '18C':[],\n        '19C':['EEG011', 'EEG043'],\n        '20C': ['EEG033', 'EEG044', 'EEG045', 'EEG059', 'EEG052'],\n        '21C':['EEG012', 'EEG010', 'EEG007', 'EEG003', 'EEG030', 'EEG029', 'EEG024', 'EEG046', \n               'EEG059', 'EEG042', 'EEG062'],\n        '22C': [],#really bad eeg\n        '23C':['EEG003', 'EEG018', 'EEG025', 'EEG037', 'EEG027'],\n        '24C':['EEG001', 'EEG017', 'EEG013', 'EEG020', 'EEG022', 'EEG027', 'EEG029', 'EEG028'],\n        '25C':['EEG013', 'EEG001', 'EEG002', 'EEG017', 'EEG028', 'EEG027', 'EEG026', 'EEG023', 'EEG022'],", "        '24C':['EEG001', 'EEG017', 'EEG013', 'EEG020', 'EEG022', 'EEG027', 'EEG029', 'EEG028'],\n        '25C':['EEG013', 'EEG001', 'EEG002', 'EEG017', 'EEG028', 'EEG027', 'EEG026', 'EEG023', 'EEG022'],\n        '26C':['EEG034', 'EEG035', 'EEG037', 'EEG042', 'EEG043', 'EEG048', 'EEG050'],\n        '27C':['EEG033', 'EEG063'],\n        '28C':['EEG019', 'EEG038'],\n        '29C':['EEG009', 'EEG023', 'EEG033'],\n        '30C':[],\n        '31C':['EEG017', 'EEG001', 'EEG002', 'EEG003', 'EEG032', 'EEG022', 'EEG023', \n               'EEG027', 'EEG026', 'EEG028', 'EEG050'],#lot of blinks/otherwise quite bad data\n        '32C':['EEG003'],", "               'EEG027', 'EEG026', 'EEG028', 'EEG050'],#lot of blinks/otherwise quite bad data\n        '32C':['EEG003'],\n        '33C':['EEG001', 'EEG003', 'EEG020', 'EEG002', 'EEG026', 'EEG028', 'EEG027', \n               'EEG022', 'EEG023', 'EEG056', 'EEG060'],\n        '34C':[],\n        '35C':['EEG013', 'EEG012', 'EEG034', 'EEG030', 'EEG043', 'EEG047'],#eog, ecg wrong labels\n        '36C':['EEG003', 'EEG006'],\n        '37C':['EEG005', 'EEG017', 'EEG013', 'EEG002', 'EEG001', 'EEG003', 'EEG023', 'EEG022', 'EEG027'],\n        '38C':[],\n        '39C':['EEG018'],", "        '38C':[],\n        '39C':['EEG018'],\n        '40C':[],\n        '41C':[],\n        '01P':[],\n        '02P':['EEG003', 'EEG013', 'EEG017', 'EEG022', 'EEG027', 'EEG061'],\n        '03P':['EEG005', 'EEG001', 'EEG032', 'EEG027', 'EEG023', 'EEG022'],\n        '04P':['EEG018'],\n        '05P':[],\n        '06P':['EEG013', 'EEG022', 'EEG023', 'EEG026', 'EEG032', 'EEG056'],", "        '05P':[],\n        '06P':['EEG013', 'EEG022', 'EEG023', 'EEG026', 'EEG032', 'EEG056'],\n        '07P':[],\n        '08P':['EEG027', 'EEG042', 'EEG063'],#karvaisia kanavia\n        '09P':['EEG009', 'EEG035'],\n        '10P': ['EEG006'], #a lot of eye movement and heart artifacts\n        '11P':[],\n        '12P':[],\n        '13P': ['EEG038'],\n        '14P':['EEG018', 'EEG027', 'EEG043', 'EEG048'],", "        '13P': ['EEG038'],\n        '14P':['EEG018', 'EEG027', 'EEG043', 'EEG048'],\n        '15P':['EEG056', 'EEG059', 'EEG060', 'EEG044', 'EEG046', 'EEG057', 'EEG045', 'EEG063'],\n        '16P':[],\n        '17P':['EEG017'],#001-007 \"karvaisia\"\n        '18P':['EEG017', 'EEG020', 'EEG001', 'EEG026', 'EEG022', 'EEG027', 'EEG023', \n               'EEG039', 'EEG028', 'EEG037', 'EEG047'],\n        '19P':[],\n        '20P':['EEG061'],\n        '21P':[],", "        '20P':['EEG061'],\n        '21P':[],\n        '22P':['EEG001', 'EEG017', 'EEG019', 'EEG020', 'EEG013', 'EEG027', 'EEG028', 'EEG048'],\n        '23P':[],#karvaisia kanavia\n        '24P':['EEG023', 'EEG033', 'EEG032'],#karvaisia kanavia\n        '25P':['EEG003', 'EEG023', 'EEG033'],\n        '26P':['EEG003'],\n        '27P':['EEG027', 'EEG037', 'EEG049', 'EEG056'],\n        '28P':['EEG003', 'EEG007', 'EEG024'],\n        '29P':['EEG005', 'EEG001', 'EEG019', 'EEG020', 'EEG003', 'EEG022', 'EEG023', ", "        '28P':['EEG003', 'EEG007', 'EEG024'],\n        '29P':['EEG005', 'EEG001', 'EEG019', 'EEG020', 'EEG003', 'EEG022', 'EEG023', \n               'EEG026', 'EEG027', 'EEG063'],\n        '30P':['EEG058'],\n        '31P':['EEG003', 'EEG011', 'EEG007', 'EEG027', 'EEG046'],\n    }\npasat2_bads = {\n        '01C': ['EEG033', 'EEG025', 'EEG023'],\n        '02C': [],\n        '03C': ['EEG044'],", "        '02C': [],\n        '03C': ['EEG044'],\n        '04C': ['EEG026', 'EEG028', 'EEG038', 'EEG027', 'EEG045', 'EEG049', 'EEG043', 'EEG057', 'EEG064'], \n        '05C': ['EEG010'],\n        '06C':['EEG001', 'EEG020', 'EEG022', 'EEG023', 'EEG026', 'EEG027', 'EEG028'],\n        '07C': [],\n        '08C': ['EEG003'],\n        '09C': ['EEG027'], #horrible eog!!\n        '10C':[],\n        '11C': ['EEG029'],#karvaisia kanavia 1-7, dead eog, weird ecg", "        '10C':[],\n        '11C': ['EEG029'],#karvaisia kanavia 1-7, dead eog, weird ecg\n        '12C':['EEG016', 'EEG023', 'EEG033'],\n        '13C':  ['EEG003'],\n        '14C':['EEG023', 'EEG033'],\n        '15C':['EEG023', 'EEG033', 'EEG055'],\n        '16C':[],\n        '17C': ['EEG005', 'EEG017', 'EEG023', 'EEG026', 'EEG027', 'EEG028', 'EEG029'],\n        '18C':[],\n        '19C':['EEG043'],", "        '18C':[],\n        '19C':['EEG043'],\n        '20C':  ['EEG033', 'EEG044', 'EEG045', 'EEG059'],\n        '21C': ['EEG003', 'EEG010', 'EEG012', 'EEG019', 'EEG007', 'EEG030', 'EEG029', \n                'EEG039', 'EEG024', 'EEG046', 'EEG042', 'EEG059', 'EEG064', 'EEG062'],\n        '22C': [],#really bad eeg\n        '23C':['EEG018', 'EEG025', 'EEG027', 'EEG037'],\n        '24C':['EEG001', 'EEG013', 'EEG017', 'EEG027', 'EEG022', 'EEG028', 'EEG029', 'EEG047'],\n        '25C':['EEG013', 'EEG002', 'EEG001', 'EEG023', 'EEG026', 'EEG027', 'EEG028'],#two first seconds bad\n        '26C':['EEG018', 'EEG034', 'EEG035', 'EEG037', 'EEG042', 'EEG043', 'EEG048', 'EEG050', 'EEG049'],", "        '25C':['EEG013', 'EEG002', 'EEG001', 'EEG023', 'EEG026', 'EEG027', 'EEG028'],#two first seconds bad\n        '26C':['EEG018', 'EEG034', 'EEG035', 'EEG037', 'EEG042', 'EEG043', 'EEG048', 'EEG050', 'EEG049'],\n        '27C':['EEG003', 'EEG033'],\n        '28C':['EEG019'],\n        '29C':['EEG023', 'EEG033'],\n        '30C':[],\n        '31C':['EEG001', 'EEG002', 'EEG017', 'EEG022', 'EEG023', 'EEG026', 'EEG027', \n               'EEG028', 'EEG032', 'EEG050'],\n        '32C':['EEG003'],\n        '33C':['EEG001', 'EEG003', 'EEG013', 'EEG020', 'EEG023', 'EEG026', 'EEG027', ", "        '32C':['EEG003'],\n        '33C':['EEG001', 'EEG003', 'EEG013', 'EEG020', 'EEG023', 'EEG026', 'EEG027', \n               'EEG028', 'EEG022', 'EEG056'],\n        '34C':[],\n        '35C':['EEG013', 'EEG034'],#eog, ecg wrong labels\n        '36C':['EEG003', 'EEG006'],\n        '37C':['EEG005', 'EEG013', 'EEG017', 'EEG002', 'EEG022', 'EEG023', 'EEG027', 'EEG028'],\n        '38C':[],\n        '39C':[],\n        '40C':[],", "        '39C':[],\n        '40C':[],\n        '41C':['EEG014'],\n        '01P':[],\n        '02P':['EEG013', 'EEG017', 'EEG022', 'EEG027'],\n        '03P':['EEG003', 'EEG013', 'EEG032', 'EEG022', 'EEG023', 'EEG027'],\n        '04P':['EEG018'],\n        '05P':[],\n        '06P':['EEG013', 'EEG012', 'EEG022', 'EEG023', 'EEG026', 'EEG032'],\n        '07P':[],", "        '06P':['EEG013', 'EEG012', 'EEG022', 'EEG023', 'EEG026', 'EEG032'],\n        '07P':[],\n        '08P':['EEG027', 'EEG042'],#karvaisia kanavia\n        '09P':['EEG009', 'EEG018', 'EEG035'],\n        '10P':[], #a lot of eye movement and heart artifacts\n        '11P':[],\n        '12P':[],\n        '13P': ['EEG038'],\n        '14P':['EEG018', 'EEG027', 'EEG043', 'EEG048'],#a lot of eye artefacts\n        '15P':['EEG044', 'EEG056', 'EEG059', 'EEG060', 'EEG063'],", "        '14P':['EEG018', 'EEG027', 'EEG043', 'EEG048'],#a lot of eye artefacts\n        '15P':['EEG044', 'EEG056', 'EEG059', 'EEG060', 'EEG063'],\n        '16P':[],\n        '17P':['EEG017'],#karvaisia kanavia\n        '18P':['EEG020', 'EEG017', 'EEG026', 'EEG028', 'EEG022', 'EEG047'],\n        '19P':['EEG015'],\n        '20P':['EEG014', 'EEG061'],\n        '21P':[],\n        '22P':['EEG017', 'EEG019', 'EEG020', 'EEG022', 'EEG028', 'EEG048'],\n        '23P':[],", "        '22P':['EEG017', 'EEG019', 'EEG020', 'EEG022', 'EEG028', 'EEG048'],\n        '23P':[],\n        '24P':['EEG023', 'EEG033'],#a lot of eye artefacts\n        '25P':['EEG003', 'EEG023', 'EEG033'],\n        '26P':['EEG003'],\n        '27P':['EEG027', 'EEG056', 'EEG064', 'EEG061'],\n        '28P':['EEG003', 'EEG007', 'EEG028'],\n        '29P':['EEG001', 'EEG020', 'EEG005', 'EEG019', 'EEG022', 'EEG023', 'EEG026', 'EEG027'],\n        '30P':[],\n        '31P':['EEG003', 'EEG011'],", "        '30P':[],\n        '31P':['EEG003', 'EEG011'],\n    }\n###############################################################################\n# Templates for filenames\n#\n# This part of the config file uses the FileNames class. It provides a small\n# wrapper around string.format() to keep track of a list of filenames.\n# See fnames.py for details on how this class works.\nfname = FileNames()", "# See fnames.py for details on how this class works.\nfname = FileNames()\n\n# Some directories\nfname.add('raw_data_dir', raw_data_dir)\nfname.add('processed_data_dir', processed_data_dir)\n\n# Continuous data\nfname.add('raw', '{raw_data_dir}/sub-{subject}/ses-{ses}/meg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_proc-raw_meg.fif')\nfname.add('filt', '{processed_data_dir}/sub-{subject}/ses-01/eeg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_filt.fif')", "fname.add('raw', '{raw_data_dir}/sub-{subject}/ses-{ses}/meg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_proc-raw_meg.fif')\nfname.add('filt', '{processed_data_dir}/sub-{subject}/ses-01/eeg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_filt.fif')\nfname.add('clean', '{processed_data_dir}/sub-{subject}/ses-{ses}/eeg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_clean.fif')\n\n# Maxfilter\nfname.add('tsss', '{raw_data_dir}/sub-{subject}/ses-{ses}/meg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_proc-raw_meg_mc_tsss.fif')\nfname.add('pos', '{raw_data_dir}/sub-{subject}/ses-{ses}/meg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_movecomp.pos') \nfname.add('tsss_log', '{raw_data_dir}/sub-{subject}/ses-{ses}/meg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_tsss_log.log')\n\n", "\n\n# Files used during EOG and ECG artifact suppression\nfname.add('ica', '{processed_data_dir}/sub-{subject}/ses-{ses}/eeg/sub-{subject}_ses-{ses}_task-{task}_run-0{run}_ica.h5')\n\n# PSD files\nfname.add('psds', '{processed_data_dir}/sub-{subject}/ses-{ses}/eeg/sub-{subject}_psds.h5')\n\n# Band power files\nfname.add('bandpower', '{processed_data_dir}/sub-{subject}/ses-{ses}/eeg/sub-{subject}_bandpower.csv')", "# Band power files\nfname.add('bandpower', '{processed_data_dir}/sub-{subject}/ses-{ses}/eeg/sub-{subject}_bandpower.csv')\n\n# Filenames for MNE reports\nfname.add('reports_dir', f'{reports_dir}')\nfname.add('report', '{reports_dir}/sub-{subject}-report.h5')\nfname.add('report_html', '{reports_dir}/sub-{subject}-report.html')\n\n# Filenames for figures\nfname.add('figures_dir', f'{figures_dir}')", "# Filenames for figures\nfname.add('figures_dir', f'{figures_dir}')\nfname.add('figure_psds', '{figures_dir}/psds.pdf')\n\n\ndef get_all_fnames(subject, kind, ses='01', exclude=None):\n    \"\"\"Get all filenames for a given subject of a given kind.\n\n    Not all subjects have exactly the same files. For example, subject 1 does\n    not have an emptyroom recording, while subject 4 has 2 runs of emptyroom.\n    Use this function to get a list of the the files that are present for a\n    given subject. It will check which raw files there are and based on that\n    will generate a list with corresponding filenames of the given kind.\n\n    You can exclude the recordings for one or more tasks with the ``exclude``\n    parameter. For example, to skip the emptyroom recordings, set\n    ``exclude='emptyroom'``.\n\n    Parameters\n    ----------\n    subject : str\n        The subject to get the names of the raw files for.\n    kind : 'raw' | 'tsss' | 'filt' | 'eog_ecg_events' | 'ica'\n        The kind of files to return the filenames for.\n    ses: str\n        The measurement session (e.g. 01 or 02). Defaults to 01\n    exclude : None | str | list of str\n        The tasks to exclude from the list.\n        Defaults to not excluding anything.\n\n    Returns\n    -------\n    all_fnames : list of str\n        The names of the files of the given kind.\n    \"\"\"\n    import os.path as op\n\n    if exclude is None:\n        exclude = []\n    elif type(exclude) == str:\n        exclude = [exclude]\n    elif type(exclude) != list:\n        raise TypeError('The `exclude` parameter should be None, str or list')\n\n    all_fnames = list()\n    #print('Looking for: ' + str(fname.raw(subject=subject)))\n    for task in tasks:\n        if task in exclude:\n            continue\n        for run in [1, 2]:\n            if op.exists(fname.raw(subject=subject, ses=ses, task=task, run=run)):\n                all_fnames.append(fname.files()[f'{kind}'](subject=subject, ses=ses, task=task, run=run))\n    return all_fnames", "\n\ndef task_from_fname(fname):\n    \"\"\"Extract task name from a BIDS filename.\"\"\"\n    import re\n    match = re.search(r'task-([^_]+)_run-(\\d\\d)', str(fname))\n    task = match.group(1)\n    run = int(match.group(2))\n    if task == 'PASAT':\n        return f'{task}_run{run}'\n    else:\n        return task", "\ndef select_task_segments(task):\n    \"\"\"\n    Define the task segments to be used for the analysis\n    \n    \n    Input parameters\n    ---------\n    - task : str\n        Each of the four tasks that have been measured for this experiment: Eyes Closed (ec), Eyes Open (eo), Paced Auditory Serial Addition Test 1 or 2 (PASAT_1 or PASAT_2)\n    \n    Returns\n    -------\n    - chosen_tasks: The list of chosen task's segments \n    \"\"\"\n    # Segments present in each of the tasks\n    tasks = [['ec_1', 'ec_2', 'ec_3'], \n             ['eo_1', 'eo_2', 'eo_3'], \n             ['PASAT_run1_1', 'PASAT_run1_2'], \n             ['PASAT_run2_1', 'PASAT_run2_2']]\n       \n    # Define which files to read for each subject\n    if task == 'ec':\n        chosen_tasks = tasks[0]\n    elif task == 'eo':\n        chosen_tasks = tasks[1]\n    elif task == 'PASAT_1':\n        chosen_tasks = tasks[2]\n    elif task == 'PASAT_2': \n        chosen_tasks = tasks[3]\n    else:\n        raise(\"Incorrect task\")\n       \n    return chosen_tasks", ""]}
{"filename": "src/pickle_data_handler.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nClass that handles the loading (bundling) and un-loading (exporting) data from the pickle object.\n\n@author: Estanislao Porta\n\"\"\"\nimport os\nimport time\nimport pickle", "import time\nimport pickle\n\nclass PickleDataHandler:\n    \n    \n    @staticmethod\n    def export_data(dataframe, metadata):\n        if dataframe.empty:\n            raise ValueError(\"The dataframe cannot be empty.\")\n        if not isinstance(metadata, dict):\n            raise ValueError(\"Metadata must be a dictionary.\")\n        if not metadata:\n            raise ValueError(\"The metadata file cannot be empty.\")\n\n        try: \n            with open(\"eeg_tmp_data.pickle\", \"wb\") as f:\n                pickle.dump((dataframe, metadata), f)\n        except (TypeError, IOError) as e:\n            print(f'An error occurred: {e}')\n            return False\n        \n        print('INFO: CSV data and metadata have been bundled into file \"eeg_tmp_data.pickle\".')\n        return True\n    \n    @staticmethod\n    def load_data():  \n        # Check if the file exists.\n        file_path = \"eeg_tmp_data.pickle\"\n        if not os.path.exists(file_path):\n            print(\"The file 'eeg_tmp_data.pickle' does not exist in the current directory. The program will exit.\")\n            return False\n        # Check if the age of the file is older than 1 day.\n        file_age = time.time() - os.path.getmtime(file_path)\n        if file_age > 86400:\n            raise ValueError(\"The data file is older than 1 day.\")\n        \n        try:\n            with open(\"eeg_tmp_data.pickle\", \"rb\") as fin:\n                dataframe, metadata = pickle.load(fin)\n        except (IOError, TypeError) as e:\n            print(f'An error occurred: {e}')\n            return False\n        \n        if dataframe.empty:\n            raise ValueError(\"The dataframe is empty.\")\n        if not isinstance(metadata, dict):\n            raise ValueError(\"Metadata must be a dictionary.\")\n        if not metadata:\n            raise ValueError(\"The metadata file cannot be empty.\")\n            \n        print('INFO: CSV data and metadata have been read in from file \"eeg_tmp_data.pickle\".')\n        return dataframe, metadata"]}
{"filename": "src/fnames.py", "chunked_list": ["\"\"\"Utility class to manage a list of filenames.\n\nUse the `add` method to add new filenames. You specify a short \"alias\" for\nthem, which you can use to retrieve the full filename later:\n\n>>> fname = FileNames()\n>>> fname.add('my_file', '/path/to/file1'\n>>> fname.my_file\n'/path/to/file1'\n", "'/path/to/file1'\n\nFilenames can also be templates that can be used to generate\nfilenames for different subjects, conditions, etc.:\n\n>>> fname = FileNames()\n>>> fname.add('epochs', '/data/{subject}/{cond}-epo.fif')\n>>> fname.epochs(subject='sub001', cond='face')\n'/data/sub001/face-epo.fif'\n", "'/data/sub001/face-epo.fif'\n\nTemplates can contain placeholders in the way `string.format` allows,\nincluding formatting options:\n\n>>> fname = FileNames()\n>>> fname.add('epochs', '/data/sub{subject:03d}/{cond}-epo.fif')\n>>> fname.epochs(subject=1, cond='face')\n'/data/sub001/face-epo.fif'\n", "'/data/sub001/face-epo.fif'\n\nIf a placeholder happens to be the alias of a file that has been added earlier,\nthe placeholder is automatically filled:\n\n>>> fname = FileNames()\n>>> fname.add('subjects', '/data/subjects_dir')\n>>> fname.add('epochs', '{subjects}/{subject}/{cond}-epo.fif')\n>>> fname.epochs(subject='sub001', cond='face')\n'/data/subjects_dir/sub001/face-epo.fif'", ">>> fname.epochs(subject='sub001', cond='face')\n'/data/subjects_dir/sub001/face-epo.fif'\n\nIf all placeholders could be automatically filled, no brackets () are required\nwhen accessing it:\n\n>>> fname = FileNames()\n>>> fname.add('subjects', '/data/subjects_dir')\n>>> fname.add('fsaverage', '{subjects}/fsaverage-src.fif')\n>>> fname.fsaverage", ">>> fname.add('fsaverage', '{subjects}/fsaverage-src.fif')\n>>> fname.fsaverage\n'/data/subjects_dir/fsaverage-src.fif'\n\nIf computing the file path gets more complicated than the cases above, you can\nsupply your own function. When the filename is requested, your function will\nget called with the FileNames object as first parameter, followed by any\nparameters that were supplied along with the request:\n\n>>> fname = FileNames()", "\n>>> fname = FileNames()\n>>> fname.add('basedir', '/data/subjects_dir')\n>>> def my_function(files, subject):\n...     if subject == 1:\n...         return files.basedir + '/103hdsolli.fif'\n...     else:\n...         return files.basedir + '/%s.fif' % subject\n>>> fname.add('complicated', my_function)\n>>> fname.complicated(subject=1)", ">>> fname.add('complicated', my_function)\n>>> fname.complicated(subject=1)\n'/data/subjects_dir/103hdsolli.fif'\n\nAuthor: Marijn van Vliet <w.m.vanvliet@gmail.com>\n\"\"\"\nimport string\nfrom pathlib import Path\n\n\nclass FileNames(object):\n    \"\"\"Utility class to manage filenames.\"\"\"\n\n    def files(self):\n        \"\"\"Obtain a list of file aliases known to this FileNames object.\n\n        Returns\n        -------\n        files : list of str\n            The list of file aliases.\n        \"\"\"\n        files = dict()\n        for name, value in self.__dict__.items():\n            public_methods = ['list_filenames', 'add']\n            if not name.startswith('_') and name not in public_methods:\n                files[name] = value\n        return files\n\n    def add(self, alias, fname):\n        \"\"\"Add a new filename.\n\n        Parameters\n        ----------\n        alias : str\n            A short alias for the full filename. This alias can later be used\n            to retrieve the filename. Aliases can not start with '_' or a\n            number.\n        fname : str | function\n            The full filename. Either a string, with possible placeholder\n            values, or a function that will compute the filename. If you\n            specify a function, it will get called with the FileNames object as\n            first parameter, followed by any parameters that were supplied\n            along with the request.\n        \"\"\"\n        if callable(fname):\n            self._add_function(alias, fname)\n        else:\n            # Determine whether the string contains placeholders and whether\n            # all placeholders can be pre-filled with existing file aliases.\n            placeholders = _get_placeholders(fname)\n            if len(placeholders) == 0:\n                self._add_fname(alias, fname)  # Plain string filename\n            else:\n                prefilled = _prefill_placeholders(placeholders, self.files(),\n                                                  dict())\n                if len(prefilled) == len(placeholders):\n                    # The template could be completely pre-filled. Add the\n                    # result as a plain string filename.\n                    self._add_fname(alias, Path(fname.format(**prefilled)))\n                else:\n                    # Add filename as a template\n                    self._add_template(alias, fname)\n\n    def _add_fname(self, alias, fname):\n        \"\"\"Add a filename that is a plain string.\"\"\"\n        self.__dict__[alias] = Path(fname)\n\n    def _add_template(self, alias, template):\n        \"\"\"Add a filename that is a string containing placeholders.\"\"\"\n        # Construct a function that will do substitution for any placeholders\n        # in the template.\n        def fname(**kwargs):\n            return Path(_substitute(template, self.files(), kwargs))\n\n        # Bind the fname function to this instance of FileNames\n        self.__dict__[alias] = fname\n\n    def _add_function(self, alias, func):\n        \"\"\"Add a filename that is computed using a user-specified function.\"\"\"\n        # Construct a function that will call the user supplied function with\n        # the proper arguments. We prepend 'self' so the user supplied function\n        # has easy access to all the filepaths.\n        def fname(**kwargs):\n            return func(self, **kwargs)\n\n        # Bind the fname function to this instance of FileNames\n        self.__dict__[alias] = fname", "\n\nclass FileNames(object):\n    \"\"\"Utility class to manage filenames.\"\"\"\n\n    def files(self):\n        \"\"\"Obtain a list of file aliases known to this FileNames object.\n\n        Returns\n        -------\n        files : list of str\n            The list of file aliases.\n        \"\"\"\n        files = dict()\n        for name, value in self.__dict__.items():\n            public_methods = ['list_filenames', 'add']\n            if not name.startswith('_') and name not in public_methods:\n                files[name] = value\n        return files\n\n    def add(self, alias, fname):\n        \"\"\"Add a new filename.\n\n        Parameters\n        ----------\n        alias : str\n            A short alias for the full filename. This alias can later be used\n            to retrieve the filename. Aliases can not start with '_' or a\n            number.\n        fname : str | function\n            The full filename. Either a string, with possible placeholder\n            values, or a function that will compute the filename. If you\n            specify a function, it will get called with the FileNames object as\n            first parameter, followed by any parameters that were supplied\n            along with the request.\n        \"\"\"\n        if callable(fname):\n            self._add_function(alias, fname)\n        else:\n            # Determine whether the string contains placeholders and whether\n            # all placeholders can be pre-filled with existing file aliases.\n            placeholders = _get_placeholders(fname)\n            if len(placeholders) == 0:\n                self._add_fname(alias, fname)  # Plain string filename\n            else:\n                prefilled = _prefill_placeholders(placeholders, self.files(),\n                                                  dict())\n                if len(prefilled) == len(placeholders):\n                    # The template could be completely pre-filled. Add the\n                    # result as a plain string filename.\n                    self._add_fname(alias, Path(fname.format(**prefilled)))\n                else:\n                    # Add filename as a template\n                    self._add_template(alias, fname)\n\n    def _add_fname(self, alias, fname):\n        \"\"\"Add a filename that is a plain string.\"\"\"\n        self.__dict__[alias] = Path(fname)\n\n    def _add_template(self, alias, template):\n        \"\"\"Add a filename that is a string containing placeholders.\"\"\"\n        # Construct a function that will do substitution for any placeholders\n        # in the template.\n        def fname(**kwargs):\n            return Path(_substitute(template, self.files(), kwargs))\n\n        # Bind the fname function to this instance of FileNames\n        self.__dict__[alias] = fname\n\n    def _add_function(self, alias, func):\n        \"\"\"Add a filename that is computed using a user-specified function.\"\"\"\n        # Construct a function that will call the user supplied function with\n        # the proper arguments. We prepend 'self' so the user supplied function\n        # has easy access to all the filepaths.\n        def fname(**kwargs):\n            return func(self, **kwargs)\n\n        # Bind the fname function to this instance of FileNames\n        self.__dict__[alias] = fname", "\n\ndef _get_placeholders(template):\n    \"\"\"Get all placeholders from a template string.\n\n    Parameters\n    ----------\n    template : str\n        The template string to get the placeholders for.\n\n    Returns\n    -------\n    placeholders : list of str\n        The list of placeholder names that were found in the template string.\n    \"\"\"\n    return [p[1] for p in string.Formatter().parse(template)\n            if p[1] is not None and len(p[1]) > 0]", "\n\ndef _substitute(template, files, user_values):\n    \"\"\"Makes a filename from a template.\n\n    Any placeholders that point to known file aliases will be prefilled. The\n    rest is filled given the values provided by the user when requesting the\n    filename.\n\n    Parameters\n    ----------\n    template : str\n        The template string for the filename.\n    files : list of str\n        A list of file aliases that are already known.\n    user_values : dict\n        The key=value parameters that the user specified when requesting the\n        filename.\n\n    Returns\n    -------\n    filename : str\n        The filename, obtained by filling all the placeholders of the template\n        string.\n    \"\"\"\n    # Get all placeholder names\n    placeholders = _get_placeholders(template)\n\n    # Pre-fill placeholders based on existing file aliases\n    placeholder_values = _prefill_placeholders(placeholders, files,\n                                               user_values)\n\n    # Add user specified values for the placeholders\n    placeholder_values.update(**user_values)\n\n    # Check whether all placeholder values are now properly provided.\n    provided = set(placeholder_values.keys())\n    needed = set(placeholders)\n    missing = needed - provided\n    if len(missing) > 0:\n        raise ValueError('Cannot construct filename, because the following '\n                         'parameters are missing: %s' % missing)\n\n    # Do the substitution\n    return template.format(**placeholder_values)", "\n\ndef _prefill_placeholders(placeholders, files, user_values):\n    \"\"\"Search through existing file aliases to pre-fill placeholder values.\n\n    Parameters\n    ----------\n    placeholders : list of str\n        The list of placeholder names that were found in the template string.\n    files : list of str\n        A list of file aliases that are already known.\n    user_values : dict\n        The key=value parameters that the user specified when requesting the\n        filename. Can be empty if no parameters were specified (yet).\n\n    Returns\n    -------\n    placeholder_values : dict\n        A dictionary containing the values for the placeholders that could be\n        pre-filled.\n    \"\"\"\n    placeholder_values = dict()\n\n    for placeholder in placeholders:\n        if placeholder in files:\n            # Placeholder name is a filename, so get the path\n            path = files[placeholder]\n            if not isinstance(path, Path):\n                try:\n                    path = path(**user_values)\n                except ValueError:\n                    # Placeholder could not be pre-filled given the supplied\n                    # values by the user.\n                    continue\n\n            # Add the path as possible placeholder value\n            placeholder_values[placeholder] = path\n\n    return placeholder_values", ""]}
{"filename": "src/check_system.py", "chunked_list": ["\"\"\"\nThis script performs a series of checks on the system to see if everything is\nready to run the analysis pipeline.\n\"\"\"\n\nimport os\nimport pkg_resources\nimport mne\nfrom config_common import raw_data_dir, processed_data_dir, figures_dir, reports_dir\n", "from config_common import raw_data_dir, processed_data_dir, figures_dir, reports_dir\n\n# Check to see if the python dependencies are fullfilled.\ndependencies = []\nwith open('../requirements.txt') as f:\n    for line in f:\n        line = line.strip()\n        if len(line) == 0 or line.startswith('#'):\n            continue\n        dependencies.append(line)", "\n# This raises errors of dependencies are not met\ntry:\n    pkg_resources.working_set.require(dependencies)\nexcept pkg_resources.VersionConflict as e:\n    # Get the conflicting distribution and requirement\n    dist = e.dist\n    req = e.req\n\n    # Create a custom error message\n    error_message = f\"\\nVersion conflict:Library {dist} ({dist.location}) does not meet the requirements: {req}\"\n\n    # Raise a new exception with the custom error message\n    raise ValueError(error_message) from e", "\n# Check that the raw data directory is present on the system and raise error if doesnt exist\nif not os.path.exists(raw_data_dir):\n    raise ValueError(f'The `raw_data_dir` points to a directory that does not exist: {raw_data_dir}')\n\n# Make sure the processed data, figures and reports directories exist\nif not os.path.exists(processed_data_dir):\n    print(f'Creating directory {processed_data_dir}')\n    os.makedirs(processed_data_dir, exist_ok=True)\nif not os.path.exists(figures_dir):\n    print(f'Creating directory {figures_dir}')\n    os.makedirs(figures_dir, exist_ok=True)", "if not os.path.exists(figures_dir):\n    print(f'Creating directory {figures_dir}')\n    os.makedirs(figures_dir, exist_ok=True)\nif not os.path.exists(reports_dir):\n    print(f'Creating directory {reports_dir}')\n    os.makedirs(reports_dir, exist_ok=True)\n\n# Prints some information about the system\n#print('\\nNME dependencies installed in the system\\n------')\n#mne.sys_info()", "#print('\\nNME dependencies installed in the system\\n------')\n#mne.sys_info()\n#print('-------------')\n\nprint('INFO: Success! System requirements are met.\\n')\n"]}
{"filename": "src/processing/01_freqfilt.py", "chunked_list": ["\"\"\"\nPerform bandpass filtering and notch filtering to get rid of cHPI and powerline\nfrequencies.\n\n\nRunning:\nimport subprocess\nsubprocess.run('/net/tera2/home/heikkiv/work_s2022/mtbi-eeg/python/processing/eeg/runsome.sh', shell=True)\n\n\"\"\"", "\n\"\"\"\n\nimport argparse\nfrom collections import defaultdict\nfrom mne.io import read_raw_fif\nfrom mne import open_report, set_log_level\nimport datetime\nimport time\nimport os", "import time\nimport os\nimport sys\n\nparent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(parent_dir)\n\n# Save time of beginning of the execution to measure running time\nstart_time = time.time()\n", "start_time = time.time()\n\nfrom config_eeg import get_all_fnames, fname, ec_bads, eo_bads, pasat1_bads, pasat2_bads, freq_min, filt_freq_max, fnotch\n\n# Deal with command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nargs = parser.parse_args()\n\n# Along the way, we collect figures for quality control", "\n# Along the way, we collect figures for quality control\nfigures = defaultdict(list)\n\n# Not all subjects have files for all conditions. These functions grab the\n# files that do exist for the subject.\nexclude = ['emptyroom'] #these don't have eye blinks.\nall_fnames = zip(\n    get_all_fnames(args.subject, kind='raw', exclude=exclude),\n    get_all_fnames(args.subject, kind='filt', exclude=exclude),", "    get_all_fnames(args.subject, kind='raw', exclude=exclude),\n    get_all_fnames(args.subject, kind='filt', exclude=exclude),\n)\n\n# Date and time\nnow = datetime.datetime.now()\ndate_time = now.strftime('%A, %d. %B %Y %I:%M%p')\n\ncorrupted_raw_files = []\n\nfor raw_fname, filt_fname in all_fnames:\n    try:\n        raw = read_raw_fif(raw_fname, preload=True)\n    except NameError as e:\n        raise NameError(f'Subject {args.subject} does not exist') from e\n    except (IOError, ValueError) as error:\n        corrupted_raw_files.append(args.subject)\n        print(f'Error: {error}')\n        continue\n\n    \n    # Reduce logging level (technically, one could define it in the read_raw_fif function, but it seems to be buggy)\n    # More info about the bug can be found here: https://github.com/mne-tools/mne-python/issues/8872\n    set_log_level(verbose='Warning')\n\n    # Mark bad channels that were manually annotated earlier.\n    raw_str = str(raw_fname)\n    if 'task-ec' in raw_str:\n        raw.info['bads'] = ec_bads[args.subject]\n        task = 'ec'\n    elif 'task-eo' in raw_str:\n        raw.info['bads'] = eo_bads[args.subject]\n        task = 'eo'\n    elif 'task-PASAT' in raw_str and 'run-01' in raw_str:\n        raw.info['bads'] = pasat1_bads[args.subject]\n        task = 'pasat1'\n    elif 'task-PASAT' in raw_str and 'run-02' in raw_str:\n        raw.info['bads'] = pasat2_bads[args.subject]\n        task = 'pasat2'\n    \n    # Remove MEG channels. This is the EEG pipeline after all.\n    raw.pick_types(meg=False, eeg=True, eog=True, stim=True, ecg=True, exclude=[])\n    \n    # Plot segment of raw data\n    figures['raw segment'].append(raw.plot(n_channels=30, title = date_time, show=False))\n    \n    # Interpolate bad channels\n    raw.interpolate_bads()\n    figures['interpolated segment'].append(raw.plot(n_channels=30, title = date_time + task, show=False))\n    \n    # Add a plot of the power spectrum to the list of figures to be placed in\n    # the HTML report.\n    raw_plot = raw.compute_psd(fmin=freq_min, fmax=filt_freq_max).plot(show=False)\n    figures['before filt'].append(raw_plot)\n\n    # Remove 50Hz power line noise (and the first harmonic: 100Hz)\n    filt = raw.notch_filter(fnotch, picks=['eeg', 'eog', 'ecg'])\n    \n    # Apply bandpass filter\n    filt = filt.filter(l_freq=freq_min, h_freq=filt_freq_max, picks=['eeg', 'eog', 'ecg'])\n\n    # Save the filtered data\n    filt_fname.parent.mkdir(parents=True, exist_ok=True)\n    filt.save(filt_fname, overwrite=True)\n\n    # Add a plot of the power spectrum of the filtered data to the list of\n    # figures to be placed in the HTML report.\n    filt_plot = filt.plot_psd(fmin=freq_min, fmax=filt_freq_max, show=False)\n    figures['after filt'].append(filt_plot)\n    \n    raw.close()", "corrupted_raw_files = []\n\nfor raw_fname, filt_fname in all_fnames:\n    try:\n        raw = read_raw_fif(raw_fname, preload=True)\n    except NameError as e:\n        raise NameError(f'Subject {args.subject} does not exist') from e\n    except (IOError, ValueError) as error:\n        corrupted_raw_files.append(args.subject)\n        print(f'Error: {error}')\n        continue\n\n    \n    # Reduce logging level (technically, one could define it in the read_raw_fif function, but it seems to be buggy)\n    # More info about the bug can be found here: https://github.com/mne-tools/mne-python/issues/8872\n    set_log_level(verbose='Warning')\n\n    # Mark bad channels that were manually annotated earlier.\n    raw_str = str(raw_fname)\n    if 'task-ec' in raw_str:\n        raw.info['bads'] = ec_bads[args.subject]\n        task = 'ec'\n    elif 'task-eo' in raw_str:\n        raw.info['bads'] = eo_bads[args.subject]\n        task = 'eo'\n    elif 'task-PASAT' in raw_str and 'run-01' in raw_str:\n        raw.info['bads'] = pasat1_bads[args.subject]\n        task = 'pasat1'\n    elif 'task-PASAT' in raw_str and 'run-02' in raw_str:\n        raw.info['bads'] = pasat2_bads[args.subject]\n        task = 'pasat2'\n    \n    # Remove MEG channels. This is the EEG pipeline after all.\n    raw.pick_types(meg=False, eeg=True, eog=True, stim=True, ecg=True, exclude=[])\n    \n    # Plot segment of raw data\n    figures['raw segment'].append(raw.plot(n_channels=30, title = date_time, show=False))\n    \n    # Interpolate bad channels\n    raw.interpolate_bads()\n    figures['interpolated segment'].append(raw.plot(n_channels=30, title = date_time + task, show=False))\n    \n    # Add a plot of the power spectrum to the list of figures to be placed in\n    # the HTML report.\n    raw_plot = raw.compute_psd(fmin=freq_min, fmax=filt_freq_max).plot(show=False)\n    figures['before filt'].append(raw_plot)\n\n    # Remove 50Hz power line noise (and the first harmonic: 100Hz)\n    filt = raw.notch_filter(fnotch, picks=['eeg', 'eog', 'ecg'])\n    \n    # Apply bandpass filter\n    filt = filt.filter(l_freq=freq_min, h_freq=filt_freq_max, picks=['eeg', 'eog', 'ecg'])\n\n    # Save the filtered data\n    filt_fname.parent.mkdir(parents=True, exist_ok=True)\n    filt.save(filt_fname, overwrite=True)\n\n    # Add a plot of the power spectrum of the filtered data to the list of\n    # figures to be placed in the HTML report.\n    filt_plot = filt.plot_psd(fmin=freq_min, fmax=filt_freq_max, show=False)\n    figures['after filt'].append(filt_plot)\n    \n    raw.close()", "\n# Write HTML report with the quality control figures\nsection='Filtering'\nwith open_report(fname.report(subject=args.subject)) as report:\n    report.add_figure(\n        figures['before filt'],\n        title='Before frequency filtering',\n        caption=('Eyes open', 'Eyes closed', 'PASAT run 1', 'PASAT run 2'),\n        replace=True,\n        section=section,\n        tags=('filt')\n    )\n    report.add_figure(\n        figures['after filt'],\n        title='After frequency filtering',\n        caption=('Eyes open', 'Eyes closed', 'PASAT run 1', 'PASAT run 2'),\n        replace=True,\n        section=section,\n        tags=('filt')\n    )\n    report.add_figure(\n        figures['raw segment'],\n        title='Before interpolation',\n        caption=('Eyes open', 'Eyes closed', 'PASAT run 1', 'PASAT run 2'),\n        replace=True,\n        section=section,\n        tags=('raw')\n    )\n    report.add_figure(\n        figures['interpolated segment'],\n        title='After interpolation',\n        caption=('Eyes open', 'Eyes closed', 'PASAT run 1', 'PASAT run 2'),\n        replace=True,\n        section=section,\n        tags=('raw')\n    )\n    report.save(fname.report_html(subject=args.subject),\n                overwrite=True, open_browser=False)", "\nwith open('corrupted_subjects.txt', 'a') as file:\n    for bad_file in corrupted_raw_files:\n        file.write(bad_file+'\\n')\n    file.close()\n\n# Calculate time that the script takes to run\nexecution_time = (time.time() - start_time)\nprint('\\n###################################################\\n')\nprint(f'Execution time of 01_freqfilter.py is: {round(execution_time,2)} seconds\\n')", "print('\\n###################################################\\n')\nprint(f'Execution time of 01_freqfilter.py is: {round(execution_time,2)} seconds\\n')\nprint('###################################################\\n')\n"]}
{"filename": "src/processing/04_bandpower.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Tue Jun 14 12:29:27 2022\n\n@author: aino\n\nCalculates log band power (absolute) for each subject\n\nRunning:", "\nRunning:\nimport subprocess\nsubprocess.run('/net/tera2/home/aino/work/mtbi-eeg/python/processing/eeg/runall.sh', shell=True)\n\"\"\"\n\n\nimport argparse\nimport h5py\nimport numpy as np", "import h5py\nimport numpy as np\nfrom pathlib import Path\nimport time\nimport os\nimport sys\n\nparent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(parent_dir)\nfrom config_eeg import fname, thin_bands, wide_bands, processed_data_dir", "sys.path.append(parent_dir)\nfrom config_eeg import fname, thin_bands, wide_bands, processed_data_dir\n\n# Save time of beginning of the execution to measure running time\nstart_time = time.time()\n\n# Deal with command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nparser.add_argument('--freq_band_type', type=str, help=\"Define the frequency bands. 'thin' are 1hz bands from 1 to 40hz. 'wide' are conventional delta, theta, etc. Default is 'thin'.\", default=\"thin\")", "parser.add_argument('subject', help='The subject to process')\nparser.add_argument('--freq_band_type', type=str, help=\"Define the frequency bands. 'thin' are 1hz bands from 1 to 40hz. 'wide' are conventional delta, theta, etc. Default is 'thin'.\", default=\"thin\")\n\nargs = parser.parse_args()\n\nif args.freq_band_type == 'wide':\n    f_bands =  wide_bands  \nelif args.freq_band_type == 'thin':\n    f_bands = thin_bands\n", "\nnormalize_ch_power = False\n\n# A list for corruprted or missing psds files\ncorrupted_psds_files = []\n\nsubject_psds = fname.psds(subject=args.subject, ses='01')\n\ntry:\n    f = h5py.File(subject_psds, 'r')\nexcept:\n    print(\"Psds file corrupted or missing\")\n    corrupted_psds_files.append(args.subject)", "try:\n    f = h5py.File(subject_psds, 'r')\nexcept:\n    print(\"Psds file corrupted or missing\")\n    corrupted_psds_files.append(args.subject)\n    \npsds_keys = list(f.keys())\npsds_data = f[psds_keys[0]]\ndata_keys = list(psds_data)\ndata = dict()", "data_keys = list(psds_data)\ndata = dict()\n\n# Add the data for each PSD to the dictionary 'data'\nfor i in data_keys:\n    if 'eo' in i or 'ec' in i or 'PASAT' in i:\n        dict_key = i.removeprefix('key_')\n        data[dict_key] = np.array(psds_data[i])\nfreqs = np.array(psds_data['key_freqs'])\ninfo_keys = list(psds_data['key_info'])", "freqs = np.array(psds_data['key_freqs'])\ninfo_keys = list(psds_data['key_info'])\n\nf.close()\n\n# Create a directory to save the .csv files\ndirectory = f'{processed_data_dir}/sub-{args.subject}/ses-01/eeg/bandpowers'\nPath(directory).mkdir(parents=True, exist_ok=True)\n\n# Calculate the average bandpower for each PSD\nfor data_obj in list(data.keys()):\n    data_bandpower = [] \n    data_arr = data[data_obj]\n    \n    if normalize_ch_power:\n        ch_tot_powers = np.sum(data_arr, axis=1)\n        data_arr = data_arr/ch_tot_powers[:, None]\n    \n    for fmin, fmax in f_bands:           \n        min_index = np.argmax(freqs > fmin) - 1\n        max_index = np.argmax(freqs > fmax) - 1\n\n        bandpower = np.mean(data_arr[:, min_index:max_index], axis=1)           \n        data_bandpower.append(bandpower)\n    \n    # Save the calculated bandpowers\n    filename = f'{directory}/{args.freq_band_type}_{data_obj}.csv'\n    np.savetxt(filename, data_bandpower, delimiter=',')  ", "\n# Calculate the average bandpower for each PSD\nfor data_obj in list(data.keys()):\n    data_bandpower = [] \n    data_arr = data[data_obj]\n    \n    if normalize_ch_power:\n        ch_tot_powers = np.sum(data_arr, axis=1)\n        data_arr = data_arr/ch_tot_powers[:, None]\n    \n    for fmin, fmax in f_bands:           \n        min_index = np.argmax(freqs > fmin) - 1\n        max_index = np.argmax(freqs > fmax) - 1\n\n        bandpower = np.mean(data_arr[:, min_index:max_index], axis=1)           \n        data_bandpower.append(bandpower)\n    \n    # Save the calculated bandpowers\n    filename = f'{directory}/{args.freq_band_type}_{data_obj}.csv'\n    np.savetxt(filename, data_bandpower, delimiter=',')  ", "\nwith open('psds_corrupted_or_missing.txt', 'a') as file:\n    for bad_file in corrupted_psds_files:\n        file.write(bad_file + '\\n')\n    file.close()\n\n    \n# Calculate time that the script takes to run\nexecution_time = (time.time() - start_time)\nprint('\\n###################################################\\n')", "execution_time = (time.time() - start_time)\nprint('\\n###################################################\\n')\nprint(f'Execution time of 04_bandpower.py for {args.freq_band_type} frequency bands is: {round(execution_time,2)} seconds\\n')\nprint('###################################################\\n')"]}
{"filename": "src/processing/__init__.py", "chunked_list": [""]}
{"filename": "src/processing/02_ica.py", "chunked_list": ["\"\"\"\nRemove EOG & ECG artifacts through independant component analysis (ICA).\n\n\nRunning: \nimport subprocess\nsubprocess.run('/net/tera2/home/aino/work/mtbi-eeg/python/processing/eeg/runall.sh', shell=True)\n\"\"\"\n\nimport argparse", "\nimport argparse\nfrom collections import defaultdict\n\nfrom mne import Epochs, set_log_level\nfrom mne.io import read_raw_fif\nfrom mne.preprocessing import create_eog_epochs, create_ecg_epochs, ICA\nfrom mne import open_report\nimport datetime\nimport time", "import datetime\nimport time\nimport os\nimport sys\n\nparent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(parent_dir)\nfrom config_eeg import get_all_fnames, task_from_fname, fname, ecg_channel\n\n", "\n\n# Save time of beginning of the execution to measure running time\nstart_time = time.time()\n\n# Deal with command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nargs = parser.parse_args()\n", "args = parser.parse_args()\n\n# Along the way, we collect figures for quality control\nfigures = defaultdict(list)\n\n# Not all subjects have files for all conditions. These functions grab the\n# files that do exist for the subject.\nexclude = ['emptyroom'] #these don't have eye blinks.\nbad_subjects = ['01P', '02P', '03P', '04P', '05P', '06P', '07P']#these ica need to be done manually\nall_fnames = zip(", "bad_subjects = ['01P', '02P', '03P', '04P', '05P', '06P', '07P']#these ica need to be done manually\nall_fnames = zip(\n    get_all_fnames(args.subject, kind='filt', exclude=exclude),\n    get_all_fnames(args.subject, kind='ica', exclude=exclude),\n    get_all_fnames(args.subject, kind='clean', exclude=exclude),\n)\n\nfor filt_fname, ica_fname, clean_fname in all_fnames:\n    task = task_from_fname(filt_fname)\n    #TODO: crop first and last 2-5 s\n    raw_filt = read_raw_fif(filt_fname, preload=True)\n    \n    # Reduce logging level (technically, one could define it in the read_raw_fif function, but it seems to be buggy)\n    # More info about the bug can be found here: https://github.com/mne-tools/mne-python/issues/8872\n    set_log_level(verbose='Warning')\n\n    # Run a detection algorithm for the onsets of eye blinks (EOG) and heartbeat artefacts (ECG)\n    eog_events = create_eog_epochs(raw_filt)\n    #TODO: skip eog events for ec\n    if ecg_channel in raw_filt.info['ch_names']:\n                        ecg_events = create_ecg_epochs(raw_filt)\n                        ecg_exists = True\n    else:\n        ecg_exists = False\n    # Perform ICA decomposition\n    ica = ICA(n_components=0.99, random_state=0).fit(raw_filt)\n\n    # Find components that are likely capturing EOG artifacts\n    \n    bads_eog, scores_eog = ica.find_bads_eog(raw_filt)\n    print('Bads EOG:', bads_eog)\n    try:\n        bads_ecg, scores_ecg = ica.find_bads_ecg(raw_filt, method='correlation',threshold='auto')\n    except ValueError:\n        print('Not able to find ecg components')\n        bads_ecg = []\n        scores_ecg = []\n    # Mark the EOG components for removal\n    ica.exclude = bads_eog + bads_ecg\n    ica.save(ica_fname, overwrite=True) \n\n    # Remove the EOG artifact components from the signal.\n    raw_ica = ica.apply(raw_filt)\n    raw_ica.save(clean_fname, overwrite=True)\n\n    # Date and time\n    now = datetime.datetime.now()\n    date_time = now.strftime('%A, %d. %B %Y %I:%M%p')\n\n    # Put a whole lot of quality control figures in the HTML report.\n    with open_report(fname.report(subject=args.subject)) as report:\n        if len(bads_eog)>0:\n            report.add_ica(ica=ica, \n                            title=f' {task}' + ' EOG', \n                            inst=raw_filt, \n                            picks=bads_eog,\n                            eog_evoked=eog_events.average(),\n                            eog_scores=scores_eog,\n                            tags=(f'{task}', 'EOG', 'ICA'),\n                            replace=True\n                            )\n        if ecg_exists:\n            if len(bads_ecg)>0:\n                report.add_ica(ica=ica, \n                                title=f' {task}' + ' ECG', \n                                inst=raw_filt, \n                                picks=bads_ecg,\n                                ecg_evoked=ecg_events.average(),\n                                ecg_scores=scores_ecg,\n                                tags=(f'{task}', 'ECG', 'ICA'),\n                                replace=True\n                                )\n\n        report.add_figure(\n            ica.plot_overlay(eog_events.average(), title=date_time, show=False),\n            f'{task}: EOG overlay', replace=True, tags=(f'{task}', 'ICA', 'EOG', 'overlay'))\n        \n        if ecg_exists:\n\n            \n            report.add_figure(\n                ica.plot_overlay(ecg_events.average(), title=date_time, show=False),\n                f'{task}: ECG overlay', replace=True, tags=(f'{task}', 'ICA', 'ECG', 'overlay'))\n            \n\n        report.save(fname.report_html(subject=args.subject),\n                    overwrite=True, open_browser=False)\n    \n    with open(\"ecg_missing.txt\", \"a\") as file:\n        file_name = task_from_fname(filt_fname)\n        if not ecg_exists:\n            print(f'{args.subject}: no ECG found') \n            file.write(str(args.subject)+file_name+'\\n')\n        file.close()", "\n# Calculate time that the script takes to run\nexecution_time = (time.time() - start_time)\nprint('\\n###################################################\\n')\nprint(f'Execution time of 02_ica.py is: {round(execution_time,2)} seconds\\n')\nprint('###################################################\\n')\n"]}
{"filename": "src/processing/run_files.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Mar 15 11:23:04 2023\n\nRuns the scripts in the processing folder \n\nIt could also be done in bash using something like \n    # Define the arguments for the first file\n    arg1_vals=(\"eo\" \"ec\" \"PASAT_1\" \"PASAT_2\")", "    # Define the arguments for the first file\n    arg1_vals=(\"eo\" \"ec\" \"PASAT_1\" \"PASAT_2\")\n    arg2_vals=(\"thin\" \"wide\")\n    \n    # Call the first Python file with each set of arguments\n    for (( i=0; i<${#arg1_vals[@]}; i++ )); do\n        python file1.py --task \"${arg1_vals[i]}\" --freq_band_type \"${arg2_vals[i]}\"\n        # Call the second Python file without any arguments\n        python file2.py\n    done", "        python file2.py\n    done\n@author: portae1\n\"\"\"\n\nimport subprocess\nimport time\nimport re\n\n# Flag used for test run", "\n# Flag used for test run\nTEST_RUN = False\n\n\n# Save time of beginning of the execution to measure running time\nhere_start_time = time.time()\n\n# Define a list of tuples containing the different argument combinations to use\n#subjects = ['10C', '30P']", "# Define a list of tuples containing the different argument combinations to use\n#subjects = ['10C', '30P']\narg_set = [('--freq_band_type', 'thin'),\n            ('--freq_band_type', 'wide'),]\n\nsubject_pattern = r'^\\d{2}[PC]'   \n\n\nif TEST_RUN:\n    subjects = ['10C', '11P']\nelse:\n    try:\n        with open('subjects.txt', 'r') as subjects_file:\n            subjects = [line.rstrip() for line in subjects_file.readlines()]\n            # Assert that each line has the expected format\n            for line in subjects:\n                assert re.match(subject_pattern, line), f\"Subject '{line}' does not have the expected format.\"\n\n    except FileNotFoundError as e:\n        print(\"The file 'subjects.txt' does not exist in the current directory. The program will exit.\")\n        raise e", "if TEST_RUN:\n    subjects = ['10C', '11P']\nelse:\n    try:\n        with open('subjects.txt', 'r') as subjects_file:\n            subjects = [line.rstrip() for line in subjects_file.readlines()]\n            # Assert that each line has the expected format\n            for line in subjects:\n                assert re.match(subject_pattern, line), f\"Subject '{line}' does not have the expected format.\"\n\n    except FileNotFoundError as e:\n        print(\"The file 'subjects.txt' does not exist in the current directory. The program will exit.\")\n        raise e", "\nfor subject in subjects:\n    print(f'### \\nRunning using subject {subject}...\\n')\n    # Call the first Python \n    subprocess.run(['python3', '01_freqfilt.py', subject])\n    print(f'Finished executing 01_freqfilt for subject {subject}\\n')\n    # Call the second Python file\n    subprocess.run(['python3', '02_ica.py', subject])\n    print(f'Finished executing 02_ica for subject {subject}\\n')\n    # Call the third script\n    subprocess.run(['python3', '03_psds.py', subject])\n    print(f'Finished executing 03_psds for subject {subject}\\n')\n    # Create bandpowers\n    for arg in arg_set:\n        subprocess.run(['python3', '04_bandpower.py', subject] + list(arg))\n    print(f'Finished executing 04_bandpower for subject {subject}\\n')", "    \n\n# Calculate time that the script takes to run\nhere_execution_time = (time.time() - here_start_time)\nprint('\\n###################################################')\nprint('Processing pipeline has finalized executing')\nprint(f'Total execution time is: {round(here_execution_time/60,1)} minutes')\nprint(f'Average time is {round(here_execution_time/len(subjects),1)} seconds per subject')\nprint('###################################################\\n')\n", "print('###################################################\\n')\n"]}
{"filename": "src/processing/03_psds.py", "chunked_list": ["\"\"\"\nCompute the Power Spectral Density (PSD) for each channel.\n\nRunning:\nimport subprocess\nsubprocess.run('/net/tera2/home/aino/work/mtbi-eeg/python/processing/eeg/runall.sh', shell=True)\n\n\"\"\"\n\nimport argparse", "\nimport argparse\n\nfrom mne.io import read_raw_fif\nfrom mne.time_frequency import psd_array_welch\nfrom h5io import write_hdf5\nfrom mne.viz import iter_topography\nfrom mne import open_report, find_layout, pick_info, pick_types, set_log_level\nimport matplotlib.pyplot as plt\nimport datetime", "import matplotlib.pyplot as plt\nimport datetime\nimport time\nimport os\nimport sys\n\nparent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(parent_dir)\nfrom config_eeg import fname, n_fft, get_all_fnames, task_from_fname, freq_max\n", "from config_eeg import fname, n_fft, get_all_fnames, task_from_fname, freq_max\n\n# Save time of beginning of the execution to measure running time\nstart_time = time.time()\n\n# Deal with command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nargs = parser.parse_args()\n", "args = parser.parse_args()\n\n# Compute the PSD for each task\npsds = dict()\n\n# Not all subjects have files for all conditions. These functions grab the\n# files that do exist for the subject.\nexclude = ['emptyroom'] \nbad_subjects = ['01P', '02P', '03P', '04P', '05P', '06P', '07P']#these ica need to be done manually\nall_fnames = zip(", "bad_subjects = ['01P', '02P', '03P', '04P', '05P', '06P', '07P']#these ica need to be done manually\nall_fnames = zip(\n    get_all_fnames(args.subject, kind='psds', exclude=exclude),\n    get_all_fnames(args.subject, kind='clean', exclude=exclude),\n)\n\nfor psds_fname, clean_fname in all_fnames:\n    task = task_from_fname(clean_fname)\n    run = 1\n    if '1' in task:\n        task_wo_run = task.removesuffix('_run1')\n    elif '2' in task:\n        task_wo_run = task.removesuffix('_run2')    \n        run = 2\n    else:\n        task_wo_run = task\n    \n    raw = read_raw_fif(fname.clean(subject=args.subject, task=task_wo_run, run=run,ses='01'),\n                       preload=True)\n    \n    # Reduce logging level (technically, one could define it in the read_raw_fif function, but it seems to be buggy)\n    # More info about the bug can be found here: https://github.com/mne-tools/mne-python/issues/8872\n    set_log_level(verbose='Warning')\n    \n    raw.info['bads']=[]\n    sfreq=raw.info['sfreq']\n    \n    if 'eo' in task or 'ec' in task:\n        clean_1 = raw.copy().crop(tmin=30, tmax=90)\n        clean_2 = raw.copy().crop(tmin=120, tmax=180)\n        clean_3 = raw.copy().crop(tmin=210, tmax=260)\n        psds[task+'_3'], freqs = psd_array_welch(clean_3.get_data(picks=['eeg']), sfreq=sfreq, \n                                                 fmax=freq_max, n_fft=n_fft)\n\n    elif 'PASAT' in task:\n        clean_1 = raw.copy().crop(tmin=2, tmax=62)\n        clean_2 = raw.copy().crop(tmin=62, tmax=122)\n    \n    psds[task+'_1'], freqs = psd_array_welch(clean_1.get_data(picks=['eeg']), sfreq=sfreq,\n                                             fmax=freq_max, n_fft=n_fft)\n    psds[task+'_2'], freqs = psd_array_welch(clean_2.get_data(picks=['eeg']), sfreq=sfreq,\n                                             fmax=freq_max, n_fft=n_fft)\n    \n    \n    # Add some metadata to the file we are writing\n    psds['info'] = raw.info\n    psds['freqs'] = freqs\n    write_hdf5(fname.psds(subject=args.subject, ses='01'), psds, overwrite=True)", "\n# Add a PSD plot to the report.\nraw.pick_types(meg=False, eeg=True, eog=False, stim=False, ecg=False, exclude=[])\ninfo = pick_info(raw.info, sel=None)\nlayout = find_layout(info, exclude=[])\n\n\ndef on_pick(ax, ch_idx):\n    \"\"\"Create a larger PSD plot for when one of the tiny PSD plots is\n       clicked.\"\"\"\n    ax.plot(psds['freqs'], psds['ec_1'][ch_idx], color='C0',\n            label='eyes closed')\n    ax.plot(psds['freqs'], psds['eo_1'][ch_idx], color='C1',\n            label='eyes open')\n    ax.plot(psds['freqs'], psds['PASAT_run1_1'][ch_idx], color='C2',\n            label='pasat run 1')\n    ax.plot(psds['freqs'], psds['PASAT_run2_1'][ch_idx], color='C3',\n            label='pasat run 2')\n    ax.legend()\n    ax.set_xlabel('Frequency')\n    ax.set_ylabel('PSD')", "\n\n# Make the big topo figure\nfig = plt.figure(figsize=(14, 9))\naxes = iter_topography(info, layout, on_pick=on_pick, fig=fig,\n                       axis_facecolor='white', fig_facecolor='white',\n                       axis_spinecolor='white')\nfor ax, ch_idx in axes:\n    handles = [\n        ax.plot(psds['freqs'], psds['ec_1'][ch_idx], color='C0'),\n        ax.plot(psds['freqs'], psds['eo_1'][ch_idx], color='C1'),\n        ax.plot(psds['freqs'], psds['PASAT_run1_1'][ch_idx], color='C2'),\n        ax.plot(psds['freqs'], psds['PASAT_run2_1'][ch_idx], color='C3'),\n    ]", "fig.legend(handles)\n\n\nwith open_report(fname.report(subject=args.subject)) as report:\n    report.add_figure(fig, 'PSDs', replace=True)\n    report.save(fname.report_html(subject=args.subject),\n                overwrite=True, open_browser=False)\n\n# Calculate time that the script takes to run\nexecution_time = (time.time() - start_time)", "# Calculate time that the script takes to run\nexecution_time = (time.time() - start_time)\nprint('\\n###################################################\\n')\nprint(f'Execution time of 03_psds.py is: {round(execution_time,2)} seconds\\n')\nprint('###################################################\\n')\n"]}
{"filename": "src/analysis/03_fit_classifier_and_plot.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n#################################\n# 03_fit_classifier_and_plot.py #\n#################################\n\n@authors: Verna Heikkinen, Aino Kuusi, Estanislao Porta\n\nTakes the processed data, fits four different ML classifiers,", "\nTakes the processed data, fits four different ML classifiers,\nperforms cross validation and evaluates the performance of the classification\nusing mean ROC curves.\n\nData is split it in folds according to 10-fold StratifiedGroupKFold\nIf only one segment of a task is to be used, CV is done using StratifiedKFold CV.\nArguments used to run the script are added to pickle object.\n\nArguments", "\nArguments\n---------\n    - eeg_tmp_data.pickle : pickle object\n        Object of pickle format containing the dataframe with the data\n        and the metadata with the information about the arguments\n        used to run the 01_read_processed_data script.\n    - seed : int\n        Value for initialization of the classifiers and the CV.\n    - scaling : bool", "        Value for initialization of the classifiers and the CV.\n    - scaling : bool\n        Define whether to perform scaling over data or not.\n    - scaling_method : str\n        Define what is the preferred scaling method.\n    - one_segment_per_task : bool\n        Define whether one or all segments of the task will be used for the classification.\n    - which_segment : int\n        Defines which of the segments will be used.\n    - dont_save_fig: bool", "        Defines which of the segments will be used.\n    - dont_save_fig: bool\n        Define whether to refrain from saving the figure to disk.\n    - display_figure: bool\n        Define whether to display the figure in graphical interface\n        (e.g., when running script in HPC).\n\nReturns\n-------\n    - Prints out figure", "-------\n    - Prints out figure\n    - figure : pickle object\n        Object of pickle format containing the dataframe with the data\n        and the metadata with the information about the arguments\n        used to run this script.\n    - metadata?\n    - report?\n\n# TODO: Define metric and export them to CSV file", "\n# TODO: Define metric and export them to CSV file\n\"\"\"\nimport sys\nimport os\nimport argparse\nimport time\nfrom math import sqrt\nfrom datetime import datetime\n", "from datetime import datetime\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, accuracy_score\nfrom sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold", "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, accuracy_score\nfrom sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom statistics import mean, stdev\n\nSRC_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(SRC_DIR)\nfrom config_common import figures_dir, reports_dir\nfrom config_eeg import seed, folds", "from config_common import figures_dir, reports_dir\nfrom config_eeg import seed, folds\nfrom pickle_data_handler import PickleDataHandler\n# Create directory if it doesn't exist\nif not os.path.isdir(figures_dir):\n    os.makedirs(figures_dir)\n\ndef initialize_argparser(metadata):\n    \"\"\" Initialize argparser and add args to metadata.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-v', '--verbosity', action='store_true', help='Define the verbosity of the output. Default: False', default=False)\n    parser.add_argument('-s', '--seed', type=int, help=f'Seed value used for CV splits, and for classifiers and for CV splits. Default: {seed}', metavar='int', default=seed) # Note: different sklearn versions could yield different results \n    parser.add_argument('--scaling', action='store_true', help='Scaling of data before fitting. Can only be used if data is not normalized. Default: False', default=False)\n    parser.add_argument('--scaling_method', choices=scaling_methods, help='Method for scaling data, choose from the options. Default: RobustScaler', default=scaling_methods[2]) \n    parser.add_argument('--one_segment_per_task', action='store_true',  help='Utilizes only one of the segments from the tasks. Default: False', default=False)\n    parser.add_argument('--which_segment', type=int, help='Define which number of segment to use: 1, 2, etc. Default is 1', metavar='', default=1)\n    parser.add_argument('--display_fig', action='store_true', help='Displays the figure. Default: False', default=False)\n    parser.add_argument('--dont_save_fig', action='store_true', help='Saves figure to disk. Default: True', default=False)\n    #parser.add_argument('--threads', type=int, help=\"Number of threads, using multiprocessing\", default=1) #skipped for now\n    args = parser.parse_args()\n    \n    # Add the input arguments to the metadata dictionary\n    metadata[\"folds\"] = folds\n    metadata[\"seed\"] = seed\n    metadata[\"verbosity\"] = args.verbosity\n    if args.scaling and metadata[\"normalization\"]:\n        raise TypeError(\"You are trying to scale data that has been already normalized.\")\n    metadata[\"scaling\"] = args.scaling\n    metadata[\"scaling_method\"] = args.scaling_method\n    metadata[\"one_segment_per_task\"] = args.one_segment_per_task\n    metadata[\"which_segment\"] = args.which_segment\n    if  args.one_segment_per_task and (args.which_segment > metadata[\"segments\"]):\n        raise TypeError(f'The segment you chose is larger than the number of available segments for task {metadata[\"task\"]}. Please choose a value between 1 and {metadata[\"segments\"]}.')\n    metadata[\"display_fig\"] = args.display_fig\n\n    return metadata, args", "\ndef initialize_cv(dataframe, metadata):\n    \"\"\"Initialize Cross Validation and gets data splits as a list \"\"\"\n    # Define features, classes and groups\n    X = dataframe.iloc[:, 2:]\n    y = dataframe.loc[:, 'Group']\n    groups = dataframe.loc[:, 'Subject']\n\n    # Slice data\n    if metadata[\"one_segment_per_task\"]:\n        # Removes (segments-1) rows out of the dataframe\n        X = X[metadata[\"which_segment\"]:len(X):metadata[\"segments\"]]\n        y = y[metadata[\"which_segment\"]:len(y):metadata[\"segments\"]]\n        groups = groups[metadata[\"which_segment\"]:len(groups):metadata[\"segments\"]]\n\n        # Initialize Stratified K Fold\n        skf = StratifiedKFold(n_splits=metadata[\"folds\"], shuffle=True, random_state=seed)\n        data_split = list(skf.split(X, y, groups))\n    else:\n        # Initialize Stratified Group K Fold\n        sgkf = StratifiedGroupKFold(n_splits=metadata[\"folds\"], shuffle=True, random_state=seed)\n        data_split = list(sgkf.split(X, y, groups))\n\n    return X, y, data_split", "\ndef initialize_subplots(metadata):\n    \"\"\"Creates figure with 2x2 subplots, sets axes and fig title\"\"\"\n    # Disable interactive mode in case plotting is not needed\n    plt.ioff()\n    fig_roc, axs = plt.subplots(nrows=2, ncols=2,\n                            sharex=True, sharey=True,\n                            figsize=(10, 10))\n\n    # Add figure title and save it to metadata\n    if metadata[\"scaling\"]:\n        figure_title = (\n            f'Task: {metadata[\"task\"]}, Freq band: {metadata[\"freq_band_type\"]}, '\n            f'Channel data normalization: {metadata[\"normalization\"]}, \\n'\n            f'Using one-segment: {metadata[\"one_segment_per_task\"]}, Scaling: '\n            f'{metadata[\"scaling\"]}, metadata[\"scaling_method\"]'\n        )\n    else:\n        figure_title = (\n            f'Task: {metadata[\"task\"]}, Band type: {metadata[\"freq_band_type\"]}, '\n            f'Channel data normalization: {metadata[\"normalization\"]}, \\n'\n            f'Using one-segment: {metadata[\"one_segment_per_task\"]}, Scaling: '\n            f'{metadata[\"scaling\"]}'\n        )\n    fig_roc.suptitle(figure_title)\n    # Add x and y labels\n    axs[0, 0].set(ylabel='True Positive Rate')\n    axs[1, 0].set(ylabel='True Positive Rate')\n    axs[1, 0].set(xlabel='False Positive Rate')\n    axs[1, 1].set(xlabel='False Positive Rate')\n\n    # Display figure if needed\n    if metadata[\"display_fig\"]:\n        plt.show(block=False)\n    else:\n        print('INFO: Figure will not be displayed.')\n    return fig_roc, axs, metadata", "\ndef perform_data_split(X, y, split, train_index, test_index):\n    \"\"\"Splits X and y data into training and testing according to the data split indexes\"\"\"\n    skip_split = False\n    # Generate train and test sets for this split\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    # Scale if needed:\n    if metadata[\"scaling\"] and not metadata[\"normalization\"]:\n        scaler = metadata[\"scaling_method\"]\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n\n    # Control if there's only one class in a fold\n    if np.unique(y[test_index]).size == 1:\n        print(f\"WARN: Split {split+1} has only 1 class in the test set, skipping it. ####\")\n        skip_split = True\n    # Print out class balance if needed\n    if metadata[\"verbosity\"]:\n        print(f\"\\nSplit {split+1}:\")\n        _, counts_test = np.unique(y[test_index], return_counts=True)\n        _, counts_train = np.unique(y[train_index], return_counts=True)\n\n        print(f'INFO: Class balance in test set (C-P): '\n              f'{round(counts_test[0]/(y[test_index].size)*100)}-'\n              f'{round(counts_test[1]/(y[test_index].size)*100)}')\n        print(f'INFO: Class balance in training set (C-P): '\n              f'{round(counts_train[0]/(y[train_index].size)*100)}-'\n              f'{round(counts_train[1]/(y[train_index].size)*100)}')\n\n    return X_train, X_test, y_train, y_test, skip_split", "\ndef roc_per_clf(tprs, aucs, ax, name, clf):\n    \"\"\" Calculates the mean TruePositiveRate and AUC for classifier 'clf'.\n    Adds confidence interval of the AUC to the figure\n    Adds the chance plot to the figure\n    \"\"\"\n    mean_fpr = np.linspace(0, 1, 100)\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_tpr[-1] = 1.0\n    # Calculate AUC's mean and confidence interval based on fpr and tpr and add to plot\n    mean_auc = round(auc(mean_fpr, mean_tpr), 3)\n    std_auc = round(np.std(aucs), 3)\n    ax.plot(mean_fpr, mean_tpr, color='tab:blue',\n            label=r'AUC = %0.2f $\\pm$ %0.2f' % (mean_auc, std_auc),\n            lw=2, alpha=.8)\n    # Calculate upper and lower std_dev band around mean and add to plot\n    std_tpr = np.std(tprs, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    #ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='tab:blue', alpha=.2)\n    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='tab:grey', alpha=.2,\n                    label=r'$\\pm$ 1 std. dev.')\n    ax.set(xlim=[0, 1], ylim=[0, 1], title=name)\n    ax.legend(loc=\"lower right\", fontsize=12) \n    #ax.grid(True)\n    # Plot chance curve\n    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='tab:red',\n            label='Chance', alpha=.3)\n    # Estimate confidence interval\n    ci_auc = round(std_auc*1.96/sqrt(folds), 3)\n    print(f'\\nINFO: Classifier = {clf}')\n    print('\\tAUC = %0.2f \\u00B1 %0.2f' % (mean_auc, ci_auc))\n\n    return mean_tpr", "\ndef metrics_per_clf(sensitivity, specificity, accuracy):\n    \"\"\"Calculates metrics and confidence interval for each classifier\"\"\"\n    mean_sens = round(mean(sensitivity), 2)\n    ci_sens = round(stdev(sensitivity)*1.96/sqrt(folds), 2)\n    mean_spec = round(mean(specificity), 2)\n    ci_spec = round(stdev(specificity)*1.96/sqrt(folds), 2)\n    mean_acc = round(mean(accuracy), 2)\n    ci_acc = round(stdev(accuracy)*1.96/sqrt(folds), 2)\n\n    print('\\tSensitivity = %0.2f \\u00B1 %0.2f' % (mean_sens, ci_sens))\n    print('\\tSpecificity = %0.2f \\u00B1 %0.2f' % (mean_spec, ci_spec))\n    print('\\tAccuracy = %0.2f \\u00B1 %0.2f' % (mean_acc, ci_acc))\n    return mean_sens, ci_sens, mean_spec, ci_spec, mean_acc, ci_acc", "\ndef fit_and_plot(X, y, classifiers, data_split, metadata):\n    \"\"\"\n    Loops over all classifiers according to the data split of the CV.\n    Plots the split ROCs in subplots\n    Arguments\n    ---------\n        - X : list\n            Sample subjects\n        - y : list\n            Features of the samples\n        - classifiers :  list\n            List with the functions used as ML classifiers\n        - data_split : list\n            Indexes  of the Training and Testing sets for the CV splits\n        - metadata : dict\n            Object containing the parameters used in the analysis\n\n    Returns\n    -------\n         - Figure with 2x2 subplots: matplotlib plot\n         - metadata : dict containing df 'metrics', which includes:\n                - tpr_per_classifier : list\n                - sensitivity_per_classifier : list\n                - specificity_per_classifier : list\n                - f1_per_classifier : list\n    \"\"\"\n    # Initialize dataframe where the metrics will be stored\n    tpr_per_classifier = []\n    accuracy_per_classifier = []\n    ci_acc_clf = []\n    sensitivity_per_classifier = []\n    ci_sens_clf = []\n    specificity_per_classifier = []\n    ci_spec_clf = []\n    # Submethod 4.1 - Initialize the subplots\n    fig_roc, axs, metadata = initialize_subplots(metadata)\n    # Iterate over the classifiers to populate each subplot\n    for ax, (name, clf) in zip(axs.flat, classifiers):\n        tprs = []\n        aucs = []\n        accuracy = []\n        sensitivity = []\n        specificity = []\n        mean_fpr = np.linspace(0, 1, 100)\n        # Fit the classifiers to the split\n        for split, (train_index, test_index) in enumerate(data_split):\n            # Submethod 4.2 - Slice the X and y data according to CV's data_split\n            X_train, X_test, y_train, y_test, skip_split = \\\n                perform_data_split(X, y, split, train_index, test_index)\n            # Skip this split if class balance is bad\n            if skip_split:\n                continue\n\n            # Fit classifier and predict outcomes\n            clf.fit(X_train, y_train)\n            probas_ = clf.predict_proba(X_test)\n            y_pred = clf.predict(X_test)\n            # Compute ROC curve\n            fpr, tpr, _ = roc_curve(y_test, probas_[:, 1])\n            # Append the (tpr vs fpr) values interpolated over mean_fpr\n            tprs.append(np.interp(mean_fpr, fpr, tpr))\n            tprs[-1][0] = 0.0\n            # Calculate the AUC for this ROC\n            roc_auc = auc(fpr, tpr)\n            aucs.append(roc_auc)\n            # Plot the ROC for this split\n            ax.plot(fpr, tpr, lw=1, alpha=0.3,\n                    label=f'Split {split+1} (AUC = {roc_auc:.2f})')\n            # To not add the split AUC to legend, uncomment this: \n            #ax.plot(fpr, tpr, lw=1, alpha=0.3)\n            \n            # Get the sensitivity, specificity and accuracy values\n            tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel() \n            sensitivity.append(tp / (tp + fn))\n            specificity.append(tn / (tn + fp))\n            accuracy_test = accuracy_score(y_test, y_pred)\n            accuracy.append(accuracy_test)\n            \n            # Print out set's accuracy score to evaluate overfitting:\n            if metadata[\"verbosity\"]:\n                print(f\"INFO: Accuracy score in test set: {accuracy:.2f}\")\n                y_train_pred = clf.predict(X_train)\n                accuracy_train = accuracy_score(y_train, y_train_pred)\n                print(f\"INFO: Accuracy score in training set: {accuracy_train:.2f}\")\n            \n        # Submethods 4.3 & 4.4 - Calculate means & metrics per classifier\n        mean_tpr = roc_per_clf(tprs, aucs, ax, name, clf)\n        mean_sensitivity, ci_sens, mean_specificity, ci_spec, mean_accuracy, ci_acc = metrics_per_clf(sensitivity, specificity, accuracy)\n        \n        tpr_per_classifier.append(mean_tpr.T)\n        accuracy_per_classifier.append(mean_accuracy)\n        ci_acc_clf.append(ci_acc)\n        sensitivity_per_classifier.append(mean_sensitivity)\n        ci_sens_clf.append(ci_sens)\n        specificity_per_classifier.append(mean_specificity)\n        ci_spec_clf.append(ci_spec)\n\n    metrics = pd.DataFrame({\n                    'Classifiers': [pair[0] for pair in classifiers],\n                    'Accuracy': accuracy_per_classifier,\n                    'Accuracy_CI': ci_acc_clf,\n                    'Sensitivity': sensitivity_per_classifier,\n                    'Sensitivity_CI': ci_sens_clf,\n                    'Specificity': specificity_per_classifier,\n                    'Specificity_CI': ci_spec_clf,\n                    'TPR': tpr_per_classifier\n                    })\n    metadata[\"metrics\"] = metrics\n    return fig_roc, metadata", "\ndef plot_boxplot(metadata):\n    \"\"\"Plot boxplot of mean AUC, Sensitivity and Specificity and their 95% confidence intervals\"\"\"\n    df = metadata[\"metrics\"]\n   # Set up marker shapes and colors for each classifier\n    markers = [\"o\", \"^\", \"s\", \"d\"]\n    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\n    \n    # Create subplots for each metric\n    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n    \n    # Iterate over each metric\n    for i, metric in enumerate(['Accuracy', 'Sensitivity', 'Specificity']):\n        ax = axs[i]\n            \n        # Iterate over each classifier\n        for j, clf in enumerate(df.index):\n            # Get the mean value and CI of the current metric for the current classifier\n            mean_val = df.loc[clf, metric]\n            ci = df.loc[clf, metric+'_CI']           \n            # Plot the mean value as a marker with the corresponding shape and color\n            ax.plot(j, mean_val, marker=markers[j], markersize=10, color=colors[j])\n            # Plot the CI as a vertical error bar\n            ax.vlines(j, mean_val - ci, mean_val + ci, color=colors[j], linewidth=2)\n            \n        # Set the x-axis tick labels to be the classifier names\n        ax.set_xticks(np.arange(len(df.index)))\n        ax.set_xticklabels([])\n        ax.set_ylim(0,1)\n        # Set the y-axis label to be the current metric name\n        ax.set_ylabel(metric)\n        ax.axhline(y=0.5, color='grey', linestyle='--')\n    # Add a legend for the marker shapes and the corresponding classifiers\n    handles = []\n    for j, clf in enumerate(df[\"Classifiers\"]):\n        handle = plt.Line2D([0], [0], marker=markers[j], color='w', label=clf, markerfacecolor=colors[j], markersize=10)\n        handles.append(handle)\n    fig.legend(handles=handles, loc='center', bbox_to_anchor=(0.5, 0.05), ncol=len(classifiers))\n    \n    # Adjust spacing between subplots\n    fig.subplots_adjust(wspace=0.3)\n    fig.suptitle(\"Classification metrics\")\n    if metadata[\"display_fig\"]:\n        plt.show(block=False)\n    else:\n        print('INFO: Figure will not be displayed.')\n    return fig", "\n\ndef save_figures(metadata):\n    \"\"\"Saves active  figure to disk\"\"\"\n    # Define filename\n    if metadata[\"normalization\"] and not metadata[\"scaling\"]:\n        figure_filename = f'{metadata[\"task\"]}_{metadata[\"freq_band_type\"]}_normalized_not-scaled.png'\n    elif not metadata[\"normalization\"] and metadata[\"scaling\"]:\n        figure_filename = f'{metadata[\"task\"]}_{metadata[\"freq_band_type\"]}_not-normalized_scaled.png'\n    elif not metadata[\"normalization\"] and not metadata[\"scaling\"]:\n        figure_filename = f'{metadata[\"task\"]}_{metadata[\"freq_band_type\"]}_not-normalized_not-scaled.png'\n\n    # Save the figure\n    metadata[\"roc-plots-filename\"] = figure_filename\n    fig_roc.savefig(os.path.join(figures_dir, figure_filename))\n    boxplot_filename = f'{metadata[\"roc-plots-filename\"][:-4]}_boxplot.png'\n    fig_boxplot.savefig(os.path.join(figures_dir, boxplot_filename))\n    \n    print(f'INFO: Figures \"{figure_filename}\" and \"{boxplot_filename}\" have been saved to folder {figures_dir}')", "    \ndef save_csv(metadata):\n    \"\"\"Saves the classification metrics as a csv\"\"\"\n    csv_filename = f'{metadata[\"roc-plots-filename\"][:-4]}.csv'\n    csv_path = os.path.join(reports_dir, csv_filename)\n    df = metadata[\"metrics\"]\n    with open(csv_path, 'w') as file:\n        file.write(f'#{metadata[\"timestamp\"]}\\n')\n        df.to_csv(file, index=False)\n    print(f'INFO: CSV data with metrics \"{csv_filename}\" has been saved to folder {figures_dir}')", "\nif __name__ == \"__main__\":\n\n    # Save time of beginning of the execution to measure running time\n    start_time = time.time()\n\n    # 1 - Read data\n    handler = PickleDataHandler()\n    dataframe, metadata = handler.load_data()\n\n    # Define scaling methods and classifiers\n    scaling_methods = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n    classifiers = [\n        ('Support Vector Machine', SVC(kernel='rbf', probability=True, random_state=seed)),\n        ('Logistic Regression', LogisticRegression(penalty='l1', solver='liblinear', random_state=seed)),\n        ('Random Forest', RandomForestClassifier(random_state=seed)),\n        ('Linear Discriminant Analysis', LinearDiscriminantAnalysis(solver='svd'))\n    ]\n    metadata[\"Classifiers\"] = classifiers\n\n    # 2 - Initialize command line arguments and save arguments to metadata\n    metadata, args = initialize_argparser(metadata)\n\n    # 3 - Define input data, initialize CV and get data split\n    X, y, data_split = initialize_cv(dataframe, metadata)\n\n    # 4 - Fit classifiers and plot\n    fig_roc, metadata = fit_and_plot(X, y, classifiers, data_split, metadata)\n    # 4.5 - Plot  boxplot\n    fig_boxplot = plot_boxplot(metadata)\n    \n    # 5 -  Add timestamp\n    metadata[\"timestamp\"] = datetime.now()\n\n    # 6 - Save the figure to disk\n    if args.dont_save_fig:\n        print('INFO: Figures will not be saved to disk.')\n    else:\n        save_figures(metadata)\n    \n    # 7 - Save CSV data to reports dir\n    save_csv(metadata)\n    \n    # 8 - Export metadata\n    handler.export_data(dataframe, metadata)\n\n    # Calculate time that the script takes to run\n    execution_time = (time.time() - start_time)\n    print('\\n###################################################\\n')\n    print(f'Execution time of 03_fit_classifier_and_plot.py: {round(execution_time, 2)} seconds\\n')\n    print('###################################################\\n')", ""]}
{"filename": "src/analysis/05_reports_to_pdf.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nBundle up all HTMLs from the `reports_dir` into one PDF naamed 'mtbi_meeg_report.pdf'\nBe careful because it will overwrite files with the same name\n\n@author: Estanislao Porta\n# TODO: Check if filename exists, and avoid overwriting\n\"\"\"\nfrom weasyprint import HTML, CSS", "\"\"\"\nfrom weasyprint import HTML, CSS\nimport os\nimport sys\nSRC_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(SRC_DIR)\nfrom config_common import reports_dir, figures_dir\n\n# Get list of HTML files in directory\nhtml_files = [os.path.join(reports_dir, f) for f in os.listdir(reports_dir) if f.endswith('.html')]", "# Get list of HTML files in directory\nhtml_files = [os.path.join(reports_dir, f) for f in os.listdir(reports_dir) if f.endswith('.html')]\n\n# Load all HTML files and concatenate into a single HTML string\nhtml_string = ''\nfor html_file in html_files:\n    with open(html_file, 'r') as f:\n        html = f.read()\n        if html_string:\n            # Add a page break before all HTML files except the first one\n            html_string += f'<div style=\"page-break-before: always;\"></div>{html}'\n        else:\n            html_string += html", "\n# Used to resolve relative paths from the HTMLs\nbase_url =f'file://{figures_dir}'\n# Initialize a WeasyPrint document\npdf_document = HTML(string=html_string, base_url=base_url)\n\n# Define the CSS styles to apply to the PDF document\ncss = \"\"\"\nimg {\n    max-width: 100%;", "img {\n    max-width: 100%;\n    max-height: 100%;\n    object-fit: contain;\n    }\n    \"\"\"\n# Write the html into a PDF\nfilename='mtbi_meeg_report.pdf'\n\npdf_document.write_pdf(os.path.join(reports_dir, filename), presentational_hints=True, stylesheets=[CSS(string=css)])", "\npdf_document.write_pdf(os.path.join(reports_dir, filename), presentational_hints=True, stylesheets=[CSS(string=css)])\nprint(f\"INFO: Success! All the HTML reports from {reports_dir} have been combined into one PDF named '{filename}'\" )"]}
{"filename": "src/analysis/__init__.py", "chunked_list": [""]}
{"filename": "src/analysis/01_read_processed_data.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n#############################\n# 01_read_processed_data.py #\n#############################\n\n@authors: Verna Heikkinen, Aino Kuusi, Estanislao Porta\n\nReads in EEG data from CSV files into a dataframe", "\nReads in EEG data from CSV files into a dataframe\nEach rows contains bandpower data for each channel and frequency band.\nThe dataframe and the arguments used to run the script are added to a pickle object.\n\nArguments\n---------\n    - task : str\n        Each of the four tasks that have been measured for this experiment:\n        Eyes Closed (ec), Eyes Open (eo),", "        Each of the four tasks that have been measured for this experiment:\n        Eyes Closed (ec), Eyes Open (eo),\n        Paced Auditory Serial Addition Test 1 or 2 (PASAT_1 or PASAT_2)\n    - freq_band_type : str\n        Frequency bands used in the binning of the subject information.\n        Thin bands are 1hz bands from 1 to 43hz.\n        Wide bands are conventional Delta, Theta, Alpha, Beta, Gamma\n    - not_normalized : bool\n        Defines whether channel data is not normalized for all the channels\n", "        Defines whether channel data is not normalized for all the channels\n\nReturns\n-------\n    - eeg_tmp_data.pickle : pickle object\n        Object of pickle format containing the dataframe with the data\n        and the metadata with the information about the arguments\n        used to run this script.\n\n# TODO: Add number of subjects and number of features to metadata", "\n# TODO: Add number of subjects and number of features to metadata\n\"\"\"\n\nimport os\nimport sys\nimport argparse\nimport time\nimport re\n", "import re\n\nimport csv\nimport numpy as np\nimport pandas as pd\n\nSRC_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(SRC_DIR)\nfrom config_common import processed_data_dir, user, host\nfrom config_eeg import thin_bands, wide_bands, select_task_segments, channels", "from config_common import processed_data_dir, user, host\nfrom config_eeg import thin_bands, wide_bands, select_task_segments, channels\nfrom pickle_data_handler import PickleDataHandler\n\n\ndef initialize_argparser_and_metadata():\n    \"\"\" Initialize argparser and add args to metadata.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', choices=['eo','ec','PASAT_1', 'PASAT_2'], help='Define the task: ec, eo, PASAT_1 or PASAT_2. Default=PASAT_2', default='PASAT_2')\n    parser.add_argument('--freq_band_type', choices=['thin', 'wide'], help=\"Define the frequency bands. 'thin' are 1hz bands from 1 to 43hz. 'wide' are conventional delta, theta, etc. Default: wide\", default='wide')\n    parser.add_argument('--not_normalized', action='store_true', help='Data will not be normalized. Default: True', default=False)\n    #parser.add_argument('--threads', type=int, help=\"Number of threads, using multiprocessing\", default=1) \n    args = parser.parse_args()\n\n    # Create dictonary with metadata information\n    # NOTE: It is important that it is CREATED here and not that stuff gets appended\n    metadata = {\"task\": args.task, \"freq_band_type\": args.freq_band_type, \"normalization\": not args.not_normalized}\n    # Define the number of segments per task\n    if metadata[\"task\"] in ('eo', 'ec'):\n        segments = 3\n    elif metadata[\"task\"] in ('PASAT_1', 'PASAT_2'):\n        segments = 2\n    metadata[\"segments\"] = segments\n\n    print('######## \\nINFO: Starting to run 01_read_processed_data.py')\n\n    # Print out the chosen configuration\n    if args.not_normalized:\n        print(f\"INFO: Reading in data from task {args.task}, using {args.freq_band_type} frequency bands. Data **will NOT** be normalized.\")\n    else:\n        print(f\"INFO: Reading in data from task '{args.task}', using '{args.freq_band_type}' frequency bands. Data **will** be normalized.\")\n    return metadata, args", "\ndef read_subjects():\n    \"\"\"\n    Reads in the list of subjects from file subjects.txt. Asserts format to contain two digits and then a letter P or C for Patients or Controls. \n\n    Returns\n    -------\n    - subjects: a list with all the subjects\n\n    \"\"\"\n     # List of extra controls, dismissed so we'd have equal number of P vs C\n    to_exclude = ['32C', '33C', '34C', '35C', '36C', '37C', '38C', '39C', '40C', '41C', '12P']\n\n    subject_pattern = r'^\\d{2}[PC]'\n    try:\n        with open('subjects.txt', 'r') as subjects_file:\n            subjects = [line.rstrip() for line in subjects_file.readlines()]\n            # Assert that each line has the expected format\n            for line in subjects:\n                assert re.match(subject_pattern, line), f\"Subject '{line}' does not have the expected format.\"\n    except FileNotFoundError as error_warning:\n        print(\"The file 'subjects.txt' does not exist in the current directory. The program will exit.\")\n        raise error_warning\n\n    # Excluse subjects with errors\n    for i in to_exclude:\n        subjects.remove(i)\n\n    return subjects", "\ndef create_subjects_and_tasks(chosen_tasks, subjects):\n\n    \"\"\"\n    Combines the subjects and with the chosen tasks and creates a list of subjects_and_tasks\n\n    Arguments\n    ---------\n    - chosen_tasks: list of subtasks pertaining to each task\n    - subjects: list of all the subjects\n\n    Returns\n    -------\n    - subjects_and_tasks: a list with 2-uples formed by all the combinations of (subjects, tasks)\n\n    \"\"\"\n    subjects_and_tasks = [(x, y) for x in subjects for y in chosen_tasks]\n    print(f'INFO: There are {len(subjects_and_tasks)} subject_and_task combinations.')\n\n    return subjects_and_tasks", "\ndef read_data(subjects_and_tasks, freq_band_type, not_normalized, processed_data_dir):\n    \"\"\"\n    Read in processed bandpower data for each subject_and_tasks from files\n    Creates an array of np with PSD data\n\n    Arguments\n    ---------\n    - subjects_and_tasks: list of 2-uples\n            Contains the combinations of subjects and segments (e.g., (Subject1, Task1_segment1), (Subject1, Task1_segment2), ...)\n    - freq_band_type: str\n            Frequency bins, 'thin' or 'wide'\n    - not_normalized: boolean\n            If True, normalization of the PSD data for all channels will not be performed\n    - processed_data_dir: str\n            path to the processed data directory as defined in config_common\n\n    Returns\n    -----\n    - all_bands_vector: list of np arrays\n            Each row contains the PSD data (for the chosen frquency bands and for all channels) per subject_and_tasks\n    \"\"\"\n    # Initialize a list to store processed data for each unique subject+segment combination\n    all_bands_vectors = []\n    if freq_band_type == 'thin':\n        freqs = thin_bands\n    if freq_band_type == 'wide':\n        freqs = wide_bands\n\n    # Iterate over all combinations of (subject, subtask) and populate 'all_bands_vectors' with numpy array 'sub_bands_array' containing processed data for each subject_and_tasks\n    for pair in subjects_and_tasks:\n        # Construct the path pointing to where processed data for (subject,task) is stored\n        subject, task = pair[0].rstrip(), pair[1]\n        path_to_processed_data = os.path.join(f'{processed_data_dir}', f'sub-{subject}', 'ses-01', 'eeg', 'bandpowers', f'{freq_band_type}_{task}.csv')\n\n        # List where the read data will be added\n        subject_and_task_bands_list = []\n\n        # Read csv file and saves each the data to f_bands_list\n        with open(path_to_processed_data, 'r') as file:\n            reader = csv.reader(file)\n            for frequency_band in reader:\n                try:\n                    subject_and_task_bands_list.append([float(f) for f in frequency_band])\n                except ValueError as e:\n                    print(\"Error: Invalid data, could not convert to float\")\n                    raise e\n\n        # Convert list to array\n        if freq_band_type == 'thin':\n            # Thin bands should not need slicing but better safe than sorry\n            subject_and_task_bands_array = np.array(subject_and_task_bands_list[:len(freqs)])\n        else:\n            subject_and_task_bands_array = np.array(subject_and_task_bands_list)\n\n        # Normalize each band\n        if not not_normalized:\n            ch_tot_powers = np.sum(subject_and_task_bands_array, axis=0)\n            subject_and_task_bands_array = subject_and_task_bands_array / ch_tot_powers[None, :]\n\n        subject_and_task_bands_vector = np.concatenate(subject_and_task_bands_array.transpose())\n\n        # Validate subject_and_task_bands_vector length and add to matrix\n        assert len(subject_and_task_bands_vector) == (channels * len(freqs)), f\"Processed data for subject {subject} does not have the expected length when using {freq_band_type} frequency bands.\"\n        all_bands_vectors.append(subject_and_task_bands_vector)\n\n    print(f'INFO: Shape of \\'all_bands_vectors\\' is {len(all_bands_vectors)} x {len(all_bands_vectors[0])}, as expected.')\n    return all_bands_vectors", "\ndef create_data_frame(subjects_and_tasks, all_bands_vectors):\n    \"\"\"\n    Create a dataframe structure to be used by the model_testing and ROC_AUC.py scripts\n\n    Arguments\n    ---------\n    - all_bands_vector: list of np arrays\n            Each row contains the PSD data (for the chosen frquency bands and for all channels) per subject_and_tasks\n    - subjects_and_tasks: list of 2-uples\n            Contains the combinations of subjects and segments (e.g., (Subject1, Task1_segment1), (Subject1, Task1_segment2), ...) \n\n    Returns\n    ------\n    - dataframe: panda dataframe\n            Each row contains the subject_and_task label, the group which it belongs to, and the PSD data (for the chosen frquency bands and for all channels) per subject_and_tasks\n    \"\"\"\n    if not subjects_and_tasks:\n        raise ValueError(\"The list of subject-task combinations cannot be empty.\")\n    if len(all_bands_vectors) == 0:\n        raise ValueError(\"The list of PSD data cannot be empty.\")\n\n    # Create a list of indices of format 'subject_segment'\n    indices = [i[0].rstrip() + '_' + i[1] for i in subjects_and_tasks]\n\n    # Convert list to numpy array to dataframe\n    dataframe = pd.DataFrame(np.array(all_bands_vectors, dtype=object), index=indices)\n\n    groups = []\n    subs = []\n    for subject, _ in subjects_and_tasks:\n        subs.append(subject)\n        if 'P' in subject:\n            groups.append(1)\n        elif 'C' in subject:\n            groups.append(0)\n        else:\n            groups.append(2) # In case there is a problem\n    dataframe.insert(0, 'Group', groups)\n    dataframe.insert(1, 'Subject', subs)\n\n    return dataframe", "\n\nif __name__ == '__main__':\n\n    # Save time of beginning of the execution to measure running time\n    start_time = time.time()\n\n    # 1 - Initialize command line arguments and save arguments to metadata\n    metadata, args = initialize_argparser_and_metadata()\n\n    # 2 - Define subtasks according to input arguments\n    chosen_tasks = select_task_segments(args.task)\n\n    # 3 - Read in the list of subjects from file subjects.txt\n    subjects = read_subjects()\n\n    # 4 - Read in list of subjects from file and create subjects_and_tasks list\n    subjects_and_tasks = create_subjects_and_tasks(chosen_tasks, subjects)\n\n    # 5 - Create list: each row contains all frequency bands and all channels per subject_and_task\n    all_bands_vectors = read_data(subjects_and_tasks, args.freq_band_type, args.not_normalized, processed_data_dir)\n\n    # 6 - Create dataframe\n    dataframe = create_data_frame(subjects_and_tasks, all_bands_vectors)\n\n    # 7 - Add info to metadata\n    if \"k22\" in processed_data_dir:\n        metadata[\"dataset\"] = \"k22\"\n    metadata[\"user\"] = f'{user}@{host}'\n    metadata[\"license\"] = \"MIT License\"\n\n    # 8 - Outputs the pickle object composed by the dataframe file and metadata to be used by 02_plot_processed_data.py and 03_fit_classifier_and_plot.py\n    handler = PickleDataHandler()\n    handler.export_data(dataframe=dataframe, metadata=metadata)\n\n    # Calculate time that the script takes to run\n    execution_time = (time.time() - start_time)\n    print('\\n###################################################\\n')\n    print(f'Execution time of 01_read_processed_data.py is: {round(execution_time,2)} seconds\\n')\n    print('###################################################\\n')", ""]}
{"filename": "src/analysis/count_code_lines.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Mar 23 12:39:16 2023\n\n@author: portae1\n\"\"\"\n\n\ndef count_lines_of_code(filepath):\n    with open(filepath, 'r') as f:\n        lines = f.readlines()\n    count_code = 0\n    count_comments = 0\n    count_docstrings = 0\n    in_multiline_string = False\n    for line in lines:\n        stripped_line = line.strip()\n        if stripped_line.startswith('\"\"\"') or stripped_line.startswith(\"'''\"):\n            if not in_multiline_string:\n                count_docstrings += 1\n            in_multiline_string = not in_multiline_string\n        elif stripped_line.startswith('#') or in_multiline_string:\n            count_comments += 1\n        elif stripped_line:\n            count_code += 1\n    return count_code, count_comments, count_docstrings", "\ndef count_lines_of_code(filepath):\n    with open(filepath, 'r') as f:\n        lines = f.readlines()\n    count_code = 0\n    count_comments = 0\n    count_docstrings = 0\n    in_multiline_string = False\n    for line in lines:\n        stripped_line = line.strip()\n        if stripped_line.startswith('\"\"\"') or stripped_line.startswith(\"'''\"):\n            if not in_multiline_string:\n                count_docstrings += 1\n            in_multiline_string = not in_multiline_string\n        elif stripped_line.startswith('#') or in_multiline_string:\n            count_comments += 1\n        elif stripped_line:\n            count_code += 1\n    return count_code, count_comments, count_docstrings", "# Example usage:\nfile_path = ['01_read_processed_data.py', '02_plot_processed_data.py', '03_fit_classifier_and_plot.py', '04_create_report.py']\nfor file in file_path:\n    num_code_lines, num_comments, num_docstrings = count_lines_of_code(file)\n    print(file)\n    print(f'Number of lines of code: {num_code_lines}')\n    print(f'Number of comments: {num_comments}')\n    print(f'Number of docstrings: {num_docstrings}')"]}
{"filename": "src/analysis/04_create_report.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n#################################\n#    04_create_report.py        #\n#################################\n\n@author: Estanislao Porta\nCreates an HTML report with the images created in the previous step of the pipeline\n", "Creates an HTML report with the images created in the previous step of the pipeline\n\n# TODO: Add classification metrics\n\n# TODO: If control plots are not found, text should be included, not an error?\n\"\"\"\n\nimport os\nimport sys\nSRC_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))", "import sys\nSRC_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(SRC_DIR)\nfrom config_common import figures_dir, reports_dir\nfrom pickle_data_handler import PickleDataHandler \n \nif not os.path.isdir(reports_dir):\n    os.makedirs(reports_dir)\n\n\ndef create_report(metadata):\n    # Define filename & open HTML file\n    report_filename = f'report_{metadata[\"roc-plots-filename\"][:-4]}.html'\n    report_path = os.path.join(reports_dir, report_filename)\n    report = open(report_path, 'w')\n    \n    # General header\n    report.write(f'''\n    <!DOCTYPE html>\n    <html>\n    <head>\n    \t<title>mTBI-EEG - Analysis</title>\n    </head>\n    <body>\n    \t<h1>mTBI-EEG report: {metadata[\"task\"]} - {metadata[\"freq_band_type\"]}</h1>\n    ''')  \n    if metadata[\"normalization\"] and not metadata[\"scaling\"]:\n        report.write('<h2>Normalized - Notq scaled</h2>')\n    if not metadata[\"normalization\"] and metadata[\"scaling\"]:\n        report.write('<h2>Not normalized - Scaled</h2>')\n    if not metadata[\"normalization\"] and not metadata[\"scaling\"]:\n        report.write('<h2>Not normalized - Not scaled</h2>') \n    \n    # Include the PSD Control Plots  \n    if \"psd-control-plot-filename\" in metadata:\n        control_plots = os.path.join(figures_dir, metadata[\"psd-control-plot-filename\"])\n        if not os.path.isfile(control_plots):            \n            raise FileNotFoundError('Control plots were expected but are not found')\n        \n        report.write(f'''\n        <h2>PSD Averages - Control plot</h1>\n        \n        <p>Processed data is plotted in the figure below, to visually assess the data. The PSD for each frequency bin was averaged accross all the channels. The first subplot shows these averages per subject, enabling to identify outliers.</p>\n        \n        <p>In the second subplot, the PSD for each frequency bin was averaged accross all the channels and all the subjects within each group. The standard deviation for both groups is also displayed.</p>\n        <img src=\"{control_plots}\" class=\"center\">\n        ''')\n    else:\n        print('INFO: No control plots')\n    \n    # Include the ROC plots\n    if \"roc-plots-filename\" in metadata:\n        roc_plots = os.path.join(figures_dir, metadata[\"roc-plots-filename\"])\n        \n        if not os.path.isfile(roc_plots):            \n            raise FileNotFoundError('ROC plots were expected but are not found')\n        \n        report.write(f'''   \n        <h2>ROC Plots</h2>\n        <p>Processed data was analyzed using four different ML classifiers. Validation was done using Stratified KFold Cross Validation. The subplots below show the ROC curves obtained using each of the classifiers.</p>\n        <img src=\"{roc_plots}\" class=\"center\">\n        ''')\n    else:\n        raise TypeError('No ROC plots')\n    # Metrics section\n    report.write('''\n                 <h2>Metrics</h2>\n                 ''')\n    metrics = metadata[\"metrics\"].drop('TPR', axis=1)\n    report.write(metrics.to_html(index=False))\n    # Metadata section                     \n    report.write('''\n                 <h2>Metadata</h2>\n                 <ul>\n                 ''')\n    # Loop over the dictionary items and write each key-value pair in a separate row\n    for key, value in metadata.items():\n        if key == \"metrics\":\n            continue\n        report.write(f'<li><b>{key}:</b> {value}</li>\\n')\n    # Close the unordered list and close the body section\n    report.write('''\n        </ul>\n        </body>\n        </html>\n        ''')\n    report.close()\n    print(f'INFO: File \"{report_filename}\" has been created in {reports_dir}.')", "\n\ndef create_report(metadata):\n    # Define filename & open HTML file\n    report_filename = f'report_{metadata[\"roc-plots-filename\"][:-4]}.html'\n    report_path = os.path.join(reports_dir, report_filename)\n    report = open(report_path, 'w')\n    \n    # General header\n    report.write(f'''\n    <!DOCTYPE html>\n    <html>\n    <head>\n    \t<title>mTBI-EEG - Analysis</title>\n    </head>\n    <body>\n    \t<h1>mTBI-EEG report: {metadata[\"task\"]} - {metadata[\"freq_band_type\"]}</h1>\n    ''')  \n    if metadata[\"normalization\"] and not metadata[\"scaling\"]:\n        report.write('<h2>Normalized - Notq scaled</h2>')\n    if not metadata[\"normalization\"] and metadata[\"scaling\"]:\n        report.write('<h2>Not normalized - Scaled</h2>')\n    if not metadata[\"normalization\"] and not metadata[\"scaling\"]:\n        report.write('<h2>Not normalized - Not scaled</h2>') \n    \n    # Include the PSD Control Plots  \n    if \"psd-control-plot-filename\" in metadata:\n        control_plots = os.path.join(figures_dir, metadata[\"psd-control-plot-filename\"])\n        if not os.path.isfile(control_plots):            \n            raise FileNotFoundError('Control plots were expected but are not found')\n        \n        report.write(f'''\n        <h2>PSD Averages - Control plot</h1>\n        \n        <p>Processed data is plotted in the figure below, to visually assess the data. The PSD for each frequency bin was averaged accross all the channels. The first subplot shows these averages per subject, enabling to identify outliers.</p>\n        \n        <p>In the second subplot, the PSD for each frequency bin was averaged accross all the channels and all the subjects within each group. The standard deviation for both groups is also displayed.</p>\n        <img src=\"{control_plots}\" class=\"center\">\n        ''')\n    else:\n        print('INFO: No control plots')\n    \n    # Include the ROC plots\n    if \"roc-plots-filename\" in metadata:\n        roc_plots = os.path.join(figures_dir, metadata[\"roc-plots-filename\"])\n        \n        if not os.path.isfile(roc_plots):            \n            raise FileNotFoundError('ROC plots were expected but are not found')\n        \n        report.write(f'''   \n        <h2>ROC Plots</h2>\n        <p>Processed data was analyzed using four different ML classifiers. Validation was done using Stratified KFold Cross Validation. The subplots below show the ROC curves obtained using each of the classifiers.</p>\n        <img src=\"{roc_plots}\" class=\"center\">\n        ''')\n    else:\n        raise TypeError('No ROC plots')\n    # Metrics section\n    report.write('''\n                 <h2>Metrics</h2>\n                 ''')\n    metrics = metadata[\"metrics\"].drop('TPR', axis=1)\n    report.write(metrics.to_html(index=False))\n    # Metadata section                     \n    report.write('''\n                 <h2>Metadata</h2>\n                 <ul>\n                 ''')\n    # Loop over the dictionary items and write each key-value pair in a separate row\n    for key, value in metadata.items():\n        if key == \"metrics\":\n            continue\n        report.write(f'<li><b>{key}:</b> {value}</li>\\n')\n    # Close the unordered list and close the body section\n    report.write('''\n        </ul>\n        </body>\n        </html>\n        ''')\n    report.close()\n    print(f'INFO: File \"{report_filename}\" has been created in {reports_dir}.')", "\n\nif __name__ == \"__main__\":\n    handler = PickleDataHandler()\n    dataframe, metadata = handler.load_data()\n    create_report(metadata)\n    "]}
{"filename": "src/analysis/run_files.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Mar 15 11:23:04 2023\n\nIt runs the scripts:\n    01_read_processed_data.py,\n    02_plot_processed_data,\n    03_fit_classifier_and_plot.py,\n    04_create_report", "    03_fit_classifier_and_plot.py,\n    04_create_report\n\nIt will:\n- Read processed data for all subjects in subjects.txt\n- Plot control plots and save them to the 'figures_dir'\n- Fit classifiers, plot ROCs, and save the ROC plots and the metrics to a pickle object\n- Create an html report in the 'reports_dir'\n\n\"\"\"", "\n\"\"\"\n\nimport subprocess\n\n# Define a list of tuples containing the different argument combinations to use\narg_sets = [\n#            ('--task', 'eo', '--freq_band_type', 'thin'),\n#            ('--task', 'ec', '--freq_band_type', 'thin'),\n#            ('--task', 'PASAT_1', '--freq_band_type', 'thin'),", "#            ('--task', 'ec', '--freq_band_type', 'thin'),\n#            ('--task', 'PASAT_1', '--freq_band_type', 'thin'),\n            ('--task', 'PASAT_2', '--freq_band_type', 'thin', '--not_normalized'),\n]\n\n\nfor arg_set in arg_sets:\n    # Call the first Python file with each set of arguments\n    proc1 = subprocess.run(['python3', '01_read_processed_data.py'] + list(arg_set), stdout=subprocess.PIPE)\n    print(proc1.stdout.decode('utf-8'))\n    # Call the second Python file without any arguments\n    proc2 = subprocess.run(['python3', '02_plot_processed_data.py'], stdout=subprocess.PIPE)\n    print(proc2.stdout.decode('utf-8'))\n    # Call the third script\n    proc3 = subprocess.run(['python3', '03_fit_classifier_and_plot.py', '--scaling'], stdout=subprocess.PIPE)\n    print(proc3.stdout.decode('utf-8'))\n    # Create report, no arguments\n    proc4 = subprocess.run(['python3', '04_create_report.py'], stdout=subprocess.PIPE)\n    print(proc4.stdout.decode('utf-8'))", "    \nprint('Finished running for all tasks.')\n"]}
{"filename": "src/analysis/02_plot_processed_data.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n#############################\n# 02_plot_processed_data.py #\n#############################\n\n@authors: Verna Heikkinen, Aino Kuusi, Estanislao Porta\n\nPlots the processed EEG data of the PSD intensity (averaged across all channels) vs frequency for each subject and for each group.", "\nPlots the processed EEG data of the PSD intensity (averaged across all channels) vs frequency for each subject and for each group.\n\nIt is used for visual assessment of individual subjects and general group behaviour. Arguments used to run the script are added to pickle object.\n\nArguments\n---------\n    - eeg_tmp_data.pickle : pickle object\n        Object of pickle format containing the dataframe with the data\n        and the metadata with the information about the arguments", "        Object of pickle format containing the dataframe with the data\n        and the metadata with the information about the arguments\n        used to run this script.\n    - control_plot_segment : int\n        Define which of the segments from the task will be used for plotting. \n    - roi : str\n        Defines the Region Of Interest for more localized information (WIP - Not currently functional).\n\nReturns\n-------", "Returns\n-------\n\n    - eeg_tmp_data.pickle : pickle object \n        Object of pickle format containing the dataframe with the data as well as the metadata with the information about the arguments used to run this script.\n\n# TODO: Remove hardcoded values of frequency and use from config_eeg\n# TODO: violin plots?\n# TODO: ROIs. Check this out for rois: https://www.nature.com/articles/s41598-021-02789-9\n\"\"\"", "# TODO: ROIs. Check this out for rois: https://www.nature.com/articles/s41598-021-02789-9\n\"\"\"\nimport time\nimport argparse\nimport os\nimport sys\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSRC_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.append(SRC_DIR)\nfrom config_common import figures_dir\nfrom pickle_data_handler import PickleDataHandler\nfrom config_eeg import channels, thin_bands, wide_bands\n\n#sns.set_style()", "\n#sns.set_style()\n\ndef initialize_argparser(metadata):\n    \"\"\" Initialize argparser and add args to metadata.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-v', '--verbosity', action='store_true', help='Define the verbosity of the output. Default: False', default=False)\n    roi_areas = ['All', 'Frontal', 'Occipital', 'FTC', 'Centro-parietal']\n    parser.add_argument('--roi', type=str, choices=roi_areas, help='ROI areas to be plotted. Default: All', default='All')\n    parser.add_argument('--control_plot_segment', type=int, help='Define which number of segment to use: 1, 2, etc. Default: 1', metavar='', default=1)    \n    #parser.add_argument('--threads', type=int, help=\"Number of threads, using multiprocessing\", default=1) #skipped for now\n    args = parser.parse_args()\n\n    # Add the input arguments to the metadata dictionary\n    metadata[\"control_plot_segment\"] = args.control_plot_segment\n    if metadata[\"control_plot_segment\"] > metadata[\"segments\"]:\n        raise IndexError(f'List index out of range. The segment you chose is not allowed for task {metadata[\"task\"]}. Please choose a value between 1 and {metadata[\"segments\"]}.')\n    metadata[\"roi\"] = args.roi\n    return metadata", "\ndef define_freq_bands(metadata):\n    if metadata[\"freq_band_type\"] == 'thin':\n        #freqs = np.array([x for x in range(1, 43)])\n        freqs = np.array([bands[0] for bands in thin_bands])\n    elif metadata[\"freq_band_type\"] == 'wide':\n        #freqs = np.array([1, 3, 5.2, 7.6, 10.2, 13, 16, 19.2, 22.6, 26.2, 30, 34, 38.2]).T\n        freqs = np.array([bands[0] for bands in wide_bands])\n\n    return freqs", "\ndef global_averaging(df, metadata, freqs):\n\n    if df.isnull().values.any():\n        raise ValueError(\"Error: There is at least one NaN value.\") \n\n    global_averages = []\n\n     # Transform data to array, change to logscale and re-shape to 2D. Calculate average across all channels per subject \n    for idx in df.index:\n        subj_arr = np.array(df.loc[idx])[2:]\n        subj_arr = 10 * np.log10(subj_arr.astype(float))\n        if subj_arr.size == 0:\n            raise ValueError(\"Error: Empty data array.\")\n        else:\n            try:\n                subj_arr = np.reshape(subj_arr, (channels, freqs.size))\n            except ValueError as e:\n                print(\"Error: Data array has incorrect dimensions.\")\n                raise e\n        if metadata[\"roi\"] == 'Frontal':\n            subj_arr = subj_arr[0:22, :]\n        GA = np.mean(subj_arr, axis=0)\n        global_averages.append(GA)\n\n    return global_averages", "\ndef create_df_for_plotting(df, metadata, freqs, global_averages):\n\n    plot_df = pd.DataFrame(np.array(global_averages), columns=freqs)\n    plot_df = plot_df.set_index(df.index)\n    plot_df.insert(0, \"Subject\", df['Subject'])\n    plot_df.insert(1, \"Group\", df['Group'])\n\n    # Slice the array based on the index of the segment to plot\n    segment_index = metadata[\"control_plot_segment\"] - 1\n    plot_df = plot_df[segment_index:len(df):metadata[\"segments\"]]\n\n    return plot_df", "\ndef plot_control_figures(plot_df, metadata):\n    '''\n    Plot a figure with two subplots: one with individual patients and another with group means and SD\n    '''\n\n    f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n    #plt.style.use('seaborn-darkgrid')\n    figure_title = f'Average PSD over all channels vs frequency. \\nTask: {metadata[\"task\"]}, Freq band: {metadata[\"freq_band_type\"]}, Channel data normalization: {metadata[\"normalization\"]} \\nUsing segment {metadata[\"control_plot_segment\"]} out of {metadata[\"segments\"]}, Region of interest: {metadata[\"roi\"]}.'\n    f.suptitle('PSD data - Subjects and group averages')\n    ax1.set_xlim(0, freqs[-1]+2)\n    # Subplot 1\n    ax1.set_ylabel('PSD (dB)')\n    ax1.set_xticks(range(0, 40, 5))\n    ax2.set_xticks(range(0, 40, 5))\n\n    for _, row in plot_df.iterrows():\n        if row['Group'] == 1:\n            col = 'tab:red'\n        else:\n            col = 'tab:green'\n        data = row[2:]\n        data = np.array(data)\n        ax1.plot(freqs, data.T, color=col, alpha=0.2)\n        legend_elements = [plt.Line2D([0], [0], color='g', lw=1, label='Controls'),\n                   plt.Line2D([0], [0], color='r', lw=1, label='Patients')]\n        ax1.legend(handles=legend_elements)\n        #ax1.text(x=freqs[-1], y=data[-1], s=row['Subject'], horizontalalignment='left', size='small', color=col)\n    \n    # Subplot 2\n    #Calculate means of each group & plot\n    group_means = plot_df.groupby('Group').mean(numeric_only=True)\n    ax2.plot(freqs, group_means.iloc[0, :], 'tab:green', linestyle='--', linewidth=1, label='Mean controls')\n    ax2.plot(freqs, group_means.iloc[1, :], color='tab:red', linestyle='-.', linewidth=1, label='Mean patients')\n\n    ax2.set_xlabel('Frequency (Hz)')\n    ax2.set_ylabel('PSD (dB)') #only if no channel scaling\n    ax2.legend()\n\n    # Calculate SD of each group & plot around means\n    group_sd = plot_df.groupby('Group').std(numeric_only=True)\n    c_plus = group_means.iloc[0, :] + group_sd.iloc[0, :]\n    c_minus = group_means.iloc[0, :] - group_sd.iloc[0, :]\n    ax2.fill_between(freqs, c_plus, c_minus, color='tab:green', alpha=.2, linewidth=.5)\n\n    p_plus = group_means.iloc[1, :] + group_sd.iloc[1, :]\n    p_minus = group_means.iloc[1, :] - group_sd.iloc[1, :]\n    ax2.fill_between(freqs, p_plus, p_minus, color='tab:red', alpha=.2, linewidth=.5)", "\ndef save_fig(metadata):\n    \"\"\"\n    Saves fig to disk\n    \"\"\"\n    if metadata[\"normalization\"]:\n        fig_filename = f'psd-control-plot_{metadata[\"task\"]}_{metadata[\"freq_band_type\"]}_normalized.png'\n    else:\n        fig_filename = f'psd-control-plot_{metadata[\"task\"]}_{metadata[\"freq_band_type\"]}_not-normalized.png'\n    plt.savefig(os.path.join(figures_dir, fig_filename))\n    metadata[\"psd-control-plot-filename\"] = fig_filename\n    print(f'INFO: Figure \"{fig_filename}\" has been saved to folder {figures_dir}')\n    return metadata", "\n\nif __name__ == '__main__':\n\n    # Save time of beginning of the execution to measure running time\n    start_time = time.time()\n\n    # Execute the submethods:\n    # 1 - Read data\n    handler = PickleDataHandler()\n    dataframe, metadata = handler.load_data()\n\n    # 2 - InitializeInitialize command line arguments and save arguments to metadata\n    metadata = initialize_argparser(metadata)\n\n    # 3 - Define Frequency bands\n    freqs = define_freq_bands(metadata)\n\n    # 4 - Do global averaging and ROI slicing\n    global_averages = global_averaging(dataframe, metadata, freqs)\n\n    # 5- Create DF for plotting\n    plot_df = create_df_for_plotting(dataframe, metadata, freqs, global_averages)\n\n    # 6 - Plot control plot\n    plot_control_figures(plot_df, metadata)\n\n    # 7 - Save active figure and add information to metadata\n    metadata = save_fig(metadata)\n\n    # 8 - Export pickle object\n    handler.export_data(dataframe, metadata)\n\n    # Calculate time that the script takes to run\n    execution_time = (time.time() - start_time)\n    print('\\n###################################################\\n')\n    print(f'Execution time of 02_plot_processed_data.py: {round(execution_time, 2)} seconds\\n')\n    print('###################################################\\n')", ""]}
{"filename": "src/analysis/03_psd_topoplots.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nPlots PSD info in an interactive manner.\n\nPlot PSDS as a topoplot:\n    - channelwise average PSDS\n    - global averages\n\n", "\n\nCreated on Fri Apr 14 10:15:13 2023\n\n# TODO: Refactor into modular structure\n\n@author: heikkiv\n\"\"\"\n\nimport os", "\nimport os\nimport sys\nimport mne\nimport numpy as np\nimport pandas as pd\nimport h5py\n\nimport matplotlib.pyplot as plt\nfrom mne.viz import iter_topography", "import matplotlib.pyplot as plt\nfrom mne.viz import iter_topography\n#from mne.time_frequency import read_spectrum\n\nparent_dir = os.path.abspath(os.path.join(os.path.dirname('src'), '..'))\nsys.path.append(parent_dir)\nfrom config_eeg import fname\n\n# COMMENT/Question: is it ok if this cannot be run from console?\n", "# COMMENT/Question: is it ok if this cannot be run from console?\n\n#read in the subjects\nwith open('subjects.txt', 'r') as subjects_file:\n    subjects = [line.rstrip() for line in subjects_file.readlines()]\n\n#define task to be plotted\ntask = 'PASAT_run2'\n\n# Idea: store the data in a ?nested? dictionary", "\n# Idea: store the data in a ?nested? dictionary\n# subj_data = {\n#  'task' : task name (maybe unnecessary)\n#  'group': patient / control\n#  'data' : ndarray of psds?\n#  'age' : int, could be added but omitted for now. \n# }\n\nPSD_allsubj = {}", "\nPSD_allsubj = {}\n\nfor subject in subjects:\n    subject_psds = fname.psds(subject=subject, ses='01')\n\n    try:\n        f = h5py.File(subject_psds, 'r')\n    except:\n        print(\"Psds file corrupted or missing\")\n        \n    psds_keys = list(f.keys())\n    psds_data = f[psds_keys[0]]\n    data_keys = list(psds_data)\n    data = dict()\n    \n    freqs = np.array(psds_data['key_freqs']) #extract freq info\n    \n    if 'P' in subject:\n        group='Patient' \n    elif 'C' in subject:\n        group='Control'\n    \n    for i in data_keys:\n        if 'eo' in i or 'ec' in i or 'PASAT' in i:\n            dict_key = i.removeprefix('key_')\n            # Take only the first segment run of the task, for now.\n            if task in dict_key and dict_key.endswith('_1'): \n                psds = np.array(psds_data[i])\n                # scale to dB\n                psds = 20 * np.log10(psds)\n                #define the task name \n                task = dict_key.removesuffix('_2') \n                \n                PSD_allsubj[subject] = {'task': task, \n                                        'group': group,\n                                        'data': psds}            \n    f.close()", "\n#%%Create a df from dict\nPSD_df = pd.DataFrame.from_dict(PSD_allsubj, orient='index')\n\n# Calculate ch-wise mean psds per group\nclinical_groups = PSD_df.groupby('group')\n\ngroup_ch_means = []\nnames = [] \nfor name, group_df in clinical_groups:\n    group_data = group_df['data']\n    Arr = np.array([i for i in group_data]) #nsubj x n_chs x n_freq\n    mean_data = np.mean(Arr, axis=0) #get mean data over all subjects within group\n    group_ch_means.append(mean_data)\n    names.append(name)", "names = [] \nfor name, group_df in clinical_groups:\n    group_data = group_df['data']\n    Arr = np.array([i for i in group_data]) #nsubj x n_chs x n_freq\n    mean_data = np.mean(Arr, axis=0) #get mean data over all subjects within group\n    group_ch_means.append(mean_data)\n    names.append(name)\n\ngroup_n_mean1 = zip(names, group_ch_means)\ngroup_n_mean = [(name, psd_data) for name, psd_data in group_n_mean1]", "group_n_mean1 = zip(names, group_ch_means)\ngroup_n_mean = [(name, psd_data) for name, psd_data in group_n_mean1]\n\n#read in one raw data file to get sensor location info\nraw = mne.io.read_raw_fif(fname.clean(subject=subject, task='ec', run=1,ses='01'),\n                   preload=True)\n\n#%% Plotting functions and utils\ndef my_callback1(ax, ch_idx):\n    \"\"\"\n    This block of code is executed once you click on one of the channel axes\n    in the plot. To work with the viz internals, this function should only take\n    two parameters, the axis and the channel or data index.\n    \"\"\"\n    for name, data in group_n_mean:\n        ax.plot(freqs, data[ch_idx], label=name) #for all the group averages\n        ax.set_xlabel('Frequency (Hz)')\n        ax.set_ylabel('Power (dB)')\n        ax.legend(loc=\"upper right\")", "def my_callback1(ax, ch_idx):\n    \"\"\"\n    This block of code is executed once you click on one of the channel axes\n    in the plot. To work with the viz internals, this function should only take\n    two parameters, the axis and the channel or data index.\n    \"\"\"\n    for name, data in group_n_mean:\n        ax.plot(freqs, data[ch_idx], label=name) #for all the group averages\n        ax.set_xlabel('Frequency (Hz)')\n        ax.set_ylabel('Power (dB)')\n        ax.legend(loc=\"upper right\")", "        \ndef my_callback2(ax, ch_idx):\n    \"\"\"\n    Once clicked in the topoplot, plots cohort mean PSD with individual traces.\n    It does so separately for each cohort, otherwise plots become too crowded.\n    \"\"\"\n    name, group_mean = group_n_mean[i] #which group. TODO: name!\n    cohort_data = clinical_groups.get_group(name)\n\n    ax.plot(freqs, group_mean[ch_idx], color=colors[i], label=f'{name} mean', lw=2) #for all the group averages\n    ax.set_xlabel('Frequency (Hz)')\n    ax.set_ylabel('Power (dB)')\n    ax.legend(loc=\"upper right\")\n    \n    for index, row in cohort_data.iterrows(): #generally it's ill-advised to loop over df rows\n        data = row['data']\n        ax.plot(freqs, data[ch_idx], color=colors[i], alpha=0.2) #for all the group averages\n        ax.text(90, data[ch_idx,-1], index, size='small')", "\n# Define colours\nprop_cycle = plt.rcParams['axes.prop_cycle']\ncolors = prop_cycle.by_key()['color']\n\ni=1 #zero for controls, 1 for patients\n\n#loop through all channels and create an axis for them\nfor ax, idx in iter_topography(raw.info,\n                               fig_facecolor='white',\n                               axis_facecolor='white',\n                               axis_spinecolor='white',\n                               on_pick=my_callback1):\n    ax.plot(psds[idx], color='grey') #just to show some general output for the big figure", "for ax, idx in iter_topography(raw.info,\n                               fig_facecolor='white',\n                               axis_facecolor='white',\n                               axis_spinecolor='white',\n                               on_pick=my_callback1):\n    ax.plot(psds[idx], color='grey') #just to show some general output for the big figure\n    \nplt.gcf().suptitle(f'Power spectral densities, {task}')\nplt.show()", "plt.show()"]}
{"filename": "src/other_files/04b_fooof.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nFits a FOOOF (fitting oscillations & one over f) model for PSDs.\nCreates alternative/additional features to channel bandpowers \n\nCreated on Fri Feb 24 12:26:23 2023\n\n@author: heikkiv\n\"\"\"", "@author: heikkiv\n\"\"\"\n\nimport numpy as np\nimport h5py \nimport mne\nimport argparse\nfrom pathlib import Path\nfrom fooof import FOOOF\nimport datetime", "from fooof import FOOOF\nimport datetime\nimport time\nfrom config_eeg import fname, f_bands\n\nimport sys\nsys.path.append('../analysis/')\n#from 01_read_processed_data import define_subtasks #THIS DOES NOT WORK due to number in the beginning\n\n\ndef define_subtasks(task):\n    \"\"\"\n    Define the subtasks to be used for the analysis\n    \n    \n    Input parameters\n    ---------\n    - task: chosen task (eyes open, eyes closed, Paced Auditory Serial Addition Test 1 or PASAT 2)\n    \n    Returns\n    -------\n    - chosen_tasks: The list of chosen subtasks\n    \"\"\"\n    tasks = [['ec_1', 'ec_2', 'ec_3'], \n             ['eo_1', 'eo_2', 'eo_3'], \n             ['PASAT_run1_1', 'PASAT_run1_2'], \n             ['PASAT_run2_1', 'PASAT_run2_2']]\n       \n    # Define which files to read for each subject\n    if task == 'ec':\n        chosen_tasks = tasks[0]\n    elif task == 'eo':\n        chosen_tasks = tasks[1]\n    elif task == 'PASAT_1':\n        chosen_tasks = tasks[2]\n    elif task == 'PASAT_2': \n        chosen_tasks = tasks[3]\n    else:\n        raise(\"Incorrect task\")\n    \n    \n    return chosen_tasks", "\n\ndef define_subtasks(task):\n    \"\"\"\n    Define the subtasks to be used for the analysis\n    \n    \n    Input parameters\n    ---------\n    - task: chosen task (eyes open, eyes closed, Paced Auditory Serial Addition Test 1 or PASAT 2)\n    \n    Returns\n    -------\n    - chosen_tasks: The list of chosen subtasks\n    \"\"\"\n    tasks = [['ec_1', 'ec_2', 'ec_3'], \n             ['eo_1', 'eo_2', 'eo_3'], \n             ['PASAT_run1_1', 'PASAT_run1_2'], \n             ['PASAT_run2_1', 'PASAT_run2_2']]\n       \n    # Define which files to read for each subject\n    if task == 'ec':\n        chosen_tasks = tasks[0]\n    elif task == 'eo':\n        chosen_tasks = tasks[1]\n    elif task == 'PASAT_1':\n        chosen_tasks = tasks[2]\n    elif task == 'PASAT_2': \n        chosen_tasks = tasks[3]\n    else:\n        raise(\"Incorrect task\")\n    \n    \n    return chosen_tasks", "\n\n# Save time of beginning of the execution to measure running time\nstart_time = time.time()\n\n# Deal with command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nparser.add_argument('task', help='Which measurement condition to use')\nargs = parser.parse_args()", "parser.add_argument('task', help='Which measurement condition to use')\nargs = parser.parse_args()\n\n\n\nsubject_psds = fname.psds(subject=args.subject, ses='01')\n  \nf = h5py.File(subject_psds, 'r')\npsds_keys = list(f.keys())\npsds_data = f[psds_keys[0]]", "psds_keys = list(f.keys())\npsds_data = f[psds_keys[0]]\ndata_keys = list(psds_data)\ndata = dict()\n\n# Add the data for each PSD to the dictionary 'data'\nfor i in data_keys:\n    if 'eo' in i or 'ec' in i or 'PASAT' in i:\n        dict_key = i.removeprefix('key_')\n        data[dict_key]=np.array(psds_data[i])", "freqs = np.array(psds_data['key_freqs'])\ninfo_keys = list(psds_data['key_info'])\n\nf.close()\n\n  # Calculate the average bandpower for each PSD\nfor data_obj in list(data.keys()):\n    data_bandpower =[] \n    for band in f_bands:\n        fmin, fmax = band[0], band[1]\n        \n        min_index = np.argmax(freqs > fmin) - 1\n        max_index = np.argmax(freqs > fmax) -1\n        \n        bandpower = np.trapz(data[data_obj][:, min_index: max_index], freqs[min_index: max_index], axis = 1)\n        \n        data_bandpower.append(bandpower)\n    \n    avg_bandpower=np.array([np.mean(power) for power in data_bandpower])\n    freqs=np.arange(1,90, step=1)\n    \n    # Initialize a FOOOF object (Here on a rougher scale)\n    fm = FOOOF()\n    # Set the frequency range to fit the model\n    freq_range = [2, 80]\n    # Report: fit the model, print the resulting parameters, and plot the reconstruction\n    fm.report(freqs, avg_bandpower, freq_range)", "\n\nchosen_task = define_subtasks(task=args.task) #TODO: different name perhaps?\nspectra = data[chosen_task[0]]\nglobal_avg = np.mean(spectra, axis=0)  #Global characteristics OR analysis on some/all chs?\n\n# I do not yet know how I want the script to be...\n# Loop through everyhing or do one task only? Also where to save results?\n\n# Initialize a FOOOF object", "\n# Initialize a FOOOF object\nfm = FOOOF()\n\n# Set the frequency range to fit the model\nfreq_range = [2, 60]\n\n# Report: fit the model, print the resulting parameters, and plot the reconstruction\nfm.report(freqs, global_avg, freq_range)\n    ", "fm.report(freqs, global_avg, freq_range)\n    \n# Combine peak representations\nfm.plot(plot_aperiodic=True, plot_peaks='line-shade-outline', plt_log=False)\n\n\n\n# Calculate time that the script takes to run\nexecution_time = (time.time() - start_time)\nprint('\\n###################################################\\n')", "execution_time = (time.time() - start_time)\nprint('\\n###################################################\\n')\nprint(f'Execution time of 04_bandpower.py is: {round(execution_time,2)} seconds\\n')\nprint('###################################################\\n')\n\n    "]}
{"filename": "src/other_files/plot.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Sep 16 10:28:20 2022\n\n@author: aino\n\nPlots ROI grand averages or PSDs for a task. \nTo run, use runscript.py\n\"\"\"", "To run, use runscript.py\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport argparse\n\n\ndef plot_ROI_grand_averages(df, bands, n_runs, n_channels):\n    \"\"\"\n    Plots grand averages for frontal lobe, occipital lobe and all sensors. Patients vs controls.\n\n    Parameters\n    ----------\n    df : DataFrame\n        Data.\n    bands : list\n        Labels for frequency bands.\n    n_runs : int\n        Number of runs per subject.\n    n_channels : int\n        Number of channels in EEG (this isn't probably needed)\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    log_df = np.log10(df.iloc[:, 2:n_f_bands*n_channels+1])\n    # ROI total powers for each frequency band\n    global_tot = []\n    frontal_tot = []\n    occipital_tot = []\n    \n    # Get information for each channel\n    for i in range(n_channels):\n        global_tot.append(log_df.iloc[:, 0+n_f_bands*i:n_f_bands+n_f_bands*i])\n        if i < 23:\n            frontal_tot.append(log_df.iloc[:, 0+n_f_bands*i:n_f_bands+n_f_bands*i])\n        if i > 54:\n            occipital_tot.append(log_df.iloc[:, 0+n_f_bands*i:n_f_bands+n_f_bands*i]) \n    # global_tot is a list on dataframes (n_f_bands x (subjects + tasks)). Each element of this list represents a single channel\n    global_df = np.add(global_tot[0], global_tot[1])\n    frontal_df = np.add(frontal_tot[0], frontal_tot[1])\n    occipital_df = np.add(occipital_tot[0], occipital_tot[1])\n    # Sum the dataframes such that we get one dataframe (n_f_bands x (subjects + tasks)) and the total bandpower for each frequency band\n    for i in range(n_channels-3):\n        global_df = np.add(global_df, global_tot[i+2])\n        if i < 21:\n            frontal_df = np.add(frontal_df, frontal_tot[i+2])\n        if i < 6:\n            occipital_df = np.add(occipital_df, occipital_tot[i+2])\n    # Problem: for channel 64 there are only 88 frequency bands?? \n    \n    #Divide the total bandpowers by the number of channels\n    global_df = np.divide(global_df, 63)\n    frontal_df = np.divide(frontal_df, 22)\n    occipital_df = np.divide(occipital_df, 9)\n    # Insert 'Group' column\n    global_df.insert(0, 'Group', groups)\n    frontal_df.insert(0, 'Group', groups)\n    occipital_df.insert(0, 'Group', groups)\n    \n    # Calculate the number of patients and controls\n    controls = len(global_df.loc[global_df['Group'] == 0])/n_runs\n    patients = len(global_df.loc[global_df['Group']==1])/n_runs\n    # Calculate and plot grand average patients vs controls \n\n    controls_total_power = np.sum(global_df.loc[global_df['Group']==0], axis = 0)\n    controls_average = np.divide(controls_total_power[1:n_f_bands+1], controls)\n    patients_total_power = np.sum(global_df.loc[global_df['Group']==1], axis = 0)    \n    patients_average = np.divide(patients_total_power[1:n_f_bands+1], patients)\n\n\n\n    axes[0].plot(bands, controls_average, label='Controls')\n    axes[0].plot(bands, patients_average, label='Patients')\n    axes[0].title.set_text('Global average')\n    axes[0].legend()\n\n    # Plot region of interest\n    # Occipital lobe (channels 55-64)\n    controls_sum_o = np.sum(occipital_df.loc[global_df['Group']==0], axis = 0)\n    controls_average_o = np.divide(controls_sum_o[1:n_f_bands+1], controls)\n    patients_sum_o = np.sum(occipital_df.loc[global_df['Group']==1], axis = 0)    \n    patients_average_o = np.divide(patients_sum_o[1:n_f_bands+1], patients)\n\n    axes[1].plot(bands, controls_average_o, label='Controls')\n    axes[1].plot(bands, patients_average_o, label='Patients')\n    axes[1].title.set_text('Frontal lobe')\n    axes[1].legend()\n\n    # Frontal lobe (channels 1-22 (?))\n    controls_sum_f = np.sum(frontal_df.loc[global_df['Group']==0], axis = 0)\n    controls_average_f = np.divide(controls_sum_f[1:n_f_bands+1], controls)\n    patients_sum_f = np.sum(frontal_df.loc[global_df['Group']==1], axis = 0)    \n    patients_average_f = np.divide(patients_sum_f[1:n_f_bands+1], patients)\n\n    axes[2].plot(bands, controls_average_f, label='Controls')\n    axes[2].plot(bands, patients_average_f, label='Patients')\n    axes[2].title.set_text('Occipital lobe')\n    axes[2].legend()\n\n    fig.supxlabel('Frequency (Hz)')\n    fig.supylabel('Normalized PSDs')", "\ndef plot_ROI_grand_averages(df, bands, n_runs, n_channels):\n    \"\"\"\n    Plots grand averages for frontal lobe, occipital lobe and all sensors. Patients vs controls.\n\n    Parameters\n    ----------\n    df : DataFrame\n        Data.\n    bands : list\n        Labels for frequency bands.\n    n_runs : int\n        Number of runs per subject.\n    n_channels : int\n        Number of channels in EEG (this isn't probably needed)\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    log_df = np.log10(df.iloc[:, 2:n_f_bands*n_channels+1])\n    # ROI total powers for each frequency band\n    global_tot = []\n    frontal_tot = []\n    occipital_tot = []\n    \n    # Get information for each channel\n    for i in range(n_channels):\n        global_tot.append(log_df.iloc[:, 0+n_f_bands*i:n_f_bands+n_f_bands*i])\n        if i < 23:\n            frontal_tot.append(log_df.iloc[:, 0+n_f_bands*i:n_f_bands+n_f_bands*i])\n        if i > 54:\n            occipital_tot.append(log_df.iloc[:, 0+n_f_bands*i:n_f_bands+n_f_bands*i]) \n    # global_tot is a list on dataframes (n_f_bands x (subjects + tasks)). Each element of this list represents a single channel\n    global_df = np.add(global_tot[0], global_tot[1])\n    frontal_df = np.add(frontal_tot[0], frontal_tot[1])\n    occipital_df = np.add(occipital_tot[0], occipital_tot[1])\n    # Sum the dataframes such that we get one dataframe (n_f_bands x (subjects + tasks)) and the total bandpower for each frequency band\n    for i in range(n_channels-3):\n        global_df = np.add(global_df, global_tot[i+2])\n        if i < 21:\n            frontal_df = np.add(frontal_df, frontal_tot[i+2])\n        if i < 6:\n            occipital_df = np.add(occipital_df, occipital_tot[i+2])\n    # Problem: for channel 64 there are only 88 frequency bands?? \n    \n    #Divide the total bandpowers by the number of channels\n    global_df = np.divide(global_df, 63)\n    frontal_df = np.divide(frontal_df, 22)\n    occipital_df = np.divide(occipital_df, 9)\n    # Insert 'Group' column\n    global_df.insert(0, 'Group', groups)\n    frontal_df.insert(0, 'Group', groups)\n    occipital_df.insert(0, 'Group', groups)\n    \n    # Calculate the number of patients and controls\n    controls = len(global_df.loc[global_df['Group'] == 0])/n_runs\n    patients = len(global_df.loc[global_df['Group']==1])/n_runs\n    # Calculate and plot grand average patients vs controls \n\n    controls_total_power = np.sum(global_df.loc[global_df['Group']==0], axis = 0)\n    controls_average = np.divide(controls_total_power[1:n_f_bands+1], controls)\n    patients_total_power = np.sum(global_df.loc[global_df['Group']==1], axis = 0)    \n    patients_average = np.divide(patients_total_power[1:n_f_bands+1], patients)\n\n\n\n    axes[0].plot(bands, controls_average, label='Controls')\n    axes[0].plot(bands, patients_average, label='Patients')\n    axes[0].title.set_text('Global average')\n    axes[0].legend()\n\n    # Plot region of interest\n    # Occipital lobe (channels 55-64)\n    controls_sum_o = np.sum(occipital_df.loc[global_df['Group']==0], axis = 0)\n    controls_average_o = np.divide(controls_sum_o[1:n_f_bands+1], controls)\n    patients_sum_o = np.sum(occipital_df.loc[global_df['Group']==1], axis = 0)    \n    patients_average_o = np.divide(patients_sum_o[1:n_f_bands+1], patients)\n\n    axes[1].plot(bands, controls_average_o, label='Controls')\n    axes[1].plot(bands, patients_average_o, label='Patients')\n    axes[1].title.set_text('Frontal lobe')\n    axes[1].legend()\n\n    # Frontal lobe (channels 1-22 (?))\n    controls_sum_f = np.sum(frontal_df.loc[global_df['Group']==0], axis = 0)\n    controls_average_f = np.divide(controls_sum_f[1:n_f_bands+1], controls)\n    patients_sum_f = np.sum(frontal_df.loc[global_df['Group']==1], axis = 0)    \n    patients_average_f = np.divide(patients_sum_f[1:n_f_bands+1], patients)\n\n    axes[2].plot(bands, controls_average_f, label='Controls')\n    axes[2].plot(bands, patients_average_f, label='Patients')\n    axes[2].title.set_text('Occipital lobe')\n    axes[2].legend()\n\n    fig.supxlabel('Frequency (Hz)')\n    fig.supylabel('Normalized PSDs')", "    # TODO: scale the plot so that all x-axis labels are visible \n    \n    \ndef plot(df, task, bands):\n    \"\"\"\n    Plots PSDs for controls and patients\n\n    Parameters\n    ----------\n    df : DataFrame\n        Data.\n    task : str\n        (is this needed? probably not)\n    bands : str\n        Wide or thin bands - used to determine the number of bands\n\n    Returns\n    -------\n    None.\n\n    \"\"\"\n    #vectorized data back to matrix (n*m), from which we should calculate global powers\n    #So each df row now has [ch1_freq1, ..., ch64_freq89, ch2_freq1, ..., ch64_freq1, ...ch64_freq64] \n    \n    #-> revert these\n    \n    subject_array_list = [];\n    global_averages = [];\n    \n    drop_subs=False\n    ROI = 'All' #One of 'All', 'Frontal', 'Occipital', 'FTC', 'Centro-parietal'\n \n    if bands == 'wide':\n        n_bands = 6\n    elif bands == 'thin':\n        n_bands = 89\n    else:\n        raise(\"incorrect value for --freq_bands\")\n    freqs = np.array([x for x in range(0,n_bands)]) #todo: pls no hardcoded values!\n    \n    #check this out for rois: https://www.nature.com/articles/s41598-021-02789-9\n    \n    for idx in df.index:\n        subj_data=df.loc[idx]\n        subj_arr = np.array(subj_data)[3:len(subj_data)]\n        subj_arr = 10*np.log10(subj_arr.astype(float))\n        \n        #reshape to 2D array again: (+ change to logscale)\n        subj_arr = np.reshape(subj_arr, (64, n_bands)) #Rows=channels, cols=freqbands\n        \n        if ROI == 'frontal': #TODO: check these channels\n            subj_arr = subj_arr[0:22,:]\n        #calculate global average power accross all chs:\n        GA = np.mean(subj_arr, axis=0)\n        global_averages.append(GA)\n        #TODO: same for ROIs?\n        \n    df.reset_index(inplace=True)\n    #shoo=np.array(global_averages)\n    plot_df = pd.DataFrame(np.array(global_averages), columns=freqs)\n    plot_df.set_index(df.index)\n    plot_df['Group'] =  df['Group'].values\n    plot_df['Subject'] = df['index'].values\n    \n    \n    \n    plot_df = plot_df.iloc[::2,:] #take every other value(=1obs. per subject)\n    \n    #The following subjects have very low power in PASAT_1:\n    subs_to_drop=['15P', '19P', '31P', '36C', '08P', '31C']\n    if drop_subs:\n        for sub in subs_to_drop:\n            plot_df = plot_df.drop(plot_df[plot_df['Subject']==sub].index)\n\n    \n    for subj in plot_df['Subject'].values: \n        data = plot_df.loc[lambda plot_df: plot_df['Subject']==subj]\n        group = int(data['Group'])\n        if group==1: \n            col='red' #change color based on clinical status\n        else:\n            col='green'\n        \n        i=list(plot_df['Subject'].values).index(subj)\n        \n        data=data.drop(['Group', 'Subject'], axis=1)\n        plt.plot(freqs, data.values.T, color=col, alpha=0.2)\n        plt.text(n_bands +1 ,data.values.T[-1], subj, horizontalalignment='left', size='small', color=col)\n    \n    #Calculate also means of controls and patients\n    del plot_df['Subject']\n    group_means=plot_df.groupby('Group').mean()\n    \n    plt.plot(freqs, group_means.iloc[0,:], 'g--', linewidth=1, label='Controls')\n    plt.plot(freqs, group_means.iloc[1,:], 'r-.', linewidth=1, label='Patients')\n    df = pd.read_csv('/net/tera2/home/aino/work/mtbi-eeg/python/analysis/dataframe.csv')\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('PSD (dB)') #only if no channel scaling\n    plt.title(f'{ROI}')\n    plt.legend()\n    \n    #Make SD plot\n    plt.figure()\n    group_sd=plot_df.groupby('Group').std()\n    \n    \n    plt.plot(freqs, group_means.iloc[0,:], 'g--', linewidth=1, label='Controls')\n    plt.plot(freqs, group_means.iloc[1,:], 'r-.', linewidth=1, label='Patients')\n    \n    c_plus=group_means.iloc[0,:]+group_sd.iloc[0,:]\n    c_minus=group_means.iloc[0,:]-group_sd.iloc[0,:]\n    plt.fill_between(freqs, c_plus, c_minus, color='g', alpha=.2, linewidth=.5)\n    \n    p_plus=group_means.iloc[1,:]+group_sd.iloc[1,:]\n    p_minus=group_means.iloc[1,:]-group_sd.iloc[1,:]\n    plt.fill_between(freqs, p_plus, p_minus, color='r', alpha=.2, linewidth=.5)\n    \n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('PSD (dB)') #only if no channel scaling\n    plt.legend()", "    \n\n# # Plot band powers for a single channel and a single subject\n# fig3, ax3 = plt.subplots()\n# sub_df =log_df.loc[log_df.index==df.index[0]]\n# sub_array = []# # Plot band powers for a single channel and a single subject\n# fig3, ax3 = plt.subplots()\n# sub_df =log_df.loc[log_df.index==df.index[0]]\n# sub_array = []\n# channel = 1 ", "# sub_array = []\n# channel = 1 \n# for i in range(n_f_bands):\n#     sub_array.append(sub_df.iloc[:, channel-1+64*i])\n# ax3.plot(channels, pd.DataFrame(sub_array))\n# plt.title('Sub-'+df.index[0]+' Channel '+str(channel))\n# channel = 1 \n# for i in range(n_f_bands):\n#     sub_array.append(sub_df.iloc[:, channel-1+64*i])\n# ax3.plot(channels, pd.DataFrame(sub_array))", "#     sub_array.append(sub_df.iloc[:, channel-1+64*i])\n# ax3.plot(channels, pd.DataFrame(sub_array))\n# plt.title('Sub-'+df.index[0]+' Channel '+str(channel))\n\n#This is to be implemented\n# # Plot band powers for a single channel and a single subject\n# fig3, ax3 = plt.subplots()\n# sub_df =log_df.loc[log_df.index==df.index[0]]\n# sub_array = []\n# channel = 1 ", "# sub_array = []\n# channel = 1 \n# for i in range(n_f_bands):\n#     sub_array.append(sub_df.iloc[:, channel-1+64*i])\n# ax3.plot(channels, pd.DataFrame(sub_array))\n# plt.title('Sub-'+df.index[0]+' Channel '+str(channel))\n\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    df = pd.read_csv('/net/tera2/home/aino/work/mtbi-eeg/python/analysis/dataframe.csv')\n\n    #parser.add_argument('--threads', type=int, help=\"Number of threads, using multiprocessing\", default=1) #skipped for now\n    parser.add_argument('--plots', type=str, help='ROI, PSD')\n    parser.add_argument('--freq_bands', type=str, help=\"wide, thin\", default='wide')\n    parser.add_argument('--task', type=str, help=\"ec, eo, PASAT_1 or PASAT_2\")\n\n    args = parser.parse_args()\n    \n    save_folder = \"/net/tera2/home/aino/work/mtbi-eeg/python/figures\"\n    \n\n\n        \n    \n    if args.plots == 'ROI':\n        subjects = df.loc[:,'Subject']\n        del df['Subject']\n        # Number of runs\n        if args.task == 'ec' or 'eo':\n            n_runs = 3\n        elif args.task == 'PASAT_1' or 'PASAT_2':\n            n_runs = 2\n        # Frequency band names\n        if args.freq_bands == 'wide':\n            n_f_bands = 6\n            bands=['delta', 'theta', 'alpha', 'beta', 'gamma', 'high gamma']\n        elif args.freq_bands == 'thin':\n            n_f_bands = 89\n            bands = [x for x in range(n_f_bands)]\n\n        groups = df.loc[:, 'Group']\n        n_channels = 64\n\n        fig, axes = plt.subplots(1,3)\n        plot_ROI_grand_averages(df, bands, n_runs, n_channels)\n        save_file = f\"{save_folder}/ROI_{args.task}_{args.freq_bands}.pdf\"\n        plt.savefig(fname=save_file)\n    #TODO: modify this so that the plots work if the frequency bands are changed\n    #TODO: check https://www.python-graph-gallery.com/123-highlight-a-line-in-line-plot for deviations. Construct a dataframe? Move plotting to new script entirely?\n    \n    if args.plots == 'PSD':\n        # Change the style of plot\n        plt.style.use('seaborn-darkgrid')\n        plt.figure()\n        plot(df, args.task, args.freq_bands)\n        save_file = f\"{save_folder}/PSD_{args.task}_{args.freq_bands}.pdf\"\n        plt.savefig(fname=save_file)", "\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    df = pd.read_csv('/net/tera2/home/aino/work/mtbi-eeg/python/analysis/dataframe.csv')\n\n    #parser.add_argument('--threads', type=int, help=\"Number of threads, using multiprocessing\", default=1) #skipped for now\n    parser.add_argument('--plots', type=str, help='ROI, PSD')\n    parser.add_argument('--freq_bands', type=str, help=\"wide, thin\", default='wide')\n    parser.add_argument('--task', type=str, help=\"ec, eo, PASAT_1 or PASAT_2\")\n\n    args = parser.parse_args()\n    \n    save_folder = \"/net/tera2/home/aino/work/mtbi-eeg/python/figures\"\n    \n\n\n        \n    \n    if args.plots == 'ROI':\n        subjects = df.loc[:,'Subject']\n        del df['Subject']\n        # Number of runs\n        if args.task == 'ec' or 'eo':\n            n_runs = 3\n        elif args.task == 'PASAT_1' or 'PASAT_2':\n            n_runs = 2\n        # Frequency band names\n        if args.freq_bands == 'wide':\n            n_f_bands = 6\n            bands=['delta', 'theta', 'alpha', 'beta', 'gamma', 'high gamma']\n        elif args.freq_bands == 'thin':\n            n_f_bands = 89\n            bands = [x for x in range(n_f_bands)]\n\n        groups = df.loc[:, 'Group']\n        n_channels = 64\n\n        fig, axes = plt.subplots(1,3)\n        plot_ROI_grand_averages(df, bands, n_runs, n_channels)\n        save_file = f\"{save_folder}/ROI_{args.task}_{args.freq_bands}.pdf\"\n        plt.savefig(fname=save_file)\n    #TODO: modify this so that the plots work if the frequency bands are changed\n    #TODO: check https://www.python-graph-gallery.com/123-highlight-a-line-in-line-plot for deviations. Construct a dataframe? Move plotting to new script entirely?\n    \n    if args.plots == 'PSD':\n        # Change the style of plot\n        plt.style.use('seaborn-darkgrid')\n        plt.figure()\n        plot(df, args.task, args.freq_bands)\n        save_file = f\"{save_folder}/PSD_{args.task}_{args.freq_bands}.pdf\"\n        plt.savefig(fname=save_file)", "\n\n\n"]}
{"filename": "src/other_files/wilcoxon.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Tue Oct 11 12:18:46 2022\n\n@author: aino\n\nPlots histograms for each frequency band. (should these be moved to plot.py??)\nPerforms the Wilcoxon signed rank test. \n\"\"\"", "Performs the Wilcoxon signed rank test. \n\"\"\"\nfrom readdata import dataframe as df\nfrom plot import global_df as gdf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import wilcoxon\n", "from scipy.stats import wilcoxon\n\n#gdf = gdf.drop(['22P_PASAT_run1_2', '22P_PASAT_run1_1']) #We want matched controls and patients, 22P's control had bad data\n#gdf = gdf.drop(['22P_ec_1', '22P_ec_2', '22P_ec_3'])\n#gdf = gdf.drop(['22P_eo_1', '22P_eo_2', '22P_eo_3'])\npatients = gdf.loc[gdf['Group']==1]\ncontrols = gdf.loc[gdf['Group']==0]\n\nplot = True\n", "plot = True\n\n\ndelta_p = patients.iloc[:, 1]\ndelta_c =controls.iloc[:, 1]\ntheta_p = patients.iloc[:, 2]\ntheta_c = controls.iloc[:, 2]\nalpha_p = patients.iloc[:, 3]\nalpha_c = controls.iloc[:, 3]\nbeta_p = patients.iloc[:, 4]", "alpha_c = controls.iloc[:, 3]\nbeta_p = patients.iloc[:, 4]\nbeta_c = controls.iloc[:, 4]\ngamma_p = patients.iloc[:, 5]\ngamma_c = controls.iloc[:, 5]\nhgamma_p = patients.iloc[:, 6]\nhgamma_c =controls.iloc[:, 6]\n\n\nif plot:\n    fig, axes = plt.subplots(2,6)\n    sns.histplot(delta_c, kde=True, color='g', ax = axes[0][0], bins=15)\n    sns.histplot(delta_p, kde=True, color='r', ax = axes[1][0], bins=15)\n    sns.histplot(theta_c, kde=True, color='g', ax = axes[0][1], bins=15)\n    sns.histplot(theta_p, kde=True, color='r', ax = axes[1][1], bins=15)\n    sns.histplot(alpha_c, kde=True, color='g', ax = axes[0][2], bins=15)\n    sns.histplot(alpha_p, kde=True, color='r', ax = axes[1][2], bins=15)\n    sns.histplot(beta_c, kde=True, color='g', ax = axes[0][3], bins=15)\n    sns.histplot(beta_p, kde=True, color='r', ax = axes[1][3], bins=15)\n    sns.histplot(gamma_c, kde=True, color='g', ax = axes[0][4], bins=15)\n    sns.histplot(gamma_p, kde=True, color='r', ax = axes[1][4], bins=15)\n    sns.histplot(hgamma_c, kde=True, color='g', ax = axes[0][5], bins=15)\n    sns.histplot(hgamma_p, kde=True, color='r', ax = axes[1][5], bins=15)\n    \n    # Set labels and titles\n    for i in range(6):\n        axes[1][i].set_ylabel('')\n        axes[0][i].set_ylabel('')\n        axes[0][i].set_xlabel('')\n        axes[1][i].set_xlabel('')\n    axes[0][0].set_xlim([-1.2,0])\n    axes[1][0].set_xlim([-1.2, 0])\n    axes[0][1].set_xlim([-1.5,-0.5])\n    axes[1][1].set_xlim([-1.5, -0.5])\n    axes[0][2].set_xlim([-1.75,-0.5])\n    axes[1][2].set_xlim([-1.75, -0.5])\n    axes[0][3].set_xlim([-1.5,-0.5])\n    axes[1][3].set_xlim([-1.5, -0.5])\n    axes[0][4].set_xlim([-2.5,-1])\n    axes[1][4].set_xlim([-2.5, -1])\n    axes[0][5].set_xlim([-1.8,-0.3])\n    axes[1][5].set_xlim([-1.8, -0.3])\n    axes[0][0].set_ylabel('Controls')\n    axes[1][0].set_ylabel('Patients')\n    axes[0][0].title.set_text('Delta')\n    axes[0][1].title.set_text('Theta')\n    axes[0][2].title.set_text('Alpha')\n    axes[0][3].title.set_text('Beta')\n    axes[0][4].title.set_text('Gamma')\n    axes[0][5].title.set_text('High gamma')\n    \n    \n    fig.suptitle('Patients vs controls')\n    fig.supxlabel('Power (dB)')\n    fig.supylabel('Count')", "\nif plot:\n    fig, axes = plt.subplots(2,6)\n    sns.histplot(delta_c, kde=True, color='g', ax = axes[0][0], bins=15)\n    sns.histplot(delta_p, kde=True, color='r', ax = axes[1][0], bins=15)\n    sns.histplot(theta_c, kde=True, color='g', ax = axes[0][1], bins=15)\n    sns.histplot(theta_p, kde=True, color='r', ax = axes[1][1], bins=15)\n    sns.histplot(alpha_c, kde=True, color='g', ax = axes[0][2], bins=15)\n    sns.histplot(alpha_p, kde=True, color='r', ax = axes[1][2], bins=15)\n    sns.histplot(beta_c, kde=True, color='g', ax = axes[0][3], bins=15)\n    sns.histplot(beta_p, kde=True, color='r', ax = axes[1][3], bins=15)\n    sns.histplot(gamma_c, kde=True, color='g', ax = axes[0][4], bins=15)\n    sns.histplot(gamma_p, kde=True, color='r', ax = axes[1][4], bins=15)\n    sns.histplot(hgamma_c, kde=True, color='g', ax = axes[0][5], bins=15)\n    sns.histplot(hgamma_p, kde=True, color='r', ax = axes[1][5], bins=15)\n    \n    # Set labels and titles\n    for i in range(6):\n        axes[1][i].set_ylabel('')\n        axes[0][i].set_ylabel('')\n        axes[0][i].set_xlabel('')\n        axes[1][i].set_xlabel('')\n    axes[0][0].set_xlim([-1.2,0])\n    axes[1][0].set_xlim([-1.2, 0])\n    axes[0][1].set_xlim([-1.5,-0.5])\n    axes[1][1].set_xlim([-1.5, -0.5])\n    axes[0][2].set_xlim([-1.75,-0.5])\n    axes[1][2].set_xlim([-1.75, -0.5])\n    axes[0][3].set_xlim([-1.5,-0.5])\n    axes[1][3].set_xlim([-1.5, -0.5])\n    axes[0][4].set_xlim([-2.5,-1])\n    axes[1][4].set_xlim([-2.5, -1])\n    axes[0][5].set_xlim([-1.8,-0.3])\n    axes[1][5].set_xlim([-1.8, -0.3])\n    axes[0][0].set_ylabel('Controls')\n    axes[1][0].set_ylabel('Patients')\n    axes[0][0].title.set_text('Delta')\n    axes[0][1].title.set_text('Theta')\n    axes[0][2].title.set_text('Alpha')\n    axes[0][3].title.set_text('Beta')\n    axes[0][4].title.set_text('Gamma')\n    axes[0][5].title.set_text('High gamma')\n    \n    \n    fig.suptitle('Patients vs controls')\n    fig.supxlabel('Power (dB)')\n    fig.supylabel('Count')", "\n\n\nres_delta = wilcoxon(x=delta_p, y=delta_c)\nres_theta = wilcoxon(x=theta_p, y=theta_c)\nres_alpha = wilcoxon(x=alpha_p, y=alpha_c)\nres_beta = wilcoxon(x=beta_p, y=beta_c)\nres_gamma = wilcoxon(x=gamma_p, y= gamma_c)\nres_hgamma = wilcoxon(x=hgamma_p, y=hgamma_c)\n", "res_hgamma = wilcoxon(x=hgamma_p, y=hgamma_c)\n\nprint(res_delta.pvalue, res_theta.pvalue, res_alpha.pvalue, res_beta.pvalue, res_gamma.pvalue, res_hgamma.pvalue)\n\n\n\n"]}
{"filename": "src/other_files/check_bandpower_files_are_created_wip.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Mar 29 12:20:55 2023\n\n@author: portae1\n\"\"\"\n\nimport os.path\nimport datetime", "import os.path\nimport datetime\n\ndef is_file_recent(file_path, time_threshold):\n    \"\"\"\n    Checks if a file exists and was modified within the specified time threshold.\n\n    Parameters:\n    file_path (str): The path to the file to check.\n    time_threshold (float): The time threshold in seconds.\n\n    Returns:\n    bool: True if the file exists and was modified within the time threshold, False otherwise.\n    \"\"\"\n    if not os.path.exists(file_path):\n        return False\n\n    time_diff = datetime.datetime.now() - datetime.datetime.fromtimestamp(os.path.getmtime(file_path))\n    \n    return time_diff.total_seconds() <= time_threshold", "\nif is_file_recent(\"path/to/file.txt\", time_threshold=1):\n    # do something with the file\n    pass\nelse:\n    # file doesn't exist or was not modified recently\n    pass\n\n", ""]}
{"filename": "src/other_files/hyperparameter.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Jul  6 15:49:07 2022\n\n@author: aino\n\"\"\"\n\nimport argparse\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold", "import argparse\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom readdata import dataframe\n", "from readdata import dataframe\n\n# Deal with command line arguments\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument('--clf', type=str, help='classifier')\nparser.add_argument('--task', type=str, help='task')\nparser.add_argument('--parameters', type=dict, help='')\nparser.add_argument()", "parser.add_argument('--parameters', type=dict, help='')\nparser.add_argument()\nparser.add_argument()\n\nargs = parser.parse_args()\n\n# Number of random trials\nNUM_TRIALS = 10\n\n# Get data", "\n# Get data\nX, y = dataframe.iloc[:,1:dataframe.shape[1]], dataframe.loc[:, 'Group']\n\n# Set up possible values of parameters to optimize over\nparam_grid = {'C':[1,10,100], 'penalty': ['l1','l2']}\n\n# Model to optimize\nestimator = LogisticRegression(solver='liblinear')\n", "estimator = LogisticRegression(solver='liblinear')\n\n# Array to store scores\nnested_scores = np.zeros(NUM_TRIALS)\n\n# Nested cross validation\nfor i in range(NUM_TRIALS):\n    # Choose cross validation methods\n    inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n    outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n    \n\n    # Nested CV with parameter optimization\n    clf = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=inner_cv)\n    nested_score = cross_val_score(estimator=estimator, X=X, y=y, cv=outer_cv)\n    nested_scores[i] = nested_score.mean()", "    "]}
{"filename": "src/other_files/annotate_bad_channels.py", "chunked_list": ["\"\"\"\nThis script is used for manually annotation bad EEG channels.\nThe idea is to run this in an ipython console through:\n\n>>> %run annotate_bad_channels.py <subject number>\n\nThe script will load the raw data and make a plot of it. Inside the plot you\ncan scroll through the data and click on the channel names to mark them as bad.\nWhen you close the plot, the script will print out the channels you have\nmarked. These channels can then be added to the big `bads` list inside", "When you close the plot, the script will print out the channels you have\nmarked. These channels can then be added to the big `bads` list inside\nconfig_eeg.py.\n\"\"\"\nimport argparse\n\nimport mne\n\nfrom config_eeg import fname, bads\nfrom config_common import tasks", "from config_eeg import fname, bads\nfrom config_common import tasks\n\n# Deal with command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nargs = parser.parse_args()\n\nraw = mne.io.read_raw_fif(fname.raw(subject=args.subject, ses='01', task=tasks[1], run=1), \n                          preload=True)", "raw = mne.io.read_raw_fif(fname.raw(subject=args.subject, ses='01', task=tasks[1], run=1), \n                          preload=True)\n#raw.info['bads'] = bads[args.subject]\nraw.pick_types(meg=False, eeg=True, eog=True, ecg=True)\nraw.filter(1, 100)\nraw.notch_filter([50, 100])\nraw.plot(scalings=dict(eog=100E-6, eeg=50E-6))\nprint(raw.info['bads'])\n", ""]}
{"filename": "src/other_files/dodo.py", "chunked_list": ["\"\"\"\nDo-it script to execute the entire pipeline using the doit tool:\nhttp://pydoit.org\n\nAll the filenames are defined in config.py\n\"\"\"\nimport sys\nsys.path.append('..')\n\nfrom config_eeg import fname, subjects, get_all_fnames", "\nfrom config_eeg import fname, subjects, get_all_fnames\n\n# Configuration for the \"doit\" tool.\nDOIT_CONFIG = dict(\n    # While running scripts, output everything the script is printing to the\n    # screen.\n    verbosity=2,\n\n    # When the user executes \"doit list\", list the tasks in the order they are", "\n    # When the user executes \"doit list\", list the tasks in the order they are\n    # defined in this file, instead of alphabetically.\n    sort='definition',\n)\n\ndef task_filt():\n    \"\"\"Step 01: Perform frequency filtering\"\"\"\n    for subject in subjects:\n        yield dict(\n            name=f'sub-{subject:02d}',\n            file_dep=get_all_fnames(subject, 'raw') + ['01_freqfilt.py'],\n            targets=get_all_fnames(subject, 'filt'),\n            actions=[f'python 01_freqfilt.py {subject}'],\n        )", "\ndef task_ica():\n    \"\"\"Step 02: Remove blink (EOG) artifacts using ICA\"\"\"\n    for subject in subjects:\n        yield dict(\n            name=f'sub-{subject:02d}',\n            file_dep=(get_all_fnames(subject, 'raw', exclude=['emptyroom', 'eyesclosed']) +\n                      get_all_fnames(subject, 'filt', exclude=['emptyroom', 'eyesclosed']) +\n                      ['02_ica.py']),\n            targets=(get_all_fnames(subject, 'ica', exclude=['emptyroom', 'eyesclosed']) +\n                     get_all_fnames(subject, 'clean', exclude=['emptyroom', 'eyesclosed'])),\n            actions=[f'python 02_ica.py {subject}'],\n        )", "\ndef task_psds():\n    \"\"\"Step 03: Compute the Power Spectral Density (PSD) for each recording.\"\"\"\n    for subject in subjects:\n        yield dict(\n            name=f'sub-{subject:02d}',\n            file_dep=[\n                fname.clean(subject=subject, task='eyesopen', run=1, ses='01'),\n                fname.clean(subject=subject, task='eyesclosed', run=1, ses='01'),\n                fname.clean(subject=subject, task='pasat', run=1, ses='01'),\n                fname.clean(subject=subject, task='pasat', run=2, ses='01'),\n                '03_psds.py',\n            ],\n            targets=[fname.psds(subject=subject, ses='01')],\n            actions=[f'python 03_psds.py {subject}'],\n        )", ""]}
{"filename": "src/other_files/ica_without_ecg_ch.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nScript for handling the ICA for subjects without ECG sensor. \nBuilds virtual ECG chennel from magnetometers.\n\nCreated on Thu Jun 30 14:12:52 2022\n\n@author: aino\n", "@author: aino\n\nRunning: \nimport subprocess\nsubprocess.run('/net/tera2/home/aino/work/mtbi-eeg/python/processing/eeg/runsome.sh', shell=True)\n\"\"\"\nimport argparse\nfrom collections import defaultdict\n\nfrom mne import Epochs", "\nfrom mne import Epochs\nfrom mne.io import read_raw_fif\nfrom mne.preprocessing import find_eog_events, find_ecg_events, ICA\nfrom mne import open_report\nimport datetime\n\nfrom config_eeg import get_all_fnames, task_from_fname, fname, ecg_channel, ec_bads, eo_bads, pasat1_bads, pasat2_bads\n\n", "\n\n# Deal with command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nargs = parser.parse_args()\n\n# For collecting figures for quality control\nfigures = defaultdict(list)\n", "figures = defaultdict(list)\n\nexclude = []\n\nall_fnames = zip(get_all_fnames(args.subject, kind='filt', exclude=exclude),\n                 get_all_fnames(args.subject, kind='ica', exclude=exclude),\n                 get_all_fnames(args.subject, kind='tsss', exclude=exclude),\n                 get_all_fnames(args.subject, kind='clean', exclude=exclude))\n\nfor filt_fname, ica_fname, raw_fname, clean_fname in all_fnames:\n    task = task_from_fname(filt_fname)\n    raw = read_raw_fif(raw_fname, preload=True)\n    \n        # Mark bad channels that were manually annotated earlier.\n    raw_str = str(raw_fname)\n    if 'task-ec' in raw_str:\n        raw.info['bads'] = ec_bads[args.subject]\n    elif 'task-eo' in raw_str:\n        raw.info['bads'] = eo_bads[args.subject]\n    elif 'task-PASAT' in raw_str and 'run-01' in raw_str:\n        raw.info['bads'] = pasat1_bads[args.subject]\n    elif 'task-PASAT' in raw_str and 'run-02' in raw_str:\n        raw.info['bads'] = pasat2_bads[args.subject]\n    \n    # Date and time\n    now = datetime.datetime.now()\n    date_time = now.strftime('%A, %d. %B %Y %I:%M%p')\n    \n    # Plot segment of raw data\n    figures['raw_segment'].append(raw.plot(n_channels=30, title = date_time, show=False))\n\n    \n    # Interpolate bad channels\n    raw.interpolate_bads()\n    figures['interpolated_segment'].append(raw.plot(n_channels=30, title = date_time, show=False))\n    \n    # Remove 50Hz power line noise (and the first harmonic: 100Hz)\n    filt = raw.notch_filter(50, picks=['eeg', 'eog', 'ecg', 'meg'])\n    \n    # Apply bandpass filter\n    filt = raw.filter(1, 90, picks=['eeg','eog','ecg','meg'])\n    \n    # Run a detection algorithm for the onsets of eye blinks (EOG) and heartbeat artefacts (ECG)\n    eog_events = find_eog_events(filt)\n    eog_epochs = Epochs(filt, eog_events, tmin=-0.5, tmax=0.5, preload=True)\n    \n    ecg_events, ch, _ = find_ecg_events(filt)\n    ecg_epochs = Epochs(filt, ecg_events, tmin = -0.5, tmax = 0.5, preload=True)\n    \n    # Perform ICA decomposition\n    ica = ICA(n_components=0.99, random_state=0).fit(filt)\n    \n    # Find components that are likely capturing EOG artifacts\n    bads_eog, scores_eog = ica.find_bads_eog(eog_epochs, threshold=2.0)\n    # Find components that are likely capturing ECG artifacts\n    bads_ecg, scores_ecg = ica.find_bads_ecg(filt, method = 'correlation', threshold='auto')\n    #TODO: ecg_epochs????\n    # Remove MEG channels \n    raw.pick_types(meg=False, eeg=True, eog=False, stim=False, ecg=False, exclude=[])\n    \n    # Mark the components for removal\n    ica.exclude = bads_eog + bads_ecg\n    ica.save(ica_fname, overwrite=True)\n    \n    # Date and time\n    now = datetime.datetime.now()\n    date_time = now.strftime('%A, %d. %B %Y %I:%M%p')\n\n    # Put a whole lot of quality control figures in the HTML report.\n    with open_report(fname.report(subject=args.subject)) as report:\n         # if len(bads_eog)>0:\n         #     report.add_ica(ica=ica, \n         #                     title=f' {task}' + ' EOG', \n         #                     inst=filt, \n         #                     picks=bads_eog,\n         #                     eog_evoked=eog_epochs.average(),\n         #                     eog_scores=scores_eog,\n         #                     tags=(f'{task}', 'EOG', 'ICA'),\n         #                     replace=True\n         #                     )\n         # if len(bads_ecg)>0:\n         #    report.add_ica(ica=ica, \n         #                    title=f' {task}' + ' ECG', \n         #                    inst=filt, \n         #                    picks=bads_ecg,\n         #                    ecg_evoked=ecg_epochs.average(),\n         #                    ecg_scores=scores_ecg,\n         #                    tags=(f'{task}', 'ECG', 'ICA'),\n         #                    replace=True\n         #                    )\n          report.add_figure(\n              ica.plot_scores(scores_eog, exclude=bads_eog, title=date_time, show=False),\n              f'{task}: EOG scores', replace=True, tags=('EOG', f'{task}', 'ICA'))\n\n          report.add_figure(\n              ica.plot_overlay(eog_epochs.average(), title=date_time, show=False),\n              f'{task}: EOG overlay', replace=True, tags=(f'{task}', 'ICA', 'EOG', 'overlay'))\n         \n\n          report.add_figure(\n              ica.plot_scores(scores_ecg, exclude=bads_ecg, title=date_time, show=False),\n              f'{task}: ECG scores', replace=True, tags=('ECG', f'{task}', 'ICA'))\n             \n          report.add_figure(\n              ica.plot_overlay(ecg_epochs.average(), title=date_time, show=False),\n              f'{task}: ECG overlay', replace=True, tags=(f'{task}', 'ICA', 'ECG', 'overlay'))\n             \n          if len(bads_ecg) == 1:\n             report.add_figure(\n                 ica.plot_properties(ecg_epochs, bads_ecg, show=False),\n                 [f'{task}: ECG Component {i:02d}' for i in bads_ecg],\n                 replace=True, tags=('ECG', f'{task}', 'ICA'))\n          elif len(bads_ecg) > 1:\n              report.add_figure(\n                ica.plot_properties(ecg_epochs, bads_ecg, show=False),\n                f'{task}: ECG component properties', \n                #captions=[f'{task}: Component {i:02d}' for i in bads_ecg],\n                replace=True, tags=('ECG', f'{task}', 'ICA'))\n                 \n                 \n          if len(bads_eog) == 1:\n              report.add_figure(\n                  ica.plot_properties(eog_epochs, bads_eog, show=False),\n                  [f'{task}: EOG Component {i:02d}' for i in bads_eog],\n                  replace=True, tags=('EOG', f'{task}', 'ICA'))\n          elif len(bads_eog) > 1:\n              report.add_figure(\n                  ica.plot_properties(eog_epochs, bads_eog, show=False),\n                  f'{task}: EOG component properties',\n                  #captions=[f'{task}: Component {i:02d}' for i in bads_eog],\n                  replace=True, tags=('EOG', f'{task}', 'ICA'))\n\n          report.save(fname.report_html(subject=args.subject),\n                    overwrite=True, open_browser=False)", "\nfor filt_fname, ica_fname, raw_fname, clean_fname in all_fnames:\n    task = task_from_fname(filt_fname)\n    raw = read_raw_fif(raw_fname, preload=True)\n    \n        # Mark bad channels that were manually annotated earlier.\n    raw_str = str(raw_fname)\n    if 'task-ec' in raw_str:\n        raw.info['bads'] = ec_bads[args.subject]\n    elif 'task-eo' in raw_str:\n        raw.info['bads'] = eo_bads[args.subject]\n    elif 'task-PASAT' in raw_str and 'run-01' in raw_str:\n        raw.info['bads'] = pasat1_bads[args.subject]\n    elif 'task-PASAT' in raw_str and 'run-02' in raw_str:\n        raw.info['bads'] = pasat2_bads[args.subject]\n    \n    # Date and time\n    now = datetime.datetime.now()\n    date_time = now.strftime('%A, %d. %B %Y %I:%M%p')\n    \n    # Plot segment of raw data\n    figures['raw_segment'].append(raw.plot(n_channels=30, title = date_time, show=False))\n\n    \n    # Interpolate bad channels\n    raw.interpolate_bads()\n    figures['interpolated_segment'].append(raw.plot(n_channels=30, title = date_time, show=False))\n    \n    # Remove 50Hz power line noise (and the first harmonic: 100Hz)\n    filt = raw.notch_filter(50, picks=['eeg', 'eog', 'ecg', 'meg'])\n    \n    # Apply bandpass filter\n    filt = raw.filter(1, 90, picks=['eeg','eog','ecg','meg'])\n    \n    # Run a detection algorithm for the onsets of eye blinks (EOG) and heartbeat artefacts (ECG)\n    eog_events = find_eog_events(filt)\n    eog_epochs = Epochs(filt, eog_events, tmin=-0.5, tmax=0.5, preload=True)\n    \n    ecg_events, ch, _ = find_ecg_events(filt)\n    ecg_epochs = Epochs(filt, ecg_events, tmin = -0.5, tmax = 0.5, preload=True)\n    \n    # Perform ICA decomposition\n    ica = ICA(n_components=0.99, random_state=0).fit(filt)\n    \n    # Find components that are likely capturing EOG artifacts\n    bads_eog, scores_eog = ica.find_bads_eog(eog_epochs, threshold=2.0)\n    # Find components that are likely capturing ECG artifacts\n    bads_ecg, scores_ecg = ica.find_bads_ecg(filt, method = 'correlation', threshold='auto')\n    #TODO: ecg_epochs????\n    # Remove MEG channels \n    raw.pick_types(meg=False, eeg=True, eog=False, stim=False, ecg=False, exclude=[])\n    \n    # Mark the components for removal\n    ica.exclude = bads_eog + bads_ecg\n    ica.save(ica_fname, overwrite=True)\n    \n    # Date and time\n    now = datetime.datetime.now()\n    date_time = now.strftime('%A, %d. %B %Y %I:%M%p')\n\n    # Put a whole lot of quality control figures in the HTML report.\n    with open_report(fname.report(subject=args.subject)) as report:\n         # if len(bads_eog)>0:\n         #     report.add_ica(ica=ica, \n         #                     title=f' {task}' + ' EOG', \n         #                     inst=filt, \n         #                     picks=bads_eog,\n         #                     eog_evoked=eog_epochs.average(),\n         #                     eog_scores=scores_eog,\n         #                     tags=(f'{task}', 'EOG', 'ICA'),\n         #                     replace=True\n         #                     )\n         # if len(bads_ecg)>0:\n         #    report.add_ica(ica=ica, \n         #                    title=f' {task}' + ' ECG', \n         #                    inst=filt, \n         #                    picks=bads_ecg,\n         #                    ecg_evoked=ecg_epochs.average(),\n         #                    ecg_scores=scores_ecg,\n         #                    tags=(f'{task}', 'ECG', 'ICA'),\n         #                    replace=True\n         #                    )\n          report.add_figure(\n              ica.plot_scores(scores_eog, exclude=bads_eog, title=date_time, show=False),\n              f'{task}: EOG scores', replace=True, tags=('EOG', f'{task}', 'ICA'))\n\n          report.add_figure(\n              ica.plot_overlay(eog_epochs.average(), title=date_time, show=False),\n              f'{task}: EOG overlay', replace=True, tags=(f'{task}', 'ICA', 'EOG', 'overlay'))\n         \n\n          report.add_figure(\n              ica.plot_scores(scores_ecg, exclude=bads_ecg, title=date_time, show=False),\n              f'{task}: ECG scores', replace=True, tags=('ECG', f'{task}', 'ICA'))\n             \n          report.add_figure(\n              ica.plot_overlay(ecg_epochs.average(), title=date_time, show=False),\n              f'{task}: ECG overlay', replace=True, tags=(f'{task}', 'ICA', 'ECG', 'overlay'))\n             \n          if len(bads_ecg) == 1:\n             report.add_figure(\n                 ica.plot_properties(ecg_epochs, bads_ecg, show=False),\n                 [f'{task}: ECG Component {i:02d}' for i in bads_ecg],\n                 replace=True, tags=('ECG', f'{task}', 'ICA'))\n          elif len(bads_ecg) > 1:\n              report.add_figure(\n                ica.plot_properties(ecg_epochs, bads_ecg, show=False),\n                f'{task}: ECG component properties', \n                #captions=[f'{task}: Component {i:02d}' for i in bads_ecg],\n                replace=True, tags=('ECG', f'{task}', 'ICA'))\n                 \n                 \n          if len(bads_eog) == 1:\n              report.add_figure(\n                  ica.plot_properties(eog_epochs, bads_eog, show=False),\n                  [f'{task}: EOG Component {i:02d}' for i in bads_eog],\n                  replace=True, tags=('EOG', f'{task}', 'ICA'))\n          elif len(bads_eog) > 1:\n              report.add_figure(\n                  ica.plot_properties(eog_epochs, bads_eog, show=False),\n                  f'{task}: EOG component properties',\n                  #captions=[f'{task}: Component {i:02d}' for i in bads_eog],\n                  replace=True, tags=('EOG', f'{task}', 'ICA'))\n\n          report.save(fname.report_html(subject=args.subject),\n                    overwrite=True, open_browser=False)", "    \n    \n    \n    \n    \n    \n"]}
{"filename": "src/other_files/runscript.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Mon Jan 16 13:37:19 2023\n\n@author: aino\n\nRuns scripts readdata.py, ROC_AUC.py and plot.py with chosen arguments.\n\"\"\"\n", "\"\"\"\n\nimport subprocess\n\nif __name__ == \"__main__\":\n    # Choose task ('ec', 'eo', 'PASAT_1', 'PASAT_2')\n    task = 'PASAT_2'\n    # Choose frequency bands ('wide', 'thin')\n    bands = 'thin'\n    # Choose classifier ('LR', 'LDA', 'SVM')\n    clf = 'LR'\n    # Choose what to plot ('PSD', 'ROI')\n    plots = 'PSD'\n    \n    roc = False\n    plot = True\n\n    #TODO: what else should be possible to choose? All subjects vs matched subjects?\n    \n    # Run readdata.py\n    subprocess.call(f\"python readdata.py --task {task} --freq_bands {bands}\", shell=True)\n    if roc:\n        # Run ROC_AUC.py\n        subprocess.call(f\"python ROC_AUC.py --task {task} --clf {clf}\", shell=True)\n    \n    if plot:\n        subprocess.call(f\"python plot.py --task {task} --freq_bands {bands} --plots {plots}\", shell=True)", "        \n"]}
{"filename": "src/other_files/00_maxfilter.py", "chunked_list": ["#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Jun 15 11:48:59 2022\n\n@author: heikkiv\n\nScript that applies maxfiltering on the bidsified data.\nDoes all tasks in a row. Based on the script by Mia Liljestr\u00f6m.\n", "Does all tasks in a row. Based on the script by Mia Liljestr\u00f6m.\n\nNOTE: needs to be ran on Maxfilter computer, either manually or via SSH connection (ssh -X ypsilon).\n\"\"\"\n\nimport subprocess\nimport argparse\nimport os\nfrom config_eeg import get_all_fnames, fname, tasks\n", "from config_eeg import get_all_fnames, fname, tasks\n\n#TODO: maxfilter each task, save to bidsified. IN PROGRESS\n#mne.set_log_level('INFO')\n\ncross_talk = '/net/tera2/opt/neuromag/databases/ctc/ct_sparse.fif' #cross-talk correction data file\ncalibration = '/net/tera2/opt/neuromag/databases/sss/sss_cal.dat' #calibration datafile\n\n#Handle command line arguments\nparser = argparse.ArgumentParser(description=__doc__)", "#Handle command line arguments\nparser = argparse.ArgumentParser(description=__doc__)\nparser.add_argument('subject', help='The subject to process')\nargs = parser.parse_args()\n\nsubject = args.subject\n\n\nall_fnames = zip(\n    get_all_fnames(args.subject, kind='raw'), #raw data", "all_fnames = zip(\n    get_all_fnames(args.subject, kind='raw'), #raw data\n    get_all_fnames(args.subject, kind='tsss'), #maxfiltered data\n    get_all_fnames(args.subject, kind='tsss_log'), #log files\n    get_all_fnames(args.subject, kind='pos') #position file\n)\n\n\n#TODO: another solution is to use MNE version; would that be better??\nprint(\"Maxfiltering subject \", args.subject)", "#TODO: another solution is to use MNE version; would that be better??\nprint(\"Maxfiltering subject \", args.subject)\n\nfor input_f, output_f, log_f, pos_f in all_fnames:\n    \n    #trans_f = fname.raw(subject=subject, task=tasks[0], run=1)\n    trans_f = 'default'\n    \n    #arguments given to maxfilter program. TODO: check these!\n    args = ['/neuro/bin/util/maxfilter', '-f', input_f, '-o', output_f, '-st', '-movecomp', \\\n            '-autobad','on', '-trans', trans_f, '-ctc', cross_talk, '-cal', calibration, \\\n            '-hpicons','-origin','fit','-in', '8', '-out', '3', '-frame','head', '-hp', pos_f, '-force', '-v']  \n    \n    \n    #save the error log\n    log_output = open(log_f, \"w\")\n    \n    # run maxfilter, FIXME\n    subprocess.run(args=args, stdout=log_output,stderr=log_output)", "\n\n"]}
