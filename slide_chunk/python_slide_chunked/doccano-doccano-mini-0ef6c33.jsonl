{"filename": "tests/test_prompts.py", "chunked_list": ["from doccano_mini.prompts import make_classification_prompt, make_task_free_prompt\n\n\ndef test_make_classification_prompt():\n    examples = [\n        {\"text\": \"That would be awesome!\", \"label\": \"positive\"},\n        {\"text\": \"This is awful!\", \"label\": \"negative\"},\n    ]\n\n    expected = \"\"\"\\\nClassify the text into one of the following labels:\n- negative\n- positive\n\n\ntext: That would be awesome!\nlabel: positive\n\ntext: This is awful!\nlabel: negative\n\ntext: It's very hot.\"\"\"\n\n    input_text = \"It's very hot.\"\n\n    prompt = make_classification_prompt(examples)\n\n    assert prompt.format(input=input_text) == expected", "\n\ndef test_make_task_free_prompt():\n    examples = [\n        {\"English\": \"I like sushi.\", \"Japanese\": \"\u5bff\u53f8\u304c\u597d\u304d\u3067\u3059\u3002\"},\n        {\"English\": \"I live in Japan.\", \"Japanese\": \"\u65e5\u672c\u306b\u4f4f\u3093\u3067\u3044\u307e\u3059\u3002\"},\n    ]\n\n    expected = \"\"\"\\\nPredict Japanese based on English.\n\nEnglish: I like sushi.\nJapanese: \u5bff\u53f8\u304c\u597d\u304d\u3067\u3059\u3002\n\nEnglish: I live in Japan.\nJapanese: \u65e5\u672c\u306b\u4f4f\u3093\u3067\u3044\u307e\u3059\u3002\n\nEnglish: I'm developing doccano-mini.\"\"\"\n\n    english_text = \"I'm developing doccano-mini.\"\n\n    prompt = make_task_free_prompt(examples)\n\n    assert prompt.format(English=english_text) == expected", ""]}
{"filename": "doccano_mini/components.py", "chunked_list": ["import os\nfrom pathlib import Path\nfrom typing import Optional\n\nimport streamlit as st\nfrom langchain.llms import OpenAI\nfrom langchain.prompts.few_shot import FewShotPromptTemplate\nfrom langchain.schema import BaseLanguageModel\n\n\ndef display_download_button():\n    st.header(\"Download a config file\")\n    with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as f:\n        st.download_button(\n            label=\"Download\",\n            data=f,\n            file_name=\"config.yaml\",\n        )", "\n\ndef display_download_button():\n    st.header(\"Download a config file\")\n    with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as f:\n        st.download_button(\n            label=\"Download\",\n            data=f,\n            file_name=\"config.yaml\",\n        )", "\n\ndef usage():\n    st.header(\"Usage\")\n    filepath = Path(__file__).parent.resolve() / \"docs\" / \"usage.md\"\n    with filepath.open(\"r\", encoding=\"utf-8\") as f:\n        st.markdown(f.read())\n\n\ndef task_instruction_editor(prompt: FewShotPromptTemplate) -> FewShotPromptTemplate:\n    st.header(\"Edit instruction\")\n    with st.expander(\"See instruction\"):\n        prompt.prefix = st.text_area(label=\"Enter task instruction\", value=prompt.prefix, height=200)\n    return prompt", "\ndef task_instruction_editor(prompt: FewShotPromptTemplate) -> FewShotPromptTemplate:\n    st.header(\"Edit instruction\")\n    with st.expander(\"See instruction\"):\n        prompt.prefix = st.text_area(label=\"Enter task instruction\", value=prompt.prefix, height=200)\n    return prompt\n\n\ndef openai_model_form() -> Optional[BaseLanguageModel]:\n    # https://platform.openai.com/docs/models/gpt-3-5\n    AVAILABLE_MODELS = (\n        \"gpt-3.5-turbo\",\n        \"gpt-3.5-turbo-0301\",\n        \"text-davinci-003\",\n        \"text-davinci-002\",\n        \"code-davinci-002\",\n    )\n    api_key = st.text_input(\"API key\", value=os.environ.get(\"OPENAI_API_KEY\", \"\"), type=\"password\")\n    model_name = st.selectbox(\"Model\", AVAILABLE_MODELS, index=2)\n    temperature = st.slider(\"Temperature\", min_value=0.0, max_value=1.0, value=0.7, step=0.01)\n    top_p = st.slider(\"Top-p\", min_value=0.0, max_value=1.0, value=1.0, step=0.01)\n    if not api_key:\n        return None\n    return OpenAI(model_name=model_name, temperature=temperature, top_p=top_p, openai_api_key=api_key)  # type:ignore", "def openai_model_form() -> Optional[BaseLanguageModel]:\n    # https://platform.openai.com/docs/models/gpt-3-5\n    AVAILABLE_MODELS = (\n        \"gpt-3.5-turbo\",\n        \"gpt-3.5-turbo-0301\",\n        \"text-davinci-003\",\n        \"text-davinci-002\",\n        \"code-davinci-002\",\n    )\n    api_key = st.text_input(\"API key\", value=os.environ.get(\"OPENAI_API_KEY\", \"\"), type=\"password\")\n    model_name = st.selectbox(\"Model\", AVAILABLE_MODELS, index=2)\n    temperature = st.slider(\"Temperature\", min_value=0.0, max_value=1.0, value=0.7, step=0.01)\n    top_p = st.slider(\"Top-p\", min_value=0.0, max_value=1.0, value=1.0, step=0.01)\n    if not api_key:\n        return None\n    return OpenAI(model_name=model_name, temperature=temperature, top_p=top_p, openai_api_key=api_key)  # type:ignore", ""]}
{"filename": "doccano_mini/home.py", "chunked_list": ["from pathlib import Path\n\nimport streamlit as st\n\n\ndef main():\n    st.set_page_config(page_title=\"doccano-mini\", page_icon=\":memo:\")\n    filepath = Path(__file__).parent.resolve() / \"docs\" / \"README.md\"\n\n    # Development\n    if not filepath.exists():\n        filepath = Path(__file__).parent.parent.resolve() / \"README.md\"\n\n    with filepath.open(\"r\", encoding=\"utf-8\") as f:\n        st.markdown(f.read(), unsafe_allow_html=True)", "\n\nif __name__ == \"__main__\":\n    main()\n"]}
{"filename": "doccano_mini/__init__.py", "chunked_list": [""]}
{"filename": "doccano_mini/utils.py", "chunked_list": ["import re\n\n\ndef escape_markdown(text: str) -> str:\n    # Brought from https://github.com/python-telegram-bot/python-telegram-bot/blob/v20.2/telegram/helpers.py#L66\n    escape_chars = r\"\\_*[]()~`>#+-=|{}.!$\"\n    return re.sub(f\"([{re.escape(escape_chars)}])\", r\"\\\\\\1\", text)\n"]}
{"filename": "doccano_mini/prompts.py", "chunked_list": ["import json\nfrom typing import List\n\nfrom langchain.prompts.few_shot import FewShotPromptTemplate\nfrom langchain.prompts.prompt import PromptTemplate\n\n\ndef make_classification_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n    unique_labels = set([example[\"label\"] for example in examples])\n\n    task_instruction = \"Classify the text into one of the following labels:\\n\"\n    # Sorting to make label order deterministic\n    for label in sorted(unique_labels):\n        task_instruction += f\"- {label}\\n\"\n\n    example_prompt = PromptTemplate(input_variables=[\"text\", \"label\"], template=\"text: {text}\\nlabel: {label}\")\n    prompt = FewShotPromptTemplate(\n        examples=examples,\n        example_prompt=example_prompt,\n        prefix=task_instruction,\n        suffix=\"text: {input}\",\n        input_variables=[\"input\"],\n    )\n    return prompt", "\n\ndef make_question_answering_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n    task_instruction = (\n        \"You are a highly intelligent question answering bot. \"\n        \"You take context and question as input and return the answer from the context. \"\n        \"Retain as much information as needed to answer the question at a later time. \"\n        \"If you don't know the answer, you should return N/A.\"\n    )\n\n    example_prompt = PromptTemplate(\n        input_variables=[\"context\", \"question\", \"answer\"],\n        template=\"context: {context}\\nquestion: {question}\\nanswer: {answer}\",\n    )\n    prompt = FewShotPromptTemplate(\n        examples=examples,\n        example_prompt=example_prompt,\n        prefix=task_instruction,\n        suffix=\"context: {context}\\nquestion: {question}\",\n        input_variables=[\"context\", \"question\"],\n    )\n    return prompt", "\n\ndef make_summarization_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n    task_instruction = (\n        \"You are a highly intelligent Summarization system. \"\n        \"You take Passage as input and summarize the passage as an expert.\"\n    )\n    example_prompt = PromptTemplate(\n        input_variables=[\"passage\", \"summary\"], template=\"passage: {passage}\\nsummary: {summary}\"\n    )\n    prompt = FewShotPromptTemplate(\n        examples=examples,\n        example_prompt=example_prompt,\n        prefix=task_instruction,\n        suffix=\"passage: {passage}\",\n        input_variables=[\"passage\"],\n    )\n    return prompt", "\n\ndef make_paraphrase_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n    task_instruction = (\n        \"You are a highly intelligent paraphrasing system. You take text as input and paraphrase it as an expert.\"\n    )\n    example_prompt = PromptTemplate(\n        input_variables=[\"text\", \"paraphrase\"], template=\"text: {text}\\nparaphrase: {paraphrase}\"\n    )\n    prompt = FewShotPromptTemplate(\n        examples=examples,\n        example_prompt=example_prompt,\n        prefix=task_instruction,\n        suffix=\"text: {text}\",\n        input_variables=[\"text\"],\n    )\n    return prompt", "\n\ndef make_task_free_prompt(examples: List[dict]) -> FewShotPromptTemplate:\n    columns = list(examples[0])\n\n    task_instruction = f\"Predict {columns[-1]} based on {', '.join(columns[:-1])}.\"\n    example_prompt = PromptTemplate(\n        input_variables=columns, template=\"\\n\".join([f\"{column}: {{{column}}}\" for column in columns])\n    )\n\n    prompt = FewShotPromptTemplate(\n        examples=examples,\n        example_prompt=example_prompt,\n        prefix=task_instruction,\n        suffix=\"\\n\".join([f\"{column}: {{{column}}}\" for column in columns[:-1]]),\n        input_variables=columns[:-1],\n    )\n    return prompt", "\n\ndef make_named_entity_recognition_prompt(examples: List[dict], **kwargs) -> FewShotPromptTemplate:\n    task_instruction = (\n        \"You are a highly intelligent and accurate Named-entity recognition(NER) system. \"\n        \"You take Passage as input and your task is to recognize and extract specific types of \"\n        \"named entities in that given passage and classify into a set of entity types.\\n\"\n    )\n    types = kwargs.get(\"types\", [])\n    task_instruction += \"The following entity types are allowed:\\n\"\n    for type in types:\n        task_instruction += f\"- {type}\\n\"\n\n    for example in examples:\n        entities = [\n            {\"mention\": example[\"text\"][entity[\"start\"] : entity[\"end\"]], \"type\": entity[\"label\"]}\n            for entity in example[\"entities\"]\n        ]\n        example[\"entities\"] = json.dumps(entities)\n\n    example_prompt = PromptTemplate(\n        input_variables=[\"text\", \"entities\"],\n        template=\"text: {text}\\nentities: {entities}\",\n    )\n    prompt = FewShotPromptTemplate(\n        examples=examples,\n        example_prompt=example_prompt,\n        prefix=task_instruction,\n        suffix=\"text: {{text}}\",\n        input_variables=[\"text\"],\n        template_format=\"jinja2\",\n    )\n    return prompt", ""]}
{"filename": "doccano_mini/layout.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport pandas as pd\nimport streamlit as st\nfrom langchain.chains import LLMChain\nfrom langchain.prompts.few_shot import FewShotPromptTemplate\n\nfrom doccano_mini.components import (", "\nfrom doccano_mini.components import (\n    display_download_button,\n    openai_model_form,\n    task_instruction_editor,\n    usage,\n)\nfrom doccano_mini.utils import escape_markdown\n\n\nclass BasePage(ABC):\n    example_path: str = \"\"\n\n    def __init__(self, title: str) -> None:\n        self.title = title\n\n    @property\n    def columns(self) -> List[str]:\n        return []\n\n    def load_examples(self, filename: str) -> pd.DataFrame:\n        filepath = Path(__file__).parent.resolve().joinpath(\"examples\", filename)\n        return pd.read_json(filepath)\n\n    def make_examples(self, columns: List[str]) -> List[Dict]:\n        df = self.load_examples(self.example_path)\n        edited_df = st.experimental_data_editor(df, num_rows=\"dynamic\", width=1000)\n        examples = edited_df.to_dict(orient=\"records\")\n        return examples\n\n    @abstractmethod\n    def make_prompt(self, examples: List[Dict]) -> FewShotPromptTemplate:\n        raise NotImplementedError()\n\n    @abstractmethod\n    def prepare_inputs(self, columns: List[str]) -> Dict:\n        raise NotImplementedError()\n\n    def annotate(self, examples: List[Dict]) -> List[Dict]:\n        return examples\n\n    def render(self) -> None:\n        st.title(self.title)\n        st.header(\"Annotate your data\")\n        columns = self.columns\n        examples = self.make_examples(columns)\n        examples = self.annotate(examples)\n\n        prompt = self.make_prompt(examples)\n        prompt = task_instruction_editor(prompt)\n\n        st.header(\"Test\")\n        col1, col2 = st.columns([3, 1])\n\n        with col1:\n            inputs = self.prepare_inputs(columns)\n\n        with col2:\n            llm = openai_model_form()\n\n        with st.expander(\"See your prompt\"):\n            st.markdown(f\"```\\n{prompt.format(**inputs)}\\n```\")\n\n        if llm is None:\n            st.error(\"Enter your API key.\")\n\n        if st.button(\"Predict\", disabled=llm is None):\n            chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n            response = chain.run(**inputs)\n            st.markdown(escape_markdown(response).replace(\"\\n\", \"  \\n\"))\n\n            chain.save(\"config.yaml\")\n            display_download_button()\n        usage()", "\n\nclass BasePage(ABC):\n    example_path: str = \"\"\n\n    def __init__(self, title: str) -> None:\n        self.title = title\n\n    @property\n    def columns(self) -> List[str]:\n        return []\n\n    def load_examples(self, filename: str) -> pd.DataFrame:\n        filepath = Path(__file__).parent.resolve().joinpath(\"examples\", filename)\n        return pd.read_json(filepath)\n\n    def make_examples(self, columns: List[str]) -> List[Dict]:\n        df = self.load_examples(self.example_path)\n        edited_df = st.experimental_data_editor(df, num_rows=\"dynamic\", width=1000)\n        examples = edited_df.to_dict(orient=\"records\")\n        return examples\n\n    @abstractmethod\n    def make_prompt(self, examples: List[Dict]) -> FewShotPromptTemplate:\n        raise NotImplementedError()\n\n    @abstractmethod\n    def prepare_inputs(self, columns: List[str]) -> Dict:\n        raise NotImplementedError()\n\n    def annotate(self, examples: List[Dict]) -> List[Dict]:\n        return examples\n\n    def render(self) -> None:\n        st.title(self.title)\n        st.header(\"Annotate your data\")\n        columns = self.columns\n        examples = self.make_examples(columns)\n        examples = self.annotate(examples)\n\n        prompt = self.make_prompt(examples)\n        prompt = task_instruction_editor(prompt)\n\n        st.header(\"Test\")\n        col1, col2 = st.columns([3, 1])\n\n        with col1:\n            inputs = self.prepare_inputs(columns)\n\n        with col2:\n            llm = openai_model_form()\n\n        with st.expander(\"See your prompt\"):\n            st.markdown(f\"```\\n{prompt.format(**inputs)}\\n```\")\n\n        if llm is None:\n            st.error(\"Enter your API key.\")\n\n        if st.button(\"Predict\", disabled=llm is None):\n            chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n            response = chain.run(**inputs)\n            st.markdown(escape_markdown(response).replace(\"\\n\", \"  \\n\"))\n\n            chain.save(\"config.yaml\")\n            display_download_button()\n        usage()", ""]}
{"filename": "doccano_mini/cli.py", "chunked_list": ["import sys\nfrom pathlib import Path\n\nimport streamlit.web.cli as stcli\n\n\ndef main():\n    filepath = str(Path(__file__).parent.resolve() / \"home.py\")\n    sys.argv = [\"streamlit\", \"run\", filepath, \"--global.developmentMode=false\"]\n    sys.exit(stcli.main())", "\n\nif __name__ == \"__main__\":\n    main()\n"]}
{"filename": "doccano_mini/pages/04_Paraphrase.py", "chunked_list": ["from typing import Dict, List\n\nimport streamlit as st\n\nfrom doccano_mini.layout import BasePage\nfrom doccano_mini.prompts import make_paraphrase_prompt\n\n\nclass ParaphrasePage(BasePage):\n    example_path = \"paraphrase.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_paraphrase_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\n            \"text\": st.text_area(label=\"Text.\", value=\"\", height=300),\n        }", "class ParaphrasePage(BasePage):\n    example_path = \"paraphrase.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_paraphrase_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\n            \"text\": st.text_area(label=\"Text.\", value=\"\", height=300),\n        }", "\n\npage = ParaphrasePage(title=\"Paraphrase\")\npage.render()\n"]}
{"filename": "doccano_mini/pages/02_Question_Answering.py", "chunked_list": ["from typing import Dict, List\n\nimport streamlit as st\n\nfrom doccano_mini.layout import BasePage\nfrom doccano_mini.prompts import make_question_answering_prompt\n\n\nclass QuestionAnsweringPage(BasePage):\n    example_path = \"question_answering.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_question_answering_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\n            \"context\": st.text_area(label=\"Context.\", value=\"\", height=300),\n            \"question\": st.text_input(label=\"Question.\", value=\"\"),\n        }", "class QuestionAnsweringPage(BasePage):\n    example_path = \"question_answering.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_question_answering_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\n            \"context\": st.text_area(label=\"Context.\", value=\"\", height=300),\n            \"question\": st.text_input(label=\"Question.\", value=\"\"),\n        }", "\n\npage = QuestionAnsweringPage(title=\"Question Answering\")\npage.render()\n"]}
{"filename": "doccano_mini/pages/01_Text_Classification.py", "chunked_list": ["from typing import Dict, List\n\nimport streamlit as st\n\nfrom doccano_mini.layout import BasePage\nfrom doccano_mini.prompts import make_classification_prompt\n\n\nclass TextClassificationPage(BasePage):\n    example_path = \"text_classification.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_classification_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\"input\": st.text_area(label=\"Please enter your text.\", value=\"\", height=300)}", "class TextClassificationPage(BasePage):\n    example_path = \"text_classification.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_classification_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\"input\": st.text_area(label=\"Please enter your text.\", value=\"\", height=300)}\n\n", "\n\npage = TextClassificationPage(title=\"Text Classification\")\npage.render()\n"]}
{"filename": "doccano_mini/pages/09_Task_Free.py", "chunked_list": ["from typing import Dict, List\n\nimport streamlit as st\n\nfrom doccano_mini.layout import BasePage\nfrom doccano_mini.prompts import make_task_free_prompt\n\n\nclass TaskFreePage(BasePage):\n    @property\n    def columns(self) -> List[str]:\n        num_cols = st.number_input(\"Set the number of columns\", min_value=2, max_value=10)\n        columns = [st.text_input(f\"Column {i + 1}:\", value=f\"column {i + 1}\") for i in range(int(num_cols))]\n        return columns\n\n    def make_examples(self, columns: List[str]):\n        df = self.load_examples(\"task_free.json\")\n        df = df.reindex(columns, axis=\"columns\", fill_value=\"\")\n        edited_df = st.experimental_data_editor(df, num_rows=\"dynamic\", width=1000)\n        examples = edited_df.to_dict(orient=\"records\")\n        return examples\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_task_free_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {column: st.text_area(label=f\"Input for {column}:\", value=\"\", height=300) for column in columns[:-1]}", "class TaskFreePage(BasePage):\n    @property\n    def columns(self) -> List[str]:\n        num_cols = st.number_input(\"Set the number of columns\", min_value=2, max_value=10)\n        columns = [st.text_input(f\"Column {i + 1}:\", value=f\"column {i + 1}\") for i in range(int(num_cols))]\n        return columns\n\n    def make_examples(self, columns: List[str]):\n        df = self.load_examples(\"task_free.json\")\n        df = df.reindex(columns, axis=\"columns\", fill_value=\"\")\n        edited_df = st.experimental_data_editor(df, num_rows=\"dynamic\", width=1000)\n        examples = edited_df.to_dict(orient=\"records\")\n        return examples\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_task_free_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {column: st.text_area(label=f\"Input for {column}:\", value=\"\", height=300) for column in columns[:-1]}", "\n\npage = TaskFreePage(title=\"Task Free\")\npage.render()\n"]}
{"filename": "doccano_mini/pages/06_(Beta)_Evaluation.py", "chunked_list": ["from collections import defaultdict\n\nimport pandas as pd\nimport streamlit as st\nfrom datasets import load_dataset\nfrom langchain.chains import LLMChain\nfrom more_itertools import interleave_longest\nfrom sklearn.metrics import classification_report\n\nfrom doccano_mini.components import openai_model_form, task_instruction_editor", "\nfrom doccano_mini.components import openai_model_form, task_instruction_editor\nfrom doccano_mini.prompts import make_classification_prompt\nfrom doccano_mini.utils import escape_markdown\n\nAVAILABLE_DATASETS = (\"imdb\", \"ag_news\", \"rotten_tomatoes\")\n\n\n@st.cache_resource\ndef prepare_dataset(dataset_id):\n    # Loading dataset\n    dataset = load_dataset(dataset_id, split=\"train\")\n    # Splitting dataset\n    dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", shuffle=True)\n\n    # Preparing indices\n    indices_by_label = defaultdict(list)\n    for i, x in enumerate(dataset[\"train\"]):\n        indices_by_label[x[\"label\"]].append(i)\n\n    return dataset, list(interleave_longest(*indices_by_label.values()))", "@st.cache_resource\ndef prepare_dataset(dataset_id):\n    # Loading dataset\n    dataset = load_dataset(dataset_id, split=\"train\")\n    # Splitting dataset\n    dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", shuffle=True)\n\n    # Preparing indices\n    indices_by_label = defaultdict(list)\n    for i, x in enumerate(dataset[\"train\"]):\n        indices_by_label[x[\"label\"]].append(i)\n\n    return dataset, list(interleave_longest(*indices_by_label.values()))", "\n\nst.title(\"Text Classification Evaluation on \ud83e\udd17 datasets\")\n\nst.header(\"Setup your data\")\n\ndataset_id = st.selectbox(\"Select a dataset\", options=AVAILABLE_DATASETS)\n\ndataset, train_indices = prepare_dataset(dataset_id)\n", "dataset, train_indices = prepare_dataset(dataset_id)\n\ntrain_dataset = dataset[\"train\"]\nvalidation_dataset = dataset[\"test\"]\n\nlabel_info = train_dataset.features[\"label\"]\nnum_classes = label_info.num_classes\nfew_shot_example_size = int(\n    st.number_input(\"Number of examples\", min_value=num_classes, max_value=num_classes * 5, value=num_classes)\n)", "    st.number_input(\"Number of examples\", min_value=num_classes, max_value=num_classes * 5, value=num_classes)\n)\n\nsubset = []\nfor i in range(few_shot_example_size):\n    example = train_dataset[train_indices[i]]\n    subset.append({\"text\": example[\"text\"], \"label\": label_info.int2str(example[\"label\"])})\n\n\ndf = pd.DataFrame(subset)", "\ndf = pd.DataFrame(subset)\n\nst.write(df)\n\nprompt = make_classification_prompt(df.to_dict(\"records\"))\nprompt = task_instruction_editor(prompt)\n\n\nst.header(\"Test\")", "\nst.header(\"Test\")\ncol1, col2 = st.columns([3, 1])\n\nwith col1:\n    inputs = {\"input\": st.text_area(label=\"Please enter your text.\", value=\"\", height=300)}\n\nwith col2:\n    llm = openai_model_form()\n\nwith st.expander(\"See your prompt\"):\n    st.markdown(f\"```\\n{prompt.format(**inputs)}\\n```\")", "\nwith st.expander(\"See your prompt\"):\n    st.markdown(f\"```\\n{prompt.format(**inputs)}\\n```\")\n\nif llm is None:\n    st.error(\"Enter your API key.\")\n\nif st.button(\"Predict\", disabled=llm is None):\n    chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n    response = chain.run(**inputs)\n    st.markdown(escape_markdown(response).replace(\"\\n\", \"  \\n\"))", "\nst.subheader(\"Evaluation\")\n\nevaluation_size = int(st.number_input(\"Number of examples\", min_value=5, max_value=validation_dataset.dataset_size))\n\nif llm is None:\n    st.error(\"Enter your API key.\")\n\nif st.button(\"Evaluate\", disabled=llm is None):\n    chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n    y_true = []\n    y_pred = []\n    for i in range(evaluation_size):\n        example = validation_dataset[i]\n        response = chain.run(input=example[\"text\"])\n        y_true.append(label_info.int2str(example[\"label\"]))\n        y_pred.append(response.split(\":\")[-1].strip())\n\n    st.text(classification_report(y_true, y_pred, digits=3))", "if st.button(\"Evaluate\", disabled=llm is None):\n    chain = LLMChain(llm=llm, prompt=prompt)  # type:ignore\n    y_true = []\n    y_pred = []\n    for i in range(evaluation_size):\n        example = validation_dataset[i]\n        response = chain.run(input=example[\"text\"])\n        y_true.append(label_info.int2str(example[\"label\"]))\n        y_pred.append(response.split(\":\")[-1].strip())\n\n    st.text(classification_report(y_true, y_pred, digits=3))", ""]}
{"filename": "doccano_mini/pages/03_Summarization.py", "chunked_list": ["from typing import Dict, List\n\nimport streamlit as st\n\nfrom doccano_mini.layout import BasePage\nfrom doccano_mini.prompts import make_summarization_prompt\n\n\nclass SummarizationPage(BasePage):\n    example_path = \"summarization.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_summarization_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\n            \"passage\": st.text_area(label=\"Passage.\", value=\"\", height=300),\n        }", "class SummarizationPage(BasePage):\n    example_path = \"summarization.json\"\n\n    def make_prompt(self, examples: List[Dict]):\n        return make_summarization_prompt(examples)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\n            \"passage\": st.text_area(label=\"Passage.\", value=\"\", height=300),\n        }", "\n\npage = SummarizationPage(title=\"Summarization\")\npage.render()\n"]}
{"filename": "doccano_mini/pages/05_Named_Entity_Recognition.py", "chunked_list": ["from typing import Dict, List\n\nimport pandas as pd\nimport streamlit as st\nfrom st_ner_annotate import st_ner_annotate\n\nfrom doccano_mini.layout import BasePage\nfrom doccano_mini.prompts import make_named_entity_recognition_prompt\nfrom doccano_mini.storages.entity import EntitySessionStorage\nfrom doccano_mini.storages.stepper import StepperSessionStorage", "from doccano_mini.storages.entity import EntitySessionStorage\nfrom doccano_mini.storages.stepper import StepperSessionStorage\n\n\nclass NamedEntityRecognitionPage(BasePage):\n    example_path = \"named_entity_recognition.json\"\n\n    def __init__(self, title: str) -> None:\n        super().__init__(title)\n        self.types: List[str] = []\n        self.entity_repository = EntitySessionStorage()\n        self.stepper_repository = StepperSessionStorage()\n\n    def define_entity_types(self):\n        st.subheader(\"Define entity types\")\n        default_types = pd.DataFrame([{\"type\": entity_type} for entity_type in [\"ORG\", \"LOC\", \"PER\"]])\n        edited_df = st.experimental_data_editor(default_types, num_rows=\"dynamic\", width=1000)\n        types = edited_df[\"type\"].values\n        self.types = types\n        return types\n\n    def annotate(self, examples: List[Dict]) -> List[Dict]:\n        if len(examples) == 0:\n            return []\n\n        types = self.define_entity_types()\n        selected_type = st.selectbox(\"Select an entity type\", types)\n\n        col1, col2, _ = st.columns([1, 1, 8])\n        col1.button(\"Prev\", on_click=self.stepper_repository.decrement, args=(len(examples),))\n        col2.button(\"Next\", on_click=self.stepper_repository.increment, args=(len(examples),))\n\n        self.stepper_repository.fit(len(examples))\n        step = self.stepper_repository.get_step()\n        text = examples[step][\"text\"]\n        entities = self.entity_repository.find_by_text(text)\n        entities = st_ner_annotate(selected_type, text, entities, key=text)\n        self.entity_repository.store_by_text(text, entities)\n        return examples\n\n    def make_prompt(self, examples: List[Dict]):\n        examples = [\n            {**example, \"entities\": self.entity_repository.find_by_text(example[\"text\"])} for example in examples\n        ]\n        return make_named_entity_recognition_prompt(examples, types=self.types)\n\n    def prepare_inputs(self, columns: List[str]):\n        return {\"text\": st.text_area(label=\"Please enter your text.\", value=\"\", height=300)}", "\n\npage = NamedEntityRecognitionPage(title=\"Named Entity Recognition\")\npage.render()\n"]}
{"filename": "doccano_mini/storages/session_storage.py", "chunked_list": ["from typing import Any\n\nfrom streamlit.runtime.state import SessionStateProxy\n\n\nclass SessionStorage:\n    def __init__(self, state: SessionStateProxy) -> None:\n        self.state = state\n\n    def init_state(self, key: str, value: Any) -> None:\n        if key not in self.state:\n            self.state[key] = value\n\n    def set_state(self, key: str, value: Any, *, do_init: bool = False) -> None:\n        if do_init:\n            self.init_state(key, value)\n\n        self.state[key] = value\n\n    def get_state(self, key: str) -> Any:\n        return self.state.get(key, None)", ""]}
{"filename": "doccano_mini/storages/entity.py", "chunked_list": ["from collections import defaultdict\nfrom typing import List\n\nimport streamlit as st\n\nfrom doccano_mini.models.entity import Entity\nfrom doccano_mini.storages.session_storage import SessionStorage\n\n\nclass EntitySessionStorage:\n    def __init__(self) -> None:\n        self.storage = SessionStorage(state=st.session_state)\n        self.storage.init_state(\"entities\", defaultdict(list))\n\n    def find_by_text(self, text: str) -> List[Entity]:\n        entities = self.storage.get_state(\"entities\")\n        return entities.get(text, [])\n\n    def store_by_text(self, text: str, entities: List[Entity]) -> None:\n        current_entities = self.storage.get_state(\"entities\")\n        current_entities[text] = entities\n        self.storage.set_state(\"entities\", current_entities)", "\nclass EntitySessionStorage:\n    def __init__(self) -> None:\n        self.storage = SessionStorage(state=st.session_state)\n        self.storage.init_state(\"entities\", defaultdict(list))\n\n    def find_by_text(self, text: str) -> List[Entity]:\n        entities = self.storage.get_state(\"entities\")\n        return entities.get(text, [])\n\n    def store_by_text(self, text: str, entities: List[Entity]) -> None:\n        current_entities = self.storage.get_state(\"entities\")\n        current_entities[text] = entities\n        self.storage.set_state(\"entities\", current_entities)", ""]}
{"filename": "doccano_mini/storages/stepper.py", "chunked_list": ["import streamlit as st\n\nfrom doccano_mini.models.stepper import Stepper\nfrom doccano_mini.storages.session_storage import SessionStorage\n\n\nclass StepperSessionStorage:\n    def __init__(self) -> None:\n        self.storage = SessionStorage(state=st.session_state)\n        self.storage.init_state(\"step\", 0)\n\n    def get_step(self) -> int:\n        return self.storage.get_state(\"step\")\n\n    def fit(self, total: int) -> None:\n        step = self.storage.get_state(\"step\")\n        stepper = Stepper(step)\n        stepper.fit(total)\n        self.storage.set_state(\"step\", stepper.step)\n\n    def increment(self, total: int) -> None:\n        step = self.storage.get_state(\"step\")\n        stepper = Stepper(step)\n        stepper.increment(total)\n        self.storage.set_state(\"step\", stepper.step)\n\n    def decrement(self, total: int) -> None:\n        step = self.storage.get_state(\"step\")\n        stepper = Stepper(step)\n        stepper.decrement(total)\n        self.storage.set_state(\"step\", stepper.step)", ""]}
{"filename": "doccano_mini/models/entity.py", "chunked_list": ["from typing import TypedDict\n\n\nclass Entity(TypedDict):\n    start: int\n    end: int\n    label: str\n"]}
{"filename": "doccano_mini/models/stepper.py", "chunked_list": ["class Stepper:\n    def __init__(self, step=0):\n        self._step = step\n\n    @property\n    def step(self) -> int:\n        return self._step\n\n    def fit(self, total: int):\n        if self._step >= total:\n            self._step = total - 1\n\n    def at(self, step: int, total: int):\n        if step >= total:\n            raise ValueError(f\"step must be less than {total}\")\n        if step < 0:\n            raise ValueError(\"step must be greater than 0\")\n        self._step = step\n\n    def increment(self, total: int):\n        self._step += 1\n        if self._step >= total:\n            self._step = 0\n\n    def decrement(self, total: int):\n        self._step -= 1\n        if self._step < 0:\n            self._step = total - 1", ""]}
