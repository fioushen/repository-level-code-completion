{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\nversion = open('VERSION').read().strip()\nlicense = open('LICENSE').read().strip()\n\nsetup(\n    name=\"pointstorm\",\n    version=version,\n    license=license,\n    description=\"Embedding vectors for data on the move\",", "    license=license,\n    description=\"Embedding vectors for data on the move\",\n    author=\"xsfa\",\n    author_email=\"tesfaaog@gmail.com\",\n    url=\"https://github.com/xsfa/pointstorm\",\n    packages=find_packages(),\n    install_requires=[\n        'bytewax==0.16.0',\n        'requests>=2.28.0',\n        'kafka-python==2.0.2',", "        'requests>=2.28.0',\n        'kafka-python==2.0.2',\n        'confluent-kafka',\n        'faker',\n        'transformers',\n        'torch',\n        'pydantic',\n        'unstructured'\n        'numpy',\n        'unittest'", "        'numpy',\n        'unittest'\n    ],\n    classifiers=[\n        \"Development Status :: 3 - Alpha\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",", "        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n    ],\n)\n"]}
{"filename": "pointstorm/config.py", "chunked_list": ["import logging\n\nabstract_logger = logging.getLogger(\"pointstorm_log\")\nabstract_logger.setLevel(logging.DEBUG)\n\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\n\nformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s: %(message)s\")\nconsole_handler.setFormatter(formatter)", "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s: %(message)s\")\nconsole_handler.setFormatter(formatter)\n\nabstract_logger.addHandler(console_handler)"]}
{"filename": "pointstorm/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/monitoring.py", "chunked_list": [""]}
{"filename": "pointstorm/ingestion/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/ingestion/cdc/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/ingestion/cdc/debezium.py", "chunked_list": ["# ingesting debezium event\n# matching existing record on vector entry metadata"]}
{"filename": "pointstorm/ingestion/event/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/ingestion/event/kafka.py", "chunked_list": ["# Generic imports\nimport json\nimport logging\nimport warnings\nimport os\nimport uuid\nwarnings.filterwarnings(action = 'ignore')\n\n# Ingestion Imports\nfrom bytewax.testing import run_main", "# Ingestion Imports\nfrom bytewax.testing import run_main\nfrom bytewax.dataflow import Dataflow\nfrom bytewax.connectors.kafka import KafkaInput\nfrom bytewax.connectors.stdio import StdOutput\n# from kafka import KafkaConsumer, TopicPartition\n\n# ML imports\nfrom transformers import AutoTokenizer, AutoModel\nimport torch", "from transformers import AutoTokenizer, AutoModel\nimport torch\n\n# Local imports\nfrom pointstorm.config import abstract_logger as kafka_logger\nfrom pointstorm.embedding.text import Document, generate_embedding\n\nclass KafkaIngestionException(Exception):\n    pass\n\nclass KafkaTextEmbeddings():\n    def __init__(self, kafka_topic, kafka_bootstrap_server, kafka_config, huggingface_model_name):\n        self.kafka_topic = kafka_topic\n        self.kafka_bootstrap_server = kafka_bootstrap_server\n        self.kafka_config = kafka_config\n        self.model_name = huggingface_model_name\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModel.from_pretrained(self.model_name)\n\n    def set_output(self, output):\n        # TODO: Add output\n        self.output = output\n\n    def embedding(self, message) -> Document:\n        \"\"\"\n        Generating embedding using text embedding class\n        \"\"\"\n\n        if \"raw_text\" in json.loads(message[1]):\n            message = str(json.loads(message[1])[\"raw_text\"])\n        else:\n            raise KafkaIngestionException(\"Message does not contain the specified text field: \" + self.text_field)\n        \n        doc = Document(\n            id=str(uuid.uuid4()),\n            group_key=\"group1\",\n            metadata={},\n            text=[message],\n            embeddings=[[]]\n        )\n        \n        doc = generate_embedding(\n            document=doc, \n            tokenizer=self.tokenizer, \n            model=self.model\n        )\n\n        kafka_logger.info(f\"Generated embeddings for message: {message} ({doc.id}): {doc.embeddings}\")\n        return doc\n    \n    def run(self):\n        input_config = KafkaInput(\n            brokers=[self.kafka_bootstrap_server],\n            topics=[self.kafka_topic],\n            add_config=self.kafka_config\n        )\n\n        kafka_logger.info(\"Started KafkaTextEmbeddings for topic: \" + self.kafka_topic)\n        flow = Dataflow()\n        flow.input(self.kafka_topic, input_config)\n        flow.map(self.embedding)\n        flow.output(\"stdout\", StdOutput())\n        run_main(flow)", "\nclass KafkaTextEmbeddings():\n    def __init__(self, kafka_topic, kafka_bootstrap_server, kafka_config, huggingface_model_name):\n        self.kafka_topic = kafka_topic\n        self.kafka_bootstrap_server = kafka_bootstrap_server\n        self.kafka_config = kafka_config\n        self.model_name = huggingface_model_name\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModel.from_pretrained(self.model_name)\n\n    def set_output(self, output):\n        # TODO: Add output\n        self.output = output\n\n    def embedding(self, message) -> Document:\n        \"\"\"\n        Generating embedding using text embedding class\n        \"\"\"\n\n        if \"raw_text\" in json.loads(message[1]):\n            message = str(json.loads(message[1])[\"raw_text\"])\n        else:\n            raise KafkaIngestionException(\"Message does not contain the specified text field: \" + self.text_field)\n        \n        doc = Document(\n            id=str(uuid.uuid4()),\n            group_key=\"group1\",\n            metadata={},\n            text=[message],\n            embeddings=[[]]\n        )\n        \n        doc = generate_embedding(\n            document=doc, \n            tokenizer=self.tokenizer, \n            model=self.model\n        )\n\n        kafka_logger.info(f\"Generated embeddings for message: {message} ({doc.id}): {doc.embeddings}\")\n        return doc\n    \n    def run(self):\n        input_config = KafkaInput(\n            brokers=[self.kafka_bootstrap_server],\n            topics=[self.kafka_topic],\n            add_config=self.kafka_config\n        )\n\n        kafka_logger.info(\"Started KafkaTextEmbeddings for topic: \" + self.kafka_topic)\n        flow = Dataflow()\n        flow.input(self.kafka_topic, input_config)\n        flow.map(self.embedding)\n        flow.output(\"stdout\", StdOutput())\n        run_main(flow)"]}
{"filename": "pointstorm/inputs/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/destinations/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/producers/text_producer.py", "chunked_list": ["import json\nimport time\nimport logging\nimport random \nfrom confluent_kafka import Producer\nfrom faker import Faker\n\nlogger = logging.getLogger(__name__)\n\nclass TextProducer:\n    \"\"\"\n    Produce raw text data to Kafka Topic\n    \"\"\"\n\n    def __init__(self, kafka_topic, config):\n        self.topic = kafka_topic\n        self.config = config\n        self.producer = Producer(config)\n\n    def produce(self, text):\n        def receipt(err, msg):\n            if err is not None:\n                logger.error('Failed to deliver message: {}'.format(err.value()))\n            else:\n                message = 'Produced message on topic {} with value of {}\\n'.format(msg.topic(), msg.value().decode('utf-8'))\n                logger.info(message)\n                print(message)\n\n        data = {\n            \"msg_time\": time.time(),\n            \"raw_text\": text,\n        }\n        self.producer.poll(1)\n        self.producer.produce(self.topic, json.dumps(data).encode('utf-8'), callback=receipt)\n        self.producer.flush()", "\nclass TextProducer:\n    \"\"\"\n    Produce raw text data to Kafka Topic\n    \"\"\"\n\n    def __init__(self, kafka_topic, config):\n        self.topic = kafka_topic\n        self.config = config\n        self.producer = Producer(config)\n\n    def produce(self, text):\n        def receipt(err, msg):\n            if err is not None:\n                logger.error('Failed to deliver message: {}'.format(err.value()))\n            else:\n                message = 'Produced message on topic {} with value of {}\\n'.format(msg.topic(), msg.value().decode('utf-8'))\n                logger.info(message)\n                print(message)\n\n        data = {\n            \"msg_time\": time.time(),\n            \"raw_text\": text,\n        }\n        self.producer.poll(1)\n        self.producer.produce(self.topic, json.dumps(data).encode('utf-8'), callback=receipt)\n        self.producer.flush()"]}
{"filename": "pointstorm/producers/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/examples/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/examples/kafka/kafka_producer.py", "chunked_list": ["from pointstorm.producers.text_producer import TextProducer\nfrom faker import Faker\n\nfake = Faker()\n\n# Create Kafka Producer\nkafka_config = {\n    'bootstrap.servers':'localhost:9092',\n}\n", "}\n\nkafka_topic = \"user-tracker2\"\np = TextProducer(kafka_topic, kafka_config)\nprint('Kafka Producer has been initiated...')\n\n# Producing 10 random sentences to Kafka topic\ndef produce():    \n    for i in range(10):\n        # generating fake sentence\n        sentence = fake.sentence(nb_words=6, variable_nb_words=True, ext_word_list=None)\n        p.produce(sentence)", "\nproduce()"]}
{"filename": "pointstorm/examples/kafka/__init__.py", "chunked_list": [""]}
{"filename": "pointstorm/examples/kafka/run_kafka.py", "chunked_list": ["import os\nfrom pointstorm.ingestion.event.kafka import KafkaTextEmbeddings\n\nif __name__ == \"__main__\":\n    kafka_consumer_config = {\n        'group.id': f\"kafka_text_vectorizer\",\n        'auto.offset.reset': 'largest',\n        'enable.auto.commit': True\n    }\n\n    kafka_embeddings = KafkaTextEmbeddings(\n        kafka_topic=\"user-tracker2\",\n        kafka_bootstrap_server=\"localhost:9092\",\n        kafka_config=kafka_consumer_config,\n        huggingface_model_name= \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n    )\n    kafka_embeddings.run()"]}
{"filename": "pointstorm/embedding/text.py", "chunked_list": ["import hashlib\nfrom typing import List, Optional\nfrom pydantic import BaseModel\nfrom typing import Any, Optional\nfrom numpy import ndarray\nfrom transformers import AutoTokenizer, AutoModel\n\nimport json\n\nfrom unstructured.partition.html import partition_html", "\nfrom unstructured.partition.html import partition_html\nfrom unstructured.cleaners.core import clean, replace_unicode_quotes, clean_non_ascii_chars\nfrom unstructured.staging.huggingface import chunk_by_attention_window\nfrom unstructured.staging.huggingface import stage_for_transformers\n\nimport hashlib\nfrom pydantic import BaseModel\nfrom typing import Any, Optional\n\nclass Document(BaseModel):\n    \"\"\"\n    Document object to be used for generating embeddings.\n    @params:\n        id: Unique identifier for the document.\n        group_key: Group key for the document.\n        metadata: Metadata for the document.\n        text: The text.\n        embeddings: Generated embeddings.\n    \"\"\"\n    id: str\n    group_key: Optional[str] = None\n    metadata: Optional[dict] = {}\n    text: Optional[list]\n    embeddings: Optional[list] = []", "from typing import Any, Optional\n\nclass Document(BaseModel):\n    \"\"\"\n    Document object to be used for generating embeddings.\n    @params:\n        id: Unique identifier for the document.\n        group_key: Group key for the document.\n        metadata: Metadata for the document.\n        text: The text.\n        embeddings: Generated embeddings.\n    \"\"\"\n    id: str\n    group_key: Optional[str] = None\n    metadata: Optional[dict] = {}\n    text: Optional[list]\n    embeddings: Optional[list] = []", "\ndef generate_embedding(document: Document, tokenizer: AutoTokenizer, model: AutoModel) -> Document:\n    \"\"\"\n    Generate embedding for a given document using a pretrained model.\n    @params: \n        document: Document for which to generate the embeddings.\n    returns: \n        Document: Document object with updated embeddings.\n    \"\"\"\n    try:\n        inputs = tokenizer(\n            document.text,\n            padding=True,\n            truncation=True,\n            return_tensors=\"pt\",\n            max_length=384\n        )\n        result = model(**inputs)\n        embeddings = result.last_hidden_state[:, 0, :].cpu().detach().numpy()\n        flattened_embeddings = embeddings.flatten().tolist()\n        document.embeddings.append(flattened_embeddings)\n\n        return document\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        return None"]}
{"filename": "pointstorm/embedding/text_tests.py", "chunked_list": ["import unittest\nfrom pointstorm.embedding.text import Document, generate_embedding\nfrom unittest.mock import patch, MagicMock\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\n\nclass TestDocumentModel(unittest.TestCase):\n    def test_document_model_creation(self):\n        doc = Document(\n            id=\"123\",\n            group_key=\"group1\",\n            metadata={\"author\": \"John Doe\"},\n            text=[\"Hello, world!\"],\n            embeddings=[[]]\n        )\n        self.assertEqual(doc.id, \"123\")\n        self.assertEqual(doc.group_key, \"group1\")\n        self.assertEqual(doc.metadata, {\"author\": \"John Doe\"})\n        self.assertEqual(doc.text, [\"Hello, world!\"])\n        self.assertEqual(doc.embeddings, [[]])", "\n\n@patch(\"builtins.print\")\nclass TestGenerateEmbedding(unittest.TestCase):\n    @patch.object(AutoTokenizer, 'from_pretrained')\n    @patch.object(AutoModel, 'from_pretrained')\n    def setUp(self, mock_model, mock_tokenizer):\n        self.mock_model = mock_model\n        self.mock_tokenizer = mock_tokenizer\n        self.document = Document(\n            id=\"123\",\n            group_key=\"group1\",\n            metadata={\"author\": \"John Doe\"},\n            text=[\"Hello, world!\"],\n            embeddings=[[]]\n        )\n\n    def test_generate_embedding_success(self, mock_print):\n        # Mocking the tokenizer and model return values\n        self.mock_tokenizer.return_value = {\"input_ids\": [1, 2, 3], \"attention_mask\": [1, 1, 1]}\n        self.mock_model.return_value = MagicMock(last_hidden_state=torch.tensor([[1, 2, 3]]))\n\n        # Create fake tokenizer and model\n        tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n        model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n\n        result = generate_embedding(document=self.document, tokenizer=tokenizer, model=model)\n\n        # Check that the function returned a Document\n        self.assertIsInstance(result, Document)\n\n        # Check that embeddings are there\n        self.assertGreaterEqual(len(result.embeddings), 1)", "\n# Run the tests\nif __name__ == '__main__':\n    unittest.main()"]}
{"filename": "pointstorm/embedding/__init__.py", "chunked_list": [""]}
