{"filename": "setup.py", "chunked_list": ["import os\nimport platform\nimport numpy as np\nfrom setuptools import setup\nfrom setuptools.command.build_ext import build_ext\nfrom distutils.extension import Extension\nfrom Cython.Build import cythonize\n\n\n# --------------------------------------------------------------------------------------------", "\n# --------------------------------------------------------------------------------------------\n# Handling compile args for Cython\n# --------------------------------------------------------------------------------------------\nif platform.system() == \"Darwin\":\n    compile_opts = [\n        \"-std=c++11\",\n        \"-Ofast\",  # '-fopenmp',\n        \"-mmacosx-version-min={:}\".format(platform.mac_ver()[0]),\n    ]\n\nelif platform.system() == \"Linux\":\n    compile_opts = [\n        \"-std=c++11\",\n        \"-Ofast\",  # '-fopenmp'\n    ]\n\nelse:\n    raise EnvironmentError(\n        \"Not supported platform: {plat}\".format(plat=platform.system())\n    )", "\n\n# --------------------------------------------------------------------------------------------\n# C++/Cython extesnions and packages\n# --------------------------------------------------------------------------------------------\ntsp_ext = Extension(\n    \"torch_integral.tsp_solver.solver\",\n    sources=[\"torch_integral/tsp_solver/solver.pyx\"],\n    extra_compile_args=compile_opts,\n    extra_link_args=compile_opts,", "    extra_compile_args=compile_opts,\n    extra_link_args=compile_opts,\n    language=\"c++\",\n    include_dirs=[np.get_include()],\n)\next_modules = [tsp_ext]\npackages = [\n    \"torch_integral\",\n    \"torch_integral.tsp_solver\",\n    \"torch_integral.graph\",", "    \"torch_integral.tsp_solver\",\n    \"torch_integral.graph\",\n    \"torch_integral.parametrizations\",\n]\n\n\n# --------------------------------------------------------------------------------------------\n# Package setup\n# --------------------------------------------------------------------------------------------\nsetup(", "# --------------------------------------------------------------------------------------------\nsetup(\n    name=\"TorchIntegral\",\n    ext_modules=cythonize(ext_modules),\n    version=\"0.0.0.0\",\n    author=\"Azim Kurbanov, Solodskikh Kirill\",\n    author_email=\"hello@thestage.ai\",\n    maintainer=\"TheStage.AI\",\n    maintainer_email=\"hello@thestage.ai\",\n    install_requires=[\"cython\"],", "    maintainer_email=\"hello@thestage.ai\",\n    install_requires=[\"cython\"],\n    description=\"Official Integral Neural Networks in PyTorch.\",\n    url=\"https://inn.thestage.ai\",\n    zip_safe=False,\n    packages=packages,\n    license=\"Apache License 2.0\",\n    long_description=\"Bla Bla\",\n    classifiers=[\"Programming Language :: Python :: 3\"],\n)", "    classifiers=[\"Programming Language :: Python :: 3\"],\n)\n"]}
{"filename": "tests/tsp_test.py", "chunked_list": ["import torch\nimport time\nimport torch_integral\nfrom torch_integral.tsp_solver import two_opt_find_permutation\n\ntensors = [\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},", "    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},", "    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n    {\"value\": torch.randn(512, 512, 3, 3), \"dim\": 0},\n]\n\nt = time.time()\nind = two_opt_find_permutation(tensors, 64, 100, 0.01)\nt = time.time() - t\n\nprint(\"time: \", t)", "\nprint(\"time: \", t)\n"]}
{"filename": "torch_integral/model.py", "chunked_list": ["import copy\nfrom typing import Any, Mapping\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils import parametrize\nfrom .grid import GridND\nfrom .graph import IntegralTracer\nfrom .parametrizations import IntegralParameterization\nfrom .parametrizations import InterpolationWeights1D\nfrom .parametrizations import InterpolationWeights2D", "from .parametrizations import InterpolationWeights1D\nfrom .parametrizations import InterpolationWeights2D\nfrom .permutation import NOptPermutation\nfrom .quadrature import TrapezoidalQuadrature\nfrom .grid import TrainableGrid1D\nfrom .utils import (\n    reset_batchnorm,\n    get_parent_name,\n    fuse_batchnorm,\n    get_parent_module,", "    fuse_batchnorm,\n    get_parent_module,\n    get_attr_by_name,\n)\n\n\nclass IntegralModel(nn.Module):\n    \"\"\"\n    Contains original model with parametrized layers and IntegralGroups list.\n\n    Parameters\n    ----------\n    model: torch.nn.Module.\n        Model with parametrized layers.\n    groups: List[IntegralGroup].\n        List related groups.\n    \"\"\"\n\n    def __init__(self, model, groups):\n        super(IntegralModel, self).__init__()\n        self.model = model\n        groups.sort(key=lambda g: g.count_parameters())\n        self.groups = nn.ModuleList(groups)\n        # Rename groups to integral_groups\n        self.original_size = None\n        self.original_size = self.calculate_compression()\n\n    def generate_grid(self):\n        \"\"\"Creates new grids in each group.\"\"\"\n        for group in self.groups:\n            group.grid.generate_grid()\n\n    def clear(self):\n        \"\"\"Clears cached tensors in all integral groups.\"\"\"\n        for group in self.groups:\n            group.clear()\n\n    def load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True):\n        out = super().load_state_dict(state_dict, strict)\n        self.clear()\n\n        return out\n\n    def forward(self, x):\n        \"\"\"\n        Performs forward pass of the model.\n\n        Parameters\n        ----------\n        x: the same as wrapped model's input type.\n            Input of the model.\n\n        Returns\n        -------\n        Model's output.\n        \"\"\"\n        self.generate_grid()\n\n        return self.model(x)\n\n    def calculate_compression(self):\n        \"\"\"\n        Returns 1 - ratio of the size of the current\n        model to the original size of the model.\n        \"\"\"\n        out = 0\n        self.generate_grid()\n\n        for group in self.groups:\n            group.clear()\n\n        for name, param in self.model.named_parameters():\n            if \"parametrizations.\" not in name:\n                out += param.numel()\n            elif name.endswith(\".original\"):\n                name = name.replace(\".original\", \"\")\n                name = name.replace(\"parametrizations.\", \"\")\n                tensor = get_attr_by_name(self.model, name)\n                out += tensor.numel()\n\n        if self.original_size is not None:\n            out = 1.0 - out / self.original_size\n\n        return out\n\n    def resize(self, sizes):\n        \"\"\"\n        Resizes grids in each group.\n\n        Parameters\n        ----------\n        sizes: List[int].\n            List of new sizes.\n        \"\"\"\n        for group, size in zip(self.groups, sizes):\n            group.resize(size)\n\n    def reset_grids(self, grids):\n        for group, grid in zip(self.groups, grids):\n            group.reset_grid(grid)\n\n    def reset_distributions(self, distributions):\n        \"\"\"\n        Sets new distributions in each IntegralGroup.grid.\n\n        Parameters\n        ----------\n        distributions: List[torch_integral.grid.Distribution].\n            List of new distributions.\n        \"\"\"\n        for group, dist in zip(self.groups, distributions):\n            group.reset_distribution(dist)\n\n    def grids(self):\n        \"\"\"Returns list of grids of each integral group.\"\"\"\n        return [group.grid for group in self.groups]\n\n    def __getattr__(self, item):\n        if item in dir(self):\n            out = super().__getattr__(item)\n        else:\n            out = getattr(self.model, item)\n\n        return out\n\n    def transform_to_discrete(self):\n        \"\"\"Samples weights, removes parameterizations and returns discrete model.\"\"\"\n        self.generate_grid()\n        parametrizations = []\n\n        for name, module in self.model.named_modules():\n            for attr_name in (\"weight\", \"bias\"):\n                if parametrize.is_parametrized(module, attr_name):\n                    parametrization = getattr(module.parametrizations, attr_name)[0]\n                    parametrizations.append((module, attr_name, parametrization))\n                    parametrize.remove_parametrizations(module, attr_name, True)\n\n        discrete_model = copy.deepcopy(self.model)\n\n        for p_data in parametrizations:\n            module, attr_name, parametrization = p_data\n            parametrize.register_parametrization(\n                module, attr_name, parametrization, unsafe=True\n            )\n\n        return discrete_model\n\n    def grid_tuning(self, train_bn=False, train_bias=False, use_all_grids=False):\n        \"\"\"\n        Sets requires_grad = False for all parameters except TrainableGrid's parameters,\n        biases and BatchNorm parameters (if corresponding flag is True).\n\n        Parameters\n        ----------\n        train_bn: bool.\n            Set True to train BatchNorm parameters.\n        train_bias: bool.\n            Set True to train biases.\n        use_all_grids: bool.\n            Set True to use all grids in each group.\n        \"\"\"\n        if use_all_grids:\n            for group in self.groups:\n                if group.subgroups is None:\n                    group.reset_grid(TrainableGrid1D(group.grid_size()))\n\n        for name, param in self.named_parameters():\n            parent = get_parent_module(self, name)\n\n            if isinstance(parent, TrainableGrid1D):\n                param.requires_grad = True\n            else:\n                param.requires_grad = False\n\n        if train_bn:\n            reset_batchnorm(self)\n\n        if train_bias:\n            for group in self.groups:\n                for p in group.params:\n                    if \"bias\" in p[\"name\"]:\n                        parent = get_parent_module(self.model, p[\"name\"])\n                        if parametrize.is_parametrized(parent, \"bias\"):\n                            parametrize.remove_parametrizations(parent, \"bias\", True)\n                        getattr(parent, \"bias\").requires_grad = True", "\n\nclass IntegralWrapper:\n    \"\"\"\n    Wrapper class which allows batch norm fusion,\n    permutation of tensor parameters to obtain continuous structure in the tensor\n    and convertation of discrete model to integral.\n\n    Parameters\n    ----------\n    init_from_discrete: bool.\n        If set True, then parametrization will be optimized with\n        gradient descent to approximate discrete model's weights.\n    fuse_bn: bool.\n        If True, then convolutions and batchnorms will be fused.\n    optimize_iters: int.\n        Number of optimization iterations for discerete weight tensor approximation.\n    start_lr: float.\n        Learning rate when optimizing parametrizations.\n    permutation_config: dict.\n        Arguments of permutation method.\n    build_functions: dict.\n        Dictionary with keys\n    permutation_iters: int.\n        Number of iterations of total variation optimization process.\n    verbose: bool.\n        If True, then information about model convertation process will be printed.\n    \"\"\"\n\n    def __init__(\n        self,\n        init_from_discrete=True,\n        fuse_bn=True,\n        optimize_iters=0,\n        start_lr=1e-2,\n        permutation_config=None,\n        build_functions=None,\n        permutation_iters=100,\n        verbose=True,\n    ):\n        self.init_from_discrete = init_from_discrete\n        self.fuse_bn = fuse_bn\n        self.optimize_iters = optimize_iters\n        self.start_lr = start_lr\n        self.build_functions = build_functions\n        self.verbose = verbose\n        self.rearranger = None\n\n        if permutation_config is not None:\n            permutation_class = permutation_config.pop(\"class\")\n            self.rearranger = permutation_class(**permutation_config)\n\n        elif self.init_from_discrete and permutation_iters > 0:\n            self.rearranger = NOptPermutation(permutation_iters, verbose)\n\n    def _rearrange(self, groups):\n        \"\"\"\n        Rearranges the tensors in each group along continuous\n        dimension to obtain continuous structure in tensors.\n\n        Parameters\n        ----------\n        groups: List[IntegralGroup].\n            List of related integral groups.\n        \"\"\"\n        for i, group in enumerate(groups):\n            params = list(group.params)\n            feature_maps = group.tensors\n\n            if self.verbose:\n                print(f\"Rearranging of group {i}\")\n\n            for parent in group.parents:\n                start = 0\n\n                for another_group in parent.subgroups:\n                    if group is not another_group:\n                        start += another_group.size\n                    else:\n                        break\n\n                for p in parent.params:\n                    params.append(\n                        {\n                            \"name\": p[\"name\"],\n                            \"value\": p[\"value\"],\n                            \"dim\": p[\"dim\"],\n                            \"start_index\": start,\n                        }\n                    )\n\n            self.rearranger(params, feature_maps, group.size)\n\n    def preprocess_model(\n        self,\n        model,\n        example_input,\n        continuous_dims,\n        discrete_dims=None,\n        custom_operations=None,\n        custom_hooks=None,\n    ):\n        \"\"\"\n        Builds dependency graph of the model, fuses BatchNorms\n        and permutes tensor parameters along countinuous\n        dimension to obtain smooth structure.\n\n        Parameters\n        ----------\n        model: torch.nn.Module.\n            Discrete neural network.\n        example_input: torch.Tensor or List[int].\n            Example input for the model.\n        continuous_dims: Dict[str, List[int]].\n            Dictionary with keys as names of parameters and values\n            as lists of continuous dimensions of corresponding parameters.\n        discrete_dims: Dict[str, List[int]].\n            Dictionary with keys as names of parameters and values\n            as lists of discrete dimensions of corresponding parameters.\n        custom_operations: Dict[Union[str, Callable], Callable].\n            Dictionary which contains custom tracing operations for the graph.\n        custom_hooks: Dict[torch.nn.Module, Callable].\n            Dictionary which contains custom hooks for the graph.\n\n        Returns\n        -------\n        List[IntegralGroup].\n            List of IntegralGroup objects.\n        Dict[str, List[int]].\n            Modified dictionary with continuous dimensions.\n        \"\"\"\n        tracer = IntegralTracer(\n            model, continuous_dims, discrete_dims, custom_operations, custom_hooks\n        )\n        tracer.build_groups(example_input)\n\n        if self.fuse_bn:\n            integral_convs = set()\n\n            for name, _ in model.named_parameters():\n                if name in tracer.continuous_dims:\n                    parent = get_parent_module(model, name)\n                    dims = tracer.continuous_dims[name]\n\n                    if isinstance(parent, nn.Conv2d) and 0 in dims:\n                        integral_convs.add(get_parent_name(name)[0])\n\n            fuse_batchnorm(model.eval(), list(integral_convs))\n\n        tracer = IntegralTracer(\n            model, continuous_dims, discrete_dims, custom_operations, custom_hooks\n        )\n        groups = tracer.build_groups(example_input)\n\n        if self.init_from_discrete and self.rearranger is not None:\n            self._rearrange(groups)\n\n        return groups, tracer.continuous_dims\n\n    def __call__(\n        self,\n        model,\n        example_input,\n        continuous_dims,\n        discrete_dims=None,\n        custom_operations=None,\n        custom_hooks=None,\n    ):\n        \"\"\"\n        Parametrizes tensor parameters of the model\n        and wraps the model into IntegralModel class.\n\n        Parameters\n        ----------\n        model: torch.nn.Module.\n            Discrete neural network.\n        example_input: List[int] or torch.Tensor.\n            Example input for the model.\n        continuous_dims: Dict[str, List[int]].\n            Dictionary with keys as names of parameters and values\n            as lists of continuous dimensions of corresponding parameters.\n        discrete_dims: Dict[str, List[int]].\n            Dictionary with keys as names of parameters and values\n            as lists of discrete dimensions of corresponding parameters.\n\n        Returns\n        -------\n        IntegralModel.\n            Model converted to integral form.\n        \"\"\"\n        integral_groups, continuous_dims = self.preprocess_model(\n            model,\n            example_input,\n            continuous_dims,\n            discrete_dims,\n            custom_operations,\n            custom_hooks,\n        )\n        groups = [g for g in integral_groups if g.subgroups is None]\n\n        for group in groups:\n            group.initialize_grids()\n\n        for group in integral_groups:\n            for p in group.params:\n                _, name = get_parent_name(p[\"name\"])\n                parent = get_parent_module(model, p[\"name\"])\n\n                if not parametrize.is_parametrized(parent, name) or all(\n                    [\n                        not isinstance(obj, IntegralParameterization)\n                        for obj in parent.parametrizations[name]\n                    ]\n                ):\n                    if (\n                        self.build_functions is not None\n                        and type(parent) in self.build_functions\n                    ):\n                        build_function = self.build_functions[type(parent)]\n                    elif isinstance(parent, (nn.Linear, nn.Conv2d, nn.Conv1d)):\n                        build_function = build_base_parameterization\n                    else:\n                        raise AttributeError(\n                            f\"Provide build function for attribute {name} of {type(parent)}\"\n                        )\n\n                    dims = continuous_dims[p[\"name\"]]\n                    w_func, quadrature = build_function(parent, name, dims)\n                    grids_list = []\n\n                    for g in p[\"value\"].grids:\n                        if hasattr(g, \"grid\") and g.grid is not None:\n                            if g in integral_groups:\n                                grids_list.append(g.grid)\n\n                    grid = GridND(grids_list)\n                    delattr(p[\"value\"], \"grids\")\n                    parametrization = IntegralParameterization(\n                        w_func, grid, quadrature\n                    ).to(p[\"value\"].device)\n                    target = p[\"value\"].detach().clone()\n                    target.requires_grad = False\n                    parametrize.register_parametrization(\n                        parent, name, parametrization, unsafe=True\n                    )\n\n                    if self.init_from_discrete:\n                        self._optimize_parameters(parent, p[\"name\"], target)\n\n                else:\n                    parametrization = parent.parametrizations[name][0]\n\n                p[\"function\"] = parametrization\n\n        integral_model = IntegralModel(model, integral_groups)\n\n        return integral_model\n\n    def _optimize_parameters(self, module, name, target):\n        \"\"\"\n        Optimize parametrization with Adam\n        to approximate tensor attribute of given module.\n\n        Parameters\n        ----------\n        module: torch.nn.Module.\n            Layer of the model.\n        name: str.\n            Name of the parameter.\n        target: torch.Tensor.\n            Tensor to approximate.\n        \"\"\"\n        module.train()\n        _, attr = get_parent_name(name)\n        criterion = torch.nn.MSELoss()\n        opt = torch.optim.Adam(module.parameters(), lr=self.start_lr, weight_decay=0.0)\n        scheduler = torch.optim.lr_scheduler.StepLR(\n            opt, step_size=self.optimize_iters // 5, gamma=0.2\n        )\n\n        if self.verbose:\n            print(name)\n            print(\n                \"loss before optimization: \",\n                float(criterion(getattr(module, attr), target)),\n            )\n\n        for i in range(self.optimize_iters):\n            weight = getattr(module, attr)\n            loss = criterion(weight, target)\n            loss.backward()\n            opt.step()\n            scheduler.step()\n            opt.zero_grad()\n\n            if i == self.optimize_iters - 1 and self.verbose:\n                print(\"loss after optimization: \", float(loss))", "\n\ndef build_base_parameterization(module, name, dims, scale=1.0):\n    \"\"\"\n    Builds parametrization and quadrature objects\n    for parameters of Conv2d, Conv1d or Linear\n\n    Parameters\n    ----------\n    module: torhc.nn.Module.\n        Layer of the model.\n    name: str.\n        Name of the parameter.\n    dims: List[int].\n        List of continuous dimensions of the parameter.\n    scale: float.\n        Parametrization size multiplier.\n\n    Returns\n    -------\n    IntegralParameterization.\n        Parametrization of the parameter.\n    BaseIntegrationQuadrature.\n        Quadrature object for the parameter.\n    \"\"\"\n    quadrature = None\n    func = None\n\n    if name == \"weight\":\n        weight = getattr(module, name)\n        cont_shape = [int(scale * weight.shape[d]) for d in dims]\n\n        if weight.ndim > len(dims):\n            discrete_shape = [\n                weight.shape[d] for d in range(weight.ndim) if d not in dims\n            ]\n        else:\n            discrete_shape = None\n\n        if len(cont_shape) == 2:\n            func = InterpolationWeights2D(cont_shape, discrete_shape)\n        elif len(cont_shape) == 1:\n            func = InterpolationWeights1D(cont_shape[0], discrete_shape, dims[0])\n\n        if 1 in dims and weight.shape[1] > 3:\n            grid_indx = 0 if len(cont_shape) == 1 else 1\n            quadrature = TrapezoidalQuadrature([1], [grid_indx])\n\n    elif \"bias\" in name:\n        bias = getattr(module, name)\n        cont_shape = int(scale * bias.shape[0])\n        func = InterpolationWeights1D(cont_shape)\n\n    return func, quadrature", ""]}
{"filename": "torch_integral/permutation.py", "chunked_list": ["import torch\nfrom .tsp_solver import two_opt_find_permutation\n\n\ndef total_variance(tensors):\n    \"\"\"\n    Calculates total variation of tensors along given dimension.\n\n    Parameters\n    ----------\n    tensors: List[Dict[str, obj]].\n        List of dicts with keys 'value' and 'dim'.\n\n    Returns\n    -------\n    total_var: float.\n        Estimated total variation.\n    \"\"\"\n    total_var = 0.0\n\n    for t in tensors:\n        tensor = t[\"value\"]\n        dim = t[\"dim\"]\n        tensor = tensor.transpose(dim, 0)\n        diff = (tensor[1:] - tensor[:-1]).abs().mean()\n        total_var = total_var + diff\n\n    return total_var", "\n\nclass BasePermutation:\n    \"\"\"Base class for tensors permutaiton.\"\"\"\n\n    def __call__(self, params, feature_maps, size):\n        \"\"\"\n        Performs permutation of weight tensors along given dimension.\n\n        Parameters\n        ----------\n        params: List[Dict[str, obj]].\n            List of dicts with keys 'value', 'dim', 'name'.\n            Value is a parameter tensor.\n        feature_maps: List[Dict[str, obj]].\n            List of dicts with keys 'value', 'dim', 'name'.\n            Value is a feature map tensor.\n        size: int.\n            Size of tensor dimension along which permutation should be performed.\n        \"\"\"\n        permutation = self.find_permutation(params, feature_maps, size)\n\n        for t in params:\n            dim = t[\"dim\"]\n            tensor = t[\"value\"]\n\n            if \"start_index\" not in t:\n                start = 0\n            else:\n                start = t[\"start_index\"]\n\n            permuted = torch.index_select(tensor, dim, permutation + start)\n            tensor.data = torch.slice_scatter(\n                tensor, permuted, dim, start, start + size\n            )\n\n    def find_permutation(self, params, feature_maps, size):\n        \"\"\"Method should return list of indices.\"\"\"\n        raise NotImplementedError(\"Implement this method in derived class.\")", "\n\nclass RandomPermutation(BasePermutation):\n    def find_permutation(self, params, feature_maps, size):\n        \"\"\"Returns random permutation of given size.\"\"\"\n        return torch.randperm(size, device=params[0][\"value\"].device)\n\n\nclass NOptPermutation(BasePermutation):\n    \"\"\"\n    Class for total variation optimization using py2opt algorithm.\n\n    Parameters\n    ----------\n    iters: int.\n    threshold: float.\n    verbose: bool.\n    \"\"\"\n\n    def __init__(self, iters=100, threshold=0.001, verbose=True):\n        super(NOptPermutation, self).__init__()\n        self.iters = iters\n        self.verbose = verbose\n        self.threshold = threshold\n\n    def find_permutation(self, params, feature_maps, size):\n        \"\"\"Uses py2opt algorithm to find permutation of given tensors.\"\"\"\n        optimize_tensors = self._select_tensors(params, feature_maps)\n        indices = two_opt_find_permutation(\n            optimize_tensors, size, self.iters, self.threshold\n        )\n        device = params[0][\"value\"].device\n        indices = indices.type(torch.long).to(device)\n\n        return indices\n\n    def _select_tensors(self, params, feature_maps):\n        \"\"\"Returns list of tensors which total variation should be optimized.\"\"\"\n        return params", "class NOptPermutation(BasePermutation):\n    \"\"\"\n    Class for total variation optimization using py2opt algorithm.\n\n    Parameters\n    ----------\n    iters: int.\n    threshold: float.\n    verbose: bool.\n    \"\"\"\n\n    def __init__(self, iters=100, threshold=0.001, verbose=True):\n        super(NOptPermutation, self).__init__()\n        self.iters = iters\n        self.verbose = verbose\n        self.threshold = threshold\n\n    def find_permutation(self, params, feature_maps, size):\n        \"\"\"Uses py2opt algorithm to find permutation of given tensors.\"\"\"\n        optimize_tensors = self._select_tensors(params, feature_maps)\n        indices = two_opt_find_permutation(\n            optimize_tensors, size, self.iters, self.threshold\n        )\n        device = params[0][\"value\"].device\n        indices = indices.type(torch.long).to(device)\n\n        return indices\n\n    def _select_tensors(self, params, feature_maps):\n        \"\"\"Returns list of tensors which total variation should be optimized.\"\"\"\n        return params", "\n\nclass NOptOutFiltersPermutation(NOptPermutation):\n    \"\"\"\n    Class implements NOptPermutation\n    interface for optimzation of out filters total variation.\n    \"\"\"\n\n    def __init__(self, iters=100, verbose=True):\n        super(NOptOutFiltersPermutation, self).__init__(iters, verbose)\n\n    def _select_tensors(self, params, feature_maps):\n        tensors = [t for t in params if \"bias\" not in t[\"name\"] and t[\"dim\"] == 0]\n\n        if len(tensors) == 0:\n            tensors = params\n\n        return tensors", "\n\nclass NOoptFeatureMapPermutation(NOptPermutation):\n    \"\"\"\n    Class implements NOptPermutation interface\n    for optimzation of feature maps total variation.\n    \"\"\"\n\n    def _select_tensors(self, params, feature_maps):\n        \"\"\" \"\"\"\n        out = []\n\n        for f in feature_maps:\n            if f[\"operation\"] == \"conv_linear\":\n                out.append(f)\n\n        if len(out) == 0:\n            out = feature_maps\n\n        return out", ""]}
{"filename": "torch_integral/__init__.py", "chunked_list": ["from .model import IntegralWrapper\nfrom .model import IntegralModel\nfrom .graph import IntegralTracer\nfrom .grid import UniformDistribution\nfrom .grid import NormalDistribution\nfrom .grid import TrainableGrid1D\nfrom .grid import RandomLinspace\nfrom .utils import grid_tuning\nfrom .utils import standard_continuous_dims\n", "from .utils import standard_continuous_dims\n"]}
{"filename": "torch_integral/utils.py", "chunked_list": ["import torch\nfrom typing import Tuple, Dict, Any, List\nimport torch.fx as fx\nimport copy\nimport torch.nn as nn\nfrom collections import OrderedDict\nfrom .grid import TrainableGrid1D\nfrom contextlib import contextmanager\nfrom torch.nn.utils import parametrize\n", "from torch.nn.utils import parametrize\n\n\ndef get_attr_by_name(module, name):\n    \"\"\" \"\"\"\n    for s in name.split(\".\"):\n        module = getattr(module, s)\n\n    return module\n", "\n\ndef get_parent_name(qualname: str) -> Tuple[str, str]:\n    \"\"\"\n    Splits a ``qualname`` into parent path and last atom.\n    For example, `foo.bar.baz` -> (`foo.bar`, `baz`)\n    \"\"\"\n    *parent, name = qualname.rsplit(\".\", 1)\n    return parent[0] if parent else \"\", name\n", "\n\ndef get_parent_module(module, attr_path):\n    \"\"\"\n    Returns parent module of module.attr_path.\n\n    Parameters\n    ----------\n    module: torch.nn.Module.\n    attr_path: str.\n    \"\"\"\n    parent_name, attr_name = get_parent_name(attr_path)\n\n    if parent_name != \"\":\n        parent = get_attr_by_name(module, parent_name)\n    else:\n        parent = module\n\n    return parent", "\n\ndef remove_all_hooks(model: torch.nn.Module) -> None:\n    \"\"\" \"\"\"\n    for name, child in model._modules.items():\n        if child is not None:\n            if hasattr(child, \"_forward_hooks\"):\n                child._forward_hooks = OrderedDict()\n            remove_all_hooks(child)\n", "\n\ndef fuse_batchnorm(model, convs):\n    \"\"\"\n    Fuse conv and bn only if conv is in convs argument.\n\n    Parameters\n    ----------\n    model: torch.nn.Module.\n    convs: List[torch.nn.ConvNd].\n    \"\"\"\n    fx_model: fx.GraphModule = fx.symbolic_trace(model)\n    modules = dict(fx_model.named_modules())\n\n    for node in fx_model.graph.nodes:\n        if node.op != \"call_module\":\n            continue\n        if (\n            type(modules[node.target]) is nn.BatchNorm2d\n            and type(modules[node.args[0].target]) is nn.Conv2d\n        ):\n            if node.args[0].target in convs:\n                if len(node.args[0].users) > 1:\n                    continue\n                conv = modules[node.args[0].target]\n                bn = modules[node.target]\n                inplace_conv_bn_fusion(conv, bn)\n                parent_name, attr_name = get_parent_name(node.target)\n                parent = get_parent_module(model, node.target)\n                setattr(parent, attr_name, torch.nn.Identity())", "\n\ndef inplace_conv_bn_fusion(conv, bn):\n    \"\"\" \"\"\"\n    assert not (conv.training or bn.training), \"Fusion only for eval!\"\n    conv.weight.data, bias = fuse_conv_bn_weights(\n        conv.weight,\n        conv.bias,\n        bn.running_mean,\n        bn.running_var,\n        bn.eps,\n        bn.weight,\n        bn.bias,\n    )\n\n    if conv.bias is None:\n        conv.bias = torch.nn.Parameter(bias).to(conv.weight.device)\n    else:\n        conv.bias.data = bias", "\n\ndef fuse_conv_bn_weights(conv_w, conv_b, bn_rm, bn_rv, bn_eps, bn_w, bn_b):\n    \"\"\" \"\"\"\n    if conv_b is None:\n        conv_b = torch.zeros_like(bn_rm)\n    if bn_w is None:\n        bn_w = torch.ones_like(bn_rm)\n    if bn_b is None:\n        bn_b = torch.zeros_like(bn_rm)\n    bn_var_rsqrt = torch.rsqrt(bn_rv + bn_eps)\n\n    conv_w = conv_w * (bn_w * bn_var_rsqrt).reshape(\n        [-1] + [1] * (len(conv_w.shape) - 1)\n    )\n    conv_b = (conv_b - bn_rm) * bn_var_rsqrt * bn_w + bn_b\n\n    return conv_w, conv_b", "\n\ndef reset_batchnorm(model):\n    \"\"\"\n    Set new BatchNorm2d in place of fused batch norm layers.\n\n    Parameters\n    ----------\n    model: torch.nn.Module.\n    \"\"\"\n    fx_model = torch.fx.symbolic_trace(model)\n    modules = dict(model.named_modules())\n\n    for node in fx_model.graph.nodes:\n        if node.op != \"call_module\":\n            continue\n\n        if type(modules[node.target]) is nn.Identity:\n            conv = modules[node.args[0].target]\n            size = conv.weight.shape[0]\n            bn = nn.BatchNorm2d(size)\n            _, attr_name = get_parent_name(node.target)\n            parent = get_parent_module(model, node.target)\n            setattr(parent, attr_name, bn)", "\n\ndef standard_continuous_dims(model):\n    \"\"\"\n    Returns dict containing names of all Conv2d and Linear layer's parameters as keys\n    and [0, 1] / [0] as values for weight / bias.\n\n    Parameters\n    ----------\n    model: torch.nn.Module.\n\n    Returns\n    -------\n    Dict[str, List[int]].\n    \"\"\"\n    continuous_dims = {}\n\n    for name, param in model.named_parameters():\n        parent_name, attr_name = get_parent_name(name)\n        parent = get_parent_module(model, name)\n\n        if isinstance(parent, (torch.nn.Linear, torch.nn.Conv2d)):\n            if \"weight\" in attr_name:\n                continuous_dims[name] = [0, 1]\n\n            elif \"bias\" in name:\n                continuous_dims[name] = [0]\n\n    return continuous_dims", "\n\n@contextmanager\ndef grid_tuning(integral_model, train_bn=False, train_bias=False, use_all_grids=False):\n    \"\"\"\n    Context manager sets requires_grad=True only for TrainableGrid parameters\n    and batch norm and bias parameters if corresponding flag is set True.\n\n    Parameters\n    ----------\n    train_bn: bool.\n    train_bias: bool.\n    use_all_grids: bool.\n    \"\"\"\n    integral_model.grid_tuning(train_bn, train_bias, use_all_grids)\n\n    try:\n        yield None\n\n    finally:\n        for name, param in integral_model.named_parameters():\n            parent = get_parent_module(integral_model, name)\n\n            if isinstance(parent, TrainableGrid1D):\n                param.requires_grad = False\n            else:\n                param.requires_grad = True", ""]}
{"filename": "torch_integral/grid.py", "chunked_list": ["import torch\nimport random\nfrom scipy.special import roots_legendre\n\n\nclass Distribution:\n    \"\"\"\n    Base class for grid size distribution.\n\n    Attributes\n    ----------\n    min_val: int.\n        Minimal possible random value.\n    max_val: int.\n        Maximal possible random value.\n    \"\"\"\n\n    def __init__(self, min_val, max_val):\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def sample(self):\n        \"\"\"Samples random integer number from distribution.\"\"\"\n        raise NotImplementedError(\"Implement this method in derived class.\")", "\n\nclass UniformDistribution(Distribution):\n    def __init__(self, min_val, max_val):\n        super().__init__(min_val, max_val)\n\n    def sample(self):\n        return random.randint(self.min_val, self.max_val)\n\n\nclass NormalDistribution(Distribution):\n    def __init__(self, min_val, max_val):\n        super(NormalDistribution, self).__init__(min_val, max_val)\n\n    def sample(self):\n        out = random.normalvariate(0, 0.5 * (self.max_val - self.min_val))\n        out = self.max_val - int(abs(out))\n\n        if out < self.min_val:\n            out = random.randint(self.min_val, self.max_val)\n\n        return out", "\n\nclass NormalDistribution(Distribution):\n    def __init__(self, min_val, max_val):\n        super(NormalDistribution, self).__init__(min_val, max_val)\n\n    def sample(self):\n        out = random.normalvariate(0, 0.5 * (self.max_val - self.min_val))\n        out = self.max_val - int(abs(out))\n\n        if out < self.min_val:\n            out = random.randint(self.min_val, self.max_val)\n\n        return out", "\n\nclass IGrid(torch.nn.Module):\n    \"\"\"Base Grid class.\"\"\"\n\n    def __init__(self):\n        super(IGrid, self).__init__()\n        self.curr_grid = None\n        self.eval_size = None\n\n    def forward(self):\n        \"\"\"\n        Performs forward pass. Generates new grid if\n        last generated grid is not saved, else returns saved one.\n\n        Returns\n        -------\n        torch.Tensor.\n            Generated grid points.\n        \"\"\"\n        if self.curr_grid is None:\n            out = self.generate_grid()\n        else:\n            out = self.curr_grid\n\n        return out\n\n    def ndim(self):\n        \"\"\"Returns dimensionality of grid object.\"\"\"\n        return 1\n\n    def size(self):\n        return self.eval_size\n\n    def generate_grid(self):\n        \"\"\"Samples new grid points.\"\"\"\n        raise NotImplementedError(\"Implement this method in derived class.\")", "\n\nclass ConstantGrid1D(IGrid):\n    \"\"\"\n    Class implements IGrid interface for fixed grid.\n\n    Parameters\n    ----------\n    init_value: torch.Tensor.\n    \"\"\"\n\n    def __init__(self, init_value):\n        super(ConstantGrid1D, self).__init__()\n        self.curr_grid = init_value\n\n    def generate_grid(self):\n        return self.curr_grid", "\n\nclass TrainableGrid1D(IGrid):\n    \"\"\"Grid with TrainablePartition.\n\n    Parameters\n    ----------\n    size: int.\n    init_value: torch.Tensor.\n    \"\"\"\n\n    def __init__(self, size, init_value=None):\n        super(TrainableGrid1D, self).__init__()\n        self.eval_size = size\n        self.curr_grid = torch.nn.Parameter(torch.linspace(-1, 1, size))\n        if init_value is not None:\n            assert size == init_value.shape[0]\n            self.curr_grid.data = init_value\n\n    def generate_grid(self):\n        return self.curr_grid", "\n\nclass RandomLinspace(IGrid):\n    \"\"\"\n    Grid which generates random sized tensor each time,\n    when generate_grid method is called.\n    Size of tensor is sampled from ``size_distribution``.\n\n    Parameters\n    ----------\n    size_distribution: Distribution.\n    noise_std: float.\n    \"\"\"\n\n    def __init__(self, size_distribution, noise_std=0):\n        super(RandomLinspace, self).__init__()\n        self.distribution = size_distribution\n        self.eval_size = size_distribution.max_val\n        self.noise_std = noise_std\n        self.generate_grid()\n\n    def generate_grid(self):\n        if self.training:\n            size = self.distribution.sample()\n        else:\n            size = self.eval_size\n\n        self.curr_grid = torch.linspace(-1, 1, size)\n\n        if self.noise_std > 0:\n            noise = torch.normal(torch.zeros(size), self.noise_std * torch.ones(size))\n            self.curr_grid = self.curr_grid + noise\n\n        return self.curr_grid\n\n    def resize(self, new_size):\n        \"\"\"Set new value for evaluation size.\"\"\"\n        self.eval_size = new_size\n        self.generate_grid()", "\n\nclass RandomLegendreGrid(RandomLinspace):\n    def __init__(self, size_distribution):\n        super(RandomLinspace, self).__init__()\n        self.distribution = size_distribution\n        self.eval_size = size_distribution.max_val\n        self.generate_grid()\n\n    def generate_grid(self):\n        if self.training:\n            size = self.distribution.sample()\n        else:\n            size = self.eval_size\n\n        self.curr_grid, _ = roots_legendre(size)\n        self.curr_grid = torch.tensor(self.curr_grid, dtype=torch.float32)\n\n        return self.curr_grid", "\n\nclass CompositeGrid1D(IGrid):\n    \"\"\"Grid which consist of concatenated IGrid objects.\"\"\"\n\n    def __init__(self, grids):\n        super(CompositeGrid1D, self).__init__()\n        self.grids = torch.nn.ModuleList(grids)\n        size = self.size()\n        self.proportions = [(grid.size() - 1) / (size - 1) for grid in grids]\n        self.generate_grid()\n\n    def reset_grid(self, index, new_grid):\n        self.grids[index] = new_grid\n        self.generate_grid()\n\n    def generate_grid(self):\n        g_list = []\n        start = 0.0\n        h = 1 / (self.size() - 1)\n        device = None\n\n        for i, grid in enumerate(self.grids):\n            g = grid.generate_grid()\n            device = g.device if device is None else device\n            g = (g + 1.0) / 2.0\n            g = start + g * self.proportions[i]\n            g_list.append(g.to(device))\n            start += self.proportions[i] + h\n\n        self.curr_grid = 2.0 * torch.cat(g_list) - 1.0\n\n        return self.curr_grid\n\n    def size(self):\n        return sum([g.size() for g in self.grids])", "\n\nclass GridND(IGrid):\n    \"\"\"N-dimensional grid, each dimension of which is an object of type IGrid.\"\"\"\n\n    def __init__(self, grid_objects):\n        super(GridND, self).__init__()\n        self.grid_objects = torch.nn.ModuleList(grid_objects)\n\n        self.generate_grid()\n\n    def ndim(self):\n        \"\"\"Returns dimensionality of grid object.\"\"\"\n        return sum([grid.ndim() for grid in self.grid_objects])\n\n    def reset_grid(self, dim, new_grid):\n        \"\"\"Replaces grid at given index.\"\"\"\n        self.grid_objects[dim] = new_grid\n        self.generate_grid()\n\n    def generate_grid(self):\n        self.curr_grid = [grid.generate_grid() for grid in self.grid_objects]\n\n        return self.curr_grid\n\n    def forward(self):\n        self.curr_grid = [grid() for grid in self.grid_objects]\n\n        return self.curr_grid\n\n    def __iter__(self):\n        return iter(self.grid_objects)", ""]}
{"filename": "torch_integral/quadrature.py", "chunked_list": ["import torch\nfrom scipy.special import roots_legendre\n\n\nclass BaseIntegrationQuadrature(torch.nn.Module):\n    \"\"\"\n    Base quadrature class.\n\n    Parameters\n    ----------\n    integration_dims: List[int].\n        Numbers of dimensions along which we multiply by the quadrature weights\n    grid_indices: List[int].\n        Indices of corresponding grids.\n\n    Attributes\n    ----------\n    integration_dims: List[int].\n    grid_indices: List[int].\n    \"\"\"\n\n    def __init__(self, integration_dims, grid_indices=None):\n        super().__init__()\n        self.integration_dims = integration_dims\n\n        if grid_indices is None:\n            self.grid_indices = integration_dims\n        else:\n            self.grid_indices = grid_indices\n            assert len(grid_indices) == len(integration_dims)\n\n    def multiply_coefficients(self, discretization, grid):\n        \"\"\"\n        Multiply discretization tensor by quadrature weights along integration_dims.\n\n        Parameters\n        ----------\n        discretization: torch.Tensor.\n            Tensor to be multiplied by quadrature weights.\n        grid: List[torch.Tensor].\n            List of tensors with sampling points.\n\n        Returns\n        -------\n        torch.Tensor.\n            ``discretization`` multiplied by quadrature weights.\n        \"\"\"\n        raise NotImplementedError(\"Implement this method in derived class.\")\n\n    def forward(self, function, grid):\n        \"\"\"\n        Performs forward pass of the Module.\n\n        Parameters\n        ----------\n        function: callable or torch.Tensor.\n            Function to be integrated.\n        grid: List[torch.Tensor].\n            List of tensors with sampling points.\n\n        Returns\n        -------\n        torch.Tensor.\n            ``function`` discretized and multiplied by quadrature weights.\n        \"\"\"\n        if callable(function):\n            out = function(grid)\n        else:\n            out = function\n\n        out = self.multiply_coefficients(out, grid)\n\n        return out", "\n\nclass TrapezoidalQuadrature(BaseIntegrationQuadrature):\n    \"\"\"Class for integration with trapezoidal rule.\"\"\"\n\n    def multiply_coefficients(self, discretization, grid):\n        \"\"\" \"\"\"\n        for i in range(len(self.integration_dims)):\n            grid_i = self.grid_indices[i]\n            dim = self.integration_dims[i]\n            x = grid[grid_i].to(discretization.device)\n            h = torch.zeros_like(x)\n            h[1:-1] = x[2:] - x[:-2]\n            h[0] = x[1] - x[0]\n            h[-1] = x[-1] - x[-2]\n            size = [1] * discretization.ndim\n            size[dim] = h.size(0)\n            h = h.view(size)\n            discretization = discretization * (h * 0.5)\n\n        return discretization", "\n\nclass RiemannQuadrature(BaseIntegrationQuadrature):\n    \"\"\"Rectangular integration rule.\"\"\"\n\n    def multiply_coefficients(self, discretization, grid):\n        \"\"\" \"\"\"\n        for i in range(len(self.integration_dims)):\n            grid_i = self.grid_indices[i]\n            dim = self.integration_dims[i]\n            x = grid[grid_i].to(discretization.device)\n            h = x[1:] - x[:-1]\n            h = torch.cat([0.5 * h[0], 0.5 * (h[:-1] + h[1:]), 0.5 * h[-1]])\n            size = [1] * discretization.ndim\n            size[dim] = h.size(0)\n            h = h.view(size)\n            discretization = discretization * h\n\n        return discretization", "\n\nclass SimpsonQuadrature(BaseIntegrationQuadrature):\n    \"\"\"\n    Integratioin of the function in propositioin\n    that function is quadratic between sampling points.\n    \"\"\"\n\n    def multiply_coefficients(self, discretization, grid):\n        \"\"\" \"\"\"\n        for i in range(len(self.integration_dims)):\n            grid_i = self.grid_indices[i]\n            dim = self.integration_dims[i]\n            x = grid[grid_i].to(discretization.device)\n            # assert x.shape[0] % 2 == 1\n            step = x[1] - x[0]\n            h = torch.ones_like(x)\n            h[1::2] *= 4.0\n            h[2:-1:2] *= 2.0\n            h *= step / 3.0\n            size = [1] * discretization.ndim\n            size[dim] = h.size(0)\n            h = h.view(size)\n            discretization = discretization * h\n\n        return discretization", "\n\nclass LegendreQuadrature(BaseIntegrationQuadrature):\n    \"\"\" \"\"\"\n\n    def multiply_coefficients(self, discretization, grid):\n        \"\"\" \"\"\"\n        for i in range(len(self.integration_dims)):\n            grid_i = self.grid_indices[i]\n            dim = self.integration_dims[i]\n            x = grid[grid_i].to(discretization.device)\n            _, weights = roots_legendre(x.shape[0])\n            h = torch.tensor(weights, dtype=torch.float32, device=discretization.device)\n            size = [1] * discretization.ndim\n            size[dim] = h.size(0)\n            h = h.view(size)\n            discretization = discretization * h\n\n        return discretization", "\n\ndef integrate(quadrature, function, grid):\n    \"\"\"\n    Function to integrate function with given quadrature rule.\n\n    Parameters\n    ----------\n    quadrature: BaseIntegrationQuadrature or callable or str.\n        Quadrature rule.\n    function: callable or torch.Tensor.\n        Function to be integrated.\n    grid: List[torch.Tensor].\n        List of tensors with sampling points.\n\n    Returns\n    -------\n    torch.Tensor.\n        Integral of ``function``.\n    \"\"\"\n    if callable(quadrature):\n        discretization = quadrature(function, grid)\n    elif type(quadrature) == str:\n        pass\n\n    out = torch.sum(discretization, quadrature.integration_dims)\n\n    return out", ""]}
{"filename": "torch_integral/graph/integral_group.py", "chunked_list": ["import torch\nfrom ..grid import RandomLinspace, UniformDistribution, CompositeGrid1D\n\n\nclass IntegralGroup(torch.nn.Module):\n    \"\"\"\n    Class for grouping tensors and parameters.\n    Group is a collection of paris of tensor and it's dimension.\n    Two parameter tensors are considered to be in the same group\n    if they should have the same integration grid.\n    Group can contain subgroups. This means that parent group's grid is a con\n    catenation of subgroups grids.\n\n    Parameters\n    ----------\n    size: int.\n        Each tensor in the group should have the same size along certain dimension.\n    \"\"\"\n\n    def __init__(self, size):\n        super(IntegralGroup, self).__init__()\n        self.size = size\n        self.subgroups = None\n        self.parents = []\n        self.grid = None\n        self.params = []\n        self.tensors = []\n        self.operations = []\n\n    def append_param(self, name, value, dim, operation=None):\n        \"\"\"\n        Adds parameter tensor to the group.\n\n        Parameters\n        ----------\n        name: str.\n        value: torch.Tensor.\n        dim: int.\n        operation: str.\n        \"\"\"\n        self.params.append(\n            {\"value\": value, \"name\": name, \"dim\": dim, \"operation\": operation}\n        )\n\n    def append_tensor(self, value, dim, operation=None):\n        \"\"\"\n        Adds tensor to the group.\n\n        Parameters\n        ----------\n        value: torch.Tensor.\n        dim: int.\n        operation: str.\n        \"\"\"\n        self.tensors.append({\"value\": value, \"dim\": dim, \"operation\": operation})\n\n    def clear_params(self):\n        self.params = []\n\n    def clear_tensors(self):\n        self.tensors = []\n\n    def set_subgroups(self, groups):\n        self.subgroups = groups\n\n        for subgroup in self.subgroups:\n            subgroup.parents.append(self)\n\n    def build_operations_set(self):\n        \"\"\"Builds set of operations in the group.\"\"\"\n        self.operations = set([t[\"operation\"] for t in self.tensors])\n\n    @staticmethod\n    def append_to_groups(tensor, operation=None, attr_name=\"grids\"):\n        if hasattr(tensor, attr_name):\n            for i, g in enumerate(getattr(tensor, attr_name)):\n                if g is not None:\n                    g.append_tensor(tensor, i, operation)\n\n    def grid_size(self):\n        \"\"\"Returns size of the grid.\"\"\"\n        return self.grid.size()\n\n    def clear(self, new_grid=None):\n        \"\"\"Resets grid and removes cached values.\"\"\"\n        for param_dict in self.params:\n            function = param_dict[\"function\"]\n            dim = list(function.grid).index(self.grid)\n            grid = new_grid if new_grid is not None else self.grid\n            function.grid.reset_grid(dim, grid)\n            function.clear()\n\n    def initialize_grids(self):\n        \"\"\"Sets default RandomLinspace grid.\"\"\"\n        if self.grid is None:\n            if self.subgroups is not None:\n                for subgroup in self.subgroups:\n                    if subgroup.grid is None:\n                        subgroup.initialize_grids()\n\n                self.grid = CompositeGrid1D([sub.grid for sub in self.subgroups])\n            else:\n                distrib = UniformDistribution(self.size, self.size)\n                self.grid = RandomLinspace(distrib)\n\n        for parent in self.parents:\n            if parent.grid is None:\n                parent.initialize_grids()\n\n    def reset_grid(self, new_grid):\n        \"\"\"\n        Set new integration grid for the group.\n\n        Parameters\n        ----------\n        new_grid: IntegralGrid.\n        \"\"\"\n        self.clear(new_grid)\n\n        for parent in self.parents:\n            parent.reset_child_grid(self, new_grid)\n\n        self.grid = new_grid\n\n    def reset_child_grid(self, child, new_grid):\n        \"\"\"Sets new integration grid for given child of the group.\"\"\"\n        i = self.subgroups.index(child)\n        self.grid.reset_grid(i, new_grid)\n        self.clear()\n\n    def resize(self, new_size):\n        \"\"\"If grid supports resizing, resizes it.\"\"\"\n        if hasattr(self.grid, \"resize\"):\n            self.grid.resize(new_size)\n\n        self.clear()\n\n        for parent in self.parents:\n            parent.clear()\n\n    def reset_distribution(self, distribution):\n        \"\"\"Sets new distribution for the group.\"\"\"\n        if hasattr(self.grid, \"distribution\"):\n            self.grid.distribution = distribution\n\n    def __str__(self):\n        result = \"\"\n\n        for p in self.params:\n            result += p[\"name\"] + \": \" + str(p[\"dim\"]) + \"\\n\"\n\n        return result\n\n    def count_parameters(self):\n        ans = 0\n\n        for p in self.params:\n            ans += p[\"value\"].numel()\n\n        return ans", "\n\ndef merge_groups(x, x_dim, y, y_dim):\n    \"\"\"Merges two groups of tensors ``x`` and `yy`` with indices ``x_dim`` and ``y_dim``.\"\"\"\n    if type(x) in (int, float):\n        x = torch.tensor(x)\n    if type(y) in (int, float):\n        y = torch.tensor(y)\n    if not hasattr(x, \"grids\"):\n        x.grids = [None for _ in range(x.ndim)]\n    if not hasattr(y, \"grids\"):\n        y.grids = [None for _ in range(y.ndim)]\n    if y.grids[y_dim] is not None:\n        x, x_dim, y, y_dim = y, y_dim, x, x_dim\n\n    if x.grids[x_dim] is not None:\n        if y.grids[y_dim] is not None:\n            if len(y.grids[y_dim].parents) > 0:\n                x, x_dim, y, y_dim = y, y_dim, x, x_dim\n\n            if y.grids[y_dim].subgroups is not None:\n                x, x_dim, y, y_dim = y, y_dim, x, x_dim\n\n            if x.grids[x_dim] is not y.grids[y_dim]:\n                for param in y.grids[y_dim].params:\n                    dim = param[\"dim\"]\n                    t = param[\"value\"]\n\n                    if t is not y:\n                        t.grids[dim] = x.grids[x_dim]\n\n                x.grids[x_dim].params.extend(y.grids[y_dim].params)\n                y.grids[y_dim].clear_params()\n\n                for tensor in y.grids[y_dim].tensors:\n                    dim = tensor[\"dim\"]\n                    t = tensor[\"value\"]\n\n                    if t is not y:\n                        t.grids[dim] = x.grids[x_dim]\n\n                x.grids[x_dim].tensors.extend(y.grids[y_dim].tensors)\n                y.grids[y_dim].clear_tensors()\n\n        y.grids[y_dim] = x.grids[x_dim]", ""]}
{"filename": "torch_integral/graph/operations.py", "chunked_list": ["import operator\nimport torch\nfrom .integral_group import IntegralGroup\nfrom .integral_group import merge_groups\nfrom ..utils import get_attr_by_name\n\n\ndef transpose(inp, dim0, dim1):\n    out = torch.transpose(inp, dim0, dim1)\n\n    if hasattr(inp, \"grids\"):\n        out.grids = list(inp.grids)\n        out.grids[dim0], out.grids[dim1] = out.grids[dim1], out.grids[dim0]\n\n    IntegralGroup.append_to_groups(out, \"transpose\")\n\n    return out", "\n\ndef permute(inp, dims):\n    out = torch.permute(inp, dims)\n\n    if hasattr(inp, \"grids\"):\n        out.grids = [None] * inp.ndim\n\n        for i in range(len(dims)):\n            out.grids[i] = inp.grids[dims[i]]\n\n    IntegralGroup.append_to_groups(out, \"permute\")\n\n    return out", "\n\ndef getitem(inp, slices):\n    out = operator.getitem(inp, slices)\n    out.grids = [None] * out.ndim\n\n    if hasattr(inp, \"grids\"):\n        j = 0\n\n        for i in range(inp.ndim):\n            if i < len(slices):  # ADD Ellipsis\n                if slices[i] == slice(None):\n                    out.grids[j] = inp.grids[i]\n                    j += 1\n\n    IntegralGroup.append_to_groups(out, \"getitem\")\n\n    return out", "\n\ndef neutral_hook(module, input, output):\n    if hasattr(input[0], \"grids\"):\n        output.grids = input[0].grids\n        IntegralGroup.append_to_groups(output, \"neutral\")\n\n\ndef neutral_decorator(call_func):\n    def wrapper(*args, **kwargs):\n        out = call_func(*args, **kwargs)\n\n        if hasattr(args[0], \"grids\"):\n            out.grids = args[0].grids\n            IntegralGroup.append_to_groups(out, \"neutral\")\n\n        return out\n\n    return wrapper", "def neutral_decorator(call_func):\n    def wrapper(*args, **kwargs):\n        out = call_func(*args, **kwargs)\n\n        if hasattr(args[0], \"grids\"):\n            out.grids = args[0].grids\n            IntegralGroup.append_to_groups(out, \"neutral\")\n\n        return out\n\n    return wrapper", "\n\ndef conv_linear_decorator(function):\n    def conv_linear(*args):\n        x, weight, bias = args[:3]\n        out = function(*args)\n\n        if bias is not None:\n            merge_groups(bias, 0, weight, 0)\n\n        merge_groups(weight, 1, x, 1)\n        merge_groups(out, 1, weight, 0)\n        IntegralGroup.append_to_groups(out, \"conv_linear\")\n\n        return out\n\n    return conv_linear", "\n\ndef batch_norm(*args, **kwargs):\n    out = torch.nn.functional.batch_norm(*args, **kwargs)\n    inp = args[0]\n    weight = kwargs[\"weight\"]\n    bias = kwargs[\"bias\"]\n    merge_groups(inp, 1, weight, 0)\n    merge_groups(bias, 0, weight, 0)\n    merge_groups(out, 1, weight, 0)\n    IntegralGroup.append_to_groups(out, \"batch_norm\")\n\n    return out", "\n\ndef aggregation_decorator(func):\n    def wrapper(inp, *dims, **kwargs):\n        out = func(inp, *dims, **kwargs)\n\n        for d in range(out.ndim):\n            if d not in dims:\n                merge_groups(out, d, inp, d)\n\n        IntegralGroup.append_to_groups(out, \"aggregation\")\n\n        return out\n\n    return wrapper", "\n\ndef max_min_decorator(func):\n    def wrapper(inp, dim, **kwargs):\n        out = func(inp, dim, **kwargs)\n        values = out.values\n\n        for d in range(values.ndim):\n            if d != dim:\n                merge_groups(values, d, inp, d)\n\n        IntegralGroup.append_to_groups(values, \"min_max\")\n\n        return out\n\n    return wrapper", "\n\ndef view(*args, **kwargs):\n    inp = args[0]\n    out = inp.view(*args[1:])\n    out.grids = [None] * out.ndim\n\n    if hasattr(inp, \"grids\"):\n        i = 1\n\n        for g in inp.grids:\n            if g is not None:\n                while out.shape[i] != g.size:\n                    i += 1\n\n                out.grids[i] = g\n                i += 1\n\n        IntegralGroup.append_to_groups(out)\n\n    return out", "\n\ndef reshape(*args, **kwargs):\n    inp = args[0]\n    out = inp.reshape(*args[1:])\n    out.grids = [None] * out.ndim\n\n    if hasattr(inp, \"grids\"):\n        i = 1\n\n        for g in inp.grids:\n            if g is not None:\n                while out.shape[i] != g.size:\n                    i += 1\n\n                out.grids[i] = g\n                i += 1\n\n        IntegralGroup.append_to_groups(out)\n\n    return out", "\n\ndef concatenate(inputs, dim):\n    out = torch.cat(inputs, dim)\n    out.grids = [None] * out.ndim\n\n    for d in range(out.ndim):\n        if d != dim:\n            for x in inputs[1:]:\n                merge_groups(inputs[0], d, x, d)\n\n            out.grids[d] = inputs[0].grids[d]\n\n        else:\n            out.grids[d] = IntegralGroup(out.shape[d])\n            out.grids[d].set_subgroups([x.grids[d] for x in inputs])\n\n    IntegralGroup.append_to_groups(out, \"concat\")\n\n    return out", "\n\ndef operators_decorator(operator):\n    def wrapper(x, y):\n        out = operator(x, y)\n\n        if type(x) in (int, float):\n            x = torch.tensor(x)\n\n        if type(y) in (int, float):\n            y = torch.tensor(y)\n\n        if y.ndim > x.ndim:\n            x, y = y, x\n\n        k = x.ndim - y.ndim\n\n        for dim in range(y.ndim):\n            if x.shape[k + dim] != 1 and y.shape[dim] != 1:\n                merge_groups(x, k + dim, y, dim)\n\n        out.grids = x.grids\n\n        for dim in range(out.ndim):\n            if out.grids[dim] is None:\n                if dim - k >= 0 and y.shape[dim - k] > 1:\n                    out.grids[dim] = y.grids[dim - k]\n\n            if out.shape[dim] == 1:\n                out.grids[dim] = None\n\n        IntegralGroup.append_to_groups(out, \"operator\")\n\n        return out\n\n    return wrapper", "\n\ndef matmul(x, y):\n    out = x @ y\n    out.grids = [None] * out.ndim\n\n    if y.ndim > x.ndim:\n        y, x = x, y\n\n    k = x.ndim - y.ndim\n    merge_groups(y, y.ndim - 2, x, x.ndim - 1)\n\n    for i in range(y.ndim - 2):\n        merge_groups(x, i + k, y, i)\n\n    for d in range(x.ndim - 1):\n        out.grids.append(x.grids[d])\n\n    out.grids.append(y.grids[y.ndim - 1])\n    IntegralGroup.append_to_groups(out, \"matmul\")\n\n    return out", "\n\ndef interpolate(*args, **kwargs):\n    out = torch.nn.functional.interpolate(*args, **kwargs)\n    out.grids = [None] * out.ndim\n\n    if hasattr(args[0], \"grids\"):\n        for d in range(out.ndim):\n            out.grids[d] = args[0].grids[d]\n\n    IntegralGroup.append_to_groups(out, \"interpolate\")\n\n    return out", "\n\n# def einsum(equation, *args):\n#     out = torch.einsum(equation, *args)\n#     inp_str, out_str = equation.split('->')\n#     tensors = inp_str.split(',')\n#\n#     return out\n", ""]}
{"filename": "torch_integral/graph/__init__.py", "chunked_list": ["from .trace import IntegralTracer\n"]}
{"filename": "torch_integral/graph/trace.py", "chunked_list": ["import torch\nfrom .operations import *\nfrom .integral_group import IntegralGroup\nfrom ..utils import remove_all_hooks\n\n\nclass SymbolicFxTracer(torch.fx.Tracer):\n    \"\"\"torch.fx.Tracer which leaf modules are batch norm layers.\"\"\"\n\n    def is_leaf_module(self, m, qualname):\n        return isinstance(\n            m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)\n        )", "\n\nclass IntegralTracer(torch.fx.Interpreter):\n    \"\"\"\n    Class for building dependency graph of the neural network.\n    Builds related groups of parameter tensors.\n    Related group is a set of pairs of tensor and dimensioin.\n    Two parameters belong to one related group\n    if they should have the same size along the corresponding dimension.\n\n    Parameters\n    ----------\n    model: torch.nn.Module.\n    continuous_dims: Dict[str, List[int]].\n        Dictionary which contains names of the model's parameters\n        and it's continuous dimension indices.\n    discrete_dims: Dict[str, List[int]].\n        Dictionary which contains names of the model's parameters\n        and dimensions that can not be continuous.\n        If there is the same element in discrete_dims and continuous_dims, then\n        the element will be removed from continuous_dims.\n    additional_operations: Dict[Union[str, Callable], Callable].\n        Dictionary which contains custom tracing operations for the graph.\n    additional_hooks: Dict[torch.nn.Module, Callable].\n        Dictionary which contains custom hooks for the graph.\n\n    Examples\n    --------\n    For example, if we have a model with two convolutional layers\n    and we want to make continuous only first convolutional layer's\n    output dimension then we can write:\n\n    .. code-block:: python\n\n        import torch\n        from torch_integral.graph import IntegralTracer\n        from torchvision.models import resnet18\n\n        model = resnet18(pretrained=True)\n        example_input = torch.randn(1, 3, 224, 224)\n        continuous_dims = {\n            \"layer4.0.conv1.weight\": [0],\n            \"layer4.0.conv1.bias\": [0],\n        }\n        IntegralTracer = IntegralTracer(model, example_input, continuous_dims)\n\n    Here  first dimension of the `layer4.0.conv1.weight`, `layer4.0.conv1.bias` and second dim\n    of the `conv_2.weight` are belong to the same IntegralGroup,\n    because it's sizes should be equal.\n    Note that it is not necessary to list all parameter names of the related group.\n    It is enough to list only one tensor of the group and all other tensors will be\n    added automatically. For example, in example above it was enough to write\n    `continuous_dims = {layer4.0.conv1.weight: [0]}`.\n    \"\"\"\n\n    def __init__(\n        self,\n        model,\n        continuous_dims,\n        discrete_dims=None,\n        additional_operations=None,\n        additional_hooks=None,\n    ):\n        graph = SymbolicFxTracer().trace(model.eval())\n        gm = torch.fx.GraphModule(model, graph)\n        super().__init__(gm, True)\n        self.model = model\n        self.groups = None\n        self.continuous_dims = continuous_dims\n\n        if discrete_dims is not None:\n            self.discrete_dims = discrete_dims\n        else:\n            self.discrete_dims = {}\n\n        self.default_operations = {\n            operator.add: operators_decorator(operator.add),\n            operator.sub: operators_decorator(operator.sub),\n            operator.mul: operators_decorator(operator.mul),\n            operator.getitem: getitem,\n            torch.permute: permute,\n            torch.transpose: transpose,\n            torch.matmul: matmul,\n            torch.nn.functional.interpolate: interpolate,\n            torch.mean: aggregation_decorator(torch.mean),\n            torch.sum: aggregation_decorator(torch.sum),\n            torch.max: max_min_decorator(torch.max),\n            torch.min: max_min_decorator(torch.min),\n            torch.cat: concatenate,\n            torch.conv1d: conv_linear_decorator(torch.conv1d),\n            torch.conv2d: conv_linear_decorator(torch.conv2d),\n            torch.conv3d: conv_linear_decorator(torch.conv3d),\n            torch._C._nn.linear: conv_linear_decorator(torch._C._nn.linear),\n            torch.nn.functional.batch_norm: batch_norm,\n            \"mean\": aggregation_decorator(torch.mean),\n            \"sum\": aggregation_decorator(torch.sum),\n            \"view\": view,\n            \"reshape\": reshape,\n            \"mul\": operators_decorator(operator.mul),\n            \"add\": operators_decorator(operator.add),\n        }\n        self.default_hooks = {\n            torch.nn.BatchNorm1d: neutral_hook,\n            torch.nn.BatchNorm2d: neutral_hook,\n            torch.nn.BatchNorm3d: neutral_hook,\n            torch.nn.Identity: neutral_hook,\n        }\n\n        if additional_operations is not None:\n            self.default_operations.update(additional_operations)\n\n        if additional_hooks is not None:\n            self.default_hooks.update(additional_hooks)\n\n    def build_groups(self, *args, initial_env=None, enable_io_processing=True):\n        \"\"\"\n        Builds dependency groups of the neural network.\n\n        Parameters\n        ----------\n        *args: List[torch.Tensor] or List[List[int]].\n            Input tensors of the model or shapes of input tensors.\n        initial_env: Dict[str, torch.Tensor].\n        enable_io_processing: bool.\n            If True, then input and output tensors will be processed.\n\n        Returns\n        -------\n        self.groups: List[IntegralGroup].\n            List of related parameters groups.\n        \"\"\"\n        self.groups = []\n        self.model.eval()\n\n        for name, param in self.model.named_parameters():\n            param.grids = [None] * param.ndim\n\n            if name in self.continuous_dims:\n                dims = self.continuous_dims[name]\n            else:\n                dims = list(range(param.ndim))\n\n            for dim in dims:\n                size = param.shape[dim]\n                group = IntegralGroup(size)\n                group.append_param(name, param, dim)\n                param.grids[dim] = group\n                self.groups.append(group)\n\n        device = next(iter(self.model.parameters())).device\n        args = list(args)\n\n        for i in range(len(args)):\n            if type(args[i]) == torch.Tensor:\n                args[i] = args[i].to(device)\n            else:\n                args[i] = torch.rand(args[i]).to(device)\n\n        output = self.run(*args, initial_env, enable_io_processing)\n        remove_all_hooks(self.model)\n        self.groups = [group for group in self.groups if len(group.params)]\n        delete_indices = []\n\n        for i, group in enumerate(self.groups):\n            delete_group = True\n\n            for p in group.params:\n                if (\n                    p[\"name\"] in self.continuous_dims\n                    and p[\"dim\"] in self.continuous_dims[p[\"name\"]]\n                ):\n                    delete_group = False\n\n                if (\n                    p[\"name\"] in self.discrete_dims\n                    and p[\"dim\"] in self.discrete_dims[p[\"name\"]]\n                ):\n                    for d in group.params:\n                        if (\n                            d[\"name\"] in self.continuous_dims\n                            and d[\"dim\"] in self.continuous_dims[d[\"name\"]]\n                        ):\n                            self.continuous_dims[d[\"name\"]].remove(d[\"dim\"])\n\n                            if len(self.continuous_dims[d[\"name\"]]) == 0:\n                                self.continuous_dims.pop(d[\"name\"])\n\n                    delete_group = True\n                    break\n\n            if delete_group:\n                delete_indices.append(i)\n            else:\n                for p in group.params:\n                    if p[\"name\"] in self.continuous_dims:\n                        dims = self.continuous_dims[p[\"name\"]]\n\n                        if p[\"dim\"] not in dims:\n                            dims.append(p[\"dim\"])\n                    else:\n                        self.continuous_dims[p[\"name\"]] = [p[\"dim\"]]\n\n        self.groups = [\n            group for i, group in enumerate(self.groups) if i not in delete_indices\n        ]\n\n        def add_parent_groups(group, parents):\n            for parent in group.parents:\n                if parent not in parents:\n                    parents.add(parent)\n                add_parent_groups(parent, parents)\n\n        parents = set()\n\n        for group in self.groups:\n            add_parent_groups(group, parents)\n            group.build_operations_set()\n\n        for parent in parents:\n            parent.build_operations_set()\n\n        self.groups.extend(list(parents))\n\n        return self.groups\n\n    def call_function(self, target, args, kwargs):\n        \"\"\"\n        Instead of usual call_function method,\n        this method calls decorated function to build dependency graph.\n\n        Parameters\n        ----------\n        target: Callable.\n            Function to call.\n        args: List[torch.Tensor].\n            Arguments of the function.\n        kwargs: Dict[str, torch.Tensor].\n            Keyword arguments of the function.\n\n        Returns\n        -------\n        result: torch.Tensor.\n            Result of the function.\n        \"\"\"\n        if target in self.default_operations:\n            return self.default_operations[target](*args, **kwargs)\n        else:\n            return neutral_decorator(target)(*args, **kwargs)\n\n    def call_method(self, target, args, kwargs):\n        \"\"\"\n        Instead of usual call_method method,\n        this method calls decorated function to build dependency graph.\n\n        Parameters\n        ----------\n        target: Callable.\n            Method to call.\n        args: List[torch.Tensor].\n            Arguments of the method.\n        kwargs: Dict[str, torch.Tensor].\n            Keyword arguments of the method.\n\n        Returns\n        -------\n        result: torch.Tensor.\n            Result of the method.\n        \"\"\"\n        if target in self.default_operations:\n            return self.default_operations[target](*args, **kwargs)\n        else:\n            return super().call_method(target, args, kwargs)\n\n    def call_module(self, target, args, kwargs):\n        \"\"\"\n        Registers tracing forward hooks before calling submodules.\n\n        Parameters\n        ----------\n        target: Callable.\n            Submodule to call.\n        args: List[torch.Tensor].\n            Arguments of the submodule.\n        kwargs: Dict[str, torch.Tensor].\n            Keyword arguments of the submodule.\n\n        Returns\n        -------\n        result: torch.Tensor.\n            Result of the submodule.\n        \"\"\"\n        submod = self.fetch_attr(target)\n\n        if type(submod) in self.default_hooks:\n            submod.register_forward_hook(self.default_hooks[type(submod)])\n\n        return submod(*args, **kwargs)", ""]}
{"filename": "torch_integral/tsp_solver/__init__.py", "chunked_list": ["from .solver import two_opt_find_permutation\n"]}
{"filename": "torch_integral/parametrizations/integral_weight.py", "chunked_list": ["import torch\n\n\nclass IntegralParameterization(torch.nn.Module):\n    \"\"\"\n    Class for weights parametrization. Can be registereg as parametrization\n    with torch.nn.utils.parametrize.register_parametrization\n\n    Parameters\n    ----------\n    weight_function: torch.nn.Module.\n    grid: torch_integral.grid.IGrid.\n    quadrature: torch_integral.quadrature.BaseIntegrationQuadrature.\n    \"\"\"\n\n    def __init__(self, weight_function, grid, quadrature):\n        super().__init__()\n        self.weight_function = weight_function\n        self.quadrature = quadrature\n        self.grid = grid\n        self.last_value = None\n        self.train_volume = 1.0\n\n    def sample_weights(self, w):\n        \"\"\"\n        Evaluate pparametrization function on grid.\n\n        Parameters\n        ----------\n        w: torch.Tensor.\n\n        Returns\n        -------\n        torch.Tensor.\n            Sampled weight function on grid.\n        \"\"\"\n        x = self.grid()\n        weight = self.weight_function(x)\n\n        if self.quadrature is not None:\n            weight = self.quadrature(weight, x) * self.train_volume\n\n        return weight\n\n    def reset_quadrature(self, quadrature):\n        \"\"\"Replaces quadrature object.\"\"\"\n        weight = self.sample_weights(None)\n        self.quadrature = quadrature\n        self.right_inverse(weight)\n\n    def clear(self):\n        self.last_value = None\n\n    def forward(self, w):\n        \"\"\"\n        Performs forward pass. Samples new weights on grid\n        if training or last sampled tensor is not cached.\n\n        Parameters\n        ----------\n        w: torch.Tensor.\n        \"\"\"\n        if self.training or self.last_value is None:\n            weight = self.sample_weights(w)\n\n            if self.training:\n                self.clear()\n            else:\n                self.last_value = weight\n\n        else:\n            weight = self.last_value\n\n        return weight.to(w.device)\n\n    def right_inverse(self, x):\n        \"\"\"Initialization method which is used when setattr of parametrized tensor called.\"\"\"\n        if hasattr(self.weight_function, \"init_values\"):\n            if self.quadrature is not None:\n                ones = torch.ones_like(x, device=x.device)\n                q_coeffs = self.quadrature.multiply_coefficients(ones, self.grid())\n                x = x / q_coeffs\n\n                for dim in self.quadrature.integration_dims:\n                    self.train_volume *= x.shape[dim] - 1\n\n                self.train_volume *= 0.5\n                x = x / self.train_volume\n\n            self.weight_function.init_values(x)\n\n        return x", "\n\nif __name__ == \"__main__\":\n    import torch\n    import sys\n\n    sys.path.append(\"../../\")\n    from interpolation_weights import InterpolationWeights1D\n    from interpolation_weights import InterpolationWeights2D\n    from torch_integral.grid import RandomUniformGrid1D\n    from torch_integral.grid import ConstantGrid1D\n    from torch_integral.grid import GridND\n    from torch_integral.grid import UniformDistribution\n    from torch.nn.utils import parametrize\n    from torch_integral.quadrature import TrapezoidalQuadrature\n    from torch_integral import IntegralWrapper\n\n    N = 64\n    func = InterpolationWeights2D([64, 64], [5, 5]).cuda()\n    conv = torch.nn.Conv2d(64, 64, 5).cuda()\n    target = conv.weight.data.clone()\n    grid = GridND(\n        {\n            # '0': ConstantGrid1D((torch.rand(64)*2-1).sort().values),\n            \"0\": RandomUniformGrid1D(UniformDistribution(64, 64)),\n            \"1\": RandomUniformGrid1D(UniformDistribution(64, 64)),\n        }\n    )\n    quadrature = TrapezoidalQuadrature([1])\n    param = IntegralParameterization(\n        func,\n        grid,\n        quadrature,\n    )\n    parametrize.register_parametrization(conv, \"weight\", param, unsafe=True)\n    wrapper = IntegralWrapper(optimize_iters=3000, start_lr=1e-2)\n    wrapper._optimize_parameters(conv, \"weight\", target, param.parameters())", ""]}
{"filename": "torch_integral/parametrizations/__init__.py", "chunked_list": ["from .interpolation_weights import InterpolationWeights1D\nfrom .interpolation_weights import InterpolationWeights2D\nfrom .integral_weight import IntegralParameterization\n"]}
{"filename": "torch_integral/parametrizations/interpolation_weights.py", "chunked_list": ["import torch\nfrom functools import reduce\nfrom torch.nn.functional import grid_sample, interpolate\n\n\nclass IWeights(torch.nn.Module):\n    \"\"\"\n    Base weight parametrization class.\n\n    Parameters\n    ----------\n    discrete_shape: List[int].\n        Sizes of parametrized tensor along discrete dimension.\n    \"\"\"\n\n    def __init__(self, discrete_shape):\n        super().__init__()\n        self._discrete_shape = discrete_shape\n\n    def init_values(self):\n        \"\"\" \"\"\"\n        raise NotImplementedError(\"Implement this method in derived class.\")\n\n    def forward(self, grid):\n        \"\"\"\n        Performs forward pass\n\n        Parameters\n        ----------\n        grid: List[torch.Tensor].\n            List of discretization grids along each dimension.\n        \"\"\"\n        raise NotImplementedError(\"Implement this method in derived class.\")", "\n\nclass InterpolationWeightsBase(IWeights):\n    \"\"\"\n    Base class for parametrization based on torch.nn.functional.grid_sample.\n\n    Parameters\n    ----------\n    cont_size: List[int].\n        Shape of trainable parameter along continuous dimensions.\n    discrete_shape: List[int].\n        Sizes of parametrized tensor along discrete dimension.\n    interpolate_mode: str.\n        Same modes as in torch.nn.functional.grid_sample.\n    padding_mode: str.\n    align_corners: bool.\n    \"\"\"\n\n    def __init__(\n        self,\n        cont_size,\n        discrete_shape=None,\n        interpolate_mode=\"bicubic\",\n        padding_mode=\"border\",\n        align_corners=True,\n    ):\n        super(InterpolationWeightsBase, self).__init__(discrete_shape)\n        self.iterpolate_mode = interpolate_mode\n        self.padding_mode = padding_mode\n        self.align_corners = align_corners\n\n        if discrete_shape is not None:\n            self.planes_num = int(reduce(lambda a, b: a * b, discrete_shape))\n        else:\n            self.planes_num = 1\n\n        self.values = torch.nn.Parameter(torch.rand(1, self.planes_num, *cont_size))\n\n    def _preprocess_grid(self, grid):\n        \"\"\" \"\"\"\n        device = self.values.device\n\n        for i in range(len(grid)):\n            grid[i] = grid[i].to(device)\n\n        if len(grid) == 1:\n            grid.append(torch.tensor(0.0, device=device))\n\n        grid = torch.stack(\n            torch.meshgrid(grid[::-1], indexing=\"ij\"),\n            dim=len(grid),\n        ).unsqueeze(0)\n\n        return grid\n\n    def _postprocess_output(self, out):\n        \"\"\" \"\"\"\n        raise NotImplementedError(\"Implement this method in derived class.\")\n\n    def forward(self, grid):\n        \"\"\"\n        Performs forward pass\n\n        Parameters\n        ----------\n        grid: List[torch.Tensor].\n            List of discretization grids along each dimension.\n\n        Returns\n        -------\n        torch.Tensor.\n            Sampled ``self.values`` on grid.\n\n        \"\"\"\n        grid = self._preprocess_grid(grid)\n        out = grid_sample(\n            self.values,\n            grid,\n            mode=self.iterpolate_mode,\n            padding_mode=self.padding_mode,\n            align_corners=self.align_corners,\n        )\n        return self._postprocess_output(out)", "\n\nclass InterpolationWeights1D(InterpolationWeightsBase):\n    \"\"\"\n    Class implementing InterpolationWeightsBase for parametrization\n    of tensor with one continuous dimension.\n\n    Parameters\n    ----------\n    cont_size: List[int].\n        Shape of trainable parameter along continuous dimensions.\n    discrete_shape: List[int].\n        Sizes of parametrized tensor along discrete dimension.\n    cont_dim: int.\n        Index of continuous dimension.\n    interpolate_mode: str.\n        See torch.nn.functional.grid_sample.\n    padding_mode: str.\n        See torch.nn.functional.grid_sample.\n    align_corners: bool.\n        See torch.nn.functional.grid_sample.\n    \"\"\"\n\n    def __init__(\n        self,\n        cont_size,\n        discrete_shape=None,\n        cont_dim=0,\n        interpolate_mode=\"bicubic\",\n        padding_mode=\"border\",\n        align_corners=True,\n    ):\n        super(InterpolationWeights1D, self).__init__(\n            [cont_size, 1],\n            discrete_shape,\n            interpolate_mode,\n            padding_mode,\n            align_corners,\n        )\n        self.cont_dim = cont_dim\n\n    def init_values(self, x):\n        \"\"\" \"\"\"\n        if x.ndim == 1:\n            x = x[None, None, :, None]\n        else:\n            permutation = [i for i in range(x.ndim) if i != self.cont_dim]\n            x = x.permute(*permutation, self.cont_dim)\n            x = x.reshape(1, -1, x.shape[-1], 1)\n\n        if x.shape[-2:] == self.values.shape[-2:]:\n            self.values.data = x\n        else:\n            self.values.data = interpolate(\n                x, self.values.shape[-2:], mode=self.iterpolate_mode\n            )\n\n    def _postprocess_output(self, out):\n        \"\"\" \"\"\"\n        discrete_shape = self._discrete_shape\n\n        if discrete_shape is None:\n            discrete_shape = []\n\n        shape = out.shape[-1:]\n        out = out.view(*discrete_shape, *shape)\n        permutation = list(range(out.ndim))\n        permutation[self.cont_dim] = out.ndim - 1\n        j = 0\n\n        for i in range(len(permutation)):\n            if i != self.cont_dim:\n                permutation[i] = j\n                j += 1\n\n        out = out.permute(*permutation).contiguous()\n\n        return out", "\n\nclass InterpolationWeights2D(InterpolationWeightsBase):\n    \"\"\"\n    Class implementing InterpolationWeightsBase for parametrization\n    of tensor with two continuous dimensions.\n\n    Parameters\n    ----------\n    cont_size: List[int].\n        Shape of trainable parameter along continuous dimensions.\n    discrete_shape: List[int].\n        Sizes of parametrized tensor along discrete dimension.\n    interpolate_mode: str.\n        See torch.nn.functional.grid_sample.\n    padding_mode: str.\n        See torch.nn.functional.grid_sample.\n    align_corners: bool.\n        See torch.nn.functional.grid_sample.\n    \"\"\"\n\n    def init_values(self, x):\n        \"\"\" \"\"\"\n        if x.ndim == 2:\n            x = x[None, None, :, :]\n        else:\n            permutation = list(range(2, x.ndim))\n            shape = x.shape[:2]\n            x = x.permute(*permutation, 0, 1)\n            x = x.reshape(1, -1, *shape)\n\n        if x.shape[-2:] == self.values.shape[-2:]:\n            self.values.data = x\n        else:\n            self.values.data = interpolate(\n                x, self.values.shape[-2:], mode=self.iterpolate_mode\n            )\n\n    def _postprocess_output(self, out):\n        discrete_shape = self._discrete_shape\n\n        if discrete_shape is None:\n            discrete_shape = []\n\n        shape = out.shape[-2:]\n        out = out.view(*discrete_shape, *shape)\n        dims = range(out.ndim - 2)\n        out = out.permute(out.ndim - 1, out.ndim - 2, *dims)\n\n        return out.contiguous()", ""]}
{"filename": "examples/sr/edsr.py", "chunked_list": ["import argparse\nimport torch\nfrom super_image import EdsrModel, ImageLoader\nfrom super_image.data import EvalDataset, TrainDataset, augment_five_crop\nfrom super_image import Trainer, TrainingArguments\nfrom datasets import load_dataset\nimport torch_integral as inn\nfrom torch_integral.permutation import NOptOutFiltersPermutation\nfrom torch_integral.utils import standard_continuous_dims\nfrom PIL import Image", "from torch_integral.utils import standard_continuous_dims\nfrom PIL import Image\nimport requests\n\n\nparser = argparse.ArgumentParser(description=\"INN EDSR\")\nparser.add_argument(\n    \"--checkpoint\", default=None, help=\"path to model checkpoint (default: None)\"\n)\nparser.add_argument(", ")\nparser.add_argument(\n    \"-e\",\n    \"--evaluate\",\n    dest=\"evaluate\",\n    action=\"store_true\",\n    help=\"evaluate model on validation set\",\n)\nparser.add_argument(\n    \"--integral\", action=\"store_true\", help=\"use integral neural network\"", "parser.add_argument(\n    \"--integral\", action=\"store_true\", help=\"use integral neural network\"\n)\nparser.add_argument(\n    \"--grid-tuning\",\n    action=\"store_true\",\n    help=\"tune only grid of integral neural network\",\n)\nparser.add_argument(\n    \"--resample\", action=\"store_true\", help=\"prune integral neural network\"", "parser.add_argument(\n    \"--resample\", action=\"store_true\", help=\"prune integral neural network\"\n)\nparser.add_argument(\n    \"--scale\", default=4, type=int, help=\"super resolution scale (default: 4)\"\n)\nparser.add_argument(\"-b\", \"--batch-size\", default=32, type=int, metavar=\"N\")\nparser.add_argument(\"-w\", \"--workers\", default=48, type=int)\nparser.add_argument(\n    \"--epochs\", default=400, type=int, metavar=\"N\", help=\"number of total epochs to run\"", "parser.add_argument(\n    \"--epochs\", default=400, type=int, metavar=\"N\", help=\"number of total epochs to run\"\n)\nargs = parser.parse_args()\n\n# DATA\naugmented_dataset = load_dataset(\n    \"eugenesiow/Div2k\", f\"bicubic_x{args.scale}\", split=\"train\"\n).map(augment_five_crop, batched=True, desc=\"Augmenting Dataset\")\ntrain_dataset = TrainDataset(augmented_dataset)", ").map(augment_five_crop, batched=True, desc=\"Augmenting Dataset\")\ntrain_dataset = TrainDataset(augmented_dataset)\neval_dataset = EvalDataset(\n    load_dataset(\"eugenesiow/Div2k\", f\"bicubic_x{args.scale}\", split=\"validation\")\n)\n\n# MODEL\nmodel = EdsrModel.from_pretrained(\"eugenesiow/edsr\", scale=args.scale).cuda()\n\nif args.integral:\n    continuous_dims = standard_continuous_dims(model)\n    discrete_dims = {\n        \"sub_mean.weight\": [0, 1],\n        \"add_mean.weight\": [0, 1],\n        \"head.0.weight\": [1],\n        \"tail.0.0.weight\": [0],\n        \"tail.0.2.weight\": [0, 1],\n        \"tail.1.weight\": [0, 1],\n    }\n    example_input = [1, 3, 32, 32]\n    model = inn.IntegralWrapper(\n        init_from_discrete=(args.checkpoint is None),\n        permutation_config={\"class\": NOptOutFiltersPermutation},\n    )(model, example_input, continuous_dims, discrete_dims).cuda()\n\n    # RESAMPLE\n    for i, group in enumerate(model.groups):\n        if \"operator\" not in group.operations:\n            size = 100 if i > 3 else 256\n        else:\n            size = 200\n\n        group.reset_distribution(inn.UniformDistribution(size, 256))\n        new_size = size if args.resample else 256\n\n        if args.grid_tuning:\n            group.reset_grid(inn.TrainableGrid1D(new_size))\n        elif args.resample:\n            group.resize(new_size)", "\nif args.integral:\n    continuous_dims = standard_continuous_dims(model)\n    discrete_dims = {\n        \"sub_mean.weight\": [0, 1],\n        \"add_mean.weight\": [0, 1],\n        \"head.0.weight\": [1],\n        \"tail.0.0.weight\": [0],\n        \"tail.0.2.weight\": [0, 1],\n        \"tail.1.weight\": [0, 1],\n    }\n    example_input = [1, 3, 32, 32]\n    model = inn.IntegralWrapper(\n        init_from_discrete=(args.checkpoint is None),\n        permutation_config={\"class\": NOptOutFiltersPermutation},\n    )(model, example_input, continuous_dims, discrete_dims).cuda()\n\n    # RESAMPLE\n    for i, group in enumerate(model.groups):\n        if \"operator\" not in group.operations:\n            size = 100 if i > 3 else 256\n        else:\n            size = 200\n\n        group.reset_distribution(inn.UniformDistribution(size, 256))\n        new_size = size if args.resample else 256\n\n        if args.grid_tuning:\n            group.reset_grid(inn.TrainableGrid1D(new_size))\n        elif args.resample:\n            group.resize(new_size)", "\nif args.checkpoint is not None:\n    model.load_state_dict(torch.load(args.checkpoint))\n\nif args.integral:\n    print(\"Compression: \", model.eval().calculate_compression())\n\n# TRAIN\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",", "training_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=args.epochs,\n    learning_rate=1e-4,\n    per_device_train_batch_size=args.batch_size,\n    dataloader_num_workers=args.workers,\n    dataloader_pin_memory=True,\n)\n\ntrainer = Trainer(", "\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n)\n\nif args.integral and args.grid_tuning:\n    model.grid_tuning(False, True, False)", "if args.integral and args.grid_tuning:\n    model.grid_tuning(False, True, False)\n\nif not args.evaluate:\n    trainer.train()\n\n# EVAL\ntrainer.eval(1)\n\nurl = 'http://people.rennes.inria.fr/Aline.Roumy/results/images_SR_BMVC12/input_groundtruth/butterfly_mini_d4_gaussian.bmp'", "\nurl = 'http://people.rennes.inria.fr/Aline.Roumy/results/images_SR_BMVC12/input_groundtruth/butterfly_mini_d4_gaussian.bmp'\nimage = Image.open(requests.get(url, stream=True).raw)\ninputs = ImageLoader.load_image(image).cuda()\npreds = model(inputs)\nImageLoader.save_image(preds, f'scaled_{args.scale}x.png')\nImageLoader.save_compare(inputs, preds, f'scaled_{args.scale}x_compare.png')\n"]}
{"filename": "examples/classification/mnist.py", "chunked_list": ["import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom catalyst import dl\nimport sys\nimport os\nfrom torch_integral import IntegralWrapper\nfrom torch_integral import UniformDistribution\nfrom torch_integral import standard_continuous_dims", "from torch_integral import UniformDistribution\nfrom torch_integral import standard_continuous_dims\n\n\nclass MnistNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv_1 = nn.Conv2d(\n            1, 16, 3, padding=1, bias=True, padding_mode=\"replicate\"\n        )\n        self.conv_2 = nn.Conv2d(\n            16, 32, 5, padding=2, bias=True, padding_mode=\"replicate\"\n        )\n        self.conv_3 = nn.Conv2d(\n            32, 64, 5, padding=2, bias=True, padding_mode=\"replicate\"\n        )\n        self.f_1 = nn.ReLU()\n        self.f_2 = nn.ReLU()\n        self.f_3 = nn.ReLU()\n        self.pool = nn.AvgPool2d(2, 2)\n        self.linear = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = self.f_1(self.conv_1(x))\n        x = self.pool(x)\n        x = self.f_2(self.conv_2(x))\n        x = self.pool(x)\n        x = self.f_3(self.conv_3(x))\n        x = self.pool(x)\n        x = self.linear(x[:, :, 0, 0])\n\n        return x", "\n\n# ------------------------------------------------------------------------------------\n# Data\n# ------------------------------------------------------------------------------------\nbatch_size = 128\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n)", "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n)\n\nroot = os.path.expanduser(\"~\")\ntrain_dataset = torchvision.datasets.MNIST(\n    root=root, train=True, download=True, transform=transform\n)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n\nval_dataset = torchvision.datasets.MNIST(", "\nval_dataset = torchvision.datasets.MNIST(\n    root=root, train=False, download=True, transform=transform\n)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False)\nloaders = {\"train\": train_dataloader, \"valid\": val_dataloader}\n\n# ------------------------------------------------------------------------------------\n# Model\n# ------------------------------------------------------------------------------------", "# Model\n# ------------------------------------------------------------------------------------\nmodel = MnistNet().cuda()\ncontinuous_dims = standard_continuous_dims(model)\ncontinuous_dims.update({\"linear.weight\": [1], \"linear.bias\": [], \"conv_1.weight\": [0]})\nwrapper = IntegralWrapper(init_from_discrete=True)\nmodel = wrapper(model, [1, 1, 28, 28], continuous_dims)\nranges = [[16, 16], [32, 64], [16, 32]]\nmodel.reset_distributions([UniformDistribution(*r) for r in ranges])\n", "model.reset_distributions([UniformDistribution(*r) for r in ranges])\n\n# ------------------------------------------------------------------------------------\n# Train\n# ------------------------------------------------------------------------------------\nopt = torch.optim.Adam(\n    model.parameters(),\n    lr=2e-3,\n)\nloader_len = len(train_dataloader)", ")\nloader_len = len(train_dataloader)\nsched = torch.optim.lr_scheduler.MultiStepLR(\n    opt, [loader_len * 3, loader_len * 5, loader_len * 7, loader_len * 9], gamma=0.5\n)\ncross_entropy = nn.CrossEntropyLoss()\nlog_dir = \"./logs/mnist\"\nrunner = dl.SupervisedRunner(\n    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n)", "    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n)\ncallbacks = [\n    dl.AccuracyCallback(\n        input_key=\"logits\", target_key=\"targets\", topk=(1,), num_classes=10\n    ),\n    dl.SchedulerCallback(mode=\"batch\", loader_key=\"train\", metric_key=\"loss\"),\n]\nloggers = []\nepochs = 10", "loggers = []\nepochs = 10\n\nrunner.train(\n    model=model,\n    criterion=cross_entropy,\n    optimizer=opt,\n    scheduler=sched,\n    loaders=loaders,\n    num_epochs=epochs,", "    loaders=loaders,\n    num_epochs=epochs,\n    callbacks=callbacks,\n    loggers=loggers,\n    logdir=log_dir,\n    valid_loader=\"valid\",\n    valid_metric=\"loss\",\n    minimize_valid_metric=True,\n    cpu=False,\n    verbose=True,", "    cpu=False,\n    verbose=True,\n    fp16=False,\n)\n\n# ------------------------------------------------------------------------------------\n# Eval\n# ------------------------------------------------------------------------------------\nmodel.resize([16, 32, 16])\nprint(\"compression rate: \", model.eval().calculate_compression())", "model.resize([16, 32, 16])\nprint(\"compression rate: \", model.eval().calculate_compression())\nmodel = model.transform_to_discrete()\nmetrics = runner.evaluate_loader(\n    model=model, loader=loaders[\"valid\"], callbacks=callbacks[:-1]\n)\n"]}
{"filename": "examples/classification/nin_cifar.py", "chunked_list": ["import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom catalyst import dl\nfrom pytorchcv.model_provider import get_model\nimport os\nfrom torch_integral import IntegralWrapper, grid_tuning, TrainableGrid1D\n\n\ndef nin_cifar10(pretrained=True):\n    net = get_model(\"nin_cifar10\", pretrained=pretrained)\n    net.features.stage2.dropout2 = torch.nn.Identity()\n    net.features.stage3.dropout3 = torch.nn.Identity()\n\n    return net", "\n\ndef nin_cifar10(pretrained=True):\n    net = get_model(\"nin_cifar10\", pretrained=pretrained)\n    net.features.stage2.dropout2 = torch.nn.Identity()\n    net.features.stage3.dropout3 = torch.nn.Identity()\n\n    return net\n\n", "\n\n# DATA\nbatch_size = 128\n\naugmentation = transforms.Compose(\n    [\n        transforms.ToTensor(),\n        transforms.RandomHorizontalFlip(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),", "        transforms.RandomHorizontalFlip(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    ]\n)\npreprocess = transforms.Compose(\n    [\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    ]\n)", "    ]\n)\n\nroot = os.path.expanduser(\"~\") + \"/datasets/\"\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=root, train=True, download=True, transform=augmentation\n)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n\nval_dataset = torchvision.datasets.CIFAR10(", "\nval_dataset = torchvision.datasets.CIFAR10(\n    root=root, train=False, download=True, transform=preprocess\n)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False)\nloaders = {\"train\": train_dataloader, \"valid\": val_dataloader}\n\n# ------------------------------------------------------------------------------------\n# Model\n# ------------------------------------------------------------------------------------", "# Model\n# ------------------------------------------------------------------------------------\nmodel = nin_cifar10().cuda()\ncontinuous_dims = {}\n\nfor name, mod in model.named_modules():\n    if \"stage3\" in name:\n        if not isinstance(mod, torch.nn.BatchNorm2d):\n            if hasattr(mod, \"weight\"):\n                continuous_dims[name + \".weight\"] = [0, 1]\n            if hasattr(mod, \"bias\"):\n                continuous_dims[name + \".bias\"] = [0]", "\nmodel = IntegralWrapper(\n    init_from_discrete=True,\n    fuse_bn=True,\n    permutation_iters=3000,\n    optimize_iters=0,\n    start_lr=1e-3,\n    verbose=True,\n)(model, [1, 3, 32, 32], continuous_dims)\n", ")(model, [1, 3, 32, 32], continuous_dims)\n\n# ------------------------------------------------------------------------------------\n# Train\n# ------------------------------------------------------------------------------------\ncross_entropy = nn.CrossEntropyLoss()\nlog_dir = \"./logs/cifar\"\nrunner = dl.SupervisedRunner(\n    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n)", "    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n)\ncallbacks = [\n    dl.AccuracyCallback(\n        input_key=\"logits\", target_key=\"targets\", topk=(1,), num_classes=10\n    ),\n    dl.SchedulerCallback(mode=\"batch\", loader_key=\"train\", metric_key=\"loss\"),\n]\nloggers = []\nepochs = 10", "loggers = []\nepochs = 10\n\nfor group in model.groups:\n    if \"operator\" not in group.operations:\n        n = group.size\n        new_size = int(float(n) * 0.5)\n        group.reset_grid(TrainableGrid1D(new_size))\n\nprint(\"compression: \", model.eval().calculate_compression())", "\nprint(\"compression: \", model.eval().calculate_compression())\n\nwith grid_tuning(model, False, True):\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)\n    epoch_len = len(train_dataloader)\n    sched = torch.optim.lr_scheduler.MultiStepLR(\n        opt, [epoch_len * 2, epoch_len * 5, epoch_len * 6, epoch_len * 8], gamma=0.33\n    )\n    runner.train(\n        model=model,\n        criterion=cross_entropy,\n        optimizer=opt,\n        scheduler=sched,\n        loaders=loaders,\n        num_epochs=epochs,\n        callbacks=callbacks,\n        loggers=loggers,\n        logdir=log_dir,\n        valid_loader=\"valid\",\n        valid_metric=\"loss\",\n        verbose=True,\n        cpu=False,\n    )", "\n# ------------------------------------------------------------------------------------\n# Eval\n# ------------------------------------------------------------------------------------\nmetrics = runner.evaluate_loader(\n    model=model, loader=loaders[\"valid\"], callbacks=callbacks[:1]\n)\n"]}
{"filename": "examples/classification/imagenet.py", "chunked_list": ["import os\nimport torch\nimport argparse\nfrom torchvision import models\nfrom catalyst import dl\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nfrom catalyst.engines import GPUEngine\nfrom catalyst.engines import DataParallelEngine\nfrom torch_integral import UniformDistribution, IntegralWrapper", "from catalyst.engines import DataParallelEngine\nfrom torch_integral import UniformDistribution, IntegralWrapper\n\n\nparser = argparse.ArgumentParser(description=\"INN IMAGENET\")\nparser.add_argument(\n    \"data\",\n    metavar=\"DIR\",\n    nargs=\"?\",\n    default=\"imagenet\",", "    nargs=\"?\",\n    default=\"imagenet\",\n    help=\"path to dataset (default: imagenet)\",\n)\nparser.add_argument(\n    \"--checkpoint\", default=None, help=\"path to model checkpoint (default: None)\"\n)\nparser.add_argument(\n    \"-e\",\n    \"--evaluate\",", "    \"-e\",\n    \"--evaluate\",\n    dest=\"evaluate\",\n    action=\"store_true\",\n    help=\"evaluate model on validation set\",\n)\nparser.add_argument(\n    \"--integral\", action=\"store_true\", help=\"use integral neural network\"\n)\nparser.add_argument(", ")\nparser.add_argument(\n    \"--resample\", action=\"store_true\", help=\"prune integral neural network\"\n)\nparser.add_argument(\n    \"--data-parallel\", action=\"store_true\", help=\"use data parallel engine\"\n)\nparser.add_argument(\"-b\", \"--batch-size\", default=256, type=int, metavar=\"N\")\nparser.add_argument(\"-w\", \"--workers\", default=48, type=int)\nparser.add_argument(", "parser.add_argument(\"-w\", \"--workers\", default=48, type=int)\nparser.add_argument(\n    \"--epochs\", default=90, type=int, metavar=\"N\", help=\"number of total epochs to run\"\n)\nargs = parser.parse_args()\n\n# DATA\ntraindir = os.path.join(args.data, \"train\")\nvaldir = os.path.join(args.data, \"val\")\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])", "valdir = os.path.join(args.data, \"val\")\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\ntrain_dataset = datasets.ImageFolder(\n    traindir,\n    transforms.Compose(\n        [\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),", "            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]\n    ),\n)\n\nval_dataset = datasets.ImageFolder(\n    valdir,\n    transforms.Compose(", "    valdir,\n    transforms.Compose(\n        [\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ]\n    ),\n)", "    ),\n)\n\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset,\n    args.batch_size,\n    shuffle=False,\n    num_workers=args.workers,\n    pin_memory=True,\n)", "    pin_memory=True,\n)\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset,\n    args.batch_size,\n    shuffle=True,\n    num_workers=args.workers,\n    pin_memory=True,\n)\ndataloaders = {\"train\": train_dataloader, \"valid\": val_dataloader}", ")\ndataloaders = {\"train\": train_dataloader, \"valid\": val_dataloader}\n\n# MODEL\nmodel = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).cuda()\ncontinuous_dims = {}\n\nif args.integral:\n    continuous_dims = {\n        \"layer4.0.conv1.weight\": [0, 1],\n        \"layer4.0.conv2.weight\": [0, 1],\n        \"layer4.0.downsample.0.weight\": [0, 1],\n        \"layer4.1.conv1.weight\": [0, 1],\n        \"layer4.1.conv2.weight\": [0, 1],\n    }\n    discrete_dims = {\"fc.weight\": [1]}\n    wrapper = IntegralWrapper(\n        init_from_discrete=(args.checkpoint is None), permutation_iters=1000\n    )\n    model = wrapper(model, [1, 3, 224, 224], continuous_dims, discrete_dims)\n    model.groups[-1].reset_distribution(UniformDistribution(338, 512))\n    model.groups[-2].reset_distribution(UniformDistribution(338, 512))", "\nif args.checkpoint is not None:\n    model.load_state_dict(torch.load(args.checkpoint))\n\nif args.resample:\n    model.groups[-1].resize(338)\n    model.groups[-2].resize(338)\n    print(\"model compression: \", model.eval().calculate_compression())\n\n# Train", "\n# Train\nlog_dir = \"./logs/imagenet/\"\nrunner = dl.SupervisedRunner(\n    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n)\ncallbacks = [\n    dl.AccuracyCallback(\n        input_key=\"logits\",\n        target_key=\"targets\",", "        input_key=\"logits\",\n        target_key=\"targets\",\n        topk=(1,),\n        num_classes=1000,\n        log_on_batch=True,\n    ),\n    dl.SchedulerCallback(mode=\"batch\", loader_key=\"train\", metric_key=\"loss\"),\n]\nif args.data_parallel:\n    engine = DataParallelEngine()\nelse:\n    engine = GPUEngine()", "if args.data_parallel:\n    engine = DataParallelEngine()\nelse:\n    engine = GPUEngine()\n\nif not args.evaluate:\n    loggers = []\n    cross_entropy = torch.nn.CrossEntropyLoss()\n    opt = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-8)\n    epoch_len = len(dataloaders[\"train\"])\n    sched = torch.optim.lr_scheduler.MultiStepLR(\n        opt,\n        [epoch_len * 10, epoch_len * 20, epoch_len * 30, epoch_len * 40],\n        gamma=0.33,\n    )\n    runner.train(\n        model=model,\n        criterion=cross_entropy,\n        optimizer=opt,\n        scheduler=sched,\n        loaders=dataloaders,\n        num_epochs=args.epochs,\n        callbacks=callbacks,\n        loggers=loggers,\n        logdir=log_dir,\n        valid_loader=\"valid\",\n        valid_metric=\"loss\",\n        minimize_valid_metric=True,\n        engine=engine,\n        verbose=True,\n    )", "\nmetrics = runner.evaluate_loader(\n    model=model,\n    loader=dataloaders[\"valid\"],\n    callbacks=callbacks[:1],\n    verbose=True,\n    engine=engine,\n)\n", ""]}
{"filename": "docs/conf.py", "chunked_list": ["# flake8: noqa\n# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------", "\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport datetime\nimport os\nimport re", "import os\nimport re\nimport sys\n\nsys.path.append(\"../\")\n\n# -- Project information -----------------------------------------------------\n\nproject = \"TorchIntegral v.0.0.0.0\"\ncopyright = \"{}, TheStage.ai\".format(datetime.datetime.now().year)", "project = \"TorchIntegral v.0.0.0.0\"\ncopyright = \"{}, TheStage.ai\".format(datetime.datetime.now().year)\nauthor = \"Azim Kurbanov, Kirill Solodskikh\"\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \"1.0\"\n", "# needs_sphinx = \"1.0\"\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \"sphinx.ext.*\") or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.coverage\",\n    \"sphinx.ext.mathjax\",", "    \"sphinx.ext.coverage\",\n    \"sphinx.ext.mathjax\",\n    \"sphinx.ext.viewcode\",\n    \"sphinx.ext.githubpages\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.autosummary\"\n    # \"releases\",\n]\n\nautodoc_inherit_docstrings = False", "\nautodoc_inherit_docstrings = False\nnapoleon_google_docstring = False\nnapoleon_include_init_with_doc = True\nnapoleon_numpy_docstring = True\n\nautosummary_generate = True\nautodoc_default_flags = [\"members\"]\n\n# Add any paths that contain templates here, relative to this directory.", "\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\".rst\", \".md\"]\nsource_suffix = \".rst\"\n", "source_suffix = \".rst\"\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.", "# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = \"Python\"\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\n# Ignoring Third-party packages", "\n# Ignoring Third-party packages\n\nautodoc_mock_imports = [\n    # \"torch\",\n    # \"torchvision\",\n    \"alchemy\",\n    \"neptune\",\n    \"wandb\",\n    \"gym\",", "    \"wandb\",\n    \"gym\",\n    \"gridfs\",\n    \"pymongo\",\n    \"redis\",\n]\n\n# autodoc_default_flags = [\n#     \"members\", \"undoc-members\", \"private-members\",\n#     \"special-members\", \"inherited-members\", \"show-inheritance\"", "#     \"members\", \"undoc-members\", \"private-members\",\n#     \"special-members\", \"inherited-members\", \"show-inheritance\"\n# ]\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for", "\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"integral_sphinx_theme\"\n# html_logo = \"integral_sphinx_theme/images/logo.png\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.", "# further.  For a list of options available for each theme, see the\n# documentation.\n#\nhtml_theme_options = {}\n# html_theme_options = {\n#     \"display_version\": True,\n#     \"prev_next_buttons_location\": \"bottom\",\n#     \"collapse_navigation\": False,\n#     \"sticky_navigation\": True,\n#     \"navigation_depth\": 4,", "#     \"sticky_navigation\": True,\n#     \"navigation_depth\": 4,\n# }\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\n# html_static_path = [\"_static\"]\n\nhtml_short_title = \"Integral Nerual Networks\"", "\nhtml_short_title = \"Integral Nerual Networks\"\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\"t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\"localtoc.html\", \"relations.html\", \"sourcelink.html\",\n# \"searchbox.html\"]``.", "# default: ``[\"localtoc.html\", \"relations.html\", \"sourcelink.html\",\n# \"searchbox.html\"]``.\n#\n# html_sidebars = {}\n\nhtml_context = {\n    \"display_github\": True,\n    \"source_url_prefix\": (\"https://github.com/TheStageAI/TorchIntegral\"),\n    \"github_host\": \"github.com\",\n    # \"github_user\": docs_user,", "    \"github_host\": \"github.com\",\n    # \"github_user\": docs_user,\n    # \"github_repo\": docs_repo,\n    \"github_version\": \"master\",\n    \"conf_py_path\": \"/docs/\",\n    \"source_suffix\": \".rst\",\n}\n\n# -- Options for HTMLHelp output ---------------------------------------------\n", "# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \"TorchIntegraldoc\"\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\"letterpaper\" or \"a4paper\").\n    #", "    # The paper size (\"letterpaper\" or \"a4paper\").\n    #\n    # \"papersize\": \"letterpaper\",\n    # The font size (\"10pt\", \"11pt\" or \"12pt\").\n    #\n    # \"pointsize\": \"10pt\",\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \"preamble\": \"\",\n    # Latex figure (float) alignment", "    # \"preamble\": \"\",\n    # Latex figure (float) alignment\n    #\n    # \"figure_align\": \"htbp\",\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\n", "#  author, documentclass [howto, manual, or own class]).\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, \"TorchIntegral\", \"TorchIntegral Documentation\", [author], 1)]\n\n# -- Options for Texinfo output ----------------------------------------------\n", "# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        \"TorchIntegral\",\n        \"TorchIntegral Documentation\",", "        \"TorchIntegral\",\n        \"TorchIntegral Documentation\",\n        author,\n        \"TorchIntegral\",\n        \"One line description of project.\",\n        \"Continuous\",\n    ),\n]\n\n# -- Options for Epub output -------------------------------------------------", "\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \"\"", "#\n# epub_identifier = \"\"\n\n# A unique identification for the text.\n#\n# epub_uid = \"\"\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\"search.html\"]\n", "epub_exclude_files = [\"search.html\"]\n\n# -- Extension configuration -------------------------------------------------\n\n# -- Options for todo extension ----------------------------------------------\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n", ""]}
