{"filename": "setup.py", "chunked_list": ["\"\"\"Setup file for the package.\"\"\"\n\nfrom setuptools import setup\n\nsetup()\n"]}
{"filename": "github_actions_utils/color.py", "chunked_list": ["\"\"\"Color utils for GitHub actions.\"\"\"\nfrom colorsys import hsv_to_rgb\n\n\ndef score_to_hex_color(score: float, score_min: float, score_max: float) -> str:\n    \"\"\"Convert score to hex color red > bright green.\"\"\"\n    norm_score = max(0, (score - score_min) / (score_max - score_min))\n    hsv = (1 / 3 * norm_score, 1, 1)\n    rgb = hsv_to_rgb(*hsv)\n    rgb_tuple = tuple(int(255 * value) for value in rgb)\n    hex_color = f\"#{rgb_tuple[0]:02x}{rgb_tuple[1]:02x}{rgb_tuple[2]:02x}\"\n    return hex_color", ""]}
{"filename": "github_actions_utils/pylint_manager.py", "chunked_list": ["\"\"\"Manage Pylint output on workflow.\"\"\"\nimport sys\n\nfrom github_actions_utils.color import score_to_hex_color\n\n\ndef check_output() -> float:\n    \"\"\"Check output of Pylint.\n\n    Raises\n    ------\n    ValueError\n        If Pylint score is below SCORE_MIN.\n\n    Returns\n    -------\n    score: float\n        Score of Pylint.\n    \"\"\"\n    args = sys.argv[1:]\n    score = -10000.0  # A default value\n    for arg in args:\n        if arg.startswith(\"--score=\"):\n            score = float(arg.split(\"=\")[1])\n    if score == -10000.0:\n        raise ValueError(\"Please specify the score of Pylint using the flag --score=N.\")\n    if score < PYLINT_SCORE_MIN:\n        raise ValueError(\n            f\"Pylint score {score} is lower than minimum ({PYLINT_SCORE_MIN})\"\n        )\n\n    return score", "\n\ndef main() -> None:\n    \"\"\"Check score and print it.\"\"\"\n    score = check_output()\n    # Print color to be used in GitHub Actions\n    print(score_to_hex_color(score, PYLINT_SCORE_MIN, PYLINT_SCORE_MAX))\n\n\nif __name__ == \"__main__\":\n    # PYLINT_SCORE_MIN can be changed safely depending on your needs.\n    PYLINT_SCORE_MIN = 8.5\n    PYLINT_SCORE_MAX = 10.0\n    main()", "\nif __name__ == \"__main__\":\n    # PYLINT_SCORE_MIN can be changed safely depending on your needs.\n    PYLINT_SCORE_MIN = 8.5\n    PYLINT_SCORE_MAX = 10.0\n    main()\n"]}
{"filename": "github_actions_utils/__init__.py", "chunked_list": ["\"\"\"GitHub actions utilities.\"\"\"\n"]}
{"filename": "github_actions_utils/pydocstyle_manager.py", "chunked_list": ["\"\"\"Manage Pydocstyle output on workflow.\"\"\"\nimport sys\n\n\ndef check_output() -> None:\n    \"\"\"Check output of Pydocstyle.\n\n    Raises\n    ------\n    ValueError\n        If Pydocstyle find errors.\n    \"\"\"\n    args = sys.argv[1:]\n    n_errors = -1  # A default value\n    for arg in args:\n        if arg.startswith(\"--n_errors=\"):\n            n_errors = int(arg.split(\"=\")[1])\n    if n_errors == -1:\n        raise ValueError(\n            \"Please specify the number of errors found by Pydocstyle \"\n            \"using the flag --n_errors=N.\"\n        )\n    if n_errors > 0:\n        raise ValueError(\n            f\"Pydocstyle found {n_errors} errors in python \"\n            \"docstrings. Please fix them.\",\n        )", "\n\nif __name__ == \"__main__\":\n    check_output()\n"]}
{"filename": "github_actions_utils/pytest_manager.py", "chunked_list": ["\"\"\"Manage Pytest-cov output on workflow.\"\"\"\nimport sys\n\nfrom github_actions_utils.color import score_to_hex_color\n\n\ndef check_output() -> float:\n    \"\"\"Check output of Pytest-cov.\n\n    Raises\n    ------\n    ValueError\n        If Pytest find failures.\n    ValueError\n        If coverage is below SCORE_MIN.\n\n    Returns\n    -------\n    score: float\n        Score of coverage.\n    \"\"\"\n    args = sys.argv[1:]\n    n_failures, score = -1, -1.0  # Default values\n    for arg in args:\n        if arg.startswith(\"--score=\"):\n            score_percent = arg.split(\"=\")[1]\n            score = float(score_percent.split(\"%\")[0])\n        if arg.startswith(\"--n_failures=\"):\n            n_failures_str = arg.split(\"=\")[1]\n            n_failures = 0 if n_failures_str == \"\" else int(n_failures_str)\n\n    if n_failures == -1:\n        raise ValueError(\n            \"Please specify the number of failures found by Pytest \"\n            \"using the flag --n_failures=N.\",\n        )\n    if score == -1:\n        raise ValueError(\n            \"Please specify the score of coverage using the flag --score=N (in %).\",\n        )\n\n    if n_failures > 0:\n        raise ValueError(f\"Pytest finds {n_failures} failure(s) on tests.\")\n    if score < COV_SCORE_MIN:\n        raise ValueError(\n            f\"Pytest coverage {score}% is lower than minimum ({COV_SCORE_MIN}%)\",\n        )\n\n    return score", "\n\ndef main() -> None:\n    \"\"\"Check score and print it.\"\"\"\n    score = check_output()\n    # Print color to be used in GitHub Actions\n    print(score_to_hex_color(score, COV_SCORE_MIN, COV_SCORE_MAX))\n\n\nif __name__ == \"__main__\":\n    # COV_SCORE_MIN can be changed safely depending on your needs.\n    # NOTE: score on %\n    COV_SCORE_MIN = 0\n    COV_SCORE_MAX = 100\n    main()", "\nif __name__ == \"__main__\":\n    # COV_SCORE_MIN can be changed safely depending on your needs.\n    # NOTE: score on %\n    COV_SCORE_MIN = 0\n    COV_SCORE_MAX = 100\n    main()\n"]}
{"filename": "tests/__init__.py", "chunked_list": ["\"\"\"Tests for CLI Config.\"\"\"\n"]}
{"filename": "tests/conftest.py", "chunked_list": ["\"\"\"Shared pytest fixtures.\"\"\"\nfrom typing import Any, Dict\n\nimport pytest\n\nfrom cliconfig.base import Config\nfrom cliconfig.processing.base import Processing\nfrom cliconfig.tag_routines import clean_all_tags, clean_tag, is_tag_in\n\n\nclass ProcessAdd1(Processing):\n    \"\"\"Add 1 to values with tag \"@add1\".\"\"\"\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, value in items:\n            if is_tag_in(flat_key, \"add1\"):\n                flat_config.dict[clean_tag(flat_key, \"add1\")] = value + 1\n                del flat_config.dict[flat_key]\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\"\"\"\n        flat_config.dict[\"processing name\"] = \"ProcessAdd1\"\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\"\"\"\n        return self.premerge(flat_config)", "\n\nclass ProcessAdd1(Processing):\n    \"\"\"Add 1 to values with tag \"@add1\".\"\"\"\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, value in items:\n            if is_tag_in(flat_key, \"add1\"):\n                flat_config.dict[clean_tag(flat_key, \"add1\")] = value + 1\n                del flat_config.dict[flat_key]\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\"\"\"\n        flat_config.dict[\"processing name\"] = \"ProcessAdd1\"\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\"\"\"\n        return self.premerge(flat_config)", "\n\nclass ProcessKeep(Processing):\n    \"\"\"Prevent a value from being changed after the merge.\"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.keep_vals: Dict[str, Any] = {}\n\n    # pylint: disable=unused-argument\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, value in items:\n            if is_tag_in(flat_key, \"keep\"):\n                new_key = clean_tag(flat_key, \"keep\")\n                flat_config.dict[new_key] = value\n                del flat_config.dict[flat_key]\n                self.keep_vals[clean_all_tags(flat_key)] = value\n        return flat_config\n\n    # pylint: disable=unused-argument\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\"\"\"\n        for key, value in self.keep_vals.items():\n            if key in flat_config.dict:\n                flat_config.dict[key] = value\n        self.keep_vals = {}\n        return flat_config\n\n    # pylint: disable=unused-argument\n    def postload(self, flat_config: Config) -> Config:\n        \"\"\"Post-load processing.\"\"\"\n        for key, value in self.keep_vals.items():\n            flat_config.dict[key] = value\n        self.keep_vals = {}\n        return flat_config", "\n\n@pytest.fixture()\ndef process_add1() -> ProcessAdd1:\n    \"\"\"Return a processing object that adds 1 on tag \"@add1\".\"\"\"\n    return ProcessAdd1()\n\n\n@pytest.fixture()\ndef process_keep() -> ProcessKeep:\n    \"\"\"Return a processing object that keep a value unchanged after the merge.\"\"\"\n    return ProcessKeep()", "@pytest.fixture()\ndef process_keep() -> ProcessKeep:\n    \"\"\"Return a processing object that keep a value unchanged after the merge.\"\"\"\n    return ProcessKeep()\n"]}
{"filename": "tests/integration/test_ex_docs.py", "chunked_list": ["\"\"\"Test ProcessBypassTyping.\"\"\"\n\nfrom typing import Dict, Set\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig import Config\nfrom cliconfig.process_routines import merge_flat_processing\nfrom cliconfig.processing.base import Processing", "from cliconfig.process_routines import merge_flat_processing\nfrom cliconfig.processing.base import Processing\nfrom cliconfig.processing.builtin import ProcessTyping\nfrom cliconfig.tag_routines import clean_all_tags, clean_tag, is_tag_in\n\n\nclass ProcessPrintSorted(Processing):\n    \"\"\"Print the parameters tagged with \"@look\", sorted by value on post-merge.\"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.looked_keys: Set[str] = set()\n        # Pre-merge just look for the tag so order is not important\n        self.premerge_order = 0.0\n        # Post-merge should be after the copy processing if we want the final values\n        # on post-merge\n        self.postmerge_order = 15.0\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        # Browse a freeze version of the dict (because we will modify it to remove tags)\n        items = list(flat_config.dict.items())\n        for flat_key, value in items:\n            if is_tag_in(flat_key, \"look\"):  # Check if the key contains the tag\n                # Remove the tag and update the dict\n                new_key = clean_tag(flat_key, \"look\")\n                flat_config.dict[new_key] = value\n                del flat_config.dict[flat_key]\n                # Store the key\n                # remove all tags = true parameter name\n                clean_key = clean_all_tags(flat_key)\n                self.looked_keys.add(clean_key)\n        return flat_config\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\"\"\"\n        values = []\n        for key in self.looked_keys:\n            # IMPORTANT\n            # (\"if key in flat_config.dict:\" is important in case of some keys were\n            # removed or if multiple dicts with different parameters are seen by\n            # the processing)\n            if key in flat_config.dict:\n                values.append(flat_config.dict[key])\n        print(\"The sorted looked values are: \", sorted(values))\n        # If we don't want to keep the looked keys for further print:\n        self.looked_keys = set()\n\n        return flat_config", "\n\nclass ProcessBypassTyping(Processing):\n    \"\"\"Bypass type check of ProcessTyping for parameters tagged with \"@bypass_typing\".\n\n    In pre-merge it looks for a parameter with the tag \"@bypass_typing\",\n    removes it and change the internal ProcessTyping variables to avoid\n    checking the type of the parameter with ProcessTyping.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.bypassed_forced_types: Dict[str, tuple] = {}\n        # Before ProcessTyping pre-merge to let it change the type\n        self.premerge_order = -1.0\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, value in items:\n            if is_tag_in(flat_key, \"bypass_typing\"):\n                new_key = clean_tag(flat_key, \"bypass_typing\")\n                flat_config.dict[new_key] = value\n                del flat_config.dict[flat_key]\n                clean_key = clean_all_tags(flat_key)\n                for processing in flat_config.process_list:\n                    if (\n                        isinstance(processing, ProcessTyping)\n                        and clean_key in processing.forced_types\n                    ):\n                        forced_type = processing.forced_types.pop(clean_key)\n                        self.bypassed_forced_types[clean_key] = forced_type\n        return flat_config", "\n\ndef test_process_print_sorted(capsys: pytest.CaptureFixture) -> None:\n    \"\"\"Test ProcessPrintSorted.\"\"\"\n    config1 = Config({\"a@look\": 0, \"b@look\": 2, \"c\": 3}, [ProcessPrintSorted()])\n    config2 = Config({\"a@look\": 1, \"d@look\": 4}, [])\n    capsys.readouterr()\n    merge_flat_processing(config1, config2)\n    out = capsys.readouterr().out\n    check.equal(out, \"The sorted looked values are:  [1, 2, 4]\\n\")", "\n\ndef test_process_bypass_typing() -> None:\n    \"\"\"Test ProcessBypassTyping.\"\"\"\n    config1 = Config({\"a@type:int\": 0}, [ProcessBypassTyping(), ProcessTyping()])\n    config2 = Config({\"a@bypass_typing@type:str\": \"a\"}, [])\n    merge_flat_processing(config1, config2)\n    config1 = Config({\"a@type:int\": 0}, [ProcessBypassTyping(), ProcessTyping()])\n    config2 = Config({\"a@type:str\": \"a\"}, [])\n    # Reset ProcessTyping\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"Find the tag '@type:str' on a key that has already \"\n            \"been associated to an other type: int.*\"\n        ),\n    ):\n        merge_flat_processing(config1, config2)", ""]}
{"filename": "tests/integration/test_inte_multiple_tags.py", "chunked_list": ["\"\"\"Integration test for multiple tags.\"\"\"\nimport random\nimport shutil\nimport sys\nfrom copy import deepcopy\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig import (", "\nfrom cliconfig import (\n    Config,\n    create_processing_keep_property,\n    create_processing_value,\n    load_config,\n    make_config,\n    save_config,\n)\nfrom cliconfig.dict_routines import load_dict", ")\nfrom cliconfig.dict_routines import load_dict\nfrom cliconfig.process_routines import merge_flat_processing\n\n\ndef test_multiple_tags() -> None:\n    \"\"\"Integration test for multiple tags.\"\"\"\n    sys_argv = sys.argv.copy()\n    sys.argv = [\"test_inte_multiple_tags.py\"]\n    config = make_config(\"tests/configs/integration/test1/main.yaml\")\n    expected_config = {\n        \"path_1\": \"tests/configs/integration/test1/sub1.yaml\",\n        \"path_2\": \"tests/configs/integration/test1/sub2.yaml\",\n        \"config1\": {\n            \"param\": 2,\n            \"param2\": 1,\n        },\n        \"config2\": {\n            \"param\": 2,\n        },\n        \"config3\": {\n            \"select\": \"config3.param1\",\n            \"param1\": 0,\n        },\n    }\n    check.equal(config.dict, expected_config)\n    config = merge_flat_processing(\n        config,\n        Config({\"config2.param\": 5.6}, []),\n        preprocess_first=False,\n    )\n    with pytest.raises(\n        ValueError, match=\"Key previously tagged with '@type:None|int'.*\"\n    ):\n        config.process_list[3].endbuild(config)\n    sys.argv = sys_argv", "\n\ndef test_multiple_tags2() -> None:\n    \"\"\"2nd integration test for multiple tags.\"\"\"\n    sys_argv = sys.argv.copy()\n    sys.argv = [\n        \"test_inte_multiple_tags2.py\",\n        \"--config\",\n        \"[tests/configs/integration/test2/exp1.yaml, \"\n        \"tests/configs/integration/test2/exp2.yaml]\",\n        \"--train.n_epochs=20\",\n        \"--train.optimizer.momentum=0\",\n        \"--train.optimizer.type=Adam\",\n    ]\n\n    def func_pos_enc_type(x: str) -> str:\n        if x in [\"absolute\", \"relative\", \"embed\"]:\n            return x\n        raise ValueError(f\"Invalid value for pos_enc_type: {x}\")\n\n    def func_optim_type(x: str) -> str:\n        if x in [\"SGD\", \"Adam\"]:\n            return x\n        raise ValueError(f\"Invalid value for optim_type: {x}\")\n\n    proc_pos_enc_type = create_processing_value(\n        func_pos_enc_type,\n        tag_name=\"pos_enc\",\n        order=20,\n        persistent=True,\n    )\n    proc_optim_type = create_processing_value(\n        func_optim_type,\n        tag_name=\"optim_type\",\n        order=20,\n        persistent=True,\n    )\n    proc_protect = create_processing_keep_property(\n        func=lambda x: x,\n        tag_name=\"protect\",\n        premerge_order=-15,\n        postmerge_order=15,\n    )\n    proc_run_id = create_processing_value(\n        lambda run_id: run_id if run_id is not None else random.randint(0, 1000000),\n        regex=\"run_id.*\",\n    )\n    config = make_config(\n        \"tests/configs/integration/test2/default.yaml\",\n        process_list=[proc_pos_enc_type, proc_optim_type, proc_protect, proc_run_id],\n        add_default_processing=True,\n    )\n    expected_dict = {\n        \"project_name\": \"ImageClassif\",\n        \"models\": {\n            \"archi_name\": \"models.vit_b16\",\n            \"vit_b16\": {\n                \"pos_enc_type\": \"absolute\",\n                \"attn_dropout\": 0.2,\n                \"dropout\": 0.1,\n                \"in_size\": 512,\n                \"n_blocks\": 12,\n            },\n        },\n        \"data\": {\n            \"data_size\": 512,\n            \"dataset_path\": \"../../mydata\",\n            \"standardization\": True,\n            \"augmentation\": [\"RandomHorizontalFlip\", \"RandomVerticalFlip\"],\n            \"dataset_cfg_path\": \"tests/configs/integration/test2/data.yaml\",\n        },\n        \"train\": {\n            \"n_epochs\": 20,\n            \"optimizer\": {\n                \"type\": \"Adam\",\n                \"lr\": 0.001,\n                \"momentum\": 0,\n            },\n        },\n        \"metadata\": {\n            \"exp_details\": {\n                \"goal\": \"Test multiple processings\",\n                \"config_folder\": \"tests/configs/integration/test2\",\n            }\n        },\n    }\n    check.is_instance(config.dict[\"run_id\"], int)\n    config_dict = deepcopy(config.dict)\n    del config_dict[\"run_id\"]\n    check.equal(config_dict, expected_dict)\n    save_config(config, \"tests/tmp/config.yaml\")\n    saved_dict = load_dict(\"tests/tmp/config.yaml\")\n    check.equal(\n        saved_dict[\"data\"][\"augmentation@type:List[str]\"],\n        [\"RandomHorizontalFlip\", \"RandomVerticalFlip\"],\n    )\n    check.equal(\n        saved_dict[\"models\"][\"archi_name@type:None|str@select\"], \"models.vit_b16\"\n    )\n    check.equal(\n        saved_dict[\"models\"][\"vit_b16\"][\"in_size@copy@type:int\"], \"data.data_size\"\n    )\n    config = load_config(\n        \"tests/tmp/config.yaml\",\n        [\"tests/configs/integration/test2/default.yaml\"],\n        config.process_list,\n    )\n    del config.dict[\"run_id\"]\n    check.equal(config.dict, expected_dict)\n    with pytest.raises(ValueError, match=\"Key previously tagged with '@type:int.*\"):\n        config.process_list[7].endbuild(\n            Config({\"models.vit_b16.n_blocks\": 5.6}, config.process_list)\n        )\n    with pytest.raises(\n        ValueError, match=\"Found attempt to modify a key with '@copy' tag.*\"\n    ):\n        merge_flat_processing(config, Config({\"models.vit_b16.in_size\": 224}, []))\n\n    shutil.rmtree(\"tests/tmp\")\n    sys.argv = sys_argv", ""]}
{"filename": "tests/unit/test_cli_parser.py", "chunked_list": ["\"\"\"Test for cli_parser.py.\"\"\"\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig.cli_parser import parse_cli\n\n\ndef test_parse_cli() -> None:\n    \"\"\"Test for parse_cli.\"\"\"\n    config_paths, config_cli_params = parse_cli(\n        [\"main.py\", \"--config\", \"config1.yaml,config2.yaml\", \"--a=1\", \"--b=2\"]\n    )\n    check.equal(config_paths, [\"config1.yaml\", \"config2.yaml\"])\n    config_paths, config_cli_params = parse_cli(\n        [\"main.py\", \"--config\", \"[config1.yaml, config2.yaml]\", \"--a=1\", \"--b=2\"]\n    )\n    check.equal(config_paths, [\"config1.yaml\", \"config2.yaml\"])\n    check.equal(config_cli_params, {\"a\": 1, \"b\": 2})\n    b_str = \"{'2': {'3': 4, '5': [6.3], '7': True, '8': Null, '9': [2, {'a': 1}]}}\"\n    config_paths, config_cli_params = parse_cli(\n        [\"main.py\", \"--a='b=c'\", f\"--b={b_str}\"]\n    )\n    val = {\n        \"a\": \"b=c\",\n        \"b\": {\"2\": {\"3\": 4, \"5\": [6.3], \"7\": True, \"8\": None, \"9\": [2, {\"a\": 1}]}},\n    }\n    check.equal(config_paths, [])\n    check.equal(config_cli_params, val)\n    config_paths, config_cli_params = parse_cli(\n        [\"main.py\", \"--unknown\", \"--a=1\", \"--unknwon2=2\", \"--b=3\"]\n    )\n    val2 = {\"unknown\": True, \"a\": 1, \"unknwon2\": 2, \"b\": 3}\n    check.equal(config_paths, [])\n    check.equal(config_cli_params, val2)\n    with pytest.raises(ValueError, match=\"Only one '--config ' argument is allowed.*\"):\n        parse_cli([\"main.py\", \"--config\", \"config1.yaml\", \"--config\", \"config2.yaml\"])", ""]}
{"filename": "tests/unit/test_process_routines.py", "chunked_list": ["\"\"\"Tests for dict routines with preprocessing.\"\"\"\nimport re\nimport shutil\n\nimport pytest\nimport pytest_check as check\nimport yaml\n\nfrom cliconfig.base import Config\nfrom cliconfig.process_routines import (", "from cliconfig.base import Config\nfrom cliconfig.process_routines import (\n    end_build_processing,\n    load_processing,\n    merge_flat_paths_processing,\n    merge_flat_processing,\n    save_processing,\n)\nfrom cliconfig.processing.base import Processing\nfrom tests.conftest import ProcessAdd1, ProcessKeep", "from cliconfig.processing.base import Processing\nfrom tests.conftest import ProcessAdd1, ProcessKeep\n\n\ndef test_merge_flat_processing(\n    process_add1: ProcessAdd1,\n    process_keep: ProcessKeep,\n) -> None:\n    \"\"\"Test merge_flat_processing.\"\"\"\n\n    class _ProcessingTest(Processing):\n        def __init__(self) -> None:\n            super().__init__()\n            self.attr = 0\n\n    proc1 = _ProcessingTest()\n    proc2 = _ProcessingTest()\n    proc2.attr = 1\n    proc3 = _ProcessingTest()\n\n    config1 = Config({\"a\": {\"b\": 1, \"c\": 2, \"d@keep\": 3}}, [proc1, proc2, process_add1])\n    config2 = Config({\"a\": {\"b\": 2, \"c@add1\": 3, \"d\": 4}}, [proc3, process_keep])\n    config = merge_flat_processing(\n        config1,\n        config2,\n        allow_new_keys=False,\n    )\n    check.equal(\n        config.dict,\n        {\"a.b\": 2, \"a.c\": 4, \"a.d\": 3},\n    )\n    check.equal(config.process_list, [proc1, proc2, process_add1, process_keep])\n    check.equal(process_keep.keep_vals, {})", "\n\ndef test_merge_flat_paths_processing(\n    process_add1: ProcessAdd1,\n    process_keep: ProcessKeep,\n) -> None:\n    \"\"\"Test merge_flat_paths_processing.\"\"\"\n    config1 = Config(\n        {\"param1@add1\": 0, \"param2.param3@keep\": 1}, [process_add1, process_keep]\n    )\n    config2 = Config({\"param2.param3\": 3}, [])\n    expected_dict = {\"param1\": 1, \"param2.param3\": 1}\n    check.equal(\n        merge_flat_paths_processing(\n            \"tests/configs/configtag1.yaml\",\n            \"tests/configs/configtag2.yaml\",\n            allow_new_keys=False,\n            additional_process=[process_add1, process_keep],\n        ),\n        Config(expected_dict, [process_add1, process_keep]),\n    )\n    check.equal(\n        merge_flat_paths_processing(\n            config1,\n            config2,\n            allow_new_keys=False,\n        ),\n        Config(expected_dict, [process_add1, process_keep]),\n    )\n    check.equal(process_keep.keep_vals, {})", "\n    # Case with dict in input\n\n\ndef test_save_processing(\n    process_add1: ProcessAdd1,\n    process_keep: ProcessKeep,\n) -> None:\n    \"\"\"Test save_processing.\"\"\"\n    config = Config(\n        {\"param1@add1\": 0, \"param2.param3@add1\": 1}, [process_add1, process_keep]\n    )\n    save_processing(config, \"tests/tmp/config.yaml\")\n    with open(\"tests/tmp/config.yaml\", \"r\", encoding=\"utf-8\") as yaml_file:\n        loaded_dict = yaml.safe_load(yaml_file)\n    check.equal(loaded_dict, {\"param1\": 1, \"param2\": {\"param3\": 2}})\n    check.equal(process_keep.keep_vals, {})\n    shutil.rmtree(\"tests/tmp\")", "\n\ndef test_load_processing(\n    process_add1: ProcessAdd1,\n    process_keep: ProcessKeep,\n) -> None:\n    \"\"\"Test load_processing.\"\"\"\n    process_keep.keep_vals = {\"param2.param3\": 0}\n    config = load_processing(\n        \"tests/configs/configtag2.yaml\",\n        [process_add1, process_keep],\n    )\n    check.equal(config.dict, {\"param2.param3\": 0})\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"config_or_path must be a Config instance or a path to a yaml file \"\n            \"but you passed a dict. If you want to use it as a valid input, \"\n            \"you should use Config(<input dict>, []) instead.\"\n        ),\n    ):\n        merge_flat_paths_processing(\n            {\"a\": 2},  # type: ignore\n            Config({\"a\": 1}, []),\n        )\n    with pytest.raises(\n        ValueError,\n        match=(\"config_or_path must be a Config instance or a path to a yaml file.\"),\n    ):\n        merge_flat_paths_processing(\n            Config({\"a\": 1}, []),\n            (\"not a path\",),  # type: ignore\n        )", "\n\ndef test_end_build_processing(process_add1: ProcessAdd1) -> None:\n    \"\"\"Test end_build_processing.\"\"\"\n    config = Config({\"param1@add1\": 0}, [process_add1])\n    config = end_build_processing(config)\n    check.equal(config.dict, {\"param1@add1\": 0, \"processing name\": \"ProcessAdd1\"})\n"]}
{"filename": "tests/unit/test_config_routines.py", "chunked_list": ["\"\"\"Tests for config.py.\"\"\"\nimport os\nimport shutil\nimport sys\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig.base import Config\nfrom cliconfig.config_routines import load_config, make_config, save_config, show_config", "from cliconfig.base import Config\nfrom cliconfig.config_routines import load_config, make_config, save_config, show_config\nfrom cliconfig.processing.base import Processing\n\n\ndef test_make_config(capsys: pytest.CaptureFixture, process_add1: Processing) -> None:\n    \"\"\"Test make_config.\"\"\"\n    sys_argv = sys.argv.copy()\n    sys.argv = [\n        \"tests/test_make_config.py.py\",\n        \"--config\",\n        \"tests/configs/config1.yaml,tests/configs/config2.yaml\",\n        \"--unknown\",\n        \"--param2@add1=6\",\n        \"--unknown2=8\",  # check that not error but a warning in console\n    ]\n    capsys.readouterr()  # Clear stdout and stderr\n    config = make_config(\n        \"tests/configs/default1.yaml\",\n        \"tests/configs/default2.yaml\",\n        process_list=[process_add1],\n        fallback=\"tests/configs/fallback.yaml\",\n    )\n    captured = capsys.readouterr()\n    out = captured.out\n    expected_config = {\n        \"param1\": 4,\n        \"param2\": 7,\n        \"param3\": 3,\n        \"letters\": {\n            \"letter1\": \"f\",\n            \"letter2\": \"e\",\n            \"letter3\": \"c\",\n            \"letter4\": \"d\",\n        },\n        \"processing name\": \"ProcessAdd1\",\n    }\n    expected_out = (\n        \"[CONFIG] Warning: New keys found in CLI parameters that will not be merged:\\n\"\n        \"  - unknown\\n\"\n        \"  - unknown2\\n\"\n        \"[CONFIG] Info: Merged 2 default config(s), \"\n        \"2 additional config(s) and 1 CLI parameter(s).\\n\"\n    )\n    check.equal(config.dict, expected_config)\n    check.equal(out, expected_out)\n\n    # No additional configs and fallback\n    sys.argv = [\n        \"tests/test_make_config.py.py\",\n    ]\n    config = make_config(\n        \"tests/configs/default1.yaml\",\n        \"tests/configs/default2.yaml\",\n        fallback=\"tests/configs/fallback.yaml\",\n    )\n    expected_config = {\n        \"param1\": 1,\n        \"param2\": -1,\n        \"param3\": 3,\n        \"letters\": {\n            \"letter1\": \"z\",\n            \"letter2\": \"b\",\n            \"letter3\": \"c\",\n            \"letter4\": \"d\",\n        },\n    }\n    check.equal(config.dict, expected_config)\n    config = make_config(add_default_processing=False)\n    check.equal(config.dict, {})\n    check.equal(config.process_list, [])\n\n    # No CLI\n    sys.argv = [\n        \"tests/test_make_config.py.py\",\n        \"--config\",\n        \"tests/configs/config1.yaml\",\n        \"--param2=6\",\n    ]\n    config = make_config(\n        \"tests/configs/default1.yaml\",\n        \"tests/configs/default2.yaml\",\n        fallback=\"tests/configs/fallback.yaml\",\n        no_cli=True,\n    )\n    expected_config = {\n        \"param1\": 1,\n        \"param2\": 2,\n        \"param3\": 3,\n        \"letters\": {\n            \"letter1\": \"a\",\n            \"letter2\": \"b\",\n            \"letter3\": \"c\",\n            \"letter4\": \"d\",\n        },\n    }\n\n    sys.argv = sys_argv.copy()", "\n\ndef test_load_config(process_add1: Processing) -> None:\n    \"\"\"Test and load_config.\"\"\"\n    # With default configs\n    config = load_config(\n        \"tests/configs/config2.yaml\",\n        default_config_paths=[\n            \"tests/configs/default1.yaml\",\n            \"tests/configs/default2.yaml\",\n        ],\n        process_list=[process_add1],\n    )\n    expected_config = {\n        \"param1\": 4,\n        \"param2\": 2,\n        \"param3\": 3,\n        \"letters\": {\n            \"letter1\": \"a\",\n            \"letter2\": \"e\",\n            \"letter3\": \"c\",\n            \"letter4\": \"d\",\n        },\n        \"processing name\": \"ProcessAdd1\",\n    }\n    check.equal(config.dict, expected_config)\n    # Additional keys when allow_new_keys=False\n    with pytest.raises(ValueError, match=\"New parameter found 'param3'.*\"):\n        load_config(\n            \"tests/configs/default2.yaml\",\n            default_config_paths=[\n                \"tests/configs/default1.yaml\",\n            ],\n        )", "\n\ndef test_show_config() -> None:\n    \"\"\"Test show_config.\"\"\"\n    show_config(Config({\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}, \"e\": \"f\"}, []))\n\n\ndef test_save_config() -> None:\n    \"\"\"Test save_config.\"\"\"\n    config = Config({\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}, \"e\": \"f\"}, [])\n    save_config(config, \"tests/tmp/config.yaml\")\n    check.is_true(os.path.exists(\"tests/tmp/config.yaml\"))\n    shutil.rmtree(\"tests/tmp\")", ""]}
{"filename": "tests/unit/test_tag_routines.py", "chunked_list": ["\"\"\"Test the tag routines.\"\"\"\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig.tag_routines import clean_all_tags, clean_tag, dict_clean_tags, is_tag_in\n\n\n@pytest.fixture()\ndef key1() -> str:\n    \"\"\"Return a key with many tags.\"\"\"\n    return \"abc@tag.def@tag_2.ghi@tag\"", "@pytest.fixture()\ndef key1() -> str:\n    \"\"\"Return a key with many tags.\"\"\"\n    return \"abc@tag.def@tag_2.ghi@tag\"\n\n\n@pytest.fixture()\ndef key2() -> str:\n    \"\"\"Return a key with many many tags.\"\"\"\n    return \"abc@hashtag@tagg@tag@tag 2@tag@ag.def@tag _.jkl@tag.mno@tag\"", "\n\ndef test_clean_tag(key1: str, key2: str) -> None:\n    \"\"\"Test clean_tag.\"\"\"\n    check.equal(\n        clean_tag(key1, \"tag\"),\n        \"abc.def@tag_2.ghi\",\n    )\n    check.equal(\n        clean_tag(key1, \"@tag\"),\n        \"abc.def@tag_2.ghi\",\n    )\n    check.equal(clean_tag(key2, \"tag\"), \"abc@hashtag@tagg@tag 2@ag.def@tag _.jkl.mno\")\n    check.equal(clean_tag(key2, \"@tag\"), \"abc@hashtag@tagg@tag 2@ag.def@tag _.jkl.mno\")", "\n\ndef test_clean_all_tags(key1: str, key2: str) -> None:\n    \"\"\"Test clean_all_tags.\"\"\"\n    check.equal(\n        clean_all_tags(key1),\n        \"abc.def.ghi\",\n    )\n    check.equal(\n        clean_all_tags(key2),\n        \"abc.def.jkl.mno\",\n    )", "\n\ndef test_dict_clean_tags(key1: str, key2: str) -> None:\n    \"\"\"Test dict_clean_tag.\"\"\"\n    in_dict = {\n        \"abc.def.pqr\": 0,\n        key1: 1,\n        key2: 2,\n    }\n    out_dict, tagged_keys = dict_clean_tags(in_dict)\n    check.equal(out_dict, {\"abc.def.pqr\": 0, \"abc.def.ghi\": 1, \"abc.def.jkl.mno\": 2})\n    check.is_true(key1 in tagged_keys)\n    check.is_true(key1 in tagged_keys)", "\n\ndef test_is_tag_in() -> None:\n    \"\"\"Test is_tag_in.\"\"\"\n    check.is_true(is_tag_in(\"config.config2.config3@tag\", \"tag\"))\n    check.is_false(is_tag_in(\"config.config2.config3@tag\", \"tog\"))\n    check.is_false(is_tag_in(\"config.config2.config3@tag_2\", \"tag\"))\n    check.is_false(is_tag_in(\"config.config2.config3@tag_2@tog\", \"tag\"))\n    check.is_true(is_tag_in(\"config.config2.config3@tag@tog\", \"@tag\"))\n    check.is_true(is_tag_in(\"config.config2.config3@tag@tog\", \"@tog\"))\n    check.is_true(is_tag_in(\"config.config2@tag.config3@tog\", \"tag\", full_key=True))\n    check.is_false(is_tag_in(\"config.config2@tag.config3@tog\", \"tag\", full_key=False))", ""]}
{"filename": "tests/unit/test_base_config.py", "chunked_list": ["\"\"\"Test base class of configuration.\"\"\"\n\nimport pytest_check as check\n\nfrom cliconfig.base import Config\nfrom cliconfig.dict_routines import unflatten\nfrom cliconfig.processing.base import Processing\n\n\ndef test_config(process_add1: Processing) -> None:\n    \"\"\"Test base class of configuration.\"\"\"\n    config_dict = {\"a.b\": 1, \"b\": 2, \"c.d.e\": 3, \"c.d.f\": [2, 3]}\n    config_dict = unflatten(config_dict)\n    config = Config(config_dict, [process_add1])\n    check.equal(config.dict, config_dict)\n    check.equal(config.process_list, [process_add1])\n    check.equal(repr(config), f\"Config({config_dict}, ['ProcessAdd1'])\")\n    config_dict2 = {\"c.d.e\": 3, \"a.b\": 1, \"b\": 2, \"c.d.f\": [2, 3]}\n    config_dict2 = unflatten(config_dict2)\n    config2 = Config(config_dict2, [process_add1])\n    check.equal(config, config2)\n    config3 = Config(config_dict2, [process_add1, process_add1])\n    check.not_equal(config, config3)\n    config4 = Config(config_dict2, [])\n    check.not_equal(config, config4)\n    # Test get/set attribute\n    config = Config(config_dict, [process_add1])\n    check.equal(config.a.b, 1)\n    check.equal(config.c.d.f, [2, 3])\n    check.equal(config.c.d, Config({\"e\": 3, \"f\": [2, 3]}, [process_add1]))\n    config.a.b = 2\n    check.equal(config.a.b, 2)\n    config.c.d.f = [3, 4]\n    check.equal(config.c.d.f, [3, 4])\n    config.c.d.f.append(5)\n    check.equal(config.c.d.f, [3, 4, 5])\n    # Test delete attribute\n    del config.a.b\n    check.equal(config.dict, {\"a\": {}, \"b\": 2, \"c\": {\"d\": {\"e\": 3, \"f\": [3, 4, 5]}}})\n    del config.c.d\n    check.equal(config.dict, {\"a\": {}, \"b\": 2, \"c\": {}})\n    # Should no raise error\n    del config.dict\n    del config.process_list", "\ndef test_config(process_add1: Processing) -> None:\n    \"\"\"Test base class of configuration.\"\"\"\n    config_dict = {\"a.b\": 1, \"b\": 2, \"c.d.e\": 3, \"c.d.f\": [2, 3]}\n    config_dict = unflatten(config_dict)\n    config = Config(config_dict, [process_add1])\n    check.equal(config.dict, config_dict)\n    check.equal(config.process_list, [process_add1])\n    check.equal(repr(config), f\"Config({config_dict}, ['ProcessAdd1'])\")\n    config_dict2 = {\"c.d.e\": 3, \"a.b\": 1, \"b\": 2, \"c.d.f\": [2, 3]}\n    config_dict2 = unflatten(config_dict2)\n    config2 = Config(config_dict2, [process_add1])\n    check.equal(config, config2)\n    config3 = Config(config_dict2, [process_add1, process_add1])\n    check.not_equal(config, config3)\n    config4 = Config(config_dict2, [])\n    check.not_equal(config, config4)\n    # Test get/set attribute\n    config = Config(config_dict, [process_add1])\n    check.equal(config.a.b, 1)\n    check.equal(config.c.d.f, [2, 3])\n    check.equal(config.c.d, Config({\"e\": 3, \"f\": [2, 3]}, [process_add1]))\n    config.a.b = 2\n    check.equal(config.a.b, 2)\n    config.c.d.f = [3, 4]\n    check.equal(config.c.d.f, [3, 4])\n    config.c.d.f.append(5)\n    check.equal(config.c.d.f, [3, 4, 5])\n    # Test delete attribute\n    del config.a.b\n    check.equal(config.dict, {\"a\": {}, \"b\": 2, \"c\": {\"d\": {\"e\": 3, \"f\": [3, 4, 5]}}})\n    del config.c.d\n    check.equal(config.dict, {\"a\": {}, \"b\": 2, \"c\": {}})\n    # Should no raise error\n    del config.dict\n    del config.process_list", ""]}
{"filename": "tests/unit/test_dict_routines.py", "chunked_list": ["\"\"\"Tests for dict routines.\"\"\"\nimport os\nimport shutil\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig.dict_routines import (\n    _del_key,\n    clean_pre_flat,", "    _del_key,\n    clean_pre_flat,\n    flatten,\n    load_dict,\n    merge_flat,\n    merge_flat_paths,\n    save_dict,\n    show_dict,\n    unflatten,\n)", "    unflatten,\n)\n\n\ndef test_flatten() -> None:\n    \"\"\"Test flatten(.\"\"\"\n    check.equal(\n        flatten({\"a.b\": 1, \"a\": {\"c\": 2}, \"d\": 3}),\n        {\"a.b\": 1, \"a.c\": 2, \"d\": 3},\n    )\n    check.equal(\n        flatten({\"a.b\": {\"c\": 1}, \"a\": {\"b.d\": 2}, \"a.e\": {\"f.g\": 3}}),\n        {\"a.b.c\": 1, \"a.b.d\": 2, \"a.e.f.g\": 3},\n    )\n    check.equal(\n        flatten({\"a.b\": 1, \"a\": {\"c\": {}}, \"a.c\": 3}),\n        {\"a.b\": 1, \"a.c\": 3},\n    )\n    with pytest.raises(ValueError, match=\"duplicated key 'a.b'\"):\n        flatten({\"a.b\": 1, \"a\": {\"b\": 1}})", "\n\ndef test_unflatten() -> None:\n    \"\"\"Test unflatten.\"\"\"\n    check.equal(\n        unflatten({\"a.b\": 1, \"a.c\": 2, \"c\": 3}),\n        {\"a\": {\"b\": 1, \"c\": 2}, \"c\": 3},\n    )\n    with pytest.raises(ValueError, match=\"The dict must be flatten.*\"):\n        unflatten({\"a.b\": 1, \"a\": {\"c\": 2}})", "\n\ndef test_merge_flat() -> None:\n    \"\"\"Test merge_flat.\"\"\"\n    dict1 = {\"a.b\": 1, \"a\": {\"c\": 2}}\n    dict2 = {\"c\": 3}\n    check.equal(\n        merge_flat(dict1, dict2, allow_new_keys=True),\n        {\"a.b\": 1, \"a.c\": 2, \"c\": 3},\n    )\n    with pytest.raises(ValueError, match=\"New parameter found 'c'.*\"):\n        merge_flat(dict1, dict2, allow_new_keys=False)\n    dict1 = {\"a.b\": 1, \"a\": {\"b\": 1, \"c\": 2}}\n    with pytest.raises(\n        ValueError,\n        match=\"Duplicated key found.*You may consider calling 'clean_pre_flat'.*\",\n    ):\n        merge_flat(dict1, dict2, allow_new_keys=True)", "\n\ndef test_merge_flat_paths() -> None:\n    \"\"\"Test merge_flat_paths.\"\"\"\n    dict1 = {\n        \"param1\": 1,\n        \"param2\": 2,\n        \"letters\": {\n            \"letter1\": \"a\",\n            \"letter2\": \"b\",\n        },\n    }\n    dict2 = {\n        \"param3\": 3,\n        \"letters\": {\n            \"letter3\": \"c\",\n            \"letter4\": \"d\",\n        },\n    }\n    expected_dict = {\n        \"param1\": 1,\n        \"param2\": 2,\n        \"param3\": 3,\n        \"letters.letter1\": \"a\",\n        \"letters.letter2\": \"b\",\n        \"letters.letter3\": \"c\",\n        \"letters.letter4\": \"d\",\n    }\n\n    flat_dict = merge_flat_paths(\n        \"tests/configs/default1.yaml\",\n        \"tests/configs/default2.yaml\",\n        allow_new_keys=True,\n    )\n    check.equal(flat_dict, expected_dict)\n    flat_dict = merge_flat_paths(dict1, dict2, allow_new_keys=True)\n    check.equal(flat_dict, expected_dict)\n    flat_dict = merge_flat_paths(\n        dict1, \"tests/configs/default2.yaml\", allow_new_keys=True\n    )\n    check.equal(flat_dict, expected_dict)\n    with pytest.raises(ValueError, match=\"New parameter found 'param3'.*\"):\n        merge_flat_paths(\n            \"tests/configs/default1.yaml\",\n            \"tests/configs/default2.yaml\",\n            allow_new_keys=False,\n        )", "\n\ndef test_del_key() -> None:\n    \"\"\"Test _del_key.\"\"\"\n    in_dict = {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}\n    _del_key(in_dict, \"a.b.c\")\n    check.equal(in_dict, {\"a\": {\"d\": 2}, \"a.e\": 3})\n\n    in_dict = {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}\n    _del_key(in_dict, \"a.b.c\", keep_flat=True)\n    check.equal(in_dict, {\"a\": {\"d\": 2}, \"a.e\": 3, \"a.b.c\": 4})\n\n    in_dict = {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}\n    _del_key(in_dict, \"a.b.c\", keep_unflat=True)\n    check.equal(in_dict, {\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3})\n\n    with pytest.raises(ValueError, match=\"Key 'a.b.z' not found in dict.\"):\n        _del_key({\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}, \"a.b.z\")\n    with pytest.raises(ValueError, match=\"Key 'a.z.c' not found in dict.\"):\n        _del_key({\"a\": {\"b\": {\"c\": 1}, \"d\": 2}, \"a.e\": 3, \"a.b.c\": 4}, \"a.z.c\")", "\n\ndef test_clean_pre_flat() -> None:\n    \"\"\"Test clean_pre_flat.\"\"\"\n    check.equal(\n        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"flat\"),\n        {\"a.b\": 1, \"c\": 3},\n    )\n    check.equal(\n        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"unflat\"),\n        {\"a\": {\"b\": 2}, \"c\": 3},\n    )\n    with pytest.raises(ValueError, match=\"duplicated key 'a.b'\"):\n        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"error\")\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"priority argument must be one of 'flat', 'unflat' or 'error' but \"\n            \"found 'UNKNOWN'\"\n        ),\n    ):\n        clean_pre_flat({\"a.b\": 1, \"a\": {\"b\": 2}, \"c\": 3}, priority=\"UNKNOWN\")", "\n\ndef test_save_load_dict() -> None:\n    \"\"\"Test save_dict and load_dict.\"\"\"\n    dict1 = {\"a\": 1, \"b\": {\"c\": 2}, \"d\": [2, 3.0], \"e\": [{\"f\": 4}]}\n    save_dict(dict1, \"tests/tmp/config.yaml\")\n    check.is_true(os.path.isfile(\"tests/tmp/config.yaml\"))\n    dict2 = load_dict(\"tests/tmp/config.yaml\")\n    check.equal(dict1, dict2)\n    # Case multiple files and yaml tags\n    out_dict = load_dict(\"tests/configs/multi_files_with_tags.yaml\")\n    expected_dict = {\n        \"config@cfg\": {\n            \"param1@par@other\": 1,\n            \"param2\": {\"a\": 1.0, \"b@par2\": \"2.1\"},\n        },\n        \"config2\": {\n            \"param3@par3\": 3.2,\n            \"param4@par4\": [4, 5, {\"6\": 6}],\n            \"param5\": [True, 8],\n        },\n        \"config3@cfg3\": {\"param6\": {\"param7@par7\": None}, \"param8\": \"True\"},\n        \"config4@cfg4\": {\"config5@cfg5\": {\"param9\": \"11\"}},\n    }\n    check.equal(out_dict, expected_dict)\n    shutil.rmtree(\"tests/tmp\")", "\n\ndef test_show_dict() -> None:\n    \"\"\"Test show_dict.\"\"\"\n    in_dict = {\n        \"model\": {\n            \"s1_ae_config\": {\n                \"in_dim\": 2,\n                \"out_dim\": 1,\n                \"layer_channels\": [16, 32, 64],\n                \"conv_per_layer\": 1,\n                \"residual\": False,\n                \"dropout_rate\": 0.0,\n            },\n            \"mask_module_dim\": [6, 2],\n            \"glob_module_dims\": [2, 8, 2],\n            \"conv_block_dims\": [32, 64, 128],\n        },\n        \"train\": {\n            \"n_epochs\": 100,\n            \"optimizer\": {\n                \"name\": \"Adam\",\n                \"lr\": 0.001,\n                \"weight_decay\": 0.0,\n                \"warmup_steps\": 0,\n            },\n        },\n        \"data\": {\n            \"dataset\": \"mnist\",\n            \"batch_size\": 128,\n            \"num_workers\": 6,\n        },\n    }\n    show_dict(in_dict)", ""]}
{"filename": "tests/unit/processing/test_base_processing.py", "chunked_list": ["\"\"\"Test base class of processing.\"\"\"\n\nimport pytest_check as check\n\nfrom cliconfig.base import Config\nfrom cliconfig.processing.base import Processing\n\n\ndef test_processing() -> None:\n    \"\"\"Test Processing.\"\"\"\n\n    class _ProcessingTest(Processing):\n        def __init__(self) -> None:\n            super().__init__()\n            self.attr = 0\n\n    config = Config({\"a.b\": 1, \"b\": 2, \"c.d.e\": 3, \"c.d.f\": [2, 3]}, [])\n    base_process = Processing()\n    check.equal(\n        (\n            base_process.premerge(config),\n            base_process.postmerge(config),\n            base_process.endbuild(config),\n            base_process.presave(config),\n            base_process.postload(config),\n        ),\n        (config, config, config, config, config),\n    )\n    # Check equality of Processing objects\n    proc1 = _ProcessingTest()\n    proc1.attr = 0\n    proc2 = _ProcessingTest()\n    proc2.attr = 0\n    check.equal(proc1, proc2)\n    proc2.attr = 1\n    check.not_equal(proc1, proc2)", "def test_processing() -> None:\n    \"\"\"Test Processing.\"\"\"\n\n    class _ProcessingTest(Processing):\n        def __init__(self) -> None:\n            super().__init__()\n            self.attr = 0\n\n    config = Config({\"a.b\": 1, \"b\": 2, \"c.d.e\": 3, \"c.d.f\": [2, 3]}, [])\n    base_process = Processing()\n    check.equal(\n        (\n            base_process.premerge(config),\n            base_process.postmerge(config),\n            base_process.endbuild(config),\n            base_process.presave(config),\n            base_process.postload(config),\n        ),\n        (config, config, config, config, config),\n    )\n    # Check equality of Processing objects\n    proc1 = _ProcessingTest()\n    proc1.attr = 0\n    proc2 = _ProcessingTest()\n    proc2.attr = 0\n    check.equal(proc1, proc2)\n    proc2.attr = 1\n    check.not_equal(proc1, proc2)", ""]}
{"filename": "tests/unit/processing/test_builtin.py", "chunked_list": ["\"\"\"Test built-in processing classes.\"\"\"\nimport re\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig.base import Config\nfrom cliconfig.dict_routines import flatten\nfrom cliconfig.processing.builtin import (\n    DefaultProcessings,", "from cliconfig.processing.builtin import (\n    DefaultProcessings,\n    ProcessCheckTags,\n    ProcessCopy,\n    ProcessDelete,\n    ProcessMerge,\n    ProcessNew,\n    ProcessSelect,\n    ProcessTyping,\n)", "    ProcessTyping,\n)\n\n\ndef test_process_merge() -> None:\n    \"\"\"Test ProcessMerge.\"\"\"\n    # Test @merge_add\n    processing = ProcessMerge()\n    flat_dict = {\n        \"config1.param1\": 0,\n        \"config1.param2\": 1,\n        \"config2_path@merge_add\": \"tests/configs/merge/default2.yaml\",\n    }\n    flat_config = Config(flat_dict, [processing])\n    flat_config = processing.premerge(flat_config)\n    expected_dict = {\n        \"config1.param1\": 0,\n        \"config1.param2\": 1,\n        \"config2.param1\": 2,\n        \"config2.param2\": 3,\n        \"config3.param1\": 4,\n        \"config3.param2\": 5,\n        \"config2_path\": \"tests/configs/merge/default2.yaml\",\n        \"config3_path\": \"tests/configs/merge/default3.yaml\",\n    }\n    check.equal(flat_config.dict, expected_dict)\n\n    # Case of introducing a new key\n    flat_dict = {\n        \"config1.param1\": 0,\n        \"config1.param2\": 1,\n        \"config3.param1\": 4,\n        \"config2_path@merge_add\": \"tests/configs/merge/default2.yaml\",\n    }\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"@merge_add doest not allow to add \"\n            \"already existing keys but key 'config3.param1'.*\"\n        ),\n    ):\n        processing.premerge(Config(flat_dict, [processing]))\n\n    # Test @merge_before and @merge_after\n    flat_dict = {\n        \"a.b\": 1,\n        \"a.b_path@merge_after\": \"tests/configs/merge/additional2.yaml\",\n    }\n    flat_config = Config(flat_dict, [processing])\n    flat_config = processing.premerge(flat_config)\n    expected_dict = {\n        \"a.b\": 2,\n        \"a.b_path\": \"tests/configs/merge/additional2.yaml\",\n        \"c_path\": \"tests/configs/merge/additional3.yaml\",\n        \"c\": 3,\n    }\n    check.equal(flat_config.dict, expected_dict)\n    flat_dict = {\n        \"a.b\": 1,\n        \"a.b_path@merge_before\": \"tests/configs/merge/additional2.yaml\",\n        \"c\": 3,\n    }\n    flat_config = Config(flat_dict, [processing])\n    flat_config = processing.premerge(flat_config)\n    expected_dict = {\n        \"a.b\": 1,\n        \"a.b_path\": \"tests/configs/merge/additional2.yaml\",\n        \"c_path\": \"tests/configs/merge/additional3.yaml\",\n        \"c\": 3,\n    }\n    check.equal(flat_config.dict, expected_dict)\n    check.equal(flat_config.process_list, [processing])\n\n    # Not valid path\n    for tag in [\"merge_before\", \"merge_after\", \"merge_add\"]:\n        with pytest.raises(\n            ValueError,\n            match=re.escape(\n                f\"Key with '@{tag}' tag must be associated \"\n                \"to a string corresponding to a *yaml* file.\"\n                f\"The problem occurs at key: a@{tag}\"\n            ),\n        ):\n            processing.premerge(Config({f\"a@{tag}\": \"no_yaml\"}, [processing]))", "\n\ndef test_process_copy() -> None:\n    \"\"\"Test ProcessCopy.\"\"\"\n    processing = ProcessCopy()\n    flat_dict = {\n        \"config1.param1\": 1,\n        \"config2.param2@copy\": \"config1.param1\",\n    }\n    flat_config = Config(flat_dict, [processing])\n    flat_config = processing.premerge(flat_config)\n    check.equal(\n        flat_config.dict, {\"config1.param1\": 1, \"config2.param2\": \"config1.param1\"}\n    )\n    flat_config.dict[\"config1.param1\"] = 2\n    flat_config = processing.postmerge(flat_config)\n    check.equal(flat_config.dict, {\"config1.param1\": 2, \"config2.param2\": 2})\n    check.equal(processing.copied_keys, {\"config2.param2\"})\n    flat_config = processing.presave(flat_config)\n    check.equal(processing.current_value, {\"config2.param2\": 2})\n    check.equal(\n        flat_config.dict, {\"config1.param1\": 2, \"config2.param2@copy\": \"config1.param1\"}\n    )\n    check.equal(processing.keys_to_copy, {\"config2.param2\": \"config1.param1\"})\n    check.equal(flat_config.process_list, [processing])\n    # Reset copy processing\n    processing.keys_to_copy = {}\n    # Case of wrong key\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"Key with '@copy' tag must be associated \"\n            \"to a string corresponding to a flat key. \"\n            \"The problem occurs at key: a@copy with value: True\"\n        ),\n    ):\n        processing.premerge(Config({\"a@copy\": True}, [processing]))\n    # Case of already existing @copy but associated to an other key\n    processing.keys_to_copy = {\"a\": \"b\"}\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"Key with '@copy' has change its value to copy. Found key: a@copy@tag \"\n            \"with value: c, previous value to copy: b\"\n        ),\n    ):\n        processing.premerge(Config({\"a@copy@tag\": \"c\"}, [processing]))\n    # Case of non-existing key (on post-merge): do not raise error\n    processing.keys_to_copy = {\"a\": \"b\"}\n    processing.postmerge(Config({\"a\": \"b\"}, [processing]))\n    # Case of non-existing key (on end-build): raise error\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"A key with '@copy' tag has been found but the key to copy does not \"\n            \"exist at the end of the build and it has been never copied. Found key: \"\n            \"a that would copy the key: b.\"\n        ),\n    ):\n        processing.endbuild(Config({\"a\": \"b\"}, [processing]))\n    # Copy if it appears on end-build\n    config = processing.endbuild(Config({\"a\": \"b\", \"b\": 3}, [processing]))\n    check.equal(config.dict[\"a\"], 3)\n    # Case overwriting a key\n    processing.current_value = {\"a\": 2}\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"Found attempt to modify a key with '@copy' tag. The key is \"\n            \"protected against direct updates. Found key: a of value c that copy \"\n            \"b of value 1\"\n        ),\n    ):\n        processing.postmerge(Config({\"a\": \"c\", \"b\": 1}, [processing]))", "\n\ndef test_process_typing() -> None:\n    \"\"\"Test ProcessTyping.\"\"\"\n    processing = ProcessTyping()\n    flat_dict = {\n        \"param1@type:int\": 1,\n        \"param2@type:List[Optional[Dict[str, int|float]]]\": [{\"a\": [0.0]}],\n    }\n    flat_config = Config(flat_dict, [processing])\n    flat_config = processing.premerge(flat_config)\n    flat_config.dict[\"param1\"] = 3\n    flat_config.dict[\"param2\"] = {\"a\": None, \"b\": [{\"c\": 1}]}\n    flat_config.dict = flatten(flat_config.dict)\n    flat_config = processing.postmerge(flat_config)\n    check.equal(\n        flat_config.dict, {\"param1\": 3, \"param2.a\": None, \"param2.b\": [{\"c\": 1}]}\n    )\n    check.equal(\n        flat_config.process_list[0].forced_types,  # type: ignore\n        {\n            \"param1\": (int,),\n            \"param2\": ((\"list\", ((type(None), (\"dict\", (str,), (int, float))),)),),\n        },\n    )\n    check.equal(\n        flat_config.process_list[0].type_desc,  # type: ignore\n        {\"param1\": \"int\", \"param2\": \"List[Optional[Dict[str, int|float]]]\"},\n    )\n    flat_config = processing.endbuild(flat_config)  # no error\n    flat_config = processing.presave(flat_config)\n    check.equal(\n        flat_config.dict,\n        {\"param1@type:int\": 3, \"param2.a\": None, \"param2.b\": [{\"c\": 1}]},\n    )\n    processing.forced_types = {}  # Reset forced types\n    processing.type_desc = {}  # Reset type description\n\n    # Case of different type on pre-merge: do not raise error!\n    processing.premerge(Config({\"param@type:int\": \"str\"}, [processing]))\n\n    # Case of already existing type and othere in premerge\n    processing.forced_types = {\"param\": (int,)}\n    processing.type_desc = {\"param\": \"int\"}\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"Find the tag '@type:str' on a key that has already been associated \"\n            \"to an other type: int. Find problem at key: param@type:str\"\n        ),\n    ):\n        processing.premerge(Config({\"param@type:str\": \"str\"}, [processing]))\n\n    # Case of wrong type in post-merge: no error\n    processing.forced_types = {\"param\": (int,)}\n    processing.type_desc = {\"param\": \"int\"}\n    processing.postmerge(Config({\"param\": \"mystr\"}, [processing]))\n    # Case of wrong type in end-build: raise error\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"Key previously tagged with '@type:int' must be \"\n            \"associated to a value of type int. Find the \"\n            \"value: mystr of type <class 'str'> at key: param\"\n        ),\n    ):\n        processing.endbuild(Config({\"param\": \"mystr\"}, [processing]))", "\n\ndef test_process_select() -> None:\n    \"\"\"Test ProcessSelect.\"\"\"\n    processing = ProcessSelect()\n    flat_dict = {\n        \"models.model_names@select\": [\"models.model1\", \"models.model3\"],\n        \"models.model1.param1\": 1,\n        \"models.model1.param2\": 2,\n        \"models.model2.param1\": 3,\n        \"models.model2.param2\": 4,\n        \"models.model3.submodel.param\": 5,\n        \"models.model4.param\": 6,\n    }\n    expected_dict = {\n        \"models.model_names\": [\"models.model1\", \"models.model3\"],\n        \"models.model1.param1\": 1,\n        \"models.model1.param2\": 2,\n        \"models.model3.submodel.param\": 5,\n    }\n    config = Config(flat_dict, [])\n    config = processing.premerge(config)\n    config = processing.postmerge(config)\n    check.equal(config.dict, expected_dict)\n    config = processing.presave(config)\n    check.is_in(\"models.model_names@select\", config.dict)\n    check.equal(\n        config.dict[\"models.model_names@select\"], [\"models.model1\", \"models.model3\"]\n    )\n    check.is_not_in(\"models.model_names\", config.dict)\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"The keys in the list of parameters tagged with '@select' must be \"\n            \"identical before the last dot (= on the same subconfig). Find: \"\n            \"abab and dede before the last dot.\"\n        ),\n    ):\n        processing.premerge(Config({\"p@select\": [\"abab.cdcd\", \"dede.fgfg\"]}, []))\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"The value of parameters tagged with '@select' must be a string or a \"\n            \"list of strings representing flat key(s). \"\n        ),\n    ):\n        processing.premerge(Config({\"p@select\": 0}, []))\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"Find attempt to delete the configuration at the root. You must pass a \"\n            \"flat key with a least one dot on parameter tagged with @select. \"\n            \"Find key: p@select with value: root\"\n        ),\n    ):\n        processing.premerge(Config({\"p@select\": \"root\"}, []))", "\n\ndef test_process_delete() -> None:\n    \"\"\"Test ProcessDelete.\"\"\"\n    processing = ProcessDelete()\n    config = Config(\n        {\n            \"@select@delete\": \"configs.config1\",\n            \"1@merge_add@delete\": \"config1.yaml\",\n            \"2@merge_add@delete\": \"config2.yaml\",\n        },\n        [processing],\n    )\n    config = processing.premerge(config)\n    check.equal(config.dict, {})", "\n\ndef test_process_new() -> None:\n    \"\"\"Test ProcessNew.\"\"\"\n    processing = ProcessNew()\n    flat_dict = {\n        \"param1\": 1,\n        \"config1\": {\n            \"param2\": 2,\n            \"subconfig@new\": {\"param3\": 3, \"param4\": 4},\n        },\n        \"config2@new@tag.subconfig.param3\": 3,\n        \"config3.subconfig@new.param4\": 4,\n    }\n    flat_dict = flatten(flat_dict)\n    config = Config(flat_dict, [processing])\n    check.equal(\n        processing.premerge(config).dict,\n        {\n            \"param1\": 1,\n            \"config1.param2\": 2,\n        },\n    )\n    check.equal(\n        processing.postmerge(config).dict,\n        {\n            \"param1\": 1,\n            \"config1.param2\": 2,\n            \"config1.subconfig.param3\": 3,\n            \"config1.subconfig.param4\": 4,\n            \"config2.subconfig.param3\": 3,\n            \"config3.subconfig.param4\": 4,\n        },\n    )\n    check.equal(\n        processing.presave(config).dict,\n        {\n            \"param1\": 1,\n            \"config1.param2\": 2,\n            \"config1.subconfig.param3@new\": 3,\n            \"config1.subconfig.param4@new\": 4,\n            \"config2.subconfig.param3@new\": 3,\n            \"config3.subconfig.param4@new\": 4,\n        },\n    )", "\n\ndef test_process_check_tags() -> None:\n    \"\"\"Test ProcessCheckTags.\"\"\"\n    processing = ProcessCheckTags()\n    flat_dict = {\n        \"config.param1\": 1,\n        \"param1\": 2,\n    }\n    config = Config(flat_dict, [processing])\n    check.equal(processing.premerge(config).dict, flat_dict)\n\n    flat_dicts = [{\"param1@tag\": 1}, {\"@foo\": 2}, {\"@\": 3}]\n    for flat_dict in flat_dicts:\n        with pytest.raises(\n            ValueError,\n            match=(\n                \"Keys with tags are encountered at the end of \"\n                \"the pre-merge process.*\"\n            ),\n        ):\n            processing.premerge(Config(flat_dict, [processing]))", "\n\ndef test_default_processings() -> None:\n    \"\"\"Test DefaultProcessings.\"\"\"\n    config = Config({}, DefaultProcessings().list)\n    for proc in [\n        ProcessCheckTags(),\n        ProcessMerge(),\n        ProcessCopy(),\n        ProcessTyping(),\n        ProcessDelete(),\n        ProcessSelect(),\n        ProcessNew(),\n    ]:\n        check.is_in(proc, config.process_list)", ""]}
{"filename": "tests/unit/processing/test_type_parser.py", "chunked_list": ["\"\"\"Test the type parser module.\"\"\"\nimport re\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig.processing._type_parser import (\n    _isinstance,\n    _parse_dict,\n    _parse_list,", "    _parse_dict,\n    _parse_list,\n    _parse_optional,\n    _parse_type,\n    _parse_union,\n)\n\n\ndef test_type_parser_isinstance() -> None:\n    \"\"\"Test _parse_type and _isinstance.\"\"\"\n    type_ = _parse_type(\"None\")\n    check.equal(type_, (type(None),))\n    check.is_true(_isinstance(None, type_))\n    check.is_false(_isinstance([None], type_))\n\n    type_ = _parse_type(\"List[float]\")\n    check.equal(type_, ((\"list\", (float,)),))\n\n    type_ = _parse_type(\"list|dict\")\n    check.equal(type_, (list, dict))\n    check.is_true(_isinstance([2.0, True], type_))\n\n    type_ = _parse_type(\"Dict[str, List[float]]\")\n    check.equal(type_, ((\"dict\", (str,), ((\"list\", (float,)),)),))\n    check.is_true(_isinstance({\"a\": [1.0, 2.0]}, type_))\n    check.is_false(_isinstance({\"a\": [1.0, 2.0], \"b\": [1.0, 2]}, type_))\n\n    type_ = _parse_type(\"Dict[str|bool, int|float]\")\n    check.equal(type_, ((\"dict\", (str, bool), (int, float)),))\n\n    type_ = _parse_type(\"Union[Optional[float], Any]\")\n    check.equal(type_, ((type(None), float), object))\n    check.is_true(_isinstance(\"2\", type_))\n\n    type_ = _parse_type(\n        \"Dict[str, Union[List[None|float], Dict[bool, Optional[list]]]]|List[Any]|\"\n        \"Dict[int, Optional[Dict[str, float]]]|Optional[float]\"\n    )\n    check.equal(\n        (\n            (\n                \"dict\",\n                (str,),\n                (\n                    (\"list\", (type(None), float)),\n                    (\"dict\", (bool,), ((type(None), list),)),\n                ),\n            ),\n            (\"list\", (object,)),\n            (\"dict\", (int,), ((type(None), (\"dict\", (str,), (float,))),)),\n            (type(None), float),\n        ),\n        type_,\n    )\n    check.is_true(_isinstance({\"a\": [None, 1.0], \"b\": {True: None}}, type_))\n    check.is_true(_isinstance([[]], type_))\n    check.is_true(_isinstance({1: {\"a\": 2.0}}, type_))\n    check.is_false(_isinstance({\"a\": [None, 1.0], \"b\": {False: 1, True: \"1\"}}, type_))\n\n    # Wrong type description\n    with pytest.raises(ValueError, match=\"Unknown type: 'unknown'\"):\n        _parse_type(\"unknown\")\n    desc = \"str, List[float]\"\n    with pytest.raises(ValueError, match=re.escape(f\"Unknown type: '{desc}'\")):\n        _parse_type(desc)\n    desc = \"None||float\"\n    with pytest.raises(ValueError, match=f\"Unknown type: '{desc}'\"):\n        _parse_type(desc)\n    desc = (\n        \"Dict[str, Union[List[None|float], Dict[bool, Optionnal[int]]]]|List[Any]|\"\n        \"Dict[List[int], Optional[Dict[str, float]]]|float\"\n    )  # Optionnal with 2 n\n    with pytest.raises(ValueError, match=f\"Unknown type: '{desc}'\"):\n        _parse_type(desc)\n\n    # Wrong type in isinstance (here a 'dict' tuple has 3 elements instead of 2)\n    wrong_type = (\n        (\n            \"dict\",\n            (str,),\n            (\n                (\"list\", (type(None), float)),\n                (\"dict\", (bool,), ((type(None), list),), str),\n            ),\n        ),\n        (\"list\", (object,)),\n        (\"dict\", (int,), ((type(None), (\"dict\", (str,), (float,))),)),\n        (type(None), float),\n    )\n    with pytest.raises(ValueError, match=\"Invalid type for _isinstance:.*\"):\n        _isinstance({\"a\": {True: \"a\"}}, wrong_type)", "def test_type_parser_isinstance() -> None:\n    \"\"\"Test _parse_type and _isinstance.\"\"\"\n    type_ = _parse_type(\"None\")\n    check.equal(type_, (type(None),))\n    check.is_true(_isinstance(None, type_))\n    check.is_false(_isinstance([None], type_))\n\n    type_ = _parse_type(\"List[float]\")\n    check.equal(type_, ((\"list\", (float,)),))\n\n    type_ = _parse_type(\"list|dict\")\n    check.equal(type_, (list, dict))\n    check.is_true(_isinstance([2.0, True], type_))\n\n    type_ = _parse_type(\"Dict[str, List[float]]\")\n    check.equal(type_, ((\"dict\", (str,), ((\"list\", (float,)),)),))\n    check.is_true(_isinstance({\"a\": [1.0, 2.0]}, type_))\n    check.is_false(_isinstance({\"a\": [1.0, 2.0], \"b\": [1.0, 2]}, type_))\n\n    type_ = _parse_type(\"Dict[str|bool, int|float]\")\n    check.equal(type_, ((\"dict\", (str, bool), (int, float)),))\n\n    type_ = _parse_type(\"Union[Optional[float], Any]\")\n    check.equal(type_, ((type(None), float), object))\n    check.is_true(_isinstance(\"2\", type_))\n\n    type_ = _parse_type(\n        \"Dict[str, Union[List[None|float], Dict[bool, Optional[list]]]]|List[Any]|\"\n        \"Dict[int, Optional[Dict[str, float]]]|Optional[float]\"\n    )\n    check.equal(\n        (\n            (\n                \"dict\",\n                (str,),\n                (\n                    (\"list\", (type(None), float)),\n                    (\"dict\", (bool,), ((type(None), list),)),\n                ),\n            ),\n            (\"list\", (object,)),\n            (\"dict\", (int,), ((type(None), (\"dict\", (str,), (float,))),)),\n            (type(None), float),\n        ),\n        type_,\n    )\n    check.is_true(_isinstance({\"a\": [None, 1.0], \"b\": {True: None}}, type_))\n    check.is_true(_isinstance([[]], type_))\n    check.is_true(_isinstance({1: {\"a\": 2.0}}, type_))\n    check.is_false(_isinstance({\"a\": [None, 1.0], \"b\": {False: 1, True: \"1\"}}, type_))\n\n    # Wrong type description\n    with pytest.raises(ValueError, match=\"Unknown type: 'unknown'\"):\n        _parse_type(\"unknown\")\n    desc = \"str, List[float]\"\n    with pytest.raises(ValueError, match=re.escape(f\"Unknown type: '{desc}'\")):\n        _parse_type(desc)\n    desc = \"None||float\"\n    with pytest.raises(ValueError, match=f\"Unknown type: '{desc}'\"):\n        _parse_type(desc)\n    desc = (\n        \"Dict[str, Union[List[None|float], Dict[bool, Optionnal[int]]]]|List[Any]|\"\n        \"Dict[List[int], Optional[Dict[str, float]]]|float\"\n    )  # Optionnal with 2 n\n    with pytest.raises(ValueError, match=f\"Unknown type: '{desc}'\"):\n        _parse_type(desc)\n\n    # Wrong type in isinstance (here a 'dict' tuple has 3 elements instead of 2)\n    wrong_type = (\n        (\n            \"dict\",\n            (str,),\n            (\n                (\"list\", (type(None), float)),\n                (\"dict\", (bool,), ((type(None), list),), str),\n            ),\n        ),\n        (\"list\", (object,)),\n        (\"dict\", (int,), ((type(None), (\"dict\", (str,), (float,))),)),\n        (type(None), float),\n    )\n    with pytest.raises(ValueError, match=\"Invalid type for _isinstance:.*\"):\n        _isinstance({\"a\": {True: \"a\"}}, wrong_type)", "\n\ndef test_errors_in_parse() -> None:\n    \"\"\"Test error raised in _parse_X functions.\"\"\"\n    with pytest.raises(ValueError, match=\"Invalid List type:.*\"):\n        _parse_list(\"List[bool, str]\")\n\n    with pytest.raises(ValueError, match=\"Invalid Dict type:.*\"):\n        _parse_dict(\"Dict[str, bool, int]]\")\n\n    with pytest.raises(ValueError, match=\"Invalid Union type:.*\"):\n        _parse_union(\"Union[str]\")\n\n    with pytest.raises(ValueError, match=\"Invalid Optional type:.*\"):\n        _parse_optional(\"Optional[str, int]\")", ""]}
{"filename": "tests/unit/processing/test_create.py", "chunked_list": ["\"\"\"Test helpers to create processing functions.\"\"\"\nimport re\n\nimport pytest\nimport pytest_check as check\n\nfrom cliconfig.base import Config\nfrom cliconfig.processing.create import (\n    _is_matched,\n    create_processing_keep_property,", "    _is_matched,\n    create_processing_keep_property,\n    create_processing_value,\n)\n\n\ndef test_is_matched() -> None:\n    \"\"\"Test _is_matched.\"\"\"\n    check.is_true(_is_matched(\"foo.bar.test\", regex=\".*st\", tag_name=None))\n    check.is_false(_is_matched(\"test.bar.foo\", regex=\".*st\", tag_name=None))\n    check.is_true(_is_matched(\"foo.bar.test@tag\", regex=None, tag_name=\"tag\"))\n    check.is_false(_is_matched(\"foo.bar@tag.test\", regex=None, tag_name=\"tag\"))\n    check.is_false(_is_matched(\"foo.bar.test@tag2\", regex=None, tag_name=\"tag\"))\n    with pytest.raises(\n        ValueError, match=\"Either regex or tag_name must be defined but not both.\"\n    ):\n        _is_matched(\"foo.bar\", \".*\", \"tag\")\n    with pytest.raises(\n        ValueError, match=\"Either regex or tag_name must be defined.\"\n    ):\n        _is_matched(\"foo.bar\", None, None)", "\n\ndef test_create_processing_value() -> None:\n    \"\"\"Test create_processing_value.\"\"\"\n    # Persistent, premerge\n    proc1 = create_processing_value(\n        lambda x: x + 1, tag_name=\"add1\", order=1.0, persistent=True\n    )\n    proc2 = create_processing_value(\n        lambda x: -x, regex=\"neg_number.*\", order=0.0, persistent=True\n    )\n    in_dict = {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3@add1\": 1}\n    config = Config(in_dict, [proc1, proc2])\n    config = config.process_list[1].premerge(config)\n    config = config.process_list[0].premerge(config)\n    check.equal(config.dict, {\"neg_number1\": -1, \"neg_number2\": -1, \"neg_number3\": 0})\n    config = config.process_list[1].premerge(config)\n    config = config.process_list[0].premerge(config)\n    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n    config = config.process_list[1].postmerge(config)\n    config = config.process_list[0].postmerge(config)\n    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n    config = config.process_list[1].endbuild(config)\n    config = config.process_list[0].endbuild(config)\n    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n    config = config.process_list[1].presave(config)\n    config = config.process_list[0].presave(config)\n    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n    config = config.process_list[1].postload(config)\n    config = config.process_list[0].postload(config)\n    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n    # Non persistent, postmerge\n    proc2 = create_processing_value(\n        lambda x: -x, \"postmerge\", regex=\"neg_number.*\", order=0.0, persistent=False\n    )\n    proc1 = create_processing_value(\n        lambda x: x + 1, \"postmerge\", tag_name=\"add1\", order=1.0, persistent=False\n    )\n    in_dict = {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3@add1\": 1}\n    config = Config(in_dict, [proc1, proc2])\n    config = config.process_list[1].premerge(config)\n    config = config.process_list[0].premerge(config)\n    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 1})\n    config = config.process_list[1].postmerge(config)\n    config = config.process_list[0].postmerge(config)\n    check.equal(config.dict, {\"neg_number1\": -1, \"neg_number2\": -1, \"neg_number3\": 0})\n    config = config.process_list[1].premerge(config)\n    config = config.process_list[0].premerge(config)\n    config = config.process_list[1].postmerge(config)\n    config = config.process_list[0].postmerge(config)\n    check.equal(config.dict, {\"neg_number1\": 1, \"neg_number2\": 1, \"neg_number3\": 0})\n    # No signature, endbuild, presave, postload\n    proc1 = create_processing_value(type, \"endbuild\", tag_name=\"get_type\")\n    proc2 = create_processing_value(str, \"presave\", tag_name=\"to_str\")\n    proc3 = create_processing_value(\n        lambda *args: 0,  # noqa\n        \"postload\",\n        tag_name=\"zero\"\n    )\n    in_dict2 = {\n        \"type1@get_type@to_str@zero\": 1,\n        \"type2@get_type@to_str@zero\": \"2\",\n        \"type3@get_type@to_str@zero\": True\n    }\n    config = Config(in_dict2, [proc1, proc2, proc3])\n    config = config.process_list[0].premerge(config)\n    config = config.process_list[1].premerge(config)\n    config = config.process_list[2].premerge(config)\n    check.equal(config.dict, {\"type1\": 1, \"type2\": \"2\", \"type3\": True})\n    config = config.process_list[0].endbuild(config)\n    check.equal(config.dict, {\"type1\": int, \"type2\": str, \"type3\": bool})\n    config = config.process_list[1].presave(config)\n    check.equal(config.dict, {\n        \"type1\": \"<class 'int'>\",\n        \"type2\": \"<class 'str'>\",\n        \"type3\": \"<class 'bool'>\"\n    })\n    config = config.process_list[2].postload(config)\n    check.equal(config.dict, {\"type1\": 0, \"type2\": 0, \"type3\": 0})\n\n    # Config in input\n    proc = create_processing_value(\n        lambda x, flat_config: eval(  # pylint: disable=eval-used\n            x, {\"config\": flat_config}\n        ),\n        tag_name=\"eval\",\n        persistent=False,\n    )\n    eval_dict = {\"param1\": 1, \"param2@eval\": \"config.param1 + 1\"}\n    config = Config(eval_dict, [proc])\n    config = config.process_list[0].premerge(config)\n    check.equal(config.dict, {\"param1\": 1, \"param2\": 2})\n\n    # Failing cases\n    with pytest.raises(\n        ValueError, match=\"Processing type 'UNKNOWN' not recognized.*\"\n    ):\n        create_processing_value(lambda x: x + 1, \"UNKNOWN\", tag_name=\"tag\")\n    with pytest.raises(\n        ValueError, match=\"You must provide a tag or a regex but not both.\"\n    ):\n        create_processing_value(lambda x: x + 1, tag_name=\"add1\", regex=\"neg_number.*\")\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"You must provide a tag or a regex (to trigger the value update).\"\n        ),\n    ):\n        create_processing_value(lambda x: x + 1, order=0.0)", "\n\ndef test_create_processing_keep_property() -> None:\n    \"\"\"Test create_processing_keep_property.\"\"\"\n    proc1 = create_processing_keep_property(type, regex=\".*\")\n    proc2 = create_processing_keep_property(lambda x: x, tag_name=\"protect\")\n    proc3 = create_processing_keep_property(\n        lambda x, config: len(x + config.dict[\"list\"]),\n        tag_name=\"len\",\n    )\n    in_dict = {\"str\": \"foo\", \"int\": 2, \"list@protect\": [1, 2, 3], \"list2@len\": [1, 2]}\n    config = Config(in_dict, [proc1, proc2, proc3])\n    config = config.process_list[0].premerge(config)\n    config = config.process_list[1].premerge(config)\n    config = config.process_list[2].premerge(config)\n    check.equal(\n        config.dict,\n        {\"str\": \"foo\", \"int\": 2, \"list\": [1, 2, 3], \"list2\": [1, 2]}\n    )\n    config.dict = {\"str\": \"foo\", \"int\": -1, \"list\": [1, 2, 3], \"list2\": [4, 5]}\n    config = config.process_list[0].postmerge(config)\n    config = config.process_list[1].postmerge(config)\n    config = config.process_list[2].postmerge(config)\n    config.dict = {\"str\": \"foo2\", \"int\": 6, \"list\": [1, 2, 3], \"list2\": [8, 9]}\n    config = config.process_list[0].endbuild(config)\n    config = config.process_list[1].endbuild(config)\n    config = config.process_list[2].endbuild(config)\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"Property of key str has changed from <class 'str'> to <class 'int'> \"\n            \"while it is protected by a keep-property processing (problem found on \"\n            \"end-build).\"\n        ),\n    ):\n        config.process_list[0].endbuild(Config({\"str\": 0}, []))\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"Property of key list has changed from [1, 2, 3] to [1, 2] while \"\n            \"it is protected by a keep-property processing (problem found on \"\n            \"post-merge).\"\n        ),\n    ):\n        config.process_list[1].postmerge(Config({\"list\": [1, 2]}, []))\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"Property of key list2 has changed from 5 to 3 while \"\n            \"it is protected by a keep-property processing (problem found on \"\n            \"post-merge).\"\n        ),\n    ):\n        config.process_list[2].postmerge(Config({\"list\": [1, 2], \"list2\": [3]}, []))\n    # Should not raise on pre-merge:\n    config.process_list[0].premerge(Config({\"str\": 0}, []))\n    config.process_list[1].premerge(Config({\"list\": [1, 2]}, []))\n    config.process_list[2].premerge(Config({\"list\": [1, 2], \"list2\": []}, []))\n\n    # Failing cases\n    with pytest.raises(\n        ValueError, match=\"You must provide a tag or a regex but not both.\"\n    ):\n        create_processing_keep_property(lambda x: x, tag_name=\"protect\", regex=\".*\")\n    with pytest.raises(\n        ValueError,\n        match=re.escape(\n            \"You must provide a tag or a regex (to trigger the value update).\"\n        ),\n    ):\n        create_processing_keep_property(lambda x: x, premerge_order=0.0)", ""]}
{"filename": "docs/conf.py", "chunked_list": ["\"\"\"Configuration file for the Sphinx documentation builder.\"\"\"\n# pylint: disable=all\n# For the full list of built-in configuration values, see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\nimport os\nimport sys\n\nfrom setuptools_scm import get_version\n\nsys.path.insert(0, os.path.abspath(\"../\"))", "\nsys.path.insert(0, os.path.abspath(\"../\"))\n\n# -- Project information -----------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information\n\nproject = \"CLI Config\"\ncopyright = \"2023, Valentin Goldite\"  # noqa A001\nauthor = \"Valentin Goldite\"\ntry:\n    release = get_version()\nexcept:  # noqa E722\n    release = get_version(root=\"..\", relative_to=__file__)", "author = \"Valentin Goldite\"\ntry:\n    release = get_version()\nexcept:  # noqa E722\n    release = get_version(root=\"..\", relative_to=__file__)\n\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\n\nextensions = [", "\nextensions = [\n    \"myst_parser\",\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.inheritance_diagram\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx_autodoc_typehints\",\n]\n", "]\n\nmaster_doc = \"index\"\nautoapi_type = \"python\"\nautoapi_dirs = [\"cliconfig\"]\n\nautodoc_default_options = {\n    \"member-order\": \"bysource\",\n    \"undoc-members\": True,\n}", "    \"undoc-members\": True,\n}\n\nadd_module_names = False\nautoclass_content = \"both\"\nnapoleon_use_param = True\n\nintersphinx_mapping = {\n    \"python\": (\"https://docs.python.org/\", None),\n    \"numpy\": (\"http://docs.scipy.org/doc/numpy/\", None),", "    \"python\": (\"https://docs.python.org/\", None),\n    \"numpy\": (\"http://docs.scipy.org/doc/numpy/\", None),\n}\n\ntemplates_path = [\"_templates\"]\nexclude_patterns = [\"_build\"]\n\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n", "# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\n\nhtml_theme = \"sphinx_rtd_theme\"\n\nhtml_theme_options = {\n    \"canonical_url\": \"\",\n    \"analytics_id\": \"UA-XXXXXXX-1\",\n    \"logo_only\": False,\n    \"display_version\": True,\n    \"prev_next_buttons_location\": \"both\",", "    \"display_version\": True,\n    \"prev_next_buttons_location\": \"both\",\n    \"style_external_links\": \"#ff9900\",\n    \"style_nav_header_background\": \"#ff9900\",\n    # Toc options\n    \"collapse_navigation\": False,\n    \"sticky_navigation\": True,\n    \"navigation_depth\": 4,\n    \"includehidden\": True,\n    \"titles_only\": False,", "    \"includehidden\": True,\n    \"titles_only\": False,\n}\nhtml_context = {\n    \"display_github\": True,  # Integrate GitHub\n    \"github_user\": \"valentingol\",  # Username\n    \"github_repo\": \"cliconfig\",  # Repo name\n    \"github_version\": \"main\",  # Version\n    \"conf_py_path\": \"/docs/\",  # Path in the checkout to the docs root\n}", "    \"conf_py_path\": \"/docs/\",  # Path in the checkout to the docs root\n}\n"]}
{"filename": "cliconfig/dict_routines.py", "chunked_list": ["\"\"\"Routines to manipulate nested and flat dictionaries (and mix of both).\n\nUsed by :mod:`.process_routines` and :mod:`.config_routines`.\n\"\"\"\nimport os\nfrom typing import Any, Dict, Tuple, Union\n\nimport yaml\nfrom flatten_dict import flatten as _flatten\nfrom flatten_dict import unflatten as _unflatten", "from flatten_dict import flatten as _flatten\nfrom flatten_dict import unflatten as _unflatten\n\nfrom cliconfig.yaml_tags._yaml_tags import get_yaml_loader, insert_tags\n\n\ndef merge_flat(\n    dict1: Dict[str, Any],\n    dict2: Dict[str, Any],\n    *,\n    allow_new_keys: bool = True,\n) -> Dict[str, Any]:\n    \"\"\"Flatten then merge dict2 into dict1. The result is flat.\n\n    Work even if dict1 and dict2 have a mix of nested and flat\n    dictionaries. For instance like this:\n\n    .. code-block:: python\n\n        dict1 = {'a.b': 1, 'a': {'c': 2}, 'a.d': {'e.f': 3}}\n\n    Parameters\n    ----------\n    dict1 : Dict[str, Any]\n        The first dict. It can be nested, flat or a mix of both.\n    dict2 : Dict[str, Any]\n        The second dict to merge into first dict.\n    allow_new_keys : bool, optional\n        If True, new keys (that are not in dict1) are allowed in dict2.\n        By default True.\n\n    Raises\n    ------\n    ValueError\n        If allow_new_keys is False and dict2 has new keys that are not in dict1.\n    ValueError\n        If there are conflicting keys when flatten one of the dicts.\n        See last example. You may consider calling :func:`clean_pre_flat` on the input\n        dicts in that case.\n\n    Returns\n    -------\n    flat_dict : Dict[str, Any]\n        The flat dict (all keys are at the root and separated by dots).\n\n    Examples\n    --------\n    ::\n\n        >>> merge_dict({'a.b': 1, 'a': {'c': 2}},  {'c': 3}, allow_new_keys=True)\n        {'a.b': 1, 'a.c': 2, 'c': 3}\n        >>> merge_dict({'a.b': 1, 'a': {'c': 2}},  {'c': 3}, allow_new_keys=False)\n        ValueError: New parameter found 'c' that is not in the original dict.\n        >>> merge_dict({'a.b': 1, 'a': {'b': 1}},  {'c': 3}, allow_new_keys=True)\n        ValueError: duplicated key 'a.b'.\n        The above exception was the direct cause of the following exception:\n        ValueError: You may consider calling 'clean_pre_flat' on dict 1 before merging.\n    \"\"\"\n    # Flatten dicts\n    flat_dict1, flat_dict2 = _flat_before_merge(dict1, dict2)\n\n    if not allow_new_keys:\n        # Check that there are no new keys in dict2\n        for key in flat_dict2:\n            if key not in flat_dict1.keys():\n                raise ValueError(\n                    f\"New parameter found '{key}' in that is not in the original \"\n                    \"dict.\"\n                )\n    # Merge flat dicts\n    flat_dict = {**flat_dict1, **flat_dict2}\n    return flat_dict", "\n\ndef _flat_before_merge(\n    dict1: Dict[str, Any], dict2: Dict[str, Any]\n) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"Flatten two dicts to merge them later.\"\"\"\n    # Flatten dicts\n    flat_dicts = []\n    for i, _dict in enumerate([dict1, dict2]):\n        # Check if already flat\n        is_flat = all(not isinstance(val, dict) for val in _dict.values())\n        if not is_flat:\n            try:\n                flat_dict = flatten(_dict)\n            except ValueError as exc:\n                raise ValueError(\n                    f\"Duplicated key found in dict {i + 1} when flattening. \"\n                    f\"You may consider calling 'clean_pre_flat' before merging.\"\n                ) from exc\n        else:\n            flat_dict = _dict\n        flat_dicts.append(flat_dict)\n    return flat_dicts[0], flat_dicts[1]", "\n\ndef merge_flat_paths(\n    dict_or_path1: Union[str, Dict[str, Any]],\n    dict_or_path2: Union[str, Dict[str, Any]],\n    *,\n    allow_new_keys: bool = True,\n) -> Dict[str, Any]:\n    \"\"\"Flatten then merge two dict eventually loaded from yaml file paths.\n\n    Similar to :func:`.merge_flat` but allow passing the paths of dicts\n    as inputs. It merges the second dict into the first one.\n\n    Parameters\n    ----------\n    dict_or_path1 : Union[str, Dict[str, Any]]\n        The first dict or its path.\n    dict_or_path2 : Union[str, Dict[str, Any]]\n        The second dict or its path, to merge into first dict.\n    allow_new_keys : bool, optional\n        If True, new keys (that are not in dict1) are allowed in dict2.\n        By default True.\n\n    Raises\n    ------\n    ValueError\n        If allow_new_keys is False and dict2 has new keys that are not in dict1.\n    ValueError\n        If there are conflicting keys when flatten one of the dicts.\n        See last example. You may consider calling :func:`clean_pre_flat` on the input\n        dicts in that case.\n\n    Returns\n    -------\n    flat_dict : Dict[str, Any]\n        The flat dict (all keys are at the root and separated by dots).\n    \"\"\"\n    dicts = []\n    for dict_or_path in [dict_or_path1, dict_or_path2]:\n        if isinstance(dict_or_path, str):\n            _dict = load_dict(dict_or_path)\n        else:\n            _dict = dict_or_path\n        dicts.append(_dict)\n    dict1, dict2 = dicts[0], dicts[1]\n    flat_dict = merge_flat(\n        dict1,\n        dict2,\n        allow_new_keys=allow_new_keys,\n    )\n    return flat_dict", "\n\ndef flatten(in_dict: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Flatten dict then return it (flat keys are built with dots).\n\n    Work even if in_dict is a mix of nested and flat dictionaries.\n    For instance like this:\n\n    .. code-block:: python\n\n        >>> flatten({'a.b': {'c': 1}, 'a': {'b.d': 2}, 'a.e': {'f.g': 3}})\n        {'a.b.c': 1, 'a.b.d': 2, 'a.e.f.g': 3}\n\n\n    Parameters\n    ----------\n    in_dict : Dict[str, Any]\n        The dict to flatten. It can be nested, already flat or a mix of both.\n\n    Raises\n    ------\n    ValueError\n        If dict has some conflicting keys (like ``{'a.b': <x>, 'a': {'b': <y>}}``).\n\n    Returns\n    -------\n    flat_dict : Dict[str, Any]\n        The flattened dict.\n\n    Note\n    ----\n        Nested empty dict are ignored even if they are conflicting (see last example).\n\n    Examples\n    --------\n    ::\n\n        >>> flatten({'a.b': 1, 'a': {'c': 2}, 'd': 3})\n        {'a.b': 1, 'a.c': 2, 'd': 3}\n        >>> flatten({'a.b': {'c': 1}, 'a': {'b.d': 2}, 'a.e': {'f.g': 3}})\n        {'a.b.c': 1, 'a.b.d': 2, 'a.e.f.g': 3}\n        >>> flatten({'a.b': 1, 'a': {'b': 1}})\n        ValueError: duplicated key 'a.b'\n        >>> flatten({'a.b': 1, 'a': {'c': {}}, 'a.c': 3})\n        {'a.b': 1, 'a.c': 3}\n\n    \"\"\"\n    flat_dict = _flatten(in_dict, reducer=\"dot\")\n    return flat_dict", "\n\ndef unflatten(flat_dict: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Unflatten a flat dict then return it.\n\n    Parameters\n    ----------\n    flat_dict : Dict[str, Any]\n        The dict to unflatten. Must be a fully flat dict (depth of 1 with keys\n        separated by dots).\n\n    Raises\n    ------\n    ValueError\n        If flat_dict is not flat and then found conflicts.\n\n    Returns\n    -------\n    unflat_dict : Dict[str, Any]\n        The output nested dict.\n\n    Examples\n    --------\n    ::\n\n        >>> unflatten({'a.b': 1, 'a.c': 2, 'c': 3})\n        {'a': {'b': 1, 'c': 2}, 'c': 3}\n        >>> unflatten({'a.b': 1, 'a': {'c': 2}})\n        ValueError: duplicated key 'a'\n        The dict must be flatten before calling unflatten function.\n    \"\"\"\n    try:\n        unflat_dict = _unflatten(flat_dict, splitter=\"dot\")\n    except ValueError as exc:\n        raise ValueError(\n            \"The dict must be flatten before calling unflatten function.\"\n        ) from exc\n    return unflat_dict", "\n\ndef clean_pre_flat(in_dict: Dict[str, Any], priority: str) -> Dict[str, Any]:\n    \"\"\"Remove keys in input dict that may cause conflicts when flattening.\n\n    Parameters\n    ----------\n    in_dict : Dict[str, Any]\n        The dict to clean. It must be the union of a fully flat dict\n        (no nested dict i values) and a fully nested dict (without dots in keys).\n        See warning section below.\n    priority: str\n        One of 'flat' or 'unflat', 'error'.\n        If 'flat', keys with dots at the root like ``{'a.b': ...}`` (flat keys) have\n        priority over nested keys like ``{'a': {'b': ...}}`` when there are conflicts.\n        If 'unflat', nested keys have priority over flat keys when there are conflicts.\n        If 'error', raise an error when there are conflicts.\n\n    Raises\n    ------\n    ValueError\n        If priority is not one of 'flat', 'unflat' or 'error'.\n\n    Returns\n    -------\n    Dict[str, Any]\n        The cleansed dict.\n\n    Warning\n    -------\n        * No flat key can contain a dict. Then, dicts like ``{'a.b': {'c': 1}}``\n          are not supported.\n        * All the keys that contain dots (the flat keys) must be at the root.\n          Then, dicts like ``{a: {'b.c': 1}}`` are not supported.\n        * To summarize, the dict must contain only fully flat dicts\n          and/or fully nested dicts.\n\n    Examples\n    --------\n    ::\n\n        >>> clean_pre_flat({'a.b': 1, 'a': {'b': 2}, 'c': 3}, priority='flat')\n        {'a.b': 1, 'c': 3}\n        >>> clean_pre_flat({'a.b': 1, 'a': {'b': 2}, 'c': 3}, priority='unflat')\n        {'a': {'b': 2}, 'c': 3}\n        >>> clean_pre_flat({'a.b': 1, 'a': {'b': 2}, 'c': 3}, priority='error')\n        ValueError: duplicated key 'a.b'\n    \"\"\"\n    if priority in (\"flat\", \"unflat\"):\n        # Check that there are no conflicts\n        flat_part = dict(filter(lambda items: \".\" in items[0], in_dict.items()))\n        unflat_part = dict(filter(lambda items: \".\" not in items[0], in_dict.items()))\n        unflat_part_flat = flatten(unflat_part)\n        if priority == \"unflat\":\n            for key in flat_part:\n                if key in unflat_part_flat:\n                    _del_key(in_dict, key, keep_flat=False, keep_unflat=True)\n        else:\n            for key in unflat_part_flat:\n                if key in flat_part:\n                    _del_key(in_dict, key, keep_flat=True, keep_unflat=False)\n    elif priority == \"error\":\n        flatten(in_dict)  # Will raise an error if there are conflicts\n    else:\n        raise ValueError(\n            \"priority argument must be one of 'flat', 'unflat' or 'error' but \"\n            f\"found '{priority}'.\"\n        )\n    return in_dict", "\n\ndef _del_key(\n    in_dict: Dict[str, Any],\n    flat_key: str,\n    *,\n    keep_flat: bool = False,\n    keep_unflat: bool = False,\n) -> None:\n    \"\"\"Remove in place a value in dict corresponding to a flat key (e.g. 'a.b.c').\n\n    Parameters\n    ----------\n    in_dict : Dict[str, Any]\n        The dict to clean. It must be the union of a fully flat dict\n        (no nested dict i values) and a fully nested dict (without dots in keys).\n        See warning section below.\n    flat_key: str\n        The flat key to remove. E.g. 'a.b.c'.\n    keep_flat: bool, optional\n        If True, keep the flat key in the dict. By default False.\n    keep_unflat: bool, optional\n        If True, keep the unflat key in the dict. By default False.\n\n    Raises\n    ------\n    ValueError\n        If the key is not found in the dict.\n\n    Warning\n    -------\n        * No flat key can contain a dict. Then, dicts like ``{'a.b': {'c': 1}}``\n          are not supported.\n        * All the keys that contain dots (the flat keys) must be at the root.\n          Then, dicts like ``{a: {'b.c': 1}}`` are not supported.\n        * To summarize, the dict must contain only fully flat dicts\n          and fully nested dicts.\n\n    Examples\n    --------\n    ::\n\n        >>> in_dict = {'a': {'b': {'c': 1}, 'd': 2}, 'a.b.c': 4}\n        >>> _del_key(in_dict, 'a.b.c'); in_dict\n        {'a': {'d': 2}}\n        >>> _del_key(in_dict, 'a.b.c', keep_flat=True); in_dict\n        {'a': {'d': 2}, 'a.b.c': 4}\n        >>> _del_key(in_dict, 'a.b.c', keep_unflat=True); in_dict\n        {'a': {'b': {'c': 1}, 'd': 2}}\n        >>> _del_key(in_dict, 'a.b.z')\n        ValueError: Key 'a.b.z' not found in dict.\n        >>> _del_key(in_dict, 'a.z.c')\n        ValueError: Key 'a.z.c' not found in dict.\n    \"\"\"\n    found_key = False\n    if not keep_flat and flat_key in in_dict:\n        # Remove flat_key if it exists at the root\n        found_key = True\n        del in_dict[flat_key]\n\n    def recursive_del_key(\n        in_dict: Dict[str, Any], key: str, *, found_key: bool\n    ) -> bool:\n        first_key, *other_keys = key.split(\".\", 1)\n        if other_keys:\n            if first_key in in_dict:\n                # Delete key in sub-dict\n                new_key = recursive_del_key(\n                    in_dict[first_key],\n                    \".\".join(other_keys),\n                    found_key=found_key,\n                )\n                found_key = found_key or new_key\n                # Remove if empty\n                if in_dict[first_key] == {}:\n                    del in_dict[first_key]\n            else:\n                # No key found, return input found_key\n                return found_key\n        else:\n            if first_key in in_dict:\n                found_key = True\n                del in_dict[first_key]\n            else:\n                # No key found, return input found_key\n                return found_key\n        return found_key\n\n    if not keep_unflat:\n        # Remove flat_key if it exists in a nested dict\n        found_key = recursive_del_key(in_dict, flat_key, found_key=found_key)\n    # Raise error if key not found\n    if not found_key:\n        raise ValueError(f\"Key '{flat_key}' not found in dict.\")", "\n\ndef save_dict(in_dict: Dict[str, Any], path: str) -> None:\n    \"\"\"Save a dict to a yaml file (with yaml.dump).\n\n    Parameters\n    ----------\n    in_dict : Dict[str, Any]\n        The dict to save.\n    path : str\n        The path to the yaml file to save the dict.\n    \"\"\"\n    dir_path = os.path.dirname(path)\n    os.makedirs(dir_path, exist_ok=True)\n    with open(path, \"w\", encoding=\"utf-8\") as cfg_file:\n        yaml.dump(in_dict, cfg_file, default_flow_style=False)", "\n\ndef load_dict(path: str) -> Dict[str, Any]:\n    \"\"\"Load dict from a yaml file path.\n\n     Support multiple files in the same document and yaml tags.\n\n    Parameters\n    ----------\n    path : str\n        The path to the file to load the dict.\n\n    Returns\n    -------\n    out_dict : Dict[str, Any]\n        The nested (unflatten) loaded dict.\n\n    Note\n    ----\n\n        * If multiple yaml files are in the same document, they are merged\n        from the first to the last.\n        * To use multiple yaml tags, separate them with \"@\". E.g. ``!tag1@tag2``.\n        * You can combine any number of yaml and cliconfig tags together.\n    \"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as cfg_file:\n        file_dicts = yaml.load_all(cfg_file, Loader=get_yaml_loader())\n        out_dict: Dict[str, Any] = {}\n        for file_dict in file_dicts:\n            new_dict, _ = insert_tags(file_dict)\n            out_dict = merge_flat(out_dict, new_dict, allow_new_keys=True)\n    return unflatten(out_dict)", "\n\ndef show_dict(in_dict: Dict[str, Any], start_indent: int = 0) -> None:\n    \"\"\"Show the input dict in a pretty way.\n\n    The config dict is automatically unflattened before printing.\n\n    Parameters\n    ----------\n    in_dict : Dict[str, Any]\n        The dict to show.\n    start_indent : int, optional\n        The number of starting tab indent (4 spaces), by default 0.\n    \"\"\"\n\n    def pretty_print(in_dict: Dict[str, Any], indent: int) -> None:\n        \"\"\"Pretty print the dict recursively.\"\"\"\n        for key, value in in_dict.items():\n            print(f\"{'    ' * indent}{key}: \", end=\"\")\n            if isinstance(value, dict):\n                print()\n                pretty_print(value, indent + 1)\n            elif isinstance(value, str):\n                print(f\"'{value}'\")\n            else:\n                print(value)\n\n    pretty_print(unflatten(in_dict), start_indent)", ""]}
{"filename": "cliconfig/cli_parser.py", "chunked_list": ["\"\"\"Parser for CLI commands.\"\"\"\nfrom typing import Any, Dict, List, Tuple\n\nimport yaml\n\n\ndef parse_cli(sys_argv: List[str]) -> Tuple[List[str], Dict[str, Any]]:\n    \"\"\"Parser for CLI commands.\n\n    Return list of config path(s) that are detected with ``--config`` followed\n    by a space. If multiple paths are provided, they must be separated by a comma\n    and no space around the comma. It also possible to provide a list of paths.\n\n    Return also a dictionary of parameters from CLI detected with ``--<key>=<value>``\n    (with \"=\" and without spaces around). If no value is provided,\n    it is True by default (like for a flag).\n\n    Parameters\n    ----------\n    sys_argv : List[str]\n        List of arguments from sys.argv.\n\n    Raises\n    ------\n    Value Error\n        If the ``--config`` argument (with space) is used more than once.\n\n    Returns\n    -------\n    config_paths : List[str]\n        List of paths to config files to merge.\n    cli_params_dict : Dict[str, Any]\n        Dictionary of parameters from CLI.\n\n    Examples\n    --------\n    .. code-block:: text\n\n        $ python my_script.py --config config.yaml --foo.bar.param=[1, 2, 3]\n\n    Will be parsed as ``config_paths=['config.yaml']``\n    and ``cli_params={'foo.bar.param': [1, 2, 3]}``.\n    It is equivalent to: ``{'foo': {'bar': {'param': [1, 2, 3]}}`` for\n    :func:`.merge_flat` and :func:`.make_config`.\n    \"\"\"\n    cli_params_dict: Dict[str, Any] = {}\n    config_paths: List[str] = []\n    i = 0\n    while i < len(sys_argv):\n        elem = sys_argv[i]\n        if elem == \"--config\":\n            if config_paths:\n                raise ValueError(\n                    \"Only one '--config ' argument is allowed in CLI (used for \"\n                    \"config merging).\"\n                )\n            configs = yaml.safe_load(sys_argv[i + 1])\n            if isinstance(configs, list):\n                config_paths = configs\n            if isinstance(configs, str):\n                config_paths = sys_argv[i + 1].split(\",\")\n            i += 2\n        elif elem.startswith(\"--\"):\n            splits = elem.split(\"=\", maxsplit=1)\n            if len(splits) == 2:\n                key, value_str = splits\n            else:\n                key = splits[0]\n                # If no value is provided, use True because it could\n                # be seen as a flag\n                value_str = \"true\"\n            key = key[2:]\n            value = yaml.safe_load(value_str)\n            cli_params_dict[key] = value\n            i += 1\n        else:  # Not a config parameter\n            i += 1\n    return config_paths, cli_params_dict", ""]}
{"filename": "cliconfig/base.py", "chunked_list": ["\"\"\"Base classes of Config object.\"\"\"\nfrom typing import TYPE_CHECKING, Any, Dict, List, Optional\n\n# Imports Processing for mypy type checking only\nif TYPE_CHECKING:\n    from cliconfig.processing.base import Processing\n\n\nclass Config:\n    \"\"\"Class for configuration.\n\n    Config object contain the config dict and the processing list\n    and no methods except ``__init__``, ``__repr__``, ``__eq__``,\n    ``__getattribute__``, ``__setattr__`` and ``__delattr__``.\n    The Config objects are mutable and not hashable.\n\n    Parameters\n    ----------\n    config_dict : Dict[str, Any]\n        The config dict.\n    process_list : Optional[List[Processing]], optional\n        The list of Processing objects. If None, an empty list is used.\n        The default is None.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_dict: Dict[str, Any],\n        process_list: Optional[List[\"Processing\"]] = None,\n    ) -> None:\n        self.dict = config_dict\n        self.process_list = process_list if process_list else []\n\n    def __repr__(self) -> str:\n        \"\"\"Representation of Config object.\"\"\"\n        process_classes = [process.__class__.__name__ for process in self.process_list]\n        return f\"Config({self.dict}, {process_classes})\"\n\n    def __eq__(self, other: Any) -> bool:\n        \"\"\"Equality operator.\n\n        Two Config objects are equal if their dicts are equal and their\n        lists of Processing objects are equal (order doesn't matter).\n        \"\"\"\n        if (\n            isinstance(other, Config)\n            and self.dict == other.dict\n            and len(self.process_list) == len(other.process_list)\n        ):\n            equal = True\n            for processing in self.process_list:\n                equal = equal and processing in other.process_list\n            for processing in other.process_list:\n                equal = equal and processing in self.process_list\n            return equal\n        return False\n\n    def __getattribute__(self, __name: str) -> Any:\n        \"\"\"Get attribute, sub-configuration or parameter.\n\n        The dict should be nested (unflattened). If it is not the case,\n        you can apply :func:`dict_routines.flatten` on ``config.dict``\n        to unflatten it.\n        \"\"\"\n        if __name in [\"dict\", \"process_list\"]:\n            return super().__getattribute__(__name)\n        if __name not in self.dict:\n            keys = \", \".join(self.dict.keys())\n            raise AttributeError(  # pylint: disable=raise-missing-from\n                f\"Config has no attribute '{__name}'. Available keys are: {keys}.\"\n            )\n        if isinstance(self.dict[__name], dict):\n            # If the attribute is a dict, return a Config object\n            # so that we can access the nested keys with multiple dots\n            return Config(self.dict[__name], process_list=self.process_list)\n        return self.dict[__name]\n\n    def __setattr__(self, __name: str, value: Any) -> None:\n        \"\"\"Set attribute, sub-configuration or parameter.\n\n        The dict should be nested (unflattened). If it is not the case,\n        you can apply :func:`dict_routines.flatten` on ``config.dict``\n        to unflatten it.\n        \"\"\"\n        if __name in [\"dict\", \"process_list\"]:\n            super().__setattr__(__name, value)\n        else:\n            self.dict[__name] = value\n\n    def __delattr__(self, __name: str) -> None:\n        \"\"\"Delete attribute, sub-configuration or parameter.\n\n        The dict should be nested (unflattened). If it is not the case,\n        you can apply :func:`dict_routines.flatten` on ``config.dict``\n        to unflatten it.\n        \"\"\"\n        if __name in [\"dict\", \"process_list\"]:\n            super().__delattr__(__name)\n        else:\n            del self.dict[__name]", "class Config:\n    \"\"\"Class for configuration.\n\n    Config object contain the config dict and the processing list\n    and no methods except ``__init__``, ``__repr__``, ``__eq__``,\n    ``__getattribute__``, ``__setattr__`` and ``__delattr__``.\n    The Config objects are mutable and not hashable.\n\n    Parameters\n    ----------\n    config_dict : Dict[str, Any]\n        The config dict.\n    process_list : Optional[List[Processing]], optional\n        The list of Processing objects. If None, an empty list is used.\n        The default is None.\n    \"\"\"\n\n    def __init__(\n        self,\n        config_dict: Dict[str, Any],\n        process_list: Optional[List[\"Processing\"]] = None,\n    ) -> None:\n        self.dict = config_dict\n        self.process_list = process_list if process_list else []\n\n    def __repr__(self) -> str:\n        \"\"\"Representation of Config object.\"\"\"\n        process_classes = [process.__class__.__name__ for process in self.process_list]\n        return f\"Config({self.dict}, {process_classes})\"\n\n    def __eq__(self, other: Any) -> bool:\n        \"\"\"Equality operator.\n\n        Two Config objects are equal if their dicts are equal and their\n        lists of Processing objects are equal (order doesn't matter).\n        \"\"\"\n        if (\n            isinstance(other, Config)\n            and self.dict == other.dict\n            and len(self.process_list) == len(other.process_list)\n        ):\n            equal = True\n            for processing in self.process_list:\n                equal = equal and processing in other.process_list\n            for processing in other.process_list:\n                equal = equal and processing in self.process_list\n            return equal\n        return False\n\n    def __getattribute__(self, __name: str) -> Any:\n        \"\"\"Get attribute, sub-configuration or parameter.\n\n        The dict should be nested (unflattened). If it is not the case,\n        you can apply :func:`dict_routines.flatten` on ``config.dict``\n        to unflatten it.\n        \"\"\"\n        if __name in [\"dict\", \"process_list\"]:\n            return super().__getattribute__(__name)\n        if __name not in self.dict:\n            keys = \", \".join(self.dict.keys())\n            raise AttributeError(  # pylint: disable=raise-missing-from\n                f\"Config has no attribute '{__name}'. Available keys are: {keys}.\"\n            )\n        if isinstance(self.dict[__name], dict):\n            # If the attribute is a dict, return a Config object\n            # so that we can access the nested keys with multiple dots\n            return Config(self.dict[__name], process_list=self.process_list)\n        return self.dict[__name]\n\n    def __setattr__(self, __name: str, value: Any) -> None:\n        \"\"\"Set attribute, sub-configuration or parameter.\n\n        The dict should be nested (unflattened). If it is not the case,\n        you can apply :func:`dict_routines.flatten` on ``config.dict``\n        to unflatten it.\n        \"\"\"\n        if __name in [\"dict\", \"process_list\"]:\n            super().__setattr__(__name, value)\n        else:\n            self.dict[__name] = value\n\n    def __delattr__(self, __name: str) -> None:\n        \"\"\"Delete attribute, sub-configuration or parameter.\n\n        The dict should be nested (unflattened). If it is not the case,\n        you can apply :func:`dict_routines.flatten` on ``config.dict``\n        to unflatten it.\n        \"\"\"\n        if __name in [\"dict\", \"process_list\"]:\n            super().__delattr__(__name)\n        else:\n            del self.dict[__name]", ""]}
{"filename": "cliconfig/config_routines.py", "chunked_list": ["\"\"\"Functions to manipulate config as dict with yaml files and CLI.\"\"\"\nimport sys\nfrom typing import Any, Dict, List, Optional\n\nfrom cliconfig.base import Config\nfrom cliconfig.cli_parser import parse_cli\nfrom cliconfig.dict_routines import flatten, show_dict, unflatten\nfrom cliconfig.process_routines import (\n    end_build_processing,\n    load_processing,", "    end_build_processing,\n    load_processing,\n    merge_flat_paths_processing,\n    merge_flat_processing,\n    save_processing,\n)\nfrom cliconfig.processing.base import Processing\nfrom cliconfig.processing.builtin import DefaultProcessings\nfrom cliconfig.tag_routines import clean_all_tags\n", "from cliconfig.tag_routines import clean_all_tags\n\n\ndef make_config(\n    *default_config_paths: str,\n    process_list: Optional[List[Processing]] = None,\n    add_default_processing: bool = True,\n    fallback: str = \"\",\n    no_cli: bool = False,\n) -> Config:\n    r\"\"\"Make a config from default config(s) and CLI argument(s) with processing.\n\n    The function uses the CLI Config routines :func:`.parse_cli` to parse the CLI\n    arguments and merge them with :func:`.merge_flat_paths_processing`, applying\n    the pre-merge and post-merge processing functions on each merge.\n\n    Parameters\n    ----------\n    default_config_paths : Tuple[str]\n        Paths to default configs. They are merged in order and new keys\n        are allowed.\n    process_list: Optional[List[Processing]], optional\n        The list of processing to apply during each merge. None for empty list.\n        By default None.\n    add_default_processing : bool, optional\n        If add_default_processing is True, the default processings\n        (found on :class:`.DefaultProcessings`) are added to the list of\n        processings. By default True.\n    fallback : str, optional\n        Path of the configuration to use if no additional config is provided\n        with ``--config``. No fallback config if empty string (default),\n        in that case, the config is the default configs plus the CLI arguments.\n    no_cli : bool, optional\n        If True, the CLI arguments are not parsed and the config is only\n        built from the default_config_paths in input and the\n        fallback argument is ignored. By default False.\n\n    Raises\n    ------\n    ValueError\n        If additional configs have new keys that are not in default configs.\n\n    Returns\n    -------\n    config : Config\n        The nested built config. Contains the config dict (config.dict) and\n        the processing list (config.process_list) which can be used to apply\n        further processing routines.\n\n    Note\n    ----\n\n        Setting additional arguments from CLI that are not in default configs\n        does NOT raise an error but only a warning. This ensures the compatibility\n        with other CLI usage (e.g notebook, argparse, etc.)\n\n    Examples\n    --------\n    ::\n\n        # main.py\n        config = make_config('data.yaml', 'model.yaml', 'train.yaml')\n\n    .. code-block:: text\n\n        $ python main.py -- config [bestmodel.yaml,mydata.yaml] \\\n              --architecture.layers.hidden_dim=64\n\n    \"\"\"\n    # Create the processing list\n    process_list_: List[Processing] = [] if process_list is None else process_list\n    if add_default_processing:\n        process_list_ += DefaultProcessings().list\n    config = Config({}, process_list_)\n    if no_cli:\n        additional_config_paths: List[str] = []\n        cli_params_dict: Dict[str, Any] = {}\n    else:\n        additional_config_paths, cli_params_dict = parse_cli(sys.argv)\n        if not additional_config_paths and fallback:\n            # Add fallback config\n            additional_config_paths = [fallback]\n    # Merge default configs and additional configs\n    for i, paths in enumerate([default_config_paths, additional_config_paths]):\n        # Allow new keys for default configs only\n        allow_new_keys = i == 0\n        for path in paths:\n            config = merge_flat_paths_processing(\n                config,\n                path,\n                allow_new_keys=allow_new_keys,\n                preprocess_first=False,  # Already processed\n            )\n\n    # Allow new keys for CLI parameters but do not merge them and raise\n    # warning.\n    cli_params_dict = flatten(cli_params_dict)\n    new_keys, keys = [], list(cli_params_dict.keys())\n    for key in keys:\n        if clean_all_tags(key) not in config.dict:\n            # New key: delete it\n            new_keys.append(clean_all_tags(key))\n            del cli_params_dict[key]\n    if new_keys:\n        new_keys_message = \"  - \" + \"\\n  - \".join(new_keys)\n        print(\n            \"[CONFIG] Warning: New keys found in CLI parameters \"\n            f\"that will not be merged:\\n{new_keys_message}\"\n        )\n    # Merge CLI parameters\n    cli_params_config = Config(cli_params_dict, [])\n    config = merge_flat_processing(\n        config, cli_params_config, allow_new_keys=False, preprocess_first=False\n    )\n    print(\n        f\"[CONFIG] Info: Merged {len(default_config_paths)} default config(s), \"\n        f\"{len(additional_config_paths)} additional config(s) and \"\n        f\"{len(cli_params_dict)} CLI parameter(s).\"\n    )\n    # Apply end-build processing\n    config = end_build_processing(config)\n    # Unflatten the config dict\n    config.dict = unflatten(config.dict)\n    return config", "\n\ndef load_config(\n    path: str,\n    default_config_paths: Optional[List[str]] = None,\n    process_list: Optional[List[Processing]] = None,\n    *,\n    add_default_processing: bool = True,\n) -> Config:\n    \"\"\"Load config from a file and merge into optional default configs.\n\n    First merge the default configs together (if any), then load the config\n    from path, apply the post-load processing, and finally merge the loaded\n    config.\n\n    Parameters\n    ----------\n    path : str\n        The path to the file to load the configuration.\n    default_config_paths : Optional[List[str]], optional\n        Paths to default configs. They are merged in order, new keys are allowed.\n        Then, the loaded config is merged into the result. None for no default configs.\n        By default None.\n    process_list: Optional[List[Processing]]\n        The list of processing to apply after loading and for the merges.\n        If None, no processing is applied. By default None.\n    add_default_processing : bool, optional\n        If add_default_processing is True, the default processings\n        (found on :class:`.DefaultProcessings`) are added to the list of\n        processings. By default True.\n\n    Returns\n    -------\n    config: Dict[str, Any]\n        The nested loaded config. Contains the config dict (config.dict) and\n        the processing list (config.process_list) which can be used to apply\n        further processing routines.\n\n    Note\n    ----\n\n        If default configs are provided, the function does not allow new keys\n        for the loaded config. This is for helping the user to see how to\n        adapt the config file if the default configs have changed.\n    \"\"\"\n    # Crate process_list\n    process_list_: List[Processing] = [] if process_list is None else process_list\n    if add_default_processing:\n        process_list_ += DefaultProcessings().list\n\n    config = Config({}, process_list_)\n    if default_config_paths:\n        for config_path in default_config_paths:\n            config = merge_flat_paths_processing(\n                config,\n                config_path,\n                allow_new_keys=True,\n                preprocess_first=False,  # Already processed\n            )\n    loaded_config = load_processing(path, config.process_list)\n    # Update the config list from loaded_config in config\n    config.process_list = loaded_config.process_list\n    # Merge the loaded config into the config and\n    # disallow new keys for loaded config\n    # if default configs are provided\n    config = merge_flat_processing(\n        config,\n        loaded_config,\n        allow_new_keys=default_config_paths is None,\n        preprocess_first=False,\n    )\n    # Apply end-build processing\n    config = end_build_processing(config)\n    # Unflatten the config\n    config.dict = unflatten(config.dict)\n    return config", "\n\ndef save_config(config: Config, path: str) -> None:\n    \"\"\"Save a config and apply pre-save processing before saving.\n\n    Alias for :func:`.save_processing`.\n\n    Parameters\n    ----------\n    config : Dict[str, Any]\n        The config to save.\n    path : str\n        The path to the yaml file to save the dict.\n    \"\"\"\n    save_processing(config, path)", "\n\ndef show_config(config: Config) -> None:\n    \"\"\"Show the config dict in a pretty way.\n\n    The config dict is automatically unflattened before printing.\n\n    Parameters\n    ----------\n    config : Config\n        The config to show.\n    \"\"\"\n    print(\"Config:\")\n    show_dict(config.dict, start_indent=1)", ""]}
{"filename": "cliconfig/tag_routines.py", "chunked_list": ["\"\"\"Routines to manipulate the tags on the keys of a dict.\n\nUsed by the processing functions.\n\"\"\"\nimport copy\nimport re\nfrom typing import Any, Dict, List, Tuple\n\n\ndef clean_tag(flat_key: str, tag_name: str) -> str:\n    \"\"\"Clean a tag from a flat key.\n\n    It removes all occurrences of the tag with the exact name.\n\n    Parameters\n    ----------\n    flat_key : str\n        The flat key to clean.\n    tag_name : str\n        The name of the tag to remove, with or without the '@' prefix.\n\n    Returns\n    -------\n    flat_key : str\n        The cleaned flat key.\n\n    Note\n    ----\n        ``tag_name`` is supposed to be the exact name of the tag.\n\n    Examples\n    --------\n    ::\n\n        >>> clean_tag('abc@tag.def@tag_2.ghi@tag', 'tag')\n        abc.def@tag_2.ghi\n    \"\"\"\n    if tag_name[0] == \"@\":\n        tag_name = tag_name[1:]\n    # Replace \"@tag@other_tag\" by \"@other_tag\"\n    parts = flat_key.split(f\"@{tag_name}@\")\n    flat_key = \"@\".join(parts)\n    # Replace \"@tag.\" by \".\"\n    parts = flat_key.split(f\"@{tag_name}.\")\n    flat_key = \".\".join(parts)\n    # Remove \"@tag\" at the end of the string\n    if flat_key.endswith(f\"@{tag_name}\"):\n        flat_key = flat_key[: -len(f\"@{tag_name}\")]\n    return flat_key", "\ndef clean_tag(flat_key: str, tag_name: str) -> str:\n    \"\"\"Clean a tag from a flat key.\n\n    It removes all occurrences of the tag with the exact name.\n\n    Parameters\n    ----------\n    flat_key : str\n        The flat key to clean.\n    tag_name : str\n        The name of the tag to remove, with or without the '@' prefix.\n\n    Returns\n    -------\n    flat_key : str\n        The cleaned flat key.\n\n    Note\n    ----\n        ``tag_name`` is supposed to be the exact name of the tag.\n\n    Examples\n    --------\n    ::\n\n        >>> clean_tag('abc@tag.def@tag_2.ghi@tag', 'tag')\n        abc.def@tag_2.ghi\n    \"\"\"\n    if tag_name[0] == \"@\":\n        tag_name = tag_name[1:]\n    # Replace \"@tag@other_tag\" by \"@other_tag\"\n    parts = flat_key.split(f\"@{tag_name}@\")\n    flat_key = \"@\".join(parts)\n    # Replace \"@tag.\" by \".\"\n    parts = flat_key.split(f\"@{tag_name}.\")\n    flat_key = \".\".join(parts)\n    # Remove \"@tag\" at the end of the string\n    if flat_key.endswith(f\"@{tag_name}\"):\n        flat_key = flat_key[: -len(f\"@{tag_name}\")]\n    return flat_key", "\n\ndef clean_all_tags(flat_key: str) -> str:\n    \"\"\"Clean all tags from a flat key.\n\n    Parameters\n    ----------\n    flat_key : str\n        The flat key to clean.\n\n    Returns\n    -------\n    flat_key : str\n        The cleaned flat key.\n    \"\"\"\n    list_keys = flat_key.split(\".\")\n    for i, key in enumerate(list_keys):\n        key = re.sub(r\"@.*\", \"\", key)\n        list_keys[i] = key\n    flat_key = \".\".join(list_keys)\n    return flat_key", "\n\ndef dict_clean_tags(flat_dict: Dict[str, Any]) -> Tuple[Dict[str, Any], List[str]]:\n    \"\"\"Clean a dict from all tags and return the list of keys with tags.\n\n    Parameters\n    ----------\n    flat_dict : Dict[str, Any]\n        The flat dict to clean.\n\n    Returns\n    -------\n    clean_dict : Dict[str, Any]\n        The cleaned flat dict without tags in the keys.\n    tagged_keys : List[str]\n        The list of keys with tags that have been cleaned.\n    \"\"\"\n    items = list(flat_dict.items())\n    clean_dict = copy.deepcopy(flat_dict)\n    tagged_keys = []\n    for key, value in items:\n        if \"@\" in key:\n            del clean_dict[key]\n            clean_dict[clean_all_tags(key)] = value\n            tagged_keys.append(key)\n    return clean_dict, tagged_keys", "\n\ndef is_tag_in(flat_key: str, tag_name: str, *, full_key: bool = False) -> bool:\n    \"\"\"Check if a tag is in a flat key.\n\n    The tag name must be the exact name, with or without the \"@\".\n    It supports the case where there are other tags that are prefixes\n    or suffixes of the considered tag.\n\n    Parameters\n    ----------\n    flat_key : str\n        The flat key to check.\n    tag_name : str\n        The name of the tag to check, with or without the '@' prefix.\n    full_key : bool, optional\n        If True, check for the full key. If False, check for the last part of\n        the flat key (after the last dot) that correspond to the parameter name.\n        By default, False.\n\n    Returns\n    -------\n    bool\n        True if the tag is in the flat key, False otherwise.\n    \"\"\"\n    if tag_name[0] == \"@\":\n        tag_name = tag_name[1:]\n    if not full_key:\n        flat_key = flat_key.split(\".\")[-1]\n    is_in = (\n        flat_key.endswith(f\"@{tag_name}\")\n        or f\"@{tag_name}@\" in flat_key\n        or f\"@{tag_name}.\" in flat_key\n    )\n    return is_in", ""]}
{"filename": "cliconfig/__init__.py", "chunked_list": ["\"\"\"CLI Config: build your configuration from CLI by merging with processing.\n\nCopyright \u00a9 2023  Valentin Goldit\u00e9\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the MIT License.\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n    This project is free to use for COMMERCIAL USE, MODIFICATION,", "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n    This project is free to use for COMMERCIAL USE, MODIFICATION,\n    DISTRIBUTION and PRIVATE USE as long as the original license is\n    include as well as this copy right notice.\n\"\"\"\nfrom cliconfig._version import __version__, __version_tuple__\nfrom cliconfig.base import Config\nfrom cliconfig.config_routines import load_config, make_config, save_config, show_config\nfrom cliconfig.process_routines import (\n    merge_flat_paths_processing,", "from cliconfig.process_routines import (\n    merge_flat_paths_processing,\n    merge_flat_processing,\n)\nfrom cliconfig.processing.base import Processing\nfrom cliconfig.processing.builtin import DefaultProcessings\nfrom cliconfig.processing.create import (\n    create_processing_keep_property,\n    create_processing_value,\n)", "    create_processing_value,\n)\n\n__all__ = [\n    \"__version__\",\n    \"__version_tuple__\",\n    \"Config\",\n    \"DefaultProcessings\",\n    \"Processing\",\n    \"create_processing_keep_property\",", "    \"Processing\",\n    \"create_processing_keep_property\",\n    \"create_processing_value\",\n    \"make_config\",\n    \"load_config\",\n    \"merge_flat_paths_processing\",\n    \"merge_flat_processing\",\n    \"save_config\",\n    \"show_config\",\n]", "    \"show_config\",\n]\n"]}
{"filename": "cliconfig/process_routines.py", "chunked_list": ["\"\"\"Routines to manipulate dictionaries with processing.\n\nUsed by :mod:`.config_routines`.\n\"\"\"\nfrom typing import List, Optional, Union\n\nfrom cliconfig.base import Config\nfrom cliconfig.dict_routines import (\n    _flat_before_merge,\n    flatten,", "    _flat_before_merge,\n    flatten,\n    load_dict,\n    merge_flat,\n    save_dict,\n    unflatten,\n)\nfrom cliconfig.processing.base import Processing\n\n\ndef merge_flat_processing(\n    config1: Config,\n    config2: Config,\n    *,\n    allow_new_keys: bool = True,\n    preprocess_first: bool = True,\n    preprocess_second: bool = True,\n    postprocess: bool = True,\n) -> Config:\n    \"\"\"Flatten, merge config2 into config1 and apply pre and post processing.\n\n    Work even if the config dicts have a mix of nested and flat dictionaries.\n    If both arguments are configs, the process lists are merged before applying\n    the processing. The duplicate processings (with same internal variables)\n    are removed.\n\n    Parameters\n    ----------\n    config1 : Config\n        The first config.\n    config2 : Config\n        The second dict to merge into config1.\n    allow_new_keys : bool, optional\n        If True, new keys (that are not in config1) are allowed in config2.\n        Otherwise, it raises an error. By default True.\n    preprocess_first : bool, optional\n        If True, apply pre-merge processing to config1. By default True.\n    preprocess_second : bool, optional\n        If True, apply pre-merge processing to config2. By default True.\n    postprocess : bool, optional\n        If True, apply post-merge processing to the merged config. By default True.\n\n    Raises\n    ------\n    ValueError\n        If allow_new_keys is False and config2 has new keys that are not in config1.\n    ValueError\n        If there are conflicting keys when flatten one of the dicts.\n\n    Returns\n    -------\n    flat_config : Config\n        The merged flat config.\n    \"\"\"\n    # Flatten the dictionaries\n    config1.dict, config2.dict = _flat_before_merge(config1.dict, config2.dict)\n    # Get the process list of the merge\n    process_list = config1.process_list\n    for process in config2.process_list:\n        # NOTE 2 processings are equal if they are the same class and add the same\n        # attributes.\n        if process not in process_list:\n            process_list.append(process)\n    # Apply the pre-merge processing\n    if preprocess_first:\n        config1.process_list = process_list\n        pre_order_list = sorted(process_list, key=lambda x: x.premerge_order)\n        for processing in pre_order_list:\n            config1 = processing.premerge(config1)\n        process_list = config1.process_list\n    if preprocess_second:\n        config2.process_list = process_list\n        pre_order_list = sorted(process_list, key=lambda x: x.premerge_order)\n        for processing in pre_order_list:\n            config2 = processing.premerge(config2)\n        process_list = config2.process_list\n    # Merge the dictionaries\n    flat_dict = merge_flat(config1.dict, config2.dict, allow_new_keys=allow_new_keys)\n    # Create the new config\n    flat_config = Config(flat_dict, process_list)\n    # Apply the postmerge processing\n    if postprocess:\n        post_order_list = sorted(process_list, key=lambda x: x.postmerge_order)\n        for processing in post_order_list:\n            flat_config = processing.postmerge(flat_config)\n    return flat_config", "\n\ndef merge_flat_processing(\n    config1: Config,\n    config2: Config,\n    *,\n    allow_new_keys: bool = True,\n    preprocess_first: bool = True,\n    preprocess_second: bool = True,\n    postprocess: bool = True,\n) -> Config:\n    \"\"\"Flatten, merge config2 into config1 and apply pre and post processing.\n\n    Work even if the config dicts have a mix of nested and flat dictionaries.\n    If both arguments are configs, the process lists are merged before applying\n    the processing. The duplicate processings (with same internal variables)\n    are removed.\n\n    Parameters\n    ----------\n    config1 : Config\n        The first config.\n    config2 : Config\n        The second dict to merge into config1.\n    allow_new_keys : bool, optional\n        If True, new keys (that are not in config1) are allowed in config2.\n        Otherwise, it raises an error. By default True.\n    preprocess_first : bool, optional\n        If True, apply pre-merge processing to config1. By default True.\n    preprocess_second : bool, optional\n        If True, apply pre-merge processing to config2. By default True.\n    postprocess : bool, optional\n        If True, apply post-merge processing to the merged config. By default True.\n\n    Raises\n    ------\n    ValueError\n        If allow_new_keys is False and config2 has new keys that are not in config1.\n    ValueError\n        If there are conflicting keys when flatten one of the dicts.\n\n    Returns\n    -------\n    flat_config : Config\n        The merged flat config.\n    \"\"\"\n    # Flatten the dictionaries\n    config1.dict, config2.dict = _flat_before_merge(config1.dict, config2.dict)\n    # Get the process list of the merge\n    process_list = config1.process_list\n    for process in config2.process_list:\n        # NOTE 2 processings are equal if they are the same class and add the same\n        # attributes.\n        if process not in process_list:\n            process_list.append(process)\n    # Apply the pre-merge processing\n    if preprocess_first:\n        config1.process_list = process_list\n        pre_order_list = sorted(process_list, key=lambda x: x.premerge_order)\n        for processing in pre_order_list:\n            config1 = processing.premerge(config1)\n        process_list = config1.process_list\n    if preprocess_second:\n        config2.process_list = process_list\n        pre_order_list = sorted(process_list, key=lambda x: x.premerge_order)\n        for processing in pre_order_list:\n            config2 = processing.premerge(config2)\n        process_list = config2.process_list\n    # Merge the dictionaries\n    flat_dict = merge_flat(config1.dict, config2.dict, allow_new_keys=allow_new_keys)\n    # Create the new config\n    flat_config = Config(flat_dict, process_list)\n    # Apply the postmerge processing\n    if postprocess:\n        post_order_list = sorted(process_list, key=lambda x: x.postmerge_order)\n        for processing in post_order_list:\n            flat_config = processing.postmerge(flat_config)\n    return flat_config", "\n\ndef merge_flat_paths_processing(\n    config_or_path1: Union[str, Config],\n    config_or_path2: Union[str, Config],\n    *,\n    additional_process: Optional[List[Processing]] = None,\n    allow_new_keys: bool = True,\n    preprocess_first: bool = True,\n    preprocess_second: bool = True,\n    postprocess: bool = True,\n) -> Config:\n    \"\"\"Flatten, merge and apply processing to two configs or their yaml paths.\n\n    Similar to :func:`merge_flat_processing` but allows to pass configs\n    or their yaml paths. Work even if the configs have a mix of nested and flat dicts.\n    If both arguments are configs, the process lists are merged before applying\n    the processing. The duplicate processings (with same internal variables)\n    are removed.\n\n    Parameters\n    ----------\n    config_or_path1 : Union[str, Config]\n        The first config or its path.\n    config_or_path2 : Union[str, Config]\n        The second config or its path, to merge into first config.\n    additional_process : Optional[List[Processing]], optional\n        Additional processings to apply to the merged config. It can\n        be useful to merge a config from its path while it has some specific\n        processings.\n    allow_new_keys : bool, optional\n        If True, new keys (that are not in config1) are allowed in config2.\n        Otherwise, it raises an error. By default True.\n    preprocess_first : bool, optional\n        If True, apply pre-merge processing to config1. By default True.\n    preprocess_second : bool, optional\n        If True, apply pre-merge processing to config2. By default True.\n    postprocess : bool, optional\n        If True, apply post-merge processing to the merged config. By default True.\n\n    Raises\n    ------\n    ValueError\n        If allow_new_keys is False and config2 has new keys that are not in config1.\n    ValueError\n        If there are conflicting keys when flatten one of the dicts.\n\n    Returns\n    -------\n    flat_config : Config\n        The merged flat config.\n    \"\"\"\n    configs = []\n    for config_or_path in [config_or_path1, config_or_path2]:\n        if isinstance(config_or_path, str):\n            config_dict = load_dict(config_or_path)\n            config = Config(config_dict, [])\n        elif isinstance(config_or_path, Config):\n            config = config_or_path\n        elif isinstance(config_or_path, dict):\n            raise ValueError(\n                \"config_or_path must be a Config instance or a path to a yaml file \"\n                \"but you passed a dict. If you want to use it as a valid input, \"\n                \"you should use Config(<input dict>, []) instead.\"\n            )\n        else:\n            raise ValueError(\n                \"config_or_path must be a Config instance or a path to a yaml file.\"\n            )\n        configs.append(config)\n    config1, config2 = configs[0], configs[1]\n    if additional_process is not None:\n        config1.process_list.extend(additional_process)\n        config2.process_list.extend(additional_process)\n    flat_config = merge_flat_processing(\n        config1,\n        config2,\n        allow_new_keys=allow_new_keys,\n        preprocess_first=preprocess_first,\n        preprocess_second=preprocess_second,\n        postprocess=postprocess,\n    )\n    return flat_config", "\n\ndef save_processing(config: Config, path: str) -> None:\n    \"\"\"Save a config and apply pre-save processing before saving.\n\n    Parameters\n    ----------\n    config : Config\n        The config to save.\n    path : str\n        The path to the yaml file to save the config dict.\n    \"\"\"\n    config.dict = flatten(config.dict)\n    # Get the pre-save order\n    order_list = sorted(config.process_list, key=lambda x: x.presave_order)\n    # Apply the pre-save processing\n    for processing in order_list:\n        config = processing.presave(config)\n    # Unflatten and save the dict\n    config.dict = unflatten(config.dict)\n    save_dict(config.dict, path)", "\n\ndef load_processing(path: str, process_list: List[Processing]) -> Config:\n    \"\"\"Load a dict from yaml file path and apply post-load processing.\n\n    Parameters\n    ----------\n    path : str\n        The path to the file to load the dict.\n    process_list: List[Processing]\n        The list of processing to apply after loading. Only post-load\n        processing is applied. The order of the processing is given\n        by the postload_order attribute of the processing.\n\n    Returns\n    -------\n    flat_config : Config\n        The loaded flat config.\n    \"\"\"\n    # Load the dict and flatten it\n    out_dict = flatten(load_dict(path))\n    flat_config = Config(out_dict, process_list)\n    # Get the post-load order\n    order_list = sorted(process_list, key=lambda x: x.postload_order)\n    # Apply the post-load processing\n    for processing in order_list:\n        flat_config = processing.postload(flat_config)\n    return flat_config", "\n\ndef end_build_processing(flat_config: Config) -> Config:\n    \"\"\"Apply end-build processings to a flat config.\n\n    Parameters\n    ----------\n    flat_config : Config\n        The flat config to apply the end-build processings.\n\n    Returns\n    -------\n    flat_config : Config\n        The flat config after applying the end-build processings.\n    \"\"\"\n    order_list = sorted(flat_config.process_list, key=lambda x: x.endbuild_order)\n    for processing in order_list:\n        flat_config = processing.endbuild(flat_config)\n    return flat_config", ""]}
{"filename": "cliconfig/processing/base.py", "chunked_list": ["\"\"\"Base class for processing.\n\nUsed to make configuration object and run the routines in :mod:`.process_routines`\nand :mod:`.config_routines`.\n\"\"\"\nfrom cliconfig.base import Config\n\n\nclass Processing:\n    \"\"\"Processing base class.\n\n    Each processing classes contains pre-merge, post-merge, pre-save\n    and post-load processing. They are used with routines that apply\n    processing in :mod:`.process_routines` and\n    :mod:`.config_routines`.\n\n    That are applied in the order defined\n    by the order attribute in case of multiple processing.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.premerge_order = 0.0\n        self.postmerge_order = 0.0\n        self.endbuild_order = 0.0\n        self.presave_order = 0.0\n        self.postload_order = 0.0\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\n\n        Function applied to the flat config to modify it\n        before merging. It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\n\n        Function applied to the flat config to modify it\n        after merging . It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\n\n        Function applied to the flat config to modify it at the end of\n        a building process (typically :func:`.make_config` or :func:`.load_config`).\n        It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\n\n        Function applied to the flat config to modify it before\n        saving. It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def postload(self, flat_config: Config) -> Config:\n        \"\"\"Post-load processing.\n\n        Function applied to the flat config to modify it after\n        loading. It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def __eq__(self, __value: object) -> bool:\n        \"\"\"Equality operator.\n\n        Two processing are equal if they are the same class and add the same\n        attributes (accessed with ``__dict__``).\n        \"\"\"\n        equal = (\n            isinstance(__value, self.__class__) and self.__dict__ == __value.__dict__\n        )\n        return equal", "class Processing:\n    \"\"\"Processing base class.\n\n    Each processing classes contains pre-merge, post-merge, pre-save\n    and post-load processing. They are used with routines that apply\n    processing in :mod:`.process_routines` and\n    :mod:`.config_routines`.\n\n    That are applied in the order defined\n    by the order attribute in case of multiple processing.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.premerge_order = 0.0\n        self.postmerge_order = 0.0\n        self.endbuild_order = 0.0\n        self.presave_order = 0.0\n        self.postload_order = 0.0\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\n\n        Function applied to the flat config to modify it\n        before merging. It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\n\n        Function applied to the flat config to modify it\n        after merging . It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\n\n        Function applied to the flat config to modify it at the end of\n        a building process (typically :func:`.make_config` or :func:`.load_config`).\n        It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\n\n        Function applied to the flat config to modify it before\n        saving. It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def postload(self, flat_config: Config) -> Config:\n        \"\"\"Post-load processing.\n\n        Function applied to the flat config to modify it after\n        loading. It takes a flat config and returns a flat config.\n        \"\"\"\n        return flat_config\n\n    def __eq__(self, __value: object) -> bool:\n        \"\"\"Equality operator.\n\n        Two processing are equal if they are the same class and add the same\n        attributes (accessed with ``__dict__``).\n        \"\"\"\n        equal = (\n            isinstance(__value, self.__class__) and self.__dict__ == __value.__dict__\n        )\n        return equal", ""]}
{"filename": "cliconfig/processing/__init__.py", "chunked_list": ["\"\"\"Processing module to apply functions on merge (before and after), save and load.\"\"\"\n\nfrom cliconfig.processing.base import Processing\n\n__all__ = [\"Processing\"]\n"]}
{"filename": "cliconfig/processing/builtin.py", "chunked_list": ["\"\"\"Built-in processing classes.\n\nBuilt-in classes to apply pre-merge, post-merge, pre-save and post-load modifications\nto dict with processing routines :mod:`.process_routines`.\n\nThey are the default processing used by the config routines :func:`.load_config`\nand :func:`.make_config`.\n\"\"\"\nfrom typing import Any, Dict, List, Set\n", "from typing import Any, Dict, List, Set\n\nfrom cliconfig.base import Config\nfrom cliconfig.process_routines import (\n    merge_flat_paths_processing,\n    merge_flat_processing,\n)\nfrom cliconfig.processing._type_parser import _isinstance, _parse_type\nfrom cliconfig.processing.base import Processing\nfrom cliconfig.tag_routines import clean_all_tags, clean_tag, dict_clean_tags, is_tag_in", "from cliconfig.processing.base import Processing\nfrom cliconfig.tag_routines import clean_all_tags, clean_tag, dict_clean_tags, is_tag_in\n\n\nclass ProcessMerge(Processing):\n    \"\"\"Merge dicts just in time with ``@merge_after/_before/_add`` tags.\n\n    Tag your key with ``@merge_after``, ``@merge_before`` or ``@merge_add``\n    to load the config corresponding to the value (which is a yaml path) and\n    merge it just before or after the current config. The merged dicts will be\n    processed with pre-merge but not post-merge to ensure that merged\n    configurations are recursively processed with pre-merge before applying a\n    post-merge processing. It allows the merged configs to make references to\n    each other (typically for copy) even without containing the merge tags\n    itself.\n\n    * '@merge_add' merges the dict corresponding to the path by allowing ONLY new keys\n      It is a security check when you want to add a dict completely new,\n      the typical usage for a default config splitted in several files.\n    * '@merge_after' merge the dict corresponding to the path on the current dict\n    * '@merge_before' merge the current dict on the dict corresponding to the path\n\n    The processing is a pre-merge processing only and occurs before\n    almost all of the other processings.\n    Pre-merge order: -20.0\n\n    Examples\n    --------\n    .. code-block:: yaml\n\n        # config1.yaml\n        a:\n          b: 1\n          b_path@merge_after: dict2.yaml\n\n        # config2.yaml\n        a.b: 2\n        c_path@merge_add: config3.yaml\n\n        # config3.yaml\n        c: 3\n\n    Before merging, the config1 is interpreted as the dict:\n\n    ::\n\n        {'a': {'b': 2, 'b_path': 'config2.yaml'}, 'c_path': 'config3.yaml', 'c': 3}\n\n    If you replace '@merge_after' by '@merge_before', it will be:\n\n    ::\n\n        {'a': {'b': 1, 'b_path': 'config2.yaml'}, 'c_path': 'config3.yaml', 'c': 3}\n\n    Finally, if you replace ``@merge_after`` by ``@merge_add``, it will raises an\n    error because the key ``a.b`` already exists in the dict.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.premerge_order = -20.0\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, val in items:\n            if is_tag_in(flat_key, \"merge_after\"):\n                if not isinstance(val, str) or not val.endswith(\".yaml\"):\n                    raise ValueError(\n                        \"Key with '@merge_after' tag must be associated \"\n                        \"to a string corresponding to a *yaml* file.\"\n                        f\"The problem occurs at key: {flat_key}\"\n                    )\n                # Remove the tag in the dict\n                del flat_config.dict[flat_key]\n                flat_config.dict[clean_tag(flat_key, \"merge_after\")] = val\n                # Merge + process the dicts\n                # NOTE: we allow new keys with security because the merge\n                # following this pre-merge will avoid the creation of\n                # new keys if needed.\n                flat_config = merge_flat_paths_processing(\n                    flat_config,\n                    val,\n                    allow_new_keys=True,\n                    preprocess_first=False,  # Already processed\n                    postprocess=False,\n                )\n\n            elif is_tag_in(flat_key, \"merge_before\"):\n                if not isinstance(val, str) or not val.endswith(\".yaml\"):\n                    raise ValueError(\n                        \"Key with '@merge_before' tag must be associated \"\n                        \"to a string corresponding to a *yaml* file.\"\n                        f\"The problem occurs at key: {flat_key}\"\n                    )\n                # Remove the tag in the dict\n                del flat_config.dict[flat_key]\n                flat_config.dict[clean_tag(flat_key, \"merge_before\")] = val\n                # Merge + process the dicts\n                flat_config = merge_flat_paths_processing(\n                    val,\n                    flat_config,\n                    allow_new_keys=True,\n                    preprocess_second=False,  # Already processed\n                    postprocess=False,\n                )\n\n            elif is_tag_in(flat_key, \"merge_add\"):\n                if not isinstance(val, str) or not val.endswith(\".yaml\"):\n                    raise ValueError(\n                        \"Key with '@merge_add' tag must be associated \"\n                        \"to a string corresponding to a *yaml* file.\"\n                        f\"The problem occurs at key: {flat_key}\"\n                    )\n                # Remove the tag in the dict\n                del flat_config.dict[flat_key]\n                flat_config.dict[clean_tag(flat_key, \"merge_add\")] = val\n                # Pre-merge process the dict with the process list of\n                # the current config\n                flat_config_to_merge = merge_flat_paths_processing(\n                    Config({}, []),\n                    val,\n                    additional_process=flat_config.process_list,\n                    allow_new_keys=True,\n                    preprocess_first=False,  # Already processed\n                    postprocess=False,\n                )\n                clean_dict, _ = dict_clean_tags(flat_config.dict)\n                clean_dict_to_merge, _ = dict_clean_tags(flat_config_to_merge.dict)\n                for key in clean_dict_to_merge:\n                    if clean_all_tags(key) in clean_dict:\n                        raise ValueError(\n                            f\"@merge_add doest not allow to add already \"\n                            f\"existing keys but key '{key}' is found in both \"\n                            \"dicts. Use @merge_after or @merge_before if you \"\n                            \"want to merge this key, or check your key names.\"\n                        )\n                # Merge the dicts (order is not important by construction)\n                # NOTE: we delete the process list of the current config\n                # to speed up the process by avoiding redundant processing\n                flat_config = merge_flat_processing(\n                    Config(flat_config.dict, []),\n                    flat_config_to_merge,\n                    allow_new_keys=True,\n                    preprocess_first=False,  # Already processed\n                    preprocess_second=False,  # Already processed\n                    postprocess=False,\n                )\n        return flat_config", "\n\nclass ProcessCopy(Processing):\n    \"\"\"Copy a value with ``@copy`` tag. The copy is protected from direct updates.\n\n    Tag your key with ``@copy`` and with value the name of the flat key to copy.\n    The pre-merge processing removes the tag. The post-merge processing\n    sets the value (if the copied key exists). The end-build processing checks\n    that the copied key exists or was already copied once. The pre-save processing\n    restore the tag and the key to copy to keep the information on future loads.\n    The post-merge and the end-build processings occurs after most processings to\n    allow the user to modify or add the copied key before the copy.\n    Pre-merge order: 0.0\n    Post-merge order: 10.0\n    End-build order: 10.0\n    Pre-save order: 0.0\n\n    Examples\n    --------\n    .. code-block:: yaml\n\n        # config.yaml\n        a:\n          b: 1\n          c@copy: a.b\n\n    Before merging, the config is interpreted as the dict\n\n    .. code-block:: python\n\n        {'a': {'b': 1, 'c': 1}}\n\n    Note\n    ----\n\n        * The copy key is protected against any modification and will raise an error\n          if you try to modify it but will be updated if the copied key is updated.\n        * If the key to copy does not exist in the config on post-merge, no error\n          is raised to let the user the possibility to add the key later via merge.\n          However, if the key still does not exist at the end of the build\n          (and the key was never copied), an error is raised.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.premerge_order = 0.0\n        self.postmerge_order = 10.0\n        self.endbuild_order = 10.0\n        self.presave_order = 0.0\n        self.keys_to_copy: Dict[str, str] = {}\n        self.copied_keys: Set[str] = set()\n        self.current_value: Dict[str, Any] = {}\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, val in items:\n            if is_tag_in(flat_key, \"copy\"):\n                if not isinstance(val, str):\n                    raise ValueError(\n                        \"Key with '@copy' tag must be associated \"\n                        \"to a string corresponding to a flat key. \"\n                        f\"The problem occurs at key: {flat_key} with value: {val}\"\n                    )\n                clean_key = clean_all_tags(flat_key)\n                if (\n                    clean_key in self.keys_to_copy\n                    and self.keys_to_copy[clean_key] != val\n                ):\n                    raise ValueError(\n                        \"Key with '@copy' has change its value to copy. Found key: \"\n                        f\"{flat_key} with value: {val}, previous value to copy: \"\n                        f\"{self.keys_to_copy[clean_key]}\"\n                    )\n                # Store the key to copy and value\n                self.keys_to_copy[clean_key] = val\n                self.current_value[clean_key] = val\n                # Remove the tag and update the dict\n                flat_config.dict[clean_tag(flat_key, \"copy\")] = val\n                del flat_config.dict[flat_key]\n        return flat_config\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\"\"\"\n        for key, val in self.keys_to_copy.items():\n            # NOTE: Do not raise an error if the key to copy does not exist\n            # yet because it can be added later in a future merge\n            if key in flat_config.dict and val in flat_config.dict:\n                if flat_config.dict[key] != self.current_value[key]:\n                    # The key has been modified\n                    raise ValueError(\n                        \"Found attempt to modify a key with '@copy' tag. The key \"\n                        f\"is protected against direct updates. Found key: {key} of \"\n                        f\"value {flat_config.dict[key]} that copy {val} of value \"\n                        f\"{flat_config.dict[val]}\"\n                    )\n                # Copy the value\n                flat_config.dict[key] = flat_config.dict[val]\n                self.copied_keys.add(key)\n                # Update the current value\n                self.current_value[key] = flat_config.dict[val]\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\"\"\"\n        for key, val in self.keys_to_copy.items():\n            if key in flat_config.dict and key not in self.copied_keys:\n                if val in flat_config.dict:\n                    # Copy the value\n                    flat_config.dict[key] = flat_config.dict[val]\n                    self.copied_keys.add(key)\n                else:\n                    raise ValueError(\n                        \"A key with '@copy' tag has been found but the key to copy \"\n                        \"does not exist at the end of the build and it has been \"\n                        f\"never copied. Found key: {key} that would copy the \"\n                        f\"key: {val}.\"\n                    )\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\"\"\"\n        # Restore the tag with the key to copy to keep the information\n        # on further loading\n        keys = list(flat_config.dict.keys())\n        for key in keys:\n            clean_key = clean_all_tags(key)\n            if clean_key in self.keys_to_copy:\n                new_key = key + \"@copy\"\n                del flat_config.dict[key]\n                flat_config.dict[new_key] = self.keys_to_copy[clean_key]\n        return flat_config", "\n\nclass ProcessTyping(Processing):\n    \"\"\"Force a type with ``@type:<mytype>`` tag. The type is then forced forever.\n\n    Allow basic types (none, any, bool, int, float, str, list, dict), nested lists,\n    nested dicts, unions (with Union or the '|' symbol) and Optional.\n    The type description is lowercased and spaces are removed.\n\n    For instance: ``@type:None|List[Dict[str, int|float]]`` is valid and force\n    the type to be None or a list containing dicts with str keys and int or float\n    values.\n\n    The processing stores the type in pre-merge and check alls forced types on\n    end-build. It restore the tag in pre-save to keep the information on\n    future loads. The end-build processing occurs after almost all processings.\n    Pre-merge order: 0.0\n    End-build order: 20.0\n    Pre-save order: 0.0\n\n    Note\n    ----\n        The type is not checked on pre-merge or ost-merge to allow the parameter\n        to be updated (by a copy or a merge for instance). The goal of this\n        processing is to ensure the type at the end of the build.\n\n    Examples\n    --------\n    ::\n\n        in_dict = {\"param@type:None|List[int|float]\": None}\n        dict1 = {param: [0, 1, 2.0]}  # no error\n        dict2 = {param: [0, 1, 2.0, 'a']}  # error\n\n    Merging configs with dictionaries ``in_dict`` and ``dict1`` raises no\n    error and ``param`` is forced to be None or a list of int or float forever.\n    Merging config with ``in_dict`` and ``dict3`` raises an error on post-merge\n    due to the 'a' value (which is a string).\n\n    Note that removing \"None|\" in the type description of ``param`` still\n    doesn't raise an error in the first case because the type checking is\n    evaluated after the merge with ``dict2``.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.premerge_order = 0.0\n        self.endbuild_order = 20.0\n        self.presave_order = 0.0\n        self.forced_types: Dict[str, tuple] = {}\n        self.type_desc: Dict[str, str] = {}  # For error messages\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, val in items:\n            end_key = flat_key.split(\".\")[-1]\n            if \"@type:\" in end_key:\n                # Get the type description\n                trail = end_key.split(\"@type:\")[-1]\n                type_desc = trail.split(\"@\")[0]  # (in case of multiple tags)\n                expected_type = tuple(_parse_type(type_desc))\n                clean_key = clean_all_tags(flat_key)\n                if clean_key in self.forced_types and set(\n                    self.forced_types[clean_key]\n                ) != set(expected_type):\n                    raise ValueError(\n                        f\"Find the tag '@type:{type_desc}' on a key that has already \"\n                        \"been associated to an other type: \"\n                        f\"{self.type_desc[clean_key]}. \"\n                        f\"Find problem at key: {flat_key}\"\n                    )\n                # Remove the tag\n                del flat_config.dict[flat_key]\n                flat_config.dict[clean_tag(flat_key, f\"type:{type_desc}\")] = val\n                # Store the forced type\n                self.forced_types[clean_key] = expected_type\n                self.type_desc[clean_key] = type_desc\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\"\"\"\n        for key, expected_type in self.forced_types.items():\n            if key in flat_config.dict and not _isinstance(\n                flat_config.dict[key], expected_type\n            ):\n                type_desc = self.type_desc[key]\n                raise ValueError(\n                    f\"Key previously tagged with '@type:{type_desc}' must be \"\n                    f\"associated to a value of type {type_desc}. Find the \"\n                    f\"value: {flat_config.dict[key]} of type \"\n                    f\"{type(flat_config.dict[key])} at key: {key}\"\n                )\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\"\"\"\n        # Restore the tag with the type to keep the information\n        # on further loading\n        keys = list(flat_config.dict.keys())\n        for key in keys:\n            clean_key = clean_all_tags(key)\n            if clean_key in self.type_desc:\n                new_key = key + f\"@type:{self.type_desc[clean_key]}\"\n                flat_config.dict[new_key] = flat_config.dict[key]\n                del flat_config.dict[key]\n        return flat_config", "\n\nclass ProcessSelect(Processing):\n    \"\"\"Select a sub-config with ``@select`` and delete the rest of its parent config.\n\n    First look in pre-merge for a parameter tagged with ``@select`` containing a\n    flat key corresponding to a sub-configurations to keep. The parent configuration\n    is then deleted on post-merge, except the selected sub-configuration\n    and eventually the tagged parameter (if it is in the same sub-configuration).\n    It is also possible to select multiple keys of a same sub-configuration\n    (meaning that the part before the last dot must be equal) by passing a\n    list of flat keys.\n    Pre-merge order: 0.0\n    Post-merge order: 0.0\n\n    Examples\n    --------\n    .. code-block:: yaml\n\n        models:\n            model_names@select: [models.model1, models.model3]\n            model1:\n                param1: 1\n                param2: 2\n            model2:\n                param1: 3\n                param2: 4\n            model3:\n                submodel:\n                    param: 5\n            model4:\n                param: 6\n\n    Result in deleting ``models.model2`` (``param1`` and ``param2``) and\n    ``models.model4.param``, and keeping the rest.\n\n    Warning\n    -------\n\n        For security reasons, this processing prevents from deleting\n        the configuration at the root, which is the case when the\n        selected key doesn't contain a dot. It raises an error in this case.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.keys_that_select: Set[str] = set()\n        self.subconfigs_to_delete: Set[str] = set()\n        self.keys_to_keep: Set[str] = set()\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, val in items:\n            if is_tag_in(flat_key, \"select\"):\n                # Remove the tag\n                clean_key = clean_all_tags(flat_key)\n                del flat_config.dict[flat_key]\n                flat_config.dict[clean_tag(flat_key, \"select\")] = val\n                self.keys_that_select.add(clean_key)\n                if isinstance(val, str):\n                    subconfig = \".\".join(flat_key.split(\".\")[:-1])\n                    keys_to_keep = [clean_key, val]\n                elif isinstance(val, list):\n                    subconfig = \".\".join(val[0].split(\".\")[:-1])\n                    for key in val[1:]:\n                        subconfig2 = \".\".join(key.split(\".\")[:-1])\n                        if subconfig != subconfig2:\n                            raise ValueError(\n                                \"The keys in the list of parameters tagged with \"\n                                \"'@select' must be identical before the last dot \"\n                                f\"(= on the same subconfig). Find: {subconfig} and \"\n                                f\"{subconfig2} before the last dot.\"\n                            )\n                    keys_to_keep = [clean_key] + val\n                else:\n                    raise ValueError(\n                        \"The value of parameters tagged with '@select' must be a \"\n                        \"string or a list of strings representing flat key(s). \"\n                    )\n                subconfig = clean_all_tags(subconfig)\n                if subconfig == \"\":\n                    raise ValueError(\n                        \"Find attempt to delete the configuration at the root. You \"\n                        \"must pass a flat key with a least one dot on parameter \"\n                        f\"tagged with @select. Find key: {flat_key} with value: {val}\"\n                    )\n                self.subconfigs_to_delete.add(subconfig)\n                self.keys_to_keep.update(keys_to_keep)\n        return flat_config\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\"\"\"\n\n        def _is_in_subconfig(key: str, subconfig: str) -> bool:\n            \"\"\"Check if a key is in a subconfig with the exact name.\"\"\"\n            return key == subconfig or key.startswith(subconfig + \".\")\n\n        # Delete all keys on the subconfigs except the ones to keep\n        for subconfig in self.subconfigs_to_delete:\n            for key in list(flat_config.dict.keys()):\n                if _is_in_subconfig(key, subconfig) and not any(\n                    _is_in_subconfig(key, key_to_keep)\n                    for key_to_keep in self.keys_to_keep\n                ):\n                    del flat_config.dict[key]\n        return super().postmerge(flat_config)\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\"\"\"\n        # Restore the tag with the type to keep the information\n        # on further loading\n        keys = list(flat_config.dict.keys())\n        for key in keys:\n            clean_key = clean_all_tags(key)\n            if clean_key in self.keys_that_select:\n                new_key = key + \"@select\"\n                flat_config.dict[new_key] = flat_config.dict[key]\n                del flat_config.dict[key]\n        return flat_config", "\n\nclass ProcessDelete(Processing):\n    \"\"\"Delete the parameters tagged with ``@delete`` on pre-merge.\n\n    This processing is useful to activate a processing without adding\n    an additional parameter in the default configuration to avoid the error\n    on merge with ``allow_new_keys=False``. This processing is applied very\n    late on pre-merge to allow the others processing to be applied before\n    deleting the parameters.\n    Pre-merge order: 30.0\n\n    Examples\n    --------\n    .. code-block:: yaml\n\n        # main.yaml\n        1@select@delete: configs.config1\n        2@merge_add@delete: config1.yaml\n        3@merge_add@delete: config2.yaml\n\n        # config1.yaml\n        configs.config1.param: 1\n        configs.config1.param2: 2\n\n        # config2.yaml\n        configs.config2.param: 3\n        configs.config2.param: 4\n\n    Here we want to merge two config files and select one sub-config.\n    We use the corresponding tags but we don't have a good name for the keys\n    and instead of adding a new parameter in the default configuration with\n    random names like \"1\", \"2\", \"3\", we use the ``@delete`` tag to delete the\n    keys after the pre-merge processing.\n\n    Warning\n    -------\n\n        The parameter is deleted on pre-merge. Therefore, if the parameter\n        also exists on the other configuration during merge (without the tag),\n        this parameter will be remain as it is. This processing is more used\n        to delete parameter that is NOT present in the default configuration.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        # After all pre-merge processing\n        self.premerge_order = 30.0\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        keys = list(flat_config.dict.keys())\n        for key in keys:\n            if is_tag_in(key, \"delete\"):\n                del flat_config.dict[key]\n        return flat_config", "\n\nclass ProcessNew(Processing):\n    \"\"\"Allow new sub-config/parameter absent from default config with tag ``@new``.\n\n    The tagged sub-config/parameter and its value is stored during pre-merge and\n    is deleted to avoid error on merge due to new key. It is then restored on\n    post-merge. Finally, the tag is restored on pre-save for further loading.\n    This processing is applied very late on pre-merge to allow\n    the others processing to be applied before deleting the parameters.\n    The post-merge processing is applied very early to allow the other processing\n    to use this new parameter.\n    Pre-merge order: 30.0\n    Post-merge order: -20.0\n    Pre-save order: 0.0\n\n    Disclaimer: It is preferable to have an exhaustive default configuration instead\n    of abusing this processing to improve the readability and to avoid typos errors\n    in the name of the parameters or their sub-configs.\n\n    Examples\n    --------\n    .. code-block:: yaml\n\n        # default.yaml\n        param1: 1\n\n        # additional.yaml\n        param2@new: 2\n        subconfig@new.subsubconfig:\n            param3: 3\n            param4: 4\n\n    Use default.yaml as default configuration and add additional.yaml as additional\n    configuration via CLI results on the configuration containing param1, param2\n    and the nested config containing param3 and param4.\n    Without the ``@new`` tag, an error is raised because param2 is not present in\n    the default configuration.\n\n    Note\n    ----\n\n        * Tag a subconfig by adding ``@new`` at the end of the key containing\n          the sub-config dict in your yaml file.\n        * When a parameter is added with this processing, it is possible to modify it\n          later via config merge without the tag because the parameter is then present\n          in the current configuration.\n        * If the tagged parameter or sub-config is already present in the current\n          configuration, no error are raised and the value is still updated on\n          post-merge. It may no have influence in practice.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.premerge_order = 30.0\n        self.postmerge_order = -20.0\n        self.new_vals: Dict[str, Any] = {}\n        self.new_vals_backup: Dict[str, Any] = {}\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        keys = list(flat_config.dict.keys())\n        for key in keys:\n            # NOTE: we don't use is_tag_in because we want to look\n            # for tags in the sub-configs too.\n            if \"@new@\" in key or \"@new.\" in key or key.endswith(\"@new\"):\n                clean_key = clean_all_tags(key)\n                self.new_vals[clean_key] = flat_config.dict[key]\n                self.new_vals_backup[clean_key] = flat_config.dict[key]\n                del flat_config.dict[key]\n        return flat_config\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\"\"\"\n        flat_config.dict.update(self.new_vals)\n        # Reset the new values to avoid re-adding them later\n        self.new_vals = {}\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\"\"\"\n        # Restore the tag @new to allow loading the config later by allowing\n        # these new parameters.\n        for key, value in self.new_vals_backup.items():\n            if key in flat_config.dict:\n                flat_config.dict[key + \"@new\"] = value\n                del flat_config.dict[key]\n        return flat_config", "\n\nclass ProcessCheckTags(Processing):\n    \"\"\"Raise an error if a tag is present in a key after pre-merging processes.\n\n    This security processing is always applied after all pre-merge process and\n    checks for '@' in the keys. It raises an error if one is found.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n        # NOTE: this processing is a special meta-processing that must be\n        # applied after all other pre-merge processing to ensure security.\n        # That why it has a very high pre-merge order and it is not a\n        # good idea to make pre-merge processing with higher order.\n        self.premerge_order = 1000.0\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        _, tagged_keys = dict_clean_tags(flat_config.dict)\n        if tagged_keys:\n            keys_message = \"\\n\".join(tagged_keys[:5])\n            raise ValueError(\n                \"Keys with tags are encountered at the end of \"\n                \"the pre-merge process. It is probably a mistake due to:\\n\"\n                \"- a typo in tag name\\n\"\n                \"- a missing processing in process_list\\n\"\n                \"- the use of an 'at' ('@') in a parameter name\\n\"\n                \"- the use of a custom processing that does not remove a tag\\n\\n\"\n                \"The tagged keys encountered (5 first if more than 5) are:\\n\"\n                f\"{keys_message}\"\n            )\n        return flat_config", "\n\nclass DefaultProcessings:\n    \"\"\"Default list of built-in processings.\n\n    To add these processings to a Config instance, use:\n    ::\n\n        config.process_list += DefaultProcessings().list\n\n    The current default processing list contains:\n     * ProcessCheckTags: protect against '@' in keys at the end of pre-merge)\n     * ProcessMerge (@merge_all, @merge_before, @merge_after): merge multiple\n       files into one.\n     * ProcessCopy (@copy): persistently copy a value from one key to an other\n       and protect it\n     * ProcessTyping (@type:X): force the type of parameter to any type X.\n     * ProcessSelect (@select): select sub-config(s) to keep and delete the\n       other sub-configs in the same parent config.\n     * ProcessDelete (@delete): delete the parameter tagged with @delete on\n       pre-merge.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.list: List[Processing] = [\n            ProcessCheckTags(),\n            ProcessMerge(),\n            ProcessCopy(),\n            ProcessTyping(),\n            ProcessSelect(),\n            ProcessDelete(),\n            ProcessNew(),\n        ]", ""]}
{"filename": "cliconfig/processing/_type_parser.py", "chunked_list": ["\"\"\"Private module with type parser for processing module with type manipulation.\"\"\"\nfrom pydoc import locate\nfrom typing import List, Optional, Tuple, Type, Union\n\n\ndef _parse_type(type_desc: str) -> Tuple:\n    \"\"\"Parse a type description.\n\n    Allow basic types (none, any, bool, int, float, str, list, dict), nested lists,\n    nested dicts, unions (with Union or the '|' symbol) and Optional.\n\n    Examples of representation:\n     * \"str\" -> (str,)\n     * \"None|Any\" -> (type(None), object)\n     * \"list|float\" -> (list, float)\n     * \"List[float]\" -> ((\"list\", (float,)),)\n     * \"Dict[str, Any]\" -> ((\"dict\", (str,), (object,)),)\n     * \"Dict[str, List[float]]\" -> ((\"dict\", (str,), (((\"list\", (float,)),),)),)\n     * \"Dict[str|bool, int|float]\" -> ((\"dict\", (str, bool), (int, float)),)\n     * ...\n\n    Raises\n    ------\n    ValueError\n        If the type description is not valid or not recognized.\n\n    Note\n    ----\n        The type description is lowercased and spaces are removed before parsing.\n    \"\"\"\n    # Clean up\n    old_type_desc = type_desc\n    type_desc = type_desc.replace(\" \", \"\").lower()\n    try:\n        # Base typeParseType\n        base_type = _parse_base_type(type_desc)\n        if base_type is not None:\n            return (base_type,)\n        # Split the external blocks enclosed by brackets\n        blocks = _split_brackets(type_desc, delimiter=\"|\")\n        types: Tuple = ()\n        for block in blocks:\n            if block[:5] == \"list[\":\n                types += _parse_list(block)\n            elif block[:5] == \"dict[\":\n                types += _parse_dict(block)\n            elif block[:9] == \"optional[\":\n                types += _parse_optional(block)\n            elif block[:6] == \"union[\":\n                types += _parse_union(block)\n            else:  # Should be a base type\n                base_type = _parse_base_type(block)\n                if base_type is not None:\n                    types += (base_type,)\n                else:\n                    raise ValueError(f\"Unknown type: '{block}'\")\n        return types\n    except ValueError as err:\n        # Revert the traceback to show the original type description\n        raise ValueError(f\"Unknown type: '{old_type_desc}'\") from err", "\n\ndef _parse_base_type(type_desc: str) -> Optional[Type]:\n    \"\"\"Parse a base type description.\n\n    Base types are: none, any, bool, int, float and str, list, dict.\n    Return None if the type is not a base type.\n    \"\"\"\n    if type_desc == \"none\":\n        return type(None)\n    if type_desc == \"any\":\n        # Match any type\n        return object\n    if type_desc in (\"bool\", \"int\", \"float\", \"str\", \"list\", \"dict\"):\n        return locate(type_desc)  # type: ignore\n    return None", "\n\ndef _parse_list(type_desc: str) -> Tuple:\n    \"\"\"Parse a \"list\" type description.\"\"\"\n    sub_desc = type_desc[5:-1]\n    if len(_split_brackets(sub_desc, delimiter=\",\")) > 1:\n        raise ValueError(f\"Invalid List type: '{type_desc}'\")\n    return ((\"list\",) + (_parse_type(sub_desc),),)\n\n\ndef _parse_dict(type_desc: str) -> Tuple:\n    \"\"\"Parse an \"dict\" type description.\"\"\"\n    sub_desc = type_desc[5:-1]\n    sub_blocks = _split_brackets(sub_desc, delimiter=\",\")\n    if len(sub_blocks) != 2:\n        raise ValueError(f\"Invalid Dict type: '{type_desc}'\")\n    key_type = _parse_type(sub_blocks[0])\n    value_type = _parse_type(sub_blocks[1])\n    return ((\"dict\",) + (key_type,) + ((value_type),),)", "\n\ndef _parse_dict(type_desc: str) -> Tuple:\n    \"\"\"Parse an \"dict\" type description.\"\"\"\n    sub_desc = type_desc[5:-1]\n    sub_blocks = _split_brackets(sub_desc, delimiter=\",\")\n    if len(sub_blocks) != 2:\n        raise ValueError(f\"Invalid Dict type: '{type_desc}'\")\n    key_type = _parse_type(sub_blocks[0])\n    value_type = _parse_type(sub_blocks[1])\n    return ((\"dict\",) + (key_type,) + ((value_type),),)", "\n\ndef _parse_optional(type_desc: str) -> Tuple:\n    \"\"\"Parse an \"optional\" type description.\"\"\"\n    sub_desc = type_desc[9:-1]\n    if len(_split_brackets(sub_desc, delimiter=\",\")) > 1:\n        raise ValueError(f\"Invalid Optional type: '{type_desc}'\")\n    return ((type(None),) + _parse_type(sub_desc),)\n\n\ndef _parse_union(type_desc: str) -> Tuple:\n    \"\"\"Parse an \"union\" type description.\"\"\"\n    sub_desc = type_desc[6:-1]\n    # Split by comma\n    sub_blocks = _split_brackets(sub_desc, delimiter=\",\")\n    if len(sub_blocks) < 2:\n        raise ValueError(f\"Invalid Union type: '{type_desc}'\")\n    types: Tuple = ()\n    union_types = [_parse_type(sub_block) for sub_block in sub_blocks]\n    for union_type in union_types:\n        types += union_type\n    return types", "\n\ndef _parse_union(type_desc: str) -> Tuple:\n    \"\"\"Parse an \"union\" type description.\"\"\"\n    sub_desc = type_desc[6:-1]\n    # Split by comma\n    sub_blocks = _split_brackets(sub_desc, delimiter=\",\")\n    if len(sub_blocks) < 2:\n        raise ValueError(f\"Invalid Union type: '{type_desc}'\")\n    types: Tuple = ()\n    union_types = [_parse_type(sub_block) for sub_block in sub_blocks]\n    for union_type in union_types:\n        types += union_type\n    return types", "\n\ndef _split_brackets(type_desc: str, delimiter: str) -> List[str]:\n    \"\"\"Split a type description in blocks enclosed by brackets.\"\"\"\n    blocks = []\n    bracket_count = 0\n    i, j = 0, 0\n    while j < len(type_desc):\n        char = type_desc[j]\n        if char == \"[\":\n            bracket_count += 1\n        elif char == \"]\":\n            bracket_count -= 1\n        if bracket_count == 0 and char == delimiter:\n            blocks.append(type_desc[i:j])\n            i = j + 1\n            j += 2\n        else:\n            j += 1\n    blocks.append(type_desc[i:j])\n    return blocks", "\n\ndef _isinstance(obj: object, types: Union[Type, Tuple]) -> bool:\n    \"\"\"Check if an object is an instance of a type or a tuple of types.\n\n    Intended to work with the outputs of _parse_type.\n    \"\"\"\n    if isinstance(types, type):\n        return isinstance(obj, types)\n    if types[0] == \"list\" and len(types) == 2:\n        return isinstance(obj, list) and all(\n            _isinstance(elem, types[1]) for elem in obj\n        )\n    if types[0] == \"dict\" and len(types) == 3:\n        return (\n            isinstance(obj, dict)\n            and all(_isinstance(key, types[1]) for key in obj)\n            and all(_isinstance(value, types[2]) for value in obj.values())\n        )\n    if isinstance(types[0], (type, tuple)):\n        return any(_isinstance(obj, sub_types) for sub_types in types)\n    raise ValueError(f\"Invalid type for _isinstance: '{types}'\")", ""]}
{"filename": "cliconfig/processing/create.py", "chunked_list": ["\"\"\"Functions to create new processing quickly.\"\"\"\n# pylint: disable=unused-argument\nimport re\nfrom inspect import signature\nfrom typing import Any, Callable, Dict, Optional, Set, Union\n\nfrom cliconfig.base import Config\nfrom cliconfig.processing.base import Processing\nfrom cliconfig.tag_routines import clean_all_tags, clean_tag, is_tag_in\n", "from cliconfig.tag_routines import clean_all_tags, clean_tag, is_tag_in\n\n\ndef _is_matched(key: str, tag_name: Optional[str], regex: Optional[str]) -> bool:\n    \"\"\"Check if key match the regex or contain the tag.\"\"\"\n    if tag_name is not None and regex is not None:\n        raise ValueError(\"Either regex or tag_name must be defined but not both.\")\n    # Case defined with tag\n    if tag_name is not None:\n        return is_tag_in(key, tag_name)\n    # Case defined with regex\n    if regex is not None:\n        param_name = key.split(\".\")[-1].split(\"@\")[0]\n        return re.match(regex, param_name) is not None\n    raise ValueError(\"Either regex or tag_name must be defined.\")", "\n\nclass _ProcessingValue(Processing):\n    \"\"\"Processing class for make_processing_value.\"\"\"\n\n    def __init__(\n        self,\n        func: Union[Callable[[Any], Any], Callable[[Any, Config], Any]],\n        processing_type: str,\n        *,\n        regex: Optional[str],\n        tag_name: Optional[str],\n        order: float,\n        persistent: bool,\n    ) -> None:\n        super().__init__()\n        self.func = func\n        self.processing_type = processing_type\n        self.regex = regex\n        self.tag_name = tag_name\n        if processing_type == \"premerge\":\n            self.premerge_order = order\n        elif processing_type == \"postmerge\":\n            self.postmerge_order = order\n        elif processing_type == \"endbuild\":\n            self.endbuild_order = order\n        elif processing_type == \"presave\":\n            self.presave_order = order\n        elif processing_type == \"postload\":\n            self.postload_order = order\n        else:\n            raise ValueError(\n                f\"Processing type '{processing_type}' not recognized. Must be\"\n                \"one of 'premerge', 'postmerge', 'endbuild', 'presave' or\"\n                \"'postload'.\"\n            )\n        self.persistent = persistent\n        # matched_keys: store keys that match the regex or contain the tag\n        self.matched_keys: Set[str] = set()\n\n    def _apply_update(self, flat_config: Config) -> Config:\n        \"\"\"Apply value updates to matching parameters.\n\n        Does not assume that the keys are clean (it is not always the case\n        on pre-merge and post-load for instance).\n        \"\"\"\n        items = list(flat_config.dict.items())\n        for key, value in items:\n            clean_key = clean_all_tags(key)\n            if clean_key in self.matched_keys:\n                # Remove clean_key from match_keys if not persistent\n                if not self.persistent:\n                    self.matched_keys.remove(clean_key)\n\n                # Apply update\n\n                value = flat_config.dict[key]\n                try:\n                    # Case one argument\n                    if len(signature(self.func).parameters) == 1:\n                        flat_config.dict[key] = self.func(value)  # type: ignore\n                    # Case two arguments\n                    else:\n                        flat_config.dict[key] = self.func(  # type: ignore\n                            value, flat_config\n                        )\n                except ValueError:\n                    # Case no signature, trying to call with one argument\n                    flat_config.dict[key] = self.func(value)  # type: ignore\n        return flat_config\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, value in items:\n            if _is_matched(flat_key, self.tag_name, self.regex):\n                # Store the key\n                self.matched_keys.add(clean_all_tags(flat_key))\n                # Remove the tag if any\n                if self.tag_name:\n                    del flat_config.dict[flat_key]\n                    new_key = clean_tag(flat_key, self.tag_name)\n                    flat_config.dict[new_key] = value\n\n        if self.processing_type == \"premerge\":\n            return self._apply_update(flat_config)\n        return flat_config\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\"\"\"\n        if self.processing_type == \"postmerge\":\n            return self._apply_update(flat_config)\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\"\"\"\n        if self.processing_type == \"endbuild\":\n            return self._apply_update(flat_config)\n        return flat_config\n\n    def presave(self, flat_config: Config) -> Config:\n        \"\"\"Pre-save processing.\"\"\"\n        if self.processing_type == \"presave\":\n            return self._apply_update(flat_config)\n        return flat_config\n\n    def postload(self, flat_config: Config) -> Config:\n        \"\"\"Post-load processing.\"\"\"\n        if self.processing_type == \"postload\":\n            return self._apply_update(flat_config)\n        return flat_config", "\n\nclass _ProcessingKeepProperty(Processing):\n    \"\"\"Processing class for make_processing_keep_property.\"\"\"\n\n    def __init__(\n        self,\n        func: Union[Callable[[Any], Any], Callable[[Any, Config], Any]],\n        *,\n        regex: Optional[str],\n        tag_name: Optional[str],\n        premerge_order: float,\n        postmerge_order: float,\n        endbuild_order: float,\n    ) -> None:\n        super().__init__()\n        self.func = func\n        self.regex = regex\n        self.tag_name = tag_name\n        self.premerge_order = premerge_order\n        self.postmerge_order = postmerge_order\n        self.endbuild_order = endbuild_order\n\n        self.properties: Dict[str, Any] = {}\n\n    def _eval_property(self, key: str, flat_config: Config) -> Any:\n        \"\"\"Evaluate property.\"\"\"\n        try:\n            # Case one argument\n            if len(signature(self.func).parameters) == 1:\n                return self.func(flat_config.dict[key])  # type: ignore\n            # Case two arguments\n            return self.func(flat_config.dict[key], flat_config)  # type: ignore\n        except ValueError:\n            # Case no signature, trying to call with one argument\n            return self.func(flat_config.dict[key])  # type: ignore\n\n    def premerge(self, flat_config: Config) -> Config:\n        \"\"\"Pre-merge processing.\"\"\"\n        items = list(flat_config.dict.items())\n        for flat_key, value in items:\n            if _is_matched(flat_key, self.tag_name, self.regex):\n                clean_key = clean_all_tags(flat_key)\n                if clean_key not in self.properties:\n                    property_ = self._eval_property(flat_key, flat_config)\n                    self.properties[clean_key] = property_\n                if self.tag_name:\n                    del flat_config.dict[flat_key]\n                    new_key = clean_tag(flat_key, self.tag_name)\n                    flat_config.dict[new_key] = value\n        return flat_config\n\n    def _check_properties(self, flat_config: Config, processing_timing: str) -> None:\n        \"\"\"Check if all properties are still the same.\"\"\"\n        for flat_key, expected_property in self.properties.items():\n            if flat_key in flat_config.dict:\n                property_ = self._eval_property(flat_key, flat_config)\n                if property_ != expected_property:\n                    raise ValueError(\n                        f\"Property of key {flat_key} has changed from \"\n                        f\"{expected_property} to \"\n                        f\"{property_} while it is protected by a keep-property \"\n                        f\"processing (problem found on {processing_timing}).\"\n                    )\n\n    def postmerge(self, flat_config: Config) -> Config:\n        \"\"\"Post-merge processing.\"\"\"\n        self._check_properties(flat_config, \"post-merge\")\n        return flat_config\n\n    def endbuild(self, flat_config: Config) -> Config:\n        \"\"\"End-build processing.\"\"\"\n        self._check_properties(flat_config, \"end-build\")\n        return flat_config", "\n\ndef create_processing_value(\n    func: Union[Callable[[Any], Any], Callable[[Any, Config], Any]],\n    processing_type: str = \"premerge\",\n    *,\n    regex: Optional[str] = None,\n    tag_name: Optional[str] = None,\n    order: float = 0.0,\n    persistent: bool = False,\n) -> Processing:\n    r\"\"\"Create a processing object that modifies a value in config using tag or regex.\n\n    The processing is applied on pre-merge. It triggers when the key matches\n    the tag or the regex. The function apply ``flat_dict[key] = func(flat_dict[key])``.\n    You must only provide one of tag or regex. If tag is provided, the tag will be\n    removed from the key during pre-merge.\n\n    It also possible to pass the flat config as a second argument of the function\n    ``func``. In this case, the function apply\n    ``flat_dict[key] = func(flat_dict[key], flat_config)``.\n\n    Parameters\n    ----------\n    func : Callable\n        The function to apply to the value (and eventually the flat config)\n        to make the new value so that:\n        flat_dict[key] = func(flat_dict[key]) or func(flat_dict[key], flat_config)\n    processing_type : str, optional\n        One of \"premerge\", \"postmerge\", \"presave\", \"postload\" or \"endbuild\".\n        Timing to apply the value update. In all cases the tag is removed on pre-merge.\n        By default \"premerge\".\n    regex : Optional[str]\n        The regex to match the key.\n    tag_name : Optional[str]\n        The tag (without \"@\") to match the key. The tag is removed on pre-merge.\n    order : int, optional\n        The pre-merge order. By default 0.0.\n    persistent : bool, optional\n        If True, the processing will be applied on all keys that have already\n        matched the tag before. By nature, using regex make the processing\n        always persistent. By default, False.\n\n    Raises\n    ------\n    ValueError\n        If both tag and regex are provided or if none of them are provided.\n    ValueError\n        If the processing type is not one of \"premerge\", \"postmerge\", \"presave\",\n        \"postload\" or \"endbuild\".\n\n    Returns\n    -------\n    processing : Processing\n        The processing object with the pre-merge method.\n\n\n    Examples\n    --------\n    With the following config and 2 processings:\n\n    .. code_block: yaml\n\n        # config.yaml\n        neg_number1: 1\n        neg_number2: 1\n        neg_number3@add1: 1\n\n    ::\n\n        proc2 = create_processing_value(lambda val: -val, regex=\"neg_number.*\",\n            order=0.0)\n        proc1 = create_processing_value(lambda val: val + 1, tag_name=\"add1\",\n            order=1.0)\n\n    When config.yaml is merged with an other config, it will be considered\n    before merging as:\n\n    ::\n\n        {'number1': -1, 'number2': -1, 'number3': 0}\n\n    Using the config as a second argument of the function:\n\n    .. code_block: yaml\n\n        # config.yaml\n        param1: 1\n        param2@eval: \"config.param1 + 1\"\n\n    ::\n\n        proc = create_processing_value(\n            lambda val, config: eval(val, {'config': config}),\n            processing_type='postmerge', tag_name='eval', persistent=False\n        )\n\n    After config.yaml is merged with another config, param2 will be evaluated\n    as 2 (except if config.param1 has changed with a processing before).\n    \"\"\"\n    if tag_name is not None:\n        if regex is not None:\n            raise ValueError(\"You must provide a tag or a regex but not both.\")\n    else:\n        if regex is None:\n            raise ValueError(\n                \"You must provide a tag or a regex (to trigger the value update).\"\n            )\n    proc = _ProcessingValue(func, processing_type, regex=regex,\n                            tag_name=tag_name, order=order, persistent=persistent)\n    return proc", "\n\ndef create_processing_keep_property(\n    func: Callable,\n    regex: Optional[str] = None,\n    tag_name: Optional[str] = None,\n    premerge_order: float = 0.0,\n    postmerge_order: float = 0.0,\n    endbuild_order: float = 0.0,\n) -> Processing:\n    \"\"\"Create a processing object that keep a property from a value using tag or regex.\n\n    The pre-merge processing looks for keys that match the tag or the regex, apply\n    the function func on the value and store the result (= the \"property\"):\n    ``property = func(flat_dict[key])``.\n    The post-merge processing will check that the property is the same as the one\n    stored during pre-merge. If not, it will raise a ValueError.\n\n    It also possible to pass the flat config as a second argument of the function\n    ``func``. In this case, the function apply\n    ``property = func(flat_dict[key], flat_config)``.\n\n    Parameters\n    ----------\n    func : Callable\n        The function to apply to the value (and eventually the flat config)\n        to define the property to keep.\n        property = func(flat_dict[key]) or func(flat_dict[key], flat_config)\n    regex : Optional[str]\n        The regex to match the key.\n    tag_name : Optional[str]\n        The tag (without \"@\") to match the key. The values are modified when\n        triggering the pattern \".*@<tag_name>.*\" and the tag is removed from the key.\n    premerge_order : float, optional\n        The pre-merge order, by default 0.0\n    postmerge_order : float, optional\n        The post-merge order, by default 0.0\n    endbuild_order : float, optional\n        The end-build order, by default 0.0\n\n    Raises\n    ------\n    ValueError\n        If both tag and regex are provided or if none of them are provided.\n\n    Returns\n    -------\n    Processing\n        The processing object with the pre-merge and post-merge methods.\n\n    Examples\n    --------\n    A processing that enforce the types of all the parameters to be constant\n    (equal to the type of the first value encountered):\n\n    ::\n\n        create_processing_keep_property(type, regex=\".*\", premerge_order=15.0,\n                                        postmerge_order=15.0, endbuild_order=15.0)\n\n    A processing that protect parameters tagged with @protect from being changed:\n\n    ::\n\n        create_processing_keep_property(lambda x: x, tag_name=\"protect\",\n                                        premerge_order=15.0, postmerge_order=15.0)\n    \"\"\"\n    if tag_name is not None:\n        if regex is not None:\n            raise ValueError(\"You must provide a tag or a regex but not both.\")\n    else:\n        if regex is None:\n            raise ValueError(\n                \"You must provide a tag or a regex (to trigger the value update).\"\n            )\n    processing = _ProcessingKeepProperty(\n        func,\n        regex=regex,\n        tag_name=tag_name,\n        premerge_order=premerge_order,\n        postmerge_order=postmerge_order,\n        endbuild_order=endbuild_order,\n    )\n    return processing", ""]}
{"filename": "cliconfig/yaml_tags/_yaml_tags.py", "chunked_list": ["\"\"\"Module to convert yaml tags in yaml file to python dict with  cliconfig tags.\"\"\"\n\nfrom typing import Any, Dict, Optional, Tuple\n\nimport yaml\n\n\nclass TaggedNode:\n    \"\"\"Node class for tagged tree (with yaml tags).\"\"\"\n\n    def __init__(self, value: Any, tag: str, *, is_config: bool) -> None:\n        self.tag = tag\n        self.value = value\n        self.is_config = is_config", "\n\ndef tagged_constructor(\n    loader: yaml.SafeLoader, tag_suffix: str, node: yaml.Node\n) -> Any:\n    \"\"\"Build a tagged tree node from yaml node.\"\"\"\n    if isinstance(node, yaml.ScalarNode):\n        return TaggedNode(loader.construct_scalar(node), tag_suffix, is_config=False)\n    if isinstance(node, yaml.SequenceNode):\n        return TaggedNode(loader.construct_sequence(node), tag_suffix, is_config=False)\n    return TaggedNode(\n        loader.construct_mapping(node), tag_suffix, is_config=True  # type: ignore\n    )", "\n\ndef get_yaml_loader() -> Any:\n    \"\"\"Return a yaml loader to parse tags and build tagged tree.\"\"\"\n    loader = yaml.SafeLoader\n    loader.add_multi_constructor(\"\", tagged_constructor)  # type: ignore\n    return loader\n\n\ndef insert_tags(tagged_tree: Any) -> Tuple[Any, Optional[str]]:\n    \"\"\"Build dict with cliconfig tag from tagged tree (with yaml tags).\"\"\"\n    if isinstance(tagged_tree, TaggedNode) and tagged_tree.is_config:\n        tag = tagged_tree.tag\n        if tag:\n            tag = tag.replace(\"!\", \"\")\n        out_dict = build_tree_from_dict(tagged_tree.value)\n        return out_dict, tag\n    if isinstance(tagged_tree, dict):\n        out_dict = build_tree_from_dict(tagged_tree)\n        return out_dict, None\n    if isinstance(tagged_tree, TaggedNode):\n        tag = tagged_tree.tag\n        if tag:\n            tag = tag.replace(\"!\", \"\")\n        if isinstance(tagged_tree.value, str):\n            value = yaml.safe_load(tagged_tree.value)\n        else:\n            value = tagged_tree.value\n        return value, tag\n    return tagged_tree, None", "\ndef insert_tags(tagged_tree: Any) -> Tuple[Any, Optional[str]]:\n    \"\"\"Build dict with cliconfig tag from tagged tree (with yaml tags).\"\"\"\n    if isinstance(tagged_tree, TaggedNode) and tagged_tree.is_config:\n        tag = tagged_tree.tag\n        if tag:\n            tag = tag.replace(\"!\", \"\")\n        out_dict = build_tree_from_dict(tagged_tree.value)\n        return out_dict, tag\n    if isinstance(tagged_tree, dict):\n        out_dict = build_tree_from_dict(tagged_tree)\n        return out_dict, None\n    if isinstance(tagged_tree, TaggedNode):\n        tag = tagged_tree.tag\n        if tag:\n            tag = tag.replace(\"!\", \"\")\n        if isinstance(tagged_tree.value, str):\n            value = yaml.safe_load(tagged_tree.value)\n        else:\n            value = tagged_tree.value\n        return value, tag\n    return tagged_tree, None", "\n\ndef build_tree_from_dict(in_dict: Dict) -> Dict[str, Any]:\n    \"\"\"Build a dict with cliconfig tag from a dict of tagged trees.\"\"\"\n    out_dict: Dict[str, Any] = {}\n    for key, value in in_dict.items():\n        tree, tag = insert_tags(value)\n        if tag:\n            subtag = tag.replace(\"!\", \"\")\n            key = f\"{key}@{subtag}\"\n        out_dict[key] = tree\n    return out_dict", ""]}
