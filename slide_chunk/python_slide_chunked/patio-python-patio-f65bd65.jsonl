{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/test_registry.py", "chunked_list": ["import pickle\n\nimport pytest\n\nfrom patio import Registry\n\n\ndef test_registry_properties(subtests):\n    r: Registry = Registry(project=\"foo\", strict=False, auto_naming=False)\n    assert r.project == \"foo\"\n    assert not r.strict\n    assert not r.auto_naming\n\n    r = Registry(project=\"bar\", strict=True, auto_naming=True)\n    assert r.project == \"bar\"\n    assert r.strict\n    assert r.auto_naming", "\n\ndef test_registry_as_mapping(subtests):\n    r: Registry = Registry()\n\n    with subtests.test(\"contains\"):\n        r[\"foo\"] = lambda x: None\n        assert \"foo\" in r\n        assert len(r) == 1\n\n    with subtests.test(\"del\"):\n        del r[\"foo\"]\n        assert \"foo\" not in r\n        assert len(r) == 0\n\n    with subtests.test(\"add twice\"):\n        r[\"foo\"] = lambda x: None\n\n        with pytest.raises(RuntimeError):\n            r[\"foo\"] = lambda x: None\n\n        del r[\"foo\"]\n\n    with subtests.test(\"locked\"):\n        assert not r.is_locked\n        r.lock()\n        assert r.is_locked\n        # Should be ok\n        r.lock()\n\n        with pytest.raises(RuntimeError):\n            r[\"foo\"] = lambda x: None\n\n        with pytest.raises(RuntimeError):\n            del r[\"foo\"]", "\n\ndef test_registry_decorator(subtests):\n    r: Registry = Registry(auto_naming=True)\n\n    @r(\"foo\")\n    def foo():\n        pass\n\n    with subtests.test(\"contains\"):\n        assert \"foo\" in r\n    with subtests.test(\"iter\"):\n        assert list(r) == [\"foo\"]\n    with subtests.test(\"items\"):\n        assert dict(r.items()) == {\"foo\": foo}\n    with subtests.test(\"keys\"):\n        assert list(r.keys()) == [\"foo\"]\n    with subtests.test(\"values\"):\n        assert list(r.values()) == [foo]\n\n    with subtests.test(\"del\"):\n        del r[\"foo\"]\n        assert \"foo\" not in r", "\n\ndef test_auto_naming(subtests):\n    with subtests.test(\"enabled\"):\n        r: Registry = Registry(project=\"test\", auto_naming=True)\n\n        with pytest.raises(KeyError):\n            print(r[\"bar\"])\n\n        @r\n        def foo():\n            pass\n\n        auto_name = r.get_name(foo)\n        assert auto_name in r\n        assert auto_name == (\n            \"test.tests.test_registry.test_auto_naming.<locals>.foo\"\n        )\n\n        assert r.resolve(auto_name) == r.resolve(foo)\n\n    with subtests.test(\"disabled\"):\n        r = Registry(project=\"test\", auto_naming=False)\n\n        with pytest.raises(ValueError):\n            @r\n            def foo():\n                pass\n\n        @r(\"spam\")\n        def spam():\n            pass\n\n        assert r.resolve(\"spam\") == spam\n        with pytest.raises(ValueError):\n            assert r.resolve(spam) is not None\n\n    with subtests.test(\"strict\"):\n        r = Registry(project=\"test\", auto_naming=True, strict=True)\n\n        @r\n        def bar():\n            pass\n\n        def baz():\n            pass\n\n        auto_name = r.get_name(bar)\n        assert auto_name in r\n        assert auto_name == (\n            \"test.tests.test_registry.test_auto_naming.<locals>.bar.\"\n            \"R+2IfaUD/3mHEJQ+XeqUstkXG1ZBRtFA74WWe05ex+w\"\n        )\n        assert r.resolve(auto_name) == r.resolve(bar)\n\n        with pytest.raises(KeyError):\n            r.get_name(baz)\n\n        r(baz)\n\n        assert r.get_name(baz) == (\n            \"test.tests.test_registry.test_auto_naming.<locals>.baz.\"\n            \"mYEWlo2vwOi3I/Z2rb5wayVONVncmvJ83EX07QsVOq8\"\n        )", "\n\ndef pickling_foo():\n    return\n\n\ndef pickling_bar():\n    return 1\n\n\ndef test_pickling():\n    r1: Registry = Registry()\n    r1(pickling_foo)\n    r1(pickling_bar)\n    r1[\"spam\"] = pickling_bar\n\n    dumped = pickle.dumps(r1)\n\n    r2: Registry = pickle.loads(dumped)\n\n    assert len(r2)\n    assert list(r1) == list(r2)\n    assert list(sorted(r1.items())) == list(sorted(r2.items()))", "\n\ndef test_pickling():\n    r1: Registry = Registry()\n    r1(pickling_foo)\n    r1(pickling_bar)\n    r1[\"spam\"] = pickling_bar\n\n    dumped = pickle.dumps(r1)\n\n    r2: Registry = pickle.loads(dumped)\n\n    assert len(r2)\n    assert list(r1) == list(r2)\n    assert list(sorted(r1.items())) == list(sorted(r2.items()))", ""]}
{"filename": "tests/test_memory_broker.py", "chunked_list": ["from functools import reduce\nfrom operator import mul\nfrom typing import Any, AsyncGenerator\n\nimport pytest\n\nfrom patio import Registry\nfrom patio.broker import MemoryBroker\nfrom patio.executor import ThreadPoolExecutor\n", "from patio.executor import ThreadPoolExecutor\n\n\n@pytest.fixture\ndef registry():\n    r: Registry = Registry()\n\n    @r(\"mul\")\n    def multiply(*args: int) -> int:\n        return reduce(mul, args)\n\n    return r", "\n\n@pytest.fixture\nasync def broker(\n    thread_executor: ThreadPoolExecutor,\n) -> AsyncGenerator[Any, MemoryBroker]:\n    async with MemoryBroker(thread_executor) as broker:\n        yield broker\n\n", "\n\nasync def test_mul(broker: MemoryBroker):\n    assert await broker.call(\"mul\", 1, 2, 3) == 6\n"]}
{"filename": "tests/test_executor.py", "chunked_list": ["import asyncio\nfrom functools import reduce\nfrom operator import mul\nfrom typing import Any, AsyncGenerator\n\nimport pytest\n\nfrom patio import Registry\nfrom patio.executor import (\n    AbstractExecutor, AsyncExecutor, NullExecutor, ProcessPoolExecutor,", "from patio.executor import (\n    AbstractExecutor, AsyncExecutor, NullExecutor, ProcessPoolExecutor,\n    ThreadPoolExecutor,\n)\n\n\nclass AsyncExecutorBaseCase:\n    @staticmethod\n    def multiply(*args: int) -> Any:\n        raise NotImplementedError\n\n    @pytest.fixture\n    def registry(self) -> Registry:\n        rpc: Registry = Registry()\n        rpc[\"mul\"] = self.multiply\n        return rpc\n\n    async def test_multiply(self, executor: AbstractExecutor):\n        assert await executor.submit(self.multiply, 1, 2, 3) == 6\n\n    async def test_multiply_gather(self, executor: AbstractExecutor):\n        tasks = []\n\n        for _ in range(100):\n            tasks.append(executor.submit(self.multiply, 1, 2, 3))\n\n        assert await asyncio.gather(*tasks) == [6] * 100", "\n\nclass TestAsyncExecutor(AsyncExecutorBaseCase):\n    @pytest.fixture\n    async def executor(\n        self, registry: Registry,\n    ) -> AsyncGenerator[Any, AbstractExecutor]:\n        async with AsyncExecutor(registry) as executor:\n            yield executor\n\n    @staticmethod\n    async def multiply(*args: int) -> int:\n        return reduce(mul, args)", "\n\nclass TestThreadPoolExecutor(AsyncExecutorBaseCase):\n    @pytest.fixture\n    async def executor(\n        self, registry: Registry,\n    ) -> AsyncGenerator[Any, AbstractExecutor]:\n        async with ThreadPoolExecutor(registry) as executor:\n            yield executor\n\n    @staticmethod\n    def multiply(*args: int) -> int:\n        return reduce(mul, args)", "\n\nclass TestProcessPoolExecutor(AsyncExecutorBaseCase):\n    @pytest.fixture\n    async def executor(\n        self, registry: Registry,\n    ) -> AsyncGenerator[Any, AbstractExecutor]:\n        async with ProcessPoolExecutor(registry) as executor:\n            yield executor\n\n    @staticmethod\n    def multiply(*args: int) -> int:\n        return reduce(mul, args)", "\n\nclass TestNullExecutor:\n    @pytest.fixture\n    def registry(self) -> Registry:\n        rpc: Registry = Registry()\n        return rpc\n\n    @pytest.fixture\n    async def executor(\n        self, registry: Registry,\n    ) -> AsyncGenerator[Any, NullExecutor]:\n        async with NullExecutor(registry) as executor:\n            yield executor\n\n    async def test_simple(self, executor: AbstractExecutor):\n        with pytest.raises(RuntimeError):\n            await executor.submit(print)", ""]}
{"filename": "tests/conftest.py", "chunked_list": ["from typing import Any, AsyncGenerator\n\nimport pytest\n\nfrom patio import Registry\nfrom patio.executor import ThreadPoolExecutor\n\n\n@pytest.fixture\ndef registry():\n    return Registry()", "@pytest.fixture\ndef registry():\n    return Registry()\n\n\n@pytest.fixture()\nasync def thread_executor(\n    registry: Registry,\n) -> AsyncGenerator[Any, ThreadPoolExecutor]:\n    async with ThreadPoolExecutor(registry) as executor:", ") -> AsyncGenerator[Any, ThreadPoolExecutor]:\n    async with ThreadPoolExecutor(registry) as executor:\n        yield executor\n"]}
{"filename": "tests/tcp_broker/test_tcp_broker.py", "chunked_list": ["import asyncio\nimport time\nfrom functools import reduce\nfrom operator import mul, truediv\n\nimport pytest\n\nfrom patio import Registry, TCPClientBroker, TCPServerBroker\nfrom patio.broker import TimeoutType\nfrom patio.broker.tcp.protocol import Protocol", "from patio.broker import TimeoutType\nfrom patio.broker.tcp.protocol import Protocol\n\n\n@pytest.fixture\ndef registry():\n    rpc: Registry = Registry()\n\n    @rpc(\"mul\")\n    def multiply(*args: int) -> int:\n        return reduce(mul, args)\n\n    @rpc(\"div\")\n    def division(*args: int) -> int:\n        return reduce(truediv, args)\n\n    @rpc(\"sleep\")\n    def sleep(delay: TimeoutType) -> None:\n        time.sleep(delay)\n\n    return rpc", "\n\nasync def test_mul(\n    server_broker: TCPServerBroker,\n    client_broker: TCPClientBroker,\n    subtests,\n):\n    with subtests.test(\"call from server\"):\n        assert await server_broker.call(\"mul\", 1, 2, 3) == 6\n    with subtests.test(\"call from client\"):\n        assert await client_broker.call(\"mul\", 1, 2, 3) == 6", "    with subtests.test(\"call from client\"):\n        assert await client_broker.call(\"mul\", 1, 2, 3) == 6\n\n    with subtests.test(\"max serial reached\"):\n        client_broker.protocol.serial = Protocol.MAX_SERIAL - 1\n        assert await client_broker.call(\"mul\", 2, 2) == 4\n        assert client_broker.protocol.serial == 1\n\n    with subtests.test(\"error\"):\n        with pytest.raises(ZeroDivisionError):\n            assert await server_broker.call(\"div\", 2, 0)", "    with subtests.test(\"error\"):\n        with pytest.raises(ZeroDivisionError):\n            assert await server_broker.call(\"div\", 2, 0)\n\n\nasync def test_timeout(\n    server_broker: TCPServerBroker,\n    client_broker: TCPClientBroker,\n    subtests,\n):\n    with pytest.raises(asyncio.TimeoutError):\n        await server_broker.call(\"sleep\", 0.5, timeout=0.1)", "    subtests,\n):\n    with pytest.raises(asyncio.TimeoutError):\n        await server_broker.call(\"sleep\", 0.5, timeout=0.1)\n    # waiting for response\n    await asyncio.sleep(1)\n\n\nasync def test_no_route(\n    server_broker: TCPServerBroker,", "async def test_no_route(\n    server_broker: TCPServerBroker,\n    client_broker: TCPClientBroker,\n    subtests,\n):\n    with pytest.raises(asyncio.TimeoutError):\n        await server_broker.call(\"not-found\", timeout=0.5)\n"]}
{"filename": "tests/tcp_broker/__init__.py", "chunked_list": [""]}
{"filename": "tests/tcp_broker/test_restricted.py", "chunked_list": ["import os\nimport pickle\n\nimport pytest\n\nfrom patio import Registry, TCPClientBroker, TCPServerBroker\nfrom patio.broker.serializer import (\n    AbstractSerializer, RestrictedPickleSerializer,\n)\n", ")\n\n\n@pytest.fixture(params=[RestrictedPickleSerializer()], ids=[\"restricted\"])\ndef serializer(request) -> AbstractSerializer:\n    return request.param\n\n\n@pytest.fixture\ndef registry():\n    rpc: Registry = Registry()\n\n    @rpc(\"call_any\")\n    def call_any(func, *args):\n        return func(*args)\n\n    return rpc", "@pytest.fixture\ndef registry():\n    rpc: Registry = Registry()\n\n    @rpc(\"call_any\")\n    def call_any(func, *args):\n        return func(*args)\n\n    return rpc\n", "\n\nasync def test_restricted(\n    server_broker: TCPServerBroker,\n    client_broker: TCPClientBroker,\n    subtests,\n):\n    with pytest.raises(pickle.UnpicklingError):\n        assert await client_broker.call(\n            \"call_any\", os.execv, \"ls\", [\"ls\", \"-1\"],\n        )", ""]}
{"filename": "tests/tcp_broker/conftest.py", "chunked_list": ["import ssl\nfrom pathlib import Path\nfrom typing import Any, AsyncGenerator, Optional, Tuple\n\nimport pytest\n\nfrom patio import TCPClientBroker, TCPServerBroker\nfrom patio.broker.serializer import (\n    AbstractSerializer, PickleSerializer, RestrictedPickleSerializer,\n)", "    AbstractSerializer, PickleSerializer, RestrictedPickleSerializer,\n)\nfrom patio.executor import ThreadPoolExecutor\n\n\nSSL_PATH = Path(__file__).parent / \"ssl\"\nSSL_CA_FILE = SSL_PATH / \"CA.pem\"\nSSL_SERVER_CERT_FILE = SSL_PATH / \"server.pem\"\nSSL_CLIENT_CERT_FILE = SSL_PATH / \"client.pem\"\nSSL_SERVER_KEY_FILE = SSL_PATH / \"server.key\"", "SSL_CLIENT_CERT_FILE = SSL_PATH / \"client.pem\"\nSSL_SERVER_KEY_FILE = SSL_PATH / \"server.key\"\nSSL_CLIENT_KEY_FILE = SSL_PATH / \"client.key\"\n\n\ndef ssl_server_context(\n    mode=ssl.VerifyMode.CERT_OPTIONAL,\n) -> ssl.SSLContext:\n    ctx = ssl.SSLContext()\n    ctx.verify_mode = mode\n    ctx.load_verify_locations(SSL_CA_FILE)\n    ctx.load_cert_chain(SSL_SERVER_CERT_FILE, SSL_SERVER_KEY_FILE)\n    return ctx", "\n\ndef ssl_client_context() -> ssl.SSLContext:\n    ctx = ssl.SSLContext()\n    ctx.load_cert_chain(SSL_CLIENT_CERT_FILE, SSL_CLIENT_KEY_FILE)\n    return ctx\n\n\n@pytest.fixture()\ndef server_port(aiomisc_unused_port_factory) -> int:\n    return aiomisc_unused_port_factory()", "@pytest.fixture()\ndef server_port(aiomisc_unused_port_factory) -> int:\n    return aiomisc_unused_port_factory()\n\n\n@pytest.fixture(\n    params=[\n        [\n            ssl_server_context(ssl.VerifyMode.CERT_OPTIONAL),\n            ssl.create_default_context(cafile=SSL_CA_FILE),", "            ssl_server_context(ssl.VerifyMode.CERT_OPTIONAL),\n            ssl.create_default_context(cafile=SSL_CA_FILE),\n        ],\n        [\n            ssl_server_context(ssl.VerifyMode.CERT_REQUIRED),\n            ssl_client_context(),\n        ],\n        [None, None],\n    ],\n    ids=[\"ssl\", \"ssl-client\", \"no-ssl\"],", "    ],\n    ids=[\"ssl\", \"ssl-client\", \"no-ssl\"],\n)\ndef ssl_context_pair(request) -> Tuple[\n    Optional[ssl.SSLContext],\n    Optional[ssl.SSLContext],\n]:\n    return request.param\n\n", "\n\n@pytest.fixture(\n    params=[\n        PickleSerializer(),\n        RestrictedPickleSerializer(),\n    ],\n    ids=[\"pickle\", \"restricted-pickle\"],\n)\ndef serializer(request) -> AbstractSerializer:\n    return request.param", ")\ndef serializer(request) -> AbstractSerializer:\n    return request.param\n\n\n@pytest.fixture()\nasync def server_broker(\n    server_port: int, thread_executor: ThreadPoolExecutor,\n    localhost: str, ssl_context_pair, serializer: AbstractSerializer,\n) -> AsyncGenerator[Any, TCPServerBroker]:", "    localhost: str, ssl_context_pair, serializer: AbstractSerializer,\n) -> AsyncGenerator[Any, TCPServerBroker]:\n    ctx, _ = ssl_context_pair\n    async with TCPServerBroker(\n        thread_executor, ssl_context=ctx, serializer=serializer,\n    ) as broker:\n        await broker.listen(localhost, server_port)\n        yield broker\n\n", "\n\n@pytest.fixture()\nasync def client_broker(\n    server_port: int, thread_executor: ThreadPoolExecutor,\n    server_broker: TCPServerBroker, localhost: str, ssl_context_pair,\n    serializer: AbstractSerializer,\n) -> AsyncGenerator[Any, TCPClientBroker]:\n    _, ctx = ssl_context_pair\n    async with TCPClientBroker(", "    _, ctx = ssl_context_pair\n    async with TCPClientBroker(\n        thread_executor, ssl_context=ctx, serializer=serializer,\n    ) as broker:\n        await broker.connect(localhost, server_port)\n        yield broker\n"]}
{"filename": "patio/registry.py", "chunked_list": ["import hashlib\nimport inspect\nfrom base64 import b64encode\nfrom collections import defaultdict\nfrom types import MappingProxyType\nfrom typing import (\n    Any, Awaitable, Callable, DefaultDict, Dict, Generic, ItemsView, Iterator,\n    KeysView, MutableMapping, Optional, Set, Tuple, TypeVar, Union, ValuesView,\n    overload,\n)", "    overload,\n)\n\nfrom patio.compat import Self\n\n\nT = TypeVar(\"T\")\n\nAsyncTaskFunctionType = Callable[..., Awaitable[T]]\nSyncTaskFunctionType = Callable[..., T]", "AsyncTaskFunctionType = Callable[..., Awaitable[T]]\nSyncTaskFunctionType = Callable[..., T]\nTaskFunctionType = Union[AsyncTaskFunctionType, SyncTaskFunctionType]\n\n\nStoreType = Union[Dict[str, TaskFunctionType], MappingProxyType]\nReverseStoreType = Union[\n    DefaultDict[TaskFunctionType, Set[str]],\n    MappingProxyType,\n]", "    MappingProxyType,\n]\n\n\nclass Registry(MutableMapping, Generic[T]):\n    \"\"\"\n    This is a container of functions for their subsequent execution.\n    You can register a function by specific name or without it,\n    in which case the function is assigned a unique name that depends on\n    the source code of the function.\n\n    This registry does not necessarily have to match on the calling and called\n    sides, but for functions that you register without a name it is must be,\n    and then you should not need to pass the function name but the function\n    itself when you will call it.\n\n    An instance of the registry must be transferred to the broker,\n    the first broker in the process of setting up will block the registry\n    to write, that is, registering new functions will be impossible.\n\n    An optional ``project`` parameter, this is essentially like a namespace\n    that will help avoid clash functions in different projects with the same\n    name. It is recommended to specify it and the broker should also use this\n    parameter, so it should be the same value within the same project.\n\n    You can either manually register elements or use a\n    registry instance as a decorator:\n\n    .. code-block:: python\n\n        from patio import Registry\n\n        rpc = Registry(project=\"example\")\n\n        # Will be registered with auto generated name\n        @rpc\n        def mul(a, b):\n            return a * b\n\n        @rpc('div')\n        def div(a, b):\n            return a / b\n\n        def pow(a, b):\n            return a ** b\n\n        def sub(a, b):\n            return a - b\n\n        # Register with auto generated name\n        rpc.register(pow)\n\n        rpc.register(sub, \"sub\")\n\n    Alternatively using ``register`` method:\n\n    .. code-block:: python\n\n        from patio import Registry\n\n        rpc = Registry(project=\"example\")\n\n        def pow(a, b):\n            return a ** b\n\n        def sub(a, b):\n            return a - b\n\n        # Register with auto generated name\n        rpc.register(pow)\n\n        rpc.register(sub, \"sub\")\n\n    Finally, you can register functions explicitly, as if it were\n    just a dictionary:\n\n    .. code-block:: python\n\n        from patio import Registry\n\n        rpc = Registry(project=\"example\")\n\n        def mul(a, b):\n            return a * b\n\n        rpc['mul'] = mul\n\n    \"\"\"\n\n    __slots__ = (\n        \"__project\", \"__strict\", \"__store\", \"__reverse_store\", \"__locked\",\n        \"__auto_naming\",\n    )\n\n    def __init__(\n        self, project: Optional[str] = None, strict: bool = False,\n        auto_naming: bool = True,\n    ):\n        self.__auto_naming: bool = auto_naming\n        self.__project = project\n        self.__strict = strict\n        self.__store: StoreType = {}\n        self.__reverse_store: ReverseStoreType = defaultdict(set)\n        self.__locked = False\n\n    @property\n    def is_locked(self) -> bool:\n        return self.__locked\n\n    @property\n    def project(self) -> Optional[str]:\n        return self.__project\n\n    @property\n    def strict(self) -> bool:\n        return self.__strict\n\n    @property\n    def auto_naming(self) -> bool:\n        return self.__auto_naming\n\n    def _make_function_name(self, func: TaskFunctionType) -> str:\n        parts = []\n\n        if self.project is not None:\n            parts.append(self.project)\n\n        if hasattr(func, \"__module__\"):\n            parts.append(func.__module__)\n\n        if hasattr(func, \"__qualname__\"):\n            parts.append(func.__qualname__)\n\n        if self.strict:\n            sources = inspect.getsource(func)\n            parts.append(\n                b64encode(\n                    hashlib.blake2s(sources.encode()).digest(),\n                ).strip(b\"=\").decode(),\n            )\n\n        return \".\".join(parts)\n\n    def lock(self) -> None:\n        if self.is_locked:\n            return\n        self.__store = MappingProxyType(self.__store)\n        self.__reverse_store = MappingProxyType({\n            k: frozenset(v) for k, v in self.__reverse_store.items()\n        })\n        self.__locked = True\n\n    def register(\n        self, func: TaskFunctionType, name: Optional[str] = None,\n    ) -> str:\n        if name is None:\n            if not self.__auto_naming:\n                raise ValueError(\n                    \"auto_naming is disabled, \"\n                    \"name parameter is required\",\n                )\n            name = self._make_function_name(func)\n        self[name] = func\n        return name\n\n    @overload\n    def __call__(self, name: TaskFunctionType) -> TaskFunctionType:\n        ...\n\n    @overload\n    def __call__(\n        self, name: Optional[str] = None,\n    ) -> Callable[..., TaskFunctionType]:\n        ...\n\n    def __call__(\n        self, name: Union[Optional[str], TaskFunctionType] = None,\n    ) -> Union[Callable[..., TaskFunctionType], TaskFunctionType]:\n        if callable(name):\n            return self.__call__(None)(name)\n\n        function_name: Optional[str] = name\n\n        def decorator(func: TaskFunctionType) -> TaskFunctionType:\n            self.register(func, function_name)\n            return func\n        return decorator\n\n    def __setitem__(self, name: str, func: TaskFunctionType) -> None:\n        if name in self.__store:\n            raise RuntimeError(\n                f\"Task with name {name!r} already \"\n                f\"registered for {self.__store[name]!r}\",\n            )\n\n        if (\n            isinstance(self.__store, MappingProxyType) or\n            isinstance(self.__reverse_store, MappingProxyType)\n        ):\n            raise RuntimeError(\"Registry locked\")\n\n        self.__store[name] = func\n        self.__reverse_store[func].add(name)\n\n    def __delitem__(self, name: str) -> None:\n        if (\n            isinstance(self.__store, MappingProxyType) or\n            isinstance(self.__reverse_store, MappingProxyType)\n        ):\n            raise RuntimeError(\"Registry locked\")\n\n        func = self.__store.pop(name)\n        del self.__reverse_store[func]\n\n    def __getitem__(self, name: str) -> TaskFunctionType:\n        return self.__store[name]\n\n    def __len__(self) -> int:\n        return len(self.__store)\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self.__store)\n\n    def items(self) -> ItemsView[str, TaskFunctionType]:\n        return self.__store.items()\n\n    def keys(self) -> KeysView[str]:\n        return self.__store.keys()\n\n    def values(self) -> ValuesView[TaskFunctionType]:\n        return self.__store.values()\n\n    def get_names(self, func: TaskFunctionType) -> Tuple[str, ...]:\n        return tuple(self.__reverse_store[func])\n\n    def get_name(self, func: TaskFunctionType) -> str:\n        candidates = self.get_names(func)\n        if not candidates:\n            raise KeyError(f\"{func!r} has not been registered\")\n        return candidates[0]\n\n    @overload\n    def resolve(self, func: str) -> Callable[..., T]:\n        ...\n\n    @overload\n    def resolve(self, func: Callable[..., T]) -> Callable[..., T]:\n        ...\n\n    def resolve(\n        self, func: Union[str, Callable[..., T]],\n    ) -> Callable[..., Any]:\n        if not isinstance(func, str):\n            if not self.__auto_naming:\n                raise ValueError(\n                    \"auto_naming is disabled, \"\n                    \"name parameter is required\",\n                )\n            func = self.get_name(func)\n        return self[func]\n\n    def __getstate__(self) -> Dict[str, Any]:\n        return dict(\n            auto_naming=self.__auto_naming,\n            project=self.__project,\n            strict=self.__strict,\n            store=self.__store,\n            locked=self.__locked,\n        )\n\n    def __setstate__(self, state: Dict[str, Any]) -> None:\n        self.__auto_naming = state[\"auto_naming\"]\n        self.__project = state[\"project\"]\n        self.__strict = state[\"strict\"]\n        self.__locked = state[\"locked\"]\n        self.__store = {}\n        self.__reverse_store = defaultdict(set)\n\n        for name, func in state[\"store\"].items():\n            self[name] = func\n\n    def __copy__(self) -> Self:\n        clone = self.__class__()\n        clone.__setstate__(self.__getstate__())\n        return clone", "\n\n__all__ = (\n    \"AsyncTaskFunctionType\",\n    \"Registry\",\n    \"SyncTaskFunctionType\",\n    \"T\",\n    \"TaskFunctionType\",\n)\n", ")\n"]}
{"filename": "patio/compat.py", "chunked_list": ["import asyncio\nimport sys\nfrom typing import Generic, TypeVar\n\n\ntry:\n    from typing import Self  # type: ignore\nexcept ImportError:\n    from typing_extensions import Self\n", "\n\nT = TypeVar(\"T\")\n\n\nif sys.version_info >= (3, 9):\n    from asyncio import Queue\nelse:\n    class Queue(asyncio.Queue, Generic[T]):\n        async def get(self) -> T:\n            return await super().get()\n\n        async def put(self, element: T) -> T:\n            return await super().put(element)\n\n        def get_nowait(self) -> T:\n            return super().get_nowait()\n\n        def put_nowait(self, element: T) -> None:\n            return super().put_nowait(element)", "\n\n__all__ = (\"Queue\", \"Self\")\n"]}
{"filename": "patio/__init__.py", "chunked_list": ["from patio.broker import (\n    AbstractBroker, MemoryBroker, TCPBrokerBase, TCPClientBroker,\n    TCPServerBroker,\n)\nfrom patio.executor import (\n    AbstractExecutor, AsyncExecutor, NullExecutor, ProcessPoolExecutor,\n    ThreadPoolExecutor,\n)\nfrom patio.registry import Registry, TaskFunctionType\n", "from patio.registry import Registry, TaskFunctionType\n\n\n__all__ = (\n    \"AbstractBroker\",\n    \"AbstractExecutor\",\n    \"AsyncExecutor\",\n    \"MemoryBroker\",\n    \"NullExecutor\",\n    \"ProcessPoolExecutor\",", "    \"NullExecutor\",\n    \"ProcessPoolExecutor\",\n    \"Registry\",\n    \"TCPBrokerBase\",\n    \"TCPClientBroker\",\n    \"TCPServerBroker\",\n    \"TaskFunctionType\",\n    \"ThreadPoolExecutor\",\n)\n", ")\n"]}
{"filename": "patio/executor/base.py", "chunked_list": ["from __future__ import annotations\n\nfrom abc import abstractmethod\nfrom typing import Any, AsyncContextManager, Awaitable, Generic, Union\n\nfrom patio.registry import Registry, T, TaskFunctionType\n\n\nclass AbstractExecutor(Generic[T], AsyncContextManager):\n    \"\"\"\n    An Executor is an entity that executes local functions on the local side.\n    The following executors are implemented in the package:\n\n    * :class:`AsyncExecutor`\n    * :class:`ThreadPoolExecutor`\n    * :class:`ProcessPoolExecutor`\n    * :class:`NullExecutor`\n\n    Its role is to reliably execute jobs without taking too much so as not to\n    cause a denial of service, or excessive memory consumption.\n\n    The executor instance is passing to the broker, it's usually applies\n    it to the whole registry. Therefore, you should understand what functions\n    the registry must contain to choose kind of an executor.\n    \"\"\"\n\n    DEFAULT_MAX_WORKERS: int = 4\n\n    def __init__(\n        self, registry: Registry, max_workers: int = DEFAULT_MAX_WORKERS,\n    ):\n        self.registry = registry\n        self.max_workers = max_workers\n\n    @abstractmethod\n    async def setup(self) -> None:\n        \"\"\"\n        Configures the executor, can be called several times, with the\n        assumption that it will be configured exactly once.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Not implemented method setup \"\n            f\"in {self.__class__.__name__!r} \",\n        )\n\n    @abstractmethod\n    def submit(\n        self, func: TaskFunctionType, *args: Any, **kwargs: Any\n    ) -> Awaitable[T]:\n        \"\"\"\n        Passes the function to execute, and waits for the result, returns it.\n\n        :param func: Function to be executed\n        :param args: positional arguments of the Function\n        :param kwargs: keyword arguments of the function\n        :return: the result that the function will return\n        \"\"\"\n        raise NotImplementedError(\n            f\"Not implemented method submit in {self.__class__.__name__!r} \"\n            f\"Call {func!r} with args={args!r}, kwargs={kwargs!r} skipped\",\n        )\n\n    @abstractmethod\n    async def shutdown(self) -> None:\n        \"\"\"\n        Performs an executor stop. All related and unperformed tasks\n        must be completed.\n        \"\"\"\n\n    async def __aenter__(self) -> AbstractExecutor:\n        await self.setup()\n        return self\n\n    async def __aexit__(self, *args: Any) -> None:\n        await self.shutdown()\n\n    async def execute(\n        self, func: Union[str, TaskFunctionType], *args: Any, **kwargs: Any\n    ) -> T:\n        func = self.registry.resolve(func)\n        return await self.submit(func, *args, ** kwargs)", "class AbstractExecutor(Generic[T], AsyncContextManager):\n    \"\"\"\n    An Executor is an entity that executes local functions on the local side.\n    The following executors are implemented in the package:\n\n    * :class:`AsyncExecutor`\n    * :class:`ThreadPoolExecutor`\n    * :class:`ProcessPoolExecutor`\n    * :class:`NullExecutor`\n\n    Its role is to reliably execute jobs without taking too much so as not to\n    cause a denial of service, or excessive memory consumption.\n\n    The executor instance is passing to the broker, it's usually applies\n    it to the whole registry. Therefore, you should understand what functions\n    the registry must contain to choose kind of an executor.\n    \"\"\"\n\n    DEFAULT_MAX_WORKERS: int = 4\n\n    def __init__(\n        self, registry: Registry, max_workers: int = DEFAULT_MAX_WORKERS,\n    ):\n        self.registry = registry\n        self.max_workers = max_workers\n\n    @abstractmethod\n    async def setup(self) -> None:\n        \"\"\"\n        Configures the executor, can be called several times, with the\n        assumption that it will be configured exactly once.\n        \"\"\"\n        raise NotImplementedError(\n            f\"Not implemented method setup \"\n            f\"in {self.__class__.__name__!r} \",\n        )\n\n    @abstractmethod\n    def submit(\n        self, func: TaskFunctionType, *args: Any, **kwargs: Any\n    ) -> Awaitable[T]:\n        \"\"\"\n        Passes the function to execute, and waits for the result, returns it.\n\n        :param func: Function to be executed\n        :param args: positional arguments of the Function\n        :param kwargs: keyword arguments of the function\n        :return: the result that the function will return\n        \"\"\"\n        raise NotImplementedError(\n            f\"Not implemented method submit in {self.__class__.__name__!r} \"\n            f\"Call {func!r} with args={args!r}, kwargs={kwargs!r} skipped\",\n        )\n\n    @abstractmethod\n    async def shutdown(self) -> None:\n        \"\"\"\n        Performs an executor stop. All related and unperformed tasks\n        must be completed.\n        \"\"\"\n\n    async def __aenter__(self) -> AbstractExecutor:\n        await self.setup()\n        return self\n\n    async def __aexit__(self, *args: Any) -> None:\n        await self.shutdown()\n\n    async def execute(\n        self, func: Union[str, TaskFunctionType], *args: Any, **kwargs: Any\n    ) -> T:\n        func = self.registry.resolve(func)\n        return await self.submit(func, *args, ** kwargs)", ""]}
{"filename": "patio/executor/thread_pool.py", "chunked_list": ["import asyncio\nimport concurrent.futures\nfrom functools import cached_property, partial\nfrom typing import Any, Awaitable\n\nfrom patio.executor.base import AbstractExecutor\nfrom patio.registry import SyncTaskFunctionType, T\n\n\nclass ThreadPoolExecutor(AbstractExecutor[T]):\n    \"\"\"\n    Execute jobs in a thread pool. Jobs cannot be asynchronous functions.\n    This means that the whole registry must not contain functions other than\n    specified kind.\n    \"\"\"\n    __slots__ = \"max_workers\", \"executor\"\n\n    DEFAULT_MAX_WORKERS: int = 4\n\n    executor: concurrent.futures.ThreadPoolExecutor\n\n    @cached_property\n    def loop(self) -> asyncio.AbstractEventLoop:\n        return asyncio.get_running_loop()\n\n    async def setup(self) -> None:\n        if hasattr(self, \"executor\"):\n            return\n\n        self.executor = await self.loop.run_in_executor(\n            None, concurrent.futures.ThreadPoolExecutor, self.max_workers,\n        )\n\n    def submit(\n        self, func: SyncTaskFunctionType, *args: Any, **kwargs: Any\n    ) -> Awaitable[T]:\n        return self.loop.run_in_executor(\n            self.executor, partial(func, *args, **kwargs),\n        )\n\n    async def shutdown(self) -> None:\n        await self.loop.run_in_executor(\n            None, partial(self.executor.shutdown, wait=True),\n        )", "\nclass ThreadPoolExecutor(AbstractExecutor[T]):\n    \"\"\"\n    Execute jobs in a thread pool. Jobs cannot be asynchronous functions.\n    This means that the whole registry must not contain functions other than\n    specified kind.\n    \"\"\"\n    __slots__ = \"max_workers\", \"executor\"\n\n    DEFAULT_MAX_WORKERS: int = 4\n\n    executor: concurrent.futures.ThreadPoolExecutor\n\n    @cached_property\n    def loop(self) -> asyncio.AbstractEventLoop:\n        return asyncio.get_running_loop()\n\n    async def setup(self) -> None:\n        if hasattr(self, \"executor\"):\n            return\n\n        self.executor = await self.loop.run_in_executor(\n            None, concurrent.futures.ThreadPoolExecutor, self.max_workers,\n        )\n\n    def submit(\n        self, func: SyncTaskFunctionType, *args: Any, **kwargs: Any\n    ) -> Awaitable[T]:\n        return self.loop.run_in_executor(\n            self.executor, partial(func, *args, **kwargs),\n        )\n\n    async def shutdown(self) -> None:\n        await self.loop.run_in_executor(\n            None, partial(self.executor.shutdown, wait=True),\n        )", ""]}
{"filename": "patio/executor/null.py", "chunked_list": ["import copy\nfrom typing import Any, Awaitable, Callable\n\nfrom patio.executor.base import AbstractExecutor\nfrom patio.registry import T\n\n\nclass NullExecutor(AbstractExecutor):\n    \"\"\"\n    Doesn't execute anything, serves as a stub to explicitly forbid calls\n    to this registry.\n    \"\"\"\n\n    async def setup(self) -> None:\n        self.registry = copy.copy(self.registry)\n        self.registry.clear()\n\n    def submit(\n        self, func: Callable[..., T], *args: Any, **kwargs: Any\n    ) -> Awaitable[T]:\n        raise RuntimeError(\"Null executor can't execute anything\")\n\n    async def shutdown(self) -> None:\n        pass", ""]}
{"filename": "patio/executor/__init__.py", "chunked_list": ["from .asyncronous import AsyncExecutor\nfrom .base import AbstractExecutor\nfrom .null import NullExecutor\nfrom .process_pool import ProcessPoolExecutor\nfrom .thread_pool import ThreadPoolExecutor\n\n\n__all__ = (\n    \"AbstractExecutor\",\n    \"AsyncExecutor\",", "    \"AbstractExecutor\",\n    \"AsyncExecutor\",\n    \"NullExecutor\",\n    \"ProcessPoolExecutor\",\n    \"ThreadPoolExecutor\",\n)\n"]}
{"filename": "patio/executor/process_pool.py", "chunked_list": ["import asyncio\nimport concurrent.futures\nfrom functools import cached_property, partial\nfrom typing import Any, Awaitable\n\nfrom patio.executor.base import AbstractExecutor\nfrom patio.registry import SyncTaskFunctionType, T\n\n\nclass ProcessPoolExecutor(AbstractExecutor[T]):\n    \"\"\"\n    Execute jobs in the process pool. Jobs cannot be asynchronous functions.\n    This means that the whole registry must not contain functions other than\n    specified kind.\n    \"\"\"\n    __slots__ = \"max_workers\", \"executor\"\n\n    DEFAULT_MAX_WORKERS: int = 4\n\n    executor: concurrent.futures.ProcessPoolExecutor\n\n    @cached_property\n    def loop(self) -> asyncio.AbstractEventLoop:\n        return asyncio.get_running_loop()\n\n    async def setup(self) -> None:\n        if hasattr(self, \"executor\"):\n            return\n\n        self.executor = await self.loop.run_in_executor(\n            None, concurrent.futures.ProcessPoolExecutor, self.max_workers,\n        )\n\n    def submit(\n        self, func: SyncTaskFunctionType, *args: Any, **kwargs: Any\n    ) -> Awaitable[T]:\n        return self.loop.run_in_executor(\n            self.executor, partial(func, *args, **kwargs),\n        )\n\n    async def shutdown(self) -> None:\n        await self.loop.run_in_executor(None, self.executor.shutdown, True)", "\nclass ProcessPoolExecutor(AbstractExecutor[T]):\n    \"\"\"\n    Execute jobs in the process pool. Jobs cannot be asynchronous functions.\n    This means that the whole registry must not contain functions other than\n    specified kind.\n    \"\"\"\n    __slots__ = \"max_workers\", \"executor\"\n\n    DEFAULT_MAX_WORKERS: int = 4\n\n    executor: concurrent.futures.ProcessPoolExecutor\n\n    @cached_property\n    def loop(self) -> asyncio.AbstractEventLoop:\n        return asyncio.get_running_loop()\n\n    async def setup(self) -> None:\n        if hasattr(self, \"executor\"):\n            return\n\n        self.executor = await self.loop.run_in_executor(\n            None, concurrent.futures.ProcessPoolExecutor, self.max_workers,\n        )\n\n    def submit(\n        self, func: SyncTaskFunctionType, *args: Any, **kwargs: Any\n    ) -> Awaitable[T]:\n        return self.loop.run_in_executor(\n            self.executor, partial(func, *args, **kwargs),\n        )\n\n    async def shutdown(self) -> None:\n        await self.loop.run_in_executor(None, self.executor.shutdown, True)", ""]}
{"filename": "patio/executor/asyncronous.py", "chunked_list": ["import asyncio\nfrom functools import cached_property\nfrom typing import Any, Callable, Set, Tuple\n\nfrom patio.compat import Queue\nfrom patio.executor.base import AbstractExecutor\nfrom patio.registry import AsyncTaskFunctionType, T\n\n\nQueueType = Queue[Tuple[Callable[..., T], Any, Any, asyncio.Future]]", "\nQueueType = Queue[Tuple[Callable[..., T], Any, Any, asyncio.Future]]\n\n\nclass AsyncExecutor(AbstractExecutor[T]):\n    \"\"\"\n    Executes the incoming tasks in the pool of the several concurrent tasks.\n    Tasks must be asynchronous functions, or functions that return an\n    awaitable object.\n    This means that the whole registry must not contain functions other than\n    specified kind.\n    \"\"\"\n    __slots__ = \"max_workers\", \"queue\", \"tasks\"\n\n    def __init__(self, *args: Any, **kwargs: Any):\n        super().__init__(*args, **kwargs)\n        self.queue: QueueType = Queue(maxsize=self.max_workers)\n        self.tasks: Set[asyncio.Task] = set()\n        self.started: bool = False\n\n    @cached_property\n    def loop(self) -> asyncio.AbstractEventLoop:\n        return asyncio.get_running_loop()\n\n    async def _executor(self) -> None:\n        while True:\n            func, args, kwargs, future = await self.queue.get()\n            if future.done():\n                continue\n            try:\n                future.set_result(await func(*args, **kwargs))\n            except Exception as e:\n                if future.done():\n                    continue\n                future.set_exception(e)\n\n    async def setup(self) -> None:\n        if self.started:\n            return\n\n        for _ in range(self.max_workers):\n            self.tasks.add(asyncio.create_task(self._executor()))\n        self.started = True\n\n    async def submit(\n        self, func: AsyncTaskFunctionType, *args: Any, **kwargs: Any\n    ) -> T:\n        future = self.loop.create_future()\n        await self.queue.put((func, args, kwargs, future))\n        return await future\n\n    async def shutdown(self) -> None:\n        cancelled = []\n        for task in self.tasks:\n            if task.done():\n                continue\n            task.cancel()\n            cancelled.append(task)\n\n        if cancelled:\n            await asyncio.gather(*cancelled, return_exceptions=True)", ""]}
{"filename": "patio/broker/abc.py", "chunked_list": ["import asyncio\nfrom abc import ABC, abstractmethod\nfrom functools import cached_property\nfrom typing import Any, Awaitable, Coroutine, List, Optional, Set, Union\n\nfrom patio.compat import Self\nfrom patio.executor import AbstractExecutor\nfrom patio.registry import TaskFunctionType\n\n", "\n\nTimeoutType = Union[int, float]\n\n\nclass AbstractBroker(ABC):\n    def __init__(self, executor: AbstractExecutor):\n        self.executor = executor\n        self.__tasks: Set[asyncio.Task] = set()\n\n    @cached_property\n    def loop(self) -> asyncio.AbstractEventLoop:\n        return asyncio.get_running_loop()\n\n    def create_task(self, coro: Coroutine[Any, Any, Any]) -> asyncio.Task:\n        task = self.loop.create_task(coro)\n        self.__tasks.add(task)\n        task.add_done_callback(self.__tasks.discard)\n        return task\n\n    async def setup(self) -> None:\n        await self.executor.setup()\n\n    async def close(self) -> None:\n        tasks: List[Awaitable[Any]] = [self.executor.shutdown()]\n        for task in tuple(self.__tasks):\n            if task.done():\n                continue\n            task.cancel()\n            tasks.append(task)\n        await asyncio.gather(*tasks, return_exceptions=True)\n\n    @abstractmethod\n    async def call(\n        self,\n        func: Union[str, TaskFunctionType],\n        *args: Any,\n        timeout: Optional[TimeoutType] = None,\n        **kwargs: Any,\n    ) -> Any:\n        ...\n\n    async def __aenter__(self) -> Self:\n        await self.setup()\n        return self\n\n    async def __aexit__(\n        self, exc_type: Any, exc_val: Any, exc_tb: Any,\n    ) -> None:\n        await self.close()\n\n    async def join(self) -> None:\n        async def waiter() -> None:\n            await self.loop.create_future()\n        await self.create_task(waiter())", "\n\n__all__ = \"AbstractBroker\", \"TimeoutType\", \"TaskFunctionType\"\n"]}
{"filename": "patio/broker/__init__.py", "chunked_list": ["from .abc import AbstractBroker, TimeoutType\nfrom .memory import MemoryBroker\nfrom .tcp.broker import TCPBrokerBase, TCPClientBroker, TCPServerBroker\n\n\n__all__ = (\n    \"AbstractBroker\",\n    \"MemoryBroker\",\n    \"TCPBrokerBase\",\n    \"TCPClientBroker\",", "    \"TCPBrokerBase\",\n    \"TCPClientBroker\",\n    \"TCPServerBroker\",\n    \"TimeoutType\",\n)\n"]}
{"filename": "patio/broker/serializer.py", "chunked_list": ["from __future__ import annotations\n\nimport builtins\nimport inspect\nimport pickle\nfrom abc import ABC, abstractmethod\nfrom io import BytesIO\nfrom typing import Any, Iterator\n\n\nclass AbstractSerializer(ABC):\n    @abstractmethod\n    def pack(self, payload: Any) -> bytes:\n        ...\n\n    @abstractmethod\n    def unpack(self, payload: bytes) -> Any:\n        ...", "\n\nclass AbstractSerializer(ABC):\n    @abstractmethod\n    def pack(self, payload: Any) -> bytes:\n        ...\n\n    @abstractmethod\n    def unpack(self, payload: bytes) -> Any:\n        ...", "\n\nclass PickleSerializer(AbstractSerializer):\n    def pack(self, payload: Any) -> bytes:\n        return pickle.dumps(payload, protocol=pickle.HIGHEST_PROTOCOL)\n\n    def unpack(self, payload: bytes) -> Any:\n        return pickle.loads(payload)\n\n\ndef _builtins_exceptions() -> Iterator[str]:\n    for item in dir(builtins):\n        obj = getattr(builtins, item)\n        if not inspect.isclass(obj):\n            continue\n        if issubclass(obj, BaseException):\n            yield f\"builtins.{obj.__name__}\"", "\n\ndef _builtins_exceptions() -> Iterator[str]:\n    for item in dir(builtins):\n        obj = getattr(builtins, item)\n        if not inspect.isclass(obj):\n            continue\n        if issubclass(obj, BaseException):\n            yield f\"builtins.{obj.__name__}\"\n", "\n\nclass RestrictedUnpickler(pickle.Unpickler):\n    SAFE_EXCLUDES = frozenset({\n        \"builtins.complex\",\n        \"builtins.set\",\n        \"builtins.frozenset\",\n        *_builtins_exceptions(),\n    })\n\n    UNSAFE_MODULES = frozenset(\n        {\"builtins\", \"os\", \"sys\", \"posix\", \"_winapi\"},\n    )\n\n    def find_class(self, module: str, name: str) -> Any:\n        if module not in self.UNSAFE_MODULES:\n            return super().find_class(module, name)\n\n        if f\"{module}.{name}\" in self.SAFE_EXCLUDES:\n            return super().find_class(module, name)\n\n        raise pickle.UnpicklingError(f\"The '{module}.{name}' is forbidden\")", "\n\nclass RestrictedPickleSerializer(PickleSerializer):\n    def unpack(self, payload: bytes) -> Any:\n        with BytesIO(payload) as fp:\n            return RestrictedUnpickler(fp).load()\n"]}
{"filename": "patio/broker/memory.py", "chunked_list": ["import asyncio\nfrom typing import Any, Optional, Union\n\nfrom patio.broker.abc import AbstractBroker, TimeoutType\nfrom patio.registry import TaskFunctionType\n\n\nclass MemoryBroker(AbstractBroker):\n    async def call(\n        self,\n        func: Union[str, TaskFunctionType],\n        *args: Any,\n        timeout: Optional[TimeoutType] = 86400,\n        **kwargs: Any,\n    ) -> Any:\n        return await asyncio.wait_for(\n            self.executor.execute(func, *args, **kwargs),\n            timeout=timeout,\n        )", "\n\n__all__ = \"MemoryBroker\",\n"]}
{"filename": "patio/broker/tcp/protocol.py", "chunked_list": ["from __future__ import annotations\n\nimport hashlib\nimport threading\nfrom dataclasses import dataclass\nfrom enum import IntEnum, unique\nfrom io import BytesIO\nfrom random import getrandbits\nfrom struct import Struct\nfrom typing import Any, Optional, Tuple", "from struct import Struct\nfrom typing import Any, Optional, Tuple\n\nfrom patio.broker.serializer import AbstractSerializer\n\n\n@unique\nclass PacketTypes(IntEnum):\n    AUTH_DIGEST = 0\n    AUTH_REQUEST = 1\n    AUTH_RESPONSE = 2\n    AUTH_OK = 3\n    DISCOVER_REQUEST = 5\n    DISCOVER_RESPONSE = 6\n    REQUEST = 10\n    RESPONSE = 20\n    ERROR = 30", "\n\n@dataclass\nclass Header:\n    STRUCT = Struct(\"!bII\")\n    SIZE = STRUCT.size\n\n    type: PacketTypes\n    size: int\n    serial: int\n\n    def pack(self) -> bytes:\n        return self.STRUCT.pack(self.type.value, self.size, self.serial)\n\n    @classmethod\n    def unpack(cls, data: bytes) -> Header:\n        kind, size, serial = cls.STRUCT.unpack(data)\n        return cls(type=PacketTypes(kind), size=size, serial=serial)", "\n\nclass Protocol:\n    HEADER_STRUCT = Struct(\"!bII\")\n    MAX_SERIAL = 4294967295\n\n    __slots__ = \"__key\", \"serial\", \"lock\", \"serializer\"\n\n    def __init__(self, *, serializer: AbstractSerializer, key: bytes = b\"\"):\n        self.__key = key\n        self.serial = 0\n        self.lock = threading.Lock()\n        self.serializer = serializer\n\n    def get_serial(self) -> int:\n        with self.lock:\n            self.serial += 1\n\n            if self.serial >= self.MAX_SERIAL:\n                self.serial = 1\n\n            return self.serial\n\n    def digest(\n        self, data: bytes, *, salt: Optional[bytes] = None\n    ) -> Tuple[bytes, bytes]:\n        if salt is None:\n            salt = getrandbits(32).to_bytes(4, \"big\")\n        return salt, hashlib.blake2s(data, key=self.__key, salt=salt).digest()\n\n    def pack(\n        self, payload: Any, packet_type: PacketTypes,\n        *, serial: Optional[int] = None\n    ) -> bytes:\n        with BytesIO() as fp:\n            fp.seek(Header.SIZE)\n            fp.write(self.serializer.pack(payload))\n\n            header = Header(\n                type=packet_type,\n                size=fp.tell() - self.HEADER_STRUCT.size,\n                serial=serial or self.get_serial(),\n            )\n\n            fp.seek(0)\n            fp.write(header.pack())\n\n            return fp.getvalue()\n\n    def authorize_request(self, token: bytes) -> bytes:\n        salt, digest = self.digest(token)\n        return self.pack((salt, digest, token), PacketTypes.AUTH_REQUEST)\n\n    def authorize_check(self, payload: bytes) -> bool:\n        salt, digest, token = self.serializer.unpack(payload)\n        return self.digest(token, salt=salt) == (salt, digest)\n\n    def pack_error(self, exception: Exception, serial: int) -> bytes:\n        return self.pack(exception, PacketTypes.ERROR, serial=serial)", "\n\n__all__ = (\"PacketTypes\", \"Header\", \"Protocol\")\n"]}
{"filename": "patio/broker/tcp/broker.py", "chunked_list": ["from __future__ import annotations\n\nimport asyncio\nimport logging\nimport pickle\nimport ssl\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom collections import defaultdict, deque\nfrom dataclasses import dataclass", "from collections import defaultdict, deque\nfrom dataclasses import dataclass\nfrom functools import cached_property\nfrom types import MappingProxyType\nfrom typing import (\n    Any, Callable, Coroutine, DefaultDict, Deque, Dict, Iterable, List, Mapping,\n    Optional, Set, Tuple, TypeVar, Union, final,\n)\n\nfrom patio.broker import AbstractBroker, TimeoutType", "\nfrom patio.broker import AbstractBroker, TimeoutType\nfrom patio.broker.serializer import (\n    AbstractSerializer, RestrictedPickleSerializer,\n)\nfrom patio.broker.tcp.protocol import Header, PacketTypes, Protocol\nfrom patio.compat import Queue\nfrom patio.executor import AbstractExecutor\nfrom patio.registry import Registry, TaskFunctionType\n", "from patio.registry import Registry, TaskFunctionType\n\n\nT = TypeVar(\"T\")\nlog = logging.getLogger(__name__)\n\n\n@dataclass(frozen=True)\nclass RPCEvent:\n    header: Header\n    payload: bytes", "class RPCEvent:\n    header: Header\n    payload: bytes\n\n\n@dataclass\nclass CallRequest:\n    func: str\n    args: Tuple[Any, ...]\n    kwargs: Dict[str, Any]\n    timeout: Optional[TimeoutType]", "\n\nclass PacketHandler(ABC):\n    reader: asyncio.StreamReader\n    writer: asyncio.StreamWriter\n    protocol: Protocol\n    executor: AbstractExecutor\n\n    def __init__(\n        self,\n        reader: asyncio.StreamReader,\n        writer: asyncio.StreamWriter,\n        executor: AbstractExecutor,\n        protocol: Protocol,\n    ):\n        self.reader = reader\n        self.writer = writer\n        self.protocol = protocol\n        self.executor = executor\n        self.__client_info = self.writer.get_extra_info(\"peername\")\n\n        self.__events: Queue[RPCEvent] = Queue(self.executor.max_workers)\n        self.__results: Dict[int, asyncio.Future] = {}\n\n        self.__method_map: Mapping[\n            PacketTypes, Callable[[RPCEvent], Coroutine[Any, Any, Any]],\n        ] = MappingProxyType({\n            PacketTypes.REQUEST: self.handle_request,\n            PacketTypes.RESPONSE: self.handle_response,\n            PacketTypes.ERROR: self.handle_error,\n            PacketTypes.DISCOVER_REQUEST: self.handle_discover_request,\n        })\n\n    @cached_property\n    def loop(self) -> asyncio.AbstractEventLoop:\n        return asyncio.get_running_loop()\n\n    async def get_event(self) -> RPCEvent:\n        header = Header.unpack(await self.reader.readexactly(Header.SIZE))\n        payload = await self.reader.readexactly(header.size)\n        return RPCEvent(header=header, payload=payload)\n\n    async def handle_request(self, event: RPCEvent) -> None:\n        try:\n            request: CallRequest = self.protocol.serializer.unpack(\n                event.payload,\n            )\n            result = await asyncio.wait_for(\n                self.executor.execute(\n                    request.func, *request.args, **request.kwargs\n                ),\n                timeout=request.timeout,\n            )\n            self.writer.write(\n                self.protocol.pack(\n                    result, PacketTypes.RESPONSE, serial=event.header.serial,\n                ),\n            )\n        except Exception as e:\n            self.writer.write(\n                self.protocol.pack(\n                    e, PacketTypes.ERROR, serial=event.header.serial,\n                ),\n            )\n\n    async def handle_response(self, event: RPCEvent) -> None:\n        future = self.__results.pop(event.header.serial)\n        if future.done():\n            return\n        try:\n            payload = self.protocol.serializer.unpack(event.payload)\n        except (ValueError, pickle.UnpicklingError) as e:\n            future.set_exception(e)\n            return\n\n        future.set_result(payload)\n\n    async def handle_error(self, event: RPCEvent) -> None:\n        future = self.__results.pop(event.header.serial)\n        if future.done():\n            return\n\n        try:\n            payload = self.protocol.serializer.unpack(event.payload)\n        except (ValueError, pickle.UnpicklingError) as e:\n            future.set_exception(e)\n            return\n\n        future.set_exception(payload)\n\n    async def handle_discover_request(self, event: RPCEvent) -> None:\n        self.writer.write(\n            self.protocol.pack(\n                list(self.executor.registry),\n                PacketTypes.DISCOVER_RESPONSE,\n                serial=event.header.serial,\n            ),\n        )\n\n    async def step(self) -> None:\n        event = await self.get_event()\n        method = self.__method_map[event.header.type]\n        await method(event)\n\n    async def make_request(self, request: CallRequest) -> Any:\n        serial = self.protocol.get_serial()\n        future = self.loop.create_future()\n        self.__results[serial] = future\n        self.writer.write(\n            self.protocol.pack(request, PacketTypes.REQUEST, serial=serial),\n        )\n        return await future\n\n    async def discover(self) -> List[str]:\n        self.writer.write(\n            self.protocol.pack(None, PacketTypes.DISCOVER_REQUEST),\n        )\n        while True:\n            event: RPCEvent = await self.get_event()\n\n            if event.header.type == PacketTypes.DISCOVER_REQUEST:\n                await self.handle_discover_request(event)\n                continue\n\n            return self.protocol.serializer.unpack(event.payload)\n\n    @abstractmethod\n    async def authorize(self) -> bool:\n        raise NotImplementedError\n\n    async def close(self) -> None:\n        if not self.writer.can_write_eof():\n            return\n        self.writer.close()\n        await self.writer.wait_closed()\n\n    async def process_events(self) -> None:\n        while True:\n            event = await self.__events.get()\n            method = self.__method_map[event.header.type]\n            await method(event)\n            self.__events.task_done()\n\n    async def start_processing(self) -> None:\n        workers = []\n\n        for _ in range(self.executor.max_workers):\n            workers.append(self.loop.create_task(self.process_events()))\n\n        try:\n            while True:\n                try:\n                    await self.__events.put(await self.get_event())\n                except (ConnectionError, asyncio.IncompleteReadError):\n                    address, port = self.__client_info[:2]\n\n                    if \":\" in address:\n                        address = f\"[{address}]\"\n\n                    log.info(\n                        \"Client connection tcp://%s:%d had been closed\",\n                        address, port,\n                    )\n                    return\n        finally:\n            del self.__events\n\n            cancelling = []\n            for worker in workers:\n                if worker.done():\n                    continue\n                worker.cancel()\n                cancelling.append(worker)\n            if cancelling:\n                await asyncio.gather(*cancelling, return_exceptions=True)", "\n\nclass ServerPacketHandler(PacketHandler):\n    async def authorize(self) -> bool:\n        token = uuid.uuid4().bytes\n        self.writer.write(self.protocol.pack(token, PacketTypes.AUTH_DIGEST))\n        event = await self.get_event()\n\n        if event.header.type != PacketTypes.AUTH_REQUEST:\n            return False\n\n        if not self.protocol.authorize_check(event.payload):\n            return False\n\n        self.writer.write(self.protocol.pack(None, PacketTypes.AUTH_OK))\n        return True", "\n\nclass ClientPacketHandler(PacketHandler):\n    async def authorize(self) -> bool:\n        event = await self.get_event()\n        if event.header.type != PacketTypes.AUTH_DIGEST:\n            return False\n        token = event.payload\n        self.writer.write(self.protocol.authorize_request(token))\n        event = await self.get_event()\n        return event.header.type == PacketTypes.AUTH_OK", "\n\nclass TCPBrokerBase(AbstractBroker, ABC):\n    protocol: Protocol\n    registry: Registry\n\n    def __init__(\n        self,\n        executor: AbstractExecutor,\n        key: bytes = b\"\", *,\n        ssl_context: Optional[ssl.SSLContext] = None,\n        reconnect_timeout: TimeoutType = 1,\n        serializer: AbstractSerializer = RestrictedPickleSerializer()\n    ):\n        self.protocol = Protocol(key=key, serializer=serializer)\n        self.reconnect_timeout = reconnect_timeout\n        self._ssl_context: Optional[ssl.SSLContext] = ssl_context\n        self.__handlers: DefaultDict[str, Deque[PacketHandler]] = (\n            defaultdict(deque)\n        )\n        self.__rotate_lock = asyncio.Lock()\n\n        super().__init__(executor=executor)\n\n    async def _get_handler(self, method: str) -> PacketHandler:\n        handler: PacketHandler\n\n        async with self.__rotate_lock:\n            while method not in self.__handlers:\n                log.warning(\n                    \"No active connections, retrying after %.3f seconds.\",\n                    self.reconnect_timeout,\n                )\n                await asyncio.sleep(self.reconnect_timeout)\n            handler = self.__handlers[method].popleft()\n            self.__handlers[method].append(handler)\n        return handler\n\n    async def _add_handler(\n        self, handler: PacketHandler, methods: Iterable[str],\n    ) -> None:\n        for method in methods:\n            self.__handlers[method].append(handler)\n\n    async def _remove_handler(self, handler: PacketHandler) -> None:\n        async with self.__rotate_lock:\n            for handlers in self.__handlers.values():\n                handlers.remove(handler)\n\n    async def call(\n        self,\n        func: Union[str, TaskFunctionType],\n        *args: Any,\n        timeout: Optional[TimeoutType] = None,\n        **kwargs: Any,\n    ) -> Any:\n        if not isinstance(func, str):\n            raise TypeError(\"Only strings supports\")\n\n        request = CallRequest(\n            func=func, args=args, kwargs=kwargs, timeout=timeout,\n        )\n\n        async def go(name: str) -> Any:\n            handler = await self._get_handler(name)\n            return await handler.make_request(request)\n\n        return await asyncio.wait_for(go(func), timeout=timeout)", "\n\nDEFAULT_PORT = 15383\n\n\n@final\nclass TCPServerBroker(TCPBrokerBase):\n    def __init__(\n        self,\n        executor: AbstractExecutor,\n        key: bytes = b\"\", *,\n        ssl_context: Optional[ssl.SSLContext] = None,\n        reconnect_timeout: TimeoutType = 1,\n        serializer: AbstractSerializer = RestrictedPickleSerializer()\n    ):\n        super().__init__(\n            executor=executor, key=key, ssl_context=ssl_context,\n            reconnect_timeout=reconnect_timeout, serializer=serializer,\n        )\n        self.servers: Set[asyncio.AbstractServer] = set()\n\n    async def _on_client_connected(\n        self, reader: asyncio.StreamReader, writer: asyncio.StreamWriter,\n    ) -> None:\n        handler = ServerPacketHandler(\n            reader=reader, writer=writer,\n            executor=self.executor, protocol=self.protocol,\n        )\n\n        async def handle() -> None:\n            if not await handler.authorize():\n                raise RuntimeError(\"Unauthorized\")\n\n            methods = await handler.discover()\n\n            await self._add_handler(handler, methods or ())\n\n            try:\n                await handler.start_processing()\n            finally:\n                await self._remove_handler(handler)\n\n        await self.create_task(handle())\n\n    async def listen(\n        self, address: str, port: int = DEFAULT_PORT, **kwargs: Any\n    ) -> None:\n        if \"ssl\" not in kwargs:\n            kwargs[\"ssl\"] = self._ssl_context\n\n        self.servers.add(\n            await asyncio.start_server(\n                self._on_client_connected,\n                host=address,\n                port=port,\n                **kwargs\n            ),\n        )\n\n    async def close(self) -> None:\n        tasks = [super().close()]\n        for server in self.servers:\n            server.close()\n            tasks.append(server.wait_closed())\n        await asyncio.gather(*tasks, return_exceptions=True)", "\n\n@final\nclass TCPClientBroker(TCPBrokerBase):\n    async def connection_fabric(\n        self, address: str, port: int,\n        on_connected: asyncio.Event,\n        **kwargs: Any\n    ) -> None:\n        if \"ssl\" not in kwargs:\n            kwargs[\"ssl\"] = self._ssl_context\n\n        while True:\n            try:\n                reader, writer = await asyncio.open_connection(\n                    host=address, port=port, **kwargs\n                )\n                try:\n                    handler = ClientPacketHandler(\n                        reader=reader, writer=writer,\n                        executor=self.executor, protocol=self.protocol,\n                    )\n                    if not await handler.authorize():\n                        raise RuntimeError(\"Unauthorized\")\n\n                    methods = await handler.discover()\n                    on_connected.set()\n                    await self._add_handler(handler, methods or ())\n                    await handler.start_processing()\n                except asyncio.CancelledError:\n                    if not writer.is_closing():\n                        writer.close()\n                        await writer.wait_closed()\n                    raise\n\n                if not writer.is_closing():\n                    writer.close()\n                    await writer.wait_closed()\n\n                on_connected.clear()\n                await self._remove_handler(handler)\n\n                log.error(\n                    \"Connection to tcp://%s:%d closed. \"\n                    \"Reconnecting after %.3f seconds...\",\n                    address, port, self.reconnect_timeout,\n                )\n            except (ConnectionError, asyncio.TimeoutError):\n                log.error(\n                    \"Failed to establish connection to tcp://%s:%d closed. \"\n                    \"Reconnecting after %.3f seconds.\",\n                    address, port, self.reconnect_timeout,\n                )\n            finally:\n                await asyncio.sleep(self.reconnect_timeout)\n            log.info(\n                \"Connection attempts to tcp://%s:%d has been stopped.\",\n                address, port,\n            )\n\n    async def connect(\n        self, address: str, port: int = DEFAULT_PORT, **kwargs: Any\n    ) -> None:\n        event = asyncio.Event()\n        self.create_task(\n            self.connection_fabric(address, port, event, **kwargs),\n        )\n        await event.wait()", "\n\n__all__ = (\"TCPBrokerBase\", \"TCPClientBroker\", \"TCPServerBroker\")\n"]}
{"filename": "patio/broker/tcp/__init__.py", "chunked_list": ["from .broker import TCPBrokerBase, TCPClientBroker, TCPServerBroker\n\n\n__all__ = (\n    \"TCPBrokerBase\",\n    \"TCPClientBroker\",\n    \"TCPServerBroker\",\n)\n", ""]}
{"filename": "examples/tcp/client-is-caller/client.py", "chunked_list": ["import asyncio\n\nfrom patio import Registry\nfrom patio.broker.tcp import TCPClientBroker\nfrom patio.executor import ThreadPoolExecutor\n\n\nrpc = Registry(project=\"test\", strict=True)\n\n", "\n\nasync def main():\n    async with ThreadPoolExecutor(rpc) as executor:\n        async with TCPClientBroker(executor) as broker:\n            await broker.connect(address=\"127.0.0.1\")\n            await broker.connect(address=\"::1\")\n            print(\n                await asyncio.gather(\n                    *[", "                await asyncio.gather(\n                    *[\n                        broker.call(\"mul\", i, i) for i in range(10)\n                    ]\n                ),\n            )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "if __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
{"filename": "examples/tcp/client-is-caller/server.py", "chunked_list": ["import asyncio\nfrom functools import reduce\n\nfrom patio import Registry\nfrom patio.broker.tcp import TCPServerBroker\nfrom patio.executor import ThreadPoolExecutor\n\n\nrpc = Registry(project=\"test\", strict=True)\n", "rpc = Registry(project=\"test\", strict=True)\n\n\ndef mul(*args):\n    return reduce(lambda x, y: x * y, args)\n\n\nasync def main():\n    rpc.register(mul, \"mul\")\n", "    rpc.register(mul, \"mul\")\n\n    async with ThreadPoolExecutor(rpc) as executor:\n        async with TCPServerBroker(executor) as broker:\n            await broker.listen(address=\"127.0.0.1\")\n            await broker.listen(address=\"::1\")\n            await broker.join()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "\nif __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
{"filename": "examples/tcp/server-is-caller/client.py", "chunked_list": ["import asyncio\nfrom functools import reduce\n\nfrom patio import Registry\nfrom patio.broker.tcp import TCPClientBroker\nfrom patio.executor import ThreadPoolExecutor\n\n\nrpc = Registry(project=\"test\", strict=True)\n", "rpc = Registry(project=\"test\", strict=True)\n\n\ndef mul(*args):\n    return reduce(lambda x, y: x * y, args)\n\n\nasync def main():\n    rpc.register(mul, \"mul\")\n", "    rpc.register(mul, \"mul\")\n\n    async with ThreadPoolExecutor(rpc) as executor:\n        async with TCPClientBroker(executor) as broker:\n            await broker.connect(address=\"127.0.0.1\")\n            await broker.join()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "if __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
{"filename": "examples/tcp/server-is-caller/server.py", "chunked_list": ["import asyncio\n\nfrom patio import Registry\nfrom patio.broker.tcp import TCPServerBroker\nfrom patio.executor import ThreadPoolExecutor\n\n\nrpc = Registry(project=\"test\", strict=True)\n\n", "\n\nasync def main():\n    async with ThreadPoolExecutor(rpc) as executor:\n        async with TCPServerBroker(executor) as broker:\n            await broker.listen(address=\"127.0.0.1\")\n            while True:\n                print(\n                    await asyncio.gather(\n                        *[", "                    await asyncio.gather(\n                        *[\n                            broker.call(\"mul\", i, i) for i in range(10)\n                        ], return_exceptions=True\n                    ),\n                )\n                await asyncio.sleep(1)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "\nif __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
{"filename": "examples/memory/multiplication-decorator.py", "chunked_list": ["import asyncio\nfrom functools import reduce\n\nfrom patio import AsyncExecutor, MemoryBroker, Registry\n\n\nrpc = Registry(project=\"test\", strict=True)\n\n\n@rpc", "\n@rpc\nasync def mul(*args):\n    loop = asyncio.get_running_loop()\n    return await loop.run_in_executor(None, reduce, lambda x, y: x * y, args)\n\n\nasync def main():\n    async with AsyncExecutor(max_workers=50) as executor:\n        async with MemoryBroker(executor) as broker:", "    async with AsyncExecutor(max_workers=50) as executor:\n        async with MemoryBroker(executor) as broker:\n            await broker.setup(registry=rpc)\n\n            print(\n                await asyncio.gather(\n                    *[\n                        broker.call(mul, i, i) for i in range(10)\n                    ]\n                ),", "                    ]\n                ),\n            )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
{"filename": "examples/memory/multiplication.py", "chunked_list": ["import asyncio\nfrom functools import reduce\n\nfrom patio import MemoryBroker, Registry\nfrom patio.executor import ThreadPoolExecutor\n\n\nrpc = Registry(project=\"test\", strict=True)\n\n\ndef mul(*args):\n    return reduce(lambda x, y: x * y, args)", "\n\ndef mul(*args):\n    return reduce(lambda x, y: x * y, args)\n\n\nasync def main():\n    rpc.register(mul, \"mul\")\n\n    async with ThreadPoolExecutor(rpc) as executor:", "\n    async with ThreadPoolExecutor(rpc) as executor:\n        async with MemoryBroker(executor) as broker:\n            print(\n                await asyncio.gather(\n                    *[\n                        broker.call(mul, i, i) for i in range(10)\n                    ]\n                ),\n            )", "                ),\n            )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
