{"filename": "tests/test_np_model.py", "chunked_list": ["import tempfile\nfrom pathlib import Path\n\nimport numpy as np\nimport pytest\nfrom hypothesis.extra.numpy import arrays\n\nfrom pydantic_numpy.model import NumpyModel\nfrom pydantic_numpy.model.np_model import model_agnostic_load\nfrom pydantic_numpy.typing import NpNDArray", "from pydantic_numpy.model.np_model import model_agnostic_load\nfrom pydantic_numpy.typing import NpNDArray\n\nTEST_MODEL_OBJECT_ID = \"test\"\nOTHER_TEST_MODEL_OBJECT_ID = \"other_test\"\nNON_ARRAY_VALUE = 5\n\n\nclass NumpyModelForTest(NumpyModel):\n    array: NpNDArray\n    non_array: int", "class NumpyModelForTest(NumpyModel):\n    array: NpNDArray\n    non_array: int\n\n\nclass TestWithArbitraryForTest(NumpyModelForTest, arbitrary_types_allowed=True):\n    my_arbitrary_slice: slice\n\n\ndef _create_example_array():\n    return arrays(np.float64, (1,)).example()", "\ndef _create_example_array():\n    return arrays(np.float64, (1,)).example()\n\n\ndef _numpy_model():\n    return NumpyModelForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n\n\n@pytest.fixture\ndef numpy_model():\n    return _numpy_model()", "\n@pytest.fixture\ndef numpy_model():\n    return _numpy_model()\n\n\n@pytest.fixture(\n    params=[\n        _numpy_model(),\n        TestWithArbitraryForTest(", "        _numpy_model(),\n        TestWithArbitraryForTest(\n            array=_create_example_array(), non_array=NON_ARRAY_VALUE, my_arbitrary_slice=slice(0, 10)\n        ),\n    ]\n)\ndef numpy_model_with_arbitrary(request):\n    return request.param\n\n\ndef test_io_yaml(numpy_model: NumpyModel) -> None:\n    with tempfile.TemporaryDirectory() as tmp_dirname:\n        numpy_model.dump(tmp_dirname, TEST_MODEL_OBJECT_ID)\n        assert numpy_model.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model", "\n\ndef test_io_yaml(numpy_model: NumpyModel) -> None:\n    with tempfile.TemporaryDirectory() as tmp_dirname:\n        numpy_model.dump(tmp_dirname, TEST_MODEL_OBJECT_ID)\n        assert numpy_model.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model\n\n\ndef test_io_compressed_pickle(numpy_model_with_arbitrary: NumpyModel) -> None:\n    with tempfile.TemporaryDirectory() as tmp_dirname:\n        numpy_model_with_arbitrary.dump(tmp_dirname, TEST_MODEL_OBJECT_ID, pickle=True)\n        assert numpy_model_with_arbitrary.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model_with_arbitrary", "def test_io_compressed_pickle(numpy_model_with_arbitrary: NumpyModel) -> None:\n    with tempfile.TemporaryDirectory() as tmp_dirname:\n        numpy_model_with_arbitrary.dump(tmp_dirname, TEST_MODEL_OBJECT_ID, pickle=True)\n        assert numpy_model_with_arbitrary.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model_with_arbitrary\n\n\ndef test_io_pickle(numpy_model_with_arbitrary: NumpyModel) -> None:\n    with tempfile.TemporaryDirectory() as tmp_dirname:\n        numpy_model_with_arbitrary.dump(tmp_dirname, TEST_MODEL_OBJECT_ID, pickle=True, compress=False)\n        assert numpy_model_with_arbitrary.load(tmp_dirname, TEST_MODEL_OBJECT_ID) == numpy_model_with_arbitrary", "\n\ndef test_typing_json_dump(numpy_model: NumpyModel):\n    assert numpy_model.model_dump_json() == '{\"array\":\"%s\",\"non_array\":%s}' % (\n        np.array2string(numpy_model.array),\n        NON_ARRAY_VALUE,\n    ), \"\"\n\n\ndef test_model_agnostic_load():\n    class NumpyModelAForTest(NumpyModel):\n        array: NpNDArray\n        non_array: int\n\n    class NumpyModelBForTest(NumpyModel):\n        array: NpNDArray\n        non_array: int\n\n    model_a = NumpyModelAForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n    model_b = NumpyModelBForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n\n    with tempfile.TemporaryDirectory() as tmp_dirname:\n        tmp_dir_path = Path(tmp_dirname)\n\n        model_a.dump(tmp_dir_path, TEST_MODEL_OBJECT_ID)\n        model_b.dump(tmp_dir_path, OTHER_TEST_MODEL_OBJECT_ID)\n\n        models = [model_a, model_b]\n        assert model_a == model_agnostic_load(tmp_dir_path, TEST_MODEL_OBJECT_ID, models=models)\n        assert model_b == model_agnostic_load(tmp_dir_path, OTHER_TEST_MODEL_OBJECT_ID, models=models)", "\ndef test_model_agnostic_load():\n    class NumpyModelAForTest(NumpyModel):\n        array: NpNDArray\n        non_array: int\n\n    class NumpyModelBForTest(NumpyModel):\n        array: NpNDArray\n        non_array: int\n\n    model_a = NumpyModelAForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n    model_b = NumpyModelBForTest(array=_create_example_array(), non_array=NON_ARRAY_VALUE)\n\n    with tempfile.TemporaryDirectory() as tmp_dirname:\n        tmp_dir_path = Path(tmp_dirname)\n\n        model_a.dump(tmp_dir_path, TEST_MODEL_OBJECT_ID)\n        model_b.dump(tmp_dir_path, OTHER_TEST_MODEL_OBJECT_ID)\n\n        models = [model_a, model_b]\n        assert model_a == model_agnostic_load(tmp_dir_path, TEST_MODEL_OBJECT_ID, models=models)\n        assert model_b == model_agnostic_load(tmp_dir_path, OTHER_TEST_MODEL_OBJECT_ID, models=models)", ""]}
{"filename": "tests/test_typing.py", "chunked_list": ["import tempfile\nfrom pathlib import Path\nfrom typing import Optional\n\nimport numpy as np\nimport numpy.typing as npt\nimport pytest\nfrom hypothesis.extra.numpy import arrays\nfrom pydantic import ValidationError\n", "from pydantic import ValidationError\n\nfrom pydantic_numpy.helper.validation import PydanticNumpyMultiArrayNumpyFileOnFilePath\nfrom pydantic_numpy.model import MultiArrayNumpyFile\nfrom pydantic_numpy.util import np_general_all_close\nfrom tests.helper.cache import cached_calculation\nfrom tests.helper.groups import (\n    data_type_array_typing_dimensions,\n    dimension_testing_group,\n    strict_data_type_nd_array_typing_dimensions,", "    dimension_testing_group,\n    strict_data_type_nd_array_typing_dimensions,\n    supported_data_types,\n)\n\nAXIS_LENGTH = 1\n\n\n@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\ndef test_correct_type(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n    assert cached_calculation(pydantic_typing)(\n        array_field=arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n    )", "@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\ndef test_correct_type(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n    assert cached_calculation(pydantic_typing)(\n        array_field=arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n    )\n\n\n@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", strict_data_type_nd_array_typing_dimensions)\n@pytest.mark.parametrize(\"wrong_numpy_type\", supported_data_types)\ndef test_wrong_dtype_type(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int], wrong_numpy_type):\n    if wrong_numpy_type == numpy_dtype:\n        return True\n\n    bad_array = arrays(wrong_numpy_type, tuple(AXIS_LENGTH for _ in range(dimensions or 5))).example()\n    with pytest.raises(ValidationError):\n        cached_calculation(pydantic_typing)(array_field=bad_array)", "@pytest.mark.parametrize(\"wrong_numpy_type\", supported_data_types)\ndef test_wrong_dtype_type(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int], wrong_numpy_type):\n    if wrong_numpy_type == numpy_dtype:\n        return True\n\n    bad_array = arrays(wrong_numpy_type, tuple(AXIS_LENGTH for _ in range(dimensions or 5))).example()\n    with pytest.raises(ValidationError):\n        cached_calculation(pydantic_typing)(array_field=bad_array)\n\n", "\n\n@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", dimension_testing_group)\ndef test_wrong_dimension(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n    wrong_dimension = dimensions + 1\n\n    bad_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(wrong_dimension or 5))).example()\n    with pytest.raises(ValueError):\n        cached_calculation(pydantic_typing)(array_field=bad_array)\n", "\n\n@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\ndef test_file_path_passing_validation(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npz\") as tf:\n        np.savez_compressed(tf.name, my_array=hyp_array)\n        numpy_model = cached_calculation(pydantic_typing)(array_field=Path(tf.name))\n\n        assert np_general_all_close(numpy_model.array_field, hyp_array)", "\n\n@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\ndef test_file_path_error_on_reading_single_array_file(\n    numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]\n):\n    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npz\") as tf:\n        np.savez_compressed(tf.name, my_array=hyp_array, my_identical_array=hyp_array)\n        model = cached_calculation(pydantic_typing)\n\n        with pytest.raises(PydanticNumpyMultiArrayNumpyFileOnFilePath):\n            model(array_field=Path(tf.name))", "\n\n@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\ndef test_multi_array_numpy_passing_validation(numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]):\n    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npz\") as tf:\n        np.savez_compressed(tf.name, my_array=hyp_array)\n        numpy_model = cached_calculation(pydantic_typing)(\n            array_field=MultiArrayNumpyFile(path=Path(tf.name), key=\"my_array\")\n        )\n\n        assert np_general_all_close(numpy_model.array_field, hyp_array)", "\n\n@pytest.mark.parametrize(\"numpy_dtype,pydantic_typing,dimensions\", data_type_array_typing_dimensions)\ndef test_multi_array_numpy_error_on_reading_single_array_file(\n    numpy_dtype: npt.DTypeLike, pydantic_typing, dimensions: Optional[int]\n):\n    hyp_array = arrays(numpy_dtype, tuple(AXIS_LENGTH for _ in range(dimensions or 1))).example()\n    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=True, suffix=\".npy\") as tf:\n        np.save(tf.name, hyp_array)\n        model = cached_calculation(pydantic_typing)\n\n        with pytest.raises(AttributeError):\n            model(array_field=MultiArrayNumpyFile(path=Path(tf.name), key=\"my_array\"))", ""]}
{"filename": "tests/__init__.py", "chunked_list": [""]}
{"filename": "tests/helper/cache.py", "chunked_list": ["from functools import cache\n\nfrom pydantic import BaseModel\n\n\n@cache\ndef cached_calculation(array_type_hint) -> type[BaseModel]:\n    class ModelForTesting(BaseModel):\n        array_field: array_type_hint\n\n    return ModelForTesting", ""]}
{"filename": "tests/helper/__init__.py", "chunked_list": [""]}
{"filename": "tests/helper/groups.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.typing import *\n\nsupported_data_types = (\n    np.int64,\n    np.int32,\n    np.int16,\n    np.int8,\n    np.uint64,", "    np.int8,\n    np.uint64,\n    np.uint32,\n    np.uint16,\n    np.uint8,\n    np.float128,\n    np.float64,\n    np.float32,\n    np.float16,\n    np.complex256,", "    np.float16,\n    np.complex256,\n    np.complex128,\n    np.complex64,\n    np.datetime64,\n    np.timedelta64,\n)\n\ndata_type_1d_array_typing_dimensions = [\n    (np.int64, Np1DArrayInt64, 1),", "data_type_1d_array_typing_dimensions = [\n    (np.int64, Np1DArrayInt64, 1),\n    (np.int32, Np1DArrayInt32, 1),\n    (np.int16, Np1DArrayInt16, 1),\n    (np.int8, Np1DArrayInt8, 1),\n    (np.uint64, Np1DArrayUint64, 1),\n    (np.uint32, Np1DArrayUint32, 1),\n    (np.uint16, Np1DArrayUint16, 1),\n    (np.uint8, Np1DArrayUint8, 1),\n    (np.float128, Np1DArrayFp128, 1),", "    (np.uint8, Np1DArrayUint8, 1),\n    (np.float128, Np1DArrayFp128, 1),\n    (np.float64, Np1DArrayFp64, 1),\n    (np.float32, Np1DArrayFp32, 1),\n    (np.float16, Np1DArrayFp16, 1),\n    (np.complex256, Np1DArrayComplex256, 1),\n    (np.complex128, Np1DArrayComplex128, 1),\n    (np.complex64, Np1DArrayComplex64, 1),\n    (bool, Np1DArrayBool, 1),\n    (np.datetime64, Np1DArrayDatetime64, 1),", "    (bool, Np1DArrayBool, 1),\n    (np.datetime64, Np1DArrayDatetime64, 1),\n    (np.timedelta64, Np1DArrayTimedelta64, 1),\n]\ndata_type_2d_array_typing_dimensions = [\n    (np.int64, Np2DArrayInt64, 2),\n    (np.int32, Np2DArrayInt32, 2),\n    (np.int16, Np2DArrayInt16, 2),\n    (np.int8, Np2DArrayInt8, 2),\n    (np.uint64, Np2DArrayUint64, 2),", "    (np.int8, Np2DArrayInt8, 2),\n    (np.uint64, Np2DArrayUint64, 2),\n    (np.uint32, Np2DArrayUint32, 2),\n    (np.uint16, Np2DArrayUint16, 2),\n    (np.uint8, Np2DArrayUint8, 2),\n    (np.float128, Np2DArrayFp128, 2),\n    (np.float64, Np2DArrayFp64, 2),\n    (np.float32, Np2DArrayFp32, 2),\n    (np.float16, Np2DArrayFp16, 2),\n    (np.complex256, Np2DArrayComplex256, 2),", "    (np.float16, Np2DArrayFp16, 2),\n    (np.complex256, Np2DArrayComplex256, 2),\n    (np.complex128, Np2DArrayComplex128, 2),\n    (np.complex64, Np2DArrayComplex64, 2),\n    (bool, Np2DArrayBool, 2),\n    (np.datetime64, Np2DArrayDatetime64, 2),\n    (np.timedelta64, Np2DArrayTimedelta64, 2),\n]\ndata_type_3d_array_typing_dimensions = [\n    (np.int64, Np3DArrayInt64, 3),", "data_type_3d_array_typing_dimensions = [\n    (np.int64, Np3DArrayInt64, 3),\n    (np.int32, Np3DArrayInt32, 3),\n    (np.int16, Np3DArrayInt16, 3),\n    (np.int8, Np3DArrayInt8, 3),\n    (np.uint64, Np3DArrayUint64, 3),\n    (np.uint32, Np3DArrayUint32, 3),\n    (np.uint16, Np3DArrayUint16, 3),\n    (np.uint8, Np3DArrayUint8, 3),\n    (np.float128, Np3DArrayFp128, 3),", "    (np.uint8, Np3DArrayUint8, 3),\n    (np.float128, Np3DArrayFp128, 3),\n    (np.float64, Np3DArrayFp64, 3),\n    (np.float32, Np3DArrayFp32, 3),\n    (np.float16, Np3DArrayFp16, 3),\n    (np.complex256, Np3DArrayComplex256, 3),\n    (np.complex128, Np3DArrayComplex128, 3),\n    (np.complex64, Np3DArrayComplex64, 3),\n    (bool, Np3DArrayBool, 3),\n    (np.datetime64, Np3DArrayDatetime64, 3),", "    (bool, Np3DArrayBool, 3),\n    (np.datetime64, Np3DArrayDatetime64, 3),\n    (np.timedelta64, Np3DArrayTimedelta64, 3),\n]\ndata_type_nd_array_typing_dimensions = [\n    (np.int64, NpNDArrayInt64, None),\n    (np.int32, NpNDArrayInt32, None),\n    (np.int16, NpNDArrayInt16, None),\n    (np.int8, NpNDArrayInt8, None),\n    (np.uint64, NpNDArrayUint64, None),", "    (np.int8, NpNDArrayInt8, None),\n    (np.uint64, NpNDArrayUint64, None),\n    (np.uint32, NpNDArrayUint32, None),\n    (np.uint16, NpNDArrayUint16, None),\n    (np.uint8, NpNDArrayUint8, None),\n    (np.float128, NpNDArrayFp128, None),\n    (np.float64, NpNDArrayFp64, None),\n    (np.float32, NpNDArrayFp32, None),\n    (np.float16, NpNDArrayFp16, None),\n    (np.complex256, NpNDArrayComplex256, None),", "    (np.float16, NpNDArrayFp16, None),\n    (np.complex256, NpNDArrayComplex256, None),\n    (np.complex128, NpNDArrayComplex128, None),\n    (np.complex64, NpNDArrayComplex64, None),\n    (bool, NpNDArrayBool, None),\n    (np.datetime64, NpNDArrayDatetime64, None),\n    (np.timedelta64, NpNDArrayTimedelta64, None),\n]\n\ndata_type_array_typing_dimensions = [", "\ndata_type_array_typing_dimensions = [\n    *data_type_1d_array_typing_dimensions,\n    *data_type_2d_array_typing_dimensions,\n    *data_type_3d_array_typing_dimensions,\n    *data_type_nd_array_typing_dimensions,\n]\n\n# Data type strict\nstrict_data_type_1d_array_typing_dimensions = [", "# Data type strict\nstrict_data_type_1d_array_typing_dimensions = [\n    (np.int64, NpStrict1DArrayInt64, 1),\n    (np.int32, NpStrict1DArrayInt32, 1),\n    (np.int16, NpStrict1DArrayInt16, 1),\n    (np.int8, NpStrict1DArrayInt8, 1),\n    (np.uint64, NpStrict1DArrayUint64, 1),\n    (np.uint32, NpStrict1DArrayUint32, 1),\n    (np.uint16, NpStrict1DArrayUint16, 1),\n    (np.uint8, NpStrict1DArrayUint8, 1),", "    (np.uint16, NpStrict1DArrayUint16, 1),\n    (np.uint8, NpStrict1DArrayUint8, 1),\n    (np.float128, NpStrict1DArrayFp128, 1),\n    (np.float64, NpStrict1DArrayFp64, 1),\n    (np.float32, NpStrict1DArrayFp32, 1),\n    (np.float16, NpStrict1DArrayFp16, 1),\n    (np.complex256, NpStrict1DArrayComplex256, 1),\n    (np.complex128, NpStrict1DArrayComplex128, 1),\n    (np.complex64, NpStrict1DArrayComplex64, 1),\n    (bool, NpStrict1DArrayBool, 1),", "    (np.complex64, NpStrict1DArrayComplex64, 1),\n    (bool, NpStrict1DArrayBool, 1),\n    (np.datetime64, NpStrict1DArrayDatetime64, 1),\n    (np.timedelta64, NpStrict1DArrayTimedelta64, 1),\n]\nstrict_data_type_2d_array_typing_dimensions = [\n    (np.int64, NpStrict2DArrayInt64, 2),\n    (np.int32, NpStrict2DArrayInt32, 2),\n    (np.int16, NpStrict2DArrayInt16, 2),\n    (np.int8, NpStrict2DArrayInt8, 2),", "    (np.int16, NpStrict2DArrayInt16, 2),\n    (np.int8, NpStrict2DArrayInt8, 2),\n    (np.uint64, NpStrict2DArrayUint64, 2),\n    (np.uint32, NpStrict2DArrayUint32, 2),\n    (np.uint16, NpStrict2DArrayUint16, 2),\n    (np.uint8, NpStrict2DArrayUint8, 2),\n    (np.float128, NpStrict2DArrayFp128, 2),\n    (np.float64, NpStrict2DArrayFp64, 2),\n    (np.float32, NpStrict2DArrayFp32, 2),\n    (np.float16, NpStrict2DArrayFp16, 2),", "    (np.float32, NpStrict2DArrayFp32, 2),\n    (np.float16, NpStrict2DArrayFp16, 2),\n    (np.complex256, NpStrict2DArrayComplex256, 2),\n    (np.complex128, NpStrict2DArrayComplex128, 2),\n    (np.complex64, NpStrict2DArrayComplex64, 2),\n    (bool, NpStrict2DArrayBool, 2),\n    (np.datetime64, NpStrict2DArrayDatetime64, 2),\n    (np.timedelta64, NpStrict2DArrayTimedelta64, 2),\n]\nstrict_data_type_3d_array_typing_dimensions = [", "]\nstrict_data_type_3d_array_typing_dimensions = [\n    (np.int64, NpStrict3DArrayInt64, 3),\n    (np.int32, NpStrict3DArrayInt32, 3),\n    (np.int16, NpStrict3DArrayInt16, 3),\n    (np.int8, NpStrict3DArrayInt8, 3),\n    (np.uint64, NpStrict3DArrayUint64, 3),\n    (np.uint32, NpStrict3DArrayUint32, 3),\n    (np.uint16, NpStrict3DArrayUint16, 3),\n    (np.uint8, NpStrict3DArrayUint8, 3),", "    (np.uint16, NpStrict3DArrayUint16, 3),\n    (np.uint8, NpStrict3DArrayUint8, 3),\n    (np.float128, NpStrict3DArrayFp128, 3),\n    (np.float64, NpStrict3DArrayFp64, 3),\n    (np.float32, NpStrict3DArrayFp32, 3),\n    (np.float16, NpStrict3DArrayFp16, 3),\n    (np.complex256, NpStrict3DArrayComplex256, 3),\n    (np.complex128, NpStrict3DArrayComplex128, 3),\n    (np.complex64, NpStrict3DArrayComplex64, 3),\n    (bool, NpStrict3DArrayBool, 3),", "    (np.complex64, NpStrict3DArrayComplex64, 3),\n    (bool, NpStrict3DArrayBool, 3),\n    (np.datetime64, NpStrict3DArrayDatetime64, 3),\n    (np.timedelta64, NpStrict3DArrayTimedelta64, 3),\n]\nstrict_data_type_nd_array_typing_dimensions = [\n    (np.int64, NpStrictNDArrayInt64, None),\n    (np.int32, NpStrictNDArrayInt32, None),\n    (np.int16, NpStrictNDArrayInt16, None),\n    (np.int8, NpStrictNDArrayInt8, None),", "    (np.int16, NpStrictNDArrayInt16, None),\n    (np.int8, NpStrictNDArrayInt8, None),\n    (np.uint64, NpStrictNDArrayUint64, None),\n    (np.uint32, NpStrictNDArrayUint32, None),\n    (np.uint16, NpStrictNDArrayUint16, None),\n    (np.uint8, NpStrictNDArrayUint8, None),\n    (np.float128, NpStrictNDArrayFp128, None),\n    (np.float64, NpStrictNDArrayFp64, None),\n    (np.float32, NpStrictNDArrayFp32, None),\n    (np.float16, NpStrictNDArrayFp16, None),", "    (np.float32, NpStrictNDArrayFp32, None),\n    (np.float16, NpStrictNDArrayFp16, None),\n    (np.complex256, NpStrictNDArrayComplex256, None),\n    (np.complex128, NpStrictNDArrayComplex128, None),\n    (np.complex64, NpStrictNDArrayComplex64, None),\n    (bool, NpStrictNDArrayBool, None),\n    (np.datetime64, NpStrictNDArrayDatetime64, None),\n    (np.timedelta64, NpStrictNDArrayTimedelta64, None),\n]\n", "]\n\nstrict_data_type_array_typing_dimensions = [\n    *strict_data_type_1d_array_typing_dimensions,\n    *strict_data_type_2d_array_typing_dimensions,\n    *strict_data_type_3d_array_typing_dimensions,\n    *strict_data_type_nd_array_typing_dimensions,\n]\n\ndimension_testing_group = [", "\ndimension_testing_group = [\n    (np.int64, Np1DArrayInt64, 1),\n    (np.int64, Np2DArrayInt64, 2),\n    (np.int64, Np3DArrayInt64, 3),\n]\n"]}
{"filename": "pydantic_numpy/__init__.py", "chunked_list": ["from pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\nfrom pydantic_numpy.typing.n_dimensional import *\n"]}
{"filename": "pydantic_numpy/util.py", "chunked_list": ["import numpy as np\nimport numpy.typing as npt\nfrom numpy.core._exceptions import UFuncTypeError\nfrom semver import Version\n\n\ndef np_general_all_close(arr_a: npt.NDArray, arr_b: npt.NDArray, rtol: float = 1e-05, atol: float = 1e-08) -> bool:\n    \"\"\"\n    Data type agnostic function to define if two numpy array have elements that are close\n\n    Parameters\n    ----------\n    arr_a: npt.NDArray\n    arr_b: npt.NDArray\n    rtol: float\n        See np.allclose\n    atol: float\n        See np.allclose\n\n    Returns\n    -------\n    Bool\n    \"\"\"\n    return _np_general_all_close(arr_a, arr_b, rtol, atol)", "\n\nif Version.parse(np.version.version) < Version.parse(\"1.25.0\"):\n\n    def _np_general_all_close(arr_a: npt.NDArray, arr_b: npt.NDArray, rtol: float = 1e-05, atol: float = 1e-08) -> bool:\n        try:\n            return np.allclose(arr_a, arr_b, rtol=rtol, atol=atol, equal_nan=True)\n        except UFuncTypeError:\n            return np.allclose(arr_a.astype(np.float64), arr_b.astype(np.float64), rtol=rtol, atol=atol, equal_nan=True)\n        except TypeError:\n            return bool(np.all(arr_a == arr_b))\n\nelse:\n    from numpy.exceptions import DTypePromotionError\n\n    def _np_general_all_close(arr_a: npt.NDArray, arr_b: npt.NDArray, rtol: float = 1e-05, atol: float = 1e-08) -> bool:\n        try:\n            return np.allclose(arr_a, arr_b, rtol=rtol, atol=atol, equal_nan=True)\n        except UFuncTypeError:\n            return np.allclose(arr_a.astype(np.float64), arr_b.astype(np.float64), rtol=rtol, atol=atol, equal_nan=True)\n        except DTypePromotionError:\n            return bool(np.all(arr_a == arr_b))", ""]}
{"filename": "pydantic_numpy/model/__init__.py", "chunked_list": ["from pydantic_numpy.model.multi_array import MultiArrayNumpyFile\nfrom pydantic_numpy.model.np_model import NumpyModel\n"]}
{"filename": "pydantic_numpy/model/np_model.py", "chunked_list": ["import pickle as pickle_pkg\nfrom pathlib import Path\nfrom typing import Any, Callable, ClassVar, Iterable, Optional\n\nimport compress_pickle\nimport numpy as np\nimport numpy.typing as npt\nfrom pydantic import BaseModel, DirectoryPath, FilePath, computed_field, validate_call\nfrom ruamel.yaml import YAML\n", "from ruamel.yaml import YAML\n\nfrom pydantic_numpy.util import np_general_all_close\n\nyaml = YAML()\n\n\nclass NumpyModel(BaseModel):\n    _dump_compression: ClassVar[str] = \"lz4\"\n    _dump_numpy_savez_file_name: ClassVar[str] = \"arrays.npz\"\n    _dump_non_array_file_stem: ClassVar[str] = \"object_info\"\n\n    _directory_suffix: ClassVar[str] = \".pdnp\"\n\n    def __eq__(self, other: Any) -> bool:\n        if isinstance(other, NumpyModel):\n            self_type = self.__pydantic_generic_metadata__[\"origin\"] or self.__class__\n            other_type = other.__pydantic_generic_metadata__[\"origin\"] or other.__class__\n\n            self_ndarray_field_to_array, self_other_field_to_value = self._dump_numpy_split_dict()\n            other_ndarray_field_to_array, other_other_field_to_value = other._dump_numpy_split_dict()\n\n            return (\n                self_type == other_type\n                and self_other_field_to_value == other_other_field_to_value\n                and self.__pydantic_private__ == other.__pydantic_private__\n                and self.__pydantic_extra__ == other.__pydantic_extra__\n                and _compare_np_array_dicts(self_ndarray_field_to_array, other_ndarray_field_to_array)\n            )\n        elif isinstance(other, BaseModel):\n            return super().__eq__(other)\n        else:\n            return NotImplemented  # delegate to the other item in the comparison\n\n    @classmethod\n    @validate_call\n    def model_directory_path(cls, output_directory: DirectoryPath, object_id: str) -> DirectoryPath:\n        return output_directory / f\"{object_id}.{cls.__name__}{cls._directory_suffix}\"\n\n    @classmethod\n    @validate_call\n    def load(\n        cls,\n        output_directory: DirectoryPath,\n        object_id: str,\n        *,\n        pre_load_modifier: Optional[Callable[[dict[str, Any]], dict[str, Any]]] = None,\n    ):\n        \"\"\"\n        Load NumpyModel instance\n\n        Parameters\n        ----------\n        output_directory: DirectoryPath\n            The root directory where all model instances of interest are stored\n        object_id: String\n            The ID of the model instance\n        pre_load_modifier: Callable[[dict[str, Any]], dict[str, Any]] | None\n            Optional function that modifies the loaded arrays\n\n        Returns\n        -------\n        NumpyModel instance\n        \"\"\"\n        object_directory_path = cls.model_directory_path(output_directory, object_id)\n\n        npz_file = np.load(object_directory_path / cls._dump_numpy_savez_file_name)\n\n        other_path: FilePath\n        if (other_path := object_directory_path / cls._dump_compressed_pickle_file_name).exists():\n            other_field_to_value = compress_pickle.load(other_path)\n        elif (other_path := object_directory_path / cls._dump_pickle_file_name).exists():\n            with open(other_path, \"rb\") as in_pickle:\n                other_field_to_value = pickle_pkg.load(in_pickle)\n        elif (other_path := object_directory_path / cls._dump_non_array_yaml_name).exists():\n            with open(other_path, \"r\") as in_yaml:\n                other_field_to_value = yaml.load(in_yaml)\n        else:\n            other_field_to_value = {}\n\n        field_to_value = {**npz_file, **other_field_to_value}\n        if pre_load_modifier:\n            field_to_value = pre_load_modifier(field_to_value)\n\n        return cls(**field_to_value)\n\n    @validate_call\n    def dump(\n        self, output_directory: Path, object_id: str, *, compress: bool = True, pickle: bool = False\n    ) -> DirectoryPath:\n        assert \"arbitrary_types_allowed\" not in self.model_config or (\n            self.model_config[\"arbitrary_types_allowed\"] and pickle\n        ), \"Arbitrary types are only supported in pickle mode\"\n\n        dump_directory_path = self.model_directory_path(output_directory, object_id)\n        dump_directory_path.mkdir(parents=True, exist_ok=True)\n\n        ndarray_field_to_array, other_field_to_value = self._dump_numpy_split_dict()\n\n        if ndarray_field_to_array:\n            (np.savez_compressed if compress else np.savez)(\n                dump_directory_path / self._dump_numpy_savez_file_name, **ndarray_field_to_array\n            )\n\n        if other_field_to_value:\n            if pickle:\n                if compress:\n                    compress_pickle.dump(\n                        other_field_to_value,\n                        dump_directory_path / self._dump_compressed_pickle_file_name,\n                        compression=self._dump_compression,\n                    )\n                else:\n                    with open(dump_directory_path / self._dump_pickle_file_name, \"wb\") as out_pickle:\n                        pickle_pkg.dump(other_field_to_value, out_pickle)\n\n            else:\n                with open(dump_directory_path / self._dump_non_array_yaml_name, \"w\") as out_yaml:\n                    yaml.dump(other_field_to_value, out_yaml)\n\n        return dump_directory_path\n\n    def _dump_numpy_split_dict(self) -> tuple[dict, dict]:\n        ndarray_field_to_array = {}\n        other_field_to_value = {}\n\n        for k, v in self.model_dump(exclude_unset=True).items():\n            if isinstance(v, np.ndarray):\n                ndarray_field_to_array[k] = v\n            else:\n                other_field_to_value[k] = v\n\n        return ndarray_field_to_array, other_field_to_value\n\n    @classmethod  # type: ignore[misc]\n    @computed_field(return_type=str)\n    @property\n    def _dump_compressed_pickle_file_name(cls) -> str:\n        return f\"{cls._dump_non_array_file_stem}.pickle.{cls._dump_compression}\"\n\n    @classmethod  # type: ignore[misc]\n    @computed_field(return_type=str)\n    @property\n    def _dump_pickle_file_name(cls) -> str:\n        return f\"{cls._dump_non_array_file_stem}.pickle\"\n\n    @classmethod  # type: ignore[misc]\n    @computed_field(return_type=str)\n    @property\n    def _dump_non_array_yaml_name(cls) -> str:\n        return f\"{cls._dump_non_array_file_stem}.yaml\"", "\n\ndef model_agnostic_load(\n    output_directory: DirectoryPath,\n    object_id: str,\n    models: Iterable[type[NumpyModel]],\n    not_found_error: bool = False,\n    **load_kwargs,\n) -> Optional[NumpyModel]:\n    \"\"\"\n    Provided an Iterable containing possible models, and the directory where they have been dumped. Load the first\n    instance of model that matches the provided object ID.\n\n    Parameters\n    ----------\n    output_directory: DirectoryPath\n        The root directory where all model instances of interest are stored\n    object_id: String\n        The ID of the model instance\n    models: Iterable[type[NumpyModel]]\n        All NumpyModel instances of interest, note that they should have differing names\n    not_found_error: bool\n        If True, throw error when the respective model instance was not found\n    load_kwargs\n        Key-word arguments to pass to the load function\n\n    Returns\n    -------\n    NumpyModel instance if found\n    \"\"\"\n    for model in models:\n        if model.model_directory_path(output_directory, object_id).exists():\n            return model.load(output_directory, object_id, **load_kwargs)\n\n    if not_found_error:\n        raise FileNotFoundError(\n            f\"Could not find NumpyModel with {object_id} in {output_directory}.\"\n            f\"Tried from following classes:\\n{', '.join(model.__name__ for model in models)}\"\n        )\n\n    return None", "\n\ndef _compare_np_array_dicts(\n    dict_a: dict[str, npt.NDArray], dict_b: dict[str, npt.NDArray], rtol: float = 1e-05, atol: float = 1e-08\n) -> bool:\n    \"\"\"\n    Compare two dictionaries containing numpy arrays as values.\n\n    Parameters:\n    dict_a, dict_b: dictionaries to compare. They should have same keys.\n    rtol, atol: relative and absolute tolerances for np.isclose()\n\n    Returns:\n    Boolean value for each key, True if corresponding arrays are close, else False.\n    \"\"\"\n\n    keys1 = frozenset(dict_a.keys())\n    keys2 = frozenset(dict_b.keys())\n\n    if keys1 != keys2:\n        raise ValueError(\"Dictionaries have different keys\")\n\n    for key in keys1:\n        arr_a = dict_a[key]\n        arr_b = dict_b[key]\n\n        if arr_a.shape != arr_b.shape:\n            raise ValueError(f\"Arrays for key '{key}' have different shapes\")\n\n        if not np_general_all_close(arr_a, arr_b, rtol, atol):\n            return False\n\n    return True", "\n\n__all__ = [\"NumpyModel\", \"model_agnostic_load\"]\n"]}
{"filename": "pydantic_numpy/model/multi_array.py", "chunked_list": ["from functools import lru_cache\n\nimport numpy as np\nimport numpy.typing as npt\nfrom pydantic import FilePath\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass(frozen=True)\nclass MultiArrayNumpyFile:\n    path: FilePath\n    key: str\n    cached_load: bool = False\n\n    def load(self) -> npt.NDArray:\n        \"\"\"\n        Load the NDArray stored in the given path within the given key\n\n        Returns\n        -------\n        NDArray\n        \"\"\"\n        loaded = _cached_np_array_load(self.path) if self.cached_load else np.load(self.path)\n        try:\n            return loaded[self.key]\n        except IndexError:\n            msg = f\"The given path points to an uncompressed numpy file, which only has one array in it: {self.path}\"\n            raise AttributeError(msg)", "@dataclass(frozen=True)\nclass MultiArrayNumpyFile:\n    path: FilePath\n    key: str\n    cached_load: bool = False\n\n    def load(self) -> npt.NDArray:\n        \"\"\"\n        Load the NDArray stored in the given path within the given key\n\n        Returns\n        -------\n        NDArray\n        \"\"\"\n        loaded = _cached_np_array_load(self.path) if self.cached_load else np.load(self.path)\n        try:\n            return loaded[self.key]\n        except IndexError:\n            msg = f\"The given path points to an uncompressed numpy file, which only has one array in it: {self.path}\"\n            raise AttributeError(msg)", "\n\n@lru_cache\ndef _cached_np_array_load(path: FilePath):\n    \"\"\"\n    Store the loaded numpy object within LRU cache in case we need it several times\n\n    Parameters\n    ----------\n    path: FilePath\n        Path to the numpy file\n\n    Returns\n    -------\n    Same as np.load\n    \"\"\"\n    return np.load(path)", "\n\n__all__ = [\"MultiArrayNumpyFile\"]\n"]}
{"filename": "pydantic_numpy/typing/ii_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNp2DArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=2, strict_data_typing=False)\n\nNp2DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=2)\nNp2DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=2)\nNp2DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=2)\nNp2DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=2)", "Np2DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=2)\nNp2DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=2)\n\nNp2DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=2)\nNp2DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=2)\nNp2DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=2)\nNp2DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=2)\n\nNp2DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=2)\nNp2DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=2)", "Np2DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=2)\nNp2DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=2)\nNp2DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=2)\nNp2DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=2)\n\nNp2DArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, dimensions=2)\nNp2DArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, dimensions=2)\nNp2DArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, dimensions=2)\n\nNp2DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=2)", "\nNp2DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=2)\n\n\n# Non-number types\nNp2DArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, dimensions=2)\nNp2DArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, dimensions=2)\n\n\n__all__ = [", "\n__all__ = [\n    \"Np2DArray\",\n    \"Np2DArrayInt64\",\n    \"Np2DArrayInt32\",\n    \"Np2DArrayInt16\",\n    \"Np2DArrayInt8\",\n    \"Np2DArrayUint64\",\n    \"Np2DArrayUint32\",\n    \"Np2DArrayUint16\",", "    \"Np2DArrayUint32\",\n    \"Np2DArrayUint16\",\n    \"Np2DArrayUint8\",\n    \"Np2DArrayFp128\",\n    \"Np2DArrayFp64\",\n    \"Np2DArrayFp32\",\n    \"Np2DArrayFp16\",\n    \"Np2DArrayComplex256\",\n    \"Np2DArrayComplex128\",\n    \"Np2DArrayComplex64\",", "    \"Np2DArrayComplex128\",\n    \"Np2DArrayComplex64\",\n    \"Np2DArrayBool\",\n    \"Np2DArrayDatetime64\",\n    \"Np2DArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/i_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNp1DArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=1, strict_data_typing=False)\n\nNp1DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=1)\nNp1DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=1)\nNp1DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=1)\nNp1DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=1)", "Np1DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=1)\nNp1DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=1)\n\nNp1DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=1)\nNp1DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=1)\nNp1DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=1)\nNp1DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=1)\n\nNp1DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=1)\nNp1DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=1)", "Np1DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=1)\nNp1DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=1)\nNp1DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=1)\nNp1DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=1)\n\nNp1DArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, dimensions=1)\nNp1DArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, dimensions=1)\nNp1DArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, dimensions=1)\n\nNp1DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=1)", "\nNp1DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=1)\n\n\n# Non-number types\nNp1DArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, dimensions=1)\nNp1DArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, dimensions=1)\n\n\n__all__ = [", "\n__all__ = [\n    \"Np1DArray\",\n    \"Np1DArrayInt64\",\n    \"Np1DArrayInt32\",\n    \"Np1DArrayInt16\",\n    \"Np1DArrayInt8\",\n    \"Np1DArrayUint64\",\n    \"Np1DArrayUint32\",\n    \"Np1DArrayUint16\",", "    \"Np1DArrayUint32\",\n    \"Np1DArrayUint16\",\n    \"Np1DArrayUint8\",\n    \"Np1DArrayFp128\",\n    \"Np1DArrayFp64\",\n    \"Np1DArrayFp32\",\n    \"Np1DArrayFp16\",\n    \"Np1DArrayComplex256\",\n    \"Np1DArrayComplex128\",\n    \"Np1DArrayComplex64\",", "    \"Np1DArrayComplex128\",\n    \"Np1DArrayComplex64\",\n    \"Np1DArrayBool\",\n    \"Np1DArrayDatetime64\",\n    \"Np1DArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/n_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNpNDArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=None, strict_data_typing=False)\n\nNpNDArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64)\nNpNDArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32)\nNpNDArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16)\nNpNDArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8)", "NpNDArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16)\nNpNDArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8)\n\nNpNDArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64)\nNpNDArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32)\nNpNDArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16)\nNpNDArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8)\n\nNpNDArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128)\nNpNDArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64)", "NpNDArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128)\nNpNDArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64)\nNpNDArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32)\nNpNDArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16)\n\nNpNDArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256)\nNpNDArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128)\nNpNDArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64)\n\nNpNDArrayBool = np_array_pydantic_annotated_typing(data_type=bool)", "\nNpNDArrayBool = np_array_pydantic_annotated_typing(data_type=bool)\n\n\n# Non-number types\nNpNDArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64)\nNpNDArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64)\n\n\n__all__ = [", "\n__all__ = [\n    \"NpNDArray\",\n    \"NpNDArrayInt64\",\n    \"NpNDArrayInt32\",\n    \"NpNDArrayInt16\",\n    \"NpNDArrayInt8\",\n    \"NpNDArrayUint64\",\n    \"NpNDArrayUint32\",\n    \"NpNDArrayUint16\",", "    \"NpNDArrayUint32\",\n    \"NpNDArrayUint16\",\n    \"NpNDArrayUint8\",\n    \"NpNDArrayFp128\",\n    \"NpNDArrayFp64\",\n    \"NpNDArrayFp32\",\n    \"NpNDArrayFp16\",\n    \"NpNDArrayComplex256\",\n    \"NpNDArrayComplex128\",\n    \"NpNDArrayComplex64\",", "    \"NpNDArrayComplex128\",\n    \"NpNDArrayComplex64\",\n    \"NpNDArrayBool\",\n    \"NpNDArrayDatetime64\",\n    \"NpNDArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/iii_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNp3DArray = np_array_pydantic_annotated_typing(data_type=None, dimensions=3, strict_data_typing=False)\n\nNp3DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=3)\nNp3DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=3)\nNp3DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=3)\nNp3DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=3)", "Np3DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=3)\nNp3DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=3)\n\nNp3DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=3)\nNp3DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=3)\nNp3DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=3)\nNp3DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=3)\n\nNp3DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=3)\nNp3DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=3)", "Np3DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=3)\nNp3DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=3)\nNp3DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=3)\nNp3DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=3)\n\nNp3DArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, dimensions=3)\nNp3DArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, dimensions=3)\nNp3DArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, dimensions=3)\n\nNp3DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=3)", "\nNp3DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=3)\n\n\n# Non-number types\nNp3DArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, dimensions=3)\nNp3DArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, dimensions=3)\n\n__all__ = [\n    \"Np3DArray\",", "__all__ = [\n    \"Np3DArray\",\n    \"Np3DArrayInt64\",\n    \"Np3DArrayInt32\",\n    \"Np3DArrayInt16\",\n    \"Np3DArrayInt8\",\n    \"Np3DArrayUint64\",\n    \"Np3DArrayUint32\",\n    \"Np3DArrayUint16\",\n    \"Np3DArrayUint8\",", "    \"Np3DArrayUint16\",\n    \"Np3DArrayUint8\",\n    \"Np3DArrayFp128\",\n    \"Np3DArrayFp64\",\n    \"Np3DArrayFp32\",\n    \"Np3DArrayFp16\",\n    \"Np3DArrayComplex256\",\n    \"Np3DArrayComplex128\",\n    \"Np3DArrayComplex64\",\n    \"Np3DArrayBool\",", "    \"Np3DArrayComplex64\",\n    \"Np3DArrayBool\",\n    \"Np3DArrayDatetime64\",\n    \"Np3DArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/__init__.py", "chunked_list": ["from pydantic_numpy.typing.i_dimensional import *\nfrom pydantic_numpy.typing.ii_dimensional import *\nfrom pydantic_numpy.typing.iii_dimensional import *\nfrom pydantic_numpy.typing.n_dimensional import *\nfrom pydantic_numpy.typing.strict_data_type.i_dimensional import *\nfrom pydantic_numpy.typing.strict_data_type.ii_dimensional import *\nfrom pydantic_numpy.typing.strict_data_type.iii_dimensional import *\nfrom pydantic_numpy.typing.strict_data_type.n_dimensional import *\n", ""]}
{"filename": "pydantic_numpy/typing/strict_data_type/ii_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNpStrict2DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=2, strict_data_typing=True)\n\nNpStrict2DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=2, strict_data_typing=True)", "\nNpStrict2DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=2, strict_data_typing=True)\n\nNpStrict2DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=2, strict_data_typing=True)", "NpStrict2DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=2, strict_data_typing=True)\nNpStrict2DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=2, strict_data_typing=True)\n\nNpStrict2DArrayComplex256 = np_array_pydantic_annotated_typing(\n    data_type=np.complex256, dimensions=2, strict_data_typing=True\n)\nNpStrict2DArrayComplex128 = np_array_pydantic_annotated_typing(\n    data_type=np.complex128, dimensions=2, strict_data_typing=True\n)\nNpStrict2DArrayComplex64 = np_array_pydantic_annotated_typing(", ")\nNpStrict2DArrayComplex64 = np_array_pydantic_annotated_typing(\n    data_type=np.complex64, dimensions=2, strict_data_typing=True\n)\n\nNpStrict2DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=2, strict_data_typing=True)\n\n\n# Non-number types\nNpStrict2DArrayDatetime64 = np_array_pydantic_annotated_typing(", "# Non-number types\nNpStrict2DArrayDatetime64 = np_array_pydantic_annotated_typing(\n    data_type=np.datetime64, dimensions=2, strict_data_typing=True\n)\nNpStrict2DArrayTimedelta64 = np_array_pydantic_annotated_typing(\n    data_type=np.timedelta64, dimensions=2, strict_data_typing=True\n)\n\n\n__all__ = [", "\n__all__ = [\n    \"NpStrict2DArrayInt64\",\n    \"NpStrict2DArrayInt32\",\n    \"NpStrict2DArrayInt16\",\n    \"NpStrict2DArrayInt8\",\n    \"NpStrict2DArrayUint64\",\n    \"NpStrict2DArrayUint32\",\n    \"NpStrict2DArrayUint16\",\n    \"NpStrict2DArrayUint8\",", "    \"NpStrict2DArrayUint16\",\n    \"NpStrict2DArrayUint8\",\n    \"NpStrict2DArrayFp128\",\n    \"NpStrict2DArrayFp64\",\n    \"NpStrict2DArrayFp32\",\n    \"NpStrict2DArrayFp16\",\n    \"NpStrict2DArrayComplex256\",\n    \"NpStrict2DArrayComplex128\",\n    \"NpStrict2DArrayComplex64\",\n    \"NpStrict2DArrayBool\",", "    \"NpStrict2DArrayComplex64\",\n    \"NpStrict2DArrayBool\",\n    \"NpStrict2DArrayDatetime64\",\n    \"NpStrict2DArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/i_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNpStrict1DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=1, strict_data_typing=True)\n\nNpStrict1DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=1, strict_data_typing=True)", "\nNpStrict1DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=1, strict_data_typing=True)\n\nNpStrict1DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=1, strict_data_typing=True)", "NpStrict1DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=1, strict_data_typing=True)\nNpStrict1DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=1, strict_data_typing=True)\n\nNpStrict1DArrayComplex256 = np_array_pydantic_annotated_typing(\n    data_type=np.complex256, dimensions=1, strict_data_typing=True\n)\nNpStrict1DArrayComplex128 = np_array_pydantic_annotated_typing(\n    data_type=np.complex128, dimensions=1, strict_data_typing=True\n)\nNpStrict1DArrayComplex64 = np_array_pydantic_annotated_typing(", ")\nNpStrict1DArrayComplex64 = np_array_pydantic_annotated_typing(\n    data_type=np.complex64, dimensions=1, strict_data_typing=True\n)\n\nNpStrict1DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=1, strict_data_typing=True)\n\n\n# Non-number types\nNpStrict1DArrayDatetime64 = np_array_pydantic_annotated_typing(", "# Non-number types\nNpStrict1DArrayDatetime64 = np_array_pydantic_annotated_typing(\n    data_type=np.datetime64, dimensions=1, strict_data_typing=True\n)\nNpStrict1DArrayTimedelta64 = np_array_pydantic_annotated_typing(\n    data_type=np.timedelta64, dimensions=1, strict_data_typing=True\n)\n\n\n__all__ = [", "\n__all__ = [\n    \"NpStrict1DArrayInt64\",\n    \"NpStrict1DArrayInt32\",\n    \"NpStrict1DArrayInt16\",\n    \"NpStrict1DArrayInt8\",\n    \"NpStrict1DArrayUint64\",\n    \"NpStrict1DArrayUint32\",\n    \"NpStrict1DArrayUint16\",\n    \"NpStrict1DArrayUint8\",", "    \"NpStrict1DArrayUint16\",\n    \"NpStrict1DArrayUint8\",\n    \"NpStrict1DArrayFp128\",\n    \"NpStrict1DArrayFp64\",\n    \"NpStrict1DArrayFp32\",\n    \"NpStrict1DArrayFp16\",\n    \"NpStrict1DArrayComplex256\",\n    \"NpStrict1DArrayComplex128\",\n    \"NpStrict1DArrayComplex64\",\n    \"NpStrict1DArrayBool\",", "    \"NpStrict1DArrayComplex64\",\n    \"NpStrict1DArrayBool\",\n    \"NpStrict1DArrayDatetime64\",\n    \"NpStrict1DArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/n_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNpStrictNDArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, strict_data_typing=True)\nNpStrictNDArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, strict_data_typing=True)\nNpStrictNDArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, strict_data_typing=True)\nNpStrictNDArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, strict_data_typing=True)\n\nNpStrictNDArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, strict_data_typing=True)", "\nNpStrictNDArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, strict_data_typing=True)\nNpStrictNDArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, strict_data_typing=True)\nNpStrictNDArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, strict_data_typing=True)\nNpStrictNDArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, strict_data_typing=True)\n\nNpStrictNDArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, strict_data_typing=True)\nNpStrictNDArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, strict_data_typing=True)\nNpStrictNDArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, strict_data_typing=True)\nNpStrictNDArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, strict_data_typing=True)", "NpStrictNDArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, strict_data_typing=True)\nNpStrictNDArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, strict_data_typing=True)\n\nNpStrictNDArrayComplex256 = np_array_pydantic_annotated_typing(data_type=np.complex256, strict_data_typing=True)\nNpStrictNDArrayComplex128 = np_array_pydantic_annotated_typing(data_type=np.complex128, strict_data_typing=True)\nNpStrictNDArrayComplex64 = np_array_pydantic_annotated_typing(data_type=np.complex64, strict_data_typing=True)\n\nNpStrictNDArrayBool = np_array_pydantic_annotated_typing(data_type=bool, strict_data_typing=True)\n\n", "\n\n# Non-number types\nNpStrictNDArrayDatetime64 = np_array_pydantic_annotated_typing(data_type=np.datetime64, strict_data_typing=True)\nNpStrictNDArrayTimedelta64 = np_array_pydantic_annotated_typing(data_type=np.timedelta64, strict_data_typing=True)\n\n\n__all__ = [\n    \"NpStrictNDArrayInt64\",\n    \"NpStrictNDArrayInt32\",", "    \"NpStrictNDArrayInt64\",\n    \"NpStrictNDArrayInt32\",\n    \"NpStrictNDArrayInt16\",\n    \"NpStrictNDArrayInt8\",\n    \"NpStrictNDArrayUint64\",\n    \"NpStrictNDArrayUint32\",\n    \"NpStrictNDArrayUint16\",\n    \"NpStrictNDArrayUint8\",\n    \"NpStrictNDArrayFp128\",\n    \"NpStrictNDArrayFp64\",", "    \"NpStrictNDArrayFp128\",\n    \"NpStrictNDArrayFp64\",\n    \"NpStrictNDArrayFp32\",\n    \"NpStrictNDArrayFp16\",\n    \"NpStrictNDArrayComplex256\",\n    \"NpStrictNDArrayComplex128\",\n    \"NpStrictNDArrayComplex64\",\n    \"NpStrictNDArrayBool\",\n    \"NpStrictNDArrayDatetime64\",\n    \"NpStrictNDArrayTimedelta64\",", "    \"NpStrictNDArrayDatetime64\",\n    \"NpStrictNDArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/iii_dimensional.py", "chunked_list": ["import numpy as np\n\nfrom pydantic_numpy.helper.annotation import np_array_pydantic_annotated_typing\n\nNpStrict3DArrayInt64 = np_array_pydantic_annotated_typing(data_type=np.int64, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayInt32 = np_array_pydantic_annotated_typing(data_type=np.int32, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayInt16 = np_array_pydantic_annotated_typing(data_type=np.int16, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayInt8 = np_array_pydantic_annotated_typing(data_type=np.int8, dimensions=3, strict_data_typing=True)\n\nNpStrict3DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=3, strict_data_typing=True)", "\nNpStrict3DArrayUint64 = np_array_pydantic_annotated_typing(data_type=np.uint64, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayUint32 = np_array_pydantic_annotated_typing(data_type=np.uint32, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayUint16 = np_array_pydantic_annotated_typing(data_type=np.uint16, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayUint8 = np_array_pydantic_annotated_typing(data_type=np.uint8, dimensions=3, strict_data_typing=True)\n\nNpStrict3DArrayFp128 = np_array_pydantic_annotated_typing(data_type=np.float128, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayFp64 = np_array_pydantic_annotated_typing(data_type=np.float64, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=3, strict_data_typing=True)", "NpStrict3DArrayFp32 = np_array_pydantic_annotated_typing(data_type=np.float32, dimensions=3, strict_data_typing=True)\nNpStrict3DArrayFp16 = np_array_pydantic_annotated_typing(data_type=np.float16, dimensions=3, strict_data_typing=True)\n\nNpStrict3DArrayComplex256 = np_array_pydantic_annotated_typing(\n    data_type=np.complex256, dimensions=3, strict_data_typing=True\n)\nNpStrict3DArrayComplex128 = np_array_pydantic_annotated_typing(\n    data_type=np.complex128, dimensions=3, strict_data_typing=True\n)\nNpStrict3DArrayComplex64 = np_array_pydantic_annotated_typing(", ")\nNpStrict3DArrayComplex64 = np_array_pydantic_annotated_typing(\n    data_type=np.complex64, dimensions=3, strict_data_typing=True\n)\n\nNpStrict3DArrayBool = np_array_pydantic_annotated_typing(data_type=bool, dimensions=3, strict_data_typing=True)\n\n\n# Non-number types\nNpStrict3DArrayDatetime64 = np_array_pydantic_annotated_typing(", "# Non-number types\nNpStrict3DArrayDatetime64 = np_array_pydantic_annotated_typing(\n    data_type=np.datetime64, dimensions=3, strict_data_typing=True\n)\nNpStrict3DArrayTimedelta64 = np_array_pydantic_annotated_typing(\n    data_type=np.timedelta64, dimensions=3, strict_data_typing=True\n)\n\n__all__ = [\n    \"NpStrict3DArrayInt64\",", "__all__ = [\n    \"NpStrict3DArrayInt64\",\n    \"NpStrict3DArrayInt32\",\n    \"NpStrict3DArrayInt16\",\n    \"NpStrict3DArrayInt8\",\n    \"NpStrict3DArrayUint64\",\n    \"NpStrict3DArrayUint32\",\n    \"NpStrict3DArrayUint16\",\n    \"NpStrict3DArrayUint8\",\n    \"NpStrict3DArrayFp128\",", "    \"NpStrict3DArrayUint8\",\n    \"NpStrict3DArrayFp128\",\n    \"NpStrict3DArrayFp64\",\n    \"NpStrict3DArrayFp32\",\n    \"NpStrict3DArrayFp16\",\n    \"NpStrict3DArrayComplex256\",\n    \"NpStrict3DArrayComplex128\",\n    \"NpStrict3DArrayComplex64\",\n    \"NpStrict3DArrayBool\",\n    \"NpStrict3DArrayDatetime64\",", "    \"NpStrict3DArrayBool\",\n    \"NpStrict3DArrayDatetime64\",\n    \"NpStrict3DArrayTimedelta64\",\n]\n"]}
{"filename": "pydantic_numpy/typing/strict_data_type/__init__.py", "chunked_list": [""]}
{"filename": "pydantic_numpy/helper/annotation.py", "chunked_list": ["from collections.abc import Sequence\nfrom pathlib import Path\nfrom typing import Any, Callable, ClassVar, Optional, Union\n\nimport numpy as np\nfrom numpy.typing import DTypeLike\nfrom pydantic import FilePath, GetJsonSchemaHandler, PositiveInt\nfrom pydantic.json_schema import JsonSchemaValue\nfrom pydantic_core import core_schema\nfrom typing_extensions import Annotated", "from pydantic_core import core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic_numpy.helper.validation import (\n    create_array_validator,\n    validate_multi_array_numpy_file,\n    validate_numpy_array_file,\n)\nfrom pydantic_numpy.model.multi_array import MultiArrayNumpyFile\n", "from pydantic_numpy.model.multi_array import MultiArrayNumpyFile\n\n\nclass NpArrayPydanticAnnotation:\n    dimensions: ClassVar[Optional[PositiveInt]]\n\n    data_type: ClassVar[DTypeLike]\n    strict_data_typing: ClassVar[bool]\n\n    @classmethod\n    def factory(\n        cls, *, data_type: DTypeLike, dimensions: Optional[int] = None, strict_data_typing: bool = False\n    ) -> type:\n        \"\"\"\n        Create an instance NpArrayPydanticAnnotation that is configured for a specific dimension and dtype.\n\n        The signature of the function is data_type, dimension and not dimension, data_type to reduce amount of\n        code for all the types.\n\n        Parameters\n        ----------\n        data_type: DTypeLike\n        dimensions: Optional[int]\n            Number of dimensions determine the depth of the numpy array.\n        strict_data_typing: bool\n            If True, the dtype of the numpy array must be identical to the data_type. No conversion attempts.\n\n        Returns\n        -------\n        NpArrayPydanticAnnotation\n        \"\"\"\n        if strict_data_typing and not data_type:\n            msg = \"Strict data typing requires data_type (DTypeLike) definition\"\n            raise ValueError(msg)\n\n        return type(\n            (\n                f\"Np{'Strict' if strict_data_typing else ''}{dimensions or 'N'}DArray\"\n                f\"{data_type.__name__.capitalize() if data_type else ''}PydanticAnnotation\"\n            ),\n            (cls,),\n            {\"dimensions\": dimensions, \"data_type\": data_type, \"strict_data_typing\": strict_data_typing},\n        )\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls,\n        _source_type: Any,\n        _handler: Callable[[Any], core_schema.CoreSchema],\n    ) -> core_schema.CoreSchema:\n        np_array_validator = create_array_validator(cls.dimensions, cls.data_type, cls.strict_data_typing)\n        np_array_schema = core_schema.no_info_plain_validator_function(np_array_validator)\n\n        return core_schema.json_or_python_schema(\n            python_schema=core_schema.chain_schema([_common_numpy_array_validator, np_array_schema]),\n            json_schema=np_array_schema,\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                lambda arr: np.array2string(arr), when_used=\"json\"\n            ),\n        )\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, _core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n    ) -> JsonSchemaValue:\n        return handler(\n            dict(\n                type=(\n                    f\"np.ndarray[{_int_to_dim_type[cls.dimensions] if cls.dimensions else 'Any'}, \"\n                    f\"{np.dtype[cls.data_type.__name__] if _data_type_resolver(cls.data_type) else cls.data_type}]\"  # type: ignore[name-defined]\n                ),\n                strict_data_typing=cls.strict_data_typing,\n            )\n        )", "\n\ndef np_array_pydantic_annotated_typing(\n    data_type: DTypeLike = None, dimensions: Optional[int] = None, strict_data_typing: bool = False\n):\n    \"\"\"\n    Generates typing and pydantic annotation of a np.ndarray parametrized with given constraints\n\n    Parameters\n    ----------\n    data_type: DTypeLike\n    dimensions: Optional[int]\n        Number of dimensions determine the depth of the numpy array.\n    strict_data_typing: bool\n        If True, the dtype of the numpy array must be identical to the data_type. No conversion attempts.\n\n    Returns\n    -------\n    type-hint for np.ndarray with Pydantic support\n    \"\"\"\n    return Annotated[\n        Union[\n            FilePath,\n            MultiArrayNumpyFile,\n            np.ndarray[  # type: ignore[misc]\n                _int_to_dim_type[dimensions] if dimensions else Any,\n                np.dtype[data_type] if _data_type_resolver(data_type) else data_type,\n            ],\n        ],\n        NpArrayPydanticAnnotation.factory(\n            data_type=data_type, dimensions=dimensions, strict_data_typing=strict_data_typing\n        ),\n    ]", "\n\ndef _data_type_resolver(data_type: DTypeLike):\n    return data_type is not None and issubclass(data_type, np.generic)\n\n\n_int_to_dim_type = {1: tuple[int], 2: tuple[int, int], 3: tuple[int, int, int]}\n_common_numpy_array_validator = core_schema.union_schema(\n    [\n        core_schema.chain_schema(", "    [\n        core_schema.chain_schema(\n            [\n                core_schema.is_instance_schema(Path),\n                core_schema.no_info_plain_validator_function(validate_numpy_array_file),\n            ]\n        ),\n        core_schema.chain_schema(\n            [\n                core_schema.is_instance_schema(MultiArrayNumpyFile),", "            [\n                core_schema.is_instance_schema(MultiArrayNumpyFile),\n                core_schema.no_info_plain_validator_function(validate_multi_array_numpy_file),\n            ]\n        ),\n        core_schema.is_instance_schema(np.ndarray),\n        core_schema.chain_schema(\n            [\n                core_schema.is_instance_schema(Sequence),\n                core_schema.no_info_plain_validator_function(lambda v: np.asarray(v)),", "                core_schema.is_instance_schema(Sequence),\n                core_schema.no_info_plain_validator_function(lambda v: np.asarray(v)),\n            ]\n        ),\n    ]\n)\n"]}
{"filename": "pydantic_numpy/helper/__init__.py", "chunked_list": [""]}
{"filename": "pydantic_numpy/helper/validation.py", "chunked_list": ["from typing import Callable, Optional\n\nimport numpy as np\nimport numpy.typing as npt\nfrom numpy import floating, integer\nfrom numpy.lib.npyio import NpzFile\nfrom pydantic import FilePath\n\nfrom pydantic_numpy.model.multi_array import MultiArrayNumpyFile\n", "from pydantic_numpy.model.multi_array import MultiArrayNumpyFile\n\n\nclass PydanticNumpyMultiArrayNumpyFileOnFilePath(Exception):\n    pass\n\n\ndef create_array_validator(\n    dimensions: Optional[int], target_data_type: npt.DTypeLike, strict_data_typing: bool\n) -> Callable[[npt.NDArray], npt.NDArray]:\n    \"\"\"\n    Creates a validator that ensures the numpy array has the defined dimensions and dtype (data_type).\n\n    Parameters\n    ----------\n    dimensions: int | None\n        Default to None; if set to an integer, enforce the dimension of the numpy array to that integer\n    target_data_type: DTypeLike\n        The data type the array must have after validation, arrays with different data types will be converted\n        during validation. Float to integer is rounded (np.round) followed by an astype with target data type.\n    strict_data_typing: bool\n        Default False; if True, the incoming array must its dtype match the target_data_type. Strict mode.\n\n    Returns\n    -------\n    Callable[[npt.NDArray], npt.NDArray]\n    Validator for numpy array\n    \"\"\"\n\n    def array_validator(array: npt.NDArray) -> npt.NDArray:\n        if dimensions and (array_dimensions := len(array.shape)) != dimensions:\n            msg = f\"Array {array_dimensions}-dimensional; the target dimensions is {dimensions}\"\n            raise ValueError(msg)\n\n        if target_data_type and array.dtype.type != target_data_type:\n            if strict_data_typing:\n                msg = f\"The data_type {array.dtype.type} does not coincide with type hint; {target_data_type}\"\n                raise ValueError(msg)\n\n            if issubclass(_resolve_type_of_array_dtype(target_data_type), integer) and issubclass(\n                _resolve_type_of_array_dtype(array.dtype), floating\n            ):\n                array = np.round(array).astype(target_data_type, copy=False)\n            else:\n                array = array.astype(target_data_type, copy=True)\n\n        return array\n\n    return array_validator", "\n\ndef validate_numpy_array_file(v: FilePath) -> npt.NDArray:\n    \"\"\"\n    Validate file path to numpy file by loading and return the respective numpy array\n\n    Parameters\n    ----------\n    v: FilePath\n        Path to the numpy file\n\n    Returns\n    -------\n    NDArray\n    \"\"\"\n    result = np.load(v)\n\n    if isinstance(result, NpzFile):\n        files = result.files\n        if len(files) > 1:\n            msg = (\n                f\"The provided file path is a multi array NpzFile, which is not supported; \"\n                f\"convert to single array NpzFiles.\\n\"\n                f\"Path to multi array file: {result}\\n\"\n                f\"Array keys: {', '.join(result.files)}\\n\"\n                f\"Use pydantic_numpy.{MultiArrayNumpyFile.__class__.__name__} instead of a PathLike alone\"\n            )\n            raise PydanticNumpyMultiArrayNumpyFileOnFilePath(msg)\n        result = result[files[0]]\n\n    return result", "\n\ndef validate_multi_array_numpy_file(v: MultiArrayNumpyFile) -> npt.NDArray:\n    \"\"\"\n    Validation function for loading numpy array from a name mapping numpy file\n\n    Parameters\n    ----------\n    v: MultiArrayNumpyFile\n        MultiArrayNumpyFile to load\n\n    Returns\n    -------\n    NDArray from MultiArrayNumpyFile\n    \"\"\"\n    return v.load()", "\n\ndef _resolve_type_of_array_dtype(array_dtype: npt.DTypeLike) -> type:\n    \"\"\"\n    np.dtype have the type stored in the type attribute, function to extract that type.\n    If the DTypelike isn't np.dtype we just return what is already a type.\n\n    Parameters\n    ----------\n    array_dtype: DTypeLike\n\n    Returns\n    -------\n    type\n    \"\"\"\n    if hasattr(array_dtype, \"type\"):\n        return array_dtype.type\n    else:\n        return array_dtype", ""]}
