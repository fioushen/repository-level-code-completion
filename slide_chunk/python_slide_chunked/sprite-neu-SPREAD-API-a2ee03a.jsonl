{"filename": "print_dataset.py", "chunked_list": ["\"\"\"\nPrint various information about the dataset and its recordings\n\"\"\"\nimport argparse\nimport os\n\nfrom core import *\n\nimport logging\n", "import logging\n\nformatter = logging.Formatter('%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlogging.basicConfig(level=logging.DEBUG,\n                    format='%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlog = logging.getLogger('spread')\nlog.setLevel(logging.INFO)\n\n\ndef process_info(dataset, recordings_list, filters, table_of_contents=False, no_show=False, recount_pictures=False):\n    \"\"\"\n    Process the dataset and print information\n    @param dataset: Root directory of the dataset\n    @param recordings_list: List of recordings to print (eg: [rec_23 rec_52 syn_104 noi_2])\n    @param filters: List of space separated filters for recordings (eg: [class=wifi channel=13])\n    @param table_of_contents: Boolean, print out the table of contents and save it to files\n    @param no_show: Boolean, only save the contents; don't print them\n    @param recount_pictures: Recount pictures for all recordings\n    @return: None\n    \"\"\"\n\n    # Initialize dataset\n    ds = Dataset(dataset, recount_pictures=recount_pictures)\n\n    if table_of_contents:\n        if not no_show:\n            log.info(\"\\n\\nTable of Contents\\n\\n%s\", ds.cont_table.get_table_str())\n        ds.cont_table.save_to_csv()\n        ds.cont_table.save_to_json()\n        ds.cont_table.save_reclist_to_json()\n        log.info(\"Dataset information are stored in global metadata: %s\", ds.metadata_dir)\n\n    # Print info about a list of recordings\n    if recordings_list:\n        for rec in recordings_list:\n            rec = Dataset.get_rec_name(rec)\n\n            try:\n                ds.recordings_dict[rec].print_info()\n            except KeyError:\n                log.error(\"Recording %s not found\", rec)\n\n    # Print info about filtered recordings based on given properties\n    if filters:\n        filtered = ds.filter_recordings(filters)\n        for rec in filtered:\n            rec.print_info()\n        log.info(\"List of filtered recordings: %s\", ' '.join([x.name for x in filtered]))", "\ndef process_info(dataset, recordings_list, filters, table_of_contents=False, no_show=False, recount_pictures=False):\n    \"\"\"\n    Process the dataset and print information\n    @param dataset: Root directory of the dataset\n    @param recordings_list: List of recordings to print (eg: [rec_23 rec_52 syn_104 noi_2])\n    @param filters: List of space separated filters for recordings (eg: [class=wifi channel=13])\n    @param table_of_contents: Boolean, print out the table of contents and save it to files\n    @param no_show: Boolean, only save the contents; don't print them\n    @param recount_pictures: Recount pictures for all recordings\n    @return: None\n    \"\"\"\n\n    # Initialize dataset\n    ds = Dataset(dataset, recount_pictures=recount_pictures)\n\n    if table_of_contents:\n        if not no_show:\n            log.info(\"\\n\\nTable of Contents\\n\\n%s\", ds.cont_table.get_table_str())\n        ds.cont_table.save_to_csv()\n        ds.cont_table.save_to_json()\n        ds.cont_table.save_reclist_to_json()\n        log.info(\"Dataset information are stored in global metadata: %s\", ds.metadata_dir)\n\n    # Print info about a list of recordings\n    if recordings_list:\n        for rec in recordings_list:\n            rec = Dataset.get_rec_name(rec)\n\n            try:\n                ds.recordings_dict[rec].print_info()\n            except KeyError:\n                log.error(\"Recording %s not found\", rec)\n\n    # Print info about filtered recordings based on given properties\n    if filters:\n        filtered = ds.filter_recordings(filters)\n        for rec in filtered:\n            rec.print_info()\n        log.info(\"List of filtered recordings: %s\", ' '.join([x.name for x in filtered]))", "\n\ndef main():\n    \"\"\"\n    Parse arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Print information about the dataset or specific recordings\")\n    parser.add_argument(\"--dataset\", required=True,\n                        help=\"Root directory of the dataset.\")\n    parser.add_argument(\"--recordings\", nargs=\"*\",\n                        help=\"List of recordings to print info for.\")\n    parser.add_argument(\"--show\", nargs=\"*\",\n                        help=\"Print recordings that satisfy some criteria (eg --show classes=wifi channel=3)\")\n    parser.add_argument(\"--contents\", action='store_true',\n                        help=\"Print out a table of contents for the dataset\")\n    parser.add_argument(\"--no-show\", action='store_true',\n                        help=\"Don't print contents, only save in in the dataset_root_dir/metadata\")\n    parser.add_argument(\"--recount-pictures\", action='store_true',\n                        help=\"Count the pictures for every recording during loading to refresh the recording and \"\n                             \"dataset metadata. Results in slower initialization of the dataset.\")\n    args = parser.parse_args()\n\n    process_info(args.dataset, args.recordings, args.show, args.contents, args.no_show, args.recount_pictures)", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "generate_compressed_data.py", "chunked_list": ["\"\"\"This tool generates compressed pictures and compresses existing annotations of recordings\"\"\"\nimport argparse\nimport logging\n\nfrom core import *\n\nformatter = logging.Formatter('%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlogging.basicConfig(level=logging.DEBUG,\n                    format='%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlog = logging.getLogger('spread')", "                    format='%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlog = logging.getLogger('spread')\nlog.setLevel(logging.INFO)\n\n\ndef gen_compressed_data(dataset, recordings, pictures_only, annotations_only, compr_avg, compr_proc):\n    \"\"\"Compress recording pictures\"\"\"\n\n    # Initialize dataset\n    ds = Dataset(dataset)\n\n    # Print info about a list of recordings\n\n    if recordings:\n        recordings = [ds.recordings_dict.get(rec, None) for rec in recordings]\n    else:\n        recordings = [x for x in ds.recordings if not x.compressed_pic_list or len(x.compressed_pic_list) < 152]\n\n    mode = \"compressed\"\n    for rec in recordings:\n        if not annotations_only:\n            log.info(\"Compressing pictures for recording %s\", rec.name)\n            rec.generate_pictures(mode=mode, navg=compr_avg, nproc=compr_proc)\n        if not pictures_only:\n            log.info(\"Compressing annotations for recording %s\", rec.name)\n            rec.compress_annotations(compr_avg * compr_proc)", "\n\ndef main():\n    \"\"\"Parse args\"\"\"\n    parser = argparse.ArgumentParser(description=\"Generate compressed pictures and annotations\")\n    parser.add_argument(\"--dataset\", required=True,\n                        help=\"Root directory of the dataset.\")\n    parser.add_argument(\"--recordings\", nargs=\"*\",\n                        help=\"List of recordings to print info for.\")\n    parser.add_argument(\"--compr-avg\", type=int, default=3,\n                        help=\"Total compression factor is: `compr-avg * compr-proc`.\")\n    parser.add_argument(\"--compr-proc\", type=int, default=4,\n                        help=\"Total compression factor is: `compr-avg * compr-proc`.\")\n    parser.add_argument(\"--pictures-only\", action='store_true',\n                        help='Only generate compressed pictures.')\n    parser.add_argument(\"--annotations-only\", action='store_true',\n                        help='Only generate compressed annotations.')\n    args = parser.parse_args()\n\n    gen_compressed_data(args.dataset, args.recordings, args.pictures_only, args.annotations_only, args.compr_avg,\n                        args.compr_proc)", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "create_synthetic.py", "chunked_list": ["\"\"\"\nCreate synthetic transmissions to augment the dataset for initial training.\n\nBased on pre-made molds for all classes, the user can create a small dataset of artificial data with the\nclasses of their choice.\n\nWorkflow:\n==============================================================\n             DATA AUGMENTATION ON PER-PACKET BASIS\n   PROCESSING FLOW:", "             DATA AUGMENTATION ON PER-PACKET BASIS\n   PROCESSING FLOW:\n\n   MANUAL EXTRACT SAMPLES/MOLDS ==>  ADJUST SNR ==> ADJUST LENGTH\n                                                          |\n                                                          V\n                      VERTICAL PADDING <== HORIZONTAL PADDING\n==============================================================\n\"\"\"\n", "\"\"\"\n\nfrom __future__ import division\nfrom PIL import Image\nimport numpy as np\nfrom random import randint, choice\n\nimport argparse\nimport os\nimport datetime", "import os\nimport datetime\n\nfrom core import data_clip\nfrom core import img_flip\nfrom core import stack_image_channels\nfrom core import check_collision\nfrom core import img_scale\nfrom core import constants\nfrom core import Frame", "from core import constants\nfrom core import Frame\nfrom core import Packet\n\n\ndef gen_synthetic_single_emission(category, savepath, snr_range=None, nfft=512, nlines=512,\n                                  length_range=(62, 512), length_step=15, full_length_ratio=10):\n    \"\"\" Generate data for single class \"\"\"\n    if snr_range is None:\n        snr_range = [-10, 0, 10]\n\n    # Sanitizing save path\n    if not os.path.isdir(savepath):\n        os.makedirs(savepath)\n\n    # Report file\n    reportfile = os.path.dirname(savepath) + '/report_' + str(datetime.datetime.now().date()) + '.txt'\n    f_report = open(reportfile, 'a+')\n    f_report.write('Report for category ' + constants.CATEGORIES[category][\"main\"] + '\\n\\n')\n\n    # Load background mold\n    background_mold = dict()\n    for background in constants.CATEGORIES[-1]['element']:\n        background_mold[background] = np.load(constants.MOLD_PATHS[background])\n\n    print(\"===> Generating data for \" +str(constants.CATEGORIES[category][\"main\"]))\n    count = 0\n\n    for obj_key in constants.CATEGORIES[category][\"element\"]:\n        print(\"==>[ Processing object \"+str(obj_key)+\" ]\")\n\n        # Load main object mold\n        object_mold = np.load(constants.MOLD_PATHS[obj_key])\n\n        # Change the background\n        for background in background_mold:\n            print(\">! Change frame background to \"+str(background)+\" for \"+str(obj_key))\n\n            # Change the SNR variation\n            for snr in snr_range:\n                if obj_key == 'bt_1' and snr == snr_range[0]:\n                    continue\n\n                if obj_key == 'bt_2' and snr != snr_range[1]:\n                    continue\n\n                print(\">! Apply SNR variation of \"+str(snr))\n\n                # Writing counts to the report...\n                f_report.write('Start count for category ' + constants.CATEGORIES[category][\n                    'main'] + ' object ' + obj_key + ' with snr change ' + str(snr) + ':' + str(count) + '\\n')\n\n                # Start adjusting\n                if constants.VAR[obj_key]:  # Length can be adjusted\n                    for length in range(length_range[0], length_range[1] + 1, length_step):\n                        # Only do replication for full-length packets\n                        replicate = full_length_ratio\n                        if length != length_range[1]:\n                            replicate = 1\n\n                        while replicate > 0:\n                            print(\"! Change object length to \"+str(length))\n\n                            # Get the lower and upper bounds of objects in the frame \n                            x_start_point = constants.AUGMENT_CHANNELS[category]['start']\n                            y_start_point = 0\n\n                            x_end_point = constants.LIMIT_INDEX\n                            y_end_point = 512\n\n                            for i in range(x_start_point, x_end_point - object_mold.shape[1],\n                                           constants.AUGMENT_CHANNELS[category]['space'] *\n                                           constants.AUGMENT_CHANNELS[category][\n                                               'skip']):  # Avoid similar samples by frequency skipping\n\n                                # Vertical padding\n                                j = y_start_point\n                                while j + length <= y_end_point:  # Avoid similar samples by random time skipping\n                                    left_offset = i\n                                    top_offset = j\n\n                                    # Adjust main object\n                                    c_object = Packet(object_mold, category, constants.VAR[obj_key])\n                                    c_object.adjust_length(length)\n                                    c_object.adjust_snr(snr)\n\n                                    # Create and adjust frame\n                                    pathname = savepath + \"/\" + constants.CATEGORIES[category]['main'] + \"_\" + str(\n                                        count) + \".jpg\"\n                                    frame = Frame(pathname, background_mold[background], nfft, nlines)\n                                    current_box = frame.add_packet(c_object, left_offset, top_offset)\n\n                                    # Save image\n                                    data_clip(frame.frame_data, constants.VMIN, constants.VMAX)\n                                    image_data = img_scale(frame.frame_data, constants.VMIN, constants.VMAX)\n                                    image_data = img_flip(stack_image_channels(image_data), ax=0)\n                                    image = Image.fromarray(image_data)\n                                    image.save(pathname)\n                                    count += 1\n\n                                    # Time skipping\n                                    j += np.random.randint(10, 30, 1)[0]\n\n                            # Make sure to decrement the replication\n                            replicate -= 1\n\n                else:  # Length is fixed\n                    print(\"! Length is fixed...\")\n\n                    # Get the lower and upper bounds of objects in the frame \n                    x_start_point = constants.AUGMENT_CHANNELS[category]['start']\n                    y_start_point = 0\n\n                    x_end_point = constants.LIMIT_INDEX\n                    y_end_point = 512\n\n                    for i in range(x_start_point, x_end_point - object_mold.shape[1],\n                                   constants.AUGMENT_CHANNELS[category]['space'] * constants.AUGMENT_CHANNELS[category][\n                                       'skip']):  # Avoid similar samples by frequency skipping\n\n                        # Vertical padding\n                        j = y_start_point\n                        while j + object_mold.shape[0] < y_end_point:  # Avoid similar samples by random time skipping\n                            left_offset = i\n                            top_offset = j\n\n                            # Adjust main object\n                            c_object = Packet(object_mold, category, constants.VAR[obj_key])\n                            c_object.adjust_snr(snr)\n\n                            # Create and adjust frame\n                            pathname = savepath + \"/\" + constants.CATEGORIES[category]['main'] + \"_\" + str(\n                                count) + \".jpg\"\n                            frame = Frame(pathname, background_mold[background], nfft, nlines)\n                            current_box = frame.add_packet(c_object, left_offset, top_offset)\n\n                            # Save image\n                            data_clip(frame.frame_data, constants.VMIN, constants.VMAX)\n                            image_data = img_scale(frame.frame_data, constants.VMIN, constants.VMAX)\n                            image_data = img_flip(stack_image_channels(image_data), ax=0)\n                            image = Image.fromarray(image_data, 'RGB')\n                            image.save(pathname)\n                            count += 1\n\n                            # Time skipping\n                            j += np.random.randint(10, 30, 1)[0]\n\n                # Writing counts for the report...\n                f_report.write('Finish count for category ' + constants.CATEGORIES[category][\n                    'main'] + ' object ' + obj_key + ' with snr change ' + str(snr) + ':' + str(count) + '\\n')\n                f_report.write('==================================================\\n')\n\n    f_report.close()\n    print(\"> Done processing \"+str(constants.CATEGORIES[category]['main'])+\". \"+str(count)+\" elements generated\")\n    print(\"Images saved in: \"+savepath)\n    print(\"Processing report: \"+reportfile)\n    return savepath", "\n\ndef gen_synthetic_colliding_emission(categories, savepath, snr_range=None, nfft=512, nlines=512, num_coll_iter=500,\n                                     length_range=(62, 512), length_step=15, full_length_ratio=10):\n    \"\"\" Generate collisions for 2 classes \"\"\"\n\n    if snr_range is None:\n        snr_range = [-10, 0, 10]\n\n    # Parsing the classes\n    cat1, cat2 = categories\n\n    # Sanitizing save path\n    if not os.path.isdir(savepath):\n        os.makedirs(savepath)\n\n    # Report file\n    reportfile = os.path.dirname(savepath) + '/report_' + str(datetime.datetime.now().date()) + '.txt'\n    f_report = open(reportfile, 'a+')\n    f_report.write('Report for collision of ' + constants.CATEGORIES[cat1][\"main\"] + ' ' + constants.CATEGORIES[cat2][\n        \"main\"] + '\\n\\n')\n\n    # Load background mold\n    background_mold = dict()\n    for background in constants.CATEGORIES[-1]['element']:\n        background_mold[background] = np.load(constants.MOLD_PATHS[background])\n\n    print(\"===> Generating data for collision \"+str(constants.CATEGORIES[cat1][\"main\"])+\" \"+str(constants.CATEGORIES[cat2][\"main\"]))\n    count = 0\n\n    # Change the background\n    for background in background_mold:\n        print(\">! Change frame background to \"+str(background))\n\n        # Change the object for each category\n        for obj1 in constants.CATEGORIES[cat1]['element']:\n            object_mold1 = np.load(constants.MOLD_PATHS[obj1])\n            for snr_obj1 in snr_range:\n                if obj1 == 'bt_1' and snr_obj1 == snr_range[0]:\n                    continue\n\n                if obj1 == 'bt_2' and snr_obj1 != snr_range[1]:\n                    continue\n\n                print(\">! Apply SNR variation of \"+str(snr_obj1)+\" to \"+str(obj1))\n                for obj2 in constants.CATEGORIES[cat2]['element']:\n                    object_mold2 = np.load(constants.MOLD_PATHS[obj2])\n                    for snr_obj2 in snr_range:\n                        if obj2 == 'bt_1' and snr_obj2 == snr_range[0]:\n                            continue\n\n                        if obj2 == 'bt_2' and snr_obj2 != snr_range[1]:\n                            continue\n\n                        # Collision is not visible\n                        if (snr_obj1 == snr_range[0] and snr_obj2 == snr_range[2]) or (\n                                snr_obj1 == snr_range[2] and snr_obj2 == snr_range[0]):\n                            continue\n\n                        print(\">! Apply SNR variation of \"+str(snr_obj2)+\" to \"+str(obj2))\n                        f_report.write(\n                            'Start count for collision of ' + obj1 + ' and ' + obj2 + ' with snr change ' + str(\n                                snr_obj1) + ' and ' + str(snr_obj2) + ':' + str(count) + '\\n')\n\n                        \"\"\"\n                        One problem is that, it's not trivial to come up with all collision\n                        patterns, considering all settings of length, and snrs. So, the most\n                        efficient way would be generating a number of samples for each combination\n                        of SNRs and objects.\n                        \"\"\"\n\n                        iter_counts = 0\n                        while iter_counts < num_coll_iter:\n\n                            packet_obj1 = Packet(object_mold1, cat1, constants.VAR[obj1])\n                            packet_obj1.adjust_snr(snr_obj1)\n\n                            packet_obj2 = Packet(object_mold2, cat2, constants.VAR[obj2])\n                            packet_obj2.adjust_snr(snr_obj2)\n\n                            # Varying lengths if needed\n                            if constants.VAR[obj1]:\n                                packet_obj1.adjust_length(randint(100, 512))\n                            if constants.VAR[obj2]:\n                                packet_obj2.adjust_length(randint(100, 512))\n\n                            # Generate collision: Need to check if collision is possible\n                            collidable = False\n                            left_offset1 = None\n                            left_offset2 = None\n                            top_offset1 = None\n                            top_offset2 = None\n\n                            while collidable == False:\n                                # First, choose the location of the first packet\n                                left_offset1 = choice(range(constants.AUGMENT_CHANNELS[cat1]['start'],\n                                                            constants.LIMIT_INDEX - packet_obj1.width,\n                                                            constants.AUGMENT_CHANNELS[cat1]['space']))\n                                top_offset1 = choice(range(0, 512 - packet_obj1.length + 1, 1))\n\n                                range2 = range(constants.AUGMENT_CHANNELS[cat2]['start'],\n                                               constants.LIMIT_INDEX - packet_obj2.width,\n                                               constants.AUGMENT_CHANNELS[cat2]['space'])\n                                collidable, left_offset2 = check_collision(left_offset1, packet_obj1.width, range2,\n                                                                           packet_obj2.width)\n\n                            top_offset2 = choice(\n                                range(min(max(0, top_offset1 - int(packet_obj2.length / 2)), 512 - packet_obj2.length),\n                                      min(512 - packet_obj2.length, top_offset1 + int(packet_obj1.length / 2)) + 1, 1))\n                            # Collision not visible\n                            if (\n                                    left_offset1 <= left_offset2 and left_offset1 + packet_obj1.width >= left_offset2 + packet_obj2.width and\n                                    top_offset1 <= top_offset2 and top_offset1 + packet_obj1.length >= top_offset2 + packet_obj2.length and\n                                    snr_obj1 < snr_obj2 and obj2 != 'bt_2') or \\\n                                    (\n                                            left_offset2 <= left_offset1 and left_offset2 + packet_obj2.width >= left_offset1 + packet_obj1.width and\n                                            top_offset2 <= top_offset1 and top_offset2 + packet_obj2.length >= top_offset1 + packet_obj1.length and\n                                            snr_obj2 < snr_obj1 and obj1 != 'bt_2'):\n                                continue\n\n                            # Create and adjust frame\n                            pathname = savepath + \"/\" + \"collision_\" + constants.CATEGORIES[cat1][\"main\"] + \"_\" + \\\n                                       constants.CATEGORIES[cat2][\"main\"] + \"_\" + str(count) + \".jpg\"\n                            frame = Frame(pathname, background_mold[background], nfft, nlines)\n                            frame.add_packet(packet_obj1, left_offset1, top_offset1)\n                            frame.add_packet(packet_obj2, left_offset2, top_offset2)\n\n                            # Save image\n                            data_clip(frame.frame_data, constants.VMIN, constants.VMAX)\n                            image_data = img_scale(frame.frame_data, constants.VMIN, constants.VMAX)\n                            image_data = img_flip(stack_image_channels(image_data), ax=0)\n                            image = Image.fromarray(image_data)\n                            image.save(pathname)\n                            count += 1\n                            iter_counts += 1\n\n                        # Writing counts for the report...\n                        f_report.write(\n                            'Finish count for collision of ' + obj1 + ' and ' + obj2 + ' with snr change ' + str(\n                                snr_obj1) + ' and ' + str(snr_obj2) + ':' + str(count) + '\\n')\n                        f_report.write('==================================================\\n')\n\n    f_report.close()\n    print(\"> Done processing collisions of \"+str(constants.CATEGORIES[cat1]['main'])+\" \"+str(constants.CATEGORIES[cat2]['main'])+\". \"+str(count)+\" elements generated\")\n    print(\"Images saved in: \"+savepath)\n    print(\"Processing report: \"+reportfile)\n    return savepath", "\n\ndef gen_synthetic_data(category, save_path, snr_range=None, nfft=512, nlines=512, num_coll_iter=500, length_range=(62, 512),\n                       length_step=15, full_length_ratio=10):\n    \"\"\"\n    Generate synthetic dataset based on category and the corresponding mold. Return the directory of the dataset.\n    \"\"\"\n    if isinstance(category, int):\n        return gen_synthetic_single_emission(category, save_path, snr_range, nfft, nlines,\n                                             length_range, length_step, full_length_ratio)\n    elif isinstance(category, list) or isinstance(category, tuple) :\n        if len(category) == 1:\n            return gen_synthetic_single_emission(category[0], save_path, snr_range, nfft, nlines,\n                                                 length_range, length_step, full_length_ratio)\n        elif len(category) == 2:\n            return gen_synthetic_colliding_emission(category, save_path, snr_range, nfft, nlines, num_coll_iter, length_range,\n                                                    length_step, full_length_ratio)\n        else:\n            raise NotImplementedError(\"Collision with more than two emission categories is not supported.\")\n    else:\n        raise TypeError(\"Wrong format for emission category.\")", "\n\ndef main():\n    \"\"\" Parse args \"\"\"\n    parser = argparse.ArgumentParser(description=\"Create synthetic emission data.\",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"--save-path\", type=str, required=True,\n                        help=\"Directory path to save data.\")\n    parser.add_argument(\"--categories\", \"-c\", type=int,\n                        choices=[x for x in constants.CATEGORIES.keys() if x > -1], required=True, nargs=\"*\",\n                        help=\"Category(-ies) of synthetic emissions. Specifying two categories generates a collision.\")\n    parser.add_argument(\"--snr-range\", nargs=\"+\", type=int, default=[-10, 0, 10],\n                        help=\"SNR Values for the synthetic emissions.\")\n    parser.add_argument(\"--n-fft\", type=int, default=512,\n                        help=\"Nfft for image generation. SPREAD dataset uses 512.\")\n    parser.add_argument(\"--n-lines\", type=int, default=512,\n                        help=\"Nlines for image generation. SPREAD dataset uses 512.\")\n    parser.add_argument(\"--num-coll-iter\", \"-i\", type=int, default=500,\n                        help=\"Number of random iterations for each choice of collision setting regarding the location.\")\n    parser.add_argument(\"--length-range\", \"-l\", type=int, nargs=2, default=(62, 512),\n                        help=\"Range for adjustment of emissions length.\")\n    parser.add_argument(\"--length-step\", \"-s\", type=int, default=15,\n                        help=\"Length adjustment step. I.e.: For 100MHz recordings, a step of 10 corresponds to ~50us.\")\n    parser.add_argument(\"--full-length-ratio\", \"-r\", type=int, default=10,\n                        help=\"Ratio of full length packets to synthetic ones. Generating more full length packets \"\n                             \"improves training performance.\")\n    args = parser.parse_args()\n\n    assert len(args.categories) <= 2, \"A number of one or two categories may be selected.\"\n\n    gen_synthetic_data(args.categories, args.save_path, snr_range=args.snr_range, nfft=args.n_fft, nlines=args.n_lines,\n                       num_coll_iter=args.num_coll_iter, length_range=args.length_range, length_step=args.length_step,\n                       full_length_ratio=args.full_length_ratio)", "\n\nif __name__ == \"__main__\":\n    main()\n"]}
{"filename": "generate_pictures.py", "chunked_list": ["\"\"\"\nTool to generate pictures for recordings of SPREAD.\n\"\"\"\nimport argparse\n\nfrom core import *\n\nimport logging\n\nformatter = logging.Formatter('%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')", "\nformatter = logging.Formatter('%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlogging.basicConfig(level=logging.DEBUG,\n                    format='%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlog = logging.getLogger('spread')\nlog.setLevel(logging.INFO)\n\n\ndef process_gen_pics(dataset_dir, recordings=None, mode='grayscale', overwrite=False, log_noise=None, fft_size=512,\n                     img_limit=0, filters=None):\n    \"\"\"\n    Generates pictures of a recording and saves them in the picture directory of the dataset\n    \"\"\"\n\n    # Load the dataset\n    ds = Dataset(dataset_dir)\n\n    # Get the recording objects\n    if recordings:\n        to_pic = [ds.recordings_dict.get(Dataset.get_rec_name(x), None) for x in recordings]\n    elif filters:\n        to_pic = ds.filter_recordings(filters)\n    else:\n        to_pic = ds.recordings\n\n    for rec in to_pic:\n        if not rec:\n            log.error(\"No recording found\")\n            continue\n        else:\n            if not rec.metadata.no_of_pictures or rec.metadata.no_of_pictures == 0 or overwrite:\n                rec.generate_pictures(log_noise=log_noise, npics=img_limit, mode=mode,\n                                      nfft=fft_size)\n            else:\n                log.info(\"Skipping recording %s because pictures already exist. Specify \\\"--overwrite\\\" if desired.\",\n                         rec.name)", "def process_gen_pics(dataset_dir, recordings=None, mode='grayscale', overwrite=False, log_noise=None, fft_size=512,\n                     img_limit=0, filters=None):\n    \"\"\"\n    Generates pictures of a recording and saves them in the picture directory of the dataset\n    \"\"\"\n\n    # Load the dataset\n    ds = Dataset(dataset_dir)\n\n    # Get the recording objects\n    if recordings:\n        to_pic = [ds.recordings_dict.get(Dataset.get_rec_name(x), None) for x in recordings]\n    elif filters:\n        to_pic = ds.filter_recordings(filters)\n    else:\n        to_pic = ds.recordings\n\n    for rec in to_pic:\n        if not rec:\n            log.error(\"No recording found\")\n            continue\n        else:\n            if not rec.metadata.no_of_pictures or rec.metadata.no_of_pictures == 0 or overwrite:\n                rec.generate_pictures(log_noise=log_noise, npics=img_limit, mode=mode,\n                                      nfft=fft_size)\n            else:\n                log.info(\"Skipping recording %s because pictures already exist. Specify \\\"--overwrite\\\" if desired.\",\n                         rec.name)", "\n\ndef main():\n    \"\"\"\n    Parse arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(description='Generate pictures for all or selected recordings',\n                                     formatter_class=argparse.RawTextHelpFormatter)\n    parser.add_argument(\"--dataset\", required=True,\n                        help=\"Root directory of the dataset.\")\n    parser.add_argument(\"--recordings\", nargs=\"*\",\n                        help=\"List of recordings to generate pictures for. If no recordings are specified, all \\\n                             recordings with no pictures will be processed\")\n    parser.add_argument(\"--filter\", nargs=\"*\",\n                        help=\"Pass recordings with filters (eg: classes=3)\")\n    parser.add_argument(\"--mode\", type=str, default='grayscale', choices=['grayscale', 'compressed'],\n                        help='Choose mode: grayscale or compressed')\n    # parser.add_argument(\"--compr-factor\", type=int, default=12,\n    #                     help=\"Compression factor.\")\n    parser.add_argument(\"--overwrite\", action='store_true',\n                        help=\"Overwrites previously generated pictures\")\n    parser.add_argument(\"--log-noise\",\n                        help=\"Noise level in dB. If omitted, noise is read from the recording metadata.\")\n    parser.add_argument(\"--img-limit\", type=int, default=0,\n                        help='Number of pictures to generate (default: 0 (all pictures)')\n    parser.add_argument(\"--fft-size\", type=int, default=512,\n                        help=\"FFT size\")\n    args = parser.parse_args()\n\n    process_gen_pics(args.dataset, args.recordings, args.mode, args.overwrite, args.log_noise, args.fft_size,\n                     args.img_limit, args.filter)", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "combine_recordings.py", "chunked_list": ["\"\"\"\nScript to create synthetic recordings in the Dataset from current recordings.\n\"\"\"\nimport argparse\nimport os\nimport logging\nfrom random import choice as pick_one\nfrom time import time\nfrom multiprocessing import Process, Queue\nfrom core import *", "from multiprocessing import Process, Queue\nfrom core import *\n\nformatter = logging.Formatter('%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlogging.basicConfig(level=logging.DEBUG,\n                    format='%(asctime)s - %(filename)s:%(lineno)d - %(levelname)s - %(message)s')\nlog = logging.getLogger('spread')\nlog.setLevel(logging.DEBUG)\n\n\ndef get_obj_from_files(ds, from_files):\n    \"\"\"\n    Returns a list of objects based on their filenames\n    \"\"\"\n    from_files = [os.path.basename(x).split('.32fc')[0] for x in from_files]  # get rid of file path and extension\n    rec_obj_list = sorted([ds.recordings_dict[x] for x in from_files], key=lambda rec: rec.id)\n    return rec_obj_list", "\n\ndef get_obj_from_files(ds, from_files):\n    \"\"\"\n    Returns a list of objects based on their filenames\n    \"\"\"\n    from_files = [os.path.basename(x).split('.32fc')[0] for x in from_files]  # get rid of file path and extension\n    rec_obj_list = sorted([ds.recordings_dict[x] for x in from_files], key=lambda rec: rec.id)\n    return rec_obj_list\n", "\n\ndef get_obj_from_properties(ds, from_properties):\n    \"\"\"\n    Returns a list of objects based on their properties\n    \"\"\"\n    rec_obj_list = []\n    for rec_prop in from_properties:\n        # Split the filters in the required list format [key=value ...]\n        rec_prop = rec_prop.split(',')\n        # and pick a random one from the filtered recordings\n        filtered = ds.filter_recordings(rec_prop)\n        if not filtered:\n            log.error(\"No recording found that satisfies the properties: %s\", ','.join(rec_prop))\n            skipped_combos = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"skipped_combs.txt\")\n            with open(skipped_combos, 'a') as sc:\n                sc.write(\"%s\\n\" % ' '.join(from_properties))\n            return\n        which_one = pick_one(filtered)\n        rec_obj_list.append(which_one)\n    rec_obj_list.sort(key=lambda rec: rec.id)\n    return rec_obj_list", "\n\ndef combine_recordings(dataset, from_files, from_properties, to_files, ds=None,\n                       q=None, md_only=False):\n    \"\"\"\n    Creates synthetic data from the given recordings. This includes initializing\n    the recording and the metadata, and storing them in the dataset, depending on\n    the options given.\n    \"\"\"\n\n    if q:\n        ds = q.get()\n    if not ds:\n        ds = Dataset(dataset)\n\n    # Either get recordings explicitly from filenames\n    if from_files:\n        rec_obj_list = get_obj_from_files(ds, from_files)\n    # choose random recordings based on input filters\n    elif from_properties:\n        rec_obj_list = get_obj_from_properties(ds, from_properties)\n    else:\n        rec_obj_list = None\n    if not rec_obj_list:\n        log.info(\"No recordings to combine, skipping.\")\n        return\n\n    t = time()\n    to_file = to_files[0] if to_files else None\n    # Create the synthetic recording object and optionally the complex samples file\n    synthetic = Recording.merge_recordings(rec_obj_list, to_file, mockup=md_only)\n    # Create the synthetic metadata\n    if not synthetic:\n        log.error(\"Synthetic %s could not be found.\", to_file)\n        return\n    synthetic.metadata = RecordingMetadata.combine_metadata(synthetic, [x.metadata for x in rec_obj_list])\n    # Create the metafile for the recording and store the metadata\n    synthetic.metadata.store_metadata()\n    synthetic.print_info()\n    log.info(\"Time elapsed: %s minutes\", (time() - t) / 60)", "\n\ndef combine_annotations(dataset, synthetics=None, ds=None):\n    \"\"\"Creates synthetic annotations for synthetic recordings, by combining the annotations of the source recordings.\"\"\"\n\n    if not ds:\n        ds = Dataset(dataset)\n\n    if synthetics:\n        synthetics = [ds.recordings_dict.get(x, None) for x in synthetics]\n    else:\n        synthetics = [x for x in ds.recordings if x.metadata.synthetic]\n\n    for syn in synthetics:\n        if not syn:\n            log.error(\"Synthetic not found.\")\n            continue\n        log.info(\"Creating synthetic annotations for recording %s\", syn.name)\n        if not os.path.isdir(syn.rec_pics_dir):\n            try:\n                os.mkdir(syn.rec_pics_dir)\n            except OSError:\n                pass\n        if not os.path.isdir(syn.synthetic_annotations_dir):\n            os.mkdir(syn.synthetic_annotations_dir)\n        if not os.path.isdir(syn.compressed_pics_dir):\n            try:\n                os.mkdir(syn.compressed_pics_dir)\n            except OSError:\n                pass\n\n        sources = [ds.recordings_dict.get(x, None) for x in syn.metadata.sources]\n\n        # If a source is missing (i.e. removed from dataset)\n        if None in sources:\n            log.info(\"Synthetic %s is depending on a missing source: %s. Skipping.\", syn.name,\n                     ' '.join([x for x in syn.metadata.sources if not ds.recordings_dict.get(x, None)]))\n            continue\n\n        # Check if all source recordings have compressed annotations and use these first\n        if all([x.compressed_annotation_list for x in sources]):\n            log.info(\"Using compressed annotations.\")\n            for compr_ann in sources[0].compressed_annotation_list:\n                syn_pic_id = get_id_from_pic_name(os.path.basename(compr_ann))\n                pic_annotations = []\n\n                # Find the corresponding annotation of every source file\n                for src_rec in sources:\n                    src_ann_file = os.path.join(src_rec.compressed_pics_dir, src_rec.pic_prefix + \"_\" + str(syn_pic_id)\n                                                + \".txt\")\n                    try:\n                        with open(src_ann_file, 'r') as f:\n                            src_annot = f.read().strip().split('\\n')\n                    except IOError:\n                        log.error(\"File missing for source rec: %s\", src_ann_file)\n                        continue\n                    pic_annotations.extend(src_annot)\n\n                # Merge all the lines together\n                pic_annotations = '\\n'.join(pic_annotations)\n                # and save them in the synthetic annotation\n                outfile = os.path.join(syn.compressed_pics_dir,\n                                       syn.pic_prefix + \"_\" + str(syn_pic_id) + \".txt\")\n                with open(outfile, 'w') as f:\n                    f.write(pic_annotations)\n\n        # Else if not, for every picture in the synthetic file\n        else:\n            for syn_pic in syn.pic_list:\n                syn_pic_id = get_id_from_pic_name(os.path.basename(syn_pic))\n                pic_annotations = []\n                # Find the corresponding annotation of every source file\n                for src_rec in sources:\n                    if src_rec.fixed_label_list:\n                        src_dir = src_rec.fixed_labels_dir\n                    else:\n                        log.info(\"Fixed labels were not found for recording %s in %s. Skipping recording: %s.\",\n                                 src_rec.name,\n                                 src_rec.fixed_labels_dir,\n                                 syn.name)\n                        break\n                    src_ann_file = os.path.join(src_dir, src_rec.pic_prefix + \"_\" + str(syn_pic_id) + \".txt\")\n                    with open(src_ann_file, 'r') as f:\n                        src_annot = f.read().strip().split('\\n')\n                    pic_annotations.extend(src_annot)\n                else:\n                    # Merge all the lines together\n                    pic_annotations = '\\n'.join(pic_annotations)\n                    # and save them in the synthetic annotation\n                    outfile = os.path.join(syn.synthetic_annotations_dir,\n                                           syn.pic_prefix + \"_\" + str(syn_pic_id) + \".txt\")\n                    with open(outfile, 'w') as f:\n                        f.write(pic_annotations)\n                    continue\n                break", "\n\ndef main():\n    \"\"\"\n    Parse arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter,\n                                     description=\"\"\"This tool creates synthetic data based on other real or synthetic \\\n        data of SPREAD.\n        The data can be produced by merging other sample files.\n\n        Example usage:\n        python combine_recordings.py --from source1.32fc source2.32fc --to combined.32fc\n\n        In order to provide property filters as input instead of recording names one can use:\n\n        --from-properties class=wifi,channel=3,duration=10 class=wmic class=bluetooth,transmission=continuous\n\n        In that case there will be chosen and merged a random:\n        \n        wifi, channel 3, 10 second recording, with a\n        wireless microphone recording, and a\n        continuous bluetooth recording.\n\n        Pay attention to the comma and space separations to avoid merging wrong files.\n\"\"\")\n    parser.add_argument(\"--dataset\", required=True,\n                        help=\"Dataset root directory\")\n    source = parser.add_mutually_exclusive_group(required=True)\n    source.add_argument(\"--from-files\", nargs=\"+\",\n                        help='File(s) to create synthetic data from.')\n    source.add_argument(\"--from-properties\", nargs=\"+\",\n                        help='Specify source recordings depending on their properties giving a \\\n        comma-separated list of property=value for each recording. \\\n        A random dataset recording satisfying the properties (if any) will be used.')\n    parser.add_argument(\"--to-files\", nargs='+',\n                        help='File(s) to write synthetic data to.')\n    source.add_argument(\"--combine-annotations\", action='store_true',\n                        help=\"Create annotations for the specified synthetic recordings by combining the annotations\\\n                             of the source recordings.\")\n    parser.add_argument(\"--synthetics\", nargs=\"*\",\n                        help=\"Synthetic recordings to create annotations for. If not specified, all of them are\\\n                             generated.\")\n    parser.add_argument(\"--mock\", action=\"store_true\", help=\"Only print metadata of the resulting synthetic.\")\n    args = parser.parse_args()\n\n    if args.combine_annotations:\n        combine_annotations(args.dataset, args.synthetics)\n        return\n\n    combine_recordings(args.dataset, args.from_files, args.from_properties, args.to_files, md_only=args.mock)", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/_dataset.py", "chunked_list": ["\"\"\"\nDefinition of the dataset top level structure: Dataset\n\"\"\"\nimport os\nimport glob\nimport logging\nfrom ._recording import Recording\nfrom ._tables import DatasetTable\nfrom ._metadata import DatasetMetadata\nfrom ._utils import *", "from ._metadata import DatasetMetadata\nfrom ._utils import *\n\nlog = logging.getLogger('spread')\n\n\n__all__ = ['Dataset']\n\n\nclass Dataset(object):\n    \"\"\"\n    Represents an instance of SPREAD\n    \"\"\"\n\n    @staticmethod\n    def get_rec_name(recname):\n        \"\"\"\n        Returns the name of a recording, omitting the 32fc/dat extension\n        \"\"\"\n        if recname.endswith('.32fc'):\n            return recname.split('.32fc')[0]\n        elif recname.endswith('.dat'):\n            return recname.split('.dat')[0]\n        else:\n            return recname\n\n    def __init__(self, root_dir, recount_pictures=False):\n        \"\"\"\n                Dataset structure\n\n                    dataset_root\n        recordings                      pictures                        metadata\nrec_<id>.32fc  rec_<id>.json    rec<id>/rec_<id>_pic_<pic_id>       global_metadata_files\n        \"\"\"\n\n        # Root directory of the dataset\n        self.root_dir = os.path.abspath(root_dir)\n        if not os.path.isdir(self.root_dir):\n            log.error(\"Dataset root directory not found.\")\n\n        # Dataset directories\n        self.recordings_dir = os.path.join(self.root_dir, \"recordings\")\n        # Pictures\n        self.pictures_dir = os.path.join(self.root_dir, \"pictures\")\n        # Noise Calculation\n        self.noise_calc_dir = os.path.join(self.root_dir, \"noise_calculations\")\n        # Metadata dir, containing global metadata\n        self.metadata_dir = os.path.join(self.root_dir, \"metadata\")\n\n        # Dataset metadata instance\n        self.metadata = DatasetMetadata(self)\n\n        if not os.path.isdir(self.metadata_dir):\n            os.mkdir(self.metadata_dir)\n\n        # File naming\n        self.default_rec_name_prefix = \"rec_\"\n        self.default_syn_name_prefix = \"syn_\"\n\n        # Image naming <rec_ID>_<pic_ID>.jpg\n\n        # Dataset toolset\n        self.tools = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n        self.core_dir = os.path.join(self.tools, 'core')\n        self.flowgraphs = os.path.join(self.core_dir, 'flowgraphs')\n        self.gen_dat_snr = os.path.join(self.flowgraphs, 'samples_fft.py')\n        self.gen_fft_samples = os.path.join(self.flowgraphs, 'samples_to_dat.py')\n\n        self.gen_pics_script = os.path.join(self.core_dir, 'gen_pics.py')\n\n        # Dictionary containing all the recording objects\n        self._recordings_dict = {}\n\n        # Table of contents\n        self.cont_table = None\n\n        self.load_recordings(recount_pictures=recount_pictures)\n\n        try:\n            self.load_content_table()\n        except Exception as e:\n            log.error(\"There was an error loading the table of contents: %s\", e)\n\n        self.print_info()\n\n    def load_recordings(self, recount_pictures=False):\n        \"\"\"\n        Loads and initializes the recordings of this dataset\n        \"\"\"\n        files = glob.glob(os.path.join(self.recordings_dir, '*.32fc'))\n        for rec in files:\n            rec_obj = Recording(rec, self, recount_pictures=recount_pictures)\n            self._recordings_dict[rec_obj.name] = rec_obj\n\n    def add_recording(self, rec_object=None, recname=None):\n        \"\"\"\n        Adds a recording to the dataset either by recording object or by recording name (ie: rec_145)\n        \"\"\"\n        if recname:\n            recfile = [os.path.join(self.recordings_dir, '%s.32fc' % recname)]\n            rec_obj = Recording(recfile, self)\n            self._recordings_dict[rec_obj.name] = rec_obj\n        elif rec_object:\n            self._recordings_dict[rec_object.name] = rec_object\n\n    def get_last_synthetic_index(self):\n        \"\"\"\n        Loads and initializes the recordings of this dataset\n        \"\"\"\n        files = glob.glob(os.path.join(self.recordings_dir, 'syn_*.32fc'))\n        if not files:\n            return 0\n        indexes = [x.split('syn_')[1].split('.')[0] for x in files]\n        try:\n            indexes = [int(x) for x in indexes]\n            return max(indexes)\n        except ValueError:\n            return None\n\n    @property\n    def recordings(self):\n        \"\"\"\n        Returns a list of all recording objects in the dataset\n        \"\"\"\n        return sorted(self._recordings_dict.values(), key=lambda x: (x.name[0], x.id))\n\n    @property\n    def recordings_dict(self):\n        \"\"\"\n        Returns the dictionary of recordings\n        \"\"\"\n        return self._recordings_dict\n\n    @property\n    def sorted_recordings(self):\n        \"\"\"\n        Returns a sorted list of recordings based on their name and ID\n        \"\"\"\n        return sorted(self._recordings_dict.values(), key=lambda x: (x.name[0], x.id))\n\n    @property\n    def sorted_recording_names(self):\n        \"\"\"\n        Returns a sorted list of recording names\n        \"\"\"\n        return sorted(self._recordings_dict.keys())\n\n    def get_synthetic_outfile(self):\n        \"\"\"\n        Returns the next available name for synthetic recordings using the default prefix\n        \"\"\"\n        last_index = self.get_last_synthetic_index()\n        if last_index is None:\n            return None\n        else:\n            return self.default_syn_name_prefix + str(last_index+1) + '.32fc'\n\n    def filter_recordings(self, filters):\n        \"\"\"\n        Return a list of recordings that satisfy the given filters.\n        :param filters: list of filters in the form of [key1=value1, key2=value2, ...]\n        :return: list of recordings objects that satisfy all the filters\n        \"\"\"\n        filtered = []\n        for rec in self.recordings:\n            for fltr in filters:\n                try:\n                    fltr_k, fltr_v = fltr.split('=')\n                except ValueError:\n                    log.error(\"Please make sure you are properly providing the filters in the format of key=value\")\n                    continue\n                # Additional properties search\n                if fltr_k == 'classes':\n                    try:\n                        fltr_v = int(fltr_v)\n                    except ValueError:\n                        log.error(\"Please provide an integer to filter the number of classes.\")\n                        continue\n                    if len(rec.metadata.sources) != fltr_v:\n                        break\n                elif fltr_k == 'sources':\n                    if fltr_v not in rec.metadata.sources:\n                        break\n                # If a filter is not satisfied, discard it\n                elif str(rec.metadata.metadata.get(fltr_k, '')) != fltr_v:\n                    break\n            else:\n                filtered.append(rec)\n                continue\n            continue\n        return sorted(filtered, key=lambda x: (x.name[0], x.id))\n\n    def load_content_table(self):\n        \"\"\"\n        Loads the table of contents\n        \"\"\"\n        self.cont_table = DatasetTable(self)\n\n    def get_total_size(self):\n        \"\"\"\n        Returns the total size of the dataset\n        \"\"\"\n        return total_size([x.file_size for x in self.recordings])\n\n    def get_total_duration(self):\n        \"\"\"\n        Returns total duration of recordings in seconds\n        \"\"\"\n        try:\n            return sum([int(x.metadata.duration) for x in self.recordings])\n        except TypeError:\n            return None\n\n    def get_total_no_pictures(self):\n        \"\"\"\n        Returns total amount of pictures in the dataset\n        \"\"\"\n        try:\n            return sum([x.metadata.no_of_pictures for x in self.recordings])\n        except TypeError:\n            return None\n\n    def print_info(self):\n        \"\"\"\n        Prints info about the dataset\n        \"\"\"\n        log.info(\"Loading SPREAD from %s\", self.root_dir)\n        # log.info(\"Dataset root directory: %s\", self.root_dir)\n        log.info(\"Total number of recordings: %s\", len(self.recordings))\n        log.info(\"Total duration of recordings in seconds: %s\", self.get_total_duration())\n        log.info(\"Total number of pictures: %s\", self.get_total_no_pictures())\n        log.info(\"Total size: %s\", self.get_total_size())", "\nclass Dataset(object):\n    \"\"\"\n    Represents an instance of SPREAD\n    \"\"\"\n\n    @staticmethod\n    def get_rec_name(recname):\n        \"\"\"\n        Returns the name of a recording, omitting the 32fc/dat extension\n        \"\"\"\n        if recname.endswith('.32fc'):\n            return recname.split('.32fc')[0]\n        elif recname.endswith('.dat'):\n            return recname.split('.dat')[0]\n        else:\n            return recname\n\n    def __init__(self, root_dir, recount_pictures=False):\n        \"\"\"\n                Dataset structure\n\n                    dataset_root\n        recordings                      pictures                        metadata\nrec_<id>.32fc  rec_<id>.json    rec<id>/rec_<id>_pic_<pic_id>       global_metadata_files\n        \"\"\"\n\n        # Root directory of the dataset\n        self.root_dir = os.path.abspath(root_dir)\n        if not os.path.isdir(self.root_dir):\n            log.error(\"Dataset root directory not found.\")\n\n        # Dataset directories\n        self.recordings_dir = os.path.join(self.root_dir, \"recordings\")\n        # Pictures\n        self.pictures_dir = os.path.join(self.root_dir, \"pictures\")\n        # Noise Calculation\n        self.noise_calc_dir = os.path.join(self.root_dir, \"noise_calculations\")\n        # Metadata dir, containing global metadata\n        self.metadata_dir = os.path.join(self.root_dir, \"metadata\")\n\n        # Dataset metadata instance\n        self.metadata = DatasetMetadata(self)\n\n        if not os.path.isdir(self.metadata_dir):\n            os.mkdir(self.metadata_dir)\n\n        # File naming\n        self.default_rec_name_prefix = \"rec_\"\n        self.default_syn_name_prefix = \"syn_\"\n\n        # Image naming <rec_ID>_<pic_ID>.jpg\n\n        # Dataset toolset\n        self.tools = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n        self.core_dir = os.path.join(self.tools, 'core')\n        self.flowgraphs = os.path.join(self.core_dir, 'flowgraphs')\n        self.gen_dat_snr = os.path.join(self.flowgraphs, 'samples_fft.py')\n        self.gen_fft_samples = os.path.join(self.flowgraphs, 'samples_to_dat.py')\n\n        self.gen_pics_script = os.path.join(self.core_dir, 'gen_pics.py')\n\n        # Dictionary containing all the recording objects\n        self._recordings_dict = {}\n\n        # Table of contents\n        self.cont_table = None\n\n        self.load_recordings(recount_pictures=recount_pictures)\n\n        try:\n            self.load_content_table()\n        except Exception as e:\n            log.error(\"There was an error loading the table of contents: %s\", e)\n\n        self.print_info()\n\n    def load_recordings(self, recount_pictures=False):\n        \"\"\"\n        Loads and initializes the recordings of this dataset\n        \"\"\"\n        files = glob.glob(os.path.join(self.recordings_dir, '*.32fc'))\n        for rec in files:\n            rec_obj = Recording(rec, self, recount_pictures=recount_pictures)\n            self._recordings_dict[rec_obj.name] = rec_obj\n\n    def add_recording(self, rec_object=None, recname=None):\n        \"\"\"\n        Adds a recording to the dataset either by recording object or by recording name (ie: rec_145)\n        \"\"\"\n        if recname:\n            recfile = [os.path.join(self.recordings_dir, '%s.32fc' % recname)]\n            rec_obj = Recording(recfile, self)\n            self._recordings_dict[rec_obj.name] = rec_obj\n        elif rec_object:\n            self._recordings_dict[rec_object.name] = rec_object\n\n    def get_last_synthetic_index(self):\n        \"\"\"\n        Loads and initializes the recordings of this dataset\n        \"\"\"\n        files = glob.glob(os.path.join(self.recordings_dir, 'syn_*.32fc'))\n        if not files:\n            return 0\n        indexes = [x.split('syn_')[1].split('.')[0] for x in files]\n        try:\n            indexes = [int(x) for x in indexes]\n            return max(indexes)\n        except ValueError:\n            return None\n\n    @property\n    def recordings(self):\n        \"\"\"\n        Returns a list of all recording objects in the dataset\n        \"\"\"\n        return sorted(self._recordings_dict.values(), key=lambda x: (x.name[0], x.id))\n\n    @property\n    def recordings_dict(self):\n        \"\"\"\n        Returns the dictionary of recordings\n        \"\"\"\n        return self._recordings_dict\n\n    @property\n    def sorted_recordings(self):\n        \"\"\"\n        Returns a sorted list of recordings based on their name and ID\n        \"\"\"\n        return sorted(self._recordings_dict.values(), key=lambda x: (x.name[0], x.id))\n\n    @property\n    def sorted_recording_names(self):\n        \"\"\"\n        Returns a sorted list of recording names\n        \"\"\"\n        return sorted(self._recordings_dict.keys())\n\n    def get_synthetic_outfile(self):\n        \"\"\"\n        Returns the next available name for synthetic recordings using the default prefix\n        \"\"\"\n        last_index = self.get_last_synthetic_index()\n        if last_index is None:\n            return None\n        else:\n            return self.default_syn_name_prefix + str(last_index+1) + '.32fc'\n\n    def filter_recordings(self, filters):\n        \"\"\"\n        Return a list of recordings that satisfy the given filters.\n        :param filters: list of filters in the form of [key1=value1, key2=value2, ...]\n        :return: list of recordings objects that satisfy all the filters\n        \"\"\"\n        filtered = []\n        for rec in self.recordings:\n            for fltr in filters:\n                try:\n                    fltr_k, fltr_v = fltr.split('=')\n                except ValueError:\n                    log.error(\"Please make sure you are properly providing the filters in the format of key=value\")\n                    continue\n                # Additional properties search\n                if fltr_k == 'classes':\n                    try:\n                        fltr_v = int(fltr_v)\n                    except ValueError:\n                        log.error(\"Please provide an integer to filter the number of classes.\")\n                        continue\n                    if len(rec.metadata.sources) != fltr_v:\n                        break\n                elif fltr_k == 'sources':\n                    if fltr_v not in rec.metadata.sources:\n                        break\n                # If a filter is not satisfied, discard it\n                elif str(rec.metadata.metadata.get(fltr_k, '')) != fltr_v:\n                    break\n            else:\n                filtered.append(rec)\n                continue\n            continue\n        return sorted(filtered, key=lambda x: (x.name[0], x.id))\n\n    def load_content_table(self):\n        \"\"\"\n        Loads the table of contents\n        \"\"\"\n        self.cont_table = DatasetTable(self)\n\n    def get_total_size(self):\n        \"\"\"\n        Returns the total size of the dataset\n        \"\"\"\n        return total_size([x.file_size for x in self.recordings])\n\n    def get_total_duration(self):\n        \"\"\"\n        Returns total duration of recordings in seconds\n        \"\"\"\n        try:\n            return sum([int(x.metadata.duration) for x in self.recordings])\n        except TypeError:\n            return None\n\n    def get_total_no_pictures(self):\n        \"\"\"\n        Returns total amount of pictures in the dataset\n        \"\"\"\n        try:\n            return sum([x.metadata.no_of_pictures for x in self.recordings])\n        except TypeError:\n            return None\n\n    def print_info(self):\n        \"\"\"\n        Prints info about the dataset\n        \"\"\"\n        log.info(\"Loading SPREAD from %s\", self.root_dir)\n        # log.info(\"Dataset root directory: %s\", self.root_dir)\n        log.info(\"Total number of recordings: %s\", len(self.recordings))\n        log.info(\"Total duration of recordings in seconds: %s\", self.get_total_duration())\n        log.info(\"Total number of pictures: %s\", self.get_total_no_pictures())\n        log.info(\"Total size: %s\", self.get_total_size())", ""]}
{"filename": "core/_annotation.py", "chunked_list": ["\"\"\"\nDefinition of the annotation object\n\"\"\"\nfrom . import constants\n\n\nclass Annotation(object):\n    \"\"\"\n    Represents an instance of Annotation with information about the label and the region of the object\n\n    Label: Integer denoting the class index in the given dataset\n\n    Annotation region coordinates. They should always map to a region in the corresponding image normalized by the image\n    size. That is, point (322, 456) in a (512x512) image should have coordinates (0.6289062, 0.890625). If given values\n    are invalid they are adjusted to the range of [0,1].\n\n    Note: A 6 digit precision is recommended for use with Yolo tools.\n\n    x_c: Box center x coordinate\n    y_c: Box center y coordinate\n    Box width\n    Box height\n    \"\"\"\n\n    @staticmethod\n    def nrmlz(value, size):\n        \"\"\"\n        Normalize a given value by the size of the picture. Truncates to 6 decimals.\n\n        For example pixel position 322 in a 512 length scale would return 0.6289062.\n        \"\"\"\n        return round(float(value) / size, 6)\n\n    @staticmethod\n    def denormlz(value, size):\n        \"\"\"\n        Return the absolute value based on the image size.\n\n        For example pixel position 0.6289062 in a 512 length scale would return 322.\n        \"\"\"\n        return int(value * size)\n\n    @classmethod\n    def get_annotation_from_borders(cls, label, left, right, bottom, up):\n        \"\"\"\n        Return an annotation object based on given borders of the object region.\n\n        Note: Borders should be given normalized by the image size\n        \"\"\"\n        label = int(label)\n        width = right - left\n        height = bottom - up\n        x_c = float(left) + width / 2.0\n        y_c = float(up) + height / 2.0\n        if any([x > 1.0 for x in [x_c, y_c, width, height]]):\n            return None\n        else:\n            return cls(label, x_c, y_c, width, height)\n\n    @classmethod\n    def get_annotation_from_str(cls, annot_str):\n        \"\"\"\n        Return an annotation object based on given annotation string. Annotation string is assumed to follow the YOLO\n        convention as follows, with coordinates normalized by the the image size:\n\n        <label center_x center_y width height>\n        \"\"\"\n        label, x_c, y_c, width, height = annot_str.split()\n        return cls(int(label), float(x_c), float(y_c), float(width), float(height))\n\n    @classmethod\n    def empty(cls):\n        \"\"\"Returns an empty/invalid annotation instance\"\"\"\n        return cls(-1, 0.0, 0.0, 0.0, 0.0)\n\n    @classmethod\n    def combine_annotations(cls, i, j):\n        \"\"\"\n        Combines the coordinates of two annotations into a single one and returns a string representing the combined one\n        \"\"\"\n        # Create a new annotation with the same borders as the two old ones\n        new_up = min(i.up(), j.up())\n        new_down = max(i.down(), j.down())\n        new_left = min(i.left(), j.left())\n        new_right = max(i.right(), j.right())\n        new_width = new_right - new_left\n        new_height = new_down - new_up\n        return cls(\n            i.label,\n            new_left + new_width / 2.0,\n            new_up + new_height / 2.0,\n            new_width,\n            new_height\n        )\n\n    @staticmethod\n    def merge_annotations(annot_list):\n        \"\"\"\n        Given a list of annotation objects, returns a list of merged annotations based on their location and class\n        \"\"\"\n        # Remove possible empty or invalid annotations\n        annot_list = [ann for ann in annot_list if ann.label >= 0]\n\n        # Sort all the annotations based on the class index and on the start of transmission\n        annot_list.sort(key=lambda x: (x.label, x.y_c - x.height / 2.0))\n        # Iteratively merge annotations until necessary\n        while True:\n            for i in annot_list[:-1]:\n                for j in annot_list[annot_list.index(i) + 1:]:\n                    # Check same class\n                    if i.label == j.label:\n                        # Check similar left and right\n                        avg_width = (i.width + j.width) / 2\n                        if (abs(i.x_c - i.width / 2.0 - j.x_c + j.width / 2.0) <\n                            constants.SIDE_THRESHOLD[i.label] * avg_width and\n                            abs(i.x_c + i.width / 2.0 - j.x_c - j.width / 2.0) <\n                            constants.SIDE_THRESHOLD[i.label] * avg_width) or \\\n                                ((i.x_c - i.width / 2.0 - j.x_c + j.width / 2.0) *\n                                 (i.x_c + i.width / 2.0 - j.x_c - j.width / 2.0)) < 0:\n                            # Check beginning - end (this approach also merges overlapping transmissions in the same\n                            # channel which is intended since it would be hard to separate the weaker transmission in\n                            # the picture)\n                            if j.y_c - j.height / 2.0 - i.y_c - i.height / 2.0 < constants.TIME_THRESHOLD[i.label]:\n                                merged = Annotation.combine_annotations(i, j)\n                                break\n                # Inner for loop else clause\n                else:\n                    continue\n                # If inner for-loop breaks, break the outer for-loop in order to reconstruct the list and start over.\n                break\n            # When no more merging is needed\n            else:\n                # Break the while-loop\n                break\n\n            # Otherwise replace the merged elements with the new one and continue the while-loop.\n            annot_list.insert(annot_list.index(i), merged)\n            # Remove both merged annotations, mind that the index of j is increased by one.\n            annot_list.remove(i)\n            annot_list.remove(j)\n            continue\n\n        return annot_list\n\n    @classmethod\n    def compress_annotation(cls, annot, compr_factor, pic_index):\n        \"\"\"\n        Return a new, compressed annotation from a given annotation and a compression factor.\n\n        We assume that the original annotation was generated on flipped pictures. Therefore, no flipping should be done,\n        the boxes must be compressed by the factor in height and the center coordinate must be adjusted to reflect the\n        compression.\n        \"\"\"\n\n        # If the original annotation is empty or invalid, return an empty annotation\n        if annot.label < 0:\n            return cls.empty()\n\n        # Compress by the factor, setting a minimum threshold to avoid completely flattening the annotation\n        new_height = annot.height / compr_factor\n\n        # If annotation is compressed to 1 pixel or less, delete it\n        if new_height < 1 / 512.0:\n            return cls.empty()\n\n        # Adjust the new center. The compression is done by stacking <compr_factor> pictures vertically and compressing\n        # them, first input picture being moved at the bottom of the resulting one (to depict the flipping of pictures)\n        new_y_c = (annot.y_c + compr_factor - pic_index - 1) / float(compr_factor)\n        return cls(\n            annot.label,\n            annot.x_c,\n            new_y_c,\n            annot.width,\n            new_height\n        )\n\n    def __init__(self, label, x_c, y_c, width, height):\n        try:\n            self.label = int(label)\n            self.x_c = max(min(float(x_c), 1.0), 0.0)\n            self.y_c = max(min(float(y_c), 1.0), 0.0)\n            self.width = max(min(float(width), 1.0), 0.0)\n            self.height = max(min(float(height), 1.0), 0.0)\n        except ValueError as e:\n            raise e\n\n    # Set of helper properties to quickly check if the annotation region falls within valid numbers ([0,1])\n    @property\n    def left(self):\n        \"\"\"Return the left border of the object region in the annotation\"\"\"\n        return self.x_c - self.width / 2\n\n    @property\n    def right(self):\n        \"\"\"Return the right border of the object region in the annotation\"\"\"\n        return self.x_c + self.width / 2\n\n    @property\n    def bottom(self):\n        \"\"\"Return the lower border of the object region in the annotation\"\"\"\n        return self.y_c + self.height / 2\n\n    @property\n    def up(self):\n        \"\"\"Return the upper border of the object region in the annotation\"\"\"\n        return self.y_c - self.height / 2\n\n    def shift_center(self, new_center_point):\n        \"\"\"Shifts the annotation to a new center point given by a tuple of (new_x_c, new_y_c)\"\"\"\n        self.x_c, self.y_c = new_center_point\n\n    def scale_annotation(self, factor, ax=None):\n        \"\"\"\n        Scales the annotation (up/down) by a given factor along a given axes (x/y, w/h, width/height). If no axes is\n        provided, both dimensions are scaled\n        \"\"\"\n        if not ax:\n            ax = 'both'\n        if ax.lower() in ['x', 'w', 'width', 'both']:\n            self.width *= factor\n        elif ax.lower() in ['y', 'h', 'height', 'both']:\n            self.height *= factor\n\n    def get_annot_str(self):\n        \"\"\"\n        Returns a string for the annotation following the convention of YOLO with coordinates normalized in the range of\n        [0,1]:\n\n        <label center_x center_y width height>\n        \"\"\"\n        return \"%d %.6f %.6f %.6f %.6f\" % (\n            self.label,\n            self.x_c,\n            self.y_c,\n            self.width,\n            self.height\n        )", "\n# Define Box Class\n\n# Connect Annotation and Box classes both ways?\n\n# Draw boxes on images\n"]}
{"filename": "core/_tables.py", "chunked_list": ["\"\"\"\nDefinition of dataset tables\n\"\"\"\nimport pandas as pd\nimport logging\nimport os\nimport json\n\nfrom collections import defaultdict\n", "from collections import defaultdict\n\nlog = logging.getLogger('spread')\n\n\nclass DatasetTable(object):\n    \"\"\"\n    Represents an instance of a dataset content table containing information about the dataset recordings\n    \"\"\"\n\n    # Table format\n    # Any changes here will reflect on the output of the table\n    # Mind that the separator must be comma and space (ie: \", \")\n    # in order to be parsed \n    table_format = '''\n    Recording, Synthetic, Sources, Class, Channel, Noise level (dB), SNR (dB; estimate)\n    '''.strip()\n\n    string_size_thres = 20\n\n    @staticmethod\n    def get_short_name(data_str):\n        \"\"\"\n        Return a short name for a given string, mainly by shortening the class names\n        in order to reduce the necessary table width and increase readability\n        :param data_str:    original string\n        :return:            short_version\n        \"\"\"\n        # Set a threshold to avoid shortening when not necessary\n        if len(str(data_str)) < DatasetTable.string_size_thres:\n            return data_str\n        else:\n            return data_str.replace('lightbridge', 'LiBr').replace('bluetooth', 'Blth').replace('zigbee', 'ZgB')\n\n    @staticmethod\n    def table_to_md_mapping(column, rec):\n        \"\"\"\n        Given a recording object, return the metadata info for the table columns\n        \"\"\"\n\n        # Mapping between table columns and recording attributes\n        table_rec_mapping = {\n                'Recording':            rec.name,\n                'Synthetic':            rec.metadata.synthetic,\n                'Sources':              '-' if not rec.metadata.synthetic else ','.join(rec.metadata.sources),\n                'Class':                DatasetTable.get_short_name(','.join(rec.metadata.d_class)),\n                'Channel':              DatasetTable.get_short_name(','.join(rec.metadata.channel)),\n                'Noise level (dB)':     round(rec.metadata.noise_pwr_db, 2),\n                'SNR (dB; estimate)':   DatasetTable.get_short_name(\"%s (%s)\" % (','.join(rec.metadata.snr),\n                                                                                 ','.join(rec.metadata.snr_range))),\n            }\n\n        return table_rec_mapping[column]\n\n    def __init__(self, dataset, csv_file=None, json_file=None):\n\n        # Dataset\n        self.dataset = dataset\n\n        # CSV file\n        self.csv_file = csv_file if csv_file else os.path.join(self.dataset.metadata_dir, \"table_of_contents.csv\")\n\n        # JSON file\n        self.json_file = json_file if json_file else os.path.join(self.dataset.metadata_dir, \"table_of_contents.json\")\n        self.reclist_json_file = os.path.join(self.dataset.metadata_dir, \"list_of_recordings.json\")\n\n        self.table_columns = self.table_format.split(', ')\n        self.table_dict = defaultdict(list)\n\n        for rec in self.dataset.sorted_recordings:\n            for column in self.table_columns:\n                try:\n                    self.table_dict[column].append(DatasetTable.table_to_md_mapping(column, rec))\n                except Exception as e:\n                    print(e, column)\n                    exit()\n\n        self.table = pd.DataFrame(data=self.table_dict)\n        self.table = self.table[self.table_format.split(', ')]\n\n    def get_table_str(self, index=False):\n        \"\"\"\n        Prints the table of contents\n        \"\"\"\n        return self.table.to_string(index=index)\n\n    def save_to_csv(self):\n        \"\"\"\n        Saves the table of contents in the csv file\n        \"\"\"\n        if not self.csv_file:\n            log.error(\"No csv file specified.\")\n            return\n        else:\n            self.table.to_csv(self.csv_file, index=False, encoding='utf8')\n\n    def save_to_json(self):\n        \"\"\"\n        Saves the table of contents in the json file\n        \"\"\"\n        if not self.json_file:\n            log.error(\"No json file specified.\")\n            return\n        else:\n            self.table.to_json(self.json_file)\n\n    def save_reclist_to_json(self):\n        \"\"\"\n        Saves the list of recording names to a json file\n        \"\"\"\n        with open(self.reclist_json_file, 'w') as jw:\n            json.dump(self.dataset.sorted_recording_names, jw)", ""]}
{"filename": "core/frame.py", "chunked_list": ["from __future__ import division\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nfrom copy import deepcopy\n\nCOMMON_NOISE = -45\n\n\nclass Frame(object):\n    def __init__(self, pathname, background_data, width, height):\n        self.width = width\n        self.height = height\n        self.background = background_data\n        self.background_length = self.background.shape[0]\n\n        self.frame_data = deepcopy(background_data)  # Background needs to be full-frame\n\n        self.packets = []  # Packets in the frame\n\n        self.pathname = pathname\n        self.annotation_pathname = pathname[:-4] + \".txt\"\n\n    def add_packet(self, packet, left_offset=None, top_offset=None, noise=None):\n        \"\"\"\n        Add packet to current frame. the background need to be of full-frame.\n        \"\"\"\n        if not noise:\n            noise = COMMON_NOISE\n        packet_data = packet.data\n\n        assert isinstance(left_offset, int) and isinstance(top_offset, int), \\\n            \"The offsets are not properly set!\"\n\n        # Adding packet to the current frame\n        for i in range(top_offset, top_offset + packet.length):\n            for j in range(left_offset, left_offset + packet.width):\n                log_to_pow_bg = pow(10.0, (self.frame_data[i][j] + noise) / 10.0)\n                log_to_pow_trans = pow(10.0, (packet_data[i - top_offset][j - left_offset] + noise) / 10.0)\n                self.frame_data[i][j] = 10 * math.log10(log_to_pow_bg + log_to_pow_trans) - noise\n\n        bottom_offset = self.height - packet.length - top_offset\n\n        # Extracting object frame info\n        box_x_c = left_offset + packet.width / 2\n        # Y-axis will be flipped to make the waterfall plot.\n        box_y_c = self.height - (self.height - bottom_offset + top_offset) / 2\n        box_w = packet.width\n        box_h = packet.length\n        category = packet.category\n\n        # Append the bounding box to annotation file\n        fopen = open(self.annotation_pathname, 'a+')\n        fopen.write(str(category) + \" \" + str(round(box_x_c / self.width, 6)) + \" \" + str(\n            round(box_y_c / self.height, 6)) + \" \" + str(round(box_w / self.width, 6)) + \" \" + str(\n            round(box_h / self.height, 6)) + \"\\n\")\n        fopen.close()\n\n        self.packets.append(packet)\n\n        return\n\n    def convert_image(self, cmap, vmin, vmax):\n        \"\"\"\n        Directly convert 2D data into RGB image data of a spectrogram\n        \"\"\"\n        norm = plt.Normalize(vmin, vmax)\n        return np.flip(np.array(np.floor(cmap(norm(self.frame_data)) * 256)[:, :, :-1]).astype(np.uint8), axis=0)", "\nclass Frame(object):\n    def __init__(self, pathname, background_data, width, height):\n        self.width = width\n        self.height = height\n        self.background = background_data\n        self.background_length = self.background.shape[0]\n\n        self.frame_data = deepcopy(background_data)  # Background needs to be full-frame\n\n        self.packets = []  # Packets in the frame\n\n        self.pathname = pathname\n        self.annotation_pathname = pathname[:-4] + \".txt\"\n\n    def add_packet(self, packet, left_offset=None, top_offset=None, noise=None):\n        \"\"\"\n        Add packet to current frame. the background need to be of full-frame.\n        \"\"\"\n        if not noise:\n            noise = COMMON_NOISE\n        packet_data = packet.data\n\n        assert isinstance(left_offset, int) and isinstance(top_offset, int), \\\n            \"The offsets are not properly set!\"\n\n        # Adding packet to the current frame\n        for i in range(top_offset, top_offset + packet.length):\n            for j in range(left_offset, left_offset + packet.width):\n                log_to_pow_bg = pow(10.0, (self.frame_data[i][j] + noise) / 10.0)\n                log_to_pow_trans = pow(10.0, (packet_data[i - top_offset][j - left_offset] + noise) / 10.0)\n                self.frame_data[i][j] = 10 * math.log10(log_to_pow_bg + log_to_pow_trans) - noise\n\n        bottom_offset = self.height - packet.length - top_offset\n\n        # Extracting object frame info\n        box_x_c = left_offset + packet.width / 2\n        # Y-axis will be flipped to make the waterfall plot.\n        box_y_c = self.height - (self.height - bottom_offset + top_offset) / 2\n        box_w = packet.width\n        box_h = packet.length\n        category = packet.category\n\n        # Append the bounding box to annotation file\n        fopen = open(self.annotation_pathname, 'a+')\n        fopen.write(str(category) + \" \" + str(round(box_x_c / self.width, 6)) + \" \" + str(\n            round(box_y_c / self.height, 6)) + \" \" + str(round(box_w / self.width, 6)) + \" \" + str(\n            round(box_h / self.height, 6)) + \"\\n\")\n        fopen.close()\n\n        self.packets.append(packet)\n\n        return\n\n    def convert_image(self, cmap, vmin, vmax):\n        \"\"\"\n        Directly convert 2D data into RGB image data of a spectrogram\n        \"\"\"\n        norm = plt.Normalize(vmin, vmax)\n        return np.flip(np.array(np.floor(cmap(norm(self.frame_data)) * 256)[:, :, :-1]).astype(np.uint8), axis=0)", ""]}
{"filename": "core/_metadata.py", "chunked_list": ["\"\"\"\nDefinition of the metadata structures of the dataset\n\nRecordingMetadata\nDatasetMetadata\n\"\"\"\nimport os\nimport json\nimport datetime\nimport logging", "import datetime\nimport logging\n\nfrom ._utils import *\nfrom . import constants\n\nfrom textwrap import dedent\n\n__all__ = ['RecordingMetadata', 'DatasetMetadata']\n", "__all__ = ['RecordingMetadata', 'DatasetMetadata']\n\nlog = logging.getLogger('spread')\n\n\nclass RecordingMetadata(object):\n    \"\"\"\n    Represents an instance of recording metadata.\n\n    This includes information about the actual recording such as date created, duration, or transmission infromation.\n\n    If the recording is synthetic, it also includes information about the way the recording was created, the source\n    files, etc.\n    \"\"\"\n\n    @staticmethod\n    def get_rec_metafile(recfile):\n        \"\"\"\n        Returns the metadata file of the recording.\n        Looks for a JSON file in the same directory as the recording with the same prefix\n        :param recfile: path to recording file\n        :return: recording metadata file (.json)\n        \"\"\"\n        recfile = os.path.abspath(recfile)\n        return os.path.splitext(recfile)[0]+'.json'\n        # if os.path.isfile(os.path.splitext(recfile)[0]+'.json'):\n        #     return os.path.splitext(recfile)[0]+'.json'\n        # else:\n        #     return None\n\n    @classmethod\n    def combine_metadata(cls, recording, from_md):\n        \"\"\"\n        Combines multiple metadata objects into a new metadata object. Used for the creation of synthetic data.\n        @param recording: synthetic recording object to create metadata for\n        @param from_md: Source metadata objects\n        @return: Combined metadata object\n        \"\"\"\n        # Initial values for the synthetic metadata\n        combined = {\n            'date_recorded': datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S'),\n            'classes': ','.join([x for y in from_md for x in y.d_class]),\n            'noise_db': add_noise_levels([x.noise_pwr_db for x in from_md]),\n            'synthetic': True,\n            'sources': ','.join([x.rec_name for x in from_md]),\n            'rec_name': recording.name,\n            'duration': min([x.duration for x in from_md]),\n        }\n\n        initial_combined_keys = list(combined.keys())\n\n        for md in from_md:\n            for key in md.metadata:\n                if key in initial_combined_keys + ['freq_sweep', 'no_of_pictures', 'file_size']:\n                    continue\n\n                if key == \"tx\":\n                    new_value = md.metadata[key]\n                else:\n                    new_value = md.metadata['classes']+'_'+str(md.metadata[key])\n                # If the key already exists include the new metadata separated by commas\n                if key in combined:\n                    combined[key] += ',' + new_value\n                # Else create it\n                else:\n                    combined[key] = new_value\n        return cls(recording, md_from_dict=combined)\n\n    def __init__(self, recording, md_from_dict=None):\n\n        # Initial metadata\n        if md_from_dict:\n            self._metadata = md_from_dict              # Initialize metadata dict\n        else:\n            self._metadata = {}\n\n        self.recording = recording\n\n        # Metadata file\n        self.metafile = RecordingMetadata.get_rec_metafile(recording.recfile)\n\n        # Parse the recording metadata to retrieve properties\n        if not self._metadata:\n            if self.metafile:\n                if os.path.isfile(self.metafile):\n                    self.load_metadata()\n\n        self.rec_name = self._gets('rec_name')\n        self._synthetic = self._getb('synthetic')\n        self.sources = self._gets('sources').split(',')\n        self.date_recorded = self._gets('date_recorded')\n        self.d_class = (self._gets('class') or self._gets('classes')).split(',')\n        self.duration = self._geti('duration')\n\n        self.channel = (self._gets('channel') or self._gets('channels')).split(',')\n        self.cfreq = (self._gets('cfreq') or self._gets('fc')).split(',')\n        self.samp_rate = self._gets('samp_rate').split(',')\n        self.noise_pwr_db = self._getf('noise_pwr_db') or self._getf('noise_db')\n        self.noise_variance = self._getf('noise_variance')\n        self.snr = self._gets('snr').split(',')\n        self._snr_range = self._gets('snr_range').split(',')\n\n        if not self._snr_range or self._snr_range == [''] or self._snr_range == ['n/a'] or \\\n                ''.join(self._snr_range) == 'n/a':\n            self._set_md_value('snr_range', ','.join(self._get_snr_range()))\n            self._snr_range = self._gets('snr_range').split(',')\n\n        # If the transmission was a frequency sweep, the information is stored in this dictionary in order to be parsed\n        self.freq_sweep = self._get_md_value('freq_sweep')\n\n        self.transmission = self._gets('transmission')      # Transmission (continuous or interval)\n        self.type = self._gets('type')                      # Type of transmission(data, control, ping, n/a)\n\n        self.no_of_pictures = self._geti('no_of_pictures')\n        self.file_size = self._gets('file_size')\n\n    def load_metadata(self):\n        \"\"\"\n        Parses the metafile and stores metadata in a dictionary\n        \"\"\"\n        try:\n            with open(self.metafile, \"r\") as mf:\n                self._metadata = json.load(mf)\n        # Some metadata files have an extra closing bracket when multiprocessing is used\n        except ValueError:\n            # Try fixing a recognized pattern\n            with open(self.metafile, \"r\") as mf:\n                meta_contents = mf.read().strip()\n            if meta_contents[-2:] == \"}}\":\n                meta_contents = meta_contents[:-1]\n            try:\n                self._metadata = json.loads(meta_contents)\n            except ValueError:\n                recname = self.recording.name if self.recording else None\n                log.error(\"Error loading metadata for recording: %s\", recname)\n                self._metadata = {}\n\n        # Rename potentially old fields\n        renamed_keys = {\n            \"class\": \"classes\",\n            \"channel\": \"channels\",\n            \"cfreq\": \"fc\",\n            \"noise_pwr_db\": \"noise_db\",\n        }\n        for renamed_key in renamed_keys.keys():\n            if renamed_key in self._metadata.keys():\n                self._metadata[renamed_keys.get(renamed_key)] = self._metadata.pop(renamed_key)\n\n    def store_metadata(self):\n        \"\"\"\n        Stores the current metadata dictionary in the metafile, overwriting the previous contents.\n        \"\"\"\n        if self._metadata:\n            with open(self.metafile, \"w\") as mf:\n                json.dump(self._metadata, mf)\n\n    @property\n    def metadata(self):\n        \"\"\"\n        Returns the dictionary containing the recording metadata\n        \"\"\"\n        return self._metadata\n\n    @property\n    def synthetic(self):\n        \"\"\"\n        Returns True if the recording is synthetic\n        \"\"\"\n        return self._synthetic\n\n    @property\n    def snr_range(self):\n        \"\"\"\n        Returns the snr range of the recording out of 'low', 'mid', 'high'.\n        \"\"\"\n        return self._snr_range\n\n    def _get_snr_range(self):\n        \"\"\"\n        Categorizes the SNR of the recording in a range of LOW, MID, HIGH, depending on the class and SNR value\n        Different transmissions have different depiction in the pictures based on their type and snr value. This\n        classification as high, mid, or low is just meant to help with the analysis and prediction workflow.\n        \"\"\"\n\n        # SNR ranges are defined in the constants.py\n        snr_ranges = constants.SNR_RANGES\n        ret = []\n        for i in range(len(self.d_class)):\n            rec_class = self.d_class[i]\n            try:\n                snr = self.snr[i].lstrip(\"%s_\" % self.d_class[i])\n                snr = round(float(snr), 2)\n            except ValueError:\n                return 'n/a'\n\n            # For the class in question, identify the range the SNR falls into\n            for thres in snr_ranges[rec_class]:\n                if snr > thres:\n                    ret.append(snr_ranges['label'][snr_ranges[rec_class].index(thres)])\n                    break\n                continue\n        return ret\n\n    def _geti(self, value, default=0):\n        \"\"\"\n        Return the metadata value as an int\n        \"\"\"\n        try:\n            ret_value = int(self._get_md_value(value, default))\n        except ValueError:\n            ret_value = default\n            log.error(\"Error trying to load the proper value for %s. Loading default value: %s.\", value, default)\n        return ret_value\n\n    def _geti_list(self, value, default=None):\n        \"\"\"\n        Return the metadata value as a list of ints parsed from a comma separated string\n        \"\"\"\n        if default is None:\n            default = [0]\n        ret_value = self._get_md_value(value, default)\n        ret_value = ret_value.split(',')\n        return [int(x) if x else 0 for x in ret_value]\n\n    def _getf(self, value, default=0.0):\n        \"\"\"\n        Return the metadata value as a float\n        \"\"\"\n        try:\n            ret_value = float(self._get_md_value(value, default))\n        except ValueError:\n            ret_value = default\n            log.error(\"Error trying to load the proper value for %s. Loading default value: %s.\", value, default)\n        return ret_value\n\n    def _getf_list(self, value, default=None):\n        \"\"\"\n        Return the metadata value as a list of floats parsed from a comma separated string\n        \"\"\"\n        if default is None:\n            default = [0.0]\n        ret_value = self._get_md_value(value, default)\n        ret_value = ret_value.split(',')\n        return [float(x) if x else 0.0 for x in ret_value]\n\n    def _gets(self, value, default=''):\n        \"\"\"\n        Return the metadata value as a string\n        \"\"\"\n        try:\n            ret_value = str(self._get_md_value(value, default))\n        except ValueError:\n            ret_value = default\n            log.error(\"Error trying to load the proper value for %s. Loading default value: %s.\", value, default)\n        return ret_value\n\n    def _getb(self, value, default=None):\n        \"\"\"\n        Return the metadata value as boolean\n        \"\"\"\n        return True if self._get_md_value(value, default).lower() == 'true' else False\n\n    def _get_md_value(self, value, default=None):\n        return str(self._metadata.get(value, default))\n\n    def _set_md_value(self, key, value):\n        \"\"\"\n        Modifies or adds a metadata key value. Used only for development purposes\n        \"\"\"\n        self._metadata.update({key: value})\n\n    def get_md_string(self):\n        \"\"\"\n        Returns a string containing the metadata info for screen printing purposes\n        \"\"\"\n        md_str = \"\"\"\\\n                Name of recording: %s\n                Synthetic: %s\n                Sources: %s\n                Center frequency: %s\n                Sample rate: %s\n                Duration: %s\n                Class(es): %s\n                Type: %s\n                Channel(s): %s\n                Transmission(s): %s\n                Noise level in dB: %s\n                SNR: %s\n                SNR Range(s): %s\n                Number of pictures: %s\n                \"\"\" % (\n                        self.rec_name,\n                        self.synthetic,\n                        ','.join(self.sources),\n                        ','.join(self.cfreq),\n                        ','.join(self.samp_rate),\n                        self.duration,\n                        ','.join(self.d_class),\n                        self.type,\n                        ','.join(self.channel),\n                        self.transmission,\n                        self.noise_pwr_db,\n                        ','.join(self.snr),\n                        ','.join(self.snr_range),\n                        self.no_of_pictures\n                        )\n        return dedent(md_str)", "\n\nclass DatasetMetadata(object):\n    \"\"\"\n    Represents an instance of dataset metadata.\n\n    This can be information like size, number of recordings or pictures, types of classes, and so on.\n    \"\"\"\n    def __init__(self, ds):\n        self.dataset = ds\n        self.ds_md_folder = os.path.join(self.dataset.root_dir, 'metadata')\n\n        if not os.path.isdir(self.ds_md_folder):\n            os.mkdir(self.ds_md_folder)\n\n        self.class_names_file = os.path.join(self.ds_md_folder, \"classes.json\")\n\n        self.classes = self.load_class_names()\n\n    def load_class_names(self):\n        \"\"\"Load the dictionary containing class names and indices from the dataset metadata.\"\"\"\n        if os.path.isfile(self.class_names_file):\n            with open(self.class_names_file, 'r') as cf:\n                class_dict = json.load(cf)\n        else:\n            class_dict = dict()\n        return class_dict", ""]}
{"filename": "core/packet.py", "chunked_list": ["from copy import deepcopy\nimport numpy as np\n\nclass Packet(object):\n    def __init__(self, data, category, var_length=True):\n        self.data = deepcopy(data)                  # should be numpy array\n        self.length = data.shape[0]\n        self.width = data.shape[1]\n        self.category = category\n        self.var_length = var_length    # Indicate if packet length is variable\n\n    def adjust_snr(self, attennuation, limit_thres=0):\n        self.data[self.data>limit_thres] -= attennuation        # Decrease the snr globally\n        return\n\n\n    def adjust_length(self, target_length, cushion=20):\n        if target_length <= self.length:\n            tail = target_length/2\n            self.data = np.vstack((self.data[:tail,...], self.data[-(target_length-tail):, ...]))\n            self.length = target_length\n            assert self.length == self.data.shape[0]    # Check the length consistency\n        else:           # If we wish to extend, stacking the last part of a packet to the existing data...\n            if self.length < cushion:\n                print(\"Packet is too short. No need to adjust.\")\n                return\n\n            stacked_data = deepcopy(self.data[:-cushion,...])\n\n            while stacked_data.shape[0] < target_length:    # Stacking until we fill up the gap between target_length and data length.\n                gap = target_length-stacked_data.shape[0]\n                if gap < self.length-cushion:               # Partial stacking\n                    stacked_data = np.vstack((stacked_data, self.data[-gap:,...]))\n                else:                                       # Full stacking\n                    stacked_data = np.vstack((stacked_data, self.data[cushion:-cushion,...]))\n\n            # Check the data and update the attributes\n            assert stacked_data.shape[0] == target_length\n\n            self.data = stacked_data\n            self.length = target_length\n\n        return"]}
{"filename": "core/_utils.py", "chunked_list": ["\"\"\"\nUtils file that defines miscellaneous functions\n\"\"\"\n\nimport math\nimport struct\nfrom . import constants\nimport numpy as np\nfrom random import choice\nfrom PIL import Image", "from random import choice\nfrom PIL import Image\n\n\ndef pwr_to_db(pwr):\n    \"\"\"\n    Returns the power in dB\n    \"\"\"\n    return 10*math.log10(pwr)\n", "\n\ndef db_to_pwr(db_lvl):\n    \"\"\"\n    Returns the absolute power\n    \"\"\"\n    return 10**(db_lvl/10.0)\n\n\ndef add_noise_levels(db_noise_levels):\n    \"\"\"\n    Gets a list of noise levels and returns the additive noise in dB\n    \"\"\"\n    absolute_noise_levels = [db_to_pwr(x) for x in db_noise_levels]\n    sum_noise = sum(absolute_noise_levels)\n    return pwr_to_db(sum_noise)", "\ndef add_noise_levels(db_noise_levels):\n    \"\"\"\n    Gets a list of noise levels and returns the additive noise in dB\n    \"\"\"\n    absolute_noise_levels = [db_to_pwr(x) for x in db_noise_levels]\n    sum_noise = sum(absolute_noise_levels)\n    return pwr_to_db(sum_noise)\n\n\ndef load_bytes_from_fd(fd, start=None, end=None):\n    \"\"\"\n    Reads `batch` number of samples from a file descriptor into a tuple and returns the tuple\n    \"\"\"\n    if start:\n        fd.seek(start)\n    binary = fd.read(end-start)\n    syntax = str(len(binary) / 4) + \"f\"\n    try:\n        data = struct.unpack(syntax, binary)\n        return data\n    except struct.error:        # not enough bytes to unpack, end of binary\n        return None", "\n\ndef load_bytes_from_fd(fd, start=None, end=None):\n    \"\"\"\n    Reads `batch` number of samples from a file descriptor into a tuple and returns the tuple\n    \"\"\"\n    if start:\n        fd.seek(start)\n    binary = fd.read(end-start)\n    syntax = str(len(binary) / 4) + \"f\"\n    try:\n        data = struct.unpack(syntax, binary)\n        return data\n    except struct.error:        # not enough bytes to unpack, end of binary\n        return None", "\n\ndef load_array_from_fd(fd):\n    \"\"\"Loads a numpy array from given file descriptor\"\"\"\n    try:\n        return np.load(fd)\n    except (IOError, ValueError):\n        return None\n\n\ndef data_reshape(data, step, nfft):\n    \"\"\"\n    Reshape the array of data to form I,Q pairs\n    \"\"\"\n    return np.reshape(data, (step, nfft))", "\n\ndef data_reshape(data, step, nfft):\n    \"\"\"\n    Reshape the array of data to form I,Q pairs\n    \"\"\"\n    return np.reshape(data, (step, nfft))\n\n\ndef append_samples_to_file(filename, samples):\n    \"\"\"\n    Appends the samples to file\n    \"\"\"\n    syntax = str(len(samples))+'f'\n    binary = struct.pack(syntax, *samples)\n    with open(filename, 'ab') as of:\n        of.write(binary)", "\ndef append_samples_to_file(filename, samples):\n    \"\"\"\n    Appends the samples to file\n    \"\"\"\n    syntax = str(len(samples))+'f'\n    binary = struct.pack(syntax, *samples)\n    with open(filename, 'ab') as of:\n        of.write(binary)\n", "\n\ndef data_clip(data, min_snr, max_snr):\n    \"\"\"\n    Clip the lower and upper values in a matrix\n    \"\"\"\n    if min_snr is not None:\n        data[data < min_snr] = min_snr\n    if max_snr is not None:\n        data[data > max_snr] = max_snr\n    return data", "\n\ndef img_scale(data, min_snr, max_snr):\n    \"\"\"\n    Assuming data is already clipped\n    \"\"\"\n    return ((data-min_snr).astype(float)/(max_snr-min_snr)*255).astype(np.uint8)\n\n\ndef img_flip(data, ax=0):\n    \"\"\"\n    Flip array along an axis\n    \"\"\"\n    return np.flip(data, axis=ax)", "\ndef img_flip(data, ax=0):\n    \"\"\"\n    Flip array along an axis\n    \"\"\"\n    return np.flip(data, axis=ax)\n\n\ndef stack_image_channels(img_data):\n    \"\"\"\n    Stack image channels assuming array is 2D\n    \"\"\"\n    return np.stack((img_data, img_data, img_data), axis=-1)", "def stack_image_channels(img_data):\n    \"\"\"\n    Stack image channels assuming array is 2D\n    \"\"\"\n    return np.stack((img_data, img_data, img_data), axis=-1)\n\n\ndef check_collision(left_offset1, width1, range2, width2, error=5):\n    \"\"\"\n    Checking if collision between two packets is possible\n    \"\"\"\n    lo2_choices = []\n    for lo2 in range2:\n        if left_offset1 > lo2 + width2 - error:\n            continue\n\n        if lo2 > left_offset1 + width1 - error:\n            break\n\n        lo2_choices.append(lo2)\n\n    if len(lo2_choices) < 1:    # Collision is not possible\n        return False, None\n    else:\n        return True, choice(lo2_choices)", "\n\ndef spectro_plot(data_img, img_name=None, display=True, save=False):\n    \"\"\"\n    Show or save an image from a given array\n    \"\"\"\n    im = Image.fromarray(data_img)\n    if save:\n        im.save(img_name)\n    elif display:\n        im.show()\n    return", "\n\ndef convert_size(size_bytes, back=False):\n    \"\"\"\n    Converts a size value to string and back using the hurry module. If hurry is not found, standard conversion is used.\n    @param size_bytes:\n    @param back:\n    @return:\n    \"\"\"\n    try:\n        # Try to import hurry filesize for more readable output\n        from hurry.filesize import size as h_size, si           # (system si assumes 1K == 1000 instead of 1024)\n        # For back conversion, return absolute bytes size given a string as input\n        if back:\n            # If si is used the mapping is\n            back_map = {x[1]: x[0] for x in si}\n            # # Else\n            # back_map = {'B': 1, 'G': 1073741824, 'K': 1024, 'M': 1048576, 'P': 1125899906842624, 'T': 1099511627776}\n            try:\n                return int(size_bytes[:-1])*back_map[size_bytes[-1]] if size_bytes != '0' else 0\n            except ValueError as e:\n                print (e)\n                return None\n        else:\n            return h_size(size_bytes, system=si)\n    # If package is not installed, print out in bytes\n    except ImportError:\n        if back:\n            return int(size_bytes[:-1]) * constants.UNITS[size_bytes[-1]] if size_bytes != '0' else 0\n        else:\n            return \"%sB\" % size_bytes", "\n\ndef total_size(size_strs):\n    \"\"\"\n    Given a list of strings [1G, 500M, 2.5T] it calculates and returns a string with the total size\n    \"\"\"\n    size_sum = sum([convert_size(x, back=True) for x in size_strs if x])\n    try:\n        # Try to import hurry filesize for more readable output\n        # noinspection PyUnresolvedReferences\n        from hurry.filesize import size as h_size, si           # (system si assumes 1K == 1000 instead of 1024)\n        total_size_str = h_size(size_sum, system=si)\n    except ImportError:\n        # Package not installed\n        total_size_str = \"%sB\\t(Please install hurry.filesize package (pip install hurry.filesize)\\\n for more readable output)\" % size_sum\n    return total_size_str", "\n\ndef convert_freq(freq, back=False):\n    \"\"\"Convert freq values from string to absolute value and back\"\"\"\n    if back:\n        return \"%s Hz\" % freq\n    else:\n        if not freq:\n            return 0.0\n        return float(freq[:-1]) * constants.UNITS[freq[-1]]  # if freq != '0.0' else 0.0", "\n\ndef get_pairs(item_list):\n    \"\"\"\n    Given a list of items, returns all possible pair combinations.\n    \"\"\"\n    pairs = []\n    for i in item_list[:-1]:\n        pairs.extend([(i, j) for j in item_list[item_list.index(i)+1:len(item_list)]])\n    return pairs", "\n\ndef get_id_from_pic_name(picname):\n    \"\"\"\n    Returns the ID of a (compressed) picture/annotation.\n\n    Naming format is: <recording prefix>_<rec_ID>_pic_<pic_ID>.<jpg,txt>\n    \"\"\"\n    pic_id = picname.split(\".\")[0].split(\"_\")[-1]\n    try:\n        if isinstance(pic_id, str) and \"grsc\" in pic_id:\n            pic_id = pic_id.replace(\"grsc\", \"\")\n        pic_id = int(pic_id)\n    except ValueError:\n        pic_id = -1\n    return pic_id", "\n\ndef do_collide(transmissions):\n    \"\"\"\n    Returns true if any pair of transmission settings (class and channel) in the given list causes a collision.\n    \"\"\"\n    for i in transmissions[:-1]:\n        if i[0] == 1 or i[0] == 4:\n            continue\n        for j in transmissions[transmissions.index(i)+1:]:\n            if j[0] == 1 or j[0] == 4:\n                continue\n            i_cf = constants.CHANNELS[i[0]][0][i[1]]\n            i_bw = constants.CHANNELS[i[0]][1]\n            i_range = (i_cf - i_bw / 2.0, i_cf + i_bw / 2.0)\n            j_cf = constants.CHANNELS[j[0]][0][j[1]]\n            j_bw = constants.CHANNELS[j[0]][1]\n            j_range = (j_cf - j_bw / 2.0, j_cf + j_bw / 2.0)\n            # print(\"%s %s\" % ((i_range[0]-j_range[0]), (i_range[1]-i_range[1])))\n            if (i_range[0]-j_range[0]) * (i_range[1]-j_range[1]) < 0:\n                return True\n    return False", ""]}
{"filename": "core/_plotter.py", "chunked_list": ["\"\"\"\nHelper class to plot interactive images with matplotlib\n\"\"\"\nfrom os.path import join\nimport logging\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom matplotlib.widgets import RectangleSelector\n\n", "\n\n__all__ = ['Plotter']\n\nlogging.getLogger('matplotlib').setLevel(logging.WARNING)\nlog = logging.getLogger('spread')\n\n\nclass Plotter(object):\n    \"\"\"\n    Represents an instance of plotter for the Recording class\n    \"\"\"\n\n    @staticmethod\n    def _get_image_from_data(data, mode=None):\n        try:\n            im = Image.fromarray(data, mode=mode)\n            return im\n        except AttributeError:\n            return None\n\n    @staticmethod\n    def onkeypress(event):\n        \"\"\"Experimental function to test key press\"\"\"\n        if event.key == 'q':\n            pass\n            # print('event is q')\n\n    @staticmethod\n    def toggle_selector(event):\n        \"\"\"Activate the mouse click\"\"\"\n        Plotter.toggle_selector.RS.set_active(True)\n\n    def __init__(self):\n        \"\"\"Instance of plotter helper class\"\"\"\n\n        self.selected_areas = None\n\n    def area_borders(self):\n        \"\"\"Return the borders of the selected area\"\"\"\n        left = int(min(self.selected_areas[0], self.selected_areas[2]))\n        right = int(max(self.selected_areas[0], self.selected_areas[2]))\n        bottom = int(max(self.selected_areas[1], self.selected_areas[3]))\n        up = int(min(self.selected_areas[1], self.selected_areas[3]))\n        return left, right, bottom, up\n\n    def pretty_area_print(self):\n        \"\"\"Return a string descrptions of the selected area for prettier output\"\"\"\n        return \"Left: %s\\n\" \\\n               \"Right: %s \\n\" \\\n               \"Bottom: %s \\n\" \\\n               \"Up: %s\" % self.area_borders()\n\n    def plot(self, im=None, data=None, subplot=None, outfile=None, figdir=None, resize=None, options=None):\n        \"\"\"\n        Plot function either plots in a given subplot and returns the subplot or saves the image to a file.\n        \"\"\"\n\n        im = im if im else Plotter._get_image_from_data(data)\n\n        if resize:\n            im = im.resize(resize)\n\n        if not im:\n            log.error(\"Nothing to plot.\")\n            return None\n\n        if subplot is not None:\n            self._plot(im, subplot, options)\n        else:\n            Plotter._save_image(im, outfile, figdir)\n\n    def _line_select_callback(self, clk, rls):\n        \"\"\"\n        Handles mouse events to trigger noise area selection or image selection\n        \"\"\"\n        self.selected_areas = [clk.xdata, clk.ydata, rls.xdata, rls.ydata]\n\n    def _plot(self, im, subplot, options):\n        \"\"\"Plot image either with pillow or matlab for more options\"\"\"\n        if subplot == \"pillow\":\n            im.show()\n        else:\n            subplot.imshow(im)\n            if options:\n                if options.get('noise_input', None):\n                    Plotter.toggle_selector.RS = RectangleSelector(\n                        subplot, self._line_select_callback, useblit=True, button=[1], minspanx=5,\n                        minspany=5, spancoords='pixels', interactive=True\n                    )\n                    noise_box = plt.connect('key_press_event', Plotter.toggle_selector)\n\n                if options.get('button', None):\n                    # Expect a list of dict for buttons\n                    for btn in options.get('button'):\n                        btn_label = btn.get('label', '')\n\n                        # Button position as in [left, bottom, width, height]\n                        btn_position = btn.get('position', None)\n\n                        btn_action = btn.get('action')()\n\n            plt.show()\n        pass\n\n    @staticmethod\n    def _save_image(im, outfile, figdir):\n        \"\"\"Save image to file\"\"\"\n        img_name = join(figdir, outfile)\n        im.save(img_name)", "class Plotter(object):\n    \"\"\"\n    Represents an instance of plotter for the Recording class\n    \"\"\"\n\n    @staticmethod\n    def _get_image_from_data(data, mode=None):\n        try:\n            im = Image.fromarray(data, mode=mode)\n            return im\n        except AttributeError:\n            return None\n\n    @staticmethod\n    def onkeypress(event):\n        \"\"\"Experimental function to test key press\"\"\"\n        if event.key == 'q':\n            pass\n            # print('event is q')\n\n    @staticmethod\n    def toggle_selector(event):\n        \"\"\"Activate the mouse click\"\"\"\n        Plotter.toggle_selector.RS.set_active(True)\n\n    def __init__(self):\n        \"\"\"Instance of plotter helper class\"\"\"\n\n        self.selected_areas = None\n\n    def area_borders(self):\n        \"\"\"Return the borders of the selected area\"\"\"\n        left = int(min(self.selected_areas[0], self.selected_areas[2]))\n        right = int(max(self.selected_areas[0], self.selected_areas[2]))\n        bottom = int(max(self.selected_areas[1], self.selected_areas[3]))\n        up = int(min(self.selected_areas[1], self.selected_areas[3]))\n        return left, right, bottom, up\n\n    def pretty_area_print(self):\n        \"\"\"Return a string descrptions of the selected area for prettier output\"\"\"\n        return \"Left: %s\\n\" \\\n               \"Right: %s \\n\" \\\n               \"Bottom: %s \\n\" \\\n               \"Up: %s\" % self.area_borders()\n\n    def plot(self, im=None, data=None, subplot=None, outfile=None, figdir=None, resize=None, options=None):\n        \"\"\"\n        Plot function either plots in a given subplot and returns the subplot or saves the image to a file.\n        \"\"\"\n\n        im = im if im else Plotter._get_image_from_data(data)\n\n        if resize:\n            im = im.resize(resize)\n\n        if not im:\n            log.error(\"Nothing to plot.\")\n            return None\n\n        if subplot is not None:\n            self._plot(im, subplot, options)\n        else:\n            Plotter._save_image(im, outfile, figdir)\n\n    def _line_select_callback(self, clk, rls):\n        \"\"\"\n        Handles mouse events to trigger noise area selection or image selection\n        \"\"\"\n        self.selected_areas = [clk.xdata, clk.ydata, rls.xdata, rls.ydata]\n\n    def _plot(self, im, subplot, options):\n        \"\"\"Plot image either with pillow or matlab for more options\"\"\"\n        if subplot == \"pillow\":\n            im.show()\n        else:\n            subplot.imshow(im)\n            if options:\n                if options.get('noise_input', None):\n                    Plotter.toggle_selector.RS = RectangleSelector(\n                        subplot, self._line_select_callback, useblit=True, button=[1], minspanx=5,\n                        minspany=5, spancoords='pixels', interactive=True\n                    )\n                    noise_box = plt.connect('key_press_event', Plotter.toggle_selector)\n\n                if options.get('button', None):\n                    # Expect a list of dict for buttons\n                    for btn in options.get('button'):\n                        btn_label = btn.get('label', '')\n\n                        # Button position as in [left, bottom, width, height]\n                        btn_position = btn.get('position', None)\n\n                        btn_action = btn.get('action')()\n\n            plt.show()\n        pass\n\n    @staticmethod\n    def _save_image(im, outfile, figdir):\n        \"\"\"Save image to file\"\"\"\n        img_name = join(figdir, outfile)\n        im.save(img_name)", ""]}
{"filename": "core/__init__.py", "chunked_list": ["\"\"\"Core module\"\"\"\nfrom ._dataset import *\nfrom ._recording import *\nfrom ._metadata import *\nfrom ._utils import *\nfrom ._annotation import Annotation\nfrom . import constants\nfrom ._plotter import *\nfrom gen_pics import plot_recording\nfrom frame import Frame", "from gen_pics import plot_recording\nfrom frame import Frame\nfrom packet import Packet\n"]}
{"filename": "core/constants.py", "chunked_list": ["\"\"\"\nConstant values for the dataset toolset\n\"\"\"\nCLASSES = {\n    0: 'wifi',\n    1: 'bluetooth',\n    2: 'zigbee',\n    3: 'lightbridge',\n    4: 'wmic'\n}", "    4: 'wmic'\n}\n\nCLASS_INDEX = {CLASSES[x]: x for x in CLASSES}\n\nCOLORS = {\n    0: (82, 250, 88),\n    1: (231, 242, 80),\n    2: (240, 31, 38),\n    3: (122, 57, 95),", "    2: (240, 31, 38),\n    3: (122, 57, 95),\n    4: (43, 168, 224),\n}\n\nUNITS = {\n    'Hz': 1,\n    'B': 1,\n    'K': 1e3,\n    'M': 1e6,", "    'K': 1e3,\n    'M': 1e6,\n    'G': 1e9,\n    'T': 1e12,\n}\n\n# SNR ranges for each class were identified heuristically and are defined here\nSNR_RANGES = {\n    'label': ['high', 'mid', 'low'],\n    'wifi': [27, 15, 0],", "    'label': ['high', 'mid', 'low'],\n    'wifi': [27, 15, 0],\n    'bluetooth': [22, 13, 0],\n    'zigbee': [27, 13, 0],\n    'lightbridge': [27, 13, 0],\n    'wmic': [22, 15, 0],\n}\n\n# Thresholds for merging annotation boxes\n# (different for each class depending on the possible overlapping with the adjacent channels", "# Thresholds for merging annotation boxes\n# (different for each class depending on the possible overlapping with the adjacent channels\nSIDE_THRESHOLD = {\n    0: 0.1,\n    1: 0.3,\n    2: 0.5,\n    3: 0.5,\n    4: 0.5,\n}\n", "}\n\nTIME_THRESHOLD = {\n    0: 2 / 512.0,\n    1: 1 / 512.0,\n    2: 1 / 512.0,\n    3: 2 / 512.0,\n    4: 2 / 512.0,\n}\n", "}\n\n# RF characteristics of the classes for all channels as a tuple of center frequencies and bw\nCHANNELS = {\n    0: ({x: y for x, y in zip(range(14), range(2412, 2475, 5))}, 22),\n    1: ({x: y for x, y in zip(['n/a'], ['n/a'])}, 1),\n    2: ({x: y for x, y in zip(range(11, 27), range(2405, 2485, 5))}, 2),\n    3: ({x: y for x, y in zip(range(13, 21), range(2406, 2476, 10))}, 10),\n    4: ({x: y for x, y in zip(['n/a'], ['n/a'])}, 2),\n}", "    4: ({x: y for x, y in zip(['n/a'], ['n/a'])}, 2),\n}\n\n\"\"\"\nConstant values for the augmentation script\n\"\"\"\n\nCATEGORIES = {\n    -1: {\"main\": \"background\", \"element\": [\"background\"]},\n    0: {\"main\": \"wifi\", \"element\": [\"wifi_1\", \"wifi_2\"]},", "    -1: {\"main\": \"background\", \"element\": [\"background\"]},\n    0: {\"main\": \"wifi\", \"element\": [\"wifi_1\", \"wifi_2\"]},\n    1: {\"main\": \"bluetooth\", \"element\": [\"bt_1\", \"bt_2\"]},\n    2: {\"main\": \"zigbee\", \"element\": [\"zigbee\"]},\n    3: {\"main\": \"lightbridge\", \"element\": [\"lightbridge\"]},\n    4: {\"main\": \"wmic\", \"element\": [\"wmic\"]}\n}\n\nMOLD_PATHS = {\n    'background': 'augmentation_data/molds/background.npy',", "MOLD_PATHS = {\n    'background': 'augmentation_data/molds/background.npy',\n    'wifi_1': 'augmentation_data/molds/wifi_1.npy',\n    'wifi_2': 'augmentation_data/molds/wifi_2.npy',\n    'bt_1': 'augmentation_data/molds/bt_1.npy',\n    'bt_2': 'augmentation_data/molds/bt_2.npy',\n    'zigbee': 'augmentation_data/molds/zigbee.npy',\n    'lightbridge': 'augmentation_data/molds/lightbridge.npy',\n    'wmic': 'augmentation_data/molds/wmic.npy',\n}", "    'wmic': 'augmentation_data/molds/wmic.npy',\n}\n\nVAR = {\n    'background': None,\n    'wifi_1': True,\n    'wifi_2': False,\n    'bt_1': True,\n    'bt_2': True,\n    'zigbee': True,", "    'bt_2': True,\n    'zigbee': True,\n    'lightbridge': True,\n    'wmic': True,\n}\n\n# Mimicking wireless channels.\n# Recording frequency range 2390 - 2490\nAUGMENT_CHANNELS = {\n    0: {'start': 56, 'space': 25, 'skip': 2},", "AUGMENT_CHANNELS = {\n    0: {'start': 56, 'space': 25, 'skip': 2},\n    # WiFi: From 2401 MHz -> (2401-2390)/100*512 ~ 56, channel splace 5 MHz -> 5/100*512 ~25\n    1: {'start': 56, 'space': 10, 'skip': 5},\n    # Bluetooth (Considering BLE): From 2401 MHz -> (2401-2390)/100*512 ~ 56, channel splace 2 MHz -> 2/100*512 ~ 10\n    2: {'start': 71, 'space': 25, 'skip': 2},\n    # Zigbee: From 2404 MHz -> (2404-2390)/100*512 ~ 71, channel splace 5 MHz -> 5/100*512 ~25\n    3: {'start': 61, 'space': 51, 'skip': 1},\n    # Lightbridge: From 2402 MHz -> (2402-2390)/100*512 ~ 61, channel space 10 MHz -> 10/100*512 ~ 51\n    4: {'start': 56, 'space': 25, 'skip': 2},  # Wireless microphone: Avoid complexity, set it the same as Zigbee.", "    # Lightbridge: From 2402 MHz -> (2402-2390)/100*512 ~ 61, channel space 10 MHz -> 10/100*512 ~ 51\n    4: {'start': 56, 'space': 25, 'skip': 2},  # Wireless microphone: Avoid complexity, set it the same as Zigbee.\n}\n\nLIMIT_INDEX = 476  # Max. freq = 2483 MHz (WiFi), (2483-2390)/100*512 ~ 476\n\n# IMAGE MAPPING\nVMIN = -10\nVMAX = 50\n", "VMAX = 50\n"]}
{"filename": "core/_recording.py", "chunked_list": ["\"\"\"\nRecording class and related functionalities to support the recording object of the Dataset\n\"\"\"\nimport os\nimport sys\nimport glob\nimport subprocess\nimport json\nimport time\nimport logging", "import time\nimport logging\nimport numpy as np\n\nfrom argparse import Namespace\nfrom matplotlib import pyplot as plt\n\ntry:\n    from . import flowgraphs\nexcept SyntaxError:\n    raise Exception(\"Flowgraphs cannot be imported. Please try with Python2.7.\")", "\nfrom . import _metadata as metadata\nfrom . import _utils as utils\nfrom . import _annotation as annotation\nfrom ._plotter import Plotter\nfrom ._annotation import Annotation\nfrom gen_pics import plot_recording\n\n__all__ = ['Recording']\n", "__all__ = ['Recording']\n\nlog = logging.getLogger('spread')\n\n\nclass Recording(object):\n    \"\"\"\n    Represents a recording of the dataset with data parsed from the recording and its metadata\n    \"\"\"\n\n    heuristic_noise_calculation = 5.568650501352949 ** 2\n\n    @staticmethod\n    def get_rec_id(name):\n        \"\"\"\n        Returns the id of the recording when the name format is rec_*\n        \"\"\"\n        try:\n            return int(name.split('_')[-1])\n        except ValueError:\n            return -1\n\n    @staticmethod\n    def get_recname(recfile):\n        \"\"\"\n        Returns recording name based on the given path. The recording name is the basename of\n        the path without any extension.\n        :param recfile: path to recording file\n        :return: recording name\n        \"\"\"\n        recfile = os.path.abspath(recfile)\n        return os.path.splitext(os.path.basename(recfile))[0]\n\n    @staticmethod\n    def get_rectype(recfile):\n        \"\"\"\n        Returns recording type based on the given path.\n        :param recfile: path to recording file\n        :return: recording type\n        \"\"\"\n        recfile = os.path.abspath(recfile)\n        return os.path.splitext(os.path.basename(recfile))[1]\n\n    @classmethod\n    def merge_recordings(cls, rec_objects, outfile=None, mockup=False):\n        \"\"\"\n        Takes multiple recording objects as input and returns one recording object as output\n        :param rec_objects: list of recording objects to merge\n        :param outfile: filepath to save the result\n        :param mockup: If true, don't create the recording, just display the resulting metadata\n        :return Recording: Combined recording object\n        \"\"\"\n        if len(rec_objects) < 2:\n            log.info(\"At least 2 recordings are needed in order to merge...\")\n            return None\n        elif len(rec_objects) > 5:\n            log.info(\"Merging of more than 5 recordings is not implemented\")\n            return None\n        else:\n            ds = rec_objects[0].dataset\n            if not outfile:\n                outfile = ds.get_synthetic_outfile()\n                if not outfile:\n                    log.error(\"Error determining synthetic filename\")\n                    sys.exit(-1)\n                outfile = os.path.join(ds.recordings_dir, outfile)\n            log.info(\"Merging recordings %s to create %s\", ' '.join([x.name for x in rec_objects]),\n                     os.path.basename(outfile))\n            if mockup:\n                with open(outfile, 'w') as ow:\n                    ow.write(\"\")\n            else:\n                # Use the appropriate GNUradio script to combine the recordings\n                flowgraph_dict = {\n                    2: flowgraphs.merge2recordings.main,\n                    3: flowgraphs.merge3recordings.main,\n                    4: flowgraphs.merge4recordings.main,\n                    5: flowgraphs.merge5recordings.main,\n                }\n\n                # Create the appropriate filenames to pass as arguments\n                filenames = {'outfile': outfile}\n                # One for each input file\n                for i in range(len(rec_objects)):\n                    filenames['file%s' % (i + 1)] = rec_objects[i].recfile\n\n                args = Namespace(**filenames)\n\n                # Call the proper flowgraph with the arguments mapping\n                t = time.time()\n                try:\n                    flowgraph_dict[len(rec_objects)](options=args)\n                    log.info(\"GNUradio merging time: %s\", time.time()-t)\n                except RuntimeError as e:\n                    log.error(\"GNUradio failed to merge recordings. Error: \", str(e))\n                    return\n\n            # Initialize  the recording\n            return cls(outfile, rec_objects[0].dataset, no_md=True)\n\n    def __init__(self, recfile, dataset, no_md=False, recount_pictures=False):\n\n        # Dataset istance that the recording is member of\n        self.dataset = dataset\n\n        self.plotter = None\n\n        # Recording files and names\n        # Absolute recording file path\n        self.recfile = os.path.abspath(recfile)\n\n        # File descriptor of recording file, used to read chunks of data when processing\n        # Should be closed after operation.\n        self.file_descriptor = None\n\n        # Name of the recording with no extension (eg: rec_43)\n        self.name = Recording.get_recname(recfile)\n        # Id of recording (eg: 43)\n        self.id = Recording.get_rec_id(self.name)\n\n        # Directory for files needed for noise calculation (fft samples, SNR values, pics, etc)\n        self.noise_calc_dir = os.path.join(self.dataset.noise_calc_dir, self.name)\n        # SNR values file and fft samples file\n        self.dat_file = os.path.join(self.noise_calc_dir, self.name + '.dat')\n        self.fft_file = os.path.join(self.noise_calc_dir, self.name + '_fft.32fc')\n\n        # Pictures directory and picture files prefix (eg: rec_43_pic_546)\n        self.rec_pics_dir = os.path.join(self.dataset.pictures_dir, self.name)  # Pictures directory for the recording\n        self.compressed_pics_dir = os.path.join(self.rec_pics_dir, 'compressed_pictures')\n        self.pic_prefix = \"%s_pic\" % self.name\n        self.corrected_annotations_dir = os.path.join(self.rec_pics_dir, \"corrected_annotations\")\n        self.synthetic_annotations_dir = os.path.join(self.rec_pics_dir, \"synthetic_annotations\")\n        self.fixed_labels_dir = os.path.join(self.rec_pics_dir, \"corrected_labels\")\n\n        self._annotation_list = None\n        self._synth_annotation_list = None\n        self._corrected_annotation_list = None\n        self._fixed_label_list = None\n        self._compr_annotation_list = None\n        self._pic_list = None\n        self._compr_pic_list = None\n\n        if no_md:\n            self.metadata = None\n        else:\n            self.metadata = metadata.RecordingMetadata(self)\n\n        if recount_pictures:\n            self.metadata.no_of_pictures = self._count_all_pictures()\n            self.metadata._metadata['no_of_pictures'] = self.metadata.no_of_pictures\n            self.metadata.store_metadata()\n\n    def _get_annot_list(self):\n        \"\"\"Get a list of annotations generated in the picture directory\"\"\"\n        ann_pattern = os.path.join(self.rec_pics_dir, '%s_*.txt' % self.pic_prefix)\n        return sorted(glob.glob(ann_pattern), key=lambda x: int(utils.get_id_from_pic_name(os.path.basename(x))))\n\n    def _get_synth_annot_list(self):\n        \"\"\"Get a list of synthetic annotations generated for synthetic recordings\"\"\"\n        ann_pattern = os.path.join(self.synthetic_annotations_dir, '%s_*.txt' % self.pic_prefix)\n        return sorted(glob.glob(ann_pattern), key=lambda x: int(utils.get_id_from_pic_name(os.path.basename(x))))\n\n    def _get_corr_annot_list(self):\n        \"\"\"Get a list of corrected annotations, if available\"\"\"\n        ann_pattern = os.path.join(self.corrected_annotations_dir, '%s_*.txt' % self.pic_prefix)\n        return sorted(glob.glob(ann_pattern), key=lambda x: int(utils.get_id_from_pic_name(os.path.basename(x))))\n\n    def _get_fixed_label_list(self):\n        \"\"\"Get a list of manually fixed labels\"\"\"\n        ann_pattern = os.path.join(self.fixed_labels_dir, '%s_*.txt' % self.pic_prefix)\n        return sorted(glob.glob(ann_pattern), key=lambda x: int(utils.get_id_from_pic_name(os.path.basename(x))))\n\n    def _get_compr_annot_list(self):\n        \"\"\"Get a list of compressed annotations generated in the compressed picture directory\"\"\"\n        ann_pattern = os.path.join(self.compressed_pics_dir, '%s_*.txt' % self.pic_prefix)\n        return sorted(glob.glob(ann_pattern), key=lambda x: int(utils.get_id_from_pic_name(os.path.basename(x))))\n\n    def _get_pic_list(self, prefix=''):\n        \"\"\"\n        Gets the pictures generated for the recording\n        \"\"\"\n        pic_pattern = os.path.join(self.rec_pics_dir, prefix + '*.jpg')\n        return sorted(glob.glob(pic_pattern), key=lambda x: int(utils.get_id_from_pic_name(os.path.basename(x))))\n\n    def _get_compr_pic_list(self, prefix=''):\n        \"\"\"\n        Gets the compressed pictures generated for the recording\n        \"\"\"\n        pic_pattern = os.path.join(self.compressed_pics_dir, prefix + '*.jpg')\n        return sorted(glob.glob(pic_pattern), key=lambda x: int(utils.get_id_from_pic_name(os.path.basename(x))))\n\n    def _get_file_size(self):\n        \"\"\"\n        Calculates the disk space occupied by this recording, including the pictures generated by it\n        \"\"\"\n        bytes_size = os.path.getsize(self.recfile)\n        try:\n            bytes_size += os.path.getsize(self.rec_pics_dir)\n        except OSError:\n            # No pictures directory\n            pass\n        return utils.convert_size(bytes_size)\n\n    def _count_all_pictures(self):\n        \"\"\"\n        Counts all pictures associated with this recording\n        \"\"\"\n        return len(self.compressed_pic_list) + len(self.pic_list)\n\n    @property\n    def pic_list(self):\n        \"\"\"Returns a list of the generated pictures for the recording\"\"\"\n        if not self._pic_list:\n            self._pic_list = self._get_pic_list()\n        return self._pic_list\n\n    @property\n    def annotation_list(self):\n        \"\"\"Returns a list of annotation files (absolute paths) located in the picture directory of the recording\"\"\"\n        if not self._annotation_list:\n            self._annotation_list = self._get_annot_list()\n        return self._annotation_list\n\n    @property\n    def synth_annotation_list(self):\n        \"\"\"Returns a list of synthetic annotation files (absolute paths)\"\"\"\n        if not self._synth_annotation_list:\n            self._synth_annotation_list = self._get_synth_annot_list()\n        return self._synth_annotation_list\n\n    @property\n    def corrected_annotation_list(self):\n        \"\"\"Return a list of corrected annotations\"\"\"\n        if not self._corrected_annotation_list:\n            self._corrected_annotation_list = self._get_corr_annot_list()\n        return self._corrected_annotation_list\n\n    @property\n    def fixed_label_list(self):\n        \"\"\"Return list of manually fixed labels\"\"\"\n        if not self._fixed_label_list:\n            self._fixed_label_list = self._get_fixed_label_list()\n        return self._fixed_label_list\n\n    @property\n    def compressed_annotation_list(self):\n        \"\"\"\n        Returns a list of compressed annotation files (absolute paths) located in the compressed picture directory of\n        the recording\n        \"\"\"\n        if not self._compr_annotation_list:\n            self._compr_annotation_list = self._get_compr_annot_list()\n        return self._compr_annotation_list\n\n    @property\n    def compressed_pic_list(self):\n        \"\"\"\n        Returns a list of compressed picture files (absolute paths) located in the compressed picture directory of\n        the recording\n        \"\"\"\n        if not self._compr_pic_list:\n            self._compr_pic_list = self._get_compr_pic_list()\n        return self._compr_pic_list\n\n    @property\n    def file_size(self):\n        \"\"\"\n        Returns the recording size including the complex samples and the generated pictures.\n        File size is read from metadata or if None, it's calculated by parsing the filesystem.\n        \"\"\"\n        # return self.metadata.metadata.get('file_size', '')\n        return self.metadata.metadata.get('file_size', str(self._get_file_size()))\n\n    def play_samples(self):\n        \"\"\"\n        Loads the complex samples and previews them with GNUradio\n        \"\"\"\n        log.info(\"Playing recording %s.\", self.name)\n        flowgraphs.view_samples_from_file.main(options=Namespace(filename=self.recfile, freq=2.44e9,\n                                                                 refresh_rate=30, samp_rate=100e6,\n                                                                 fft_size=512))\n        log.info(\"Done.\")\n        return\n\n    def gen_dat_file(self, noise_pwr_db=None, fft_size=512):\n        \"\"\"\n        Generates the SNR file\n        \"\"\"\n\n        # By default, get the noise level from metadata\n        if not noise_pwr_db:\n            noise_pwr_db = int(round(float(self.metadata.noise_pwr_db)))\n            # Noise metadata defaults to 0 if non existant.\n            if noise_pwr_db == 0:\n                noise_pwr_db = -50  # -50 is a reasonable starting point for noise level\n\n        # Create the directory if needed\n        if not os.path.isdir(self.noise_calc_dir):\n            os.makedirs(self.noise_calc_dir)\n\n        flowgraphs.samples_to_dat.main(options=Namespace(filename=self.recfile,\n                                                         output=os.path.splitext(self.dat_file)[0],\n                                                         noise_pwr_db=noise_pwr_db, fft_size=fft_size))\n\n    def gen_fft_file(self, fft_size=512):\n        \"\"\"\n        Generates the fft samples\n        \"\"\"\n        # Create the directory if needed\n        if not os.path.isdir(self.noise_calc_dir):\n            os.makedirs(self.noise_calc_dir)\n\n        flowgraphs.samples_fft.main(options=Namespace(filename=self.recfile, output=os.path.splitext(self.fft_file)[0],\n                                                      fft_size=fft_size))\n\n    def remove_dat_file(self):\n        \"\"\"\n        Deletes the SNR file\n        \"\"\"\n        try:\n            os.remove(self.dat_file)\n        except OSError:\n            pass\n\n    def remove_fft_file(self):\n        \"\"\"\n        Deletes the fft samples\n        \"\"\"\n        try:\n            os.remove(self.fft_file)\n        except OSError:\n            pass\n\n    def remove_pictures(self):\n        \"\"\"\n        Deletes all pictures and noise calculations of the recording\n        \"\"\"\n        cmd = \"rm -r %s %s\" % (self.noise_calc_dir, self.rec_pics_dir)\n        subprocess.call(cmd.split())\n\n    def create_artificial_data(self, mold=None, freq_steps=None, time_steps=None, prefix=None, figdir=None, label=None):\n        \"\"\"\n        Uses a given transmission area as a mold to create artificial data on various\n        \"\"\"\n        if not os.environ.get('DISPLAY', None):\n            log.warning(\"No available X server. Interactive mold creation cannot proceed without display.\\n\\\n                        Consider connecting with X server forwarding, otherwise consider passing an input array\"\n                        \"to use as a mold.\")\n            return None\n\n        if not self.metadata.noise_pwr_db:\n            log_noise, noise_variance = self.calculate_noise()\n            if not log_noise:\n                log.error(\"Recording %s: Noise level could not be determined, unable to create mold.\", self.name)\n                return None\n        else:\n            log_noise = self.metadata.noise_pwr_db\n            noise_variance = self.metadata.noise_variance\n            if not noise_variance:\n                noise_variance = 5.568650501352949 ** 2\n\n        log.info(\"Creating artificial data for recording %s\", self.name)\n\n        if label:\n            try:\n                # If label is given like an integer use this to annotate the pictures\n                label_index = int(label)\n            except ValueError:\n                # otherwise look for the dataset classes to find the corresponding index\n                label_index = self.dataset.metadata.ds_classes().get(label.upper(), None)\n\n            if not label_index:\n                log.error(\"Label not found in the dataset classes. Please update the file %s to include the desired\"\n                          \"label or provide a label index directly for a new class.\",\n                          self.dataset.metadata.class_names_file)\n                return\n\n        if not mold:\n            if not os.path.isfile(self.dat_file):\n                self.gen_dat_file()\n\n            log.info(\"Please draw a region in the following picture to identify mold\")\n\n            npoints = 512 * 512\n            nbytes = npoints * 4\n\n            # Preview the first 10 images for the user to pick a mold region\n            img_index = 0\n            with open(self.dat_file, 'rb') as df:\n                while True:\n                    if img_index > 9:\n                        break\n                    data = utils.load_bytes_from_fd(df, img_index * nbytes, (img_index + 1) * nbytes)\n\n                    if not data:  # No more data to unpack\n                        break\n\n                    data = utils.data_reshape(data, -1, 512)\n\n                    # Process the data before creating the image, create a copy to keep original intact\n                    img_data = utils.data_clip(np.copy(data), -10, 50)\n                    img_data = utils.img_scale(img_data, -10, 50)\n                    img_data = utils.img_flip(img_data)\n\n                    subplot = plt.subplot()\n\n                    pltr = Plotter()\n                    pltr.plot(data=img_data, subplot=subplot, options={'noise_input': True})\n\n                    # If input area was given, break\n                    if pltr.selected_areas:\n                        log.info(\"Mold region recognized:\\n%s\", pltr.pretty_area_print())\n\n                        left, right, bottom, up = pltr.area_borders()\n\n                        # Get the average SNR from the original data (mainly before scaling)\n                        mold = data[up:bottom, left:right]\n                        break\n\n        # Create a background noise array for the artificial data\n        mu = log_noise\n        sigma = float(noise_variance) ** 0.5\n        noise_array = np.random.normal(mu - log_noise, sigma, (512, 512))\n\n        # Prepare the prefix and save directories\n        if not prefix:\n            prefix = self.pic_prefix\n\n        if not figdir:\n            figdir = os.path.join('.', '%s_artificial_data' % self.name)\n\n        if not os.path.isdir(figdir):\n            os.makedirs(figdir)\n\n        # Prepare the annotations to be augmented along with the data\n        if label:\n            annot = Annotation.get_annotation_from_borders(\n                label_index,\n                Annotation.nrmlz(left, 512),\n                Annotation.nrmlz(right, 512),\n                Annotation.nrmlz(bottom, 512),\n                Annotation.nrmlz(up, 512)\n            )\n\n            if not annot:\n                log.error(\"There was an error creating the original annotation. Exiting.\")\n                return\n\n        img_index = 0\n        for tstep in time_steps:\n\n            # Printed (saved) image is actually flipped over the time axes to better illustrate the flow of packets over\n            # time. Thus, input time steps must also be corrected to follow the flipped orientation of the image.\n            tstep = 512 - tstep\n            t_start = tstep - mold.shape[0] / 2\n            t_end = t_start + mold.shape[0]\n            for fstep in freq_steps:\n                f_start = fstep - mold.shape[1] / 2\n                f_end = f_start + mold.shape[1]\n\n                artif_arr = np.copy(noise_array)\n                try:\n                    artif_arr[t_start:t_end, f_start:f_end] = mold\n                except ValueError:\n                    log.error(\"There was an error patching the requested region at the position with:\\n\"\n                              \"Center: (%s, %s).\\n Make sure the region can fit in the image. Skipping...\",\n                              fstep, tstep)\n                    continue\n                img_name = \"%s_%d.jpg\" % (prefix, img_index)\n\n                artif_arr = utils.data_clip(artif_arr, -10, 50)\n                artif_arr = utils.img_flip(utils.img_scale(artif_arr, -10, 50))\n\n                pltr = Plotter()\n                pltr.plot(data=artif_arr, outfile=img_name, figdir=figdir)\n\n                # Shift annotation accordingly and save to file\n                if label:\n                    annot.shift_center((Annotation.nrmlz(fstep, 512), Annotation.nrmlz(tstep, 512)))\n                    annot_str = annot.get_annot_str()\n                    ann_file = os.path.join(figdir, \"%s_%d.txt\" % (prefix, img_index))\n\n                    with open(ann_file, 'w') as af:\n                        af.write(annot_str)\n\n                img_index += 1\n        log.info(\"Artificial data created for recording %s\", self.name)\n\n    def calculate_noise(self):\n        \"\"\"\n        Calculate the noise level in dB in a given region of the picture\n        \"\"\"\n\n        if not os.environ.get('DISPLAY', None):\n            log.warning(\"No available X server. Interactive noise calculation cannot proceed without display.\\n\\\n                        Consider connecting with X server forwarding, otherwise manually calculate noise and update\\\n                        the recording metadata accordingly.\")\n            return None, None\n\n        # Always regenerate the dat file to make sure the ground truth is consistent\n        self.gen_dat_file(noise_pwr_db=-50)\n\n        npoints = 512 * 512\n        nbytes = npoints * 4\n\n        # Preview the first 10 images for the user to pick a noise region\n        log_noise = None\n        img_index = 0\n        with open(self.dat_file, 'rb') as df:\n            while True:\n                if img_index > 9:\n                    break\n                data = utils.load_bytes_from_fd(df, img_index * nbytes, (img_index + 1) * nbytes)\n\n                if not data:  # No more data to unpack\n                    break\n\n                data = utils.data_reshape(data, -1, 512)\n\n                # Process the data before creating the image, create a copy to keep original intact\n                img_data = utils.data_clip(np.copy(data), -10, 50)\n                img_data = utils.img_scale(img_data, -10, 50)\n                img_data = utils.img_flip(img_data)\n\n                subplot = plt.subplot()\n\n                pltr = Plotter()\n                pltr.plot(data=img_data, subplot=subplot, options={'noise_input': True})\n\n                # If input area was given, break\n                if pltr.selected_areas:\n                    log.info(\"Noise region recognized: %s\", pltr.pretty_area_print())\n\n                    left, right, bottom, up = pltr.area_borders()\n\n                    # Get the average SNR from the original data (mainly before scaling)\n                    cropped = data[up:bottom, left:right]\n\n                    # This is the avg SNR in the cropped region, we need to add it to the noise level that was used to\n                    # create the dat file in the first place\n                    avg_snr_db = np.mean(cropped)\n                    noise_variance = np.var(cropped)\n                    log_noise = -50 + avg_snr_db\n\n                    # Remove dat file because it was created with a default noise value rather than the real one\n                    self.remove_dat_file()\n                    log.info(\"Noise level calculated: %s dB\", log_noise)\n                    break\n\n                img_index += 1\n        return log_noise, noise_variance\n\n    def compress_annotations(self, compr_factor, merge=True):\n        \"\"\"\n        Compress annotations into the compressed picture directory. If no original annotations are found, an error is\n        returned and nothing is generated.\n        \"\"\"\n\n        to_compress = self.fixed_label_list if not self.metadata.synthetic else self.synth_annotation_list\n\n        if not to_compress:\n            log.info(\"No corrected labels found for recording %s. Nothing to compress...\", self.name)\n            return\n        if not os.path.isdir(self.compressed_pics_dir):\n            os.mkdir(self.compressed_pics_dir)\n\n        compressed_pic_annotations = []\n\n        # Fetch all original annotations for every picture\n        for pic_ann in to_compress:\n            new_pic_index = to_compress.index(pic_ann) / compr_factor\n            pic_index = to_compress.index(pic_ann) % compr_factor\n            with open(pic_ann, 'r') as orig_ann:\n                pic_annotations = orig_ann.read().strip().split('\\n')\n\n            extend_annot = [annotation.Annotation.get_annotation_from_str(x) for x in pic_annotations]\n            extend_annot = [annotation.Annotation.compress_annotation(x, compr_factor, pic_index) for x in\n                            extend_annot]\n            compressed_pic_annotations.extend(extend_annot)\n\n            # Save the compressed annotation\n            if pic_index == compr_factor - 1:\n                if merge:\n                    compressed_pic_annotations = annotation.Annotation.merge_annotations(compressed_pic_annotations)\n                compressed_pic_annotations = '\\n'.join([x.get_annot_str() for x in compressed_pic_annotations\n                                                        if x.get_annot_str()])\n                compressed_ann_file = os.path.join(self.compressed_pics_dir,\n                                                   self.pic_prefix + \"_\" + str(new_pic_index) + \".txt\")\n                with open(compressed_ann_file, 'w') as comp_ann:\n                    comp_ann.write(compressed_pic_annotations)\n                compressed_pic_annotations = []\n\n        log.info(\"Compressed annotations for recording %s were saved in: %s\", self.name, self.compressed_pics_dir)\n\n    def generate_pictures(self, log_noise=None, nfft=512, nlines=512, navg=3, nproc=4, npics=0, pic_prefix=None,\n                          mode='grayscale', expand=None, trim=50):\n        \"\"\"\n        Generates pictures from a recording file\n        \"\"\"\n\n        # Clipping parameters\n        min_snr = -10\n        max_snr = 50\n\n        log.info(\"Generating pictures for recording: %s\", self.name)\n\n        # Use recorded noise measurements unless overridden\n        noise_var = None\n        if not log_noise:\n            log_noise = int(round(self.metadata.noise_pwr_db))\n            if not log_noise:\n                log_noise, noise_var = self.calculate_noise()\n                if not log_noise:\n                    log.error(\"Recording %s: Noise level could not be determined, no pictures generated.\", self.name)\n                    return\n                else:\n                    self.metadata.noise_pwr_db = log_noise\n                    self.metadata.noise_variance = noise_var\n                    self.metadata._metadata['noise_db'] = self.metadata.noise_pwr_db\n                    self.metadata._metadata['noise_variance'] = self.metadata.noise_variance\n                    self.metadata.store_metadata()\n                    log_noise = int(round(float(self.metadata.noise_pwr_db)))\n        if not noise_var:\n            noise_var = float(self.metadata.noise_variance)\n            if not noise_var:\n                noise_var = Recording.heuristic_noise_calculation\n\n        # If expanding to a wider bandwidth, create array with noise values as background\n        if expand:\n            transm_freq = float(expand[0])\n            transm_rate = float(expand[1])\n            wide_freq = float(expand[2])\n            wide_rate = float(expand[3])\n            avg_factor = int(wide_rate / transm_rate)\n            mu = log_noise\n            sigma = float(noise_var) ** 0.5\n            noise_array = np.random.normal(mu-log_noise, sigma, (nlines, nfft * avg_factor))\n\n        if not os.path.isdir(self.rec_pics_dir):\n            os.makedirs(self.rec_pics_dir)\n\n        # Use default picture prefix unless specified\n        if not pic_prefix:\n            pic_prefix = self.pic_prefix\n\n        npoints = nfft * nlines * navg * nproc\n\n        if mode.lower() == 'grayscale':\n\n            if not os.path.isfile(self.dat_file):\n                self.gen_dat_file()\n\n            nbytes = npoints * 4\n\n            img_index = 0\n            with open(self.dat_file, \"rb\") as df:\n                while True:\n                    data = utils.load_bytes_from_fd(df, img_index * nbytes, (img_index + 1) * nbytes)\n\n                    if not data:  # No more data to unpack\n                        break\n\n                    # Reshape into an array of (nfft, nlines)\n                    data = utils.data_reshape(data, -1, nfft)\n\n                    # If expanding to a wider bandwidth average the loaded data accordingly and fit them into the\n                    # previously created noise array (background)\n                    if expand:\n                        if not trim:\n                            trim = 0\n                        # Position the transmission subarray in the new wider array\n                        new_start_freq = wide_freq - wide_rate / 2.0\n                        sub_array_center = int((transm_freq - new_start_freq) * (int(nfft) / wide_rate) * avg_factor)\n                        sub_array_size = int(nfft)\n                        sub_array_start = sub_array_center - sub_array_size / 2\n                        sub_array_end = sub_array_start + sub_array_size\n\n                        noise_array[:, sub_array_start + trim:sub_array_end - trim] = data[:, trim:-trim]\n\n                        data = noise_array\n\n                    greyscale_avg = navg * nproc\n                    if greyscale_avg > 1 and type(greyscale_avg) is int:\n                        avg_data = np.empty((int(data.shape[0] / greyscale_avg), data.shape[1]))\n                        for i in range(0, data.shape[0], greyscale_avg):\n                            try:\n                                avg_data[int(i / greyscale_avg)] = np.mean(data[i:i + greyscale_avg], axis=0, keepdims=True)\n                            except IndexError as e:\n                                if int(i / greyscale_avg) >= data.shape[0] / greyscale_avg:\n                                    # Last chunk of data reached\n                                    break\n                                else:\n                                    raise e\n                    else:\n                        avg_data = data\n\n                    avg_data = utils.data_clip(avg_data, min_snr, max_snr)\n                    avg_data = utils.img_flip(utils.img_scale(avg_data, min_snr, max_snr))\n\n                    img_name = \"%s_%d.jpg\" % (pic_prefix, img_index)\n\n                    pltr = Plotter()\n                    pltr.plot(data=avg_data, outfile=img_name, figdir=self.rec_pics_dir, resize=(nfft, nlines))\n\n                    img_index += 1\n\n                    # Check if img limit is reached and exit\n                    if npics and npics > 0:\n                        if img_index >= npics:\n                            break\n\n            self.remove_dat_file()\n\n        elif mode.lower() == 'compressed':\n            self.gen_fft_file()\n            plot_recording(self.fft_file, self.compressed_pics_dir, pic_prefix, nfft, nlines, navg, nproc,\n                           log_noise=log_noise, img_mode=mode, disp=\"save\", img_limit=npics)\n            self.remove_fft_file()\n\n        if not npics:\n            npics = 'All'\n        pic_out_dir = self.rec_pics_dir if mode == 'grayscale' else self.compressed_pics_dir\n        log.info(\"%s pictures were generated in the directory: %s\", npics, pic_out_dir)\n        return\n\n    def print_info(self):\n        \"\"\"\n        Prints info about the recording\n        \"\"\"\n        log.info(\"\\\nInformation about recording %s:\\n\\n\\\nRecorded on %s. \\n\\n\\\nNumber of pictures generated: %s\\n\\n\\\nMetadata \\n%s\", self.name,\n                 self.metadata.date_recorded,\n                 self.metadata.no_of_pictures,\n                 self.metadata.get_md_string())\n        log.info(json.dumps(self.metadata.metadata))", ""]}
{"filename": "core/_box.py", "chunked_list": ["\"\"\"\nDefinition of the box object\n\"\"\"\n"]}
{"filename": "core/gen_pics.py", "chunked_list": ["\"\"\"\nHelper script to generate images for recordings. Used by class `Recording`.\n\"\"\"\nimport argparse\nimport struct\nimport sys\nfrom PIL import Image\n\nimport numpy as np\nimport os", "import numpy as np\nimport os\nfrom . import _utils as utils\n# from core import img_scale, data_clip\n\nSNR_MIN = -10\nSNR_MAX = 50\n\nnp.set_printoptions(threshold=sys.maxsize)\n", "np.set_printoptions(threshold=sys.maxsize)\n\n\ndef data_IO_snr(fopen, npoints, nfft, navg):\n    \"\"\"\n    IO from a SNR file.\n    \"\"\"\n    binary = fopen.read(npoints*4)\n    syntax = str(npoints) + \"f\"\n\n    data = struct.unpack(syntax, binary)\n    data = np.reshape(data, (-1, nfft))\n\n    if navg > 1 and type(navg) is int:\n        avg_data = np.empty((data.shape[0]/navg, data.shape[1]))\n        for i in range(0, data.shape[0], navg):\n            avg_data[i/navg] = np.mean(data[i:i+navg], axis=0, keepdims=True)\n\n        utils.data_clip(avg_data, SNR_MIN, SNR_MAX)\n        avg_data = np.flip(utils.img_scale(avg_data, SNR_MIN, SNR_MAX),axis=0)\n        return avg_data\n    else:\n        utils.data_clip(data, SNR_MIN, SNR_MAX)\n        data = np.flip(utils.img_scale(data, SNR_MIN, SNR_MAX),axis=0)\n        return data", "\n\ndef data_IO_raw_compressed(fopen, npoints, nfft, navg, nproc, log_noise):\n    \"\"\"\n    IO from an FFT-ed complex recording file.\n    \"\"\"\n    binary = fopen.read(npoints*4*2)\n    syntax = str(npoints*2) + \"f\"\n\n    data = struct.unpack(syntax, binary)\n    data = np.reshape(data, (-1, nfft*2))\n\n    real = np.take(data, np.arange(0, data.shape[1], 2), axis=1)\n    imge = np.take(data, np.arange(1, data.shape[1], 2), axis=1)\n\n    pwr = real**2+imge**2\n\n    # Window Averaging\n    avg_pwr = np.empty((pwr.shape[0]/navg, pwr.shape[1]))\n    for i in range(0, pwr.shape[0], navg):\n        avg_pwr[i/navg] = np.mean(pwr[i:i+navg,:], axis=0, keepdims=True)\n\n    # Window Max-Min-\n    max_pwr = np.empty((avg_pwr.shape[0]/nproc, avg_pwr.shape[1]))\n    min_pwr = np.empty((avg_pwr.shape[0]/nproc, avg_pwr.shape[1]))\n    avg_pwr_2 = np.empty((avg_pwr.shape[0]/nproc, avg_pwr.shape[1]))\n    for i in range(0, avg_pwr.shape[0], nproc):\n        max_pwr[i/nproc] = np.max(avg_pwr[i:i+nproc,:], axis=0, keepdims=True)\n        min_pwr[i/nproc] = np.min(avg_pwr[i:i+nproc,:], axis=0, keepdims=True)\n        avg_pwr_2[i/nproc] = np.mean(avg_pwr[i:i+nproc,:], axis=0, keepdims=True)\n\n    max_pwr = (10*np.log10(max_pwr)-log_noise).astype(int)\n    min_pwr = (10*np.log10(min_pwr)-log_noise).astype(int)\n    avg_pwr_2 = (10*np.log10(avg_pwr_2)-log_noise).astype(int)\n\n    # utils.data_clip, scaling\n    utils.data_clip(max_pwr, SNR_MIN, SNR_MAX)\n    utils.data_clip(min_pwr, SNR_MIN, SNR_MAX)\n    utils.data_clip(avg_pwr_2, SNR_MIN, SNR_MAX)\n\n    max_pwr = np.flip(utils.img_scale(max_pwr, SNR_MIN, SNR_MAX), axis=0)\n    min_pwr = np.flip(utils.img_scale(min_pwr, SNR_MIN, SNR_MAX), axis=0)\n    avg_pwr_2 = np.flip(utils.img_scale(avg_pwr_2, SNR_MIN, SNR_MAX), axis=0)\n\n    return max_pwr, min_pwr, avg_pwr_2", "\n\ndef spectro_plot(data_img, disp, img_name):\n    im = Image.fromarray(data_img)\n    if disp == 'save':\n        im.save(img_name)\n    elif disp == 'show':\n        im.show()\n    return\n", "\n\ndef plot_recording(file, figdir, prefix, nfft, nline, navg, nproc, log_noise, img_mode='grayscale', disp='save', img_limit=None):\n    \"\"\"\n        Plot the recorded data.\n        img_mode: 'grayscale' - Replicate SNR data in 3 channels\n                  'compressed' - Compress data for each channel\n    \"\"\"\n    NPOINTS = nfft*nline*navg*nproc\n    fopen = open(file, \"rb\")\n\n    if not os.path.isdir(figdir):\n        os.makedirs(figdir)\n\n    img_index = 0\n    while True:\n        try:\n            if img_mode == 'grayscale':\n                data = data_IO_snr(fopen, NPOINTS, nfft, navg)\n                data_img = np.stack((data, data, data), axis=-1)\n\n            elif img_mode == 'compressed':\n                data_ch1, data_ch2, data_ch3 = data_IO_raw_compressed(fopen, NPOINTS, nfft, navg, nproc, log_noise)\n                data_img = np.stack((data_ch1, data_ch2, data_ch3), axis=-1)\n            else:\n                print(\"Unrecognized mode: \", img_mode)\n                return\n\n            fname = figdir + \"/\" + prefix + \"_\" + str(img_index) + \".jpg\"\n            spectro_plot(data_img, disp, fname)\n\n            img_index += 1\n\n            # Check if img limit is reached and exit\n            if img_limit and img_limit>0:\n                if img_index == img_limit:\n                    print(\"Image limit reached: %s. Stopping...\", img_limit)\n                    break\n\n        except struct.error:\n            print(\"Done.\")\n            break\n\n    # Always close the file after done\n    fopen.close()\n    return", "\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"file\", type=str, required=True,\n        help='Path to data: If mode is \"grayscale\" or \"discretized\" (experimental), the file should include SNR values (.dat file). If mode is \"compressed\", the file should include I&Q values after FFT.')\n    parser.add_argument(\"--figdir\", type=str, required=True,\n        help='Path to figure storage')\n    parser.add_argument(\"--prefix\", type=str, default='rec',\n        help='Prefix of the images')\n    parser.add_argument(\"--nfft\", type=int, default=512,\n        help='Num. of FFT points')\n    parser.add_argument(\"--nline\", type=int, default=512,\n        help='Num. of data lines to plot (after avg)')\n    parser.add_argument(\"--navg\", type=int, default=10,\n        help='Average window size')\n    parser.add_argument(\"--nproc\", type=int, default=10,\n        help='Max/min window size')\n    parser.add_argument(\"--log-noise\", type=int, default=-47,\n        help='Measured log-noise level.')\n    parser.add_argument(\"--img-mode\", type=str, default='grayscale',\n        help='Image mode: grayscale, compressed, discretized')\n    parser.add_argument(\"--disp\", type=str, default='save',\n        help='Display mode')\n    parser.add_argument(\"--img-limit\", type=int,\n        help='Limit the images to be generated.')\n    args = parser.parse_args()\n\n    plot_recording(args.file, args.figdir, args.prefix, args.nfft, args.nline, args.navg, args.nproc,\n                   args.log_noise, img_mode=args.img_mode, disp=args.disp, img_limit=args.img_limit)", ""]}
{"filename": "core/flowgraphs/merge5recordings.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: Merge5Recordings\n# GNU Radio version: 3.7.13.5\n##################################################\n\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation", "from gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import gr\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\n\n\nclass merge5recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', file3='', file4='', file5='', outfile=''):\n        gr.top_block.__init__(self, \"Merge5Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.file3 = file3\n        self.file4 = file4\n        self.file5 = file5\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file5, False)\n        try:\n            self.blocks_file_source_0_0_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file4, False)\n        try:\n            self.blocks_file_source_0_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file3, False)\n        try:\n            self.blocks_file_source_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n        self.connect((self.blocks_file_source_0_0_0, 0), (self.blocks_add_xx_0, 2))\n        self.connect((self.blocks_file_source_0_0_0_0, 0), (self.blocks_add_xx_0, 3))\n        self.connect((self.blocks_file_source_0_0_0_0_0, 0), (self.blocks_add_xx_0, 4))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_file3(self):\n        return self.file3\n\n    def set_file3(self, file3):\n        self.file3 = file3\n        self.blocks_file_source_0_0_0.open(self.file3, False)\n\n    def get_file4(self):\n        return self.file4\n\n    def set_file4(self, file4):\n        self.file4 = file4\n        self.blocks_file_source_0_0_0_0.open(self.file4, False)\n\n    def get_file5(self):\n        return self.file5\n\n    def set_file5(self, file5):\n        self.file5 = file5\n        self.blocks_file_source_0_0_0_0_0.open(self.file5, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\nclass merge5recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', file3='', file4='', file5='', outfile=''):\n        gr.top_block.__init__(self, \"Merge5Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.file3 = file3\n        self.file4 = file4\n        self.file5 = file5\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file5, False)\n        try:\n            self.blocks_file_source_0_0_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file4, False)\n        try:\n            self.blocks_file_source_0_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file3, False)\n        try:\n            self.blocks_file_source_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n        self.connect((self.blocks_file_source_0_0_0, 0), (self.blocks_add_xx_0, 2))\n        self.connect((self.blocks_file_source_0_0_0_0, 0), (self.blocks_add_xx_0, 3))\n        self.connect((self.blocks_file_source_0_0_0_0_0, 0), (self.blocks_add_xx_0, 4))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_file3(self):\n        return self.file3\n\n    def set_file3(self, file3):\n        self.file3 = file3\n        self.blocks_file_source_0_0_0.open(self.file3, False)\n\n    def get_file4(self):\n        return self.file4\n\n    def set_file4(self, file4):\n        self.file4 = file4\n        self.blocks_file_source_0_0_0_0.open(self.file4, False)\n\n    def get_file5(self):\n        return self.file5\n\n    def set_file5(self, file5):\n        self.file5 = file5\n        self.blocks_file_source_0_0_0_0_0.open(self.file5, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--file1\", dest=\"file1\", type=\"string\", default='',\n        help=\"Set file1 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file2\", dest=\"file2\", type=\"string\", default='',\n        help=\"Set file2 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file3\", dest=\"file3\", type=\"string\", default='',\n        help=\"Set file3 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file4\", dest=\"file4\", type=\"string\", default='',\n        help=\"Set file4 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file5\", dest=\"file5\", type=\"string\", default='',\n        help=\"Set file5 [default=%default]\")\n    parser.add_option(\n        \"\", \"--outfile\", dest=\"outfile\", type=\"string\", default='',\n        help=\"Set outfile [default=%default]\")\n    return parser", "\n\ndef main(top_block_cls=merge5recordings, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n\n    tb = top_block_cls(file1=options.file1, file2=options.file2, file3=options.file3, file4=options.file4, file5=options.file5, outfile=options.outfile)\n    tb.start()\n    tb.wait()\n", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/flowgraphs/__init__.py", "chunked_list": ["\"\"\"\nInitialize package\n\"\"\"\nfrom . import view_samples_from_file\nfrom . import freq_samples_to_dat\nfrom . import samples_fft\nfrom . import samples_to_dat\nfrom . import merge2recordings\nfrom . import merge3recordings\nfrom . import merge4recordings", "from . import merge3recordings\nfrom . import merge4recordings\nfrom . import merge5recordings\n"]}
{"filename": "core/flowgraphs/merge4recordings.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: Merge4Recordings\n# GNU Radio version: 3.7.13.5\n##################################################\n\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation", "from gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import gr\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\n\n\nclass merge4recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', file3='', file4='', outfile=''):\n        gr.top_block.__init__(self, \"Merge4Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.file3 = file3\n        self.file4 = file4\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file4, False)\n        try:\n            self.blocks_file_source_0_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file3, False)\n        try:\n            self.blocks_file_source_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n        self.connect((self.blocks_file_source_0_0_0, 0), (self.blocks_add_xx_0, 2))\n        self.connect((self.blocks_file_source_0_0_0_0, 0), (self.blocks_add_xx_0, 3))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_file3(self):\n        return self.file3\n\n    def set_file3(self, file3):\n        self.file3 = file3\n        self.blocks_file_source_0_0_0.open(self.file3, False)\n\n    def get_file4(self):\n        return self.file4\n\n    def set_file4(self, file4):\n        self.file4 = file4\n        self.blocks_file_source_0_0_0_0.open(self.file4, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\nclass merge4recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', file3='', file4='', outfile=''):\n        gr.top_block.__init__(self, \"Merge4Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.file3 = file3\n        self.file4 = file4\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file4, False)\n        try:\n            self.blocks_file_source_0_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file3, False)\n        try:\n            self.blocks_file_source_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n        self.connect((self.blocks_file_source_0_0_0, 0), (self.blocks_add_xx_0, 2))\n        self.connect((self.blocks_file_source_0_0_0_0, 0), (self.blocks_add_xx_0, 3))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_file3(self):\n        return self.file3\n\n    def set_file3(self, file3):\n        self.file3 = file3\n        self.blocks_file_source_0_0_0.open(self.file3, False)\n\n    def get_file4(self):\n        return self.file4\n\n    def set_file4(self, file4):\n        self.file4 = file4\n        self.blocks_file_source_0_0_0_0.open(self.file4, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--file1\", dest=\"file1\", type=\"string\", default='',\n        help=\"Set file1 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file2\", dest=\"file2\", type=\"string\", default='',\n        help=\"Set file2 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file3\", dest=\"file3\", type=\"string\", default='',\n        help=\"Set file3 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file4\", dest=\"file4\", type=\"string\", default='',\n        help=\"Set file4 [default=%default]\")\n    parser.add_option(\n        \"\", \"--outfile\", dest=\"outfile\", type=\"string\", default='',\n        help=\"Set outfile [default=%default]\")\n    return parser", "\n\ndef main(top_block_cls=merge4recordings, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n\n    tb = top_block_cls(file1=options.file1, file2=options.file2, file3=options.file3, file4=options.file4, outfile=options.outfile)\n    tb.start()\n    tb.wait()\n", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/flowgraphs/samples_to_dat.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: Samples To Dat\n# GNU Radio version: 3.7.13.5\n##################################################\n\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation", "from gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import fft\nfrom gnuradio import gr\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.fft import window\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\n", "import pmt\n\n\nclass samples_to_dat(gr.top_block):\n\n    def __init__(self, fft_size=512, filename=\"\", noise_pwr_db=-50, output=\"testing\"):\n        gr.top_block.__init__(self, \"Samples To Dat\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.fft_size = fft_size\n        self.filename = filename\n        self.noise_pwr_db = noise_pwr_db\n        self.output = output\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.fft_vxx_0 = fft.fft_vcc(fft_size, True, (window.blackmanharris(fft_size)), True, 1)\n        self.blocks_stream_to_vector_0 = blocks.stream_to_vector(gr.sizeof_gr_complex*1, fft_size)\n        self.blocks_nlog10_ff_0 = blocks.nlog10_ff(10, fft_size, -noise_pwr_db)\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, filename, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_float*fft_size, output+\".dat\", False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_complex_to_mag_squared_0 = blocks.complex_to_mag_squared(fft_size)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_complex_to_mag_squared_0, 0), (self.blocks_nlog10_ff_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_stream_to_vector_0, 0))\n        self.connect((self.blocks_nlog10_ff_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_stream_to_vector_0, 0), (self.fft_vxx_0, 0))\n        self.connect((self.fft_vxx_0, 0), (self.blocks_complex_to_mag_squared_0, 0))\n\n    def get_fft_size(self):\n        return self.fft_size\n\n    def set_fft_size(self, fft_size):\n        self.fft_size = fft_size\n\n    def get_filename(self):\n        return self.filename\n\n    def set_filename(self, filename):\n        self.filename = filename\n        self.blocks_file_source_0.open(self.filename, False)\n\n    def get_noise_pwr_db(self):\n        return self.noise_pwr_db\n\n    def set_noise_pwr_db(self, noise_pwr_db):\n        self.noise_pwr_db = noise_pwr_db\n\n    def get_output(self):\n        return self.output\n\n    def set_output(self, output):\n        self.output = output\n        self.blocks_file_sink_0.open(self.output+\".dat\")", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--fft-size\", dest=\"fft_size\", type=\"intx\", default=512,\n        help=\"Set fft-size [default=%default]\")\n    parser.add_option(\n        \"-f\", \"--filename\", dest=\"filename\", type=\"string\", default=\"\",\n        help=\"Set file [default=%default]\")\n    parser.add_option(\n        \"-n\", \"--noise-pwr-db\", dest=\"noise_pwr_db\", type=\"intx\", default=-50,\n        help=\"Set noise_pwr_db [default=%default]\")\n    parser.add_option(\n        \"-o\", \"--output\", dest=\"output\", type=\"string\", default=\"testing\",\n        help=\"Set outfile [default=%default]\")\n    return parser", "\n\ndef main(top_block_cls=samples_to_dat, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n\n    tb = top_block_cls(fft_size=options.fft_size, filename=options.filename, noise_pwr_db=options.noise_pwr_db, output=options.output)\n    tb.start()\n    tb.wait()\n", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/flowgraphs/merge3recordings.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: Merge3Recordings\n# GNU Radio version: 3.7.13.5\n##################################################\n\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation", "from gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import gr\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\n\n\nclass merge3recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', file3='', outfile=''):\n        gr.top_block.__init__(self, \"Merge3Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.file3 = file3\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file3, False)\n        try:\n            self.blocks_file_source_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n        self.connect((self.blocks_file_source_0_0_0, 0), (self.blocks_add_xx_0, 2))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_file3(self):\n        return self.file3\n\n    def set_file3(self, file3):\n        self.file3 = file3\n        self.blocks_file_source_0_0_0.open(self.file3, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\nclass merge3recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', file3='', outfile=''):\n        gr.top_block.__init__(self, \"Merge3Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.file3 = file3\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file3, False)\n        try:\n            self.blocks_file_source_0_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n        self.connect((self.blocks_file_source_0_0_0, 0), (self.blocks_add_xx_0, 2))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_file3(self):\n        return self.file3\n\n    def set_file3(self, file3):\n        self.file3 = file3\n        self.blocks_file_source_0_0_0.open(self.file3, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--file1\", dest=\"file1\", type=\"string\", default='',\n        help=\"Set file1 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file2\", dest=\"file2\", type=\"string\", default='',\n        help=\"Set file2 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file3\", dest=\"file3\", type=\"string\", default='',\n        help=\"Set file3 [default=%default]\")\n    parser.add_option(\n        \"\", \"--outfile\", dest=\"outfile\", type=\"string\", default='',\n        help=\"Set outfile [default=%default]\")\n    return parser", "\n\ndef main(top_block_cls=merge3recordings, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n\n    tb = top_block_cls(file1=options.file1, file2=options.file2, file3=options.file3, outfile=options.outfile)\n    tb.start()\n    tb.wait()\n", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/flowgraphs/view_samples_from_file.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: View Samples From File\n# GNU Radio version: 3.7.13.5\n##################################################\n\nif __name__ == '__main__':\n    import ctypes", "if __name__ == '__main__':\n    import ctypes\n    import sys\n    if sys.platform.startswith('linux'):\n        try:\n            x11 = ctypes.cdll.LoadLibrary('libX11.so')\n            x11.XInitThreads()\n        except:\n            print \"Warning: failed to XInitThreads()\"\n", "            print \"Warning: failed to XInitThreads()\"\n\nfrom PyQt4 import Qt\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import gr\nfrom gnuradio import qtgui\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser", "from gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\nimport sip\nimport sys\nfrom gnuradio import qtgui\n\n\nclass view_samples_from_file(gr.top_block, Qt.QWidget):\n", "class view_samples_from_file(gr.top_block, Qt.QWidget):\n\n    def __init__(self, fft_size=512, freq=2.44e9, refresh_rate=30, samp_rate=100e6, filename=''):\n        gr.top_block.__init__(self, \"View Samples From File\")\n        Qt.QWidget.__init__(self)\n        self.setWindowTitle(\"View Samples From File\")\n        qtgui.util.check_set_qss()\n        try:\n            self.setWindowIcon(Qt.QIcon.fromTheme('gnuradio-grc'))\n        except:", "            self.setWindowIcon(Qt.QIcon.fromTheme('gnuradio-grc'))\n        except:\n            pass\n        self.top_scroll_layout = Qt.QVBoxLayout()\n        self.setLayout(self.top_scroll_layout)\n        self.top_scroll = Qt.QScrollArea()\n        self.top_scroll.setFrameStyle(Qt.QFrame.NoFrame)\n        self.top_scroll_layout.addWidget(self.top_scroll)\n        self.top_scroll.setWidgetResizable(True)\n        self.top_widget = Qt.QWidget()", "        self.top_scroll.setWidgetResizable(True)\n        self.top_widget = Qt.QWidget()\n        self.top_scroll.setWidget(self.top_widget)\n        self.top_layout = Qt.QVBoxLayout(self.top_widget)\n        self.top_grid_layout = Qt.QGridLayout()\n        self.top_layout.addLayout(self.top_grid_layout)\n\n        self.settings = Qt.QSettings(\"GNU Radio\", \"view_samples_from_file\")\n        self.restoreGeometry(self.settings.value(\"geometry\").toByteArray())\n", "        self.restoreGeometry(self.settings.value(\"geometry\").toByteArray())\n\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.fft_size = fft_size\n        self.freq = freq\n        self.refresh_rate = refresh_rate\n        self.samp_rate = samp_rate", "        self.refresh_rate = refresh_rate\n        self.samp_rate = samp_rate\n        self.filename = filename\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.qtgui_sink_x_0 = qtgui.sink_c(\n        \tfft_size, #fftsize\n        \tfirdes.WIN_BLACKMAN_hARRIS, #wintype", "        \tfft_size, #fftsize\n        \tfirdes.WIN_BLACKMAN_hARRIS, #wintype\n        \tfreq, #fc\n        \tsamp_rate, #bw\n        \t\"\", #name\n        \tTrue, #plotfreq\n        \tTrue, #plotwaterfall\n        \tFalse, #plottime\n        \tFalse, #plotconst\n        )", "        \tFalse, #plotconst\n        )\n        self.qtgui_sink_x_0.set_update_time(1.0/refresh_rate)\n        self._qtgui_sink_x_0_win = sip.wrapinstance(self.qtgui_sink_x_0.pyqwidget(), Qt.QWidget)\n        self.top_grid_layout.addWidget(self._qtgui_sink_x_0_win)\n\n        self.qtgui_sink_x_0.enable_rf_freq(True)\n\n\n", "\n\n        self.blocks_throttle_0 = blocks.throttle(gr.sizeof_gr_complex*1, samp_rate,True)\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, filename, True)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n", "            pass\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_throttle_0, 0))\n        self.connect((self.blocks_throttle_0, 0), (self.qtgui_sink_x_0, 0))\n", "        self.connect((self.blocks_throttle_0, 0), (self.qtgui_sink_x_0, 0))\n\n    def closeEvent(self, event):\n        self.settings = Qt.QSettings(\"GNU Radio\", \"view_samples_from_file\")\n        self.settings.setValue(\"geometry\", self.saveGeometry())\n        event.accept()\n\n    def get_fft_size(self):\n        return self.fft_size\n", "        return self.fft_size\n\n    def set_fft_size(self, fft_size):\n        self.fft_size = fft_size\n\n    def get_freq(self):\n        return self.freq\n\n    def set_freq(self, freq):\n        self.freq = freq", "    def set_freq(self, freq):\n        self.freq = freq\n        self.qtgui_sink_x_0.set_frequency_range(self.freq, self.samp_rate)\n\n    def get_refresh_rate(self):\n        return self.refresh_rate\n\n    def set_refresh_rate(self, refresh_rate):\n        self.refresh_rate = refresh_rate\n", "        self.refresh_rate = refresh_rate\n\n    def get_samp_rate(self):\n        return self.samp_rate\n\n    def set_samp_rate(self, samp_rate):\n        self.samp_rate = samp_rate\n        self.qtgui_sink_x_0.set_frequency_range(self.freq, self.samp_rate)\n        self.blocks_throttle_0.set_sample_rate(self.samp_rate)\n", "        self.blocks_throttle_0.set_sample_rate(self.samp_rate)\n\n    def get_filename(self):\n        return self.filename\n\n    def set_filename(self, filename):\n        self.filename = filename\n        self.blocks_file_source_0.open(self.filename, True)\n\n", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--fft-size\", dest=\"fft_size\", type=\"intx\", default=512,\n        help=\"Set fft_size [default=%default]\")\n    parser.add_option(\n        \"-f\", \"--freq\", dest=\"freq\", type=\"eng_float\", default=eng_notation.num_to_str(2.44e9),\n        help=\"Set freq [default=%default]\")", "        \"-f\", \"--freq\", dest=\"freq\", type=\"eng_float\", default=eng_notation.num_to_str(2.44e9),\n        help=\"Set freq [default=%default]\")\n    parser.add_option(\n        \"\", \"--refresh-rate\", dest=\"refresh_rate\", type=\"eng_float\", default=eng_notation.num_to_str(30),\n        help=\"Set refresh_rate [default=%default]\")\n    parser.add_option(\n        \"-s\", \"--samp-rate\", dest=\"samp_rate\", type=\"eng_float\", default=eng_notation.num_to_str(100e6),\n        help=\"Set samp_rate [default=%default]\")\n    parser.add_option(\n        \"\", \"--filename\", dest=\"filename\", type=\"string\", default='',", "    parser.add_option(\n        \"\", \"--filename\", dest=\"filename\", type=\"string\", default='',\n        help=\"Set filename [default=%default]\")\n    return parser\n\n\ndef main(top_block_cls=view_samples_from_file, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n", "        options, _ = argument_parser().parse_args()\n\n    from distutils.version import StrictVersion\n    if StrictVersion(Qt.qVersion()) >= StrictVersion(\"4.5.0\"):\n        style = gr.prefs().get_string('qtgui', 'style', 'raster')\n        Qt.QApplication.setGraphicsSystem(style)\n    qapp = Qt.QApplication(sys.argv)\n\n    tb = top_block_cls(fft_size=options.fft_size, freq=options.freq, refresh_rate=options.refresh_rate, samp_rate=options.samp_rate, filename=options.filename)\n    tb.start()", "    tb = top_block_cls(fft_size=options.fft_size, freq=options.freq, refresh_rate=options.refresh_rate, samp_rate=options.samp_rate, filename=options.filename)\n    tb.start()\n    tb.show()\n\n    def quitting():\n        tb.stop()\n        tb.wait()\n    qapp.connect(qapp, Qt.SIGNAL(\"aboutToQuit()\"), quitting)\n    qapp.exec_()\n", "    qapp.exec_()\n\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/flowgraphs/merge2recordings.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: Merge2Recordings\n# GNU Radio version: 3.7.13.5\n##################################################\n\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation", "from gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import gr\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\n\n\nclass merge2recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', outfile=''):\n        gr.top_block.__init__(self, \"Merge2Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\nclass merge2recordings(gr.top_block):\n\n    def __init__(self, file1='', file2='', outfile=''):\n        gr.top_block.__init__(self, \"Merge2Recordings\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.file1 = file1\n        self.file2 = file2\n        self.outfile = outfile\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_file_source_0_0 = blocks.file_source(gr.sizeof_gr_complex*1, file2, False)\n        try:\n            self.blocks_file_source_0_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, file1, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_gr_complex*1, outfile, False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_add_xx_0 = blocks.add_vcc(1)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_add_xx_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_add_xx_0, 0))\n        self.connect((self.blocks_file_source_0_0, 0), (self.blocks_add_xx_0, 1))\n\n    def get_file1(self):\n        return self.file1\n\n    def set_file1(self, file1):\n        self.file1 = file1\n        self.blocks_file_source_0.open(self.file1, False)\n\n    def get_file2(self):\n        return self.file2\n\n    def set_file2(self, file2):\n        self.file2 = file2\n        self.blocks_file_source_0_0.open(self.file2, False)\n\n    def get_outfile(self):\n        return self.outfile\n\n    def set_outfile(self, outfile):\n        self.outfile = outfile\n        self.blocks_file_sink_0.open(self.outfile)", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--file1\", dest=\"file1\", type=\"string\", default='',\n        help=\"Set file1 [default=%default]\")\n    parser.add_option(\n        \"\", \"--file2\", dest=\"file2\", type=\"string\", default='',\n        help=\"Set file2 [default=%default]\")\n    parser.add_option(\n        \"\", \"--outfile\", dest=\"outfile\", type=\"string\", default='',\n        help=\"Set outfile [default=%default]\")\n    return parser", "\n\ndef main(top_block_cls=merge2recordings, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n\n    tb = top_block_cls(file1=options.file1, file2=options.file2, outfile=options.outfile)\n    tb.start()\n    tb.wait()\n", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/flowgraphs/samples_fft.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: Samples Fft\n# GNU Radio version: 3.7.13.5\n##################################################\n\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation", "from gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import fft\nfrom gnuradio import gr\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.fft import window\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\n", "import pmt\n\n\nclass samples_fft(gr.top_block):\n\n    def __init__(self, fft_size=512, filename=\"\", output=\"testing_fft\"):\n        gr.top_block.__init__(self, \"Samples Fft\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.fft_size = fft_size\n        self.filename = filename\n        self.output = output\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.fft_vxx_0 = fft.fft_vcc(fft_size, True, (window.blackmanharris(fft_size)), True, 1)\n        self.blocks_stream_to_vector_0 = blocks.stream_to_vector(gr.sizeof_gr_complex*1, fft_size)\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, filename, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_2 = blocks.file_sink(gr.sizeof_gr_complex*fft_size, output+\".32fc\", False)\n        self.blocks_file_sink_2.set_unbuffered(False)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_stream_to_vector_0, 0))\n        self.connect((self.blocks_stream_to_vector_0, 0), (self.fft_vxx_0, 0))\n        self.connect((self.fft_vxx_0, 0), (self.blocks_file_sink_2, 0))\n\n    def get_fft_size(self):\n        return self.fft_size\n\n    def set_fft_size(self, fft_size):\n        self.fft_size = fft_size\n\n    def get_filename(self):\n        return self.filename\n\n    def set_filename(self, filename):\n        self.filename = filename\n        self.blocks_file_source_0.open(self.filename, False)\n\n    def get_output(self):\n        return self.output\n\n    def set_output(self, output):\n        self.output = output\n        self.blocks_file_sink_2.open(self.output+\".32fc\")", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--fft-size\", dest=\"fft_size\", type=\"intx\", default=512,\n        help=\"Set fft-size [default=%default]\")\n    parser.add_option(\n        \"-f\", \"--filename\", dest=\"filename\", type=\"string\", default=\"\",\n        help=\"Set file [default=%default]\")\n    parser.add_option(\n        \"-o\", \"--output\", dest=\"output\", type=\"string\", default=\"testing_fft\",\n        help=\"Set outfile [default=%default]\")\n    return parser", "\n\ndef main(top_block_cls=samples_fft, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n\n    tb = top_block_cls(fft_size=options.fft_size, filename=options.filename, output=options.output)\n    tb.start()\n    tb.wait()\n", "\n\nif __name__ == '__main__':\n    main()\n"]}
{"filename": "core/flowgraphs/freq_samples_to_dat.py", "chunked_list": ["#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n##################################################\n# GNU Radio Python Flow Graph\n# Title: Freq Samples To Dat\n# GNU Radio version: 3.7.13.5\n##################################################\n\nfrom gnuradio import blocks\nfrom gnuradio import eng_notation", "from gnuradio import blocks\nfrom gnuradio import eng_notation\nfrom gnuradio import gr\nfrom gnuradio.eng_option import eng_option\nfrom gnuradio.filter import firdes\nfrom optparse import OptionParser\nimport pmt\n\n\nclass freq_samples_to_dat(gr.top_block):\n\n    def __init__(self, fft_size=512, filename=\"\", noise_pwr_db=-50, output=\"testing\"):\n        gr.top_block.__init__(self, \"Freq Samples To Dat\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.fft_size = fft_size\n        self.filename = filename\n        self.noise_pwr_db = noise_pwr_db\n        self.output = output\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_stream_to_vector_0 = blocks.stream_to_vector(gr.sizeof_gr_complex*1, fft_size)\n        self.blocks_nlog10_ff_0 = blocks.nlog10_ff(10, fft_size, -noise_pwr_db)\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, filename, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_float*fft_size, output+\".dat\", False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_complex_to_mag_squared_0 = blocks.complex_to_mag_squared(fft_size)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_complex_to_mag_squared_0, 0), (self.blocks_nlog10_ff_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_stream_to_vector_0, 0))\n        self.connect((self.blocks_nlog10_ff_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_stream_to_vector_0, 0), (self.blocks_complex_to_mag_squared_0, 0))\n\n    def get_fft_size(self):\n        return self.fft_size\n\n    def set_fft_size(self, fft_size):\n        self.fft_size = fft_size\n\n    def get_filename(self):\n        return self.filename\n\n    def set_filename(self, filename):\n        self.filename = filename\n        self.blocks_file_source_0.open(self.filename, False)\n\n    def get_noise_pwr_db(self):\n        return self.noise_pwr_db\n\n    def set_noise_pwr_db(self, noise_pwr_db):\n        self.noise_pwr_db = noise_pwr_db\n\n    def get_output(self):\n        return self.output\n\n    def set_output(self, output):\n        self.output = output\n        self.blocks_file_sink_0.open(self.output+\".dat\")", "\nclass freq_samples_to_dat(gr.top_block):\n\n    def __init__(self, fft_size=512, filename=\"\", noise_pwr_db=-50, output=\"testing\"):\n        gr.top_block.__init__(self, \"Freq Samples To Dat\")\n\n        ##################################################\n        # Parameters\n        ##################################################\n        self.fft_size = fft_size\n        self.filename = filename\n        self.noise_pwr_db = noise_pwr_db\n        self.output = output\n\n        ##################################################\n        # Blocks\n        ##################################################\n        self.blocks_stream_to_vector_0 = blocks.stream_to_vector(gr.sizeof_gr_complex*1, fft_size)\n        self.blocks_nlog10_ff_0 = blocks.nlog10_ff(10, fft_size, -noise_pwr_db)\n        self.blocks_file_source_0 = blocks.file_source(gr.sizeof_gr_complex*1, filename, False)\n        try:\n            self.blocks_file_source_0.set_begin_tag(pmt.PMT_NIL)\n        except AttributeError:\n            # This is a new feature in 3.7.12 that's not backward compatible to 3.7.10.2.\n            pass\n        self.blocks_file_sink_0 = blocks.file_sink(gr.sizeof_float*fft_size, output+\".dat\", False)\n        self.blocks_file_sink_0.set_unbuffered(False)\n        self.blocks_complex_to_mag_squared_0 = blocks.complex_to_mag_squared(fft_size)\n\n\n\n        ##################################################\n        # Connections\n        ##################################################\n        self.connect((self.blocks_complex_to_mag_squared_0, 0), (self.blocks_nlog10_ff_0, 0))\n        self.connect((self.blocks_file_source_0, 0), (self.blocks_stream_to_vector_0, 0))\n        self.connect((self.blocks_nlog10_ff_0, 0), (self.blocks_file_sink_0, 0))\n        self.connect((self.blocks_stream_to_vector_0, 0), (self.blocks_complex_to_mag_squared_0, 0))\n\n    def get_fft_size(self):\n        return self.fft_size\n\n    def set_fft_size(self, fft_size):\n        self.fft_size = fft_size\n\n    def get_filename(self):\n        return self.filename\n\n    def set_filename(self, filename):\n        self.filename = filename\n        self.blocks_file_source_0.open(self.filename, False)\n\n    def get_noise_pwr_db(self):\n        return self.noise_pwr_db\n\n    def set_noise_pwr_db(self, noise_pwr_db):\n        self.noise_pwr_db = noise_pwr_db\n\n    def get_output(self):\n        return self.output\n\n    def set_output(self, output):\n        self.output = output\n        self.blocks_file_sink_0.open(self.output+\".dat\")", "\n\ndef argument_parser():\n    parser = OptionParser(usage=\"%prog: [options]\", option_class=eng_option)\n    parser.add_option(\n        \"\", \"--fft-size\", dest=\"fft_size\", type=\"intx\", default=512,\n        help=\"Set fft-size [default=%default]\")\n    parser.add_option(\n        \"-f\", \"--filename\", dest=\"filename\", type=\"string\", default=\"\",\n        help=\"Set file [default=%default]\")\n    parser.add_option(\n        \"-n\", \"--noise-pwr-db\", dest=\"noise_pwr_db\", type=\"intx\", default=-50,\n        help=\"Set noise_pwr_db [default=%default]\")\n    parser.add_option(\n        \"-o\", \"--output\", dest=\"output\", type=\"string\", default=\"testing\",\n        help=\"Set outfile [default=%default]\")\n    return parser", "\n\ndef main(top_block_cls=freq_samples_to_dat, options=None):\n    if options is None:\n        options, _ = argument_parser().parse_args()\n\n    tb = top_block_cls(fft_size=options.fft_size, filename=options.filename, noise_pwr_db=options.noise_pwr_db, output=options.output)\n    tb.start()\n    tb.wait()\n", "\n\nif __name__ == '__main__':\n    main()\n"]}
