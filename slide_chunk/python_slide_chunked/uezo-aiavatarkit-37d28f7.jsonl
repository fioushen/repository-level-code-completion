{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\n\nsetup(\n    name=\"aiavatar\",\n    version=\"0.2.1\",\n    url=\"https://github.com/uezo/aiavatar\",\n    author=\"uezo\",\n    author_email=\"uezo@uezo.net\",\n    maintainer=\"uezo\",\n    maintainer_email=\"uezo@uezo.net\",", "    maintainer=\"uezo\",\n    maintainer_email=\"uezo@uezo.net\",\n    description=\"\ud83e\udd70 Building AI-based conversational avatars lightning fast \u26a1\ufe0f\ud83d\udcac\",\n    long_description=open(\"README.md\").read(),\n    long_description_content_type=\"text/markdown\",\n    packages=find_packages(exclude=[\"examples*\", \"tests*\"]),\n    install_requires=[\"aiohttp\", \"numpy\", \"openai\", \"sounddevice\"],\n    license=\"Apache v2\",\n    classifiers=[\n        \"Programming Language :: Python :: 3\"", "    classifiers=[\n        \"Programming Language :: Python :: 3\"\n    ]\n)\n"]}
{"filename": "tests/processors/test_chatgpt.py", "chunked_list": ["import pytest\nfrom aiavatar.processors.chatgpt import ChatGPTProcessor\n\n@pytest.fixture\ndef chatgpt_processor():\n    return ChatGPTProcessor(\"YOUR_API_KEY\", temperature=0.0)\n\n@pytest.mark.asyncio\nasync def test_chat(chatgpt_processor: ChatGPTProcessor):\n    resp_iter = chatgpt_processor.chat(\"\u304a\u3057\u3083\u3079\u308a\u3057\u3088\u3046\")", "async def test_chat(chatgpt_processor: ChatGPTProcessor):\n    resp_iter = chatgpt_processor.chat(\"\u304a\u3057\u3083\u3079\u308a\u3057\u3088\u3046\")\n\n    async for r in resp_iter:\n        assert len(r) > 0\n\n    assert len(chatgpt_processor.histories) == 2\n\n@pytest.mark.asyncio\nasync def test_reset_histories(chatgpt_processor: ChatGPTProcessor):", "@pytest.mark.asyncio\nasync def test_reset_histories(chatgpt_processor: ChatGPTProcessor):\n    chatgpt_processor.histories.append(\"a\")\n    chatgpt_processor.histories.append(\"b\")\n\n    assert len(chatgpt_processor.histories) == 2\n\n    chatgpt_processor.reset_histories()\n\n    assert len(chatgpt_processor.histories) == 0", "\n    assert len(chatgpt_processor.histories) == 0\n"]}
{"filename": "tests/device/test_audio.py", "chunked_list": ["from aiavatar.device import AudioDevice\n\ndef test_get_default_input_device_info():\n    d = AudioDevice.get_default_input_device_info()\n    assert d[\"index\"] >= 0\n    assert d[\"index\"] < 1000\n    assert d[\"name\"] is not None\n\ndef test_get_default_output_device_info():\n    d = AudioDevice.get_default_output_device_info()\n    assert d[\"index\"] >= 0\n    assert d[\"index\"] < 1000\n    assert d[\"name\"] is not None", "def test_get_default_output_device_info():\n    d = AudioDevice.get_default_output_device_info()\n    assert d[\"index\"] >= 0\n    assert d[\"index\"] < 1000\n    assert d[\"name\"] is not None\n\ndef test_get_input_device_by_name():\n    d = AudioDevice.get_input_device_by_name(\"\u30de\u30a4\u30af\")\n    assert d is not None\n    assert d[\"index\"] >= 0\n    assert d[\"max_input_channels\"] > 0\n\n    d = AudioDevice.get_input_device_by_name(\"_aiavater_dummy_\")\n    assert d is None", "\ndef test_get_output_device_by_name():\n    d = AudioDevice.get_output_device_by_name(\"\u30b9\u30d4\u30fc\u30ab\u30fc\")\n    assert d is not None\n    assert d[\"index\"] >= 0\n    assert d[\"max_output_channels\"] > 0\n\n    d = AudioDevice.get_output_device_by_name(\"_aiavater_dummy_\")\n    assert d is None\n\ndef test_get_audio_devices():\n    devices = AudioDevice.get_audio_devices()\n    assert len(devices) >= 2\n\n    for d in devices:\n        assert d[\"index\"] >= 0\n        assert d[\"index\"] < 1000\n        assert d[\"name\"] is not None", "\ndef test_get_audio_devices():\n    devices = AudioDevice.get_audio_devices()\n    assert len(devices) >= 2\n\n    for d in devices:\n        assert d[\"index\"] >= 0\n        assert d[\"index\"] < 1000\n        assert d[\"name\"] is not None\n", ""]}
{"filename": "tests/speech/test_voicevox.py", "chunked_list": ["import asyncio\nimport pytest\nfrom time import time\nfrom aiavatar.speech.voicevox import VoicevoxSpeechController\n\n@pytest.fixture\ndef voicevox_controller():\n    return VoicevoxSpeechController(base_url=\"http://127.0.0.1:50021\", speaker_id=46)\n\n@pytest.mark.asyncio", "\n@pytest.mark.asyncio\nasync def test_prefetch_download_task_started(voicevox_controller):\n    text = \"\u3053\u3093\u306b\u3061\u306f\"\n    voice = voicevox_controller.prefetch(text)\n    assert voice.text == text\n    assert voice.download_task is not None\n    assert voice.audio_clip is None\n\n@pytest.mark.asyncio", "\n@pytest.mark.asyncio\nasync def test_prefetch_download_completed(voicevox_controller):\n    text = \"\u3053\u3093\u306b\u3061\u306f\"\n    voice = voicevox_controller.prefetch(text)\n    await voice.download_task\n    assert voice.audio_clip is not None\n\n@pytest.mark.asyncio\nasync def test_speak_audio_played(voicevox_controller):", "@pytest.mark.asyncio\nasync def test_speak_audio_played(voicevox_controller):\n    text = \"\u3053\u3093\u306b\u3061\u306f\u3002\u3053\u306e\u97f3\u58f0\u306f\u3001\u30c6\u30b9\u30c8\u306e\u305f\u3081\u306b\u518d\u751f\u3055\u308c\u3066\u3044\u307e\u3059\u3002\"\n    start_time = time()\n    await voicevox_controller.speak(text)\n    assert time() - start_time > 1\n\n@pytest.mark.asyncio\nasync def test_is_speaking(voicevox_controller):\n    text = \"\u3053\u3093\u306b\u3061\u306f\u3002\u3053\u306e\u97f3\u58f0\u306f\u3001\u30c6\u30b9\u30c8\u306e\u305f\u3081\u306b\u518d\u751f\u3055\u308c\u3066\u3044\u307e\u3059\u3002\"", "async def test_is_speaking(voicevox_controller):\n    text = \"\u3053\u3093\u306b\u3061\u306f\u3002\u3053\u306e\u97f3\u58f0\u306f\u3001\u30c6\u30b9\u30c8\u306e\u305f\u3081\u306b\u518d\u751f\u3055\u308c\u3066\u3044\u307e\u3059\u3002\"\n    voice = voicevox_controller.prefetch(text)\n    await voice.download_task\n\n    assert voicevox_controller.is_speaking() is False\n\n    speech_task = asyncio.create_task(voicevox_controller.speak(text))\n    await asyncio.sleep(0.1)    # wait for starting speech\n", "    await asyncio.sleep(0.1)    # wait for starting speech\n\n    while not speech_task.done():\n        assert voicevox_controller.is_speaking() is True\n        await asyncio.sleep(0.1)\n    \n    await speech_task\n\n    assert voicevox_controller.is_speaking() is False\n", "    assert voicevox_controller.is_speaking() is False\n"]}
{"filename": "aiavatar/avatar.py", "chunked_list": ["import asyncio\nfrom logging import getLogger, NullHandler\nimport re\nfrom typing import Callable\nfrom .speech import SpeechController\nfrom .animation import AnimationController\nfrom .face import FaceController\n\nclass AvatarRequest:\n    def __init__(self, text_to_speech: str=None, animation_name: str=None, animation_duration: float = 3.0, face_name: str=None, face_duration: float=3.0):\n        self.text_to_speech = text_to_speech\n        self.animation_name = animation_name\n        self.animation_duration = animation_duration\n        self.face_name = face_name\n        self.face_duration = face_duration", "class AvatarRequest:\n    def __init__(self, text_to_speech: str=None, animation_name: str=None, animation_duration: float = 3.0, face_name: str=None, face_duration: float=3.0):\n        self.text_to_speech = text_to_speech\n        self.animation_name = animation_name\n        self.animation_duration = animation_duration\n        self.face_name = face_name\n        self.face_duration = face_duration\n\n\nclass AvatarController:\n    def __init__(self, speech_controller: SpeechController, animation_controller: AnimationController, face_controller: FaceController, parser: Callable=None):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.speech_controller = speech_controller\n        self.animation_controller = animation_controller\n        self.animation_task = None\n        self.face_controller = face_controller\n        self.face_task = None\n        self.parse = parser or self.parse_default\n        self.requests = []\n\n    async def start(self):\n        # TODO: Stop exisiting tasks before start processing new requests\n\n        while True:\n            if len(self.requests) > 0:\n                req = self.requests.pop(0)\n                if req is None:\n                    break\n                await self.perform(req)\n            else:\n                await asyncio.sleep(0.01)\n\n    def parse_default(self, text: str) -> AvatarRequest:\n        avreq = AvatarRequest()\n\n        # Face\n        face_pattarn = r\"\\[face:(\\w+)\\]\"\n        faces = re.findall(face_pattarn, text)\n        if faces:\n            avreq.face_name = faces[0]\n            avreq.face_duration = 4.0\n            text = re.sub(face_pattarn, \"\", text)\n\n        # Animation\n        animation_pattarn = r\"\\[animation:(\\w+)\\]\"\n        animations = re.findall(animation_pattarn, text)\n        if animations:\n            avreq.animation_name = animations[0]\n            avreq.animation_duration = 4.0\n            text = re.sub(animation_pattarn, \"\", text)\n\n        # Speech\n        avreq.text_to_speech = text\n\n        return avreq\n\n    def set_text(self, text: str):\n        avreq = self.parse(text)\n        self.speech_controller.prefetch(avreq.text_to_speech)\n        self.requests.append(avreq)\n\n    def set_stop(self):\n        self.requests.append(None)\n\n    async def perform(self, avatar_request: AvatarRequest):\n        # Face\n        if avatar_request.face_name:\n            if self.face_task:\n                self.face_task.cancel()\n            self.face_task = asyncio.create_task(\n                self.face_controller.set_face(avatar_request.face_name, avatar_request.face_duration)\n            )\n        \n        # Animation\n        if avatar_request.animation_name:\n            if self.animation_task:\n                self.animation_task.cancel()\n            self.animation_task = asyncio.create_task(\n                self.animation_controller.animate(avatar_request.animation_name, avatar_request.animation_duration)\n            )\n\n        # Speech\n        self.logger.info(avatar_request.text_to_speech)\n        await self.speech_controller.speak(avatar_request.text_to_speech)\n\n    def is_speaking(self) -> bool:\n        return self.speech_controller.is_speaking()", "\nclass AvatarController:\n    def __init__(self, speech_controller: SpeechController, animation_controller: AnimationController, face_controller: FaceController, parser: Callable=None):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.speech_controller = speech_controller\n        self.animation_controller = animation_controller\n        self.animation_task = None\n        self.face_controller = face_controller\n        self.face_task = None\n        self.parse = parser or self.parse_default\n        self.requests = []\n\n    async def start(self):\n        # TODO: Stop exisiting tasks before start processing new requests\n\n        while True:\n            if len(self.requests) > 0:\n                req = self.requests.pop(0)\n                if req is None:\n                    break\n                await self.perform(req)\n            else:\n                await asyncio.sleep(0.01)\n\n    def parse_default(self, text: str) -> AvatarRequest:\n        avreq = AvatarRequest()\n\n        # Face\n        face_pattarn = r\"\\[face:(\\w+)\\]\"\n        faces = re.findall(face_pattarn, text)\n        if faces:\n            avreq.face_name = faces[0]\n            avreq.face_duration = 4.0\n            text = re.sub(face_pattarn, \"\", text)\n\n        # Animation\n        animation_pattarn = r\"\\[animation:(\\w+)\\]\"\n        animations = re.findall(animation_pattarn, text)\n        if animations:\n            avreq.animation_name = animations[0]\n            avreq.animation_duration = 4.0\n            text = re.sub(animation_pattarn, \"\", text)\n\n        # Speech\n        avreq.text_to_speech = text\n\n        return avreq\n\n    def set_text(self, text: str):\n        avreq = self.parse(text)\n        self.speech_controller.prefetch(avreq.text_to_speech)\n        self.requests.append(avreq)\n\n    def set_stop(self):\n        self.requests.append(None)\n\n    async def perform(self, avatar_request: AvatarRequest):\n        # Face\n        if avatar_request.face_name:\n            if self.face_task:\n                self.face_task.cancel()\n            self.face_task = asyncio.create_task(\n                self.face_controller.set_face(avatar_request.face_name, avatar_request.face_duration)\n            )\n        \n        # Animation\n        if avatar_request.animation_name:\n            if self.animation_task:\n                self.animation_task.cancel()\n            self.animation_task = asyncio.create_task(\n                self.animation_controller.animate(avatar_request.animation_name, avatar_request.animation_duration)\n            )\n\n        # Speech\n        self.logger.info(avatar_request.text_to_speech)\n        await self.speech_controller.speak(avatar_request.text_to_speech)\n\n    def is_speaking(self) -> bool:\n        return self.speech_controller.is_speaking()", ""]}
{"filename": "aiavatar/bot.py", "chunked_list": ["import asyncio\nfrom logging import getLogger, NullHandler\nimport traceback\nfrom typing import Callable\n# Device\nfrom .device import AudioDevice\n# Processor\nfrom .processors.chatgpt import ChatGPTProcessor\n# Listener\nfrom .listeners.voicerequest import VoiceRequestListener", "# Listener\nfrom .listeners.voicerequest import VoiceRequestListener\n# Avatar\nfrom .speech.voicevox import VoicevoxSpeechController\nfrom .animation import AnimationController, AnimationControllerDummy\nfrom .face import FaceController, FaceControllerDummy\nfrom .avatar import AvatarController\n\nclass AIAvatar:\n    def __init__(\n        self,\n        google_api_key: str,\n        openai_api_key: str,\n        voicevox_url: str,\n        voicevox_speaker_id: int=46,\n        volume_threshold: int=3000,\n        start_voice: str=\"\u3069\u3046\u3057\u305f\u306e\",\n        functions: dict=None,\n        system_message_content: str=None,\n        animation_controller: AnimationController=None,\n        face_controller: FaceController=None,\n        avatar_request_parser: Callable=None,\n        input_device: int=-1,\n        output_device: int=-1\n    ):\n\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.google_api_key = google_api_key\n        self.openai_api_key = openai_api_key\n        self.voicevox_url = voicevox_url\n        self.voicevox_speaker_id = voicevox_speaker_id\n        self.volume_threshold = volume_threshold\n\n        # Audio Devices\n        if isinstance(input_device, int):\n            if input_device < 0:\n                input_device_info = AudioDevice.get_default_input_device_info()\n                input_device = input_device_info[\"index\"]\n            else:\n                input_device_info = AudioDevice.get_device_info(input_device)\n        elif isinstance(input_device, str):\n            input_device_info = AudioDevice.get_input_device_by_name(input_device)\n            if input_device_info is None:\n                input_device_info = AudioDevice.get_default_input_device_info()\n            input_device = input_device_info[\"index\"]\n\n        self.input_device = input_device\n        self.logger.info(f\"Input device: [{input_device}] {input_device_info['name']}\")\n\n        if isinstance(output_device, int):\n            if output_device < 0:\n                output_device_info = AudioDevice.get_default_output_device_info()\n                output_device = output_device_info[\"index\"]\n            else:\n                output_device_info = AudioDevice.get_device_info(output_device)\n        elif isinstance(output_device, str):\n            output_device_info = AudioDevice.get_output_device_by_name(output_device)\n            if output_device_info is None:\n                output_device_info = AudioDevice.get_default_output_device_info()\n            output_device = output_device_info[\"index\"]\n\n        self.output_device = output_device\n        self.logger.info(f\"Output device: [{output_device}] {output_device_info['name']}\")\n\n        # Processor\n        self.chat_processor = ChatGPTProcessor(self.openai_api_key, functions=functions, system_message_content=system_message_content)\n\n        # Listeners\n        self.request_listener = VoiceRequestListener(self.google_api_key, volume_threshold=volume_threshold, device_index=self.input_device)\n\n        # Avatar\n        speech_controller = VoicevoxSpeechController(self.voicevox_url, self.voicevox_speaker_id, device_index=self.output_device)\n        animation_controller = animation_controller or AnimationControllerDummy()\n        face_controller = face_controller or FaceControllerDummy()\n        self.avatar_controller = AvatarController(speech_controller, animation_controller, face_controller, avatar_request_parser)\n\n        # Chat\n        self.chat_task = None\n        self.start_voice = start_voice\n\n    async def chat(self, request_on_start: str=None, skip_start_voice: bool=False):\n        if not skip_start_voice:\n            try:\n                await self.avatar_controller.speech_controller.speak(self.start_voice)\n            except Exception as ex:\n                self.logger.error(f\"Error at starting chat: {str(ex)}\\n{traceback.format_exc()}\")\n\n        while True:\n            try:\n                if request_on_start:\n                    req = request_on_start\n                    request_on_start = None\n                else:\n                    req = await self.request_listener.get_request()\n                    if not req:\n                        break\n\n                self.logger.info(f\"User: {req}\")\n                self.logger.info(\"AI:\")\n\n                avatar_task = asyncio.create_task(self.avatar_controller.start())\n\n                stream_buffer = \"\"\n                async for t in self.chat_processor.chat(req):\n                    stream_buffer += t\n                    sp = stream_buffer.replace(\"\u3002\", \"\u3002|\").replace(\"\u3001\", \"\u3001|\").replace(\"\uff01\", \"\uff01|\").replace(\"\uff1f\", \"\uff1f|\").split(\"|\")\n                    if len(sp) > 1: # >1 means `|` is found (splited at the end of sentence)\n                        sentence = sp.pop(0)\n                        stream_buffer = \"\".join(sp)\n                        self.avatar_controller.set_text(sentence)\n\n                self.avatar_controller.set_stop()\n                await avatar_task\n            \n            except Exception as ex:\n                self.logger.error(f\"Error at chatting loop: {str(ex)}\\n{traceback.format_exc()}\")\n\n    async def start_chat(self, request_on_start: str=None, skip_start_voice: bool=False):\n        self.stop_chat()\n        self.chat_task = asyncio.create_task(self.chat(request_on_start, skip_start_voice))\n        await self.chat_task\n\n    def stop_chat(self):\n        if self.chat_task is not None:\n            self.chat_task.cancel()", "class AIAvatar:\n    def __init__(\n        self,\n        google_api_key: str,\n        openai_api_key: str,\n        voicevox_url: str,\n        voicevox_speaker_id: int=46,\n        volume_threshold: int=3000,\n        start_voice: str=\"\u3069\u3046\u3057\u305f\u306e\",\n        functions: dict=None,\n        system_message_content: str=None,\n        animation_controller: AnimationController=None,\n        face_controller: FaceController=None,\n        avatar_request_parser: Callable=None,\n        input_device: int=-1,\n        output_device: int=-1\n    ):\n\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.google_api_key = google_api_key\n        self.openai_api_key = openai_api_key\n        self.voicevox_url = voicevox_url\n        self.voicevox_speaker_id = voicevox_speaker_id\n        self.volume_threshold = volume_threshold\n\n        # Audio Devices\n        if isinstance(input_device, int):\n            if input_device < 0:\n                input_device_info = AudioDevice.get_default_input_device_info()\n                input_device = input_device_info[\"index\"]\n            else:\n                input_device_info = AudioDevice.get_device_info(input_device)\n        elif isinstance(input_device, str):\n            input_device_info = AudioDevice.get_input_device_by_name(input_device)\n            if input_device_info is None:\n                input_device_info = AudioDevice.get_default_input_device_info()\n            input_device = input_device_info[\"index\"]\n\n        self.input_device = input_device\n        self.logger.info(f\"Input device: [{input_device}] {input_device_info['name']}\")\n\n        if isinstance(output_device, int):\n            if output_device < 0:\n                output_device_info = AudioDevice.get_default_output_device_info()\n                output_device = output_device_info[\"index\"]\n            else:\n                output_device_info = AudioDevice.get_device_info(output_device)\n        elif isinstance(output_device, str):\n            output_device_info = AudioDevice.get_output_device_by_name(output_device)\n            if output_device_info is None:\n                output_device_info = AudioDevice.get_default_output_device_info()\n            output_device = output_device_info[\"index\"]\n\n        self.output_device = output_device\n        self.logger.info(f\"Output device: [{output_device}] {output_device_info['name']}\")\n\n        # Processor\n        self.chat_processor = ChatGPTProcessor(self.openai_api_key, functions=functions, system_message_content=system_message_content)\n\n        # Listeners\n        self.request_listener = VoiceRequestListener(self.google_api_key, volume_threshold=volume_threshold, device_index=self.input_device)\n\n        # Avatar\n        speech_controller = VoicevoxSpeechController(self.voicevox_url, self.voicevox_speaker_id, device_index=self.output_device)\n        animation_controller = animation_controller or AnimationControllerDummy()\n        face_controller = face_controller or FaceControllerDummy()\n        self.avatar_controller = AvatarController(speech_controller, animation_controller, face_controller, avatar_request_parser)\n\n        # Chat\n        self.chat_task = None\n        self.start_voice = start_voice\n\n    async def chat(self, request_on_start: str=None, skip_start_voice: bool=False):\n        if not skip_start_voice:\n            try:\n                await self.avatar_controller.speech_controller.speak(self.start_voice)\n            except Exception as ex:\n                self.logger.error(f\"Error at starting chat: {str(ex)}\\n{traceback.format_exc()}\")\n\n        while True:\n            try:\n                if request_on_start:\n                    req = request_on_start\n                    request_on_start = None\n                else:\n                    req = await self.request_listener.get_request()\n                    if not req:\n                        break\n\n                self.logger.info(f\"User: {req}\")\n                self.logger.info(\"AI:\")\n\n                avatar_task = asyncio.create_task(self.avatar_controller.start())\n\n                stream_buffer = \"\"\n                async for t in self.chat_processor.chat(req):\n                    stream_buffer += t\n                    sp = stream_buffer.replace(\"\u3002\", \"\u3002|\").replace(\"\u3001\", \"\u3001|\").replace(\"\uff01\", \"\uff01|\").replace(\"\uff1f\", \"\uff1f|\").split(\"|\")\n                    if len(sp) > 1: # >1 means `|` is found (splited at the end of sentence)\n                        sentence = sp.pop(0)\n                        stream_buffer = \"\".join(sp)\n                        self.avatar_controller.set_text(sentence)\n\n                self.avatar_controller.set_stop()\n                await avatar_task\n            \n            except Exception as ex:\n                self.logger.error(f\"Error at chatting loop: {str(ex)}\\n{traceback.format_exc()}\")\n\n    async def start_chat(self, request_on_start: str=None, skip_start_voice: bool=False):\n        self.stop_chat()\n        self.chat_task = asyncio.create_task(self.chat(request_on_start, skip_start_voice))\n        await self.chat_task\n\n    def stop_chat(self):\n        if self.chat_task is not None:\n            self.chat_task.cancel()", ""]}
{"filename": "aiavatar/__init__.py", "chunked_list": ["# Device\nfrom .device import AudioDevice\n# Processor\nfrom .processors.chatgpt import ChatGPTProcessor\n# Listener\nfrom .listeners.wakeword import WakewordListener\nfrom .listeners.voicerequest import VoiceRequestListener\n# Avatar\nfrom .speech.voicevox import VoicevoxSpeechController\nfrom .avatar import AvatarController", "from .speech.voicevox import VoicevoxSpeechController\nfrom .avatar import AvatarController\n# Bot\nfrom .bot import AIAvatar\n"]}
{"filename": "aiavatar/processors/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom typing import Iterator\n\nclass ChatProcessor(ABC):\n    @abstractmethod\n    async def chat(self, text: str) -> Iterator[str]:\n        pass\n"]}
{"filename": "aiavatar/processors/chatgpt.py", "chunked_list": ["from logging import getLogger, NullHandler\nimport traceback\nimport json\nfrom typing import Iterator, Callable\nfrom openai import ChatCompletion\nfrom . import ChatProcessor\n\nclass ChatGPTFunction:\n    def __init__(self, name: str, description: str=None, parameters: dict=None, func: Callable=None):\n        self.name = name\n        self.description = description\n        self.parameters = parameters\n        self.func = func\n    \n    def get_spec(self):\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"parameters\": self.parameters\n        }", "\n\nclass ChatCompletionStreamResponse:\n    def __init__(self, stream: Iterator[str], function_name: str=None):\n        self.stream = stream\n        self.function_name = function_name\n\n    @property\n    def response_type(self):\n        return \"function_call\" if self.function_name else \"content\"", "\n\nclass ChatGPTProcessor(ChatProcessor):\n    def __init__(self, api_key: str, model: str=\"gpt-3.5-turbo-0613\", temperature: float=1.0, max_tokens: int=0, functions: dict=None, system_message_content: str=None, history_count: int=10):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.api_key = api_key\n        self.model = model\n        self.temperature = temperature\n        self.max_tokens = max_tokens\n        self.functions = functions or {}\n        self.system_message_content = system_message_content\n        self.history_count = history_count\n        self.histories = []\n\n    def add_function(self, name: str, description: str=None, parameters: dict=None, func: Callable=None):\n        self.functions[name] = ChatGPTFunction(name=name, description=description, parameters=parameters, func=func)\n\n    def reset_histories(self):\n        self.histories.clear()\n\n    async def chat_completion_stream(self, messages, call_functions: bool=True):\n        params = {\n            \"api_key\": self.api_key,\n            \"messages\": messages,\n            \"model\": self.model,\n            \"temperature\": self.temperature,\n            \"stream\": True,\n        }\n        if self.max_tokens:\n            params[\"max_tokens\"] = self.max_tokens\n\n        if call_functions and self.functions:\n            params[\"functions\"] = [v.get_spec() for _, v in self.functions.items()]\n\n        stream_resp = ChatCompletionStreamResponse(await ChatCompletion.acreate(**params))\n\n        async for chunk in stream_resp.stream:\n            if chunk:\n                delta = chunk[\"choices\"][0][\"delta\"]\n                if delta.get(\"function_call\"):\n                    stream_resp.function_name = delta[\"function_call\"][\"name\"]\n                break\n        \n        return stream_resp\n\n    async def chat(self, text: str) -> Iterator[str]:\n        try:\n            messages = []\n            if self.system_message_content:\n                messages.append({\"role\": \"system\", \"content\": self.system_message_content})\n            messages.extend(self.histories[-1 * self.history_count:])\n            messages.append({\"role\": \"user\", \"content\": text})\n\n            response_text = \"\"\n            stream_resp = await self.chat_completion_stream(messages)\n\n            async for chunk in stream_resp.stream:\n                delta = chunk[\"choices\"][0][\"delta\"]\n                if stream_resp.response_type == \"content\":\n                    content = delta.get(\"content\")\n                    if content:\n                        response_text += delta[\"content\"]\n                        yield content\n\n                elif stream_resp.response_type == \"function_call\":\n                    function_call = delta.get(\"function_call\")\n                    if function_call:\n                        arguments = function_call[\"arguments\"]\n                        response_text += arguments\n\n            if stream_resp.response_type == \"function_call\":\n                self.histories.append(messages[-1])\n                self.histories.append({\n                    \"role\": \"assistant\",\n                    \"function_call\": {\n                        \"name\": stream_resp.function_name,\n                        \"arguments\": response_text\n                    },\n                    \"content\": None\n                })\n\n                api_resp = await self.functions[stream_resp.function_name].func(**json.loads(response_text))\n\n                messages.append({\"role\": \"function\", \"content\": json.dumps(api_resp), \"name\": stream_resp.function_name})\n\n                response_text = \"\"\n                stream_resp = await self.chat_completion_stream(messages, False)\n\n                async for chunk in stream_resp.stream:\n                    delta = chunk[\"choices\"][0][\"delta\"]\n                    content = delta.get(\"content\")\n                    if content:\n                        response_text += content\n                        yield content\n                \n            if response_text:\n                self.histories.append(messages[-1])\n                self.histories.append({\"role\": \"assistant\", \"content\": response_text})\n\n        except Exception as ex:\n            self.logger.error(f\"Error at chat: {str(ex)}\\n{traceback.format_exc()}\")\n            raise ex", ""]}
{"filename": "aiavatar/face/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\nfrom logging import getLogger, NullHandler\nfrom threading import Thread\nfrom time import time, sleep\n\nclass FaceController(ABC):\n    @abstractmethod\n    async def set_face(self, name: str, duration: float):\n        pass\n\n    @abstractmethod\n    def reset(self):\n        pass", "\n\nclass FaceControllerBase(FaceController):\n    def __init__(self, verbose: bool=False):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n        self.verbose = verbose\n\n        self.faces = {\n            \"neutral\": \"('_')\",\n            \"joy\": \"(^o^)\",\n            \"angry\": \"(#\uff40\u0414\u00b4)\",\n            \"sorrow\": \"(; ;)\",\n            \"fun\": \"(*^_^*)\",\n        }\n\n        self.reset_at = None\n        self.reset_thread = Thread(target=self.reset_worker, daemon=True)\n        self.reset_thread.start()\n\n    def reset_worker(self):\n        while True:\n            if self.reset_at and time() >= self.reset_at:\n                if self.verbose:\n                    self.logger.info(f\"Time to reset: {self.reset_at}\")\n                self.reset()\n                self.reset_at = None\n\n            sleep(0.1)\n\n    def subscribe_reset(self, reset_at: float):\n        self.reset_at = reset_at\n        if self.verbose:\n            self.logger.info(f\"Reset subscribed at {self.reset_at}\")\n\n    async def set_face(self, name: str, duration: float):\n        self.subscribe_reset(time() + duration)\n        self.logger.info(f\"face: {self.faces[name]} ({name})\")\n\n    def reset(self):\n        self.logger.info(f\"Reset face: {self.faces['neutral']} (neutral)\")", "\n\nclass FaceControllerDummy(FaceControllerBase):\n    pass\n"]}
{"filename": "aiavatar/face/vrchat.py", "chunked_list": ["import asyncio\nfrom time import time\nfrom pythonosc import udp_client\nfrom . import FaceControllerBase\n\nclass VRChatFaceController(FaceControllerBase):\n    def __init__(self, osc_address: str=\"/avatar/parameters/FaceOSC\", faces: dict=None, neutral_key: str=\"neutral\", host: str=\"127.0.0.1\", port: int=9000, verbose: bool=False):\n        super().__init__(verbose)\n\n        self.osc_address = osc_address\n        self.faces = faces or {\n            \"neutral\": 0,\n            \"joy\": 1,\n            \"angry\": 2,\n            \"sorrow\": 3,\n            \"fun\": 4,\n            \"surprise\": 5,\n        }\n        self.neutral_key = neutral_key\n        self.host = host\n        self.port = port\n\n        self.client = udp_client.SimpleUDPClient(self.host, self.port)\n\n    async def set_face(self, name: str, duration: float):\n        self.subscribe_reset(time() + duration)\n\n        osc_value = self.faces.get(name)\n        if osc_value is None:\n            self.logger.warning(f\"Face '{name}' is not registered\")\n            return\n\n        self.logger.info(f\"face: {name} ({osc_value})\")\n        self.client.send_message(self.osc_address, osc_value)\n\n    def reset(self):\n        self.logger.info(f\"Reset face: {self.neutral_key} ({self.faces[self.neutral_key]})\")\n        self.client.send_message(self.osc_address, self.faces[self.neutral_key])\n\n    def test_osc(self):\n        while True:\n            self.set_face(input(\"Face name: \"), 3.0)", "\nif __name__ == \"__main__\":\n    vrc_face_controller = VRChatFaceController()\n    asyncio.run(vrc_face_controller.test_osc())\n"]}
{"filename": "aiavatar/listeners/wakeword.py", "chunked_list": ["import asyncio\nfrom threading import Thread\nfrom typing import Callable\nfrom . import SpeechListenerBase\n\nclass WakewordListener(SpeechListenerBase):\n    def __init__(self, api_key: str, wakewords: list, on_wakeword: Callable, volume_threshold: int=3000, timeout: float=0.3, min_duration: float=0.2, max_duration: float=2, lang: str=\"ja-JP\", rate: int=44100, chennels: int=1, device_index: int=-1, verbose: bool=False):\n        super().__init__(api_key, self.invoke_on_wakeword, volume_threshold, timeout, 0.0, min_duration, max_duration, lang, rate, chennels, device_index)\n        self.wakewords = wakewords\n        self.on_wakeword = on_wakeword\n        self.verbose = verbose\n    \n    async def invoke_on_wakeword(self, text: str):\n        if self.verbose:\n            self.logger.info(f\"Recognized: {text}\")\n\n        if text in self.wakewords:\n            await self.on_wakeword(text)\n\n    def start(self):\n        th = Thread(target=asyncio.run, args=(self.start_listening(),), daemon=True)\n        th.start()\n        return th", ""]}
{"filename": "aiavatar/listeners/__init__.py", "chunked_list": ["import base64\nfrom logging import getLogger, NullHandler\nimport numpy\nimport time\nimport traceback\nfrom typing import Callable\nimport aiohttp\nimport sounddevice\n\nclass SpeechListenerBase:\n    def __init__(self, api_key: str, on_speech_recognized: Callable, volume_threshold: int=3000, timeout: float=1.0, detection_timeout: float=0.0, min_duration: float=0.3, max_duration: float=20.0, lang: str=\"ja-JP\", rate: int=44100, channels: int=1, device_index: int=-1):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.api_key = api_key\n        self.on_speech_recognized = on_speech_recognized\n        self.volume_threshold = volume_threshold\n        self.timeout = timeout\n        self.detection_timeout = detection_timeout\n        self.min_duration = min_duration\n        self.max_duration = max_duration\n        self.lang = lang\n        self.channels = channels\n        self.rate = rate\n        self.device_index = device_index\n        self.is_listening = False\n\n    def record_audio(self, device_index) -> bytes:\n        audio_data = []\n\n        def callback(in_data, frame_count, time_info, status):\n            audio_data.append(in_data.copy())\n\n        try:\n            stream = sounddevice.InputStream(\n                device=device_index,\n                channels=self.channels,\n                samplerate=self.rate,\n                dtype=numpy.int16,\n                callback=callback\n            )\n\n            start_time = time.time()\n            is_recording = False\n            silence_start_time = time.time()\n            is_silent = False\n            last_detected_time = time.time()\n            stream.start()\n\n            while stream.active:\n                current_time = time.time()\n                volume = numpy.linalg.norm(audio_data[-10:]) / 50 if audio_data else 0\n\n                if not is_recording:\n                    if volume > self.volume_threshold:\n                        audio_data = audio_data[-100:]  # Use 100ms data before start recording\n                        is_recording = True\n                        start_time = current_time\n\n                else:\n                    if volume <= self.volume_threshold:\n                        if is_silent:\n                            if current_time - silence_start_time > self.timeout:\n                                # Timeouot\n                                recorded_length = current_time - start_time - self.timeout\n\n                                if recorded_length < self.min_duration:\n                                    self.logger.info(f\"Too short: {recorded_length}\")\n                                    is_recording = False\n                                    audio_data.clear()\n\n                                else:\n                                    return b\"\".join(audio_data)\n                            else:\n                                # Continue silent\n                                pass\n\n                        else:\n                            # Start silent\n                            silence_start_time = current_time\n                            is_silent = True\n\n                    else:\n                        # Detecting voice\n                        is_silent = False\n                        last_detected_time = current_time\n\n                    if current_time - start_time > self.max_duration:\n                        self.logger.info(f\"Max recording duration reached: {current_time - start_time}\")\n                        is_recording = False\n                        audio_data.clear()\n\n                if self.detection_timeout > 0 and time.time() - last_detected_time > self.detection_timeout:\n                    self.logger.info(f\"Voice detection timeout: {self.detection_timeout}\")\n                    break\n\n        except Exception as ex:\n            self.logger.error(f\"Error at record_audio: {str(ex)}\\n{traceback.format_exc()}\")\n\n        finally:\n            stream.stop()\n            stream.close()\n\n        # Return empty bytes\n        return b\"\".join([])\n\n    async def transcribe(self, audio_data: list) -> str:\n        audio_b64 = base64.b64encode(audio_data).decode(\"utf-8\")\n\n        request_body = {\n            \"config\": {\n                \"encoding\": \"LINEAR16\",\n                \"sampleRateHertz\": self.rate,\n                \"languageCode\": self.lang,\n            },\n            \"audio\": {\n                \"content\": audio_b64\n            },\n        }\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                f\"https://speech.googleapis.com/v1/speech:recognize?key={self.api_key}\",\n                json=request_body\n            ) as resp:\n                j = await resp.json()\n\n                if resp.status != 200:\n                    self.logger.error(f\"Failed in recognition: {resp.status}\\n{j}\")\n                    return None\n\n                if j.get(\"results\"):\n                    if j[\"results\"][0][\"alternatives\"][0].get(\"transcript\"):\n                        return j[\"results\"][0][\"alternatives\"][0][\"transcript\"]\n\n        return None\n\n    async def start_listening(self):\n        self.is_listening = True\n\n        try:\n            self.logger.info(f\"Listening... ({self.__class__.__name__})\")\n            while self.is_listening:\n                audio_data = self.record_audio(self.device_index)\n\n                if audio_data:\n                    recognized_text = await self.transcribe(audio_data)\n\n                    if recognized_text:\n                        await self.on_speech_recognized(recognized_text)\n                    else:\n                        self.logger.info(\"No speech recognized\")\n                \n                else:\n                    # Stop listening when no recorded data\n                    break\n\n            self.logger.info(f\"Stopped listening ({self.__class__.__name__})\")\n\n        except Exception as ex:\n            self.logger.error(f\"Error at start_listening: {str(ex)}\\n{traceback.format_exc()}\")\n\n        finally:\n            self.is_listening = False\n\n    def stop_listening(self):\n        self.is_listening = False", "\nclass SpeechListenerBase:\n    def __init__(self, api_key: str, on_speech_recognized: Callable, volume_threshold: int=3000, timeout: float=1.0, detection_timeout: float=0.0, min_duration: float=0.3, max_duration: float=20.0, lang: str=\"ja-JP\", rate: int=44100, channels: int=1, device_index: int=-1):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.api_key = api_key\n        self.on_speech_recognized = on_speech_recognized\n        self.volume_threshold = volume_threshold\n        self.timeout = timeout\n        self.detection_timeout = detection_timeout\n        self.min_duration = min_duration\n        self.max_duration = max_duration\n        self.lang = lang\n        self.channels = channels\n        self.rate = rate\n        self.device_index = device_index\n        self.is_listening = False\n\n    def record_audio(self, device_index) -> bytes:\n        audio_data = []\n\n        def callback(in_data, frame_count, time_info, status):\n            audio_data.append(in_data.copy())\n\n        try:\n            stream = sounddevice.InputStream(\n                device=device_index,\n                channels=self.channels,\n                samplerate=self.rate,\n                dtype=numpy.int16,\n                callback=callback\n            )\n\n            start_time = time.time()\n            is_recording = False\n            silence_start_time = time.time()\n            is_silent = False\n            last_detected_time = time.time()\n            stream.start()\n\n            while stream.active:\n                current_time = time.time()\n                volume = numpy.linalg.norm(audio_data[-10:]) / 50 if audio_data else 0\n\n                if not is_recording:\n                    if volume > self.volume_threshold:\n                        audio_data = audio_data[-100:]  # Use 100ms data before start recording\n                        is_recording = True\n                        start_time = current_time\n\n                else:\n                    if volume <= self.volume_threshold:\n                        if is_silent:\n                            if current_time - silence_start_time > self.timeout:\n                                # Timeouot\n                                recorded_length = current_time - start_time - self.timeout\n\n                                if recorded_length < self.min_duration:\n                                    self.logger.info(f\"Too short: {recorded_length}\")\n                                    is_recording = False\n                                    audio_data.clear()\n\n                                else:\n                                    return b\"\".join(audio_data)\n                            else:\n                                # Continue silent\n                                pass\n\n                        else:\n                            # Start silent\n                            silence_start_time = current_time\n                            is_silent = True\n\n                    else:\n                        # Detecting voice\n                        is_silent = False\n                        last_detected_time = current_time\n\n                    if current_time - start_time > self.max_duration:\n                        self.logger.info(f\"Max recording duration reached: {current_time - start_time}\")\n                        is_recording = False\n                        audio_data.clear()\n\n                if self.detection_timeout > 0 and time.time() - last_detected_time > self.detection_timeout:\n                    self.logger.info(f\"Voice detection timeout: {self.detection_timeout}\")\n                    break\n\n        except Exception as ex:\n            self.logger.error(f\"Error at record_audio: {str(ex)}\\n{traceback.format_exc()}\")\n\n        finally:\n            stream.stop()\n            stream.close()\n\n        # Return empty bytes\n        return b\"\".join([])\n\n    async def transcribe(self, audio_data: list) -> str:\n        audio_b64 = base64.b64encode(audio_data).decode(\"utf-8\")\n\n        request_body = {\n            \"config\": {\n                \"encoding\": \"LINEAR16\",\n                \"sampleRateHertz\": self.rate,\n                \"languageCode\": self.lang,\n            },\n            \"audio\": {\n                \"content\": audio_b64\n            },\n        }\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                f\"https://speech.googleapis.com/v1/speech:recognize?key={self.api_key}\",\n                json=request_body\n            ) as resp:\n                j = await resp.json()\n\n                if resp.status != 200:\n                    self.logger.error(f\"Failed in recognition: {resp.status}\\n{j}\")\n                    return None\n\n                if j.get(\"results\"):\n                    if j[\"results\"][0][\"alternatives\"][0].get(\"transcript\"):\n                        return j[\"results\"][0][\"alternatives\"][0][\"transcript\"]\n\n        return None\n\n    async def start_listening(self):\n        self.is_listening = True\n\n        try:\n            self.logger.info(f\"Listening... ({self.__class__.__name__})\")\n            while self.is_listening:\n                audio_data = self.record_audio(self.device_index)\n\n                if audio_data:\n                    recognized_text = await self.transcribe(audio_data)\n\n                    if recognized_text:\n                        await self.on_speech_recognized(recognized_text)\n                    else:\n                        self.logger.info(\"No speech recognized\")\n                \n                else:\n                    # Stop listening when no recorded data\n                    break\n\n            self.logger.info(f\"Stopped listening ({self.__class__.__name__})\")\n\n        except Exception as ex:\n            self.logger.error(f\"Error at start_listening: {str(ex)}\\n{traceback.format_exc()}\")\n\n        finally:\n            self.is_listening = False\n\n    def stop_listening(self):\n        self.is_listening = False", ""]}
{"filename": "aiavatar/listeners/voicerequest.py", "chunked_list": ["from . import SpeechListenerBase\n\nclass VoiceRequestListener(SpeechListenerBase):\n    def __init__(self, api_key: str, volume_threshold: int=3000, timeout: float=1.0, detection_timeout: float=10.0, min_duration: float=0.3, max_duration: float=20.0, lang: str=\"ja-JP\", rate: int=44100, channels: int=1, device_index: int=-1):\n        super().__init__(api_key, self.on_request, volume_threshold, timeout, detection_timeout, min_duration, max_duration, lang, rate, channels, device_index)\n        self.last_recognized_text = None\n\n    async def on_request(self, text: str):\n        self.last_recognized_text = text\n        self.stop_listening()\n\n    async def get_request(self):\n        await self.start_listening()\n        resp = self.last_recognized_text\n        self.last_recognized_text = None\n        return resp", ""]}
{"filename": "aiavatar/device/audio.py", "chunked_list": ["import sounddevice\n\nclass AudioDevice:\n    @classmethod\n    def get_default_input_device_info(cls):\n        device_list = sounddevice.query_devices()\n        for idx in sounddevice.default.device:\n            if device_list[idx][\"max_input_channels\"] > 0:\n                return device_list[idx]\n\n    @classmethod\n    def get_default_output_device_info(cls):\n        device_list = sounddevice.query_devices()\n        for idx in sounddevice.default.device:\n            if device_list[idx][\"max_output_channels\"] > 0:\n                return device_list[idx]\n\n    @classmethod\n    def get_device_info(cls, index: int):\n        return sounddevice.query_devices(index)\n\n    @classmethod\n    def get_input_device_by_name(cls, name: str):\n        for d in sounddevice.query_devices():\n            if d[\"max_input_channels\"] > 0:\n                if name.lower() in d[\"name\"].lower():\n                    return d\n        return None\n\n    @classmethod\n    def get_output_device_by_name(cls, name: str):\n        for d in sounddevice.query_devices():\n            if d[\"max_output_channels\"] > 0:\n                if name.lower() in d[\"name\"].lower():\n                    return d\n        return None\n\n    @classmethod\n    def get_input_device_with_prompt(cls, prompt: str=None):\n        print(\"==== Input devices ====\")\n        for d in sounddevice.query_devices():\n            if d[\"max_input_channels\"] > 0:\n                print(f'{d[\"index\"]}: {d[\"name\"]}')\n        idx = input(prompt or \"Index of microphone device (Skip to use default): \")\n        if idx == \"\":\n            return cls.get_default_input_device_info()\n        else:\n            return cls.get_device_info(int(idx))\n\n    @classmethod\n    def get_output_device_with_prompt(cls, prompt: str=None):\n        print(\"==== Output devices ====\")\n        for d in sounddevice.query_devices():\n            if d[\"max_output_channels\"] > 0:\n                print(f'{d[\"index\"]}: {d[\"name\"]}')\n        idx = input(prompt or \"Index of speaker device (Skip to use default): \")\n        if idx == \"\":\n            return cls.get_default_output_device_info()\n        else:\n            return cls.get_device_info(int(idx))\n\n    @classmethod\n    def get_audio_devices(cls):\n        return sounddevice.query_devices()\n\n    @classmethod\n    def list_audio_devices(cls):\n        print(cls.get_audio_devices())", ""]}
{"filename": "aiavatar/device/__init__.py", "chunked_list": ["from .audio import AudioDevice\n"]}
{"filename": "aiavatar/speech/voicevox.py", "chunked_list": ["import aiohttp\nimport asyncio\nimport io\nfrom logging import getLogger, NullHandler\nimport traceback\nimport wave\nimport numpy\nimport sounddevice\nfrom . import SpeechController\n\nclass VoiceClip:\n    def __init__(self, text: str):\n        self.text = text\n        self.download_task = None\n        self.audio_clip = None", "from . import SpeechController\n\nclass VoiceClip:\n    def __init__(self, text: str):\n        self.text = text\n        self.download_task = None\n        self.audio_clip = None\n\n\nclass VoicevoxSpeechController(SpeechController):\n    def __init__(self, base_url: str, speaker_id: int, device_index: int=-1):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.base_url = base_url\n        self.speaker_id = speaker_id\n        self.device_index = device_index\n        self.voice_clips = {}\n        self._is_speaking = False\n\n    async def download(self, voice: VoiceClip):\n        params = {\"speaker\": self.speaker_id, \"text\": voice.text}\n        async with aiohttp.ClientSession() as session:\n            async with session.post(self.base_url + \"/audio_query\", params=params) as query_resp:\n                audio_query = await query_resp.json()\n                async with session.post(self.base_url + \"/synthesis\", params={\"speaker\": self.speaker_id}, json=audio_query) as audio_resp:\n                    voice.audio_clip = await audio_resp.read()\n\n    def prefetch(self, text: str):\n        v = self.voice_clips.get(text)\n        if v:\n            return v\n\n        v = VoiceClip(text)\n        v.download_task = asyncio.create_task(self.download(v))\n        self.voice_clips[text] = v\n        return v\n\n    async def speak(self, text: str):\n        voice = self.prefetch(text)\n        \n        if not voice.audio_clip:\n            await voice.download_task\n        \n        with wave.open(io.BytesIO(voice.audio_clip), \"rb\") as f:\n            try:\n                self._is_speaking = True\n                data = numpy.frombuffer(\n                    f.readframes(f.getnframes()),\n                    dtype=numpy.int16\n                )\n                sounddevice.play(data, f.getframerate(), device=self.device_index)\n                sounddevice.wait()\n\n            except Exception as ex:\n                self.logger.error(f\"Error at speaking: {str(ex)}\\n{traceback.format_exc()}\")\n\n            finally:\n                self._is_speaking = False\n\n    def is_speaking(self) -> bool:\n        return self._is_speaking", "\nclass VoicevoxSpeechController(SpeechController):\n    def __init__(self, base_url: str, speaker_id: int, device_index: int=-1):\n        self.logger = getLogger(__name__)\n        self.logger.addHandler(NullHandler())\n\n        self.base_url = base_url\n        self.speaker_id = speaker_id\n        self.device_index = device_index\n        self.voice_clips = {}\n        self._is_speaking = False\n\n    async def download(self, voice: VoiceClip):\n        params = {\"speaker\": self.speaker_id, \"text\": voice.text}\n        async with aiohttp.ClientSession() as session:\n            async with session.post(self.base_url + \"/audio_query\", params=params) as query_resp:\n                audio_query = await query_resp.json()\n                async with session.post(self.base_url + \"/synthesis\", params={\"speaker\": self.speaker_id}, json=audio_query) as audio_resp:\n                    voice.audio_clip = await audio_resp.read()\n\n    def prefetch(self, text: str):\n        v = self.voice_clips.get(text)\n        if v:\n            return v\n\n        v = VoiceClip(text)\n        v.download_task = asyncio.create_task(self.download(v))\n        self.voice_clips[text] = v\n        return v\n\n    async def speak(self, text: str):\n        voice = self.prefetch(text)\n        \n        if not voice.audio_clip:\n            await voice.download_task\n        \n        with wave.open(io.BytesIO(voice.audio_clip), \"rb\") as f:\n            try:\n                self._is_speaking = True\n                data = numpy.frombuffer(\n                    f.readframes(f.getnframes()),\n                    dtype=numpy.int16\n                )\n                sounddevice.play(data, f.getframerate(), device=self.device_index)\n                sounddevice.wait()\n\n            except Exception as ex:\n                self.logger.error(f\"Error at speaking: {str(ex)}\\n{traceback.format_exc()}\")\n\n            finally:\n                self._is_speaking = False\n\n    def is_speaking(self) -> bool:\n        return self._is_speaking", ""]}
{"filename": "aiavatar/speech/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\n\nclass SpeechController(ABC):\n    @abstractmethod\n    def prefetch(self, text: str):\n        pass\n\n    @abstractmethod\n    async def speak(self, text: str):\n        pass\n\n    @abstractmethod\n    def is_speaking(self) -> bool:\n        pass", ""]}
{"filename": "aiavatar/animation/__init__.py", "chunked_list": ["from abc import ABC, abstractmethod\n\nclass AnimationController(ABC):\n    @abstractmethod\n    async def animate(self, name: str, duration: float):\n        pass\n\n\nclass AnimationControllerDummy(AnimationController):\n    async def animate(self, name: str, duration: float):\n        pass", "class AnimationControllerDummy(AnimationController):\n    async def animate(self, name: str, duration: float):\n        pass\n"]}
{"filename": "examples/run.py", "chunked_list": ["import logging\nfrom aiavatar import AIAvatar, WakewordListener\n\nGOOGLE_API_KEY = \"YOUR_API_KEY\"\nOPENAI_API_KEY = \"YOUR_API_KEY\"\nVV_URL = \"http://127.0.0.1:50021\"\nVV_SPEAKER = 46\n\n# Configure root logger\nlogger = logging.getLogger()", "# Configure root logger\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\nlog_format = logging.Formatter(\"[%(levelname)s] %(asctime)s : %(message)s\")\nstreamHandler = logging.StreamHandler()\nstreamHandler.setFormatter(log_format)\nlogger.addHandler(streamHandler)\n\n# Prompt\nsystem_message_content = \"\"\"\u3042\u306a\u305f\u306f\u300cjoy\u300d\u300cangry\u300d\u300csorrow\u300d\u300cfun\u300d\u306e4\u3064\u306e\u8868\u60c5\u3092\u6301\u3063\u3066\u3044\u307e\u3059\u3002", "# Prompt\nsystem_message_content = \"\"\"\u3042\u306a\u305f\u306f\u300cjoy\u300d\u300cangry\u300d\u300csorrow\u300d\u300cfun\u300d\u306e4\u3064\u306e\u8868\u60c5\u3092\u6301\u3063\u3066\u3044\u307e\u3059\u3002\n\u7279\u306b\u8868\u60c5\u3092\u8868\u73fe\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6587\u7ae0\u306e\u5148\u982d\u306b[face:joy]\u306e\u3088\u3046\u306b\u633f\u5165\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\u4f8b\n[face:joy]\u306d\u3048\u3001\u6d77\u304c\u898b\u3048\u308b\u3088\uff01[face:fun]\u65e9\u304f\u6cf3\u3054\u3046\u3088\u3002\n\"\"\"\n\n# Create AIAvatar\napp = AIAvatar(", "# Create AIAvatar\napp = AIAvatar(\n    google_api_key=GOOGLE_API_KEY,\n    openai_api_key=OPENAI_API_KEY,\n    voicevox_url=VV_URL,\n    voicevox_speaker_id=VV_SPEAKER,\n    system_message_content=system_message_content,\n)\n\n# Create WakewordListener", "\n# Create WakewordListener\nwakewords = [\"\u3053\u3093\u306b\u3061\u306f\"]\n\nasync def on_wakeword(text):\n    logger.info(f\"Wakeword: {text}\")\n    await app.start_chat()\n\nwakeword_listener = WakewordListener(\n    api_key=GOOGLE_API_KEY,", "wakeword_listener = WakewordListener(\n    api_key=GOOGLE_API_KEY,\n    wakewords=wakewords,\n    on_wakeword=on_wakeword,\n    device_index=app.input_device\n)\n\n# Start listening\nww_thread = wakeword_listener.start()\nww_thread.join()", "ww_thread = wakeword_listener.start()\nww_thread.join()\n"]}
{"filename": "examples/device.py", "chunked_list": ["from aiavatar import AudioDevice\n\nAudioDevice.list_audio_devices()\n"]}
{"filename": "examples/chatgpt_functions/weather.py", "chunked_list": ["import aiohttp\nfrom datetime import datetime, timezone, timedelta\n\nclass WeatherFunction:\n    def __init__(self, google_api_key: str, weather_appid: str):\n        self.google_api_key = google_api_key\n        self.weather_appid = weather_appid\n        self.name = \"get_weather\"\n        self.description=\"Get the weather forecast in a given location\"\n        self.parameters = {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\"\n                }\n            }\n        }\n\n    async def get_weather(self, location, tz_offset=9) -> dict:\n        ret = {\n            \"description\": \"Compose a summary of the `weather_forecasts` information as a response message.\",\n            \"weather_forecasts\": []\n        }\n\n        async with aiohttp.ClientSession() as session:\n            async with session.get(\n                    f\"https://maps.googleapis.com/maps/api/geocode/json?address={location}&key={self.google_api_key}\"\n                ) as resp:\n                geo = await resp.json()\n\n            lat = geo[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n            lon = geo[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n\n            async with session.get(\n                    f\"http://api.openweathermap.org/data/2.5/forecast?APPID={self.weather_appid}&lat={lat}&lon={lon}&cnt=9\"\n                ) as resp:\n                weather = await resp.json()\n\n\n        for v in weather[\"list\"]:\n            w = {}\n\n            w[\"time\"] = datetime.fromtimestamp(v[\"dt\"], timezone(timedelta(hours=tz_offset))).isoformat()\n            if v[\"weather\"][0][\"main\"] == \"Clear\":\n                w[\"weather\"] = \"clear\"\n            elif v[\"weather\"][0][\"main\"] == \"Clouds\":\n                w[\"weather\"] = \"clouds\"\n            elif v[\"weather\"][0][\"main\"] == \"Rain\":\n                w[\"weather\"] = \"rain\"\n            elif v[\"weather\"][0][\"main\"] == \"Snow\":\n                w[\"weather\"] = \"snow\"\n            w[\"temperature\"] = str(int(v[\"main\"][\"temp\"] - 273.15))\n\n            ret[\"weather_forecasts\"].append(w)\n\n        return ret", ""]}
