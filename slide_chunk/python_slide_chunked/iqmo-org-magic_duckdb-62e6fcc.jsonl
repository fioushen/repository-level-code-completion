{"filename": "setup.py", "chunked_list": ["from setuptools import setup, find_packages\nfrom codecs import open\nfrom os import path\n\nhere = path.abspath(path.dirname(__file__))\n\nwith open(path.join(here, \"README.md\"), encoding=\"utf-8\") as f:\n    long_description = f.read()\n\nwith open(\"magic_duckdb/_version.py\", \"r\") as file:\n    code = file.read()\n    exec(code)\n    _version = __version__  # type: ignore # noqa", "\nwith open(\"magic_duckdb/_version.py\", \"r\") as file:\n    code = file.read()\n    exec(code)\n    _version = __version__  # type: ignore # noqa\n\nsetup(\n    name=\"magic_duckdb\",\n    version=_version,  # type: ignore # noqa\n    description=\"Jupyter Cell and Line Magics for DuckDB\",", "    version=_version,  # type: ignore # noqa\n    description=\"Jupyter Cell and Line Magics for DuckDB\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/iqmo-org/magic_duckdb\",\n    author=\"iqmo\",\n    author_email=\"info@iqmo.com\",\n    classifiers=[],\n    keywords=\"Jupyter, Cell Magic, DuckDB, Line Magic, Magic\",\n    packages=find_packages(exclude=[\"tests\"]),", "    keywords=\"Jupyter, Cell Magic, DuckDB, Line Magic, Magic\",\n    packages=find_packages(exclude=[\"tests\"]),\n    include_package_data=True,\n    install_requires=[\"duckdb>=0.8.0\", \"pandas\"],\n)\n"]}
{"filename": "tests/test_autocomplete.py", "chunked_list": ["import duckdb\nfrom pandas import DataFrame\nimport numpy as np\nfrom magic_duckdb import magic\nfrom magic_duckdb.autocomplete.autocompletion_v2 import DqlCustomCompleter\nfrom types import SimpleNamespace\n\n\ndef test_simple_autocomplete():\n    with duckdb.connect() as con:\n        con.execute(\n            \"CREATE TABLE IF NOT EXISTS my_new_table as select 'abc' as my_first_column, 'def' as my_second_column\"\n        )\n        con.execute(\n            \"CREATE TABLE IF NOT EXISTS another_table as select 'abc' as my_first_column, 'def' as my_second_column\"\n        )\n\n        someDataFrame = DataFrame(columns=[\"col123\", \"col345\", \"col919191\"])\n\n        # Test of underlying v2 completer (ipython 8.6.0 or above)\n\n        some_tablename = \"tablenamereallylong\"\n        # create some tables\n        simpledf = DataFrame(np.random.randn(10, 20))  # type: ignore # noqa\n\n        con.execute(\n            f\"CREATE OR REPLACE TABLE {some_tablename} as select * from simpledf\"\n        )\n        con.execute(\n            \"CREATE OR REPLACE TABLE  sometablename2 as select * from range(10) t(my_column_1)\"\n        )\n        con.execute(\n            \"CREATE OR REPLACE TABLE  longtablenameishardtomakeup as select * from range(10) t(d)\"\n        )\n        con.execute(\"show tables\").df()\n\n        # test autocompletion\n        magic.connection = con\n        fake_ipython_shell = SimpleNamespace(user_ns=locals())\n\n        completer = DqlCustomCompleter(shell=fake_ipython_shell)\n\n        # completer finds the table names\n        event = SimpleNamespace(full_text=\"%dql s\", token=\"s\")\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert \"SELECT\" in results\n\n        event = SimpleNamespace(\n            token=\"from\",\n            full_text=\"%dql select * from \",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert some_tablename in results\n        assert \"SELECT\" not in results\n\n        # Tablename doesn't exist\n        event = SimpleNamespace(\n            token=\"blah.\",\n            full_text=\"%dql select blah.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert len(results) == 0\n\n        event = SimpleNamespace(\n            token=\"tablenamereallylong.\",\n            full_text=\"%dql  tablenamereallylong.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n\n        assert results is not None\n        assert \"19\" in results\n\n        event = SimpleNamespace(\n            token=\"tablenamereallylong.\",\n            full_text=\"%dql select tablenamereallylong.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert \"17\" in results\n\n        event = SimpleNamespace(\n            token=f\"{some_tablename}.\",\n            full_text=f\"%dql select {some_tablename}.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert \"19\" in results", "def test_simple_autocomplete():\n    with duckdb.connect() as con:\n        con.execute(\n            \"CREATE TABLE IF NOT EXISTS my_new_table as select 'abc' as my_first_column, 'def' as my_second_column\"\n        )\n        con.execute(\n            \"CREATE TABLE IF NOT EXISTS another_table as select 'abc' as my_first_column, 'def' as my_second_column\"\n        )\n\n        someDataFrame = DataFrame(columns=[\"col123\", \"col345\", \"col919191\"])\n\n        # Test of underlying v2 completer (ipython 8.6.0 or above)\n\n        some_tablename = \"tablenamereallylong\"\n        # create some tables\n        simpledf = DataFrame(np.random.randn(10, 20))  # type: ignore # noqa\n\n        con.execute(\n            f\"CREATE OR REPLACE TABLE {some_tablename} as select * from simpledf\"\n        )\n        con.execute(\n            \"CREATE OR REPLACE TABLE  sometablename2 as select * from range(10) t(my_column_1)\"\n        )\n        con.execute(\n            \"CREATE OR REPLACE TABLE  longtablenameishardtomakeup as select * from range(10) t(d)\"\n        )\n        con.execute(\"show tables\").df()\n\n        # test autocompletion\n        magic.connection = con\n        fake_ipython_shell = SimpleNamespace(user_ns=locals())\n\n        completer = DqlCustomCompleter(shell=fake_ipython_shell)\n\n        # completer finds the table names\n        event = SimpleNamespace(full_text=\"%dql s\", token=\"s\")\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert \"SELECT\" in results\n\n        event = SimpleNamespace(\n            token=\"from\",\n            full_text=\"%dql select * from \",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert some_tablename in results\n        assert \"SELECT\" not in results\n\n        # Tablename doesn't exist\n        event = SimpleNamespace(\n            token=\"blah.\",\n            full_text=\"%dql select blah.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert len(results) == 0\n\n        event = SimpleNamespace(\n            token=\"tablenamereallylong.\",\n            full_text=\"%dql  tablenamereallylong.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n\n        assert results is not None\n        assert \"19\" in results\n\n        event = SimpleNamespace(\n            token=\"tablenamereallylong.\",\n            full_text=\"%dql select tablenamereallylong.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert \"17\" in results\n\n        event = SimpleNamespace(\n            token=f\"{some_tablename}.\",\n            full_text=f\"%dql select {some_tablename}.\",\n        )\n        r = completer.line_completer(event)\n        results = [sc.text for sc in r[\"completions\"]]\n        assert results is not None\n        assert \"19\" in results", "        # Tablename doesn't exist\n"]}
{"filename": "tests/test_types.py", "chunked_list": ["from IPython.terminal.embed import InteractiveShellEmbed\nfrom magic_duckdb import duckdb_mode\n\n\ndef create_shell() -> object:\n    ipshell = InteractiveShellEmbed()\n    ipshell.run_cell(\"%load_ext magic_duckdb\")\n    return ipshell\n\n\ndef test_types():\n    # Not expected to occur, but should gracefully handle\n    ipshell = create_shell()\n\n    execution_result = ipshell.run_cell(\"%dql --listtypes\")\n    o = execution_result.result\n    print(o)\n    assert \"df\" in o\n    for otype in o:\n        execution_result2 = ipshell.run_cell(f\"%dql -t {otype} PRAGMA version\")\n        assert execution_result2.error_in_exec is None\n\n        outobj = execution_result2.result\n        assert otype == \"show\" or outobj is not None", "\n\ndef test_types():\n    # Not expected to occur, but should gracefully handle\n    ipshell = create_shell()\n\n    execution_result = ipshell.run_cell(\"%dql --listtypes\")\n    o = execution_result.result\n    print(o)\n    assert \"df\" in o\n    for otype in o:\n        execution_result2 = ipshell.run_cell(f\"%dql -t {otype} PRAGMA version\")\n        assert execution_result2.error_in_exec is None\n\n        outobj = execution_result2.result\n        assert otype == \"show\" or outobj is not None", "\n\ndef test_explains():\n    # Not expected to occur, but should gracefully handle\n    ipshell = create_shell()\n\n    for e in duckdb_mode.DuckDbMode.explain_functions:\n        if \"draw\" not in e:\n            er = ipshell.run_cell(f\"%dql -e {e} select * from range(10)\")\n            assert er.error_in_exec is None\n            o = er.result\n            assert o is not None", ""]}
{"filename": "tests/test_jinja.py", "chunked_list": ["from IPython.terminal.embed import InteractiveShellEmbed\n\n\ndef create_shell() -> object:\n    ipshell = InteractiveShellEmbed()\n    ipshell.run_cell(\"%load_ext magic_duckdb\")\n    return ipshell\n\n\ndef test_jinj2():\n    ipshell = create_shell()\n\n    er = ipshell.run_cell(\"%dql --jinja2 select '{{abc}}' as col1\")\n    # assert isinstance(er.error_in_exec, KeyError)\n\n    ipshell.run_cell(\"abc = 'test'\")\n    er = ipshell.run_cell(\"%dql --jinja2 select '{{abc}}'\")\n    assert er.error_in_exec is None\n    assert \"'test'\" in er.result.columns", "\ndef test_jinj2():\n    ipshell = create_shell()\n\n    er = ipshell.run_cell(\"%dql --jinja2 select '{{abc}}' as col1\")\n    # assert isinstance(er.error_in_exec, KeyError)\n\n    ipshell.run_cell(\"abc = 'test'\")\n    er = ipshell.run_cell(\"%dql --jinja2 select '{{abc}}'\")\n    assert er.error_in_exec is None\n    assert \"'test'\" in er.result.columns", "\n\ndef test_param():\n    ipshell = create_shell()\n\n    ipshell.run_cell(\"somename = 'abcdef'\")\n\n    er = ipshell.run_cell(\"%dql -p somename select ? as col1\")\n    assert er.error_in_exec is None\n    assert \"col1\" in er.result.columns\n    assert \"abcdef\" == er.result.iat[0, 0]", ""]}
{"filename": "tests/test_connections.py", "chunked_list": ["from magic_duckdb.magic import DuckDbMagic\nfrom IPython.terminal.embed import InteractiveShellEmbed\n\n\ndef test_none_inputs():\n    # Not expected to occur, but should gracefully handle\n    ipshell = InteractiveShellEmbed()\n    m = DuckDbMagic(shell=ipshell)\n\n    result = m.execute(line=\"-cn :memory:\", cell=None)\n\n    result = m.execute(line=\"-d PRAGMA version\", cell=None)\n    assert result is not None\n\n    result = m.execute(line=None, cell=\"PRAGMA version\")\n    assert result is not None\n\n    result = m.execute(line=\"\", cell=\"PRAGMA version\")\n    assert result is not None", "\n\ndef test_cn_file():\n    # Not expected to occur, but should gracefully handle\n    ipshell = InteractiveShellEmbed()\n    m = DuckDbMagic(shell=ipshell)\n\n    filename = \"test.db\"\n\n    m.execute(line=f\"-cn {filename}\")\n    df = m.execute(\"PRAGMA database_list\")\n\n    assert len(df) == 1\n    assert df.at[0, \"file\"].endswith(filename)", "\n\ndef test_co_file():\n    # Not expected to occur, but should gracefully handle\n    ipshell = InteractiveShellEmbed()\n    m = DuckDbMagic(shell=ipshell)\n\n    fname = \"test.db\"\n    ipshell.user_ns[\"filename\"] = fname\n\n    ipshell.run_cell(\"import duckdb\")\n    ipshell.run_cell(\"fcon = duckdb.connect(filename)\")\n\n    m.execute(line=\"-co fcon\")\n    df = m.execute(line=\"PRAGMA database_list\")\n\n    assert len(df) == 1\n\n    assert df.at[0, \"file\"].endswith(fname)\n\n    o = m.execute(line=\"-g\")\n    df2 = o.execute(\"PRAGMA database_list\").df()\n    assert df2.at[0, \"file\"].endswith(fname)", "\n\ndef test_close():\n    ipshell = InteractiveShellEmbed()\n    m = DuckDbMagic(shell=ipshell)\n\n    # No exception here\n    m.execute(line=\"--close\")\n\n    fname = \"test.db\"\n    m.execute(line=f\"-cn {fname}\")\n    df = m.execute(line=\"PRAGMA database_list\")\n\n    assert len(df) == 1\n    assert df.at[0, \"file\"].endswith(fname)\n\n    m.execute(line=\"--close\")\n    df2 = m.execute(line=\"PRAGMA database_list\")\n    assert df2.at[0, \"name\"] == \"memory\"", ""]}
{"filename": "tests/conftest.py", "chunked_list": [""]}
{"filename": "magic_duckdb/_version.py", "chunked_list": ["# This file is entirely overwritten at build time\n# Module dunamai is used to create the dev and release __version__'s\n# from the most recent git tag\n# See git action yaml for details\n\n__version__ = \"0.0.0\"\n__commit__ = \"1234567890\"\n__commit_short__ = \"1234\"\n", ""]}
{"filename": "magic_duckdb/magic.py", "chunked_list": ["import logging\nimport argparse\nfrom typing import Optional, Dict\n\nfrom traitlets.config.configurable import Configurable\nfrom IPython.core.magic_arguments import argument, magic_arguments, parse_argstring\nfrom IPython.core.magic import (\n    Magics,\n    cell_magic,\n    line_magic,", "    cell_magic,\n    line_magic,\n    magics_class,\n    no_var_expand,\n    needs_local_scope,\n)\n\n# from IPython.core.getipython import get_ipython\nfrom duckdb import ConnectionException, DuckDBPyConnection\nfrom magic_duckdb.extras import jinja_template", "from duckdb import ConnectionException, DuckDBPyConnection\nfrom magic_duckdb.extras import jinja_template\nfrom magic_duckdb.autocomplete.common import init_completers\nfrom magic_duckdb.duckdb_mode import DuckDbMode\n\n\nlogger = logging.getLogger(\"magic_duckdb\")\n\n# Disable autocompletion initialization by setting this to False before loading extension\nENABLE_AUTOCOMPLETE = True", "# Disable autocompletion initialization by setting this to False before loading extension\nENABLE_AUTOCOMPLETE = True\n# dbwrapper: To override database logic, replace or monkeypatch this object\ndbwrapper: DuckDbMode = DuckDbMode()\n# database connection object created via -d (default), -cn (connection string) or -co (connection object)\nconnection: Optional[DuckDBPyConnection] = None\n\n\ndef _get_obj_from_name(shell, name: str) -> Optional[object]:\n    return shell.ev(name) if shell is not None else None", "def _get_obj_from_name(shell, name: str) -> Optional[object]:\n    return shell.ev(name) if shell is not None else None\n\n\n@magics_class\nclass DuckDbMagic(Magics, Configurable):\n    # selected via -t. None = Pandas.\n    default_export_function = None\n\n    def __init__(self, shell, attr_matches: bool = True):\n        Configurable.__init__(self, config=shell.config)\n        Magics.__init__(self, shell=shell)\n\n        # Add to configurable modules via %config\n        self.shell.configurables.append(self)  # type: ignore\n\n    def connect_by_objectname(self, connection_object):\n        con: DuckDBPyConnection = _get_obj_from_name(self.shell, connection_object)  # type: ignore\n        if not isinstance(con, DuckDBPyConnection):\n            raise ValueError(f\"{connection_object} is not a DuckDBPyConnection\")\n        elif con is None:\n            raise ValueError(f\"Couldn't find {connection_object}\")\n        else:\n            logger.info(f\"Using existing connection: {connection_object}\")\n            global connection\n            connection = con\n\n    def format_wrapper(self, query):\n        try:\n            from magic_duckdb.extras.sqlformatter import formatsql\n\n            return formatsql(query)\n        except Exception as e:\n            logger.exception(\"Error processing\")\n            raise e\n\n    def ai_wrapper(self, chat: bool, prompt, query):\n        try:\n            from magic_duckdb.extras import sql_ai\n\n            sql_ai.call_ai(connection, chat, prompt, query)\n            return None  # suppress for now, need to figure out formatting\n        except Exception as e:\n            logger.exception(\"Error with AI\")\n            raise e\n\n    @no_var_expand\n    @needs_local_scope\n    @line_magic(\"dql\")\n    @cell_magic(\"dql\")\n    @magic_arguments()\n    @argument(\"-l\", \"--listtypes\", help=\"List the available types\", action=\"store_true\")\n    @argument(\"-g\", \"--getcon\", help=\"Return current connection\", action=\"store_true\")\n    @argument(\n        \"-d\", \"--default_connection\", help=\"Use default connection\", action=\"store_true\"\n    )\n    @argument(\"-f\", \"--format\", help=\"Format (beautify) SQL input\", action=\"store_true\")\n    @argument(\"-ai\", help=\"Format (beautify) SQL input\", action=\"store_true\")\n    @argument(\"-aichat\", help=\"Format (beautify) SQL input\", action=\"store_true\")\n    @argument(\n        \"-cn\",\n        \"--connection_string\",\n        help=\"Connect to a database using the connection string, such as :memory: or file.db\",\n        nargs=1,\n        type=str,\n        action=\"store\",\n    )\n    @argument(\n        \"-co\",\n        \"--connection_object\",\n        help=\"Connect to a database using the connection object\",\n        nargs=1,\n        type=str,\n        action=\"store\",\n    )\n    @argument(\n        \"-t\",\n        \"--type\",\n        help=\"Set the default output type\",\n        nargs=1,\n        type=str,\n        action=\"store\",\n    )\n    @argument(\n        \"-o\",\n        \"--output\",\n        help=\"Write the output to the specified variable\",\n        nargs=1,\n        type=str,\n        action=\"store\",\n    )\n    @argument(\n        \"-e\",\n        \"--explain\",\n        help=\"Explain or Explain Analyze or AST\",\n        nargs=1,\n        type=str,\n        action=\"store\",\n    )\n    @argument(\"--tables\", help=\"Return table names\", action=\"store_true\")\n    @argument(\"--close\", help=\"Close database connection\", action=\"store_true\")\n    @argument(\"-j\", \"--jinja2\", help=\"Apply Jinja2 Template\", action=\"store_true\")\n    @argument(\n        \"-p\",\n        \"--param\",\n        dest=\"queryparams\",\n        help=\"Params from user_ns\",\n        action=\"append\",\n    )\n    @argument(\"rest\", nargs=argparse.REMAINDER)\n    def execute(self, line: str = \"\", cell: str = \"\", local_ns=None):\n        global connection\n        cell = \"\" if cell is None else cell\n        line = \"\" if line is None else line\n        user_ns: Dict[str, object] = self.shell.user_ns  # type: ignore\n\n        args = parse_argstring(self.execute, line)\n\n        rest = \" \".join(args.rest)\n        query = f\"{rest}\\n{cell}\".strip()\n\n        if args.jinja2:\n            query = jinja_template.apply_template(query, user_ns)\n\n        if args.listtypes:\n            return dbwrapper.export_functions\n        elif args.getcon:\n            return connection\n        elif args.format:\n            return self.format_wrapper(query)\n        elif args.ai:\n            return self.ai_wrapper(False, rest, query)\n        elif args.aichat:\n            return self.ai_wrapper(False, rest, query)\n        elif args.close:\n            if connection is not None:\n                try:\n                    connection.close()\n                finally:\n                    connection = None\n\n        thisconnection = None\n        if args.default_connection:\n            thisconnection = dbwrapper.default_connection()\n        if args.connection_object:\n            thisconnection = self.connect_by_objectname(args.connection_object[0])\n        if args.connection_string:\n            thisconnection = dbwrapper.connect(args.connection_string[0])\n\n        if args.type and args.type[0] not in dbwrapper.export_functions:\n            raise ValueError(\n                f\"{args.type[0]} not found in {dbwrapper.export_functions}\"\n            )\n\n        if args.explain:\n            explain_function = args.explain[0]\n            if explain_function not in dbwrapper.explain_functions:\n                raise ValueError(\n                    f\"{explain_function} not found in {dbwrapper.explain_functions}\"\n                )\n        else:\n            explain_function = None\n\n        logger.debug(f\"Query = {query}, {len(query)}\")\n        if query is None or len(query) == 0:\n            if args.type:\n                # print(\"Default format changed: {args.type[0]}\")\n                self.default_export_function = args.type[0]\n            if thisconnection is not None:\n                # print(f\"Default connection changed: \", \"default_connection()\" if args.default_connection else args.connection_object[0] if args.connection_object else args.connection_string)\n                connection = thisconnection\n            logger.debug(\"Nothing to execute\")\n            return\n\n        if thisconnection is None:\n            if connection is None:\n                # print(\"Default connection changed: default_connection()\")\n                connection = dbwrapper.default_connection()\n            thisconnection = connection\n\n        try:\n            if args.queryparams:\n                queryparams = [user_ns[p] for p in args.queryparams]\n            else:\n                queryparams = None\n\n            if args.tables:\n                return thisconnection.get_table_names(query)\n\n            o = dbwrapper.execute(\n                query_string=query,\n                connection=thisconnection,\n                export_function=args.type[0]\n                if args.type\n                else self.default_export_function,\n                explain_function=explain_function,\n                params=queryparams,\n            )\n            if args.output:\n                user_ns[args.output[0]] = o\n            return o\n        except ConnectionException as e:\n            logger.exception(\n                f\"Unable to connect, connection may already be closed {e}. Setting connection to None\"\n            )\n            connection = None", "\n\ndef load_ipython_extension(ip):\n    \"\"\"Load the extension in IPython.\"\"\"\n    if ip is None:\n        raise ValueError(\"No ipython found\")\n\n    if ENABLE_AUTOCOMPLETE:\n        init_completers(ip)\n\n    ip.register_magics(DuckDbMagic)", ""]}
{"filename": "magic_duckdb/__init__.py", "chunked_list": ["from magic_duckdb.magic import load_ipython_extension  # noqa\nfrom magic_duckdb._version import __version__\nfrom magic_duckdb._version import __commit__\nfrom magic_duckdb._version import __commit_short__\n"]}
{"filename": "magic_duckdb/duckdb_mode.py", "chunked_list": ["import duckdb\n\nfrom typing import Optional, List\nimport json\nfrom magic_duckdb.extras.explain_analyze_graphviz import draw_graphviz\nfrom magic_duckdb.extras.ast_graphviz import ast_draw_graphviz, ast_tree\n\n\ndef execute_db(\n    *, query: str, con: duckdb.DuckDBPyConnection, execute: bool = False, params=None\n):\n    \"\"\"Simple wrapper to allow alternative implementations or wrappers to be inserted\n    execute = False: returns a Relation object\"\"\"\n\n    if execute or params is not None:\n        return con.execute(query, parameters=params)\n    else:\n        return con.sql(query)", "def execute_db(\n    *, query: str, con: duckdb.DuckDBPyConnection, execute: bool = False, params=None\n):\n    \"\"\"Simple wrapper to allow alternative implementations or wrappers to be inserted\n    execute = False: returns a Relation object\"\"\"\n\n    if execute or params is not None:\n        return con.execute(query, parameters=params)\n    else:\n        return con.sql(query)", "\n\nclass DuckDbMode:\n    \"\"\"Lightweight wrapper to separate duckdb specific logic from the Magic.\n    Goal here is to expose all of DuckDB's goodness, but also make it easy to extend or replace this.\n    \"\"\"\n\n    export_functions: List[str] = [\n        \"df\",\n        \"arrow\",\n        \"pl\",\n        \"describe\",\n        \"show\",\n        \"relation\",\n    ]\n\n    explain_functions: List[str] = [\n        \"explain\",\n        \"explain_analyze_tree\",\n        \"explain_analyze_json\",\n        \"explain_analyze_draw\",\n        \"analyze\",\n        \"ast_json\",\n        \"ast_draw\",\n        \"ast_tree\",\n    ]\n\n    def default_connection(self) -> duckdb.DuckDBPyConnection:\n        return duckdb.default_connection\n\n    def connect(self, conn_string: str) -> duckdb.DuckDBPyConnection:\n        return duckdb.connect(conn_string)\n\n    def explain_analyze(\n        self,\n        query_string: str,\n        connection: duckdb.DuckDBPyConnection,\n        export_function,\n        explain_function,\n    ):\n        # query_tree\n\n        if explain_function == \"explain_analyze_tree\" or explain_function == \"analyze\":\n            execute_db(\n                query=\"PRAGMA enable_profiling=query_tree\", con=connection, execute=True\n            )\n            r = execute_db(query=query_string, con=connection, execute=False)\n            t = r.explain(type=\"analyze\")  # type: ignore\n            print(t)\n            return t\n        elif explain_function == \"explain_analyze_json\":\n            execute_db(\n                query=\"PRAGMA enable_profiling=json\", con=connection, execute=True\n            )\n            r = execute_db(query=query_string, con=connection, execute=False)\n            j = r.explain(type=\"analyze\")  # type: ignore\n            return j\n        elif explain_function == \"explain_analyze_draw\":\n            execute_db(\n                query=\"PRAGMA enable_profiling=json\", con=connection, execute=True\n            )\n            r = execute_db(query=query_string, con=connection, execute=False)\n            j = r.explain(type=\"analyze\")  # type: ignore\n            return draw_graphviz(j)\n        elif explain_function == \"explain\":\n            r = execute_db(query=query_string, con=connection, execute=False)\n            j = r.explain()  # type: ignore\n            print(j)\n            return j\n        elif explain_function.startswith(\"ast\"):\n            r = connection.execute(\n                \"select json_serialize_sql($1::varchar)\", [query_string]\n            )\n            df = r.df()\n            json_str = df.iat[0, 0]\n            json_obj = json.loads(json_str)\n            if explain_function == \"ast_json\":\n                return json_obj\n            elif explain_function == \"ast_draw\":\n                return ast_draw_graphviz(json_obj)\n            elif explain_function == \"ast_tree\":\n                return ast_tree(json_obj)\n            else:\n                raise ValueError(f\"Unexpected AST mode {explain_function}\")\n\n        else:\n            raise ValueError(f\"Unexpected explain mode {explain_function}\")\n\n    def execute(\n        self,\n        query_string: str,\n        connection: Optional[duckdb.DuckDBPyConnection] = None,\n        export_function: Optional[str] = None,\n        explain_function: Optional[str] = None,\n        params: Optional[List[object]] = None,\n    ):\n        if connection is None:\n            connection = self.default_connection()\n\n        if export_function is None:\n            export_function = self.export_functions[0]\n\n        if explain_function is not None:\n            return self.explain_analyze(\n                query_string, connection, export_function, explain_function\n            )\n        else:\n            try:\n                if export_function in [\"show\", \"describe\"]:\n                    execute = False\n                else:\n                    execute = True\n                r = execute_db(\n                    query=query_string, con=connection, params=params, execute=execute\n                )\n            except Exception as e:\n                raise ValueError(f\"Error executing {query_string} in DuckDB\") from e\n\n            if r is None or (\"relation\" == export_function):\n                return r\n            else:\n                export_function = export_function\n                f = getattr(r, export_function)\n                return f()", ""]}
{"filename": "magic_duckdb/autocomplete/autocompletion_v2.py", "chunked_list": ["# Autocompletion using iPython 8.6.0 or higher\n# 8.6.0 introduced several enhancements to IPCompleter.\n# An important change is being able to complete against the entire cell text\n# for a cell magic. In v1 (pre 8.6.0), could only complete against the current line.\n\nimport re\nfrom typing import List, Optional\nfrom IPython.core.completer import IPCompleter\n\nfrom magic_duckdb.autocomplete.common import (", "\nfrom magic_duckdb.autocomplete.common import (\n    get_table_names,\n    get_column_names,\n    pragma_phrases,\n    sql_phrases,\n    sql_expects_tablename,\n)\nfrom IPython.core.completer import (\n    SimpleMatcherResult,", "from IPython.core.completer import (\n    SimpleMatcherResult,\n    SimpleCompletion,\n    context_matcher,\n    CompletionContext,\n)\n\nimport logging\n\nlogger = logging.getLogger(__name__)", "\nlogger = logging.getLogger(__name__)\n\npragma_before = re.compile(r\"(?si).*pragma\\s*\")\n\n\nclass DqlCustomCompleter(IPCompleter):\n    # In VSCode, text_until_cursor only returns the current line... not the entire cell/block. As far as I can tell, we'd need an extension for vscode, which seems like a bit too much work\n\n    def __init__(self, *args, **kwargs):\n        self.ipython = kwargs.get(\"shell\")\n        super().__init__(*args, **kwargs)\n\n    all_phrases = sql_expects_tablename + sql_phrases + pragma_phrases\n    lastword_pat = re.compile(r\"(?si)(^|.*[\\s])(\\S+)\\.\")\n    expects_table_pat = re.compile(r\"(?si).*from\")\n\n    def convert_to_return(\n        self, completions: List[str], matched_fragment: Optional[str] = None\n    ) -> SimpleMatcherResult:\n        simple_completions = [\n            SimpleCompletion(text=t, type=\"duckdb\") for t in completions\n        ]\n\n        # It took way too many hours to figure out that matched_fragment=\"\" was needed here\n        # Otherwise the results get suppressed\n        r = SimpleMatcherResult(\n            completions=simple_completions,\n            suppress=True,\n            matched_fragment=matched_fragment,\n            ordered=True,\n        )\n        return r\n\n    @context_matcher()  # type: ignore\n    def line_completer(self, event: CompletionContext) -> SimpleMatcherResult:\n        # if not %dql, returns nothing\n        # if ends with a sql_expects_tablename phrase, then returns just table names\n        # if ends in a period, checks to see if prefix is a tablename, and if so, returns column names\n        # otherwise returns all sql phrases and tablenames\n        # https://github.com/ipython/ipython/blob/a418f38c4f96de1755701041fe5d8deffbf906db/IPython/core/completer.py#L563\n\n        try:\n            # logger.info(event)\n            logger.debug(f\"{type(event)}, {self.ipython}, {event}\")\n\n            # return self.convert_to_return([\"SELECT\"], event.token)\n\n            if hasattr(event, \"full_text\"):\n                text = event.full_text\n            else:\n                logger.debug(f\"No full_text, nothing to do {event}\")\n                return self.convert_to_return([])\n\n            if not text.startswith(\"%dql\") and not text.startswith(\"%%dql\"):\n                return self.convert_to_return([])\n\n            # if hasattr(event, \"command\"):\n            #    command = event.command\n            # else:\n            #    logger.info(f\"{event}\")\n            #    #command = None\n\n            if hasattr(event, \"token\"):\n                token = event.token\n            else:\n                token = \"\"\n\n            line_after = text[4:].strip()\n\n            logger.debug(f\"{event}, {type(event)}\")\n\n            if token is not None and token.endswith(\".\"):\n                # VScode is ignoring or suppressing completions after a period.\n                # get the word preceding the period\n                tablename = token[:-1]\n                logger.debug(tablename)\n\n                # TODO: Deal with Aliases and SubQueries (xyz as abc)\n                columns = get_column_names(self.ipython, tablename)\n                logger.debug(f\"Using columns {columns}\")\n                return self.convert_to_return(columns, matched_fragment=\"\")\n\n            # if the last phrase should be followed by a table name, return the list of tables\n            elif self.expects_table_pat.match(line_after) is not None:\n                names = get_table_names(self.ipython)\n                if len(names) == 0:\n                    names = [\"No Tables or DataFrames Found\"]\n                logger.debug(f\"Expects table name, returning {names}\")\n\n                return self.convert_to_return(names, matched_fragment=event.token)\n\n            # default: return all phrases and tablenames\n            allp = self.all_phrases + get_table_names(self.ipython)\n            return self.convert_to_return(allp, event.token)\n\n        except Exception:\n            logger.exception(f\"Error completing {event}\")\n            return self.convert_to_return([])", "\n\ndef init_completer(ipython):\n    dql_completer = DqlCustomCompleter(\n        shell=ipython, greedy=True\n    )  # , attr_matches=True)\n\n    # Development notes:\n    # This took a while to figure out, partially because of the multiple APIs and signatures involved.\n    #\n    # What I learned:\n    # The ipython (get_ipython) environment has a Completer object\n    # Completer is an IPCompleter\n    # You can extend this completer in several ways, including:\n    # - Wrapping it\n    # - Registering a custom_completer, of which there are several ways: add_hook, Completer.custom_completers.add_s and add_re, or customer_completers.insert\n    #\n    # ipython 8.6.0 introduced new a v2 version of the API, for completers decorated with @context_matcher(), this API uses a different signature\n    # see ipython.core.completer for more info\n    # The main advantage of v2 is getting the full cell text, not just current cell\n    #\n    # add_s or add_re calls with two parameters:\n    # callable(self, event)\n    # The event contains: 2023-04-02 07:14:42,857 - magic_duckdb - INFO - namespace(line='%dql asda', symbol='asda', command='%dql', text_until_cursor='%dql asda')\n    #\n    # set_custom_completer was an alternative method of adding, which seemed inconsistent within VScode... but it passed three parameters:\n    # self, ipcompleter, linebuffer, cursor_pos\n    #\n    # the third method was add_hook('custom_complete'...)\n    # which is a synonym for add_s or add_re\n    #\n    # https://github.com/ipython/ipython/pull/13745\n    # https://ipython.readthedocs.io/en/stable/api/generated/IPython.core.completer.html\n    # https://raw.githubusercontent.com/ipython/ipython/main/IPython/core/completer.py\n    # https://ipython.org/ipython-doc/rel-0.12.1/api/generated/IPython.utils.strdispatch.html#IPython.utils.strdispatch.StrDispatch.s_matches\n    # https://github.com/ipython/ipython/blob/9663a9adc4c87490f1dc59c8b6f32cdfd0c5094a/IPython/core/tests/test_completer.py\n    #\n    # Also, annoyingly, VScode inserts some completions in: https://stackoverflow.com/questions/72824819/vscode-autocomplete-intellisense-in-jupyter-notebook-when-starting-string-lit\n\n    # ipython.Completer.custom_completers.add_s(\n    #    \"%dql\", dql_completer.line_completer, priority=-1\n    # )\n\n    # ipython.Completer.suppress_competing_matchers = True\n    # ip.Completer.custom_completers.add_re(r'(?si).*dql.*', dql_completer.complete)\n\n    ipython.Completer.custom_completer_matcher = dql_completer.line_completer", "    # ipython.Completer.custom_matchers.insert(0, dql_completer.line_completer)\n    # ipython.use_jedi = False\n\n    # ipython.Completer.suppress_competing_matchers = True\n"]}
{"filename": "magic_duckdb/autocomplete/__init__.py", "chunked_list": [""]}
{"filename": "magic_duckdb/autocomplete/autocompletion_v1.py", "chunked_list": ["# autocompletion for pre-iPython 8.6.0\n# the main limitation here is\nfrom magic_duckdb.autocomplete.common import (\n    get_table_names,\n    get_column_names,\n    sql_expects_tablename,\n)\n\nimport logging\n", "import logging\n\nlogger = logging.getLogger(\"magic_duckdb\")\n\n\ndef line_completer(ipython, event):\n    # v1 (pre 8.6.0 iPython) only passes the current line, not the entire text. So, line magics are fine but cell magics aren't\n\n    try:\n        logger.debug(event)\n        command = event.command\n        if command != \"%dql\" and command != \"%%dql\":\n            return\n\n        line = event.line\n        symbol = event.symbol\n        # text_until_cursor = event.text_until_cursor\n\n        if symbol == \"\" and line[-1] == \" \":\n            last_word = line.split(\" \")[-2]\n            logger.info(last_word)\n\n            if last_word.upper() in sql_expects_tablename:\n                return get_table_names(ipython)\n        elif symbol[-1] == \".\":\n            tablename = symbol[:-1]\n\n            columns = get_column_names(ipython, tablename)\n            logger.debug(f\"Using columns {columns}, {type(columns)}\")\n\n            # To complete a word, the current symbol needs to be prefixed\n            # To suggest the next word, just return the next word\n            results = [f\"{symbol}{col}\" for col in columns]\n            logger.info(results)\n            return results\n\n        logger.info(event)\n    except Exception:\n        logger.exception(f\"Error: {event}\")", "\n\ndef init_completer(ipython):\n    ipython.set_hook(\"complete_command\", line_completer, re_key=\"[%]+dql.*\")\n"]}
{"filename": "magic_duckdb/autocomplete/common.py", "chunked_list": ["import logging\nfrom typing import List\n\nfrom magic_duckdb import magic\nfrom pandas import DataFrame\n\nlogger = logging.getLogger(\"magic_duckdb\")\n\nsql_expects_tablename = [\n    \"UNION\",", "sql_expects_tablename = [\n    \"UNION\",\n    \"UNION ALL\",\n    \"UNION ALL BY NAME\",\n    \"UNION BY NAME\",\n    \"JOIN\",\n    \"INNER JOIN\",\n    \"LEFT JOIN\",\n    \"RIGHT JOIN\",\n    \"FULL JOIN\",", "    \"RIGHT JOIN\",\n    \"FULL JOIN\",\n    \"LEFT OUTER JOIN\",\n    \"RIGHT OUTER JOIN\",\n    \"FROM\",\n    \"INTO\",\n]\n\nsql_phrases = [\n    \"PRAGMA\",", "sql_phrases = [\n    \"PRAGMA\",\n    \"SELECT\",\n    \"WHERE\",\n    \"GROUP BY\",\n    \"ORDER BY\",\n    \"LIMIT\",\n    \"INSERT\",\n    \"UPDATE\",\n    \"DELETE\",", "    \"UPDATE\",\n    \"DELETE\",\n    \"ALTER\",\n    \"DROP\",\n    \"TRUNCATE\",\n    \"TABLE\",\n    \"DATABASE\",\n    \"INDEX\",\n    \"VIEW\",\n    \"FUNCTION\",", "    \"VIEW\",\n    \"FUNCTION\",\n    \"PROCEDURE\",\n    \"TRIGGER\",\n    \"AND\",\n    \"OR\",\n    \"NOT\",\n    \"BETWEEN\",\n    \"LIKE\",\n    \"IN\",", "    \"LIKE\",\n    \"IN\",\n    \"NULL\",\n    \"IS\",\n    \"EXISTS\",\n    \"COUNT\",\n    \"SUM\",\n    \"MIN\",\n    \"MAX\",\n    \"AVG\",", "    \"MAX\",\n    \"AVG\",\n    \"DISTINCT\",\n    \"AS\",\n    \"CREATE TABLE\",\n    \"CREATE OR REPLACE TABLE\",\n    \"CREATE TABLE IF NOT EXISTS\",\n    \"CREATE VIEW\",\n]\n", "]\n\npragma_phrases = [\n    \"PRAGMA version\",\n    \"PRAGMA database_list\",\n    \"PRAGMA database_size\",\n    \"PRAGMA show_tables\",\n    \"PRAGMA show_tables_expanded\",\n    \"PRAGMA table_info('\",\n    \"PRAGMA functions\",", "    \"PRAGMA table_info('\",\n    \"PRAGMA functions\",\n    \"PRAGMA collations\",\n    \"PRAGMA enable_progress_bar\",\n    \"PRAGMA disable_progress_bar\",\n    \"PRAGMA enable_profiling\",\n    \"PRAGMA disable_profiling\",\n    \"PRAGMA disable_optimizer\",\n    \"PRAGMA enable_optimizer\",\n    \"PRAGMA enable_verification\",", "    \"PRAGMA enable_optimizer\",\n    \"PRAGMA enable_verification\",\n    \"PRAGMA disable_verification\",\n    \"PRAGMA verify_parallelism\",\n    \"PRAGMA disable_verify_parallelism\",\n    \"PRAGMA force_index_join\",\n    \"PRAGMA force_checkpoint\",\n]\n\n\ndef get_table_names(ipython) -> List[str]:\n    try:\n        user_keys = [k for k, v in ipython.user_ns.items() if isinstance(v, DataFrame)]\n\n        if magic.connection is not None:\n            tables = magic.connection.sql(\"show tables\")\n            if tables is None:\n                return user_keys\n            else:\n                return list(tables.df()[\"name\"]) + user_keys\n        else:\n            logger.info(user_keys)\n            return user_keys\n    except Exception:\n        logger.exception(\"Unable to get table names\")\n        return []", "\n\ndef get_table_names(ipython) -> List[str]:\n    try:\n        user_keys = [k for k, v in ipython.user_ns.items() if isinstance(v, DataFrame)]\n\n        if magic.connection is not None:\n            tables = magic.connection.sql(\"show tables\")\n            if tables is None:\n                return user_keys\n            else:\n                return list(tables.df()[\"name\"]) + user_keys\n        else:\n            logger.info(user_keys)\n            return user_keys\n    except Exception:\n        logger.exception(\"Unable to get table names\")\n        return []", "\n\ndef get_column_names(ipython, tablename: str) -> List[str]:\n    try:\n        # check if an object\n        # o = ipython.ev(tablename)\n        o = ipython.user_ns.get(tablename)\n        if o is None and magic.connection is not None:\n            columns = magic.connection.sql(f\"pragma table_info('{tablename}')\")\n            if columns is None:\n                logger.debug(\"None columns\")\n                return []\n            else:\n                names = list(columns.df().astype(str)[\"name\"])\n                logger.debug(f\"Column names {names}\")\n                return names\n        elif o is not None:\n            if isinstance(o, DataFrame):\n                return list(o.columns)\n            else:\n                logger.debug(f\"{tablename} in namespace, but not a DataFrame {type(o)}\")\n                return []\n        else:\n            return []\n    except Exception:\n        logger.exception(\"Unable to get column names\")\n        return []", "\n\ndef init_completers(ip):\n    try:\n        from magic_duckdb.autocomplete.autocompletion_v2 import init_completer\n\n        init_completer(ipython=ip)\n    except Exception:\n        logger.debug(\n            \"Unable to initialize autocompletion_v2. iPython 8.6.0+ is required. Trying v1 completer\"\n        )\n        try:\n            from magic_duckdb.autocomplete.autocompletion_v2 import init_completer\n\n            init_completer(ipython=ip)\n        except Exception:\n            logger.debug(\"Unable to initialize autocompletion_v1\")", ""]}
{"filename": "magic_duckdb/extras/logging_init.py", "chunked_list": ["import logging\n\n\ndef log_to_file(logfile: str):\n    logger = logging.getLogger(\"magic_duckdb\")\n    logger.setLevel(logging.DEBUG)\n\n    file_handler = logging.FileHandler(logfile)\n    file_handler.setLevel(logging.DEBUG)\n    formatter = logging.Formatter(\n        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    )\n\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)", ""]}
{"filename": "magic_duckdb/extras/sqlformatter.py", "chunked_list": ["import pathlib\nfrom subprocess import Popen, PIPE, STDOUT\nimport logging\n\nlogger = logging.getLogger(\"magic_duckdb\")\n\nlanguage_mode = \"postgresql\"\nindentStyle = \"standard\"\nkeywordCase = \"upper\"\nlinesBetweenQueries = 0", "keywordCase = \"upper\"\nlinesBetweenQueries = 0\nlogicalOperatorNewline = \"after\"\ndenseOperators = \"true\"\n\n\ndef formatsql(query: str):\n    logger.debug(f\"Formatting {query}\")\n    config = f'\"keywordCase\": \"{keywordCase}\", \"indentStyle\": \"{indentStyle}\", \"linesBetweenQuerys\": {linesBetweenQueries}, \"logicalOperatorNewline\": \"{logicalOperatorNewline}\", \"denseOperators\": \"{denseOperators}\"'\n    config = \"{\" + config + \"}\"\n\n    pathlib.Path(\"format_config.json\").write_text(config)\n\n    cmd = [\n        \"npx\",\n        \"sql-formatter\",\n        \"-l\",\n        language_mode,\n        \"--config\",\n        \"format_config.json\",\n    ]\n\n    p = Popen(cmd, stdout=PIPE, stdin=PIPE, stderr=STDOUT, shell=True)\n    stdout_data = p.communicate(input=query.encode())[0]\n\n    print(stdout_data.decode())\n    return stdout_data.decode()", ""]}
{"filename": "magic_duckdb/extras/jinja_template.py", "chunked_list": ["def apply_template(sql: str, user_ns) -> str:\n    try:\n        from jinja2 import Template\n    except Exception as e:\n        raise ValueError(\n            \"Jinja2 must be installed to use --jinja: %pip install Jinja2\"\n        ) from e\n\n    t = Template(sql)\n    return t.render(user_ns)", ""]}
{"filename": "magic_duckdb/extras/__init__.py", "chunked_list": [""]}
{"filename": "magic_duckdb/extras/sql_ai.py", "chunked_list": ["#\n#\n# Futures:\n# Use embeddings\n# Maintain conversation context\nimport openai  # type: ignore\nimport logging\nfrom typing import Tuple, Optional\nimport textwrap\n", "import textwrap\n\nlogger = logging.getLogger(\"magic_duckdb\")\n\nOPENAI_KEY = None\nprint_prompts = False\nCOMPLETION_ENGINE = \"text-davinci-002\"\n# COMPLETION_ENGINE = \"gpt-4-32k-0314\"\n\nCHATCOMPLETION_ENGINE = \"gpt-3.5-turbo\"", "\nCHATCOMPLETION_ENGINE = \"gpt-3.5-turbo\"\n\n\ndef get_columns(connection) -> str:\n    df = connection.sql(\n        \"select table_name, column_name, data_type from duckdb_columns\"\n    ).df()\n\n    return df.to_csv(index=False)\n    col_desc = []\n\n    return [\"column_name\", \"data_type\"]\n\n    for t in df[\"table_name\"].unique():\n        cols = [\n            f\"{v[0]} (type = {v[1]})\"\n            for v in df.loc[df[\"table_name\"] == t, [\"column_name\", \"data_type\"]].values\n        ]\n        cols_desc = \",\".join(cols)\n\n        desc = f\"Table {t} has the following columns and data types - {cols_desc}\"\n        col_desc.append(desc)\n\n    return \"\\n\".join(col_desc)", "\n\ndef get_schema(connection) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n    try:\n        if connection is None:\n            return None, None, None\n\n        t = connection.sql(\"PRAGMA show_tables\")\n        if t is None:  # no tables = None\n            return None, None, None\n        else:\n            tables = t.df()\n\n        if len(tables) == 0:\n            tables = None\n        else:\n            tables = \", \".join(tables[\"name\"].values)\n\n        cols = get_columns(connection)\n\n        constraints = connection.sql(\"select * from duckdb_constraints\").df()\n\n        if len(constraints) == 0:\n            constraints = None\n        else:\n            constraints = constraints.to_csv()\n\n        return tables, cols, constraints\n    except Exception:\n        logger.exception(\"Error getting schema\")\n        return None, None, None", "\n\ndef call_ai(connection, chat: bool, prompt, query):\n    return ai_statement(\n        connection=connection, prompt=prompt, statement=query, chat=chat\n    )\n\n\ndef ai_statement(connection, prompt: str, statement: str, chat: bool = False):\n    logger.info(f\"Passing {prompt} statement to AI (chat={chat}): {statement}\")\n    # Prepare prompt\n    tables, cols, constraints = get_schema(connection)\n\n    prompt = f\"{prompt}\\nMy query is: {statement}\\nMy database is DuckDB. DuckDB's SQL is similar to postgresql. DuckDB sql supports: select, from, join, where, group by, grouping sets, having, order by, limit, sample, unnest, with, window, qualify, values and filter. \"\n    context = f\"I am writing SQL for a DuckDB database. My database's tables, columns and column data types are the following comma separated table: \\n{cols}\\n\\nConstraints: {constraints}\"\n\n    full_prompt = context + \"\\nMy question is: \" + prompt\n    logger.debug(f\"Num tokens: {len(prompt.split(' '))}\")\n\n    logger.info(f\"Prompt = \\n{full_prompt}\")\n    if print_prompts:\n        print(\"-------------Prompt---------------\")\n        print(full_prompt)\n\n    if OPENAI_KEY is None:\n        raise ValueError(\n            \"Set the OPENAI_KEY before using. \\nfrom magic_duckdb.extras import sql_ai\\nsql_ai.OPENAI_KEY=yourkey\"\n        )\n    else:\n        openai.api_key = OPENAI_KEY\n\n    if chat:\n        response = openai.ChatCompletion.create(\n            model=CHATCOMPLETION_ENGINE,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": full_prompt,\n                }\n            ],\n            max_tokens=193,\n            temperature=0,\n        )\n        result = response[\"choices\"][0][\"message\"][\"content\"]  # type: ignore\n\n    else:\n        response = openai.Completion.create(\n            engine=COMPLETION_ENGINE,\n            prompt=full_prompt,\n            max_tokens=100,\n            n=1,\n            stop=None,\n            temperature=0.5,\n        )\n\n        result = response.choices[0].text.strip()  # type: ignore\n\n    cell = textwrap.dedent(result)\n    # Insert 4 spaces of indentation before each line\n    cell = textwrap.indent(cell, \" \" * 4)\n\n    print(\"-------------OpenAI Response---------------\")\n    print(cell)\n    return cell", "def ai_statement(connection, prompt: str, statement: str, chat: bool = False):\n    logger.info(f\"Passing {prompt} statement to AI (chat={chat}): {statement}\")\n    # Prepare prompt\n    tables, cols, constraints = get_schema(connection)\n\n    prompt = f\"{prompt}\\nMy query is: {statement}\\nMy database is DuckDB. DuckDB's SQL is similar to postgresql. DuckDB sql supports: select, from, join, where, group by, grouping sets, having, order by, limit, sample, unnest, with, window, qualify, values and filter. \"\n    context = f\"I am writing SQL for a DuckDB database. My database's tables, columns and column data types are the following comma separated table: \\n{cols}\\n\\nConstraints: {constraints}\"\n\n    full_prompt = context + \"\\nMy question is: \" + prompt\n    logger.debug(f\"Num tokens: {len(prompt.split(' '))}\")\n\n    logger.info(f\"Prompt = \\n{full_prompt}\")\n    if print_prompts:\n        print(\"-------------Prompt---------------\")\n        print(full_prompt)\n\n    if OPENAI_KEY is None:\n        raise ValueError(\n            \"Set the OPENAI_KEY before using. \\nfrom magic_duckdb.extras import sql_ai\\nsql_ai.OPENAI_KEY=yourkey\"\n        )\n    else:\n        openai.api_key = OPENAI_KEY\n\n    if chat:\n        response = openai.ChatCompletion.create(\n            model=CHATCOMPLETION_ENGINE,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": full_prompt,\n                }\n            ],\n            max_tokens=193,\n            temperature=0,\n        )\n        result = response[\"choices\"][0][\"message\"][\"content\"]  # type: ignore\n\n    else:\n        response = openai.Completion.create(\n            engine=COMPLETION_ENGINE,\n            prompt=full_prompt,\n            max_tokens=100,\n            n=1,\n            stop=None,\n            temperature=0.5,\n        )\n\n        result = response.choices[0].text.strip()  # type: ignore\n\n    cell = textwrap.dedent(result)\n    # Insert 4 spaces of indentation before each line\n    cell = textwrap.indent(cell, \" \" * 4)\n\n    print(\"-------------OpenAI Response---------------\")\n    print(cell)\n    return cell", ""]}
{"filename": "magic_duckdb/extras/ast_graphviz.py", "chunked_list": ["from dataclasses import dataclass\nfrom typing import Dict, List, Tuple, Optional\nimport logging\n\n# An experiment at showing the AST using SQLParse.\n\nlogger = logging.getLogger(\"magic_duckdb\")\n\n# Extra path is optional: you should have \"dot\" in your PATH. If not, you can set extra_path to the\n# fully qualified path to your dot executable.", "# Extra path is optional: you should have \"dot\" in your PATH. If not, you can set extra_path to the\n# fully qualified path to your dot executable.\ndot_path = None\n# \"c:\\\\Program files\\\\graphviz\\\\bin\\\\dot.exe\"\n\n# graphviz.backend.dot_command.DOT_BINARY = pathlib.Path(\"c:\\\\Program files\\\\graphviz\\\\bin\\\\dot\")  # type: ignore # noqa\nSUPPRESS_EMPTY = True\nbasic_types = (int, float, str, bool, complex)\n\n", "\n\n@dataclass\nclass Node:\n    id: int\n    name: str\n    parent: \"Node\"\n    properties: Dict\n    children: List[\"Node\"]\n\n    def props_str(self):\n        return \" \".join([f\"{v}\" for k, v in self.properties.items()])", "\n\ndef get_tree(ast_json) -> Tuple[List[Node], List[Tuple[Node, Node]]]:\n    nodes: List[Node] = []\n    edges: List[Tuple[Node, Node]] = []\n\n    def get_node(name, parent):\n        id = len(nodes)\n        node = Node(id=id, name=name, parent=parent, properties={}, children=[])\n        nodes.append(node)\n\n        if parent is not None:\n            parent.children.append(node)\n            edges.append((parent, node))\n        return node\n\n    def process_node(name, o, parent: Optional[Node], use_parent: bool = False):\n        if SUPPRESS_EMPTY:\n            if o is None:\n                return\n            if isinstance(o, str) and o == \"\":\n                return\n            if isinstance(o, list) and len(o) == 0:\n                return\n\n        if use_parent:\n            assert parent is not None\n            node = parent\n        else:\n            node = get_node(name, parent)\n        if isinstance(o, basic_types):\n            prop = node.properties.get(\"value\")\n            if prop is not None:\n                # Only case where we hit this was column_names\n                # Might need to change if there are other similar\n                # cases where \".\" isn't the right delimiter\n                node.properties[\"value\"] = f\"{prop}.{o}\"\n            else:\n                node.properties[\"value\"] = f\"{o}\"\n\n        elif isinstance(o, dict):\n            if \"type\" in o:\n                node.properties[\"type\"] = o[\"type\"]\n            if \"class\" in o and o[\"class\"] != o.get(\"type\"):\n                node.properties[\"class\"] = o[\"class\"]\n            for k, v in o.items():\n                if k != \"type\" and k != \"class\":\n                    process_node(k, v, node)\n        elif isinstance(o, list):\n            for obj in o:  # skip over\n                process_node(name, obj, node, True)\n\n    process_node(\"Root\", ast_json, None)\n\n    return nodes, edges", "\n\ndef _print_node(n: Node, depth, lines):\n    indent = \"-\" * depth\n\n    lines.append(f\"{indent} | {n.name}: {n.props_str()}\")\n    for c in n.children:\n        _print_node(c, depth + 1, lines)\n\n\ndef ast_tree(ast_json):\n    nodes, edges = get_tree(ast_json)\n\n    root = nodes[0]\n\n    lines = []\n    _print_node(root, 0, lines)\n\n    return \"\\n\".join(lines)", "\n\ndef ast_tree(ast_json):\n    nodes, edges = get_tree(ast_json)\n\n    root = nodes[0]\n\n    lines = []\n    _print_node(root, 0, lines)\n\n    return \"\\n\".join(lines)", "\n\ndef ast_draw_graphviz(ast_json):\n    try:\n        # Defer loading, since this is optional\n        import graphviz  # type: ignore # noqa\n\n        logger.debug(\"Graphviz Python module is available\")\n    except Exception:\n        logger.debug(\"Graphviz Python module not available\")\n        return None\n    dot = graphviz.Digraph()  # type: ignore # noqa\n    dot.attr(rankdir=\"LR\")\n\n    nodes, edges = get_tree(ast_json)\n\n    for node in nodes:\n        if node.properties is not None and len(node.properties) > 0:\n            props = \"\\\\n\".join([f\"{v}\" for k, v in node.properties.items()])\n        else:\n            props = None\n        node_label = f\"{node.name}\\\\n{props}\" if props is not None else f\"<{node.name}>\"\n        dot.node(f\"{node.id}\", node_label, shape=\"rectangle\")\n\n    for e in edges:\n        dot.edge(f\"{e[0].id}\", f\"{e[1].id}\", color=\"red\")\n\n    return dot", ""]}
{"filename": "magic_duckdb/extras/explain_analyze_graphviz.py", "chunked_list": ["import os\nimport pathlib\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nimport json\nimport logging\n\nlogger = logging.getLogger(\"magic_duckdb\")\n\n# Extra path is optional: you should have \"dot\" in your PATH. If not, you can set extra_path to the", "\n# Extra path is optional: you should have \"dot\" in your PATH. If not, you can set extra_path to the\n# fully qualified path to your dot executable.\ndot_path = None\n# \"c:\\\\Program files\\\\graphviz\\\\bin\\\\dot.exe\"\n\n\ndef draw_graphviz(plan_json: str):\n    try:\n        # Defer loading, since this is optional\n        import graphviz  # type: ignore # noqa\n\n        logger.debug(\"Graphviz Python module is available\")\n    except Exception:\n        logger.debug(\"Graphviz Python module not available\")\n        return None\n\n    names_to_shapes = {\n        \"Query\": \"tripleoctagon\",\n        \"RESULT_COLLECTOR\": \"doubleoctagon\",\n        \"EXPLAIN_ANALYZE\": \"doubleoctagon\",\n        \"PROJECTION\": \"rectangle\",\n        \"DELIM_JOIN\": \"rectangle\",\n        \"HASH_JOIN\": \"rectangle\",\n    }\n\n    if dot_path is not None and os.path.exists(dot_path):\n        logger.debug(f\"Using dot_path {dot_path}\")\n\n        # graphviz.DOT_BINARY = pathlib.Path(\"c:\\\\Program files\\\\graphviz\\\\bin\\\\\")\n        # graphviz.backend.DOT_BINARY = pathlib.Path(\"c:\\\\Program files\\\\graphviz\\\\bin\\\\\")\n        graphviz.backend.dot_command.DOT_BINARY = pathlib.Path(dot_path)  # type: ignore # noqa\n\n    dot = graphviz.Digraph()  # type: ignore # noqa\n\n    @dataclass\n    class Node:\n        id: int\n        name: str\n        parent: \"Node\"\n        properties: Dict\n\n    nodes: List[Node] = []\n    edges: List[Dict] = []\n\n    def get_node(name, parent):\n        id = len(nodes)\n        node = Node(id=id, name=name, parent=parent, properties={})\n        nodes.append(node)\n        return node\n\n    def process_node(node_json, parent: Optional[Node]):\n        name = node_json.get(\"name\")\n        node = get_node(name, parent)\n\n        node.properties[\"cardinality\"] = node_json.get(\"cardinality\")\n\n        extra_info = node_json.get(\"extra_info\")\n        if extra_info is not None:\n            node.properties[\"extra_info\"] = extra_info.strip(\" \\t\\r\\n\").replace(\n                \"\\n\", \"\\\\n\"\n            )\n\n        node.properties[\"result\"] = node_json.get(\"result\")\n\n        timing = node_json.get(\"timing\")\n        timing_percent = (\n            timing / total_time if timing is not None and total_time is not None else 0\n        )\n\n        if timing is not None:\n            node.properties[\"timing\"] = f\"{timing:.2f} ({timing_percent:.0%})\"\n        props = [\n            f\"{k}={v}\" if k != \"extra_info\" else v\n            for k, v in node.properties.items()\n            if v is not None and v != \"\"\n        ]\n        propstr = \"\\\\n\".join(props)\n\n        shape = names_to_shapes.get(node.name)\n        if shape is None:\n            shape = \"ellipse\"\n        dot.node(f\"{node.id}\", f\"{node.name}\\\\n{propstr}\", weight=\"10\", shape=shape)\n\n        if parent is not None:\n            edges.append((parent.id, node.id, {\"weight\": node_json.get(\"timing\")}))  # type: ignore\n\n            dot.edge(f\"{parent.id}\", f\"{node.id}\")\n\n        children = node_json.get(\"children\")\n        if children is not None:\n            for child in children:\n                process_node(child, node)\n\n    j = json.loads(plan_json)\n\n    total_time = j.get(\"timing\")\n    process_node(j, None)\n\n    return dot", ""]}
