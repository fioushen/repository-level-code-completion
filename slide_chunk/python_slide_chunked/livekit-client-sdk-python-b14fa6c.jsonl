{"filename": "setup.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pathlib\n\nfrom setuptools import setup\n", "from setuptools import setup\n\nhere = pathlib.Path(__file__).parent.resolve()\nlong_description = (here / \"README.md\").read_text(encoding=\"utf-8\")\n\nsetup(\n    name=\"livekit\",\n    version=\"0.2.3\",\n    description=\"LiveKit Python Client SDK for LiveKit\",\n    long_description=long_description,", "    description=\"LiveKit Python Client SDK for LiveKit\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/livekit/client-sdk-python\",\n    classifiers=[\n        \"Development Status :: 3 - Alpha\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",", "        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3 :: Only\",\n    ],\n\n    keywords=\"webrtc, livekit\",\n    license=\"Apache-2.0\",", "    keywords=\"webrtc, livekit\",\n    license=\"Apache-2.0\",\n    packages=[\"livekit\"],\n    python_requires=\">=3.7, <4\",\n    install_requires=[\"pyee>=11.0.0\",\n                      \"protobuf>=3.1.0\", \"types-protobuf>=3.1.0\"],\n    package_data={\n        \"livekit\": ['lib/*/*/*.*', '_proto/*.py'],\n    },\n    project_urls={", "    },\n    project_urls={\n        \"Documentation\": \"https://docs.livekit.io\",\n        \"Website\": \"https://livekit.io/\",\n        \"Source\": \"https://github.com/livekit/client-sdk-python/\",\n    },\n)\n"]}
{"filename": "examples/publish_hue.py", "chunked_list": ["import asyncio\nimport colorsys\nimport logging\nfrom signal import SIGINT, SIGTERM\n\nimport numpy as np\n\nimport livekit\n\nURL = 'ws://localhost:7880'", "\nURL = 'ws://localhost:7880'\nTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'  # noqa\n\n\nasync def publish_frames(source: livekit.VideoSource):\n    argb_frame = livekit.ArgbFrame(\n        livekit.VideoFormatType.FORMAT_ARGB, 1280, 720)\n\n    arr = np.ctypeslib.as_array(argb_frame.data)", "\n    arr = np.ctypeslib.as_array(argb_frame.data)\n\n    framerate = 1 / 30\n    hue = 0.0\n\n    while True:\n        frame = livekit.VideoFrame(\n            0, livekit.VideoRotation.VIDEO_ROTATION_0, argb_frame.to_i420())\n", "            0, livekit.VideoRotation.VIDEO_ROTATION_0, argb_frame.to_i420())\n\n        rgb = colorsys.hsv_to_rgb(hue, 1.0, 1.0)\n        rgb = [(x * 255) for x in rgb] # type: ignore\n\n        argb_color = np.array(rgb + [255], dtype=np.uint8)\n        arr.flat[::4] = argb_color[0]\n        arr.flat[1::4] = argb_color[1]\n        arr.flat[2::4] = argb_color[2]\n        arr.flat[3::4] = argb_color[3]", "        arr.flat[2::4] = argb_color[2]\n        arr.flat[3::4] = argb_color[3]\n\n        source.capture_frame(frame)\n\n        hue += framerate/3  # 3s for a full cycle\n        if hue >= 1.0:\n            hue = 0.0\n\n        try:\n            await asyncio.sleep(framerate)\n        except asyncio.CancelledError:\n            break", "\n        try:\n            await asyncio.sleep(framerate)\n        except asyncio.CancelledError:\n            break\n\n\nasync def main():\n    room = livekit.Room()\n", "    room = livekit.Room()\n\n    logging.info(\"connecting to %s\", URL)\n    try:\n        await room.connect(URL, TOKEN)\n        logging.info(\"connected to room %s\", room.name)\n    except livekit.ConnectError as e:\n        logging.error(\"failed to connect to the room: %s\", e)\n        return False\n", "\n    # publish a track\n    source = livekit.VideoSource()\n    source_task = asyncio.create_task(publish_frames(source))\n\n    track = livekit.LocalVideoTrack.create_video_track(\"hue\", source)\n    options = livekit.TrackPublishOptions()\n    options.source = livekit.TrackSource.SOURCE_CAMERA\n    publication = await room.local_participant.publish_track(track, options)\n    logging.info(\"published track %s\", publication.sid)", "    publication = await room.local_participant.publish_track(track, options)\n    logging.info(\"published track %s\", publication.sid)\n\n    try:\n        await room.run()\n    except asyncio.CancelledError:\n        logging.info(\"closing the room\")\n        source_task.cancel()\n        await source_task\n        await room.disconnect()", "\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO, handlers=[\n                        logging.FileHandler(\"publish_hue.log\"), logging.StreamHandler()])\n\n    loop = asyncio.get_event_loop()\n    main_task = asyncio.ensure_future(main())\n    for signal in [SIGINT, SIGTERM]:\n        loop.add_signal_handler(signal, main_task.cancel)\n    try:\n        loop.run_until_complete(main_task)\n    finally:\n        loop.close()", ""]}
{"filename": "examples/basic_room.py", "chunked_list": ["import asyncio\nimport logging\nfrom signal import SIGINT, SIGTERM\nfrom typing import Union\n\nimport livekit\n\nURL = 'ws://localhost:7880'\nTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'\n", "TOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'\n\n\nasync def main() -> None:\n    room = livekit.Room()\n\n    @room.listens_to(\"participant_connected\")\n    def on_participant_connected(participant: livekit.RemoteParticipant) -> None:\n        logging.info(\n            \"participant connected: %s %s\", participant.sid, participant.identity)", "\n    @room.listens_to(\"participant_disconnected\")\n    def on_participant_disconnected(participant: livekit.RemoteParticipant):\n        logging.info(\"participant disconnected: %s %s\",\n                     participant.sid, participant.identity)\n\n    @room.listens_to(\"local_track_published\")\n    def on_local_track_published(publication: livekit.LocalTrackPublication,\n                                 track: Union[livekit.LocalAudioTrack,\n                                              livekit.LocalVideoTrack]):\n        logging.info(\"local track published: %s\", publication.sid)", "\n    @room.listens_to(\"active_speakers_changed\")\n    def on_active_speakers_changed(speakers: list[livekit.Participant]):\n        logging.info(\"active speakers changed: %s\", speakers)\n\n    @room.listens_to(\"local_track_unpublished\")\n    def on_local_track_unpublished(publication: livekit.LocalTrackPublication):\n        logging.info(\"local track unpublished: %s\", publication.sid)\n\n    @room.listens_to(\"track_published\")\n    def on_track_published(publication: livekit.RemoteTrackPublication,\n                           participant: livekit.RemoteParticipant):\n        logging.info(\"track published: %s from participant %s (%s)\",\n                     publication.sid, participant.sid, participant.identity)", "\n    @room.listens_to(\"track_published\")\n    def on_track_published(publication: livekit.RemoteTrackPublication,\n                           participant: livekit.RemoteParticipant):\n        logging.info(\"track published: %s from participant %s (%s)\",\n                     publication.sid, participant.sid, participant.identity)\n\n    @room.listens_to(\"track_unpublished\")\n    def on_track_unpublished(publication: livekit.RemoteTrackPublication,\n                             participant: livekit.RemoteParticipant):\n        logging.info(\"track unpublished: %s\", publication.sid)", "    def on_track_unpublished(publication: livekit.RemoteTrackPublication,\n                             participant: livekit.RemoteParticipant):\n        logging.info(\"track unpublished: %s\", publication.sid)\n\n    # Keep a reference to the streams, otherwise they will be disposed\n    audio_stream = None\n    video_stream = None\n\n    @room.listens_to(\"track_subscribed\")\n    def on_track_subscribed(track: livekit.Track,\n                            publication: livekit.RemoteTrackPublication,\n                            participant: livekit.RemoteParticipant):\n        logging.info(\"track subscribed: %s\", publication.sid)\n        if track.kind == livekit.TrackKind.KIND_VIDEO:\n            nonlocal video_stream\n            video_stream = livekit.VideoStream(track)\n\n            @video_stream.on(\"frame_received\")\n            def on_video_frame(frame: livekit.VideoFrame):\n                # received a video frame from the track\n                pass\n        elif track.kind == livekit.TrackKind.KIND_AUDIO:\n            print(\"Subscribed to an Audio Track\")\n            nonlocal audio_stream\n            audio_stream = livekit.AudioStream(track)\n\n            @audio_stream.on('frame_received')\n            def on_audio_frame(frame: livekit.AudioFrame):\n                # received an audio frame from the track\n                pass", "    @room.listens_to(\"track_subscribed\")\n    def on_track_subscribed(track: livekit.Track,\n                            publication: livekit.RemoteTrackPublication,\n                            participant: livekit.RemoteParticipant):\n        logging.info(\"track subscribed: %s\", publication.sid)\n        if track.kind == livekit.TrackKind.KIND_VIDEO:\n            nonlocal video_stream\n            video_stream = livekit.VideoStream(track)\n\n            @video_stream.on(\"frame_received\")\n            def on_video_frame(frame: livekit.VideoFrame):\n                # received a video frame from the track\n                pass\n        elif track.kind == livekit.TrackKind.KIND_AUDIO:\n            print(\"Subscribed to an Audio Track\")\n            nonlocal audio_stream\n            audio_stream = livekit.AudioStream(track)\n\n            @audio_stream.on('frame_received')\n            def on_audio_frame(frame: livekit.AudioFrame):\n                # received an audio frame from the track\n                pass", "\n    @room.listens_to(\"track_unsubscribed\")\n    def on_track_unsubscribed(track: livekit.Track,\n                              publication: livekit.RemoteTrackPublication,\n                              participant: livekit.RemoteParticipant):\n        logging.info(\"track unsubscribed: %s\", publication.sid)\n\n    @room.listens_to(\"data_received\")\n    def on_data_received(data: bytes,\n                         kind: livekit.DataPacketKind,\n                         participant: livekit.Participant):\n        logging.info(\"received data from %s: %s\", participant.identity, data)", "    def on_data_received(data: bytes,\n                         kind: livekit.DataPacketKind,\n                         participant: livekit.Participant):\n        logging.info(\"received data from %s: %s\", participant.identity, data)\n\n    @room.listens_to(\"connection_quality_changed\")\n    def on_connection_quality_changed(participant: livekit.Participant,\n                                      quality: livekit.ConnectionQuality):\n        logging.info(\"connection quality changed for %s\", participant.identity)\n", "\n    @room.listens_to(\"track_subscription_failed\")\n    def on_track_subscription_failed(participant: livekit.RemoteParticipant,\n                                     track_sid: str,\n                                     error: str):\n        logging.info(\"track subscription failed: %s %s\",\n                     participant.identity, error)\n\n    @room.listens_to(\"connection_state_changed\")\n    def on_connection_state_changed(state: livekit.ConnectionState):\n        logging.info(\"connection state changed: %s\", state)", "    @room.listens_to(\"connection_state_changed\")\n    def on_connection_state_changed(state: livekit.ConnectionState):\n        logging.info(\"connection state changed: %s\", state)\n\n    @room.listens_to(\"connected\")\n    def on_connected() -> None:\n        logging.info(\"connected\")\n\n    @room.listens_to(\"disconnected\")\n    def on_disconnected() -> None:\n        logging.info(\"disconnected\")", "    @room.listens_to(\"disconnected\")\n    def on_disconnected() -> None:\n        logging.info(\"disconnected\")\n\n    @room.listens_to(\"reconnecting\")\n    def on_reconnecting() -> None:\n        logging.info(\"reconnecting\")\n\n    @room.listens_to(\"reconnected\")\n    def on_reconnected() -> None:\n        logging.info(\"reconnected\")", "    @room.listens_to(\"reconnected\")\n    def on_reconnected() -> None:\n        logging.info(\"reconnected\")\n\n    try:\n        logging.info(\"connecting to %s\", URL)\n        await room.connect(URL, TOKEN)\n        logging.info(\"connected to room %s\", room.name)\n\n        await room.local_participant.publish_data(\"hello world\")\n\n        logging.info(\"participants: %s\", room.participants)\n\n        await room.run()\n    except livekit.ConnectError as e:\n        logging.error(\"failed to connect to the room: %s\", e)\n    except asyncio.CancelledError:\n        logging.info(\"closing the room\")\n        await room.disconnect()", "\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO, handlers=[\n                        logging.FileHandler(\"basic_room.log\"), logging.StreamHandler()])\n\n    loop = asyncio.get_event_loop()\n    main_task = asyncio.ensure_future(main())\n    for signal in [SIGINT, SIGTERM]:\n        loop.add_signal_handler(signal, main_task.cancel)\n    try:\n        loop.run_until_complete(main_task)\n    finally:\n        loop.close()", ""]}
{"filename": "examples/publish_wave.py", "chunked_list": ["import asyncio\nimport logging\nfrom signal import SIGINT, SIGTERM\n\nimport numpy as np\n\nimport livekit\n\nURL = 'ws://localhost:7880'\nTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'", "URL = 'ws://localhost:7880'\nTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'\n\n\nasync def publish_frames(source: livekit.AudioSource):\n    sample_rate = 48000\n    frequency = 440\n    amplitude = 32767  # for 16-bit audio\n    num_channels = 1\n    samples_per_channel = 480  # 10ms at 48kHz", "    num_channels = 1\n    samples_per_channel = 480  # 10ms at 48kHz\n    time = np.arange(samples_per_channel) / sample_rate\n    total_samples = 0\n\n    audio_frame = livekit.AudioFrame.create(\n        sample_rate, num_channels, samples_per_channel)\n\n    audio_data = np.ctypeslib.as_array(audio_frame.data)\n", "    audio_data = np.ctypeslib.as_array(audio_frame.data)\n\n    while True:\n        time = (total_samples + np.arange(samples_per_channel)) / sample_rate\n\n        sine_wave = (amplitude * np.sin(2 * np.pi *\n                     frequency * time)).astype(np.int16)\n        np.copyto(audio_data, sine_wave)\n\n        source.capture_frame(audio_frame)", "\n        source.capture_frame(audio_frame)\n\n        total_samples += samples_per_channel\n\n        try:\n            await asyncio.sleep(1 / 100)  # 10m\n        except asyncio.CancelledError:\n            break\n", "\n\nasync def main() -> None:\n    room = livekit.Room()\n\n    logging.info(\"connecting to %s\", URL)\n    try:\n        await room.connect(URL, TOKEN)\n        logging.info(\"connected to room %s\", room.name)\n    except livekit.ConnectError as e:\n        logging.error(\"failed to connect to the room: %s\", e)\n        return", "\n    # publish a track\n    source = livekit.AudioSource()\n    source_task = asyncio.create_task(publish_frames(source))\n\n    track = livekit.LocalAudioTrack.create_audio_track(\"sinewave\", source)\n    options = livekit.TrackPublishOptions()\n    options.source = livekit.TrackSource.SOURCE_MICROPHONE\n    publication = await room.local_participant.publish_track(track, options)\n    logging.info(\"published track %s\", publication.sid)", "    publication = await room.local_participant.publish_track(track, options)\n    logging.info(\"published track %s\", publication.sid)\n\n    try:\n        await room.run()\n    except asyncio.CancelledError:\n        logging.info(\"closing the room\")\n        source_task.cancel()\n        await source_task\n        await room.disconnect()", "\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO, handlers=[\n                        logging.FileHandler(\"publish_wave.log\"), logging.StreamHandler()])\n\n    loop = asyncio.get_event_loop()\n    main_task = asyncio.ensure_future(main())\n    for signal in [SIGINT, SIGTERM]:\n        loop.add_signal_handler(signal, main_task.cancel)\n    try:\n        loop.run_until_complete(main_task)\n    finally:\n        loop.close()", ""]}
{"filename": "examples/whisper/whisper.py", "chunked_list": ["import asyncio\nimport ctypes\nimport logging\nimport pathlib\nimport platform\nfrom signal import SIGINT, SIGTERM\n\nimport numpy as np\n\nimport livekit", "\nimport livekit\n\nos = platform.system().lower()\nif os == \"windows\":\n    lib_file = 'whisper.dll'\nelif os == \"darwin\":\n    lib_file = 'libwhisper.dylib'\nelse:\n    lib_file = 'libwhisper.so'", "\nwhisper_dir = pathlib.Path(__file__).parent.absolute() / \"whisper.cpp\"\nlibname = str(whisper_dir / lib_file)\nfname_model = str(whisper_dir / \"models/ggml-tiny.en.bin\")\n\nURL = 'ws://localhost:7880'\nTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'  # noqa\n\n\n# declare the Whisper C API  (Only what we need, keep things simple)", "\n# declare the Whisper C API  (Only what we need, keep things simple)\n# also see this issue: https://github.com/ggerganov/whisper.cpp/issues/9\n# structure must match https://github.com/ggerganov/whisper.cpp/blob/master/whisper.h\n\n\nclass WhisperSamplingStrategy(ctypes.c_int):\n    WHISPER_SAMPLING_GREEDY = 0\n    WHISPER_SAMPLING_BEAM_SEARCH = 1\n", "\n\nclass WhisperFullParams(ctypes.Structure):\n    _fields_ = [\n        ('strategy', ctypes.c_int),\n        ('n_threads',  ctypes.c_int),\n        ('n_max_text_ctx', ctypes.c_int),\n        ('offset_ms', ctypes.c_int),\n        ('duration_ms', ctypes.c_int),\n        ('translate', ctypes.c_bool),\n        ('no_context', ctypes.c_bool),\n        ('single_segment', ctypes.c_bool),\n        ('print_special', ctypes.c_bool),\n        ('print_progress', ctypes.c_bool),\n        ('print_realtime', ctypes.c_bool),\n        ('print_timestamps', ctypes.c_bool),\n        ('token_timestamps', ctypes.c_bool),\n        ('thold_pt', ctypes.c_float),\n        ('thold_ptsum', ctypes.c_float),\n        ('max_len', ctypes.c_int),\n        ('split_on_word', ctypes.c_bool),\n        ('max_tokens', ctypes.c_int),\n        ('speed_up', ctypes. c_bool),\n        ('audio_ctx', ctypes. c_int),\n        ('tdrz_enable', ctypes. c_bool),\n        ('initial_prompt', ctypes.c_char_p),\n        ('prompt_tokens', ctypes.c_void_p),\n        ('prompt_n_tokens', ctypes.c_int),\n        ('language', ctypes.c_char_p),\n        ('detect_language', ctypes.c_bool),\n        ('suppress_blank', ctypes.c_bool),\n        ('suppress_non_speech_tokens', ctypes.c_bool),\n        ('temperature', ctypes.c_float),\n        ('max_initial_ts', ctypes.c_float),\n        ('length_penalty', ctypes.c_float),\n        ('temperature_inc', ctypes. c_float),\n        ('entropy_thold', ctypes. c_float),\n        ('logprob_thold', ctypes. c_float),\n        ('no_speech_thold', ctypes. c_float),\n        ('greedy', ctypes.c_int),\n        ('beam_size', ctypes.c_int),\n        ('patience', ctypes.c_float),\n        ('new_segment_callback', ctypes.c_void_p),\n        ('new_segment_callback_user_data', ctypes.c_void_p),\n        ('progress_callback', ctypes.c_void_p),\n        ('progress_callback_user_data', ctypes.c_void_p),\n        ('encoder_begin_callback', ctypes.c_void_p),\n        ('encoder_begin_callback_user_data', ctypes.c_void_p),\n        ('logits_filter_callback', ctypes.c_void_p),\n        ('logits_filter_callback_user_data', ctypes.c_void_p),\n    ]", "\n\nWHISPER_SAMPLE_RATE = 16000\nSAMPLES_30_SECS = WHISPER_SAMPLE_RATE * 30\nSAMPLES_KEEP = WHISPER_SAMPLE_RATE * 1  # data to keep from the old inference\nSAMPLES_STEP = WHISPER_SAMPLE_RATE * 3  # 3 seconds of new data\n\nwhisper = ctypes.CDLL(libname)\nwhisper.whisper_init_from_file.argtypes = [ctypes.c_char_p]\nwhisper.whisper_init_from_file.restype = ctypes.c_void_p", "whisper.whisper_init_from_file.argtypes = [ctypes.c_char_p]\nwhisper.whisper_init_from_file.restype = ctypes.c_void_p\nwhisper.whisper_full_default_params.restype = WhisperFullParams\nwhisper.whisper_full_get_segment_text.restype = ctypes.c_char_p\nctx = whisper.whisper_init_from_file(fname_model.encode('utf-8'))\n\ndata_30_secs = np.zeros(SAMPLES_30_SECS, dtype=np.float32)\nwritten_samples = 0  # nb. of samples written to data_30_secs for the cur. inference\n\n\ndef on_audio_frame(frame: livekit.AudioFrame):\n    global data_30_secs, written_samples\n\n    # whisper requires 16kHz mono, so resample the data\n    # also convert the samples from int16 to float32\n    frame = frame.remix_and_resample(\n        WHISPER_SAMPLE_RATE, 1)\n\n    data = np.array(frame.data, dtype=np.float32) / 32768.0\n\n    # write the data inside data_30_secs at written_samples\n    data_start = SAMPLES_KEEP + written_samples\n    data_30_secs[data_start:data_start+len(data)] = data\n    written_samples += len(data)\n\n    if written_samples >= SAMPLES_STEP:\n        params = whisper.whisper_full_default_params(\n            WhisperSamplingStrategy.WHISPER_SAMPLING_GREEDY)\n        params.print_realtime = False\n        params.print_progress = False\n\n        ctx_ptr = ctypes.c_void_p(ctx)\n        data_ptr = data_30_secs.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n        res = whisper.whisper_full(ctx_ptr,\n                                   params,\n                                   data_ptr,\n                                   written_samples + SAMPLES_KEEP)\n\n        if res != 0:\n            logging.error(\"error while running inference: %s\", res)\n            return\n\n        n_segments = whisper.whisper_full_n_segments(ctx_ptr)\n        for i in range(n_segments):\n            t0 = whisper.whisper_full_get_segment_t0(ctx_ptr, i)\n            t1 = whisper.whisper_full_get_segment_t1(ctx_ptr, i)\n            txt = whisper.whisper_full_get_segment_text(ctx_ptr, i)\n\n            logging.info(\n                f\"{t0/1000.0:.3f} - {t1/1000.0:.3f} : {txt.decode('utf-8')}\")\n\n        # write old data to the beginning of the buffer (SAMPLES_KEEP)\n        data_30_secs[:SAMPLES_KEEP] = data_30_secs[data_start +\n                                                   written_samples - SAMPLES_KEEP:\n                                                   data_start + written_samples]\n        written_samples = 0", "\n\ndef on_audio_frame(frame: livekit.AudioFrame):\n    global data_30_secs, written_samples\n\n    # whisper requires 16kHz mono, so resample the data\n    # also convert the samples from int16 to float32\n    frame = frame.remix_and_resample(\n        WHISPER_SAMPLE_RATE, 1)\n\n    data = np.array(frame.data, dtype=np.float32) / 32768.0\n\n    # write the data inside data_30_secs at written_samples\n    data_start = SAMPLES_KEEP + written_samples\n    data_30_secs[data_start:data_start+len(data)] = data\n    written_samples += len(data)\n\n    if written_samples >= SAMPLES_STEP:\n        params = whisper.whisper_full_default_params(\n            WhisperSamplingStrategy.WHISPER_SAMPLING_GREEDY)\n        params.print_realtime = False\n        params.print_progress = False\n\n        ctx_ptr = ctypes.c_void_p(ctx)\n        data_ptr = data_30_secs.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n        res = whisper.whisper_full(ctx_ptr,\n                                   params,\n                                   data_ptr,\n                                   written_samples + SAMPLES_KEEP)\n\n        if res != 0:\n            logging.error(\"error while running inference: %s\", res)\n            return\n\n        n_segments = whisper.whisper_full_n_segments(ctx_ptr)\n        for i in range(n_segments):\n            t0 = whisper.whisper_full_get_segment_t0(ctx_ptr, i)\n            t1 = whisper.whisper_full_get_segment_t1(ctx_ptr, i)\n            txt = whisper.whisper_full_get_segment_text(ctx_ptr, i)\n\n            logging.info(\n                f\"{t0/1000.0:.3f} - {t1/1000.0:.3f} : {txt.decode('utf-8')}\")\n\n        # write old data to the beginning of the buffer (SAMPLES_KEEP)\n        data_30_secs[:SAMPLES_KEEP] = data_30_secs[data_start +\n                                                   written_samples - SAMPLES_KEEP:\n                                                   data_start + written_samples]\n        written_samples = 0", "\n\nasync def main():\n    room = livekit.Room()\n    audio_stream = None\n\n    @room.listens_to(\"track_published\")\n    def on_track_published(publication: livekit.RemoteTrackPublication,\n                           participant: livekit.RemoteParticipant):\n        # Only subscribe to the audio tracks coming from the microphone\n        if publication.kind == livekit.TrackKind.KIND_AUDIO \\\n                and publication.source == livekit.TrackSource.SOURCE_MICROPHONE:\n            logging.info(\"track published: %s from participant %s (%s), subscribing...\",\n                         publication.sid, participant.sid, participant.identity)\n\n            publication.set_subscribed(True)", "\n    @room.listens_to(\"track_subscribed\")\n    def on_track_subscribed(track: livekit.Track,\n                            publication: livekit.RemoteTrackPublication,\n                            participant: livekit.RemoteParticipant):\n        logging.info(\"starting listening to: %s\", participant.identity)\n        nonlocal audio_stream\n        audio_stream = livekit.AudioStream(track)\n        audio_stream.add_listener('frame_received', on_audio_frame)\n\n    try:\n        logging.info(\"connecting to %s\", URL)\n        await room.connect(URL, TOKEN, livekit.RoomOptions(auto_subscribe=False))\n        logging.info(\"connected to room %s\", room.name)\n\n        # check if there are already published audio tracks\n        for participant in room.participants.values():\n            for track in participant.tracks.values():\n                if track.kind == livekit.TrackKind.KIND_AUDIO \\\n                        and track.source == livekit.TrackSource.SOURCE_MICROPHONE:\n                    track.set_subscribed(True)\n\n        await room.run()\n    except livekit.ConnectError as e:\n        logging.error(\"failed to connect to the room: %s\", e)\n    except asyncio.CancelledError:\n        logging.info(\"closing the room\")\n        await room.disconnect()", "\n    try:\n        logging.info(\"connecting to %s\", URL)\n        await room.connect(URL, TOKEN, livekit.RoomOptions(auto_subscribe=False))\n        logging.info(\"connected to room %s\", room.name)\n\n        # check if there are already published audio tracks\n        for participant in room.participants.values():\n            for track in participant.tracks.values():\n                if track.kind == livekit.TrackKind.KIND_AUDIO \\\n                        and track.source == livekit.TrackSource.SOURCE_MICROPHONE:\n                    track.set_subscribed(True)\n\n        await room.run()\n    except livekit.ConnectError as e:\n        logging.error(\"failed to connect to the room: %s\", e)\n    except asyncio.CancelledError:\n        logging.info(\"closing the room\")\n        await room.disconnect()", "\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO, handlers=[\n                        logging.FileHandler(\"whisper.log\"), logging.StreamHandler()])\n\n    loop = asyncio.get_event_loop()\n    main_task = asyncio.ensure_future(main())\n    for signal in [SIGINT, SIGTERM]:\n        loop.add_signal_handler(signal, main_task.cancel)\n    try:\n        loop.run_until_complete(main_task)\n    finally:\n        loop.close()\n\n    whisper.whisper_free(ctypes.c_void_p(ctx))", ""]}
{"filename": "examples/face_landmark/face_landmark.py", "chunked_list": ["import asyncio\nimport os\nfrom queue import Queue\n\nimport cv2\nimport mediapipe as mp\nimport numpy as np\nfrom mediapipe import solutions\nfrom mediapipe.framework.formats import landmark_pb2\n", "from mediapipe.framework.formats import landmark_pb2\n\nimport livekit\n\nURL = 'ws://localhost:7880'\nTOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE5MDY2MTMyODgsImlzcyI6IkFQSVRzRWZpZFpqclFvWSIsIm5hbWUiOiJuYXRpdmUiLCJuYmYiOjE2NzI2MTMyODgsInN1YiI6Im5hdGl2ZSIsInZpZGVvIjp7InJvb20iOiJ0ZXN0Iiwicm9vbUFkbWluIjp0cnVlLCJyb29tQ3JlYXRlIjp0cnVlLCJyb29tSm9pbiI6dHJ1ZSwicm9vbUxpc3QiOnRydWV9fQ.uSNIangMRu8jZD5mnRYoCHjcsQWCrJXgHCs0aNIgBFY'\n\nframe_queue = Queue()\nargb_frame = None\n", "argb_frame = None\n\n# You can download a face landmark model file from https://developers.google.com/mediapipe/solutions/vision/face_landmarker#models\nmodel_file = 'face_landmarker.task'\nmodel_path = os.path.dirname(os.path.realpath(__file__)) + '/' + model_file\n\nBaseOptions = mp.tasks.BaseOptions\nFaceLandmarker = mp.tasks.vision.FaceLandmarker\nFaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\nVisionRunningMode = mp.tasks.vision.RunningMode", "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\nVisionRunningMode = mp.tasks.vision.RunningMode\n\noptions = FaceLandmarkerOptions(\n    base_options=BaseOptions(model_asset_path=model_path),\n    running_mode=VisionRunningMode.VIDEO)\n\n# from https://github.com/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb\n\n\ndef draw_landmarks_on_image(rgb_image, detection_result):\n    face_landmarks_list = detection_result.face_landmarks\n\n    # Loop through the detected faces to visualize.\n    for idx in range(len(face_landmarks_list)):\n        face_landmarks = face_landmarks_list[idx]\n\n        # Draw the face landmarks.\n        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n        face_landmarks_proto.landmark.extend([\n            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n        ])\n\n        solutions.drawing_utils.draw_landmarks(\n            image=rgb_image,\n            landmark_list=face_landmarks_proto,\n            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n            landmark_drawing_spec=None,\n            connection_drawing_spec=mp.solutions.drawing_styles\n            .get_default_face_mesh_tesselation_style())\n        solutions.drawing_utils.draw_landmarks(\n            image=rgb_image,\n            landmark_list=face_landmarks_proto,\n            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n            landmark_drawing_spec=None,\n            connection_drawing_spec=mp.solutions.drawing_styles\n            .get_default_face_mesh_contours_style())\n        solutions.drawing_utils.draw_landmarks(\n            image=rgb_image,\n            landmark_list=face_landmarks_proto,\n            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n            landmark_drawing_spec=None,\n            connection_drawing_spec=mp.solutions.drawing_styles\n            .get_default_face_mesh_iris_connections_style())", "\n\ndef draw_landmarks_on_image(rgb_image, detection_result):\n    face_landmarks_list = detection_result.face_landmarks\n\n    # Loop through the detected faces to visualize.\n    for idx in range(len(face_landmarks_list)):\n        face_landmarks = face_landmarks_list[idx]\n\n        # Draw the face landmarks.\n        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n        face_landmarks_proto.landmark.extend([\n            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n        ])\n\n        solutions.drawing_utils.draw_landmarks(\n            image=rgb_image,\n            landmark_list=face_landmarks_proto,\n            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n            landmark_drawing_spec=None,\n            connection_drawing_spec=mp.solutions.drawing_styles\n            .get_default_face_mesh_tesselation_style())\n        solutions.drawing_utils.draw_landmarks(\n            image=rgb_image,\n            landmark_list=face_landmarks_proto,\n            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n            landmark_drawing_spec=None,\n            connection_drawing_spec=mp.solutions.drawing_styles\n            .get_default_face_mesh_contours_style())\n        solutions.drawing_utils.draw_landmarks(\n            image=rgb_image,\n            landmark_list=face_landmarks_proto,\n            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n            landmark_drawing_spec=None,\n            connection_drawing_spec=mp.solutions.drawing_styles\n            .get_default_face_mesh_iris_connections_style())", "\n\nasync def room() -> None:\n    room = livekit.Room()\n    await room.connect(URL, TOKEN)\n    print(\"connected to room: \" + room.name)\n\n    video_stream = None\n\n    @room.on(\"track_subscribed\")\n    def on_track_subscribed(track: livekit.Track,\n                            publication: livekit.RemoteTrackPublication,\n                            participant: livekit.RemoteParticipant):\n        if track.kind == livekit.TrackKind.KIND_VIDEO:\n            nonlocal video_stream\n            video_stream = livekit.VideoStream(track)\n\n            @video_stream.on(\"frame_received\")\n            def on_video_frame(frame: livekit.VideoFrame):\n                frame_queue.put(frame)", "\n    @room.on(\"track_subscribed\")\n    def on_track_subscribed(track: livekit.Track,\n                            publication: livekit.RemoteTrackPublication,\n                            participant: livekit.RemoteParticipant):\n        if track.kind == livekit.TrackKind.KIND_VIDEO:\n            nonlocal video_stream\n            video_stream = livekit.VideoStream(track)\n\n            @video_stream.on(\"frame_received\")\n            def on_video_frame(frame: livekit.VideoFrame):\n                frame_queue.put(frame)", "\n    await room.run()\n\n\ndef display_frames() -> None:\n    cv2.namedWindow('livekit_video', cv2.WINDOW_AUTOSIZE)\n    cv2.startWindowThread()\n\n    global argb_frame\n\n    with FaceLandmarker.create_from_options(options) as landmarker:\n        while True:\n            frame = frame_queue.get()\n            buffer = frame.buffer\n\n            if argb_frame is None or argb_frame.width != buffer.width or argb_frame.height != buffer.height:\n                argb_frame = livekit.ArgbFrame(\n                    livekit.VideoFormatType.FORMAT_ABGR, buffer.width, buffer.height)\n\n            buffer.to_argb(argb_frame)\n\n            arr = np.ctypeslib.as_array(argb_frame.data)\n            arr = arr.reshape((argb_frame.height, argb_frame.width, 4))\n            arr = cv2.cvtColor(arr, cv2.COLOR_RGBA2RGB)\n\n            mp_image = mp.Image(\n                image_format=mp.ImageFormat.SRGB, data=arr)\n\n            detection_result = landmarker.detect_for_video(\n                mp_image, frame.timestamp)\n\n            draw_landmarks_on_image(arr, detection_result)\n\n            arr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n\n            cv2.imshow('livekit_video', arr)\n            if cv2.waitKey(1) & 0xFF == ord('q'):\n                break\n\n    cv2.destroyAllWindows()", "\n\nasync def main() -> None:\n    loop = asyncio.get_event_loop()\n    future = loop.run_in_executor(None, asyncio.run, room())\n\n    display_frames()\n    await future\n\nif __name__ == \"__main__\":\n    asyncio.run(main())", "\nif __name__ == \"__main__\":\n    asyncio.run(main())\n"]}
{"filename": "livekit/track_publication.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import Optional\n\nfrom livekit._proto import track_pb2 as proto_track\n", "from livekit._proto import track_pb2 as proto_track\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom .track import Track\n\n\nclass TrackPublication():\n    def __init__(self, handle: FfiHandle, info: proto_track.TrackPublicationInfo):\n        self._info = info\n        self.track: Optional[Track] = None\n        self._ffi_handle = handle\n\n    @property\n    def sid(self) -> str:\n        return self._info.sid\n\n    @property\n    def name(self) -> str:\n        return self._info.name\n\n    @property\n    def kind(self) -> proto_track.TrackKind.ValueType:\n        return self._info.kind\n\n    @property\n    def source(self) -> proto_track.TrackSource.ValueType:\n        return self._info.source\n\n    @property\n    def simulcasted(self) -> bool:\n        return self._info.simulcasted\n\n    @property\n    def width(self) -> int:\n        return self._info.width\n\n    @property\n    def height(self) -> int:\n        return self._info.height\n\n    @property\n    def mime_type(self) -> str:\n        return self._info.mime_type\n\n    @property\n    def muted(self) -> bool:\n        return self._info.muted", "\n\nclass LocalTrackPublication(TrackPublication):\n    def __init__(self, handle: FfiHandle, info: proto_track.TrackPublicationInfo):\n        super().__init__(handle, info)\n\n\nclass RemoteTrackPublication(TrackPublication):\n    def __init__(self, handle: FfiHandle, info: proto_track.TrackPublicationInfo):\n        super().__init__(handle, info)\n        self.subscribed = False\n\n    def set_subscribed(self, subscribed: bool):\n        req = proto_ffi.FfiRequest()\n        req.set_subscribed.subscribe = subscribed\n        req.set_subscribed.publication_handle = self._ffi_handle.handle\n        ffi_client.request(req)", ""]}
{"filename": "livekit/video_frame.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport ctypes\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi", "from ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom ._proto import video_frame_pb2 as proto_video_frame\nfrom ._proto.video_frame_pb2 import VideoFormatType, VideoFrameBufferType, VideoRotation\n\n\nclass VideoFrame():\n    def __init__(self, timestamp_us: int, rotation: VideoRotation.ValueType, buffer: 'VideoFrameBuffer') -> None:\n        self.buffer = buffer\n        self.timestamp_us = timestamp_us\n        self.rotation = rotation", "\n\nclass VideoFrameBuffer():\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        self._info = info\n        self._ffi_handle = ffi_handle\n\n    @property\n    def width(self) -> int:\n        return self._info.width\n\n    @property\n    def height(self) -> int:\n        return self._info.height\n\n    @property\n    def type(self) -> VideoFrameBufferType.ValueType:\n        return self._info.buffer_type\n\n    def to_i420(self) -> 'I420Buffer':\n        req = proto_ffi.FfiRequest()\n        req.to_i420.buffer_handle = self._ffi_handle.handle\n\n        resp = ffi_client.request(req)\n\n        new_info = resp.to_i420.buffer\n        ffi_handle = FfiHandle(new_info.handle.id)\n        return I420Buffer(ffi_handle, new_info)\n\n    def to_argb(self, dst: 'ArgbFrame') -> None:\n        req = proto_ffi.FfiRequest()\n        req.to_argb.buffer_handle = self._ffi_handle.handle\n        req.to_argb.dst_ptr = ctypes.addressof(dst.data)\n        req.to_argb.dst_format = dst.format\n        req.to_argb.dst_stride = dst.width * 4\n        req.to_argb.dst_width = dst.width\n        req.to_argb.dst_height = dst.height\n\n        ffi_client.request(req)\n\n    @staticmethod\n    def create(ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> 'VideoFrameBuffer':\n        \"\"\"\n        Create the right class instance from the VideoFrameBufferInfo\n        \"\"\"\n\n        if info.buffer_type == VideoFrameBufferType.NATIVE:\n            return NativeVideoFrameBuffer(ffi_handle, info)\n        elif info.buffer_type == VideoFrameBufferType.I420:\n            return I420Buffer(ffi_handle, info)\n        elif info.buffer_type == VideoFrameBufferType.I420A:\n            return I420ABuffer(ffi_handle, info)\n        elif info.buffer_type == VideoFrameBufferType.I422:\n            return I422Buffer(ffi_handle, info)\n        elif info.buffer_type == VideoFrameBufferType.I444:\n            return I444Buffer(ffi_handle, info)\n        elif info.buffer_type == VideoFrameBufferType.I010:\n            return I010Buffer(ffi_handle, info)\n        elif info.buffer_type == VideoFrameBufferType.NV12:\n            return NV12Buffer(ffi_handle, info)\n        else:\n            raise Exception('Unsupported VideoFrameBufferType')", "\n\nclass NativeVideoFrameBuffer(VideoFrameBuffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n\nclass PlanarYuvBuffer(VideoFrameBuffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n    @property\n    def chroma_width(self) -> int:\n        return self._info.yuv.chroma_width\n\n    @property\n    def chroma_height(self) -> int:\n        return self._info.yuv.chroma_height\n\n    @property\n    def stride_y(self) -> int:\n        return self._info.yuv.stride_y\n\n    @property\n    def stride_u(self) -> int:\n        return self._info.yuv.stride_u\n\n    @property\n    def stride_v(self) -> int:\n        return self._info.yuv.stride_v", "\n\nclass PlanarYuv8Buffer(PlanarYuvBuffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n    @property\n    def data_y(self) -> ctypes.Array[ctypes.c_uint8]:\n        arr = ctypes.cast(self._info.yuv.data_y_ptr, ctypes.POINTER(\n            ctypes.c_uint8 * (self._info.yuv.stride_y * self._info.height))).contents\n        return arr\n\n    @property\n    def data_u(self) -> ctypes.Array[ctypes.c_uint8]:\n        arr = ctypes.cast(self._info.yuv.data_u_ptr, ctypes.POINTER(\n            ctypes.c_uint8 * (self._info.yuv.stride_u * self._info.yuv.chroma_height))).contents\n        return arr\n\n    @property\n    def data_v(self) -> ctypes.Array[ctypes.c_uint8]:\n        arr = ctypes.cast(self._info.yuv.data_v_ptr, ctypes.POINTER(\n            ctypes.c_uint8 * (self._info.yuv.stride_v * self._info.yuv.chroma_height))).contents\n        return arr", "\n\nclass PlanarYuv16Buffer(PlanarYuvBuffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n    @property\n    def data_y(self) -> ctypes.Array[ctypes.c_uint16]:\n        arr = ctypes.cast(self._info.yuv.data_y_ptr, ctypes.POINTER(\n            ctypes.c_uint16 * (self._info.yuv.stride_y // 2 * self._info.height))).contents\n        return arr\n\n    @property\n    def data_u(self) -> ctypes.Array[ctypes.c_uint16]:\n        arr = ctypes.cast(self._info.yuv.data_u_ptr, ctypes.POINTER(\n            ctypes.c_uint16 * (self._info.yuv.stride_u // 2 * self._info.yuv.chroma_height))).contents\n        return arr\n\n    @property\n    def data_v(self) -> ctypes.Array[ctypes.c_uint16]:\n        arr = ctypes.cast(self._info.yuv.data_v_ptr, ctypes.POINTER(\n            ctypes.c_uint16 * (self._info.yuv.stride_v // 2 * self._info.yuv.chroma_height))).contents\n        return arr", "\n\nclass BiplanaraYuv8Buffer(VideoFrameBuffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n    @property\n    def data_y(self) -> ctypes.Array[ctypes.c_uint8]:\n        arr = ctypes.cast(self._info.bi_yuv.data_y_ptr, ctypes.POINTER(\n            ctypes.c_uint8 * (self._info.bi_yuv.stride_y * self._info.height))).contents\n        return arr\n\n    @property\n    def data_uv(self) -> ctypes.Array[ctypes.c_uint8]:\n        arr = ctypes.cast(self._info.bi_yuv.data_uv_ptr, ctypes.POINTER(\n            ctypes.c_uint8 * (self._info.bi_yuv.stride_uv * self._info.bi_yuv.chroma_height))).contents\n        return arr", "\n\nclass I420Buffer(PlanarYuv8Buffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n\nclass I420ABuffer(PlanarYuv8Buffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n    @property\n    def data_a(self) -> ctypes.Array[ctypes.c_uint8]:\n        arr = ctypes.cast(self._info.yuv.data_a_ptr, ctypes.POINTER(\n            ctypes.c_uint8 * (self._info.yuv.stride_a * self._info.height))).contents\n        return arr", "\n\nclass I422Buffer(PlanarYuv8Buffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n\nclass I444Buffer(PlanarYuv8Buffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)", "\n\nclass I010Buffer(PlanarYuv16Buffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)\n\n\nclass NV12Buffer(BiplanaraYuv8Buffer):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_video_frame.VideoFrameBufferInfo) -> None:\n        super().__init__(ffi_handle, info)", "\n\nclass ArgbFrame:\n    \"\"\"\n    Mainly used to simplify the usage of to_argb method\n    So the users don't need to deal with ctypes\n    \"\"\"\n\n    def __init__(self, format: VideoFormatType.ValueType, width: int, height: int) -> None:\n        self._format = format\n        self.width = width\n        self.height = height\n        self.data = (ctypes.c_uint8 * (width * height *\n                     ctypes.sizeof(ctypes.c_uint32)))()  # alloc frame\n\n    def to_i420(self) -> I420Buffer:\n        # TODO(theomonnom): avoid unnecessary buffer allocation\n        req = proto_ffi.FfiRequest()\n        req.to_i420.argb.format = self._format\n        req.to_i420.argb.width = self.width\n        req.to_i420.argb.height = self.height\n        req.to_i420.argb.stride = self.width * 4\n        req.to_i420.argb.ptr = ctypes.addressof(self.data)\n\n        res = ffi_client.request(req)\n        buffer_info = res.to_i420.buffer\n        ffi_handle = FfiHandle(buffer_info.handle.id)\n        return I420Buffer(ffi_handle, buffer_info)\n\n    @property\n    def format(self) -> VideoFormatType.ValueType:\n        return self._format", ""]}
{"filename": "livekit/room.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nimport ctypes\nfrom dataclasses import dataclass\nfrom typing import Optional", "from dataclasses import dataclass\nfrom typing import Optional\n\nfrom pyee.asyncio import EventEmitter\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom ._proto import participant_pb2 as proto_participant\nfrom ._proto import room_pb2 as proto_room\nfrom ._proto.room_pb2 import ConnectionState", "from ._proto import room_pb2 as proto_room\nfrom ._proto.room_pb2 import ConnectionState\nfrom ._proto.track_pb2 import TrackKind\nfrom .participant import LocalParticipant, Participant, RemoteParticipant\nfrom .track import RemoteAudioTrack, RemoteVideoTrack\nfrom .track_publication import RemoteTrackPublication\n\n\n@dataclass\nclass RoomOptions:\n    auto_subscribe: bool = True\n    dynacast: bool = True", "@dataclass\nclass RoomOptions:\n    auto_subscribe: bool = True\n    dynacast: bool = True\n\n\nclass ConnectError(Exception):\n    def __init__(self, message: str):\n        self.message = message\n", "\n\nclass Room(EventEmitter):\n    def __init__(self) -> None:\n        super().__init__()\n        self.participants: dict[str, RemoteParticipant] = {}\n        self.connection_state = ConnectionState.CONN_DISCONNECTED\n        self._ffi_handle: Optional[FfiHandle] = None\n        ffi_client.add_listener('room_event', self._on_room_event)\n\n    def __del__(self):\n        ffi_client.remove_listener('room_event', self._on_room_event)\n\n    @property\n    def sid(self) -> str:\n        return self._info.sid\n\n    @property\n    def name(self) -> str:\n        return self._info.name\n\n    @property\n    def metadata(self) -> str:\n        return self._info.metadata\n\n    def isconnected(self) -> bool:\n        return self._ffi_handle is not None and \\\n            self.connection_state != ConnectionState.CONN_DISCONNECTED\n\n    async def connect(self,\n                      url: str,\n                      token: str,\n                      options: RoomOptions = RoomOptions()) -> None:\n        req = proto_ffi.FfiRequest()\n        req.connect.url = url\n        req.connect.token = token\n\n        # options\n        req.connect.options.auto_subscribe = options.auto_subscribe\n        req.connect.options.dynacast = options.dynacast\n\n        resp = ffi_client.request(req)\n        future: asyncio.Future[proto_room.ConnectCallback] = asyncio.Future()\n\n        @ffi_client.listens_to('connect')\n        def on_connect_callback(cb: proto_room.ConnectCallback):\n            if cb.async_id == resp.connect.async_id:\n                future.set_result(cb)\n                ffi_client.remove_listener('connect', on_connect_callback)\n\n        cb = await future\n        if cb.error:\n            raise ConnectError(cb.error)\n\n        self._close_future: asyncio.Future[None] = asyncio.Future()\n        self._ffi_handle = FfiHandle(cb.room.handle.id)\n        self._info = cb.room\n        self.connection_state = ConnectionState.CONN_CONNECTED\n\n        lp_handle = FfiHandle(cb.local_participant.handle.id)\n        self.local_participant = LocalParticipant(\n            lp_handle, cb.local_participant)\n\n        for pt in cb.participants:\n            rp_handle = FfiHandle(pt.participant.handle.id)\n            rp = self._create_remote_participant(rp_handle, pt.participant)\n\n            # add the initial remote participant tracks\n            for publication_info in pt.publications:\n                pub_handle = FfiHandle(publication_info.handle.id)\n                publication = RemoteTrackPublication(\n                    pub_handle, publication_info)\n                rp.tracks[publication.sid] = publication\n\n    async def disconnect(self) -> None:\n        if not self.isconnected():\n            return\n\n        req = proto_ffi.FfiRequest()\n        req.disconnect.room_handle = self._ffi_handle.handle  # type: ignore\n\n        resp = ffi_client.request(req)\n        future: asyncio.Future[proto_room.DisconnectCallback] = asyncio.Future(\n        )\n\n        @ffi_client.on('disconnect')\n        def on_disconnect_callback(cb: proto_room.DisconnectCallback):\n            if cb.async_id == resp.disconnect.async_id:\n                future.set_result(cb)\n                ffi_client.remove_listener(\n                    'disconnect', on_disconnect_callback)\n\n        await future\n        if not self._close_future.cancelled():\n            self._close_future.set_result(None)\n\n    async def run(self) -> None:\n        await self._close_future\n\n    def _on_room_event(self, event: proto_room.RoomEvent):\n        if self._ffi_handle is None:\n            return\n\n        if event.room_handle != self._ffi_handle.handle:\n            return\n\n        which = event.WhichOneof('message')\n        if which == 'participant_connected':\n            rp_info = event.participant_connected.info\n            ffi_handle = FfiHandle(rp_info.handle.id)\n            rparticipant = self._create_remote_participant(\n                ffi_handle, rp_info)\n            self.emit('participant_connected', rparticipant)\n        elif which == 'participant_disconnected':\n            sid = event.participant_disconnected.participant_sid\n            rparticipant = self.participants.pop(sid)\n            self.emit('participant_disconnected', rparticipant)\n        elif which == 'local_track_published':\n            sid = event.local_track_published.track_sid\n            # publication is created inside LocalParticipant.publish_track\n            # (This event is called after that)\n            lpublication = self.local_participant.tracks[sid]\n            track = lpublication.track\n            self.emit('local_track_published', lpublication, track)\n        elif which == 'local_track_unpublished':\n            sid = event.local_track_unpublished.publication_sid\n            lpublication = self.local_participant.tracks[sid]\n            self.emit('local_track_unpublished', lpublication)\n        elif which == 'track_published':\n            rparticipant = self.participants[event.track_published.participant_sid]\n            ffi_handle = FfiHandle(event.track_published.publication.handle.id)\n            rpublication = RemoteTrackPublication(ffi_handle,\n                                                  event.track_published.publication)\n            rparticipant.tracks[rpublication.sid] = rpublication\n            self.emit('track_published', rpublication, rparticipant)\n        elif which == 'track_unpublished':\n            rparticipant = self.participants[event.track_unpublished.participant_sid]\n            rpublication = rparticipant.tracks.pop(\n                event.track_unpublished.publication_sid)\n            self.emit('track_unpublished', rpublication, rparticipant)\n        elif which == 'track_subscribed':\n            track_info = event.track_subscribed.track\n            rparticipant = self.participants[event.track_subscribed.participant_sid]\n            rpublication = rparticipant.tracks[track_info.sid]\n            ffi_handle = FfiHandle(track_info.handle.id)\n            rpublication.subscribed = True\n            if track_info.kind == TrackKind.KIND_VIDEO:\n                remote_video_track = RemoteVideoTrack(ffi_handle, track_info)\n                rpublication.track = remote_video_track\n                self.emit('track_subscribed',\n                          remote_video_track, rpublication, rparticipant)\n            elif track_info.kind == TrackKind.KIND_AUDIO:\n                remote_audio_track = RemoteAudioTrack(ffi_handle, track_info)\n                rpublication.track = remote_audio_track\n                self.emit('track_subscribed', remote_audio_track,\n                          rpublication, rparticipant)\n        elif which == 'track_unsubscribed':\n            sid = event.track_unsubscribed.participant_sid\n            rparticipant = self.participants[sid]\n            rpublication = rparticipant.tracks[event.track_unsubscribed.track_sid]\n            track = rpublication.track\n            rpublication.track = None\n            rpublication.subscribed = False\n            self.emit('track_unsubscribed', track, rpublication, rparticipant)\n        elif which == 'track_subscription_failed':\n            sid = event.track_subscription_failed.participant_sid\n            rparticipant = self.participants[sid]\n            error = event.track_subscription_failed.error\n            self.emit('track_subscription_failed', rparticipant,\n                      event.track_subscription_failed.track_sid, error)\n        elif which == 'track_muted':\n            sid = event.track_muted.participant_sid\n            participant = self._retrieve_participant(sid)\n            publication = participant.tracks[event.track_muted.track_sid]\n            publication._info.muted = True\n            if publication.track:\n                publication.track._info.muted = True\n\n            self.emit('track_muted', participant, publication)\n        elif which == 'track_unmuted':\n            sid = event.track_unmuted.participant_sid\n            participant = self._retrieve_participant(sid)\n            publication = participant.tracks[event.track_unmuted.track_sid]\n            publication._info.muted = False\n            if publication.track:\n                publication.track._info.muted = False\n\n            self.emit('track_unmuted', participant, publication)\n        elif which == 'active_speakers_changed':\n            speakers: list[Participant] = []\n            for sid in event.active_speakers_changed.participant_sids:\n                speakers.append(self._retrieve_participant(sid))\n\n            self.emit('active_speakers_changed', speakers)\n        elif which == 'connection_quality_changed':\n            sid = event.connection_quality_changed.participant_sid\n            p = self._retrieve_participant(sid)\n\n            self.emit('connection_quality_changed',\n                      p, event.connection_quality_changed.quality)\n        elif which == 'data_received':\n            rparticipant = self.participants[event.data_received.participant_sid]\n            buffer_info = event.data_received.data\n            native_data = ctypes.cast(buffer_info.data_ptr,\n                                      ctypes.POINTER(ctypes.c_byte\n                                                     * buffer_info.data_len)).contents\n            data = bytearray(native_data)\n            FfiHandle(buffer_info.handle.id)\n            self.emit('data_received', data,\n                      event.data_received.kind, rparticipant)\n        elif which == 'connection_state_changed':\n            state = event.connection_state_changed.state\n            self.connection_state = state\n            self.emit('connection_state_changed', state)\n        elif which == 'connected':\n            self.emit('connected')\n        elif which == 'disconnected':\n            self.emit('disconnected')\n        elif which == 'reconnecting':\n            self.emit('reconnecting')\n        elif which == 'reconnected':\n            self.emit('reconnected')\n\n    def _retrieve_participant(self, sid: str) -> Participant:\n        \"\"\" Retrieve a participant by sid, returns the LocalParticipant\n          if sid matches \"\"\"\n        if sid == self.local_participant.sid:\n            return self.local_participant\n        else:\n            return self.participants[sid]\n\n    def _create_remote_participant(self, handle: FfiHandle,\n                                   info: proto_participant.ParticipantInfo) \\\n            -> RemoteParticipant:\n        if info.sid in self.participants:\n            raise Exception('participant already exists')\n\n        participant = RemoteParticipant(handle, info)\n        self.participants[participant.sid] = participant\n        return participant", ""]}
{"filename": "livekit/_ffi_client.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nimport ctypes\nimport platform\nimport threading", "import platform\nimport threading\n\nimport pkg_resources\nfrom pyee.asyncio import EventEmitter\n\nfrom ._proto import ffi_pb2 as proto_ffi\n\nos = platform.system().lower()\narch = platform.machine().lower()", "os = platform.system().lower()\narch = platform.machine().lower()\nlib_path = 'lib/{}/{}'.format(os, arch)\n\nif os == \"windows\":\n    lib_file = 'livekit_ffi.dll'\nelif os == \"darwin\":\n    lib_file = 'liblivekit_ffi.dylib'\nelse:\n    lib_file = 'liblivekit_ffi.so'", "\nlibpath = pkg_resources.resource_filename('livekit', lib_path + '/' + lib_file)\n\nffi_lib = ctypes.CDLL(libpath)\n\n# C function types\nffi_lib.livekit_ffi_request.argtypes = [\n    ctypes.POINTER(ctypes.c_ubyte),\n    ctypes.c_size_t,\n    ctypes.POINTER(ctypes.POINTER(ctypes.c_ubyte)),", "    ctypes.c_size_t,\n    ctypes.POINTER(ctypes.POINTER(ctypes.c_ubyte)),\n    ctypes.POINTER(ctypes.c_size_t)\n]\nffi_lib.livekit_ffi_request.restype = ctypes.c_uint64\n\nffi_lib.livekit_ffi_drop_handle.argtypes = [ctypes.c_uint64]\nffi_lib.livekit_ffi_drop_handle.restype = ctypes.c_bool\n\nINVALID_HANDLE = 0", "\nINVALID_HANDLE = 0\n\n\n@ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.POINTER(ctypes.c_uint8), ctypes.c_size_t)\ndef ffi_event_callback(data_ptr: ctypes.POINTER(ctypes.c_uint8),  # type: ignore\n                       data_len: ctypes.c_size_t) -> None:\n    event_data = bytes(data_ptr[:int(data_len)])\n    event = proto_ffi.FfiEvent()\n    event.ParseFromString(event_data)\n\n    with ffi_client._lock:\n        loop = ffi_client._event_loop\n\n    loop.call_soon_threadsafe(dispatch_event, event)", "\n\ndef dispatch_event(event: proto_ffi.FfiEvent) -> None:\n    which = str(event.WhichOneof('message'))\n    ffi_client.emit(which, getattr(event, which))\n\n\nclass FfiClient(EventEmitter):\n    def __init__(self) -> None:\n        super().__init__()\n        self._lock = threading.Lock()\n\n        req = proto_ffi.FfiRequest()\n        cb_callback = int(ctypes.cast(\n            ffi_event_callback, ctypes.c_void_p).value)  # type: ignore\n        req.initialize.event_callback_ptr = cb_callback\n        self.request(req)\n\n    def set_event_loop(self, loop: asyncio.AbstractEventLoop) -> None:\n        with self._lock:\n            self._event_loop = loop\n\n    def request(self, req: proto_ffi.FfiRequest) -> proto_ffi.FfiResponse:\n        proto_data = req.SerializeToString()\n        proto_len = len(proto_data)\n        data = (ctypes.c_ubyte * proto_len)(*proto_data)\n\n        resp_ptr = ctypes.POINTER(ctypes.c_ubyte)()\n        resp_len = ctypes.c_size_t()\n        handle = ffi_lib.livekit_ffi_request(\n            data, proto_len, ctypes.byref(resp_ptr), ctypes.byref(resp_len))\n\n        resp_data = bytes(resp_ptr[:resp_len.value])\n        resp = proto_ffi.FfiResponse()\n        resp.ParseFromString(resp_data)\n\n        FfiHandle(handle)\n        return resp", "\n\nclass FfiHandle:\n    def __init__(self, handle: int) -> None:\n        self.handle = handle\n\n    def __del__(self):\n        if self.handle != INVALID_HANDLE:\n            assert ffi_lib.livekit_ffi_drop_handle(\n                ctypes.c_uint64(self.handle))", "\n\nffi_client = FfiClient()\nffi_client.set_event_loop(asyncio.get_event_loop())\n"]}
{"filename": "livekit/audio_source.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import audio_frame_pb2 as proto_audio_frame\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom .audio_frame import AudioFrame", "from ._proto import ffi_pb2 as proto_ffi\nfrom .audio_frame import AudioFrame\n\n\nclass AudioSource:\n    def __init__(self) -> None:\n        req = proto_ffi.FfiRequest()\n        req.new_audio_source.type = proto_audio_frame.AudioSourceType.AUDIO_SOURCE_NATIVE\n\n        resp = ffi_client.request(req)\n        self._info = resp.new_audio_source.source\n        self._ffi_handle = FfiHandle(self._info.handle.id)\n\n    def capture_frame(self, frame: AudioFrame) -> None:\n        req = proto_ffi.FfiRequest()\n\n        req.capture_audio_frame.source_handle = self._ffi_handle.handle\n        req.capture_audio_frame.buffer_handle = frame._ffi_handle.handle\n        ffi_client.request(req)", ""]}
{"filename": "livekit/__init__.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"LiveKit Client SDK\n\"\"\"\n\n# flake8: noqa", "\n# flake8: noqa\nfrom ._proto.room_pb2 import (\n    ConnectionQuality,\n    ConnectionState,\n    DataPacketKind,\n    TrackPublishOptions,\n)\nfrom ._proto.track_pb2 import StreamState, TrackKind, TrackSource\nfrom ._proto.video_frame_pb2 import VideoFormatType, VideoFrameBufferType, VideoRotation", "from ._proto.track_pb2 import StreamState, TrackKind, TrackSource\nfrom ._proto.video_frame_pb2 import VideoFormatType, VideoFrameBufferType, VideoRotation\nfrom .audio_frame import AudioFrame\nfrom .audio_source import AudioSource\nfrom .audio_stream import AudioStream\nfrom .participant import LocalParticipant, Participant, RemoteParticipant\nfrom .room import ConnectError, Room, RoomOptions\nfrom .track import (\n    LocalAudioTrack,\n    LocalVideoTrack,", "    LocalAudioTrack,\n    LocalVideoTrack,\n    RemoteAudioTrack,\n    RemoteVideoTrack,\n    Track,\n)\nfrom .track_publication import (\n    LocalTrackPublication,\n    RemoteTrackPublication,\n    TrackPublication,", "    RemoteTrackPublication,\n    TrackPublication,\n)\nfrom .video_frame import (\n    ArgbFrame,\n    I010Buffer,\n    I420ABuffer,\n    I420Buffer,\n    I422Buffer,\n    NativeVideoFrameBuffer,", "    I422Buffer,\n    NativeVideoFrameBuffer,\n    NV12Buffer,\n    PlanarYuv8Buffer,\n    PlanarYuv16Buffer,\n    PlanarYuvBuffer,\n    VideoFrame,\n    VideoFrameBuffer,\n)\nfrom .video_source import VideoSource", ")\nfrom .video_source import VideoSource\nfrom .video_stream import VideoStream\n\n__version__ = \"0.2.0\"\n"]}
{"filename": "livekit/audio_stream.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom weakref import WeakValueDictionary\n\nfrom pyee.asyncio import EventEmitter\n", "from pyee.asyncio import EventEmitter\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import audio_frame_pb2 as proto_audio_frame\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom .audio_frame import AudioFrame\nfrom .track import Track\n\n\nclass AudioStream(EventEmitter):\n    _streams: WeakValueDictionary[int, 'AudioStream'] = WeakValueDictionary()\n    _initialized = False\n\n    @classmethod\n    def initalize(cls) -> None:\n        if cls._initialized:\n            return\n\n        cls._initialized = True\n        # See VideoStream for the reason we don't use the instance method for the listener\n        ffi_client.add_listener('audio_stream_event',\n                                cls._on_audio_stream_event)\n\n    @classmethod\n    def _on_audio_stream_event(cls, event: proto_audio_frame.AudioStreamEvent) -> None:\n        stream = cls._streams.get(event.source_handle)\n        if stream is None:\n            return\n\n        which = event.WhichOneof('message')\n        if which == 'frame_received':\n            frame_info = event.frame_received.frame\n            ffi_handle = FfiHandle(frame_info.handle.id)\n            frame = AudioFrame(frame_info, ffi_handle)\n            stream._on_frame_received(frame)\n\n    def __init__(self, track: Track) -> None:\n        super().__init__()\n        self.__class__.initalize()\n\n        req = proto_ffi.FfiRequest()\n        new_audio_stream = req.new_audio_stream\n        new_audio_stream.track_handle = track._ffi_handle.handle\n        new_audio_stream.type = proto_audio_frame.AudioStreamType.AUDIO_STREAM_NATIVE\n\n        resp = ffi_client.request(req)\n        stream_info = resp.new_audio_stream.stream\n\n        self._streams[stream_info.handle.id] = self\n        self._ffi_handle = FfiHandle(stream_info.handle.id)\n        self._info = stream_info\n        self._track = track\n\n    def _on_frame_received(self, frame: AudioFrame) -> None:\n        self.emit('frame_received', frame)\n\n    def __del__(self):\n        self._streams.pop(self._ffi_handle.handle, None)", "\nclass AudioStream(EventEmitter):\n    _streams: WeakValueDictionary[int, 'AudioStream'] = WeakValueDictionary()\n    _initialized = False\n\n    @classmethod\n    def initalize(cls) -> None:\n        if cls._initialized:\n            return\n\n        cls._initialized = True\n        # See VideoStream for the reason we don't use the instance method for the listener\n        ffi_client.add_listener('audio_stream_event',\n                                cls._on_audio_stream_event)\n\n    @classmethod\n    def _on_audio_stream_event(cls, event: proto_audio_frame.AudioStreamEvent) -> None:\n        stream = cls._streams.get(event.source_handle)\n        if stream is None:\n            return\n\n        which = event.WhichOneof('message')\n        if which == 'frame_received':\n            frame_info = event.frame_received.frame\n            ffi_handle = FfiHandle(frame_info.handle.id)\n            frame = AudioFrame(frame_info, ffi_handle)\n            stream._on_frame_received(frame)\n\n    def __init__(self, track: Track) -> None:\n        super().__init__()\n        self.__class__.initalize()\n\n        req = proto_ffi.FfiRequest()\n        new_audio_stream = req.new_audio_stream\n        new_audio_stream.track_handle = track._ffi_handle.handle\n        new_audio_stream.type = proto_audio_frame.AudioStreamType.AUDIO_STREAM_NATIVE\n\n        resp = ffi_client.request(req)\n        stream_info = resp.new_audio_stream.stream\n\n        self._streams[stream_info.handle.id] = self\n        self._ffi_handle = FfiHandle(stream_info.handle.id)\n        self._info = stream_info\n        self._track = track\n\n    def _on_frame_received(self, frame: AudioFrame) -> None:\n        self.emit('frame_received', frame)\n\n    def __del__(self):\n        self._streams.pop(self._ffi_handle.handle, None)", ""]}
{"filename": "livekit/audio_frame.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport ctypes\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import audio_frame_pb2 as proto_audio", "from ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import audio_frame_pb2 as proto_audio\nfrom ._proto import ffi_pb2 as proto_ffi\n\n\nclass AudioFrame():\n    def __init__(self, info: proto_audio.AudioFrameBufferInfo, ffi_handle: FfiHandle) -> None:\n        self._info = info\n        self._ffi_handle = ffi_handle\n\n        data_len = self.num_channels * self.samples_per_channel\n        self.data = ctypes.cast(info.data_ptr,\n                                ctypes.POINTER(ctypes.c_int16 * data_len)).contents\n\n    @staticmethod\n    def create(sample_rate: int, num_channels: int, samples_per_channel: int) -> 'AudioFrame':\n        # TODO(theomonnom): There should be no problem to directly send audio date from a Python created ctypes buffer\n        req = proto_ffi.FfiRequest()\n        req.alloc_audio_buffer.sample_rate = sample_rate\n        req.alloc_audio_buffer.num_channels = num_channels\n        req.alloc_audio_buffer.samples_per_channel = samples_per_channel\n\n        resp = ffi_client.request(req)\n\n        info = resp.alloc_audio_buffer.buffer\n        ffi_handle = FfiHandle(info.handle.id)\n\n        return AudioFrame(info, ffi_handle)\n\n    def remix_and_resample(self, sample_rate: int, num_channels: int) -> 'AudioFrame':\n        \"\"\" Resample the audio frame to the given sample rate and number of channels.\"\"\"\n\n        req = proto_ffi.FfiRequest()\n        req.new_audio_resampler.CopyFrom(\n            proto_audio.NewAudioResamplerRequest())\n\n        resp = ffi_client.request(req)\n        resampler_handle = FfiHandle(\n            resp.new_audio_resampler.resampler.handle.id)\n\n        resample_req = proto_ffi.FfiRequest()\n        resample_req.remix_and_resample.resampler_handle = resampler_handle.handle\n        resample_req.remix_and_resample.buffer_handle = self._ffi_handle.handle\n        resample_req.remix_and_resample.sample_rate = sample_rate\n        resample_req.remix_and_resample.num_channels = num_channels\n\n        resp = ffi_client.request(resample_req)\n        info = resp.remix_and_resample.buffer\n        ffi_handle = FfiHandle(info.handle.id)\n        return AudioFrame(info, ffi_handle)\n\n    @property\n    def sample_rate(self) -> int:\n        return self._info.sample_rate\n\n    @property\n    def num_channels(self) -> int:\n        return self._info.num_channels\n\n    @property\n    def samples_per_channel(self) -> int:\n        return self._info.samples_per_channel", ""]}
{"filename": "livekit/track.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import TYPE_CHECKING\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi", "from ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom ._proto import track_pb2 as proto_track\n\nif TYPE_CHECKING:\n    from .audio_source import AudioSource\n    from .video_source import VideoSource\n\n\nclass Track():\n    def __init__(self, handle: FfiHandle, info: proto_track.TrackInfo):\n        self._info = info\n        self._ffi_handle = handle\n\n    @property\n    def sid(self) -> str:\n        return self._info.sid\n\n    @property\n    def name(self) -> str:\n        return self._info.name\n\n    @property\n    def kind(self) -> proto_track.TrackKind.ValueType:\n        return self._info.kind\n\n    @property\n    def stream_state(self) -> proto_track.StreamState.ValueType:\n        return self._info.stream_state\n\n    @property\n    def muted(self) -> bool:\n        return self._info.muted\n\n    def update_info(self, info: proto_track.TrackInfo):\n        self._info = info", "\nclass Track():\n    def __init__(self, handle: FfiHandle, info: proto_track.TrackInfo):\n        self._info = info\n        self._ffi_handle = handle\n\n    @property\n    def sid(self) -> str:\n        return self._info.sid\n\n    @property\n    def name(self) -> str:\n        return self._info.name\n\n    @property\n    def kind(self) -> proto_track.TrackKind.ValueType:\n        return self._info.kind\n\n    @property\n    def stream_state(self) -> proto_track.StreamState.ValueType:\n        return self._info.stream_state\n\n    @property\n    def muted(self) -> bool:\n        return self._info.muted\n\n    def update_info(self, info: proto_track.TrackInfo):\n        self._info = info", "\n\nclass LocalAudioTrack(Track):\n    def __init__(self, handle: FfiHandle, info: proto_track.TrackInfo):\n        super().__init__(handle, info)\n\n    @staticmethod\n    def create_audio_track(name: str, source: 'AudioSource') -> 'LocalAudioTrack':\n        req = proto_ffi.FfiRequest()\n        req.create_audio_track.name = name\n        req.create_audio_track.source_handle = source._ffi_handle.handle\n\n        resp = ffi_client.request(req)\n        track_info = resp.create_audio_track.track\n        ffi_handle = FfiHandle(track_info.handle.id)\n        return LocalAudioTrack(ffi_handle, track_info)", "\n\nclass LocalVideoTrack(Track):\n    def __init__(self, handle: FfiHandle, info: proto_track.TrackInfo):\n        super().__init__(handle, info)\n\n    @staticmethod\n    def create_video_track(name: str, source: 'VideoSource') -> 'LocalVideoTrack':\n        req = proto_ffi.FfiRequest()\n        req.create_video_track.name = name\n        req.create_video_track.source_handle = source._ffi_handle.handle\n\n        resp = ffi_client.request(req)\n        track_info = resp.create_video_track.track\n        ffi_handle = FfiHandle(track_info.handle.id)\n        return LocalVideoTrack(ffi_handle, track_info)", "\n\nclass RemoteAudioTrack(Track):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_track.TrackInfo):\n        super().__init__(ffi_handle, info)\n\n\nclass RemoteVideoTrack(Track):\n    def __init__(self, ffi_handle: FfiHandle, info: proto_track.TrackInfo):\n        super().__init__(ffi_handle, info)", ""]}
{"filename": "livekit/video_source.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom ._proto import video_frame_pb2 as proto_video_frame\nfrom .video_frame import VideoFrame", "from ._proto import video_frame_pb2 as proto_video_frame\nfrom .video_frame import VideoFrame\n\n\nclass VideoSource:\n    def __init__(self) -> None:\n        req = proto_ffi.FfiRequest()\n        req.new_video_source.type = proto_video_frame.VideoSourceType.VIDEO_SOURCE_NATIVE\n\n        resp = ffi_client.request(req)\n        self._info = resp.new_video_source.source\n        self._ffi_handle = FfiHandle(self._info.handle.id)\n\n    def capture_frame(self, frame: VideoFrame) -> None:\n        req = proto_ffi.FfiRequest()\n        req.capture_video_frame.source_handle = self._ffi_handle.handle\n        req.capture_video_frame.buffer_handle = frame.buffer._ffi_handle.handle\n        req.capture_video_frame.frame.rotation = frame.rotation\n        req.capture_video_frame.frame.timestamp_us = frame.timestamp_us\n        ffi_client.request(req)", ""]}
{"filename": "livekit/video_stream.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom weakref import WeakValueDictionary\n\nfrom pyee.asyncio import EventEmitter\n", "from pyee.asyncio import EventEmitter\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom ._proto import video_frame_pb2 as proto_video_frame\nfrom .track import Track\nfrom .video_frame import VideoFrame, VideoFrameBuffer\n\n\nclass VideoStream(EventEmitter):\n    _streams: WeakValueDictionary[int, 'VideoStream'] = WeakValueDictionary()\n    _initialized = False\n\n    @classmethod\n    def initalize(cls) -> None:\n        if cls._initialized:\n            return\n\n        cls._initialized = True\n\n        # Not using the instance method the listener because it keeps a strong reference\n        # to the instance.\n        # And we rely on __del__ to determine when the instance isn't used\n        ffi_client.add_listener('video_stream_event',\n                                cls._on_video_stream_event)\n\n    @classmethod\n    def _on_video_stream_event(cls, event: proto_video_frame.VideoStreamEvent) -> None:\n        stream = cls._streams.get(event.stream_handle)\n        if stream is None:\n            return\n\n        which = event.WhichOneof('message')\n        if which == 'frame_received':\n            frame_info = event.frame_received.frame\n            buffer_info = event.frame_received.buffer\n            ffi_handle = FfiHandle(buffer_info.handle.id)\n\n            frame = VideoFrame(frame_info.timestamp_us, frame_info.rotation,\n                               VideoFrameBuffer.create(ffi_handle, buffer_info))\n            stream._on_frame_received(frame)\n\n    def __init__(self, track: Track) -> None:\n        super().__init__()\n        self.__class__.initalize()\n\n        req = proto_ffi.FfiRequest()\n        new_video_stream = req.new_video_stream\n        new_video_stream.track_handle = track._ffi_handle.handle\n        new_video_stream.type = proto_video_frame.VideoStreamType.VIDEO_STREAM_NATIVE\n\n        resp = ffi_client.request(req)\n        stream_info = resp.new_video_stream.stream\n\n        self._streams[stream_info.handle.id] = self\n        self._ffi_handle = FfiHandle(stream_info.handle.id)\n        self._info = stream_info\n        self._track = track\n\n    def _on_frame_received(self, frame: VideoFrame) -> None:\n        self.emit('frame_received', frame)\n\n    def __del__(self) -> None:\n        self._streams.pop(self._ffi_handle.handle, None)", "\nclass VideoStream(EventEmitter):\n    _streams: WeakValueDictionary[int, 'VideoStream'] = WeakValueDictionary()\n    _initialized = False\n\n    @classmethod\n    def initalize(cls) -> None:\n        if cls._initialized:\n            return\n\n        cls._initialized = True\n\n        # Not using the instance method the listener because it keeps a strong reference\n        # to the instance.\n        # And we rely on __del__ to determine when the instance isn't used\n        ffi_client.add_listener('video_stream_event',\n                                cls._on_video_stream_event)\n\n    @classmethod\n    def _on_video_stream_event(cls, event: proto_video_frame.VideoStreamEvent) -> None:\n        stream = cls._streams.get(event.stream_handle)\n        if stream is None:\n            return\n\n        which = event.WhichOneof('message')\n        if which == 'frame_received':\n            frame_info = event.frame_received.frame\n            buffer_info = event.frame_received.buffer\n            ffi_handle = FfiHandle(buffer_info.handle.id)\n\n            frame = VideoFrame(frame_info.timestamp_us, frame_info.rotation,\n                               VideoFrameBuffer.create(ffi_handle, buffer_info))\n            stream._on_frame_received(frame)\n\n    def __init__(self, track: Track) -> None:\n        super().__init__()\n        self.__class__.initalize()\n\n        req = proto_ffi.FfiRequest()\n        new_video_stream = req.new_video_stream\n        new_video_stream.track_handle = track._ffi_handle.handle\n        new_video_stream.type = proto_video_frame.VideoStreamType.VIDEO_STREAM_NATIVE\n\n        resp = ffi_client.request(req)\n        stream_info = resp.new_video_stream.stream\n\n        self._streams[stream_info.handle.id] = self\n        self._ffi_handle = FfiHandle(stream_info.handle.id)\n        self._info = stream_info\n        self._track = track\n\n    def _on_frame_received(self, frame: VideoFrame) -> None:\n        self.emit('frame_received', frame)\n\n    def __del__(self) -> None:\n        self._streams.pop(self._ffi_handle.handle, None)", ""]}
{"filename": "livekit/participant.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport asyncio\nimport ctypes\nfrom typing import List, Optional, Union\n", "from typing import List, Optional, Union\n\nfrom ._ffi_client import FfiHandle, ffi_client\nfrom ._proto import ffi_pb2 as proto_ffi\nfrom ._proto import participant_pb2 as proto_participant\nfrom ._proto import room_pb2 as proto_room\nfrom ._proto.room_pb2 import DataPacketKind, TrackPublishOptions\nfrom .track import LocalAudioTrack, LocalVideoTrack, Track\nfrom .track_publication import (\n    LocalTrackPublication,", "from .track_publication import (\n    LocalTrackPublication,\n    RemoteTrackPublication,\n    TrackPublication,\n)\n\n\nclass PublishTrackError(Exception):\n    def __init__(self, message: str) -> None:\n        self.message = message", "\n\nclass UnpublishTrackError(Exception):\n    def __init__(self, message: str) -> None:\n        self.message = message\n\n\nclass PublishDataError(Exception):\n    def __init__(self, message: str) -> None:\n        self.message = message", "\n\nclass Participant():\n    def __init__(self, handle: FfiHandle, info: proto_participant.ParticipantInfo) \\\n            -> None:\n        self._info = info\n        self._ffi_handle = handle\n        self.tracks: dict[str, TrackPublication] = {}\n\n    @property\n    def sid(self) -> str:\n        return self._info.sid\n\n    @property\n    def name(self) -> str:\n        return self._info.name\n\n    @property\n    def identity(self) -> str:\n        return self._info.identity\n\n    @property\n    def metadata(self) -> str:\n        return self._info.metadata", "\n\nclass LocalParticipant(Participant):\n    def __init__(self, handle: FfiHandle, info: proto_participant.ParticipantInfo) \\\n            -> None:\n        super().__init__(handle, info)\n        self.tracks: dict[str, LocalTrackPublication] = {}  # type: ignore\n\n    async def publish_data(self,\n                           payload: Union[bytes, str],\n                           kind: DataPacketKind.ValueType = DataPacketKind.KIND_RELIABLE,\n                           destination_sids: Optional[Union[List[str], List['RemoteParticipant']]] = None) -> None:\n\n        if isinstance(payload, str):\n            payload = payload.encode('utf-8')\n\n        data_len = len(payload)\n\n        cdata = (ctypes.c_byte * data_len)(*payload)\n\n        req = proto_ffi.FfiRequest()\n        req.publish_data.local_participant_handle = self._ffi_handle.handle\n        req.publish_data.data_ptr = ctypes.addressof(cdata)\n        req.publish_data.data_len = data_len\n        req.publish_data.kind = kind\n\n        if destination_sids is not None:\n            sids = []\n            for p in destination_sids:\n                if isinstance(p, RemoteParticipant):\n                    sids.append(p.sid)\n                else:\n                    sids.append(p)\n\n            req.publish_data.destination_sids.extend(sids)\n\n        resp = ffi_client.request(req)\n        future: asyncio.Future[proto_room.PublishDataCallback] = asyncio.Future(\n        )\n\n        @ffi_client.on('publish_data')\n        def on_publish_callback(cb: proto_room.PublishDataCallback):\n            if cb.async_id == resp.publish_data.async_id:\n                future.set_result(cb)\n                ffi_client.remove_listener(\n                    'publish_data', on_publish_callback)\n\n        cb = await future\n        if cb.error:\n            raise PublishDataError(cb.error)\n\n    async def publish_track(self, track: Track, options: TrackPublishOptions) \\\n            -> TrackPublication:\n        if not isinstance(track, LocalAudioTrack) \\\n                and not isinstance(track, LocalVideoTrack):\n            raise Exception('cannot publish a remote track')\n\n        req = proto_ffi.FfiRequest()\n        req.publish_track.track_handle = track._ffi_handle.handle\n        req.publish_track.local_participant_handle = self._ffi_handle.handle\n        req.publish_track.options.CopyFrom(options)\n\n        resp = ffi_client.request(req)\n\n        future: asyncio.Future[proto_room.PublishTrackCallback] = asyncio.Future(\n        )\n\n        @ffi_client.on('publish_track')\n        def on_publish_callback(cb: proto_room.PublishTrackCallback):\n            if cb.async_id == resp.publish_track.async_id:\n                future.set_result(cb)\n                ffi_client.remove_listener(\n                    'publish_track', on_publish_callback)\n\n        cb = await future\n\n        if cb.error:\n            raise PublishTrackError(cb.error)\n\n        pub_info = cb.publication\n        pub_handle = FfiHandle(pub_info.handle.id)\n        track_publication = LocalTrackPublication(pub_handle, pub_info)\n        track_publication.track = track\n        self.tracks[track_publication.sid] = track_publication\n        return track_publication\n\n    async def unpublish_track(self, track_sid: str) -> None:\n        req = proto_ffi.FfiRequest()\n        req.unpublish_track.local_participant_handle = self._ffi_handle.handle\n        req.unpublish_track.track_sid = track_sid\n\n        resp = ffi_client.request(req)\n\n        future: asyncio.Future[proto_room.UnpublishTrackCallback] = asyncio.Future(\n        )\n\n        @ffi_client.on('unpublish_track')\n        def on_unpublish_callback(cb: proto_room.UnpublishTrackCallback):\n            if cb.async_id == resp.unpublish_track.async_id:\n                future.set_result(cb)\n                ffi_client.remove_listener(\n                    'unpublish_track', on_unpublish_callback)\n\n        cb = await future\n        if cb.error:\n            raise UnpublishTrackError(cb.error)\n\n        publication = self.tracks.pop(track_sid)\n        publication.track = None", "\n\nclass RemoteParticipant(Participant):\n    def __init__(self, handle: FfiHandle, info: proto_participant.ParticipantInfo) \\\n            -> None:\n        super().__init__(handle, info)\n        self.tracks: dict[str, RemoteTrackPublication] = {}  # type: ignore\n"]}
{"filename": "livekit/_proto/ffi_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: ffi.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom . import track_pb2 as track__pb2\nfrom . import room_pb2 as room__pb2\nfrom . import video_frame_pb2 as video__frame__pb2\nfrom . import audio_frame_pb2 as audio__frame__pb2\n", "from . import audio_frame_pb2 as audio__frame__pb2\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\tffi.proto\\x12\\rlivekit.proto\\x1a\\x0btrack.proto\\x1a\\nroom.proto\\x1a\\x11video_frame.proto\\x1a\\x11\\x61udio_frame.proto\\\"\\x83\\x0b\\n\\nFfiRequest\\x12\\x36\\n\\ninitialize\\x18\\x01 \\x01(\\x0b\\x32 .livekit.proto.InitializeRequestH\\x00\\x12\\x30\\n\\x07\\x64ispose\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.DisposeRequestH\\x00\\x12\\x30\\n\\x07\\x63onnect\\x18\\x03 \\x01(\\x0b\\x32\\x1d.livekit.proto.ConnectRequestH\\x00\\x12\\x36\\n\\ndisconnect\\x18\\x04 \\x01(\\x0b\\x32 .livekit.proto.DisconnectRequestH\\x00\\x12;\\n\\rpublish_track\\x18\\x05 \\x01(\\x0b\\x32\\\".livekit.proto.PublishTrackRequestH\\x00\\x12?\\n\\x0funpublish_track\\x18\\x06 \\x01(\\x0b\\x32$.livekit.proto.UnpublishTrackRequestH\\x00\\x12\\x39\\n\\x0cpublish_data\\x18\\x07 \\x01(\\x0b\\x32!.livekit.proto.PublishDataRequestH\\x00\\x12=\\n\\x0eset_subscribed\\x18\\x08 \\x01(\\x0b\\x32#.livekit.proto.SetSubscribedRequestH\\x00\\x12\\x44\\n\\x12\\x63reate_video_track\\x18\\t \\x01(\\x0b\\x32&.livekit.proto.CreateVideoTrackRequestH\\x00\\x12\\x44\\n\\x12\\x63reate_audio_track\\x18\\n \\x01(\\x0b\\x32&.livekit.proto.CreateAudioTrackRequestH\\x00\\x12\\x44\\n\\x12\\x61lloc_video_buffer\\x18\\x0b \\x01(\\x0b\\x32&.livekit.proto.AllocVideoBufferRequestH\\x00\\x12@\\n\\x10new_video_stream\\x18\\x0c \\x01(\\x0b\\x32$.livekit.proto.NewVideoStreamRequestH\\x00\\x12@\\n\\x10new_video_source\\x18\\r \\x01(\\x0b\\x32$.livekit.proto.NewVideoSourceRequestH\\x00\\x12\\x46\\n\\x13\\x63\\x61pture_video_frame\\x18\\x0e \\x01(\\x0b\\x32\\'.livekit.proto.CaptureVideoFrameRequestH\\x00\\x12/\\n\\x07to_i420\\x18\\x0f \\x01(\\x0b\\x32\\x1c.livekit.proto.ToI420RequestH\\x00\\x12/\\n\\x07to_argb\\x18\\x10 \\x01(\\x0b\\x32\\x1c.livekit.proto.ToArgbRequestH\\x00\\x12\\x44\\n\\x12\\x61lloc_audio_buffer\\x18\\x11 \\x01(\\x0b\\x32&.livekit.proto.AllocAudioBufferRequestH\\x00\\x12@\\n\\x10new_audio_stream\\x18\\x12 \\x01(\\x0b\\x32$.livekit.proto.NewAudioStreamRequestH\\x00\\x12@\\n\\x10new_audio_source\\x18\\x13 \\x01(\\x0b\\x32$.livekit.proto.NewAudioSourceRequestH\\x00\\x12\\x46\\n\\x13\\x63\\x61pture_audio_frame\\x18\\x14 \\x01(\\x0b\\x32\\'.livekit.proto.CaptureAudioFrameRequestH\\x00\\x12\\x46\\n\\x13new_audio_resampler\\x18\\x15 \\x01(\\x0b\\x32\\'.livekit.proto.NewAudioResamplerRequestH\\x00\\x12\\x44\\n\\x12remix_and_resample\\x18\\x16 \\x01(\\x0b\\x32&.livekit.proto.RemixAndResampleRequestH\\x00\\x42\\t\\n\\x07message\\\"\\x9a\\x0b\\n\\x0b\\x46\\x66iResponse\\x12\\x37\\n\\ninitialize\\x18\\x01 \\x01(\\x0b\\x32!.livekit.proto.InitializeResponseH\\x00\\x12\\x31\\n\\x07\\x64ispose\\x18\\x02 \\x01(\\x0b\\x32\\x1e.livekit.proto.DisposeResponseH\\x00\\x12\\x31\\n\\x07\\x63onnect\\x18\\x03 \\x01(\\x0b\\x32\\x1e.livekit.proto.ConnectResponseH\\x00\\x12\\x37\\n\\ndisconnect\\x18\\x04 \\x01(\\x0b\\x32!.livekit.proto.DisconnectResponseH\\x00\\x12<\\n\\rpublish_track\\x18\\x05 \\x01(\\x0b\\x32#.livekit.proto.PublishTrackResponseH\\x00\\x12@\\n\\x0funpublish_track\\x18\\x06 \\x01(\\x0b\\x32%.livekit.proto.UnpublishTrackResponseH\\x00\\x12:\\n\\x0cpublish_data\\x18\\x07 \\x01(\\x0b\\x32\\\".livekit.proto.PublishDataResponseH\\x00\\x12>\\n\\x0eset_subscribed\\x18\\x08 \\x01(\\x0b\\x32$.livekit.proto.SetSubscribedResponseH\\x00\\x12\\x45\\n\\x12\\x63reate_video_track\\x18\\t \\x01(\\x0b\\x32\\'.livekit.proto.CreateVideoTrackResponseH\\x00\\x12\\x45\\n\\x12\\x63reate_audio_track\\x18\\n \\x01(\\x0b\\x32\\'.livekit.proto.CreateAudioTrackResponseH\\x00\\x12\\x45\\n\\x12\\x61lloc_video_buffer\\x18\\x0b \\x01(\\x0b\\x32\\'.livekit.proto.AllocVideoBufferResponseH\\x00\\x12\\x41\\n\\x10new_video_stream\\x18\\x0c \\x01(\\x0b\\x32%.livekit.proto.NewVideoStreamResponseH\\x00\\x12\\x41\\n\\x10new_video_source\\x18\\r \\x01(\\x0b\\x32%.livekit.proto.NewVideoSourceResponseH\\x00\\x12G\\n\\x13\\x63\\x61pture_video_frame\\x18\\x0e \\x01(\\x0b\\x32(.livekit.proto.CaptureVideoFrameResponseH\\x00\\x12\\x30\\n\\x07to_i420\\x18\\x0f \\x01(\\x0b\\x32\\x1d.livekit.proto.ToI420ResponseH\\x00\\x12\\x30\\n\\x07to_argb\\x18\\x10 \\x01(\\x0b\\x32\\x1d.livekit.proto.ToArgbResponseH\\x00\\x12\\x45\\n\\x12\\x61lloc_audio_buffer\\x18\\x11 \\x01(\\x0b\\x32\\'.livekit.proto.AllocAudioBufferResponseH\\x00\\x12\\x41\\n\\x10new_audio_stream\\x18\\x12 \\x01(\\x0b\\x32%.livekit.proto.NewAudioStreamResponseH\\x00\\x12\\x41\\n\\x10new_audio_source\\x18\\x13 \\x01(\\x0b\\x32%.livekit.proto.NewAudioSourceResponseH\\x00\\x12G\\n\\x13\\x63\\x61pture_audio_frame\\x18\\x14 \\x01(\\x0b\\x32(.livekit.proto.CaptureAudioFrameResponseH\\x00\\x12G\\n\\x13new_audio_resampler\\x18\\x15 \\x01(\\x0b\\x32(.livekit.proto.NewAudioResamplerResponseH\\x00\\x12\\x45\\n\\x12remix_and_resample\\x18\\x16 \\x01(\\x0b\\x32\\'.livekit.proto.RemixAndResampleResponseH\\x00\\x42\\t\\n\\x07message\\\"\\xd0\\x04\\n\\x08\\x46\\x66iEvent\\x12.\\n\\nroom_event\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.RoomEventH\\x00\\x12\\x30\\n\\x0btrack_event\\x18\\x02 \\x01(\\x0b\\x32\\x19.livekit.proto.TrackEventH\\x00\\x12=\\n\\x12video_stream_event\\x18\\x03 \\x01(\\x0b\\x32\\x1f.livekit.proto.VideoStreamEventH\\x00\\x12=\\n\\x12\\x61udio_stream_event\\x18\\x04 \\x01(\\x0b\\x32\\x1f.livekit.proto.AudioStreamEventH\\x00\\x12\\x31\\n\\x07\\x63onnect\\x18\\x05 \\x01(\\x0b\\x32\\x1e.livekit.proto.ConnectCallbackH\\x00\\x12\\x37\\n\\ndisconnect\\x18\\x06 \\x01(\\x0b\\x32!.livekit.proto.DisconnectCallbackH\\x00\\x12\\x31\\n\\x07\\x64ispose\\x18\\x07 \\x01(\\x0b\\x32\\x1e.livekit.proto.DisposeCallbackH\\x00\\x12<\\n\\rpublish_track\\x18\\x08 \\x01(\\x0b\\x32#.livekit.proto.PublishTrackCallbackH\\x00\\x12@\\n\\x0funpublish_track\\x18\\t \\x01(\\x0b\\x32%.livekit.proto.UnpublishTrackCallbackH\\x00\\x12:\\n\\x0cpublish_data\\x18\\n \\x01(\\x0b\\x32\\\".livekit.proto.PublishDataCallbackH\\x00\\x42\\t\\n\\x07message\\\"/\\n\\x11InitializeRequest\\x12\\x1a\\n\\x12\\x65vent_callback_ptr\\x18\\x01 \\x01(\\x04\\\"\\x14\\n\\x12InitializeResponse\\\"\\x1f\\n\\x0e\\x44isposeRequest\\x12\\r\\n\\x05\\x61sync\\x18\\x01 \\x01(\\x08\\\"5\\n\\x0f\\x44isposeResponse\\x12\\x15\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04H\\x00\\x88\\x01\\x01\\x42\\x0b\\n\\t_async_id\\\"#\\n\\x0f\\x44isposeCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'ffi_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n  _FFIREQUEST._serialized_start=92\n  _FFIREQUEST._serialized_end=1503\n  _FFIRESPONSE._serialized_start=1506\n  _FFIRESPONSE._serialized_end=2940\n  _FFIEVENT._serialized_start=2943\n  _FFIEVENT._serialized_end=3535\n  _INITIALIZEREQUEST._serialized_start=3537\n  _INITIALIZEREQUEST._serialized_end=3584\n  _INITIALIZERESPONSE._serialized_start=3586\n  _INITIALIZERESPONSE._serialized_end=3606\n  _DISPOSEREQUEST._serialized_start=3608\n  _DISPOSEREQUEST._serialized_end=3639\n  _DISPOSERESPONSE._serialized_start=3641\n  _DISPOSERESPONSE._serialized_end=3694\n  _DISPOSECALLBACK._serialized_start=3696\n  _DISPOSECALLBACK._serialized_end=3731", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/track_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: track.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom . import handle_pb2 as handle__pb2\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x0btrack.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\">\\n\\x17\\x43reateVideoTrackRequest\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rsource_handle\\x18\\x02 \\x01(\\x04\\\"C\\n\\x18\\x43reateVideoTrackResponse\\x12\\'\\n\\x05track\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\">\\n\\x17\\x43reateAudioTrackRequest\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rsource_handle\\x18\\x02 \\x01(\\x04\\\"C\\n\\x18\\x43reateAudioTrackResponse\\x12\\'\\n\\x05track\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\"\\x0c\\n\\nTrackEvent\\\"\\x9a\\x02\\n\\x14TrackPublicationInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12&\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x18.livekit.proto.TrackKind\\x12*\\n\\x06source\\x18\\x05 \\x01(\\x0e\\x32\\x1a.livekit.proto.TrackSource\\x12\\x13\\n\\x0bsimulcasted\\x18\\x06 \\x01(\\x08\\x12\\r\\n\\x05width\\x18\\x07 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x08 \\x01(\\r\\x12\\x11\\n\\tmime_type\\x18\\t \\x01(\\t\\x12\\r\\n\\x05muted\\x18\\n \\x01(\\x08\\x12\\x0e\\n\\x06remote\\x18\\x0b \\x01(\\x08\\\"\\xce\\x01\\n\\tTrackInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12&\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x18.livekit.proto.TrackKind\\x12\\x30\\n\\x0cstream_state\\x18\\x05 \\x01(\\x0e\\x32\\x1a.livekit.proto.StreamState\\x12\\r\\n\\x05muted\\x18\\x06 \\x01(\\x08\\x12\\x0e\\n\\x06remote\\x18\\x07 \\x01(\\x08*=\\n\\tTrackKind\\x12\\x10\\n\\x0cKIND_UNKNOWN\\x10\\x00\\x12\\x0e\\n\\nKIND_AUDIO\\x10\\x01\\x12\\x0e\\n\\nKIND_VIDEO\\x10\\x02*\\x81\\x01\\n\\x0bTrackSource\\x12\\x12\\n\\x0eSOURCE_UNKNOWN\\x10\\x00\\x12\\x11\\n\\rSOURCE_CAMERA\\x10\\x01\\x12\\x15\\n\\x11SOURCE_MICROPHONE\\x10\\x02\\x12\\x16\\n\\x12SOURCE_SCREENSHARE\\x10\\x03\\x12\\x1c\\n\\x18SOURCE_SCREENSHARE_AUDIO\\x10\\x04*D\\n\\x0bStreamState\\x12\\x11\\n\\rSTATE_UNKNOWN\\x10\\x00\\x12\\x10\\n\\x0cSTATE_ACTIVE\\x10\\x01\\x12\\x10\\n\\x0cSTATE_PAUSED\\x10\\x02\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n", "DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x0btrack.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\">\\n\\x17\\x43reateVideoTrackRequest\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rsource_handle\\x18\\x02 \\x01(\\x04\\\"C\\n\\x18\\x43reateVideoTrackResponse\\x12\\'\\n\\x05track\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\">\\n\\x17\\x43reateAudioTrackRequest\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\rsource_handle\\x18\\x02 \\x01(\\x04\\\"C\\n\\x18\\x43reateAudioTrackResponse\\x12\\'\\n\\x05track\\x18\\x01 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\"\\x0c\\n\\nTrackEvent\\\"\\x9a\\x02\\n\\x14TrackPublicationInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12&\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x18.livekit.proto.TrackKind\\x12*\\n\\x06source\\x18\\x05 \\x01(\\x0e\\x32\\x1a.livekit.proto.TrackSource\\x12\\x13\\n\\x0bsimulcasted\\x18\\x06 \\x01(\\x08\\x12\\r\\n\\x05width\\x18\\x07 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x08 \\x01(\\r\\x12\\x11\\n\\tmime_type\\x18\\t \\x01(\\t\\x12\\r\\n\\x05muted\\x18\\n \\x01(\\x08\\x12\\x0e\\n\\x06remote\\x18\\x0b \\x01(\\x08\\\"\\xce\\x01\\n\\tTrackInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12&\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x18.livekit.proto.TrackKind\\x12\\x30\\n\\x0cstream_state\\x18\\x05 \\x01(\\x0e\\x32\\x1a.livekit.proto.StreamState\\x12\\r\\n\\x05muted\\x18\\x06 \\x01(\\x08\\x12\\x0e\\n\\x06remote\\x18\\x07 \\x01(\\x08*=\\n\\tTrackKind\\x12\\x10\\n\\x0cKIND_UNKNOWN\\x10\\x00\\x12\\x0e\\n\\nKIND_AUDIO\\x10\\x01\\x12\\x0e\\n\\nKIND_VIDEO\\x10\\x02*\\x81\\x01\\n\\x0bTrackSource\\x12\\x12\\n\\x0eSOURCE_UNKNOWN\\x10\\x00\\x12\\x11\\n\\rSOURCE_CAMERA\\x10\\x01\\x12\\x15\\n\\x11SOURCE_MICROPHONE\\x10\\x02\\x12\\x16\\n\\x12SOURCE_SCREENSHARE\\x10\\x03\\x12\\x1c\\n\\x18SOURCE_SCREENSHARE_AUDIO\\x10\\x04*D\\n\\x0bStreamState\\x12\\x11\\n\\rSTATE_UNKNOWN\\x10\\x00\\x12\\x10\\n\\x0cSTATE_ACTIVE\\x10\\x01\\x12\\x10\\n\\x0cSTATE_PAUSED\\x10\\x02\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'track_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n  _TRACKKIND._serialized_start=818\n  _TRACKKIND._serialized_end=879\n  _TRACKSOURCE._serialized_start=882\n  _TRACKSOURCE._serialized_end=1011\n  _STREAMSTATE._serialized_start=1013\n  _STREAMSTATE._serialized_end=1081\n  _CREATEVIDEOTRACKREQUEST._serialized_start=44\n  _CREATEVIDEOTRACKREQUEST._serialized_end=106\n  _CREATEVIDEOTRACKRESPONSE._serialized_start=108\n  _CREATEVIDEOTRACKRESPONSE._serialized_end=175\n  _CREATEAUDIOTRACKREQUEST._serialized_start=177\n  _CREATEAUDIOTRACKREQUEST._serialized_end=239\n  _CREATEAUDIOTRACKRESPONSE._serialized_start=241\n  _CREATEAUDIOTRACKRESPONSE._serialized_end=308\n  _TRACKEVENT._serialized_start=310\n  _TRACKEVENT._serialized_end=322\n  _TRACKPUBLICATIONINFO._serialized_start=325\n  _TRACKPUBLICATIONINFO._serialized_end=607\n  _TRACKINFO._serialized_start=610\n  _TRACKINFO._serialized_end=816", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/room_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: room.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom . import handle_pb2 as handle__pb2\nfrom . import participant_pb2 as participant__pb2\nfrom . import track_pb2 as track__pb2\nfrom . import video_frame_pb2 as video__frame__pb2\n", "from . import video_frame_pb2 as video__frame__pb2\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\nroom.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\x1a\\x11participant.proto\\x1a\\x0btrack.proto\\x1a\\x11video_frame.proto\\\"Y\\n\\x0e\\x43onnectRequest\\x12\\x0b\\n\\x03url\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05token\\x18\\x02 \\x01(\\t\\x12+\\n\\x07options\\x18\\x03 \\x01(\\x0b\\x32\\x1a.livekit.proto.RoomOptions\\\"#\\n\\x0f\\x43onnectResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"\\xf9\\x02\\n\\x0f\\x43onnectCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x12%\\n\\x04room\\x18\\x03 \\x01(\\x0b\\x32\\x17.livekit.proto.RoomInfo\\x12\\x39\\n\\x11local_participant\\x18\\x04 \\x01(\\x0b\\x32\\x1e.livekit.proto.ParticipantInfo\\x12J\\n\\x0cparticipants\\x18\\x05 \\x03(\\x0b\\x32\\x34.livekit.proto.ConnectCallback.ParticipantWithTracks\\x1a\\x87\\x01\\n\\x15ParticipantWithTracks\\x12\\x33\\n\\x0bparticipant\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.ParticipantInfo\\x12\\x39\\n\\x0cpublications\\x18\\x02 \\x03(\\x0b\\x32#.livekit.proto.TrackPublicationInfoB\\x08\\n\\x06_error\\\"(\\n\\x11\\x44isconnectRequest\\x12\\x13\\n\\x0broom_handle\\x18\\x01 \\x01(\\x04\\\"&\\n\\x12\\x44isconnectResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"&\\n\\x12\\x44isconnectCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"\\x82\\x01\\n\\x13PublishTrackRequest\\x12 \\n\\x18local_participant_handle\\x18\\x01 \\x01(\\x04\\x12\\x14\\n\\x0ctrack_handle\\x18\\x02 \\x01(\\x04\\x12\\x33\\n\\x07options\\x18\\x03 \\x01(\\x0b\\x32\\\".livekit.proto.TrackPublishOptions\\\"(\\n\\x14PublishTrackResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"\\x80\\x01\\n\\x14PublishTrackCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x12\\x38\\n\\x0bpublication\\x18\\x03 \\x01(\\x0b\\x32#.livekit.proto.TrackPublicationInfoB\\x08\\n\\x06_error\\\"g\\n\\x15UnpublishTrackRequest\\x12 \\n\\x18local_participant_handle\\x18\\x01 \\x01(\\x04\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\x12\\x19\\n\\x11stop_on_unpublish\\x18\\x03 \\x01(\\x08\\\"*\\n\\x16UnpublishTrackResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"H\\n\\x16UnpublishTrackCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x42\\x08\\n\\x06_error\\\"\\xa1\\x01\\n\\x12PublishDataRequest\\x12 \\n\\x18local_participant_handle\\x18\\x01 \\x01(\\x04\\x12\\x10\\n\\x08\\x64\\x61ta_ptr\\x18\\x02 \\x01(\\x04\\x12\\x10\\n\\x08\\x64\\x61ta_len\\x18\\x03 \\x01(\\x04\\x12+\\n\\x04kind\\x18\\x04 \\x01(\\x0e\\x32\\x1d.livekit.proto.DataPacketKind\\x12\\x18\\n\\x10\\x64\\x65stination_sids\\x18\\x05 \\x03(\\t\\\"\\'\\n\\x13PublishDataResponse\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\\"E\\n\\x13PublishDataCallback\\x12\\x10\\n\\x08\\x61sync_id\\x18\\x01 \\x01(\\x04\\x12\\x12\\n\\x05\\x65rror\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x42\\x08\\n\\x06_error\\\"E\\n\\x14SetSubscribedRequest\\x12\\x11\\n\\tsubscribe\\x18\\x01 \\x01(\\x08\\x12\\x1a\\n\\x12publication_handle\\x18\\x02 \\x01(\\x04\\\"\\x17\\n\\x15SetSubscribedResponse\\\";\\n\\rVideoEncoding\\x12\\x13\\n\\x0bmax_bitrate\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rmax_framerate\\x18\\x02 \\x01(\\x01\\\"$\\n\\rAudioEncoding\\x12\\x13\\n\\x0bmax_bitrate\\x18\\x01 \\x01(\\x04\\\"\\x8a\\x02\\n\\x13TrackPublishOptions\\x12\\x34\\n\\x0evideo_encoding\\x18\\x01 \\x01(\\x0b\\x32\\x1c.livekit.proto.VideoEncoding\\x12\\x34\\n\\x0e\\x61udio_encoding\\x18\\x02 \\x01(\\x0b\\x32\\x1c.livekit.proto.AudioEncoding\\x12.\\n\\x0bvideo_codec\\x18\\x03 \\x01(\\x0e\\x32\\x19.livekit.proto.VideoCodec\\x12\\x0b\\n\\x03\\x64tx\\x18\\x04 \\x01(\\x08\\x12\\x0b\\n\\x03red\\x18\\x05 \\x01(\\x08\\x12\\x11\\n\\tsimulcast\\x18\\x06 \\x01(\\x08\\x12*\\n\\x06source\\x18\\x07 \\x01(\\x0e\\x32\\x1a.livekit.proto.TrackSource\\\"P\\n\\x0bRoomOptions\\x12\\x16\\n\\x0e\\x61uto_subscribe\\x18\\x01 \\x01(\\x08\\x12\\x17\\n\\x0f\\x61\\x64\\x61ptive_stream\\x18\\x02 \\x01(\\x08\\x12\\x10\\n\\x08\\x64ynacast\\x18\\x03 \\x01(\\x08\\\"_\\n\\nBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x10\\n\\x08\\x64\\x61ta_ptr\\x18\\x02 \\x01(\\x04\\x12\\x10\\n\\x08\\x64\\x61ta_len\\x18\\x03 \\x01(\\x04\\\"\\xd9\\t\\n\\tRoomEvent\\x12\\x13\\n\\x0broom_handle\\x18\\x01 \\x01(\\x04\\x12\\x44\\n\\x15participant_connected\\x18\\x02 \\x01(\\x0b\\x32#.livekit.proto.ParticipantConnectedH\\x00\\x12J\\n\\x18participant_disconnected\\x18\\x03 \\x01(\\x0b\\x32&.livekit.proto.ParticipantDisconnectedH\\x00\\x12\\x43\\n\\x15local_track_published\\x18\\x04 \\x01(\\x0b\\x32\\\".livekit.proto.LocalTrackPublishedH\\x00\\x12G\\n\\x17local_track_unpublished\\x18\\x05 \\x01(\\x0b\\x32$.livekit.proto.LocalTrackUnpublishedH\\x00\\x12\\x38\\n\\x0ftrack_published\\x18\\x06 \\x01(\\x0b\\x32\\x1d.livekit.proto.TrackPublishedH\\x00\\x12<\\n\\x11track_unpublished\\x18\\x07 \\x01(\\x0b\\x32\\x1f.livekit.proto.TrackUnpublishedH\\x00\\x12:\\n\\x10track_subscribed\\x18\\x08 \\x01(\\x0b\\x32\\x1e.livekit.proto.TrackSubscribedH\\x00\\x12>\\n\\x12track_unsubscribed\\x18\\t \\x01(\\x0b\\x32 .livekit.proto.TrackUnsubscribedH\\x00\\x12K\\n\\x19track_subscription_failed\\x18\\n \\x01(\\x0b\\x32&.livekit.proto.TrackSubscriptionFailedH\\x00\\x12\\x30\\n\\x0btrack_muted\\x18\\x0b \\x01(\\x0b\\x32\\x19.livekit.proto.TrackMutedH\\x00\\x12\\x34\\n\\rtrack_unmuted\\x18\\x0c \\x01(\\x0b\\x32\\x1b.livekit.proto.TrackUnmutedH\\x00\\x12G\\n\\x17\\x61\\x63tive_speakers_changed\\x18\\r \\x01(\\x0b\\x32$.livekit.proto.ActiveSpeakersChangedH\\x00\\x12M\\n\\x1a\\x63onnection_quality_changed\\x18\\x0e \\x01(\\x0b\\x32\\'.livekit.proto.ConnectionQualityChangedH\\x00\\x12\\x34\\n\\rdata_received\\x18\\x0f \\x01(\\x0b\\x32\\x1b.livekit.proto.DataReceivedH\\x00\\x12I\\n\\x18\\x63onnection_state_changed\\x18\\x10 \\x01(\\x0b\\x32%.livekit.proto.ConnectionStateChangedH\\x00\\x12-\\n\\tconnected\\x18\\x11 \\x01(\\x0b\\x32\\x18.livekit.proto.ConnectedH\\x00\\x12\\x33\\n\\x0c\\x64isconnected\\x18\\x12 \\x01(\\x0b\\x32\\x1b.livekit.proto.DisconnectedH\\x00\\x12\\x33\\n\\x0creconnecting\\x18\\x13 \\x01(\\x0b\\x32\\x1b.livekit.proto.ReconnectingH\\x00\\x12\\x31\\n\\x0breconnected\\x18\\x14 \\x01(\\x0b\\x32\\x1a.livekit.proto.ReconnectedH\\x00\\x42\\t\\n\\x07message\\\"f\\n\\x08RoomInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x10\\n\\x08metadata\\x18\\x04 \\x01(\\t\\\"D\\n\\x14ParticipantConnected\\x12,\\n\\x04info\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.ParticipantInfo\\\"2\\n\\x17ParticipantDisconnected\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\\"(\\n\\x13LocalTrackPublished\\x12\\x11\\n\\ttrack_sid\\x18\\x01 \\x01(\\t\\\"0\\n\\x15LocalTrackUnpublished\\x12\\x17\\n\\x0fpublication_sid\\x18\\x01 \\x01(\\t\\\"c\\n\\x0eTrackPublished\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x38\\n\\x0bpublication\\x18\\x02 \\x01(\\x0b\\x32#.livekit.proto.TrackPublicationInfo\\\"D\\n\\x10TrackUnpublished\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x17\\n\\x0fpublication_sid\\x18\\x02 \\x01(\\t\\\"S\\n\\x0fTrackSubscribed\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\'\\n\\x05track\\x18\\x02 \\x01(\\x0b\\x32\\x18.livekit.proto.TrackInfo\\\"?\\n\\x11TrackUnsubscribed\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\\"T\\n\\x17TrackSubscriptionFailed\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\x12\\r\\n\\x05\\x65rror\\x18\\x03 \\x01(\\t\\\"8\\n\\nTrackMuted\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\\":\\n\\x0cTrackUnmuted\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\ttrack_sid\\x18\\x02 \\x01(\\t\\\"1\\n\\x15\\x41\\x63tiveSpeakersChanged\\x12\\x18\\n\\x10participant_sids\\x18\\x01 \\x03(\\t\\\"f\\n\\x18\\x43onnectionQualityChanged\\x12\\x17\\n\\x0fparticipant_sid\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\x07quality\\x18\\x02 \\x01(\\x0e\\x32 .livekit.proto.ConnectionQuality\\\"\\x96\\x01\\n\\x0c\\x44\\x61taReceived\\x12\\'\\n\\x04\\x64\\x61ta\\x18\\x01 \\x01(\\x0b\\x32\\x19.livekit.proto.BufferInfo\\x12\\x1c\\n\\x0fparticipant_sid\\x18\\x02 \\x01(\\tH\\x00\\x88\\x01\\x01\\x12+\\n\\x04kind\\x18\\x03 \\x01(\\x0e\\x32\\x1d.livekit.proto.DataPacketKindB\\x12\\n\\x10_participant_sid\\\"G\\n\\x16\\x43onnectionStateChanged\\x12-\\n\\x05state\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.ConnectionState\\\"\\x0b\\n\\tConnected\\\"\\x0e\\n\\x0c\\x44isconnected\\\"\\x0e\\n\\x0cReconnecting\\\"\\r\\n\\x0bReconnected*N\\n\\x11\\x43onnectionQuality\\x12\\x10\\n\\x0cQUALITY_POOR\\x10\\x00\\x12\\x10\\n\\x0cQUALITY_GOOD\\x10\\x01\\x12\\x15\\n\\x11QUALITY_EXCELLENT\\x10\\x02*S\\n\\x0f\\x43onnectionState\\x12\\x15\\n\\x11\\x43ONN_DISCONNECTED\\x10\\x00\\x12\\x12\\n\\x0e\\x43ONN_CONNECTED\\x10\\x01\\x12\\x15\\n\\x11\\x43ONN_RECONNECTING\\x10\\x02*3\\n\\x0e\\x44\\x61taPacketKind\\x12\\x0e\\n\\nKIND_LOSSY\\x10\\x00\\x12\\x11\\n\\rKIND_RELIABLE\\x10\\x01\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'room_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n  _CONNECTIONQUALITY._serialized_start=4700\n  _CONNECTIONQUALITY._serialized_end=4778\n  _CONNECTIONSTATE._serialized_start=4780\n  _CONNECTIONSTATE._serialized_end=4863\n  _DATAPACKETKIND._serialized_start=4865\n  _DATAPACKETKIND._serialized_end=4916\n  _CONNECTREQUEST._serialized_start=94\n  _CONNECTREQUEST._serialized_end=183\n  _CONNECTRESPONSE._serialized_start=185\n  _CONNECTRESPONSE._serialized_end=220\n  _CONNECTCALLBACK._serialized_start=223\n  _CONNECTCALLBACK._serialized_end=600\n  _CONNECTCALLBACK_PARTICIPANTWITHTRACKS._serialized_start=455\n  _CONNECTCALLBACK_PARTICIPANTWITHTRACKS._serialized_end=590\n  _DISCONNECTREQUEST._serialized_start=602\n  _DISCONNECTREQUEST._serialized_end=642\n  _DISCONNECTRESPONSE._serialized_start=644\n  _DISCONNECTRESPONSE._serialized_end=682\n  _DISCONNECTCALLBACK._serialized_start=684\n  _DISCONNECTCALLBACK._serialized_end=722\n  _PUBLISHTRACKREQUEST._serialized_start=725\n  _PUBLISHTRACKREQUEST._serialized_end=855\n  _PUBLISHTRACKRESPONSE._serialized_start=857\n  _PUBLISHTRACKRESPONSE._serialized_end=897\n  _PUBLISHTRACKCALLBACK._serialized_start=900\n  _PUBLISHTRACKCALLBACK._serialized_end=1028\n  _UNPUBLISHTRACKREQUEST._serialized_start=1030\n  _UNPUBLISHTRACKREQUEST._serialized_end=1133\n  _UNPUBLISHTRACKRESPONSE._serialized_start=1135\n  _UNPUBLISHTRACKRESPONSE._serialized_end=1177\n  _UNPUBLISHTRACKCALLBACK._serialized_start=1179\n  _UNPUBLISHTRACKCALLBACK._serialized_end=1251\n  _PUBLISHDATAREQUEST._serialized_start=1254\n  _PUBLISHDATAREQUEST._serialized_end=1415\n  _PUBLISHDATARESPONSE._serialized_start=1417\n  _PUBLISHDATARESPONSE._serialized_end=1456\n  _PUBLISHDATACALLBACK._serialized_start=1458\n  _PUBLISHDATACALLBACK._serialized_end=1527\n  _SETSUBSCRIBEDREQUEST._serialized_start=1529\n  _SETSUBSCRIBEDREQUEST._serialized_end=1598\n  _SETSUBSCRIBEDRESPONSE._serialized_start=1600\n  _SETSUBSCRIBEDRESPONSE._serialized_end=1623\n  _VIDEOENCODING._serialized_start=1625\n  _VIDEOENCODING._serialized_end=1684\n  _AUDIOENCODING._serialized_start=1686\n  _AUDIOENCODING._serialized_end=1722\n  _TRACKPUBLISHOPTIONS._serialized_start=1725\n  _TRACKPUBLISHOPTIONS._serialized_end=1991\n  _ROOMOPTIONS._serialized_start=1993\n  _ROOMOPTIONS._serialized_end=2073\n  _BUFFERINFO._serialized_start=2075\n  _BUFFERINFO._serialized_end=2170\n  _ROOMEVENT._serialized_start=2173\n  _ROOMEVENT._serialized_end=3414\n  _ROOMINFO._serialized_start=3416\n  _ROOMINFO._serialized_end=3518\n  _PARTICIPANTCONNECTED._serialized_start=3520\n  _PARTICIPANTCONNECTED._serialized_end=3588\n  _PARTICIPANTDISCONNECTED._serialized_start=3590\n  _PARTICIPANTDISCONNECTED._serialized_end=3640\n  _LOCALTRACKPUBLISHED._serialized_start=3642\n  _LOCALTRACKPUBLISHED._serialized_end=3682\n  _LOCALTRACKUNPUBLISHED._serialized_start=3684\n  _LOCALTRACKUNPUBLISHED._serialized_end=3732\n  _TRACKPUBLISHED._serialized_start=3734\n  _TRACKPUBLISHED._serialized_end=3833\n  _TRACKUNPUBLISHED._serialized_start=3835\n  _TRACKUNPUBLISHED._serialized_end=3903\n  _TRACKSUBSCRIBED._serialized_start=3905\n  _TRACKSUBSCRIBED._serialized_end=3988\n  _TRACKUNSUBSCRIBED._serialized_start=3990\n  _TRACKUNSUBSCRIBED._serialized_end=4053\n  _TRACKSUBSCRIPTIONFAILED._serialized_start=4055\n  _TRACKSUBSCRIPTIONFAILED._serialized_end=4139\n  _TRACKMUTED._serialized_start=4141\n  _TRACKMUTED._serialized_end=4197\n  _TRACKUNMUTED._serialized_start=4199\n  _TRACKUNMUTED._serialized_end=4257\n  _ACTIVESPEAKERSCHANGED._serialized_start=4259\n  _ACTIVESPEAKERSCHANGED._serialized_end=4308\n  _CONNECTIONQUALITYCHANGED._serialized_start=4310\n  _CONNECTIONQUALITYCHANGED._serialized_end=4412\n  _DATARECEIVED._serialized_start=4415\n  _DATARECEIVED._serialized_end=4565\n  _CONNECTIONSTATECHANGED._serialized_start=4567\n  _CONNECTIONSTATECHANGED._serialized_end=4638\n  _CONNECTED._serialized_start=4640\n  _CONNECTED._serialized_end=4651\n  _DISCONNECTED._serialized_start=4653\n  _DISCONNECTED._serialized_end=4667\n  _RECONNECTING._serialized_start=4669\n  _RECONNECTING._serialized_end=4683\n  _RECONNECTED._serialized_start=4685\n  _RECONNECTED._serialized_end=4698", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/__init__.py", "chunked_list": ["# Copyright 2023 LiveKit, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,", "# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n"]}
{"filename": "livekit/_proto/participant_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: participant.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom . import handle_pb2 as handle__pb2\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11participant.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"\\x7f\\n\\x0fParticipantInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x10\\n\\x08identity\\x18\\x04 \\x01(\\t\\x12\\x10\\n\\x08metadata\\x18\\x05 \\x01(\\tB\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n", "DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11participant.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"\\x7f\\n\\x0fParticipantInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x0b\\n\\x03sid\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x10\\n\\x08identity\\x18\\x04 \\x01(\\t\\x12\\x10\\n\\x08metadata\\x18\\x05 \\x01(\\tB\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'participant_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n  _PARTICIPANTINFO._serialized_start=50\n  _PARTICIPANTINFO._serialized_end=177", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/video_frame_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: video_frame.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom . import handle_pb2 as handle__pb2\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11video_frame.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"k\\n\\x17\\x41llocVideoBufferRequest\\x12\\x31\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32#.livekit.proto.VideoFrameBufferType\\x12\\r\\n\\x05width\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\\"O\\n\\x18\\x41llocVideoBufferResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"[\\n\\x15NewVideoStreamRequest\\x12\\x14\\n\\x0ctrack_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoStreamType\\\"H\\n\\x16NewVideoStreamResponse\\x12.\\n\\x06stream\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.VideoStreamInfo\\\"\\x93\\x01\\n\\x15NewVideoSourceRequest\\x12,\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoSourceType\\x12=\\n\\nresolution\\x18\\x02 \\x01(\\x0b\\x32$.livekit.proto.VideoSourceResolutionH\\x00\\x88\\x01\\x01\\x42\\r\\n\\x0b_resolution\\\"H\\n\\x16NewVideoSourceResponse\\x12.\\n\\x06source\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.VideoSourceInfo\\\"v\\n\\x18\\x43\\x61ptureVideoFrameRequest\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x05\\x66rame\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.VideoFrameInfo\\x12\\x15\\n\\rbuffer_handle\\x18\\x03 \\x01(\\x04\\\"\\x1b\\n\\x19\\x43\\x61ptureVideoFrameResponse\\\"o\\n\\rToI420Request\\x12\\x0e\\n\\x06\\x66lip_y\\x18\\x01 \\x01(\\x08\\x12-\\n\\x04\\x61rgb\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.ARGBBufferInfoH\\x00\\x12\\x17\\n\\rbuffer_handle\\x18\\x03 \\x01(\\x04H\\x00\\x42\\x06\\n\\x04\\x66rom\\\"E\\n\\x0eToI420Response\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"\\xb6\\x01\\n\\rToArgbRequest\\x12\\x15\\n\\rbuffer_handle\\x18\\x01 \\x01(\\x04\\x12\\x0f\\n\\x07\\x64st_ptr\\x18\\x02 \\x01(\\x04\\x12\\x32\\n\\ndst_format\\x18\\x03 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoFormatType\\x12\\x12\\n\\ndst_stride\\x18\\x04 \\x01(\\r\\x12\\x11\\n\\tdst_width\\x18\\x05 \\x01(\\r\\x12\\x12\\n\\ndst_height\\x18\\x06 \\x01(\\r\\x12\\x0e\\n\\x06\\x66lip_y\\x18\\x07 \\x01(\\x08\\\"\\x10\\n\\x0eToArgbResponse\\\"D\\n\\x0fVideoResolution\\x12\\r\\n\\x05width\\x18\\x01 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\r\\x12\\x12\\n\\nframe_rate\\x18\\x03 \\x01(\\x01\\\"|\\n\\x0e\\x41RGBBufferInfo\\x12\\x0b\\n\\x03ptr\\x18\\x01 \\x01(\\x04\\x12.\\n\\x06\\x66ormat\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoFormatType\\x12\\x0e\\n\\x06stride\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x05 \\x01(\\r\\\"V\\n\\x0eVideoFrameInfo\\x12\\x14\\n\\x0ctimestamp_us\\x18\\x01 \\x01(\\x03\\x12.\\n\\x08rotation\\x18\\x02 \\x01(\\x0e\\x32\\x1c.livekit.proto.VideoRotation\\\"\\xc6\\x02\\n\\x14VideoFrameBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x38\\n\\x0b\\x62uffer_type\\x18\\x02 \\x01(\\x0e\\x32#.livekit.proto.VideoFrameBufferType\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x01(\\r\\x12\\x31\\n\\x03yuv\\x18\\x05 \\x01(\\x0b\\x32\\\".livekit.proto.PlanarYuvBufferInfoH\\x00\\x12\\x36\\n\\x06\\x62i_yuv\\x18\\x06 \\x01(\\x0b\\x32$.livekit.proto.BiplanarYuvBufferInfoH\\x00\\x12\\x31\\n\\x06native\\x18\\x07 \\x01(\\x0b\\x32\\x1f.livekit.proto.NativeBufferInfoH\\x00\\x42\\x08\\n\\x06\\x62uffer\\\"\\xda\\x01\\n\\x13PlanarYuvBufferInfo\\x12\\x14\\n\\x0c\\x63hroma_width\\x18\\x01 \\x01(\\r\\x12\\x15\\n\\rchroma_height\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08stride_y\\x18\\x03 \\x01(\\r\\x12\\x10\\n\\x08stride_u\\x18\\x04 \\x01(\\r\\x12\\x10\\n\\x08stride_v\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08stride_a\\x18\\x06 \\x01(\\r\\x12\\x12\\n\\ndata_y_ptr\\x18\\x07 \\x01(\\x04\\x12\\x12\\n\\ndata_u_ptr\\x18\\x08 \\x01(\\x04\\x12\\x12\\n\\ndata_v_ptr\\x18\\t \\x01(\\x04\\x12\\x12\\n\\ndata_a_ptr\\x18\\n \\x01(\\x04\\\"\\x92\\x01\\n\\x15\\x42iplanarYuvBufferInfo\\x12\\x14\\n\\x0c\\x63hroma_width\\x18\\x01 \\x01(\\r\\x12\\x15\\n\\rchroma_height\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08stride_y\\x18\\x03 \\x01(\\r\\x12\\x11\\n\\tstride_uv\\x18\\x04 \\x01(\\r\\x12\\x12\\n\\ndata_y_ptr\\x18\\x05 \\x01(\\x04\\x12\\x13\\n\\x0b\\x64\\x61ta_uv_ptr\\x18\\x06 \\x01(\\x04\\\"\\x12\\n\\x10NativeBufferInfo\\\"n\\n\\x0fVideoStreamInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoStreamType\\\"q\\n\\x10VideoStreamEvent\\x12\\x15\\n\\rstream_handle\\x18\\x01 \\x01(\\x04\\x12;\\n\\x0e\\x66rame_received\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.VideoFrameReceivedH\\x00\\x42\\t\\n\\x07message\\\"w\\n\\x12VideoFrameReceived\\x12,\\n\\x05\\x66rame\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.VideoFrameInfo\\x12\\x33\\n\\x06\\x62uffer\\x18\\x02 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"6\\n\\x15VideoSourceResolution\\x12\\r\\n\\x05width\\x18\\x01 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\r\\\"n\\n\\x0fVideoSourceInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoSourceType*(\\n\\nVideoCodec\\x12\\x07\\n\\x03VP8\\x10\\x00\\x12\\x08\\n\\x04H264\\x10\\x01\\x12\\x07\\n\\x03\\x41V1\\x10\\x02*l\\n\\rVideoRotation\\x12\\x14\\n\\x10VIDEO_ROTATION_0\\x10\\x00\\x12\\x15\\n\\x11VIDEO_ROTATION_90\\x10\\x01\\x12\\x16\\n\\x12VIDEO_ROTATION_180\\x10\\x02\\x12\\x16\\n\\x12VIDEO_ROTATION_270\\x10\\x03*U\\n\\x0fVideoFormatType\\x12\\x0f\\n\\x0b\\x46ORMAT_ARGB\\x10\\x00\\x12\\x0f\\n\\x0b\\x46ORMAT_BGRA\\x10\\x01\\x12\\x0f\\n\\x0b\\x46ORMAT_ABGR\\x10\\x02\\x12\\x0f\\n\\x0b\\x46ORMAT_RGBA\\x10\\x03*j\\n\\x14VideoFrameBufferType\\x12\\n\\n\\x06NATIVE\\x10\\x00\\x12\\x08\\n\\x04I420\\x10\\x01\\x12\\t\\n\\x05I420A\\x10\\x02\\x12\\x08\\n\\x04I422\\x10\\x03\\x12\\x08\\n\\x04I444\\x10\\x04\\x12\\x08\\n\\x04I010\\x10\\x05\\x12\\x08\\n\\x04NV12\\x10\\x06\\x12\\t\\n\\x05WEBGL\\x10\\x07*Y\\n\\x0fVideoStreamType\\x12\\x17\\n\\x13VIDEO_STREAM_NATIVE\\x10\\x00\\x12\\x16\\n\\x12VIDEO_STREAM_WEBGL\\x10\\x01\\x12\\x15\\n\\x11VIDEO_STREAM_HTML\\x10\\x02**\\n\\x0fVideoSourceType\\x12\\x17\\n\\x13VIDEO_SOURCE_NATIVE\\x10\\x00\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n", "DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11video_frame.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"k\\n\\x17\\x41llocVideoBufferRequest\\x12\\x31\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32#.livekit.proto.VideoFrameBufferType\\x12\\r\\n\\x05width\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\\"O\\n\\x18\\x41llocVideoBufferResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"[\\n\\x15NewVideoStreamRequest\\x12\\x14\\n\\x0ctrack_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoStreamType\\\"H\\n\\x16NewVideoStreamResponse\\x12.\\n\\x06stream\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.VideoStreamInfo\\\"\\x93\\x01\\n\\x15NewVideoSourceRequest\\x12,\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoSourceType\\x12=\\n\\nresolution\\x18\\x02 \\x01(\\x0b\\x32$.livekit.proto.VideoSourceResolutionH\\x00\\x88\\x01\\x01\\x42\\r\\n\\x0b_resolution\\\"H\\n\\x16NewVideoSourceResponse\\x12.\\n\\x06source\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.VideoSourceInfo\\\"v\\n\\x18\\x43\\x61ptureVideoFrameRequest\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x05\\x66rame\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.VideoFrameInfo\\x12\\x15\\n\\rbuffer_handle\\x18\\x03 \\x01(\\x04\\\"\\x1b\\n\\x19\\x43\\x61ptureVideoFrameResponse\\\"o\\n\\rToI420Request\\x12\\x0e\\n\\x06\\x66lip_y\\x18\\x01 \\x01(\\x08\\x12-\\n\\x04\\x61rgb\\x18\\x02 \\x01(\\x0b\\x32\\x1d.livekit.proto.ARGBBufferInfoH\\x00\\x12\\x17\\n\\rbuffer_handle\\x18\\x03 \\x01(\\x04H\\x00\\x42\\x06\\n\\x04\\x66rom\\\"E\\n\\x0eToI420Response\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"\\xb6\\x01\\n\\rToArgbRequest\\x12\\x15\\n\\rbuffer_handle\\x18\\x01 \\x01(\\x04\\x12\\x0f\\n\\x07\\x64st_ptr\\x18\\x02 \\x01(\\x04\\x12\\x32\\n\\ndst_format\\x18\\x03 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoFormatType\\x12\\x12\\n\\ndst_stride\\x18\\x04 \\x01(\\r\\x12\\x11\\n\\tdst_width\\x18\\x05 \\x01(\\r\\x12\\x12\\n\\ndst_height\\x18\\x06 \\x01(\\r\\x12\\x0e\\n\\x06\\x66lip_y\\x18\\x07 \\x01(\\x08\\\"\\x10\\n\\x0eToArgbResponse\\\"D\\n\\x0fVideoResolution\\x12\\r\\n\\x05width\\x18\\x01 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\r\\x12\\x12\\n\\nframe_rate\\x18\\x03 \\x01(\\x01\\\"|\\n\\x0e\\x41RGBBufferInfo\\x12\\x0b\\n\\x03ptr\\x18\\x01 \\x01(\\x04\\x12.\\n\\x06\\x66ormat\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoFormatType\\x12\\x0e\\n\\x06stride\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x05 \\x01(\\r\\\"V\\n\\x0eVideoFrameInfo\\x12\\x14\\n\\x0ctimestamp_us\\x18\\x01 \\x01(\\x03\\x12.\\n\\x08rotation\\x18\\x02 \\x01(\\x0e\\x32\\x1c.livekit.proto.VideoRotation\\\"\\xc6\\x02\\n\\x14VideoFrameBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x38\\n\\x0b\\x62uffer_type\\x18\\x02 \\x01(\\x0e\\x32#.livekit.proto.VideoFrameBufferType\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x01(\\r\\x12\\x31\\n\\x03yuv\\x18\\x05 \\x01(\\x0b\\x32\\\".livekit.proto.PlanarYuvBufferInfoH\\x00\\x12\\x36\\n\\x06\\x62i_yuv\\x18\\x06 \\x01(\\x0b\\x32$.livekit.proto.BiplanarYuvBufferInfoH\\x00\\x12\\x31\\n\\x06native\\x18\\x07 \\x01(\\x0b\\x32\\x1f.livekit.proto.NativeBufferInfoH\\x00\\x42\\x08\\n\\x06\\x62uffer\\\"\\xda\\x01\\n\\x13PlanarYuvBufferInfo\\x12\\x14\\n\\x0c\\x63hroma_width\\x18\\x01 \\x01(\\r\\x12\\x15\\n\\rchroma_height\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08stride_y\\x18\\x03 \\x01(\\r\\x12\\x10\\n\\x08stride_u\\x18\\x04 \\x01(\\r\\x12\\x10\\n\\x08stride_v\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08stride_a\\x18\\x06 \\x01(\\r\\x12\\x12\\n\\ndata_y_ptr\\x18\\x07 \\x01(\\x04\\x12\\x12\\n\\ndata_u_ptr\\x18\\x08 \\x01(\\x04\\x12\\x12\\n\\ndata_v_ptr\\x18\\t \\x01(\\x04\\x12\\x12\\n\\ndata_a_ptr\\x18\\n \\x01(\\x04\\\"\\x92\\x01\\n\\x15\\x42iplanarYuvBufferInfo\\x12\\x14\\n\\x0c\\x63hroma_width\\x18\\x01 \\x01(\\r\\x12\\x15\\n\\rchroma_height\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08stride_y\\x18\\x03 \\x01(\\r\\x12\\x11\\n\\tstride_uv\\x18\\x04 \\x01(\\r\\x12\\x12\\n\\ndata_y_ptr\\x18\\x05 \\x01(\\x04\\x12\\x13\\n\\x0b\\x64\\x61ta_uv_ptr\\x18\\x06 \\x01(\\x04\\\"\\x12\\n\\x10NativeBufferInfo\\\"n\\n\\x0fVideoStreamInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoStreamType\\\"q\\n\\x10VideoStreamEvent\\x12\\x15\\n\\rstream_handle\\x18\\x01 \\x01(\\x04\\x12;\\n\\x0e\\x66rame_received\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.VideoFrameReceivedH\\x00\\x42\\t\\n\\x07message\\\"w\\n\\x12VideoFrameReceived\\x12,\\n\\x05\\x66rame\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.VideoFrameInfo\\x12\\x33\\n\\x06\\x62uffer\\x18\\x02 \\x01(\\x0b\\x32#.livekit.proto.VideoFrameBufferInfo\\\"6\\n\\x15VideoSourceResolution\\x12\\r\\n\\x05width\\x18\\x01 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\r\\\"n\\n\\x0fVideoSourceInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.VideoSourceType*(\\n\\nVideoCodec\\x12\\x07\\n\\x03VP8\\x10\\x00\\x12\\x08\\n\\x04H264\\x10\\x01\\x12\\x07\\n\\x03\\x41V1\\x10\\x02*l\\n\\rVideoRotation\\x12\\x14\\n\\x10VIDEO_ROTATION_0\\x10\\x00\\x12\\x15\\n\\x11VIDEO_ROTATION_90\\x10\\x01\\x12\\x16\\n\\x12VIDEO_ROTATION_180\\x10\\x02\\x12\\x16\\n\\x12VIDEO_ROTATION_270\\x10\\x03*U\\n\\x0fVideoFormatType\\x12\\x0f\\n\\x0b\\x46ORMAT_ARGB\\x10\\x00\\x12\\x0f\\n\\x0b\\x46ORMAT_BGRA\\x10\\x01\\x12\\x0f\\n\\x0b\\x46ORMAT_ABGR\\x10\\x02\\x12\\x0f\\n\\x0b\\x46ORMAT_RGBA\\x10\\x03*j\\n\\x14VideoFrameBufferType\\x12\\n\\n\\x06NATIVE\\x10\\x00\\x12\\x08\\n\\x04I420\\x10\\x01\\x12\\t\\n\\x05I420A\\x10\\x02\\x12\\x08\\n\\x04I422\\x10\\x03\\x12\\x08\\n\\x04I444\\x10\\x04\\x12\\x08\\n\\x04I010\\x10\\x05\\x12\\x08\\n\\x04NV12\\x10\\x06\\x12\\t\\n\\x05WEBGL\\x10\\x07*Y\\n\\x0fVideoStreamType\\x12\\x17\\n\\x13VIDEO_STREAM_NATIVE\\x10\\x00\\x12\\x16\\n\\x12VIDEO_STREAM_WEBGL\\x10\\x01\\x12\\x15\\n\\x11VIDEO_STREAM_HTML\\x10\\x02**\\n\\x0fVideoSourceType\\x12\\x17\\n\\x13VIDEO_SOURCE_NATIVE\\x10\\x00\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'video_frame_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n  _VIDEOCODEC._serialized_start=2686\n  _VIDEOCODEC._serialized_end=2726\n  _VIDEOROTATION._serialized_start=2728\n  _VIDEOROTATION._serialized_end=2836\n  _VIDEOFORMATTYPE._serialized_start=2838\n  _VIDEOFORMATTYPE._serialized_end=2923\n  _VIDEOFRAMEBUFFERTYPE._serialized_start=2925\n  _VIDEOFRAMEBUFFERTYPE._serialized_end=3031\n  _VIDEOSTREAMTYPE._serialized_start=3033\n  _VIDEOSTREAMTYPE._serialized_end=3122\n  _VIDEOSOURCETYPE._serialized_start=3124\n  _VIDEOSOURCETYPE._serialized_end=3166\n  _ALLOCVIDEOBUFFERREQUEST._serialized_start=50\n  _ALLOCVIDEOBUFFERREQUEST._serialized_end=157\n  _ALLOCVIDEOBUFFERRESPONSE._serialized_start=159\n  _ALLOCVIDEOBUFFERRESPONSE._serialized_end=238\n  _NEWVIDEOSTREAMREQUEST._serialized_start=240\n  _NEWVIDEOSTREAMREQUEST._serialized_end=331\n  _NEWVIDEOSTREAMRESPONSE._serialized_start=333\n  _NEWVIDEOSTREAMRESPONSE._serialized_end=405\n  _NEWVIDEOSOURCEREQUEST._serialized_start=408\n  _NEWVIDEOSOURCEREQUEST._serialized_end=555\n  _NEWVIDEOSOURCERESPONSE._serialized_start=557\n  _NEWVIDEOSOURCERESPONSE._serialized_end=629\n  _CAPTUREVIDEOFRAMEREQUEST._serialized_start=631\n  _CAPTUREVIDEOFRAMEREQUEST._serialized_end=749\n  _CAPTUREVIDEOFRAMERESPONSE._serialized_start=751\n  _CAPTUREVIDEOFRAMERESPONSE._serialized_end=778\n  _TOI420REQUEST._serialized_start=780\n  _TOI420REQUEST._serialized_end=891\n  _TOI420RESPONSE._serialized_start=893\n  _TOI420RESPONSE._serialized_end=962\n  _TOARGBREQUEST._serialized_start=965\n  _TOARGBREQUEST._serialized_end=1147\n  _TOARGBRESPONSE._serialized_start=1149\n  _TOARGBRESPONSE._serialized_end=1165\n  _VIDEORESOLUTION._serialized_start=1167\n  _VIDEORESOLUTION._serialized_end=1235\n  _ARGBBUFFERINFO._serialized_start=1237\n  _ARGBBUFFERINFO._serialized_end=1361\n  _VIDEOFRAMEINFO._serialized_start=1363\n  _VIDEOFRAMEINFO._serialized_end=1449\n  _VIDEOFRAMEBUFFERINFO._serialized_start=1452\n  _VIDEOFRAMEBUFFERINFO._serialized_end=1778\n  _PLANARYUVBUFFERINFO._serialized_start=1781\n  _PLANARYUVBUFFERINFO._serialized_end=1999\n  _BIPLANARYUVBUFFERINFO._serialized_start=2002\n  _BIPLANARYUVBUFFERINFO._serialized_end=2148\n  _NATIVEBUFFERINFO._serialized_start=2150\n  _NATIVEBUFFERINFO._serialized_end=2168\n  _VIDEOSTREAMINFO._serialized_start=2170\n  _VIDEOSTREAMINFO._serialized_end=2280\n  _VIDEOSTREAMEVENT._serialized_start=2282\n  _VIDEOSTREAMEVENT._serialized_end=2395\n  _VIDEOFRAMERECEIVED._serialized_start=2397\n  _VIDEOFRAMERECEIVED._serialized_end=2516\n  _VIDEOSOURCERESOLUTION._serialized_start=2518\n  _VIDEOSOURCERESOLUTION._serialized_end=2572\n  _VIDEOSOURCEINFO._serialized_start=2574\n  _VIDEOSOURCEINFO._serialized_end=2684", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/handle_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: handle.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x0chandle.proto\\x12\\rlivekit.proto\\\"\\x1c\\n\\x0e\\x46\\x66iOwnedHandle\\x12\\n\\n\\x02id\\x18\\x01 \\x01(\\x04\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())", "\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'handle_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n  _FFIOWNEDHANDLE._serialized_start=31\n  _FFIOWNEDHANDLE._serialized_end=59\n# @@protoc_insertion_point(module_scope)", "# @@protoc_insertion_point(module_scope)\n"]}
{"filename": "livekit/_proto/audio_frame_pb2.py", "chunked_list": ["# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: audio_frame.proto\n\"\"\"Generated protocol buffer code.\"\"\"\nfrom google.protobuf.internal import builder as _builder\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import descriptor_pool as _descriptor_pool\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n", "# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom . import handle_pb2 as handle__pb2\n\n\nDESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11\\x61udio_frame.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"a\\n\\x17\\x41llocAudioBufferRequest\\x12\\x13\\n\\x0bsample_rate\\x18\\x01 \\x01(\\r\\x12\\x14\\n\\x0cnum_channels\\x18\\x02 \\x01(\\r\\x12\\x1b\\n\\x13samples_per_channel\\x18\\x03 \\x01(\\r\\\"O\\n\\x18\\x41llocAudioBufferResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"[\\n\\x15NewAudioStreamRequest\\x12\\x14\\n\\x0ctrack_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioStreamType\\\"H\\n\\x16NewAudioStreamResponse\\x12.\\n\\x06stream\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.AudioStreamInfo\\\"\\x8a\\x01\\n\\x15NewAudioSourceRequest\\x12,\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioSourceType\\x12\\x37\\n\\x07options\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.AudioSourceOptionsH\\x00\\x88\\x01\\x01\\x42\\n\\n\\x08_options\\\"H\\n\\x16NewAudioSourceResponse\\x12.\\n\\x06source\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.AudioSourceInfo\\\"H\\n\\x18\\x43\\x61ptureAudioFrameRequest\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rbuffer_handle\\x18\\x02 \\x01(\\x04\\\"\\x1b\\n\\x19\\x43\\x61ptureAudioFrameResponse\\\"\\x1a\\n\\x18NewAudioResamplerRequest\\\"Q\\n\\x19NewAudioResamplerResponse\\x12\\x34\\n\\tresampler\\x18\\x01 \\x01(\\x0b\\x32!.livekit.proto.AudioResamplerInfo\\\"u\\n\\x17RemixAndResampleRequest\\x12\\x18\\n\\x10resampler_handle\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rbuffer_handle\\x18\\x02 \\x01(\\x04\\x12\\x14\\n\\x0cnum_channels\\x18\\x03 \\x01(\\r\\x12\\x13\\n\\x0bsample_rate\\x18\\x04 \\x01(\\r\\\"O\\n\\x18RemixAndResampleResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"\\x9f\\x01\\n\\x14\\x41udioFrameBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x10\\n\\x08\\x64\\x61ta_ptr\\x18\\x02 \\x01(\\x04\\x12\\x14\\n\\x0cnum_channels\\x18\\x03 \\x01(\\r\\x12\\x13\\n\\x0bsample_rate\\x18\\x04 \\x01(\\r\\x12\\x1b\\n\\x13samples_per_channel\\x18\\x05 \\x01(\\r\\\"n\\n\\x0f\\x41udioStreamInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioStreamType\\\"q\\n\\x10\\x41udioStreamEvent\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12;\\n\\x0e\\x66rame_received\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.AudioFrameReceivedH\\x00\\x42\\t\\n\\x07message\\\"H\\n\\x12\\x41udioFrameReceived\\x12\\x32\\n\\x05\\x66rame\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"e\\n\\x12\\x41udioSourceOptions\\x12\\x19\\n\\x11\\x65\\x63ho_cancellation\\x18\\x01 \\x01(\\x08\\x12\\x19\\n\\x11noise_suppression\\x18\\x02 \\x01(\\x08\\x12\\x19\\n\\x11\\x61uto_gain_control\\x18\\x03 \\x01(\\x08\\\"n\\n\\x0f\\x41udioSourceInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioSourceType\\\"C\\n\\x12\\x41udioResamplerInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle*A\\n\\x0f\\x41udioStreamType\\x12\\x17\\n\\x13\\x41UDIO_STREAM_NATIVE\\x10\\x00\\x12\\x15\\n\\x11\\x41UDIO_STREAM_HTML\\x10\\x01**\\n\\x0f\\x41udioSourceType\\x12\\x17\\n\\x13\\x41UDIO_SOURCE_NATIVE\\x10\\x00\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n", "DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\\n\\x11\\x61udio_frame.proto\\x12\\rlivekit.proto\\x1a\\x0chandle.proto\\\"a\\n\\x17\\x41llocAudioBufferRequest\\x12\\x13\\n\\x0bsample_rate\\x18\\x01 \\x01(\\r\\x12\\x14\\n\\x0cnum_channels\\x18\\x02 \\x01(\\r\\x12\\x1b\\n\\x13samples_per_channel\\x18\\x03 \\x01(\\r\\\"O\\n\\x18\\x41llocAudioBufferResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"[\\n\\x15NewAudioStreamRequest\\x12\\x14\\n\\x0ctrack_handle\\x18\\x01 \\x01(\\x04\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioStreamType\\\"H\\n\\x16NewAudioStreamResponse\\x12.\\n\\x06stream\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.AudioStreamInfo\\\"\\x8a\\x01\\n\\x15NewAudioSourceRequest\\x12,\\n\\x04type\\x18\\x01 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioSourceType\\x12\\x37\\n\\x07options\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.AudioSourceOptionsH\\x00\\x88\\x01\\x01\\x42\\n\\n\\x08_options\\\"H\\n\\x16NewAudioSourceResponse\\x12.\\n\\x06source\\x18\\x01 \\x01(\\x0b\\x32\\x1e.livekit.proto.AudioSourceInfo\\\"H\\n\\x18\\x43\\x61ptureAudioFrameRequest\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rbuffer_handle\\x18\\x02 \\x01(\\x04\\\"\\x1b\\n\\x19\\x43\\x61ptureAudioFrameResponse\\\"\\x1a\\n\\x18NewAudioResamplerRequest\\\"Q\\n\\x19NewAudioResamplerResponse\\x12\\x34\\n\\tresampler\\x18\\x01 \\x01(\\x0b\\x32!.livekit.proto.AudioResamplerInfo\\\"u\\n\\x17RemixAndResampleRequest\\x12\\x18\\n\\x10resampler_handle\\x18\\x01 \\x01(\\x04\\x12\\x15\\n\\rbuffer_handle\\x18\\x02 \\x01(\\x04\\x12\\x14\\n\\x0cnum_channels\\x18\\x03 \\x01(\\r\\x12\\x13\\n\\x0bsample_rate\\x18\\x04 \\x01(\\r\\\"O\\n\\x18RemixAndResampleResponse\\x12\\x33\\n\\x06\\x62uffer\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"\\x9f\\x01\\n\\x14\\x41udioFrameBufferInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12\\x10\\n\\x08\\x64\\x61ta_ptr\\x18\\x02 \\x01(\\x04\\x12\\x14\\n\\x0cnum_channels\\x18\\x03 \\x01(\\r\\x12\\x13\\n\\x0bsample_rate\\x18\\x04 \\x01(\\r\\x12\\x1b\\n\\x13samples_per_channel\\x18\\x05 \\x01(\\r\\\"n\\n\\x0f\\x41udioStreamInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioStreamType\\\"q\\n\\x10\\x41udioStreamEvent\\x12\\x15\\n\\rsource_handle\\x18\\x01 \\x01(\\x04\\x12;\\n\\x0e\\x66rame_received\\x18\\x02 \\x01(\\x0b\\x32!.livekit.proto.AudioFrameReceivedH\\x00\\x42\\t\\n\\x07message\\\"H\\n\\x12\\x41udioFrameReceived\\x12\\x32\\n\\x05\\x66rame\\x18\\x01 \\x01(\\x0b\\x32#.livekit.proto.AudioFrameBufferInfo\\\"e\\n\\x12\\x41udioSourceOptions\\x12\\x19\\n\\x11\\x65\\x63ho_cancellation\\x18\\x01 \\x01(\\x08\\x12\\x19\\n\\x11noise_suppression\\x18\\x02 \\x01(\\x08\\x12\\x19\\n\\x11\\x61uto_gain_control\\x18\\x03 \\x01(\\x08\\\"n\\n\\x0f\\x41udioSourceInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle\\x12,\\n\\x04type\\x18\\x02 \\x01(\\x0e\\x32\\x1e.livekit.proto.AudioSourceType\\\"C\\n\\x12\\x41udioResamplerInfo\\x12-\\n\\x06handle\\x18\\x01 \\x01(\\x0b\\x32\\x1d.livekit.proto.FfiOwnedHandle*A\\n\\x0f\\x41udioStreamType\\x12\\x17\\n\\x13\\x41UDIO_STREAM_NATIVE\\x10\\x00\\x12\\x15\\n\\x11\\x41UDIO_STREAM_HTML\\x10\\x01**\\n\\x0f\\x41udioSourceType\\x12\\x17\\n\\x13\\x41UDIO_SOURCE_NATIVE\\x10\\x00\\x42\\x10\\xaa\\x02\\rLiveKit.Protob\\x06proto3')\n\n_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())\n_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'audio_frame_pb2', globals())\nif _descriptor._USE_C_DESCRIPTORS == False:\n\n  DESCRIPTOR._options = None\n  DESCRIPTOR._serialized_options = b'\\252\\002\\rLiveKit.Proto'\n  _AUDIOSTREAMTYPE._serialized_start=1773\n  _AUDIOSTREAMTYPE._serialized_end=1838\n  _AUDIOSOURCETYPE._serialized_start=1840\n  _AUDIOSOURCETYPE._serialized_end=1882\n  _ALLOCAUDIOBUFFERREQUEST._serialized_start=50\n  _ALLOCAUDIOBUFFERREQUEST._serialized_end=147\n  _ALLOCAUDIOBUFFERRESPONSE._serialized_start=149\n  _ALLOCAUDIOBUFFERRESPONSE._serialized_end=228\n  _NEWAUDIOSTREAMREQUEST._serialized_start=230\n  _NEWAUDIOSTREAMREQUEST._serialized_end=321\n  _NEWAUDIOSTREAMRESPONSE._serialized_start=323\n  _NEWAUDIOSTREAMRESPONSE._serialized_end=395\n  _NEWAUDIOSOURCEREQUEST._serialized_start=398\n  _NEWAUDIOSOURCEREQUEST._serialized_end=536\n  _NEWAUDIOSOURCERESPONSE._serialized_start=538\n  _NEWAUDIOSOURCERESPONSE._serialized_end=610\n  _CAPTUREAUDIOFRAMEREQUEST._serialized_start=612\n  _CAPTUREAUDIOFRAMEREQUEST._serialized_end=684\n  _CAPTUREAUDIOFRAMERESPONSE._serialized_start=686\n  _CAPTUREAUDIOFRAMERESPONSE._serialized_end=713\n  _NEWAUDIORESAMPLERREQUEST._serialized_start=715\n  _NEWAUDIORESAMPLERREQUEST._serialized_end=741\n  _NEWAUDIORESAMPLERRESPONSE._serialized_start=743\n  _NEWAUDIORESAMPLERRESPONSE._serialized_end=824\n  _REMIXANDRESAMPLEREQUEST._serialized_start=826\n  _REMIXANDRESAMPLEREQUEST._serialized_end=943\n  _REMIXANDRESAMPLERESPONSE._serialized_start=945\n  _REMIXANDRESAMPLERESPONSE._serialized_end=1024\n  _AUDIOFRAMEBUFFERINFO._serialized_start=1027\n  _AUDIOFRAMEBUFFERINFO._serialized_end=1186\n  _AUDIOSTREAMINFO._serialized_start=1188\n  _AUDIOSTREAMINFO._serialized_end=1298\n  _AUDIOSTREAMEVENT._serialized_start=1300\n  _AUDIOSTREAMEVENT._serialized_end=1413\n  _AUDIOFRAMERECEIVED._serialized_start=1415\n  _AUDIOFRAMERECEIVED._serialized_end=1487\n  _AUDIOSOURCEOPTIONS._serialized_start=1489\n  _AUDIOSOURCEOPTIONS._serialized_end=1590\n  _AUDIOSOURCEINFO._serialized_start=1592\n  _AUDIOSOURCEINFO._serialized_end=1702\n  _AUDIORESAMPLERINFO._serialized_start=1704\n  _AUDIORESAMPLERINFO._serialized_end=1771", "# @@protoc_insertion_point(module_scope)\n"]}
